\begin{thebibliography}{10}

\bibitem{ba2016layernorm}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock {\em arXiv preprint arXiv:1607.06450}, 2016.

\bibitem{bai2022transfusion}
Xuyang Bai, Zeyu Hu, Xinge Zhu, Qingqiu Huang, Yilun Chen, Hongbo Fu, and
  Chiew-Lan Tai.
\newblock {TransFusion}: Robust lidar-camera fusion for 3d object detection
  with transformers.
\newblock In {\em CVPR}, 2022.

\bibitem{caesar2020nuscenes}
Holger Caesar, Varun Bankiti, Alex~H Lang, Sourabh Vora, Venice~Erin Liong,
  Qiang Xu, Anush Krishnan, Yu~Pan, Giancarlo Baldan, and Oscar Beijbom.
\newblock {nuScenes}: A multimodal dataset for autonomous driving.
\newblock In {\em CVPR}, 2020.

\bibitem{cai2022reversible}
Yuxuan Cai, Yizhuang Zhou, Qi~Han, Jianjian Sun, Xiangwen Kong, Jun Li, and
  Xiangyu Zhang.
\newblock Reversible column networks.
\newblock In {\em ICLR}, 2023.

\bibitem{chen2022persformer}
Li~Chen, Chonghao Sima, Yang Li, Zehan Zheng, Jiajie Xu, Xiangwei Geng,
  Hongyang Li, Conghui He, Jianping Shi, Yu~Qiao, et~al.
\newblock Persformer: 3d lane detection via perspective transformer and the
  openlane benchmark.
\newblock In {\em ECCV}, 2022.

\bibitem{chen2023end}
Li~Chen, Penghao Wu, Kashyap Chitta, Bernhard Jaeger, Andreas Geiger, and
  Hongyang Li.
\newblock End-to-end autonomous driving: Challenges and frontiers.
\newblock {\em arXiv preprint arXiv:2306.16927}, 2023.

\bibitem{cmz2023cf}
Mengzhao Chen, Mingbao Lin, Ke~Li, Yunhang Shen, Yongjian Wu, Fei Chao, and
  Rongrong Ji.
\newblock Cf-vit: A general coarse-to-fine method for vision transformer.
\newblock In {\em AAAI}, 2023.

\bibitem{cmz2023smmix}
Mengzhao Chen, Mingbao Lin, Zhihang Lin, Yuxin Zhang, Fei Chao, and Rongrong
  Ji.
\newblock Smmix: Self-motivated image mixing for vision transformers.
\newblock In {\em ICCV}, 2023.

\bibitem{cmz2023diffrate}
Mengzhao Chen, Wenqi Shao, Peng Xu, Mingbao Lin, Kaipeng Zhang, Fei Chao,
  Rongrong Ji, Yu~Qiao, and Ping Luo.
\newblock Diffrate: Differentiable compression rate for efficient vision
  transformers.
\newblock {\em arXiv preprint arXiv:2305.17997}, 2023.

\bibitem{chen2022futr3d}
Xuanyao Chen, Tianyuan Zhang, Yue Wang, Yilun Wang, and Hang Zhao.
\newblock Futr3d: A unified sensor fusion framework for 3d detection.
\newblock {\em arXiv preprint arXiv:2203.10642}, 2022.

\bibitem{chen2022bevdistill}
Zehui Chen, Zhenyu Li, Shiquan Zhang, Liangji Fang, Qinhong Jiang, and Feng
  Zhao.
\newblock Bevdistill: Cross-modal bev distillation for multi-view 3d object
  detection.
\newblock {\em arXiv preprint arXiv:2211.09386}, 2022.

\bibitem{chong2022monodistill}
Zhiyu Chong, Xinzhu Ma, Hong Zhang, Yuxin Yue, Haojie Li, Zhihui Wang, and
  Wanli Ouyang.
\newblock {MonoDistill}: Learning spatial features for monocular 3d object
  detection.
\newblock {\em arXiv preprint arXiv:2201.10830}, 2022.

\bibitem{mmdet3d2020}
MMDetection3D Contributors.
\newblock {MMDetection3D: OpenMMLab} next-generation platform for general {3D}
  object detection.
\newblock \url{https://github.com/open-mmlab/mmdetection3d}, 2020.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock {ImageNet}: A large-scale hierarchical image database.
\newblock In {\em CVPR}, 2009.

\bibitem{feng2022aedet}
Chengjian Feng, Zequn Jie, Yujie Zhong, Xiangxiang Chu, and Lin Ma.
\newblock Aedet: Azimuth-invariant multi-view 3d object detection.
\newblock {\em arXiv preprint arXiv:2211.12501}, 2022.

\bibitem{gao2023sparse}
Yulu Gao, Chonghao Sima, Shaoshuai Shi, Shangzhe Di, Si~Liu, and Hongyang Li.
\newblock Sparse dense fusion for 3d object detection.
\newblock In {\em IROS}, 2023.

\bibitem{guo2021liga}
Xiaoyang Guo, Shaoshuai Shi, Xiaogang Wang, and Hongsheng Li.
\newblock {LIGA-Stereo}: Learning lidar geometry aware representations for
  stereo-based 3d detector.
\newblock In {\em ICCV}, 2021.

\bibitem{han2023recurrent}
Chunrui Han, Jianjian Sun, Zheng Ge, Jinrong Yang, Runpei Dong, Hongyu Zhou,
  Weixin Mao, Yuang Peng, and Xiangyu Zhang.
\newblock Exploring recurrent long-term temporal fusion for multi-view 3d
  perception.
\newblock {\em arXiv preprint arXiv:2303.05970}, 2023.

\bibitem{han2023videobev}
Chunrui Han, Jianjian Sun, Zheng Ge, Jinrong Yang, Runpei Dong, Hongyu Zhou,
  Weixin Mao, Yuang Peng, and Xiangyu Zhang.
\newblock Exploring recurrent long-term temporal fusion for multi-view 3d
  perception.
\newblock {\em arXiv preprint arXiv:2303.05970}, 2023.

\bibitem{he2016resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{hu2023planning}
Yihan Hu, Jiazhi Yang, Li~Chen, Keyu Li, Chonghao Sima, Xizhou Zhu, Siqi Chai,
  Senyao Du, Tianwei Lin, Wenhai Wang, et~al.
\newblock Planning-oriented autonomous driving.
\newblock In {\em CVPR}, 2023.

\bibitem{huang2022bevdet4d}
Junjie Huang and Guan Huang.
\newblock {BEVDet4D}: Exploit temporal cues in multi-camera 3d object
  detection.
\newblock {\em arXiv preprint arXiv:2203.17054}, 2022.

\bibitem{huang2021bevdet}
Junjie Huang, Guan Huang, Zheng Zhu, and Dalong Du.
\newblock {BEVDet}: High-performance multi-camera 3d object detection in
  bird-eye-view.
\newblock {\em arXiv preprint arXiv:2112.11790}, 2021.

\bibitem{huang2023geometricaware}
Linyan Huang, Huijie Wang, Jia Zeng, Shengchuan Zhang, Liujuan Cao, Rongrong
  Ji, Junchi Yan, and Hongyang Li.
\newblock Geometric-aware pretraining for vision-centric 3d object detection.
\newblock {\em arXiv preprint arXiv:2304.03105}, 2023.

\bibitem{huang2022tigbev}
Peixiang Huang, Li~Liu, Renrui Zhang, Song Zhang, Xinli Xu, Baichao Wang, and
  Guoyi Liu.
\newblock Tig-bev: Multi-view bev 3d object detection via target inner-geometry
  learning.
\newblock {\em arXiv preprint arXiv:2212.13979}, 2022.

\bibitem{jia2023driveadapter}
Xiaosong Jia, Yulu Gao, Li~Chen, Junchi Yan, Patrick~Langechuan Liu, and
  Hongyang Li.
\newblock Driveadapter: Breaking the coupling barrier of perception and
  planning in end-to-end autonomous driving.
\newblock In {\em ICCV}, 2023.

\bibitem{jia2023thinktwice}
Xiaosong Jia, Penghao Wu, Li~Chen, Jiangwei Xie, Conghui He, Junchi Yan, and
  Hongyang Li.
\newblock Think twice before driving: Towards scalable decoders for end-to-end
  autonomous driving.
\newblock In {\em CVPR}, 2023.

\bibitem{jiang2022polarformer}
Yanqin Jiang, Li~Zhang, Zhenwei Miao, Xiatian Zhu, Jin Gao, Weiming Hu, and
  Yu-Gang Jiang.
\newblock {Polarforme}r: Multi-camera 3d object detection with polar
  transformers.
\newblock {\em arXiv preprint arXiv:2206.15398}, 2022.

\bibitem{klingner2023X3KD}
Marvin Klingner, Shubhankar Borse, Varun~Ravi Kumar, Behnaz Rezaei, Venkatraman
  Narayanan, Senthil Yogamani, and Fatih Porikli.
\newblock X$^3$kd: Knowledge distillation across modalities, tasks and stages
  for multi-camera 3d object detection.
\newblock {\em arXiv preprint arXiv:2303.02203}, 2023.

\bibitem{lang2019pointpillar}
Alex~H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar
  Beijbom.
\newblock {PointPillars}: Fast encoders for object detection from point clouds.
\newblock In {\em CVPR}, 2019.

\bibitem{li2022delving}
Hongyang Li, Chonghao Sima, Jifeng Dai, Wenhai Wang, Lewei Lu, Huijie Wang,
  Enze Xie, Zhiqi Li, Hanming Deng, Hao Tian, et~al.
\newblock Delving into the devils of bird's-eye-view perception: A review,
  evaluation and recipe.
\newblock {\em arXiv preprint arXiv:2209.05324}, 2022.

\bibitem{li2022bevlgkd}
Jianing Li, Ming Lu, Jiaming Liu, Yandong Guo, Li~Du, and Shanghang Zhang.
\newblock Bev-lgkd: A unified lidar-guided knowledge distillation framework for
  bev 3d object detection.
\newblock {\em arXiv preprint arXiv:2212.00623}, 2022.

\bibitem{li2022uvtr}
Yanwei Li, Yilun Chen, Xiaojuan Qi, Zeming Li, Jian Sun, and Jiaya Jia.
\newblock Unifying voxel-based representation with transformer for 3d object
  detection.
\newblock {\em arXiv preprint arXiv:2206.00630}, 2022.

\bibitem{li2022bevstereo}
Yinhao Li, Han Bao, Zheng Ge, Jinrong Yang, Jianjian Sun, and Zeming Li.
\newblock Bevstereo: Enhancing depth estimation in multi-view 3d object
  detection with dynamic temporal stereo.
\newblock {\em arXiv preprint arXiv:2209.10248}, 2022.

\bibitem{li2022bevdepth}
Yinhao Li, Zheng Ge, Guanyi Yu, Jinrong Yang, Zengran Wang, Yukang Shi,
  Jianjian Sun, and Zeming Li.
\newblock {BEVDepth}: Acquisition of reliable depth for multi-view 3d object
  detection.
\newblock {\em arXiv preprint arXiv:2206.10092}, 2022.

\bibitem{li2022bevformer}
Zhiqi Li, Wenhai Wang, Hongyang Li, Enze Xie, Chonghao Sima, Tong Lu, Qiao Yu,
  and Jifeng Dai.
\newblock {BEVFormer}: Learning bird's-eye-view representation from
  multi-camera images via spatiotemporal transformers.
\newblock {\em arXiv preprint arXiv:2203.17270}, 2022.

\bibitem{li2023voxelformer}
Zhuoling Li, Chuanrui Zhang, Wei-Chiu Ma, Yipin Zhou, Linyan Huang, Haoqian
  Wang, SerNam Lim, and Hengshuang Zhao.
\newblock Voxelformer: Bird's-eye-view feature generation based on dual-view
  attention for multi-view 3d object detection.
\newblock {\em arXiv preprint arXiv:2304.01054}, 2023.

\bibitem{liang2022bevfusion}
Tingting Liang, Hongwei Xie, Kaicheng Yu, Zhongyu Xia, Zhiwei Lin, Yongtao
  Wang, Tao Tang, Bing Wang, and Zhi Tang.
\newblock {BEVFusion}: A simple and robust lidar-camera fusion framework.
\newblock {\em arXiv preprint arXiv:2205.13790}, 2022.

\bibitem{liu2022petr}
Yingfei Liu, Tiancai Wang, Xiangyu Zhang, and Jian Sun.
\newblock {PETR}: Position embedding transformation for multi-view 3d object
  detection.
\newblock {\em arXiv preprint arXiv:2203.05625}, 2022.

\bibitem{liu2022petrv2}
Yingfei Liu, Junjie Yan, Fan Jia, Shuailin Li, Qi~Gao, Tiancai Wang, Xiangyu
  Zhang, and Jian Sun.
\newblock {PETRv2}: A unified framework for 3d perception from multi-camera
  images.
\newblock {\em arXiv preprint arXiv:2206.01256}, 2022.

\bibitem{liu2021swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In {\em ICCV}, 2021.

\bibitem{liu2022convnet}
Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell,
  and Saining Xie.
\newblock A convnet for the 2020s.
\newblock In {\em CVPR}, 2022.

\bibitem{park2022solofusion}
Jinhyung Park, Chenfeng Xu, Shijia Yang, Kurt Keutzer, Kris Kitani, Masayoshi
  Tomizuka, and Wei Zhan.
\newblock Time will tell: New outlooks and a baseline for temporal multi-view
  3d object detection.
\newblock {\em arXiv preprint arXiv:2210.02443}, 2022.

\bibitem{romero2014fitnets}
Adriana Romero, Nicolas Ballas, Samira~Ebrahimi Kahou, Antoine Chassang, Carlo
  Gatta, and Yoshua Bengio.
\newblock Fitnets: Hints for thin deep nets.
\newblock {\em arXiv preprint arXiv:1412.6550}, 2014.

\bibitem{shi2021pvrcnn++}
Shaoshuai Shi, Li~Jiang, Jiajun Deng, Zhe Wang, Chaoxu Guo, Jianping Shi,
  Xiaogang Wang, and Hongsheng Li.
\newblock {PV-RCNN++}: Point-voxel feature set abstraction with local vector
  representation for 3d object detection.
\newblock {\em arXiv preprint arXiv:2102.00463}, 2021.

\bibitem{shu2021cwd}
Changyong Shu, Yifan Liu, Jianfei Gao, Zheng Yan, and Chunhua Shen.
\newblock Channel-wise knowledge distillation for dense prediction.
\newblock In {\em ICCV}, 2021.

\bibitem{Tong_2023_ICCV}
Wenwen Tong, Chonghao Sima, Tai Wang, Li~Chen, Silei Wu, Hanming Deng, Yi~Gu,
  Lewei Lu, Ping Luo, Dahua Lin, and Hongyang Li.
\newblock Scene as occupancy.
\newblock In {\em ICCV}, 2023.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em NeurIPS}, 2017.

\bibitem{vora2020pointpainting}
Sourabh Vora, Alex~H Lang, Bassam Helou, and Oscar Beijbom.
\newblock {PointPainting}: Sequential fusion for 3d object detection.
\newblock In {\em CVPR}, 2020.

\bibitem{wang2023openlanev2}
Huijie Wang, Tianyu Li, Yang Li, Li~Chen, Chonghao Sima, Zhenbo Liu, Yuting
  Wang, Shengyin Jiang, Peijin Jia, Bangjun Wang, Feng Wen, Hang Xu, Ping Luo,
  Junchi Yan, Wei Zhang, and Hongyang Li.
\newblock Openlane-v2: A topology reasoning benchmark for scene understanding
  in autonomous driving, 2023.

\bibitem{wang2023streampetr}
Shihao Wang, Yingfei Liu, Tiancai Wang, Ying Li, and Xiangyu Zhang.
\newblock Exploring object-centric temporal modeling for efficient multi-view
  3d object detection.
\newblock {\em arXiv preprint arXiv:2303.11926}, 2023.

\bibitem{wang2021fcos3d}
Tai Wang, Xinge Zhu, Jiangmiao Pang, and Dahua Lin.
\newblock {FCOS3D}: Fully convolutional one-stage monocular 3d object
  detection.
\newblock In {\em ICCV}, 2021.

\bibitem{wang2022detr3d}
Yue Wang, Vitor~Campagnolo Guizilini, Tianyuan Zhang, Yilun Wang, Hang Zhao,
  and Justin Solomon.
\newblock {DETR3D}: 3d object detection from multi-view images via 3d-to-2d
  queries.
\newblock In {\em CoRL}, 2022.

\bibitem{wang2022sts}
Zengran Wang, Chen Min, Zheng Ge, Yinhao Li, Zeming Li, Hongyu Yang, and
  Di~Huang.
\newblock {STS}: Surround-view temporal stereo for multi-view 3d detection.
\newblock {\em arXiv preprint arXiv:2208.10145}, 2022.

\bibitem{wu2022trajectoryguided}
Penghao Wu, Xiaosong Jia, Li~Chen, Junchi Yan, Hongyang Li, and Yu~Qiao.
\newblock Trajectory-guided control prediction for end-to-end autonomous
  driving: A simple yet strong baseline.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2022.

\bibitem{Xiong_2023_CVPR}
Kaixin Xiong, Shi Gong, Xiaoqing Ye, Xiao Tan, Ji~Wan, Errui Ding, Jingdong
  Wang, and Xiang Bai.
\newblock Cape: Camera view position embedding for multi-view 3d object
  detection.
\newblock In {\em CVPR}, pages 21570--21579, June 2023.

\bibitem{yan2023cmt}
Junjie Yan, Yingfei Liu, Jianjian Sun, Fan Jia, Shuailin Li, Tiancai Wang, and
  Xiangyu Zhang.
\newblock Cross modal transformer via coordinates encoding for 3d object
  dectection.
\newblock {\em arXiv preprint arXiv:2301.01283}, 2023.

\bibitem{yang2022bevformer}
Chenyu Yang, Yuntao Chen, Hao Tian, Chenxin Tao, Xizhou Zhu, Zhaoxiang Zhang,
  Gao Huang, Hongyang Li, Yu~Qiao, Lewei Lu, et~al.
\newblock Bevformer v2: Adapting modern image backbones to bird's-eye-view
  recognition via perspective supervision.
\newblock {\em arXiv preprint arXiv:2211.10439}, 2022.

\bibitem{yang2022deepinteraction}
Zeyu Yang, Jiaqi Chen, Zhenwei Miao, Wei Li, Xiatian Zhu, and Li~Zhang.
\newblock {DeepInteraction}: 3d object detection via modality interaction.
\newblock {\em arXiv preprint arXiv:2208.11112}, 2022.

\bibitem{yin2021centerpoint}
Tianwei Yin, Xingyi Zhou, and Philipp Krahenbuhl.
\newblock Center-based 3d object detection and tracking.
\newblock In {\em CVPR}, 2021.

\bibitem{Zeng_2023_CVPR}
Jia Zeng, Li~Chen, Hanming Deng, Lewei Lu, Junchi Yan, Yu~Qiao, and Hongyang
  Li.
\newblock Distilling focal knowledge from imperfect expert for 3d object
  detection.
\newblock In {\em CVPR}, 2023.

\bibitem{zhao2023bevsimdet}
Haimei Zhao, Qiming Zhang, Shanshan Zhao, Jing Zhang, and Dacheng Tao.
\newblock Bevsimdet: Simulated multi-modal distillation in bird's-eye view for
  multi-view 3d object detection.
\newblock {\em arXiv preprint arXiv:2303.16818}, 2023.

\bibitem{zhou2019center}
Xingyi Zhou, Dequan Wang, and Philipp Kr{\"a}henb{\"u}hl.
\newblock Objects as points.
\newblock {\em arXiv preprint arXiv:1904.07850}, 2019.

\bibitem{zhou2021monocular}
Yunsong Zhou, Yuan He, Hongzi Zhu, Cheng Wang, Hongyang Li, and Qinhong Jiang.
\newblock Monocular 3d object detection: An extrinsic parameter free approach.
\newblock In {\em CVPR}, 2021.

\bibitem{Zhou2022monocular}
Yunsong Zhou, Yuan He, Hongzi Zhu, Cheng Wang, Hongyang Li, and Qinhong Jiang.
\newblock Monoef: Extrinsic parameter free monocular 3d object detection.
\newblock {\em IEEE TPAMI}, 2022.

\end{thebibliography}
