\begin{thebibliography}{45}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anderson et~al.(1987)Anderson, Veith, and
  Weininger]{anderson1987smiles}
Eric Anderson, Gilman~D Veith, and David Weininger.
\newblock \emph{{SMILES}, a line notation and computerized interpreter for
  chemical structures}.
\newblock {US} Environmental Protection Agency, Environmental Research
  Laboratory, 1987.

\bibitem[Arora et~al.(2019)Arora, Du, Hu, Li, Salakhutdinov, and
  Wang]{arora2019exact}
Sanjeev Arora, Simon~S Du, Wei Hu, Zhiyuan Li, Russ~R Salakhutdinov, and
  Ruosong Wang.
\newblock On exact computation with an infinitely wide neural net.
\newblock \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Auer et~al.(2002)Auer, Cesa-Bianchi, and Fischer]{auer2002finite}
Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock \emph{Machine learning}, 2002.

\bibitem[Auer et~al.(2008)Auer, Jaksch, and Ortner]{auer2008near}
Peter Auer, Thomas Jaksch, and Ronald Ortner.
\newblock Near-optimal regret bounds for reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 2008.

\bibitem[Bietti and Bach(2021)]{bietti2020deep}
Alberto Bietti and Francis Bach.
\newblock {Deep equals shallow for {R}e{LU} networks in kernel regimes}.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Bietti et~al.(2021)Bietti, Venturi, and Bruna]{bietti2021sample}
Alberto Bietti, Luca Venturi, and Joan Bruna.
\newblock On the sample complexity of learning under geometric stability.
\newblock \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Bogunovic and Krause(2021)]{bogunovic2021misspecified}
Ilija Bogunovic and Andreas Krause.
\newblock Misspecified {G}aussian process bandit optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Bogunovic et~al.(2016)Bogunovic, Scarlett, Krause, and
  Cevher]{bogunovic2016truncated}
Ilija Bogunovic, Jonathan Scarlett, Andreas Krause, and Volkan Cevher.
\newblock Truncated variance reduction: A unified approach to {B}ayesian
  optimization and level-set estimation.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Bogunovic et~al.(2022)Bogunovic, Li, Krause, and
  Scarlett]{bogunovic2022robust}
Ilija Bogunovic, Zihan Li, Andreas Krause, and Jonathan Scarlett.
\newblock A robust phased elimination algorithm for corruption-tolerant
  {G}aussian process bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Cao and Gu(2019)]{cao2019generalization}
Yuan Cao and Quanquan Gu.
\newblock Generalization bounds of stochastic gradient descent for wide and
  deep neural networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Chizat et~al.(2019)Chizat, Oyallon, and Bach]{chizat2019lazy}
Lenaic Chizat, Edouard Oyallon, and Francis Bach.
\newblock On lazy training in differentiable programming.
\newblock \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Chowdhury and Gopalan(2017)]{chowdhury2017kernelized}
Sayak~Ray Chowdhury and Aditya Gopalan.
\newblock On kernelized multi-armed bandits.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Contal et~al.(2013)Contal, Buffoni, Robicquet, and
  Vayatis]{contal2013parallel}
Emile Contal, David Buffoni, Alexandre Robicquet, and Nicolas Vayatis.
\newblock Parallel gaussian process optimization with upper confidence bound
  and pure exploration.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}. Springer, 2013.

\bibitem[De et~al.(2012)De, Smola, and Zoghi]{de2012exponential}
Nando De, Alex Smola, and Masrour Zoghi.
\newblock Exponential regret bounds for {G}aussian process bandits with
  deterministic observations.
\newblock In \emph{International Conference on Machine Learning}, 2012.

\bibitem[Du et~al.(2019)Du, Hou, Salakhutdinov, Poczos, Wang, and
  Xu]{du2019graph}
Simon~S Du, Kangcheng Hou, Russ~R Salakhutdinov, Barnabas Poczos, Ruosong Wang,
  and Keyulu Xu.
\newblock Graph neural tangent kernel: Fusing graph neural networks with graph
  kernels.
\newblock \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Gligorijevi{\'c} et~al.(2021)Gligorijevi{\'c}, Renfrew, Kosciolek,
  Leman, Berenberg, Vatanen, Chandler, Taylor, Fisk, Vlamakis,
  et~al.]{gligorijevic2021structure}
Vladimir Gligorijevi{\'c}, P~Douglas Renfrew, Tomasz Kosciolek, Julia~Koehler
  Leman, Daniel Berenberg, Tommi Vatanen, Chris Chandler, Bryn~C Taylor, Ian~M
  Fisk, Hera Vlamakis, et~al.
\newblock Structure-based protein function prediction using graph convolutional
  networks.
\newblock \emph{Nature communications}, 2021.

\bibitem[G{\'o}mez-Bombarelli et~al.(2018)G{\'o}mez-Bombarelli, Wei, Duvenaud,
  Hern{\'a}ndez-Lobato, S{\'a}nchez-Lengeling, Sheberla, Aguilera-Iparraguirre,
  Hirzel, Adams, and Aspuru-Guzik]{gomez2018automatic}
Rafael G{\'o}mez-Bombarelli, Jennifer~N Wei, David Duvenaud, Jos{\'e}~Miguel
  Hern{\'a}ndez-Lobato, Benjam{\'\i}n S{\'a}nchez-Lengeling, Dennis Sheberla,
  Jorge Aguilera-Iparraguirre, Timothy~D Hirzel, Ryan~P Adams, and Al{\'a}n
  Aspuru-Guzik.
\newblock Automatic chemical design using a data-driven continuous
  representation of molecules.
\newblock \emph{ACS central science}, 2018.

\bibitem[Griffiths and Hern{\'a}ndez-Lobato(2020)]{griffiths2020constrained}
Ryan-Rhys Griffiths and Jos{\'e}~Miguel Hern{\'a}ndez-Lobato.
\newblock Constrained {B}ayesian optimization for automatic chemical design
  using variational autoencoders.
\newblock \emph{Chemical science}, 2020.

\bibitem[Gu et~al.(2021)Gu, Karbasi, Khosravi, Mirrokni, and
  Zhou]{gu2021batched}
Quanquan Gu, Amin Karbasi, Khashayar Khosravi, Vahab Mirrokni, and Dongruo
  Zhou.
\newblock Batched neural bandits.
\newblock \emph{arXiv preprint arXiv:2102.13028}, 2021.

\bibitem[Guo and Buehler(2020)]{guo2020semi}
Kai Guo and Markus~J Buehler.
\newblock A semi-supervised approach to architected materials design using
  graph neural networks.
\newblock \emph{Extreme Mechanics Letters}, 2020.

\bibitem[Jacot et~al.(2018)Jacot, Gabriel, and Hongler]{jacot2018neural}
Arthur Jacot, Franck Gabriel, and Cl{\'e}ment Hongler.
\newblock Neural tangent kernel: {C}onvergence and generalization in neural
  networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Jiang et~al.(2021)Jiang, Wu, Hsieh, Chen, Liao, Wang, Shen, Cao, Wu,
  and Hou]{jiang2021could}
Dejun Jiang, Zhenxing Wu, Chang-Yu Hsieh, Guangyong Chen, Ben Liao, Zhe Wang,
  Chao Shen, Dongsheng Cao, Jian Wu, and Tingjun Hou.
\newblock Could graph neural networks learn better molecular representation for
  drug discovery? a comparison study of descriptor-based and graph-based
  models.
\newblock \emph{Journal of cheminformatics}, 2021.

\bibitem[Jin et~al.(2018)Jin, Barzilay, and Jaakkola]{jin2018junction}
Wengong Jin, Regina Barzilay, and Tommi Jaakkola.
\newblock Junction tree variational autoencoder for molecular graph generation.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Kandasamy et~al.(2015)Kandasamy, Schneider, and
  P{\'o}czos]{kandasamy2015high}
Kirthevasan Kandasamy, Jeff Schneider, and Barnab{\'a}s P{\'o}czos.
\newblock High dimensional {B}ayesian optimisation and bandits via additive
  models.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2015.

\bibitem[Kassraie and Krause(2022)]{kassraie2021neural}
Parnian Kassraie and Andreas Krause.
\newblock Neural contextual bandits without regret.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2022.

\bibitem[Kingma and Ba(2015)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Kipf and Welling(2017)]{kipf2016semi}
Thomas~N Kipf and Max Welling.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Korovina et~al.(2020)Korovina, Xu, Kandasamy, Neiswanger, Poczos,
  Schneider, and Xing]{korovina2020chembo}
Ksenia Korovina, Sailun Xu, Kirthevasan Kandasamy, Willie Neiswanger, Barnabas
  Poczos, Jeff Schneider, and Eric Xing.
\newblock Chembo: {B}ayesian optimization of small organic molecules with
  synthesizable recommendations.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2020.

\bibitem[Krause and Ong(2011)]{krause2011contextual}
Andreas Krause and Cheng Ong.
\newblock Contextual {G}aussian process bandit optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2011.

\bibitem[Li and Scarlett(2022)]{li2022gaussian}
Zihan Li and Jonathan Scarlett.
\newblock Gaussian process bandit optimization with few batches.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}. PMLR, 2022.

\bibitem[Lu and Van~Roy(2019)]{lu2019information}
Xiuyuan Lu and Benjamin Van~Roy.
\newblock Information-theoretic confidence bounds for reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Mei et~al.(2021)Mei, Misiakiewicz, and Montanari]{mei2021learning}
Song Mei, Theodor Misiakiewicz, and Andrea Montanari.
\newblock Learning with invariances in random features and kernel models.
\newblock \emph{CoRR}, 2021.

\bibitem[Novak et~al.(2020)Novak, Xiao, Hron, Lee, Alemi, Sohl-Dickstein, and
  Schoenholz]{neuraltangents2020}
Roman Novak, Lechao Xiao, Jiri Hron, Jaehoon Lee, Alexander~A. Alemi, Jascha
  Sohl-Dickstein, and Samuel~S. Schoenholz.
\newblock Neural tangents: Fast and easy infinite neural networks in {P}ython.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in {P}y{T}orch, 2017.

\bibitem[Rolland et~al.(2018)Rolland, Scarlett, Bogunovic, and
  Cevher]{rolland2018high}
Paul Rolland, Jonathan Scarlett, Ilija Bogunovic, and Volkan Cevher.
\newblock High-dimensional {B}ayesian optimization via additive models with
  overlapping groups.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2018.

\bibitem[Russo and Van~Roy(2014)]{russo2014learning}
Daniel Russo and Benjamin Van~Roy.
\newblock Learning to optimize via posterior sampling.
\newblock \emph{Mathematics of Operations Research}, 2014.

\bibitem[Srinivas et~al.(2010)Srinivas, Krause, Kakade, and
  Seeger]{srinivas2009gaussian}
Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger.
\newblock Gaussian process optimization in the bandit setting: No regret and
  experimental design.
\newblock In \emph{International Conference on Machine Learning}, 2010.

\bibitem[Stanton et~al.(2022)Stanton, Maddox, Gruver, Maffettone, Delaney,
  Greenside, and Wilson]{stanton2022accelerating}
Samuel Stanton, Wesley Maddox, Nate Gruver, Phillip Maffettone, Emily Delaney,
  Peyton Greenside, and Andrew~Gordon Wilson.
\newblock Accelerating {B}ayesian optimization for biological sequence design
  with denoising autoencoders.
\newblock In \emph{International Conference on Machine Learning}, 2022.

\bibitem[Thompson(1933)]{thompson1933likelihood}
William~R Thompson.
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock \emph{Biometrika}, 1933.

\bibitem[Vakili et~al.(2021{\natexlab{a}})Vakili, Bouziani, Jalali, Bernacchia,
  and shan Shiu]{vakili2021optimal}
Sattar Vakili, Nacime Bouziani, Sepehr Jalali, Alberto Bernacchia, and Da~shan
  Shiu.
\newblock Optimal order simple regret for gaussian process bandits.
\newblock In \emph{Advances in Neural Information Processing Systems},
  2021{\natexlab{a}}.

\bibitem[Vakili et~al.(2021{\natexlab{b}})Vakili, Khezeli, and
  Picheny]{vakili2020information}
Sattar Vakili, Kia Khezeli, and Victor Picheny.
\newblock On information gain and regret bounds in {G}aussian process bandits.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2021{\natexlab{b}}.

\bibitem[Valko et~al.(2013)Valko, Korda, Munos, Flaounas, and
  Cristianini]{valko2013finite}
Michal Valko, Nathan Korda, R\'{e}mi Munos, Ilias Flaounas, and Nello
  Cristianini.
\newblock Finite-time analysis of kernelised contextual bandits.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, 2013.

\bibitem[Valko et~al.(2014)Valko, Munos, Kveton, and
  Koc{\'a}k]{valko2014spectral}
Michal Valko, R{\'e}mi Munos, Branislav Kveton, and Tom{\'a}{\v{s}} Koc{\'a}k.
\newblock Spectral bandits for smooth graph functions.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[ZHANG et~al.(2021)ZHANG, Zhou, Li, and Gu]{zhang2020neural}
Weitong ZHANG, Dongruo Zhou, Lihong Li, and Quanquan Gu.
\newblock Neural {T}hompson {S}ampling.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Zhou et~al.(2020)Zhou, Li, and Gu]{zhou2020neural}
Dongruo Zhou, Lihong Li, and Quanquan Gu.
\newblock Neural contextual bandits with {UCB}-based exploration.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\end{thebibliography}
