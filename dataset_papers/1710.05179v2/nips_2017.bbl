\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{andreas2016neural}
J.~Andreas, M.~Rohrbach, T.~Darrell, and D.~Klein.
\newblock Neural module networks.
\newblock In {\em CVPR}, 2016.

\bibitem{antol2015vqa}
S.~Antol, A.~Agrawal, J.~Lu, M.~Mitchell, D.~Batra, C.~Lawrence~Zitnick, and
  D.~Parikh.
\newblock {VQA:} visual question answering.
\newblock In {\em ICCV}, 2015.

\bibitem{ba2013adaptive}
J.~Ba and B.~Frey.
\newblock Adaptive dropout for training deep neural networks.
\newblock In {\em NIPS}, 2013.

\bibitem{ba2015learning}
J.~Ba, R.~R. Salakhutdinov, R.~B. Grosse, and B.~J. Frey.
\newblock Learning wake-sleep recurrent attention models.
\newblock In {\em NIPS}, 2015.

\bibitem{bornschein2015reweighted}
J.~Bornschein and Y.~Bengio.
\newblock Reweighted wake-sleep.
\newblock In {\em ICLR}, 2015.

\bibitem{bulo2016dropout}
S.~R. Bulo, L.~Porzi, and P.~Kontschieder.
\newblock Dropout distillation.
\newblock In {\em ICML}, 2016.

\bibitem{burda2016importance}
Y.~Burda, R.~Grosse, and R.~Salakhutdinov.
\newblock Importance weighted autoencoders.
\newblock In {\em ICLR}, 2016.

\bibitem{feichtenhofer2016convolutional}
C.~Feichtenhofer, A.~Pinz, and A.~Zisserman.
\newblock Convolutional two-stream network fusion for video action recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{gal2016dropout}
Y.~Gal and Z.~Ghahramani.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In {\em ICML}, 2016.

\bibitem{han2017branchout}
B.~Han, J.~Sim, and H.~Adam.
\newblock Branchout: Regularization for online ensemble tracking with
  convolutional neural networks.
\newblock In {\em CVPR}, 2017.

\bibitem{han2017deep}
D.~Han, J.~Kim, and J.~Kim.
\newblock Deep pyramidal residual networks.
\newblock {\em CVPR}, 2017.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{he2016identity}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Identity mappings in deep residual networks.
\newblock In {\em ECCV}, 2016.

\bibitem{huang2017densely}
G.~Huang, Z.~Liu, K.~Q. Weinberger, and L.~van~der Maaten.
\newblock Densely connected convolutional networks.
\newblock {\em CVPR}, 2017.

\bibitem{huang2016deep}
G.~Huang, Y.~Sun, Z.~Liu, D.~Sedra, and K.~Q. Weinberger.
\newblock Deep networks with stochastic depth.
\newblock In {\em ECCV}, 2016.

\bibitem{jain2015drop}
P.~Jain, V.~Kulkarni, A.~Thakurta, and O.~Williams.
\newblock To drop or not to drop: Robustness, consistency and differential
  privacy properties of dropout.
\newblock {\em arXiv preprint arXiv:1503.02031}, 2015.

\bibitem{kingma2015variational}
D.~P. Kingma, T.~Salimans, and M.~Welling.
\newblock Variational dropout and the local reparameterization trick.
\newblock In {\em NIPS}, 2015.

\bibitem{kingma2014auto}
D.~P. Kingma and M.~Welling.
\newblock Auto-encoding variational bayes.
\newblock In {\em ICLR}, 2014.

\bibitem{krizhevsky2009learning}
A.~Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, University of Toronto, 2009.

\bibitem{krizhevsky2012imagenet}
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em NIPS}, 2012.

\bibitem{larsson2017fractalnet}
G.~Larsson, M.~Maire, and G.~Shakhnarovich.
\newblock Fractalnet: Ultra-deep neural networks without residuals.
\newblock {\em ICLR}, 2017.

\bibitem{li2016improved}
Z.~Li, B.~Gong, and T.~Yang.
\newblock Improved dropout for shallow and deep learning.
\newblock In {\em NIPS}, 2016.

\bibitem{long2015fully}
J.~Long, E.~Shelhamer, and T.~Darrell.
\newblock Fully convolutional networks for semantic segmentation.
\newblock In {\em CVPR}, 2015.

\bibitem{ma2016dropout}
X.~Ma, Y.~Gao, Z.~Hu, Y.~Yu, Y.~Deng, and E.~Hovy.
\newblock Dropout with expectation-linear regularization.
\newblock In {\em ICLR}, 2016.

\bibitem{mnih2016variational}
A.~Mnih and D.~Rezende.
\newblock Variational inference for monte carlo objectives.
\newblock In {\em ICML}, 2016.

\bibitem{mnih2015human}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~A. Rusu, J.~Veness, M.~G. Bellemare,
  A.~Graves, M.~Riedmiller, A.~K. Fidjeland, G.~Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 518(7540):529--533, 2015.

\bibitem{nam2016learning}
H.~Nam and B.~Han.
\newblock Learning multi-domain convolutional neural networks for visual
  tracking.
\newblock In {\em CVPR}, 2016.

\bibitem{noh2015learning}
H.~Noh, S.~Hong, and B.~Han.
\newblock Learning deconvolution network for semantic segmentation.
\newblock In {\em ICCV}, 2015.

\bibitem{noh2016image}
H.~Noh, S.~Hong, and B.~Han.
\newblock Image question answering using convolutional neural network with
  dynamic parameter prediction.
\newblock In {\em CVPR}, 2016.

\bibitem{raiko2015techniques}
T.~Raiko, M.~Berglund, G.~Alain, and L.~Dinh.
\newblock Techniques for learning binary stochastic feedforward neural
  networks.
\newblock In {\em ICLR}, 2015.

\bibitem{ren2015faster}
S.~Ren, K.~He, R.~Girshick, and J.~Sun.
\newblock Faster {R-CNN}: Towards real-time object detection with region
  proposal networks.
\newblock In {\em NIPS}, 2015.

\bibitem{simonyan2014very}
K.~Simonyan and A.~Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In {\em ICLR}, 2015.

\bibitem{soomro2012ucf101}
K.~Soomro, A.~R. Zamir, and M.~Shah.
\newblock {UCF101:} a dataset of 101 human actions classes from videos in the
  wild.
\newblock {\em arXiv preprint arXiv:1212.0402}, 2012.

\bibitem{srivastava2014dropout}
N.~Srivastava, G.~E. Hinton, A.~Krizhevsky, I.~Sutskever, and R.~Salakhutdinov.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock {\em JMLR}, 15(1):1929--1958, 2014.

\bibitem{vinyals2015show}
O.~Vinyals, A.~Toshev, S.~Bengio, and D.~Erhan.
\newblock Show and tell: A neural image caption generator.
\newblock In {\em CVPR}, 2015.

\bibitem{wager2013dropout}
S.~Wager, S.~Wang, and P.~S. Liang.
\newblock Dropout training as adaptive regularization.
\newblock In {\em NIPS}, 2013.

\bibitem{wan2013regularization}
L.~Wan, M.~Zeiler, S.~Zhang, Y.~LeCun, and R.~Fergus.
\newblock Regularization of neural networks using dropconnect.
\newblock In {\em ICML}, 2013.

\bibitem{wu2016google}
Y.~Wu, M.~Schuster, Z.~Chen, Q.~V. Le, M.~Norouzi, W.~Macherey, M.~Krikun,
  Y.~Cao, Q.~Gao, K.~Macherey, et~al.
\newblock Google's neural machine translation system: Bridging the gap between
  human and machine translation.
\newblock {\em arXiv preprint arXiv:1609.08144}, 2016.

\bibitem{yang2016stacked}
Z.~Yang, X.~He, J.~Gao, L.~Deng, and A.~Smola.
\newblock Stacked attention networks for image question answering.
\newblock In {\em CVPR}, 2016.

\bibitem{zagoruyko2016wide}
S.~Zagoruyko and N.~Komodakis.
\newblock Wide residual networks.
\newblock In {\em BMVC}, 2016.

\end{thebibliography}
