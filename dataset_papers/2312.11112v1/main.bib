@inproceedings{stratified,
  title={Stratified Transformer for 3D Point Cloud Segmentation},
  author={Lai, Xin and Liu, Jianhui and Jiang, Li and Wang, Liwei and Zhao, Hengshuang and Liu, Shu and Qi, Xiaojuan and Jia, Jiaya},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={8500--8509},
  year={2022}
}

@inproceedings{ptv2,
  title     = {Point transformer V2: Grouped Vector Attention and Partition-based Pooling},
  author    = {Wu, Xiaoyang and Lao, Yixing and Jiang, Li and Liu, Xihui and Zhao, Hengshuang},
  booktitle = {Adv. Neural Inform. Process. Syst.},
  year      = {2022}
}

@inproceedings{ptv1,
  title={Point transformer},
  author={Zhao, Hengshuang and Jiang, Li and Jia, Jiaya and Torr, Philip HS and Koltun, Vladlen},
  booktitle={Int. Conf. Comput. Vis.},
  pages={16259--16268},
  year={2021}
}

@inproceedings{fpt,
 title={Fast Point Transformer},
 author={Park, Chunghyun and Jeong, Yoonwoo and Cho, Minsu and Park, Jaesik},
 booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
 year={2022},
 pages={16949--16958}
}

@article{octformer,  
 title={OctFormer: Octree-based Transformers for 3D Point Clouds}, 
 author={Wang, Peng-Shuai}, 
 year={2023}, 
 journal={arXiv preprint arXiv:2305.03045} 
}

@InProceedings{cswin,
    author    = {Dong, Xiaoyi and Bao, Jianmin and Chen, Dongdong and Zhang, Weiming and Yu, Nenghai and Yuan, Lu and Chen, Dong and Guo, Baining},
    title     = {CSWin Transformer: A General Vision Transformer Backbone With Cross-Shaped Windows},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog.},
    year      = {2022},
    pages     = {12124--12134}
}

@inproceedings{qi2017pointnet,
  title={Pointnet: Deep learning on point sets for 3d classification and segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={652--660},
  year={2017}
}

@article{qi2017pointnet++,
  title={Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
  author={Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
  journal={Adv. Neural Inform. Process. Syst.},
  volume={30},
  year={2017}
}

@inproceedings{minkowski,
  title={4d spatio-temporal convnets: Minkowski convolutional neural networks},
  author={Choy, Christopher and Gwak, JunYoung and Savarese, Silvio},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={3075--3084},
  year={2019}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Adv. Neural Inform. Process. Syst.},
  volume={30},
  year={2017}
}

@inproceedings{liu2021Swin,
  title={Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Int. Conf. Comput. Vis.},
  year={2021}
}

@inproceedings{dai2017scannet,
    title={ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes},
    author={Dai, Angela and Chang, Angel X. and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
    booktitle = {IEEE Conf. Comput. Vis. Pattern Recog.},
    year = {2017}
}


@article{xu2021vitae,
  title={Vitae: Vision transformer advanced by exploring intrinsic inductive bias},
  author={Xu, Yufei and Zhang, Qiming and Zhang, Jing and Tao, Dacheng},
  journal={Adv. Neural Inform. Process. Syst.},
  volume={34},
  year={2021}
}

@article{vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{wu2021rethinking,
  title={Rethinking and improving relative position encoding for vision transformer},
  author={Wu, Kan and Peng, Houwen and Chen, Minghao and Fu, Jianlong and Chao, Hongyang},
  booktitle={Int. Conf. Comput. Vis.},
  pages={10033--10041},
  year={2021}
}

@inproceedings{qi2016volumetric,
  title={Volumetric and multi-view cnns for object classification on 3d data},
  author={Qi, Charles R and Su, Hao and Nie{\ss}ner, Matthias and Dai, Angela and Yan, Mengyuan and Guibas, Leonidas J},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={5648--5656},
  year={2016}
}

@inproceedings{wu20153d,
  title={3d shapenets: A deep representation for volumetric shapes},
  author={Wu, Zhirong and Song, Shuran and Khosla, Aditya and Yu, Fisher and Zhang, Linguang and Tang, Xiaoou and Xiao, Jianxiong},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={1912--1920},
  year={2015}
}

@inproceedings{graham20183d,
  title={3d semantic segmentation with submanifold sparse convolutional networks},
  author={Graham, Benjamin and Engelcke, Martin and Van Der Maaten, Laurens},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={9224--9232},
  year={2018}
}

@inproceedings{Riegler2017OctNet,
  title={OctNet: Learning Deep 3D Representations at High Resolutions},
  author={Riegler, Gernot and Ulusoy, Ali Osman and Geiger, Andreas},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  year={2017}
}

@inproceedings{lei2019octree,
  title={Octree guided cnn with spherical kernels for 3d point clouds},
  author={Lei, Huan and Akhtar, Naveed and Mian, Ajmal},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={9631--9640},
  year={2019}
}

@inproceedings{chen2017multi,
  title={Multi-view 3d object detection network for autonomous driving},
  author={Chen, Xiaozhi and Ma, Huimin and Wan, Ji and Li, Bo and Xia, Tian},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={1907--1915},
  year={2017}
}

@inproceedings{su2015multi,
  title={Multi-view convolutional neural networks for 3d shape recognition},
  author={Su, Hang and Maji, Subhransu and Kalogerakis, Evangelos and Learned-Miller, Erik},
  booktitle={Int. Conf. Comput. Vis.},
  pages={945--953},
  year={2015}
}

@inproceedings{thomas2019kpconv,
  title={Kpconv: Flexible and deformable convolution for point clouds},
  author={Thomas, Hugues and Qi, Charles R and Deschaud, Jean-Emmanuel and Marcotegui, Beatriz and Goulette, Fran{\c{c}}ois and Guibas, Leonidas J},
  booktitle={Int. Conf. Comput. Vis.},
  pages={6411--6420},
  year={2019}
}

@inproceedings{wu2019pointconv,
  title={Pointconv: Deep convolutional networks on 3d point clouds},
  author={Wu, Wenxuan and Qi, Zhongang and Fuxin, Li},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={9621--9630},
  year={2019}
}

@article{dgcnn,
  title={Dynamic Graph CNN for Learning on Point Clouds},
  author={Wang, Yue and Sun, Yongbin and Liu, Ziwei and Sarma, Sanjay E. and Bronstein, Michael M. and Solomon, Justin M.},
  journal={ACM Trans. Graph.},
  year={2019}
}

@inproceedings{zhao2019pointweb,
  title={Pointweb: Enhancing local neighborhood features for point cloud processing},
  author={Zhao, Hengshuang and Jiang, Li and Fu, Chi-Wing and Jia, Jiaya},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={5565--5573},
  year={2019}
}

@inproceedings{hu2020randla,
  title={Randla-net: Efficient semantic segmentation of large-scale point clouds},
  author={Hu, Qingyong and Yang, Bo and Xie, Linhai and Rosa, Stefano and Guo, Yulan and Wang, Zhihua and Trigoni, Niki and Markham, Andrew},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={11108--11117},
  year={2020}
}

@article{li2018pointcnn,
  title={Pointcnn: Convolution on x-transformed points},
  author={Li, Yangyan and Bu, Rui and Sun, Mingchao and Wu, Wei and Di, Xinhan and Chen, Baoquan},
  journal={Adv. Neural Inform. Process. Syst.},
  volume={31},
  year={2018}
}

@inproceedings{xu2021paconv,
  title={Paconv: Position adaptive convolution with dynamic kernel assembling on point clouds},
  author={Xu, Mutian and Ding, Runyu and Zhao, Hengshuang and Qi, Xiaojuan},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={3173--3182},
  year={2021}
}

@article{guo2021pct,
  title={Pct: Point cloud transformer},
  author={Guo, Meng-Hao and Cai, Jun-Xiong and Liu, Zheng-Ning and Mu, Tai-Jiang and Martin, Ralph R and Hu, Shi-Min},
  journal={Comput. Vis. Media},
  volume={7},
  pages={187--199}
}

@inproceedings{huang2019ccnet,
  title={Ccnet: Criss-cross attention for semantic segmentation},
  author={Huang, Zilong and Wang, Xinggang and Huang, Lichao and Huang, Chang and Wei, Yunchao and Liu, Wenyu},
  booktitle={Int. Conf. Comput. Vis.},
  pages={603--612},
  year={2019}
}

@inproceedings{wang2020axial,
  title={Axial-deeplab: Stand-alone axial-attention for panoptic segmentation},
  author={Wang, Huiyu and Zhu, Yukun and Green, Bradley and Adam, Hartwig and Yuille, Alan and Chen, Liang-Chieh},
  booktitle={Eur. Conf. Comput. Vis.},
  pages={108--126},
  year={2020}
}

@inproceedings{guo2022cmt,
  title={Cmt: Convolutional neural networks meet vision transformers},
  author={Guo, Jianyuan and Han, Kai and Wu, Han and Tang, Yehui and Chen, Xinghao and Wang, Yunhe and Xu, Chang},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={12175--12185},
  year={2022}
}

@inproceedings{wu2021cvt,
  title={Cvt: Introducing convolutions to vision transformers},
  author={Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei},
  booktitle={Int. Conf. Comput. Vis.},
  pages={22--31},
  year={2021}
}

@inproceedings{sunrgbd,
  author={Song, Shuran and Lichtenberg, Samuel P. and Xiao, Jianxiong},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.}, 
  title={SUN RGB-D: A RGB-D scene understanding benchmark suite}, 
  year={2015},
  pages={567-576},
}

@inproceedings{dai20183dmv,
	title={3dmv: Joint 3d-multi-view prediction for 3d semantic scene segmentation},
	author={Dai, Angela and Nie{\ss}ner, Matthias},
	booktitle={Eur. Conf. Comput. Vis.},
	pages={452--468},
	year={2018}
}

@inproceedings{narita2019panopticfusion,
	title={Panopticfusion: Online volumetric semantic mapping at the level of stuff and things},
	author={Narita, Gaku and Seno, Takashi and Ishikawa, Tomoya and Kaji, Yohsuke},
	booktitle={IEEE Int. Conf. Intell. Rob. Syst.},
	pages={4205--4212},
	year={2019},
	organization={IEEE}
}

@inproceedings{chiang2019unified,
	title={A unified point-based framework for 3d segmentation},
	author={Chiang, Hung-Yueh and Lin, Yen-Liang and Liu, Yueh-Cheng and Hsu, Winston H},
	booktitle={Int. Conf. 3D Vis.},
	pages={155--163},
	year={2019},
	organization={IEEE}
}

@inproceedings{yan2020pointasnl,
	title={Pointasnl: Robust point clouds processing using nonlocal neural networks with adaptive sampling},
	author={Yan, Xu and Zheng, Chaoda and Li, Zhen and Wang, Sheng and Cui, Shuguang},
	booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
	pages={5589--5598},
	year={2020}
}

@inproceedings{lei2020seggcn,
	title={Seggcn: Efficient 3d point cloud segmentation with fuzzy spherical kernel},
	author={Lei, Huan and Akhtar, Naveed and Mian, Ajmal},
	booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
	pages={11611--11620},
	year={2020}
}

@inproceedings{hu2020jsenet,
	title={Jsenet: Joint semantic segmentation and edge detection network for 3d point clouds},
	author={Hu, Zeyu and Zhen, Mingmin and Bai, Xuyang and Fu, Hongbo and Tai, Chiew-lan},
	booktitle={Eur. Conf. Comput. Vis.},
	pages={222--239},
	year={2020}
}

@inproceedings{zhang2020deep,
	title={Deep fusionnet for point cloud semantic segmentation},
	author={Zhang, Feihu and Fang, Jin and Wah, Benjamin and Torr, Philip},
	booktitle={Eur. Conf. Comput. Vis.},
	pages={644--663},
	year={2020}
}

@inproceedings{choy20194d,
	title={4d spatio-temporal convnets: Minkowski convolutional neural networks},
	author={Choy, Christopher and Gwak, JunYoung and Savarese, Silvio},
	booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
	pages={3075--3084},
	year={2019}
}

@article{qian2022pointnext,
	title={Pointnext: Revisiting pointnet++ with improved training and scaling strategies},
	author={Qian, Guocheng and Li, Yuchen and Peng, Houwen and Mai, Jinjie and Hammoud, Hasan and Elhoseiny, Mohamed and Ghanem, Bernard},
	journal={Adv. Neural Inform. Process. Syst.},
	volume={35},
	pages={23192--23204},
	year={2022}
}

@article{swin3d,
	title={Swin3D: A Pretrained Transformer Backbone for 3D Indoor Scene Understanding},
	author={Yang, Yuqi and Guo, Yuxiao and Xiong, Jianyu and Liu, Yang and Pan, Hao and Wang, Pengshuai and Tong, Xin and Guo, Baining},
	journal={arXiv preprint arXiv:2304.06906},
	year={2023}
}

@article{chen2022scaling,
	title={Scaling up kernels in 3d cnns},
	author={Chen, Yukang and Liu, Jianhui and Qi, Xiaojuan and Zhang, Xiangyu and Sun, Jian and Jia, Jiaya},
	journal={Adv. Neural Inform. Process. Syst.},
	year={2022}
}

@inproceedings{nekrasov2021mix3d,
	title={Mix3d: Out-of-context data augmentation for 3d scenes},
	author={Nekrasov, Alexey and Schult, Jonas and Litany, Or and Leibe, Bastian and Engelmann, Francis},
	booktitle={Int. Conf. 3D Vis.},
	pages={116--125},
	year={2021}
}

@inproceedings{tchapmi2017segcloud,
	title     = {Segcloud: Semantic segmentation of 3d point clouds},
	author    = {Tchapmi, Lyne and Choy, Christopher and Armeni, Iro and Gwak, JunYoung and Savarese, Silvio},
	booktitle = {Int. Conf. 3D Vis.},
	year      = {2017}
}

@inproceedings{tatarchenko2018tangent,
	title     = {Tangent convolutions for dense prediction in 3d},
	author    = {Tatarchenko, Maxim and Park, Jaesik and Koltun, Vladlen and Zhou, Qian-Yi},
	booktitle = {IEEE Conf. Comput. Vis. Pattern Recog.},
	year      = {2018}
}

@inproceedings{jiang2019hierarchical,
	title     = {Hierarchical point-edge interaction network for point cloud semantic segmentation},
	author    = {Jiang, Li and Zhao, Hengshuang and Liu, Shu and Shen, Xiaoyong and Fu, Chi-Wing and Jia, Jiaya},
	booktitle = {Int. Conf. Comput. Vis.},
	year      = {2019}
}

@inproceedings{wang2019graph,
	title     = {Graph attention convolution for point cloud semantic segmentation},
	author    = {Wang, Lei and Huang, Yuchun and Hou, Yaolin and Zhang, Shenman and Shan, Jie},
	booktitle = {IEEE Conf. Comput. Vis. Pattern Recog.},
	year      = {2019}
}

@inproceedings{yang2019modeling,
	title     = {Modeling point clouds with self-attention and gumbel subset sampling},
	author    = {Yang, Jiancheng and Zhang, Qiang and Ni, Bingbing and Li, Linguo and Liu, Jinxian and Zhou, Mengdie and Tian, Qi},
	booktitle = {IEEE Conf. Comput. Vis. Pattern Recog.},
	year      = {2019}
}

@inproceedings{wang2018deep,
	title     = {Deep parametric continuous convolutional neural networks},
	author    = {Wang, Shenlong and Suo, Simon and Ma, Wei-Chiu and Pokrovsky, Andrei and Urtasun, Raquel},
	booktitle = {IEEE Conf. Comput. Vis. Pattern Recog.},
	year      = {2018}
}

@inproceedings{landrieu2018large,
	title     = {Large-scale point cloud semantic segmentation with superpoint graphs},
	author    = {Landrieu, Loic and Simonovsky, Martin},
	booktitle = {IEEE Conf. Comput. Vis. Pattern Recog.},
	year      = {2018}
}

@article{gpt,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{chu2021twins,
  title={Twins: Revisiting the design of spatial attention in vision transformers},
  author={Chu, Xiangxiang and Tian, Zhi and Wang, Yuqing and Zhang, Bo and Ren, Haibing and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
  journal={Adv. Neural Inform. Process. Syst.},
  volume={34},
  pages={9355--9366},
  year={2021}
}

@article{zhang2023vitaev2,
  title={Vitaev2: Vision transformer advanced by exploring inductive bias for image recognition and beyond},
  author={Zhang, Qiming and Xu, Yufei and Zhang, Jing and Tao, Dacheng},
  journal={Int. J. Comput. Vis.},
  pages={1--22},
  year={2023}
}

@inproceedings{rukhovich2022fcaf3d,
  title={FCAF3D: fully convolutional anchor-free 3D object detection},
  author={Rukhovich, Danila and Vorontsova, Anna and Konushin, Anton},
  booktitle={Eur. Conf. Comput. Vis.},
  pages={477--493},
  year={2022}
}

@inproceedings{qi2019deep,
  title={Deep hough voting for 3d object detection in point clouds},
  author={Qi, Charles R and Litany, Or and He, Kaiming and Guibas, Leonidas J},
  booktitle={Int. Conf. Comput. Vis.},
  pages={9277--9286},
  year={2019}
}

@inproceedings{xie2020mlcvnet,
  title={Mlcvnet: Multi-level context votenet for 3d object detection},
  author={Xie, Qian and Lai, Yu-Kun and Wu, Jing and Wang, Zhoutao and Zhang, Yiming and Xu, Kai and Wang, Jun},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={10447--10456},
  year={2020}
}

@inproceedings{misra2021end,
  title={An end-to-end transformer model for 3d object detection},
  author={Misra, Ishan and Girdhar, Rohit and Joulin, Armand},
  booktitle={Int. Conf. Comput. Vis.},
  pages={2906--2917},
  year={2021}
}

@inproceedings{zhang2020h3dnet,
  title={H3dnet: 3d object detection using hybrid geometric primitives},
  author={Zhang, Zaiwei and Sun, Bo and Yang, Haitao and Huang, Qixing},
  booktitle={Eur. Conf. Comput. Vis.},
  pages={311--329},
  year={2020},
  organization={Springer}
}

@inproceedings{cheng2021back,
  title={Back-tracing representative points for voting-based 3d object detection in point clouds},
  author={Cheng, Bowen and Sheng, Lu and Shi, Shaoshuai and Yang, Ming and Xu, Dong},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={8963--8972},
  year={2021}
}

@inproceedings{chen2020hierarchical,
  title={A hierarchical graph network for 3d object detection on point clouds},
  author={Chen, Jintai and Lei, Biwen and Song, Qingyu and Ying, Haochao and Chen, Danny Z and Wu, Jian},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={392--401},
  year={2020}
}

@inproceedings{xie2021venet,
  title={Venet: Voting enhancement network for 3d object detection},
  author={Xie, Qian and Lai, Yu-Kun and Wu, Jing and Wang, Zhoutao and Lu, Dening and Wei, Mingqiang and Wang, Jun},
  booktitle={Int. Conf. Comput. Vis.},
  pages={3712--3721},
  year={2021}
}

@inproceedings{liu2021group,
  title={Group-free 3d object detection via transformers},
  author={Liu, Ze and Zhang, Zheng and Cao, Yue and Hu, Han and Tong, Xin},
  booktitle={Int. Conf. Comput. Vis.},
  pages={2949--2958},
  year={2021}
}

@article{wang2022cagroup3d,
  title={Cagroup3d: Class-aware grouping for 3d object detection on point clouds},
  author={Wang, Haiyang and Dong, Shaocong and Shi, Shaoshuai and Li, Aoxue and Li, Jianan and Li, Zhenguo and Wang, Liwei and others},
  journal={Adv. Neural Inform. Process. Syst.},
  volume={35},
  pages={29975--29988},
  year={2022}
}


@inproceedings{hou2021exploring,
  title={Exploring data-efficient 3d scene understanding with contrastive scene contexts},
  author={Hou, Ji and Graham, Benjamin and Nie{\ss}ner, Matthias and Xie, Saining},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={15587--15597},
  year={2021}
}

@article{khosla2020supervised,
  title={Supervised contrastive learning},
  author={Khosla, Prannay and Teterwak, Piotr and Wang, Chen and Sarna, Aaron and Tian, Yonglong and Isola, Phillip and Maschinot, Aaron and Liu, Ce and Krishnan, Dilip},
  journal={Adv. Neural Inform. Process. Syst.},
  volume={33},
  pages={18661--18673},
  year={2020}
}

@inproceedings{rozenberszki2022language,
  title={Language-grounded indoor 3D semantic segmentation in the wild},
  author={Rozenberszki, David and Litany, Or and Dai, Angela},
  booktitle={Eur. Conf. Comput. Vis.},
  pages={125--141},
  year={2022}
}

@inproceedings{s3dis,
  title={3d semantic parsing of large-scale indoor spaces},
  author={Armeni, Iro and Sener, Ozan and Zamir, Amir R and Jiang, Helen and Brilakis, Ioannis and Fischer, Martin and Savarese, Silvio},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={1534--1543},
  year={2016}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={770--778},
  year={2016}
}

@inproceedings{loshchilovdecoupled,
  title={Decoupled Weight Decay Regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={International Conference on Learning Representations}
}

@inproceedings{mao2021voxel,
  title={Voxel transformer for 3d object detection},
  author={Mao, Jiageng and Xue, Yujing and Niu, Minzhe and Bai, Haoyue and Feng, Jiashi and Liang, Xiaodan and Xu, Hang and Xu, Chunjing},
  booktitle={Int. Conf. Comput. Vis.},
  pages={3164--3173},
  year={2021}
}

@inproceedings{he2022voxel,
  title={Voxel set transformer: A set-to-set approach to 3d object detection from point clouds},
  author={He, Chenhang and Li, Ruihuang and Li, Shuai and Zhang, Lei},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={8417--8427},
  year={2022}
}

@inproceedings{fan2022embracing,
  title={Embracing single stride 3d object detector with sparse transformer},
  author={Fan, Lue and Pang, Ziqi and Zhang, Tianyuan and Wang, Yu-Xiong and Zhao, Hang and Wang, Feng and Wang, Naiyan and Zhang, Zhaoxiang},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={8458--8468},
  year={2022}
}

@inproceedings{kaul2022convolutional,
  title={Convolutional point Transformer},
  author={Kaul, Chaitanya and Mitton, Joshua and Dai, Hang and Murray-Smith, Roderick},
  booktitle={Asian Conf. Comput. Vis.},
  pages={303--319},
  year={2022}
}
@article{liu2023flatformer,
  title={FlatFormer: Flattened Window Attention for Efficient Point Cloud Transformer},
  author={Liu, Zhijian and Yang, Xinyu and Tang, Haotian and Yang, Shang and Han, Song},
  journal={arXiv preprint arXiv:2301.08739},
  year={2023}
}

@article{lu20223dctn,
  title={3DCTN: 3D convolution-transformer network for point cloud classification},
  author={Lu, Dening and Xie, Qian and Gao, Kyle and Xu, Linlin and Li, Jonathan},
  journal={IEEE trans. Intell. Transp. Syst.},
  volume={23},
  number={12},
  pages={24854--24865},
  year={2022},
  publisher={IEEE}
}

@inproceedings{liu2019relation,
  title={Relation-shape convolutional neural network for point cloud analysis},
  author={Liu, Yongcheng and Fan, Bin and Xiang, Shiming and Pan, Chunhong},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={8895--8904},
  year={2019}
}

@inproceedings{liu2019densepoint,
  title={Densepoint: Learning densely contextual representation for efficient point cloud processing},
  author={Liu, Yongcheng and Fan, Bin and Meng, Gaofeng and Lu, Jiwen and Xiang, Shiming and Pan, Chunhong},
  booktitle={Int. Conf. Comput. Vis.},
  pages={5239--5248},
  year={2019}
}

@inproceedings{liu2020closer,
  title={A closer look at local aggregation operators in point cloud analysis},
  author={Liu, Ze and Hu, Han and Cao, Yue and Zhang, Zheng and Tong, Xin},
  booktitle={Eur. Conf. Comput. Vis.},
  pages={326--342},
  year={2020}
}

@article{qiu2021geometric,
  title={Geometric back-projection network for point cloud classification},
  author={Qiu, Shi and Anwar, Saeed and Barnes, Nick},
  journal={IEEE Trans. Multimedia},
  volume={24},
  pages={1943--1955},
  year={2021},
  publisher={IEEE}
}

@inproceedings{xiang2021walk,
  title={Walk in the cloud: Learning curves for point clouds shape analysis},
  author={Xiang, Tiange and Zhang, Chaoyi and Song, Yang and Yu, Jianhui and Cai, Weidong},
  booktitle={Int. Conf. Comput. Vis.},
  pages={915--924},
  year={2021}
}

@inproceedings{zhou2021adaptive,
  title={Adaptive graph convolution for point cloud analysis},
  author={Zhou, Haoran and Feng, Yidan and Fang, Mingsheng and Wei, Mingqiang and Qin, Jing and Lu, Tong},
  booktitle={Int. Conf. Comput. Vis.},
  pages={4965--4974},
  year={2021}
}

@article{ma2022rethinking,
  title={Rethinking network design and local geometry in point cloud: A simple residual MLP framework},
  author={Ma, Xu and Qin, Can and You, Haoxuan and Ran, Haoxi and Fu, Yun},
  journal={arXiv preprint arXiv:2202.07123},
  year={2022}
}

@misc{snpart,
  title={SketchUp},
  author={3D Warehouse},
  howpublished={\url{https://3dwarehouse.sketchup.com/}},
  year={2022},
}

@inproceedings{lee2022sagemix,
  title={Sagemix: Saliency-guided mixup for point clouds},
  author={Lee, Sanghyeok and Jeon, Minkyu and Kim, Injae and Xiong, Yunyang and Kim, Hyunwoo J},
  booktitle={Adv. Neural Inform. Process. Syst.},
  year={2022}
}

@inproceedings{milioto2019rangenet++,
  title={Rangenet++: Fast and accurate lidar semantic segmentation},
  author={Milioto, Andres and Vizzo, Ignacio and Behley, Jens and Stachniss, Cyrill},
  booktitle={IEEE/RSJ international conference on intelligent robots and systems (IROS)},
  year={2019}
}

@inproceedings{zhang2020polarnet,
  title={Polarnet: An improved grid representation for online lidar point clouds semantic segmentation},
  author={Zhang, Yang and Zhou, Zixiang and David, Philip and Yue, Xiangyu and Xi, Zerong and Gong, Boqing and Foroosh, Hassan},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  year={2020}
}

@inproceedings{cortinhal2020salsanext,
  title={SalsaNext: Fast, uncertainty-aware semantic segmentation of LiDAR point clouds},
  author={Cortinhal, Tiago and Tzelepis, George and Erdal Aksoy, Eren},
  booktitle={International Symposium on Visual Computing},
  year={2020}
}

@article{liong2020amvnet,
  title={Amvnet: Assertion-based multi-view fusion network for lidar semantic segmentation},
  author={Liong, Venice Erin and Nguyen, Thi Ngoc Tho and Widjaja, Sergi and Sharma, Dhananjai and Chong, Zhuang Jie},
  journal={arXiv:2012.04934},
  year={2020}
}

@inproceedings{zhu2021cylindrical,
  title={Cylindrical and asymmetrical 3d convolution networks for lidar segmentation},
  author={Zhu, Xinge and Zhou, Hui and Wang, Tai and Hong, Fangzhou and Ma, Yuexin and Li, Wei and Li, Hongsheng and Lin, Dahua},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  year={2021}
}

@inproceedings{hou2022point,
  title={Point-to-Voxel Knowledge Distillation for LiDAR Semantic Segmentation},
  author={Hou, Yuenan and Zhu, Xinge and Ma, Yuexin and Loy, Chen Change and Li, Yikang},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  year={2022}
}

@inproceedings{xu2021rpvnet,
  title={Rpvnet: A deep and efficient range-point-voxel fusion network for lidar point cloud segmentation},
  author={Xu, Jianyun and Zhang, Ruixiang and Dou, Jian and Zhu, Yushi and Sun, Jie and Pu, Shiliang},
  booktitle={Int. Conf. Comput. Vis.},
  year={2021}
}

@inproceedings{yan20222dpass,
  title={2DPASS: 2D Priors Assisted Semantic Segmentation on LiDAR Point Clouds},
  author={Yan, Xu and Gao, Jiantao and Zheng, Chaoda and Zheng, Chao and Zhang, Ruimao and Cui, Shuguang and Li, Zhen},
  booktitle={Eur. Conf. Comput. Vis.},
  year={2022}
}


@inproceedings{yan2021sparse,
  title={Sparse single sweep lidar point cloud segmentation via learning contextual shape priors from scene completion},
  author={Yan, Xu and Gao, Jiantao and Li, Jie and Zhang, Ruimao and Li, Zhen and Huang, Rui and Cui, Shuguang},
  booktitle={AAAI},
  year={2021}
}

@inproceedings{tang2020searching,
  title={Searching efficient 3d architectures with sparse point-voxel convolution},
  author={Tang, Haotian and Liu, Zhijian and Zhao, Shengyu and Lin, Yujun and Lin, Ji and Wang, Hanrui and Han, Song},
  booktitle={Eur. Conf. Comput. Vis.},
  year={2020}
}

@inproceedings{cheng20212,
  title={2-s3net: Attentive feature fusion with adaptive feature selection for sparse semantic segmentation network},
  author={Cheng, Ran and Razani, Ryan and Taghavi, Ehsan and Li, Enxu and Liu, Bingbing},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  year={2021}
}

@inproceedings{lai2023spherical,
  title={Spherical transformer for lidar-based 3d recognition},
  author={Lai, Xin and Chen, Yukang and Lu, Fanbin and Liu, Jianhui and Jia, Jiaya},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={17545--17555},
  year={2023}
}

@inproceedings{bai2022transfusion,
  title={Transfusion: Robust lidar-camera fusion for 3d object detection with transformers},
  author={Bai, Xuyang and Hu, Zeyu and Zhu, Xinge and Huang, Qingqiu and Chen, Yilun and Fu, Hongbo and Tai, Chiew-Lan},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={1090--1099},
  year={2022}
}

@inproceedings{behley2019semantickitti,
  title={Semantickitti: A dataset for semantic scene understanding of lidar sequences},
  author={Behley, Jens and Garbade, Martin and Milioto, Andres and Quenzel, Jan and Behnke, Sven and Stachniss, Cyrill and Gall, Jurgen},
  booktitle={Int. Conf. Comput. Vis.},
  pages={9297--9307},
  year={2019}
}

@inproceedings{caesar2020nuscenes,
  title={nuscenes: A multimodal dataset for autonomous driving},
  author={Caesar, Holger and Bankiti, Varun and Lang, Alex H and Vora, Sourabh and Liong, Venice Erin and Xu, Qiang and Krishnan, Anush and Pan, Yu and Baldan, Giancarlo and Beijbom, Oscar},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={11621--11631},
  year={2020}
}

@inproceedings{chan2022efficient,
  title={Efficient geometry-aware 3D generative adversarial networks},
  author={Chan, Eric R and Lin, Connor Z and Chan, Matthew A and Nagano, Koki and Pan, Boxiao and De Mello, Shalini and Gallo, Orazio and Guibas, Leonidas J and Tremblay, Jonathan and Khamis, Sameh and others},
  booktitle={IEEE Conf. Comput. Vis. Pattern Recog.},
  pages={16123--16133},
  year={2022}
}