\begin{thebibliography}{88}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Felleman and van Essen(1991)]{felleman_distributed_1991}
D.~J. Felleman and D.~C. van Essen.
\newblock Distributed hierarchical processing in the primate cerebral cortex.
\newblock \emph{Cerebral Cortex}, 1\penalty0 (1):\penalty0 1--47, 1991.

\bibitem[Douglas and Martin(2004)]{douglas_neuronal_2004}
Rodney~J. Douglas and Kevan~A.C. Martin.
\newblock Neuronal circuits of the neocortex.
\newblock \emph{Annual Review of Neuroscience}, 27\penalty0 (1):\penalty0
  419--451, 2004.

\bibitem[Liao and Poggio(2016)]{liao_bridging_2016}
Qianli Liao and Tomaso Poggio.
\newblock Bridging the gaps between residual learning, recurrent neural
  networks and visual cortex.
\newblock \emph{arXiv preprint arXiv:1604.03640}, 2016.

\bibitem[Nayebi et~al.(2018)Nayebi, Bear, Kubilius, Kar, Ganguli, Sussillo,
  DiCarlo, and Yamins]{nayebi_task-driven_2018}
Aran Nayebi, Daniel Bear, Jonas Kubilius, Kohitij Kar, Surya Ganguli, David
  Sussillo, James~J. DiCarlo, and Daniel~L. Yamins.
\newblock Task-driven convolutional recurrent models of the visual system.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Kubilius et~al.(2019)Kubilius, Schrimpf, Kar, Rajalingham, Hong,
  Majaj, Issa, Bashivan, Prescott-Roy, Schmidt, Nayebi, Bear, Yamins, and
  DiCarlo]{kubilius_brain-like_2019}
Jonas Kubilius, Martin Schrimpf, Kohitij Kar, Rishi Rajalingham, Ha~Hong, Najib
  Majaj, Elias Issa, Pouya Bashivan, Jonathan Prescott-Roy, Kailyn Schmidt,
  Aran Nayebi, Daniel Bear, Daniel~L. Yamins, and James~J. DiCarlo.
\newblock Brain-like object recognition with high-performing shallow recurrent
  {ANNs}.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  2019.

\bibitem[van Bergen and Kriegeskorte(2020)]{van_bergen_going_2020}
Ruben~S. van Bergen and Nikolaus Kriegeskorte.
\newblock Going in circles is the way forward: the role of recurrence in visual
  inference.
\newblock \emph{Current Opinion in Neurobiology}, 65:\penalty0 176--193, 2020.

\bibitem[Linsley et~al.(2020)Linsley, Karkada~Ashok, Govindarajan, Liu, and
  Serre]{linsley_stable_2020}
Drew Linsley, Alekh Karkada~Ashok, Lakshmi~Narasimhan Govindarajan, Rex Liu,
  and Thomas Serre.
\newblock Stable and expressive recurrent vision models.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  2020.

\bibitem[Bai et~al.(2019)Bai, Kolter, and Koltun]{bai_deep_2019}
Shaojie Bai, J.~Zico Kolter, and Vladlen Koltun.
\newblock Deep equilibrium models.
\newblock \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Bai et~al.(2020)Bai, Koltun, and Kolter]{bai_multiscale_2020}
Shaojie Bai, Vladlen Koltun, and J.~Zico Kolter.
\newblock Multiscale deep equilibrium models.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Huang et~al.(2021)Huang, Bai, and Kolter]{huang_implicit2_2021}
Zhichun Huang, Shaojie Bai, and J.~Zico Kolter.
\newblock Implicit$^{\textrm{2}}$: implicit layers for implicit
  representations.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  2021.

\bibitem[Grossberg(1987)]{grossberg_competitive_1987}
Stephen Grossberg.
\newblock Competitive learning: {From} interactive activation to adaptive
  resonance.
\newblock \emph{Cognitive science}, 11\penalty0 (1):\penalty0 23--63, 1987.

\bibitem[Crick(1989)]{crick_recent_1989}
Francis Crick.
\newblock The recent excitement about neural networks.
\newblock \emph{Nature}, 337:\penalty0 129--132, 1989.

\bibitem[Lillicrap and Santoro(2019)]{lillicrap_backpropagation_2019}
Timothy~P. Lillicrap and Adam Santoro.
\newblock Backpropagation through time and the brain.
\newblock \emph{Current Opinion in Neurobiology}, 55:\penalty0 82--89, 2019.

\bibitem[Körding and König(2001)]{kording_supervised_2001}
Konrad~P Körding and Peter König.
\newblock Supervised and unsupervised learning with two sites of synaptic
  integration.
\newblock \emph{Journal of Computational Neuroscience}, 11\penalty0
  (3):\penalty0 207--215, 2001.

\bibitem[Lee et~al.(2015)Lee, Zhang, Fischer, and Bengio]{lee_difference_2015}
Dong-Hyun Lee, Saizheng Zhang, Asja Fischer, and Yoshua Bengio.
\newblock Difference target propagation.
\newblock In \emph{Joint {European} {Conference} on {Machine} {Learning} and
  {Knowledge} {Discovery} in {Databases}}, 2015.

\bibitem[Lillicrap et~al.(2016)Lillicrap, Cownden, Tweed, and
  Akerman]{lillicrap_random_2016}
Timothy~P. Lillicrap, Daniel Cownden, Douglas~B. Tweed, and Colin~J. Akerman.
\newblock Random synaptic feedback weights support error backpropagation for
  deep learning.
\newblock \emph{Nature Communications}, 7\penalty0 (1):\penalty0 13276, 2016.

\bibitem[Sacramento et~al.(2018)Sacramento, Costa, Bengio, and
  Senn]{sacramento_dendritic_2018}
João Sacramento, Rui~P. Costa, Yoshua Bengio, and Walter Senn.
\newblock Dendritic cortical microcircuits approximate the backpropagation
  algorithm.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  2018.

\bibitem[Roelfsema and Holtmaat(2018)]{roelfsema_control_2018}
Pieter~R. Roelfsema and Anthony Holtmaat.
\newblock Control of synaptic plasticity in deep cortical networks.
\newblock \emph{Nature Reviews Neuroscience}, 19\penalty0 (3):\penalty0
  166--180, 2018.

\bibitem[Whittington and Bogacz(2019)]{whittington_theories_2019}
James C.~R. Whittington and Rafal Bogacz.
\newblock Theories of error back-propagation in the brain.
\newblock \emph{Trends in Cognitive Sciences}, 23\penalty0 (3):\penalty0
  235--250, 2019.

\bibitem[Richards and Lillicrap(2019)]{richards_dendritic_2019}
Blake~A. Richards and Timothy~P. Lillicrap.
\newblock Dendritic solutions to the credit assignment problem.
\newblock \emph{Current Opinion in Neurobiology}, 54:\penalty0 28--36, 2019.

\bibitem[Richards et~al.(2019)Richards, Lillicrap, Beaudoin, Bengio, Bogacz,
  Christensen, Clopath, Costa, de~Berker, Ganguli, Gillon, Hafner, Kepecs,
  Kriegeskorte, Latham, Lindsay, Miller, Naud, Pack, Poirazi, Roelfsema,
  Sacramento, Saxe, Scellier, Schapiro, Senn, Wayne, Yamins, Zenke, Zylberberg,
  Therien, and Kording]{richards_deep_2019}
Blake~A. Richards, Timothy~P. Lillicrap, Philippe Beaudoin, Yoshua Bengio,
  Rafal Bogacz, Amelia Christensen, Claudia Clopath, Rui~Ponte Costa, Archy
  de~Berker, Surya Ganguli, Colleen~J. Gillon, Danijar Hafner, Adam Kepecs,
  Nikolaus Kriegeskorte, Peter Latham, Grace~W. Lindsay, Kenneth~D. Miller,
  Richard Naud, Christopher~C. Pack, Panayiota Poirazi, Pieter Roelfsema, João
  Sacramento, Andrew Saxe, Benjamin Scellier, Anna~C. Schapiro, Walter Senn,
  Greg Wayne, Daniel Yamins, Friedemann Zenke, Joel Zylberberg, Denis Therien,
  and Konrad~P. Kording.
\newblock A deep learning framework for neuroscience.
\newblock \emph{Nature Neuroscience}, 22\penalty0 (11):\penalty0 1761--1770,
  2019.

\bibitem[Lillicrap et~al.(2020)Lillicrap, Santoro, Marris, Akerman, and
  Hinton]{lillicrap_backpropagation_2020}
Timothy~P. Lillicrap, Adam Santoro, Luke Marris, Colin~J. Akerman, and Geoffrey
  Hinton.
\newblock Backpropagation and the brain.
\newblock \emph{Nature Reviews Neuroscience}, 21\penalty0 (6):\penalty0
  335--346, 2020.

\bibitem[Payeur et~al.(2021)Payeur, Guerguiev, Zenke, Richards, and
  Naud]{payeur_burst-dependent_2021}
Alexandre Payeur, Jordan Guerguiev, Friedemann Zenke, Blake~A. Richards, and
  Richard Naud.
\newblock Burst-dependent synaptic plasticity can coordinate learning in
  hierarchical circuits.
\newblock \emph{Nature Neuroscience}, 24\penalty0 (7):\penalty0 1010--1019,
  2021.

\bibitem[Scellier and Bengio(2017)]{scellier_equilibrium_2017}
Benjamin Scellier and Yoshua Bengio.
\newblock Equilibrium propagation: bridging the gap between energy-based models
  and backpropagation.
\newblock \emph{Frontiers in Computational Neuroscience}, 11, 2017.

\bibitem[Bellec et~al.(2020)Bellec, Scherr, Subramoney, Hajek, Salaj,
  Legenstein, and Maass]{bellec_solution_2020}
Guillaume Bellec, Franz Scherr, Anand Subramoney, Elias Hajek, Darjan Salaj,
  Robert Legenstein, and Wolfgang Maass.
\newblock A solution to the learning dilemma for recurrent networks of spiking
  neurons.
\newblock \emph{Nature Communications}, 11\penalty0 (1):\penalty0 3625, 2020.

\bibitem[Martin et~al.(2000)Martin, Grimwood, and Morris]{martin2000synaptic}
Stephen~J. Martin, Paul~D. Grimwood, and Richard~G.M. Morris.
\newblock Synaptic plasticity and memory: an evaluation of the hypothesis.
\newblock \emph{Annual Review of Neuroscience}, 23\penalty0 (1):\penalty0
  649--711, 2000.

\bibitem[Amos(2019)]{amos_differentiable_2019}
Brandon Amos.
\newblock \emph{Differentiable optimization-based modeling for machine
  learning}.
\newblock {PhD} {Thesis}, Carnegie Mellon University, 2019.

\bibitem[Gould et~al.(2021)Gould, Hartley, and Campbell]{gould_deep_2021}
Stephen Gould, Richard Hartley, and Dylan~John Campbell.
\newblock Deep declarative networks.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2021.

\bibitem[El~Ghaoui et~al.(2021)El~Ghaoui, Gu, Travacca, Askari, and
  Tsai]{el_ghaoui_implicit_2021}
Laurent El~Ghaoui, Fangda Gu, Bertrand Travacca, Armin Askari, and Alicia Tsai.
\newblock Implicit deep learning.
\newblock \emph{SIAM Journal on Mathematics of Data Science}, 3\penalty0
  (3):\penalty0 930--958, 2021.

\bibitem[Meulemans et~al.(2022)Meulemans, Farinha, Cervera, Sacramento, and
  Grewe]{meulemans_minimizing_2022}
Alexander Meulemans, Matilde~Tristany Farinha, Maria~R. Cervera, João
  Sacramento, and Benjamin~F. Grewe.
\newblock Minimizing control for credit assignment with strong feedback.
\newblock \emph{arXiv preprint arXiv:2204.07249}, 2022.

\bibitem[Werbos(1974)]{werbos_beyond_1974}
Paul Werbos.
\newblock \emph{Beyond regression: new tools for prediction and analysis in the
  behavioral sciences}.
\newblock Ph.{D}. thesis, Harvard University, 1974.

\bibitem[Rumelhart et~al.(1986)Rumelhart, Hinton, and
  Williams]{rumelhart_learning_1986}
David~E. Rumelhart, Geoffrey~E. Hinton, and Ronald~J. Williams.
\newblock Learning representations by back-propagating errors.
\newblock \emph{Nature}, 323\penalty0 (6088):\penalty0 533--536, 1986.

\bibitem[Almeida(1989)]{almeida_backpropagation_1989}
Luís~B. Almeida.
\newblock Backpropagation in perceptrons with feedback.
\newblock In Rolf Eckmiller and Christoph v.d. Malsburg, editors, \emph{Neural
  {Computers}}, pages 199--208. Springer Berlin Heidelberg, 1989.

\bibitem[Pineda(1989)]{pineda_recurrent_1989}
Fernando~J. Pineda.
\newblock Recurrent backpropagation and the dynamical approach to adaptive
  neural computation.
\newblock \emph{Neural Computation}, 1\penalty0 (2):\penalty0 161--172, 1989.

\bibitem[Zucchet et~al.(2022)Zucchet, Schug, von Oswald, Zhao, and
  Sacramento]{zucchet_contrastive_2022}
Nicolas Zucchet, Simon Schug, Johannes von Oswald, Dominic Zhao, and João
  Sacramento.
\newblock A contrastive rule for meta-learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Whittington and Bogacz(2017)]{whittington_approximation_2017}
James C.~R. Whittington and Rafal Bogacz.
\newblock An approximation of the error backpropagation algorithm in a
  predictive coding network with local {Hebbian} synaptic plasticity.
\newblock \emph{Neural Computation}, 29\penalty0 (5):\penalty0 1229--1262,
  2017.

\bibitem[Friston(2009)]{friston_free-energy_2009}
Karl Friston.
\newblock The free-energy principle: a rough guide to the brain?
\newblock \emph{Trends in Cognitive Sciences}, 13\penalty0 (7):\penalty0
  293--301, 2009.

\bibitem[Carreira-Perpinan and Wang(2014)]{carreira-perpinan_distributed_2014}
Miguel Carreira-Perpinan and Weiran Wang.
\newblock Distributed optimization of deeply nested systems.
\newblock In \emph{Artificial {Intelligence} and {Statistics}}, 2014.

\bibitem[Dold et~al.(2019)Dold, Kungl, Sacramento, Petrovici, Schindler, Binas,
  Bengio, and Senn]{dold_lagrangian_2019}
Dominik Dold, Akos~F. Kungl, João Sacramento, Mihai~A. Petrovici, Kaspar
  Schindler, Jonathan Binas, Yoshua Bengio, and Walter Senn.
\newblock Lagrangian dynamics of dendritic microcircuits enables real-time
  backpropagation of errors.
\newblock In \emph{Computational and {Systems} {Neuroscience} ({Cosyne})},
  2019.

\bibitem[Scellier(2021)]{scellier_deep_2021}
Benjamin Scellier.
\newblock \emph{A deep learning theory for neural networks grounded in
  physics}.
\newblock {PhD} {Thesis}, Université de Montréal, 2021.

\bibitem[Guerguiev et~al.(2017)Guerguiev, Lillicrap, and
  Richards]{guerguiev_towards_2017}
Jordan Guerguiev, Timothy~P. Lillicrap, and Blake~A. Richards.
\newblock Towards deep learning with segregated dendrites.
\newblock \emph{eLife}, 6:\penalty0 e22901, 2017.

\bibitem[Akrout et~al.(2019)Akrout, Wilson, Humphreys, Lillicrap, and
  Tweed]{akrout_deep_2019}
Mohamed Akrout, Collin Wilson, Peter Humphreys, Timothy~P. Lillicrap, and
  Douglas~B. Tweed.
\newblock Deep learning without weight transport.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  2019.

\bibitem[Meulemans et~al.(2020)Meulemans, Carzaniga, Suykens, Sacramento, and
  Grewe]{meulemans_theoretical_2020}
Alexander Meulemans, Francesco Carzaniga, Johan Suykens, João Sacramento, and
  Benjamin~F. Grewe.
\newblock A theoretical framework for target propagation.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  2020.

\bibitem[Podlaski and Machens(2020)]{podlaski_biological_2020}
William~F. Podlaski and Christian~K. Machens.
\newblock Biological credit assignment through dynamic inversion of feedforward
  networks.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  2020.

\bibitem[Pozzi et~al.(2020)Pozzi, Bohte, and
  Roelfsema]{pozzi_attention-gated_2020}
Isabella Pozzi, Sander Bohte, and Pieter Roelfsema.
\newblock Attention-gated brain propagation: how the brain can implement
  reward-based error backpropagation.
\newblock \emph{Advances in Neural Information Processing Systems}, pages
  2516--2526, 2020.

\bibitem[Gilbert and Li(2013)]{gilbert_top-down_2013}
Charles~D. Gilbert and Wu~Li.
\newblock Top-down influences on visual processing.
\newblock \emph{Nature Reviews Neuroscience}, 14\penalty0 (5):\penalty0
  350--363, 2013.

\bibitem[Manita et~al.(2015)Manita, Suzuki, Homma, Matsumoto, Odagawa, Yamada,
  Ota, Matsubara, Inutsuka, Sato, Ohkura, Yamanaka, Yanagawa, Nakai, Hayashi,
  Larkum, and Murayama]{manita_top-down_2015}
Satoshi Manita, Takayuki Suzuki, Chihiro Homma, Takashi Matsumoto, Maya
  Odagawa, Kazuyuki Yamada, Keisuke Ota, Chie Matsubara, Ayumu Inutsuka,
  Masaaki Sato, Masamichi Ohkura, Akihiro Yamanaka, Yuchio Yanagawa, Junichi
  Nakai, Yasunori Hayashi, Matthew~E. Larkum, and Masanori Murayama.
\newblock A top-down cortical circuit for accurate sensory perception.
\newblock \emph{Neuron}, 86\penalty0 (5):\penalty0 1304--1316, 2015.

\bibitem[Marques et~al.(2018)Marques, Nguyen, Fioreze, and
  Petreanu]{marques_functional_2018}
Tiago Marques, Julia Nguyen, Gabriela Fioreze, and Leopoldo Petreanu.
\newblock The functional organization of cortical feedback inputs to primary
  visual cortex.
\newblock \emph{Nature Neuroscience}, 21\penalty0 (5):\penalty0 757--764, 2018.

\bibitem[Kirchberger et~al.(2021)Kirchberger, Mukherjee, Schnabel, van Beest,
  Barsegyan, Levelt, Heimel, Lorteije, van~der Togt, Self, and
  Roelfsema]{kirchberger_essential_2021}
Lisa Kirchberger, Sreedeep Mukherjee, Ulf~H. Schnabel, Enny~H. van Beest, Areg
  Barsegyan, Christiaan~N. Levelt, J.~Alexander Heimel, Jeannette A.~M.
  Lorteije, Chris van~der Togt, Matthew~W. Self, and Pieter~R. Roelfsema.
\newblock The essential role of recurrent processing for figure-ground
  perception in mice.
\newblock \emph{Science Advances}, 7\penalty0 (27):\penalty0 eabe1833, 2021.

\bibitem[Nøkland(2016)]{nokland_direct_2016}
Arild Nøkland.
\newblock Direct feedback alignment provides learning in deep neural networks.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  2016.

\bibitem[Meulemans et~al.(2021)Meulemans, Tristany~Farinha, Garcia~Ordonez,
  Vilimelis~Aceituno, Sacramento, and Grewe]{meulemans_credit_2021}
Alexander Meulemans, Matilde Tristany~Farinha, Javier Garcia~Ordonez, Pau
  Vilimelis~Aceituno, João Sacramento, and Benjamin~F. Grewe.
\newblock Credit assignment in neural networks through deep feedback control.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  2021.

\bibitem[LeCun(1998)]{lecun_mnist_1998}
Yann LeCun.
\newblock The {MNIST} database of handwritten digits.
\newblock \emph{Available at http://yann. lecun. com/exdb/mnist}, 1998.

\bibitem[Bartunov et~al.(2018)Bartunov, Santoro, Richards, Marris, Hinton, and
  Lillicrap]{bartunov_assessing_2018}
Sergey Bartunov, Adam Santoro, Blake Richards, Luke Marris, Geoffrey~E. Hinton,
  and Timothy~P. Lillicrap.
\newblock Assessing the scalability of biologically-motivated deep learning
  algorithms and architectures.
\newblock In \emph{Advances in neural information processing systems}, 2018.

\bibitem[Kolen and Pollack(1994)]{kolen_back-propagation_1994}
John~F. Kolen and Jordan~B. Pollack.
\newblock Back-propagation without weight transport.
\newblock In \emph{Proceedings of 1994 {IEEE} {International} {Conference} on
  {Neural} {Networks} ({ICNN}’94)}, 1994.

\bibitem[Mikulasch et~al.(2022)Mikulasch, Rudelt, Wibral, and
  Priesemann]{mikulasch_dendritic_2022}
Fabian~A. Mikulasch, Lucas Rudelt, Michael Wibral, and Viola Priesemann.
\newblock Dendritic predictive coding: {A} theory of cortical computation with
  spiking neurons.
\newblock \emph{arXiv preprint arXiv:2205.05303}, 2022.

\bibitem[Rao and Ballard(1999)]{rao_predictive_1999}
Rajesh P.~N. Rao and Dana~H. Ballard.
\newblock Predictive coding in the visual cortex: a functional interpretation
  of some extra-classical receptive-field effects.
\newblock \emph{Nature Neuroscience}, 2\penalty0 (1):\penalty0 79--87, 1999.

\bibitem[Bastos et~al.(2012)Bastos, Usrey, Adams, Mangun, Fries, and
  Friston]{bastos_canonical_2012}
Andre~M. Bastos, W.~Martin Usrey, Rick~A. Adams, George~R. Mangun, Pascal
  Fries, and Karl~J. Friston.
\newblock Canonical microcircuits for predictive coding.
\newblock \emph{Neuron}, 76\penalty0 (4):\penalty0 695--711, 2012.

\bibitem[Keller and Mrsic-Flogel(2018)]{keller_predictive_2018}
Georg~B. Keller and Thomas~D. Mrsic-Flogel.
\newblock Predictive processing: a canonical cortical computation.
\newblock \emph{Neuron}, 100\penalty0 (2):\penalty0 424--435, 2018.

\bibitem[Fathony et~al.(2020)Fathony, Sahu, Willmott, and
  Kolter]{fathony_multiplicative_2020}
Rizal Fathony, Anit~Kumar Sahu, Devin Willmott, and J.~Zico Kolter.
\newblock Multiplicative filter networks.
\newblock September 2020.

\bibitem[Krizhevsky and Hinton(2009)]{krizhevsky_learning_2009}
Alex Krizhevsky and Geoffrey Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, 2009.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he_deep_2016}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the {IEEE} {Conference} on {Computer}
  {Vision} and {Pattern} {Recognition}}, 2016.

\bibitem[Chen et~al.(2018)Chen, Rubanova, Bettencourt, and
  Duvenaud]{chen_neural_2018}
Ricky T.~Q. Chen, Yulia Rubanova, Jesse Bettencourt, and David~K. Duvenaud.
\newblock Neural ordinary differential equations.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  2018.

\bibitem[Sitzmann et~al.(2020)Sitzmann, Martel, Bergman, Lindell, and
  Wetzstein]{sitzmann_implicit_2020}
Vincent Sitzmann, Julien Martel, Alexander Bergman, David Lindell, and Gordon
  Wetzstein.
\newblock Implicit neural representations with periodic activation functions.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  2020.

\bibitem[Thrun and Pratt(1998)]{thrun_learning_1998}
Sebastian Thrun and Lorien Pratt.
\newblock \emph{Learning to learn}.
\newblock Springer US, 1998.

\bibitem[Behrens et~al.(2018)Behrens, Muller, Whittington, Mark, Baram,
  Stachenfeld, and Kurth-Nelson]{behrens_what_2018}
Timothy E.~J. Behrens, Timothy~H Muller, James C.~R. Whittington, Shirley Mark,
  Alon~B. Baram, Kimberly~L Stachenfeld, and Zeb Kurth-Nelson.
\newblock What is a cognitive map? {Organizing} knowledge for flexible
  behavior.
\newblock \emph{Neuron}, 100\penalty0 (2):\penalty0 490--509, 2018.

\bibitem[Wang et~al.(2018)Wang, Kurth-Nelson, Kumaran, Tirumala, Soyer, Leibo,
  Hassabis, and Botvinick]{wang_prefrontal_2018}
Jane~X. Wang, Zeb Kurth-Nelson, Dharshan Kumaran, Dhruva Tirumala, Hubert
  Soyer, Joel~Z. Leibo, Demis Hassabis, and Matthew Botvinick.
\newblock Prefrontal cortex as a meta-reinforcement learning system.
\newblock \emph{Nature Neuroscience}, 21\penalty0 (6):\penalty0 860--868, 2018.

\bibitem[Wang(2021)]{wang_meta-learning_2021}
Jane~X. Wang.
\newblock Meta-learning in natural and artificial intelligence.
\newblock \emph{Current Opinion in Behavioral Sciences}, 38:\penalty0 90--95,
  2021.

\bibitem[Rajeswaran et~al.(2019)Rajeswaran, Finn, Kakade, and
  Levine]{rajeswaran_meta-learning_2019}
Aravind Rajeswaran, Chelsea Finn, Sham Kakade, and Sergey Levine.
\newblock Meta-learning with implicit gradients.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  2019.

\bibitem[Fusi et~al.(2005)Fusi, Drew, and Abbott]{fusi_cascade_2005}
Stefano Fusi, Patrick~J. Drew, and Larry~F. Abbott.
\newblock Cascade models of synaptically stored memories.
\newblock \emph{Neuron}, 45\penalty0 (4):\penalty0 599--611, 2005.

\bibitem[Ziegler et~al.(2015)Ziegler, Zenke, Kastner, and
  Gerstner]{ziegler_synaptic_2015}
Lorric Ziegler, Friedemann Zenke, David~B. Kastner, and Wulfram Gerstner.
\newblock Synaptic consolidation: from synapses to behavioral modeling.
\newblock \emph{Journal of Neuroscience}, 35\penalty0 (3):\penalty0 1319--1334,
  2015.

\bibitem[Benna and Fusi(2016)]{benna_computational_2016}
Marcus~K. Benna and Stefano Fusi.
\newblock Computational principles of synaptic memory consolidation.
\newblock \emph{Nature Neuroscience}, 19\penalty0 (12):\penalty0 1697--1706,
  2016.

\bibitem[Zenke et~al.(2017)Zenke, Poole, and Ganguli]{zenke_continual_2017}
Friedemann Zenke, Ben Poole, and Surya Ganguli.
\newblock Continual learning through synaptic intelligence.
\newblock In \emph{International {Conference} on {Machine} {Learning}}, 2017.

\bibitem[Kirkpatrick et~al.(2017)Kirkpatrick, Pascanu, Rabinowitz, Veness,
  Desjardins, Rusu, Milan, Quan, Ramalho, Grabska-Barwinska, Hassabis, Clopath,
  Kumaran, and Hadsell]{kirkpatrick_overcoming_2017}
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume
  Desjardins, Andrei~A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka
  Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and
  Raia Hadsell.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock \emph{Proceedings of the National Academy of Sciences of the United
  States of America}, 114\penalty0 (13):\penalty0 3521--3526, 2017.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn_model-agnostic_2017}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International {Conference} on {Machine} {Learning}}, 2017.

\bibitem[Luketina et~al.(2016)Luketina, Berglund, Greff, and
  Raiko]{luketina_scalable_2016}
Jelena Luketina, Mathias Berglund, Klaus Greff, and Tapani Raiko.
\newblock Scalable gradient-based tuning of continuous regularization
  hyperparameters.
\newblock In \emph{International {Conference} on {Machine} {Learning}}, 2016.

\bibitem[Nichol et~al.(2018)Nichol, Achiam, and
  Schulman]{nichol_first-order_2018}
Alex Nichol, Joshua Achiam, and John Schulman.
\newblock On first-order meta-learning algorithms.
\newblock \emph{arXiv preprint arXiv:1803.02999}, 2018.

\bibitem[Lorraine et~al.(2020)Lorraine, Vicol, and
  Duvenaud]{lorraine_optimizing_2020}
Jonathan Lorraine, Paul Vicol, and David Duvenaud.
\newblock Optimizing millions of hyperparameters by implicit differentiation.
\newblock In \emph{International {Conference} on {Artificial} {Intelligence}
  and {Statistics}}, 2020.

\bibitem[Lake et~al.(2015)Lake, Salakhutdinov, and
  Tenenbaum]{lake_human-level_2015}
Brenden~M. Lake, Ruslan Salakhutdinov, and Joshua~B. Tenenbaum.
\newblock Human-level concept learning through probabilistic program induction.
\newblock \emph{Science}, 350\penalty0 (6266):\penalty0 1332--1338, 2015.

\bibitem[Bryson and Ho(1969)]{bryson_applied_1969}
A.~E. Bryson and Y.~C. Ho.
\newblock \emph{Applied optimal control: optimization, estimation, and
  control}.
\newblock Blaisdell Pub. Co., 1969.

\bibitem[Baydin et~al.(2018)Baydin, Pearlmutter, Radul, and
  Siskind]{baydin_automatic_2018}
Atilim~Gunes Baydin, Barak~A. Pearlmutter, Alexey~Andreyevich Radul, and
  Jeffrey~Mark Siskind.
\newblock Automatic differentiation in machine learning: a survey.
\newblock \emph{Journal of Marchine Learning Research}, 18:\penalty0 1--43,
  2018.

\bibitem[LeCun(1988)]{lecun_theoretical_1988}
Yann LeCun.
\newblock A theoretical framework for back-propagation.
\newblock In \emph{Proceedings of the 1998 {Connectionist} {Models} {Summer}
  {School}}, 1988.

\bibitem[Gilra and Gerstner(2017)]{gilra_predicting_2017}
Aditya Gilra and Wulfram Gerstner.
\newblock Predicting non-linear dynamics by stable local learning in a
  recurrent spiking neural network.
\newblock \emph{eLife}, 6:\penalty0 e28295, 2017.

\bibitem[Denève et~al.(2017)Denève, Alemi, and Bourdoukan]{deneve_brain_2017}
Sophie Denève, Alireza Alemi, and Ralph Bourdoukan.
\newblock The brain as an efficient and robust adaptive learner.
\newblock \emph{Neuron}, 94\penalty0 (5):\penalty0 969--977, 2017.

\bibitem[Alemi et~al.(2018)Alemi, Machens, Deneve, and
  Slotine]{alemi_learning_2018}
Alireza Alemi, Christian Machens, Sophie Deneve, and Jean-Jacques Slotine.
\newblock Learning nonlinear dynamics in efficient, balanced spiking networks
  using local plasticity rules.
\newblock In \emph{Proceedings of the {AAAI} {Conference} on {Artificial}
  {Intelligence}}, 2018.

\bibitem[Rusakov et~al.(2020)Rusakov, Savtchenko, and
  Latham]{rusakov_noisy_2020}
Dmitri~A. Rusakov, Leonid~P. Savtchenko, and Peter~E. Latham.
\newblock Noisy synaptic conductance: {Bug} or a feature?
\newblock \emph{Trends in Neurosciences}, 43\penalty0 (6):\penalty0 363--372,
  2020.

\bibitem[Hopfield(1984)]{hopfield_neurons_1984}
J.~J. Hopfield.
\newblock Neurons with graded response have collective computational properties
  like those of two-state neurons.
\newblock \emph{Proceedings of the National Academy of Sciences}, 81\penalty0
  (10):\penalty0 3088--3092, 1984.

\bibitem[Cohen and Grossberg(1983)]{cohen_absolute_1983}
Michael~A. Cohen and Stephen Grossberg.
\newblock Absolute stability of global pattern formation and parallel memory
  storage by competitive neural networks.
\newblock \emph{IEEE Transactions on Systems, Man, and Cybernetics},
  SMC-13\penalty0 (5):\penalty0 815--826, 1983.

\bibitem[Kingma and Ba(2015)]{kingma_adam_2015}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In \emph{International {Conference} on {Learning} {Representations}},
  2015.

\end{thebibliography}
