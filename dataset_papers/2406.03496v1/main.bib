@article{zhai2019large,
author    = {Xiaohua Zhai and
               Joan Puigcerver and
               Alexander Kolesnikov and
               Pierre Ruyssen and
               Carlos Riquelme and
               Mario Lucic and
               Josip Djolonga and
               Andr{\'{e}} Susano Pinto and
               Maxim Neumann and
               Alexey Dosovitskiy and
               Lucas Beyer and
               Olivier Bachem and
               Michael Tschannen and
               Marcin Michalski and
               Olivier Bousquet and
               Sylvain Gelly and
               Neil Houlsby},
  title     = {A Large-scale Study of Representation Learning with the Visual Task Adaptation Benchmark},
  journal   = {CoRR},
  volume    = {abs/1910.04867},
  year      = {2019}
}

@inproceedings{salman2020adversarially,
  title={Do adversarially robust imagenet models transfer better?},
  author={Salman, Hadi and Ilyas, Andrew and Engstrom, Logan and Kapoor, Ashish and Madry, Aleksander},
  booktitle = {NeurIPS},
  year      = {2020}
}

@inproceedings{DBLP:conf/iclr/SanhWRBSACSRDBX22,
  author       = {Victor Sanh and
                  Albert Webson and
                  Colin Raffel and
                  Stephen H. Bach and
                  Lintang Sutawika and
                  Zaid Alyafeai and
                  Antoine Chaffin and
                  Arnaud Stiegler and
                  Arun Raja and
                  others},
  title        = {Multitask Prompted Training Enables Zero-Shot Task Generalization},
  booktitle    = {{ICLR}},
  year         = {2022}
}

@article{kendall1938new,
  title={A new measure of rank correlation},
  author={Kendall, Maurice G},
  journal={Biometrika},
  volume={30},
  number={1/2},
  year={1938}
}

@inproceedings{rong2020self,
  title={Self-Supervised Graph Transformer on Large-Scale Molecular Data},
  author={Rong, Yu and Bian, Yatao and Xu, Tingyang and Xie, Weiyang and Wei, Ying and Huang, Wenbing and Huang, Junzhou},
  journal={NeurIPS},
  year={2020}
}

@article{ding2023enhancing,
  title={Enhancing Chat Language Models by Scaling High-quality Instructional Conversations},
  author={Ding, Ning and Chen, Yulin and Xu, Bokai and Qin, Yujia and Zheng, Zhi and Hu, Shengding and Liu, Zhiyuan and Sun, Maosong and Zhou, Bowen},
  journal={arXiv preprint arXiv:2305.14233},
  year={2023}
}

@inproceedings{DBLP:conf/nips/ZhouLX0SMMEYYZG23,
  author       = {Chunting Zhou and
                  Pengfei Liu and
                  Puxin Xu and
                  Srinivasan Iyer and
                  Jiao Sun and
                  Yuning Mao and
                  Xuezhe Ma and
                  Avia Efrat and
                  Ping Yu and
                  Lili Yu and
                  Susan Zhang and
                  Gargi Ghosh and
                  Mike Lewis and
                  Luke Zettlemoyer and
                  Omer Levy},
  title        = {{LIMA:} Less Is More for Alignment},
  booktitle    = {{NeurIPS}},
  year         = {2023}
}

@misc{BELLE,
  author = {BELLEGroup},
  title = {BELLE: Be Everyone's Large Language model Engine},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/LianjiaTech/BELLE}},
}

@inproceedings{DBLP:conf/cvpr/ChangCNGSB22,
  author       = {Yingshan Chang and
                  Guihong Cao and
                  Mridu Narang and
                  Jianfeng Gao and
                  Hisami Suzuki and
                  Yonatan Bisk},
  title        = {WebQA: Multihop and Multimodal {QA}},
  booktitle    = {{CVPR}},
  pages        = {16474--16483},
  publisher    = {{IEEE}},
  year         = {2022}
}

@article{belle2023exploring,
  title={Exploring the Impact of Instruction Data Scaling on Large Language Models: An Empirical Study on Real-World Use Cases},
  author={Yunjie Ji and Yong Deng and Yan Gong and Yiping Peng and Qiang Niu and Lei Zhang and Baochang Ma and Xiangang Li},
  journal={arXiv preprint arXiv:2303.14742},
  year={2023}
}

@article{wen2023chathome,
  title={ChatHome: Development and Evaluation of a Domain-Specific Language Model for Home Renovation},
  author={Wen, Cheng and Sun, Xianghui and Zhao, Shuaijiang and Fang, Xiaoquan and Chen, Liangyu and Zou, Wei},
  journal={arXiv preprint arXiv:2307.15290},
  year={2023}
}

@article{peng2023instruction,
  title={Instruction Tuning with GPT-4},
  author={Peng, Baolin and Li, Chunyuan and He, Pengcheng and Galley, Michel and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2304.03277},
  year={2023}
}
 
@inproceedings{hjelm2018learning,
  title={Learning deep representations by mutual information estimation and maximization},
  author={Hjelm, R Devon and Fedorov, Alex and Lavoie-Marchildon, Samuel and Grewal, Karan and Bachman, Phil and Trischler, Adam and Bengio, Yoshua},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{dwivedi2019representation,
  title={Representation similarity analysis for efficient task taxonomy \& transfer learning},
  author={Dwivedi, Kshitij and Roig, Gemma},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{cui2018large,
  title={Large scale fine-grained categorization and domain-specific transfer learning},
  author={Cui, Yin and Song, Yang and Sun, Chen and Howard, Andrew and Belongie, Serge},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{DBLP:conf/icml/YouLWL21,
  author    = {Kaichao You and
               Yong Liu and
               Jianmin Wang and
               Mingsheng Long},
  title     = {LogME: Practical Assessment of Pre-trained Models for Transfer Learning},
  booktitle = {ICML},
  year      = {2021}
}

@article{DBLP:journals/corr/abs-2001-08361,
  author       = {Jared Kaplan and
                  Sam McCandlish and
                  Tom Henighan and
                  Tom B. Brown and
                  Benjamin Chess and
                  Rewon Child and
                  Scott Gray and
                  Alec Radford and
                  Jeffrey Wu and
                  Dario Amodei},
  title        = {Scaling Laws for Neural Language Models},
  journal      = {CoRR},
  volume       = {abs/2001.08361},
  year         = {2020}
}

@article{DBLP:journals/jmlr/ChowdheryNDBMRBCSGSSTMRBTSPRDHPBAI23,
  author       = {Aakanksha Chowdhery and
                  Sharan Narang and
                  Jacob Devlin and
                  Maarten Bosma and
                  Gaurav Mishra and
                  Adam Roberts and
                  Paul Barham and
                  Hyung Won Chung and
                  Charles Sutton and
                  Sebastian Gehrmann and
                  others},
  title        = {PaLM: Scaling Language Modeling with Pathways},
  journal      = {J. Mach. Learn. Res.},
  volume       = {24},
  pages        = {240:1--240:113},
  year         = {2023}
}

@article{deshpande2021linearized,
  title={A linearized framework and a new benchmark for model selection for fine-tuning},
  author={Deshpande, Aditya and Achille, Alessandro and Ravichandran, Avinash and Li, Hao and Zancato, Luca and Fowlkes, Charless and Bhotika, Rahul and Soatto, Stefano and Perona, Pietro},
  journal   = {CoRR},
  volume    = {abs/2102.00084},
  year      = {2021}
}

@inproceedings{film,
  author       = {Ethan Perez and
                  Florian Strub and
                  Harm de Vries and
                  Vincent Dumoulin and
                  Aaron C. Courville},
  title        = {FiLM: Visual Reasoning with a General Conditioning Layer},
  booktitle    = {{AAAI}},
  pages        = {3942--3951},
  year         = {2018}
}

@inproceedings{eaton2008modeling,
  title={Modeling transfer relationships between learning tasks for improved inductive transfer},
  author    = {Eric Eaton and
               Marie desJardins and
               Terran Lane},
  booktitle={ECML/PKDD},
  year={2008}
}

@inproceedings{sinapov2015learning,
  title={Learning inter-task transferability in the absence of target task samples},
  author={Sinapov, Jivko and Narvekar, Sanmit and Leonetti, Matteo and Stone, Peter},
  booktitle={AAMAS},
  year={2015}
}

@inproceedings{nguyen2020leep,
  title={LEEP: A New Measure to Evaluate Transferability of Learned Representations},
  author={Nguyen, Cuong V and Hassner, Tal and Archambeau, Cedric and Seeger, Matthias},
  booktitle={ICML},
  year={2020}
}

@inproceedings{DBLP:conf/iclr/HuSWALWWC22,
  author       = {Edward J. Hu and
                  Yelong Shen and
                  Phillip Wallis and
                  Zeyuan Allen{-}Zhu and
                  Yuanzhi Li and
                  Shean Wang and
                  Lu Wang and
                  Weizhu Chen},
  title        = {LoRA: Low-Rank Adaptation of Large Language Models},
  booktitle    = {{ICLR}},
  year         = {2022}
}

@article{DBLP:journals/corr/abs-2403-03432,
  author       = {Wenfeng Feng and
                  Chuzhan Hao and
                  Yuewei Zhang and
                  Yu Han and
                  Hao Wang},
  title        = {Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2403.03432},
  year         = {2024}
}

@article{valipour2022dylora,
  title={Dylora: Parameter efficient tuning of pre-trained models using dynamic search-free low-rank adaptation},
  author={Valipour, Mojtaba and Rezagholizadeh, Mehdi and Kobyzev, Ivan and Ghodsi, Ali},
  journal={arXiv preprint arXiv:2210.07558},
  year={2022}
}

@inproceedings{DBLP:conf/acl/LiL20,
  author       = {Xiang Lisa Li and
                  Percy Liang},
  title        = {Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  booktitle    = {{ACL/IJCNLP}},
  pages        = {4582--4597},
  year         = {2021}
}

@inproceedings{tran2019transferability,
  title={Transferability and hardness of supervised classification tasks},
  author    = {Anh Tuan Tran and
               Cuong V. Nguyen and
               Tal Hassner},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{zamir2018taskonomy,
  title={Taskonomy: Disentangling task transfer learning},
  author={Zamir, Amir R and Sax, Alexander and Shen, William and Guibas, Leonidas J and Malik, Jitendra and Savarese, Silvio},
  booktitle={CVPR},
  year={2018}
}


@article{mmlu,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@article{mbpp,
  title={Program synthesis with large language models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021}
}

@article{cmmlu,
  title={{CMMLU}: Measuring massive multitask language understanding in {Chinese}},
  author={Li, Haonan and Zhang, Yixuan and Koto, Fajri and Yang, Yifei and Zhao, Hai and Gong, Yeyun and Duan, Nan and Baldwin, Timothy},
  journal={arXiv preprint arXiv:2306.09212},
  year={2023}
}

@article{ceval,
  title={{C-Eval}: A multi-level multi-discipline chinese evaluation suite for foundation models},
  author={Huang, Yuzhen and Bai, Yuzhuo and Zhu, Zhihao and Zhang, Junlei and Zhang, Jinghan and Su, Tangjun and Liu, Junteng and Lv, Chuancheng and Zhang, Yikai and Lei, Jiayi and others},
  journal={arXiv preprint arXiv:2305.08322},
  year={2023}
}


@inproceedings{ocnli,
  author       = {Hai Hu and
                  Kyle Richardson and
                  Liang Xu and
                  Lu Li and
                  Sandra K{\"{u}}bler and
                  Lawrence S. Moss},
  title        = {{OCNLI:} Original Chinese Natural Language Inference},
  booktitle    = {{EMNLP}},
  series       = {Findings of {ACL}},
  volume       = {{EMNLP} 2020},
  pages        = {3512--3526},
  year         = {2020}
}


@inproceedings{chid,
  author       = {Chujie Zheng and
                  Minlie Huang and
                  Aixin Sun},
  title        = {ChID: {A} Large-scale Chinese IDiom Dataset for Cloze Test},
  booktitle    = {{ACL}},
  pages        = {778--787},
  year         = {2019}
}


@inproceedings{race,
  author       = {Guokun Lai and
                  Qizhe Xie and
                  Hanxiao Liu and
                  Yiming Yang and
                  Eduard H. Hovy},
  title        = {{RACE:} Large-scale ReAding Comprehension Dataset From Examinations},
  booktitle    = {{EMNLP}},
  pages        = {785--794},
  year         = {2017}
}


@inproceedings{DBLP:conf/acl/BanerjeePMB19,
  author       = {Pratyay Banerjee and
                  Kuntal Kumar Pal and
                  Arindam Mitra and
                  Chitta Baral},
  title        = {Careful Selection of Knowledge to Solve Open Book Question Answering},
  booktitle    = {{ACL}},
  pages        = {6120--6129},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/p19-1615},
  doi          = {10.18653/V1/P19-1615},
  timestamp    = {Fri, 06 Aug 2021 00:41:04 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/BanerjeePMB19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/icdar/KimYSOOB23,
  author       = {Geewook Kim and
                  Shuhei Yokoo and
                  Sukmin Seo and
                  Atsuki Osanai and
                  Yamato Okamoto and
                  Youngmin Baek},
  title        = {On Text Localization in End-to-End OCR-Free Document Understanding
                  Transformer Without Text Localization Supervision},
  booktitle    = {{ICDAR}},
  series       = {Lecture Notes in Computer Science},
  volume       = {14193},
  pages        = {215--232},
  year         = {2023}
}

@article{DBLP:journals/corr/abs-2403-00231,
  author       = {Lei Li and
                  Yuqi Wang and
                  Runxin Xu and
                  Peiyi Wang and
                  Xiachong Feng and
                  Lingpeng Kong and
                  Qi Liu},
  title        = {Multimodal ArXiv: {A} Dataset for Improving Scientific Comprehension
                  of Large Vision-Language Models},
  journal      = {CoRR},
  volume       = {abs/2403.00231},
  year         = {2024}
}


@misc{sakaguchi2019winogrande,
      title={WinoGrande: An Adversarial Winograd Schema Challenge at Scale}, 
      author={Keisuke Sakaguchi and Ronan Le Bras and Chandra Bhagavatula and Yejin Choi},
      year={2019},
      eprint={1907.10641},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{arc,
  author       = {Peter Clark and
                  Isaac Cowhey and
                  Oren Etzioni and
                  Tushar Khot and
                  Ashish Sabharwal and
                  Carissa Schoenick and
                  Oyvind Tafjord},
  title        = {Think you have Solved Question Answering? Try ARC, the {AI2} Reasoning
                  Challenge},
  journal      = {CoRR},
  volume       = {abs/1803.05457},
  year         = {2018}
}


@inproceedings{clue,
  author       = {Liang Xu and
                  Hai Hu and
                  Xuanwei Zhang and
                  Lu Li and
                  Chenjie Cao and
                  Yudong Li and
                  Yechen Xu and
                  Kai Sun and
                  Dian Yu and
                  Cong Yu and
                  Yin Tian and
                  Qianqian Dong and
                  Weitang Liu and
                  Bo Shi and
                  Yiming Cui and
                  Junyi Li and
                  Jun Zeng and
                  Rongzhao Wang and
                  Weijian Xie and
                  Yanting Li and
                  Yina Patterson and
                  Zuoyu Tian and
                  Yiwen Zhang and
                  He Zhou and
                  Shaoweihua Liu and
                  Zhe Zhao and
                  Qipeng Zhao and
                  Cong Yue and
                  Xinrui Zhang and
                  Zhengliang Yang and
                  Kyle Richardson and
                  Zhenzhong Lan},
  title        = {{CLUE:} {A} Chinese Language Understanding Evaluation Benchmark},
  booktitle    = {{COLING}},
  pages        = {4762--4772},
  year         = {2020}
}



@article{gsm8k,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}


@inproceedings{hellaswag,
  author       = {Rowan Zellers and
                  Ari Holtzman and
                  Yonatan Bisk and
                  Ali Farhadi and
                  Yejin Choi},
  title        = {{HellaSwag}: Can a Machine Really Finish Your Sentence?},
  booktitle    = {{ACL}},
  pages        = {4791--4800},
  year         = {2019}
}

@inproceedings{piqa,
  author       = {Yonatan Bisk and
                  Rowan Zellers and
                  Ronan Le Bras and
                  Jianfeng Gao and
                  Yejin Choi},
  title        = {{PIQA:} Reasoning about Physical Commonsense in Natural Language},
  booktitle    = {{AAAI}},
  pages        = {7432--7439},
  year         = {2020}
}



@article{siqa,
  author       = {Maarten Sap and
                  Hannah Rashkin and
                  Derek Chen and
                  Ronan Le Bras and
                  Yejin Choi},
  title        = {{SocialIQA}: Commonsense Reasoning about Social Interactions},
  journal      = {CoRR},
  volume       = {abs/1904.09728},
  year         = {2019}
}



@inproceedings{boolq,
  author       = {Christopher Clark and
                  Kenton Lee and
                  Ming{-}Wei Chang and
                  Tom Kwiatkowski and
                  Michael Collins and
                  Kristina Toutanova},
  title        = {BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions},
  booktitle    = {{ACL}},
  pages        = {2924--2936},
  year         = {2019}
}



@inproceedings{commonsenseqa,
  author       = {Alon Talmor and
                  Jonathan Herzig and
                  Nicholas Lourie and
                  Jonathan Berant},
  title        = {{CommonsenseQA}: {A} Question Answering Challenge Targeting Commonsense
                  Knowledge},
  booktitle    = {{ACL}},
  pages        = {4149--4158},
  year         = {2019}
}

@article{naturalquestions,
  author       = {Tom Kwiatkowski and
                  Jennimaria Palomaki and
                  Olivia Redfield and
                  Michael Collins and
                  Ankur P. Parikh and
                  Chris Alberti and
                  Danielle Epstein and
                  Illia Polosukhin and
                  Jacob Devlin and
                  Kenton Lee and
                  Kristina Toutanova and
                  Llion Jones and
                  Matthew Kelcey and
                  Ming{-}Wei Chang and
                  Andrew M. Dai and
                  Jakob Uszkoreit and
                  Quoc Le and
                  Slav Petrov},
  title        = {Natural Questions: a Benchmark for Question Answering Research},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {7},
  pages        = {452--466},
  year         = {2019}
}



@inproceedings{achille2019task2vec,
  title={Task2vec: Task embedding for meta-learning},
  author={Achille, Alessandro and Lam, Michael and Tewari, Rahul and Ravichandran, Avinash and Maji, Subhransu and Fowlkes, Charless C and Soatto, Stefano and Perona, Pietro},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{bao2019information,
  title={An Information-Theoretic Approach to Transferability in Task Transfer Learning},
  author={Bao, Yajie and Li, Yang and Huang, Shao-Lun and Zhang, Lin and Zheng, Lizhong and Zamir, Amir and Guibas, Leonidas},
  booktitle={ICIP},
  year={2019}
}

@inproceedings{song2020depara,
  title={DEPARA: Deep Attribution Graph for Deep Knowledge Transferability},
  author={Song, Jie and Chen, Yixin and Ye, Jingwen and Wang, Xinchao and Shen, Chengchao and Mao, Feng and Song, Mingli},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{neyshabur2020being,
  title={What is being transferred in transfer learning?},
  author={Neyshabur, Behnam and Sedghi, Hanie and Zhang, Chiyuan},
  booktitle={NeurIPS},
  year={2020}
}

@article{pan2009survey,
  title={A survey on transfer learning},
  author={Pan, Sinno Jialin and Yang, Qiang},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={22},
  number={10},
  year={2009}
}

@inproceedings{sharif2014cnn,
  title={CNN features off-the-shelf: an astounding baseline for recognition},
  author={Sharif Razavian, Ali and Azizpour, Hossein and Sullivan, Josephine and Carlsson, Stefan},
  booktitle={CVPR Workshops},
  year={2014}
}

@article{azizpour2015factors,
  title={Factors of transferability for a generic convnet representation},
  author={Azizpour, Hossein and Razavian, Ali Sharif and Sullivan, Josephine and Maki, Atsuto and Carlsson, Stefan},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={38},
  number={9},
  year={2015}
}

@inproceedings{yosinski2014transferable,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  booktitle={NIPS},
  year={2014}
}

@article{qin2019rethinking,
  title={Rethinking softmax with cross-entropy: Neural network classifier as mutual information estimator},
  author={Qin, Zhenyue and Kim, Dongwoo and Gedeon, Tom},
  journal   = {CoRR},
  volume    = {abs/1911.10688},
  year      = {2019}
}

@inproceedings{wang2019characterizing,
  title={Characterizing and avoiding negative transfer},
  author={Wang, Zirui and Dai, Zihang and P{\'o}czos, Barnab{\'a}s and Carbonell, Jaime},
  booktitle={CVPR},
  year={2019}
}

@article{zhang2020overcoming,
  title={Overcoming Negative Transfer: A Survey},
  author={Zhang, Wen and Deng, Lingfei and Wu, Dongrui},
  journal   = {CoRR},
  volume    = {abs/2009.00909},
  year      = {2020}
}

@article{weiss2016survey,
  title={A survey of transfer learning},
  author={Weiss, Karl and Khoshgoftaar, Taghi M and Wang, DingDing},
  journal={Journal of Big data},
  volume={3},
  number={1},
  year={2016}
}

@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International Journal of Computer Vision},
  volume={115},
  number={3},
  year={2015}
}


@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  year={2016}
}

@article{bousquet2002stability,
  title={Stability and generalization},
  author={Bousquet, Olivier and Elisseeff, Andr{\'e}},
  journal={J. Mach. Learn. Res.},
  volume={2},
  year={2002}
}

@inproceedings{li2021ranking,
  title={Ranking neural checkpoints},
  author={Li, Yandong and Jia, Xuhui and Sang, Ruoxin and Zhu, Yukun and Green, Bradley and Wang, Liqiang and Gong, Boqing},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{DBLP:conf/cvpr/TanLH21,
  author    = {Yang Tan and
               Yang Li and
               Shao-Lun Huang},
  title     = {{OTCE}: A Transferability Metric for Cross-Domain Cross-Task Representations},
  booktitle = {CVPR},
  year      = {2021}
}

@inproceedings{tong2021mathematical,
  title={A Mathematical Framework for Quantifying Transferability in Multi-source Transfer Learning},
  author={Tong, Xinyi and Xu, Xiangxiang and Huang, Shao-Lun and Zheng, Lizhong},
  journal={NeurIPS},
  year={2021}
}

@inproceedings{grill2020bootstrap,
  author    = {Jean-Bastien Grill and
               Florian Strub and
               Florent Altch{\'{e}} and
               Corentin Tallec and
               Pierre H. Richemond and
               Elena Buchatskaya and
               Carl Doersch and
               Bernardo {\'{A}}vila Pires and
               Zhaohan Guo and
               Mohammad Gheshlaghi Azar and
               Bilal Piot and
               Koray Kavukcuoglu and
               R{\'{e}}mi Munos and
               Michal Valko},
  title     = {Bootstrap Your Own Latent - {A} New Approach to Self-Supervised Learning},
  booktitle = {NeurIPS},
  year      = {2020}
}

@inproceedings{DBLP:conf/cvpr/PandyAUFM22,
  author    = {Michal P{\'{a}}ndy and
               Andrea Agostinelli and
               Jasper R. R. Uijlings and
               Vittorio Ferrari and
               Thomas Mensink},
  title     = {Transferability Estimation using Bhattacharyya Class Separability},
  booktitle = {CVPR},
  year      = {2022}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={ICML},
  year={2020}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={NIPS},
  year={2012}
}


@article{vaart1997weak,
  title={Weak convergence and empirical processes with applications to statistics},
  author={Vaart, AW van der and Wellner, Jon A},
  journal={Journal of the Royal Statistical Society},
  volume={160},
  number={3},
  year={1997}
}

@inproceedings{berg2014birdsnap,
  title={Birdsnap: Large-scale fine-grained visual categorization of birds},
  author={Berg, Thomas and Liu, Jiongxin and Woo Lee, Seung and Alexander, Michelle L and Jacobs, David W and Belhumeur, Peter N},
  booktitle={CVPR},
  year={2014}
}

@inproceedings{fei2004caltech101,
  title={Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories},
  author={Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
  booktitle={CVPR Workshops},
  year={2004}
}

@article{griffin2007caltech256,
  title={Caltech-256 object category dataset},
  author={Griffin, Gregory and Holub, Alex and Perona, Pietro},
  journal={California Institute of Technology},
  volume={6},
  year={2007}
}

@inproceedings{cimpoi2014dtd,
  title={Describing textures in the wild},
  author={Cimpoi, Mircea and Maji, Subhransu and Kokkinos, Iasonas and Mohamed, Sammy and Vedaldi, Andrea},
  booktitle={CVPR},
  year={2014}
}

@article{maji2013aircraft,
  title={Fine-grained visual classification of aircraft},
  author={Maji, Subhransu and Rahtu, Esa and Kannala, Juho and Blaschko, Matthew and Vedaldi, Andrea},
  journal   = {CoRR},
  volume    = {abs/1306.5151},
  year      = {2013}
}

@inproceedings{bossard2014food,
  title={Food-101--mining discriminative components with random forests},
  author={Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
  booktitle={ECCV},
  year={2014}
}

@inproceedings{nilsback2008flowers,
  title={Automated flower classification over a large number of classes},
  author={Nilsback, Maria-Elena and Zisserman, Andrew},
  booktitle={ICVGIP},
  year={2008}
}

@inproceedings{parkhi2012cats,
  author    = {Omkar M. Parkhi and
               Andrea Vedaldi and
               Andrew Zisserman and
               C. V. Jawahar},
  title     = {Cats and dogs},
  booktitle={CVPR},
  year={2012}
}

@inproceedings{xiao2010sun,
  title={Sun database: Large-scale scene recognition from abbey to zoo},
  author={Xiao, Jianxiong and Hays, James and Ehinger, Krista A and Oliva, Aude and Torralba, Antonio},
  booktitle={CVPR},
  year={2010}
}

@inproceedings{KrauseStarkDengFei-Fei_3DRR2013,
  title = {3D Object Representations for Fine-Grained Categorization},
  booktitle = {4th International IEEE Workshop on 3D Representation and Recognition (3dRR-13)},
  year = {2013},
  author = {Jonathan Krause and Michael Stark and Jia Deng and Li Fei-Fei}
}


@inproceedings{benoit_pytorch:_2019,
  title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  booktitle = {NeurIPS},
  author = {Benoit, Steiner and Zachary, DeVito and Soumith, Chintala and Sam, Gross and Adam, Paszke and Francisco, Massa and Adam, Lerer and Gregory, Chanan and Zeming, Lin and Edward, Yang and Alban, Desmaison and Alykhan, Tejani and Andreas, Kopf and James, Bradbury and Luca, Antiga and Martin, Raison and Natalia, Gimelshein and Sasank, Chilamkurthy and Trevor, Killeen and Lu, Fang and Junjie, Bai},
  year={2019}
}

@inproceedings{abadi_tensorflow:_2016,
  title = {Tensorflow: a system for large-scale machine learning},
  booktitle = {OSDI},
  author = {Abadi, Martín and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael},
  year = {2016}
}

@inproceedings{wolf_transformers:_2020,
  title = {Transformers: State-of-the-art natural language processing},
  booktitle = {EMNLP},
  author = {Wolf, Thomas and Chaumond, Julien and Debut, Lysandre and Sanh, Victor and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam},
  year = {2020}
}

@manual{tfhub,
  title  = "TensorFlow Hub",
  author = "Google",
  url    = "https://tfhub.dev/",
  year = 2018
}

@manual{pytorch-hub,
  title  = "PyTorch Hub",
  author = "FAIR",
  url    = "https://pytorch.org/hub/",
  year = 2019
}

@book{bishop_pattern_2006,
  title = {Pattern Recognition and Machine Learning},
  author = {Bishop, Christopher M.},
  year = {2006},
  address={New York}
}

@inproceedings{ding2022pretrained,
    title={Pre-Trained Model Reusability Evaluation for Small-Data Transfer Learning},
    author={Yao-Xiang Ding and Xi-Zhu Wu and Kun Zhou and Zhi-Hua Zhou},
    booktitle={NeurIPS},
    year={2022}
}

@inproceedings{Enric2022GULP,
  author    = {Enric Boix Adser{\`{a}} and
               Hannah Lawrence and
               George Stepaniants and
               Philippe Rigollet},
  title     = {{GULP:} a prediction-based metric between representations},
  booktitle={NeurIPS},
  year={2022}
}

@article{DBLP:journals/tkde/WuXLZ23,
  author    = {Xi-Zhu Wu and
               Wenkai Xu and
               Song Liu and
               Zhi-Hua Zhou},
  title     = {Model Reuse With Reduced Kernel Mean Embedding Specification},
  journal   = {IEEE Transactions on Knowledge and Data Engineering},
  volume    = {35},
  number    = {1},
}

@inproceedings{DBLP:conf/acml/DingZ20,
  author    = {Yao-Xiang Ding and
               Zhi-Hua Zhou},
  title     = {Boosting-Based Reliable Model Reuse},
  booktitle = {ACML},
  year      = {2020}
}

@article{Zhou16a,
  author    = {Zhi-Hua Zhou},
  title     = {Learnware: on the future of machine learning},
  journal   = {Frontiers Computer Science},
  volume    = {10},
  number    = {4},
  year      = {2016}
}

@inproceedings{DBLP:conf/nips/HuangQC21,
  author    = {Jiaji Huang and
               Qiang Qiu and
               Kenneth Church},
  title     = {Exploiting a Zoo of Checkpoints for Unseen Tasks},
  booktitle = {NeurIPS},
  year      = {2021}
}

@inproceedings{DBLP:conf/nips/SongCWSS19,
  author    = {Jie Song and
               Yixin Chen and
               Xinchao Wang and
               Chengchao Shen and
               Mingli Song},
  title     = {Deep Model Transferability from Attribution Maps},
  booktitle = {NeurIPS},
  year      = {2019}
}

@inproceedings{DBLP:conf/eccv/DingCLCS22,
  author    = {Nan Ding and
               Xi Chen and
               Tomer Levinboim and
               Soravit Changpinyo and
               Radu Soricut},
  title     = {PACTran: PAC-Bayesian Metrics for Estimating the Transferability of
               Pretrained Models to Classification Tasks},
  booktitle = {ECCV},
  year      = {2022}
}

@inproceedings{DBLP:conf/icml/HuangHRY022,
  author    = {Long-Kai Huang and
               Junzhou Huang and
               Yu Rong and
               Qiang Yang and
               Ying Wei},
  title     = {Frustratingly Easy Transferability Estimation},
  booktitle = {ICML},
  year      = {2022}
}

@inproceedings{DBLP:conf/nips/Alvarez-MelisF20,
  author    = {David Alvarez-Melis and
               Nicol{\`{o}} Fusi},
  title     = {Geometric Dataset Distances via Optimal Transport},
  booktitle = {NeurIPS},
  year      = {2020}
}

@inproceedings{
dong2022zood,
title={ZooD: Exploiting Model Zoo for Out-of-Distribution Generalization},
author={Qishi Dong and Muhammad Awais and Fengwei Zhou and Chuanlong Xie and Tianyang Hu and Yongxin Yang and Sung-Ho Bae and Zhenguo Li},
booktitle={NeurIPS},
year={2022}
}

@article{you2022ranking,
  title={Ranking and Tuning Pre-trained Models: A New Paradigm for Exploiting Model Hubs},
  author={You, Kaichao and Liu, Yong and Zhang, Ziyang and Wang, Jianmin and Jordan, Michael I and Long, Mingsheng},
  journal={J. Mach. Learn. Res.},
  volume={23},
  year={2022}
}

@inproceedings{ben-david_exploiting_2003,
  title = {Exploiting task relatedness for multiple task learning},
  booktitle = {COLT},
  author = {Ben-David, Shai and Schuller, Reba},
  year = {2003}
}

@inproceedings{DBLP:conf/nips/Ben-DavidBCP06,
  author    = {Shai Ben-David and
               John Blitzer and
               Koby Crammer and
               Fernando Pereira},
  title     = {Analysis of Representations for Domain Adaptation},
  booktitle = {NIPS},
  year      = {2006}
}

@inproceedings{rosenstein2005transfer,
  title={To transfer or not to transfer},
  author={Rosenstein, Michael T and Marx, Zvika and Kaelbling, Leslie Pack and Dietterich, Thomas G},
  booktitle={NIPS Workshop on Transfer Learning},
  volume={898},
  year={2005}
}

@techreport{krizhevsky_learning_2009,
    title = {Learning multiple layers of features from tiny images},
	author = {Krizhevsky, Alex and Hinton, Geoffrey},
	year = {2009}
}

@article{KonidarisSB12,
  author    = {George Dimitri Konidaris and
               Ilya Scheidwasser and
               Andrew G. Barto},
  title     = {Transfer in Reinforcement Learning via Shared Features},
  journal   = {J. Mach. Learn. Res.},
  volume    = {13},
  year      = {2012}
}


@techreport{WahCUB_200_2011,
	Title = {{The Caltech-UCSD Birds-200-2011 Dataset}},
	Author = {Wah, C. and Branson, S. and Welinder, P. and Perona, P. and Belongie, S.},
	Year = {2011},
	Institution = {California Institute of Technology},
	Number = {CNS-TR-2011-001}
}

@inproceedings{DBLP:conf/cvpr/HornBFHBIPB15,
  author    = {Grant Van Horn and
               Steve Branson and
               Ryan Farrell and
               Scott Haber and
               Jessie Barry and
               Panos Ipeirotis and
               Pietro Perona and
               Serge J. Belongie},
  title     = {Building a bird recognition app and large scale dataset with citizen
               scientists: The fine print in fine-grained dataset collection},
  booktitle = {CVPR},
  year      = {2015}
}

@article{DBLP:journals/corr/abs-2009-07888,
  author    = {Zhuangdi Zhu and
               Kaixiang Lin and
               Jiayu Zhou},
  title     = {Transfer Learning in Deep Reinforcement Learning: {A} Survey},
  journal   = {CoRR},
  volume    = {abs/2009.07888},
  year      = {2020}
}

@inproceedings{szegedy_rethinking_2016,
	title = {Rethinking the {Inception} {Architecture} for {Computer} {Vision}},
	booktitle = {{CVPR}},
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	year = {2016}
}

@inproceedings{huang_densely_2017,
	title = {Densely connected convolutional networks},
	booktitle = {{CVPR}},
	author = {Huang, Gao and Liu, Zhuang and Weinberger, Kilian Q. and van der Maaten, Laurens},
	year = {2017}
}

@inproceedings{sandler_mobilenetv2:_2018,
	title = {{MobileNetV}2: inverted residuals and linear bottlenecks},
	booktitle = {{CVPR}},
	author = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
	year = {2018}
}


@inproceedings{tan_mnasnet:_2019,
	title = {Mnasnet: {Platform}-aware neural architecture search for mobile},
	booktitle = {{CVPR}},
	author = {Tan, Mingxing and Chen, Bo and Pang, Ruoming and Vasudevan, Vijay and Sandler, Mark and Howard, Andrew and Le, Quoc V.},
	year = {2019}
}

@inproceedings{DBLP:conf/nips/VaswaniSPUJGKP17,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention is All you Need},
  booktitle = {NeurIPS},
  year      = {2017}
}


@inproceedings{CoatesNL11,
  author    = {Adam Coates and
               Andrew Y. Ng and
               Honglak Lee},
  title     = {An Analysis of Single-Layer Networks in Unsupervised Feature Learning},
  booktitle = {AISTATS},
  year      = {2011}
}

@inproceedings{khosla2011novel,
  title={Novel dataset for fine-grained image categorization: Stanford dogs},
  author={Khosla, Aditya and Jayadevaprakash, Nityananda and Yao, Bangpeng and Li, Fei-Fei},
  booktitle={CVPR workshop on FGVC},
  volume={2},
  year={2011},
}

@article{helber2019eurosat,
  title={Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification},
  author={Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and Borth, Damian},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  year={2019},
}

@inproceedings{DBLP:conf/cvpr/LeCunHB04,
  author    = {Yann LeCun and
               Fu Jie Huang and
               L{\'{e}}on Bottou},
  title     = {Learning Methods for Generic Object Recognition with Invariance to
               Pose and Lighting},
  booktitle = {CVPR},
  year      = {2004}
}

@inproceedings{netzer2011reading,
title	= {Reading Digits in Natural Images with Unsupervised Feature Learning},
author	= {Yuval Netzer and Tao Wang and Adam Coates and Alessandro Bissacco and Bo Wu and Andrew Y. Ng},
year	= {2011},
booktitle	= {NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011}
}

@article{DBLP:journals/pieee/ChengHL17,
  author    = {Gong Cheng and
               Junwei Han and
               Xiaoqiang Lu},
  title     = {Remote Sensing Image Scene Classification: Benchmark and State of
               the Art},
  journal   = {Proceedings of IEEE},
  volume    = {105},
  number    = {10},
  year      = {2017}
}

@article{DBLP:journals/corr/XiaHHSBZZ16,
  author    = {Gui-Song Xia and
               Jingwen Hu and
               Fan Hu and
               Baoguang Shi and
               Xiang Bai and
               Yanfei Zhong and
               Liangpei Zhang},
  title     = {AID: A Benchmark Dataset for Performance Evaluation of Aerial
               Scene Classification},
  journal   = {CoRR},
  volume    = {abs/1608.05167},
  year      = {2016}
}

@inproceedings{DBLP:conf/iccv/LiYSH17,
  author    = {Da Li and
               Yongxin Yang and
               Yi-Zhe Song and
               Timothy M. Hospedales},
  title     = {Deeper, Broader and Artier Domain Generalization},
  booktitle = {ICCV},
  year      = {2017}

}

@inproceedings{DBLP:conf/iccv/FangXR13,
  author    = {Chen Fang and
               Ye Xu and
               Daniel N. Rockmore},
  title     = {Unbiased Metric Learning: On the Utilization of Multiple Datasets
               and Web Images for Softening Bias},
  booktitle = {ICCV},
  year      = {2013}
}

@inproceedings{DBLP:journals/corr/KingmaB14,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {ICLR},
  year      = {2015}
}

@inproceedings{DBLP:conf/eccv/AgostinelliPUMF22,
  author    = {Andrea Agostinelli and
               Michal P{\'{a}}ndy and
               Jasper R. R. Uijlings and
               Thomas Mensink and
               Vittorio Ferrari},
  title     = {How Stable Are Transferability Metrics Evaluations?},
  booktitle = {ECCV},
  year      = {2022}
}

@inproceedings{DBLP:conf/cvpr/RenggliPRPR0L22,
  author    = {C{\'{e}}dric Renggli and
               Andr{\'{e}} Susano Pinto and
               Luka Rimanic and
               Joan Puigcerver and
               Carlos Riquelme and
               Ce Zhang and
               Mario Lucic},
  title     = {Which Model to Transfer? Finding the Needle in the Growing Haystack},
  booktitle = {CVPR},
  year      = {2022}
}

@article{DBLP:journals/corr/abs-2110-06893,
  author    = {Shibal Ibrahim and
               Natalia Ponomareva and
               Rahul Mazumder},
  title     = {Newer is not always better: Rethinking transferability metrics, their
               peculiarities, stability and performance},
  journal   = {CoRR},
  volume    = {abs/2110.06893},
  year      = {2021}
}

@inproceedings{DBLP:conf/nips/BolyaMH21,
  author    = {Daniel Bolya and
               Rohit Mittapalli and
               Judy Hoffman},
  title     = {Scalable Diverse Model Selection for Accessible Transfer Learning},
  booktitle = {NeurIPS 2021},
  year      = {2021}
}


@InProceedings{pmlr-v80-wei18a,
  title = 	 {Transfer Learning via Learning to Transfer},
  author =       {Wei, Ying and Zhang, Yu and Huang, Junzhou and Yang, Qiang},
  booktitle = 	 {ICML},
  year = 	 {2018}
}

@inproceedings{mansour2009domain,
  title={Domain adaptation: Learning bounds and algorithms},
  author={Mansour, Yishay and Mohri, Mehryar and Rostamizadeh, Afshin},
  booktitle={COLT},
  year={2009}
}

@inproceedings{JiaTCCBHL22,
  author    = {Menglin Jia and
               Luming Tang and
               Bor-Chun Chen and
               Claire Cardie and
               Serge J. Belongie and
               Bharath Hariharan and
               Ser-Nam Lim},
  title     = {Visual Prompt Tuning},
  booktitle = {ECCV},
  year      = {2022}
}

@inproceedings{Bao0PW22,
  author    = {Hangbo Bao and
               Li Dong and
               Songhao Piao and
               Furu Wei},
  title     = {BEiT: {BERT} Pre-Training of Image Transformers},
  booktitle = {ICLR},
  year      = {2022}
}

@inproceedings{DevlinCLT19,
  author    = {Jacob Devlin and
               Ming-Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  booktitle = {NAACL-HLT},
  year      = {2019},
}

@inproceedings{RadfordKHRGASAM21,
  author    = {Alec Radford and
               Jong Wook Kim and
               Chris Hallacy and
               Aditya Ramesh and
               Gabriel Goh and
               Sandhini Agarwal and
               Girish Sastry and
               Amanda Askell and
               Pamela Mishkin and
               Jack Clark and
               Gretchen Krueger and
               Ilya Sutskever},
  title     = {Learning Transferable Visual Models From Natural Language Supervision},
  booktitle = {ICML},
  year      = {2021}
}

@inproceedings{WolfDSCDMCRLFDS20,
  author    = {Thomas Wolf and
               Lysandre Debut and
               Victor Sanh and
               Julien Chaumond and
               Clement Delangue and
               Anthony Moi and
               Pierric Cistac and
               Tim Rault and
               R{\'{e}}mi Louf and
               Morgan Funtowicz and
               Joe Davison and
               Sam Shleifer and
               Patrick von Platen and
               Clara Ma and
               Yacine Jernite and
               Julien Plu and
               Canwen Xu and
               Teven Le Scao and
               Sylvain Gugger and
               Mariama Drame and
               Quentin Lhoest and
               Alexander M. Rush},
  title     = {Transformers: State-of-the-Art Natural Language Processing},
  booktitle = {EMNLP},
  year      = {2020}
}

@inproceedings{DBLP:conf/eccv/DwivediHCR20,
  author    = {Kshitij Dwivedi and
               Jiahui Huang and
               Radoslaw Martin Cichy and
               Gemma Roig},
  title     = {Duality Diagram Similarity: {A} Generic Framework for Initialization
               Selection in Task Transfer Learning},
  booktitle = {ECCV},
  year      = {2020}
}

@inproceedings{DBLP:conf/mm/JouC16,
  author    = {Brendan Jou and
               Shih-Fu Chang},
  title     = {Deep Cross Residual Learning for Multitask Visual Recognition},
  booktitle = {ACM MM},
  year      = {2016}
}

@article{DBLP:journals/pami/RanjanPC19,
  author    = {Rajeev Ranjan and
               Vishal M. Patel and
               Rama Chellappa},
  title     = {HyperFace: {A} Deep Multi-Task Learning Framework for Face Detection,
               Landmark Localization, Pose Estimation, and Gender Recognition},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume    = {41},
  number    = {1},
  year      = {2019}
}

@inproceedings{DBLP:conf/cvpr/KornblithSL19,
  author    = {Simon Kornblith and
               Jonathon Shlens and
               Quoc V. Le},
  title     = {Do Better ImageNet Models Transfer Better?},
  booktitle = {CVPR},
  year      = {2019}
}

@inproceedings{huh16neurips,
  author  = {Huh, M. and Agrawal, P. and Efros, A.A.},
  title   = {What makes ImageNet good for transfer learning?},
  year    = {2016},
  booktitle = {NIPS LSCVS workshop},
}

@article{kriegeskorte_2008,
  year = {2008},
  author = {Nikolaus Kriegeskorte},
  title = {Representational similarity analysis {\textendash} connecting the branches of systems neuroscience},
  journal = {Frontiers in Systems Neuroscience}
}

@inproceedings{DBLP:conf/corl/JamesBD18,
  author    = {Stephen James and
               Michael Bloesch and
               Andrew J. Davison},
  title     = {Task-Embedded Control Networks for Few-Shot Imitation Learning},
  booktitle = {CoRL},
  year      = {2018}
}

@inproceedings{DBLP:conf/ijcai/LanLGW19,
  author    = {Lin Lan and
               Zhenguo Li and
               Xiaohong Guan and
               Pinghui Wang},
  title     = {Meta Reinforcement Learning with Task Embedding and Shared Policy},
  booktitle = {IJCAI},
  year      = {2019}
}


@inproceedings{kornblith2019similarity,
  title={Similarity of neural network representations revisited},
  author={Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
  booktitle={ICML},
  year={2019}
}

@article{Zhou2022Learnware,
  author    = {Zhi-Hua Zhou and
               Zhi-Hao Tan},
  title     = {Learnware: Small Models Do Big},
  journal   = {CoRR},
  volume    = {abs/2210.03647},
  year      = {2022}
}

@inproceedings{Cakir0XKS19,
  author    = {Fatih {\c{C}}akir and
               Kun He and
               Xide Xia and
               Brian Kulis and
               Stan Sclaroff},
  title     = {Deep Metric Learning to Rank},
  booktitle = {CVPR},
  year      = {2019}
}

@inproceedings{McFeeL10,
  author    = {Brian McFee and
               Gert R. G. Lanckriet},
  title     = {Metric Learning to Rank},
  booktitle = {ICML},
  year      = {2010}
}

@article{AilonM10,
  author    = {Nir Ailon and
               Mehryar Mohri},
  title     = {Preference-based learning to rank},
  journal   = {Machine Learning},
  volume    = {80},
  number    = {2-3},
  year      = {2010}
}

@book{Mohri2012Foundations,
  author    = {Mehryar Mohri and
               Afshin Rostamizadeh and
               Ameet Talwalkar},
  title     = {Foundations of Machine Learning},
  series    = {Adaptive computation and machine learning},
  year      = {2012}
}

@inproceedings{Joachims02Optimizing,
  author    = {Thorsten Joachims},
  title     = {Optimizing search engines using clickthrough data},
  booktitle = {SIGKDD},
  year      = {2002},
}

@inproceedings{DBLP:conf/iclr/LiYZGXDYG22,
  author    = {Chunyuan Li and
               Jianwei Yang and
               Pengchuan Zhang and
               Mei Gao and
               Bin Xiao and
               Xiyang Dai and
               Lu Yuan and
               Jianfeng Gao},
  title     = {Efficient Self-supervised Vision Transformers for Representation Learning},
  booktitle = {ICLR},
  year      = {2022}
}

@article{copeland1,
  author    = {Ann Arbor},
  title     = {A Reasonable Social Welfare Function},
  journal   = {Seminar on Applications of Mathematics to Social Sciences},
  year      = {1951}
}

@article{copeland2,
  author    = {Saari and Donald G. and Vincent R. Merlin},
  title     = {The Copeland Method: I.: Relationships and the Dictionary},
  journal   = {Economic Theory},
  volume    = {8},
  number    = {1},
  year      = {1996}
}

@inproceedings{DBLP:conf/eccv/ShaoZGZYWSL22,
  author    = {Wenqi Shao and
               Xun Zhao and
               Yixiao Ge and
               Zhaoyang Zhang and
               Lei Yang and
               Xiaogang Wang and
               Ying Shan and
               Ping Luo},
  title     = {Not All Models Are Equal: Predicting Model Transferability in a Self-challenging
               Fisher Space},
  booktitle = {ECCV},
  year      = {2022}
}


@inproceedings{ZaheerKRPSS17,
  author    = {Manzil Zaheer and
               Satwik Kottur and
               Siamak Ravanbakhsh and
               Barnab{\'{a}}s P{\'{o}}czos and
               Ruslan Salakhutdinov and
               Alexander J. Smola},
  title     = {Deep Sets},
  booktitle = {NIPS},
  year      = {2017}
}

@inproceedings{Maurer16,
  author    = {Andreas Maurer},
  title     = {A Vector-Contraction Inequality for Rademacher Complexities},
  booktitle = {ALT},
  year      = {2016}
}

@article{MaurerPR16,
  author    = {Andreas Maurer and
               Massimiliano Pontil and
               Bernardino Romera-Paredes},
  title     = {The Benefit of Multitask Representation Learning},
  journal   = {J. Mach. Learn. Res.},
  volume    = {17},
  year      = {2016}
}

@article{Maurer09,
  author    = {Andreas Maurer},
  title     = {Transfer bounds for linear feature learning},
  journal   = {Machine Learnine},
  volume    = {75},
  number    = {3},
  year      = {2009}
}

@article{DBLP:journals/corr/abs-2211-16299,
  author    = {Huiyan Qi and
               Lechao Cheng and
               Jingjing Chen and
               Yue Yu and
               Zunlei Feng and
               Yu-Gang Jiang},
  title     = {Transferability Estimation Based On Principal Gradient Expectation},
  journal   = {CoRR},
  volume    = {abs/2211.16299},
  year      = {2022}
}

@inproceedings{DBLP:conf/cvpr/VenkateswaraECP17,
  author    = {Hemanth Venkateswara and
               Jose Eusebio and
               Shayok Chakraborty and
               Sethuraman Panchanathan},
  title     = {Deep Hashing Network for Unsupervised Domain Adaptation},
  booktitle = {CVPR},
  year      = {2017}
}

@misc{dsprites17,
    author = {Loic Matthey and Irina Higgins and Demis Hassabis and Alexander Lerchner},
    title = {dSprites: Disentanglement testing Sprites dataset},
    howpublished= {https://github.com/deepmind/dsprites-dataset/},
    year = {2017},
}

@misc{chroma,
    author = {Chroma Group},
    title = {Chroma - the open-source embedding database.},
    howpublished= {https://github.com/chroma-core/chroma},
    year = {2017},
}

@inproceedings{DBLP:conf/iccv/LiuL00W0LG21,
  author       = {Ze Liu and
                  Yutong Lin and
                  Yue Cao and
                  Han Hu and
                  Yixuan Wei and
                  Zheng Zhang and
                  Stephen Lin and
                  Baining Guo},
  title        = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  booktitle    = {{ICCV}},
  year         = {2021}
}

@article{DBLP:journals/corr/abs-1910-04867,
  author       = {Xiaohua Zhai and
                  Joan Puigcerver and
                  Alexander Kolesnikov and
                  Pierre Ruyssen and
                  Carlos Riquelme and
                  Mario Lucic and
                  Josip Djolonga and
                  Andr{\'{e}} Susano Pinto and
                  Maxim Neumann and
                  Alexey Dosovitskiy and
                  Lucas Beyer and
                  Olivier Bachem and
                  Michael Tschannen and
                  Marcin Michalski and
                  Olivier Bousquet and
                  Sylvain Gelly and
                  Neil Houlsby},
  title        = {The Visual Task Adaptation Benchmark},
  journal      = {CoRR},
  volume       = {abs/1910.04867},
  year         = {2019},
}

@inproceedings{DBLP:conf/icml/XiaLWZL08,
  author       = {Fen Xia and
                  Tie{-}Yan Liu and
                  Jue Wang and
                  Wensheng Zhang and
                  Hang Li},
  title        = {Listwise approach to learning to rank: theory and algorithm},
  booktitle    = {ICML},
  volume       = {307},
  year         = {2008},
}

@inproceedings{DBLP:conf/cvpr/ZhangSQ17,
  author       = {Zhifei Zhang and
                  Yang Song and
                  Hairong Qi},
  title        = {Age Progression/Regression by Conditional Adversarial Autoencoder},
  booktitle    = {{CVPR}},
  year         = {2017}
}

@inproceedings{DBLP:conf/cvpr/RebuffiKSL17,
  author       = {Sylvestre{-}Alvise Rebuffi and
                  Alexander Kolesnikov and
                  Georg Sperl and
                  Christoph H. Lampert},
  title        = {iCaRL: Incremental Classifier and Representation Learning},
  booktitle    = {{CVPR}},
  year         = {2017}
}

@Misc{peft,
  title =        {PEFT: State-of-the-art Parameter-Efficient Fine-Tuning methods},
  author =       {Sourab Mangrulkar and Sylvain Gugger and Lysandre Debut and Younes Belkada and Sayak Paul},
  howpublished = {\url{https://github.com/huggingface/peft}},
  year =         {2022}
}

@Misc{kd,
  title =        {Exploring knowledge distillation of Deep neural nets for efficient hardware solutions},
  author =       {Haitong Li},
  howpublished = {\url{https://github.com/haitongli/knowledge-distillation-pytorch}},
  year =         {2018}
}

@inproceedings{DBLP:conf/icml/WortsmanIGRLMNF22,
  author       = {Mitchell Wortsman and
                  Gabriel Ilharco and
                  Samir Yitzhak Gadre and
                  Rebecca Roelofs and
                  Raphael Gontijo Lopes and
                  Ari S. Morcos and
                  Hongseok Namkoong and
                  Ali Farhadi and
                  Yair Carmon and
                  Simon Kornblith and
                  Ludwig Schmidt},
  title        = {Model soups: averaging weights of multiple fine-tuned models improves
                  accuracy without increasing inference time},
  booktitle    = {ICML},
  volume       = {162},
  year         = {2022}
}

@article{zeng2022glm,
  title={Glm-130b: An open bilingual pre-trained model},
  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},
  journal={arXiv preprint arXiv:2210.02414},
  year={2022}
}

@misc{2023opencompass,
    title={OpenCompass: A Universal Evaluation Platform for Foundation Models},
    author={OpenCompass Contributors},
    howpublished = {\url{https://github.com/open-compass/opencompass}},
    year={2023}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@misc{yang2023baichuan,
      title={Baichuan 2: Open Large-scale Language Models}, 
      author={Aiyuan Yang and Bin Xiao and Bingning Wang and Borong Zhang and Ce Bian and Chao Yin and Chenxu Lv and Da Pan and Dian Wang and Dong Yan and Fan Yang and Fei Deng and Feng Wang and Feng Liu and Guangwei Ai and Guosheng Dong and Haizhou Zhao and Hang Xu and Haoze Sun and Hongda Zhang and Hui Liu and Jiaming Ji and Jian Xie and JunTao Dai and Kun Fang and Lei Su and Liang Song and Lifeng Liu and Liyun Ru and Luyao Ma and Mang Wang and Mickel Liu and MingAn Lin and Nuolan Nie and Peidong Guo and Ruiyang Sun and Tao Zhang and Tianpeng Li and Tianyu Li and Wei Cheng and Weipeng Chen and Xiangrong Zeng and Xiaochuan Wang and Xiaoxi Chen and Xin Men and Xin Yu and Xuehai Pan and Yanjun Shen and Yiding Wang and Yiyu Li and Youxin Jiang and Yuchen Gao and Yupeng Zhang and Zenan Zhou and Zhiying Wu},
      year={2023},
      eprint={2309.10305},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{2023internlm,
    title={InternLM: A Multilingual Language Model with Progressively Enhanced Capabilities},
    author={InternLM Team},
    howpublished = {\url{https://github.com/InternLM/InternLM}},
    year={2023}
}

@misc{zheng2023judging,
      title={Judging LLM-as-a-judge with MT-Bench and Chatbot Arena},
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric. P Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{qwen,
  title={Qwen Technical Report},
  author={Jinze Bai and Shuai Bai and Yunfei Chu and Zeyu Cui and Kai Dang and Xiaodong Deng and Yang Fan and Wenbin Ge and Yu Han and Fei Huang and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}

@inproceedings{DBLP:conf/nips/WangPNSMHLB19,
  author       = {Alex Wang and
                  Yada Pruksachatkun and
                  Nikita Nangia and
                  Amanpreet Singh and
                  Julian Michael and
                  Felix Hill and
                  Omer Levy and
                  Samuel R. Bowman},
  title        = {SuperGLUE: {A} Stickier Benchmark for General-Purpose Language Understanding
                  Systems},
  booktitle    = {NeurIPS},
  year         = {2019}
}

@inproceedings{DBLP:conf/emnlp/NarayanCL18,
  author       = {Shashi Narayan and
                  Shay B. Cohen and
                  Mirella Lapata},
  title        = {Don't Give Me the Details, Just the Summary! Topic-Aware Convolutional
                  Neural Networks for Extreme Summarization},
  booktitle    = {EMNLP},
  year         = {2018}
}

@article{DBLP:journals/corr/abs-2305-08322,
  author       = {Yuzhen Huang and
                  Yuzhuo Bai and
                  Zhihao Zhu and
                  Junlei Zhang and
                  Jinghan Zhang and
                  Tangjun Su and
                  Junteng Liu and
                  Chuancheng Lv and
                  Yikai Zhang and
                  Jiayi Lei and
                  Yao Fu and
                  Maosong Sun and
                  Junxian He},
  title        = {C-Eval: {A} Multi-Level Multi-Discipline Chinese Evaluation Suite
                  for Foundation Models},
  journal      = {CoRR},
  volume       = {abs/2305.08322},
  year         = {2023}
}

@article{DBLP:journals/corr/abs-2211-09110,
  author       = {Percy Liang and
                  Rishi Bommasani and
                  Tony Lee and
                  Dimitris Tsipras and
                  Dilara Soylu and
                  Michihiro Yasunaga and
                  Yian Zhang and
                  Deepak Narayanan and
                  Yuhuai Wu and
                  Ananya Kumar and
                  Benjamin Newman and
                  Binhang Yuan and
                  Bobby Yan and
                  Ce Zhang and
                  Christian Cosgrove and
                  Christopher D. Manning and
                  Christopher R{\'{e}} and
                  Diana Acosta{-}Navas and
                  Drew A. Hudson and
                  Eric Zelikman and
                  Esin Durmus and
                  Faisal Ladhak and
                  Frieda Rong and
                  Hongyu Ren and
                  Huaxiu Yao and
                  Jue Wang and
                  Keshav Santhanam and
                  Laurel J. Orr and
                  Lucia Zheng and
                  Mert Y{\"{u}}ksekg{\"{o}}n{\"{u}}l and
                  Mirac Suzgun and
                  Nathan Kim and
                  Neel Guha and
                  Niladri S. Chatterji and
                  Omar Khattab and
                  Peter Henderson and
                  Qian Huang and
                  Ryan Chi and
                  Sang Michael Xie and
                  Shibani Santurkar and
                  Surya Ganguli and
                  Tatsunori Hashimoto and
                  Thomas Icard and
                  Tianyi Zhang and
                  Vishrav Chaudhary and
                  William Wang and
                  Xuechen Li and
                  Yifan Mai and
                  Yuhui Zhang and
                  Yuta Koreeda},
  title        = {Holistic Evaluation of Language Models},
  journal      = {CoRR},
  volume       = {abs/2211.09110},
  year         = {2022}
}


















@article{zhong2023agieval,
  author       = {Wanjun Zhong and
                  Ruixiang Cui and
                  Yiduo Guo and
                  Yaobo Liang and
                  Shuai Lu and
                  Yanlin Wang and
                  Amin Saied and
                  Weizhu Chen and
                  Nan Duan},
  title        = {AGIEval: {A} Human-Centric Benchmark for Evaluating Foundation Models},
  journal      = {CoRR},
  volume       = {abs/2304.06364},
  year         = {2023}
}

@inproceedings{xu-etal-2020-clue,
  author       = {Liang Xu and
                  Hai Hu and
                  Xuanwei Zhang and
                  Lu Li and
                  Chenjie Cao and
                  Yudong Li and
                  Yechen Xu and
                  Kai Sun and
                  Dian Yu and
                  Cong Yu and others},
  title        = {{CLUE:} {A} Chinese Language Understanding Evaluation Benchmark},
  booktitle    = {{COLING}},
  year         = {2020}
}

@inproceedings{levesque2012winograd,
  author       = {Hector J. Levesque and
                  Ernest Davis and
                  Leora Morgenstern},
  title        = {The Winograd Schema Challenge},
  booktitle    = {{KR}},
  year         = {2012}
}

@inproceedings{clark2019boolq,
  author       = {Christopher Clark and
                  Kenton Lee and
                  Ming{-}Wei Chang and
                  Tom Kwiatkowski and
                  Michael Collins and
                  Kristina Toutanova},
  title        = {BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions},
  booktitle    = {{NAACL-HLT}},
  year         = {2019}
}


@article{kwiatkowski2019natural,
  author       = {Tom Kwiatkowski and
                  Jennimaria Palomaki and
                  Olivia Redfield and
                  Michael Collins and
                  Ankur P. Parikh and
                  Chris Alberti and
                  Danielle Epstein and
                  Illia Polosukhin and
                  Jacob Devlin and
                  Kenton Lee and
                  Kristina Toutanova and
                  Llion Jones and
                  Matthew Kelcey and
                  Ming{-}Wei Chang and
                  Andrew M. Dai and
                  Jakob Uszkoreit and
                  Quoc Le and
                  Slav Petrov},
  title        = {Natural Questions: a Benchmark for Question Answering Research},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {7},
  year         = {2019}
}

@article{sun2019investigating,
  author       = {Kai Sun and
                  Dian Yu and
                  Dong Yu and
                  Claire Cardie},
  title        = {Investigating Prior Knowledge for Challenging Chinese Machine Reading
                  Comprehension},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {8},
  year         = {2020}
}



@inproceedings{dagan2005pascal,
  title={The pascal recognising textual entailment challenge},
  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
  booktitle={Machine learning challenges workshop},
  year={2005},
  organization={Springer}
}


@article{Zhang2023EvaluatingTP,
  author       = {Xiaotian Zhang and
                  Chunyang Li and
                  Yi Zong and
                  Zhengyu Ying and
                  Liang He and
                  Xipeng Qiu},
  title        = {Evaluating the Performance of Large Language Models on {GAOKAO} Benchmark},
  journal      = {CoRR},
  volume       = {abs/2305.12474},
  year         = {2023}
}

@article{tydiqa,
  author       = {Jonathan H. Clark and
                  Jennimaria Palomaki and
                  Vitaly Nikolaev and
                  Eunsol Choi and
                  Dan Garrette and
                  Michael Collins and
                  Tom Kwiatkowski},
  title        = {TyDi {QA:} {A} Benchmark for Information-Seeking Question Answering
                  in Typologically Diverse Languages},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {8},
  year         = {2020}
}

@inproceedings{talmor2018commonsenseqa,
  author       = {Alon Talmor and
                  Jonathan Herzig and
                  Nicholas Lourie and
                  Jonathan Berant},
  title        = {CommonsenseQA: {A} Question Answering Challenge Targeting Commonsense
                  Knowledge},
  booktitle    = {{NAACL-HLT}},
  year         = {2019}
}

@inproceedings{paperno2016lambada,
  author       = {Denis Paperno and
                  Germ{\'{a}}n Kruszewski and
                  Angeliki Lazaridou and
                  Quan Ngoc Pham and
                  Raffaella Bernardi and
                  Sandro Pezzelle and
                  Marco Baroni and
                  Gemma Boleda and
                  Raquel Fern{\'{a}}ndez},
  title        = {The {LAMBADA} dataset: Word prediction requiring a broad discourse
                  context},
  booktitle    = {{ACL}},
  year         = {2016}
}

@inproceedings{roemmele2011choice,
  author       = {Melissa Roemmele and
                  Cosmin Adrian Bejan and
                  Andrew S. Gordon},
  title        = {Choice of Plausible Alternatives: An Evaluation of Commonsense Causal
                  Reasoning},
  booktitle    = {{AAAI} Spring Symposium},
  year         = {2011}
}






@article{DBLP:journals/corr/abs-2002-00573,
  author       = {Wei{-}Lun Chao and
                  Han{-}Jia Ye and
                  De{-}Chuan Zhan and
                  Mark E. Campbell and
                  Kilian Q. Weinberger},
  title        = {Revisiting Meta-Learning as Supervised Learning},
  journal      = {CoRR},
  volume       = {abs/2002.00573},
  year         = {2020}
}

@inproceedings{DBLP:conf/aaai/LuYZ21,
  author       = {Su Lu and
                  Han{-}Jia Ye and
                  De{-}Chuan Zhan},
  title        = {Tailoring Embedding Function to Heterogeneous Few-Shot Tasks by Global
                  and Local Feature Adaptors},
  booktitle    = {{AAAI}},
  year         = {2021}
}

@article{DBLP:journals/pami/YeZJZ21,
  author       = {Han{-}Jia Ye and
                  De{-}Chuan Zhan and
                  Yuan Jiang and
                  Zhi{-}Hua Zhou},
  title        = {Heterogeneous Few-Shot Model Rectification With Semantic Mapping},
  journal      = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
  volume       = {43},
  number       = {11},
  year         = {2021}
}

@article{DBLP:journals/pami/YeZLJ20,
  author       = {Han{-}Jia Ye and
                  De{-}Chuan Zhan and
                  Nan Li and
                  Yuan Jiang},
  title        = {Learning Multiple Local Metrics: Global Consideration Helps},
  journal      = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
  volume       = {42},
  number       = {7},
  year         = {2020}
}

@inproceedings{DBLP:conf/ijcai/YangYZJ15,
  author       = {Yang Yang and
                  Han{-}Jia Ye and
                  De{-}Chuan Zhan and
                  Yuan Jiang},
  title        = {Auxiliary Information Regularized Machine for Multiple Modality Feature
                  Learning},
  booktitle    = {{IJCAI}},
  year         = {2015}
}


@inproceedings{DBLP:conf/icml/Guo0LZ23,
  author       = {Lan{-}Zhe Guo and
                  Zhi Zhou and
                  Yu{-}Feng Li and
                  Zhi{-}Hua Zhou},
  title        = {Identifying Useful Learnwares for Heterogeneous Label Spaces},
  booktitle    = {{ICML}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  year         = {2023}
}

@inproceedings{DBLP:conf/ijcai/TanT0Z23,
  author       = {Peng Tan and
                  Zhi{-}Hao Tan and
                  Yuan Jiang and
                  Zhi{-}Hua Zhou},
  title        = {Handling Learnwares Developed from Heterogeneous Feature Spaces without
                  Auxiliary Data},
  booktitle    = {{IJCAI}},
  year         = {2023}
}

@article{Tan2022TowardsEL,
  title={Towards enabling learnware to handle heterogeneous feature spaces},
  author={Peng Tan and Zhi-Hao Tan and Yuan Jiang and Zhi-Hua Zhou},
  journal={Machine Learning},
  year={2022}
}

@inproceedings{dosovitskiy2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={ICLR},
  year={2020}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={ICCV},
  pages={10012--10022},
  year={2021}
}

@article{dong2024ixc2,
  title={InternLM-XComposer2: Mastering free-form text-image composition and comprehension in vision-language large model},
  author={Dong, Xiaoyi and Zhang, Pan and Zang, Yuhang and Cao, Yuhang and Wang, Bin and Ouyang, Linke and Wei, Xilin and Zhang, Songyang and Duan, Haodong and Cao, Maosong and others},
  journal={arXiv preprint arXiv:2401.16420},
  year={2024}
}


@inproceedings{guo2019eaten,
  title={Eaten: Entity-aware attention for single shot visual text extraction},
  author={Guo, He and Qin, Xiameng and Liu, Jiaming and Han, Junyu and Liu, Jingtuo and Ding, Errui},
  booktitle={ICDAR},
  pages={254--259},
  year={2019}
}


@inproceedings{singh2021textocr,
  title={Textocr: Towards large-scale end-to-end reasoning for arbitrary-shaped scene text},
  author={Singh, Amanpreet and Pang, Guan and Toh, Mandy and Huang, Jing and Galuba, Wojciech and Hassner, Tal},
  booktitle={CVPR},
  pages={8802--8812},
  year={2021}
}

@article{masry2023unichart,
  title={Unichart: A universal vision-language pretrained model for chart comprehension and reasoning},
  author={Masry, Ahmed and Kavehzadeh, Parsa and Do, Xuan Long and Hoque, Enamul and Joty, Shafiq},
  journal={arXiv preprint arXiv:2305.14761},
  year={2023}
}

@inproceedings{methani2020plotqa,
  title={Plotqa: Reasoning over scientific plots},
  author={Methani, Nitesh and Ganguly, Pritha and Khapra, Mitesh M and Kumar, Pratyush},
  booktitle={WACV},
  pages={1527--1536},
  year={2020}
}

@article{liu2020casia,
  title={Offline handwritten Chinese text recognition with convolutional neural networks},
  author={Liu, Brian and Xu, Xianchao and Zhang, Yu},
  journal={arXiv preprint arXiv:2006.15619},
  year={2020}
}

@article{veit2016cocotext,
  title={Coco-text: Dataset and benchmark for text detection and recognition in natural images},
  author={Veit, Andreas and Matera, Tomas and Neumann, Lukas and Matas, Jiri and Belongie, Serge},
  journal={arXiv preprint arXiv:1601.07140},
  year={2016}
}


@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{minicpm,
  title={MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies},
  author={Hu, Shengding and Tu, Yuge and Han, Xu and He, Chaoqun and Cui, Ganqu and Long, Xiang and Zheng, Zhi and Fang, Yewei and Huang, Yuxiang and Zhao, Weilin and others},
  journal={arXiv preprint arXiv:2404.06395},
  year={2024}
}

@misc{gemini,
  title = {Introducing Gemini: our largest and most capable AI model},
  author = {Google},
  url = {https://blog.google/technology/ai/google-gemini-ai/},
  year={2023}
}

@article{reid2024gemini1_5,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Reid, Machel and Savinov, Nikolay and Teplyashin, Denis and Lepikhin, Dmitry and Lillicrap, Timothy and Alayrac, Jean-baptiste and Soricut, Radu and Lazaridou, Angeliki and Firat, Orhan and Schrittwieser, Julian and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@article{tong2024mmvp,
  title={Eyes wide shut? exploring the visual shortcomings of multimodal llms},
  author={Tong, Shengbang and Liu, Zhuang and Zhai, Yuexiang and Ma, Yi and LeCun, Yann and Xie, Saining},
  journal={arXiv preprint arXiv:2401.06209},
  year={2024}
}

@inproceedings{kim2022synthdog,
  title     = {OCR-Free Document Understanding Transformer},
  author    = {Kim, Geewook and Hong, Teakgyu and Yim, Moonbin and Nam, JeongYeon and Park, Jinyoung and Yim, Jinyeong and Hwang, Wonseok and Yun, Sangdoo and Han, Dongyoon and Park, Seunghyun},
  booktitle = {ECCV},
  year      = {2022}
}

@article{yuan2019ctw,
  title={A large chinese text dataset in the wild},
  author={Yuan, Tai-Ling and Zhu, Zhe and Xu, Kun and Li, Cheng-Jun and Mu, Tai-Jiang and Hu, Shi-Min},
  journal={Journal of Computer Science and Technology},
  volume={34},
  pages={509--521},
  year={2019},
  publisher={Springer}
}

@inproceedings{gupta2016synthtext,
  title={Synthetic data for text localisation in natural images},
  author={Gupta, Ankush and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={CVPR},
  pages={2315--2324},
  year={2016}
}

@article{chen2023internvl,
  title={Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Muyan, Zhong and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others},
  journal={arXiv preprint arXiv:2312.14238},
  year={2023}
}

@article{mckinzie2024mm1,
  title={Mm1: Methods, analysis \& insights from multimodal llm pre-training},
  author={McKinzie, Brandon and Gan, Zhe and Fauconnier, Jean-Philippe and Dodge, Sam and Zhang, Bowen and Dufter, Philipp and Shah, Dhruti and Du, Xianzhi and Peng, Futang and Weers, Floris and others},
  journal={arXiv preprint arXiv:2403.09611},
  year={2024}
}

@article{DBLP:journals/corr/abs-2312-11514,
  author       = {Keivan Alizadeh and
                  Iman Mirzadeh and
                  Dmitry Belenko and
                  Karen Khatamifard and
                  Minsik Cho and
                  Carlo C. Del Mundo and
                  Mohammad Rastegari and
                  Mehrdad Farajtabar},
  title        = {{LLM} in a flash: Efficient Large Language Model Inference with Limited
                  Memory},
  journal      = {CoRR},
  volume       = {abs/2312.11514},
  year         = {2023}
}

@inproceedings{DBLP:conf/sc/RajbhandariRRSH21,
  author       = {Samyam Rajbhandari and
                  Olatunji Ruwase and
                  Jeff Rasley and
                  Shaden Smith and
                  Yuxiong He},
  title        = {ZeRO-infinity: breaking the {GPU} memory wall for extreme scale deep
                  learning},
  booktitle    = {International Conference for High Performance Computing, Networking,
                  Storage and Analysis, {SC} 2021, St. Louis, Missouri, USA, November
                  14-19, 2021},
  pages        = {59},
  publisher    = {{ACM}},
  year         = {2021}
}

@article{DBLP:journals/corr/abs-2401-02669,
  author       = {Bin Lin and
                  Tao Peng and
                  Chen Zhang and
                  Minmin Sun and
                  Lanbo Li and
                  Hanyu Zhao and
                  Wencong Xiao and
                  Qi Xu and
                  Xiafei Qiu and
                  Shen Li and
                  Zhigang Ji and
                  Yong Li and
                  Wei Lin},
  title        = {Infinite-LLM: Efficient {LLM} Service for Long Context with DistAttention
                  and Distributed KVCache},
  journal      = {CoRR},
  volume       = {abs/2401.02669},
  year         = {2024}
}

@inproceedings{DBLP:conf/sc/AminabadiRALLZRSZRH22,
  author       = {Reza Yazdani Aminabadi and
                  Samyam Rajbhandari and
                  Ammar Ahmad Awan and
                  Cheng Li and
                  Du Li and
                  Elton Zheng and
                  Olatunji Ruwase and
                  Shaden Smith and
                  Minjia Zhang and
                  Jeff Rasley and
                  Yuxiong He},
  title        = {DeepSpeed- Inference: Enabling Efficient Inference of Transformer
                  Models at Unprecedented Scale},
  booktitle    = {{SC22}},
  pages        = {46:1--46:15},
  year         = {2022}
}

% IDEFICS
@misc{laurencon2023idefics,
      title={OBELICS: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents},
      author={Hugo Laurençon and Lucile Saulnier and Léo Tronchon and Stas Bekman and Amanpreet Singh and Anton Lozhkov and Thomas Wang and Siddharth Karamcheti and Alexander M. Rush and Douwe Kiela and Matthieu Cord and Victor Sanh},
      year={2023},
      eprint={2306.16527},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@inproceedings{wang2021pyramid,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  booktitle={ICCV},
  pages={568--578},
  year={2021}
}

@inproceedings{li2023unmasked,
  title={Unmasked teacher: Towards training-efficient video foundation models},
  author={Li, Kunchang and Wang, Yali and Li, Yizhuo and Wang, Yi and He, Yinan and Wang, Limin and Qiao, Yu},
  booktitle={ICCV},
  pages={19948--19960},
  year={2023}
}

@misc{mmseg2020,
    title={{MMSegmentation}: OpenMMLab Semantic Segmentation Toolbox and Benchmark},
    author={MMSegmentation Contributors},
    howpublished = {\url{https://github.com/open-mmlab/mmsegmentation}},
    year={2020}
}

@inproceedings{he2022mae,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={CVPR},
  pages={16000--16009},
  year={2022}
}

@inproceedings{kirillov2019panoptic,
  title={Panoptic feature pyramid networks},
  author={Kirillov, Alexander and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={CVPR},
  pages={6399--6408},
  year={2019}
}

@inproceedings{xiao2018upernet,
  title={Unified perceptual parsing for scene understanding},
  author={Xiao, Tete and Liu, Yingcheng and Zhou, Bolei and Jiang, Yuning and Sun, Jian},
  booktitle={ECCV},
  pages={418--434},
  year={2018}
}

@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={ICML},
  pages={10347--10357},
  year={2021}
}


@inproceedings{wang2023internimage,
  title={Internimage: Exploring large-scale vision foundation models with deformable convolutions},
  author={Wang, Wenhai and Dai, Jifeng and Chen, Zhe and Huang, Zhenhang and Li, Zhiqi and Zhu, Xizhou and Hu, Xiaowei and Lu, Tong and Lu, Lewei and Li, Hongsheng and others},
  booktitle={CVPR},
  pages={14408--14419},
  year={2023}
}

@article{oquab2023dinov2,
  title={DINOv2: Learning Robust Visual Features without Supervision},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy V and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and HAZIZA, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others},
  journal={TMLR},
  year={2023}
}


@article{tsimpoukelli2021multimodal,
	author = {Tsimpoukelli, Maria and Menick, Jacob L and Cabi, Serkan and Eslami, SM and Vinyals, Oriol and Hill, Felix},
	journal = {Advances in Neural Information Processing Systems},
	pages = {200--212},
	title = {Multimodal few-shot learning with frozen language models},
	volume = {34},
	year = {2021}}

@article{chen2015cococaption,
  title={Microsoft coco captions: Data collection and evaluation server},
  author={Chen, Xinlei and Fang, Hao and Lin, Tsung-Yi and Vedantam, Ramakrishna and Gupta, Saurabh and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  journal={arXiv preprint arXiv:1504.00325},
  year={2015}
}

@article{chen2023palix,
  title={PaLI-X: On Scaling up a Multilingual Vision and Language Model},
  author={Chen, Xi and Djolonga, Josip and Padlewski, Piotr and Mustafa, Basil and Changpinyo, Soravit and Wu, Jialin and Ruiz, Carlos Riquelme and Goodman, Sebastian and Wang, Xiao and Tay, Yi and others},
  journal={arXiv preprint arXiv:2305.18565},
  year={2023}
}

@article{wei2022fdswin,
  title={Contrastive learning rivals masked image modeling in fine-tuning via feature distillation},
  author={Wei, Yixuan and Hu, Han and Xie, Zhenda and Zhang, Zheng and Cao, Yue and Bao, Jianmin and Chen, Dong and Guo, Baining},
  journal={arXiv preprint arXiv:2205.14141},
  year={2022}
}

@inproceedings{cheng2022mask2former,
  title={Masked-attention mask transformer for universal image segmentation},
  author={Cheng, Bowen and Misra, Ishan and Schwing, Alexander G and Kirillov, Alexander and Girdhar, Rohit},
  booktitle={CVPR},
  pages={1290--1299},
  year={2022}
}

@article{xiao2021early,
  title={Early convolutions help transformers see better},
  author={Xiao, Tete and Dollar, Piotr and Singh, Mannat and Mintun, Eric and Darrell, Trevor and Girshick, Ross},
  journal={NeurIPS},
  volume={34},
  year={2021}
}

@article{wang2021pvtv2,
  title={Pvt v2: Improved baselines with pyramid vision transformer},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  journal={CVMJ},
  volume={8},
  number={3},
  pages={415--424},
  year={2022},
  publisher={Springer}
}


@inproceedings{wu2021cvt,
  title={Cvt: Introducing convolutions to vision transformers},
  author={Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei},
  booktitle={ICCV},
  pages={22--31},
  year={2021}
}

@article{gu2021hrvit,
  title={Hrvit: Multi-scale high-resolution vision transformer},
  author={Gu, Jiaqi and Kwon, Hyoukjun and Wang, Dilin and Ye, Wei and Li, Meng and Chen, Yu-Hsin and Lai, Liangzhen and Chandra, Vikas and Pan, David Z},
  journal={arXiv preprint arXiv:2111.01236},
  year={2021}
}

@article{lu2024deepseekvl,
  title={Deepseek-vl: Towards real-world vision-language understanding},
  author={Lu, Haoyu and Liu, Wen and Zhang, Bo and Wang, Bingxuan and Dong, Kai and Liu, Bo and Sun, Jingxiang and Ren, Tongzheng and Li, Zhuoshu and Sun, Yaofeng and others},
  journal={arXiv preprint arXiv:2403.05525},
  year={2024}
}

@article{kuznetsova2020openimage,
  title={The open images dataset v4: Unified image classification, object detection, and visual relationship detection at scale},
  author={Kuznetsova, Alina and Rom, Hassan and Alldrin, Neil and Uijlings, Jasper and Krasin, Ivan and Pont-Tuset, Jordi and Kamali, Shahab and Popov, Stefan and Malloci, Matteo and Kolesnikov, Alexander and others},
  journal={IJCV},
  volume={128},
  number={7},
  pages={1956--1981},
  year={2020}
}

@article{mmstar,
      title={Are We on the Right Way for Evaluating Large Vision-Language Models?}, 
      author={Chen, Lin and Li, Jinsong and Dong, Xiaoyi and Zhang, Pan and Zang, Yuhang and Chen, Zehui and Duan, Haodong and Wang, Jiaqi and Qiao, Yu and Lin, Dahua and Zhao, Feng},
      journal={arXiv preprint arXiv:2403.20330},
      year={2024}
  }

@article{liu2023mmcinst,
  title={Mmc: Advancing multimodal chart understanding with large-scale instruction tuning},
  author={Liu, Fuxiao and Wang, Xiaoyang and Yao, Wenlin and Chen, Jianshu and Song, Kaiqiang and Cho, Sangwoo and Yacoob, Yaser and Yu, Dong},
  journal={arXiv preprint arXiv:2311.10774},
  year={2023}
}

@article{wang2023cogvlm,
  title={Cogvlm: Visual expert for pretrained language models},
  author={Wang, Weihan and Lv, Qingsong and Yu, Wenmeng and Hong, Wenyi and Qi, Ji and Wang, Yan and Ji, Junhui and Yang, Zhuoyi and Zhao, Lei and Song, Xixuan and others},
  journal={arXiv preprint arXiv:2311.03079},
  year={2023}
}

@article{yuan2021hrformer,
  title={HRFormer: High-Resolution Vision Transformer for Dense Prediction},
  author={Yuan, Yuhui and Fu, Rao and Huang, Lang and Lin, Weihong and Zhang, Chao and Chen, Xilin and Wang, Jingdong},
  journal={NeurIPS},
  volume={34},
  year={2021}
}

@article{dong2021cswin,
  title={Cswin transformer: A general vision transformer backbone with cross-shaped windows},
  author={Dong, Xiaoyi and Bao, Jianmin and Chen, Dongdong and Zhang, Weiming and Yu, Nenghai and Yuan, Lu and Chen, Dong and Guo, Baining},
  journal={arXiv preprint arXiv:2107.00652},
  year={2021}
}

@article{xie2021segformer,
  title={SegFormer: Simple and efficient design for semantic segmentation with transformers},
  author={Xie, Enze and Wang, Wenhai and Yu, Zhiding and Anandkumar, Anima and Alvarez, Jose M and Luo, Ping},
  journal={NeurIPS},
  volume={34},
  year={2021}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  pages={770--778},
  year={2016}
}

@inproceedings{liu2022convnet,
  title={A convnet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle={CVPR},
  pages={11976--11986},
  year={2022}
}

@inproceedings{zhang2020bridging,
  title={Bridging the gap between anchor-based and anchor-free detection via adaptive training sample selection},
  author={Zhang, Shifeng and Chi, Cheng and Yao, Yongqiang and Lei, Zhen and Li, Stan Z},
  booktitle={CVPR},
  pages={9759--9768},
  year={2020}
}

@article{cai2019cascade,
  title={Cascade R-CNN: high quality object detection and instance segmentation},
  author={Cai, Zhaowei and Vasconcelos, Nuno},
  journal={TPAMI},
  volume={43},
  number={5},
  pages={1483--1498},
  year={2019}
}

@article{li2020generalized,
  title={Generalized focal loss: Learning qualified and distributed bounding boxes for dense object detection},
  author={Li, Xiang and Wang, Wenhai and Wu, Lijun and Chen, Shuo and Hu, Xiaolin and Li, Jun and Tang, Jinhui and Yang, Jian},
  journal={NeurIPS},
  volume={33},
  pages={21002--21012},
  year={2020}
}

@inproceedings{sun2021sparse,
  title={Sparse r-cnn: End-to-end object detection with learnable proposals},
  author={Sun, Peize and Zhang, Rufeng and Jiang, Yi and Kong, Tao and Xu, Chenfeng and Zhan, Wei and Tomizuka, Masayoshi and Li, Lei and Yuan, Zehuan and Wang, Changhu and others},
  booktitle={CVPR},
  pages={14454--14463},
  year={2021}
}


@article{li2021benchmarking,
  title={Benchmarking detection transfer learning with vision transformers},
  author={Li, Yanghao and Xie, Saining and Chen, Xinlei and Dollar, Piotr and He, Kaiming and Girshick, Ross},
  journal={arXiv preprint arXiv:2111.11429},
  year={2021}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@inproceedings{touvron2021going,
  title={Going deeper with image transformers},
  author={Touvron, Hugo and Cord, Matthieu and Sablayrolles, Alexandre and Synnaeve, Gabriel and J{\'e}gou, Herv{\'e}},
  booktitle={ICCV},
  pages={32--42},
  year={2021}
}

@article{chu2021conditional,
  title={Conditional positional encodings for vision transformers},
  author={Chu, Xiangxiang and Tian, Zhi and Zhang, Bo and Wang, Xinlong and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
  journal={arXiv preprint arXiv:2102.10882},
  year={2021}
}

@inproceedings{huang2016droppath,
  title={Deep networks with stochastic depth},
  author={Huang, Gao and Sun, Yu and Liu, Zhuang and Sedra, Daniel and Weinberger, Kilian Q},
  booktitle={ECCV},
  pages={646--661},
  year={2016}
}

@inproceedings{rasley2020deepspeed,
  title={Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters},
  author={Rasley, Jeff and Rajbhandari, Samyam and Ruwase, Olatunji and He, Yuxiong},
  booktitle={SIGKDD},
  pages={3505--3506},
  year={2020}
}

@inproceedings{rajbhandari2020zero,
  title={Zero: Memory optimizations toward training trillion parameter models},
  author={Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  booktitle={SC20: International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--16},
  year={2020},
  organization={IEEE}
}

@inproceedings{chollet2017xception,
  title={Xception: Deep learning with depthwise separable convolutions},
  author={Chollet, Fran{\c{c}}ois},
  booktitle={CVPR},
  pages={1251--1258},
  year={2017}
}

@article{zhu2023ghost,
  title={Ghost in the Minecraft: Generally Capable Agents for Open-World Enviroments via Large Language Models with Text-based Knowledge and Memory},
  author={Zhu, Xizhou and Chen, Yuntao and Tian, Hao and Tao, Chenxin and Su, Weijie and Yang, Chenyu and Huang, Gao and Li, Bin and Lu, Lewei and Wang, Xiaogang and others},
  journal={arXiv preprint arXiv:2305.17144},
  year={2023}
}

@inproceedings{zhu2020deformable,
  title={Deformable detr: Deformable transformers for end-to-end object detection},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  booktitle={ICLR},
  year={2020}
}

@article{thomee2016yfcc100m,
  title={YFCC100M: The new data in multimedia research},
  author={Thomee, Bart and Shamma, David A and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
  journal={Communications of the ACM},
  volume={59},
  number={2},
  pages={64--73},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@inproceedings{mehta2020delight,
  title={DeLighT: Deep and Light-weight Transformer},
  author={Mehta, Sachin and Ghazvininejad, Marjan and Iyer, Srinivasan and Zettlemoyer, Luke and Hajishirzi, Hannaneh},
  booktitle={ICLR},
  year={2020}
}

@misc{laion_ai_2023_clip,
  author = {LAION-AI},
  title = {CLIP Benchmark: CLIP-like model evaluation},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/LAION-AI/CLIP_benchmark}},
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={ECCV},
  pages={740--755},
  year={2014}
}

@inproceedings{yao2021filip,
  title={FILIP: Fine-grained Interactive Language-Image Pre-Training},
  author={Yao, Lewei and Huang, Runhui and Hou, Lu and Lu, Guansong and Niu, Minzhe and Xu, Hang and Liang, Xiaodan and Li, Zhenguo and Jiang, Xin and Xu, Chunjing},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{cai2022reversible,
  title={Reversible Column Networks},
  author={Cai, Yuxuan and Zhou, Yizhuang and Han, Qi and Sun, Jianjian and Kong, Xiangwen and Li, Jun and Zhang, Xiangyu},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{zhai2022scaling,
  title={Scaling vision transformers},
  author={Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
  booktitle={CVPR},
  pages={12104--12113},
  year={2022}
}



@article{wang2023onepeace,
  title={ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities},
  author={Wang, Peng and Wang, Shijie and Lin, Junyang and Bai, Shuai and Zhou, Xiaohuan and Zhou, Jingren and Wang, Xinggang and Zhou, Chang},
  journal={arXiv preprint arXiv:2305.11172},
  year={2023}
}

@inproceedings{singh2023maws,
  title={The effectiveness of MAE pre-pretraining for billion-scale pretraining},
  author={Singh, Mannat and Duval, Quentin and Alwala, Kalyan Vasudev and Fan, Haoqi and Aggarwal, Vaibhav and Adcock, Aaron and Joulin, Armand and Doll{\'a}r, Piotr and Feichtenhofer, Christoph and Girshick, Ross and others},
  booktitle={ICCV},
  pages={5484--5494},
  year={2023}
}

@inproceedings{agrawal2019nocaps,
  title={Nocaps: Novel object captioning at scale},
  author={Agrawal, Harsh and Desai, Karan and Wang, Yufei and Chen, Xinlei and Jain, Rishabh and Johnson, Mark and Batra, Dhruv and Parikh, Devi and Lee, Stefan and Anderson, Peter},
  booktitle={ICCV},
  pages={8948--8957},
  year={2019}
}

@article{bai2023touchstone,
  title={Touchstone: Evaluating vision-language models by language models},
  author={Bai, Shuai and Yang, Shusheng and Bai, Jinze and Wang, Peng and Zhang, Xingxuan and Lin, Junyang and Wang, Xinggang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.16890},
  year={2023}
}

@article{liu2023mmbench,
  title={MMBench: Is Your Multi-modal Model an All-around Player?},
  author={Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and others},
  journal={arXiv preprint arXiv:2307.06281},
  year={2023}
}

@misc{textocr_gpt4v_dataset,
  title = {TextOCR GPT-4V Dataset},
  author = {Jimmycarter},
  howpublished = {\url{https://huggingface.co/datasets/jimmycarter/textocr-gpt4v}},
  organization = {Hugging Face},
  year={2023}
}

@misc{OpenHermes2_5,
  title = {OpenHermes 2.5: An Open Dataset of Synthetic Data for Generalist LLM Assistants},
  author = {Teknium},
  year = {2023},
  organization = {HuggingFace},
  howpublished = {\url{https://huggingface.co/datasets/teknium/OpenHermes-2.5}}
}

@article{bai2024coig,
  title={COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning},
  author={Bai, Yuelin and Du, Xinrun and Liang, Yiming and Jin, Yonggang and Liu, Ziqiang and Zhou, Junting and Zheng, Tianyu and Zhang, Xincheng and Ma, Nuo and Wang, Zekun and others},
  journal={arXiv preprint arXiv:2403.18058},
  year={2024}
}



@article{wang2023lvisinstruct4v,
  title={To see is to believe: Prompting gpt-4v for better visual instruction tuning},
  author={Wang, Junke and Meng, Lingchen and Weng, Zejia and He, Bo and Wu, Zuxuan and Jiang, Yu-Gang},
  journal={arXiv preprint arXiv:2311.07574},
  year={2023}
}

@article{he2023wanjuan,
  title={Wanjuan: A comprehensive multimodal dataset for advancing english and chinese large models},
  author={He, Conghui and Jin, Zhenjiang and Xu, Chao and Qiu, Jiantao and Wang, Bin and Li, Wei and Yan, Hang and Wang, Jiaqi and Lin, Dahua},
  journal={arXiv preprint arXiv:2308.10755},
  year={2023}
}

@misc{laion_gpt4v_dataset,
  title = {GPT-4V Dataset},
  author={LAION},
  howpublished = {\url{https://huggingface.co/datasets/laion/gpt4v-dataset}},
  organization = {LAION},
  year={2023}
}

@article{chen2024allava,
  title={ALLaVA: Harnessing GPT4V-synthesized Data for A Lite Vision-Language Model},
  author={Chen, Guiming Hardy and Chen, Shunian and Zhang, Ruifei and Chen, Junying and Wu, Xiangbo and Zhang, Zhiyi and Chen, Zhihong and Li, Jianquan and Wan, Xiang and Wang, Benyou},
  journal={arXiv preprint arXiv:2402.11684},
  year={2024}
}


@article{krishna2017vg,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={IJCV},
  volume={123},
  pages={32--73},
  year={2017},
  publisher={Springer}
}


@inproceedings{lerner2022viquae,
  title={ViQuAE, a dataset for knowledge-based visual question answering about named entities},
  author={Lerner, Paul and Ferret, Olivier and Guinaudeau, Camille and Le Borgne, Herv{\'e} and Besan{\c{c}}on, Romaric and Moreno, Jos{\'e} G and Lov{\'o}n Melgarejo, Jes{\'u}s},
  booktitle={SIGIR},
  pages={3108--3120},
  year={2022}
}


@inproceedings{li2023superclevr,
  title={Super-CLEVR: A virtual benchmark to diagnose domain robustness in visual reasoning},
  author={Li, Zhuowan and Wang, Xingrui and Stengel-Eskin, Elias and Kortylewski, Adam and Ma, Wufei and Van Durme, Benjamin and Yuille, Alan L},
  booktitle={CVPR},
  pages={14963--14973},
  year={2023}
}

@inproceedings{shah2019kvqa,
  title={Kvqa: Knowledge-aware visual question answering},
  author={Shah, Sanket and Mishra, Anand and Yadati, Naganand and Talukdar, Partha Pratim},
  booktitle={AAAI},
  volume={33},
  number={01},
  pages={8876--8884},
  year={2019}
}


@article{yu2023mathqa,
  title={Metamath: Bootstrap your own mathematical questions for large language models},
  author={Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James T and Li, Zhenguo and Weller, Adrian and Liu, Weiyang},
  journal={arXiv preprint arXiv:2309.12284},
  year={2023}
}


@article{lu2021geometry3k,
  title={Inter-GPS: Interpretable geometry problem solving with formal language and symbolic reasoning},
  author={Lu, Pan and Gong, Ran and Jiang, Shibiao and Qiu, Liang and Huang, Siyuan and Liang, Xiaodan and Zhu, Song-Chun},
  journal={arXiv preprint arXiv:2105.04165},
  year={2021}
}


@inproceedings{kafle2018dvqa,
  title={Dvqa: Understanding data visualizations via question answering},
  author={Kafle, Kushal and Price, Brian and Cohen, Scott and Kanan, Christopher},
  booktitle={CVPR},
  pages={5648--5656},
  year={2018}
}

@article{lindstrom2022clevrmath,
  title={Clevr-math: A dataset for compositional language, visual and mathematical reasoning},
  author={Lindstr{\"o}m, Adam Dahlgren and Abraham, Savitha Sam},
  journal={arXiv preprint arXiv:2208.05358},
  year={2022}
}

@article{lu2022tablemwp,
  title={Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning},
  author={Lu, Pan and Qiu, Liang and Chang, Kai-Wei and Wu, Ying Nian and Zhu, Song-Chun and Rajpurohit, Tanmay and Clark, Peter and Kalyan, Ashwin},
  journal={arXiv preprint arXiv:2209.14610},
  year={2022}
}

@inproceedings{cao2022geoqa_plus,
  title={An augmented benchmark dataset for geometric question answering through dual parallel text encoding},
  author={Cao, Jie and Xiao, Jing},
  booktitle={COLING},
  pages={1511--1520},
  year={2022}
}


@inproceedings{kembhavi2017tqa,
  title={Are you smarter than a sixth grader? textbook question answering for multimodal machine comprehension},
  author={Kembhavi, Aniruddha and Seo, Minjoon and Schwenk, Dustin and Choi, Jonghyun and Farhadi, Ali and Hajishirzi, Hannaneh},
  booktitle={CVPR},
  pages={4999--5007},
  year={2017}
}

@article{liu2023vsr,
  title={Visual spatial reasoning},
  author={Liu, Fangyu and Emerson, Guy and Collier, Nigel},
  journal={TACL},
  volume={11},
  pages={635--651},
  year={2023}
}

@inproceedings{zhu2023languagebind,
  title={LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment},
  author={Zhu, Bin and Lin, Bin and Ning, Munan and Yan, Yang and Cui, Jiaxi and HongFa, WANG and Pang, Yatian and Jiang, Wenhao and Zhang, Junwu and Li, Zongwei and others},
  booktitle={ICLR},
  year={2023}
}

@article{wang2022internvideo,
  title={Internvideo: General video foundation models via generative and discriminative learning},
  author={Wang, Yi and Li, Kunchang and Li, Yizhuo and He, Yinan and Huang, Bingkun and Zhao, Zhiyu and Zhang, Hongjie and Xu, Jilan and Liu, Yi and Wang, Zun and others},
  journal={arXiv preprint arXiv:2212.03191},
  year={2022}
}


@article{fu2023mme,
  title={MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models},
  author={Fu, Chaoyou and Chen, Peixian and Shen, Yunhang and Qin, Yulei and Zhang, Mengdan and Lin, Xu and Qiu, Zhenyu and Lin, Wei and Yang, Jinrui and Zheng, Xiawu and others},
  journal={arXiv preprint arXiv:2306.13394},
  year={2023}
}


@inproceedings{chen2022altclip,
  title={AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities},
  author={Chen, Zhongzhi and Liu, Guang and Zhang, Bo-Wen and Yang, Qinghong and Wu, Ledell},
  booktitle={ACL},
  pages={8666--8682},
  year={2023}
}

@article{xie2022zero,
  title={Zero and R2D2: A large-scale Chinese cross-modal benchmark and A vision-language framework},
  author={Xie, Chunyu and Li, Jincheng and Cai, Heng and Kong, Fanjing and Wu, Xiaoyu and Song, Jianfei and Morimitsu, Henrique and Yao, Lin and Wang, Dexin and Leng, Dawei and others},
  journal={arXiv preprint arXiv:2205.03860},
  year={2022}
}

@article{fengshenbang,
  title={Fengshenbang 1.0: Being the foundation of chinese cognitive intelligence},
  author={Zhang, Jiaxing and Gan, Ruyi and Wang, Junjie and Zhang, Yuxiang and Zhang, Lin and Yang, Ping and Gao, Xinyu and Wu, Ziwei and Dong, Xiaoqun and He, Junqing and others},
  journal={arXiv preprint arXiv:2209.02970},
  year={2022}
}


@article{gu2022wukong,
  title={Wukong: A 100 million large-scale chinese cross-modal pre-training benchmark},
  author={Gu, Jiaxi and Meng, Xiaojun and Lu, Guansong and Hou, Lu and Minzhe, Niu and Liang, Xiaodan and Yao, Lewei and Huang, Runhui and Zhang, Wei and Jiang, Xin and others},
  journal={NeurIPS},
  volume={35},
  pages={26418--26431},
  year={2022}
}

@article{sun2023evaclip,
  title={Eva-clip: Improved training techniques for clip at scale},
  author={Sun, Quan and Fang, Yuxin and Wu, Ledell and Wang, Xinlong and Cao, Yue},
  journal={arXiv preprint arXiv:2303.15389},
  year={2023}
}

@article{wang2022omnivl,
  title={Omnivl: One foundation model for image-language and video-language tasks},
  author={Wang, Junke and Chen, Dongdong and Wu, Zuxuan and Luo, Chong and Zhou, Luowei and Zhao, Yucheng and Xie, Yujia and Liu, Ce and Jiang, Yu-Gang and Yuan, Lu},
  journal={NeurIPS},
  volume={35},
  pages={5696--5710},
  year={2022}
}

@misc{openclip,
  author       = {Ilharco, Gabriel and
                  Wortsman, Mitchell and
                  Wightman, Ross and
                  Gordon, Cade and
                  Carlini, Nicholas and
                  Taori, Rohan and
                  Dave, Achal and
                  Shankar, Vaishaal and
                  Namkoong, Hongseok and
                  Miller, John and
                  Hajishirzi, Hannaneh and
                  Farhadi, Ali and
                  Schmidt, Ludwig},
  title        = {OpenCLIP},
  year         = 2021,
  howpublished = {Zenodo. Version 0.1. \url{https://doi.org/10.5281/zenodo.5143773}},
  note         = {DOI: 10.5281/zenodo.5143773}
}

@inproceedings{li2023pope,
  title={Evaluating Object Hallucination in Large Vision-Language Models},
  author={Li, Yifan and Du, Yifan and Zhou, Kun and Wang, Jinpeng and Zhao, Wayne Xin and Wen, Ji-Rong},
  booktitle={EMNLP},
  pages={292--305},
  year={2023}
}


@misc{idefics2023,
  title = {Introducing IDEFICS: An Open Reproduction of State-of-the-Art Visual Language Model},
  author = {{IDEFICS}},
  year = {2023},
  howpublished = {\url{https://huggingface.co/blog/idefics}}
}


@inproceedings{li2023flip,
  title={Scaling language-image pre-training via masking},
  author={Li, Yanghao and Fan, Haoqi and Hu, Ronghang and Feichtenhofer, Christoph and He, Kaiming},
  booktitle={CVPR},
  pages={23390--23400},
  year={2023}
}

@article{li2023monkey,
  title={Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models},
  author={Li, Zhang and Yang, Biao and Liu, Qiang and Ma, Zhiyin and Zhang, Shuo and Yang, Jingxu and Sun, Yabo and Liu, Yuliang and Bai, Xiang},
  journal={arXiv preprint arXiv:2311.06607},
  year={2023}
}

@inproceedings{singh2019textvqa,
  title={Towards vqa models that can read},
  author={Singh, Amanpreet and Natarajan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},
  booktitle={CVPR},
  pages={8317--8326},
  year={2019}
}

@inproceedings{gurari2018vizwiz,
  title={Vizwiz grand challenge: Answering visual questions from blind people},
  author={Gurari, Danna and Li, Qing and Stangl, Abigale J and Guo, Anhong and Lin, Chi and Grauman, Kristen and Luo, Jiebo and Bigham, Jeffrey P},
  booktitle={CVPR},
  pages={3608--3617},
  year={2018}
}

@article{carreira2018k600,
  title={A short note about kinetics-600},
  author={Carreira, Joao and Noland, Eric and Banki-Horvath, Andras and Hillier, Chloe and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1808.01340},
  year={2018}
}

@article{carreira2019k700,
  title={A short note on the kinetics-700 human action dataset},
  author={Carreira, Joao and Noland, Eric and Hillier, Chloe and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1907.06987},
  year={2019}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={ICML},
  pages={4904--4916},
  year={2021}
}

@misc{contributors2020mmsegmentation,
  title={MMSegmentation: Openmmlab semantic segmentation toolbox and benchmark},
  author={Contributors, MMSegmentation},
  year={2020}
}

@inproceedings{yang2020muse,
  title={Multilingual Universal Sentence Encoder for Semantic Retrieval},
  author={Yang, Yinfei and Cer, Daniel and Ahmad, Amin and Guo, Mandy and Law, Jax and Constant, Noah and Abrego, Gustavo Hernandez and Yuan, Steve and Tar, Chris and Sung, Yun-Hsuan and others},
  booktitle={ACL},
  pages={87--94},
  year={2020}
}

@inproceedings{zhai2022lit,
  title={Lit: Zero-shot transfer with locked-image text tuning},
  author={Zhai, Xiaohua and Wang, Xiao and Mustafa, Basil and Steiner, Andreas and Keysers, Daniel and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={CVPR},
  pages={18123--18133},
  year={2022}
}

@article{bai2023qwenvl,
  title={Qwen-vl: A frontier large vision-language model with versatile abilities},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}


@inproceedings{zhou2017ade20k,
  title={Scene parsing through ade20k dataset},
  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  booktitle={CVPR},
  pages={633--641},
  year={2017}
}

@inproceedings{touvron2022deit3,
  title={Deit iii: Revenge of the vit},
  author={Touvron, Hugo and Cord, Matthieu and J{\'e}gou, Herv{\'e}},
  booktitle={ECCV},
  pages={516--533},
  year={2022}
}

@inproceedings{dehghani2023vit22b,
  title={Scaling vision transformers to 22 billion parameters},
  author={Dehghani, Mostafa and Djolonga, Josip and Mustafa, Basil and Padlewski, Piotr and Heek, Jonathan and Gilmer, Justin and Steiner, Andreas Peter and Caron, Mathilde and Geirhos, Robert and Alabdulmohsin, Ibrahim and others},
  booktitle={ICML},
  pages={7480--7512},
  year={2023}
}

@inproceedings{carreira2017k400,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={CVPR},
  pages={6299--6308},
  year={2017}
}

@inproceedings{wang2023internvid,
  title={Internvid: A large-scale video-text dataset for multimodal understanding and generation},
  author={Wang, Yi and He, Yinan and Li, Yizhuo and Li, Kunchang and Yu, Jiashuo and Ma, Xin and Chen, Xinyuan and Wang, Yaohui and Luo, Ping and Liu, Ziwei and others},
  booktitle={ICLR},
  year={2024}
}

@article{yuan2021florence,
  title={Florence: A new foundation model for computer vision},
  author={Yuan, Lu and Chen, Dongdong and Chen, Yi-Ling and Codella, Noel and Dai, Xiyang and Gao, Jianfeng and Hu, Houdong and Huang, Xuedong and Li, Boxin and Li, Chunyuan and others},
  journal={arXiv preprint arXiv:2111.11432},
  year={2021}
}

@inproceedings{fei2004learning,
  title={Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories},
  author={Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
  booktitle={CVPRW},
  pages={178--178},
  year={2004}
}

@inproceedings{xiao2010sun,
  title={Sun database: Large-scale scene recognition from abbey to zoo},
  author={Xiao, Jianxiong and Hays, James and Ehinger, Krista A and Oliva, Aude and Torralba, Antonio},
  booktitle={CVPRW},
  pages={3485--3492},
  year={2010}
}

@inproceedings{berg2014birdsnap,
  title={Birdsnap: Large-scale fine-grained visual categorization of birds},
  author={Berg, Thomas and Liu, Jiongxin and Woo Lee, Seung and Alexander, Michelle L and Jacobs, David W and Belhumeur, Peter N},
  booktitle={CVPR},
  pages={2011--2018},
  year={2014}
}

@inproceedings{goodfellow2013fer2013,
  title={Challenges in representation learning: A report on three machine learning contests},
  author={Goodfellow, Ian J and Erhan, Dumitru and Carrier, Pierre Luc and Courville, Aaron and Mirza, Mehdi and Hamner, Ben and Cukierski, Will and Tang, Yichuan and Thaler, David and Lee, Dong-Hyun and others},
  booktitle={ICONIP},
  pages={117--124},
  year={2013}
}

@inproceedings{nilsback2008flowers,
  title={Automated flower classification over a large number of classes},
  author={Nilsback, Maria-Elena and Zisserman, Andrew},
  booktitle={ICVGIP},
  pages={722--729},
  year={2008}
}

@inproceedings{bossard2014food101,
  title={Food-101--mining discriminative components with random forests},
  author={Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
  booktitle={ECCV},
  pages={446--461},
  year={2014}
}

@article{stallkamp2012gtsrb,
  title={Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition},
  author={Stallkamp, Johannes and Schlipsing, Marc and Salmen, Jan and Igel, Christian},
  journal={Neural networks},
  volume={32},
  pages={323--332},
  year={2012},
  publisher={Elsevier}
}

@inproceedings{parkhi2012cats,
  title={Cats and dogs},
  author={Parkhi, Omkar M and Vedaldi, Andrea and Zisserman, Andrew and Jawahar, CV},
  booktitle={CVPR},
  pages={3498--3505},
  year={2012},
}


@inproceedings{coates2011stl10,
  title={An analysis of single-layer networks in unsupervised feature learning},
  author={Coates, Adam and Ng, Andrew and Lee, Honglak},
  booktitle={AISTAT},
  pages={215--223},
  year={2011}
}

@article{everingham2015pascal,
  title={The pascal visual object classes challenge: A retrospective},
  author={Everingham, Mark and Eslami, SM Ali and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal={IJCV},
  volume={111},
  pages={98--136},
  year={2015},
  publisher={Springer}
}

@article{cheng2017resisc45,
  title={Remote sensing image scene classification: Benchmark and state of the art},
  author={Cheng, Gong and Han, Junwei and Lu, Xiaoqiang},
  journal={Proceedings of the IEEE},
  volume={105},
  number={10},
  pages={1865--1883},
  year={2017},
  publisher={IEEE}
}

@article{helber2019eurosat,
  title={Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification},
  author={Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and Borth, Damian},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  volume={12},
  number={7},
  pages={2217--2226},
  year={2019},
  publisher={IEEE}
}

@inproceedings{krause2013cars,
  title={3d object representations for fine-grained categorization},
  author={Krause, Jonathan and Stark, Michael and Deng, Jia and Fei-Fei, Li},
  booktitle={ICCVW},
  pages={554--561},
  year={2013}
}

@inproceedings{cimpoi2014d2d,
  title={Describing textures in the wild},
  author={Cimpoi, Mircea and Maji, Subhransu and Kokkinos, Iasonas and Mohamed, Sammy and Vedaldi, Andrea},
  booktitle={CVPR},
  pages={3606--3613},
  year={2014}
}


@article{maji2013fgvc,
  title={Fine-grained visual classification of aircraft},
  author={Maji, Subhransu and Rahtu, Esa and Kannala, Juho and Blaschko, Matthew and Vedaldi, Andrea},
  journal={arXiv preprint arXiv:1306.5151},
  year={2013}
}

@article{yu2022coca,
  title={Coca: Contrastive captioners are image-text foundation models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}

@article{li2019cococn,
  title={COCO-CN for cross-lingual image tagging, captioning, and retrieval},
  author={Li, Xirong and Xu, Chaoxi and Wang, Xiaoxu and Lan, Weiyu and Jia, Zhengxiong and Yang, Gang and Xu, Jieping},
  journal={TMM},
  volume={21},
  number={9},
  pages={2347--2360},
  year={2019},
  publisher={IEEE}
}

@article{krizhevsky2009cifar,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and others},
  year={2009}
}

@article{lecun1998mnist,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998}
}

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={ICML},
  pages={448--456},
  year={2015}
}

@inproceedings{plummer2015flickr30k,
  title={Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models},
  author={Plummer, Bryan A and Wang, Liwei and Cervantes, Chris M and Caicedo, Juan C and Hockenmaier, Julia and Lazebnik, Svetlana},
  booktitle={ICCV},
  pages={2641--2649},
  year={2015}
}

@inproceedings{lan2017flickrcn,
  title={Fluency-guided cross-lingual image captioning},
  author={Lan, Weiyu and Li, Xirong and Dong, Jianfeng},
  booktitle={ACM MM},
  pages={1549--1557},
  year={2017}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{mmdetection,
  title   = {{MMDetection}: Open MMLab Detection Toolbox and Benchmark},
  author  = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and
             Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and
             Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and
             Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and
             Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong
             and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua},
  journal= {arXiv preprint arXiv:1906.07155},
  year={2019}
}

@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={ICCV},
  pages={2961--2969},
  year={2017}
}

@inproceedings{lin2017focal,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={ICCV},
  pages={2980--2988},
  year={2017}
}

@article{li2022uniformer,
  title={UniFormer: Unifying Convolution and Self-attention for Visual Recognition},
  author={Li, Kunchang and Wang, Yali and Zhang, Junhao and Gao, Peng and Song, Guanglu and Liu, Yu and Li, Hongsheng and Qiao, Yu},
  journal={arXiv preprint arXiv:2201.09450},
  year={2022}
}

@article{yang2021focal,
  title={Focal self-attention for local-global interactions in vision transformers},
  author={Yang, Jianwei and Li, Chunyuan and Zhang, Pengchuan and Dai, Xiyang and Xiao, Bin and Yuan, Lu and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2107.00641},
  year={2021}
}

@article{huang2021shuffle,
  title={Shuffle transformer: Rethinking spatial shuffle for vision transformer},
  author={Huang, Zilong and Ben, Youcheng and Luo, Guozhong and Cheng, Pei and Yu, Gang and Fu, Bin},
  journal={arXiv preprint arXiv:2106.03650},
  year={2021}
}

@article{steiner2021train,
  title={How to train your vit? data, augmentation, and regularization in vision transformers},
  author={Steiner, Andreas and Kolesnikov, Alexander and Zhai, Xiaohua and Wightman, Ross and Uszkoreit, Jakob and Beyer, Lucas},
  journal={arXiv preprint arXiv:2106.10270},
  year={2021}
}

@inproceedings{he2019rethinking,
  title={Rethinking imagenet pre-training},
  author={He, Kaiming and Girshick, Ross and Doll{\'a}r, Piotr},
  booktitle={ICCV},
  pages={4918--4927},
  year={2019}
}

@inproceedings{hu2018senet,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={CVPR},
  pages={7132--7141},
  year={2018}
}

@inproceedings{dai2017deformable,
  title={Deformable convolutional networks},
  author={Dai, Jifeng and Qi, Haozhi and Xiong, Yuwen and Li, Yi and Zhang, Guodong and Hu, Han and Wei, Yichen},
  booktitle={ICCV},
  pages={764--773},
  year={2017}
}

@inproceedings{ding2021repvgg,
  title={Repvgg: Making vgg-style convnets great again},
  author={Ding, Xiaohan and Zhang, Xiangyu and Ma, Ningning and Han, Jungong and Ding, Guiguang and Sun, Jian},
  booktitle={CVPR},
  pages={13733--13742},
  year={2021}
}

@inproceedings{ghiasi2021simple,
  title={Simple copy-paste is a strong data augmentation method for instance segmentation},
  author={Ghiasi, Golnaz and Cui, Yin and Srinivas, Aravind and Qian, Rui and Lin, Tsung-Yi and Cubuk, Ekin D and Le, Quoc V and Zoph, Barret},
  booktitle={CVPR},
  pages={2918--2928},
  year={2021}
}

@article{iandola2014densenet,
  title={Densenet: Implementing efficient convnet descriptor pyramids},
  author={Iandola, Forrest and Moskewicz, Matt and Karayev, Sergey and Girshick, Ross and Darrell, Trevor and Keutzer, Kurt},
  journal={arXiv preprint arXiv:1404.1869},
  year={2014}
}

@article{chu2021twins,
  title={Twins: Revisiting the design of spatial attention in vision transformers},
  author={Chu, Xiangxiang and Tian, Zhi and Wang, Yuqing and Zhang, Bo and Ren, Haibing and Wei, Xiaolin and Xia, Huaxia and Shen, Chunhua},
  journal={NeurIPS},
  volume={34},
  year={2021}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={NeurIPS},
  volume={30},
  year={2017}
}

@article{zhu2021uni,
  title={Uni-Perceiver: Pre-training Unified Architecture for Generic Perception for Zero-shot and Few-shot Tasks},
  author={Zhu, Xizhou and Zhu, Jinguo and Li, Hao and Wu, Xiaoshi and Wang, Xiaogang and Li, Hongsheng and Wang, Xiaohua and Dai, Jifeng},
  journal={arXiv preprint arXiv:2112.01522},
  year={2021}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={CVPR},
  pages={248--255},
  year={2009}
}

@inproceedings{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={NAACL},
  pages={4171--4186},
  year={2019}
}


@article{baevski2022data2vec,
  title={Data2vec: A general framework for self-supervised learning in speech, vision and language},
  author={Baevski, Alexei and Hsu, Wei-Ning and Xu, Qiantong and Babu, Arun and Gu, Jiatao and Auli, Michael},
  journal={arXiv preprint arXiv:2202.03555},
  year={2022}
}

@article{cui2023chinesellama,
  title={Efficient and effective text encoding for chinese llama and alpaca},
  author={Cui, Yiming and Yang, Ziqing and Yao, Xin},
  journal={arXiv preprint arXiv:2304.08177},
  year={2023}
}

@inproceedings{xie2017aggregated,
  title={Aggregated residual transformations for deep neural networks},
  author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle={CVPR},
  pages={1492--1500},
  year={2017}
}

@article{taori2023alpaca,
  title={Alpaca: A strong, replicable instruction-following model},
  author={Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
  journal={Stanford Center for Research on Foundation Models. https://crfm. stanford. edu/2023/03/13/alpaca. html},
  volume={3},
  number={6},
  pages={7},
  year={2023}
}

@inproceedings{jaegle2021perceiver,
  title={Perceiver: General perception with iterative attention},
  author={Jaegle, Andrew and Gimeno, Felix and Brock, Andy and Vinyals, Oriol and Zisserman, Andrew and Carreira, Joao},
  booktitle={ICML},
  pages={4651--4664},
  year={2021}
}

@article{fedus2022switch,
  title={Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
  author={Fedus, William and Zoph, Barret and Shazeer, Noam},
  journal={JMLR},
  volume={23},
  number={1},
  pages={5232--5270},
  year={2022},
  publisher={JMLRORG}
}


@article{girdhar2022omnivore,
  title={Omnivore: A Single Model for Many Visual Modalities},
  author={Girdhar, Rohit and Singh, Mannat and Ravi, Nikhila and van der Maaten, Laurens and Joulin, Armand and Misra, Ishan},
  journal={arXiv preprint arXiv:2201.08377},
  year={2022}
}


@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={NeurIPS},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{lewis2019bart,
  title={Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1910.13461},
  year={2019}
}

@article{raffel2019exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={arXiv preprint arXiv:1910.10683},
  year={2019}
}

@article{smith2022using,
  title={Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model},
  author={Smith, Shaden and Patwary, Mostofa and Norick, Brandon and LeGresley, Patrick and Rajbhandari, Samyam and Casper, Jared and Liu, Zhun and Prabhumoye, Shrimai and Zerveas, George and Korthikanti, Vijay and others},
  journal={arXiv preprint arXiv:2201.11990},
  year={2022}
}

@inproceedings{stickland2019bert,
  title={Bert and pals: Projected attention layers for efficient adaptation in multi-task learning},
  author={Stickland, Asa Cooper and Murray, Iain},
  booktitle={ICML},
  pages={5986--5995},
  year={2019}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={ICML},
  pages={2790--2799},
  year={2019}
}

@article{sung2021vl,
  title={VL-Adapter: Parameter-Efficient Transfer Learning for Vision-and-Language Tasks},
  author={Sung, Yi-Lin and Cho, Jaemin and Bansal, Mohit},
  journal={arXiv preprint arXiv:2112.06825},
  year={2021}
}

@inproceedings{strudel2021segmenter,
  title={Segmenter: Transformer for semantic segmentation},
  author={Strudel, Robin and Garcia, Ricardo and Laptev, Ivan and Schmid, Cordelia},
  booktitle={ICCV},
  pages={7262--7272},
  year={2021}
}

@inproceedings{ranftl2021vision,
  title={Vision transformers for dense prediction},
  author={Ranftl, Ren{\'e} and Bochkovskiy, Alexey and Koltun, Vladlen},
  booktitle={ICCV},
  pages={12179--12188},
  year={2021}
}

@inproceedings{zheng2021rethinking,
  title={Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers},
  author={Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others},
  booktitle={CVPR},
  pages={6881--6890},
  year={2021}
}

@inproceedings{xu2021co,
  title={Co-scale conv-attentional image transformers},
  author={Xu, Weijian and Xu, Yifan and Chang, Tyler and Tu, Zhuowen},
  booktitle={ICCV},
  pages={9981--9990},
  year={2021}
}

@article{han2021transformer,
  title={Transformer in transformer},
  author={Han, Kai and Xiao, An and Wu, Enhua and Guo, Jianyuan and Xu, Chunjing and Wang, Yunhe},
  journal={NeurIPS},
  volume={34},
  year={2021}
}

@article{li2021localvit,
  title={Localvit: Bringing locality to vision transformers},
  author={Li, Yawei and Zhang, Kai and Cao, Jiezhang and Timofte, Radu and Van Gool, Luc},
  journal={arXiv preprint arXiv:2104.05707},
  year={2021}
}

@article{liu2021video,
  title={Video swin transformer},
  author={Liu, Ze and Ning, Jia and Cao, Yue and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Hu, Han},
  journal={arXiv preprint arXiv:2106.13230},
  year={2021}
}

@article{liu2021swinv2,
  title={Swin Transformer V2: Scaling Up Capacity and Resolution},
  author={Liu, Ze and Hu, Han and Lin, Yutong and Yao, Zhuliang and Xie, Zhenda and Wei, Yixuan and Ning, Jia and Cao, Yue and Zhang, Zheng and Dong, Li and others},
  journal={arXiv preprint arXiv:2111.09883},
  year={2021}
}


@article{zhang2021tip,
  title={Tip-Adapter: Training-free CLIP-Adapter for Better Vision-Language Modeling},
  author={Zhang, Renrui and Fang, Rongyao and Gao, Peng and Zhang, Wei and Li, Kunchang and Dai, Jifeng and Qiao, Yu and Li, Hongsheng},
  journal={arXiv preprint arXiv:2111.03930},
  year={2021}
}

@article{gao2021clip,
  title={Clip-adapter: Better vision-language models with feature adapters},
  author={Gao, Peng and Geng, Shijie and Zhang, Renrui and Ma, Teli and Fang, Rongyao and Zhang, Yongfeng and Li, Hongsheng and Qiao, Yu},
  journal={arXiv preprint arXiv:2110.04544},
  year={2021}
}


@inproceedings{lin2017feature,
  title={Feature pyramid networks for object detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={CVPR},
  pages={2117--2125},
  year={2017}
}


@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv:2205.01068},
  year={2022}
}


@inproceedings{li2021panoptic,
  title={Panoptic SegFormer: Delving Deeper into Panoptic Segmentation with Transformers},
  author={Li, Zhiqi and Wang, Wenhai and Xie, Enze and Yu, Zhiding and Anandkumar, Anima and Alvarez, Jose M and Lu, Tong and Luo, Ping},
  booktitle={CVPR},
  year={2022}
}

@article{ali2021xcit,
  title={Xcit: Cross-covariance image transformers},
  author={Ali, Alaaeldin and Touvron, Hugo and Caron, Mathilde and Bojanowski, Piotr and Douze, Matthijs and Joulin, Armand and Laptev, Ivan and Neverova, Natalia and Synnaeve, Gabriel and Verbeek, Jakob and others},
  journal={NeurIPS},
  volume={34},
  year={2021}
}

@article{rosenfeld2018incremental,
  title={Incremental learning through deep adaptation},
  author={Rosenfeld, Amir and Tsotsos, John K},
  journal={TPAMI},
  volume={42},
  number={3},
  pages={651--663},
  year={2018}
}

@inproceedings{rebuffi2018efficient,
  title={Efficient parametrization of multi-domain deep neural networks},
  author={Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
  booktitle={CVPR},
  pages={8119--8127},
  year={2018}
}

@article{rebuffi2017learning,
  title={Learning multiple visual domains with residual adapters},
  author={Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
  journal={NeurIPS},
  volume={30},
  year={2017}
}

@article{chen2021simple,
  title={A Simple Single-Scale Vision Transformer for Object Localization and Instance Segmentation},
  author={Chen, Wuyang and Du, Xianzhi and Yang, Fan and Beyer, Lucas and Zhai, Xiaohua and Lin, Tsung-Yi and Chen, Huizhong and Li, Jing and Song, Xiaodan and Wang, Zhangyang and others},
  journal={arXiv preprint arXiv:2112.09747},
  year={2021}
}

@inproceedings{bolya2020tide,
  title={Tide: A general toolbox for identifying object detection errors},
  author={Bolya, Daniel and Foley, Sean and Hays, James and Hoffman, Judy},
  booktitle={ECCV},
  pages={558--573},
  year={2020}
}

@inproceedings{kamann2020benchmarking,
  title={Benchmarking the robustness of semantic segmentation models},
  author={Kamann, Christoph and Rother, Carsten},
  booktitle={CVPR},
  pages={8828--8838},
  year={2020}
}

@article{michaelis2019benchmarking,
  title={Benchmarking robustness in object detection: Autonomous driving when winter is coming},
  author={Michaelis, Claudio and Mitzkus, Benjamin and Geirhos, Robert and Rusak, Evgenia and Bringmann, Oliver and Ecker, Alexander S and Bethge, Matthias and Brendel, Wieland},
  journal={arXiv preprint arXiv:1907.07484},
  year={2019}
}

@inproceedings{bao2021beit,
  title={Beit: Bert pre-training of image transformers},
  author={Bao, Hangbo and Dong, Li and Wei, Furu},
  booktitle={ICLR},
  year={2022}
}

@article{peng2022beitv2,
  title={BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers},
  author={Peng, Zhiliang and Dong, Li and Bao, Hangbo and Ye, Qixiang and Wei, Furu},
  journal={arXiv preprint arXiv:2208.06366},
  year={2022}
}

@inproceedings{peng2021conformer,
  title={Conformer: Local features coupling global representations for visual recognition},
  author={Peng, Zhiliang and Huang, Wei and Gu, Shanzhi and Xie, Lingxi and Wang, Yaowei and Jiao, Jianbin and Ye, Qixiang},
  booktitle={ICCV},
  pages={367--376},
  year={2021}
}

@article{cheng2021masked,
  title={Masked-attention mask transformer for universal image segmentation},
  author={Cheng, Bowen and Misra, Ishan and Schwing, Alexander G and Kirillov, Alexander and Girdhar, Rohit},
  journal={arXiv preprint arXiv:2112.01527},
  year={2021}
}

@inproceedings{huang2021fapn,
  title={FaPN: Feature-aligned pyramid network for dense image prediction},
  author={Huang, Shihua and Lu, Zhichao and Cheng, Ran and He, Cheng},
  booktitle={ICCV},
  pages={864--873},
  year={2021}
}

@article{jain2021semask,
  title={SeMask: Semantically Masked Transformers for Semantic Segmentation},
  author={Jain, Jitesh and Singh, Anukriti and Orlov, Nikita and Huang, Zilong and Li, Jiachen and Walton, Steven and Shi, Humphrey},
  journal={arXiv preprint arXiv:2112.12782},
  year={2021}
}

@article{cui2022region,
  title={Region Rebalance for Long-Tailed Semantic Segmentation},
  author={Cui, Jiequan and Yuan, Yuhui and Zhong, Zhisheng and Tian, Zhuotao and Hu, Han and Lin, Stephen and Jia, Jiaya},
  journal={arXiv preprint arXiv:2204.01969},
  year={2022}
}


@inproceedings{fang2019instaboost,
  title={Instaboost: Boosting instance segmentation via probability map guided copy-pasting},
  author={Fang, Hao-Shu and Sun, Jianhua and Wang, Runzhong and Gou, Minghao and Li, Yong-Lu and Lu, Cewu},
  booktitle={ICCV},
  pages={682--691},
  year={2019}
}

@article{liang2021cbnetv2,
  title={Cbnetv2: A composite backbone network architecture for object detection},
  author={Liang, Tingting and Chu, Xiaojie and Liu, Yudong and Wang, Yongtao and Tang, Zhi and Chu, Wei and Chen, Jingdong and Ling, Haibin},
  journal={arXiv preprint arXiv:2107.00420},
  year={2021}
}

@inproceedings{caesar2018coco,
  title={Coco-stuff: Thing and stuff classes in context},
  author={Caesar, Holger and Uijlings, Jasper and Ferrari, Vittorio},
  booktitle={CVPR},
  pages={1209--1218},
  year={2018}
}

@inproceedings{Cordts_2016_CVPR,
    author = {Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
    title = {The Cityscapes Dataset for Semantic Urban Scene Understanding},
    booktitle = {CVPR},
    year = {2016}
}

@inproceedings{neuhold2017mapillary,
  title={The mapillary vistas dataset for semantic understanding of street scenes},
  author={Neuhold, Gerhard and Ollmann, Tobias and Rota Bulo, Samuel and Kontschieder, Peter},
  booktitle={ICCV},
  pages={4990--4999},
  year={2017}
}

@article{tao2020hierarchical,
  title={Hierarchical multi-scale attention for semantic segmentation},
  author={Tao, Andrew and Sapra, Karan and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:2005.10821},
  year={2020}
}

@inproceedings{yuan2019segmentation,
  title={Segmentation transformer: Object-contextual representations for semantic segmentation},
  author={Yuan, Yuhui and Chen, Xiaokang and Chen, Xilin and Wang, Jingdong},
  booktitle={ECCV},
  year={2020}
}

@article{bousselham2021efficient,
  title={Efficient Self-Ensemble Framework for Semantic Segmentation},
  author={Bousselham, Walid and Thibault, Guillaume and Pagano, Lucas and Machireddy, Archana and Gray, Joe and Chang, Young Hwan and Song, Xubo},
  journal={arXiv preprint arXiv:2111.13280},
  year={2021}
}

@article{huang2021channelized,
  title={Channelized Axial Attention for Semantic Segmentation--Considering Channel Relation within Spatial Attention for Semantic Segmentation},
  author={Huang, Ye and Kang, Di and Jia, Wenjing and He, Xiangjian and Liu, Liu},
  journal={arXiv preprint arXiv:2101.07434},
  year={2021}
}

@article{lin2022structtoken,
  title={StructToken: Rethinking Semantic Segmentation with Structural Prior},
  author={Lin, Fangjian and Liang, Zhanhao and He, Junjun and Zheng, Miao and Tian, Shengwei and Chen, Kai},
  journal={arXiv preprint arXiv:2203.12612},
  year={2022}
}

@article{huang2022car,
  title={CAR: Class-aware Regularizations for Semantic Segmentation},
  author={Huang, Ye and Kang, Di and Chen, Liang and Zhe, Xuefei and Jia, Wenjing and He, Xiangjian and Bao, Linchao},
  journal={arXiv preprint arXiv:2203.07160},
  year={2022}
}

@inproceedings{mottaghi2014role,
  title={The role of context for object detection and semantic segmentation in the wild},
  author={Mottaghi, Roozbeh and Chen, Xianjie and Liu, Xiaobai and Cho, Nam-Gyu and Lee, Seong-Whan and Fidler, Sanja and Urtasun, Raquel and Yuille, Alan},
  booktitle={CVPR},
  pages={891--898},
  year={2014}
}

@inproceedings{chen2019hybrid,
  title={Hybrid task cascade for instance segmentation},
  author={Chen, Kai and Pang, Jiangmiao and Wang, Jiaqi and Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and Liu, Ziwei and Shi, Jianping and Ouyang, Wanli and others},
  booktitle={CVPR},
  pages={4974--4983},
  year={2019}
}

@inproceedings{dai2021dynamic,
  title={Dynamic head: Unifying object detection heads with attentions},
  author={Dai, Xiyang and Chen, Yinpeng and Xiao, Bin and Chen, Dongdong and Liu, Mengchen and Yuan, Lu and Zhang, Lei},
  booktitle={CVPR},
  pages={7373--7382},
  year={2021}
}

@inproceedings{li2021improved,
  title={Mvitv2: Improved multiscale vision transformers for classification and detection},
  author={Li, Yanghao and Wu, Chao-Yuan and Fan, Haoqi and Mangalam, Karttikeya and Xiong, Bo and Malik, Jitendra and Feichtenhofer, Christoph},
  booktitle={CVPR},
  pages={4804--4814},
  year={2022}
}

@article{zhu2022uni,
  title={Uni-Perceiver-MoE: Learning Sparse Generalist Models with Conditional MoEs},
  author={Zhu, Jinguo and Zhu, Xizhou and Wang, Wenhai and Wang, Xiaohua and Li, Hongsheng and Wang, Xiaogang and Dai, Jifeng},
  journal={arXiv preprint arXiv:2206.04674},
  year={2022}
}

@article{wu2022p2t,
  title={P2T: Pyramid pooling transformer for scene understanding},
  author={Wu, Yu-Huan and Liu, Yun and Zhan, Xin and Cheng, Ming-Ming},
  journal={TPAMI},
  year={2022}
}


@article{fang2022unleashing,
  title={Unleashing vanilla vision transformer with masked image modeling for object detection},
  author={Fang, Yuxin and Yang, Shusheng and Wang, Shijie and Ge, Yixiao and Shan, Ying and Wang, Xinggang},
  journal={arXiv preprint arXiv:2204.02964},
  year={2022}
}

@article{li2022exploring,
  title={Exploring plain vision transformer backbones for object detection},
  author={Li, Yanghao and Mao, Hanzi and Girshick, Ross and He, Kaiming},
  journal={arXiv preprint arXiv:2203.16527},
  year={2022}
}

@article{park2022vision,
  title={How Do Vision Transformers Work?},
  author={Park, Namuk and Kim, Songkuk},
  journal={arXiv preprint arXiv:2202.06709},
  year={2022}
}

@article{si2022inception,
  title={Inception Transformer},
  author={Si, Chenyang and Yu, Weihao and Zhou, Pan and Zhou, Yichen and Wang, Xinchao and Yan, Shuicheng},
  journal={arXiv preprint arXiv:2205.12956},
  year={2022}
}

@inproceedings{wu2022pale,
  title={Pale transformer: A general vision transformer backbone with pale-shaped attention},
  author={Wu, Sitong and Wu, Tianyi and Tan, Haoru and Guo, Guodong},
  booktitle={AAAI},
  volume={36},
  number={3},
  pages={2731--2739},
  year={2022}
}

@inproceedings{shao2019objects365,
  title={Objects365: A large-scale, high-quality dataset for object detection},
  author={Shao, Shuai and Li, Zeming and Zhang, Tianyuan and Peng, Chao and Yu, Gang and Zhang, Xiangyu and Li, Jing and Sun, Jian},
  booktitle={ICCV},
  pages={8430--8439},
  year={2019}
}

@inproceedings{bodla2017soft,
  title={Soft-NMS--improving object detection with one line of code},
  author={Bodla, Navaneeth and Singh, Bharat and Chellappa, Rama and Davis, Larry S},
  booktitle={ICCV},
  pages={5561--5569},
  year={2017}
}

@article{rao2022hornet,
  title={HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions},
  author={Rao, Yongming and Zhao, Wenliang and Tang, Yansong and Zhou, Jie and Lim, Ser-Nam and Lu, Jiwen},
  journal={arXiv preprint arXiv:2207.14284},
  year={2022}
}

@article{li2022maskdino,
  title={Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation},
  author={Li, Feng and Zhang, Hao and Liu, Shilong and Zhang, Lei and Ni, Lionel M and Shum, Heung-Yeung and others},
  journal={arXiv preprint arXiv:2206.02777},
  year={2022}
}

@article{wei2022kdswin,
  title={Contrastive Learning Rivals Masked Image Modeling in Fine-tuning via Feature Distillation},
  author={Wei, Yixuan and Hu, Han and Xie, Zhenda and Zhang, Zheng and Cao, Yue and Bao, Jianmin and Chen, Dong and Guo, Baining},
  journal={arXiv preprint arXiv:2205.14141},
  year={2022}
}



@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}


@article{jia2022visual,
  title={Visual prompt tuning},
  author={Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  journal={arXiv preprint arXiv:2203.12119},
  year={2022}
}

@article{bahng2022exploring,
  title={Exploring visual prompts for adapting large-scale models},
  author={Bahng, Hyojin and Jahanian, Ali and Sankaranarayanan, Swami and Isola, Phillip},
  journal={arXiv preprint arXiv:2203.17274},
  volume={1},
  number={3},
  pages={4},
  year={2022}
}

@article{chen2022adaptformer,
  title={AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition},
  author={Chen, Shoufa and Ge, Chongjian and Tong, Zhan and Wang, Jiangliu and Song, Yibing and Wang, Jue and Luo, Ping},
  journal={arXiv preprint arXiv:2205.13535},
  year={2022}
}

@inproceedings{japanese-clip,
  author={Makoto Shiin, Tianyu Zhao, Kei Sawada},
  title={Construction and Public Release of Language Image Pretraining Models in Japanese},
  booktitle={MIRU},
  year={2022}
}

@inproceedings{carlsson2022mclip,
  title={Cross-lingual and multilingual clip},
  author={Carlsson, Fredrik and Eisen, Philipp and Rekathati, Faton and Sahlgren, Magnus},
  booktitle={LREC},
  pages={6848--6854},
  year={2022}
}

@inproceedings{hendrycks2021imagenet_a,
  title={Natural adversarial examples},
  author={Hendrycks, Dan and Zhao, Kevin and Basart, Steven and Steinhardt, Jacob and Song, Dawn},
  booktitle={CVPR},
  pages={15262--15271},
  year={2021}
}

@article{aggarwal2020xtd,
  title={Towards zero-shot Cross-lingual Image retrieval},
  author={Aggarwal, Pranav and Kale, Ajinkya},
  journal={arXiv preprint arXiv:2012.05107},
  year={2020}
}

@article{jain2021mural,
  title={Mural: multimodal, multitask retrieval across languages},
  author={Jain, Aashi and Guo, Mandy and Srinivasan, Krishna and Chen, Ting and Kudugunta, Sneha and Jia, Chao and Yang, Yinfei and Baldridge, Jason},
  journal={arXiv preprint arXiv:2109.05125},
  year={2021}
}

@article{wang2019imagenet_sketch,
  title={Learning robust global representations by penalizing local predictive power},
  author={Wang, Haohan and Ge, Songwei and Lipton, Zachary and Xing, Eric P},
  journal={NeurIPS},
  volume={32},
  year={2019}
}

@inproceedings{recht2019imagenetv2,
  title={Do imagenet classifiers generalize to imagenet?},
  author={Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  booktitle={ICML},
  pages={5389--5400},
  year={2019}
}

@article{barbu2019objectnet,
  title={Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models},
  author={Barbu, Andrei and Mayo, David and Alverio, Julian and Luo, William and Wang, Christopher and Gutfreund, Dan and Tenenbaum, Josh and Katz, Boris},
  journal={NeurIPS},
  volume={32},
  year={2019}
}

@article{huang2023kosmos1,
  title={Language is not all you need: Aligning perception with language models},
  author={Huang, Shaohan and Dong, Li and Wang, Wenhui and Hao, Yaru and Singhal, Saksham and Ma, Shuming and Lv, Tengchao and Cui, Lei and Mohammed, Owais Khan and Liu, Qiang and others},
  journal={arXiv preprint arXiv:2302.14045},
  year={2023}
}

@article{wang2021simvlm,
  title={Simvlm: Simple visual language model pretraining with weak supervision},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  journal={arXiv preprint arXiv:2108.10904},
  year={2021}
}

@inproceedings{sun2023emu,
  title={Generative pretraining in multimodality},
  author={Sun, Quan and Yu, Qiying and Cui, Yufeng and Zhang, Fan and Zhang, Xiaosong and Wang, Yueze and Gao, Hongcheng and Liu, Jingjing and Huang, Tiejun and Wang, Xinlong},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{dong2023dreamllm,
  title={DreamLLM: Synergistic Multimodal Comprehension and Creation},
  author={Dong, Runpei and Han, Chunrui and Peng, Yuang and Qi, Zekun and Ge, Zheng and Yang, Jinrong and Zhao, Liang and Sun, Jianjian and Zhou, Hongyu and Wei, Haoran and others},
  booktitle={ICLR},
  year={2024}
}


@article{instructblip,
  title={Instructblip: Towards general-purpose vision-language models with instruction tuning},
  author={Dai, Wenliang and Li, Junnan and Li, Dongxu and Tiong, Anthony Meng Huat and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale N and Hoi, Steven},
  journal={NeurIPS},
  volume={36},
  year={2024}
}


@article{chen2023shikra,
  title={Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic},
  author={Chen, Keqin and Zhang, Zhao and Zeng, Weili and Zhang, Richong and Zhu, Feng and Zhao, Rui},
  journal={arXiv preprint arXiv:2306.15195},
  year={2023}
}

@inproceedings{wang2023allseeing,
  title={The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World},
  author={Wang, Weiyun and Shi, Min and Li, Qingyun and Wang, Wenhai and Huang, Zhenhang and Xing, Linjie and Chen, Zhe and Li, Hao and Zhu, Xizhou and Cao, Zhiguo and others},
  booktitle={ICLR},
  year={2024}
}

@article{zeng2022socratic,
	author = {Zeng, Andy and Attarian, Maria and Ichter, Brian and Choromanski, Krzysztof and Wong, Adrian and Welker, Stefan and Tombari, Federico and Purohit, Aveek and Ryoo, Michael and Sindhwani, Vikas and others},
	journal = {arXiv preprint arXiv:2204.00598},
	title = {Socratic models: Composing zero-shot multimodal reasoning with language},
	year = {2022}}

@article{peng2023kosmos2,
  title={Kosmos-2: Grounding Multimodal Large Language Models to the World},
  author={Peng, Zhiliang and Wang, Wenhui and Dong, Li and Hao, Yaru and Huang, Shaohan and Ma, Shuming and Wei, Furu},
  journal={arXiv preprint arXiv:2306.14824},
  year={2023}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={NeurIPS},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{hao2022metavlm,
  title={Language models are general-purpose interfaces},
  author={Hao, Yaru and Song, Haoyu and Dong, Li and Huang, Shaohan and Chi, Zewen and Wang, Wenhui and Ma, Shuming and Wei, Furu},
  journal={arXiv preprint arXiv:2206.06336},
  year={2022}
}

@inproceedings{hendrycks2021imagenet_r,
  title={The many faces of robustness: A critical analysis of out-of-distribution generalization},
  author={Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and others},
  booktitle={ICCV},
  pages={8340--8349},
  year={2021}
}

@article{bianchi2021clip_italian,
  title={Contrastive Language-Image Pre-training for the Italian Language},
  author={Bianchi, Federico and Attanasio, Giuseppe and Pisoni, Raphael and Terragni, Silvia and Sarti, Gabriele and Lakshmi, Sri},
  journal={arXiv preprint arXiv:2108.08688},
  year={2021}
}


@article{yang2022cnclip,
  title={Chinese clip: Contrastive vision-language pretraining in chinese},
  author={Yang, An and Pan, Junshu and Lin, Junyang and Men, Rui and Zhang, Yichang and Zhou, Jingren and Zhou, Chang},
  journal={arXiv preprint arXiv:2211.01335},
  year={2022}
}

@article{zhang2022neural,
  title={Neural Prompt Search},
  author={Zhang, Yuanhan and Zhou, Kaiyang and Liu, Ziwei},
  journal={arXiv preprint arXiv:2206.04673},
  year={2022}
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={ICML},
  pages={12888--12900},
  year={2022}
}

@inproceedings{li2023blip2,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={ICML},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}


@inproceedings{wang2023beit3,
  title={Image as a Foreign Language: BEiT Pretraining for Vision and Vision-Language Tasks},
  author={Wang, Wenhui and Bao, Hangbo and Dong, Li and Bjorck, Johan and Peng, Zhiliang and Liu, Qiang and Aggarwal, Kriti and Mohammed, Owais Khan and Singhal, Saksham and Som, Subhojit and others},
  booktitle={CVPR},
  pages={19175--19186},
  year={2023}
}

@article{li2021albef,
  title={Align before fuse: Vision and language representation learning with momentum distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
  journal={NeurIPS},
  volume={34},
  pages={9694--9705},
  year={2021}
}

@article{xu2023lvlm,
  title={Lvlm-ehub: A comprehensive evaluation benchmark for large vision-language models},
  author={Xu, Peng and Shao, Wenqi and Zhang, Kaipeng and Gao, Peng and Liu, Shuo and Lei, Meng and Meng, Fanqing and Huang, Siyuan and Qiao, Yu and Luo, Ping},
  journal={arXiv preprint arXiv:2306.09265},
  year={2023}
}

@article{zeng2023lynx,
  title={What Matters in Training a GPT4-Style Language Model with Multimodal Inputs?},
  author={Zeng, Yan and Zhang, Hanbo and Zheng, Jiani and Xia, Jiangnan and Wei, Guoqiang and Wei, Yang and Zhang, Yuchen and Kong, Tao},
  journal={arXiv preprint arXiv:2307.02469},
  year={2023}
}

@article{shao2023tiny,
  title={Tiny lvlm-ehub: Early multimodal experiments with bard},
  author={Shao, Wenqi and Hu, Yutao and Gao, Peng and Lei, Meng and Zhang, Kaipeng and Meng, Fanqing and Xu, Peng and Huang, Siyuan and Li, Hongsheng and Qiao, Yu and others},
  journal={arXiv preprint arXiv:2308.03729},
  year={2023}
}

@misc{liu2024llavanext,
    title={LLaVA-NeXT: Improved reasoning, OCR, and world knowledge},
    url={https://llava-vl.github.io/blog/2024-01-30-llava-next/},
    author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
    month={January},
    year={2024}
}


@article{jie2022convolutional,
  title={Convolutional bypasses are better vision transformer adapters},
  author={Jie, Shibo and Deng, Zhi-Hong},
  journal={arXiv preprint arXiv:2207.07039},
  year={2022}
}

@inproceedings{fang2022eva,
  title={EVA: Exploring the Limits of Masked Visual Representation Learning at Scale},
  author={Fang, Yuxin and Wang, Wen and Xie, Binhui and Sun, Quan and Wu, Ledell and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},
  booktitle={CVPR},
  pages={19358--19369},
  year={2023}
}

@article{liu2023llava,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={NeurIPS},
  volume={36},
  year={2023}
}

@article{liu2023ocrbench,
  title={On the hidden mystery of ocr in large multimodal models},
  author={Liu, Yuliang and Li, Zhang and Li, Hongliang and Yu, Wenwen and Huang, Mingxin and Peng, Dezhi and Liu, Mingyu and Chen, Mingrui and Li, Chunyuan and Jin, Lianwen and others},
  journal={arXiv preprint arXiv:2305.07895},
  year={2023}
}


@inproceedings{mathew2021docvqa,
  title={Docvqa: A dataset for vqa on document images},
  author={Mathew, Minesh and Karatzas, Dimosthenis and Jawahar, CV},
  booktitle={WACV},
  pages={2200--2209},
  year={2021}
}

@article{wang2023visionllm,
  title={Visionllm: Large language model is also an open-ended decoder for vision-centric tasks},
  author={Wang, Wenhai and Chen, Zhe and Chen, Xiaokang and Wu, Jiannan and Zhu, Xizhou and Zeng, Gang and Luo, Ping and Lu, Tong and Zhou, Jie and Qiao, Yu and others},
  journal={NeurIPS},
  volume={36},
  year={2023}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{zhang2022rest,
  title={Rest v2: simpler, faster and stronger},
  author={Zhang, Qinglong and Yang, Yu-Bin},
  journal={NeurIPS},
  volume={35},
  pages={36440--36452},
  year={2022}
}

@article{zhang2021rest,
  title={Rest: An efficient transformer for visual recognition},
  author={Zhang, Qinglong and Yang, Yu-Bin},
  journal={NeurIPS},
  volume={34},
  pages={15475--15485},
  year={2021}
}

@article{fang2023eva02,
  title={Eva-02: A visual representation for neon genesis},
  author={Fang, Yuxin and Sun, Quan and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},
  journal={arXiv preprint arXiv:2303.11331},
  year={2023}
}

@Misc{xFormers2022,
  author =       {Benjamin Lefaudeux and Francisco Massa and Diana Liskovich and Wenhan Xiong and Vittorio Caggiano and Sean Naren and Min Xu and Jieru Hu and Marta Tintore and Susan Zhang and Patrick Labatut and Daniel Haziza},
  title =        {xFormers: A modular and hackable Transformer modelling library},
  howpublished = {\url{https://github.com/facebookresearch/xformers}},
  year =         {2022}
}

@article{dao2022flashattention,
  title={Flashattention: Fast and memory-efficient exact attention with io-awareness},
  author={Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={NeurIPS},
  volume={35},
  pages={16344--16359},
  year={2022}
}


@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={NeurIPS},
  volume={25},
  year={2012}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={NeurIPS},
  volume={35},
  pages={24824--24837},
  year={2022}
}


@article{openai2023gpt4,
  author       = {OpenAI},
  title        = {{GPT-4} Technical Report},
  journal      = {CoRR},
  volume       = {abs/2303.08774},
  year         = {2023}
}

@article{wei2022emergent,
  author       = {Jason Wei and
                  Yi Tay and
                  Rishi Bommasani and
                  Colin Raffel and
                  Barret Zoph and
                  Sebastian Borgeaud and
                  Dani Yogatama and
                  Maarten Bosma and
                  Denny Zhou and
                  Donald Metzler and
                  Ed H. Chi and
                  Tatsunori Hashimoto and
                  Oriol Vinyals and
                  Percy Liang and
                  Jeff Dean and
                  William Fedus},
  title        = {Emergent Abilities of Large Language Models},
  journal      = {Trans. Mach. Learn. Res.},
  volume       = {2022},
  year         = {2022}
}

@article{touvron2023llama2,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}



@article{schuhmann2022laion5b,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={NeurIPS},
  volume={35},
  pages={25278--25294},
  year={2022}
}

@misc{byeon2022coyo,
  title={Coyo-700m: Image-text pair dataset},
  author={Byeon, Minwoo and Park, Beomhee and Kim, Haecheon and Lee, Sungjun and Baek, Woonhyuk and Kim, Saehoon},
  year={2022}
}

@inproceedings{changpinyo2021cc12m,
  title={Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts},
  author={Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle={CVPR},
  pages={3558--3568},
  year={2021}
}


@inproceedings{chen2022vitadapter,
  title={Vision Transformer Adapter for Dense Predictions},
  author={Chen, Zhe and Duan, Yuchen and Wang, Wenhai and He, Junjun and Lu, Tong and Dai, Jifeng and Qiao, Yu},
  booktitle={ICLR},
  year={2022}
}

@article{wei2023skywork,
  title={Skywork: A More Open Bilingual Foundation Model},
  author={Wei, Tianwen and Zhao, Liang and Zhang, Lichang and Zhu, Bo and Wang, Lijie and Yang, Haihua and Li, Biye and Cheng, Cheng and L{\"u}, Weiwei and Hu, Rui and others},
  journal={arXiv preprint arXiv:2310.19341},
  year={2023}
}

@inproceedings{hudson2019gqa,
  title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle={CVPR},
  pages={6700--6709},
  year={2019}
}

@article{ustalov2023toloka,
  title={Toloka Visual Question Answering Benchmark},
  author={Ustalov, Dmitry and Pavlichenko, Nikita and Koshelev, Sergey and Likhobaba, Daniil and Smirnova, Alisa},
  journal={arXiv preprint arXiv:2309.16511},
  year={2023}
}

@inproceedings{DBLP:conf/acl/0009C23,
  author       = {Jie Huang and
                  Kevin Chen{-}Chuan Chang},
  title        = {Towards Reasoning in Large Language Models: {A} Survey},
  booktitle    = {{ACL}},
  year         = {2023}
}

@article{driess2023palme,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}

@article{liu2023controlllm,
  title={ControlLLM: Augment Language Models with Tools by Searching on Graphs},
  author={Liu, Zhaoyang and Lai, Zeqiang and Gao, Zhangwei and Cui, Erfei and Zhu, Xizhou and Lu, Lewei and Chen, Qifeng and Qiao, Yu and Dai, Jifeng and Wang, Wenhai},
  journal={arXiv preprint arXiv:2310.17796},
  year={2023}
}

@article{yang2023gpt4tools,
  title={Gpt4tools: Teaching large language model to use tools via self-instruction},
  author={Yang, Rui and Song, Lin and Li, Yanwei and Zhao, Sijie and Ge, Yixiao and Li, Xiu and Shan, Ying},
  journal={NeurIPS},
  volume={36},
  year={2024}
}

@article{ye2023mplug2,
  title={mplug-owl2: Revolutionizing multi-modal large language model with modality collaboration},
  author={Ye, Qinghao and Xu, Haiyang and Ye, Jiabo and Yan, Ming and Liu, Haowei and Qian, Qi and Zhang, Ji and Huang, Fei and Zhou, Jingren},
  journal={arXiv preprint arXiv:2311.04257},
  year={2023}
}

@article{hu2023paperowl,
  title={mplug-paperowl: Scientific diagram analysis with the multimodal large language model},
  author={Hu, Anwen and Shi, Yaya and Xu, Haiyang and Ye, Jiabo and Ye, Qinghao and Yan, Ming and Li, Chenliang and Qian, Qi and Zhang, Ji and Huang, Fei},
  journal={arXiv preprint arXiv:2311.18248},
  year={2023}
}

@article{liu2024convbench,
  title={ConvBench: A Multi-Turn Conversation Evaluation Benchmark with Hierarchical Capability for Large Vision-Language Models},
  author={Liu, Shuo and Ying, Kaining and Zhang, Hao and Yang, Yue and Lin, Yuqi and Zhang, Tianle and Li, Chuanhao and Qiao, Yu and Luo, Ping and Shao, Wenqi and others},
  journal={arXiv preprint arXiv:2403.20194},
  year={2024}
}

@article{chen2023videollm,
  title={Videollm: Modeling video sequence with large language models},
  author={Chen, Guo and Zheng, Yin-Dong and Wang, Jiahao and Xu, Jilan and Huang, Yifei and Pan, Junting and Wang, Yi and Wang, Yali and Qiao, Yu and Lu, Tong and others},
  journal={arXiv preprint arXiv:2305.13292},
  year={2023}
}

@article{wang2024internvideo2,
  title={InternVideo2: Scaling Video Foundation Models for Multimodal Video Understanding},
  author={Wang, Yi and Li, Kunchang and Li, Xinhao and Yu, Jiashuo and He, Yinan and Chen, Guo and Pei, Baoqi and Zheng, Rongkun and Xu, Jilan and Wang, Zun and others},
  journal={arXiv preprint arXiv:2403.15377},
  year={2024}
}

@misc{opencompass2023,
    title={OpenCompass: A Universal Evaluation Platform for Foundation Models},
    author={OpenCompass Contributors},
    howpublished = {\url{https://github.com/open-compass/opencompass}},
    year={2023}
}

@article{ormazabal2024reka,
  title={Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models},
  author={Ormazabal, Aitor and Zheng, Che and d'Autume, Cyprien de Masson and Yogatama, Dani and Fu, Deyu and Ong, Donovan and Chen, Eric and Lamprecht, Eugenie and Pham, Hai and Ong, Isaac and others},
  journal={arXiv preprint arXiv:2404.12387},
  year={2024}
}

@article{lu2022scienceqa,
  title={Learn to explain: Multimodal reasoning via thought chains for science question answering},
  author={Lu, Pan and Mishra, Swaroop and Xia, Tanglin and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Kalyan, Ashwin},
  journal={NeurIPS},
  volume={35},
  pages={2507--2521},
  year={2022}
}

@article{ma2024groma,
  title={Groma: Localized Visual Tokenization for Grounding Multimodal Large Language Models},
  author={Ma, Chuofan and Jiang, Yi and Wu, Jiannan and Yuan, Zehuan and Qi, Xiaojuan},
  journal={arXiv preprint arXiv:2404.13013},
  year={2024}
}


@article{mmtbench,
  title={MMT-Bench: A Comprehensive Multimodal Benchmark for Evaluating Large Vision-Language Models Towards Multitask AGI},
  author={Ying, Kaining and Meng, Fanqing and Wang, Jin and Li, Zhiqian and Lin, Han and Yang, Yue and Zhang, Hao and Zhang, Wenbo and Lin, Yuqi and Liu, Shuo and Lei, Jiayi and Lu, Quanfeng and Chen, Runjian and Xu, Peng and Zhang, Renrui and Zhang, Haozhe and Gao, Peng and Wang, Yali and Qiao, Yu and Luo, Ping and Zhang, Kaipeng and Shao, Wenqi},
  journal={arXiv preprint arXiv:2404.16006},
  year={2024}
}

@inproceedings{das2017visualdialog,
  title={Visual dialog},
  author={Das, Abhishek and Kottur, Satwik and Gupta, Khushi and Singh, Avi and Yadav, Deshraj and Moura, Jos{\'e} MF and Parikh, Devi and Batra, Dhruv},
  booktitle={CVPR},
  pages={326--335},
  year={2017}
}

@inproceedings{yang2019xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  booktitle={NeurIPS},
  year={2019}
}


@article{li2022paddleocr,
  title={PP-OCRv3: More attempts for the improvement of ultra lightweight OCR system},
  author={Li, Chenxia and Liu, Weiwei and Guo, Ruoyu and Yin, Xiaoting and Jiang, Kaitao and Du, Yongkun and Du, Yuning and Zhu, Lingfeng and Lai, Baohua and Hu, Xiaoguang and others},
  journal={arXiv preprint arXiv:2206.03001},
  year={2022}
}

@inproceedings{DBLP:conf/slt/ChiCWHC0L21,
  author       = {Po{-}Han Chi and
                  Pei{-}Hung Chung and
                  Tsung{-}Han Wu and
                  Chun{-}Cheng Hsieh and
                  Yen{-}Hao Chen and
                  Shang{-}Wen Li and
                  Hung{-}yi Lee},
  title        = {Audio Albert: {A} Lite Bert for Self-Supervised Learning of Audio
                  Representation},
  booktitle    = {{IEEE} {SLT}},
  pages        = {344--350},
  year         = {2021}
}

@article{DBLP:journals/corr/abs-2308-01390,
  author       = {Anas Awadalla and
                  Irena Gao and
                  Josh Gardner and
                  Jack Hessel and
                  Yusuf Hanafy and
                  Wanrong Zhu and
                  Kalyani Marathe and
                  Yonatan Bitton and
                  Samir Yitzhak Gadre and
                  Shiori Sagawa and
                  Jenia Jitsev and
                  Simon Kornblith and
                  Pang Wei Koh and
                  Gabriel Ilharco and
                  Mitchell Wortsman and
                  Ludwig Schmidt},
  title        = {OpenFlamingo: An Open-Source Framework for Training Large Autoregressive
                  Vision-Language Models},
  journal      = {CoRR},
  volume       = {abs/2308.01390},
  year         = {2023}
}

@article{raffel2020exploring,
	author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
	journal = {The J. Mach. Learn. Res.},
	number = {1},
	pages = {5485--5551},
	publisher = {JMLRORG},
	title = {Exploring the limits of transfer learning with a unified text-to-text transformer},
	volume = {21},
	year = {2020}}

@article{chen2023sharegpt4v,
  title={Sharegpt4v: Improving large multi-modal models with better captions},
  author={Chen, Lin and Li, Jisong and Dong, Xiaoyi and Zhang, Pan and He, Conghui and Wang, Jiaqi and Zhao, Feng and Lin, Dahua},
  journal={arXiv preprint arXiv:2311.12793},
  year={2023}
}

@inproceedings{suris2023vipergpt,
  title={Vipergpt: Visual inference via python execution for reasoning},
  author={Sur{\'\i}s, D{\'\i}dac and Menon, Sachit and Vondrick, Carl},
  booktitle={ICCV},
  pages={11888--11898},
  year={2023}
}

@article{yu2023mmvet,
  title={Mm-vet: Evaluating large multimodal models for integrated capabilities},
  author={Yu, Weihao and Yang, Zhengyuan and Li, Linjie and Wang, Jianfeng and Lin, Kevin and Liu, Zicheng and Wang, Xinchao and Wang, Lijuan},
  journal={arXiv preprint arXiv:2308.02490},
  year={2023}
}

@article{guan2023hallusionbench,
  title={Hallusionbench: An advanced diagnostic suite for entangled language hallucination \& visual illusion in large vision-language models},
  author={Guan, Tianrui and Liu, Fuxiao and Wu, Xiyang and Xian, Ruiqi and Li, Zongxia and Liu, Xiaoyu and Wang, Xijun and Chen, Lichang and Huang, Furong and Yacoob, Yaser and others},
  journal={arXiv preprint arXiv:2310.14566},
  year={2023}
}

@article{lu2023mathvista,
  title={Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts},
  author={Lu, Pan and Bansal, Hritik and Xia, Tony and Liu, Jiacheng and Li, Chunyuan and Hajishirzi, Hannaneh and Cheng, Hao and Chang, Kai-Wei and Galley, Michel and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2310.02255},
  year={2023}
}

@article{ai2024yi,
  title={Yi: Open foundation models by 01. ai},
  author={Young, Alex and Chen, Bei and Li, Chao and Huang, Chengen and Zhang, Ge and Zhang, Guanwei and Li, Heng and Zhu, Jiangcheng and Chen, Jianqun and Chang, Jing and others},
  journal={arXiv preprint arXiv:2403.04652},
  year={2024}
}

@article{li2023seed,
  title={Seed-bench: Benchmarking multimodal llms with generative comprehension},
  author={Li, Bohao and Wang, Rui and Wang, Guangzhi and Ge, Yuying and Ge, Yixiao and Shan, Ying},
  journal={arXiv preprint arXiv:2307.16125},
  year={2023}
}

@article{yang2023mmreact,
  title={Mm-react: Prompting chatgpt for multimodal reasoning and action},
  author={Yang, Zhengyuan and Li, Linjie and Wang, Jianfeng and Lin, Kevin and Azarnasab, Ehsan and Ahmed, Faisal and Liu, Zicheng and Liu, Ce and Zeng, Michael and Wang, Lijuan},
  journal={arXiv preprint arXiv:2303.11381},
  year={2023}
}

@article{yue2023mmmu,
  title={Mmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert agi},
  author={Yue, Xiang and Ni, Yuansheng and Zhang, Kai and Zheng, Tianyu and Liu, Ruoqi and Zhang, Ge and Stevens, Samuel and Jiang, Dongfu and Ren, Weiming and Sun, Yuxuan and others},
  journal={arXiv preprint arXiv:2311.16502},
  year={2023}
}

@article{tomgpt,
author = {Chen, Yunkai and Wang, Qimeng and Wu, Shiwei and Gao, Yan and Xu, Tong and Hu, Yao},
title = {TOMGPT: Reliable Text-Only Training Approach for Cost-Effective Multi-modal Large Language Model},
year = {2024},
journal = {ACM Trans. Knowl. Discov. Data},
}

@inproceedings{he2024malmm,
  title = {MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding},
  author    = {He, Bo and Li, Hengduo and Jang, Young Kyun and Jia, Menglin and Cao, Xuefei and Shah, Ashish and Shrivastava, Abhinav and Lim, Ser-Nam},
  booktitle = {{CVPR}},
  year = {2024}
}

@article{DBLP:journals/corr/abs-2206-02967,
  author       = {Junnan Li and
                  Silvio Savarese and
                  Steven C. H. Hoi},
  title        = {Masked Unsupervised Self-training for Zero-shot Image Classification},
  journal      = {CoRR},
  volume       = {abs/2206.02967},
  year         = {2022}
}

@inproceedings{radford2021clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  pages={8748--8763},
  year={2021}
}

@inproceedings{zhu2023minigpt4,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  booktitle={ICLR},
  year={2024}
}


% internlm
@misc{2023internlm,
    title={InternLM: A Multilingual Language Model with Progressively Enhanced Capabilities},
    author={InternLM Team},
    howpublished = {\url{https://github.com/InternLM/InternLM}},
    year={2023}
}

% moss
@article{sun2023moss,
  title={Moss: Training conversational language models from synthetic data},
  author={Sun, Tianxiang and Zhang, Xiaotian and He, Zhengfu and Li, Peng and Cheng, Qinyuan and Yan, Hang and Liu, Xiangyang and Shao, Yunfan and Tang, Qiong and Zhao, Xingjian and others},
  journal={arXiv preprint arXiv:2307.15020},
  volume={7},
  year={2023}
}

% chatglm
@inproceedings{du2022glm,
  title={GLM: General Language Model Pretraining with Autoregressive Blank Infilling},
  author={Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie},
  booktitle={ACL},
  pages={320--335},
  year={2022}
}

@inproceedings{chen2022pali,
  title={PaLI: A Jointly-Scaled Multilingual Language-Image Model},
  author={Chen, Xi and Wang, Xiao and Changpinyo, Soravit and Piergiovanni, AJ and Padlewski, Piotr and Salz, Daniel and Goodman, Sebastian and Grycner, Adam and Mustafa, Basil and Beyer, Lucas and others},
  booktitle={ICLR},
  year={2022}
}

@misc{google_bard,
  title        = {Google Bard},
  author       = {Google},
  year         = {2023},
  howpublished = {\url{https://bard.google.com/}},
}


@article{zheng2023vicuna,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={NeurIPS},
  volume={36},
  year={2024}
}


@article{baichuan2023baichuan2,
  title={Baichuan 2: Open Large-scale Language Models},
  author={Baichuan},
  journal={arXiv preprint arXiv:2309.10305},
  url={https://arxiv.org/abs/2309.10305},
  year={2023}
}

@article{refinedweb,
  title={The {R}efined{W}eb dataset for {F}alcon {LLM}: outperforming curated corpora with web data, and web data only},
  author={Guilherme Penedo and Quentin Malartic and Daniel Hesslow and Ruxandra Cojocaru and Alessandro Cappelli and Hamza Alobeidli and Baptiste Pannier and Ebtesam Almazrouei and Julien Launay},
  journal={arXiv preprint arXiv:2306.01116},
  eprint={2306.01116},
  eprinttype = {arXiv},
  url={https://arxiv.org/abs/2306.01116},
  year={2023}
}

@article{liu2023improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2310.03744},
  year={2023}
}

@misc{claude3series2024,
  author = {{Anthropic}},
  title = {The Claude 3 Model Family: Opus, Sonnet, Haiku},
  year = {2024},
  howpublished = {\url{https://www.anthropic.com}},
  url = {https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf}
}

@misc{claude,
  title = {Introducing {Claude}},
  author = {Anthropic},
  institution = {Anthropic},
  url = {https://www.anthropic.com/index/introducing-claude},
  year={2023}
}

@misc{step1v2023,
  author = {{StepFun Research Team}},
  title = {Step-1V: A Hundred Billion Parameter Multimodal Large Model},
  howpublished = {\url{https://platform.stepfun.com}},
  year = {2024}
}

@article{bi2024deepseekllm,
  title={Deepseek llm: Scaling open-source language models with longtermism},
  author={Bi, Xiao and Chen, Deli and Chen, Guanting and Chen, Shanhuang and Dai, Damai and Deng, Chengqi and Ding, Honghui and Dong, Kai and Du, Qiushi and Fu, Zhe and others},
  journal={arXiv preprint arXiv:2401.02954},
  year={2024}
}

@article{dong2024xc24khd,
  title={InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD},
  author={Dong, Xiaoyi and Zhang, Pan and Zang, Yuhang and Cao, Yuhang and Wang, Bin and Ouyang, Linke and Zhang, Songyang and Duan, Haodong and Zhang, Wenwei and Li, Yining and others},
  journal={arXiv preprint arXiv:2404.06512},
  year={2024}
}

@misc{hptpro2024,
  author = {{HyperGAI Research Team}},
  title = {Introducing HPT: A Family of Leading Multimodal LLMs},
  year = {2024},
  howpublished = {\url{https://www.hypergai.com/blog/introducing-hpt-a-family-of-leading-multimodal-llms}}
}


@article{ye2023mplugdocowl,
  title={mplug-docowl: Modularized multimodal large language model for document understanding},
  author={Ye, Jiabo and Hu, Anwen and Xu, Haiyang and Ye, Qinghao and Yan, Ming and Dan, Yuhao and Zhao, Chenlin and Xu, Guohai and Li, Chenliang and Tian, Junfeng and others},
  journal={arXiv preprint arXiv:2307.02499},
  year={2023}
}

@article{cai2024internlm2,
  title={Internlm2 technical report},
  author={Cai, Zheng and Cao, Maosong and Chen, Haojiong and Chen, Kai and Chen, Keyu and Chen, Xin and Chen, Xun and Chen, Zehui and Chen, Zhi and Chu, Pei and others},
  journal={arXiv preprint arXiv:2403.17297},
  year={2024}
}

@article{lin2024moellava,
  title={Moe-llava: Mixture of experts for large vision-language models},
  author={Lin, Bin and Tang, Zhenyu and Ye, Yang and Cui, Jiaxi and Zhu, Bin and Jin, Peng and Zhang, Junwu and Ning, Munan and Yuan, Li},
  journal={arXiv preprint arXiv:2401.15947},
  year={2024}
}

@article{beyer2020imagenetreal,
  title={Are we done with imagenet?},
  author={Beyer, Lucas and H{\'e}naff, Olivier J and Kolesnikov, Alexander and Zhai, Xiaohua and Oord, A{\"a}ron van den},
  journal={arXiv preprint arXiv:2006.07159},
  year={2020}
}

@article{2023interngpt,
  title={InternGPT: Solving Vision-Centric Tasks by Interacting with ChatGPT Beyond Language},
  author={Liu, Zhaoyang and He, Yinan and Wang, Wenhai and Wang, Weiyun and Wang, Yi and Chen, Shoufa and Zhang, Qinglong and Lai, Zeqiang and Yang, Yang and Li, Qingyun and Yu, Jiashuo and others},
  journal={arXiv preprint arXiv:2305.05662},
  year={2023}
}

@article{wu2023visual,
  title={Visual chatgpt: Talking, drawing and editing with visual foundation models},
  author={Wu, Chenfei and Yin, Shengming and Qi, Weizhen and Wang, Xiaodong and Tang, Zecheng and Duan, Nan},
  journal={arXiv preprint arXiv:2303.04671},
  year={2023}
}

@article{shen2023hugginggpt,
  title={Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face},
  author={Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  journal={NeurIPS},
  volume={36},
  year={2024}
}

@article{mu2023embodiedgpt,
  title={Embodiedgpt: Vision-language pre-training via embodied chain of thought},
  author={Mu, Yao and Zhang, Qinglong and Hu, Mengkang and Wang, Wenhai and Ding, Mingyu and Jin, Jun and Wang, Bin and Dai, Jifeng and Qiao, Yu and Luo, Ping},
  journal={NeurIPS},
  volume={36},
  year={2024}
}

@article{ordonez2011sbu,
  title={Im2text: Describing images using 1 million captioned photographs},
  author={Ordonez, Vicente and Kulkarni, Girish and Berg, Tamara},
  journal={NeurIPS},
  volume={24},
  year={2011}
}


@inproceedings{sharma2018cc3m,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={ACL},
  year={2018}
}

@article{schuhmann2022laioncoco,
  title={Laion coco: 600m synthetic captions from laion2b-en.},
  author={Schuhmann, Christoph and Köpf, Andreas and Vencu, Richard and Coombes, Theo and Beaumont, Romain},
  journal = {https://laion.ai/blog/laion-coco/},
  year={2022}
}

@article{loshchilov2017adamw,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{lin2023sphinx,
  title={Sphinx: The joint mixing of weights, tasks, and visual embeddings for multi-modal large language models},
  author={Lin, Ziyi and Liu, Chris and Zhang, Renrui and Gao, Peng and Qiu, Longtian and Xiao, Han and Qiu, Han and Lin, Chen and Shao, Wenqi and Chen, Keqin and others},
  journal={arXiv preprint arXiv:2311.07575},
  year={2023}
}

@article{chen2024far,
  title={How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites},
  author={Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and others},
  journal={arXiv preprint arXiv:2404.16821},
  year={2024}
}

@misc{DBRX,
    title={Introducing DBRX: A New State-of-the-Art Open LLM},
    url={https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm},
    author={The Mosaic Research Team},
    month={March},
    year={2024}
}

@misc{shazeer2017outrageously,
      title={Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer}, 
      author={Noam Shazeer and Azalia Mirhoseini and Krzysztof Maziarz and Andy Davis and Quoc Le and Geoffrey Hinton and Jeff Dean},
      year={2017},
      eprint={1701.06538},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{lv2023kosmos2_5,
  title={Kosmos-2.5: A multimodal literate model},
  author={Lv, Tengchao and Huang, Yupan and Chen, Jingye and Cui, Lei and Ma, Shuming and Chang, Yaoyao and Huang, Shaohan and Wang, Wenhui and Dong, Li and Luo, Weiyao and others},
  journal={arXiv preprint arXiv:2309.11419},
  year={2023}
}

@article{zhan2024anygpt,
  title={AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling},
  author={Zhan, Jun and Dai, Junqi and Ye, Jiasheng and Zhou, Yunhua and Zhang, Dong and Liu, Zhigeng and Zhang, Xin and Yuan, Ruibin and Zhang, Ge and Li, Linyang and others},
  journal={arXiv preprint arXiv:2402.12226},
  year={2024}
}

@article{liu2023llavaplus,
  title={LLaVA-Plus: Learning to Use Tools for Creating Multimodal Agents},
  author={Liu, Shilong and Cheng, Hao and Liu, Haotian and Zhang, Hao and Li, Feng and Ren, Tianhe and Zou, Xueyan and Yang, Jianwei and Su, Hang and Zhu, Jun and Zhang, Lei and Gao, Jianfeng and Li, Chunyuan},
  journal={arXiv:2311.05437},
  year={2023}
}

@article{li2023mimicit,
    title={MIMIC-IT: Multi-Modal In-Context Instruction Tuning},
    author={Bo Li and Yuanhan Zhang and Liangyu Chen and Jinghao Wang and Fanyi Pu and Jingkang Yang and Chunyuan Li and Ziwei Liu},
    year={2023},
    eprint={2306.05425},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@article{li2024miniGemini,
  title={Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models},
  author={Li, Yanwei and Zhang, Yuechen and Wang, Chengyao and Zhong, Zhisheng and Chen, Yixin and Chu, Ruihang and Liu, Shaoteng and Jia, Jiaya},
  journal={arXiv preprint arXiv:2403.18814},
  year={2024}
}

@article{liu2024textmonkey,
  title={TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document},
  author={Liu, Yuliang and Yang, Biao and Liu, Qiang and Li, Zhang and Ma, Zhiyin and Zhang, Shuo and Bai, Xiang},
  journal={arXiv preprint arXiv:2403.04473},
  year={2024}
}

@article{chu2023mobilevlm,
  title={Mobilevlm: A fast, reproducible and strong vision language assistant for mobile devices},
  author={Chu, Xiangxiang and Qiao, Limeng and Lin, Xinyang and Xu, Shuang and Yang, Yang and Hu, Yiming and Wei, Fei and Zhang, Xinyu and Zhang, Bo and Wei, Xiaolin and others},
  journal={arXiv preprint arXiv:2312.16886},
  year={2023}
}

@article{chu2024mobilevlm,
  title={MobileVLM V2: Faster and Stronger Baseline for Vision Language Model},
  author={Chu, Xiangxiang and Qiao, Limeng and Zhang, Xinyu and Xu, Shuang and Wei, Fei and Yang, Yang and Sun, Xiaofei and Hu, Yiming and Lin, Xinyang and Zhang, Bo and others},
  journal={arXiv preprint arXiv:2402.03766},
  year={2024}
}

@inproceedings{zhai2023siglip,
  title={Sigmoid loss for language image pre-training},
  author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={ICCV},
  pages={11975--11986},
  year={2023}
}

@inproceedings{shi2017rctw17,
  title={Icdar2017 competition on reading chinese text in the wild (rctw-17)},
  author={Shi, Baoguang and Yao, Cong and Liao, Minghui and Yang, Mingkun and Xu, Pei and Cui, Linyan and Belongie, Serge and Lu, Shijian and Bai, Xiang},
  booktitle={ICDAR},
  volume={1},
  pages={1429--1434},
  year={2017}
}

@inproceedings{chng2019art,
  title={Icdar2019 robust reading challenge on arbitrary-shaped text-rrc-art},
  author={Chng, Chee Kheng and Liu, Yuliang and Sun, Yipeng and Ng, Chun Chet and Luo, Canjie and Ni, Zihan and Fang, ChuanMing and Zhang, Shuaitao and Han, Junyu and Ding, Errui and others},
  booktitle={ICDAR},
  pages={1571--1576},
  year={2019}
}

@inproceedings{zhang2019rects,
  title={Icdar 2019 robust reading challenge on reading chinese text on signboard},
  author={Zhang, Rui and Zhou, Yongsheng and Jiang, Qianyi and Song, Qi and Li, Nan and Zhou, Kai and Wang, Lei and Wang, Dong and Liao, Minghui and Yang, Mingkun and others},
  booktitle={ICDAR},
  pages={1577--1581},
  year={2019}
}

@misc{xai2024grokv,
  author = {X.ai},
  title = {Grok-1.5 Vision Preview},
  year = {2024},
  howpublished = {\url{https://x.ai/blog/grok-1.5v}}
}

@inproceedings{sun2019lsvt,
  title={ICDAR 2019 competition on large-scale street view text with partial labeling-RRC-LSVT},
  author={Sun, Yipeng and Ni, Zihan and Chng, Chee-Kheng and Liu, Yuliang and Luo, Canjie and Ng, Chun Chet and Han, Junyu and Ding, Errui and Liu, Jingtuo and Karatzas, Dimosthenis and others},
  booktitle={ICDAR},
  pages={1557--1562},
  year={2019}
}

@inproceedings{qi2022dureadervis,
  title={DuReadervis: A Chinese dataset for open-domain document visual question answering},
  author={Qi, Le and Lv, Shangwen and Li, Hongyu and Liu, Jing and Zhang, Yu and She, Qiaoqiao and Wu, Hua and Wang, Haifeng and Liu, Ting},
  booktitle={ACL},
  pages={1338--1351},
  year={2022}
}

@article{ye2023ureader,
  title={Ureader: Universal ocr-free visually-situated language understanding with multimodal large language model},
  author={Ye, Jiabo and Hu, Anwen and Xu, Haiyang and Ye, Qinghao and Yan, Ming and Xu, Guohai and Li, Chenliang and Tian, Junfeng and Qian, Qi and Zhang, Ji and others},
  journal={arXiv preprint arXiv:2310.05126},
  year={2023}
}

@article{DBLP:journals/corr/abs-2310-01852,
  author       = {Bin Zhu and
                  Bin Lin and
                  Munan Ning and
                  Yang Yan and
                  Jiaxi Cui and
                  Hongfa Wang and
                  Yatian Pang and
                  Wenhao Jiang and
                  Junwu Zhang and
                  Zongwei Li and
                  Wancai Zhang and
                  Zhifeng Li and
                  Wei Liu and
                  Li Yuan},
  title        = {LanguageBind: Extending Video-Language Pretraining to N-modality by
                  Language-based Semantic Alignment},
  journal      = {CoRR},
  volume       = {abs/2310.01852},
  year         = {2023}
}

@article{xu2024llava_uhd,
  title={LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images},
  author={Xu, Ruyi and Yao, Yuan and Guo, Zonghao and Cui, Junbo and Ni, Zanlin and Ge, Chunjiang and Chua, Tat-Seng and Liu, Zhiyuan and Sun, Maosong and Huang, Gao},
  journal={arXiv preprint arXiv:2403.11703},
  year={2024}
}

@article{li2023otterhd,
  title={Otterhd: A high-resolution multi-modality model},
  author={Li, Bo and Zhang, Peiyuan and Yang, Jingkang and Zhang, Yuanhan and Pu, Fanyi and Liu, Ziwei},
  journal={arXiv preprint arXiv:2311.04219},
  year={2023}
}

@article{hu2024mplug_docowl_1_5,
  title={mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding},
  author={Hu, Anwen and Xu, Haiyang and Ye, Jiabo and Yan, Ming and Zhang, Liang and Zhang, Bo and Li, Chen and Zhang, Ji and Jin, Qin and Huang, Fei and others},
  journal={arXiv preprint arXiv:2403.12895},
  year={2024}
}

@article{luo2024llava_hr,
  title={Feast Your Eyes: Mixture-of-Resolution Adaptation for Multimodal Large Language Models},
  author={Luo, Gen and Zhou, Yiyi and Zhang, Yuxin and Zheng, Xiawu and Sun, Xiaoshuai and Ji, Rongrong},
  journal={arXiv preprint arXiv:2403.03003},
  year={2024}
}

@article{Ren2023TimeChat,
  title={TimeChat: A Time-sensitive Multimodal Large Language Model for Long Video Understanding},
  author={Shuhuai Ren and Linli Yao and Shicheng Li and Xu Sun and Lu Hou},
  journal={ArXiv},
  year={2023},
  volume={abs/2312.02051},
}

@article{wei2023vary,
  title={Vary: Scaling up the vision vocabulary for large vision-language models},
  author={Wei, Haoran and Kong, Lingyu and Chen, Jinyue and Zhao, Liang and Ge, Zheng and Yang, Jinrong and Sun, Jianjian and Han, Chunrui and Zhang, Xiangyu},
  journal={arXiv preprint arXiv:2312.06109},
  year={2023}
}


@article{hong2023cogagent,
  title={Cogagent: A visual language model for gui agents},
  author={Hong, Wenyi and Wang, Weihan and Lv, Qingsong and Xu, Jiazheng and Yu, Wenmeng and Ji, Junhui and Wang, Yan and Wang, Zihan and Dong, Yuxiao and Ding, Ming and others},
  journal={arXiv preprint arXiv:2312.08914},
  year={2023}
}

@article{wang2024allseeingv2,
  title={The All-Seeing Project V2: Towards General Relation Comprehension of the Open World},
  author={Wang, Weiyun and Ren, Yiming and Luo, Haowen and Li, Tiantong and Yan, Chenxiang and Chen, Zhe and Wang, Wenhai and Li, Qingyun and Lu, Lewei and Zhu, Xizhou and others},
  journal={arXiv preprint arXiv:2402.19474},
  year={2024}
}

@article{li2023llamavid,
  title={LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models},
  author={Li, Yanwei and Wang, Chengyao and Jia, Jiaya},
  journal={arXiv preprint arXiv:2311.17043},
  year={2023}
}

@article{tian2024mminterleaved,
  title={Mm-interleaved: Interleaved image-text generative modeling via multi-modal feature synchronizer},
  author={Tian, Changyao and Zhu, Xizhou and Xiong, Yuwen and Wang, Weiyun and Chen, Zhe and Wang, Wenhai and Chen, Yuntao and Lu, Lewei and Lu, Tong and Zhou, Jie and others},
  journal={arXiv preprint arXiv:2401.10208},
  year={2024}
}

@inproceedings{zhang2023llama-adapter,
  title={Llama-adapter: Efficient fine-tuning of language models with zero-init attention},
  author={Zhang, Renrui and Han, Jiaming and Zhou, Aojun and Hu, Xiangfei and Yan, Shilin and Lu, Pan and Li, Hongsheng and Gao, Peng and Qiao, Yu},
  booktitle={ICLR},
  year={2024}
}

@article{gao2023llama-adapterv2,
  title={Llama-adapter v2: Parameter-efficient visual instruction model},
  author={Gao, Peng and Han, Jiaming and Zhang, Renrui and Lin, Ziyi and Geng, Shijie and Zhou, Aojun and Zhang, Wei and Lu, Pan and He, Conghui and Yue, Xiangyu and others},
  journal={arXiv preprint arXiv:2304.15010},
  year={2023}
}

@article{zhang2023gpt4roi,
  title={Gpt4roi: Instruction tuning large language model on region-of-interest},
  author={Zhang, Shilong and Sun, Peize and Chen, Shoufa and Xiao, Min and Shao, Wenqi and Zhang, Wenwei and Chen, Kai and Luo, Ping},
  journal={arXiv preprint arXiv:2307.03601},
  year={2023}
}

@article{DBLP:journals/corr/abs-2402-06196,
  author       = {Shervin Minaee and
                  Tom{\'{a}}s Mikolov and
                  Narjes Nikzad and
                  Meysam Chenaghlu and
                  Richard Socher and
                  Xavier Amatriain and
                  Jianfeng Gao},
  title        = {Large Language Models: {A} Survey},
  journal      = {CoRR},
  volume       = {abs/2402.06196},
  year         = {2024}
}

@inproceedings{DBLP:conf/nips/0001XH23,
  author       = {Qi Qian and
                  Yuanhong Xu and
                  Juhua Hu},
  title        = {Intra-Modal Proxy Learning for Zero-Shot Visual Categorization with
                  {CLIP}},
  booktitle    = {NeurIPS},
  year         = {2023}
}

@inproceedings{DBLP:conf/nips/ZhuHAGDFYSW023,
  author       = {Wanrong Zhu and
                  Jack Hessel and
                  Anas Awadalla and
                  Samir Yitzhak Gadre and
                  Jesse Dodge and
                  Alex Fang and
                  Youngjae Yu and
                  Ludwig Schmidt and
                  William Yang Wang and
                  Yejin Choi},
  title        = {Multimodal {C4:} An Open, Billion-scale Corpus of Images Interleaved
                  with Text},
  booktitle    = {NeurIPS},
  year         = {2023}
}

@inproceedings{DBLP:conf/nips/GoelBBRVG22,
  author       = {Shashank Goel and
                  Hritik Bansal and
                  Sumit Bhatia and
                  Ryan A. Rossi and
                  Vishwa Vinay and
                  Aditya Grover},
  title        = {CyCLIP: Cyclic Contrastive Language-Image Pretraining},
  booktitle    = {NeurIPS},
  year         = {2022}
}

@inproceedings{DBLP:conf/nips/DuanXZTZZ23,
  author       = {Haoyi Duan and
                  Yan Xia and
                  Mingze Zhou and
                  Li Tang and
                  Jieming Zhu and
                  Zhou Zhao},
  title        = {Cross-modal Prompts: Adapting Large Pre-trained Models for Audio-Visual
                  Downstream Tasks},
  booktitle    = {NeurIPS},
  year         = {2023}
}

@inproceedings{DBLP:conf/nips/LiSGJXH21,
  author       = {Junnan Li and
                  Ramprasaath R. Selvaraju and
                  Akhilesh Gotmare and
                  Shafiq R. Joty and
                  Caiming Xiong and
                  Steven Chu{-}Hong Hoi},
  title        = {Align before Fuse: Vision and Language Representation Learning with
                  Momentum Distillation},
  booktitle    = {NeurIPS},
  pages        = {9694--9705},
  year         = {2021}
}

@inproceedings{DBLP:conf/nips/LiangZKYZ22,
  author       = {Weixin Liang and
                  Yuhui Zhang and
                  Yongchan Kwon and
                  Serena Yeung and
                  James Y. Zou},
  title        = {Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive
                  Representation Learning},
  booktitle    = {NeurIPS},
  year         = {2022}
}

@article{wu2023nextgpt,
  title={Next-gpt: Any-to-any multimodal llm},
  author={Wu, Shengqiong and Fei, Hao and Qu, Leigang and Ji, Wei and Chua, Tat-Seng},
  journal={arXiv preprint arXiv:2309.05519},
  year={2023}
}

@article{li2023videochat,
  title={Videochat: Chat-centric video understanding},
  author={Li, KunChang and He, Yinan and Wang, Yi and Li, Yizhuo and Wang, Wenhai and Luo, Ping and Wang, Yali and Wang, Limin and Qiao, Yu},
  journal={arXiv preprint arXiv:2305.06355},
  year={2023}
}

@article{lai2023lisa,
  title={Lisa: Reasoning segmentation via large language model},
  author={Lai, Xin and Tian, Zhuotao and Chen, Yukang and Li, Yanwei and Yuan, Yuhui and Liu, Shu and Jia, Jiaya},
  journal={arXiv preprint arXiv:2308.00692},
  year={2023}
}

@article{yang2023gpt-4v,
  title={The dawn of lmms: Preliminary explorations with gpt-4v (ision)},
  author={Yang, Zhengyuan and Li, Linjie and Lin, Kevin and Wang, Jianfeng and Lin, Chung-Ching and Liu, Zicheng and Wang, Lijuan},
  journal={arXiv preprint arXiv:2309.17421},
  volume={9},
  year={2023}
}

@article{lin2023video,
  title={Video-LLaVA: Learning United Visual Representation by Alignment Before Projection},
  author={Lin, Bin and Zhu, Bin and Ye, Yang and Ning, Munan and Jin, Peng and Yuan, Li},
  journal={arXiv preprint arXiv:2311.10122},
  year={2023}
}

@article{li2023otter,
  title={Otter: A multi-modal model with in-context instruction tuning},
  author={Li, Bo and Zhang, Yuanhan and Chen, Liangyu and Wang, Jinghao and Yang, Jingkang and Liu, Ziwei},
  journal={arXiv preprint arXiv:2305.03726},
  year={2023}
}

@article{zhang2023video-llama,
  title={Video-llama: An instruction-tuned audio-visual language model for video understanding},
  author={Zhang, Hang and Li, Xin and Bing, Lidong},
  journal={arXiv preprint arXiv:2306.02858},
  year={2023}
}

@inproceedings{sidorov2020textcaps,
  title={Textcaps: a dataset for image captioning with reading comprehension},
  author={Sidorov, Oleksii and Hu, Ronghang and Rohrbach, Marcus and Singh, Amanpreet},
  booktitle={ECCV},
  pages={742--758},
  year={2020}
}

@inproceedings{goyal2017vqav2,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={CVPR},
  pages={6904--6913},
  year={2017}
}

@inproceedings{marino2019okvqa,
  title={Ok-vqa: A visual question answering benchmark requiring external knowledge},
  author={Marino, Kenneth and Rastegari, Mohammad and Farhadi, Ali and Mottaghi, Roozbeh},
  booktitle={CVPR},
  pages={3195--3204},
  year={2019}
}

@inproceedings{schwenk2022aokvqa,
  title={A-okvqa: A benchmark for visual question answering using world knowledge},
  author={Schwenk, Dustin and Khandelwal, Apoorv and Clark, Christopher and Marino, Kenneth and Mottaghi, Roozbeh},
  booktitle={ECCV},
  pages={146--162},
  year={2022}
}

@article{lu2021iconqa,
  title={Iconqa: A new benchmark for abstract diagram understanding and visual language reasoning},
  author={Lu, Pan and Qiu, Liang and Chen, Jiaqi and Xia, Tony and Zhao, Yizhou and Zhang, Wei and Yu, Zhou and Liang, Xiaodan and Zhu, Song-Chun},
  journal={arXiv preprint arXiv:2110.13214},
  year={2021}
}

@inproceedings{kembhavi2016ai2d,
  title={A diagram is worth a dozen images},
  author={Kembhavi, Aniruddha and Salvato, Mike and Kolve, Eric and Seo, Minjoon and Hajishirzi, Hannaneh and Farhadi, Ali},
  booktitle={ECCV},
  pages={235--251},
  year={2016}
}

@inproceedings{das2017visdial,
  title={Visual dialog},
  author={Das, Abhishek and Kottur, Satwik and Gupta, Khushi and Singh, Avi and Yadav, Deshraj and Moura, Jos{\'e} MF and Parikh, Devi and Batra, Dhruv},
  booktitle={CVPR},
  pages={326--335},
  year={2017}
}


@inproceedings{masry2022chartqa,
  title={ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning},
  author={Masry, Ahmed and Do, Xuan Long and Tan, Jia Qing and Joty, Shafiq and Hoque, Enamul},
  booktitle={ACL},
  pages={2263--2279},
  year={2022}
}


@inproceedings{biten2019stvqa,
  title={Scene text visual question answering},
  author={Biten, Ali Furkan and Tito, Ruben and Mafla, Andres and Gomez, Lluis and Rusinol, Mar{\c{c}}al and Valveny, Ernest and Jawahar, CV and Karatzas, Dimosthenis},
  booktitle={ICCV},
  pages={4291--4301},
  year={2019}
}

@inproceedings{clark2017docqa,
  title={Simple and Effective Multi-Paragraph Reading Comprehension},
  author={Clark, Christopher and Gardner, Matt},
  booktitle={ACL},
  pages={845--855},
  year={2018}
}


@inproceedings{mishra2019ocrvqa,
  title={Ocr-vqa: Visual question answering by reading text in images},
  author={Mishra, Anand and Shekhar, Shashank and Singh, Ajeet Kumar and Chakraborty, Anirban},
  booktitle={ICDAR},
  pages={947--952},
  year={2019}
}

@inproceedings{wang2020estvqa,
  title={On the general value of evidence, and bilingual scene-text visual question answering},
  author={Wang, Xinyu and Liu, Yuliang and Shen, Chunhua and Ng, Chun Chet and Luo, Canjie and Jin, Lianwen and Chan, Chee Seng and Hengel, Anton van den and Wang, Liangwei},
  booktitle={CVPR},
  pages={10126--10135},
  year={2020}
}

@article{zhang2023llavar,
  title={Llavar: Enhanced visual instruction tuning for text-rich image understanding},
  author={Zhang, Yanzhe and Zhang, Ruiyi and Gu, Jiuxiang and Zhou, Yufan and Lipka, Nedim and Yang, Diyi and Sun, Tong},
  journal={arXiv preprint arXiv:2306.17107},
  year={2023}
}

@inproceedings{yu2016refcoco,
  title={Modeling context in referring expressions},
  author={Yu, Licheng and Poirson, Patrick and Yang, Shan and Berg, Alexander C and Berg, Tamara L},
  booktitle={ECCV},
  pages={69--85},
  year={2016}
}

@inproceedings{mao2016refcocog,
  title={Generation and comprehension of unambiguous object descriptions},
  author={Mao, Junhua and Huang, Jonathan and Toshev, Alexander and Camburu, Oana and Yuille, Alan L and Murphy, Kevin},
  booktitle={CVPR},
  pages={11--20},
  year={2016}
}

@article{zhao2023svit,
  title={Svit: Scaling up visual instruction tuning},
  author={Zhao, Bo and Wu, Boya and Huang, Tiejun},
  journal={arXiv preprint arXiv:2307.04087},
  year={2023}
}

@article{liu2023lrv-instruction,
  title={Aligning Large Multi-Modal Model with Robust Instruction Tuning},
  author={Liu, Fuxiao and Lin, Kevin and Li, Linjie and Wang, Jianfeng and Yacoob, Yaser and Wang, Lijuan},
  journal={arXiv preprint arXiv:2306.14565},
  year={2023}
}

@inproceedings{mathew2022infographicvqa,
  title={Infographicvqa},
  author={Mathew, Minesh and Bagal, Viraj and Tito, Rub{\`e}n and Karatzas, Dimosthenis and Valveny, Ernest and Jawahar, CV},
  booktitle={WACV},
  pages={1697--1706},
  year={2022}
}

@inproceedings{xu2016msrvtt,
  title={Msr-vtt: A large video description dataset for bridging video and language},
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle={CVPR},
  pages={5288--5296},
  year={2016}
}

@article{xue2023alleviating,
  title={Alleviating data insufficiency for Chinese sign language recognition},
  author={Xue, Wanli and Liu, Jingze and Yan, Siyi and Zhou, Yuxi and Yuan, Tiantian and Guo, Qing},
  journal={Visual Intelligence},
  volume={1},
  number={1},
  pages={26},
  year={2023},
  publisher={Springer}
}

@misc{gpt4v,
  title={GPT-4V(ision) System Card},
  author={OpenAI},
  howpublished={\url{https://cdn.openai.com/papers/GPTV_System_Card.pdf}},
  year={2023}
}

% ChatGPT
@misc{openai2020chatgpt,
  title = {ChatGPT},
  author = {OpenAI},
  year = {2022},
  howpublished = {\url{https://openai.com/blog/chatgpt}}
}


@misc{jiang2023mistral,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{DBLP:journals/corr/abs-2312-14233,
  author       = {Jitesh Jain and
                  Jianwei Yang and
                  Humphrey Shi},
  title        = {VCoder: Versatile Vision Encoders for Multimodal Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2312.14233},
  year         = {2023}
}

@article{cha2023honeybee,
  title={Honeybee: Locality-enhanced projector for multimodal llm},
  author={Cha, Junbum and Kang, Wooyoung and Mun, Jonghwan and Roh, Byungseok},
  journal={arXiv preprint arXiv:2312.06742},
  year={2023}
}

@article{DBLP:journals/corr/abs-2312-07533,
  author       = {Ji Lin and
                  Hongxu Yin and
                  Wei Ping and
                  Yao Lu and
                  Pavlo Molchanov and
                  Andrew Tao and
                  Huizi Mao and
                  Jan Kautz and
                  Mohammad Shoeybi and
                  Song Han},
  title        = {{VILA:} On Pre-training for Visual Language Models},
  journal      = {CoRR},
  volume       = {abs/2312.07533},
  year         = {2023}
}

@article{li2024cumo,
  title={CuMo: Scaling Multimodal LLM with Co-Upcycled Mixture-of-Experts},
  author={Li, Jiachen and Wang, Xinyao and Zhu, Sijie and Kuo, Chia-wen and Xu, Lu and Chen, Fan and Jain, Jitesh and Shi, Humphrey and Wen, Longyin},
  journal={arXiv:},
  year={2024}
}

% Vicuna
@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

%coco caption
@misc{chen2015microsoft,
      title={Microsoft COCO Captions: Data Collection and Evaluation Server}, 
      author={Xinlei Chen and Hao Fang and Tsung-Yi Lin and Ramakrishna Vedantam and Saurabh Gupta and Piotr Dollar and C. Lawrence Zitnick},
      year={2015},
      eprint={1504.00325},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}

@article{DBLP:journals/corr/abs-2301-00234,
  author       = {Qingxiu Dong and
                  Lei Li and
                  Damai Dai and
                  Ce Zheng and
                  Zhiyong Wu and
                  Baobao Chang and
                  Xu Sun and
                  Jingjing Xu and
                  Lei Li and
                  Zhifang Sui},
  title        = {A Survey for In-context Learning},
  journal      = {CoRR},
  volume       = {abs/2301.00234},
  year         = {2023}
}

@inproceedings{DBLP:conf/nips/Ouyang0JAWMZASR22,
  author       = {Long Ouyang and
                  Jeffrey Wu and
                  Xu Jiang and
                  Diogo Almeida and
                  Carroll L. Wainwright and
                  Pamela Mishkin and
                  Chong Zhang and
                  Sandhini Agarwal and
                  Katarina Slama and
                  Alex Ray and others},
  title        = {Training language models to follow instructions with human feedback},
  booktitle    = {NeurIPS},
  year         = {2022}
}

@article{DBLP:journals/corr/abs-2210-11416,
  author       = {Hyung Won Chung and
                  Le Hou and
                  Shayne Longpre and
                  Barret Zoph and
                  Yi Tay and
                  William Fedus and
                  Eric Li and
                  Xuezhi Wang and
                  Mostafa Dehghani and
                  Siddhartha Brahma and others},
  title        = {Scaling Instruction-Finetuned Language Models},
  journal      = {CoRR},
  volume       = {abs/2210.11416},
  year         = {2022}
}

@inproceedings{wei2022finetuned,
  title     = {Finetuned Language Models are Zero-Shot Learners},
  author    = {Jason Wei and Maarten Bosma and Vincent Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V Le},
  booktitle = {ICLR},
  year      = {2022}
}

@inproceedings{DBLP:conf/nips/ChristianoLBMLA17,
  author       = {Paul F. Christiano and
                  Jan Leike and
                  Tom B. Brown and
                  Miljan Martic and
                  Shane Legg and
                  Dario Amodei},
  title        = {Deep Reinforcement Learning from Human Preferences},
  booktitle    = {NeurIPS},
  pages        = {4299--4307},
  year         = {2017}
}

@article{DBLP:journals/corr/abs-1909-08593,
  author       = {Daniel M. Ziegler and
                  Nisan Stiennon and
                  Jeffrey Wu and
                  Tom B. Brown and
                  Alec Radford and
                  Dario Amodei and
                  Paul F. Christiano and
                  Geoffrey Irving},
  title        = {Fine-Tuning Language Models from Human Preferences},
  journal      = {CoRR},
  volume       = {abs/1909.08593},
  year         = {2019}
}


@inproceedings{DBLP:conf/nips/StiennonO0ZLVRA20,
  author       = {Nisan Stiennon and
                  Long Ouyang and
                  Jeffrey Wu and
                  Daniel M. Ziegler and
                  Ryan Lowe and
                  Chelsea Voss and
                  Alec Radford and
                  Dario Amodei and
                  Paul F. Christiano},
  title        = {Learning to summarize with human feedback},
  booktitle    = {Advances in Neural Information Processing Systems 33: Annual Conference
                  on Neural Information Processing Systems 2020, NeurIPS 2020, December
                  6-12, 2020, virtual},
  year         = {2020}
}


@inproceedings{DBLP:conf/nips/ZhangHDZY23,
  author       = {Yi{-}Kai Zhang and
                  Ting{-}Ji Huang and
                  Yao{-}Xiang Ding and
                  De{-}Chuan Zhan and
                  Han{-}Jia Ye},
  title        = {Model Spider: Learning to Rank Pre-Trained Models Efficiently},
  booktitle    = {NeurIPS},
  year         = {2023}
}

@article{DBLP:journals/corr/abs-2403-13797,
  author       = {Chao Yi and
                  De{-}Chuan Zhan and
                  Han{-}Jia Ye},
  title        = {Bridge the Modality and Capacity Gaps in Vision-Language Model Selection},
  journal      = {CoRR},
  volume       = {abs/2403.13797},
  year         = {2024}
}