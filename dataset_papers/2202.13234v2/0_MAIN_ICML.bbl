\begin{thebibliography}{51}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbasi-Yadkori et~al.(2011)Abbasi-Yadkori, P{\'a}l, and
  Szepesv{\'a}ri]{abbasi2011improved}
Abbasi-Yadkori, Y., P{\'a}l, D., and Szepesv{\'a}ri, C.
\newblock Improved algorithms for linear stochastic bandits.
\newblock \emph{Advances in neural information processing systems},
  24:\penalty0 2312--2320, 2011.

\bibitem[Allen-Zhu et~al.(2017)Allen-Zhu, Li, Singh, and Wang]{allen2017near}
Allen-Zhu, Z., Li, Y., Singh, A., and Wang, Y.
\newblock Near-optimal design of experiments via regret minimization.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  126--135. PMLR, 2017.

\bibitem[Amani et~al.(2019)Amani, Alizadeh, and Thrampoulidis]{amani2019linear}
Amani, S., Alizadeh, M., and Thrampoulidis, C.
\newblock Linear stochastic bandits under safety constraints.
\newblock \emph{arXiv preprint arXiv:1908.05814}, 2019.

\bibitem[Azizi et~al.(2021)Azizi, Kveton, and Ghavamzadeh]{azizi2021fixed}
Azizi, M., Kveton, B., and Ghavamzadeh, M.
\newblock Fixed-budget best-arm identification in contextual bandits: A
  static-adaptive algorithm.
\newblock \emph{arXiv preprint arXiv:2106.04763}, 2021.

\bibitem[Baird et~al.(2018)Baird, Bohren, McIntosh, and
  {\"O}zler]{baird2018optimal}
Baird, S., Bohren, J.~A., McIntosh, C., and {\"O}zler, B.
\newblock Optimal design of experiments in the presence of interference.
\newblock \emph{Review of Economics and Statistics}, 100\penalty0 (5):\penalty0
  844--860, 2018.

\bibitem[Bertsimas \& Tsitsiklis(1997)Bertsimas and
  Tsitsiklis]{bertsimas1997introduction}
Bertsimas, D. and Tsitsiklis, J.~N.
\newblock \emph{Introduction to linear optimization}, volume~6.
\newblock Athena Scientific Belmont, MA, 1997.

\bibitem[Bottou et~al.(2013)Bottou, Peters, Qui{\~n}onero-Candela, Charles,
  Chickering, Portugaly, Ray, Simard, and Snelson]{bottou2013counterfactual}
Bottou, L., Peters, J., Qui{\~n}onero-Candela, J., Charles, D.~X., Chickering,
  D.~M., Portugaly, E., Ray, D., Simard, P., and Snelson, E.
\newblock Counterfactual reasoning and learning systems: The example of
  computational advertising.
\newblock \emph{Journal of Machine Learning Research}, 14\penalty0 (11), 2013.

\bibitem[Bouhtou et~al.(2010)Bouhtou, Gaubert, and
  Sagnol]{bouhtou2010submodularity}
Bouhtou, M., Gaubert, S., and Sagnol, G.
\newblock Submodularity and randomized rounding techniques for optimal
  experimental design.
\newblock \emph{Electronic Notes in Discrete Mathematics}, 36:\penalty0
  679--686, 2010.

\bibitem[Boyd \& Vandenberghe(2007)Boyd and Vandenberghe]{boyd2007localization}
Boyd, S. and Vandenberghe, L.
\newblock Localization and cutting-plane methods.
\newblock \emph{From Stanford EE 364b lecture notes}, 2007.

\bibitem[Boyd et~al.(2004)Boyd, Boyd, and Vandenberghe]{boyd2004convex}
Boyd, S., Boyd, S.~P., and Vandenberghe, L.
\newblock \emph{Convex optimization}.
\newblock Cambridge university press, 2004.

\bibitem[Brown \& Gajek(1990)Brown and Gajek]{brown1990information}
Brown, L.~D. and Gajek, L.
\newblock Information inequalities for the bayes risk.
\newblock \emph{The Annals of Statistics}, 18\penalty0 (4):\penalty0
  1578--1594, 1990.

\bibitem[Brumback(2009)]{brumback2009note}
Brumback, B.~A.
\newblock A note on using the estimated versus the known propensity score to
  estimate the average treatment effect.
\newblock \emph{Statistics \& Probability Letters}, 79\penalty0 (4):\penalty0
  537--542, 2009.

\bibitem[Cai et~al.(2020)Cai, Lu, and Song]{cai2020validation}
Cai, H., Lu, W., and Song, R.
\newblock On validation and planning of an optimal decision rule with
  application in healthcare studies.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1262--1270. PMLR, 2020.

\bibitem[Cai et~al.(2021)Cai, Shi, Song, and Lu]{cai2021deep}
Cai, H., Shi, C., Song, R., and Lu, W.
\newblock Deep jump learning for off-policy evaluation in continuous treatment
  settings.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Degenne et~al.(2019)Degenne, Koolen, and M{\'e}nard]{degenne2019non}
Degenne, R., Koolen, W.~M., and M{\'e}nard, P.
\newblock Non-asymptotic pure exploration by solving games.
\newblock \emph{arXiv preprint arXiv:1906.10431}, 2019.

\bibitem[Deng(2012)]{deng2012mnist}
Deng, L.
\newblock The mnist database of handwritten digit images for machine learning
  research [best of the web].
\newblock \emph{IEEE Signal Processing Magazine}, 29\penalty0 (6):\penalty0
  141--142, 2012.

\bibitem[Dud{\'\i}k et~al.(2014)Dud{\'\i}k, Erhan, Langford, and
  Li]{dudik2014doubly}
Dud{\'\i}k, M., Erhan, D., Langford, J., and Li, L.
\newblock Doubly robust policy evaluation and optimization.
\newblock \emph{Statistical Science}, 29\penalty0 (4):\penalty0 485--511, 2014.

\bibitem[Fontaine et~al.(2021)Fontaine, Perrault, Valko, and
  Perchet]{fontaine2021online}
Fontaine, X., Perrault, P., Valko, M., and Perchet, V.
\newblock Online a-optimal design and active linear regression.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3374--3383. PMLR, 2021.

\bibitem[Frank et~al.(1956)Frank, Wolfe, et~al.]{frank1956algorithm}
Frank, M., Wolfe, P., et~al.
\newblock An algorithm for quadratic programming.
\newblock \emph{Naval research logistics quarterly}, 3\penalty0 (1-2):\penalty0
  95--110, 1956.

\bibitem[Horvitz \& Thompson(1952)Horvitz and
  Thompson]{horvitz1952generalization}
Horvitz, D.~G. and Thompson, D.~J.
\newblock A generalization of sampling without replacement from a finite
  universe.
\newblock \emph{Journal of the American statistical Association}, 47\penalty0
  (260):\penalty0 663--685, 1952.

\bibitem[Hsu et~al.(2011)Hsu, Kakade, and Zhang]{hsu2011analysis}
Hsu, D., Kakade, S.~M., and Zhang, T.
\newblock An analysis of random design linear regression.
\newblock \emph{arXiv preprint arXiv:1106.2363}, 2011.

\bibitem[Jaggi(2013)]{jaggi2013revisiting}
Jaggi, M.
\newblock Revisiting frank-wolfe: Projection-free sparse convex optimization.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  427--435. PMLR, 2013.

\bibitem[Jiang \& Li(2016)Jiang and Li]{jiang2016doubly}
Jiang, N. and Li, L.
\newblock Doubly robust off-policy value evaluation for reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  652--661. PMLR, 2016.

\bibitem[Kallus et~al.(2021)Kallus, Saito, and Uehara]{kallus2021optimal}
Kallus, N., Saito, Y., and Uehara, M.
\newblock Optimal off-policy evaluation from multiple logging policies.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5247--5256. PMLR, 2021.

\bibitem[Kazerouni et~al.(2016)Kazerouni, Ghavamzadeh, Abbasi-Yadkori, and
  Van~Roy]{kazerouni2016conservative}
Kazerouni, A., Ghavamzadeh, M., Abbasi-Yadkori, Y., and Van~Roy, B.
\newblock Conservative contextual linear bandits.
\newblock \emph{arXiv preprint arXiv:1611.06426}, 2016.

\bibitem[Kveton et~al.(2021)Kveton, Konobeev, Zaheer, Hsu, Mladenov, Boutilier,
  and Szepesvari]{kveton2021meta}
Kveton, B., Konobeev, M., Zaheer, M., Hsu, C.-w., Mladenov, M., Boutilier, C.,
  and Szepesvari, C.
\newblock Meta-thompson sampling.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5884--5893. PMLR, 2021.

\bibitem[Lattimore \& Szepesv{\'a}ri(2020)Lattimore and
  Szepesv{\'a}ri]{lattimore2020bandit}
Lattimore, T. and Szepesv{\'a}ri, C.
\newblock \emph{Bandit algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem[Lee(1988)]{lee1988constrained}
Lee, C. M.-S.
\newblock Constrained optimal designs.
\newblock \emph{Journal of Statistical Planning and Inference}, 18\penalty0
  (3):\penalty0 377--389, 1988.

\bibitem[Li et~al.(2011)Li, Chu, Langford, and Wang]{li2011unbiased}
Li, L., Chu, W., Langford, J., and Wang, X.
\newblock Unbiased offline evaluation of contextual-bandit-based news article
  recommendation algorithms.
\newblock In \emph{Proceedings of the fourth ACM international conference on
  Web search and data mining}, pp.\  297--306, 2011.

\bibitem[Li et~al.(2015)Li, Munos, and Szepesv{\'a}ri]{li2015toward}
Li, L., Munos, R., and Szepesv{\'a}ri, C.
\newblock Toward minimax off-policy value estimation.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  608--616.
  PMLR, 2015.

\bibitem[Moradipari et~al.(2020)Moradipari, Thrampoulidis, and
  Alizadeh]{moradipari2020stage}
Moradipari, A., Thrampoulidis, C., and Alizadeh, M.
\newblock Stage-wise conservative linear bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Oosterhuis \& de~Rijke(2020)Oosterhuis and
  de~Rijke]{oosterhuis2020taking}
Oosterhuis, H. and de~Rijke, M.
\newblock Taking the counterfactual online: Efficient and unbiased online
  evaluation for ranking.
\newblock In \emph{Proceedings of the 2020 ACM SIGIR on International
  Conference on Theory of Information Retrieval}, pp.\  137--144, 2020.

\bibitem[Sachdeva et~al.(2020)Sachdeva, Su, and Joachims]{sachdeva2020off}
Sachdeva, N., Su, Y., and Joachims, T.
\newblock Off-policy bandits with deficient support.
\newblock In \emph{Proceedings of the 26th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pp.\  965--975, 2020.

\bibitem[Shah \& Sinha(2012)Shah and Sinha]{shah2012theory}
Shah, K.~R. and Sinha, B.
\newblock \emph{Theory of optimal designs}, volume~54.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Shi et~al.(2021)Shi, Wan, Chernozhukov, and Song]{shi2021deeply}
Shi, C., Wan, R., Chernozhukov, V., and Song, R.
\newblock Deeply-debiased off-policy interval estimation.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  9580--9591. PMLR, 2021.

\bibitem[Slivkins(2019)]{slivkins2019introduction}
Slivkins, A.
\newblock Introduction to multi-armed bandits.
\newblock \emph{arXiv preprint arXiv:1904.07272}, 2019.

\bibitem[Su et~al.(2020)Su, Dimakopoulou, Krishnamurthy, and
  Dud{\'\i}k]{su2020doubly}
Su, Y., Dimakopoulou, M., Krishnamurthy, A., and Dud{\'\i}k, M.
\newblock Doubly robust off-policy evaluation with shrinkage.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  9167--9176. PMLR, 2020.

\bibitem[Swaminathan et~al.(2016)Swaminathan, Krishnamurthy, Agarwal,
  Dud{\'\i}k, Langford, Jose, and Zitouni]{swaminathan2016off}
Swaminathan, A., Krishnamurthy, A., Agarwal, A., Dud{\'\i}k, M., Langford, J.,
  Jose, D., and Zitouni, I.
\newblock Off-policy evaluation for slate recommendation.
\newblock \emph{arXiv preprint arXiv:1605.04812}, 2016.

\bibitem[Thomas et~al.(2015)Thomas, Theocharous, and
  Ghavamzadeh]{thomas2015high}
Thomas, P., Theocharous, G., and Ghavamzadeh, M.
\newblock High confidence policy improvement.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2380--2388. PMLR, 2015.

\bibitem[Tran-The et~al.(2021)Tran-The, Gupta, Nguyen-Tang, Rana, and
  Venkatesh]{tran2021combining}
Tran-The, H., Gupta, S., Nguyen-Tang, T., Rana, S., and Venkatesh, S.
\newblock Combining online learning and offline learning for contextual bandits
  with deficient support.
\newblock \emph{arXiv preprint arXiv:2107.11533}, 2021.

\bibitem[Tsiatis(2007)]{tsiatis2007semiparametric}
Tsiatis, A.
\newblock \emph{Semiparametric theory and missing data}.
\newblock Springer Science \& Business Media, 2007.

\bibitem[Tucker \& Joachims(2022)Tucker and Joachims]{tucker2022variance}
Tucker, A.~D. and Joachims, T.
\newblock Variance-optimal augmentation logging for counterfactual evaluation
  in contextual bandits.
\newblock \emph{arXiv preprint arXiv:2202.01721}, 2022.

\bibitem[Vershynin(2010)]{vershynin2010introduction}
Vershynin, R.
\newblock Introduction to the non-asymptotic analysis of random matrices.
\newblock \emph{arXiv preprint arXiv:1011.3027}, 2010.

\bibitem[Wan et~al.(2021)Wan, Ge, and Song]{wan2021metadata}
Wan, R., Ge, L., and Song, R.
\newblock Metadata-based multi-task bandits with bayesian hierarchical models.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Wang et~al.(2017)Wang, Agarwal, and Dud{\i}k]{wang2017optimal}
Wang, Y.-X., Agarwal, A., and Dud{\i}k, M.
\newblock Optimal and adaptive off-policy evaluation in contextual bandits.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3589--3597. PMLR, 2017.

\bibitem[Wu et~al.(2015)Wu, Srikant, Liu, and Jiang]{wu2015algorithms}
Wu, H., Srikant, R., Liu, X., and Jiang, C.
\newblock Algorithms with logarithmic or sublinear regret for constrained
  contextual bandits.
\newblock \emph{arXiv preprint arXiv:1504.06937}, 2015.

\bibitem[Wu et~al.(2016)Wu, Shariff, Lattimore, and
  Szepesv{\'a}ri]{wu2016conservative}
Wu, Y., Shariff, R., Lattimore, T., and Szepesv{\'a}ri, C.
\newblock Conservative bandits.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1254--1262. PMLR, 2016.

\bibitem[Xu et~al.(2018)Xu, Honda, and Sugiyama]{xu2018fully}
Xu, L., Honda, J., and Sugiyama, M.
\newblock A fully adaptive algorithm for pure exploration in linear bandits.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  843--851. PMLR, 2018.

\bibitem[Zanette et~al.(2021)Zanette, Dong, Lee, and
  Brunskill]{zanette2021design}
Zanette, A., Dong, K., Lee, J.~N., and Brunskill, E.
\newblock Design of experiments for stochastic contextual linear bandits.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 22720--22731, 2021.

\bibitem[Zhou et~al.(2017)Zhou, Mayer-Hamblett, Khan, and
  Kosorok]{zhou2017residual}
Zhou, X., Mayer-Hamblett, N., Khan, U., and Kosorok, M.~R.
\newblock Residual weighted learning for estimating individualized treatment
  rules.
\newblock \emph{Journal of the American Statistical Association}, 112\penalty0
  (517):\penalty0 169--187, 2017.

\bibitem[Zhu \& Kveton(2022)Zhu and Kveton]{zhu2021safe}
Zhu, R. and Kveton, B.
\newblock Safe optimal design with applications in off-policy learning.
\newblock In \emph{Proceedings of the 25th International Conference on
  Artificial Intelligence and Statistics}, pp.\  2436--2447, 2022.

\end{thebibliography}
