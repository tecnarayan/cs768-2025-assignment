\begin{thebibliography}{34}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Zinkevich(2003)]{zinkevich2003online}
M.~Zinkevich.
\newblock Online convex programming and generalized infinitesimal gradient
  ascent.
\newblock In \emph{International Conference on Machine Learing (ICML)}, 2003.

\bibitem[Hazan(2016)]{hazan2016introduction}
E.~Hazan.
\newblock Introduction to online convex optimization.
\newblock \emph{Foundations and Trends{\textregistered} in Optimization},
  2\penalty0 (3-4):\penalty0 157--325, 2016.

\bibitem[Hazan and Megiddo(2007)]{hazan2007online}
E.~Hazan and N.~Megiddo.
\newblock {O}nline {L}earning with {P}rior {K}nowledge.
\newblock In \emph{{L}earning {T}heory}, pages 499--513. Springer, 2007.

\bibitem[Cesa-Bianchi et~al.(2017)Cesa-Bianchi, Gaillard, Gentile, and
  Gerchinovitz]{cesa2017algorithmic}
N.~Cesa-Bianchi, P.~Gaillard, C.~Gentile, and S.~Gerchinovitz.
\newblock Algorithmic chaining and the role of partial feedback in online
  nonparametric learning.
\newblock In Satyen Kale and Ohad Shamir, editors, \emph{Conference on
  Computational Learning Theory (COLT)}, volume~65 of \emph{Proceedings of
  Machine Learning Research}, pages 465--481, Amsterdam, Netherlands, 07--10
  Jul 2017. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v65/cesa-bianchi17a.html}.

\bibitem[Rakhlin et~al.(2015)Rakhlin, Sridharan, and Tewari]{rakhlin2015online}
A.~Rakhlin, K.~Sridharan, and A.~Tewari.
\newblock Online learning via sequential complexities.
\newblock \emph{Journal of Machine Learning Research}, 16\penalty0
  (2):\penalty0 155--186, 2015.

\bibitem[Freund et~al.(1997)Freund, Schapire, Singer, and
  Warmuth]{freund1997using}
Y.~Freund, R.~E. Schapire, Y.~Singer, and M.~K. Warmuth.
\newblock Using and combining predictors that specialize.
\newblock In \emph{Proceedings of the {T}wenty-{N}inth {A}nnual {ACM}
  {S}ymposium on {T}heory of {C}omputing}, pages 334--343. ACM, 1997.

\bibitem[Luo and Schapire(2015)]{luo2015achieving}
H.~Luo and R.~E. Schapire.
\newblock Achieving {A}ll with {N}o {P}arameters: Ada{N}ormal{H}edge.
\newblock In \emph{Conference on Computational Learning Theory (COLT)}, 2015.

\bibitem[Brown and Low(1996)]{brown1996constrained}
L.~D. Brown and M.~G. Low.
\newblock A constrained risk inequality with applications to nonparametric
  functional estimation.
\newblock \emph{The Annals of Statistics}, 24\penalty0 (6):\penalty0
  2524--2535, 1996.

\bibitem[Efromovich and Low(1994)]{efromovich1994adaptive}
S.~Efromovich and M.~G. Low.
\newblock Adaptive estimates of linear functionals.
\newblock \emph{Probability theory and related fields}, 98\penalty0
  (2):\penalty0 261--275, 1994.

\bibitem[Lepski(1992)]{lepski1992problems}
O.~V. Lepski.
\newblock On problems of adaptive estimation in white gaussian noise.
\newblock \emph{Topics in nonparametric estimation}, 12:\penalty0 87--106,
  1992.

\bibitem[Mammen and van~de Geer(1997)]{mammen1997locally}
E.~Mammen and S.~van~de Geer.
\newblock Locally adaptive regression splines.
\newblock \emph{The Annals of Statistics}, 25\penalty0 (1):\penalty0 387--413,
  1997.

\bibitem[Tibshirani(2014)]{tibshirani2014adaptive}
R.~J. Tibshirani.
\newblock Adaptive piecewise polynomial estimation via trend filtering.
\newblock \emph{The Annals of Statistics}, 42\penalty0 (1):\penalty0 285--323,
  2014.

\bibitem[Vovk(2006{\natexlab{a}})]{vovk2006metric}
V.~Vovk.
\newblock Metric entropy in competitive on-line prediction.
\newblock \emph{arXiv preprint cs/0609045}, 2006{\natexlab{a}}.

\bibitem[Vovk(2006{\natexlab{b}})]{vovk2006online}
V.~Vovk.
\newblock On-line regression competitive with reproducing kernel {H}ilbert
  spaces.
\newblock In \emph{International Conference on Theory and Applications of
  Models of Computation}. Springer, 2006{\natexlab{b}}.

\bibitem[Vovk(2007)]{vovk2007competing}
V.~Vovk.
\newblock Competing with wild prediction rules.
\newblock \emph{Machine Learning}, 69\penalty0 (2):\penalty0 193--212, 2007.

\bibitem[Rakhlin and Sridharan(2014)]{rakhlin2014online}
A.~Rakhlin and K.~Sridharan.
\newblock {O}nline {N}on-{P}arametric {R}egression.
\newblock In \emph{Conference on Computational Learning Theory (COLT)}, 2014.

\bibitem[Gaillard and Gerchinovitz(2015)]{gaillard2015chaining}
P.~Gaillard and S.~Gerchinovitz.
\newblock A chaining algorithm for online nonparametric regression.
\newblock In \emph{Conference on Computational Learning Theory (COLT)}, 2015.

\bibitem[Kpotufe and Orabona(2013)]{kpotufe2013regression}
S.~Kpotufe and F.~Orabona.
\newblock {R}egression-{T}ree {T}uning in a {S}treaming {S}etting.
\newblock In \emph{Conference on Neural Information Processing Systems (NIPS)},
  2013.

\bibitem[Helmbold and Schapire(1997)]{helmbold1997predicting}
D.~P. Helmbold and R.~E. Schapire.
\newblock Predicting nearly as well as the best pruning of a decision tree.
\newblock \emph{Machine Learning}, 27\penalty0 (1):\penalty0 51--68, 1997.

\bibitem[Cesa-Bianchi and Lugosi(2006)]{cesa2006prediction}
N.~Cesa-Bianchi and G.~Lugosi.
\newblock \emph{Prediction, learning, and games}.
\newblock Cambridge university press, 2006.

\bibitem[Willems et~al.(1995)Willems, Shtarkov, and
  Tjalkens]{willems1995context}
F.~M.J. Willems, Y.~M. Shtarkov, and T.~J. Tjalkens.
\newblock The context-tree weighting method: basic properties.
\newblock \emph{IEEE Transactions on Information Theory}, 41\penalty0
  (3):\penalty0 653--664, 1995.

\bibitem[van Erven and Koolen(2016)]{van2016metagrad}
T.~van Erven and W.~M. Koolen.
\newblock Metagrad: Multiple learning rates in online learning.
\newblock In \emph{Conference on Neural Information Processing Systems (NIPS)},
  2016.

\bibitem[Orabona and P{\'a}l(2016)]{orabona2016coin}
F.~Orabona and D.~P{\'a}l.
\newblock Coin betting and parameter-free online learning.
\newblock In \emph{Conference on Neural Information Processing Systems (NIPS)},
  2016.

\bibitem[Kpotufe(2011)]{kpotufe2011k}
S.~Kpotufe.
\newblock k-{NN} regression adapts to local intrinsic dimension.
\newblock In \emph{Conference on Neural Information Processing Systems (NIPS)},
  2011.

\bibitem[Kpotufe and Garg(2013)]{kpotufe2013adaptivity}
S.~Kpotufe and V.~Garg.
\newblock Adaptivity to local smoothness and dimension in kernel regression.
\newblock In \emph{Conference on Neural Information Processing Systems (NIPS)},
  2013.

\bibitem[Kuzborskij and Cesa-Bianchi(2017)]{kuzborskij2017nonparametric}
I.~Kuzborskij and N.~Cesa-Bianchi.
\newblock {N}onparametric {O}nline {R}egression while {L}earning the {M}etric.
\newblock In \emph{Conference on Neural Information Processing Systems (NIPS)},
  2017.

\bibitem[Mhammedi et~al.(2019)Mhammedi, Koolen, and
  Van~Erven]{mhammedi2019lipschitz}
Z.~Mhammedi, W.~M. Koolen, and T.~Van~Erven.
\newblock Lipschitz adaptivity with multiple learning rates in online learning.
\newblock In \emph{Conference on Computational Learning Theory (COLT)}, 2019.

\bibitem[Munos(2011)]{munos2011optimistic}
R.~Munos.
\newblock Optimistic optimization of a deterministic function without the
  knowledge of its smoothness.
\newblock In \emph{Conference on Neural Information Processing Systems (NIPS)},
  2011.

\bibitem[Cavallanti et~al.(2007)Cavallanti, Cesa-Bianchi, and
  Gentile]{cavallanti2007tracking}
G.~Cavallanti, N.~Cesa-Bianchi, and C.~Gentile.
\newblock Tracking the best hyperplane with a simple budget perceptron.
\newblock \emph{Machine Learning}, 69\penalty0 (2-3):\penalty0 143--167, 2007.

\bibitem[Dekel et~al.(2008)Dekel, Shalev-Shwartz, and
  Singer]{dekel2008forgetron}
O.~Dekel, S.~Shalev-Shwartz, and Y.~Singer.
\newblock The forgetron: A kernel-based perceptron on a budget.
\newblock \emph{SIAM Journal on Computing}, 37\penalty0 (5):\penalty0
  1342--1372, 2008.

\bibitem[Koolen and Van~Erven(2015)]{koolen2015second}
W.~M. Koolen and T.~Van~Erven.
\newblock Second-order quantile methods for experts and combinatorial games.
\newblock In \emph{Conference on Computational Learning Theory (COLT)}, 2015.

\bibitem[Orabona(2019)]{orabona2019modern}
F.~Orabona.
\newblock A modern introduction to online learning.
\newblock \emph{arXiv preprint arXiv:1912.13213}, 2019.

\bibitem[Mourtada and Maillard(2017)]{mourtada2017efficient}
J.~Mourtada and O.-A. Maillard.
\newblock Efficient tracking of a growing number of experts.
\newblock In \emph{Algorithmic Learning Theory (ALT)}, 2017.

\bibitem[Auer et~al.(2002)Auer, Cesa-Bianchi, and Gentile]{auer2002adaptive}
P.~Auer, N.~Cesa-Bianchi, and C.~Gentile.
\newblock Adaptive and self-confident on-line learning algorithms.
\newblock \emph{Journal of Computer and System Sciences}, 64\penalty0
  (1):\penalty0 48--75, 2002.

\end{thebibliography}
