\begin{thebibliography}{}

\bibitem[Agrawal et~al., 2017a]{agrawal2017mnl}
Agrawal, S., Avadhanula, V., Goyal, V., and Zeevi, A. (2017a).
\newblock Mnl-bandit: a dynamic learning approach to assortment selection.
\newblock {\em arXiv preprint arXiv:1706.03880}.

\bibitem[Agrawal et~al., 2017b]{agrawal2017thompson}
Agrawal, S., Avadhanula, V., Goyal, V., and Zeevi, A. (2017b).
\newblock Thompson sampling for the mnl-bandit.
\newblock {\em arXiv preprint arXiv:1706.00977}.

\bibitem[Auer, 2002]{auer2002using}
Auer, P. (2002).
\newblock Using confidence bounds for exploitation-exploration trade-offs.
\newblock {\em Journal of Machine Learning Research}, 3(Nov):397--422.

\bibitem[Chen et~al., 2013]{chen2013combinatorial}
Chen, W., Wang, Y., and Yuan, Y. (2013).
\newblock Combinatorial multi-armed bandit: General framework and applications.
\newblock In {\em International Conference on Machine Learning}, pages
  151--159.

\bibitem[Cheung and Simchi-Levi, 2017]{cheung2017thompson}
Cheung, W.~C. and Simchi-Levi, D. (2017).
\newblock Thompson sampling for online personalized assortment optimization
  problems with multinomial logit choice models.

\bibitem[Flores et~al., 2018]{flores2018assortment}
Flores, A., Berbeglia, G., and Van~Hentenryck, P. (2018).
\newblock Assortment optimization under the sequential multinomial logit model.
\newblock {\em European Journal of Operational Research}.

\bibitem[K{\"o}k et~al., 2008]{kok2008assortment}
K{\"o}k, A.~G., Fisher, M.~L., and Vaidyanathan, R. (2008).
\newblock Assortment planning: Review of literature and industry practice.
\newblock In {\em Retail supply chain management}, pages 99--153. Springer.

\bibitem[Robbins, 1985]{robbins1985some}
Robbins, H. (1985).
\newblock Some aspects of the sequential design of experiments.
\newblock In {\em Herbert Robbins Selected Papers}, pages 169--177. Springer.

\bibitem[Rusmevichientong et~al., 2010]{rusmevichientong2010dynamic}
Rusmevichientong, P., Shen, Z.-J.~M., and Shmoys, D.~B. (2010).
\newblock Dynamic assortment optimization with a multinomial logit choice model
  and capacity constraint.
\newblock {\em Operations research}, 58(6):1666--1680.

\bibitem[Rusmevichientong and Tsitsiklis, 2010]{rusmevichientong2010linearly}
Rusmevichientong, P. and Tsitsiklis, J.~N. (2010).
\newblock Linearly parameterized bandits.
\newblock {\em Mathematics of Operations Research}, 35(2):395--411.

\bibitem[Saur{\'e} and Zeevi, 2013]{saure2013optimal}
Saur{\'e}, D. and Zeevi, A. (2013).
\newblock Optimal dynamic assortment planning with demand learning.
\newblock {\em Manufacturing \& Service Operations Management}, 15(3):387--404.

\bibitem[Sutton et~al., 1998]{sutton1998reinforcement}
Sutton, R.~S., Barto, A.~G., et~al. (1998).
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press.

\bibitem[Talluri and Van~Ryzin, 2004]{talluri2004revenue}
Talluri, K. and Van~Ryzin, G. (2004).
\newblock Revenue management under a general discrete choice model of consumer
  behavior.
\newblock {\em Management Science}, 50(1):15--33.

\bibitem[Train, 2009]{train2009discrete}
Train, K.~E. (2009).
\newblock {\em Discrete choice methods with simulation}.
\newblock Cambridge university press.

\end{thebibliography}
