\begin{thebibliography}{10}

\bibitem{abramson2024accurate}
Josh Abramson, Jonas Adler, Jack Dunger, Richard Evans, Tim Green, Alexander Pritzel, Olaf Ronneberger, Lindsay Willmore, Andrew~J Ballard, Joshua Bambrick, et~al.
\newblock Accurate structure prediction of biomolecular interactions with alphafold 3.
\newblock {\em Nature}, pages 1--3, 2024.

\bibitem{jumper2021highly}
John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin {\v{Z}}{\'\i}dek, Anna Potapenko, et~al.
\newblock Highly accurate protein structure prediction with alphafold.
\newblock {\em Nature}, 596(7873):583--589, 2021.

\bibitem{lin2022language}
Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos~Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, et~al.
\newblock Language models of protein sequences at the scale of evolution enable accurate structure prediction.
\newblock {\em BioRxiv}, 2022:500902, 2022.

\bibitem{gebauer2019symmetry}
Niklas Gebauer, Michael Gastegger, and Kristof Sch{\"u}tt.
\newblock Symmetry-adapted generation of 3d point sets for the targeted discovery of molecules.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{pmlr-v162-hoogeboom22a}
Emiel Hoogeboom, V\'{\i}ctor~Garcia Satorras, Cl{\'e}ment Vignac, and Max Welling.
\newblock Equivariant diffusion for molecule generation in 3{D}.
\newblock In Kamalika Chaudhuri, Stefanie Jegelka, Le~Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, {\em Proceedings of the 39th International Conference on Machine Learning}, volume 162 of {\em Proceedings of Machine Learning Research}, pages 8867--8887. PMLR, 17--23 Jul 2022.

\bibitem{xu2022geodiff}
Minkai Xu, Lantao Yu, Yang Song, Chence Shi, Stefano Ermon, and Jian Tang.
\newblock Geodiff: A geometric diffusion model for molecular conformation generation.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{jing2022torsional}
Bowen Jing, Gabriele Corso, Jeffrey Chang, Regina Barzilay, and Tommi Jaakkola.
\newblock Torsional diffusion for molecular conformer generation.
\newblock In S.~Koyejo, S.~Mohamed, A.~Agarwal, D.~Belgrave, K.~Cho, and A.~Oh, editors, {\em Advances in Neural Information Processing Systems}, volume~35, pages 24240--24253. Curran Associates, Inc., 2022.

\bibitem{noe2019boltzmann}
Frank No{\'e}, Simon Olsson, Jonas K{\"o}hler, and Hao Wu.
\newblock Boltzmann generators --- sampling equilibrium states of many-body systems with deep learning.
\newblock {\em Science}, 365:eaaw1147, 2019.

\bibitem{coretti2024boltzmann}
Alessandro Coretti, Sebastian Falkner, Jan Weinreich, Christoph Dellago, and O~Anatole von Lilienfeld.
\newblock Boltzmann generators and the new frontier of computational sampling in many-body systems.
\newblock {\em arXiv preprint arXiv:2404.16566}, 2024.

\bibitem{rotskoff2024sampling}
Grant~M Rotskoff.
\newblock Sampling thermodynamic ensembles of molecular systems with generative neural networks: Will integrating physics-based models close the generalization gap?
\newblock {\em Current Opinion in Solid State and Materials Science}, 30:101158, 2024.

\bibitem{klein2023timewarp}
Leon Klein, Andrew Y.~K. Foong, Tor~Erlend Fjelde, Bruno~Kacper Mlodozeniec, Marc Brockschmidt, Sebastian Nowozin, Frank Noe, and Ryota Tomioka.
\newblock Timewarp: Transferable acceleration of molecular dynamics by learning time-coarsened dynamics.
\newblock In {\em Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem{tabak2010density}
Esteban~G Tabak, Eric Vanden-Eijnden, et~al.
\newblock Density estimation by dual ascent of the log-likelihood.
\newblock {\em Communications in Mathematical Sciences}, 8(1):217--233, 2010.

\bibitem{tabak2013family}
Esteban~G Tabak and Cristina~V Turner.
\newblock A family of nonparametric density estimation algorithms.
\newblock {\em Communications on Pure and Applied Mathematics}, 66(2):145--164, 2013.

\bibitem{papamakarios19_normal_flows_probab_model_infer}
George Papamakarios, Eric Nalisnick, Danilo~Jimenez Rezende, Shakir Mohamed, and Balaji Lakshminarayanan.
\newblock Normalizing flows for probabilistic modeling and inference.
\newblock {\em CoRR}, 2019.

\bibitem{RezendeEtAl_NormalizingFlows}
Danilo Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock In {\em International conference on machine learning}, pages 1530--1538. PMLR, 2015.

\bibitem{chen2018neural}
Tian~Qi Chen, Yulia Rubanova, Jesse Bettencourt, and David~K Duvenaud.
\newblock Neural ordinary differential equations.
\newblock In {\em Advances in neural information processing systems}, pages 6571--6583, 2018.

\bibitem{grathwohl2018ffjord}
Will Grathwohl, Ricky T.~Q. Chen, Jesse Bettencourt, and David Duvenaud.
\newblock Scalable reversible generative models with free-form continuous dynamics.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{dinh14_nice}
Laurent Dinh, David Krueger, and Yoshua Bengio.
\newblock Nice: Non-linear independent components estimation.
\newblock {\em CoRR}, 2014.

\bibitem{lipman2022flow}
Yaron Lipman, Ricky T.~Q. Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le.
\newblock Flow matching for generative modeling.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2023.

\bibitem{albergo2023building}
Michael~Samuel Albergo and Eric Vanden-Eijnden.
\newblock Building normalizing flows with stochastic interpolants.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2023.

\bibitem{liu2023flow}
Xingchao Liu, Chengyue Gong, and qiang liu.
\newblock Flow straight and fast: Learning to generate and transfer data with rectified flow.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2023.

\bibitem{tong2023conditional}
Alexander Tong, Nikolay Malkin, Guillaume Huguet, Yanlei Zhang, Jarrid Rector-Brooks, Kilian Fatras, Guy Wolf, and Yoshua Bengio.
\newblock Conditional flow matching: Simulation-free dynamic optimal transport.
\newblock {\em arXiv preprint arXiv:2302.00482}, 2023.

\bibitem{klein2023equivariant}
Leon Klein, Andreas Kr{\"a}mer, and Frank Noe.
\newblock Equivariant flow matching.
\newblock In {\em Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem{midgley2023se}
Laurence~Illing Midgley, Vincent Stimper, Javier Antoran, Emile Mathieu, Bernhard Sch{\"o}lkopf, and Jos{\'e}~Miguel Hern{\'a}ndez-Lobato.
\newblock {SE}(3) equivariant augmented coupling flows.
\newblock In {\em Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem{wirnsberger2020targeted}
Peter Wirnsberger, Andrew~J Ballard, George Papamakarios, Stuart Abercrombie, S{\'e}bastien Racani{\`e}re, Alexander Pritzel, Danilo Jimenez~Rezende, and Charles Blundell.
\newblock Targeted free energy estimation via learned mappings.
\newblock {\em The Journal of Chemical Physics}, 153(14):144112, 2020.

\bibitem{dibak2021temperature}
Manuel Dibak, Leon Klein, Andreas Kr\"amer, and Frank No\'e.
\newblock Temperature steerable flows and {Boltzmann} generators.
\newblock {\em Phys. Rev. Res.}, 4:L042005, Oct 2022.

\bibitem{kohler2021smooth}
Jonas K\"{o}hler, Andreas Kr\"{a}mer, and Frank No√©.
\newblock Smooth normalizing flows.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.S. Liang, and J.~Wortman Vaughan, editors, {\em Advances in Neural Information Processing Systems}, volume~34, pages 2796--2809. Curran Associates, Inc., 2021.

\bibitem{midgley2022flow}
Laurence~Illing Midgley, Vincent Stimper, Gregor N.~C. Simm, Bernhard Sch{\"o}lkopf, and Jos{\'e}~Miguel Hern{\'a}ndez-Lobato.
\newblock Flow annealed importance sampling bootstrap.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2023.

\bibitem{ding2021deepbar}
Xinqiang Ding and Bin Zhang.
\newblock Deepbar: A fast and exact method for binding free energy computation.
\newblock {\em Journal of Physical Chemistry Letters}, 12:2509--2515, 3 2021.

\bibitem{kim2024scalableNormFlows}
Joseph~C. Kim, David Bloore, Karan Kapoor, Jun Feng, Ming-Hong Hao, and Mengdi Wang.
\newblock Scalable normalizing flows enable boltzmann generators for macromolecules.
\newblock In {\em International Conference on Learning Representations (ICLR)}, 2024.

\bibitem{Ahmad2022}
Rasool Ahmad and Wei Cai.
\newblock Free energy calculation of crystalline solids using normalizing flows.
\newblock {\em Modelling and Simulation in Materials Science and Engineering}, 30(6):065007, September 2022.

\bibitem{nicoli2021estimation}
Kim~A Nicoli, Christopher~J Anders, Lena Funcke, Tobias Hartung, Karl Jansen, Pan Kessel, Shinichi Nakajima, and Paolo Stornati.
\newblock Estimation of thermodynamic observables in lattice field theories with deep generative models.
\newblock {\em Physical review letters}, 126(3):032001, 2021.

\bibitem{schebek2024efficient}
Maximilian Schebek, Michele Invernizzi, Frank No{\'e}, and Jutta Rogal.
\newblock Efficient mapping of phase diagrams with conditional boltzmann generators.
\newblock {\em Machine Learning: Science and Technology}, 2024.

\bibitem{wu2020snf}
Hao Wu, Jonas K\"{o}hler, and Frank Noe.
\newblock Stochastic normalizing flows.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin, editors, {\em Advances in Neural Information Processing Systems}, volume~33, pages 5933--5944. Curran Associates, Inc., 2020.

\bibitem{ding2021computing}
Xinqiang Ding and Bin Zhang.
\newblock Computing absolute free energy with deep generative models.
\newblock {\em Biophysical Journal}, 120(3):195a, 2021.

\bibitem{rizzi2023multimap}
Andrea Rizzi, Paolo Carloni, and Michele Parrinello.
\newblock Multimap targeted free energy estimation, 2023.

\bibitem{tamagnone2024coarse}
Samuel Tamagnone, Alessandro Laio, and Marylou Gabri{\'e}.
\newblock Coarse-grained molecular dynamics with normalizing flows.
\newblock {\em Journal of Chemical Theory and Computation}, 20(18):7796--7805, 2024.

\bibitem{schonle2024sampling}
Christoph Sch{\"o}nle, Marylou Gabri{\'e}, Tony Leli{\`e}vre, and Gabriel Stoltz.
\newblock Sampling metastable systems using collective variables and jarzynski-crooks paths.
\newblock {\em arXiv preprint arXiv:2405.18160}, 2024.

\bibitem{kohler2020equivariant}
Jonas K{\"o}hler, Leon Klein, and Frank No{\'e}.
\newblock Equivariant flows: exact likelihood generative learning for symmetric densities.
\newblock In {\em International conference on machine learning}, pages 5361--5370. PMLR, 2020.

\bibitem{Rezende2019EquivariantHF}
Danilo~Jimenez Rezende, S{\'e}bastien Racani{\`e}re, Irina Higgins, and Peter Toth.
\newblock Equivariant {H}amiltonian flows.
\newblock {\em arXiv preprint arXiv:1909.13739}, 2019.

\bibitem{satorras2021n}
Victor Garcia~Satorras, Emiel Hoogeboom, Fabian Fuchs, Ingmar Posner, and Max Welling.
\newblock E(n) equivariant normalizing flows.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.S. Liang, and J.~Wortman Vaughan, editors, {\em Advances in Neural Information Processing Systems}, volume~34, pages 4181--4192. Curran Associates, Inc., 2021.

\bibitem{kohler2023rigid}
Jonas K{\"{o}}hler, Michele Invernizzi, Pim de~Haan, and Frank No{\'{e}}.
\newblock Rigid body flows for sampling molecular crystal structures.
\newblock In {\em International Conference on Machine Learning, {ICML} 2023}, volume 202 of {\em Proceedings of Machine Learning Research}, pages 17301--17326. {PMLR}, 2023.

\bibitem{rizzi2021targeted}
Andrea Rizzi, Paolo Carloni, and Michele Parrinello.
\newblock Targeted free energy perturbation revisited: Accurate free energies from mapped reference potentials.
\newblock {\em Journal of Physical Chemistry Letters}, 12:9449--9454, 2021.

\bibitem{invernizzi2022skipping}
Michele Invernizzi, Andreas Kr\"amer, Cecilia Clementi, and Frank No{\'e}.
\newblock Skipping the replica exchange ladder with normalizing flows.
\newblock {\em The Journal of Physical Chemistry Letters}, 13:11643--11649, 2022.

\bibitem{swanson2023mises}
Kirk Swanson, Jake~Lawrence Williams, and Eric~M Jonas.
\newblock Von mises mixture distributions for molecular conformation generation.
\newblock In {\em International Conference on Machine Learning}, pages 33319--33342. PMLR, 2023.

\bibitem{abdin2023pepflow}
Osama Abdin and Philip~M Kim.
\newblock Pepflow: direct conformational sampling from peptide energy landscapes through hypernetwork-conditioned diffusion.
\newblock {\em bioRxiv}, pages 2023--06, 2023.

\bibitem{jing2024alphafold}
Bowen Jing, Bonnie Berger, and Tommi Jaakkola.
\newblock Alphafold meets flow matching for generating protein ensembles.
\newblock {\em arXiv preprint arXiv:2402.04845}, 2024.

\bibitem{zheng2024predicting}
Shuxin Zheng, Jiyan He, Chang Liu, Yu~Shi, Ziheng Lu, Weitao Feng, Fusong Ju, Jiaxi Wang, Jianwei Zhu, Yaosen Min, et~al.
\newblock Predicting equilibrium distributions for molecular systems with deep learning.
\newblock {\em Nature Machine Intelligence}, pages 1--10, 2024.

\bibitem{diez2024generation}
Juan~Viguera Diez, Sara~Romeo Atance, Ola Engkvist, and Simon Olsson.
\newblock Generation of conformational ensembles of small molecules via surrogate model-assisted molecular dynamics.
\newblock {\em Machine Learning: Science and Technology}, 5(2):025010, 2024.

\bibitem{schreiner2023implicit}
Mathias Schreiner, Ole Winther, and Simon Olsson.
\newblock Implicit transfer operator learning: Multiple time-resolution models for molecular dynamics.
\newblock In {\em Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem{charron2023navigating}
Nicholas~E Charron, Felix Musil, Andrea Guljas, Yaoyi Chen, Klara Bonneau, Aldo~S Pasos-Trejo, Jacopo Venturin, Daria Gusew, Iryna Zaporozhets, Andreas Kr{\"a}mer, et~al.
\newblock Navigating protein landscapes with a machine-learned transferable coarse-grained model.
\newblock {\em arXiv preprint arXiv:2310.18278}, 2023.

\bibitem{kohler2023flow}
Jonas K{\"o}hler, Yaoyi Chen, Andreas Kr{\"a}mer, Cecilia Clementi, and Frank No{\'e}.
\newblock Flow-matching: Efficient coarse-graining of molecular dynamics without forces.
\newblock {\em Journal of Chemical Theory and Computation}, 19(3):942--952, 2023.

\bibitem{song2023equivariant}
Yuxuan Song, Jingjing Gong, Minkai Xu, Ziyao Cao, Yanyan Lan, Stefano Ermon, Hao Zhou, and Wei-Ying Ma.
\newblock Equivariant flow matching with hybrid probability transport for 3d molecule generation.
\newblock In {\em Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem{wang2024protein}
Yan Wang, Lihao Wang, Yuning Shen, Yiqun Wang, Huizhuo Yuan, Yue Wu, and Quanquan Gu.
\newblock Protein conformation generation via force-guided se (3) diffusion models.
\newblock {\em arXiv preprint arXiv:2403.14088}, 2024.

\bibitem{pmlr-v238-draxler24a}
Felix Draxler, Peter Sorrenson, Lea Zimmermann, Armand Rousselot, and Ullrich K\"{o}the.
\newblock Free-form flows: Make any architecture a normalizing flow.
\newblock In Sanjoy Dasgupta, Stephan Mandt, and Yingzhen Li, editors, {\em Proceedings of The 27th International Conference on Artificial Intelligence and Statistics}, volume 238 of {\em Proceedings of Machine Learning Research}, pages 2197--2205. PMLR, 02--04 May 2024.

\bibitem{wiegand1968kish}
H~Wiegand.
\newblock Kish, l.: Survey sampling. john wiley \& sons, inc., new york, london 1965, ix+ 643 s., 31 abb., 56 tab., preis 83 s., 1968.

\bibitem{papamakarios2021normalizing}
George Papamakarios, Eric~T Nalisnick, Danilo~Jimenez Rezende, Shakir Mohamed, and Balaji Lakshminarayanan.
\newblock Normalizing flows for probabilistic modeling and inference.
\newblock {\em J. Mach. Learn. Res.}, 22(57):1--64, 2021.

\bibitem{satorras2021graph}
V{\i}ctor~Garcia Satorras, Emiel Hoogeboom, and Max Welling.
\newblock E (n) equivariant graph neural networks.
\newblock In {\em International conference on machine learning}, pages 9323--9332. PMLR, 2021.

\bibitem{jing2020learning}
Bowen Jing, Stephan Eismann, Patricia Suriana, Raphael John~Lamarre Townshend, and Ron Dror.
\newblock Learning from protein structure with geometric vector perceptrons.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{schutt2021equivariant}
Kristof Sch{\"u}tt, Oliver Unke, and Michael Gastegger.
\newblock Equivariant message passing for the prediction of tensorial properties and molecular spectra.
\newblock In {\em International Conference on Machine Learning}, pages 9377--9388. PMLR, 2021.

\bibitem{liao2023equiformer}
Yi-Lun Liao and Tess Smidt.
\newblock Equiformer: Equivariant graph attention transformer for 3d atomistic graphs.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2023.

\bibitem{gasteiger2021gemnet}
Johannes Gasteiger, Florian Becker, and Stephan G{\"u}nnemann.
\newblock Gemnet: Universal directional graph neural networks for molecules.
\newblock {\em Advances in Neural Information Processing Systems}, 34:6790--6802, 2021.

\bibitem{Khler2020EquivariantFE}
Jonas K{\"o}hler, Leon Klein, and Frank No{\'e}.
\newblock Equivariant flows: exact likelihood generative learning for symmetric densities.
\newblock In {\em International Conference on Machine Learning}, pages 5361--5370. PMLR, 2020.

\bibitem{xtb}
Christoph Bannwarth, Sebastian Ehlert, and Stefan Grimme.
\newblock Gfn2-xtb‚Äîan accurate and broadly parametrized self-consistent tight-binding quantum chemical method with multipole electrostatics and density-dependent dispersion contributions.
\newblock {\em Journal of Chemical Theory and Computation}, 15(3):1652--1671, 2019.
\newblock PMID: 30741547.

\bibitem{perez2013identification}
Guillermo P{\'e}rez-Hern{\'a}ndez, Fabian Paul, Toni Giorgino, Gianni De~Fabritiis, and Frank No{\'e}.
\newblock Identification of slow molecular order parameters for {M}arkov model construction.
\newblock {\em The Journal of chemical physics}, 139(1):07B604\_1, 2013.

\bibitem{jing2023eigenfold}
Bowen Jing, Ezra Erives, Peter Pao-Huang, Gabriele Corso, Bonnie Berger, and Tommi Jaakkola.
\newblock Eigenfold: Generative protein structure prediction with diffusion models.
\newblock {\em arXiv preprint arXiv:2304.02198}, 2023.

\bibitem{stark2023harmonic}
Hannes St{\"a}rk, Bowen Jing, Regina Barzilay, and Tommi Jaakkola.
\newblock Harmonic self-conditioned flow matching for multi-ligand docking and binding site design.
\newblock {\em arXiv preprint arXiv:2310.05764}, 2023.

\bibitem{sharon2024go}
Dina~A Sharon, Yining Huang, Motolani Oyewole, and Sammy Mustafa.
\newblock How to go with the flow: an analysis of flow matching molecular docking performance with priors of varying information content.
\newblock In {\em ICLR 2024 Workshop on Generative and Experimental Perspectives for Biomolecular Design}, 2024.

\bibitem{du2023new}
Weitao Du, Yuanqi Du, Limei Wang, Dieqiao Feng, Guifeng Wang, Shuiwang Ji, Carla Gomes, and Zhi-Ming Ma.
\newblock A new perspective on building efficient and expressive 3d equivariant graph neural networks.
\newblock {\em arXiv preprint arXiv:2304.04757}, 2023.

\bibitem{yang2024mattersim}
Han Yang, Chenxi Hu, Yichi Zhou, Xixian Liu, Yu~Shi, Jielan Li, Guanzhi Li, Zekun Chen, Shuizhou Chen, Claudio Zeni, et~al.
\newblock Mattersim: A deep learning atomistic model across elements, temperatures and pressures.
\newblock {\em arXiv preprint arXiv:2405.04967}, 2024.

\bibitem{NEURIPS2019_9015}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In {\em Advances in Neural Information Processing Systems 32}, pages 8024--8035. Curran Associates, Inc., 2019.

\bibitem{politorchdyn}
Michael Poli, Stefano Massaroli, Atsushi Yamashita, Hajime Asama, Jinkyoo Park, and Stefano Ermon.
\newblock Torchdyn: Implicit models and neural numerical methods in pytorch.
\newblock In {\em Neural Information Processing Systems, Workshop on Physical Reasoning and Inductive Biases for the Real World}, volume~2, 2021.

\bibitem{hagberg2008exploring}
Aric Hagberg, Pieter Swart, and Daniel S~Chult.
\newblock Exploring network structure, dynamics, and function using networkx.
\newblock Technical report, Los Alamos National Lab.(LANL), Los Alamos, NM (United States), 2008.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\end{thebibliography}
