\newcommand{\noopsort}[1]{} \newcommand{\printfirst}[2]{#1}
  \newcommand{\singleletter}[1]{#1} \newcommand{\switchargs}[2]{#2#1}
\begin{thebibliography}{}

\bibitem[\protect\citename{Baldi, }1989]{baldi1989linear}
Baldi, Pierre. 1989.
\newblock Linear learning: Landscapes and algorithms.
\newblock {In} {\em Advances in neural information processing systems}.
\newblock pp.~65--72.

\bibitem[\protect\citename{Baldi \& Hornik, }1989]{baldi1989neural}
Baldi, Pierre, \& Hornik, Kurt. 1989.
\newblock Neural networks and principal component analysis: Learning from
  examples without local minima.
\newblock {\em Neural networks}, {\bf 2}(1), 53--58.

\bibitem[\protect\citename{Baldi \& Lu, }2012]{baldi2012complex}
Baldi, Pierre, \& Lu, Zhiqin. 2012.
\newblock Complex-valued autoencoders.
\newblock {\em Neural Networks}, {\bf 33}, 136--147.

\bibitem[\protect\citename{Blum \& Rivest, }1992]{blum1992training}
Blum, Avrim~L, \& Rivest, Ronald~L. 1992.
\newblock Training a 3-node neural network is NP-complete.
\newblock {\em Neural Networks}, {\bf 5}(1), 117--127.

\bibitem[\protect\citename{Choromanska {\em et~al.},
  }2015a]{choromanska2015loss}
Choromanska, Anna, Henaff, MIkael, Mathieu, Michael, Ben~Arous, Gerard, \&
  LeCun, Yann. 2015a.
\newblock The Loss Surfaces of Multilayer Networks.
\newblock {In} {\em Proceedings of the Eighteenth International Conference on
  Artificial Intelligence and Statistics}.
\newblock pp.~192--204.

\bibitem[\protect\citename{Choromanska {\em et~al.},
  }2015b]{choromanska2015open}
Choromanska, Anna, LeCun, Yann, \& Arous, G{\'e}rard~Ben. 2015b.
\newblock Open Problem: The landscape of the loss surfaces of multilayer
  networks.
\newblock {In} {\em Proceedings of The 28th Conference on Learning Theory}.
\newblock pp.~1756--1760.

\bibitem[\protect\citename{Dauphin {\em et~al.}, }2014]{dauphin2014identifying}
Dauphin, Yann~N, Pascanu, Razvan, Gulcehre, Caglar, Cho, Kyunghyun, Ganguli,
  Surya, \& Bengio, Yoshua. 2014.
\newblock Identifying and attacking the saddle point problem in
  high-dimensional non-convex optimization.
\newblock {In} {\em Advances in Neural Information Processing Systems}.
\newblock pp.~2933--2941.

\bibitem[\protect\citename{Ge {\em et~al.}, }2015]{ge2015escaping}
Ge, Rong, Huang, Furong, Jin, Chi, \& Yuan, Yang. 2015.
\newblock Escaping From Saddle Points---Online Stochastic Gradient for Tensor
  Decomposition.
\newblock {In} {\em Proceedings of The 28th Conference on Learning Theory}.
\newblock pp.~797--842.

\bibitem[\protect\citename{Goodfellow {\em et~al.},
  }2016]{Goodfellow-et-al-2016-Book}
Goodfellow, Ian, Bengio, Yoshua, \& Courville, Aaron. 2016.
\newblock {\em Deep Learning}.
\newblock Book in preparation for MIT Press.
  \url{http://www.deeplearningbook.org}.

\bibitem[\protect\citename{Livni {\em et~al.}, }2014]{livni2014computational}
Livni, Roi, Shalev-Shwartz, Shai, \& Shamir, Ohad. 2014.
\newblock On the computational efficiency of training neural networks.
\newblock {In} {\em Advances in Neural Information Processing Systems}.
\newblock pp.~855--863.

\bibitem[\protect\citename{Mhaskar {\em et~al.}, }2016]{mhaskar2016learning}
Mhaskar, Hrushikesh, Liao, Qianli, \& Poggio, Tomaso. 2016.
\newblock Learning Real and Boolean Functions: When Is Deep Better Than
  Shallow.
\newblock {\em Massachusetts Institute of Technology CBMM Memo No. 45}.

\bibitem[\protect\citename{Murty \& Kabadi, }1987]{murty1987some}
Murty, Katta~G, \& Kabadi, Santosh~N. 1987.
\newblock Some NP-complete problems in quadratic and nonlinear programming.
\newblock {\em Mathematical programming}, {\bf 39}(2), 117--129.

\bibitem[\protect\citename{Rockafellar \& Wets,
  }2009]{rockafellar2009variational}
Rockafellar, R~Tyrrell, \& Wets, Roger J-B. 2009.
\newblock {\em Variational analysis}.
\newblock  Vol. 317.
\newblock Springer Science \& Business Media.

\bibitem[\protect\citename{Saxe {\em et~al.}, }2014]{saxe2013exact}
Saxe, Andrew~M, McClelland, James~L, \& Ganguli, Surya. 2014.
\newblock Exact solutions to the nonlinear dynamics of learning in deep linear
  neural networks.
\newblock {In} {\em International Conference on Learning Representations}.

\bibitem[\protect\citename{Zhang, }2006]{zhang2006schur}
Zhang, Fuzhen. 2006.
\newblock {\em The Schur complement and its applications}.
\newblock  Vol. 4.
\newblock Springer Science \& Business Media.

\end{thebibliography}
