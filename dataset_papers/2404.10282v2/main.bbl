\begin{thebibliography}{45}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bengio(2013)]{bengio2013deep}
Bengio, Y.
\newblock Deep learning of representations: looking forward.
\newblock In \emph{Statistical Language and Speech Processing}, 2013.

\bibitem[Bengio et~al.(2013)Bengio, L{\'e}onard, and Courville]{bengio2013estimating}
Bengio, Y., L{\'e}onard, N., and Courville, A.
\newblock Estimating or propagating gradients through stochastic neurons for conditional computation.
\newblock \emph{arXiv preprint arXiv:1308.3432}, 2013.

\bibitem[Bradbury et~al.(2018)Bradbury, Frostig, Hawkins, Johnson, Leary, Maclaurin, Necula, Paszke, Vander{P}las, Wanderman-{M}ilne, and Zhang]{bradbury2018jax}
Bradbury, J., Frostig, R., Hawkins, P., Johnson, M.~J., Leary, C., Maclaurin, D., Necula, G., Paszke, A., Vander{P}las, J., Wanderman-{M}ilne, S., and Zhang, Q.
\newblock {JAX}: composable transformations of {P}ython+{N}um{P}y programs, 2018.
\newblock URL \url{http://github.com/google/jax}.

\bibitem[Burgess \& Kim(2018)Burgess and Kim]{burgess20183d}
Burgess, C. and Kim, H.
\newblock 3{D} shapes dataset, 2018.
\newblock URL \url{https://github.com/deepmind/3dshapes-dataset/}.

\bibitem[Burgess et~al.(2017)Burgess, Higgins, Pal, Matthey, Watters, Desjardins, and Lerchner]{burgess2017understanding}
Burgess, C.~P., Higgins, I., Pal, A., Matthey, L., Watters, N., Desjardins, G., and Lerchner, A.
\newblock Understanding disentangling in $\beta$-{VAE}.
\newblock In \emph{NIPS Workshop on Learning Disentangled Representations}, 2017.

\bibitem[Chen et~al.(2018)Chen, Li, Grosse, and Duvenaud]{chen2018isolating}
Chen, R.~T., Li, X., Grosse, R.~B., and Duvenaud, D.~K.
\newblock Isolating sources of disentanglement in variational autoencoders.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Comon(1994)]{comon1994independent}
Comon, P.
\newblock Independent component analysis, a new concept?
\newblock \emph{Signal Processing}, 36\penalty0 (3):\penalty0 287--314, 1994.

\bibitem[Dhariwal \& Nichol(2021)Dhariwal and Nichol]{dhariwal2021diffusion}
Dhariwal, P. and Nichol, A.
\newblock Diffusion models beat {GANs} on image synthesis.
\newblock \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Eastwood \& Williams(2018)Eastwood and Williams]{eastwood2018framework}
Eastwood, C. and Williams, C.~K.
\newblock A framework for the quantitative evaluation of disentangled representations.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Gondal et~al.(2019)Gondal, Wuthrich, Miladinovic, Locatello, Breidt, Volchkov, Akpo, Bachem, Sch\"{o}lkopf, and Bauer]{gondal2019transfer}
Gondal, M.~W., Wuthrich, M., Miladinovic, D., Locatello, F., Breidt, M., Volchkov, V., Akpo, J., Bachem, O., Sch\"{o}lkopf, B., and Bauer, S.
\newblock On the transfer of inductive bias from simulation to the real world: a new disentanglement dataset.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y.
\newblock Generative adversarial networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2014.

\bibitem[Gresele et~al.(2021)Gresele, Von~K{\"u}gelgen, Stimper, Sch{\"o}lkopf, and Besserve]{gresele2021independent}
Gresele, L., Von~K{\"u}gelgen, J., Stimper, V., Sch{\"o}lkopf, B., and Besserve, M.
\newblock Independent mechanism analysis, a new concept?
\newblock \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Harris et~al.(2020)Harris, Millman, Van Der~Walt, Gommers, Virtanen, Cournapeau, Wieser, Taylor, Berg, Smith, et~al.]{harris2020array}
Harris, C.~R., Millman, K.~J., Van Der~Walt, S.~J., Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N.~J., et~al.
\newblock Array programming with {NumPy}.
\newblock \emph{Nature}, 585\penalty0 (7825):\penalty0 357--362, 2020.

\bibitem[Higgins et~al.(2017)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick, Mohamed, and Lerchner]{higgins2017beta}
Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M., Mohamed, S., and Lerchner, A.
\newblock $\beta$-{VAE}: learning basic visual concepts with a constrained variational framework.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Horan et~al.(2021)Horan, Richardson, and Weiss]{horan2021when}
Horan, D., Richardson, E., and Weiss, Y.
\newblock When is unsupervised disentanglement possible?
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Hsu et~al.(2023)Hsu, Dorrell, Whittington, Wu, and Finn]{hsu2023disentanglement}
Hsu, K., Dorrell, W., Whittington, J.~C., Wu, J., and Finn, C.
\newblock Disentanglement via latent quantization.
\newblock \emph{Advances in Neural Information Processing Systems}, 2023.

\bibitem[Hutchinson(1989)]{hutchinson1989stochastic}
Hutchinson, M.~F.
\newblock A stochastic estimator of the trace of the influence matrix for laplacian smoothing splines.
\newblock \emph{Communications in Statistics-Simulation and Computation}, 18\penalty0 (3):\penalty0 1059--1076, 1989.

\bibitem[Hyv{\"a}rinen \& Oja(2000)Hyv{\"a}rinen and Oja]{hyv_arinen2000independent}
Hyv{\"a}rinen, A. and Oja, E.
\newblock Independent component analysis: algorithms and applications.
\newblock \emph{Neural Networks}, 13\penalty0 (4-5):\penalty0 411--430, 2000.

\bibitem[Hyv{\"a}rinen \& Pajunen(1999)Hyv{\"a}rinen and Pajunen]{hyv_arinen1999nonlinear}
Hyv{\"a}rinen, A. and Pajunen, P.
\newblock Nonlinear independent component analysis: existence and uniqueness results.
\newblock \emph{Neural Networks}, 12\penalty0 (3):\penalty0 429--439, 1999.

\bibitem[Jang et~al.(2017)Jang, Gu, and Poole]{jang2017categorical}
Jang, E., Gu, S., and Poole, B.
\newblock Categorical reparameterization with {Gumbel-Softmax}.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Jing et~al.(2020)Jing, Zbontar, et~al.]{jing2020implicit}
Jing, L., Zbontar, J., et~al.
\newblock Implicit rank-minimizing autoencoder.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Khemakhem et~al.(2020)Khemakhem, Kingma, Monti, and Hyvarinen]{khemakhem2020variational}
Khemakhem, I., Kingma, D., Monti, R., and Hyvarinen, A.
\newblock Variational autoencoders and nonlinear {ICA}: a unifying framework.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, 2020.

\bibitem[Kidger \& Garcia(2021)Kidger and Garcia]{kidger2021equinox}
Kidger, P. and Garcia, C.
\newblock Equinox: neural networks in {JAX} via callable {P}y{T}rees and filtered transformations.
\newblock \emph{Differentiable Programming Workshop at Neural Information Processing Systems}, 2021.

\bibitem[Kim \& Mnih(2018)Kim and Mnih]{kim2018disentangling}
Kim, H. and Mnih, A.
\newblock Disentangling by factorising.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{kingma2014auto}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational {Bayes}.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Kumar et~al.(2018)Kumar, Sattigeri, and Balakrishnan]{kumar2018variational}
Kumar, A., Sattigeri, P., and Balakrishnan, A.
\newblock Variational inference of disentangled latent concepts from unlabeled observations.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Leeb et~al.(2023)Leeb, Lanzillotta, Annadani, Besserve, Bauer, and Sch{\"o}lkopf]{leeb2023structure}
Leeb, F., Lanzillotta, G., Annadani, Y., Besserve, M., Bauer, S., and Sch{\"o}lkopf, B.
\newblock Structure by architecture: structured representations without regularization.
\newblock In \emph{International Conference on Learning Representations}, 2023.

\bibitem[Locatello et~al.(2019)Locatello, Bauer, Lucic, Raetsch, Gelly, Sch{\"o}lkopf, and Bachem]{locatello2019challenging}
Locatello, F., Bauer, S., Lucic, M., Raetsch, G., Gelly, S., Sch{\"o}lkopf, B., and Bachem, O.
\newblock Challenging common assumptions in the unsupervised learning of disentangled representations.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Maddison et~al.(2017)Maddison, Mnih, and Teh]{maddison2017concrete}
Maddison, C.~J., Mnih, A., and Teh, Y.~W.
\newblock The concrete distribution: a continuous relaxation of discrete random variables.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Mentzer et~al.(2024)Mentzer, Minnen, Agustsson, and Tschannen]{mentzer2024finite}
Mentzer, F., Minnen, D., Agustsson, E., and Tschannen, M.
\newblock Finite scalar quantization: {VQ-VAE} made simple.
\newblock In \emph{International Conference on Learning Representations}, 2024.

\bibitem[Moran et~al.(2022)Moran, Sridhar, Wang, and Blei]{moran2022identifiable}
Moran, G.~E., Sridhar, D., Wang, Y., and Blei, D.
\newblock Identifiable deep generative models via sparse decoding.
\newblock \emph{Transactions on Machine Learning Research}, 2022.

\bibitem[Nie(2019)]{nie2019high}
Nie, W.
\newblock High resolution disentanglement datasets, 2019.
\newblock URL \url{https://github.com/NVlabs/High-res-disentanglement-datasets}.

\bibitem[Oord et~al.(2017)Oord, Vinyals, and Kavukcuoglu]{oord2017neural}
Oord, A. v.~d., Vinyals, O., and Kavukcuoglu, K.
\newblock Neural discrete representation learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot, and {{\'E}}douard Duchesnay]{pedregosa2011scikit}
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and {{\'E}}douard Duchesnay.
\newblock Scikit-learn: machine learning in {P}ython.
\newblock \emph{Journal of Machine Learning Research}, 12\penalty0 (85):\penalty0 2825--2830, 2011.

\bibitem[Peebles et~al.(2020)Peebles, Peebles, Zhu, Efros, and Torralba]{peebles2020hessian}
Peebles, W., Peebles, J., Zhu, J.-Y., Efros, A., and Torralba, A.
\newblock The {H}essian penalty: a weak prior for unsupervised disentanglement.
\newblock In \emph{European Conference on Computer Vision}, 2020.

\bibitem[Rudin et~al.(2022)Rudin, Chen, Chen, Huang, Semenova, and Zhong]{rudin2022interpretable}
Rudin, C., Chen, C., Chen, Z., Huang, H., Semenova, L., and Zhong, C.
\newblock Interpretable machine learning: fundamental principles and 10 grand challenges.
\newblock \emph{Statistic Surveys}, 16:\penalty0 1--85, 2022.

\bibitem[Silverman(1998)]{silverman2018density}
Silverman, B.~W.
\newblock \emph{Density estimation for statistics and data analysis}.
\newblock Routledge, 1998.

\bibitem[Sorrenson et~al.(2020)Sorrenson, Rother, and K{\"o}the]{sorrenson2020disentanglement}
Sorrenson, P., Rother, C., and K{\"o}the, U.
\newblock Disentanglement by nonlinear {ICA} with general incompressible-flow networks ({GIN}).
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Studen{\`y} \& Vejnarov{\'a}(1998)Studen{\`y} and Vejnarov{\'a}]{studeny1998multiinformation}
Studen{\`y}, M. and Vejnarov{\'a}, J.
\newblock The multiinformation function as a tool for measuring stochastic dependence.
\newblock \emph{Learning in Graphical Models}, pp.\  261--297, 1998.

\bibitem[Wang et~al.(2023)Wang, Xiao, Seyde, Hasani, and Rus]{wang2023measuring}
Wang, T.-H., Xiao, W., Seyde, T., Hasani, R., and Rus, D.
\newblock Measuring interpretability of neural policies of robots with disentangled representation.
\newblock In \emph{Conference on Robot Learning}, 2023.

\bibitem[Wei et~al.(2021)Wei, Shi, Liu, Ji, Gao, Wu, and Zuo]{wei2021orthogonal}
Wei, Y., Shi, Y., Liu, X., Ji, Z., Gao, Y., Wu, Z., and Zuo, W.
\newblock Orthogonal {Jacobian} regularization for unsupervised disentanglement in image generation.
\newblock In \emph{International Conference on Computer Vision}, 2021.

\bibitem[Whittington et~al.(2023)Whittington, Dorrell, Ganguli, and Behrens]{whittington2023disentanglement}
Whittington, J. C.~R., Dorrell, W., Ganguli, S., and Behrens, T.
\newblock Disentanglement with biological constraints: a theory of functional cell types.
\newblock In \emph{International Conference on Learning Representations}, 2023.

\bibitem[Yang et~al.(2022)Yang, Yang, Sun, Zhang, Zhang, Li, and Yan]{yang2022volume}
Yang, X., Yang, Y., Sun, J., Zhang, X., Zhang, S., Li, Z., and Yan, J.
\newblock Nonlinear {ICA} using volume-preserving transformations.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Zheng \& Lapata(2022)Zheng and Lapata]{zheng2022disentangled}
Zheng, H. and Lapata, M.
\newblock Disentangled sequence to sequence learning for compositional generalization.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, 2022.

\bibitem[Zheng et~al.(2022)Zheng, Ng, and Zhang]{zheng2022identifiability}
Zheng, Y., Ng, I., and Zhang, K.
\newblock On the identifiability of nonlinear {ICA}: sparsity and beyond.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\end{thebibliography}
