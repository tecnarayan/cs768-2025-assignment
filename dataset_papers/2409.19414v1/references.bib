@article{morris2020tudataset,
  title={Tudataset: A collection of benchmark datasets for learning with graphs},
  author={Morris, Christopher and Kriege, Nils M and Bause, Franka and Kersting, Kristian and Mutzel, Petra and Neumann, Marion},
  journal={arXiv preprint arXiv:2007.08663},
  year={2020}
}
@article{hu2020open,
  title={Open graph benchmark: Datasets for machine learning on graphs},
  author={Hu, Weihua and Fey, Matthias and Zitnik, Marinka and Dong, Yuxiao and Ren, Hongyu and Liu, Bowen and Catasta, Michele and Leskovec, Jure},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={22118--22133},
  year={2020}
}
@article{gomez2018automatic,
  title={Automatic chemical design using a data-driven continuous representation of molecules},
  author={G{\'o}mez-Bombarelli, Rafael and Wei, Jennifer N and Duvenaud, David and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and S{\'a}nchez-Lengeling, Benjam{\'\i}n and Sheberla, Dennis and Aguilera-Iparraguirre, Jorge and Hirzel, Timothy D and Adams, Ryan P and Aspuru-Guzik, Al{\'a}n},
  journal={ACS central science},
  volume={4},
  number={2},
  pages={268--276},
  year={2018},
  publisher={ACS Publications}
}
@article{dwivedi2022long,
  title={Long range graph benchmark},
  author={Dwivedi, Vijay Prakash and Ramp{\'a}{\v{s}}ek, Ladislav and Galkin, Michael and Parviz, Ali and Wolf, Guy and Luu, Anh Tuan and Beaini, Dominique},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={22326--22340},
  year={2022}
}
@article{dwivedi2023benchmarking,
  title={Benchmarking graph neural networks},
  author={Dwivedi, Vijay Prakash and Joshi, Chaitanya K and Luu, Anh Tuan and Laurent, Thomas and Bengio, Yoshua and Bresson, Xavier},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={43},
  pages={1--48},
  year={2023}
}
@article{locatello2020object,
  title={Object-centric learning with slot attention},
  author={Locatello, Francesco and Weissenborn, Dirk and Unterthiner, Thomas and Mahendran, Aravindh and Heigold, Georg and Uszkoreit, Jakob and Dosovitskiy, Alexey and Kipf, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={11525--11538},
  year={2020}
}
@article{velivckovic2017graph,
  title={Graph attention networks},
  author={Veli{\v{c}}kovi{\'c}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Lio, Pietro and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1710.10903},
  year={2017}
}

@inproceedings{
gcn,
title={Semi-Supervised Classification with Graph Convolutional Networks},
author={Thomas N. Kipf and Max Welling},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=SJU4ayYgl}
}

@article{social_networks_example_1,
  author       = {Wenqi Fan and
                  Yao Ma and
                  Qing Li and
                  Jianping Wang and
                  Guoyong Cai and
                  Jiliang Tang and
                  Dawei Yin},
  title        = {A Graph Neural Network Framework for Social Recommendations},
  journal      = {{IEEE} Trans. Knowl. Data Eng.},
  volume       = {34},
  number       = {5},
  pages        = {2033--2047},
  year         = {2022},
  url          = {https://doi.org/10.1109/TKDE.2020.3008732},
  doi          = {10.1109/TKDE.2020.3008732},
  timestamp    = {Wed, 27 Apr 2022 20:10:43 +0200},
  biburl       = {https://dblp.org/rec/journals/tkde/FanMLWCTY22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{gnns_in_sciences_example_1,
  author       = {David Duvenaud and
                  Dougal Maclaurin and
                  Jorge Aguilera{-}Iparraguirre and
                  Rafael G{\'{o}}mez{-}Bombarelli and
                  Timothy Hirzel and
                  Al{\'{a}}n Aspuru{-}Guzik and
                  Ryan P. Adams},
  title        = {Convolutional Networks on Graphs for Learning Molecular Fingerprints},
  journal      = {CoRR},
  volume       = {abs/1509.09292},
  year         = {2015},
  url          = {http://arxiv.org/abs/1509.09292},
  eprinttype    = {arXiv},
  eprint       = {1509.09292},
  timestamp    = {Mon, 22 Jul 2019 14:09:23 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/DuvenaudMAGHAA15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{gnns_in_sciences_example_2,
  author       = {Wengong Jin and
                  Kevin Yang and
                  Regina Barzilay and
                  Tommi S. Jaakkola},
  title        = {Learning Multimodal Graph-to-Graph Translation for Molecule Optimization},
  booktitle    = {7th International Conference on Learning Representations, {ICLR} 2019,
                  New Orleans, LA, USA, May 6-9, 2019},
  publisher    = {OpenReview.net},
  year         = {2019},
  url          = {https://openreview.net/forum?id=B1xJAsA5F7},
  timestamp    = {Thu, 25 Jul 2019 14:25:56 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/JinYBJ19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{gnns_in_sciences_example_3,
  author       = {John Bradshaw and
                  Matt J. Kusner and
                  Brooks Paige and
                  Marwin H. S. Segler and
                  Jos{\'{e}} Miguel Hern{\'{a}}ndez{-}Lobato},
  title        = {A Generative Model For Electron Paths},
  booktitle    = {7th International Conference on Learning Representations, {ICLR} 2019,
                  New Orleans, LA, USA, May 6-9, 2019},
  publisher    = {OpenReview.net},
  year         = {2019},
  url          = {https://openreview.net/forum?id=r1x4BnCqKX},
  timestamp    = {Thu, 25 Jul 2019 14:25:42 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/BradshawKPSH19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{gnns_for_cv_example_1,
  author       = {Eitan Kosman and
                  Dotan Di Castro},
  editor       = {Shai Avidan and
                  Gabriel J. Brostow and
                  Moustapha Ciss{\'{e}} and
                  Giovanni Maria Farinella and
                  Tal Hassner},
  title        = {GraphVid: It only Takes a Few Nodes to Understand a Video},
  booktitle    = {Computer Vision - {ECCV} 2022 - 17th European Conference, Tel Aviv,
                  Israel, October 23-27, 2022, Proceedings, Part {XXXV}},
  series       = {Lecture Notes in Computer Science},
  volume       = {13695},
  pages        = {195--212},
  publisher    = {Springer},
  year         = {2022},
  url          = {https://doi.org/10.1007/978-3-031-19833-5\_12},
  doi          = {10.1007/978-3-031-19833-5\_12},
  timestamp    = {Sun, 13 Nov 2022 17:52:09 +0100},
  biburl       = {https://dblp.org/rec/conf/eccv/KosmanC22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@article{gnns_for_cv_example_2,
  author       = {Medhini Narasimhan and
                  Svetlana Lazebnik and
                  Alexander G. Schwing},
  title        = {Out of the Box: Reasoning with Graph Convolution Nets for Factual
                  Visual Question Answering},
  journal      = {CoRR},
  volume       = {abs/1811.00538},
  year         = {2018},
  url          = {http://arxiv.org/abs/1811.00538},
  eprinttype    = {arXiv},
  eprint       = {1811.00538},
  timestamp    = {Thu, 22 Nov 2018 17:58:30 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1811-00538.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{gnns_for_nlp_example_1,
    title = "Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks",
    author = "Wang, Zhichun  and
      Lv, Qingsong  and
      Lan, Xiaohan  and
      Zhang, Yu",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1032",
    doi = "10.18653/v1/D18-1032",
    pages = "349--357",
    abstract = "Multilingual knowledge graphs (KGs) such as DBpedia and YAGO contain structured knowledge of entities in several distinct languages, and they are useful resources for cross-lingual AI and NLP applications. Cross-lingual KG alignment is the task of matching entities with their counterparts in different languages, which is an important way to enrich the cross-lingual links in multilingual KGs. In this paper, we propose a novel approach for cross-lingual KG alignment via graph convolutional networks (GCNs). Given a set of pre-aligned entities, our approach trains GCNs to embed entities of each language into a unified vector space. Entity alignments are discovered based on the distances between entities in the embedding space. Embeddings can be learned from both the structural and attribute information of entities, and the results of structure embedding and attribute embedding are combined to get accurate alignments. In the experiments on aligning real multilingual KGs, our approach gets the best performance compared with other embedding-based KG alignment approaches.",
}



@inproceedings{gnns_for_nlp_example_2,
  author       = {Xien Liu and
                  Xinxin You and
                  Xiao Zhang and
                  Ji Wu and
                  Ping Lv},
  title        = {Tensor Graph Convolutional Networks for Text Classification},
  booktitle    = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2020, The Thirty-Second Innovative Applications of Artificial Intelligence
                  Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
                  Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
                  February 7-12, 2020},
  pages        = {8409--8416},
  publisher    = {{AAAI} Press},
  year         = {2020},
  url          = {https://doi.org/10.1609/aaai.v34i05.6359},
  doi          = {10.1609/AAAI.V34I05.6359},
  timestamp    = {Mon, 04 Sep 2023 16:50:25 +0200},
  biburl       = {https://dblp.org/rec/conf/aaai/LiuYZWL20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{zaheer2017deep,
  title={Deep sets},
  author={Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Russ R and Smola, Alexander J},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{li2020deepergcn,
  title={Deepergcn: All you need to train deeper gcns},
  author={Li, Guohao and Xiong, Chenxin and Thabet, Ali and Ghanem, Bernard},
  journal={arXiv preprint arXiv:2006.07739},
  year={2020}
}
@article{xu2018powerful,
  title={How powerful are graph neural networks?},
  author={Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
  journal={arXiv preprint arXiv:1810.00826},
  year={2018}
}
@article{corso2020principal,
  title={Principal neighbourhood aggregation for graph nets},
  author={Corso, Gabriele and Cavalleri, Luca and Beaini, Dominique and Li{\`o}, Pietro and Veli{\v{c}}kovi{\'c}, Petar},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13260--13271},
  year={2020}
}
@article{rampavsek2022recipe,
  title={Recipe for a general, powerful, scalable graph transformer},
  author={Ramp{\'a}{\v{s}}ek, Ladislav and Galkin, Michael and Dwivedi, Vijay Prakash and Luu, Anh Tuan and Wolf, Guy and Beaini, Dominique},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={14501--14515},
  year={2022}
}
@article{ying2021transformers,
  title={Do transformers really perform badly for graph representation?},
  author={Ying, Chengxuan and Cai, Tianle and Luo, Shengjie and Zheng, Shuxin and Ke, Guolin and He, Di and Shen, Yanming and Liu, Tie-Yan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={28877--28888},
  year={2021}
}
@article{kreuzer2021rethinking,
  title={Rethinking graph transformers with spectral attention},
  author={Kreuzer, Devin and Beaini, Dominique and Hamilton, Will and L{\'e}tourneau, Vincent and Tossou, Prudencio},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={21618--21629},
  year={2021}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{wu2020comprehensive,
  title={A comprehensive survey on graph neural networks},
  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Philip, S Yu},
  journal={IEEE transactions on neural networks and learning systems},
  volume={32},
  number={1},
  pages={4--24},
  year={2020},
  publisher={IEEE}
}
@inproceedings{wang2022powerful,
  title={How powerful are spectral graph neural networks},
  author={Wang, Xiyuan and Zhang, Muhan},
  booktitle={International Conference on Machine Learning},
  pages={23341--23362},
  year={2022},
  organization={PMLR}
}
@article{bruna2013spectral,
  title={Spectral networks and locally connected networks on graphs},
  author={Bruna, Joan and Zaremba, Wojciech and Szlam, Arthur and LeCun, Yann},
  journal={arXiv preprint arXiv:1312.6203},
  year={2013}
}
@article{defferrard2016convolutional,
  title={Convolutional neural networks on graphs with fast localized spectral filtering},
  author={Defferrard, Micha{\"e}l and Bresson, Xavier and Vandergheynst, Pierre},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}
@article{chien2020adaptive,
  title={Adaptive universal generalized pagerank graph neural network},
  author={Chien, Eli and Peng, Jianhao and Li, Pan and Milenkovic, Olgica},
  journal={arXiv preprint arXiv:2006.07988},
  year={2020}
}
@article{he2021bernnet,
  title={Bernnet: Learning arbitrary graph spectral filters via bernstein approximation},
  author={He, Mingguo and Wei, Zhewei and Xu, Hongteng and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={14239--14251},
  year={2021}
}
@inproceedings{chiang2019cluster,
  title={Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks},
  author={Chiang, Wei-Lin and Liu, Xuanqing and Si, Si and Li, Yang and Bengio, Samy and Hsieh, Cho-Jui},
  booktitle={Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={257--266},
  year={2019}
}

Provably Powerful Graph Networks
@inproceedings{PPGN,
  author       = {Haggai Maron and
                  Heli Ben{-}Hamu and
                  Hadar Serviansky and
                  Yaron Lipman},
  editor       = {Hanna M. Wallach and
                  Hugo Larochelle and
                  Alina Beygelzimer and
                  Florence d'Alch{\'{e}}{-}Buc and
                  Emily B. Fox and
                  Roman Garnett},
  title        = {Provably Powerful Graph Networks},
  booktitle    = {Advances in Neural Information Processing Systems 32: Annual Conference
                  on Neural Information Processing Systems 2019, NeurIPS 2019, December
                  8-14, 2019, Vancouver, BC, Canada},
  pages        = {2153--2164},
  year         = {2019},
  url          = {https://proceedings.neurips.cc/paper/2019/hash/bb04af0f7ecaee4aae62035497da1387-Abstract.html},
  timestamp    = {Mon, 16 May 2022 15:41:51 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/MaronBSL19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}




@inproceedings{polynomials,
  author       = {Omri Puny and
                  Derek Lim and
                  Bobak Toussi Kiani and
                  Haggai Maron and
                  Yaron Lipman},
  editor       = {Andreas Krause and
                  Emma Brunskill and
                  Kyunghyun Cho and
                  Barbara Engelhardt and
                  Sivan Sabato and
                  Jonathan Scarlett},
  title        = {Equivariant Polynomials for Graph Neural Networks},
  booktitle    = {International Conference on Machine Learning, {ICML} 2023, 23-29 July
                  2023, Honolulu, Hawaii, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {28191--28222},
  publisher    = {{PMLR}},
  year         = {2023},
  url          = {https://proceedings.mlr.press/v202/puny23a.html},
  timestamp    = {Mon, 28 Aug 2023 17:23:08 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/PunyLKML23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{graph_transformers_basic,
  author       = {Seongjun Yun and
                  Minbyul Jeong and
                  Raehyun Kim and
                  Jaewoo Kang and
                  Hyunwoo J. Kim},
  editor       = {Hanna M. Wallach and
                  Hugo Larochelle and
                  Alina Beygelzimer and
                  Florence d'Alch{\'{e}}{-}Buc and
                  Emily B. Fox and
                  Roman Garnett},
  title        = {Graph Transformer Networks},
  booktitle    = {Advances in Neural Information Processing Systems 32: Annual Conference
                  on Neural Information Processing Systems 2019, NeurIPS 2019, December
                  8-14, 2019, Vancouver, BC, Canada},
  pages        = {11960--11970},
  year         = {2019},
  url          = {https://proceedings.neurips.cc/paper/2019/hash/9d63484abb477c97640154d40595a3bb-Abstract.html},
  timestamp    = {Mon, 16 May 2022 15:41:51 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/YunJKKK19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{gps,
  author       = {Ladislav Ramp{\'{a}}sek and
                  Mikhail Galkin and
                  Vijay Prakash Dwivedi and
                  Anh Tuan Luu and
                  Guy Wolf and
                  Dominique Beaini},
  title        = {Recipe for a General, Powerful, Scalable Graph Transformer},
  journal      = {CoRR},
  volume       = {abs/2205.12454},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2205.12454},
  doi          = {10.48550/ARXIV.2205.12454},
  eprinttype    = {arXiv},
  eprint       = {2205.12454},
  timestamp    = {Mon, 30 May 2022 15:47:29 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2205-12454.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{sgc,
  title = 	 {Simplifying Graph Convolutional Networks},
  author = 	 {Wu, Felix and Souza, Amauri and Zhang, Tianyi and Fifty, Christopher and Yu, Tao and Weinberger, Kilian},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {6861--6871},
  year = 	 {2019},
  publisher = 	 {PMLR},
}


@inproceedings{chebyshev,
 author = {Defferrard, Micha\"{e}l and Bresson, Xavier and Vandergheynst, Pierre},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering},
 url = {https://proceedings.neurips.cc/paper_files/paper/2016/file/04df4d434d481c5bb723be1b6df1ee65-Paper.pdf},
 volume = {29},
 year = {2016}
}

@article{JacobiConv,
  author    = {Xiyuan Wang and
               Muhan Zhang},
  title     = {How Powerful are Spectral Graph Neural Networks},
  journal   = {ICML},
  year      = {2022}
}

@inproceedings{pna,
 title = {Principal Neighbourhood Aggregation for Graph Nets},
 author = {Corso, Gabriele and Cavalleri, Luca and Beaini, Dominique and Li\`{o}, Pietro and Veli\v{c}kovi\'{c}, Petar},
 booktitle = {Advances in Neural Information Processing Systems},
 year = {2020}
}

@inproceedings{deep-sets,
 author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Russ R and Smola, Alexander J},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Deep Sets},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/f22e4747da1aa27e363d86d40ff442fe-Paper.pdf},
 volume = {30},
 year = {2017}
}



@article{lower_bound,
  author       = {Chaitanya K. Joshi and
                  Cristian Bodnar and
                  Simon V. Mathis and
                  Taco Cohen and
                  Pietro Li{\`{o}}},
  title        = {On the Expressive Power of Geometric Graph Neural Networks},
  journal      = {CoRR},
  volume       = {abs/2301.09308},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2301.09308},
  doi          = {10.48550/ARXIV.2301.09308},
  eprinttype    = {arXiv},
  eprint       = {2301.09308},
  timestamp    = {Thu, 26 Jan 2023 15:26:31 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2301-09308.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{dym_1,
  title={Low-Dimensional Invariant Embeddings for Universal Geometric Learning},
  author={Dym, Nadav and Gortler, Steven J},
  journal={Foundations of Computational Mathematics},
  pages={1--41},
  year={2024},
  publisher={Springer}
}

@inproceedings{
dym_2,
title={Neural Injective Functions for Multisets, Measures and Graphs via a Finite Witness Theorem},
author={Tal Amir and Steven J. Gortler and Ilai Avni and Ravina Ravina and Nadav Dym},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=TQlpqmCeMe}
}
@article{schneckenreiter2024gnn,
  title={GNN-VPA: A Variance-Preserving Aggregation Strategy for Graph Neural Networks},
  author={Schneckenreiter, Lisa and Freinschlag, Richard and Sestak, Florian and Brandstetter, Johannes and Klambauer, G{\"u}nter and Mayr, Andreas},
  journal={arXiv preprint arXiv:2403.04747},
  year={2024}
}

@inproceedings{
vpa,
title={{GNN}-{VPA}: A Variance-Preserving Aggregation Strategy for Graph Neural Networks},
author={Lisa Schneckenreiter and Richard Freinschlag and Florian Sestak and Johannes Brandstetter and G{\"u}nter Klambauer and Andreas Mayr},
booktitle={The Second Tiny Papers Track at ICLR 2024},
year={2024},
url={https://openreview.net/forum?id=2yuAxTs0QV}
}

@misc{fishnets,
      title={Fishnets: Information-Optimal, Scalable Aggregation for Sets and Graphs}, 
      author={T. Lucas Makinen and Justin Alsing and Benjamin D. Wandelt},
      year={2023},
      eprint={2310.03812},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{
tailor2022adaptive,
title={Adaptive Filters for Low-Latency and Memory-Efficient Graph Neural Networks},
author={Shyam A. Tailor and Felix Opolka and Pietro Lio and Nicholas Donald Lane},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=hl9ePdHO4_s}
}

@inproceedings{lstm,
author = {Hamilton, William L. and Ying, Rex and Leskovec, Jure},
title = {Inductive representation learning on large graphs},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {1025â€“1035},
numpages = {11},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@inproceedings{regularizing,
author = {Cohen-Karlik, Edo and David, Avichai Ben and Globerson, Amir},
title = {Regularizing towards permutation invariance in recurrent models},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {In many machine learning problems the output should not depend on the order of the input. Such "permutation invariant" functions have been studied extensively recently. Here we argue that temporal architectures such as RNNs are highly relevant for such problems, despite the inherent dependence of RNNs on order. We show that RNNs can be regularized towards permutation invariance, and that this can result in compact models, as compared to non-recurrent architectures. We implement this idea via a novel form of stochastic regularization.Existing solutions mostly suggest restricting the learning problem to hypothesis classes which are permutation invariant by design [Zaheer et al., 2017, Lee et al., 2019, Murphy et al., 2018]. Our approach of enforcing permutation invari-ance via regularization gives rise to models which are semi permutation invariant (e.g. invariant to some permutations and not to others). We show that our method outperforms other permutation invariant approaches on synthetic and real world datasets.},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {1542},
numpages = {11},
location = {<conf-loc>, <city>Vancouver</city>, <state>BC</state>, <country>Canada</country>, </conf-loc>},
series = {NIPS '20}
}

@inproceedings{
    baek2021accurate,
    title={Accurate Learning of Graph Representations with Graph Multiset Pooling},
    author={Jinheon Baek and Minki Kang and Sung Ju Hwang},
    booktitle={International Conference on Learning Representations},
    year={2021},
    url={https://openreview.net/forum?id=JHcqXGaqiGn}
}


@inproceedings{
ong2022learnable,
title={Learnable Commutative Monoids for Graph Neural Networks},
author={Euan Ong and Petar Veli{\v{c}}kovi{\'c}},
booktitle={The First Learning on Graphs Conference},
year={2022},
url={https://openreview.net/forum?id=WtFobB28VDey}
}


@inproceedings{
buterez2022graph,
title={Graph Neural Networks with Adaptive Readouts},
author={David Buterez and Jon Paul Janet and Steven J Kiddle and Dino Oglic and Pietro Li{\`o}},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=yts7fLpWY9G}
}

@inproceedings{
tailor2022egc,
title={Do We Need Anistropic Graph Neural Networks?},
author={Shyam A. Tailor and Felix Opolka and Pietro Lio and Nicholas Donald Lane},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=hl9ePdHO4_s}
}

@article{zinc,
author = {Irwin, John and Sterling, Teague and Mysinger, Michael and Bolstad, Erin and Coleman, Ryan},
year = {2012},
month = {05},
pages = {},
title = {ZINC: A Free Tool to Discover Chemistry for Biology},
volume = {52},
journal = {Journal of chemical information and modeling},
doi = {10.1021/ci3001277}
}

@misc{cahill2024bilipschitz,
      title={Towards a bilipschitz invariant theory}, 
      author={Jameson Cahill and Joseph W. Iverson and Dustin G. Mixon},
      year={2024},
      eprint={2305.17241},
      archivePrefix={arXiv},
      primaryClass={math.FA}
}

@article{
  velickovic2018graph,
  title="{Graph Attention Networks}",
  author={Veli{\v{c}}kovi{\'{c}}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Li{\`{o}}, Pietro and Bengio, Yoshua},
  journal={International Conference on Learning Representations},
  year={2018},
  url={https://openreview.net/forum?id=rJXMpikCZ},
  note={accepted as poster},
}

@inproceedings{
  brody2022how,
  title={How Attentive are Graph Attention Networks? },
  author={Shaked Brody and Uri Alon and Eran Yahav},
  booktitle={International Conference on Learning Representations},
  year={2022},
  url={https://openreview.net/forum?id=F72ximsx7C1}
}

@inproceedings{
xu2018how,
title={How Powerful are Graph Neural Networks?},
author={Keyulu Xu and Weihua Hu and Jure Leskovec and Stefanie Jegelka},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=ryGs6iA5Km},
}

@inproceedings{bevilacqua2022equivariant,
title={Equivariant Subgraph Aggregation Networks},
author={Beatrice Bevilacqua and Fabrizio Frasca and Derek Lim and Balasubramaniam Srinivasan and Chen Cai and Gopinath Balamurugan and Michael M. Bronstein and Haggai Maron},
booktitle={International Conference on Learning Representations},
year={2022},
}

@article{rampasek2022GPS,
  title={{Recipe for a General, Powerful, Scalable Graph Transformer}}, 
  author={Ladislav Ramp\'{a}\v{s}ek and Mikhail Galkin and Vijay Prakash Dwivedi and Anh Tuan Luu and Guy Wolf and Dominique Beaini},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  year={2022}
}

@article{bresson2017residual,
  title={Residual gated graph convnets},
  author={Bresson, Xavier and Laurent, Thomas},
  journal={arXiv preprint arXiv:1711.07553},
  year={2017}
}

@article{kortvelesy2023generalised,
  title={Generalised f-mean aggregation for graph neural networks},
  author={Kortvelesy, Ryan and Morad, Steven and Prorok, Amanda},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={34439--34450},
  year={2023}
}