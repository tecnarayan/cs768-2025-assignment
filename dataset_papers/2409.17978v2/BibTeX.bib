@inproceedings{
darcet2024vision,
title={Vision Transformers Need Registers},
author={Timoth{\'e}e Darcet and Maxime Oquab and Julien Mairal and Piotr Bojanowski},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=2dnO3LLiJ1}
}

@inproceedings{
dosovitskiy2021an,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=YicbFdNTTy}
}

@inproceedings{yu2022metaformer,
  title={Metaformer is actually what you need for vision},
  author={Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10819--10829},
  year={2022}
}

@inproceedings{zamir2022restormer,
  title={Restormer: Efficient transformer for high-resolution image restoration},
  author={Zamir, Syed Waqas and Arora, Aditya and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Yang, Ming-Hsuan},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5728--5739},
  year={2022}
}

@inproceedings{liu2022swin,
  title={Swin transformer v2: Scaling up capacity and resolution},
  author={Liu, Ze and Hu, Han and Lin, Yutong and Yao, Zhuliang and Xie, Zhenda and Wei, Yixuan and Ning, Jia and Cao, Yue and Zhang, Zheng and Dong, Li and others},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12009--12019},
  year={2022}
}

@article{tolstikhin2021mlp,
  title={Mlp-mixer: An all-mlp architecture for vision},
  author={Tolstikhin, Ilya O and Houlsby, Neil and Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Unterthiner, Thomas and Yung, Jessica and Steiner, Andreas and Keysers, Daniel and Uszkoreit, Jakob and others},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={24261--24272},
  year={2021}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}

@article{li2022efficientformer,
  title={Efficientformer: Vision transformers at mobilenet speed},
  author={Li, Yanyu and Yuan, Geng and Wen, Yang and Hu, Ju and Evangelidis, Georgios and Tulyakov, Sergey and Wang, Yanzhi and Ren, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={12934--12949},
  year={2022}
}

@article{kudugunta2023matformer,
  title={MatFormer: Nested Transformer for Elastic Inference},
  author={Kudugunta, Sneha and Kusupati, Aditya and Dettmers, Tim and Chen, Kaifeng and Dhillon, Inderjit and Tsvetkov, Yulia and Hajishirzi, Hannaneh and Kakade, Sham and Farhadi, Ali and Jain, Prateek and others},
  journal={arXiv preprint arXiv:2310.07707},
  year={2023}
}

@article{hou2020dynabert,
  title={Dynabert: Dynamic bert with adaptive width and depth},
  author={Hou, Lu and Huang, Zhiqi and Shang, Lifeng and Jiang, Xin and Chen, Xiao and Liu, Qun},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9782--9793},
  year={2020}
}

@inproceedings{chavan2022vision,
  title={Vision transformer slimming: Multi-dimension searching in continuous optimization space},
  author={Chavan, Arnav and Shen, Zhiqiang and Liu, Zhuang and Liu, Zechun and Cheng, Kwang-Ting and Xing, Eric P},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4931--4941},
  year={2022}
}

@article{salehi2023sharcs,
  title={Sharcs: Efficient transformers through routing with dynamic width sub-networks},
  author={Salehi, Mohammadreza and Mehta, Sachin and Kusupati, Aditya and Farhadi, Ali and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2310.12126},
  year={2023}
}

@inproceedings{beyer2023flexivit,
  title={Flexivit: One model for all patch sizes},
  author={Beyer, Lucas and Izmailov, Pavel and Kolesnikov, Alexander and Caron, Mathilde and Kornblith, Simon and Zhai, Xiaohua and Minderer, Matthias and Tschannen, Michael and Alabdulmohsin, Ibrahim and Pavetic, Filip},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14496--14506},
  year={2023}
}

@article{kusupati2022matryoshka,
  title={Matryoshka representation learning},
  author={Kusupati, Aditya and Bhatt, Gantavya and Rege, Aniket and Wallingford, Matthew and Sinha, Aditya and Ramanujan, Vivek and Howard-Snyder, William and Chen, Kaifeng and Kakade, Sham and Jain, Prateek and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={30233--30249},
  year={2022}
}

@inproceedings{rippel2014learning,
  title={Learning ordered representations with nested dropout},
  author={Rippel, Oren and Gelbart, Michael and Adams, Ryan},
  booktitle={International Conference on Machine Learning},
  pages={1746--1754},
  year={2014},
  organization={PMLR}
}

@article{yu2018slimmable,
  title={Slimmable neural networks},
  author={Yu, Jiahui and Yang, Linjie and Xu, Ning and Yang, Jianchao and Huang, Thomas},
  journal={arXiv preprint arXiv:1812.08928},
  year={2018}
}

@inproceedings{fang2018nestdnn,
  title={Nestdnn: Resource-aware multi-tenant on-device deep learning for continuous mobile vision},
  author={Fang, Biyi and Zeng, Xiao and Zhang, Mi},
  booktitle={Proceedings of the 24th Annual International Conference on Mobile Computing and Networking},
  pages={115--127},
  year={2018}
}

@inproceedings{touvron2022deit,
  title={Deit iii: Revenge of the vit},
  author={Touvron, Hugo and Cord, Matthieu and J{\'e}gou, Herv{\'e}},
  booktitle={European conference on computer vision},
  pages={516--533},
  year={2022},
  organization={Springer}
}

@inproceedings{wang2021pyramid,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={568--578},
  year={2021}
}

@article{valipour2023sortednet,
  title={Sortednet, a place for every network and every network in its place: Towards a generalized solution for training many-in-one neural networks},
  author={Valipour, Mojtaba and Rezagholizadeh, Mehdi and Rajabzadeh, Hossein and Tahaei, Marzieh and Chen, Boxing and Ghodsi, Ali},
  journal={arXiv preprint arXiv:2309.00255},
  year={2023}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

@INPROCEEDINGS{5206848,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  keywords={Large-scale systems;Image databases;Explosions;Internet;Robustness;Information retrieval;Image retrieval;Multimedia databases;Ontologies;Spine},
  doi={10.1109/CVPR.2009.5206848}}

@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International conference on machine learning},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}

@inproceedings{koike2020stochastic,
  title={Stochastic bottleneck: Rateless auto-encoder for flexible dimensionality reduction},
  author={Koike-Akino, Toshiaki and Wang, Ye},
  booktitle={2020 IEEE International Symposium on Information Theory (ISIT)},
  pages={2735--2740},
  year={2020},
  organization={IEEE}
}

@article{rao2021dynamicvit,
  title={Dynamicvit: Efficient vision transformers with dynamic token sparsification},
  author={Rao, Yongming and Zhao, Wenliang and Liu, Benlin and Lu, Jiwen and Zhou, Jie and Hsieh, Cho-Jui},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13937--13949},
  year={2021}
}

@inproceedings{yin2022vit,
  title={A-vit: Adaptive tokens for efficient vision transformer},
  author={Yin, Hongxu and Vahdat, Arash and Alvarez, Jose M and Mallya, Arun and Kautz, Jan and Molchanov, Pavlo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10809--10818},
  year={2022}
}

@article{wang2021not,
  title={Not all images are worth 16x16 words: Dynamic transformers for efficient image recognition},
  author={Wang, Yulin and Huang, Rui and Song, Shiji and Huang, Zeyi and Huang, Gao},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={11960--11973},
  year={2021}
}

@inproceedings{tang2022patch,
  title={Patch slimming for efficient vision transformers},
  author={Tang, Yehui and Han, Kai and Wang, Yunhe and Xu, Chang and Guo, Jianyuan and Xu, Chao and Tao, Dacheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12165--12174},
  year={2022}
}

@inproceedings{chefer2021transformer,
  title={Transformer interpretability beyond attention visualization},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={782--791},
  year={2021}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@misc{rw2019timm,
  author = {Ross Wightman},
  title = {PyTorch Image Models},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {10.5281/zenodo.4414861},
  howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}

@inproceedings{recht2019imagenet,
  title={Do ImageNet Classifiers Generalize to ImageNet?},
  author={Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  booktitle={International Conference on Machine Learning},
  pages={5389--5400},
  year={2019}
}

@article{hendrycks2020many,
  title={The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization},
  author={Dan Hendrycks and Steven Basart and Norman Mu and Saurav Kadavath and Frank Wang and Evan Dorundo and Rahul Desai and Tyler Zhu and Samyak Parajuli and Mike Guo and Dawn Song and Jacob Steinhardt and Justin Gilmer},
  journal={arXiv preprint arXiv:2006.16241},
  year={2020}
}

@article{hendrycks2019nae,
  title={Natural Adversarial Examples},
  author={Dan Hendrycks and Kevin Zhao and Steven Basart and Jacob Steinhardt and Dawn Song},
  journal={arXiv preprint arXiv:1907.07174},
  year={2019}
}

@inproceedings{wang2019learning,
        title={Learning Robust Global Representations by Penalizing Local Predictive Power},
        author={Wang, Haohan and Ge, Songwei and Lipton, Zachary and Xing, Eric P},
        booktitle={Advances in Neural Information Processing Systems},
        pages={10506--10518},
        year={2019}
}

@article{beyer2020imagenet,
  title={Are we done with ImageNet?},
  author={Lucas Beyer and Olivier J. Henaff and Alexander Kolesnikov and Xiaohua Zhai and Aaron van den Oord},
  journal={arXiv preprint arXiv:2002.05709},
  year={2020}
}
@article{ILSVRC15,
  Author={Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
  Title={ {ImageNet Large Scale Visual Recognition Challenge} },
  Year={2015},
  journal={International Journal of Computer Vision (IJCV)},
  doi={10.1007/s11263-015-0816-y},
  volume={115},
  number={3},
  pages={211-252}
}

@inproceedings{vasu2023fastvit,
  title={FastViT: A fast hybrid vision transformer using structural reparameterization},
  author={Vasu, Pavan Kumar Anasosalu and Gabriel, James and Zhu, Jeff and Tuzel, Oncel and Ranjan, Anurag},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5785--5795},
  year={2023}
}

@article{
mehta2023separable,
title={Separable Self-attention for Mobile Vision Transformers},
author={Sachin Mehta and Mohammad Rastegari},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
url={https://openreview.net/forum?id=tBl4yBEjKi},
note={}
}

@inproceedings{kong2022spvit,
  title={SPViT: Enabling Faster Vision Transformers via Latency-Aware Soft Token Pruning},
  author={Kong, Zhenglun and Dong, Peiyan and Ma, Xiaolong and Meng, Xin and Niu, Wei and Sun, Mengshu and Shen, Xuan and Yuan, Geng and Ren, Bin and Tang, Hao and others},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XI},
  pages={620--640},
  year={2022},
  organization={Springer}
}

@misc{liu2024ghostnetv3exploringtrainingstrategies,
      title={GhostNetV3: Exploring the Training Strategies for Compact Models}, 
      author={Zhenhua Liu and Zhiwei Hao and Kai Han and Yehui Tang and Yunhe Wang},
      year={2024},
      eprint={2404.11202},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2404.11202}, 
}

@InProceedings{Hojjat_2023_CVPR,
    author    = {Hojjat, Ali and Haberer, Janek and Landsiedel, Olaf},
    title     = {ProgDTD: Progressive Learned Image Compression With Double-Tail-Drop Training},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
    month     = {June},
    year      = {2023},
    pages     = {1130-1139}
}