\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{LvdWK{\etalchar{+}}20}

\bibitem[AGNZ18]{arora_stronger_2018}
Sanjeev Arora, Rong Ge, Behnam Neyshabur, and Yi~Zhang.
\newblock Stronger {Generalization} {Bounds} for {Deep} {Nets} via a
  {Compression} {Approach}.
\newblock In {\em International {Conference} on {Machine} {Learning}}, pages
  254--263, 2018.

\bibitem[Bek20]{bekkers2020bspline}
Erik~J Bekkers.
\newblock B-spline {CNN}s on lie groups.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem[BFT17]{bartlett_spectrally-normalized_2017}
Peter~L Bartlett, Dylan~J Foster, and Matus~J Telgarsky.
\newblock Spectrally-normalized margin bounds for neural networks.
\newblock In I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, {\em Advances in {Neural}
  {Information} {Processing} {Systems} 30}, pages 6240--6249. Curran
  Associates, Inc., 2017.

\bibitem[BG22]{biggs_non-vacuous_2022}
Felix Biggs and Benjamin Guedj.
\newblock Non-{Vacuous} {Generalisation} {Bounds} for {Shallow} {Neural}
  {Networks}.
\newblock {\em arXiv:2202.01627 [cs, stat]}, February 2022.
\newblock arXiv: 2202.01627.

\bibitem[BLV{\etalchar{+}}18]{bekkers2018roto}
Erik~J. Bekkers, Maxime~W Lafarge, Mitko Veta, Koen~A.J. Eppenhof, Josien~P.W.
  Pluim, and Remco Duits.
\newblock Roto-translation covariant convolutional networks for medical image
  analysis.
\newblock In {\em International Conference on Medical Image Computing and
  Computer-Assisted Intervention (MICCAI)}, 2018.

\bibitem[BM19]{bietti2019stability}
Alberto Bietti and Julien Mairal.
\newblock Group invariance, stability to deformations, and complexity of deep
  convolutional representations.
\newblock {\em J. Mach. Learn. Res.}, 20(1):876–924, January 2019.

\bibitem[CGW18]{generaltheory}
Taco~S. Cohen, Mario Geiger, and Maurice Weiler.
\newblock A general theory of equivariant {CNN}s on homogeneous spaces.
\newblock {\em arXiv preprint arXiv:1811.02017}, 2018.

\bibitem[CLW22]{cesa2022a}
Gabriele Cesa, Leon Lang, and Maurice Weiler.
\newblock A program to build e(n)-equivariant steerable {CNN}s.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem[CW16a]{cohen_group_2016}
Taco~S. Cohen and Max Welling.
\newblock Group {Equivariant} {Convolutional} {Networks}.
\newblock {\em arXiv:1602.07576 [cs, stat]}, February 2016.
\newblock arXiv: 1602.07576.

\bibitem[CW16b]{cohen_steerable_2016}
Taco~S. Cohen and Max Welling.
\newblock Steerable {CNNs}.
\newblock In {\em {ICLR} 2017}, November 2016.

\bibitem[DDFK16]{Dieleman2016-CYC}
Sander Dieleman, Jeffrey De~Fauw, and Koray Kavukcuoglu.
\newblock Exploiting cyclic symmetry in convolutional neural networks.
\newblock In {\em International Conference on Machine Learning ({ICML})}, 2016.

\bibitem[DDN{\etalchar{+}}20]{dziugaite_search_2020}
Gintare~Karolina Dziugaite, Alexandre Drouin, Brady Neal, Nitarshan Rajkumar,
  Ethan Caballero, Linbo Wang, Ioannis Mitliagkas, and Daniel~M. Roy.
\newblock In search of robust measures of generalization.
\newblock {\em Advances in Neural Information Processing Systems},
  33:11723--11733, 2020.

\bibitem[DMGP19]{defferrard_deepsphere_2019}
Michaël Defferrard, Martino Milani, Frédérick Gusset, and Nathanaël
  Perraudin.
\newblock {DeepSphere}: a graph-based spherical {CNN}.
\newblock In {\em International {Conference} on {Learning} {Representations}},
  2019.

\bibitem[DR17]{dziugaite_computing_2017}
Gintare~Karolina Dziugaite and Daniel~M. Roy.
\newblock Computing nonvacuous generalization bounds for deep (stochastic)
  neural networks with many more parameters than training data.
\newblock {\em arXiv preprint arXiv:1703.11008}, 2017.

\bibitem[DR18a]{dziugaite_entropy-sgd_2018}
Gintare~Karolina Dziugaite and Daniel Roy.
\newblock Entropy-{SGD} optimizes the prior of a {PAC}-{Bayes} bound:
  {Generalization} properties of {Entropy}-{SGD} and data-dependent priors.
\newblock In {\em International {Conference} on {Machine} {Learning}}, pages
  1377--1386, July 2018.

\bibitem[DR18b]{dziugaite_data-dependent_2018}
Gintare~Karolina Dziugaite and Daniel~M. Roy.
\newblock Data-dependent {PAC}-{Bayes} priors via differential privacy.
\newblock In {\em Advances in {Neural} {Information} {Processing} {Systems}},
  pages 8430--8441, 2018.

\bibitem[Ele22]{elesedy_group_2022}
Bryn Elesedy.
\newblock Group symmetry in {PAC} learning.
\newblock In {\em {ICLR} 2022 {Workshop} on {Geometrical} and {Topological}
  {Representation} {Learning}}, page~9, 2022.

\bibitem[EZ21]{elesedy_provably_2021}
Bryn Elesedy and Sheheryar Zaidi.
\newblock Provably strict generalisation benefit for equivariant models.
\newblock In {\em International {Conference} on {Machine} {Learning}}, pages
  2959--2969. PMLR, 2021.

\bibitem[FSIW20]{finzi_generalizing_2020}
Marc Finzi, Samuel Stanton, Pavel Izmailov, and Andrew~Gordon Wilson.
\newblock Generalizing convolutional neural networks for equivariance to lie
  groups on arbitrary continuous data.
\newblock In {\em International {Conference} on {Machine} {Learning}}, pages
  3165--3176. PMLR, 2020.

\bibitem[GLLM09]{germain_pac-bayesian_2009}
Pascal Germain, Alexandre Lacasse, François Laviolette, and Mario Marchand.
\newblock {PAC}-{Bayesian} learning of linear classifiers.
\newblock In {\em Proceedings of the 26th {Annual} {International} {Conference}
  on {Machine} {Learning}}, pages 353--360, 2009.

\bibitem[GRS18]{golowich_size-independent_2018}
Noah Golowich, Alexander Rakhlin, and Ohad Shamir.
\newblock Size-{Independent} {Sample} {Complexity} of {Neural} {Networks}.
\newblock In {\em Conference {On} {Learning} {Theory}}, pages 297--299, July
  2018.

\bibitem[JNK{\etalchar{+}}20]{jiang_fantastic_2020}
Yiding Jiang, Behnam Neyshabur, Dilip Krishnan, Hossein Mobahi, and Samy
  Bengio.
\newblock Fantastic {Generalization} {Measures} and {Where} to {Find} {Them}.
\newblock In {\em International {Conference} on {Learning} {Representations}},
  2020.

\bibitem[KT18]{Kondor2018-GENERAL}
Risi Kondor and Shubhendu Trivedi.
\newblock On the generalization of equivariance and convolution in neural
  networks to the action of compact groups.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2018.

\bibitem[KZSS21]{koehler_uniform_2021}
Frederic Koehler, Lijia Zhou, Danica~J. Sutherland, and Nathan Srebro.
\newblock Uniform {Convergence} of {Interpolators}: {Gaussian} {Width}, {Norm}
  {Bounds} and {Benign} {Overfitting}.
\newblock In {\em Advances in {Neural} {Information} {Processing} {Systems}},
  May 2021.

\bibitem[LM00]{laurent_adaptive_2000}
B.~Laurent and P.~Massart.
\newblock Adaptive estimation of a quadratic functional by model selection.
\newblock {\em Annals of Statistics}, 28(5):1302--1338, October 2000.
\newblock Publisher: Institute of Mathematical Statistics.

\bibitem[LMLK21]{ledent_norm-based_2021}
Antoine Ledent, Waleed Mustafa, Yunwen Lei, and Marius Kloft.
\newblock Norm-based generalisation bounds for deep multi-class convolutional
  neural networks.
\newblock In {\em 35th {AAAI} {Conference} on {Artificial} {Intelligence}},
  pages 8279--8287. AAAI Press, 2021.

\bibitem[LS19]{long_size-free_2019}
Philip~M. Long and Hanie Sedghi.
\newblock Size-free generalization bounds for convolutional neural networks.
\newblock {\em arXiv:1905.12600 [cs, math, stat]}, May 2019.
\newblock arXiv: 1905.12600.

\bibitem[LSBP16]{laptev2016ti}
Dmitry Laptev, Nikolay Savinov, Joachim~M Buhmann, and Marc Pollefeys.
\newblock Ti-pooling: transformation-invariant pooling for feature learning in
  convolutional neural networks.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 289--297, 2016.

\bibitem[LSt02]{langford_pac-bayes_2002}
John Langford and John Shawe-taylor.
\newblock {PAC}-{Bayes} \& {Margins}.
\newblock In {\em Advances in {Neural} {Information} {Processing} {Systems}
  15}. Citeseer, 2002.

\bibitem[LvdWK{\etalchar{+}}20]{lyle2020benefits}
Clare Lyle, Mark van~der Wilk, Marta Kwiatkowska, Yarin Gal, and Benjamin
  Bloem-Reddy.
\newblock On the benefits of invariance in neural networks.
\newblock {\em arXiv preprint arXiv:2005.00178}, 2020.

\bibitem[Mal12]{mallat_group_2012}
Stéphane Mallat.
\newblock Group invariant scattering.
\newblock {\em Communications on Pure and Applied Mathematics},
  65(10):1331--1398, 2012.

\bibitem[McA98]{mcallester_pac-bayesian_1998}
David~A. McAllester.
\newblock Some {PAC}-{Bayesian} {Theorems}.
\newblock In {\em Machine {Learning}}, pages 230--234. ACM Press, 1998.

\bibitem[NBS18]{neyshabur_pac-bayesian_2018}
Behnam Neyshabur, Srinadh Bhojanapalli, and Nathan Srebro.
\newblock A {PAC}-{Bayesian} {Approach} to {Spectrally}-{Normalized} {Margin}
  {Bounds} for {Neural} {Networks}.
\newblock In {\em International {Conference} on {Learning} {Representations}},
  2018.

\bibitem[NDR21]{negrea_defense_2021}
Jeffrey Negrea, Gintare~Karolina Dziugaite, and Daniel~M. Roy.
\newblock In {Defense} of {Uniform} {Convergence}: {Generalization} via
  derandomization with an application to interpolating predictors.
\newblock Technical Report arXiv:1912.04265, arXiv, September 2021.

\bibitem[NK19]{nagarajan_uniform_2019}
Vaishnavh Nagarajan and J.~Zico Kolter.
\newblock Uniform convergence may be unable to explain generalization in deep
  learning.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer,
  F.~d{\textbackslash}textquotesingle Alché-Buc, E.~Fox, and R.~Garnett,
  editors, {\em Advances in {Neural} {Information} {Processing} {Systems} 32},
  pages 11615--11626. Curran Associates, Inc., 2019.

\bibitem[PLDV19]{pitas_limitations_2019}
Konstantinos Pitas, Andreas Loukas, Mike Davies, and Pierre Vandergheynst.
\newblock Some limitations of norm based generalization bounds in deep neural
  networks.
\newblock {\em arXiv:1905.09677 [cs, stat]}, May 2019.
\newblock arXiv: 1905.09677.

\bibitem[Rav20]{universalgroupmlp}
Siamak Ravanbakhsh.
\newblock Universal equivariant multilayer perceptrons.
\newblock {\em arXiv preprint arXiv:2002.02912}, 2020.

\bibitem[Ser77]{serre1977linear}
Jean-Pierre Serre.
\newblock {\em Linear representations of finite groups}.
\newblock Springer, 1977.

\bibitem[SGSR17a]{sokolic_generalization_2017}
Jure Sokolić, Raja Giryes, Guillermo Sapiro, and Miguel Rodrigues.
\newblock Generalization {Error} of {Invariant} {Classifiers}.
\newblock In {\em Artificial {Intelligence} and {Statistics}}, pages
  1094--1103, 2017.

\bibitem[SGSR17b]{sokolic_robust_2017}
Jure Sokolić, Raja Giryes, Guillermo Sapiro, and Miguel Rodrigues.
\newblock Robust {Large} {Margin} {Deep} {Neural} {Networks}.
\newblock {\em IEEE Transactions on Signal Processing}, 65(16):4265--4280,
  August 2017.

\bibitem[SIK21]{sannai_improved_2021}
Akiyoshi Sannai, Masaaki Imaizumi, and Makoto Kawano.
\newblock Improved generalization bounds of group invariant/equivariant deep
  networks via quotient feature spaces.
\newblock In {\em Uncertainty in {Artificial} {Intelligence}}, pages 771--780.
  PMLR, 2021.

\bibitem[ST89]{Shawe-Taylor_1989}
J.~Shawe-Taylor.
\newblock Building symmetries into feedforward networks.
\newblock In {\em 1989 First IEE International Conference on Artificial Neural
  Networks, (Conf. Publ. No. 313)}, page 158–162, Oct 1989.

\bibitem[ST93]{Shawe-Taylor_1993}
J~Shawe-Taylor.
\newblock Symmetries and discriminability in feedforward network architectures.
\newblock {\em IEEE Trans. Neural Netw.}, page 1–25, 1993.

\bibitem[STW96]{shawe-taylor_representation_1996}
John Shawe-Taylor and Jeffrey Wood.
\newblock Representation theory and invariant neural networks.
\newblock {\em Discrete Applied Mathematics}, 69(1-2):33--60, August 1996.
\newblock Publisher: North-Holland.

\bibitem[Tro12]{tropp2012user}
Joel~A Tropp.
\newblock User-friendly tail bounds for sums of random matrices.
\newblock {\em Foundations of computational mathematics}, 12(4):389--434, 2012.

\bibitem[TSK{\etalchar{+}}18]{TensorFieldNets}
Nathaniel Thomas, Tess Smidt, Steven~M. Kearnes, Lusann Yang, Li~Li, Kai
  Kohlhoff, and Patrick Riley.
\newblock Tensor field networks: Rotation- and translation-equivariant neural
  networks for 3d point clouds.
\newblock {\em arXiv preprint arXiv:1802.08219}, 2018.

\bibitem[VPL20]{valle-perez_generalization_2020}
Guillermo Valle-Pérez and Ard~A. Louis.
\newblock Generalization bounds for deep learning, December 2020.
\newblock arXiv:2012.04115 [cs, stat].

\bibitem[VSS22]{vardi_sample_2022}
Gal Vardi, Ohad Shamir, and Nathan Srebro.
\newblock The {Sample} {Complexity} of {One}-{Hidden}-{Layer} {Neural}
  {Networks}.
\newblock {\em arXiv:2202.06233 [cs, stat]}, February 2022.

\bibitem[WC19]{Weiler2019}
Maurice Weiler and Gabriele Cesa.
\newblock {General $E(2)$-Equivariant Steerable CNNs}.
\newblock In {\em Conference on Neural Information Processing Systems
  (NeurIPS)}, 2019.

\bibitem[WFVW21]{weiler_coordinate_2021}
Maurice Weiler, Patrick Forré, Erik Verlinde, and Max Welling.
\newblock Coordinate {Independent} {Convolutional} {Networks}–{Isometry} and
  {Gauge} {Equivariant} {Convolutions} on {Riemannian} {Manifolds}.
\newblock {\em arXiv preprint arXiv:2106.06020}, 2021.

\bibitem[WGTB17]{Worrall2017-HNET}
Daniel~E. Worrall, Stephan~J. Garbin, Daniyar Turmukhambetov, and Gabriel~J.
  Brostow.
\newblock Harmonic networks: Deep translation and rotation equivariance.
\newblock In {\em {Conference on Computer Vision and Pattern Recognition
  (CVPR)}}, 2017.

\bibitem[WGW{\etalchar{+}}18]{3d_steerableCNNs}
Maurice Weiler, Mario Geiger, Max Welling, Wouter Boomsma, and Taco~S. Cohen.
\newblock {3D} steerable {CNN}s: Learning rotationally equivariant features in
  volumetric data.
\newblock In {\em Conference on Neural Information Processing Systems
  (NeurIPS)}, 2018.

\bibitem[WHS18]{Weiler2018-STEERABLE}
Maurice Weiler, Fred~A. Hamprecht, and Martin Storath.
\newblock Learning steerable filters for rotation equivariant {CNNs}.
\newblock In {\em Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2018.

\bibitem[WM19]{wei_improved_2019}
Colin Wei and Tengyu Ma.
\newblock Improved {Sample} {Complexities} for {Deep} {Networks} and {Robust}
  {Classification} via an {All}-{Layer} {Margin}.
\newblock {\em arXiv:1910.04284 [cs, stat]}, October 2019.
\newblock arXiv: 1910.04284.

\bibitem[WST96]{Wood_Shawe-Taylor_1996}
Jeffrey Wood and John Shawe-Taylor.
\newblock Representation theory and invariant neural networks.
\newblock {\em Discrete Applied Mathematics}, 69(1):33 -- 60, 1996.

\bibitem[ZAH21]{zhu_understanding_2021}
Sicheng Zhu, Bang An, and Furong Huang.
\newblock Understanding the {Generalization} {Benefit} of {Model} {Invariance}
  from a {Data} {Perspective}.
\newblock In {\em Advances in {Neural} {Information} {Processing} {Systems}},
  2021.

\bibitem[ZBH{\etalchar{+}}17]{zhang_understanding_2017}
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals.
\newblock Understanding deep learning requires rethinking generalization.
\newblock In {\em {ICLR} 2017}, 2017.

\end{thebibliography}
