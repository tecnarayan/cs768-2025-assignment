\begin{thebibliography}{}

\bibitem[Abadi et~al., 2016]{abadi2016tensorflow}
Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M.,
  Ghemawat, S., Irving, G., Isard, M., et~al. (2016).
\newblock Tensorflow: A system for large-scale machine learning.
\newblock In {\em 12th $\{$USENIX$\}$ Symposium on Operating Systems Design and
  Implementation ($\{$OSDI$\}$ 16)}, pages 265--283.

\bibitem[Baydin et~al., 2017]{baydin2017automatic}
Baydin, A.~G., Pearlmutter, B.~A., Radul, A.~A., and Siskind, J.~M. (2017).
\newblock Automatic differentiation in machine learning: a survey.
\newblock {\em The Journal of Machine Learning Research}, 18(1):5595--5637.

\bibitem[Forrester et~al., 2008]{forrester2008engineering}
Forrester, A., Sobester, A., and Keane, A. (2008).
\newblock {\em Engineering design via surrogate modelling: a practical guide}.
\newblock John Wiley \& Sons.

\bibitem[Frazier et~al., 2008]{frazier2008knowledge}
Frazier, P.~I., Powell, W.~B., and Dayanik, S. (2008).
\newblock A knowledge-gradient policy for sequential information collection.
\newblock {\em SIAM Journal on Control and Optimization}, 47(5):2410--2439.

\bibitem[Gablonsky et~al., 2001]{gablonsky2001modifications}
Gablonsky, J.~M. et~al. (2001).
\newblock {\em Modifications of the DIRECT Algorithm.}
\newblock PhD thesis.

\bibitem[Hennig and Schuler, 2012]{hennig2012entropy}
Hennig, P. and Schuler, C.~J. (2012).
\newblock Entropy search for information-efficient global optimization.
\newblock {\em Journal of Machine Learning Research}, 13(Jun):1809--1837.

\bibitem[Hern{\'a}ndez-Lobato et~al., 2014]{hernandez2014predictive}
Hern{\'a}ndez-Lobato, J.~M., Hoffman, M.~W., and Ghahramani, Z. (2014).
\newblock Predictive entropy search for efficient global optimization of
  black-box functions.
\newblock In {\em Advances in neural information processing systems}, pages
  918--926.

\bibitem[Huang et~al., 2006]{huang2006sequential}
Huang, D., Allen, T.~T., Notz, W.~I., and Miller, R.~A. (2006).
\newblock Sequential kriging optimization using multiple-fidelity evaluations.
\newblock {\em Structural and Multidisciplinary Optimization}, 32(5):369--382.

\bibitem[Incropera et~al., 2007]{incropera2007fundamentals}
Incropera, F.~P., Lavine, A.~S., Bergman, T.~L., and DeWitt, D.~P. (2007).
\newblock {\em Fundamentals of heat and mass transfer}.
\newblock Wiley.

\bibitem[Jones et~al., 1993]{jones1993lipschitzian}
Jones, D.~R., Perttunen, C.~D., and Stuckman, B.~E. (1993).
\newblock Lipschitzian optimization without the lipschitz constant.
\newblock {\em Journal of optimization Theory and Applications},
  79(1):157--181.

\bibitem[Jones et~al., 1998]{jones1998efficient}
Jones, D.~R., Schonlau, M., and Welch, W.~J. (1998).
\newblock Efficient global optimization of expensive black-box functions.
\newblock {\em Journal of Global optimization}, 13(4):455--492.

\bibitem[Kandasamy et~al., 2016]{kandasamy2016gaussian}
Kandasamy, K., Dasarathy, G., Oliva, J.~B., Schneider, J., and P{\'o}czos, B.
  (2016).
\newblock Gaussian process bandit optimisation with multi-fidelity evaluations.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  992--1000.

\bibitem[Kandasamy et~al., 2017]{kandasamy2017multi}
Kandasamy, K., Dasarathy, G., Schneider, J., and P{\'o}czos, B. (2017).
\newblock Multi-fidelity bayesian optimisation with continuous approximations.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 1799--1808. JMLR. org.

\bibitem[Kingma and Ba, 2014]{kingma2014adam}
Kingma, D.~P. and Ba, J. (2014).
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}.

\bibitem[Kingma and Welling, 2013]{kingma2013auto}
Kingma, D.~P. and Welling, M. (2013).
\newblock Auto-encoding variational bayes.
\newblock {\em arXiv preprint arXiv:1312.6114}.

\bibitem[Klein et~al., 2017]{klein2017fast}
Klein, A., Falkner, S., Bartels, S., Hennig, P., and Hutter, F. (2017).
\newblock Fast bayesian optimization of machine learning hyperparameters on
  large datasets.
\newblock In {\em Artificial Intelligence and Statistics}, pages 528--536.

\bibitem[Laguna and Mart{\'\i}, 2005]{laguna2005experimental}
Laguna, M. and Mart{\'\i}, R. (2005).
\newblock Experimental testing of advanced scatter search designs for global
  optimization of multimodal functions.
\newblock {\em Journal of Global Optimization}, 33(2):235--255.

\bibitem[Lam et~al., 2015]{lam2015multifidelity}
Lam, R., Allaire, D.~L., and Willcox, K.~E. (2015).
\newblock Multifidelity optimization using statistical surrogate modeling for
  non-hierarchical information sources.
\newblock In {\em 56th AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and
  Materials Conference}, page 0143.

\bibitem[Liu and Nocedal, 1989]{liu1989limited}
Liu, D.~C. and Nocedal, J. (1989).
\newblock On the limited memory bfgs method for large scale optimization.
\newblock {\em Mathematical programming}, 45(1-3):503--528.

\bibitem[McLeod et~al., 2017]{mcleod2017practical}
McLeod, M., Osborne, M.~A., and Roberts, S.~J. (2017).
\newblock Practical bayesian optimization for variable cost objectives.
\newblock {\em arXiv preprint arXiv:1703.04335}.

\bibitem[Minka, 2001]{minka2001expectation}
Minka, T.~P. (2001).
\newblock Expectation propagation for approximate bayesian inference.
\newblock In {\em Proceedings of the Seventeenth conference on Uncertainty in
  artificial intelligence}, pages 362--369.

\bibitem[Mockus, 2012]{mockus2012bayesian}
Mockus, J. (2012).
\newblock {\em Bayesian approach to global optimization: theory and
  applications}, volume~37.
\newblock Springer Science \& Business Media.

\bibitem[Mockus et~al., 1978]{mockus1978application}
Mockus, J., Tiesis, V., and Zilinskas, A. (1978).
\newblock The application of {B}ayesian methods for seeking the extremum.
\newblock {\em Towards global optimization}, 2(117-129):2.

\bibitem[Park, 1991]{park1991tuning}
Park, J.~S. (1991).
\newblock Tuning complex computer codes to data and optimal designs.

\bibitem[Peherstorfer et~al., 2018]{peherstorfer2018survey}
Peherstorfer, B., Willcox, K., and Gunzburger, M. (2018).
\newblock Survey of multifidelity methods in uncertainty propagation,
  inference, and optimization.
\newblock {\em Siam Review}, 60(3):550--591.

\bibitem[Perdikaris et~al., 2017]{perdikaris2017nonlinear}
Perdikaris, P., Raissi, M., Damianou, A., Lawrence, N., and Karniadakis, G.~E.
  (2017).
\newblock Nonlinear information fusion algorithms for data-efficient
  multi-fidelity modelling.
\newblock {\em Proceedings of the Royal Society A: Mathematical, Physical and
  Engineering Sciences}, 473(2198):20160751.

\bibitem[Perrone et~al., 2018]{perrone2018scalable}
Perrone, V., Jenatton, R., Seeger, M.~W., and Archambeau, C. (2018).
\newblock Scalable hyperparameter transfer learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6845--6855.

\bibitem[Picheny et~al., 2013]{picheny2013quantile}
Picheny, V., Ginsbourger, D., Richet, Y., and Caplin, G. (2013).
\newblock Quantile-based optimization of noisy computer experiments with
  tunable precision.
\newblock {\em Technometrics}, 55(1):2--13.

\bibitem[Poloczek et~al., 2017]{poloczek2017multi}
Poloczek, M., Wang, J., and Frazier, P. (2017).
\newblock Multi-information source optimization.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4288--4298.

\bibitem[Rasmussen and Williams, 2006]{Rasmussen06GP}
Rasmussen, C.~E. and Williams, C. K.~I. (2006).
\newblock {\em Gaussian Processes for Machine Learning}.
\newblock MIT Press.

\bibitem[Snoek et~al., 2012]{snoek2012practical}
Snoek, J., Larochelle, H., and Adams, R.~P. (2012).
\newblock Practical bayesian optimization of machine learning algorithms.
\newblock In {\em Advances in neural information processing systems}, pages
  2951--2959.

\bibitem[Snoek et~al., 2015]{snoek2015scalable}
Snoek, J., Rippel, O., Swersky, K., Kiros, R., Satish, N., Sundaram, N.,
  Patwary, M., Prabhat, M., and Adams, R. (2015).
\newblock Scalable bayesian optimization using deep neural networks.
\newblock In {\em International conference on machine learning}, pages
  2171--2180.

\bibitem[Song et~al., 2019]{song2019general}
Song, J., Chen, Y., and Yue, Y. (2019).
\newblock A general framework for multi-fidelity bayesian optimization with
  gaussian processes.
\newblock In {\em The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 3158--3167.

\bibitem[Srinivas et~al., 2010]{srinivas2010gaussian}
Srinivas, N., Krause, A., Kakade, S., and Seeger, M. (2010).
\newblock Gaussian process optimization in the bandit setting: no regret and
  experimental design.
\newblock In {\em Proceedings of the 27th International Conference on
  International Conference on Machine Learning}, pages 1015--1022.

\bibitem[Swersky et~al., 2013]{swersky2013multi}
Swersky, K., Snoek, J., and Adams, R.~P. (2013).
\newblock Multi-task bayesian optimization.
\newblock In {\em Advances in neural information processing systems}, pages
  2004--2012.

\bibitem[Takeno et~al., 2019]{takeno2019multi}
Takeno, S., Fukuoka, H., Tsukada, Y., Koyama, T., Shiga, M., Takeuchi, I., and
  Karasuyama, M. (2019).
\newblock Multi-fidelity bayesian optimization with max-value entropy search.
\newblock {\em arXiv preprint arXiv:1901.08275}.

\bibitem[Wainwright et~al., 2008]{wainwright2008graphical}
Wainwright, M.~J., Jordan, M.~I., et~al. (2008).
\newblock Graphical models, exponential families, and variational inference.
\newblock {\em Foundations and Trends{\textregistered} in Machine Learning},
  1(1--2):1--305.

\bibitem[Wang and Jegelka, 2017]{wang2017max}
Wang, Z. and Jegelka, S. (2017).
\newblock Max-value entropy search for efficient bayesian optimization.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 3627--3635. JMLR. org.

\bibitem[Wu and Frazier, 2017]{wu2018continuous}
Wu, J. and Frazier, P.~I. (2017).
\newblock Continuous-fidelity bayesian optimization with knowledge gradient.
\newblock In {\em NIPS Workshop on Bayesian Optimization}.

\bibitem[Zhang et~al., 2017]{zhang2017information}
Zhang, Y., Hoang, T.~N., Low, B. K.~H., and Kankanhalli, M. (2017).
\newblock Information-based multi-fidelity bayesian optimization.
\newblock In {\em NIPS Workshop on Bayesian Optimization}.

\bibitem[Zienkiewicz et~al., 1977]{zienkiewicz1977finite}
Zienkiewicz, O.~C., Taylor, R.~L., Zienkiewicz, O.~C., and Taylor, R.~L.
  (1977).
\newblock {\em The finite element method}, volume~36.
\newblock McGraw-hill London.

\end{thebibliography}
