% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{najafabadi2015deep}
M.~M. Najafabadi, F.~Villanustre, T.~M. Khoshgoftaar, N.~Seliya, R.~Wald, and
  E.~Muharemagic, ``Deep learning applications and challenges in big data
  analytics,'' \emph{Journal of Big Data}, vol.~2, no.~1, pp. 1--21, 2015.

\bibitem{goodfellow2016deep}
I.~Goodfellow, Y.~Bengio, A.~Courville, and Y.~Bengio, \emph{Deep
  learning}.\hskip 1em plus 0.5em minus 0.4em\relax MIT press Cambridge, 2016,
  vol.~1, no.~2.

\bibitem{kittur2008crowdsourcing}
A.~Kittur, E.~H. Chi, and B.~Suh, ``Crowdsourcing user studies with mechanical
  turk,'' in \emph{Proceedings of the Sigchi Conference on Human Factors in
  Computing Systems}, 2008, pp. 453--456.

\bibitem{Buhrmester2011AmazonsMT}
M.~D. Buhrmester, T.~Kwang, and S.~Gosling, ``Amazon's mechanical turk,''
  \emph{Perspectives on Psychological Science}, vol.~6, pp. 3--5, 2011.

\bibitem{wazny2017crowdsourcing}
K.~Wazny, ``“crowdsourcing” ten years in: A review,'' \emph{Journal of
  Global Health}, vol.~7, p. 020602, 2017.

\bibitem{donna2013beyond}
D.~Vakharia and M.~Lease, ``Beyond {AMT:} an analysis of crowd work
  platforms,'' \emph{Computing Research Repository}, 2013.

\bibitem{karger2011iterative}
D.~Karger, S.~Oh, and D.~Shah, ``Iterative learning for reliable crowdsourcing
  systems,'' in \emph{Advances in Neural Information Processing Systems},
  vol.~24, 2011a, pp. 1953--1961.

\bibitem{karger2013efficient}
D.~R. Karger, S.~Oh, and D.~Shah, ``Efficient crowdsourcing for multi-class
  labeling,'' \emph{ACM Sigmetrics Performance Evaluation Review}, vol.~41,
  no.~1, pp. 81--92, 2013.

\bibitem{karger2014budget}
------, ``Budget-optimal task allocation for reliable crowdsourcing systems,''
  \emph{Operations Research}, vol.~62, no.~1, pp. 1--24, 2014.

\bibitem{karger2011budget}
D.~R. {Karger}, S.~{Oh}, and D.~{Shah}, ``Budget-optimal crowdsourcing using
  low-rank matrix approximations,'' in \emph{Annual Allerton Conference on
  Communication, Control, and Computing}, 2011b, pp. 284--291.

\bibitem{snow2008cheap}
R.~Snow, B.~O'Connor, D.~Jurafsky, and A.~Y. Ng, ``Cheap and fast---but is it
  good?: evaluating non-expert annotations for natural language tasks,'' in
  \emph{Proceedings of the Conference on Empirical Methods in Natural Language
  Processing}, 2008, pp. 254--263.

\bibitem{welinder2010multidimensional}
P.~Welinder, S.~Branson, P.~Perona, and S.~J. Belongie, ``The multidimensional
  wisdom of crowds,'' in \emph{Advances in Neural Information Processing
  Systems}, 2010, pp. 2424--2432.

\bibitem{liu2012variational}
Q.~Liu, J.~Peng, and A.~T. Ihler, ``Variational inference for crowdsourcing,''
  in \emph{Advances in neural information processing systems}, vol.~25, 2012,
  pp. 692--700.

\bibitem{zhang2014spectral}
Y.~Zhang, X.~Chen, D.~Zhou, and M.~I. Jordan, ``Spectral methods meet {EM}: A
  provably optimal algorithm for crowdsourcing,'' \emph{Journal of Machine
  Learning Research}, vol.~17, no. 102, pp. 1--44, 2016.

\bibitem{traganitis2018blind}
P.~A. Traganitis, A.~Pages-Zamora, and G.~B. Giannakis, ``Blind multiclass
  ensemble classification,'' \emph{IEEE Trans. Signal Process.}, vol.~66,
  no.~18, pp. 4737--4752, 2018.

\bibitem{ibrahim2019crowdsourcing}
S.~Ibrahim, X.~Fu, N.~Kargas, and K.~Huang, ``Crowdsourcing via pairwise
  co-occurrences: Identifiability and algorithms,'' in \emph{Advances in Neural
  Information Processing Systems}, vol.~32, 2019, pp. 7847--7857.

\bibitem{ma2018gradient}
Y.~Ma, A.~Olshevsky, C.~Szepesvari, and V.~Saligrama, ``Gradient descent for
  sparse rank-one matrix completion for crowd-sourced aggregation of sparsely
  interacting workers,'' in \emph{Proceedings of International Conference on
  Machine Learning}, vol.~80, 2018, pp. 3335--3344.

\bibitem{dawid1979maximum}
A.~P. Dawid and A.~M. Skene, ``Maximum likelihood estimation of observer
  error-rates using the {EM} algorithm,'' \emph{Applied statistics}, pp.
  20--28, 1979.

\bibitem{ghosh2011moderates}
A.~Ghosh, S.~Kale, and P.~McAfee, ``Who moderates the moderators?:
  crowdsourcing abuse detection in user-generated content,'' in
  \emph{Proceedings of the ACM conference on Electronic commerce}, 2011, pp.
  167--176.

\bibitem{dalvi2013aggregating}
N.~Dalvi, A.~Dasgupta, R.~Kumar, and V.~Rastogi, ``Aggregating crowdsourced
  binary ratings,'' in \emph{Proceedings of International Conference on World
  Wide Web}, 2013, pp. 285--294.

\bibitem{huang2014non}
K.~Huang, N.~Sidiropoulos, and A.~Swami, ``Non-negative matrix factorization
  revisited: Uniqueness and algorithm for symmetric decomposition,'' \emph{IEEE
  Trans. Signal Process.}, vol.~62, no.~1, pp. 211--224, 2014.

\bibitem{salk2017limitations}
C.~F. Salk, T.~Sturn, L.~See, and S.~Fritz, ``Limitations of majority agreement
  in crowdsourced image interpretation,'' \emph{Transactions in GIS}, vol.~21,
  no.~2, pp. 207--223, 2017.

\bibitem{li2014error}
H.~Li and B.~Yu, ``Error rate bounds and iterative weighted majority voting for
  crowdsourcing,'' \emph{arXiv preprint arXiv:1411.4086}, 2014.

\bibitem{li2015theoretical}
H.~Li, ``Theoretical analysis and efficient algorithms for crowdsourcing,''
  Ph.D. dissertation, UC Berkeley, 2015.

\bibitem{whitehill2009whose}
J.~Whitehill, T.~fan Wu, J.~Bergsma, J.~R. Movellan, and P.~L. Ruvolo, ``Whose
  vote should count more: Optimal integration of labels from labelers of
  unknown expertise,'' in \emph{Advances in Neural Information Processing
  Systems}, 2009, vol.~22, pp. 2035--2043.

\bibitem{zhou2012learning}
D.~Zhou, S.~Basu, Y.~Mao, and J.~C. Platt, ``Learning from the wisdom of crowds
  by minimax entropy,'' in \emph{Advances in Neural Information Processing
  Systems}, 2012, vol.~25, pp. 2195--2203.

\bibitem{zhou2015regularized}
D.~Zhou, Q.~Liu, J.~C. Platt, C.~Meek, and N.~B. Shah, ``Regularized minimax
  conditional entropy for crowdsourcing,'' \emph{Computing Research
  Repository}, 2015.

\bibitem{fu2020block}
X.~Fu, S.~Ibrahim, H.-T. Wai, C.~Gao, and K.~Huang, ``Block-randomized
  stochastic proximal gradient for low-rank tensor factorization,'' \emph{IEEE
  Trans. Signal Process.}, vol.~68, pp. 2170--2185, 2020.

\bibitem{fu2020computing}
X.~Fu, N.~Vervliet, L.~De~Lathauwer, K.~Huang, and N.~Gillis, ``Computing
  large-scale matrix and tensor decomposition with structured factors: A
  unified nonconvex optimization perspective,'' \emph{IEEE Signal Process.
  Mag.}, vol.~37, no.~5, pp. 78--94, 2020.

\bibitem{han2015minimax}
Y.~Han, J.~Jiao, and T.~Weissman, ``Minimax estimation of discrete
  distributions under $l_1$ loss,'' \emph{IEEE Trans. Inf. Theory}, vol.~61,
  no.~11, pp. 6343--6354, 2015.

\bibitem{fu2018nonnegative}
X.~Fu, K.~Huang, N.~D. Sidiropoulos, and W.-K. Ma, ``Nonnegative matrix
  factorization for signal and data analytics: Identifiability, algorithms, and
  applications.'' \emph{IEEE Signal Process. Mag.}, vol.~36, no.~2, pp. 59--80,
  2019.

\bibitem{fu2018identifiability}
X.~Fu, K.~Huang, and N.~D. Sidiropoulos, ``On identifiability of nonnegative
  matrix factorization,'' \emph{IEEE Signal Process. Lett.}, vol.~25, no.~3,
  pp. 328--332, 2018.

\bibitem{fu2015blind}
X.~Fu, W.-K. Ma, K.~Huang, and N.~D. Sidiropoulos, ``Blind separation of
  quasi-stationary sources: Exploiting convex geometry in covariance domain,''
  \emph{IEEE Trans. Signal Process.}, vol.~63, no.~9, pp. 2306--2320, May 2015.

\bibitem{fu2016robust}
X.~Fu, K.~Huang, B.~Yang, W.-K. Ma, and N.~D. Sidiropoulos, ``Robust volume
  minimization-based matrix factorization for remote sensing and document
  clustering,'' \emph{IEEE Trans. Signal Process.}, vol.~64, no.~23, pp.
  6254--6268, 2016.

\bibitem{gillis2020nonnegative}
N.~Gillis, \emph{Nonnegative Matrix Factorization}.\hskip 1em plus 0.5em minus
  0.4em\relax Society for Industrial and Applied Mathematics, 2020.

\bibitem{Candes11}
E.~Cand\'es, X.~Li, Y.~Ma, and J.~Wright, ``Robust principal component
  analysis?'' \emph{Journal of the ACM}, vol.~58, no.~3, 2011.

\bibitem{xu2012robust}
H.~Xu, C.~Caramanis, and S.~Sanghavi, ``Robust {PCA} via outlier pursuit,''
  \emph{IEEE Trans. Inf. Theory}, vol.~58, no.~5, pp. 3047--3064, 2012.

\bibitem{nie2014optimal}
F.~Nie, J.~Yuan, and H.~Huang, ``Optimal mean robust principal component
  analysis,'' in \emph{International Conference on Machine Learning}, 2014, pp.
  1062--1070.

\bibitem{sun2016guaranteed}
R.~Sun and Z.-Q. Luo, ``Guaranteed matrix completion via non-convex
  factorization,'' \emph{IEEE Trans. Inf. Theory}, vol.~62, no.~11, pp.
  6535--6579, 2016.

\bibitem{Chartrand2008}
R.~Chartrand and W.~Yin, ``Iteratively reweighted algorithms for compressive
  sensing,'' in \emph{Proceedings of International Conference on Acoustics,
  Speech and Signal Processing}, 2008, pp. 3869 --3872.

\bibitem{fu2015joint}
X.~Fu, K.~Huang, W.-K. Ma, N.~Sidiropoulos, and R.~Bro, ``Joint tensor
  factorization and outlying slab suppression with applications,'' \emph{IEEE
  Trans. Signal Process.}, vol.~63, no.~23, pp. 6315--6328, 2015.

\bibitem{huang2014putting}
K.~Huang and N.~Sidiropoulos, ``Putting nonnegative matrix factorization to the
  test: a tutorial derivation of pertinent {Cramer-Rao} bounds and performance
  benchmarking,'' \emph{IEEE Signal Process. Mag.}, vol.~31, no.~3, pp. 76--86,
  2014.

\bibitem{gillis2012sparse}
N.~Gillis, ``Sparse and unique nonnegative matrix factorization through data
  preprocessing,'' \emph{The Journal of Machine Learning Research}, vol.~13,
  no.~1, pp. 3349--3386, 2012.

\bibitem{vavasis2010complexity}
S.~A. Vavasis, ``On the complexity of nonnegative matrix factorization,''
  \emph{SIAM Journal on Optimization}, vol.~20, no.~3, pp. 1364--1377, 2010.

\bibitem{donoho2003does}
D.~Donoho and V.~Stodden, ``When does non-negative matrix factorization give a
  correct decomposition into parts?'' in \emph{Advances in neural information
  processing systems}, vol.~16, 2003.

\bibitem{li2016recovery}
Y.~Li, Y.~Liang, and A.~Risteski, ``Recovery guarantee of non-negative matrix
  factorization via alternating updates,'' in \emph{Advances in Neural
  Information Processing Systems}, vol.~29, 2016, pp. 4987--4995.

\bibitem{li2017provable}
Y.~Li and Y.~Liang, ``Provable alternating gradient descent for non-negative
  matrix factorization with strong correlations,'' in \emph{Proceedings of the
  34th International Conference on Machine Learning}, vol.~70.\hskip 1em plus
  0.5em minus 0.4em\relax PMLR, 06--11 Aug 2017, pp. 2062--2070.

\bibitem{zhou2014aggregated}
D.~Zhou, Q.~Liu, J.~Platt, and C.~Meek, ``Aggregating ordinal labels from
  crowds by minimax conditional entropy,'' in \emph{Proceedings of
  International Conference on Machine Learning}, vol.~32, 2014, pp. 262--270.

\bibitem{zhou2016crowdtensor}
Y.~Zhou and J.~He, ``Crowdsourcing via tensor augmentation and completion,'' in
  \emph{Proceedings of the Twenty-Fifth International Joint Conference on
  Artificial Intelligence}, 2016, p. 2435–2441.

\bibitem{li2018multi}
S.-Y. Li and Y.~Jiang, ``Multi-label crowdsourcing learning with incomplete
  annotations,'' in \emph{PRICAI 2018: Trends in Artificial Intelligence},
  2018, pp. 232--245.

\bibitem{Rodrigues2018deep}
F.~Rodrigues and F.~Pereira, ``Deep learning from crowds,'' \emph{Proceedings
  of the AAAI Conference on Artificial Intelligence}, vol.~32, no.~1, 2018.

\bibitem{razaviyayn2013unified}
M.~Razaviyayn, M.~Hong, and Z.-Q. Luo, ``A unified convergence analysis of
  block successive minimization methods for nonsmooth optimization,''
  \emph{SIAM Journal on Optimization}, vol.~23, no.~2, pp. 1126--1153, 2013.

\bibitem{yu2014useful}
Y.~Yu, T.~Wang, and R.~J. Samworth, ``{A useful variant of the Davis–Kahan
  theorem for statisticians},'' \emph{Biometrika}, vol. 102, no.~2, pp.
  315--323, 2014.

\bibitem{wang2012stability}
Y.-X. Wang and H.~Xu, ``Stability of matrix factorization for collaborative
  filtering,'' in \emph{Proceedings of International Conference on Machine
  Learning}, 2012, p. 163–170.

\bibitem{serfling1974probability}
R.~J. Serfling, ``Probability inequalities for the sum in sampling without
  replacement,'' \emph{Annals of Statistics}, vol.~2, no.~1, pp. 39--48, 1974.

\bibitem{wedin1972perturbation}
P.~Wedin, ``{Perturbation bounds in connection with singular value
  decomposition},'' \emph{BIT Numerical Mathematics}, vol.~12, pp. 99--111,
  1972.

\bibitem{mirsky1960quater}
L.~Mirsky, ``{Symmetric gauge functions and unitarily invariant norms},''
  \emph{The Quarterly Journal of Mathematics}, vol.~11, no.~1, pp. 50--59,
  1960.

\bibitem{fan2018eigenvector}
J.~Fan, W.~Wang, and Y.~Zhong, ``An $l_\infty$ eigenvector perturbation bound
  and its application to robust covariance estimation,'' \emph{Journal of
  Machine Learning Research}, vol.~18, no. 207, pp. 1--42, 2018.

\end{thebibliography}
