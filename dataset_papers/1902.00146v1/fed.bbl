\begin{thebibliography}{60}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2015)Abadi, Agarwal, Barham, Brevdo, Chen, Citro,
  Corrado, Davis, Dean, Devin, Ghemawat, Goodfellow, Harp, Irving, Isard, Jia,
  Jozefowicz, Kaiser, Kudlur, Levenberg, Man\'{e}, Monga, Moore, Murray, Olah,
  Schuster, Shlens, Steiner, Sutskever, Talwar, Tucker, Vanhoucke, Vasudevan,
  Vi\'{e}gas, Vinyals, Warden, Wattenberg, Wicke, Yu, and Zheng]{AbadiEtAl2015}
Mart\'{\i}n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,
  Craig Citro, Greg~S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin,
  Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard,
  Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh
  Levenberg, Dandelion Man\'{e}, Rajat Monga, Sherry Moore, Derek Murray, Chris
  Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal
  Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi\'{e}gas,
  Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and
  Xiaoqiang Zheng.
\newblock {TensorFlow}: Large-scale machine learning on heterogeneous systems,
  2015.
\newblock URL \url{https://www.tensorflow.org/}.
\newblock Software available from tensorflow.org.

\bibitem[Agarwal et~al.(2018)Agarwal, Suresh, Yu, Kumar, and
  McMahan]{AgarwalSureshYuKumarMcMahan2018}
Naman Agarwal, Ananda~Theertha Suresh, Felix~X. Yu, Sanjiv Kumar, and Brendan
  McMahan.
\newblock {cpSGD}: Communication-efficient and differentially-private
  distributed {SGD}.
\newblock In \emph{Proceedings of NeurIPS}, pages 7575--7586, 2018.

\bibitem[Banerjee et~al.(2005)Banerjee, Merugu, Dhillon, and
  Ghosh]{banerjee2005clustering}
Arindam Banerjee, Srujana Merugu, Inderjit~S Dhillon, and Joydeep Ghosh.
\newblock Clustering with {B}regman divergences.
\newblock \emph{Journal of machine learning research}, 6\penalty0
  (Oct):\penalty0 1705--1749, 2005.

\bibitem[Ben{-}David et~al.(2006)Ben{-}David, Blitzer, Crammer, and
  Pereira]{BenDavidBlitzerCrammerPereira2006}
Shai Ben{-}David, John Blitzer, Koby Crammer, and Fernando Pereira.
\newblock Analysis of representations for domain adaptation.
\newblock In \emph{{NIPS}}, pages 137--144, 2006.

\bibitem[Bickel et~al.(1975)Bickel, Hammel, and
  O{\textquoteright}Connell]{Bickel398}
P.~J. Bickel, E.~A. Hammel, and J.~W. O{\textquoteright}Connell.
\newblock Sex bias in graduate admissions: Data from {B}erkeley.
\newblock \emph{Science}, 187\penalty0 (4175):\penalty0 398--404, 1975.
\newblock ISSN 0036-8075.

\bibitem[Blake(1998)]{blake1998uci}
Catherine~L Blake.
\newblock {UCI} repository of machine learning databases, {I}rvine,
  {U}niversity of {C}alifornia.
\newblock \emph{\url{http://www.ics.uci.edu/~mlearn/MLRepository}}, 1998.

\bibitem[Blitzer et~al.(2007)Blitzer, Dredze, and
  Pereira]{Blitzer07Biographies}
John Blitzer, Mark Dredze, and Fernando Pereira.
\newblock {Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation
  for Sentiment Classification}.
\newblock In \emph{Proceedings of ACL 2007}, Prague, Czech Republic, 2007.

\bibitem[Cortes and Mohri(2014)]{CortesMohri2014}
Corinna Cortes and Mehryar Mohri.
\newblock Domain adaptation and sample bias correction theory and algorithm for
  regression.
\newblock \emph{Theor. Comput. Sci.}, 519:\penalty0 103--126, 2014.

\bibitem[Cortes et~al.(2015)Cortes, Mohri, and
  Mu{\~{n}}oz~Medina]{CortesMohriMunoz2015}
Corinna Cortes, Mehryar Mohri, and Andres Mu{\~{n}}oz~Medina.
\newblock Adaptation algorithm and theory based on generalized discrepancy.
\newblock In \emph{{KDD}}, pages 169--178, 2015.

\bibitem[Danescu-Niculescu-Mizil and Lee(2011)]{danescu2011chameleons}
Cristian Danescu-Niculescu-Mizil and Lillian Lee.
\newblock Chameleons in imagined conversations: A new approach to understanding
  coordination of linguistic style in dialogs.
\newblock In \emph{Proceedings of the 2nd Workshop on Cognitive Modeling and
  Computational Linguistics}, pages 76--87. Association for Computational
  Linguistics, 2011.

\bibitem[Daskalakis et~al.(2017)Daskalakis, Ilyas, Syrgkanis, and
  Zeng]{daskalakis2017training}
Constantinos Daskalakis, Andrew Ilyas, Vasilis Syrgkanis, and Haoyang Zeng.
\newblock Training {GAN}s with optimism.
\newblock \emph{arXiv preprint arXiv:1711.00141}, 2017.

\bibitem[Dredze et~al.(2007)Dredze, Blitzer, Talukdar, Ganchev, Graca, and
  Pereira]{Dredze07Frustratingly}
Mark Dredze, John Blitzer, Pratha~Pratim Talukdar, Kuzman Ganchev, Joao Graca,
  and Fernando Pereira.
\newblock {Frustratingly Hard Domain Adaptation for Parsing}.
\newblock In \emph{Proceedings of CoNLL 2007}, Prague, Czech Republic, 2007.

\bibitem[Farnia and Tse(2016)]{farnia2016minimax}
Farzan Farnia and David Tse.
\newblock A minimax approach to supervised learning.
\newblock In \emph{Proceedings of NIPS}, pages 4240--4248, 2016.

\bibitem[Ganin and Lempitsky(2015)]{ganin_icml15}
Yaroslav Ganin and Victor~S. Lempitsky.
\newblock Unsupervised domain adaptation by backpropagation.
\newblock In \emph{{ICML}}, volume~37, pages 1180--1189, 2015.

\bibitem[Gauvain and Chin-Hui(1994)]{Gauvain&Lee}
Jean-Luc Gauvain and Chin-Hui.
\newblock Maximum a posteriori estimation for multivariate gaussian mixture
  observations of {M}arkov chains.
\newblock \emph{IEEE Transactions on Speech and Audio Processing}, 2\penalty0
  (2):\penalty0 291â€“--298, 1994.

\bibitem[Girshick et~al.(2014)Girshick, Donahue, Darrell, and Malik]{rcnn}
Ross~B. Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik.
\newblock Rich feature hierarchies for accurate object detection and semantic
  segmentation.
\newblock In \emph{{CVPR}}, pages 580--587, 2014.

\bibitem[Gong et~al.(2012)Gong, Shi, Sha, and Grauman]{gong_cvpr12}
Boqing Gong, Yuan Shi, Fei Sha, and Kristen Grauman.
\newblock Geodesic flow kernel for unsupervised domain adaptation.
\newblock In \emph{{CVPR}}, pages 2066--2073, 2012.

\bibitem[Gong et~al.(2013{\natexlab{a}})Gong, Grauman, and Sha]{gong_icml13}
Boqing Gong, Kristen Grauman, and Fei Sha.
\newblock Connecting the dots with landmarks: Discriminatively learning
  domain-invariant features for unsupervised domain adaptation.
\newblock In \emph{{ICML}}, volume~28, pages 222--230, 2013{\natexlab{a}}.

\bibitem[Gong et~al.(2013{\natexlab{b}})Gong, Grauman, and Sha]{gong_nips13}
Boqing Gong, Kristen Grauman, and Fei Sha.
\newblock Reshaping visual datasets for domain adaptation.
\newblock In \emph{{NIPS}}, pages 1286--1294, 2013{\natexlab{b}}.

\bibitem[Gr{\"u}nwald(2007)]{grunwald2007minimum}
Peter~D. Gr{\"u}nwald.
\newblock \emph{The minimum description length principle}.
\newblock MIT press, 2007.

\bibitem[Hard et~al.(2018)Hard, Rao, Mathews, Beaufays, Augenstein, Eichner,
  Kiddon, and Ramage]{hard2018federated}
Andrew Hard, Kanishka Rao, Rajiv Mathews, Fran{\c{c}}oise Beaufays, Sean
  Augenstein, Hubert Eichner, Chlo{\'e} Kiddon, and Daniel Ramage.
\newblock Federated learning for mobile keyboard prediction.
\newblock \emph{arXiv preprint arXiv:1811.03604}, 2018.

\bibitem[Hardt et~al.(2016)Hardt, Price, Srebro, et~al.]{hardt2016equality}
Moritz Hardt, Eric Price, Nati Srebro, et~al.
\newblock Equality of opportunity in supervised learning.
\newblock In \emph{Proceedings of NIPS}, pages 3315--3323, 2016.

\bibitem[Hoffman et~al.(2012)Hoffman, Kulis, Darrell, and
  Saenko]{hoffman_eccv12}
Judy Hoffman, Brian Kulis, Trevor Darrell, and Kate Saenko.
\newblock Discovering latent domains for multisource domain adaptation.
\newblock In \emph{{ECCV}}, volume 7573, pages 702--715, 2012.

\bibitem[Hoffman et~al.(2013)Hoffman, Rodner, Donahue, Saenko, and
  Darrell]{hoffman_iclr13}
Judy Hoffman, Erik Rodner, Jeff Donahue, Kate Saenko, and Trevor Darrell.
\newblock Efficient learning of domain-invariant image representations.
\newblock In \emph{{ICLR}}, 2013.

\bibitem[Hoffman et~al.(2018)Hoffman, Mohri, and Zhang]{HoffmanMohriZhang2018}
Judy Hoffman, Mehryar Mohri, and Ningshan Zhang.
\newblock Algorithms and theory for multiple-source adaptation.
\newblock In \emph{Proceedings of NeurIPS}, pages 8256--8266, 2018.

\bibitem[Jelinek(1998)]{jelinek}
Frederick Jelinek.
\newblock \emph{{Statistical Methods for Speech Recognition}}.
\newblock The MIT Press, 1998.

\bibitem[Jiang and Zhai(2007)]{jiang-zhai07}
Jing Jiang and ChengXiang Zhai.
\newblock {Instance Weighting for Domain Adaptation in NLP}.
\newblock In \emph{Proceedings of ACL 2007}, pages 264--271, Prague, Czech
  Republic, 2007. Association for Computational Linguistics.

\bibitem[Juditsky et~al.(2011)Juditsky, Nemirovski, and
  Tauvel]{juditsky2011solving}
Anatoli Juditsky, Arkadi Nemirovski, and Claire Tauvel.
\newblock Solving variational inequalities with stochastic mirror-prox
  algorithm.
\newblock \emph{Stochastic Systems}, 1\penalty0 (1):\penalty0 17--58, 2011.

\bibitem[Koltchinskii and Panchenko(2002)]{KoltchinskiiPanchenko2002}
Vladmir Koltchinskii and Dmitry Panchenko.
\newblock Empirical margin distributions and bounding the generalization error
  of combined classifiers.
\newblock \emph{Annals of Statistics}, 30, 2002.

\bibitem[Kone{\v{c}}n{\`y} et~al.(2016{\natexlab{a}})Kone{\v{c}}n{\`y},
  McMahan, Ramage, and Richt{\'a}rik]{konecny2016federated2}
Jakub Kone{\v{c}}n{\`y}, H~Brendan McMahan, Daniel Ramage, and Peter
  Richt{\'a}rik.
\newblock Federated optimization: Distributed machine learning for on-device
  intelligence.
\newblock \emph{arXiv preprint arXiv:1610.02527}, 2016{\natexlab{a}}.

\bibitem[Kone{\v{c}}n{\`y} et~al.(2016{\natexlab{b}})Kone{\v{c}}n{\`y},
  McMahan, Yu, Richt{\'a}rik, Suresh, and Bacon]{konevcny2016federated}
Jakub Kone{\v{c}}n{\`y}, H~Brendan McMahan, Felix~X Yu, Peter Richt{\'a}rik,
  Ananda~Theertha Suresh, and Dave Bacon.
\newblock Federated learning: Strategies for improving communication
  efficiency.
\newblock \emph{arXiv preprint arXiv:1610.05492}, 2016{\natexlab{b}}.

\bibitem[Lee and Raginsky(2017)]{lee2017minimax}
Jaeho Lee and Maxim Raginsky.
\newblock Minimax statistical learning and domain adaptation with {W}asserstein
  distances.
\newblock \emph{arXiv preprint arXiv:1705.07815}, 2017.

\bibitem[Legetter and Woodland(1995)]{Legetter&Woodlang}
C.~J. Legetter and Phil~C. Woodland.
\newblock Maximum likelihood linear regression for speaker adaptation of
  continuous density hidden {M}arkov models.
\newblock \emph{Computer Speech and Language}, pages 171--185, 1995.

\bibitem[Liu et~al.(2015)Liu, Zhou, and Luo]{liu2015multiple}
Jianwei Liu, Jiajia Zhou, and Xionglin Luo.
\newblock Multiple source domain adaptation: A sharper bound using weighted
  {R}ademacher complexity.
\newblock In \emph{Technologies and Applications of Artificial Intelligence
  (TAAI), 2015 Conference on}, pages 546--553. IEEE, 2015.

\bibitem[Long et~al.(2015)Long, Cao, Wang, and Jordan]{long_icml15}
Mingsheng Long, Yue Cao, Jianmin Wang, and Michael~I. Jordan.
\newblock Learning transferable features with deep adaptation networks.
\newblock In \emph{{ICML}}, volume~37, pages 97--105, 2015.

\bibitem[Mansour et~al.(2009{\natexlab{a}})Mansour, Mohri, and
  Rostamizadeh]{MansourMohriRostamizadeh2009}
Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh.
\newblock Multiple source adaptation and the {R}{\'e}nyi divergence.
\newblock In \emph{{UAI}}, pages 367--374, 2009{\natexlab{a}}.

\bibitem[Mansour et~al.(2009{\natexlab{b}})Mansour, Mohri, and
  Rostamizadeh]{MansourMohriRostamizadeh2009Bis}
Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh.
\newblock Domain adaptation: Learning bounds and algorithms.
\newblock In \emph{{COLT}}, 2009{\natexlab{b}}.

\bibitem[Mansour et~al.(2009{\natexlab{c}})Mansour, Mohri, and
  Rostamizadeh]{MansourMohriRostamizadeh2009a}
Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh.
\newblock Domain adaptation with multiple sources.
\newblock In \emph{{NIPS}}, pages 1041--1048, 2009{\natexlab{c}}.

\bibitem[Marcus et~al.(1993)Marcus, Marcinkiewicz, and
  Santorini]{marcus1993building}
Mitchell~P Marcus, Mary~Ann Marcinkiewicz, and Beatrice Santorini.
\newblock Building a large annotated corpus of english: The penn treebank.
\newblock \emph{Computational linguistics}, 19\penalty0 (2):\penalty0 313--330,
  1993.

\bibitem[Mart\'{\i}nez(2002)]{martinez}
Aleix~M. Mart\'{\i}nez.
\newblock Recognizing imprecisely localized, partially occluded, and expression
  variant faces from a single sample per class.
\newblock \emph{IEEE Trans. Pattern Anal. Mach. Intell.}, 24\penalty0
  (6):\penalty0 748--763, 2002.

\bibitem[McMahan et~al.(2017)McMahan, Moore, Ramage, Hampson, and
  y~Arcas]{McMahanMooreRamageHampsonAguera2017}
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
  Blaise~Ag{\"{u}}era y~Arcas.
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock In \emph{Proceedings of AISTATS}, pages 1273--1282, 2017.

\bibitem[Mohri et~al.(2018)Mohri, Rostamizadeh, and
  Talwalkar]{MohriRostamizadehTalwalkar2012}
Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar.
\newblock \emph{Foundations of Machine Learning}.
\newblock MIT Press, second edition, 2018.

\bibitem[Muandet et~al.(2013)Muandet, Balduzzi, and
  Sch{\"{o}}lkopf]{MuandetBalduzziScholkopf2013}
Krikamol Muandet, David Balduzzi, and Bernhard Sch{\"{o}}lkopf.
\newblock Domain generalization via invariant feature representation.
\newblock In \emph{{ICML}}, volume~28, pages 10--18, 2013.

\bibitem[Nemirovski and Yudin(1983)]{NemirovskiYudin1983}
Arkadii~Semenovich Nemirovski and David~Berkovich Yudin.
\newblock \emph{Problem complexity and Method Efficiency in Optimization}.
\newblock Wiley, 1983.

\bibitem[Pan and Yang(2010)]{pan_tkda2010}
Sinno~Jialin Pan and Qiang Yang.
\newblock A survey on transfer learning.
\newblock \emph{{IEEE} Trans. Knowl. Data Eng.}, 22\penalty0 (10):\penalty0
  1345--1359, 2010.

\bibitem[Pietra et~al.(1992)Pietra, Pietra, Mercer, and Roukos]{DellaPietra}
S.~Della Pietra, V.~Della Pietra, R.~L. Mercer, and S.~Roukos.
\newblock Adaptive language modeling using minimum discriminant estimation.
\newblock In \emph{HLT '91: Proceedings of the workshop on Speech and Natural
  Language}, pages 103--106, Morristown, NJ, USA, 1992. Association for
  Computational Linguistics.

\bibitem[Raju et~al.(2018)Raju, Hedayatnia, Liu, Gandhe, Khatri, Metallinou,
  Venkatesh, and Rastrow]{raju2018contextual}
Anirudh Raju, Behnam Hedayatnia, Linda Liu, Ankur Gandhe, Chandra Khatri,
  Angeliki Metallinou, Anu Venkatesh, and Ariya Rastrow.
\newblock Contextual language model adaptation for conversational agents.
\newblock \emph{arXiv preprint arXiv:1806.10215}, 2018.

\bibitem[Rakhlin and Sridharan(2013)]{rakhlin2013optimization}
Sasha Rakhlin and Karthik Sridharan.
\newblock Optimization, learning, and games with predictable sequences.
\newblock In \emph{Proceedings of NIPS}, pages 3066--3074, 2013.

\bibitem[Roark and Bacchiani(2003)]{roark03supervised}
Brian Roark and Michiel Bacchiani.
\newblock Supervised and unsupervised {PCFG} adaptation to novel domains.
\newblock In \emph{Proceedings of HLT-NAACL}, 2003.

\bibitem[Rosenfeld(1996)]{Rosenfeld96}
Roni Rosenfeld.
\newblock {A Maximum Entropy Approach to Adaptive Statistical Language
  Modeling}.
\newblock \emph{Computer Speech and Language}, 10:\penalty0 187--228, 1996.

\bibitem[Saenko et~al.(2010)Saenko, Kulis, Fritz, and Darrell]{saenko_eccv10}
Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell.
\newblock Adapting visual category models to new domains.
\newblock In \emph{{ECCV}}, volume 6314, pages 213--226, 2010.

\bibitem[Smith et~al.(2017)Smith, Chiang, Sanjabi, and
  Talwalkar]{SmithChiangSanjabiTalwalkar2017}
Virginia Smith, Chao{-}Kai Chiang, Maziar Sanjabi, and Ameet~S. Talwalkar.
\newblock Federated multi-task learning.
\newblock In \emph{Proceedings of NIPS}, pages 4427--4437, 2017.

\bibitem[Suresh et~al.(2017)Suresh, Yu, Kumar, and
  McMahan]{suresh2017distributed}
Ananda~Theertha Suresh, Felix~X Yu, Sanjiv Kumar, and H~Brendan McMahan.
\newblock Distributed mean estimation with limited communication.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 3329--3337. JMLR. org, 2017.

\bibitem[Tzeng et~al.(2015)Tzeng, Hoffman, Darrell, and Saenko]{tzeng_iccv15}
Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko.
\newblock Simultaneous deep transfer across domains and tasks.
\newblock In \emph{{ICCV}}, pages 4068--4076, 2015.

\bibitem[Wang and Carreira-Perpin{\'a}n(2013)]{wang2013projection}
Weiran Wang and Miguel~A Carreira-Perpin{\'a}n.
\newblock Projection onto the probability simplex: An efficient algorithm with
  a simple proof, and an application.
\newblock \emph{arXiv preprint arXiv:1309.1541}, 2013.

\bibitem[Woodworth et~al.(2018)Woodworth, Wang, Smith, McMahan, and
  Srebro]{WoodworthWangSmithMcMahanSrebro2018}
Blake~E. Woodworth, Jialei Wang, Adam~D. Smith, Brendan McMahan, and Nati
  Srebro.
\newblock Graph oracle models, lower bounds, and gaps for parallel stochastic
  optimization.
\newblock In \emph{Proceedings of NeurIPS}, pages 8505--8515, 2018.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-{MNIST}: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock \emph{CoRR}, abs/1708.07747, 2017.
\newblock URL \url{http://arxiv.org/abs/1708.07747}.

\bibitem[Xu et~al.(2014)Xu, Li, Niu, and Xu]{xu_eccv14}
Zheng Xu, Wen Li, Li~Niu, and Dong Xu.
\newblock Exploiting low-rank structure from latent domains for domain
  generalization.
\newblock In \emph{{ECCV}}, volume 8691, pages 628--643, 2014.

\bibitem[Yang et~al.(2007)Yang, Yan, and Hauptmann]{yang_acmm07}
Jun Yang, Rong Yan, and Alexander~G. Hauptmann.
\newblock Cross-domain video concept detection using adaptive svms.
\newblock In \emph{{ACM} Multimedia}, pages 188--197, 2007.

\bibitem[Zhang et~al.(2015)Zhang, Gong, and Sch{\"{o}}lkopf]{zhang2015multi}
Kun Zhang, Mingming Gong, and Bernhard Sch{\"{o}}lkopf.
\newblock Multi-source domain adaptation: {A} causal view.
\newblock In \emph{{AAAI}}, pages 3150--3157, 2015.

\end{thebibliography}
