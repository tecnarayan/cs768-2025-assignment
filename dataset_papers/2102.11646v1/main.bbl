\begin{thebibliography}{69}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aflalo et~al.(2020)Aflalo, Noy, Lin, Friedman, and
  Zelnik]{aflalo2020knapsack}
Aflalo, Y., Noy, A., Lin, M., Friedman, I., and Zelnik, L.
\newblock Knapsack pruning with inner distillation.
\newblock \emph{arXiv preprint arXiv:2002.08258}, 2020.

\bibitem[Bender et~al.(2018)Bender, Kindermans, Zoph, Vasudevan, and
  Le]{bender2018understanding}
Bender, G., Kindermans, P.-J., Zoph, B., Vasudevan, V., and Le, Q.
\newblock Understanding and simplifying one-shot architecture search.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  550--559. PMLR, 2018.

\bibitem[Berrada et~al.(2018)Berrada, Zisserman, and Kumar]{berrada2018deep}
Berrada, L., Zisserman, A., and Kumar, M.~P.
\newblock Deep frank-wolfe for neural network optimization.
\newblock \emph{arXiv preprint arXiv:1811.07591}, 2018.

\bibitem[Bottou(1998)]{SGD}
Bottou, L.
\newblock Online algorithms and stochastic approxima-p tions.
\newblock \emph{Online learning and neural networks}, 1998.

\bibitem[Brock et~al.(2017)Brock, Lim, Ritchie, and Weston]{brock2017smash}
Brock, A., Lim, T., Ritchie, J.~M., and Weston, N.
\newblock Smash: one-shot model architecture search through hypernetworks.
\newblock \emph{arXiv preprint arXiv:1708.05344}, 2017.

\bibitem[Cai et~al.(2018)Cai, Zhu, and Han]{cai2018proxylessnas}
Cai, H., Zhu, L., and Han, S.
\newblock Proxylessnas: Direct neural architecture search on target task and
  hardware.
\newblock \emph{arXiv preprint arXiv:1812.00332}, 2018.

\bibitem[Cai et~al.(2019)Cai, Gan, Wang, Zhang, and Han]{OFA}
Cai, H., Gan, C., Wang, T., Zhang, Z., and Han, S.
\newblock Once-for-all: Train one network and specialize it for efficient
  deployment.
\newblock \emph{arXiv preprint arXiv:1908.09791}, 2019.

\bibitem[Chen et~al.(2020)Chen, Zhou, Yi, and Gu]{chen2020frank}
Chen, J., Zhou, D., Yi, J., and Gu, Q.
\newblock A frank-wolfe framework for efficient and effective adversarial
  attacks.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pp.\  3486--3494, 2020.

\bibitem[Chen et~al.(2019)Chen, Xie, Wu, and Tian]{P-DARTS}
Chen, X., Xie, L., Wu, J., and Tian, Q.
\newblock Progressive differentiable architecture search: Bridging the depth
  gap between search and evaluation.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  1294--1303, 2019.

\bibitem[Chu et~al.(2019)Chu, Zhang, Xu, and Li]{fairnas}
Chu, X., Zhang, B., Xu, R., and Li, J.
\newblock Fairnas: Rethinking evaluation fairness of weight sharing neural
  architecture search.
\newblock \emph{arXiv preprint arXiv:1907.01845}, 2019.

\bibitem[Combettes et~al.(2020)Combettes, Spiegel, and
  Pokutta]{combettes2020projection}
Combettes, C.~W., Spiegel, C., and Pokutta, S.
\newblock Projection-free adaptive gradients for large-scale optimization.
\newblock \emph{arXiv preprint arXiv:2009.14114}, 2020.

\bibitem[Cubuk et~al.(2018)Cubuk, Zoph, Mane, Vasudevan, and Le]{autoaugment}
Cubuk, E.~D., Zoph, B., Mane, D., Vasudevan, V., and Le, Q.~V.
\newblock Autoaugment: Learning augmentation policies from data.
\newblock \emph{arXiv preprint arXiv:1805.09501}, 2018.

\bibitem[d'Aspremont \& Pilanci(2020)d'Aspremont and Pilanci]{d2020global}
d'Aspremont, A. and Pilanci, M.
\newblock Global convergence of frank wolfe on one hidden layer networks.
\newblock \emph{arXiv preprint arXiv:2002.02208}, 2020.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{imagenet_cvpr09}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock {ImageNet: A Large-Scale Hierarchical Image Database}.
\newblock In \emph{CVPR09}, 2009.

\bibitem[Dong \& Yang(2019)Dong and Yang]{dong2019network}
Dong, X. and Yang, Y.
\newblock Network pruning via transformable architecture search.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  760--771, 2019.

\bibitem[Frank et~al.(1956)Frank, Wolfe, et~al.]{frank_wolfe}
Frank, M., Wolfe, P., et~al.
\newblock An algorithm for quadratic programming.
\newblock \emph{Naval research logistics quarterly}, 3\penalty0 (1-2):\penalty0
  95--110, 1956.

\bibitem[Guo et~al.(2020)Guo, Zhang, Mu, Heng, Liu, Wei, and Sun]{SPOS}
Guo, Z., Zhang, X., Mu, H., Heng, W., Liu, Z., Wei, Y., and Sun, J.
\newblock Single path one-shot neural architecture search with uniform
  sampling.
\newblock In \emph{European Conference on Computer Vision}, pp.\  544--560.
  Springer, 2020.

\bibitem[Han et~al.(2015{\natexlab{a}})Han, Mao, and Dally]{han2015deep}
Han, S., Mao, H., and Dally, W.~J.
\newblock Deep compression: Compressing deep neural networks with pruning,
  trained quantization and huffman coding.
\newblock \emph{arXiv preprint arXiv:1510.00149}, 2015{\natexlab{a}}.

\bibitem[Han et~al.(2015{\natexlab{b}})Han, Pool, Tran, and
  Dally]{han2015learning}
Han, S., Pool, J., Tran, J., and Dally, W.
\newblock Learning both weights and connections for efficient neural network.
\newblock \emph{Advances in neural information processing systems},
  28:\penalty0 1135--1143, 2015{\natexlab{b}}.

\bibitem[Hazan \& Luo(2016{\natexlab{a}})Hazan and Luo]{SFW}
Hazan, E. and Luo, H.
\newblock Variance-reduced and projection-free stochastic optimization.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1263--1271. PMLR, 2016{\natexlab{a}}.

\bibitem[Hazan \& Luo(2016{\natexlab{b}})Hazan and Luo]{hazan2016variance}
Hazan, E. and Luo, H.
\newblock Variance-reduced and projection-free stochastic optimization.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1263--1271. PMLR, 2016{\natexlab{b}}.

\bibitem[Hazan \& Minasyan(2020)Hazan and Minasyan]{hazan2020faster}
Hazan, E. and Minasyan, E.
\newblock Faster projection-free online learning.
\newblock In \emph{Conference on Learning Theory}, pp.\  1877--1893. PMLR,
  2020.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{ResNet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock \emph{2016 IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  770--778, 2015.

\bibitem[He et~al.(2018)He, Lin, Liu, Wang, Li, and Han]{he2018amc}
He, Y., Lin, J., Liu, Z., Wang, H., Li, L.-J., and Han, S.
\newblock Amc: Automl for model compression and acceleration on mobile devices.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  784--800, 2018.

\bibitem[Hinton et~al.(2015)Hinton, Vinyals, and Dean]{KD}
Hinton, G., Vinyals, O., and Dean, J.
\newblock Distilling the knowledge in a neural network.
\newblock In \emph{NIPS Deep Learning and Representation Learning Workshop},
  2015.
\newblock URL \url{http://arxiv.org/abs/1503.02531}.

\bibitem[Howard et~al.(2019)Howard, Pang, Adam, Le, Sandler, Chen, Wang, Chen,
  Tan, Chu, Vasudevan, and Zhu]{mobilenetv3}
Howard, A., Pang, R., Adam, H., Le, Q.~V., Sandler, M., Chen, B., Wang, W.,
  Chen, L., Tan, M., Chu, G., Vasudevan, V., and Zhu, Y.
\newblock Searching for mobilenetv3.
\newblock In \emph{2019 {IEEE/CVF} International Conference on Computer Vision,
  {ICCV} 2019, Seoul, Korea (South), October 27 - November 2, 2019}, pp.\
  1314--1324. {IEEE}, 2019.
\newblock \doi{10.1109/ICCV.2019.00140}.
\newblock URL \url{https://doi.org/10.1109/ICCV.2019.00140}.

\bibitem[Howard et~al.(2017)Howard, Zhu, Chen, Kalenichenko, Wang, Weyand,
  Andreetto, and Adam]{howard2017mobilenets}
Howard, A.~G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T.,
  Andreetto, M., and Adam, H.
\newblock Mobilenets: Efficient convolutional neural networks for mobile vision
  applications.
\newblock \emph{arXiv preprint arXiv:1704.04861}, 2017.

\bibitem[Hu et~al.(2018)Hu, Shen, and Sun]{SE}
Hu, J., Shen, L., and Sun, G.
\newblock Squeeze-and-excitation networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  7132--7141, 2018.

\bibitem[Hu et~al.(2020)Hu, Wu, and He]{TF-NAS}
Hu, Y., Wu, X., and He, R.
\newblock Tf-nas: Rethinking three search freedoms of latency-constrained
  differentiable neural architecture search.
\newblock \emph{arXiv preprint arXiv:2008.05314}, 2020.

\bibitem[Huang et~al.(2017)Huang, Chen, Li, Wu, van~der Maaten, and
  Weinberger]{huang2017multi}
Huang, G., Chen, D., Li, T., Wu, F., van~der Maaten, L., and Weinberger, K.~Q.
\newblock Multi-scale dense networks for resource efficient image
  classification.
\newblock \emph{arXiv preprint arXiv:1703.09844}, 2017.

\bibitem[Huang et~al.(2019)Huang, Cheng, Bapna, Firat, Chen, Chen, Lee, Ngiam,
  Le, Wu, et~al.]{huang2019gpipe}
Huang, Y., Cheng, Y., Bapna, A., Firat, O., Chen, D., Chen, M., Lee, H., Ngiam,
  J., Le, Q.~V., Wu, Y., et~al.
\newblock Gpipe: Efficient training of giant neural networks using pipeline
  parallelism.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  103--112, 2019.

\bibitem[Hubara et~al.(2016)Hubara, Courbariaux, Soudry, El-Yaniv, and
  Bengio]{hubara2016binarized}
Hubara, I., Courbariaux, M., Soudry, D., El-Yaniv, R., and Bengio, Y.
\newblock Binarized neural networks.
\newblock \emph{Advances in neural information processing systems},
  29:\penalty0 4107--4115, 2016.

\bibitem[Intel(R)(2019)]{mkl_dnn}
Intel(R).
\newblock Intel(r) math kernel library for deep neural networks (intel(r)
  mkl-dnn), 2019.
\newblock URL \url{https://github.com/rsdubtso/mkl-dnn}.

\bibitem[Jaggi(2013)]{jaggi2013revisiting}
Jaggi, M.
\newblock Revisiting frank-wolfe: Projection-free sparse convex optimization.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  427--435. PMLR, 2013.

\bibitem[Jang et~al.(2016)Jang, Gu, and Poole]{GumbelSM}
Jang, E., Gu, S., and Poole, B.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock \emph{arXiv preprint arXiv:1611.01144}, 2016.

\bibitem[Kellerer et~al.(2004)Kellerer, Pferschy, and Pisinger]{MCKP}
Kellerer, H., Pferschy, U., and Pisinger, D.
\newblock \emph{The Multiple-Choice Knapsack Problem}, pp.\  317--347.
\newblock Springer Berlin Heidelberg, Berlin, Heidelberg, 2004.
\newblock ISBN 978-3-540-24777-7.
\newblock \doi{10.1007/978-3-540-24777-7_11}.
\newblock URL \url{https://doi.org/10.1007/978-3-540-24777-7_11}.

\bibitem[Lacoste-Julien \& Jaggi(2015)Lacoste-Julien and
  Jaggi]{lacoste2015global}
Lacoste-Julien, S. and Jaggi, M.
\newblock On the global linear convergence of frank-wolfe optimization
  variants.
\newblock \emph{arXiv preprint arXiv:1511.05932}, 2015.

\bibitem[Lacoste-Julien et~al.(2013{\natexlab{a}})Lacoste-Julien, Jaggi,
  Schmidt, and Pletscher]{BCFW}
Lacoste-Julien, S., Jaggi, M., Schmidt, M., and Pletscher, P.
\newblock Block-coordinate frank-wolfe optimization for structural svms.
\newblock In \emph{International Conference on Machine Learning}, pp.\  53--61.
  PMLR, 2013{\natexlab{a}}.

\bibitem[Lacoste-Julien et~al.(2013{\natexlab{b}})Lacoste-Julien, Jaggi,
  Schmidt, and Pletscher]{lacoste2013block}
Lacoste-Julien, S., Jaggi, M., Schmidt, M., and Pletscher, P.
\newblock Block-coordinate frank-wolfe optimization for structural svms.
\newblock In \emph{International Conference on Machine Learning}, pp.\  53--61.
  PMLR, 2013{\natexlab{b}}.

\bibitem[Liang et~al.(2019)Liang, Zhang, Sun, He, Huang, Zhuang, and
  Li]{DARTS+}
Liang, H., Zhang, S., Sun, J., He, X., Huang, W., Zhuang, K., and Li, Z.
\newblock Darts+: Improved differentiable architecture search with early
  stopping.
\newblock \emph{arXiv preprint arXiv:1909.06035}, 2019.

\bibitem[Lin et~al.(2017)Lin, Rao, Lu, and Zhou]{lin2017runtime}
Lin, J., Rao, Y., Lu, J., and Zhou, J.
\newblock Runtime neural pruning.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2181--2191, 2017.

\bibitem[Liu et~al.(2018)Liu, Simonyan, and Yang]{liu2018darts}
Liu, H., Simonyan, K., and Yang, Y.
\newblock Darts: Differentiable architecture search.
\newblock \emph{arXiv preprint arXiv:1806.09055}, 2018.

\bibitem[Maurice(1938)]{KendallTau}
Maurice, K.
\newblock A new measure of rank correlation.
\newblock \emph{Biometrika}, 30\penalty0 (1-2):\penalty0 81--89, 1938.

\bibitem[Nash(2000)]{simplex}
Nash, J.~C.
\newblock The (dantzig) simplex method for linear programming.
\newblock \emph{Computing in Science and Engg.}, 2\penalty0 (1):\penalty0
  29--31, January 2000.

\bibitem[Nayman et~al.(2019)Nayman, Noy, Ridnik, Friedman, Jin, and
  Zelnik]{nayman2019xnas}
Nayman, N., Noy, A., Ridnik, T., Friedman, I., Jin, R., and Zelnik, L.
\newblock Xnas: Neural architecture search with expert advice.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1977--1987, 2019.

\bibitem[Noy et~al.(2020)Noy, Nayman, Ridnik, Zamir, Doveh, Friedman, Giryes,
  and Zelnik]{noy2020asap}
Noy, A., Nayman, N., Ridnik, T., Zamir, N., Doveh, S., Friedman, I., Giryes,
  R., and Zelnik, L.
\newblock Asap: Architecture search, anneal and prune.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  493--503. PMLR, 2020.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E.,
  DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L.,
  Bai, J., and Chintala, S.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A., d\textquotesingle
  Alch\'{e}-Buc, F., Fox, E., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems 32}, pp.\  8024--8035. Curran Associates,
  Inc., 2019.

\bibitem[Pokutta et~al.(2020)Pokutta, Spiegel, and Zimmer]{pokutta2020deep}
Pokutta, S., Spiegel, C., and Zimmer, M.
\newblock Deep neural network training with frank-wolfe.
\newblock \emph{arXiv preprint arXiv:2010.07243}, 2020.

\bibitem[Real et~al.(2019)Real, Aggarwal, Huang, and Le]{real2019regularized}
Real, E., Aggarwal, A., Huang, Y., and Le, Q.~V.
\newblock Regularized evolution for image classifier architecture search.
\newblock In \emph{Proceedings of the aaai conference on artificial
  intelligence}, volume~33, pp.\  4780--4789, 2019.

\bibitem[Ridnik et~al.(2020)Ridnik, Lawen, Noy, Ben~Baruch, Sharir, and
  Friedman]{ridnik2020tresnet}
Ridnik, T., Lawen, H., Noy, A., Ben~Baruch, E., Sharir, G., and Friedman, I.
\newblock Tresnet: High performance gpu-dedicated architecture.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision}, pp.\  1400--1409, 2020.

\bibitem[Sandler et~al.(2018{\natexlab{a}})Sandler, Howard, Zhu, Zhmoginov, and
  Chen]{mobilenetv2}
Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., and Chen, L.-C.
\newblock Mobilenetv2: Inverted residuals and linear bottlenecks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  4510--4520, 2018{\natexlab{a}}.

\bibitem[Sandler et~al.(2018{\natexlab{b}})Sandler, Howard, Zhu, Zhmoginov, and
  Chen]{sandler2018mobilenetv2}
Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., and Chen, L.-C.
\newblock Mobilenetv2: Inverted residuals and linear bottlenecks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  4510--4520, 2018{\natexlab{b}}.

\bibitem[Simonyan \& Zisserman(2015)Simonyan and Zisserman]{VGG}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Spearman(1961)]{spearman1961general}
Spearman, C.
\newblock "general intelligence" objectively determined and measured.
\newblock 1961.

\bibitem[Sun et~al.(2019)Sun, Cao, Zhu, and Zhao]{sun2019survey}
Sun, S., Cao, Z., Zhu, H., and Zhao, J.
\newblock A survey of optimization methods from a machine learning perspective.
\newblock \emph{IEEE transactions on cybernetics}, 50\penalty0 (8):\penalty0
  3668--3681, 2019.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{label_smoothing}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  2818--2826, 2016.

\bibitem[Tan \& Le(2019)Tan and Le]{effnet}
Tan, M. and Le, Q.~V.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In Chaudhuri, K. and Salakhutdinov, R. (eds.), \emph{Proceedings of
  the 36th International Conference on Machine Learning, {ICML} 2019, 9-15 June
  2019, Long Beach, California, {USA}}, volume~97 of \emph{Proceedings of
  Machine Learning Research}, pp.\  6105--6114. {PMLR}, 2019.
\newblock URL \url{http://proceedings.mlr.press/v97/tan19a.html}.

\bibitem[Tan et~al.(2019)Tan, Chen, Pang, Vasudevan, Sandler, Howard, and
  Le]{tan2019mnasnet}
Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le,
  Q.~V.
\newblock Mnasnet: Platform-aware neural architecture search for mobile.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  2820--2828, 2019.

\bibitem[Tsiligkaridis \& Roberts(2020)Tsiligkaridis and
  Roberts]{tsiligkaridis2020frank}
Tsiligkaridis, T. and Roberts, J.
\newblock On frank-wolfe optimization for adversarial robustness and
  interpretability.
\newblock \emph{arXiv preprint arXiv:2012.12368}, 2020.

\bibitem[Umuroglu et~al.(2017)Umuroglu, Fraser, Gambardella, Blott, Leong,
  Jahre, and Vissers]{umuroglu2017finn}
Umuroglu, Y., Fraser, N.~J., Gambardella, G., Blott, M., Leong, P., Jahre, M.,
  and Vissers, K.
\newblock Finn: A framework for fast, scalable binarized neural network
  inference.
\newblock In \emph{Proceedings of the 2017 ACM/SIGDA International Symposium on
  Field-Programmable Gate Arrays}, pp.\  65--74, 2017.

\bibitem[Wang et~al.(2018)Wang, Yu, Dou, Darrell, and
  Gonzalez]{wang2018skipnet}
Wang, X., Yu, F., Dou, Z.-Y., Darrell, T., and Gonzalez, J.~E.
\newblock Skipnet: Learning dynamic routing in convolutional networks.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  409--424, 2018.

\bibitem[Wu et~al.(2019)Wu, Dai, Zhang, Wang, Sun, Wu, Tian, Vajda, Jia, and
  Keutzer]{fbnet}
Wu, B., Dai, X., Zhang, P., Wang, Y., Sun, F., Wu, Y., Tian, Y., Vajda, P.,
  Jia, Y., and Keutzer, K.
\newblock Fbnet: Hardware-aware efficient convnet design via differentiable
  neural architecture search.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2019, Long Beach, CA, USA, June 16-20, 2019}, pp.\
  10734--10742. Computer Vision Foundation / {IEEE}, 2019.
\newblock \doi{10.1109/CVPR.2019.01099}.

\bibitem[Xie et~al.(2018)Xie, Zheng, Liu, and Lin]{SNAS}
Xie, S., Zheng, H., Liu, C., and Lin, L.
\newblock Snas: stochastic neural architecture search.
\newblock \emph{arXiv preprint arXiv:1812.09926}, 2018.

\bibitem[Yu et~al.(2020)Yu, Ranftl, and Salzmann]{yu2020train}
Yu, K., Ranftl, R., and Salzmann, M.
\newblock How to train your super-net: An analysis of training heuristics in
  weight-sharing nas.
\newblock \emph{arXiv preprint arXiv:2003.04276}, 2020.

\bibitem[Zhang et~al.(2017)Zhang, Cisse, Dauphin, and Lopez-Paz]{mixup}
Zhang, H., Cisse, M., Dauphin, Y.~N., and Lopez-Paz, D.
\newblock mixup: Beyond empirical risk minimization.
\newblock \emph{arXiv preprint arXiv:1710.09412}, 2017.

\bibitem[Zhang et~al.(2020{\natexlab{a}})Zhang, Wu, Zhang, Zhu, Zhang, Lin,
  Sun, He, Mueller, Manmatha, et~al.]{zhang2020resnest}
Zhang, H., Wu, C., Zhang, Z., Zhu, Y., Zhang, Z., Lin, H., Sun, Y., He, T.,
  Mueller, J., Manmatha, R., et~al.
\newblock Resnest: Split-attention networks.
\newblock \emph{arXiv preprint arXiv:2004.08955}, 2020{\natexlab{a}}.

\bibitem[Zhang et~al.(2020{\natexlab{b}})Zhang, Chen, Mokhtari, Hassani, and
  Karbasi]{zhang2020quantized}
Zhang, M., Chen, L., Mokhtari, A., Hassani, H., and Karbasi, A.
\newblock Quantized frank-wolfe: Faster optimization, lower communication, and
  projection free.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  3696--3706. PMLR, 2020{\natexlab{b}}.

\bibitem[Zhang et~al.(2018)Zhang, Zhou, Lin, and Sun]{zhang2018shufflenet}
Zhang, X., Zhou, X., Lin, M., and Sun, J.
\newblock Shufflenet: An extremely efficient convolutional neural network for
  mobile devices.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  6848--6856, 2018.

\bibitem[Zoph \& Le(2016)Zoph and Le]{zoph2016neural}
Zoph, B. and Le, Q.~V.
\newblock Neural architecture search with reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.01578}, 2016.

\end{thebibliography}
