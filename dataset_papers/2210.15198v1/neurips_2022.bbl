\begin{thebibliography}{63}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Lee et~al.(2018)Lee, Lee, Lee, and Shin]{lee2018simple}
Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin.
\newblock A simple unified framework for detecting out-of-distribution samples
  and adversarial attacks.
\newblock In \emph{{NeurIPS}}, 2018.

\bibitem[Nalisnick et~al.(2019)Nalisnick, Matsukawa, Teh, G{\"{o}}r{\"{u}}r,
  and Lakshminarayanan]{nalisnickdo19}
Eric~T. Nalisnick, Akihiro Matsukawa, Yee~Whye Teh, Dilan G{\"{o}}r{\"{u}}r,
  and Balaji Lakshminarayanan.
\newblock Do deep generative models know what they don't know?
\newblock In \emph{{ICLR}}, 2019.

\bibitem[Ren et~al.(2019)Ren, Liu, Fertig, Snoek, Poplin, DePristo, Dillon, and
  Lakshminarayanan]{RenLFSPDDL19}
Jie Ren, Peter~J. Liu, Emily Fertig, Jasper Snoek, Ryan Poplin, Mark~A.
  DePristo, Joshua~V. Dillon, and Balaji Lakshminarayanan.
\newblock Likelihood ratios for out-of-distribution detection.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Vernekar et~al.(2019)Vernekar, Gaurav, Abdelzad, Denouden, Salay, and
  Czarnecki]{vernekar2019out}
Sachin Vernekar, Ashish Gaurav, Vahdat Abdelzad, Taylor Denouden, Rick Salay,
  and Krzysztof Czarnecki.
\newblock Out-of-distribution detection in classifiers via generation.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Nguyen et~al.(2015)Nguyen, Yosinski, and Clune]{nguyen2015deep}
Anh Nguyen, Jason Yosinski, and Jeff Clune.
\newblock Deep neural networks are easily fooled: High confidence predictions
  for unrecognizable images.
\newblock In \emph{{CVPR}}, 2015.

\bibitem[Yang et~al.(2021{\natexlab{a}})Yang, Zhou, Li, and
  Liu]{yang2021generalized}
Jingkang Yang, Kaiyang Zhou, Yixuan Li, and Ziwei Liu.
\newblock Generalized out-of-distribution detection: A survey.
\newblock \emph{arXiv preprint arXiv:2110.11334}, 2021{\natexlab{a}}.

\bibitem[Hendrycks and Gimpel(2017)]{hendrycks2016baseline}
Dan Hendrycks and Kevin Gimpel.
\newblock A baseline for detecting misclassified and out-of-distribution
  examples in neural networks.
\newblock In \emph{{ICLR}}, 2017.

\bibitem[Liu et~al.(2020{\natexlab{a}})Liu, Wang, Owens, and Li]{liu2020energy}
Weitang Liu, Xiaoyun Wang, John~D Owens, and Yixuan Li.
\newblock Energy-based out-of-distribution detection.
\newblock In \emph{{NeurIPS}}, 2020{\natexlab{a}}.

\bibitem[Huang et~al.(2021{\natexlab{a}})Huang, Geng, and
  Li]{huang2021importance}
Rui Huang, Andrew Geng, and Yixuan Li.
\newblock On the importance of gradients for detecting distributional shifts in
  the wild.
\newblock In \emph{{NeurIPS}}, 2021{\natexlab{a}}.

\bibitem[Sastry and Oore(2020)]{sastry2019detecting}
Chandramouli~Shama Sastry and Sageev Oore.
\newblock Detecting out-of-distribution examples with gram matrices.
\newblock In \emph{ICML}, 2020.

\bibitem[Elsayed et~al.(2019)Elsayed, Goodfellow, and
  Sohl-Dickstein]{elsayed2018adversarial}
Gamaleldin~F Elsayed, Ian Goodfellow, and Jascha Sohl-Dickstein.
\newblock Adversarial reprogramming of neural networks.
\newblock In \emph{{ICLR}}, 2019.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei{-}Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li{-}Jia Li, Kai Li, and Li~Fei{-}Fei.
\newblock Imagenet: {A} large-scale hierarchical image database.
\newblock In \emph{{CVPR}}, 2009.

\bibitem[Tsai et~al.(2020)Tsai, Chen, and Ho]{TsaiCH20}
Yun{-}Yun Tsai, Pin{-}Yu Chen, and Tsung{-}Yi Ho.
\newblock Transfer learning without knowing: Reprogramming black-box machine
  learning models with scarce data and limited resources.
\newblock In \emph{{ICML}}, 2020.

\bibitem[Krizhevsky and Hinton(2009)]{krizhevsky2009learning}
Alex Krizhevsky and Geoffrey Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock \emph{Technical Report TR-2009, University of Toronto}, 2009.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and
  Ng]{netzer2011reading}
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo~Wu, and Andrew~Y
  Ng.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock In \emph{NeurIPS Workshop on Deep Learning and Unsupervised Feature
  Learning}, 2011.

\bibitem[Cimpoi et~al.(2014)Cimpoi, Maji, Kokkinos, Mohamed, and
  Vedaldi]{cimpoi2014describing}
Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, and Andrea
  Vedaldi.
\newblock Describing textures in the wild.
\newblock In \emph{{CVPR}}, 2014.

\bibitem[Chen et~al.(2020)Chen, Lan, Sun, and Zheng]{ChenLSZ20}
Xingyu Chen, Xuguang Lan, Fuchun Sun, and Nanning Zheng.
\newblock A boundary based out-of-distribution classifier for generalized
  zero-shot learning.
\newblock In \emph{ECCV}, 2020.

\bibitem[Huang et~al.(2021{\natexlab{b}})Huang, Li, Wang, Chen, Dong, and
  Zhou]{huang2020feature}
Haiwen Huang, Zhihan Li, Lulu Wang, Sishuo Chen, Bin Dong, and Xinyu Zhou.
\newblock Feature space singularity for out-of-distribution detection.
\newblock In \emph{safeAI}, 2021{\natexlab{b}}.

\bibitem[Zaeemzadeh et~al.(2021)Zaeemzadeh, Bisagno, Sambugaro, Conci,
  Rahnavard, and Shah]{zaeemzadeh2021out}
Alireza Zaeemzadeh, Niccol{\`o} Bisagno, Zeno Sambugaro, Nicola Conci, Nazanin
  Rahnavard, and Mubarak Shah.
\newblock Out-of-distribution detection using union of 1-dimensional subspaces.
\newblock In \emph{{CVPR}}, 2021.

\bibitem[Serr{\`{a}} et~al.(2020)Serr{\`{a}}, {\'{A}}lvarez, G{\'{o}}mez,
  Slizovskaia, N{\'{u}}{\~{n}}ez, and Luque]{SerraAGSNL20}
Joan Serr{\`{a}}, David {\'{A}}lvarez, Vicen{\c{c}} G{\'{o}}mez, Olga
  Slizovskaia, Jos{\'{e}}~F. N{\'{u}}{\~{n}}ez, and Jordi Luque.
\newblock Input complexity and out-of-distribution detection with
  likelihood-based generative models.
\newblock In \emph{{ICLR}}, 2020.

\bibitem[Zhang et~al.(2021)Zhang, Goldstein, and Ranganath]{ZhangGR21}
Lily~H. Zhang, Mark Goldstein, and Rajesh Ranganath.
\newblock Understanding failures in out-of-distribution detection with deep
  generative models.
\newblock In \emph{{ICML}}, 2021.

\bibitem[Hambardzumyan et~al.(2021)Hambardzumyan, Khachatrian, and
  May]{hambardzumyan2021warp}
Karen Hambardzumyan, Hrant Khachatrian, and Jonathan May.
\newblock Warp: Word-level adversarial reprogramming.
\newblock In \emph{ACL}, 2021.

\bibitem[Yang et~al.(2021{\natexlab{b}})Yang, Tsai, and Chen]{YangTC21}
Chao{-}Han~Huck Yang, Yun{-}Yun Tsai, and Pin{-}Yu Chen.
\newblock Voice2series: Reprogramming acoustic models for time series
  classification.
\newblock In \emph{{ICML}}, 2021{\natexlab{b}}.

\bibitem[Liang et~al.(2018)Liang, Li, and Srikant]{LiangLS18}
Shiyu Liang, Yixuan Li, and R.~Srikant.
\newblock Enhancing the reliability of out-of-distribution image detection in
  neural networks.
\newblock In \emph{ICLR}, 2018.

\bibitem[Wang et~al.(2021{\natexlab{a}})Wang, Liu, Han, Liu, Gong, Niu, Zhou,
  and Sugiyama]{wang2021probabilistic}
Qizhou Wang, Feng Liu, Bo~Han, Tongliang Liu, Chen Gong, Gang Niu, Mingyuan
  Zhou, and Masashi Sugiyama.
\newblock Probabilistic margins for instance reweighting in adversarial
  training.
\newblock In \emph{{NeurIPS}}, 2021{\natexlab{a}}.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{{ICLR}}, 2018.

\bibitem[Keskar et~al.(2017)Keskar, Mudigere, Nocedal, Smelyanskiy, and
  Tang]{KeskarMNST17}
Nitish~Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy,
  and Ping Tak~Peter Tang.
\newblock On large-batch training for deep learning: Generalization gap and
  sharp minima.
\newblock In \emph{{ICLR}}, 2017.

\bibitem[Foret et~al.(2021)Foret, Kleiner, Mobahi, and Neyshabur]{ForetKMN21}
Pierre Foret, Ariel Kleiner, Hossein Mobahi, and Behnam Neyshabur.
\newblock Sharpness-aware minimization for efficiently improving
  generalization.
\newblock In \emph{{ICLR}}, 2021.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Mazeika, and
  Dietterich]{HendrycksMD19}
Dan Hendrycks, Mantas Mazeika, and Thomas~G. Dietterich.
\newblock Deep anomaly detection with outlier exposure.
\newblock In \emph{{ICLR}}, 2019.

\bibitem[Mann(2006)]{mann2006numerically}
Tobias~P Mann.
\newblock Numerically stable hidden markov model implementation.
\newblock \emph{An HMM Scaling Tutorial}, pages 1--8, 2006.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and Fei-Fei]{ILSVRC15}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein,
  Alexander~C. Berg, and Li~Fei-Fei.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock In \emph{IJCV}, 2015.

\bibitem[Zhou et~al.(2018)Zhou, Lapedriza, Khosla, Oliva, and
  Torralba]{ZhouLKO018}
Bolei Zhou, {\`{A}}gata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio
  Torralba.
\newblock Places: {A} 10 million image database for scene recognition.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 40\penalty0 (6):\penalty0 1452--1464, 2018.

\bibitem[Yu et~al.(2015)Yu, Seff, Zhang, Song, Funkhouser, and
  Xiao]{yu2015lsun}
Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, and Jianxiong
  Xiao.
\newblock Lsun: Construction of a large-scale image dataset using deep learning
  with humans in the loop.
\newblock \emph{arXiv preprint arXiv:1506.03365}, 2015.

\bibitem[Xu et~al.(2015)Xu, Ehinger, Zhang, Finkelstein, Kulkarni, and
  Xiao]{xu2015turkergaze}
Pingmei Xu, Krista~A Ehinger, Yinda Zhang, Adam Finkelstein, Sanjeev~R
  Kulkarni, and Jianxiong Xiao.
\newblock Turkergaze: Crowdsourcing saliency with webcam based eye tracking.
\newblock \emph{arXiv preprint arXiv:1504.06755}, 2015.

\bibitem[Davis and Goadrich(2006)]{DavisG06}
Jesse Davis and Mark Goadrich.
\newblock The relationship between precision-recall and {ROC} curves.
\newblock In \emph{{ICML}}, 2006.

\bibitem[Zagoruyko and Komodakis(2016)]{zagoruyko2016wide}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Wide residual networks.
\newblock In \emph{{BMVC}}, 2016.

\bibitem[Huang and Li(2021)]{HuangL21}
Rui Huang and Yixuan Li.
\newblock {MOS:} towards scaling out-of-distribution detection for large
  semantic space.
\newblock In \emph{{CVPR}}, 2021.

\bibitem[Winkens et~al.(2020)Winkens, Bunel, Roy, Stanforth, Natarajan, Ledsam,
  MacWilliams, Kohli, Karthikesalingam, and Kohl]{winkens2020contrastive}
Jim Winkens, Rudy Bunel, Abhijit~Guha Roy, Robert Stanforth, Vivek Natarajan,
  Joseph~R Ledsam, Patricia MacWilliams, Pushmeet Kohli, Alan Karthikesalingam,
  and Simon Kohl.
\newblock Contrastive training for improved out-of-distribution detection.
\newblock \emph{arXiv preprint arXiv:2007.05566}, 2020.

\bibitem[Tack et~al.(2020)Tack, Mo, Jeong, and Shin]{tack2020csi}
Jihoon Tack, Sangwoo Mo, Jongheon Jeong, and Jinwoo Shin.
\newblock Csi: Novelty detection via contrastive learning on distributionally
  shifted instances.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Morteza and Li(2022)]{morteza2021provable}
Peyman Morteza and Yixuan Li.
\newblock Provable guarantees for understanding out-of-distribution detection.
\newblock In \emph{{AAAI}}, 2022.

\bibitem[Sun et~al.(2021)Sun, Guo, and Li]{sun2021react}
Yiyou Sun, Chuan Guo, and Yixuan Li.
\newblock React: Out-of-distribution detection with rectified activations.
\newblock In \emph{{NeurIPS}}, 2021.

\bibitem[Wang et~al.(2021{\natexlab{b}})Wang, Liu, Bocchieri, and
  Li]{wang2021can}
Haoran Wang, Weitang Liu, Alex Bocchieri, and Yixuan Li.
\newblock Can multi-label classification networks know what they don’t know?
\newblock In \emph{{NeurIPS}}, 2021{\natexlab{b}}.

\bibitem[Li et~al.(2022{\natexlab{a}})Li, Wang, Xia, Liu, Miao, and
  An]{li2022ood}
Yewen Li, Chaojie Wang, Xiaobo Xia, Tongliang Liu, Xin Miao, and Bo~An.
\newblock Out-of-distribution detection with an adaptive likelihood ratio on
  informative hierarchical vae.
\newblock In \emph{NeurIPS}, 2022{\natexlab{a}}.

\bibitem[Xiao et~al.(2020)Xiao, Yan, and Amit]{XiaoYA20}
Zhisheng Xiao, Qing Yan, and Yali Amit.
\newblock Likelihood regret: An out-of-distribution detection score for
  variational auto-encoder.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Kirichenko et~al.(2020)Kirichenko, Izmailov, and
  Wilson]{KirichenkoIW20}
Polina Kirichenko, Pavel Izmailov, and Andrew~Gordon Wilson.
\newblock Why normalizing flows fail to detect out-of-distribution data.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[DeVries and Taylor(2018)]{devries2018learning}
Terrance DeVries and Graham~W Taylor.
\newblock Learning confidence for out-of-distribution detection in neural
  networks.
\newblock \emph{arXiv preprint arXiv:1802.04865}, 2018.

\bibitem[Wang et~al.(2021{\natexlab{c}})Wang, Li, Che, Zhou, Liu, and
  Li]{wang2021energy}
Yezhen Wang, Bo~Li, Tong Che, Kaiyang Zhou, Ziwei Liu, and Dongsheng Li.
\newblock Energy-based open-world uncertainty modeling for confidence
  calibration.
\newblock In \emph{ICCV}, 2021{\natexlab{c}}.

\bibitem[Bitterwolf et~al.(2020)Bitterwolf, Meinke, and Hein]{BitterwolfM020}
Julian Bitterwolf, Alexander Meinke, and Matthias Hein.
\newblock Certifiably adversarially robust detection of out-of-distribution
  data.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Choi and Chung(2020)]{ChoiC20}
Sung{-}Ik Choi and Sae{-}Young Chung.
\newblock Novelty detection via blurring.
\newblock In \emph{{ICLR}}, 2020.

\bibitem[Hein et~al.(2019)Hein, Andriushchenko, and Bitterwolf]{0001AB19}
Matthias Hein, Maksym Andriushchenko, and Julian Bitterwolf.
\newblock Why relu networks yield high-confidence predictions far away from the
  training data and how to mitigate the problem.
\newblock In \emph{{CVPR}}, 2019.

\bibitem[Hendrycks et~al.(2020)Hendrycks, Mu, Cubuk, Zoph, Gilmer, and
  Lakshminarayanan]{HendrycksMCZGL20}
Dan Hendrycks, Norman Mu, Ekin~Dogus Cubuk, Barret Zoph, Justin Gilmer, and
  Balaji Lakshminarayanan.
\newblock Augmix: {A} simple data processing method to improve robustness and
  uncertainty.
\newblock In \emph{{ICLR}}, 2020.

\bibitem[Thulasidasan et~al.(2019)Thulasidasan, Chennupati, Bilmes,
  Bhattacharya, and Michalak]{ThulasidasanCBB19}
Sunil Thulasidasan, Gopinath Chennupati, Jeff~A. Bilmes, Tanmoy Bhattacharya,
  and Sarah Michalak.
\newblock On mixup training: Improved calibration and predictive uncertainty
  for deep neural networks.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Huang et~al.(2022)Huang, Xia, Shen, Han, Gong, Gong, and
  Liu]{huang2022harnessing}
Zhuo Huang, Xiaobo Xia, Li~Shen, Bo~Han, Mingming Gong, Chen Gong, and
  Tongliang Liu.
\newblock Harnessing out-of-distribution examples via augmenting content and
  style.
\newblock \emph{arXiv preprint arXiv:2207.03162}, 2022.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{GoodfellowSS14}
Ian~J. Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{{ICLR}}, 2015.

\bibitem[Gu et~al.(2019)Gu, Liu, Dolan{-}Gavitt, and Garg]{GuLDG19}
Tianyu Gu, Kang Liu, Brendan Dolan{-}Gavitt, and Siddharth Garg.
\newblock Badnets: Evaluating backdooring attacks on deep neural networks.
\newblock \emph{{IEEE} Access}, 7:\penalty0 47230--47244, 2019.

\bibitem[Li et~al.(2021)Li, Li, Wu, Li, He, and Lyu]{li2021invisible}
Yuezun Li, Yiming Li, Baoyuan Wu, Longkang Li, Ran He, and Siwei Lyu.
\newblock Invisible backdoor attack with sample-specific triggers.
\newblock In \emph{ICCV}, 2021.

\bibitem[Liu et~al.(2020{\natexlab{b}})Liu, Ma, Bailey, and Lu]{LiuM0020}
Yunfei Liu, Xingjun Ma, James Bailey, and Feng Lu.
\newblock Reflection backdoor: {A} natural backdoor attack on deep neural
  networks.
\newblock In \emph{ECCV}, 2020{\natexlab{b}}.

\bibitem[Saha et~al.(2020)Saha, Subramanya, and Pirsiavash]{SahaSP20}
Aniruddha Saha, Akshayvarun Subramanya, and Hamed Pirsiavash.
\newblock Hidden trigger backdoor attacks.
\newblock In \emph{AAAI}, 2020.

\bibitem[Li et~al.(2022{\natexlab{b}})Li, Jiang, Li, and Xia]{li2020backdoor}
Yiming Li, Yong Jiang, Zhifeng Li, and Shu-Tao Xia.
\newblock Backdoor learning: A survey.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  pages 1--18, 2022{\natexlab{b}}.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Basart, Mazeika, Zou, Kwon,
  Mostajabi, and Steinhardt]{hendrycks2021improving}
Dan Hendrycks, Steven Basart, Mantas Mazeika, Andy Zou, Joseph Kwon,
  Mohammadreza Mostajabi, and Jacob Steinhardt.
\newblock Improving and assessing anomaly detectors for large-scale settings.
\newblock 2021.

\bibitem[Le and Yang(2015)]{le2015tiny}
Ya~Le and Xuan Yang.
\newblock Tiny imagenet visual recognition challenge.
\newblock \emph{CS 231N}, 7\penalty0 (7):\penalty0 3, 2015.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{{CVPR}}, 2016.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{DosovitskiyB0WZ21}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In \emph{ICLR}, 2021.

\end{thebibliography}
