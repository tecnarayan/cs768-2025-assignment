\begin{thebibliography}{49}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Allais(1990)]{allais1990allais}
Allais, M.
\newblock Allais paradox.
\newblock In \emph{Utility and Probability}, pp.\  3--9. Springer, 1990.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and Bottou]{wgan}
Arjovsky, M., Chintala, S., and Bottou, L.
\newblock {Wasserstein Generative Adversarial Networks}.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning (ICML)}, 2017.

\bibitem[Azar et~al.(2012)Azar, Munos, and Kappen]{azar2012sample}
Azar, M.~G., Munos, R., and Kappen, H.~J.
\newblock On the sample complexity of reinforcement learning with a generative
  model.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, 2012.

\bibitem[Barth-Maron et~al.(2018)Barth-Maron, Hoffman, Budden, Dabney, Horgan,
  TB, Muldal, Heess, and Lillicrap]{barthmaron2018d4pg}
Barth-Maron, G., Hoffman, M.~W., Budden, D., Dabney, W., Horgan, D., TB, D.,
  Muldal, A., Heess, N., and Lillicrap, T.
\newblock Distributional policy gradients.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2018.

\bibitem[Bellemare et~al.(2013)Bellemare, Naddaf, Veness, and
  Bowling]{bellemare13arcade}
Bellemare, M.~G., Naddaf, Y., Veness, J., and Bowling, M.
\newblock {The Arcade Learning Environment: an evaluation platform for general
  agents}.
\newblock \emph{Journal of Artificial Intelligence Research}, 47:\penalty0
  253--279, 2013.

\bibitem[Bellemare et~al.(2017)Bellemare, Dabney, and Munos]{c51}
Bellemare, M.~G., Dabney, W., and Munos, R.
\newblock A distributional perspective on reinforcement learning.
\newblock \emph{Proceedings of the 34th International Conference on Machine
  Learning (ICML)}, 2017.

\bibitem[Bellman(1957)]{bellman57dynamic}
Bellman, R.~E.
\newblock \emph{{Dynamic Programming}}.
\newblock Princeton University Press, Princeton, NJ, 1957.

\bibitem[Bousquet et~al.(2017)Bousquet, Gelly, Tolstikhin, Simon-Gabriel, and
  Schoelkopf]{bousquet2017optimal}
Bousquet, O., Gelly, S., Tolstikhin, I., Simon-Gabriel, C.-J., and Schoelkopf,
  B.
\newblock From optimal transport to generative modeling: the vegan cookbook.
\newblock \emph{arXiv preprint arXiv:1705.07642}, 2017.

\bibitem[Chow \& Ghavamzadeh(2014)Chow and Ghavamzadeh]{chow2014algorithms}
Chow, Y. and Ghavamzadeh, M.
\newblock {Algorithms for CVaR optimization in MDPs}.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3509--3517, 2014.

\bibitem[Dabney et~al.(2018)Dabney, Rowland, Bellemare, and
  Munos]{dabney2017qr}
Dabney, W., Rowland, M., Bellemare, M.~G., and Munos, R.
\newblock Distributional reinforcement learning with quantile regression.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2018.

\bibitem[Dhaene et~al.(2012)Dhaene, Kukush, Linders, and
  Tang]{dhaene2012remarks}
Dhaene, J., Kukush, A., Linders, D., and Tang, Q.
\newblock Remarks on quantiles and distortion risk measures.
\newblock \emph{European Actuarial Journal}, 2\penalty0 (2):\penalty0 319--328,
  2012.

\bibitem[Fortunato et~al.(2017)Fortunato, Azar, Piot, Menick, Osband, Graves,
  Mnih, Munos, Hassabis, Pietquin, et~al.]{fortunato2017noisy}
Fortunato, M., Azar, M.~G., Piot, B., Menick, J., Osband, I., Graves, A., Mnih,
  V., Munos, R., Hassabis, D., Pietquin, O., et~al.
\newblock Noisy networks for exploration.
\newblock \emph{arXiv preprint arXiv:1706.10295}, 2017.

\bibitem[Geist \& Pietquin(2010)Geist and Pietquin]{geist2010kalman}
Geist, M. and Pietquin, O.
\newblock Kalman temporal differences.
\newblock \emph{Journal of Artificial Intelligence Research}, 39:\penalty0
  483--532, 2010.

\bibitem[Gonzalez \& Wu(1999)Gonzalez and Wu]{gonzalez1999shape}
Gonzalez, R. and Wu, G.
\newblock On the shape of the probability weighting function.
\newblock \emph{Cognitive Psychology}, 38\penalty0 (1):\penalty0 129--166,
  1999.

\bibitem[Gruslys et~al.(2018)Gruslys, Dabney, Azar, Piot, Bellemare, and
  Munos]{gruslys2018reactor}
Gruslys, A., Dabney, W., Azar, M.~G., Piot, B., Bellemare, M.~G., and Munos, R.
\newblock {The Reactor: a fast and sample-efficient actor-critic agent for
  reinforcement learning}.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2018.

\bibitem[Hessel et~al.(2018)Hessel, Modayil, Van~Hasselt, Schaul, Ostrovski,
  Dabney, Horgan, Piot, Azar, and Silver]{hessel2018rainbow}
Hessel, M., Modayil, J., Van~Hasselt, H., Schaul, T., Ostrovski, G., Dabney,
  W., Horgan, D., Piot, B., Azar, M., and Silver, D.
\newblock Rainbow: combining improvements in deep reinforcement learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2018.

\bibitem[Howard \& Matheson(1972)Howard and Matheson]{howard1972risk}
Howard, R.~A. and Matheson, J.~E.
\newblock Risk-sensitive markov decision processes.
\newblock \emph{Management Science}, 18\penalty0 (7):\penalty0 356--369, 1972.

\bibitem[Huber(1964)]{huber1964robust}
Huber, P.~J.
\newblock Robust estimation of a location parameter.
\newblock \emph{The Annals of Mathematical Statistics}, 35\penalty0
  (1):\penalty0 73--101, 1964.

\bibitem[Jaquette(1973)]{jaquette73markov}
Jaquette, S.~C.
\newblock Markov decision processes with a new optimality criterion: discrete
  time.
\newblock \emph{The Annals of Statistics}, 1\penalty0 (3):\penalty0 496--505,
  1973.

\bibitem[Koenker(2005)]{qrbook}
Koenker, R.
\newblock \emph{{Quantile Regression}}.
\newblock {Cambridge University Press}, 2005.

\bibitem[Lattimore \& Hutter(2012)Lattimore and Hutter]{lattimore2012pac}
Lattimore, T. and Hutter, M.
\newblock {PAC bounds for discounted MDPs}.
\newblock In \emph{International Conference on Algorithmic Learning Theory},
  pp.\  320--334. Springer, 2012.

\bibitem[Maddison et~al.(2017)Maddison, Lawson, Tucker, Heess, Doucet, Mnih,
  and Teh]{maddison2017particle}
Maddison, C.~J., Lawson, D., Tucker, G., Heess, N., Doucet, A., Mnih, A., and
  Teh, Y.~W.
\newblock Particle value functions.
\newblock \emph{arXiv preprint arXiv:1703.05820}, 2017.

\bibitem[Majumdar \& Pavone(2017)Majumdar and Pavone]{majumdar2017should}
Majumdar, A. and Pavone, M.
\newblock {How should a robot assess risk? Towards an axiomatic theory of risk
  in robotics}.
\newblock \emph{arXiv preprint arXiv:1710.11040}, 2017.

\bibitem[Marcus et~al.(1997)Marcus, Fern{\'a}ndez-Gaucherand,
  Hern{\'a}ndez-Hernandez, Coraluppi, and Fard]{marcus1997risk}
Marcus, S.~I., Fern{\'a}ndez-Gaucherand, E., Hern{\'a}ndez-Hernandez, D.,
  Coraluppi, S., and Fard, P.
\newblock Risk sensitive markov decision processes.
\newblock In \emph{Systems and Control in the Twenty-First Century}, pp.\
  263--279. Springer, 1997.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih15nature}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., et~al.
\newblock {Human-level control through deep reinforcement learning}.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529--533, 2015.

\bibitem[Moerland et~al.(2017)Moerland, Broekens, and
  Jonker]{moerland2017efficient}
Moerland, T.~M., Broekens, J., and Jonker, C.~M.
\newblock Efficient exploration with double uncertain value networks.
\newblock \emph{arXiv preprint arXiv:1711.10789}, 2017.

\bibitem[Morimura et~al.(2010{\natexlab{a}})Morimura, Hachiya, Sugiyama,
  Tanaka, and Kashima]{morimura10parametric}
Morimura, T., Hachiya, H., Sugiyama, M., Tanaka, T., and Kashima, H.
\newblock Parametric return density estimation for reinforcement learning.
\newblock In \emph{Proceedings of the Conference on Uncertainty in Artificial
  Intelligence (UAI)}, 2010{\natexlab{a}}.

\bibitem[Morimura et~al.(2010{\natexlab{b}})Morimura, Sugiyama, Kashima,
  Hachiya, and Tanaka]{morimura2010nonparametric}
Morimura, T., Sugiyama, M., Kashima, H., Hachiya, H., and Tanaka, T.
\newblock Nonparametric return distribution approximation for reinforcement
  learning.
\newblock In \emph{Proceedings of the 27th International Conference on Machine
  Learning (ICML)}, pp.\  799--806, 2010{\natexlab{b}}.

\bibitem[M{\"u}ller(1997)]{muller1997integral}
M{\"u}ller, A.
\newblock Integral probability metrics and their generating classes of
  functions.
\newblock \emph{Advances in Applied Probability}, 29\penalty0 (2):\penalty0
  429--443, 1997.

\bibitem[Nair et~al.(2015)Nair, Srinivasan, Blackwell, Alcicek, Fearon,
  De~Maria, Panneershelvam, Suleyman, Beattie, and Petersen]{nair15massively}
Nair, A., Srinivasan, P., Blackwell, S., Alcicek, C., Fearon, R., De~Maria, A.,
  Panneershelvam, V., Suleyman, M., Beattie, C., and Petersen, S. e.~a.
\newblock Massively parallel methods for deep reinforcement learning.
\newblock In \emph{ICML Workshop on Deep Learning}, 2015.

\bibitem[Osband et~al.(2013)Osband, Russo, and Van~Roy]{osband2013more}
Osband, I., Russo, D., and Van~Roy, B.
\newblock (more) efficient reinforcement learning via posterior sampling.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3003--3011, 2013.

\bibitem[Puterman(1994)]{puterman94markov}
Puterman, M.~L.
\newblock \emph{{Markov Decision Processes: Discrete Stochastic Dynamic
  Programming}}.
\newblock John Wiley \& Sons, Inc., 1994.

\bibitem[Rowland et~al.(2018)Rowland, Bellemare, Dabney, Munos, and
  Teh]{rowland2018analysis}
Rowland, M., Bellemare, M.~G., Dabney, W., Munos, R., and Teh, Y.~W.
\newblock An analysis of categorical distributional reinforcement learning.
\newblock In \emph{AISTATS}, 2018.

\bibitem[Schaul et~al.(2015)Schaul, Horgan, Gregor, and
  Silver]{schaul2015universal}
Schaul, T., Horgan, D., Gregor, K., and Silver, D.
\newblock Universal value function approximators.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1312--1320, 2015.

\bibitem[Schaul et~al.(2016)Schaul, Quan, Antonoglou, and
  Silver]{schaul16prioritized}
Schaul, T., Quan, J., Antonoglou, I., and Silver, D.
\newblock Prioritized experience replay.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2016.

\bibitem[Sobel(1982)]{sobel82variance}
Sobel, M.~J.
\newblock The variance of discounted markov decision processes.
\newblock \emph{Journal of Applied Probability}, 19\penalty0 (04):\penalty0
  794--802, 1982.

\bibitem[Sutton(1988)]{sutton1988learning}
Sutton, R.~S.
\newblock Learning to predict by the methods of temporal differences.
\newblock \emph{Machine Learning}, 3\penalty0 (1):\penalty0 9--44, 1988.

\bibitem[Tolstikhin et~al.(2017)Tolstikhin, Bousquet, Gelly, and
  Schoelkopf]{tolstikhin2017wasserstein}
Tolstikhin, I., Bousquet, O., Gelly, S., and Schoelkopf, B.
\newblock Wasserstein auto-encoders.
\newblock \emph{arXiv preprint arXiv:1711.01558}, 2017.

\bibitem[Tversky \& Kahneman(1992)Tversky and Kahneman]{tversky1992advances}
Tversky, A. and Kahneman, D.
\newblock Advances in prospect theory: cumulative representation of
  uncertainty.
\newblock \emph{Journal of Risk and Uncertainty}, 5\penalty0 (4):\penalty0
  297--323, 1992.

\bibitem[van Hasselt et~al.(2016)van Hasselt, Guez, and
  Silver]{vanhasselt16deep}
van Hasselt, H., Guez, A., and Silver, D.
\newblock {Deep reinforcement learning with double Q-learning}.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2016.

\bibitem[von Neumann \& Morgenstern(1947)von Neumann and
  Morgenstern]{von1947theory}
von Neumann, J. and Morgenstern, O.
\newblock \emph{Theory of Games and Economic Behavior}.
\newblock Princeton University Press, 1947.

\bibitem[Wang(1996)]{wang1996premium}
Wang, S.
\newblock Premium calculation by transforming the layer premium density.
\newblock \emph{ASTIN Bulletin: The Journal of the IAA}, 26\penalty0
  (1):\penalty0 71--92, 1996.

\bibitem[Wang(2000)]{wang2000class}
Wang, S.~S.
\newblock A class of distortion operators for pricing financial and insurance
  risks.
\newblock \emph{Journal of Risk and Insurance}, pp.\  15--36, 2000.

\bibitem[Wang et~al.(2016)Wang, Schaul, Hessel, van Hasselt, Lanctot, and
  de~Freitas]{wang2016dueling}
Wang, Z., Schaul, T., Hessel, M., van Hasselt, H., Lanctot, M., and de~Freitas,
  N.
\newblock Dueling network architectures for deep reinforcement learning.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, 2016.

\bibitem[Watkins(1989)]{watkins1989learning}
Watkins, C. J. C.~H.
\newblock \emph{Learning from delayed rewards}.
\newblock PhD thesis, King's College, Cambridge, 1989.

\bibitem[White(1988)]{white88mean}
White, D.~J.
\newblock Mean, variance, and probabilistic criteria in finite markov decision
  processes: a review.
\newblock \emph{Journal of Optimization Theory and Applications}, 56\penalty0
  (1):\penalty0 1--29, 1988.

\bibitem[Wu \& Gonzalez(1996)Wu and Gonzalez]{wu1996curvature}
Wu, G. and Gonzalez, R.
\newblock Curvature of the probability weighting function.
\newblock \emph{Management Science}, 42\penalty0 (12):\penalty0 1676--1690,
  1996.

\bibitem[Yaari(1987)]{yaari1987dual}
Yaari, M.~E.
\newblock The dual theory of choice under risk.
\newblock \emph{Econometrica: Journal of the Econometric Society}, pp.\
  95--115, 1987.

\bibitem[Yu et~al.(2016)Yu, Bauza, Fazeli, and Rodriguez]{yu2016more}
Yu, K.-T., Bauza, M., Fazeli, N., and Rodriguez, A.
\newblock More than a million ways to be pushed. a high-fidelity experimental
  dataset of planar pushing.
\newblock In \emph{Intelligent Robots and Systems (IROS), 2016 IEEE/RSJ
  International Conference on}, pp.\  30--37. IEEE, 2016.

\end{thebibliography}
