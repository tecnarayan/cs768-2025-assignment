\begin{thebibliography}{10}

\bibitem{antoniou2017data}
Antreas Antoniou, Amos Storkey, and Harrison Edwards.
\newblock Data augmentation generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1711.04340}, 2017.

\bibitem{baena2022preventing}
Raphael Baena, Lucas Drumetz, and Vincent Gripon.
\newblock Preventing manifold intrusion with locality: Local mixup.
\newblock {\em arXiv preprint arXiv:2201.04368}, 2022.

\bibitem{bouthillier2015dropout}
Xavier Bouthillier, Kishore Konda, Pascal Vincent, and Roland Memisevic.
\newblock Dropout as data augmentation.
\newblock {\em arXiv preprint arXiv:1506.08700}, 2015.

\bibitem{buhlmann2020invariance}
Peter B{\"u}hlmann.
\newblock Invariance, causality and robustness.
\newblock {\em Statistical Science}, 35(3):404--426, 2020.

\bibitem{carratino2020mixup}
Luigi Carratino, Moustapha Ciss{\'e}, Rodolphe Jenatton, and Jean-Philippe
  Vert.
\newblock On mixup regularization.
\newblock {\em The Journal of Machine Learning Research}, 23(1):14632--14662,
  2022.

\bibitem{chadebec2021data}
Cl{\'e}ment Chadebec and St{\'e}phanie Allassonni{\`e}re.
\newblock Data augmentation with variational autoencoders and manifold
  sampling.
\newblock In {\em Deep Generative Models, and Data Augmentation, Labelling, and
  Imperfections}, pages 184--192. Springer, 2021.

\bibitem{cubuk2019autoaugment}
Ekin~D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc~V Le.
\newblock Autoaugment: Learning augmentation strategies from data.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition workshops}, pages 113--123, 2019.

\bibitem{cubuk2020randaugment}
Ekin~D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V Le.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition workshops}, pages 702--703, 2020.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem{devries2017improved}
Terrance DeVries and Graham~W Taylor.
\newblock Improved regularization of convolutional neural networks with cutout.
\newblock {\em arXiv preprint arXiv:1708.04552}, 2017.

\bibitem{didelez2010assumptions}
Vanessa Didelez, Sha Meng, and Nuala~A Sheehan.
\newblock Assumptions of iv methods for observational epidemiology.
\newblock {\em Statistical Science}, 25(1):22--40, 2010.

\bibitem{dua2019uci}
Dheeru Dua and Casey Graff.
\newblock {UCI} machine learning repository, 2017.

\bibitem{goodfellow2020generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial networks.
\newblock {\em Communications of the ACM}, 63(11):139--144, 2020.

\bibitem{harrison1978hedonichousing}
David Harrison and Daniel~L Rubinfeld.
\newblock Hedonic housing prices and the demand for clean air.
\newblock {\em Journal of Environmental Economics and Management},
  5(1):81--102, 1978.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{ho2019population}
Daniel Ho, Eric Liang, Xi~Chen, Ion Stoica, and Pieter Abbeel.
\newblock Population based augmentation: Efficient learning of augmentation
  policy schedules.
\newblock In {\em International Conference on Machine Learning}, pages
  2731--2741. PMLR, 2019.

\bibitem{huang2021therapeutics}
Kexin Huang, Tianfan Fu, Wenhao Gao, Yue Zhao, Yusuf Roohani, Jure Leskovec,
  Connor~W Coley, Cao Xiao, Jimeng Sun, and Marinka Zitnik.
\newblock Therapeutics data commons: Machine learning datasets and tasks for
  drug discovery and development.
\newblock {\em arXiv preprint arXiv:2102.09548}, 2021.

\bibitem{hwang2021regmix}
Seong-Hyeon Hwang and Steven~Euijong Whang.
\newblock Regmix: Data mixing augmentation for regression.
\newblock {\em arXiv preprint arXiv:2106.03374}, 2021.

\bibitem{kelleypace1997spatial}
R.~{Kelley Pace} and Ronald Barry.
\newblock Sparse spatial autoregressions.
\newblock {\em Statistics and Probability Letters}, 33(3):291--297, 1997.

\bibitem{kim2021co}
Jang-Hyun Kim, Wonho Choo, Hosan Jeong, and Hyun~Oh Song.
\newblock Co-mixup: Saliency guided joint mixup with supermodular diversity.
\newblock {\em arXiv preprint arXiv:2102.03065}, 2021.

\bibitem{kim2020puzzle}
Jang-Hyun Kim, Wonho Choo, and Hyun~Oh Song.
\newblock Puzzle mix: Exploiting saliency and local statistics for optimal
  mixup.
\newblock In {\em International Conference on Machine Learning}, pages
  5275--5285. PMLR, 2020.

\bibitem{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em arXiv preprint arXiv:1312.6114}, 2013.

\bibitem{koh2021wilds}
Pang~Wei Koh, Shiori Sagawa, Henrik Marklund, Sang~Michael Xie, Marvin Zhang,
  Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard~Lanas Phillips,
  Irena Gao, et~al.
\newblock Wilds: A benchmark of in-the-wild distribution shifts.
\newblock In {\em International Conference on Machine Learning}, pages
  5637--5664. PMLR, 2021.

\bibitem{kooperberg1997statlib}
Charles Kooperberg.
\newblock Statlib: an archive for statistical software, datasets, and
  information.
\newblock {\em The American Statistician}, 51(1):98, 1997.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{krizhevsky2012}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock {\em Advances in neural information processing systems}, 25, 2012.

\bibitem{lai2018modeling}
Guokun Lai, Wei-Cheng Chang, Yiming Yang, and Hanxiao Liu.
\newblock Modeling long-and short-term temporal patterns with deep neural
  networks.
\newblock In {\em The 41st international ACM SIGIR conference on research \&
  development in information retrieval}, pages 95--104, 2018.

\bibitem{lakshminarayanan2017simple}
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock {\em Proceedings of the IEEE}, 86(11):2278--2324, 1998.

\bibitem{lim2019fast}
Sungbin Lim, Ildoo Kim, Taesup Kim, Chiheon Kim, and Sungwoong Kim.
\newblock Fast autoaugment.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{lin2019online}
Chen Lin, Minghao Guo, Chuming Li, Xin Yuan, Wei Wu, Junjie Yan, Dahua Lin, and
  Wanli Ouyang.
\newblock Online hyper-parameter learning for auto-augmentation strategy.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 6579--6588, 2019.

\bibitem{lingchen2020uniformaugment}
Tom~Ching LingChen, Ava Khonsari, Amirreza Lashkari, Mina~Rafi Nazari,
  Jaspreet~Singh Sambee, and Mario~A Nascimento.
\newblock Uniformaugment: A search-free probabilistic data augmentation
  approach.
\newblock {\em arXiv preprint arXiv:2003.14348}, 2020.

\bibitem{liu2022automix}
Zicheng Liu, Siyuan Li, Di~Wu, Zihan Liu, Zhiyuan Chen, Lirong Wu, and Stan~Z
  Li.
\newblock Automix: Unveiling the power of mixup for stronger classifiers.
\newblock In {\em European Conference on Computer Vision}, pages 441--458.
  Springer, 2022.

\bibitem{liu2021divaug}
Zirui Liu, Haifeng Jin, Ting-Hsiang Wang, Kaixiong Zhou, and Xia Hu.
\newblock Divaug: Plug-in automated data augmentation with explicit diversity
  maximization.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 4762--4770, 2021.

\bibitem{macqueen1967classification}
J~MacQueen.
\newblock Classification and analysis of multivariate observations.
\newblock In {\em 5th Berkeley Symp. Math. Statist. Probability}, pages
  281--297, 1967.

\bibitem{muller2021trivialaugment}
Samuel~G M{\"u}ller and Frank Hutter.
\newblock Trivialaugment: Tuning-free yet state-of-the-art data augmentation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 774--782, 2021.

\bibitem{ouyang2020video}
David Ouyang, Bryan He, Amirata Ghorbani, Neal Yuan, Joseph Ebinger, Curtis~P
  Langlotz, Paul~A Heidenreich, Robert~A Harrington, David~H Liang, Euan~A
  Ashley, et~al.
\newblock Video-based ai for beat-to-beat assessment of cardiac function.
\newblock {\em Nature}, 580(7802):252--256, 2020.

\bibitem{ozturk2018deepdta}
Hakime {\"O}zt{\"u}rk, Arzucan {\"O}zg{\"u}r, and Elif Ozkirimli.
\newblock Deepdta: deep drug--target binding affinity prediction.
\newblock {\em Bioinformatics}, 34(17):i821--i829, 2018.

\bibitem{Peters_book}
Jonas Peters, Dominik Janzing, and Bernhard Schoelkopf, editors.
\newblock {\em Elements of Causal Inference}.
\newblock MIT Press, Cambridge, MA, 2017.

\bibitem{Peters2016}
Jonas Peters, Nicolai Meinshausen, and Peter B{\"u}hlmann.
\newblock Causal inference by using invariant prediction: Identification and
  confidence intervals.
\newblock {\em Journal of the Royal Statistical Society Series B},
  78(5):947--1012, 2016.

\bibitem{rojas2018invariant}
Mateo Rojas-Carulla, Bernhard Sch{\"o}lkopf, Richard Turner, and Jonas Peters.
\newblock Invariant models for causal transfer learning.
\newblock {\em The Journal of Machine Learning Research}, 19(1):1309--1342,
  2018.

\bibitem{rothenhausler2021anchor}
Dominik Rothenh{\"a}usler, Nicolai Meinshausen, Peter B{\"u}hlmann, Jonas
  Peters, et~al.
\newblock Anchor regression: Heterogeneous data meet causality.
\newblock {\em Journal of the Royal Statistical Society Series B},
  83(2):215--246, 2021.

\bibitem{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{tang2020onlineaugment}
Zhiqiang Tang, Yunhe Gao, Leonid Karlinsky, Prasanna Sattigeri, Rogerio Feris,
  and Dimitris Metaxas.
\newblock Onlineaugment: Online data augmentation with less domain knowledge.
\newblock In {\em European Conference on Computer Vision}, pages 313--329.
  Springer, 2020.

\bibitem{taylor2018improving}
Luke Taylor and Geoff Nitschke.
\newblock Improving deep learning with generic data augmentation.
\newblock In {\em 2018 IEEE Symposium Series on Computational Intelligence
  (SSCI)}, pages 1542--1547. IEEE, 2018.

\bibitem{verma2019manifold}
Vikas Verma, Alex Lamb, Christopher Beckham, Amir Najafi, Ioannis Mitliagkas,
  David Lopez-Paz, and Yoshua Bengio.
\newblock Manifold mixup: Better representations by interpolating hidden
  states.
\newblock In {\em International conference on machine learning}, pages
  6438--6447. PMLR, 2019.

\bibitem{wang2021augmax}
Haotao Wang, Chaowei Xiao, Jean Kossaifi, Zhiding Yu, Anima Anandkumar, and
  Zhangyang Wang.
\newblock Augmax: Adversarial composition of random augmentations for robust
  training.
\newblock {\em Advances in neural information processing systems}, 34:237--250,
  2021.

\bibitem{xu2022universal}
Xiaogang Xu, Hengshuang Zhao, and Philip Torr.
\newblock Universal adaptive data augmentation.
\newblock {\em arXiv preprint arXiv:2207.06658}, 2022.

\bibitem{yao2022cmix}
Huaxiu Yao, Yiping Wang, Linjun Zhang, James Zou, and Chelsea Finn.
\newblock C-mixup: Improving generalization in regression.
\newblock In {\em Proceeding of the Thirty-Sixth Conference on Neural
  Information Processing Systems}, 2022.

\bibitem{yun2019cutmix}
Sangdoo Yun, Dongyoon Han, Seong~Joon Oh, Sanghyuk Chun, Junsuk Choe, and
  Youngjoon Yoo.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In {\em Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 6023--6032, 2019.

\bibitem{zhang2017mixup}
Hongyi Zhang, Moustapha Cisse, Yann~N Dauphin, and David Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock {\em arXiv preprint arXiv:1710.09412}, 2017.

\bibitem{zhang2020does}
Linjun Zhang, Zhun Deng, Kenji Kawaguchi, Amirata Ghorbani, and James Zou.
\newblock How does mixup help with robustness and generalization?
\newblock {\em arXiv preprint arXiv:2010.04819}, 2020.

\bibitem{zhang2019adversarial}
Xinyu Zhang, Qiang Wang, Jian Zhang, and Zhao Zhong.
\newblock Adversarial autoaugment.
\newblock {\em arXiv preprint arXiv:1912.11188}, 2019.

\end{thebibliography}
