\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aher et~al.(2023)Aher, Arriaga, and T.~Kalai]{aher2023simulate}
Gati Aher, Rosa~I. Arriaga, and Adam T.~Kalai.
\newblock Using large language models to simulate multiple humans and replicate
  human subject studies.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2023.

\bibitem[Andreas(2022)]{andreas2022language}
Jacob Andreas.
\newblock Language models as agent models.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2022}, pages 5769--5779, 2022.

\bibitem[Anwar et~al.(2024)Anwar, Saparov, Rando, Paleka, Turpin, Hase, Lubana,
  Jenner, Casper, Sourbut, et~al.]{anwar2024foundational}
Usman Anwar, Abulhair Saparov, Javier Rando, Daniel Paleka, Miles Turpin, Peter
  Hase, Ekdeep~Singh Lubana, Erik Jenner, Stephen Casper, Oliver Sourbut,
  et~al.
\newblock Foundational challenges in assuring alignment and safety of large
  language models.
\newblock \emph{arXiv preprint arXiv:2404.09932}, 2024.

\bibitem[Arditi and Obeso(2023)]{obeso2023refusal}
Andy Arditi and Oscar Obeso.
\newblock Refusal mechanisms: initial experiments with llama-2-7b-chat.
\newblock 2023.
\newblock URL
  \url{https://www.lesswrong.com/posts/pYcEhoAoPfHhgJ8YC/refusal-mechanisms-initial-experiments-with-llama-2-7b-chat}.
\newblock (Date accessed: 14.05.2024).

\bibitem[Arditi et~al.(2024)Arditi, Obeso, Syed, Gurnee, and
  Nanda]{arditi2024refusaldirection}
Andy Arditi, Oscar Obeso, Aaquib Syed, Wes Gurnee, and Neel Nanda.
\newblock Refusal in {LLM}s is mediated by a single direction.
\newblock 2024.
\newblock URL
  \url{https://www.lesswrong.com/posts/jGuXSZgv6qfdhMCuJ/refusal-in-llms-is-mediated-by-a-single-direction}.
\newblock (Date accessed: 14.05.2024).

\bibitem[Bai et~al.(2022{\natexlab{a}})Bai, Jones, Ndousse, Askell, Chen,
  DasSarma, Drain, Fort, Ganguli, Henighan, et~al.]{bai2022training}
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma,
  Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et~al.
\newblock Training a helpful and harmless assistant with reinforcement learning
  from human feedback.
\newblock \emph{arXiv preprint arXiv:2204.05862}, 2022{\natexlab{a}}.

\bibitem[Bai et~al.(2022{\natexlab{b}})Bai, Kadavath, Kundu, Askell, Kernion,
  Jones, Chen, Goldie, Mirhoseini, McKinnon, et~al.]{bai2022constitutional}
Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion,
  Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon,
  et~al.
\newblock Constitutional {AI}: Harmlessness from ai feedback.
\newblock \emph{arXiv preprint arXiv:2212.08073}, 2022{\natexlab{b}}.

\bibitem[Berglund et~al.(2023)Berglund, Tong, Kaufmann, Balesni, Stickland,
  Korbak, and Evans]{berglund2023reversal}
Lukas Berglund, Meg Tong, Maximilian Kaufmann, Mikita Balesni, Asa~Cooper
  Stickland, Tomasz Korbak, and Owain Evans.
\newblock The reversal curse: {LLMs} trained on “{A is B}” fail to learn
  “{B is A}”.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations}, 2023.

\bibitem[Burns et~al.(2022)Burns, Ye, Klein, and
  Steinhardt]{burns2022discovering}
Collin Burns, Haotian Ye, Dan Klein, and Jacob Steinhardt.
\newblock Discovering latent knowledge in language models without supervision.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2022.

\bibitem[Carlini et~al.(2023)Carlini, Nasr, Choquette-Choo, Jagielski, Gao,
  Koh, Ippolito, Tram{\`e}r, and Schmidt]{carlini2023are}
Nicholas Carlini, Milad Nasr, Christopher~A. Choquette-Choo, Matthew Jagielski,
  Irena Gao, Pang~Wei Koh, Daphne Ippolito, Florian Tram{\`e}r, and Ludwig
  Schmidt.
\newblock Are aligned neural networks adversarially aligned?
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing
  Systems}, 2023.
\newblock URL \url{https://openreview.net/forum?id=OQQoD8Vc3B}.

\bibitem[Chao et~al.(2023)Chao, Robey, Dobriban, Hassani, Pappas, and
  Wong]{chao2023jailbreaking}
Patrick Chao, Alexander Robey, Edgar Dobriban, Hamed Hassani, George~J Pappas,
  and Eric Wong.
\newblock Jailbreaking black box large language models in twenty queries.
\newblock \emph{NeurIPS 2023 Workshop R0-FoMo homepage}, 2023.
\newblock URL \url{https://arxiv.org/abs/2310.08419}.

\bibitem[Chen et~al.(2024)Chen, Vondrick, and Mao]{chen2024selfie}
Haozhe Chen, Carl Vondrick, and Chengzhi Mao.
\newblock Selfie: Self-interpretation of large language model embeddings.
\newblock \emph{arXiv preprint arXiv:2403.10949}, 2024.

\bibitem[Cheng et~al.(2023)Cheng, Durmus, and Jurafsky]{cheng2023marked}
Myra Cheng, Esin Durmus, and Dan Jurafsky.
\newblock Marked personas: Using natural language prompts to measure
  stereotypes in language models.
\newblock In \emph{Proceedings of the 61st Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 1504--1532,
  2023.

\bibitem[Chiang et~al.(2023)Chiang, Li, Lin, Sheng, Wu, Zhang, Zheng, Zhuang,
  Zhuang, Gonzalez, Stoica, and Xing]{vicuna2023}
Wei-Lin Chiang, Zhuohan Li, Zi~Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin
  Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph~E. Gonzalez, Ion Stoica, and
  Eric~P. Xing.
\newblock Vicuna: An open-source chatbot impressing {GPT}-4 with 90\%*
  {ChatGPT} quality, March 2023.
\newblock URL \url{https://lmsys.org/blog/2023-03-30-vicuna/}.

\bibitem[Deshpande et~al.(2023)Deshpande, Murahari, Rajpurohit, Kalyan, and
  Narasimhan]{deshpande2023toxicity}
Ameet Deshpande, Vishvak Murahari, Tanmay Rajpurohit, Ashwin Kalyan, and
  Karthik Narasimhan.
\newblock Toxicity in chatgpt: Analyzing persona-assigned language models.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2023}, pages 1236--1270, 2023.

\bibitem[Din et~al.(2023)Din, Karidi, Choshen, and Geva]{din2023jump}
Alexander~Yom Din, Taelin Karidi, Leshem Choshen, and Mor Geva.
\newblock Jump to conclusions: Short-cutting transformers with linear
  transformations.
\newblock \emph{arXiv preprint arXiv:2303.09435}, 2023.

\bibitem[Ganguli et~al.(2022)Ganguli, Lovitt, Kernion, Askell, Bai, Kadavath,
  Mann, Perez, Schiefer, Ndousse, et~al.]{ganguli2022red}
Deep Ganguli, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai, Saurav
  Kadavath, Ben Mann, Ethan Perez, Nicholas Schiefer, Kamal Ndousse, et~al.
\newblock Red teaming language models to reduce harms: Methods, scaling
  behaviors, and lessons learned.
\newblock \emph{arXiv preprint arXiv:2209.07858}, 2022.

\bibitem[Geva et~al.(2023)Geva, Bastings, Filippova, and
  Globerson]{geva-etal-2023-dissecting}
Mor Geva, Jasmijn Bastings, Katja Filippova, and Amir Globerson.
\newblock Dissecting recall of factual associations in auto-regressive language
  models.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors,
  \emph{Proceedings of the 2023 Conference on Empirical Methods in Natural
  Language Processing}, pages 12216--12235, Singapore, December 2023.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.emnlp-main.751}.
\newblock URL \url{https://aclanthology.org/2023.emnlp-main.751}.

\bibitem[Ghandeharioun et~al.(2024)Ghandeharioun, Caciularu, Pearce, Dixon, and
  Geva]{ghandeharioun2024patchscopes}
Asma Ghandeharioun, Avi Caciularu, Adam Pearce, Lucas Dixon, and Mor Geva.
\newblock Patchscopes: A unifying framework for inspecting hidden
  representations of language models.
\newblock \emph{arXiv preprint arXiv:2401.06102}, 2024.

\bibitem[Gonen and Goldberg(2019)]{gonen2019lipstick}
Hila Gonen and Yoav Goldberg.
\newblock Lipstick on a pig: Debiasing methods cover up systematic gender
  biases in word embeddings but do not remove them.
\newblock In \emph{Proceedings of the 2019 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 609--614, 2019.

\bibitem[Gupta et~al.(2023)Gupta, Shrivastava, Deshpande, Kalyan, Clark,
  Sabharwal, and Khot]{gupta2023bias}
Shashank Gupta, Vaishnavi Shrivastava, Ameet Deshpande, Ashwin Kalyan, Peter
  Clark, Ashish Sabharwal, and Tushar Khot.
\newblock Bias runs deep: Implicit reasoning biases in persona-assigned {LLMs}.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations}, 2023.

\bibitem[Hendel et~al.(2023)Hendel, Geva, and Globerson]{hendel2023context}
Roee Hendel, Mor Geva, and Amir Globerson.
\newblock In-context learning creates task vectors.
\newblock In \emph{The 2023 Conference on Empirical Methods in Natural Language
  Processing}, 2023.

\bibitem[Hernandez et~al.(2024)Hernandez, Sharma, Haklay, Meng, Wattenberg,
  Andreas, Belinkov, and Bau]{hernandez2023linearity}
Evan Hernandez, Arnab~Sen Sharma, Tal Haklay, Kevin Meng, Martin Wattenberg,
  Jacob Andreas, Yonatan Belinkov, and David Bau.
\newblock Linearity of relation decoding in transformer language models.
\newblock \emph{The Thirteenth International Conference on Learning
  Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=w7LU2s14kE}.

\bibitem[Joshi et~al.(2023)Joshi, Rando, Saparov, Kim, and
  He]{joshi2023personas}
Nitish Joshi, Javier Rando, Abulhair Saparov, Najoung Kim, and He~He.
\newblock Personas as a way to model truthfulness in language models.
\newblock \emph{arXiv preprint arXiv:2310.18168}, 2023.

\bibitem[Lee et~al.(2024)Lee, Bai, Pres, Wattenberg, Kummerfeld, and
  Mihalcea]{lee2024mechanistic}
Andrew Lee, Xiaoyan Bai, Itamar Pres, Martin Wattenberg, Jonathan~K Kummerfeld,
  and Rada Mihalcea.
\newblock A mechanistic understanding of alignment algorithms: A case study on
  dpo and toxicity.
\newblock \emph{arXiv preprint arXiv:2401.01967}, 2024.

\bibitem[Li et~al.(2024{\natexlab{a}})Li, Liu, Bashkansky, Bau, Vi{\'e}gas,
  Pfister, and Wattenberg]{li2024measuring}
Kenneth Li, Tianle Liu, Naomi Bashkansky, David Bau, Fernanda Vi{\'e}gas,
  Hanspeter Pfister, and Martin Wattenberg.
\newblock Measuring and controlling persona drift in language model dialogs.
\newblock \emph{arXiv preprint arXiv:2402.10962}, 2024{\natexlab{a}}.

\bibitem[Li et~al.(2024{\natexlab{b}})Li, Patel, Vi{\'e}gas, Pfister, and
  Wattenberg]{li2024inference}
Kenneth Li, Oam Patel, Fernanda Vi{\'e}gas, Hanspeter Pfister, and Martin
  Wattenberg.
\newblock Inference-time intervention: Eliciting truthful answers from a
  language model.
\newblock \emph{Advances in Neural Information Processing Systems}, 36,
  2024{\natexlab{b}}.

\bibitem[Lisa P.~Argyle and Wingate(2023)]{argyle2023simulate}
Nancy Fulda Joshua R. Gubler Christopher~Rytting Lisa P.~Argyle, Ethan C.~Busby
  and David Wingate.
\newblock Out of one, many: Using language models to simulate human samples.
\newblock \emph{Political Analysis}, 31:\penalty0 337--351, 2023.

\bibitem[Liu et~al.(2023)Liu, Xing, and Zou]{liu2023context}
Sheng Liu, Lei Xing, and James Zou.
\newblock In-context vectors: Making in context learning more effective and
  controllable through latent space steering.
\newblock \emph{arXiv preprint arXiv:2311.06668}, 2023.

\bibitem[Mack and Turner(2024)]{mack2024mechanistic}
Andrew Mack and Alex Turner.
\newblock Mechanistically eliciting latent behaviors in language models.
\newblock 2024.
\newblock URL
  \url{https://www.alignmentforum.org/posts/ioPnHKFyy4Cw2Gr2x/mechanistically-eliciting-latent-behaviors-in-language-1}.
\newblock (Date accessed: 14.05.2024).

\bibitem[Mehrotra et~al.(2023)Mehrotra, Zampetakis, Kassianik, Nelson,
  Anderson, Singer, and Karbasi]{mehrotra2023tree}
Anay Mehrotra, Manolis Zampetakis, Paul Kassianik, Blaine Nelson, Hyrum
  Anderson, Yaron Singer, and Amin Karbasi.
\newblock Tree of attacks: Jailbreaking black-box llms automatically.
\newblock \emph{arXiv preprint arXiv:2312.02119}, 2023.

\bibitem[Merchant et~al.(2020)Merchant, Rahimtoroghi, Pavlick, and
  Tenney]{merchant2020happens}
Amil Merchant, Elahe Rahimtoroghi, Ellie Pavlick, and Ian Tenney.
\newblock What happens to bert embeddings during fine-tuning?
\newblock In \emph{Proceedings of the Third BlackboxNLP Workshop on Analyzing
  and Interpreting Neural Networks for NLP}, pages 33--44, 2020.

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin,
  Zhang, Agarwal, Slama, Ray, et~al.]{ouyang2022training}
Long Ouyang, Jeffrey Wu, Xu~Jiang, Diogo Almeida, Carroll Wainwright, Pamela
  Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock \emph{Advances in neural information processing systems},
  35:\penalty0 27730--27744, 2022.

\bibitem[Pal et~al.(2023)Pal, Sun, Yuan, Wallace, and Bau]{pal2023future}
Koyena Pal, Jiuding Sun, Andrew Yuan, Byron~C Wallace, and David Bau.
\newblock Future lens: Anticipating subsequent tokens from a single hidden
  state.
\newblock In \emph{Proceedings of the 27th Conference on Computational Natural
  Language Learning (CoNLL)}, pages 548--560, 2023.

\bibitem[Park et~al.(2023)Park, Choe, and Veitch]{park2023linear}
Kiho Park, Yo~Joong Choe, and Victor Veitch.
\newblock The linear representation hypothesis and the geometry of large
  language models.
\newblock In \emph{Causal Representation Learning Workshop at NeurIPS 2023},
  2023.

\bibitem[Prakash et~al.(2023)Prakash, Shaham, Haklay, Belinkov, and
  Bau]{prakash2023fine}
Nikhil Prakash, Tamar~Rott Shaham, Tal Haklay, Yonatan Belinkov, and David Bau.
\newblock Fine-tuning enhances existing mechanisms: A case study on entity
  tracking.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations}, 2023.

\bibitem[Rimsky et~al.(2023)Rimsky, Gabrieli, Schulz, Tong, Hubinger, and
  Turner]{rimsky2023steering}
Nina Rimsky, Nick Gabrieli, Julian Schulz, Meg Tong, Evan Hubinger, and
  Alexander~Matt Turner.
\newblock Steering llama 2 via contrastive activation addition.
\newblock \emph{arXiv preprint arXiv:2312.06681}, 2023.

\bibitem[Schuster et~al.(2022)Schuster, Fisch, Gupta, Dehghani, Bahri, Tran,
  Tay, and Metzler]{schuster2022confident}
Tal Schuster, Adam Fisch, Jai Gupta, Mostafa Dehghani, Dara Bahri, Vinh Tran,
  Yi~Tay, and Donald Metzler.
\newblock Confident adaptive language modeling.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 17456--17472, 2022.

\bibitem[Schwartz et~al.(2020)Schwartz, Stanovsky, Swayamdipta, Dodge, and
  Smith]{schwartz2020right}
Roy Schwartz, Gabriel Stanovsky, Swabha Swayamdipta, Jesse Dodge, and Noah~A
  Smith.
\newblock The right tool for the job: Matching model and instance complexities.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 6640--6651, 2020.

\bibitem[Solaiman and Dennison(2021)]{solaiman2021process}
Irene Solaiman and Christy Dennison.
\newblock Process for adapting language models to society (palms) with
  values-targeted datasets.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 5861--5873, 2021.

\bibitem[Steck et~al.(2024)Steck, Ekanadham, and Kallus]{steck2024cosine}
Harald Steck, Chaitanya Ekanadham, and Nathan Kallus.
\newblock Is cosine-similarity of embeddings really about similarity?
\newblock \emph{arXiv preprint arXiv:2403.05440}, 2024.

\bibitem[Subramani et~al.(2022)Subramani, Suresh, and
  Peters]{subramani2022extracting}
Nishant Subramani, Nivedita Suresh, and Matthew~E Peters.
\newblock Extracting latent steering vectors from pretrained language models.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL 2022}, pages 566--581, 2022.

\bibitem[Team et~al.(2024)Team, Mesnard, Hardin, Dadashi, Bhupatiraju, Pathak,
  Sifre, Rivi{\`e}re, Kale, Love, et~al.]{team2024gemma}
Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju,
  Shreya Pathak, Laurent Sifre, Morgane Rivi{\`e}re, Mihir~Sanjay Kale,
  Juliette Love, et~al.
\newblock Gemma: Open models based on gemini research and technology.
\newblock \emph{arXiv preprint arXiv:2403.08295}, 2024.

\bibitem[Tenney et~al.(2019)Tenney, Das, and Pavlick]{tenney2019bert}
Ian Tenney, Dipanjan Das, and Ellie Pavlick.
\newblock Bert rediscovers the classical nlp pipeline.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pages 4593--4601, 2019.

\bibitem[Touvron et~al.(2023{\natexlab{a}})Touvron, Lavril, Izacard, Martinet,
  Lachaux, Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar,
  et~al.]{touvron2023llama1}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
  Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric
  Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023{\natexlab{a}}.

\bibitem[Touvron et~al.(2023{\natexlab{b}})Touvron, Martin, Stone, Albert,
  Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale,
  et~al.]{touvron2023llama}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine
  Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,
  et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv preprint arXiv:2307.09288}, 2023{\natexlab{b}}.

\bibitem[Vi{\'e}gas and Wattenberg(2023)]{viegas2023system}
Fernanda Vi{\'e}gas and Martin Wattenberg.
\newblock The system model and the user model: Exploring {AI} dashboard design.
\newblock \emph{arXiv preprint arXiv:2305.02469}, 2023.

\bibitem[Voita et~al.(2019)Voita, Sennrich, and Titov]{voita2019bottom}
Elena Voita, Rico Sennrich, and Ivan Titov.
\newblock The bottom-up evolution of representations in the transformer: A
  study with machine translation and language modeling objectives.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pages 4396--4406, 2019.

\bibitem[Wei et~al.(2023)Wei, Haghtalab, and Steinhardt]{wei2023jailbroken}
Alexander Wei, Nika Haghtalab, and Jacob Steinhardt.
\newblock Jailbroken: How does {LLM} safety training fail?
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing
  Systems}, 2023.
\newblock URL \url{https://openreview.net/forum?id=jA235JGM09}.

\bibitem[Wu et~al.(2020)Wu, Belinkov, Sajjad, Durrani, Dalvi, and
  Glass]{wu2020similarity}
John Wu, Yonatan Belinkov, Hassan Sajjad, Nadir Durrani, Fahim Dalvi, and James
  Glass.
\newblock Similarity analysis of contextual word representation models.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 4638--4655, 2020.

\bibitem[Zeng et~al.(2024)Zeng, Lin, Zhang, Yang, Jia, and
  Shi]{zeng2024persuasion}
Yi~Zeng, Hongpeng Lin, Jingwen Zhang, Diyi Yang, Ruoxi Jia, and Weiyan Shi.
\newblock How {Johnny} can persuade {LLMs} to jailbreak them: Rethinking
  persuasion to challenge {AI} safety by humanizing {LLMs}.
\newblock \emph{arXiv preprint arXiv:2401.06373}, 2024.

\bibitem[Zhou et~al.(2022)Zhou, Ethayarajh, Card, and
  Jurafsky]{zhou2022problems}
Kaitlyn Zhou, Kawin Ethayarajh, Dallas Card, and Dan Jurafsky.
\newblock Problems with cosine as a measure of embedding similarity for high
  frequency words.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association
  for Computational Linguistics (Volume 2: Short Papers)}, pages 401--423,
  2022.

\bibitem[Zou et~al.(2023{\natexlab{a}})Zou, Phan, Chen, Campbell, Guo, Ren,
  Pan, Yin, Mazeika, Dombrowski, et~al.]{zou2023representation}
Andy Zou, Long Phan, Sarah Chen, James Campbell, Phillip Guo, Richard Ren,
  Alexander Pan, Xuwang Yin, Mantas Mazeika, Ann-Kathrin Dombrowski, et~al.
\newblock Representation engineering: A top-down approach to {AI} transparency.
\newblock \emph{arXiv preprint arXiv:2310.01405}, 2023{\natexlab{a}}.

\bibitem[Zou et~al.(2023{\natexlab{b}})Zou, Wang, Kolter, and
  Fredrikson]{zou2023universal}
Andy Zou, Zifan Wang, J~Zico Kolter, and Matt Fredrikson.
\newblock Universal and transferable adversarial attacks on aligned language
  models.
\newblock \emph{arXiv preprint arXiv:2307.15043}, 2023{\natexlab{b}}.

\end{thebibliography}
