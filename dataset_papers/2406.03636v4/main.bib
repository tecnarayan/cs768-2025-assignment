@inproceedings{barrett2010smt,
  title={The smt-lib standard: Version 2.0},
  author={Barrett, Clark and Stump, Aaron and Tinelli, Cesare and others},
  booktitle={Proceedings of the 8th international workshop on satisfiability modulo theories (Edinburgh, UK)},
  volume={13},
  pages={14},
  year={2010}
}

@inproceedings{elmaaroufi-colm24,
  author       = {Karim Elmaaroufi and
                  Devan Shanker and
                  Ana Cismaru and
                  Marcell Vazquez{-}Chanlatte and
                  Alberto L. Sangiovanni{-}Vincentelli and
                  Matei Zaharia and
                  Sanjit A. Seshia},
  title        = {{ScenicNL:} Generating Probabilistic Scenario Programs from Natural Language},  
  booktitle = {Conference on Language Models (COLM)},
  OPTpages        = {331--351},
  year         = {2024},
  abstract  = {For cyber-physical systems (CPS), including robotics and autonomous vehicles, mass deployment has been hindered by fatal errors that occur
when operating in rare events. To replicate rare events such as vehicle crashes, many companies have created logging systems and employed
crash reconstruction experts to meticulously recreate these valuable events in simulation. However, in these methods, â€what ifâ€ questions are not
easily formulated and answered. We present ScenarioNL, an AI System for creating scenario programs from natural language. Specifically, we gen-
erate these programs from police crash reports. Reports normally contain uncertainty about the exact details of the incidents which we represent
through a Probabilistic Programming Language (PPL), Scenic. By using Scenic, we can clearly and concisely represent uncertainty and variation
over CPS behaviors, properties, and interactions. We demonstrate how commonplace prompting techniques with the best Large Language Models
(LLM) are incapable of reasoning about probabilistic scenario programs and generating code for low-resource languages such as Scenic. Our sys-
tem is comprised of several LLMs chained together with several kinds of prompting strategies, a compiler, and a simulator. We evaluate our system
on publicly available autonomous vehicle crash reports in California from the last five years and share insights into how we generate code that is both
semantically meaningful and syntactically correct},
}

@article{fremont2023scenic,
  title={Scenic: A language for scenario specification and data generation},
  author={Fremont, Daniel J and Kim, Edward and Dreossi, Tommaso and Ghosh, Shromona and Yue, Xiangyu and Sangiovanni-Vincentelli, Alberto L and Seshia, Sanjit A},
  journal={Machine Learning},
  volume={112},
  number={10},
  pages={3805--3849},
  year={2023},
  publisher={Springer}
}


@misc{peng2024humanevalxlmultilingualcodegeneration,
      title={HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization}, 
      author={Qiwei Peng and Yekun Chai and Xuhong Li},
      year={2024},
      eprint={2402.16694},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.16694}, 
}

@misc{li2023starcodersourceyou,
      title={StarCoder: may the source be with you!}, 
      author={Raymond Li and Loubna Ben Allal and Yangtian Zi and Niklas Muennighoff and Denis Kocetkov and Chenghao Mou and Marc Marone and Christopher Akiki and Jia Li and Jenny Chim and Qian Liu and Evgenii Zheltonozhskii and Terry Yue Zhuo and Thomas Wang and Olivier Dehaene and Mishig Davaadorj and Joel Lamy-Poirier and João Monteiro and others},
      year={2023},
      eprint={2305.06161},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.06161}, 
}

@misc{geminiteam2024geminifamilyhighlycapable,
      title={Gemini: A Family of Highly Capable Multimodal Models}, 
      author={Gemini Team and Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M. Dai and Anja Hauth and Katie Millican and David Silver and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and others},
      year={2024},
      eprint={2312.11805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.11805}, 
}

@misc{chen2021evaluatinglargelanguagemodels,
      title={Evaluating Large Language Models Trained on Code}, 
      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and others},
      year={2021},
      eprint={2107.03374},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2107.03374}, 
}

@incollection{barrett-smtbookch21,
  author    = "Clark Barrett and Roberto Sebastiani and Sanjit A. Seshia and Cesare Tinelli",
  title     = "Satisfiability Modulo Theories",
  booktitle = "Handbook of Satisfiability",
  publisher = "IOS Press",
  edition = "Second",
  chapter   = 33,
  pages = "1267--1329",
  editor    = "Armin Biere and Marijn Heule and Hans van Maaren and Toby Walsh",
  year      = 2021
}

@article{MyersCACM2004,
    author = {Myers, Brad A. and Pane, John F. and Ko, Amy J.},
    title = {Natural programming languages and environments},
    year = {2004},
    issue_date = {September 2004},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {47},
    number = {9},
    issn = {0001-0782},
    url = {https://doi.org/10.1145/1015864.1015888},
    doi = {10.1145/1015864.1015888},
    journal = {Commun. ACM},
    month = {sep},
    pages = {47–52},
    numpages = {6}
}

@article{ChasinsCACM2021,
    author = {Chasins, Sarah E. and Glassman, Elena L. and Sunshine, Joshua},
    title = {{PL} and {HCI}: better together},
    year = {2021},
    issue_date = {August 2021},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {64},
    number = {8},
    issn = {0001-0782},
    url = {https://doi.org/10.1145/3469279},
    doi = {10.1145/3469279},
    journal = {Commun. ACM},
    month = {jul},
    pages = {98–106},
    numpages = {9}
}

@inbook{HopperHOPL1978,
    author = {Hopper, Gracy Murray},
    title = {Keynote address},
    year = {1978},
    isbn = {0127450408},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/800025.1198341},
    booktitle = {History of Programming Languages},
    pages = {7–20},
    numpages = {14}
}
@article{deepseek-coder,
  title={DeepSeek-Coder: When the Large Language Model Meets Programming--The Rise of Code Intelligence},
  author={Guo, Daya and Zhu, Qihao and Yang, Dejian and Xie, Zhenda and Dong, Kai and Zhang, Wentao and Chen, Guanting and Bi, Xiao and Wu, Y and Li, YK and others},
  journal={arXiv preprint arXiv:2401.14196},
  year={2024}
}
@article{livecodebench,
  title={LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code},
  author={Jain, Naman and Han, King and Gu, Alex and Li, Wen-Ding and Yan, Fanjia and Zhang, Tianjun and Wang, Sida and Solar-Lezama, Armando and Sen, Koushik and Stoica, Ion},
  journal={arXiv preprint arXiv:2403.07974},
  year={2024}
}
@article{picard,
  title={PICARD: Parsing incrementally for constrained auto-regressive decoding from language models},
  author={Scholak, Torsten and Schucher, Nathan and Bahdanau, Dzmitry},
  journal={arXiv preprint arXiv:2109.05093},
  year={2021}
}
@inproceedings{selfrepair,
  title={Is Self-Repair a Silver Bullet for Code Generation?},
  author={Olausson, Theo X and Inala, Jeevana Priya and Wang, Chenglong and Gao, Jianfeng and Solar-Lezama, Armando},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{fsedafny,
author = {Misu, Md Rakib Hossain and Lopes, Cristina V. and Ma, Iris and Noble, James},
title = {Towards AI-Assisted Synthesis of Verified Dafny Methods},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643763},
doi = {10.1145/3643763},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {37},
numpages = {24},
keywords = {Dafny, LLM, Program Synthesis, Program Verification}
}

@inproceedings{z3,
  title={Z3: An efficient SMT solver},
  author={De Moura, Leonardo and Bj{\o}rner, Nikolaj},
  booktitle={International conference on Tools and Algorithms for the Construction and Analysis of Systems},
  pages={337--340},
  year={2008},
  organization={Springer}
}
@inproceedings{z3opt,
  title={$\nu$z-an optimizing SMT solver},
  author={Bj{\o}rner, Nikolaj and Phan, Anh-Dung and Fleckenstein, Lars},
  booktitle={Tools and Algorithms for the Construction and Analysis of Systems: 21st International Conference, TACAS 2015, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2015, London, UK, April 11-18, 2015, Proceedings 21},
  pages={194--199},
  year={2015},
  organization={Springer}
}
@article{selfdebug,
  title={Teaching large language models to self-debug},
  author={Chen, Xinyun and Lin, Maxwell and Sch{\"a}rli, Nathanael and Zhou, Denny},
  journal={arXiv preprint arXiv:2304.05128},
  year={2023}
}
@article{reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{melcer2024constrained,
  title={Constrained Decoding for Code Language Models via Efficient Left and Right Quotienting of Context-Sensitive Grammars},
  author={Melcer, Daniel and Fulton, Nathan and Gouda, Sanjay Krishna and Qian, Haifeng},
  journal={arXiv preprint arXiv:2402.17988},
  year={2024}
}
@inproceedings{constraineddecoding,
    title = "Grammar-Constrained Decoding for Structured {NLP} Tasks without Finetuning",
    author = "Geng, Saibo  and
      Josifoski, Martin  and
      Peyrard, Maxime  and
      West, Robert",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.674",
    doi = "10.18653/v1/2023.emnlp-main.674",
    pages = "10932--10952",
    abstract = "Despite their impressive performance, large language models (LMs) still struggle with reliably generating complex output structures when not finetuned to follow the required output format exactly. To address this issue, grammar-constrained decoding (GCD) can be used to control the generation of LMs, guaranteeing that the output follows a given structure. Most existing GCD methods are, however, limited to specific tasks, such as parsing or code generation. In this work, we demonstrate that formal grammars can describe the output space for a much wider range of tasks and argue that GCD can serve as a unified framework for structured NLP tasks in general. For increased flexibility, we introduce input-dependent grammars, which allow the grammar to depend on the input and thus enable the generation of different output structures for different inputs. We then empirically demonstrate the power and flexibility of GCD-enhanced LMs on (1) information extraction, (2) entity disambiguation, and (3) constituency parsing. Our results indicate that grammar-constrained LMs substantially outperform unconstrained LMs or even beat task-specific finetuned models. Grammar constraints thus hold great promise for harnessing off-the-shelf LMs for a wide range of structured NLP tasks, especially where training data is scarce or finetuning is expensive. Code and data: https://github.com/epfl-dlab/GCD.",
}
@article{gpt4,
  title={GPT-4 technical report},
  author={OpenAI, R},
  journal={ArXiv},
  volume={2303},
  year={2023}
}

@misc{openai2024gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and and others},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv}
} 

@article{mbpp,
  title={Program synthesis with large language models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021}
}
@article{codellama,
  title={Code llama: Open foundation models for code},
  author={Roziere, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and others},
  journal={arXiv preprint arXiv:2308.12950},
  year={2023}
}

@inbook{McCarthyHOPL1978,
    author = {McCarthy, John},
    title = {History of LISP},
    year = {1978},
    isbn = {0127450408},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/800025.1198360},
    booktitle = {History of Programming Languages},
    pages = {173–185},
    numpages = {13}
}

@book{Glaser2017Routledge,
  title={Discovery of grounded theory: Strategies for qualitative research},
  author={Glaser, Barney and Strauss, Anselm},
  year={2017},
  publisher={Routledge}
}

@article{CassanoArxiv2023,
  title={Knowledge Transfer from High-Resource to Low-Resource Programming Languages for Code LLMs},
  author={Cassano, Federico and Gouwar, John and Lucchetti, Francesca and Schlesinger, Claire and Anderson, Carolyn Jane and Greenberg, Michael and Jangda, Abhinav and Guha, Arjun},
  journal={arXiv preprint arXiv:2308.09895},
  year={2023}
}

@inproceedings{chen2022transferability,
  title={On the transferability of pre-trained language models for low-resource programming languages},
  author={Chen, Fuxiang and Fard, Fatemeh H and Lo, David and Bryksin, Timofey},
  booktitle={Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension},
  pages={401--412},
  year={2022}
}

@Book{leeseshia-16,
  author = 	 {Edward A. Lee and Sanjit A. Seshia},
  title = 	 {Introduction to Embedded Systems: A Cyber-Physical Systems Approach},
  publisher = 	 {MIT Press},
  url = 	 {http://leeseshia.org},
  year = 	 {2016},
  OPTkey = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTaddress = 	 {},
  edition = 	 {Second Edition}
}


@inproceedings{uclid5,
  author       = {Elizabeth Polgreen and
                  Kevin Cheang and
                  Pranav Gaddamadugu and
                  Adwait Godbole and
                  Kevin Laeufer and
                  Shaokai Lin and
                  Yatin A. Manerkar and
                  Federico Mora and
                  Sanjit A. Seshia},
  title        = {{UCLID5:} Multi-modal Formal Modeling, Verification, and Synthesis},
  booktitle    = {{CAV} {(1)}},
  series       = {Lecture Notes in Computer Science},
  volume       = {13371},
  pages        = {538--551},
  publisher    = {Springer},
  year         = {2022}
}
@inproceedings{uclid52,
  author       = {Sanjit A. Seshia and
                  Pramod Subramanyan},
  title        = {{UCLID5:} Integrating Modeling, Verification, Synthesis and Learning},
  booktitle    = {{MEMOCODE}},
  pages        = {1--10},
  publisher    = {{IEEE}},
  year         = {2018}
}
@book{baierkatoen,
  author       = {Christel Baier and
                  Joost{-}Pieter Katoen},
  title        = {Principles of model checking},
  publisher    = {{MIT} Press},
  year         = {2008}
}
@inproceedings{leeseshia,
  author       = {Edward A. Lee and
                  Sanjit A. Seshia},
  title        = {An introductory textbook on cyber-physical systems},
  booktitle    = {{WESE}},
  pages        = {1},
  publisher    = {{ACM}},
  year         = {2010}
}


@book{huthryan,
  author       = {Michael Huth and
                  Mark Dermot Ryan},
  title        = {Logic in computer science - modelling and reasoning about systems
                  {(2.} ed.)},
  publisher    = {Cambridge University Press},
  year         = {2004}
}

@article{ZvonimirOOPSLA2014,
    author = {Pavlinovic, Zvonimir and King, Tim and Wies, Thomas},
    title = {Finding minimum type error sources},
    year = {2014},
    issue_date = {October 2014},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {49},
    number = {10},
    issn = {0362-1340},
    url = {https://doi.org/10.1145/2714064.2660230},
    doi = {10.1145/2714064.2660230},
    journal = {SIGPLAN Not.},
    month = {oct},
    pages = {525–542},
    numpages = {18},
    keywords = {type errors, satisfiability modulo theories, diagnostics}
}

@article{WangNeurIPS2024,
  title={Grammar prompting for domain-specific language generation with large language models},
  author={Wang, Bailin and Wang, Zi and Wang, Xuezhi and Cao, Yuan and A Saurous, Rif and Kim, Yoon},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{
    AgrawalNeurIPS2023,
    title={Monitor-Guided Decoding of Code {LM}s with Static Analysis of Repository Context},
    author={Lakshya Agrawal and Aditya Kanade and Navin Goyal and Shuvendu K Lahiri and Sriram Rajamani},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
    url={https://openreview.net/forum?id=qPUbKxKvXq}
}


@article{TarassowArxiv2023,
  title={The potential of LLMs for coding with low-resource and domain-specific programming languages},
  author={Tarassow, Artur},
  journal={arXiv preprint arXiv:2307.13018},
  year={2023}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@inproceedings{leino2010dafny,
  title={Dafny: An automatic program verifier for functional correctness},
  author={Leino, K Rustan M},
  booktitle={International conference on logic for programming artificial intelligence and reasoning},
  pages={348--370},
  year={2010},
  organization={Springer}
}


@incollection{papadimitriou2003computational,
  title={Computational complexity},
  author={Papadimitriou, Christos H},
  booktitle={Encyclopedia of computer science},
  pages={260--265},
  year={2003}
}

@article{damas1984type,
  title={Type assignment in programming languages},
  author={Damas, Luis},
  journal={KB thesis scanning project 2015},
  year={1984},
  publisher={The University of Edinburgh}
}

@article{Poesia2022SynchromeshRC,
  title={Synchromesh: Reliable code generation from pre-trained language models},
  author={Gabriel Poesia and Oleksandr Polozov and Vu Le and Ashish Tiwari and Gustavo Soares and Christopher Meek and Sumit Gulwani},
  journal={ArXiv},
  year={2022},
  volume={abs/2201.11227},
  url={https://api.semanticscholar.org/CorpusID:246294475}
}

@misc{bogin2023leveraging,
  title = {Leveraging Code to Improve In-context Learning for Semantic Parsing},
  author = {Bogin, Ben and Gupta, Shivanshu and Clark, Peter and Sabharwal, Ashish},
  year = {2023},
  eprint = {2311.09519},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}

@inproceedings{akhundov2021verification,
  title={Verification by Gambling on Program Slices},
  author={Akhundov, Murad and Mora, Federico and Feng, Nick and Hui, Vincent and Chechik, Marsha},
  booktitle={Automated Technology for Verification and Analysis: 19th International Symposium, ATVA 2021, Gold Coast, QLD, Australia, October 18--22, 2021, Proceedings 19},
  pages={266--282},
  year={2021},
  organization={Springer}
}


@inproceedings{10.1145/2884781.2884833,
    author = {Stol, Klaas-Jan and Ralph, Paul and Fitzgerald, Brian},
    title = {Grounded theory in software engineering research: a critical review and guidelines},
    year = {2016},
    isbn = {9781450339001},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2884781.2884833},
    doi = {10.1145/2884781.2884833},
    abstract = {Grounded Theory (GT) has proved an extremely useful research approach in several fields including medical sociology, nursing, education and management theory. However, GT is a complex method based on an inductive paradigm that is fundamentally different from the traditional hypothetico-deductive research model. As there are at least three variants of GT, some ostensibly GT research suffers from method slurring, where researchers adopt an arbitrary subset of GT practices that are not recognizable as GT. In this paper, we describe the variants of GT and identify the core set of GT practices. We then analyze the use of grounded theory in software engineering. We carefully and systematically selected 98 articles that mention GT, of which 52 explicitly claim to use GT, with the other 46 using GT techniques only. Only 16 articles provide detailed accounts of their research procedures. We offer guidelines to improve the quality of both conducting and reporting GT studies. The latter is an important extension since current GT guidelines in software engineering do not cover the reporting process, despite good reporting being necessary for evaluating a study and informing subsequent research.},
    booktitle = {Proceedings of the 38th International Conference on Software Engineering},
    pages = {120–131},
    numpages = {12},
    keywords = {grounded theory, guidelines, review, software engineering},
    location = {Austin, Texas},
    series = {ICSE '16}
}

@article{10.1145/3586030,
author = {Barke, Shraddha and James, Michael B. and Polikarpova, Nadia},
title = {Grounded Copilot: How Programmers Interact with Code-Generating Models},
year = {2023},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3586030},
doi = {10.1145/3586030},
abstract = {Powered by recent advances in code-generating models, AI assistants like Github Copilot promise to change the face of programming forever. But what is this new face of programming? We present the first grounded theory analysis of how programmers interact with Copilot, based on observing 20 participants—with a range of prior experience using the assistant—as they solve diverse programming tasks across four languages. Our main finding is that interactions with programming assistants are bimodal: in acceleration mode, the programmer knows what to do next and uses Copilot to get there faster; in exploration mode, the programmer is unsure how to proceed and uses Copilot to explore their options. Based on our theory, we provide recommendations for improving the usability of future AI programming assistants.},
journal = {Proc. ACM Program. Lang.},
month = apr,
articleno = {78},
numpages = {27},
keywords = {Program Synthesis, Grounded Theory, AI Assistants}
}


@inproceedings{wang-etal-2023-self-instruct,
    title = "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
    author = "Wang, Yizhong  and
      Kordi, Yeganeh  and
      Mishra, Swaroop  and
      Liu, Alisa  and
      Smith, Noah A.  and
      Khashabi, Daniel  and
      Hajishirzi, Hannaneh",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.754",
    doi = "10.18653/v1/2023.acl-long.754",
    pages = "13484--13508",
}


@inproceedings{10.5555/3600270.3602070,
author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
title = {Chain-of-thought prompting elicits reasoning in large language models},
year = {2024},
isbn = {9781713871088},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We explore how generating a chain of thought—a series of intermediate reasoning steps—significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain-of-thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting.Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
booktitle = {Proceedings of the 36th International Conference on Neural Information Processing Systems},
articleno = {1800},
numpages = {14},
location = {New Orleans, LA, USA},
series = {NIPS '22}
}

@misc{bhatia2024verifiedcodetranspilationllms,
      title={Verified Code Transpilation with LLMs}, 
      author={Sahil Bhatia and Jie Qiu and Niranjan Hasabnis and Sanjit A. Seshia and Alvin Cheung},
      year={2024},
      eprint={2406.03003},
      archivePrefix={arXiv},
      primaryClass={cs.PL},
      url={https://arxiv.org/abs/2406.03003}, 
}