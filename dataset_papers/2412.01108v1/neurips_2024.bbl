\begin{thebibliography}{10}

\bibitem{Romero2009ExploringPF}
Philip~A. Romero and Frances~H. Arnold.
\newblock Exploring protein fitness landscapes by directed evolution.
\newblock {\em Nature Reviews Molecular Cell Biology}, 10:866--876, 2009.

\bibitem{Notin2024MachineLF}
Pascal Notin, Nathan~J. Rollins, Yarin Gal, Chris Sander, and Debora Marks.
\newblock Machine learning for functional protein design.
\newblock {\em Nature Biotechnology}, 42:216--228, 2024.

\bibitem{biswas2021low}
Surojit Biswas, Grigory Khimulya, Ethan~C Alley, Kevin~M Esvelt, and George~M Church.
\newblock Low-n protein engineering with data-efficient deep learning.
\newblock {\em Nature methods}, 18(4):389--396, 2021.

\bibitem{hopf2017mutation}
Thomas~A Hopf, John~B Ingraham, Frank~J Poelwijk, Charlotta~PI Sch{\"a}rfe, Michael Springer, Chris Sander, and Debora~S Marks.
\newblock Mutation effects predicted from sequence co-variation.
\newblock {\em Nature biotechnology}, 35(2):128--135, 2017.

\bibitem{meier2021language}
Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu, and Alex Rives.
\newblock Language models enable zero-shot prediction of the effects of mutations on protein function.
\newblock {\em Advances in neural information processing systems}, 34:29287--29303, 2021.

\bibitem{riesselman2018deep}
Adam~J Riesselman, John~B Ingraham, and Debora~S Marks.
\newblock Deep generative models of genetic variation capture the effects of mutations.
\newblock {\em Nature methods}, 15(10):816--822, 2018.

\bibitem{frazer2021disease}
Jonathan Frazer, Pascal Notin, Mafalda Dias, Aidan Gomez, Joseph~K Min, Kelly Brock, Yarin Gal, and Debora~S Marks.
\newblock Disease variant prediction with deep generative models of evolutionary data.
\newblock {\em Nature}, 599(7883):91--95, 2021.

\bibitem{laine2019gemme}
Elodie Laine, Yasaman Karami, and Alessandra Carbone.
\newblock Gemme: a simple and fast global epistatic model predicting mutational effects.
\newblock {\em Molecular biology and evolution}, 36(11):2604--2619, 2019.

\bibitem{shin2021protein}
Jung-Eun Shin, Adam~J Riesselman, Aaron~W Kollasch, Conor McMahon, Elana Simon, Chris Sander, Aashish Manglik, Andrew~C Kruse, and Debora~S Marks.
\newblock Protein design and variant prediction using autoregressive generative models.
\newblock {\em Nature communications}, 12(1):2403, 2021.

\bibitem{alley2019unified}
Ethan~C Alley, Grigory Khimulya, Surojit Biswas, Mohammed AlQuraishi, and George~M Church.
\newblock Unified rational protein engineering with sequence-based deep representation learning.
\newblock {\em Nature methods}, 16(12):1315--1322, 2019.

\bibitem{rives2021biological}
Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C~Lawrence Zitnick, Jerry Ma, et~al.
\newblock Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences.
\newblock {\em Proceedings of the National Academy of Sciences}, 118(15), 2021.

\bibitem{Madani2020ProGenLM}
Ali Madani, Bryan McCann, Nikhil~Vijay Naik, Nitish~Shirish Keskar, Namrata Anand, Raphael~R. Eguchi, Po-Ssu Huang, and Richard Socher.
\newblock Progen: Language modeling for protein generation.
\newblock {\em bioRxiv}, 2020.

\bibitem{rao2021msa}
Roshan~M Rao, Jason Liu, Robert Verkuil, Joshua Meier, John Canny, Pieter Abbeel, Tom Sercu, and Alexander Rives.
\newblock Msa transformer.
\newblock In {\em Proceedings of the 38th International Conference on Machine Learning}, volume 139 of {\em Proceedings of Machine Learning Research}, pages 8844--8856. PMLR, 18--24 Jul 2021.

\bibitem{notin2022tranception}
Pascal Notin, Mafalda Dias, Jonathan Frazer, Javier~Marchena Hurtado, Aidan~N Gomez, Debora Marks, and Yarin Gal.
\newblock Tranception: protein fitness prediction with autoregressive transformers and inference-time retrieval.
\newblock In {\em International Conference on Machine Learning}, pages 16990--17017. PMLR, 2022.

\bibitem{notin2022trancepteve}
Pascal Notin, Lood Van~Niekerk, Aaron~W Kollasch, Daniel Ritter, Yarin Gal, and Debora~S Marks.
\newblock Trancepteve: Combining family-specific and family-agnostic models of protein sequences for improved fitness prediction.
\newblock {\em bioRxiv}, pages 2022--12, 2022.

\bibitem{Morcos2011DirectcouplingAO}
Faruck Morcos, Andrea Pagnani, Bryan Lunt, Arianna Bertolino, Debora~S. Marks, Chris Sander, Riccardo Zecchina, Jos{\'e}~Nelson Onuchic, Terence Hwa, and Martin Weigt.
\newblock Direct-coupling analysis of residue coevolution captures native contacts across many protein families.
\newblock {\em Proceedings of the National Academy of Sciences}, 108:E1293 -- E1301, 2011.

\bibitem{Ingraham2019GenerativeMF}
John Ingraham, Vikas~K. Garg, Regina Barzilay, and T.~Jaakkola.
\newblock Generative models for graph-based protein design.
\newblock In {\em DGS@ICLR}, 2019.

\bibitem{Baumann1989PolarityAA}
G~Baumann, Cornelius Fr{\"o}mmel, and Chris Sander.
\newblock Polarity as a criterion in protein design.
\newblock {\em Protein engineering}, 2 5:329--34, 1989.

\bibitem{jing2021equivariant}
Bowen Jing, Stephan Eismann, Pratham~N. Soni, and Ron~O. Dror.
\newblock Learning from protein structure with geometric vector perceptrons.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{zhang2022protein}
Zuobai Zhang, Minghao Xu, Arian Jamasb, Vijil Chenthamarakshan, Aurelie Lozano, Payel Das, and Jian Tang.
\newblock Protein representation learning by geometric structure pretraining.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2023.

\bibitem{hsu2022learning}
Chloe Hsu, Robert Verkuil, Jason Liu, Zeming Lin, Brian Hie, Tom Sercu, Adam Lerer, and Alexander Rives.
\newblock Learning inverse folding from millions of predicted structures.
\newblock In {\em International conference on machine learning}, pages 8946--8970. PMLR, 2022.

\bibitem{dauparas2022robust}
Justas Dauparas, Ivan Anishchenko, Nathaniel Bennett, Hua Bai, Robert~J Ragotte, Lukas~F Milles, Basile~IM Wicky, Alexis Courbet, Rob~J de~Haas, Neville Bethel, et~al.
\newblock Robust deep learning--based protein sequence design using proteinmpnn.
\newblock {\em Science}, 378(6615):49--56, 2022.

\bibitem{yang2023masked}
Kevin~K Yang, Niccol{\`o} Zanichelli, and Hugh Yeh.
\newblock Masked inverse folding with sequence transfer for protein representation learning.
\newblock {\em Protein Engineering, Design and Selection}, 36:gzad015, 2023.

\bibitem{paul2023combining}
Steffanie Paul, Aaron Kollasch, Pascal Notin, and Debora Marks.
\newblock Combining structure and sequence for superior fitness prediction.
\newblock In {\em NeurIPS 2023 Generative AI and Biology (GenBio) Workshop}, 2023.

\bibitem{Cagiada2024PredictingAP}
Matteo Cagiada, Sergey Ovchinnikov, and Kresten Lindorff-Larsen.
\newblock Predicting absolute protein folding stability using generative models.
\newblock {\em bioRxiv}, 2024.

\bibitem{su2024saprot}
Jin Su, Chenchen Han, Yuyang Zhou, Junjie Shan, Xibin Zhou, and Fajie Yuan.
\newblock Saprot: Protein language modeling with structure-aware vocabulary.
\newblock In {\em The Twelfth International Conference on Learning Representations}, 2024.

\bibitem{tan2023semantical}
Yang Tan, Bingxin Zhou, Lirong Zheng, Guisheng Fan, and Liang Hong.
\newblock Semantical and topological protein encoding toward enhanced bioactivity and thermostability.
\newblock {\em bioRxiv}, pages 2023--12, 2023.

\bibitem{cheng2023accurate}
Jun Cheng, Guido Novati, Joshua Pan, Clare Bycroft, Akvil{\.e} {\v{Z}}emgulyt{\.e}, Taylor Applebaum, Alexander Pritzel, Lai~Hong Wong, Michal Zielinski, Tobias Sargeant, et~al.
\newblock Accurate proteome-wide missense variant effect prediction with alphamissense.
\newblock {\em Science}, 381(6664):eadg7492, 2023.

\bibitem{gainza2020deciphering}
Pablo Gainza, Freyr Sverrisson, Frederico Monti, Emanuele Rodola, D~Boscaini, Michael~M Bronstein, and Bruno~E Correia.
\newblock Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning.
\newblock {\em Nature Methods}, 17(2):184--192, 2020.

\bibitem{dawson2017cath}
Natalie~L Dawson, Tony~E Lewis, Sayoni Das, Jonathan~G Lees, David Lee, Paul Ashford, Christine~A Orengo, and Ian Sillitoe.
\newblock Cath: an expanded resource to predict protein function through structure and sequence.
\newblock {\em Nucleic acids research}, 45(D1):D289--D295, 2017.

\bibitem{notin2023proteingym}
Pascal Notin, Aaron Kollasch, Daniel Ritter, Lood Van~Niekerk, Steffanie Paul, Han Spinner, Nathan Rollins, Ada Shaw, Rose Orenbuch, Ruben Weitzman, et~al.
\newblock Proteingym: large-scale benchmarks for protein fitness prediction and design.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2023.

\bibitem{lin2023evolutionary}
Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Nikita Smetanin, Robert Verkuil, Ori Kabeli, Yaniv Shmueli, et~al.
\newblock Evolutionary-scale prediction of atomic-level protein structure with a language model.
\newblock {\em Science}, 379(6637):1123--1130, 2023.

\bibitem{somnath2021multi}
Vignesh~Ram Somnath, Charlotte Bunne, and Andreas Krause.
\newblock Multi-scale representation learning on proteins.
\newblock {\em Advances in Neural Information Processing Systems}, 34:25244--25255, 2021.

\bibitem{tape2019}
Roshan Rao, Nicholas Bhattacharya, Neil Thomas, Yan Duan, Xi~Chen, John Canny, Pieter Abbeel, and Yun~S Song.
\newblock Evaluating protein transfer learning with tape.
\newblock In {\em Advances in Neural Information Processing Systems}, 2019.

\bibitem{elnaggar2020prottrans}
Ahmed Elnaggar, Michael Heinzinger, Christian Dallago, Ghalia Rehawi, Wang Yu, Llion Jones, Tom Gibbs, Tamas Feher, Christoph Angerer, Martin Steinegger, Debsindhu Bhowmik, and Burkhard Rost.
\newblock Prottrans: Towards cracking the language of lifes code through self-supervised deep learning and high performance computing.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, pages 1--1, 2021.

\bibitem{gligorijevic2021structure}
Vladimir Gligorijevi{\'c}, P~Douglas Renfrew, Tomasz Kosciolek, Julia~Koehler Leman, Daniel Berenberg, Tommi Vatanen, Chris Chandler, Bryn~C Taylor, Ian~M Fisk, Hera Vlamakis, et~al.
\newblock Structure-based protein function prediction using graph convolutional networks.
\newblock {\em Nature communications}, 12(1):1--14, 2021.

\bibitem{hermosilla2020intrinsic}
Pedro Hermosilla, Marco Sch{\"a}fer, Mat{\v{e}}j Lang, Gloria Fackelmann, Pere~Pau V{\'a}zquez, Barbora Kozl{\'\i}kov{\'a}, Michael Krone, Tobias Ritschel, and Timo Ropinski.
\newblock Intrinsic-extrinsic convolution and pooling for learning on 3d protein structures.
\newblock {\em International Conference on Learning Representations}, 2021.

\bibitem{chen2022structure}
Can~(Sam) Chen, Jingbo Zhou, Fan Wang, Xue Liu, and Dejing Dou.
\newblock Structure-aware protein self-supervised learning.
\newblock {\em Bioinformatics}, 39, 2022.

\bibitem{zhang2023physics}
Zuobai Zhang, Minghao Xu, Aurelie Lozano, Vijil Chenthamarakshan, Payel Das, and Jian Tang.
\newblock Pre-training protein encoder via siamese sequence-structure diffusion trajectory prediction.
\newblock In {\em Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem{sverrisson2021fast}
Freyr Sverrisson, Jean Feydy, Bruno~E Correia, and Michael~M Bronstein.
\newblock Fast end-to-end learning on protein surfaces.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 15272--15281, 2021.

\bibitem{mallet2023atomsurf}
Vincent Mallet, Souhaib Attaiki, and Maks Ovsjanikov.
\newblock Atomsurf: Surface representation for learning on protein structures.
\newblock {\em arXiv preprint arXiv:2309.16519}, 2023.

\bibitem{wang2022lm}
Zichen Wang, Steven~A Combs, Ryan Brand, Miguel~Romero Calvo, Panpan Xu, George Price, Nataliya Golovach, Emmanuel~O Salawu, Colby~J Wise, Sri~Priya Ponnapalli, et~al.
\newblock Lm-gvp: an extensible sequence and structure informed deep learning framework for protein property prediction.
\newblock {\em Scientific reports}, 12(1):6832, 2022.

\bibitem{zhang2023enhancing}
Zuobai Zhang, Chuanrui Wang, Minghao Xu, Vijil Chenthamarakshan, Aurelie Lozano, Payel Das, and Jian Tang.
\newblock A systematic study of joint representation learning on protein sequences and structures.
\newblock {\em arXiv preprint arXiv:2303.06275}, 2023.

\bibitem{lee2024pretraining}
Youhan Lee, Hasun Yu, Jaemyung Lee, and Jaehoon Kim.
\newblock Pre-training sequence, structure, and surface features for comprehensive protein representation learning.
\newblock In {\em The Twelfth International Conference on Learning Representations}, 2024.

\bibitem{wu2023integration}
Fang Wu, Lirong Wu, Dragomir Radev, Jinbo Xu, and Stan~Z Li.
\newblock Integration of pre-trained protein language models into geometric deep learning networks.
\newblock {\em Communications Biology}, 6(1):876, 2023.

\bibitem{yang2019machine}
Kevin~K Yang, Zachary Wu, and Frances~H Arnold.
\newblock Machine-learning-guided directed evolution for protein engineering.
\newblock {\em Nature methods}, 16(8):687--694, 2019.

\bibitem{gelman2021neural}
Sam Gelman, Sarah~A Fahlberg, Pete Heinzelman, Philip~A Romero, and Anthony Gitter.
\newblock Neural networks to learn protein sequence--function relationships from deep mutational scanning data.
\newblock {\em Proceedings of the National Academy of Sciences}, 118(48):e2104878118, 2021.

\bibitem{dallago2021flip}
Christian Dallago, Jody Mou, Kadina~E Johnston, Bruce~J Wittmann, Nicholas Bhattacharya, Samuel Goldman, Ali Madani, and Kevin~K Yang.
\newblock Flip: Benchmark tasks in fitness landscape inference for proteins.
\newblock {\em bioRxiv}, pages 2021--11, 2021.

\bibitem{notin2023proteinnpt}
Pascal Notin, Ruben Weitzman, Debora Marks, and Yarin Gal.
\newblock Proteinnpt: improving protein property prediction and design with non-parametric transformers.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2023.

\bibitem{nijkamp2023progen2}
Erik Nijkamp, Jeffrey~A Ruffolo, Eli~N Weinstein, Nikhil Naik, and Ali Madani.
\newblock Progen2: exploring the boundaries of protein language models.
\newblock {\em Cell systems}, 14(11):968--978, 2023.

\bibitem{yang2024convolutions}
Kevin~K Yang, Nicolo Fusi, and Alex~X Lu.
\newblock Convolutions are competitive with transformers for protein sequence pretraining.
\newblock {\em Cell Systems}, 15(3):286--294, 2024.

\bibitem{truong2023poet}
Timothy Truong~Jr and Tristan Bepler.
\newblock Poet: A generative model of protein families as sequences-of-sequences.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2023.

\bibitem{van2024fast}
Michel Van~Kempen, Stephanie~S Kim, Charlotte Tumescheit, Milot Mirdita, Jeongjae Lee, Cameron~LM Gilchrist, Johannes S{\"o}ding, and Martin Steinegger.
\newblock Fast and accurate protein structure search with foldseek.
\newblock {\em Nature Biotechnology}, 42(2):243--246, 2024.

\bibitem{fowler2014deep}
Douglas~M Fowler and Stanley Fields.
\newblock Deep mutational scanning: a new style of protein science.
\newblock {\em Nature methods}, 11(8):801--807, 2014.

\bibitem{rasmussen2010gaussian}
Carl~Edward Rasmussen and Hannes Nickisch.
\newblock Gaussian processes for machine learning (gpml) toolbox.
\newblock {\em The Journal of Machine Learning Research}, 11:3011--3015, 2010.

\bibitem{cao2019efficient}
Yueqi Cao, Didong Li, Huafei Sun, Amir~H Assadi, and Shiqiang Zhang.
\newblock Efficient curvature estimation for oriented point clouds.
\newblock {\em stat}, 1050:26, 2019.

\bibitem{sun2009concise}
Jian Sun, Maks Ovsjanikov, and Leonidas Guibas.
\newblock A concise and provably informative multi-scale signature based on heat diffusion.
\newblock In {\em Computer graphics forum}, volume~28, pages 1383--1392. Wiley Online Library, 2009.

\bibitem{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock {\em arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{boucher2016quantifying}
Jeffrey~I Boucher, Daniel~NA Bolon, and Dan~S Tawfik.
\newblock Quantifying and understanding the fitness effects of protein mutations: Laboratory versus nature.
\newblock {\em Protein Science}, 25(7):1219--1226, 2016.

\bibitem{olson_comprehensive_2014}
C.~Anders Olson, Nicholas~C. Wu, and Ren Sun.
\newblock A comprehensive biophysical description of pairwise epistasis throughout an entire protein domain.
\newblock {\em Current Biology}, 24(22):2643--2651, November 2014.

\end{thebibliography}
