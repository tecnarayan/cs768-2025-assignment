\begin{thebibliography}{49}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anderson(1982)]{anderson1982reverse}
Anderson, B.~D.
\newblock Reverse-time diffusion equation models.
\newblock \emph{Stochastic Processes and their Applications}, 12\penalty0
  (3):\penalty0 313--326, 1982.

\bibitem[Bansal et~al.(2022)Bansal, Borgnia, Chu, Li, Kazemi, Huang, Goldblum,
  Geiping, and Goldstein]{bansal2022cold}
Bansal, A., Borgnia, E., Chu, H.-M., Li, J.~S., Kazemi, H., Huang, F.,
  Goldblum, M., Geiping, J., and Goldstein, T.
\newblock Cold diffusion: Inverting arbitrary image transforms without noise.
\newblock \emph{arXiv preprint arXiv:2208.09392}, 2022.

\bibitem[Blau \& Michaeli(2018)Blau and Michaeli]{blau2018perception}
Blau, Y. and Michaeli, T.
\newblock The perception-distortion tradeoff.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  6228--6237, 2018.

\bibitem[Chan et~al.(2016)Chan, Wang, and Elgendy]{chan2016plug}
Chan, S.~H., Wang, X., and Elgendy, O.~A.
\newblock Plug-and-play admm for image restoration: Fixed-point convergence and
  applications.
\newblock \emph{IEEE Transactions on Computational Imaging}, 3\penalty0
  (1):\penalty0 84--98, 2016.

\bibitem[Chung \& Ye(2022)Chung and Ye]{chung2022score}
Chung, H. and Ye, J.~C.
\newblock Score-based diffusion models for accelerated mri.
\newblock \emph{Medical Image Analysis}, 80:\penalty0 102479, 2022.

\bibitem[Chung et~al.(2022{\natexlab{a}})Chung, Kim, Mccann, Klasky, and
  Ye]{chung2022diffusion}
Chung, H., Kim, J., Mccann, M.~T., Klasky, M.~L., and Ye, J.~C.
\newblock Diffusion posterior sampling for general noisy inverse problems.
\newblock \emph{arXiv preprint arXiv:2209.14687}, 2022{\natexlab{a}}.

\bibitem[Chung et~al.(2022{\natexlab{b}})Chung, Sim, Ryu, and
  Ye]{chung2022improving}
Chung, H., Sim, B., Ryu, D., and Ye, J.~C.
\newblock Improving diffusion models for inverse problems using manifold
  constraints.
\newblock \emph{arXiv preprint arXiv:2206.00941}, 2022{\natexlab{b}}.

\bibitem[Chung et~al.(2022{\natexlab{c}})Chung, Sim, and Ye]{chung2022come}
Chung, H., Sim, B., and Ye, J.~C.
\newblock Come-closer-diffuse-faster: Accelerating conditional diffusion models
  for inverse problems through stochastic contraction.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  12413--12422, 2022{\natexlab{c}}.

\bibitem[Daras et~al.(2022)Daras, Delbracio, Talebi, Dimakis, and
  Milanfar]{daras2022soft}
Daras, G., Delbracio, M., Talebi, H., Dimakis, A.~G., and Milanfar, P.
\newblock Soft diffusion: Score matching for general corruptions.
\newblock \emph{arXiv preprint arXiv:2209.05442}, 2022.

\bibitem[Deasy et~al.(2021)Deasy, Simidjievski, and Li{\`o}]{deasy2021heavy}
Deasy, J., Simidjievski, N., and Li{\`o}, P.
\newblock Heavy-tailed denoising score matching.
\newblock \emph{arXiv preprint arXiv:2112.09788}, 2021.

\bibitem[Delbracio \& Milanfar(2023)Delbracio and
  Milanfar]{delbracio2023inversion}
Delbracio, M. and Milanfar, P.
\newblock Inversion by direct iteration: An alternative to denoising diffusion
  for image restoration.
\newblock \emph{arXiv preprint arXiv:2303.11435}, 2023.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pp.\  248--255. Ieee, 2009.

\bibitem[Dhariwal \& Nichol(2021)Dhariwal and Nichol]{dhariwal_diffusion_2021}
Dhariwal, P. and Nichol, A.
\newblock Diffusion {Models} {Beat} {GANs} on {Image} {Synthesis}.
\newblock \emph{arXiv preprint arXiv:2105.05233}, 2021.

\bibitem[Heitz et~al.(2023)Heitz, Belcour, and Chambon]{heitz2023iterative}
Heitz, E., Belcour, L., and Chambon, T.
\newblock Iterative $\alpha$ -(de)blending: a minimalist deterministic
  diffusion model.
\newblock \emph{arXiv preprint arXiv:2305.03486}, 2023.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and
  Hochreiter]{heusel2017gans}
Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and Hochreiter, S.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho_denoising_2020}
Ho, J., Jain, A., and Abbeel, P.
\newblock Denoising {Diffusion} {Probabilistic} {Models}.
\newblock \emph{arXiv preprint arXiv:2006.11239}, 2020.

\bibitem[Ho et~al.(2022)Ho, Salimans, Gritsenko, Chan, Norouzi, and
  Fleet]{ho2022video}
Ho, J., Salimans, T., Gritsenko, A., Chan, W., Norouzi, M., and Fleet, D.~J.
\newblock Video diffusion models.
\newblock \emph{arXiv preprint arXiv:2204.03458}, 2022.

\bibitem[Hoogeboom \& Salimans(2022)Hoogeboom and
  Salimans]{hoogeboom2022blurring}
Hoogeboom, E. and Salimans, T.
\newblock Blurring diffusion models.
\newblock \emph{arXiv preprint arXiv:2209.05557}, 2022.

\bibitem[Jalal et~al.(2021)Jalal, Arvinte, Daras, Price, Dimakis, and
  Tamir]{jalal2021robust}
Jalal, A., Arvinte, M., Daras, G., Price, E., Dimakis, A.~G., and Tamir, J.
\newblock Robust compressed sensing mri with deep generative priors.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 14938--14954, 2021.

\bibitem[Kadkhodaie \& Simoncelli(2021)Kadkhodaie and
  Simoncelli]{kadkhodaie2021stochastic}
Kadkhodaie, Z. and Simoncelli, E.
\newblock Stochastic solutions for linear inverse problems using the prior
  implicit in a denoiser.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 13242--13254, 2021.

\bibitem[Karras et~al.(2018)Karras, Aila, Laine, and
  Lehtinen]{karras_progressive_2018}
Karras, T., Aila, T., Laine, S., and Lehtinen, J.
\newblock Progressive {Growing} of {GANs} for {Improved} {Quality},
  {Stability}, and {Variation}.
\newblock \emph{arXiv:1710.10196 [cs, stat]}, 2018.

\bibitem[Karras et~al.(2019)Karras, Laine, and Aila]{karras2019style}
Karras, T., Laine, S., and Aila, T.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  4401--4410, 2019.

\bibitem[Kawar et~al.(2021)Kawar, Vaksman, and Elad]{kawar2021snips}
Kawar, B., Vaksman, G., and Elad, M.
\newblock Snips: Solving noisy inverse problems stochastically.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 21757--21769, 2021.

\bibitem[Kawar et~al.(2022{\natexlab{a}})Kawar, Elad, Ermon, and
  Song]{kawar2022denoising}
Kawar, B., Elad, M., Ermon, S., and Song, J.
\newblock Denoising diffusion restoration models.
\newblock \emph{arXiv preprint arXiv:2201.11793}, 2022{\natexlab{a}}.

\bibitem[Kawar et~al.(2022{\natexlab{b}})Kawar, Song, Ermon, and
  Elad]{kawar2022jpeg}
Kawar, B., Song, J., Ermon, S., and Elad, M.
\newblock Jpeg artifact correction using denoising diffusion restoration
  models.
\newblock \emph{arXiv preprint arXiv:2209.11888}, 2022{\natexlab{b}}.

\bibitem[Kong et~al.(2020)Kong, Ping, Huang, Zhao, and
  Catanzaro]{kong2020diffwave}
Kong, Z., Ping, W., Huang, J., Zhao, K., and Catanzaro, B.
\newblock Diffwave: A versatile diffusion model for audio synthesis.
\newblock \emph{arXiv preprint arXiv:2009.09761}, 2020.

\bibitem[Lee et~al.(2022)Lee, Chung, Kim, and Ye]{lee2022progressive}
Lee, S., Chung, H., Kim, J., and Ye, J.~C.
\newblock Progressive deblurring of diffusion models for coarse-to-fine image
  synthesis.
\newblock \emph{arXiv preprint arXiv:2207.11192}, 2022.

\bibitem[Liang et~al.(2021)Liang, Cao, Sun, Zhang, Van~Gool, and
  Timofte]{liang_swinir_2021}
Liang, J., Cao, J., Sun, G., Zhang, K., Van~Gool, L., and Timofte, R.
\newblock {SwinIR}: {Image} {restoration} {using} {Swin} {Transformer}.
\newblock \emph{arXiv:2108.10257}, 2021.

\bibitem[Liu et~al.(2023)Liu, Vahdat, Huang, Theodorou, Nie, and
  Anandkumar]{liu20232}
Liu, G.-H., Vahdat, A., Huang, D.-A., Theodorou, E.~A., Nie, W., and
  Anandkumar, A.
\newblock {I} $^2${I} {SB}: Image-to-image schrodinger bridge.
\newblock \emph{arXiv preprint arXiv:2302.05872}, 2023.

\bibitem[Nachmani et~al.(2021)Nachmani, Roman, and Wolf]{nachmani2021denoising}
Nachmani, E., Roman, R.~S., and Wolf, L.
\newblock Denoising diffusion gamma models.
\newblock \emph{arXiv preprint arXiv:2110.05948}, 2021.

\bibitem[Okhotin et~al.(2023)Okhotin, Molchanov, Arkhipkin, Bartosh, Alanov,
  and Vetrov]{okhotin2023star}
Okhotin, A., Molchanov, D., Arkhipkin, V., Bartosh, G., Alanov, A., and Vetrov,
  D.
\newblock Star-shaped denoising diffusion probabilistic models.
\newblock \emph{arXiv preprint arXiv:2302.05259}, 2023.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and
  Chen]{ramesh2022hierarchical}
Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., and Chen, M.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 2022.

\bibitem[Rissanen et~al.(2022)Rissanen, Heinonen, and
  Solin]{rissanen2022generative}
Rissanen, S., Heinonen, M., and Solin, A.
\newblock Generative modelling with inverse heat dissipation.
\newblock \emph{arXiv preprint arXiv:2206.13397}, 2022.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and
  Ommer]{rombach2022high}
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  10684--10695, 2022.

\bibitem[Saharia et~al.(2021)Saharia, Ho, Chan, Salimans, Fleet, and
  Norouzi]{saharia_image_2021}
Saharia, C., Ho, J., Chan, W., Salimans, T., Fleet, D.~J., and Norouzi, M.
\newblock Image {Super}-{Resolution} via {Iterative} {Refinement}.
\newblock \emph{arXiv:2104.07636 [cs, eess]}, 2021.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton,
  Ghasemipour, Ayan, Mahdavi, Lopes, et~al.]{saharia2022photorealistic}
Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E., Ghasemipour,
  S. K.~S., Ayan, B.~K., Mahdavi, S.~S., Lopes, R.~G., et~al.
\newblock Photorealistic text-to-image diffusion models with deep language
  understanding.
\newblock \emph{arXiv preprint arXiv:2205.11487}, 2022.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and
  Ganguli]{sohl2015deep}
Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2256--2265. PMLR, 2015.

\bibitem[Song et~al.(2023{\natexlab{a}})Song, Kwon, Zhang, Hu, Qu, and
  Shen]{song2023solving}
Song, B., Kwon, S.~M., Zhang, Z., Hu, X., Qu, Q., and Shen, L.
\newblock Solving inverse problems with latent diffusion models via hard data
  consistency.
\newblock \emph{arXiv preprint arXiv:2307.08123}, 2023{\natexlab{a}}.

\bibitem[Song et~al.(2021{\natexlab{a}})Song, Meng, and
  Ermon]{song2021denoising}
Song, J., Meng, C., and Ermon, S.
\newblock Denoising diffusion implicit models.
\newblock In \emph{International Conference on Learning Representations},
  2021{\natexlab{a}}.
\newblock URL \url{https://openreview.net/forum?id=St1giarCHLP}.

\bibitem[Song et~al.(2023{\natexlab{b}})Song, Vahdat, Mardani, and
  Kautz]{songpseudoinverse}
Song, J., Vahdat, A., Mardani, M., and Kautz, J.
\newblock Pseudoinverse-guided diffusion models for inverse problems.
\newblock In \emph{International Conference on Learning Representations},
  2023{\natexlab{b}}.

\bibitem[Song \& Ermon(2020{\natexlab{a}})Song and Ermon]{song_generative_2020}
Song, Y. and Ermon, S.
\newblock Generative {Modeling} by {Estimating} {Gradients} of the {Data}
  {Distribution}.
\newblock \emph{arXiv:1907.05600 [cs, stat]}, 2020{\natexlab{a}}.

\bibitem[Song \& Ermon(2020{\natexlab{b}})Song and Ermon]{song_improved_2020}
Song, Y. and Ermon, S.
\newblock Improved {Techniques} for {Training} {Score}-{Based} {Generative}
  {Models}.
\newblock \emph{arXiv:2006.09011 [cs, stat]}, 2020{\natexlab{b}}.

\bibitem[Song et~al.(2020)Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and
  Poole]{song2020score}
Song, Y., Sohl-Dickstein, J., Kingma, D.~P., Kumar, A., Ermon, S., and Poole,
  B.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock \emph{arXiv preprint arXiv:2011.13456}, 2020.

\bibitem[Song et~al.(2021{\natexlab{b}})Song, Shen, Xing, and
  Ermon]{song2021solving}
Song, Y., Shen, L., Xing, L., and Ermon, S.
\newblock Solving inverse problems in medical imaging with score-based
  generative models.
\newblock \emph{arXiv preprint arXiv:2111.08005}, 2021{\natexlab{b}}.

\bibitem[Vincent(2011)]{vincent2011connection}
Vincent, P.
\newblock A connection between score matching and denoising autoencoders.
\newblock \emph{Neural computation}, 23\penalty0 (7):\penalty0 1661--1674,
  2011.

\bibitem[Welker et~al.(2022)Welker, Chapman, and Gerkmann]{welker2022driftrec}
Welker, S., Chapman, H.~N., and Gerkmann, T.
\newblock Driftrec: Adapting diffusion models to blind image restoration tasks.
\newblock \emph{arXiv preprint arXiv:2211.06757}, 2022.

\bibitem[Whang et~al.(2022)Whang, Delbracio, Talebi, Saharia, Dimakis, and
  Milanfar]{whang2022deblurring}
Whang, J., Delbracio, M., Talebi, H., Saharia, C., Dimakis, A.~G., and
  Milanfar, P.
\newblock Deblurring via stochastic refinement.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  16293--16303, 2022.

\bibitem[Yue et~al.(2024)Yue, Wang, and Loy]{yue2024resshift}
Yue, Z., Wang, J., and Loy, C.~C.
\newblock Resshift: Efficient diffusion model for image super-resolution by
  residual shifting.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Zhang et~al.(2018)Zhang, Isola, Efros, Shechtman, and
  Wang]{zhang2018unreasonable}
Zhang, R., Isola, P., Efros, A.~A., Shechtman, E., and Wang, O.
\newblock The unreasonable effectiveness of deep features as a perceptual
  metric.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  586--595, 2018.

\end{thebibliography}
