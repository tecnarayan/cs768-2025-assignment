\begin{thebibliography}{10}

\bibitem{alqahtani_applications_2021}
Hamed Alqahtani, Manolya Kavakli-Thorne, and Gulshan Kumar.
\newblock Applications of {Generative} {Adversarial} {Networks} ({GANs}): {An}
  {Updated} {Review}.
\newblock {\em Archives of Computational Methods in Engineering},
  28(2):525--552, March 2021.

\bibitem{arjovsky2017principled}
Martin Arjovsky and Léon Bottou.
\newblock Towards principled methods for training generative adversarial
  networks, 2017.

\bibitem{arjovsky2017wasserstein}
Martin Arjovsky, Soumith Chintala, and L{\'e}on Bottou.
\newblock Wasserstein generative adversarial networks.
\newblock In {\em International conference on machine learning}, pages
  214--223. PMLR, 2017.

\bibitem{balaji2021understanding}
Yogesh Balaji, Mohammadmahdi Sajedi, Neha~Mukund Kalibhat, Mucong Ding, Dominik
  Stöger, Mahdi Soltanolkotabi, and Soheil Feizi.
\newblock Understanding overparameterization in generative adversarial
  networks, 2021.

\bibitem{bietti_inductive_2019}
Alberto Bietti and Julien Mairal.
\newblock On the {Inductive} {Bias} of {Neural} {Tangent} {Kernels}.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d' Alché-Buc,
  E.~Fox, and R.~Garnett, editors, {\em Advances in {Neural} {Information}
  {Processing} {Systems}}, volume~32. Curran Associates, Inc., 2019.

\bibitem{binkowski2018demystifying}
Miko{\l}aj Bi{\'n}kowski, Danica~J Sutherland, Michael Arbel, and Arthur
  Gretton.
\newblock {Demystifying MMD GANs}.
\newblock {\em arXiv preprint arXiv:1801.01401}, 2018.

\bibitem{bonneel2011displacement}
Nicolas Bonneel, Michiel Van De~Panne, Sylvain Paris, and Wolfgang Heidrich.
\newblock Displacement interpolation using lagrangian mass transport.
\newblock In {\em Proceedings of the 2011 SIGGRAPH Asia conference}, pages
  1--12, 2011.

\bibitem{Borji2021GANeval}
Ali Borji.
\newblock Pros and cons of {GAN} evaluation measures: New developments.
\newblock {\em CoRR}, abs/2103.09396, 2021.

\bibitem{franceschi2021neural}
Jean-Yves Franceschi, Emmanuel de~Bézenac, Ibrahim Ayed, Mickaël Chen,
  Sylvain Lamprier, and Patrick Gallinari.
\newblock A neural tangent kernel perspective of gans, 2021.

\bibitem{goodfellow2016nips}
Ian Goodfellow.
\newblock Nips 2016 tutorial: Generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1701.00160}, 2016.

\bibitem{goodfellow2014generative}
Ian~J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David
  Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial networks, 2014.

\bibitem{gretton2012kernel}
Arthur Gretton, Karsten~M Borgwardt, Malte~J Rasch, Bernhard Sch{\"o}lkopf, and
  Alexander Smola.
\newblock A kernel two-sample test.
\newblock {\em The Journal of Machine Learning Research}, 13(1):723--773, 2012.

\bibitem{gulrajani2017improved}
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron
  Courville.
\newblock Improved training of wasserstein gans.
\newblock {\em arXiv preprint arXiv:1704.00028}, 2017.

\bibitem{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{jacot2018neural}
Arthur Jacot, Franck Gabriel, and Cl{\'e}ment Hongler.
\newblock Neural tangent kernel: Convergence and generalization in neural
  networks.
\newblock In {\em Advances in neural information processing systems}, pages
  8571--8580, 2018.

\bibitem{khrulkov2021functional}
Valentin Khrulkov, Artem Babenko, and Ivan Oseledets.
\newblock Functional space analysis of local gan convergence.
\newblock In {\em International Conference on Machine Learning}, pages
  5432--5442. PMLR, 2021.

\bibitem{Kodali2017dragan}
Naveen Kodali, Jacob~D. Abernethy, James Hays, and Zsolt Kira.
\newblock How to train your {DRAGAN}.
\newblock {\em CoRR}, abs/1705.07215, 2017.

\bibitem{li2017mmd}
Chun-Liang Li, Wei-Cheng Chang, Yu~Cheng, Yiming Yang, and Barnab{\'a}s
  P{\'o}czos.
\newblock {MMD GAN: Towards deeper understanding of moment matching network}.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{mescheder2018training}
Lars Mescheder, Andreas Geiger, and Sebastian Nowozin.
\newblock Which training methods for gans do actually converge?, 2018.

\bibitem{mescheder2017numerics}
Lars Mescheder, Sebastian Nowozin, and Andreas Geiger.
\newblock The numerics of gans.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{mroueh2021convergence}
Youssef Mroueh and Truyen Nguyen.
\newblock On the convergence of gradient descent in gans: Mmd gan as a gradient
  flow.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 1720--1728. PMLR, 2021.

\bibitem{nagarajan2018gradient}
Vaishnavh Nagarajan and J.~Zico Kolter.
\newblock Gradient descent gan optimization is locally stable, 2018.

\bibitem{nie2020towards}
Weili Nie and Ankit~B Patel.
\newblock Towards a better understanding and regularization of gan training
  dynamics.
\newblock In {\em Uncertainty in Artificial Intelligence}, pages 281--291.
  PMLR, 2020.

\bibitem{Rahimi2007RFF}
Ali Rahimi and Benjamin Recht.
\newblock Random features for large-scale kernel machines.
\newblock In J.~Platt, D.~Koller, Y.~Singer, and S.~Roweis, editors, {\em
  Advances in Neural Information Processing Systems}, volume~20. Curran
  Associates, Inc., 2007.

\bibitem{Richardson2018NDB}
Eitan Richardson and Yair Weiss.
\newblock On gans and gmms.
\newblock {\em CoRR}, abs/1805.12462, 2018.

\bibitem{thanh2020forgetting}
Hoang Thanh{-}Tung, Truyen Tran, and Svetha Venkatesh.
\newblock On catastrophic forgetting and mode collapse in generative
  adversarial networks.
\newblock {\em CoRR}, abs/1807.04015, 2018.

\bibitem{unterthiner2017coulomb}
Thomas Unterthiner, Bernhard Nessler, Calvin Seward, G{\"u}nter Klambauer,
  Martin Heusel, Hubert Ramsauer, and Sepp Hochreiter.
\newblock {Coulomb GANs: Provably optimal Nash equilibria via potential
  fields}.
\newblock {\em arXiv preprint arXiv:1708.08819}, 2017.

\bibitem{vidyasagar2002nonlinear}
Mathukumalli Vidyasagar.
\newblock {\em Nonlinear systems analysis}, volume~42.
\newblock Siam, 2002.

\bibitem{wang2021survey}
Zhengwei Wang, Qi~She, and Tomás Ward.
\newblock Generative adversarial networks in computer vision: A survey and
  taxonomy.
\newblock {\em ACM Computing Surveys}, 54:1--38, 02 2021.

\bibitem{xu2019understanding}
Kun Xu, Chongxuan Li, Jun Zhu, and Bo~Zhang.
\newblock Understanding and stabilizing gans' training dynamics with control
  theory.
\newblock {\em arXiv preprint arXiv:1909.13188}, 2019.

\end{thebibliography}
