@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{sohn2015learning,
  title={Learning structured output representation using deep conditional generative models},
  author={Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3483--3491},
  year={2015}
}

@article{rezende2014stochastic,
  title={Stochastic backpropagation and approximate inference in deep generative models},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  journal={arXiv preprint arXiv:1401.4082},
  year={2014}
}

@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@incollection{gordon1995stable,
  title={Stable function approximation in dynamic programming},
  author={Gordon, Geoffrey J},
  booktitle={Machine Learning Proceedings 1995},
  pages={261--268},
  year={1995},
  publisher={Elsevier}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@inproceedings{riedmiller2005neural,
  title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
  author={Riedmiller, Martin},
  booktitle={European Conference on Machine Learning},
  pages={317--328},
  year={2005},
  organization={Springer}
}

@inproceedings{evans2016learning,
  title={Learning the Preferences of Ignorant, Inconsistent Agents.},
  author={Evans, Owain},
  year={2016},
  booktitle={AAAI},
  pages={323--329},
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={International Conference on Machine Learning},
  volume={2},
  pages={267-274},
  year={2002}
}

@inproceedings{achiam2017constrained,
  title={Constrained Policy Optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={22--31},
  year={2017}
}

@article{pham2018constrained,
  title={Constrained Exploration and Recovery from Experience Shaping},
  author={Pham, Tu-Hoa and De Magistris, Giovanni and Agravante, Don Joven and Chaudhury, Subhajit and Munawar, Asim and Tachibana, Ryuki},
  journal={arXiv preprint arXiv:1809.08925},
  year={2018}
}

@article{silver2018residual,
  title={Residual Policy Learning},
  author={Silver, Tom and Allen, Kelsey and Tenenbaum, Josh and Kaelbling, Leslie},
  journal={arXiv preprint arXiv:1812.06298},
  year={2018}
}

@article{johannink2018residual,
  title={Residual Reinforcement Learning for Robot Control},
  author={Johannink, Tobias and Bahl, Shikhar and Nair, Ashvin and Luo, Jianlan and Kumar, Avinash and Loskyll, Matthias and Ojea, Juan Aparicio and Solowjow, Eugen and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.03201},
  year={2018}
}

@inproceedings{peters2010relative,
  title={Relative Entropy Policy Search.},
  author={Peters, Jan and M{\"u}lling, Katharina},
  year={2010},
  booktitle={AAAI}, 
  pages={1607--1612}
}

@article{van2017non,
  title={Non-parametric policy search with limited information loss},
  author={Van Hoof, Herke and Neumann, Gerhard and Peters, Jan},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={2472--2517},
  year={2017},
}

@inproceedings{dearden1998bayesian,
  title={Bayesian Q-learning},
  author={Dearden, Richard and Friedman, Nir and Russell, Stuart},
  booktitle={AAAI/IAAI},
  pages={761--768},
  year={1998}
}

@article{strehl2008analysis,
  title={An analysis of model-based interval estimation for Markov decision processes},
  author={Strehl, Alexander L and Littman, Michael L},
  journal={Journal of Computer and System Sciences},
  volume={74},
  number={8},
  pages={1309--1331},
  year={2008},
  publisher={Elsevier}
}

@article{azizzadenesheli2018bayesian,
  title={Efficient Exploration through Bayesian Deep Q-Networks},
  author={Azizzadenesheli, Kamyar and Brunskill, Emma and Anandkumar, Animashree},
  journal={arXiv preprint arXiv:1802.04412},
  year={2018}
}

@article{touati2018randomized,
  title={Randomized Value Functions via Multiplicative Normalizing Flows},
  author={Touati, Ahmed and Satija, Harsh and Romoff, Joshua and Pineau, Joelle and Vincent, Pascal},
  journal={arXiv preprint arXiv:1806.02315},
  year={2018}
}

@inproceedings{osband2018randomized,
title = {Randomized Prior Functions for Deep Reinforcement Learning},
author = {Osband, Ian and Aslanides, John and Cassirer, Albin},
booktitle = {Advances in Neural Information Processing Systems 31},
pages = {8626--8638},
year = {2018},
}

@inproceedings{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1471--1479},
  year={2016}
}

@inproceedings{pathak2017curiosity,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  year={2017},
  booktitle={International Conference on Machine Learning},
  volume={2017}
}

@InProceedings{colas2018gep,
  title = 	 {{GEP}-{PG}: Decoupling Exploration and Exploitation in Deep Reinforcement Learning Algorithms},
  author = 	 {Colas, C{\'e}dric and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  booktitle = 	 {International Conference on Machine Learning},
  pages = 	 {1039--1048},
  year = 	 {2018},
  volume = 	 {80},
  publisher = 	 {PMLR},
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={International Conference on Machine Learning},
  pages={465--472},
  year={2011}
}

@inproceedings{gal2016improving,
  title={Improving PILCO with Bayesian neural network dynamics models},
  author={Gal, Yarin and McAllister, Rowan and Rasmussen, Carl Edward},
  year={2016},
  booktitle={Data-Efficient Machine Learning workshop, International Conference on Machine Learning}
}

@article{higuera2018synthesizing,
  title={Synthesizing Neural Network Controllers with Probabilistic Model based Reinforcement Learning},
  author={Higuera, Juan Camilo Gamboa and Meger, David and Dudek, Gregory},
  journal={arXiv preprint arXiv:1803.02291},
  year={2018}
}

@inproceedings{chua2018deep,
title = {Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
author = {Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
booktitle = {Advances in Neural Information Processing Systems 31},
pages = {4759--4770},
year = {2018},
}

@article{xu2018algorithmic,
  title={Algorithmic Framework for Model-based Reinforcement Learning with Theoretical Guarantees},
  author={Xu, Huazhe and Li, Yuanzhi and Tian, Yuandong and Darrell, Trevor and Ma, Tengyu},
  journal={arXiv preprint arXiv:1807.03858},
  year={2018}
}

@inproceedings{buckman2018sample,
  title={Sample-efficient reinforcement learning with stochastic ensemble value expansion},
  author={Buckman, Jacob and Hafner, Danijar and Tucker, George and Brevdo, Eugene and Lee, Honglak},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8234--8244},
  year={2018}
}

@article{imani2018distributional,
  author={Ehsan Imani and Martha White},
  title={Improving Regression Performance with Distributional Losses},
  journal={arXiv preprint arXiv:1806.04613},
  year={2018},
}

@article{huber1964robust,
  title={Robust estimation of a location parameter},
  author={Huber, Peter J and others},
  journal={The annals of mathematical statistics},
  volume={35},
  number={1},
  pages={73--101},
  year={1964},
  publisher={Institute of Mathematical Statistics}
}

@article{koenker2001quantile,
  title={Quantile regression},
  author={Koenker, Roger and Hallock, Kevin F},
  journal={Journal of economic perspectives},
  volume={15},
  number={4},
  pages={143--156},
  year={2001}
}

@inproceedings{bhatnagar2009convergent,
  title={Convergent temporal-difference learning with arbitrary smooth function approximation},
  author={Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S and Maei, Hamid R and Szepesv{\'a}ri, Csaba},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1204--1212},
  year={2009}
}

@article{trask2018neural,
  author={Trask, Andrew and Hill, Felix and Reed, Scott and Rae, Jack and Dyer, Chris and Blunsom, Phil},
  title={Neural Arithmetic Logic Units},
  journal={arXiv preprint arXiv:1808.00508},
  year={2018},
}

@article{daupara2018implicit,
  author={Justas Dauparas and Ryota Tomioka and Katja Hofmann},
  title={Depth and nonlinearity induce implicit exploration for {RL}},
  journal={arXiv preprint arXiv:1805.11711},
  year={2018},
}

@article{zhang2017expreplay,
  title={A Deeper Look at Experience Replay},
  author={Zhang, Shangtong and Sutton, Richard S},
  journal={arXiv preprint arXiv:1712.01275},
  year={2017}
}

@inproceedings{de2015expreplay,
  title={The importance of experience replay database composition in deep reinforcement learning},
  author={de Bruin, Tim and Kober, Jens and Tuyls, Karl and Babu{\v{s}}ka, Robert},
  booktitle={Deep Reinforcement Learning Workshop, NIPS},
  year={2015}
}


@inproceedings{de2016improved,
  title={Improved deep reinforcement learning for robotics through distribution-based experience retention},
  author={de Bruin, Tim and Kober, Jens and Tuyls, Karl and Babu{\v{s}}ka, Robert},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={3947--3952},
  year={2016},
  organization={IEEE}
}

@article{isele2018selective,
  title={Selective Experience Replay for Lifelong Learning},
  author={Isele, David and Cosgun, Akansel},
  journal={arXiv preprint arXiv:1802.10269},
  year={2018}
}

@inproceedings{ziebart2008maximum,
  title={Maximum Entropy Inverse Reinforcement Learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K},
  booktitle={AAAI},
  volume={8},
  pages={1433-1438},
  year={2008}
}

@inproceedings{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4565--4573},
  year={2016}
}

@article{schaal1999imitation,
  title={Is imitation learning the route to humanoid robots?},
  author={Schaal, Stefan},
  journal={Trends in Cognitive Sciences},
  volume={3},
  number={6},
  pages={233--242},
  year={1999},
  publisher={Elsevier}
}

@article{argall2009survey,
  title={A survey of robot learning from demonstration},
  author={Argall, Brenna D and Chernova, Sonia and Veloso, Manuela and Browning, Brett},
  journal={Robotics and Autonomous Systems},
  volume={57},
  number={5},
  pages={469--483},
  year={2009},
  publisher={Elsevier}
}

@article{hussein2017imitation,
  title={Imitation learning: A survey of learning methods},
  author={Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
  journal={ACM Computing Surveys (CSUR)},
  volume={50},
  number={2},
  pages={21},
  year={2017},
  publisher={ACM}
}

@inproceedings{kim2013learning,
  title={Learning from limited demonstrations},
  author={Kim, Beomjoon and Farahmand, Amir-massoud and Pineau, Joelle and Precup, Doina},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2859--2867},
  year={2013}
}

@inproceedings{piot2014boosted,
  title={Boosted bellman residual minimization handling expert demonstrations},
  author={Piot, Bilal and Geist, Matthieu and Pietquin, Olivier},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={549--564},
  year={2014},
  organization={Springer}
}

@inproceedings{chemali2015direct,
  title={Direct Policy Iteration with Demonstrations},
  author={Chemali, Jessica and Lazaric, Alessandro},
  booktitle={Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year={2015},
}

@article{hester2017deep,
  title={Deep Q-learning from Demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Dulac-Arnold, Gabriel and others},
  journal={arXiv preprint arXiv:1704.03732},
  year={2017}
}

@article{vevcerik2017leveraging,
  title={Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards},
  author={Ve{\v{c}}er{\'\i}k, Matej and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@inproceedings{nair2018overcoming,
  title={Overcoming exploration in reinforcement learning with demonstrations},
  author={Nair, Ashvin and McGrew, Bob and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6292--6299},
  year={2018},
  organization={IEEE}
}

@InProceedings{oh2018self,
  title = 	 {Self-Imitation Learning},
  author = 	 {Oh, Junhyuk and Guo, Yijie and Singh, Satinder and Lee, Honglak},
  booktitle = 	 {International Conference on Machine Learning},
  pages = 	 {3878--3887},
  year = 	 {2018},
  volume = 	 {80},
  publisher = 	 {PMLR}
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011}
}

@inproceedings{ho2016model,
  title={Model-free imitation learning with policy optimization},
  author={Ho, Jonathan and Gupta, Jayesh and Ermon, Stefano},
  booktitle={International Conference on Machine Learning},
  pages={2760--2769},
  year={2016}
}

@inproceedings{sun2017deeply,
  title={Deeply AggreVaTeD: Differentiable Imitation Learning for Sequential Prediction},
  author={Sun, Wen and Venkatraman, Arun and Gordon, Geoffrey J and Boots, Byron and Bagnell, J Andrew},
  booktitle={International Conference on Machine Learning},
  pages={3309--3318},
  year={2017}
}

@article{cheng2018fast,
  title={Fast Policy Learning through Imitation and Reinforcement},
  author={Cheng, Ching-An and Yan, Xinyan and Wagener, Nolan and Boots, Byron},
  journal={arXiv preprint arXiv:1805.10413},
  year={2018}
}

@article{sun2018truncated,
  title={Truncated Horizon Policy Search: Combining Reinforcement Learning \& Imitation Learning},
  author={Sun, Wen and Bagnell, J Andrew and Boots, Byron},
  journal={arXiv preprint arXiv:1805.11240},
  year={2018}
}

@article{gao2018imperfect,
  title={Reinforcement learning from imperfect demonstrations},
  author={Gao, Yang and Lin, Ji and Yu, Fisher and Levine, Sergey and Darrell, Trevor},
  journal={arXiv preprint arXiv:1802.05313},
  year={2018}
}

@incollection{mccloskey1989catastrophic,
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  booktitle={Psychology of Learning and Motivation},
  volume={24},
  pages={109--165},
  year={1989},
  publisher={Elsevier}
}

@article{goodfellow2013empirical,
  title={An empirical investigation of catastrophic forgetting in gradient-based neural networks},
  author={Goodfellow, Ian J and Mirza, Mehdi and Xiao, Da and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1312.6211},
  year={2013}
}

@InProceedings{fujimoto2018addressing,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {International Conference on Machine Learning},
  pages = 	 {1587--1596},
  year = 	 {2018},
  volume = 	 {80},
  publisher = 	 {PMLR},
}

@article{konda2003onactor,
  title={On Actor-Critic Algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  journal={SIAM journal on Control and Optimization},
  volume={42},
  number={4},
  pages={1143--1166},
  year={2003},
  publisher={SIAM}
}

@article{espeholt2018impala,
  title={IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  journal={arXiv preprint arXiv:1802.01561},
  year={2018}
}

@inproceedings{mannor2011mean,
  title={Mean-variance optimization in Markov decision processes},
  author={Mannor, Shie and Tsitsiklis, John N},
  booktitle={International Conference on Machine Learning},
  pages={177--184},
  year={2011},
}

@inproceedings{precup2001off,
  title={Off-policy temporal-difference learning with function approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={International Conference on Machine Learning},
  pages={417--424},
  year={2001}
}

@inproceedings{jiang2016doubly,
  title={Doubly Robust Off-policy Value Evaluation for Reinforcement Learning},
  author={Jiang, Nan and Li, Lihong},
  booktitle={International Conference on Machine Learning},
  pages={652--661},
  year={2016}
}

@inproceedings{peshkin2002learning,
  title={Learning from Scarce Experience},
  author={Peshkin, Leonid and Shelton, Christian R},
  booktitle={International Conference on Machine Learning},
  pages={498--505},
  year={2002},
}

@inproceedings{thomas2015high,
  title={High confidence policy improvement},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={2380--2388},
  year={2015}
}

@inproceedings{liu2018representation,
  title={Representation balancing mdps for off-policy policy evaluation},
  author={Liu, Yao and Gottesman, Omer and Raghu, Aniruddh and Komorowski, Matthieu and Faisal, Aldo A and Doshi-Velez, Finale and Brunskill, Emma},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2644--2653},
  year={2018}
}

@inproceedings{hallak2017consistent,
  title={Consistent on-line off-policy evaluation},
  author={Hallak, Assaf and Mannor, Shie},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1372--1383},
  year={2017},
  organization={JMLR. org}
}

@article{gelada2019off,
  title={Off-Policy Deep Reinforcement Learning by Bootstrapping the Covariate Shift},
  author={Gelada, Carles and Bellemare, Marc G},
  journal={arXiv preprint arXiv:1901.09455},
  year={2019}
}

@inproceedings{DoubleDQN,
  title={Deep Reinforcement Learning with Double Q-Learning.},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={AAAI},
  pages={2094--2100},
  year={2016},
}

@article{Smoothie,
  author    = {Ofir Nachum and Mohammad Norouzi and George Tucker and Dale Schuurmans},
  title     = {Smoothed Action Value Functions for Learning Gaussian Policies},
  year      = {2018},
  journal={arXiv preprint arXiv:1803.02348},
}

@InProceedings{UncertaintyBellman,
  title = 	 {The Uncertainty {B}ellman Equation and Exploration},
  author = 	 {O'Donoghue, Brendan and Osband, Ian and Munos, Remi and Mnih, Vlad},
  booktitle = 	 {International Conference on Machine Learning},
  pages = 	 {3839--3848},
  year = 	 {2018},
  volume = 	 {80},
  publisher = 	 {PMLR},
}

@inproceedings{AVGDQN,
  title={Averaged-DQN: Variance Reduction and Stabilization for Deep Reinforcement Learning},
  author={Anschel, Oron and Baram, Nir and Shimkin, Nahum},
  booktitle={International Conference on Machine Learning},
  pages={176--185},
  year={2017}
}

@inproceedings{osband2016deep,
  title={Deep exploration via bootstrapped DQN},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4026--4034},
  year={2016}
}

@article{DQN,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Research}
}

@article{DDPG,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{DPG,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={International Conference on Machine Learning},
  pages={387--395},
  year={2014}
}


@inproceedings{PrioritizedExpReplay,
  address = {Puerto Rico},
  author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  booktitle = {International Conference on Learning Representations},
  title = {Prioritized Experience Replay},
  year = {2016}
}

@inproceedings{bellemare2017distributional,
  title={A Distributional Perspective on Reinforcement Learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={449--458},
  year={2017}
}

@article{dabney2017distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1710.10044},
  year={2017}
}

@article{wang2015dueling,
  title={Dueling Network Architectures for Deep Reinforcement Learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
  booktitle={International Conference on Machine Learning},
  pages={1995--2003},
  year={2016}
}

@article{hessel2017rainbow,
  title={Rainbow: Combining Improvements in Deep Reinforcement Learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  journal={arXiv preprint arXiv:1710.02298},
  year={2017}
}

@inproceedings{a3c,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International Conference on Machine Learning},
  pages={1928--1937},
  year={2016}
}

@article{optimalitytightening,
  title={Learning to play in a day: Faster deep reinforcement learning by optimality tightening},
  author={He, Frank S and Liu, Yang and Schwing, Alexander G and Peng, Jian},
  journal={arXiv preprint arXiv:1611.01606},
  year={2016}
}

@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1054--1062},
  year={2016}
}

@article{ppo,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{acktr,
  title = {Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation},
  author = {Wu, Yuhuai and Mansimov, Elman and Grosse, Roger B and Liao, Shun and Ba, Jimmy},
  booktitle = {Advances in Neural Information Processing Systems},
  pages = {5285--5294},
  year = {2017},
}

@inproceedings{trpo,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015}
}

@article{qprop,
  title={Q-prop: Sample-efficient policy gradient with an off-policy critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.02247},
  year={2016}
}

@article{bellemare2013arcade,
  title={The Arcade Learning Environment: An Evaluation Platform for General Agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@inproceedings{duan2016benchmark,
  title={Benchmarking deep reinforcement learning for continuous control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={1329--1338},
  year={2016}
}

@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}

@misc{OpenAIGym,
    Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
    Title = {OpenAI Gym},
    Year = {2016},
    Eprint = {arXiv:1606.01540},
}

@inproceedings{mujoco,
  title={MuJoCo: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{hendersonRL2017,
   author = {{Henderson}, Peter and {Islam}, Riashat and {Bachman}, Philip and {Pineau}, Joelle and {Precup}, Doina and {Meger}, David},
    title = "{Deep Reinforcement Learning that Matters}",
  journal = {arXiv preprint arXiv:1709.06560},
     year = 2017,
}

@article{alphago,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={Nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Research}
}

@article{expreplay1992,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}

@inproceedings{tdc,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={Sutton, Richard S and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv{\'a}ri, Csaba and Wiewiora, Eric},
  booktitle={International Conference on Machine Learning},
  pages={993--1000},
  year={2009},
  organization={ACM}
}

@inproceedings{lu2018delusional,
  title={Non-delusional Q-learning and value-iteration},
  author={Lu, Tyler and Schuurmans, Dale and Boutilier, Craig},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9971--9981},
  year={2018}
}

@inproceedings{thrun1993bias,
  title={Issues in using function approximation for reinforcement learning},
  author={Thrun, Sebastian and Schwartz, Anton},
  booktitle={Proceedings of the 1993 Connectionist Models Summer School Hillsdale, NJ. Lawrence Erlbaum},
  year={1993}
}

@inproceedings{hasselt2010double,
  title={Double Q-learning},
  author={Van Hasselt, Hado},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2613--2621},
  year={2010}
}

@inproceedings{moreno2006noisy,
  title={Noisy reinforcements in reinforcement learning: some case studies based on gridworlds},
  author={Moreno, Alvaro and Mart{\'\i}n, Jos{\'e} D and Soria, Emilio and Magdalena, Rafael}
}

@book{bellman,
  title={Dynamic Programming},
  author={Bellman, Richard},
  year={1957},
  publisher={Princeton University Press}
}

@phdthesis{watkins1989qlearning,
  title={Learning from delayed rewards},
  author={Watkins, Christopher John Cornish Hellaby},
  year={1989},
  school={King's College, Cambridge}
}

@article{melo2001convergence,
  title={Convergence of Q-learning: A simple proof},
  author={Melo, Francisco S},
  year={2001},
  pages={1--4},
  journal={Institute Of Systems and Robotics, Tech. Rep}
}

@article{dayan1992q,
  title={Q-learning},
  author={Dayan, Peter and Watkins, Christopher John Cornish Hellaby},
  journal={Machine learning},
  volume={8},
  number={3},
  pages={279--292},
  year={1992},
  publisher={Citeseer}
}

@article{sutton1988tdlearning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  volume={3},
  number={1},
  pages={9--44},
  year={1988},
  publisher={Springer}
}

@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={1},
  year={1998},
  publisher={MIT press Cambridge}
}

@article{williams1992reinforce,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@inproceedings{baird1995residual,
  title={Residual algorithms: Reinforcement learning with function approximation},
  author={Baird, Leemon and others},
  booktitle={International Conference on Machine Learning},
  pages={30--37},
  year={1995}
}

@book{pendrith1997estimator,
  title={Estimator variance in reinforcement learning: Theoretical problems and practical solutions},
  author={Pendrith, Mark D and Ryan, Malcolm RK and others},
  year={1997},
  publisher={University of New South Wales, School of Computer Science and Engineering}
}

@inproceedings{fox2015glearning,
  title={Taming the noise in reinforcement learning via soft updates},
  author={Fox, Roy and Pakman, Ari and Tishby, Naftali},
  booktitle={Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
  pages={202--211},
  year={2016},
  organization={AUAI Press}
}

@article{mahmood2017is,
  title={Multi-step Off-policy Learning Without Importance Sampling Ratios},
  author={Mahmood, Ashique Rupam and Yu, Huizhen and Sutton, Richard S},
  journal={arXiv preprint arXiv:1702.03006},
  year={2017}
}

@article{gradientboostingfriedman,
  title={Greedy function approximation: a gradient boosting machine},
  author={Friedman, Jerome H},
  journal={Annals of statistics},
  pages={1189--1232},
  year={2001},
  publisher={JSTOR}
}

@inproceedings{boostingmason,
  title={Boosting algorithms as gradient descent},
  author={Mason, Llew and Baxter, Jonathan and Bartlett, Peter L and Frean, Marcus R},
  booktitle={Advances in neural information processing systems},
  pages={512--518},
  year={2000}
}

@article{abel2016exploratory,
  title={Exploratory gradient boosting for reinforcement learning in complex domains},
  author={Abel, David and Agarwal, Alekh and Diaz, Fernando and Krishnamurthy, Akshay and Schapire, Robert E},
  journal={arXiv preprint arXiv:1603.04119},
  year={2016}
}

@inproceedings{resnetshe,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{popov2017data,
  title={Data-efficient Deep Reinforcement Learning for Dexterous Manipulation},
  author={Popov, Ivaylo and Heess, Nicolas and Lillicrap, Timothy and Hafner, Roland and Barth-Maron, Gabriel and Vecerik, Matej and Lampe, Thomas and Tassa, Yuval and Erez, Tom and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1704.03073},
  year={2017}
}

@article{mannor2007bias,
  title={Bias and variance approximation in value function estimates},
  author={Mannor, Shie and Simester, Duncan and Sun, Peng and Tsitsiklis, John N},
  journal={Management Science},
  volume={53},
  number={2},
  pages={308--322},
  year={2007},
  publisher={INFORMS}
}

@inproceedings{petrik2009discount,
  title={Biasing approximate dynamic programming with a lower discount factor},
  author={Petrik, Marek and Scherrer, Bruno},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1265--1272},
  year={2009}
}

@incollection{NVA,
  title = {Natural Value Approximators: Learning when to Trust Past Estimates},
  author = {Xu, Zhongwen and Modayil, Joseph and van Hasselt, Hado P and Barreto, Andre and Silver, David and Schaul, Tom},
  booktitle = {Advances in Neural Information Processing Systems 30},
  pages = {2117--2125},
  year = {2017},
}

@article{barth-maron2018distributional,
  title={Distributional Policy Gradients},
  author={Gabriel Barth-Maron and Matthew W Hoffman and David Budden and Will Dabney and Dan Horgan and Dhruva TB and Alistair Muldal and Nicolas Heess and Timothy Lillicrap},
  journal={International Conference on Learning Representations},
  year={2018},
}

@article{horgan2018distributed,
  title={Distributed Prioritized Experience Replay},
  author={Dan Horgan and John Quan and David Budden and Gabriel Barth-Maron and Matteo Hessel and Hado van Hasselt and David Silver},
  journal={International Conference on Learning Representations},
  year={2018},
}

@article{ormoneit2002kernel,
  title={Kernel-based reinforcement learning},
  author={Ormoneit, Dirk and Sen, {\'S}aunak},
  journal={Machine learning},
  volume={49},
  number={2-3},
  pages={161--178},
  year={2002},
  publisher={Springer}
}

@inproceedings{lee2013biascor,
  title={Bias-corrected q-learning to control max-operator bias in q-learning},
  author={Lee, Donghun and Defourny, Boris and Powell, Warren B},
  booktitle={Adaptive Dynamic Programming And Reinforcement Learning (ADPRL), 2013 IEEE Symposium on},
  pages={93--99},
  year={2013},
  organization={IEEE}
}

@article{kaelbling1996reinforcement,
  title={Reinforcement learning: A survey},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  journal={Journal of Artificial Intelligence Research},
  volume={4},
  pages={237--285},
  year={1996}
}

@article{lai1985asymptotically,
  title={Asymptotically efficient adaptive allocation rules},
  author={Lai, Tze Leung and Robbins, Herbert},
  journal={Advances in Applied Mathematics},
  volume={6},
  number={1},
  pages={4--22},
  year={1985},
  publisher={Academic Press}
}

@article{jaksch2010near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Apr},
  pages={1563--1600},
  year={2010}
}

@InProceedings{haarnoja2018soft,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author = 	 {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = 	 {International Conference on Machine Learning},
  pages = 	 {1861--1870},
  year = 	 {2018},
  volume = 	 {80},
  publisher = 	 {PMLR},
}

@article{singh2000convergence,
  title={Convergence results for single-step on-policy reinforcement-learning algorithms},
  author={Singh, Satinder and Jaakkola, Tommi and Littman, Michael L and Szepesv{\'a}ri, Csaba},
  journal={Machine learning},
  volume={38},
  number={3},
  pages={287--308},
  year={2000},
  publisher={Springer}
}

@book{bertsekas1995dynamic,
  title={Neuro-Dynamic Programming},
  author={Bertsekas, Dimitri P and John N. Tsitsiklis},
  year={1996},
  publisher={Athena scientific Belmont, MA}
}

@article{uhlenbeck1930theory,
  title={On the theory of the Brownian motion},
  author={Uhlenbeck, George E and Ornstein, Leonard S},
  journal={Physical review},
  volume={36},
  number={5},
  pages={823},
  year={1930},
  publisher={APS}
}

@inproceedings{van2009theoretical,
  title={A theoretical and empirical analysis of Expected Sarsa},
  author={Van Seijen, Harm and Van Hasselt, Hado and Whiteson, Shimon and Wiering, Marco},
  booktitle={Adaptive Dynamic Programming and Reinforcement Learning, 2009. ADPRL'09. IEEE Symposium on},
  pages={177--184},
  year={2009},
  organization={IEEE}
}

@inproceedings{gu2016continuous,
  title={Continuous deep q-learning with model-based acceleration},
  author={Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={2829--2838},
  year={2016}
}

@article{tavakoli2017action,
  title={Action Branching Architectures for Deep Reinforcement Learning},
  author={Tavakoli, Arash and Pardo, Fabio and Kormushev, Petar},
  journal={arXiv preprint arXiv:1711.08946},
  year={2017}
}

@article{metz2017discrete,
  title={Discrete sequential prediction of continuous actions for deep RL},
  author={Metz, Luke and Ibarz, Julian and Jaitly, Navdeep and Davidson, James},
  journal={arXiv preprint arXiv:1705.05035},
  year={2017}
}

@inproceedings{kalashnikov2018scalable,
  title={Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={Conference on Robot Learning},
  pages={651--673},
  year={2018}
}

