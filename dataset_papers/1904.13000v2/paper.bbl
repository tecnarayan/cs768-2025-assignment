\begin{thebibliography}{10}

\bibitem{athalye2018obfuscated}
A.~Athalye, N.~Carlini, and D.~Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2018.

\bibitem{berry1941accuracy}
A.~C. Berry.
\newblock The accuracy of the gaussian approximation to the sum of independent
  variates.
\newblock {\em Transactions of the american mathematical society},
  49(1):122--136, 1941.

\bibitem{brendel2018decision}
W.~Brendel, J.~Rauber, and M.~Bethge.
\newblock Decision-based adversarial attacks: Reliable attacks against
  black-box machine learning models.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{carlini2018prototypical}
N.~Carlini, U.~Erlingsson, and N.~Papernot.
\newblock Prototypical examples in deep learning: Metrics, characteristics, and
  utility.
\newblock 2018.

\bibitem{carlini2016hidden}
N.~Carlini, P.~Mishra, T.~Vaidya, Y.~Zhang, M.~Sherr, C.~Shields, D.~Wagner,
  and W.~Zhou.
\newblock Hidden voice commands.
\newblock In {\em USENIX Security Symposium}, pages 513--530, 2016.

\bibitem{carlini2016towards}
N.~Carlini and D.~Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In {\em IEEE Symposium on Security and Privacy}, 2017.

\bibitem{chen2019boundary}
J.~Chen and M.~I. Jordan.
\newblock Boundary attack++: Query-efficient decision-based adversarial attack.
\newblock {\em arXiv preprint arXiv:1904.02144}, 2019.

\bibitem{chen2018ead}
P.-Y. Chen, Y.~Sharma, H.~Zhang, J.~Yi, and C.-J. Hsieh.
\newblock Ead: elastic-net attacks to deep neural networks via adversarial
  examples.
\newblock In {\em AAAI Conference on Artificial Intelligence}, 2018.

\bibitem{demontis2016security}
A.~Demontis, P.~Russu, B.~Biggio, G.~Fumera, and F.~Roli.
\newblock On security and sparsity of linear classifiers for adversarial
  settings.
\newblock In {\em Joint IAPR International Workshops on Statistical Techniques
  in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition
  (SSPR)}, pages 322--332. Springer, 2016.

\bibitem{duchi2008efficient}
J.~Duchi, S.~Shalev-Shwartz, Y.~Singer, and T.~Chandra.
\newblock Efficient projections onto the l1-ball for learning in high
  dimensions.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2008.

\bibitem{engstrom2017rotation}
L.~Engstrom, B.~Tran, D.~Tsipras, L.~Schmidt, and A.~Madry.
\newblock A rotation and a translation suffice: Fooling {CNNs} with simple
  transformations.
\newblock {\em arXiv preprint arXiv:1712.02779}, 2017.

\bibitem{fawzi2018adversarial}
A.~Fawzi, H.~Fawzi, and O.~Fawzi.
\newblock Adversarial vulnerability for any classifier.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1186--1195, 2018.

\bibitem{geirhos2018imagenet}
R.~Geirhos, P.~Rubisch, C.~Michaelis, M.~Bethge, F.~A. Wichmann, and
  W.~Brendel.
\newblock {ImageNet}-trained {CNNs} are biased towards texture; increasing
  shape bias improves accuracy and robustness.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2019.

\bibitem{gilmer2018adversarial}
J.~Gilmer, L.~Metz, F.~Faghri, S.~S. Schoenholz, M.~Raghu, M.~Wattenberg, and
  I.~Goodfellow.
\newblock Adversarial spheres.
\newblock {\em arXiv preprint arXiv:1801.02774}, 2018.

\bibitem{goodfellow2014explaining}
I.~J. Goodfellow, J.~Shlens, and C.~Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2015.

\bibitem{grosse2016adversarial}
K.~Grosse, N.~Papernot, P.~Manoharan, M.~Backes, and P.~McDaniel.
\newblock Adversarial examples for malware detection.
\newblock In {\em European Symposium on Research in Computer Security}, 2017.

\bibitem{hendrycks2018benchmarking}
D.~Hendrycks and T.~Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2019.

\bibitem{ilyas2019adversarial}
A.~Ilyas, S.~Santurkar, D.~Tsipras, L.~Engstrom, B.~Tran, and A.~Madry.
\newblock Adversarial examples are not bugs, they are features.
\newblock {\em arXiv preprint arXiv:1905.02175}, 2019.

\bibitem{jo2017measuring}
J.~Jo and Y.~Bengio.
\newblock Measuring the tendency of {CNNs} to learn surface statistical
  regularities.
\newblock {\em arXiv preprint arXiv:1711.11561}, 2017.

\bibitem{kang2019transfer}
D.~Kang, Y.~Sun, T.~Brown, D.~Hendrycks, and J.~Steinhardt.
\newblock Transfer of adversarial robustness between perturbation types.
\newblock {\em arXiv preprint arXiv:1905.01034}, 2019.

\bibitem{khoury2019geometry}
M.~Khoury and D.~Hadfield-Menell.
\newblock On the geometry of adversarial examples, 2019.

\bibitem{kurakin2016scale}
A.~Kurakin, I.~Goodfellow, and S.~Bengio.
\newblock Adversarial machine learning at scale.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2017.

\bibitem{li2018second}
B.~Li, C.~Chen, W.~Wang, and L.~Carin.
\newblock Second-order adversarial attack and certifiable robustness.
\newblock {\em arXiv preprint arXiv:1809.03113}, 2018.

\bibitem{madry2018tutorial}
A.~Madry and Z.~Kolter.
\newblock Adversarial robustness: Theory and practice.
\newblock In {\em Tutorial at NeurIPS 2018}, 2018.

\bibitem{madry2018towards}
A.~Madry, A.~Makelov, L.~Schmidt, D.~Tsipras, and A.~Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2018.

\bibitem{mahloujifar2018curse}
S.~Mahloujifar, D.~I. Diochnos, and M.~Mahmoody.
\newblock The curse of concentration in robust learning: Evasion and poisoning
  attacks from concentration of measure.
\newblock {\em arXiv preprint arXiv:1809.03063}, 2018.

\bibitem{papernot2016practical}
N.~Papernot, P.~McDaniel, I.~Goodfellow, S.~Jha, Z.~B. Celik, and A.~Swami.
\newblock Practical black-box attacks against machine learning.
\newblock In {\em ASIACCS}, pages 506--519. ACM, 2017.

\bibitem{raghunathan2018certified}
A.~Raghunathan, J.~Steinhardt, and P.~Liang.
\newblock Certified defenses against adversarial examples.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2018.

\bibitem{ribeiro2016should}
M.~T. Ribeiro, S.~Singh, and C.~Guestrin.
\newblock Why should i trust you?: Explaining the predictions of any
  classifier.
\newblock In {\em KDD}. ACM, 2016.

\bibitem{schmidt2018adversarially}
L.~Schmidt, S.~Santurkar, D.~Tsipras, K.~Talwar, and A.~Madry.
\newblock Adversarially robust generalization requires more data.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  5019--5031, 2018.

\bibitem{schott2018towards}
L.~Schott, J.~Rauber, M.~Bethge, and W.~Brendel.
\newblock Towards the first adversarially robust neural network model on mnist.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2019.

\bibitem{openreview}
L.~Schott, J.~Rauber, M.~Bethge, and W.~Brendel.
\newblock Towards the first adversarially robust neural network model on mnist
  ({OpenReview} comment on spatial transformations), 2019.

\bibitem{shafahi2019adversarial}
A.~Shafahi, W.~R. Huang, C.~Studer, S.~Feizi, and T.~Goldstein.
\newblock Are adversarial examples inevitable?
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2019.

\bibitem{shafahi2019free}
A.~Shafahi, M.~Najibi, A.~Ghiasi, Z.~Xu, J.~Dickerson, C.~Studer, L.~S. Davis,
  G.~Taylor, and T.~Goldstein.
\newblock Adversarial training for free!
\newblock {\em arXiv preprint arXiv:1904.12843}, 2019.

\bibitem{sharma2017attacking}
Y.~Sharma and P.-Y. Chen.
\newblock Attacking the madry defense model with l1-based adversarial examples.
\newblock {\em arXiv preprint arXiv:1710.10733}, 2017.

\bibitem{stock2018convnets}
P.~Stock and M.~Cisse.
\newblock Convnets and imagenet beyond accuracy: Understanding mistakes and
  uncovering biases.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 498--512, 2018.

\bibitem{szegedy2013intriguing}
C.~Szegedy, W.~Zaremba, I.~Sutskever, J.~Bruna, D.~Erhan, I.~Goodfellow, and
  R.~Fergus.
\newblock Intriguing properties of neural networks.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2014.

\bibitem{fullversion}
F.~Tram{\`e}r and D.~Boneh.
\newblock Adversarial training and robustness for multiple perturbations.
\newblock In {\em Neural Information Processing Systems (NeurIPS) 2019}, 2019.
\newblock arXiv preprint arXiv:1904.13000.

\bibitem{tramer2018adblock}
F.~Tram{\`e}r, P.~Dupr{\'e}, G.~Rusak, G.~Pellegrino, and D.~Boneh.
\newblock Ad-versarial: Perceptual ad-blocking meets adversarial machine
  learning.
\newblock arXiv preprint arXiv:1811:03194, Nov 2018.

\bibitem{tramer2018ensemble}
F.~Tram{\`e}r, A.~Kurakin, N.~Papernot, I.~Goodfellow, D.~Boneh, and
  P.~McDaniel.
\newblock Ensemble adversarial training: Attacks and defenses.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2018.

\bibitem{tsipras2019robustness}
D.~Tsipras, S.~Santurkar, L.~Engstrom, A.~Turner, and A.~Madry.
\newblock Robustness may be at odds with accuracy.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2019.

\bibitem{wong2018provable}
E.~Wong and Z.~Kolter.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock In {\em International Conference on Machine Learning}, pages
  5283--5292, 2018.

\bibitem{xu2009robustness}
H.~Xu, C.~Caramanis, and S.~Mannor.
\newblock Robustness and regularization of support vector machines.
\newblock {\em Journal of Machine Learning Research}, 10(Jul):1485--1510, 2009.

\bibitem{zhang2019you}
D.~Zhang, T.~Zhang, Y.~Lu, Z.~Zhu, and B.~Dong.
\newblock You only propagate once: Painless adversarial training using maximal
  principle.
\newblock {\em arXiv preprint arXiv:1905.00877}, 2019.

\end{thebibliography}
