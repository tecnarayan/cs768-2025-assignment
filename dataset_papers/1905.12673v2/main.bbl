\begin{thebibliography}{20}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahmad et~al.(2009)Ahmad, Liu, Javidi, Zhao, and
  Krishnamachari]{ahmad2009optimality}
Sahand Haji~Ali Ahmad, Mingyan Liu, Tara Javidi, Qing Zhao, and Bhaskar
  Krishnamachari.
\newblock Optimality of myopic sensing in multichannel opportunistic access.
\newblock \emph{IEEE Transactions on Information Theory}, 55\penalty0
  (9):\penalty0 4040--4050, 2009.

\bibitem[Cesa-Bianchi and Lugosi(2012)]{cesa2012combinatorial}
Nicolo Cesa-Bianchi and G{\'a}bor Lugosi.
\newblock Combinatorial bandits.
\newblock \emph{Journal of Computer and System Sciences}, 78\penalty0
  (5):\penalty0 1404--1422, 2012.

\bibitem[Dai et~al.(2011)Dai, Gai, Krishnamachari, and Zhao]{dai2011non}
Wenhan Dai, Yi~Gai, Bhaskar Krishnamachari, and Qing Zhao.
\newblock The non-bayesian restless multi-armed bandit: A case of
  near-logarithmic regret.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pages 2940--2943. IEEE, 2011.

\bibitem[Dai et~al.(2014)Dai, Gai, and Krishnamachari]{dai2014online}
Wenhan Dai, Yi~Gai, and Bhaskar Krishnamachari.
\newblock Online learning for multi-channel opportunistic access over unknown
  markovian channels.
\newblock In \emph{IEEE International Conference on Sensing, Communication, and
  Networking (SECON)}, pages 64--71. IEEE, 2014.

\bibitem[Gittins et~al.(1989)Gittins, Glazebrook, Weber, and
  Weber]{gittins1989multi}
John~C Gittins, Kevin~D Glazebrook, Richard Weber, and Richard Weber.
\newblock \emph{Multi-armed bandit allocation indices}, volume~25.
\newblock Wiley Online Library, 1989.

\bibitem[Lattimore and Szepesv{\'a}ri()]{lattimore2018bandit}
Tor Lattimore and Csaba Szepesv{\'a}ri.
\newblock \emph{Bandit algorithms}.
\newblock Cambridge University Press.
\newblock forthcoming.

\bibitem[Liu et~al.(2011)Liu, Liu, and Zhao]{liu2011logarithmic}
Haoyang Liu, Keqin Liu, and Qing Zhao.
\newblock Logarithmic weak regret of non-bayesian restless multi-armed bandit.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pages 1968--1971. IEEE, 2011.

\bibitem[Liu et~al.(2013)Liu, Liu, and Zhao]{liu2013learning}
Haoyang Liu, Keqin Liu, and Qing Zhao.
\newblock Learning in a changing world: Restless multiarmed bandit with unknown
  dynamics.
\newblock \emph{IEEE Transactions on Information Theory}, 59\penalty0
  (3):\penalty0 1902--1916, 2013.

\bibitem[Liu and Zhao(2010)]{liu2010indexability}
Keqin Liu and Qing Zhao.
\newblock Indexability of restless bandit problems and optimality of whittle
  index for dynamic multichannel access.
\newblock \emph{IEEE Transactions on Information Theory}, 56\penalty0
  (11):\penalty0 5547--5567, 2010.

\bibitem[Meshram et~al.(2016)Meshram, Gopalan, and
  Manjunath]{meshram2016optimal}
Rahul Meshram, Aditya Gopalan, and D~Manjunath.
\newblock Optimal recommendation to users that react: Online learning for a
  class of pomdps.
\newblock In \emph{IEEE 55th Conference on Decision and Control (CDC)}, pages
  7210--7215. IEEE, 2016.

\bibitem[Meshram et~al.(2017)Meshram, Gopalan, and
  Manjunath]{meshram2017restless}
Rahul Meshram, Aditya Gopalan, and D~Manjunath.
\newblock Restless bandits that hide their hand and recommendation systems.
\newblock In \emph{IEEE International Conference on Communication Systems and
  Networks (COMSNETS)}, pages 206--213. IEEE, 2017.

\bibitem[Meshram et~al.(2018)Meshram, Manjunath, and
  Gopalan]{meshram2018whittle}
Rahul Meshram, D~Manjunath, and Aditya Gopalan.
\newblock On the whittle index for restless multiarmed hidden markov bandits.
\newblock \emph{IEEE Transactions on Automatic Control}, 63\penalty0
  (9):\penalty0 3046--3053, 2018.

\bibitem[Ortner et~al.(2012)Ortner, Ryabko, Auer, and Munos]{ortner2012regret}
Ronald Ortner, Daniil Ryabko, Peter Auer, and R{\'e}mi Munos.
\newblock Regret bounds for restless markov bandits.
\newblock In \emph{International Conference on Algorithmic Learning Theory},
  pages 214--228. Springer, 2012.

\bibitem[Osband et~al.(2013)Osband, Russo, and Van~Roy]{osband2013more}
Ian Osband, Daniel Russo, and Benjamin Van~Roy.
\newblock (more) efficient reinforcement learning via posterior sampling.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3003--3011, 2013.

\bibitem[Papadimitriou and Tsitsiklis(1999)]{papadimitriou1999complexity}
Christos~H Papadimitriou and John~N Tsitsiklis.
\newblock The complexity of optimal queuing network control.
\newblock \emph{Mathematics of Operations Research}, 24\penalty0 (2):\penalty0
  293--305, 1999.

\bibitem[Robbins(1952)]{robbins1952some}
Herbert Robbins.
\newblock Some aspects of the sequential design of experiments.
\newblock \emph{Bulletin of the American Mathematical Society}, 58\penalty0
  (5):\penalty0 527--535, 1952.

\bibitem[Russo and Van~Roy(2014)]{russo2014learning}
Daniel Russo and Benjamin Van~Roy.
\newblock Learning to optimize via posterior sampling.
\newblock \emph{Mathematics of Operations Research}, 39\penalty0 (4):\penalty0
  1221--1243, 2014.

\bibitem[Tekin and Liu(2012)]{tekin2012online}
Cem Tekin and Mingyan Liu.
\newblock Online learning of rested and restless bandits.
\newblock \emph{IEEE Transactions on Information Theory}, 58\penalty0
  (8):\penalty0 5588--5611, 2012.

\bibitem[Thompson(1933)]{thompson1933likelihood}
William~R Thompson.
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock \emph{Biometrika}, 25\penalty0 (3/4):\penalty0 285--294, 1933.

\bibitem[Whittle(1988)]{whittle1988restless}
Peter Whittle.
\newblock Restless bandits: Activity allocation in a changing world.
\newblock \emph{Journal of applied probability}, 25\penalty0 (A):\penalty0
  287--298, 1988.

\end{thebibliography}
