\begin{thebibliography}{18}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Baird et~al.(1995)]{baird1995residual}
L.~Baird et~al.
\newblock Residual algorithms: Reinforcement learning with function
  approximation.
\newblock In \emph{Proceedings of the twelfth international conference on
  machine learning}, pages 30--37, 1995.

\bibitem[Beck and Teboulle(2009)]{beck2009fast}
A.~Beck and M.~Teboulle.
\newblock A fast iterative shrinkage-thresholding algorithm for linear inverse
  problems.
\newblock \emph{SIAM journal on imaging sciences}, 2\penalty0 (1):\penalty0
  183--202, 2009.

\bibitem[Bertsekas(2011)]{Ber11a}
D.~Bertsekas.
\newblock Incremental proximal methods for large scale convex optimization.
\newblock \emph{Mathematical Programming, Ser. B}, 129:\penalty0 163--195,
  2011.

\bibitem[Dann et~al.(2014)Dann, Neumann, and Peters]{dann2014policy}
C.~Dann, G.~Neumann, and J.~Peters.
\newblock Policy evaluation with temporal differences: A survey and comparison.
\newblock \emph{The Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 809--883, 2014.

\bibitem[Dentcheva et~al.(2015)Dentcheva, Penev, and
  Ruszczynski]{dentcheva2015statistical}
D.~Dentcheva, S.~Penev, and A.~Ruszczynski.
\newblock Statistical estimation of composite risk functionals and risk
  optimization problems.
\newblock \emph{arXiv preprint arXiv:1504.02658}, 2015.

\bibitem[Ermoliev(1976)]{Erm76}
Y.~Ermoliev.
\newblock \emph{Methods of Stochastic Programming}.
\newblock Monographs in Optimization and OR, Nauka, Moscow, 1976.

\bibitem[Ghadimi and Lan(2015)]{ghadimi2015accelerated}
S.~Ghadimi and G.~Lan.
\newblock Accelerated gradient methods for nonconvex nonlinear and stochastic
  programming.
\newblock \emph{Mathematical Programming}, pages 1--41, 2015.

\bibitem[Gurbuzbalaban et~al.(2015)Gurbuzbalaban, Ozdaglar, and
  Parrilo]{gurbuzbalaban2015convergence}
M.~Gurbuzbalaban, A.~Ozdaglar, and P.~Parrilo.
\newblock On the convergence rate of incremental aggregated gradient
  algorithms.
\newblock \emph{arXiv preprint arXiv:1506.02081}, 2015.

\bibitem[Liu et~al.(2015)Liu, Liu, Ghavamzadeh, Mahadevan, and
  Petrik]{liu2015finite}
B.~Liu, J.~Liu, M.~Ghavamzadeh, S.~Mahadevan, and M.~Petrik.
\newblock Finite-sample analysis of proximal gradient td algorithms.
\newblock In \emph{Proc. The 31st Conf. Uncertainty in Artificial Intelligence,
  Amsterdam, Netherlands}, 2015.

\bibitem[Liu and Wright(2015)]{liu2015asynchronous}
J.~Liu and S.~J. Wright.
\newblock Asynchronous stochastic coordinate descent: Parallelism and
  convergence properties.
\newblock \emph{SIAM Journal on Optimization}, 25\penalty0 (1):\penalty0
  351--376, 2015.

\bibitem[Nedi\'c(2011)]{Ned11}
A.~Nedi\'c.
\newblock Random algorithms for convex minimization problems.
\newblock \emph{Mathematical Programming, Ser. B}, 129:\penalty0 225--253,
  2011.

\bibitem[Nedi\'c and Bertsekas(2001)]{NeB01}
A.~Nedi\'c and D.~Bertsekas.
\newblock Incremental subgradient methods for nondifferentiable optimization.
\newblock \emph{SIAM Journal on Optimization}, 12:\penalty0 109--138, 2001.

\bibitem[Rakhlin et~al.(2012)Rakhlin, Shamir, and Sridharan]{RSS11}
A.~Rakhlin, O.~Shamir, and K.~Sridharan.
\newblock Making gradient descent optimal for strongly convex stochastic
  optimization.
\newblock In \emph{Proceedings of the 29th International Conference on Machine
  Learning}, pages 449--456, 2012.

\bibitem[Shamir and Zhang(2013)]{ShZ12}
O.~Shamir and T.~Zhang.
\newblock Stochastic gradient descent for non-smooth optimization: Convergence
  results and optimal averaging schemes.
\newblock In \emph{Proceedings of The 30th International Conference on Machine
  Learning}, pages 71--79, 2013.

\bibitem[Sutton and Barto(1998)]{sutton1998reinforcement}
R.~S. Sutton and A.~G. Barto.
\newblock \emph{Reinforcement Learning: An Introduction}.
\newblock MIT press, 1998.

\bibitem[Wang and Bertsekas(2014)]{WaB13}
M.~Wang and D.~Bertsekas.
\newblock Incremental constraint projection-proximal methods for nonsmooth
  convex optimization.
\newblock \emph{SIAM Journal on Optimization}, to appear, 2014.

\bibitem[Wang et~al.(2016)Wang, Fang, and Liu]{wang2014stochastic}
M.~Wang, E.~X. Fang, and H.~Liu.
\newblock Stochastic compositional gradient descent: Algorithms for minimizing
  compositions of expected-value functions.
\newblock \emph{Mathematical Programming Series A}, 2016.

\bibitem[White and White(2016)]{white2016investigating}
A.~White and M.~White.
\newblock Investigating practical, linear temporal difference learning.
\newblock \emph{arXiv preprint arXiv:1602.08771}, 2016.

\end{thebibliography}
