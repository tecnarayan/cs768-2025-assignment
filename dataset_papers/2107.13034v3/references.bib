@inproceedings{nguyen2021dataset,
  title={Dataset Meta-Learning from Kernel Ridge-Regression}, 
  author={Timothy Nguyen and Zhourong Chen and Jaehoon Lee},
  year={2021},
  booktitle = {International Conference on Learning Representations},
  year={2021}
}

@article{bohdal2020flexible,
  title={Flexible Dataset Distillation: Learn Labels Instead of Images},
  author={Bohdal, Ondrej and Yang, Yongxin and Hospedales, Timothy},
  journal={arXiv preprint arXiv:2006.08572},
  year={2020}
}


@article{bietti2021approximation,
  title={Approximation and Learning with Deep Convolutional Models: a Kernel Perspective},
  author={Bietti, Alberto},
  journal={arXiv preprint arXiv:2102.10032},
  year={2021}
}

@article{wang2018dataset,
  title={Dataset distillation},
  author={Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio and Efros, Alexei A},
  journal={arXiv preprint arXiv:1811.10959},
  year={2018}
}


@article{sucholutsky2019softlabel,
  title={Soft-Label Dataset Distillation and Text Dataset Distillation},
  author={Sucholutsky, Ilia and Schonlau, Matthias},
  journal={arXiv preprint arXiv:1910.02551},
  year={2019}
}


@inproceedings{Jacot2018ntk,
  title={Neural Tangent Kernel: Convergence and Generalization in Neural Networks},
  author={Arthur Jacot and Franck Gabriel and Clement Hongler},
  booktitle = {Advances in Neural Information Processing Systems},
  year={2018}
}

@inproceedings{zandieh2021scaling,
      title={Scaling Neural Tangent Kernels via Sketching and Random Features}, 
      author={Amir Zandieh and Insu Han and Haim Avron and Neta Shoham and Chaewon Kim and Jinwoo Shin},
      booktitle = {Advances in Neural Information Processing Systems},      
      year={2021},
}

@inproceedings{zhao2020dataset,
title={Dataset Condensation with Gradient Matching},
author={Bo Zhao and Konda Reddy Mopuri and Hakan Bilen},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{zhao2021dataset,
  title={Dataset Condensation with Differentiable Siamese Augmentation},
  author={Bo Zhao and Hakan Bilen},
  booktitle={International Conference on Machine Learning},
  year={2021}
}

@inproceedings{Ansuini2019IntrinsicDO,
  title={Intrinsic dimension of data representations in deep neural networks},
  author={A. Ansuini and A. Laio and J. Macke and D. Zoccolan},
  booktitle={NeurIPS},
  year={2019}
}


@inproceedings{koh2017understanding,
  title={Understanding black-box predictions via influence functions},
  author={Koh, Pang Wei and Liang, Percy},
  booktitle={Proceedings of the 34th International Conference on Machine Learning},
  year={2017}
}


@misc{ober2020global,
    title={Global inducing point variational posteriors for Bayesian neural networks and deep Gaussian processes},
    author={Sebastian W. Ober and Laurence Aitchison},
    year={2020},
    eprint={2005.08140},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@inproceedings{wilson2015deep,
  title={Deep kernel learning},
  author={Wilson, Andrew Gordon and Hu, Zhiting and Salakhutdinov, Ruslan and Xing, Eric P},
  booktitle={Artificial intelligence and statistics},
  pages={370--378},
  year={2016}
}

@article{shleifer2019using,
  title={Using Small Proxy Datasets to Accelerate Hyperparameter Search},
  author={Shleifer, Sam and Prokop, Eric},
  journal={arXiv preprint arXiv:1906.04887},
  year={2019}
}

@article{borsos2020coresets,
  title={Coresets via Bilevel Optimization for Continual Learning and Streaming},
  author={Borsos, Zal{\'a}n and Mutn{\`y}, Mojm{\'\i}r and Krause, Andreas},
  journal={arXiv preprint arXiv:2006.03875},
  year={2020}
}

@inproceedings{Bartlett2001,
author = {Bartlett, Peter and Mendelson, Shahar},
year = {2001},
month = {06},
pages = {224-240},
title = {Rademacher and Gaussian Complexities: Risk Bounds and Structural Results},
volume = {3},
journal = {The Journal of Machine Learning Research},
doi = {10.1007/3-540-44581-1_15}
}

@inproceedings{lorraine2019optimizing,
  title={Optimizing millions of hyperparameters by implicit differentiation},
  author={Lorraine, Jonathan and Vicol, Paul and Duvenaud, David},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1540--1552},
  year={2020},
  organization={PMLR}
}

@article{bertinetto2018meta,
  title={Meta-learning with differentiable closed-form solvers},
  author={Bertinetto, Luca and Henriques, Joao F and Torr, Philip HS and Vedaldi, Andrea},
  journal={arXiv preprint arXiv:1805.08136},
  year={2018}
}

@article{arora2019harnessing,
  title={Harnessing the power of infinitely wide deep nets on small-data tasks},
  author={Arora, Sanjeev and Du, Simon S and Li, Zhiyuan and Salakhutdinov, Ruslan and Wang, Ruosong and Yu, Dingli},
  journal={arXiv preprint arXiv:1910.01663},
  year={2019}
}

@inproceedings{lee2019meta,
  title={Meta-learning with differentiable convex optimization},
  author={Lee, Kwonjoon and Maji, Subhransu and Ravichandran, Avinash and Soatto, Stefano},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={10657--10665},
  year={2019}
}


@inproceedings{maclaurin2015gradient,
  title={Gradient-based hyperparameter optimization through reversible learning},
  author={Maclaurin, Dougal and Duvenaud, David and Adams, Ryan},
  booktitle={International Conference on Machine Learning},
  pages={2113--2122},
  year={2015}
}

@inproceedings{snelson2006sparse,
  title={Sparse Gaussian processes using pseudo-inputs},
  author={Snelson, Edward and Ghahramani, Zoubin},
  booktitle={Advances in neural information processing systems},
  pages={1257--1264},
  year={2006}
}

@article{neal,
  author={Neal, Radford M.},
  title={Priors for infinite networks (Tech. Rep. No. CRG-TR-94-1)},
  journal={University of Toronto},
  year={1994},
}

@inproceedings{
    lee2018deep,
    title={Deep Neural Networks as Gaussian Processes},
    author={Jaehoon Lee and Yasaman Bahri and Roman Novak and Sam Schoenholz and Jeffrey Pennington and Jascha Sohl-dickstein},
    booktitle={International Conference on Learning Representations},
    year={2018},
}

@inproceedings{matthews2018,
    title={Gaussian Process Behaviour in Wide Deep Neural Networks},
    author={Alexander{\ }G.{\ }de{\ }G. Matthews and Jiri Hron and Mark Rowland and Richard E. Turner and Zoubin Ghahramani},
    booktitle={International Conference on Learning Representations},
    year={2018},
}

@inproceedings{novak2018bayesian,
  title={Bayesian Deep Convolutional Networks with Many Channels are Gaussian Processes},
  author={Roman Novak and Lechao Xiao and Jaehoon Lee and Yasaman Bahri and Greg Yang and Jiri Hron and Daniel A. Abolafia and Jeffrey Pennington and Jascha Sohl-Dickstein},
  booktitle={International Conference on Learning Representations},
  year={2019}
}


@inproceedings{garriga2018deep,
  title={Deep convolutional networks as shallow Gaussian processes},
  author={Garriga-Alonso, Adri{\`a} and Aitchison, Laurence and Rasmussen, Carl Edward},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{hron2020,
  author = {Jiri Hron and Yasaman Bahri and Jascha Sohl-Dickstein and Roman Novak},
  year = "2020",
  booktitle = "International Conference on Machine Learning",
  title = "Infinite attention: {NNGP} and {NTK} for deep attention networks",
}

@inproceedings{lee2019wide,
  title={Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent},
  author={Lee, Jaehoon and Xiao, Lechao and  Schoenholz, Samuel S. and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019},
}

@incollection{arora2019on,
title = {On Exact Computation with an Infinitely Wide Neural Net},
author = {Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Russ R and Wang, Ruosong},
booktitle = {Advances in Neural Information Processing Systems},
pages = {8141--8150},
year = {2019},
publisher = {Curran Associates, Inc.},
}

@inproceedings{shankar2020neural,
  title={Neural Kernels Without Tangents},
  author={Vaishaal Shankar and Alex Chengyu Fang and Wenshuo Guo and Sara Fridovich-Keil and Ludwig Schmidt and Jonathan Ragan-Kelley and Benjamin Recht},
  booktitle={International Conference on Machine Learning},
  year={2020}
}

@article{li2019enhanced,
  title={Enhanced Convolutional Neural Tangent Kernels},
  author={Li, Zhiyuan and Wang, Ruosong and Yu, Dingli and Du, Simon S and Hu, Wei and Salakhutdinov, Ruslan and Arora, Sanjeev},
  journal={arXiv preprint arXiv:1911.00809},
  year={2019}
}

@inproceedings{neuraltangents2020,
    title={Neural Tangents: Fast and Easy Infinite Neural Networks in Python},
    author={Roman Novak and Lechao Xiao and Jiri Hron and Jaehoon Lee and Alexander A. Alemi and Jascha Sohl-Dickstein and Samuel S. Schoenholz},
    booktitle={International Conference on Learning Representations},
    year={2020},
    url={https://github.com/google/neural-tangents}
}


@inproceedings{
Arora2020Harnessing,
title={Harnessing the Power of Infinitely Wide Deep Nets on Small-data Tasks},
author={Sanjeev Arora and Simon S. Du and Zhiyuan Li and Ruslan Salakhutdinov and Ruosong Wang and Dingli Yu},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rkl8sJBYvH}
}

@software{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and Skye Wanderman-Milne},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.1.46},
  year = {2018},
}

@article{lecun2010mnist,
  title={MNIST handwritten digit database},
  author={LeCun, Yann and Cortes, Corinna and Burges, CJ},
  journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
  volume={2},
  year={2010}
}

@online{xiao2017/online,
  author       = {Han Xiao and Kashif Rasul and Roland Vollgraf},
  title        = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
  date         = {2017-08-28},
  year         = {2017},
  eprintclass  = {cs.LG},
  eprinttype   = {arXiv},
  eprint       = {cs.LG/1708.07747},
}

@article{DBLP:journals/corr/abs-1805-00569,
  author    = {Yang You and
               James Demmel and
               Cho{-}Jui Hsieh and
               Richard W. Vuduc},
  title     = {Accurate, Fast and Scalable Kernel Ridge Regression on Parallel and
               Distributed Systems},
  journal   = {CoRR},
  volume    = {abs/1805.00569},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.00569},
  archivePrefix = {arXiv},
  eprint    = {1805.00569},
  timestamp = {Mon, 13 Aug 2018 16:47:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-00569.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{nguyen2020stochastic,
  title={Stochastic Subset Selection},
  author={Nguyen, Tuan A and Andreis, Bruno and Lee, Juho and Yang, Eunho and Hwang, Sung Ju},
  journal={arXiv preprint arXiv:2006.14222},
  year={2020}
}

@inproceedings{williams2001using,
  title={Using the Nystr{\"o}m method to speed up kernel machines},
  author={Williams, Christopher KI and Seeger, Matthias},
  booktitle={Advances in neural information processing systems},
  pages={682--688},
  year={2001}
}

@article{drineas2005nystrom,
  title={On the Nystr{\"o}m method for approximating a Gram matrix for improved kernel-based learning},
  author={Drineas, Petros and Mahoney, Michael W},
  journal={journal of machine learning research},
  volume={6},
  number={Dec},
  pages={2153--2175},
  year={2005}
}

@article{NIPS2016_6385,
  author    = {Oriol Vinyals and
               Charles Blundell and
               Timothy P. Lillicrap and
               Koray Kavukcuoglu and
               Daan Wierstra},
  title     = {Matching Networks for One Shot Learning},
  journal   = {CoRR},
  volume    = {abs/1606.04080},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.04080},
  archivePrefix = {arXiv},
  eprint    = {1606.04080},
  timestamp = {Mon, 13 Aug 2018 16:46:48 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/VinyalsBLKW16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@incollection{NIPS2017_6996,
title = {Prototypical Networks for Few-shot Learning},
author = {Snell, Jake and Swersky, Kevin and Zemel, Richard},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {4077--4087},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/6996-prototypical-networks-for-few-shot-learning.pdf}
}

@article{metriclearning,
author = {Kaya, Mahmut and Bilge, H.s},
year = {2019},
month = {08},
pages = {1066},
title = {Deep Metric Learning: A Survey},
volume = {11},
journal = {Symmetry},
doi = {10.3390/sym11091066}
}

@article{Abadi_2016,
   title={Deep Learning with Differential Privacy},
   ISBN={9781450341394},
   url={http://dx.doi.org/10.1145/2976749.2978318},
   DOI={10.1145/2976749.2978318},
   journal={Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
   publisher={ACM},
   author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H. Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
   year={2016},
   month={Oct}
}

@misc{chen2020multistage,
      title={Multi-Stage Influence Function}, 
      author={Hongge Chen and Si Si and Yang Li and Ciprian Chelba and Sanjiv Kumar and Duane Boning and Cho-Jui Hsieh},
      year={2020},
      eprint={2007.09081},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{sohl2020infinite,
  title={On the infinite width limit of neural networks with a standard parameterization},
  author={Sohl-Dickstein, Jascha and Novak, Roman and Schoenholz, Samuel S and Lee, Jaehoon},
  journal={arXiv preprint arXiv:2001.07301},
  year={2020}
}

@inproceedings{lee2020finite,
  title={Finite Versus Infinite Neural Networks: an Empirical Study},
  author={Lee, Jaehoon and Schoenholz, Samuel S and Pennington, Jeffrey and Adlam, Ben and Xiao, Lechao and Novak, Roman and Sohl-Dickstein, Jascha},
  booktitle = {Advances in Neural Information Processing Systems},
  year={2020}
}

@article{lecun1998gradient,
	Author = {LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
	Journal = {Proceedings of the IEEE},
	Number = {11},
	Pages = {2278--2324},
	Publisher = {IEEE},
	Title = {Gradient-Based Learning Applied to Document Recognition},
	Volume = {86},
	Year = {1998}}
	

@inproceedings{mairal2014convolutional,
	Author = {Mairal, Julien and Koniusz, Piotr and Harchaoui, Zaid and Schmid, Cordelia},
	Booktitle = {Advances in Neural Information Processing Systems},
	Title = {Convolutional Kernel Networks},
	Year = {2014}}

@article{zagoruyko2016wide,
  author    = {Sergey Zagoruyko and
               Nikos Komodakis},
  title     = {Wide Residual Networks},
  journal   = {CoRR},
  volume    = {abs/1605.07146},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.07146},
  archivePrefix = {arXiv},
  eprint    = {1605.07146},
  timestamp = {Mon, 13 Aug 2018 16:46:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ZagoruykoK16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{titsias2009variational,
  title={Variational learning of inducing variables in sparse Gaussian processes},
  author={Titsias, Michalis},
  booktitle={Artificial Intelligence and Statistics},
  pages={567--574},
  year={2009}
}

@misc{hastie2019surprises,
      title={Surprises in High-Dimensional Ridgeless Least Squares Interpolation}, 
      author={Trevor Hastie and Andrea Montanari and Saharon Rosset and Ryan J. Tibshirani},
      year={2019},
      eprint={1903.08560},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}

@book{kato,
title={Perturbation Theory of Linear Operators},
author={T. Kato},
year={1976},
publisher={Springer-Verlag},
edition=2,
address={Berlin}
}

@article{bordes2005fast,
  title={Fast kernel classifiers with online and active learning},
  author={Bordes, Antoine and Ertekin, Seyda and Weston, Jason and Bottou, L{\'e}on},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Sep},
  pages={1579--1619},
  year={2005}
}

@article{steinwart2003sparseness,
  title={Sparseness of support vector machines},
  author={Steinwart, Ingo},
  journal={Journal of Machine Learning Research},
  volume={4},
  number={Nov},
  pages={1071--1105},
  year={2003}
}

@misc{huang2020instahide,
      title={InstaHide: Instance-hiding Schemes for Private Distributed Learning}, 
      author={Yangsibo Huang and Zhao Song and Kai Li and Sanjeev Arora},
      year={2020},
      eprint={2010.02772},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}

@article{phillips2016coresets,
  title={Coresets and sketches},
  author={Phillips, Jeff M},
  journal={arXiv preprint arXiv:1601.00617},
  year={2016}
}

@article{jubran2019introduction,
  title={Introduction to coresets: Accurate coresets},
  author={Jubran, Ibrahim and Maalouf, Alaa and Feldman, Dan},
  journal={arXiv preprint arXiv:1910.08707},
  year={2019}
}

@article{10.2307/2027337,
 ISSN = {00361445},
 URL = {http://www.jstor.org/stable/2027337},
 author = {T. N. E. Greville},
 journal = {SIAM Review},
 number = {4},
 pages = {518--521},
 publisher = {Society for Industrial and Applied Mathematics},
 title = {Note on the Generalized Inverse of a Matrix Product},
 volume = {8},
 year = {1966}
}

@article{facco2017estimating,
  title={Estimating the intrinsic dimension of datasets by a minimal neighborhood information},
  author={Facco, Elena and d’Errico, Maria and Rodriguez, Alex and Laio, Alessandro},
  journal={Scientific reports},
  volume={7},
  number={1},
  pages={1--8},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{DBLP:journals/corr/abs-1712-00409,
  author    = {Joel Hestness and
               Sharan Narang and
               Newsha Ardalani and
               Gregory F. Diamos and
               Heewoo Jun and
               Hassan Kianinejad and
               Md. Mostofa Ali Patwary and
               Yang Yang and
               Yanqi Zhou},
  title     = {Deep Learning Scaling is Predictable, Empirically},
  journal   = {CoRR},
  volume    = {abs/1712.00409},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.00409},
  archivePrefix = {arXiv},
  eprint    = {1712.00409},
  timestamp = {Mon, 13 Aug 2018 16:48:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1712-00409.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{kaplan2020scaling,
      title={Scaling Laws for Neural Language Models}, 
      author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
      year={2020},
      eprint={2001.08361},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ilyas2019adversarial,
      title={Adversarial Examples Are Not Bugs, They Are Features}, 
      author={Andrew Ilyas and Shibani Santurkar and Dimitris Tsipras and Logan Engstrom and Brandon Tran and Aleksander Madry},
      year={2019},
      eprint={1905.02175},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  pages={1097--1105},
  year={2012}
}


@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}


@article{neyshabur2020being,
  title={What is being transferred in transfer learning?},
  author={Neyshabur, Behnam and Sedghi, Hanie and Zhang, Chiyuan},
  journal={arXiv preprint arXiv:2008.11687},
  year={2020}
}

@article{nagarajan2020understanding,
  title={Understanding the failure modes of out-of-distribution generalization},
  author={Nagarajan, Vaishnavh and Andreassen, Anders and Neyshabur, Behnam},
  journal={arXiv preprint arXiv:2010.15775},
  year={2020}
}

@article{huh2016makes,
  title={What makes ImageNet good for transfer learning?},
  author={Huh, Minyoung and Agrawal, Pulkit and Efros, Alexei A},
  journal={arXiv preprint arXiv:1608.08614},
  year={2016}
}

@article{hermann2020shapes,
  title={What shapes feature representations? Exploring datasets, architectures, and training},
  author={Hermann, Katherine L and Lampinen, Andrew K},
  journal={arXiv preprint arXiv:2006.12433},
  year={2020}
}

@online{fashionmnist,
  author       = {Han Xiao and Kashif Rasul and Roland Vollgraf},
  title        = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
  date         = {2017-08-28},
  year         = {2017},
  eprintclass  = {cs.LG},
  eprinttype   = {arXiv},
  eprint       = {cs.LG/1708.07747},
}

@article{svhn,
author = {Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
booktitle = {Advances in Neural Information Processing Systems ({NIPS})},
title = {Reading Digits in Natural Images with Unsupervised Feature Learning},
year = {2011}
}

@article{mnist,
  title={MNIST handwritten digit database},
  author={LeCun, Yann and Cortes, Corinna and Burges, CJ},
  journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
  volume={2},
  year={2010}
}

@TECHREPORT{cifar10,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    institution = {},
    year = {2009}
}

@inproceedings{yaida2019non,
  title={Non-{G}aussian processes and neural networks at finite widths},
  author={Yaida, Sho},
  booktitle={Mathematical and Scientific Machine Learning Conference},
  year={2020}
}

@article{andreassen2020,
  title={Asymptotics of Wide Convolutional Neural Networks},
  author={Andreassen, Anders and Dyer, Ethan},
  journal={arxiv preprint arXiv:2008.08675},
  year={2020}
}

@inproceedings{
Dyer2020Asymptotics,
title={Asymptotics of Wide Networks from Feynman Diagrams},
author={Ethan Dyer and Guy Gur-Ari},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=S1gFvANKDS}
}

@inproceedings{huang2019dynamics,
  title={Dynamics of deep neural networks and neural tangent hierarchy},
  author={Huang, Jiaoyang and Yau, Horng-Tzer},
  booktitle={International Conference on Machine Learning},
  year={2020}
}

@InProceedings{cubuk2019cvpr,
author = {Cubuk, Ekin D. and Zoph, Barret and Mane, Dandelion and Vasudevan, Vijay and Le, Quoc V.},
title = {AutoAugment: Learning Augmentation Strategies From Data},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}

@article{yang2019scaling,
  title={Scaling Limits of Wide Neural Networks with Weight Sharing: Gaussian Process Behavior, Gradient Independence, and Neural Tangent Kernel Derivation},
  author={Yang, Greg},
  journal={arXiv preprint arXiv:1902.04760},
  year={2019}
}

@inproceedings{yang2019wide,
  title={Wide feedforward or recurrent neural networks of any architecture are gaussian processes},
  author={Yang, Greg},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}

@misc{sharma2020neural,
      title={A Neural Scaling Law from the Dimension of the Data Manifold}, 
      author={Utkarsh Sharma and Jared Kaplan},
      year={2020},
      eprint={2004.10802},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@ARTICLE{1054365,
  author={Bennett, R.},
  journal={IEEE Transactions on Information Theory}, 
  title={The intrinsic dimensionality of signal collections}, 
  year={1969},
  volume={15},
  number={5},
  pages={517-525},
  doi={10.1109/TIT.1969.1054365}}
  
@article{CAMASTRA201626,
title = {Intrinsic dimension estimation: Advances and open problems},
journal = {Information Sciences},
volume = {328},
pages = {26-41},
year = {2016},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2015.08.029},
url = {https://www.sciencedirect.com/science/article/pii/S0020025515006179},
author = {Francesco Camastra and Antonino Staiano},
keywords = {Intrinsic dimension, Curse of dimensionality, Maximum likelihood, Correlation dimension, Dimensionality reduction},
abstract = {Dimensionality reduction methods are preprocessing techniques used for coping with high dimensionality. They have the aim of projecting the original data set of dimensionality N, without information loss, onto a lower M-dimensional submanifold. Since the value of M is unknown, techniques that allow knowing in advance the value of M, called intrinsic dimension (ID), are quite useful. The aim of the paper is to review state-of-the-art of the methods of ID estimation, underlining the recent advances and the open problems.}
}

@inproceedings{xiao2019disentangling,
  title={Disentangling trainability and generalization in deep learning},
  author={Xiao, Lechao and Pennington, Jeffrey and Schoenholz, Samuel S},
  booktitle={International Conference on Machine Learning},
  year={2020}
}

@article{lewkowycz2020large,
  title={The large learning rate phase of deep learning: the catapult mechanism},
  author={Lewkowycz, Aitor and Bahri, Yasaman and Dyer, Ethan and Sohl-Dickstein, Jascha and Gur-Ari, Guy},
  journal={arXiv preprint arXiv:2003.02218},
  year={2020}
}

@inproceedings{lewkowycz2020l2reg,
 author = {Lewkowycz, Aitor and Gur-Ari, Guy},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {4790--4799},
 title = {On the training dynamics of deep networks with L\_2 regularization},
 volume = {33},
 year = {2020}
}

@inproceedings{
adlam2021exploring,
title={Exploring the Uncertainty Properties of Neural Networks{\textquoteright} Implicit Priors in the Infinite-Width Limit},
author={Ben Adlam and Jaehoon Lee and Lechao Xiao and Jeffrey Pennington and Jasper Snoek},
booktitle={International Conference on Learning Representations},
year={2021},
}


@article{geiger2020scaling,
  title={Scaling description of generalization with number of parameters in deep learning},
  author={Geiger, Mario and Jacot, Arthur and Spigler, Stefano and Gabriel, Franck and Sagun, Levent and d’Ascoli, St{\'e}phane and Biroli, Giulio and Hongler, Cl{\'e}ment and Wyart, Matthieu},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  volume={2020},
  number={2},
  pages={023401},
  year={2020},
  publisher={IOP Publishing}
}

@article{jacot2019order,
  title={Order and chaos: NTK views on DNN normalization, checkerboard and boundary artifacts},
  author={Jacot, Arthur and Gabriel, Franck and Ged, Fran{\c{c}}ois and Hongler, Cl{\'e}ment},
  journal={arXiv preprint arXiv:1907.05715},
  year={2019}
}

@inproceedings{adlam2020neural,
  title={The neural tangent kernel in high dimensions: Triple descent and a multi-scale theory of generalization},
  author={Adlam, Ben and Pennington, Jeffrey},
  booktitle={International Conference on Machine Learning},
  pages={74--84},
  year={2020},
  organization={PMLR}
}

@article{bahri2021explaining,
  title={Explaining neural scaling laws},
  author={Bahri, Yasaman and Dyer, Ethan and Kaplan, Jared and Lee, Jaehoon and Sharma, Utkarsh},
  journal={arXiv preprint arXiv:2102.06701},
  year={2021}
}



@inproceedings{
rosenfeld2020a,
title={A Constructive Prediction of the Generalization Error Across Scales},
author={Jonathan S. Rosenfeld and Amir Rosenfeld and Yonatan Belinkov and Nir Shavit},
booktitle={International Conference on Learning Representations},
year={2020},
}

@article{park2020towards,
  title={Towards nngp-guided neural architecture search},
  author={Park, Daniel S and Lee, Jaehoon and Peng, Daiyi and Cao, Yuan and Sohl-Dickstein, Jascha},
  journal={arXiv preprint arXiv:2011.06006},
  year={2020}
}

@inproceedings{
chen2021neural,
title={Neural Architecture Search on ImageNet in Four {\{}GPU{\}} Hours: A Theoretically Inspired Perspective},
author={Wuyang Chen and Xinyu Gong and Zhangyang Wang},
booktitle={International Conference on Learning Representations},
year={2021},
}