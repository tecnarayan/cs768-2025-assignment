\begin{thebibliography}{10}

\bibitem{achiam2023gpt}
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya,
  Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
  Shyamal Anadkat, et~al.
\newblock Gpt-4 technical report.
\newblock {\em arXiv preprint arXiv:2303.08774}, 2023.

\bibitem{Bedi2024.04.15.24305869}
Suhana Bedi, Yutong Liu, Lucy Orr-Ewing, Dev Dash, Sanmi Koyejo, Alison
  Callahan, Jason~A. Fries, Michael Wornow, Akshay Swaminathan, Lisa~Soleymani
  Lehmann, Hyo~Jung Hong, Mehr Kashyap, Akash~R. Chaurasia, Nirav~R. Shah,
  Karandeep Singh, Troy Tazbaz, Arnold Milstein, Michael~A. Pfeffer, and
  Nigam~H. Shah.
\newblock A systematic review of testing and evaluation of healthcare
  applications of large language models (llms).
\newblock {\em medRxiv}, 2024.

\bibitem{chen2022multi}
Zhihong Chen, Yuhao Du, Jinpeng Hu, Yang Liu, Guanbin Li, Xiang Wan, and
  Tsung-Hui Chang.
\newblock Multi-modal masked autoencoders for medical vision-and-language
  pre-training.
\newblock {\em MICCAI}, 2022.

\bibitem{chen2024selfplay}
Zixiang Chen, Yihe Deng, Huizhuo Yuan, Kaixuan Ji, and Quanquan Gu.
\newblock Self-play fine-tuning converts weak language models to strong
  language models.
\newblock {\em arXiv preprint arXiv:2401.01335}, 2024.

\bibitem{chung2022scaling}
Hyung~Won Chung, Le~Hou, Shayne Longpre, Barret Zoph, Yi~Tay, William Fedus,
  Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et~al.
\newblock Scaling instruction-finetuned language models.
\newblock {\em arXiv preprint arXiv:2210.11416}, 2022.

\bibitem{do2021multiple}
Tuong Do, Binh~X Nguyen, Erman Tjiputra, Minh Tran, Quang~D Tran, and Anh
  Nguyen.
\newblock Multiple meta-model quantifying for medical visual question
  answering.
\newblock {\em MICCAI}, 2021.

\bibitem{eslami2023pubmedclip}
Sedigheh Eslami, Christoph Meinel, and Gerard De~Melo.
\newblock Pubmedclip: How much does clip benefit visual question answering in
  the medical domain?
\newblock {\em EACL}, 2023.

\bibitem{fleming2024medalign}
Scott~L Fleming, Alejandro Lozano, William~J Haberkorn, Jenelle~A Jindal,
  Eduardo Reis, Rahul Thapa, Louis Blankemeier, Julian~Z Genkins, Ethan
  Steinberg, Ashwin Nayak, et~al.
\newblock Medalign: a clinician-generated dataset for instruction following
  with electronic medical records.
\newblock {\em AAAI}, 2024.

\bibitem{gao2023enabling}
Tianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen.
\newblock Enabling large language models to generate text with citations.
\newblock {\em EMNLP}, 2023.

\bibitem{he2020pathvqa}
Xuehai He, Yichen Zhang, Luntian Mou, Eric Xing, and Pengtao Xie.
\newblock Pathvqa: 30000+ questions for medical visual question answering.
\newblock {\em arXiv preprint arXiv:2003.10286}, 2020.

\bibitem{hu2023tifa}
Yushi Hu, Benlin Liu, Jungo Kasai, Yizhong Wang, Mari Ostendorf, Ranjay
  Krishna, and Noah~A Smith.
\newblock Tifa: Accurate and interpretable text-to-image faithfulness
  evaluation with question answering.
\newblock 2023.

\bibitem{plip}
Zhi Huang, Federico Bianchi, Mert Yuksekgonul, Thomas~J. Montine, and James
  Zou.
\newblock A visual--language foundation model for pathology image analysis
  using medical twitter.
\newblock {\em Nat. Med.}, 2023.

\bibitem{kim2024generalizing}
Taehee Kim, Yeongjae Cho, Heejun Shin, Yohan Jo, and Dongmyung Shin.
\newblock Generalizing visual question answering from synthetic to
  human-written questions via a chain of qa with a large language model.
\newblock {\em arXiv preprint arXiv:2401.06400}, 2024.

\bibitem{lau2018dataset}
Jason~J Lau, Soumya Gayen, Asma Ben~Abacha, and Dina Demner-Fushman.
\newblock A dataset of clinically generated visual questions and answers about
  radiology images.
\newblock {\em Sci. Data}, 2018.

\bibitem{li2024llava}
Chunyuan Li, Cliff Wong, Sheng Zhang, Naoto Usuyama, Haotian Liu, Jianwei Yang,
  Tristan Naumann, Hoifung Poon, and Jianfeng Gao.
\newblock Llava-med: Training a large language-and-vision assistant for
  biomedicine in one day.
\newblock {\em NeurIPS}, 2024.

\bibitem{li2023masked}
Pengfei Li, Gang Liu, Jinlong He, Zixu Zhao, and Shenjun Zhong.
\newblock Masked vision and language pre-training with unimodal and multimodal
  contrastive losses for medical visual question answering.
\newblock {\em MICCAI}, 2023.

\bibitem{li2023self}
Pengfei Li, Gang Liu, Lin Tan, Jinying Liao, and Shenjun Zhong.
\newblock Self-supervised vision-language pretraining for medial visual
  question answering.
\newblock {\em ISBI}, 2023.

\bibitem{lin2023pmc}
Weixiong Lin, Ziheng Zhao, Xiaoman Zhang, Chaoyi Wu, Ya~Zhang, Yanfeng Wang,
  and Weidi Xie.
\newblock Pmc-clip: Contrastive language-image pre-training using biomedical
  documents.
\newblock {\em MICCAI}, 2023.

\bibitem{liu2021slake}
Bo~Liu, Li-Ming Zhan, Li~Xu, Lin Ma, Yan Yang, and Xiao-Ming Wu.
\newblock Slake: A semantically-labeled knowledge-enhanced dataset for medical
  visual question answering.
\newblock {\em ISBI}, 2021.

\bibitem{liu2023improvedllava}
Haotian Liu, Chunyuan Li, Yuheng Li, and Yong~Jae Lee.
\newblock Improved baselines with visual instruction tuning.
\newblock {\em CVPR}, 2024.

\bibitem{liu2023visual}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee.
\newblock Visual instruction tuning.
\newblock {\em NeurIPS}, 2023.

\bibitem{liu2023llava}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee.
\newblock Visual instruction tuning, 2023.

\bibitem{Manas_Krojer_Agrawal_2024}
Oscar Ma√±as, Benno Krojer, and Aishwarya Agrawal.
\newblock Improving automatic vqa evaluation using large language models.
\newblock {\em AAAI}, 2024.

\bibitem{DBLP:conf/acl/MishraKBH22}
Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi.
\newblock Cross-task generalization via natural language crowdsourcing
  instructions.
\newblock {\em ACL}, 2022.

\bibitem{moor2023foundation}
Michael Moor, Oishi Banerjee, Zahra Shakeri~Hossein Abad, Harlan~M Krumholz,
  Jure Leskovec, Eric~J Topol, and Pranav Rajpurkar.
\newblock Foundation models for generalist medical artificial intelligence.
\newblock {\em Nature}, 616:259--265, 2023.

\bibitem{ning2023album}
Munan Ning, Yujia Xie, Dongdong Chen, Zeyin Song, Lu~Yuan, Yonghong Tian,
  Qixiang Ye, and Li~Yuan.
\newblock Album storytelling with iterative story-aware captioning and large
  language models.
\newblock {\em arXiv preprint arXiv:2305.12943}, 2023.

\bibitem{doi:10.7326/M23-2772}
Jesutofunmi~A. Omiye, Haiwen Gui, Shawheen~J. Rezaei, James Zou, and Roxana
  Daneshjou.
\newblock Large language models in medicine: The potentials and pitfalls.
\newblock {\em Ann. Intern. Med.}, 2024.

\bibitem{peng2023instruction}
Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao.
\newblock Instruction tuning with gpt-4.
\newblock {\em arXiv preprint arXiv:2304.03277}, 2023.

\bibitem{saab2024capabilities}
Khaled Saab, Tao Tu, Wei-Hung Weng, Ryutaro Tanno, David Stutz, Ellery Wulczyn,
  Fan Zhang, Tim Strother, Chunjong Park, Elahe Vedadi, et~al.
\newblock Capabilities of gemini models in medicine.
\newblock {\em arXiv preprint arXiv:2404.18416}, 2024.

\bibitem{sun2023text}
Xiaofei Sun, Xiaoya Li, Jiwei Li, Fei Wu, Shangwei Guo, Tianwei Zhang, and
  Guoyin Wang.
\newblock Text classification via large language models.
\newblock 2023.

\bibitem{alpaca}
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos
  Guestrin, Percy Liang, and Tatsunori~B. Hashimoto.
\newblock Stanford alpaca: An instruction-following llama model, 2023.

\bibitem{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
  Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric
  Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock {\em arXiv preprint arXiv:2302.13971}, 2023.

\bibitem{touvron2023llama2}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine
  Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,
  et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock {\em arXiv preprint arXiv:2307.09288}, 2023.

\bibitem{tu2024towards}
Tao Tu, Shekoofeh Azizi, Danny Driess, Mike Schaekermann, Mohamed Amin,
  Pi-Chuan Chang, Andrew Carroll, Charles Lau, Ryutaro Tanno, Ira Ktena, et~al.
\newblock Towards generalist biomedical ai.
\newblock {\em NEJM AI}, 2024.

\bibitem{van2023open}
Tom Van~Sonsbeek, Mohammad~Mahdi Derakhshani, Ivona Najdenkoska, Cees~GM Snoek,
  and Marcel Worring.
\newblock Open-ended medical visual question answering through prefix tuning of
  language models.
\newblock {\em MICCAI}, 2023.

\bibitem{wan2023gptre}
Zhen Wan, Fei Cheng, Zhuoyuan Mao, Qianying Liu, Haiyue Song, Jiwei Li, and
  Sadao Kurohashi.
\newblock Gpt-re: In-context learning for relation extraction using large
  language models.
\newblock {\em EMNLP}, 2023.

\bibitem{wang2023selfinstruct}
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah~A. Smith, Daniel
  Khashabi, and Hannaneh Hajishirzi.
\newblock Self-instruct: Aligning language models with self-generated
  instructions.
\newblock {\em ACL}, 2023.

\bibitem{DBLP:conf/iclr/WeiBZGYLDDL22}
Jason Wei, Maarten Bosma, Vincent~Y. Zhao, Kelvin Guu, Adams~Wei Yu, Brian
  Lester, Nan Du, Andrew~M. Dai, and Quoc~V. Le.
\newblock Finetuned language models are zero-shot learners.
\newblock {\em ICLR}, 2022.

\bibitem{wu2024pmc}
Chaoyi Wu, Weixiong Lin, Xiaoman Zhang, Ya~Zhang, Weidi Xie, and Yanfeng Wang.
\newblock Pmc-llama: toward building open-source language models for medicine.
\newblock {\em JAMIA}, 2024.

\bibitem{yao2023tree}
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas~L. Griffiths, Yuan
  Cao, and Karthik Narasimhan.
\newblock Tree of thoughts: Deliberate problem solving with large language
  models.
\newblock {\em NeurIPS}, 2023.

\bibitem{zhang2023large}
Sheng Zhang, Yanbo Xu, Naoto Usuyama, Jaspreet Bagga, Robert Tinn, Sam Preston,
  Rajesh Rao, Mu~Wei, Naveen Valluri, Cliff Wong, et~al.
\newblock Large-scale domain-specific pretraining for biomedical
  vision-language processing.
\newblock {\em arXiv preprint arXiv:2303.00915}, 2023.

\bibitem{zhang2024biomedclip}
Sheng Zhang, Yanbo Xu, Naoto Usuyama, Hanwen Xu, Jaspreet Bagga, Robert Tinn,
  Sam Preston, Rajesh Rao, Mu~Wei, Naveen Valluri, Cliff Wong, Andrea Tupini,
  Yu~Wang, Matt Mazzola, Swadheen Shukla, Lars Liden, Jianfeng Gao, Matthew~P.
  Lungren, Tristan Naumann, Sheng Wang, and Hoifung Poon.
\newblock Biomedclip: a multimodal biomedical foundation model pretrained from
  fifteen million scientific image-text pairs.
\newblock {\em arXiv preprint arXiv:2303.00915}, 2024.

\bibitem{zhang2023instruction}
Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang,
  Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, et~al.
\newblock Instruction tuning for large language models: A survey.
\newblock {\em arXiv preprint arXiv:2308.10792}, 2023.

\bibitem{zhang2023pmcvqa}
Xiaoman Zhang, Chaoyi Wu, Ziheng Zhao, Weixiong Lin, Ya~Zhang, Yanfeng Wang,
  and Weidi Xie.
\newblock Pmc-vqa: Visual instruction tuning for medical visual question
  answering.
\newblock {\em arXiv preprint arXiv:2305.10415}, 2023.

\bibitem{zhao2021calibrate}
Tony~Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh.
\newblock Calibrate before use: Improving few-shot performance of language
  models.
\newblock {\em ICML}, 2021.

\bibitem{DBLP:conf/nips/ZhengC00WZL0LXZ23}
Lianmin Zheng, Wei{-}Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu,
  Yonghao Zhuang, Zi~Lin, Zhuohan Li, Dacheng Li, Eric~P. Xing, Hao Zhang,
  Joseph~E. Gonzalez, and Ion Stoica.
\newblock Judging llm-as-a-judge with mt-bench and chatbot arena.
\newblock In {\em NeurIPS}, 2023.

\end{thebibliography}
