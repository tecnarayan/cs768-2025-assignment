\begin{thebibliography}{10}

\bibitem{anand1993improved}
Rangachari Anand, Kishan~G Mehrotra, Chilukuri~K Mohan, and Sanjay Ranka.
\newblock An improved algorithm for neural network classification of imbalanced training sets.
\newblock {\em IEEE transactions on neural networks}, 4(6):962--969, 1993.

\bibitem{arjovsky2019invariant}
Martin Arjovsky, L{\'e}on Bottou, Ishaan Gulrajani, and David Lopez-Paz.
\newblock Invariant risk minimization.
\newblock {\em arXiv preprint arXiv:1907.02893}, 2019.

\bibitem{arnaboldi2023high}
Luca Arnaboldi, Ludovic Stephan, Florent Krzakala, and Bruno Loureiro.
\newblock From high-dimensional \& mean-field dynamics to dimensionless odes: A unifying approach to sgd in two-layers networks.
\newblock In Gergely Neu and Lorenzo Rosasco, editors, {\em Proceedings of Thirty Sixth Conference on Learning Theory}, volume 195 of {\em Proceedings of Machine Learning Research}, pages 1199--1227. PMLR, 12--15 Jul 2023.

\bibitem{arpit2017closer}
Devansh Arpit, Stanis{\l}aw Jastrz{\k{e}}bski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder~S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et~al.
\newblock A closer look at memorization in deep networks.
\newblock In {\em International conference on machine learning}, pages 233--242. PMLR, 2017.

\bibitem{bell2023simplicity}
Samuel~James Bell and Levent Sagun.
\newblock Simplicity bias leads to amplified performance disparities.
\newblock In {\em Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency}, pages 355--369, 2023.

\bibitem{ben2022high}
Gerard Ben~Arous, Reza Gheissari, and Aukosh Jagannath.
\newblock High-dimensional limit theorems for sgd: Effective dynamics and critical scaling.
\newblock {\em Advances in Neural Information Processing Systems}, 35:25349--25362, 2022.

\bibitem{berk2021fairness}
Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, and Aaron Roth.
\newblock Fairness in criminal justice risk assessments: The state of the art.
\newblock {\em Sociological Methods \& Research}, 50(1):3--44, 2021.

\bibitem{biehl1995learning}
Michael Biehl and Holm Schwarze.
\newblock Learning by on-line gradient descent.
\newblock {\em Journal of Physics A: Mathematical and general}, 28(3):643, 1995.

\bibitem{buolamwini2018gender}
Joy Buolamwini and Timnit Gebru.
\newblock Gender shades: Intersectional accuracy disparities in commercial gender classification.
\newblock In {\em Conference on fairness, accountability and transparency}, pages 77--91. PMLR, 2018.

\bibitem{farnia2018spectral}
Farzan Farnia, Jesse Zhang, and David Tse.
\newblock A spectral approach to generalization and optimization in neural networks.
\newblock 2018.

\bibitem{feng2022has}
Yunhe Feng and Chirag Shah.
\newblock Has ceo gender bias really been fixed? adversarial attacking and improving gender fairness in image search.
\newblock In {\em Proceedings of the AAAI Conference on Artificial Intelligence}, volume~36, pages 11882--11890, 2022.

\bibitem{francazi2023initial}
Emanuele Francazi, Aurelien Lucchi, and Marco Baity-Jesi.
\newblock Initial guessing bias: How untrained networks favor some classes.
\newblock {\em arXiv preprint arXiv:2306.00809}, 2023.

\bibitem{ganesh2023impact}
Prakhar Ganesh, Hongyan Chang, Martin Strobel, and Reza Shokri.
\newblock On the impact of machine learning randomness on group fairness.
\newblock In {\em Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency}, pages 1789--1800, 2023.

\bibitem{geirhos2020shortcut}
Robert Geirhos, J{\"o}rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and Felix~A Wichmann.
\newblock Shortcut learning in deep neural networks.
\newblock {\em Nature Machine Intelligence}, 2(11):665--673, 2020.

\bibitem{goldt2019dynamics}
Sebastian Goldt, Madhu Advani, Andrew~M Saxe, Florent Krzakala, and Lenka Zdeborov{\'a}.
\newblock Dynamics of stochastic gradient descent for two-layer neural networks in the teacher-student setup.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{gunasekar2018implicit}
Suriya Gunasekar, Jason~D Lee, Daniel Soudry, and Nati Srebro.
\newblock Implicit bias of gradient descent on linear convolutional networks.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{haixiang2017learning}
Guo Haixiang, Li~Yijing, Jennifer Shang, Gu~Mingyun, Huang Yuanyue, and Gong Bing.
\newblock Learning from class-imbalanced data: Review of methods and applications.
\newblock {\em Expert systems with applications}, 73:220--239, 2017.

\bibitem{hermann2023foundations}
Katherine~L Hermann, Hossein Mobahi, Thomas Fel, and Michael~C Mozer.
\newblock On the foundations of shortcut learning.
\newblock In {\em The Twelfth International Conference on Learning Representations}, 2024.

\bibitem{iofinova2023bias}
Eugenia Iofinova, Alexandra Peste, and Dan Alistarh.
\newblock Bias in pruned vision models: In-depth analysis and countermeasures.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 24364--24373, 2023.

\bibitem{karkkainen2021fairface}
Kimmo Karkkainen and Jungseock Joo.
\newblock Fairface: Face attribute dataset for balanced race, gender, and age for bias measurement and mitigation.
\newblock In {\em Proceedings of the IEEE/CVF winter conference on applications of computer vision}, pages 1548--1558, 2021.

\bibitem{kay2015unequal}
Matthew Kay, Cynthia Matuszek, and Sean~A Munson.
\newblock Unequal representation and gender stereotypes in image search results for occupations.
\newblock In {\em Proceedings of the 33rd annual acm conference on human factors in computing systems}, pages 3819--3828, 2015.

\bibitem{krawczyk2016learning}
Bartosz Krawczyk.
\newblock Learning from imbalanced data: open challenges and future directions.
\newblock {\em Progress in Artificial Intelligence}, 5(4):221--232, 2016.

\bibitem{lecun2002efficient}
Yann LeCun, L{\'e}on Bottou, Genevieve~B Orr, and Klaus-Robert M{\"u}ller.
\newblock Efficient backprop.
\newblock In {\em Neural networks: Tricks of the trade}, pages 9--50. Springer, 2002.

\bibitem{lelarge2019asymptotic}
Marc Lelarge and L{\'e}o Miolane.
\newblock Asymptotic bayes risk for gaussian mixture in a semi-supervised setting.
\newblock In {\em 2019 IEEE 8th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)}, pages 639--643. IEEE, 2019.

\bibitem{lesieur2016phase}
Thibault Lesieur, Caterina De~Bacco, Jess Banks, Florent Krzakala, Cris Moore, and Lenka Zdeborov{\'a}.
\newblock Phase transitions and optimal algorithms in high-dimensional gaussian mixture clustering.
\newblock In {\em 2016 54th Annual Allerton Conference on Communication, Control, and Computing (Allerton)}, pages 601--608. IEEE, 2016.

\bibitem{liu2021just}
Evan~Z Liu, Behzad Haghgoo, Annie~S Chen, Aditi Raghunathan, Pang~Wei Koh, Shiori Sagawa, Percy Liang, and Chelsea Finn.
\newblock Just train twice: Improving group robustness without training group information.
\newblock In {\em International Conference on Machine Learning}, pages 6781--6792. PMLR, 2021.

\bibitem{liu2018celeba}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Large-scale celebfaces attributes (celeba) dataset.
\newblock {\em Retrieved August}, 15(2018):11, 2018.

\bibitem{mangalam2019deep}
Karttikeya Mangalam and Vinay~Uday Prabhu.
\newblock Do deep neural networks learn shallow learnable examples first?
\newblock In {\em ICML 2019 Workshop on Identifying and Understanding Deep Learning Phenomena}, 2019.

\bibitem{nagarajan2021understanding}
Vaishnavh Nagarajan, Anders Andreassen, and Behnam Neyshabur.
\newblock Understanding the failure modes of out-of-distribution generalization.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{nakkiran2019sgd}
Preetum Nakkiran, Gal Kaplun, Dimitris Kalimeris, Tristan Yang, Benjamin~L Edelman, Fred Zhang, and Boaz Barak.
\newblock Sgd on neural networks learns functions of increasing complexity.
\newblock {\em Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem{neyshabur2014search}
Behnam Neyshabur, Ryota Tomioka, and Nathan Srebro.
\newblock In search of the real inductive bias: On the role of implicit regularization in deep learning.
\newblock {\em arXiv preprint arXiv:1412.6614}, 2014.

\bibitem{rahaman2019spectral}
Nasim Rahaman, Aristide Baratin, Devansh Arpit, Felix Draxler, Min Lin, Fred Hamprecht, Yoshua Bengio, and Aaron Courville.
\newblock On the spectral bias of neural networks.
\newblock In {\em International conference on machine learning}, pages 5301--5310. PMLR, 2019.

\bibitem{refinetti2023neural}
Maria Refinetti, Alessandro Ingrosso, and Sebastian Goldt.
\newblock Neural networks trained with sgd learn distributions of increasing complexity.
\newblock In {\em International Conference on Machine Learning}, pages 28843--28863. PMLR, 2023.

\bibitem{saad1995dynamics}
David Saad and Sara Solla.
\newblock Dynamics of on-line gradient descent learning for multilayer neural networks.
\newblock {\em Advances in neural information processing systems}, 8, 1995.

\bibitem{Sagawa2020Distributionally}
Shiori Sagawa, Pang~Wei Koh, Tatsunori~B. Hashimoto, and Percy Liang.
\newblock Distributionally robust neural networks.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{sagawa2019distributionally}
Shiori Sagawa, Pang~Wei Koh, Tatsunori~B Hashimoto, and Percy Liang.
\newblock Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization.
\newblock In {\em International Conference on Learning Representations (ICLR)}, 2020.

\bibitem{sagawa2020investigation}
Shiori Sagawa, Aditi Raghunathan, Pang~Wei Koh, and Percy Liang.
\newblock An investigation of why overparameterization exacerbates spurious correlations.
\newblock In {\em International Conference on Machine Learning}, pages 8346--8356. PMLR, 2020.

\bibitem{mannelli2022unfair}
Stefano Sarao~Mannelli, Federica Gerace, Negar Rostamzadeh, and Luca Saglietti.
\newblock Unfair geometries: exactly solvable data model with fairness implications.
\newblock {\em arXiv preprint arXiv:2205.15935}, 2022.

\bibitem{shah2020pitfalls}
Harshay Shah, Kaustav Tamuly, Aditi Raghunathan, Prateek Jain, and Praneeth Netrapalli.
\newblock The pitfalls of simplicity bias in neural networks.
\newblock {\em Advances in Neural Information Processing Systems}, 33:9573--9585, 2020.

\bibitem{suresh2021framework}
Harini Suresh and John Guttag.
\newblock A framework for understanding sources of harm throughout the machine learning life cycle.
\newblock In {\em Equity and access in algorithms, mechanisms, and optimization}, pages 1--9. 2021.

\bibitem{xu2018understanding}
Zhiqin~John Xu.
\newblock Understanding training and generalization in deep learning by fourier analysis.
\newblock {\em arXiv preprint arXiv:1808.04295}, 2018.

\bibitem{yang2024identifying}
Yu~Yang, Eric Gan, Gintare~Karolina Dziugaite, and Baharan Mirzasoleiman.
\newblock Identifying spurious biases early in training through the lens of simplicity bias.
\newblock In {\em International Conference on Artificial Intelligence and Statistics}, pages 2953--2961. PMLR, 2024.

\bibitem{ye2021procrustean}
Han-Jia Ye, De-Chuan Zhan, and Wei-Lun Chao.
\newblock Procrustean training for imbalanced deep learning.
\newblock In {\em Proceedings of the IEEE/CVF international conference on computer vision}, pages 92--102, 2021.

\end{thebibliography}
