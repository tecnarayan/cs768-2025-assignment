\begin{thebibliography}{43}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2016)Agarwal, Allen-Zhu, Bullins, Hazan, and
  Ma]{agarwal2016finding}
Naman Agarwal, Zeyuan Allen-Zhu, Brian Bullins, Elad Hazan, and Tengyu Ma.
\newblock Finding approximate local minima for nonconvex optimization in linear
  time.
\newblock \emph{arXiv preprint arXiv:1611.01146}, 2016.

\bibitem[Belkin et~al.(2014)Belkin, Rademacher, and Voss]{belkin2014basis}
Mikhail Belkin, Luis Rademacher, and James Voss.
\newblock Basis learning as an algorithmic primitive.
\newblock \emph{arXiv preprint arXiv:1411.1420}, 2014.

\bibitem[Bengio(2009)]{bengio2009learning}
Yoshua Bengio.
\newblock Learning deep architectures for {AI}.
\newblock \emph{Foundations and trends{\textregistered} in Machine Learning},
  2\penalty0 (1):\penalty0 1--127, 2009.

\bibitem[Bhojanapalli et~al.(2015)Bhojanapalli, Kyrillidis, and
  Sanghavi]{bhojanapalli2015dropping}
Srinadh Bhojanapalli, Anastasios Kyrillidis, and Sujay Sanghavi.
\newblock Dropping convexity for faster semi-definite optimization.
\newblock \emph{arXiv:1509.03917}, 2015.

\bibitem[Bhojanapalli et~al.(2016)Bhojanapalli, Neyshabur, and
  Srebro]{bhojanapalli2016global}
Srinadh Bhojanapalli, Behnam Neyshabur, and Nathan Srebro.
\newblock Global optimality of local search for low rank matrix recovery.
\newblock \emph{arXiv preprint arXiv:1605.07221}, 2016.

\bibitem[Burer and Monteiro(2003)]{burer2003nonlinear}
Samuel Burer and Renato~DC Monteiro.
\newblock A nonlinear programming algorithm for solving semidefinite programs
  via low-rank factorization.
\newblock \emph{Mathematical Programming}, 95\penalty0 (2):\penalty0 329--357,
  2003.

\bibitem[Candes and Recht(2012)]{candes2012exact}
Emmanuel Candes and Benjamin Recht.
\newblock Exact matrix completion via convex optimization.
\newblock \emph{Communications of the ACM}, 55\penalty0 (6):\penalty0 111--119,
  2012.

\bibitem[Candes and Plan(2011)]{candes2011tight}
Emmanuel~J Candes and Yaniv Plan.
\newblock Tight oracle inequalities for low-rank matrix recovery from a minimal
  number of noisy random measurements.
\newblock \emph{IEEE Transactions on Information Theory}, 57\penalty0
  (4):\penalty0 2342--2359, 2011.

\bibitem[Cand{\`e}s and Recht(2009)]{candes2009exact}
Emmanuel~J Cand{\`e}s and Benjamin Recht.
\newblock Exact matrix completion via convex optimization.
\newblock \emph{Foundations of Computational mathematics}, 9\penalty0
  (6):\penalty0 717--772, 2009.

\bibitem[Candes et~al.(2006)Candes, Romberg, and Tao]{candes2006stable}
Emmanuel~J Candes, Justin~K Romberg, and Terence Tao.
\newblock Stable signal recovery from incomplete and inaccurate measurements.
\newblock \emph{Communications on pure and applied mathematics}, 59\penalty0
  (8):\penalty0 1207--1223, 2006.

\bibitem[Cand{\`e}s et~al.(2011)Cand{\`e}s, Li, Ma, and
  Wright]{candes2011robust}
Emmanuel~J Cand{\`e}s, Xiaodong Li, Yi~Ma, and John Wright.
\newblock Robust principal component analysis?
\newblock \emph{Journal of the ACM (JACM)}, 58\penalty0 (3):\penalty0 11, 2011.

\bibitem[Carmon et~al.(2016)Carmon, Duchi, Hinder, and
  Sidford]{carmon2016accelerated}
Yair Carmon, John~C Duchi, Oliver Hinder, and Aaron Sidford.
\newblock Accelerated methods for non-convex optimization.
\newblock \emph{arXiv preprint arXiv:1611.00756}, 2016.

\bibitem[Chen and Wainwright(2015)]{chen2015fast}
Yudong Chen and Martin~J Wainwright.
\newblock Fast low-rank estimation by projected gradient descent: General
  statistical and algorithmic guarantees.
\newblock \emph{arXiv preprint arXiv:1509.03025}, 2015.

\bibitem[Davenport and Romberg(2016)]{davenport2016overview}
Mark~A Davenport and Justin Romberg.
\newblock An overview of low-rank matrix recovery from incomplete observations.
\newblock \emph{IEEE Journal of Selected Topics in Signal Processing},
  10\penalty0 (4):\penalty0 608--622, 2016.

\bibitem[Davenport et~al.(2014)Davenport, Plan, van~den Berg, and
  Wootters]{davenport20141}
Mark~A Davenport, Yaniv Plan, Ewout van~den Berg, and Mary Wootters.
\newblock 1-bit matrix completion.
\newblock \emph{Information and Inference}, 3\penalty0 (3):\penalty0 189--223,
  2014.

\bibitem[Fazel(2002)]{fazel2002matrix}
Maryam Fazel.
\newblock \emph{Matrix rank minimization with applications}.
\newblock PhD thesis, PhD thesis, Stanford University, 2002.

\bibitem[Ge et~al.(2015)Ge, Huang, Jin, and Yuan]{ge2015escaping}
Rong Ge, Furong Huang, Chi Jin, and Yang Yuan.
\newblock Escaping from saddle points---online stochastic gradient for tensor
  decomposition.
\newblock \emph{arXiv:1503.02101}, 2015.

\bibitem[Ge et~al.(2016)Ge, Lee, and Ma]{ge2016matrix}
Rong Ge, Jason~D Lee, and Tengyu Ma.
\newblock Matrix completion has no spurious local minimum.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2973--2981, 2016.

\bibitem[Hardt(2014)]{hardt2014understanding}
Moritz Hardt.
\newblock Understanding alternating minimization for matrix completion.
\newblock In \emph{FOCS 2014}. IEEE, 2014.

\bibitem[Hardt and Wootters(2014)]{hardt2014fast}
Moritz Hardt and Mary Wootters.
\newblock Fast matrix completion without the condition number.
\newblock In \emph{COLT 2014}, pages 638--678, 2014.

\bibitem[Hotelling(1933)]{hotelling1933analysis}
Harold Hotelling.
\newblock Analysis of a complex of statistical variables into principal
  components.
\newblock \emph{Journal of educational psychology}, 24\penalty0 (6):\penalty0
  417, 1933.

\bibitem[Jain et~al.(2013)Jain, Netrapalli, and Sanghavi]{jain2013low}
Prateek Jain, Praneeth Netrapalli, and Sujay Sanghavi.
\newblock Low-rank matrix completion using alternating minimization.
\newblock In \emph{Proceedings of the forty-fifth annual ACM symposium on
  Theory of computing}, pages 665--674, 2013.

\bibitem[Jin et~al.(2017)Jin, Ge, Netrapalli, Kakade, and
  Jordan]{jin2017escape}
Chi Jin, Rong Ge, Praneeth Netrapalli, Sham~M Kakade, and Michael~I Jordan.
\newblock How to escape saddle points efficiently.
\newblock \emph{arXiv preprint arXiv:1703.00887}, 2017.

\bibitem[Keshavan et~al.(2010{\natexlab{a}})Keshavan, Montanari, and
  Oh]{keshavan2010matrix}
Raghunandan~H Keshavan, Andrea Montanari, and Sewoong Oh.
\newblock Matrix completion from a few entries.
\newblock \emph{Information Theory, IEEE Transactions on}, 56\penalty0
  (6):\penalty0 2980--2998, 2010{\natexlab{a}}.

\bibitem[Keshavan et~al.(2010{\natexlab{b}})Keshavan, Montanari, and
  Oh]{keshavan2010matrixnoisy}
Raghunandan~H Keshavan, Andrea Montanari, and Sewoong Oh.
\newblock Matrix completion from noisy entries.
\newblock \emph{The Journal of Machine Learning Research}, 11:\penalty0
  2057--2078, 2010{\natexlab{b}}.

\bibitem[Koren(2009)]{koren2009bellkor}
Yehuda Koren.
\newblock The bellkor solution to the netflix grand prize.
\newblock \emph{Netflix prize documentation}, 81, 2009.

\bibitem[Lata{\l}a(2005)]{latala2005some}
Rafa{\l} Lata{\l}a.
\newblock Some estimates of norms of random matrices.
\newblock \emph{Proceedings of the American Mathematical Society}, 133\penalty0
  (5):\penalty0 1273--1282, 2005.

\bibitem[Li and Tang(2016)]{li2016nonconvex}
Qiuwei Li and Gongguo Tang.
\newblock The nonconvex geometry of low-rank matrix optimizations with general
  objective functions.
\newblock \emph{arXiv preprint arXiv:1611.03060}, 2016.

\bibitem[Li et~al.(2016)Li, Liang, and Risteski]{li2016recovery}
Yuanzhi Li, Yingyu Liang, and Andrej Risteski.
\newblock Recovery guarantee of weighted low-rank approximation via alternating
  minimization.
\newblock \emph{arXiv preprint arXiv:1602.02262}, 2016.

\bibitem[Lin et~al.(2010)Lin, Chen, and Ma]{lin2010augmented}
Zhouchen Lin, Minming Chen, and Yi~Ma.
\newblock The augmented lagrange multiplier method for exact recovery of
  corrupted low-rank matrices.
\newblock \emph{arXiv preprint arXiv:1009.5055}, 2010.

\bibitem[Nesterov and Polyak(2006)]{nesterov2006cubic}
Yurii Nesterov and Boris~T Polyak.
\newblock Cubic regularization of newton method and its global performance.
\newblock \emph{Mathematical Programming}, 108\penalty0 (1):\penalty0 177--205,
  2006.

\bibitem[Netrapalli et~al.(2014)Netrapalli, Niranjan, Sanghavi, Anandkumar, and
  Jain]{netrapalli2014non}
Praneeth Netrapalli, UN~Niranjan, Sujay Sanghavi, Animashree Anandkumar, and
  Prateek Jain.
\newblock Non-convex robust pca.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1107--1115, 2014.

\bibitem[Park et~al.(2016)Park, Kyrillidis, Caramanis, and
  Sanghavi]{park2016non}
Dohyung Park, Anastasios Kyrillidis, Constantine Caramanis, and Sujay Sanghavi.
\newblock Non-square matrix sensing without spurious local minima via the
  burer-monteiro approach.
\newblock \emph{arXiv preprint arXiv:1609.03240}, 2016.

\bibitem[Recht et~al.(2010)Recht, Fazel, and Parrilo]{recht2010guaranteed}
Benjamin Recht, Maryam Fazel, and Pablo~A Parrilo.
\newblock Guaranteed minimum-rank solutions of linear matrix equations via
  nuclear norm minimization.
\newblock \emph{SIAM review}, 52\penalty0 (3):\penalty0 471--501, 2010.

\bibitem[Rennie and Srebro(2005)]{rennie2005fast}
Jasson~DM Rennie and Nathan Srebro.
\newblock Fast maximum margin matrix factorization for collaborative
  prediction.
\newblock In \emph{Proceedings of the 22nd international conference on Machine
  learning}, pages 713--719. ACM, 2005.

\bibitem[Sun et~al.(2015{\natexlab{a}})Sun, Qu, and Wright]{sun2015complete1}
Ju~Sun, Qing Qu, and John Wright.
\newblock Complete dictionary recovery over the sphere {I}: Overview and the
  geometric picture.
\newblock \emph{arXiv:1511.03607}, 2015{\natexlab{a}}.

\bibitem[Sun et~al.(2015{\natexlab{b}})Sun, Qu, and Wright]{sun2015nonconvex}
Ju~Sun, Qing Qu, and John Wright.
\newblock When are nonconvex problems not scary?
\newblock \emph{arXiv preprint arXiv:1510.06096}, 2015{\natexlab{b}}.

\bibitem[Sun and Luo(2015)]{sun2015guaranteed}
Ruoyu Sun and Zhi-Quan Luo.
\newblock Guaranteed matrix completion via nonconvex factorization.
\newblock In \emph{Foundations of Computer Science (FOCS), 2015 IEEE 56th
  Annual Symposium on}, pages 270--289. IEEE, 2015.

\bibitem[Tu et~al.(2015)Tu, Boczar, Soltanolkotabi, and Recht]{tu2015low}
Stephen Tu, Ross Boczar, Mahdi Soltanolkotabi, and Benjamin Recht.
\newblock Low-rank solutions of linear matrix equations via procrustes flow.
\newblock \emph{arXiv preprint arXiv:1507.03566}, 2015.

\bibitem[Yi et~al.(2016)Yi, Park, Chen, and Caramanis]{yi2016fast}
Xinyang Yi, Dohyung Park, Yudong Chen, and Constantine Caramanis.
\newblock Fast algorithms for robust pca via gradient descent.
\newblock In \emph{Advances in neural information processing systems}, pages
  4152--4160, 2016.

\bibitem[Zhang et~al.(2017)Zhang, Wang, and Gu]{zhang2017nonconvex}
Xiao Zhang, Lingxiao Wang, and Quanquan Gu.
\newblock A nonconvex free lunch for low-rank plus sparse matrix recovery.
\newblock \emph{arXiv preprint arXiv:1702.06525}, 2017.

\bibitem[Zhao et~al.(2015)Zhao, Wang, and Liu]{zhao2015nonconvex}
Tuo Zhao, Zhaoran Wang, and Han Liu.
\newblock A nonconvex optimization framework for low rank matrix estimation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  559--567, 2015.

\bibitem[Zheng and Lafferty(2016)]{zheng2016convergence}
Qinqing Zheng and John Lafferty.
\newblock Convergence analysis for rectangular matrix completion using
  burer-monteiro factorization and gradient descent.
\newblock \emph{arXiv preprint arXiv:1605.07051}, 2016.

\end{thebibliography}
