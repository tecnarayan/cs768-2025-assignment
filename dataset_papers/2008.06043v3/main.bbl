\begin{thebibliography}{49}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2020)Agarwal, Schuurmans, and
  Norouzi]{agarwal2020optimistic}
Rishabh Agarwal, Dale Schuurmans, and Mohammad Norouzi.
\newblock An optimistic perspective on offline reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Arnold et~al.(2021)Arnold, Iqbal, and Sha]{arnold2021when}
S{\'e}bastien M.~R. Arnold, Shariq Iqbal, and Fei Sha.
\newblock When maml can adapt fast and how to assist when it cannot.
\newblock In Arindam Banerjee and Kenji Fukumizu, editors, \emph{Proceedings of
  The 24th International Conference on Artificial Intelligence and Statistics},
  volume 130 of \emph{Proceedings of Machine Learning Research}, pages
  244--252. PMLR, 13--15 Apr 2021.
\newblock URL \url{http://proceedings.mlr.press/v130/arnold21a.html}.

\bibitem[Bechtle et~al.(2019)Bechtle, Molchanov, Chebotar, Grefenstette,
  Righetti, Sukhatme, and Meier]{bechtle2019meta}
Sarah Bechtle, Artem Molchanov, Yevgen Chebotar, Edward Grefenstette, Ludovic
  Righetti, Gaurav Sukhatme, and Franziska Meier.
\newblock Meta-learning via learned loss.
\newblock \emph{arXiv preprint arXiv:1906.05374}, 2019.

\bibitem[Bengio et~al.(1992)Bengio, Bengio, Cloutier, and
  Gecsei]{bengio1992optimization}
Samy Bengio, Yoshua Bengio, Jocelyn Cloutier, and Jan Gecsei.
\newblock On the optimization of a synaptic learning rule.
\newblock In \emph{Preprints Conf. Optimality in Artificial and Biological
  Neural Networks}, volume~2. Univ. of Texas, 1992.

\bibitem[Deleu et~al.(2019)Deleu, W\"urfl, Samiei, Cohen, and
  Bengio]{deleu2019torchmeta}
Tristan Deleu, Tobias W\"urfl, Mandana Samiei, Joseph~Paul Cohen, and Yoshua
  Bengio.
\newblock {Torchmeta: A Meta-Learning library for PyTorch}, 2019.
\newblock URL \url{https://arxiv.org/abs/1909.06576}.
\newblock Available at: https://github.com/tristandeleu/pytorch-meta.

\bibitem[Dorfman and Tamar(2020)]{dorfman2020offline}
Ron Dorfman and Aviv Tamar.
\newblock Offline meta reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2008.02598}, 2020.

\bibitem[Duan et~al.(2016)Duan, Schulman, Chen, Bartlett, Sutskever, and
  Abbeel]{duan2016rl}
Yan Duan, John Schulman, Xi~Chen, Peter~L Bartlett, Ilya Sutskever, and Pieter
  Abbeel.
\newblock Rl2: Fast reinforcement learning via slow reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.02779}, 2016.

\bibitem[Fakoor et~al.(2020)Fakoor, Chaudhari, Soatto, and
  Smola]{fakoor2019meta}
Rasool Fakoor, Pratik Chaudhari, Stefano Soatto, and Alexander~J. Smola.
\newblock Meta-q-learning.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Finn and Levine(2018)]{finn2017universality}
Chelsea Finn and Sergey Levine.
\newblock Meta-learning and universality: Deep representations and gradient
  descent can approximate any learning algorithm.
\newblock \emph{International Conference on Learning Representations}, 10 2018.

\bibitem[Finn et~al.(2017{\natexlab{a}})Finn, Abbeel, and
  Levine]{finn2017model}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International Conference on Machine Learning},
  2017{\natexlab{a}}.

\bibitem[Finn et~al.(2017{\natexlab{b}})Finn, Yu, Zhang, Abbeel, and
  Levine]{finn2017one}
Chelsea Finn, Tianhe Yu, Tianhao Zhang, Pieter Abbeel, and Sergey Levine.
\newblock One-shot visual imitation learning via meta-learning.
\newblock \emph{CoRL}, abs/1709.04905, 2017{\natexlab{b}}.
\newblock URL \url{http://arxiv.org/abs/1709.04905}.

\bibitem[Finn(2018)]{finn2018thesis}
Chelsea~B Finn.
\newblock \emph{Learning to Learn with Gradients}.
\newblock University of California, Berkeley, 2018.

\bibitem[Fujimoto et~al.(2018)Fujimoto, Hoof, and
  Meger]{fujimoto2018addressing}
Scott Fujimoto, Herke Hoof, and David Meger.
\newblock Addressing function approximation error in actor-critic methods.
\newblock In \emph{International Conference on Machine Learning}, pages
  1582--1591, 2018.

\bibitem[Fujimoto et~al.(2019)Fujimoto, Meger, and Precup]{fujimoto19bcq}
Scott Fujimoto, David Meger, and Doina Precup.
\newblock Off-policy deep reinforcement learning without exploration.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors,
  \emph{Proceedings of the 36th International Conference on Machine Learning},
  volume~97 of \emph{Proceedings of Machine Learning Research}, pages
  2052--2062, Long Beach, California, USA, 09--15 Jun 2019. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v97/fujimoto19a.html}.

\bibitem[Grefenstette et~al.(2019)Grefenstette, Amos, Yarats, Htut, Molchanov,
  Meier, Kiela, Cho, and Chintala]{grefenstette2019generalized}
Edward Grefenstette, Brandon Amos, Denis Yarats, Phu~Mon Htut, Artem Molchanov,
  Franziska Meier, Douwe Kiela, Kyunghyun Cho, and Soumith Chintala.
\newblock Generalized inner loop meta-learning.
\newblock \emph{arXiv preprint arXiv:1910.01727}, 2019.

\bibitem[Gupta et~al.(2018)Gupta, Mendonca, Liu, Abbeel, and
  Levine]{gupta2018meta_arxiv}
Abhishek Gupta, Russell Mendonca, YuXuan Liu, Pieter Abbeel, and Sergey Levine.
\newblock Meta-reinforcement learning of structured exploration strategies.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5302--5311, 2018.

\bibitem[Ha et~al.(2016)Ha, Dai, and Le]{ha2016hypernetworks}
David Ha, Andrew Dai, and Quoc~V. Le.
\newblock Hypernetworks, 2016.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Abbeel, and
  Levine]{haarnoja2018soft}
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock \emph{arXiv preprint arXiv:1801.01290}, 2018.

\bibitem[Houthooft et~al.(2018)Houthooft, Chen, Isola, Stadie, Wolski, Ho, and
  Abbeel]{houthooft2018evolved}
Rein Houthooft, Yuhua Chen, Phillip Isola, Bradly Stadie, Filip Wolski,
  OpenAI~Jonathan Ho, and Pieter Abbeel.
\newblock Evolved policy gradients.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5400--5409, 2018.

\bibitem[Humplik et~al.(2019)Humplik, Galashov, Hasenclever, Ortega, Teh, and
  Heess]{humplik2019meta}
Jan Humplik, Alexandre Galashov, Leonard Hasenclever, Pedro~A Ortega, Yee~Whye
  Teh, and Nicolas Heess.
\newblock Meta reinforcement learning as task inference.
\newblock \emph{arXiv preprint arXiv:1905.06424}, 2019.

\bibitem[Jaques et~al.(2019)Jaques, Ghandeharioun, Shen, Ferguson, Lapedriza,
  Jones, Gu, and Picard]{jaques2019way}
Natasha Jaques, Asma Ghandeharioun, Judy~Hanwen Shen, Craig Ferguson, Agata
  Lapedriza, Noah Jones, Shixiang Gu, and Rosalind Picard.
\newblock Way off-policy batch deep reinforcement learning of implicit human
  preferences in dialog.
\newblock \emph{arXiv preprint arXiv:1907.00456}, 2019.

\bibitem[Kingma and Ba(2015)]{DBLP:journals/corr/KingmaB14}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In Yoshua Bengio and Yann LeCun, editors, \emph{3rd International
  Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May
  7-9, 2015, Conference Track Proceedings}, 2015.
\newblock URL \url{http://arxiv.org/abs/1412.6980}.

\bibitem[Kirsch et~al.(2020)Kirsch, van Steenkiste, and
  Schmidhuber]{Kirsch2020Improving}
Louis Kirsch, Sjoerd van Steenkiste, and Juergen Schmidhuber.
\newblock Improving generalization in meta reinforcement learning using learned
  objectives.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=S1evHerYPr}.

\bibitem[Kumar et~al.(2019{\natexlab{a}})Kumar, Fu, Soh, Tucker, and
  Levine]{bear}
Aviral Kumar, Justin Fu, Matthew Soh, George Tucker, and Sergey Levine.
\newblock Stabilizing off-policy q-learning via bootstrapping error reduction.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  11761--11771, 2019{\natexlab{a}}.

\bibitem[Kumar et~al.(2019{\natexlab{b}})Kumar, Fu, Tucker, and
  Levine]{kumar19bear}
Aviral Kumar, Justin Fu, George Tucker, and Sergey Levine.
\newblock Stabilizing off-policy q-learning via bootstrapping error reduction.
\newblock \emph{NeurIPS}, 2019{\natexlab{b}}.
\newblock URL \url{http://arxiv.org/abs/1906.00949}.

\bibitem[Lake et~al.(2015)Lake, Salakhutdinov, and Tenenbaum]{Lake2015human}
B.~M. Lake, R.~Salakhutdinov, and J.~B. Tenenbaum.
\newblock Human-level concept learning through probabilistic program induction.
\newblock \emph{Science}, 350\penalty0 (6266):\penalty0 1332--1338, December
  2015.
\newblock \doi{10.1126/science.aab3050}.
\newblock URL \url{https://doi.org/10.1126/science.aab3050}.

\bibitem[Levine et~al.(2020)Levine, Kumar, Tucker, and Fu]{levine2020offline}
Sergey Levine, Aviral Kumar, George Tucker, and Justin Fu.
\newblock Offline reinforcement learning: Tutorial, review, and perspectives on
  open problems.
\newblock \emph{arXiv preprint arXiv:2005.01643}, 2020.

\bibitem[Luna~Gutierrez and Leonetti(2020)]{gutierrez2020information}
Ricardo Luna~Gutierrez and Matteo Leonetti.
\newblock Information-theoretic task selection for meta-reinforcement learning.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~33,
  pages 20532--20542. Curran Associates, Inc., 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/file/ec3183a7f107d1b8dbb90cb3c01ea7d5-Paper.pdf}.

\bibitem[Mendonca et~al.(2019)Mendonca, Gupta, Kralev, Abbeel, Levine, and
  Finn]{mendonca2019guided}
Russell Mendonca, Abhishek Gupta, Rosen Kralev, Pieter Abbeel, Sergey Levine,
  and Chelsea Finn.
\newblock Guided meta-policy search.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  9653--9664, 2019.

\bibitem[Mishra et~al.(2017)Mishra, Rohaninejad, Chen, and
  Abbeel]{mishra2017meta-learning}
Nikhil Mishra, Mostafa Rohaninejad, Xi~Chen, and Pieter Abbeel.
\newblock Meta-learning with temporal convolutions.
\newblock \emph{arXiv:1707.03141}, 2017.

\bibitem[Nagabandi et~al.(2019)Nagabandi, Clavera, Liu, Fearing, Abbeel,
  Levine, and Finn]{nagabandi2018learning}
Anusha Nagabandi, Ignasi Clavera, Simin Liu, Ronald~S Fearing, Pieter Abbeel,
  Sergey Levine, and Chelsea Finn.
\newblock Learning to adapt in dynamic, real-world environments through
  meta-reinforcement learning.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2019.

\bibitem[Nair et~al.(2020)Nair, Dalal, Gupta, and Levine]{nair2020accelerating}
Ashvin Nair, Murtaza Dalal, Abhishek Gupta, and Sergey Levine.
\newblock Accelerating online reinforcement learning with offline datasets,
  2020.

\bibitem[Peng et~al.(2019)Peng, Kumar, Zhang, and Levine]{peng2019awr}
Xue~Bin Peng, Aviral Kumar, Grace Zhang, and Sergey Levine.
\newblock Advantage-weighted regression: Simple and scalable off-policy
  reinforcement learning, 2019.

\bibitem[Peters and Schaal(2007)]{rwr}
Jan Peters and Stefan Schaal.
\newblock Reinforcement learning by reward-weighted regression for operational
  space control.
\newblock In \emph{Proceedings of the 24th International Conference on Machine
  Learning}, ICML ’07, page 745–750, New York, NY, USA, 2007. Association
  for Computing Machinery.
\newblock ISBN 9781595937933.
\newblock \doi{10.1145/1273496.1273590}.
\newblock URL \url{https://doi.org/10.1145/1273496.1273590}.

\bibitem[Rajeswaran et~al.(2019)Rajeswaran, Finn, Kakade, and
  Levine]{rajeswaran2019meta}
Aravind Rajeswaran, Chelsea Finn, Sham~M Kakade, and Sergey Levine.
\newblock Meta-learning with implicit gradients.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  113--124, 2019.

\bibitem[Rakelly et~al.(2019)Rakelly, Zhou, Quillen, Finn, and
  Levine]{rakelly2019efficient}
Kate Rakelly, Aurick Zhou, Deirdre Quillen, Chelsea Finn, and Sergey Levine.
\newblock Efficient off-policy meta-reinforcement learning via probabilistic
  context variables.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Rothfuss et~al.(2018)Rothfuss, Lee, Clavera, Asfour, and
  Abbeel]{rothfuss2018promp}
Jonas Rothfuss, Dennis Lee, Ignasi Clavera, Tamim Asfour, and Pieter Abbeel.
\newblock Promp: Proximal meta-policy search.
\newblock \emph{arXiv preprint arXiv:1810.06784}, 2018.

\bibitem[Rusu et~al.(2019)Rusu, Rao, Sygnowski, Vinyals, Pascanu, Osindero, and
  Hadsell]{rusu2018metalearning}
Andrei~A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu,
  Simon Osindero, and Raia Hadsell.
\newblock Meta-learning with latent embedding optimization.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=BJgklhAcK7}.

\bibitem[S{\ae}mundsson et~al.(2018)S{\ae}mundsson, Hofmann, and
  Deisenroth]{saemundsson2018meta}
Steind{\'o}r S{\ae}mundsson, Katja Hofmann, and Marc~Peter Deisenroth.
\newblock Meta reinforcement learning with latent variable gaussian processes.
\newblock \emph{arXiv preprint arXiv:1803.07551}, 2018.

\bibitem[Schmidhuber(1987)]{schmidhuber1987evolutionary}
Jurgen Schmidhuber.
\newblock Evolutionary principles in self-referential learning.
\newblock \emph{On learning how to learn: The meta-meta-... hook.) Diploma
  thesis, Institut f. Informatik, Tech. Univ. Munich}, 1:\penalty0 2, 1987.

\bibitem[Thrun and Pratt(1998)]{thrun1998learning}
Sebastian Thrun and Lorien Pratt.
\newblock Learning to learn: Introduction and overview.
\newblock In \emph{Learning to learn}, pages 3--17. Springer, 1998.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Kavukcuoglu, and
  Wierstra]{vinyals2016matching}
Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Koray Kavukcuoglu, and Daan
  Wierstra.
\newblock Matching networks for one shot learning.
\newblock In D.~Lee, M.~Sugiyama, U.~Luxburg, I.~Guyon, and R.~Garnett,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~29,
  pages 3630--3638. Curran Associates, Inc., 2016.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2016/file/90e1357833654983612fb05e3ec9148c-Paper.pdf}.

\bibitem[Wang et~al.(2016)Wang, Kurth-Nelson, Tirumala, Soyer, Leibo, Munos,
  Blundell, Kumaran, and Botvinick]{wang2016learning}
Jane~X Wang, Zeb Kurth-Nelson, Dhruva Tirumala, Hubert Soyer, Joel~Z Leibo,
  Remi Munos, Charles Blundell, Dharshan Kumaran, and Matt Botvinick.
\newblock Learning to reinforcement learn.
\newblock \emph{arXiv preprint arXiv:1611.05763}, 2016.

\bibitem[Wu et~al.(2019)Wu, Tucker, and Nachum]{brac}
Yifan Wu, George Tucker, and Ofir Nachum.
\newblock Behavior regularized offline reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1911.11361}, 2019.

\bibitem[Wu et~al.(2018)Wu, Ren, Liao, and Grosse]{wu2018understanding}
Yuhuai Wu, Mengye Ren, Renjie Liao, and Roger Grosse.
\newblock Understanding short-horizon bias in stochastic meta-optimization.
\newblock \emph{arXiv preprint arXiv:1803.02021}, 2018.

\bibitem[Yang et~al.(2019)Yang, Caluwaerts, Iscen, Tan, and
  Finn]{yang2019norml}
Yuxiang Yang, Ken Caluwaerts, Atil Iscen, Jie Tan, and Chelsea Finn.
\newblock Norml: No-reward meta learning.
\newblock In \emph{Proceedings of the 18th International Conference on
  Autonomous Agents and MultiAgent Systems}, pages 323--331. International
  Foundation for Autonomous Agents and Multiagent Systems, 2019.

\bibitem[Yu et~al.(2019)Yu, Quillen, He, Julian, Hausman, Finn, and
  Levine]{yu2019metaworld}
Tianhe Yu, Deirdre Quillen, Zhanpeng He, Ryan Julian, Karol Hausman, Chelsea
  Finn, and Sergey Levine.
\newblock Meta-world: A benchmark and evaluation for multi-task and meta
  reinforcement learning.
\newblock In \emph{Conference on Robot Learning}, 2019.

\bibitem[Zintgraf et~al.(2020)Zintgraf, Shiarlis, Igl, Schulze, Gal, Hofmann,
  and Whiteson]{zintgraf2019varibad}
Luisa Zintgraf, Kyriacos Shiarlis, Maximilian Igl, Sebastian Schulze, Yarin
  Gal, Katja Hofmann, and Shimon Whiteson.
\newblock Varibad: A very good method for bayes-adaptive deep rl via
  meta-learning.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Zintgraf et~al.(2019)Zintgraf, Shiarlis, Kurin, Hofmann, and
  Whiteson]{zintgraf2018fast}
Luisa~M Zintgraf, Kyriacos Shiarlis, Vitaly Kurin, Katja Hofmann, and Shimon
  Whiteson.
\newblock Fast context adaptation via meta-learning.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\end{thebibliography}
