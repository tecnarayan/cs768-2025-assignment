@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}


@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={22--31},
  year={2017},
  organization={JMLR. org}
}

@article{konyushkova2020semi,
  title={Semi-supervised reward learning for offline reinforcement learning},
  author={Konyushkova, Ksenia and Zolna, Konrad and Aytar, Yusuf and Novikov, Alexander and Reed, Scott and Cabi, Serkan and de Freitas, Nando},
  journal={arXiv preprint arXiv:2012.06899},
  year={2020}
}

@inproceedings{chebotar2017path,
  title={Path integral guided policy search},
  author={Chebotar, Yevgen and Kalakrishnan, Mrinal and Yahya, Ali and Li, Adrian and Schaal, Stefan and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3381--3388},
  year={2017},
  organization={IEEE}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{singh2020cog,
  title={Cog: Connecting new skills to past experience with offline reinforcement learning},
  author={Singh, Avi and Yu, Albert and Yang, Jonathan and Zhang, Jesse and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2010.14500},
  year={2020}
}

@article{yu2021conservative,
  title={Conservative Data Sharing for Multi-Task Offline Reinforcement Learning},
  author={Yu, Tianhe and Kumar, Aviral and Chebotar, Yevgen and Hausman, Karol and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2109.08128},
  year={2021}
}

@article{eysenbach2021replacing,
  title={Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification},
  author={Eysenbach, Benjamin and Levine, Sergey and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2103.12656},
  year={2021}
}

@article{fu2018variational,
  title={Variational inverse control with events: A general framework for data-driven reward definition},
  author={Fu, Justin and Singh, Avi and Ghosh, Dibya and Yang, Larry and Levine, Sergey},
  journal={arXiv preprint arXiv:1805.11686},
  year={2018}
}

@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}

@inproceedings{yu2020meta,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@article{kalashnikov2021mt,
  title={MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale},
  author={Kalashnikov, Dmitry and Varley, Jacob and Chebotar, Yevgen and Swanson, Benjamin and Jonschkowski, Rico and Finn, Chelsea and Levine, Sergey and Hausman, Karol},
  journal={Conference on Robot Learning (CoRL)},
  year={2021}
}

@inproceedings{lee2019SLAC,
  title={Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model
},
  author={Alex X. Lee and Anusha Nagabandi and Pieter Abbeel and Sergey Levine},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}


@inproceedings{Hafner2019PlanNet,
  title={International Conference on Machine
Learning},
  author={Danijar Hafner and Timothy Lillicrap and Ian Fischer and Ruben Villegas and David Ha and Honglak Lee and James Davidson},
  booktitle={ International Conference on Machine
Learning},
  year={2019}
}

@article{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@article{liu2020provably,
  title={Provably good batch reinforcement learning without great exploration},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={arXiv preprint arXiv:2007.08202},
  year={2020}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul and Leike, Jan and Brown, Tom B and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={arXiv preprint arXiv:1706.03741},
  year={2017}
}

@article{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Van Hoof, Herke and Meger, David},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}

@article{fujimoto2018off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  journal={arXiv preprint arXiv:1812.02900},
  year={2018}
}

@inproceedings{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11761--11771},
  year={2019}
}

@article{wu2019behavior,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{jaques2019way,
  title={Way off-policy batch deep reinforcement learning of implicit human preferences in dialog},
  author={Jaques, Natasha and Ghandeharioun, Asma and Shen, Judy Hanwen and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang and Picard, Rosalind},
  journal={arXiv preprint arXiv:1907.00456},
  year={2019}
}

@article{nachum2019algaedice,
  title={AlgaeDICE: Policy Gradient from Arbitrary Experience},
  author={Nachum, Ofir and Dai, Bo and Kostrikov, Ilya and Chow, Yinlam and Li, Lihong and Schuurmans, Dale},
  journal={arXiv preprint arXiv:1912.02074},
  year={2019}
}

@article{peng2019advantage,
  title={Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@article{siegel2020keep,
  title={Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning},
  author={Siegel, Noah Y and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Riedmiller, Martin},
  journal={arXiv preprint arXiv:2002.08396},
  year={2020}
}

@inproceedings{janner2019trust,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12498--12509},
  year={2019}
}

@article{luo2018algorithmic,
  title={Algorithmic framework for model-based deep reinforcement learning with theoretical guarantees},
  author={Luo, Yuping and Xu, Huazhe and Li, Yuanzhi and Tian, Yuandong and Darrell, Trevor and Ma, Tengyu},
  journal={arXiv preprint arXiv:1807.03858},
  year={2018}
}

@article{agarwal2019striving,
  title={Striving for simplicity in off-policy deep reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1907.04543},
  year={2019}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{balaji2017ensemble,
author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
title = {Simple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {6405–6416},
numpages = {12},
location = {Long Beach, California, USA},
series = {NIPS’17}
}

@inproceedings{precup2001off,
  title={Off-policy temporal-difference learning with function approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={ICML},
  pages={417--424},
  year={2001}
}

@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1054--1062},
  year={2016}
}

@article{ajksbook,
  title={Reinforcement learning: Theory and algorithms},
  author={Agarwal, Alekh and Jiang, Nan and Kakade, Sham M},
  journal={CS Dept., UW Seattle, Seattle, WA, USA, Tech. Rep},
  year={2019}
}

@misc{fu2020d4rl,
    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},
    year={2020},
    eprint={2004.07219},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{fujimoto2019benchmarking,
  title={Benchmarking Batch Deep Reinforcement Learning Algorithms},
  author={Fujimoto, Scott and Conti, Edoardo and Ghavamzadeh, Mohammad and Pineau, Joelle},
  journal={arXiv preprint arXiv:1910.01708},
  year={2019}
}

@article{sutton1991dyna,
  title={Dyna, an integrated architecture for learning, planning, and reacting},
  author={Sutton, Richard S},
  journal={ACM Sigart Bulletin},
  volume={2},
  number={4},
  pages={160--163},
  year={1991},
  publisher={ACM New York, NY, USA}
}

@InCollection{LangeGR12,
	title =	"Batch Reinforcement Learning",
	author =	"Sascha Lange and Thomas Gabel and Martin A.
	Riedmiller",
	booktitle =	"Reinforcement Learning",
	publisher =	"Springer",
	year = 	"2012",
	volume =	"12",
}

@Article{LiuSAB19,
  title =	"Off-Policy Policy Gradient with State Distribution
		 Correction",
  author =	"Yao Liu and Adith Swaminathan and Alekh Agarwal
		 and Emma Brunskill",
  journal =	"CoRR",
  year = 	"2019",
  volume =	"abs/1904.08473",
}

@Article{SwaminathanJ15,
	title =	"Batch learning from logged bandit feedback through
	counterfactual risk minimization",
	author =	"Adith Swaminathan and Thorsten Joachims",
	journal =	"J. Mach. Learn. Res",
	year = 	"2015",
	volume =	"16",
	pages =	"1731--1755",
}

@article{Liu2020ProvablyGB,
  title={Provably Good Batch Reinforcement Learning Without Great Exploration},
  author={Yao Liu and A. Swaminathan and A. Agarwal and Emma Brunskill},
  journal={ArXiv},
  year={2020},
  volume={abs/2007.08202}
}

@article{argenson2020model,
  title={Model-Based Offline Planning},
  author={Argenson, Arthur and Dulac-Arnold, Gabriel},
  journal={arXiv preprint arXiv:2008.05556},
  year={2020}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{kidambi2020morel,
  title={MOReL: Model-Based Offline Reinforcement Learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={arXiv preprint arXiv:2005.05951},
  year={2020}
}

@article{matsushima2020deployment,
  title={Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization},
  author={Matsushima, Tatsuya and Furuta, Hiroki and Matsuo, Yutaka and Nachum, Ofir and Gu, Shixiang},
  journal={arXiv preprint arXiv:2006.03647},
  year={2020}
}

@article{wang2020critic,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and {\.Z}o{\l}na, Konrad and Springenberg, Jost Tobias and Reed, Scott and Shahriari, Bobak and Siegel, Noah and Merel, Josh and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={arXiv preprint arXiv:2006.15134},
  year={2020}
}

@article{yu2020mopo,
  title={MOPO: Model-based Offline Policy Optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={arXiv preprint arXiv:2005.13239},
  year={2020}
}

@article{zhanggendice,
  title={GenDICE: Generalized offline estimation of stationary values, 2020},
  author={Zhang, Ruiyi and Dai, Bo and Lihong, Li and Schuurmans, Dale},
  journal={Preprint}
}

@inproceedings{chua2018deep,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4754--4765},
  year={2018}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@phdthesis{thomas2015safe,
  title={Safe reinforcement learning},
  author={Thomas, Philip S},
  year={2015},
  school={University of Massachusetts Libraries}
}

@inproceedings{agarwal2020optimistic,
  title={An optimistic perspective on offline reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={104--114},
  year={2020},
  organization={PMLR}
}

@article{Wang2018SupervisedRL,
  title={Supervised Reinforcement Learning with Recurrent Neural Network for Dynamic Treatment Recommendation},
  author={L. Wang and Wei Zhang and Xiaofeng He and H. Zha},
  journal={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  year={2018}
}

@article{Rafailov2020LOMPO,
  title={Offline Reinforcement Learning from Images with Latent Space Models},
  author={Rafael Rafailov and Tianhe Yu and A. Rajeswaran and Chelsea Finn},
  journal={Learning for Decision Making and Control (L4DC)},
  year={2021},
}

@article{Buckman2020TheIO,
  title={The Importance of Pessimism in Fixed-Dataset Policy Optimization},
  author={J. Buckman and Carles Gelada and Marc G. Bellemare},
  journal={ArXiv},
  year={2020},
  volume={abs/2009.06799}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  pages={503--556},
  year={2005},
  publisher={Microtome Publishing}
}

@inproceedings{riedmiller2005neural,
  title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
  author={Riedmiller, Martin},
  booktitle={European Conference on Machine Learning},
  pages={317--328},
  year={2005},
  organization={Springer}
}

@article{rafailov2020offline,
  title={Offline Reinforcement Learning from Images with Latent Space Models},
  author={Rafailov, Rafael and Yu, Tianhe and Rajeswaran, Aravind and Finn, Chelsea},
  journal={arXiv preprint arXiv:2012.11547},
  year={2020}
}

@article{singh2020parrot,
  title={Parrot: Data-Driven Behavioral Priors for Reinforcement Learning},
  author={Singh, Avi and Liu, Huihan and Zhou, Gaoyue and Yu, Albert and Rhinehart, Nicholas and Levine, Sergey},
  journal={arXiv preprint arXiv:2011.10024},
  year={2020}
}

@article{xie2019improvisation,
  title={Improvisation through physical understanding: Using novel objects as tools with visual foresight},
  author={Xie, Annie and Ebert, Frederik and Levine, Sergey and Finn, Chelsea},
  journal={Robotics: Science and Systems (RSS)},
  year={2019}
}

@article{jaques2020human,
  title={Human-centric dialog training via offline reinforcement learning},
  author={Jaques, Natasha and Shen, Judy Hanwen and Ghandeharioun, Asma and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang Shane and Picard, Rosalind},
  journal={arXiv preprint arXiv:2010.05848},
  year={2020}
}

@article{kumar2020discor,
  title={DisCor: Corrective Feedback in Reinforcement Learning via Distribution Correction},
  author={Kumar, Aviral and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2003.07305},
  year={2020}
}

@article{dorfman2020offline,
  title={Offline meta reinforcement learning},
  author={Dorfman, Ron and Tamar, Aviv},
  journal={arXiv preprint arXiv:2008.02598},
  year={2020}
}

@article{sutton2016emphatic,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@article{raghu2017deep,
  title={Deep reinforcement learning for sepsis treatment},
  author={Raghu, Aniruddh and Komorowski, Matthieu and Ahmed, Imran and Celi, Leo and Szolovits, Peter and Ghassemi, Marzyeh},
  journal={arXiv preprint arXiv:1711.09602},
  year={2017}
}

@article{shortreed2011informing,
  title={Informing sequential clinical decision-making through reinforcement learning: an empirical study},
  author={Shortreed, Susan M and Laber, Eric and Lizotte, Daniel J and Stroup, T Scott and Pineau, Joelle and Murphy, Susan A},
  journal={Machine learning},
  volume={84},
  number={1-2},
  pages={109--136},
  year={2011},
  publisher={Springer}
}

@inproceedings{pinto2016supersizing,
  title={Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours},
  author={Pinto, Lerrel and Gupta, Abhinav},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={3406--3413},
  year={2016},
  organization={IEEE}
}

@inproceedings{kalashnikov2018scalable,
  title={Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={Conference on Robot Learning},
  pages={651--673},
  year={2018},
  organization={PMLR}
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robot motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}

@article{oh2015action,
  title={Action-conditional video prediction using deep networks in atari games},
  author={Oh, Junhyuk and Guo, Xiaoxiao and Lee, Honglak and Lewis, Richard and Singh, Satinder},
  journal={arXiv preprint arXiv:1507.08750},
  year={2015}
}

@article{kaiser2019model,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@InProceedings{RossB12,
  title =	"Agnostic System Identification for Model-Based Reinforcement Learning",
  author =	"Stephane Ross and Drew Bagnell",
  year = 	"2012",
  booktitle =	"ICML",
}

@INPROCEEDINGS{Rajeswaran-Game-MBRL,
    AUTHOR    = {Aravind Rajeswaran AND Igor Mordatch AND Vikash Kumar},
    TITLE     = "{A Game Theoretic Framework for
Model-Based Reinforcement Learning}",
    BOOKTITLE = {ICML},
    YEAR      = {2020},
}

@article{Abdolmaleki2018MaximumAP,
  title={Maximum a Posteriori Policy Optimisation},
  author={Abbas Abdolmaleki and Jost Tobias Springenberg and Y. Tassa and R. Munos and N. Heess and Martin A. Riedmiller},
  journal={ArXiv},
  year={2018},
  volume={abs/1806.06920}
}

@INPROCEEDINGS{POLO,
    AUTHOR  = {Kendall Lowrey AND Aravind Rajeswaran AND Sham Kakade AND 
             Emanuel Todorov AND Igor Mordatch},
    TITLE   = "{Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control}",
    BOOKTITLE = "{International Conference on Learning Representations (ICLR)}",
    YEAR      = {2019},
}

@inproceedings{Todorov2005,
  title={A generalized iterative LQG method for locally-optimal feedback control of constrained nonlinear stochastic systems},
  author={Emanuel Todorov and Weiwei Li},
  booktitle={ACC},
  year={2005},
}

@article{WilliamsMPPI,
  title={Information theoretic MPC for model-based reinforcement learning},
  author={Grady Williams and Nolan Wagener and Brian Goldfain and Paul Drews and James M. Rehg and Byron Boots and Evangelos Theodorou},
  journal={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2017},
  pages={1714-1721}
}

@Misc{RRT,
  title =	"Rapidly-Exploring Random Trees: A New Tool for Path Planning",
  author =	"Steven M. Lavalle",
  year = 	"1998",
}

@article{Nagabandi2019DeepDM,
  title={Deep Dynamics Models for Learning Dexterous Manipulation},
  author={Anusha Nagabandi and K. Konolige and S. Levine and V. Kumar},
  journal={ArXiv},
  year={2019},
  volume={abs/1909.11652}
}

@Article{OsbandAC18,
  title =	"Randomized Prior Functions for Deep Reinforcement Learning",
  author =	"Ian Osband and John Aslanides and Albin Cassirer",
  journal =	"CoRR",
  year = 	"2018",
  volume =	"abs/1806.03335",
}

@InProceedings{Azizzadenesheli18,
  title =	"Efficient Exploration Through Bayesian Deep
		 Q-Networks",
  author =	"Kamyar Azizzadenesheli and Emma Brunskill and
		 Animashree Anandkumar",
  publisher =	"IEEE",
  year = 	"2018",
  booktitle =	"ITA",
  pages =	"1--9",
}

@InProceedings{BurdaESK19,
  title =	"Exploration by random network distillation",
  author =	"Yuri Burda and Harrison Edwards and Amos J. Storkey and Oleg Klimov",
  publisher =	"OpenReview.net",
  year = 	"2019",
  booktitle =	"ICLR",
}

@article{Chen2019InformationTheoreticCI,
  title={Information-Theoretic Considerations in Batch Reinforcement Learning},
  author={J. Chen and Nan Jiang},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.00360}
}

@Book{BertsekasBook,
  author =	"Dimitri P. Bertsekas and John N. Tsitsiklis",
  title =	"Neuro-Dynamic Programming",
  publisher =	"Athena Scientific",
  year = 	"1996",
  address =	"Belmont, MA",
}

@Book{SuttonBook,
  author =	"R. S. Sutton and A. G. Barto",
  title =	"Reinforcement Learning: An Introduction",
  year = 	"1998",
  publisher =	"MIT Press",
  address =	"Cambridge, MA",
}

@article{Munos2008FiniteTimeBF,
  title={Finite-Time Bounds for Fitted Value Iteration},
  author={R{\'e}mi Munos and Csaba Szepesvari},
  journal={J. Mach. Learn. Res.},
  year={2008},
  volume={9},
  pages={815-857}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@inproceedings{mandlekar2020iris,
  title={Iris: Implicit reinforcement without interaction at scale for learning control from offline robot manipulation data},
  author={Mandlekar, Ajay and Ramos, Fabio and Boots, Byron and Savarese, Silvio and Fei-Fei, Li and Garg, Animesh and Fox, Dieter},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4414--4420},
  year={2020},
  organization={IEEE}
}

@article{zhou2020plas,
  title={PLAS: Latent Action Space for Offline Reinforcement Learning},
  author={Zhou, Wenxuan and Bajracharya, Sujay and Held, David},
  journal={arXiv preprint arXiv:2011.07213},
  year={2020}
}

@inproceedings{kahn2018composable,
  title={Composable action-conditioned predictors: Flexible off-policy learning for robot navigation},
  author={Kahn, Gregory and Villaflor, Adam and Abbeel, Pieter and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={806--816},
  year={2018},
  organization={PMLR}
}

@article{Yu2020BDD100KAD,
  title={BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning},
  author={F. Yu and H. Chen and X. Wang and Wenqi Xian and Yingying Chen and Fangchen Liu and V. Madhavan and Trevor Darrell},
  journal={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020},
  pages={2633-2642}
}

@inproceedings{
lee2021representation,
title={Representation Balancing Offline Model-based Reinforcement Learning},
author={Byung-Jun Lee and Jongmin Lee and Kee-Eung Kim},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=QpNz8r_Ri2Y}
}

@article{swazinna2020overcoming,
  title={Overcoming Model Bias for Robust Offline Deep Reinforcement Learning},
  author={Swazinna, Phillip and Udluft, Steffen and Runkler, Thomas},
  journal={arXiv preprint arXiv:2008.05533},
  year={2020}
}

@article{tassa2018deepmind,
  title={Deepmind control suite},
  author={Tassa, Yuval and Doron, Yotam and Muldal, Alistair and Erez, Tom and Li, Yazhe and Casas, Diego de Las and Budden, David and Abdolmaleki, Abbas and Merel, Josh and Lefrancq, Andrew and others},
  journal={arXiv preprint arXiv:1801.00690},
  year={2018}
}

@article{ovadia2019can,
  title={Can you trust your model's uncertainty? Evaluating predictive uncertainty under dataset shift},
  author={Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, David and Nowozin, Sebastian and Dillon, Joshua V and Lakshminarayanan, Balaji and Snoek, Jasper},
  journal={arXiv preprint arXiv:1906.02530},
  year={2019}
}

@article{degris2012off,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@inproceedings{laroche2019safe,
  title={Safe policy improvement with baseline bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Des Combes, Remi Tachet},
  booktitle={International Conference on Machine Learning},
  pages={3652--3661},
  year={2019},
  organization={PMLR}
}

@article{petrik2016safe,
  title={Safe policy improvement by minimizing robust baseline regret},
  author={Petrik, Marek and Chow, Yinlam and Ghavamzadeh, Mohammad},
  journal={arXiv preprint arXiv:1607.03842},
  year={2016}
}

@inproceedings{osband2017posterior,
  title={Why is posterior sampling better than optimism for reinforcement learning?},
  author={Osband, Ian and Van Roy, Benjamin},
  booktitle={International Conference on Machine Learning},
  pages={2701--2710},
  year={2017},
  organization={PMLR}
}

@article{jaksch2010near,
  title={Near-optimal Regret Bounds for Reinforcement Learning.},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={4},
  year={2010}
}

@misc{dasari2020robonet,
      title={RoboNet: Large-Scale Multi-Robot Learning}, 
      author={Sudeep Dasari and Frederik Ebert and Stephen Tian and Suraj Nair and Bernadette Bucher and Karl Schmeckpeper and Siddharth Singh and Sergey Levine and Chelsea Finn},
      year={2020},
      eprint={1910.11215},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@inproceedings{
kumar2021implicit,
title={Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning},
author={Aviral Kumar and Rishabh Agarwal and Dibya Ghosh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=O9bnihsFfXU}
}

@article{eysenbach2020rewriting,
  title={Rewriting history with inverse rl: Hindsight inference for policy improvement},
  author={Eysenbach, Benjamin and Geng, Xinyang and Levine, Sergey and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2002.11089},
  year={2020}
}

@article{li2020generalized,
  title={Generalized hindsight for reinforcement learning},
  author={Li, Alexander C and Pinto, Lerrel and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2002.11708},
  year={2020}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1707.01495},
  year={2017}
}

@article{caruana1997multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  journal={Machine learning},
  volume={28},
  number={1},
  pages={41--75},
  year={1997},
  publisher={Springer}
}

@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International conference on machine learning},
  pages={1312--1320},
  year={2015},
  organization={PMLR}
}

@article{pong2018temporal,
  title={Temporal difference models: Model-free deep rl for model-based control},
  author={Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.09081},
  year={2018}
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={IJCAI},
  pages={1094--1099},
  year={1993},
  organization={Citeseer}
}

@inproceedings{espeholt2018impala,
  author    = {Lasse Espeholt and
               Hubert Soyer and
               R{\'{e}}mi Munos and
               Karen Simonyan and
               Volodymyr Mnih and
               Tom Ward and
               Yotam Doron and
               Vlad Firoiu and
               Tim Harley and
               Iain Dunning and
               Shane Legg and
               Koray Kavukcuoglu},
  title     = {{IMPALA:} Scalable Distributed Deep-RL with Importance Weighted Actor-Learner
               Architectures},
  booktitle = { International Conference on Machine Learning},
  year      = {2018},
}

@inproceedings{hessel2019popart,
  title={Multi-task deep reinforcement learning with popart},
  author={Hessel, Matteo and Soyer, Hubert and Espeholt, Lasse and Czarnecki, Wojciech and Schmitt, Simon and van Hasselt, Hado},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  year={2019}
}

@inproceedings{riedmiller2018learning,
  title={Learning by playing solving sparse reward tasks from scratch},
  author={Riedmiller, Martin and Hafner, Roland and Lampe, Thomas and Neunert, Michael and Degrave, Jonas and Wiele, Tom and Mnih, Vlad and Heess, Nicolas and Springenberg, Jost Tobias},
  booktitle={International Conference on Machine Learning},
  pages={4344--4353},
  year={2018},
  organization={PMLR}
}

@article{teh2017distral,
  title={Distral: Robust multitask reinforcement learning},
  author={Teh, Yee Whye and Bapst, Victor and Czarnecki, Wojciech Marian and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
  journal={arXiv preprint arXiv:1707.04175},
  year={2017}
}

@inproceedings{wilson2007multi,
  title={Multi-task reinforcement learning: a hierarchical bayesian approach},
  author={Wilson, Aaron and Fern, Alan and Ray, Soumya and Tadepalli, Prasad},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={1015--1022},
  year={2007}
}

@article{rusu2015policy,
  title={Policy distillation},
  author={Rusu, Andrei A and Colmenarejo, Sergio Gomez and Gulcehre, Caglar and Desjardins, Guillaume and Kirkpatrick, James and Pascanu, Razvan and Mnih, Volodymyr and Kavukcuoglu, Koray and Hadsell, Raia},
  journal={arXiv preprint arXiv:1511.06295},
  year={2015}
}

@article{ghosh2017divide,
  title={Divide-and-conquer reinforcement learning},
  author={Ghosh, Dibya and Singh, Avi and Rajeswaran, Aravind and Kumar, Vikash and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.09874},
  year={2017}
}

@article{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={arXiv preprint arXiv:2001.06782},
  year={2020}
}

@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2102.08363},
  year={2021}
}

@article{strehl2010learning,
  title={Learning from logged implicit exploration data},
  author={Strehl, Alex and Langford, John and Kakade, Sham and Li, Lihong},
  journal={arXiv preprint arXiv:1003.0120},
  year={2010}
}

@inproceedings{garcin2014offline,
  title={Offline and online evaluation of news recommender systems at swissinfo. ch},
  author={Garcin, Florent and Faltings, Boi and Donatsch, Olivier and Alazzawi, Ayar and Bruttin, Christophe and Huber, Amr},
  booktitle={Proceedings of the 8th ACM Conference on Recommender systems},
  pages={169--176},
  year={2014}
}

@article{charles2013counterfactual,
  title={Counterfactual reasoning and learning systems: The example of computational advertising},
  author={Charles, Denis and Chickering, Max and Simard, Patrice},
  journal={Journal of Machine Learning Research},
  volume={14},
  year={2013}
}

@inproceedings{theocharous2015ad,
  title={Ad recommendation systems for life-time value optimization},
  author={Theocharous, Georgios and Thomas, Philip S and Ghavamzadeh, Mohammad},
  booktitle={Proceedings of the 24th International Conference on World Wide Web},
  pages={1305--1310},
  year={2015}
}

@inproceedings{thomas2017predictive,
  title={Predictive Off-Policy Policy Evaluation for Nonstationary Decision Problems, with Applications to Digital Marketing.},
  author={Thomas, Philip S and Theocharous, Georgios and Ghavamzadeh, Mohammad and Durugkar, Ishan and Brunskill, Emma},
  booktitle={AAAI},
  pages={4740--4745},
  year={2017}
}

@article{parisotto2015actor,
  title={Actor-mimic: Deep multitask and transfer reinforcement learning},
  author={Parisotto, Emilio and Ba, Jimmy Lei and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1511.06342},
  year={2015}
}

@article{schaul2019ray,
  title={Ray interference: a source of plateaus in deep reinforcement learning},
  author={Schaul, Tom and Borsa, Diana and Modayil, Joseph and Pascanu, Razvan},
  journal={arXiv preprint arXiv:1904.11455},
  year={2019}
}

@inproceedings{yu2020metaworld,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@article{sodhani2021multi,
  title={Multi-Task Reinforcement Learning with Context-based Representations},
  author={Sodhani, Shagun and Zhang, Amy and Pineau, Joelle},
  journal={arXiv preprint arXiv:2102.06177},
  year={2021}
}

@article{xu2020knowledge,
  title={Knowledge Transfer in Multi-Task Deep Reinforcement Learning for Continuous Control},
  author={Xu, Zhiyuan and Wu, Kun and Che, Zhengping and Tang, Jian and Ye, Jieping},
  year={2020}
}

@inproceedings{guez2008adaptive,
  title={Adaptive Treatment of Epilepsy via Batch-mode Reinforcement Learning.},
  author={Guez, Arthur and Vincent, Robert D and Avoli, Massimo and Pineau, Joelle},
  booktitle={AAAI},
  pages={1671--1678},
  year={2008}
}

@inproceedings{d2019sharing,
  title={Sharing knowledge in multi-task deep reinforcement learning},
  author={D'Eramo, Carlo and Tateo, Davide and Bonarini, Andrea and Restelli, Marcello and Peters, Jan},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{gulcehre2020rl,
  title={Rl unplugged: Benchmarks for offline reinforcement learning},
  author={Gulcehre, Caglar and Wang, Ziyu and Novikov, Alexander and Paine, Tom Le and Colmenarejo, Sergio G{\'o}mez and Zolna, Konrad and Agarwal, Rishabh and Merel, Josh and Mankowitz, Daniel and Paduraru, Cosmin and others},
  journal={arXiv preprint arXiv:2006.13888},
  year={2020}
}

@article{yang2020multi,
  title={Multi-task reinforcement learning with soft modularization},
  author={Yang, Ruihan and Xu, Huazhe and Wu, Yi and Wang, Xiaolong},
  journal={arXiv preprint arXiv:2003.13661},
  year={2020}
}

@article{tao2020repaint,
  title={REPAINT: Knowledge Transfer in Deep Reinforcement Learning},
  author={Tao, Yunzhe and Genc, Sahika and Chung, Jonathan and Sun, Tao and Mallya, Sunil},
  journal={arXiv preprint arXiv:2011.11827},
  year={2020}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}

@article{tian2020model,
  title={Model-Based Visual Planning with Self-Supervised Functional Distances},
  author={Tian, Stephen and Nair, Suraj and Ebert, Frederik and Dasari, Sudeep and Eysenbach, Benjamin and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2012.15373},
  year={2020}
}

@article{chebotar2021actionable,
  title={Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills},
  author={Chebotar, Yevgen and Hausman, Karol and Lu, Yao and Xiao, Ted and Kalashnikov, Dmitry and Varley, Jake and Irpan, Alex and Eysenbach, Benjamin and Julian, Ryan and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2104.07749},
  year={2021}
}

@article{sun2019policy,
  title={Policy continuation with hindsight inverse dynamics},
  author={Sun, Hao and Li, Zhizhong and Liu, Xiaotong and Lin, Dahua and Zhou, Bolei},
  journal={arXiv preprint arXiv:1910.14055},
  year={2019}
}

@article{pitis2020counterfactual,
  title={Counterfactual Data Augmentation using Locally Factored Dynamics},
  author={Pitis, Silviu and Creager, Elliot and Garg, Animesh},
  journal={arXiv preprint arXiv:2007.02863},
  year={2020}
}

@article{liu2019competitive,
  title={Competitive experience replay},
  author={Liu, Hao and Trott, Alexander and Socher, Richard and Xiong, Caiming},
  journal={arXiv preprint arXiv:1902.00528},
  year={2019}
}

@article{yang2021bias,
  title={Bias-reduced multi-step hindsight experience replay},
  author={Yang, Rui and Lyu, Jiafei and Yang, Yu and Ya, Jiangpeng and Luo, Feng and Luo, Dijun and Li, Lanqing and Li, Xiu},
  journal={arXiv preprint arXiv:2102.12962},
  year={2021}
}

@article{lynch2020grounding,
  title={Grounding language in play},
  author={Lynch, Corey and Sermanet, Pierre},
  journal={arXiv preprint arXiv:2005.07648},
  year={2020}
}

@article{lin2019reinforcement,
  title={Reinforcement learning without ground-truth state},
  author={Lin, Xingyu and Baweja, Harjatin Singh and Held, David},
  journal={arXiv preprint arXiv:1905.07866},
  year={2019}
}

@article{huang2019mapping,
  title={Mapping state space using landmarks for universal goal reaching},
  author={Huang, Zhiao and Liu, Fangchen and Su, Hao},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={1942--1952},
  year={2019}
}

@article{nair2018visual,
  title={Visual reinforcement learning with imagined goals},
  author={Nair, Ashvin and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
  journal={arXiv preprint arXiv:1807.04742},
  year={2018}
}

@inproceedings{xie2018few,
  title={Few-shot goal inference for visuomotor learning and planning},
  author={Xie, Annie and Singh, Avi and Levine, Sergey and Finn, Chelsea},
  booktitle={Conference on Robot Learning},
  pages={40--52},
  year={2018},
  organization={PMLR}
}

@article{chen2021learning,
  title={Learning Generalizable Robotic Reward Functions from" In-The-Wild" Human Videos},
  author={Chen, Annie S and Nair, Suraj and Finn, Chelsea},
  journal={arXiv preprint arXiv:2103.16817},
  year={2021}
}

@article{yang2021representation,
  title={Representation matters: Offline pretraining for sequential decision making},
  author={Yang, Mengjiao and Nachum, Ofir},
  journal={arXiv preprint arXiv:2102.05815},
  year={2021}
}

@article{li2019multi,
  title={Multi-task batch reinforcement learning with metric learning},
  author={Li, Jiachen and Vuong, Quan and Liu, Shuang and Liu, Minghua and Ciosek, Kamil and Ross, Keith and Christensen, Henrik Iskov and Su, Hao},
  journal={arXiv preprint arXiv:1909.11373},
  year={2019}
}

@article{killian2020empirical,
  title={An Empirical Study of Representation Learning for Reinforcement Learning in Healthcare},
  author={Killian, Taylor W and Zhang, Haoran and Subramanian, Jayakumar and Fatemi, Mehdi and Ghassemi, Marzyeh},
  journal={arXiv preprint arXiv:2011.11235},
  year={2020}
}

@inproceedings{sharma2018multiple,
  title={Multiple interactions made easy (mime): Large scale demonstrations data for imitation},
  author={Sharma, Pratyusha and Mohan, Lekha and Pinto, Lerrel and Gupta, Abhinav},
  booktitle={Conference on robot learning},
  pages={906--915},
  year={2018},
  organization={PMLR}
}

@article{zhang2021method,
  title={A Method of Offline Reinforcement Learning Virtual Reality Satellite Attitude Control Based on Generative Adversarial Network},
  author={Zhang, Jian and Wu, Fengge},
  journal={Wireless Communications and Mobile Computing},
  volume={2021},
  year={2021},
  publisher={Hindawi}
}

@inproceedings{xiao2021general,
  title={A general offline reinforcement learning framework for interactive recommendation},
  author={Xiao, Teng and Wang, Donglin},
  booktitle={The Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021},
  year={2021}
}

@article{kiyohara2021accelerating,
  title={Accelerating Offline Reinforcement Learning Application in Real-Time Bidding and Recommendation: Potential Use of Simulation},
  author={Kiyohara, Haruka and Kawakami, Kosuke and Saito, Yuta},
  journal={arXiv preprint arXiv:2109.08331},
  year={2021}
}

@inproceedings{kreutzer2021offline,
  title={Offline Reinforcement Learning from Human Feedback in Real-World Sequence-to-Sequence Tasks},
  author={Kreutzer, Julia and Riezler, Stefan and Lawrence, Carolin},
  booktitle={Proceedings of the 5th Workshop on Structured Prediction for NLP (SPNLP 2021)},
  pages={37--43},
  year={2021}
}

@article{tang2021model,
  title={Model Selection for Offline Reinforcement Learning: Practical Considerations for Healthcare Settings},
  author={Tang, Shengpu and Wiens, Jenna},
  journal={arXiv preprint arXiv:2107.11003},
  year={2021}
}

@article{liu2021offline,
  title={Offline reinforcement learning with uncertainty for treatment strategies in sepsis},
  author={Liu, Ran and Greenstein, Joseph L and Fackler, James C and Bergmann, Jules and Bembea, Melania M and Winslow, Raimond L},
  journal={arXiv preprint arXiv:2107.04491},
  year={2021}
}

@article{apostolopoulos2021personalization,
  title={Personalization for Web-based Services using Offline Reinforcement Learning},
  author={Apostolopoulos, Pavlos Athanasios and Wang, Zehui and Wang, Hanson and Zhou, Chad and Virochsiri, Kittipat and Zhou, Norm and Markov, Igor L},
  journal={arXiv preprint arXiv:2102.05612},
  year={2021}
}

@article{de2021discovering,
  title={Discovering an Aid Policy to Minimize Student Evasion Using Offline Reinforcement Learning},
  author={de Lima, Leandro M and Krohling, Renato A},
  journal={arXiv preprint arXiv:2104.10258},
  year={2021}
}

@article{zhan2021deepthermal,
  title={DeepThermal: Combustion Optimization for Thermal Power Generating Units Using Offline Reinforcement Learning},
  author={Zhan, Xianyuan and Xu, Haoran and Zhang, Yue and Huo, Yusen and Zhu, Xiangyu and Yin, Honglei and Zheng, Yu},
  journal={arXiv preprint arXiv:2102.11492},
  year={2021}
}

@article{sinha2021s4rl,
  title={S4RL: Surprisingly Simple Self-Supervision for Offline Reinforcement Learning},
  author={Sinha, Samarth and Garg, Animesh},
  journal={arXiv preprint arXiv:2103.06326},
  year={2021}
}

@inproceedings{kostrikov2021offline,
  title={Offline reinforcement learning with fisher divergence critic regularization},
  author={Kostrikov, Ilya and Fergus, Rob and Tompson, Jonathan and Nachum, Ofir},
  booktitle={International Conference on Machine Learning},
  pages={5774--5783},
  year={2021},
  organization={PMLR}
}

@article{fujimoto2021minimalist,
  title={A Minimalist Approach to Offline Reinforcement Learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={arXiv preprint arXiv:2106.06860},
  year={2021}
}

@inproceedings{ghasemipour2021emaq,
  title={Emaq: Expected-max q-learning operator for simple yet effective offline and online rl},
  author={Ghasemipour, Seyed Kamyar Seyed and Schuurmans, Dale and Gu, Shixiang Shane},
  booktitle={International Conference on Machine Learning},
  pages={3682--3691},
  year={2021},
  organization={PMLR}
}

@inproceedings{stooke2021decoupling,
  title={Decoupling representation learning from reinforcement learning},
  author={Stooke, Adam and Lee, Kimin and Abbeel, Pieter and Laskin, Michael},
  booktitle={International Conference on Machine Learning},
  pages={9870--9879},
  year={2021},
  organization={PMLR}
}

@article{sener2018multi,
  title={Multi-task learning as multi-objective optimization},
  author={Sener, Ozan and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1810.04650},
  year={2018}
}

@inproceedings{Ziebart2008MaximumEI,
  title={Maximum Entropy Inverse Reinforcement Learning},
  author={Brian D. Ziebart and Andrew L. Maas and J. Bagnell and A. Dey},
  booktitle={AAAI},
  year={2008}
}

@article{gangwani2019learning,
      title={Learning Belief Representations for Imitation Learning in POMDPs}, 
      author={Tanmay Gangwani and Joel Lehman and Qiang Liu and Jian Peng},
      year={2020},
      journal = {Conference on Uncertainty in Artificial Intelligence}
}

@article{baram2016modelbased,
      title={Model-based Adversarial Imitation Learning}, 
      author={Nir Baram and Oron Anschel and Shie Mannor},
      year={2016},
      journal = {Conference on Neural Information Processing Systems}

}

@article{sun2021attention,
      title={Adversarial Inverse Reinforcement Learning with
Self-attention Dynamics Model}, 
      author={Jiankai Sun and Lantao Yu and Pinqian Dong and Bo Lu and Bolei Zhou},
      year={2021},
      journal = {IEEE Robotics and Automation Letters}

}

@book{SuttonBook,
	title        = {Reinforcement Learning: An Introduction},
	author       = {Richard Sutton and Andrew Barto},
	year         = 1998,
	publisher    = {MIT Press}
}


@article{gelada2019deepmdp,
      title={DeepMDP: Learning Continuous Latent Space Models for Representation Learning}, 
      author={Carles Gelada and Saurabh Kumar and Jacob Buckman and Ofir Nachum and Marc G. Bellemare},
      year={2019},
      journal = { International Conference on Machine Learning}

}

@article{hafner2020dream,
      title={Dream to Control: Learning Behaviors by Latent Imagination}, 
      author={Danijar Hafner and Timothy Lillicrap and Jimmy Ba and Mohammad Norouzi},
      year={2020},
      journal = {International Conference on Learning Representations},

}

@inproceedings{finn2016deep,
  title={Deep spatial autoencoders for visuomotor learning},
  author={Finn, Chelsea and Tan, Xin Yu and Duan, Yan and Darrell, Trevor and Levine, Sergey and Abbeel, Pieter},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={512--519},
  year={2016},
  organization={IEEE}
}

@article{hafner2019learning,
      title={Learning Latent Dynamics for Planning from Pixels}, 
      author={Danijar Hafner and Timothy Lillicrap and Ian Fischer and Ruben Villegas and David Ha and Honglak Lee and James Davidson},
      year={2019},
      journal = { International Conference on Machine Learning}
}

@article{lee2020stochastic,
      title={Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model}, 
      author={Alex X. Lee and Anusha Nagabandi and Pieter Abbeel and Sergey Levine},
      year={2020},
      journal = {Conference on Neural Information Processing Systems}
      }

@article{karl2017deep,
      title={Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data}, 
      author={Maximilian Karl and Maximilian Soelch and Justin Bayer and Patrick van der Smagt},
      year={2017},
      journal = { International Conference on Machine Learning}
}

@article{zhang2019solar,
      title={SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning}, 
      author={Marvin Zhang and Sharad Vikram and Laura Smith and Pieter Abbeel and Matthew J. Johnson and Sergey Levine},
      year={2019},
      journal = { International Conference on Machine Learning}
}

@miarticlesc{watter2015embed,
      title={Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images}, 
      author={Manuel Watter and Jost Tobias Springenberg and Joschka Boedecker and Martin Riedmiller},
      year={2015},
      journal = {Conference on Neural Information Processing Systems}
}

@article{zolna2020taskrelevant,
      title={Task-Relevant Adversarial Imitation Learning}, 
      author={Konrad Zolna and Scott Reed and Alexander Novikov and Sergio Gomez Colmenarejo and David Budden and Serkan Cabi and Misha Denil and Nando de Freitas and Ziyu Wang},
      year={2020},
      journal = {Conference on Robot Learning},
}


@article{visual2018reed,
author = {Scott Reed and Yusuf Aytar and Ziyu Wang and Tom Paine and Aaron van den Oord and Tobias Pfaff and Sergio Gomez and Alexander Novikov and David Budden and Oriol Vinyals},
journal = {DeepMind Technical Report},
title = {Visual Imitation with a Minimal Adversary},
year = {2018}
}



@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@inproceedings{pomerleau1988alvinn,
  title={ALVINN: an autonomous land vehicle in a neural network},
  author={Pomerleau, Dean A},
  booktitle={Proceedings of the 1st International Conference on Neural Information Processing Systems},
  pages={305--313},
  year={1988}
}

@inproceedings{finn2016guided,
  title={Guided cost learning: Deep inverse optimal control via policy optimization},
  author={Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={49--58},
  year={2016},
  organization={PMLR}
}

@article{MGAIL2016Baram,
author = {Nir Baram and Oron Anschel and Shie Mannor},
journal = {Conference on Neural Information Processing Systems },
title = {Model-based Adversarial Imitation Learning},
year = {2016}
}

@article{CI2018Levine,
author = {Sergey Levine},
journal = {ArXiv Preprint},
title = {Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review},
year = {2018}
}


@article{SLAC20202Lee,
author = {Alex X. Lee and Anusha Nagabandi and Pieter Abbeel and Sergey Levine},
journal = {Conference on Neural Information Processing Systems},
title = {Stochastic Latent Actor-Critic: Deep Reinforcement
Learning with a Latent Variable Model},
year = {2020}
}

@article{PlanNet2019Hafner,
author = {Danijar Hafner and Timothy Lillicrap and Ian Fischer and Ruben Villegas and David Ha and Honglak Lee and James Davidson},
journal = {International Conference on Machine
Learning},
title = {Learning Latent Dynamics for Planning from Pixels},
year = {2019}
}


@article{Dreamer2020Hafner,
author = {Danijar Hafner and Timothy Lillicrap and Jimmy Ba and Mohammad Norouzi},
journal = {International Conference on Learning Representations},
title = {Dream to Control: Learning Behaviors by Latent Imagination},
year = {2020}
}



@article{VICEFu2018,
author = {Justin Fu and Avi Singh and Dibya Ghosh and Larry Yang and Sergey Levine},
journal = {Conference on Neural Information Processing Systems},
title = {Variational Inverse Control with Events: A General
Framework for Data-Driven Reward Definition},
year = {2018}
}

@article{AIRLFu2018,
author = {Justin Fu and Katie Luo and Sergey Levine},
journal = {International Conference on Learning Representations},
title = {Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
year = {2018}
}

@article{LS2019Muller,
author = {Rafael Müller and Simon Kornblith and Geoffrey Hinton},
journal = {Conference on Neural Information Processing Systems},
title = {When Does Label Smoothing Help?},
year = {2019}
}

@article{rafailov2020offline,
  title={Offline Reinforcement Learning from Images with Latent Space Models},
  author={Rafailov, Rafael and Yu, Tianhe and Rajeswaran, Aravind and Finn, Chelsea},
  journal={arXiv preprint arXiv:2012.11547},
  year={2020}
}

@article{ValueDICE2019Kostrikov,
author = {Ilya Kostrikov and Ofir Nachum and Jonathan Tompson},
journal = {International Conference on Learning Representations},
title = {Imitation Learning via Off-Policy Distribution Matching},
year = {2020}
}

@article{SQIL2020Reddy,
author = {Siddharth Reddy and Anca D. Dragan and Sergey Levine},
journal = {International Conference on Learning Representations},
title = {SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards},
year = {2020}
}


@article{SAM2019Blonde,
author = {Lionel Blondé and Alexandros Kalousis},
journal = {AISTATS},
title = {Sample-Efficient Imitation Learning via Generative Adversarial Nets
},
year = {2019}
}



@article{DAC2019Kostrikov,
author = {Ilya Kostrikov and Kumar Krishna Agrawal and Debidatta Dwibedi and Sergey Levine and Jonathan Tompson},
journal = {International Conference on Learning Representations},
title = {Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning},
year = {2019}
}

@article{Feedback2021Spencer,
author = {Jonathan Spencer and Sanjiban Choudhury and Arun Venkatraman and Brian Ziebart and J. Andrew Bagnell},
journal = {ArXiv Preprint},
title = {Feedback in Imitation Learning: The Three Regimes of Covariate Shift},
year = {2021}
}



@article{Dagger2011Ross,
author = {Stephane Ross and Geoffrey J. Gordon and J. Andrew Bagnell},
journal = {AISTATS},
title = {A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning},
year = {2011}
}




@article{GAIL2016Ho,
author = {Jonathan Ho and Stefano Ermon},
journal = {Conference on Neural Information Processing Systems},
title = {Generative Adversarial Imitation Learning},
year = {2016}
}


@article{GAIL201Finn,
author = {Chelsea Finn and Paul Christiano and Pieter Abbeel and Sergey Levine},
journal = {ArXiv Preprint},
title = {A connection between generative adversarial
networks, inverse reinforcement learning, and energy-based models},
year = {2016}
}







@article{DIV2019Sayed,
author = {Seyed Kamyar Seyed Ghasemipour and Richard Zemel and Shixiang Gu},
journal = {Conference on Robot Learning},
title = {A Divergence Minimization Perspective on Imitation Learning Methods},
year = {2019}
}


@article{Ke2019ImitationLA,
  title={Imitation Learning as f-Divergence Minimization},
  author={Liyiming Ke and Matt Barnes and W. Sun and Gilwoo Lee and Sanjiban Choudhury and S. Srinivasa},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.12888}
}






@misc{mnih2013playing,
      title={Playing Atari with Deep Reinforcement Learning}, 
      author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
      year={2013},
      eprint={1312.5602},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{tassa2018deepmind,
      title={DeepMind Control Suite}, 
      author={Yuval Tassa and Yotam Doron and Alistair Muldal and Tom Erez and Yazhe Li and Diego de Las Casas and David Budden and Abbas Abdolmaleki and Josh Merel and Andrew Lefrancq and Timothy Lillicrap and Martin Riedmiller},
      year={2018},
      eprint={1801.00690},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}



@INPROCEEDINGS{Rajeswaran-RSS-18,
    AUTHOR    = {Aravind Rajeswaran AND Vikash Kumar AND Abhishek Gupta AND
                 Giulia Vezzani AND John Schulman AND Emanuel Todorov AND Sergey Levine},
    TITLE     = "{Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations}",
    BOOKTITLE = {Proceedings of Robotics: Science and Systems (RSS)},
    YEAR      = {2018},
}


@inproceedings{RajeswaranGameMBRL,
	title        = {{A Game Theoretic Framework for Model-Based Reinforcement Learning}},
	author       = {Aravind Rajeswaran AND Igor Mordatch AND Vikash Kumar},
	year         = 2020,
	booktitle    = {{ICML}},
}


@article{pddm2019Nagabandi,
author = {Anusha Nagabandi and Kurt Konolige and Sergey Levine and Vikash Kumar},
journal = {Conference on Robot Learning},
title = {Deep Dynamics Models
for Learning Dexterous Manipulation},
year = {2019}
}


@misc{blonde2020lipschitzness,
      title={Lipschitzness Is All You Need To Tame Off-policy Generative Adversarial Imitation Learning}, 
      author={Lionel Blondé and Pablo Strasser and Alexandros Kalousis},
      year={2020},
      eprint={2006.16785},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@misc{gelada2019deepmdp,
      title={DeepMDP: Learning Continuous Latent Space Models for Representation Learning}, 
      author={Carles Gelada and Saurabh Kumar and Jacob Buckman and Ofir Nachum and Marc G. Bellemare},
journal = {International conference on machine learning},
title = {DeepMDP: Learning Continuous Latent Space Models for Representation Learning},
year = {2019}
}

@article{Amodei2016ConcretePI,
  title={Concrete Problems in AI Safety},
  author={Dario Amodei and Chris Olah and J. Steinhardt and Paul F. Christiano and John Schulman and Dan Man{\'e}},
  journal={ArXiv},
  year={2016},
  volume={abs/1606.06565},
}

@article{Everitt2019RewardTP,
  title={Reward Tampering Problems and Solutions in Reinforcement Learning: A Causal Influence Diagram Perspective},
  author={Tom Everitt and Marcus Hutter},
  journal={ArXiv},
  year={2019},
  volume={abs/1908.04734}
}

@inproceedings{Goodfellow2014GenerativeAN,
  title={Generative Adversarial Nets},
  author={Ian J. Goodfellow and Jean Pouget-Abadie and M. Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron C. Courville and Yoshua Bengio},
  booktitle={NIPS},
  year={2014}
}

@inproceedings{Ziebart2008MaximumEI,
  title={Maximum Entropy Inverse Reinforcement Learning},
  author={Brian D. Ziebart and Andrew L. Maas and J. Bagnell and A. Dey},
  booktitle={AAAI},
  year={2008}
}

@article{Portelas2020AutomaticCL,
  title={Automatic Curriculum Learning For Deep RL: A Short Survey},
  author={R{\'e}my Portelas and C{\'e}dric Colas and Lilian Weng and Katja Hofmann and Pierre-Yves Oudeyer},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.04664}
}

@article{Khetarpal2020TowardsCR,
  title={Towards Continual Reinforcement Learning: A Review and Perspectives},
  author={Khimya Khetarpal and Matthew Riemer and I. Rish and Doina Precup},
  journal={ArXiv},
  year={2020},
  volume={abs/2012.13490}
}

@inproceedings{Lowe2017MultiAgentAF,
  title={Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  author={Ryan Lowe and Yi Wu and Aviv Tamar and Jean Harb and P. Abbeel and Igor Mordatch},
  booktitle={NIPS},
  year={2017}
}

@article{Blei2016VariationalIA,
  title={Variational Inference: A Review for Statisticians},
  author={David M. Blei and A. Kucukelbir and Jon D. McAuliffe},
  journal={Journal of the American Statistical Association},
  year={2016},
  volume={112},
  pages={859 - 877}
}

@article{eysenbach2020c,
  title={C-Learning: Learning to Achieve Goals via Recursive Classification},
  author={Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey},
  journal={arXiv preprint arXiv:2011.08909},
  year={2020}
}

@inproceedings{zeng2018learning,
  title={Learning synergies between pushing and grasping with self-supervised deep reinforcement learning},
  author={Zeng, Andy and Song, Shuran and Welker, Stefan and Lee, Johnny and Rodriguez, Alberto and Funkhouser, Thomas},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4238--4245},
  year={2018},
  organization={IEEE}
}

@article{andrychowicz2020learning,
  title={Learning dexterous in-hand manipulation},
  author={Andrychowicz, OpenAI: Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and others},
  journal={The International Journal of Robotics Research},
  volume={39},
  number={1},
  pages={3--20},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{van2015learning,
  title={Learning robot in-hand manipulation with tactile features},
  author={Van Hoof, Herke and Hermans, Tucker and Neumann, Gerhard and Peters, Jan},
  booktitle={2015 IEEE-RAS 15th International Conference on Humanoid Robots (Humanoids)},
  pages={121--127},
  year={2015},
  organization={IEEE}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}

@article{kumar2016learning,
  title={Learning dexterous manipulation policies from experience and imitation},
  author={Kumar, Vikash and Gupta, Abhishek and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.05095},
  year={2016}
}

@inproceedings{schenck2017visual,
  title={Visual closed-loop control for pouring liquids},
  author={Schenck, Connor and Fox, Dieter},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2629--2636},
  year={2017},
  organization={IEEE}
}

@inproceedings{yahya2017collective,
  title={Collective robot reinforcement learning with distributed asynchronous guided policy search},
  author={Yahya, Ali and Li, Adrian and Kalakrishnan, Mrinal and Chebotar, Yevgen and Levine, Sergey},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={79--86},
  year={2017},
  organization={IEEE}
}

@inproceedings{matas2018sim,
  title={Sim-to-real reinforcement learning for deformable object manipulation},
  author={Matas, Jan and James, Stephen and Davison, Andrew J},
  booktitle={Conference on Robot Learning},
  pages={734--743},
  year={2018},
  organization={PMLR}
}

@article{singh2019end,
  title={End-to-end robotic reinforcement learning without reward engineering},
  author={Singh, Avi and Yang, Larry and Hartikainen, Kristian and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:1904.07854},
  year={2019}
}

@article{julian2020efficient,
  title={Efficient Adaptation for End-to-End Vision-Based Robotic Manipulation},
  author={Julian, Ryan and Swanson, Benjamin and Sukhatme, Gaurav S and Levine, Sergey and Finn, Chelsea and Hausman, Karol},
  journal={arXiv preprint arXiv:2004.10190},
  year={2020}
}

@article{cabi2019framework,
  title={A framework for data-driven robotics},
  author={Cabi, Serkan and Colmenarejo, Sergio G{\'o}mez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and Zo{\l}na, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
  journal={arXiv preprint arXiv:1909.12200},
  year={2019}
}

@inproceedings{kappler2015leveraging,
  title={Leveraging big data for grasp planning},
  author={Kappler, Daniel and Bohg, Jeannette and Schaal, Stefan},
  booktitle={2015 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4304--4311},
  year={2015},
  organization={IEEE}
}

@inproceedings{pinto2016supersizing,
  title={Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours},
  author={Pinto, Lerrel and Gupta, Abhinav},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={3406--3413},
  year={2016},
  organization={IEEE}
}

@article{levine2018learning,
  title={Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection},
  author={Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Ibarz, Julian and Quillen, Deirdre},
  journal={The International Journal of Robotics Research},
  volume={37},
  number={4-5},
  pages={421--436},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{gupta2018robot,
  title={Robot learning in homes: Improving generalization and reducing dataset bias},
  author={Gupta, Abhinav and Murali, Adithyavairavan and Gandhi, Dhiraj and Pinto, Lerrel},
  journal={arXiv preprint arXiv:1807.07049},
  year={2018}
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robot motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}


@article{mandlekar2020learning,
  title={Learning to generalize across long-horizon tasks from human demonstrations},
  author={Mandlekar, Ajay and Xu, Danfei and Mart{\'\i}n-Mart{\'\i}n, Roberto and Savarese, Silvio and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2003.06085},
  year={2020}
}

@article{torabi2018generative,
  title={Generative adversarial imitation from observation},
  author={Torabi, Faraz and Warnell, Garrett and Stone, Peter},
  journal={arXiv preprint arXiv:1807.06158},
  year={2018}
}

@article{cabi2019scaling,
  title={Scaling data-driven robotics with reward sketching and batch reinforcement learning},
  author={Cabi, Serkan and Colmenarejo, Sergio G{\'o}mez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and Zolna, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
  journal={arXiv preprint arXiv:1909.12200},
  year={2019}
}

@article{zolna2020offline,
  title={Offline Learning from Demonstrations and Unlabeled Experience},
  author={Zolna, Konrad and Novikov, Alexander and Konyushkova, Ksenia and Gulcehre, Caglar and Wang, Ziyu and Aytar, Yusuf and Denil, Misha and de Freitas, Nando and Reed, Scott},
  journal={arXiv preprint arXiv:2011.13885},
  year={2020}
}

@article{zhu2020ingredients,
  title={The ingredients of real-world robotic reinforcement learning},
  author={Zhu, Henry and Yu, Justin and Gupta, Abhishek and Shah, Dhruv and Hartikainen, Kristian and Singh, Avi and Kumar, Vikash and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.12570},
  year={2020}
}

@inproceedings{ng2000irl,
 author={Ng, Andrew Y. and Russell, Stuart J.},
 title={Algorithms for Inverse Reinforcement Learning},
 booktitle={Proceedings of the Seventeenth International Conference on Machine Learning},
 series={ICML '00},
 year={2000}
} 

@inproceedings{ratliff2006,
 author = {Ratliff, Nathan D. and Bagnell, J. Andrew and Zinkevich, Martin A.},
 title = {Maximum Margin Planning},
 booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
 series = {ICML '06},
 year = {2006}
} 

@inproceedings{ramachandran2007bayesianirl,
 author = {Ramachandran, Deepak and Amir, Eyal},
 title = {Bayesian Inverse Reinforcement Learning},
 booktitle = {Proceedings of the 20th International Joint Conference on Artifical Intelligence},
 series = {IJCAI'07},
 year = {2007}
} 

@inproceedings{ziebart2008maximum,
  title={Maximum entropy inverse reinforcement learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K},
  booktitle={Aaai},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}

@INPROCEEDINGS{abbeel2004apprenticeship,
    author = "Abbeel, Pieter and Ng, Andrew Y",
    title = "Apprenticeship learning via inverse reinforcement learning",
    booktitle = "Proceedings of the twenty-first international conference on Machine learning",
    pages = "1",
    institution = "ACM",
    year = "2004"
}

@inproceedings{jin2021pessimism,
  title={Is Pessimism Provably Efficient for Offline RL?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={5084--5096},
  year={2021},
  organization={PMLR}
}

@article{rashidinejad2021bridging,
  title={Bridging offline reinforcement learning and imitation learning: A tale of pessimism},
  author={Rashidinejad, Paria and Zhu, Banghua and Ma, Cong and Jiao, Jiantao and Russell, Stuart},
  journal={arXiv preprint arXiv:2103.12021},
  year={2021}
}

@inproceedings{duan2020minimax,
  title={Minimax-optimal off-policy evaluation with linear function approximation},
  author={Duan, Yaqi and Jia, Zeyu and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={2701--2709},
  year={2020},
  organization={PMLR}
}

@article{yang2021trail,
  title={TRAIL: Near-Optimal Imitation Learning with Suboptimal Data},
  author={Yang, Mengjiao and Levine, Sergey and Nachum, Ofir},
  journal={arXiv preprint arXiv:2110.14770},
  year={2021}
}


@inproceedings{mitchell2021offline,
  title={Offline meta-reinforcement learning with advantage weighting},
  author={Mitchell, Eric and Rafailov, Rafael and Peng, Xue Bin and Levine, Sergey and Finn, Chelsea},
  booktitle={International Conference on Machine Learning},
  pages={7780--7791},
  year={2021},
  organization={PMLR}
}

@article{dorfman2021offline,
  title={Offline Meta Reinforcement Learning--Identifiability Challenges and Effective Data Collection Strategies},
  author={Dorfman, Ron and Shenfeld, Idan and Tamar, Aviv},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}