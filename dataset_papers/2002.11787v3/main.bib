@inproceedings{abadi2016tensorflow,
  title={Tensorflow: a system for large-scale machine learning.},
  author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
  booktitle={OSDI},
  volume={16},
  pages={265--283},
  year={2016}
}

@inproceedings{seide2016cntk,
  title={CNTK: Microsoft's open-source deep-learning toolkit},
  author={Seide, Frank and Agarwal, Amit},
  booktitle={Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={2135--2135},
  year={2016},
  organization={ACM}
}

@article{chen2015mxnet,
  title={Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems},
  author={Chen, Tianqi and Li, Mu and Li, Yutian and Lin, Min and Wang, Naiyan and Wang, Minjie and Xiao, Tianjun and Xu, Bing and Zhang, Chiyuan and Zhang, Zheng},
  journal={arXiv preprint arXiv:1512.01274},
  year={2015}
}

@book{gropp1999using,
  title={Using MPI-2: Advanced features of the message passing interface},
  author={Gropp, William and Thakur, Rajeev and Lusk, Ewing},
  year={1999},
  publisher={MIT press}
}

@article{tang2018distributed,
  title={Distributed Learning over Unreliable Networks},
  author={Tang, Hanlin and Yu, Chen and Renggli, Cedric and Kassing, Simon and Singla, Ankit and Alistarh, Dan and Liu, Ji and Zhang, Ce},
  journal={arXiv preprint arXiv:1810.07766},
  year={2018}
}

@inproceedings{li2014scaling,
  title={Scaling Distributed Machine Learning with the Parameter Server.},
  author={Li, Mu and Andersen, David G and Park, Jun Woo and Smola, Alexander J and Ahmed, Amr and Josifovski, Vanja and Long, James and Shekita, Eugene J and Su, Bor-Yiing},
  booktitle={OSDI},
  volume={14},
  pages={583--598},
  year={2014}
}

@inproceedings{li2014communication,
  title={Communication efficient distributed machine learning with the parameter server},
  author={Li, Mu and Andersen, David G and Smola, Alexander J and Yu, Kai},
  booktitle={Advances in Neural Information Processing Systems},
  pages={19--27},
  year={2014}
}

@inproceedings{lian2017can,
  title={Can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent},
  author={Lian, Xiangru and Zhang, Ce and Zhang, Huan and Hsieh, Cho-Jui and Zhang, Wei and Liu, Ji},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5330--5340},
  year={2017}
}

@article{tang2018d,
  title={D2: Decentralized Training over Decentralized Data},
  author={Tang, Hanlin and Lian, Xiangru and Yan, Ming and Zhang, Ce and Liu, Ji},
  journal={arXiv preprint arXiv:1803.07068},
  year={2018}
}

@article{lian2017asynchronous,
  title={Asynchronous Decentralized Parallel Stochastic Gradient Descent},
  author={Lian, Xiangru and Zhang, Wei and Zhang, Ce and Liu, Ji},
  journal={arXiv preprint arXiv:1710.06952},
  year={2017}
}

@inproceedings{zhang2017zipml,
  title={Zipml: Training linear models with end-to-end low precision, and a little bit of deep learning},
  author={Zhang, Hantian and Li, Jerry and Kara, Kaan and Alistarh, Dan and Liu, Ji and Zhang, Ce},
  booktitle={International Conference on Machine Learning},
  pages={4035--4043},
  year={2017}
}

@inproceedings{alistarh2017qsgd,
  title={QSGD: Communication-efficient SGD via gradient quantization and encoding},
  author={Alistarh, Dan and Grubic, Demjan and Li, Jerry and Tomioka, Ryota and Vojnovic, Milan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1709--1720},
  year={2017}
}

@article{wu2018error,
  title={Error Compensated Quantized SGD and its Applications to Large-scale Distributed Optimization},
  author={Wu, Jiaxiang and Huang, Weidong and Huang, Junzhou and Zhang, Tong},
  journal={arXiv preprint arXiv:1806.08054},
  year={2018}
}

@article{DBLP:journals/corr/abs-1806-11536,
  author    = {Amirhossein Reisizadeh and
               Aryan Mokhtari and
               S. Hamed Hassani and
               Ramtin Pedarsani},
  title     = {Quantized Decentralized Consensus Optimization},
  journal   = {CoRR},
  volume    = {abs/1806.11536},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.11536},
  archivePrefix = {arXiv},
  eprint    = {1806.11536},
  timestamp = {Mon, 13 Aug 2018 16:47:07 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1806-11536},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{tang2018communication,
  title={Communication compression for decentralized training},
  author={Tang, Hanlin and Gan, Shaoduo and Zhang, Ce and Zhang, Tong and Liu, Ji},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7663--7673},
  year={2018}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={IEEE}
}

@article{krizhevsky2014cifar,
  title={The CIFAR-10 dataset},
  author={Krizhevsky, Alex and Nair, Vinod and Hinton, Geoffrey},
  journal={online: http://www. cs. toronto. edu/kriz/cifar. html},
  year={2014}
}

@article{lan2017communication,
  title={Communication-efficient algorithms for decentralized and stochastic optimization},
  author={Lan, Guanghui and Lee, Soomin and Zhou, Yi},
  journal={arXiv preprint arXiv:1701.03961},
  year={2017}
}

@inproceedings{mokhtari2015decentralized,
  title={Decentralized double stochastic averaging gradient},
  author={Mokhtari, Aryan and Ribeiro, Alejandro},
  booktitle={Signals, Systems and Computers, 2015 49th Asilomar Conference on},
  pages={406--410},
  year={2015},
  organization={IEEE}
}@article{grubic2018synchronous,
  title={Synchronous Multi-GPU Deep Learning with Low-Precision Communication: An Experimental Study},
  author={Grubic, D and Tam, L and Alistarh, Dan and Zhang, Ce},
  journal={Proceedings of the EDBT 2018},
  year={2018}
}

@inproceedings{sirb2016consensus,
  title={Consensus optimization with delayed and stochastic gradients on decentralized networks},
  author={Sirb, Benjamin and Ye, Xiaojing},
  booktitle={Big Data (Big Data), 2016 IEEE International Conference on},
  pages={76--85},
  year={2016},
  organization={IEEE}
}

@article{wu2018decentralized,
  title={Decentralized consensus optimization with asynchrony and delays},
  author={Wu, Tianyu and Yuan, Kun and Ling, Qing and Yin, Wotao and Sayed, Ali H},
  journal={IEEE Transactions on Signal and Information Processing over Networks},
  volume={4},
  number={2},
  pages={293--307},
  year={2018},
  publisher={IEEE}
}

@inproceedings{seide20141,
  title={1-bit stochastic gradient descent and its application to data-parallel distributed training of speech dnns},
  author={Seide, Frank and Fu, Hao and Droppo, Jasha and Li, Gang and Yu, Dong},
  booktitle={Fifteenth Annual Conference of the International Speech Communication Association},
  year={2014}
}

@inproceedings{suresh2017distributed,
  title={Distributed mean estimation with limited communication},
  author={Suresh, Ananda Theertha and Yu, Felix X and Kumar, Sanjiv and McMahan, H Brendan},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3329--3337},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{wangni2018gradient,
  title={Gradient sparsification for communication-efficient distributed optimization},
  author={Wangni, Jianqiao and Wang, Jialei and Liu, Ji and Zhang, Tong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1306--1316},
  year={2018}
}

@inproceedings{stich2018sparsified,
  title={Sparsified sgd with memory},
  author={Stich, Sebastian U and Cordonnier, Jean-Baptiste and Jaggi, Martin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4452--4463},
  year={2018}
}

@inproceedings{dobbe2017fully,
  title={Fully decentralized policies for multi-agent systems: An information theoretic approach},
  author={Dobbe, Roel and Fridovich-Keil, David and Tomlin, Claire},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2941--2950},
  year={2017}
}

@inproceedings{he2018cola,
  title={COLA: Decentralized Linear Learning},
  author={He, Lie and Bian, An and Jaggi, Martin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4541--4551},
  year={2018}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{koloskova2019decentralized,
  title={Decentralized Stochastic Optimization and Gossip Algorithms with Compressed Communication},
  author={Koloskova, Anastasia and Stich, Sebastian U and Jaggi, Martin},
  journal={arXiv preprint arXiv:1902.00340},
  year={2019}
}

@inproceedings{yu2019dist,
title={Distributed Learning over Unreliable Networks},
  author={Yu, Chen and Tang, Hanlin and Renggli, Cedric and Kassing, Simon and Singla, Ankit and Alistarh, Dan and Zhang, Ce and Liu, Ji},
  booktitle={International Conference on Machine Learning},
  pages={7202--7212},
  year={2019}
}

@inproceedings{wen2017terngrad,
  title={Terngrad: Ternary gradients to reduce communication in distributed deep learning},
  author={Wen, Wei and Xu, Cong and Yan, Feng and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
  booktitle={Advances in neural information processing systems},
  pages={1509--1519},
  year={2017}
}

@inproceedings{jiang2018linear,
  title={A linear speedup analysis of distributed deep learning with sparse and quantized communication},
  author={Jiang, Peng and Agrawal, Gagan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2525--2536},
  year={2018}
}

@article{nazari2019dadam,
  title={DADAM: A consensus-based distributed adaptive gradient method for online optimization},
  author={Nazari, Parvin and Tarzanagh, Davoud Ataee and Michailidis, George},
  journal={arXiv preprint arXiv:1901.09109},
  year={2019}
}

@article{zhang2019asynchronous,
  title={Asynchronous Decentralized Optimization in Directed Networks},
  author={Zhang, Jiaqi and You, Keyou},
  journal={arXiv preprint arXiv:1901.08215},
  year={2019}
}

@article{han2015deep,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={arXiv preprint arXiv:1510.00149},
  year={2015}
}

@article{assran2018stochastic,
  title={Stochastic gradient push for distributed deep learning},
  author={Assran, Mahmoud and Loizou, Nicolas and Ballas, Nicolas and Rabbat, Michael},
  journal={arXiv preprint arXiv:1811.10792},
  year={2018}
}

@article{acharya2019distributed,
  title={Distributed Learning with Sublinear Communication},
  author={Acharya, Jayadev and De Sa, Christopher and Foster, Dylan J and Sridharan, Karthik},
  journal={arXiv preprint arXiv:1902.11259},
  year={2019}
}

@inproceedings{li2017training,
  title={Training quantized nets: A deeper understanding},
  author={Li, Hao and De, Soham and Xu, Zheng and Studer, Christoph and Samet, Hanan and Goldstein, Tom},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5811--5821},
  year={2017}
}

@inproceedings{gupta2015deep,
  title={Deep learning with limited numerical precision},
  author={Gupta, Suyog and Agrawal, Ankur and Gopalakrishnan, Kailash and Narayanan, Pritish},
  booktitle={International Conference on Machine Learning},
  pages={1737--1746},
  year={2015}
}

@article{aysal2008distributed,
  title={Distributed average consensus with dithered quantization},
  author={Aysal, Tuncer Can and Coates, Mark J and Rabbat, Michael G},
  journal={IEEE Transactions on Signal Processing},
  volume={56},
  number={10},
  pages={4905--4918},
  year={2008},
  publisher={IEEE}
}

@article{carli2010gossip,
  title={Gossip consensus algorithms via quantized communication},
  author={Carli, Ruggero and Fagnani, Fabio and Frasca, Paolo and Zampieri, Sandro},
  journal={Automatica},
  volume={46},
  number={1},
  pages={70--80},
  year={2010},
  publisher={Elsevier}
}

@article{carli2010quantized,
  title={Quantized average consensus via dynamic coding/decoding schemes},
  author={Carli, Ruggero and Bullo, Francesco and Zampieri, Sandro},
  journal={International Journal of Robust and Nonlinear Control: IFAC-Affiliated Journal},
  volume={20},
  number={2},
  pages={156--175},
  year={2010},
  publisher={Wiley Online Library}
}

@inproceedings{dean2012large,
  title={Large scale distributed deep networks},
  author={Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Mao, Mark and Senior, Andrew and Tucker, Paul and Yang, Ke and Le, Quoc V and others},
  booktitle={Advances in neural information processing systems},
  pages={1223--1231},
  year={2012}
}

@incollection{bottou2010large,
  title={Large-scale machine learning with stochastic gradient descent},
  author={Bottou, L{\'e}on},
  booktitle={Proceedings of COMPSTAT'2010},
  pages={177--186},
  year={2010},
  publisher={Springer}
}

@inproceedings{zhang2004solving,
  title={Solving large scale linear prediction problems using stochastic gradient descent algorithms},
  author={Zhang, Tong},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={116},
  year={2004},
  organization={ACM}
}

@inproceedings{alistarh2018brief,
  title={A Brief Tutorial on Distributed and Concurrent Machine Learning},
  author={Alistarh, Dan},
  booktitle={Proceedings of the 2018 ACM Symposium on Principles of Distributed Computing},
  pages={487--488},
  year={2018},
  organization={ACM}
}

@article{goyal2017accurate,
  title={Accurate, large minibatch sgd: Training imagenet in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv preprint arXiv:1706.02677},
  year={2017}
}

@inproceedings{wang2018atomo,
  title={Atomo: Communication-efficient learning via atomic sparsification},
  author={Wang, Hongyi and Sievert, Scott and Liu, Shengchao and Charles, Zachary and Papailiopoulos, Dimitris and Wright, Stephen},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9850--9861},
  year={2018}
}

@inproceedings{alistarh2018convergence,
  title={The convergence of sparsified gradient methods},
  author={Alistarh, Dan and Hoefler, Torsten and Johansson, Mikael and Konstantinov, Nikola and Khirirat, Sarit and Renggli, C{\'e}dric},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5973--5983},
  year={2018}
}

@inproceedings{doan2018convergence,
  title={On the Convergence of Distributed Subgradient Methods under Quantization},
  author={Doan, Thinh T and Maguluri, Siva Theja and Romberg, Justin},
  booktitle={2018 56th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  pages={567--574},
  year={2018},
  organization={IEEE}
}

@inproceedings{de2017understanding,
  title={Understanding and optimizing asynchronous low-precision stochastic gradient descent},
  author={De Sa, Christopher and Feldman, Matthew and R{\'e}, Christopher and Olukotun, Kunle},
  booktitle={ACM SIGARCH Computer Architecture News},
  volume={45},
  number={2},
  pages={561--574},
  year={2017},
  organization={ACM}
}

@article{hendrikx2018accelerated,
  title={Accelerated decentralized optimization with local updates for smooth and strongly convex objectives},
  author={Hendrikx, Hadrien and Massouli{\'e}, Laurent and Bach, Francis},
  journal={arXiv preprint arXiv:1810.02660},
  year={2018}
}

@book{levin2017markov,
  title={Markov chains and mixing times},
  author={Levin, David A and Peres, Yuval},
  volume={107},
  year={2017},
  publisher={American Mathematical Soc.}
}

@article{stich2018local,
  title={Local SGD converges fast and communicates little},
  author={Stich, Sebastian U},
  journal={arXiv preprint arXiv:1805.09767},
  year={2018}
}

@article{de2018high,
  title={High-accuracy low-precision training},
  author={De Sa, Christopher and Leszczynski, Megan and Zhang, Jian and Marzoev, Alana and Aberger, Christopher R and Olukotun, Kunle and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:1803.03383},
  year={2018}
}

@article{tang2019texttt,
  title={DeepSqueeze: Parallel Stochastic Gradient Descent with Double-Pass Error-Compensated Compression},
  author={Tang, Hanlin and Lian, Xiangru and Qiu, Shuang and Yuan, Lei and Zhang, Ce and Zhang, Tong and Liu, Ji},
  journal={arXiv preprint arXiv:1907.07346},
  year={2019}
}

@inproceedings{recht2011hogwild,
  title={Hogwild: A lock-free approach to parallelizing stochastic gradient descent},
  author={Recht, Benjamin and Re, Christopher and Wright, Stephen and Niu, Feng},
  booktitle={Advances in neural information processing systems},
  pages={693--701},
  year={2011}
}

@article{bergstra2012random,
  title={Random search for hyper-parameter optimization},
  author={Bergstra, James and Bengio, Yoshua},
  journal={Journal of machine learning research},
  volume={13},
  number={Feb},
  pages={281--305},
  year={2012}
}

@inproceedings{al2003certificateless,
  title={Certificateless public key cryptography},
  author={Al-Riyami, Sattam S and Paterson, Kenneth G},
  booktitle={International conference on the theory and application of cryptology and information security},
  pages={452--473},
  year={2003},
  organization={Springer}
}