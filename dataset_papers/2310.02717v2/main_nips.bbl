\begin{thebibliography}{42}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbasi-Yadkori et~al.(2011)Abbasi-Yadkori, P{\'a}l, and Szepesv{\'a}ri]{abbasi2011improved}
Yasin Abbasi-Yadkori, D{\'a}vid P{\'a}l, and Csaba Szepesv{\'a}ri.
\newblock Improved algorithms for linear stochastic bandits.
\newblock \emph{Advances in neural information processing systems}, 24, 2011.

\bibitem[Auer et~al.(2002)Auer, Cesa-Bianchi, and Fischer]{auer2002finite}
Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock \emph{Machine learning}, 47\penalty0 (2):\penalty0 235--256, 2002.

\bibitem[Ban and He(2021)]{ban2021local}
Yikun Ban and Jingrui He.
\newblock Local clustering in contextual multi-armed bandits.
\newblock In \emph{Proceedings of the Web Conference 2021}, pages 2335--2346, 2021.

\bibitem[Bubeck et~al.(2012)Bubeck, Cesa-Bianchi, et~al.]{bubeck2012regret}
S{\'e}bastien Bubeck, Nicolo Cesa-Bianchi, et~al.
\newblock Regret analysis of stochastic and nonstochastic multi-armed bandit problems.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning}, 5\penalty0 (1):\penalty0 1--122, 2012.

\bibitem[Cai et~al.(2018)Cai, Liu, Chen, and Lui]{cai2018online}
Kechao Cai, Xutong Liu, Yu-Zhen~Janice Chen, and John~CS Lui.
\newblock An online learning approach to network application optimization with guarantee.
\newblock In \emph{IEEE INFOCOM 2018-IEEE Conference on Computer Communications}, pages 2006--2014. IEEE, 2018.

\bibitem[Cella and Pontil(2021)]{cella2021multi}
Leonardo Cella and Massimiliano Pontil.
\newblock Multi-task and meta-learning with sparse linear bandits.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pages 1692--1702. PMLR, 2021.

\bibitem[Cella et~al.(2020)Cella, Lazaric, and Pontil]{cella2020meta}
Leonardo Cella, Alessandro Lazaric, and Massimiliano Pontil.
\newblock Meta-learning with stochastic linear bandits.
\newblock In \emph{International Conference on Machine Learning}, pages 1360--1370. PMLR, 2020.

\bibitem[Cella et~al.(2023)Cella, Lounici, Pacreau, and Pontil]{cella2023multi}
Leonardo Cella, Karim Lounici, Gr{\'e}goire Pacreau, and Massimiliano Pontil.
\newblock Multi-task representation learning with stochastic linear bandits.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 4822--4847. PMLR, 2023.

\bibitem[Chu et~al.(2011)Chu, Li, Reyzin, and Schapire]{chu2011contextual}
Wei Chu, Lihong Li, Lev Reyzin, and Robert Schapire.
\newblock Contextual bandits with linear payoff functions.
\newblock In \emph{Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics}, pages 208--214. JMLR Workshop and Conference Proceedings, 2011.

\bibitem[Deshmukh et~al.(2017)Deshmukh, Dogan, and Scott]{deshmukh2017multi}
Aniket~Anand Deshmukh, Urun Dogan, and Clay Scott.
\newblock Multi-task learning for contextual bandits.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Foster et~al.(2020)Foster, Gentile, Mohri, and Zimmert]{foster2020adapting}
Dylan~J Foster, Claudio Gentile, Mehryar Mohri, and Julian Zimmert.
\newblock Adapting to misspecification in contextual bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 11478--11489, 2020.

\bibitem[Gentile et~al.(2014)Gentile, Li, and Zappella]{gentile2014online}
Claudio Gentile, Shuai Li, and Giovanni Zappella.
\newblock Online clustering of bandits.
\newblock In \emph{International Conference on Machine Learning}, pages 757--765. PMLR, 2014.

\bibitem[Gentile et~al.(2017)Gentile, Li, Kar, Karatzoglou, Zappella, and Etrue]{gentile2017context}
Claudio Gentile, Shuai Li, Purushottam Kar, Alexandros Karatzoglou, Giovanni Zappella, and Evans Etrue.
\newblock On context-dependent clustering of bandits.
\newblock In \emph{International Conference on machine learning}, pages 1253--1262. PMLR, 2017.

\bibitem[Ghosh et~al.(2017)Ghosh, Chowdhury, and Gopalan]{ghosh2017misspecified}
Avishek Ghosh, Sayak~Ray Chowdhury, and Aditya Gopalan.
\newblock Misspecified linear bandits.
\newblock In \emph{Thirty-First AAAI Conference on Artificial Intelligence}, 2017.

\bibitem[Hainmueller and Hazlett(2014)]{hainmueller2014kernel}
Jens Hainmueller and Chad Hazlett.
\newblock Kernel regularized least squares: Reducing misspecification bias with a flexible and interpretable machine learning approach.
\newblock \emph{Political Analysis}, 22\penalty0 (2):\penalty0 143--168, 2014.

\bibitem[Hariri et~al.(2014)Hariri, Mobasher, and Burke]{hariri2014context}
Negar Hariri, Bamshad Mobasher, and Robin Burke.
\newblock Context adaptation in interactive recommender systems.
\newblock In \emph{Proceedings of the 8th ACM Conference on Recommender Systems}, pages 41--48, 2014.

\bibitem[Harper and Konstan(2015)]{harper2015movielens}
F~Maxwell Harper and Joseph~A Konstan.
\newblock The movielens datasets: History and context.
\newblock \emph{Acm transactions on interactive intelligent systems (tiis)}, 5\penalty0 (4):\penalty0 1--19, 2015.

\bibitem[Hong et~al.(2022)Hong, Kveton, Zaheer, and Ghavamzadeh]{hong2022hierarchical}
Joey Hong, Branislav Kveton, Manzil Zaheer, and Mohammad Ghavamzadeh.
\newblock Hierarchical bayesian bandits.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 7724--7741. PMLR, 2022.

\bibitem[Huang et~al.(2021)Huang, Wu, Yang, and Shen]{huang2021federated}
Ruiquan Huang, Weiqiang Wu, Jing Yang, and Cong Shen.
\newblock Federated linear contextual bandits.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 27057--27068, 2021.

\bibitem[Kohli et~al.(2013)Kohli, Salek, and Stoddard]{kohli2013fast}
Pushmeet Kohli, Mahyar Salek, and Greg Stoddard.
\newblock A fast bandit algorithm for recommendation to users with heterogenous tastes.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~27, pages 1135--1141, 2013.

\bibitem[Kong et~al.(2023)Kong, Zhao, and Li]{kong2023best}
Fang Kong, Canzhe Zhao, and Shuai Li.
\newblock Best-of-three-worlds analysis for linear bandits with follow-the-regularized-leader algorithm.
\newblock \emph{arXiv preprint arXiv:2303.06825}, 2023.

\bibitem[Lattimore and Szepesv{\'a}ri(2020)]{lattimore2020bandit}
Tor Lattimore and Csaba Szepesv{\'a}ri.
\newblock \emph{Bandit algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem[Lattimore et~al.(2020)Lattimore, Szepesvari, and Weisz]{lattimore2020learning}
Tor Lattimore, Csaba Szepesvari, and Gellert Weisz.
\newblock Learning with good feature representations in bandits and in rl with a generative model.
\newblock In \emph{International Conference on Machine Learning}, pages 5662--5670. PMLR, 2020.

\bibitem[Li et~al.(2010)Li, Chu, Langford, and Schapire]{li2010contextual}
Lihong Li, Wei Chu, John Langford, and Robert~E Schapire.
\newblock A contextual-bandit approach to personalized news article recommendation.
\newblock In \emph{Proceedings of the 19th international conference on World wide web}, pages 661--670, 2010.

\bibitem[Li and Zhang(2018)]{li2018online}
Shuai Li and Shengyu Zhang.
\newblock Online clustering of contextual cascading bandits.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~32, 2018.

\bibitem[Li et~al.(2016)Li, Karatzoglou, and Gentile]{li2016collaborative}
Shuai Li, Alexandros Karatzoglou, and Claudio Gentile.
\newblock Collaborative filtering bandits.
\newblock In \emph{Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval}, pages 539--548, 2016.

\bibitem[Li et~al.(2019)Li, Chen, Li, and Leung]{10.5555/3367243.3367445}
Shuai Li, Wei Chen, Shuai Li, and Kwong-Sak Leung.
\newblock Improved algorithm on online clustering of bandits.
\newblock In \emph{Proceedings of the 28th International Joint Conference on Artificial Intelligence}, IJCAI'19, page 2923â€“2929. AAAI Press, 2019.
\newblock ISBN 9780999241141.

\bibitem[Liu et~al.(2022)Liu, Zhao, Yu, Li, and Lui]{liu2022federated}
Xutong Liu, Haoru Zhao, Tong Yu, Shuai Li, and John Lui.
\newblock Federated online clustering of bandits.
\newblock In \emph{The 38th Conference on Uncertainty in Artificial Intelligence}, 2022.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Zuo, Wang, Lui, Hajiesmaili, Wierman, and Chen]{liu2023contextual}
Xutong Liu, Jinhang Zuo, Siwei Wang, John~CS Lui, Mohammad Hajiesmaili, Adam Wierman, and Wei Chen.
\newblock Contextual combinatorial bandits with probabilistically triggered arms.
\newblock In \emph{International Conference on Machine Learning}, pages 22559--22593. PMLR, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Zuo, Xie, Joe-Wong, and Lui]{liu2023variance}
Xutong Liu, Jinhang Zuo, Hong Xie, Carlee Joe-Wong, and John~CS Lui.
\newblock Variance-adaptive algorithm for probabilistic maximum coverage bandits with general feedback.
\newblock In \emph{IEEE INFOCOM 2023-IEEE Conference on Computer Communications}, pages 1--10. IEEE, 2023{\natexlab{b}}.

\bibitem[Pacchiano et~al.(2020)Pacchiano, Phan, Abbasi~Yadkori, Rao, Zimmert, Lattimore, and Szepesvari]{pacchiano2020model}
Aldo Pacchiano, My~Phan, Yasin Abbasi~Yadkori, Anup Rao, Julian Zimmert, Tor Lattimore, and Csaba Szepesvari.
\newblock Model selection in contextual stochastic bandit problems.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 10328--10337, 2020.

\bibitem[Shi and Shen(2021)]{shi2021federated}
Chengshuai Shi and Cong Shen.
\newblock Federated multi-armed bandits.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~35, pages 9603--9611, 2021.

\bibitem[Soare et~al.(2014)Soare, Alsharif, Lazaric, and Pineau]{soare2014multi}
Marta Soare, Ouais Alsharif, Alessandro Lazaric, and Joelle Pineau.
\newblock Multi-task linear bandits.
\newblock In \emph{NIPS2014 workshop on transfer and multi-task learning: theory meets practice}, 2014.

\bibitem[Wan et~al.(2021)Wan, Ge, and Song]{wan2021metadata}
Runzhe Wan, Lin Ge, and Rui Song.
\newblock Metadata-based multi-task bandits with bayesian hierarchical models.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 29655--29668, 2021.

\bibitem[Wan et~al.(2023)Wan, Ge, and Song]{wan2023towards}
Runzhe Wan, Lin Ge, and Rui Song.
\newblock Towards scalable and robust structured bandits: A meta-learning framework.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 1144--1173. PMLR, 2023.

\bibitem[Wang et~al.(2021)Wang, Zhang, Singh, Riek, and Chaudhuri]{wang2021multitask}
Zhi Wang, Chicheng Zhang, Manish~Kumar Singh, Laurel Riek, and Kamalika Chaudhuri.
\newblock Multitask bandit learning through heterogeneous feedback aggregation.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 1531--1539. PMLR, 2021.

\bibitem[Wang et~al.(2022)Wang, Zhang, and Chaudhuri]{wang2022thompson}
Zhi Wang, Chicheng Zhang, and Kamalika Chaudhuri.
\newblock Thompson sampling for robust transfer in multi-task bandits.
\newblock \emph{arXiv preprint arXiv:2206.08556}, 2022.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Liu, Li, and Lui]{wang2023efficient}
Zhiyong Wang, Xutong Liu, Shuai Li, and John~CS Lui.
\newblock Efficient explorative key-term selection strategies for conversational contextual bandits.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~37, pages 10288--10295, 2023{\natexlab{a}}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Xie, Yu, Li, and Lui]{wang2023online}
Zhiyong Wang, Jize Xie, Tong Yu, Shuai Li, and John Lui.
\newblock Online corrupted user detection and regret minimization.
\newblock \emph{arXiv preprint arXiv:2310.04768}, 2023{\natexlab{b}}.

\bibitem[Wu et~al.(2021)Wu, Zhao, Yu, Li, and Li]{wu2021clustering}
Junda Wu, Canzhe Zhao, Tong Yu, Jingyang Li, and Shuai Li.
\newblock Clustering of conversational bandits for user preference learning and elicitation.
\newblock In \emph{Proceedings of the 30th ACM International Conference on Information \& Knowledge Management}, pages 2129--2139, 2021.

\bibitem[Wu et~al.(2016)Wu, Wang, Gu, and Wang]{wu2016contextual}
Qingyun Wu, Huazheng Wang, Quanquan Gu, and Hongning Wang.
\newblock Contextual bandits in a collaborative environment.
\newblock In \emph{Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval}, pages 529--538, 2016.

\bibitem[Zong et~al.(2016)Zong, Ni, Sung, Ke, Wen, and Kveton]{zong2016cascading}
Shi Zong, Hao Ni, Kenny Sung, Nan~Rosemary Ke, Zheng Wen, and Branislav Kveton.
\newblock Cascading bandits for large-scale recommendation problems.
\newblock \emph{arXiv preprint arXiv:1603.05359}, 2016.

\end{thebibliography}
