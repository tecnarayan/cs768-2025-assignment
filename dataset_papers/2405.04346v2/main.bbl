\begin{thebibliography}{70}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alzantot et~al.(2018)Alzantot, Sharma, Elgohary, Ho, Srivastava, and
  Chang]{alzantot2018generating}
Alzantot, M., Sharma, Y., Elgohary, A., Ho, B.-J., Srivastava, M., and Chang,
  K.-W.
\newblock Generating natural language adversarial examples.
\newblock In \emph{Conference on Empirical Methods in Natural Language
  Processing (EMNLP)}, 2018.

\bibitem[Belinkov \& Bisk(2018)Belinkov and Bisk]{belinkov2018synthetic}
Belinkov, Y. and Bisk, Y.
\newblock Synthetic and natural noise both break neural machine translation.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Bengio et~al.(2000)Bengio, Ducharme, and
  Vincent]{bengio2000embeddings}
Bengio, Y., Ducharme, R., and Vincent, P.
\newblock A neural probabilistic language model.
\newblock \emph{Advances in neural information processing systems (NeurIPS)},
  2000.

\bibitem[Bojanowski et~al.(2017)Bojanowski, Grave, Joulin, and
  Mikolov]{bojanowski2017fasttext}
Bojanowski, P., Grave, E., Joulin, A., and Mikolov, T.
\newblock Enriching word vectors with subword information.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  2017.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, McCandlish, Radford, Sutskever, and Amodei]{Brown2020gpt3}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S.,
  Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler,
  D., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray,
  S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever,
  I., and Amodei, D.
\newblock Language models are few-shot learners.
\newblock In \emph{Advances in neural information processing systems
  (NeurIPS)}, 2020.

\bibitem[Carlini \& Wagner(2017)Carlini and Wagner]{carlini2017towards}
Carlini, N. and Wagner, D.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{2017 IEEE symposium on security and privacy (sp)}, 2017.

\bibitem[Carlini et~al.(2023)Carlini, Nasr, Choquette-Choo, Jagielski, Gao,
  Koh, Ippolito, Tram{\`e}r, and Schmidt]{carlini2023are}
Carlini, N., Nasr, M., Choquette-Choo, C.~A., Jagielski, M., Gao, I., Koh,
  P.~W., Ippolito, D., Tram{\`e}r, F., and Schmidt, L.
\newblock Are aligned neural networks adversarially aligned?
\newblock In \emph{Advances in neural information processing systems
  (NeurIPS)}, 2023.

\bibitem[Cer et~al.(2018)Cer, Yang, Kong, Hua, Limtiaco, St.~John, Constant,
  Guajardo-Cespedes, Yuan, Tar, Strope, and Kurzweil]{cer2018USE}
Cer, D., Yang, Y., Kong, S.-y., Hua, N., Limtiaco, N., St.~John, R., Constant,
  N., Guajardo-Cespedes, M., Yuan, S., Tar, C., Strope, B., and Kurzweil, R.
\newblock Universal sentence encoder for {E}nglish.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing: System Demonstrations}, 2018.

\bibitem[Chen et~al.(2021)Chen, Tworek, Jun, Yuan, de~Oliveira~Pinto, Kaplan,
  Edwards, Burda, Joseph, Brockman, Ray, Puri, Krueger, Petrov, Khlaaf, Sastry,
  Mishkin, Chan, Gray, Ryder, Pavlov, Power, Kaiser, Bavarian, Winter, Tillet,
  Such, Cummings, Plappert, Chantzis, Barnes, Herbert-Voss, Guss, Nichol,
  Paino, Tezak, Tang, Babuschkin, Balaji, Jain, Saunders, Hesse, Carr, Leike,
  Achiam, Misra, Morikawa, Radford, Knight, Brundage, Murati, Mayer, Welinder,
  McGrew, Amodei, McCandlish, Sutskever, and Zaremba]{chen2021copilot}
Chen, M., Tworek, J., Jun, H., Yuan, Q., de~Oliveira~Pinto, H.~P., Kaplan, J.,
  Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger,
  G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S.,
  Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavarian, M., Winter, C.,
  Tillet, P., Such, F.~P., Cummings, D., Plappert, M., Chantzis, F., Barnes,
  E., Herbert-Voss, A., Guss, W.~H., Nichol, A., Paino, A., Tezak, N., Tang,
  J., Babuschkin, I., Balaji, S., Jain, S., Saunders, W., Hesse, C., Carr,
  A.~N., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford, A., Knight,
  M., Brundage, M., Murati, M., Mayer, K., Welinder, P., McGrew, B., Amodei,
  D., McCandlish, S., Sutskever, I., and Zaremba, W.
\newblock Evaluating large language models trained on code.
\newblock \emph{arXiv preprint arXiv:2107.03374}, 2021.

\bibitem[Cheng et~al.(2020)Cheng, Yi, Chen, Zhang, and
  Hsieh]{cheng2020seq2sick}
Cheng, M., Yi, J., Chen, P.-Y., Zhang, H., and Hsieh, C.-J.
\newblock Seq2sick: Evaluating the robustness of sequence-to-sequence models
  with adversarial examples.
\newblock \emph{AAAI Conference on Artificial Intelligence}, 34, 2020.

\bibitem[Chiang et~al.(2023)Chiang, Li, Lin, Sheng, Wu, Zhang, Zheng, Zhuang,
  Zhuang, Gonzalez, et~al.]{chiang2023vicuna}
Chiang, W.-L., Li, Z., Lin, Z., Sheng, Y., Wu, Z., Zhang, H., Zheng, L.,
  Zhuang, S., Zhuang, Y., Gonzalez, J.~E., et~al.
\newblock Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt
  quality.
\newblock \emph{See https://vicuna. lmsys. org (accessed 14 April 2023)}, 2023.

\bibitem[Dagan et~al.(2006)Dagan, Glickman, and Magnini]{dagan2006rte}
Dagan, I., Glickman, O., and Magnini, B.
\newblock The pascal recognising textual entailment challenge.
\newblock In Qui{\~{n}}onero-Candela, J., Dagan, I., Magnini, B., and
  d'Alch{\'e} Buc, F. (eds.), \emph{Machine Learning Challenges. Evaluating
  Predictive Uncertainty, Visual Object Classification, and Recognising Tectual
  Entailment}. Springer Berlin Heidelberg, 2006.

\bibitem[Davis(2003)]{davis2003words}
Davis, M.
\newblock Psycholinguistic evidence on scrambled letters in reading, 2003.
\newblock URL \url{https://www.mrc-cbu.cam.ac.uk/people/matt.davis/cmabridge/}.

\bibitem[Demontis et~al.(2019)Demontis, Melis, Pintor, Jagielski, Biggio,
  Oprea, Nita-Rotaru, and Roli]{demontis2019adversarial}
Demontis, A., Melis, M., Pintor, M., Jagielski, M., Biggio, B., Oprea, A.,
  Nita-Rotaru, C., and Roli, F.
\newblock Why do adversarial attacks transfer? explaining transferability of
  evasion and poisoning attacks.
\newblock In \emph{28th USENIX security symposium (USENIX security 19)}, pp.\
  321--338, 2019.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{devlin2019bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, 2019.

\bibitem[Dyrmishi et~al.(2023)Dyrmishi, Ghamizi, and Cordy]{dyrmishi2023humans}
Dyrmishi, S., Ghamizi, S., and Cordy, M.
\newblock How do humans perceive adversarial text? a reality check on the
  validity and naturalness of word-based adversarial attacks.
\newblock In \emph{Proceedings of the 61st Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, 2023.

\bibitem[Ebrahimi et~al.(2018)Ebrahimi, Rao, Lowd, and
  Dou]{ebrahimi-etal-2018-hotflip}
Ebrahimi, J., Rao, A., Lowd, D., and Dou, D.
\newblock {H}ot{F}lip: White-box adversarial examples for text classification.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 2: Short Papers)}, 2018.

\bibitem[Gao et~al.(2018)Gao, Lanchantin, Soffa, and Qi]{gao2018deepwordbug}
Gao, J., Lanchantin, J., Soffa, M.~L., and Qi, Y.
\newblock Black-box generation of adversarial text sequences to evade deep
  learning classifiers.
\newblock In \emph{IEEE Security and Privacy Workshops (SPW)}, 2018.

\bibitem[Garg \& Ramakrishnan(2020)Garg and Ramakrishnan]{garg2020bae}
Garg, S. and Ramakrishnan, G.
\newblock {BAE}: {BERT}-based adversarial examples for text classification.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, 2020.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{Goodfellow2015}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock In Bengio, Y. and LeCun, Y. (eds.), \emph{International Conference on
  Learning Representations (ICLR)}, 2015.

\bibitem[Gulli(2005)]{gulli2005agnews}
Gulli, A.
\newblock Ag's corpus of news articles, 2005.
\newblock URL
  \url{http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html}.

\bibitem[Guo et~al.(2021)Guo, Sablayrolles, J{\'e}gou, and
  Kiela]{guo2021gradient}
Guo, C., Sablayrolles, A., J{\'e}gou, H., and Kiela, D.
\newblock Gradient-based adversarial attacks against text transformers.
\newblock In \emph{Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, 2021.

\bibitem[Held et~al.(1974)Held, Wolfe, and Crowder]{held1974validation}
Held, M., Wolfe, P., and Crowder, H.~P.
\newblock Validation of subgradient optimization.
\newblock \emph{Mathematical programming}, 6:\penalty0 62--88, 1974.

\bibitem[Hou et~al.(2023)Hou, Jia, Zhang, Zhang, Zhang, Liu, and
  Chang]{hou2023textgrad}
Hou, B., Jia, J., Zhang, Y., Zhang, G., Zhang, Y., Liu, S., and Chang, S.
\newblock Textgrad: Advancing robustness evaluation in {NLP} by gradient-driven
  optimization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2023.

\bibitem[Jin et~al.(2020)Jin, Jin, Zhou, and Szolovits]{Jin2020textfooler}
Jin, D., Jin, Z., Zhou, J.~T., and Szolovits, P.
\newblock Is bert really robust? a strong baseline for natural language attack
  on text classification and entailment.
\newblock \emph{AAAI Conference on Artificial Intelligence}, 2020.

\bibitem[Jones et~al.(2020)Jones, Jia, Raghunathan, and
  Liang]{jones2020robencodings}
Jones, E., Jia, R., Raghunathan, A., and Liang, P.
\newblock Robust encodings: A framework for combating adversarial typos.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, 2020.

\bibitem[Kudo \& Richardson(2018)Kudo and Richardson]{kudo2018sentencepiece}
Kudo, T. and Richardson, J.
\newblock {S}entence{P}iece: A simple and language independent subword
  tokenizer and detokenizer for neural text processing.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing: System Demonstrations}. Association for
  Computational Linguistics, 2018.

\bibitem[Lan et~al.(2020)Lan, Chen, Goodman, Gimpel, Sharma, and
  Soricut]{Lan2020albert}
Lan, Z., Chen, M., Goodman, S., Gimpel, K., Sharma, P., and Soricut, R.
\newblock Albert: A lite bert for self-supervised learning of language
  representations.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Lee et~al.(2022)Lee, Moon, Lee, and Song]{lee2022query}
Lee, D., Moon, S., Lee, J., and Song, H.~O.
\newblock Query-efficient and scalable black-box adversarial attacks on
  discrete sequential data via bayesian optimization.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  12478--12497. PMLR, 2022.

\bibitem[Lei et~al.(2019)Lei, Wu, Chen, Dimakis, Dhillon, and
  Witbrock]{lei2019discrete}
Lei, Q., Wu, L., Chen, P.-Y., Dimakis, A., Dhillon, I.~S., and Witbrock, M.~J.
\newblock Discrete adversarial attacks and submodular optimization with
  applications to text classification.
\newblock \emph{Proceedings of Machine Learning and Systems}, 1:\penalty0
  146--165, 2019.

\bibitem[Levenshtein et~al.(1966)]{levenshtein1966binary}
Levenshtein, V.~I. et~al.
\newblock Binary codes capable of correcting deletions, insertions, and
  reversals.
\newblock In \emph{Soviet physics doklady}, volume~10, pp.\  707--710. Soviet
  Union, 1966.

\bibitem[Li et~al.(2019)Li, Ji, Du, Li, and Wang]{li2019textbugger}
Li, J., Ji, S., Du, T., Li, B., and Wang, T.
\newblock Textbugger: Generating adversarial text against real-world
  applications.
\newblock \emph{Network and Distributed Systems Security (NDSS) Symposium},
  2019.

\bibitem[Li et~al.(2020)Li, Ma, Guo, Xue, and Qiu]{li2020bertattack}
Li, L., Ma, R., Guo, Q., Xue, X., and Qiu, X.
\newblock {BERT}-{ATTACK}: Adversarial attack against {BERT} using {BERT}.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, 2020.

\bibitem[Liu et~al.(2022)Liu, Yu, Hu, Li, Lin, Ma, Yang, and
  Wen]{liu2022character}
Liu, A., Yu, H., Hu, X., Li, S., Lin, L., Ma, F., Yang, Y., and Wen, L.
\newblock Character-level white-box adversarial attacks against transformers
  via attachable subwords substitution.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, 2022.

\bibitem[Liu et~al.(2023)Liu, Xu, Chen, and Xiao]{liu2023autodan}
Liu, X., Xu, N., Chen, M., and Xiao, C.
\newblock Autodan: Generating stealthy jailbreak prompts on aligned large
  language models.
\newblock \emph{arXiv preprint arXiv:2310.04451}, 2023.

\bibitem[Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis,
  Zettlemoyer, and Stoyanov]{liu2019roberta}
Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M.,
  Zettlemoyer, L., and Stoyanov, V.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{arXiv preprint arXiv:1907.11692}, 2019.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2018AT}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Mihov \& Schulz(2004)Mihov and Schulz]{mihov2004fast}
Mihov, S. and Schulz, K.~U.
\newblock Fast approximate search in large dictionaries.
\newblock \emph{Computational Linguistics}, 30\penalty0 (4):\penalty0 451--477,
  2004.
\newblock \doi{10.1162/0891201042544938}.
\newblock URL \url{https://aclanthology.org/J04-4003}.

\bibitem[Mikolov et~al.(2013)Mikolov, Sutskever, Chen, Corrado, and
  Dean]{mikolov2013word2vec}
Mikolov, T., Sutskever, I., Chen, K., Corrado, G.~S., and Dean, J.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In \emph{Advances in neural information processing systems
  (NeurIPS)}, 2013.

\bibitem[Mitankin(2005)]{mitankin2005universal}
Mitankin, P.~N.
\newblock Universal levenshtein automata. building and properties.
\newblock \emph{Sofia University St. Kliment Ohridski}, 2005.

\bibitem[Morris et~al.(2020{\natexlab{a}})Morris, Lifland, Lanchantin, Ji, and
  Qi]{morris2020reevaluating}
Morris, J., Lifland, E., Lanchantin, J., Ji, Y., and Qi, Y.
\newblock Reevaluating adversarial examples in natural language.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2020}, 2020{\natexlab{a}}.

\bibitem[Morris et~al.(2020{\natexlab{b}})Morris, Lifland, Yoo, Grigsby, Jin,
  and Qi]{morris2020textattack}
Morris, J., Lifland, E., Yoo, J.~Y., Grigsby, J., Jin, D., and Qi, Y.
\newblock Textattack: A framework for adversarial attacks, data augmentation,
  and adversarial training in nlp.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing: System Demonstrations}, 2020{\natexlab{b}}.

\bibitem[Nasr et~al.(2023)Nasr, Carlini, Hayase, Jagielski, Cooper, Ippolito,
  Choquette-Choo, Wallace, Tramèr, and Lee]{nasr2023scalable}
Nasr, M., Carlini, N., Hayase, J., Jagielski, M., Cooper, A.~F., Ippolito, D.,
  Choquette-Choo, C.~A., Wallace, E., Tramèr, F., and Lee, K.
\newblock Scalable extraction of training data from (production) language
  models, 2023.

\bibitem[OpenAI(2023)]{openai2023gpt4}
OpenAI.
\newblock Gpt-4 technical report.
\newblock \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem[Palmer(2000)]{palmer2000tokenisation}
Palmer, D.~D.
\newblock Tokenisation and sentence segmentation.
\newblock \emph{Handbook of natural language processing}, 2000.

\bibitem[Pennington et~al.(2014)Pennington, Socher, and
  Manning]{pennington2014glove}
Pennington, J., Socher, R., and Manning, C.~D.
\newblock Glove: Global vectors for word representation.
\newblock In \emph{Proceedings of the 2014 conference on empirical methods in
  natural language processing (EMNLP)}, pp.\  1532--1543, 2014.

\bibitem[Peters et~al.(2018)Peters, Neumann, Iyyer, Gardner, Clark, Lee, and
  Zettlemoyer]{peters2018elmo}
Peters, M.~E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and
  Zettlemoyer, L.
\newblock Deep contextualized word representations.
\newblock In \emph{Proceedings of the 2018 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}, 2018.

\bibitem[Pruthi et~al.(2019)Pruthi, Dhingra, and
  Lipton]{pruthi2019misspellings}
Pruthi, D., Dhingra, B., and Lipton, Z.~C.
\newblock Combating adversarial misspellings with robust word recognition.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, 2019.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever,
  et~al.]{radford2019gpt2}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 2019.

\bibitem[Rajpurkar et~al.(2016)Rajpurkar, Zhang, Lopyrev, and
  Liang]{rajpurkar2016qnli}
Rajpurkar, P., Zhang, J., Lopyrev, K., and Liang, P.
\newblock {SQ}u{AD}: 100,000+ questions for machine comprehension of text.
\newblock In Su, J., Duh, K., and Carreras, X. (eds.), \emph{Proceedings of the
  2016 Conference on Empirical Methods in Natural Language Processing}, pp.\
  2383--2392, Austin, Texas, November 2016. Association for Computational
  Linguistics.
\newblock \doi{10.18653/v1/D16-1264}.
\newblock URL \url{https://aclanthology.org/D16-1264}.

\bibitem[Rawlinson(1976)]{rawlinson1976words}
Rawlinson, G.
\newblock \emph{The Significance of Letter Position in Word Recognition}.
\newblock Phd thesis, Nottingham University, 1976.

\bibitem[Ren et~al.(2019)Ren, Deng, He, and Che]{ren2019PWWS}
Ren, S., Deng, Y., He, K., and Che, W.
\newblock Generating natural language adversarial examples through probability
  weighted word saliency.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, 2019.

\bibitem[Sadrizadeh et~al.(2023{\natexlab{a}})Sadrizadeh, Aghdam, Dolamic, and
  Frossard]{sadrizadeh2023targetedMT}
Sadrizadeh, S., Aghdam, A.~D., Dolamic, L., and Frossard, P.
\newblock Targeted adversarial attacks against neural machine translation.
\newblock In \emph{ICASSP 2023-2023 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  1--5. IEEE, 2023{\natexlab{a}}.

\bibitem[Sadrizadeh et~al.(2023{\natexlab{b}})Sadrizadeh, Dolamic, and
  Frossard]{sadrizadeh2023transfool}
Sadrizadeh, S., Dolamic, L., and Frossard, P.
\newblock Transfool: An adversarial attack against neural machine translation
  models.
\newblock \emph{Transactions on Machine Learning Research}, 2023{\natexlab{b}}.
\newblock ISSN 2835-8856.
\newblock URL \url{https://openreview.net/forum?id=sFk3aBNb81}.

\bibitem[Sennrich et~al.(2015)Sennrich, Haddow, and Birch]{sennrich2015BPE}
Sennrich, R., Haddow, B., and Birch, A.
\newblock Neural machine translation of rare words with subword units.
\newblock \emph{arXiv preprint arXiv:1508.07909}, 2015.

\bibitem[Socher et~al.(2013)Socher, Perelygin, Wu, Chuang, Manning, Ng, and
  Potts]{socher2013sst}
Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C.~D., Ng, A., and
  Potts, C.
\newblock Recursive deep models for semantic compositionality over a sentiment
  treebank.
\newblock In \emph{Proceedings of the 2013 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, 2013.

\bibitem[Song et~al.(2021)Song, Salcianu, Song, Dopson, and
  Zhou]{song2021fastwordpiece}
Song, X., Salcianu, A., Song, Y., Dopson, D., and Zhou, D.
\newblock Fast {W}ord{P}iece tokenization.
\newblock In \emph{Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}. Association for Computational Linguistics,
  2021.

\bibitem[Sutskever et~al.(2014)Sutskever, Vinyals, and
  Le]{sutskever2014sequence}
Sutskever, I., Vinyals, O., and Le, Q.~V.
\newblock Sequence to sequence learning with neural networks.
\newblock \emph{Advances in neural information processing systems (NeurIPS)},
  27, 2014.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{Szegedy2014}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2014.

\bibitem[Touvron et~al.(2023)Touvron, Martin, Stone, Albert, Almahairi, Babaei,
  Bashlykov, Batra, Bhargava, Bhosale, et~al.]{touvron2023llama}
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y.,
  Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv preprint arXiv:2307.09288}, 2023.

\bibitem[Touzet(2016)]{touzet2016levenshtein}
Touzet, H.
\newblock On the levenshtein automaton and the size of the neighbourhood of a
  word.
\newblock In \emph{Language and Automata Theory and Applications}, pp.\
  207--218. Springer, 2016.

\bibitem[Wallace et~al.(2020)Wallace, Stern, and Song]{wallace2020imitationMT}
Wallace, E., Stern, M., and Song, D.
\newblock Imitation attacks and defenses for black-box machine translation
  systems.
\newblock In Webber, B., Cohn, T., He, Y., and Liu, Y. (eds.),
  \emph{Proceedings of the 2020 Conference on Empirical Methods in Natural
  Language Processing (EMNLP)}, Online, 2020. Association for Computational
  Linguistics.

\bibitem[Wang et~al.(2019)Wang, Singh, Michael, Hill, Levy, and
  Bowman]{wang2018glue}
Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., and Bowman, S.~R.
\newblock {GLUE}: A multi-task benchmark and analysis platform for natural
  language understanding.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.

\bibitem[Webster \& Kit(1992)Webster and Kit]{websterkit1992tokenization}
Webster, J.~J. and Kit, C.
\newblock Tokenization as the initial phase in {NLP}.
\newblock In \emph{{COLING} 1992 Volume 4: The 14th {I}nternational
  {C}onference on {C}omputational {L}inguistics}, 1992.

\bibitem[Williams et~al.(2018)Williams, Nangia, and Bowman]{williams2018mnli}
Williams, A., Nangia, N., and Bowman, S.
\newblock A broad-coverage challenge corpus for sentence understanding through
  inference.
\newblock In \emph{Proceedings of the 2018 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}. Association for Computational
  Linguistics, 2018.

\bibitem[Yang et~al.(2020)Yang, Chen, Hsieh, Wang, and Jordan]{Yang2020greedy}
Yang, P., Chen, J., Hsieh, C.-J., Wang, J.-L., and Jordan, M.~I.
\newblock Greedy attack and gumbel attack: Generating adversarial examples for
  discrete data.
\newblock \emph{Journal of Machine Learning Research}, 21\penalty0
  (43):\penalty0 1--36, 2020.
\newblock URL \url{http://jmlr.org/papers/v21/19-569.html}.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, Ghaoui, and
  Jordan]{Zhang2019TRADES}
Zhang, H., Yu, Y., Jiao, J., Xing, E., Ghaoui, L.~E., and Jordan, M.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2019.

\bibitem[Zhang et~al.(2015)Zhang, Zhao, and LeCun]{zhang2015agnews}
Zhang, X., Zhao, J., and LeCun, Y.
\newblock Character-level convolutional networks for text classification.
\newblock In Cortes, C., Lawrence, N., Lee, D., Sugiyama, M., and Garnett, R.
  (eds.), \emph{Advances in Neural Information Processing Systems}, volume~28.
  Curran Associates, Inc., 2015.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2015/file/250cf8b51c773f3f8dc8b4be867a9a02-Paper.pdf}.

\bibitem[Zhu et~al.(2023)Zhu, Zhang, An, Wu, Barrow, Wang, Huang, Nenkova, and
  Sun]{zhu2023autodan}
Zhu, S., Zhang, R., An, B., Wu, G., Barrow, J., Wang, Z., Huang, F., Nenkova,
  A., and Sun, T.
\newblock Autodan: Automatic and interpretable adversarial attacks on large
  language models.
\newblock \emph{arXiv preprint arXiv:2310.15140}, 2023.

\bibitem[Zou et~al.(2023)Zou, Wang, Kolter, and Fredrikson]{zou2023universal}
Zou, A., Wang, Z., Kolter, J.~Z., and Fredrikson, M.
\newblock Universal and transferable adversarial attacks on aligned language
  models.
\newblock \emph{arXiv preprint arXiv:2307.15043}, 2023.

\end{thebibliography}
