\newcommand{\noopsort}[1]{} \newcommand{\printfirst}[2]{#1}
  \newcommand{\singleletter}[1]{#1} \newcommand{\switchargs}[2]{#2#1}
\begin{thebibliography}{10}

\bibitem{AHV04}
P.~Agarwal, S.~Har-Peled, and K.~Varadarajan.
\newblock Approximating extent measures of points.
\newblock {\em Journal of the ACM}, 51(4):606--635, 2004.

\bibitem{bachem2015coresets}
O.~Bachem, M.~Lucic, and A.~Krause.
\newblock Coresets for nonparametric estimation-the case of dp-means.
\newblock In {\em ICML}, pages 209--217, 2015.

\bibitem{bachem2018scalable}
O.~Bachem, M.~Lucic, and A.~Krause.
\newblock Scalable k-means clustering via lightweight coresets.
\newblock In {\em KDD'18 Proceedings of the 24th ACM SIGKDD International
  Conference on Knowledge Discovery \& Data Mining}, pages 1119--1127. ACM,
  2018.

\bibitem{pmlr-v84-bachem18a}
O.~Bachem, M.~Lucic, and S.~Lattanzi.
\newblock One-shot coresets: The case of k-clustering.
\newblock In A.~Storkey and F.~Perez-Cruz, editors, {\em Proceedings of the
  Twenty-First International Conference on Artificial Intelligence and
  Statistics}, volume~84 of {\em Proceedings of Machine Learning Research},
  pages 784--792, Playa Blanca, Lanzarote, Canary Islands, 09--11 Apr 2018.
  PMLR.

\bibitem{buadoiu2008optimal}
M.~B{\u{a}}doiu and K.~L. Clarkson.
\newblock Optimal core-sets for balls.
\newblock {\em Computational Geometry}, 40(1):14--22, 2008.

\bibitem{balcan2013distributed}
M.-F.~F. Balcan, S.~Ehrlich, and Y.~Liang.
\newblock Distributed $ k $-means and $ k $-median clustering on general
  topologies.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1995--2003, 2013.

\bibitem{braverman2016new}
V.~Braverman, D.~Feldman, and H.~Lang.
\newblock New frameworks for offline and streaming coreset constructions.
\newblock {\em arXiv preprint arXiv:1612.00889}, 2016.

\bibitem{pmlr-v97-braverman19a}
V.~Braverman, S.~H.-C. Jiang, R.~Krauthgamer, and X.~Wu.
\newblock Coresets for ordered weighted clustering.
\newblock In K.~Chaudhuri and R.~Salakhutdinov, editors, {\em Proceedings of
  the 36th International Conference on Machine Learning}, volume~97 of {\em
  Proceedings of Machine Learning Research}, pages 744--753, Long Beach,
  California, USA, 09--15 Jun 2019. PMLR.

\bibitem{CC01a}
C.-C. Chang and C.-J. Lin.
\newblock {LIBSVM}: A library for support vector machines.
\newblock {\em ACM Transactions on Intelligent Systems and Technology},
  2:27:1--27:27, 2011.
\newblock Software available at \url{http://www.csie.ntu.edu.tw/~cjlin/libsvm}.

\bibitem{clarkson2005subgradient}
K.~L. Clarkson.
\newblock Subgradient and sampling algorithms for l 1 regression.
\newblock In {\em Proceedings of the sixteenth annual ACM-SIAM symposium on
  Discrete algorithms}, pages 257--266. Society for Industrial and Applied
  Mathematics, 2005.

\bibitem{clarkson2010coresets}
K.~L. Clarkson.
\newblock Coresets, sparse greedy approximation, and the frank-wolfe algorithm.
\newblock {\em ACM Transactions on Algorithms (TALG)}, 6(4):63, 2010.

\bibitem{clarkson2017low}
K.~L. Clarkson and D.~P. Woodruff.
\newblock Low-rank approximation and regression in input sparsity time.
\newblock {\em Journal of the ACM (JACM)}, 63(6):1--45, 2017.

\bibitem{cohen2015dimensionality}
M.~B. Cohen, S.~Elder, C.~Musco, C.~Musco, and M.~Persu.
\newblock Dimensionality reduction for k-means clustering and low rank
  approximation.
\newblock In {\em Proceedings of the forty-seventh annual ACM symposium on
  Theory of computing}, pages 163--172, 2015.

\bibitem{cohen2015p}
M.~B. Cohen and R.~Peng.
\newblock L p row sampling by lewis weights.
\newblock In {\em Proceedings of the forty-seventh annual ACM symposium on
  Theory of computing}, pages 183--192. ACM, 2015.

\bibitem{cohen2015lp}
M.~B. Cohen and R.~Peng.
\newblock Lp row sampling by lewis weights.
\newblock In {\em Proceedings of the forty-seventh annual ACM symposium on
  Theory of computing}, pages 183--192, 2015.

\bibitem{corless1996lambertw}
R.~M. Corless, G.~H. Gonnet, D.~E. Hare, D.~J. Jeffrey, and D.~E. Knuth.
\newblock On the lambertw function.
\newblock {\em Advances in Computational mathematics}, 5(1):329--359, 1996.

\bibitem{curtain2019coresets}
R.~Curtain, S.~Im, B.~Moseley, K.~Pruhs, and A.~Samadian.
\newblock On coresets for regularized loss minimization.
\newblock {\em arXiv preprint arXiv:1905.10845}, 2019.

\bibitem{dasgupta2009sampling}
A.~Dasgupta, P.~Drineas, B.~Harb, R.~Kumar, and M.~W. Mahoney.
\newblock Sampling algorithms and coresets for $\backslash$ell\_p regression.
\newblock {\em SIAM Journal on Computing}, 38(5):2060--2078, 2009.

\bibitem{Dua:2019}
D.~Dua and C.~Graff.
\newblock {UCI} machine learning repository, 2017.

\bibitem{feldman2020core}
D.~Feldman.
\newblock Core-sets: Updated survey.
\newblock In {\em Sampling Techniques for Supervised or Unsupervised Tasks},
  pages 23--44. Springer, 2020.

\bibitem{feldman2011scalable}
D.~Feldman, M.~Faulkner, and A.~Krause.
\newblock Scalable training of mixture models via coresets.
\newblock In {\em Advances in neural information processing systems}, pages
  2142--2150, 2011.

\bibitem{feldman2011unified}
D.~Feldman and M.~Langberg.
\newblock A unified framework for approximating and clustering data.
\newblock In {\em Proceedings of the forty-third annual ACM symposium on Theory
  of computing}, pages 569--578. ACM, 2011.

\bibitem{feldman2010coresets}
D.~Feldman, M.~Monemizadeh, C.~Sohler, and D.~P. Woodruff.
\newblock Coresets and sketches for high dimensional subspace approximation
  problems.
\newblock In {\em Proceedings of the twenty-first annual ACM-SIAM symposium on
  Discrete Algorithms}, pages 630--649. SIAM, 2010.

\bibitem{feldman2014coresets}
D.~Feldman, G.~Rossman, M.~Volkov, and D.~Rus.
\newblock Coresets for k-segmentation of streaming data.
\newblock In {\em NIPS}, 2014.

\bibitem{feldman2013turning}
D.~Feldman, M.~Schmidt, and C.~Sohler.
\newblock Turning big data into tiny data: Constant-size coresets for k-means,
  pca and projective clustering.
\newblock In {\em Proceedings of the twenty-fourth annual ACM-SIAM symposium on
  Discrete algorithms}, pages 1434--1453. SIAM, 2013.

\bibitem{feldman2012data}
D.~Feldman and L.~J. Schulman.
\newblock Data reduction for weighted and outlier-resistant clustering.
\newblock In {\em Proceedings of the twenty-third annual ACM-SIAM symposium on
  Discrete Algorithms}, pages 1343--1354. SIAM, 2012.

\bibitem{feurer2015efficient}
M.~Feurer, A.~Klein, K.~Eggensperger, J.~Springenberg, M.~Blum, and F.~Hutter.
\newblock Efficient and robust automated machine learning.
\newblock In {\em Advances in neural information processing systems}, pages
  2962--2970, 2015.

\bibitem{gu2012coreset}
L.~Gu.
\newblock A coreset-based semi-supverised clustering using one-class support
  vector machines.
\newblock In {\em Control Engineering and Communication Technology (ICCECT),
  2012 International Conference on}, pages 52--55. IEEE, 2012.

\bibitem{guyon2015design}
I.~Guyon, K.~Bennett, G.~Cawley, H.~J. Escalante, S.~Escalera, T.~K. Ho,
  N.~Maci{\`a}, B.~Ray, M.~Saeed, A.~Statnikov, et~al.
\newblock Design of the 2015 chalearn automl challenge.
\newblock In {\em 2015 International Joint Conference on Neural Networks
  (IJCNN)}, pages 1--8. IEEE, 2015.

\bibitem{har2007maximum}
S.~Har-Peled, D.~Roth, and D.~Zimak.
\newblock Maximum margin coresets for active and noise tolerant learning.
\newblock In {\em IJCAI}, pages 836--841, 2007.

\bibitem{hastie2009elements}
T.~Hastie, R.~Tibshirani, and J.~Friedman.
\newblock {\em The elements of statistical learning: data mining, inference,
  and prediction}.
\newblock Springer Science \& Business Media, 2009.

\bibitem{huggins2016coresets}
J.~Huggins, T.~Campbell, and T.~Broderick.
\newblock Coresets for scalable bayesian logistic regression.
\newblock In {\em Advances In Neural Information Processing Systems}, pages
  4080--4088, 2016.

\bibitem{john2014extremum}
F.~John.
\newblock Extremum problems with inequalities as subsidiary conditions.
\newblock In {\em Traces and emergence of nonlinear programming}, pages
  197--215. Springer, 2014.

\bibitem{jubran2020sets}
I.~Jubran, M.~Tukan, A.~Maalouf, and D.~Feldman.
\newblock Sets clustering.
\newblock {\em arXiv preprint arXiv:2003.04135}, 2020.

\bibitem{karnin2019discrepancy}
Z.~Karnin and E.~Liberty.
\newblock Discrepancy, coresets, and sketches in machine learning.
\newblock In {\em Conference on Learning Theory}, pages 1975--1993, 2019.

\bibitem{kuang2004applied}
J.-C. Kuang.
\newblock Applied inequalities.
\newblock {\em Shandong Science and Technology Press, Jinan, China}, 3, 2004.

\bibitem{langberg2010universal}
M.~Langberg and L.~J. Schulman.
\newblock Universal $\varepsilon$-approximators for integrals.
\newblock In {\em Proceedings of the twenty-first annual ACM-SIAM symposium on
  Discrete Algorithms}, pages 598--607. SIAM, 2010.

\bibitem{lovasz1986algorithmic}
L.~Lov{\'a}sz.
\newblock {\em An algorithmic theory of numbers, graphs and convexity}.
\newblock SIAM, 1986.

\bibitem{lucic2015strong}
M.~Lucic, O.~Bachem, and A.~Krause.
\newblock Strong coresets for hard and soft bregman clustering with
  applications to exponential family mixtures.
\newblock In A.~Gretton and C.~C. Robert, editors, {\em Proceedings of the 19th
  International Conference on Artificial Intelligence and Statistics},
  volume~51 of {\em Proceedings of Machine Learning Research}, pages 1--9,
  Cadiz, Spain, 09--11 May 2016. PMLR.

\bibitem{lucic2017training}
M.~Lucic, M.~Faulkner, A.~Krause, and D.~Feldman.
\newblock Training gaussian mixture models at scale via coresets.
\newblock {\em The Journal of Machine Learning Research}, 18(1):5885--5909,
  2017.

\bibitem{maalouf2019fast}
A.~Maalouf, I.~Jubran, and D.~Feldman.
\newblock Fast and accurate least-mean-squares solvers.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  8305--8316, 2019.

\bibitem{maalouf2019tight}
A.~Maalouf, A.~Statman, and D.~Feldman.
\newblock Tight sensitivity bounds for smaller coresets.
\newblock {\em arXiv preprint arXiv:1907.01433}, 2019.

\bibitem{meyer2000matrix}
C.~D. Meyer.
\newblock {\em Matrix analysis and applied linear algebra}, volume~71.
\newblock Siam, 2000.

\bibitem{munteanu2018coresets}
A.~Munteanu, C.~Schwiegelshohn, C.~Sohler, and D.~Woodruff.
\newblock On coresets for logistic regression.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6561--6570, 2018.

\bibitem{oliphant2006guide}
T.~E. Oliphant.
\newblock {\em A guide to NumPy}, volume~1.
\newblock Trelgol Publishing USA, 2006.

\bibitem{scikit-learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock {\em Journal of Machine Learning Research}, 12:2825--2830, 2011.

\bibitem{phillips2016coresets}
J.~M. Phillips.
\newblock Coresets and sketches.
\newblock {\em arXiv preprint arXiv:1601.00617}, 2016.

\bibitem{rudin1991functional}
W.~Rudin.
\newblock {\em Functional Analysis}.
\newblock International series in pure and applied mathematics. McGraw-Hill,
  1991.

\bibitem{sarlos2006improved}
T.~Sarlos.
\newblock Improved approximation algorithms for large matrices via random
  projections.
\newblock In {\em 2006 47th Annual IEEE Symposium on Foundations of Computer
  Science (FOCS'06)}, pages 143--152. IEEE, 2006.

\bibitem{schmidt2019fair}
M.~Schmidt, C.~Schwiegelshohn, and C.~Sohler.
\newblock Fair coresets and streaming algorithms for fair k-means.
\newblock In {\em International Workshop on Approximation and Online
  Algorithms}, pages 232--251. Springer, 2019.

\bibitem{sohler2011subspace}
C.~Sohler and D.~P. Woodruff.
\newblock Subspace embeddings for the l1-norm with applications.
\newblock In {\em Proceedings of the forty-third annual ACM symposium on Theory
  of computing}, pages 755--764, 2011.

\bibitem{sohler2018strong}
C.~Sohler and D.~P. Woodruff.
\newblock Strong coresets for k-median and subspace approximation: Goodbye
  dimension.
\newblock In {\em 2018 IEEE 59th Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 802--813. IEEE, 2018.

\bibitem{tolochinsky2018generic}
E.~Tolochinsky and D.~Feldman.
\newblock Generic coreset for scalable learning of monotonic kernels: Logistic
  regression, sigmoid and more.
\newblock {\em arXiv preprint arXiv:1802.07382}, 2018.

\bibitem{tsang2006generalized}
I.-H. Tsang, J.-Y. Kwok, and J.~M. Zurada.
\newblock Generalized core vector machines.
\newblock {\em IEEE Transactions on Neural Networks}, 17(5):1126--1140, 2006.

\bibitem{tsang2005core}
I.~W. Tsang, J.~T. Kwok, and P.-M. Cheung.
\newblock Core vector machines: Fast svm training on very large data sets.
\newblock {\em Journal of Machine Learning Research}, 6(Apr):363--392, 2005.

\bibitem{tsang2005very}
I.~W. Tsang, J.~T.-Y. Kwok, and P.-M. Cheung.
\newblock Very large svm training using core vector machines.
\newblock In {\em AISTATS}, 2005.

\bibitem{tukan2020coresets}
M.~Tukan, C.~Baykal, D.~Feldman, and D.~Rus.
\newblock On coresets for support vector machines.
\newblock {\em arXiv preprint arXiv:2002.06469}, 2020.

\bibitem{uzilov2006detection}
A.~V. Uzilov, J.~M. Keegan, and D.~H. Mathews.
\newblock Detection of non-coding rnas on the basis of predicted secondary
  structure formation free energy change.
\newblock {\em BMC bioinformatics}, 7(1):173, 2006.

\bibitem{10.5555/1593511}
G.~Van~Rossum and F.~L. Drake.
\newblock {\em Python 3 Reference Manual}.
\newblock CreateSpace, Scotts Valley, CA, 2009.

\bibitem{2020SciPy-NMeth}
P.~{Virtanen}, R.~{Gommers}, T.~E. {Oliphant}, M.~{Haberland}, T.~{Reddy},
  D.~{Cournapeau}, E.~{Burovski}, P.~{Peterson}, W.~{Weckesser}, J.~{Bright},
  S.~J. {van der Walt}, M.~{Brett}, J.~{Wilson}, K.~{Jarrod Millman},
  N.~{Mayorov}, A.~R.~J. {Nelson}, E.~{Jones}, R.~{Kern}, E.~{Larson},
  C.~{Carey}, {\.I}.~{Polat}, Y.~{Feng}, E.~W. {Moore}, J.~{Vand erPlas},
  D.~{Laxalde}, J.~{Perktold}, R.~{Cimrman}, I.~{Henriksen}, E.~A. {Quintero},
  C.~R. {Harris}, A.~M. {Archibald}, A.~H. {Ribeiro}, F.~{Pedregosa}, P.~{van
  Mulbregt}, and S.~.~. {Contributors}.
\newblock {SciPy 1.0: Fundamental Algorithms for Scientific Computing in
  Python}.
\newblock {\em Nature Methods}, 2020.

\bibitem{woodruff2013subspace}
D.~Woodruff and Q.~Zhang.
\newblock Subspace embeddings and$\backslash$ell\_p-regression using
  exponential random variables.
\newblock In {\em Conference on Learning Theory}, pages 546--567, 2013.

\end{thebibliography}
