\begin{thebibliography}{}

\bibitem[Dempster et~al., 1977]{dempster1777maximum}
Dempster, A.~P., Laird, N.~M., and Rubin, D.~B. (1977).
\newblock Maximum likelihood from incomplete data via the em algorithm.
\newblock {\em Journal of the Royal Statistical Society, Series B}, 39(1).

\bibitem[Dissmann et~al., 2012]{dissmann2012selecting}
Dissmann, J., Brechmann, E.~C., Czado, C., and Kurowicka, D. (2012).
\newblock Selecting and estimating regular vine copulae and application to
  financial returns.
\newblock {\em arXiv preprint arXiv:1202.2002}.

\bibitem[Fr{\'e}chet, 1960]{frechet1960tableaux}
Fr{\'e}chet, M. (1960).
\newblock Les tableaux dont les marges sont donn{\'e}es.
\newblock {\em Trabajos de estad{\'\i}stica}, 11(1):3--18.

\bibitem[Genest et~al., 2009]{genest2009editorial}
Genest, C., Gerber, H.~U., Goovaerts, M.~J., and Laeven, R. (2009).
\newblock Editorial to the special issue on modeling and measurement of
  multivariate risk in insurance and finance.
\newblock {\em Insurance: Mathematics and Economics}, 44(2):143--145.

\bibitem[Giordano et~al., 2015]{giordano2015linear}
Giordano, R., Broderick, T., and Jordan, M.~I. (2015).
\newblock Linear response methods for accurate covariance estimates from mean
  field variational bayes.
\newblock In {\em Neural Information Processing Systems}.

\bibitem[Gruber and Czado, 2015]{gruber2015sequential}
Gruber, L. and Czado, C. (2015).
\newblock Sequential bayesian model selection of regular vine copulas.
\newblock {\em International Society for Bayesian Analysis}.

\bibitem[Hoff et~al., 2001]{hoff2001latent}
Hoff, P.~D., Raftery, A.~E., and Handcock, M.~S. (2001).
\newblock Latent space approaches to social network analysis.
\newblock {\em Journal of the American Statistical Association}, 97:1090--1098.

\bibitem[Hoffman and Blei, 2015]{hoffman2015structured}
Hoffman, M.~D. and Blei, D.~M. (2015).
\newblock {Structured Stochastic Variational Inference}.
\newblock In {\em Artificial Intelligence and Statistics}.

\bibitem[Hoffman et~al., 2013]{hoffman2013stochastic}
Hoffman, M.~D., Blei, D.~M., Wang, C., and Paisley, J. (2013).
\newblock Stochastic variational inference.
\newblock {\em Journal of Machine Learning Research}, 14:1303--1347.

\bibitem[Joe, 1996]{joe1996families}
Joe, H. (1996).
\newblock {\em Families of $m$-variate distributions with given margins and
  $m(m-1)/2$ bivariate dependence parameters}, pages 120--141.
\newblock Institute of Mathematical Statistics.

\bibitem[Kappen and Wiegerinck, 2001]{kappen2001second}
Kappen, H.~J. and Wiegerinck, W. (2001).
\newblock {Second order approximations for probability models}.
\newblock In {\em Neural Information Processing Systems}.

\bibitem[Kingma and Ba, 2015]{kingma2015adam}
Kingma, D.~P. and Ba, J.~L. (2015).
\newblock {Adam: a Method for Stochastic Optimization}.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Kurowicka and Cooke, 2006]{kurowicka2006uncertainty}
Kurowicka, D. and Cooke, R.~M. (2006).
\newblock {\em Uncertainty Analysis with High Dimensional Dependence
  Modelling}.
\newblock Wiley, New York.

\bibitem[Nelsen, 2006]{nelsen2006introduction}
Nelsen, R.~B. (2006).
\newblock {\em An Introduction to Copulas (Springer Series in Statistics)}.
\newblock Springer-Verlag New York, Inc.

\bibitem[Ranganath et~al., 2014]{ranganath2014black}
Ranganath, R., Gerrish, S., and Blei, D.~M. (2014).
\newblock Black box variational inference.
\newblock In {\em Artificial Intelligence and Statistics}, pages 814--822.

\bibitem[Recht et~al., 2011]{recht2011hogwild}
Recht, B., Re, C., Wright, S., and Niu, F. (2011).
\newblock Hogwild: A lock-free approach to parallelizing stochastic gradient
  descent.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  693--701.

\bibitem[Rezende et~al., 2014]{rezende2014stochastic}
Rezende, D.~J., Mohamed, S., and Wierstra, D. (2014).
\newblock {Stochastic Backpropagation and Approximate Inference in Deep
  Generative Models}.
\newblock In {\em International Conference on Machine Learning}.

\bibitem[Robbins and Monro, 1951]{robbins1951stochastic}
Robbins, H. and Monro, S. (1951).
\newblock A stochastic approximation method.
\newblock {\em The Annals of Mathematical Statistics}, 22(3):400--407.

\bibitem[Saul and Jordan, 1995]{saul1995exploiting}
Saul, L. and Jordan, M.~I. (1995).
\newblock Exploiting tractable substructures in intractable networks.
\newblock In {\em Neural Information Processing Systems}, pages 486--492.

\bibitem[Seeger, 2010]{seeger2010gaussian}
Seeger, M. (2010).
\newblock Gaussian covariance and scalable variational inference.
\newblock In {\em International Conference on Machine Learning}.

\bibitem[Sklar, 1959]{sklar1959fonstions}
Sklar, A. (1959).
\newblock Fonstions de r\'epartition \`a $n$ dimensions et leurs marges.
\newblock {\em Publications de l'Institut de Statistique de l'Universit\'e de
  {P}aris}, 8:229--231.

\bibitem[{Stan Development Team}, 2015]{stan-software:2015}
{Stan Development Team} (2015).
\newblock Stan: A c++ library for probability and sampling, version 2.8.0.

\bibitem[Toulis and Airoldi, 2014]{toulis2014implicit}
Toulis, P. and Airoldi, E.~M. (2014).
\newblock {Implicit stochastic gradient descent}.
\newblock {\em arXiv preprint arXiv:1408.2923}.

\bibitem[Tran et~al., 2015]{tran2015stochastic}
Tran, D., Toulis, P., and Airoldi, E.~M. (2015).
\newblock {Stochastic gradient descent methods for estimation with large data
  sets}.
\newblock {\em arXiv preprint arXiv:1509.06459}.

\bibitem[Wainwright and Jordan, 2008]{wainwright2008graphical}
Wainwright, M.~J. and Jordan, M.~I. (2008).
\newblock {Graphical Models, Exponential Families, and Variational Inference}.
\newblock {\em Foundations and Trends in Machine Learning}, 1(1-2):1--305.

\end{thebibliography}
