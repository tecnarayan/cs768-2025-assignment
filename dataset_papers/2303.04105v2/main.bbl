\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{Achille_2019_ICCV}
Alessandro Achille, Michael Lam, Rahul Tewari, Avinash Ravichandran, Subhransu
  Maji, Charless~C. Fowlkes, Stefano Soatto, and Pietro Perona.
\newblock Task2vec: Task embedding for meta-learning.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, October 2019.

\bibitem{alain2016understanding}
Guillaume Alain and Yoshua Bengio.
\newblock Understanding intermediate layers using linear classifier probes.
\newblock In {\em 5th International Conference on Learning Representations,
  ICLR 2017, Toulon, France, April 24-26, 2017, Workshop Track Proceedings}.
  OpenReview.net, 2017.

\bibitem{alayrac2022flamingo}
Jean{-}Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr,
  Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds,
  Roman Ring, Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong, Sina
  Samangooei, Marianne Monteiro, Jacob~L. Menick, Sebastian Borgeaud, Andy
  Brock, Aida Nematzadeh, Sahand Sharifzadeh, Mikolaj Binkowski, Ricardo
  Barreira, Oriol Vinyals, Andrew Zisserman, and Kar{\'{e}}n Simonyan.
\newblock Flamingo: a visual language model for few-shot learning.
\newblock In {\em NeurIPS}, 2022.

\bibitem{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock {\em arXiv preprint arXiv:1607.06450}, 2016.

\bibitem{barz2019enhancing}
Björn Barz, Kai Schröter, Moritz Münch, Bin Yang, Andrea Unger, Doris
  Dransch, and Joachim Denzler.
\newblock Enhancing flood impact analysis using interactive retrieval of social
  media images.
\newblock {\em Archives of Data Science, Series A (Online First)}, 5(1):A06, 21
  S. online, 2018.

\bibitem{zaken2021bitfit}
Elad Ben~Zaken, Yoav Goldberg, and Shauli Ravfogel.
\newblock {B}it{F}it: Simple parameter-efficient fine-tuning for
  transformer-based masked language-models.
\newblock In {\em Proceedings of the 60th Annual Meeting of the Association for
  Computational Linguistics (Volume 2: Short Papers)}, pages 1--9, Dublin,
  Ireland, May 2022. Association for Computational Linguistics.

\bibitem{berriel2021ba2}
Rodrigo~Ferreira Berriel, St{\'{e}}phane Lathuili{\`{e}}re, Moin Nabi, Tassilo
  Klein, Thiago Oliveira{-}Santos, Nicu Sebe, and Elisa Ricci.
\newblock Budget-aware adapters for multi-domain learning.
\newblock In {\em 2019 {IEEE/CVF} International Conference on Computer Vision,
  {ICCV} 2019, Seoul, Korea (South), October 27 - November 2, 2019}, pages
  382--391. {IEEE}, 2019.

\bibitem{pmlr-v162-borgeaud22a}
Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza
  Rutherford, Katie Millican, George~Bm Van Den~Driessche, Jean-Baptiste
  Lespiau, Bogdan Damoc, Aidan Clark, Diego De~Las~Casas, Aurelia Guy, Jacob
  Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones,
  Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals,
  Simon Osindero, Karen Simonyan, Jack Rae, Erich Elsen, and Laurent Sifre.
\newblock Improving language models by retrieving from trillions of tokens.
\newblock In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari,
  Gang Niu, and Sivan Sabato, editors, {\em Proceedings of the 39th
  International Conference on Machine Learning}, volume 162 of {\em Proceedings
  of Machine Learning Research}, pages 2206--2240. PMLR, 17--23 Jul 2022.

\bibitem{carion2020end}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em European conference on computer vision}, pages 213--229.
  Springer, 2020.

\bibitem{chaudhry2018efficient}
Arslan Chaudhry, Marc’Aurelio Ranzato, Marcus Rohrbach, and Mohamed
  Elhoseiny.
\newblock Efficient lifelong learning with a-{GEM}.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In {\em International conference on machine learning}, pages
  1597--1607. PMLR, 2020.

\bibitem{cherti2023reproducible}
Mehdi Cherti, Romain Beaumont, Ross Wightman, Mitchell Wortsman, Gabriel
  Ilharco, Cade Gordon, Christoph Schuhmann, Ludwig Schmidt, and Jenia Jitsev.
\newblock Reproducible scaling laws for contrastive language-image learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 2818--2829, 2023.

\bibitem{chorowski2015attention}
Jan~K Chorowski, Dzmitry Bahdanau, Dmitriy Serdyuk, Kyunghyun Cho, and Yoshua
  Bengio.
\newblock Attention-based models for speech recognition.
\newblock {\em Advances in neural information processing systems}, 28, 2015.

\bibitem{cimpoi14describing}
M. Cimpoi, S. Maji, I. Kokkinos, S. Mohamed, , and A. Vedaldi.
\newblock Describing textures in the wild.
\newblock In {\em Proceedings of the {IEEE} Conf. on Computer Vision and
  Pattern Recognition ({CVPR})}, 2014.

\bibitem{cookjohn}
John~D Cook.
\newblock Upper and lower bounds for the normal distribution function.
\newblock {\em John D Cook's Blog}, 2018.

\bibitem{deshpande2021linearized}
Aditya Deshpande, Alessandro Achille, Avinash Ravichandran, Hao Li, Luca
  Zancato, Charless Fowlkes, Rahul Bhotika, Stefano Soatto, and Pietro Perona.
\newblock A linearized framework and a new benchmark for model selection for
  fine-tuning.
\newblock {\em arXiv preprint arXiv:2102.00084}, 2021.

\bibitem{devaguptapu2023deltapatching}
Chaitanya Devaguptapu, Samarth Sinha, K~J Joseph, Vineeth~N Balasubramanian,
  and Animesh Garg.
\newblock $\delta$-patching: A framework for rapid adaptation of pre-trained
  convolutional networks without base performance loss, 2023.

\bibitem{devlin2018bert}
Jacob Devlin, Ming{-}Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT:} pre-training of deep bidirectional transformers for language
  understanding.
\newblock In Jill Burstein, Christy Doran, and Thamar Solorio, editors, {\em
  Proceedings of the 2019 Conference of the North American Chapter of the
  Association for Computational Linguistics: Human Language Technologies,
  {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and
  Short Papers)}, pages 4171--4186. Association for Computational Linguistics,
  2019.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{finn2017model}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In {\em International conference on machine learning}, pages
  1126--1135. PMLR, 2017.

\bibitem{ghiasi2019fpn}
Golnaz Ghiasi, Tsung-Yi Lin, and Quoc~V Le.
\newblock Nas-fpn: Learning scalable feature pyramid architecture for object
  detection.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 7036--7045, 2019.

\bibitem{gontijo2021no}
Raphael Gontijo-Lopes, Yann Dauphin, and Ekin~Dogus Cubuk.
\newblock No one representation to rule them all: Overlapping features of
  training methods.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{guo2019spottune}
Yunhui Guo, Honghui Shi, Abhishek Kumar, Kristen Grauman, Tajana Rosing, and
  Rogerio Feris.
\newblock Spottune: transfer learning through adaptive fine-tuning.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 4805--4814, 2019.

\bibitem{hariharan2015hypercolumns}
Bharath Hariharan, Pablo Arbel{\'a}ez, Ross Girshick, and Jitendra Malik.
\newblock Hypercolumns for object segmentation and fine-grained localization.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 447--456, 2015.

\bibitem{he2021towards}
Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham
  Neubig.
\newblock Towards a unified view of parameter-efficient transfer learning.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{he2016resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em 2016 {IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2016, Las Vegas, NV, USA, June 27-30, 2016}, pages
  770--778. {IEEE} Computer Society, 2016.

\bibitem{helber2019eurosat}
Patrick Helber, Benjamin Bischke, Andreas Dengel, and Damian Borth.
\newblock Eurosat: A novel dataset and deep learning benchmark for land use and
  land cover classification.
\newblock {\em IEEE Journal of Selected Topics in Applied Earth Observations
  and Remote Sensing}, 2019.

\bibitem{houlsby2019parameter}
Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin
  De~Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly.
\newblock Parameter-efficient transfer learning for nlp.
\newblock In {\em International Conference on Machine Learning}, pages
  2790--2799. PMLR, 2019.

\bibitem{hu2021lora}
Edward~J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
  Wang, Lu Wang, and Weizhu Chen.
\newblock Lo{RA}: Low-rank adaptation of large language models.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{iglovikov2018ternausnet}
Vladimir Iglovikov and Alexey Shvets.
\newblock Ternausnet: U-net with vgg11 encoder pre-trained on imagenet for
  image segmentation.
\newblock {\em arXiv preprint arXiv:1801.05746}, 2018.

\bibitem{ilharco2022patching}
Gabriel Ilharco, Mitchell Wortsman, Samir~Yitzhak Gadre, Shuran Song, Hannaneh
  Hajishirzi, Simon Kornblith, Ali Farhadi, and Ludwig Schmidt.
\newblock Patching open-vocabulary models by interpolating weights, 2022.

\bibitem{jaegle2021perceiver}
Andrew Jaegle, Felix Gimeno, Andy Brock, Oriol Vinyals, Andrew Zisserman, and
  Joao Carreira.
\newblock Perceiver: General perception with iterative attention.
\newblock In {\em International conference on machine learning}, pages
  4651--4664. PMLR, 2021.

\bibitem{jia2021scaling}
Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le,
  Yun-Hsuan Sung, Zhen Li, and Tom Duerig.
\newblock Scaling up visual and vision-language representation learning with
  noisy text supervision.
\newblock In {\em International Conference on Machine Learning}, pages
  4904--4916. PMLR, 2021.

\bibitem{jia2022visual}
Menglin Jia, Luming Tang, Bor-Chun Chen, Claire Cardie, Serge Belongie, Bharath
  Hariharan, and Ser-Nam Lim.
\newblock Visual prompt tuning.
\newblock In {\em European Conference on Computer Vision (ECCV)}, 2022.

\bibitem{KhoslaYaoJayadevaprakashFeiFei_FGVC2011}
Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao, and Li Fei-Fei.
\newblock Novel dataset for fine-grained image categorization.
\newblock In {\em First Workshop on Fine-Grained Visual Categorization, IEEE
  Conference on Computer Vision and Pattern Recognition}, Colorado Springs, CO,
  June 2011.

\bibitem{kirkpatrick2017overcoming}
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume
  Desjardins, Andrei~A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka
  Grabska-Barwinska, et~al.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock {\em Proceedings of the national academy of sciences},
  114(13):3521--3526, 2017.

\bibitem{kolesnikov2020big}
Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung,
  Sylvain Gelly, and Neil Houlsby.
\newblock Big transfer (bit): General visual representation learning.
\newblock In {\em European conference on computer vision}, pages 491--507.
  Springer, 2020.

\bibitem{kornblith2019better}
Simon Kornblith, Jonathon Shlens, and Quoc~V Le.
\newblock Do better imagenet models transfer better?
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 2661--2671, 2019.

\bibitem{NEURIPS2020_bc573864}
Zhi Kou, Kaichao You, Mingsheng Long, and Jianmin Wang.
\newblock Stochastic normalization.
\newblock In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin,
  editors, {\em Advances in Neural Information Processing Systems}, volume~33,
  pages 16304--16314. Curran Associates, Inc., 2020.

\bibitem{KrauseStarkDengFei-Fei_3DRR2013}
Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei.
\newblock 3d object representations for fine-grained categorization.
\newblock In {\em 4th International IEEE Workshop on 3D Representation and
  Recognition (3dRR-13)}, Sydney, Australia, 2013.

\bibitem{lee2019set}
Juho Lee, Yoonho Lee, Jungtaek Kim, Adam Kosiorek, Seungjin Choi, and Yee~Whye
  Teh.
\newblock Set transformer: A framework for attention-based
  permutation-invariant neural networks.
\newblock In {\em International conference on machine learning}, pages
  3744--3753. PMLR, 2019.

\bibitem{lee2019meta}
Kwonjoon Lee, Subhransu Maji, Avinash Ravichandran, and Stefano Soatto.
\newblock Meta-learning with differentiable convex optimization.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 10657--10665, 2019.

\bibitem{lester2021power}
Brian Lester, Rami Al-Rfou, and Noah Constant.
\newblock The power of scale for parameter-efficient prompt tuning.
\newblock In {\em Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pages 3045--3059, Online and Punta Cana,
  Dominican Republic, Nov. 2021. Association for Computational Linguistics.

\bibitem{li2021align}
Junnan Li, Ramprasaath Selvaraju, Akhilesh Gotmare, Shafiq Joty, Caiming Xiong,
  and Steven Chu~Hong Hoi.
\newblock Align before fuse: Vision and language representation learning with
  momentum distillation.
\newblock {\em Advances in neural information processing systems},
  34:9694--9705, 2021.

\bibitem{li2016revisiting}
Yanghao Li, Naiyan Wang, Jianping Shi, Jiaying Liu, and Xiaodi Hou.
\newblock Revisiting batch normalization for practical domain adaptation.
\newblock In {\em 5th International Conference on Learning Representations,
  {ICLR} 2017, Toulon, France, April 24-26, 2017, Workshop Track Proceedings}.
  OpenReview.net, 2017.

\bibitem{li2017learning}
Zhizhong Li and Derek Hoiem.
\newblock Learning without forgetting.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  40(12):2935--2947, 2017.

\bibitem{lin2017feature}
Tsung-Yi Lin, Piotr Doll{\'a}r, Ross Girshick, Kaiming He, Bharath Hariharan,
  and Serge Belongie.
\newblock Feature pyramid networks for object detection.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2117--2125, 2017.

\bibitem{liu2021swin}
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 10012--10022, 2021.

\bibitem{liu2022convnext}
Zhuang Liu, Hanzi Mao, Chao{-}Yuan Wu, Christoph Feichtenhofer, Trevor Darrell,
  and Saining Xie.
\newblock A convnet for the 2020s.
\newblock In {\em {IEEE/CVF} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2022, New Orleans, LA, USA, June 18-24, 2022}, pages
  11966--11976, 2022.

\bibitem{loshchilov2017decoupled}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock {\em arXiv preprint arXiv:1711.05101}, 2017.

\bibitem{loshchilov2016sgdr}
Ilya Loshchilov and Frank Hutter.
\newblock {SGDR}: Stochastic gradient descent with warm restarts.
\newblock In {\em International Conference on Learning Representations}, 2017.

\bibitem{loshchcilov2019adamw}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{mahajan2018exploring}
Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan, Kaiming He, Manohar Paluri,
  Yixuan Li, Ashwin Bharambe, and Laurens Van Der~Maaten.
\newblock Exploring the limits of weakly supervised pretraining.
\newblock In {\em Proceedings of the European conference on computer vision
  (ECCV)}, pages 181--196, 2018.

\bibitem{maji2013fine}
Subhransu Maji, Esa Rahtu, Juho Kannala, Matthew Blaschko, and Andrea Vedaldi.
\newblock Fine-grained visual classification of aircraft.
\newblock {\em arXiv preprint arXiv:1306.5151}, 2013.

\bibitem{mallya2018piggyback}
Arun Mallya, Dillon Davis, and Svetlana Lazebnik.
\newblock Piggyback: Adapting a single network to multiple tasks by learning to
  mask weights.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 67--82, 2018.

\bibitem{Nilsback08}
Maria-Elena Nilsback and Andrew Zisserman.
\newblock Automated flower classification over a large number of classes.
\newblock In {\em Indian Conference on Computer Vision, Graphics and Image
  Processing}, Dec 2008.

\bibitem{herbarium}
New York Botanical~Garden (NYBG).
\newblock Fgvc 7 - herbarium 2020, 2020.

\bibitem{Pandy_2022_CVPR}
Michal P\'andy, Andrea Agostinelli, Jasper Uijlings, Vittorio Ferrari, and
  Thomas Mensink.
\newblock Transferability estimation using bhattacharyya class separability.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 9172--9182, June 2022.

\bibitem{parkhi12a}
Omkar~M. Parkhi, Andrea Vedaldi, Andrew Zisserman, and C.~V. Jawahar.
\newblock Cats and dogs.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  2012.

\bibitem{quattoni2009recognizing}
Ariadna Quattoni and Antonio Torralba.
\newblock Recognizing indoor scenes.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 413--420. IEEE, 2009.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em International Conference on Machine Learning}, pages
  8748--8763. PMLR, 2021.

\bibitem{radford2018improving}
Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et~al.
\newblock Improving language understanding by generative pre-training.
\newblock {\em arXiv}, 2018.

\bibitem{rajbhandari2020zero}
Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He.
\newblock Zero: Memory optimizations toward training trillion parameter models.
\newblock In {\em SC20: International Conference for High Performance
  Computing, Networking, Storage and Analysis}, pages 1--16. IEEE, 2020.

\bibitem{DBLP:journals/corr/SalehE15}
Babak Saleh and Ahmed Elgammal.
\newblock Large-scale classification of fine-art paintings: Learning the right
  metric on the right feature.
\newblock {\em International Journal for Digital Art History}, Oct. 2016.

\bibitem{sandler2022fine}
Mark Sandler, Andrey Zhmoginov, Max Vladymyrov, and Andrew Jackson.
\newblock Fine-tuning image transformers using learnable memory.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12155--12164, 2022.

\bibitem{shen2021partial}
Zhiqiang Shen, Zechun Liu, Jie Qin, Marios Savvides, and Kwang-Ting Cheng.
\newblock Partial is better than all: Revisiting fine-tuning strategy for
  few-shot learning.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pages 9594--9602, 2021.

\bibitem{touvron2022deit}
Hugo Touvron, Matthieu Cord, and Herv\'{e} J\'{e}gou.
\newblock Deit iii: Revenge of the vit.
\newblock In {\em Computer Vision – ECCV 2022: 17th European Conference, Tel
  Aviv, Israel, October 23–27, 2022, Proceedings, Part XXIV}, page 516–533,
  Berlin, Heidelberg, 2022. Springer-Verlag.

\bibitem{vasconcelos2022proper}
Cristina Vasconcelos, Vighnesh Birodkar, and Vincent Dumoulin.
\newblock Proper reuse of image classification features improves object
  detection.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 13628--13637, 2022.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{WahCUB_200_2011}
C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie.
\newblock Caltech-ucsd birds-200-2011.
\newblock Technical Report CNS-TR-2011-001, California Institute of Technology,
  2011.

\bibitem{wallingford2022task}
Matthew Wallingford, Hao Li, Alessandro Achille, Avinash Ravichandran, Charless
  Fowlkes, Rahul Bhotika, and Stefano Soatto.
\newblock Task adaptive parameter sharing for multi-task learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 7561--7570, 2022.

\bibitem{wang2019learning}
Haohan Wang, Songwei Ge, Zachary Lipton, and Eric~P Xing.
\newblock Learning robust global representations by penalizing local predictive
  power.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  10506--10518, 2019.

\bibitem{wang2022learning}
Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren,
  Guolong Su, Vincent Perot, Jennifer Dy, and Tomas Pfister.
\newblock Learning to prompt for continual learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 139--149, 2022.

\bibitem{xie2017aggregated}
Saining Xie, Ross Girshick, Piotr Doll{\'a}r, Zhuowen Tu, and Kaiming He.
\newblock Aggregated residual transformations for deep neural networks.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1492--1500, 2017.

\bibitem{yang2022rep}
Li Yang, Adnan~Siraj Rakin, and Deliang Fan.
\newblock Rep-net: Efficient on-device learning via feature reprogramming.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12277--12286, 2022.

\bibitem{you2020co}
Kaichao You, Zhi Kou, Mingsheng Long, and Jianmin Wang.
\newblock Co-tuning for transfer learning.
\newblock {\em Advances in Neural Information Processing Systems},
  33:17236--17246, 2020.

\bibitem{yu2022coca}
Jiahui Yu, Zirui Wang, Vijay Vasudevan, Legg Yeung, Mojtaba Seyedhosseini, and
  Yonghui Wu.
\newblock Coca: Contrastive captioners are image-text foundation models.
\newblock {\em Transactions on Machine Learning Research}, 2022.

\bibitem{zeiler2014visualizing}
Matthew~D Zeiler and Rob Fergus.
\newblock Visualizing and understanding convolutional networks.
\newblock In {\em European conference on computer vision}, pages 818--833.
  Springer, 2014.

\bibitem{zhang2020side}
Jeffrey~O Zhang, Alexander Sax, Amir Zamir, Leonidas Guibas, and Jitendra
  Malik.
\newblock Side-tuning: a baseline for network adaptation via additive side
  networks.
\newblock In {\em Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part III 16}, pages 698--714.
  Springer, 2020.

\bibitem{zhu2020deformable}
Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai.
\newblock Deformable {\{}detr{\}}: Deformable transformers for end-to-end
  object detection.
\newblock In {\em International Conference on Learning Representations}, 2021.

\end{thebibliography}
