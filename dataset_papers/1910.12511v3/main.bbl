\begin{thebibliography}{67}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2018)Agarwal, Gonen, and Hazan]{agarwal2018learning}
N.~Agarwal, A.~Gonen, and E.~Hazan.
\newblock Learning in non-convex games with an optimization oracle.
\newblock \emph{arXiv:1810.07362}, 2018.

\bibitem[Ahmadi-Javid(2012)]{ahmadi2012entropic}
A.~Ahmadi-Javid.
\newblock Entropic value-at-risk: A new coherent risk measure.
\newblock \emph{Journal of Optimization Theory and Applications}, 155\penalty0
  (3):\penalty0 1105--1123, 2012.

\bibitem[Alatur et~al.(2020)Alatur, Levy, and Krause]{alatur2020multi}
P.~Alatur, K.~Y. Levy, and A.~Krause.
\newblock Multi-player bandits: The adversarial case.
\newblock \emph{Journal of Machine Learning Research}, 21\penalty0
  (77):\penalty0 1--23, 2020.

\bibitem[Anari et~al.(2016)Anari, Gharan, and Rezaei]{anari2016monte}
N.~Anari, S.~O. Gharan, and A.~Rezaei.
\newblock Monte carlo markov chain algorithms for sampling strongly rayleigh
  distributions and determinantal point processes.
\newblock In \emph{Conference on Learning Theory}, pages 103--115, 2016.

\bibitem[Artzner et~al.(1999)]{artzner1999coherent}
P.~Artzner et~al.
\newblock Coherent measures of risk.
\newblock \emph{Mathematical finance}, pages 203--228, 1999.

\bibitem[Audibert et~al.(2013)Audibert, Bubeck, and Lugosi]{audibert2013regret}
J.-Y. Audibert, S.~Bubeck, and G.~Lugosi.
\newblock Regret in online combinatorial optimization.
\newblock \emph{Mathematics of Operations Research}, 39\penalty0 (1):\penalty0
  31--45, 2013.

\bibitem[Auer et~al.(2002)Auer, Cesa-Bianchi, Freund, and
  Schapire]{auer2002nonstochastic}
P.~Auer, N.~Cesa-Bianchi, Y.~Freund, and R.~E. Schapire.
\newblock The nonstochastic multiarmed bandit problem.
\newblock \emph{SIAM journal on computing}, 32\penalty0 (1):\penalty0 48--77,
  2002.

\bibitem[Barthelm{\'e} et~al.(2019)Barthelm{\'e}, Amblard, Tremblay,
  et~al.]{barthelme2019asymptotic}
S.~Barthelm{\'e}, P.-O. Amblard, N.~Tremblay, et~al.
\newblock Asymptotic equivalence of fixed-size and varying-size determinantal
  point processes.
\newblock \emph{Bernoulli}, pages 3555--3589, 2019.

\bibitem[Beck and Teboulle(2003)]{beck2003mirror}
A.~Beck and M.~Teboulle.
\newblock Mirror descent and nonlinear projected subgradient methods for convex
  optimization.
\newblock \emph{Operations Research Letters}, 31\penalty0 (3):\penalty0
  167--175, 2003.

\bibitem[Borsos et~al.(2019)Borsos, Curi, Levy, and Krause]{borsos2019online}
Z.~Borsos, S.~Curi, K.~Y. Levy, and A.~Krause.
\newblock Online variance reduction with mixtures.
\newblock In \emph{International Conference on Machine Learning}, pages
  705--714, 2019.

\bibitem[Brown(2007)]{brown2007large}
D.~B. Brown.
\newblock Large deviations bounds for estimating conditional value-at-risk.
\newblock \emph{Operations Research Letters}, 35\penalty0 (6):\penalty0
  722--730, 2007.

\bibitem[Brownlees et~al.(2015)Brownlees, Joly, Lugosi,
  et~al.]{brownlees2015empirical}
C.~Brownlees, E.~Joly, G.~Lugosi, et~al.
\newblock Empirical risk minimization for heavy-tailed losses.
\newblock \emph{The Annals of Statistics}, 43\penalty0 (6):\penalty0
  2507--2536, 2015.

\bibitem[Bubeck et~al.(2012)Bubeck, Cesa-Bianchi, and
  Kakade]{bubeck2012towards}
S.~Bubeck, N.~Cesa-Bianchi, and S.~M. Kakade.
\newblock Towards minimax policies for online linear optimization with bandit
  feedback.
\newblock In \emph{Conference on Learning Theory}, pages 41--1, 2012.

\bibitem[Carneiro et~al.(2010)]{carneiro2010risk}
M.~C. Carneiro et~al.
\newblock Risk management in the oil supply chain: a cvar approach.
\newblock \emph{Industrial \& Engineering Chemistry Research}, pages
  3286--3294, 2010.

\bibitem[Cesa-Bianchi and Lugosi(2012)]{cesa2012combinatorial}
N.~Cesa-Bianchi and G.~Lugosi.
\newblock Combinatorial bandits.
\newblock \emph{Journal of Computer and System Sciences}, 78\penalty0
  (5):\penalty0 1404--1422, 2012.

\bibitem[Chow et~al.(2017)Chow, Ghavamzadeh, Janson, and Pavone]{chow2017risk}
Y.~Chow, M.~Ghavamzadeh, L.~Janson, and M.~Pavone.
\newblock Risk-constrained reinforcement learning with percentile risk
  criteria.
\newblock \emph{The Journal of Machine Learning Research}, 18\penalty0
  (1):\penalty0 6070--6120, 2017.

\bibitem[Clauset et~al.(2009)Clauset, Shalizi, and Newman]{clauset2009power}
A.~Clauset, C.~R. Shalizi, and M.~E. Newman.
\newblock Power-law distributions in empirical data.
\newblock \emph{SIAM review}, 51\penalty0 (4):\penalty0 661--703, 2009.

\bibitem[Derezi{\'n}ski et~al.(2019)Derezi{\'n}ski, Calandriello, and
  Valko]{derezinski2019exact}
M.~Derezi{\'n}ski, D.~Calandriello, and M.~Valko.
\newblock Exact sampling of determinantal point processes with sublinear time
  preprocessing.
\newblock \emph{arXiv:1905.13476}, 2019.

\bibitem[Devroye et~al.(2013)Devroye, Gy{\"o}rfi, and
  Lugosi]{devroye2013probabilistic}
L.~Devroye, L.~Gy{\"o}rfi, and G.~Lugosi.
\newblock \emph{A probabilistic theory of pattern recognition}, volume~31.
\newblock Springer Science \& Business Media, 2013.

\bibitem[Dua and Graff(2017)]{Dua:2019}
D.~Dua and C.~Graff.
\newblock {UCI} machine learning repository, 2017.
\newblock URL \url{http://archive.ics.uci.edu/ml}.

\bibitem[Duchi et~al.(2016)Duchi, Glynn, and Namkoong]{duchi2016statistics}
J.~Duchi, P.~Glynn, and H.~Namkoong.
\newblock Statistics of robust optimization: A generalized empirical likelihood
  approach.
\newblock \emph{arXiv:1610.03425}, 2016.

\bibitem[Eaton and Haas(1995)]{eaton1995titanic}
J.~P. Eaton and C.~A. Haas.
\newblock \emph{Titanic, triumph and tragedy}.
\newblock WW Norton \& Company, 1995.

\bibitem[Esfahani and Kuhn(2018)]{esfahani2018data}
P.~M. Esfahani and D.~Kuhn.
\newblock Data-driven distributionally robust optimization using the
  wasserstein metric: Performance guarantees and tractable reformulations.
\newblock \emph{Mathematical Programming}, 171\penalty0 (1-2):\penalty0
  115--166, 2018.

\bibitem[Fan et~al.(2017)Fan, Lyu, Ying, and Hu]{fan2017learning}
Y.~Fan, S.~Lyu, Y.~Ying, and B.~Hu.
\newblock Learning with average top-k loss.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  497--505, 2017.

\bibitem[Freund and Schapire(1999)]{freund1999adaptive}
Y.~Freund and R.~E. Schapire.
\newblock Adaptive game playing using multiplicative weights.
\newblock \emph{Games and Economic Behavior}, 29\penalty0 (1-2):\penalty0
  79--103, 1999.

\bibitem[Gotoh and Takeda(2016)]{gotoh2016cvar}
J.-y. Gotoh and A.~Takeda.
\newblock Cvar minimizations in support vector machines.
\newblock \emph{Financial Signal Processing and Machine Learning}, pages
  233--265, 2016.

\bibitem[Hazan(2016)]{hazan2016introduction}
E.~Hazan.
\newblock Introduction to online convex optimization.
\newblock \emph{Foundations and Trends in Optimization}, pages 157--325, 2016.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Hinton et~al.(2012)Hinton, Srivastava, Krizhevsky, Sutskever, and
  Salakhutdinov]{hinton2012improving}
G.~E. Hinton, N.~Srivastava, A.~Krizhevsky, I.~Sutskever, and R.~R.
  Salakhutdinov.
\newblock Improving neural networks by preventing co-adaptation of feature
  detectors.
\newblock \emph{arXiv:1207.0580}, 2012.

\bibitem[Ioffe and Szegedy(2015)]{ioffe2015batch}
S.~Ioffe and C.~Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{arXiv:1502.03167}, 2015.

\bibitem[Kahneman and Tversky(2013)]{kahneman2013prospect}
D.~Kahneman and A.~Tversky.
\newblock Prospect theory: An analysis of decision under risk.
\newblock In \emph{Handbook of the fundamentals of financial decision making:
  Part I}, pages 99--127. World Scientific, 2013.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv:1412.6980}, 2014.

\bibitem[Kirschner et~al.(2020)Kirschner, Bogunovic, Jegelka, and
  Krause]{kirschner20}
J.~Kirschner, I.~Bogunovic, S.~Jegelka, and A.~Krause.
\newblock Distributionally robust bayesian optimization.
\newblock In \emph{The 23rd International Conference on Artificial Intelligence
  and Statistics}, 2020.

\bibitem[Koolen et~al.(2010)Koolen, Warmuth, and Kivinen]{koolen2010hedging}
W.~M. Koolen, M.~K. Warmuth, and J.~Kivinen.
\newblock Hedging structured concepts.
\newblock In \emph{COLT}, pages 93--105, 2010.

\bibitem[Krizhevsky et~al.(2014)Krizhevsky, Nair, and
  Hinton]{krizhevsky2014cifar}
A.~Krizhevsky, V.~Nair, and G.~Hinton.
\newblock The cifar-10 dataset.
\newblock \emph{online: http://www. cs. toronto. edu/kriz/cifar. html}, 2014.

\bibitem[Krokhmal et~al.(2002)Krokhmal, Palmquist, and
  Uryasev]{krokhmal2002portfolio}
P.~Krokhmal, J.~Palmquist, and S.~Uryasev.
\newblock Portfolio optimization with conditional value-at-risk objective and
  constraints.
\newblock \emph{Journal of risk}, 4:\penalty0 43--68, 2002.

\bibitem[Kulesza et~al.(2012)Kulesza, Taskar, et~al.]{kulesza2012determinantal}
A.~Kulesza, B.~Taskar, et~al.
\newblock Determinantal point processes for machine learning.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  5\penalty0 (2--3):\penalty0 123--286, 2012.

\bibitem[Lattimore and Szepesv{\'a}ri(2018)]{lattimore2018bandit}
T.~Lattimore and C.~Szepesv{\'a}ri.
\newblock Bandit algorithms.
\newblock \emph{preprint}, 2018.

\bibitem[LeCun et~al.(1995)LeCun, Bengio, et~al.]{lecun1995convolutional}
Y.~LeCun, Y.~Bengio, et~al.
\newblock Convolutional networks for images, speech, and time series.
\newblock \emph{The handbook of brain theory and neural networks},
  3361\penalty0 (10):\penalty0 1995, 1995.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, Haffner,
  et~al.]{lecun1998gradient}
Y.~LeCun, L.~Bottou, Y.~Bengio, P.~Haffner, et~al.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Lee et~al.(2020)Lee, Park, and Shin]{lee2020learning}
J.~Lee, S.~Park, and J.~Shin.
\newblock Learning bounds for risk-sensitive learning.
\newblock \emph{arXiv preprint arXiv:2006.08138}, 2020.

\bibitem[Mehrabi et~al.(2019)Mehrabi, Morstatter, Saxena, Lerman, and
  Galstyan]{mehrabi2019survey}
N.~Mehrabi, F.~Morstatter, N.~Saxena, K.~Lerman, and A.~Galstyan.
\newblock A survey on bias and fairness in machine learning.
\newblock \emph{arXiv preprint arXiv:1908.09635}, 2019.

\bibitem[Mhammedi et~al.(2020)Mhammedi, Guedj, and Williamson]{mhammedi2020pac}
Z.~Mhammedi, B.~Guedj, and R.~C. Williamson.
\newblock Pac-bayesian bound for the conditional value at risk.
\newblock \emph{arXiv preprint arXiv:2006.14763}, 2020.

\bibitem[Murty(1983)]{murty1983linear}
K.~G. Murty.
\newblock \emph{Linear programming}.
\newblock Springer, 1983.

\bibitem[Murty and Kabadi(1987)]{murty1987some}
K.~G. Murty and S.~N. Kabadi.
\newblock Some np-complete problems in quadratic and nonlinear programming.
\newblock \emph{Mathematical programming}, 39\penalty0 (2):\penalty0 117--129,
  1987.

\bibitem[Namkoong and Duchi(2016)]{namkoong2016stochastic}
H.~Namkoong and J.~C. Duchi.
\newblock Stochastic gradient methods for distributionally robust optimization
  with f-divergences.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2208--2216, 2016.

\bibitem[Namkoong and Duchi(2017)]{namkoong2017variance}
H.~Namkoong and J.~C. Duchi.
\newblock Variance-based regularization with convex objectives.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2971--2980, 2017.

\bibitem[Nemirovski and Shapiro(2006)]{nemirovski2006convex}
A.~Nemirovski and A.~Shapiro.
\newblock Convex approximations of chance constrained programs.
\newblock \emph{SIAM Journal on Optimization}, 17\penalty0 (4):\penalty0
  969--996, 2006.

\bibitem[Ogryczak and Tamir(2003)]{ogryczak2003minimizing}
W.~Ogryczak and A.~Tamir.
\newblock Minimizing the sum of the k largest functions in linear time.
\newblock \emph{Information Processing Letters}, 85\penalty0 (3):\penalty0
  117--122, 2003.

\bibitem[Paszke et~al.(2017)]{paszke2017automatic}
A.~Paszke et~al.
\newblock Automatic differentiation in pytorch.
\newblock In \emph{NIPS Autodiff Workshop}, 2017.

\bibitem[Pratt(1978)]{pratt1978risk}
J.~W. Pratt.
\newblock Risk aversion in the small and in the large.
\newblock In \emph{Uncertainty in Economics}, pages 59--79. Elsevier, 1978.

\bibitem[Rabin(2013)]{rabin2013risk}
M.~Rabin.
\newblock Risk aversion and expected-utility theory.
\newblock In \emph{Handbook of the Fundamentals of Financial Decision Making},
  pages 241--252. World Scientific, 2013.

\bibitem[Rockafellar et~al.(2000)Rockafellar, Uryasev,
  et~al.]{rockafellar2000optimization}
R.~T. Rockafellar, S.~Uryasev, et~al.
\newblock Optimization of conditional value-at-risk.
\newblock \emph{Journal of risk}, 2:\penalty0 21--42, 2000.

\bibitem[Rubino and Tuffin(2009)]{rubino2009rare}
G.~Rubino and B.~Tuffin.
\newblock \emph{Rare event simulation using Monte Carlo methods}.
\newblock John Wiley \& Sons, 2009.

\bibitem[Sani et~al.(2012)Sani, Lazaric, and Munos]{sani2012risk}
A.~Sani, A.~Lazaric, and R.~Munos.
\newblock Risk-aversion in multi-armed bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3275--3283, 2012.

\bibitem[Sch{\"o}lkopf et~al.(2000)Sch{\"o}lkopf, Smola, Williamson, and
  Bartlett]{scholkopf2000new}
B.~Sch{\"o}lkopf, A.~J. Smola, R.~C. Williamson, and P.~L. Bartlett.
\newblock New support vector algorithms.
\newblock \emph{Neural computation}, 12\penalty0 (5):\penalty0 1207--1245,
  2000.

\bibitem[Shalev-Shwartz and Wexler(2016)]{shalev2016minimizing}
S.~Shalev-Shwartz and Y.~Wexler.
\newblock Minimizing the maximal loss: How and why.
\newblock In \emph{ICML}, pages 793--801, 2016.

\bibitem[Shapiro et~al.(2009)Shapiro, Dentcheva, and
  Ruszczy{\'n}ski]{shapiro2009lectures}
A.~Shapiro, D.~Dentcheva, and A.~Ruszczy{\'n}ski.
\newblock \emph{Lectures on stochastic programming: modeling and theory}.
\newblock SIAM, 2009.

\bibitem[Simonyan and Zisserman(2014)]{simonyan2014very}
K.~Simonyan and A.~Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv:1409.1556}, 2014.

\bibitem[Soma and Yoshida(2020)]{soma2020statistical}
T.~Soma and Y.~Yoshida.
\newblock Statistical learning with conditional value at risk.
\newblock \emph{arXiv preprint arXiv:2002.05826}, 2020.

\bibitem[Tarnopolskaya and Zhu(2010)]{tarnopolskaya2010cvar}
T.~Tarnopolskaya and Z.~Zhu.
\newblock Cvar-minimising hedging by a smoothing method.
\newblock \emph{ANZIAM}, 52:\penalty0 237--256, 2010.

\bibitem[Uchiya et~al.(2010)Uchiya, Nakamura, and Kudo]{uchiya2010algorithms}
T.~Uchiya, A.~Nakamura, and M.~Kudo.
\newblock Algorithms for adversarial bandit problems with multiple plays.
\newblock In \emph{International Conference on Algorithmic Learning Theory},
  pages 375--389. Springer, 2010.

\bibitem[Vapnik(1992)]{vapnik1992principles}
V.~Vapnik.
\newblock Principles of risk minimization for learning theory.
\newblock In \emph{Advances in neural information processing systems}, pages
  831--838, 1992.

\bibitem[Williamson and Menon(2019)]{williamson2019fairness}
R.~Williamson and A.~Menon.
\newblock Fairness risk measures.
\newblock In \emph{International Conference on Machine Learning}, pages
  6786--6797, 2019.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017fashion}
H.~Xiao, K.~Rasul, and R.~Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock \emph{arXiv:1708.07747}, 2017.

\bibitem[Zimmerman(1997)]{zimmerman1997teacher}
D.~W. Zimmerman.
\newblock Teacher’s corner: A note on interpretation of the paired-samples t
  test.
\newblock \emph{Journal of Educational and Behavioral Statistics}, 22\penalty0
  (3):\penalty0 349--360, 1997.

\bibitem[Zinkevich(2003)]{zinkevich2003online}
M.~Zinkevich.
\newblock Online convex programming and generalized infinitesimal gradient
  ascent.
\newblock In \emph{Proceedings of the 20th International Conference on Machine
  Learning (ICML-03)}, pages 928--936, 2003.

\end{thebibliography}
