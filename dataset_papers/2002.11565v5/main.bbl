\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbasi \& Gagn{\'e}(2017)Abbasi and Gagn{\'e}]{abbasi2017robustness}
Abbasi, M. and Gagn{\'e}, C.
\newblock Robustness to adversarial examples through an ensemble of
  specialists.
\newblock \emph{arXiv preprint arXiv:1702.06856}, 2017.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and
  Wagner]{athalye2018obfuscated}
Athalye, A., Carlini, N., and Wagner, D.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, volume~80 of \emph{Proceedings of Machine Learning Research}, pp.\
   274--283, Stockholmsmässan, Stockholm Sweden, 10--15 Jul 2018. PMLR.

\bibitem[Bhagoji et~al.(2019)Bhagoji, Cullina, and Mittal]{NIPS2019_8968}
Bhagoji, A.~N., Cullina, D., and Mittal, P.
\newblock Lower bounds on adversarial robustness from optimal transport.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pp.\
  7496--7508. Curran Associates, Inc., 2019.

\bibitem[Biggio et~al.(2013)Biggio, Corona, Maiorca, Nelson, {\v{S}}rndi{\'c},
  Laskov, Giacinto, and Roli]{biggio2013evasion}
Biggio, B., Corona, I., Maiorca, D., Nelson, B., {\v{S}}rndi{\'c}, N., Laskov,
  P., Giacinto, G., and Roli, F.
\newblock Evasion attacks against machine learning at test time.
\newblock In \emph{Joint European conference on machine learning and knowledge
  discovery in databases}, pp.\  387--402. Springer, 2013.

\bibitem[Brown(1951)]{brown1951iterative}
Brown, G.~W.
\newblock Iterative solution of games by fictitious play.
\newblock \emph{Activity analysis of production and allocation}, 13\penalty0
  (1):\penalty0 374--376, 1951.

\bibitem[Br\"{u}ckner \& Scheffer(2011)Br\"{u}ckner and
  Scheffer]{10.1145/2020408.2020495}
Br\"{u}ckner, M. and Scheffer, T.
\newblock Stackelberg games for adversarial prediction problems.
\newblock In \emph{Proceedings of the 17th ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, KDD ’11, pp.\  547–555, New
  York, NY, USA, 2011. Association for Computing Machinery.
\newblock ISBN 9781450308137.
\newblock \doi{10.1145/2020408.2020495}.

\bibitem[Bubeck et~al.(2019)Bubeck, Lee, Price, and
  Razenshteyn]{pmlr-v97-bubeck19a}
Bubeck, S., Lee, Y.~T., Price, E., and Razenshteyn, I.
\newblock Adversarial examples from computational constraints.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, volume~97 of \emph{Proceedings of Machine Learning Research}, pp.\
   831--840, Long Beach, California, USA, 09--15 Jun 2019. PMLR.

\bibitem[Carlini \& Wagner(2017)Carlini and Wagner]{carlini2017towards}
Carlini, N. and Wagner, D.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{2017 IEEE Symposium on Security and Privacy (SP)}, pp.\
  39--57. IEEE, 2017.

\bibitem[Carlini et~al.(2019)Carlini, Athalye, Papernot, Brendel, Rauber,
  Tsipras, Goodfellow, and Madry]{carlini2019evaluating}
Carlini, N., Athalye, A., Papernot, N., Brendel, W., Rauber, J., Tsipras, D.,
  Goodfellow, I., and Madry, A.
\newblock On evaluating adversarial robustness.
\newblock \emph{arXiv preprint arXiv:1902.06705}, 2019.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and
  Kolter]{KolterRandomizedSmoothing}
Cohen, J.~M., Rosenfeld, E., and Kolter, J.~Z.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock \emph{CoRR}, abs/1902.02918, 2019.

\bibitem[Dhillon et~al.(2018)Dhillon, Azizzadenesheli, Bernstein, Kossaifi,
  Khanna, Lipton, and Anandkumar]{pruningDefenseICLR2018}
Dhillon, G.~S., Azizzadenesheli, K., Bernstein, J.~D., Kossaifi, J., Khanna,
  A., Lipton, Z.~C., and Anandkumar, A.
\newblock Stochastic activation pruning for robust adversarial defense.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Fawzi et~al.(2016)Fawzi, Moosavi-Dezfooli, and
  Frossard]{NIPS2016_6331}
Fawzi, A., Moosavi-Dezfooli, S.-M., and Frossard, P.
\newblock Robustness of classifiers: from adversarial to random noise.
\newblock In \emph{Advances in Neural Information Processing Systems 29}, pp.\
  1632--1640. Curran Associates, Inc., 2016.

\bibitem[Fawzi et~al.(2018)Fawzi, Fawzi, and Fawzi]{NIPS2018Fawzi}
Fawzi, A., Fawzi, H., and Fawzi, O.
\newblock Adversarial vulnerability for any classifier.
\newblock In \emph{Advances in Neural Information Processing Systems 31}, pp.\
  1186--1195. Curran Associates, Inc., 2018.

\bibitem[Freund \& Schapire(1995)Freund and
  Schapire]{freund95decisiontheoretic}
Freund, Y. and Schapire, R.~E.
\newblock {A Decision Theoretic Generalization of On-Line Learning and an
  Application to Boosting}.
\newblock In Vit{\'a}nyi, P. M.~B. (ed.), \emph{Second European Conference on
  Computational Learning Theory (EuroCOLT-95)}, pp.\  23--37, 1995.
\newblock URL \url{citeseer.nj.nec.com/freund95decisiontheoretic.html}.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Goodfellow, I., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Gourdeau et~al.(2019)Gourdeau, Kanade, Kwiatkowska, and
  Worrell]{NIPS2019_8963}
Gourdeau, P., Kanade, V., Kwiatkowska, M., and Worrell, J.
\newblock On the hardness of robust classification.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pp.\
  7444--7453. Curran Associates, Inc., 2019.

\bibitem[He et~al.(2017)He, Wei, Chen, Carlini, and Song]{he2017adversarial}
He, W., Wei, J., Chen, X., Carlini, N., and Song, D.
\newblock Adversarial example defense: Ensembles of weak defenses are not
  strong.
\newblock In \emph{11th $\{$USENIX$\}$ Workshop on Offensive Technologies
  ($\{$WOOT$\}$ 17)}, 2017.

\bibitem[Ilyas et~al.(2019)Ilyas, Santurkar, Tsipras, Engstrom, Tran, and
  Madry]{NIPS2019_8307}
Ilyas, A., Santurkar, S., Tsipras, D., Engstrom, L., Tran, B., and Madry, A.
\newblock Adversarial examples are not bugs, they are features.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pp.\
  125--136. Curran Associates, Inc., 2019.

\bibitem[Krizhevsky \& Hinton(2009)Krizhevsky and
  Hinton]{krizhevsky2009learning}
Krizhevsky, A. and Hinton, G.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, Citeseer, 2009.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton, et~al.]{cifar10}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Lecuyer et~al.(2018)Lecuyer, Atlidakis, Geambasu, Hsu, and
  Jana]{lecuyer2018certified}
Lecuyer, M., Atlidakis, V., Geambasu, R., Hsu, D., and Jana, S.
\newblock Certified robustness to adversarial examples with differential
  privacy.
\newblock In \emph{2019 IEEE Symposium on Security and Privacy (SP)}, pp.\
  727--743, 2018.

\bibitem[Lee \& Raginsky(2018)Lee and Raginsky]{NIPS2018_7534}
Lee, J. and Raginsky, M.
\newblock Minimax statistical learning with wasserstein distances.
\newblock In \emph{Advances in Neural Information Processing Systems 31}, pp.\
  2687--2696. Curran Associates, Inc., 2018.

\bibitem[Li et~al.(2019)Li, Chen, Wang, and Carin]{NIPS2019_9143}
Li, B., Chen, C., Wang, W., and Carin, L.
\newblock Certified adversarial robustness with additive noise.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pp.\
  9459--9469. Curran Associates, Inc., 2019.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2018towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Pang et~al.(2019)Pang, Xu, Du, Chen, and Zhu]{pang2019improving}
Pang, T., Xu, K., Du, C., Chen, N., and Zhu, J.
\newblock Improving adversarial robustness via promoting ensemble diversity.
\newblock \emph{arXiv preprint arXiv:1901.08846}, 2019.

\bibitem[Papernot et~al.(2016{\natexlab{a}})Papernot, McDaniel, Jha,
  Fredrikson, Celik, and Swami]{Papernot2016TheLO}
Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.~B., and Swami,
  A.
\newblock The limitations of deep learning in adversarial settings.
\newblock In \emph{Security and Privacy (EuroS\&P), 2016 IEEE European
  Symposium on}, pp.\  372--387. IEEE, 2016{\natexlab{a}}.

\bibitem[Papernot et~al.(2016{\natexlab{b}})Papernot, McDaniel, Wu, Jha, and
  Swami]{papernot2016distillation}
Papernot, N., McDaniel, P., Wu, X., Jha, S., and Swami, A.
\newblock Distillation as a defense to adversarial perturbations against deep
  neural networks.
\newblock In \emph{2016 IEEE Symposium on Security and Privacy (SP)}, pp.\
  582--597. IEEE, 2016{\natexlab{b}}.

\bibitem[Perdomo \& Singer(2019)Perdomo and
  Singer]{DBLP:journals/corr/abs-1906-02816}
Perdomo, J.~C. and Singer, Y.
\newblock Robust attacks against multiple classifiers.
\newblock \emph{CoRR}, abs/1906.02816, 2019.

\bibitem[Pinot et~al.(2019)Pinot, Meunier, Araujo, Kashima, Yger,
  Gouy{-}Pailler, and Atif]{Pinot2019}
Pinot, R., Meunier, L., Araujo, A., Kashima, H., Yger, F., Gouy{-}Pailler, C.,
  and Atif, J.
\newblock Theoretical evidence for adversarial robustness through
  randomization.
\newblock In \emph{Advances in Neural Information Processing Systems 32
  (NeurIPS)}. 2019.

\bibitem[Pydi \& Jog(2019)Pydi and Jog]{pydi2019adversarial}
Pydi, M.~S. and Jog, V.
\newblock Adversarial risk via optimal transport and optimal couplings, 2019.

\bibitem[{Rota Bulò} et~al.(2017){Rota Bulò}, {Biggio}, {Pillai}, {Pelillo},
  and {Roli}]{7533509}
{Rota Bulò}, S., {Biggio}, B., {Pillai}, I., {Pelillo}, M., and {Roli}, F.
\newblock Randomized prediction games for adversarial machine learning.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  28\penalty0 (11):\penalty0 2466--2478, Nov 2017.

\bibitem[Sen et~al.(2020)Sen, Ravindran, and Raghunathan]{sen2020empir}
Sen, S., Ravindran, B., and Raghunathan, A.
\newblock Empir: Ensembles of mixed precision deep networks for increased
  robustness against adversarial attacks.
\newblock \emph{arXiv preprint arXiv:2004.10162}, 2020.

\bibitem[Sinha et~al.(2018)Sinha, Namkoong, and Duchi]{sinha2018certifiable}
Sinha, A., Namkoong, H., and Duchi, J.
\newblock Certifiable distributional robustness with principled adversarial
  training.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{Szegedy2013IntriguingPO}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Tramer et~al.(2020)Tramer, Carlini, Brendel, and
  Madry]{tramer2020adaptive}
Tramer, F., Carlini, N., Brendel, W., and Madry, A.
\newblock On adaptive attacks to adversarial example defenses.
\newblock \emph{arXiv preprint arXiv:2002.08347}, 2020.

\bibitem[Tramèr et~al.(2017)Tramèr, Papernot, Goodfellow, Boneh, and
  McDaniel]{tramer-papernot2017transferable}
Tramèr, F., Papernot, N., Goodfellow, I., Boneh, D., and McDaniel, P.
\newblock The space of transferable adversarial examples.
\newblock \emph{arXiv}, 2017.
\newblock URL \url{https://arxiv.org/abs/1704.03453}.

\bibitem[Verma \& Swami(2019)Verma and Swami]{verma2019error}
Verma, G. and Swami, A.
\newblock Error correcting output codes improve probability estimation and
  adversarial robustness of deep neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  8643--8653, 2019.

\bibitem[Wang et~al.(2019)Wang, Shi, and Osher]{NIPS2019_8443}
Wang, B., Shi, Z., and Osher, S.
\newblock Resnets ensemble via the feynman-kac formalism to improve natural and
  robust accuracies.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pp.\
  1655--1665. Curran Associates, Inc., 2019.

\bibitem[Xie et~al.(2018)Xie, Wang, Zhang, Ren, and
  Yuille]{Xie2017MitigatingAE}
Xie, C., Wang, J., Zhang, Z., Ren, Z., and Yuille, A.
\newblock Mitigating adversarial effects through randomization.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Xu et~al.(2017)Xu, Evans, and Qi]{xu2017feature}
Xu, W., Evans, D., and Qi, Y.
\newblock Feature squeezing mitigates and detects carlini/wagner adversarial
  examples.
\newblock \emph{arXiv preprint arXiv:1705.10686}, 2017.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and Komodakis]{ZagoruykoK16}
Zagoruyko, S. and Komodakis, N.
\newblock Wide residual networks.
\newblock In \emph{Proceedings of the British Machine Vision Conference
  (BMVC)}, pp.\  87.1--87.12. BMVA Press, September 2016.
\newblock ISBN 1-901725-59-6.
\newblock \doi{10.5244/C.30.87}.

\end{thebibliography}
