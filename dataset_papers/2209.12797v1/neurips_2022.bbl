\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{ba2014deep}
Ba, J., Caruana, R.: Do deep nets really need to be deep? Advances in neural
  information processing systems  \textbf{27} (2014)

\bibitem{bertasius2021space}
Bertasius, G., Wang, H., Torresani, L.: Is space-time attention all you need
  for video understanding. arXiv preprint arXiv:2102.05095  \textbf{2}(3), ~4
  (2021)

\bibitem{caba2015activitynet}
Caba~Heilbron, F., Escorcia, V., Ghanem, B., Carlos~Niebles, J.: Activitynet: A
  large-scale video benchmark for human activity understanding. In: Proceedings
  of the ieee conference on computer vision and pattern recognition. pp.
  961--970 (2015)

\bibitem{carreira2017quo}
Carreira, J., Zisserman, A.: Quo vadis, action recognition? a new model and the
  kinetics dataset. In: proceedings of the IEEE Conference on Computer Vision
  and Pattern Recognition. pp. 6299--6308 (2017)

\bibitem{2020mmaction2}
Contributors, M.: Openmmlab's next generation video understanding toolbox and
  benchmark. \url{https://github.com/open-mmlab/mmaction2} (2020)

\bibitem{donahue2015long}
Donahue, J., Anne~Hendricks, L., Guadarrama, S., Rohrbach, M., Venugopalan, S.,
  Saenko, K., Darrell, T.: Long-term recurrent convolutional networks for
  visual recognition and description. In: Proceedings of the IEEE conference on
  computer vision and pattern recognition. pp. 2625--2634 (2015)

\bibitem{fan2018watching}
Fan, H., Xu, Z., Zhu, L., Yan, C., Ge, J., Yang, Y.: Watching a small portion
  could be as good as watching all: Towards efficient video classification. In:
  IJCAI International Joint Conference on Artificial Intelligence (2018)

\bibitem{fan2019more}
Fan, Q., Chen, C.F.R., Kuehne, H., Pistoia, M., Cox, D.: More is less: Learning
  efficient video representations by big-little network and depthwise temporal
  aggregation. Advances in Neural Information Processing Systems  \textbf{32}
  (2019)

\bibitem{feichtenhofer2020x3d}
Feichtenhofer, C.: X3d: Expanding architectures for efficient video
  recognition. In: Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition. pp. 203--213 (2020)

\bibitem{feichtenhofer2019slowfast}
Feichtenhofer, C., Fan, H., Malik, J., He, K.: Slowfast networks for video
  recognition. In: Proceedings of the IEEE/CVF international conference on
  computer vision. pp. 6202--6211 (2019)

\bibitem{gao2020listen}
Gao, R., Oh, T.H., Grauman, K., Torresani, L.: Listen to look: Action
  recognition by previewing audio. In: Proceedings of the IEEE/CVF Conference
  on Computer Vision and Pattern Recognition. pp. 10457--10467 (2020)

\bibitem{garcia2018modality}
Garcia, N.C., Morerio, P., Murino, V.: Modality distillation with multiple
  stream networks for action recognition. In: Proceedings of the European
  Conference on Computer Vision (ECCV). pp. 103--118 (2018)

\bibitem{ghodrati2021frameexit}
Ghodrati, A., Bejnordi, B.E., Habibian, A.: Frameexit: Conditional early
  exiting for efficient video recognition. In: Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition. pp. 15608--15618
  (2021)

\bibitem{goyal2017something}
Goyal, R., Ebrahimi~Kahou, S., Michalski, V., Materzynska, J., Westphal, S.,
  Kim, H., Haenel, V., Fruend, I., Yianilos, P., Mueller-Freitag, M., et~al.:
  The" something something" video database for learning and evaluating visual
  common sense. In: Proceedings of the IEEE international conference on
  computer vision. pp. 5842--5850 (2017)

\bibitem{he2016deep}
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image
  recognition. In: Proceedings of the IEEE conference on computer vision and
  pattern recognition. pp. 770--778 (2016)

\bibitem{heo2019comprehensive}
Heo, B., Kim, J., Yun, S., Park, H., Kwak, N., Choi, J.Y.: A comprehensive
  overhaul of feature distillation. In: Proceedings of the IEEE/CVF
  International Conference on Computer Vision. pp. 1921--1930 (2019)

\bibitem{hinton2015distilling}
Hinton, G., Vinyals, O., Dean, J., et~al.: Distilling the knowledge in a neural
  network. arXiv preprint arXiv:1503.02531  \textbf{2}(7) (2015)

\bibitem{jiang2017exploiting}
Jiang, Y.G., Wu, Z., Wang, J., Xue, X., Chang, S.F.: Exploiting feature and
  class relationships in video categorization with regularized deep neural
  networks. IEEE transactions on pattern analysis and machine intelligence
  \textbf{40}(2),  352--364 (2017)

\bibitem{kay2017kinetics}
Kay, W., Carreira, J., Simonyan, K., Zhang, B., Hillier, C., Vijayanarasimhan,
  S., Viola, F., Green, T., Back, T., Natsev, P., et~al.: The kinetics human
  action video dataset. arXiv preprint arXiv:1705.06950  (2017)

\bibitem{kim2021efficient}
Kim, H., Jain, M., Lee, J.T., Yun, S., Porikli, F.: Efficient action
  recognition via dynamic knowledge propagation. In: Proceedings of the
  IEEE/CVF International Conference on Computer Vision. pp. 13719--13728 (2021)

\bibitem{kim2018paraphrasing}
Kim, J., Park, S., Kwak, N.: Paraphrasing complex network: Network compression
  via factor transfer. Advances in neural information processing systems
  \textbf{31} (2018)

\bibitem{komodakis2017paying}
Komodakis, N., Zagoruyko, S.: Paying more attention to attention: improving the
  performance of convolutional neural networks via attention transfer. In: ICLR
  (2017)

\bibitem{kondratyuk2021movinets}
Kondratyuk, D., Yuan, L., Li, Y., Zhang, L., Tan, M., Brown, M., Gong, B.:
  Movinets: Mobile video networks for efficient video recognition. In:
  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition. pp. 16020--16030 (2021)

\bibitem{korbar2019scsampler}
Korbar, B., Tran, D., Torresani, L.: Scsampler: Sampling salient clips from
  video for efficient action recognition. In: Proceedings of the IEEE/CVF
  International Conference on Computer Vision. pp. 6232--6242 (2019)

\bibitem{li2020tea}
Li, Y., Ji, B., Shi, X., Zhang, J., Kang, B., Wang, L.: Tea: Temporal
  excitation and aggregation for action recognition. In: Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 909--918
  (2020)

\bibitem{li2018videolstm}
Li, Z., Gavrilyuk, K., Gavves, E., Jain, M., Snoek, C.G.: Videolstm convolves,
  attends and flows for action recognition. Computer Vision and Image
  Understanding  \textbf{166},  41--50 (2018)

\bibitem{lin2019tsm}
Lin, J., Gan, C., Han, S.: Tsm: Temporal shift module for efficient video
  understanding. In: Proceedings of the IEEE/CVF International Conference on
  Computer Vision. pp. 7083--7093 (2019)

\bibitem{lin2022ocsampler}
Lin, J., Duan, H., Chen, K., Lin, D., Wang, L.: Ocsampler: Compressing videos
  to one clip with single-step sampling. arXiv preprint arXiv:2201.04388
  (2022)

\bibitem{liu2021video}
Liu, Z., Ning, J., Cao, Y., Wei, Y., Zhang, Z., Lin, S., Hu, H.: Video swin
  transformer. arXiv preprint arXiv:2106.13230  (2021)

\bibitem{liu2020teinet}
Liu, Z., Luo, D., Wang, Y., Wang, L., Tai, Y., Wang, C., Li, J., Huang, F., Lu,
  T.: Teinet: Towards an efficient architecture for video recognition. In:
  Proceedings of the AAAI Conference on Artificial Intelligence. vol.~34, pp.
  11669--11676 (2020)

\bibitem{liu2021tam}
Liu, Z., Wang, L., Wu, W., Qian, C., Lu, T.: Tam: Temporal adaptive module for
  video recognition. In: Proceedings of the IEEE/CVF International Conference
  on Computer Vision. pp. 13708--13718 (2021)

\bibitem{meng2020ar}
Meng, Y., Lin, C.C., Panda, R., Sattigeri, P., Karlinsky, L., Oliva, A.,
  Saenko, K., Feris, R.: Ar-net: Adaptive frame resolution for efficient action
  recognition. In: European Conference on Computer Vision. pp. 86--104.
  Springer (2020)

\bibitem{meng2021adafuse}
Meng, Y., Panda, R., Lin, C.C., Sattigeri, P., Karlinsky, L., Saenko, K.,
  Oliva, A., Feris, R.: Adafuse: Adaptive temporal fusion network for efficient
  action recognition. arXiv preprint arXiv:2102.05775  (2021)

\bibitem{neimark2021video}
Neimark, D., Bar, O., Zohar, M., Asselmann, D.: Video transformer network. In:
  Proceedings of the IEEE/CVF International Conference on Computer Vision. pp.
  3163--3172 (2021)

\bibitem{patrick2021keeping}
Patrick, M., Campbell, D., Asano, Y., Misra, I., Metze, F., Feichtenhofer, C.,
  Vedaldi, A., Henriques, J.F.: Keeping your eye on the ball: Trajectory
  attention in video transformers. Advances in Neural Information Processing
  Systems  \textbf{34} (2021)

\bibitem{purwanto2019extreme}
Purwanto, D., Renanda Adhi~Pramono, R., Chen, Y.T., Fang, W.H.: Extreme low
  resolution action recognition with spatial-temporal multi-head self-attention
  and knowledge distillation. In: Proceedings of the IEEE/CVF International
  Conference on Computer Vision Workshops. pp.~0--0 (2019)

\bibitem{romero2014fitnets}
Romero, A., Ballas, N., Kahou, S.E., Chassang, A., Gatta, C., Bengio, Y.:
  Fitnets: Hints for thin deep nets. arXiv preprint arXiv:1412.6550  (2014)

\bibitem{stroud2020d3d}
Stroud, J., Ross, D., Sun, C., Deng, J., Sukthankar, R.: D3d: Distilled 3d
  networks for video action recognition. In: Proceedings of the IEEE/CVF Winter
  Conference on Applications of Computer Vision. pp. 625--634 (2020)

\bibitem{sun2021dynamic}
Sun, X., Panda, R., Chen, C.F.R., Oliva, A., Feris, R., Saenko, K.: Dynamic
  network quantization for efficient video inference. In: Proceedings of the
  IEEE/CVF International Conference on Computer Vision. pp. 7375--7385 (2021)

\bibitem{tan2019efficientnet}
Tan, M., Le, Q.: Efficientnet: Rethinking model scaling for convolutional
  neural networks. In: International conference on machine learning. pp.
  6105--6114. PMLR (2019)

\bibitem{tran2015learning}
Tran, D., Bourdev, L., Fergus, R., Torresani, L., Paluri, M.: Learning
  spatiotemporal features with 3d convolutional networks. In: Proceedings of
  the IEEE international conference on computer vision. pp. 4489--4497 (2015)

\bibitem{tran2019video}
Tran, D., Wang, H., Torresani, L., Feiszli, M.: Video classification with
  channel-separated convolutional networks. In: Proceedings of the IEEE/CVF
  International Conference on Computer Vision. pp. 5552--5561 (2019)

\bibitem{tran2018closer}
Tran, D., Wang, H., Torresani, L., Ray, J., LeCun, Y., Paluri, M.: A closer
  look at spatiotemporal convolutions for action recognition. In: Proceedings
  of the IEEE conference on Computer Vision and Pattern Recognition. pp.
  6450--6459 (2018)

\bibitem{wang2016temporal}
Wang, L., Xiong, Y., Wang, Z., Qiao, Y., Lin, D., Tang, X., Gool, L.V.:
  Temporal segment networks: Towards good practices for deep action
  recognition. In: European conference on computer vision. pp. 20--36. Springer
  (2016)

\bibitem{wang2021adaptive}
Wang, Y., Chen, Z., Jiang, H., Song, S., Han, Y., Huang, G.: Adaptive focus for
  efficient video recognition. In: Proceedings of the IEEE/CVF International
  Conference on Computer Vision. pp. 16249--16258 (2021)

\bibitem{wang2021adafocus}
Wang, Y., Yue, Y., Lin, Y., Jiang, H., Lai, Z., Kulikov, V., Orlov, N., Shi,
  H., Huang, G.: Adafocus v2: End-to-end training of spatial dynamic networks
  for video recognition. arXiv preprint arXiv:2112.14238  (2021)

\bibitem{wu2019multi}
Wu, W., He, D., Tan, X., Chen, S., Wen, S.: Multi-agent reinforcement learning
  based frame sampling for effective untrimmed video recognition. In:
  Proceedings of the IEEE/CVF International Conference on Computer Vision. pp.
  6222--6231 (2019)

\bibitem{wu2020dynamic}
Wu, W., He, D., Tan, X., Chen, S., Yang, Y., Wen, S.: Dynamic inference: A new
  approach toward efficient video action recognition. In: Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops. pp.
  676--677 (2020)

\bibitem{wu2019liteeval}
Wu, Z., Xiong, C., Jiang, Y.G., Davis, L.S.: Liteeval: A coarse-to-fine
  framework for resource efficient video recognition. Advances in neural
  information processing systems  \textbf{32} (2019)

\bibitem{wu2019adaframe}
Wu, Z., Xiong, C., Ma, C.Y., Socher, R., Davis, L.S.: Adaframe: Adaptive frame
  selection for fast video recognition. In: Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition. pp. 1278--1287 (2019)

\bibitem{xie2018rethinking}
Xie, S., Sun, C., Huang, J., Tu, Z., Murphy, K.: Rethinking spatiotemporal
  feature learning: Speed-accuracy trade-offs in video classification. In:
  Proceedings of the European conference on computer vision (ECCV). pp.
  305--321 (2018)

\bibitem{zhou2018temporal}
Zhou, B., Andonian, A., Oliva, A., Torralba, A.: Temporal relational reasoning
  in videos. In: Proceedings of the European conference on computer vision
  (ECCV). pp. 803--818 (2018)

\bibitem{zolfaghari2018eco}
Zolfaghari, M., Singh, K., Brox, T.: Eco: Efficient convolutional network for
  online video understanding. In: Proceedings of the European conference on
  computer vision (ECCV). pp. 695--712 (2018)

\end{thebibliography}
