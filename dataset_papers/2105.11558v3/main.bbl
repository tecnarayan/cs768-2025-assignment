\begin{thebibliography}{10}

\bibitem{vidyasagar2002nonlinear}
Mathukumalli Vidyasagar.
\newblock {\em Nonlinear systems analysis}.
\newblock SIAM, 2002.

\bibitem{chen1989representations}
Sheng Chen and Steve~A Billings.
\newblock {Representations of non-linear systems: the NARMAX model}.
\newblock {\em International journal of control}, 49(3):1013--1032, 1989.

\bibitem{elman1990finding}
Jeffrey~L Elman.
\newblock Finding structure in time.
\newblock {\em Cognitive science}, 14(2):179--211, 1990.

\bibitem{jordan1997serial}
Michael~I Jordan.
\newblock {Serial order: A parallel distributed processing approach}.
\newblock In {\em Advances in psychology}, volume 121, pages 471--495.
  Elsevier, 1997.

\bibitem{ljung1999system}
Lennart Ljung.
\newblock System identification.
\newblock {\em Wiley encyclopedia of electrical and electronics engineering},
  pages 1--19, 1999.

\bibitem{aastrom1971system}
{{\AA}str{\"o}m, Karl Johan and Eykhoff, Peter}.
\newblock System identificationâ€”a survey.
\newblock {\em Automatica}, 7(2):123--162, 1971.

\bibitem{campi2002finite}
Marco~C Campi and Erik Weyer.
\newblock Finite sample properties of system identification methods.
\newblock {\em IEEE Transactions on Automatic Control}, 47(8):1329--1334, 2002.

\bibitem{vidyasagar2006learning}
Mathukumalli Vidyasagar and Rajeeva~L Karandikar.
\newblock A learning theory approach to system identification and stochastic
  adaptive control.
\newblock In {\em Probabilistic and randomized methods for design under
  uncertainty}, pages 265--302. Springer, 2006.

\bibitem{hall2016inference}
Eric~C Hall, Garvesh Raskutti, and Rebecca Willett.
\newblock Inference of high-dimensional autoregressive generalized linear
  models.
\newblock {\em arXiv preprint arXiv:1605.02693}, 2016.

\bibitem{wood2014behavioral}
John Wood.
\newblock {\em Behavioral modeling and linearization of RF power amplifiers}.
\newblock Artech house, 2014.

\bibitem{simchowitz2018learning}
Max Simchowitz, Horia Mania, Stephen Tu, Michael~I Jordan, and Benjamin Recht.
\newblock {Learning without mixing: Towards a sharp analysis of linear system
  identification}.
\newblock {\em arXiv preprint arXiv:1802.08334}, 2018.

\bibitem{sarkar2019near}
Tuhin Sarkar and Alexander Rakhlin.
\newblock Near optimal finite time identification of arbitrary linear dynamical
  systems.
\newblock In {\em International Conference on Machine Learning}, pages
  5610--5618. PMLR, 2019.

\bibitem{shalev2009stochastic}
Shai Shalev-Shwartz, Ohad Shamir, Nathan Srebro, and Karthik Sridharan.
\newblock {Stochastic Convex Optimization.}
\newblock In {\em COLT}, 2009.

\bibitem{paulin2015concentration}
Daniel Paulin et~al.
\newblock {Concentration inequalities for Markov chains by Marton couplings and
  spectral methods}.
\newblock {\em Electronic Journal of Probability}, 20, 2015.

\bibitem{rotinov2019reverse}
Egor Rotinov.
\newblock Reverse experience replay.
\newblock {\em arXiv preprint arXiv:1910.08780}, 2019.

\bibitem{ambrose2016reverse}
R~Ellen Ambrose, Brad~E Pfeiffer, and David~J Foster.
\newblock Reverse replay of hippocampal place cells is uniquely modulated by
  changing reward.
\newblock {\em Neuron}, 91(5):1124--1136, 2016.

\bibitem{haga2018recurrent}
Tatsuya Haga and Tomoki Fukai.
\newblock Recurrent network model for learning goal-directed sequences through
  reverse replay.
\newblock {\em Elife}, 7:e34171, 2018.

\bibitem{whelan2021robotic}
Matthew~T Whelan, Tony~J Prescott, and Eleni Vasilaki.
\newblock A robotic model of hippocampal reverse replay for reinforcement
  learning.
\newblock {\em arXiv preprint arXiv:2102.11914}, 2021.

\bibitem{jain2021streaming}
Prateek Jain, Suhas~S Kowshik, Dheeraj Nagaraj, and Praneeth Netrapalli.
\newblock {Streaming Linear System Identification with Reverse Experience
  Replay}.
\newblock {\em arXiv preprint arXiv:2103.05896}, 2021.

\bibitem{abbasi2011online}
{Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba}.
\newblock Online least squares estimation with self-normalized processes: An
  application to bandit problems.
\newblock {\em arXiv preprint arXiv:1102.2670}, 2011.

\bibitem{pena2008self}
Victor~H Pe{\~n}a, Tze~Leung Lai, and Qi-Man Shao.
\newblock {\em {Self-normalized processes: Limit theory and Statistical
  Applications}}.
\newblock Springer Science \& Business Media, 2008.

\bibitem{diakonikolas2020approximation}
Ilias Diakonikolas, Surbhi Goel, Sushrut Karmalkar, Adam~R Klivans, and Mahdi
  Soltanolkotabi.
\newblock Approximation schemes for relu regression.
\newblock In {\em Conference on Learning Theory}, pages 1452--1485. PMLR, 2020.

\bibitem{chen1990non}
Sheng Chen, Stephen~A Billings, and PM~Grant.
\newblock Non-linear system identification using neural networks.
\newblock {\em International journal of control}, 51(6):1191--1214, 1990.

\bibitem{allen2018convergence}
Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song.
\newblock On the convergence rate of training recurrent neural networks.
\newblock {\em arXiv preprint arXiv:1810.12065}, 2018.

\bibitem{bahmani2019convex}
Sohail Bahmani and Justin Romberg.
\newblock Convex programming for estimation in nonlinear recurrent models.
\newblock {\em arXiv preprint arXiv:1908.09915}, 2019.

\bibitem{oymak2019stochastic}
Samet Oymak.
\newblock Stochastic gradient descent learns state equations with nonlinear
  activations.
\newblock In {\em Conference on Learning Theory}, pages 2551--2579. PMLR, 2019.

\bibitem{miller2018stable}
John Miller and Moritz Hardt.
\newblock Stable recurrent models.
\newblock {\em arXiv preprint arXiv:1805.10369}, 2018.

\bibitem{mania2020active}
Horia Mania, Michael~I Jordan, and Benjamin Recht.
\newblock Active learning for nonlinear system identification with guarantees.
\newblock {\em arXiv preprint arXiv:2006.10277}, 2020.

\bibitem{sarker2020parameter}
Arnab Sarker, Joseph~E Gaudio, and Anuradha~M Annaswamy.
\newblock {Parameter Estimation Bounds Based on the Theory of Spectral Lines}.
\newblock {\em arXiv preprint arXiv:2006.12687}, 2020.

\bibitem{mao2020finite}
Yanbing Mao, Naira Hovakimyan, Petros Voulgaris, and Lui Sha.
\newblock {Finite-Time Model Inference From A Single Noisy Trajectory}.
\newblock {\em arXiv preprint arXiv:2010.06616}, 2020.

\bibitem{sattar2020non}
Yahya Sattar and Samet Oymak.
\newblock Non-asymptotic and accurate learning of nonlinear dynamical systems.
\newblock {\em arXiv preprint arXiv:2002.08538}, 2020.

\bibitem{foster2020learning}
Dylan Foster, Tuhin Sarkar, and Alexander Rakhlin.
\newblock Learning nonlinear dynamical systems from a single trajectory.
\newblock In {\em Learning for Dynamics and Control}, pages 851--861. PMLR,
  2020.

\bibitem{kakade2011efficient}
Sham Kakade, Adam~Tauman Kalai, Varun Kanade, and Ohad Shamir.
\newblock Efficient learning of generalized linear and single index models with
  isotonic regression.
\newblock {\em arXiv preprint arXiv:1104.2018}, 2011.

\bibitem{gao2021improved}
Yue Gao and Garvesh Raskutti.
\newblock Improved prediction and network estimation using the monotone single
  index multi-variate autoregressive model.
\newblock {\em arXiv preprint arXiv:2106.14630}, 2021.

\bibitem{simchowitz2019learning}
Max Simchowitz, Ross Boczar, and Benjamin Recht.
\newblock Learning linear dynamical systems with semi-parametric least squares.
\newblock In {\em Conference on Learning Theory}, pages 2714--2802. PMLR, 2019.

\bibitem{sarkar2019finite}
Tuhin Sarkar, Alexander Rakhlin, and Munther~A Dahleh.
\newblock Finite-time system identification for partially observed lti systems
  of unknown order.
\newblock {\em arXiv preprint arXiv:1902.01848}, 2019.

\bibitem{kalai2009isotron}
Adam~Tauman Kalai and Ravi Sastry.
\newblock {The Isotron Algorithm: High-Dimensional Isotonic Regression.}
\newblock In {\em COLT}. Citeseer, 2009.

\bibitem{boffi2020reflectron}
Nicholas~M Boffi, Stephen Tu, and Jean-Jacques~E Slotine.
\newblock {The Reflectron: Exploiting geometry for learning generalized linear
  models}.
\newblock {\em arXiv preprint arXiv:2006.08575}, 2020.

\bibitem{nagaraj2020least}
Dheeraj Nagaraj, Xian Wu, Guy Bresler, Prateek Jain, and Praneeth Netrapalli.
\newblock {Least Squares Regression with Markovian Data: Fundamental Limits and
  Algorithms}.
\newblock {\em Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem{lin1992self}
Long-Ji Lin.
\newblock Self-improving reactive agents based on reinforcement learning,
  planning and teaching.
\newblock {\em Machine learning}, 8(3-4):293--321, 1992.

\bibitem{hsu2016loss}
Daniel Hsu and Sivan Sabato.
\newblock Loss minimization and parameter estimation with heavy tails.
\newblock {\em The Journal of Machine Learning Research}, 17(1):543--582, 2016.

\bibitem{hamilton1994time}
James~Douglas Hamilton.
\newblock {\em Time series analysis}.
\newblock Princeton university press, 1994.

\bibitem{kuznetsov2016time}
Vitaly Kuznetsov and Mehryar Mohri.
\newblock Time series prediction and online learning.
\newblock In {\em Conference on Learning Theory}, pages 1190--1213. PMLR, 2016.

\bibitem{sutton1998introduction}
Richard~S Sutton, Andrew~G Barto, et~al.
\newblock {\em Introduction to reinforcement learning}, volume 135.
\newblock MIT press Cambridge, 1998.

\bibitem{bousquet2002stability}
{Bousquet, Olivier and Elisseeff, Andr{\'e}}.
\newblock Stability and generalization.
\newblock {\em The Journal of Machine Learning Research}, 2:499--526, 2002.

\bibitem{hardt2016train}
Moritz Hardt, Ben Recht, and Yoram Singer.
\newblock {Train faster, generalize better: Stability of stochastic gradient
  descent}.
\newblock In {\em International Conference on Machine Learning}, pages
  1225--1234. PMLR, 2016.

\bibitem{nagaraj2019sgd}
Dheeraj Nagaraj, Prateek Jain, and Praneeth Netrapalli.
\newblock {SGD without replacement: Sharper rates for general smooth convex
  functions}.
\newblock In {\em International Conference on Machine Learning}, pages
  4703--4711. PMLR, 2019.

\bibitem{boucheron2013concentration}
{Boucheron, St{\'e}phane and Lugosi, G{\'a}bor and Massart, Pascal}.
\newblock {\em {Concentration inequalities: A nonasymptotic theory of
  independence}}.
\newblock Oxford university press, 2013.

\bibitem{dieuleveut2020bridging}
Aymeric Dieuleveut, Alain Durmus, Francis Bach, et~al.
\newblock Bridging the gap between constant step size stochastic gradient
  descent and markov chains.
\newblock {\em Annals of Statistics}, 48(3):1348--1382, 2020.

\bibitem{vershynin2019high}
Roman Vershynin.
\newblock High-dimensional probability, 2019.

\bibitem{vershynin2010introduction}
Roman Vershynin.
\newblock Introduction to the non-asymptotic analysis of random matrices.
\newblock {\em arXiv preprint arXiv:1011.3027}, 2010.

\end{thebibliography}
