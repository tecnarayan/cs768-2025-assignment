\begin{thebibliography}{82}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aditya et~al.(2018)Aditya, Anirban, Abhishek, and Prantik]{aditya1710grad}
C.~Aditya, S.~Anirban, D.~Abhishek, and H.~Prantik.
\newblock Grad-cam++: improved visual explanations for deep convolutional networks. arxiv 2018.
\newblock \emph{arXiv preprint arXiv:1710.11063}, 2018.

\bibitem[Akhtar(2023)]{Akhtar2023ASO}
N.~Akhtar.
\newblock A survey of explainable ai in deep visual modeling: Methods and metrics.
\newblock \emph{ArXiv}, abs/2301.13445, 2023.

\bibitem[Akula et~al.(2020)Akula, Wang, and Zhu]{akula2020cocox}
A.~Akula, S.~Wang, and S.-C. Zhu.
\newblock Cocox: Generating conceptual and counterfactual explanations via fault-lines.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~34, pages 2594--2601, 2020.

\bibitem[Alvarez~Melis and Jaakkola(2018)]{alvarez2018towards}
D.~Alvarez~Melis and T.~Jaakkola.
\newblock Towards robust interpretability with self-explaining neural networks.
\newblock \emph{Adv. Neural Inform. Process. Syst.}, 2018.

\bibitem[Anders et~al.(2022)Anders, Weber, Neumann, Samek, M{\"u}ller, and Lapuschkin]{anders2022finding}
C.~J. Anders, L.~Weber, D.~Neumann, W.~Samek, K.-R. M{\"u}ller, and S.~Lapuschkin.
\newblock Finding and removing clever hans: Using explanation methods to debug and improve deep models.
\newblock \emph{Information Fusion}, 77:\penalty0 261--295, 2022.

\bibitem[Bahadori and Heckerman(2020)]{bahadori2020debiasing}
M.~T. Bahadori and D.~E. Heckerman.
\newblock Debiasing concept-based explanations with causal analysis.
\newblock \emph{arXiv preprint arXiv:2007.11500}, 2020.

\bibitem[Barrow and Tenenbaum(1978)]{IID78}
H.~G. Barrow and J.~M. Tenenbaum.
\newblock Recovering intrinsic scene characteristics from images.
\newblock 1978.

\bibitem[Beckh et~al.(2023)Beckh, M{\"u}ller, Jakobs, Toborek, Tan, Fischer, Welke, Houben, and von Rueden]{beckhsok}
K.~Beckh, S.~M{\"u}ller, M.~Jakobs, V.~Toborek, H.~Tan, R.~Fischer, P.~Welke, S.~Houben, and L.~von Rueden.
\newblock Sok: Harnessing prior knowledge for explainable machine learning: An overview.
\newblock In \emph{First IEEE Conference on Secure and Trustworthy Machine Learning}, 2023.

\bibitem[Bell et~al.(2014{\natexlab{a}})Bell, Bala, and Snavely]{IIW}
S.~Bell, K.~Bala, and N.~Snavely.
\newblock Intrinsic images in the wild.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 33:\penalty0 1 -- 12, 2014{\natexlab{a}}.

\bibitem[Bell et~al.(2014{\natexlab{b}})Bell, Bala, and Snavely]{bell2014intrinsic}
S.~Bell, K.~Bala, and N.~Snavely.
\newblock Intrinsic images in the wild.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 33\penalty0 (4):\penalty0 1--12, 2014{\natexlab{b}}.

\bibitem[Bonneel et~al.(2017)Bonneel, Kovacs, Paris, and Bala]{BKPB17}
N.~Bonneel, B.~Kovacs, S.~Paris, and K.~Bala.
\newblock {Intrinsic Decompositions for Image Editing}.
\newblock \emph{Computer Graphics Forum (Eurographics State of The Art Report)}, 2017.

\bibitem[Caron et~al.(2018)Caron, Bojanowski, Joulin, and Douze]{caron2018deep}
M.~Caron, P.~Bojanowski, A.~Joulin, and M.~Douze.
\newblock Deep clustering for unsupervised learning of visual features.
\newblock In \emph{Proceedings of the European conference on computer vision (ECCV)}, pages 132--149, 2018.

\bibitem[Caron et~al.(2021)Caron, Touvron, Misra, J{\'e}gou, Mairal, Bojanowski, and Joulin]{caron2021emerging}
M.~Caron, H.~Touvron, I.~Misra, H.~J{\'e}gou, J.~Mairal, P.~Bojanowski, and A.~Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 9650--9660, 2021.

\bibitem[Chang(2018)]{chang2018concept}
D.~T. Chang.
\newblock Concept-oriented deep learning: Generative concept representations.
\newblock \emph{arXiv preprint arXiv:1811.06622}, 2018.

\bibitem[Cimpoi et~al.(2014)Cimpoi, Maji, Kokkinos, Mohamed, and Vedaldi]{cimpoi2014describing}
M.~Cimpoi, S.~Maji, I.~Kokkinos, S.~Mohamed, and A.~Vedaldi.
\newblock Describing textures in the wild.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 3606--3613, 2014.

\bibitem[Du et~al.(2019)Du, Liu, and Hu]{du2019techniques}
M.~Du, N.~Liu, and X.~Hu.
\newblock Techniques for interpretable machine learning.
\newblock \emph{Communications of the ACM}, 63\penalty0 (1):\penalty0 68--77, 2019.

\bibitem[Erion et~al.(2021)Erion, Janizek, Sturmfels, Lundberg, and Lee]{erion2021improving}
G.~Erion, J.~D. Janizek, P.~Sturmfels, S.~M. Lundberg, and S.-I. Lee.
\newblock Improving performance of deep learning models with axiomatic attribution priors and expected gradients.
\newblock \emph{Nature machine intelligence}, 3\penalty0 (7):\penalty0 620--631, 2021.

\bibitem[Fong and Vedaldi(2017)]{fong2017interpretable}
R.~C. Fong and A.~Vedaldi.
\newblock Interpretable explanations of black boxes by meaningful perturbation.
\newblock In \emph{Proceedings of the IEEE international conference on computer vision}, pages 3429--3437, 2017.

\bibitem[Gao et~al.(2022)Gao, Gu, Jiang, Hong, Yu, and Zhao]{gao2022going}
Y.~Gao, S.~Gu, J.~Jiang, S.~R. Hong, D.~Yu, and L.~Zhao.
\newblock Going beyond xai: A systematic survey for explanation-guided learning.
\newblock \emph{arXiv preprint arXiv:2212.03954}, 2022.

\bibitem[Garces et~al.(2022)Garces, Rodriguez-Pardo, Casas, and Lopez-Moreno]{iidSurvey2022}
E.~Garces, C.~Rodriguez-Pardo, D.~Casas, and J.~Lopez-Moreno.
\newblock A survey on intrinsic images: Delving deep into lambert and beyond.
\newblock \emph{Int. J. Comput. Vision}, 130\penalty0 (3):\penalty0 836â€“868, 2022.

\bibitem[Ghandeharioun et~al.(2021)Ghandeharioun, Kim, Li, Jou, Eoff, and Picard]{ghandeharioun2021dissect}
A.~Ghandeharioun, B.~Kim, C.-L. Li, B.~Jou, B.~Eoff, and R.~W. Picard.
\newblock Dissect: Disentangled simultaneous explanations via concept traversals.
\newblock \emph{arXiv preprint arXiv:2105.15164}, 2021.

\bibitem[Ghorbani et~al.(2019)Ghorbani, Wexler, Zou, and Kim]{ghorbani2019towards}
A.~Ghorbani, J.~Wexler, J.~Zou, and B.~Kim.
\newblock Towards automatic concept-based explanations.
\newblock \emph{arXiv preprint arXiv:1902.03129}, 2019.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and Szegedy]{goodfellow2014explaining}
I.~J. Goodfellow, J.~Shlens, and C.~Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[Gupta et~al.(2023)Gupta, Saini, and Narayanan]{10.1145/3571600.3571603}
A.~Gupta, S.~Saini, and P.~J. Narayanan.
\newblock Interpreting intrinsic image decomposition using concept activations.
\newblock In \emph{Proceedings of the Thirteenth Indian Conference on Computer Vision, Graphics and Image Processing}, ICVGIP '22, New York, NY, USA, 2023. Association for Computing Machinery.
\newblock ISBN 9781450398220.
\newblock \doi{10.1145/3571600.3571603}.

\bibitem[Hase and Bansal(2021)]{hase2021can}
P.~Hase and M.~Bansal.
\newblock When can models learn from explanations? a formal framework for understanding the roles of explanation data.
\newblock \emph{arXiv preprint arXiv:2102.02201}, 2021.

\bibitem[Hinton et~al.(2015)Hinton, Vinyals, and Dean]{hinton2015distilling}
G.~Hinton, O.~Vinyals, and J.~Dean.
\newblock Distilling the knowledge in a neural network.
\newblock \emph{arXiv preprint arXiv:1503.02531}, 2015.

\bibitem[Hinton and Salakhutdinov(2006)]{hinton2006reducing}
G.~E. Hinton and R.~R. Salakhutdinov.
\newblock Reducing the dimensionality of data with neural networks.
\newblock \emph{science}, 313\penalty0 (5786):\penalty0 504--507, 2006.

\bibitem[Hitzler and Sarker(2022)]{hitzler2022human}
P.~Hitzler and M.~Sarker.
\newblock Human-centered concept explanations for neural networks.
\newblock \emph{Neuro-Symbolic Artificial Intelligence: The State of the Art}, 342\penalty0 (337):\penalty0 2, 2022.

\bibitem[Holmberg et~al.(2022)Holmberg, Davidsson, and Linde]{Holmberg2022MappingKR}
L.~Holmberg, P.~Davidsson, and P.~Linde.
\newblock Mapping knowledge representations to concepts: A review and new perspectives.
\newblock \emph{ArXiv}, abs/2301.00189, 2022.

\bibitem[Jain et~al.(2022)Jain, Lawrence, Moitra, and Madry]{jain2022distilling}
S.~Jain, H.~Lawrence, A.~Moitra, and A.~Madry.
\newblock Distilling model failures as directions in latent space.
\newblock \emph{arXiv preprint arXiv:2206.14754}, 2022.

\bibitem[Kazhdan et~al.(2020)Kazhdan, Dimanov, Jamnik, Li{\`o}, and Weller]{kazhdan2020now}
D.~Kazhdan, B.~Dimanov, M.~Jamnik, P.~Li{\`o}, and A.~Weller.
\newblock Now you see me (cme): concept-based model extraction.
\newblock \emph{arXiv preprint arXiv:2010.13233}, 2020.

\bibitem[Keswani et~al.(2022)Keswani, Ramakrishnan, Reddy, and Balasubramanian]{keswani2022proto2proto}
M.~Keswani, S.~Ramakrishnan, N.~Reddy, and V.~N. Balasubramanian.
\newblock Proto2proto: Can you recognize the car, the way i do?
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 10233--10243, 2022.

\bibitem[Kim et~al.(2018)Kim, Wattenberg, Gilmer, Cai, Wexler, Viegas, et~al.]{kim2018interpretability}
B.~Kim, M.~Wattenberg, J.~Gilmer, C.~Cai, J.~Wexler, F.~Viegas, et~al.
\newblock Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav).
\newblock In \emph{International conference on machine learning}, pages 2668--2677. PMLR, 2018.

\bibitem[Kim et~al.(2021{\natexlab{a}})Kim, Kim, Seo, and Yoon]{Kim2021XProtoNetDI}
E.~Kim, S.~Kim, M.~Seo, and S.~Yoon.
\newblock Xprotonet: Diagnosis in chest radiography with global and local explanations.
\newblock \emph{2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 15714--15723, 2021{\natexlab{a}}.

\bibitem[Kim et~al.(2021{\natexlab{b}})Kim, Lee, and Choo]{kim2021biaswap}
E.~Kim, J.~Lee, and J.~Choo.
\newblock Biaswap: Removing dataset bias with bias-tailored swapping augmentation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 14992--15001, 2021{\natexlab{b}}.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Koh et~al.(2020)Koh, Nguyen, Tang, Mussmann, Pierson, Kim, and Liang]{koh2020concept}
P.~W. Koh, T.~Nguyen, Y.~S. Tang, S.~Mussmann, E.~Pierson, B.~Kim, and P.~Liang.
\newblock Concept bottleneck models.
\newblock In \emph{International Conference on Machine Learning}, pages 5338--5348. PMLR, 2020.

\bibitem[Kovacs et~al.(2017{\natexlab{a}})Kovacs, Bell, Snavely, and Bala]{SAW}
B.~Kovacs, S.~Bell, N.~Snavely, and K.~Bala.
\newblock Shading annotations in the wild.
\newblock \emph{2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 850--859, 2017{\natexlab{a}}.

\bibitem[Kovacs et~al.(2017{\natexlab{b}})Kovacs, Bell, Snavely, and Bala]{kovacs2017shading}
B.~Kovacs, S.~Bell, N.~Snavely, and K.~Bala.
\newblock Shading annotations in the wild.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 6998--7007, 2017{\natexlab{b}}.

\bibitem[L~EH(1971)]{l1971lightness}
M.~L~EH.
\newblock Lightness and retinex theory.
\newblock \emph{J. Opt. Soc. Am.}, 61\penalty0 (1):\penalty0 1--11, 1971.

\bibitem[Land(1977)]{retinex77}
E.~H. Land.
\newblock The retinex theory of color vision.
\newblock \emph{Scientific American}, 237 6:\penalty0 108--28, 1977.

\bibitem[LeCun(1998)]{lecun1998mnist}
Y.~LeCun.
\newblock The mnist database of handwritten digits.
\newblock \emph{http://yann. lecun. com/exdb/mnist/}, 1998.

\bibitem[Lee et~al.(2021)Lee, Kim, Lee, Lee, and Choo]{lee2021learning}
J.~Lee, E.~Kim, J.~Lee, J.~Lee, and J.~Choo.
\newblock Learning debiased representation via disentangled feature augmentation.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 25123--25133, 2021.

\bibitem[Li et~al.(2020)Li, Zhou, Xiong, and Hoi]{li2020prototypical}
J.~Li, P.~Zhou, C.~Xiong, and S.~C. Hoi.
\newblock Prototypical contrastive learning of unsupervised representations.
\newblock \emph{arXiv preprint arXiv:2005.04966}, 2020.

\bibitem[Li and Vasconcelos(2019)]{li2019repair}
Y.~Li and N.~Vasconcelos.
\newblock Repair: Removing representation bias by dataset resampling.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 9572--9581, 2019.

\bibitem[Li et~al.(2023)Li, Guo, and Ge]{li2023pseudo}
Y.~Li, L.~Guo, and Y.~Ge.
\newblock Pseudo labels for unsupervised domain adaptation: A review.
\newblock \emph{Electronics}, 12\penalty0 (15):\penalty0 3325, 2023.

\bibitem[Li and Snavely(2018)]{CGintrinsics}
Z.~Li and N.~Snavely.
\newblock Cgintrinsics: Better intrinsic image decomposition through physically-based rendering.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, 2018.

\bibitem[Linardatos et~al.(2020)Linardatos, Papastefanopoulos, and Kotsiantis]{linardatos2020explainable}
P.~Linardatos, V.~Papastefanopoulos, and S.~Kotsiantis.
\newblock Explainable ai: A review of machine learning interpretability methods.
\newblock \emph{Entropy}, 23\penalty0 (1):\penalty0 18, 2020.

\bibitem[Ma et~al.(2017)Ma, Feng, Jiang, Xia, and Peng]{ma2017intrinsic}
Y.~Ma, X.~Feng, X.~Jiang, Z.~Xia, and J.~Peng.
\newblock Intrinsic image decomposition: A comprehensive review.
\newblock In \emph{Image and Graphics: 9th International Conference, ICIG 2017, Shanghai, China, September 13-15, 2017, Revised Selected Papers, Part I 9}, pages 626--638. Springer, 2017.

\bibitem[Moayeri et~al.(2023)Moayeri, Rezaei, Sanjabi, and Feizi]{moayeri2023text}
M.~Moayeri, K.~Rezaei, M.~Sanjabi, and S.~Feizi.
\newblock Text-to-concept (and back) via cross-model alignment.
\newblock \emph{arXiv preprint arXiv:2305.06386}, 2023.

\bibitem[Nassar et~al.(2023)Nassar, Hayat, Abbasnejad, Rezatofighi, and Haffari]{nassar2023protocon}
I.~Nassar, M.~Hayat, E.~Abbasnejad, H.~Rezatofighi, and G.~Haffari.
\newblock Protocon: Pseudo-label refinement via online clustering and prototypical consistency for efficient semi-supervised learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 11641--11650, 2023.

\bibitem[Niu et~al.(2022)Niu, Shan, and Wang]{niu2022spice}
C.~Niu, H.~Shan, and G.~Wang.
\newblock Spice: Semantic pseudo-labeling for image clustering.
\newblock \emph{IEEE Transactions on Image Processing}, 31:\penalty0 7264--7278, 2022.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot, and Duchesnay]{scikit-learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel, M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos, D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 2825--2830, 2011.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry, A.~Askell, P.~Mishkin, J.~Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International conference on machine learning}, pages 8748--8763. PMLR, 2021.

\bibitem[Rieger et~al.(2020)Rieger, Singh, Murdoch, and Yu]{rieger2020interpretations}
L.~Rieger, C.~Singh, W.~Murdoch, and B.~Yu.
\newblock Interpretations are useful: penalizing explanations to align neural networks with prior knowledge.
\newblock In \emph{International conference on machine learning}, pages 8116--8126. PMLR, 2020.

\bibitem[Ross et~al.(2017)Ross, Hughes, and Doshi-Velez]{ross2017right}
A.~S. Ross, M.~C. Hughes, and F.~Doshi-Velez.
\newblock Right for the right reasons: Training differentiable models by constraining their explanations.
\newblock \emph{arXiv preprint arXiv:1703.03717}, 2017.

\bibitem[Saha and Roy(2023)]{saha2023saliency}
G.~Saha and K.~Roy.
\newblock Saliency guided experience packing for replay in continual learning.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pages 5273--5283, 2023.

\bibitem[Samek et~al.(2017)Samek, Wiegand, and M{\"u}ller]{samek2017explainable}
W.~Samek, T.~Wiegand, and K.-R. M{\"u}ller.
\newblock Explainable artificial intelligence: Understanding, visualizing and interpreting deep learning models.
\newblock \emph{arXiv preprint arXiv:1708.08296}, 2017.

\bibitem[Sawada and Nakamura(2022{\natexlab{a}})]{Sawada2022CSENNCS}
Y.~Sawada and K.~Nakamura.
\newblock C-senn: Contrastive self-explaining neural network.
\newblock \emph{ArXiv}, abs/2206.09575, 2022{\natexlab{a}}.

\bibitem[Sawada and Nakamura(2022{\natexlab{b}})]{Sawada2022ConceptBM}
Y.~Sawada and K.~Nakamura.
\newblock Concept bottleneck model with additional unsupervised concepts.
\newblock \emph{IEEE Access}, 10:\penalty0 41758--41765, 2022{\natexlab{b}}.

\bibitem[Schramowski et~al.(2020)Schramowski, Stammer, Teso, Brugger, Herbert, Shao, Luigs, Mahlein, and Kersting]{schramowski2020making}
P.~Schramowski, W.~Stammer, S.~Teso, A.~Brugger, F.~Herbert, X.~Shao, H.-G. Luigs, A.-K. Mahlein, and K.~Kersting.
\newblock Making deep neural networks right for the right scientific reasons by interacting with their explanations.
\newblock \emph{Nature Machine Intelligence}, 2\penalty0 (8):\penalty0 476--486, 2020.

\bibitem[Schrouff et~al.(2021)Schrouff, Baur, Hou, Mincu, Loreaux, Blanes, Wexler, Karthikesalingam, and Kim]{schrouff2021best}
J.~Schrouff, S.~Baur, S.~Hou, D.~Mincu, E.~Loreaux, R.~Blanes, J.~Wexler, A.~Karthikesalingam, and B.~Kim.
\newblock Best of both worlds: local and global explanations with human-understandable concepts.
\newblock \emph{arXiv preprint arXiv:2106.08641}, 2021.

\bibitem[Schwalbe(2022)]{schwalbe2022concept}
G.~Schwalbe.
\newblock Concept embedding analysis: A review.
\newblock \emph{arXiv preprint arXiv:2203.13909}, 2022.

\bibitem[Selvaraju et~al.(2017)Selvaraju, Cogswell, Das, Vedantam, Parikh, and Batra]{selvaraju2017grad}
R.~R. Selvaraju, M.~Cogswell, A.~Das, R.~Vedantam, D.~Parikh, and D.~Batra.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based localization.
\newblock In \emph{Proceedings of the IEEE international conference on computer vision}, pages 618--626, 2017.

\bibitem[Smilkov et~al.(2017)Smilkov, Thorat, Kim, Vi{\'e}gas, and Wattenberg]{smilkov2017smoothgrad}
D.~Smilkov, N.~Thorat, B.~Kim, F.~Vi{\'e}gas, and M.~Wattenberg.
\newblock Smoothgrad: removing noise by adding noise.
\newblock \emph{arXiv preprint arXiv:1706.03825}, 2017.

\bibitem[Song et~al.(2023)Song, Shyn, and Kim]{song2023img2tab}
Y.~Song, S.~K. Shyn, and K.-s. Kim.
\newblock Img2tab: Automatic class relevant concept discovery from stylegan features for explainable image classification.
\newblock \emph{arXiv preprint arXiv:2301.06324}, 2023.

\bibitem[Soni et~al.(2020)Soni, Shah, Seng, and Moore]{Soni2020AdversarialT}
R.~Soni, N.~Shah, C.~T. Seng, and J.~D. Moore.
\newblock Adversarial tcav - robust and effective interpretation of intermediate layers in neural networks.
\newblock \emph{ArXiv}, abs/2002.03549, 2020.

\bibitem[Tanwisuth et~al.(2021)Tanwisuth, Fan, Zheng, Zhang, Zhang, Chen, and Zhou]{tanwisuth2021prototype}
K.~Tanwisuth, X.~Fan, H.~Zheng, S.~Zhang, H.~Zhang, B.~Chen, and M.~Zhou.
\newblock A prototype-oriented framework for unsupervised domain adaptation.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 17194--17208, 2021.

\bibitem[Tartaglione et~al.(2021)Tartaglione, Barbano, and Grangetto]{tartaglione2021end}
E.~Tartaglione, C.~A. Barbano, and M.~Grangetto.
\newblock End: Entangling and disentangling deep representations for bias correction.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 13508--13517, 2021.

\bibitem[Tschernezki et~al.(2022{\natexlab{a}})Tschernezki, Laina, Larlus, and Vedaldi]{tschernezki2022neural}
V.~Tschernezki, I.~Laina, D.~Larlus, and A.~Vedaldi.
\newblock Neural feature fusion fields: 3d distillation of self-supervised 2d image representations.
\newblock \emph{arXiv preprint arXiv:2209.03494}, 2022{\natexlab{a}}.

\bibitem[Tschernezki et~al.(2022{\natexlab{b}})Tschernezki, Laina, Larlus, and Vedaldi]{tschernezki22neural}
V.~Tschernezki, I.~Laina, D.~Larlus, and A.~Vedaldi.
\newblock Neural feature fusion fields: {3D} distillation of self-supervised {2D} image representations.
\newblock In \emph{Proceedings of the International Conference on {3D} Vision (3DV)}, 2022{\natexlab{b}}.

\bibitem[Voj{\'\i}{\v{r}} and Kliegr(2020)]{vojivr2020editable}
S.~Voj{\'\i}{\v{r}} and T.~Kliegr.
\newblock Editable machine learning models? a rule-based framework for user studies of explainability.
\newblock \emph{Advances in Data Analysis and Classification}, 14\penalty0 (4):\penalty0 785--799, 2020.

\bibitem[Wang and Deng(2018)]{wang2018deep}
M.~Wang and W.~Deng.
\newblock Deep visual domain adaptation: A survey.
\newblock \emph{Neurocomputing}, 312:\penalty0 135--153, 2018.

\bibitem[Wang et~al.(2020)Wang, Yao, Kwok, and Ni]{wang2020generalizing}
Y.~Wang, Q.~Yao, J.~T. Kwok, and L.~M. Ni.
\newblock Generalizing from a few examples: A survey on few-shot learning.
\newblock \emph{ACM computing surveys (csur)}, 53\penalty0 (3):\penalty0 1--34, 2020.

\bibitem[Wanyan et~al.(2023)Wanyan, Seneviratne, Shen, and Kirley]{wanyan2023dino}
X.~Wanyan, S.~Seneviratne, S.~Shen, and M.~Kirley.
\newblock Dino-mc: Self-supervised contrastive learning for remote sensing imagery with multi-sized local crops.
\newblock \emph{arXiv preprint arXiv:2303.06670}, 2023.

\bibitem[Weber et~al.(2022)Weber, Lapuschkin, Binder, and Samek]{weber2022beyond}
L.~Weber, S.~Lapuschkin, A.~Binder, and W.~Samek.
\newblock Beyond explaining: Opportunities and challenges of xai-based model improvement.
\newblock \emph{Information Fusion}, 2022.

\bibitem[Wu et~al.(2018)Wu, Hughes, Parbhoo, Zazzi, Roth, and Doshi-Velez]{wu2018beyond}
M.~Wu, M.~Hughes, S.~Parbhoo, M.~Zazzi, V.~Roth, and F.~Doshi-Velez.
\newblock Beyond sparsity: Tree regularization of deep models for interpretability.
\newblock In \emph{Proceedings of the AAAI conference on artificial intelligence}, volume~32, 2018.

\bibitem[Xian et~al.(2018)Xian, Lampert, Schiele, and Akata]{xian2018zero}
Y.~Xian, C.~H. Lampert, B.~Schiele, and Z.~Akata.
\newblock Zero-shot learningâ€”a comprehensive evaluation of the good, the bad and the ugly.
\newblock \emph{IEEE transactions on pattern analysis and machine intelligence}, 41\penalty0 (9):\penalty0 2251--2265, 2018.

\bibitem[Xue et~al.(2022)Xue, Huang, Zhang, Cheng, Song, Wu, and Song]{xue2022protopformer}
M.~Xue, Q.~Huang, H.~Zhang, L.~Cheng, J.~Song, M.~Wu, and M.~Song.
\newblock Protopformer: Concentrating on prototypical parts in vision transformers for interpretable image recognition.
\newblock \emph{arXiv preprint arXiv:2208.10431}, 2022.

\bibitem[Yang et~al.(2023)Yang, Huang, Guo, Lin, and Zhao]{yang2023small}
L.~Yang, B.~Huang, S.~Guo, Y.~Lin, and T.~Zhao.
\newblock A small-sample text classification model based on pseudo-label fusion clustering algorithm.
\newblock \emph{Applied Sciences}, 13\penalty0 (8):\penalty0 4716, 2023.

\bibitem[Zhang et~al.(2021{\natexlab{a}})Zhang, Madumal, Miller, Ehinger, and Rubinstein]{zhang2021invertible}
R.~Zhang, P.~Madumal, T.~Miller, K.~A. Ehinger, and B.~I. Rubinstein.
\newblock Invertible concept-based explanations for cnn models with non-negative concept activation vectors.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~35, pages 11682--11690, 2021{\natexlab{a}}.

\bibitem[Zhang et~al.(2021{\natexlab{b}})Zhang, Ti{\v{n}}o, Leonardis, and Tang]{zhang2021survey}
Y.~Zhang, P.~Ti{\v{n}}o, A.~Leonardis, and K.~Tang.
\newblock A survey on neural network interpretability.
\newblock \emph{IEEE Transactions on Emerging Topics in Computational Intelligence}, 5\penalty0 (5):\penalty0 726--742, 2021{\natexlab{b}}.

\end{thebibliography}
