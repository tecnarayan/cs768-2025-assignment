\begin{thebibliography}{106}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alba \& Tomassini(2002)Alba and Tomassini]{alba2002parallelism}
Alba, E. and Tomassini, M.
\newblock Parallelism and evolutionary algorithms.
\newblock \emph{IEEE transactions on evolutionary computation}, 2002.

\bibitem[Alet et~al.(2019)Alet, Schneider, Lozano-Perez, and
  Kaelbling]{alet2019meta}
Alet, F., Schneider, M.~F., Lozano-Perez, T., and Kaelbling, L.~P.
\newblock Meta-learning curiosity algorithms.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Andrychowicz et~al.(2016)Andrychowicz, Denil, Gomez, Hoffman, Pfau,
  Schaul, and de~Freitas]{andrychowicz2016learning}
Andrychowicz, M., Denil, M., Gomez, S., Hoffman, M.~W., Pfau, D., Schaul, T.,
  and de~Freitas, N.
\newblock Learning to learn by gradient descent by gradient descent.
\newblock In \emph{NIPS}, 2016.

\bibitem[Angeline et~al.(1994)Angeline, Saunders, and
  Pollack]{angeline1994evolutionary}
Angeline, P.~J., Saunders, G.~M., and Pollack, J.~B.
\newblock An evolutionary algorithm that constructs recurrent neural networks.
\newblock \emph{IEEE transactions on Neural Networks}, 1994.

\bibitem[Baker et~al.(2017)Baker, Gupta, Naik, and Raskar]{baker2016designing}
Baker, B., Gupta, O., Naik, N., and Raskar, R.
\newblock Designing neural network architectures using reinforcement learning.
\newblock In \emph{ICLR}, 2017.

\bibitem[Balog et~al.(2017)Balog, Gaunt, Brockschmidt, Nowozin, and
  Tarlow]{balog2017deepcoder}
Balog, M., Gaunt, A.~L., Brockschmidt, M., Nowozin, S., and Tarlow, D.
\newblock Deepcoder: Learning to write programs.
\newblock \emph{ICLR}, 2017.

\bibitem[Bello et~al.(2017)Bello, Zoph, Vasudevan, and Le]{bello2017neural}
Bello, I., Zoph, B., Vasudevan, V., and Le, Q.~V.
\newblock Neural optimizer search with reinforcement learning.
\newblock \emph{ICML}, 2017.

\bibitem[Bengio et~al.(1994)Bengio, Bengio, and Cloutier]{bengio1994use}
Bengio, S., Bengio, Y., and Cloutier, J.
\newblock Use of genetic programming for the search of a new learning rule for
  neural networks.
\newblock In \emph{Evolutionary Computation}, 1994.

\bibitem[Bengio(2012)]{bengio2012practical}
Bengio, Y.
\newblock Practical recommendations for gradient-based training of deep
  architectures.
\newblock In \emph{Neural networks: Tricks of the trade}. Springer, 2012.

\bibitem[Bengio et~al.(2013)Bengio, L{\'e}onard, and
  Courville]{bengio2013estimating}
Bengio, Y., L{\'e}onard, N., and Courville, A.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock \emph{arXiv preprint}, 2013.

\bibitem[Bergstra \& Bengio(2012)Bergstra and Bengio]{bergstra2012random}
Bergstra, J. and Bengio, Y.
\newblock Random search for hyper-parameter optimization.
\newblock \emph{JMLR}, 2012.

\bibitem[Cai et~al.(2019)Cai, Zhu, and Han]{cai2018proxylessnas}
Cai, H., Zhu, L., and Han, S.
\newblock Proxylessnas: Direct neural architecture search on target task and
  hardware.
\newblock \emph{ICLR}, 2019.

\bibitem[Chalmers(1991)]{chalmers1991evolution}
Chalmers, D.~J.
\newblock The evolution of learning: An experiment in genetic connectionism.
\newblock In \emph{Connectionist Models}. Elsevier, 1991.

\bibitem[Chen et~al.(2017)Chen, Liu, and Song]{chen2017towards}
Chen, X., Liu, C., and Song, D.
\newblock Towards synthesizing complex programs from input-output examples.
\newblock \emph{arXiv preprint arXiv:1706.01284}, 2017.

\bibitem[Chrabaszcz et~al.(2017)Chrabaszcz, Loshchilov, and
  Hutter]{chrabaszcz2017downsampled}
Chrabaszcz, P., Loshchilov, I., and Hutter, F.
\newblock A downsampled variant of imagenet as an alternative to the cifar
  datasets.
\newblock \emph{arXiv preprint arXiv:1707.08819}, 2017.

\bibitem[Collins(2002)]{collins2002discriminative}
Collins, M.
\newblock Discriminative training methods for hidden markov models: Theory and
  experiments with perceptron algorithms.
\newblock In \emph{Proceedings of the ACL-02 conference on Empirical methods in
  natural language processing-Volume 10}, pp.\  1--8. Association for
  Computational Linguistics, 2002.

\bibitem[Cubuk et~al.(2019{\natexlab{a}})Cubuk, Zoph, Mane, Vasudevan, and
  Le]{cubuk2018autoaugment}
Cubuk, E.~D., Zoph, B., Mane, D., Vasudevan, V., and Le, Q.~V.
\newblock Autoaugment: Learning augmentation policies from data.
\newblock \emph{CVPR}, 2019{\natexlab{a}}.

\bibitem[Cubuk et~al.(2019{\natexlab{b}})Cubuk, Zoph, Shlens, and
  Le]{cubuk2019randaugment}
Cubuk, E.~D., Zoph, B., Shlens, J., and Le, Q.~V.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock \emph{arXiv preprint arXiv:1909.13719}, 2019{\natexlab{b}}.

\bibitem[Devlin et~al.(2017)Devlin, Uesato, Bhupatiraju, Singh, rahman Mohamed,
  and Kohli]{Devlin2017RobustFillNP}
Devlin, J., Uesato, J., Bhupatiraju, S., Singh, R., rahman Mohamed, A., and
  Kohli, P.
\newblock Robustfill: Neural program learning under noisy i/o.
\newblock In \emph{ICML}, 2017.

\bibitem[Elsken et~al.(2019{\natexlab{a}})Elsken, Metzen, and
  Hutter]{elsken2018efficient}
Elsken, T., Metzen, J.~H., and Hutter, F.
\newblock Efficient multi-objective neural architecture search via lamarckian
  evolution.
\newblock In \emph{ICLR}, 2019{\natexlab{a}}.

\bibitem[Elsken et~al.(2019{\natexlab{b}})Elsken, Metzen, and
  Hutter]{elsken2019neural}
Elsken, T., Metzen, J.~H., and Hutter, F.
\newblock Neural architecture search.
\newblock In \emph{Automated Machine Learning}. Springer, 2019{\natexlab{b}}.

\bibitem[Fahlman \& Lebiere(1990)Fahlman and Lebiere]{fahlman1990cascade}
Fahlman, S.~E. and Lebiere, C.
\newblock The cascade-correlation learning architecture.
\newblock In \emph{NIPS}, 1990.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
Finn, C., Abbeel, P., and Levine, S.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{ICML}, 2017.

\bibitem[Forsyth et~al.(1981)]{forsyth1981beagle}
Forsyth, R. et~al.
\newblock Beagle-a darwinian approach to pattern recognition.
\newblock \emph{Kybernetes}, 10\penalty0 (3):\penalty0 159--166, 1981.

\bibitem[Gaier \& Ha(2019)Gaier and Ha]{gaier2019weight}
Gaier, A. and Ha, D.
\newblock Weight agnostic neural networks.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Ghiasi et~al.(2019)Ghiasi, Lin, and Le]{ghiasi2019fpn}
Ghiasi, G., Lin, T.-Y., and Le, Q.~V.
\newblock Nas-fpn: Learning scalable feature pyramid architecture for object
  detection.
\newblock In \emph{CVPR}, 2019.

\bibitem[Goldberg \& Deb(1991)Goldberg and Deb]{goldberg1991comparative}
Goldberg, D.~E. and Deb, K.
\newblock A comparative analysis of selection schemes used in genetic
  algorithms.
\newblock \emph{FOGA}, 1991.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, and
  Courville]{goodfellow2016deep}
Goodfellow, I., Bengio, Y., and Courville, A.
\newblock \emph{Deep learning}.
\newblock MIT press, 2016.

\bibitem[Graves et~al.(2014)Graves, Wayne, and Danihelka]{graves2014neural}
Graves, A., Wayne, G., and Danihelka, I.
\newblock Neural turing machines.
\newblock \emph{arXiv preprint arXiv:1410.5401}, 2014.

\bibitem[Gulwani et~al.(2017)Gulwani, Polozov, Singh,
  et~al.]{gulwani2017program}
Gulwani, S., Polozov, O., Singh, R., et~al.
\newblock Program synthesis.
\newblock \emph{Foundations and Trends{\textregistered} in Programming
  Languages}, 2017.

\bibitem[Hazan et~al.(2015)Hazan, Levy, and Shalev-Shwartz]{hazan2015beyond}
Hazan, E., Levy, K., and Shalev-Shwartz, S.
\newblock Beyond convexity: Stochastic quasi-convex optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1594--1602, 2015.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{he2015delving}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Delving deep into rectifiers: Surpassing human-level performance on
  imagenet classification.
\newblock In \emph{ICCV}, 2015.

\bibitem[Hochreiter \& Schmidhuber(1997)Hochreiter and
  Schmidhuber]{hochreiter1997long}
Hochreiter, S. and Schmidhuber, J.
\newblock Long short-term memory.
\newblock \emph{Neural Computation}, 1997.

\bibitem[Holland(1975)]{holland1975adaptation}
Holland, J.
\newblock Adaptation in natural and artificial systems: an introductory
  analysis with application to biology.
\newblock \emph{Control and artificial intelligence}, 1975.

\bibitem[Hutter et~al.(2011)Hutter, Hoos, and
  Leyton-Brown]{hutter2011sequential}
Hutter, F., Hoos, H.~H., and Leyton-Brown, K.
\newblock Sequential model-based optimization for general algorithm
  configuration.
\newblock In \emph{LION}, 2011.

\bibitem[Jaderberg et~al.(2017)Jaderberg, Dalibard, Osindero, Czarnecki,
  Donahue, Razavi, Vinyals, Green, Dunning, Simonyan,
  et~al.]{jaderberg2017population}
Jaderberg, M., Dalibard, V., Osindero, S., Czarnecki, W.~M., Donahue, J.,
  Razavi, A., Vinyals, O., Green, T., Dunning, I., Simonyan, K., et~al.
\newblock Population based training of neural networks.
\newblock \emph{arXiv}, 2017.

\bibitem[Jayakumar et~al.(2020)Jayakumar, Menick, Czarnecki, Schwarz, Rae,
  Osindero, Teh, Harley, and Pascanu]{jayakumar2020multiplicative}
Jayakumar, S.~M., Menick, J., Czarnecki, W.~M., Schwarz, J., Rae, J., Osindero,
  S., Teh, Y.~W., Harley, T., and Pascanu, R.
\newblock Multiplicative interactions and where to find them.
\newblock In \emph{ICLR}, 2020.

\bibitem[Kim \& Rigazio(2015)Kim and Rigazio]{kim2015deep}
Kim, M. and Rigazio, L.
\newblock Deep clustered convolutional kernels.
\newblock \emph{arXiv}, 2015.

\bibitem[Koza \& Koza(1992)Koza and Koza]{koza1992genetic}
Koza, J.~R. and Koza, J.~R.
\newblock \emph{Genetic programming: on the programming of computers by means
  of natural selection}.
\newblock MIT press, 1992.

\bibitem[Krizhevsky \& Hinton(2009)Krizhevsky and
  Hinton]{krizhevsky2009learning}
Krizhevsky, A. and Hinton, G.
\newblock Learning multiple layers of features from tiny images.
\newblock \emph{Master's thesis, Dept. of Computer Science, U. of Toronto},
  2009.

\bibitem[Lake et~al.(2015)Lake, Salakhutdinov, and Tenenbaum]{lake2015human}
Lake, B.~M., Salakhutdinov, R., and Tenenbaum, J.~B.
\newblock Human-level concept learning through probabilistic program induction.
\newblock \emph{Science}, 350\penalty0 (6266):\penalty0 1332--1338, 2015.

\bibitem[LeCun et~al.(1995)LeCun, Bengio, et~al.]{lecun1995convolutional}
LeCun, Y., Bengio, Y., et~al.
\newblock Convolutional networks for images, speech, and time series.
\newblock \emph{The handbook of brain theory and neural networks}, 1995.

\bibitem[LeCun et~al.(1998)LeCun, Cortes, and Burges]{lecun1998mnist}
LeCun, Y., Cortes, C., and Burges, C.~J.
\newblock The mnist database of handwritten digits, 1998.

\bibitem[Lenat(1983)]{lenat1983eurisko}
Lenat, D.~B.
\newblock Eurisko: a program that learns new heuristics and domain concepts:
  the nature of heuristics iii: program design and results.
\newblock \emph{Artificial intelligence}, 21\penalty0 (1-2):\penalty0 61--98,
  1983.

\bibitem[Levy(2016)]{levy2016power}
Levy, K.~Y.
\newblock The power of normalization: Faster evasion of saddle points.
\newblock \emph{arXiv preprint arXiv:1611.04831}, 2016.

\bibitem[Li \& Malik(2017)Li and Malik]{li2017learning}
Li, K. and Malik, J.
\newblock Learning to optimize.
\newblock \emph{ICLR}, 2017.

\bibitem[Li \& Talwalkar(2019)Li and Talwalkar]{li2019RS}
Li, L. and Talwalkar, A.
\newblock Random search and reproducibility for neural architecture search.
\newblock \emph{CoRR}, abs/1902.07638, 2019.
\newblock URL \url{http://arxiv.org/abs/1902.07638}.

\bibitem[Li et~al.(2018)Li, Jamieson, DeSalvo, Rostamizadeh, and
  Talwalkar]{li2017hyperband}
Li, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A., and Talwalkar, A.
\newblock Hyperband: A novel bandit-based approach to hyperparameter
  optimization.
\newblock \emph{JMLR}, 2018.

\bibitem[Liang et~al.(2016)Liang, Berant, Le, Forbus, and
  Lao]{Liang2016NeuralSM}
Liang, C., Berant, J., Le, Q.~V., Forbus, K.~D., and Lao, N.
\newblock Neural symbolic machines: Learning semantic parsers on freebase with
  weak supervision.
\newblock In \emph{ACL}, 2016.

\bibitem[Liang et~al.(2018)Liang, Norouzi, Berant, Le, and
  Lao]{Liang2018MemoryAP}
Liang, C., Norouzi, M., Berant, J., Le, Q.~V., and Lao, N.
\newblock Memory augmented policy optimization for program synthesis and
  semantic parsing.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Liu et~al.(2018)Liu, Zoph, Shlens, Hua, Li, Fei-Fei, Yuille, Huang,
  and Murphy]{liu2017progressive}
Liu, C., Zoph, B., Shlens, J., Hua, W., Li, L.-J., Fei-Fei, L., Yuille, A.,
  Huang, J., and Murphy, K.
\newblock Progressive neural architecture search.
\newblock \emph{ECCV}, 2018.

\bibitem[Liu et~al.(2019{\natexlab{a}})Liu, Chen, Schroff, Adam, Hua, Yuille,
  and Fei-Fei]{liu2019auto}
Liu, C., Chen, L.-C., Schroff, F., Adam, H., Hua, W., Yuille, A.~L., and
  Fei-Fei, L.
\newblock Auto-deeplab: Hierarchical neural architecture search for semantic
  image segmentation.
\newblock In \emph{CVPR}, 2019{\natexlab{a}}.

\bibitem[Liu et~al.(2019{\natexlab{b}})Liu, Simonyan, and Yang]{liu2018darts}
Liu, H., Simonyan, K., and Yang, Y.
\newblock Darts: Differentiable architecture search.
\newblock \emph{ICLR}, 2019{\natexlab{b}}.

\bibitem[Loshchilov \& Hutter(2016)Loshchilov and Hutter]{loshchilov2016cma}
Loshchilov, I. and Hutter, F.
\newblock Cma-es for hyperparameter optimization of deep neural networks.
\newblock \emph{arXiv preprint arXiv:1604.07269}, 2016.

\bibitem[Mei et~al.(2020)Mei, Li, Lian, Jin, Yang, Yuille, and
  Yang]{mei2019atomnas}
Mei, J., Li, Y., Lian, X., Jin, X., Yang, L., Yuille, A., and Yang, J.
\newblock Atomnas: Fine-grained end-to-end neural architecture search.
\newblock \emph{ICLR}, 2020.

\bibitem[Mendoza et~al.(2016)Mendoza, Klein, Feurer, Springenberg, and
  Hutter]{mendoza2016towards}
Mendoza, H., Klein, A., Feurer, M., Springenberg, J.~T., and Hutter, F.
\newblock Towards automatically-tuned neural networks.
\newblock In \emph{Workshop on Automatic Machine Learning}, 2016.

\bibitem[Metz et~al.(2019)Metz, Maheswaranathan, Cheung, and
  Sohl-Dickstein]{metz2019meta}
Metz, L., Maheswaranathan, N., Cheung, B., and Sohl-Dickstein, J.
\newblock Meta-learning update rules for unsupervised representation learning.
\newblock In \emph{ICLR}, 2019.

\bibitem[Miikkulainen et~al.(2019)Miikkulainen, Liang, Meyerson, Rawal, Fink,
  Francon, Raju, Shahrzad, Navruzyan, Duffy, et~al.]{miikkulainen2019evolving}
Miikkulainen, R., Liang, J., Meyerson, E., Rawal, A., Fink, D., Francon, O.,
  Raju, B., Shahrzad, H., Navruzyan, A., Duffy, N., et~al.
\newblock Evolving deep neural networks.
\newblock In \emph{Artificial Intelligence in the Age of Neural Networks and
  Brain Computing}. Elsevier, 2019.

\bibitem[Nair \& Hinton(2010)Nair and Hinton]{nair2010rectified}
Nair, V. and Hinton, G.~E.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In \emph{ICML}, 2010.

\bibitem[Neelakantan et~al.(2015)Neelakantan, Le, and
  Sutskever]{Neelakantan2015NeuralPI}
Neelakantan, A., Le, Q.~V., and Sutskever, I.
\newblock Neural programmer: Inducing latent programs with gradient descent.
\newblock \emph{CoRR}, abs/1511.04834, 2015.

\bibitem[Negrinho et~al.(2019)Negrinho, Gormley, Gordon, Patil, Le, and
  Ferreira]{negrinho2019towards}
Negrinho, R., Gormley, M., Gordon, G.~J., Patil, D., Le, N., and Ferreira, D.
\newblock Towards modular and programmable architecture search.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and
  Ng]{netzer2011reading}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock 2011.

\bibitem[Noy et~al.(2019)Noy, Nayman, Ridnik, Zamir, Doveh, Friedman, Giryes,
  and Zelnik-Manor]{noy2019asap}
Noy, A., Nayman, N., Ridnik, T., Zamir, N., Doveh, S., Friedman, I., Giryes,
  R., and Zelnik-Manor, L.
\newblock Asap: Architecture search, anneal and prune.
\newblock \emph{arXiv}, 2019.

\bibitem[Orchard \& Wang(2016)Orchard and Wang]{orchard2016evolution}
Orchard, J. and Wang, L.
\newblock The evolution of a generalized neural learning rule.
\newblock In \emph{IJCNN}, 2016.

\bibitem[Parisotto et~al.(2016)Parisotto, rahman Mohamed, Singh, Li, Zhou, and
  Kohli]{Parisotto2016NeuroSymbolicPS}
Parisotto, E., rahman Mohamed, A., Singh, R., Li, L., Zhou, D., and Kohli, P.
\newblock Neuro-symbolic program synthesis.
\newblock \emph{ArXiv}, abs/1611.01855, 2016.

\bibitem[Park et~al.(2019)Park, Chan, Zhang, Chiu, Zoph, Cubuk, and
  Le]{park2019specaugment}
Park, D.~S., Chan, W., Zhang, Y., Chiu, C.-C., Zoph, B., Cubuk, E.~D., and Le,
  Q.~V.
\newblock Specaugment: A simple data augmentation method for automatic speech
  recognition.
\newblock \emph{Proc. Interspeech}, 2019.

\bibitem[Pitrat(1996)]{pitrat1996implementation}
Pitrat, J.
\newblock Implementation of a reflective system.
\newblock \emph{Future Generation Computer Systems}, 12\penalty0
  (2-3):\penalty0 235--242, 1996.

\bibitem[Polozov \& Gulwani(2015)Polozov and Gulwani]{Polozov2015FlashMetaAF}
Polozov, O. and Gulwani, S.
\newblock Flashmeta: a framework for inductive program synthesis.
\newblock In \emph{OOPSLA 2015}, 2015.

\bibitem[Polyak \& Juditsky(1992)Polyak and Juditsky]{polyak1992acceleration}
Polyak, B.~T. and Juditsky, A.~B.
\newblock Acceleration of stochastic approximation by averaging.
\newblock \emph{SIAM journal on control and optimization}, 30\penalty0
  (4):\penalty0 838--855, 1992.

\bibitem[Ramachandran et~al.(2017)Ramachandran, Zoph, and
  Le]{ramachandran2017searching}
Ramachandran, P., Zoph, B., and Le, Q.
\newblock Searching for activation functions.
\newblock \emph{ICLR Workshop}, 2017.

\bibitem[Ravi \& Larochelle(2017)Ravi and Larochelle]{ravi2016optimization}
Ravi, S. and Larochelle, H.
\newblock Optimization as a model for few-shot learning.
\newblock \emph{ICLR}, 2017.

\bibitem[Real et~al.(2017)Real, Moore, Selle, Saxena, Suematsu, Le, and
  Kurakin]{real2017large}
Real, E., Moore, S., Selle, A., Saxena, S., Suematsu, Y.~L., Le, Q., and
  Kurakin, A.
\newblock Large-scale evolution of image classifiers.
\newblock In \emph{ICML}, 2017.

\bibitem[Real et~al.(2019)Real, Aggarwal, Huang, and Le]{real2018regularized}
Real, E., Aggarwal, A., Huang, Y., and Le, Q.~V.
\newblock Regularized evolution for image classifier architecture search.
\newblock \emph{AAAI}, 2019.

\bibitem[Reed \& de~Freitas(2015)Reed and de~Freitas]{Reed2015NeuralP}
Reed, S.~E. and de~Freitas, N.
\newblock Neural programmer-interpreters.
\newblock \emph{CoRR}, abs/1511.06279, 2015.

\bibitem[Risi \& Stanley(2010)Risi and Stanley]{risi2010indirectly}
Risi, S. and Stanley, K.~O.
\newblock Indirectly encoding neural plasticity as a pattern of local rules.
\newblock In \emph{International Conference on Simulation of Adaptive
  Behavior}, 2010.

\bibitem[Rumelhart et~al.(1986)Rumelhart, Hinton, and
  Williams]{rumelhart1986learning}
Rumelhart, D.~E., Hinton, G.~E., and Williams, R.~J.
\newblock Learning representations by back-propagating errors.
\newblock \emph{Nature}, 1986.

\bibitem[Runarsson \& Jonsson(2000)Runarsson and
  Jonsson]{runarsson2000evolution}
Runarsson, T.~P. and Jonsson, M.~T.
\newblock Evolution and design of distributed learning rules.
\newblock In \emph{ECNN}, 2000.

\bibitem[Schmidhuber(1987)]{schmidhuber1987evolutionary}
Schmidhuber, J.
\newblock \emph{Evolutionary principles in self-referential learning, or on
  learning how to learn: the meta-meta-... hook}.
\newblock PhD thesis, Technische Universit{\"a}t M{\"u}nchen, 1987.

\bibitem[Schmidhuber(2004)]{schmidhuber2004optimal}
Schmidhuber, J.
\newblock Optimal ordered problem solver.
\newblock \emph{Machine Learning}, 54\penalty0 (3):\penalty0 211--254, 2004.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, Van
  Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot,
  et~al.]{silver2016mastering}
Silver, D., Huang, A., Maddison, C.~J., Guez, A., Sifre, L., Van Den~Driessche,
  G., Schrittwieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M.,
  et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock \emph{Nature}, 2016.

\bibitem[Silver et~al.(2017)Silver, Schrittwieser, Simonyan, Antonoglou, Huang,
  Guez, Hubert, Baker, Lai, Bolton, et~al.]{silver2017mastering}
Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez,
  A., Hubert, T., Baker, L., Lai, M., Bolton, A., et~al.
\newblock Mastering the game of go without human knowledge.
\newblock \emph{Nature}, 2017.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{snoek2012practical}
Snoek, J., Larochelle, H., and Adams, R.~P.
\newblock Practical bayesian optimization of machine learning algorithms.
\newblock In \emph{NIPS}, 2012.

\bibitem[So et~al.(2019)So, Liang, and Le]{So2019TheET}
So, D.~R., Liang, C., and Le, Q.~V.
\newblock The evolved transformer.
\newblock In \emph{ICML}, 2019.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{srivastava2014dropout}
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov,
  R.
\newblock Dropout: A simple way to prevent neural networks from overfitting.
\newblock \emph{JMLR}, 2014.

\bibitem[Stanley \& Miikkulainen(2002)Stanley and
  Miikkulainen]{stanley2002evolving}
Stanley, K.~O. and Miikkulainen, R.
\newblock Evolving neural networks through augmenting topologies.
\newblock \emph{Evol.\ Comput.}, 2002.

\bibitem[Stanley et~al.(2019)Stanley, Clune, Lehman, and
  Miikkulainen]{stanley2019designing}
Stanley, K.~O., Clune, J., Lehman, J., and Miikkulainen, R.
\newblock Designing neural networks through neuroevolution.
\newblock \emph{Nature Machine Intelligence}, 2019.

\bibitem[Suganuma et~al.(2017)Suganuma, Shirakawa, and
  Nagao]{suganuma2017genetic}
Suganuma, M., Shirakawa, S., and Nagao, T.
\newblock A genetic programming approach to designing convolutional neural
  network architectures.
\newblock In \emph{GECCO}, 2017.

\bibitem[Sun et~al.(2019)Sun, Xue, Zhang, and Yen]{sun2019evolving}
Sun, Y., Xue, B., Zhang, M., and Yen, G.~G.
\newblock Evolving deep convolutional neural networks for image classification.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 2019.

\bibitem[Tan et~al.(2019)Tan, Chen, Pang, Vasudevan, Sandler, Howard, and
  Le]{tan2019mnasnet}
Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le,
  Q.~V.
\newblock Mnasnet: Platform-aware neural architecture search for mobile.
\newblock In \emph{CVPR}, 2019.

\bibitem[Valkov et~al.(2018)Valkov, Chaudhari, Srivastava, Sutton, and
  Chaudhuri]{Valkov2018HOUDINILL}
Valkov, L., Chaudhari, D., Srivastava, A., Sutton, C.~A., and Chaudhuri, S.
\newblock Houdini: Lifelong learning as program synthesis.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Vanschoren(2019)]{vanschoren2018meta}
Vanschoren, J.
\newblock Meta-learning.
\newblock \emph{Automated Machine Learning}, 2019.

\bibitem[Wang et~al.(2019)Wang, Lehman, Clune, and Stanley]{wang2019paired}
Wang, R., Lehman, J., Clune, J., and Stanley, K.~O.
\newblock Paired open-ended trailblazer (poet): Endlessly generating
  increasingly complex and diverse learning environments and their solutions.
\newblock \emph{GECCO}, 2019.

\bibitem[Wichrowska et~al.(2017)Wichrowska, Maheswaranathan, Hoffman,
  Colmenarejo, Denil, de~Freitas, and Sohl-Dickstein]{wichrowska2017learned}
Wichrowska, O., Maheswaranathan, N., Hoffman, M.~W., Colmenarejo, S.~G., Denil,
  M., de~Freitas, N., and Sohl-Dickstein, J.
\newblock Learned optimizers that scale and generalize.
\newblock \emph{ICML}, 2017.

\bibitem[Wilson et~al.(2018)Wilson, Cussat-Blanc, Luga, and
  Miller]{wilson2018evolving}
Wilson, D.~G., Cussat-Blanc, S., Luga, H., and Miller, J.~F.
\newblock Evolving simple programs for playing atari games.
\newblock In \emph{Proceedings of the Genetic and Evolutionary Computation
  Conference}, pp.\  229--236, 2018.

\bibitem[Wu et~al.(2016)Wu, Schuster, Chen, Le, Norouzi, et~al.]{wu2016google}
Wu, Y., Schuster, M., Chen, Z., Le, Q.~V., Norouzi, M., et~al.
\newblock Google's neural machine translation system: Bridging the gap between
  human and machine translation.
\newblock \emph{arXiv}, 2016.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017fashion}
Xiao, H., Rasul, K., and Vollgraf, R.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock \emph{arXiv preprint arXiv:1708.07747}, 2017.

\bibitem[Xie \& Yuille(2017)Xie and Yuille]{xie2017genetic}
Xie, L. and Yuille, A.
\newblock Genetic {CNN}.
\newblock In \emph{ICCV}, 2017.

\bibitem[Xie et~al.(2019)Xie, Kirillov, Girshick, and He]{xie2019exploring}
Xie, S., Kirillov, A., Girshick, R., and He, K.
\newblock Exploring randomly wired neural networks for image recognition.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  1284--1293, 2019.

\bibitem[Yang et~al.(2020)Yang, Esperan{\c{c}}a, and
  Carlucci]{yang2019evaluation}
Yang, A., Esperan{\c{c}}a, P.~M., and Carlucci, F.~M.
\newblock Nas evaluation is frustratingly hard.
\newblock \emph{ICLR}, 2020.

\bibitem[Yao et~al.(2018)Yao, Wang, Chen, Dai, Yi-Qi, Yu-Feng, Wei-Wei, Qiang,
  and Yang]{yao2018taking}
Yao, Q., Wang, M., Chen, Y., Dai, W., Yi-Qi, H., Yu-Feng, L., Wei-Wei, T.,
  Qiang, Y., and Yang, Y.
\newblock Taking human out of learning applications: A survey on automated
  machine learning.
\newblock \emph{arXiv}, 2018.

\bibitem[Yao(1999)]{yao1999evolving}
Yao, X.
\newblock Evolving artificial neural networks.
\newblock \emph{IEEE}, 1999.

\bibitem[Ying et~al.(2019)Ying, Klein, Real, Christiansen, Murphy, and
  Hutter]{ying2019bench}
Ying, C., Klein, A., Real, E., Christiansen, E., Murphy, K., and Hutter, F.
\newblock Nas-bench-101: Towards reproducible neural architecture search.
\newblock \emph{ICML}, 2019.

\bibitem[Zela et~al.(2018)Zela, Klein, Falkner, and Hutter]{zela2018towards}
Zela, A., Klein, A., Falkner, S., and Hutter, F.
\newblock Towards automated deep learning: Efficient joint neural architecture
  and hyperparameter search.
\newblock \emph{ICML AutoML Workshop}, 2018.

\bibitem[Zhong et~al.(2018)Zhong, Yan, Wu, Shao, and Liu]{zhong2018practical}
Zhong, Z., Yan, J., Wu, W., Shao, J., and Liu, C.-L.
\newblock Practical block-wise neural network architecture generation.
\newblock In \emph{CVPR}, 2018.

\bibitem[Zoph \& Le(2016)Zoph and Le]{zoph2016neural}
Zoph, B. and Le, Q.~V.
\newblock Neural architecture search with reinforcement learning.
\newblock In \emph{ICLR}, 2016.

\bibitem[Zoph et~al.(2018)Zoph, Vasudevan, Shlens, and Le]{zoph2017learning}
Zoph, B., Vasudevan, V., Shlens, J., and Le, Q.~V.
\newblock Learning transferable architectures for scalable image recognition.
\newblock In \emph{CVPR}, 2018.

\end{thebibliography}
