\begin{thebibliography}{26}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Balcan et~al.(2012)Balcan, Blum, Fine, and
  Mansour]{balcan2012distributed}
Balcan, M.~F., Blum, A., Fine, S., and Mansour, Y.
\newblock Distributed learning, communication complexity and privacy.
\newblock In \emph{Conference on Learning Theory}, pp.\  26.1--26.22. JMLR
  Workshop and Conference Proceedings, 2012.

\bibitem[Blum et~al.(2021)Blum, Heinecke, and Reyzin]{blum2021communication}
Blum, A., Heinecke, S., and Reyzin, L.
\newblock Communication-aware collaborative learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, 2021.

\bibitem[Braverman et~al.(2019)Braverman, Kol, Moran, and
  Saxena]{braverman2019convex}
Braverman, M., Kol, G., Moran, S., and Saxena, R.~R.
\newblock Convex set disjointness, distributed learning of halfspaces, and lp
  feasibility.
\newblock \emph{arXiv preprint arXiv:1909.03547}, 2019.

\bibitem[Bshouty(1997)]{bshouty1997exact}
Bshouty, N.~H.
\newblock Exact learning of formulas in parallel.
\newblock \emph{Machine Learning}, 26\penalty0 (1):\penalty0 25--41, 1997.

\bibitem[Bun et~al.(2019)Bun, Kamath, Steinke, and Wu]{bun2019private}
Bun, M., Kamath, G., Steinke, T., and Wu, S.~Z.
\newblock Private hypothesis selection.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 156--167, 2019.

\bibitem[Chen et~al.(2016)Chen, Balcan, and Chau]{chen2016communication}
Chen, S.-T., Balcan, M.-F., and Chau, D.~H.
\newblock Communication efficient distributed agnostic boosting.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  1299--1307.
  PMLR, 2016.

\bibitem[Collins et~al.(2002)Collins, Schapire, and
  Singer]{collins2002logistic}
Collins, M., Schapire, R.~E., and Singer, Y.
\newblock Logistic regression, adaboost and bregman distances.
\newblock \emph{Machine Learning}, 48\penalty0 (1):\penalty0 253--285, 2002.

\bibitem[Daum{\'e} et~al.(2012{\natexlab{a}})Daum{\'e}, Phillips, Saha, and
  Venkatasubramanian]{daume2012protocols}
Daum{\'e}, III, H., Phillips, J., Saha, A., and Venkatasubramanian, S.
\newblock Protocols for learning classifiers on distributed data.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  282--290.
  PMLR, 2012{\natexlab{a}}.

\bibitem[Daum{\'e} et~al.(2012{\natexlab{b}})Daum{\'e}, Phillips, Saha, and
  Venkatasubramanian]{daume2012efficient}
Daum{\'e}, III, H., Phillips, J.~M., Saha, A., and Venkatasubramanian, S.
\newblock Efficient protocols for distributed classification and optimization.
\newblock In \emph{International Conference on Algorithmic Learning Theory},
  pp.\  154--168. Springer, 2012{\natexlab{b}}.

\bibitem[Dietterich(2000)]{dietterich2000experimental}
Dietterich, T.~G.
\newblock An experimental comparison of three methods for constructing
  ensembles of decision trees: Bagging, boosting, and randomization.
\newblock \emph{Machine learning}, 40\penalty0 (2):\penalty0 139--157, 2000.

\bibitem[Freund \& Schapire(1997)Freund and Schapire]{freund1997decision}
Freund, Y. and Schapire, R.~E.
\newblock A decision-theoretic generalization of on-line learning and an
  application to boosting.
\newblock \emph{Journal of computer and system sciences}, 55\penalty0
  (1):\penalty0 119--139, 1997.

\bibitem[Impagliazzo(1995)]{impagliazzo1995hard}
Impagliazzo, R.
\newblock Hard-core distributions for somewhat hard problems.
\newblock In \emph{Proceedings of IEEE 36th Annual Foundations of Computer
  Science}, pp.\  538--545. IEEE, 1995.

\bibitem[Kale(2007)]{kale2007boosting}
Kale, S.
\newblock Boosting and hard-core set constructions: a simplified approach.
\newblock In \emph{Electronic Colloquium on Computational Complexity (ECCC)},
  volume~14, pp.\  131. Citeseer, 2007.

\bibitem[Kalyanasundaram \& Schintger(1992)Kalyanasundaram and
  Schintger]{kalyanasundaram1992probabilistic}
Kalyanasundaram, B. and Schintger, G.
\newblock The probabilistic communication complexity of set intersection.
\newblock \emph{SIAM Journal on Discrete Mathematics}, 5\penalty0 (4):\penalty0
  545--557, 1992.

\bibitem[Kane et~al.(2019)Kane, Livni, Moran, and
  Yehudayoff]{kane2019communication}
Kane, D., Livni, R., Moran, S., and Yehudayoff, A.
\newblock On communication complexity of classification problems.
\newblock In \emph{Conference on Learning Theory}, pp.\  1903--1943. PMLR,
  2019.

\bibitem[Kushilevitz \& Nisan(1996)Kushilevitz and
  Nisan]{kushilevitz_nisan_1996}
Kushilevitz, E. and Nisan, N.
\newblock \emph{Communication Complexity}.
\newblock Cambridge University Press, 1996.
\newblock \doi{10.1017/CBO9780511574948}.

\bibitem[Lazarevic \& Obradovic(2001)Lazarevic and
  Obradovic]{lazarevic2001distributed}
Lazarevic, A. and Obradovic, Z.
\newblock The distributed boosting algorithm.
\newblock In \emph{Proceedings of the seventh ACM SIGKDD international
  conference on Knowledge discovery and data mining}, pp.\  311--316, 2001.

\bibitem[Long \& Servedio(2011)Long and Servedio]{long2011algorithms}
Long, P. and Servedio, R.
\newblock Algorithms and hardness results for parallel large margin learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  24:\penalty0 1314--1322, 2011.

\bibitem[Long \& Servedio(2010)Long and Servedio]{long2010random}
Long, P.~M. and Servedio, R.~A.
\newblock Random classification noise defeats all convex potential boosters.
\newblock \emph{Machine learning}, 78\penalty0 (3):\penalty0 287--304, 2010.

\bibitem[Rao \& Yehudayoff(2020)Rao and Yehudayoff]{rao_yehudayoff_2020}
Rao, A. and Yehudayoff, A.
\newblock \emph{Communication Complexity: and Applications}.
\newblock Cambridge University Press, 2020.
\newblock \doi{10.1017/9781108671644}.

\bibitem[Razborov(1990)]{razborov1990distributional}
Razborov, A.~A.
\newblock On the distributional complexity of disjointness.
\newblock In \emph{International Colloquium on Automata, Languages, and
  Programming}, pp.\  249--253. Springer, 1990.

\bibitem[Schapire \& Freund(2013)Schapire and Freund]{schapire2013boosting}
Schapire, R.~E. and Freund, Y.
\newblock Boosting: Foundations and algorithms.
\newblock \emph{Kybernetes}, 2013.

\bibitem[Vapnik \& Chervonenkis(1971)Vapnik and Chervonenkis]{vapnik71uniform}
Vapnik, V.~N. and Chervonenkis, A.~Y.
\newblock On the uniform convergence of relative frequencies of events to their
  probabilities.
\newblock \emph{Theory of Probability and its Applications}, 16\penalty0
  (2):\penalty0 264--280, 1971.

\bibitem[Vempala et~al.(2020)Vempala, Wang, and
  Woodruff]{vempala2020communication}
Vempala, S.~S., Wang, R., and Woodruff, D.~P.
\newblock The communication complexity of optimization.
\newblock In \emph{Proceedings of the Fourteenth Annual ACM-SIAM Symposium on
  Discrete Algorithms}, pp.\  1733--1752. SIAM, 2020.

\bibitem[Yao(1979)]{yao1979some}
Yao, A. C.-C.
\newblock Some complexity questions related to distributive computing
  (preliminary report).
\newblock In \emph{Proceedings of the eleventh annual ACM symposium on Theory
  of computing}, pp.\  209--213, 1979.

\bibitem[Zinkevich et~al.(2010)Zinkevich, Weimer, Smola, and
  Li]{zinkevich2010parallelized}
Zinkevich, M., Weimer, M., Smola, A.~J., and Li, L.
\newblock Parallelized stochastic gradient descent.
\newblock In \emph{NIPS}. Citeseer, 2010.

\end{thebibliography}
