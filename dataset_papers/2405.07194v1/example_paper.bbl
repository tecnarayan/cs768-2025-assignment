\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Cai et~al.(2019)Cai, Gan, Wang, Zhang, and Han]{cai2019once}
Cai, H., Gan, C., Wang, T., Zhang, Z., and Han, S.
\newblock Once-for-all: Train one network and specialize it for efficient
  deployment.
\newblock \emph{arXiv preprint arXiv:1908.09791}, 2019.

\bibitem[Chen et~al.(2021)Chen, Peng, Fu, and Ling]{chen2021autoformer}
Chen, M., Peng, H., Fu, J., and Ling, H.
\newblock Autoformer: Searching transformers for visual recognition.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pp.\  12270--12280, 2021.

\bibitem[Clark et~al.(2019)Clark, Lee, Chang, Kwiatkowski, Collins, and
  Toutanova]{clark2019boolq}
Clark, C., Lee, K., Chang, M.-W., Kwiatkowski, T., Collins, M., and Toutanova,
  K.
\newblock Boolq: Exploring the surprising difficulty of natural yes/no
  questions.
\newblock \emph{arXiv preprint arXiv:1905.10044}, 2019.

\bibitem[Clark et~al.(2018)Clark, Cowhey, Etzioni, Khot, Sabharwal, Schoenick,
  and Tafjord]{clark2018ace}
Clark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, A., Schoenick, C., and
  Tafjord, O.
\newblock Think you have solved question answering? try arc, the ai2 reasoning
  challenge.
\newblock \emph{arXiv preprint arXiv:1803.05457}, 2018.

\bibitem[Contributors(2021)]{2021mmrazor}
Contributors, M.
\newblock Openmmlab model compression toolbox and benchmark.
\newblock \url{https://github.com/open-mmlab/mmrazor}, 2021.

\bibitem[Contributors(2022)]{mmyolo2022}
Contributors, M.
\newblock {MMYOLO: OpenMMLab YOLO} series toolbox and benchmark.
\newblock \url{https://github.com/open-mmlab/mmyolo}, 2022.

\bibitem[Contributors(2023)]{2023mmpretrain}
Contributors, M.
\newblock Openmmlab's pre-training toolbox and benchmark.
\newblock \url{https://github.com/open-mmlab/mmpretrain}, 2023.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pp.\  248--255. Ieee, 2009.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020vit}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Fang et~al.(2023)Fang, Ma, Song, Mi, and Wang]{fang2023depgraph}
Fang, G., Ma, X., Song, M., Mi, M.~B., and Wang, X.
\newblock Depgraph: Towards any structural pruning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  16091--16101, 2023.

\bibitem[Frankle \& Carbin(2018)Frankle and Carbin]{frankle2018lottery}
Frankle, J. and Carbin, M.
\newblock The lottery ticket hypothesis: Finding sparse, trainable neural
  networks.
\newblock \emph{arXiv preprint arXiv:1803.03635}, 2018.

\bibitem[Gao et~al.(2022)Gao, Huang, Zhang, and Huang]{gao2022ddnp}
Gao, S., Huang, F., Zhang, Y., and Huang, H.
\newblock Disentangled differentiable network pruning.
\newblock In \emph{European Conference on Computer Vision}, pp.\  328--345.
  Springer, 2022.

\bibitem[Guo et~al.(2021{\natexlab{a}})Guo, Liu, and Xu]{guo2021jointpruning}
Guo, J., Liu, J., and Xu, D.
\newblock Jointpruning: Pruning networks along multiple dimensions for
  efficient point cloud processing.
\newblock \emph{IEEE Transactions on Circuits and Systems for Video
  Technology}, 32\penalty0 (6):\penalty0 3659--3672, 2021{\natexlab{a}}.

\bibitem[Guo et~al.(2021{\natexlab{b}})Guo, Yuan, Tan, Wang, Yang, and
  Liu]{guo2021gdp}
Guo, Y., Yuan, H., Tan, J., Wang, Z., Yang, S., and Liu, J.
\newblock Gdp: Stabilized neural network pruning via gates with differentiable
  polarization.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  5239--5250, 2021{\natexlab{b}}.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016resnet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[He et~al.(2020)He, Ding, Liu, Zhu, Zhang, and Yang]{lfpc}
He, Y., Ding, Y., Liu, P., Zhu, L., Zhang, H., and Yang, Y.
\newblock Learning filter pruning criteria for deep convolutional neural
  networks acceleration.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  2009--2018, 2020.

\bibitem[Herrmann et~al.(2020)Herrmann, Bowen, and Zabih]{herrmann2020gumbel}
Herrmann, C., Bowen, R.~S., and Zabih, R.
\newblock Channel selection using gumbel softmax.
\newblock In \emph{European Conference on Computer Vision}, pp.\  241--257.
  Springer, 2020.

\bibitem[Humble et~al.(2022)Humble, Shen, Latorre, Darve, and
  Alvarez]{humble2022soft}
Humble, R., Shen, M., Latorre, J.~A., Darve, E., and Alvarez, J.
\newblock Soft masking for cost-constrained channel pruning.
\newblock In \emph{European Conference on Computer Vision}, pp.\  641--657.
  Springer, 2022.

\bibitem[Jocher et~al.(2023)Jocher, Chaurasia, and Qiu]{yolov8}
Jocher, G., Chaurasia, A., and Qiu, J.
\newblock {YOLO by Ultralytics}, January 2023.
\newblock URL \url{https://github.com/ultralytics/ultralytics}.

\bibitem[Lee et~al.(2018)Lee, Ajanthan, and Torr]{lee2018snip}
Lee, N., Ajanthan, T., and Torr, P.~H.
\newblock Snip: Single-shot network pruning based on connection sensitivity.
\newblock \emph{arXiv preprint arXiv:1810.02340}, 2018.

\bibitem[Li et~al.(2020)Li, Wu, Su, and Wang]{li2020eagleeye}
Li, B., Wu, B., Su, J., and Wang, G.
\newblock Eagleeye: Fast sub-net evaluation for efficient neural network
  pruning.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16}, pp.\  639--654.
  Springer, 2020.

\bibitem[Li et~al.(2023)Li, Yang, Bhardwaj, and Marculescu]{li2023zico}
Li, G., Yang, Y., Bhardwaj, K., and Marculescu, R.
\newblock Zico: Zero-shot nas via inverse coefficient of variation on
  gradients.
\newblock \emph{arXiv preprint arXiv:2301.11300}, 2023.

\bibitem[Li et~al.(2016)Li, Kadav, Durdanovic, Samet, and Graf]{li2016l1}
Li, H., Kadav, A., Durdanovic, I., Samet, H., and Graf, H.~P.
\newblock Pruning filters for efficient convnets.
\newblock \emph{arXiv preprint arXiv:1608.08710}, 2016.

\bibitem[Li et~al.()Li, Zhao, Yuan, Lin, Wang, and Chen]{lipas}
Li, Y., Zhao, P., Yuan, G., Lin, X., Wang, Y., and Chen, X.
\newblock Pruning-as-search: Efficient neural architecture search via channel
  pruning and structural reparameterization.

\bibitem[Li et~al.(2021)Li, Lin, Liu, Ye, Wang, Chao, Yang, Ma, Tian, and
  Ji]{cc}
Li, Y., Lin, S., Liu, J., Ye, Q., Wang, M., Chao, F., Yang, F., Ma, J., Tian,
  Q., and Ji, R.
\newblock Towards compact cnns via collaborative compression.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  6438--6447, 2021.

\bibitem[Lin et~al.(2021)Lin, Wang, Sun, Chen, Sun, Qian, Li, and
  Jin]{lin2021zen}
Lin, M., Wang, P., Sun, Z., Chen, H., Sun, X., Qian, Q., Li, H., and Jin, R.
\newblock Zen-nas: A zero-shot nas for high-performance image recognition.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  347--356, 2021.

\bibitem[Liu et~al.(2022)Liu, Han, Xiao, Nie, Zhang, and
  Wang]{liu2022modelamplification}
Liu, C., Han, K., Xiao, A., Nie, Y., Zhang, W., and Wang, Y.
\newblock Network amplification with efficient macs allocation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  1933--1942, 2022.

\bibitem[Liu et~al.(2018{\natexlab{a}})Liu, Simonyan, and Yang]{liu2018darts}
Liu, H., Simonyan, K., and Yang, Y.
\newblock Darts: Differentiable architecture search.
\newblock \emph{arXiv preprint arXiv:1806.09055}, 2018{\natexlab{a}}.

\bibitem[Liu et~al.(2021)Liu, Zhang, Kuang, Zhou, Xue, Wang, Chen, Yang, Liao,
  and Zhang]{liu2021group}
Liu, L., Zhang, S., Kuang, Z., Zhou, A., Xue, J.-H., Wang, X., Chen, Y., Yang,
  W., Liao, Q., and Zhang, W.
\newblock Group fisher pruning for practical network compression.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7021--7032. PMLR, 2021.

\bibitem[Liu et~al.(2018{\natexlab{b}})Liu, Sun, Zhou, Huang, and
  Darrell]{liu2018rethinking}
Liu, Z., Sun, M., Zhou, T., Huang, G., and Darrell, T.
\newblock Rethinking the value of network pruning.
\newblock \emph{arXiv preprint arXiv:1810.05270}, 2018{\natexlab{b}}.

\bibitem[Ma et~al.(2023)Ma, Fang, and Wang]{ma2023llmpruner}
Ma, X., Fang, G., and Wang, X.
\newblock Llm-pruner: On the structural pruning of large language models.
\newblock \emph{arXiv preprint arXiv:2305.11627}, 2023.

\bibitem[Marcus et~al.(1993)Marcus, Santorini, and
  Marcinkiewicz]{marcus1993ptb}
Marcus, M., Santorini, B., and Marcinkiewicz, M.~A.
\newblock Building a large annotated corpus of english: The penn treebank.
\newblock 1993.

\bibitem[Merity et~al.(2016)Merity, Xiong, Bradbury, and
  Socher]{merity2016wiki}
Merity, S., Xiong, C., Bradbury, J., and Socher, R.
\newblock Pointer sentinel mixture models.
\newblock \emph{arXiv preprint arXiv:1609.07843}, 2016.

\bibitem[Molchanov et~al.(2019)Molchanov, Mallya, Tyree, Frosio, and
  Kautz]{molchanov2019tayler}
Molchanov, P., Mallya, A., Tyree, S., Frosio, I., and Kautz, J.
\newblock Importance estimation for neural network pruning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  11264--11272, 2019.

\bibitem[Moons et~al.(2021)Moons, Noorzad, Skliar, Mariani, Mehta, Lott, and
  Blankevoort]{moons2021donna}
Moons, B., Noorzad, P., Skliar, A., Mariani, G., Mehta, D., Lott, C., and
  Blankevoort, T.
\newblock Distilling optimal neural networks: Rapid search in diverse spaces.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  12229--12238, 2021.

\bibitem[Ning et~al.(2020)Ning, Zhao, Li, Lei, Wang, and Yang]{ning2020dsa}
Ning, X., Zhao, T., Li, W., Lei, P., Wang, Y., and Yang, H.
\newblock Dsa: More efficient budgeted pruning via differentiable sparsity
  allocation.
\newblock In \emph{European Conference on Computer Vision}, pp.\  592--607.
  Springer, 2020.

\bibitem[OpenAI(2023)]{openai2023gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2023.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, Sutskever,
  et~al.]{radford2018gpt}
Radford, A., Narasimhan, K., Salimans, T., Sutskever, I., et~al.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem[Sakaguchi et~al.(2021)Sakaguchi, Bras, Bhagavatula, and
  Choi]{sakaguchi2021winogrande}
Sakaguchi, K., Bras, R.~L., Bhagavatula, C., and Choi, Y.
\newblock Winogrande: An adversarial winograd schema challenge at scale.
\newblock \emph{Communications of the ACM}, 64\penalty0 (9):\penalty0 99--106,
  2021.

\bibitem[Sandler et~al.(2018)Sandler, Howard, Zhu, Zhmoginov, and
  Chen]{sandler2018mobilenetv2}
Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., and Chen, L.-C.
\newblock Mobilenetv2: Inverted residuals and linear bottlenecks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  4510--4520, 2018.

\bibitem[Tan \& Le(2019)Tan and Le]{tan2019efficientnet}
Tan, M. and Le, Q.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In \emph{International conference on machine learning}, pp.\
  6105--6114. PMLR, 2019.

\bibitem[Tan et~al.(2019)Tan, Chen, Pang, Vasudevan, Sandler, Howard, and
  Le]{tan2019mnasnet}
Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le,
  Q.~V.
\newblock Mnasnet: Platform-aware neural architecture search for mobile.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  2820--2828, 2019.

\bibitem[Taori et~al.(2023)Taori, Gulrajani, Zhang, Dubois, Li, Guestrin,
  Liang, and Hashimoto]{alpaca}
Taori, R., Gulrajani, I., Zhang, T., Dubois, Y., Li, X., Guestrin, C., Liang,
  P., and Hashimoto, T.~B.
\newblock Stanford alpaca: An instruction-following llama model.
\newblock \url{https://github.com/tatsu-lab/stanford_alpaca}, 2023.

\bibitem[Touvron et~al.(2021)Touvron, Cord, Douze, Massa, Sablayrolles, and
  J{\'e}gou]{deit}
Touvron, H., Cord, M., Douze, M., Massa, F., Sablayrolles, A., and J{\'e}gou,
  H.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock In \emph{International conference on machine learning}, pp.\
  10347--10357. PMLR, 2021.

\bibitem[Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux,
  Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{touvron2023llama}
Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix,
  T., Rozi{\`e}re, B., Goyal, N., Hambro, E., Azhar, F., et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem[Wan et~al.(2020)Wan, Dai, Zhang, He, Tian, Xie, Wu, Yu, Xu, Chen,
  et~al.]{wan2020fbnetv2}
Wan, A., Dai, X., Zhang, P., He, Z., Tian, Y., Xie, S., Wu, B., Yu, M., Xu, T.,
  Chen, K., et~al.
\newblock Fbnetv2: Differentiable neural architecture search for spatial and
  channel dimensions.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  12965--12974, 2020.

\bibitem[Wang \& Fu(2022)Wang and Fu]{tpp}
Wang, H. and Fu, Y.
\newblock Trainability preserving neural structured pruning.
\newblock \emph{arXiv preprint arXiv:2207.12534}, 2022.

\bibitem[Wang et~al.(2020)Wang, Qin, Zhang, and Fu]{greg}
Wang, H., Qin, C., Zhang, Y., and Fu, Y.
\newblock Neural pruning via growing regularization.
\newblock \emph{arXiv preprint arXiv:2012.09243}, 2020.

\bibitem[Wightman(2019)]{rw2019timm}
Wightman, R.
\newblock Pytorch image models.
\newblock \url{https://github.com/rwightman/pytorch-image-models}, 2019.

\bibitem[Wightman et~al.(2021)Wightman, Touvron, and
  J{\'e}gou]{wightman2021rsb}
Wightman, R., Touvron, H., and J{\'e}gou, H.
\newblock Resnet strikes back: An improved training procedure in timm.
\newblock \emph{arXiv preprint arXiv:2110.00476}, 2021.

\bibitem[Xie et~al.(2022)Xie, Su, You, Ma, Wang, and Qian]{xie2022scalenet}
Xie, J., Su, X., You, S., Ma, Z., Wang, F., and Qian, C.
\newblock Scalenet: Searching for the model to scale.
\newblock In \emph{European Conference on Computer Vision}, pp.\  104--120.
  Springer, 2022.

\bibitem[Yao et~al.(2021)Yao, Wu, Ma, Shen, Keutzer, Mahoney, and
  He]{yao2021leap}
Yao, Z., Wu, X., Ma, L., Shen, S., Keutzer, K., Mahoney, M.~W., and He, Y.
\newblock Leap: Learnable pruning for transformer-based models.
\newblock \emph{arXiv preprint arXiv:2105.14636}, 2021.

\bibitem[Zhuang et~al.(2020)Zhuang, Zhang, Huang, Zeng, Shuang, and
  Li]{zhuang2020polar}
Zhuang, T., Zhang, Z., Huang, Y., Zeng, X., Shuang, K., and Li, X.
\newblock Neuron-level structured pruning using polarization regularizer.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 9865--9877, 2020.

\bibitem[Zoph \& Le(2016)Zoph and Le]{zoph2016rlnas}
Zoph, B. and Le, Q.~V.
\newblock Neural architecture search with reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.01578}, 2016.

\end{thebibliography}
