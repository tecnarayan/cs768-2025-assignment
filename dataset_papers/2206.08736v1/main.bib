@inproceedings{janner2020gamma,
  title={Gamma-Models: Generative Temporal Difference Learning for Infinite-Horizon Prediction},
  author={Janner, Michael and Mordatch, Igor and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}

@article{dayan1993improving,
  title={Improving generalization for temporal difference learning: The successor representation},
  author={Dayan, Peter},
  journal={Neural Computation},
  volume={5},
  number={4},
  pages={613--624},
  year={1993},
  publisher={MIT Press}
}

@inproceedings{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  booktitle={Proceedings of the International Conference on Learning Representations},
  year={2016}
}

@inproceedings{durkan2019neural,
  title={Neural spline flows},
  author={Durkan, Conor and Bekasov, Artur and Murray, Iain and Papamakarios, George},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}

@inproceedings{kingma2018glow,
  title={Glow: Generative flow with invertible 1x1 convolutions},
  author={Kingma, Diederik P and Dhariwal, Prafulla},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018}
}

@inproceedings{dinh2016density,
  title={Density estimation using real {NVP}},
  author={Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  booktitle={Proceedings of the International Conference on Learning Representations},
  year={2017}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={Proceedings of the International Conference on Learning Representations},
  year={2015}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv},
  year={2016}
}

@inproceedings{rezende2015variational,
  title={Variational inference with normalizing flows},
  author={Rezende, Danilo and Mohamed, Shakir},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2015},
}

@inproceedings{barreto2016successor,
  title={Successor features for transfer in reinforcement learning},
  author={Barreto, Andr{\'e} and Dabney, Will and Munos, R{\'e}mi and Hunt, Jonathan J and Schaul, Tom and Van Hasselt, Hado and Silver, David},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{pmlr-v80-barreto18a,
  title = 	 {Transfer in Deep Reinforcement Learning Using Successor Features and Generalised Policy Improvement},
  author =       {Barreto, Andre and Borsa, Diana and Quan, John and Schaul, Tom and Silver, David and Hessel, Matteo and Mankowitz, Daniel and Zidek, Augustin and Munos, R{\'e}mi},
  booktitle = 	 {Proceedings of the International Conference on Machine Learning},
  year = 	 {2018},
}


@inproceedings{barreto2019optionkeyboard,
  author    = {Andr{\'{e}} Barreto and
               Diana Borsa and
               Shaobo Hou and
               Gheorghe Comanici and
               Eser Ayg{\"{u}}n and
               Philippe Hamel and
               Daniel Toyama and
               Jonathan J. Hunt and
               Shibl Mourad and
               David Silver and
               Doina Precup},
  title     = {The Option Keyboard: Combining Skills in Reinforcement Learning},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2019},
}

@inproceedings{higgins2016beta,
  title={beta-{VAE}: Learning basic visual concepts with a constrained variational framework},
  author={Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
  year={2016},
  booktitle={Proceedings of the International Conference on Learning Representations}
}

@inproceedings{
abdolmaleki2018maximum,
title={Maximum a Posteriori Policy Optimisation},
author={Abbas Abdolmaleki and Jost Tobias Springenberg and Yuval Tassa and R{\'e}mi Munos and Nicolas Heess and Martin Riedmiller},
booktitle={Proceedings of the International Conference on Learning Representations},
year={2018},
}

@inproceedings{todorov2012mujoco,
  title={{MuJoCo}: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={Proceedings of the IEEE International Conference on Intelligent Robots and Systems},
  year={2012},
}

@inproceedings{efroni2018beyond,
  author={Efroni, Yonathan and Dalal, Gal and Scherrer, Bruno and Mannor, Shie},
  title={Beyond the One Step Greedy Approach in Reinforcement Learning},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2018},
}

@inproceedings{sutton1995td,
  title={{TD} models: Modeling the world at a mixture of time scales},
  author={Sutton, Richard S},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={1995},
}

@book{kushner2003stochastic,
  title={Stochastic Approximation and Recursive Algorithms and Applications},
  author={Kushner, Harold and Yin, G George},
  year={2003},
  publisher={Springer}
}

@book{sutton2018reinforcement,
  title={Reinforcement Learning: An Introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT Press}
}

@book{puterman2014markov,
  title={Markov decision processes: Discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@book{szepesvari2010algorithms,
  title={Algorithms for Reinforcement Learning},
  author={Szepesv{\'a}ri, {\relax Cs}aba},
  year={2010},
  publisher={Morgan \& Claypool}
}

@book{meyn2022control,
  title={Control Systems and Reinforcement Learning},
  author={Sean Meyn},
  publisher={Cambridge University Press},
  year={2022}
}

@book{bertsekas1996neuro,
  title={Neuro-Dynamic Programming},
  author={Bertsekas, Dimitri P. and Tsitsiklis, John N.},
  year={1996},
  publisher={Athena Scientific}
}

@inproceedings{borsa2019universal, 
	title={Universal Successor Features Approximators}, 
	author={Diana Borsa and Andre Barreto and John Quan and Daniel J. Mankowitz and Hado van Hasselt and R{\'e}mi Munos and David Silver and Tom Schaul}, 
	booktitle={Proceedings of the International Conference on Learning Representations}, 
	year={2019}, 
}

@inproceedings{hunt2019composing,
  title = 	 {Composing Entropic Policies using Divergence Correction},
  author = 	 {Hunt, Jonathan and Barreto, Andre and Lillicrap, Timothy and Heess, Nicolas},
  booktitle = 	 {Proceedings of the International Conference on Machine Learning},
  year = 	 {2019}
}
  
@inproceedings{hansen2020fast, 
  author    = {Steven Hansen and
               Will Dabney and
               Andr{\'{e}} Barreto and
               Tom Van de Wiele and
               David Warde{-}Farley and
               Volodymyr Mnih},
  title     = {Fast Task Inference with Variational Intrinsic Successor Features},
  booktitle={Proceedings of the International Conference on Learning Representations}, 
  year={2020}
}
  
@article {barreto2020fast,
	author = {Barreto, Andr{\'e} and Hou, Shaobo and Borsa, Diana and Silver, David and Precup, Doina},
	title = {Fast reinforcement learning with generalized policy updates},
	volume = {117},
	number = {48},
	pages = {30079--30087},
	year = {2020},
	publisher = {National Academy of Sciences},
	issn = {0027-8424},
	journal = {Proceedings of the National Academy of Sciences}
}

@inproceedings{efroni2018multiple,
  title={Multiple-step greedy policies in online and approximate reinforcement learning},
  author={Efroni, Yonathan and Dalal, Gal and Scherrer, Bruno and Mannor, Shie},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018}
}

@inproceedings{tomar2020multi,
  title={Multi-step Greedy Reinforcement Learning Algorithms},
  author={Tomar, Manan and Efroni, Yonathan and Ghavamzadeh, Mohammad},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2020},
}

@inproceedings{efroni2019combine,
  title={How to combine tree-search methods in reinforcement learning},
  author={Efroni, Yonathan and Dalal, Gal and Scherrer, Bruno and Mannor, Shie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2019}
}

@inproceedings{dalal2021improve,
  title={Improve Agents without Retraining: Parallel Tree Search with Off-Policy Correction},
  author={Dalal, Gal and Hallak, Assaf and Dalton, Steven and Frosio, Iuri and Mannor, Shie and Chechik, Gal},
  booktitle={Advances in Neural Information Processing Systems},
  year={2021}
}

@incollection{robbins1971convergence,
  title={A convergence theorem for non negative almost supermartingales and some applications},
  author={Robbins, Herbert and Siegmund, David},
  booktitle={Optimizing methods in statistics},
  pages={233--257},
  year={1971},
  publisher={Elsevier}
}

@book{norris1998markov,
  title={Markov Chains},
  author={Norris, James R},
  year={1998},
  publisher={Cambridge University Press}
}

@article{perron1907theorie,
  title={Zur {T}heorie der {M}atrices},
  author={Perron, Oskar},
  journal={Mathematische Annalen},
  volume={64},
  number={2},
  pages={248--263},
  year={1907},
  publisher={Springer}
}

@article{frobenius1912ueber,
  title= {{\"U}ber {M}atrizen aus nicht negativen {E}lementen},
  author = {Frobenius, Georg},
  year = {1912},
  journal = {Sitzungsberichte Akad. Wiss. Berlin}
}

@book{seneta2006non,
  title={Non-Negative Matrices and {M}arkov Chains},
  author={Seneta, Eugene},
  year={2006},
  publisher={Springer Science \& Business Media}
}

@inproceedings{busoniu2012optimistic,
  title={Optimistic planning for {M}arkov decision processes},
  author={Bu{\c{s}}oniu, Lucian and Munos, R{\'e}mi},
  booktitle={Proceedings of the International Conference on Artificial Intelligence and Statistics},
  year={2012},
}

@article{feldman2014simple,
  title={Simple regret optimization in online planning for {M}arkov decision processes},
  author={Feldman, Zohar and Domshlak, Carmel},
  journal={Journal of Artificial Intelligence Research},
  volume={51},
  pages={165--205},
  year={2014}
}

@article{munos2014bandits,
    year = {2014},
    volume = {7},
    journal = {Foundations and Trends® in Machine Learning},
    title = {From Bandits to {M}onte-{C}arlo Tree Search: The Optimistic Principle Applied to Optimization and Planning},
    number = {1},
    pages = {1-129},
    author = {R{\'e}mi Munos}
}

@inproceedings{szorenyi2014optimistic,
  title={Optimistic planning in {M}arkov decision processes using a generative model},
  author={Sz{\"o}r{\'e}nyi, Bal{\'a}zs and Kedenburg, Gunnar and Munos, R{\'e}mi},
  booktitle={Advances in Neural Information Processing Systems},
  year={2014}
}

@inproceedings{feldman2013monte,
  title={{M}onte-{C}arlo planning: {T}heoretically fast convergence meets practical efficiency},
  author={Feldman, Zohar and Domshlak, Carmel},
  booktitle={Proceedings of the Conference on Uncertainty in Artificial Intelligence},
  year={2013}
}

@incollection{busoniu2012survey,
  title={A survey of optimistic planning in {M}arkov decision processes},
  author={Bu{\c{s}}oniu, Lucian and Munos, R{\'e}mi and Babu{\v{s}}ka, Robert},
  booktitle={Reinforcement Learning and Adaptive Dynamic Programming for Feedback Control},
  pages={494--516},
  chapter = {22},
  year={2012},
  editor={Frank L. Lewis and Derong Liu},
  publisher={John Wiley \& Sons}
}

@inproceedings{feldman2014mabs,
  title={On {MAB}s and separation of concerns in {M}onte-{C}arlo planning for {MDP}s},
  author={Feldman, Zohar and Domshlak, Carmel},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  year={2014}
}

@inproceedings{lesner2015non,
  title={Non-stationary approximate modified policy iteration},
  author={Lesner, Boris and Scherrer, Bruno},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2015},
}

@inproceedings{kingma2014auto,
  title={Auto-encoding variational {B}ayes},
  author={Kingma, Diederik P and Welling, Max},
  booktitle={Proceedings of the International Conference on Learning Representations},
  year={2014}
}

@inproceedings{rezende2014stochastic,
  title={Stochastic backpropagation and approximate inference in deep generative models},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2014},
}

@inproceedings{sohn2015learning,
  title={Learning structured output representation using deep conditional generative models},
  author={Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
  booktitle={Advances in Neural Information Processing Systems},
  year={2015}
}

@inproceedings{precup2000eligibility,
  author = {Precup, Doina and Sutton, Richard S. and Singh, Satinder P.},
  title = {Eligibility Traces for Off-Policy Policy Evaluation},
  year = {2000},
  booktitle = {Proceedings of the International Conference on Machine Learning},
}

@inproceedings{zahavy2021discovering,
  author    = {Tom Zahavy and
               Andr{\'{e}} Barreto and
               Daniel J. Mankowitz and
               Shaobo Hou and
               Brendan O'Donoghue and
               Iurii Kemaev and
               Satinder Singh},
  title     = {Discovering a set of policies for the worst case reward},
  booktitle = {Proceedings of the International Conference on Learning Representations},
  year      = {2021},
}

@inproceedings{silver2012compositional,
  title={Compositional planning using optimal option models},
  author={Silver, David and Ciosek, Kamil},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2012}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{precup1998theoretical,
  title={Theoretical results on reinforcement learning with temporally abstract options},
  author={Precup, Doina and Sutton, Richard S and Singh, Satinder},
  booktitle={Proceedings of the European Conference on Machine Learning},
  year={1998},
}

@inproceedings{precup1998multi,
  title={Multi-time models for temporally abstract planning},
  author={Precup, Doina and Sutton, Richard S and Singh, S},
  booktitle={Advances in Neural Information Processing Systems},
  year={1998},
}

@inproceedings{toussaint2006probabilistic,
  title={Probabilistic inference for solving discrete and continuous state {M}arkov Decision Processes},
  author={Toussaint, Marc and Storkey, Amos},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2006}
}

@Article{hunter2007matplotlib,
  Author    = {Hunter, J. D.},
  Title     = {Matplotlib: A 2D graphics environment},
  Journal   = {Computing in Science \& Engineering},
  Volume    = {9},
  Number    = {3},
  Pages     = {90--95},
  abstract  = {Matplotlib is a 2D graphics package used for Python for
  application development, interactive scripting, and publication-quality
  image generation across user interfaces and operating systems.},
  publisher = {IEEE COMPUTER SOC},
  year      = 2007
}

@Article{         harris2020array,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
                 R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 publisher     = {Springer Science and Business Media {LLC}},
}

@misc{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  year = {2018},
}

@misc{deepmind2020jax,
  title = {The {D}eep{M}ind {JAX} {E}cosystem},
  author = {Babuschkin, Igor and Baumli, Kate and Bell, Alison and Bhupatiraju, Surya and Bruce, Jake and Buchlovsky, Peter and Budden, David and Cai, Trevor and Clark, Aidan and Danihelka, Ivo and Fantacci, Claudio and Godwin, Jonathan and Jones, Chris and Hennigan, Tom and Hessel, Matteo and Kapturowski, Steven and Keck, Thomas and Kemaev, Iurii and King, Michael and Martens, Lena and Mikulik, Vladimir and Norman, Tamara and Quan, John and Papamakarios, George and Ring, Roman and Ruiz, Francisco and Sanchez, Alvaro and Schneider, Rosalia and Sezener, Eren and Spencer, Stephen and Srinivasan, Srivatsan and Stokowiec, Wojciech and Viola, Fabio},
  year = {2020},
}

@inproceedings{toussaint2005,
  author={Marc Toussaint and Amos Storkey},
  title={Probabilistic inference for computing optimal policies in {MDP}s},
  booktitle={{NIPS} Workshop on Game Theory, Machine Learning and Reasoning under Uncertainty},
  year={2005}
}

@inproceedings{dabney2020temporally,
  title={Temporally-extended $\epsilon$-greedy exploration},
  author={Dabney, Will and Ostrovski, Georg and Barreto, Andr{\'e}},
  booktitle={Proceedings of the International Conference on Learning Representations},
  year={2021}
}

@inproceedings{scherrer2012use,
  title={On the use of non-stationary policies for stationary infinite-horizon {M}arkov decision processes},
  author={Scherrer, Bruno and Lesner, Boris},
  booktitle={Advances in Neural Information Processing Systems},
  year={2012}
}

@inproceedings{strens2000bayesian,
  title={A {B}ayesian framework for reinforcement learning},
  author={Strens, Malcolm},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2000}
}

@inproceedings{osband2013more,
  title={(More) efficient reinforcement learning via posterior sampling},
  author={Osband, Ian and Russo, Daniel and Van Roy, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  year={2013}
}

@inproceedings{osband2016deep,
  title={Deep exploration via bootstrapped {DQN}},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@inproceedings{agrawal2017optimistic,
  title={Optimistic posterior sampling for reinforcement learning: worst-case regret bounds},
  author={Agrawal, Shipra and Jia, Randy},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{russo2018tutorial,
  title={A tutorial on {T}hompson sampling},
  author={Russo, Daniel J and Van Roy, Benjamin and Kazerouni, Abbas and Osband, Ian and Wen, Zheng and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={11},
  number={1},
  pages={1--96},
  year={2018},
  publisher={Now Publishers, Inc.}
}

@article{blier2021learning,
  title={Learning successor states and goal-dependent values: A mathematical viewpoint},
  author={Blier, L{\'e}onard and Tallec, Corentin and Ollivier, Yann},
  journal={arXiv},
  year={2021}
}

@inproceedings{touati2021learning,
  author    = {Ahmed Touati and
               Yann Ollivier},
  title     = {Learning One Representation to Optimize All Rewards},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2021}
}

@article{grimm2019disentagled,
  author    = {Christopher Grimm and
               Irina Higgins and
               Andr{\'{e}} Barreto and
               Denis Teplyashin and
               Markus Wulfmeier and
               Tim Hertweck and
               Raia Hadsell and
               Satinder Singh},
  title     = {Disentangled Cumulants Help Successor Representations Transfer New Tasks},
  journal   = {arXiv},
  year      = {2019},
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={Proceedings of the International Joint Conference on Artificial Intelligence},
  year={1993},
}

@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2015},
}

@inproceedings{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{pong2018temporal,
  title={Temporal difference models: Model-free deep {RL} for model-based control},
  author={Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
  booktitle={Proceedings of the International Conference on Learning Representations},
  year={2018}
}

@inproceedings{eysenbach2021c,
  title={C-learning: Learning to achieve goals via recursive classification},
  author={Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey},
  booktitle={Proceedings of the International Conference on Learning Representations},
  year={2021}
}

@inproceedings{yao2014universal,
  title={Universal option models},
  author={Yao, Hengshuai and
  Szepesv{\'a}ri, {{\relax Cs}aba} and Sutton, Richard S and Modayil, Joseph and Bhatnagar, Shalabh},
  booktitle={Advances in Neural Information Processing Systems},
  year={2014}
}

@inproceedings{harutyunyan2019termination,
  title={The termination critic},
  author={Harutyunyan, Anna and Dabney, Will and Borsa, Diana and Heess, Nicolas and Munos, R{\'e}mi and Precup, Doina},
  booktitle={Proceedings of the International Conference on Artificial Intelligence and Statistics},
  year={2019}
}

@inproceedings{harb2018waiting,
  title={When waiting is not an option: Learning options with a deliberation cost},
  author={Harb, Jean and Bacon, Pierre-Luc and Klissarov, Martin and Precup, Doina},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{machado2017laplacian,
  title={A {L}aplacian framework for option discovery in reinforcement learning},
  author={Machado, Marlos C and Bellemare, Marc G and Bowling, Michael},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2017},
}

@inproceedings{mcgovern2001automatic,
  title={Automatic Discovery of Subgoals in Reinforcement Learning
using Diverse Density},
  author={Amy McGovern and Andrew G Barto},
  year={2001},
  booktitle={Proceedings of the International Conference on Machine Learning}
}

@inproceedings{kulkarni2016hierarchical,
  title={Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation},
  author={Kulkarni, Tejas D and Narasimhan, Karthik and Saeedi, Ardavan and Tenenbaum, Josh},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@inproceedings{menache2002q,
  title={Q-cut — dynamic discovery of sub-goals in reinforcement learning},
  author={Menache, Ishai and Mannor, Shie and Shimkin, Nahum},
  booktitle={Proceedings of the European Conference on Machine Learning},
  year={2002},
}

@phdthesis{precup2000temporal,
  title={Temporal abstraction in reinforcement learning},
  author={Precup, Doina},
  year={2000},
  school={University of Massachusetts Amherst}
}

@inproceedings{csimcsek2004using,
  title={Using relative novelty to identify useful temporal abstractions in reinforcement learning},
  author={{\c{S}}im{\c{s}}ek, {\"O}zg{\"u}r and Barto, Andrew G},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2004}
}

@inproceedings{wulfmeier2021data,
  title={Data-efficient hindsight off-policy option learning},
  author={Wulfmeier, Markus and Rao, Dushyant and Hafner, Roland and Lampe, Thomas and Abdolmaleki, Abbas and Hertweck, Tim and Neunert, Michael and Tirumala, Dhruva and Siegel, Noah and Heess, Nicolas and Riedmiller, Martin},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2021},
}

@inproceedings{brunskill2014pac,
  title={{PAC}-inspired option discovery in lifelong reinforcement learning},
  author={Brunskill, Emma and Li, Lihong},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2014},
}

@InProceedings{nemecek2021policy,
  title = 	 {Policy Caches with Successor Features},
  author =       {Nemecek, Mark and Parr, Ronald},
  booktitle = 	 {Proceedings of the International Conference on Machine Learning},
  year = 	 {2021},
}

@inproceedings{alver2022constructing,
    title={Constructing a Good Behavior Basis for Transfer using Generalized Policy Updates},
    author={Safa Alver and Doina Precup},
    booktitle={Proceedings of the International Conference on Learning Representations},
    year={2022},
}

@article{lehnert2020successor,
  author    = {Lucas Lehnert and
               Michael L. Littman},
  title     = {Successor Features Combine Elements of Model-Free and Model-based
               Reinforcement Learning},
  journal   = {Journal of Machine Learning Research},
  volume    = {21},
  pages     = {196:1--196:53},
  year      = {2020},
}

@inproceedings{fujimoto2021deep,
  title={A Deep Reinforcement Learning Approach to Marginalized Importance Sampling with the Successor Representation},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2021},
}

@article{kulkarni2016deep,
  title={Deep successor reinforcement learning},
  author={Kulkarni, Tejas D. and Saeedi, Ardavan and Gautam, Simanta and Gershman, Samuel J},
  journal={arXiv},
  year={2016}
}

