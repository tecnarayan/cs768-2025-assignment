
@inproceedings{Carpentier,
author = {Carpentier, Alexandra and Valko, Michal},
title = {Simple Regret for Infinitely Many Armed Bandits},
year = {2015},
publisher = {JMLR.org},
booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
pages = {1133–1141},
numpages = {9},
location = {Lille, France},
series = {ICML'15}
}

@InProceedings{Seznec2,
  title = 	 {A single algorithm for both restless and rested rotting bandits},
  author =       {Seznec, Julien and Menard, Pierre and Lazaric, Alessandro and Valko, Michal},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {3784--3794},
  year = 	 {2020},
  editor = 	 {Chiappa, Silvia and Calandra, Roberto},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR},
}


@InProceedings{Traca,
  title = 	 {Reducing Exploration of Dying Arms in Mortal Bandits},
  author =       {Trac{\`{a}}, Stefano and Rudin, Cynthia and Yan, Weiyu},
  booktitle = 	 {Proceedings of The 35th Uncertainty in Artificial Intelligence Conference},
  pages = 	 {156--163},
  year = 	 {2020},
  editor = 	 {Adams, Ryan P. and Gogate, Vibhav},
  volume = 	 {115},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {22--25 Jul},
  publisher =    {PMLR},
}

@inproceedings{seznec2019rotting,
  title={Rotting bandits are no harder than stochastic ones},
  author={Seznec, Julien and Locatelli, Andrea and Carpentier, Alexandra and Lazaric, Alessandro and Valko, Michal},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={2564--2572},
  year={2019},
  organization={PMLR}
}


@article{Besbes2,
author = {Besbes, Omar and Gur, Yonatan and Zeevi, Assaf},
title = {Optimal Exploration-Exploitation in a Multi-armed Bandit Problem with Non-stationary Rewards},
journal = {Stochastic Systems},
volume = {9},
number = {4},
pages = {319-337},
year = {2019},
}

@article{levine2017rotting,
  title={Rotting bandits},
  author={Levine, Nir and Crammer, Koby and Mannor, Shie},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{Heidari,
author = {Heidari, Hoda and Kearns, Michael and Roth, Aaron},
title = {Tight Policy Regret Bounds for Improving and Decaying Bandits},
year = {2016},
booktitle = {Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence},
pages = {1562–1570},
numpages = {9},
location = {New York, New York, USA},
series = {IJCAI'16}
}

@InProceedings{Komiyama,
author="Komiyama, Junpei
and Qin, Tao",
editor="Liu, Tie-Yan
and Qi, Qi
and Ye, Yinyu",
title="Time-Decaying Bandits for Non-stationary Systems",
booktitle="Web and Internet Economics",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="460--466",
}

@article{besbes2014stochastic,
  title={Stochastic multi-armed-bandit problem with non-stationary rewards},
  author={Besbes, Omar and Gur, Yonatan and Zeevi, Assaf},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@inproceedings{Garivier,
    Address = {Berlin, Heidelberg},
	Author = {Garivier, Aur{\'e}lien and Moulines, Eric},
	Booktitle = {Algorithmic Learning Theory},
	Da = {2011//},
	Editor = {Kivinen, Jyrki and Szepesv{\'a}ri, Csaba and Ukkonen, Esko and Zeugmann, Thomas},
	Id = {10.1007/978-3-642-24412-4{\_}16},
	Isbn = {978-3-642-24412-4},
	Pages = {174--188},
	Publisher = {Springer Berlin Heidelberg},
	Title = {On Upper-Confidence Bound Policies for Switching Bandit Problems},
	Ty = {CONF},
	Year = {2011}
	}


@inproceedings{Yu,
author = {Yu, Jia Yuan and Mannor, Shie},
title = {Piecewise-Stationary Bandit Problems with Side Observations},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {1177–1184},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@inproceedings{Chakrabarti,
author = {Chakrabarti, Deepayan and Kumar, Ravi and Radlinski, Filip and Upfal, Eli},
title = {Mortal Multi-Armed Bandits},
year = {2008},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 21st International Conference on Neural Information Processing Systems},
pages = {273–280},
numpages = {8},
location = {Vancouver, British Columbia, Canada},
series = {NIPS'08}
}
@article{Bayati,
  title={The Unreasonable Effectiveness of Greedy Algorithms in Multi-Armed Bandit with Many Arms},
  author={Bayati, Mohsen and Hamidi, Nima and Johari, Ramesh and Khosravi, Khashayar},
  journal={arXiv preprint arXiv:2002.10121},
  year={2020}
}
@article{wang,
  title={Algorithms for infinitely many-armed bandits},
  author={Wang, Yizao and Audibert, Jean-Yves and Munos, R{\'e}mi},
  journal={Advances in Neural Information Processing Systems},
  volume={21},
  year={2008}
}@inproceedings{Bonald,
author = {Bonald, Thomas and Prouti\`{e}re, Alexandre},
title = {Two-Target Algorithms for Infinite-Armed Bandits with Bernoulli Rewards},
year = {2013},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2},
pages = {2184–2192},
numpages = {9},
location = {Lake Tahoe, Nevada},
series = {NIPS'13}
}

@article{Berry,
author = {Donald A. Berry and Robert W. Chen and Alan Zame and David C. Heath and Larry A. Shepp},
title = {{Bandit problems with infinitely many arms}},
volume = {25},
journal = {The Annals of Statistics},
number = {5},
publisher = {Institute of Mathematical Statistics},
pages = {2103 -- 2116},
keywords = {bandit problems, dynamic allocation of Bernoulli processes, Sequential experimentation, staying with a winner, switching with a loser},
year = {1997},
}


@inproceedings{immorlica2019adversarial,
  title={Adversarial bandits with knapsacks},
  author={Immorlica, Nicole and Sankararaman, Karthik Abinav and Schapire, Robert and Slivkins, Aleksandrs},
  booktitle={2019 IEEE 60th Annual Symposium on Foundations of Computer Science (FOCS)},
  pages={202--219},
  year={2019},
  organization={IEEE}
}

@article{agrawal2019bandits,
  title={Bandits with global convex constraints and objective},
  author={Agrawal, Shipra and Devanur, Nikhil R},
  journal={Operations Research},
  volume={67},
  number={5},
  pages={1486--1502},
  year={2019},
  publisher={INFORMS}
}

@inproceedings{badanidiyuru2013bandits,
  title={Bandits with knapsacks},
  author={Badanidiyuru, Ashwinkumar and Kleinberg, Robert and Slivkins, Aleksandrs},
  booktitle={2013 IEEE 54th Annual Symposium on Foundations of Computer Science},
  pages={207--216},
  year={2013},
  organization={IEEE}
}

@article{alon2017nonstochastic,
  title={Nonstochastic multi-armed bandits with graph-structured feedback},
  author={Alon, Noga and Cesa-Bianchi, Nicolo and Gentile, Claudio and Mannor, Shie and Mansour, Yishay and Shamir, Ohad},
  journal={SIAM Journal on Computing},
  volume={46},
  number={6},
  pages={1785--1826},
  year={2017},
  publisher={SIAM}
}

@article{brown2011wasted,
  title={How {I} wasted too long finding a concentration inequality for sums of geometric variables},
  author={Brown, Daniel G},
  journal={Found at https://cs. uwaterloo. ca/\~{} browndg/negbin. pdf},
  volume={8},
  number={4},
  year={2011}
}


@article{Slivkins,
year = {2019},
volume = {12},
journal = {Foundations and Trends\textregistered\ in Machine Learning},
title = {Introduction to Multi-Armed Bandits},
number = {1-2},
pages = {1-286},
author = {Aleksandrs Slivkins}
}

@book{lattimore, 
place={Cambridge}, 
title={Bandit Algorithms}, 
publisher={Cambridge University Press}, 
author={Lattimore, Tor and Szepesv{\' a}ri, Csaba}, 
year={2020}
}

@inproceedings{Brownian,
  author    = {Aleksandrs Slivkins and
               Eli Upfal},
  title     = {Adapting to a Changing Environment: the Brownian Restless Bandits},
  booktitle = {21st Annual Conference on Learning Theory - {COLT} 2008, Helsinki,
               Finland, July 9-12, 2008},
  pages     = {343--354},
  year      = {2008},
}

@article{auer,
author = {Auer, Peter and Cesa-Bianchi, Nicol{\' o} and Freund, Yoav and Schapire, Robert E.},
title = {The Nonstochastic Multiarmed Bandit Problem},
journal = {SIAM Journal on Computing},
volume = {32},
number = {1},
pages = {48-77},
year = {2002},
}

@article{Bouneffouf,
title = {Multi-armed bandit problem with known trend},
journal = {Neurocomputing},
volume = {205},
pages = {16-21},
year = {2016},
author = {Djallel Bouneffouf and Raphael F{\' e}raud},
}

@article{thompson,
    author = {Thompson, William R},
    title = {ON THE LIKELIHOOD THAT ONE UNKNOWN PROBABILITY EXCEEDS ANOTHER IN VIEW OF THE EVIDENCE OF TWO SAMPLES},
    journal = {Biometrika},
    volume = {25},
    number = {3-4},
    pages = {285-294},
    year = {1933},
    month = {12}
}

@article{lai,
author = {Lai, T.L and Robbins, Herbert},
title = {Asymptotically Efficient Adaptive Allocation Rules},
year = {1985},
issue_date = {March, 1985},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {6},
number = {1},
journal = {Adv. Appl. Math.},
month = {mar},
pages = {4–22},
numpages = {19}
}

@inproceedings{cheung2019learning,
  title={Learning to optimize under non-stationarity},
  author={Cheung, Wang Chi and Simchi-Levi, David and Zhu, Ruihao},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={1079--1087},
  year={2019},
  organization={PMLR}
}

@misc{hartland,
author = {C. Hartland and S. Gelly and N. Baskiotis and O. Teytaud and M. Sebag},
title = {Multi-armed bandit, dynamic environments and meta-bandits},
url = {https://hal.archives-ouvertes.fr/hal-00113668/document},
year = {2006},
}@inproceedings{auer2019adaptively,
  title={Adaptively tracking the best bandit arm with an unknown number of distribution changes},
  author={Auer, Peter and Gajane, Pratik and Ortner, Ronald},
  booktitle={Conference on Learning Theory},
  pages={138--158},
  year={2019},
  organization={PMLR}
}@inproceedings{chen2019new,
  title={A new algorithm for non-stationary contextual bandits: Efficient, optimal and parameter-free},
  author={Chen, Yifang and Lee, Chung-Wei and Luo, Haipeng and Wei, Chen-Yu},
  booktitle={Conference on Learning Theory},
  pages={696--726},
  year={2019},
  organization={PMLR}
}@inproceedings{zhao2020simple,
  title={A simple approach for non-stationary linear bandits},
  author={Zhao, Peng and Zhang, Lijun and Jiang, Yuan and Zhou, Zhi-Hua},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={746--755},
  year={2020},
  organization={PMLR}
}@article{russac2019weighted,
  title={Weighted linear bandits for non-stationary environments},
  author={Russac, Yoan and Vernade, Claire and Capp{\'e}, Olivier},
  journal={arXiv preprint arXiv:1909.09146},
  year={2019}
}@inproceedings{cheung2020reinforcement,
  title={Reinforcement learning for non-stationary markov decision processes: The blessing of (more) optimism},
  author={Cheung, Wang Chi and Simchi-Levi, David and Zhu, Ruihao},
  booktitle={International Conference on Machine Learning},
  pages={1843--1854},
  year={2020},
  organization={PMLR}
}@article{rigollet2015high,
  title={High dimensional statistics},
  author={Rigollet, Phillippe and H{\"u}tter, Jan-Christian},
  journal={Lecture notes for course 18S997},
  volume={813},
  pages={814},
  year={2015}
}@article{welford1962note,
  title={Note on a method for calculating corrected sums of squares and products},
  author={Welford, BP},
  journal={Technometrics},
  volume={4},
  number={3},
  pages={419--420},
  year={1962},
  publisher={Taylor \& Francis}
}@misc{Alex,
  author        = {Alex Tsun},
  title         = {Probability \& Statistics
with Applications to
Computing},
url = {https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf},
  year          = {2020}
}@article{auer2002finite,
  title={Finite-time analysis of the multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Fischer, Paul},
  journal={Machine learning},
  volume={47},
  number={2},
  pages={235--256},
  year={2002},
  publisher={Springer}
}@article{abbasi2011improved,
  title={Improved algorithms for linear stochastic bandits},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}@inproceedings{bubeck2011lipschitz,
  title={Lipschitz bandits without the lipschitz constant},
  author={Bubeck, S{\'e}bastien and Stoltz, Gilles and Yu, Jia Yuan},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={144--158},
  year={2011},
  organization={Springer}
}
@inproceedings{kim2022rotting,
  title={Rotting infinitely many-armed bandits},
  author={Kim, Jung-hun and Vojnovic, Milan and Yun, Se-Young},
  booktitle={International Conference on Machine Learning},
  pages={11229--11254},
  year={2022},
  organization={PMLR}
}
@inproceedings{aziz2018pure,
  title={Pure exploration in infinitely-armed bandit models with fixed-confidence},
  author={Aziz, Maryam and Anderton, Jesse and Kaufmann, Emilie and Aslam, Javed},
  booktitle={Algorithmic Learning Theory},
  pages={3--24},
  year={2018},
  organization={PMLR}
}@inproceedings{li2010contextual,
  title={A contextual-bandit approach to personalized news article recommendation},
  author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  booktitle={Proceedings of the 19th international conference on World wide web},
  pages={661--670},
  year={2010}
}@article{villar2015multi,
  title={Multi-armed bandit models for the optimal design of clinical trials: benefits and challenges},
  author={Villar, Sof{\'\i}a S and Bowden, Jack and Wason, James},
  journal={Statistical science: a review journal of the Institute of Mathematical Statistics},
  volume={30},
  number={2},
  pages={199},
  year={2015},
  publisher={Europe PMC Funders}
}
@inproceedings{metelli2022stochastic,
  title={Stochastic Rising Bandits},
  author={Metelli, Alberto Maria and Trovo, Francesco and Pirola, Matteo and Restelli, Marcello},
  booktitle={International Conference on Machine Learning},
  pages={15421--15457},
  year={2022},
  organization={PMLR}
}@article{slivkins2019introduction,
  title={Introduction to multi-armed bandits},
  author={Slivkins, Aleksandrs and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={12},
  number={1-2},
  pages={1--286},
  year={2019},
  publisher={Now Publishers, Inc.}
}@article{huo2017risk,
  title={Risk-aware multi-armed bandit problem with application to portfolio selection},
  author={Huo, Xiaoguang and Fu, Feng},
  journal={Royal Society open science},
  volume={4},
  number={11},
  pages={171377},
  year={2017},
  publisher={The Royal Society Publishing}
}@inproceedings{wei2021non,
  title={Non-stationary reinforcement learning without prior knowledge: An optimal black-box approach},
  author={Wei, Chen-Yu and Luo, Haipeng},
  booktitle={Conference on learning theory},
  pages={4300--4354},
  year={2021},
  organization={PMLR}
}@article{mussi2023best,
  title={Best Arm Identification for Stochastic Rising Bandits},
  author={Mussi, Marco and Montenegro, Alessandro and Trovo, Francesco and Restelli, Marcello and Metelli, Alberto Maria},
  journal={arXiv preprint arXiv:2302.07510},
  year={2023}
}@article{russac2020algorithms,
  title={Algorithms for non-stationary generalized linear bandits},
  author={Russac, Yoan and Capp{\'e}, Olivier and Garivier, Aur{\'e}lien},
  journal={arXiv preprint arXiv:2003.10113},
  year={2020}
}@inproceedings{wang2023revisiting,
  title={Revisiting Weighted Strategy for Non-stationary Parametric Bandits},
  author={Wang, Jing and Zhao, Peng and Zhou, Zhi-Hua},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={7913--7942},
  year={2023},
  organization={PMLR}
}@inproceedings{russac2021self,
  title={Self-concordant analysis of generalized linear bandits with forgetting},
  author={Russac, Yoan and Faury, Louis and Capp{\'e}, Olivier and Garivier, Aur{\'e}lien},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={658--666},
  year={2021},
  organization={PMLR}
}@article{zhao2021non,
  title={Non-stationary linear bandits revisited},
  author={Zhao, Peng and Zhang, Lijun},
  journal={arXiv preprint arXiv:2103.05324},
  volume={19},
  year={2021}
}@article{foster,
  title={Statistical Reinforcement Learning and Decision Making: Course Notes},
  author={Dylan J. Foster, Alexander Rakhlin},
  journal={MIT Lecture notes for course 9.S915 Fall 2022},
  year={2022}
}@inproceedings{auer2007improved,
  title={Improved rates for the stochastic continuum-armed bandit problem},
  author={Auer, Peter and Ortner, Ronald and Szepesv{\'a}ri, Csaba},
  booktitle={International Conference on Computational Learning Theory},
  pages={454--468},
  year={2007},
  organization={Springer}
}@article{kleinberg2004nearly,
  title={Nearly tight bounds for the continuum-armed bandit problem},
  author={Kleinberg, Robert},
  journal={Advances in Neural Information Processing Systems},
  volume={17},
  year={2004}
}@article{auer2002nonstochastic,
  title={The nonstochastic multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
  journal={SIAM journal on computing},
  volume={32},
  number={1},
  pages={48--77},
  year={2002},
  publisher={SIAM}
}