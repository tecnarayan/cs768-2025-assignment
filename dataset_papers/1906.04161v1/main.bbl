\begin{thebibliography}{45}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achiam \& Sastry(2017)Achiam and Sastry]{josh_surprise}
Achiam, J. and Sastry, S.
\newblock Surprise-based intrinsic motivation for deep reinforcement learning.
\newblock \emph{arXiv:1703.01732}, 2017.

\bibitem[Bellemare et~al.(2016)Bellemare, Srinivasan, Ostrovski, Schaul,
  Saxton, and Munos]{bellemare2016unifying}
Bellemare, M., Srinivasan, S., Ostrovski, G., Schaul, T., Saxton, D., and
  Munos, R.
\newblock Unifying count-based exploration and intrinsic motivation.
\newblock In \emph{NIPS}, 2016.

\bibitem[Bengio et~al.(2013)Bengio, L{\'e}onard, and
  Courville]{bengio2013estimating}
Bengio, Y., L{\'e}onard, N., and Courville, A.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock \emph{arXiv:1308.3432}, 2013.

\bibitem[Boyd \& Vandenberghe(2004)Boyd and Vandenberghe]{boyd2004convex}
Boyd, S. and Vandenberghe, L.
\newblock \emph{Convex optimization}.
\newblock Cambridge university press, 2004.

\bibitem[Burda et~al.(2019)Burda, Edwards, Pathak, Storkey, Darrell, and
  Efros]{burda2018large}
Burda, Y., Edwards, H., Pathak, D., Storkey, A., Darrell, T., and Efros, A.~A.
\newblock Large-scale study of curiosity-driven learning.
\newblock \emph{ICLR}, 2019.

\bibitem[Chua et~al.(2018)Chua, Calandra, McAllister, and Levine]{chua2018deep}
Chua, K., Calandra, R., McAllister, R., and Levine, S.
\newblock Deep reinforcement learning in a handful of trials using
  probabilistic dynamics models.
\newblock \emph{arXiv preprint arXiv:1805.12114}, 2018.

\bibitem[Dagan \& Engelson(1995)Dagan and Engelson]{Dagan1995}
Dagan, I. and Engelson, S.
\newblock Committee-based sampling for training probabilistic classifiers.
\newblock \emph{ICML}, 1995.

\bibitem[Deisenroth \& Rasmussen(2011{\natexlab{a}})Deisenroth and
  Rasmussen]{Deisenroth11}
Deisenroth, M. and Rasmussen, C.
\newblock Pilco: A model-based and data-efficient approach to policy search.
\newblock \emph{ICML}, 2011{\natexlab{a}}.

\bibitem[Deisenroth \& Rasmussen(2011{\natexlab{b}})Deisenroth and
  Rasmussen]{deisenroth2011pilco}
Deisenroth, M. and Rasmussen, C.~E.
\newblock Pilco: A model-based and data-efficient approach to policy search.
\newblock In \emph{ICML}, 2011{\natexlab{b}}.

\bibitem[Eysenbach et~al.(2018)Eysenbach, Gupta, Ibarz, and
  Levine]{eysenbach2018diversity}
Eysenbach, B., Gupta, A., Ibarz, J., and Levine, S.
\newblock Diversity is all you need: Learning skills without a reward function.
\newblock \emph{arXiv:1802.06070}, 2018.

\bibitem[Fortunato et~al.(2017)Fortunato, Azar, Piot, Menick, Osband, Graves,
  Mnih, Munos, Hassabis, Pietquin, Blundell, and Legg]{fortunato2017noisy}
Fortunato, M., Azar, M.~G., Piot, B., Menick, J., Osband, I., Graves, A., Mnih,
  V., Munos, R., Hassabis, D., Pietquin, O., Blundell, C., and Legg, S.
\newblock Noisy networks for exploration.
\newblock \emph{arXiv:1706.10295}, 2017.

\bibitem[Fu et~al.(2017)Fu, Co-Reyes, and Levine]{fu2017ex2}
Fu, J., Co-Reyes, J.~D., and Levine, S.
\newblock Ex2: Exploration with exemplar models for deep reinforcement
  learning.
\newblock \emph{NIPS}, 2017.

\bibitem[Gal \& Ghahramani(2015)Gal and Ghahramani]{gal2015}
Gal, Y. and Ghahramani, Z.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock \emph{arXiv preprint arXiv:1506.02142}, 2015.

\bibitem[Gal et~al.(2016)Gal, McAllister, and Rasmussen]{gal2016improving}
Gal, Y., McAllister, R., and Rasmussen, C.~E.
\newblock Improving pilco with bayesian neural network dynamics models.
\newblock In \emph{Data-Efficient Machine Learning workshop, ICML}, 2016.

\bibitem[Gregor et~al.(2017)Gregor, Rezende, and
  Wierstra]{gregor2017variational}
Gregor, K., Rezende, D.~J., and Wierstra, D.
\newblock Variational intrinsic control.
\newblock \emph{ICLR Workshop}, 2017.

\bibitem[Henaff et~al.(2019)Henaff, Canziani, and LeCun]{henaff2019model}
Henaff, M., Canziani, A., and LeCun, Y.
\newblock Model-predictive policy learning with uncertainty regularization for
  driving in dense traffic.
\newblock \emph{ICLR}, 2019.

\bibitem[Houlsby et~al.(2011)Houlsby, Huszár, Ghahramani, and
  Lengyel]{Houlsby2011}
Houlsby, N., Huszár, F., Ghahramani, Z., and Lengyel, M.
\newblock Bayesian active learning for classification and preference learning.
\newblock \emph{arXiv}, 2011.

\bibitem[Houthooft et~al.(2016)Houthooft, Chen, Duan, Schulman, De~Turck, and
  Abbeel]{houthooft2016vime}
Houthooft, R., Chen, X., Duan, Y., Schulman, J., De~Turck, F., and Abbeel, P.
\newblock Vime: Variational information maximizing exploration.
\newblock In \emph{NIPS}, 2016.

\bibitem[Juliani et~al.(2018)Juliani, Berges, Vckay, Gao, Henry, Mattar, and
  Lange]{unity_ml}
Juliani, A., Berges, V.-P., Vckay, E., Gao, Y., Henry, H., Mattar, M., and
  Lange, D.
\newblock Unity: A general platform for intelligent agents.
\newblock \emph{arXiv:1809.02627}, 2018.

\bibitem[Kolter \& Ng(2009)Kolter and Ng]{kolter09}
Kolter, Z. and Ng, A.
\newblock Near-bayesian exploration in polynomial time.
\newblock \emph{ICML}, 2009.

\bibitem[Lehman \& Stanley(2011{\natexlab{a}})Lehman and
  Stanley]{lehman2011abandoning}
Lehman, J. and Stanley, K.~O.
\newblock Abandoning objectives: Evolution through the search for novelty
  alone.
\newblock \emph{Evolutionary computation}, 2011{\natexlab{a}}.

\bibitem[Lehman \& Stanley(2011{\natexlab{b}})Lehman and
  Stanley]{lehman2011evolving}
Lehman, J. and Stanley, K.~O.
\newblock Evolving a diversity of virtual creatures through novelty search and
  local competition.
\newblock In \emph{Proceedings of the 13th annual conference on Genetic and
  evolutionary computation}, 2011{\natexlab{b}}.

\bibitem[Lewis \& Gale(1994)Lewis and Gale]{Lewis1994}
Lewis, D. and Gale, W.
\newblock A sequential algorithm for training text classifiers.
\newblock \emph{ACM SIGIR}, 1994.

\bibitem[Lillicrap et~al.(2016)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{lillicrap2015continuous}
Lillicrap, T.~P., Hunt, J.~J., Pritzel, A., Heess, N., Erez, T., Tassa, Y.,
  Silver, D., and Wierstra, D.
\newblock Continuous control with deep reinforcement learning.
\newblock \emph{ICLR}, 2016.

\bibitem[Lopes et~al.(2012)Lopes, Lang, Toussaint, and
  Oudeyer]{lopes2012exploration}
Lopes, M., Lang, T., Toussaint, M., and Oudeyer, P.-Y.
\newblock Exploration in model-based reinforcement learning by empirically
  estimating learning progress.
\newblock In \emph{NIPS}, 2012.

\bibitem[Machado et~al.(2017)Machado, Bellemare, Talvitie, Veness, Hausknecht,
  and Bowling]{stickyAtari}
Machado, M.~C., Bellemare, M.~G., Talvitie, E., Veness, J., Hausknecht, M.~J.,
  and Bowling, M.
\newblock Revisiting the arcade learning environment: Evaluation protocols and
  open problems for general agents.
\newblock \emph{CoRR}, abs/1709.06009, 2017.
\newblock URL \url{http://arxiv.org/abs/1709.06009}.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik,
  Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis]{dqn}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., Petersen,
  S., Beattie, C., Sadik, A., Antonoglou, I., King, H., Kumaran, D., Wierstra,
  D., Legg, S., and Hassabis, D.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529--533, February 2015.

\bibitem[Osband et~al.(2016)Osband, Blundell, Pritzel, and
  Van~Roy]{osband2016deep}
Osband, I., Blundell, C., Pritzel, A., and Van~Roy, B.
\newblock Deep exploration via bootstrapped dqn.
\newblock In \emph{NIPS}, 2016.

\bibitem[Oudeyer \& Kaplan(2009)Oudeyer and Kaplan]{oudeyer2009intrinsic}
Oudeyer, P.-Y. and Kaplan, F.
\newblock What is intrinsic motivation? a typology of computational approaches.
\newblock \emph{Frontiers in neurorobotics}, 2009.

\bibitem[Oudeyer et~al.(2007)Oudeyer, Kaplan, and Hafner]{oudeyer2007intrinsic}
Oudeyer, P.-Y., Kaplan, F., and Hafner, V.~V.
\newblock Intrinsic motivation systems for autonomous mental development.
\newblock \emph{Evolutionary Computation}, 2007.

\bibitem[Pathak et~al.(2017)Pathak, Agrawal, Efros, and
  Darrell]{pathakICMl17curiosity}
Pathak, D., Agrawal, P., Efros, A.~A., and Darrell, T.
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock In \emph{ICML}, 2017.

\bibitem[Plappert et~al.(2017)Plappert, Houthooft, Dhariwal, Sidor, Chen, Chen,
  Asfour, Abbeel, and Andrychowicz]{plappert2017parameter}
Plappert, M., Houthooft, R., Dhariwal, P., Sidor, S., Chen, R.~Y., Chen, X.,
  Asfour, T., Abbeel, P., and Andrychowicz, M.
\newblock Parameter space noise for exploration.
\newblock \emph{arXiv:1706.01905}, 2017.

\bibitem[Poupart et~al.(2006)Poupart, Vlassis, Hoey, and
  Regan]{poupart2006analytic}
Poupart, P., Vlassis, N., Hoey, J., and Regan, K.
\newblock An analytic solution to discrete bayesian reinforcement learning.
\newblock In \emph{ICML}, 2006.

\bibitem[Schmidhuber(1991{\natexlab{a}})]{schmidhuber1991curious}
Schmidhuber, J.
\newblock Curious model-building control systems.
\newblock In \emph{Neural Networks, 1991. 1991 IEEE International Joint
  Conference on}, pp.\  1458--1463. IEEE, 1991{\natexlab{a}}.

\bibitem[Schmidhuber(1991{\natexlab{b}})]{schmidhuber1991possibility}
Schmidhuber, J.
\newblock A possibility for implementing curiosity and boredom in
  model-building neural controllers.
\newblock In \emph{From animals to animats: Proceedings of the first
  international conference on simulation of adaptive behavior},
  1991{\natexlab{b}}.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{ppo}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv:1707.06347}, 2017.

\bibitem[Settles(2010)]{Settles2010}
Settles, B.
\newblock Active learning literature survey.
\newblock \emph{U Madison Tech Report}, 2010.

\bibitem[Seung et~al.(1992)Seung, Opper, and Sompolinsky]{Seung1992}
Seung, H., Opper, M., and Sompolinsky, H.
\newblock Query by committee.
\newblock \emph{COLT}, 1992.

\bibitem[Shyam et~al.(2019)Shyam, Ja\'{s}kowski, and Gomez]{shyam2019max}
Shyam, P., Ja\'{s}kowski, W., and Gomez, F.
\newblock {Model-Based Active Exploration}.
\newblock In \emph{ICML}, 2019.

\bibitem[Still \& Precup(2012)Still and Precup]{still2012information}
Still, S. and Precup, D.
\newblock An information-theoretic approach to curiosity-driven reinforcement
  learning.
\newblock \emph{Theory in Biosciences}, 2012.

\bibitem[Strehl \& Littman(2008)Strehl and Littman]{strehl08}
Strehl, A. and Littman, M.
\newblock An analysis of model-based interval estimation for markov decision
  processes.
\newblock \emph{Journal of Computer and System Sciences}, 2008.

\bibitem[Sukhbaatar et~al.(2018)Sukhbaatar, Kostrikov, Szlam, and
  Fergus]{sukhbaatar2017intrinsic}
Sukhbaatar, S., Kostrikov, I., Szlam, A., and Fergus, R.
\newblock Intrinsic motivation and automatic curricula via asymmetric
  self-play.
\newblock In \emph{ICLR}, 2018.

\bibitem[Sun et~al.(2011)Sun, Gomez, and Schmidhuber]{sun2011planning}
Sun, Y., Gomez, F., and Schmidhuber, J.
\newblock Planning to be surprised: Optimal bayesian exploration in dynamic
  environments.
\newblock In \emph{AGI}, 2011.

\bibitem[Williams(1992)]{williams1992simple}
Williams, R.~J.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock \emph{Machine learning}, 1992.

\bibitem[Zeng et~al.(2018)Zeng, Song, Welker, Lee, Rodriguez, and
  Funkhouser]{DBLP:journals/corr/abs-1803-09956}
Zeng, A., Song, S., Welker, S., Lee, J., Rodriguez, A., and Funkhouser, T.~A.
\newblock Learning synergies between pushing and grasping with self-supervised
  deep reinforcement learning.
\newblock \emph{CoRR}, abs/1803.09956, 2018.
\newblock URL \url{http://arxiv.org/abs/1803.09956}.

\end{thebibliography}
