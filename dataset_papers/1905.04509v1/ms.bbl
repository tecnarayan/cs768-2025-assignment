\begin{thebibliography}{59}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bolukbasi et~al.(2017)Bolukbasi, Wang, Dekel, and
  Saligrama]{icml/adaptive_nn}
Bolukbasi, T., Wang, J., Dekel, O., and Saligrama, V.
\newblock Adaptive neural networks for efficient inference.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  527--536, 2017.

\bibitem[Chen et~al.(2018)Chen, Tung, Vedula, and Mori]{eccv/clipq}
Chen, C., Tung, F., Vedula, N., and Mori, G.
\newblock Constraint-aware deep neural network compression.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  400--415, 2018.

\bibitem[Chen et~al.(2017)Chen, Li, Xiao, Jin, Yan, and Feng]{nips/dualpath}
Chen, Y., Li, J., Xiao, H., Jin, X., Yan, S., and Feng, J.
\newblock Dual path networks.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pp.\  4470--4478, 2017.

\bibitem[Courbariaux \& Bengio(2016)Courbariaux and Bengio]{corr/binarynet}
Courbariaux, M. and Bengio, Y.
\newblock Binarynet: Training deep neural networks with weights and activations
  constrained to +1 or -1.
\newblock \emph{CoRR}, abs/1602.02830, 2016.

\bibitem[Dai et~al.(2018)Dai, Zhu, Guo, and Wipf]{icml/info_bottle}
Dai, B., Zhu, C., Guo, B., and Wipf, D.
\newblock Compressing neural networks using the variational information
  bottleneck.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  1135--1144, 2018.

\bibitem[Dai et~al.(2017)Dai, Qi, Xiong, Li, Zhang, Hu, and Wei]{iccv/deform}
Dai, J., Qi, H., Xiong, Y., Li, Y., Zhang, G., Hu, H., and Wei, Y.
\newblock Deformable convolutional networks.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision (ICCV)}, pp.\  764--773, 2017.

\bibitem[Figurnov et~al.(2017)Figurnov, Collins, Zhu, Zhang, Huang, Vetrov, and
  Salakhutdinov]{cvpr/spatial_adaptive}
Figurnov, M., Collins, M.~D., Zhu, Y., Zhang, L., Huang, J., Vetrov, D., and
  Salakhutdinov, R.
\newblock Spatially adaptive computation time for residual networks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp.\  1039--1048, 2017.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and Szegedy]{iclr/adv}
Goodfellow, I., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2015.
\newblock URL \url{http://arxiv.org/abs/1412.6572}.

\bibitem[Gordon et~al.(2018)Gordon, Eban, Nachum, Chen, Wu, Yang, and
  Choi]{cvpr/morphnet}
Gordon, A., Eban, E., Nachum, O., Chen, B., Wu, H., Yang, T.-J., and Choi, E.
\newblock Morphnet: Fast \& simple resource-constrained structure learning of
  deep networks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2018.

\bibitem[Guo et~al.(2016)Guo, Yao, and Chen]{nips/dyn_surgery}
Guo, Y., Yao, A., and Chen, Y.
\newblock Dynamic network surgery for efficient dnns.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pp.\  1379--1387, 2016.

\bibitem[Han et~al.(2015)Han, Mao, and Dally]{corr/deepcomp}
Han, S., Mao, H., and Dally, W.~J.
\newblock Deep compression: Compressing deep neural network with pruning,
  trained quantization and huffman coding.
\newblock \emph{CoRR}, abs/1510.00149, 2015.

\bibitem[Han et~al.(2016)Han, Pool, Narang, Mao, Tang, Elsen, Catanzaro, Tran,
  and Dally]{corr/dsd}
Han, S., Pool, J., Narang, S., Mao, H., Tang, S., Elsen, E., Catanzaro, B.,
  Tran, J., and Dally, W.~J.
\newblock {DSD:} regularizing deep neural networks with dense-sparse-dense
  training flow.
\newblock \emph{CoRR}, abs/1607.04381, 2016.

\bibitem[He et~al.(2016{\natexlab{a}})He, Zhang, Ren, and Sun]{cvpr/resnet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp.\  770--778. {IEEE} Computer Society,
  2016{\natexlab{a}}.

\bibitem[He et~al.(2016{\natexlab{b}})He, Zhang, Ren, and Sun]{eccv/identity}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Identity mappings in deep residual networks.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, volume 9908
  of \emph{Lecture Notes in Computer Science}, pp.\  630--645. Springer,
  2016{\natexlab{b}}.

\bibitem[He et~al.(2017)He, Zhang, and Sun]{cvpr/he_channel}
He, Y., Zhang, X., and Sun, J.
\newblock Channel pruning for accelerating very deep neural networks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp.\  1389--1397, 2017.

\bibitem[Howard et~al.(2017)Howard, Zhu, Chen, Kalenichenko, Wang, Weyand,
  Andreetto, and Adam]{corr/mobilenet}
Howard, A.~G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T.,
  Andreetto, M., and Adam, H.
\newblock Mobilenets: Efficient convolutional neural networks for mobile vision
  applications.
\newblock \emph{CoRR}, abs/1704.04861, 2017.

\bibitem[Huang et~al.(2017)Huang, Liu, van~der Maaten, and
  Weinberger]{cvpr/densenet}
Huang, G., Liu, Z., van~der Maaten, L., and Weinberger, K.~Q.
\newblock Densely connected convolutional networks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp.\  2261--2269. {IEEE} Computer Society, 2017.

\bibitem[Huang et~al.(2018{\natexlab{a}})Huang, Chen, Li, Wu, van~der Maaten,
  and Weinberger]{iclr/msdnet}
Huang, G., Chen, D., Li, T., Wu, F., van~der Maaten, L., and Weinberger, K.
\newblock Multi-scale dense networks for resource efficient image
  classification.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018{\natexlab{a}}.
\newblock URL \url{https://openreview.net/forum?id=Hk2aImxAb}.

\bibitem[Huang et~al.(2018{\natexlab{b}})Huang, Liu, Van~der Maaten, and
  Weinberger]{cvpr/condensenet}
Huang, G., Liu, S., Van~der Maaten, L., and Weinberger, K.~Q.
\newblock Condensenet: An efficient densenet using learned group convolutions.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  2752--2761, 2018{\natexlab{b}}.

\bibitem[Iandola et~al.(2016)Iandola, Moskewicz, Ashraf, Han, Dally, and
  Keutzer]{corr/squeezenet}
Iandola, F.~N., Moskewicz, M.~W., Ashraf, K., Han, S., Dally, W.~J., and
  Keutzer, K.
\newblock Squeezenet: Alexnet-level accuracy with 50x fewer parameters and
  {\textless}{1MB} model size.
\newblock \emph{CoRR}, abs/1602.07360, 2016.

\bibitem[Ioannou et~al.(2017)Ioannou, Robertson, Cipolla, and
  Criminisi]{cvpr/deeproots}
Ioannou, Y., Robertson, D., Cipolla, R., and Criminisi, A.
\newblock Deep roots: Improving cnn efficiency with hierarchical filter groups.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp.\  1231--1240, 2017.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{icml/batchnorm}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  volume~37 of \emph{{JMLR} Workshop and Conference Proceedings}, pp.\
  448--456. JMLR, 2015.

\bibitem[Jaderberg et~al.(2014)Jaderberg, Vedaldi, and Zisserman]{bmvc/lowrank}
Jaderberg, M., Vedaldi, A., and Zisserman, A.
\newblock Speeding up convolutional neural networks with low rank expansions.
\newblock In \emph{Proceedings of the British Machine Vision Conference
  (BMVC)}, 2014.

\bibitem[Jeon \& Kim(2017)Jeon and Kim]{cvpr/active}
Jeon, Y. and Kim, J.
\newblock Active convolution: Learning the shape of convolution for image
  classification.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp.\  4201--4209, 2017.

\bibitem[Jeon \& Kim(2018)Jeon and Kim]{nips/asl}
Jeon, Y. and Kim, J.
\newblock Constructing fast network through deconstruction of convolution.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems (NIPS)}, pp.\  5955--5965. Curran Associates,
  Inc., 2018.

\bibitem[Kawaguchi \& Kaelbling(2019)Kawaguchi and Kaelbling]{corr/elim_allbad}
Kawaguchi, K. and Kaelbling, L.~P.
\newblock Elimination of all bad local minima in deep learning.
\newblock \emph{arXiv preprint arXiv:1901.00279}, 2019.

\bibitem[Kellerer et~al.(2004)Kellerer, Pferschy, and Pisinger]{book/knapsack}
Kellerer, H., Pferschy, U., and Pisinger, D.
\newblock \emph{Knapsack Problems}.
\newblock Springer, Berlin, Germany, 2004.

\bibitem[Krizhevsky(2009)]{dataset/cifar}
Krizhevsky, A.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, Department of Computer Science, University of
  Toronto, 2009.

\bibitem[Li et~al.(2016)Li, Kadav, Durdanovic, Samet, and Graf]{corr/LiKDSG16}
Li, H., Kadav, A., Durdanovic, I., Samet, H., and Graf, H.~P.
\newblock Pruning filters for efficient convnets.
\newblock \emph{CoRR}, abs/1608.08710, 2016.

\bibitem[Liang et~al.(2018)Liang, Sun, Lee, and Srikant]{nips/elim_one}
Liang, S., Sun, R., Lee, J.~D., and Srikant, R.
\newblock Adding one neuron can eliminate all bad local minima.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pp.\  4355--4365. Curran Associates, Inc., 2018.

\bibitem[Liu et~al.(2017)Liu, Li, Shen, Huang, Yan, and Zhang]{iccv/slimming}
Liu, Z., Li, J., Shen, Z., Huang, G., Yan, S., and Zhang, C.
\newblock Learning efficient convolutional networks through network slimming.
\newblock In \emph{IEEE International Conference on Computer Vision (ICCV)},
  pp.\  2755--2763. IEEE, 2017.

\bibitem[Louizos et~al.(2017)Louizos, Ullrich, and Welling]{nips/bcdeep}
Louizos, C., Ullrich, K., and Welling, M.
\newblock Bayesian compression for deep learning.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pp.\  3290--3300, 2017.

\bibitem[Louizos et~al.(2018)Louizos, Welling, and Kingma]{iclr/l0}
Louizos, C., Welling, M., and Kingma, D.~P.
\newblock Learning sparse neural networks through {$L_0$} regularization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.
\newblock URL \url{https://openreview.net/forum?id=H1Y8hhg0b}.

\bibitem[Luo et~al.(2018)Luo, Tian, Qin, Chen, and Liu]{nips/naonet}
Luo, R., Tian, F., Qin, T., Chen, E., and Liu, T.-Y.
\newblock Neural architecture optimization.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pp.\  7827--7838, 2018.

\bibitem[Ma et~al.(2018)Ma, Zhang, Zheng, and Sun]{eccv/shuffle_v2}
Ma, N., Zhang, X., Zheng, H.-T., and Sun, J.
\newblock Shufflenet v2: Practical guidelines for efficient cnn architecture
  design.
\newblock In \emph{The European Conference on Computer Vision (ECCV)},
  September 2018.

\bibitem[Molchanov et~al.(2017)Molchanov, Ashukha, and Vetrov]{icml/vd_sparse}
Molchanov, D., Ashukha, A., and Vetrov, D.
\newblock Variational dropout sparsifies deep neural networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  2498--2507, 2017.

\bibitem[Nair \& Hinton(2010)Nair and Hinton]{icml/relu}
Nair, V. and Hinton, G.~E.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  807--814. Omnipress, 2010.

\bibitem[Neklyudov et~al.(2017)Neklyudov, Molchanov, Ashukha, and
  Vetrov]{nips/sbp}
Neklyudov, K., Molchanov, D., Ashukha, A., and Vetrov, D.~P.
\newblock Structured bayesian pruning via log-normal multiplicative noise.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pp.\  6778--6787, 2017.

\bibitem[Novikov et~al.(2015)Novikov, Podoprikhin, Osokin, and
  Vetrov]{nips/tensorizing}
Novikov, A., Podoprikhin, D., Osokin, A., and Vetrov, D.~P.
\newblock Tensorizing neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pp.\  442--450, 2015.

\bibitem[Raidl \& Gottlieb(2005)Raidl and Gottlieb]{ec/evol_knapsack}
Raidl, G.~R. and Gottlieb, J.
\newblock Empirical analysis of locality, heritability and heuristic bias in
  evolutionary algorithms: A case study for the multidimensional knapsack
  problem.
\newblock \emph{Evolutionary Computation}, 13\penalty0 (4):\penalty0 441--475,
  2005.

\bibitem[Rastegari et~al.(2016)Rastegari, Ordonez, Redmon, and
  Farhadi]{eccv/xnornet}
Rastegari, M., Ordonez, V., Redmon, J., and Farhadi, A.
\newblock {XNOR}-{N}et: Imagenet classification using binary convolutional
  neural networks.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, pp.\
  525--542. Springer, 2016.

\bibitem[Real et~al.(2018)Real, Aggarwal, Huang, and Le]{corr/amoebanet}
Real, E., Aggarwal, A., Huang, Y., and Le, Q.~V.
\newblock Regularized evolution for image classifier architecture search.
\newblock \emph{CoRR}, abs/1802.01548, 2018.
\newblock URL \url{http://arxiv.org/abs/1802.01548}.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and Fei-Fei]{dataset/ilsvrc}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., Berg, A.~C., and Fei-Fei, L.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock \emph{International Journal of Computer Vision (IJCV)}, 115\penalty0
  (3):\penalty0 211--252, 2015.
\newblock \doi{10.1007/s11263-015-0816-y}.

\bibitem[Sahay et~al.(2011{\natexlab{a}})Sahay, Scobie, Hill, O'carroll,
  Kheirbek, Burghardt, Fenton, Dranovsky, and Hen]{nature/increasing}
Sahay, A., Scobie, K.~N., Hill, A.~S., O'carroll, C.~M., Kheirbek, M.~A.,
  Burghardt, N.~S., Fenton, A.~A., Dranovsky, A., and Hen, R.
\newblock Increasing adult hippocampal neurogenesis is sufficient to improve
  pattern separation.
\newblock \emph{Nature}, 472\penalty0 (7344):\penalty0 466, 2011{\natexlab{a}}.

\bibitem[Sahay et~al.(2011{\natexlab{b}})Sahay, Wilson, and
  Hen]{nature/pattern}
Sahay, A., Wilson, D.~A., and Hen, R.
\newblock Pattern separation: a common function for new neurons in hippocampus
  and olfactory bulb.
\newblock \emph{Neuron}, 70\penalty0 (4):\penalty0 582--588,
  2011{\natexlab{b}}.

\bibitem[Sandler et~al.(2018)Sandler, Howard, Zhu, Zhmoginov, and
  Chen]{cvpr/mobilenetv2}
Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., and Chen, L.-C.
\newblock Mobilenetv2: Inverted residuals and linear bottlenecks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp.\  4510--4520, 2018.

\bibitem[Selvaraju et~al.(2017)Selvaraju, Cogswell, Das, Vedantam, Parikh,
  Batra, et~al.]{iccv/grad_cam}
Selvaraju, R.~R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D.,
  et~al.
\newblock {Grad-CAM}: Visual explanations from deep networks via gradient-based
  localization.
\newblock In \emph{IEEE International Conference on Computer Vision (ICCV)},
  pp.\  618--626, 2017.

\bibitem[Simonyan \& Zisserman(2014)Simonyan and Zisserman]{corr/vggnet}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{CoRR}, abs/1409.1556, 2014.
\newblock URL \url{http://arxiv.org/abs/1409.1556}.

\bibitem[Sun et~al.(2018)Sun, Li, Liu, and Wang]{corr/igcv3}
Sun, K., Li, M., Liu, D., and Wang, J.
\newblock {IGCV3}: Interleaved low-rank group convolutions for efficient deep
  neural networks.
\newblock \emph{CoRR}, abs/1806.00178, 2018.
\newblock URL \url{http://arxiv.org/abs/1806.00178}.

\bibitem[Szegedy et~al.(2015)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{cvpr/inception}
Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.~E., Anguelov, D., Erhan,
  D., Vanhoucke, V., and Rabinovich, A.
\newblock Going deeper with convolutions.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp.\  1--9. {IEEE} Computer Society, 2015.

\bibitem[Vasquez \& Vimont(2005)Vasquez and Vimont]{ejor/improved_knapsack}
Vasquez, M. and Vimont, Y.
\newblock Improved results on the 0--1 multidimensional knapsack problem.
\newblock \emph{European Journal of Operational Research}, 165\penalty0
  (1):\penalty0 70--81, 2005.

\bibitem[Wen et~al.(2016)Wen, Wu, Wang, Chen, and Li]{nips/ssl}
Wen, W., Wu, C., Wang, Y., Chen, Y., and Li, H.
\newblock Learning structured sparsity in deep neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pp.\  2074--2082, 2016.

\bibitem[Wu et~al.(2018)Wu, Wan, Yue, Jin, Zhao, Golmant, Gholaminejad,
  Gonzalez, and Keutzer]{cvpr/shift}
Wu, B., Wan, A., Yue, X., Jin, P., Zhao, S., Golmant, N., Gholaminejad, A.,
  Gonzalez, J., and Keutzer, K.
\newblock Shift: A zero flop, zero parameter alternative to spatial
  convolutions.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp.\  9127--9135, 2018.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{dataset/fmnist}
Xiao, H., Rasul, K., and Vollgraf, R.
\newblock {Fashion-MNIST}: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock \emph{CoRR}, abs/1708.07747, 2017.
\newblock URL \url{http://arxiv.org/abs/1708.07747}.

\bibitem[Xie et~al.(2017)Xie, Girshick, Doll{\'{a}}r, Tu, and He]{cvpr/resnext}
Xie, S., Girshick, R.~B., Doll{\'{a}}r, P., Tu, Z., and He, K.
\newblock Aggregated residual transformations for deep neural networks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp.\  5987--5995. {IEEE} Computer Society, 2017.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and Komodakis]{bmvc/wide}
Zagoruyko, S. and Komodakis, N.
\newblock Wide residual networks.
\newblock In \emph{Proceedings of the British Machine Vision Conference
  (BMVC)}. {BMVA} Press, 2016.

\bibitem[Zhang et~al.(2017)Zhang, Qi, Xiao, and Wang]{iccv/interleaved}
Zhang, T., Qi, G.-J., Xiao, B., and Wang, J.
\newblock Interleaved group convolutions.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision (ICCV)}, pp.\  4373--4382, 2017.

\bibitem[Zhang et~al.(2018)Zhang, Zhou, Lin, and Sun]{cvpr/shufflenet}
Zhang, X., Zhou, X., Lin, M., and Sun, J.
\newblock Shufflenet: An extremely efficient convolutional neural network for
  mobile devices.
\newblock In \emph{The IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2018.

\bibitem[Zoph et~al.(2018)Zoph, Vasudevan, Shlens, and Le]{cvpr/nasnet}
Zoph, B., Vasudevan, V., Shlens, J., and Le, Q.~V.
\newblock Learning transferable architectures for scalable image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp.\  8697--8710, 2018.

\end{thebibliography}
