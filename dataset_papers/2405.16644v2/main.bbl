\begin{thebibliography}{10}

\bibitem{aguech2000perturbation}
Rafik Aguech, Eric Moulines, and Pierre Priouret.
\newblock On a perturbation approach for the analysis of stochastic tracking
  algorithms.
\newblock {\em SIAM Journal on Control and Optimization}, 39(3):872--899, 2000.

\bibitem{pmlr-v99-anastasiou19a}
Andreas Anastasiou, Krishnakumar Balasubramanian, and Murat~A. Erdogdu.
\newblock Normal approximation for stochastic gradient descent via
  non-asymptotic rates of martingale {CLT}.
\newblock In Alina Beygelzimer and Daniel Hsu, editors, {\em Proceedings of the
  Thirty-Second Conference on Learning Theory}, volume~99 of {\em Proceedings
  of Machine Learning Research}, pages 115--137. PMLR, 25--28 Jun 2019.

\bibitem{archibald1995generation}
TW~Archibald, KIM McKinnon, and LC~Thomas.
\newblock On the generation of markov decision processes.
\newblock {\em Journal of the Operational Research Society}, 46(3):354--361,
  1995.

\bibitem{auer2002finite}
Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock {\em Machine learning}, 47:235--256, 2002.

\bibitem{bach:moulines:2013}
F.~Bach and E.~Moulines.
\newblock Non-strongly-convex smooth stochastic approximation with convergence
  rate o(1/n).
\newblock In C.~J.~C. Burges, L.~Bottou, M.~Welling, Z.~Ghahramani, and K.~Q.
  Weinberger, editors, {\em Advances in Neural Information Processing Systems},
  volume~26. Curran Associates, Inc., 2013.

\bibitem{benveniste2012adaptive}
A.~Benveniste, M.~M{\'e}tivier, and P.~Priouret.
\newblock {\em Adaptive algorithms and stochastic approximations}, volume~22.
\newblock Springer Science \& Business Media, 2012.

\bibitem{bhandari2018finite}
J.~Bhandari, D.~Russo, and R.~Singal.
\newblock A finite time analysis of temporal difference learning with linear
  function approximation.
\newblock In {\em Conference On Learning Theory}, pages 1691--1692, 2018.

\bibitem{bolthausen1982}
E.~Bolthausen.
\newblock {Exact Convergence Rates in Some Martingale Central Limit Theorems}.
\newblock {\em The Annals of Probability}, 10(3):672 -- 688, 1982.

\bibitem{borkar:sa:2008}
Vivek~S Borkar.
\newblock {\em Stochastic Approximation: A Dynamical Systems Viewpoint}.
\newblock Cambridge University Press, 2008.

\bibitem{brosse2018pitfalls}
Nicolas Brosse, Alain Durmus, and Eric Moulines.
\newblock The promises and pitfalls of stochastic gradient langevin dynamics.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, {\em Advances in Neural Information Processing
  Systems}, volume~31. Curran Associates, Inc., 2018.

\bibitem{chen2020aos}
Xi~Chen, Jason~D. Lee, Xin~T. Tong, and Yichen Zhang.
\newblock {Statistical inference for model parameters in stochastic gradient
  descent}.
\newblock {\em The Annals of Statistics}, 48(1):251 -- 273, 2020.

\bibitem{Chernozhukov2013}
Victor Chernozhukov, Denis Chetverikov, and Kengo Kato.
\newblock Gaussian approximations and multiplier bootstrap for maxima of sums
  of high-dimensional random vectors.
\newblock {\em Ann. Statist.}, 41(6):2786--2819, 2013.

\bibitem{Chernozhukov2015}
Victor Chernozhukov, Denis Chetverikov, and Kengo Kato.
\newblock Central limit theorems and bootstrap in high dimensions.
\newblock {\em Ann. Probab.}, 45(4):2309--2352, 2017.

\bibitem{dalal2019tale}
G.~Dalal, Balazs Szorenyi, and G.~Thoppe.
\newblock A tale of two-timescale reinforcement learning with the tightest
  finite-time bound.
\newblock {\em arXiv preprint arXiv:1911.09157}, 2019.

\bibitem{duchi2012ergodic}
John~C Duchi, Alekh Agarwal, Mikael Johansson, and Michael~I Jordan.
\newblock Ergodic mirror descent.
\newblock {\em SIAM Journal on Optimization}, 22(4):1549--1578, 2012.

\bibitem{durmus2022finite}
Alain Durmus, Eric Moulines, Alexey Naumov, and Sergey Samsonov.
\newblock Finite-time high-probability bounds for {P}olyak-{R}uppert averaged
  iterates of linear stochastic approximation.
\newblock {\em Mathematics of Operations Research}, 2024.

\bibitem{durmus2021tight}
Alain Durmus, Eric Moulines, Alexey Naumov, Sergey Samsonov, Kevin Scaman, and
  Hoi-To Wai.
\newblock Tight high probability bounds for linear stochastic approximation
  with fixed stepsize.
\newblock In M.~Ranzato, A.~Beygelzimer, K.~Nguyen, P.~S. Liang, J.~W. Vaughan,
  and Y.~Dauphin, editors, {\em Advances in Neural Information Processing
  Systems}, volume~34, pages 30063--30074. Curran Associates, Inc., 2021.

\bibitem{durmus2021stability}
Alain Durmus, Eric Moulines, Alexey Naumov, Sergey Samsonov, and Hoi-To Wai.
\newblock On the stability of random matrix product with markovian noise:
  Application to linear stochastic approximation and td learning.
\newblock In Mikhail Belkin and Samory Kpotufe, editors, {\em Proceedings of
  Thirty Fourth Conference on Learning Theory}, volume 134 of {\em Proceedings
  of Machine Learning Research}, pages 1711--1752. PMLR, 15--19 Aug 2021.

\bibitem{efron1992bootstrap}
Bradley Efron.
\newblock Bootstrap methods: another look at the jackknife.
\newblock In {\em Breakthroughs in statistics: Methodology and distribution},
  pages 569--593. Springer, 1992.

\bibitem{esseen1945}
Carl-Gustav Esseen.
\newblock {Fourier analysis of distribution functions. A mathematical study of
  the Laplace-Gaussian law}.
\newblock {\em Acta Mathematica}, 77(none):1 -- 125, 1945.

\bibitem{eweda:macchi:1983}
E.~Eweda and O.~Macchi.
\newblock Quadratic mean and almost-sure convergence of unbounded stochastic
  approximation algorithms with correlated observations.
\newblock {\em Ann. Inst. H. Poincar\'{e} Sect. B (N.S.)}, 19(3):235--255,
  1983.

\bibitem{JMLR:v19:17-370}
Yixin Fang, Jinfeng Xu, and Lei Yang.
\newblock Online bootstrap confidence intervals for the stochastic gradient
  descent estimator.
\newblock {\em Journal of Machine Learning Research}, 19(78):1--21, 2018.

\bibitem{fort:clt:markov:2015}
{G. Fort}.
\newblock Central limit theorems for stochastic approximation with controlled
  {M}arkov chain dynamics.
\newblock {\em ESAIM: PS}, 19:60--80, 2015.

\bibitem{gaunt2023bounding}
Robert~E Gaunt and Siqi Li.
\newblock Bounding {K}olmogorov distances through {W}asserstein and related
  integral probability metrics.
\newblock {\em Journal of Mathematical Analysis and Applications},
  522(1):126985, 2023.

\bibitem{geist2014off}
Matthieu Geist, Bruno Scherrer, et~al.
\newblock Off-policy learning with eligibility traces: a survey.
\newblock {\em J. Mach. Learn. Res.}, 15(1):289--333, 2014.

\bibitem{GoodBengCour16}
Ian~J. Goodfellow, Yoshua Bengio, and Aaron Courville.
\newblock {\em Deep Learning}.
\newblock MIT Press, Cambridge, MA, USA, 2016.
\newblock \url{http://www.deeplearningbook.org}.

\bibitem{Bernolli2019}
Friedrich G\"{o}tze, Alexey Naumov, Vladimir Spokoiny, and Vladimir Ulyanov.
\newblock Large ball probabilities, {G}aussian comparison and
  anti-concentration.
\newblock {\em Bernoulli}, 25(4A):2538--2563, 2019.

\bibitem{hao2019_bootstrap_ucb}
Botao Hao, Yasin Abbasi~Yadkori, Zheng Wen, and Guang Cheng.
\newblock Bootstrapping upper confidence bound.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, {\em Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.

\bibitem{huang2020matrix}
De~Huang, Jonathan Niles-Weed, Joel~A Tropp, and Rachel Ward.
\newblock Matrix concentration for products.
\newblock {\em Foundations of Computational Mathematics}, pages 1--33, 2021.

\bibitem{huo2023bias}
Dongyan Huo, Yudong Chen, and Qiaomin Xie.
\newblock Bias and extrapolation in markovian linear stochastic approximation
  with constant stepsizes.
\newblock In {\em Abstract Proceedings of the 2023 ACM SIGMETRICS International
  Conference on Measurement and Modeling of Computer Systems}, pages 81--82,
  2023.

\bibitem{jirak2022quantitative}
Moritz Jirak and Martin Wahl.
\newblock Quantitative limit theorems and bootstrap approximations for
  empirical spectral projectors.
\newblock {\em Probability Theory and Related Fields}, 190(1):119--177, 2024.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{kostenetskiy2021hpc}
PS~Kostenetskiy, RA~Chulkevich, and VI~Kozyrev.
\newblock Hpc resources of the higher school of economics.
\newblock In {\em Journal of Physics: Conference Series}, volume 1740, page
  012050. IOP Publishing, 2021.

\bibitem{kushner2003stochastic}
Harold Kushner and G~George Yin.
\newblock {\em Stochastic approximation and recursive algorithms and
  applications}, volume~35.
\newblock Springer Science \& Business Media, 2003.

\bibitem{lakshminarayanan2018linear}
C.~Lakshminarayanan and C.~Szepesvari.
\newblock Linear stochastic approximation: How far does constant step-size and
  iterate averaging go?
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 1347--1355, 2018.

\bibitem{lan2012optimal}
Guanghui Lan.
\newblock An optimal method for stochastic composite optimization.
\newblock {\em Mathematical Programming}, 133(1-2):365--397, 2012.

\bibitem{LEE2024105673}
Sokbae Lee, Yuan Liao, Myung~Hwan Seo, and Youngki Shin.
\newblock Fast inference for quantile regression with tens of millions of
  observations.
\newblock {\em Journal of Econometrics}, page 105673, 2024.

\bibitem{li2023sharp}
Gen Li, Weichen Wu, Yuejie Chi, Cong Ma, Alessandro Rinaldo, and Yuting Wei.
\newblock High-probability sample complexities for policy evaluation with
  linear function approximation.
\newblock {\em IEEE Transactions on Information Theory}, 70(8):5969--5999,
  2024.

\bibitem{pmlr-v178-li22b}
Xiang Li, Jiadong Liang, Xiangyu Chang, and Zhihua Zhang.
\newblock Statistical estimation and online inference via local sgd.
\newblock In Po-Ling Loh and Maxim Raginsky, editors, {\em Proceedings of
  Thirty Fifth Conference on Learning Theory}, volume 178 of {\em Proceedings
  of Machine Learning Research}, pages 1613--1661. PMLR, 02--05 Jul 2022.

\bibitem{li2023online}
Xiang Li, Jiadong Liang, and Zhihua Zhang.
\newblock Online statistical inference for nonlinear stochastic approximation
  with {M}arkovian data.
\newblock {\em arXiv preprint arXiv:2302.07690}, 2023.

\bibitem{li2023statistical}
Xiang Li, Wenhao Yang, Jiadong Liang, Zhihua Zhang, and Michael~I Jordan.
\newblock A statistical analysis of {P}olyak-{R}uppert averaged {Q}-learning.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 2207--2261. PMLR, 2023.

\bibitem{mnih2015}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A. Rusu, Joel Veness,
  Marc~G. Bellemare, Alex Graves, Martin Riedmiller, Andreas~K. Fidjeland,
  Georg Ostrovski, Stig Petersen, Charles Beattie, Amir Sadik, Ioannis
  Antonoglou, Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg, and
  Demis Hassabis.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 518(7540):529--533, 2015.

\bibitem{mou2020linear}
Wenlong Mou, Chris~Junchi Li, Martin~J Wainwright, Peter~L Bartlett, and
  Michael~I Jordan.
\newblock On linear stochastic approximation: {F}ine-grained {P}olyak-{R}uppert
  and non-asymptotic concentration.
\newblock In {\em Conference on Learning Theory}, pages 2947--2997. PMLR, 2020.

\bibitem{mou2021optimal}
Wenlong Mou, Ashwin Pananjady, Martin~J Wainwright, and Peter~L Bartlett.
\newblock Optimal and instance-dependent guarantees for markovian linear
  stochastic approximation.
\newblock {\em Mathematical Statistics and Learning}, 7(1):41--153, 2024.

\bibitem{moulines2011non}
Eric Moulines and Francis Bach.
\newblock Non-asymptotic analysis of stochastic approximation algorithms for
  machine learning.
\newblock {\em Advances in neural information processing systems}, 24:451--459,
  2011.

\bibitem{PTRF2019}
Alexey Naumov, Vladimir Spokoiny, and Vladimir Ulyanov.
\newblock Bootstrap confidence sets for spectral projectors of sample
  covariance.
\newblock {\em Probab. Theory Related Fields}, 174(3-4):1091--1132, 2019.

\bibitem{nemirovski2009robust}
Arkadi Nemirovski, Anatoli Juditsky, Guanghui Lan, and Alexander Shapiro.
\newblock Robust stochastic approximation approach to stochastic programming.
\newblock {\em SIAM Journal on optimization}, 19(4):1574--1609, 2009.

\bibitem{nemirovskij1983problem}
Arkadij~Semenovi{\v{c}} Nemirovskij and David~Borisovich Yudin.
\newblock Problem complexity and method efficiency in optimization.
\newblock 1983.

\bibitem{nourdin2022multivariate}
Ivan Nourdin, Giovanni Peccati, and Xiaochuan Yang.
\newblock Multivariate normal approximation on the wiener space: new bounds in
  the convex distance.
\newblock {\em Journal of Theoretical Probability}, 35(3):2020--2037, 2022.

\bibitem{osekowski:2012}
A.~Osekowski.
\newblock {\em Sharp Martingale and Semimartingale Inequalities}.
\newblock Monografie Matematyczne 72. Birkhäuser Basel, 1 edition, 2012.

\bibitem{patil2023finite}
Gandharv Patil, LA~Prashanth, Dheeraj Nagaraj, and Doina Precup.
\newblock Finite time analysis of temporal difference learning with linear
  function approximation: Tail averaging and regularisation.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 5438--5448. PMLR, 2023.

\bibitem{petrov1975sums}
V.~Petrov.
\newblock {\em Sums of Independent Random Variables}.
\newblock Ergebnisse der Mathematik und ihrer Grenzgebiete. 2. Folge. Springer
  Berlin Heidelberg, 1975.

\bibitem{polyak1992acceleration}
Boris~T Polyak and Anatoli~B Juditsky.
\newblock Acceleration of stochastic approximation by averaging.
\newblock {\em SIAM journal on control and optimization}, 30(4):838--855, 1992.

\bibitem{poznyak:control}
A.~S. Poznyak.
\newblock {\em Advanced Mathematical Tools for Automatic Control Engineers:
  Deterministic Techniques}.
\newblock Elsevier, Oxford, 2008.

\bibitem{rakhlin2012making}
Alexander Rakhlin, Ohad Shamir, and Karthik Sridharan.
\newblock Making gradient descent optimal for strongly convex stochastic
  optimization.
\newblock In {\em Proceedings of the 29th International Coference on
  International Conference on Machine Learning}, pages 1571--1578, 2012.

\bibitem{JASA2023}
Pratik Ramprasad, Yuantong Li, Zhuoran Yang, Zhaoran Wang, Will~Wei Sun, and
  Guang Cheng.
\newblock Online bootstrap inference for policy evaluation in reinforcement
  learning.
\newblock {\em J. Amer. Statist. Assoc.}, 118(544):2901--2914, 2023.

\bibitem{ross2011stein}
Nathan Ross.
\newblock {Fundamentals of Stein's method}.
\newblock {\em Probability Surveys}, 8(none):210 -- 293, 2011.

\bibitem{rubin1981bayesian}
Donald~B Rubin.
\newblock The bayesian bootstrap.
\newblock {\em The annals of statistics}, pages 130--134, 1981.

\bibitem{ruppert1988efficient}
David Ruppert.
\newblock Efficient estimations from a slowly convergent robbins-monro process.
\newblock Technical report, Cornell University Operations Research and
  Industrial Engineering, 1988.

\bibitem{russo2014learning}
Daniel Russo and Benjamin Van~Roy.
\newblock Learning to optimize via posterior sampling.
\newblock {\em Mathematics of Operations Research}, 39(4):1221--1243, 2014.

\bibitem{samsonov2023finite}
Sergey Samsonov, Daniil Tiapkin, Alexey Naumov, and Eric Moulines.
\newblock Improved {H}igh-{P}robability {B}ounds for the {T}emporal
  {D}ifference {L}earning {A}lgorithm via {E}xponential {S}tability.
\newblock In Shipra Agrawal and Aaron Roth, editors, {\em Proceedings of Thirty
  Seventh Conference on Learning Theory}, volume 247 of {\em Proceedings of
  Machine Learning Research}, pages 4511--4547. PMLR, 30 Jun--03 Jul 2024.

\bibitem{shao2003mathematical}
Jun Shao.
\newblock {\em Mathematical statistics}.
\newblock Springer Science \& Business Media, 2003.

\bibitem{shao2022berry}
Qi-Man Shao and Zhuo-Song Zhang.
\newblock Berry--{E}sseen bounds for multivariate nonlinear statistics with
  applications to {M}-estimators and stochastic gradient descent algorithms.
\newblock {\em Bernoulli}, 28(3):1548--1576, 2022.

\bibitem{spokoiny2015}
Vladimir Spokoiny and Mayya Zhilova.
\newblock {Bootstrap confidence sets under model misspecification}.
\newblock {\em The Annals of Statistics}, 43(6):2653 -- 2675, 2015.

\bibitem{srikant2024rates}
R~Srikant.
\newblock Rates of convergence in the central limit theorem for markov chains,
  with an application to {TD} learning.
\newblock {\em arXiv preprint arXiv:2401.15719}, 2024.

\bibitem{sutton1988learning}
R.~S Sutton.
\newblock Learning to predict by the methods of temporal differences.
\newblock {\em Machine learning}, 3(1):9--44, 1988.

\bibitem{sutton:book:2018}
R.~S. Sutton and Andrew~G. Barto.
\newblock {\em Reinforcement Learning: An Introduction}.
\newblock The MIT Press, second edition, 2018.

\bibitem{MR2802042}
Joel~A. Tropp.
\newblock Freedman's inequality for matrix martingales.
\newblock {\em Electron. Commun. Probab.}, 16:262--270, 2011.

\bibitem{tropp2015introduction}
Joel~A Tropp et~al.
\newblock An introduction to matrix concentration inequalities.
\newblock {\em Foundations and Trends{\textregistered} in Machine Learning},
  8(1-2):1--230, 2015.

\bibitem{tsitsiklis:td:1997}
J.~N. {Tsitsiklis} and B.~{Van Roy}.
\newblock An analysis of temporal-difference learning with function
  approximation.
\newblock {\em IEEE Transactions on Automatic Control}, 42(5):674--690, May
  1997.

\bibitem{van1996weak}
A.~W. Van Der~Vaart and J.~A. Wellner.
\newblock {\em Weak convergence and empirical processes}.
\newblock Springer Series in Statistics, 1996.

\bibitem{vapnik2013nature}
Vladimir Vapnik.
\newblock {\em The nature of statistical learning theory}.
\newblock Springer science \& business media, 2013.

\bibitem{zhu2023online_cov_matr}
Xi~Chen Wanrong~Zhu and Wei~Biao Wu.
\newblock Online {C}ovariance {M}atrix {E}stimation in {S}tochastic {G}radient
  {D}escent.
\newblock {\em Journal of the American Statistical Association},
  118(541):393--404, 2023.

\bibitem{zhong2023online}
Yanjie Zhong, Todd Kuffner, and Soumendra Lahiri.
\newblock Online {B}ootstrap {I}nference with {N}onconvex {S}tochastic
  {G}radient {D}escent {E}stimator.
\newblock {\em arXiv preprint arXiv:2306.02205}, 2023.

\bibitem{zolotarev1984probability}
Vladimir~Mikhailovich Zolotarev.
\newblock Probability metrics.
\newblock {\em Theory of Probability \& Its Applications}, 28(2):278--302,
  1984.

\end{thebibliography}
