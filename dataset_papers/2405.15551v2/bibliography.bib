@inproceedings{panchal2023flash,
  title={Flash: concept drift adaptation in federated learning},
  author={Panchal, Kunjal and Choudhary, Sunav and Mitra, Subrata and Mukherjee, Koyel and Sarkhel, Somdeb and Mitra, Saayan and Guan, Hui},
  booktitle={International Conference on Machine Learning},
  pages={26931--26962},
  year={2023},
  organization={PMLR}
}
@article{kairouz2021open,
  author={Peter Kairouz and H. Brendan McMahan and Brendan Avent and Aurélien Bellet and Mehdi Bennis and Arjun Nitin Bhagoji and Kallista A. Bonawitz and Zachary Charles and Graham Cormode and Rachel Cummings and Rafael G. L. D'Oliveira and Hubert Eichner and Salim El Rouayheb and David Evans and Josh Gardner and Zachary Garrett and Adrià Gascón and Badih Ghazi and Phillip B. Gibbons and Marco Gruteser and Zaïd Harchaoui and Chaoyang He and Lie He and Zhouyuan Huo and Ben Hutchinson and Justin Hsu and Martin Jaggi and Tara Javidi and Gauri Joshi and Mikhail Khodak and Jakub Konecný and Aleksandra Korolova and Farinaz Koushanfar and Sanmi Koyejo and Tancrède Lepoint and Yang Liu and Prateek Mittal and Mehryar Mohri and Richard Nock and Ayfer Özgür and Rasmus Pagh and Hang Qi and Daniel Ramage and Ramesh Raskar and Mariana Raykova and Dawn Song and Weikang Song and Sebastian U. Stich and Ziteng Sun and Ananda Theertha Suresh and Florian Tramèr and Praneeth Vepakomma and Jianyu Wang and Li Xiong and Zheng Xu and Qiang Yang and Felix X. Yu and Han Yu and Sen Zhao},
  title={Advances and Open Problems in Federated Learning},
  year={2021},
  journal={Foundations and Trends in Machine Learning},
}

@inproceedings{
malladi2023mezo,
title={Fine-Tuning Language Models with Just Forward Passes},
author={Sadhika Malladi and Tianyu Gao and Eshaan Nichani and Alex Damian and Jason D. Lee and Danqi Chen and Sanjeev Arora},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
}

@misc{feng2023does,
      title={Does Federated Learning Really Need Backpropagation?}, 
      author={Haozhe Feng and Tianyu Pang and Chao Du and Wei Chen and Shuicheng Yan and Min Lin},
      year={2023},
      eprint={2301.12195},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{openai2024gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
      year={2024},
      journal={arXiv 2303.08774},
}

@article{anil2023palm,
      title={PaLM 2 Technical Report}, 
      author={Rohan Anil and Andrew M. Dai and Orhan Firat and Melvin Johnson and Dmitry Lepikhin and Alexandre Passos and Siamak Shakeri and Emanuel Taropa and Paige Bailey and Zhifeng Chen and Eric Chu and Jonathan H. Clark and Laurent El Shafey and Yanping Huang and Kathy Meier-Hellstern and Gaurav Mishra and Erica Moreira and Mark Omernick and Kevin Robinson and Sebastian Ruder and Yi Tay and Kefan Xiao and Yuanzhong Xu and Yujing Zhang and Gustavo Hernandez Abrego and Junwhan Ahn and Jacob Austin and Paul Barham and Jan Botha and James Bradbury and Siddhartha Brahma and Kevin Brooks and Michele Catasta and Yong Cheng and Colin Cherry and Christopher A. Choquette-Choo and Aakanksha Chowdhery and Clément Crepy and Shachi Dave and Mostafa Dehghani and Sunipa Dev and Jacob Devlin and Mark Díaz and Nan Du and Ethan Dyer and Vlad Feinberg and Fangxiaoyu Feng and Vlad Fienber and Markus Freitag and Xavier Garcia and Sebastian Gehrmann and Lucas Gonzalez and Guy Gur-Ari and Steven Hand and Hadi Hashemi and Le Hou and Joshua Howland and Andrea Hu and Jeffrey Hui and Jeremy Hurwitz and Michael Isard and Abe Ittycheriah and Matthew Jagielski and Wenhao Jia and Kathleen Kenealy and Maxim Krikun and Sneha Kudugunta and Chang Lan and Katherine Lee and Benjamin Lee and Eric Li and Music Li and Wei Li and YaGuang Li and Jian Li and Hyeontaek Lim and Hanzhao Lin and Zhongtao Liu and Frederick Liu and Marcello Maggioni and Aroma Mahendru and Joshua Maynez and Vedant Misra and Maysam Moussalem and Zachary Nado and John Nham and Eric Ni and Andrew Nystrom and Alicia Parrish and Marie Pellat and Martin Polacek and Alex Polozov and Reiner Pope and Siyuan Qiao and Emily Reif and Bryan Richter and Parker Riley and Alex Castro Ros and Aurko Roy and Brennan Saeta and Rajkumar Samuel and Renee Shelby and Ambrose Slone and Daniel Smilkov and David R. So and Daniel Sohn and Simon Tokumine and Dasha Valter and Vijay Vasudevan and Kiran Vodrahalli and Xuezhi Wang and Pidong Wang and Zirui Wang and Tao Wang and John Wieting and Yuhuai Wu and Kelvin Xu and Yunhan Xu and Linting Xue and Pengcheng Yin and Jiahui Yu and Qiao Zhang and Steven Zheng and Ce Zheng and Weikang Zhou and Denny Zhou and Slav Petrov and Yonghui Wu},
      year={2023},
      journal={arXiv 2305.10403},
}

@inproceedings{narayanan2021efficient,
author = {Narayanan, Deepak and Shoeybi, Mohammad and Casper, Jared and LeGresley, Patrick and Patwary, Mostofa and Korthikanti, Vijay and Vainbrand, Dmitri and Kashinkunti, Prethvi and Bernauer, Julie and Catanzaro, Bryan and Phanishayee, Amar and Zaharia, Matei},
title = {Efficient large-scale language model training on GPU clusters using megatron-LM},
year = {2021},
publisher = {Association for Computing Machinery},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
}

@inproceedings{brown2020gpt3,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Language Models are Few-Shot Learners},
 year = {2020}
}

@article{touvron2023llama,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      journal={arXiv 2307.09288},
}


@article{chuang2022military,
author = {Chuang, Hsiu-Min and Cheng, Ding-Wei},
title = {Conversational AI over Military Scenarios Using Intent Detection and Response Generation},
journal = {Applied Sciences},
year = {2022},
}

@article{huber2024leveraging,
  title={Leveraging the Potential of Large Language Models in Education Through Playful and Game-Based Learning},
  author={Huber, Stefan E and Kiili, Kristian and Nebel, Steve and Ryan, Richard M and Sailer, Michael and Ninaus, Manuel},
  journal={Educational Psychology Review},
  year={2024},
  publisher={Springer}
}

@inproceedings{
hu2022lora,
title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
author={Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
booktitle={International Conference on Learning Representations},
year={2022},
}

@inproceedings{liu2022ia3,
 author = {Liu, Haokun and Tam, Derek and Muqeeth, Mohammed and Mohta, Jay and Huang, Tenghao and Bansal, Mohit and Raffel, Colin A},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning},
 year = {2022}
}

@inproceedings{li2021prefixtuning,
    title = "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
    author = "Li, Xiang Lisa  and
      Liang, Percy",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    year = "2021",
    publisher = "Association for Computational Linguistics",
}

@inproceedings{
qiu2023oft,
title={Controlling Text-to-Image Diffusion by Orthogonal Finetuning},
author={Zeju Qiu and Weiyang Liu and Haiwen Feng and Yuxuan Xue and Yao Feng and Zhen Liu and Dan Zhang and Adrian Weller and Bernhard Sch{\"o}lkopf},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
}

@article{baydin2017autodiff,
author = {Baydin, At\i{}l\i{}m G\"{u}nes and Pearlmutter, Barak A. and Radul, Alexey Andreyevich and Siskind, Jeffrey Mark},
title = {Automatic differentiation in machine learning: a survey},
year = {2017},
journal = {The Journal of Machine Learning Research},
}

@InProceedings{jacob2018quant,
author = {Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
title = {Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2018}
}

@article{baydin2022gradients,
      title={Gradients without Backpropagation}, 
      author={Atılım Güneş Baydin and Barak A. Pearlmutter and Don Syme and Frank Wood and Philip Torr},
      year={2022},
      journal={arXiv 2202.08587},
}

@InProceedings{macmahan2017aFedLearning,
  title = 	 {{Communication-Efficient Learning of Deep Networks from Decentralized Data}},
  author = 	 {McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Arcas, Blaise Aguera y},
  booktitle = 	 {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
  year = 	 {2017},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
}

@article{dara2022FLiot,
title = {Scalable Federated-Learning and Internet-of-Things enabled architecture for Chest Computer Tomography image classification},
journal = {Computers and Electrical Engineering},
author = {Suresh Dara and Ambedkar Kanapala and A. Ramesh Babu and Swetha Dhamercherala and Ankit Vidyarthi and Ruchi Agarwal},
year={2022},
}

@article{li2022healthiot,
  author={Li, Li and Yu, Xi and Cai, Xuliang and He, Xin and Liu, Yanhong},
  journal={IEEE Internet of Things Journal}, 
  title={Contract Theory Based Incentive Mechanism for Federated Learning in Health CrowdSensing}, 
  year={2022},
}

@article{loftus2022FLHealthcare,
author = {Tyler J Loftus and Matthew M Ruppert and Benjamin Shickel and Tezcan Ozrazgat-Baslanti and Jeremy A Balch and Philip A Efron and 
Gilbert R Upchurch, Jr. and Parisa Rashidi and Christopher Tignanelli and 
Jiang Bian and Azra Bihorac},
title ={Federated learning for preserving data privacy in collaborative healthcare research},
journal = {Digital Health},
year = {2022},
}

@article{guan2024flmedicalsurvey,
title = {Federated learning for medical image analysis: A survey},
journal = {Pattern Recognition},
year = {2024},
author = {Hao Guan and Pew-Thian Yap and Andrea Bozoki and Mingxia Liu},
}

@inproceedings{wu2023personalized,
  title={Personalized federated learning under mixture of distributions},
  author={Wu, Yue and Zhang, Shuaicheng and Yu, Wenchao and Liu, Yanchi and Gu, Quanquan and Zhou, Dawei and Chen, Haifeng and Cheng, Wei},
  booktitle={International Conference on Machine Learning},
  year={2023},
  organization={PMLR}
}

@inproceedings{lin2022fednlp,
    title = "{F}ed{NLP}: Benchmarking Federated Learning Methods for Natural Language Processing Tasks",
    author = "Lin, Bill Yuchen  and
      He, Chaoyang  and
      Ze, Zihang  and
      Wang, Hulin  and
      Hua, Yufen  and
      Dupuy, Christophe  and
      Gupta, Rahul  and
      Soltanolkotabi, Mahdi  and
      Ren, Xiang  and
      Avestimehr, Salman",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2022",
    year = "2022",
    publisher = "Association for Computational Linguistics",
}

@article{tian2022fedbert,
  title={Fedbert: When federated learning meets pre-training},
  author={Tian, Yuanyishu and Wan, Yao and Lyu, Lingjuan and Yao, Dezhong and Jin, Hai and Sun, Lichao},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  year={2022},
}

@article{xu2024fwdllm,
      title={FwdLLM: Efficient FedLLM using Forward Gradient}, 
      author={Mengwei Xu and Dongqi Cai and Yaozong Wu and Xiang Li and Shangguang Wang},
      year={2024},
      journal={arXiv 2308.13894},
}

@inproceedings{cai2023fedadapter,
author = {Cai, Dongqi and Wu, Yaozong and Wang, Shangguang and Xu, Mengwei},
title = {FedAdapter: Efficient Federated Learning for Mobile NLP},
year = {2023},
publisher = {Association for Computing Machinery},
booktitle = {Proceedings of the ACM Turing Award Celebration Conference - China 2023},
}

@article{feng2023baffle,
      title={Does Federated Learning Really Need Backpropagation?}, 
      author={Haozhe Feng and Tianyu Pang and Chao Du and Wei Chen and Shuicheng Yan and Min Lin},
      year={2023},
      journal={arXiv 2301.12195},
}

@inproceedings{pinelli2023flirt,
  title={FLIRT: Federated Learning for Information Retrieval},
  author={Pinelli, Fabio and Tolomei, Gabriele and Trappolini, Giovanni},
  booktitle={Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year={2023}
}

@inproceedings{
andrew2024oneshot,
title={One-shot Empirical Privacy Estimation for Federated Learning},
author={Galen Andrew and Peter Kairouz and Sewoong Oh and Alina Oprea and Hugh Brendan McMahan and Vinith Menon Suriyakumar},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}

@inproceedings{
wang2024a,
title={A Lightweight Method for Tackling Unknown Participation Statistics in Federated Averaging},
author={Shiqiang Wang and Mingyue Ji},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}

@inproceedings{
huang2024stochastic,
title={Stochastic Controlled Averaging for Federated Learning with Communication Compression},
author={Xinmeng Huang and Ping Li and Xiaoyun Li},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}

@article{borzunov2024distributed,
  title={Distributed Inference and Fine-tuning of Large Language Models Over The Internet},
  author={Borzunov, Alexander and Ryabinin, Max and Chumachenko, Artem and Baranchuk, Dmitry and Dettmers, Tim and Belkada, Younes and Samygin, Pavel and Raffel, Colin A},
  journal={Advances in Neural Information Processing Systems},
  year={2024}
}

@inproceedings{reddi2021adaptive,
title={Adaptive Federated Optimization},
author={Sashank J. Reddi and Zachary Charles and Manzil Zaheer and Zachary Garrett and Keith Rush and Jakub Kone{\v{c}}n{\'y} and Sanjiv Kumar and Hugh Brendan McMahan},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{
panchal2023flow,
title={Flow: Per-instance Personalized Federated Learning},
author={Kunjal Panchal and Sunav Choudhary and Nisarg Parikh and Lijun Zhang and Hui Guan},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
}

@article{pang2020efficient,
  title={Efficient learning of generative models via finite-difference score matching},
  author={Pang, Tianyu and Xu, Kun and Li, Chongxuan and Song, Yang and Ermon, Stefano and Zhu, Jun},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@book{burden2005numerical,
author = {Burden, Richard L. and Faires, J. Douglas.},
booktitle = {Numerical analysis},
edition = {8th ed.},
isbn = {0534392008},
lccn = {2004113929},
publisher = {Thomson Brooks/Cole},
title = {Numerical analysis / Richard L. Burden, J. Douglas Faires.},
year = {2005},
}

@inproceedings{he2023learning,
  title={Learning physics-informed neural networks without stacked back-propagation},
  author={He, Di and Li, Shanda and Shi, Wenlei and Gao, Xiaotian and Zhang, Jia and Bian, Jiang and Wang, Liwei and Liu, Tie-Yan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2023},
  organization={PMLR}
}

@article{sharma2022accelerated,
  title={Accelerated training of physics-informed neural networks (pinns) using meshless discretizations},
  author={Sharma, Ramansh and Shankar, Varun},
  journal={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{vlatakis2019efficiently,
  title={Efficiently avoiding saddle points with zero order methods: No gradients required},
  author={Vlatakis-Gkaragkounis, Emmanouil-Vasileios and Flokas, Lampros and Piliouras, Georgios},
  journal={Advances in neural information processing systems},
  year={2019}
}

@article{tang2020distributed,
  title={Distributed zero-order algorithms for nonconvex multiagent optimization},
  author={Tang, Yujie and Zhang, Junshan and Li, Na},
  journal={IEEE Transactions on Control of Network Systems},
  year={2020},
  publisher={IEEE}
}

@article{richardson1955finitedifferences, 
    title={An Introduction to the Calculus of Finite Differences. By C.H. Richardson Pp. vi, 142. 28s. 1954. (Van Nostrand, New York; Macmillan, London)}, 
    volume={39}, 
    DOI={10.2307/3608616}, 
    number={330}, 
    journal={The Mathematical Gazette}, author={C. H. Richardson}, 
    year={1955}, 
}

@book{jordan1965calculus,
  title={Calculus of finite differences},
  author={Jord{\'a}n, K{\'a}roly},
  year={1965},
  publisher={American Mathematical Soc.}
}

@article{ye2024openfedllm,
      title={OpenFedLLM: Training Large Language Models on Decentralized Private Data via Federated Learning}, 
      author={Rui Ye and Wenhao Wang and Jingyi Chai and Dihan Li and Zexi Li and Yinda Xu and Yaxin Du and Yanfeng Wang and Siheng Chen},
      year={2024},
      journal={arXiv 2402.06954},
}

@article{fan2023fatellm,
      title={FATE-LLM: A Industrial Grade Federated Learning Framework for Large Language Models}, 
      author={Tao Fan and Yan Kang and Guoqiang Ma and Weijing Chen and Wenbin Wei and Lixin Fan and Qiang Yang},
      year={2023},
      journal={arXiv 2310.10049},
}

@article{lai2022fedscale,
      title={FedScale: Benchmarking Model and System Performance of Federated Learning at Scale}, 
      author={Fan Lai and Yinwei Dai and Sanjay S. Singapuram and Jiachen Liu and Xiangfeng Zhu and Harsha V. Madhyastha and Mosharaf Chowdhury},
      year={2022},
      journal={arXiv 2105.11367},
}

@inproceedings{ro2022scaling,
    title = "Scaling Language Model Size in Cross-Device Federated Learning",
    author = "Ro, Jae  and
      Breiner, Theresa  and
      McConnaughey, Lara  and
      Chen, Mingqing  and
      Suresh, Ananda  and
      Kumar, Shankar  and
      Mathews, Rajiv",
    booktitle = "Proceedings of the First Workshop on Federated Learning for Natural Language Processing (FL4NLP 2022)",
    year = "2022",
    publisher = "Association for Computational Linguistics",
}

@inproceedings{malaviya2023reducing,
  title={Reducing communication overhead in federated learning for pre-trained language models using parameter-efficient finetuning},
  author={Malaviya, Shubham and Shukla, Manish and Lodha, Sachin},
  booktitle={Conference on Lifelong Learning Agents},
  year={2023},
  organization={PMLR}
}

@inproceedings{zhang2023fedpetuning,
    title = "{F}ed{PET}uning: When Federated Learning Meets the Parameter-Efficient Tuning Methods of Pre-trained Language Models",
    author = "Zhang, Zhuo  and
      Yang, Yuanhang  and
      Dai, Yong  and
      Wang, Qifan  and
      Yu, Yue  and
      Qu, Lizhen  and
      Xu, Zenglin",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    year = "2023",
    publisher = "Association for Computational Linguistics",
}

@article{park2023fedfwd,
      title={FedFwd: Federated Learning without Backpropagation}, 
      author={Seonghwan Park and Dahun Shin and Jinseok Chung and Namhoon Lee},
      year={2023},
      journal={arXiv 2309.01150},
}

@article{hinton2022forwardforward,
      title={The Forward-Forward Algorithm: Some Preliminary Investigations}, 
      author={Geoffrey Hinton},
      year={2022},
      journal={arXiv 2212.13345},
}

@inproceedings{zaken2022bitfit,
    title = "{B}it{F}it: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models",
    author = "Ben Zaken, Elad  and
      Goldberg, Yoav  and
      Ravfogel, Shauli",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    year = "2022",
    publisher = "Association for Computational Linguistics",
}

@inproceedings{
zhang2024llamaadapter,
title={{LL}a{MA}-Adapter: Efficient Fine-tuning of Large Language Models with Zero-initialized Attention},
author={Renrui Zhang and Jiaming Han and Chris Liu and Aojun Zhou and Pan Lu and Hongsheng Li and Peng Gao and Yu Qiao},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}

@inproceedings{li2021ditto,
  title={Ditto: Fair and robust federated learning through personalization},
  author={Li, Tian and Hu, Shengyuan and Beirami, Ahmad and Smith, Virginia},
  booktitle={International conference on machine learning},
  year={2021},
}

@article{wu2022motley,
  title={Motley: Benchmarking heterogeneity and personalization in federated learning},
  author={Wu, Shanshan and Li, Tian and Charles, Zachary and Xiao, Yu and Liu, Ziyu and Xu, Zheng and Smith, Virginia},
  journal={arXiv 2206.09262},
  year={2022}
}

@inproceedings{
oh2022fedbabu,
title={Fed{BABU}: Toward Enhanced Representation for Federated Image Classification},
author={Jaehoon Oh and SangMook Kim and Se-Young Yun},
booktitle={International Conference on Learning Representations},
year={2022},
}

@inproceedings{zhang2015agnewsyelpyahoo,
  title={Character-level Convolutional Networks for Text Classification},
  author={Xiang Zhang and Junbo Jake Zhao and Yann LeCun},
  booktitle={Neural Information Processing Systems},
  year={2015},
    note = {Available at \url{https://huggingface.co/datasets/ag_news}, \url{https://huggingface.co/datasets/yelp_polarity}, \url{https://huggingface.co/datasets/yahoo_answers_topics}, Accessed on 15 May, 2024}
}

@inproceedings{socher2013sst2,
    title = "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    author = "Socher, Richard  and
      Perelygin, Alex  and
      Wu, Jean  and
      Chuang, Jason  and
      Manning, Christopher D.  and
      Ng, Andrew  and
      Potts, Christopher",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    year = "2013",
    publisher = "Association for Computational Linguistics",
    note = {Available at \url{https://huggingface.co/datasets/stanfordnlp/sst2}, Accessed on 15 May, 2024}    
}

@inproceedings{bowman2015snli,
    title = "A large annotated corpus for learning natural language inference",
    author = "Bowman, Samuel R.  and
      Angeli, Gabor  and
      Potts, Christopher  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    year = "2015",
    publisher = "Association for Computational Linguistics",
    note = {Available at \url{https://huggingface.co/datasets/stanfordnlp/snli}, Accessed on 15 May, 2024}
}

@InProceedings{williams2018mnli,
  author = "Williams, Adina and Nangia, Nikita and Bowman, Samuel",
  title = "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
  booktitle = "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
  year = "2018",
  publisher = "Association for Computational Linguistics",
  note = {Available at \url{https://huggingface.co/datasets/SetFit/mnli}, Accessed on 15 May, 2024}
}

@article{chandra2020qqp,
      title={Experiments on Paraphrase Identification Using Quora Question Pairs Dataset}, 
      author={Andreas Chandra and Ruben Stefanus},
      year={2020},
      journal={arXiv 2006.02648},
}
@inproceedings{rajpurkar2018squad,
    title = "Know What You Don{'}t Know: Unanswerable Questions for {SQ}u{AD}",
    author = "Rajpurkar, Pranav and Jia, Robin and Liang, Percy",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    year = "2018",
    publisher = "Association for Computational Linguistics",
    note = {Available at \url{https://huggingface.co/datasets/rajpurkar/squad_v2}, Accessed on 15 May, 2024}
}

@inproceedings{khashabi2018multirc,
    title = "Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences",
    author = "Khashabi, Daniel and Chaturvedi, Snigdha and Roth, Michael and Upadhyay, Shyam  and Roth, Dan",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    year = "2018",
    publisher = "Association for Computational Linguistics",
    note = {Available at \url{https://huggingface.co/datasets/mtc/multirc}, Accessed on 15 May, 2024}
}

@article{liu2019roberta,
  author    = {Yinhan Liu and Myle Ott and
               Naman Goyal and Jingfei Du and
               Mandar Joshi and Danqi Chen and
               Omer Levy and Mike Lewis and
               Luke Zettlemoyer and Veselin Stoyanov},
  title     = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal   = {arxiv 1907.11692},
  year      = {2019},
}

@article{devlin2018bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {arXiv 1810.04805},
  year      = {2018},
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv 1910.01108},
  year={2019}
}

@article{lan2019albert,
  author    = {Zhenzhong Lan and
               Mingda Chen and
               Sebastian Goodman and
               Kevin Gimpel and
               Piyush Sharma and
               Radu Soricut},
  title     = {{ALBERT:} {A} Lite {BERT} for Self-supervised Learning of Language
               Representations},
  journal   = {arXiv 1909.11942},
  year      = {2019},
}

@article{raffel2020t5,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
}

@article{beutel2020flower,
  title={Flower: A Friendly Federated Learning Research Framework},
  author={Beutel, Daniel J and Topal, Taner and Mathur, Akhil and Qiu, Xinchi and Parcollet, Titouan and Lane, Nicholas D},
  journal={arXiv preprint 2007.14390},
  year={2020}
}

@inproceedings{thapa2022splitfed,
  title={Splitfed: When federated learning meets split learning},
  author={Thapa, Chandra and Arachchige, Pathum Chamikara Mahawaga and Camtepe, Seyit and Sun, Lichao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2022}
}

@article{fang2022fedzo,
   author={Fang, Wenzhi and Yu, Ziyi and Jiang, Yuning and Shi, Yuanming and Jones, Colin N. and Zhou, Yong},
   title={Communication-Efficient Stochastic Zeroth-Order Optimization for Federated Learning},
   journal={IEEE Transactions on Signal Processing},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   year={2022},
}

@article{zhang2022opt,
      title={OPT: Open Pre-trained Transformer Language Models}, 
      author={Susan Zhang and Stephen Roller and Naman Goyal and Mikel Artetxe and Moya Chen and Shuohui Chen and Christopher Dewan and Mona Diab and Xian Li and Xi Victoria Lin and Todor Mihaylov and Myle Ott and Sam Shleifer and Kurt Shuster and Daniel Simig and Punit Singh Koura and Anjali Sridhar and Tianlu Wang and Luke Zettlemoyer},
      year={2022},
      journal={arXiv 2205.01068},
}

@Online{autogptq,
  accessed = {2024-04-22},
  title    = {{AutoGPTQ}},
  year    = {2024},
  url      = {https://github.com/AutoGPTQ/AutoGPTQ},
}

@article{ding2023peftsurvey,
  title={Parameter-efficient fine-tuning of large-scale pre-trained language models},
  author={Ding, Ning and Qin, Yujia and Yang, Guang and Wei, Fuchao and Yang, Zonghan and Su, Yusheng and Hu, Shengding and Chen, Yulin and Chan, Chi-Min and Chen, Weize and others},
  journal={Nature Machine Intelligence},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{han2024peftsurvey,
      title={Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey}, 
      author={Zeyu Han and Chao Gao and Jinyang Liu and Jeff Zhang and Sai Qian Zhang},
      year={2024},
      journal={arXiv 2403.14608},
}

@inproceedings{
dettmers2023qlora,
title={{QL}o{RA}: Efficient Finetuning of Quantized {LLM}s},
author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
}

@InProceedings{reddy2020scaffold,
  title = 	 {{SCAFFOLD}: Stochastic Controlled Averaging for Federated Learning},
  author =       {Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  year = 	 {2020},
}







