\begin{thebibliography}{79}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[{Adaptive Agent Team} et~al.(2023){Adaptive Agent Team}, Bauer, Baumli, Baveja, Behbahani, Bhoopchand, Bradley-Schmieg, Chang, Clay, Collister, Dasagi, Gonzalez, Gregor, Hughes, Kashem, Loks-Thompson, Openshaw, Parker-Holder, Pathak, Perez-Nieves, Rakicevic, Rocktäschel, Schroecker, Sygnowski, Tuyls, York, Zacherl, and Zhang]{ada}
{Adaptive Agent Team}, Jakob Bauer, Kate Baumli, Satinder Baveja, Feryal Behbahani, Avishkar Bhoopchand, Nathalie Bradley-Schmieg, Michael Chang, Natalie Clay, Adrian Collister, Vibhavari Dasagi, Lucy Gonzalez, Karol Gregor, Edward Hughes, Sheleem Kashem, Maria Loks-Thompson, Hannah Openshaw, Jack Parker-Holder, Shreya Pathak, Nicolas Perez-Nieves, Nemanja Rakicevic, Tim Rocktäschel, Yannick Schroecker, Jakub Sygnowski, Karl Tuyls, Sarah York, Alexander Zacherl, and Lei Zhang.
\newblock Human-timescale adaptation in an open-ended task space, 2023.
\newblock URL \url{https://arxiv.org/abs/2301.07608}.

\bibitem[Agarwal et~al.(2020)Agarwal, Schuurmans, and Norouzi]{agarwal2020optimistic}
Rishabh Agarwal, Dale Schuurmans, and Mohammad Norouzi.
\newblock An optimistic perspective on offline reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Agarwal et~al.(2021)Agarwal, Schwarzer, Castro, Courville, and Bellemare]{rliable}
Rishabh Agarwal, Max Schwarzer, Pablo~Samuel Castro, Aaron~C Courville, and Marc Bellemare.
\newblock Deep reinforcement learning at the edge of the statistical precipice.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.S. Liang, and J.~Wortman Vaughan, editors, \emph{Advances in Neural Information Processing Systems}, volume~34, pages 29304--29320. Curran Associates, Inc., 2021.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2021/file/f514cec81cb148559cf475e7426eed5e-Paper.pdf}.

\bibitem[Ajay et~al.(2022)Ajay, Du, Gupta, Tenenbaum, Jaakkola, and Agrawal]{decision_diffuser}
Anurag Ajay, Yilun Du, Abhi Gupta, Joshua Tenenbaum, Tommi Jaakkola, and Pulkit Agrawal.
\newblock Is conditional generative modeling all you need for decision-making?
\newblock \emph{arXiv preprint arXiv:2211.15657}, 2022.

\bibitem[An et~al.(2021)An, Moon, Kim, and Song]{edac}
Gaon An, Seungyong Moon, Jang-Hyun Kim, and Hyun~Oh Song.
\newblock Uncertainty-based offline reinforcement learning with diversified q-ensemble.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.S. Liang, and J.~Wortman Vaughan, editors, \emph{Advances in Neural Information Processing Systems}, volume~34, pages 7436--7447. Curran Associates, Inc., 2021.
\newblock URL \url{https://proceedings.neurips.cc/paper/2021/file/3d3d286a8d153a4a58156d0e02d8570c-Paper.pdf}.

\bibitem[Azar et~al.(2012)Azar, Munos, and Kappen]{azar2012sample}
Mohammad~Gheshlaghi Azar, R{\'e}mi Munos, and Bert Kappen.
\newblock On the sample complexity of reinforcement learning with a generative model.
\newblock \emph{arXiv preprint arXiv:1206.6461}, 2012.

\bibitem[Azizi et~al.(2023)Azizi, Kornblith, Saharia, Norouzi, and Fleet]{azizi2023synthetic}
Shekoofeh Azizi, Simon Kornblith, Chitwan Saharia, Mohammad Norouzi, and David~J. Fleet.
\newblock Synthetic data from diffusion models improves imagenet classification, 2023.

\bibitem[Ball et~al.(2021)Ball, Lu, Parker-Holder, and Roberts]{augwm}
Philip~J Ball, Cong Lu, Jack Parker-Holder, and Stephen Roberts.
\newblock Augmented world models facilitate zero-shot dynamics generalization from a single offline environment.
\newblock In Marina Meila and Tong Zhang, editors, \emph{Proceedings of the 38th International Conference on Machine Learning}, volume 139 of \emph{Proceedings of Machine Learning Research}, pages 619--629. PMLR, 18--24 Jul 2021.
\newblock URL \url{https://proceedings.mlr.press/v139/ball21a.html}.

\bibitem[Ball et~al.(2023)Ball, Smith, Kostrikov, and Levine]{ball_rlpd}
Philip~J. Ball, Laura Smith, Ilya Kostrikov, and Sergey Levine.
\newblock Efficient online reinforcement learning with offline data, 2023.
\newblock URL \url{https://arxiv.org/abs/2302.02948}.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider, Schulman, Tang, and Zaremba]{openai_gym}
Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba.
\newblock Openai gym, 2016.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 1877--1901, 2020.

\bibitem[Chen et~al.(2021)Chen, Wang, Zhou, and Ross]{redq}
Xinyue Chen, Che Wang, Zijian Zhou, and Keith~W. Ross.
\newblock Randomized ensembled double q-learning: Learning fast without a model.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=AY8zfZm0tDd}.

\bibitem[Chen et~al.(2023)Chen, Kiami, Gupta, and Kumar]{genaug}
Zoey Chen, Sho Kiami, Abhishek Gupta, and Vikash Kumar.
\newblock Genaug: Retargeting behaviors to unseen situations via generative augmentation, 2023.
\newblock URL \url{https://arxiv.org/abs/2302.06671}.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern recognition}, pages 248--255. Ieee, 2009.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[D'Oro et~al.(2023)D'Oro, Schwarzer, Nikishin, Bacon, Bellemare, and Courville]{sr_sac}
Pierluca D'Oro, Max Schwarzer, Evgenii Nikishin, Pierre-Luc Bacon, Marc~G Bellemare, and Aaron Courville.
\newblock Sample-efficient reinforcement learning by breaking the replay ratio barrier.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=OpC-9aBBVJe}.

\bibitem[Du et~al.(2023)Du, Yang, Dai, Dai, Nachum, Tenenbaum, Schuurmans, and Abbeel]{universal_policies}
Yilun Du, Mengjiao Yang, Bo~Dai, Hanjun Dai, Ofir Nachum, Joshua~B. Tenenbaum, Dale Schuurmans, and Pieter Abbeel.
\newblock Learning universal policies via text-guided video generation, 2023.
\newblock URL \url{https://arxiv.org/abs/2302.00111}.

\bibitem[Espeholt et~al.(2018)Espeholt, Soyer, Munos, Simonyan, Mnih, Ward, Doron, Firoiu, Harley, Dunning, Legg, and Kavukcuoglu]{impala}
Lasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Vlad Mnih, Tom Ward, Yotam Doron, Vlad Firoiu, Tim Harley, Iain Dunning, Shane Legg, and Koray Kavukcuoglu.
\newblock {IMPALA}: Scalable distributed deep-{RL} with importance weighted actor-learner architectures.
\newblock In \emph{Proceedings of the 35th International Conference on Machine Learning}, 2018.

\bibitem[Fedus et~al.(2020)Fedus, Ramachandran, Agarwal, Bengio, Larochelle, Rowland, and Dabney]{revisitingexpreplay}
William Fedus, Prajit Ramachandran, Rishabh Agarwal, Yoshua Bengio, Hugo Larochelle, Mark Rowland, and Will Dabney.
\newblock Revisiting fundamentals of experience replay.
\newblock In \emph{Proceedings of the 37th International Conference on Machine Learning}, 2020.

\bibitem[Fieller et~al.(1957)Fieller, Hartley, and Pearson]{rank_corr}
E.~C. Fieller, H.~O. Hartley, and E.~S. Pearson.
\newblock Tests for rank correlation coefficients. i.
\newblock \emph{Biometrika}, 44\penalty0 (3/4):\penalty0 470--481, 1957.
\newblock ISSN 00063444.
\newblock URL \url{http://www.jstor.org/stable/2332878}.

\bibitem[Fu et~al.(2020)Fu, Kumar, Nachum, Tucker, and Levine]{d4rl}
Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, and Sergey Levine.
\newblock D4rl: Datasets for deep data-driven reinforcement learning, 2020.

\bibitem[Fujimoto and Gu(2021)]{fujimoto2021minimalist}
Scott Fujimoto and Shixiang~Shane Gu.
\newblock A minimalist approach to offline reinforcement learning.
\newblock In \emph{Thirty-Fifth Conference on Neural Information Processing Systems}, 2021.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozair, Courville, and Bengio]{gan}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In Z.~Ghahramani, M.~Welling, C.~Cortes, N.~Lawrence, and K.Q. Weinberger, editors, \emph{Advances in Neural Information Processing Systems}, volume~27. Curran Associates, Inc., 2014.
\newblock URL \url{https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf}.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Abbeel, and Levine]{sac}
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor.
\newblock In Jennifer Dy and Andreas Krause, editors, \emph{Proceedings of the 35th International Conference on Machine Learning}, volume~80 of \emph{Proceedings of Machine Learning Research}, pages 1861--1870. PMLR, 10--15 Jul 2018.
\newblock URL \url{https://proceedings.mlr.press/v80/haarnoja18b.html}.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock \emph{CoRR}, abs/1512.03385, 2015.

\bibitem[He et~al.(2022)He, Sun, Yu, Xue, Zhang, Torr, Bai, and Qi]{image_synthetic}
Ruifei He, Shuyang Sun, Xin Yu, Chuhui Xue, Wenqing Zhang, Philip Torr, Song Bai, and Xiaojuan Qi.
\newblock Is synthetic data from generative models ready for image recognition?, 2022.
\newblock URL \url{https://arxiv.org/abs/2210.07574}.

\bibitem[Hester et~al.(2017)Hester, Vecerik, Pietquin, Lanctot, Schaul, Piot, Horgan, Quan, Sendonaris, Dulac-Arnold, Osband, Agapiou, Leibo, and Gruslys]{dqfd}
Todd Hester, Matej Vecerik, Olivier Pietquin, Marc Lanctot, Tom Schaul, Bilal Piot, Dan Horgan, John Quan, Andrew Sendonaris, Gabriel Dulac-Arnold, Ian Osband, John Agapiou, Joel~Z. Leibo, and Audrunas Gruslys.
\newblock Deep q-learning from demonstrations, 2017.
\newblock URL \url{https://arxiv.org/abs/1704.03732}.

\bibitem[Hilton et~al.(2023)Hilton, Tang, and Schulman]{hilton2023scaling}
Jacob Hilton, Jie Tang, and John Schulman.
\newblock Scaling laws for single-agent reinforcement learning, 2023.
\newblock URL \url{https://arxiv.org/abs/2301.13442}.

\bibitem[Ho and Salimans(2021)]{ho2021classifierfree}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock In \emph{NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications}, 2021.
\newblock URL \url{https://openreview.net/forum?id=qw8AKxfYbI}.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ddpm}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin, editors, \emph{Advances in Neural Information Processing Systems}, volume~33, pages 6840--6851. Curran Associates, Inc., 2020.
\newblock URL \url{https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf}.

\bibitem[Hoogeboom et~al.(2021)Hoogeboom, Nielsen, Jaini, Forr{\'e}, and Welling]{hoogeboom2021argmax}
Emiel Hoogeboom, Didrik Nielsen, Priyank Jaini, Patrick Forr{\'e}, and Max Welling.
\newblock Argmax flows and multinomial diffusion: Learning categorical distributions.
\newblock In A.~Beygelzimer, Y.~Dauphin, P.~Liang, and J.~Wortman Vaughan, editors, \emph{Advances in Neural Information Processing Systems}, 2021.
\newblock URL \url{https://openreview.net/forum?id=6nbpPqUCIi7}.

\bibitem[Huang et~al.(2017)Huang, Ley, Vlachou-Konchylaki, and Hu]{huang2017enhanced}
Vincent Huang, Tobias Ley, Martha Vlachou-Konchylaki, and Wenfeng Hu.
\newblock Enhanced experience replay generation for efficient reinforcement learning, 2017.
\newblock URL \url{https://arxiv.org/abs/1705.08245}.

\bibitem[Hyv{{\"a}}rinen(2005)]{JMLR:v6:hyvarinen05a}
Aapo Hyv{{\"a}}rinen.
\newblock Estimation of non-normalized statistical models by score matching.
\newblock \emph{Journal of Machine Learning Research}, 6\penalty0 (24):\penalty0 695--709, 2005.
\newblock URL \url{http://jmlr.org/papers/v6/hyvarinen05a.html}.

\bibitem[{Imre}(2021)]{vae_gr}
Baris {Imre}.
\newblock An investigation of generative replay in deep reinforcement learning, January 2021.
\newblock URL \url{http://essay.utwente.nl/85772/}.

\bibitem[Janner et~al.(2019)Janner, Fu, Zhang, and Levine]{janner2019mbpo}
Michael Janner, Justin Fu, Marvin Zhang, and Sergey Levine.
\newblock When to trust your model: Model-based policy optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Janner et~al.(2022)Janner, Du, Tenenbaum, and Levine]{janner2022diffuser}
Michael Janner, Yilun Du, Joshua Tenenbaum, and Sergey Levine.
\newblock Planning with diffusion for flexible behavior synthesis.
\newblock In \emph{International Conference on Machine Learning}, 2022.

\bibitem[Kapturowski et~al.(2019)Kapturowski, Ostrovski, Dabney, Quan, and Munos]{r2d2}
Steven Kapturowski, Georg Ostrovski, Will Dabney, John Quan, and Remi Munos.
\newblock Recurrent experience replay in distributed reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Karras et~al.(2022)Karras, Aittala, Aila, and Laine]{edm}
Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine.
\newblock Elucidating the design space of diffusion-based generative models.
\newblock In Alice~H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=k7FuTOWMOc7}.

\bibitem[Kidambi et~al.(2020)Kidambi, Rajeswaran, Netrapalli, and Joachims]{morel}
Rahul Kidambi, Aravind Rajeswaran, Praneeth Netrapalli, and Thorsten Joachims.
\newblock Morel: Model-based offline reinforcement learning.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin, editors, \emph{Advances in Neural Information Processing Systems}, volume~33, pages 21810--21823. Curran Associates, Inc., 2020.
\newblock URL \url{https://proceedings.neurips.cc/paper/2020/file/f7efa4f864ae9b88d43527f4b14f750f-Paper.pdf}.

\bibitem[Kingma and Welling(2014)]{vae}
Diederik~P. Kingma and Max Welling.
\newblock {Auto-Encoding Variational Bayes}.
\newblock In \emph{2nd International Conference on Learning Representations, {ICLR} 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings}, 2014.

\bibitem[Kostrikov et~al.(2022)Kostrikov, Nair, and Levine]{iql}
Ilya Kostrikov, Ashvin Nair, and Sergey Levine.
\newblock Offline reinforcement learning with implicit q-learning.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=68n2s9ZJWF8}.

\bibitem[Kotelnikov et~al.(2022)Kotelnikov, Baranchuk, Rubachev, and Babenko]{kotelnikov2022tabddpm}
Akim Kotelnikov, Dmitry Baranchuk, Ivan Rubachev, and Artem Babenko.
\newblock Tabddpm: Modelling tabular data with diffusion models, 2022.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and Hinton]{alexnet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In F.~Pereira, C.~J.~C. Burges, L.~Bottou, and K.~Q. Weinberger, editors, \emph{Advances in Neural Information Processing Systems 25}, 2012.

\bibitem[Kumar et~al.(2020)Kumar, Zhou, Tucker, and Levine]{cql}
Aviral Kumar, Aurick Zhou, George Tucker, and Sergey Levine.
\newblock Conservative q-learning for offline reinforcement learning.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin, editors, \emph{Advances in Neural Information Processing Systems}, volume~33, pages 1179--1191. Curran Associates, Inc., 2020.
\newblock URL \url{https://proceedings.neurips.cc/paper/2020/file/0d2b2061826a5df3221116a5085a6052-Paper.pdf}.

\bibitem[Laskin et~al.(2020)Laskin, Lee, Stooke, Pinto, Abbeel, and Srinivas]{rad}
Misha Laskin, Kimin Lee, Adam Stooke, Lerrel Pinto, Pieter Abbeel, and Aravind Srinivas.
\newblock Reinforcement learning with augmented data.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin, editors, \emph{Advances in Neural Information Processing Systems}, volume~33, pages 19884--19895. Curran Associates, Inc., 2020.
\newblock URL \url{https://proceedings.neurips.cc/paper/2020/file/e615c82aba461681ade82da2da38004a-Paper.pdf}.

\bibitem[Levine et~al.(2020)Levine, Kumar, Tucker, and Fu]{offlinerl_survey}
Sergey Levine, Aviral Kumar, George Tucker, and Justin Fu.
\newblock Offline reinforcement learning: Tutorial, review, and perspectives on open problems, 2020.

\bibitem[Li et~al.(2020)Li, Wei, Chi, Gu, and Chen]{li2020breaking}
Gen Li, Yuting Wei, Yuejie Chi, Yuantao Gu, and Yuxin Chen.
\newblock Breaking the sample size barrier in model-based reinforcement learning with a generative model.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 12861--12872, 2020.

\bibitem[Li et~al.(2023)Li, Kumar, Kostrikov, and Levine]{li2023efficient}
Qiyang Li, Aviral Kumar, Ilya Kostrikov, and Sergey Levine.
\newblock Efficient deep reinforcement learning requires regulating statistical overfitting.
\newblock In \emph{International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=14-kr46GvP-}.

\bibitem[Lu et~al.(2022{\natexlab{a}})Lu, Ball, Parker-Holder, Osborne, and Roberts]{lu2022revisiting}
Cong Lu, Philip Ball, Jack Parker-Holder, Michael Osborne, and Stephen~J. Roberts.
\newblock Revisiting design choices in offline model based reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2022{\natexlab{a}}.
\newblock URL \url{https://openreview.net/forum?id=zz9hXVhf40}.

\bibitem[Lu et~al.(2022{\natexlab{b}})Lu, Ball, Rudner, Parker-Holder, Osborne, and Teh]{vd4rl}
Cong Lu, Philip~J. Ball, Tim G.~J. Rudner, Jack Parker-Holder, Michael~A. Osborne, and Yee~Whye Teh.
\newblock Challenges and opportunities in offline reinforcement learning from visual observations, 2022{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2206.04779}.

\bibitem[{Ludjen}(2021)]{gan_gr}
A.C.P.P. {Ludjen}.
\newblock Generative replay in deep reinforcement learning, June 2021.
\newblock URL \url{http://essay.utwente.nl/87315/}.

\bibitem[Massey~Jr(1951)]{massey1951kolmogorov}
Frank~J Massey~Jr.
\newblock The kolmogorov-smirnov test for goodness of fit.
\newblock \emph{Journal of the American statistical Association}, 46\penalty0 (253):\penalty0 68--78, 1951.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare, Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik, Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis]{dqn}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei Rusu, Joel Veness, Marc Bellemare, Alex Graves, Martin Riedmiller, Andreas Fidjeland, Georg Ostrovski, Stig Petersen, Charles Beattie, Amir Sadik, Ioannis Antonoglou, Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg, and Demis Hassabis.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518:\penalty0 529--33, 02 2015.
\newblock \doi{10.1038/nature14236}.

\bibitem[{Patki} et~al.(2016){Patki}, {Wedge}, and {Veeramachaneni}]{sdv}
N.~{Patki}, R.~{Wedge}, and K.~{Veeramachaneni}.
\newblock The synthetic data vault.
\newblock In \emph{2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA)}, pages 399--410, Oct 2016.
\newblock \doi{10.1109/DSAA.2016.49}.

\bibitem[Pearce et~al.(2023)Pearce, Rashid, Kanervisto, Bignell, Sun, Georgescu, Macua, Tan, Momennejad, Hofmann, and Devlin]{pearce2023imitating}
Tim Pearce, Tabish Rashid, Anssi Kanervisto, Dave Bignell, Mingfei Sun, Raluca Georgescu, Sergio~Valcarcel Macua, Shan~Zheng Tan, Ida Momennejad, Katja Hofmann, and Sam Devlin.
\newblock Imitating human behaviour with diffusion models.
\newblock In \emph{International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=Pv1GPQzRrC8}.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever, et~al.]{radford2019language}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 1\penalty0 (8):\penalty0 9, 2019.

\bibitem[Rahimi and Recht(2007)]{rff}
Ali Rahimi and Benjamin Recht.
\newblock Random features for large-scale kernel machines.
\newblock In J.~Platt, D.~Koller, Y.~Singer, and S.~Roweis, editors, \emph{Advances in Neural Information Processing Systems}, volume~20. Curran Associates, Inc., 2007.
\newblock URL \url{https://proceedings.neurips.cc/paper/2007/file/013a006f03dbc5392effeb8f18fda755-Paper.pdf}.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and Chen]{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 2022.

\bibitem[Rombach et~al.(2021)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2021highresolution}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer.
\newblock High-resolution image synthesis with latent diffusion models, 2021.

\bibitem[Sariyildiz et~al.(2023)Sariyildiz, Alahari, Larlus, and Kalantidis]{sariyildiz2023fake}
Mert~Bulent Sariyildiz, Karteek Alahari, Diane Larlus, and Yannis Kalantidis.
\newblock Fake it till you make it: Learning transferable representations from synthetic imagenet clones.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2023.

\bibitem[Schaal(1996)]{lfd}
Stefan Schaal.
\newblock Learning from demonstration.
\newblock In M.C. Mozer, M.~Jordan, and T.~Petsche, editors, \emph{Advances in Neural Information Processing Systems}, volume~9. MIT Press, 1996.
\newblock URL \url{https://proceedings.neurips.cc/paper/1996/file/68d13cf26c4b4f4f932e3eff990093ba-Paper.pdf}.

\bibitem[Schmidhuber(2019)]{schmidhuber2019reinforcement}
Juergen Schmidhuber.
\newblock Reinforcement learning upside down: Don't predict rewards--just map them to actions.
\newblock \emph{arXiv preprint arXiv:1912.02875}, 2019.

\bibitem[Schuhmann et~al.(2022)Schuhmann, Beaumont, Vencu, Gordon, Wightman, Cherti, Coombes, Katta, Mullis, Wortsman, Schramowski, Kundurthy, Crowson, Schmidt, Kaczmarczyk, and Jitsev]{schuhmann2022laionb}
Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade~W Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, Patrick Schramowski, Srivatsa~R Kundurthy, Katherine Crowson, Ludwig Schmidt, Robert Kaczmarczyk, and Jenia Jitsev.
\newblock {LAION}-5b: An open large-scale dataset for training next generation image-text models.
\newblock In \emph{Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track}, 2022.
\newblock URL \url{https://openreview.net/forum?id=M3Y74vmsMcY}.

\bibitem[Sehwag et~al.(2022)Sehwag, Mahloujifar, Handina, Dai, Xiang, Chiang, and Mittal]{sehwag2022robust}
Vikash Sehwag, Saeed Mahloujifar, Tinashe Handina, Sihui Dai, Chong Xiang, Mung Chiang, and Prateek Mittal.
\newblock Robust learning meets generative models: Can proxy distributions improve adversarial robustness?
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=WVX0NNVBBkV}.

\bibitem[Shin et~al.(2017)Shin, Lee, Kim, and Kim]{NIPS2017_0efbe980}
Hanul Shin, Jung~Kwon Lee, Jaehong Kim, and Jiwon Kim.
\newblock Continual learning with deep generative replay.
\newblock In I.~Guyon, U.~Von Luxburg, S.~Bengio, H.~Wallach, R.~Fergus, S.~Vishwanathan, and R.~Garnett, editors, \emph{Advances in Neural Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.
\newblock URL \url{https://proceedings.neurips.cc/paper/2017/file/0efbe98067c6c73dba1250d2beaa81f9-Paper.pdf}.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and Ganguli]{pmlr-v37-sohl-dickstein15}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In Francis Bach and David Blei, editors, \emph{Proceedings of the 32nd International Conference on Machine Learning}, volume~37 of \emph{Proceedings of Machine Learning Research}, pages 2256--2265, Lille, France, 07--09 Jul 2015. PMLR.
\newblock URL \url{https://proceedings.mlr.press/v37/sohl-dickstein15.html}.

\bibitem[Sutton and Barto(2018)]{Sutton1998}
Richard~S. Sutton and Andrew~G. Barto.
\newblock \emph{Reinforcement Learning: An Introduction}.
\newblock The MIT Press, second edition, 2018.
\newblock URL \url{http://incompleteideas.net/book/the-book-2nd.html}.

\bibitem[Tarasov et~al.(2022)Tarasov, Nikulin, Akimov, Kurenkov, and Kolesnikov]{corl}
Denis Tarasov, Alexander Nikulin, Dmitry Akimov, Vladislav Kurenkov, and Sergey Kolesnikov.
\newblock {CORL}: Research-oriented deep offline reinforcement learning library.
\newblock In \emph{3rd Offline RL Workshop: Offline RL as a ''Launchpad''}, 2022.
\newblock URL \url{https://openreview.net/forum?id=SyAS49bBcv}.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{mujoco}
Emanuel Todorov, Tom Erez, and Yuval Tassa.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{2012 IEEE/RSJ International Conference on Intelligent Robots and Systems}, pages 5026--5033. IEEE, 2012.
\newblock \doi{10.1109/IROS.2012.6386109}.

\bibitem[Tolstikhin et~al.(2021)Tolstikhin, Houlsby, Kolesnikov, Beyer, Zhai, Unterthiner, Yung, Steiner, Keysers, Uszkoreit, Lucic, and Dosovitskiy]{mlp_mixer}
Ilya Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Thomas Unterthiner, Jessica Yung, Andreas~Peter Steiner, Daniel Keysers, Jakob Uszkoreit, Mario Lucic, and Alexey Dosovitskiy.
\newblock {MLP}-mixer: An all-{MLP} architecture for vision.
\newblock In A.~Beygelzimer, Y.~Dauphin, P.~Liang, and J.~Wortman Vaughan, editors, \emph{Advances in Neural Information Processing Systems}, 2021.
\newblock URL \url{https://openreview.net/forum?id=EI2KOXKdnP}.

\bibitem[Tunyasuvunakool et~al.(2020)Tunyasuvunakool, Muldal, Doron, Liu, Bohez, Merel, Erez, Lillicrap, Heess, and Tassa]{tunyasuvunakool2020}
Saran Tunyasuvunakool, Alistair Muldal, Yotam Doron, Siqi Liu, Steven Bohez, Josh Merel, Tom Erez, Timothy Lillicrap, Nicolas Heess, and Yuval Tassa.
\newblock dm\_control: Software and tasks for continuous control.
\newblock \emph{Software Impacts}, 6:\penalty0 100022, 2020.
\newblock ISSN 2665-9638.
\newblock \doi{https://doi.org/10.1016/j.simpa.2020.100022}.
\newblock URL \url{https://www.sciencedirect.com/science/article/pii/S2665963820300099}.

\bibitem[Van~der Maaten and Hinton(2008)]{tsne}
Laurens Van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using t-sne.
\newblock \emph{Journal of machine learning research}, 9\penalty0 (11), 2008.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{NIPS2017_3f5ee243}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, \L~ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In I.~Guyon, U.~Von Luxburg, S.~Bengio, H.~Wallach, R.~Fergus, S.~Vishwanathan, and R.~Garnett, editors, \emph{Advances in Neural Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.

\bibitem[Vincent(2011)]{vincent2011connection}
Pascal Vincent.
\newblock A connection between score matching and denoising autoencoders.
\newblock \emph{Neural Computation}, 23\penalty0 (7):\penalty0 1661--1674, 2011.
\newblock \doi{10.1162/NECO_a_00142}.

\bibitem[Wagenmaker and Pacchiano(2022)]{aldo2022leveraging}
Andrew Wagenmaker and Aldo Pacchiano.
\newblock Leveraging offline data in online reinforcement learning, 2022.
\newblock URL \url{https://arxiv.org/abs/2211.04974}.

\bibitem[Xu et~al.(2019)Xu, Skoularidou, Cuesta-Infante, and Veeramachaneni]{ctgan}
Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni.
\newblock Modeling tabular data using conditional gan.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, \emph{Advances in Neural Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.
\newblock URL \url{https://proceedings.neurips.cc/paper/2019/file/254ed7d2de3b23ab10936522dd547b78-Paper.pdf}.

\bibitem[Yarats et~al.(2022)Yarats, Fergus, Lazaric, and Pinto]{drqv2}
Denis Yarats, Rob Fergus, Alessandro Lazaric, and Lerrel Pinto.
\newblock Mastering visual continuous control: Improved data-augmented reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=_SJ-_yyes8}.

\bibitem[Yu et~al.(2020)Yu, Thomas, Yu, Ermon, Zou, Levine, Finn, and Ma]{mopo}
Tianhe Yu, Garrett Thomas, Lantao Yu, Stefano Ermon, James~Y Zou, Sergey Levine, Chelsea Finn, and Tengyu Ma.
\newblock Mopo: Model-based offline policy optimization.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin, editors, \emph{Advances in Neural Information Processing Systems}, volume~33, pages 14129--14142. Curran Associates, Inc., 2020.
\newblock URL \url{https://proceedings.neurips.cc/paper/2020/file/a322852ce0df73e204b7e67cbbef0d0a-Paper.pdf}.

\bibitem[Yu et~al.(2023)Yu, Xiao, Stone, Tompson, Brohan, Wang, Singh, Tan, M, Peralta, Ichter, Hausman, and Xia]{rosie}
Tianhe Yu, Ted Xiao, Austin Stone, Jonathan Tompson, Anthony Brohan, Su~Wang, Jaspiar Singh, Clayton Tan, Dee M, Jodilyn Peralta, Brian Ichter, Karol Hausman, and Fei Xia.
\newblock Scaling robot learning with semantically imagined experience, 2023.
\newblock URL \url{https://arxiv.org/abs/2302.11550}.

\end{thebibliography}
