\begin{thebibliography}{10}

\bibitem{bickel2015statistics}
Peter~J Bickel and Kjell~A Doksum.
\newblock {\em Mathematical statistics: basic ideas and selected topics,
  volumes I-II package}.
\newblock CRC Press, 2015.

\bibitem{carlini2017towards}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In {\em 2017 ieee symposium on security and privacy (sp)}, pages
  39--57. IEEE, 2017.

\bibitem{carmon2019unlabeled}
Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, Percy Liang, and John~C Duchi.
\newblock Unlabeled data improves adversarial robustness.
\newblock In {\em Proceedings of the 33rd International Conference on Neural
  Information Processing Systems}, pages 11192--11203, 2019.

\bibitem{chen2022decision}
Chen Chen, Jingfeng Zhang, Xilie Xu, Lingjuan Lyu, Chaochao Chen, Tianlei Hu,
  and Gang Chen.
\newblock Decision boundary-aware data augmentation for adversarial training.
\newblock {\em IEEE Transactions on Dependable and Secure Computing}, 2022.

\bibitem{croce2020reliable}
Francesco Croce and Matthias Hein.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock In {\em International conference on machine learning}, pages
  2206--2216, 2020.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255, 2009.

\bibitem{guo2017interpret}
Chuan Guo, Geoff Pleiss, Yu~Sun, and Kilian~Q Weinberger.
\newblock On calibration of modern neural networks.
\newblock In {\em International Conference on Machine Learning}, pages
  1321--1330. PMLR, 2017.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{hong2021federated}
Junyuan Hong, Haotao Wang, Zhangyang Wang, and Jiayu Zhou.
\newblock Federated robustness propagation: Sharing adversarial robustness in
  federated learning.
\newblock {\em arXiv preprint arXiv:2106.10196}, 2021.

\bibitem{hsieh2020skew}
Kevin Hsieh, Amar Phanishayee, Onur Mutlu, and Phillip Gibbons.
\newblock The non-iid data quagmire of decentralized machine learning.
\newblock In {\em International Conference on Machine Learning}, pages
  4387--4398. PMLR, 2020.

\bibitem{karimireddy2020scaffold}
Sai~Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian
  Stich, and Ananda~Theertha Suresh.
\newblock Scaffold: Stochastic controlled averaging for federated learning.
\newblock In {\em International Conference on Machine Learning}, pages
  5132--5143, 2020.

\bibitem{klenke2013bayes}
Achim Klenke.
\newblock {\em Probability theory: a comprehensive course}.
\newblock Springer Science \& Business Media, 2013.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock In {\em Technical report}, 2009.

\bibitem{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock {\em Advances in neural information processing systems},
  25:1097--1105, 2012.

\bibitem{kurakin2016adversarial}
Alexey Kurakin, Ian Goodfellow, and Samy Bengio.
\newblock Adversarial machine learning at scale.
\newblock {\em arXiv preprint arXiv:1611.01236}, 2016.

\bibitem{li2018federated}
Tian Li, Anit~Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
  Virginia Smith.
\newblock Federated optimization in heterogeneous networks.
\newblock {\em arXiv preprint arXiv:1812.06127}, 2018.

\bibitem{li2020fedprox}
Tian Li, Anit~Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
  Virginia Smith.
\newblock Federated optimization in heterogeneous networks.
\newblock {\em Proceedings of Machine Learning and Systems}, 2:429--450, 2020.

\bibitem{li2021anti}
Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo~Li, and Xingjun Ma.
\newblock Anti-backdoor learning: Training clean models on poisoned data.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{luo2019skeweg}
Jiahuan Luo, Xueyang Wu, Yun Luo, Anbu Huang, Yunfeng Huang, Yang Liu, and
  Qiang Yang.
\newblock Real-world image datasets for federated learning.
\newblock {\em arXiv preprint arXiv:1910.11089}, 2019.

\bibitem{lyu2020privacy}
Lingjuan Lyu, Han Yu, Xingjun Ma, Chen Chen, Lichao Sun, Jun Zhao, Qiang Yang,
  and Philip~S Yu.
\newblock Privacy and robustness in federated learning: Attacks and defenses.
\newblock {\em arXiv preprint arXiv:2012.06337}, 2020.

\bibitem{lyu2020threats}
Lingjuan Lyu, Han Yu, Jun Zhao, and Qiang Yang.
\newblock Threats to federated learning.
\newblock In {\em Federated Learning}, pages 3--16. Springer, 2020.

\bibitem{madry2017towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock {\em arXiv preprint arXiv:1706.06083}, 2017.

\bibitem{mcmahan2017communication}
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise~Aguera
  y~Arcas.
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock In {\em Artificial Intelligence and Statistics}, pages 1273--1282.
  PMLR, 2017.

\bibitem{menon2020long}
Aditya~Krishna Menon, Sadeep Jayasumana, Ankit~Singh Rawat, Himanshu Jain,
  Andreas Veit, and Sanjiv Kumar.
\newblock Long-tail learning via logit adjustment.
\newblock {\em arXiv preprint arXiv:2007.07314}, 2020.

\bibitem{netzer2011reading_SVHN}
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo~Wu, and Andrew~Y
  Ng.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock In {\em NeurIPS Workshop on Deep Learning and Unsupervised Feature
  Learning}, 2011.

\bibitem{rice2020overfitting}
Leslie Rice, Eric Wong, and J~Zico Kolter.
\newblock Overfitting in adversarially robust deep learning.
\newblock In {\em ICML}, 2020.

\bibitem{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{tan2022fedproto}
Yue Tan, Guodong Long, Lu~Liu, Tianyi Zhou, Qinghua Lu, Jing Jiang, and Chengqi
  Zhang.
\newblock Fedproto: Federated prototype learning across heterogeneous clients.
\newblock In {\em AAAI Conference on Artificial Intelligence}, volume~36, pages
  8432--8440, 2022.

\bibitem{tan2022federated}
Yue Tan, Guodong Long, Jie Ma, Lu~Liu, Tianyi Zhou, and Jing Jiang.
\newblock Federated learning from pre-trained models: A contrastive learning
  approach.
\newblock In {\em First Workshop on Pre-training: Perspectives, Pitfalls, and
  Paths Forward at ICML 2022}.

\bibitem{tsipras2018robustness}
Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and
  Aleksander Madry.
\newblock Robustness may be at odds with accuracy.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{van2008visualizing}
Laurens Van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using t-sne.
\newblock {\em Journal of machine learning research}, 9(11), 2008.

\bibitem{wald1949consistency}
Abraham Wald.
\newblock Note on the consistency of the maximum likelihood estimate.
\newblock {\em The Annals of Mathematical Statistics}, 20(4):595--601, 1949.

\bibitem{wang2021imbalanced}
Wentao Wang, Han Xu, Xiaorui Liu, Yaxin Li, Bhavani Thuraisingham, and Jiliang
  Tang.
\newblock Imbalanced adversarial training with reweighting.
\newblock {\em arXiv preprint arXiv:2107.13639}, 2021.

\bibitem{wang2020improving_MART}
Yisen Wang, Difan Zou, Jinfeng Yi, James Bailey, Xingjun Ma, and Quanquan Gu.
\newblock Improving adversarial robustness requires revisiting misclassified
  examples.
\newblock In {\em ICLR}, 2020.

\bibitem{wong2020fast_zico_kolter}
Eric Wong, Leslie Rice, and J.~Zico Kolter.
\newblock Fast is better than free: Revisiting adversarial training.
\newblock In {\em ICLR}, 2020.

\bibitem{wu2021adversarial}
Tong Wu, Ziwei Liu, Qingqiu Huang, Yu~Wang, and Dahua Lin.
\newblock Adversarial robustness under long-tailed distribution.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 8659--8668, 2021.

\bibitem{xu2021robust}
Han Xu, Xiaorui Liu, Yaxin Li, Anil Jain, and Jiliang Tang.
\newblock To be robust or to be fair: Towards fairness in adversarial training.
\newblock In {\em International Conference on Machine Learning}, pages
  11492--11501, 2021.

\bibitem{yang2019federated}
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong.
\newblock Federated machine learning: Concept and applications.
\newblock {\em ACM Transactions on Intelligent Systems and Technology (TIST)},
  10(2):1--19, 2019.

\bibitem{yurochkin2019bayesian}
Mikhail Yurochkin, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald, Nghia
  Hoang, and Yasaman Khazaeni.
\newblock Bayesian nonparametric federated learning of neural networks.
\newblock In {\em International Conference on Machine Learning}, pages
  7252--7261, 2019.

\bibitem{zhang2019theoretically}
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El~Ghaoui, and
  Michael Jordan.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In {\em International Conference on Machine Learning}, pages
  7472--7482. PMLR, 2019.

\bibitem{zhang2022qekd}
Jie Zhang, Chen Chen, Jiahua Dong, Ruoxi Jia, and Lingjuan Lyu.
\newblock Qekd: Query-efficient and data-free knowledge distillation from
  black-box models.
\newblock {\em arXiv preprint arXiv:2205.11158}, 2022.

\bibitem{zhang2022towards}
Jie Zhang, Bo~Li, Jianghe Xu, Shuang Wu, Shouhong Ding, Lei Zhang, and Chao Wu.
\newblock Towards efficient data free black-box adversarial attack.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15115--15125, 2022.

\bibitem{zhang2022federated}
Jie Zhang, Zhiqi Li, Bo~Li, Jianghe Xu, Shuang Wu, Shouhong Ding, and Chao Wu.
\newblock Federated learning with label distribution skew via logits
  calibration.
\newblock In {\em International Conference on Machine Learning}, pages
  26311--26329, 2022.

\bibitem{zhang2021geometry}
Jingfeng Zhang, Jianing Zhu, Gang Niu, Bo~Han, Masashi Sugiyama, and Mohan
  Kankanhalli.
\newblock Geometry-aware instance-reweighted adversarial training.
\newblock In {\em ICLR}, 2021.

\bibitem{zhou2021adversarially}
Yao Zhou, Jun Wu, and Jingrui He.
\newblock Adversarially robust federated learning for neural networks, 2021.

\bibitem{zhu2021noniidtype}
Hangyu Zhu, Jinjin Xu, Shiqing Liu, and Yaochu Jin.
\newblock Federated learning on non-iid data: A survey.
\newblock {\em Neurocomputing}, 465:371--390, 2021.

\bibitem{zizzo2020fat}
Giulio Zizzo, Ambrish Rawat, Mathieu Sinn, and Beat Buesser.
\newblock Fat: Federated adversarial training.
\newblock {\em arXiv preprint arXiv:2012.01791}, 2020.

\end{thebibliography}
