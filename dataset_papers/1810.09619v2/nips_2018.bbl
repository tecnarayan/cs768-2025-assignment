\begin{thebibliography}{10}

\bibitem{Bartlett2017}
Peter~L Bartlett, Dylan~J Foster, and Matus~J Telgarsky.
\newblock Spectrally-normalized margin bounds for neural networks.
\newblock In {\em NIPS}, 2017.

\bibitem{Candes2006}
Emmanuel~J Cand{\`e}s, Justin Romberg, and Terence Tao.
\newblock Robust uncertainty principles: Exact signal reconstruction from
  highly incomplete frequency information.
\newblock {\em IEEE Transactions on Information Theory}, 52(2):489--509, 2006.

\bibitem{Carlini2017}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In {\em SP}, 2017.

\bibitem{Cisse2017}
Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin, and Nicolas
  Usunier.
\newblock Parseval networks: Improving robustness to adversarial examples.
\newblock In {\em ICML}, 2017.

\bibitem{d2008}
Alexandre d’Aspremont, Francis Bach, and Laurent~El Ghaoui.
\newblock Optimal solutions for sparse principal component analysis.
\newblock {\em JMLR}, 9(July):1269--1294, 2008.

\bibitem{Denil2013}
Misha Denil, Babak Shakibi, Laurent Dinh, Marc’Aurelio Ranzato, and Nando
  De~Freitas.
\newblock Predicting parameters in deep learning.
\newblock In {\em NIPS}, 2013.

\bibitem{Dhillon2018}
Guneet~S Dhillon, Kamyar Azizzadenesheli, Zachary~C Lipton, Jeremy Bernstein,
  Jean Kossaifi, Aran Khanna, and Anima Anandkumar.
\newblock Stochastic activation pruning for robust adversarial defense.
\newblock In {\em ICLR}, 2018.

\bibitem{Donoho2006}
David~L Donoho.
\newblock Compressed sensing.
\newblock {\em IEEE Transactions on Information Theory}, 52(4):1289--1306,
  2006.

\bibitem{Galloway2018}
Angus Galloway, Graham~W Taylor, and Medhat Moussa.
\newblock Attacking binarized neural networks.
\newblock In {\em ICLR}, 2018.

\bibitem{Gao2017}
Ji~Gao, Beilun Wang, Zeming Lin, Weilin Xu, and Yanjun Qi.
\newblock Deepcloak: Masking deep neural network models for robustness against
  adversarial samples.
\newblock In {\em ICLR Workshop}, 2017.

\bibitem{Goodfellow2015}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In {\em ICLR}, 2015.

\bibitem{Gopalakrishnan2018}
Soorya Gopalakrishnan, Zhinus Marzi, Upamanyu Madhow, and Ramtin Pedarsani.
\newblock Combating adversarial attacks using sparse representations.
\newblock In {\em ICLR Workshop}, 2018.

\bibitem{Guo2016}
Yiwen Guo, Anbang Yao, and Yurong Chen.
\newblock Dynamic network surgery for efficient dnns.
\newblock In {\em NIPS}, 2016.

\bibitem{Han2015}
Song Han, Jeff Pool, John Tran, and William Dally.
\newblock Learning both weights and connections for efficient neural network.
\newblock In {\em NIPS}, 2015.

\bibitem{He2016}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{Hein2017}
Matthias Hein and Maksym Andriushchenko.
\newblock Formal guarantees on the robustness of a classifier against
  adversarial manipulation.
\newblock In {\em NIPS}, 2017.

\bibitem{Jia2014}
Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross
  Girshick, Sergio Guadarrama, and Trevor Darrell.
\newblock Caffe: Convolutional architecture for fast feature embedding.
\newblock In {\em MM}, 2014.

\bibitem{Lu2017}
Jiajun Lu, Theerasit Issaranon, and David Forsyth.
\newblock Safetynet: Detecting and rejecting adversarial examples robustly.
\newblock In {\em ICCV}, 2017.

\bibitem{Madry2018}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In {\em ICLR}, 2018.

\bibitem{Marzi2018}
Zhinus Marzi, Soorya Gopalakrishnan, Upamanyu Madhow, and Ramtin Pedarsani.
\newblock Sparsity-based defense against adversarial attacks on linear
  classifiers.
\newblock {\em arXiv preprint arXiv:1801.04695}, 2018.

\bibitem{Molchanov2017}
Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov.
\newblock Variational dropout sparsifies deep neural networks.
\newblock In {\em ICML}, 2017.

\bibitem{Moosavi2016}
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard.
\newblock Deep{F}ool: a simple and accurate method to fool deep neural
  networks.
\newblock In {\em CVPR}, 2016.

\bibitem{Neklyudov2017}
Kirill Neklyudov, Dmitry Molchanov, Arsenii Ashukha, and Dmitry~P Vetrov.
\newblock Structured bayesian pruning via log-normal multiplicative noise.
\newblock In {\em NIPS}, 2017.

\bibitem{Papernot2016}
Nicolas Papernot, Patrick McDaniel, Xi~Wu, Somesh Jha, and Ananthram Swami.
\newblock Distillation as a defense to adversarial perturbations against deep
  neural networks.
\newblock In {\em SP}, 2016.

\bibitem{Park2017}
Jongsoo Park, Sheng Li, Wei Wen, Ping Tak~Peter Tang, Hai Li, Yiran Chen, and
  Pradeep Dubey.
\newblock Faster cnns with direct sparse convolutions and guided pruning.
\newblock In {\em ICLR}, 2017.

\bibitem{Szegedy2014}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In {\em ICLR}, 2014.

\bibitem{Tramer2018}
Florian Tram{\`e}r, Alexey Kurakin, Nicolas Papernot, Dan Boneh, and Patrick
  McDaniel.
\newblock Ensemble adversarial training: Attacks and defenses.
\newblock In {\em ICLR}, 2018.

\bibitem{Ullrich2017}
Karen Ullrich, Edward Meeds, and Max Welling.
\newblock Soft weight-sharing for neural network compression.
\newblock In {\em ICLR}, 2017.

\bibitem{Wang2018}
Luyu Wang, Gavin~Weiguang Ding, Ruitong Huang, Yanshuai Cao, and Yik~Chau Lui.
\newblock Adversarial robustness of pruned neural networks.
\newblock In {\em ICLR Workshop submission}, 2018.

\bibitem{Weng2018}
Tsui-Wei Weng, Huan Zhang, Pin-Yu Chen, Jinfeng Yi, Dong Su, Yupeng Gao,
  Cho-Jui Hsieh, and Luca Daniel.
\newblock Evaluating the robustness of neural networks: An extreme value theory
  approach.
\newblock In {\em ICLR}, 2018.

\bibitem{Xie2018}
Cihang Xie, Jianyu Wang, Zhishuai Zhang, Zhou Ren, and Alan Yuille.
\newblock Mitigating adversarial effects through randomization.
\newblock In {\em ICLR}, 2018.

\bibitem{Ye2018}
Shaokai Ye, Siyue Wang, Xiao Wang, Bo~Yuan, Wujie Wen, and Xue Lin.
\newblock Defending {DNN} adversarial attacks with pruning and logits
  augmentation.
\newblock In {\em ICLR Workshop submission}, 2018.

\end{thebibliography}
