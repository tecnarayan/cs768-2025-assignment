\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{RRWN11}

\bibitem[ABC{\etalchar{+}}16]{tensorflow}
Mart{\'\i}n Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey
  Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et~al.
\newblock Tensorflow: A system for large-scale machine learning.
\newblock In {\em OSDI}, volume~16, pages 265--283, 2016.

\bibitem[AGL{\etalchar{+}}17]{alistarh2017qsgd}
Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, and Milan Vojnovic.
\newblock Qsgd: Communication-efficient sgd via gradient quantization and
  encoding.
\newblock In {\em NIPS}, pages 1707--1718, 2017.

\bibitem[AWD10]{Syn_DML_10}
Alekh Agarwal, Martin~J Wainwright, and John~C Duchi.
\newblock Distributed dual averaging in networks.
\newblock In {\em NIPS}, pages 550--558, 2010.

\bibitem[BGS{\etalchar{+}}17]{ByzantineML_NIPS17}
Peva Blanchard, Rachid Guerraoui, Julien Stainer, et~al.
\newblock Machine learning with adversaries: Byzantine tolerant gradient
  descent.
\newblock In {\em NIPS}, pages 118--128, 2017.

\bibitem[BIK{\etalchar{+}}16]{FederatedLearn_Aggregate}
Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H~Brendan
  McMahan, Sarvar Patel, Daniel Ramage, Aaron Segal, and Karn Seth.
\newblock Practical secure aggregation for federated learning on user-held
  data.
\newblock {\em arXiv preprint arXiv:1611.04482}, 2016.

\bibitem[BM91]{MajorityVote}
Robert~S Boyer and J~Strother Moore.
\newblock Mjrtyâ€”a fast majority vote algorithm.
\newblock In {\em Automated Reasoning}, pages 105--117. Springer, 1991.

\bibitem[CL{\etalchar{+}}99]{ByzantineError_1999}
Miguel Castro, Barbara Liskov, et~al.
\newblock Practical byzantine fault tolerance.
\newblock In {\em OSDI}, volume~99, pages 173--186, 1999.

\bibitem[CLL{\etalchar{+}}15]{MXNET}
Tianqi Chen, Mu~Li, Yutian Li, Min Lin, Naiyan Wang, Minjie Wang, Tianjun Xiao,
  Bing Xu, Chiyuan Zhang, and Zheng Zhang.
\newblock Mxnet: A flexible and efficient machine learning library for
  heterogeneous distributed systems.
\newblock {\em arXiv preprint arXiv:1512.01274}, 2015.

\bibitem[CPE17]{charles2017approximate}
Zachary Charles, Dimitris Papailiopoulos, and Jordan Ellenberg.
\newblock Approximate gradient coding via sparse random graphs.
\newblock {\em arXiv preprint arXiv:1711.06771}, 2017.

\bibitem[CPM{\etalchar{+}}16]{chen2016revisiting}
Jianmin Chen, Xinghao Pan, Rajat Monga, Samy Bengio, and Rafal Jozefowicz.
\newblock Revisiting distributed synchronous sgd.
\newblock {\em arXiv preprint arXiv:1604.00981}, 2016.

\bibitem[CSAK14]{MS_Adam}
Trishul~M Chilimbi, Yutaka Suzue, Johnson Apacible, and Karthik Kalyanaraman.
\newblock Project adam: Building an efficient and scalable deep learning
  training system.
\newblock In {\em OSDI}, volume~14, pages 571--582, 2014.

\bibitem[CSSS11]{cotter2011better}
Andrew Cotter, Ohad Shamir, Nati Srebro, and Karthik Sridharan.
\newblock Better mini-batch algorithms via accelerated gradient methods.
\newblock In {\em NIPS}, pages 1647--1655, 2011.

\bibitem[CSX17]{ByzantineML_SIGMETRICS18}
Yudong Chen, Lili Su, and Jiaming Xu.
\newblock Distributed statistical machine learning in adversarial settings:
  Byzantine gradient descent.
\newblock {\em arXiv preprint arXiv:1705.05491}, 2017.

\bibitem[CWCP18]{Draco2018}
Lingjiao Chen, Hongyi Wang, Zachary~B. Charles, and Dimitris~S. Papailiopoulos.
\newblock {DRACO:} robust distributed training via redundant gradients.
\newblock {\em arXiv preprint arXiv:1803.09877}, 2018.

\bibitem[CWP18]{chendraco}
Lingjiao Chen, Hongyi Wang, and Dimitris Papailiopoulos.
\newblock Draco: Robust distributed training against adversaries.
\newblock In {\em {SysML}}, 2018.

\bibitem[DCG16]{dutta2016short}
Sanghamitra Dutta, Viveck Cadambe, and Pulkit Grover.
\newblock Short-dot: Computing large linear transforms distributedly using
  coded short dot products.
\newblock In {\em NIPS}, pages 2100--2108, 2016.

\bibitem[DCG17]{dutta2017coded}
Sanghamitra Dutta, Viveck Cadambe, and Pulkit Grover.
\newblock Coded convolution for parallel and distributed computing within a
  deadline.
\newblock In {\em ISIT}, pages 2403--2407. IEEE, 2017.

\bibitem[DCM{\etalchar{+}}12]{dean2012large}
Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Mark Mao,
  Andrew Senior, Paul Tucker, Ke~Yang, Quoc~V Le, et~al.
\newblock Large scale distributed deep networks.
\newblock In {\em NIPS}, pages 1223--1231, 2012.

\bibitem[DPKC11]{MPI4PY}
Lisandro~D Dalcin, Rodrigo~R Paz, Pablo~A Kler, and Alejandro Cosimo.
\newblock Parallel distributed computing using python.
\newblock {\em Advances in Water Resources}, 34(9):1124--1139, 2011.

\bibitem[HZRS16]{ResNet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, pages 770--778, 2016.

\bibitem[JST{\etalchar{+}}14]{jaggi2014communication}
Martin Jaggi, Virginia Smith, Martin Tak{\'a}c, Jonathan Terhorst, Sanjay
  Krishnan, Thomas Hofmann, and Michael~I Jordan.
\newblock Communication-efficient distributed dual coordinate ascent.
\newblock In {\em NIPS}, pages 3068--3076, 2014.

\bibitem[JZ13]{johnson2013accelerating}
Rie Johnson and Tong Zhang.
\newblock Accelerating stochastic gradient descent using predictive variance
  reduction.
\newblock In {\em NIPS}, pages 315--323, 2013.

\bibitem[KAD{\etalchar{+}}07]{Byzantine2007}
Ramakrishna Kotla, Lorenzo Alvisi, Mike Dahlin, Allen Clement, and Edmund Wong.
\newblock Zyzzyva: speculative byzantine fault tolerance.
\newblock In {\em ACM SIGOPS Operating Systems Review}, volume~41, pages
  45--58. ACM, 2007.

\bibitem[KH09]{Cifar10}
Alex Krizhevsky and Geoffrey Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Kim14]{DBLP:conf/emnlp/Kim14}
Yoon Kim.
\newblock Convolutional neural networks for sentence classification.
\newblock {\em arXiv preprint arXiv:1408.5882}, 2014.

\bibitem[KMR15]{konevcny2015federated}
Jakub Kone{\v{c}}n{\`y}, Brendan McMahan, and Daniel Ramage.
\newblock Federated optimization: Distributed optimization beyond the
  datacenter.
\newblock {\em arXiv preprint arXiv:1511.03575}, 2015.

\bibitem[KMY{\etalchar{+}}16]{FederatedLearning}
Jakub Kone{\v{c}}n{\`y}, H~Brendan McMahan, Felix~X Yu, Peter Richt{\'a}rik,
  Ananda~Theertha Suresh, and Dave Bacon.
\newblock Federated learning: Strategies for improving communication
  efficiency.
\newblock {\em arXiv preprint arXiv:1610.05492}, 2016.

\bibitem[KSH12]{AlexNet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em NIPS}, pages 1097--1105, 2012.

\bibitem[LAP{\etalchar{+}}14]{ParameterServer}
Mu~Li, David~G Andersen, Jun~Woo Park, Alexander~J Smola, Amr Ahmed, Vanja
  Josifovski, James Long, Eugene~J Shekita, and Bor-Yiing Su.
\newblock Scaling distributed machine learning with the parameter server.
\newblock In {\em OSDI}, volume~14, pages 583--598, 2014.

\bibitem[LBBH98]{LeNet}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock {\em Proceedings of the IEEE}, 86(11):2278--2324, 1998.

\bibitem[LLP{\etalchar{+}}17]{MatrixCode_2016}
Kangwook Lee, Maximilian Lam, Ramtin Pedarsani, Dimitris Papailiopoulos, and
  Kannan Ramchandran.
\newblock Speeding up distributed machine learning using codes.
\newblock {\em IEEE Transactions on Information Theory}, 2017.

\bibitem[LMAA15]{li2015coded}
Songze Li, Mohammad~Ali Maddah-Ali, and A~Salman Avestimehr.
\newblock Coded mapreduce.
\newblock In {\em Communication, Control, and Computing (Allerton), 2015 53rd
  Annual Allerton Conference on}, pages 964--971, 2015.

\bibitem[LSP82]{lamport1982byzantine}
Leslie Lamport, Robert Shostak, and Marshall Pease.
\newblock The byzantine generals problem.
\newblock {\em ACM Transactions on Programming Languages and Systems (TOPLAS)},
  4(3):382--401, 1982.

\bibitem[LWR{\etalchar{+}}14]{liu2014asynchronous1}
Ji~Liu, Steve Wright, Christopher Re, Victor Bittorf, and Srikrishna Sridhar.
\newblock An asynchronous parallel stochastic coordinate descent algorithm.
\newblock In {\em ICML}, pages 469--477, 2014.

\bibitem[MPP{\etalchar{+}}15]{mania2015perturbed}
Horia Mania, Xinghao Pan, Dimitris Papailiopoulos, Benjamin Recht, Kannan
  Ramchandran, and Michael~I Jordan.
\newblock Perturbed iterate analysis for asynchronous stochastic optimization.
\newblock {\em NIPS, OPT}, 2015.

\bibitem[PGC{\etalchar{+}}17]{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in pytorch.
\newblock 2017.

\bibitem[PGCC17]{PyTorch}
Adam Paszke, Sam Gross, Soumith Chintala, and Gregory Chanan.
\newblock Pytorch, 2017.

\bibitem[Pip88]{pippenger1988reliable}
Nicholas Pippenger.
\newblock Reliable computation by formulas in the presence of noise.
\newblock {\em IEEE Transactions on Information Theory}, 34(2):194--197, 1988.

\bibitem[PL05]{MR_Data}
Bo~Pang and Lillian Lee.
\newblock Seeing stars: Exploiting class relationships for sentiment
  categorization with respect to rating scales.
\newblock In {\em ACL}, pages 115--124, 2005.

\bibitem[RPPA17]{reisizadeh2017coded}
Amirhossein Reisizadeh, Saurav Prakash, Ramtin Pedarsani, and Salman
  Avestimehr.
\newblock Coded computation over heterogeneous clusters.
\newblock In {\em ISIT}, pages 2408--2412. IEEE, 2017.

\bibitem[RRWN11]{recht2011hogwild}
Benjamin Recht, Christopher Re, Stephen Wright, and Feng Niu.
\newblock Hogwild: A lock-free approach to parallelizing stochastic gradient
  descent.
\newblock In {\em NIPS}, pages 693--701, 2011.

\bibitem[RTTD17]{raviv2017gradient}
Netanel Raviv, Itzhak Tamo, Rashish Tandon, and Alexandros~G Dimakis.
\newblock Gradient coding from cyclic mds codes and expander graphs.
\newblock {\em arXiv preprint arXiv:1707.03858}, 2017.

\bibitem[SLR16]{shah2016redundant}
Nihar~B Shah, Kangwook Lee, and Kannan Ramchandran.
\newblock When do redundant requests reduce latency?
\newblock {\em IEEE Transactions on Communications}, 64(2):715--722, 2016.

\bibitem[SZ14]{VGG}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[TLDK17]{Gradient_Coding}
Rashish Tandon, Qi~Lei, Alexandros~G Dimakis, and Nikos Karampatziakis.
\newblock Gradient coding: Avoiding stragglers in distributed learning.
\newblock In {\em ICML}, pages 3368--3376, 2017.

\bibitem[VN56]{von1956probabilistic}
John Von~Neumann.
\newblock Probabilistic logics and the synthesis of reliable organisms from
  unreliable components.
\newblock {\em Automata studies}, 34:43--98, 1956.

\bibitem[YGK17]{YangGK2017CodedInverse}
Yaoqing Yang, Pulkit Grover, and Soummya Kar.
\newblock Coded distributed computing for inverse problems.
\newblock In {\em {NIPS}}, pages 709--719, 2017.

\bibitem[ZCL15]{Syn_DMLSGD_12}
Sixin Zhang, Anna~E Choromanska, and Yann LeCun.
\newblock Deep learning with elastic averaging sgd.
\newblock In {\em NIPS}, pages 685--693, 2015.

\bibitem[ZKJ{\etalchar{+}}08]{zaharia2008improving}
Matei Zaharia, Andy Konwinski, Anthony~D Joseph, Randy~H Katz, and Ion Stoica.
\newblock Improving mapreduce performance in heterogeneous environments.
\newblock In {\em {OSDI}}, volume~8, page~7, 2008.

\end{thebibliography}
