\begin{thebibliography}{67}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2020)Agarwal, Shetty, and Fritz]{agarwal2020spurious}
Agarwal, V., Shetty, R., and Fritz, M.
\newblock Towards causal {VQA}: Revealing and reducing spurious correlations by
  invariant and covariant semantic editing.
\newblock \emph{Conference on Computer Vision and Pattern Recognition (CVPR)},
  2020.

\bibitem[Angwin et~al.(2016)Angwin, Larson, Mattu, and
  Kirchner]{angwin2016compas}
Angwin, J., Larson, J., Mattu, S., and Kirchner, L.
\newblock Machine bias.
\newblock \emph{Propublica}, 2016.

\bibitem[Barabas et~al.(2018)Barabas, Dinakar, Ito, Virza, and
  Zittrain]{barabas2018intervention}
Barabas, C., Dinakar, K., Ito, J., Virza, M., and Zittrain, J.
\newblock Interventions over predictions: Reframing the ethical debate for
  actuarial risk assessment.
\newblock \emph{Fairness, Accountability and Transparency in Machine Learning},
  2018.

\bibitem[Bearman et~al.(2009)Bearman, Korobov, and Thorne]{bearman09sexism}
Bearman, S., Korobov, N., and Thorne, A.
\newblock The fabric of internalized sexism.
\newblock \emph{Journal of Integrated Social Sciences 1(1): 10-47}, 2009.

\bibitem[Bennett et~al.(2021)Bennett, Gleason, Scheuerman, Bigham, Guo, and
  To]{bennett2021accessibility}
Bennett, C.~L., Gleason, C., Scheuerman, M.~K., Bigham, J.~P., Guo, A., and To,
  A.
\newblock “it’s complicated”: Negotiating accessibility and
  (mis)representation in image descriptions of race, gender, and disability.
\newblock \emph{Conference on Human Factors in Computing Systems (CHI)}, 2021.

\bibitem[Berk et~al.(2017)Berk, Heidari, Jabbari, Kearns, and
  Roth]{berk2017risk}
Berk, R., Heidari, H., Jabbari, S., Kearns, M., and Roth, A.
\newblock Fairness in criminal justice risk assessments: The state of the art.
\newblock \emph{Sociological Methods and Research}, 2017.

\bibitem[Bhattacharya \& Vogt(2007)Bhattacharya and Vogt]{bhattacharya2007}
Bhattacharya, J. and Vogt, W.~B.
\newblock Do instrumental variables belong in propensity scores?
\newblock \emph{NBER Technical Working Papers 0343, National Bureau of Economic
  Research, Inc.}, 2007.

\bibitem[Blodgett et~al.(2020)Blodgett, Barocas, III, and
  Wallach]{blodgett2020nlpbias}
Blodgett, S.~L., Barocas, S., III, H.~D., and Wallach, H.
\newblock Language (technology) is power: A critical survey of “bias” in
  nlp.
\newblock \emph{Association for Computational Linguistics (ACL)}, 2020.

\bibitem[Bolukbasi et~al.(2016)Bolukbasi, Chang, Zou, Saligrama, and
  Kalai]{bolukbasi2016embeddings}
Bolukbasi, T., Chang, K.-W., Zou, J., Saligrama, V., and Kalai, A.
\newblock Man is to computer programmer as woman is to homemaker? debiasing
  word embeddings.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  2016.

\bibitem[Breiman(2001)]{breiman2001cultures}
Breiman, L.
\newblock Statistical modeling: The two cultures.
\newblock \emph{Statistical Science}, 16:\penalty0 199--231, 2001.

\bibitem[Buolamwini \& Gebru(2018)Buolamwini and
  Gebru]{buolamwini2018gendershades}
Buolamwini, J. and Gebru, T.
\newblock Gender shades: Intersectional accuracy disparities in commercial
  gender classification.
\newblock \emph{Proceedings of Machine Learning Research}, 81, 2018.

\bibitem[Caliskan et~al.(2017)Caliskan, Bryson, and
  Narayanan]{caliskan2017weat}
Caliskan, A., Bryson, J.~J., and Narayanan, A.
\newblock Semantics derived automatically from language corpora contain
  human-like biases.
\newblock \emph{Science}, 2017.

\bibitem[Chen \& Wu(2020)Chen and Wu]{chen2020threshold}
Chen, M. and Wu, M.
\newblock Towards threshold invariant fair classification.
\newblock \emph{Conference on Uncertainty in Artificial Intelligence (UAI)},
  2020.

\bibitem[Choi et~al.(2020)Choi, Grover, Singh, Shu, and Ermon]{choi2020gan}
Choi, K., Grover, A., Singh, T., Shu, R., and Ermon, S.
\newblock Fair generative modeling via weak supervision.
\newblock \emph{arXiv:1910.12008}, 2020.

\bibitem[Chouldechova(2016)]{chouldechova2016recidivism}
Chouldechova, A.
\newblock Fair prediction with disparate impact: A study of bias in recidivism
  prediction instrument.
\newblock \emph{Big Data}, 2016.

\bibitem[D'Amour et~al.(2020)D'Amour, Heller, Moldovan, Adlam, Alipanahi,
  Beutel, Chen, Deaton, Eisenstein, Hoffman, Hormozdiari, Houlsby, Hou, Jerfel,
  Karthikesalingam, Lucic, Ma, McLean, Mincu, Mitani, Montanari, Nado,
  Natarajan, Nielson, Osborne, Raman, Ramasamy, Sayres, Schrouff, Seneviratne,
  Sequeira, Suresh, Veitch, Vladymyrov, Wang, Webster, Yadlowsky, Yun, Zhai,
  and Sculley]{damour2020underspecification}
D'Amour, A., Heller, K., Moldovan, D., Adlam, B., Alipanahi, B., Beutel, A.,
  Chen, C., Deaton, J., Eisenstein, J., Hoffman, M.~D., Hormozdiari, F.,
  Houlsby, N., Hou, S., Jerfel, G., Karthikesalingam, A., Lucic, M., Ma, Y.,
  McLean, C., Mincu, D., Mitani, A., Montanari, A., Nado, Z., Natarajan, V.,
  Nielson, C., Osborne, T.~F., Raman, R., Ramasamy, K., Sayres, R., Schrouff,
  J., Seneviratne, M., Sequeira, S., Suresh, H., Veitch, V., Vladymyrov, M.,
  Wang, X., Webster, K., Yadlowsky, S., Yun, T., Zhai, X., and Sculley, D.
\newblock Underspecification presents challenges for credibility in modern
  machine learning.
\newblock \emph{arXiv:2011.03395}, 2020.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{devlin2019bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{Annual Conference of the North American Chapter of the
  Association for Computational Linguistics: Human Language Technologies
  (NAACL-HLT)}, 2019.

\bibitem[Dong \& Rudin(2019)Dong and Rudin]{dong2019clouds}
Dong, J. and Rudin, C.
\newblock Variable importance clouds: A way to explore variable importance for
  the set of good models.
\newblock \emph{arXiv:1901.03209}, 2019.

\bibitem[Dwork et~al.(2012)Dwork, Hardt, Pitassi, Reingold, and
  Zemel]{dwork2012awareness}
Dwork, C., Hardt, M., Pitassi, T., Reingold, O., and Zemel, R.
\newblock Fairness through awareness.
\newblock \emph{Proceedings of the 3rd Innovations in Theoretical Computer
  Science Conference}, 2012.

\bibitem[Efron(1992)]{efron1992bootstrap}
Efron, B.
\newblock Bootstrap methods: another look at the jackknife.
\newblock In \emph{Breakthroughs in statistics}, pp.\  569--593. Springer,
  1992.

\bibitem[Fisher et~al.(2019)Fisher, Rudin, and Dominici]{fisher2019wrong}
Fisher, A., Rudin, C., and Dominici, F.
\newblock All models are wrong, but many are useful: Learning a variable's
  importance by studying an entire class of prediction models simultaneously.
\newblock \emph{Journal of Machine Learning Research}, 20, 2019.

\bibitem[Flores et~al.(2016)Flores, Bechtel, and Lowenkamp]{flores2016compas}
Flores, A.~W., Bechtel, K., and Lowenkamp, C.~T.
\newblock False positives, false negatives, and false analyses: A rejoinder to
  "machine bias: There's software used across the country to predict future
  criminals. and it's biased against blacks.".
\newblock \emph{Federal Probation Journal}, 80, 2016.

\bibitem[Foulds et~al.(2018)Foulds, Islam, Keya, and
  Pan]{foulds2018intersectionality}
Foulds, J., Islam, R., Keya, K.~N., and Pan, S.
\newblock An intersectional definition of fairness.
\newblock \emph{arXiv:1807.08362}, 2018.

\bibitem[Friedler et~al.(2019)Friedler, Scheidegger, Venkatasubramanian,
  Choudhary, Hamilton, and Roth]{friedler2019comparative}
Friedler, S.~A., Scheidegger, C., Venkatasubramanian, S., Choudhary, S.,
  Hamilton, E.~P., and Roth, D.
\newblock A comparative study of fairness-enhancing interventions in machine
  learning.
\newblock \emph{Conference on Fairness, Accountability, and Transparency
  (FAccT)}, 2019.

\bibitem[Green(2020)]{green2020recidivism}
Green, B.
\newblock The false promise of risk assessments: Epistemic reform and the
  limits of fairness.
\newblock \emph{ACM Conference on Fairness, Accountability, and Transparency
  (ACM FAccT)}, 2020.

\bibitem[Grgic-Hlaca et~al.(2016)Grgic-Hlaca, Zafar, Gummadi, and
  Weller]{hlaca2016case}
Grgic-Hlaca, N., Zafar, M.~B., Gummadi, K.~P., and Weller, A.
\newblock The case for process fairness in learning: Feature selection for fair
  decision making.
\newblock \emph{NeurIPS Symposium on Machine Learning and the Law}, 2016.

\bibitem[Hancox-Li(2020)]{li2020explanations}
Hancox-Li, L.
\newblock Robustness in machine learning explanations: Does it matter?
\newblock \emph{Conference on Fairness, Accountability, and Transparency
  (FAccT)}, 2020.

\bibitem[Hardt et~al.(2016)Hardt, Price, and Srebro]{hardt2016equalopp}
Hardt, M., Price, E., and Srebro, N.
\newblock Equality of opportunity in supervised learning.
\newblock \emph{arXiv:1610.02413}, 2016.

\bibitem[Havens \& Stal(2019)Havens and Stal]{havens2019fitbert}
Havens, S. and Stal, A.
\newblock Use {BERT} to fill in the blanks, 2019.
\newblock URL \url{https://github.com/Qordobacode/fitbert}.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he16resnet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock \emph{European Conference on Computer Vision (ECCV)}, 2016.

\bibitem[Hebert-Johnson et~al.(2018)Hebert-Johnson, Kim, Reingold, and
  Rothblum]{hebertjohnson2018multicalibration}
Hebert-Johnson, U., Kim, M.~P., Reingold, O., and Rothblum, G.~N.
\newblock Multicalibration: Calibration for the (computationally-identifiable)
  masses.
\newblock \emph{International Conference on Machine Learning (ICML)}, 2018.

\bibitem[Hendricks et~al.(2018)Hendricks, Burns, Saenko, Darrell, and
  Rohrbach]{hendricks2018snowboard}
Hendricks, L.~A., Burns, K., Saenko, K., Darrell, T., and Rohrbach, A.
\newblock Women also snowboard: Overcoming bias in captioning models.
\newblock \emph{European Conference on Computer Vision (ECCV)}, 2018.

\bibitem[Hugsy(2017)]{english_adj}
Hugsy.
\newblock English adjectives.
\newblock \url{https://gist.github.com/hugsy/8910dc78d208e40de42deb29e62df913},
  2017.

\bibitem[Jain et~al.(2020)Jain, Olmo, Sengupta, Manikonda, and
  Kambhampati]{jain2020gan}
Jain, N., Olmo, A., Sengupta, S., Manikonda, L., and Kambhampati, S.
\newblock Imperfect imaganation: Implications of gans exacerbating biases on
  facial data augmentation and snapchat selfie lenses.
\newblock \emph{arXiv:2001.09528}, 2020.

\bibitem[Jia et~al.(2020)Jia, Meng, Zhao, and Chang]{jia2020posterior}
Jia, S., Meng, T., Zhao, J., and Chang, K.-W.
\newblock Mitigating gender bias amplification in distribution by posterior
  regularization.
\newblock \emph{Annual Meeting of the Association for Computational Linguistics
  (ACL)}, 2020.

\bibitem[Keyes(2018)]{keyes2018agr}
Keyes, O.
\newblock The misgendering machines: Trans/{HCI} implications of automatic
  gender recognition.
\newblock \emph{Proceedings of the ACM on Human-Computer Interaction}, 2018.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and Hinton]{alexnet}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  pp.\  1097--1105, 2012.

\bibitem[Kuang \& Davison(2016)Kuang and Davison]{kuang2016semantic}
Kuang, S. and Davison, B.~D.
\newblock Semantic and context-aware linguistic model for bias detection.
\newblock \emph{Proc. of the Natural Language Processing meets Journalism
  IJCAI-16 Workshop}, 2016.

\bibitem[Kusner et~al.(2017)Kusner, Loftus, Russell, and
  Silva]{kusner2017counterfactual}
Kusner, M.~J., Loftus, J.~R., Russell, C., and Silva, R.
\newblock Counterfactual fairness.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  2017.

\bibitem[Larson(2017)]{larson2017gender}
Larson, B.~N.
\newblock Gender as a variable in natural-language processing: Ethical
  considerations.
\newblock \emph{Proceedings of the First ACL Workshop on Ethics in Natural
  Language Processing}, 2017.

\bibitem[Leino et~al.(2019)Leino, Black, Fredrikson, Sen, and
  Datta]{leino2019feature}
Leino, K., Black, E., Fredrikson, M., Sen, S., and Datta, A.
\newblock Feature-wise bias amplification.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2019.

\bibitem[Liang et~al.(2020)Liang, Li, Zheng, Lim, Salakhutdinov, and
  Morency]{liang2020big}
Liang, P.~P., Li, I.~M., Zheng, E., Lim, Y.~C., Salakhutdinov, R., and Morency,
  L.-P.
\newblock Towards debiasing sentence representations.
\newblock \emph{Annual Meeting of the Association for Computational Linguistics
  (ACL)}, 2020.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Bourdev, Girshick, Hays, Perona,
  Ramanan, Zitnick, and Dollar]{lin14coco}
Lin, T.-Y., Maire, M., Belongie, S., Bourdev, L., Girshick, R., Hays, J.,
  Perona, P., Ramanan, D., Zitnick, C.~L., and Dollar, P.
\newblock Microsoft {COCO}: Common objects in context.
\newblock \emph{European Conference on Computer Vision (ECCV)}, 2014.

\bibitem[Liu et~al.(2015)Liu, Luo, Wang, and Tang]{liu2015faceattributes}
Liu, Z., Luo, P., Wang, X., and Tang, X.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{Proceedings of International Conference on Computer Vision
  (ICCV)}, December 2015.

\bibitem[Lu et~al.(2019)Lu, Mardziel, Wu, Amancharla, and Datta]{lu2019nlp}
Lu, K., Mardziel, P., Wu, F., Amancharla, P., and Datta, A.
\newblock Gender bias in neural natural language processing.
\newblock \emph{arXiv:1807.11714}, 2019.

\bibitem[Marx et~al.(2020)Marx, du~Pin~Calmon, and Ustun]{marx2020multiplicity}
Marx, C.~T., du~Pin~Calmon, F., and Ustun, B.
\newblock Predictive multiplicity in classification.
\newblock \emph{arXiv:1909.06677}, 2020.

\bibitem[May et~al.(2019)May, Wang, Bordia, Bowman, and
  Rudinger]{may2019sentence}
May, C., Wang, A., Bordia, S., Bowman, S.~R., and Rudinger, R.
\newblock On measuring social biases in sentence encoders.
\newblock \emph{Annual Conference of the North American Chapter of the
  Association for Computational Linguistics (NACCL)}, 2019.

\bibitem[Mehrabi et~al.(2019)Mehrabi, Morstatter, Saxena, Lerman, and
  Galstyan]{mehrabi2019survey}
Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., and Galstyan, A.
\newblock A survey on bias and fairness in machine learning.
\newblock \emph{arXiv:1908.09635}, 2019.

\bibitem[Middleton et~al.(2016)Middleton, Scott, Diakow, and
  Hill]{middleton2016}
Middleton, J.~A., Scott, M.~A., Diakow, R., and Hill, J.~L.
\newblock Bias amplification and bias unmasking.
\newblock \emph{Political Analysis}, 3:\penalty0 307--323, 2016.

\bibitem[of~Labor~Statistics(2016)]{labor2016}
of~Labor~Statistics, U.~B.
\newblock Employed persons by detailed occupation, sex, race, and hispanic or
  latino ethnicity.
\newblock 2016.
\newblock URL \url{https://www.bls.gov/cps/aa2016/cpsaat11.pdf}.

\bibitem[Olteanu et~al.(2019)Olteanu, Castillo, Diaz, and
  Kiciman]{olteanu2019social}
Olteanu, A., Castillo, C., Diaz, F., and Kiciman, E.
\newblock Social data: Biases, methodological pitfalls, and ethical boundaries.
\newblock \emph{Frontiers in Big Data}, 2019.

\bibitem[Pawelczyk et~al.(2020)Pawelczyk, Broelemann, and
  Kasneci]{pawelczyk2020multiplicity}
Pawelczyk, M., Broelemann, K., and Kasneci, G.
\newblock On counterfactual explanations under predictive multiplicity.
\newblock \emph{Conference on Uncertainty in Artificial Intelligence (UAI)},
  2020.

\bibitem[Pearl(2010)]{pearl2010}
Pearl, J.
\newblock On a class of bias-amplifying variables that endanger effect
  estimates.
\newblock \emph{Uncertainty in Artificial Intelligence}, 2010.

\bibitem[Pearl(2011)]{pearl2011}
Pearl, J.
\newblock Invited commentary: Understanding bias amplification.
\newblock \emph{American Journal of Epidemiology}, 174, 2011.

\bibitem[Qian et~al.(2019)Qian, Muaz, Zhang, and
  Hyun]{qian2019genderequalizing}
Qian, Y., Muaz, U., Zhang, B., and Hyun, J.~W.
\newblock Reducing gender bias in word-level language models with a
  gender-equalizing loss function.
\newblock \emph{ACL-SRW}, 2019.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and Fei-Fei]{imagenet}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., Berg, A.~C., and Fei-Fei, L.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock \emph{International Journal of Computer Vision (IJCV)}, 115\penalty0
  (3):\penalty0 211--252, 2015.
\newblock \doi{10.1007/s11263-015-0816-y}.

\bibitem[Scheuerman et~al.(2020)Scheuerman, Wade, Lustig, and
  Brubaker]{scheuerman2020identity}
Scheuerman, M.~K., Wade, K., Lustig, C., and Brubaker, J.~R.
\newblock How we’ve taught algorithms to see identity: Constructing race and
  gender in image databases for facial analysis.
\newblock \emph{Proceedings of the ACM on Human-Computer Interaction}, 2020.

\bibitem[Simonyan \& Zisserman(2014)Simonyan and Zisserman]{simonyan2014vgg}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv:1409.1556}, 2014.

\bibitem[Singh et~al.(2020)Singh, Mahajan, Grauman, Lee, Feiszli, and
  Ghadiyaram]{singh2020context}
Singh, K.~K., Mahajan, D., Grauman, K., Lee, Y.~J., Feiszli, M., and
  Ghadiyaram, D.
\newblock Don't judge an object by its context: Learning to overcome contextual
  bias.
\newblock \emph{Conference on Computer Vision and Pattern Recognition (CVPR)},
  2020.

\bibitem[Stock \& Cisse(2018)Stock and Cisse]{stock2018mistakes}
Stock, P. and Cisse, M.
\newblock {ConvNets} and {ImageNet} beyond accuracy: Understanding mistakes and
  uncovering biases.
\newblock \emph{European Conference on Computer Vision (ECCV)}, 2018.

\bibitem[Suresh \& Guttag(2019)Suresh and Guttag]{suresh2019framework}
Suresh, H. and Guttag, J.~V.
\newblock A framework for understanding unintended consequences of machine
  learning.
\newblock \emph{arXiv:1901.10002}, 2019.

\bibitem[Tang et~al.(2020)Tang, Du, Li, Liu, and Hu]{tang2020caption}
Tang, R., Du, M., Li, Y., Liu, Z., and Hu, X.
\newblock Mitigating gender bias in captioning systems.
\newblock \emph{arXiv:2006.08315}, 2020.

\bibitem[Wang et~al.(2019)Wang, Zhao, Yatskar, Chang, and
  Ordonez]{wang2019balanced}
Wang, T., Zhao, J., Yatskar, M., Chang, K.-W., and Ordonez, V.
\newblock Balanced datasets are not enough: Estimating and mitigating gender
  bias in deep image representations.
\newblock \emph{International Conference on Computer Vision (ICCV)}, 2019.

\bibitem[Wick et~al.(2019)Wick, Panda, and Tristan]{wick2019tradeoff}
Wick, M., Panda, S., and Tristan, J.-B.
\newblock Unlocking fairness: a trade-off revisited.
\newblock \emph{Conference on Neural Information Processing Systems (NeurIPS)},
  2019.

\bibitem[Wooldridge(2016)]{wooldridge2016}
Wooldridge, J.~M.
\newblock Should instrumental variables be used as matching variables?
\newblock \emph{Research in Economics}, 70:\penalty0 232--237, 2016.

\bibitem[Zhao et~al.(2017)Zhao, Wang, Yatskar, Ordonez, and
  Chang]{zhao2017menshop}
Zhao, J., Wang, T., Yatskar, M., Ordonez, V., and Chang, K.-W.
\newblock Men also like shopping: Reducing gender bias amplification using
  corpus-level constraints.
\newblock \emph{Conference on Empirical Methods in Natural Language Processing
  (EMNLP)}, 2017.

\bibitem[Zhao et~al.(2018)Zhao, Wang, Yatskar, Ordonez, and
  Chang]{zhao2018winobias}
Zhao, J., Wang, T., Yatskar, M., Ordonez, V., and Chang, K.-W.
\newblock Gender bias in coreference resolution: Evaluation and debiasing
  methods.
\newblock \emph{North American Chapter of the Association for Computational
  Linguistics (NAACL)}, 2018.

\end{thebibliography}
