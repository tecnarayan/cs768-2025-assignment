\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{MMMW21}

\bibitem[ACSS20]{AlmanCS020}
Josh Alman, Timothy Chu, Aaron Schild, and Zhao Song.
\newblock Algorithms and hardness for linear algebra on geometric graphs.
\newblock In Sandy Irani, editor, {\em 61st {IEEE} Annual Symposium on
  Foundations of Computer Science, {FOCS} 2020, Durham, NC, USA, November
  16-19, 2020}, pages 541--552. {IEEE}, 2020.

\bibitem[AG11]{ascher2011first}
Uri~M Ascher and Chen Greif.
\newblock {\em A first course on numerical methods}.
\newblock SIAM, 2011.

\bibitem[AKK{\etalchar{+}}20]{ahle2020oblivious}
Thomas~D Ahle, Michael Kapralov, Jakob~BT Knudsen, Rasmus Pagh, Ameya
  Velingker, David~P Woodruff, and Amir Zandieh.
\newblock Oblivious sketching of high-degree polynomial kernels.
\newblock In {\em Proceedings of the Fourteenth Annual ACM-SIAM Symposium on
  Discrete Algorithms}, pages 141--160. SIAM, 2020.

\bibitem[ANW14]{avron2014subspace}
Haim Avron, Huy Nguyen, and David Woodruff.
\newblock Subspace embeddings for the polynomial kernel.
\newblock {\em Advances in neural information processing systems}, 27, 2014.

\bibitem[AW21]{alman2021refined}
Josh Alman and Virginia~Vassilevska Williams.
\newblock A refined laser method and faster matrix multiplication.
\newblock In {\em Proceedings of the 2021 ACM-SIAM Symposium on Discrete
  Algorithms (SODA)}, pages 522--539. SIAM, 2021.

\bibitem[BCIS18]{backurs2018}
Arturs Backurs, Moses Charikar, Piotr Indyk, and Paris Siminelakis.
\newblock Efficient density evaluation for smooth kernels.
\newblock {\em 2018 IEEE 59th Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 615--626, 2018.

\bibitem[BCW20]{bakshi2020robust}
Ainesh Bakshi, Nadiia Chepurko, and David~P Woodruff.
\newblock Robust and sample optimal algorithms for psd low rank approximation.
\newblock In {\em 2020 IEEE 61st Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 506--516. IEEE, 2020.

\bibitem[BCW22]{bakshi2022low}
Ainesh Bakshi, Kenneth~L Clarkson, and David~P Woodruff.
\newblock Low-rank approximation with $1/\varepsilon^{1/3}$ matrix-vector
  products.
\newblock {\em arXiv preprint arXiv:2202.05120}, 2022.

\bibitem[BHSW20]{braverman2020gradient}
Mark Braverman, Elad Hazan, Max Simchowitz, and Blake Woodworth.
\newblock The gradient complexity of linear regression.
\newblock In {\em Conference on Learning Theory}, pages 627--647. PMLR, 2020.

\bibitem[BIMW21]{backurs2021}
Arturs Backurs, Piotr Indyk, Cameron Musco, and Tal Wagner.
\newblock Faster kernel matrix algebra via density estimation.
\newblock In {\em Proceedings of the 38th International Conference on Machine
  Learning}, pages 500--510, 2021.

\bibitem[BIW19]{backurs2019space}
Arturs Backurs, Piotr Indyk, and Tal Wagner.
\newblock Space and time efficient kernel density estimation in high
  dimensions.
\newblock In {\em Advances in Neural Information Processing Systems 32: Annual
  Conference on Neural Information Processing Systems, NeurIPS}, pages
  15773--15782, 2019.

\bibitem[BW18]{bakshi2018sublinear}
Ainesh Bakshi and David Woodruff.
\newblock Sublinear time low-rank approximation of distance matrices.
\newblock {\em Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Can20]{canonne2020survey}
Cl{\'e}ment~L Canonne.
\newblock A survey on distribution testing: Your data is big. but is it blue?
\newblock {\em Theory of Computing}, pages 1--100, 2020.

\bibitem[CC08]{cox2008multidimensional}
Michael~AA Cox and Trevor~F Cox.
\newblock Multidimensional scaling.
\newblock In {\em Handbook of data visualization}, pages 315--347. Springer,
  2008.

\bibitem[CHC{\etalchar{+}}10]{chang2010training}
Yin-Wen Chang, Cho-Jui Hsieh, Kai-Wei Chang, Michael Ringgaard, and Chih-Jen
  Lin.
\newblock Training and testing low-degree polynomial data mappings via linear
  svm.
\newblock {\em Journal of Machine Learning Research}, 11(4), 2010.

\bibitem[CHL21]{childs2021quantum}
Andrew~M Childs, Shih-Han Hung, and Tongyang Li.
\newblock Quantum query complexity with matrix-vector products.
\newblock {\em arXiv preprint arXiv:2102.11349}, 2021.

\bibitem[CKNS20]{charikar2020}
Moses Charikar, Michael Kapralov, Navid Nouri, and Paris Siminelakis.
\newblock Kernel density estimation through density constrained near neighbor
  search.
\newblock {\em 2020 IEEE 61st Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 172--183, 2020.

\bibitem[CS17]{charikar2017hashing}
Moses Charikar and Paris Siminelakis.
\newblock Hashing-based-estimators for kernel density in high dimensions.
\newblock In Chris Umans, editor, {\em 58th {IEEE} Annual Symposium on
  Foundations of Computer Science, {FOCS}}, pages 1032--1043, 2017.

\bibitem[DPRV15]{dokmanic2015euclidean}
Ivan Dokmanic, Reza Parhizkar, Juri Ranieri, and Martin Vetterli.
\newblock Euclidean distance matrices: essential theory, algorithms, and
  applications.
\newblock {\em IEEE Signal Processing Magazine}, 32(6):12--30, 2015.

\bibitem[EK12]{eldar2012compressed}
Yonina~C Eldar and Gitta Kutyniok.
\newblock {\em Compressed sensing: theory and applications}.
\newblock Cambridge university press, 2012.

\bibitem[ES20]{epstein2020property}
Rogers Epstein and Sandeep Silwal.
\newblock Property testing of lp-type problems.
\newblock In {\em 47th International Colloquium on Automata, Languages, and
  Programming (ICALP 2020)}. Schloss Dagstuhl-Leibniz-Zentrum f{\"u}r
  Informatik, 2020.

\bibitem[Gol17]{goldreich2017introduction}
Oded Goldreich.
\newblock {\em Introduction to property testing}.
\newblock Cambridge University Press, 2017.

\bibitem[HS93]{holm1993protein}
Liisa Holm and Chris Sander.
\newblock Protein structure comparison by alignment of distance matrices.
\newblock {\em Journal of molecular biology}, 233(1):123--138, 1993.

\bibitem[ILLP04]{indyk2004closest}
Piotr Indyk, Moshe Lewenstein, Ohad Lipsky, and Ely Porat.
\newblock Closest pair problems in very high dimensions.
\newblock In {\em International Colloquium on Automata, Languages, and
  Programming}, pages 782--792. Springer, 2004.

\bibitem[IP01]{impagliazzo2001complexity}
Russell Impagliazzo and Ramamohan Paturi.
\newblock On the complexity of k-sat.
\newblock {\em Journal of Computer and System Sciences}, 62(2):367--375, 2001.

\bibitem[IPZ01]{impagliazzo2001problems}
Russell Impagliazzo, Ramamohan Paturi, and Francis Zane.
\newblock Which problems have strongly exponential complexity?
\newblock {\em Journal of Computer and System Sciences}, 63(4):512--530, 2001.

\bibitem[IRW17]{indyk2017practical}
Piotr Indyk, Ilya Razenshteyn, and Tal Wagner.
\newblock Practical data-dependent metric compression with provable guarantees.
\newblock {\em Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[IVWW19]{indyk2019sample}
Pitor Indyk, Ali Vakilian, Tal Wagner, and David~P Woodruff.
\newblock Sample-optimal low-rank approximation of distance matrices.
\newblock In {\em Conference on Learning Theory}, pages 1723--1751. PMLR, 2019.

\bibitem[JL84]{originalJL}
W.~Johnson and J.~Lindenstrauss.
\newblock Extensions of lipschitz maps into a hilbert space.
\newblock {\em Contemporary Mathematics}, 26:189--206, 01 1984.

\bibitem[Kru64]{kruskal1964multidimensional}
Joseph~B Kruskal.
\newblock Multidimensional scaling by optimizing goodness of fit to a nonmetric
  hypothesis.
\newblock {\em Psychometrika}, 29(1):1--27, 1964.

\bibitem[Kru78]{kruskal1978multidimensional}
Joseph~B Kruskal.
\newblock {\em Multidimensional scaling}.
\newblock Number~11. Sage, 1978.

\bibitem[Kuc09]{kuczma2009introduction}
Marek Kuczma.
\newblock {\em An introduction to the theory of functional equations and
  inequalities: Cauchy's equation and Jensen's inequality}.
\newblock Springer Science \& Business Media, 2009.

\bibitem[Lan50]{lanczos1950iteration}
Cornelius Lanczos.
\newblock An iteration method for the solution of the eigenvalue problem of
  linear differential and integral operators.
\newblock 1950.

\bibitem[LeC98]{lecun1998mnist}
Yann LeCun.
\newblock The mnist database of handwritten digits.
\newblock {\em http://yann. lecun. com/exdb/mnist/}, 1998.

\bibitem[LN17]{larsen2017optimality}
Kasper~Green Larsen and Jelani Nelson.
\newblock Optimality of the johnson-lindenstrauss lemma.
\newblock In {\em 2017 IEEE 58th Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 633--638. IEEE, 2017.

\bibitem[LSZ21]{lee2021quantum}
Troy Lee, Miklos Santha, and Shengyu Zhang.
\newblock Quantum algorithms for graph problems with cut queries.
\newblock In {\em Proceedings of the 2021 ACM-SIAM Symposium on Discrete
  Algorithms (SODA)}, pages 939--958. SIAM, 2021.

\bibitem[MM15]{musco2015randomized}
Cameron Musco and Christopher Musco.
\newblock Randomized block krylov methods for stronger and faster approximate
  singular value decomposition.
\newblock {\em Advances in neural information processing systems}, 28, 2015.

\bibitem[MMMW21]{meyer2021hutch++}
Raphael~A Meyer, Cameron Musco, Christopher Musco, and David~P Woodruff.
\newblock Hutch++: Optimal stochastic trace estimation.
\newblock In {\em Symposium on Simplicity in Algorithms (SOSA)}, pages
  142--155. SIAM, 2021.

\bibitem[PSM14]{pennington2014glove}
Jeffrey Pennington, Richard Socher, and Christopher~D Manning.
\newblock Glove: Global vectors for word representation.
\newblock In {\em Proceedings of the 2014 conference on empirical methods in
  natural language processing (EMNLP)}, pages 1532--1543, 2014.

\bibitem[RWZ20]{rashtchian2020vector}
Cyrus Rashtchian, David~P Woodruff, and Hanlin Zhu.
\newblock Vector-matrix-vector queries for solving linear algebra, statistics,
  and graph problems.
\newblock {\em arXiv preprint arXiv:2006.14015}, 2020.

\bibitem[S{\etalchar{+}}94]{shewchuk1994introduction}
Jonathan~Richard Shewchuk et~al.
\newblock An introduction to the conjugate gradient method without the
  agonizing pain, 1994.

\bibitem[SRB{\etalchar{+}}19]{siminelakis2019rehashing}
Paris Siminelakis, Kexin Rong, Peter Bailis, Moses Charikar, and
  Philip~Alexander Levis.
\newblock Rehashing kernel evaluation in high dimensions.
\newblock In {\em Proceedings of the 36th International Conference on Machine
  Learning, {ICML}}, pages 5789--5798, 2019.

\bibitem[SV{\etalchar{+}}14]{sachdeva2014faster}
Sushant Sachdeva, Nisheeth~K Vishnoi, et~al.
\newblock Faster algorithms via approximation theory.
\newblock {\em Foundations and Trends{\textregistered} in Theoretical Computer
  Science}, 9(2):125--210, 2014.

\bibitem[SWYZ21a]{song2021fast}
Zhao Song, David Woodruff, Zheng Yu, and Lichen Zhang.
\newblock Fast sketching of polynomial kernels of polynomial degree.
\newblock In {\em International Conference on Machine Learning}, pages
  9812--9823. PMLR, 2021.

\bibitem[SWYZ21b]{sun2021querying}
Xiaoming Sun, David~P Woodruff, Guang Yang, and Jialin Zhang.
\newblock Querying a matrix through matrix-vector products.
\newblock {\em ACM Transactions on Algorithms (TALG)}, 17(4):1--19, 2021.

\bibitem[SY07]{so2007theory}
Anthony Man-Cho So and Yinyu Ye.
\newblock Theory of semidefinite programming for sensor network localization.
\newblock {\em Mathematical Programming}, 109(2):367--384, 2007.

\bibitem[TSL00]{tenenbaum2000global}
Joshua~B Tenenbaum, Vin~de Silva, and John~C Langford.
\newblock A global geometric framework for nonlinear dimensionality reduction.
\newblock {\em science}, 290(5500):2319--2323, 2000.

\bibitem[Wie86]{wiedemann1986solving}
Douglas Wiedemann.
\newblock Solving sparse linear equations over finite fields.
\newblock {\em IEEE transactions on information theory}, 32(1):54--62, 1986.

\bibitem[Wil05]{williams2005new}
Ryan Williams.
\newblock A new algorithm for optimal 2-constraint satisfaction and its
  implications.
\newblock {\em Theoretical Computer Science}, 348(2-3):357--365, 2005.

\bibitem[Woo14]{woodruff2014sketching}
David~P Woodruff.
\newblock Sketching as a tool for numerical linear algebra.
\newblock {\em arXiv preprint arXiv:1411.4357}, 2014.

\bibitem[WS06]{weinberger2006unsupervised}
Kilian~Q Weinberger and Lawrence~K Saul.
\newblock Unsupervised learning of image manifolds by semidefinite programming.
\newblock {\em International journal of computer vision}, 70(1):77--90, 2006.

\bibitem[WZ20]{woodruff2020near}
David Woodruff and Amir Zandieh.
\newblock Near input sparsity time kernel embeddings via adaptive sampling.
\newblock In {\em International Conference on Machine Learning}, pages
  10324--10333. PMLR, 2020.

\end{thebibliography}
