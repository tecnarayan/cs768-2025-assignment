\begin{thebibliography}{48}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amodei et~al.(2016)Amodei, Olah, Steinhardt, Christiano, Schulman, and
  Man{\'e}]{amodei2016concrete}
Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and
  Dan Man{\'e}.
\newblock Concrete problems in ai safety.
\newblock \emph{arXiv preprint arXiv:1606.06565}, 2016.

\bibitem[Andreas(2022)]{andreas2022language}
Jacob Andreas.
\newblock Language models as agent models.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2022}, pp.\  5769--5779, Abu Dhabi, United Arab Emirates, December
  2022. Association for Computational Linguistics.
\newblock URL \url{https://aclanthology.org/2022.findings-emnlp.423}.

\bibitem[Askell et~al.(2021)Askell, Bai, Chen, Drain, Ganguli, Henighan, Jones,
  Joseph, Mann, DasSarma, et~al.]{askell2021general}
Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan,
  Andy Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, et~al.
\newblock A general language assistant as a laboratory for alignment.
\newblock \emph{arXiv preprint arXiv:2112.00861}, 2021.

\bibitem[Atillah(2023)]{suicide_convincing}
Imane~El Atillah.
\newblock Man ends his life after an ai chatbot 'encouraged' him to sacrifice
  himself to stop climate change.
\newblock \emph{Euronews}, 2023.

\bibitem[Bai et~al.(2022)Bai, Jones, Ndousse, Askell, Chen, DasSarma, Drain,
  Fort, Ganguli, Henighan, et~al.]{bai2022training}
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma,
  Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et~al.
\newblock Training a helpful and harmless assistant with reinforcement learning
  from human feedback.
\newblock \emph{arXiv preprint arXiv:2204.05862}, 2022.

\bibitem[Bender et~al.(2021)Bender, Gebru, McMillan-Major, and
  Shmitchell]{bender2021dangers}
Emily~M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret
  Shmitchell.
\newblock On the dangers of stochastic parrots: Can language models be too big?
\newblock In \emph{Proceedings of the 2021 ACM conference on fairness,
  accountability, and transparency}, pp.\  610--623, 2021.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 1877--1901, 2020.

\bibitem[Bubeck et~al.(2023)Bubeck, Chandrasekaran, Eldan, Gehrke, Horvitz,
  Kamar, Lee, Lee, Li, Lundberg, et~al.]{bubeck2023sparks}
S{\'e}bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric
  Horvitz, Ece Kamar, Peter Lee, Yin~Tat Lee, Yuanzhi Li, Scott Lundberg,
  et~al.
\newblock Sparks of artificial general intelligence: Early experiments with
  gpt-4.
\newblock \emph{arXiv preprint arXiv:2303.12712}, 2023.

\bibitem[Deshpande et~al.(2023)Deshpande, Murahari, Rajpurohit, Kalyan, and
  Narasimhan]{deshpande2023toxicity}
Ameet Deshpande, Vishvak Murahari, Tanmay Rajpurohit, Ashwin Kalyan, and
  Karthik Narasimhan.
\newblock Toxicity in chatgpt: Analyzing persona-assigned language models.
\newblock \emph{arXiv preprint arXiv:2304.05335}, 2023.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova]{devlin-etal-2019-bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pp.\  4171--4186,
  Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N19-1423}.
\newblock URL \url{https://aclanthology.org/N19-1423}.

\bibitem[Gehman et~al.(2020)Gehman, Gururangan, Sap, Choi, and
  Smith]{gehman-etal-2020-realtoxicityprompts}
Samuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, and Noah~A. Smith.
\newblock {R}eal{T}oxicity{P}rompts: Evaluating neural toxic degeneration in
  language models.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2020}, pp.\  3356--3369, Online, November 2020. Association for
  Computational Linguistics.
\newblock \doi{10.18653/v1/2020.findings-emnlp.301}.
\newblock URL \url{https://aclanthology.org/2020.findings-emnlp.301}.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Carlini, Schulman, and
  Steinhardt]{hendrycks2021unsolved}
Dan Hendrycks, Nicholas Carlini, John Schulman, and Jacob Steinhardt.
\newblock Unsolved problems in ml safety.
\newblock \emph{arXiv preprint arXiv:2109.13916}, 2021.

\bibitem[Hu et~al.(2022)Hu, yelong shen, Wallis, Allen-Zhu, Li, Wang, Wang, and
  Chen]{hu2021lora}
Edward~J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
  Wang, Lu~Wang, and Weizhu Chen.
\newblock Lo{RA}: Low-rank adaptation of large language models.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=nZeVKeeFYf9}.

\bibitem[Hutchinson et~al.(2020)Hutchinson, Prabhakaran, Denton, Webster,
  Zhong, and Denuyl]{hutchinson-etal-2020-social}
Ben Hutchinson, Vinodkumar Prabhakaran, Emily Denton, Kellie Webster, Yu~Zhong,
  and Stephen Denuyl.
\newblock Social biases in {NLP} models as barriers for persons with
  disabilities.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  5491--5501, Online, July 2020.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.acl-main.487}.
\newblock URL \url{https://aclanthology.org/2020.acl-main.487}.

\bibitem[Jorgensen et~al.(2023)Jorgensen, Cope, Schoots, and
  Shanahan]{jorgensen2023improving}
Ole Jorgensen, Dylan Cope, Nandi Schoots, and Murray Shanahan.
\newblock Improving activation steering in language models with mean-centring.
\newblock \emph{arXiv preprint arXiv:2312.03813}, 2023.

\bibitem[Leong et~al.(2023)Leong, Cheng, Wang, Wang, and Li]{leong2023self}
Chak~Tou Leong, Yi~Cheng, Jiashuo Wang, Jian Wang, and Wenjie Li.
\newblock Self-detoxifying language models via toxification reversal.
\newblock \emph{arXiv preprint arXiv:2310.09573}, 2023.

\bibitem[Lin et~al.(2022)Lin, Hilton, and Evans]{lin-etal-2022-truthfulqa}
Stephanie Lin, Jacob Hilton, and Owain Evans.
\newblock {T}ruthful{QA}: Measuring how models mimic human falsehoods.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pp.\  3214--3252,
  Dublin, Ireland, May 2022. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2022.acl-long.229}.
\newblock URL \url{https://aclanthology.org/2022.acl-long.229}.

\bibitem[Liu et~al.(2023)Liu, Wang, Wu, Li, Lv, Ling, Zhu, Zhang, Zheng, and
  Huang]{liu2023aligning}
Wenhao Liu, Xiaohua Wang, Muling Wu, Tianlong Li, Changze Lv, Zixuan Ling,
  Jianhao Zhu, Cenyuan Zhang, Xiaoqing Zheng, and Xuanjing Huang.
\newblock Aligning large language models with human preferences through
  representation engineering.
\newblock \emph{arXiv preprint arXiv:2312.15997}, 2023.

\bibitem[Mangrulkar et~al.(2022)Mangrulkar, Gugger, Debut, Belkada, and
  Paul]{peft}
Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, and Sayak
  Paul.
\newblock Peft: State-of-the-art parameter-efficient fine-tuning methods.
\newblock \url{https://github.com/huggingface/peft}, 2022.

\bibitem[Meta(2023)]{meta2023introducing}
AI~Meta.
\newblock Introducing llama: A foundational, 65-billion-parameter large
  language model.
\newblock \emph{Meta AI. https://ai. facebook.
  com/blog/large-language-model-llama-meta-ai}, 2023.

\bibitem[Nangia et~al.(2020)Nangia, Vania, Bhalerao, and
  Bowman]{nangia-etal-2020-crows}
Nikita Nangia, Clara Vania, Rasika Bhalerao, and Samuel~R. Bowman.
\newblock {C}row{S}-pairs: A challenge dataset for measuring social biases in
  masked language models.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pp.\  1953--1967, Online, November
  2020. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.emnlp-main.154}.
\newblock URL \url{https://aclanthology.org/2020.emnlp-main.154}.

\bibitem[Nardo(2023)]{luigi_article}
Cleo Nardo.
\newblock The waluigi effect (mega-post).
\newblock \emph{Less Wrong}, 2023.

\bibitem[Ngo(2022)]{ngo2022alignment}
Richard Ngo.
\newblock The alignment problem from a deep learning perspective.
\newblock \emph{arXiv preprint arXiv:2209.00626}, 2022.

\bibitem[Nori et~al.(2023)Nori, King, McKinney, Carignan, and
  Horvitz]{nori2023capabilities}
Harsha Nori, Nicholas King, Scott~Mayer McKinney, Dean Carignan, and Eric
  Horvitz.
\newblock Capabilities of gpt-4 on medical challenge problems.
\newblock \emph{arXiv preprint arXiv:2303.13375}, 2023.

\bibitem[O'Brien(2023)]{petition}
Matt O'Brien.
\newblock Musk, scientists call for halt to ai race sparked by chatgpt.
\newblock \emph{AP News}, 2023.

\bibitem[OpenAI(2023)]{gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2023.

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin,
  Zhang, Agarwal, Slama, Gray, Schulman, Hilton, Kelton, Miller, Simens,
  Askell, Welinder, Christiano, Leike, and Lowe]{ouyang2022training}
Long Ouyang, Jeffrey Wu, Xu~Jiang, Diogo Almeida, Carroll Wainwright, Pamela
  Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Gray, John
  Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda
  Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe.
\newblock Training language models to follow instructions with human feedback.
\newblock In Alice~H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho
  (eds.), \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=TG8KACxEON}.

\bibitem[Pan et~al.(2022)Pan, Bhatia, and Steinhardt]{pan2022the}
Alexander Pan, Kush Bhatia, and Jacob Steinhardt.
\newblock The effects of reward misspecification: Mapping and mitigating
  misaligned models.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=JYtwGwIL7ye}.

\bibitem[Park et~al.(2023)Park, O'Brien, Cai, Morris, Liang, and
  Bernstein]{park2023generative}
Joon~Sung Park, Joseph~C O'Brien, Carrie~J Cai, Meredith~Ringel Morris, Percy
  Liang, and Michael~S Bernstein.
\newblock Generative agents: Interactive simulacra of human behavior.
\newblock \emph{arXiv preprint arXiv:2304.03442}, 2023.

\bibitem[Perez et~al.(2022)Perez, Ringer, Luko{\v{s}}i{\=u}t{\.e}, Nguyen,
  Chen, Heiner, Pettit, Olsson, Kundu, Kadavath, et~al.]{perez2022discovering}
Ethan Perez, Sam Ringer, Kamil{\.e} Luko{\v{s}}i{\=u}t{\.e}, Karina Nguyen,
  Edwin Chen, Scott Heiner, Craig Pettit, Catherine Olsson, Sandipan Kundu,
  Saurav Kadavath, et~al.
\newblock Discovering language model behaviors with model-written evaluations.
\newblock \emph{arXiv preprint arXiv:2212.09251}, 2022.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever]{Radford2019LanguageMA}
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock Language models are unsupervised multitask learners.
\newblock 2019.

\bibitem[Rae et~al.(2021)Rae, Borgeaud, Cai, Millican, Hoffmann, Song,
  Aslanides, Henderson, Ring, Young, et~al.]{rae2021scaling}
Jack~W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann,
  Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young,
  et~al.
\newblock Scaling language models: Methods, analysis \& insights from training
  gopher.
\newblock \emph{arXiv preprint arXiv:2112.11446}, 2021.

\bibitem[Roose(2023)]{nytimes_marry_reporter}
Kevin Roose.
\newblock A conversation with bing’s chatbot left me deeply unsettled.
\newblock \emph{New York Times}, 2023.

\bibitem[Schulman et~al.(2023)Schulman, Zoph, Kim, Hilton, Menick, Weng,
  Felipe, Uribe, Fedus, Metz, Pokorny, Lopes, Zhao, Vijayvergiya, Sigler,
  Perelman, Voss, Heaton, Parish, Cummings, Nayak, Balcom, Schnurr, Kaftan,
  Hallacy, Turley, Deutsch, Goel, Ward, Konstantinidis, Zaremba, Ouyang,
  Bogdonoff, Gross, Medina, Yoo, Lee, Lowe, Mossing, Huizinga, Jiang,
  Wainwright, Almeida, Lin, Zhang, Xiao, Slama, Bills, Gray, Leike, Pachocki,
  Tillet, Jain, Brockman, Ryder, Paino, Yuan, Winter, Wang, Bavarian,
  Babuschkin, Sidor, Kanitscheider, Pavlov, Plappert, Tezak, Jun, Zhuk, Pong,
  Kaiser, Tworek, Carr, Weng, Agarwal, Cobbe, Kosaraju, Power, Polu, Han, Puri,
  Jain, Chess, Gibson, Boiko, Parparita, Tootoonchian, Kosic, and
  Hesse]{chatgpt}
John Schulman, Barret Zoph, Christina Kim, Jacob Hilton, Jacob Menick, Jiayi
  Weng, Juan Felipe, Ceron Uribe, Liam Fedus, Luke Metz, Michael Pokorny,
  Rapha~Gontijo Lopes, Shengjia Zhao, Arun Vijayvergiya, Eric Sigler, Adam
  Perelman, Chelsea Voss, Mike Heaton, Joel Parish, Dave Cummings, Rajeev
  Nayak, Valerie Balcom, David Schnurr, Tomer Kaftan, Chris Hallacy, Nicholas
  Turley, Noah Deutsch, Vik Goel, Jonathan Ward, Aris Konstantinidis, Wojciech
  Zaremba, Long Ouyang, Leonard Bogdonoff, Joshua Gross, David Medina, Sarah
  Yoo, Teddy Lee, Ryan Lowe, Dan Mossing, Joost Huizinga, Roger Jiang, Carroll
  Wainwright, Diogo Almeida, Steph Lin, Marvin Zhang, Kai Xiao, Katarina Slama,
  Steven Bills, Alex Gray, Jan Leike, Jakub Pachocki, Phil Tillet, Shantanu
  Jain, Greg Brockman, Nick Ryder, Alex Paino, Qiming Yuan, Clemens Winter, Ben
  Wang, Mo~Bavarian, Igor Babuschkin, Szymon Sidor, Ingmar Kanitscheider,
  Mikhail Pavlov, Matthias Plappert, Nik Tezak, Heewoo Jun, William Zhuk,
  Vitchyr Pong, Lukasz Kaiser, Jerry Tworek, Andrew Carr, Lilian Weng, Sandhini
  Agarwal, Karl Cobbe, Vineet Kosaraju, Alethea Power, Stanislas Polu, Jesse
  Han, Raul Puri, Shawn Jain, Benjamin Chess, Christian Gibson, Oleg Boiko, Emy
  Parparita, Amin Tootoonchian, Kyle Kosic, and Christopher Hesse.
\newblock Introducing chatgpt.
\newblock \emph{OpenAI blog}, 2023.

\bibitem[Shalev-Shwartz et~al.(2020)Shalev-Shwartz, Shammah, and
  Shashua]{shalev2020ethics}
Shai Shalev-Shwartz, Shaked Shammah, and Amnon Shashua.
\newblock On the ethics of building ai in a responsible manner.
\newblock \emph{arXiv preprint arXiv:2004.04644}, 2020.

\bibitem[Subhash(2023)]{subhash2023can}
Varshini Subhash.
\newblock Can large language models change user preference adversarially?
\newblock \emph{arXiv preprint arXiv:2302.10291}, 2023.

\bibitem[Taylor et~al.(2016)Taylor, Yudkowsky, LaVictoire, and
  Critch]{taylor2016alignment}
Jessica Taylor, Eliezer Yudkowsky, Patrick LaVictoire, and Andrew Critch.
\newblock Alignment for advanced machine learning systems.
\newblock \emph{Ethics of Artificial Intelligence}, pp.\  342--382, 2016.

\bibitem[Touvron et~al.(2023)Touvron, Martin, Stone, Albert, Almahairi, Babaei,
  Bashlykov, Batra, Bhargava, Bhosale, et~al.]{touvron2023llama}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine
  Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,
  et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv preprint arXiv:2307.09288}, 2023.

\bibitem[Turner et~al.(2023)Turner, Thiergart, Udell, Leech, Mini, and
  MacDiarmid]{turner2023activation}
Alex Turner, Lisa Thiergart, David Udell, Gavin Leech, Ulisse Mini, and Monte
  MacDiarmid.
\newblock Activation addition: Steering language models without optimization.
\newblock \emph{arXiv preprint arXiv:2308.10248}, 2023.

\bibitem[Venkit et~al.(2022)Venkit, Srinath, and
  Wilson]{venkit-etal-2022-study}
Pranav~Narayanan Venkit, Mukund Srinath, and Shomir Wilson.
\newblock A study of implicit bias in pretrained language models against people
  with disabilities.
\newblock In \emph{Proceedings of the 29th International Conference on
  Computational Linguistics}, pp.\  1324--1332, Gyeongju, Republic of Korea,
  October 2022. International Committee on Computational Linguistics.
\newblock URL \url{https://aclanthology.org/2022.coling-1.113}.

\bibitem[Wallace et~al.(2019)Wallace, Feng, Kandpal, Gardner, and
  Singh]{wallace-etal-2019-universal}
Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh.
\newblock Universal adversarial triggers for attacking and analyzing {NLP}.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pp.\  2153--2162, Hong Kong,
  China, November 2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/D19-1221}.
\newblock URL \url{https://aclanthology.org/D19-1221}.

\bibitem[Weidinger et~al.(2022)Weidinger, Uesato, Rauh, Griffin, Huang, Mellor,
  Glaese, Cheng, Balle, Kasirzadeh, Biles, Brown, Kenton, Hawkins, Stepleton,
  Birhane, Hendricks, Rimell, Isaac, Haas, Legassick, Irving, and
  Gabriel]{weidinger2022taxonomy}
Laura Weidinger, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang,
  John Mellor, Amelia Glaese, Myra Cheng, Borja Balle, Atoosa Kasirzadeh,
  Courtney Biles, Sasha Brown, Zac Kenton, Will Hawkins, Tom Stepleton, Abeba
  Birhane, Lisa~Anne Hendricks, Laura Rimell, William Isaac, Julia Haas, Sean
  Legassick, Geoffrey Irving, and Iason Gabriel.
\newblock Taxonomy of risks posed by language models.
\newblock In \emph{2022 ACM Conference on Fairness, Accountability, and
  Transparency}, FAccT '22, pp.\  214–229, New York, NY, USA, 2022.
  Association for Computing Machinery.
\newblock ISBN 9781450393522.
\newblock \doi{10.1145/3531146.3533088}.
\newblock URL \url{https://doi.org/10.1145/3531146.3533088}.

\bibitem[West(2023)]{west2023advances}
Colin~G West.
\newblock Advances in apparent conceptual physics reasoning in gpt-4.
\newblock \emph{arXiv e-prints}, pp.\  arXiv--2303, 2023.

\bibitem[Wies et~al.(2023)Wies, Levine, and Shashua]{wies2023learnability}
Noam Wies, Yoav Levine, and Amnon Shashua.
\newblock The learnability of in-context learning.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing
  Systems}, 2023.
\newblock URL \url{https://openreview.net/forum?id=f3JNQd7CHM}.

\bibitem[Xu et~al.(2021)Xu, Ju, Li, Boureau, Weston, and
  Dinan]{xu-etal-2021-bot}
Jing Xu, Da~Ju, Margaret Li, Y-Lan Boureau, Jason Weston, and Emily Dinan.
\newblock Bot-adversarial dialogue for safe conversational agents.
\newblock In \emph{Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pp.\  2950--2968, Online, June 2021. Association for
  Computational Linguistics.
\newblock \doi{10.18653/v1/2021.naacl-main.235}.
\newblock URL \url{https://aclanthology.org/2021.naacl-main.235}.

\bibitem[Yu \& Sagae(2021)Yu and Sagae]{yu-sagae-2021-automatically}
Dian Yu and Kenji Sagae.
\newblock Automatically exposing problems with neural dialog models.
\newblock In \emph{Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  456--470, Online and Punta Cana,
  Dominican Republic, November 2021. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2021.emnlp-main.37}.
\newblock URL \url{https://aclanthology.org/2021.emnlp-main.37}.

\bibitem[Yudkowsky(2001)]{yudkowsky2001creating}
Eliezer Yudkowsky.
\newblock Creating friendly ai 1.0: The analysis and design of benevolent goal
  architectures.
\newblock \emph{The Singularity Institute, San Francisco, USA}, 2001.

\bibitem[Zou et~al.(2023)Zou, Phan, Chen, Campbell, Guo, Ren, Pan, Yin,
  Mazeika, Dombrowski, et~al.]{zou2023representation}
Andy Zou, Long Phan, Sarah Chen, James Campbell, Phillip Guo, Richard Ren,
  Alexander Pan, Xuwang Yin, Mantas Mazeika, Ann-Kathrin Dombrowski, et~al.
\newblock Representation engineering: A top-down approach to ai transparency.
\newblock \emph{arXiv preprint arXiv:2310.01405}, 2023.

\end{thebibliography}
