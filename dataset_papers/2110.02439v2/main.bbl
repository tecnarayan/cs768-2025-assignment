\begin{thebibliography}{10}

\bibitem{dexterity}
O.~M. Andrychowicz, B.~Baker, M.~Chociej, R.~Józefowicz, B.~McGrew,
  J.~Pachocki, A.~Petron, M.~Plappert, G.~Powell, A.~Ray, J.~Schneider,
  S.~Sidor, J.~Tobin, P.~Welinder, L.~Weng, and W.~Zaremba.
\newblock Learning dexterous in-hand manipulation.
\newblock {\em The International Journal of Robotics Research}, 39(1):3--20,
  2020.

\bibitem{bengio_curriculum}
Y.~Bengio, J.~Louradour, R.~Collobert, and J.~Weston.
\newblock Curriculum learning.
\newblock In {\em Proceedings of the 26th Annual International Conference on
  Machine Learning}, ICML '09, page 41–48, New York, NY, USA, 2009.
  Association for Computing Machinery.

\bibitem{bergstra2012random}
J.~Bergstra and Y.~Bengio.
\newblock Random search for hyper-parameter optimization.
\newblock {\em Journal of Machine Learning Research}, 13:281--305, 2012.

\bibitem{berner2019dota}
C.~Berner, G.~Brockman, B.~Chan, V.~Cheung, P.~D{\k{e}}biak, C.~Dennison,
  D.~Farhi, Q.~Fischer, S.~Hashme, C.~Hesse, et~al.
\newblock Dota 2 with large scale deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1912.06680}, 2019.

\bibitem{gym}
G.~Brockman, V.~Cheung, L.~Pettersson, J.~Schneider, J.~Schulman, J.~Tang, and
  W.~Zaremba.
\newblock Openai gym.
\newblock {\em CoRR}, abs/1606.01540, 2016.

\bibitem{amigo}
A.~Campero, R.~Raileanu, H.~Kuttler, J.~B. Tenenbaum, T.~Rockt{\"a}schel, and
  E.~Grefenstette.
\newblock Learning with {AMIG}o: Adversarially motivated intrinsic goals.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{gym_minigrid}
M.~Chevalier-Boisvert, L.~Willems, and S.~Pal.
\newblock Minimalistic gridworld environment for openai gym.
\newblock \url{https://github.com/maximecb/gym-minigrid}, 2018.

\bibitem{procgen_benchmark}
K.~Cobbe, C.~Hesse, J.~Hilton, and J.~Schulman.
\newblock Leveraging procedural generation to benchmark reinforcement learning.
\newblock In {\em Proceedings of the 37th International Conference on Machine
  Learning}, pages 2048--2056, 2020.

\bibitem{coinrun}
K.~Cobbe, O.~Klimov, C.~Hesse, T.~Kim, and J.~Schulman.
\newblock Quantifying generalization in reinforcement learning.
\newblock In K.~Chaudhuri and R.~Salakhutdinov, editors, {\em Proceedings of
  the 36th International Conference on Machine Learning, {ICML} 2019, 9-15 June
  2019, Long Beach, California, {USA}}, Proceedings of Machine Learning
  Research. {PMLR}, 2019.

\bibitem{paired}
M.~Dennis, N.~Jaques, E.~Vinitsky, A.~Bayen, S.~Russell, A.~Critch, and
  S.~Levine.
\newblock Emergent complexity and zero-shot transfer via unsupervised
  environment design.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~33, 2020.

\bibitem{fang2021adaptive}
K.~Fang, Y.~Zhu, S.~Savarese, and F.-F. Li.
\newblock Adaptive procedural task generation for hard-exploration problems.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{goalgan}
C.~Florensa, D.~Held, X.~Geng, and P.~Abbeel.
\newblock Automatic goal generation for reinforcement learning agents.
\newblock In J.~Dy and A.~Krause, editors, {\em Proceedings of the 35th
  International Conference on Machine Learning}, volume~80 of {\em Proceedings
  of Machine Learning Research}, pages 1515--1528. PMLR, 10 2018.

\bibitem{fictitious_sp}
J.~Heinrich, M.~Lanctot, and D.~Silver.
\newblock Fictitious self-play in extensive-form games.
\newblock In {\em Proceedings of the 32nd International Conference on Machine
  Learning}, pages 805--813, 2015.

\bibitem{carml}
A.~Jabri, K.~Hsu, A.~Gupta, B.~Eysenbach, S.~Levine, and C.~Finn.
\newblock Unsupervised curricula for visual meta-reinforcement learning.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~32, 2019.

\bibitem{dr_evolutionary}
N.~Jakobi.
\newblock Evolutionary robotics and the radical envelope-of-noise hypothesis.
\newblock {\em Adaptive Behavior}, 6(2):325--368, 1997.

\bibitem{james2017transferring}
S.~James, A.~J. Davison, and E.~Johns.
\newblock Transferring end-to-end visuomotor control from simulation to real
  world for a multi-stage task.
\newblock In {\em 1st Conference on Robot Learning}, 2017.

\bibitem{plr}
M.~Jiang, E.~Grefenstette, and T.~Rockt{\"{a}}schel.
\newblock Prioritized level replay.
\newblock In {\em Proceedings of the 38th International Conference on Machine
  Learning, {ICML} 2021, 18-24 July 2021, Virtual Event}, volume 139 of {\em
  Proceedings of Machine Learning Research}, pages 4940--4950. {PMLR}, 2021.

\bibitem{carracing_ppo}
X.~Ma.
\newblock Car racing with pytorch.
\newblock \url{https://github.com/xtma/pytorch_car_caring}, 2019.

\bibitem{tscl}
T.~Matiisen, A.~Oliver, T.~Cohen, and J.~Schulman.
\newblock Teacher-student curriculum learning.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems}, PP,
  07 2017.

\bibitem{mehta2019activedomain}
B.~Mehta, M.~Diaz, F.~Golemo, C.~J. Pal, and L.~Paull.
\newblock Active domain randomization.
\newblock In L.~P. Kaelbling, D.~Kragic, and K.~Sugiura, editors, {\em 3rd
  Annual Conference on Robot Learning, CoRL 2019, Osaka, Japan, October 30 -
  November 1, 2019, Proceedings}, volume 100 of {\em Proceedings of Machine
  Learning Research}, pages 1162--1176. {PMLR}, 2019.

\bibitem{mnih2015human}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~A. Rusu, J.~Veness, M.~G. Bellemare,
  A.~Graves, M.~Riedmiller, A.~K. Fidjeland, G.~Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 518(7540):529--533, 2015.

\bibitem{bezier_ref}
M.~E. Mortenson.
\newblock {\em Mathematics for Computer Graphics Applications}.
\newblock Industrial Press Inc., 1999.

\bibitem{curriculum_rl_survey1}
S.~Narvekar, B.~Peng, M.~Leonetti, J.~Sinapov, M.~E. Taylor, and P.~Stone.
\newblock Curriculum learning for reinforcement learning domains: {A} framework
  and survey.
\newblock {\em Journal of Machine Learning Research}, 21:181:1--181:50, 2020.

\bibitem{nash1950equilibrium}
J.~F. Nash et~al.
\newblock Equilibrium points in n-person games.
\newblock {\em Proceedings of the National Academy of Sciences}, 36(1):48--49,
  1950.

\bibitem{rubics_cube}
OpenAI, I.~Akkaya, M.~Andrychowicz, M.~Chociej, M.~Litwin, B.~McGrew,
  A.~Petron, A.~Paino, M.~Plappert, G.~Powell, R.~Ribas, J.~Schneider,
  N.~Tezak, J.~Tworek, P.~Welinder, L.~Weng, Q.~Yuan, W.~Zaremba, and L.~Zhang.
\newblock Solving rubik's cube with a robot hand.
\newblock {\em CoRR}, abs/1910.07113, 2019.

\bibitem{openai2021asymmetric}
O.~OpenAI, M.~Plappert, R.~Sampedro, T.~Xu, I.~Akkaya, V.~Kosaraju,
  P.~Welinder, R.~D'Sa, A.~Petron, H.~P. de~Oliveira~Pinto, A.~Paino, H.~Noh,
  L.~Weng, Q.~Yuan, C.~Chu, and W.~Zaremba.
\newblock Asymmetric self-play for automatic goal discovery in robotic
  manipulation, 2021.

\bibitem{Popovici2012}
E.~Popovici, A.~Bucci, R.~P. Wiegand, and E.~D. De~Jong.
\newblock {\em Coevolutionary Principles}, pages 987--1033.
\newblock Springer Berlin Heidelberg, 2012.

\bibitem{curriculum_rl_survey2}
R.~Portelas, C.~Colas, L.~Weng, K.~Hofmann, and P.-Y. Oudeyer.
\newblock Automatic curriculum learning for deep rl: A short survey.
\newblock In C.~Bessiere, editor, {\em Proceedings of the Twenty-Ninth
  International Joint Conference on Artificial Intelligence, {IJCAI-20}}, pages
  4819--4825. International Joint Conferences on Artificial Intelligence
  Organization, 7 2020.
\newblock Survey track.

\bibitem{Racaniere2020Automated}
S.~Racaniere, A.~Lampinen, A.~Santoro, D.~Reichert, V.~Firoiu, and
  T.~Lillicrap.
\newblock Automated curriculum generation through setter-solver interactions.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{risi_togelius_pcg}
S.~Risi and J.~Togelius.
\newblock Increasing generality in machine learning through procedural content
  generation.
\newblock {\em Nature Machine Intelligence}, 2(8):428–436, 8 2020.

\bibitem{savage1951theory}
L.~J. Savage.
\newblock The theory of statistical decision.
\newblock {\em Journal of the American Statistical association},
  46(253):55--67, 1951.

\bibitem{schmidhuber_curriculum}
J.~Schmidhuber.
\newblock Powerplay: Training an increasingly general problem solver by
  continually searching for the simplest still unsolvable problem.
\newblock {\em Frontiers in Psychology}, 4:313, 06 2013.

\bibitem{gae}
J.~Schulman, P.~Moritz, S.~Levine, M.~I. Jordan, and P.~Abbeel.
\newblock High-dimensional continuous control using generalized advantage
  estimation.
\newblock In Y.~Bengio and Y.~LeCun, editors, {\em 4th International Conference
  on Learning Representations, {ICLR} 2016, San Juan, Puerto Rico, May 2-4,
  2016, Conference Track Proceedings}, 2016.

\bibitem{schulman2017proximal}
J.~Schulman, F.~Wolski, P.~Dhariwal, A.~Radford, and O.~Klimov.
\newblock Proximal policy optimization algorithms.
\newblock {\em CoRR}, abs/1707.06347, 2017.

\bibitem{silver2016mastering}
D.~Silver, A.~Huang, C.~J. Maddison, A.~Guez, L.~Sifre, G.~Van Den~Driessche,
  J.~Schrittwieser, I.~Antonoglou, V.~Panneershelvam, M.~Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock {\em Nature}, 529(7587):484--489, 2016.

\bibitem{silver2018general}
D.~Silver, T.~Hubert, J.~Schrittwieser, I.~Antonoglou, M.~Lai, A.~Guez,
  M.~Lanctot, L.~Sifre, D.~Kumaran, T.~Graepel, et~al.
\newblock A general reinforcement learning algorithm that masters chess, shogi,
  and go through self-play.
\newblock {\em Science}, 362(6419):1140--1144, 2018.

\bibitem{sukhbaatar2018intrinsic}
S.~Sukhbaatar, Z.~Lin, I.~Kostrikov, G.~Synnaeve, A.~Szlam, and R.~Fergus.
\newblock Intrinsic motivation and automatic curricula via asymmetric
  self-play.
\newblock In {\em 6th International Conference on Learning Representations,
  {ICLR} 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track
  Proceedings}. OpenReview.net, 2018.

\bibitem{attentionagent}
Y.~Tang, D.~Nguyen, and D.~Ha.
\newblock Neuroevolution of self-interpretable agents.
\newblock In {\em Proceedings of the Genetic and Evolutionary Computation
  Conference}, 2020.

\bibitem{domain_randomization}
J.~{Tobin}, R.~{Fong}, A.~{Ray}, J.~{Schneider}, W.~{Zaremba}, and P.~{Abbeel}.
\newblock Domain randomization for transferring deep neural networks from
  simulation to the real world.
\newblock In {\em 2017 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pages 23--30, 2017.

\bibitem{vinyals2019grandmaster}
O.~Vinyals, I.~Babuschkin, W.~M. Czarnecki, M.~Mathieu, A.~Dudzik, J.~Chung,
  D.~H. Choi, R.~Powell, T.~Ewalds, P.~Georgiev, et~al.
\newblock Grandmaster level in {StarCraft II} using multi-agent reinforcement
  learning.
\newblock {\em Nature}, 575(7782):350--354, 2019.

\bibitem{poet}
R.~Wang, J.~Lehman, J.~Clune, and K.~O. Stanley.
\newblock Paired open-ended trailblazer {(POET):} endlessly generating
  increasingly complex and diverse learning environments and their solutions.
\newblock {\em CoRR}, abs/1901.01753, 2019.

\bibitem{enhanced_poet}
R.~Wang, J.~Lehman, A.~Rawal, J.~Zhi, Y.~Li, J.~Clune, and K.~Stanley.
\newblock Enhanced {POET}: Open-ended reinforcement learning through unbounded
  invention of learning challenges and their solutions.
\newblock In {\em Proceedings of the 37th International Conference on Machine
  Learning}, pages 9940--9951, 2020.

\bibitem{welch1947generalization}
B.~L. Welch.
\newblock The generalization of `student's' problem when several different
  population variances are involved.
\newblock {\em Biometrika}, 34(1-2):28--35, 1947.

\bibitem{zhang2018dissection}
A.~Zhang, N.~Ballas, and J.~Pineau.
\newblock A dissection of overfitting and generalization in continuous
  reinforcement learning.
\newblock {\em arXiv preprint arXiv:1806.07937}, 2018.

\bibitem{NEURIPS2020_566f0ea4}
Y.~Zhang, P.~Abbeel, and L.~Pinto.
\newblock Automatic curriculum learning through value disagreement.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~33, pages 7648--7659, 2020.

\end{thebibliography}
