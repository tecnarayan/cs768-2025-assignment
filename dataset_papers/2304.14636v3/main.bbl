\begin{thebibliography}{64}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdelfattah et~al.(2021)Abdelfattah, Mehrotra, Dudziak, and
  Lane]{DBLP:conf/iclr/AbdelfattahMDL21}
Abdelfattah, M.~S., Mehrotra, A., Dudziak, L., and Lane, N.~D.
\newblock Zero-cost proxies for lightweight {NAS}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2021.

\bibitem[Bender et~al.(2018)Bender, Kindermans, Zoph, Vasudevan, and
  Le]{DBLP:conf/icml/BenderKZVL18}
Bender, G., Kindermans, P., Zoph, B., Vasudevan, V., and Le, Q.~V.
\newblock Understanding and simplifying one-shot architecture search.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  volume~80, pp.\  549--558, 2018.

\bibitem[Berman et~al.(2019)Berman, J{\'e}gou, Vedaldi, Kokkinos, and
  Douze]{multigrain}
Berman, M., J{\'e}gou, H., Vedaldi, A., Kokkinos, I., and Douze, M.
\newblock {MultiGrain}: A unified image embedding for classes and instances.
\newblock \emph{arXiv preprint arXiv:1902.05509}, 2019.

\bibitem[Brock et~al.(2018)Brock, Lim, Ritchie, and
  Weston]{DBLP:conf/iclr/BrockLRW18}
Brock, A., Lim, T., Ritchie, J.~M., and Weston, N.
\newblock {SMASH}: One-shot model architecture search through hypernetworks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Cai et~al.(2020)Cai, Gan, Wang, Zhang, and
  Han]{DBLP:conf/iclr/CaiGWZH20}
Cai, H., Gan, C., Wang, T., Zhang, Z., and Han, S.
\newblock {Once-for-All}: Train one network and specialize it for efficient
  deployment.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020.

\bibitem[Chen et~al.(2021{\natexlab{a}})Chen, Lin, Sun, and Li]{chen2021bench}
Chen, H., Lin, M., Sun, X., and Li, H.
\newblock {NAS-Bench-Zero}: A large scale dataset for understanding zero-shot
  neural architecture search.
\newblock \url{https://openreview.net/forum?id=hP-SILoczR}, 2021{\natexlab{a}}.

\bibitem[Chen et~al.(2021{\natexlab{b}})Chen, Peng, Fu, and Ling]{autoformer}
Chen, M., Peng, H., Fu, J., and Ling, H.
\newblock {AutoFormer}: Searching transformers for visual recognition.
\newblock In \emph{{IEEE/CVF} International Conference on Computer Vision
  (ICCV)}, pp.\  12250--12260, 2021{\natexlab{b}}.

\bibitem[Chen et~al.(2022)Chen, Cao, Zhong, Zhang, Gao, and Tao]{dearkd}
Chen, X., Cao, Q., Zhong, Y., Zhang, J., Gao, S., and Tao, D.
\newblock {DearKD}: Data-efficient early knowledge distillation for vision
  transformers.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  12042--12052, 2022.

\bibitem[Chitty-Venkata et~al.(2022)Chitty-Venkata, Emani, Vishwanath, and
  Somani]{chitty2022neural}
Chitty-Venkata, K.~T., Emani, M., Vishwanath, V., and Somani, A.~K.
\newblock Neural architecture search for transformers: A survey.
\newblock \emph{IEEE Access}, 10:\penalty0 108374--108412, 2022.

\bibitem[Cubuk et~al.(2020)Cubuk, Zoph, Shlens, and Le]{randaug}
Cubuk, E.~D., Zoph, B., Shlens, J., and Le, Q.~V.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  Workshops (CVPR)}, pp.\  3008--3017, 2020.

\bibitem[Cummings et~al.(2022)Cummings, Sarah, Sridhar, Szankin, Munoz, and
  Sundaresan]{cummings2022hardware}
Cummings, D., Sarah, A., Sridhar, S.~N., Szankin, M., Munoz, J.~P., and
  Sundaresan, S.
\newblock A hardware-aware framework for accelerating neural architecture
  search across modalities.
\newblock \emph{arXiv preprint arXiv:2205.10358}, 2022.

\bibitem[d'Ascoli et~al.(2021)d'Ascoli, Touvron, Leavitt, Morcos, Biroli, and
  Sagun]{convit}
d'Ascoli, S., Touvron, H., Leavitt, M.~L., Morcos, A.~S., Biroli, G., and
  Sagun, L.
\newblock {ConViT}: Improving vision transformers with soft convolutional
  inductive biases.
\newblock In \emph{International Conference on Machine Learning (ICML)}, volume
  139, pp.\  2286--2296, 2021.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{bert}
Devlin, J., Chang, M., Lee, K., and Toutanova, K.
\newblock {BERT:} pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{Conference of the North American Chapter of the Association
  for Computational Linguistics: Human Language Technologies (NAACL-HLT)}, pp.\
   4171--4186, 2019.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{ViT}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S.,
  Uszkoreit, J., and Houlsby, N.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2021.

\bibitem[Gong et~al.(2022)Gong, Wang, Li, Chen, Yan, Tian, Chandra,
  et~al.]{gong2022nasvit}
Gong, C., Wang, D., Li, M., Chen, X., Yan, Z., Tian, Y., Chandra, V., et~al.
\newblock {NASViT}: Neural architecture search for efficient vision
  transformers with gradient conflict aware supernet training.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2022.

\bibitem[Guo et~al.(2020)Guo, Zhang, Mu, Heng, Liu, Wei, and
  Sun]{DBLP:conf/eccv/GuoZMHLWS20}
Guo, Z., Zhang, X., Mu, H., Heng, W., Liu, Z., Wei, Y., and Sun, J.
\newblock Single path one-shot neural architecture search with uniform
  sampling.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, volume
  12361, pp.\  544--560, 2020.

\bibitem[Han et~al.(2021)Han, Xiao, Wu, Guo, Xu, and Wang]{tnt}
Han, K., Xiao, A., Wu, E., Guo, J., Xu, C., and Wang, Y.
\newblock Transformer in transformer.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pp.\  15908--15919, 2021.

\bibitem[Hoffer et~al.(2020)Hoffer, Ben{-}Nun, Hubara, Giladi, Hoefler, and
  Soudry]{batchaug}
Hoffer, E., Ben{-}Nun, T., Hubara, I., Giladi, N., Hoefler, T., and Soudry, D.
\newblock Augment your batch: Improving generalization through instance
  repetition.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  8126--8135, 2020.

\bibitem[Horn et~al.(2018)Horn, Aodha, Song, Cui, Sun, Shepard, Adam, Perona,
  and Belongie]{iNaturalist}
Horn, G.~V., Aodha, O.~M., Song, Y., Cui, Y., Sun, C., Shepard, A., Adam, H.,
  Perona, P., and Belongie, S.~J.
\newblock The inaturalist species classification and detection dataset.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  8769--8778, 2018.

\bibitem[Hsu et~al.(2021)Hsu, Bolte, Tsai, Lakhotia, Salakhutdinov, and
  Mohamed]{hubert}
Hsu, W., Bolte, B., Tsai, Y.~H., Lakhotia, K., Salakhutdinov, R., and Mohamed,
  A.
\newblock {HuBERT}: Self-supervised speech representation learning by masked
  prediction of hidden units.
\newblock \emph{{IEEE} {ACM} Trans. Audio Speech Lang. Process.}, 29:\penalty0
  3451--3460, 2021.

\bibitem[Huang et~al.(2016)Huang, Sun, Liu, Sedra, and Weinberger]{droppath}
Huang, G., Sun, Y., Liu, Z., Sedra, D., and Weinberger, K.~Q.
\newblock Deep networks with stochastic depth.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, volume 9908,
  pp.\  646--661, 2016.

\bibitem[Javaheripi et~al.(2022)Javaheripi, de~Rosa, Mukherjee, Shah, Religa,
  Mendes, Bubeck, Koushanfar, and Dey]{javaheripilitetransformersearch}
Javaheripi, M., de~Rosa, G.~H., Mukherjee, S., Shah, S., Religa, T.~L., Mendes,
  C. C.~T., Bubeck, S., Koushanfar, F., and Dey, D.
\newblock {LiteTransformerSearch}: Training-free neural architecture search for
  efficient language models.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2022.

\bibitem[Krause et~al.(2013)Krause, Stark, Deng, and Fei{-}Fei]{cars}
Krause, J., Stark, M., Deng, J., and Fei{-}Fei, L.
\newblock 3d object representations for fine-grained categorization.
\newblock In \emph{{IEEE} International Conference on Computer Vision Workshops
  (ICCV 3dRR-13)}, pp.\  554--561, 2013.

\bibitem[Krizhevsky \& Hinton(2009)Krizhevsky and Hinton]{cifar}
Krizhevsky, A. and Hinton, G.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, University of Toronto, 2009.

\bibitem[Lee et~al.(2019)Lee, Ajanthan, and Torr]{snip}
Lee, N., Ajanthan, T., and Torr, P. H.~S.
\newblock {SNIP}: Single-shot network pruning based on connection sensitivity.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.

\bibitem[Li et~al.(2020)Li, Peng, Yuan, Wang, Liang, Lin, and
  Chang]{li2020block}
Li, C., Peng, J., Yuan, L., Wang, G., Liang, X., Lin, L., and Chang, X.
\newblock Block-wisely supervised neural architecture search with knowledge
  distillation.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  1989--1998, 2020.

\bibitem[Li \& Talwalkar(2019)Li and Talwalkar]{DBLP:conf/uai/LiT19}
Li, L. and Talwalkar, A.
\newblock Random search and reproducibility for neural architecture search.
\newblock In \emph{Proceedings of the Thirty-Fifth Conference on Uncertainty in
  Artificial Intelligence (UAI)}, volume 115, pp.\  367--377, 2019.

\bibitem[Lin et~al.(2021)Lin, Wang, Sun, Chen, Sun, Qian, Li, and Jin]{zennas}
Lin, M., Wang, P., Sun, Z., Chen, H., Sun, X., Qian, Q., Li, H., and Jin, R.
\newblock {Zen-NAS}: A zero-shot nas for high-performance image recognition.
\newblock In \emph{{IEEE/CVF} International Conference on Computer Vision
  (ICCV)}, pp.\  347--356, 2021.

\bibitem[Liu et~al.(2022)Liu, Cai, and Zhuang]{focusformer}
Liu, J., Cai, J., and Zhuang, B.
\newblock {FocusFormer}: Focusing on what we need via architecture sampler.
\newblock \emph{arXiv preprint arXiv:2208.10861}, 2022.

\bibitem[Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis,
  Zettlemoyer, and Stoyanov]{liu2019roberta}
Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M.,
  Zettlemoyer, L., and Stoyanov, V.
\newblock {RoBERTa}: A robustly optimized bert pretraining approach.
\newblock \emph{arXiv preprint arXiv:1907.11692}, 2019.

\bibitem[Mellor et~al.(2021)Mellor, Turner, Storkey, and
  Crowley]{DBLP:conf/icml/MellorTSC21}
Mellor, J., Turner, J., Storkey, A.~J., and Crowley, E.~J.
\newblock Neural architecture search without training.
\newblock In \emph{International Conference on Machine Learning (ICML)}, volume
  139, pp.\  7588--7598, 2021.

\bibitem[Nilsback \& Zisserman(2008)Nilsback and Zisserman]{flowers}
Nilsback, M. and Zisserman, A.
\newblock Automated flower classification over a large number of classes.
\newblock In \emph{Indian Conference on Computer Vision, Graphics {\&} Image
  Processing (ICVGIP)}, pp.\  722--729, 2008.

\bibitem[Parkhi et~al.(2012)Parkhi, Vedaldi, Zisserman, and Jawahar]{pets}
Parkhi, O.~M., Vedaldi, A., Zisserman, A., and Jawahar, C.~V.
\newblock Cats and dogs.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  3498--3505, 2012.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E.,
  DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L.,
  Bai, J., and Chintala, S.
\newblock {PyTorch: An imperative style, high-performance deep learning
  library}.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pp.\
  8024--8035, 2019.

\bibitem[Pham et~al.(2018)Pham, Guan, Zoph, Le, and Dean]{pham2018efficient}
Pham, H., Guan, M., Zoph, B., Le, Q., and Dean, J.
\newblock Efficient neural architecture search via parameters sharing.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  4095--4104, 2018.

\bibitem[Radosavovic et~al.(2020)Radosavovic, Kosaraju, Girshick, He, and
  Doll{\'a}r]{radosavovic2020designing}
Radosavovic, I., Kosaraju, R.~P., Girshick, R., He, K., and Doll{\'a}r, P.
\newblock Designing network design spaces.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  10428--10436, 2020.

\bibitem[Real et~al.(2019)Real, Aggarwal, Huang, and
  Le]{DBLP:conf/aaai/RealAHL19}
Real, E., Aggarwal, A., Huang, Y., and Le, Q.~V.
\newblock Regularized evolution for image classifier architecture search.
\newblock In \emph{The Thirty-Third {AAAI} Conference on Artificial
  Intelligence (AAAI)}, pp.\  4780--4789, 2019.

\bibitem[Sandler et~al.(2018)Sandler, Howard, Zhu, Zhmoginov, and
  Chen]{howard2018inverted}
Sandler, M., Howard, A.~G., Zhu, M., Zhmoginov, A., and Chen, L.
\newblock Inverted residuals and linear bottlenecks: Mobile networks for
  classification, detection and segmentation.
\newblock \emph{CoRR}, abs/1801.04381, 2018.

\bibitem[Shu et~al.(2022{\natexlab{a}})Shu, Cai, Dai, Ooi, and Low]{nasi}
Shu, Y., Cai, S., Dai, Z., Ooi, B.~C., and Low, B. K.~H.
\newblock {NASI:} label- and data-agnostic neural architecture search at
  initialization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2022{\natexlab{a}}.

\bibitem[Shu et~al.(2022{\natexlab{b}})Shu, Dai, Wu, and Low]{shu2022unifying}
Shu, Y., Dai, Z., Wu, Z., and Low, B. K.~H.
\newblock Unifying and boosting gradient-based training-free neural
  architecture search.
\newblock \emph{arXiv preprint arXiv:2201.09785}, 2022{\natexlab{b}}.

\bibitem[Srinivas et~al.(2021)Srinivas, Lin, Parmar, Shlens, Abbeel, and
  Vaswani]{botnet}
Srinivas, A., Lin, T., Parmar, N., Shlens, J., Abbeel, P., and Vaswani, A.
\newblock Bottleneck transformers for visual recognition.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  16519--16529, 2021.

\bibitem[Su et~al.(2022)Su, You, Xie, Zheng, Wang, Qian, Zhang, Wang, and
  Xu]{su2022vitas}
Su, X., You, S., Xie, J., Zheng, M., Wang, F., Qian, C., Zhang, C., Wang, X.,
  and Xu, C.
\newblock {ViTAS}: Vision transformer architecture search.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, pp.\
  139--157, 2022.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{label_smoothing_2016}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  2818--2826, 2016.

\bibitem[Tan \& Le(2019)Tan and Le]{DBLP:conf/icml/TanL19}
Tan, M. and Le, Q.~V.
\newblock {EfficientNet}: Rethinking model scaling for convolutional neural
  networks.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  volume~97, pp.\  6105--6114, 2019.

\bibitem[Tan et~al.(2019)Tan, Chen, Pang, Vasudevan, Sandler, Howard, and
  Le]{DBLP:conf/cvpr/TanCPVSHL19}
Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le,
  Q.~V.
\newblock {MnasNet}: Platform-aware neural architecture search for mobile.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  2820--2828, 2019.

\bibitem[Tanaka et~al.(2020)Tanaka, Kunin, Yamins, and Ganguli]{synflow}
Tanaka, H., Kunin, D., Yamins, D. L.~K., and Ganguli, S.
\newblock Pruning neural networks without any data by iteratively conserving
  synaptic flow.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2020.

\bibitem[Touvron et~al.(2021)Touvron, Cord, Douze, Massa, Sablayrolles, and
  J{\'{e}}gou]{deit}
Touvron, H., Cord, M., Douze, M., Massa, F., Sablayrolles, A., and J{\'{e}}gou,
  H.
\newblock Training data-efficient image transformers {\&} distillation through
  attention.
\newblock In \emph{International Conference on Machine Learning (ICML)}, volume
  139, pp.\  10347--10357, 2021.

\bibitem[Wang et~al.(2020{\natexlab{a}})Wang, Zhang, and Grosse]{grasp}
Wang, C., Zhang, G., and Grosse, R.~B.
\newblock Picking winning tickets before training by preserving gradient flow.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020{\natexlab{a}}.

\bibitem[Wang et~al.(2020{\natexlab{b}})Wang, Wu, Liu, Cai, Zhu, Gan, and
  Han]{hat}
Wang, H., Wu, Z., Liu, Z., Cai, H., Zhu, L., Gan, C., and Han, S.
\newblock {HAT:} hardware-aware transformers for efficient natural language
  processing.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics (ACL)}, pp.\  7675--7688, 2020{\natexlab{b}}.

\bibitem[Wang et~al.(2022)Wang, Bai, Ao, Zhou, Xiong, Wei, Zhang, Ko, and
  Li]{lighthubert}
Wang, R., Bai, Q., Ao, J., Zhou, L., Xiong, Z., Wei, Z., Zhang, Y., Ko, T., and
  Li, H.
\newblock {LightHuBERT}: Lightweight and configurable speech representation
  learning with once-for-all hidden-unit {BERT}.
\newblock In \emph{Annual Conference of the International Speech Communication
  Association (INTERSPEECH)}, pp.\  1686--1690, 2022.

\bibitem[Wightman(2019)]{timm}
Wightman, R.
\newblock Pytorch image models.
\newblock \url{https://github.com/rwightman/pytorch-image-models}, 2019.

\bibitem[Wu et~al.(2019)Wu, Dai, Zhang, Wang, Sun, Wu, Tian, Vajda, Jia, and
  Keutzer]{wu2019fbnet}
Wu, B., Dai, X., Zhang, P., Wang, Y., Sun, F., Wu, Y., Tian, Y., Vajda, P.,
  Jia, Y., and Keutzer, K.
\newblock {FBNet}: Hardware-aware efficient convnet design via differentiable
  neural architecture search.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  10734--10742, 2019.

\bibitem[Xu et~al.(2021{\natexlab{a}})Xu, Zhao, Lin, Gao, Sun, and Yang]{knas}
Xu, J., Zhao, L., Lin, J., Gao, R., Sun, X., and Yang, H.
\newblock {KNAS:} green neural architecture search.
\newblock In \emph{International Conference on Machine Learning (ICML)}, volume
  139, pp.\  11613--11625, 2021{\natexlab{a}}.

\bibitem[Xu et~al.(2021{\natexlab{b}})Xu, Zhang, Zhang, and Tao]{vitae}
Xu, Y., Zhang, Q., Zhang, J., and Tao, D.
\newblock {ViTAE}: Vision transformer advanced by exploring intrinsic inductive
  bias.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pp.\  28522--28535, 2021{\natexlab{b}}.

\bibitem[Yang et~al.(2022)Yang, Wang, Zhang, Zhang, Wei, Lin, and Yuille]{lvt}
Yang, C., Wang, Y., Zhang, J., Zhang, H., Wei, Z., Lin, Z., and Yuille, A.~L.
\newblock Lite vision transformer with enhanced self-attention.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  11988--11998, 2022.

\bibitem[Yin et~al.(2021)Yin, Chen, Shang, Jiang, Chen, and Liu]{autotinybert}
Yin, Y., Chen, C., Shang, L., Jiang, X., Chen, X., and Liu, Q.
\newblock {AutoTinyBERT}: Automatic hyper-parameter optimization for efficient
  pre-trained language models.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics (ACL)}, pp.\  5146--5157, 2021.

\bibitem[Yu \& Huang(2019)Yu and Huang]{yu2019universally}
Yu, J. and Huang, T.~S.
\newblock Universally slimmable networks and improved training techniques.
\newblock In \emph{{IEEE/CVF} International Conference on Computer Vision
  (ICCV)}, pp.\  1803--1811, 2019.

\bibitem[Yu et~al.(2020)Yu, Jin, Liu, Bender, Kindermans, Tan, Huang, Song,
  Pang, and Le]{bignas}
Yu, J., Jin, P., Liu, H., Bender, G., Kindermans, P., Tan, M., Huang, T.~S.,
  Song, X., Pang, R., and Le, Q.
\newblock {BigNAS}: Scaling up neural architecture search with big single-stage
  models.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, volume
  12352, pp.\  702--717, 2020.

\bibitem[Yuan et~al.(2020)Yuan, Tay, Li, Wang, and Feng]{label_smoothing_2020}
Yuan, L., Tay, F. E.~H., Li, G., Wang, T., and Feng, J.
\newblock Revisiting knowledge distillation via label smoothing regularization.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  3902--3910, 2020.

\bibitem[Yuan et~al.(2021)Yuan, Chen, Wang, Yu, Shi, Jiang, Tay, Feng, and
  Yan]{t2t}
Yuan, L., Chen, Y., Wang, T., Yu, W., Shi, Y., Jiang, Z., Tay, F. E.~H., Feng,
  J., and Yan, S.
\newblock {Tokens-to-token ViT}: Training vision transformers from scratch on
  {ImageNet}.
\newblock In \emph{{IEEE/CVF} International Conference on Computer Vision
  (ICCV)}, pp.\  538--547, 2021.

\bibitem[Yun et~al.(2019)Yun, Han, Chun, Oh, Yoo, and Choe]{cutmix}
Yun, S., Han, D., Chun, S., Oh, S.~J., Yoo, Y., and Choe, J.
\newblock {CutMix}: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In \emph{{IEEE/CVF} International Conference on Computer Vision
  (ICCV)}, pp.\  6022--6031, 2019.

\bibitem[Zhang et~al.(2018)Zhang, Ciss{\'{e}}, Dauphin, and Lopez{-}Paz]{mixup}
Zhang, H., Ciss{\'{e}}, M., Dauphin, Y.~N., and Lopez{-}Paz, D.
\newblock mixup: Beyond empirical risk minimization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Zhong et~al.(2020)Zhong, Zheng, Kang, Li, and Yang]{random_erasing}
Zhong, Z., Zheng, L., Kang, G., Li, S., and Yang, Y.
\newblock Random erasing data augmentation.
\newblock In \emph{{AAAI} Conference on Artificial Intelligence (AAAI)}, pp.\
  13001--13008, 2020.

\bibitem[Zhou et~al.(2022)Zhou, Sheng, Zheng, Li, Sun, Tian, Chen, and
  Ji]{tftas}
Zhou, Q., Sheng, K., Zheng, X., Li, K., Sun, X., Tian, Y., Chen, J., and Ji, R.
\newblock Training-free transformer architecture search.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  10884--10893, 2022.

\end{thebibliography}
