% This file was created with JabRef 2.10.
% Encoding: UTF8


@String { ieee_j_ac    = {{IEEE} Trans. Autom. Control} }
@String { ieee_j_com   = {{IEEE} Trans. Commun.} }
@String { ieee_j_coml  = {{IEEE} Communications Letters} }
@String { ieee_j_it    = {{IEEE} Trans. on Information Theory} }
@String { ieee_j_jsac  = {{IEEE} J. Sel. Areas Commun.} }
@String { ieee_j_jstsp = {{IEEE} J. Sel. Topics Signal Process.} }
@String { ieee_j_sp    = {{IEEE} Trans. Signal Process.} }
@String { ieee_j_spl   = {{IEEE} Signal Processing Letters} }
@String { ieee_j_vt    = {{IEEE} Trans. on Vehicular Technology} }
@String { ieee_j_wcom  = {{IEEE} Trans. Wireless Commun.} }
@String { ieee_m_com   = {{IEEE} Communications Magazine} }
@String { ieee_m_cs    = {{IEEE} Control Systems Magazine} }
@String { ieee_m_sp    = {{IEEE} Signal Process. Mag.} }
@String { ieee_m_wc    = {{IEEE} Wireless Communications Magazine} }

@article{johnson2013accelerating,
  title={Accelerating stochastic gradient descent using predictive variance reduction},
  author={Johnson, Rie and Zhang, Tong},
  journal={Advances in neural information processing systems},
  volume={26},
  pages={315--323},
  year={2013},
  publisher={Citeseer}
}

@article{xiao2007distributed,
  title={Distributed average consensus with least-mean-square deviation},
  author={Xiao, Lin and Boyd, Stephen and Kim, Seung-Jean},
  journal={Journal of parallel and distributed computing},
  volume={67},
  number={1},
  pages={33--46},
  year={2007},
  publisher={Elsevier}
}

@article{kovalev2020optimal,
  title={Optimal and practical algorithms for smooth and strongly convex decentralized optimization},
  author={Kovalev, Dmitry and Salim, Adil and Richt{\'a}rik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{Pace_1998,
	title={ Quick computations of spatially autoregressive estimators},
	author={Pace, R.K and Barry, R.P.},
	journal={Geographical Analysis},
	volume={29},
	number={3},
	pages={232-247},
	year={1998},
}

@inproceedings{Kohavi_1996,
author = {Kohavi, Ron},
title = {Scaling up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid},
year = {1996},
publisher = {AAAI Press},
booktitle = {Proceedings of the Second International Conference on Knowledge Discovery and Data Mining},
pages = {202–207},
numpages = {6},
location = {Portland, Oregon},
series = {KDD'96}
}

@article{flake2002efficient,
  title={Efficient {SVM} regression training with {SMO}},
  author={Flake, Gary William and Lawrence, Steve},
  journal={Machine Learning},
  volume={46},
  number={1},
  pages={271--290},
  year={2002},
  publisher={Springer}
}

@article{nedic2017achieving,
	title={Achieving geometric convergence for distributed optimization over time-varying graphs},
	author={Nedic, Angelia and Olshevsky, Alex and Shi, Wei},
	journal={SIAM Journal on Optimization},
	volume={27},
	number={4},
	pages={2597--2633},
	year={2017},
	publisher={SIAM}
}

@INPROCEEDINGS{9303887,  
	author={J. {Zhang} and Q. {Ling} and A. M. -C. {So}},  booktitle={2020 59th IEEE Conference on Decision and Control (CDC)},   title={A Newton Tracking Algorithm with Exact Linear Convergence Rate for Decentralized Consensus Optimization},   year={2020},  volume={},  number={},  pages={2317-2322},  doi={10.1109/CDC42340.2020.9303887}}

@InProceedings{pmlr-v108-li20f,
	title = 	 {Communication-Efficient Distributed Optimization in Networks with Gradient Tracking and Variance Reduction},
	author =       {Li, Boyue and Cen, Shicong and Chen, Yuxin and Chi, Yuejie},
	booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
	pages = 	 {1662--1672},
	year = 	 {2020},
	editor = 	 {Silvia Chiappa and Roberto Calandra},
	volume = 	 {108},
	series = 	 {Proceedings of Machine Learning Research},
	month = 	 {26--28 Aug},
	publisher =    {PMLR}
}


@article{mokhtari2016network,
	title={Network Newton distributed optimization methods},
	author={Mokhtari, Aryan and Ling, Qing and Ribeiro, Alejandro},
	journal={IEEE Transactions on Signal Processing},
	volume={65},
	number={1},
	pages={146--161},
	year={2016},
	publisher={IEEE}
}

@article{sridharan2008fast,
	title={Fast rates for regularized objectives},
	author={Sridharan, Karthik and Shalev-Shwartz, Shai and Srebro, Nathan},
	journal={Advances in neural information processing systems},
	volume={21},
	pages={1545--1552},
	year={2008}
}

@article{sun2019distributed,
	title={Distributed optimization based on gradient-tracking revisited: Enhancing convergence rate via surrogation},
	author={Sun, Y and Daneshmand, A and Scutari, G},
	journal={arXiv:1905.02637},
	year={2019}
}

@book{auzinger2011iterative,
	title={Iterative solution of large linear systems},
	author={Wien, Auzinger},
	year={2011},
	publisher={Lecture Notes, TU Wien}
}


    
    
    @book{Vapnik13,
    	title={The nature of statistical learning theory},
    	author={Vapnik, V},
    	year={2013},
    	publisher={ Springer science \& business media}
    }


 
 @book{Bousquet02,
	title={Concentration inequalities and empirical processes theory applied to the analysis of learning algorithms},
	author={Bousquet, O.},
	year={2002},
	publisher={PhD thesis, Ecole Polytechnique: Department of Applied Mathematics Paris, France}
}

@book{SHai-Shalev-book,
	title={Understanding Machine Learning: From Theory to Algorihtms},
	author={Shai, Shalev-Shwartz and Shai Ben-David},
	year={2014},
	publisher={Cambridge University Press}
}
@book{Bekkerman_book11,
	title={Scaling up Machine Learning: Parallel and Distributed Approaches},
	author={Bekkerman, R. and  Bilenko, M.  and Langford, J.},
	year={2011},
	publisher={Cambridge University Press}
}

@article{NetDane,
	title={Communication-Efficient Distributed Optimization in Networks with Gradient Tracking and Variance Reduction},
	author={Boyue Li and Shicong Cen and Yuxin Chen and Yuejie Chi},
	journal={arXiv:1909.05844v3},
	year={2019}
}


 @InProceedings{scaman2017optimal, 
 title = {Optimal Algorithms for Smooth and Strongly Convex Distributed Optimization in Networks}, 
 author = {Kevin Scaman and Francis Bach and S{\'e}bastien Bubeck and Yin Tat Lee and Laurent Massouli{\'e}},
 booktitle = {Proceedings of the 34th International Conference on Machine Learning}, 
 pages = {3027--3036}, 
 year = {2017}, 
 volume = {70} } 

@inproceedings{scaman2018optimal,
 author = {Scaman, Kevin and Bach, Francis and Bubeck, Sebastien and Massouli\'{e}, Laurent and Lee, Yin Tat},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {2740--2749},
 title = {Optimal Algorithms for Non-Smooth Distributed Optimization in Networks},
 volume = {31},
 year = {2018}
}

@article{lan2017communication,
  title={Communication-efficient algorithms for decentralized and stochastic optimization},
  author={Lan, Guanghui and Lee, Soomin and Zhou, Yi},
  journal={Mathematical Programming},
  pages={1--48},
  year={2017},
  publisher={Springer}
}

 


@article{uribe2020dual,
  title={A dual approach for optimal algorithms in distributed optimization over networks},
  author={Uribe, C{\'e}sar A and Lee, Soomin and Gasnikov, Alexander and Nedi{\'c}, Angelia},
  journal={Optimization Methods and Software},
  pages={1--40},
  year={2020},
  publisher={Taylor \& Francis}
}

@article{rogozin2020towards,
  title={Towards accelerated rates for distributed optimization over time-varying networks},
  author={Rogozin, Alexander and Lukoshkin, Vladislav and Gasnikov, Alexander and Kovalev, Dmitry and Shulgin, Egor},
  journal={arXiv:2009.11069},
  year={2020}
}


@InProceedings{xiao2005scheme,
	Title                    = {A scheme for robust distributed sensor fusion based on average consensus},
	Author                   = {L. Xiao and S. Boyd and S. Lall},
	Booktitle                = {Proceedings of the 4th international symposium on Information processing in sensor networks},
	Year                     = {2005},
	
	Address                  = {Los Angeles, CA},
	Month                    = {April},
	Pages                    = {63-70}
}

@article{tropp2015introduction,
	title={An introduction to matrix concentration inequalities},
	author={Tropp, Joel A and others},
	journal={Foundations and Trends{\textregistered} in Machine Learning},
	volume={8},
	number={1-2},
	pages={1--230},
	year={2015},
	publisher={Now Publishers, Inc.}
}


 
 	
 	@article{Shwartz-JMLR2010,
 	title={Learnability, Stability and Uniform Convergence},
 	author={Shai Shalev-Shwartz and Ohad Shamir and Nathan Srebro and 
 	Karthik Sridharan},
 	journal={Journal of Machine Learning Research},
 	volume={11},
 	pages={2635--2670},
 	year={2010}
 	}
 
 @article{Bartlett06,
 	title={Convexity, classiﬁcation, and risk bounds},
 	author={Bartlett, P. L. and Jordan, M. I. and McAulffe, J. D. },
 	journal={Journal of the American Statistical Association},
 	volume={101},
 	number={473},
 	pages={138--156},
 	year={2006}
 }
 
 
 
  
  @article{Nedich_tutorial,
  	title={Network Topology and Communication – Computation Tradeoffs in Decentralized Optimization},
  	author={A. Nedić and  A. Olshevsky and M. G. Rabbat  },
  	journal={Proceedings of the IEEE},
  	volume={106},
  	number={5},
  	pages={953--976},
  	year={2018}
  }
  
    
@article{MokhtariDQM16,
	title={{DQM}: Decentralized quadratically approximated alternating direction method of multipliers},
	author={A. Mokhtari and  W. Shi and  Q. Ling and A. Ribeiro},
	journal={IEEE Transactions on Signal Processing},
	volume={64},
	number={19},
	pages={5158--5173},
	year={2016}}

@article{MokhtariNewton2,
	title={A decentralized second-order method with exact linear convergence rate for consensus optimization},
	author={A. Mokhtari and  W. Shi and  Q. Ling and A. Ribeiro},
	journal={IEEE Transactions on Signal Processing},
	volume={2},
	number={4},
	pages={507--522},
	year={2016}
}

 
 
@article{MokhtariNewton3,
	title={A Primal-Dual Quasi-Newton Method for Exact Consensus Optimization},
	author={M. Eisen and A. Mokhtari and   A. Ribeiro},
	journal={IEEE Transactions on Signal Processing},
	volume={67},
	number={23},
	pages={5983--5997},
	year={2019}
}

@inproceedings{shamir2014communication,
	title={Communication-efficient distributed optimization using an approximate newton-type method},
	author={Shamir, Ohad and Srebro, Nati and Zhang, Tong},
	booktitle={International conference on machine learning},
	pages={1000--1008},
	year={2014}
}

 

@inproceedings{Lian17,
	title={ Can decentralized algorithms outperform centralized algorithms? {A} case study for decentralized parallel stochastic gradient descent},
	author={X. Lian and  C. Zhang and  H. Zhang and  C.-J. Hsieh and  W. Zhang and J. Liu. },
	booktitle={Advances in Neural Information Processing Systems},
	pages={5330--5340},
	year={2017}
}

 

@inproceedings{Frostig15,
	title={ Competing with the empirical risk minimizer in a single pass},
	author={Frostig, R. and Ge, R. and  Kakade, S. M. and Sidford, A},
	booktitle={Conference on learning theory (COLT)},
	pages={728--763},
	year={2015}
}
@article{reddi2016aide,
	title={Aide: Fast and communication efficient distributed optimization},
	author={Reddi, Sashank J and Kone{\v{c}}n{\`y}, Jakub and Richt{\'a}rik, Peter and P{\'o}cz{\'o}s, Barnab{\'a}s and Smola, Alex},
	journal={arXiv:1608.06879},
	year={2016}
}

@article{yuan2019convergence,
	title={On Convergence of Distributed Approximate Newton Methods: Globalization, Sharper Bounds and Beyond},
	author={Yuan, Xiao-Tong and Li, Ping},
	journal={arXiv:1908.02246},
	year={2019}
}

@article{hendrikx2020statistically,
	title={Statistically Preconditioned Accelerated Gradient Method for Distributed Optimization},
	author={Hendrikx, Hadrien and Xiao, Lin and Bubeck, Sebastien and Bach, Francis and Massoulie, Laurent},
	journal={arXiv:2002.10726},
	year={2020}
}

@book{nesterov2018lectures,
	title={Lectures on convex optimization},
	author={Nesterov, Yurii},
	volume={137},
	publisher={Springer},
	year={2018}
}

@article{deng2016global,
	title={On the global and linear convergence of the generalized alternating direction method of multipliers},
	author={Deng, Wei and Yin, Wotao},
	journal={Journal of Scientific Computing},
	volume={66},
	number={3},
	pages={889--916},
	year={2016},
	publisher={Springer}
}


 
 


  @article{Bach10,
  	title={Self-concordant analysis for logistic regression},
  	author={F. Bach},
  	journal={Electronic Journal of Statistics},
  	volume={4},
  	pages={384--414.},
  	year={2010},
  }
    
@article{Nesterov--Cubic06,
	title={ Cubic regularization of Newton method and its global performance},
	author={Yurii Nesterov and  B.T. Polyak },
	journal={Mathematical Programming},
	volume={108},
	pages={177--205},
	year={2006}
}



 

 
 

@article{Sun19-Self-concordance,
	title={ Generalized self-concordant functions: a recipe for Newton-type methods},
	author={Tianxiao Sun and Quoc Tran-Dinh },
	journal={Mathematical Programming},
	volume={178},
	pages={145--213},
	year={2019}
}

 

@article{Bottou18,
	title={ Optimization Methods for Large-Scale Machine Learning},
	author={Leon Bottou and   Frank E. Curtis  and Jorge Nocedal},
	journal={SIAM Review},
	volume={60},
	number = {2},
	pages={223--311},
	year={2018}
}


@article{Uribe20,
	title={A Distributed Cubic-Regularized Newton Method for Smooth Convex Optimization over Networks},
	author={Cesar A. Uribe and  Ali Jadbabaie},
	journal={arXiv:2007.03562},
	year={2020}
}

 
 


@article{Zhang20,
	title={Distributed Adaptive Newton Methods with Globally Superlinear Convergence},
	author={Jiaqi Zhang and Keyou You and  Tamer Basar},
	journal={arXiv:2002.07378},
	year={2020}
}

@INPROCEEDINGS{Arjevani-ShamirNIPS15, 
	author={Yossi  Arjevani and Ohad  Shamir}, 
	booktitle={Proceedings of the 28th International Conference on Neural Information Processing Systems (NIPS)}, 
	title={Communication complexity of distributed convex learning and optimization}, 
	year={2015}, 
	volume={1}, 
	number={}, 
	pages={1756--1764},
	month={December}
	}
	
	@InProceedings{pmlr-v108-soori20a, title = {DAve-QN: A Distributed Averaged Quasi-Newton Method with Local Superlinear Convergence Rate}, author = {Soori, Saeed and Mishchenko, Konstantin and Mokhtari, Aryan and Dehnavi, Maryam Mehri and Gurbuzbalaban, Mert}, booktitle = {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics}, pages = {1965--1976}, year = {2020},  volume = {108}  }
	 	
	 	
@INPROCEEDINGS{DISCO,
	Title                    = {DiSCO: Distributed Optimization for Self-Concordant Empirical Loss},
	Author                   = {Yuchen Zhang and  Lin Xiao},
	booktitle                  = {Proceedings of the 32nd International Conference on Machine Learning (PMLR)},
	Year                     = {2015},
	Volume = 37,
	pages = {362--370}
}

 INPROCEEDINGS{DISCO,
	Title                    = {Statistically Preconditioned Accelerated Gradient Method for Distributed Optimization},
	Author                   = {Hadrien Hendrikx  and  Lin Xiao and  Sebastien Bubeck and Francis Bach and Laurent Massoulie},
	booktitle                  = {Proceedings of the 32nd International Conference on Machine Learning (PMLR)},
	Year                     = {2015},
	Volume = 37,
	pages = {362--370}
}


 @InProceedings{pmlr-v119-hendrikx20a, 
 title = {Statistically Preconditioned Accelerated Gradient Method for Distributed Optimization}, 
 author = {Hendrikx, Hadrien and Xiao, Lin and Bubeck, Sebastien and Bach, Francis and Massoulie, Laurent}, 
 booktitle = {Proceedings of the 37th International Conference on Machine Learning}, pages = {4203--4227}, 
 year = {2020},  
 volume = {119},   
 month = {13--18 Jul} }
  
  
 
@INPROCEEDINGS{DANCE20,
  title =	 {Efficient Distributed Hessian Free Algorithm for Large-scale Empirical Risk Minimization via Accumulating Sample Strategy},
  author =	 {Majid Jahani and  Xi He and   Chenxin Ma and   Aryan Mokhtari and  Dheevatsa Mudigere and  Alejandro Ribeiro and  Martin Takac},
  booktitle  =	 {Twenty Third International Conference on Artificial Intelligence and Statistics},
  year =	 2020,
   pages =	 {2634--2644}
}


@INPROCEEDINGS{ADA-Newton16,
	Title                    = {Adaptive Newton method for empirical risk minimization to statistical accuracy},
	Author                   = {Aryan Mokhtari and  Hadi Daneshmand and   Aurelien Lucchi and  Thomas Hofmann  and Alejandro Ribeiro},
	booktitle                  = {Proceedings of the Advances in Neural Information Processing Systems},
	Year                     = {2016},
	pages = {4062--4070}
}


 

@article{Network-Newton17,
	Title                    = {Network Newton Distributed Optimization Methods},
	Author                   = {Aryan Mokhtari and Qing Ling and    Alejandro Ribeiro},
	journal                  = {IEEE Transactions on Signal Processing},
	Year                     = {2017},
	issue= {1},
	pages = {146--161},
	volume = {65}  
}

 

@INPROCEEDINGS{So2020,
author = {Jiaojiao, Zhang and Ling, Qing and So, Anthony},
year = {2020},
booktitle = {59th IEEE Conference on Decision and Control (CDC)},
title = {A Newton Tracking Algorithm with Exact Linear Convergence Rate for Decentralized Consensus Optimization}
}

  @INPROCEEDINGS{Ma17,
	Title                    = {Distributed Inexact Damped Newton Method: Data Partitioning and Work-Balancing},
	Author                   = {Chenxin Ma and  Martin Takac},
	booktitle                  = {  Workshops at the Thirty-First AAAI Conference on Artificial Intelligence},
	Year                     = {2017}
}

@article{Berthier2020,
	title={Accelerated Gossip in Networks of Given Dimension Using Jacobi Polynomial Iterations},
	author={Raphael Berthier and Francis Bach and Pierre Gaillard},
	journal={SIAM J. on Mathematics of Data Science},
	volume={1},
	pages={24-47},
	issue = 2,
	year={2020}
}

@INPROCEEDINGS{GIANT,
	Title                    = {GIANT: Globally Improved Approximate Newton Method for Distributed Optimization},
	Author                   = {Shusen Wang and  Farbod Roosta-Khorasani and   Peng Xu and Michael W. Mahoney},
	booktitle                  = {Proceedings of the 32nd 32nd International Conference on Neural Information Processing Systems},
	Year                     = {2018},
	Volume = 37,
	pages = {2338--2348}
}

 

@INPROCEEDINGS{Shwartz_et_al, 
	author={Shai Shalev-Shwartz and  Ohad Shamir and  Nathan Srebro and  Karthik Sridharan}, 
	booktitle={Proceedings of the 22nd Annual Conference on Learning Theory (COLT)}, 
	title={Stochastic Convex Optimization}, 
	year={2009}, 
	Address= {Montreal, Canada},
	month={June 18-21}
}


@INPROCEEDINGS{DANE,
	Title                    = {Communication-Efficient Distributed Optimization using an Approximate Newton-type Method},
	Author                   = {Ohad Shamir and  Nati Srebro and  Tong Zhang},
	booktitle                  = {Proceedings of the 31st International Conference on Machine Learning (PMLR)},
	Year                     = {2014},
	Volume = 32,
	pages = {1000--1008}
}

 
 
 @Article{Fan2020,
Title  = {Communication-Efficient Accurate Statistical Estimation},
	Author                   = {Jianqing Fan and Yongyi Guo and  Kaizheng Wang},
	Journal                  = {arXiv:1906.04870},
	Year                     = {2019}
	}

@incollection{Zhang-Xiao-chapter18,
	author      = {Yuchen Zhang and Lin Xiao},
	title       = {Communication-efficient distributed optimization of self-concordant empirical loss},
	booktitle   = {Large-Scale and Distributed Optimization, number 2227 in Lecture Notes in
	Mathematics},
	chapter = {11},
	publisher   = {Springer},
	pages = {289--341},
	year        = {2018}
}

@inproceedings{marteau2019globally,
	title={Globally Convergent Newton Methods for Ill-conditioned Generalized Self-concordant Losses},
	author={Marteau-Ferey, Ulysse and Bach, Francis and Rudi, Alessandro},
	booktitle={Advances in Neural Information Processing Systems},
	pages={7636--7646},
	year={2019}
}


@article{jakovetic2014fast,
  title={Fast distributed gradient methods},
  author={Jakoveti{\'c}, Du{\v{s}}an and Xavier, Joao and Moura, Jos{\'e} MF},
  journal={IEEE Transactions on Automatic Control},
  volume={59},
  number={5},
  pages={1131--1146},
  year={2014},
  publisher={IEEE}
}


@article{Xu-TAC:hs,
	author = {Xu, Jinming and Zhu, Shanying and Soh, Yeng Chai and Xie, Lihua},
	title = {{Convergence of Asynchronous Distributed Gradient Methods Over Stochastic Networks}},
	journal = {IEEE Transactions on Automatic Control},
	volume = {63},
	number = {2},
	pages = {434--448},
	year={2018}
}
@Article{NEXT16,
	Title                    = {{NEXT: I}n-Network Nonconvex Optimization},
	Author                   = {P. {Di Lorenzo} and G. Scutari},
	Journal                  = {IEEE Transactions on Signal and Information Processing over Networks},
	Year                     = {2016},
	
	Month                    = {June},
	Number                   = {2},
	Pages                    = {120-136},
	Volume                   = {2},
	
	Keywords                 = {approximation theory;concave programming;convex programming;minimisation;multi-agent systems;agent sum-utility;algorithmic framework;asymptotic convergence;convex approximation techniques;convex regularizer;distributed minimization;dynamic consensus mechanism;in-network nonconvex optimization;multi-agent networks;nonconvex distributed optimization;time-varying connectivity;Algorithm design and analysis;Approximation algorithms;Convergence;Heuristic algorithms;Information processing;Optimization;Signal processing algorithms;Consensus;distributed optimization;non-convex optimization;nonconvex optimization;successive convex approximation;time-varying directed graphs},
	Owner                    = {Sonia},
	Timestamp                = {2016.10.24}
}

book{auzinger2011iterative,
	title={Iterative solution of large linear systems},
	author={Wien, Auzinger},
	year={2011},
	publisher={Lecture Notes, TU Wien}
}


article{nedic2017achieving,
  title={Achieving geometric convergence for distributed optimization over time-varying graphs},
  author={Nedic, Angelia and Olshevsky, Alex and Shi, Wei},
  journal={SIAM Journal on Optimization},
  volume={27},
  number={4},
  pages={2597--2633},
  year={2017},
  publisher={SIAM}
}

@article{shi2015extra,
  title={Extra: An exact first-order algorithm for decentralized consensus optimization},
  author={Shi, Wei and Ling, Qing and Wu, Gang and Yin, Wotao},
  journal={SIAM Journal on Optimization},
  volume={25},
  number={2},
  pages={944--966},
  year={2015},
  publisher={SIAM}
}


@INPROCEEDINGS{jadbabaie2009distributed,

  author={A. {Jadbabaie} and A. {Ozdaglar} and M. {Zargham}},

  booktitle={Proceedings of the 48h IEEE Conference on Decision and Control (CDC) held jointly with 2009 28th Chinese Control Conference}, 

  title={A distributed newton method for network optimization}, 

  year={2009},

  volume={},

  number={},

  pages={2736-2741},

  doi={10.1109/CDC.2009.5400289}}



@ARTICLE{wei2013distributed,

  author={E. {Wei} and A. {Ozdaglar} and A. {Jadbabaie}},

  journal={IEEE Transactions on Automatic Control}, 

  title={A Distributed Newton Method for Network Utility Maximization—Part II: Convergence}, 

  year={2013},

  volume={58},

  number={9},

  pages={2176-2188},

  doi={10.1109/TAC.2013.2253223}}


@ARTICLE{tutunov2019distributed,

  author={R. {Tutunov} and H. {Bou-Ammar} and A. {Jadbabaie}},

  journal={IEEE Transactions on Automatic Control}, 

  title={Distributed Newton Method for Large-Scale Consensus Optimization}, 

  year={2019},

  volume={64},

  number={10},

  pages={3983-3994},

  doi={10.1109/TAC.2019.2907711}}



@misc{uribe2020distributed,
      title={A Distributed Cubic-Regularized Newton Method for Smooth Convex Optimization over Networks}, 
      author={César A. Uribe and Ali Jadbabaie},
      year={2020},
      eprint={2007.03562},
      archivePrefix={arXiv},
      primaryClass={math.OC}
}

@article{dragomir2019optimal,
  title={Optimal complexity and certification of Bregman first-order methods},
  author={Dragomir, Radu-Alexandru and Taylor, Adrien and d'Aspremont, Alexandre and Bolte, J{\'e}r{\^o}me},
  journal={arXiv:1911.08510},
  year={2019}
}

@article{ghadimi2017second,
  title={Second-order methods with cubic regularization under inexact information},
  author={Ghadimi, Saeed and Liu, Han and Zhang, Tong},
  journal={arXiv:1710.05782},
  year={2017}
}

@article{agafonov2020inexact,
  title={Inexact Tensor Methods and Their Application to Stochastic Convex Optimization},
  author={Agafonov, Artem and Kamzolov, Dmitry and Dvurechensky, Pavel and Gasnikov, Alexander},
  journal={arXiv:2012.15636},
  year={2020}
}

@article{gorbunov2020recent,
  title={Recent theoretical advances in decentralized distributed convex optimization},
  author={Gorbunov, Eduard and Rogozin, Alexander and Beznosikov, Aleksandr and Dvinskikh, Darina and Gasnikov, Alexander},
  journal={arXiv:2011.13259},
  year={2020}
}

@article{hendrikx2020optimal,
  title={An optimal algorithm for decentralized finite sum optimization},
  author={Hendrikx, Hadrien and Bach, Francis and Massoulie, Laurent},
  journal={arXiv:2005.10675},
  year={2020}
}

@article{li2020optimal,
  title={Optimal accelerated variance reduced extra and diging for strongly convex and smooth decentralized optimization},
  author={Li, Huan and Lin, Zhouchen and Fang, Yongchun},
  journal={arXiv:2009.04373},
  year={2020}
}


@article{agafonov2021accelerated,
  title={An Accelerated Second-Order Method for Distributed Stochastic Optimization},
  author={Artem Agafonov and Pavel Dvurechensky and Gesualdo Scutari and Alexander Gasnikov and Dmitry Kamzolov and Aleksandr Lukashevich and Amir Daneshmand},
  journal={arXiv:2103.14392},
  year={2021}
}


@article{dvurechensky2021hyperfast,
  title={Hyperfast Second-Order Local Solvers for Efficient Statistically Preconditioned Distributed Optimization},
  author={Pavel Dvurechensky and Dmitry Kamzolov and Aleksandr Lukashevich and Soomin Lee and Erik Ordentlich and C\'esar A. Uribe and Alexander Gasnikov},
  journal={arXiv:2102.08246},
  year={2021}
}