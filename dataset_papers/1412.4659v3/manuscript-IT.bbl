\begin{thebibliography}{10}

\bibitem{qu2014finding}
Q.~Qu, J.~Sun, and J.~Wright, ``Finding a sparse vector in a subspace: Linear
  sparsity using alternating directions,'' in {\em Advances in Neural
  Information Processing Systems}, 2014.

\bibitem{candes2005decoding}
E.~J. Cand\`{e}s and T.~Tao, ``Decoding by linear programming,'' {\em
  Information Theory, IEEE Transactions on}, vol.~51, no.~12, pp.~4203--4215,
  2005.

\bibitem{donoho2006most}
D.~L. Donoho, ``For most large underdetermined systems of linear equations the
  minimal $\ell^1$-norm solution is also the sparsest solution,'' {\em
  Communications on pure and applied mathematics}, vol.~59, no.~6,
  pp.~797--829, 2006.

\bibitem{mccormick1983combinatorial}
S.~T. McCormick, ``A combinatorial approach to some sparse matrix problems.,''
  tech. rep., DTIC Document, 1983.

\bibitem{coleman1986null}
T.~F. Coleman and A.~Pothen, ``The null space problem i. complexity,'' {\em
  SIAM Journal on Algebraic Discrete Methods}, vol.~7, no.~4, pp.~527--537,
  1986.

\bibitem{berry85algorithm}
M.~Berry, M.~Heath, I.~Kaneko, M.~Lawo, R.~Plemmons, and R.~Ward, ``An
  algorithm to compute a sparse basis of the null space,'' {\em Numerische
  Mathematik}, vol.~47, no.~4, pp.~483--504, 1985.

\bibitem{gilbert86computing}
J.~R. Gilbert and M.~T. Heath, ``Computing a sparse basis for the null space,''
  {\em SIAM Journal on Algebraic Discrete Methods}, vol.~8, no.~3,
  pp.~446--459, 1987.

\bibitem{duff86direct}
I.~S. Duff, A.~M. Erisman, and J.~K. Reid, {\em Direct Methods for Sparse
  Matrices}.
\newblock New York, NY, USA: Oxford University Press, Inc., 1986.

\bibitem{Smola00sparsegreedy}
A.~J. Smola and B.~Sch√∂lkopf, ``Sparse greedy matrix approximation for machine
  learning,'' pp.~911--918, Morgan Kaufmann, 2000.

\bibitem{Kavitha04afaster}
T.~Kavitha, K.~Mehlhorn, D.~Michail, and K.~Paluch, ``A faster algorithm for
  minimum cycle basis of graphs,'' in {\em 31st International Colloquium on
  Automata, Languages and Programming}, pp.~846--857, Springer, 2004.

\bibitem{gottlieb2010matrix}
L.-A. Gottlieb and T.~Neylon, ``Matrix sparsification and the sparse null space
  problem,'' in {\em Approximation, Randomization, and Combinatorial
  Optimization. Algorithms and Techniques}, pp.~205--218, Springer, 2010.

\bibitem{mairal2014sparse}
J.~Mairal, F.~Bach, and J.~Ponce, ``Sparse modeling for image and vision
  processing,'' {\em arXiv preprint arXiv:1411.3230}, 2014.

\bibitem{spielman2013exact}
D.~A. Spielman, H.~Wang, and J.~Wright, ``Exact recovery of sparsely-used
  dictionaries,'' in {\em Proceedings of the 25th Annual Conference on Learning
  Theory}, 2012.

\bibitem{hand2013recovering}
P.~Hand and L.~Demanet, ``Recovering the sparsest element in a subspace,'' {\em
  arXiv preprint arXiv:1310.1654}, 2013.

\bibitem{sun2015complete}
J.~Sun, Q.~Qu, and J.~Wright, ``Complete dictionary recovery over the sphere,''
  {\em arXiv preprint arXiv:1504.06785}, 2015.

\bibitem{zou2006sparse}
H.~Zou, T.~Hastie, and R.~Tibshirani, ``Sparse principal component analysis,''
  {\em Journal of computational and graphical statistics}, vol.~15, no.~2,
  pp.~265--286, 2006.

\bibitem{johnstone2009consistency}
I.~M. Johnstone and A.~Y. Lu, ``On consistency and sparsity for principal
  components analysis in high dimensions,'' {\em Journal of the American
  Statistical Association}, vol.~104, no.~486, 2009.

\bibitem{d2007direct}
A.~d'Aspremont, L.~El~Ghaoui, M.~I. Jordan, and G.~R. Lanckriet, ``A direct
  formulation for sparse pca using semidefinite programming,'' {\em SIAM
  review}, vol.~49, no.~3, pp.~434--448, 2007.

\bibitem{krauthgamer2015semidefinite}
R.~Krauthgamer, B.~Nadler, D.~Vilenchik, {\em et~al.}, ``Do semidefinite
  relaxations solve sparse {PCA} up to the information limit?,'' {\em The
  Annals of Statistics}, vol.~43, no.~3, pp.~1300--1322, 2015.

\bibitem{ma2015sum}
T.~Ma and A.~Wigderson, ``Sum-of-squares lower bounds for sparse pca,'' {\em
  arXiv preprint arXiv:1507.06370}, 2015.

\bibitem{vu2013fantope}
V.~Q. Vu, J.~Cho, J.~Lei, and K.~Rohe, ``Fantope projection and selection: A
  near-optimal convex relaxation of sparse pca,'' in {\em Advances in Neural
  Information Processing Systems}, pp.~2670--2678, 2013.

\bibitem{lei2015sparsistency}
J.~Lei, V.~Q. Vu, {\em et~al.}, ``Sparsistency and agnostic inference in sparse
  pca,'' {\em The Annals of Statistics}, vol.~43, no.~1, pp.~299--322, 2015.

\bibitem{wang2014nonconvex}
Z.~Wang, H.~Lu, and H.~Liu, ``Nonconvex statistical optimization:
  Minimax-optimal sparse pca in polynomial time,'' {\em arXiv preprint
  arXiv:1408.5352}, 2014.

\bibitem{Aspremont07sparse}
A.~{d'Aspremont}, L.~{El Ghaoui}, M.~Jordan, and G.~Lanckriet, ``A direct
  formulation of sparse {PCA} using semidefinite programming,'' {\em SIAM
  Review}, vol.~49, no.~3, 2007.

\bibitem{zhao2013rank}
Y.-B. Zhao and M.~Fukushima, ``Rank-one solutions for homogeneous linear matrix
  equations over the positive semidefinite cone,'' {\em Applied Mathematics and
  Computation}, vol.~219, no.~10, pp.~5569--5583, 2013.

\bibitem{dai2012simple}
Y.~Dai, H.~Li, and M.~He, ``A simple prior-free method for non-rigid
  structure-from-motion factorization,'' in {\em Computer Vision and Pattern
  Recognition (CVPR), 2012 IEEE Conference on}, pp.~2018--2025, IEEE, 2012.

\bibitem{beylkin2005approximation}
G.~Beylkin and L.~Monz{\'o}n, ``On approximation of functions by exponential
  sums,'' {\em Applied and Computational Harmonic Analysis}, vol.~19, no.~1,
  pp.~17--48, 2005.

\bibitem{manolis2015dualPCA}
C.~T. Manolis and V.~Rene, ``Dual principal component pursuit,'' {\em arXiv
  preprint arXiv:1510.04390}, 2015.

\bibitem{zibulevsky2001blind}
M.~Zibulevsky and B.~A. Pearlmutter, ``Blind source separation by sparse
  decomposition in a signal dictionary,'' {\em Neural computation}, vol.~13,
  no.~4, pp.~863--882, 2001.

\bibitem{anandkumar2013overcomplete}
A.~Anandkumar, D.~Hsu, M.~Janzamin, and S.~M. Kakade, ``When are overcomplete
  topic models identifiable? uniqueness of tensor tucker decompositions with
  structured sparsity,'' in {\em Advances in Neural Information Processing
  Systems}, pp.~1986--1994, 2013.

\bibitem{ho2013nonlinear}
J.~Ho, Y.~Xie, and B.~Vemuri, ``On a nonlinear generalization of sparse coding
  and dictionary learning,'' in {\em Proceedings of The 30th International
  Conference on Machine Learning}, pp.~1480--1488, 2013.

\bibitem{nakatsukasa15finding}
Y.~Nakatsukasa, T.~Soma, and A.~Uschmajew, ``Finding a low-rank basis in a
  matrix subspace,'' {\em CoRR}, vol.~abs/1503.08601, 2015.

\bibitem{berthet2013complexity}
Q.~Berthet and P.~Rigollet, ``Complexity theoretic lower bounds for sparse
  principal component detection,'' in {\em Conference on Learning Theory},
  pp.~1046--1066, 2013.

\bibitem{barak2013rounding}
B.~Barak, J.~Kelner, and D.~Steurer, ``Rounding sum-of-squares relaxations,''
  {\em arXiv preprint arXiv:1312.6652}, 2013.

\bibitem{hopkins2015speeding}
S.~B. Hopkins, T.~Schramm, J.~Shi, and D.~Steurer, ``Speeding up sum-of-squares
  for tensor decomposition and planted sparse vectors,'' {\em arXiv preprint
  arXiv:1512.02337}, 2015.

\bibitem{arora2013new}
S.~Arora, R.~Ge, and A.~Moitra, ``New algorithms for learning incoherent and
  overcomplete dictionaries,'' {\em arXiv preprint arXiv:1308.6273}, 2013.

\bibitem{agarwal2013exact}
A.~Agarwal, A.~Anandkumar, and P.~Netrapalli, ``Exact recovery of sparsely used
  overcomplete dictionaries,'' {\em arXiv preprint arXiv:1309.1952}, 2013.

\bibitem{agarwal2013learning}
A.~Agarwal, A.~Anandkumar, P.~Jain, P.~Netrapalli, and R.~Tandon, ``Learning
  sparsely used overcomplete dictionaries via alternating minimization,'' {\em
  arXiv preprint arXiv:1310.7991}, 2013.

\bibitem{arora2014more}
S.~Arora, A.~Bhaskara, R.~Ge, and T.~Ma, ``More algorithms for provable
  dictionary learning,'' {\em arXiv preprint arXiv:1401.0579}, 2014.

\bibitem{arora2015simple}
S.~Arora, R.~Ge, T.~Ma, and A.~Moitra, ``Simple, efficient, and neural
  algorithms for sparse coding,'' {\em arXiv preprint arXiv:1503.00778}, 2015.

\bibitem{murty1987some}
K.~G. Murty and S.~N. Kabadi, ``Some {NP}-complete problems in quadratic and
  nonlinear programming,'' {\em Mathematical programming}, vol.~39, no.~2,
  pp.~117--129, 1987.

\bibitem{veryshynin2011matrix}
R.~Vershynin, ``Introduction to the non-asymptotic analysis of random
  matrices,'' {\em arXiv preprint arXiv:1011.3027}, 2010.

\bibitem{basri2003lambertian}
R.~Basri and D.~W. Jacobs, ``Lambertian reflectance and linear subspaces,''
  {\em Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  vol.~25, no.~2, pp.~218--233, 2003.

\bibitem{Candes2011-JACM}
E.~Cand\`{e}s, X.~Li, Y.~Ma, and J.~Wright, ``Robust principal component
  analysis?,'' {\em Journal of the {ACM}}, vol.~58, May 2011.

\bibitem{de1999decoupling}
V.~De~la Pena and E.~Gin{\'e}, {\em Decoupling: from dependence to
  independence}.
\newblock Springer, 1999.

\bibitem{talagrand2014upper}
M.~Talagrand, {\em Upper and Lower Bounds for Stochastic Processes: Modern
  Methods and Classical Problems}, vol.~60.
\newblock Springer Science \& Business Media, 2014.

\bibitem{luh15dictionary}
K.~Luh and V.~Vu, ``Dictionary learning with few samples and matrix
  concentration,'' {\em arXiv preprint arXiv:1503.08854}, 2015.

\bibitem{jain2013low}
P.~Jain, P.~Netrapalli, and S.~Sanghavi, ``Low-rank matrix completion using
  alternating minimization,'' in {\em Proceedings of the 45th annual ACM
  symposium on Symposium on theory of computing}, pp.~665--674, ACM, 2013.

\bibitem{hardt2013provable}
M.~Hardt, ``On the provable convergence of alternating minimization for matrix
  completion,'' {\em arXiv preprint arXiv:1312.0925}, 2013.

\bibitem{hardt2014fast}
M.~Hardt and M.~Wootters, ``Fast matrix completion without the condition
  number,'' in {\em Proceedings of The 27th Conference on Learning Theory},
  pp.~638--678, 2014.

\bibitem{hardt2014understanding}
M.~Hardt, ``Understanding alternating minimization for matrix completion,'' in
  {\em Foundations of Computer Science (FOCS), 2014 IEEE 55th Annual Symposium
  on}, pp.~651--660, IEEE, 2014.

\bibitem{jain2014fast}
P.~Jain and P.~Netrapalli, ``Fast exact matrix completion with finite
  samples,'' {\em arXiv preprint arXiv:1411.1087}, 2014.

\bibitem{netrapalli2014non}
P.~Netrapalli, U.~Niranjan, S.~Sanghavi, A.~Anandkumar, and P.~Jain,
  ``Non-convex robust pca,'' in {\em Advances in Neural Information Processing
  Systems}, pp.~1107--1115, 2014.

\bibitem{zheng2015convergent}
Q.~Zheng and J.~Lafferty, ``A convergent gradient descent algorithm for rank
  minimization and semidefinite programming from random linear measurements,''
  {\em arXiv preprint arXiv:1506.06081}, 2015.

\bibitem{tu2015low}
S.~Tu, R.~Boczar, M.~Soltanolkotabi, and B.~Recht, ``Low-rank solutions of
  linear matrix equations via procrustes flow,'' {\em arXiv preprint
  arXiv:1507.03566}, 2015.

\bibitem{chen2015fast}
Y.~Chen and M.~J. Wainwright, ``Fast low-rank estimation by projected gradient
  descent: General statistical and algorithmic guarantees,'' {\em arXiv
  preprint arXiv:1509.03025}, 2015.

\bibitem{jain2014provable}
P.~Jain and S.~Oh, ``Provable tensor factorization with missing data,'' in {\em
  Advances in Neural Information Processing Systems}, pp.~1431--1439, 2014.

\bibitem{anandkumar2014guaranteed}
A.~Anandkumar, R.~Ge, and M.~Janzamin, ``Guaranteed non-orthogonal tensor
  decomposition via alternating rank-1 updates,'' {\em arXiv preprint
  arXiv:1402.5180}, 2014.

\bibitem{anandkumar2014analyzing}
A.~Anandkumar, R.~Ge, and M.~Janzamin, ``Analyzing tensor power method
  dynamics: Applications to learning overcomplete latent variable models,''
  {\em arXiv preprint arXiv:1411.1488}, 2014.

\bibitem{anandkumar2015tensor}
A.~Anandkumar, P.~Jain, Y.~Shi, and U.~Niranjan, ``Tensor vs matrix methods:
  Robust tensor decomposition under block sparse perturbations,'' {\em arXiv
  preprint arXiv:1510.04747}, 2015.

\bibitem{ge2015escaping}
R.~Ge, F.~Huang, C.~Jin, and Y.~Yuan, ``Escaping from saddle points---online
  stochastic gradient for tensor decomposition,'' in {\em Proceedings of The
  28th Conference on Learning Theory}, pp.~797--842, 2015.

\bibitem{netrapalli2013phase}
P.~Netrapalli, P.~Jain, and S.~Sanghavi, ``Phase retrieval using alternating
  minimization,'' in {\em Advances in Neural Information Processing Systems},
  pp.~2796--2804, 2013.

\bibitem{candes2014wirtinger}
E.~J. Cand{\`{e}}s, X.~Li, and M.~Soltanolkotabi, ``Phase retrieval via
  wirtinger flow: Theory and algorithms,'' {\em arXiv preprint
  arXiv:1407.1065}, 2014.

\bibitem{chen2015solving}
Y.~Chen and E.~J. Candes, ``Solving random quadratic systems of equations is
  nearly as easy as solving linear systems,'' {\em arXiv preprint
  arXiv:1505.05114}, 2015.

\bibitem{sun2016geometric}
J.~Sun, Q.~Qu, and J.~Wright, ``A geometric analysis of phase retreival,'' {\em
  arXiv preprint arXiv:1602.06664}, 2016.

\bibitem{sun2015nonconvex}
J.~Sun, Q.~Qu, and J.~Wright, ``When are nonconvex problems not scary?,'' {\em
  arXiv preprint arXiv:1510.06096}, 2015.

\bibitem{foucart2013mathematical}
S.~Foucart and H.~Rauhut, {\em A Mathematical Introduction to Compressive
  Sensing}.
\newblock Springer, 2013.

\bibitem{figiel1977dimension}
T.~Figiel, J.~Lindenstrauss, and V.~D. Milman, ``The dimension of almost
  spherical sections of convex bodies,'' {\em Acta Mathematica}, vol.~139,
  no.~1, pp.~53--94, 1977.

\bibitem{garnaev1984widths}
A.~Y. Garnaev and E.~D. Gluskin, ``The widths of a euclidean ball,'' in {\em
  Dokl. Akad. Nauk SSSR}, vol.~277, pp.~1048--1052, 1984.

\bibitem{gluskin2003note}
E.~Gluskin and V.~Milman, ``Note on the geometric-arithmetic mean inequality,''
  in {\em Geometric aspects of Functional analysis}, pp.~131--135, Springer,
  2003.

\bibitem{pisier1999volume}
G.~Pisier, {\em The volume of convex bodies and Banach space geometry},
  vol.~94.
\newblock Cambridge University Press, 1999.

\end{thebibliography}
