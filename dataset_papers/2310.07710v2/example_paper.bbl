\begin{thebibliography}{44}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aaronson(2022)]{Aaronson2022}
Aaronson, S.
\newblock My {AI} safety lecture for {UT} effective altruism,.
\newblock 2022.
\newblock URL \url{https://scottaaronson.blog/?p=6823}.

\bibitem[Abdelnabi \& Fritz(2021)Abdelnabi and Fritz]{abdelnabi2021adversarial}
Abdelnabi, S. and Fritz, M.
\newblock Adversarial watermarking transformer: Towards tracing text provenance with data hiding.
\newblock In \emph{2021 IEEE Symposium on Security and Privacy (SP)}, pp.\  121--140. IEEE, 2021.

\bibitem[Cai et~al.(2022)Cai, Li, Wen, and Yang]{cai2022asset}
Cai, Z., Li, C., Wen, J., and Yang, S.
\newblock Asset splitting algorithm for ultrahigh dimensional portfolio selection and its theoretical property.
\newblock \emph{Journal of Econometrics}, pp.\  105291, 2022.

\bibitem[Chakraborty et~al.(2022)Chakraborty, Calo, and Wen]{chakraborty2022using}
Chakraborty, S., Calo, S.~B., and Wen, J.
\newblock Using disentangled learning to train an interpretable deep learning model, June~23 2022.
\newblock US Patent App. 17/133,437.

\bibitem[Chakraborty et~al.(2023)Chakraborty, Bedi, Zhu, An, Manocha, and Huang]{chakraborty2023possibilities}
Chakraborty, S., Bedi, A.~S., Zhu, S., An, B., Manocha, D., and Huang, F.
\newblock On the possibilities of {AI}-generated text detection.
\newblock \emph{arXiv preprint arXiv:2304.04736}, 2023.

\bibitem[Chen et~al.(2024)Chen, Wu, Chen, Liu, He, Xiong, Liu, Guo, and Huang]{chen2024your}
Chen, R., Wu, Y., Chen, L., Liu, G., He, Q., Xiong, T., Liu, C., Guo, J., and Huang, H.
\newblock Your vision-language model itself is a strong filter: Towards high-quality instruction tuning with data selection.
\newblock \emph{arXiv preprint arXiv:2402.12501}, 2024.

\bibitem[Christ et~al.(2023)Christ, Gunn, and Zamir]{christ2023undetectable}
Christ, M., Gunn, S., and Zamir, O.
\newblock Undetectable watermarks for language models.
\newblock \emph{arXiv preprint arXiv:2306.09194}, 2023.

\bibitem[Dedi{\'c} et~al.(2009)Dedi{\'c}, Itkis, Reyzin, and Russell]{dedic2009upper}
Dedi{\'c}, N., Itkis, G., Reyzin, L., and Russell, S.
\newblock Upper and lower bounds on black-box steganography.
\newblock \emph{Journal of Cryptology}, 22:\penalty0 365--394, 2009.

\bibitem[Feng et~al.(2018)Feng, Li, and Li]{feng2018indexing}
Feng, C., Li, C.-D., and Li, R.
\newblock Indexing techniques of distributed ordered tables: A survey and analysis.
\newblock \emph{Journal of Computer Science and Technology}, 33:\penalty0 169--189, 2018.

\bibitem[Gambini et~al.(2022)Gambini, Fagni, Falchi, and Tesconi]{gambini2022pushing}
Gambini, M., Fagni, T., Falchi, F., and Tesconi, M.
\newblock On pushing {DeepFake Tweet} detection capabilities to the limits.
\newblock In \emph{Proceedings of the 14th ACM Web Science Conference 2022}, pp.\  154--163, 2022.

\bibitem[Google(2023)]{palm2}
Google.
\newblock Palm-2-llm.
\newblock \emph{https://blog.google/technology/ai/google-palm-2-ai-large-language-model/}, 2023.

\bibitem[Hermann et~al.(2015)Hermann, Kocisky, Grefenstette, Espeholt, Kay, Suleyman, and Blunsom]{hermann2015teaching}
Hermann, K.~M., Kocisky, T., Grefenstette, E., Espeholt, L., Kay, W., Suleyman, M., and Blunsom, P.
\newblock Teaching machines to read and comprehend.
\newblock \emph{Advances in neural information processing systems}, 28, 2015.

\bibitem[Hong et~al.(2024)Hong, Wang, Shen, Yao, Huang, Chen, Yang, Gong, and Liu]{hong2024improving}
Hong, Z., Wang, Z., Shen, L., Yao, Y., Huang, Z., Chen, S., Yang, C., Gong, M., and Liu, T.
\newblock Improving non-transferable representation learning by harnessing content and style.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.

\bibitem[Hopper et~al.(2002)Hopper, Langford, and Von~Ahn]{hopper2002provably}
Hopper, N.~J., Langford, J., and Von~Ahn, L.
\newblock Provably secure steganography.
\newblock In \emph{Advances in Cryptologyâ€”CRYPTO 2002: 22nd Annual International Cryptology Conference Santa Barbara, California, USA, August 18--22, 2002 Proceedings 22}, pp.\  77--92. Springer, 2002.

\bibitem[Hu et~al.(2023{\natexlab{a}})Hu, Chen, Wu, Wu, Zhang, and Huang]{hu2023unbiased}
Hu, Z., Chen, L., Wu, X., Wu, Y., Zhang, H., and Huang, H.
\newblock Unbiased watermark for large language models.
\newblock \emph{arXiv preprint arXiv:2310.10669}, 2023{\natexlab{a}}.

\bibitem[Hu et~al.(2023{\natexlab{b}})Hu, Shen, Wang, Wu, Yuan, and Tao]{pmlr-v202-hu23g}
Hu, Z., Shen, L., Wang, Z., Wu, B., Yuan, C., and Tao, D.
\newblock Learning to learn from {API}s: Black-box data-free meta-learning.
\newblock In \emph{Proceedings of the 40th International Conference on Machine Learning}, pp.\  13610--13627. PMLR, 2023{\natexlab{b}}.

\bibitem[Kaptchuk et~al.(2021)Kaptchuk, Jois, Green, and Rubin]{kaptchuk2021meteor}
Kaptchuk, G., Jois, T.~M., Green, M., and Rubin, A.~D.
\newblock Meteor: Cryptographically secure steganography for realistic distributions.
\newblock In \emph{Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security}, pp.\  1529--1548, 2021.

\bibitem[Kirchenbauer et~al.(2023)Kirchenbauer, Geiping, Wen, Katz, Miers, and Goldstein]{kirchenbauer2023watermark}
Kirchenbauer, J., Geiping, J., Wen, Y., Katz, J., Miers, I., and Goldstein, T.
\newblock A watermark for large language models.
\newblock \emph{arXiv preprint arXiv:2301.10226}, 2023.

\bibitem[Kirchner et~al.(2023)Kirchner, Ahmad, Aaronson, and Leike]{kirchner2023new}
Kirchner, J.~H., Ahmad, L., Aaronson, S., and Leike, J.
\newblock New {AI} classifier for indicating {AI}-written text.
\newblock \emph{OpenAI}, 2023.

\bibitem[Krishna et~al.(2023)Krishna, Song, Karpinska, Wieting, and Iyyer]{krishna2023paraphrasing}
Krishna, K., Song, Y., Karpinska, M., Wieting, J., and Iyyer, M.
\newblock Paraphrasing evades detectors of {AI}-generated text, but retrieval is an effective defense.
\newblock \emph{arXiv preprint arXiv:2303.13408}, 2023.

\bibitem[Kuditipudi et~al.(2023)Kuditipudi, Thickstun, Hashimoto, and Liang]{kuditipudi2023robust}
Kuditipudi, R., Thickstun, J., Hashimoto, T., and Liang, P.
\newblock Robust distortion-free watermarks for language models.
\newblock \emph{arXiv preprint arXiv:2307.15593}, 2023.

\bibitem[Lin(2004)]{lin2004rouge}
Lin, C.-Y.
\newblock Rouge: A package for automatic evaluation of summaries.
\newblock In \emph{Text summarization branches out}, pp.\  74--81, 2004.

\bibitem[Liu et~al.(2020)Liu, Gu, Goyal, Li, Edunov, Ghazvininejad, Lewis, and Zettlemoyer]{liu2020multilingual}
Liu, Y., Gu, J., Goyal, N., Li, X., Edunov, S., Ghazvininejad, M., Lewis, M., and Zettlemoyer, L.
\newblock Multilingual denoising pre-training for neural machine translation.
\newblock \emph{Transactions of the Association for Computational Linguistics}, 8:\penalty0 726--742, 2020.

\bibitem[Mitchell et~al.(2023)Mitchell, Lee, Khazatsky, Manning, and Finn]{mitchell2023detectgpt}
Mitchell, E., Lee, Y., Khazatsky, A., Manning, C.~D., and Finn, C.
\newblock Detectgpt: Zero-shot machine-generated text detection using probability curvature.
\newblock \emph{arXiv preprint arXiv:2301.11305}, 2023.

\bibitem[Munyer \& Zhong(2023)Munyer and Zhong]{munyer2023deeptextmark}
Munyer, T. and Zhong, X.
\newblock Deeptextmark: Deep learning based text watermarking for detection of large language model generated text.
\newblock \emph{arXiv preprint arXiv:2305.05773}, 2023.

\bibitem[OpenAI(2023)]{openai2023gpt}
OpenAI, R.
\newblock Gpt-4 technical report.
\newblock \emph{arXiv}, pp.\  2303--08774, 2023.

\bibitem[Papineni et~al.(2002)Papineni, Roukos, Ward, and Zhu]{papineni2002bleu}
Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock In \emph{Proceedings of the 40th annual meeting of the Association for Computational Linguistics}, pp.\  311--318, 2002.

\bibitem[Qiang et~al.(2023)Qiang, Zhu, Li, Zhu, Yuan, and Wu]{qiang2023natural}
Qiang, J., Zhu, S., Li, Y., Zhu, Y., Yuan, Y., and Wu, X.
\newblock Natural language watermarking via paraphraser-based lexical substitution.
\newblock \emph{Artificial Intelligence}, 317:\penalty0 103859, 2023.

\bibitem[Tay et~al.(2020)Tay, Bahri, Zheng, Brunk, Metzler, and Tomkins]{tay2020reverse}
Tay, Y., Bahri, D., Zheng, C., Brunk, C., Metzler, D., and Tomkins, A.
\newblock Reverse engineering configurations of neural text generation models.
\newblock \emph{arXiv preprint arXiv:2004.06201}, 2020.

\bibitem[Tian(2023)]{tian2023gptzero}
Tian, E.
\newblock {GPTzero} update v1.
\newblock \emph{https://gptzero.substack.com/p/ gptzero-update-v1}, 2023.

\bibitem[Touvron et~al.(2023)Touvron, Martin, Stone, Albert, Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, et~al.]{touvron2023llama2}
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv preprint arXiv:2307.09288}, 2023.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Shen, Duan, Suo, Fang, Liu, and Gao]{wang2023distributionally}
Wang, Z., Shen, L., Duan, T., Suo, Q., Fang, L., Liu, W., and Gao, M.
\newblock Distributionally robust memory evolution with generalized divergence for continual learning.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2023{\natexlab{a}}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Shen, Liu, Duan, Zhu, Zhan, Doermann, and Gao]{wang2023defending}
Wang, Z., Shen, L., Liu, T., Duan, T., Zhu, Y., Zhan, D., Doermann, D., and Gao, M.
\newblock Defending against data-free model extraction by distributionally robust defensive training.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023{\natexlab{b}}.

\bibitem[Wen et~al.(2023)Wen, Yang, Wang, Jiang, and Li]{wen2023feature}
Wen, J., Yang, S., Wang, C.~D., Jiang, Y., and Li, R.
\newblock Feature-splitting algorithms for ultrahigh dimensional quantile regression.
\newblock \emph{Journal of Econometrics}, pp.\  105426, 2023.

\bibitem[Wolf et~al.(2019)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac, Rault, Louf, Funtowicz, et~al.]{wolf2019huggingface}
Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Rault, T., Louf, R., Funtowicz, M., et~al.
\newblock Huggingface's transformers: State-of-the-art natural language processing.
\newblock \emph{arXiv preprint arXiv:1910.03771}, 2019.

\bibitem[Wu et~al.(2022)Wu, Zhang, and Huang]{wu2022retrievalguard}
Wu, Y., Zhang, H., and Huang, H.
\newblock Retrievalguard: Provably robust 1-nearest neighbor image retrieval.
\newblock In \emph{International Conference on Machine Learning}, pp.\  24266--24279. PMLR, 2022.

\bibitem[Wu et~al.(2023)Wu, Huang, and Zhang]{wu2023law}
Wu, Y., Huang, H., and Zhang, H.
\newblock A law of robustness beyond isoperimetry.
\newblock In \emph{International Conference on Machine Learning}, pp.\  37439--37455. PMLR, 2023.

\bibitem[Xu \& Li(2017)Xu and Li]{xu2017low}
Xu, Z. and Li, C.
\newblock Low-entropy cloud computing systems.
\newblock \emph{Scientia Sinica Informationis}, 47\penalty0 (9):\penalty0 1149--1163, 2017.

\bibitem[Yang et~al.(2019)Yang, Wen, Zhan, and Kifer]{yang2019lasso}
Yang, S., Wen, J., Zhan, X., and Kifer, D.
\newblock Et-lasso: a new efficient tuning of lasso-type regularization for high-dimensional data.
\newblock In \emph{Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery \& data mining}, pp.\  607--616, 2019.

\bibitem[Yang et~al.(2020)Yang, Wen, Eckert, Wang, Liu, Wu, Li, and Zhan]{yang2020prioritizing}
Yang, S., Wen, J., Eckert, S.~T., Wang, Y., Liu, D.~J., Wu, R., Li, R., and Zhan, X.
\newblock Prioritizing genetic variants in gwas with lasso using permutation-assisted tuning.
\newblock \emph{Bioinformatics}, 36\penalty0 (12):\penalty0 3811--3817, 2020.

\bibitem[Yoo et~al.(2023)Yoo, Ahn, Jang, and Kwak]{yoo2023robust}
Yoo, K., Ahn, W., Jang, J., and Kwak, N.
\newblock Robust natural language watermarking through invariant features.
\newblock \emph{arXiv preprint arXiv:2305.01904}, 2023.

\bibitem[Zellers et~al.(2019)Zellers, Holtzman, Rashkin, Bisk, Farhadi, Roesner, and Choi]{zellers2019defending}
Zellers, R., Holtzman, A., Rashkin, H., Bisk, Y., Farhadi, A., Roesner, F., and Choi, Y.
\newblock Defending against neural fake news.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Zhang et~al.(2019)Zhang, Kishore, Wu, Weinberger, and Artzi]{zhang2019bertscore}
Zhang, T., Kishore, V., Wu, F., Weinberger, K.~Q., and Artzi, Y.
\newblock Bertscore: Evaluating text generation with bert.
\newblock \emph{arXiv preprint arXiv:1904.09675}, 2019.

\bibitem[Zhao et~al.(2023)Zhao, Ananth, Li, and Wang]{zhao2023provable}
Zhao, X., Ananth, P., Li, L., and Wang, Y.-X.
\newblock Provable robust watermarking for ai-generated text.
\newblock \emph{arXiv preprint arXiv:2306.17439}, 2023.

\end{thebibliography}
