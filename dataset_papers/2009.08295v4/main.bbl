\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bagnall et~al.(2017)Bagnall, Lines, Bostrom, Large, and
  Keogh]{bagnall16bakeoff}
Bagnall, A., Lines, J., Bostrom, A., Large, J., and Keogh, E.
\newblock The great time series classification bake off: a review and
  experimental evaluation of recent algorithmic advances.
\newblock \emph{Data Mining and Knowledge Discovery}, 31:\penalty0 606--660,
  2017.

\bibitem[Bai et~al.(2018)Bai, Kolter, and Koltun]{bai2018empirical}
Bai, S., Kolter, J.~Z., and Koltun, V.
\newblock An empirical evaluation of generic convolutional and recurrent
  networks for sequence modeling.
\newblock \emph{arXiv preprint arXiv:1803.01271}, 2018.

\bibitem[Blanes et~al.(2009)Blanes, Casas, Oteo, and Ros]{magnus2008expansion}
Blanes, S., Casas, F., Oteo, J.-A., and Ros, J.
\newblock {The Magnus expansion and some of its applications}.
\newblock \emph{Physics Reports}, 470\penalty0 (5-6):\penalty0 151--238, 2009.

\bibitem[Boutaib et~al.(2014)Boutaib, Gyurk\'{o}, Lyons, and
  Yang]{logode2014estimate}
Boutaib, Y., Gyurk\'{o}, L.~G., Lyons, T., and Yang, D.
\newblock {Dimension-free Euler estimates of rough differential equations}.
\newblock \emph{Revue Roumaine de Mathmatiques Pures et Appliques}, 59, 2014.

\bibitem[Campos et~al.(2017)Campos, Jou, Gir{\'o}-i Nieto, Torres, and
  Chang]{campos2017skip}
Campos, V., Jou, B., Gir{\'o}-i Nieto, X., Torres, J., and Chang, S.-F.
\newblock {Skip RNN: Learning to Skip State Updates in Recurrent Neural
  Networks}.
\newblock \emph{arXiv preprint arXiv:1708.06834}, 2017.

\bibitem[Chang et~al.(2017)Chang, Zhang, Han, Yu, Guo, Tan, Cui, Witbrock,
  Hasegawa-Johnson, and Huang]{chang2017dilated}
Chang, S., Zhang, Y., Han, W., Yu, M., Guo, X., Tan, W., Cui, X., Witbrock, M.,
  Hasegawa-Johnson, M.~A., and Huang, T.~S.
\newblock Dilated recurrent neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  77--87, 2017.

\bibitem[Chen(2018)]{torchdiffeq}
Chen, R. T.~Q.
\newblock \texttt{torchdiffeq}, 2018.
\newblock \url{https://github.com/rtqichen/torchdiffeq}.

\bibitem[Chen et~al.(2018)Chen, Rubanova, Bettencourt, and
  Duvenaud]{neural2018ode}
Chen, R. T.~Q., Rubanova, Y., Bettencourt, J., and Duvenaud, D.
\newblock {Neural Ordinary Differential Equations}.
\newblock \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[De~Brouwer et~al.(2019)De~Brouwer, Simm, Arany, and Moreau]{de2019gru}
De~Brouwer, E., Simm, J., Arany, A., and Moreau, Y.
\newblock Gru-ode-bayes: Continuous modeling of sporadically-observed time
  series.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  7379--7390, 2019.

\bibitem[De~Mulder et~al.(2015)De~Mulder, Bethard, and Moens]{de2015survey}
De~Mulder, W., Bethard, S., and Moens, M.-F.
\newblock A survey on the application of recurrent neural networks to
  statistical language modeling.
\newblock \emph{Computer Speech \& Language}, 30\penalty0 (1):\penalty0 61--98,
  2015.

\bibitem[Foster et~al.(2020)Foster, Lyons, and Oberhauser]{foster2020poly}
Foster, J., Lyons, T., and Oberhauser, H.
\newblock {An optimal polynomial approximation of Brownian motion}.
\newblock \emph{SIAM Journal on Numerical Analysis}, 58\penalty0 (3):\penalty0
  1393--1421, 2020.

\bibitem[Friz \& Victoir(2010)Friz and Victoir]{friz2010multidimensional}
Friz, P.~K. and Victoir, N.~B.
\newblock \emph{Multidimensional stochastic processes as rough paths: theory
  and applications}, volume 120.
\newblock Cambridge University Press, 2010.

\bibitem[Graves(2012)]{graves2012supervised}
Graves, A.
\newblock Supervised sequence labelling.
\newblock In \emph{Supervised sequence labelling with recurrent neural
  networks}, pp.\  5--13. Springer, 2012.

\bibitem[Gu et~al.(2020)Gu, Dao, Ermon, Rudra, and Re]{hippo}
Gu, A., Dao, T., Ermon, S., Rudra, A., and Re, C.
\newblock {HiPPO: Recurrent Memory with Optimal Polynomial Projections}.
\newblock \emph{arXiv:2008.07669}, 2020.

\bibitem[Gyurk\'{o}(2008)]{gyurko2008thesis}
Gyurk\'{o}, L.~G.
\newblock \emph{Numerical methods for approximating solutions to rough
  differential equations}.
\newblock DPhil thesis, University of Oxford, 2008.

\bibitem[Hambly \& Lyons(2010)Hambly and Lyons]{hambly2010sigunique}
Hambly, B. and Lyons, T.
\newblock Uniqueness for the signature of a path of bounded variation and the
  reduced path group.
\newblock \emph{Annals of Mathematics}, 171, 2010.

\bibitem[Jing et~al.(2019)Jing, Gulcehre, Peurifoy, Shen, Tegmark, Soljacic,
  and Bengio]{jing2019gated}
Jing, L., Gulcehre, C., Peurifoy, J., Shen, Y., Tegmark, M., Soljacic, M., and
  Bengio, Y.
\newblock Gated orthogonal recurrent units: On learning to forget.
\newblock \emph{Neural computation}, 31\penalty0 (4):\penalty0 765--783, 2019.

\bibitem[Kidger \& Lyons(2020{\natexlab{a}})Kidger and Lyons]{deepandnarrow}
Kidger, P. and Lyons, T.
\newblock {Universal Approximation with Deep Narrow Networks}.
\newblock \emph{COLT 2020}, 2020{\natexlab{a}}.

\bibitem[Kidger \& Lyons(2020{\natexlab{b}})Kidger and Lyons]{signatory}
Kidger, P. and Lyons, T.
\newblock {Signatory: differentiable computations of the signature and
  logsignature transforms, on both CPU and GPU}.
\newblock \emph{arXiv:2001.00706}, 2020{\natexlab{b}}.
\newblock URL \url{https://github.com/patrick-kidger/signatory}.

\bibitem[Kidger et~al.(2020)Kidger, Morrill, Foster, and
  Lyons]{kidger2020neural}
Kidger, P., Morrill, J., Foster, J., and Lyons, T.
\newblock Neural controlled differential equations for irregular time series.
\newblock \emph{arXiv preprint arXiv:2005.08926}, 2020.

\bibitem[Lechner \& Hasani(2020)Lechner and Hasani]{lechner2020learning}
Lechner, M. and Hasani, R.
\newblock Learning long-term dependencies in irregularly-sampled time series.
\newblock \emph{arXiv preprint arXiv:2006.04418}, 2020.

\bibitem[Li et~al.(2018)Li, Li, Cook, Zhu, and Gao]{li2018independently}
Li, S., Li, W., Cook, C., Zhu, C., and Gao, Y.
\newblock Independently recurrent neural network (indrnn): Building a longer
  and deeper rnn.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  5457--5466, 2018.

\bibitem[Li et~al.(2019)Li, Jin, Xuan, Zhou, Chen, Wang, and
  Yan]{li2019enhancing}
Li, S., Jin, X., Xuan, Y., Zhou, X., Chen, W., Wang, Y.-X., and Yan, X.
\newblock Enhancing the locality and breaking the memory bottleneck of
  transformer on time series forecasting.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  5243--5253, 2019.

\bibitem[Liao et~al.(2019)Liao, Lyons, Yang, and Ni]{liao2019learning}
Liao, S., Lyons, T., Yang, W., and Ni, H.
\newblock {Learning stochastic differential equations using RNN with log
  signature features}.
\newblock \emph{arXiv preprint arXiv:1908.08286}, 2019.

\bibitem[Lyons(2014)]{lyons2014streams}
Lyons, T.
\newblock Rough paths, signatures and the modelling of functions on streams.
\newblock \emph{Proceedings of the International Congress of Mathematicians},
  4, 2014.

\bibitem[Lyons et~al.(2007)Lyons, Michael, and Thierry]{roughpath2007notes}
Lyons, T., Michael, C., and Thierry, L.
\newblock \emph{Differential equations driven by rough paths}.
\newblock In \'{E}cole d’\'{e}t\'{e} de probabilit\'{e}s de Saint-Flour
  XXXIV-2004, edited by J. Picard in Volume 1908 of Lecture Notes in
  Mathematics, Berlin, Springer, 2007.

\bibitem[Lyons(1998)]{lyons1998differential}
Lyons, T.~J.
\newblock Differential equations driven by rough signals.
\newblock \emph{Revista Matem{\'a}tica Iberoamericana}, 14\penalty0
  (2):\penalty0 215--310, 1998.

\bibitem[Lyons et~al.(2004)Lyons, Caruana, L{\'e}vy, and
  Picard]{lyons2004differential}
Lyons, T.~J., Caruana, M., L{\'e}vy, T., and Picard, J.
\newblock Differential equations driven by rough paths.
\newblock \emph{Ecole d’{\'e}t{\'e} de Probabilit{\'e}s de Saint-Flour},
  34:\penalty0 1--93, 2004.

\bibitem[Pinkus(1999)]{pinkus}
Pinkus, A.
\newblock Approximation theory of the {MLP} model in neural networks.
\newblock \emph{Acta Numer.}, 8:\penalty0 143--195, 1999.

\bibitem[Reizenstein(2017)]{reizenstein2017logsig}
Reizenstein, J.
\newblock {Calculation of Iterated-Integral Signatures and Log Signatures}.
\newblock \emph{arXiv preprint arXiv:1712.02757}, 2017.

\bibitem[Rubanova et~al.(2019)Rubanova, Chen, and Duvenaud]{rubanova2019latent}
Rubanova, Y., Chen, R.~T., and Duvenaud, D.
\newblock Latent odes for irregularly-sampled time series.
\newblock \emph{arXiv preprint arXiv:1907.03907}, 2019.

\bibitem[Ryan(2002)]{tensorproducts2002book}
Ryan, R.~A.
\newblock \emph{{Introduction to Tensor Products of Banach Spaces}}.
\newblock Springer Monographs in Mathematics, Springer, 2002.

\bibitem[Sourkov(2018)]{sourkov2018igloo}
Sourkov, V.
\newblock Igloo: Slicing the features space to represent sequences.
\newblock \emph{arXiv preprint arXiv:1807.03402}, 2018.

\bibitem[Tan et~al.(2020)Tan, Bagnall, Bergmeir, Keogh, Petitjean, and
  Webb]{MonashTSRegressionArchive}
Tan, C.~W., Bagnall, A., Bergmeir, C., Keogh, E., Petitjean, F., and Webb,
  G.~I.
\newblock Monash university, uea, ucr time series regression archive, 2020.
\newblock \url{http://timeseriesregression.org/}.

\bibitem[Voelker et~al.(2019)Voelker, Kaji\'{c}, and Eliasmith]{lmu}
Voelker, A., Kaji\'{c}, I., and Eliasmith, C.
\newblock Legendre memory units: Continuous-time representation in recurrent
  neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems 32}.
  Curran Associates, Inc., 2019.

\bibitem[Wisdom et~al.(2016)Wisdom, Powers, Hershey, Le~Roux, and
  Atlas]{wisdom2016full}
Wisdom, S., Powers, T., Hershey, J., Le~Roux, J., and Atlas, L.
\newblock Full-capacity unitary recurrent neural networks.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  4880--4888, 2016.

\bibitem[Wong \& Zakai(1965)Wong and Zakai]{wongzakai1965}
Wong, E. and Zakai, M.
\newblock {On the Convergence of Ordinary Integrals to Stochastic Integrals}.
\newblock \emph{Annals of Mathematical Statistics}, 36\penalty0 (5):\penalty0
  1560--1564, 1965.

\end{thebibliography}
