\begin{thebibliography}{69}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi
\expandafter\ifx\csname url\endcsname\relax
  \def\url#1{\texttt{#1}}\fi
\expandafter\ifx\csname urlprefix\endcsname\relax\def\urlprefix{}\fi

\bibitem[{Agazzi and Lu(2019)}]{agazzi2019temporal}
\text{Agazzi, A.} and \text{Lu, J.} (2019).
\newblock Temporal-difference learning for nonlinear value function
  approximation in the lazy training regime.
\newblock \textit{arXiv preprint arXiv:1905.10917}.

\bibitem[{Agazzi and Lu(2020)}]{agazzi2020global}
\text{Agazzi, A.} and \text{Lu, J.} (2020).
\newblock Global optimality of softmax policy gradient with single hidden layer
  neural networks in the mean-field regime.
\newblock \textit{arXiv preprint arXiv:2010.11858}.

\bibitem[{Agostinelli et~al.(2019)Agostinelli, McAleer, Shmakov and
  Baldi}]{agostinelli2019solving}
\text{Agostinelli, F.}, \text{McAleer, S.}, \text{Shmakov, A.} and \text{Baldi,
  P.} (2019).
\newblock Solving the {R}ubik’s cube with deep reinforcement learning and
  search.
\newblock \textit{Nature Machine Intelligence}, \textbf{1} 356--363.

\bibitem[{Akkaya et~al.(2019)Akkaya, Andrychowicz, Chociej, Litwin, McGrew,
  Petron, Paino, Plappert, Powell, Ribas et~al.}]{akkaya2019solving}
\text{Akkaya, I.}, \text{Andrychowicz, M.}, \text{Chociej, M.}, \text{Litwin,
  M.}, \text{McGrew, B.}, \text{Petron, A.}, \text{Paino, A.}, \text{Plappert,
  M.}, \text{Powell, G.}, \text{Ribas, R.} \text{et~al.} (2019).
\newblock Solving {R}ubik's cube with a robot hand.
\newblock \textit{arXiv preprint arXiv:1910.07113}.

\bibitem[{Ambrosio and Gigli(2013)}]{ambrosio2013user}
\text{Ambrosio, L.} and \text{Gigli, N.} (2013).
\newblock A user’s guide to optimal transport.
\newblock In \textit{Modelling and Optimisation of Flows on Networks}.
  Springer, 1--155.

\bibitem[{Ambrosio et~al.(2008)Ambrosio, Gigli and
  Savar{\'e}}]{ambrosio2008gradient}
\text{Ambrosio, L.}, \text{Gigli, N.} and \text{Savar{\'e}, G.} (2008).
\newblock \textit{Gradient Flows: In Metric Spaces and in the Space of
  Probability Measures}.
\newblock Springer.

\bibitem[{Antos et~al.(2008)Antos, Szepesv{\'a}ri and
  Munos}]{antos2008learning}
\text{Antos, A.}, \text{Szepesv{\'a}ri, C.} and \text{Munos, R.} (2008).
\newblock Learning near-optimal policies with {B}ellman-residual minimization
  based fitted policy iteration and a single sample path.
\newblock \textit{Machine Learning}, \textbf{71} 89--129.

\bibitem[{Barron(1993)}]{barron1993universal}
\text{Barron, A.~R.} (1993).
\newblock Universal approximation bounds for superpositions of a sigmoidal
  function.
\newblock \textit{IEEE Transactions on Information Theory}, \textbf{39}
  930--945.

\bibitem[{Berner et~al.(2019)Berner, Brockman, Chan, Cheung, Debiak, Dennison,
  Farhi, Fischer, Hashme, Hesse et~al.}]{berner2019dota}
\text{Berner, C.}, \text{Brockman, G.}, \text{Chan, B.}, \text{Cheung, V.},
  \text{Debiak, P.}, \text{Dennison, C.}, \text{Farhi, D.}, \text{Fischer, Q.},
  \text{Hashme, S.}, \text{Hesse, C.} \text{et~al.} (2019).
\newblock Dota 2 with large scale deep reinforcement learning.
\newblock \textit{arXiv preprint arXiv:1912.06680}.

\bibitem[{Bhatnagar et~al.(2008)Bhatnagar, Ghavamzadeh, Lee and
  Sutton}]{bhatnagar2008incremental}
\text{Bhatnagar, S.}, \text{Ghavamzadeh, M.}, \text{Lee, M.} and \text{Sutton,
  R.~S.} (2008).
\newblock Incremental natural actor-critic algorithms.
\newblock In \textit{Advances in Neural Information Processing Systems}.

\bibitem[{Bhatnagar et~al.(2009)Bhatnagar, Sutton, Ghavamzadeh and
  Lee}]{bhatnagar2009natural}
\text{Bhatnagar, S.}, \text{Sutton, R.~S.}, \text{Ghavamzadeh, M.} and
  \text{Lee, M.} (2009).
\newblock Natural actor-critic algorithms.
\newblock \textit{Automatica}, \textbf{45} 2471--2482.

\bibitem[{B{\"o}rgers and Sarin(1997)}]{borgers1997learning}
\text{B{\"o}rgers, T.} and \text{Sarin, R.} (1997).
\newblock Learning through reinforcement and replicator dynamics.
\newblock \textit{Journal of Economic Theory}, \textbf{77} 1--14.

\bibitem[{Borkar(2009)}]{borkar2009stochastic}
\text{Borkar, V.~S.} (2009).
\newblock \textit{Stochastic Approximation: A Dynamical Systems Viewpoint}.
\newblock Springer.

\bibitem[{Cai et~al.(2019{\natexlab{a}})Cai, Yang, Jin and
  Wang}]{cai2019provably}
\text{Cai, Q.}, \text{Yang, Z.}, \text{Jin, C.} and \text{Wang, Z.}
  (2019{\natexlab{a}}).
\newblock Provably efficient exploration in policy optimization.
\newblock \textit{arXiv preprint arXiv:1912.05830}.

\bibitem[{Cai et~al.(2019{\natexlab{b}})Cai, Yang, Lee and
  Wang}]{cai2019neural}
\text{Cai, Q.}, \text{Yang, Z.}, \text{Lee, J.~D.} and \text{Wang, Z.}
  (2019{\natexlab{b}}).
\newblock Neural temporal-difference learning converges to global optima.
\newblock In \textit{Advances in Neural Information Processing Systems}.

\bibitem[{Chen et~al.(2020{\natexlab{a}})Chen, Wang, Liu, Yang, Li, Wang and
  Zhao}]{chen2020computation}
\text{Chen, M.}, \text{Wang, Y.}, \text{Liu, T.}, \text{Yang, Z.}, \text{Li,
  X.}, \text{Wang, Z.} and \text{Zhao, T.} (2020{\natexlab{a}}).
\newblock On computation and generalization of generative adversarial imitation
  learning.
\newblock \textit{arXiv preprint arXiv:2001.02792}.

\bibitem[{Chen et~al.(2020{\natexlab{b}})Chen, Cao, Gu and
  Zhang}]{chen2020mean}
\text{Chen, Z.}, \text{Cao, Y.}, \text{Gu, Q.} and \text{Zhang, T.}
  (2020{\natexlab{b}}).
\newblock Mean-field analysis of two-layer neural networks: Non-asymptotic
  rates and generalization bounds.
\newblock \textit{arXiv preprint arXiv:2002.04026}.

\bibitem[{Chizat and Bach(2018{\natexlab{a}})}]{chizat2018note}
\text{Chizat, L.} and \text{Bach, F.} (2018{\natexlab{a}}).
\newblock A note on lazy training in supervised differentiable programming.
\newblock \textit{arXiv preprint arXiv:1812.07956}.

\bibitem[{Chizat and Bach(2018{\natexlab{b}})}]{chizat2018global}
\text{Chizat, L.} and \text{Bach, F.} (2018{\natexlab{b}}).
\newblock On the global convergence of gradient descent for over-parameterized
  models using optimal transport.
\newblock In \textit{Advances in Neural Information Processing Systems}.

\bibitem[{Duan et~al.(2016)Duan, Chen, Houthooft, Schulman and
  Abbeel}]{duan2016benchmarking}
\text{Duan, Y.}, \text{Chen, X.}, \text{Houthooft, R.}, \text{Schulman, J.} and
  \text{Abbeel, P.} (2016).
\newblock Benchmarking deep reinforcement learning for continuous control.
\newblock In \textit{International Conference on Machine Learning}.

\bibitem[{Fang et~al.(2019{\natexlab{a}})Fang, Dong and Zhang}]{fang2019over}
\text{Fang, C.}, \text{Dong, H.} and \text{Zhang, T.} (2019{\natexlab{a}}).
\newblock Over parameterized two-level neural networks can learn near optimal
  feature representations.
\newblock \textit{arXiv preprint arXiv:1910.11508}.

\bibitem[{Fang et~al.(2019{\natexlab{b}})Fang, Gu, Zhang and
  Zhang}]{fang2019convex}
\text{Fang, C.}, \text{Gu, Y.}, \text{Zhang, W.} and \text{Zhang, T.}
  (2019{\natexlab{b}}).
\newblock Convex formulation of overparameterized deep neural networks.
\newblock \textit{arXiv preprint arXiv:1911.07626}.

\bibitem[{Farahmand et~al.(2016)Farahmand, Ghavamzadeh, Szepesv{\'a}ri and
  Mannor}]{farahmand2016regularized}
\text{Farahmand, A.-m.}, \text{Ghavamzadeh, M.}, \text{Szepesv{\'a}ri, C.} and
  \text{Mannor, S.} (2016).
\newblock Regularized policy iteration with nonparametric function spaces.
\newblock \textit{The Journal of Machine Learning Research}, \textbf{17}
  4809--4874.

\bibitem[{Farahmand et~al.(2010)Farahmand, Szepesv{\'a}ri and
  Munos}]{farahmand2010error}
\text{Farahmand, A.-m.}, \text{Szepesv{\'a}ri, C.} and \text{Munos, R.} (2010).
\newblock Error propagation for approximate policy and value iteration.
\newblock In \textit{Advances in Neural Information Processing Systems}.

\bibitem[{Friedrichs(1944)}]{friedrichs1944identity}
\text{Friedrichs, K.~O.} (1944).
\newblock The identity of weak and strong extensions of differential operators.
\newblock \textit{Transactions of the American Mathematical Society},
  \textbf{55} 132--151.

\bibitem[{Fu et~al.(2020)Fu, Yang and Wang}]{fu2020single}
\text{Fu, Z.}, \text{Yang, Z.} and \text{Wang, Z.} (2020).
\newblock Single-timescale actor-critic provably finds globally optimal policy.
\newblock \textit{arXiv preprint arXiv:2008.00483}.

\bibitem[{Harker and Pang(1990)}]{harker1990finite}
\text{Harker, P.~T.} and \text{Pang, J.-S.} (1990).
\newblock Finite-dimensional variational inequality and nonlinear
  complementarity problems: A survey of theory, algorithms and applications.
\newblock \textit{Mathematical Programming}, \textbf{48} 161--220.

\bibitem[{Hennes et~al.(2020)Hennes, Morrill, Omidshafiei, Munos, Perolat,
  Lanctot, Gruslys, Lespiau, Parmas, Du{\'e}{\~n}ez-Guzm{\'a}n
  et~al.}]{hennes2020neural}
\text{Hennes, D.}, \text{Morrill, D.}, \text{Omidshafiei, S.}, \text{Munos,
  R.}, \text{Perolat, J.}, \text{Lanctot, M.}, \text{Gruslys, A.},
  \text{Lespiau, J.-B.}, \text{Parmas, P.}, \text{Du{\'e}{\~n}ez-Guzm{\'a}n,
  E.} \text{et~al.} (2020).
\newblock Neural replicator dynamics: Multiagent learning via hedging policy
  gradients.
\newblock In \textit{International Conference on Autonomous Agents and
  MultiAgent Systems}.

\bibitem[{Hong et~al.(2020)Hong, Wai, Wang and Yang}]{hong2020two}
\text{Hong, M.}, \text{Wai, H.-T.}, \text{Wang, Z.} and \text{Yang, Z.} (2020).
\newblock A two-timescale framework for bilevel optimization: Complexity
  analysis and application to actor-critic.
\newblock \textit{arXiv preprint arXiv:2007.05170}.

\bibitem[{Jacot et~al.(2018)Jacot, Gabriel and Hongler}]{jacot2018neural}
\text{Jacot, A.}, \text{Gabriel, F.} and \text{Hongler, C.} (2018).
\newblock Neural tangent kernel: Convergence and generalization in neural
  networks.
\newblock In \textit{Advances in Neural Information Processing Systems}.

\bibitem[{Javanmard et~al.(2019)Javanmard, Mondelli and
  Montanari}]{javanmard2019analysis}
\text{Javanmard, A.}, \text{Mondelli, M.} and \text{Montanari, A.} (2019).
\newblock Analysis of a two-layer neural network via displacement convexity.
\newblock \textit{arXiv preprint arXiv:1901.01375}.

\bibitem[{Jin et~al.(2020)Jin, Yang, Wang and Jordan}]{jin2020provably}
\text{Jin, C.}, \text{Yang, Z.}, \text{Wang, Z.} and \text{Jordan, M.~I.}
  (2020).
\newblock Provably efficient reinforcement learning with linear function
  approximation.
\newblock In \textit{Conference on Learning Theory}.

\bibitem[{Kakade and Langford(2002)}]{kakade2002approximately}
\text{Kakade, S.} and \text{Langford, J.} (2002).
\newblock Approximately optimal approximate reinforcement learning.
\newblock In \textit{International Conference on Machine Learning}, vol.~2.

\bibitem[{Kakade(2002)}]{kakade2002natural}
\text{Kakade, S.~M.} (2002).
\newblock A natural policy gradient.
\newblock In \textit{Advances in Neural Information Processing Systems}.

\bibitem[{Khodadadian et~al.(2021)Khodadadian, Doan, Maguluri and
  Romberg}]{khodadadian2021finite}
\text{Khodadadian, S.}, \text{Doan, T.~T.}, \text{Maguluri, S.~T.} and
  \text{Romberg, J.} (2021).
\newblock Finite sample analysis of two-time-scale natural actor-critic
  algorithm.
\newblock \textit{arXiv preprint arXiv:2101.10506}.

\bibitem[{Konda and Tsitsiklis(2000)}]{konda2000actor}
\text{Konda, V.~R.} and \text{Tsitsiklis, J.~N.} (2000).
\newblock Actor-critic algorithms.
\newblock In \textit{Advances in Neural Information Processing Systems}.

\bibitem[{Kushner and Yin(2003)}]{kushner2003stochastic}
\text{Kushner, H.} and \text{Yin, G.~G.} (2003).
\newblock \textit{Stochastic Approximation and Recursive Algorithms and
  Applications}.
\newblock Springer.

\bibitem[{Lazaric et~al.(2016)Lazaric, Ghavamzadeh and
  Munos}]{lazaric2010analysis}
\text{Lazaric, A.}, \text{Ghavamzadeh, M.} and \text{Munos, R.} (2016).
\newblock Analysis of classification-based policy iteration algorithms.
\newblock \textit{The Journal of Machine Learning Research}, \textbf{17}
  583--612.

\bibitem[{Liu et~al.(2019)Liu, Cai, Yang and Wang}]{liu2019neural}
\text{Liu, B.}, \text{Cai, Q.}, \text{Yang, Z.} and \text{Wang, Z.} (2019).
\newblock Neural proximal/trust region policy optimization attains globally
  optimal policy.
\newblock \textit{arXiv preprint arXiv:1906.10306}.

\bibitem[{Lu et~al.(2020)Lu, Ma, Lu, Lu and Ying}]{lu2020mean}
\text{Lu, Y.}, \text{Ma, C.}, \text{Lu, Y.}, \text{Lu, J.} and \text{Ying, L.}
  (2020).
\newblock A mean field analysis of deep resnet and beyond: Towards provably
  optimization via overparameterization from depth.
\newblock In \textit{International Conference on Machine Learning}. PMLR.

\bibitem[{Mei et~al.(2019)Mei, Misiakiewicz and Montanari}]{mei2019mean}
\text{Mei, S.}, \text{Misiakiewicz, T.} and \text{Montanari, A.} (2019).
\newblock Mean-field theory of two-layers neural networks: dimension-free
  bounds and kernel limit.
\newblock In \textit{Conference on Learning Theory}. PMLR.

\bibitem[{Mei et~al.(2018)Mei, Montanari and Nguyen}]{mei2018mean}
\text{Mei, S.}, \text{Montanari, A.} and \text{Nguyen, P.-M.} (2018).
\newblock A mean field view of the landscape of two-layer neural networks.
\newblock \textit{Proceedings of the National Academy of Sciences},
  \textbf{115} E7665--E7671.

\bibitem[{Munos and Szepesv{\'a}ri(2008)}]{munos2008finite}
\text{Munos, R.} and \text{Szepesv{\'a}ri, C.} (2008).
\newblock Finite-time bounds for fitted value iteration.
\newblock \textit{The Journal of Machine Learning Research}, \textbf{9}
  815--857.

\bibitem[{Otto and Villani(2000)}]{otto2000generalization}
\text{Otto, F.} and \text{Villani, C.} (2000).
\newblock Generalization of an inequality by {T}alagrand and links with the
  logarithmic {S}obolev inequality.
\newblock \textit{Journal of Functional Analysis}, \textbf{173} 361--400.

\bibitem[{Peters and Schaal(2008)}]{peters2008natural}
\text{Peters, J.} and \text{Schaal, S.} (2008).
\newblock Natural actor-critic.
\newblock \textit{Neurocomputing}, \textbf{71} 1180--1190.

\bibitem[{Peyre(2011)}]{peyre2011comparison}
\text{Peyre, R.} (2011).
\newblock Comparison between $ w_2 $ distance and $ \dot{H}^{-1}$ norm, and
  localisation of wasserstein distance.
\newblock \textit{arXiv preprint arXiv:1104.4631}.

\bibitem[{Pinkus(1999)}]{pinkus1999approximation}
\text{Pinkus, A.} (1999).
\newblock Approximation theory of the {MLP} model in neural networks.
\newblock \textit{Acta Numerica}, \textbf{8} 143--195.

\bibitem[{Scherrer et~al.(2015)Scherrer, Ghavamzadeh, Gabillon, Lesner and
  Geist}]{scherrer2015approximate}
\text{Scherrer, B.}, \text{Ghavamzadeh, M.}, \text{Gabillon, V.}, \text{Lesner,
  B.} and \text{Geist, M.} (2015).
\newblock Approximate modified policy iteration and its application to the game
  of {T}etris.
\newblock \textit{The Journal of Machine Learning Research}, \textbf{16}
  1629--1676.

\bibitem[{Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford and
  Klimov}]{schulman2017proximal}
\text{Schulman, J.}, \text{Wolski, F.}, \text{Dhariwal, P.}, \text{Radford, A.}
  and \text{Klimov, O.} (2017).
\newblock Proximal policy optimization algorithms.
\newblock \textit{arXiv preprint arXiv:1707.06347}.

\bibitem[{Schuster and Sigmund(1983)}]{schuster1983replicator}
\text{Schuster, P.} and \text{Sigmund, K.} (1983).
\newblock Replicator dynamics.
\newblock \textit{Journal of Theoretical Biology}, \textbf{100} 533--538.

\bibitem[{Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, Van
  Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot
  et~al.}]{silver2016mastering}
\text{Silver, D.}, \text{Huang, A.}, \text{Maddison, C.~J.}, \text{Guez, A.},
  \text{Sifre, L.}, \text{Van Den~Driessche, G.}, \text{Schrittwieser, J.},
  \text{Antonoglou, I.}, \text{Panneershelvam, V.}, \text{Lanctot, M.}
  \text{et~al.} (2016).
\newblock Mastering the game of {G}o with deep neural networks and tree search.
\newblock \textit{Nature}, \textbf{529} 484--489.

\bibitem[{Silver et~al.(2017)Silver, Schrittwieser, Simonyan, Antonoglou,
  Huang, Guez, Hubert, Baker, Lai, Bolton et~al.}]{silver2017mastering}
\text{Silver, D.}, \text{Schrittwieser, J.}, \text{Simonyan, K.},
  \text{Antonoglou, I.}, \text{Huang, A.}, \text{Guez, A.}, \text{Hubert, T.},
  \text{Baker, L.}, \text{Lai, M.}, \text{Bolton, A.} \text{et~al.} (2017).
\newblock Mastering the game of {G}o without human knowledge.
\newblock \textit{Nature}, \textbf{550} 354.

\bibitem[{Sirignano and Spiliopoulos(2020{\natexlab{a}})}]{sirignano2020mean1}
\text{Sirignano, J.} and \text{Spiliopoulos, K.} (2020{\natexlab{a}}).
\newblock Mean field analysis of neural networks: A central limit theorem.
\newblock \textit{Stochastic Processes and their Applications}, \textbf{130}
  1820--1852.

\bibitem[{Sirignano and Spiliopoulos(2020{\natexlab{b}})}]{sirignano2020mean}
\text{Sirignano, J.} and \text{Spiliopoulos, K.} (2020{\natexlab{b}}).
\newblock Mean field analysis of neural networks: A law of large numbers.
\newblock \textit{SIAM Journal on Applied Mathematics}, \textbf{80} 725--752.

\bibitem[{Sutton(1988)}]{sutton1988learning}
\text{Sutton, R.~S.} (1988).
\newblock Learning to predict by the methods of temporal differences.
\newblock \textit{Machine Learning}, \textbf{3} 9--44.

\bibitem[{Sutton and Barto(2018)}]{sutton2018reinforcement}
\text{Sutton, R.~S.} and \text{Barto, A.~G.} (2018).
\newblock \textit{Reinforcement Learning: An Introduction}.
\newblock MIT press.

\bibitem[{Szepesv{\'a}ri and Munos(2005)}]{szepesvari2005finite}
\text{Szepesv{\'a}ri, C.} and \text{Munos, R.} (2005).
\newblock Finite time bounds for sampling based fitted value iteration.
\newblock In \textit{International Conference on Machine Learning}. ACM.

\bibitem[{Villani(2003)}]{villani2003topics}
\text{Villani, C.} (2003).
\newblock \textit{Topics in Optimal Transportation}.
\newblock American Mathematical Society.

\bibitem[{Villani(2008)}]{villani2008optimal}
\text{Villani, C.} (2008).
\newblock \textit{Optimal Transport: Old and New}.
\newblock Springer.

\bibitem[{Vinyals et~al.(2019)Vinyals, Babuschkin, Czarnecki, Mathieu, Dudzik,
  Chung, Choi, Powell, Ewalds, Georgiev et~al.}]{vinyals2019grandmaster}
\text{Vinyals, O.}, \text{Babuschkin, I.}, \text{Czarnecki, W.~M.},
  \text{Mathieu, M.}, \text{Dudzik, A.}, \text{Chung, J.}, \text{Choi, D.~H.},
  \text{Powell, R.}, \text{Ewalds, T.}, \text{Georgiev, P.} \text{et~al.}
  (2019).
\newblock Grandmaster level in {S}tar{C}raft {II} using multi-agent
  reinforcement learning.
\newblock \textit{Nature}, \textbf{575} 350--354.

\bibitem[{Wang et~al.(2019)Wang, Cai, Yang and Wang}]{wang2019neural}
\text{Wang, L.}, \text{Cai, Q.}, \text{Yang, Z.} and \text{Wang, Z.} (2019).
\newblock Neural policy gradient methods: Global optimality and rates of
  convergence.
\newblock \textit{arXiv preprint arXiv:1909.01150}.

\bibitem[{Watkins and Dayan(1992)}]{watkins1992q}
\text{Watkins, C.} and \text{Dayan, P.} (1992).
\newblock Q-learning.
\newblock \textit{Machine Learning}, \textbf{8} 279--292.

\bibitem[{Wei et~al.(2019)Wei, Lee, Liu and Ma}]{wei2019regularization}
\text{Wei, C.}, \text{Lee, J.~D.}, \text{Liu, Q.} and \text{Ma, T.} (2019).
\newblock Regularization matters: Generalization and optimization of neural
  nets vs their induced kernel.
\newblock In \textit{Advances in Neural Information Processing Systems}.

\bibitem[{Wu et~al.(2020)Wu, Zhang, Xu and Gu}]{wu2020finite}
\text{Wu, Y.}, \text{Zhang, W.}, \text{Xu, P.} and \text{Gu, Q.} (2020).
\newblock A finite time analysis of two time-scale actor critic methods.
\newblock \textit{arXiv preprint arXiv:2005.01350}.

\bibitem[{Xu et~al.(2020{\natexlab{a}})Xu, Wang and Liang}]{xu2020improving}
\text{Xu, T.}, \text{Wang, Z.} and \text{Liang, Y.} (2020{\natexlab{a}}).
\newblock Improving sample complexity bounds for actor-critic algorithms.
\newblock \textit{arXiv preprint arXiv:2004.12956}.

\bibitem[{Xu et~al.(2020{\natexlab{b}})Xu, Wang and Liang}]{xu2020non}
\text{Xu, T.}, \text{Wang, Z.} and \text{Liang, Y.} (2020{\natexlab{b}}).
\newblock Non-asymptotic convergence analysis of two time-scale (natural)
  actor-critic algorithms.
\newblock \textit{arXiv preprint arXiv:2005.03557}.

\bibitem[{Yang and Wang(2019{\natexlab{a}})}]{yang2019reinforcement}
\text{Yang, L.~F.} and \text{Wang, M.} (2019{\natexlab{a}}).
\newblock Reinforcement learning in feature space: Matrix bandit, kernels, and
  regret bound.
\newblock \textit{arXiv preprint arXiv:1905.10389}.

\bibitem[{Yang and Wang(2019{\natexlab{b}})}]{yang2019sample}
\text{Yang, L.~F.} and \text{Wang, M.} (2019{\natexlab{b}}).
\newblock Sample-optimal parametric q-learning using linearly additive
  features.
\newblock \textit{arXiv preprint arXiv:1902.04779}.

\bibitem[{Zhang et~al.(2020)Zhang, Cai, Yang, Chen and Wang}]{zhang2020can}
\text{Zhang, Y.}, \text{Cai, Q.}, \text{Yang, Z.}, \text{Chen, Y.} and
  \text{Wang, Z.} (2020).
\newblock Can temporal-difference and {Q}-learning learn representation? {A}
  mean-field theory.
\newblock \textit{arXiv preprint arXiv:2006.04761}.

\end{thebibliography}
