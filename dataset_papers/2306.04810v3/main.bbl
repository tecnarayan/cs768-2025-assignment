\begin{thebibliography}{69}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Rumelhart et~al.(1986)Rumelhart, Hinton, and
  Williams]{rumelhart1986learning}
David~E Rumelhart, Geoffrey~E Hinton, and Ronald~J Williams.
\newblock Learning representations by back-propagating errors.
\newblock \emph{Nature}, 323\penalty0 (6088):\penalty0 533--536, 1986.

\bibitem[Whittington and Bogacz(2019)]{whittington2019theories}
James~CR Whittington and Rafal Bogacz.
\newblock Theories of error back-propagation in the brain.
\newblock \emph{Trends in cognitive sciences}, 23\penalty0 (3):\penalty0
  235--250, 2019.

\bibitem[Crick(1989)]{crick1989recent}
Francis Crick.
\newblock The recent excitement about neural networks.
\newblock \emph{Nature}, 337:\penalty0 129--132, 1989.

\bibitem[Grossberg(1987{\natexlab{a}})]{grossberg1987competitive}
Stephen Grossberg.
\newblock Competitive learning: From interactive activation to adaptive
  resonance.
\newblock \emph{Cognitive science}, 11\penalty0 (1):\penalty0 23--63,
  1987{\natexlab{a}}.

\bibitem[Xie and Seung(2003)]{xie2003equivalence}
Xiaohui Xie and H~Sebastian Seung.
\newblock Equivalence of backpropagation and contrastive hebbian learning in a
  layered network.
\newblock \emph{Neural computation}, 15\penalty0 (2):\penalty0 441--454, 2003.

\bibitem[Scellier and Bengio(2017{\natexlab{a}})]{scellier2017equilibrium}
Benjamin Scellier and Yoshua Bengio.
\newblock Equilibrium propagation: Bridging the gap between energy-based models
  and backpropagation.
\newblock \emph{Frontiers in computational neuroscience}, 11:\penalty0 24,
  2017{\natexlab{a}}.

\bibitem[Larkum(2013)]{larkum2013cellular}
Matthew Larkum.
\newblock A cellular mechanism for cortical associations: an organizing
  principle for the cerebral cortex.
\newblock \emph{Trends in neurosciences}, 36\penalty0 (3):\penalty0 141--151,
  2013.

\bibitem[Urbanczik and Senn(2014)]{urbanczik2014learning}
Robert Urbanczik and Walter Senn.
\newblock Learning by the dendritic prediction of somatic spiking.
\newblock \emph{Neuron}, 81\penalty0 (3):\penalty0 521--528, 2014.

\bibitem[Sacramento et~al.(2018)Sacramento, Ponte~Costa, Bengio, and
  Senn]{sacramento2018dendritic}
Jo{\~a}o Sacramento, Rui Ponte~Costa, Yoshua Bengio, and Walter Senn.
\newblock Dendritic cortical microcircuits approximate the backpropagation
  algorithm.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Golkar et~al.(2022)Golkar, Tesileanu, Bahroun, Sengupta, and
  Chklovskii]{golkar2022constrained}
Siavash Golkar, Tiberiu Tesileanu, Yanis Bahroun, Anirvan Sengupta, and Dmitri
  Chklovskii.
\newblock Constrained predictive coding as a biologically plausible model of
  the cortical hierarchy.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 14155--14169, 2022.

\bibitem[Bozkurt et~al.(2023)Bozkurt, {\.I}sfendiyaro{\u{g}}lu, Pehlevan, and
  Erdogan]{bozkurt2023correlative}
Bariscan Bozkurt, Ate{\c{s}} {\.I}sfendiyaro{\u{g}}lu, Cengiz Pehlevan, and
  Alper~Tunga Erdogan.
\newblock Correlative information maximization based biologically plausible
  neural networks for correlated source separation.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=8JsaP7j1cL0}.

\bibitem[Petreanu et~al.(2009)Petreanu, Mao, Sternson, and
  Svoboda]{petreanu2009subcellular}
Leopoldo Petreanu, Tianyi Mao, Scott~M Sternson, and Karel Svoboda.
\newblock The subcellular organization of neocortical excitatory connections.
\newblock \emph{Nature}, 457\penalty0 (7233):\penalty0 1142--1145, 2009.

\bibitem[Richards and Lillicrap(2019)]{richards2019dendritic}
Blake~A Richards and Timothy~P Lillicrap.
\newblock Dendritic solutions to the credit assignment problem.
\newblock \emph{Current opinion in neurobiology}, 54:\penalty0 28--36, 2019.

\bibitem[Urban-Ciecko and Barth(2016)]{urban2016somatostatin}
Joanna Urban-Ciecko and Alison~L Barth.
\newblock Somatostatin-expressing neurons in cortical networks.
\newblock \emph{Nature Reviews Neuroscience}, 17\penalty0 (7):\penalty0
  401--409, 2016.

\bibitem[Guerguiev et~al.(2017)Guerguiev, Lillicrap, and
  Richards]{guerguiev2017towards}
Jordan Guerguiev, Timothy~P Lillicrap, and Blake~A Richards.
\newblock Towards deep learning with segregated dendrites.
\newblock \emph{Elife}, 6:\penalty0 e22901, 2017.

\bibitem[Grossberg(1987{\natexlab{b}})]{Grossberg1987CompetitiveLF}
Stephen Grossberg.
\newblock Competitive learning: From interactive activation to adaptive
  resonance.
\newblock \emph{Cogn. Sci.}, 11:\penalty0 23--63, 1987{\natexlab{b}}.

\bibitem[Lillicrap et~al.(2016)Lillicrap, Cownden, Tweed, and
  Akerman]{lillicrap2016random}
Timothy~P Lillicrap, Daniel Cownden, Douglas~B Tweed, and Colin~J Akerman.
\newblock Random synaptic feedback weights support error backpropagation for
  deep learning.
\newblock \emph{Nature communications}, 7\penalty0 (1):\penalty0 13276, 2016.

\bibitem[Akrout et~al.(2019)Akrout, Wilson, Humphreys, Lillicrap, and
  Tweed]{Akrout2019Neurips}
Mohamed Akrout, Collin Wilson, Peter Humphreys, Timothy Lillicrap, and
  Douglas~B Tweed.
\newblock Deep learning without weight transport.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2019/file/f387624df552cea2f369918c5e1e12bc-Paper.pdf}.

\bibitem[Amit(2019)]{amit2019deep}
Yali Amit.
\newblock Deep learning with asymmetric connections and hebbian updates.
\newblock \emph{Frontiers in computational neuroscience}, 13:\penalty0 18,
  2019.

\bibitem[Liao et~al.(2015)Liao, Leibo, and Poggio]{HowImportantWeightSymmetry}
Qianli Liao, Joel Leibo, and Tomaso Poggio.
\newblock How important is weight symmetry in backpropagation?
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  30, 10 2015.
\newblock \doi{10.1609/aaai.v30i1.10279}.

\bibitem[Rao and Ballard(1999)]{rao1999predictive}
Rajesh~PN Rao and Dana~H Ballard.
\newblock Predictive coding in the visual cortex: a functional interpretation
  of some extra-classical receptive-field effects.
\newblock \emph{Nature neuroscience}, 2\penalty0 (1):\penalty0 79--87, 1999.

\bibitem[Whittington and Bogacz(2017)]{whittington2017approximation}
James~CR Whittington and Rafal Bogacz.
\newblock An approximation of the error backpropagation algorithm in a
  predictive coding network with local hebbian synaptic plasticity.
\newblock \emph{Neural computation}, 29\penalty0 (5):\penalty0 1229--1262,
  2017.

\bibitem[Song et~al.(2020)Song, Lukasiewicz, Xu, and Bogacz]{song2020can}
Yuhang Song, Thomas Lukasiewicz, Zhenghua Xu, and Rafal Bogacz.
\newblock Can the brain do backpropagation?---exact implementation of
  backpropagation in predictive coding networks.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 22566--22579, 2020.

\bibitem[Scellier and Bengio(2017{\natexlab{b}})]{EqProp}
Benjamin Scellier and Yoshua Bengio.
\newblock Equilibrium propagation: Bridging the gap between energy-based models
  and backpropagation.
\newblock \emph{Frontiers in Computational Neuroscience}, 11,
  2017{\natexlab{b}}.
\newblock ISSN 1662-5188.
\newblock \doi{10.3389/fncom.2017.00024}.
\newblock URL
  \url{https://www.frontiersin.org/articles/10.3389/fncom.2017.00024}.

\bibitem[Laborieux et~al.(2021)Laborieux, Ernoult, Scellier, Bengio, Grollier,
  and Querlioz]{ScalingEP}
Axel Laborieux, Maxence Ernoult, Benjamin Scellier, Yoshua Bengio, Julie
  Grollier, and Damien Querlioz.
\newblock Scaling equilibrium propagation to deep convnets by drastically
  reducing its gradient estimator bias.
\newblock \emph{Frontiers in Neuroscience}, 15:\penalty0 633674, 02 2021.
\newblock \doi{10.3389/fnins.2021.633674}.

\bibitem[Laborieux and Zenke(2022)]{laborieux2022EPholomorphic}
Axel Laborieux and Friedemann Zenke.
\newblock Holomorphic equilibrium propagation computes exact gradients through
  finite size oscillations.
\newblock In Alice~H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho,
  editors, \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=7JqqnRrZfz6}.

\bibitem[Qin et~al.(2021)Qin, Mudur, and Pehlevan]{qin2021contrastive}
Shanshan Qin, Nayantara Mudur, and Cengiz Pehlevan.
\newblock Contrastive similarity matching for supervised learning.
\newblock \emph{Neural computation}, 33\penalty0 (5):\penalty0 1300--1328,
  2021.

\bibitem[Scellier et~al.(2018)Scellier, Goyal, Binas, Mesnard, and
  Bengio]{scellier2018generalization}
Benjamin Scellier, Anirudh Goyal, Jonathan Binas, Thomas Mesnard, and Yoshua
  Bengio.
\newblock Generalization of equilibrium propagation to vector field dynamics,
  2018.

\bibitem[Kolen and Pollack(1994)]{BP_without_weight_transport}
J.F. Kolen and J.B. Pollack.
\newblock Backpropagation without weight transport.
\newblock In \emph{Proceedings of 1994 IEEE International Conference on Neural
  Networks (ICNN'94)}, volume~3, pages 1375--1380 vol.3, 1994.
\newblock \doi{10.1109/ICNN.1994.374486}.

\bibitem[Linsker(1988)]{linsker1988self}
Ralph Linsker.
\newblock Self-organization in a perceptual network.
\newblock \emph{Computer}, 21\penalty0 (3):\penalty0 105--117, 1988.

\bibitem[Bell and Sejnowski(1995)]{bell1995information}
Anthony~J Bell and Terrence~J Sejnowski.
\newblock An information-maximization approach to blind separation and blind
  deconvolution.
\newblock \emph{Neural computation}, 7\penalty0 (6):\penalty0 1129--1159, 1995.

\bibitem[Hubel and Wiesel(1959)]{HubelReceptive}
D.H. Hubel and T.N. Wiesel.
\newblock Receptive fields of single neurones in the cat's striate cortex.
\newblock \emph{The Journal of physiology}, 148:\penalty0 574--591, 1959.

\bibitem[Bell and Sejnowski(1997)]{bell1997independent}
Anthony~J Bell and Terrence~J Sejnowski.
\newblock The “independent components” of natural scenes are edge filters.
\newblock \emph{Vision research}, 37\penalty0 (23):\penalty0 3327--3338, 1997.

\bibitem[Hjelm et~al.(2019)Hjelm, Fedorov, Lavoie-Marchildon, Grewal, Bachman,
  Trischler, and Bengio]{hjelm2018learning}
R~Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil
  Bachman, Adam Trischler, and Yoshua Bengio.
\newblock Learning deep representations by mutual information estimation and
  maximization.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2019.

\bibitem[Becker and Hinton(1992)]{becker1992self}
Suzanna Becker and Geoffrey~E Hinton.
\newblock Self-organizing neural network that discovers surfaces in random-dot
  stereograms.
\newblock \emph{Nature}, 355\penalty0 (6356):\penalty0 161--163, 1992.

\bibitem[Erdogan(2022)]{erdogan2022icassp}
Alper~T Erdogan.
\newblock An information maximization based blind source separation approach
  for dependent and independent sources.
\newblock In \emph{ICASSP 2022 - 2022 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)}, pages 4378--4382, 2022.
\newblock \doi{10.1109/ICASSP43922.2022.9746099}.

\bibitem[Ozsoy et~al.(2022)Ozsoy, Hamdan, Arik, Yuret, and
  Erdogan]{ozsoy2022selfsupervised}
Serdar Ozsoy, Shadi Hamdan, Sercan~O Arik, Deniz Yuret, and Alper~Tunga
  Erdogan.
\newblock Self-supervised learning with an information maximization criterion.
\newblock In Alice~H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho,
  editors, \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=5MgZAu2NR7X}.

\bibitem[Oja(1982)]{oja1982simplified}
Erkki Oja.
\newblock Simplified neuron model as a principal component analyzer.
\newblock \emph{Journal of mathematical biology}, 15:\penalty0 267--273, 1982.

\bibitem[Lipshutz et~al.(2021)Lipshutz, Bahroun, Golkar, Sengupta, and
  Chklovskii]{lipshutz2021biologically}
David Lipshutz, Yanis Bahroun, Siavash Golkar, Anirvan~M Sengupta, and Dmitri~B
  Chklovskii.
\newblock A biologically plausible neural network for multichannel canonical
  correlation analysis.
\newblock \emph{Neural Computation}, 33\penalty0 (9):\penalty0 2309--2352,
  2021.

\bibitem[Tatli and Erdogan(2021)]{tatli2021tsp}
Gokcan Tatli and Alper~T Erdogan.
\newblock Polytopic matrix factorization: Determinant maximization based
  criterion and identifiability.
\newblock \emph{IEEE Transactions on Signal Processing}, 69:\penalty0
  5431--5447, 2021.
\newblock \doi{10.1109/TSP.2021.3112918}.

\bibitem[Plumbley(2003)]{plumbley2003algorithms}
Mark~D Plumbley.
\newblock Algorithms for nonnegative independent component analysis.
\newblock \emph{IEEE Transactions on Neural Networks}, 14\penalty0
  (3):\penalty0 534--543, 2003.

\bibitem[Pehlevan et~al.(2017)Pehlevan, Mohan, and
  Chklovskii]{pehlevan2017blind}
Cengiz Pehlevan, Sreyas Mohan, and Dmitri~B Chklovskii.
\newblock Blind nonnegative source separation using biological neural networks.
\newblock \emph{Neural computation}, 29\penalty0 (11):\penalty0 2925--2954,
  2017.

\bibitem[Whittington et~al.(2023)Whittington, Dorrell, Ganguli, and
  Behrens]{whittington2023disentanglement}
James C.~R. Whittington, Will Dorrell, Surya Ganguli, and Timothy Behrens.
\newblock Disentanglement with biological constraints: A theory of functional
  cell types.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=9Z_GfhZnGH}.

\bibitem[L{\"u}bke et~al.(1996)L{\"u}bke, Markram, Frotscher, and
  Sakmann]{lubke1996frequency}
Joachim L{\"u}bke, Henry Markram, Michael Frotscher, and Bert Sakmann.
\newblock Frequency and dendritic distribution of autapses established by layer
  5 pyramidal neurons in the developing rat neocortex: comparison with synaptic
  innervation of adjacent neurons of the same class.
\newblock \emph{Journal of Neuroscience}, 16\penalty0 (10):\penalty0
  3209--3218, 1996.

\bibitem[O'Reilly(1996)]{o1996biologically}
Randall~C O'Reilly.
\newblock Biologically plausible error-driven learning using local activation
  differences: The generalized recirculation algorithm.
\newblock \emph{Neural computation}, 8\penalty0 (5):\penalty0 895--938, 1996.

\bibitem[Baldi and Pineda(1991)]{PierreContrastive}
Pierre Baldi and Fernando Pineda.
\newblock Contrastive learning and neural oscillations.
\newblock \emph{Neural Computation}, 3\penalty0 (4):\penalty0 526--545, 1991.
\newblock \doi{10.1162/neco.1991.3.4.526}.

\bibitem[Ketz et~al.(2013)Ketz, Morkonda, and O'Reilly]{ketz2013theta}
Nicholas Ketz, Srinimisha~G Morkonda, and Randall~C O'Reilly.
\newblock Theta coordinated error-driven learning in the hippocampus.
\newblock \emph{PLoS computational biology}, 9\penalty0 (6):\penalty0 e1003067,
  2013.

\bibitem[Fell and Axmacher(2011)]{Fellsynchronization}
Juergen Fell and Nikolai Axmacher.
\newblock The role of phase synchronization in memory processes.
\newblock \emph{Nature reviews. Neuroscience}, 12:\penalty0 105--18, 02 2011.
\newblock \doi{10.1038/nrn2979}.

\bibitem[Engel et~al.(2001)Engel, Fries, and Singer]{EngelDynamic}
Andreas Engel, Pascal Fries, and Wolf Singer.
\newblock Dynamic predictions: oscillations and synchrony in top-down
  processing.
\newblock \emph{Nature reviews. Neuroscience}, 2:\penalty0 704--716, 11 2001.
\newblock \doi{10.1038/35094565}.

\bibitem[LeCun and Cortes(2010)]{lecunMNIST}
Yann LeCun and Corinna Cortes.
\newblock {MNIST} handwritten digit database.
\newblock http://yann.lecun.com/exdb/mnist/, 2010.
\newblock URL \url{http://yann.lecun.com/exdb/mnist/}.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017fashionmnist}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms, 2017.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images, 2009.

\bibitem[Millidge et~al.(2023)Millidge, Song, Salvatori, Lukasiewicz, and
  Bogacz]{millidge2023backpropagation}
Beren Millidge, Yuhang Song, Tommaso Salvatori, Thomas Lukasiewicz, and Rafal
  Bogacz.
\newblock Backpropagation at the infinitesimal inference limit of energy-based
  models: Unifying predictive coding, equilibrium propagation, and contrastive
  hebbian learning.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=nIMifqu2EO}.

\bibitem[{Zhanghao Zhouyin} and {Ding Liu}(2021)]{zhouyin:21}
{Zhanghao Zhouyin} and {Ding Liu}.
\newblock Understanding neural networks with logarithm determinant entropy
  estimator.
\newblock \emph{arXiv preprint arXiv:1401.3420}, 2021.

\bibitem[Kailath et~al.(2000)Kailath, Sayed, and Hassibi]{kailath2000linear}
Thomas Kailath, Ali~H Sayed, and Babak Hassibi.
\newblock \emph{Linear estimation}.
\newblock Prentice-Hall information and system sciences series. Prentice Hall,
  2000.
\newblock ISBN 9780130224644.

\bibitem[Fu et~al.(2016)Fu, Huang, Yang, Ma, and Sidiropoulos]{fu:2016}
Xiao Fu, Kejun Huang, Bo~Yang, Wing-Kin Ma, and Nicholas~D Sidiropoulos.
\newblock Robust volume minimization-based matrix factorization for remote
  sensing and document clustering.
\newblock \emph{IEEE Transactions on Signal Processing}, 64\penalty0
  (23):\penalty0 6254--6268, 2016.

\bibitem[Brondsted(2012)]{brondsted2012introduction}
Arne Brondsted.
\newblock \emph{An Introduction to Convex Polytopes}, volume~90.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Donoho(2006)]{donoho2006most}
David~L Donoho.
\newblock For most large underdetermined systems of equations, the minimal
  $\ell_1$-norm near-solution approximates the sparsest near-solution.
\newblock \emph{Communications on Pure and Applied Mathematics}, 59\penalty0
  (7):\penalty0 907--934, July 2006.

\bibitem[Elad(2010)]{elad2010sparse}
Michael Elad.
\newblock \emph{Sparse and Redundant Representations: From Theory to
  Applications in Signal and Image Processing}.
\newblock Springer Science \& Business Media, 2010.

\bibitem[Duchi et~al.(2008)Duchi, Shalev-Shwartz, Singer, and
  Chandra]{duchi2008efficient}
John Duchi, Shai Shalev-Shwartz, Yoram Singer, and Tushar Chandra.
\newblock Efficient projections onto the $\ell_1$-ball for learning in high
  dimensions.
\newblock In \emph{Proceedings of the 25th International Conference on Machine
  learning}, pages 272--279, July 2008.

\bibitem[Babatas and Erdogan(2018)]{babatas2018algorithmic}
Eren Babatas and Alper~T Erdogan.
\newblock An algorithmic framework for sparse bounded component analysis.
\newblock \emph{IEEE Transactions on Signal Processing}, 66\penalty0
  (19):\penalty0 5194--5205, August 2018.

\bibitem[Studer et~al.(2014)Studer, Goldstein, Yin, and
  Baraniuk]{studer2014democratic}
Christoph Studer, Tom Goldstein, Wotao Yin, and Richard~G Baraniuk.
\newblock Democratic representations.
\newblock \emph{arXiv preprint arXiv:1401.3420}, 2014.

\bibitem[Erdogan(2013)]{erdogan2013class}
Alper~T Erdogan.
\newblock A class of bounded component analysis algorithms for the separation
  of both independent and dependent sources.
\newblock \emph{IEEE Transactions on Signal Processing}, 61\penalty0
  (22):\penalty0 5730--5743, August 2013.

\bibitem[Inan and Erdogan(2014)]{inan2014convolutive}
Huseyin~A Inan and Alper~T Erdogan.
\newblock A convolutive bounded component analysis framework for potentially
  nonstationary independent and/or dependent sources.
\newblock \emph{IEEE Transactions on Signal Processing}, 63\penalty0
  (1):\penalty0 18--30, November 2014.

\bibitem[Bozkurt et~al.(2022)Bozkurt, Pehlevan, and
  Erdogan]{bozkurt2022biologicallyplausible}
Bariscan Bozkurt, Cengiz Pehlevan, and Alper~Tunga Erdogan.
\newblock Biologically-plausible determinant maximization neural networks for
  blind separation of correlated sources.
\newblock In Alice~H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho,
  editors, \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=espX_4CLr46}.

\bibitem[Rozell et~al.(2008)Rozell, Johnson, Baraniuk, and
  Olshausen]{rozell:2008}
Christopher~J Rozell, Don~H Johnson, Richard~G Baraniuk, and Bruno~A Olshausen.
\newblock Sparse coding via thresholding and local competition in neural
  circuits.
\newblock \emph{Neural computation}, 20\penalty0 (10):\penalty0 2526--2563,
  2008.

\bibitem[Boyd and Vandenberghe(2004)]{boyd2004convex}
Stephen Boyd and Lieven Vandenberghe.
\newblock \emph{Convex optimization}.
\newblock Cambridge university press, 2004.

\bibitem[Parikh et~al.(2014)Parikh, Boyd, et~al.]{parikh2014proximal}
Neal Parikh, Stephen Boyd, et~al.
\newblock Proximal algorithms.
\newblock \emph{Foundations and trends{\textregistered} in Optimization},
  1\penalty0 (3):\penalty0 127--239, 2014.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{paszke2017automatic}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pages
  8024--8035. Curran Associates, Inc., 2019.
\newblock URL
  \url{http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}.

\end{thebibliography}
