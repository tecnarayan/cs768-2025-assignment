\begin{thebibliography}{55}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andriushchenko et~al.(2020)Andriushchenko, Croce, Flammarion, and
  Hein]{Andriushchenko2020square}
Andriushchenko, M., Croce, F., Flammarion, N., and Hein, M.
\newblock Square attack: a query-efficient black-box adversarial attack via
  random search.
\newblock In \emph{European Conference on Computer Vision}, pp.\  484--501.
  Springer, 2020.

\bibitem[AprilPyone \& Kiya(2020)AprilPyone and Kiya]{Aprilpyone2020extension}
AprilPyone, M. and Kiya, H.
\newblock An extension of encryption-inspired adversarial defense with secret
  keys against adversarial examples.
\newblock In \emph{2020 Asia-Pacific Signal and Information Processing
  Association Annual Summit and Conference (APSIPA ASC)}, pp.\  1369--1374.
  IEEE, 2020.

\bibitem[AprilPyone \& Kiya(2021{\natexlab{a}})AprilPyone and
  Kiya]{Aprilpyone2021block}
AprilPyone, M. and Kiya, H.
\newblock Block-wise image transformation with secret key for adversarially
  robust defense.
\newblock \emph{IEEE Transactions on Information Forensics and Security},
  16:\penalty0 2709--2723, 2021{\natexlab{a}}.

\bibitem[AprilPyone \& Kiya(2021{\natexlab{b}})AprilPyone and
  Kiya]{Aprilpyone2021transfer}
AprilPyone, M. and Kiya, H.
\newblock Transfer learning-based model protection with secret key.
\newblock \emph{arXiv preprint arXiv:2103.03525}, 2021{\natexlab{b}}.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and
  Wagner]{Athalye2018obfuscated}
Athalye, A., Carlini, N., and Wagner, D.~A.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In \emph{ICML}, 2018.

\bibitem[Bradbury et~al.(2018)Bradbury, Frostig, Hawkins, Johnson, Leary,
  Maclaurin, Necula, Paszke, Vander{P}las, Wanderman-{M}ilne, and
  Zhang]{jax2018github}
Bradbury, J., Frostig, R., Hawkins, P., Johnson, M.~J., Leary, C., Maclaurin,
  D., Necula, G., Paszke, A., Vander{P}las, J., Wanderman-{M}ilne, S., and
  Zhang, Q.
\newblock {JAX}: composable transformations of {P}ython+{N}um{P}y programs.
\newblock 2018.
\newblock URL \url{http://github.com/google/jax}.

\bibitem[Brendel et~al.(2018)Brendel, Rauber, and Bethge]{Brendel2018decision}
Brendel, W., Rauber, J., and Bethge, M.
\newblock Decision-based adversarial attacks: Reliable attacks against
  black-box machine learning models.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Carlini \& Wagner(2017{\natexlab{a}})Carlini and
  Wagner]{Carlini2017adversarial}
Carlini, N. and Wagner, D.
\newblock Adversarial examples are not easily detected: Bypassing ten detection
  methods.
\newblock In \emph{Proceedings of the 10th ACM workshop on artificial
  intelligence and security}, pp.\  3--14, 2017{\natexlab{a}}.

\bibitem[Carlini \& Wagner(2017{\natexlab{b}})Carlini and
  Wagner]{CarliniWagner2017towards}
Carlini, N. and Wagner, D.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{2017 ieee symposium on security and privacy (sp)}, pp.\
  39--57. IEEE, 2017{\natexlab{b}}.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and Kolter]{Cohen2019certified}
Cohen, J., Rosenfeld, E., and Kolter, Z.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1310--1320. PMLR, 2019.

\bibitem[Croce \& Hein(2020)Croce and Hein]{CroceHein2020reliable}
Croce, F. and Hein, M.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock In \emph{International conference on machine learning}, pp.\
  2206--2216. PMLR, 2020.

\bibitem[Das et~al.(2017)Das, Shanbhogue, Chen, Hohman, Chen, Kounavis, and
  Chau]{Das2017keeping}
Das, N., Shanbhogue, M., Chen, S.-T., Hohman, F., Chen, L., Kounavis, M.~E.,
  and Chau, D.~H.
\newblock Keeping the bad guys out: Protecting and vaccinating deep learning
  with jpeg compression.
\newblock \emph{arXiv preprint arXiv:1705.02900}, 2017.

\bibitem[Das et~al.(2018)Das, Shanbhogue, Chen, Hohman, Li, Chen, Kounavis, and
  Chau]{Das2018shield}
Das, N., Shanbhogue, M., Chen, S.-T., Hohman, F., Li, S., Chen, L., Kounavis,
  M.~E., and Chau, D.~H.
\newblock Shield: Fast, practical defense and vaccination for deep learning
  using jpeg compression.
\newblock In \emph{Proceedings of the 24th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pp.\  196--204, 2018.

\bibitem[Dhillon et~al.(2018)Dhillon, Azizzadenesheli, Lipton, Bernstein,
  Kossaifi, Khanna, and Anandkumar]{Dhillon2018stochastic}
Dhillon, G.~S., Azizzadenesheli, K., Lipton, Z.~C., Bernstein, J.~D., Kossaifi,
  J., Khanna, A., and Anandkumar, A.
\newblock Stochastic activation pruning for robust adversarial defense.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Dziugaite et~al.(2016)Dziugaite, Ghahramani, and
  Roy]{Dziugaite2016study}
Dziugaite, G.~K., Ghahramani, Z., and Roy, D.~M.
\newblock A study of the effect of jpg compression on adversarial images.
\newblock \emph{arXiv preprint arXiv:1608.00853}, 2016.

\bibitem[Engstrom et~al.(2019)Engstrom, Ilyas, Santurkar, Tsipras, Tran, and
  Madry]{Engstrom2019adversarial}
Engstrom, L., Ilyas, A., Santurkar, S., Tsipras, D., Tran, B., and Madry, A.
\newblock Adversarial robustness as a prior for learned representations.
\newblock \emph{arXiv preprint arXiv:1906.00945}, 2019.

\bibitem[Frostig et~al.(2018)Frostig, Johnson, and Leary]{Frostig2018compiling}
Frostig, R., Johnson, M.~J., and Leary, C.
\newblock Compiling machine learning programs via high-level tracing.
\newblock \emph{Systems for Machine Learning}, 2018.

\bibitem[Garg et~al.(2020)Garg, Jha, Mahloujifar, and
  Mohammad]{Garg2020adversarially}
Garg, S., Jha, S., Mahloujifar, S., and Mohammad, M.
\newblock Adversarially robust learning could leverage computational hardness.
\newblock In \emph{Algorithmic Learning Theory}, pp.\  364--385. PMLR, 2020.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and
  Szegedy]{Goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[Gowal et~al.(2019)Gowal, Uesato, Qin, Huang, Mann, and
  Kohli]{Gowal2019alternative}
Gowal, S., Uesato, J., Qin, C., Huang, P., Mann, T.~A., and Kohli, P.
\newblock An alternative surrogate loss for pgd-based adversarial testing.
\newblock \emph{CoRR}, abs/1910.09338, 2019.
\newblock URL \url{http://arxiv.org/abs/1910.09338}.

\bibitem[Gowal et~al.(2020)Gowal, Qin, Uesato, Mann, and
  Kohli]{Gowal2020uncovering}
Gowal, S., Qin, C., Uesato, J., Mann, T., and Kohli, P.
\newblock Uncovering the limits of adversarial training against norm-bounded
  adversarial examples.
\newblock \emph{arXiv preprint arXiv:2010.03593}, 2020.

\bibitem[Guo et~al.(2018)Guo, Rana, Cisse, and van~der
  Maaten]{Guo2018countering}
Guo, C., Rana, M., Cisse, M., and van~der Maaten, L.
\newblock Countering adversarial images using input transformations.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=SyJ7ClWCb}.

\bibitem[Harris et~al.(2020)Harris, Millman, van~der Walt, Gommers, Virtanen,
  Cournapeau, Wieser, Taylor, Berg, Smith, Kern, Picus, Hoyer, van Kerkwijk,
  Brett, Haldane, del R{\'{i}}o, Wiebe, Peterson, G{\'{e}}rard-Marchant,
  Sheppard, Reddy, Weckesser, Abbasi, Gohlke, and Oliphant]{Harris2020array}
Harris, C.~R., Millman, K.~J., van~der Walt, S.~J., Gommers, R., Virtanen, P.,
  Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N.~J., Kern, R.,
  Picus, M., Hoyer, S., van Kerkwijk, M.~H., Brett, M., Haldane, A., del
  R{\'{i}}o, J.~F., Wiebe, M., Peterson, P., G{\'{e}}rard-Marchant, P.,
  Sheppard, K., Reddy, T., Weckesser, W., Abbasi, H., Gohlke, C., and Oliphant,
  T.~E.
\newblock Array programming with {NumPy}.
\newblock \emph{Nature}, 585\penalty0 (7825):\penalty0 357--362, September
  2020.
\newblock \doi{10.1038/s41586-020-2649-2}.
\newblock URL \url{https://doi.org/10.1038/s41586-020-2649-2}.

\bibitem[He et~al.(2017)He, Wei, Chen, Carlini, and Song]{He2017adversarial}
He, W., Wei, J., Chen, X., Carlini, N., and Song, D.
\newblock Adversarial example defenses: ensembles of weak defenses are not
  strong.
\newblock In \emph{Proceedings of the 11th USENIX Conference on Offensive
  Technologies}, pp.\  15--15, 2017.

\bibitem[Hein \& Andriushchenko(2017)Hein and Andriushchenko]{Hein2017formal}
Hein, M. and Andriushchenko, M.
\newblock Formal guarantees on the robustness of a classifier against
  adversarial manipulation.
\newblock In \emph{Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, pp.\  2263--2273, 2017.

\bibitem[Ilyas et~al.(2019)Ilyas, Santurkar, Tsipras, Engstrom, Tran, and
  Madry]{Ilyas2019bugs}
Ilyas, A., Santurkar, S., Tsipras, D., Engstrom, L., Tran, B., and Madry, A.
\newblock Adversarial examples are not bugs, they are features.
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A., d\textquotesingle
  Alch\'{e}-Buc, F., Fox, E., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2019/file/e2c420d928d4bf8ce0ff2ec19b371514-Paper.pdf}.

\bibitem[Jacobsen et~al.(2018)Jacobsen, Behrmann, Zemel, and
  Bethge]{Jacobsen2018excessive}
Jacobsen, J.-H., Behrmann, J., Zemel, R., and Bethge, M.
\newblock Excessive invariance causes adversarial vulnerability.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{Kingma2015adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{ICLR (Poster)}, 2015.

\bibitem[Kurakin et~al.(2018)Kurakin, Goodfellow, Bengio, Dong, Liao, Liang,
  Pang, Zhu, Hu, Xie, et~al.]{Kurakin2018adversarial}
Kurakin, A., Goodfellow, I., Bengio, S., Dong, Y., Liao, F., Liang, M., Pang,
  T., Zhu, J., Hu, X., Xie, C., et~al.
\newblock Adversarial attacks and defences competition.
\newblock In \emph{The NIPS'17 Competition: Building Intelligent Systems}, pp.\
   195--231. Springer, 2018.

\bibitem[Liao et~al.(2018)Liao, Liang, Dong, Pang, Hu, and
  Zhu]{Liao2018defense}
Liao, F., Liang, M., Dong, Y., Pang, T., Hu, X., and Zhu, J.
\newblock Defense against adversarial attacks using high-level representation
  guided denoiser, 2018.

\bibitem[Loshchilov \& Hutter(2016)Loshchilov and Hutter]{Loshchilov2016SGRD}
Loshchilov, I. and Hutter, F.
\newblock {SGDR:} stochastic gradient descent with restarts.
\newblock \emph{CoRR}, abs/1608.03983, 2016.
\newblock URL \url{http://arxiv.org/abs/1608.03983}.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{Madry2018at}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=rJzIBfZAb}.

\bibitem[MaungMaung \& Kiya(2021)MaungMaung and Kiya]{Maungmaung2021protection}
MaungMaung, A. and Kiya, H.
\newblock A protection method of trained cnn model with secret key from
  unauthorized access.
\newblock \emph{arXiv preprint arXiv:2105.14756}, 2021.

\bibitem[Mildenhall et~al.(2020)Mildenhall, Srinivasan, Tancik, Barron,
  Ramamoorthi, and Ng]{Mildenhall2020nerf}
Mildenhall, B., Srinivasan, P.~P., Tancik, M., Barron, J.~T., Ramamoorthi, R.,
  and Ng, R.
\newblock Nerf: Representing scenes as neural radiance fields for view
  synthesis.
\newblock In \emph{European conference on computer vision (ECCV)}, pp.\
  405--421. Springer, 2020.

\bibitem[Niu et~al.(2020)Niu, Chen, Li, Yang, Li, and Yi]{Niu2020limitations}
Niu, Z., Chen, Z., Li, L., Yang, Y., Li, B., and Yi, J.
\newblock On the limitations of denoising strategies as adversarial defenses.
\newblock \emph{CoRR}, abs/2012.09384, 2020.
\newblock URL \url{https://arxiv.org/abs/2012.09384}.

\bibitem[Pang et~al.(2020)Pang, Yang, Dong, Su, and Zhu]{Pang2020bag}
Pang, T., Yang, X., Dong, Y., Su, H., and Zhu, J.
\newblock Bag of tricks for adversarial training.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Papernot et~al.(2017)Papernot, McDaniel, Goodfellow, Jha, Celik, and
  Swami]{Papernot2017practical}
Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.~B., and Swami,
  A.
\newblock Practical black-box attacks against machine learning.
\newblock In \emph{Proceedings of the 2017 ACM on Asia conference on computer
  and communications security}, pp.\  506--519, 2017.

\bibitem[Raghunathan et~al.(2018)Raghunathan, Steinhardt, and
  Liang]{Raghunathan2018certified}
Raghunathan, A., Steinhardt, J., and Liang, P.
\newblock Certified defenses against adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Ramachandran et~al.(2017)Ramachandran, Zoph, and
  Le]{Ramachandran2017searching}
Ramachandran, P., Zoph, B., and Le, Q.~V.
\newblock Searching for activation functions.
\newblock \emph{CoRR}, abs/1710.05941, 2017.
\newblock URL \url{http://arxiv.org/abs/1710.05941}.

\bibitem[Rebuffi et~al.(2021)Rebuffi, Gowal, Calian, Stimberg, Wiles, and
  Mann]{Rebuffi2021fixing}
Rebuffi, S.-A., Gowal, S., Calian, D.~A., Stimberg, F., Wiles, O., and Mann, T.
\newblock Fixing data augmentation to improve adversarial robustness.
\newblock \emph{arXiv preprint arXiv:2103.01946}, 2021.

\bibitem[Schmidt et~al.(2018)Schmidt, Santurkar, Tsipras, Talwar, and
  Madry]{Schmidt2018adversarially}
Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., and Madry, A.
\newblock Adversarially robust generalization requires more data.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Schott et~al.(2019)Schott, Rauber, Bethge, and
  Brendel]{Schott2019towards}
Schott, L., Rauber, J., Bethge, M., and Brendel, W.
\newblock Towards the first adversarially robust neural network model on mnist.
\newblock In \emph{Seventh International Conference on Learning Representations
  (ICLR 2019)}, pp.\  1--16, 2019.

\bibitem[Shaham et~al.(2018)Shaham, Garritano, Yamada, Weinberger, Cloninger,
  Cheng, Stanton, and Kluger]{Shaham2018defending}
Shaham, U., Garritano, J., Yamada, Y., Weinberger, E., Cloninger, A., Cheng,
  X., Stanton, K., and Kluger, Y.
\newblock Defending against adversarial images using basis functions
  transformations.
\newblock \emph{arXiv preprint arXiv:1803.10840}, 2018.

\bibitem[Sitzmann(2020)]{Sitzmann2020list}
Sitzmann, V.
\newblock {Awesome Implicit Representations - A curated list of resources on
  implicit neural representations}.
\newblock 2020.
\newblock URL
  \url{https://github.com/vsitzmann/awesome-implicit-representations}.

\bibitem[Sitzmann et~al.(2020)Sitzmann, Martel, Bergman, Lindell, and
  Wetzstein]{Sitzmann2020implicit}
Sitzmann, V., Martel, J., Bergman, A., Lindell, D., and Wetzstein, G.
\newblock Implicit neural representations with periodic activation functions.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Skorokhodov et~al.(2021)Skorokhodov, Ignatyev, and
  Elhoseiny]{Skorokhodov2021adversarial}
Skorokhodov, I., Ignatyev, S., and Elhoseiny, M.
\newblock Adversarial generation of continuous images.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  10753--10764, 2021.

\bibitem[Song et~al.(2018{\natexlab{a}})Song, Chen, Cheung, and
  Kuo]{Song2018defense}
Song, S., Chen, Y., Cheung, N.-M., and Kuo, C.-C.~J.
\newblock Defense against adversarial attacks with saak transform.
\newblock \emph{arXiv preprint arXiv:1808.01785}, 2018{\natexlab{a}}.

\bibitem[Song et~al.(2018{\natexlab{b}})Song, Kim, Nowozin, Ermon, and
  Kushman]{Song2018pixeldefend}
Song, Y., Kim, T., Nowozin, S., Ermon, S., and Kushman, N.
\newblock Pixeldefend: Leveraging generative models to understand and defend
  against adversarial examples.
\newblock In \emph{International Conference on Learning Representations},
  2018{\natexlab{b}}.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{Szegedy2014intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2014.
\newblock URL \url{http://arxiv.org/abs/1312.6199}.

\bibitem[Tieleman \& Hinton(2012)Tieleman and Hinton]{Tieleman2012lecture}
Tieleman, T. and Hinton, G.
\newblock Lecture 6.5-rmsprop, coursera: Neural networks for machine learning.
\newblock \emph{University of Toronto, Technical Report}, 2012.

\bibitem[Tramer et~al.(2020)Tramer, Carlini, Brendel, and
  Madry]{Tramer2020adaptive}
Tramer, F., Carlini, N., Brendel, W., and Madry, A.
\newblock On adaptive attacks to adversarial example defenses.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Wong \& Kolter(2018)Wong and Kolter]{Wong2018provable}
Wong, E. and Kolter, J.~Z.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock In \emph{ICML}, 2018.

\bibitem[Yang et~al.(2019)Yang, Zhang, Katabi, and Xu]{Yang2019me}
Yang, Y., Zhang, G., Katabi, D., and Xu, Z.
\newblock Me-net: Towards effective adversarial robustness with matrix
  estimation.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7025--7034. PMLR, 2019.

\bibitem[Yun et~al.(2019)Yun, Han, Oh, Chun, Choe, and Yoo]{Yun2019cutmix}
Yun, S., Han, D., Oh, S.~J., Chun, S., Choe, J., and Yoo, Y.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock \emph{CoRR}, abs/1905.04899, 2019.
\newblock URL \url{http://arxiv.org/abs/1905.04899}.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and
  Komodakis]{ZagoruykoKomodakis2016wrn}
Zagoruyko, S. and Komodakis, N.
\newblock Wide residual networks.
\newblock In \emph{British Machine Vision Conference 2016}. British Machine
  Vision Association, 2016.

\end{thebibliography}
