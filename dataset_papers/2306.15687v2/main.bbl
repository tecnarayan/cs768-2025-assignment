\begin{thebibliography}{79}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aghajanyan et~al.(2023)Aghajanyan, Yu, Conneau, Hsu, Hambardzumyan,
  Zhang, Roller, Goyal, Levy, and Zettlemoyer]{Aghajanyan2023ScalingLF}
A.~Aghajanyan, L.~Yu, A.~Conneau, W.-N. Hsu, K.~Hambardzumyan, S.~Zhang,
  S.~Roller, N.~Goyal, O.~Levy, and L.~Zettlemoyer.
\newblock Scaling laws for generative mixed-modal language models.
\newblock \emph{ArXiv}, abs/2301.03728, 2023.

\bibitem[Akuzawa et~al.(2018)Akuzawa, Iwasawa, and
  Matsuo]{Akuzawa2018ExpressiveSS}
K.~Akuzawa, Y.~Iwasawa, and Y.~Matsuo.
\newblock Expressive speech synthesis via modeling expressions with variational
  autoencoder.
\newblock \emph{ArXiv}, abs/1804.02135, 2018.

\bibitem[Ardila et~al.(2019)Ardila, Branson, Davis, Henretty, Kohler, Meyer,
  Morais, Saunders, Tyers, and Weber]{Ardila2019CommonVA}
R.~Ardila, M.~Branson, K.~Davis, M.~Henretty, M.~Kohler, J.~Meyer, R.~Morais,
  L.~Saunders, F.~M. Tyers, and G.~Weber.
\newblock Common voice: A massively-multilingual speech corpus.
\newblock In \emph{International Conference on Language Resources and
  Evaluation}, 2019.

\bibitem[Babu et~al.(2022)Babu, Wang, Tjandra, Lakhotia, Xu, Goyal, Singh, von
  Platen, Saraf, Pino, Baevski, Conneau, and Auli]{Babu2022XLSR}
A.~Babu, C.~Wang, A.~Tjandra, K.~Lakhotia, Q.~Xu, N.~Goyal, K.~Singh, P.~von
  Platen, Y.~Saraf, J.~Pino, A.~Baevski, A.~Conneau, and M.~Auli.
\newblock {XLS-R:} self-supervised cross-lingual speech representation learning
  at scale.
\newblock In H.~Ko and J.~H.~L. Hansen, editors, \emph{Interspeech 2022, 23rd
  Annual Conference of the International Speech Communication Association,
  Incheon, Korea, 18-22 September 2022}, pages 2278--2282. {ISCA}, 2022.

\bibitem[Baevski et~al.(2020)Baevski, Zhou, Mohamed, and
  Auli]{baevski2020wav2vec}
A.~Baevski, Y.~Zhou, A.~Mohamed, and M.~Auli.
\newblock wav2vec 2.0: A framework for self-supervised learning of speech
  representations.
\newblock \emph{Advances in neural information processing systems}, 2020.

\bibitem[Bai et~al.(2022)Bai, Zheng, Chen, Li, Ma, and Huang]{Bai2022A3TAA}
H.~Bai, R.~Zheng, J.~Chen, X.~Li, M.~Ma, and L.~Huang.
\newblock {A3T}: Alignment-aware acoustic and text pretraining for speech
  synthesis and editing.
\newblock In \emph{International Conference on Machine Learning}, 2022.

\bibitem[Borsos et~al.(2022{\natexlab{a}})Borsos, Marinier, Vincent,
  Kharitonov, Pietquin, Sharifi, Teboul, Grangier, Tagliasacchi, and
  Zeghidour]{Borsos2022AudioLMAL}
Z.~Borsos, R.~Marinier, D.~Vincent, E.~Kharitonov, O.~Pietquin, M.~Sharifi,
  O.~Teboul, D.~Grangier, M.~Tagliasacchi, and N.~Zeghidour.
\newblock {AudioLM}: a language modeling approach to audio generation.
\newblock \emph{ArXiv}, abs/2209.03143, 2022{\natexlab{a}}.

\bibitem[Borsos et~al.(2022{\natexlab{b}})Borsos, Sharifi, and
  Tagliasacchi]{Borsos2022SpeechPainterTS}
Z.~Borsos, M.~Sharifi, and M.~Tagliasacchi.
\newblock {SpeechPainter}: Text-conditioned speech inpainting.
\newblock In \emph{Interspeech}, 2022{\natexlab{b}}.

\bibitem[Brock et~al.(2018)Brock, Donahue, and Simonyan]{brock2018large}
A.~Brock, J.~Donahue, and K.~Simonyan.
\newblock Large scale gan training for high fidelity natural image synthesis.
\newblock \emph{arXiv preprint arXiv:1809.11096}, 2018.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, McCandlish, Radford, Sutskever, and
  Amodei]{Brown2020LanguageMA}
T.~B. Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~Kaplan, P.~Dhariwal,
  A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell, S.~Agarwal, A.~Herbert-Voss,
  G.~Krueger, T.~J. Henighan, R.~Child, A.~Ramesh, D.~M. Ziegler, J.~Wu,
  C.~Winter, C.~Hesse, M.~Chen, E.~Sigler, M.~Litwin, S.~Gray, B.~Chess,
  J.~Clark, C.~Berner, S.~McCandlish, A.~Radford, I.~Sutskever, and D.~Amodei.
\newblock Language models are few-shot learners.
\newblock \emph{ArXiv}, abs/2005.14165, 2020.

\bibitem[Casanova et~al.(2021)Casanova, Weber, Shulby, J{\'u}nior, G{\"o}lge,
  and Ponti]{Casanova2021YourTTSTZ}
E.~Casanova, J.~Weber, C.~D. Shulby, A.~C. J{\'u}nior, E.~G{\"o}lge, and M.~A.
  Ponti.
\newblock {YourTTS}: Towards zero-shot multi-speaker tts and zero-shot voice
  conversion for everyone.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Casanova et~al.(2022)Casanova, Junior, Shulby, Oliveira, Teixeira,
  Ponti, and Alu{\'\i}sio]{casanova2022tts}
E.~Casanova, A.~C. Junior, C.~Shulby, F.~S.~d. Oliveira, J.~P. Teixeira, M.~A.
  Ponti, and S.~Alu{\'\i}sio.
\newblock Tts-portuguese corpus: a corpus for speech synthesis in brazilian
  portuguese.
\newblock \emph{Language Resources and Evaluation}, 56\penalty0 (3):\penalty0
  1043--1055, 2022.

\bibitem[Chen(2018)]{torchdiffeq}
R.~T.~Q. Chen.
\newblock torchdiffeq, 2018.
\newblock URL \url{https://github.com/rtqichen/torchdiffeq}.

\bibitem[Chen et~al.(2018)Chen, Rubanova, Bettencourt, and Duvenaud]{cnf}
R.~T.~Q. Chen, Y.~Rubanova, J.~Bettencourt, and D.~K. Duvenaud.
\newblock Neural ordinary differential equations.
\newblock In \emph{Neural Information Processing Systems}, 2018.

\bibitem[Chen et~al.(2022)Chen, Wang, Chen, Wu, Liu, Chen, Li, Kanda, Yoshioka,
  Xiao, et~al.]{Chen2021WavLMLS}
S.~Chen, C.~Wang, Z.~Chen, Y.~Wu, S.~Liu, Z.~Chen, J.~Li, N.~Kanda,
  T.~Yoshioka, X.~Xiao, et~al.
\newblock Wavlm: Large-scale self-supervised pre-training for full stack speech
  processing.
\newblock \emph{IEEE Journal of Selected Topics in Signal Processing},
  16\penalty0 (6):\penalty0 1505--1518, 2022.

\bibitem[D{\'e}fossez et~al.(2020)D{\'e}fossez, Synnaeve, and
  Adi]{defossez2020real}
A.~D{\'e}fossez, G.~Synnaeve, and Y.~Adi.
\newblock Real time speech enhancement in the waveform domain.
\newblock \emph{ArXiv}, abs/2006.12847, 2020.

\bibitem[D{\'e}fossez et~al.(2022)D{\'e}fossez, Copet, Synnaeve, and
  Adi]{Defossez2022HighFN}
A.~D{\'e}fossez, J.~Copet, G.~Synnaeve, and Y.~Adi.
\newblock High fidelity neural audio compression.
\newblock \emph{ArXiv}, abs/2210.13438, 2022.

\bibitem[Desplanques et~al.(2020)Desplanques, Thienpondt, and
  Demuynck]{desplanques2020ecapa}
B.~Desplanques, J.~Thienpondt, and K.~Demuynck.
\newblock {ECAPA-TDNN: Emphasized Channel Attention, propagation and
  aggregation in TDNN based speaker verification}.
\newblock In \emph{Interspeech}, 2020.

\bibitem[Dhariwal and Nichol(2021)]{dhariwal2021diffusion}
P.~Dhariwal and A.~Nichol.
\newblock Diffusion models beat {GANs} on image synthesis.
\newblock \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Godfrey et~al.(1992)Godfrey, Holliman, and
  McDaniel]{godfrey1992switchboard}
J.~J. Godfrey, E.~C. Holliman, and J.~McDaniel.
\newblock Switchboard: Telephone speech corpus for research and development.
\newblock In \emph{Acoustics, Speech, and Signal Processing, IEEE International
  Conference on}, volume~1, pages 517--520. IEEE Computer Society, 1992.

\bibitem[Gulati et~al.(2020)Gulati, Qin, Chiu, Parmar, Zhang, Yu, Han, Wang,
  Zhang, Wu, et~al.]{gulati2020conformer}
A.~Gulati, J.~Qin, C.-C. Chiu, N.~Parmar, Y.~Zhang, J.~Yu, W.~Han, S.~Wang,
  Z.~Zhang, Y.~Wu, et~al.
\newblock Conformer: Convolution-augmented transformer for speech recognition.
\newblock \emph{arXiv preprint arXiv:2005.08100}, 2020.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and
  Hochreiter]{heusel2017gans}
M.~Heusel, H.~Ramsauer, T.~Unterthiner, B.~Nessler, and S.~Hochreiter.
\newblock {GANs} trained by a two time-scale update rule converge to a local
  {Nash} equilibrium.
\newblock \emph{Advances in neural information processing systems}, 2017.

\bibitem[Ho and Salimans(2022)]{ho2022classifier}
J.~Ho and T.~Salimans.
\newblock Classifier-free diffusion guidance.
\newblock \emph{arXiv preprint arXiv:2207.12598}, 2022.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{Ho2020DenoisingDP}
J.~Ho, A.~Jain, and P.~Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Hoffmann et~al.(2022)Hoffmann, Borgeaud, Mensch, Buchatskaya, Cai,
  Rutherford, de~Las~Casas, Hendricks, Welbl, Clark, Hennigan, Noland,
  Millican, van~den Driessche, Damoc, Guy, Osindero, Simonyan, Elsen, Rae,
  Vinyals, and Sifre]{Hoffmann2022TrainingCL}
J.~Hoffmann, S.~Borgeaud, A.~Mensch, E.~Buchatskaya, T.~Cai, E.~Rutherford,
  D.~de~Las~Casas, L.~A. Hendricks, J.~Welbl, A.~Clark, T.~Hennigan, E.~Noland,
  K.~Millican, G.~van~den Driessche, B.~Damoc, A.~Guy, S.~Osindero,
  K.~Simonyan, E.~Elsen, J.~W. Rae, O.~Vinyals, and L.~Sifre.
\newblock Training compute-optimal large language models.
\newblock \emph{ArXiv}, abs/2203.15556, 2022.

\bibitem[Hsu et~al.(2019)Hsu, Zhang, Weiss, Zen, Wu, Wang, Cao, Jia, Chen,
  Shen, et~al.]{Hsu2018HierarchicalGM}
W.-N. Hsu, Y.~Zhang, R.~J. Weiss, H.~Zen, Y.~Wu, Y.~Wang, Y.~Cao, Y.~Jia,
  Z.~Chen, J.~Shen, et~al.
\newblock Hierarchical generative modeling for controllable speech synthesis.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Hsu et~al.(2021)Hsu, Bolte, Tsai, Lakhotia, Salakhutdinov, and
  Mohamed]{Hsu2021HuBERTSS}
W.-N. Hsu, B.~Bolte, Y.-H.~H. Tsai, K.~Lakhotia, R.~Salakhutdinov, and
  A.~Mohamed.
\newblock Hubert: Self-supervised speech representation learning by masked
  prediction of hidden units.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 29:\penalty0 3451--3460, 2021.

\bibitem[Hsu et~al.(2022)Hsu, Remez, Shi, Donley, and Adi]{hsu2022revise}
W.-N. Hsu, T.~Remez, B.~Shi, J.~Donley, and Y.~Adi.
\newblock Revise: Self-supervised speech resynthesis with visual input for
  universal and generalized speech enhancement.
\newblock \emph{arXiv preprint arXiv:2212.11377}, 2022.

\bibitem[Huang et~al.(2022)Huang, Lam, Wang, Su, Yu, Ren, and
  Zhao]{Huang2022FastDiffAF}
R.~Huang, M.~W.~Y. Lam, J.~Wang, D.~Su, D.~Yu, Y.~Ren, and Z.~Zhao.
\newblock {FastDiff}: A fast conditional diffusion model for high-quality
  speech synthesis.
\newblock In \emph{International Joint Conference on Artificial Intelligence},
  2022.

\bibitem[Jia et~al.(2018)Jia, Zhang, Weiss, Wang, Shen, Ren, Nguyen, Pang,
  Lopez~Moreno, Wu, et~al.]{Jia2018TransferLF}
Y.~Jia, Y.~Zhang, R.~Weiss, Q.~Wang, J.~Shen, F.~Ren, P.~Nguyen, R.~Pang,
  I.~Lopez~Moreno, Y.~Wu, et~al.
\newblock Transfer learning from speaker verification to multispeaker
  text-to-speech synthesis.
\newblock \emph{Advances in neural information processing systems}, 2018.

\bibitem[Kahn et~al.(2019)Kahn, Rivi{\`e}re, Zheng, Kharitonov, Xu, Mazar'e,
  Karadayi, Liptchinsky, Collobert, Fuegen, Likhomanenko, Synnaeve, Joulin,
  rahman Mohamed, and Dupoux]{Kahn2019LibriLightAB}
J.~Kahn, M.~Rivi{\`e}re, W.~Zheng, E.~Kharitonov, Q.~Xu, P.-E. Mazar'e,
  J.~Karadayi, V.~Liptchinsky, R.~Collobert, C.~Fuegen, T.~Likhomanenko,
  G.~Synnaeve, A.~Joulin, A.~rahman Mohamed, and E.~Dupoux.
\newblock {Libri-Light}: A benchmark for asr with limited or no supervision.
\newblock \emph{International Conference on Acoustics, Speech and Signal
  Processing}, 2019.

\bibitem[Kameoka et~al.(2018)Kameoka, Kaneko, Tanaka, and
  Hojo]{Kameoka2018StarGANVCNM}
H.~Kameoka, T.~Kaneko, K.~Tanaka, and N.~Hojo.
\newblock {StarGAN-VC}: non-parallel many-to-many voice conversion using star
  generative adversarial networks.
\newblock \emph{IEEE Spoken Language Technology Workshop}, 2018.

\bibitem[Kharitonov et~al.(2021)Kharitonov, Lee, Polyak, Adi, Copet, Lakhotia,
  Nguyen, Rivi{\`e}re, rahman Mohamed, Dupoux, and
  Hsu]{Kharitonov2021TextFreePG}
E.~Kharitonov, A.~Lee, A.~Polyak, Y.~Adi, J.~Copet, K.~Lakhotia, T.~Nguyen,
  M.~Rivi{\`e}re, A.~rahman Mohamed, E.~Dupoux, and W.-N. Hsu.
\newblock Text-free prosody-aware generative spoken language modeling.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics}, 2021.

\bibitem[Kharitonov et~al.(2023)Kharitonov, Vincent, Borsos, Marinier, Girgin,
  Pietquin, Sharifi, Tagliasacchi, and Zeghidour]{spear-tts}
E.~Kharitonov, D.~Vincent, Z.~Borsos, R.~Marinier, S.~Girgin, O.~Pietquin,
  M.~Sharifi, M.~Tagliasacchi, and N.~Zeghidour.
\newblock Speak, read and prompt: High-fidelity text-to-speech with minimal
  supervision, 2023.

\bibitem[Kilgour et~al.(2019)Kilgour, Zuluaga, Roblek, and
  Sharifi]{Kilgour2019FrchetAD}
K.~Kilgour, M.~Zuluaga, D.~Roblek, and M.~Sharifi.
\newblock Fr{\'e}chet audio distance: A reference-free metric for evaluating
  music enhancement algorithms.
\newblock In \emph{Interspeech}, 2019.

\bibitem[Kim et~al.(2020)Kim, Kim, Kong, and Yoon]{Kim2020GlowTTSAG}
J.~Kim, S.~Kim, J.~Kong, and S.~Yoon.
\newblock {Glow-TTS}: A generative flow for text-to-speech via monotonic
  alignment search.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Kim et~al.(2021)Kim, Kong, and Son]{Kim2021ConditionalVA}
J.~Kim, J.~Kong, and J.~Son.
\newblock Conditional variational autoencoder with adversarial learning for
  end-to-end text-to-speech.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Kingma and Ba(2014)]{Kingma2014AdamAM}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{CoRR}, abs/1412.6980, 2014.

\bibitem[Kingma and Dhariwal(2018)]{kingma2018glow}
D.~P. Kingma and P.~Dhariwal.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Kreuk et~al.(2022)Kreuk, Polyak, Copet, Kharitonov, Nguyen,
  Rivi{\`e}re, Hsu, Mohamed, Dupoux, and Adi]{kreuk2021textless}
F.~Kreuk, A.~Polyak, J.~Copet, E.~Kharitonov, T.-A. Nguyen, M.~Rivi{\`e}re,
  W.-N. Hsu, A.~Mohamed, E.~Dupoux, and Y.~Adi.
\newblock Textless speech emotion conversion using decomposed and discrete
  representations.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, 2022.

\bibitem[Kubichek(1993)]{kubichek1993mel}
R.~Kubichek.
\newblock Mel-cepstral distance measure for objective speech quality
  assessment.
\newblock In \emph{Proceedings of IEEE pacific rim conference on communications
  computers and signal processing}, volume~1, pages 125--128. IEEE, 1993.

\bibitem[Lakhotia et~al.(2021)Lakhotia, Kharitonov, Hsu, Adi, Polyak, Bolte,
  Nguyen, Copet, Baevski, Mohamed, and Dupoux]{Lakhotia2021OnGS}
K.~Lakhotia, E.~Kharitonov, W.-N. Hsu, Y.~Adi, A.~Polyak, B.~Bolte, T.~Nguyen,
  J.~Copet, A.~Baevski, A.~B. Mohamed, and E.~Dupoux.
\newblock On generative spoken language modeling from raw audio.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  9:\penalty0 1336--1354, 2021.

\bibitem[{\L}a{\'n}cucki(2021)]{fastpitch}
A.~{\L}a{\'n}cucki.
\newblock Fastpitch: Parallel text-to-speech with pitch prediction.
\newblock In \emph{International Conference on Acoustics, Speech and Signal
  Processing}, 2021.

\bibitem[Le~Roux et~al.(2019)Le~Roux, Wisdom, Erdogan, and Hershey]{le2019sdr}
J.~Le~Roux, S.~Wisdom, H.~Erdogan, and J.~R. Hershey.
\newblock Sdr--half-baked or well done?
\newblock In \emph{ICASSP 2019-2019 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pages 626--630. IEEE, 2019.

\bibitem[Lipman et~al.(2023)Lipman, Chen, Ben-Hamu, Nickel, and
  Le]{flow-matching}
Y.~Lipman, R.~T.~Q. Chen, H.~Ben-Hamu, M.~Nickel, and M.~Le.
\newblock Flow matching for generative modeling.
\newblock In \emph{International Conference on Learning Representations}, 2023.

\bibitem[Lorenzo-Trueba et~al.(2018)Lorenzo-Trueba, Yamagishi, Toda, Saito,
  Villavicencio, Kinnunen, and Ling]{LorenzoTrueba2018TheVC}
J.~Lorenzo-Trueba, J.~Yamagishi, T.~Toda, D.~Saito, F.~Villavicencio, T.~H.
  Kinnunen, and Z.~Ling.
\newblock The voice conversion challenge 2018: Promoting development of
  parallel and nonparallel methods.
\newblock \emph{ArXiv}, abs/1804.04262, 2018.

\bibitem[McAuliffe et~al.(2017)McAuliffe, Socolof, Mihuc, Wagner, and
  Sonderegger]{McAuliffe2017MontrealFA}
M.~McAuliffe, M.~Socolof, S.~Mihuc, M.~Wagner, and M.~Sonderegger.
\newblock Montreal forced aligner: Trainable text-speech alignment using kaldi.
\newblock In \emph{Interspeech}, 2017.

\bibitem[Nguyen et~al.(2022)Nguyen, Kharitonov, Copet, Adi, Hsu, Elkahky,
  Tomasello, Algayres, Sagot, Mohamed, and Dupoux]{Nguyen2022GenerativeSD}
T.~Nguyen, E.~Kharitonov, J.~Copet, Y.~Adi, W.-N. Hsu, A.~M. Elkahky,
  P.~Tomasello, R.~Algayres, B.~Sagot, A.~Mohamed, and E.~Dupoux.
\newblock Generative spoken dialogue language modeling.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  11:\penalty0 250--266, 2022.

\bibitem[Nichol et~al.(2021)Nichol, Dhariwal, Ramesh, Shyam, Mishkin, McGrew,
  Sutskever, and Chen]{Nichol2021GLIDETP}
A.~Nichol, P.~Dhariwal, A.~Ramesh, P.~Shyam, P.~Mishkin, B.~McGrew,
  I.~Sutskever, and M.~Chen.
\newblock {GLIDE}: Towards photorealistic image generation and editing with
  text-guided diffusion models.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Panayotov et~al.(2015)Panayotov, Chen, Povey, and
  Khudanpur]{Panayotov2015LibrispeechAA}
V.~Panayotov, G.~Chen, D.~Povey, and S.~Khudanpur.
\newblock Librispeech: An asr corpus based on public domain audio books.
\newblock \emph{International Conference on Acoustics, Speech and Signal
  Processing}, 2015.

\bibitem[Park et~al.(2019)Park, Chan, Zhang, Chiu, Zoph, Cubuk, and
  Le]{park2019specAugmentAS}
D.~S. Park, W.~Chan, Y.~Zhang, C.-C. Chiu, B.~Zoph, E.~D. Cubuk, and Q.~V. Le.
\newblock {SpecAugment}: A simple data augmentation method for automatic speech
  recognition.
\newblock In \emph{Interspeech}, 2019.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen,
  Z.~Lin, N.~Gimelshein, L.~Antiga, et~al.
\newblock {Pytorch}: An imperative style, high-performance deep learning
  library.
\newblock \emph{Advances in neural information processing systems}, 2019.

\bibitem[Polyak et~al.(2021)Polyak, Adi, Copet, Kharitonov, Lakhotia, Hsu,
  Mohamed, and Dupoux]{polyak2021speech}
A.~Polyak, Y.~Adi, J.~Copet, E.~Kharitonov, K.~Lakhotia, W.-N. Hsu, A.~Mohamed,
  and E.~Dupoux.
\newblock Speech resynthesis from discrete disentangled self-supervised
  representations.
\newblock In \emph{Interspeech}, 2021.

\bibitem[Popov et~al.(2021)Popov, Vovk, Gogoryan, Sadekova, and
  Kudinov]{Popov2021GradTTSAD}
V.~Popov, I.~Vovk, V.~Gogoryan, T.~Sadekova, and M.~Kudinov.
\newblock {Grad-TTS}: A diffusion probabilistic model for text-to-speech.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Povey et~al.(2011)Povey, Ghoshal, Boulianne, Burget, Glembek, Goel,
  Hannemann, Motlicek, Qian, Schwarz, et~al.]{povey2011kaldi}
D.~Povey, A.~Ghoshal, G.~Boulianne, L.~Burget, O.~Glembek, N.~Goel,
  M.~Hannemann, P.~Motlicek, Y.~Qian, P.~Schwarz, et~al.
\newblock The kaldi speech recognition toolkit.
\newblock In \emph{Workshop on automatic speech recognition and understanding},
  2011.

\bibitem[Press et~al.(2021)Press, Smith, and Lewis]{Press2021TrainST}
O.~Press, N.~A. Smith, and M.~Lewis.
\newblock Train short, test long: Attention with linear biases enables input
  length extrapolation.
\newblock \emph{ArXiv}, abs/2108.12409, 2021.

\bibitem[Radford et~al.(2022)Radford, Kim, Xu, Brockman, McLeavey, and
  Sutskever]{Radford2022RobustSR}
A.~Radford, J.~W. Kim, T.~Xu, G.~Brockman, C.~McLeavey, and I.~Sutskever.
\newblock Robust speech recognition via large-scale weak supervision.
\newblock \emph{ArXiv}, abs/2212.04356, 2022.

\bibitem[Ramesh et~al.(2021)Ramesh, Pavlov, Goh, Gray, Voss, Radford, Chen, and
  Sutskever]{Ramesh2021ZeroShotTG}
A.~Ramesh, M.~Pavlov, G.~Goh, S.~Gray, C.~Voss, A.~Radford, M.~Chen, and
  I.~Sutskever.
\newblock Zero-shot text-to-image generation.
\newblock \emph{ArXiv}, abs/2102.12092, 2021.

\bibitem[Ren et~al.(2021)Ren, Hu, Tan, Qin, Zhao, Zhao, and
  Liu]{Ren2020FastSpeech2F}
Y.~Ren, C.~Hu, X.~Tan, T.~Qin, S.~Zhao, Z.~Zhao, and T.-Y. Liu.
\newblock Fastspeech 2: Fast and high-quality end-to-end text to speech.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Ribeiro et~al.(2011)Ribeiro, Flor{\^e}ncio, Zhang, and
  Seltzer]{ribeiro2011crowdmos}
F.~Ribeiro, D.~Flor{\^e}ncio, C.~Zhang, and M.~Seltzer.
\newblock {CrowdMOS}: An approach for crowdsourcing mean opinion score studies.
\newblock In \emph{International Conference on Acoustics, Speech and Signal
  Processing}, 2011.

\bibitem[Robinson et~al.(2019)Robinson, Obin, and Roebel]{robinson2019sequence}
C.~Robinson, N.~Obin, and A.~Roebel.
\newblock Sequence-to-sequence modelling of {F0} for speech emotion conversion.
\newblock In \emph{International Conference on Acoustics, Speech and Signal
  Processing}, 2019.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and
  Ommer]{rombach2022high}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser, and B.~Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2022.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Chang, Lee, Ho, Salimans, Fleet,
  and Norouzi]{saharia2022palette}
C.~Saharia, W.~Chan, H.~Chang, C.~Lee, J.~Ho, T.~Salimans, D.~Fleet, and
  M.~Norouzi.
\newblock Palette: Image-to-image diffusion models.
\newblock In \emph{ACM SIGGRAPH 2022 Conference Proceedings}, 2022.

\bibitem[Serr{\`a} et~al.(2022)Serr{\`a}, Pascual, Pons, Araz, and
  Scaini]{Serr2022UniversalSE}
J.~Serr{\`a}, S.~Pascual, J.~Pons, R.~O. Araz, and D.~Scaini.
\newblock Universal speech enhancement with score-based diffusion.
\newblock \emph{ArXiv}, abs/2206.03065, 2022.

\bibitem[Shen et~al.(2017)Shen, Pang, Weiss, Schuster, Jaitly, Yang, Chen,
  Zhang, Wang, Skerry-Ryan, Saurous, Agiomyrgiannakis, and
  Wu]{Shen2017NaturalTS}
J.~Shen, R.~Pang, R.~J. Weiss, M.~Schuster, N.~Jaitly, Z.~Yang, Z.~Chen,
  Y.~Zhang, Y.~Wang, R.~J. Skerry-Ryan, R.~A. Saurous, Y.~Agiomyrgiannakis, and
  Y.~Wu.
\newblock Natural {TTS} synthesis by conditioning wavenet on mel spectrogram
  predictions.
\newblock \emph{International Conference on Acoustics, Speech and Signal
  Processing}, 2017.

\bibitem[Shen et~al.(2023)Shen, Ju, Tan, Liu, Leng, He, Qin, Zhao, and
  Bian]{shen2023naturalspeech}
K.~Shen, Z.~Ju, X.~Tan, Y.~Liu, Y.~Leng, L.~He, T.~Qin, S.~Zhao, and J.~Bian.
\newblock Naturalspeech 2: Latent diffusion models are natural and zero-shot
  speech and singing synthesizers.
\newblock \emph{arXiv preprint arXiv:2304.09116}, 2023.

\bibitem[Skerry-Ryan et~al.(2018)Skerry-Ryan, Battenberg, Xiao, Wang, Stanton,
  Shor, Weiss, Clark, and Saurous]{skerry2018towards}
R.~Skerry-Ryan, E.~Battenberg, Y.~Xiao, Y.~Wang, D.~Stanton, J.~Shor, R.~Weiss,
  R.~Clark, and R.~A. Saurous.
\newblock Towards end-to-end prosody transfer for expressive speech synthesis
  with tacotron.
\newblock In \emph{international conference on machine learning}, pages
  4693--4702. PMLR, 2018.

\bibitem[Song and Ermon(2019)]{song2019generative}
Y.~Song and S.~Ermon.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Tan et~al.(2022)Tan, Chen, Liu, Cong, Zhang, Liu, Wang, Leng, Yi, He,
  Soong, Qin, Zhao, and Liu]{Tan2022NaturalSpeechET}
X.~Tan, J.~Chen, H.~Liu, J.~Cong, C.~Zhang, Y.~Liu, X.~Wang, Y.~Leng, Y.~Yi,
  L.~He, F.~K. Soong, T.~Qin, S.~Zhao, and T.-Y. Liu.
\newblock {NaturalSpeech}: End-to-end text to speech synthesis with human-level
  quality.
\newblock \emph{ArXiv}, abs/2205.04421, 2022.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{Vaswani2017AttentionIA}
A.~Vaswani, N.~M. Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  L.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock \emph{ArXiv}, abs/1706.03762, 2017.

\bibitem[Wang et~al.(2021)Wang, Hsu, Adi, Polyak, Lee, Chen, Gu, and
  Pino]{Wang2021fairseqSA}
C.~Wang, W.-N. Hsu, Y.~Adi, A.~Polyak, A.~Lee, P.-J. Chen, J.~Gu, and J.~M.
  Pino.
\newblock fairseq s$^2$: A scalable and integrable speech synthesis toolkit.
\newblock In \emph{Conference on Empirical Methods in Natural Language
  Processing}, 2021.

\bibitem[Wang et~al.(2023)Wang, Chen, Wu, Zhang, Zhou, Liu, Chen, Liu, Wang,
  Li, He, Zhao, and Wei]{Wang2023NeuralCL}
C.~Wang, S.~Chen, Y.~Wu, Z.-H. Zhang, L.~Zhou, S.~Liu, Z.~Chen, Y.~Liu,
  H.~Wang, J.~Li, L.~He, S.~Zhao, and F.~Wei.
\newblock Neural codec language models are zero-shot text to speech
  synthesizers.
\newblock \emph{ArXiv}, abs/2301.02111, 2023.

\bibitem[Wang et~al.(2018)Wang, Stanton, Zhang, Skerry-Ryan, Battenberg, Shor,
  Xiao, Ren, Jia, and Saurous]{Wang2018StyleTU}
Y.~Wang, D.~Stanton, Y.~Zhang, R.~J. Skerry-Ryan, E.~Battenberg, J.~Shor,
  Y.~Xiao, F.~Ren, Y.~Jia, and R.~A. Saurous.
\newblock Style tokens: Unsupervised style modeling, control and transfer in
  end-to-end speech synthesis.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Xu et~al.(2014)Xu, Du, Dai, and Lee]{xu2014regression}
Y.~Xu, J.~Du, L.-R. Dai, and C.-H. Lee.
\newblock A regression approach to speech enhancement based on deep neural
  networks.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 23\penalty0 (1):\penalty0 7--19, 2014.

\bibitem[Yamagishi et~al.(2019)Yamagishi, Veaux, and
  MacDonald]{Yamagishi2019CSTRVC}
J.~Yamagishi, C.~Veaux, and K.~MacDonald.
\newblock Cstr vctk corpus: English multi-speaker corpus for cstr voice cloning
  toolkit (version 0.92).
\newblock 2019.

\bibitem[Yamamoto et~al.(2020)Yamamoto, Song, and Kim]{yamamoto2020parallel}
R.~Yamamoto, E.~Song, and J.-M. Kim.
\newblock {Parallel WaveGAN}: A fast waveform generation model based on
  generative adversarial networks with multi-resolution spectrogram.
\newblock In \emph{International Conference on Acoustics, Speech and Signal
  Processing}, 2020.

\bibitem[Yu et~al.(2021)Yu, Skripniuk, Abdelnabi, and Fritz]{yu2021artificial}
N.~Yu, V.~Skripniuk, S.~Abdelnabi, and M.~Fritz.
\newblock Artificial fingerprinting for generative models: Rooting deepfake
  attribution in training data.
\newblock In \emph{Proceedings of the IEEE/CVF International conference on
  computer vision}, pages 14448--14457, 2021.

\bibitem[Zeghidour et~al.(2022)Zeghidour, Luebs, Omran, Skoglund, and
  Tagliasacchi]{Zeghidour2022SoundStreamAE}
N.~Zeghidour, A.~Luebs, A.~Omran, J.~Skoglund, and M.~Tagliasacchi.
\newblock Soundstream: An end-to-end neural audio codec.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 30:\penalty0 495--507, 2022.

\bibitem[Zen et~al.(2019)Zen, Dang, Clark, Zhang, Weiss, Jia, Chen, and
  Wu]{zen2019libritts}
H.~Zen, V.~Dang, R.~Clark, Y.~Zhang, R.~J. Weiss, Y.~Jia, Z.~Chen, and Y.~Wu.
\newblock Libritts: A corpus derived from librispeech for text-to-speech.
\newblock \emph{arXiv preprint arXiv:1904.02882}, 2019.

\end{thebibliography}
