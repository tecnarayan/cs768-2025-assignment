\begin{thebibliography}{101}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou,
  Wierstra, and Riedmiller]{dqn}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1312.5602}, 2013.

\bibitem[Silver et~al.(2017)Silver, Hubert, Schrittwieser, Antonoglou, Lai,
  Guez, Lanctot, Sifre, Kumaran, Graepel, et~al.]{alphazero}
David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew
  Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore
  Graepel, et~al.
\newblock Mastering chess and shogi by self-play with a general reinforcement
  learning algorithm.
\newblock \emph{arXiv preprint arXiv:1712.01815}, 2017.

\bibitem[Vinyals et~al.(2019)Vinyals, Babuschkin, Czarnecki, Mathieu, Dudzik,
  Chung, Choi, Powell, Ewalds, Georgiev, et~al.]{alphastar}
Oriol Vinyals, Igor Babuschkin, Wojciech~M Czarnecki, Micha{\"e}l Mathieu,
  Andrew Dudzik, Junyoung Chung, David~H Choi, Richard Powell, Timo Ewalds,
  Petko Georgiev, et~al.
\newblock Grandmaster level in starcraft ii using multi-agent reinforcement
  learning.
\newblock \emph{Nature}, 575\penalty0 (7782):\penalty0 350--354, 2019.

\bibitem[Kalashnikov et~al.(2018)Kalashnikov, Irpan, Pastor, Ibarz, Herzog,
  Jang, Quillen, Holly, Kalakrishnan, Vanhoucke, et~al.]{qt-opt}
Dmitry Kalashnikov, Alex Irpan, Peter Pastor, Julian Ibarz, Alexander Herzog,
  Eric Jang, Deirdre Quillen, Ethan Holly, Mrinal Kalakrishnan, Vincent
  Vanhoucke, et~al.
\newblock Qt-opt: Scalable deep reinforcement learning for vision-based robotic
  manipulation.
\newblock \emph{arXiv preprint arXiv:1806.10293}, 2018.

\bibitem[OpenAI et~al.(2019)OpenAI, Akkaya, Andrychowicz, Chociej, Litwin,
  McGrew, Petron, Paino, Plappert, Powell, Ribas, Schneider, Tezak, Tworek,
  Welinder, Weng, Yuan, Zaremba, and Zhang]{rubics_cube}
OpenAI, Ilge Akkaya, Marcin Andrychowicz, Maciek Chociej, Mateusz Litwin, Bob
  McGrew, Arthur Petron, Alex Paino, Matthias Plappert, Glenn Powell, Raphael
  Ribas, Jonas Schneider, Nikolas Tezak, Jerry Tworek, Peter Welinder, Lilian
  Weng, Qiming Yuan, Wojciech Zaremba, and Lei Zhang.
\newblock Solving rubik's cube with a robot hand.
\newblock \emph{CoRR}, abs/1910.07113, 2019.

\bibitem[Lee et~al.(2021)Lee, Devin, Zhou, Lampe, Bousmalis, Springenberg,
  Byravan, Abdolmaleki, Gileadi, Khosid, et~al.]{robotic-stacking-shape}
Alex~X Lee, Coline~Manon Devin, Yuxiang Zhou, Thomas Lampe, Konstantinos
  Bousmalis, Jost~Tobias Springenberg, Arunkumar Byravan, Abbas Abdolmaleki,
  Nimrod Gileadi, David Khosid, et~al.
\newblock Beyond pick-and-place: Tackling robotic stacking of diverse shapes.
\newblock In \emph{5th Annual Conference on Robot Learning}, 2021.

\bibitem[Bellemare et~al.(2020)Bellemare, Candido, Castro, Gong, Machado,
  Moitra, Ponda, and Wang]{success-balloons}
Marc~G Bellemare, Salvatore Candido, Pablo~Samuel Castro, Jun Gong, Marlos~C
  Machado, Subhodeep Moitra, Sameera~S Ponda, and Ziyu Wang.
\newblock Autonomous navigation of stratospheric balloons using reinforcement
  learning.
\newblock \emph{Nature}, 588\penalty0 (7836):\penalty0 77--82, 2020.

\bibitem[Degrave et~al.(2022)Degrave, Felici, Buchli, Neunert, Tracey,
  Carpanese, Ewalds, Hafner, Abdolmaleki, de~Las~Casas,
  et~al.]{success-tokamak}
Jonas Degrave, Federico Felici, Jonas Buchli, Michael Neunert, Brendan Tracey,
  Francesco Carpanese, Timo Ewalds, Roland Hafner, Abbas Abdolmaleki, Diego
  de~Las~Casas, et~al.
\newblock Magnetic control of tokamak plasmas through deep reinforcement
  learning.
\newblock \emph{Nature}, 602\penalty0 (7897):\penalty0 414--419, 2022.

\bibitem[Mandhane et~al.(2022)Mandhane, Zhernov, Rauh, Gu, Wang, Xue, Shang,
  Pang, Claus, Chiang, et~al.]{success-youtube-muzero}
Amol Mandhane, Anton Zhernov, Maribeth Rauh, Chenjie Gu, Miaosen Wang, Flora
  Xue, Wendy Shang, Derek Pang, Rene Claus, Ching-Han Chiang, et~al.
\newblock Muzero with self-competition for rate control in vp9 video
  compression.
\newblock \emph{arXiv preprint arXiv:2202.06626}, 2022.

\bibitem[Dulac-Arnold et~al.(2019)Dulac-Arnold, Mankowitz, and
  Hester]{challenges-rl}
Gabriel Dulac-Arnold, Daniel Mankowitz, and Todd Hester.
\newblock Challenges of real-world reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1904.12901}, 2019.

\bibitem[Silver et~al.(2014)Silver, Lever, Heess, Degris, Wierstra, and
  Riedmiller]{dpg}
David Silver, Guy Lever, Nicolas Heess, Thomas Degris, Daan Wierstra, and
  Martin Riedmiller.
\newblock Deterministic policy gradient algorithms.
\newblock 2014.

\bibitem[Lillicrap et~al.(2015)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{ddpg}
Timothy~P Lillicrap, Jonathan~J Hunt, Alexander Pritzel, Nicolas Heess, Tom
  Erez, Yuval Tassa, David Silver, and Daan Wierstra.
\newblock Continuous control with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1509.02971}, 2015.

\bibitem[Haarnoja et~al.(2018{\natexlab{a}})Haarnoja, Zhou, Abbeel, and
  Levine]{sac}
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock In Jennifer Dy and Andreas Krause, editors, \emph{Proceedings of the
  35th International Conference on Machine Learning}, volume~80 of
  \emph{Proceedings of Machine Learning Research}, pages 1861--1870. PMLR,
  10--15 Jul 2018{\natexlab{a}}.
\newblock URL \url{https://proceedings.mlr.press/v80/haarnoja18b.html}.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley,
  Silver, and Kavukcuoglu]{a3c}
Volodymyr Mnih, Adria~Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy
  Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In \emph{International conference on machine learning}, pages
  1928--1937, 2016.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{ppo}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{CoRR}, abs/1707.06347, 2017.
\newblock URL \url{http://arxiv.org/abs/1707.06347}.

\bibitem[Cobbe et~al.(2021)Cobbe, Hilton, Klimov, and Schulman]{ppg}
Karl~W Cobbe, Jacob Hilton, Oleg Klimov, and John Schulman.
\newblock Phasic policy gradient.
\newblock In \emph{International Conference on Machine Learning}, pages
  2020--2027. PMLR, 2021.

\bibitem[Pike(1966)]{cogn-poissSem01966}
AR~Pike.
\newblock Stochastic models of choice behaviour: response probabilities and
  latencies of finite markov chain systems 1.
\newblock \emph{British Journal of Mathematical and Statistical Psychology},
  19\penalty0 (1):\penalty0 15--32, 1966.

\bibitem[Ratcliff(1978)]{cogn-diffSEM01978}
Roger Ratcliff.
\newblock A theory of memory retrieval.
\newblock \emph{Psychological review}, 85\penalty0 (2):\penalty0 59, 1978.

\bibitem[Usher and McClelland(2001)]{cogn-accSEM02001}
Marius Usher and James~L McClelland.
\newblock The time course of perceptual choice: the leaky, competing
  accumulator model.
\newblock \emph{Psychological review}, 108\penalty0 (3):\penalty0 550, 2001.

\bibitem[Brown and Heathcote(2008)]{cogn-linbaccSEM2008}
Scott~D Brown and Andrew Heathcote.
\newblock The simplest complete model of choice response time: Linear ballistic
  accumulation.
\newblock \emph{Cognitive psychology}, 57\penalty0 (3):\penalty0 153--178,
  2008.

\bibitem[Gold and Shadlen(2001)]{cogn-diffNeuro02001inprimates}
Joshua~I Gold and Michael~N Shadlen.
\newblock Neural computations that underlie decisions about sensory stimuli.
\newblock \emph{Trends in cognitive sciences}, 5\penalty0 (1):\penalty0 10--16,
  2001.

\bibitem[van Maanen et~al.(2011)van Maanen, Brown, Eichele, Wagenmakers, Ho,
  Serences, and Forstmann]{cogn-diffNeuro12011}
Leendert van Maanen, Scott~D Brown, Tom Eichele, Eric-Jan Wagenmakers, Tiffany
  Ho, John Serences, and Birte~U Forstmann.
\newblock Neural correlates of trial-to-trial fluctuations in response caution.
\newblock \emph{Journal of Neuroscience}, 31\penalty0 (48):\penalty0
  17488--17495, 2011.

\bibitem[Gluth et~al.(2012)Gluth, Rieskamp, and
  B{\"u}chel]{cogn-diffNeuro22012}
Sebastian Gluth, J{\"o}rg Rieskamp, and Christian B{\"u}chel.
\newblock Deciding when to decide: time-variant sequential sampling models
  explain the emergence of value-based decisions in the human brain.
\newblock \emph{Journal of Neuroscience}, 32\penalty0 (31):\penalty0
  10686--10698, 2012.

\bibitem[Van~Maanen et~al.(2016)Van~Maanen, Fontanesi, Hawkins, and
  Forstmann]{cogn-diffNeuro32016}
Leendert Van~Maanen, Laura Fontanesi, Guy~E Hawkins, and Birte~U Forstmann.
\newblock Striatal activation reflects urgency in perceptual decision making.
\newblock \emph{Neuroimage}, 139:\penalty0 294--303, 2016.

\bibitem[Pedersen et~al.(2017)Pedersen, Frank, and Biele]{cogn-diffRL2017}
Mads~Lund Pedersen, Michael~J Frank, and Guido Biele.
\newblock The drift diffusion model as the choice rule in reinforcement
  learning.
\newblock \emph{Psychonomic bulletin \& review}, 24\penalty0 (4):\penalty0
  1234--1251, 2017.

\bibitem[Fontanesi et~al.(2019)Fontanesi, Gluth, Spektor, and
  Rieskamp]{cogn-diffRL2019}
Laura Fontanesi, Sebastian Gluth, Mikhail~S Spektor, and J{\"o}rg Rieskamp.
\newblock A reinforcement learning diffusion decision model for value-based
  decisions.
\newblock \emph{Psychonomic bulletin \& review}, 26\penalty0 (4):\penalty0
  1099--1121, 2019.

\bibitem[Ziebart(2010)]{maxentobj}
Brian~D Ziebart.
\newblock Modeling purposeful adaptive behavior with the principle of maximum
  causal entropy.
\newblock 2010.

\bibitem[Levine(2018)]{rlasinf6-levineTut}
Sergey Levine.
\newblock Reinforcement learning and control as probabilistic inference:
  Tutorial and review.
\newblock \emph{arXiv preprint arXiv:1805.00909}, 2018.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Zaremba]{gym}
Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman,
  Jie Tang, and Wojciech Zaremba.
\newblock Openai gym.
\newblock \emph{arXiv preprint arXiv:1606.01540}, 2016.

\bibitem[Tassa et~al.(2018)Tassa, Doron, Muldal, Erez, Li, Casas, Budden,
  Abdolmaleki, Merel, Lefrancq, et~al.]{dmc}
Yuval Tassa, Yotam Doron, Alistair Muldal, Tom Erez, Yazhe Li, Diego de~Las
  Casas, David Budden, Abbas Abdolmaleki, Josh Merel, Andrew Lefrancq, et~al.
\newblock Deepmind control suite.
\newblock \emph{arXiv preprint arXiv:1801.00690}, 2018.

\bibitem[Bellman(1957)]{mdp}
Richard Bellman.
\newblock A markovian decision process.
\newblock \emph{Indiana Univ. Math. J.}, 6:\penalty0 679--684, 1957.
\newblock ISSN 0022-2518.

\bibitem[Ziebart et~al.(2008)Ziebart, Maas, Bagnell, and Dey]{maxentirl}
Brian~D Ziebart, Andrew Maas, J~Andrew Bagnell, and Anind~K Dey.
\newblock Maximum entropy inverse reinforcement learning.
\newblock 2008.

\bibitem[Attias(2003)]{rlasinf2-planning}
Hagai Attias.
\newblock Planning by probabilistic inference.
\newblock In \emph{International Workshop on Artificial Intelligence and
  Statistics}, pages 9--16. PMLR, 2003.

\bibitem[Todorov(2008)]{rlasinf3-todorovduality}
Emanuel Todorov.
\newblock General duality between optimal control and estimation.
\newblock In \emph{2008 47th IEEE Conference on Decision and Control}, pages
  4286--4292. IEEE, 2008.

\bibitem[Toussaint and Storkey(2006)]{rlasinf4-mdp}
Marc Toussaint and Amos Storkey.
\newblock Probabilistic inference for solving discrete and continuous state
  markov decision processes.
\newblock In \emph{Proceedings of the 23rd international conference on Machine
  learning}, pages 945--952, 2006.

\bibitem[Ziebart et~al.(2010)Ziebart, Bagnell, and Dey]{rlasinf5-maxentziebart}
Brian~D Ziebart, J~Andrew Bagnell, and Anind~K Dey.
\newblock Modeling interaction via the principle of maximum causal entropy.
\newblock In \emph{ICML}, 2010.

\bibitem[Haarnoja et~al.(2017{\natexlab{a}})Haarnoja, Tang, Abbeel, and
  Levine]{softqfunction}
Tuomas Haarnoja, Haoran Tang, Pieter Abbeel, and Sergey Levine.
\newblock Reinforcement learning with deep energy-based policies.
\newblock In \emph{International Conference on Machine Learning}, pages
  1352--1361. PMLR, 2017{\natexlab{a}}.

\bibitem[Kingma and Welling(2013)]{vae}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Haarnoja et~al.(2018{\natexlab{b}})Haarnoja, Zhou, Hartikainen,
  Tucker, Ha, Tan, Kumar, Zhu, Gupta, Abbeel, et~al.]{sac-alg}
Tuomas Haarnoja, Aurick Zhou, Kristian Hartikainen, George Tucker, Sehoon Ha,
  Jie Tan, Vikash Kumar, Henry Zhu, Abhishek Gupta, Pieter Abbeel, et~al.
\newblock Soft actor-critic algorithms and applications.
\newblock \emph{arXiv preprint arXiv:1812.05905}, 2018{\natexlab{b}}.

\bibitem[Sutton and Barto(2018)]{suttonbarto}
Richard~S. Sutton and Andrew~G. Barto.
\newblock \emph{Reinforcement Learning: An Introduction}.
\newblock A Bradford Book, Cambridge, MA, USA, 2018.
\newblock ISBN 0262039249.

\bibitem[Bengio et~al.(1994)Bengio, Simard, and
  Frasconi]{bengio-vanishing-grad}
Yoshua Bengio, Patrice Simard, and Paolo Frasconi.
\newblock Learning long-term dependencies with gradient descent is difficult.
\newblock \emph{IEEE transactions on neural networks}, 5\penalty0 (2):\penalty0
  157--166, 1994.

\bibitem[Sharma et~al.(2017)Sharma, Lakshminarayanan, and
  Ravindran]{action-reps-policy-factor}
Sahil Sharma, Aravind~S Lakshminarayanan, and Balaraman Ravindran.
\newblock Learning to repeat: Fine grained action repetition for deep
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1702.06054}, 2017.

\bibitem[Dabney et~al.(2020)Dabney, Ostrovski, and Barreto]{epsgreedytemp}
Will Dabney, Georg Ostrovski, and Andr{\'e} Barreto.
\newblock Temporally-extended $\{\backslash$epsilon$\}$-greedy exploration.
\newblock \emph{arXiv preprint arXiv:2006.01782}, 2020.

\bibitem[Rosenthal(1995)]{small-sets-conv-prop}
Jeffrey~S Rosenthal.
\newblock Minorization conditions and convergence rates for markov chain monte
  carlo.
\newblock \emph{Journal of the American Statistical Association}, 90\penalty0
  (430):\penalty0 558--566, 1995.

\bibitem[Baxendale(2005)]{conv-bounds-1}
Peter~H Baxendale.
\newblock Renewal theory and computable convergence rates for geometrically
  ergodic markov chains.
\newblock \emph{The Annals of Applied Probability}, 15\penalty0 (1B):\penalty0
  700--738, 2005.

\bibitem[Andrieu et~al.(2015)Andrieu, Fort, and Vihola]{conv-bounds-2}
Christophe Andrieu, Gersende Fort, and Matti Vihola.
\newblock Quantitative convergence rates for subgeometric markov chains.
\newblock \emph{Journal of Applied Probability}, 52\penalty0 (2):\penalty0
  391--404, 2015.

\bibitem[Cowles and Carlin(1996)]{conv-diagnostics}
Mary~Kathryn Cowles and Bradley~P Carlin.
\newblock Markov chain monte carlo convergence diagnostics: a comparative
  review.
\newblock \emph{Journal of the American Statistical Association}, 91\penalty0
  (434):\penalty0 883--904, 1996.

\bibitem[Brooks and Roberts(1998)]{conv-diagnostics-2}
Stephen~P Brooks and Gareth~O Roberts.
\newblock Assessing convergence of markov chain monte carlo algorithms.
\newblock \emph{Statistics and Computing}, 8\penalty0 (4):\penalty0 319--335,
  1998.

\bibitem[Roy(2020)]{conv-diagnostics-3}
Vivekananda Roy.
\newblock Convergence diagnostics for markov chain monte carlo.
\newblock \emph{Annual Review of Statistics and Its Application}, 7:\penalty0
  387--412, 2020.

\bibitem[Gelman and Rubin(1992)]{gelmanrubin}
Andrew Gelman and Donald~B Rubin.
\newblock Inference from iterative simulation using multiple sequences.
\newblock \emph{Statistical science}, 7\penalty0 (4):\penalty0 457--472, 1992.

\bibitem[Brooks and Gelman(1998)]{gelmanrubin-gen-mult}
Stephen~P Brooks and Andrew Gelman.
\newblock General methods for monitoring convergence of iterative simulations.
\newblock \emph{Journal of computational and graphical statistics}, 7\penalty0
  (4):\penalty0 434--455, 1998.

\bibitem[Vats and Knudson(2021)]{gelmanrubin-revisited}
Dootika Vats and Christina Knudson.
\newblock Revisiting the gelman--rubin diagnostic.
\newblock \emph{Statistical Science}, 36\penalty0 (4):\penalty0 518--529, 2021.

\bibitem[Titterington et~al.(1985)Titterington, Afm, Smith, Makov,
  et~al.]{FiniteMixStatAna}
D~Michael Titterington, Smith Afm, Adrian~FM Smith, UE~Makov, et~al.
\newblock \emph{Statistical analysis of finite mixture distributions}, volume
  198.
\newblock John Wiley \& Sons Incorporated, 1985.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, and
  Courville]{goodfellow-deep-learning}
Ian Goodfellow, Yoshua Bengio, and Aaron Courville.
\newblock \emph{Deep learning}.
\newblock MIT press, 2016.

\bibitem[Agarwal et~al.(2021)Agarwal, Schwarzer, Castro, Courville, and
  Bellemare]{precipice-rliable}
Rishabh Agarwal, Max Schwarzer, Pablo~Samuel Castro, Aaron~C Courville, and
  Marc Bellemare.
\newblock Deep reinforcement learning at the edge of the statistical precipice.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{mujoco}
Emanuel Todorov, Tom Erez, and Yuval Tassa.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{2012 IEEE/RSJ International Conference on Intelligent Robots
  and Systems}, pages 5026--5033, 2012.
\newblock \doi{10.1109/IROS.2012.6386109}.

\bibitem[Dolan and Mor{\'e}(2002)]{perf-profile}
Elizabeth~D Dolan and Jorge~J Mor{\'e}.
\newblock Benchmarking optimization software with performance profiles.
\newblock \emph{Mathematical programming}, 91\penalty0 (2):\penalty0 201--213,
  2002.

\bibitem[Mann and Whitney(1947)]{mannwhitneyUstat}
H.~B. Mann and D.~R. Whitney.
\newblock {On a Test of Whether one of Two Random Variables is Stochastically
  Larger than the Other}.
\newblock \emph{The Annals of Mathematical Statistics}, 18\penalty0
  (1):\penalty0 50 -- 60, 1947.
\newblock \doi{10.1214/aoms/1177730491}.
\newblock URL \url{https://doi.org/10.1214/aoms/1177730491}.

\bibitem[Efron(1992)]{bootstrap-cis}
Bradley Efron.
\newblock Bootstrap methods: another look at the jackknife.
\newblock In \emph{Breakthroughs in statistics}, pages 569--593. Springer,
  1992.

\bibitem[Chen et~al.(2021)Chen, Wang, Zhou, and Ross]{redq}
Xinyue Chen, Che Wang, Zijian Zhou, and Keith Ross.
\newblock Randomized ensembled double q-learning: Learning fast without a
  model.
\newblock \emph{arXiv preprint arXiv:2101.05982}, 2021.

\bibitem[Janner et~al.(2019)Janner, Fu, Zhang, and Levine]{mbpo}
Michael Janner, Justin Fu, Marvin Zhang, and Sergey Levine.
\newblock When to trust your model: Model-based policy optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}. 2019.

\bibitem[Marino et~al.(2021)Marino, Pich{\'e}, Ialongo, and
  Yue]{iterativeAmortizedPolOptim}
Joseph Marino, Alexandre Pich{\'e}, Alessandro~Davide Ialongo, and Yisong Yue.
\newblock Iterative amortized policy optimization.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Marino et~al.(2018)Marino, Yue, and Mandt]{iterativeAmort}
Joe Marino, Yisong Yue, and Stephan Mandt.
\newblock Iterative amortized inference.
\newblock In \emph{International Conference on Machine Learning}, pages
  3403--3412. PMLR, 2018.

\bibitem[Bouthillier et~al.(2021)Bouthillier, Delaunay, Bronzi, Trofimov,
  Nichyporuk, Szeto, Mohammadi~Sepahvand, Raff, Madan, Voleti,
  et~al.]{stat-significance-neyman-pearson}
Xavier Bouthillier, Pierre Delaunay, Mirko Bronzi, Assya Trofimov, Brennan
  Nichyporuk, Justin Szeto, Nazanin Mohammadi~Sepahvand, Edward Raff, Kanika
  Madan, Vikram Voleti, et~al.
\newblock Accounting for variance in machine learning benchmarks.
\newblock \emph{Proceedings of Machine Learning and Systems}, 3:\penalty0
  747--769, 2021.

\bibitem[Dror et~al.(2019)Dror, Shlomov, and Reichart]{stoch-dom}
Rotem Dror, Segev Shlomov, and Roi Reichart.
\newblock Deep dominance-how to properly compare deep neural models.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pages 2773--2785, 2019.

\bibitem[Yarats et~al.(2022)Yarats, Fergus, Lazaric, and Pinto]{drqv2}
Denis Yarats, Rob Fergus, Alessandro Lazaric, and Lerrel Pinto.
\newblock Mastering visual continuous control: Improved data-augmented
  reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=_SJ-_yyes8}.

\bibitem[Kostrikov et~al.(2021)Kostrikov, Yarats, and Fergus]{drq}
Ilya Kostrikov, Denis Yarats, and Rob Fergus.
\newblock Image augmentation is all you need: Regularizing deep reinforcement
  learning from pixels.
\newblock In \emph{International Conference on Learning Representations}. 2021.

\bibitem[Laskin et~al.(2020)Laskin, Srinivas, and Abbeel]{curl}
Michael Laskin, Aravind Srinivas, and Pieter Abbeel.
\newblock {CURL}: Contrastive unsupervised representations for reinforcement
  learning.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, 2020.

\bibitem[Tabak and Turner(2013)]{normflowsSEM}
Esteban~G Tabak and Cristina~V Turner.
\newblock A family of nonparametric density estimation algorithms.
\newblock \emph{Communications on Pure and Applied Mathematics}, 66\penalty0
  (2):\penalty0 145--164, 2013.

\bibitem[Dinh et~al.(2016)Dinh, Sohl-Dickstein, and Bengio]{realnvp}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real nvp.
\newblock \emph{arXiv preprint arXiv:1605.08803}, 2016.

\bibitem[Kobyzev et~al.(2020)Kobyzev, Prince, and
  Brubaker]{flows-review-ind-biases}
Ivan Kobyzev, Simon~JD Prince, and Marcus~A Brubaker.
\newblock Normalizing flows: An introduction and review of current methods.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 43\penalty0 (11):\penalty0 3964--3979, 2020.

\bibitem[Abdolmaleki et~al.(2018)Abdolmaleki, Springenberg, Tassa, Munos,
  Heess, and Riedmiller]{mpo}
Abbas Abdolmaleki, Jost~Tobias Springenberg, Yuval Tassa, Remi Munos, Nicolas
  Heess, and Martin Riedmiller.
\newblock Maximum a posteriori policy optimisation.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Lee et~al.(2019)Lee, Nagabandi, Abbeel, and Levine]{slac}
Alex~X Lee, Anusha Nagabandi, Pieter Abbeel, and Sergey Levine.
\newblock Stochastic latent actor-critic: Deep reinforcement learning with a
  latent variable model.
\newblock \emph{arXiv preprint arXiv:1907.00953}, 2019.

\bibitem[Tang and Agrawal(2018)]{TRPO-norm-flows}
Yunhao Tang and Shipra Agrawal.
\newblock Boosting trust region policy optimization by normalizing flows
  policy.
\newblock \emph{arXiv preprint arXiv:1809.10326}, 2018.

\bibitem[Mazoure et~al.(2020)Mazoure, Doan, Durand, Pineau, and
  Hjelm]{PG-norm-flows}
Bogdan Mazoure, Thang Doan, Audrey Durand, Joelle Pineau, and R~Devon Hjelm.
\newblock Leveraging exploration in off-policy algorithms via normalizing
  flows.
\newblock In \emph{Conference on Robot Learning}, pages 430--444. PMLR, 2020.

\bibitem[Haarnoja et~al.(2018{\natexlab{c}})Haarnoja, Hartikainen, Abbeel, and
  Levine]{latent-norm-flows-hier}
Tuomas Haarnoja, Kristian Hartikainen, Pieter Abbeel, and Sergey Levine.
\newblock Latent space policies for hierarchical reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  1851--1860. PMLR, 2018{\natexlab{c}}.

\bibitem[Haarnoja et~al.(2017{\natexlab{b}})Haarnoja, Tang, Abbeel, and
  Levine]{rl-energy-based}
Tuomas Haarnoja, Haoran Tang, Pieter Abbeel, and Sergey Levine.
\newblock Reinforcement learning with deep energy-based policies.
\newblock In \emph{International Conference on Machine Learning}, pages
  1352--1361. PMLR, 2017{\natexlab{b}}.

\bibitem[Bengio et~al.(2013)Bengio, Yao, Alain, and Vincent]{outRLrel0-DenAE}
Yoshua Bengio, Li~Yao, Guillaume Alain, and Pascal Vincent.
\newblock Generalized denoising auto-encoders as generative models.
\newblock \emph{Advances in neural information processing systems}, 26, 2013.

\bibitem[Alain et~al.(2016)Alain, Bengio, Yao, Yosinski, Thibodeau-Laufer,
  Zhang, and Vincent]{outRLrel1-GSN}
Guillaume Alain, Yoshua Bengio, Li~Yao, Jason Yosinski, Eric Thibodeau-Laufer,
  Saizheng Zhang, and Pascal Vincent.
\newblock Gsns: generative stochastic networks.
\newblock \emph{Information and Inference: A Journal of the IMA}, 5\penalty0
  (2):\penalty0 210--249, 2016.

\bibitem[Bordes et~al.(2017)Bordes, Honari, and Vincent]{outRLrel2-INFUSION}
Florian Bordes, Sina Honari, and Pascal Vincent.
\newblock Learning to generate samples from noise through infusion training.
\newblock \emph{arXiv preprint arXiv:1703.06975}, 2017.

\bibitem[Goyal et~al.(2017)Goyal, Ke, Ganguli, and
  Bengio]{outRLrel3-VARWALKBACK}
Anirudh Goyal, Nan~Rosemary Ke, Surya Ganguli, and Yoshua Bengio.
\newblock Variational walkback: Learning a transition operator as a stochastic
  recurrent net.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Nijkamp et~al.(2019)Nijkamp, Hill, Zhu, and Wu]{outRLrel4-SHORTHMC}
Erik Nijkamp, Mitch Hill, Song-Chun Zhu, and Ying~Nian Wu.
\newblock Learning non-convergent non-persistent short-run mcmc toward
  energy-based model.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and
  Ganguli]{diffSEM0}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{International Conference on Machine Learning}, pages
  2256--2265. PMLR, 2015.

\bibitem[Song and Ermon(2019)]{diffREL_scoreMATCHermon}
Yang Song and Stefano Ermon.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{diff1DDPM}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 6840--6851, 2020.

\bibitem[Dhariwal and Nichol(2021)]{diffSUCC0}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Orey(1971)]{small0}
Steven Orey.
\newblock \emph{Limit theorems for Markov chain transition probabilities}.
\newblock van Nostrand London, 1971.

\bibitem[Nummelin(2004{\natexlab{a}})]{small1book}
Esa Nummelin.
\newblock \emph{General irreducible Markov chains and non-negative operators}.
\newblock Number~83. Cambridge University Press, 2004{\natexlab{a}}.

\bibitem[Roberts and Rosenthal(2001)]{small-set-mod-defn}
Gareth~O Roberts and Jeffrey~S Rosenthal.
\newblock Small and pseudo-small sets for markov chains.
\newblock \emph{Stochastic Models}, 17\penalty0 (2):\penalty0 121--145, 2001.

\bibitem[Nummelin(2004{\natexlab{b}})]{smallNUMM}
Esa Nummelin.
\newblock \emph{General irreducible Markov chains and non-negative operators}.
\newblock Number~83. Cambridge University Press, 2004{\natexlab{b}}.

\bibitem[Pflug(1992)]{gradientEst_ss_pflug}
G~Ch Pflug.
\newblock Gradient estimates for the performance of markov chains and discrete
  event processes.
\newblock \emph{Annals of Operations Research}, 39\penalty0 (1):\penalty0
  173--194, 1992.

\bibitem[Heidergott et~al.(2006)Heidergott, Hordijk, and
  Weisshaupt]{gradientEst_ss_pflug_unb_ext}
Bernd Heidergott, Arie Hordijk, and Heinz Weisshaupt.
\newblock Measure-valued differentiation for stationary markov chains.
\newblock \emph{Mathematics of Operations Research}, 31\penalty0 (1):\penalty0
  154--172, 2006.

\bibitem[Rainforth et~al.(2018)Rainforth, Cornish, Yang, Warrington, and
  Wood]{nested-MC-estimator}
Tom Rainforth, Rob Cornish, Hongseok Yang, Andrew Warrington, and Frank Wood.
\newblock On nesting monte carlo estimators.
\newblock In \emph{International Conference on Machine Learning}, pages
  4267--4276. PMLR, 2018.

\bibitem[McLeish(2011)]{MC-debiasing-trick}
Don McLeish.
\newblock A general method for debiasing a monte carlo estimator.
\newblock \emph{Monte Carlo methods and applications}, 17\penalty0
  (4):\penalty0 301--315, 2011.

\bibitem[LeCun et~al.(2015)LeCun, Bengio, and Hinton]{lecun_deeplearningbook}
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton.
\newblock Deep learning.
\newblock \emph{nature}, 521\penalty0 (7553):\penalty0 436--444, 2015.

\bibitem[Nestoridis and Stefanopoulos(2007)]{nestoridis_universalseries}
Vassili Nestoridis and Vangelis Stefanopoulos.
\newblock Universal series and approximate identities.
\newblock Technical report, Technical Report TR-28-2007, Department of
  Mathematics and Statistics~â€¦, 2007.

\bibitem[Kingma and Ba(2014)]{adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Cetin and Celiktutan(2021)]{learningpessimism}
Edoardo Cetin and Oya Celiktutan.
\newblock Learning pessimism for robust and efficient off-policy reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:2110.03375}, 2021.

\bibitem[Bjorck et~al.(2021)Bjorck, Gomes, and Weinberger]{deeper-deep-RL}
Johan Bjorck, Carla~P Gomes, and Kilian~Q Weinberger.
\newblock Towards deeper deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2106.01151}, 2021.

\bibitem[Fujimoto et~al.(2018)Fujimoto, van Hoof, and Meger]{td3}
Scott Fujimoto, Herke van Hoof, and David Meger.
\newblock Addressing function approximation error in actor-critic methods.
\newblock In \emph{ICML}, pages 1582--1591, 2018.
\newblock URL \url{http://proceedings.mlr.press/v80/fujimoto18a.html}.

\bibitem[Kingma et~al.(2016)Kingma, Salimans, Jozefowicz, Chen, Sutskever, and
  Welling]{invAutoFlows}
Durk~P Kingma, Tim Salimans, Rafal Jozefowicz, Xi~Chen, Ilya Sutskever, and Max
  Welling.
\newblock Improved variational inference with inverse autoregressive flow.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\end{thebibliography}
