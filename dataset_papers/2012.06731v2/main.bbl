\begin{thebibliography}{10}

\bibitem{grover2019stochastic}
Aditya Grover, Eric Wang, Aaron Zweig, and Stefano Ermon.
\newblock Stochastic optimization of sorting networks via continuous
  relaxations.
\newblock In {\em ICLR}, 2019.

\bibitem{liu2009learning}
Tie-Yan Liu et~al.
\newblock Learning to rank for information retrieval.
\newblock {\em Foundations and Trends{\textregistered} in Information
  Retrieval}, 3(3):225--331, 2009.

\bibitem{cossock2006subset}
David Cossock and Tong Zhang.
\newblock Subset ranking using regression.
\newblock In {\em COLT}, 2006.

\bibitem{li2008mcrank}
Ping Li, Qiang Wu, and Christopher~J Burges.
\newblock Mcrank: Learning to rank using multiple classification and gradient
  boosting.
\newblock In {\em NeurIPS}, 2008.

\bibitem{crammer2002pranking}
Koby Crammer and Yoram Singer.
\newblock Pranking with ranking.
\newblock In {\em NeurIPS}, 2002.

\bibitem{shashua2003ranking}
Amnon Shashua and Anat Levin.
\newblock Ranking with large margin principle: Two approaches.
\newblock In {\em NeurIPS}, 2003.

\bibitem{herbrich2000large}
Ralf Herbrich.
\newblock Large margin rank boundaries for ordinal regression.
\newblock {\em Advances in large margin classifiers}, pages 115--132, 2000.

\bibitem{freund2003efficient}
Yoav Freund, Raj Iyer, Robert~E Schapire, and Yoram Singer.
\newblock An efficient boosting algorithm for combining preferences.
\newblock {\em JMLR}, 4(Nov):933--969, 2003.

\bibitem{Burges2005}
Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole
  Hamilton, and Greg Hullender.
\newblock {Learning to rank using gradient descent}.
\newblock In {\em ICML}, 2005.

\bibitem{burges2010ranknet}
Christopher~JC Burges.
\newblock From ranknet to lambdarank to lambdamart: An overview.
\newblock {\em Learning}, 11(23-581):81, 2010.

\bibitem{zheng2008general}
Zhaohui Zheng, Hongyuan Zha, Tong Zhang, Olivier Chapelle, Keke Chen, and
  Gordon Sun.
\newblock A general boosting method and its application to learning ranking
  functions for web search.
\newblock In {\em NeurIPS}, 2008.

\bibitem{cao2006adapting}
Yunbo Cao, Jun Xu, Tie-Yan Liu, Hang Li, Yalou Huang, and Hsiao-Wuen Hon.
\newblock Adapting ranking svm to document retrieval.
\newblock In {\em SIGIR}, 2006.

\bibitem{Burges2007}
Christopher~J.C. Burges, Robert Ragno, and Quoc {Viet Le}.
\newblock {Learning to rank with nonsmooth cost functions}.
\newblock In {\em NeurIPS}, 2007.

\bibitem{wu2009smoothing}
Mingrui Wu, Yi~Chang, Zhaohui Zheng, and Hongyuan Zha.
\newblock Smoothing {DCG} for learning to rank: A novel approach using smoothed
  hinge functions.
\newblock In {\em CIKM}, 2009.

\bibitem{cao2007learning}
Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and Hang Li.
\newblock Learning to rank: from pairwise approach to listwise approach.
\newblock In {\em ICML}, 2007.

\bibitem{xia2008listwise}
Fen Xia, Tie-Yan Liu, Jue Wang, Wensheng Zhang, and Hang Li.
\newblock Listwise approach to learning to rank: theory and algorithm.
\newblock In {\em ICML}, 2008.

\bibitem{xu2007adarank}
Jun Xu and Hang Li.
\newblock Adarank: a boosting algorithm for information retrieval.
\newblock In {\em SIGIR}, 2007.

\bibitem{yue2007support}
Yisong Yue, Thomas Finley, Filip Radlinski, and Thorsten Joachims.
\newblock A support vector method for optimizing average precision.
\newblock In {\em SIGIR}, 2007.

\bibitem{taylor2008softrank}
Michael Taylor, John Guiver, Stephen Robertson, and Tom Minka.
\newblock Softrank: optimizing non-smooth rank metrics.
\newblock In {\em WSDM}, 2008.

\bibitem{Qin2013}
Tao Qin and Tie-Yan Liu.
\newblock {Introducing LETOR 4.0 Datasets}.
\newblock 2013.

\bibitem{pasumarthi2019tf}
Rama~Kumar Pasumarthi, Sebastian Bruch, Xuanhui Wang, Cheng Li, Michael
  Bendersky, et~al.
\newblock Tf-ranking: Scalable tensorflow library for learning-to-rank.
\newblock In {\em KDD}, 2019.

\bibitem{liu2011learning}
Tie-Yan Liu.
\newblock {\em Learning to rank for information retrieval}.
\newblock Springer Science \& Business Media, 2011.

\bibitem{zhu2004recall}
Mu~Zhu.
\newblock Recall, precision and average precision.
\newblock {\em Department of Statistics and Actuarial Science, University of
  Waterloo, Waterloo}, 2:30, 2004.

\bibitem{jarvelin2002cumulated}
Kalervo J{\"a}rvelin and Jaana Kek{\"a}l{\"a}inen.
\newblock Cumulated gain-based evaluation of ir techniques.
\newblock {\em ACM Transactions on Information Systems}, 20(4):422--446, 2002.

\bibitem{qin2010general}
Tao Qin, Tie-Yan Liu, and Hang Li.
\newblock A general approximation framework for direct optimization of
  information retrieval measures.
\newblock {\em Information retrieval}, 13(4):375--397, 2010.

\bibitem{blondel2020fast}
Mathieu Blondel, Olivier Teboul, Quentin Berthet, and Josip Djolonga.
\newblock Fast differentiable sorting and ranking.
\newblock In {\em ICML}, 2020.

\bibitem{chapelle2010gradient}
Olivier Chapelle and Mingrui Wu.
\newblock Gradient descent optimization of smoothed information retrieval
  metrics.
\newblock {\em Information retrieval}, 13(3):216--235, 2010.

\bibitem{adams2011ranking}
Ryan~Prescott Adams and Richard~S Zemel.
\newblock Ranking via sinkhorn propagation.
\newblock {\em arXiv preprint arXiv:1106.1925}, 2011.

\bibitem{Mena2018}
Gonzalo Mena, David Belanger, Scott Linderman, and Jasper Snoek.
\newblock {Learning Latent Permutations with Gumbel-Sinkhorn Networks}.
\newblock In {\em ICLR}, 2018.

\bibitem{Cuturi2019}
Marco Cuturi, Olivier Teboul, and Jean-Philippe Vert.
\newblock {Differentiable Ranks and Sorting using Optimal Transport}.
\newblock In {\em NeurIPS}, 2019.

\bibitem{Burges2010}
Chris Burges.
\newblock {From RankNet to LambdaRank to LambdaMART: An Overview}.
\newblock {\em JMLR}, 41(4):574--581, 2010.

\bibitem{Reddi2021RankDistilKD}
Sashank~J. Reddi, Rama~Kumar Pasumarthi, Aditya~Krishna Menon, Ankit~Singh
  Rawat, Felix~X. Yu, Seungyeon Kim, Andreas Veit, and Sanjiv Kumar.
\newblock Rankdistil: Knowledge distillation for ranking.
\newblock In {\em AISTATS}, 2021.

\bibitem{Wang2013}
Yining Wang, Liwei Wang, Yuanzhi Li, Di~He, Wei Chen, and Tie~Yan Liu.
\newblock {A theoretical analysis of NDCG ranking measures}.
\newblock {\em JMLR}, 30:25--54, 2013.

\bibitem{prillo2020softsort}
Sebastian Prillo and Julian Eisenschlos.
\newblock Softsort: A continuous relaxation for the argsort operator.
\newblock In {\em ICML}, 2020.

\bibitem{xie2020differentiable}
Yujia Xie, Hanjun Dai, Minshuo Chen, Bo~Dai, Tuo Zhao, et~al.
\newblock Differentiable top-k operator with optimal transport.
\newblock {\em arXiv preprint arXiv:2002.06504}, 2020.

\bibitem{rigutini2011sortnet}
Leonardo Rigutini, Tiziano Papini, Marco Maggini, and Franco Scarselli.
\newblock Sortnet: Learning to rank by a neural preference function.
\newblock {\em IEEE transactions on neural networks}, 22(9):1368--1380, 2011.

\bibitem{Cao2015}
Ziqiang Cao, Furu Wei, Li~Dong, Sujian Li, and Ming Zhou.
\newblock {Ranking with recursive neural networks and its application to
  multi-document summarization}.
\newblock In {\em AAAI}, 2015.

\bibitem{xiong2017end}
Chenyan Xiong, Zhuyun Dai, Jamie Callan, Zhiyuan Liu, and Russell Power.
\newblock End-to-end neural ad-hoc ranking with kernel pooling.
\newblock In {\em SIGIR}, 2017.

\bibitem{plackett1975analysis}
Robin~L Plackett.
\newblock The analysis of permutations.
\newblock {\em Applied Statistics}, pages 193--202, 1975.

\bibitem{luce2012individual}
R~Duncan Luce.
\newblock {\em Individual choice behavior: A theoretical analysis}.
\newblock Courier Corporation, 1959.

\bibitem{bengio2013estimating}
Yoshua Bengio, Nicholas L{\'e}onard, and Aaron Courville.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock {\em arXiv preprint arXiv:1308.3432}, 2013.

\bibitem{Tange2011a}
O.~Tange.
\newblock Gnu parallel - the command-line power tool.
\newblock {\em ;login: The USENIX Magazine}, 36(1):42--47, Feb 2011.

\end{thebibliography}
