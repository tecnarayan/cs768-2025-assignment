Two major challenges in distributed learning and estimation are 1) preserving
the privacy of the local samples; and 2) communicating them efficiently to a
central server, while achieving high accuracy for the end-to-end task. While
there has been significant interest in addressing each of these challenges
separately in the recent literature, treatments that simultaneously address
both challenges are still largely missing. In this paper, we develop novel
encoding and decoding mechanisms that simultaneously achieve optimal privacy
and communication efficiency in various canonical settings.
  In particular, we consider the problems of mean estimation and frequency
estimation under $\varepsilon$-local differential privacy and $b$-bit
communication constraints. For mean estimation, we propose a scheme based on
Kashin's representation and random sampling, with order-optimal estimation
error under both constraints. For frequency estimation, we present a mechanism
that leverages the recursive structure of Walsh-Hadamard matrices and achieves
order-optimal estimation error for all privacy levels and communication
budgets. As a by-product, we also construct a distribution estimation mechanism
that is rate-optimal for all privacy regimes and communication constraints,
extending recent work that is limited to $b=1$ and $\varepsilon=O(1)$. Our
results demonstrate that intelligent encoding under joint privacy and
communication constraints can yield a performance that matches the optimal
accuracy achievable under either constraint alone.