

@inproceedings{DBLP:conf/nips/BalkanskiBS18,
  author    = {Eric Balkanski and
               Adam Breuer and
               Yaron Singer},
  title     = {Non-monotone Submodular Maximization in Exponentially Fewer Iterations},
  booktitle = {Advances in Neural Information Processing Systems 31: Annual Conference
               on Neural Information Processing Systems 2018, NeurIPS 2018, December
               3-8, 2018, Montr{\'{e}}al, Canada},
  pages     = {2359--2370},
  year      = {2018},
  url       = {https://proceedings.neurips.cc/paper/2018/hash/a42a596fc71e17828440030074d15e74-Abstract.html},
  timestamp = {Thu, 21 Jan 2021 15:15:20 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/BalkanskiBS18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{wald1945some,
  title={Some generalizations of the theory of cumulative sums of random variables},
  author={Wald, Abraham},
  journal={The Annals of Mathematical Statistics},
  volume={16},
  number={3},
  pages={287--293},
  year={1945},
  publisher={JSTOR}
}

@article{Kuhnle2021a,
author = {Kuhnle, Alan and Chen, Yixin and Dey, Tonmoy},
file = {:home/alan/projects/linear-sampling-latex/main.pdf:pdf},
number = {arXiv preprint},
title = {{Best of Both Worlds: Practical and Theoretically Optimal Submodular Maximization in Parallel}},
year = {2021}
}
@incollection{karp1972reducibility,
author = {Karp, Richard M},
booktitle = {Complexity of computer computations},
pages = {85--103},
publisher = {Springer},
title = {{Reducibility among combinatorial problems}},
year = {1972}
}
@article{ibarra1975fast,
author = {Ibarra, Oscar H and Kim, Chul E},
journal = {Journal of the ACM (JACM)},
number = {4},
pages = {463--468},
publisher = {Acm New York, NY, USA},
title = {{Fast approximation algorithms for the knapsack and sum of subset problems}},
volume = {22},
year = {1975}
}
@inproceedings{Kuhnle2021,
abstract = {For the problem of maximizing a nonnegative, (not necessarily monotone) submodular function with respect to a cardinality constraint, we propose deterministic algorithms with linear time complexity; these are the first algorithms to obtain constant approximation ratio with high probability in linear time. Our first algorithm is a single-pass streaming algorithm that obtains ratio 9.298 + $\epsilon$ and makes only two queries per received element. Our second algorithm is a multi-pass streaming algorithm that obtains ratio 4 + $\epsilon$. Empirically, the algorithms are validated to use fewer queries than and to obtain comparable objective values to state-of-the-art algorithms.},
archivePrefix = {arXiv},
arxivId = {2104.06873},
author = {Kuhnle, Alan},
booktitle = {arXiv:2104.06873},
eprint = {2104.06873},
file = {:home/alan/Downloads/2104.06873.pdf:pdf},
title = {{Streaming Algorithms for Cardinality-Constrained Maximization of Non-Monotone Submodular Functions in Linear Time}},
url = {http://arxiv.org/abs/2104.06873},
year = {2021}
}
@inproceedings{Mirzasoleiman2013,
author = {Mirzasoleiman, Baharan and Karbasi, Amin and Sarkar, Rik and Krause, Andreas},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - NIPS-2013-distributed-submodular-maximization-identifying-representative-elements-in-massive-data-Paper.pdf:pdf},
title = {{Distributed Submodular Maximization: Identifying Representative Elements in Massive Data}},
year = {2013}
}
@inproceedings{Sakaue2020,
abstract = {Submodular maximization with a cardinality constraint can model various problems, and those problems are often very large in practice. For the case where objective functions are monotone, many fast approximation algorithms have been developed. The stochastic greedy algorithm (SG) is one such algorithm, which is widely used thanks to its simplicity, efficiency, and high empirical performance. However, its approximation guarantee has been proved only for monotone objective functions. When it comes to non-monotone objective functions, existing approximation algorithms are inefficient relative to the fast algorithms developed for the case of monotone objectives. In this paper, we prove that SG (with slight modification) can achieve almost $1/4$-approximation guarantees in expectation in linear time even if objective functions are non-monotone. Our result provides a constant-factor approximation algorithm with the fewest oracle queries for non-monotone submodular maximization with a cardinality constraint. Experiments validate the performance of (modified) SG.},
archivePrefix = {arXiv},
arxivId = {1908.06242},
author = {Sakaue, Shinsaku},
booktitle = {International Conference on Artificial Intelligence and Statistics (AISTATS)},
eprint = {1908.06242},
file = {:home/alan/Downloads/sakaue20a.pdf:pdf},
title = {{Guarantees of Stochastic Greedy Algorithms for Non-monotone Submodular Maximization with Cardinality Constraint}},
url = {http://arxiv.org/abs/1908.06242},
year = {2020}
}
@article{Dean2008,
abstract = {MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a _map_ function that processes a key/value pair to generate a set of intermediate key/value pairs, and a _reduce_ function that merges all intermediate values associated with the same intermediate key. Many real world tasks are expressible in this model, as shown in the paper. Programs written in this functional style are automatically parallelized and executed on a large cluster of commodity machines. The run-time system takes care of the details of partitioning the input data, scheduling the program's execution across a set of machines, handling machine failures, and managing the required inter-machine communication. This allows programmers without any experience with parallel and distributed systems to easily utilize the resources of a large distributed system. Our implementation of MapReduce runs on a large cluster of commodity machines and is highly scalable: a typical MapReduce computation processes many terabytes of data on thousands of machines. Programmers find the system easy to use: hundreds of MapReduce programs have been implemented and upwards of one thousand MapReduce jobs are executed on Google's clusters every day.},
archivePrefix = {arXiv},
arxivId = {10.1.1.163.5292},
author = {Dean, Jeffrey and Ghemawat, Sanjay},
eprint = {10.1.1.163.5292},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dean, Ghemawat - 2008 - MapReduce Simplified Data Processing on Large Clusters.pdf:pdf},
isbn = {9781595936868},
issn = {00010782},
journal = {Communications of the ACM},
number = {1},
pages = {107--113},
pmid = {11687618},
title = {{MapReduce: Simplified Data Processing on Large Clusters}},
url = {http://www.usenix.org/events/osdi04/tech/full_papers/dean/dean_html/},
volume = {51},
year = {2008}
}
@inproceedings{Barbosa2016,
abstract = {A wide variety of problems in machine learning, including exemplar clustering, document summarization, and sensor placement, can be cast as constrained submodular maximization problems. A lot of recent effort has been devoted to developing distributed algorithms for these problems. However, these results suffer from high number of rounds, suboptimal approximation ratios, or both. We develop a framework for bringing existing algorithms in the sequential setting to the distributed setting, achieving near optimal approximation ratios for many settings in only a constant number of MapReduce rounds. Our techniques also give a fast sequential algorithm for non-monotone maximization subject to a matroid constraint.},
archivePrefix = {arXiv},
arxivId = {1507.03719},
author = {Barbosa, Rafael Da Ponte and Ene, Alina and Nguyen, Huy L. and Ward, Justin},
booktitle = {IEEE Symposium on Foundations of Computer Science (FOCS)},
doi = {10.1109/FOCS.2016.74},
eprint = {1507.03719},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barbosa et al. - 2016 - A New Framework for Distributed Submodular Maximization.pdf:pdf},
isbn = {9781509039333},
issn = {02725428},
keywords = {Approximation algorithms,Distributed submodular maximization,MapReduce},
title = {{A New Framework for Distributed Submodular Maximization}},
year = {2016}
}
@inproceedings{Indyk2019,
abstract = {"Composable core-sets" are an efficient framework for solving optimization problems in massive data models. In this work, we consider efficient construction of composable core-sets for the determinant maximization problem. This can also be cast as the MAP inference task for determinantal point processes, that have recently gained a lot of interest for modeling diversity and fairness. The problem was recently studied in (Indyk et al., 2018), where they designed composable core-sets with the optimal approximation bound of {\~{O}}(k)k. On the other hand, the more practical Greedy algorithm has been previously used in similar contexts. In this work, first we provide a theoretical approximation guarantee of O(Ck2 ) for the Greedy algorithm in the context of composable core-sets; Further, we propose to use a Local Search based algorithm that while being still practical, achieves a nearly optimal approximation bound of O(k)2k; Finally, we implement all three algorithms and show the effectiveness of our proposed algorithm on standard data sets.},
author = {Indyk, Piotr and Mahabadi, Sepideh and Gharan, Shayan Oveis and Rezaei, Alireza},
booktitle = {International Conference on Machine Learning (ICML)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Indyk et al. - 2019 - Composable Core-sets for Determinant Maximization A Simple Near-Optimal Algorithm.pdf:pdf},
isbn = {9781510886988},
title = {{Composable Core-sets for Determinant Maximization: A Simple Near-Optimal Algorithm}},
year = {2019}
}
@inproceedings{Barbosa2015,
abstract = {A wide variety of problems in machine learning, including exemplar clustering, document summarization, and sensor placement, can be cast as constrained submodular maximization problems. Unfortunately, the resulting submodular optimization problems are often too large to be solved on a single machine. We consider a distributed, greedy algorithm that combines previous approaches with randomization. The result is an algorithm that is embarrassingly parallel and achieves provable, constant factor, worst-case approximation guarantees. In our experiments, we demonstrate its efficiency in large problems with different kinds of constraints with objective values always close to what is achievable in the centralized setting.},
archivePrefix = {arXiv},
arxivId = {1502.02606},
author = {Barbosa, Rafael and Ene, Alina and {Le Nguyen}, Huy and Ward, Justin},
booktitle = {International Conference on Machine Learning (ICML)},
eprint = {1502.02606},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barbosa et al. - 2015 - The Power of Randomization Distributed Submodular Maximization on Massive Datasets.pdf:pdf},
isbn = {9781510810587},
title = {{The Power of Randomization: Distributed Submodular Maximization on Massive Datasets}},
year = {2015}
}
@article{Indyk2014,
abstract = {In this paper we consider efficient construction of "composable core-sets" for basic diversity and coverage maximization problems. A core-set for a point-set in a metric space is a subset of the point-set with the property that an approxi-mate solution to the whole point-set can be obtained given the core-set alone. A composable core-set has the property that for a collection of sets, the approximate solution to the union of the sets in the collection can be obtained given the union of the composable core-sets for the point sets in the collection. Using composable core-sets one can obtain efficient solutions to a wide variety of massive data processing applications, including nearest neighbor search, streaming algorithms and map-reduce computation. Our main results are algorithms for constructing composable core-sets for several notions of "diversity objective functions", a topic that attracted a significant amount of research over the last few years. The composable core-sets we construct are small and accurate: their approximation factor almost matches that of the best "offline" algorithms for the relevant optimization problems (up to a constant factor). Moreover, we also show applications of our results to diverse nearest neighbor search, streaming algorithms and map-reduce computation. Finally, we show that for an alternative notion of diversity maximization based on the maximum coverage problem small composable core-sets do not exist. Copyright is held by the author/owner(s).},
author = {Indyk, Piotr and Mahabadi, Sepideh and Mahdian, Mohammad and Mirrokni, Vahab S.},
doi = {10.1145/2594538.2594560},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Indyk et al. - 2014 - Composable core-sets for diversity and coverage maximization.pdf:pdf},
isbn = {9781450323758},
journal = {Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems},
keywords = {Core-set,Diversity,Map-reduce,Nearest Neighbor,Streaming},
pages = {100--108},
title = {{Composable core-sets for diversity and coverage maximization}},
year = {2014}
}
@inproceedings{Epasto2017,
abstract = {We study the problem of efficiently optimizing submodular functions under cardinality constraints in distributed setting. Recently, several distributed algorithms for this problem have been introduced which either achieve a sub-optimal solution or they run in super-constant number of rounds of computation. Unlike previous work, we aim to design distributed algorithms in multiple rounds with almost optimal approximation guarantees at the cost of outputting a larger number of elements. Toward this goal, we present a distributed algorithm that, for any ϵ > 0 and any constant r , outputs a set S of O(rk/ϵ 1/r ) items in r rounds, and achieves a (1 - ϵ )-approximation of the value of the optimum set with k items. This is the first distributed algorithm that achieves an approximation factor of (1 - ϵ ) running in less than log 1 ϵ number of rounds. We also prove a hardness result showing that the output of any 1 - ϵ approximation distributed algorithm limited to one distributed round should have at least $\Omega$(k/ϵ ) items. In light of this hardness result, our distributed algorithm in one round, r = 1, is asymptotically tight in terms of the output size. We support the theoretical guarantees with an extensive empirical study of our algorithm showing that achieving almost optimum solutions is indeed possible in a few rounds for large-scale real datasets.},
author = {Epasto, Alessandro and Mirrokni, Vahab and Zadimoghaddam, Morteza},
booktitle = {Symposium on Parallelism in Algorithms and Architectures (SPAA)},
doi = {10.1145/3087556.3087574},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Epasto, Mirrokni, Zadimoghaddam - 2017 - Bicriteria Distributed Submodular Maximization in a Few Rounds.pdf:pdf},
isbn = {9781450345934},
title = {{Bicriteria Distributed Submodular Maximization in a Few Rounds}},
year = {2017}
}
@inproceedings{Mirrokni2015,
abstract = {An effective technique for solving optimization problems over massive data sets is to partition the data into smaller pieces, solve the problem on each piece and compute a representative solution from it, and finally obtain a solution inside the union of the representative solutions for all pieces. This technique can be captured via the concept of composable core-sets, and has been recently applied to solve diversity maximization problems as well as several clustering problems [7, 15, 8]. However, for coverage and submodular maximization problems, impossibility bounds are known for this technique [15]. In this paper, we focus on efficient construction of a randomized variant of composable core-sets where the above idea is applied on a random clustering of the data. We employ this technique for the coverage, monotone and non-monotone submodular maximization problems. Our results significantly improve upon the hardness results for non-randomized core-sets, and imply improved results for sub-modular maximization in a distributed and streaming settings. The effectiveness of this technique has been confirmed empirically for several machine learning applications [22], and our proof provides a theoretical foundation to this idea. In summary, we show that a simple greedy algorithm results in a 1/3-approximate randomized composable core-set for submodular maximization under a cardinality constraint. Our result also extends to non-monotone submodular functions, and leads to the first 2-round MapReduce-based constant-factor approximation algorithm with O(n) total communication complexity for either monotone or non-monotone functions. Finally, using an improved analysis technique and a new algorithm Pseudo Greedy, we present an improved 0.545-approximation algorithm for monotone sub-modular maximization, which is in turn the first MapReduce-based algorithm beating factor 1/2 in a constant number of rounds. Copyright is held by the author/owner(s).},
archivePrefix = {arXiv},
arxivId = {1506.06715},
author = {Mirrokni, Vahab and Zadimoghaddam, Morteza},
booktitle = {ACM Symposium on Theory of Computing (STOC)},
doi = {10.1145/2746539.2746624},
eprint = {1506.06715},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mirrokni, Zadimoghaddam - 2015 - Randomized Composable Core-Sets for Distributed Submodular Maximization.pdf:pdf},
isbn = {9781450335362},
issn = {07378017},
keywords = {Core-sets,Distributed algorithms,MapReduce Algorithms,Randomized Composable Coresets,Streaming Algorithms, Core-sets,Submodular Maximization},
title = {{Randomized Composable Core-Sets for Distributed Submodular Maximization}},
year = {2015}
}
@unpublished{Amanatidis2021,
abstract = {The growing need to deal with massive instances motivates the design of algorithms balancing the quality of the solution with applicability. For the latter, an important measure is the \emph{adaptive complexity}, capturing the number of sequential rounds of parallel computation needed. In this work we obtain the first \emph{constant factor} approximation algorithm for non-monotone submodular maximization subject to a knapsack constraint with \emph{near-optimal} $O(\log n)$ adaptive complexity. Low adaptivity by itself, however, is not enough: one needs to account for the total number of function evaluations (or value queries) as well. Our algorithm asks $\tilde{O}(n^2)$ value queries, but can be modified to run with only $\tilde{O}(n)$ instead, while retaining a low adaptive complexity of $O(\log^2n)$. Besides the above improvement in adaptivity, this is also the first \emph{combinatorial} approach with sublinear adaptive complexity for the problem and yields algorithms comparable to the state-of-the-art even for the special cases of cardinality constraints or monotone objectives. Finally, we showcase our algorithms' applicability on real-world datasets.},
archivePrefix = {arXiv},
arxivId = {2102.08327},
author = {Amanatidis, Georgios and Fusco, Federico and Lazos, Philip and Leonardi, Stefano and Spaccamela, Alberto Marchetti and Reiffenh{\"{a}}user, Rebecca},
eprint = {2102.08327},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Amanatidis et al. - 2021 - Submodular Maximization subject to a Knapsack Constraint Combinatorial Algorithms with Near-optimal Adaptive.pdf:pdf},
pages = {1--25},
title = {{Submodular Maximization subject to a Knapsack Constraint: Combinatorial Algorithms with Near-optimal Adaptive Complexity}},
url = {http://arxiv.org/abs/2102.08327},
year = {2021}
}
@techreport{Ghasemi2020,
abstract = {We consider an agent that is assigned with a temporal logic task in an environment whose semantic representation is only partially known. We represent the semantics of the environment with a set of state properties, called atomic propositions over which, the agent holds a probabilistic belief and updates it as new sensory measurements arrive. The goal is to design a joint perception and planning strategy for the agent that realizes the task with high probability. We develop a planning strategy that takes the semantic uncertainties into account and by doing so provides probabilistic guarantees on the task success. Furthermore, as new data arrive, the belief over the atomic propositions evolves and, subsequently, the planning strategy adapts accordingly. We evaluate the proposed method on various finite-horizon tasks in planar navigation settings where the empirical results show that the proposed method provides reliable task performance that also improves as the knowledge about the environment enhances.},
author = {Ghasemi, Mahsa and {Arinc Bulgur}, Erdem and Topcu, Ufuk},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghasemi, Arinc Bulgur, Topcu - 2020 - Task-Oriented Active Perception and Planning in Environments with Partially Known Semantics.pdf:pdf},
title = {{Task-Oriented Active Perception and Planning in Environments with Partially Known Semantics}},
year = {2020}
}
@article{Grimsman2020,
abstract = {A popular formalism for multiagent control applies tools from game theory, casting a multiagent decision problem as a cooperation-style game in which individual agents make local choices to optimize their own local utility functions in response to the observable choices made by other agents. When the system-level objective is submodular maximization, it is known that if every agent can observe the action choice of all other agents, then all Nash equilibria of a large class of resulting games are within a factor of $2$ of optimal; that is, the price of anarchy is $1/2$. However, little is known if agents cannot observe the action choices of other relevant agents. To study this, we extend the standard game-theoretic model to one in which a subset of agents either become \emph{blind} (unable to observe others' choices) or \emph{isolated} (blind, and also invisible to other agents), and we prove exact expressions for the price of anarchy as a function of the number of compromised agents. When $k$ agents are compromised (in any combination of blind or isolated), we show that the price of anarchy for a large class of utility functions is exactly $1/(2+k)$. We then show that if agents use marginal-cost utility functions and at least $1$ of the compromised agents is blind (rather than isolated), the price of anarchy improves to $1/(1+k)$. We also provide simulation results demonstrating the effects of these observation denials in a dynamic setting.},
archivePrefix = {arXiv},
arxivId = {2009.05018},
author = {Grimsman, David and Seaton, Joshua H. and Marden, Jason R. and Brown, Philip N.},
eprint = {2009.05018},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grimsman et al. - 2020 - The Cost of Denied Observation in Multiagent Submodular Optimization.pdf:pdf},
month = {sep},
title = {{The Cost of Denied Observation in Multiagent Submodular Optimization}},
url = {http://arxiv.org/abs/2009.05018},
year = {2020}
}
@inproceedings{Dolhansky2016,
abstract = {We start with an overview of a class of submodular functions called SCMMs (sums of concave composed with non-negative modular functions plus a final arbitrary modular). We then define a new class of submodular functions we call deep submodular functions or DSFs. We show that DSFs are a flexible parametric family of submodular functions that share many of the properties and advantages of deep neural networks (DNNs), including many-layered hierarchical topologies, representation learning, distributed representations, opportunities and strategies for training, and suitability to GPU-based matrix/ vector computing. DSFs can be motivated by considering a hierarchy of descriptive concepts over ground elements and where one wishes to allow submodular interaction throughout this hierarchy. In machine learning and data science applications, where there is often either a natural or an automatically learnt hierarchy of concepts over data, DSFs therefore naturally apply. Results in this paper show that DSFs constitute a strictly larger class of submodular functions than SCMMs, thus justifying their mathematical and practical utility. Moreover, we show that, for any integer k > 0, there are k-layer DSFs that cannot be represented by a k′-layer DSF for any k′ < k. This implies that, like DNNs, there is a utility to depth, but unlike DNNs (which can be universally approximated by shallow networks), the family of DSFs strictly increase with depth. Despite this property, however, we show that DSFs, even with arbitrarily large k, do not comprise all submodular functions. We show this using a technique that "backpropagates" certain requirements if it was the case that DSFs comprised all submodular functions. In offering the above results, we also define the notion of an antitone superdifferential of a concave function and show how this relates to submodular functions (in general), DSFs (in particular), negative second-order partial derivatives, continuous submodularity, and concave extensions. To further motivate our analysis, we provide various special case results from matroid theory, comparing DSFs with forms of matroid rank, in particular the laminar matroid. Lastly, we discuss strategies to learn DSFs, and define the classes of deep supermodular functions, deep difference of submodular functions, and deep multivariate submodular functions, and discuss where these can be useful in applications.},
archivePrefix = {arXiv},
arxivId = {1701.08939},
author = {Dolhansky, Brian and Bilmes, Jeffrey A},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
eprint = {1701.08939},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dolhansky, Bilmes - 2016 - Deep submodular functions definitions and learning.pdf:pdf},
issn = {10495258},
title = {{Deep submodular functions: definitions and learning}},
url = {http://papers.nips.cc/paper/6361-deep-submodular-functions-definitions-and-learning.pdf},
year = {2016}
}
@article{Lewis2004,
abstract = {Reuters Corpus Volume I (RCV1) is an archive of over 800,000 manually categorized newswire stories recently made available by Reuters, Ltd. for research purposes. Use of this data for research on text categorization requires a detailed understanding of the real world constraints under which the data was produced. Drawing on interviews with Reuters personnel and access to Reuters documentation, we describe the coding policy and quality control procedures used in producing the RCV1 data, the intended semantics of the hierarchical category taxonomies, and the corrections necessary to remove errorful data. We refer to the original data as RCV1-v1, and the corrected data as RCV1-v2. We benchmark several widely used supervised learning methods on RCV1-v2, illustrating the collection's properties, suggesting new directions for research, and providing baseline results for future studies. We make available detailed, per-category experimental results, as well as corrected versions of the category assignments and taxonomy structures, via online appendices.},
author = {Lewis, David D. and Yang, Yiming and Rose, Tony G. and Li, Fan},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Applications,Automated indexing,Controlled vocabulary indexing,Effectiveness measures,Evaluation,Feature selection,K-NN,Methodology,Multiclass,Multilabel,Nearest neighbor,News articles,Operational systems,Rocchio,SCut,SCutFBR,SVMs,Support vector machines,Term weighting,Test collection,Text classification,Thresholding},
pages = {361--397},
title = {{RCV1: A new benchmark collection for text categorization research}},
volume = {5},
year = {2004}
}
@article{Summers2016,
abstract = {Controllability and observability have long been recognized as fundamental structural properties of dynamical systems, but have recently seen renewed interest in the context of large, complex networks of dynamical systems. A basic problem is sensor and actuator placement: choose a subset from a finite set of possible placements to optimize some real-valued controllability and observability metrics of the network. Surprisingly little is known about the structure of such combinatorial optimization problems. In this paper, we show that several important classes of metrics based on the controllability and observability Gramians have a strong structural property that allows for either efficient global optimization or an approximation guarantee by using a simple greedy heuristic for their maximization. In particular, the mapping from possible placements to several scalar functions of the associated Gramian is either a modular or submodular set function. The results are illustrated on randomly generated systems and on a problem of power-electronic actuator placement in a model of the European power grid.},
archivePrefix = {arXiv},
arxivId = {1404.7665},
author = {Summers, Tyler H. and Cortesi, Fabrizio L. and Lygeros, John},
doi = {10.1109/TCNS.2015.2453711},
eprint = {1404.7665},
issn = {23255870},
journal = {IEEE Transactions on Control of Network Systems},
keywords = {Controllability,Gramians,dynamical networks,sensor and actuator placement,submodularity},
number = {1},
pages = {91--101},
publisher = {IEEE},
title = {{On Submodularity and Controllability in Complex Dynamical Networks}},
volume = {3},
year = {2016}
}
@phdthesis{Lowry2020,
author = {Lowry, Bryan},
school = {Naval Postgraduate School},
title = {{Distributed Submodular Optimization for a UXV Networked Control System}},
year = {2020}
}
@inproceedings{Wang2020,
abstract = {We study planning with submodular objective functions, where instead of maximizing the cumulative reward, the goal is to maximize the objective value induced by a submodular function. Our framework subsumes standard planning and submodular maximization with cardinality constraints as special cases, and thus many practical applications can be naturally formulated within our framework. Based on the notion of multilinear extension, we propose a novel and theoretically principled algorithmic framework for planning with submodular objective functions, which recovers classical algorithms when applied to the two special cases mentioned above. Empirically, our approach significantly outperforms baseline algorithms on synthetic environments and navigation tasks.},
archivePrefix = {arXiv},
arxivId = {2010.11863},
author = {Wang, Ruosong and Zhang, Hanrui and Chaplot, Devendra Singh and Garagi{\'{c}}, Denis and Salakhutdinov, Ruslan},
booktitle = {arXiv preprint arXiv:2010.11863},
eprint = {2010.11863},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2020 - Planning with Submodular Objective Functions.pdf:pdf},
pages = {1--20},
title = {{Planning with Submodular Objective Functions}},
url = {http://arxiv.org/abs/2010.11863},
year = {2020}
}
@article{Gotovos2015,
abstract = {A wide range of AI problems, such as sensor placement, active learning, and network influence maximization, require sequentially selecting elements from a large set with the goal of optimizing the utility of the selected subset. Moreover, each element that is picked may provide stochastic feedback, which can be used to make smarter decisions about future selections. Finding efficient policies for this general class of adaptive optimization problems can be extremely hard. However, when the objective function is adaptive monotone and adaptive submodular, a simple greedy policy attains a 1-1/e approximation ratio in terms of expected utility. Unfortunately, many practical objective functions are naturally non-monotone; to our knowledge, no existing policy has provable performance guarantees when the assumption of adaptive monotonicity is lifted. We propose the adaptive random greedy policy for maximizing adaptive submodular functions, and prove that it retains the aforementioned 1-1/e approximation ratio for functions that are also adaptive monotone, while it additionally provides a 1/e approximation ratio for non-monotone adaptive submodular functions. We showcase the benefits of adaptivity on three real-world network data sets using two non-monotone functions, representative of two classes of commonly encountered non-monotone objectives.},
author = {Gotovos, Alkis and Karbasi, Amin and Krause, Andreas},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gotovos, Karbasi, Krause - 2015 - Non-monotone adaptive submodular maximization.pdf:pdf},
isbn = {9781577357384},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {Technical Papers — Sequential Decision Making},
number = {Ijcai},
pages = {1996--2003},
title = {{Non-monotone adaptive submodular maximization}},
volume = {2015-Janua},
year = {2015}
}
@article{Gabillon2014,
abstract = {Maximization of submodular functions has wide applications in artificial intelligence and machine learning. In this paper, we propose a scalable learning algorithm for maximizing an adaptive submodular function. The key structural assumption in our solution is that the state of each item is distributed according to a generalized linear model, which is conditioned on the feature vector of the item. Our objective is to learn the parameters of this model. We analyze the performance of our algorithm, and show that its regret is polylogarithmic in time and quadratic in the number of features. Finally, we evaluate our solution on two problems, preference elicitation and face detection, and show that high-quality policies can be learned sample efficiently.},
author = {Gabillon, Victor and Kveton, Branislav and Wen, Zheng and Eriksson, Brian and Muthukrishnan, S.},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gabillon et al. - 2014 - Large-scale optimistic adaptive submodularity.pdf:pdf},
isbn = {9781577356790},
journal = {Proceedings of the National Conference on Artificial Intelligence},
keywords = {Novel Machine Learning Algorithms},
pages = {1816--1823},
title = {{Large-scale optimistic adaptive submodularity}},
volume = {3},
year = {2014}
}
@article{Amanatidis2020,
abstract = {Constrained submodular maximization problems encompass a wide variety of applications, including personalized recommendation, team formation, and revenue maximization via viral marketing. The massive instances occurring in modern day applications can render existing algorithms prohibitively slow, while frequently, those instances are also inherently stochastic. Focusing on these challenges, we revisit the classic problem of maximizing a (possibly nonmonotone) submodular function subject to a knapsack constraint. We present a simple randomized greedy algorithm that achieves a 5.83 approximation and runs in O(n log n) time, i.e., at least a factor n faster than other state-of-the-art algorithms. The robustness of our approach allows us to further transfer it to a stochastic version of the problem. There, we obtain a 9-approximation to the best adaptive policy, which is the first constant approximation for non-monotone objectives. Experimental evaluation of our algorithms showcases their improved performance on real and synthetic data.},
archivePrefix = {arXiv},
arxivId = {2007.05014},
author = {Amanatidis, Georgios and Fusco, Federico and Lazos, Philip and Leonardi, Stefano and Reiffenh{\"{a}}user, Rebecca},
eprint = {2007.05014},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Amanatidis et al. - 2020 - Fast Adaptive Non-Monotone Submodular Maximization Subject to a Knapsack Constraint.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--23},
title = {{Fast Adaptive Non-Monotone Submodular Maximization Subject to a Knapsack Constraint}},
year = {2020}
}
@article{Horel2015,
abstract = {In recent years, social networking platforms have developed into extraordinary channels for spreading and consuming information. Along with the rise of such infrastructure, there is continuous progress on techniques for spreading information effectively through inuential users. In many applications, one is restricted to select inuencers from a set of users who engaged with the topic being promoted, and due to the structure of social networks, these users often rank low in terms of their inuence potential. An alternative approach one can consider is an adaptive method which selects users in a manner which targets their inuential neighbors. The advantage of such an approach is that it leverages the friendship paradox in social networks: while users are often not inuential, they often know someone who is. Despite the various complexities in such optimization problems, we show that scalable adaptive seeding is achievable. In particular, we develop algorithms for linear inuence models with provable approximation guarantees that can be gracefully parallelized. To show the effectiveness of our methods we collected data from various verticals social network users follow. For each vertical, we collected data on the users who responded to a certain post as well as their neighbors, and applied our methods on this data. Our experiments show that adaptive seeding is scalable, and importantly, that it obtains dramatic improvements over standard approaches of information dissemination.},
archivePrefix = {arXiv},
arxivId = {1503.01438},
author = {Horel, Thibaut and Singer, Yaron},
doi = {10.1145/2736277.2741127},
eprint = {1503.01438},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Horel, Singer - 2015 - Scalable methods for adaptively seeding a social network.pdf:pdf},
isbn = {9781450334693},
journal = {WWW 2015 - Proceedings of the 24th International Conference on World Wide Web},
keywords = {Inuence Maximization,Two-stage Optimization},
pages = {441--451},
title = {{Scalable methods for adaptively seeding a social network}},
year = {2015}
}
@inproceedings{Crawford2019,
author = {Crawford, Victoria G.},
booktitle = {International Joint Conference on Artificial Intelligence (IJCAI)},
title = {{An Efficient Evolutionary Algorithm for Minimum Cost Submodular Cover}},
year = {2019}
}
@inproceedings{Li2020,
abstract = {In large-data applications, it is desirable to design algorithms with a high degree of parallelization. In the context of submodular optimization, adaptive complexity has become a widely-used measure of an algorithm's "sequentiality". Algorithms in the adaptive model proceed in rounds, and can issue polynomially many queries to a function f in each round. The queries in each round must be independent, produced by a computation that depends only on query results obtained in previous rounds. In this work, we examine two fundamental variants of submodular maximization in the adaptive complexity model: cardinality-constrained monotone maximization, and unconstrained non-mono-tone maximization. Our main result is that an r-round algorithm for cardinality-constrained monotone maximization cannot achieve an approximation factor better than 1 - 1/e - $\omega$(min{ 1/r, log2 n/r3 }), for any r < nc (where c>0 is some constant). This is the first result showing that the number of rounds must blow up polynomially large as we approach the optimal factor of 1-1/e. For the unconstrained non-monotone maximization problem, we show a positive result: For every instance, and every >0, either we obtain a (1/2-)-approximation in 1 round, or a (1/2+$\omega$(2))-approximation in O(1/2) rounds. In particular (and in contrast to the cardinality-constrained case), there cannot be an instance where (i) it is impossible to achieve an approximation factor better than 1/2 regardless of the number of rounds, and (ii) it takes r rounds to achieve a factor of 1/2-O(1/r).},
archivePrefix = {arXiv},
arxivId = {2002.09130},
author = {Li, Wenzheng and Liu, Paul and Vondr{\'{a}}k, Jan},
booktitle = {Proceedings of the Annual ACM Symposium on Theory of Computing},
doi = {10.1145/3357713.3384311},
eprint = {2002.09130},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Liu, Vondr{\'{a}}k - 2020 - A polynomial lower bound on adaptive complexity of submodular maximization.pdf:pdf},
isbn = {9781450369794},
issn = {07378017},
keywords = {Adaptive model,Lower bound,Optimization,Submodular,Symmetry gap},
month = {jun},
pages = {140--152},
publisher = {Association for Computing Machinery},
title = {{A polynomial lower bound on adaptive complexity of submodular maximization}},
year = {2020}
}
@misc{Shahriari2016a,
abstract = {Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involve many tunable configuration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.},
author = {Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P. and {De Freitas}, Nando},
booktitle = {Proceedings of the IEEE},
doi = {10.1109/JPROC.2015.2494218},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shahriari et al. - 2016 - Taking the human out of the loop A review of Bayesian optimization.pdf:pdf},
issn = {15582256},
keywords = {decision making,design of experiments,genomic medicine,optimization,response surface methodology,statistical learning},
month = {jan},
number = {1},
pages = {148--175},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Taking the human out of the loop: A review of Bayesian optimization}},
volume = {104},
year = {2016}
}
@inproceedings{Crawford2020,
author = {Crawford, Victoria G.},
booktitle = {arxiv preprint arXiv:1908:01230},
title = {{Faster Guarantees of Pareto Optimization for Submodular Maximization}},
year = {2020}
}
@article{Pan2020,
abstract = {{\textcopyright} 2013 IEEE. Information can propagate among Online Social Network (OSN) users at a high speed, which makes the OSNs important platforms for viral marketing. Although the viral marketing related problems in OSNs have been extensively studied in the past decade, the existing works all assume known propagation rates. In this paper, we propose a novel model, Dynamic Influence Propagation (DIP), which allows propagation rates to increase after a topic becomes popular and can be used for describing information propagation in OSNs more realistically. Based on DIP, we define a new research problem: Threshold Activation Problem under DIP (TAP-DIP). However, it adds another layer of complexity over the already #P-hard TAP problem. Despite it hardness, we are able to approximate TAP-DIP with O(log |V|) ratio, where |V| is the number of users in the network. Our solution consists of global optimization techniques and a novel solution to the general version of TAP. We also consider the more complicated case when the propagation rates may change multiple times and the changes are non-immediate, with corresponding solution and analyses. We test our solution using various real OSN datasets, and demonstrate that our solution not only generates high-quality seed sets, but also scales.},
author = {Pan, T. and Li, X. and Kuhnle, A. and Thai, M.T.},
doi = {10.1109/TNSE.2020.3015935},
issn = {23274697},
journal = {IEEE Transactions on Network Science and Engineering},
keywords = {Dynamic influence propagation,online social network,threshold activation problem},
number = {4},
title = {{Influence Diffusion in Online Social Networks with Propagation Rate Changes}},
volume = {7},
year = {2020}
}
@techreport{Andersson,
abstract = {We show that a unit-cost RAM with a word length of w bits can sort n integers in the range O.. 2W-1 in O (n log log n) time, for arbitrary w z log n, a significant improvement over the bound of O (n-) achieved by the fusion trees of Fredman and Willard. Provided that w 2 (log n)z+', for some fixed e > 0, the sorting can even be accomplished in linear expected time with a randomized algorithm. Both of our algorithms parallelize without loss on a unit-cost PRAM with a word length of w bits. The first one yields an algorithm that uses O (log n) time and O (n log log n) operations on a deterministic CRCW PRAM. The second one yields an algorithm that uses O(log n) expected time and O(n) expected operations on a randomized EREW PRAM, provided that w 2 (log n)2+' for some fixed c >0. Our deterministic and randomized sequential and parallel algorithms generalize to the lexicographic sorting problem of sorting multiple-precision integers represented in several words.},
author = {Andersson, Arne and Hagerupt, Torben},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andersson, Hagerupt - Unknown - Sorting in Linear Time.pdf:pdf},
title = {{Sorting in Linear Time?}}
}
@techreport{Nguye,
abstract = {A fundamental algorithmic result for matroids is that the maximum weight base can be computed using the greedy algorithm. For explicitly represented matroids an important question is the time complexity of computing such a base. It is known that one can compute it in time almost linear in the number of non-zero entries of the linear representation plus r $\omega$ , where r is the rank of the matroid and $\omega$ is the matrix multiplication exponent. In this work, we give an alternative algorithm for the same task.},
author = {Nguy{\^{e}}, Huy L},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguy{\^{e}} - Unknown - Fast greedy for linear matroids.pdf:pdf},
title = {{Fast greedy for linear matroids *}}
}
@article{Chekuri2019b,
abstract = {Partial Set Cover (PSC) is a generalization of the well-studied Set Cover problem (SC). In PSC the input consists of an integer $k$ and a set system $(U,S)$ where $U$ is a finite set, and $S \subseteq 2^U$ is a collection of subsets of $U$. The goal is to find a subcollection $S' \subseteq S$ of smallest cardinality such that sets in $S'$ cover at least $k$ elements of $U$; that is $|\cup_{A \in S'} A| \ge k$. SC is a special case of PSC when $k = |U|$. In the weighted version each set $X \in S$ has a non-negative weight $w(X)$ and the goal is to find a minimum weight subcollection to cover $k$ elements. Approximation algorithms for SC have been adapted to obtain comparable algorithms for PSC in various interesting cases. In recent work Inamdar and Varadarajan, motivated by geometric set systems, obtained a simple and elegant approach to reduce PSC to SC via the natural LP relaxation. They showed that if a deletion-closed family of SC admits a $\beta$-approximation via the natural LP relaxation, then one can obtain a $2(\beta + 1)$-approximation for PSC on the same family. In a subsequent paper, they also considered a generalization of PSC that has multiple partial covering constraints which is partly inspired by and generalizes previous work of Bera et al on the Vertex Cover problem. Our main goal in this paper is to demonstrate some useful connections between the results in previous work and submodularity. This allows us to simplify, and in some cases improve their results. We improve the approximation for PSC to $(1-1/e)(\beta + 1)$. We extend the previous work to the sparse setting.},
archivePrefix = {arXiv},
arxivId = {1907.04413},
author = {Chekuri, Chandra and Quanrud, Kent and Zhang, Zhao},
eprint = {1907.04413},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chekuri, Quanrud, Zhang - 2019 - On Approximating Partial Set Cover and Generalizations.pdf:pdf},
month = {jul},
title = {{On Approximating Partial Set Cover and Generalizations}},
url = {http://arxiv.org/abs/1907.04413},
year = {2019}
}
@techreport{Chekuri,
abstract = {We present an approximation algorithm for the maximum weight matroid intersection problem in the independence oracle model. Given two matroids defined over a common ground set N of n elements, let k be the rank of the matroid intersection and let Q denote the cost of an independence query for either ma-troid. An exact algorithm for finding a maximum car-dinality independent set (the unweighted case), due to Cunningham, runs in O(nk 1.5 Q) time. For the weighted case, algorithms due to Frank and Brezovec et al. run in O(nk 2 Q) time. There are also scaling based algorithms that run in O(n 2 √ k log(kW)Q) time, where W is the maximum weight (assuming all weights are integers), and ellipsoid-style algorithms that run in O n 2 log(n)Q + n 3 polylog(n) log(nW) time. Recently, Huang, Kakimura, and Kamiyama described an algorithm that gives a (1 −)-approximation for the weighted matroid intersection problem in O(nk 1.5 log(k)Q//) time. We observe that a (1 −)-approximation for the maximum cardinality case can be obtained in O(nkQ//) time by terminating Cunningham's algorithm early. Our main contribution is a (1−) approximation algorithm for the weighted matroid intersection problem with running time O(nk log 2 (1//)Q// 2).},
author = {Chekuri, Chandra and Quanrud, Kent},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chekuri, Quanrud - Unknown - A Fast Approximation for Maximum Weight Matroid Intersection.pdf:pdf},
title = {{A Fast Approximation for Maximum Weight Matroid Intersection *}},
url = {http://illinois.edu/$\sim$quanrud2/}
}
@article{Ashwinkumar2010,
abstract = {In the buyback problem, an algorithm observes a sequence of bids and must decide whether to accept each bid at the moment it arrives, subject to some constraints on the set of accepted bids. Decisions to reject bids are irrevocable, whereas decisions to accept bids may be canceled at a cost that is a fixed fraction of the bid value. Previous to our work, deterministic and randomized algorithms were known when the constraint is a matroid constraint. We extend this and give a deterministic algorithm for the case when the constraint is an intersection of $k$ matroid constraints. We further prove a matching lower bound on the competitive ratio for this problem and extend our results to arbitrary downward closed set systems. This problem has applications to banner advertisement, semi-streaming, routing, load balancing and other problems where preemption or cancellation of previous allocations is allowed.},
archivePrefix = {arXiv},
arxivId = {1009.5037},
author = {Ashwinkumar, B. V.},
doi = {10.1007/978-3-642-22006-7_32},
eprint = {1009.5037},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ashwinkumar - 2010 - Buyback Problem - Approximate matroid intersection with cancellation costs.pdf:pdf},
month = {sep},
title = {{Buyback Problem - Approximate matroid intersection with cancellation costs}},
url = {http://arxiv.org/abs/1009.5037 http://dx.doi.org/10.1007/978-3-642-22006-7_32},
year = {2010}
}
@article{Chen2020,
author = {Chen, Lin},
title = {{Black Box Submodular Maximization : Discrete and Continuous Settings}},
volume = {108},
year = {2020}
}
@article{Kazemi,
archivePrefix = {arXiv},
arxivId = {arXiv:2002.03503v1},
author = {Kazemi, Ehsan},
eprint = {arXiv:2002.03503v1},
pages = {1--23},
title = {{Regularized Submodular Maximization at Scale}}
}
@article{Chen2020a,
abstract = {Despite remarkable success in practice, modern machine learning models have been found to be susceptible to adversarial attacks that make human-imperceptible perturbations to the data, but result in serious and potentially dangerous prediction errors. To address this issue, practitioners often use adversarial training to learn models that are robust against such attacks at the cost of weaker generalization accuracy on unperturbed test sets. The conventional wisdom is that more training data should shrink the generalization gap between adversarially-trained models and standard models. However, we study the training of robust classifiers for both Gaussian and Bernoulli models under `∞ attacks, and we prove that more data may actually increase this gap. Furthermore, our theoretical results identify if and when additional data will finally begin to shrink the gap. Lastly, we experimentally demonstrate that our results also hold for linear regression models, which may indicate that this phenomenon occurs more broadly.},
archivePrefix = {arXiv},
arxivId = {2002.04725},
author = {Chen, Lin and Min, Yifei and Zhang, Mingrui and Karbasi, Amin},
eprint = {2002.04725},
issn = {23318422},
journal = {arXiv},
keywords = {Machine Learning, ICML},
title = {{More data can expand the generalization gap between adversarially robust and standard models}},
year = {2020}
}
@inproceedings{Balkanski2016,
abstract = {We consider the problem of learning sparse repesentations of data sets, where the goal is to reduce a data set in manner that optimizes multiple objectives. Motivated by applications of data summarization, we develop a new model which we refer to as the two-stage submodular maximization problem. This task can be viewed as a combinatorial analogue of representation learning problems such as dictionary learning and sparse regression. The two-stage problem strictly generalizes the problem of cardinality constrained submodular maximization, though the objective function is not submodular and the techniques for submodular maximization cannot be applied. We describe a continuous optimization method which achieves an approximation ratio which asymptotically approaches 1 - 1 /e. For instances where the asymptotics do not kick in, we design a local-search algorithm whose approximation ratio is arbitrarily close to 1/2. We empirically demonstrate the effectiveness of our methods on two multi-objective data summarization tasks, where the goal is to construct summaries via sparse representative subsets w.r.t. to predefined objectives.},
author = {Balkanski, Eric and Krause, Andreas and Mirzasoleiman, Baharan and Singer, Yaron},
booktitle = {International Conference on Machine Learning (ICML)},
isbn = {9781510829008},
title = {{Learning sparse combinatorial representations via two-stage submodular maximization}},
year = {2016}
}
@article{Tohidi,
archivePrefix = {arXiv},
arxivId = {arXiv:2006.09905v1},
author = {Tohidi, Ehsan and Amiri, Rouhollah and Coutino, Mario and Gesbert, David},
eprint = {arXiv:2006.09905v1},
pages = {1--12},
title = {{Submodularity in Action : From Machine Learning to Signal Processing Applications}}
}
@article{Stan2017a,
abstract = {In this paper, we consider optimizing submodular functions that are drawn from some unknown distribution. This setting arises, e.g., in recom-mender systems, where the utility of a subset of items may depend on a user-specific submodular utility function. In modern applications, the ground set of items is often so large that even the widely used (lazy) greedy algorithm is not efficient enough. As a remedy, we introduce the problem of sublinear lime probabilistic submodular maximization: Given training examples of functions (e.g., via user feature vectors), we seek to reduce the ground set so that optimizing new functions drawn from the same distribution will provide almost as much value when restricted to the reduced ground set as when using the full set. We cast this problem as a two-stage submodular maximization and develop a novel efficient algorithm for this problem which offers a 5(1-p) approximation ratio for general monotone submodular functions and general matroid constraints. We demonstrate the effectiveness of our approach on several real-world problem instances where running the maximization problem on the reduced ground set leads to two folds speed-up while incurring almost no loss.},
author = {Stan, Serban and Zadimoghaddam, Morteza and Krause, Andreas and Karbasi, Amin},
isbn = {9781510855144},
journal = {34th International Conference on Machine Learning, ICML 2017},
pages = {4981--4992},
title = {{Probabilistic submodular maximization in sub-linear time}},
volume = {7},
year = {2017}
}
@article{Krause2007,
abstract = {AI problems such as autonomous robotic exploration, automatic diagnosis and activity recognition have in common the need for choosing among a set of informative but possibly expensive observations. When monitoring spatial phenomena with sensor networks or mobile robots, for example, we need to decide which locations to observe in order to most effectively decrease the uncertainty, at minimum cost. These problems usually are NP-hard. Many observation selection objectives satisfy submodularity, an intuitive diminishing returns property - adding a sensor to a small deployment helps more than adding it to a large deployment. In this paper, we survey recent advances in systematically exploiting this submodularity property to efficiently achieve near-optimal observation selections, under complex constraints. We illustrate the effectiveness of our approaches on problems of monitoring environmental phenomena and water distribution networks. Copyright {\textcopyright} 2007, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
author = {Krause, Andreas and Guestrin, Carlos},
isbn = {1577353234},
journal = {AAAI Conference on Artificial Intelligence},
keywords = {New Scientific and Technical Advances in Research,Technical Papers},
title = {{Near-optimal observation selection using submodular functions}},
year = {2007}
}
@inproceedings{Kazemi2019a,
abstract = {Streaming algorithms are generally judged by the quality of their solution, memory footprint, and computational complexity. In this paper, we study the problem of maximizing a monotone submodular function in the streaming setting with a cardinality constraint k. We first propose SIEVE-STREAMING++, which requires just one pass over the data, keeps only O(k) elements and achieves the tight 1/2-approximation guarantee. The best previously known streaming algorithms either achieve a suboptimal 1/4-approximation with $\Theta$(k) memory or the optimal 1/2-approximation with O(k log k) memory. Next, we show that by buffering a small fraction of the stream and applying a careful filtering procedure, one can heavily reduce the number of adaptive computational rounds, thus substantially lowering the computational complexity of SIEVE-STREAMING++. We then generalize our results to the more challenging multi-source streaming setting. We show how one can achieve the tight 1/2-approximation guarantee with 0(k) shared memory while minimizing not only the required rounds of computations but also the total number of communicated bits. Finally, we demonstrate the efficiency of our algorithms on real-world data summarization tasks for multi-source streams of tweets and of YouTube videos.},
archivePrefix = {arXiv},
arxivId = {1905.00948},
author = {Kazemi, Ehsan and Mitrovic, Marko and Zadimoghaddam, Morteza and Lattanzi, Silvio and Karbasi, Amin},
booktitle = {36th International Conference on Machine Learning, ICML 2019},
eprint = {1905.00948},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kazemi et al. - 2019 - Submodular streaming in all its glory Tight approximation, minimum memory and low adaptive complexity.pdf:pdf},
isbn = {9781510886988},
month = {may},
pages = {5767--5784},
title = {{Submodular streaming in all its glory: Tight approximation, minimum memory and low adaptive complexity}},
url = {http://arxiv.org/abs/1905.00948},
volume = {2019-June},
year = {2019}
}
@techreport{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Superhuman AI for multiplayer poker.pdf:pdf},
keywords = {Convert to PDF or Image in batches!,Document Converter Pro,www.Neevia.com},
title = {{Superhuman AI for multiplayer poker}},
url = {http://science.sciencemag.org/}
}
@techreport{Balcan2020,
abstract = {Automating algorithm configuration is growing increasingly necessary as algorithms come with more and more tunable parameters. It is common to tune parameters using machine learning, optimizing algorithmic performance (runtime or solution quality, for example) using a training set of problem instances from the specific domain at hand. We investigate a fundamental question about these techniques: how large should the training set be to ensure that a parameter's average empirical performance over the training set is close to its expected, future performance? We answer this question for algorithm configuration problems that exhibit a widely-applicable structure: the algorithm's performance as a function of its parameters can be approximated by a "sim-ple" function. We show that if this approximation holds under the L ∞-norm, we can provide strong sample complexity bounds, but if the approximation holds only under the L p-norm for p < ∞, it is not possible to provide meaningful sample complexity bounds in the worst case. We empirically evaluate our bounds in the context of integer programming, obtaining sample complexity bounds that are up to 700 times smaller than the previously best-known bounds (Balcan et al., 2018a).},
author = {Balcan, Maria-Florina and Sandholm, Tuomas and Vitercik, Ellen},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balcan, Sandholm, Vitercik - 2020 - Refined Bounds for Algorithm Configuration The Knife-edge of Dual Class Approximability.pdf:pdf},
title = {{Refined Bounds for Algorithm Configuration: The Knife-edge of Dual Class Approximability}},
year = {2020}
}
@article{Balcan2019,
abstract = {Algorithms -- for example for scientific analysis -- typically have tunable parameters that significantly influence computational efficiency and solution quality. If a parameter setting leads to strong algorithmic performance on average over a set of training instances, that parameter setting -- ideally -- will perform well on previously unseen future instances. However, if the set of training instances is too small, average performance will not generalize to future performance. This raises the question: how large should this training set be? We answer this question for any algorithm satisfying an easy-to-describe, ubiquitous property: its performance is a piecewise-structured function of its parameters. We provide the first unified sample complexity framework for algorithm parameter configuration; prior research followed case-by-case analyses. We present example applications to diverse domains including biology, political science, economics, integer programming, and clustering.},
archivePrefix = {arXiv},
arxivId = {1908.02894},
author = {Balcan, Maria-Florina and DeBlasio, Dan and Dick, Travis and Kingsford, Carl and Sandholm, Tuomas and Vitercik, Ellen},
eprint = {1908.02894},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balcan et al. - 2019 - How much data is sufficient to learn high-performing algorithms.pdf:pdf},
month = {aug},
title = {{How much data is sufficient to learn high-performing algorithms?}},
url = {http://arxiv.org/abs/1908.02894},
year = {2019}
}
@techreport{Farina,
abstract = {Sequential decision processes (SDPs) model the multi-stage online decision-making problems that each player faces in an extensive-form game, as well as MDPs and POMDPs where the agent conditions on observed history. Prior regret minimization approaches for sequential decision processes typically rely heavily on having access to counterfactuals, that is, information on what would have happened had the agent chosen a different action at any decision point. While this assumption is reasonable when regret minimization algorithms are used in self-play (for instance, as a way to converge to a Nash equilibrium in an extensive-form game), it is unrealis-tic in online decision-making settings, where the algorithm is deployed to learn strategies against an unknown environment. In this paper, we give the first efficient algorithm for the bandit linear optimization problem on SDPs-and therefore also extensive-form games-and show that it achieves O(√ T) cumulative regret in expectation against any strategy.},
author = {Farina, Gabriele and Schmucker, Robin and Sandholm, Tuomas},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Farina, Schmucker, Sandholm - Unknown - Counterfactual-Free Regret Minimization for Sequential Decision Making and Extensive-Form Games.pdf:pdf},
keywords = {Convert to PDF or Image in batches!,Document Converter Pro,www.Neevia.com},
title = {{Counterfactual-Free Regret Minimization for Sequential Decision Making and Extensive-Form Games}},
url = {www.aaai.org}
}
@techreport{Farina2020,
abstract = {Monte-Carlo counterfactual regret minimization (MCCFR) is the state-of-the-art algorithm for solving sequential games that are too large for full tree traversals. It works by using gradient estimates that can be computed via sampling. However , stochastic methods for sequential games have not been investigated extensively beyond MCCFR. In this paper we develop a new framework for developing stochastic regret minimization methods. This framework allows us to use any regret-minimization algorithm, coupled with any gradient estimator. The MCCFR algorithm can be analyzed as a special case of our framework , and this analysis leads to significantly stronger theoretical guarantees on convergence, while simultaneously yielding a simplified proof. Our framework allows us to instantiate several new stochastic methods for solving sequential games. We show extensive experiments on five games, where some variants of our methods out-perform MCCFR.},
author = {Farina, Gabriele and Kroer, Christian and Sandholm, Tuomas},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Farina, Kroer, Sandholm - 2020 - Stochastic Regret Minimization in Extensive-Form Games.pdf:pdf},
title = {{Stochastic Regret Minimization in Extensive-Form Games}},
year = {2020}
}
@article{Zhang2020,
abstract = {Often -- for example in war games, strategy video games, and financial simulations -- the game is given to us only as a black-box simulator in which we can play it. In these settings, since the game may have unknown nature action distributions (from which we can only obtain samples) and/or be too large to expand fully, it can be difficult to compute strategies with guarantees on exploitability. Recent work \cite{Zhang20:Small} resulted in a notion of certificate for extensive-form games that allows exploitability guarantees while not expanding the full game tree. However, that work assumed that the black box could sample or expand arbitrary nodes of the game tree at any time, and that a series of exact game solves (via, for example, linear programming) can be conducted to compute the certificate. Each of those two assumptions severely restricts the practical applicability of that method. In this work, we relax both of the assumptions. We show that high-probability certificates can be obtained with a black box that can do nothing more than play through games, using only a regret minimizer as a subroutine. As a bonus, we obtain an equilibrium-finding algorithm with $\tilde O(1/\sqrt{T})$ convergence rate in the extensive-form game setting that does not rely on a sampling strategy with lower-bounded reach probabilities (which MCCFR assumes). We demonstrate experimentally that, in the black-box setting, our methods are able to provide nontrivial exploitability guarantees while expanding only a small fraction of the game tree.},
archivePrefix = {arXiv},
arxivId = {2009.07384},
author = {Zhang, Brian Hu and Sandholm, Tuomas},
eprint = {2009.07384},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Sandholm - 2020 - Finding and Certifying (Near-)Optimal Strategies in Black-Box Extensive-Form Games.pdf:pdf},
month = {sep},
title = {{Finding and Certifying (Near-)Optimal Strategies in Black-Box Extensive-Form Games}},
url = {http://arxiv.org/abs/2009.07384},
year = {2020}
}
@article{Zhang2020a,
abstract = {In many game settings, the game is not explicitly given but is only accessible by playing it. While there have been impressive demonstrations in such settings, prior techniques have not offered safety guarantees, that is, guarantees on the game-theoretic exploitability of the computed strategies. In this paper we introduce an approach that shows that it is possible to provide exploitability guarantees in such settings without ever exploring the entire game. We introduce a notion of a certificate of an extensive-form approximate Nash equilibrium. For verifying a certificate, we give an algorithm that runs in time linear in the size of the certificate rather than the size of the whole game. In zero-sum games, we further show that an optimal certificate -- given the exploration so far -- can be computed with any standard game-solving algorithm (e.g., using a linear program or counterfactual regret minimization). However, unlike in the cases of normal form or perfect information, we show that certain families of extensive-form games do not have small approximate certificates, even after making extremely nice assumptions on the structure of the game. Despite this difficulty, we find experimentally that very small certificates, even exact ones, often exist in large and even in infinite games. Overall, our approach enables one to try one's favorite exploration strategies while offering exploitability guarantees, thereby decoupling the exploration strategy from the equilibrium-finding process.},
archivePrefix = {arXiv},
arxivId = {2006.16387},
author = {Zhang, Brian Hu and Sandholm, Tuomas},
eprint = {2006.16387},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Sandholm - 2020 - Small Nash Equilibrium Certificates in Very Large Games.pdf:pdf},
month = {jun},
title = {{Small Nash Equilibrium Certificates in Very Large Games}},
url = {http://arxiv.org/abs/2006.16387},
year = {2020}
}
@article{Kroer2019,
abstract = {Limited lookahead has been studied for decades in perfect-information games. We initiate a new direction via two simultaneous deviation points: generalization to imperfect-information games and a game-theoretic approach. We study how one should act when facing an opponent whose lookahead is limited. We study this for opponents that differ based on their lookahead depth, based on whether they, too, have imperfect information, and based on how they break ties. We characterize the hardness of finding a Nash equilibrium or an optimal commitment strategy for either player, showing that in some of these variations the problem can be solved in polynomial time while in others it is PPAD-hard, NP-hard, or inapproximable. We proceed to design algorithms for computing optimal commitment strategies---for when the opponent breaks ties favorably, according to a fixed rule, or adversarially. We then experimentally investigate the impact of limited lookahead. The limited-lookahead player often obtains the value of the game if she knows the expected values of nodes in the game tree for some equilibrium---but we prove this is not sufficient in general. Finally, we study the impact of noise in those estimates and different lookahead depths.},
archivePrefix = {arXiv},
arxivId = {1902.06335},
author = {Kroer, Christian and Sandholm, Tuomas},
eprint = {1902.06335},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kroer, Sandholm - 2019 - Limited Lookahead in Imperfect-Information Games.pdf:pdf},
month = {feb},
title = {{Limited Lookahead in Imperfect-Information Games}},
url = {http://arxiv.org/abs/1902.06335},
year = {2019}
}
@techreport{Balcan,
abstract = {Algorithms typically come with tunable parameters that have a considerable impact on the computational resources they consume. Too often, practitioners must hand-tune the parameters , a tedious and error-prone task. A recent line of research provides algorithms that return nearly-optimal parameters from within a finite set. These algorithms can be used when the parameter space is infinite by providing as input a random sample of parameters. This data-independent dis-cretization, however, might miss pockets of nearly-optimal parameters: prior research has presented scenarios where the only viable parameters lie within an arbitrarily small region. We provide an algorithm that learns a finite set of promising parameters from within an infinite set. Our algorithm can help compile a configuration portfolio, or it can be used to select the input to a configuration algorithm for finite parameter spaces. Our approach applies to any configuration problem that satisfies a simple yet ubiquitous structure: the algorithm's performance is a piecewise constant function of its parameters. Prior research has exhibited this structure in domains from integer programming to clustering.},
author = {Balcan, Maria-Florina and Sandholm, Tuomas and Vitercik, Ellen},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balcan, Sandholm, Vitercik - Unknown - Learning to Optimize Computational Resources Frugal Training with Generalization Guarantees.pdf:pdf},
keywords = {Machine Learning},
title = {{Learning to Optimize Computational Resources: Frugal Training with Generalization Guarantees}},
url = {www.aaai.org}
}
@techreport{Blum,
abstract = {The stochastic matching problem deals with finding a maximum matching in a graph whose edges are unknown but can be accessed via queries. This is a special case of stochastic k-set packing, where the problem is to find a maximum packing of sets, each of which exists with some probability. In this paper, we provide edge and set query algorithms for these two problems, respectively, that provably achieve some fraction of the omniscient optimal solution. Our main theoretical result for the stochastic matching (i.e., 2-set packing) problem is the design of an adaptive algorithm that queries only a constant number of edges per vertex and achieves a (1 −) fraction of the omniscient optimal solution, for an arbitrarily small > 0. Moreover, this adaptive algorithm performs the queries in only a constant number of rounds. We complement this result with a non-adaptive (i.e., one round of queries) algorithm that achieves a (0.5 −) fraction of the omniscient optimum. We also extend both our results to stochastic k-set packing by designing an adaptive algorithm that achieves a (2 k −) fraction of the omniscient optimal solution, again with only O(1) queries per element. This guarantee is close to the best known polynomial-time approximation ratio of 3 k+1 − for the deterministic k-set packing problem [F{\"{u}}rer and Yu 2013]. We empirically explore the application of (adaptations of) these algorithms to the kidney exchange problem, where patients with end-stage renal failure swap willing but incompatible donors. We show on both generated data and on real data from the first 169 match runs of the UNOS nationwide kidney exchange that even a very small number of non-adaptive edge queries per vertex results in large gains in expected successful matches.},
author = {Blum, Avrim and Dickerson, John P and Procaccia, Ariel D},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blum, Dickerson, Procaccia - Unknown - X Ignorance is Almost Bliss Near-Optimal Stochastic Matching With Few Queries.pdf:pdf},
keywords = {keyword1 key2 key3},
title = {{X Ignorance is Almost Bliss: Near-Optimal Stochastic Matching With Few Queries}},
url = {http://optn.transplant.hrsa.gov.}
}
@article{Kroer2020,
abstract = {Sparse iterative methods, in particular first-order methods, are known to be among the most effective in solving large-scale two-player zero-sum extensive-form games. The convergence rates of these methods depend heavily on the properties of the distance-generating function that they are based on. We investigate both the theoretical and practical performance improvement of first-order methods (FOMs) for solving extensive-form games through better design of the dilated entropy function—a class of distance-generating functions related to the domains associated with the extensive-form games. By introducing a new weighting scheme for the dilated entropy function, we develop the first distance-generating function for the strategy spaces of sequential games that has only a logarithmic dependence on the branching factor of the player. This result improves the overall convergence rate of several FOMs working with dilated entropy function by a factor of $\Omega$ (bdd) , where b is the branching factor of the player, and d is the depth of the game tree. Thus far, counterfactual regret minimization methods have been faster in practice, and more popular, than FOMs despite their theoretically inferior convergence rates. Using our new weighting scheme and a practical parameter tuning procedure we show that, for the first time, the excessive gap technique, a classical FOM, can be made faster than the counterfactual regret minimization algorithm in practice for large games, and that the aggressive stepsize scheme of CFR+ is the only reason that the algorithm is faster in practice.},
author = {Kroer, Christian and Waugh, Kevin and Kılın{\c{c}}-Karzan, Fatma and Sandholm, Tuomas},
doi = {10.1007/s10107-018-1336-7},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kroer et al. - 2020 - Faster algorithms for extensive-form game solving via improved smoothing functions.pdf:pdf},
issn = {14364646},
journal = {Mathematical Programming},
keywords = {Bilinear saddle-point problem,Extensive-form game,First-order method,Nash equilibrium,Zero-sum game},
month = {jan},
number = {1-2},
pages = {385--417},
publisher = {Springer},
title = {{Faster algorithms for extensive-form game solving via improved smoothing functions}},
volume = {179},
year = {2020}
}
@techreport{Balcana,
abstract = {Algorithms typically come with tunable parameters that have a considerable impact on the computational resources they consume. Too often, practitioners must hand-tune the parameters , a tedious and error-prone task. A recent line of research provides algorithms that return nearly-optimal parameters from within a finite set. These algorithms can be used when the parameter space is infinite by providing as input a random sample of parameters. This data-independent dis-cretization, however, might miss pockets of nearly-optimal parameters: prior research has presented scenarios where the only viable parameters lie within an arbitrarily small region. We provide an algorithm that learns a finite set of promising parameters from within an infinite set. Our algorithm can help compile a configuration portfolio, or it can be used to select the input to a configuration algorithm for finite parameter spaces. Our approach applies to any configuration problem that satisfies a simple yet ubiquitous structure: the algorithm's performance is a piecewise constant function of its parameters. Prior research has exhibited this structure in domains from integer programming to clustering.},
author = {Balcan, Maria-Florina and Sandholm, Tuomas and Vitercik, Ellen},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balcan, Sandholm, Vitercik - Unknown - Learning to Optimize Computational Resources Frugal Training with Generalization Guarantees.pdf:pdf},
keywords = {Machine Learning},
title = {{Learning to Optimize Computational Resources: Frugal Training with Generalization Guarantees}},
url = {www.aaai.org}
}
@techreport{Balcan2018a,
abstract = {Tree search algorithms, such as branch-and-bound, are the most widely used tools for solving combinatorial problems. These algorithms recursively partition the search space to find an optimal solution. To keep the tree small, it is crucial to carefully decide, when expanding a tree node, which variable to branch on at that node to partition the remaining space. Many partitioning techniques have been proposed, but no theory describes which is optimal. We show how to use machine learning to determine an optimal weight-ing of any set of partitioning procedures for the instance distribution at hand using samples. Via theory and experiments, we show that learning to branch is both practical and hugely beneficial.},
author = {Balcan, Maria-Florina and Dick, Travis and Sandholm, Tuomas and Vitercik, Ellen},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balcan et al. - 2018 - Learning to Branch.pdf:pdf},
title = {{Learning to Branch}},
year = {2018}
}
@techreport{Balcan2020a,
abstract = {A two-part tariff is a pricing scheme that consists of an up-front lump sum fee and a per unit fee. Various products in the real world are sold via a menu, or list, of two-part tariffs-for example gym memberships , cell phone data plans, etc. We study learning high-revenue menus of two-part tariffs from buyer valuation data, in the setting where the mechanism designer has access to samples from the distribution over buyers' values rather than an explicit description thereof. Our algorithms have clear direct uses, and provide the missing piece for the recent generalization theory of two-part tariffs. We present a polynomial time algorithm for optimizing one two-part tariff. We also present an algorithm for optimizing a length-L menu of two-part tariffs with run time exponential in L but polynomial in all other problem parameters. We then generalize the problem to multiple markets. We prove how many samples suffice to guarantee that a two-part tariff scheme that is feasible on the samples is also feasible on a new problem instance with high probability. We then show that computing revenue-maximizing feasible prices is hard even for buyers with additive valuations. Then, for buyers with identical valuation distributions, we present a condition that is sufficient for the two-part tariff scheme from the unsegmented setting to be optimal for the market-segmented setting. Finally, we prove a generalization result that states how many samples suffice so that we can compute the unseg-mented solution on the samples and still be guaranteed that we get a near-optimal solution for the market-segmented setting with high probability.},
author = {Balcan, Maria-Florina and Prasad, Siddharth and Sandholm, Tuomas},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balcan, Prasad, Sandholm - 2020 - Efficient Algorithms for Learning Revenue-Maximizing Two-Part Tariffs.pdf:pdf},
keywords = {Agent-based and Multi-agent Systems: Economic Para},
title = {{Efficient Algorithms for Learning Revenue-Maximizing Two-Part Tariffs}},
year = {2020}
}
@techreport{Lesser2008,
abstract = {Traditionally, AI researchers have been attracted by the idea of creating machines that are intelligent, or understanding of the nature of human intelligence. My path to becoming an AI researcher was nontraditional, and in a way, this path has shaped my view on what the important issues are in AI. My computer science Ph.D. dissertation was not in AI or a related field, but in parallel computer architectures and operating systems [1]-yet, in a surprising way its origins are indirectly linked to AI. The idea for my dissertation grew from a term project that I did in a computer architecture course that Professor John McCarthy taught when I began my graduate studies at Stanford in the fall of 1966. AI at the Forefront of Software Complexity It was probably inevitable that I would eventually do research in AI since my abiding attraction to computer science has been the opportunity for constructing complex hardware and software artifacts and understanding how they operate. Since its inception, AI has pushed the boundaries of software complexity in order to construct programs that exhibit intelligence. Essential to the AI enterprise, and probably the aspect that has caused its software to be complex from the very beginning, is the need to deal directly with uncertainty in its many guises-uncertainty in: the information that is sensed from the environment; the situation specificity of knowledge (there is rarely common-sense knowledge that can be applied uniformly over a broad spectrum of real-world situations); the lack of complete theories that fully explain naturally occurring phenomena; and the bounded rationality of computation (NP hardness) that makes it impossible to fully assess all options. Dealing with the ubiquitous uncertainty in both data and control has led to ideas such as delayed resolution of uncertainty through non-deterministic and assumption-based computation, asynchronous and opportunistic application of knowledge and its associated constraints, exploiting approximate knowledge and heuristics to focus problem-solving activities, combining diverse sources of knowledge to resolve uncertainty, and self-aware computation and meta-level reasoning to provide more context for decision making under uncertainty. Having uncertainty as a first-class concept in computation, and the related need for large amounts of knowledge (and its modular representation and flexible application), have caused AI to constantly go beyond the contemporaneous boundaries of software complexity. This will likely continue in the future as the field builds increasingly advanced intelligent systems that operate in more open, distributed and real-world environments. The architectural design and control of such intelligent systems in terms of defining the components that make up the system and specifying the mechanisms and protocols that define their interaction has been an important aspect of my research.},
author = {Lesser, Victor},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lesser - 2008 - Reflections on being an AI System Architect.pdf:pdf},
title = {{Reflections on being an AI System Architect}},
year = {2008}
}
@techreport{Sandholm1997,
abstract = {This paper analyzes coalitions among self-interested agents that need to solve combinatorial optimization problems to operate efficiently in the world. By colluding (coordinating their actions by solving a joint optimization problem) the agents can sometimes save costs compared to operating individually. A model of bounded rationality is adopted where computation resources are costly. It is not worthwhile solving the problems optimally: solution quality is decision-theoretically traded off against computation cost. A normative, application-and protocol-independent theory of coalitions among bounded-rational agents is devised. The optimal coalition structure and its stability are significantly affected by the agents' algorithms' performance profiles and the cost of computation. This relationship is first analyzed theoretically. Then a domain classification including rational and bounded-rational agents is introduced. Experimental results are presented in vehicle routing with real data from five dispatch centers. This problem is NP-complete and the instances are so large that-with current technology-any agent's rationality is bounded by computational complexity. @ 1997 Elsevier Science B.V.},
author = {Sandholm, Tuomas W and Lesser, Victor R},
booktitle = {Artificial Intelligence},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sandholm, Lesser - 1997 - Coalitions among computationally bounded agents.pdf:pdf},
keywords = {Bounded rationality,Coalition formation,Distributed AI,Game theory,Multiagent systems,Negotiation,Resource-bounded reasoning},
pages = {99--137},
title = {{Coalitions among computationally bounded agents}},
volume = {94},
year = {1997}
}
@inproceedings{Haba2020a,
abstract = {In this paper, we propose a novel framework that converts streaming algorithms for monotone submodular maximization into streaming algorithms for non-monotone submodular maximiza-tion. This reduction readily leads to the currently tightest deterministic approximation ratio for sub-modular maximization subject to a k-matchoid constraint. Moreover, we propose the first streaming algorithm for monotone submodular maxi-mization subject to k-extendible and k-set system constraints. Together with our proposed reduction, we obtain O(k log k) and O(k 2 log k) approximation ratio for submodular maximization subject to the above constraints, respectively. We extensively evaluate the empirical performance of our algorithm against the existing work in a series of experiments including finding the maximum independent set in randomly generated graphs, maximizing linear functions over social networks, movie recommendation, Yelp location summa-rization, and Twitter data summarization.},
author = {Haba, Ran and Kazemi, Ehsan and Feldman, Moran and Karbasi, Amin},
booktitle = {International Conference on Machine Learning (ICML)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haba et al. - 2020 - Streaming Submodular Maximization under a k-Set System Constraint.pdf:pdf},
title = {{Streaming Submodular Maximization under a k-Set System Constraint}},
year = {2020}
}
@article{Buchbinder2018b,
abstract = {We study the problem of maximizing a monotone submodular function subject to a matroid constraint and present a deterministic algorithm that achieves (1/2 + {\epsilon})-approximation for the problem. This algorithm is the first deterministic algorithm known to improve over the 1/2-approximation ratio of the classical greedy algorithm proved by Nemhauser, Wolsely and Fisher in 1978.},
archivePrefix = {arXiv},
arxivId = {1807.05532},
author = {Buchbinder, Niv and Feldman, Moran and Garg, Mohit},
eprint = {1807.05532},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buchbinder, Feldman, Garg - 2018 - Deterministic (12 {epsilon})-Approximation for Submodular Maximization over a Matroid.pdf:pdf},
month = {jul},
title = {{Deterministic (1/2 + {\epsilon})-Approximation for Submodular Maximization over a Matroid}},
url = {http://arxiv.org/abs/1807.05532},
year = {2018}
}
@article{Mazyavkina2020a,
abstract = {Combinatorial optimization (CO) is the workhorse of numerous important applications in operations research, engineering, and other fields and, thus, has been attracting enormous attention from the research community recently. Some efficient approaches to common problems involve using hand-crafted heuristics to sequentially construct a solution. Therefore, it is intriguing to see how a CO problem can be reformulated as a sequential decision-making process, and whether these heuristics can be implicitly learned by a reinforcement learning (RL) agent. This survey explores the synergy between the CO and RL frameworks, which can become a promising direction for solving combinatorial problems.},
archivePrefix = {arXiv},
arxivId = {2003.03600},
author = {Mazyavkina, Nina and Sviridov, Sergey and Ivanov, Sergei and Burnaev, Evgeny},
eprint = {2003.03600},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mazyavkina et al. - 2020 - Reinforcement Learning for Combinatorial Optimization A Survey(2).pdf:pdf},
month = {mar},
title = {{Reinforcement Learning for Combinatorial Optimization: A Survey}},
url = {http://arxiv.org/abs/2003.03600},
year = {2020}
}
@inproceedings{Han2020,
abstract = {We study the problem of maximizing a non-monotone, non-negative submodular function subject to a matroid constraint. The prior best-known deterministic approximation ratio for this problem is $\frac{1}{4}-\epsilon$ under $\mathcal{O}(({n^4}/{\epsilon})\log n)$ time complexity. We show that this deterministic ratio can be improved to $\frac{1}{4}$ under $\mathcal{O}(nr)$ time complexity, and then present a more practical algorithm dubbed TwinGreedyFast which achieves $\frac{1}{4}-\epsilon$ deterministic ratio in nearly-linear running time of $\mathcal{O}(\frac{n}{\epsilon}\log\frac{r}{\epsilon})$. Our approach is based on a novel algorithmic framework of simultaneously constructing two candidate solution sets through greedy search, which enables us to get improved performance bounds by fully exploiting the properties of independence systems. As a byproduct of this framework, we also show that TwinGreedyFast achieves $\frac{1}{2p+2}-\epsilon$ deterministic ratio under a $p$-set system constraint with the same time complexity. To showcase the practicality of our approach, we empirically evaluated the performance of TwinGreedyFast on two network applications, and observed that it outperforms the state-of-the-art deterministic and randomized algorithms with efficient implementations for our problem.},
archivePrefix = {arXiv},
arxivId = {2010.11420},
author = {Han, Kai and Cao, Zongmai and Cui, Shuang and Wu, Benwei},
booktitle = {NeurIPS},
eprint = {2010.11420},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Han et al. - 2020 - Deterministic Approximation for Submodular Maximization over a Matroid in Nearly Linear Time.pdf:pdf},
pages = {1--12},
title = {{Deterministic Approximation for Submodular Maximization over a Matroid in Nearly Linear Time}},
url = {http://arxiv.org/abs/2010.11420},
year = {2020}
}
@inproceedings{Alaluf2020a,
abstract = {We study the problem of maximizing a non-monotone submodular function subject to a cardinality constraint in the streaming model. Our main contributions are two single-pass (semi-)streaming algorithms that use {\~{O}}(k) {\textperiodcentered} poly(1/$\epsilon$) memory, where k is the size constraint. At the end of the stream, both our algorithms post-process their data structures using any offline algorithm for submodular maximization, and obtain a solution whose approximation guarantee is 1+$\alpha$$\alpha$ − $\epsilon$, where $\alpha$ is the approximation of the offline algorithm. If we use an exact (exponential time) post-processing algorithm, this leads to 12 − $\epsilon$ approximation (which is nearly optimal). If we post-process with the algorithm of [5], that achieves the state-of-the-art offline approximation guarantee of $\alpha$ = 0.385, we obtain 0.2779-approximation in polynomial time, improving over the previously best polynomial-time approximation of 0.1715 due to [17]. One of our algorithms is combinatorial and enjoys fast update and overall running times. Our other algorithm is based on the multilinear extension, enjoys an improved space complexity, and can be made deterministic in some settings of interest.},
archivePrefix = {arXiv},
arxivId = {1909.13676},
author = {Alaluf, Naor and Ene, Alina and Feldman, Moran and Nguyen, Huy L. and Suh, Andrew},
booktitle = {47th International Colloquium on Automata, Languages, and Programming (ICALP)},
doi = {10.4230/LIPIcs.ICALP.2020.6},
eprint = {1909.13676},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alaluf et al. - 2020 - Optimal streaming algorithms for submodular maximization with cardinality constraints(2).pdf:pdf},
isbn = {9783959771382},
issn = {18688969},
keywords = {Cardinality constraint,Streaming algorithms,Submodular maximization},
title = {{Optimal streaming algorithms for submodular maximization with cardinality constraints}},
url = {http://arxiv.org/abs/1909.13676},
year = {2020}
}
@misc{Mun2019,
abstract = {Copyright {\textcopyright} 2019, arXiv, All rights reserved. The r-index is a tool for compressed indexing of genomic databases for exact pattern matching, which can be used to completely align reads that perfectly match some part of a genome in the database or to find seeds for reads that do not. This paper shows how to download and install the programs ri-buildfasta and ri-align; how to call ri-buildfasta on a FASTA file to build an r-index for that file; and how to query that index with ri-align.},
author = {Mun, T. and Kuhnle, A. and Boucher, C. and Gagie, T. and Langmead, B. and Manzini, G.},
booktitle = {arXiv},
title = {{Matching reads to many genomes with the r-index}},
year = {2019}
}
@misc{Pan2017b,
abstract = {Copyright {\textcopyright} 2017, arXiv, All rights reserved. Information can propagate among Online Social Network (OSN) users at a high speed, which makes the OSNs become important platforms for viral marketing. Although the viral marketing related problems in OSNs have been extensively studied in the past decade, the existing works all assume known propagation rates and are not able to solve the scenario when the rates may dynamically increase for popular topics. In this paper, we propose a novel model, Dynamic Influence Propagation (DIP), which allows propagation rates to change during the diffusion and can be used for describing information propagation in OSNs more realistically. Based on DIP, we define a new research problem: Threshold Activation Problem under DIP (TAP-DIP). TAP-DIP is more generalized than TAP and can be used for studying the DIP model. However, it adds another layer of complexity over the already #P-hard TAP problem. Despite it hardness, we are able to approximate TAP-DIP with O(log |V|) ratio. Our solution consists of two major parts: 1) the Lipschitz optimization technique and 2) a novel solution to the general version of TAP, the Multi-TAP problem. We experimentally test our solution Using various real OSN datasets, and demonstrate that our solution not only generates high-quality yet much smaller seed sets when being aware of the rate increase, but also is scalable. In addition, considering DIP or not has a significant difference in seed set selection.},
author = {Pan, T. and Kuhnle, A. and Li, X. and Thai, M.T.},
booktitle = {arXiv},
keywords = {Dynamic Influence Propagation,Online Social Network,Threshold Activation Problem},
title = {{Popular topics spread faster: New dimension for influence propagation in online social networks}},
year = {2017}
}
@misc{Kuhnle2019a,
abstract = {Copyright {\textcopyright} 2019, arXiv, All rights reserved. In this work, we consider the maximization of submodular functions constrained by independence systems. Because of the wide applicability of submodular functions, this problem has been extensively studied in the literature, on specialized independence systems. For general independence systems, even when all of the bases of the independence system have the same size, we show that for any ∊ > 0, the problem is hard to approximate within (2/n)1−∊, where n is the size of the ground set. In the same context, we show the greedy algorithm does obtain a ratio of 2/n under a mild additional assumption. Finally, we provide the first nearly linear-time algorithm for maximization of non-monotone submodular functions over p-extendible independence systems.},
author = {Kuhnle, A.},
booktitle = {arXiv},
title = {{A Note on Submodular Maximization over Independence Systems}},
year = {2019}
}
@article{Hafner2019,
abstract = {Learned world models summarize an agent's experience to facilitate learning complex behaviors. While learning world models from high-dimensional sensory inputs is becoming feasible through deep learning, there are many potential ways for deriving behaviors from them. We present Dreamer, a reinforcement learning agent that solves long-horizon tasks from images purely by latent imagination. We efficiently learn behaviors by propagating analytic gradients of learned state values back through trajectories imagined in the compact state space of a learned world model. On 20 challenging visual control tasks, Dreamer exceeds existing approaches in data-efficiency, computation time, and final performance.},
archivePrefix = {arXiv},
arxivId = {1912.01603},
author = {Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
eprint = {1912.01603},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hafner et al. - 2019 - Dream to Control Learning Behaviors by Latent Imagination.pdf:pdf},
month = {dec},
title = {{Dream to Control: Learning Behaviors by Latent Imagination}},
url = {http://arxiv.org/abs/1912.01603},
year = {2019}
}
@techreport{Zeroski2001a,
abstract = {Relational reinforcement learning is presented, a learning technique that combines reinforcement learning with relational learning or inductive logic programming. Due to the use of a more expressive representation language to represent states, actions and Q-functions, relational reinforcement learning can be potentially applied to a new range of learning tasks. One such task that we investigate is planning in the blocks world, where it is assumed that the effects of the actions are unknown to the agent and the agent has to learn a policy. Within this simple domain we show that relational reinforcement learning solves some existing problems with reinforcement learning. In particular, relational reinforcement learning allows us to employ structural representations, to abstract from specific goals pursued and to exploit the results of previous learning phases when addressing new (more complex) situations.},
author = {{ˇ Zeroski}, Sa{\v{s}}osaˇsa{\v{s}}o D},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/ˇ Zeroski - 2001 - Relational Reinforcement Learning.pdf:pdf},
keywords = {inductive logic programming,planning,reinforcement learning},
pages = {7--52},
title = {{Relational Reinforcement Learning}},
volume = {43},
year = {2001}
}
@techreport{Zeroski2001,
abstract = {Relational reinforcement learning is presented, a learning technique that combines reinforcement learning with relational learning or inductive logic programming. Due to the use of a more expressive representation language to represent states, actions and Q-functions, relational reinforcement learning can be potentially applied to a new range of learning tasks. One such task that we investigate is planning in the blocks world, where it is assumed that the effects of the actions are unknown to the agent and the agent has to learn a policy. Within this simple domain we show that relational reinforcement learning solves some existing problems with reinforcement learning. In particular, relational reinforcement learning allows us to employ structural representations, to abstract from specific goals pursued and to exploit the results of previous learning phases when addressing new (more complex) situations.},
author = {{ˇ Zeroski}, Sa{\v{s}}osaˇsa{\v{s}}o D},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/ˇ Zeroski - 2001 - Relational Reinforcement Learning.pdf:pdf},
keywords = {inductive logic programming,planning,reinforcement learning},
pages = {7--52},
title = {{Relational Reinforcement Learning}},
volume = {43},
year = {2001}
}
@article{Mitrovic2017a,
abstract = {How can we extract representative features from a dataset containing sensitive personal information, while providing individual-level privacy guarantees? Many data summarization applications are captured by the general framework of submodular maximization. As a consequence, a wide range of efficient approximation algorithms for submodular maximization have been developed. However, when such applications involve sensitive data about individuals, their privacy concerns are not automatically addressed by these algorithms. To remedy this problem, we propose a general and systematic study of differentially private submodular maximization. We present privacy-preserving algorithms for both monotone and non-monotone submodular maximization under cardinality, matroid, and p-extendible system constraints, with guarantees that are competitive with optimal solutions. Along the way, we analyze a new algorithm for non-monotone submodular maximization under a cardinality constraint, which is the first (even non-privately) to achieve a constant approximation ratio with a linear number of function evaluations. We additionally provide two concrete experiments to validate the efficacy of these algorithms. In the first experiment, we privately solve the facility location problem using a dataset of Uber pickup locations in Manhattan. In the second experiment, we perform private submodular maximization of a mutual information measure to select features relevant to classifying patients by diabetes status.},
author = {Mitrovic, Marko and Bun, Mark and Krause, Andreas and Karbasi, Amin},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitrovic et al. - 2017 - Differentially private submodular maximization Data summarization in disguise (full version).pdf:pdf},
isbn = {9781510855144},
journal = {34th International Conference on Machine Learning, ICML 2017},
pages = {3818--3841},
title = {{Differentially private submodular maximization: Data summarization in disguise (full version)}},
volume = {5},
year = {2017}
}
@techreport{Hall,
abstract = {Analogical reasoning has a long history in artificial intelligence research, primarily because of its promise for Ike acquisition unit effective use of knowledge. Defined as a representational mapping from a known "source" domain into a novel "target" domain, analogy provides a basic mechanism for effectively connecting a reasoner's past and present experience. Using a four-component process model of analogical reasoning, this paper reviews sixteen computational studies of analogy. These studies are organized chronologically within broadly defined task domains of automated deduction, problem solving and planning, natural language comprehension, and machine learning. Drawing on these detailed reviews, a comparative analysis of diverse contributions to basic analogy processes identifies recurrent problems for studies of analogy and common approaches to their solution. The paper concludes by arguing that computational studies of analogy are in a slate of adolescence: looking to more mature research areas in artificial intelligence for robust accounts of basic reasoning processes and drawing upon a long tradition of research in other disciplines.},
author = {Hall, Rogers P},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hall - Unknown - Computational Approaches to Analogical Reasoning A Comparative Analysis.pdf:pdf},
title = {{Computational Approaches to Analogical Reasoning: A Comparative Analysis}}
}
@article{Marra2020,
abstract = {Deep learning has been shown to achieve impressive results in several tasks where a large amount of training data is available. However, deep learning solely focuses on the accuracy of the predictions, neglecting the reasoning process leading to a decision, which is a major issue in life-critical applications. Probabilistic logic reasoning allows to exploit both statistical regularities and specific domain expertise to perform reasoning under uncertainty, but its scalability and brittle integration with the layers processing the sensory data have greatly limited its applications. For these reasons, combining deep architectures and probabilistic logic reasoning is a fundamental goal towards the development of intelligent agents operating in complex environments. This paper presents Relational Neural Machines, a novel framework allowing to jointly train the parameters of the learners and of a First--Order Logic based reasoner. A Relational Neural Machine is able to recover both classical learning from supervised data in case of pure sub-symbolic learning, and Markov Logic Networks in case of pure symbolic reasoning, while allowing to jointly train and perform inference in hybrid learning tasks. Proper algorithmic solutions are devised to make learning and inference tractable in large-scale problems. The experiments show promising results in different relational tasks.},
archivePrefix = {arXiv},
arxivId = {2002.02193},
author = {Marra, Giuseppe and Diligenti, Michelangelo and Giannini, Francesco and Gori, Marco and Maggini, Marco},
eprint = {2002.02193},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marra et al. - 2020 - Relational Neural Machines.pdf:pdf},
month = {feb},
title = {{Relational Neural Machines}},
url = {http://arxiv.org/abs/2002.02193},
year = {2020}
}
@inproceedings{Nyga2017,
abstract = {As autonomous, mobile robots are increasingly entering our everyday lives and the tasks they are to perform are getting continuously more complex and versatile, instructing robots by means of natural-language commands becomes more and more important. Such instructions, stated by humans and originally intended for human use, are typically formulated very vaguely and lack critical information about how to perform particular actions. Probabilistic relational models have shown promise in filling in missing information pieces that have been omitted in such instructions. However, the enormous size of these models and the computational expense in learning and reasoning often impedes their practical applicability to real-world domains. In this work, we propose a novel instance-based learning approach towards building up knowledge bases for instruction completion, which combines probabilistic methods with semantic analogical reasoning. Probabilistic reasoning is employed to build up a knowledge base of natural-language instruction sheets, while instruction completion can be achieved through fast database queries. We showcase the scalabilty of our approach by building up a KB of more than 100,000 instruction steps that have been mined from the wikihow.com web site and which are publicly accessible from within the Prac [21] natural-language interpreter.},
author = {Nyga, Daniel and Picklum, Mareike and Koralewski, Sebastian and Beetz, Michael},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2017.7989491},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nyga et al. - 2017 - Instruction completion through instance-based learning and semantic analogical reasoning.pdf:pdf},
isbn = {9781509046331},
issn = {10504729},
month = {jul},
pages = {4270--4277},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Instruction completion through instance-based learning and semantic analogical reasoning}},
year = {2017}
}
@techreport{Davis,
abstract = {Standard inductive learning requires that training and test instances come from the same distribution. Transfer learning seeks to remove this restriction. In shallow transfer , test instances are from the same domain , but have a different distribution. In deep transfer, test instances are from a different domain entirely (i.e., described by different predicates). Humans routinely perform deep transfer, but few learning systems , if any, are capable of it. In this paper we propose an approach based on a form of second-order Markov logic. Our algorithm discovers structural regularities in the source domain in the form of Markov logic formulas with predicate variables, and instantiates these formulas with predicates from the target domain. Using this approach, we have successfully transferred learned knowledge among molecular biology, social network and Web domains. The discovered patterns include broadly useful properties of predicates , like symmetry and transitivity, and relations among predicates, such as various forms of homophily.},
author = {Davis, Jesse and Domingos, Pedro},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Davis, Domingos - Unknown - Deep Transfer via Second-Order Markov Logic.pdf:pdf},
title = {{Deep Transfer via Second-Order Markov Logic}}
}
@article{Vinyals2019,
abstract = {Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions1–3, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems4. Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players. We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent reinforcement learning algorithm that uses data from both human and agent games within a diverse league of continually adapting strategies and counter-strategies, each represented by deep neural networks5,6. We evaluated our agent, AlphaStar, in the full game of StarCraft II, through a series of online games against human players. AlphaStar was rated at Grandmaster level for all three StarCraft races and above 99.8% of officially ranked human players.},
author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and Mathieu, Micha{\"{e}}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H. and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John P. and Jaderberg, Max and Vezhnevets, Alexander S. and Leblond, R{\'{e}}mi and Pohlen, Tobias and Dalibard, Valentin and Budden, David and Sulsky, Yury and Molloy, James and Paine, Tom L. and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Wu, Yuhuai and Ring, Roman and Yogatama, Dani and W{\"{u}}nsch, Dario and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Kavukcuoglu, Koray and Hassabis, Demis and Apps, Chris and Silver, David},
doi = {10.1038/s41586-019-1724-z},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vinyals et al. - 2019 - Grandmaster level in StarCraft II using multi-agent reinforcement learning.pdf:pdf;:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vinyals et al. - 2019 - Grandmaster level in StarCraft II using multi-agent reinforcement learning.zip:zip},
issn = {14764687},
journal = {Nature},
month = {nov},
number = {7782},
pages = {350--354},
pmid = {31666705},
publisher = {Nature Publishing Group},
title = {{Grandmaster level in StarCraft II using multi-agent reinforcement learning}},
volume = {575},
year = {2019}
}
@article{Zambaldi2018,
abstract = {We introduce an approach for deep reinforcement learning (RL) that improves upon the efficiency, generalization capacity, and interpretability of conventional approaches through structured perception and relational reasoning. It uses self-attention to iteratively reason about the relations between entities in a scene and to guide a model-free policy. Our results show that in a novel navigation and planning task called Box-World, our agent finds interpretable solutions that improve upon baselines in terms of sample complexity, ability to generalize to more complex scenes than experienced during training, and overall performance. In the StarCraft II Learning Environment, our agent achieves state-of-the-art performance on six mini-games -- surpassing human grandmaster performance on four. By considering architectural inductive biases, our work opens new directions for overcoming important, but stubborn, challenges in deep RL.},
archivePrefix = {arXiv},
arxivId = {1806.01830},
author = {Zambaldi, Vinicius and Raposo, David and Santoro, Adam and Bapst, Victor and Li, Yujia and Babuschkin, Igor and Tuyls, Karl and Reichert, David and Lillicrap, Timothy and Lockhart, Edward and Shanahan, Murray and Langston, Victoria and Pascanu, Razvan and Botvinick, Matthew and Vinyals, Oriol and Battaglia, Peter},
eprint = {1806.01830},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zambaldi et al. - 2018 - Relational Deep Reinforcement Learning.pdf:pdf},
month = {jun},
title = {{Relational Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1806.01830},
year = {2018}
}
@article{Dong2019,
abstract = {We propose the Neural Logic Machine (NLM), a neural-symbolic architecture for both inductive learning and logic reasoning. NLMs exploit the power of both neural networks---as function approximators, and logic programming---as a symbolic processor for objects with properties, relations, logic connectives, and quantifiers. After being trained on small-scale tasks (such as sorting short arrays), NLMs can recover lifted rules, and generalize to large-scale tasks (such as sorting longer arrays). In our experiments, NLMs achieve perfect generalization in a number of tasks, from relational reasoning tasks on the family tree and general graphs, to decision making tasks including sorting arrays, finding shortest paths, and playing the blocks world. Most of these tasks are hard to accomplish for neural networks or inductive logic programming alone.},
archivePrefix = {arXiv},
arxivId = {1904.11694},
author = {Dong, Honghua and Mao, Jiayuan and Lin, Tian and Wang, Chong and Li, Lihong and Zhou, Denny},
eprint = {1904.11694},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dong et al. - 2019 - Neural Logic Machines.pdf:pdf},
month = {apr},
title = {{Neural Logic Machines}},
url = {http://arxiv.org/abs/1904.11694},
year = {2019}
}
@article{Jiang2019,
abstract = {Deep reinforcement learning (DRL) has achieved significant breakthroughs in various tasks. However, most DRL algorithms suffer a problem of generalizing the learned policy which makes the learning performance largely affected even by minor modifications of the training environment. Except that, the use of deep neural networks makes the learned policies hard to be interpretable. To address these two challenges, we propose a novel algorithm named Neural Logic Reinforcement Learning (NLRL) to represent the policies in reinforcement learning by first-order logic. NLRL is based on policy gradient methods and differentiable inductive logic programming that have demonstrated significant advantages in terms of interpretability and generalisability in supervised tasks. Extensive experiments conducted on cliff-walking and blocks manipulation tasks demonstrate that NLRL can induce interpretable policies achieving near-optimal performance while demonstrating good generalisability to environments of different initial states and problem sizes.},
archivePrefix = {arXiv},
arxivId = {1904.10729},
author = {Jiang, Zhengyao and Luo, Shan},
eprint = {1904.10729},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang, Luo - 2019 - Neural Logic Reinforcement Learning.pdf:pdf},
month = {apr},
title = {{Neural Logic Reinforcement Learning}},
url = {http://arxiv.org/abs/1904.10729},
year = {2019}
}
@article{Bouraoui2019,
abstract = {This paper proposes a tentative and original survey of meeting points between Knowledge Representation and Reasoning (KRR) and Machine Learning (ML), two areas which have been developing quite separately in the last three decades. Some common concerns are identified and discussed such as the types of used representation, the roles of knowledge and data, the lack or the excess of information, or the need for explanations and causal understanding. Then some methodologies combining reasoning and learning are reviewed (such as inductive logic programming, neuro-symbolic reasoning, formal concept analysis, rule-based representations and ML, uncertainty in ML, or case-based reasoning and analogical reasoning), before discussing examples of synergies between KRR and ML (including topics such as belief functions on regression, EM algorithm versus revision, the semantic description of vector representations, the combination of deep learning with high level inference, knowledge graph completion, declarative frameworks for data mining, or preferences and recommendation). This paper is the first step of a work in progress aiming at a better mutual understanding of research in KRR and ML, and how they could cooperate.},
archivePrefix = {arXiv},
arxivId = {1912.06612},
author = {Bouraoui, Zied and Cornu{\'{e}}jols, Antoine and Den{\oe}ux, Thierry and Destercke, S{\'{e}}bastien and Dubois, Didier and Guillaume, Romain and Marques-Silva, Jo{\~{a}}o and Mengin, J{\'{e}}r{\^{o}}me and Prade, Henri and Schockaert, Steven and Serrurier, Mathieu and Vrain, Christel},
eprint = {1912.06612},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bouraoui et al. - 2019 - From Shallow to Deep Interactions Between Knowledge Representation, Reasoning and Machine Learning (Kay R. Amel.pdf:pdf},
month = {dec},
title = {{From Shallow to Deep Interactions Between Knowledge Representation, Reasoning and Machine Learning (Kay R. Amel group)}},
url = {http://arxiv.org/abs/1912.06612},
year = {2019}
}
@article{Garcez2019,
abstract = {Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.},
archivePrefix = {arXiv},
arxivId = {1905.06088},
author = {d'Avila Garcez, Artur and Gori, Marco and Lamb, Luis C. and Serafini, Luciano and Spranger, Michael and Tran, Son N.},
eprint = {1905.06088},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garcez et al. - 2019 - Neural-Symbolic Computing An Effective Methodology for Principled Integration of Machine Learning and Reasoning.pdf:pdf},
month = {may},
title = {{Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning}},
url = {http://arxiv.org/abs/1905.06088},
year = {2019}
}
@inproceedings{Kuhnle2020b,
author = {Kuhnle, Alan},
booktitle = {AAAI Conference on Artificial Intelligence},
title = {{Nearly Linear-Time, Parallelizable Algorithms for Non-Monotone Submodular Maximization}},
url = {https://arxiv.org/abs/2009.01947},
year = {2021}
}
@inproceedings{Kuhnle2020a,
author = {Kuhnle, Alan},
booktitle = {Artificial Intelligence and Statistics (AISTATS)},
title = {{Quick Streaming Algorithms for Maximization of Monotone Submodular Functions in Linear Time}},
url = {https://arxiv.org/abs/2009.04979},
year = {2021}
}
@inproceedings{Halabi2020,
author = {Halabi, Marwa El and Mitrovic, Slobodan and Norouzi-Fard, Ashkan and Tardos, Jakab and Tarnawski, Jakub},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
title = {{Fairness in Streaming Submodular Maximization: Algorithms and Hardness}},
year = {2020}
}
@unpublished{,
title = {{Quick Streaming Algorithms}}
}
@unpublished{Feldman2020a,
abstract = {In this paper, we present SimultaneousGreedys, a deterministic algorithm for constrained submodular maximization. At a high level, the algorithm maintains $\ell$ solutions and greedily updates them in a simultaneous fashion, rather than a sequential one. SimultaneousGreedys achieves the tightest known approximation guarantees for both $k$-extendible systems and the more general $k$-systems, which are $(k+1)^2/k = k + \mathcal{O}(1)$ and $(1 + \sqrt{k+2})^2 = k + \mathcal{O}(\sqrt{k})$, respectively. This is in contrast to previous algorithms, which are designed to provide tight approximation guarantees in one setting, but not both. Furthermore, these approximation guarantees further improve to $k+1$ when the objective is monotone. We demonstrate that the algorithm may be modified to run in nearly linear time with an arbitrarily small loss in the approximation. This leads to the first nearly linear time algorithm for submodular maximization over $k$-extendible systems and $k$-systems. Finally, the technique is flexible enough to incorporate the intersection of $m$ additional knapsack constraints, while retaining similar approximation guarantees, which are roughly $k + 2m + \mathcal{O}(\sqrt{k+m})$ for $k$-systems and $k+2m + \mathcal{O}(\sqrt{m})$ for $k$-extendible systems. To complement our algorithmic contributions, we provide a hardness result which states that no algorithm making polynomially many queries to the value and independence oracles can achieve an approximation better than $k + 1/2 + \varepsilon$.},
archivePrefix = {arXiv},
arxivId = {2009.13998},
author = {Feldman, Moran and Harshaw, Christopher and Karbasi, Amin},
eprint = {2009.13998},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feldman, Harshaw, Karbasi - 2020 - Simultaneous Greedys A Swiss Army Knife for Constrained Submodular Maximization.pdf:pdf},
title = {{Simultaneous Greedys: A Swiss Army Knife for Constrained Submodular Maximization}},
url = {http://arxiv.org/abs/2009.13998},
year = {2020}
}
@article{Gong2014,
abstract = {Video summarization is a challenging problem with great application potential. Whereas prior approaches, largely unsupervised in nature, focus on sampling useful frames and assembling them as summaries, we consider video summarization as a supervised subset selection problem. Our idea is to teach the system to learn from human-created summaries how to select informative and diverse subsets, so as to best meet evaluation metrics derived from human-perceived quality. To this end, we propose the sequential determinantal point process (seqDPP), a probabilistic model for diverse sequential subset selection. Our novel seqDPP heeds the inherent sequential structures in video data, thus overcoming the deficiency of the standard DPP, which treats video frames as randomly permutable items. Meanwhile, seqDPP retains the power of modeling diverse subsets, essential for summarization. Our extensive results of summarizing videos from 3 datasets demonstrate the superior performance of our method, compared to not only existing unsuper-vised methods but also naive applications of the standard DPP model.},
author = {Gong, Boqing and Chao, Wei Lun and Grauman, Kristen and Sha, Fei},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {January},
pages = {2069--2077},
title = {{Diverse sequential subset selection for supervised video summarization}},
volume = {3},
year = {2014}
}
@article{Macchi1975,
author = {Macchi, Odile},
journal = {Advanced in Applied Probability},
number = {1},
pages = {83--122},
title = {{The Coincidence Approach to Stochastic Point Processes}},
volume = {7},
year = {1975}
}
@article{DeAvila2011,
abstract = {The fast evolution of digital video has brought many new multimedia applications and, as a consequence, has increased the amount of research into new technologies that aim at improving the effectiveness and efficiency of video acquisition, archiving, cataloging and indexing, as well as increasing the usability of stored videos. Among possible research areas, video summarization is an important topic that potentially enables faster browsing of large video collections and also more efficient content indexing and access. Essentially, this research area consists of automatically generating a short summary of a video, which can either be a static summary or a dynamic summary. In this paper, we present VSUMM, a methodology for the production of static video summaries. The method is based on color feature extraction from video frames and k-means clustering algorithm. As an additional contribution, we also develop a novel approach for the evaluation of video static summaries. In this evaluation methodology, video summaries are manually created by users. Then, several user-created summaries are compared both to our approach and also to a number of different techniques in the literature. Experimental results show - with a confidence level of 98% - that the proposed solution provided static video summaries with superior quality relative to the approaches to which it was compared. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {{De Avila}, Sandra Eliza Fontes and Lopes, Ana Paula Brand{\~{a}}o and {Da Luz}, Antonio and {De Albuquerque Ara{\'{u}}jo}, Arnaldo},
journal = {Pattern Recognition Letters},
keywords = {Clustering,Evaluation method,Static video summary,Video summarization},
number = {1},
pages = {56--68},
publisher = {Elsevier B.V.},
title = {{VSUMM: A mechanism designed to produce static video summaries and a novel evaluation method}},
url = {http://dx.doi.org/10.1016/j.patrec.2010.08.004},
volume = {32},
year = {2011}
}
@article{Kulesza2012,
author = {Kulesza, Alex and Taskar, Ben},
journal = {Foundations and Trends in Machine Learning},
number = {2},
title = {{Determinantal Point Processes for Machine Learning}},
volume = {5},
year = {2012}
}
@inproceedings{Ene2020,
author = {Ene, Alina and Nguy{\^{e}}n, Huy L.},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Parallel Algorithm for Non-Monotone DR-Submodular Maximization}},
year = {2020}
}
@article{Bellemare2012,
abstract = {In this article we introduce the Arcade Learning Environment (ALE): both a challenge problem and a platform and methodology for evaluating the development of general, domain-independent AI technology. ALE provides an interface to hundreds of Atari 2600 game environments, each one different, interesting, and designed to be a challenge for human players. ALE presents significant research challenges for reinforcement learning, model learning, model-based planning, imitation learning, transfer learning, and intrinsic motivation. Most importantly, it provides a rigorous testbed for evaluating and comparing approaches to these problems. We illustrate the promise of ALE by developing and benchmarking domain-independent agents designed using well-established AI techniques for both reinforcement learning and planning. In doing so, we also propose an evaluation methodology made possible by ALE, reporting empirical results on over 55 different games. All of the software, including the benchmark agents, is publicly available.},
archivePrefix = {arXiv},
arxivId = {1207.4708},
author = {Bellemare, Marc G. and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
doi = {10.1613/jair.3912},
eprint = {1207.4708},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bellemare et al. - 2012 - The Arcade Learning Environment An Evaluation Platform for General Agents.pdf:pdf},
month = {jul},
title = {{The Arcade Learning Environment: An Evaluation Platform for General Agents}},
url = {http://arxiv.org/abs/1207.4708 http://dx.doi.org/10.1613/jair.3912},
year = {2012}
}
@techreport{Watkins1992,
abstract = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states. This paper presents and proves in detail a convergence theorem for Q,-learning based on that outlined in Watkins (1989). We show that Q-learning converges to the optimum action-values with probability 1 so long as all actions are repeatedly sampled in all states and the action-values are represented discretely. We also sketch extensions to the cases of non-discounted, but absorbing, Markov environments, and where many Q values can be changed each iteration, rather than just one.},
author = {Watkins, Christopher J C H and Dayan, Peter},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Watkins, Dayan - 1992 - Technical Note Q,-Learning.pdf:pdf},
keywords = {Q-learning,asynchronous dynamic programming,reinforcement learning,temporal differences},
pages = {279--292},
title = {{Technical Note Q,-Learning}},
volume = {8},
year = {1992}
}
@techreport{Segal,
abstract = {Given a connected, weighted, undirected graph G=(V,E), the minimum spanning tree problem seeks a minimum weight sub-graph T in G, which spans all vertices of G. The simple variant of the problem is known to be solvable in polynomial time, but adding some constraints, such as a maximum node degree or bounded diameter, makes it harder to solve. In the bounded diameter minimum spanning tree problem, we are given the same connected, weighted, undirected graph G=(V,E) and a constant D, and we seek to find a minimum-weight sub-graph T in G, which spans all vertices of G without cycles, where no path between any two vertices contains more than D edges (hops). In this paper, we address the bounded diameter minimum spanning tree problem for the general graph having non-negative edges weights. We present a new algorithm for solving the problem, with the proven performance ratio. We show a centralized implementation of the algorithm with O(nlogD) running time. Finally, we provide simulation results and show the empirical bound of O(log |E|) for the general case. Abstract Given a connected, weighted, undirected graph G = (V, E), the minimum spanning tree problem seeks a minimum weight sub-graph T ⊆ G, which spans all vertices of G. The simple variant of the problem is known to be solvable in polynomial time, but adding some constraints, such as a maximum node degree or bounded diameter, makes it harder to solve. In the bounded diameter minimum spanning tree problem, we are given the same connected, weighted, undirected graph G = (V, E) and a constant D, and we seek to nd a minimum-weight sub-graph T ⊆ G, which spans all vertices of G without cycles, where no path between any two vertices contains more than D edges (hops). In this paper, we address the bounded diameter minimum spanning tree problem for the general graph having non-negative edges weights. We present a new algorithm for solving the problem, with the proven performance ratio. We show a centralized implementation of the algorithm with O (n log D) running time. Finally, we provide simulation results and show the empirical bound of O(log |E|) for the general case.},
author = {Segal, Michael and Tzfaty, Oren},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Segal, Tzfaty - Unknown - Optimization Letters Finding Bounded Diameter Minimum Spanning Tree in General Graphs Finding Bounded Diameter.pdf:pdf},
keywords = {Bounded Diameter Minimum Spanning Tree Keywords Gr,Graph theory,Minimum spanning tree},
title = {{Optimization Letters Finding Bounded Diameter Minimum Spanning Tree in General Graphs Finding Bounded Diameter Minimum Spanning Tree in General Graphs}}
}
@article{Mnih2015a,
abstract = {The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
doi = {10.1038/nature14236},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mnih et al. - 2015 - Human-level control through deep reinforcement learning(3).pdf:pdf},
issn = {14764687},
journal = {Nature},
number = {7540},
pages = {529--533},
pmid = {25719670},
title = {{Human-level control through deep reinforcement learning}},
volume = {518},
year = {2015}
}
@article{Mnih2013,
abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
archivePrefix = {arXiv},
arxivId = {1312.5602},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
eprint = {1312.5602},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf:pdf},
month = {dec},
title = {{Playing Atari with Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1312.5602},
year = {2013}
}
@article{Schrittwieser2019,
abstract = {Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess and Go, where a perfect simulator is available. However, in real-world problems the dynamics governing the environment are often complex and unknown. In this work we present the MuZero algorithm which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. MuZero learns a model that, when applied iteratively, predicts the quantities most directly relevant to planning: the reward, the action-selection policy, and the value function. When evaluated on 57 different Atari games - the canonical video game environment for testing AI techniques, in which model-based planning approaches have historically struggled - our new algorithm achieved a new state of the art. When evaluated on Go, chess and shogi, without any knowledge of the game rules, MuZero matched the superhuman performance of the AlphaZero algorithm that was supplied with the game rules.},
archivePrefix = {arXiv},
arxivId = {1911.08265},
author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
eprint = {1911.08265},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schrittwieser et al. - 2019 - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model.pdf:pdf},
month = {nov},
title = {{Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model}},
url = {http://arxiv.org/abs/1911.08265},
year = {2019}
}
@article{Schrittwieser2019a,
abstract = {Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess and Go, where a perfect simulator is available. However, in real-world problems the dynamics governing the environment are often complex and unknown. In this work we present the MuZero algorithm which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. MuZero learns a model that, when applied iteratively, predicts the quantities most directly relevant to planning: the reward, the action-selection policy, and the value function. When evaluated on 57 different Atari games - the canonical video game environment for testing AI techniques, in which model-based planning approaches have historically struggled - our new algorithm achieved a new state of the art. When evaluated on Go, chess and shogi, without any knowledge of the game rules, MuZero matched the superhuman performance of the AlphaZero algorithm that was supplied with the game rules.},
archivePrefix = {arXiv},
arxivId = {1911.08265},
author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
eprint = {1911.08265},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schrittwieser et al. - 2019 - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model.pdf:pdf},
month = {nov},
title = {{Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model}},
url = {http://arxiv.org/abs/1911.08265},
year = {2019}
}
@article{Filmus2012,
abstract = {We present an optimal, combinatorial 1-1/e approximation algorithm for monotone sub modular optimization over a matroid constraint. Compared to the continuous greedy algorithm (Calinescu, Chekuri, Pal and Vondrak, 2008), our algorithm is extremely simple and requires no rounding. It consists of the greedy algorithm followed by local search. Both phases are run not on the actual objective function, but on a related non-oblivious potential function, which is also monotone sub modular. In our previous work on maximum coverage (Filmus and Ward, 2011), the potential function gives more weight to elements covered multiple times. We generalize this approach from coverage functions to arbitrary monotone sub modular functions. When the objective function is a coverage function, both definitions of the potential function coincide. The parameters used to define the potential function are closely related to Pade approximants of exp(x) evaluated at x = 1. We use this connection to determine the approximation ratio of the algorithm. {\textcopyright} 2012 IEEE.},
author = {Filmus, Yuval and Ward, Justin},
doi = {10.1109/FOCS.2012.55},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Filmus, Ward - 2012 - A tight combinatorial algorithm for submodular maximization subject to a matroid constraint.pdf:pdf},
issn = {02725428},
journal = {Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS},
keywords = {approximation algorithms,local search,matroids,submodular functions},
pages = {659--668},
publisher = {IEEE},
title = {{A tight combinatorial algorithm for submodular maximization subject to a matroid constraint}},
year = {2012}
}
@article{Chakrabarti2013,
abstract = {We study the problem of finding a maximum matching in a graph given by an input stream listing its edges in some arbitrary order, where the quantity to be maximized is given by a monotone submodular function on subsets of edges. This problem, which we call maximum submodular-function matching (MSM), is a natural generalization of maximum weight matching (MWM), which is in turn a generalization of maximum cardinality matching (MCM). We give two incomparable algorithms for this problem with space usage falling in the semi-streaming range---they store only $O(n)$ edges, using $O(n\log n)$ working memory---that achieve approximation ratios of $7.75$ in a single pass and $(3+\epsilon)$ in $O(\epsilon^{-3})$ passes respectively. The operations of these algorithms mimic those of Zelke's and McGregor's respective algorithms for MWM; the novelty lies in the analysis for the MSM setting. In fact we identify a general framework for MWM algorithms that allows this kind of adaptation to the broader setting of MSM. In the sequel, we give generalizations of these results where the maximization is over "independent sets" in a very general sense. This generalization captures hypermatchings in hypergraphs as well as independence in the intersection of multiple matroids.},
archivePrefix = {arXiv},
arxivId = {1309.2038},
author = {Chakrabarti, Amit and Kale, Sagar},
eprint = {1309.2038},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chakrabarti, Kale - 2013 - Submodular Maximization Meets Streaming Matchings, Matroids, and More.pdf:pdf},
month = {sep},
title = {{Submodular Maximization Meets Streaming: Matchings, Matroids, and More}},
url = {http://arxiv.org/abs/1309.2038},
year = {2013}
}
@article{Senior2020,
abstract = {Protein structure prediction can be used to determine the three-dimensional shape of a protein from its amino acid sequence1. This problem is of fundamental importance as the structure of a protein largely determines its function2; however, protein structures can be difficult to determine experimentally. Considerable progress has recently been made by leveraging genetic information. It is possible to infer which amino acid residues are in contact by analysing covariation in homologous sequences, which aids in the prediction of protein structures3. Here we show that we can train a neural network to make accurate predictions of the distances between pairs of residues, which convey more information about the structure than contact predictions. Using this information, we construct a potential of mean force4 that can accurately describe the shape of a protein. We find that the resulting potential can be optimized by a simple gradient descent algorithm to generate structures without complex sampling procedures. The resulting system, named AlphaFold, achieves high accuracy, even for sequences with fewer homologous sequences. In the recent Critical Assessment of Protein Structure Prediction5 (CASP13)—a blind assessment of the state of the field—AlphaFold created high-accuracy structures (with template modelling (TM) scores6 of 0.7 or higher) for 24 out of 43 free modelling domains, whereas the next best method, which used sampling and contact information, achieved such accuracy for only 14 out of 43 domains. AlphaFold represents a considerable advance in protein-structure prediction. We expect this increased accuracy to enable insights into the function and malfunction of proteins, especially in cases for which no structures for homologous proteins have been experimentally determined7.},
author = {Senior, Andrew W. and Evans, Richard and Jumper, John and Kirkpatrick, James and Sifre, Laurent and Green, Tim and Qin, Chongli and {\v{Z}}{\'{i}}dek, Augustin and Nelson, Alexander W.R. and Bridgland, Alex and Penedones, Hugo and Petersen, Stig and Simonyan, Karen and Crossan, Steve and Kohli, Pushmeet and Jones, David T. and Silver, David and Kavukcuoglu, Koray and Hassabis, Demis},
doi = {10.1038/s41586-019-1923-7},
issn = {14764687},
journal = {Nature},
number = {7792},
pages = {706--710},
pmid = {31942072},
publisher = {Springer US},
title = {{Improved protein structure prediction using potentials from deep learning}},
url = {http://dx.doi.org/10.1038/s41586-019-1923-7},
volume = {577},
year = {2020}
}
@techreport{HubertChan,
abstract = {We study the online submodular maximization problem with free disposal under a matroid constraint. Elements from some ground set arrive one by one in rounds, and the algorithm maintains a feasible set that is independent in the underlying matroid. In each round when a new element arrives, the algorithm may accept the new element into its feasible set and possibly remove elements from it, provided that the resulting set is still independent. The goal is to maximize the value of the final feasible set under some monotone submodular function, to which the algorithm has oracle access. For k-uniform matroids, we give a deterministic algorithm with competitive ratio at least 0.2959, and the ratio approaches 1 $\alpha$∞ ≈ 0.3178 as k approaches infinity, improving the previous best ratio of 0.25 by Chakrabarti and Kale (IPCO 2014), Buchbinder et al. (SODA 2015) and Chekuri et al. (ICALP 2015). We also show that our algorithm is optimal among a class of deterministic monotone algorithms that accept a new arriving element only if the objective is strictly increased. Further, we prove that no deterministic monotone algorithm can be strictly better than 0.25-competitive even for partition matroids, the most modest generalization of k-uniform matroids, matching the competitive ratio by Chakrabarti and Kale (IPCO 2014) and Chekuri et al. (ICALP 2015). Interestingly, we show that randomized algorithms are strictly more powerful by giving a (non-monotone) randomized algorithm for partition matroids with ratio 1 $\alpha$∞ ≈ 0.3178. Finally, our techniques can be extended to a more general problem that generalizes both the online sub-modular maximization problem and the online bipar-tite matching problem with free disposal. competitive algorithms for the submodular online bi-partite matching problem.},
author = {{Hubert Chan}, T-h and Huang, Zhiyi and {H-C Jiang}, Shaofeng and Kang, Ning and {Gavin Tang}, Zhihao},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hubert Chan et al. - Unknown - Online Submodular Maximization with Free Disposal Randomization Beats 1 4 for Partition Matroids.pdf:pdf},
title = {{Online Submodular Maximization with Free Disposal: Randomization Beats 1 4 for Partition Matroids *}},
url = {http://www.siam.org/journals/ojsa.php}
}
@article{Haba2020,
abstract = {In this paper, we propose a novel framework that converts streaming algorithms for monotone submodular maximization into streaming algorithms for non-monotone submodular maximization. This reduction readily leads to the currently tightest deterministic approximation ratio for submodular maximization subject to a $k$-matchoid constraint. Moreover, we propose the first streaming algorithm for monotone submodular maximization subject to $k$-extendible and $k$-set system constraints. Together with our proposed reduction, we obtain $O(k\log k)$ and $O(k^2\log k)$ approximation ratio for submodular maximization subject to the above constraints, respectively. We extensively evaluate the empirical performance of our algorithm against the existing work in a series of experiments including finding the maximum independent set in randomly generated graphs, maximizing linear functions over social networks, movie recommendation, Yelp location summarization, and Twitter data summarization.},
archivePrefix = {arXiv},
arxivId = {2002.03352},
author = {Haba, Ran and Kazemi, Ehsan and Feldman, Moran and Karbasi, Amin},
eprint = {2002.03352},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haba et al. - 2020 - Streaming Submodular Maximization under a $k$-Set System Constraint.pdf:pdf},
pages = {1--28},
title = {{Streaming Submodular Maximization under a $k$-Set System Constraint}},
url = {http://arxiv.org/abs/2002.03352},
year = {2020}
}
@article{Alaluf2019,
abstract = {In this paper we consider the problem of maximizing a non-negative submodular function subject to a cardinality constraint in the data stream model. Previously, the best known algorithm for this problem was a $5.828$-approximation semi-streaming algorithm based on a local search technique (Feldman et al., 2018). For the special case of this problem in which the objective function is also monotone, the state-of-the-art semi-streaming algorithm is an algorithm known as Sieve-Streaming, which is based on a different technique (Badanidiyuru, 2014). Adapting the technique of Sieve-Streaming to non-monotone objective functions has turned out to be a challenging task, which has so far prevented an improvement over the local search based $5.828$-approximation. In this work, we overcome the above challenge, and manage to adapt Sieve-Streaming to non-monotone objective functions by introducing a "just right" amount of randomness into it. Consequently, we get a semi-streaming polynomial time $4.282$-approximation algorithm for non-monotone objectives. Moreover, if one allows our algorithm to run in super-polynomial time, then its approximation ratio can be further improved to $3 + \varepsilon$.},
archivePrefix = {arXiv},
arxivId = {1906.11237},
author = {Alaluf, Naor and Feldman, Moran},
eprint = {1906.11237},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alaluf, Feldman - 2019 - Making a Sieve Random Improved Semi-Streaming Algorithm for Submodular Maximization under a Cardinality Constra.pdf:pdf},
title = {{Making a Sieve Random: Improved Semi-Streaming Algorithm for Submodular Maximization under a Cardinality Constraint}},
url = {http://arxiv.org/abs/1906.11237},
year = {2019}
}
@article{Cobbe2019,
abstract = {In this report, we introduce Procgen Benchmark, a suite of 16 procedurally generated game-like environments designed to benchmark both sample efficiency and generalization in reinforcement learning. We believe that the community will benefit from increased access to high quality training environments, and we provide detailed experimental protocols for using this benchmark. We empirically demonstrate that diverse environment distributions are essential to adequately train and evaluate RL agents, thereby motivating the extensive use of procedural content generation. We then use this benchmark to investigate the effects of scaling model size, finding that larger models significantly improve both sample efficiency and generalization.},
archivePrefix = {arXiv},
arxivId = {1912.01588},
author = {Cobbe, Karl and Hesse, Christopher and Hilton, Jacob and Schulman, John},
eprint = {1912.01588},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cobbe et al. - 2019 - Leveraging Procedural Generation to Benchmark Reinforcement Learning.pdf:pdf},
month = {dec},
title = {{Leveraging Procedural Generation to Benchmark Reinforcement Learning}},
url = {http://arxiv.org/abs/1912.01588},
year = {2019}
}
@book{Sutton,
author = {Sutton, Richard S. and Barto, Andrew G.},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sutton, Barto - 1998 - Introduction to Reinforcement Learning.pdf:pdf},
isbn = {9780262039246},
keywords = {A. G.,R. S. & BARTO,SUTTON},
title = {{Introduction to Reinforcement Learning}},
url = {http://incompleteideas.net/book/RLbook2020.pdf},
year = {1998}
}
@article{Real2020,
abstract = {Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.},
archivePrefix = {arXiv},
arxivId = {2003.03384},
author = {Real, Esteban and Liang, Chen and So, David R. and Le, Quoc V.},
eprint = {2003.03384},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Real et al. - 2020 - AutoML-Zero Evolving Machine Learning Algorithms From Scratch.pdf:pdf},
month = {mar},
title = {{AutoML-Zero: Evolving Machine Learning Algorithms From Scratch}},
url = {http://arxiv.org/abs/2003.03384},
year = {2020}
}
@article{Bian2019,
abstract = {Neural architecture search (NAS) is gaining more and more attention in recent years due to its flexibility and the remarkable capability of reducing the burden of neural network design. To achieve better performance, however, the searching process usually costs massive computation, which might not be affordable to researchers and practitioners. While recent attempts have employed ensemble learning methods to mitigate the enormous computation, an essential characteristic of diversity in ensemble methods is missed out, causing more similar sub-architectures to be gathered and potential redundancy in the final ensemble architecture. To bridge this gap, we propose a pruning method for NAS ensembles, named as ''Sub-Architecture Ensemble Pruning in Neural Architecture Search (SAEP).'' It targets to utilize diversity and achieve sub-ensemble architectures in a smaller size with comparable performance to the unpruned ensemble architectures. Three possible solutions are proposed to decide which subarchitectures should be pruned during the searching process. Experimental results demonstrate the effectiveness of the proposed method in largely reducing the size of ensemble architectures while maintaining the final performance. Moreover, distinct deeper architectures could be discovered if the searched sub-architectures are not diverse enough.},
archivePrefix = {arXiv},
arxivId = {1910.00370},
author = {Bian, Yijun and Song, Qingquan and Du, Mengnan and Yao, Jun and Chen, Huanhuan and Hu, Xia},
eprint = {1910.00370},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bian et al. - 2019 - Sub-Architecture Ensemble Pruning in Neural Architecture Search.pdf:pdf},
month = {oct},
title = {{Sub-Architecture Ensemble Pruning in Neural Architecture Search}},
url = {http://arxiv.org/abs/1910.00370},
year = {2019}
}
@inproceedings{Grill2020,
author = {et al. Grill, Jean-Bastien},
booktitle = {ICML},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grill - 2020 - Monte-Carlo tree search as regularized policy optimization.pdf:pdf},
title = {{Monte-Carlo tree search as regularized policy optimization}},
year = {2020}
}
@article{Tian2019,
abstract = {The AlphaGo, AlphaGo Zero, and AlphaZero series of algorithms are remarkable demonstrations of deep reinforcement learning's capabilities, achieving superhuman performance in the complex game of Go with progressively increasing autonomy. However, many obstacles remain in the understanding of and usability of these promising approaches by the research community. Toward elucidating unresolved mysteries and facilitating future research, we propose ELF OpenGo, an open-source reimplementation of the AlphaZero algorithm. ELF OpenGo is the first open-source Go AI to convincingly demonstrate superhuman performance with a perfect (20:0) record against global top professionals. We apply ELF OpenGo to conduct extensive ablation studies, and to identify and analyze numerous interesting phenomena in both the model training and in the gameplay inference procedures. Our code, models, selfplay datasets, and auxiliary data are publicly available.},
archivePrefix = {arXiv},
arxivId = {1902.04522},
author = {Tian, Yuandong and Ma, Jerry and Gong, Qucheng and Sengupta, Shubho and Chen, Zhuoyuan and Pinkerton, James and Zitnick, C. Lawrence},
eprint = {1902.04522},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tian et al. - 2019 - ELF OpenGo An Analysis and Open Reimplementation of AlphaZero.pdf:pdf},
month = {feb},
title = {{ELF OpenGo: An Analysis and Open Reimplementation of AlphaZero}},
url = {http://arxiv.org/abs/1902.04522},
year = {2019}
}
@article{Abe2019,
abstract = {There have been increasing challenges to solve combinatorial optimization problems by machine learning. Khalil et al. proposed an end-to-end reinforcement learning framework, S2V-DQN, which automatically learns graph embeddings to construct solutions to a wide range of problems. To improve the generalization ability of their Q-learning method, we propose a novel learning strategy based on AlphaGo Zero which is a Go engine that achieved a superhuman level without the domain knowledge of the game. Our framework is redesigned for combinatorial problems, where the final reward might take any real number instead of a binary response, win/lose. In experiments conducted for five kinds of NP-hard problems including {\sc MinimumVertexCover} and {\sc MaxCut}, our method is shown to generalize better to various graphs than S2V-DQN. Furthermore, our method can be combined with recently-developed graph neural network (GNN) models such as the \emph{Graph Isomorphism Network}, resulting in even better performance. This experiment also gives an interesting insight into a suitable choice of GNN models for each task.},
archivePrefix = {arXiv},
arxivId = {1905.11623},
author = {Abe, Kenshin and Xu, Zijian and Sato, Issei and Sugiyama, Masashi},
eprint = {1905.11623},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abe et al. - 2019 - Solving NP-Hard Problems on Graphs with Extended AlphaGo Zero.pdf:pdf},
month = {may},
title = {{Solving NP-Hard Problems on Graphs with Extended AlphaGo Zero}},
url = {http://arxiv.org/abs/1905.11623},
year = {2019}
}
@techreport{Ni,
abstract = {We investigate the problem of multiclass classification with rejection, where a classifier can choose not to make a prediction to avoid critical misclassification. First, we consider an approach based on simultaneous training of a classifier and a rejector, which achieves the state-of-the-art performance in the binary case. We analyze this approach for the multiclass case and derive a general condition for calibration to the Bayes-optimal solution, which suggests that calibration is hard to achieve by general loss functions unlike the binary case. Next, we consider another traditional approach based on confidence scores, in which the existing work focuses on a specific class of losses. We propose rejection criteria for more general losses for this approach and guarantee calibration to the Bayes-optimal solution. Finally, we conduct experiments to validate the relevance of our theoretical findings.},
author = {Ni, Chenri and Charoenphakdee, Nontawat and Honda, Junya and Sugiyama, Masashi},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ni et al. - Unknown - On the Calibration of Multiclass Classification with Rejection.pdf:pdf},
title = {{On the Calibration of Multiclass Classification with Rejection}}
}
@article{Badia2020,
abstract = {Atari games have been a long-standing benchmark in the reinforcement learning (RL) community for the past decade. This benchmark was proposed to test general competency of RL algorithms. Previous work has achieved good average performance by doing outstandingly well on many games of the set, but very poorly in several of the most challenging games. We propose Agent57, the first deep RL agent that outperforms the standard human benchmark on all 57 Atari games. To achieve this result, we train a neural network which parameterizes a family of policies ranging from very exploratory to purely exploitative. We propose an adaptive mechanism to choose which policy to prioritize throughout the training process. Additionally, we utilize a novel parameterization of the architecture that allows for more consistent and stable learning.},
archivePrefix = {arXiv},
arxivId = {2003.13350},
author = {Badia, Adri{\`{a}} Puigdom{\`{e}}nech and Piot, Bilal and Kapturowski, Steven and Sprechmann, Pablo and Vitvitskyi, Alex and Guo, Daniel and Blundell, Charles},
eprint = {2003.13350},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Badia et al. - 2020 - Agent57 Outperforming the Atari Human Benchmark.pdf:pdf},
month = {mar},
title = {{Agent57: Outperforming the Atari Human Benchmark}},
url = {http://arxiv.org/abs/2003.13350},
year = {2020}
}
@article{Badia2020a,
abstract = {Atari games have been a long-standing benchmark in the reinforcement learning (RL) community for the past decade. This benchmark was proposed to test general competency of RL algorithms. Previous work has achieved good average performance by doing outstandingly well on many games of the set, but very poorly in several of the most challenging games. We propose Agent57, the first deep RL agent that outperforms the standard human benchmark on all 57 Atari games. To achieve this result, we train a neural network which parameterizes a family of policies ranging from very exploratory to purely exploitative. We propose an adaptive mechanism to choose which policy to prioritize throughout the training process. Additionally, we utilize a novel parameterization of the architecture that allows for more consistent and stable learning.},
archivePrefix = {arXiv},
arxivId = {2003.13350},
author = {Badia, Adri{\`{a}} Puigdom{\`{e}}nech and Piot, Bilal and Kapturowski, Steven and Sprechmann, Pablo and Vitvitskyi, Alex and Guo, Daniel and Blundell, Charles},
eprint = {2003.13350},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Badia et al. - 2020 - Agent57 Outperforming the Atari Human Benchmark.pdf:pdf},
month = {mar},
title = {{Agent57: Outperforming the Atari Human Benchmark}},
url = {http://arxiv.org/abs/2003.13350},
year = {2020}
}
@techreport{Mnih2016,
abstract = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.},
author = {Mnih, Volodymyr and {Puigdom{\`{e}}nech Badia}, Adri{\`{a}} and Mirza, Mehdi and Graves, Alex and Harley, Tim and Lillicrap, Timothy P and Silver, David and Kavukcuoglu, Koray},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mnih et al. - 2016 - Asynchronous Methods for Deep Reinforcement Learning.pdf:pdf},
title = {{Asynchronous Methods for Deep Reinforcement Learning}},
year = {2016}
}
@article{Mnih2015,
abstract = {The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
doi = {10.1038/nature14236},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mnih et al. - 2015 - Human-level control through deep reinforcement learning(2).pdf:pdf},
issn = {14764687},
journal = {Nature},
number = {7540},
pages = {529--533},
pmid = {25719670},
publisher = {Nature Publishing Group},
title = {{Human-level control through deep reinforcement learning}},
url = {http://dx.doi.org/10.1038/nature14236},
volume = {518},
year = {2015}
}
@article{Author2020,
author = {Author, Anonymous and Address, Affiliation},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Author, Address - 2020 - Test Score Based Algorithms for Budgeted Stochastic Submodular Maximization.pdf:pdf},
number = {NeurIPS},
title = {{Test Score Based Algorithms for Budgeted Stochastic Submodular Maximization}},
year = {2020}
}
@article{Author2020a,
author = {Author, Anonymous and Address, Affiliation},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Author, Address - 2020 - Steaming algorithms for monotone DR-submodular and lattice submodular maximization with a cardinality constrain.pdf:pdf},
number = {NeurIPS},
title = {{Steaming algorithms for monotone DR-submodular and lattice submodular maximization with a cardinality constraint on the integer lattice}},
year = {2020}
}
@article{Author2020b,
author = {Author, Anonymous and Address, Affiliation},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Author, Address - 2020 - Improved Algorithms for Online Submodular Maximization via First-order Regret Bounds.pdf:pdf;:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Author, Address - 2020 - Improved Algorithms for Online Submodular Maximization via First-order Regret Bounds(2).pdf:pdf},
number = {NeurIPS},
pages = {1--10},
title = {{Improved Algorithms for Online Submodular Maximization via First-order Regret Bounds}},
year = {2020}
}
@article{Comfort2011,
author = {Comfort, W. W. and Negrepontis, S.},
doi = {10.1017/cbo9780511897337.013},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Author, Address - 2020 - A Parameterized Family of Meta-Submodular Functions(2).pdf:pdf},
journal = {Chain Conditions in Topology},
pages = {251--280},
title = {{Appendix: Meta-sub}},
year = {2011}
}
@article{Author2020c,
author = {Author, Anonymous and Address, Affiliation},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Author, Address - 2020 - Fairness in Streaming Submodular Maximization Algorithms and Hardness.pdf:pdf},
number = {NeurIPS},
title = {{Fairness in Streaming Submodular Maximization : Algorithms and Hardness}},
year = {2020}
}
@article{Author2020d,
author = {Author, Anonymous and Address, Affiliation},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Author, Address - 2020 - Robust Sequence Submodular Maximization.pdf:pdf},
number = {NeurIPS},
title = {{Robust Sequence Submodular Maximization}},
year = {2020}
}
@article{Author2020e,
author = {Author, Anonymous and Address, Affiliation},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Author, Address - 2020 - A Parameterized Family of Meta-Submodular Functions.pdf:pdf;:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Author, Address - 2020 - A Parameterized Family of Meta-Submodular Functions(2).pdf:pdf},
keywords = {1,49,and a be a,be our ground set,constant factor approxima-,diversity maximization,in some cases constrained,in the realm of,let,n,one such example arises,pairwise dissimilarity measure on,search in databases,supermodular maximization admits a,the elements of,tion,where},
number = {NeurIPS},
pages = {1--12},
title = {{A Parameterized Family of Meta-Submodular Functions}},
year = {2020}
}
@article{Barrett2019,
abstract = {Many real-world problems can be reduced to combinatorial optimization on a graph, where the subset or ordering of vertices that maximize some objective function must be found. With such tasks often NP-hard and analytically intractable, reinforcement learning (RL) has shown promise as a framework with which efficient heuristic methods to tackle these problems can be learned. Previous works construct the solution subset incrementally, adding one element at a time, however, the irreversible nature of this approach prevents the agent from revising its earlier decisions, which may be necessary given the complexity of the optimization task. We instead propose that the agent should seek to continuously improve the solution by learning to explore at test time. Our approach of exploratory combinatorial optimization (ECO-DQN) is, in principle, applicable to any combinatorial problem that can be defined on a graph. Experimentally, we show our method to produce state-of-the-art RL performance on the Maximum Cut problem. Moreover, because ECO-DQN can start from any arbitrary configuration, it can be combined with other search methods to further improve performance, which we demonstrate using a simple random search.},
archivePrefix = {arXiv},
arxivId = {1909.04063},
author = {Barrett, Thomas D. and Clements, William R. and Foerster, Jakob N. and Lvovsky, A. I.},
eprint = {1909.04063},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barrett et al. - 2019 - Exploratory Combinatorial Optimization with Reinforcement Learning.pdf:pdf},
month = {sep},
title = {{Exploratory Combinatorial Optimization with Reinforcement Learning}},
url = {http://arxiv.org/abs/1909.04063},
year = {2019}
}
@article{Ma2019,
abstract = {In this work, we introduce Graph Pointer Networks (GPNs) trained using reinforcement learning (RL) for tackling the traveling salesman problem (TSP). GPNs build upon Pointer Networks by introducing a graph embedding layer on the input, which captures relationships between nodes. Furthermore, to approximate solutions to constrained combinatorial optimization problems such as the TSP with time windows, we train hierarchical GPNs (HGPNs) using RL, which learns a hierarchical policy to find an optimal city permutation under constraints. Each layer of the hierarchy is designed with a separate reward function, resulting in stable training. Our results demonstrate that GPNs trained on small-scale TSP50/100 problems generalize well to larger-scale TSP500/1000 problems, with shorter tour lengths and faster computational times. We verify that for constrained TSP problems such as the TSP with time windows, the feasible solutions found via hierarchical RL training outperform previous baselines. In the spirit of reproducible research we make our data, models, and code publicly available.},
archivePrefix = {arXiv},
arxivId = {1911.04936},
author = {Ma, Qiang and Ge, Suwen and He, Danyang and Thaker, Darshan and Drori, Iddo},
eprint = {1911.04936},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma et al. - 2019 - Combinatorial Optimization by Graph Pointer Networks and Hierarchical Reinforcement Learning.pdf:pdf},
month = {nov},
title = {{Combinatorial Optimization by Graph Pointer Networks and Hierarchical Reinforcement Learning}},
url = {http://arxiv.org/abs/1911.04936},
year = {2019}
}
@article{Mazyavkina2020,
abstract = {Combinatorial optimization (CO) is the workhorse of numerous important applications in operations research, engineering and other fields and, thus, has been attracting enormous attention from the research community for over a century. Many efficient solutions to common problems involve using hand-crafted heuristics to sequentially construct a solution. Therefore, it is intriguing to see how a combinatorial optimization problem can be formulated as a sequential decision making process and whether efficient heuristics can be implicitly learned by a reinforcement learning agent to find a solution. This survey explores the synergy between CO and reinforcement learning (RL) framework, which can become a promising direction for solving combinatorial problems.},
archivePrefix = {arXiv},
arxivId = {2003.03600},
author = {Mazyavkina, Nina and Sviridov, Sergey and Ivanov, Sergei and Burnaev, Evgeny},
eprint = {2003.03600},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mazyavkina et al. - 2020 - Reinforcement Learning for Combinatorial Optimization A Survey.pdf:pdf},
title = {{Reinforcement Learning for Combinatorial Optimization: A Survey}},
url = {http://arxiv.org/abs/2003.03600},
year = {2020}
}
@article{Drori2020,
abstract = {Combinatorial optimization algorithms for graph problems are usually designed afresh for each new problem with careful attention by an expert to the problem structure. In this work, we develop a new framework to solve any combinatorial optimization problem over graphs that can be formulated as a single player game defined by states, actions, and rewards, including minimum spanning tree, shortest paths, traveling salesman problem, and vehicle routing problem, without expert knowledge. Our method trains a graph neural network using reinforcement learning on an unlabeled training set of graphs. The trained network then outputs approximate solutions to new graph instances in linear running time. In contrast, previous approximation algorithms or heuristics tailored to NP-hard problems on graphs generally have at least quadratic running time. We demonstrate the applicability of our approach on both polynomial and NP-hard problems with optimality gaps close to 1, and show that our method is able to generalize well: (i) from training on small graphs to testing on large graphs; (ii) from training on random graphs of one type to testing on random graphs of another type; and (iii) from training on random graphs to running on real world graphs.},
archivePrefix = {arXiv},
arxivId = {2006.03750},
author = {Drori, Iddo and Kharkar, Anant and Sickinger, William R. and Kates, Brandon and Ma, Qiang and Ge, Suwen and Dolev, Eden and Dietrich, Brenda and Williamson, David P. and Udell, Madeleine},
eprint = {2006.03750},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Drori et al. - 2020 - Learning to Solve Combinatorial Optimization Problems on Real-World Graphs in Linear Time.pdf:pdf},
number = {i},
pages = {1--19},
title = {{Learning to Solve Combinatorial Optimization Problems on Real-World Graphs in Linear Time}},
url = {http://arxiv.org/abs/2006.03750},
year = {2020}
}
@article{Wilder2019a,
abstract = {Creating impact in real-world settings requires artificial intelligence techniques to span the full pipeline from data, to predictive models, to decisions. These components are typically approached separately: a machine learning model is first trained via a measure of predictive accuracy, and then its predictions are used as input into an optimization algorithm which produces a decision. However, the loss function used to train the model may easily be misaligned with the end goal, which is to make the best decisions possible. Hand-tuning the loss function to align with optimization is a difficult and error-prone process (which is often skipped entirely).We focus on combinatorial optimization problems and introduce a general framework for decision-focused learning, where the machine learning model is directly trained in conjunction with the optimization algorithm to produce highquality decisions. Technically, our contribution is a means of integrating common classes of discrete optimization problems into deep learning or other predictive models, which are typically trained via gradient descent. The main idea is to use a continuous relaxation of the discrete problem to propagate gradients through the optimization procedure. We instantiate this framework for two broad classes of combinatorial problems: linear programs and submodular maximization. Experimental results across a variety of domains show that decisionfocused learning often leads to improved optimization performance compared to traditional methods. We find that standard measures of accuracy are not a reliable proxy for a predictive model's utility in optimization, and our method's ability to specify the true goal as the model's training objective yields substantial dividends across a range of decision problems.},
archivePrefix = {arXiv},
arxivId = {1809.05504},
author = {Wilder, Bryan and Dilkina, Bistra and Tambe, Milind},
doi = {10.1609/aaai.v33i01.33011658},
eprint = {1809.05504},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilder, Dilkina, Tambe - 2019 - Melding the Data-Decisions Pipeline Decision-Focused Learning for Combinatorial Optimization.pdf:pdf},
issn = {2159-5399},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
keywords = {maximum satifiability, semidefinte program, low-ra},
pages = {1658--1665},
title = {{Melding the Data-Decisions Pipeline: Decision-Focused Learning for Combinatorial Optimization}},
volume = {33},
year = {2019}
}
@article{Emadwiandr2013,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Emadwiandr},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/emadwiandr - 2013 - 済無No Title No Title.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {Journal of Chemical Information and Modeling},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{済無No Title No Title}},
volume = {53},
year = {2013}
}
@article{Bello2019,
abstract = {We present a framework to tackle combinatorial optimization problems using neural networks and reinforcement learning. We focus on the traveling salesman problem (TSP) and train a recurrent neural network that, given a set of city coordinates, predicts a distribution over different city permutations. Using negative tour length as the reward signal, we optimize the parameters of the recurrent neural network using a policy gradient method. Without much engineering and heuristic designing, Neural Combinatorial Optimization achieves close to optimal results on 2D Euclidean graphs with up to 100 nodes. These results, albeit still quite far from state-of-the-art, give insights into how neural networks can be used as a general tool for tackling combinatorial optimization problems.},
archivePrefix = {arXiv},
arxivId = {1611.09940},
author = {Bello, Irwan and Pham, Hieu and Le, Quoc V. and Norouzi, Mohammad and Bengio, Samy},
eprint = {1611.09940},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bello et al. - 2019 - Neural combinatorial optimization with reinforcement learning.pdf:pdf},
journal = {5th International Conference on Learning Representations, ICLR 2017 - Workshop Track Proceedings},
pages = {1--15},
title = {{Neural combinatorial optimization with reinforcement learning}},
year = {2019}
}
@inproceedings{Mislove2008,
author = {Mislove, Alan and Koppula, Hema Swetha and Gummadi, Krishna P and Druschel, Peter and Bhattacharjee, Bobby},
booktitle = {First Workshop on Online Social Networks},
title = {{Growth of the Flickr Social Network}},
year = {2008}
}
@article{Gharan2011a,
abstract = {We consider the problem of maximizing a nonnegative (possibly non-monotone) submodular set function with or without constraints. Feige et al. [9] showed a 2/5-approximation for the unconstrained problem and also proved that no approximation better than 1/2 is possible in the value oracle model. Constant-factor approximation has been also known for subinodular maximization subject to a matroid independence constraint (a factor of 0.309 [33]) and for submodular maximization subject to a matroid base constraint, provided that the fractional base packing number $\nu$ is bounded away from 1 (a 1/4-approximation assuming that $\nu$ ≥ 2 [33]). In this paper, we propose a new algorithm for submodular maximization which is based on the idea of simulated annealing. We prove that this algorithm achieves improved approximation for two problems: a 0.41-approximation for unconstrained submodular maximization, and a 0.325-approximation for submodular maximization subject to a matroid independence constraint. On the hardness side, we show that in the value oracle model it is impossible to achieve a 0.478-approximation for submodular maximization subject to a matroid independence constraint, or a 0.394-approximation subject to a matroid base constraint in matroids with two disjoint bases. Even for the special case of cardinality constraint, we prove it is impossible to achieve a 0.491-approximation. (Previously it was conceivable that a 1/2-approximation exists for these problems.) It is still an open question whether a 1/2-approximation is possible for unconstrained submodular maximization.},
archivePrefix = {arXiv},
arxivId = {1007.1632},
author = {Gharan, Shayan Oveis and Vondr{\'{a}}k, Jan},
doi = {10.1137/1.9781611973082.83},
eprint = {1007.1632},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gharan, Vondr{\'{a}}k - 2011 - Submodular maximization by simulated annealing.pdf:pdf},
isbn = {9780898719932},
journal = {ACM-SIAM Symposium on Discrete Algorithms (SODA)},
title = {{Submodular maximization by simulated annealing}},
year = {2011}
}
@inproceedings{El-Arini2011,
abstract = {In scientific research, it is often difficult to express informa- tion needs as simple keyword queries. We present a more natural way of searching for relevant scientific literature. Rather than a string of keywords, we define a query as a small set of papers deemed relevant to the research task at hand. By optimizing an objective function based on a fine-grained notion of influence between documents, our approach efficiently selects a set of highly relevant articles. Moreover, as scientists trust some authors more than oth- ers, results are personalized to individual preferences. In a user study, researchers found the papers recommended by our method to be more useful, trustworthy and diverse than those selected by popular alternatives, such as Google Scholar and a state-of-the-art topic modeling approach.},
author = {El-Arini, Khalid and Guestrin, Carlos},
booktitle = {ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)},
doi = {10.1145/2020408.2020479},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/El-Arini, Guestrin - 2011 - Beyond Keyword Search Discovering Relevant Scientific Literature.pdf:pdf},
isbn = {9781450308137},
keywords = {citation analysis,personalization},
title = {{Beyond Keyword Search: Discovering Relevant Scientific Literature}},
year = {2011}
}
@inproceedings{Sipos2012,
abstract = {In many areas of life, we now have almost complete electronic archives reaching back for well over two decades. This includes, for example, the body of research papers in computer science, all news articles written in the US, and most people's personal email. However, we have only rather limited methods for analyzing and understanding these collections. While keyword-based retrieval systems allow efficient access to individual documents in archives, we still lack methods for understanding a corpus as a whole. In this paper, we explore methods that provide a temporal summary of such corpora in terms of landmark documents, authors, and topics. In particular, we explicitly model the temporal nature of influence between documents and re-interpret summarization as a coverage problem over words anchored in time. The resulting models provide monotone sub-modular objectives for computing informative and non-redundant summaries over time, which can be efficiently optimized with greedy algorithms. Our empirical study shows the effectiveness of our approach over several baselines. {\textcopyright} 2012 ACM.},
author = {Sipos, Ruben and Swaminathan, Adith and Shivaswamy, Pannaga and Joachims, Thorsten},
booktitle = {ACM International Conference on Information and Knowledge Management (CIKM)},
doi = {10.1145/2396761.2396857},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sipos et al. - 2012 - Temporal corpus summarization using submodular word coverage.pdf:pdf},
isbn = {9781450311564},
keywords = {submodular,summarization,temporal},
title = {{Temporal corpus summarization using submodular word coverage}},
year = {2012}
}
@inproceedings{Simon2007,
abstract = {We formulate the problem of scene summarization as selecting a set of images that efficiently represents the visual content of a given scene. The ideal summary presents the most interesting and important aspects of the scene with minimal redundancy. We propose a solution to this problem using multi-user image collections from the Internet. Our solution examines the distribution of images in the collection to select a set of canonical views to form the scene summary, using clustering techniques on visual features. The summaries we compute also lend themselves naturally to the browsing of image collections, and can be augmented by analyzing user-specified image tag data. We demonstrate the approach using a collection of images of the city of Rome, showing the ability to automatically decompose the images into separate scenes, and identify canonical views for each scene. {\textcopyright}2007 IEEE.},
author = {Simon, Ian and Snavely, Noah and Seitz, Steven M.},
booktitle = {IEEE International Conference on Computer Vision (ICCV)},
doi = {10.1109/ICCV.2007.4408863},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Simon, Snavely, Seitz - 2007 - Scene summarization for online image collections.pdf:pdf},
title = {{Scene summarization for online image collections}},
year = {2007}
}
@inproceedings{Tschiatschek2014,
abstract = {We address the problem of image collection summarization by learning mixtures of submodular functions. Submodularity is useful for this problem since it naturally represents characteristics such as fidelity and diversity, desirable for any summary. Several previously proposed image summarization scoring methodologies, in fact, instinctively arrived at submodularity. We provide classes of submodular component functions (including some which are instantiated via a deep neural network) over which mixtures may be learnt. We formulate the learning of such mixtures as a supervised problem via large-margin structured prediction. As a loss function, and for automatic summary scoring, we introduce a novel summary evaluation method called V-ROUGE, and test both submodular and non-submodular optimization (using the submodular-supermodular procedure) to learn a mixture of submodular functions. Interestingly, using non-submodular optimization to learn submodular functions provides the best results. We also provide a new data set consisting of 14 real-world image collections along with many human-generated ground truth summaries collected using Amazon Mechanical Turk. We compare our method with previous work on this problem and show that our learning approach outperforms all competitors on this new data set. This paper provides, to our knowledge, the first systematic approach for quantifying the problem of image collection summarization, along with a new data set of image collections and human summaries.},
author = {Tschiatschek, Sebastian and Iyer, Rishabh and Wei, Haochen and Bilmes, Jeff},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tschiatschek et al. - 2014 - Learning Mixtures of Submodular Functions for Image Cxollection Summarization.pdf:pdf},
issn = {10495258},
title = {{Learning Mixtures of Submodular Functions for Image Cxollection Summarization}},
year = {2014}
}
@incollection{taylor2017safety,
author = {Taylor, Linnet},
booktitle = {Group Privacy},
pages = {13--36},
publisher = {Springer},
title = {{Safety in numbers? Group privacy and big data analytics in the developing world}},
year = {2017}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2019 - Quick Streaming Algorithms for Maximization of Monotone Submodular Functions in Linear Time.pdf:pdf},
title = {{Quick Streaming Algorithms for Maximization of Monotone Submodular Functions in Linear Time}},
year = {2019}
}
@article{uddin2015evaluating,
author = {Uddin, Mueen and Darabidarabkhani, Yasaman and Shah, Asadullah and Memon, Jamshed},
journal = {Renewable and Sustainable Energy Reviews},
pages = {1553--1563},
publisher = {Elsevier},
title = {{Evaluating power efficient algorithms for efficiency and carbon emissions in cloud data centers: A review}},
volume = {51},
year = {2015}
}
@inproceedings{Gomes2010,
abstract = {We consider the problem of extracting informative exemplars from a data stream. Examples of this problem include exemplar-based clustering and nonparametric inference such as Gaussian process regression on massive data sets. We show that these problems require maximization of a submodular function that captures the informativeness of a set of exemplars, over a data stream. We develop an efficient algorithm, Stream-Greedy, which is guaranteed to obtain a constant fraction of the value achieved by the optimal solution to this NP-hard optimization problem. We extensively evaluate our algorithm on large real-world data sets. Copyright 2010 by the author(s)/owner(s).},
author = {Gomes, Ryan and Krause, Andreas},
booktitle = {International Conference on Machine Learning (ICML)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gomes, Krause - 2010 - Budgeted Nonparametric Learning from Data Streams.pdf:pdf},
isbn = {9781605589077},
title = {{Budgeted Nonparametric Learning from Data Streams}},
year = {2010}
}
@inproceedings{kumar2017antisocial,
author = {Kumar, Srijan and Cheng, Justin and Leskovec, Jure},
booktitle = {International Conference on World Wide Web Companion},
pages = {947--950},
title = {{Antisocial behavior on the web: Characterization and detection}},
year = {2017}
}
@inproceedings{budak2011limiting,
author = {Budak, Ceren and Agrawal, Divyakant and {El Abbadi}, Amr},
booktitle = {Proceedings of the 20th international conference on World Wide Web (WWW)},
pages = {665--674},
title = {{Limiting the spread of misinformation in social networks}},
year = {2011}
}
@article{gosselin2008use,
author = {Gosselin, Pierre and Poitras, Philippe},
journal = {Journal of Medical Internet Research},
number = {4},
pages = {e47},
publisher = {JMIR Publications Inc., Toronto, Canada},
title = {{Use of an internet “viral” marketing software platform in health promotion}},
volume = {10},
year = {2008}
}
@article{lewandowsky2017beyond,
author = {Lewandowsky, Stephan and Ecker, Ullrich K H and Cook, John},
journal = {Journal of applied research in memory and cognition},
number = {4},
pages = {353--369},
publisher = {Elsevier},
title = {{Beyond misinformation: Understanding and coping with the “post-truth” era}},
volume = {6},
year = {2017}
}
@article{Hartline2008,
abstract = {We discuss the use of social networks in implementing viral marketing strategies. While influence maximization has been studied in this context (see Chapter 24 of [10]), we study revenue maximization, arguably, a more natural objective. In our model, a buyer's decision to buy an item is influenced by the set of other buyers that own the item and the price at which the item is offered. We focus on algorithmic question of finding revenue maximizing marketing strategies. When the buyers are completely symmetric, we can find the optimal marketing strategy in polynomial time. In the general case, motivated by hardness results, we investigate approximation algorithms for this problem. We identify a family of strategies called influence-and-exploit strategies that are based on the following idea: Initially influence the population by giving the item for free to carefully a chosen set of buyers. Then extract revenue from the remaining buyers using a 'greedy' pricing strategy. We first argue why such strategies are reasonable and then show how to use recently developed set-function maximization techniques to find the right set of buyers to influence.},
author = {Hartline, Jason and Mirrokni, Vahab S. and Sundararajan, Mukund},
doi = {10.1145/1367497.1367524},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hartline, Mirrokni, Sundararajan - 2008 - Optimal marketing strategies over social networks.pdf:pdf},
isbn = {9781605580852},
journal = {International Conference on World Wide Web (WWW)},
keywords = {Marketing,Monetizing social networks,Pricing,Sub-modular maximization},
pages = {189--198},
title = {{Optimal marketing strategies over social networks}},
year = {2008}
}
@article{Cook2015,
abstract = {The increasing prevalence of misinformation in society may adversely affect democratic decision making, which depends on a well-informed public. False infor-mation can originate from a number of sources including rumors, literary fiction, mainstream media, corporate-vested interests, governments, and nongovernmental organizations. The rise of the Internet and user-driven content has provided a venue for quick and broad dissemination of information, not all of which is accurate. Con-sequently, a large body of research spanning a number of disciplines has sought to understand misinformation and determine which interventions are most effective in reducing its influence. This essay summarizes research into misinformation, bringing together studies from psychology, political science, education, and computer science. Cognitive psychology investigates why individuals struggle with correcting misinformation and inaccurate beliefs, and why myths are so difficult to dislodge. Two important findings involve (i) various " backfire effects, " which arise when refutations ironically reinforce misconceptions, and (ii) the role of worldviews in accentuating the persistence of misinformation. Computer scientists simulate the spread of misinformation through social networks and develop algorithms to automatically detect or neutralize myths. We draw together various research threads to provide guidelines on how to effectively refute misconceptions without risking backfire effects.},
author = {Cook, John and Ecker, Ullrich and Lewandowsky, Stephan},
doi = {10.1002/9781118900772.etrds0222},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cook, Ecker, Lewandowsky - 2015 - Misinformation and How to Correct It.pdf:pdf},
isbn = {9781118900772},
journal = {Emerging Trends in the Social and Behavioral Sciences},
number = {May},
pages = {1--17},
title = {{Misinformation and How to Correct It}},
year = {2015}
}
@article{Chan2017,
abstract = {We study the online submodular maximization problem with free disposal under a matroid constraint. Elements from some ground set arrive one by one in rounds, and the algorithm maintains a feasible set that is independent in the underlying matroid. In each round when a new element arrives, the algorithm may accept the new element into its feasible set and possibly remove elements from it, provided that the resulting set is still independent. The goal is to maximize the value of the final feasible set under some monotone submodular function, to which the algorithm has oracle access. For k-uniform matroids, we give a deterministic algorithm with competitive ratio at least 0:2959, and the ratio approaches as k approaches infinity, improving the previous best ratio of 0:25 by Chakrabarti and Kale (IPCO 2014), Buchbinder et al. (SODA 2015) and Chekuri et al. (ICALP 2015). We also show that our algorithm is optimal among a class of deterministic monotone algorithms that accept a new arriving element only if the objective is strictly increased. Further, we prove that no deterministic monotone algorithm can be strictly better than 0:25-competitive even for partition matroids, the most modest generalization of k-uniform matroids, matching the competitive ratio by Chakrabarti and Kale (IPCO 2014) and Chekuri et al. (ICALP 2015). Interestingly, we show that randomized algorithms are strictly more powerful by giving a (non-monotone) randomized algorithm for partition matroids with ratio 1 Finally, our techniques can be extended to a more general problem that generalizes both the online submodular maximization problem and the online bipartite matching problem with free disposal. Using the techniques developed in this paper, we give constant-competitive algorithms for the submodular online bipartite matching problem.},
author = {Chan, T. H.Hubert and Huang, Zhiyi and Jiang, Shaofeng H.C. and Kang, Ning and Tang, Zhihao Gavin},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chan et al. - 2017 - Online Submodular Maximization with Free Disposal Randomization Beats 14 for Partition Matroids.pdf:pdf},
isbn = {9781611974782},
journal = {ACM-SIAM Symposium on Discrete Algorithms (SODA)},
pages = {1204--1223},
title = {{Online Submodular Maximization with Free Disposal: Randomization Beats 1/4 for Partition Matroids}},
year = {2017}
}
@article{McGregor2019,
abstract = {We study the classic NP-Hard problem of finding the maximum k-set coverage in the data stream model: given a set system of m sets that are subsets of a universe { 1 , {\ldots} , n} , find the k sets that cover the most number of distinct elements. The problem can be approximated up to a factor 1 − 1 / e in polynomial time. In the streaming-set model, the sets and their elements are revealed online. The main goal of our work is to design algorithms, with approximation guarantees as close as possible to 1 − 1 / e, that use sublinear space o(mn). Our main results are: Two (1 − 1 / e− ?) approximation algorithms: One uses O(?− 1) passes and {\~{O}}(?− 2k) space whereas the other uses only a single pass but {\~{O}}(?− 2m) space. {\~{O}}(⋅) suppresses polylog factors.We show that any approximation factor better than (1 − (1 − 1 / k) k) ≈ 1 − 1 / e in constant passes requires $\Omega$ (m) space for constant k even if the algorithm is allowed unbounded processing time. We also demonstrate a single-pass, (1 − ?) approximation algorithm using {\~{O}}(?− 2m⋅ min (k, ?− 1)) space. We also study the maximum k-vertex coverage problem in the dynamic graph stream model. In this model, the stream consists of edge insertions and deletions of a graph on N vertices. The goal is to find k vertices that cover the most number of distinct edges. We show that any constant approximation in constant passes requires $\Omega$ (N) space for constant k whereas {\~{O}}(?− 2N) space is sufficient for a (1 − ?) approximation and arbitrary k in a single pass.For regular graphs, we show that {\~{O}}(?− 3k) space is sufficient for a (1 − ?) approximation in a single pass. We generalize this to a ($\kappa$− ?) approximation when the ratio between the minimum and maximum degree is bounded below by $\kappa$.},
author = {McGregor, Andrew and Vu, Hoa T.},
doi = {10.1007/s00224-018-9878-x},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McGregor, Vu - 2019 - Better Streaming Algorithms for the Maximum Coverage Problem.pdf:pdf},
issn = {14330490},
journal = {Theory of Computing Systems},
keywords = {Algorithms,Approximations,Data streams,Maximum coverage},
number = {7},
pages = {1595--1619},
publisher = {Theory of Computing Systems},
title = {{Better Streaming Algorithms for the Maximum Coverage Problem}},
volume = {63},
year = {2019}
}
@article{Chakrabarti2015,
abstract = {We study the problem of finding a maximum matching in a graph given by an input stream listing its edges in some arbitrary order, where the quantity to be maximized is given by a monotone submodular function on subsets of edges. This problem, which we call maximum submodular-function matching (MSM), is a natural generalization of maximum weight matching (MWM), which is in turn a generalization of maximum cardinality matching. We give two incomparable algorithms for this problem with space usage falling in the semi-streaming range—they store only $$O(n)$$O(n) edges, using (Formula presented.) working memory—that achieve approximation ratios of 7.75 in a single pass and (Formula presented.) in (Formula presented.) passes respectively. The operations of these algorithms mimic those of Zelke's and McGregor's respective algorithms for MWM; the novelty lies in the analysis for the MSM setting. In fact we identify a general framework for MWM algorithms that allows this kind of adaptation to the broader setting of MSM. Our framework is not specific to matchings. Rather, we identify a general pattern for algorithms that maximize linear weight functions over “independent sets” and prove that such algorithms can be adapted to maximize a submodular function. The notion of independence here is very general; in particular, appealing to known weight-maximization algorithms, we obtain results for submodular maximization over hypermatchings in hypergraphs as well as independent sets in the intersection of multiple matroids.},
author = {Chakrabarti, Amit and Kale, Sagar},
doi = {10.1007/s10107-015-0900-7},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chakrabarti, Kale - 2015 - Submodular maximization meets streaming matchings, matroids, and more.pdf:pdf},
isbn = {1010701509},
issn = {14364646},
journal = {Mathematical Programming},
keywords = {68W25 Approximation algorithms,68W27 Online algorithms},
number = {1-2},
pages = {225--247},
publisher = {Springer Berlin Heidelberg},
title = {{Submodular maximization meets streaming: matchings, matroids, and more}},
url = {http://dx.doi.org/10.1007/s10107-015-0900-7},
volume = {154},
year = {2015}
}
@inproceedings{Buchbinder2015b,
abstract = {Submodular function maximization has been studied extensively in recent years under various constraints and models. The problem plays a major role in various disciplines. We study a natural online variant of this problem in which elements arrive one-by-one and the algorithm has to maintain a solution obeying certain constraints at all times. Upon arrival of an element, the algorithm has to decide whether to accept the element into its solution and may preempt previously chosen elements. The goal is to maximize a sub-modular function over the set of elements in the solution. We study two special cases of this general problem and derive upper and lower bounds on the competitive ratio. Specifically, we design a 1/e-competitive algorithm for the unconstrained case in which the algorithm may hold any subset of the elements, and constant competitive ratio algorithms for the case where the algorithm may hold at most k elements in its solution.},
archivePrefix = {arXiv},
arxivId = {1501.05801},
author = {Buchbinder, Niv and Feldman, Moran and Schwartz, Roy},
booktitle = {ACM-SIAM Symposium on Discrete Algorithms},
doi = {10.1137/1.9781611973730.80},
eprint = {1501.05801},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buchbinder, Feldman, Schwartz - 2014 - Online Submodular Maximization with Preemption.pdf:pdf;:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buchbinder, Feldman, Schwartz - 2014 - Online Submodular Maximization with Preemption(2).pdf:pdf},
title = {{Online Submodular Maximization with Preemption}},
year = {2014}
}
@article{Bengio2018,
abstract = {This paper surveys the recent attempts, both from the machine learning and operations research communities, at leveraging machine learning to solve combinatorial optimization problems. Given the hard nature of these problems, state-of-the-art algorithms rely on handcrafted heuristics for making decisions that are otherwise too expensive to compute or mathematically not well defined. Thus, machine learning looks like a natural candidate to make such decisions in a more principled and optimized way. We advocate for pushing further the integration of machine learning and combinatorial optimization and detail a methodology to do so. A main point of the paper is seeing generic optimization problems as data points and inquiring what is the relevant distribution of problems to use for learning on a given task.},
archivePrefix = {arXiv},
arxivId = {1811.06128},
author = {Bengio, Yoshua and Lodi, Andrea and Prouvost, Antoine},
eprint = {1811.06128},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bengio, Lodi, Prouvost - 2018 - Machine Learning for Combinatorial Optimization a Methodological Tour d'Horizon.pdf:pdf},
pages = {1--47},
title = {{Machine Learning for Combinatorial Optimization: a Methodological Tour d'Horizon}},
url = {http://arxiv.org/abs/1811.06128},
year = {2018}
}
@article{Wilder2019,
abstract = {Real-world applications often combine learning and optimization problems on graphs. For instance, our objective may be to cluster the graph in order to detect meaningful communities (or solve other common graph optimization problems such as facility location, maxcut, and so on). However, graphs or related attributes are often only partially observed, introducing learning problems such as link prediction which must be solved prior to optimization. Standard approaches treat learning and optimization entirely separately, while recent machine learning work aims to predict the optimal solution directly from the inputs. Here, we propose an alternative decision-focused learning approach that integrates a differentiable proxy for common graph optimization problems as a layer in learned systems. The main idea is to learn a representation that maps the original optimization problem onto a simpler proxy problem that can be efficiently differentiated through. Experimental results show that our ClusterNet system outperforms both pure end-to-end approaches (that directly predict the optimal solution) and standard approaches that entirely separate learning and optimization. Code for our system is available at https://github.com/bwilder0/clusternet.},
archivePrefix = {arXiv},
arxivId = {1905.13732},
author = {Wilder, Bryan and Ewing, Eric and Dilkina, Bistra and Tambe, Milind},
eprint = {1905.13732},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilder et al. - 2019 - End to end learning and optimization on graphs.pdf:pdf},
number = {NeurIPS},
title = {{End to end learning and optimization on graphs}},
url = {http://arxiv.org/abs/1905.13732},
year = {2019}
}
@article{Dai2017,
abstract = {The design of good heuristics or approximation algorithms for NP-hard combinatorial optimization problems often requires significant specialized knowledge and trial-and-error. Can we automate this challenging, tedious process, and learn the algorithms instead? In many real-world applications, it is typically the case that the same optimization problem is solved again and again on a regular basis, maintaining the same problem structure but differing in the data. This provides an opportunity for learning heuristic algorithms that exploit the structure of such recurring problems. In this paper, we propose a unique combination of reinforcement learning and graph embedding to address this challenge. The learned greedy policy behaves like a meta-algorithm that incrementally constructs a solution, and the action is determined by the output of a graph embedding network capturing the current state of the solution. We show that our framework can be applied to a diverse range of optimization problems over graphs, and learns effective algorithms for the Minimum Vertex Cover, Maximum Cut and Traveling Salesman problems.},
archivePrefix = {arXiv},
arxivId = {1704.01665},
author = {Dai, Hanjun and Khalil, Elias B. and Zhang, Yuyu and Dilkina, Bistra and Song, Le},
eprint = {1704.01665},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dai et al. - 2017 - Learning combinatorial optimization algorithms over graphs.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {Nips},
pages = {6349--6359},
title = {{Learning combinatorial optimization algorithms over graphs}},
volume = {2017-Decem},
year = {2017}
}
@inproceedings{Feldman2020,
abstract = {We consider the classical problem of maximizing a monotone submodular function subject to a cardinality constraint, which, due to its numerous applications, has recently been studied in various computational models. We consider a clean multi-player model that lies between the offline and streaming model, and study it under the aspect of one-way communication complexity. Our model captures the streaming setting (by considering a large number of players), and, in addition, two player approximation results for it translate into the robust setting. We present tight one-way communication complexity results for our model, which, due to the above-mentioned connections, have multiple implications in the data stream and robust setting. Even for just two players, a prior information-theoretic hardness result implies that no approximation factor above $1/2$ can be achieved in our model, if only queries to feasible sets are allowed. We show that the possibility of querying infeasible sets can actually be exploited to beat this bound, by presenting a tight $2/3$-approximation taking exponential time, and an efficient $0.514$-approximation. To the best of our knowledge, this is the first example where querying a submodular function on infeasible sets leads to provably better results. Through the above-mentioned link to the robust setting, both of these algorithms improve on the current state-of-the-art for robust submodular maximization, showing that approximation factors beyond $1/2$ are possible. Moreover, exploiting the link of our model to streaming, we settle the approximability for streaming algorithms by presenting a tight $1/2+\varepsilon$ hardness result, based on the construction of a new family of coverage functions. This improves on a prior $1-1/e+\varepsilon$ hardness and matches, up to an arbitrarily small margin, the best known approximation algorithm.},
archivePrefix = {arXiv},
arxivId = {2003.13459},
author = {Feldman, Moran and Norouzi-Fard, Ashkan and Svensson, Ola and Zenklusen, Rico},
booktitle = {arXiv preprint arXiv:2003.13459},
eprint = {2003.13459},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feldman et al. - 2020 - The One-way Communication Complexity of Submodular Maximization with Applications to Streaming and Robustness.pdf:pdf},
title = {{The One-way Communication Complexity of Submodular Maximization with Applications to Streaming and Robustness}},
url = {http://arxiv.org/abs/2003.13459},
year = {2020}
}
@article{Crawford2019c,
abstract = {In this work, we study the Submodular Cost Sub-modular Cover problem, which is to minimize the submodular cost required to ensure that the sub-modular benefit function exceeds a given threshold. Existing approximation ratios for the greedy algorithm assume a value oracle to the benefit function. However, access to a value oracle is not a realistic assumption for many applications of this problem, where the benefit function is difficult to compute. We present two incomparable approximation ratios for this problem with an approximate value oracle and demonstrate that the ratios take on empirically relevant values through a case study with the Influence Threshold problem in online social networks.},
author = {Crawford, Victoria G. and Kuhnle, Alan and Thai, My T.},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Crawford, Kuhnle, Thai - 2019 - Submodular cost submodular cover with an approximate oracle.pdf:pdf},
isbn = {9781510886988},
journal = {International Conference on Machine Learning (ICML) 2019},
pages = {2582--2599},
title = {{Submodular cost submodular cover with an approximate oracle}},
year = {2019}
}
@article{Demmel2010,
abstract = {Rate variation among the sites of a molecular sequence is commonly found in applications of phylogenetic inference. Several approaches exist to account for this feature but they do not usually enable us to pinpoint the sites that evolve under one or another rate of evolution in a straightforward manner. In this paper we concentrate on phylogenetic mixture models as tools for site classification. Our method does not rely on prior knowledge of site membership to classes or even the number of classes. Furthermore, it does not require correlated sites to be next to one another in the sequence alignment, unlike some phylogenetic hidden Markov or change-point models. We present a simulation study to show that our approach is able to correctly classify the sites to evolutionary classes and we analyse the popular alignment of the mitochondrial DNA of primates. In both examples, all mixtures outperform commonly-used models of among-site rate variation and models that do not account for rate heterogeneity. Our method for site classification is directly relevant to the profiling of genes with unknown function, and its application may lead to the discovery of partitions not otherwise recognised in the alignment. In addition, we discuss computational aspects including the use of simple Markov chain Monte Carlo (MCMC) moves to estimate phylogenetic models and argue that these move types can mix efficiently without tempering the MCMC chains.},
author = {Demmel, James and Grigori, Laura and Hoemmen, Mark and Langou, Julien},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Demmel et al. - 2010 - Communication-Optimal Parallel and Sequential QR and LU Factorizations.pdf:pdf},
journal = {Siam Journal on Computing},
keywords = {090757290,1,10,1137,35b40,82d99,92d50,ams subject classifications,collective behaviors and self-,doi,flocking,introduction,mass transportation methods,nonlinear friction equations,the description of emerging},
number = {1},
pages = {218--236},
title = {{Communication-Optimal Parallel and Sequential QR and LU Factorizations}},
volume = {42},
year = {2010}
}
@article{Kwasniewski2019,
abstract = {We propose COSMA: a parallel matrix-matrix multiplication algorithm that is near communication-optimal for all combinations of matrix dimensions, processor counts, and memory sizes. The key idea behind COSMA is to derive an optimal (up to a factor of 0.03% for 10MB of fast memory) sequential schedule and then parallelize it, preserving I/O optimality. To achieve this, we use the red-blue pebble game to precisely model MMM dependencies and derive a constructive and tight sequential and parallel I/O lower bound proofs. Compared to 2D or 3D algorithms, which fix processor decomposition upfront and then map it to the matrix dimensions, it reduces communication volume by up to √; times. COSMA outperforms the established ScaLAPACK, CARMA, and CTF algorithms in all scenarios up to 12.8x (2.2x on average), achieving up to 88% of Piz Daint's peak performance. Our work does not require any hand tuning and is maintained as an open source implementation.},
archivePrefix = {arXiv},
arxivId = {1908.09606},
author = {Kwasniewski, Grzegorz and Kabi, Marko and Besta, MacIej and Vandevondele, Joost and Solc, Raffaele and Hoefler, Torsten},
doi = {10.1145/3295500.3356181},
eprint = {1908.09606},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kwasniewski et al. - 2019 - Red-blue pebbling revisited Near optimal parallel matrix-matrix multiplication.pdf:pdf},
isbn = {9781450362290},
issn = {21674337},
journal = {International Conference for High Performance Computing, Networking, Storage and Analysis, SC},
title = {{Red-blue pebbling revisited: Near optimal parallel matrix-matrix multiplication}},
year = {2019}
}
@inproceedings{Hong1981,
author = {Hong, Jia-Wei and Kung, H.T.},
booktitle = {Symposium on the Theory of Computing (STOC)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hong, Kung - 1981 - IO Complexity The Red-Blue Pebble Game.pdf:pdf},
isbn = {0897910419},
title = {{I/O Complexity: The Red-Blue Pebble Game}},
year = {1981}
}
@inproceedings{Demaine2018,
abstract = {The red-blue pebble game was formulated in the 1980s [14] to model the I/O complexity of algorithms on a two-level memory hierarchy. Given a directed acyclic graph representing computations (vertices) and their dependencies (edges), the red-blue pebble game allows sequentially adding, removing, and recoloring red or blue pebbles according to a few rules, where red pebbles represent data in cache (fast memory) and blue pebbles represent data on disk (slow, external memory). Specifically, a vertex can be newly pebbled red if and only if all of its predecessors currently have a red pebble; pebbles can always be removed; and pebbles can be recolored between red and blue (corresponding to reading or writing data between disk and cache, also called I/Os or memory transfers). Given an upper bound on the number of red pebbles at any time (the cache size), the goal is to compute a game execution with the fewest pebble recolorings (memory transfers) that finish with pebbles on a specified subset of nodes (outputs get computed). In this paper, we investigate the complexity of computing this trade-off between red-pebble limit (cache size) and number of recolorings (memory transfers) in general DAGs. First we prove this problem PSPACE-complete through an extension of the proof PSPACE-hardness of black pebbling complexity [13]. Second, we consider a natural restriction on the red-blue pebble game to forbid pebble deletions, or equivalently, forbid discarding data from cache without first writing it to disk. This assumption both simplifies the model and immediately places the trade-off computation problem within NP. Unfortunately, we show that even this restricted version is NP-complete. Finally, we show that the trade-off problem parameterized by the number of transitions is W[1]-hard, meaning that there is likely no algorithm running in a fixed polynomial for constant number of transitions.},
author = {Demaine, Erik D. and Liu, Quanquan C.},
booktitle = {Annual ACM Symposium on Parallelism in Algorithms and Architectures},
doi = {10.1145/3210377.3210387},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Demaine, Liu - 2018 - Red-blue pebble game Complexity of computing the trade-off between cache size and memory transfers.pdf:pdf},
isbn = {9781450357999},
keywords = {Computational complexity,External memory model,Red-blue pebble game},
pages = {195--204},
title = {{Red-blue pebble game: Complexity of computing the trade-off between cache size and memory transfers}},
year = {2018}
}
@article{Scquizzato2013,
abstract = {We give lower bounds on the communication complexity required to solve several computational problems in a distributed-memory parallel machine, namely standard matrix multiplication, stencil computations, comparison sorting, and the Fast Fourier Transform. We revisit the assumptions under which preceding results were derived and provide new lower bounds which use much weaker and appropriate hypotheses. Our bounds rely on a mild assumption on work distribution, and strengthen previous results which require either the computation to be balanced among the processors, or specific initial distributions of the input data, or an upper bound on the size of processors' local memories.},
archivePrefix = {arXiv},
arxivId = {1307.1805},
author = {Scquizzato, Michele and Silvestri, Francesco},
eprint = {1307.1805},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Scquizzato, Silvestri - 2013 - Communication Lower Bounds for Distributed-Memory Computations.pdf:pdf},
keywords = {aldo gini,bsp,by the university of,communication,cpda121378,department of computer science,distributed memory,e-mail,edu,fondazione ing,in part,italy,lower bounds,most of this work,pa 15260,padova projects stpd08ja32 and,parallel algorithms,pitt,pittsburgh,scquizza,ship of,supported by a fellow-,this work was supported,university of padova,university of pittsburgh,usa},
pages = {1--21},
title = {{Communication Lower Bounds for Distributed-Memory Computations}},
url = {http://arxiv.org/abs/1307.1805},
year = {2013}
}
@article{Mayer2020,
abstract = {Deep Learning (DL) has had an immense success in the recent past, leading to state-of-the-art results in various domains, such as image recognition and natural language processing. One of the reasons for this success is the increasing size of DL models and the proliferation of vast amounts of training data being available. To keep on improving the performance of DL, increasing the scalability of DL systems is necessary. In this survey, we perform a broad and thorough investigation on challenges, techniques and tools for scalable DL on distributed infrastructures. This incorporates infrastructures for DL, methods for parallel DL training, multi-tenant resource scheduling, and the management of training and model data. Further, we analyze and compare 11 current open-source DL frameworks and tools and investigate which of the techniques are commonly implemented in practice. Finally, we highlight future research trends in DL systems that deserve further research.},
archivePrefix = {arXiv},
arxivId = {1903.11314},
author = {Mayer, Ruben and Jacobsen, Hans Arno},
doi = {10.1145/3363554},
eprint = {1903.11314},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mayer, Jacobsen - 2020 - Scalable deep learning on distributed infrastructures Challenges, techniques, and tools.pdf:pdf},
issn = {15577341},
journal = {ACM Computing Surveys},
keywords = {Deep-learning systems},
number = {1},
title = {{Scalable deep learning on distributed infrastructures: Challenges, techniques, and tools}},
volume = {53},
year = {2020}
}
@article{Valiant1990,
author = {Valiant, Leslie},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Valiant - 1990 - Leslie 6. Valiant 103.pdf:pdf},
journal = {Communications of the ACM},
number = {8},
title = {{Leslie 6. Valiant 103}},
volume = {33},
year = {1990}
}
@article{Samavatian2018,
abstract = {Recurrent Neural Networks (RNNs) are an important class of neural networks designed to retain and incorporate context into current decisions. RNNs are particularly well suited for machine learning problems in which context is important, such as speech recognition or language translation. This work presents RNNFast, a hardware accelerator for RNNs that leverages an emerging class of non-volatile memory called domain-wall memory (DWM). We show that DWM is very well suited for RNN acceleration due to its very high density and low read/write energy. At the same time, the sequential nature of input/weight processing of RNNs mitigates one of the downsides of DWM, which is the linear (rather than constant) data access time. RNNFast is very efficient and highly scalable, with flexible mapping of logical neurons to RNN hardware blocks. The basic hardware primitive, the RNN processing element (PE) includes custom DWM-based multiplication, sigmoid and tanh units for high density and low-energy. The accelerator is designed to minimize data movement by closely interleaving DWM storage and computation. We compare our design with a state-of-the-art GPGPU and find 21.8x better performance with 70x lower energy.},
archivePrefix = {arXiv},
arxivId = {1812.07609},
author = {Samavatian, Mohammad Hossein and Bacha, Anys and Zhou, Li and Teodorescu, Radu},
eprint = {1812.07609},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Samavatian et al. - 2018 - RNNFast An Accelerator for Recurrent Neural Networks Using Domain Wall Memory.pdf:pdf},
title = {{RNNFast: An Accelerator for Recurrent Neural Networks Using Domain Wall Memory}},
url = {http://arxiv.org/abs/1812.07609},
year = {2018}
}
@article{Shamir2016,
abstract = {We consider the problem of principal component analysis (PCA) in a streaming stochastic setting, where our goal is to find a direction of approximate maximal variance, based on a stream of i.i.d. data points in Rd. A simple and computationally cheap algorithm for this is stochastic gradient descent (SGD), which incrementally updates its estimate based on each new data point. However, due to the non-convex nature of the problem, analyzing its performance has been a challenge. In particular, existing guarantees rely on a non-trivial eigengap assumption on the covariance matrix, which is intuitively unnecessary. In this paper, we provide (to the best of our knowledge) the first eigengap-free convergence guarantees for SGD in the context of PCA. This also partially resolves an open problem posed in (Hardt & Price, #y2014). Moreover, under an eigengap assumption, we show that the same techniques lead to new SGD convergence guarantees with better dependence on the eigengap.},
archivePrefix = {arXiv},
arxivId = {1509.09002},
author = {Shamir, Ohad},
eprint = {1509.09002},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shamir - 2016 - Convergence of stochastic gradient descent for PCA.pdf:pdf},
isbn = {9781510829008},
journal = {33rd International Conference on Machine Learning, ICML 2016},
number = {1},
pages = {420--437},
title = {{Convergence of stochastic gradient descent for PCA}},
volume = {1},
year = {2016}
}
@article{Pillaud-Vivien2018,
abstract = {We consider stochastic gradient descent (SGD) for least-squares regression with potentially several passes over the data. While several passes have been widely reported to perform practically better in terms of predictive performance on unseen data, the existing theoretical analysis of SGD suggests that a single pass is statistically optimal. While this is true for low-dimensional easy problems, we show that for hard problems, multiple passes lead to statistically optimal predictions while single pass does not; we also show that in these hard models, the optimal number of passes over the data increases with sample size. In order to define the notion of hardness and show that our predictive performances are optimal, we consider potentially infinite-dimensional models and notions typically associated to kernel methods, namely, the decay of eigenvalues of the covariance matrix of the features and the complexity of the optimal predictor as measured through the covariance matrix. We illustrate our results on synthetic experiments with non-linear kernel methods and on a classical benchmark with a linear model.},
archivePrefix = {arXiv},
arxivId = {1805.10074},
author = {Pillaud-Vivien, Loucas and Rudi, Alessandro and Bach, Francis},
eprint = {1805.10074},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pillaud-Vivien, Rudi, Bach - 2018 - Statistical optimality of stochastic gradient descent on hard learning problems through multiple pas.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
pages = {8114--8124},
title = {{Statistical optimality of stochastic gradient descent on hard learning problems through multiple passes}},
volume = {2018-Decem},
year = {2018}
}
@phdthesis{Elango2016,
abstract = {The execution cost of a program, both in terms of time and energy, comprises computational cost and data movement cost (e.g., cost of transferring data between CPU and memory devices, between parallel processors, etc.). Technology trends will cause data movement to account for the majority of energy expenditure and execution time on emerging computers. Therefore, computational complexity alone will no longer be a sufficient metric for comparing algorithms, and a fundamental characterization of data movement complexity will be increasingly important. In their seminal work, Hong & Kung proposed the red-blue pebble game to model the data movement complexity of algorithms. Using the pebble game abstraction, Hong & Kung proved tight asymptotic lower bounds for the data movement complexity of several algorithms by reformulating the problem as a graph partitioning problem. In this dissertation, we develop a novel alternate graph min-cut based lower bounding technique. Using our technique, we derive tight lower bounds for different algorithms, with upper bounds matching within a constant factor. Further, we develop a dynamic analysis based automated heuristic for our technique, which enables automatic analysis of arbitrary computations. We provide several use cases for our automated approach. This dissertation also presents a technique, built upon the ideas of Christ et al., to derive asymptotic parametric lower bounds for a sub-class of computations, called affine computations. A static analysis based heuristic to automatically derive parametric lower bounds for affine parts of the computations is also presented. Motivated by the emerging interest in large scale parallel systems with interconnection networks and hierarchical caches with varying bandwidths at different levels, we extend the pebble game model to parallel system architecture to characterize the data movement requirements in large scale parallel computers. We provide interesting insights on architectural bottlenecks that limit the performance of algorithms on these parallel machines. Finally, using data movement complexity analysis, in conjunction with the roofline model for performance bounds, we perform an algorithm-architecture codesign exploration across an architectural design space. We model the maximal achievable performance and energy efficiency of different algorithms for a given VLSI technology, considering different architectural parameters.},
author = {Elango, Venmugil},
booktitle = {PhD Thesis, The Ohio State University},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elango - 2016 - Techniques for Characterizing the Data Movement Complexity of Computations.pdf:pdf},
isbn = {9781369005363},
keywords = {0984:Computer science,Applied sciences,Computer science,Data access complexity,Data movement complexity,High-performance computing,Io complexity,Lower bounds,Red-blue pebble game},
pages = {186},
title = {{Techniques for Characterizing the Data Movement Complexity of Computations}},
url = {https://search.proquest.com/docview/1828891570?accountid=45153},
year = {2016}
}
@article{Meyerhenke2017,
abstract = {Processing large complex networks like social networks or web graphs has attracted considerable interest. To do this in parallel, we need to partition them into pieces of roughly equal size. Unfortunately, previous parallel graph partitioners originally developed for more regular mesh-like networks do not work well for complex networks. Here we address this problem by parallelizing and adapting the label propagation technique originally developed for graph clustering. By introducing size constraints, label propagation becomes applicable for both the coarsening and the refinement phase of multilevel graph partitioning. This way we exploit the hierarchical cluster structure present in many complex networks. We obtain very high quality by applying a highly parallel evolutionary algorithm to the coarsest graph. The resulting system is both more scalable and achieves higher quality than state-of-The-Art systems like ParMetis or PT-Scotch. For large complex networks the performance differences are very big. As an example, our algorithm partitions a web graph with 3.3 G edges in 16 seconds using 512 cores of a high-performance cluster while producing a high quality partition-none of the competing systems can handle this graph on our system.},
archivePrefix = {arXiv},
arxivId = {1404.4797},
author = {Meyerhenke, Henning and Sanders, Peter and Schulz, Christian},
doi = {10.1109/TPDS.2017.2671868},
eprint = {1404.4797},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meyerhenke, Sanders, Schulz - 2017 - Parallel Graph Partitioning for Complex Networks.pdf:pdf},
issn = {10459219},
journal = {IEEE Transactions on Parallel and Distributed Systems},
keywords = {Load balancing and task assignment,algorithm design and analysis,combinatorial algorithms,graph algorithms},
number = {9},
pages = {2625--2638},
title = {{Parallel Graph Partitioning for Complex Networks}},
volume = {28},
year = {2017}
}
@article{Sanders2015,
abstract = {Parallel algorithms have been a subject of intensive algorithmic research in the 1980s. This research almost died out in the mid 1990s. In this paper we argue that it is high time to reconsider this subject since a lot of things have changed. First and foremost, parallel processing has moved from a niche application to something mandatory for any performance critical computer applications. We will also point out that even very fundamental results can still be obtained. We give examples and also formulate some open problems.},
author = {Sanders, Peter},
doi = {10.4230/LIPIcs.STACS.2015.10},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sanders - 2015 - Parallel algorithms reconsidered.pdf:pdf},
isbn = {9783939897781},
issn = {18688969},
journal = {Leibniz International Proceedings in Informatics, LIPIcs},
keywords = {Algorithm engineering,Communication efficient algorithm,Parallel algorithm,Parallel machine model,Polylogarithmic time algorithm},
number = {Stacs},
pages = {10--18},
title = {{Parallel algorithms reconsidered}},
volume = {30},
year = {2015}
}
@article{Multiprocessors2008,
author = {Multiprocessors, Private-cache Chip and Arge, Lars and Goodrich, Michael T},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Multiprocessors, Arge, Goodrich - 2008 - Fundamental Parallel Algorithms for.pdf:pdf},
isbn = {9781595939739},
keywords = {parallel external memory,pem,private-cache cmp},
pages = {197--206},
title = {{Fundamental Parallel Algorithms for}},
year = {2008}
}
@article{Aggarwal1988,
abstract = {We provide tight upper and lower bounds, up to a constant factor, for the number of inputs and outputs (I/OS) between internal memory and secondary storage required for five sorting-related problems: sorting, the fast Fourier transform (FFT), permutation networks, permuting, and matrix transposition. The bounds hold both in the worst case and in the average case, and in several situations the constant factors match. Secondary storage is modeled as a magnetic disk capable of transferring P blocks each containing B records in a single time unit; the records in each block must be input from or output to B contiguous locations on the disk. We give two optimal algorithms for the problems, which are variants of merge sorting and distribution sorting. In particular we show for P = 1 that the standard merge sorting algorithm is an optimal external sorting method, up to a constant factor in the number of I/Os. Our sorting algorithms use the same number of I/Os as does the permutation phase of key sorting, except when the internal memory size is extremely small, thus affirming the popular adage that key sorting is not faster. We also give a simpler and more direct derivation of Hong and Kung's lower bound for the FFT for the special case B = P = O(1). {\textcopyright} 1988, ACM. All rights reserved.},
author = {Aggarwal, Alok and Vitter, Jeffrey S.},
doi = {10.1145/48529.48535},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aggarwal, Vitter - 1988 - The InputOutput Complexity of Sorting and Related Problems.pdf:pdf},
issn = {15577317},
journal = {Communications of the ACM},
keywords = {Distribution sort,fast Fourier transform,input,magnetic disk,merge sort,networks,output,pebbling,secondary storage,sorting},
number = {9},
pages = {1116--1127},
title = {{The Input/Output Complexity of Sorting and Related Problems}},
volume = {31},
year = {1988}
}
@article{Grover2016,
abstract = {Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state of-the-art task-independent representations in complex networks.},
archivePrefix = {arXiv},
arxivId = {1607.00653},
author = {Grover, Aditya and Leskovec, Jure},
doi = {10.1145/2939672.2939754},
eprint = {1607.00653},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grover, Leskovec - 2016 - Node2vec Scalable feature learning for networks.pdf:pdf},
isbn = {9781450342322},
journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
keywords = {Feature learning,Graph representations,Information networks,Node embeddings},
pages = {855--864},
title = {{Node2vec: Scalable feature learning for networks}},
volume = {13-17-Augu},
year = {2016}
}
@article{Perozzi2014,
abstract = {We present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. DeepWalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate DeepWalk's latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that DeepWalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. DeepWalk's representations can provide F1 scores up to 10% higher than competing methods when labeled data is sparse. In some experiments, DeepWalk's representations are able to outperform all baseline methods while using 60% less training data. DeepWalk is also scalable. It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. These qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection. {\textcopyright} 2014 ACM.},
archivePrefix = {arXiv},
arxivId = {1403.6652},
author = {Perozzi, Bryan and Al-Rfou, Rami and Skiena, Steven},
doi = {10.1145/2623330.2623732},
eprint = {1403.6652},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perozzi, Al-Rfou, Skiena - 2014 - DeepWalk Online learning of social representations.pdf:pdf},
isbn = {9781450329569},
journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
keywords = {deep learning,latent representations,learning with partial labels,network classification,online learning,social networks},
pages = {701--710},
title = {{DeepWalk: Online learning of social representations}},
year = {2014}
}
@article{Schaffter2011,
abstract = {Motivation: Over the last decade, numerous methods have been developed for inference of regulatory networks from gene expression data. However, accurate and systematic evaluation of these methods is hampered by the difficulty of constructing adequate benchmarks and the lack of tools for a differentiated analysis of network predictions on such benchmarks.Results: Here, we describe a novel and comprehensive method for in silico benchmark generation and performance profiling of network inference methods available to the community as an open-source software called GeneNetWeaver (GNW). In addition to the generation of detailed dynamical models of gene regulatory networks to be used as benchmarks, GNW provides a network motif analysis that reveals systematic prediction errors, thereby indicating potential ways of improving inference methods. The accuracy of network inference methods is evaluated using standard metrics such as precision-recall and receiver operating characteristic curves. We show how GNW can be used to assess the performance and identify the strengths and weaknesses of six inference methods. Furthermore, we used GNW to provide the international Dialogue for Reverse Engineering Assessments and Methods (DREAM) competition with three network inference challenges (DREAM3, DREAM4 and DREAM5). {\textcopyright} The Author 2011. Published by Oxford University Press. All rights reserved.},
author = {Schaffter, Thomas and Marbach, Daniel and Floreano, Dario},
doi = {10.1093/bioinformatics/btr373},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schaffter, Marbach, Floreano - 2011 - GeneNetWeaver In silico benchmark generation and performance profiling of network inference method.pdf:pdf},
issn = {13674803},
journal = {Bioinformatics},
number = {16},
pages = {2263--2270},
title = {{GeneNetWeaver: In silico benchmark generation and performance profiling of network inference methods}},
volume = {27},
year = {2011}
}
@article{Yuan2019,
author = {Yuan, Ye and Bar-joseph, Ziv},
doi = {10.1073/pnas.1911536116},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuan, Bar-joseph - 2019 - Deep learning for inferring gene relationships from single-cell expression data.pdf:pdf},
title = {{Deep learning for inferring gene relationships from single-cell expression data}},
year = {2019}
}
@article{Pratapa,
author = {Pratapa, Aditya and Jalihal, Amogh P and Law, Jeffrey N and Bharadwaj, Aditya and Murali, T M},
doi = {10.1038/s41592-019-0690-6},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pratapa et al. - Unknown - Benchmarking algorithms for gene regulatory network inference from single-cell transcriptomic data.pdf:pdf},
issn = {1548-7105},
journal = {Nature Methods},
publisher = {Springer US},
title = {{Benchmarking algorithms for gene regulatory network inference from single-cell transcriptomic data}},
url = {http://dx.doi.org/10.1038/s41592-019-0690-6}
}
@article{Ni2016,
abstract = {Gene regulatory networks (GRNs) provide a representation of relationships between regulators and their target genes. Several methods for GRNinference, both unsupervised and supervised, have been developed to date. Because regulatory relationships consistently reprogram in diverse tissues or under different conditions, GRNs inferred without specific biological contexts are of limited applicability. In this report, a machine learning approach is presented to predict GRNs specific to developing Arabidopsis thaliana embryos. We developed the Beacon GRN inference tool to predict GRNs occurring during seed development in Arabidopsis based on a support vector machine (SVM) model. We developed both global and local inference models and compared their performance, demonstrating that local models are generally superior for our application. Using both the expression levels of the genes expressed in developing embryos and prior known regulatory relationships, GRNs were predicted for specific embryonic developmental stages. The targets that are strongly positively correlated with their regulators are mostly expressed at the beginning of seed development. Potential direct targets were identified based on a match between the promoter regions of these inferred targets and the cis elements recognized by specific regulators. Our analysis also provides evidence for previously unknown inhibitory effects of three positive regulators of gene expression. The Beacon GRN inference tool provides a valuable model system for context-specific GRN inference and is freely available at https://github.com/BeaconProjectAtVirginiaTech/beacon_network_inference.git.},
author = {Ni, Ying and Aghamirzaie, Delasa and Elmarakeby, Haitham and Collakova, Eva and Li, Song and Grene, Ruth and Heath, Lenwood S.},
doi = {10.3389/fpls.2016.01936},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ni et al. - 2016 - A machine learning approach to predict gene regulatory networks in seed development in Arabidopsis.pdf:pdf},
issn = {1664462X},
journal = {Frontiers in Plant Science},
keywords = {Arabidopsis,Binding site,Cluster,Gene expression,Gene regulatory network,Support vector machines},
number = {DECEMBER2016},
title = {{A machine learning approach to predict gene regulatory networks in seed development in Arabidopsis}},
volume = {7},
year = {2016}
}
@article{Serin2016,
abstract = {Plants are fascinating and complex organisms. A comprehensive understanding of the organization, function and evolution of plant genes is essential to disentangle important biological processes and to advance crop engineering and breeding strategies. The ultimate aim in deciphering complex biological processes is the discovery of causal genes and regulatory mechanisms controlling these processes. The recent surge of omics data has opened the door to a system-wide understanding of the flow of biological information underlying complex traits. However, dealing with the corresponding large data sets represents a challenging endeavor that calls for the development of powerful bioinformatics methods. A popular approach is the construction and analysis of gene networks. Such networks are often used for genome-wide representation of the complex functional organization of biological systems. Network based on similarity in gene expression are called (gene) co-expression networks. One of the major application of gene co-expression networks is the functional annotation of unknown genes. Constructing co-expression networks is generally straightforward. In contrast, the resulting network of connected genes can become very complex, which limits its biological interpretation. Several strategies can be employed to enhance the interpretation of the networks. A strategy in coherence with the biological question addressed needs to be established to infer reliable networks. Additional benefits can be gained from network-based strategies using prior knowledge and data integration to further enhance the elucidation of gene regulatory relationships. As a result, biological networks provide many more applications beyond the simple visualization of co-expressed genes. In this study we review the different approaches for co-expression network inference in plants. We analyse integrative genomics strategies used in recent studies that successfully identified candidate genes taking advantage of gene co-expression networks. Additionally, we discuss promising bioinformatics approaches that predict networks for specific purposes.},
author = {Serin, Elise A.R. and Nijveen, Harm and Hilhorst, Henk W.M. and Ligterink, Wilco},
doi = {10.3389/fpls.2016.00444},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Serin et al. - 2016 - Learning from co-expression networks Possibilities and challenges.pdf:pdf},
issn = {1664462X},
journal = {Frontiers in Plant Science},
keywords = {Co-expression,Gene expression,Gene networks,Gene prioritization,Transcriptomics},
number = {APR2016},
pages = {1--18},
title = {{Learning from co-expression networks: Possibilities and challenges}},
volume = {7},
year = {2016}
}
@article{Mochida2018,
abstract = {Statistical and machine learning (ML)-based methods have recently advanced in construction of gene regulatory network (GRNs) based on high-throughput biological datasets. GRNs underlie almost all cellular phenomena; hence, comprehensive GRN maps are essential tools to elucidate gene function, thereby facilitating the identification and prioritization of candidate genes for functional analysis. High-throughput gene expression datasets have yielded various statistical and ML-based algorithms to infer causal relationship between genes and decipher GRNs. This review summarizes the recent advancements in the computational inference of GRNs, based on large-scale transcriptome sequencing datasets of model plants and crops. We highlight strategies to select contextual genes for GRN inference, and statistical and ML-based methods for inferring GRNs based on transcriptome datasets from plants. Furthermore, we discuss the challenges and opportunities for the elucidation of GRNs based on large-scale datasets obtained from emerging transcriptomic applications, such as from population-scale, single-cell level, and life-course transcriptome analyses.},
author = {Mochida, Keiichi and Koda, Satoru and Inoue, Komaki and Nishii, Ryuei},
doi = {10.3389/fpls.2018.01770},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mochida et al. - 2018 - Statistical and machine learning approaches to predict gene regulatory networks from transcriptome datasets.pdf:pdf},
issn = {1664462X},
journal = {Frontiers in Plant Science},
keywords = {Gene regulatory network,Machine learning,Sparse modeling,Time series analysis,Transcriptome},
number = {November},
pages = {1--7},
title = {{Statistical and machine learning approaches to predict gene regulatory networks from transcriptome datasets}},
volume = {871},
year = {2018}
}
@inproceedings{Pan2018,
abstract = {The vulnerability of interdependent networks has recently drawn much attention, especially in the key infrastructure networks such as power and communication networks. However, the existing works mainly considered a single cascade model across the networks and there is a need for more accurate models and analysis. In this paper, we focus on the interdependent power/communication networks to accurately analyze their vulnerability by considering heterogeneous cascade models. Accurately analyzing interdependent networks is challenging as the cascades are heterogeneous yet interdependent. Also, including multiple timescales into the context can further increase the complexity. To better depict the vulnerability of interdependent networks, we first propose a method to learn a threshold model from historical data to characterize the cascades in the power network and alleviate the need of calculating complicated power network dynamics. Next, we introduce message passing equations to generalize the threshold model in the power network and the percolation model in the communication network, based on which we derive efficient solution for finding the most critical nodes in the interdependent networks. Removing the most critical nodes can cause the largest cascade and thus characterizes the vulnerability. We evaluate the performance of the proposed methods in various datasets and discuss how network parameters, such as the timescales, can impact the vulnerability.},
author = {Pan, Tianyi and Kuhnle, Alan and Li, Xiang and Thai, My T.},
booktitle = {International Conference on Distributed Computing Systems (ICDCS)},
doi = {10.1109/ICDCS.2018.00037},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pan et al. - 2018 - Vulnerability of interdependent networks with heterogeneous cascade models and timescales.pdf:pdf},
isbn = {9781538668719},
keywords = {Heterogeneous Cascade Models,Interdependent Networks,Vulnerability Analysis},
publisher = {IEEE},
title = {{Vulnerability of interdependent networks with heterogeneous cascade models and timescales}},
year = {2018}
}
@article{Fletcher2013,
abstract = {The fibroblast growth factor receptor 2 (FGFR2) locus has been consistently identified as a breast cancer risk locus in independent genome-wide association studies. However, the molecular mechanisms underlying FGFR2-mediated risk are still unknown. Using model systems we show that FGFR2-regulated genes are preferentially linked to breast cancer risk loci in expression quantitative trait loci analysis, supporting the concept that risk genes cluster in pathways. Using a network derived from 2,000 transcriptional profiles we identify SPDEF, ER$\alpha$, FOXA1, GATA3 and PTTG1 as master regulators of fibroblast growth factor receptor 2 signalling, and show that ER$\alpha$ occupancy responds to fibroblast growth factor receptor 2 signalling. Our results indicate that ER$\alpha$, FOXA1 and GATA3 contribute to the regulation of breast cancer susceptibility genes, which is consistent with the effects of anti-oestrogen treatment in breast cancer prevention, and suggest that fibroblast growth factor receptor 2 signalling has an important role in mediating breast cancer risk. {\textcopyright} 2013 Macmillan Publishers Limited. All rights reserved.},
author = {Fletcher, Michael N.C. and Castro, Mauro A.A. and Wang, Xin and {De Santiago}, Ines and O'Reilly, Martin and Chin, Suet Feung and Rueda, Oscar M. and Caldas, Carlos and Ponder, Bruce A.J. and Markowetz, Florian and Meyer, Kerstin B.},
doi = {10.1038/ncomms3464},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fletcher et al. - 2013 - Master regulators of FGFR2 signalling and breast cancer risk.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
number = {May},
pages = {1--12},
title = {{Master regulators of FGFR2 signalling and breast cancer risk}},
volume = {4},
year = {2013}
}
@article{Castro2015,
abstract = {Genetic risk for breast cancer is conferred by a combination of multiple variants of small effect. To better understand how risk loci might combine, we examined whether risk-associated genes share regulatory mechanisms. We created a breast cancer gene regulatory network comprising transcription factors and groups of putative target genes (regulons) and asked whether specific regulons are enriched for genes associated with risk loci via expression quantitative trait loci (eQTLs). We identified 36 overlapping regulons that were enriched for risk loci and formed a distinct cluster within the network, suggesting shared biology. The risk transcription factors driving these regulons are frequently mutated in cancer and lie in two opposing subgroups, which relate to estrogen receptor (ER) + luminal A or luminal B and ER {\^{a}} 'irc;' basal-like cancers and to different luminal epithelial cell populations in the adult mammary gland. Our network approach provides a foundation for determining the regulatory circuits governing breast cancer, to identify targets for intervention, and is transferable to other disease settings.},
author = {Castro, Mauro A.A. and {De Santiago}, Ines and Campbell, Thomas M. and Vaughn, Courtney and Hickey, Theresa E. and Ross, Edith and Tilley, Wayne D. and Markowetz, Florian and Ponder, Bruce A.J. and Meyer, Kerstin B.},
doi = {10.1038/ng.3458},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Castro et al. - 2015 - Regulators of genetic risk of breast cancer identified by integrative network analysis.pdf:pdf},
issn = {15461718},
journal = {Nature Genetics},
number = {1},
pages = {12--21},
publisher = {Nature Publishing Group},
title = {{Regulators of genetic risk of breast cancer identified by integrative network analysis}},
volume = {48},
year = {2015}
}
@article{Algorithm2020,
author = {Algorithm, Fast Evolutionary and Functions, Cardinality-constrained Weakly Submodular},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Algorithm, Functions - 2020 - Cover Letter.pdf:pdf},
title = {{Cover Letter}},
year = {2020}
}
@article{Huang2018,
abstract = {Background: Transcription factors (TFs) are proteins that can bind to DNA sequences and regulate gene expression. Many TFs are master regulators in cells that contribute to tissue-specific and cell-type-specific gene expression patterns in eukaryotes. Maize has been a model organism for over one hundred years, but little is known about its tissue-specific gene regulation through TFs. In this study, we used a network approach to elucidate gene regulatory networks (GRNs) in four tissues (leaf, root, SAM and seed) in maize. We utilized GENIE3, a machine-learning algorithm combined with large quantity of RNA-Seq expression data to construct four tissue-specific GRNs. Unlike some other techniques, this approach is not limited by high-quality Position Weighed Matrix (PWM), and can therefore predict GRNs for over 2000 TFs in maize. Results: Although many TFs were expressed across multiple tissues, a multi-tiered analysis predicted tissue-specific regulatory functions for many transcription factors. Some well-studied TFs emerged within the four tissue-specific GRNs, and the GRN predictions matched expectations based upon published results for many of these examples. Our GRNs were also validated by ChIP-Seq datasets (KN1, FEA4 and O2). Key TFs were identified for each tissue and matched expectations for key regulators in each tissue, including GO enrichment and identity with known regulatory factors for that tissue. We also found functional modules in each network by clustering analysis with the MCL algorithm. Conclusions: By combining publicly available genome-wide expression data and network analysis, we can uncover GRNs at tissue-level resolution in maize. Since ChIP-Seq and PWMs are still limited in several model organisms, our study provides a uniform platform that can be adapted to any species with genome-wide expression data to construct GRNs. We also present a publicly available database, maize tissue-specific GRN (mGRN, https://www.bio.fsu.edu/mcginnislab/mgrn/ ), for easy querying. All source code and data are available at Github ( https://github.com/timedreamer/maize_tissue-specific_GRN ).},
author = {Huang, Ji and Zheng, Juefei and Yuan, Hui and McGinnis, Karen},
doi = {10.1186/s12870-018-1329-y},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2018 - Distinct tissue-specific transcriptional regulation revealed by gene regulatory networks in maize.pdf:pdf},
issn = {14712229},
journal = {BMC Plant Biology},
keywords = {Bioinformatics,Database,Gene expression,Machine learning,Maize,Network,Systems biology,Transcription factor,Transcriptional regulation},
number = {1},
pages = {1--14},
publisher = {BMC Plant Biology},
title = {{Distinct tissue-specific transcriptional regulation revealed by gene regulatory networks in maize}},
volume = {18},
year = {2018}
}
@article{Xiong2017,
abstract = {The complex interactions between transcription factors (TFs) and their target genes in a spatially and temporally specific manner are crucial to all cellular processes. Reconstruction of gene regulatory networks (GRNs) from gene expression profiles can help to decipher TF-gene regulations in a variety of contexts; however, the inevitable prediction errors of GRNs hinder optimal data mining of RNA-Seq transcriptome profiles. Here we perform an integrative study of Zea mays (maize) seed development in order to identify key genes in a complex developmental process. First, we reverse engineered a GRN from 78 maize seed transcriptome profiles. Then, we studied collective gene interaction patterns and uncovered highly interwoven network communities as the building blocks of the GRN. One community, composed of mostly unknown genes interacting with opaque2, brittle endosperm1 and shrunken2, contributes to seed phenotypes. Another community, composed mostly of genes expressed in the basal endosperm transfer layer, is responsible for nutrient transport. We further integrated our inferred GRN with gene expression patterns in different seed compartments and at various developmental stages and pathways. The integration facilitated a biological interpretation of the GRN. Our yeast one-hybrid assays verified six out of eight TF-promoter bindings in the reconstructed GRN. This study identified topologically important genes in interwoven network communities that may be crucial to maize seed development.},
author = {Xiong, Wenwei and Wang, Chunlei and Zhang, Xiangbo and Yang, Qinghua and Shao, Ruixin and Lai, Jinsheng and Du, Chunguang},
doi = {10.1111/tpj.13750},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiong et al. - 2017 - Highly interwoven communities of a gene regulatory network unveil topologically important genes for maize seed dev.pdf:pdf},
issn = {1365313X},
journal = {Plant Journal},
keywords = {Zea mays,gene regulatory network,maize seed development,mutual information,network community,network inference},
number = {6},
pages = {1143--1156},
title = {{Highly interwoven communities of a gene regulatory network unveil topologically important genes for maize seed development}},
volume = {92},
year = {2017}
}
@article{Kulkarni2019,
abstract = {Transcriptional regulation is a complex and dynamic process that plays a vital role in plant growth and development. A key component in the regulation of genes is transcription factors (TFs), which coordinate the transcriptional control of gene activity. A gene regulatory network (GRN) is a collection of regulatory interactions between TFs and their target genes. The accurate delineation of GRNs offers a significant contribution to our understanding about how plant cells are organized and function, and how individual genes are regulated in various conditions, organs or cell types. During the past decade, important progress has been made in the identification of GRNs using experimental and computational approaches. However, a detailed overview of available platforms supporting the analysis of GRNs in plants is missing. Here, we review current databases, platforms and tools that perform data-driven analyses of gene regulation in Arabidopsis. The platforms are categorized into two sections, 1) promoter motif analysis tools that use motif mapping approaches to find TF motifs in the regulatory sequences of genes of interest and 2) network analysis tools that identify potential regulators for a set of input genes using a range of data types in order to generate GRNs. We discuss the diverse datasets integrated and highlight the strengths and caveats of different platforms. Finally, we shed light on the limitations of the above approaches and discuss future perspectives, including the need for integrative approaches to unravel complex GRNs in plants.},
author = {Kulkarni, Shubhada R and Vandepoele, Klaas},
doi = {https://doi.org/10.1016/j.bbagrm.2019.194447},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kulkarni, Vandepoele - 2019 - Inference of plant gene regulatory networks using data-driven methods A practical overview.pdf:pdf},
issn = {1874-9399},
journal = {Biochimica et Biophysica Acta (BBA) - Gene Regulatory Mechanisms},
keywords = {Network analysis,Plant gene regulatory networks,Promoter analysis,Systems biology},
number = {October},
pages = {194447},
publisher = {Elsevier},
title = {{Inference of plant gene regulatory networks using data-driven methods: A practical overview}},
url = {http://www.sciencedirect.com/science/article/pii/S1874939919302585},
year = {2019}
}
@article{Mercatelli2019,
abstract = {Transcriptional regulation is a fundamental molecular mechanism involved in almost every aspect of life, from homeostasis to development, from metabolism to behavior, from reaction to stimuli to disease progression. In recent years, the concept of Gene Regulatory Networks (GRNs) has grown popular as an effective applied biology approach for describing the complex and highly dynamic set of transcriptional interactions, due to its easy-to-interpret features. Since cataloguing, predicting and understanding every GRN connection in all species and cellular contexts remains a great challenge for biology, researchers have developed numerous tools and methods to infer regulatory processes. In this review, we catalogue these methods in six major areas, based on the dominant underlying information leveraged to infer GRNs: Coexpression, Sequence Motifs, Chromatin Immunoprecipitation (ChIP), Orthology, Literature and Protein-Protein Interaction (PPI) specifically focused on transcriptional complexes. The methods described here cover a wide range of user-friendliness: from web tools that require no prior computational expertise to command line programs and algorithms for large scale GRN inferences. Each method for GRN inference described herein effectively illustrates a type of transcriptional relationship, with many methods being complementary to others. While a truly holistic approach for inferring and displaying GRNs remains one of the greatest challenges in the field of systems biology, we believe that the integration of multiple methods described herein provides an effective means with which experimental and computational biologists alike may obtain the most complete pictures of transcriptional relationships. This article is part of a Special Issue entitled: Transcriptional Profiles and Regulatory Gene Networks edited by Dr. Dr. Federico Manuel Giorgi and Dr. Shaun Mahony.},
author = {Mercatelli, D. and Scalambra, L. and Triboli, L. and Ray, F. and Giorgi, F.M.},
doi = {10.1016/J.BBAGRM.2019.194430},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mercatelli et al. - 2019 - Gene regulatory network inference resources A practical overview.pdf:pdf},
issn = {1874-9399},
journal = {Biochimica et Biophysica Acta (BBA) - Gene Regulatory Mechanisms},
number = {May},
pages = {194430},
publisher = {Elsevier},
title = {{Gene regulatory network inference resources: A practical overview}},
url = {https://www.sciencedirect.com/science/article/pii/S1874939919300410},
year = {2019}
}
@article{Banf2017,
abstract = {Gene regulatory networks lie at the core of cell function control. In E. coli and S. cerevisiae, the study of gene regulatory networks has led to the discovery of regulatory mechanisms responsible for the control of cell growth, differentiation and responses to environmental stimuli. In plants, computational rendering of gene regulatory networks is gaining momentum, thanks to the recent availability of high-quality genomes and transcriptomes and development of computational network inference approaches. Here, we review current techniques, challenges and trends in gene regulatory network inference and highlight challenges and opportunities for plant science. We provide plant-specific application examples to guide researchers in selecting methodologies that suit their particular research questions. Given the interdisciplinary nature of gene regulatory network inference, we tried to cater to both biologists and computer scientists to help them engage in a dialogue about concepts and caveats in network inference. Specifically, we discuss problems and opportunities in heterogeneous data integration for eukaryotic organisms and common caveats to be considered during network model evaluation. This article is part of a Special Issue entitled: Plant Gene Regulatory Mechanisms and Networks, edited by Dr. Erich Grotewold and Dr. Nathan Springer.},
author = {Banf, Michael and Rhee, Seung Y.},
doi = {10.1016/j.bbagrm.2016.09.003},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Banf, Rhee - 2017 - Computational inference of gene regulatory networks Approaches, limitations and opportunities.pdf:pdf},
issn = {18764320},
journal = {Biochimica et Biophysica Acta - Gene Regulatory Mechanisms},
keywords = {Computational systems biology,Gene network evaluation,Gene regulatory network inference,Heterogeneous data integration,Machine learning},
number = {1},
pages = {41--52},
publisher = {Elsevier B.V.},
title = {{Computational inference of gene regulatory networks: Approaches, limitations and opportunities}},
url = {http://dx.doi.org/10.1016/j.bbagrm.2016.09.003},
volume = {1860},
year = {2017}
}
@article{Huang2017b,
abstract = {With the emergence of massively parallel sequencing, genomewide expression data production has reached an unprecedented level. This abundance of data has greatly facilitated maize research, but may not be amenable to traditional analysis techniques that were optimized for other data types. Using publicly available data, a gene coexpression network (GCN) can be constructed and used for gene function prediction, candidate gene selection, and improving understanding of regulatory pathways. Several GCN studies have been done in maize (Zea mays), mostly using microarray datasets. To build an optimal GCN from plant materials RNA-Seq data, parameters for expression data normalization and network inference were evaluated. A comprehensive evaluation of these two parameters and a ranked aggregation strategy on network performance, using libraries from 1266 maize samples, were conducted. Three normalization methods and 10 inference methods, including six correlation and four mutual information methods, were tested. The three normalization methods had very similar performance. For network inference, correlation methods performed better than mutual information methods at some genes. Increasing sample size also had a positive effect on GCN. Aggregating single networks together resulted in improved performance compared to single networks.},
author = {Huang, Ji and Vendramin, Stefania and Shi, Lizhen and McGinnis, Karen M.},
doi = {10.1104/pp.17.00825},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2017 - Construction and optimization of a large gene coexpression network in maize using RNA-seq data(2).pdf:pdf},
issn = {15322548},
journal = {Plant Physiology},
number = {1},
pages = {568--583},
title = {{Construction and optimization of a large gene coexpression network in maize using RNA-seq data}},
volume = {175},
year = {2017}
}
@inproceedings{Wu2019,
abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes and benchmarks of the existing algorithms on different learning tasks. Finally, we propose potential research directions in this rapidly growing field.},
archivePrefix = {arXiv},
arxivId = {1901.00596},
author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
booktitle = {arxiv preprint},
eprint = {1901.00596},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2019 - A Comprehensive Survey on Graph Neural Networks.pdf:pdf},
title = {{A Comprehensive Survey on Graph Neural Networks}},
url = {http://arxiv.org/abs/1901.00596},
year = {2019}
}
@techreport{Qiana,
abstract = {In this paper, we propose a new framework for designing fast parallel algorithms for fundamental statistical subset selection tasks that include feature selection and experimental design. Such tasks are known to be weakly submodular and are amenable to optimization via the standard greedy algorithm. Despite its desirable approximation guarantees, the greedy algorithm is inherently sequential and in the worst case, its parallel runtime is linear in the size of the data. Recently, there has been a surge of interest in a parallel optimization technique called adaptive sampling which produces solutions with desirable approximation guarantees for submodular maximization in exponentially faster parallel runtime. Unfortunately, we show that for general weakly submodular functions such accelerations are impossible. The major contribution in this paper is a novel relaxation of submod-ularity which we call differential submodularity. We first prove that differential submodularity characterizes objectives like feature selection and experimental design. We then design an adaptive sampling algorithm for differentially submodular functions whose parallel runtime is logarithmic in the size of the data and achieves strong approximation guarantees. Through experiments, we show the algorithm's performance is competitive with state-of-the-art methods and obtains dramatic speedups for feature selection and experimental design problems.},
author = {Qian, Sharon and Singer, Yaron},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qian, Singer - Unknown - Fast Parallel Algorithms for Statistical Subset Selection Problems.pdf:pdf},
title = {{Fast Parallel Algorithms for Statistical Subset Selection Problems}}
}
@techreport{Mitrovic,
abstract = {In many machine learning applications, one needs to interactively select a sequence of items (e.g., recommending movies based on a user's feedback) or make sequential decisions in a certain order (e.g., guiding an agent through a series of states). Not only do sequences already pose a dauntingly large search space, but we must also take into account past observations, as well as the uncertainty of future outcomes. Without further structure, finding an optimal sequence is notoriously challenging, if not completely intractable. In this paper, we view the problem of adaptive and sequential decision making through the lens of submodularity and propose an adaptive greedy policy with strong theoretical guarantees. Additionally, to demonstrate the practical utility of our results, we run experiments on Amazon product recommendation and Wikipedia link prediction tasks.},
author = {Mitrovic, Marko and Kazemi, Ehsan and Feldman, Moran and Krause, Andreas and Z{\"{u}}rich, Eth and Karbasi, Amin},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitrovic et al. - Unknown - Adaptive Sequence Submodularity.pdf:pdf},
title = {{Adaptive Sequence Submodularity}}
}
@techreport{Hassani,
abstract = {In this paper, we develop Stochastic Continuous Greedy++ (SCG++), the first efficient variant of a conditional gradient method for maximizing a continuous submodular function subject to a convex constraint. Concretely, for a monotone and continuous DR-submodular function, SCG++ achieves a tight [(1 − 1/e)OPT − ] solution while using O(1// 2) stochastic gradients and O(1//) calls to the linear optimization oracle. The best previously known algorithms either achieve a suboptimal [(1/2)OPT − ] solution with O(1// 2) stochastic gradients or the tight [(1 − 1/e)OPT − ] solution with suboptimal O(1// 3) stochastic gradients. We further provide an information-theoretic lower bound to showcase the necessity of O(1// 2) stochastic oracle queries in order to achieve [(1 − 1/e)OPT − ] for monotone and DR-submodular functions. This result shows that our proposed SCG++ enjoys optimality in terms of both approximation guarantee, i.e., (1−1/e) approximation factor, and stochastic gradient evaluations, i.e., O(1// 2) calls to the stochastic oracle. By using stochastic continuous optimization as an interface, we also show that it is possible to obtain the [(1 − 1/e)OPT − ] tight approximation guarantee for maximizing a monotone but stochastic submodular set function subject to a general matroid constraint after at most O(n 2 // 2) calls to the stochastic function value, where n is the number of elements in the ground set.},
author = {Hassani, Hamed and Karbasi, Amin and Mokhtari, Aryan and Shen, Zebang},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hassani et al. - Unknown - Stochastic Continuous Greedy When Upper and Lower Bounds Match.pdf:pdf},
title = {{Stochastic Continuous Greedy ++: When Upper and Lower Bounds Match *}}
}
@article{Ghorbani2019,
author = {Ghorbani, Behrooz and Misiakiewicz, Theodor and Mei, Song and Montanari, Andrea},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghorbani et al. - 2019 - Limitations of Lazy Training of Two-layers Neural Networks.pdf:pdf},
number = {1},
pages = {1--11},
title = {{Limitations of Lazy Training of Two-layers Neural Networks}},
volume = {2},
year = {2019}
}
@article{Net2019,
archivePrefix = {arXiv},
arxivId = {arXiv:1904.11955v2},
author = {Net, Neural},
eprint = {arXiv:1904.11955v2},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Net - 2019 - On Exact Computation with an Infinitely Wide.pdf:pdf},
number = {NeurIPS},
title = {{On Exact Computation with an Infinitely Wide}},
year = {2019}
}
@article{Gourdeau2019,
abstract = {It is becoming increasingly important to understand the vulnerability of machine learning models to adversarial attacks. In this paper we study the feasibility of robust learning from the perspective of computational learning theory, considering both sample and computational complexity. In particular, our definition of robust learnability requires polynomial sample complexity. We start with two negative results. We show that no non-trivial concept class can be robustly learned in the distribution-free setting against an adversary who can perturb just a single input bit. We show moreover that the class of monotone conjunctions cannot be robustly learned under the uniform distribution against an adversary who can perturb $\omega(\log n)$ input bits. However if the adversary is restricted to perturbing $O(\log n)$ bits, then the class of monotone conjunctions can be robustly learned with respect to a general class of distributions (that includes the uniform distribution). Finally, we provide a simple proof of the computational hardness of robust learning on the boolean hypercube. Unlike previous results of this nature, our result does not rely on another computational model (e.g. the statistical query model) nor on any hardness assumption other than the existence of a hard learning problem in the PAC framework.},
archivePrefix = {arXiv},
arxivId = {1909.05822},
author = {Gourdeau, Pascale and Kanade, Varun and Kwiatkowska, Marta and Worrell, James},
eprint = {1909.05822},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gourdeau et al. - 2019 - On the Hardness of Robust Classification.pdf:pdf},
number = {NeurIPS},
title = {{On the Hardness of Robust Classification}},
url = {http://arxiv.org/abs/1909.05822},
year = {2019}
}
@article{Cao2019,
abstract = {We study the training and generalization of deep neural networks (DNNs) in the over-parameterized regime, where the network width (i.e., number of hidden nodes per layer) is much larger than the number of training data points. We show that, the expected $0$-$1$ loss of a wide enough ReLU network trained with stochastic gradient descent (SGD) and random initialization can be bounded by the training loss of a random feature model induced by the network gradient at initialization, which we call a neural tangent random feature (NTRF) model. For data distributions that can be classified by NTRF model with sufficiently small error, our result yields a generalization error bound in the order of $\tilde{\mathcal{O}}(n^{-1/2})$ that is independent of the network width. Our result is more general and sharper than many existing generalization error bounds for over-parameterized neural networks. In addition, we establish a strong connection between our generalization error bound and the neural tangent kernel (NTK) proposed in recent work.},
archivePrefix = {arXiv},
arxivId = {1905.13210},
author = {Cao, Yuan and Gu, Quanquan},
eprint = {1905.13210},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cao, Gu - 2019 - Generalization Bounds of Stochastic Gradient Descent for Wide and Deep Neural Networks.pdf:pdf},
number = {NeurIPS},
title = {{Generalization Bounds of Stochastic Gradient Descent for Wide and Deep Neural Networks}},
url = {http://arxiv.org/abs/1905.13210},
year = {2019}
}
@article{Nagarajan2019,
author = {Nagarajan, Vaishnavh},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nagarajan - 2019 - Uniform convergence may be unable to explain generalization in deep learning.pdf:pdf},
number = {d},
title = {{Uniform convergence may be unable to explain generalization in deep learning}},
year = {2019}
}
@inproceedings{Ilyas2019,
author = {Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
booktitle = {Neural Information Processing Systems (NeurIPS)},
doi = {10.23915/distill.00019},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ilyas et al. - 2019 - Adversarial Examples Are Not Bugs, They Are Features.pdf:pdf;:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ilyas et al. - 2019 - Adversarial Examples Are Not Bugs, They Are Features(2).pdf:pdf},
title = {{Adversarial Examples Are Not Bugs, They Are Features}},
url = {https://gradientscience.org/adv/},
year = {2019}
}
@article{Mitchell2013,
abstract = {Respiratory infections stemming from influenza viruses and the Severe Acute Respiratory Syndrome corona virus (SARS-CoV) represent a serious public health threat as emerging pandemics. Despite efforts to identify the critical interactions of these viruses with host machinery, the key regulatory events that lead to disease pathology remain poorly targeted with therapeutics. Here we implement an integrated network interrogation approach, in which proteome and transcriptome datasets from infection of both viruses in human lung epithelial cells are utilized to predict regulatory genes involved in the host response. We take advantage of a novel "crowd-based" approach to identify and combine ranking metrics that isolate genes/proteins likely related to the pathogenicity of SARS-CoV and influenza virus. Subsequently, a multivariate regression model is used to compare predicted lung epithelial regulatory influences with data derived from other respiratory virus infection models. We predicted a small set of regulatory factors with conserved behavior for consideration as important components of viral pathogenesis that might also serve as therapeutic targets for intervention. Our results demonstrate the utility of integrating diverse 'omic datasets to predict and prioritize regulatory features conserved across multiple pathogen infection models.},
author = {Mitchell, Hugh D. and Eisfeld, Amie J. and Sims, Amy C. and McDermott, Jason E. and Matzke, Melissa M. and Webb-Robertson, Bobbi Jo M. and Tilton, Susan C. and Tchitchek, Nicolas and Josset, Laurence and Li, Chengjun and Ellis, Amy L. and Chang, Jean H. and Heegel, Robert A. and Luna, Maria L. and Schepmoes, Athena A. and Shukla, Anil K. and Metz, Thomas O. and Neumann, Gabriele and Benecke, Arndt G. and Smith, Richard D. and Baric, Ralph S. and Kawaoka, Yoshihiro and Katze, Michael G. and Waters, Katrina M.},
doi = {10.1371/journal.pone.0069374},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitchell et al. - 2013 - A Network Integration Approach to Predict Conserved Regulators Related to Pathogenicity of Influenza and SARS-C.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {7},
title = {{A Network Integration Approach to Predict Conserved Regulators Related to Pathogenicity of Influenza and SARS-CoV Respiratory Viruses}},
volume = {8},
year = {2013}
}
@article{Gupta2019b,
abstract = {Predicting gene functions from genome sequence alone has been difficult, and the functions of a large fraction of plant genes remain unknown. However, leveraging the vast amount of currently available gene expression data has the potential to facilitate our understanding of plant gene functions, especially in determining complex traits. Gene coexpression networks—created by integrating multiple expression datasets—connect genes with similar patterns of expression across multiple conditions. Dense gene communities in such networks, commonly referred to as modules, often indicate that the member genes are functionally related. As such, these modules serve as tools for generating new testable hypotheses, including the prediction of gene function and importance. Recently, we have seen a paradigm shift from the traditional “global” to more defined, context-specific coexpression networks. Such coexpression networks imply genetic correlations in specific biological contexts such as during development or in response to a stress. In this short review, we highlight a few recent studies that attempt to fill the large gaps in our knowledge about cellular functions of plant genes using context-specific coexpression networks.},
author = {Gupta, Chirag and Pereira, Andy},
doi = {10.12688/f1000research.17207.1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta, Pereira - 2019 - Recent advances in gene function prediction using context-specific coexpression networks in plants version 1 ref.pdf:pdf},
issn = {1759796X},
journal = {F1000Research},
keywords = {Clusters,Coexpression networks,Context specific,Gene function prediction,Modules,Network analysis},
pages = {1--10},
title = {{Recent advances in gene function prediction using context-specific coexpression networks in plants [version 1; referees: 2 approved]}},
volume = {8},
year = {2019}
}
@article{Chekuri2019a,
abstract = {We consider parallel, or low adaptivity, algorithms for submodular function maximization. This line of work was recently initiated by Balkanski and Singer and has already led to several interesting results on the cardinality constraint and explicit packing constraints. An important open problem is the classical setting of matroid constraint, which has been instrumental for developments in submodular function maximization. In this paper we develop a general strategy to parallelize the well-studied greedy algorithm and use it to obtain a randomized (1/2 − ϵ)-approximation in O log2(n)/ϵ2 rounds of adaptivity. We rely on this algorithm, and an elegant amplification approach due to Badanidiyuru and Vondr{\'{a}}k to obtain a fractional solution that yields a near-optimal randomized (1 − 1/e − ϵ)-approximation in O log2(n)/ϵ3 rounds of adaptivity. For non-negative functions we obtain a 3 − 22 − ϵ - approximation and a fractional solution that yields a (1/e − ϵ)-approximation. Our approach for parallelizing greedy yields approximations for intersections of matroids and matchoids, and the approximation ratios are comparable to those known for sequential greedy.},
archivePrefix = {arXiv},
arxivId = {1811.12568},
author = {Chekuri, Chandra and Quanrud, Kent},
doi = {10.1145/3313276.3316406},
eprint = {1811.12568},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chekuri, Quanrud - 2019 - Parallelizing greedy for submodular set function maximization in matroids and beyond(2).pdf:pdf},
isbn = {9781450367059},
issn = {07378017},
journal = {Proceedings of the Annual ACM Symposium on Theory of Computing},
keywords = {Matroids,Parallel algorithms,Submodular maximization},
pages = {78--89},
title = {{Parallelizing greedy for submodular set function maximization in matroids and beyond}},
year = {2019}
}
@article{Duren2017,
abstract = {The rapid increase of genome-wide datasets on gene expression, chromatin states, and transcription factor (TF) binding locations offers an exciting opportunity to interpret the information encoded in genomes and epigenomes. This task can be challenging as it requires joint modeling of context-specific activation of cis-regulatory elements (REs) and the effects on transcription of associated regulatory factors. To meet this challenge, we propose a statistical approach based on paired expression and chromatin accessibility (PECA) data across diverse cellular contexts. In our approach, we model (i) the localization to REs of chromatin regulators (CRs) based on their interaction with sequence-specific TFs, (ii) the activation of REs due to CRs that are localized to them, and (iii) the effect of TFs bound to activated REs on the transcription of target genes (TGs). The transcriptional regulatory network inferred by PECA provides a detailed view of how trans- and cis-regulatory elements work together to affect gene expression in a context-specific manner. We illustrate the feasibility of this approach by analyzing paired expression and accessibility data from the mouse Encyclopedia of DNA Elements (ENCODE) and explore various applications of the resulting model.},
author = {Duren, Zhana and Chen, Xi and Jiang, Rui and Wang, Yong and Wong, Wing Hung},
doi = {10.1073/pnas.1704553114},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Duren et al. - 2017 - Modeling gene regulation from paired expression and chromatin accessibility data.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Chromatin activity,Chromatin regulator,Gene regulation,Regulatory element,Transcription factor},
number = {25},
pages = {E4914--E4923},
title = {{Modeling gene regulation from paired expression and chromatin accessibility data}},
volume = {114},
year = {2017}
}
@article{Lundberg2016,
abstract = {A cell's epigenome arises from interactions among regulatory factors-transcription factors and histone modifications-co-localized at particular genomic regions. We developed a novel statistical method, ChromNet, to infer a network of these interactions, the chromatin network, by inferring conditional-dependence relationships among a large number of ChIP-seq data sets. We applied ChromNet to all available 1451 ChIP-seq data sets from the ENCODE Project, and showed that ChromNet revealed previously known physical interactions better than alternative approaches. We experimentally validated one of the previously unreported interactions, MYC-HCFC1. An interactive visualization tool is available at http://chromnet.cs.washington.edu.},
author = {Lundberg, Scott M. and Tu, William B. and Raught, Brian and Penn, Linda Z. and Hoffman, Michael M. and Lee, Su In},
doi = {10.1186/s13059-016-0925-0},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lundberg et al. - 2016 - ChromNet Learning the human chromatin network from all ENCODE ChIP-seq data.pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
number = {1},
pages = {1--19},
publisher = {Genome Biology},
title = {{ChromNet: Learning the human chromatin network from all ENCODE ChIP-seq data}},
url = {http://dx.doi.org/10.1186/s13059-016-0925-0},
volume = {17},
year = {2016}
}
@article{Ene2019b,
abstract = {We consider the problem of maximizing the multilinear extension of a submodular function subject a single matroid constraint or multiple packing constraints with a small number of adaptive rounds of evaluation queries. We obtain the first algorithms with low adaptivity for submodular maximization with a matroid constraint. Our algorithms achieve a 1 − 1/e − ϵ approximation for monotone functions and a 1/e − ϵ approximation for non-monotone functions, which nearly matches the best guarantees known in the fully adaptive setting. The number of rounds of adaptivity is O(log2 n/ϵ3), which is an exponential speedup over the existing algorithms. We obtain the first parallel algorithm for non-monotone submodular maximization subject to packing constraints. Our algorithm achieves a 1/e −ϵ approximation using O(log(n/ϵ) log(1/ϵ) log(n+ m)/ϵ2) parallel rounds, which is again an exponential speedup in parallel time over the existing algorithms. For monotone functions, we obtain a 1−1/e−ϵ approximation in O(log(n/ϵ) logm/ϵ2) parallel rounds. The number of parallel rounds of our algorithm matches that of the state of the art algorithm for solving packing LPs with a linear objective (Mahoney et al., 2016). Our results apply more generally to the problem of maximizing a diminishing returns submodular (DR-submodular) function.},
archivePrefix = {arXiv},
arxivId = {1808.09987},
author = {Ene, Alina and Nguy{\^{e}}n, Huy L. and Vladu, Adrian},
doi = {10.1145/3313276.3316389},
eprint = {1808.09987},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ene, Nguy{\^{e}}n, Vladu - 2019 - Submodular maximization with matroid and packing constraints in parallel.pdf:pdf},
isbn = {9781450367059},
issn = {07378017},
journal = {Proceedings of the Annual ACM Symposium on Theory of Computing},
keywords = {DR-submodular maximization,Matroid,Packing,Parallel complexity},
pages = {90--101},
title = {{Submodular maximization with matroid and packing constraints in parallel}},
year = {2019}
}
@article{Li2019,
abstract = {This paper addresses the challenging problem of retrieval and matching of graph structured objects, and makes two key contributions. First, we demonstrate how Graph Neural Networks (GNN), which have emerged as an effective model for various supervised prediction problems defined on structured data, can be trained to produce embedding of graphs in vector spaces that enables efficient similarity reasoning. Second, we propose a novel Graph Matching Network model that, given a pair of graphs as input, computes a similarity score between them by jointly reasoning on the pair through a new cross-graph attention-based matching mechanism. We demonstrate the effectiveness of our models on different domains including the challenging problem of control-flow-graph based function similarity search that plays an important role in the detection of vulnerabilities in software systems. The experimental analysis demonstrates that our models are not only able to exploit structure in the context of similarity learning but they can also outperform domain-specific baseline systems that have been carefully hand-engineered for these problems.},
archivePrefix = {arXiv},
arxivId = {1904.12787},
author = {Li, Yujia and Gu, Chenjie and Dullien, Thomas and Vinyals, Oriol and Kohli, Pushmeet},
eprint = {1904.12787},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2019 - Graph Matching Networks for Learning the Similarity of Graph Structured Objects.pdf:pdf},
month = {apr},
title = {{Graph Matching Networks for Learning the Similarity of Graph Structured Objects}},
url = {http://arxiv.org/abs/1904.12787},
year = {2019}
}
@article{Mocanu2018,
abstract = {Through the success of deep learning in various domains, artificial neural networks are currently among the most used artificial intelligence methods. Taking inspiration from the network properties of biological neural networks (e.g. sparsity, scale-freeness), we argue that (contrary to general practice) artificial neural networks, too, should not have fully-connected layers. Here we propose sparse evolutionary training of artificial neural networks, an algorithm which evolves an initial sparse topology (Erdos-R{\'{e}}nyi random graph) of two consecutive layers of neurons into a scale-free topology, during learning. Our method replaces artificial neural networks fully-connected layers with sparse ones before training, reducing quadratically the number of parameters, with no decrease in accuracy. We demonstrate our claims on restricted Boltzmann machines, multi-layer perceptrons, and convolutional neural networks for unsupervised and supervised learning on 15 datasets. Our approach has the potential to enable artificial neural networks to scale up beyond what is currently possible.},
archivePrefix = {arXiv},
arxivId = {1707.04780},
author = {Mocanu, Decebal Constantin and Mocanu, Elena and Stone, Peter and Nguyen, Phuong H. and Gibescu, Madeleine and Liotta, Antonio},
doi = {10.1038/s41467-018-04316-3},
eprint = {1707.04780},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mocanu et al. - 2018 - Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
number = {1},
pages = {1--12},
publisher = {Springer US},
title = {{Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science}},
url = {http://dx.doi.org/10.1038/s41467-018-04316-3},
volume = {9},
year = {2018}
}
@article{Such2017,
abstract = {Deep artificial neural networks (DNNs) are typically trained via gradient-based learning algorithms, namely backpropagation. Evolution strategies (ES) can rival backprop-based algorithms such as Q-learning and policy gradients on challenging deep reinforcement learning (RL) problems. However, ES can be considered a gradient-based algorithm because it performs stochastic gradient descent via an operation similar to a finite-difference approximation of the gradient. That raises the question of whether non-gradient-based evolutionary algorithms can work at DNN scales. Here we demonstrate they can: we evolve the weights of a DNN with a simple, gradient-free, population-based genetic algorithm (GA) and it performs well on hard deep RL problems, including Atari and humanoid locomotion. The Deep GA successfully evolves networks with over four million free parameters, the largest neural networks ever evolved with a traditional evolutionary algorithm. These results (1) expand our sense of the scale at which GAs can operate, (2) suggest intriguingly that in some cases following the gradient is not the best choice for optimizing performance, and (3) make immediately available the multitude of neuroevolution techniques that improve performance. We demonstrate the latter by showing that combining DNNs with novelty search, which encourages exploration on tasks with deceptive or sparse reward functions, can solve a high-dimensional problem on which reward-maximizing algorithms (e.g.\ DQN, A3C, ES, and the GA) fail. Additionally, the Deep GA is faster than ES, A3C, and DQN (it can train Atari in ${\raise.17ex\hbox{$\scriptstyle\sim$}}$4 hours on one desktop or ${\raise.17ex\hbox{$\scriptstyle\sim$}}$1 hour distributed on 720 cores), and enables a state-of-the-art, up to 10,000-fold compact encoding technique.},
archivePrefix = {arXiv},
arxivId = {1712.06567},
author = {Such, Felipe Petroski and Madhavan, Vashisht and Conti, Edoardo and Lehman, Joel and Stanley, Kenneth O. and Clune, Jeff},
eprint = {1712.06567},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Such et al. - 2017 - Deep Neuroevolution Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforc.pdf:pdf},
title = {{Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning}},
url = {http://arxiv.org/abs/1712.06567},
year = {2017}
}
@article{Sakaue2019a,
abstract = {The stochastic greedy algorithm (SG) is a randomized version of the greedy algorithm for submodular maximization with a size constraint. SG is highly practical since it is fast, delivers high empirical performance, and is easy to implement. However, its approximation guarantee has been proved only for monotone objective functions; this is natural since the original greedy algorithm is known to perform arbitrarily poorly for non-monotone objectives in general. In this paper, contrary to the expectation, we prove an interesting result: Thanks to the randomization, SG (with slight modification) can achieve almost $1/4$-approximation guarantees in expectation even for non-monotone objective functions. Our result provides practical and theoretically guaranteed algorithms for non-monotone submodular maximization with size a constraint, which run far faster and achieve as good objective values as existing algorithms.},
archivePrefix = {arXiv},
arxivId = {1908.06242},
author = {Sakaue, Shinsaku},
eprint = {1908.06242},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sakaue - 2019 - Guarantees of Stochastic Greedy Algorithms for Non-monotone Submodular Maximization with Cardinality Constraint.pdf:pdf},
pages = {1--14},
title = {{Guarantees of Stochastic Greedy Algorithms for Non-monotone Submodular Maximization with Cardinality Constraint}},
url = {http://arxiv.org/abs/1908.06242},
year = {2019}
}
@inproceedings{Gupta2010,
abstract = {Constrained submodular maximization problems have long been studied, with near-optimal results known under a variety of constraints when the submodular function is monotone. The case of non-monotone submodular maximization is less understood: the first approximation algorithms even for the unconstrainted setting were given by Feige et al. (FOCS '07). More recently, Lee et al. (STOC '09, APPROX '09) show how to approximately maximize non-monotone submodular functions when the constraints are given by the intersection of p matroid constraints; their algorithm is based on local-search procedures that consider p-swaps, and hence the running time may be n^Omega(p), implying their algorithm is polynomial-time only for constantly many matroids. In this paper, we give algorithms that work for p-independence systems (which generalize constraints given by the intersection of p matroids), where the running time is poly(n,p). Our algorithm essentially reduces the non-monotone maximization problem to multiple runs of the greedy algorithm previously used in the monotone case. Our idea of using existing algorithms for monotone functions to solve the non-monotone case also works for maximizing a submodular function with respect to a knapsack constraint: we get a simple greedy-based constant-factor approximation for this problem. With these simpler algorithms, we are able to adapt our approach to constrained non-monotone submodular maximization to the (online) secretary setting, where elements arrive one at a time in random order, and the algorithm must make irrevocable decisions about whether or not to select each element as it arrives. We give constant approximations in this secretary setting when the algorithm is constrained subject to a uniform matroid or a partition matroid, and give an O(log k) approximation when it is constrained by a general matroid of rank k.},
archivePrefix = {arXiv},
arxivId = {1003.1517},
author = {Gupta, Anupam and Roth, Aaron and Schoenebeck, Grant and Talwar, Kunal},
booktitle = {International Workshop on Internet and Network Economics (WINE)},
doi = {10.1007/978-3-642-17572-5_20},
eprint = {1003.1517},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta et al. - 2010 - Constrained non-monotone submodular maximization Offline and secretary algorithms.pdf:pdf;:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta et al. - 2010 - Constrained non-monotone submodular maximization Offline and secretary algorithms(2).pdf:pdf},
isbn = {3642175716},
issn = {03029743},
title = {{Constrained non-monotone submodular maximization: Offline and secretary algorithms}},
year = {2010}
}
@article{Henry2018,
archivePrefix = {arXiv},
arxivId = {arXiv:1405.7962v1},
author = {Henry, Julien and Monniaux, David and Ma, Claire},
eprint = {arXiv:1405.7962v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Henry, Monniaux, Ma - 2018 - How to Compute Worst-Case Execution Time by Optimization Modulo Theory and a Clever Encoding of Program S.pdf:pdf},
title = {{How to Compute Worst-Case Execution Time by Optimization Modulo Theory and a Clever Encoding of Program Semantics ∗}},
year = {2018}
}
@inproceedings{Kazemi2019,
abstract = {Streaming algorithms are generally judged by the quality of their solution, memory footprint, and computational complexity. In this paper, we study the problem of maximizing a monotone submodular function in the streaming setting with a cardinality constraint $k$. We first propose Sieve-Streaming++, which requires just one pass over the data, keeps only $O(k)$ elements and achieves the tight $(1/2)$-approximation guarantee. The best previously known streaming algorithms either achieve a suboptimal $(1/4)$-approximation with $\Theta(k)$ memory or the optimal $(1/2)$-approximation with $O(k\log k)$ memory. Next, we show that by buffering a small fraction of the stream and applying a careful filtering procedure, one can heavily reduce the number of adaptive computational rounds, thus substantially lowering the computational complexity of Sieve-Streaming++. We then generalize our results to the more challenging multi-source streaming setting. We show how one can achieve the tight $(1/2)$-approximation guarantee with $O(k)$ shared memory while minimizing not only the required rounds of computations but also the total number of communicated bits. Finally, we demonstrate the efficiency of our algorithms on real-world data summarization tasks for multi-source streams of tweets and of YouTube videos.},
archivePrefix = {arXiv},
arxivId = {1905.00948},
author = {Kazemi, Ehsan and Mitrovic, Marko and Zadimoghaddam, Morteza and Lattanzi, Silvio and Karbasi, Amin},
booktitle = {International Conference on Machine Learning (ICML)},
eprint = {1905.00948},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kazemi et al. - 2019 - Submodular Streaming in All its Glory Tight Approximation, Minimum Memory and Low Adaptive Complexity.pdf:pdf},
title = {{Submodular Streaming in All its Glory: Tight Approximation, Minimum Memory and Low Adaptive Complexity}},
url = {http://arxiv.org/abs/1905.00948},
year = {2019}
}
@article{Informatica,
archivePrefix = {arXiv},
arxivId = {arXiv:1411.0659v2},
author = {Informatica, Acta and Chistikov, Dmitry and Dimitrova, Rayna and Majumdar, Rupak},
eprint = {arXiv:1411.0659v2},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Informatica et al. - Unknown - Approximate Counting in SMT and Value Estimation for Probabilistic Programs.pdf:pdf},
keywords = {approximation algorithms,computation,model counting,probabilistic programming,sat,satisfiability modulo theory,smt,volume},
title = {{Approximate Counting in SMT and Value Estimation for Probabilistic Programs}}
}
@inproceedings{Chekuri2015,
abstract = {We consider the problem of maximizing a nonnegative submodular set function $f:2^{\mathcal{N}} \rightarrow \mathbb{R}^+$ subject to a $p$-matchoid constraint in the single-pass streaming setting. Previous work in this context has considered streaming algorithms for modular functions and monotone submodular functions. The main result is for submodular functions that are {\em non-monotone}. We describe deterministic and randomized algorithms that obtain a $\Omega(\frac{1}{p})$-approximation using $O(k \log k)$-space, where $k$ is an upper bound on the cardinality of the desired set. The model assumes value oracle access to $f$ and membership oracles for the matroids defining the $p$-matchoid constraint.},
archivePrefix = {arXiv},
arxivId = {1504.08024},
author = {Chekuri, Chandra and Gupta, Shalmoli and Quanrud, Kent},
booktitle = {International Colloquium on Automata, Languages, and Programming (ICALP)},
eprint = {1504.08024},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chekuri, Gupta, Quanrud - 2015 - Streaming Algorithms for Submodular Function Maximization.pdf:pdf},
title = {{Streaming Algorithms for Submodular Function Maximization}},
url = {http://arxiv.org/abs/1504.08024},
year = {2015}
}
@article{Vondrak2013,
author = {Vondr{\'{a}}k, Jan},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vondr{\'{a}}k - 2013 - Symmetry and Approximability of Submodular Maximization Problems.pdf:pdf},
journal = {SIAM Journal on Computing},
keywords = {090758209,10,1137,15a24,65f30,65h10,ams subject classifications,complex symmetric solution,doi,doubling algorithm,fixed-point,green,iteration,newton,nonlinear matrix equation,s function,s method,stable solution},
number = {1},
pages = {265--304},
title = {{Symmetry and Approximability of Submodular Maximization Problems}},
volume = {42},
year = {2013}
}
@techreport{Fedyukovich,
abstract = {Functional synthesis (FS) aims at generating an implementation from a declarative specification over sets of designated input and output variables. Traditionally, FS tasks are formulated as ∀∃-formulas, where input variables are universally quantified and output variables are existentially quantified. State-of-the-art approaches to FS proceed by eliminating existential quantifiers and extracting Skolem functions, which are then turned into implementations. Related applications benefit from having concise (i.e., compact and comprehensive) Skolem functions. In this paper, we present an approach for extracting concise Skolem functions for FS tasks specified as examples, i.e., tuples of concrete values of integer variables. Our approach builds a decision tree from relationships between inputs and outputs and preconditions that classify all examples into subsets that share the same input-output relationship. We also present an extension that is applied to hybrid FS tasks, which are formulated in part by examples and in part by arbitrary declarative specifications. Our approach is implemented on top of a functional synthesizer AE-VAL and evaluated on a set of reactive synthesis benchmarks enhanced with examples. Solutions produced by our tool are an order of magnitude smaller than ones produced by the baseline AE-VAL.},
author = {Fedyukovich, Grigory and Gupta, Aarti},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fedyukovich, Gupta - Unknown - Functional Synthesis with Examples.pdf:pdf},
title = {{Functional Synthesis with Examples}}
}
@techreport{Bhattacharyaa,
abstract = {Active learning algorithms automatically identify the most informative samples from large amounts of unlabeled data and tremendously reduce human annotation effort in inducing a robust machine learning model. Real-world data often exhibit significantly skewed class distributions, where samples from one class dominate over the other. While active learning has been extensively studied, there have been limited research efforts to develop active learning algorithms specifically for class imbalance applications. In this paper, we propose a novel framework to address this research challenge. We pose the active sample selection as a constrained optimization problem and derive a linear programming relaxation to select a batch of samples. Contrary to existing algorithms, our framework is generic and is applicable to both binary and multi-class problems, where the imbalance may exist across multiple classes. Our extensive empirical studies on four vision datasets spanning three different application domains (face, facial expression and handwritten digits recognition) with varied degrees of class imbalance demonstrate the promise and potential of the method for real-world imbalanced data applications.},
author = {Bhattacharya, Aditya R and Liu, Ji and Chakraborty, Shayok},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhattacharya - Unknown - A Generic Active Learning Framework for Class Imbalance Applications.pdf:pdf},
title = {{A Generic Active Learning Framework for Class Imbalance Applications}}
}
@article{Valba2015,
abstract = {{\textcopyright} 2015 Valba et al. Background: Connectivity networks, which reflect multiple interactions between genes and proteins, possess not only a descriptive but also a predictive value, as new connections can be extrapolated and tested by means of computational analysis. Integration of different types of connectivity data (such as co-expression and genetic interactions) in one network has proven to benefit 'guilt by association' analysis. However predictive values of connectives of different types, that had their specific functional meaning and topological characteristics were not obvious, and have been addressed in this analysis. Methods: eQTL data for 3 experimental C.elegans age groups were retrieved from WormQTL. WormNet has been used to obtain pair-wise gene interactions. The Shortest Path Function (SPF) has been adopted for statistical validation of the co-expressed gene clusters and for computational prediction of their potential gene expression regulators from a n etwork context. A new SPF-based algorithm has been applied to genetic interactions sub-networks adjacent to the clusters of co-expressed genes for ranking the most likely gene expression regulators causal to eQTLs. Results: We have demonstrated that known co-expression and genetic interactions between C. Elegans genes can be complementary in predicting gene expression regulators. Several algorithms were compared in respect to their predictive potential in different network connectivity contexts. We found that genes associated with eQTLs are highly clustered in a C. Elegans co-expression sub-network, and their adjacent genetic interactions provide the optimal functional connectivity environment for application of the new SPF-based algorithm. It was successfully tested in the reverse-prediction analysis on groups of genes with known regulators and applied to co-expressed genes and experimentally observed expression quantitative trait loci (eQTLs). Conclusions: This analysis demonstrates differences in topology and connectivity of co-expression and genetic interactions sub-networks in WormNet. The modularity of less continuous genetic interaction network does not correspond to modularity of the dense network comprised by gene co-expression interactions. However the genetic interaction network can be used much more efficiently with the SPF method in prediction of potential regulators of gene expression. The developed method can be used for validation of functional significance of suggested eQTLs and a discovery of new regulatory modules.},
author = {Valba, Olga V. and Nechaev, Sergei K. and Sterken, Mark G. and Snoek, L. Basten and Kammenga, Jan E. and Vasieva, Olga O.},
doi = {10.1186/s13040-015-0066-0},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Valba et al. - 2015 - On predicting regulatory genes by analysis of functional networks in C. Elegans.pdf:pdf},
issn = {17560381},
journal = {BioData Mining},
keywords = {Longevity,Networks,Regulatory genes,The shortest paths,eQTL},
month = {nov},
number = {1},
publisher = {BioMed Central Ltd.},
title = {{On predicting regulatory genes by analysis of functional networks in C. Elegans}},
volume = {8},
year = {2015}
}
@article{Huang2017a,
abstract = {With the emergence of massively parallel sequencing, genomewide expression data production has reached an unprecedented level. This abundance of data has greatly facilitated maize research, but may not be amenable to traditional analysis techniques that were optimized for other data types. Using publicly available data, a gene coexpression network (GCN) can be constructed and used for gene function prediction, candidate gene selection, and improving understanding of regulatory pathways. Several GCN studies have been done in maize (Zea mays), mostly using microarray datasets. To build an optimal GCN from plant materials RNA-Seq data, parameters for expression data normalization and network inference were evaluated. A comprehensive evaluation of these two parameters and a ranked aggregation strategy on network performance, using libraries from 1266 maize samples, were conducted. Three normalization methods and 10 inference methods, including six correlation and four mutual information methods, were tested. The three normalization methods had very similar performance. For network inference, correlation methods performed better than mutual information methods at some genes. Increasing sample size also had a positive effect on GCN. Aggregating single networks together resulted in improved performance compared to single networks.},
author = {Huang, Ji and Vendramin, Stefania and Shi, Lizhen and McGinnis, Karen M.},
doi = {10.1104/pp.17.00825},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2017 - Construction and optimization of a large gene coexpression network in maize using RNA-seq data.pdf:pdf},
issn = {15322548},
journal = {Plant Physiology},
month = {sep},
number = {1},
pages = {568--583},
publisher = {American Society of Plant Biologists},
title = {{Construction and optimization of a large gene coexpression network in maize using RNA-seq data}},
volume = {175},
year = {2017}
}
@inproceedings{Harshaw2019,
archivePrefix = {arXiv},
arxivId = {arXiv:1904.09354v1},
author = {Harshaw, Christopher and Feldman, Moran and Ward, Justin and Karbasi, Amin},
booktitle = {International Confer- ence on Machine Learning (ICML)},
eprint = {arXiv:1904.09354v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Harshaw et al. - 2019 - Submodular Maximization Beyond Non-negativity Guarantees, Fast Algorithms, and Applications.pdf:pdf},
title = {{Submodular Maximization Beyond Non-negativity: Guarantees, Fast Algorithms, and Applications}},
year = {2019}
}
@article{Faure2013,
abstract = {The efficacy of a newly created software package for predictive modeling of developmental gene regulatory networks (GRNs) has recently been demonstrated (Peter et al., 2012 ). The program GeNeTool computes spatial gene expression patterns based on GRN interactions and thereby allows the direct comparison of predicted and observed spatial expression patterns. GeNeTool also permits in silico exploration of both cis- and trans- perturbations of GRN interactions. Here, we present this program, review briefly its major features and applications, and provide a detailed and accessible tutorial.},
author = {Faure, Emmanuel and Peter, Isabelle S. and Davidson, Eric H.},
doi = {10.1089/cmb.2012.0297},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Faure, Peter, Davidson - 2013 - A New Software Package for Predictive Gene Regulatory Network Modeling and Redesign.pdf:pdf},
issn = {1066-5277},
journal = {Journal of Computational Biology},
keywords = {artificial life,gene networks,genetic analysis,recognition of genes,regulatory},
number = {6},
pages = {419--423},
title = {{A New Software Package for Predictive Gene Regulatory Network Modeling and Redesign}},
volume = {20},
year = {2013}
}
@article{Bhattacharya,
author = {Bhattacharya, Aditya R},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhattacharya - Unknown - A Generic Active Learning Framework for Class Imbalance Applications.pdf:pdf},
pages = {1--13},
title = {{A Generic Active Learning Framework for Class Imbalance Applications}}
}
@article{Neumann2019a,
abstract = {<p>Evolutionary diversity optimization aims to compute a diverse set of
solutions where all solutions meet a given quality criterion. With this paper,
we bridge the areas of evolutionary diversity optimization and evolutionary
multi-objective optimization. We show how popular indicators frequently used in
the area of multi-objective optimization can be used for evolutionary diversity
optimization. Our experimental investigations for evolving diverse sets of TSP
instances and images according to various features show that two of the most
prominent multi-objective indicators, namely the hypervolume indicator and the
inverted generational distance, provide excellent results in terms of
visualization and various diversity indicators.
</p>},
author = {Neumann, Aneta and Gao, Wanru and Wagner, Markus and Neumann, Frank},
doi = {10.1145/3321707.3321796},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Neumann et al. - 2019 - Evolutionary diversity optimization using multi-objective indicators.pdf:pdf},
isbn = {9781450361118},
keywords = {2019,acm reference format,and frank neumann,aneta neumann,diversity,evolutionary algorithms,features,markus wagner,wanru gao},
pages = {837--845},
title = {{Evolutionary diversity optimization using multi-objective indicators}},
year = {2019}
}
@article{Neumann2019,
author = {Neumann, Frank and Pourhassan, Mojgan and Witt, Carsten},
doi = {10.1145/3321707.3321722},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Neumann, Pourhassan, Witt - 2019 - Improved runtime results for simple randomised search heuristics on linear functions with a uniform c.pdf:pdf},
isbn = {9781450361118},
keywords = {1,constraints,ea,linear functions,randomised search heuristics},
pages = {1506--1514},
title = {{Improved runtime results for simple randomised search heuristics on linear functions with a uniform constraint}},
year = {2019}
}
@article{Pourhassan2018,
abstract = {The generalized travelling salesperson problem is an important NP-hard combinatorial optimization problem for which metaheuristics, such as local search and evolutionary algorithms, have been used very successfully. Two hierarchical approaches with different neighbourhood structures, namely a cluster-based approach and a node-based approach, have been proposed by Hu and Raidl (2008) for solving this problem. In this article, local search algorithms and simple evolutionary algorithms based on these approaches are investigated from a theoretical perspective. For local search algorithms, we point out the complementary abilities of the two approaches by presenting instances where they mutually outperform each other. Afterwards, we introduce an instance which is hard for both approaches when initialized on a particular point of the search space, but where a variable neighbourhood search combining them finds the optimal solution in polynomial time. Then we turn our attention to analysing the behaviour of simple...},
author = {Pourhassan, Mojgan and Neumann, Frank},
doi = {10.1162/evco_a_00233},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pourhassan, Neumann - 2018 - Theoretical Analysis of Local Search and Simple Evolutionary Algorithms for the Generalized Travelling Sale.pdf:pdf},
issn = {1063-6560},
journal = {Evolutionary Computation},
keywords = {bi-,combinatorial optimisation,evolutionary algorithms,generalized travelling salesperson problem,level optimisation,parameterised complexity analysis},
number = {x},
pages = {1--34},
title = {{Theoretical Analysis of Local Search and Simple Evolutionary Algorithms for the Generalized Travelling Salesperson Problem}},
year = {2018}
}
@article{Roostapour2018,
abstract = {In this paper, we consider the subset selection problem for function $f$ with constraint bound $B$ which changes over time. We point out that adaptive variants of greedy approaches commonly used in the area of submodular optimization are not able to maintain their approximation quality. Investigating the recently introduced POMC Pareto optimization approach, we show that this algorithm efficiently computes a $\phi= (\alpha_f/2)(1-\frac{1}{e^{\alpha_f}})$-approximation, where $\alpha_f$ is the submodularity ratio of $f$, for each possible constraint bound $b \leq B$. Furthermore, we show that POMC is able to adapt its set of solutions quickly in the case that $B$ increases. Our experimental investigations for the influence maximization in social networks show the advantage of POMC over generalized greedy algorithms.},
archivePrefix = {arXiv},
arxivId = {1811.07806},
author = {Roostapour, Vahid and Neumann, Aneta and Neumann, Frank and Friedrich, Tobias},
eprint = {1811.07806},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roostapour et al. - 2018 - Pareto Optimization for Subset Selection with Dynamic Cost Constraints.pdf:pdf},
keywords = {real-time heuristic search, heuristic search, plan},
title = {{Pareto Optimization for Subset Selection with Dynamic Cost Constraints}},
url = {http://arxiv.org/abs/1811.07806},
year = {2018}
}
@techreport{Harshaw,
abstract = {It is generally believed that submodular functions and the more general class of $\gamma$-weakly submodular functions-may only be optimized under the non-negativity assumption f (S) ≥ 0. In this paper, we show that once the function is expressed as the difference f = g − c, where g is monotone, non-negative, and $\gamma$-weakly submod-ular and c is non-negative modular, then strong approximation guarantees may be obtained. We present an algorithm for maximizing g − c under a k-cardinality constraint which produces a random feasible set S such that E [g(S)−c(S)] ≥ (1 − e −$\gamma$ −)g(OPT)−c(OPT), whose running time is O(n log 2 1), independent of k. We extend these results to the unconstrained setting by describing an algorithm with the same approximation guarantees and faster O(n log 1) runtime. The main techniques underlying our algorithms are twofold: the use of a surrogate objective which varies the relative importance between g and c throughout the algorithm, and a geometric sweep over possible $\gamma$ values. Our algorithmic guarantees are complemented by a hardness result showing that no polynomial-time algorithm which accesses g through a value oracle can do better. We empirically demonstrate the success of our algorithms by applying them to experimental design on the Boston Housing dataset and directed vertex cover on the Email EU dataset.},
author = {Harshaw, Christopher and Feldman, Moran and Ward, Justin and Karbasi, Amin},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Harshaw et al. - Unknown - Submodular Maximization beyond Non-negativity Guarantees, Fast Algorithms, and Applications.pdf:pdf},
title = {{Submodular Maximization beyond Non-negativity: Guarantees, Fast Algorithms, and Applications}}
}
@techreport{Karbasi,
author = {Karbasi, Amin and Bilmes, Jeff},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karbasi, Bilmes - Unknown - Submodularity in Information and Data Science Part 2 Algorithms ISIT Tutorial.pdf:pdf},
title = {{Submodularity in Information and Data Science Part 2: Algorithms ISIT Tutorial}}
}
@article{Xu2018,
abstract = {Graph Neural Networks (GNNs) are an effective framework for representation learning of graphs. GNNs follow a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and transforming representation vectors of its neighboring nodes. Many GNN variants have been proposed and have achieved state-of-the-art results on both node and graph classification tasks. However, despite GNNs revolutionizing graph representation learning, there is limited understanding of their representational properties and limitations. Here, we present a theoretical framework for analyzing the expressive power of GNNs to capture different graph structures. Our results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures. We then develop a simple architecture that is provably the most expressive among the class of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism test. We empirically validate our theoretical findings on a number of graph classification benchmarks, and demonstrate that our model achieves state-of-the-art performance.},
archivePrefix = {arXiv},
arxivId = {1810.00826},
author = {Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
eprint = {1810.00826},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - 2018 - How Powerful are Graph Neural Networks.pdf:pdf},
month = {oct},
title = {{How Powerful are Graph Neural Networks?}},
url = {http://arxiv.org/abs/1810.00826},
year = {2018}
}
@article{Staib2019,
abstract = {Distributionally robust optimization (DRO) has attracted attention in machine learning due to its connections to regularization, generalization, and robustness. Existing work has considered uncertainty sets based on phi-divergences and Wasserstein distances, each of which have drawbacks. In this paper, we study DRO with uncertainty sets measured via maximum mean discrepancy (MMD). We show that MMD DRO is roughly equivalent to regularization by the Hilbert norm and, as a byproduct, reveal deep connections to classic results in statistical learning. In particular, we obtain an alternative proof of a generalization bound for Gaussian kernel ridge regression via a DRO lense. The proof also suggests a new regularizer. Our results apply beyond kernel methods: we derive a generically applicable approximation of MMD DRO, and show that it generalizes recent work on variance-based regularization.},
archivePrefix = {arXiv},
arxivId = {1905.10943},
author = {Staib, Matthew and Jegelka, Stefanie},
eprint = {1905.10943},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Staib, Jegelka - 2019 - Distributionally Robust Optimization and Generalization in Kernel Methods.pdf:pdf},
month = {may},
title = {{Distributionally Robust Optimization and Generalization in Kernel Methods}},
url = {http://arxiv.org/abs/1905.10943},
year = {2019}
}
@article{Staib2018,
abstract = {Submodular functions have applications throughout machine learning, but in many settings, we do not have direct access to the underlying function $f$. We focus on stochastic functions that are given as an expectation of functions over a distribution $P$. In practice, we often have only a limited set of samples $f_i$ from $P$. The standard approach indirectly optimizes $f$ by maximizing the sum of $f_i$. However, this ignores generalization to the true (unknown) distribution. In this paper, we achieve better performance on the actual underlying function $f$ by directly optimizing a combination of bias and variance. Algorithmically, we accomplish this by showing how to carry out distributionally robust optimization (DRO) for submodular functions, providing efficient algorithms backed by theoretical guarantees which leverage several novel contributions to the general theory of DRO. We also show compelling empirical evidence that DRO improves generalization to the unknown stochastic submodular function.},
archivePrefix = {arXiv},
arxivId = {1802.05249},
author = {Staib, Matthew and Wilder, Bryan and Jegelka, Stefanie},
eprint = {1802.05249},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Staib, Wilder, Jegelka - 2018 - Distributionally Robust Submodular Maximization.pdf:pdf},
month = {feb},
title = {{Distributionally Robust Submodular Maximization}},
url = {http://arxiv.org/abs/1802.05249},
year = {2018}
}
@article{Alvarez-Melis2018,
abstract = {Many problems in machine learning involve calculating correspondences between sets of objects, such as point clouds or images. Discrete optimal transport provides a natural and successful approach to such tasks whenever the two sets of objects can be represented in the same space, or at least distances between them can be directly evaluated. Unfortunately neither requirement is likely to hold when object representations are learned from data. Indeed, automatically derived representations such as word embeddings are typically fixed only up to some global transformations, for example, reflection or rotation. As a result, pairwise distances across two such instances are ill-defined without specifying their relative transformation. In this work, we propose a general framework for optimal transport in the presence of latent global transformations. We cast the problem as a joint optimization over transport couplings and transformations chosen from a flexible class of invariances, propose algorithms to solve it, and show promising results in various tasks, including a popular unsupervised word translation benchmark.},
archivePrefix = {arXiv},
arxivId = {1806.09277},
author = {Alvarez-Melis, David and Jegelka, Stefanie and Jaakkola, Tommi S.},
eprint = {1806.09277},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alvarez-Melis, Jegelka, Jaakkola - 2018 - Towards Optimal Transport with Global Invariances.pdf:pdf},
month = {jun},
title = {{Towards Optimal Transport with Global Invariances}},
url = {http://arxiv.org/abs/1806.09277},
year = {2018}
}
@techreport{,
abstract = {We study the monotone, weakly submodular maximization problem ($\gamma$-WSM), which is to find a subset of size k from a universe of size n that maximizes a monotone, weakly submod-ular objective function f. For objectives with submodularity ratio $\gamma$, we provide a novel evolutionary algorithm that has an expected approximation guarantee of (1 − n −1)(1 − e −$\gamma$ −) for $\gamma$-WSM in linear time, improving upon the cubic time complexity of previous evolutionary algorithms for this problem. This improvement is a result of restricting mutations to local changes, a biased random selection of which set to mutate, and an improved theoretical analysis. In the context of several applications of $\gamma$-WSM, we demonstrate the ability of our algorithms to quickly exceed the solution of the greedy algorithm and converge faster than existing evolutionary algorithms for $\gamma$-WSM.},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Fast Evolutionary Algorithm for Maximization of Cardinality-Constrained Weakly Submodular Functions.pdf:pdf},
title = {{Fast Evolutionary Algorithm for Maximization of Cardinality-Constrained Weakly Submodular Functions}},
url = {www.aaai.org}
}
@inproceedings{Breuer2019,
abstract = {In this paper we describe a new algorithm called Fast Adaptive Sequencing Technique (FAST) for maximizing a monotone submodular function under a cardinality constraint $k$ whose approximation ratio is arbitrarily close to $1-1/e$, is $O(\log(n) \log^2(\log k))$ adaptive, and uses a total of $O(n \log\log(k))$ queries. Recent algorithms have comparable guarantees in terms of asymptotic worst case analysis, but their actual number of rounds and query complexity depend on very large constants and polynomials in terms of precision and confidence, making them impractical for large data sets. Our main contribution is a design that is extremely efficient both in terms of its non-asymptotic worst case query complexity and number of rounds, and in terms of its practical runtime. We show that this algorithm outperforms any algorithm for submodular maximization we are aware of, including hyper-optimized parallel versions of state-of-the-art serial algorithms, by running experiments on large data sets. These experiments show FAST is orders of magnitude faster than the state-of-the-art.},
archivePrefix = {arXiv},
arxivId = {1907.06173},
author = {Breuer, Adam and Balkanski, Eric and Singer, Yaron},
booktitle = {International Conference on Machine Learning (ICML)},
eprint = {1907.06173},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Breuer, Balkanski, Singer - 2019 - The FAST Algorithm for Submodular Maximization.pdf:pdf},
title = {{The FAST Algorithm for Submodular Maximization}},
url = {http://arxiv.org/abs/1907.06173},
year = {2019}
}
@article{Chekuri2019,
abstract = {We consider parallel, or low adaptivity, algorithms for submodular function maximization. This line of work was recently initiated by Balkanski and Singer and has already led to several interesting results on the cardinality constraint and explicit packing constraints. An important open problem is the classical setting of matroid constraint, which has been instrumental for developments in submodular function maximization. In this paper we develop a general strategy to parallelize the well-studied greedy algorithm and use it to obtain a randomized $\left(\frac{1}{2} - \epsilon\right)$-approximation in $\operatorname{O}\left( \frac{\log^2 n}{\epsilon^2} \right)$ rounds of adaptivity. We rely on this algorithm, and an elegant amplification approach due to Badanidiyuru and Vondr\'ak to obtain a fractional solution that yields a near-optimal randomized $\left( 1 - 1/e - \epsilon \right)$-approximation in $O\left( {\frac{\log^2 n}{\epsilon^3}} \right) $ rounds of adaptivity. For non-negative functions we obtain a $\left( {3-2\sqrt{2}}\right)$-approximation and a fractional solution that yields a $\left( {\frac{1}{e} - \epsilon}\right)$-approximation. Our approach for parallelizing greedy yields approximations for intersections of matroids and matchoids, and the approximation ratios are comparable to those known for sequential greedy.},
archivePrefix = {arXiv},
arxivId = {arXiv:1811.12568v1},
author = {Chekuri, Chandra and Quanrud, Kent},
doi = {10.1145/3313276.3316406},
eprint = {arXiv:1811.12568v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chekuri, Quanrud - 2019 - Parallelizing greedy for submodular set function maximization in matroids and beyond.pdf:pdf},
isbn = {9781450367059},
issn = {07378017},
journal = {Proceedings of the Annual ACM Symposium on Theory of Computing},
keywords = {Matroids,Parallel algorithms,Submodular maximization},
pages = {78--89},
title = {{Parallelizing greedy for submodular set function maximization in matroids and beyond}},
year = {2019}
}
@inproceedings{Ene2019a,
abstract = {We consider fast algorithms for monotone submodular maximization subject to a matroid constraint. We assume that the matroid is given as input in an explicit form, and the goal is to obtain the best possible running times for important matroids. We develop a new algorithm for a \emph{general matroid constraint} with a $1 - 1/e - \epsilon$ approximation that achieves a fast running time provided we have a fast data structure for maintaining a maximum weight base in the matroid through a sequence of decrease weight operations. We construct such data structures for graphic matroids and partition matroids, and we obtain the \emph{first algorithms} for these classes of matroids that achieve a nearly-optimal, $1 - 1/e - \epsilon$ approximation, using a nearly-linear number of function evaluations and arithmetic operations.},
archivePrefix = {arXiv},
arxivId = {1811.07464},
author = {Ene, Alina and Nguyen, Huy L.},
booktitle = {ICALP},
eprint = {1811.07464},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ene, Nguyen - 2019 - A Nearly-linear Time Algorithm for Submodular Maximization with a Knapsack Constraint.pdf:pdf},
pages = {1--24},
title = {{A Nearly-linear Time Algorithm for Submodular Maximization with a Knapsack Constraint}},
url = {http://arxiv.org/abs/1811.07464},
year = {2019}
}
@inproceedings{Ene2019,
abstract = {In this work, we give a new parallel algorithm for the problem of maximizing a non-monotone diminishing returns submodular function subject to a cardinality constraint. For any desired accuracy $\epsilon$, our algorithm achieves a $1/e - \epsilon$ approximation using $O(\log{n} \log(1/\epsilon) / \epsilon^3)$ parallel rounds of function evaluations. The approximation guarantee nearly matches the best approximation guarantee known for the problem in the sequential setting and the number of parallel rounds is nearly-optimal for any constant $\epsilon$. Previous algorithms achieve worse approximation guarantees using $\Omega(\log^2{n})$ parallel rounds. Our experimental evaluation suggests that our algorithm obtains solutions whose objective value nearly matches the value obtained by the state of the art sequential algorithms, and it outperforms previous parallel algorithms in number of parallel rounds, iterations, and solution quality.},
archivePrefix = {arXiv},
arxivId = {1905.13272},
author = {Ene, Alina and Nguyen, Huy L.},
booktitle = {arXiv preprint arXiv 1905:13272},
eprint = {1905.13272},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ene, Nguyen - 2019 - Parallel Algorithm for Non-Monotone DR-Submodular Maximization.pdf:pdf},
title = {{Parallel Algorithm for Non-Monotone DR-Submodular Maximization}},
url = {http://arxiv.org/abs/1905.13272},
year = {2019}
}
@article{Lakin2019,
abstract = {{\textcopyright} 2019, The Author(s). The characterization of antimicrobial resistance genes from high-throughput sequencing data has become foundational in public health research and regulation. This requires mapping sequence reads to databases of known antimicrobial resistance genes to determine the genes present in the sample. Mapping sequence reads to known genes is traditionally accomplished using alignment. Alignment methods have high specificity but are limited in their ability to detect sequences that are divergent from the reference database, which can result in a substantial false negative rate. We address this shortcoming through the creation of Meta-MARC, which enables detection of diverse resistance sequences using hierarchical, DNA-based Hidden Markov Models. We first describe Meta-MARC and then demonstrate its efficacy on simulated and functional metagenomic datasets. Meta-MARC has higher sensitivity relative to competing methods. This sensitivity allows for detection of sequences that are divergent from known antimicrobial resistance genes. This functionality is imperative to expanding existing antimicrobial gene databases.},
author = {Lakin, S.M. and Kuhnle, A. and Alipanahi, B. and Noyes, N.R. and Dean, C. and Muggli, M. and Raymond, R. and Abdo, Z. and Prosperi, M. and Belk, K.E. and Morley, P.S. and Boucher, C.},
doi = {10.1038/s42003-019-0545-9},
issn = {23993642},
journal = {Communications Biology},
number = {1},
title = {{Hierarchical Hidden Markov models enable accurate and diverse detection of antimicrobial resistance sequences}},
volume = {2},
year = {2019}
}
@article{Sakaue2019,
abstract = {The stochastic greedy algorithm (SG) is a randomized version of the greedy algorithm for submodular maximization with a size constraint. SG is highly practical since it is fast, delivers high empirical performance, and is easy to implement. However, its approximation guarantee has been proved only for monotone objective functions; this is natural since the original greedy algorithm is known to perform arbitrarily poorly for non-monotone objectives in general. In this paper, contrary to the expectation, we prove an interesting result: Thanks to the randomization, SG (with slight modification) can achieve almost $1/4$-approximation guarantees in expectation even for non-monotone objective functions. Our result provides practical and theoretically guaranteed algorithms for non-monotone submodular maximization with size a constraint, which run far faster and achieve as good objective values as existing algorithms.},
archivePrefix = {arXiv},
arxivId = {1908.06242},
author = {Sakaue, Shinsaku},
eprint = {1908.06242},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sakaue - 2019 - Approximation Guarantees of Stochastic Greedy Algorithms for Non-monotone Submodular Maximization with a Size Constraint.pdf:pdf},
month = {aug},
title = {{Approximation Guarantees of Stochastic Greedy Algorithms for Non-monotone Submodular Maximization with a Size Constraint}},
url = {http://arxiv.org/abs/1908.06242},
year = {2019}
}
@inproceedings{Jacot2018,
abstract = {At initialization, artificial neural networks (ANNs) are equivalent to Gaussian processes in the infinite-width limit, thus connecting them to kernel methods. We prove that the evolution of an ANN during training can also be described by a kernel: during gradient descent on the parameters of an ANN, the network function $f_\theta$ (which maps input vectors to output vectors) follows the kernel gradient of the functional cost (which is convex, in contrast to the parameter cost) w.r.t. a new kernel: the Neural Tangent Kernel (NTK). This kernel is central to describe the generalization features of ANNs. While the NTK is random at initialization and varies during training, in the infinite-width limit it converges to an explicit limiting kernel and it stays constant during training. This makes it possible to study the training of ANNs in function space instead of parameter space. Convergence of the training can then be related to the positive-definiteness of the limiting NTK. We prove the positive-definiteness of the limiting NTK when the data is supported on the sphere and the non-linearity is non-polynomial. We then focus on the setting of least-squares regression and show that in the infinite-width limit, the network function $f_\theta$ follows a linear differential equation during training. The convergence is fastest along the largest kernel principal components of the input data with respect to the NTK, hence suggesting a theoretical motivation for early stopping. Finally we study the NTK numerically, observe its behavior for wide networks, and compare it to the infinite-width limit.},
author = {Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'{e}}ment},
booktitle = {Advances in Neural Information Processing Systems},
issn = {10495258},
pages = {8571--8580},
publisher = {Neural information processing systems foundation},
title = {{Neural tangent kernel: Convergence and generalization in neural networks}},
volume = {2018-Decem},
year = {2018}
}
@article{Bilmes2017,
abstract = {We start with an overview of a class of submodular functions called SCMMs (sums of concave composed with non-negative modular functions plus a final arbitrary modular). We then define a new class of submodular functions we call {\em deep submodular functions} or DSFs. We show that DSFs are a flexible parametric family of submodular functions that share many of the properties and advantages of deep neural networks (DNNs). DSFs can be motivated by considering a hierarchy of descriptive concepts over ground elements and where one wishes to allow submodular interaction throughout this hierarchy. Results in this paper show that DSFs constitute a strictly larger class of submodular functions than SCMMs. We show that, for any integer $k>0$, there are $k$-layer DSFs that cannot be represented by a $k'$-layer DSF for any $k'<k$. This implies that, like DNNs, there is a utility to depth, but unlike DNNs, the family of DSFs strictly increase with depth. Despite this, we show (using a "backpropagation" like method) that DSFs, even with arbitrarily large $k$, do not comprise all submodular functions. In offering the above results, we also define the notion of an antitone superdifferential of a concave function and show how this relates to submodular functions (in general), DSFs (in particular), negative second-order partial derivatives, continuous submodularity, and concave extensions. To further motivate our analysis, we provide various special case results from matroid theory, comparing DSFs with forms of matroid rank, in particular the laminar matroid. Lastly, we discuss strategies to learn DSFs, and define the classes of deep supermodular functions, deep difference of submodular functions, and deep multivariate submodular functions, and discuss where these can be useful in applications.},
archivePrefix = {arXiv},
arxivId = {1701.08939},
author = {Bilmes, Jeffrey and Bai, Wenruo},
eprint = {1701.08939},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bilmes, Bai - 2017 - Deep Submodular Functions.pdf:pdf},
month = {jan},
title = {{Deep Submodular Functions}},
url = {http://arxiv.org/abs/1701.08939},
year = {2017}
}
@article{Salimans2017,
abstract = {We explore the use of Evolution Strategies (ES), a class of black box optimization algorithms, as an alternative to popular MDP-based RL techniques such as Q-learning and Policy Gradients. Experiments on MuJoCo and Atari show that ES is a viable solution strategy that scales extremely well with the number of CPUs available: By using a novel communication strategy based on common random numbers, our ES implementation only needs to communicate scalars, making it possible to scale to over a thousand parallel workers. This allows us to solve 3D humanoid walking in 10 minutes and obtain competitive results on most Atari games after one hour of training. In addition, we highlight several advantages of ES as a black box optimization technique: it is invariant to action frequency and delayed rewards, tolerant of extremely long horizons, and does not need temporal discounting or value function approximation.},
archivePrefix = {arXiv},
arxivId = {1703.03864},
author = {Salimans, Tim and Ho, Jonathan and Chen, Xi and Sidor, Szymon and Sutskever, Ilya},
eprint = {1703.03864},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Salimans et al. - 2017 - Evolution Strategies as a Scalable Alternative to Reinforcement Learning.pdf:pdf},
month = {mar},
title = {{Evolution Strategies as a Scalable Alternative to Reinforcement Learning}},
url = {http://arxiv.org/abs/1703.03864},
year = {2017}
}
@article{Jaderberg2017,
abstract = {Neural networks dominate the modern machine learning landscape, but their training and success still suffer from sensitivity to empirical choices of hyperparameters such as model architecture, loss function, and optimisation algorithm. In this work we present \emph{Population Based Training (PBT)}, a simple asynchronous optimisation algorithm which effectively utilises a fixed computational budget to jointly optimise a population of models and their hyperparameters to maximise performance. Importantly, PBT discovers a schedule of hyperparameter settings rather than following the generally sub-optimal strategy of trying to find a single fixed set to use for the whole course of training. With just a small modification to a typical distributed hyperparameter training framework, our method allows robust and reliable training of models. We demonstrate the effectiveness of PBT on deep reinforcement learning problems, showing faster wall-clock convergence and higher final performance of agents by optimising over a suite of hyperparameters. In addition, we show the same method can be applied to supervised learning for machine translation, where PBT is used to maximise the BLEU score directly, and also to training of Generative Adversarial Networks to maximise the Inception score of generated images. In all cases PBT results in the automatic discovery of hyperparameter schedules and model selection which results in stable training and better final performance.},
archivePrefix = {arXiv},
arxivId = {1711.09846},
author = {Jaderberg, Max and Dalibard, Valentin and Osindero, Simon and Czarnecki, Wojciech M. and Donahue, Jeff and Razavi, Ali and Vinyals, Oriol and Green, Tim and Dunning, Iain and Simonyan, Karen and Fernando, Chrisantha and Kavukcuoglu, Koray},
eprint = {1711.09846},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaderberg et al. - 2017 - Population Based Training of Neural Networks.pdf:pdf},
month = {nov},
title = {{Population Based Training of Neural Networks}},
url = {http://arxiv.org/abs/1711.09846},
year = {2017}
}
@article{Stanley2019,
abstract = {Much of recent machine learning has focused on deep learning, in which neural network weights are trained through variants of stochastic gradient descent. An alternative approach comes from the field of neuroevolution, which harnesses evolutionary algorithms to optimize neural networks, inspired by the fact that natural brains themselves are the products of an evolutionary process. Neuroevolution enables important capabilities that are typically unavailable to gradient-based approaches, including learning neural network building blocks (for example activation functions), hyperparameters, architectures and even the algorithms for learning themselves. Neuroevolution also differs from deep learning (and deep reinforcement learning) by maintaining a population of solutions during search, enabling extreme exploration and massive parallelization. Finally, because neuroevolution research has (until recently) developed largely in isolation from gradient-based neural network research, it has developed many unique and effective techniques that should be effective in other machine learning areas too. This Review looks at several key aspects of modern neuroevolution, including large-scale computing, the benefits of novelty and diversity, the power of indirect encoding, and the field's contributions to meta-learning and architecture search. Our hope is to inspire renewed interest in the field as it meets the potential of the increasing computation available today, to highlight how many of its ideas can provide an exciting resource for inspiration and hybridization to the deep learning, deep reinforcement learning and machine learning communities, and to explain how neuroevolution could prove to be a critical tool in the long-term pursuit of artificial general intelligence.},
author = {Stanley, Kenneth O. and Clune, Jeff and Lehman, Joel and Miikkulainen, Risto},
doi = {10.1038/s42256-018-0006-z},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stanley et al. - 2019 - Designing neural networks through neuroevolution.pdf:pdf},
journal = {Nature Machine Intelligence},
month = {jan},
number = {1},
pages = {24--35},
publisher = {Springer Nature},
title = {{Designing neural networks through neuroevolution}},
volume = {1},
year = {2019}
}
@inproceedings{Conti2018,
abstract = {Evolution strategies (ES) are a family of black-box optimization algorithms able to train deep neural networks roughly as well as Q-learning and policy gradient methods on challenging deep reinforcement learning (RL) problems, but are much faster (e.g. hours vs. days) because they parallelize better. However, many RL problems require directed exploration because they have reward functions that are sparse or deceptive (i.e. contain local optima), and it is unknown how to encourage such exploration with ES. Here we show that algorithms that have been invented to promote directed exploration in small-scale evolved neural networks via populations of exploring agents, specifically novelty search (NS) and quality diversity (QD) algorithms, can be hybridized with ES to improve its performance on sparse or deceptive deep RL tasks, while retaining scalability. Our experiments confirm that the resultant new algorithms, NS-ES and two QD algorithms, NSR-ES and NSRA-ES, avoid local optima encountered by ES to achieve higher performance on Atari and simulated robots learning to walk around a deceptive trap. This paper thus introduces a family of fast, scalable algorithms for reinforcement learning that are capable of directed exploration. It also adds this new family of exploration algorithms to the RL toolbox and raises the interesting possibility that analogous algorithms with multiple simultaneous paths of exploration might also combine well with existing RL algorithms outside ES.},
author = {Conti, Edoardo and Madhavan, Vashisht and Such, Felipe Petroski and Lehman, Joel and Stanley, Kenneth O. and Clune, Jeff},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Conti et al. - 2018 - Improving exploration in evolution strategies for deep reinforcement learning via a population of novelty-seeking.pdf:pdf},
issn = {10495258},
pages = {5027--5038},
publisher = {Neural information processing systems foundation},
title = {{Improving exploration in evolution strategies for deep reinforcement learning via a population of novelty-seeking agents}},
volume = {2018-Decem},
year = {2018}
}
@article{Shafahi2019,
abstract = {Adversarial training, in which a network is trained on adversarial examples, is one of the few defenses against adversarial attacks that withstands strong attacks. Unfortunately, the high cost of generating strong adversarial examples makes standard adversarial training impractical on large-scale problems like ImageNet. We present an algorithm that eliminates the overhead cost of generating adversarial examples by recycling the gradient information computed when updating model parameters. Our "free" adversarial training algorithm achieves state-of-the-art robustness on CIFAR-10 and CIFAR-100 datasets at negligible additional cost compared to natural training, and can be 7 to 30 times faster than other strong adversarial training methods. Using a single workstation with 4 P100 GPUs and 2 days of runtime, we can train a robust model for the large-scale ImageNet classification task that maintains 40% accuracy against PGD attacks.},
archivePrefix = {arXiv},
arxivId = {1904.12843},
author = {Shafahi, Ali and Najibi, Mahyar and Ghiasi, Amin and Xu, Zheng and Dickerson, John and Studer, Christoph and Davis, Larry S. and Taylor, Gavin and Goldstein, Tom},
eprint = {1904.12843},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shafahi et al. - 2019 - Adversarial Training for Free!.pdf:pdf},
month = {apr},
title = {{Adversarial Training for Free!}},
url = {http://arxiv.org/abs/1904.12843},
year = {2019}
}
@article{Lee2017,
abstract = {It has long been known that a single-layer fully-connected neural network with an i.i.d. prior over its parameters is equivalent to a Gaussian process (GP), in the limit of infinite network width. This correspondence enables exact Bayesian inference for infinite width neural networks on regression tasks by means of evaluating the corresponding GP. Recently, kernel functions which mimic multi-layer random neural networks have been developed, but only outside of a Bayesian framework. As such, previous work has not identified that these kernels can be used as covariance functions for GPs and allow fully Bayesian prediction with a deep neural network. In this work, we derive the exact equivalence between infinitely wide deep networks and GPs. We further develop a computationally efficient pipeline to compute the covariance function for these GPs. We then use the resulting GPs to perform Bayesian inference for wide deep neural networks on MNIST and CIFAR-10. We observe that trained neural network accuracy approaches that of the corresponding GP with increasing layer width, and that the GP uncertainty is strongly correlated with trained network prediction error. We further find that test performance increases as finite-width trained networks are made wider and more similar to a GP, and thus that GP predictions typically outperform those of finite-width networks. Finally we connect the performance of these GPs to the recent theory of signal propagation in random neural networks.},
archivePrefix = {arXiv},
arxivId = {1711.00165},
author = {Lee, Jaehoon and Bahri, Yasaman and Novak, Roman and Schoenholz, Samuel S. and Pennington, Jeffrey and Sohl-Dickstein, Jascha},
eprint = {1711.00165},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2017 - Deep Neural Networks as Gaussian Processes.pdf:pdf},
month = {oct},
title = {{Deep Neural Networks as Gaussian Processes}},
url = {http://arxiv.org/abs/1711.00165},
year = {2017}
}
@inproceedings{Orseau2018,
abstract = {We introduce two novel tree search algorithms that use a policy to guide search. The first algorithm is a best-first enumeration that uses a cost function that allows us to prove an upper bound on the number of nodes to be expanded before reaching a goal state. We show that this best-first algorithm is particularly well suited for `needle-in-a-haystack' problems. The second algorithm is based on sampling and we prove an upper bound on the expected number of nodes it expands before reaching a set of goal states. We show that this algorithm is better suited for problems where many paths lead to a goal. We validate these tree search algorithms on 1,000 computer-generated levels of Sokoban, where the policy used to guide the search comes from a neural network trained using A3C. Our results show that the policy tree search algorithms we introduce are competitive with a state-of-the-art domain-independent planner that uses heuristic search.},
author = {Orseau, Laurent and Lattimore, Tor and Lelis, Levi H.S. and Weber, Th{\'{e}}ophane},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Orseau et al. - 2018 - Single-agent policy tree search with guarantees.pdf:pdf},
issn = {10495258},
pages = {3201--3211},
publisher = {Neural information processing systems foundation},
title = {{Single-agent policy tree search with guarantees}},
volume = {2018-Decem},
year = {2018}
}
@article{Mirzasoleiman2019,
abstract = {Many machine learning problems reduce to the problem of minimizing an expected risk, defined as the sum of a large number of, often convex, component functions. Iterative gradient methods are popular techniques for the above problems. However, they are in general slow to converge, in particular for large data sets. In this work, we develop analysis for selecting a subset (or sketch) of training data points with their corresponding learning rates in order to provide faster convergence to a close neighbordhood of the optimal solution. We show that subsets that minimize the upper-bound on the estimation error of the full gradient, maximize a submodular facility location function. As a result, by greedily maximizing the facility location function we obtain subsets that yield faster convergence to a close neighborhood of the optimum solution. We demonstrate the real-world effectiveness of our algorithm, SIG, confirming our analysis, through an extensive set of experiments on several applications, including logistic regression and training neural networks. We also include a method that provides a deliberate deterministic ordering of the data subset that is quite effective in practice. We observe that our method, while achieving practically the same loss, speeds up gradient methods by up to 10x for convex and 3x for non-convex (deep) functions.},
archivePrefix = {arXiv},
arxivId = {1906.01827},
author = {Mirzasoleiman, Baharan and Bilmes, Jeff and Leskovec, Jure},
eprint = {1906.01827},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mirzasoleiman, Bilmes, Leskovec - 2019 - Data Sketching for Faster Training of Machine Learning Models.pdf:pdf},
month = {jun},
title = {{Data Sketching for Faster Training of Machine Learning Models}},
url = {http://arxiv.org/abs/1906.01827},
year = {2019}
}
@article{Gorbunov2019,
abstract = {In this paper we introduce a unified analysis of a large family of variants of proximal stochastic gradient descent ({\tt SGD}) which so far have required different intuitions, convergence analyses, have different applications, and which have been developed separately in various communities. We show that our framework includes methods with and without the following tricks, and their combinations: variance reduction, importance sampling, mini-batch sampling, quantization, and coordinate sub-sampling. As a by-product, we obtain the first unified theory of {\tt SGD} and randomized coordinate descent ({\tt RCD}) methods, the first unified theory of variance reduced and non-variance-reduced {\tt SGD} methods, and the first unified theory of quantized and non-quantized methods. A key to our approach is a parametric assumption on the iterates and stochastic gradients. In a single theorem we establish a linear convergence result under this assumption and strong-quasi convexity of the loss function. Whenever we recover an existing method as a special case, our theorem gives the best known complexity result. Our approach can be used to motivate the development of new useful methods, and offers pre-proved convergence guarantees. To illustrate the strength of our approach, we develop five new variants of {\tt SGD}, and through numerical experiments demonstrate some of their properties.},
archivePrefix = {arXiv},
arxivId = {1905.11261},
author = {Gorbunov, Eduard and Hanzely, Filip and Richt{\'{a}}rik, Peter},
eprint = {1905.11261},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gorbunov, Hanzely, Richt{\'{a}}rik - 2019 - A Unified Theory of SGD Variance Reduction, Sampling, Quantization and Coordinate Descent.pdf:pdf},
month = {may},
title = {{A Unified Theory of SGD: Variance Reduction, Sampling, Quantization and Coordinate Descent}},
url = {http://arxiv.org/abs/1905.11261},
year = {2019}
}
@techreport{Cortes,
abstract = {We present two novel enhancements of an on-line importance-weighted active learning algorithm IWAL, using the properties of disagreements among hypotheses. The first enhancement, IWAL-D, prunes the hypothesis set with a more aggressive strategy based on the disagreement graph. We show that IWAL-D improves the generalization performance and the label complexity of the original IWAL, and quantify the improvement in terms of a disagreement graph coefficient. The second enhancement, IZOOM, further improves IWAL-D by adaptively zooming into the current version space and thus reducing the best-in-class error. We show that IZOOM admits favorable theoretical guarantees with the changing hypothesis set. We report experimental results on multiple datasets and demonstrate that the proposed algorithms achieve better test performances than IWAL given the same amount of labeling budget.},
author = {Cortes, Corinna and Desalvo, Giulia and Gentile, Claudio and Mohri, Mehryar and Zhang, Ningshan},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cortes et al. - Unknown - Active Learning with Disagreement Graphs.pdf:pdf},
title = {{Active Learning with Disagreement Graphs}}
}
@article{Bian2018a,
abstract = {Mean field inference in probabilistic models is generally a highly nonconvex problem. Existing optimization methods, e.g., coordinate ascent algorithms, can only generate local optima. In this work we propose provable mean filed methods for probabilistic log-submodular models and its posterior agreement (PA) with strong approximation guarantees. The main algorithmic technique is a new Double Greedy scheme, termed DR-DoubleGreedy, for continuous DR-submodular maximization with box-constraints. It is a one-pass algorithm with linear time complexity, reaching the optimal 1/2 approximation ratio, which may be of independent interest. We validate the superior performance of our algorithms against baseline algorithms on both synthetic and real-world datasets.},
archivePrefix = {arXiv},
arxivId = {1805.07482},
author = {Bian, An and Buhmann, Joachim M. and Krause, Andreas},
eprint = {1805.07482},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bian, Buhmann, Krause - 2018 - Optimal DR-Submodular Maximization and Applications to Provable Mean Field Inference(2).pdf:pdf},
month = {may},
title = {{Optimal DR-Submodular Maximization and Applications to Provable Mean Field Inference}},
url = {http://arxiv.org/abs/1805.07482},
year = {2018}
}
@misc{Shahriari2016,
abstract = {—Big data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., rec-ommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involves many tunable config-uration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.},
author = {Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P. and {De Freitas}, Nando},
booktitle = {Proceedings of the IEEE},
doi = {10.1109/JPROC.2015.2494218},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shahriari et al. - 2016 - Taking the human out of the loop A review of Bayesian optimization.pdf:pdf},
issn = {00189219},
keywords = {decision making,design of experiments,genomic medicine,optimization,response surface methodology,statistical learning},
month = {jan},
number = {1},
pages = {148--175},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Taking the human out of the loop: A review of Bayesian optimization}},
volume = {104},
year = {2016}
}
@article{Assadi2019,
abstract = {Maximum weight matching is one of the most fundamental combinatorial optimization problems with a wide range of applications in data mining and bioinformatics. Developing distributed weighted matching algorithms is challenging due to the sequential nature of efficient algorithms for this problem. In this paper, we develop a simple distributed algorithm for the problem on general graphs with approximation guarantee of $2+\varepsilon$ that (nearly) matches that of the sequential greedy algorithm. A key advantage of this algorithm is that it can be easily implemented in only two rounds of computation in modern parallel computation frameworks such as MapReduce. We also demonstrate the efficiency of our algorithm in practice on various graphs (some with half a trillion edges) by achieving objective values always close to what is achievable in the centralized setting.},
archivePrefix = {arXiv},
arxivId = {1906.01993},
author = {Assadi, Sepehr and Bateni, MohammadHossein and Mirrokni, Vahab},
eprint = {1906.01993},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Assadi, Bateni, Mirrokni - 2019 - Distributed Weighted Matching via Randomized Composable Coresets.pdf:pdf},
month = {jun},
title = {{Distributed Weighted Matching via Randomized Composable Coresets}},
url = {http://arxiv.org/abs/1906.01993},
year = {2019}
}
@article{Mohri2019a,
abstract = {A key learning scenario in large-scale applications is that of federated learning, where a centralized model is trained based on data originating from a large number of clients. We argue that, with the existing training and inference, federated models can be biased towards different clients. Instead, we propose a new framework of agnostic federated learning, where the centralized model is optimized for any target distribution formed by a mixture of the client distributions. We further show that this framework naturally yields a notion of fairness. We present data-dependent Rademacher complexity guarantees for learning with this objective, which guide the definition of an algorithm for agnostic federated learning. We also give a fast stochastic optimization algorithm for solving the corresponding optimization problem, for which we prove convergence bounds, assuming a convex loss function and hypothesis set. We further empirically demonstrate the benefits of our approach in several datasets. Beyond federated learning, our framework and algorithm can be of interest to other learning scenarios such as cloud computing, domain adaptation, drifting, and other contexts where the training and test distributions do not coincide.},
archivePrefix = {arXiv},
arxivId = {1902.00146},
author = {Mohri, Mehryar and Sivek, Gary and Suresh, Ananda Theertha},
eprint = {1902.00146},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohri, Sivek, Suresh - 2019 - Agnostic Federated Learning.pdf:pdf},
month = {jan},
title = {{Agnostic Federated Learning}},
url = {http://arxiv.org/abs/1902.00146},
year = {2019}
}
@article{Vaswani2018,
abstract = {Modern machine learning focuses on highly expressive models that are able to fit or interpolate the data completely, resulting in zero training loss. For such models, we show that the stochastic gradients of common loss functions satisfy a strong growth condition. Under this condition, we prove that constant step-size stochastic gradient descent (SGD) with Nesterov acceleration matches the convergence rate of the deterministic accelerated method for both convex and strongly-convex functions. We also show that this condition implies that SGD can find a first-order stationary point as efficiently as full gradient descent in non-convex settings. Under interpolation, we further show that all smooth loss functions with a finite-sum structure satisfy a weaker growth condition. Given this weaker condition, we prove that SGD with a constant step-size attains the deterministic convergence rate in both the strongly-convex and convex settings. Under additional assumptions, the above results enable us to prove an O(1/k^2) mistake bound for k iterations of a stochastic perceptron algorithm using the squared-hinge loss. Finally, we validate our theoretical findings with experiments on synthetic and real datasets.},
archivePrefix = {arXiv},
arxivId = {1810.07288},
author = {Vaswani, Sharan and Bach, Francis and Schmidt, Mark},
eprint = {1810.07288},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vaswani, Bach, Schmidt - 2018 - Fast and Faster Convergence of SGD for Over-Parameterized Models and an Accelerated Perceptron.pdf:pdf},
month = {oct},
title = {{Fast and Faster Convergence of SGD for Over-Parameterized Models and an Accelerated Perceptron}},
url = {http://arxiv.org/abs/1810.07288},
year = {2018}
}
@article{McInnes2018,
abstract = {UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.},
archivePrefix = {arXiv},
arxivId = {1802.03426},
author = {McInnes, Leland and Healy, John and Melville, James},
eprint = {1802.03426},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McInnes, Healy, Melville - 2018 - UMAP Uniform Manifold Approximation and Projection for Dimension Reduction.pdf:pdf},
month = {feb},
title = {{UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction}},
url = {http://arxiv.org/abs/1802.03426},
year = {2018}
}
@techreport{Rostamizadeh,
author = {Rostamizadeh, Afshin and Talwalkar, Ameet},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohri, Rostamizadeh, Talwalkar. - 2019 - Foundations of Machine Learning.pdf:pdf},
title = {{Foundations of Machine Learning second edition}}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - theMLbook.pdf:pdf},
title = {{theMLbook}}
}
@article{Dacrema2019,
abstract = {Deep learning techniques have become the method of choice for researchers working on algorithmic aspects of recommender systems. With the strongly increased interest in machine learning in general, it has, as a result, become difficult to keep track of what represents the state-of-the-art at the moment, e.g., for top-n recommendation tasks. At the same time, several recent publications point out problems in today's research practice in applied machine learning, e.g., in terms of the reproducibility of the results or the choice of the baselines when proposing new models. In this work, we report the results of a systematic analysis of algorithmic proposals for top-n recommendation tasks. Specifically, we considered 18 algorithms that were presented at top-level research conferences in the last years. Only 7 of them could be reproduced with reasonable effort. For these methods, it however turned out that 6 of them can often be outperformed with comparably simple heuristic methods, e.g., based on nearest-neighbor or graph-based techniques. The remaining one clearly outperformed the baselines but did not consistently outperform a well-tuned non-neural linear ranking method. Overall, our work sheds light on a number of potential problems in today's machine learning scholarship and calls for improved scientific practices in this area. Source code of our experiments and full results are available at: https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation.},
archivePrefix = {arXiv},
arxivId = {1907.06902},
author = {Dacrema, Maurizio Ferrari and Cremonesi, Paolo and Jannach, Dietmar},
doi = {10.1145/3298689.3347058},
eprint = {1907.06902},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dacrema, Cremonesi, Jannach - 2019 - Are We Really Making Much Progress A Worrying Analysis of Recent Neural Recommendation Approaches.pdf:pdf},
month = {jul},
title = {{Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches}},
url = {http://arxiv.org/abs/1907.06902 http://dx.doi.org/10.1145/3298689.3347058},
year = {2019}
}
@article{Mohri2019,
abstract = {In distributed learning, the goal is to perform a learning task over data distributed across multiple nodes with minimal (expensive) communication. Prior work (Daume III et al., 2012) proposes a general model that bounds the communication required for learning classifiers while allowing for $\eps$ training error on linearly separable data adversarially distributed across nodes. In this work, we develop key improvements and extensions to this basic model. Our first result is a two-party multiplicative-weight-update based protocol that uses $O(d^2 \log{1/\eps})$ words of communication to classify distributed data in arbitrary dimension $d$, $\eps$-optimally. This readily extends to classification over $k$ nodes with $O(kd^2 \log{1/\eps})$ words of communication. Our proposed protocol is simple to implement and is considerably more efficient than baselines compared, as demonstrated by our empirical results. In addition, we illustrate general algorithm design paradigms for doing efficient learning over distributed data. We show how to solve fixed-dimensional and high dimensional linear programming efficiently in a distributed setting where constraints may be distributed across nodes. Since many learning problems can be viewed as convex optimization problems where constraints are generated by individual points, this models many typical distributed learning scenarios. Our techniques make use of a novel connection from multipass streaming, as well as adapting the multiplicative-weight-update framework more generally to a distributed setting. As a consequence, our methods extend to the wide range of problems solvable using these techniques.},
author = {Mohri and Rostamizadeh and Talwalkar.},
doi = {10.2139/ssrn.3399990},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohri, Rostamizadeh, Talwalkar. - 2019 - Foundations of Machine Learning.pdf:pdf},
journal = {SSRN Electronic Journal},
month = {jun},
publisher = {Elsevier BV},
title = {{Foundations of Machine Learning}},
year = {2019}
}
@article{Jain2019,
abstract = {We study stochastic gradient descent {\em without replacement} (\sgdwor) for smooth convex functions. \sgdwor is widely observed to converge faster than true \sgd where each sample is drawn independently {\em with replacement}$\sim$\cite{bottou2009curiously} and hence, is more popular in practice. But it's convergence properties are not well understood as sampling without replacement leads to coupling between iterates and gradients. By using method of exchangeable pairs to bound Wasserstein distance, we provide the first non-asymptotic results for \sgdwor when applied to {\em general smooth, strongly-convex} functions. In particular, we show that \sgdwor converges at a rate of $O(1/K^2)$ while \sgd$\sim$is known to converge at $O(1/K)$ rate, where $K$ denotes the number of passes over data and is required to be {\em large enough}. Existing results for \sgdwor in this setting require additional {\em Hessian Lipschitz assumption}$\sim$\cite{gurbuzbalaban2015random,haochen2018random}. For {\em small} $K$, we show \sgdwor can achieve same convergence rate as \sgd for {\em general smooth strongly-convex} functions. Existing results in this setting require $K=1$ and hold only for generalized linear models \cite{shamir2016without}. In addition, by careful analysis of the coupling, for both large and small $K$, we obtain better dependence on problem dependent parameters like condition number.},
archivePrefix = {arXiv},
arxivId = {1903.01463},
author = {Jain, Prateek and Nagaraj, Dheeraj and Netrapalli, Praneeth},
eprint = {1903.01463},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jain, Nagaraj, Netrapalli - 2019 - SGD without Replacement Sharper Rates for General Smooth Convex Functions.pdf:pdf;:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jain, Nagaraj, Netrapalli - 2019 - SGD without Replacement Sharper Rates for General Smooth Convex Functions(2).pdf:pdf},
month = {mar},
title = {{SGD without Replacement: Sharper Rates for General Smooth Convex Functions}},
url = {http://arxiv.org/abs/1903.01463},
year = {2019}
}
@article{Metz2018,
abstract = {A major goal of unsupervised learning is to discover data representations that are useful for subsequent tasks, without access to supervised labels during training. Typically, this involves minimizing a surrogate objective, such as the negative log likelihood of a generative model, with the hope that representations useful for subsequent tasks will arise as a side effect. In this work, we propose instead to directly target later desired tasks by meta-learning an unsupervised learning rule which leads to representations useful for those tasks. Specifically, we target semi-supervised classification performance, and we meta-learn an algorithm -- an unsupervised weight update rule -- that produces representations useful for this task. Additionally, we constrain our unsupervised update rule to a be a biologically-motivated, neuron-local function, which enables it to generalize to different neural network architectures, datasets, and data modalities. We show that the meta-learned update rule produces useful features and sometimes outperforms existing unsupervised learning techniques. We further show that the meta-learned unsupervised update rule generalizes to train networks with different widths, depths, and nonlinearities. It also generalizes to train on data with randomly permuted input dimensions and even generalizes from image datasets to a text task.},
archivePrefix = {arXiv},
arxivId = {1804.00222},
author = {Metz, Luke and Maheswaranathan, Niru and Cheung, Brian and Sohl-Dickstein, Jascha},
eprint = {1804.00222},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Metz et al. - 2018 - Meta-Learning Update Rules for Unsupervised Representation Learning.pdf:pdf},
month = {mar},
title = {{Meta-Learning Update Rules for Unsupervised Representation Learning}},
url = {http://arxiv.org/abs/1804.00222},
year = {2018}
}
@inproceedings{Lu2019,
author = {Lu, Songtao and Zhao, Ziping and Huang, Kejun and Hong, Mingyi},
doi = {10.1109/icassp.2019.8683241},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu et al. - 2019 - Perturbed Projected Gradient Descent Converges to Approximate Second-order Points for Bound Constrained Nonconvex Pro.pdf:pdf},
month = {apr},
pages = {5356--5360},
publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
title = {{Perturbed Projected Gradient Descent Converges to Approximate Second-order Points for Bound Constrained Nonconvex Problems}},
year = {2019}
}
@article{Karimireddy2019a,
abstract = {Sign-based algorithms (e.g. signSGD) have been proposed as a biased gradient compression technique to alleviate the communication bottleneck in training large neural networks across multiple workers. We show simple convex counter-examples where signSGD does not converge to the optimum. Further, even when it does converge, signSGD may generalize poorly when compared with SGD. These issues arise because of the biased nature of the sign compression operator. We then show that using error-feedback, i.e. incorporating the error made by the compression operator into the next step, overcomes these issues. We prove that our algorithm EF-SGD achieves the same rate of convergence as SGD without any additional assumptions for arbitrary compression operators (including the sign operator), indicating that we get gradient compression for free. Our experiments thoroughly substantiate the theory showing the superiority of our algorithm.},
archivePrefix = {arXiv},
arxivId = {1901.09847},
author = {Karimireddy, Sai Praneeth and Rebjock, Quentin and Stich, Sebastian U. and Jaggi, Martin},
eprint = {1901.09847},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karimireddy et al. - 2019 - Error Feedback Fixes SignSGD and other Gradient Compression Schemes(3).pdf:pdf},
month = {jan},
title = {{Error Feedback Fixes SignSGD and other Gradient Compression Schemes}},
url = {http://arxiv.org/abs/1901.09847},
year = {2019}
}
@article{Karimireddy2019b,
abstract = {Sign-based algorithms (e.g. signSGD) have been proposed as a biased gradient compression technique to alleviate the communication bottleneck in training large neural networks across multiple workers. We show simple convex counter-examples where signSGD does not converge to the optimum. Further, even when it does converge, signSGD may generalize poorly when compared with SGD. These issues arise because of the biased nature of the sign compression operator. We then show that using error-feedback, i.e. incorporating the error made by the compression operator into the next step, overcomes these issues. We prove that our algorithm EF-SGD achieves the same rate of convergence as SGD without any additional assumptions for arbitrary compression operators (including the sign operator), indicating that we get gradient compression for free. Our experiments thoroughly substantiate the theory showing the superiority of our algorithm.},
archivePrefix = {arXiv},
arxivId = {1901.09847},
author = {Karimireddy, Sai Praneeth and Rebjock, Quentin and Stich, Sebastian U. and Jaggi, Martin},
eprint = {1901.09847},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karimireddy et al. - 2019 - Error Feedback Fixes SignSGD and other Gradient Compression Schemes(2).pdf:pdf},
month = {jan},
title = {{Error Feedback Fixes SignSGD and other Gradient Compression Schemes}},
url = {http://arxiv.org/abs/1901.09847},
year = {2019}
}
@inproceedings{Chekuri2018,
abstract = {Balkanski and Singer [4] recently initiated the study of adaptivity (or parallelism) for constrained submodular function maximization, and studied the setting of a cardinality constraint. Subsequent improvements for this problem by Balkanski, Rubinstein, and Singer [6] and Ene and Nguyen [21] resulted in a near-optimal (1−1/e−)-approximation in O(log n/2) rounds of adaptivity. Partly motivated by the goal of extending these results to more general constraints, we describe parallel algorithms for approximately maximizing the multilinear relaxation of a monotone submodular function subject to packing constraints. Formally our problem is to maximize F(x) over x ∈ [0,1]n subject to Ax ≤ 1 where F is the multilinear relaxation of a monotone submodular function. Our algorithm achieves a near-optimal (1 − 1/e − )-approximation in O(log2 mlog n/4) rounds where n is the cardinality of the ground set and m is the number of packing constraints. For many constraints of interest, the resulting fractional solution can be rounded via known randomized rounding schemes that are oblivious to the specific submodular function. We thus derive randomized algorithms with poly-logarithmic adaptivity for a number of constraints including partition and laminar matroids, matchings, knapsack constraints, and their intersections. Our algorithm takes a continuous view point and combines several ideas ranging from the continuous greedy algorithm of [38, 13], its adaptation to the MWU framework for packing constraints [20], and parallel algorithms for packing LPs [31, 41]. For the basic setting of cardinality constraints, this viewpoint gives rise to an alternative, simple to understand algorithm that matches recent results [6, 21]. Our algorithm to solve the multilinear relaxation is deterministic if it is given access to a value oracle for the multilinear extension and its gradient; this is possible in some interesting cases such as the coverage function of an explicitly given set system.},
archivePrefix = {arXiv},
arxivId = {1807.08678},
author = {Chekuri, Chandra and Quanrud, Kent},
booktitle = {Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
doi = {10.1137/1.9781611975482.20},
eprint = {1807.08678},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chekuri, Quanrud - 2019 - Submodular function maximization in parallel via the multilinear relaxation.pdf:pdf},
month = {jul},
pages = {303--322},
title = {{Submodular function maximization in parallel via the multilinear relaxation}},
url = {http://arxiv.org/abs/1807.08678},
year = {2019}
}
@inproceedings{Chekuri2018a,
abstract = {Balkanski and Singer [4] recently initiated the study of adaptivity (or parallelism) for constrained submodular function maximization, and studied the setting of a cardinality constraint. Subsequent improvements for this problem by Balkanski, Rubinstein, and Singer [6] and Ene and Nguyen [21] resulted in a near-optimal (1−1/e−)-approximation in O(log n/2) rounds of adaptivity. Partly motivated by the goal of extending these results to more general constraints, we describe parallel algorithms for approximately maximizing the multilinear relaxation of a monotone submodular function subject to packing constraints. Formally our problem is to maximize F(x) over x ∈ [0,1]n subject to Ax ≤ 1 where F is the multilinear relaxation of a monotone submodular function. Our algorithm achieves a near-optimal (1 − 1/e − )-approximation in O(log2 mlog n/4) rounds where n is the cardinality of the ground set and m is the number of packing constraints. For many constraints of interest, the resulting fractional solution can be rounded via known randomized rounding schemes that are oblivious to the specific submodular function. We thus derive randomized algorithms with poly-logarithmic adaptivity for a number of constraints including partition and laminar matroids, matchings, knapsack constraints, and their intersections. Our algorithm takes a continuous view point and combines several ideas ranging from the continuous greedy algorithm of [38, 13], its adaptation to the MWU framework for packing constraints [20], and parallel algorithms for packing LPs [31, 41]. For the basic setting of cardinality constraints, this viewpoint gives rise to an alternative, simple to understand algorithm that matches recent results [6, 21]. Our algorithm to solve the multilinear relaxation is deterministic if it is given access to a value oracle for the multilinear extension and its gradient; this is possible in some interesting cases such as the coverage function of an explicitly given set system.},
archivePrefix = {arXiv},
arxivId = {1807.08678},
author = {Chekuri, Chandra and Quanrud, Kent},
booktitle = {Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
doi = {10.1137/1.9781611975482.20},
eprint = {1807.08678},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chekuri, Quanrud - 2019 - Submodular function maximization in parallel via the multilinear relaxation.pdf:pdf},
month = {jul},
pages = {303--322},
title = {{Submodular function maximization in parallel via the multilinear relaxation}},
url = {http://arxiv.org/abs/1807.08678},
year = {2019}
}
@article{Ene2018,
abstract = {We consider the problem of maximizing the multilinear extension of a submodular function subject to packing constraints in parallel. For monotone functions, we obtain a $1-1/e-\epsilon$ approximation using $O(\log(n/\epsilon)\log(m)/\epsilon^2)$ rounds of adaptivity and evaluations of the function and its gradient, where $m$ is the number of packing constraints and $n$ is the number of variables. For non-monotone functions, we obtain a $1/e-\epsilon$ approximation using $O(\log(n/\epsilon)\log(1/\epsilon)\log(n+m)/\epsilon^2)$ rounds of adaptivity and evaluations of the function and its gradient. Our results apply more generally to the problem of maximizing a diminishing returns submodular (DR-submodular) function subject to packing constraints.},
archivePrefix = {arXiv},
arxivId = {1808.09987},
author = {Ene, Alina and Nguyen, Huy L. and Vladu, Adrian},
eprint = {1808.09987},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ene, Nguyen, Vladu - 2018 - Submodular Maximization with Packing Constraints in Parallel.pdf:pdf},
month = {aug},
title = {{Submodular Maximization with Packing Constraints in Parallel}},
url = {http://arxiv.org/abs/1808.09987},
year = {2018}
}
@article{Ene2018a,
abstract = {We consider fast algorithms for monotone submodular maximization subject to a matroid constraint. We assume that the matroid is given as input in an explicit form, and the goal is to obtain the best possible running times for important matroids. We develop a new algorithm for a \emph{general matroid constraint} with a $1 - 1/e - \epsilon$ approximation that achieves a fast running time provided we have a fast data structure for maintaining a maximum weight base in the matroid through a sequence of decrease weight operations. We construct such data structures for graphic matroids and partition matroids, and we obtain the \emph{first algorithms} for these classes of matroids that achieve a nearly-optimal, $1 - 1/e - \epsilon$ approximation, using a nearly-linear number of function evaluations and arithmetic operations.},
archivePrefix = {arXiv},
arxivId = {1811.07464},
author = {Ene, Alina and Nguyen, Huy L.},
eprint = {1811.07464},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ene, Nguyen - 2018 - Towards Nearly-linear Time Algorithms for Submodular Maximization with a Matroid Constraint.pdf:pdf},
month = {nov},
title = {{Towards Nearly-linear Time Algorithms for Submodular Maximization with a Matroid Constraint}},
url = {http://arxiv.org/abs/1811.07464},
year = {2018}
}
@inproceedings{Chen2018b,
abstract = {In this paper, we consider the unconstrained submodular maximization problem. We propose the first algorithm for this problem that achieves a tight $(1/2-\varepsilon)$-approximation guarantee using $\tilde{O}(\varepsilon^{-1})$ adaptive rounds and a linear number of function evaluations. No previously known algorithm for this problem achieves an approximation ratio better than $1/3$ using less than $\Omega(n)$ rounds of adaptivity, where $n$ is the size of the ground set. Moreover, our algorithm easily extends to the maximization of a non-negative continuous DR-submodular function subject to a box constraint and achieves a tight $(1/2-\varepsilon)$-approximation guarantee for this problem while keeping the same adaptive and query complexities.},
archivePrefix = {arXiv},
arxivId = {1811.06603},
author = {Chen, Lin and Feldman, Moran and Karbasi, Amin},
booktitle = {STOC},
doi = {10.1145/3313276.3316327},
eprint = {1811.06603},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Feldman, Karbasi - 2019 - Unconstrained submodular maximization with constant adaptive complexity.pdf:pdf},
isbn = {9781450367059},
issn = {07378017},
keywords = {Low adaptive complexity,Parallel computation,Submodular maximization},
month = {nov},
pages = {102--113},
title = {{Unconstrained submodular maximization with constant adaptive complexity}},
url = {http://arxiv.org/abs/1811.06603},
year = {2019}
}
@article{Langmead2010,
abstract = {This unit shows how to use the Bowtie package to align short sequencing reads, such as those output by second-generation sequencing instruments. It also includes protocols for building a genome index and calling consensus sequences from Bowtie alignments using SAMtools.},
author = {Langmead, Ben},
doi = {10.1002/0471250953.bi1107s32},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Langmead - 2010 - Aligning short sequencing reads with Bowtie.pdf:pdf},
issn = {1934340X},
journal = {Current Protocols in Bioinformatics},
keywords = {Alignment,Comparative genomics,Genome indexing,Mapping,Read alignment,Read mapping,Short reads,Software package},
number = {SUPP.32},
publisher = {John Wiley and Sons Inc.},
title = {{Aligning short sequencing reads with Bowtie}},
year = {2010}
}
@book{Boyd2004,
abstract = {From the publisher. Convex optimization problems arise frequently in many different fields. This book provides a comprehensive introduction to the subject, and shows in detail how such problems can be solved numerically with great efficiency. The book begins with the basic elements of convex sets and functions, and then describes various classes of convex optimization problems. Duality and approximation techniques are then covered, as are statistical estimation techniques. Various geometrical problems are then presented, and there is detailed discussion of unconstrained and constrained minimization problems, and interior-point methods. The focus of the book is on recognizing convex optimization problems and then finding the most appropriate technique for solving them. It contains many worked examples and homework exercises and will appeal to students, researchers and practitioners in fields such as engineering, computer science, mathematics, statistics, finance, and economics. Introduction -- Convex sets -- Convex functions -- Convex optimization problems -- Duality -- Approximation and fitting -- Statistical estimation -- Geometric problems -- Unconstrained minimization -- Equality constrained minimization -- Interior-point methods -- Appendices: A. Mathematical background -- B. Problems involving two quadratic functions -- C. Numerical linear algebra background.},
author = {Boyd, Stephen P. and Vandenberghe, Lieven.},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boyd, Vandenberghe - 2004 - Convex optimization.pdf:pdf},
isbn = {9780521833783},
pages = {716},
publisher = {Cambridge University Press},
title = {{Convex optimization}},
year = {2004}
}
@article{Gower2019,
abstract = {We propose a general yet simple theorem describing the convergence of SGD under the arbitrary sampling paradigm. Our theorem describes the convergence of an infinite array of variants of SGD, each of which is associated with a specific probability law governing the data selection rule used to form mini-batches. This is the first time such an analysis is performed, and most of our variants of SGD were never explicitly considered in the literature before. Our analysis relies on the recently introduced notion of expected smoothness and does not rely on a uniform bound on the variance of the stochastic gradients. By specializing our theorem to different mini-batching strategies, such as sampling with replacement and independent sampling, we derive exact expressions for the stepsize as a function of the mini-batch size. With this we can also determine the mini-batch size that optimizes the total complexity, and show explicitly that as the variance of the stochastic gradient evaluated at the minimum grows, so does the optimal mini-batch size. For zero variance, the optimal mini-batch size is one. Moreover, we prove insightful stepsize-switching rules which describe when one should switch from a constant to a decreasing stepsize regime.},
archivePrefix = {arXiv},
arxivId = {1901.09401},
author = {Gower, Robert Mansel and Loizou, Nicolas and Qian, Xun and Sailanbayev, Alibek and Shulgin, Egor and Richtarik, Peter},
eprint = {1901.09401},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gower et al. - 2019 - SGD General Analysis and Improved Rates.pdf:pdf;:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gower et al. - 2019 - SGD General Analysis and Improved Rates(2).pdf:pdf;:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gower et al. - 2019 - SGD General Analysis and Improved Rates(3).pdf:pdf},
month = {jan},
title = {{SGD: General Analysis and Improved Rates}},
url = {http://arxiv.org/abs/1901.09401},
year = {2019}
}
@techreport{Zhangc,
abstract = {We consider the problem of minimizing the composition of a smooth function (which can be non-convex) and a smooth vector mapping, where both of them can be express as the average of a large number of components. We propose a composite randomized incremental gradient method based on SAGA type of construction. The gradient sample complexity of our method matches that of several recently developed methods based on SVRG in the general case. However, for struc-tured problems where linear convergence rates can be obtained, our method can be much better for ill-conditioned problems. In addition, when the finite-sum structure only appear for the inner mapping, the sample complexity of our method is the same as that of SAGA for minimizing finite sum of smooth nonconvex functions, despite the additional outer composition and the stochastic composite gradients being biased in our case.},
author = {Zhang, Junyu and Xiao, Lin},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Xiao - Unknown - A Composite Randomized Incremental Gradient Method.pdf:pdf},
title = {{A Composite Randomized Incremental Gradient Method}}
}
@article{Lu2018,
abstract = {The alternating gradient descent (AGD) is a simple but popular algorithm which has been applied to problems in optimization, machine learning, data ming, and signal processing, etc. The algorithm updates two blocks of variables in an alternating manner, in which a gradient step is taken on one block, while keeping the remaining block fixed. When the objective function is nonconvex, it is well-known the AGD converges to the first-order stationary solution with a global sublinear rate. In this paper, we show that a variant of AGD-type algorithms will not be trapped by "bad" stationary solutions such as saddle points and local maximum points. In particular, we consider a smooth unconstrained optimization problem, and propose a perturbed AGD (PA-GD) which converges (with high probability) to the set of second-order stationary solutions (SS2) with a global sublinear rate. To the best of our knowledge, this is the first alternating type algorithm which takes $\mathcal{O}(\text{polylog}(d)/\epsilon^{7/3})$ iterations to achieve SS2 with high probability [where polylog$(d)$ is polynomial of the logarithm of dimension $d$ of the problem].},
archivePrefix = {arXiv},
arxivId = {1802.10418},
author = {Lu, Songtao and Hong, Mingyi and Wang, Zhengdao},
eprint = {1802.10418},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu, Hong, Wang - 2018 - On the Sublinear Convergence of Randomly Perturbed Alternating Gradient Descent to Second Order Stationary Solut.pdf:pdf},
month = {feb},
title = {{On the Sublinear Convergence of Randomly Perturbed Alternating Gradient Descent to Second Order Stationary Solutions}},
url = {http://arxiv.org/abs/1802.10418},
year = {2018}
}
@article{Karimireddy2019,
abstract = {Sign-based algorithms (e.g. signSGD) have been proposed as a biased gradient compression technique to alleviate the communication bottleneck in training large neural networks across multiple workers. We show simple convex counter-examples where signSGD does not converge to the optimum. Further, even when it does converge, signSGD may generalize poorly when compared with SGD. These issues arise because of the biased nature of the sign compression operator. We then show that using error-feedback, i.e. incorporating the error made by the compression operator into the next step, overcomes these issues. We prove that our algorithm EF-SGD achieves the same rate of convergence as SGD without any additional assumptions for arbitrary compression operators (including the sign operator), indicating that we get gradient compression for free. Our experiments thoroughly substantiate the theory showing the superiority of our algorithm.},
archivePrefix = {arXiv},
arxivId = {1901.09847},
author = {Karimireddy, Sai Praneeth and Rebjock, Quentin and Stich, Sebastian U. and Jaggi, Martin},
eprint = {1901.09847},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karimireddy et al. - 2019 - Error Feedback Fixes SignSGD and other Gradient Compression Schemes.pdf:pdf},
month = {jan},
title = {{Error Feedback Fixes SignSGD and other Gradient Compression Schemes}},
url = {http://arxiv.org/abs/1901.09847},
year = {2019}
}
@article{Dziugaite2017,
abstract = {One of the defining properties of deep learning is that models are chosen to have many more parameters than available training data. In light of this capacity for overfitting, it is remarkable that simple algorithms like SGD reliably return solutions with low test error. One roadblock to explaining these phenomena in terms of implicit regularization, structural properties of the solution, and/or easiness of the data is that many learning bounds are quantitatively vacuous when applied to networks learned by SGD in this "deep learning" regime. Logically, in order to explain generalization, we need nonvacuous bounds. We return to an idea by Langford and Caruana (2001), who used PAC-Bayes bounds to compute nonvacuous numerical bounds on generalization error for stochastic two-layer two-hidden-unit neural networks via a sensitivity analysis. By optimizing the PAC-Bayes bound directly, we are able to extend their approach and obtain nonvacuous generalization bounds for deep stochastic neural network classifiers with millions of parameters trained on only tens of thousands of examples. We connect our findings to recent and old work on flat minima and MDL-based explanations of generalization.},
archivePrefix = {arXiv},
arxivId = {1703.11008},
author = {Dziugaite, Gintare Karolina and Roy, Daniel M.},
eprint = {1703.11008},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dziugaite, Roy - 2017 - Computing Nonvacuous Generalization Bounds for Deep (Stochastic) Neural Networks with Many More Parameters than.pdf:pdf},
month = {mar},
title = {{Computing Nonvacuous Generalization Bounds for Deep (Stochastic) Neural Networks with Many More Parameters than Training Data}},
url = {http://arxiv.org/abs/1703.11008},
year = {2017}
}
@article{Zhang2016f,
abstract = {Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models.},
archivePrefix = {arXiv},
arxivId = {1611.03530},
author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
eprint = {1611.03530},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2016 - Understanding deep learning requires rethinking generalization.pdf:pdf},
month = {nov},
title = {{Understanding deep learning requires rethinking generalization}},
url = {http://arxiv.org/abs/1611.03530},
year = {2016}
}
@article{Yao2018,
abstract = {Deep Neural Networks are quite vulnerable to adversarial perturbations. Current state-of-the-art adversarial attack methods typically require very time consuming hyper-parameter tuning, or require many iterations to solve an optimization based adversarial attack. To address this problem, we present a new family of trust region based adversarial attacks, with the goal of computing adversarial perturbations efficiently. We propose several attacks based on variants of the trust region optimization method. We test the proposed methods on Cifar-10 and ImageNet datasets using several different models including AlexNet, ResNet-50, VGG-16, and DenseNet-121 models. Our methods achieve comparable results with the Carlini-Wagner (CW) attack, but with significant speed up of up to $37\times$, for the VGG-16 model on a Titan Xp GPU. For the case of ResNet-50 on ImageNet, we can bring down its classification accuracy to less than 0.1\% with at most $1.5\%$ relative $L_\infty$ (or $L_2$) perturbation requiring only $1.02$ seconds as compared to $27.04$ seconds for the CW attack. We have open sourced our method which can be accessed at [1].},
archivePrefix = {arXiv},
arxivId = {1812.06371},
author = {Yao, Zhewei and Gholami, Amir and Xu, Peng and Keutzer, Kurt and Mahoney, Michael},
eprint = {1812.06371},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yao et al. - 2018 - Trust Region Based Adversarial Attack on Neural Networks.pdf:pdf},
month = {dec},
title = {{Trust Region Based Adversarial Attack on Neural Networks}},
url = {http://arxiv.org/abs/1812.06371},
year = {2018}
}
@article{Park2019,
abstract = {We investigate how the final parameters found by stochastic gradient descent are influenced by over-parameterization. We generate families of models by increasing the number of channels in a base network, and then perform a large hyper-parameter search to study how the test error depends on learning rate, batch size, and network width. We find that the optimal SGD hyper-parameters are determined by a "normalized noise scale," which is a function of the batch size, learning rate, and initialization conditions. In the absence of batch normalization, the optimal normalized noise scale is directly proportional to width. Wider networks, with their higher optimal noise scale, also achieve higher test accuracy. These observations hold for MLPs, ConvNets, and ResNets, and for two different parameterization schemes ("Standard" and "NTK"). We observe a similar trend with batch normalization for ResNets. Surprisingly, since the largest stable learning rate is bounded, the largest batch size consistent with the optimal normalized noise scale decreases as the width increases.},
archivePrefix = {arXiv},
arxivId = {1905.03776},
author = {Park, Daniel S. and Sohl-Dickstein, Jascha and Le, Quoc V. and Smith, Samuel L.},
eprint = {1905.03776},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Park et al. - 2019 - The Effect of Network Width on Stochastic Gradient Descent and Generalization an Empirical Study.pdf:pdf},
month = {may},
title = {{The Effect of Network Width on Stochastic Gradient Descent and Generalization: an Empirical Study}},
url = {http://arxiv.org/abs/1905.03776},
year = {2019}
}
@article{Maheswaranathan2018,
abstract = {Many applications in machine learning require optimizing a function whose true gradient is unknown, but where surrogate gradient information (directions that may be correlated with, but not necessarily identical to, the true gradient) is available instead. This arises when an approximate gradient is easier to compute than the full gradient (e.g. in meta-learning or unrolled optimization), or when a true gradient is intractable and is replaced with a surrogate (e.g. in certain reinforcement learning applications, or when using synthetic gradients). We propose Guided Evolutionary Strategies, a method for optimally using surrogate gradient directions along with random search. We define a search distribution for evolutionary strategies that is elongated along a guiding subspace spanned by the surrogate gradients. This allows us to estimate a descent direction which can then be passed to a first-order optimizer. We analytically and numerically characterize the tradeoffs that result from tuning how strongly the search distribution is stretched along the guiding subspace, and we use this to derive a setting of the hyperparameters that works well across problems. Finally, we apply our method to example problems, demonstrating an improvement over both standard evolutionary strategies and first-order methods (that directly follow the surrogate gradient). We provide a demo of Guided ES at https://github.com/brain-research/guided-evolutionary-strategies},
archivePrefix = {arXiv},
arxivId = {1806.10230},
author = {Maheswaranathan, Niru and Metz, Luke and Tucker, George and Choi, Dami and Sohl-Dickstein, Jascha},
eprint = {1806.10230},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maheswaranathan et al. - 2018 - Guided evolutionary strategies escaping the curse of dimensionality in random search.pdf:pdf},
month = {jun},
title = {{Guided evolutionary strategies: escaping the curse of dimensionality in random search}},
url = {http://arxiv.org/abs/1806.10230},
year = {2018}
}
@article{Arora2019b,
abstract = {How well does a classic deep net architecture like AlexNet or VGG19 classify on a standard dataset such as CIFAR-10 when its "width" --- namely, number of channels in convolutional layers, and number of nodes in fully-connected internal layers --- is allowed to increase to infinity? Such questions have come to the forefront in the quest to theoretically understand deep learning and its mysteries about optimization and generalization. They also connect deep learning to notions such as Gaussian processes and kernels. A recent paper [Jacot et al., 2018] introduced the Neural Tangent Kernel (NTK) which captures the behavior of fully-connected deep nets in the infinite width limit trained by gradient descent; this object was implicit in some other recent papers. A subsequent paper [Lee et al., 2019] gave heuristic Monte Carlo methods to estimate the NTK and its extension, Convolutional Neural Tangent Kernel (CNTK) and used this to try to understand the limiting behavior on datasets like CIFAR-10. The current paper gives the first efficient exact algorithm (based upon dynamic programming) for computing CNTK as well as an efficient GPU implementation of this algorithm. This results in a significant new benchmark for performance of a pure kernel-based method on CIFAR-10, being 10% higher than the methods reported in [Novak et al., 2019], and only 5% lower than the performance of the corresponding finite deep net architecture (once batch normalization etc. are turned off). We give the first non-asymptotic proof showing that a fully-trained sufficiently wide net is indeed equivalent to the kernel regression predictor using NTK. Our experiments also demonstrate that earlier Monte Carlo approximation can degrade the performance significantly, thus highlighting the power of our exact kernel computation, which we have applied even to the full CIFAR-10 dataset and 20-layer nets.},
archivePrefix = {arXiv},
arxivId = {1904.11955},
author = {Arora, Sanjeev and Du, Simon S. and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Ruslan and Wang, Ruosong},
eprint = {1904.11955},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arora et al. - 2019 - On Exact Computation with an Infinitely Wide Neural Net.pdf:pdf},
month = {apr},
title = {{On Exact Computation with an Infinitely Wide Neural Net}},
url = {http://arxiv.org/abs/1904.11955},
year = {2019}
}
@article{Novak2018,
abstract = {There is a previously identified equivalence between wide fully connected neural networks (FCNs) and Gaussian processes (GPs). This equivalence enables, for instance, test set predictions that would have resulted from a fully Bayesian, infinitely wide trained FCN to be computed without ever instantiating the FCN, but by instead evaluating the corresponding GP. In this work, we derive an analogous equivalence for multi-layer convolutional neural networks (CNNs) both with and without pooling layers, and achieve state of the art results on CIFAR10 for GPs without trainable kernels. We also introduce a Monte Carlo method to estimate the GP corresponding to a given neural network architecture, even in cases where the analytic form has too many terms to be computationally feasible. Surprisingly, in the absence of pooling layers, the GPs corresponding to CNNs with and without weight sharing are identical. As a consequence, translation equivariance, beneficial in finite channel CNNs trained with stochastic gradient descent (SGD), is guaranteed to play no role in the Bayesian treatment of the infinite channel limit - a qualitative difference between the two regimes that is not present in the FCN case. We confirm experimentally, that while in some scenarios the performance of SGD-trained finite CNNs approaches that of the corresponding GPs as the channel count increases, with careful tuning SGD-trained CNNs can significantly outperform their corresponding GPs, suggesting advantages from SGD training compared to fully Bayesian parameter estimation.},
archivePrefix = {arXiv},
arxivId = {1810.05148},
author = {Novak, Roman and Xiao, Lechao and Lee, Jaehoon and Bahri, Yasaman and Yang, Greg and Hron, Jiri and Abolafia, Daniel A. and Pennington, Jeffrey and Sohl-Dickstein, Jascha},
eprint = {1810.05148},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Novak et al. - 2018 - Bayesian Deep Convolutional Networks with Many Channels are Gaussian Processes.pdf:pdf},
month = {oct},
title = {{Bayesian Deep Convolutional Networks with Many Channels are Gaussian Processes}},
url = {http://arxiv.org/abs/1810.05148},
year = {2018}
}
@article{Gupta2019,
abstract = {Motivated by recent developments in serverless systems for large-scale machine learning as well as improvements in scalable randomized matrix algorithms, we develop OverSketched Newton, a randomized Hessian-based optimization algorithm to solve large-scale smooth and strongly-convex problems in serverless systems. OverSketched Newton leverages matrix sketching ideas from Randomized Numerical Linear Algebra to compute the Hessian approximately. These sketching methods lead to inbuilt resiliency against stragglers that are a characteristic of serverless architectures. We establish that OverSketched Newton has a linear-quadratic convergence rate, and we empirically validate our results by solving large-scale supervised learning problems on real-world datasets. Experiments demonstrate a reduction of $\sim$50% in total running time on AWS Lambda, compared to state-of-the-art distributed optimization schemes.},
archivePrefix = {arXiv},
arxivId = {1903.08857},
author = {Gupta, Vipul and Kadhe, Swanand and Courtade, Thomas and Mahoney, Michael W. and Ramchandran, Kannan},
eprint = {1903.08857},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta et al. - 2019 - OverSketched Newton Fast Convex Optimization for Serverless Systems.pdf:pdf},
month = {mar},
title = {{OverSketched Newton: Fast Convex Optimization for Serverless Systems}},
url = {http://arxiv.org/abs/1903.08857},
year = {2019}
}
@article{Devarakonda2016,
abstract = {Primal and dual block coordinate descent methods are iterative methods for solving regularized and unregularized optimization problems. Distributed-memory parallel implementations of these methods have become popular in analyzing large machine learning datasets. However, existing implementations communicate at every iteration which, on modern data center and supercomputing architectures, often dominates the cost of floating-point computation. Recent results on communication-avoiding Krylov subspace methods suggest that large speedups are possible by re-organizing iterative algorithms to avoid communication. We show how applying similar algorithmic transformations can lead to primal and dual block coordinate descent methods that only communicate every $s$ iterations--where $s$ is a tuning parameter--instead of every iteration for the \textit{regularized least-squares problem}. We show that the communication-avoiding variants reduce the number of synchronizations by a factor of $s$ on distributed-memory parallel machines without altering the convergence rate and attains strong scaling speedups of up to $6.1\times$ on a Cray XC30 supercomputer.},
archivePrefix = {arXiv},
arxivId = {1612.04003},
author = {Devarakonda, Aditya and Fountoulakis, Kimon and Demmel, James and Mahoney, Michael W.},
eprint = {1612.04003},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Devarakonda et al. - 2016 - Avoiding communication in primal and dual block coordinate descent methods.pdf:pdf},
month = {dec},
title = {{Avoiding communication in primal and dual block coordinate descent methods}},
url = {http://arxiv.org/abs/1612.04003},
year = {2016}
}
@incollection{Kylasa2019,
author = {Kylasa, Sudhir and Roosta, Fred (Farbod) and Mahoney, Michael W. and Grama, Ananth},
booktitle = {Proceedings of the 2019 SIAM International Conference on Data Mining},
doi = {10.1137/1.9781611975673.79},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kylasa et al. - 2019 - GPU Accelerated Sub-Sampled Newton's Method for Convex Classification Problems.pdf:pdf},
month = {may},
pages = {702--710},
publisher = {Society for Industrial and Applied Mathematics},
title = {{GPU Accelerated Sub-Sampled Newton's Method for Convex Classification Problems}},
year = {2019}
}
@article{Lee2019,
abstract = {A longstanding goal in deep learning research has been to precisely characterize training and generalization. However, the often complex loss landscapes of neural networks have made a theory of learning dynamics elusive. In this work, we show that for wide neural networks the learning dynamics simplify considerably and that, in the infinite width limit, they are governed by a linear model obtained from the first-order Taylor expansion of the network around its initial parameters. Furthermore, mirroring the correspondence between wide Bayesian neural networks and Gaussian processes, gradient-based training of wide neural networks with a squared loss produces test set predictions drawn from a Gaussian process with a particular compositional kernel. While these theoretical results are only exact in the infinite width limit, we nevertheless find excellent empirical agreement between the predictions of the original network and those of the linearized version even for finite practically-sized networks. This agreement is robust across different architectures, optimization methods, and loss functions.},
archivePrefix = {arXiv},
arxivId = {1902.06720},
author = {Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel S. and Bahri, Yasaman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
eprint = {1902.06720},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2019 - Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent.pdf:pdf},
month = {feb},
title = {{Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent}},
url = {http://arxiv.org/abs/1902.06720},
year = {2019}
}
@article{Martin2019,
abstract = {Random Matrix Theory (RMT) is applied to analyze the weight matrices of Deep Neural Networks (DNNs), including both production quality, pre-trained models such as AlexNet and Inception, and smaller models trained from scratch, such as LeNet5 and a miniature-AlexNet. Empirical and theoretical results clearly indicate that the empirical spectral density (ESD) of DNN layer matrices displays signatures of traditionally-regularized statistical models, even in the absence of exogenously specifying traditional forms of regularization, such as Dropout or Weight Norm constraints. Building on recent results in RMT, most notably its extension to Universality classes of Heavy-Tailed matrices, we develop a theory to identify \emph{5+1 Phases of Training}, corresponding to increasing amounts of \emph{Implicit Self-Regularization}. For smaller and/or older DNNs, this Implicit Self-Regularization is like traditional Tikhonov regularization, in that there is a `size scale' separating signal from noise. For state-of-the-art DNNs, however, we identify a novel form of \emph{Heavy-Tailed Self-Regularization}, similar to the self-organization seen in the statistical physics of disordered systems. This implicit Self-Regularization can depend strongly on the many knobs of the training process. By exploiting the generalization gap phenomena, we demonstrate that we can cause a small model to exhibit all 5+1 phases of training simply by changing the batch size.},
archivePrefix = {arXiv},
arxivId = {1901.08276},
author = {Martin, Charles H. and Mahoney, Michael W.},
eprint = {1901.08276},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martin, Mahoney - 2019 - Traditional and Heavy-Tailed Self Regularization in Neural Network Models.pdf:pdf},
month = {jan},
title = {{Traditional and Heavy-Tailed Self Regularization in Neural Network Models}},
url = {http://arxiv.org/abs/1901.08276},
year = {2019}
}
@article{Golmant2018,
abstract = {Increasing the mini-batch size for stochastic gradient descent offers significant opportunities to reduce wall-clock training time, but there are a variety of theoretical and systems challenges that impede the widespread success of this technique. We investigate these issues, with an emphasis on time to convergence and total computational cost, through an extensive empirical analysis of network training across several architectures and problem domains, including image classification, image segmentation, and language modeling. Although it is common practice to increase the batch size in order to fully exploit available computational resources, we find a substantially more nuanced picture. Our main finding is that across a wide range of network architectures and problem domains, increasing the batch size beyond a certain point yields no decrease in wall-clock time to convergence for \emph{either} train or test loss. This batch size is usually substantially below the capacity of current systems. We show that popular training strategies for large batch size optimization begin to fail before we can populate all available compute resources, and we show that the point at which these methods break down depends more on attributes like model architecture and data complexity than it does directly on the size of the dataset.},
archivePrefix = {arXiv},
arxivId = {1811.12941},
author = {Golmant, Noah and Vemuri, Nikita and Yao, Zhewei and Feinberg, Vladimir and Gholami, Amir and Rothauge, Kai and Mahoney, Michael W. and Gonzalez, Joseph},
eprint = {1811.12941},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Golmant et al. - 2018 - On the Computational Inefficiency of Large Batch Sizes for Stochastic Gradient Descent.pdf:pdf},
month = {nov},
title = {{On the Computational Inefficiency of Large Batch Sizes for Stochastic Gradient Descent}},
url = {http://arxiv.org/abs/1811.12941},
year = {2018}
}
@article{Arora2019,
abstract = {How well does a classic deep net architecture like AlexNet or VGG19 classify on a standard dataset such as CIFAR-10 when its "width" --- namely, number of channels in convolutional layers, and number of nodes in fully-connected internal layers --- is allowed to increase to infinity? Such questions have come to the forefront in the quest to theoretically understand deep learning and its mysteries about optimization and generalization. They also connect deep learning to notions such as Gaussian processes and kernels. A recent paper [Jacot et al., 2018] introduced the Neural Tangent Kernel (NTK) which captures the behavior of fully-connected deep nets in the infinite width limit trained by gradient descent; this object was implicit in some other recent papers. A subsequent paper [Lee et al., 2019] gave heuristic Monte Carlo methods to estimate the NTK and its extension, Convolutional Neural Tangent Kernel (CNTK) and used this to try to understand the limiting behavior on datasets like CIFAR-10. The current paper gives the first efficient exact algorithm (based upon dynamic programming) for computing CNTK as well as an efficient GPU implementation of this algorithm. This results in a significant new benchmark for performance of a pure kernel-based method on CIFAR-10, being 10% higher than the methods reported in [Novak et al., 2019], and only 5% lower than the performance of the corresponding finite deep net architecture (once batch normalization etc. are turned off). We give the first non-asymptotic proof showing that a fully-trained sufficiently wide net is indeed equivalent to the kernel regression predictor using NTK. Our experiments also demonstrate that earlier Monte Carlo approximation can degrade the performance significantly, thus highlighting the power of our exact kernel computation, which we have applied even to the full CIFAR-10 dataset and 20-layer nets.},
archivePrefix = {arXiv},
arxivId = {1904.11955},
author = {Arora, Sanjeev and Du, Simon S. and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Ruslan and Wang, Ruosong},
eprint = {1904.11955},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arora et al. - 2019 - On Exact Computation with an Infinitely Wide Neural Net.pdf:pdf},
month = {apr},
title = {{On Exact Computation with an Infinitely Wide Neural Net}},
url = {http://arxiv.org/abs/1904.11955},
year = {2019}
}
@article{Gupta2019a,
abstract = {There is great interest in *saliency methods* (also called *attribution methods*), which give "explanations" for a deep net's decision, by assigning a *score* to each feature/pixel in the input. Their design usually involves credit-assignment via the gradient of the output with respect to input. Recently Adebayo et al. [arXiv:1810.03292] questioned the validity of many of these methods since they do not pass simple *sanity checks* which test whether the scores shift/vanish when layers of the trained net are randomized, or when the net is retrained using random labels for inputs. We propose a simple fix to existing saliency methods that helps them pass sanity checks, which we call *competition for pixels*. This involves computing saliency maps for all possible labels in the classification task, and using a simple competition among them to identify and remove less relevant pixels from the map. The simplest variant of this is *Competitive Gradient $\odot$ Input (CGI)*: it is efficient, requires no additional training, and uses only the input and gradient. Some theoretical justification is provided for it (especially for ReLU networks) and its performance is empirically demonstrated.},
archivePrefix = {arXiv},
arxivId = {1905.12152},
author = {Gupta, Arushi and Arora, Sanjeev},
eprint = {1905.12152},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta, Arora - 2019 - A Simple Saliency Method That Passes the Sanity Checks.pdf:pdf},
month = {may},
title = {{A Simple Saliency Method That Passes the Sanity Checks}},
url = {http://arxiv.org/abs/1905.12152},
year = {2019}
}
@article{Arora2019a,
abstract = {Efforts to understand the generalization mystery in deep learning have led to the belief that gradient-based optimization induces a form of implicit regularization, a bias towards models of low "complexity." We study the implicit regularization of gradient descent over deep linear neural networks for matrix completion and sensing, a model referred to as deep matrix factorization. Our first finding, supported by theory and experiments, is that adding depth to a matrix factorization enhances an implicit tendency towards low-rank solutions, oftentimes leading to more accurate recovery. Secondly, we present theoretical and empirical arguments questioning a nascent view by which implicit regularization in matrix factorization can be captured using simple mathematical norms. Our results point to the possibility that the language of standard regularizers may not be rich enough to fully encompass the implicit regularization brought forth by gradient-based optimization.},
archivePrefix = {arXiv},
arxivId = {1905.13655},
author = {Arora, Sanjeev and Cohen, Nadav and Hu, Wei and Luo, Yuping},
eprint = {1905.13655},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arora et al. - 2019 - Implicit Regularization in Deep Matrix Factorization.pdf:pdf},
month = {may},
title = {{Implicit Regularization in Deep Matrix Factorization}},
url = {http://arxiv.org/abs/1905.13655},
year = {2019}
}
@article{Bian2018,
abstract = {Mean field inference in probabilistic models is generally a highly nonconvex problem. Existing optimization methods, e.g., coordinate ascent algorithms, can only generate local optima. In this work we propose provable mean filed methods for probabilistic log-submodular models and its posterior agreement (PA) with strong approximation guarantees. The main algorithmic technique is a new Double Greedy scheme, termed DR-DoubleGreedy, for continuous DR-submodular maximization with box-constraints. It is a one-pass algorithm with linear time complexity, reaching the optimal 1/2 approximation ratio, which may be of independent interest. We validate the superior performance of our algorithms against baseline algorithms on both synthetic and real-world datasets.},
archivePrefix = {arXiv},
arxivId = {1805.07482},
author = {Bian, An and Buhmann, Joachim M. and Krause, Andreas},
eprint = {1805.07482},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bian, Buhmann, Krause - 2018 - Optimal DR-Submodular Maximization and Applications to Provable Mean Field Inference.pdf:pdf},
month = {may},
title = {{Optimal DR-Submodular Maximization and Applications to Provable Mean Field Inference}},
url = {http://arxiv.org/abs/1805.07482},
year = {2018}
}
@article{Boucher2019,
abstract = {{\textcopyright} 2019 The Author(s). High-throughput sequencing technologies have led to explosive growth of genomic databases; one of which will soon reach hundreds of terabytes. For many applications we want to build and store indexes of these databases but constructing such indexes is a challenge. Fortunately, many of these genomic databases are highly-repetitive - a characteristic that can be exploited to ease the computation of the Burrows-Wheeler Transform (BWT), which underlies many popular indexes. In this paper, we introduce a preprocessing algorithm, referred to as prefix-free parsing, that takes a text T as input, and in one-pass generates a dictionary D and a parse P of T with the property that the BWT of T can be constructed from D and P using workspace proportional to their total size and O(|T|)-time. Our experiments show that D and P are significantly smaller than T in practice, and thus, can fit in a reasonable internal memory even when T is very large. In particular, we show that with prefix-free parsing we can build an 131-MB run-length compressed FM-index (restricted to support only counting and not locating) for 1000 copies of human chromosome 19 in 2 h using 21 GB of memory, suggesting that we can build a 6.73 GB index for 1000 complete human-genome haplotypes in approximately 102 h using about 1 TB of memory.},
author = {Boucher, C. and Gagie, T. and Kuhnle, A. and Langmead, B. and Manzini, G. and Mun, T.},
doi = {10.1186/s13015-019-0148-5},
issn = {17487188},
journal = {Algorithms for Molecular Biology},
keywords = {Burrows-Wheeler Transform,Compression-aware algorithms,Genomic databases,Prefix-free parsing},
number = {1},
title = {{Prefix-free parsing for building big BWTs}},
volume = {14},
year = {2019}
}
@techreport{Leyton-Brown,
author = {Leyton-Brown, Kevin and Hutter, Frank},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leyton-Brown, Hutter - Unknown - Algorithm Configuration Learning in the Space of Algorithm Designs Tutorial.pdf:pdf},
title = {{Algorithm Configuration: Learning in the Space of Algorithm Designs [Tutorial]}}
}
@techreport{Nowak,
author = {Nowak, Robert and Hanneke, Steve},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nowak, Hanneke - Unknown - Nonparametric Active Learning Tutorial.pdf:pdf},
title = {{Nonparametric Active Learning [Tutorial]}}
}
@article{Belkin2018,
abstract = {The question of generalization in machine learning---how algorithms are able to learn predictors from a training sample to make accurate predictions out-of-sample---is revisited in light of the recent breakthroughs in modern machine learning technology. The classical approach to understanding generalization is based on bias-variance trade-offs, where model complexity is carefully calibrated so that the fit on the training sample reflects performance out-of-sample. However, it is now common practice to fit highly complex models like deep neural networks to data with (nearly) zero training error, and yet these interpolating predictors are observed to have good out-of-sample accuracy even for noisy data. How can the classical understanding of generalization be reconciled with these observations from modern machine learning practice? In this paper, we bridge the two regimes by exhibiting a new "double descent" risk curve that extends the traditional U-shaped bias-variance curve beyond the point of interpolation. Specifically, the curve shows that as soon as the model complexity is high enough to achieve interpolation on the training sample---a point that we call the "interpolation threshold"---the risk of suitably chosen interpolating predictors from these models can, in fact, be decreasing as the model complexity increases, often below the risk achieved using non-interpolating models. The double descent risk curve is demonstrated for a broad range of models, including neural networks and random forests, and a mechanism for producing this behavior is posited.},
archivePrefix = {arXiv},
arxivId = {1812.11118},
author = {Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
eprint = {1812.11118},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Belkin et al. - 2018 - Reconciling modern machine learning and the bias-variance trade-off.pdf:pdf},
month = {dec},
title = {{Reconciling modern machine learning and the bias-variance trade-off}},
url = {http://arxiv.org/abs/1812.11118},
year = {2018}
}
@article{Kalimeris2019,
abstract = {In this paper, we study the problem of robust influence maximization in the independent cascade model under a hyperparametric assumption. In social networks users influence and are influenced by individuals with similar characteristics and as such, they are associated with some features. A recent surging research direction in influence maximization focuses on the case where the edge probabilities on the graph are not arbitrary but are generated as a function of the features of the users and a global hyperparameter. We propose a model where the objective is to maximize the worst-case number of influenced users for any possible value of that hyperparameter. We provide theoretical results showing that proper robust solution in our model is NP-hard and an algorithm that achieves improper robust optimization. We make-use of sampling based techniques and of the renowned multiplicative weight updates algorithm. Additionally, we validate our method empirically and prove that it outperforms the state-of-the-art robust influence maximization techniques.},
archivePrefix = {arXiv},
arxivId = {1903.03746},
author = {Kalimeris, Dimitris and Kaplun, Gal and Singer, Yaron},
eprint = {1903.03746},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalimeris, Kaplun, Singer - 2019 - Robust Influence Maximization for Hyperparametric Models.pdf:pdf},
month = {mar},
title = {{Robust Influence Maximization for Hyperparametric Models}},
url = {http://arxiv.org/abs/1903.03746},
year = {2019}
}
@inproceedings{Balkanski2018c,
abstract = {In this paper we study submodular maximization under a matroid constraint in the adaptive complexity model. This model was recently introduced in the context of submodular optimization to quantify the information theoretic complexity of black-box optimization in a parallel computation model. Informally, the adaptivity of an algorithm is the number of sequential rounds it makes when each round can execute polynomially-many function evaluations in parallel. Since submodular optimization is regularly applied on large datasets we seek algorithms with low adaptivity to enable speedups via parallelization. Consequently, a recent line of work has been devoted to designing constant factor approximation algorithms for maximizing submodular functions under various constraints in the adaptive complexity model. Despite the burst in work on submodular maximization in the adaptive complexity model, the fundamental problem of maximizing a monotone submodular function under a matroid constraint has remained elusive. In particular, all known techniques fail for this problem and there are no known constant factor approximation algorithms whose adaptivity is sublinear in the rank of the matroid k or in the worst case sublinear in the size of the ground set n. In this paper we present an approximation algorithm for the problem of maximizing a monotone submodular function under a matroid constraint in the adaptive complexity model. The approximation guarantee of the algorithm is arbitrarily close to the optimal 1 − 1/e and it has near optimal adaptivity of O(log(n) log(k)). This result is obtained using a novel technique of adaptive sequencing which departs from previous techniques for submodular maximization in the adaptive complexity model. In addition to our main result we show how to use this technique to design other approximation algorithms with strong approximation guarantees and polylogarithmic adaptivity.},
archivePrefix = {arXiv},
arxivId = {1811.03093},
author = {Balkanski, Eric and Rubinstein, Aviad and Singer, Yaron},
booktitle = {Proceedings of the Annual ACM Symposium on Theory of Computing},
doi = {10.1145/3313276.3316304},
eprint = {1811.03093},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balkanski, Rubinstein, Singer - 2019 - An optimal approximation for submodular maximization under a matroid constraint in the adaptive c.pdf:pdf},
isbn = {9781450367059},
issn = {07378017},
keywords = {Adaptivity,Matroids,Parallel algorithms,Submodular optimization},
month = {nov},
pages = {66--77},
title = {{An optimal approximation for submodular maximization under a matroid constraint in the adaptive complexity model}},
url = {http://arxiv.org/abs/1811.03093},
year = {2019}
}
@article{Kawaguchi2019,
abstract = {In this paper, we theoretically prove that we can eliminate all suboptimal local minima by adding one neuron per output unit to any deep neural network, for multi-class classification, binary classification, and regression with an arbitrary loss function. At every local minimum of any deep neural network with added neurons, the set of parameters of the original neural network (without added neurons) is guaranteed to be a global minimum of the original neural network. The effects of the added neurons are proven to automatically vanish at every local minimum. Unlike many related results in the literature, our theoretical results are directly applicable to common deep learning tasks because the results only rely on the assumptions that automatically hold in the common tasks. Moreover, we discuss several limitations in eliminating the suboptimal local minima in this manner by providing additional theoretical results and several examples.},
archivePrefix = {arXiv},
arxivId = {1901.00279},
author = {Kawaguchi, Kenji and Kaelbling, Leslie Pack},
eprint = {1901.00279},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kawaguchi, Kaelbling - 2019 - Elimination of All Bad Local Minima in Deep Learning.pdf:pdf},
month = {jan},
title = {{Elimination of All Bad Local Minima in Deep Learning}},
url = {http://arxiv.org/abs/1901.00279},
year = {2019}
}
@techreport{Lu2018a,
abstract = {We introduce and study two algorithms to accelerate greedy coordinate descent in theory and in practice: Accelerated Semi-Greedy Coordinate Descent (ASCD) and Accelerated Greedy Coordinate Descent (AGCD). On the theory side, our main results are for ASCD: we show that ASCD achieves O(1/k 2) convergence, and it also achieves accelerated linear convergence for strongly convex functions. On the empirical side, while both AGCD and ASCD outperform Accelerated Randomized Coordinate Descent on most instances in our numerical experiments, we note that AGCD significantly outperforms the other two methods in our experiments, in spite of a lack of theoretical guarantees for this method. To complement this empirical finding for AGCD, we present an explanation why standard proof techniques for acceleration cannot work for AGCD, and we introduce a technical condition under which AGCD is guaranteed to have accelerated convergence. Finally, we confirm that this technical condition holds in our numerical experiments.},
author = {Lu, Haihao and Freund, Robert M and Mirrokni, Vahab},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu, Freund, Mirrokni - 2018 - Accelerating Greedy Coordinate Descent Methods.pdf:pdf},
title = {{Accelerating Greedy Coordinate Descent Methods}},
year = {2018}
}
@article{Huizinga2018,
abstract = {An important challenge in reinforcement learning, including evolutionary robotics, is to solve multimodal problems, where agents have to act in qualitatively different ways depending on the circumstances. Because multimodal problems are often too difficult to solve directly, it is helpful to take advantage of staging, where a difficult task is divided into simpler subtasks that can serve as stepping stones for solving the overall problem. Unfortunately, choosing an effective ordering for these subtasks is difficult, and a poor ordering can reduce the speed and performance of the learning process. Here, we provide a thorough introduction and investigation of the Combinatorial Multi-Objective Evolutionary Algorithm (CMOEA), which avoids ordering subtasks by allowing all combinations of subtasks to be explored simultaneously. We compare CMOEA against two algorithms that can similarly optimize on multiple subtasks simultaneously: NSGA-II and Lexicase Selection. The algorithms are tested on a multimodal robotics problem with six subtasks as well as a maze navigation problem with a hundred subtasks. On these problems, CMOEA either outperforms or is competitive with the controls. Separately, we show that adding a linear combination over all objectives can improve the ability of NSGA-II to solve these multimodal problems. Lastly, we show that, in contrast to NSGA-II and Lexicase Selection, CMOEA can effectively leverage secondary objectives to achieve state-of-the-art results on the robotics task. In general, our experiments suggest that CMOEA is a promising, state-of-the-art algorithm for solving multimodal problems.},
archivePrefix = {arXiv},
arxivId = {1807.03392},
author = {Huizinga, Joost and Clune, Jeff},
eprint = {1807.03392},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huizinga, Clune - 2018 - Evolving Multimodal Robot Behavior via Many Stepping Stones with the Combinatorial Multi-Objective Evolutionary.pdf:pdf},
month = {jul},
title = {{Evolving Multimodal Robot Behavior via Many Stepping Stones with the Combinatorial Multi-Objective Evolutionary Algorithm}},
url = {http://arxiv.org/abs/1807.03392},
year = {2018}
}
@article{Stanley2002,
abstract = {An important question in neuroevolution is how to gain an advantage from evolving neural network topologies along with weights. We present a method, NeuroEvolution of Augmenting Topologies (NEAT), which outperforms the best fixed-topology method on a challenging benchmark reinforcement learning task. We claim that the increased efficiency is due to (1) employing a principled method of crossover of different topologies, (2) protecting structural innovation using speciation, and (3) incrementally growing from minimal structure. We test this claim through a series of ablation studies that demonstrate that each component is necessary to the system as a whole and to each other. What results is significantly faster learning. NEAT is also an important contribution to GAs because it shows how it is possible for evolution to both optimize and complexify solutions simultaneously, offering the possibility of evolving increasingly complex solutions over generations, and strengthening the analogy with biological evolution.},
author = {Stanley, Kenneth O and Miikkulainen, Risto},
doi = {10.1162/106365602320169811},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stanley, Miikkulainen - 2002 - Evolving neural networks through augmenting topologies.pdf:pdf},
issn = {1063-6560},
journal = {Evolutionary computation},
number = {2},
pages = {99--127},
pmid = {12180173},
title = {{Evolving neural networks through augmenting topologies.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12180173},
volume = {10},
year = {2002}
}
@inproceedings{Brant2017,
abstract = {Recent studies have emphasized the merits of search processes that lack overarching objectives, instead promoting divergence by rewarding behavioral novelty. While this less objective search paradigm is more open-ended and divergent, it still diiers sig-niicantly from nature's mechanism of divergence. Rather than measuring novelty explicitly, nature is guided by a single, funda-mental constraint: survive long enough to reproduce. Surprisingly, this simple constraint produces both complexity and diversity in a continual process unparalleled by any algorithm to date. Inspired by the relative simplicity of open-endedness in nature in compar-ison to recent non-objective algorithms, this paper investigates the extent to which interactions between two coevolving popula-tions, both subject to their own constraint, or minimal criterion, can produce results that are both functional and diverse even without any behavior characterization or novelty archive. To test this new approach, a novel maze navigation domain is introduced wherein evolved agents must learn to navigate mazes whose structures are simultaneously coevolving and increasing in complexity. result is a broad range of maze topologies and successful agent trajectories in a single run, thereby suggesting the viability of minimal criterion coevolution as a new approach to non-objective search and a step towards genuinely open-ended algorithms.},
author = {Brant, Jonathan C. and Stanley, Kenneth O.},
doi = {10.1145/3071178.3071186},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brant, Stanley - 2017 - Minimal criterion coevolution.pdf:pdf},
month = {jun},
pages = {67--74},
publisher = {Association for Computing Machinery (ACM)},
title = {{Minimal criterion coevolution}},
year = {2017}
}
@inproceedings{Kotthoff2018,
abstract = {Assessing the progress made in AI and contributions to the state of the art is of major concern to the community. Recently, Frechette et al. [2016] advocated performing such analysis via the Shapley value, a concept from coalitional game theory. In this paper, we argue that while this general idea is sound, it unfairly penalizes older algorithms that advanced the state of the art when introduced, but were then outperformed by modern counterparts. Driven by this observation, we introduce the temporal Shapley value, a measure that addresses this problem while maintaining the desirable properties of the (classical) Shapley value. We use the tempo- ral Shapley value to analyze the progress made in (i) the different versions of the Quicksort algorithm; (ii) the annual SAT competitions 2007–2014; (iii) an annual competition of Constraint Programming, namely the MiniZinc challenge 2014–2016. Our analysis reveals novel insights into the development made in these important areas of research over time.},
author = {Kotthoff, Lars and Fr{\'{e}}chette, Alexandre and Michalak, Tomasz and Rahwan, Talal and Hoos, Holger H. and Leyton-Brown, Kevin},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kotthoff et al. - 2018 - Quantifying algorithmic improvements over time.pdf:pdf},
isbn = {9780999241127},
issn = {10450823},
pages = {5165--5171},
publisher = {International Joint Conferences on Artificial Intelligence},
title = {{Quantifying algorithmic improvements over time}},
volume = {2018-July},
year = {2018}
}
@article{Hutter2017,
abstract = {It is well known that different solution strategies work well for different types of instances of hard combinatorial problems. As a consequence, most solvers for the propositional satisfiability problem (SAT) expose parameters that allow them to be customized to a particular family of instances. In the international SAT competition series, these parameters are ignored: solvers are run using a single default parameter setting (supplied by the authors) for all benchmark instances in a given track. While this competition format rewards solvers with robust default settings, it does not reflect the situation faced by a practitioner who only cares about performance on one particular application and can invest some time into tuning solver parameters for this application. The new Configurable SAT Solver Competition (CSSC) compares solvers in this latter setting, scoring each solver by the performance it achieved after a fully automated configuration step. This article describes the CSSC in more detail, and reports the results obtained in its two instantiations so far, CSSC 2013 and 2014.},
author = {Hutter, Frank and Lindauer, Marius and Balint, Adrian and Bayless, Sam and Hoos, Holger and Leyton-Brown, Kevin},
doi = {10.1016/j.artint.2016.09.006},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hutter et al. - 2017 - The Configurable SAT Solver Challenge (CSSC).pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Algorithm configuration,Competition,Empirical evaluation,Propositional satisfiability},
month = {feb},
pages = {1--25},
publisher = {Elsevier B.V.},
title = {{The Configurable SAT Solver Challenge (CSSC)}},
volume = {243},
year = {2017}
}
@article{Cummings2016,
abstract = {The traditional notion of generalization---i.e., learning a hypothesis whose empirical error is close to its true error---is surprisingly brittle. As has recently been noted in [DFH+15b], even if several algorithms have this guarantee in isolation, the guarantee need not hold if the algorithms are composed adaptively. In this paper, we study three notions of generalization---increasing in strength---that are robust to postprocessing and amenable to adaptive composition, and examine the relationships between them. We call the weakest such notion Robust Generalization. A second, intermediate, notion is the stability guarantee known as differential privacy. The strongest guarantee we consider we call Perfect Generalization. We prove that every hypothesis class that is PAC learnable is also PAC learnable in a robustly generalizing fashion, with almost the same sample complexity. It was previously known that differentially private algorithms satisfy robust generalization. In this paper, we show that robust generalization is a strictly weaker concept, and that there is a learning task that can be carried out subject to robust generalization guarantees, yet cannot be carried out subject to differential privacy. We also show that perfect generalization is a strictly stronger guarantee than differential privacy, but that, nevertheless, many learning tasks can be carried out subject to the guarantees of perfect generalization.},
archivePrefix = {arXiv},
arxivId = {1602.07726},
author = {Cummings, Rachel and Ligett, Katrina and Nissim, Kobbi and Roth, Aaron and Wu, Zhiwei Steven},
eprint = {1602.07726},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cummings et al. - 2016 - Adaptive Learning with Robust Generalization Guarantees.pdf:pdf},
month = {feb},
title = {{Adaptive Learning with Robust Generalization Guarantees}},
url = {http://arxiv.org/abs/1602.07726},
year = {2016}
}
@article{Cardoso2018,
abstract = {In this paper we develop the first algorithms for online submodular minimization that preserve differential privacy under full information feedback and bandit feedback. A sequence of $T$ submodular functions over a collection of $n$ elements arrive online, and at each timestep the algorithm must choose a subset of $[n]$ before seeing the function. The algorithm incurs a cost equal to the function evaluated on the chosen set, and seeks to choose a sequence of sets that achieves low expected regret. Our first result is in the full information setting, where the algorithm can observe the entire function after making its decision at each timestep. We give an algorithm in this setting that is $\epsilon$-differentially private and achieves expected regret $\tilde{O}\left(\frac{n^{3/2}\sqrt{T}}{\epsilon}\right)$. This algorithm works by relaxing submodular function to a convex function using the Lovasz extension, and then simulating an algorithm for differentially private online convex optimization. Our second result is in the bandit setting, where the algorithm can only see the cost incurred by its chosen set, and does not have access to the entire function. This setting is significantly more challenging because the algorithm does not receive enough information to compute the Lovasz extension or its subgradients. Instead, we construct an unbiased estimate using a single-point estimation, and then simulate private online convex optimization using this estimate. Our algorithm using bandit feedback is $\epsilon$-differentially private and achieves expected regret $\tilde{O}\left(\frac{n^{3/2}T^{3/4}}{\epsilon}\right)$.},
archivePrefix = {arXiv},
arxivId = {1807.02290},
author = {Cardoso, Adrian Rivera and Cummings, Rachel},
eprint = {1807.02290},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cardoso, Cummings - 2018 - Differentially Private Online Submodular Optimization.pdf:pdf},
month = {jul},
title = {{Differentially Private Online Submodular Optimization}},
url = {http://arxiv.org/abs/1807.02290},
year = {2018}
}
@article{Zhou2018a,
abstract = {The original simplicial method (OSM), a variant of the classic Kelley's cutting plane method, has been shown to converge to the minimizer of a composite convex and submodular objective, though no rate of convergence for this method was known. Moreover, OSM is required to solve subproblems in each iteration whose size grows linearly in the number of iterations. We propose a limited memory version of Kelley's method (L-KM) and os OSM that requires limited memory (at most n + 1 constraints for an n-dimensional problem) independent of the iteration. We prove convergence for L-KM when the convex part of the objective (g) is strongly convex and show it converges linearly when g is also smooth. Our analysis relies on duality between minimization of the composite objective and minimization of a convex function over the corresponding submodular base polytope. We introduce a limited memory version, L-FCFW, of the Fully-Corrective Frank-Wolfe (FCFW) method with approximate correction, to solve the dual problem. We show that L-FCFW and L-KM are dual algorithms that produce the same sequence of iterates; hence both converge linearly (when g is smooth and strongly convex) and with limited memory. We propose L-KM to minimize composite convex and submodular objectives; however, our results on L-FCFW hold for general polytopes and may be of independent interest.},
archivePrefix = {arXiv},
arxivId = {1807.07531},
author = {Zhou, Song and Gupta, Swati and Udell, Madeleine},
eprint = {1807.07531},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou, Gupta, Udell - 2018 - Limited Memory Kelley's Method Converges for Composite Convex and Submodular Objectives.pdf:pdf},
month = {jul},
title = {{Limited Memory Kelley's Method Converges for Composite Convex and Submodular Objectives}},
url = {http://arxiv.org/abs/1807.07531},
year = {2018}
}
@article{Borsos2019,
abstract = {Adaptive importance sampling for stochastic optimization is a promising approach that offers improved convergence through variance reduction. In this work, we propose a new framework for variance reduction that enables the use of mixtures over predefined sampling distributions, which can naturally encode prior knowledge about the data. While these sampling distributions are fixed, the mixture weights are adapted during the optimization process. We propose VRM, a novel and efficient adaptive scheme that asymptotically recovers the best mixture weights in hindsight and can also accommodate sampling distributions over sets of points. We empirically demonstrate the versatility of VRM in a range of applications.},
archivePrefix = {arXiv},
arxivId = {1903.12416},
author = {Borsos, Zal{\'{a}}n and Curi, Sebastian and Levy, Kfir Y. and Krause, Andreas},
eprint = {1903.12416},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Borsos et al. - 2019 - Online Variance Reduction with Mixtures.pdf:pdf},
month = {mar},
title = {{Online Variance Reduction with Mixtures}},
url = {http://arxiv.org/abs/1903.12416},
year = {2019}
}
@inproceedings{Stan2017,
abstract = {In this paper, we consider optimizing submodular functions that are drawn from some unknown distribution. This setting arises, e.g., in recom-mender systems, where the utility of a subset of items may depend on a user-specific submodular utility function. In modern applications, the ground set of items is often so large that even the widely used (lazy) greedy algorithm is not efficient enough. As a remedy, we introduce the problem of sublinear lime probabilistic submodular maximization: Given training examples of functions (e.g., via user feature vectors), we seek to reduce the ground set so that optimizing new functions drawn from the same distribution will provide almost as much value when restricted to the reduced ground set as when using the full set. We cast this problem as a two-stage submodular maximization and develop a novel efficient algorithm for this problem which offers a 5(1-p) approximation ratio for general monotone submodular functions and general matroid constraints. We demonstrate the effectiveness of our approach on several real-world problem instances where running the maximization problem on the reduced ground set leads to two folds speed-up while incurring almost no loss.},
author = {Stan, Serban and Zadimoghaddam, Morteza and Krause, Andreas and Karbasi, Amin},
booktitle = {International Conference on Machine Learning (ICML)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stan et al. - 2017 - Probabilistic submodular maximization in sub-linear time.pdf:pdf},
isbn = {9781510855144},
title = {{Probabilistic submodular maximization in sub-linear time}},
volume = {7},
year = {2017}
}
@article{Kirschner2019,
abstract = {Bayesian optimization is known to be difficult to scale to high dimensions, because the acquisition step requires solving a non-convex optimization problem in the same search space. In order to scale the method and keep its benefits, we propose an algorithm (LineBO) that restricts the problem to a sequence of iteratively chosen one-dimensional sub-problems. We show that our algorithm converges globally and obtains a fast local rate when the function is strongly convex. Further, if the objective has an invariant subspace, our method automatically adapts to the effective dimension without changing the algorithm. Our method scales well to high dimensions and makes use of a global Gaussian process model. When combined with the SafeOpt algorithm to solve the sub-problems, we obtain the first safe Bayesian optimization algorithm with theoretical guarantees applicable in high-dimensional settings. We evaluate our method on multiple synthetic benchmarks, where we obtain competitive performance. Further, we deploy our algorithm to optimize the beam intensity of the Swiss Free Electron Laser with up to 40 parameters while satisfying safe operation constraints.},
archivePrefix = {arXiv},
arxivId = {1902.03229},
author = {Kirschner, Johannes and Mutn{\'{y}}, Mojm{\'{i}}r and Hiller, Nicole and Ischebeck, Rasmus and Krause, Andreas},
eprint = {1902.03229},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kirschner et al. - 2019 - Adaptive and Safe Bayesian Optimization in High Dimensions via One-Dimensional Subspaces.pdf:pdf},
month = {feb},
title = {{Adaptive and Safe Bayesian Optimization in High Dimensions via One-Dimensional Subspaces}},
url = {http://arxiv.org/abs/1902.03229},
year = {2019}
}
@article{Abbati2019,
abstract = {Stochastic differential equations are an important modeling class in many disciplines. Consequently, there exist many methods relying on various discretization and numerical integration schemes. In this paper, we propose a novel, probabilistic model for estimating the drift and diffusion given noisy observations of the underlying stochastic system. Using state-of-the-art adversarial and moment matching inference techniques, we circumvent the use of the discretization schemes as seen in classical approaches. This yields significant improvements in parameter estimation accuracy and robustness given random initial guesses. On four commonly used benchmark systems, we demonstrate the performance of our algorithms compared to state-of-the-art solutions based on extended Kalman filtering and Gaussian processes.},
archivePrefix = {arXiv},
arxivId = {1902.08480},
author = {Abbati, Gabriele and Wenk, Philippe and Bauer, Stefan and Osborne, Michael A and Krause, Andreas and Sch{\"{o}}lkopf, Bernhard},
eprint = {1902.08480},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abbati et al. - 2019 - AReS and MaRS - Adversarial and MMD-Minimizing Regression for SDEs.pdf:pdf},
month = {feb},
title = {{AReS and MaRS - Adversarial and MMD-Minimizing Regression for SDEs}},
url = {http://arxiv.org/abs/1902.08480},
year = {2019}
}
@techreport{Mitchell,
abstract = {Whereas people learn many different types of knowledge from diverse experiences over many years, most current machine learning systems acquire just a single function or data model from just a single data set. We propose a never-ending learning paradigm for machine learning, to better reflect the more ambitious and encompassing type of learning performed by humans. As a case study, we describe the Never-Ending Language Learner (NELL), which achieves some of the desired properties of a never-ending learner, and we discuss lessons learned. NELL has been learning to read the web 24 hours/day since January 2010, and so far has acquired a knowledge base with over 80 million confidence-weighted beliefs (e.g., servedWith(tea, biscuits)). NELL has also learned millions of features and parameters that enable it to read these beliefs from the web. Additionally, it has learned to reason over these beliefs to infer new beliefs, and is able to extend its ontology by synthesizing new relational predicates. NELL can be tracked online at http://rtw.ml.cmu.edu, and followed on Twitter at @CMUNELL.},
author = {Mitchell, T and Cohen, W and Hruschka, E and Talukdar, P and Betteridge, J and Carlson, A and Dalvi, B and Gardner, M and Kisiel, B and Krishnamurthy, J and Lao, N and Mazaitis, K and Mohammad, T and Nakashole, N and Platanios, E and Ritter, A and Samadi, M and Settles, B and Wang, R and Wijaya, D and Gupta, A and Chen, X and Saparov, A and Greaves, M and Welling, J},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitchell et al. - Unknown - Never-Ending Learning.pdf:pdf},
title = {{Never-Ending Learning}},
url = {http://rtw.ml.cmu.edu}
}
@techreport{Lu2018b,
abstract = {We introduce and study two algorithms to accelerate greedy coordinate descent in theory and in practice: Accelerated Semi-Greedy Coordinate Descent (ASCD) and Accelerated Greedy Coordinate Descent (AGCD). On the theory side, our main results are for ASCD: we show that ASCD achieves O(1/k 2) convergence, and it also achieves accelerated linear convergence for strongly convex functions. On the empirical side, while both AGCD and ASCD outperform Accelerated Randomized Coordinate Descent on most instances in our numerical experiments, we note that AGCD significantly outperforms the other two methods in our experiments, in spite of a lack of theoretical guarantees for this method. To complement this empirical finding for AGCD, we present an explanation why standard proof techniques for acceleration cannot work for AGCD, and we introduce a technical condition under which AGCD is guaranteed to have accelerated convergence. Finally, we confirm that this technical condition holds in our numerical experiments.},
author = {Lu, Haihao and Freund, Robert M and Mirrokni, Vahab},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu, Freund, Mirrokni - 2018 - Accelerating Greedy Coordinate Descent Methods.pdf:pdf},
title = {{Accelerating Greedy Coordinate Descent Methods}},
year = {2018}
}
@inproceedings{Fahrbach2018a,
abstract = {As a generalization of many classic problems in combinatorial optimization, submodular optimization has found a wide range of applications in machine learning (e.g., in feature engineering and active learning). For many large-scale optimization problems, we are often concerned with the adaptivity complexity of an algorithm, which quantifies the number of sequential rounds where polynomially-many independent function evaluations can be executed in parallel. While low adaptivity is ideal, it is not sufficient for a distributed algorithm to be efficient, since in many practical applications of submodular optimization the number of function evaluations becomes prohibitively expensive. Motivated by such applications, we study the adaptivity and query complexity of non-monotone submodular optimization. We provide the first constant approximation algorithm for maximizing a non-monotone submodular function with cardinality constraint $k$ that has nearly-optimal adaptivity complexity $O(\log(n))$. Furthermore, our algorithm makes only $O(\log(k))$ calls per element to the function evaluation oracle in expectation.},
archivePrefix = {arXiv},
arxivId = {1808.06932},
author = {Fahrbach, Matthew and Mirrokni, Vahab and Zadimoghaddam, Morteza},
booktitle = {International Conference on Machine Learning (ICML)},
eprint = {1808.06932},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fahrbach, Mirrokni, Zadimoghaddam - 2019 - Non-monotone Submodular Maximization with Nearly Optimal Adaptivity Complexity.pdf:pdf},
title = {{Non-monotone Submodular Maximization with Nearly Optimal Adaptivity Complexity}},
url = {http://arxiv.org/abs/1808.06932},
year = {2019}
}
@techreport{Crawford,
abstract = {We study the monotone, weakly submodular maximization problem (WSM), which 1 is to find a subset of size k from a universe of size n that maximizes a monotone, 2 weakly submodular objective function f. For objectives with submodularity ratio $\gamma$, 3 we provide two novel evolutionary algorithms that have an expected approximation 4 guarantee of (1 − n −1)(1 − e −$\gamma$ −) for WSM in linear time, improving upon 5 the cubic time complexity of previous evolutionary algorithms for this problem. 6 This improvement is a result of restricting mutations to local changes, a biased 7 random selection of which set to mutate, and an improved theoretical analysis. 8 In the context of several applications of WSM, we demonstrate the ability of our 9 algorithms to quickly exceed the solution of the greedy algorithm and converge 10 faster than existing evolutionary algorithms for WSM.},
author = {Crawford, Victoria and Kuhnle, Alan},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Crawford, Kuhnle - Unknown - Fast Evolutionary Algorithms for Maximization of Cardinality-Constrained Weakly Submodular Functions.pdf:pdf},
title = {{Fast Evolutionary Algorithms for Maximization of Cardinality-Constrained Weakly Submodular Functions}}
}
@inproceedings{Kuhnle2019,
abstract = {We develop two deterministic approximation algorithms for the maximization of 1 non-monotone submodular functions under cardinality constraint: both are based 2 upon the novel idea of interlacing two greedy procedures. Our algorithm FastInter-3 laceGreedy uses interlaced, thresholded greedy procedures to obtain ratio 1/4 − $\epsilon$ 4 in O n $\epsilon$ log n $\epsilon$ queries of the objective, which improves upon both the ratio and 5 the quadratic time complexity of the previously fastest deterministic algorithm for 6 this problem. We validate our algorithms in the context of two applications of non-7 monotone submodular maximization, on which FastInterlaceGreedy outperforms 8 the fastest deterministic and randomized algorithms in prior literature. 9},
author = {Kuhnle, Alan},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhnle - 2019 - Interlaced Greedy Algorithm for Maximization of Submodular Functions in Nearly Linear Time.pdf:pdf},
title = {{Interlaced Greedy Algorithm for Maximization of Submodular Functions in Nearly Linear Time}},
year = {2019}
}
@inproceedings{Friedrich2014,
abstract = {Many combinatorial optimization problems have underlying goal functions that are submodular. The classical goal is to find a good solution for a given submodular function f under a given set of constraints. In this paper, we investigate the runtime of a simple single objective evolutionary algorithm called () EA and a multiobjective evolutionary algorithm called GSEMO until they have obtained a good approximation for submodular functions. For the case of monotone submodular functions and uniform cardinality constraints, we show that the GSEMO achieves a -approximation in expected polynomial time. For the case of monotone functions where the constraints are given by the intersection of matroids, we show that the () EA achieves a ()-approximation in expected polynomial time for any constant . Turning to nonmonotone symmetric submodular functions with matroid intersection constraints, we show that the GSEMO achieves a -approximation in expected time .},
author = {Friedrich, Tobias and Neumann, Frank},
booktitle = {International Conference on Parallel Problem Solving from Nature},
doi = {10.1162/EVCO_a_00159},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Friedrich, Neumann - 2014 - Maximizing submodular functions under matroid constraints by evolutionary algorithms.pdf:pdf},
issn = {15309304},
keywords = {Approximation,Hypervolume indicator,Matroid constraints,Maximum cut,Multiobjective optimization,Runtime,Submodular functions,Theory},
title = {{Maximizing submodular functions under matroid constraints by evolutionary algorithms}},
year = {2014}
}
@article{Elenberg2018,
abstract = {We connect high-dimensional subset selection and submodular maximization. Our results extend the work of Das and Kempe (2011) from the setting of linear regression to arbitrary objective functions. For greedy feature selection, this connection allows us to obtain strong multiplicative performance bounds on several methods without statistical modeling assumptions. We also derive recovery guarantees of this form under standard assumptions. Our work shows that greedy algorithms perform within a constant factor from the best possible subset-selection solution for a broad class of general objective functions. Our methods allow a direct control over the number of obtained features as opposed to regularization parameters that only implicitly control sparsity. Our proof technique uses the concept of weak submodularity initially defined by Das and Kempe. We draw a connection between convex analysis and submodular set function theory which may be of independent interest for other statistical learning applications that have combinatorial structure.},
author = {Elenberg, Ethan R. and Khanna, Rajiv and Dimakis, Alexandros G. and Negahban, Sahand},
doi = {10.1214/17-AOS1679},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elenberg et al. - 2018 - Restricted strong convexity implies weak submodularity.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Greedy algorithms,Restricted strong convexity,Submodular functions,Subset selection},
number = {6B},
pages = {3539--3568},
title = {{Restricted strong convexity implies weak submodularity}},
volume = {46},
year = {2018}
}
@article{Friedrich2018,
abstract = {A core feature of evolutionary algorithms is their mutation operator. Recently, much attention has been devoted to the study of mutation operators with dynamic and non-uniform mutation rates. Following up on this line of work, we propose a new mutation operator and analyze its performance on the (1+1) Evolutionary Algorithm (EA). Our analyses show that this mutation operator competes with pre-existing ones, when used by the (1+1) EA on classes of problems for which results on the other mutation operators are available. We present a "jump" function for which the performance of the (1+1) EA using any static uniform mutation and any restart strategy can be worse than the performance of the (1+1) EA using our mutation operator with no restarts. We show that the (1+1) EA using our mutation operator finds a (1/3)-approximation ratio on any non-negative submodular function in polynomial time. This performance matches that of combinatorial local search algorithms specifically designed to solve this problem. Finally, we evaluate experimentally the performance of the (1+1) EA using our operator, on real-world graphs of different origins with up to 37,000 vertices and 1.6 million edges. In comparison with uniform mutation and a recently proposed dynamic scheme our operator comes out on top on these instances.},
archivePrefix = {arXiv},
arxivId = {1805.10902},
author = {Friedrich, Tobias and G{\"{o}}bel, Andreas and Quinzan, Francesco and Wagner, Markus},
eprint = {1805.10902},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Friedrich et al. - 2018 - Randomized Local Search Heuristics for Submodular Maximization and Covering Problems Benefits of Heavy-tailed.pdf:pdf},
keywords = {evolutionary algorithms,matroids,mutation operators,submodular functions},
pages = {1--18},
title = {{Randomized Local Search Heuristics for Submodular Maximization and Covering Problems: Benefits of Heavy-tailed Mutation Operators}},
url = {http://arxiv.org/abs/1805.10902},
volume = {2},
year = {2018}
}
@article{Models2007,
author = {Models, Multi-objective and Hebbinghaus, Nils},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Models, Hebbinghaus - 2007 - Approximating Covering Problems by Randomized Search Heuristics Using.pdf:pdf},
isbn = {9781595936974},
keywords = {better approximations for,combinatorial optimization,covering prob-,lems,multi-objective optimization,np-hard combinatorial optimization problems,optimization problem leads to,runtime analysis},
number = {Gecco 2007},
pages = {617--633},
title = {{Approximating Covering Problems by Randomized Search Heuristics Using}},
volume = {1},
year = {2007}
}
@article{Lu2012,
abstract = {The influence maximization is an important problem in the field of\nsocial network. Informally it is to select few people to be activated in\na social network such that their aggregated influence can make as many\nas possible people active. Kempe et al. gave a -approximation algorithm\nfor this problem in the linear threshold model and the independent\ncascade model. In addition, Chen et al. proved that the exact\ncomputation of the influence given a seed set is #P-hard in the linear\nthreshold model. Both of the two models are based on randomized\npropagation, however such information might be obtained by surveys and\ndata mining techniques. This will make great difference on the\ncomplexity of the problem. In this note, we study the complexity of the\ninfluence maximization problem in deterministic linear threshold model.\nWe show that in the deterministic linear threshold model, there is no n\n(1-epsilon) -factor polynomial time approximation for the problem unless\nP=NP. We also show that the exact computation of the influence given a\nseed set can be solved in polynomial time.},
author = {Lu, Zaixin and Zhang, Wei and Wu, Weili and Kim, Joonmo and Fu, Bin},
doi = {10.1007/s10878-011-9393-3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu et al. - 2012 - The complexity of influence maximization problem in the deterministic linear threshold model.pdf:pdf},
issn = {13826905},
journal = {Journal of Combinatorial Optimization},
keywords = {Deterministic model,Inapproximation,Social network},
number = {3},
pages = {374--378},
title = {{The complexity of influence maximization problem in the deterministic linear threshold model}},
volume = {24},
year = {2012}
}
@book{Kuhnle2019c,
abstract = {{\textcopyright} 2019, Springer Nature Switzerland AG. While short read aligners, which predominantly use the FM-index, are able to easily index one or a few human genomes, they do not scale well to indexing databases containing thousands of genomes. To understand why, it helps to examine the main components of the FM-index in more detail, which is a rank data structure over the Burrows-Wheeler Transform (BWT ) of the string that will allow us to find the interval in the string's suffix array (SA ) containing pointers to starting positions of occurrences of a given pattern; second, a sample of the SA that—when used with the rank data structure—allows us access to the SA. The rank data structure can be kept small even for large genomic databases, by run-length compressing the BWT, but until recently there was no means known to keep the SA sample small without greatly slowing down access to the SA. Now that Gagie et al. (SODA 2018) have defined an SA sample that takes about the same space as the run-length compressed BWT —we have the design for efficient FM-indexes of genomic databases but are faced with the problem of building them. In 2018 we showed how to build the BWT of large genomic databases efficiently (WABI 2018) but the problem of building Gagie et al.'s SA sample efficiently was left open. We compare our approach to state-of-the-art methods for constructing the SA sample, and demonstrate that it is the fastest and most space-efficient method on highly repetitive genomic databases. Lastly, we apply our method for indexing partial and whole human genomes and show that it improves over Bowtie with respect to both memory and time. Availability: The implementations of our methods can be found at https://gitlab.com/manzai/Big-BWT (BWT and SA sample construction) and at https://github.com/alshai/r-index (indexing).},
author = {Kuhnle, A. and Mun, T. and Boucher, C. and Gagie, T. and Langmead, B. and Manzini, G.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-030-17083-7_10},
isbn = {9783030170820},
issn = {16113349},
title = {{Efficient Construction of a Complete Index for Pan-Genomics Read Alignment}},
volume = {11467 LNBI},
year = {2019}
}
@article{Hastad1999,
author = {Hastad, Johan},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hastad - 1999 - Clique is hard to approximate within n{1-$\epsilon$}.pdf:pdf},
journal = {Acta Mathematica},
pages = {105--142},
title = {{Clique is hard to approximate within n^{1-$\epsilon$}}},
volume = {182},
year = {1999}
}
@techreport{Basu2019,
abstract = {Synopsis of Program: A grand challenge in computing is the creation of machines that can proactively interpret and learn from data in real time, solve unfamiliar problems using what they have learned, and operate with the energy efficiency of the human brain. While complex machine-learning algorithms and advanced electronic hardware (henceforth referred to as 'hardware') that can support large-scale learning have been realized in recent years and support applications such as speech recognition and computer vision, emerging computing challenges require real-time learning, prediction, and automated decision-making in diverse domains such as autonomous vehicles, military applications, healthcare informatics and business analytics. A salient feature of these emerging domains is the large and continuously streaming data sets that these applications generate, which must be processed efficiently enough to support real-time learning and decision making based on these data. This challenge requires novel hardware techniques and machine-learning architectures. This solicitation seeks to lay the foundation for next-generation co-design of RTML algorithms and hardware, with the principal focus on developing novel hardware architectures and learning algorithms in which all stages of training (including incremental training, hyperparameter estimation, and deployment) can be performed in real time. The National Science Foundation (NSF) and the Defense Advanced Research Projects Agency (DARPA) are teaming up through this Real-Time Machine Learning (RTML) program to explore high-performance, energy-efficient hardware and machine-learning architectures that can learn from a continuous stream of new data in real time, through opportunities for post-award collaboration between researchers supported by DARPA and NSF.},
author = {Basu, Sankar and Lin, Jenshan},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Basu, Lin - 2019 - Real-Time Machine Learning (RTML) IMPORTANT INFORMATION AND REVISION NOTES SUMMARY OF PROGRAM REQUIREMENTS General In.pdf:pdf},
keywords = {RTML,Real-Time Machine Learning},
title = {{Real-Time Machine Learning (RTML) IMPORTANT INFORMATION AND REVISION NOTES SUMMARY OF PROGRAM REQUIREMENTS General Information Program Title: Real-Time Machine Learning (RTML)}},
url = {https://www.nsf.gov/publications/pub_summ.jsp?},
year = {2019}
}
@techreport{Finn,
abstract = {Meta-learning for few-shot learning entails acquiring a prior over previous tasks and experiences, such that new tasks be learned from small amounts of data. However, a critical challenge in few-shot learning is task ambiguity: even when a powerful prior can be meta-learned from a large number of prior tasks, a small dataset for a new task can simply be too ambiguous to acquire a single model (e.g., a classifier) for that task that is accurate. In this paper, we propose a probabilistic meta-learning algorithm that can sample models for a new task from a model distribution. Our approach extends model-agnostic meta-learning, which adapts to new tasks via gradient descent, to incorporate a parameter distribution that is trained via a variational lower bound. At meta-test time, our algorithm adapts via a simple procedure that injects noise into gradient descent, and at meta-training time, the model is trained such that this stochastic adaptation procedure produces samples from the approximate model posterior. Our experimental results show that our method can sample plausible classifiers and regressors in ambiguous few-shot learning problems. We also show how reasoning about ambiguity can also be used for downstream active learning problems.},
author = {Finn, Chelsea and Xu, Kelvin and Levine, Sergey},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Finn, Xu, Levine - Unknown - Probabilistic Model-Agnostic Meta-Learning.pdf:pdf},
title = {{Probabilistic Model-Agnostic Meta-Learning}}
}
@article{Do,
abstract = {Single-cell RNA sequencing enables the construction of trajectories describing the dynamic changes in gene expression underlying biological processes such as cell differentiation and development. The comparison of single-cell trajectories under two distinct conditions can illuminate the differences and similarities between the two and can thus be a powerful tool. Recently developed methods for the comparison of trajectories rely on the concept of dynamic time warping (dtw), which was originally proposed for the comparison of two time series. Consequently, these methods are restricted to simple, linear trajectories. Here, we adopt and theoretically link arboreal matchings to dtw and propose an algorithm to compare complex trajectories that more realistically contain branching points that divert cells into different fates. We implement a suite of exact and heuristic algorithms suitable for the comparison of trajectories of different characteristics in our tool Trajan. Trajan automatically pairs similar biological processes between conditions and aligns them in a globally consistent manner. In an alignment of single-cell trajectories describing human muscle differentiation and myogenic reprogramming, Trajan identifies and aligns the core paths without prior information. From Trajan's alignment, we are able to reproduce recently reported barriers to reprogramming. In a perturbation experiment, we demonstrate the benefits in terms of robustness and accuracy of our model which compares entire trajectories at once, as opposed to a pairwise application of dtw. Trajan is available at https://github.com/canzarlab/Trajan.},
author = {Do, Van Hoan and Bla{\v{z}}evi´bla{\v{z}}evi´c, Mislav and Monteagudo, Pablo and Borozan, Luka and Elbassioni, Khaled and Laue, S{\"{o}}ren and Ringeling, Francisca Rojas and Matijevi´cmatijevi´c, Domagoj and Canzar, Stefan},
doi = {10.1101/522672},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Do et al. - Unknown - Dynamic pseudo-time warping of complex single-cell trajectories.pdf:pdf},
title = {{Dynamic pseudo-time warping of complex single-cell trajectories}},
url = {http://dx.doi.org/10.1101/522672}
}
@article{Hie,
abstract = {Large-scale single-cell RNA-sequencing (scRNA-seq) studies that profile hundreds of thousands of cells are becoming increasingly common, overwhelming existing analysis pipelines. Here, we describe how to enhance and accelerate single-cell data analysis by summarizing the transcriptomic heterogeneity within a data set using a small subset of cells, which we refer to as a geometric sketch. Our sketches provide more comprehensive visualization of transcriptional diversity, capture rare cell types with high sensitivity, and accurately reveal biological cell types via clustering. Our sketch of umbilical cord blood cells uncovers a rare subpopulation of inflammatory macrophages, which we experimentally validated in vitro.},
author = {Hie, Brian and Cho, Hyunghoon and Demeo, Benjamin and Bryson, Bryan and Berger, Bonnie},
doi = {10.1101/536730},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hie et al. - Unknown - Title Geometric Sketching Compactly Summarizes the Single-Cell Transcriptomic Landscape.pdf:pdf;:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hie et al. - Unknown - Title Geometric Sketching Compactly Summarizes the Single-Cell Transcriptomic Landscape(2).pdf:pdf},
title = {{Title: Geometric Sketching Compactly Summarizes the Single-Cell Transcriptomic Landscape}},
url = {http://dx.doi.org/10.1101/536730}
}
@article{Gangwani2017,
abstract = {Genetic algorithms have been widely used in many practical optimization problems. Inspired by natural selection, operators, including mutation, crossover and selection, provide effective heuristics for search and black-box optimization. However, they have not been shown useful for deep reinforcement learning, possibly due to the catastrophic consequence of parameter crossovers of neural networks. Here, we present Genetic Policy Optimization (GPO), a new genetic algorithm for sample-efficient deep policy optimization. GPO uses imitation learning for policy crossover in the state space and applies policy gradient methods for mutation. Our experiments on MuJoCo tasks show that GPO as a genetic algorithm is able to provide superior performance over the state-of-the-art policy gradient methods and achieves comparable or higher sample efficiency.},
archivePrefix = {arXiv},
arxivId = {1711.01012},
author = {Gangwani, Tanmay and Peng, Jian},
eprint = {1711.01012},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gangwani, Peng - 2017 - Policy Optimization by Genetic Distillation.pdf:pdf},
month = {nov},
title = {{Policy Optimization by Genetic Distillation}},
url = {http://arxiv.org/abs/1711.01012},
year = {2017}
}
@article{Marschall2018,
abstract = {Many disciplines, from human genetics and oncology to plant breeding, microbiology and virology, commonly face the challenge of analyzing rapidly increasing numbers of genomes. In case of Homo sapiens, the number of sequenced genomes will approach hundreds of thousands in the next few years. Simply scaling up established bioinformatics pipelines will not be sufficient for leveraging the full potential of such rich genomic data sets. Instead, novel, qualitatively different computational methods and paradigms are needed. We will witness the rapid extension of computational pan-genomics, a new sub-area of research in computational biology. In this article, we generalize existing definitions and understand a pan-genome as any collection of genomic sequences to be analyzed jointly or to be used as a reference. We examine already available approaches to construct and use pan-genomes, discuss the potential benefits of future technologies and methodologies and review open challenges from the vantage point of the above-mentioned biological disciplines. As a prominent example for a computational paradigm shift, we particularly highlight the transition from the representation of reference genomes as strings to representations as graphs. We outline how this and other challenges from different application domains translate into common computational problems, point out relevant bioinformatics techniques and identify open problems in computer science. With this review, we aim to increase awareness that a joint approach to computational pan-genomics can help address many of the problems currently faced in various domains.},
author = {Marschall, Tobias and Marz, Manja and Abeel, Thomas and Dijkstra, Louis and Dutilh, Bas E. and Ghaffaari, Ali and Kersey, Paul and Kloosterman, Wigard P. and M{\"{a}}kinen, Veli and Novak, Adam M. and Paten, Benedict and Porubsky, David and Rivals, Eric and Alkan, Can and Baaijens, Jasmijn A. and {De Bakker}, Paul I.W. and Boeva, Valentina and Bonnal, Raoul J.P. and Chiaromonte, Francesca and Chikhi, Rayan and Ciccarelli, Francesca D. and Cijvat, Robin and Datema, Erwin and {Van Duijn}, Cornelia M. and Eichler, Evan E. and Ernst, Corinna and Eskin, Eleazar and Garrison, Erik and El-Kebir, Mohammed and Klau, Gunnar W. and Korbel, Jan O. and Lameijer, Eric Wubbo and Langmead, Benjamin and Martin, Marcel and Medvedev, Paul and Mu, John C. and Neerincx, Pieter and Ouwens, Klaasjan and Peterlongo, Pierre and Pisanti, Nadia and Rahmann, Sven and Raphael, Ben and Reinert, Knut and de Ridder, Dick and de Ridder, Jeroen and Schlesner, Matthias and Schulz-Trieglaff, Ole and Sanders, Ashley D. and Sheikhizadeh, Siavash and Shneider, Carl and Smit, Sandra and Valenzuela, Daniel and Wang, Jiayin and Wessels, Lodewyk and Zhang, Ying and Guryev, Victor and Vandin, Fabio and Ye, Kai and Sch{\"{o}}nhuth, Alexander},
doi = {10.1093/bib/bbw089},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marschall et al. - 2018 - Computational pan-genomics Status, promises and challenges.pdf:pdf},
issn = {14774054},
journal = {Briefings in Bioinformatics},
keywords = {Data structures,Haplotypes,Pan-genome,Read mapping,Sequence graph},
month = {jan},
number = {1},
pages = {118--135},
publisher = {Oxford University Press},
title = {{Computational pan-genomics: Status, promises and challenges}},
volume = {19},
year = {2018}
}
@article{Berger2016,
abstract = {COMPUTATIONAL BIOLOGISTS ANSWER biological and biomedical questions by using computation in support of—or in place of—laboratory procedures, hoping to obtain more accurate answers at a greatly reduced cost. The past two decades have seen unprecedented technological progress with regard to generating biological data; next-generation sequencing, mass spectrometry, microarrays, cryo-electron microscopy, and other high-throughput approaches have led to an explosion of data. However, this explosion is a mixed blessing. On the one hand, the scale and scope of data should allow new insights into genetic and infectious diseases, cancer, basic biology, and even human migration patterns. On the other hand, researchers are generating datasets so massive that it has become difficult to analyze them to discover patterns that give clues to the underlying biological processes.},
author = {Berger, Bonnie and Daniels, Noah M. and Yu, Y. William},
doi = {10.1145/2957324},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berger, Daniels, Yu - 2016 - Computational biology in the 21st century.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = {jul},
number = {8},
pages = {72--80},
publisher = {Association for Computing Machinery (ACM)},
title = {{Computational biology in the 21st century}},
volume = {59},
year = {2016}
}
@article{Loh2012,
abstract = {Algorithms that compute directly on compressed genomic data allow analyses to keep pace with data generation.},
author = {Loh, Po-Ru and Baym, Michael and Berger, Bonnie},
doi = {10.1038/nbt.2241},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Loh, Baym, Berger - 2012 - Compressive genomics.pdf:pdf},
issn = {1087-0156},
journal = {Nature Biotechnology},
month = {jul},
number = {7},
pages = {627--630},
publisher = {Springer Nature},
title = {{Compressive genomics}},
volume = {30},
year = {2012}
}
@article{Yu2015,
abstract = {Summary Many datasets exhibit a well-defined structure that can be exploited to design faster search tools, but it is not always clear when such acceleration is possible. Here, we introduce a framework for similarity search based on characterizing a dataset's entropy and fractal dimension. We prove that searching scales in time with metric entropy (number of covering hyperspheres), if the fractal dimension of the dataset is low, and scales in space with the sum of metric entropy and information-theoretic entropy (randomness of the data). Using these ideas, we present accelerated versions of standard tools, with no loss in specificity and little loss in sensitivity, for use in three domains - high-throughput drug screening (Ammolite, 150× speedup), metagenomics (MICA, 3.5× speedup of DIAMOND [3,700× BLASTX]), and protein structure search (esFragBag, 10× speedup of FragBag). Our framework can be used to achieve "'compressive omics," and the general theory can be readily applied to data science problems outside of biology (source code: http://gems.csail.mit.edu).},
author = {Yu, Y. William and Daniels, Noah M. and Danko, David Christian and Berger, Bonnie},
doi = {10.1016/j.cels.2015.08.004},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu et al. - 2015 - Entropy-Scaling Search of Massive Biological Data.pdf:pdf},
issn = {24054712},
journal = {Cell Systems},
month = {aug},
number = {2},
pages = {130--140},
publisher = {Cell Press},
title = {{Entropy-Scaling Search of Massive Biological Data}},
volume = {1},
year = {2015}
}
@article{Cho2018,
abstract = {Representing data in hyperbolic space can effectively capture latent hierarchical relationships. With the goal of enabling accurate classification of points in hyperbolic space while respecting their hyperbolic geometry, we introduce hyperbolic SVM, a hyperbolic formulation of support vector machine classifiers, and elucidate through new theoretical work its connection to the Euclidean counterpart. We demonstrate the performance improvement of hyperbolic SVM for multi-class prediction tasks on real-world complex networks as well as simulated datasets. Our work allows analytic pipelines that take the inherent hyperbolic geometry of the data into account in an end-to-end fashion without resorting to ill-fitting tools developed for Euclidean space.},
archivePrefix = {arXiv},
arxivId = {1806.00437},
author = {Cho, Hyunghoon and DeMeo, Benjamin and Peng, Jian and Berger, Bonnie},
eprint = {1806.00437},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cho et al. - 2018 - Large-Margin Classification in Hyperbolic Space.pdf:pdf},
month = {jun},
title = {{Large-Margin Classification in Hyperbolic Space}},
url = {http://arxiv.org/abs/1806.00437},
year = {2018}
}
@article{Niazadeh2018,
abstract = {In this paper we study the fundamental problems of maximizing a continuous non-monotone submodular function over the hypercube, both with and without coordinate-wise concavity. This family of optimization problems has several applications in machine learning, economics, and communication systems. Our main result is the first $\frac{1}{2}$-approximation algorithm for continuous submodular function maximization; this approximation factor of $\frac{1}{2}$ is the best possible for algorithms that only query the objective function at polynomially many points. For the special case of DR-submodular maximization, i.e. when the submodular functions is also coordinate wise concave along all coordinates, we provide a different $\frac{1}{2}$-approximation algorithm that runs in quasilinear time. Both of these results improve upon prior work [Bian et al, 2017, Soma and Yoshida, 2017]. Our first algorithm uses novel ideas such as reducing the guaranteed approximation problem to analyzing a zero-sum game for each coordinate, and incorporates the geometry of this zero-sum game to fix the value at this coordinate. Our second algorithm exploits coordinate-wise concavity to identify a monotone equilibrium condition sufficient for getting the required approximation guarantee, and hunts for the equilibrium point using binary search. We further run experiments to verify the performance of our proposed algorithms in related machine learning applications.},
archivePrefix = {arXiv},
arxivId = {1805.09480},
author = {Niazadeh, Rad and Roughgarden, Tim and Wang, Joshua R.},
eprint = {1805.09480},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Niazadeh, Roughgarden, Wang - 2018 - Optimal Algorithms for Continuous Non-monotone Submodular and DR-Submodular Maximization.pdf:pdf},
month = {may},
title = {{Optimal Algorithms for Continuous Non-monotone Submodular and DR-Submodular Maximization}},
url = {http://arxiv.org/abs/1805.09480},
year = {2018}
}
@inproceedings{Gupta2013,
abstract = {In the Stochastic Orienteering problem, we are given a metric, where each node also has a job located there with some deterministic reward and a random size. (Think of the jobs as being chores one needs to run, and the sizes as the amount of time it takes to do the chore.) The goal is to adaptively decide which nodes to visit to maximize total expected reward, subject to the constraint that the total distance traveled plus the total size of jobs processed is at most a given budget of B. (I.e., we get reward for all those chores we finish by the end of the day). The (random) size of a job is not known until it is completely processed. Hence the problem combines aspects of both the stochastic knapsack problem with uncertain item sizes and the deterministic orienteering problem of using a limited travel time to maximize gathered rewards located at nodes. In this paper, we present a constant-factor approximation algorithm for the best non-adaptive policy for the Stochastic Orienteering problem. We also show a small adaptivity gap---i.e., the existence of a non-adaptive policy whose reward is at least an $\Omega$(1/log log B) fraction of the optimal expected reward---and hence we also get an O(log log B)-approximation algorithm for the adaptive problem. Finally we address the case when the node rewards are also random and could be correlated with the waiting time, and give a non-adaptive policy which is an O(log n {logB})-approximation to the best adaptive policy on n-node metrics with budget B.},
author = {Gupta, Anupam and Krishnaswamy, Ravishankar and Nagarajan, Viswanath and Ravi, R.},
doi = {10.1137/1.9781611973099.121},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta et al. - 2013 - Approximation Algorithms for Stochastic Orienteering.pdf:pdf},
month = {dec},
pages = {1522--1538},
publisher = {Society for Industrial & Applied Mathematics (SIAM)},
title = {{Approximation Algorithms for Stochastic Orienteering}},
year = {2013}
}
@article{Li2018,
abstract = {We introduce a new approach to decomposable submodular function minimization (DSFM) that exploits incidence relations. Incidence relations describe which variables effectively influence the component functions, and when properly utilized, they allow for improving the convergence rates of DSFM solvers. Our main results include the precise parametrization of the DSFM problem based on incidence relations, the development of new scalable alternative projections and parallel coordinate descent methods and an accompanying rigorous analysis of their convergence rates.},
archivePrefix = {arXiv},
arxivId = {1803.03851},
author = {Li, Pan and Milenkovic, Olgica},
eprint = {1803.03851},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Milenkovic - 2018 - Revisiting Decomposable Submodular Function Minimization with Incidence Relations.pdf:pdf},
month = {mar},
title = {{Revisiting Decomposable Submodular Function Minimization with Incidence Relations}},
url = {http://arxiv.org/abs/1803.03851},
year = {2018}
}
@article{Balkanski2018b,
abstract = {In this paper we consider parallelization for applications whose objective can be expressed as maximizing a non-monotone submodular function under a cardinality constraint. Our main result is an algorithm whose approximation is arbitrarily close to $1/2e$ in $O(\log^2 n)$ adaptive rounds, where $n$ is the size of the ground set. This is an exponential speedup in parallel running time over any previously studied algorithm for constrained non-monotone submodular maximization. Beyond its provable guarantees, the algorithm performs well in practice. Specifically, experiments on traffic monitoring and personalized data summarization applications show that the algorithm finds solutions whose values are competitive with state-of-the-art algorithms while running in exponentially fewer parallel iterations.},
archivePrefix = {arXiv},
arxivId = {1807.11462},
author = {Balkanski, Eric and Breuer, Adam and Singer, Yaron},
eprint = {1807.11462},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balkanski, Breuer, Singer - 2018 - Non-monotone Submodular Maximization in Exponentially Fewer Iterations(2).pdf:pdf},
month = {jul},
title = {{Non-monotone Submodular Maximization in Exponentially Fewer Iterations}},
url = {http://arxiv.org/abs/1807.11462},
year = {2018}
}
@inproceedings{Feldman2018,
abstract = {In this paper, we develop the first one-pass streaming algorithm for submodular maximization that does not evaluate the entire stream even once. By carefully subsampling each element of data stream, our algorithm enjoys the tightest approximation guarantees in various settings while having the smallest memory footprint and requiring the lowest number of function evaluations. More specifically, for a monotone submodular function and a $p$-matchoid constraint, our randomized algorithm achieves a $4p$ approximation ratio (in expectation) with $O(k)$ memory and $O(km/p)$ queries per element ($k$ is the size of the largest feasible solution and $m$ is the number of matroids used to define the constraint). For the non-monotone case, our approximation ratio increases only slightly to $4p+2-o(1)$. To the best or our knowledge, our algorithm is the first that combines the benefits of streaming and subsampling in a novel way in order to truly scale submodular maximization to massive machine learning problems. To showcase its practicality, we empirically evaluated the performance of our algorithm on a video summarization application and observed that it outperforms the state-of-the-art algorithm by up to fifty fold, while maintaining practically the same utility.},
archivePrefix = {arXiv},
arxivId = {1802.07098},
author = {Feldman, Moran and Karbasi, Amin and Kazemi, Ehsan},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
eprint = {1802.07098},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feldman, Karbasi, Kazemi - 2018 - Do less, Get More Streaming Submodular Maximization with Subsampling.pdf:pdf;:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feldman, Karbasi, Kazemi - 2018 - Do less, Get More Streaming Submodular Maximization with Subsampling(2).pdf:pdf},
issn = {10495258},
title = {{Do less, Get More: Streaming Submodular Maximization with Subsampling}},
url = {http://arxiv.org/abs/1802.07098},
year = {2018}
}
@techreport{Hassidim,
abstract = {We consider the problem of maximizing a submodular function when given access to its approximate version. Submodular functions are heavily studied in a wide variety of disciplines since they are used to model many real world phenomena and are amenable to optimization. There are many cases however in which the phenomena we observe is only approximately submodular and the optimization guarantees cease to hold. In this paper we describe a technique that yields strong guarantees for maximization of monotone submodular functions from approximate surrogates under cardinality and intersection of matroid constraints. In particular, we show tight guarantees for maximization under a cardinality constraint and 1/(1 + P) approximation under intersection of P matroids.},
author = {Hassidim, Avinatan and Singer, Yaron},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hassidim, Singer - Unknown - Optimization for Approximate Submodularity.pdf:pdf},
title = {{Optimization for Approximate Submodularity}}
}
@article{Bach2017,
abstract = {We consider the minimization of submodular functions subject to ordering constraints. We show that this optimization problem can be cast as a convex optimization problem on a space of uni-dimensional measures, with ordering constraints corresponding to first-order stochastic dominance. We propose new discretization schemes that lead to simple and efficient algorithms based on zero-th, first, or higher order oracles; these algorithms also lead to improvements without isotonic constraints. Finally, our experiments show that non-convex loss functions can be much more robust to outliers for isotonic regression, while still leading to an efficient optimization problem.},
archivePrefix = {arXiv},
arxivId = {1707.09157},
author = {Bach, Francis},
eprint = {1707.09157},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bach - 2017 - Efficient Algorithms for Non-convex Isotonic Regression through Submodular Optimization.pdf:pdf},
month = {jul},
title = {{Efficient Algorithms for Non-convex Isotonic Regression through Submodular Optimization}},
url = {http://arxiv.org/abs/1707.09157},
year = {2017}
}
@article{Liang2018a,
abstract = {One of the main difficulties in analyzing neural networks is the non-convexity of the loss function which may have many bad local minima. In this paper, we study the landscape of neural networks for binary classification tasks. Under mild assumptions, we prove that after adding one special neuron with a skip connection to the output, or one special neuron per layer, every local minimum is a global minimum.},
archivePrefix = {arXiv},
arxivId = {1805.08671},
author = {Liang, Shiyu and Sun, Ruoyu and Lee, Jason D. and Srikant, R.},
eprint = {1805.08671},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang et al. - 2018 - Adding One Neuron Can Eliminate All Bad Local Minima.pdf:pdf},
month = {may},
title = {{Adding One Neuron Can Eliminate All Bad Local Minima}},
url = {http://arxiv.org/abs/1805.08671},
year = {2018}
}
@article{Zhang2018a,
abstract = {Link prediction is a key problem for network-structured data. Link prediction heuristics use some score functions, such as common neighbors and Katz index, to measure the likelihood of links. They have obtained wide practical uses due to their simplicity, interpretability, and for some of them, scalability. However, every heuristic has a strong assumption on when two nodes are likely to link, which limits their effectiveness on networks where these assumptions fail. In this regard, a more reasonable way should be learning a suitable heuristic from a given network instead of using predefined ones. By extracting a local subgraph around each target link, we aim to learn a function mapping the subgraph patterns to link existence, thus automatically learning a `heuristic' that suits the current network. In this paper, we study this heuristic learning paradigm for link prediction. First, we develop a novel $\gamma$-decaying heuristic theory. The theory unifies a wide range of heuristics in a single framework, and proves that all these heuristics can be well approximated from local subgraphs. Our results show that local subgraphs reserve rich information related to link existence. Second, based on the $\gamma$-decaying theory, we propose a new algorithm to learn heuristics from local subgraphs using a graph neural network (GNN). Its experimental results show unprecedented performance, working consistently well on a wide range of problems.},
archivePrefix = {arXiv},
arxivId = {1802.09691},
author = {Zhang, Muhan and Chen, Yixin},
eprint = {1802.09691},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Chen - 2018 - Link Prediction Based on Graph Neural Networks.pdf:pdf},
month = {feb},
title = {{Link Prediction Based on Graph Neural Networks}},
url = {http://arxiv.org/abs/1802.09691},
year = {2018}
}
@article{Zhang2018b,
abstract = {Link prediction is a key problem for network-structured data. Link prediction heuristics use some score functions, such as common neighbors and Katz index, to measure the likelihood of links. They have obtained wide practical uses due to their simplicity, interpretability, and for some of them, scalability. However, every heuristic has a strong assumption on when two nodes are likely to link, which limits their effectiveness on networks where these assumptions fail. In this regard, a more reasonable way should be learning a suitable heuristic from a given network instead of using predefined ones. By extracting a local subgraph around each target link, we aim to learn a function mapping the subgraph patterns to link existence, thus automatically learning a `heuristic' that suits the current network. In this paper, we study this heuristic learning paradigm for link prediction. First, we develop a novel $\gamma$-decaying heuristic theory. The theory unifies a wide range of heuristics in a single framework, and proves that all these heuristics can be well approximated from local subgraphs. Our results show that local subgraphs reserve rich information related to link existence. Second, based on the $\gamma$-decaying theory, we propose a new algorithm to learn heuristics from local subgraphs using a graph neural network (GNN). Its experimental results show unprecedented performance, working consistently well on a wide range of problems.},
archivePrefix = {arXiv},
arxivId = {1802.09691},
author = {Zhang, Muhan and Chen, Yixin},
eprint = {1802.09691},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Chen - 2018 - Link Prediction Based on Graph Neural Networks.pdf:pdf},
month = {feb},
title = {{Link Prediction Based on Graph Neural Networks}},
url = {http://arxiv.org/abs/1802.09691},
year = {2018}
}
@inproceedings{Qian2015,
abstract = {Selecting the optimal subset from a large set of variables is a fundamental problem in various learning tasks such as feature selection, sparse regression, dictionary learning, etc. In this paper, we propose the POSS approach which employs evo-lutionary Pareto optimization to find a small-sized subset with good performance. We prove that for sparse regression, POSS is able to achieve the best-so-far the-oretically guaranteed approximation performance efficiently. Particularly, for the Exponential Decay subclass, POSS is proven to achieve an optimal solution. Em-pirical study verifies the theoretical results, and exhibits the superior performance of POSS to greedy and convex relaxation methods.},
author = {Qian, Chao and Yu, Yang and Zhou, Zhi-hua},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qian, Yu, Zhou - 2015 - Subset Selection by Pareto Optimization.pdf:pdf},
issn = {10495258},
title = {{Subset Selection by Pareto Optimization}},
year = {2015}
}
@inproceedings{Jenkyns1976,
author = {Jenkyns, T. A.},
booktitle = {Proceedings of the 7th Southeastern Conference on Combinatorics, Graph Theory and Computing},
keywords = {submodular functions},
mendeley-tags = {submodular functions},
title = {{The efficacy of the "greedy" algorithm}},
year = {1976}
}
@article{Bazgan2005,
abstract = {Several problems are known to be APX-, DAPX-, PTAS-, or Poly-APX-PB-complete under suitably defined approximation-preserving reductions. But, to our knowledge, no natural problem is known to be PTAS-complete and no problem at all is known to be Poly-APX-complete. On the other hand, DPTAS- and Poly-DAPX-completeness have not been studied until now. We first prove in this paper the existence of natural Poly-APX- and Poly-DAPX-complete problems under the well known PTAS-reduction and under the DPTAS-reduction (defined in "G. Ausiello, C. Bazgan, M. Demange, and V. Th. Paschos, Completeness in differential approximation classes, MFCS'03"), respectively. Next, we deal with PTAS- and DPTAS-completeness. We introduce approximation preserving reductions, called FT and DFT, respectively, and prove that, under these new reductions, natural problems are PTAS-complete, or DPTAS-complete. Then, we deal with the existence of intermediate problems under our reductions and we partially answer this question showing that the existence of NPO-intermediate problems under Turing-reductions is a sufficient condition for the existence of intermediate problems under both FT- and DFT-reductions. Finally, we show that MIN COLORING is DAPX-complete under DPTAS-reductions. This is the first DAPX-complete problem that is not simultaneously APX-complete. {\textcopyright} 2005 Elsevier B.V. All rights reserved.},
author = {Bazgan, Cristina and Escoffier, Bruno and Paschos, Vangelis Th},
doi = {10.1016/j.tcs.2005.03.007},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bazgan, Escoffier, Paschos - 2005 - Completeness in standard and differential approximation classes Poly-(D)APX- and (D)PTAS-completenes.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Approximation algorithm,Approximation schema,Combinatorial optimization,Completeness,Complexity,Reduction},
number = {2-3},
pages = {272--292},
title = {{Completeness in standard and differential approximation classes: Poly-(D)APX- and (D)PTAS-completeness}},
volume = {339},
year = {2005}
}
@article{Chen2017a,
abstract = {We present HARP, a novel method for learning low dimensional embeddings of a graph's nodes which preserves higher-order structural features. Our proposed method achieves this by compressing the input graph prior to embedding it, effectively avoiding troublesome embedding configurations (i.e. local minima) which can pose problems to non-convex optimization. HARP works by finding a smaller graph which approximates the global structure of its input. This simplified graph is used to learn a set of initial representations, which serve as good initializations for learning representations in the original, detailed graph. We inductively extend this idea, by decomposing a graph in a series of levels, and then embed the hierarchy of graphs from the coarsest one to the original graph. HARP is a general meta-strategy to improve all of the state-of-the-art neural algorithms for embedding graphs, including DeepWalk, LINE, and Node2vec. Indeed, we demonstrate that applying HARP's hierarchical paradigm yields improved implementations for all three of these methods, as evaluated on both classification tasks on real-world graphs such as DBLP, BlogCatalog, CiteSeer, and Arxiv, where we achieve a performance gain over the original implementations by up to 14% Macro F1.},
archivePrefix = {arXiv},
arxivId = {1706.07845},
author = {Chen, Haochen and Perozzi, Bryan and Hu, Yifan and Skiena, Steven},
doi = {10.475/123},
eprint = {1706.07845},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2017 - HARP Hierarchical Representation Learning for Networks.pdf:pdf},
isbn = {9781450335423},
issn = {16130073},
title = {{HARP: Hierarchical Representation Learning for Networks}},
year = {2017}
}
@article{Chen2018a,
abstract = {Network embedding methods aim at learning low-dimensional latent representation of nodes in a network. These representations can be used as features for a wide range of tasks on graphs such as classification, clustering, link prediction, and visualization. In this survey, we give an overview of network embeddings by summarizing and categorizing recent advancements in this research field. We first discuss the desirable properties of network embeddings and briefly introduce the history of network embedding algorithms. Then, we discuss network embedding methods under different scenarios, such as supervised versus unsupervised learning, learning embeddings for homogeneous networks versus for heterogeneous networks, etc. We further demonstrate the applications of network embeddings, and conclude the survey with future work in this area.},
archivePrefix = {arXiv},
arxivId = {1808.02590},
author = {Chen, Haochen and Perozzi, Bryan and Al-Rfou, Rami and Skiena, Steven},
doi = {arXiv:1808.02590v1},
eprint = {1808.02590},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2018 - A Tutorial on Network Embeddings.pdf:pdf},
title = {{A Tutorial on Network Embeddings}},
year = {2018}
}
@inproceedings{Naor2011,
author = {Naor, Joseph Seffi and Schwartz, Roy},
booktitle = {Symposium on Foundations of Computer Science (FOCS)},
doi = {10.1109/FOCS.2011.46},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Naor, Schwartz - 2011 - A Unified Continuous Greedy Algorithm for Submodular Maximization.pdf:pdf},
isbn = {0272-5428},
title = {{A Unified Continuous Greedy Algorithm for Submodular Maximization}},
year = {2011}
}
@article{Gharan2010,
abstract = {We consider the problem of maximizing a nonnegative (possibly non-monotone) submodular set function with or without constraints. Feige et al. [FOCS'07] showed a 2/5-approximation for the unconstrained problem and also proved that no approximation better than 1/2 is possible in the value oracle model. Constant-factor approximation was also given for submodular maximization subject to a matroid independence constraint (a factor of 0.309 Vondrak [FOCS'09]) and for submodular maximization subject to a matroid base constraint, provided that the fractional base packing number is at least 2 (a 1/4-approximation, Vondrak [FOCS'09]). In this paper, we propose a new algorithm for submodular maximization which is based on the idea of {\em simulated annealing}. We prove that this algorithm achieves improved approximation for two problems: a 0.41-approximation for unconstrained submodular maximization, and a 0.325-approximation for submodular maximization subject to a matroid independence constraint. On the hardness side, we show that in the value oracle model it is impossible to achieve a 0.478-approximation for submodular maximization subject to a matroid independence constraint, or a 0.394-approximation subject to a matroid base constraint in matroids with two disjoint bases. Even for the special case of cardinality constraint, we prove it is impossible to achieve a 0.491-approximation. (Previously it was conceivable that a 1/2-approximation exists for these problems.) It is still an open question whether a 1/2-approximation is possible for unconstrained submodular maximization.},
archivePrefix = {arXiv},
arxivId = {1007.1632},
author = {Gharan, Shayan Oveis and Vondr{\'{a}}k, Jan},
doi = {10.1137/1.9781611973082.83},
eprint = {1007.1632},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gharan, Vondr{\'{a}}k - 2010 - Submodular Maximization by Simulated Annealing.pdf:pdf},
isbn = {9780898719932},
pages = {1098--1116},
title = {{Submodular Maximization by Simulated Annealing}},
url = {http://arxiv.org/abs/1007.1632},
year = {2010}
}
@article{IanGoodfellowYoshuaBengio2017,
abstract = {Deep Learning book},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {{Ian Goodfellow, Yoshua Bengio}, Aaron Courville},
doi = {10.1016/B978-0-12-391420-0.09987-X},
eprint = {arXiv:1011.1669v3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ian Goodfellow, Yoshua Bengio - 2017 - The Deep Learning Book.pdf:pdf},
isbn = {3540620583, 9783540620587},
issn = {1432122X},
journal = {MIT Press},
number = {7553},
pages = {785},
pmid = {21728107},
title = {{The Deep Learning Book}},
volume = {521},
year = {2017}
}
@article{Buchbinder2016,
abstract = {The study of combinatorial optimization problems with a submodular objective has attracted much attention in recent years. Such problems are important in both theory and practice because their objective functions are very general. Obtaining further improvements for many submodular maximization problems boils down to finding better algorithms for optimizing a relaxation of them known as the multilinear extension. In this work we present an algorithm for optimizing the multilinear relaxation whose guarantee improves over the guarantee of the best previous algorithm (which was given by Ene and Nguyen (2016)). Moreover, our algorithm is based on a new technique which is, arguably, simpler and more natural for the problem at hand. In a nutshell, previous algorithms for this problem rely on symmetry properties which are natural only in the absence of a constraint. Our technique avoids the need to resort to such properties, and thus, seems to be a better fit for constrained problems.},
archivePrefix = {arXiv},
arxivId = {1611.03253},
author = {Buchbinder, Niv and Feldman, Moran},
eprint = {1611.03253},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buchbinder, Feldman - 2016 - Constrained Submodular Maximization via a Non-symmetric Technique.pdf:pdf},
journal = {Mathematics of Operations Research},
number = {3},
title = {{Constrained Submodular Maximization via a Non-symmetric Technique}},
url = {http://arxiv.org/abs/1611.03253},
volume = {44},
year = {2016}
}
@article{Feige2011a,
archivePrefix = {arXiv},
arxivId = {arXiv:1302.5877},
author = {Feige, Uriel and Mirrokni, Vahab S. and Vondr{\'{a}}k, Jan},
doi = {10.1137/090750688},
eprint = {arXiv:1302.5877},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feige, Mirrokni, Vondr{\'{a}}k - 2011 - Maximizing Non-Monotone Submodular Functions.pdf:pdf},
isbn = {0001405101},
issn = {01386557},
journal = {SIAM Journal on Computing},
number = {4},
pages = {1133--1153},
title = {{Maximizing Non-Monotone Submodular Functions}},
volume = {40},
year = {2011}
}
@inproceedings{Kuhnle2019g,
abstract = {While short read aligners, which predominantly use the FM-index, are able to easily index one or a few human genomes, they do not scale well to indexing databases containing thousands of genomes. To understand why, it helps to examine the main components of the FM-index in more detail, which is a rank data structure over the Burrows-Wheeler Transform (BWT) of the string that will allow us to find the interval in the string's suffix array (SA) containing pointers to starting positions of occurrences of a given pattern; second, a sample of the SA that \---| when used with the rank data structure \---| allows us access the SA. The rank data structure can be kept small even for large genomic databases, by run-length compressing the BWT, but until recently there was no means known to keep the SA sample small without greatly slowing down access to the SA. Now that Gagie et al. (SODA 2018) have defined an SA sample that takes about the same space as the run-length compressed BWT \---| we have the design for efficient FM-indexes of genomic databases but are faced with the problem of building them. In 2018 we showed how to build the BWT of large genomic databases efficiently (WABI 2018) but the problem of building Gagie et al.'s SA sample efficiently was left open. We compare our approach to state-of-the-art methods for constructing the SA sample, and demonstrate that it is the fastest and most space-efficient method on highly repetitive genomic databases. Lastly, we apply our method for indexing partial and whole human genomes, and show that it improves over Bowtie with respect to both memory and time.},
archivePrefix = {arXiv},
arxivId = {1811.06933},
author = {Kuhnle, Alan and Mun, Taher and Boucher, Christina and Gagie, Travis and Langmead, Ben and Manzini, Giovanni},
booktitle = {RECOMB},
doi = {10.1101/472423},
eprint = {1811.06933},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhnle et al. - 2019 - Efficient Construction of a Complete Index for Pan-Genomics Read Alignment.pdf:pdf},
title = {{Efficient Construction of a Complete Index for Pan-Genomics Read Alignment}},
url = {https://www.biorxiv.org/content/early/2018/11/19/472423},
year = {2019}
}
@article{Calinescu2011,
archivePrefix = {arXiv},
arxivId = {arXiv:0904.1950},
author = {Calinescu, Gruia and Chekuri, Chandra and Pal, Martin and Vondr{\'{a}}k, Jan},
doi = {10.1137/090745854},
eprint = {arXiv:0904.1950},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Calinescu et al. - 2011 - Maximizing a Monotone Submodular Function Subject to a Matroid Constraint.pdf:pdf},
isbn = {2011009212002},
issn = {0022-3999},
journal = {SIAM Journal on Computing},
keywords = {040617431,05c50,05c65,1,10,1137,65f10,65f35,65f50,65y05,ams subject classifications,doi,introduction,iterative method,matrix partitioning,of the preconditioned itera-,parallel computing,preconditioning,we consider the parallelization},
number = {6},
title = {{Maximizing a Monotone Submodular Function Subject to a Matroid Constraint}},
volume = {40},
year = {2011}
}
@article{Nemhauser1978a,
abstract = {A real-valued function z whose domain is all of the subsets of N = {1,..., n} is said to be submodular if <tex-math>$z(S)+z(T)\geq z(S\cup T)+z(S\cap T),\forall S,T\subseteq N$</tex-math>, and nondecreasing if <tex-math>$z(S)\leq z(T),\forall S\subset T\subseteq N$</tex-math>. We consider the problem <tex-math>${\rm max}_{S\subset N}\ \{z(S)\colon |S|\geq K$</tex-math>, z submodular and nondecreasing, z($\phi$) = 0}. Many combinatorial optimization problems can be posed in this framework. For example, a well-known location problem and the maximization of certain boolean polynomials are in this class. We present a family of algorithms that involve the partial enumeration of all sets of cardinality q and then a greedy selection of the remaining elements, q = 0,..., K - l. For fixed K, the qth member of this family requires <tex-math>$O(n^{q+1})$</tex-math> computations and is guaranteed to achieve at least <tex-math>$[1-(\frac{K-q}{K})(\frac{K-q-1}{K-q})^{K-q}]\times 100$</tex-math> percent of the optimum value. Our main result is that this is the best performance guarantee that can be obtained by any algorithm whose number of computations does not exceed <tex-math>$O(n^{q+1})$</tex-math>.},
author = {Nemhauser, G L and Wolsey, L A},
doi = {10.1287/moor.3.3.177},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nemhauser, Wolsey - 1978 - Best Algorithms for Approximating the Maximum of a Submodular Set Function.pdf:pdf},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
number = {3},
pages = {177--188},
title = {{Best Algorithms for Approximating the Maximum of a Submodular Set Function}},
url = {http://www.jstor.org/stable/3689488%5Cnhttp://about.jstor.org/terms},
volume = {3},
year = {1978}
}
@inproceedings{Gharan2011,
abstract = {We consider the problem of maximizing a nonnegative (possibly non-monotone) submodular set function with or without constraints. Feige et al. [FOCS'07] showed a 2/5-approximation for the unconstrained problem and also proved that no approximation better than 1/2 is possible in the value oracle model. Constant-factor approximation was also given for submodular maximization subject to a matroid independence constraint (a factor of 0.309 Vondrak [FOCS'09]) and for submodular maximization subject to a matroid base constraint, provided that the fractional base packing number is at least 2 (a 1/4-approximation, Vondrak [FOCS'09]). In this paper, we propose a new algorithm for submodular maximization which is based on the idea of {\em simulated annealing}. We prove that this algorithm achieves improved approximation for two problems: a 0.41-approximation for unconstrained submodular maximization, and a 0.325-approximation for submodular maximization subject to a matroid independence constraint. On the hardness side, we show that in the value oracle model it is impossible to achieve a 0.478-approximation for submodular maximization subject to a matroid independence constraint, or a 0.394-approximation subject to a matroid base constraint in matroids with two disjoint bases. Even for the special case of cardinality constraint, we prove it is impossible to achieve a 0.491-approximation. (Previously it was conceivable that a 1/2-approximation exists for these problems.) It is still an open question whether a 1/2-approximation is possible for unconstrained submodular maximization.},
archivePrefix = {arXiv},
arxivId = {1007.1632},
author = {Gharan, Shayan Oveis and Vondr{\'{a}}k, Jan},
booktitle = {Symposium on Discrete Algorithms (SODA)},
doi = {10.1137/1.9781611973082.83},
eprint = {1007.1632},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gharan, Vondr{\'{a}}k - 2011 - Submodular Maximization by Simulated Annealing.pdf:pdf},
isbn = {9780898719932},
pages = {1098--1116},
title = {{Submodular Maximization by Simulated Annealing}},
url = {http://arxiv.org/abs/1007.1632},
year = {2011}
}
@article{Gupta2010a,
abstract = {Constrained submodular maximization problems have long been studied, with near-optimal results known under a variety of constraints when the submodular function is monotone. The case of non-monotone submodular maximization is less understood: the first approximation algorithms even for the unconstrainted setting were given by Feige et al. (FOCS '07). More recently, Lee et al. (STOC '09, APPROX '09) show how to approximately maximize non-monotone submodular functions when the constraints are given by the intersection of p matroid constraints; their algorithm is based on local-search procedures that consider p-swaps, and hence the running time may be n^Omega(p), implying their algorithm is polynomial-time only for constantly many matroids. In this paper, we give algorithms that work for p-independence systems (which generalize constraints given by the intersection of p matroids), where the running time is poly(n,p). Our algorithm essentially reduces the non-monotone maximization problem to multiple runs of the greedy algorithm previously used in the monotone case. Our idea of using existing algorithms for monotone functions to solve the non-monotone case also works for maximizing a submodular function with respect to a knapsack constraint: we get a simple greedy-based constant-factor approximation for this problem. With these simpler algorithms, we are able to adapt our approach to constrained non-monotone submodular maximization to the (online) secretary setting, where elements arrive one at a time in random order, and the algorithm must make irrevocable decisions about whether or not to select each element as it arrives. We give constant approximations in this secretary setting when the algorithm is constrained subject to a uniform matroid or a partition matroid, and give an O(log k) approximation when it is constrained by a general matroid of rank k.},
archivePrefix = {arXiv},
arxivId = {1003.1517},
author = {Gupta, Anupam and Roth, Aaron and Schoenebeck, Grant and Talwar, Kunal},
doi = {10.1007/978-3-642-17572-5_20},
eprint = {1003.1517},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta et al. - 2010 - Constrained non-monotone submodular maximization Offline and secretary algorithms(2).pdf:pdf},
isbn = {3642175716},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {246--257},
title = {{Constrained non-monotone submodular maximization: Offline and secretary algorithms}},
volume = {6484 LNCS},
year = {2010}
}
@incollection{Buchbinder2018a,
author = {Buchbinder, Niv and Feldman, Moran},
booktitle = {Handbook of Approximation Algorithms and Metaheuristics},
edition = {Second},
editor = {Gonzalez, Teofilo F.},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buchbinder, Feldman - 2018 - Submodular Functions Maximization Problems -- A Survey.pdf:pdf},
title = {{Submodular Functions Maximization Problems -- A Survey}},
year = {2018}
}
@article{Vosoughi2017,
author = {Vosoughi, Soroush and Mohsenvand, Mostafa N E O and Roy, D E B},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vosoughi, Mohsenvand, Roy - 2017 - Rumor Gauge Predicting the Veracity of Rumors on Twitter r r.pdf:pdf},
number = {4},
title = {{Rumor Gauge : Predicting the Veracity of Rumors on Twitter r r}},
volume = {11},
year = {2017}
}
@inproceedings{Mirzasoleiman2018,
abstract = {The need for real time analysis of rapidly producing data streams (e.g., video and image streams) motivated the design of streaming algorithms that can efficiently extract and summarize useful information from massive data "on the fly". Such problems can often be reduced to maximizing a submodular set function subject to various constraints. While efficient streaming methods have been recently developed for monotone submodular maximization, in a wide range of applications, such as video summarization, the underlying utility function is non-monotone, and there are often various constraints imposed on the optimization problem to consider privacy or personalization. We develop the first efficient single pass streaming algorithm, Streaming Local Search, that for any streaming monotone submodular maximization algorithm with approximation guarantee $\alpha$ under a collection of independence systems ${\cal I}$, provides a constant $1/\big(1+2/\sqrt{\alpha}+1/\alpha +2d(1+\sqrt{\alpha})\big)$ approximation guarantee for maximizing a non-monotone submodular function under the intersection of ${\cal I}$ and $d$ knapsack constraints. Our experiments show that for video summarization, our method runs more than 1700 times faster than previous work, while maintaining practically the same performance.},
archivePrefix = {arXiv},
arxivId = {1706.03583},
author = {Mirzasoleiman, Baharan and Jegelka, Stefanie and Krause, Andreas},
booktitle = {AAAI Conference on Artificial Intelligence},
eprint = {1706.03583},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mirzasoleiman, Jegelka, Krause - 2018 - Streaming Non-Monotone Submodular Maximization Personalized Video Summarization on the Fly.pdf:pdf},
keywords = {Heuristic Search and Optimization Track},
title = {{Streaming Non-Monotone Submodular Maximization: Personalized Video Summarization on the Fly}},
url = {http://arxiv.org/abs/1706.03583},
year = {2018}
}
@inproceedings{Gillenwater2012,
author = {Gillenwater, Jennifer and Kulesza, Alex and Taskar, Ben},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gillenwater, Kulesza, Taskar - 2012 - Near-Optimal MAP Inference for Determinantal Point Processes.pdf:pdf},
title = {{Near-Optimal MAP Inference for Determinantal Point Processes}},
year = {2012}
}
@inproceedings{Buchbinder2015a,
abstract = {Fast algorithms for submodular maximization problems have a vast potential use in applicative settings, such as machine learning, social networks, and economics. Though fast algorithms were known for some special cases, only recently Badanidiyuru and Vondr\'{a}k (2014) were the first to explicitly look for such algorithms in the general case of maximizing a monotone submodular function subject to a matroid independence constraint. The algorithm of Badanidiyuru and Vondr\'{a}k matches the best possible approximation guarantee, while trying to reduce the number of value oracle queries the algorithm performs. Our main result is a new algorithm for this general case which establishes a surprising tradeoff between two seemingly unrelated quantities: the number of value oracle queries and the number of matroid independence queries performed by the algorithm. Specifically, one can decrease the former by increasing the latter and vice versa, while maintaining the best possible approximation guarantee. Such a tradeoff is very useful since various applications might incur significantly different costs in querying the value and matroid independence oracles. Furthermore, in case the rank of the matroid is $O(n^c)$, where $n$ is the size of the ground set and $c$ is an absolute constant smaller than $1$, the total number of oracle queries our algorithm uses can be made to have a smaller magnitude compared to that needed by Badanidiyuru and Vondr\'{a}k. We also provide even faster algorithms for the well studied special cases of a cardinality constraint and a partition matroid independence constraint, both of which capture many real-world applications and have been widely studied both theorically and in practice.},
archivePrefix = {arXiv},
arxivId = {1410.0773},
author = {Buchbinder, Niv and Feldman, Moran and Schwartz, Roy},
booktitle = {ACM-SIAM Symposium on Discrete Algorithms (SODA)},
doi = {10.1137/1.9781611973730.77},
eprint = {1410.0773},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buchbinder, Feldman, Schwartz - 2015 - Comparing Apples and Oranges Query Tradeoff in Submodular Maximization.pdf:pdf},
issn = {15265471},
title = {{Comparing Apples and Oranges: Query Tradeoff in Submodular Maximization}},
year = {2015}
}
@inproceedings{Singla2014,
abstract = {How should we present training examples to learners to teach them classification rules? This is a natural problem when training workers for crowdsourcing labeling tasks, and is also motivated by challenges in data-driven online education. We propose a natural stochastic model of the learners, modeling them as randomly switching among hypotheses based on observed feedback. We then develop STRICT, an efficient algorithm for selecting examples to teach to workers. Our solution greedily maximizes a submodular surrogate objective function in order to select examples to show to the learners. We prove that our strategy is competitive with the optimal teaching policy. Moreover, for the special case of linear separators, we prove that an exponential reduction in error probability can be achieved. Our experiments on simulated workers as well as three real image annotation tasks on Amazon Mechanical Turk show the effectiveness of our teaching algorithm.},
archivePrefix = {arXiv},
arxivId = {1402.2092},
author = {Singla, Adish and Bogunovic, Ilija and Bart{\'{o}}k, G{\'{a}}bor and Karbasi, Amin and Krause, Andreas},
booktitle = {ICML},
eprint = {1402.2092},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Singla et al. - 2014 - Near-Optimally Teaching the Crowd to Classify.pdf:pdf},
isbn = {9781634393973},
title = {{Near-Optimally Teaching the Crowd to Classify}},
url = {http://arxiv.org/abs/1402.2092},
year = {2014}
}
@inproceedings{Feldman2017,
abstract = {It is known that greedy methods perform well for maximizing monotone submodular functions. At the same time, such methods perform poorly in the face of non-monotonicity. In this paper, we show - arguably, surprisingly - that invoking the classical greedy algorithm $O(\sqrt{k})$-times leads to the (currently) fastest deterministic algorithm, called Repeated Greedy, for maximizing a general submodular function subject to $k$-independent system constraints. Repeated Greedy achieves $(1 + O(1/\sqrt{k}))k$ approximation using $O(nr\sqrt{k})$ function evaluations (here, $n$ and $r$ denote the size of the ground set and the maximum size of a feasible solution, respectively). We then show that by a careful sampling procedure, we can run the greedy algorithm only once and obtain the (currently) fastest randomized algorithm, called Sample Greedy, for maximizing a submodular function subject to $k$-extendible system constraints (a subclass of $k$-independent system constrains). Sample Greedy achieves $(k + 3)$-approximation with only $O(nr/k)$ function evaluations. Finally, we derive an almost matching lower bound, and show that no polynomial time algorithm can have an approximation ratio smaller than $ k + 1/2 - \varepsilon$. To further support our theoretical results, we compare the performance of Repeated Greedy and Sample Greedy with prior art in a concrete application (movie recommendation). We consistently observe that while Sample Greedy achieves practically the same utility as the best baseline, it performs at least two orders of magnitude faster.},
archivePrefix = {arXiv},
arxivId = {1704.01652},
author = {Feldman, Moran and Harshaw, Christopher and Karbasi, Amin},
booktitle = {Conference on Learning Theory (COLT)},
eprint = {1704.01652},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feldman, Harshaw, Karbasi - 2017 - Greed is Good Near-Optimal Submodular Maximization via Greedy Optimization.pdf:pdf},
keywords = {approximation al-,k -extendible systems,k -systems,submodular maximization},
title = {{Greed is Good: Near-Optimal Submodular Maximization via Greedy Optimization}},
url = {http://arxiv.org/abs/1704.01652},
year = {2017}
}
@inproceedings{Mirzasoleiman2016,
author = {Mirzasoleiman, Baharan and Badanidiyuru, Ashwinkumar and Karbasi, Amin},
booktitle = {International Conference on Machine Learning (ICML)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mirzasoleiman, Badanidiyuru, Karbasi - 2016 - Fast Constrained Submodular Maximization Personalized Data Summarization.pdf:pdf},
title = {{Fast Constrained Submodular Maximization : Personalized Data Summarization}},
year = {2016}
}
@inproceedings{Gupta2010,
abstract = {Constrained submodular maximization problems have long been studied, with near-optimal results known under a variety of constraints when the submodular function is monotone. The case of non-monotone submodular maximization is less understood: the first approximation algorithms even for the unconstrainted setting were given by Feige et al. (FOCS '07). More recently, Lee et al. (STOC '09, APPROX '09) show how to approximately maximize non-monotone submodular functions when the constraints are given by the intersection of p matroid constraints; their algorithm is based on local-search procedures that consider p-swaps, and hence the running time may be n^Omega(p), implying their algorithm is polynomial-time only for constantly many matroids. In this paper, we give algorithms that work for p-independence systems (which generalize constraints given by the intersection of p matroids), where the running time is poly(n,p). Our algorithm essentially reduces the non-monotone maximization problem to multiple runs of the greedy algorithm previously used in the monotone case. Our idea of using existing algorithms for monotone functions to solve the non-monotone case also works for maximizing a submodular function with respect to a knapsack constraint: we get a simple greedy-based constant-factor approximation for this problem. With these simpler algorithms, we are able to adapt our approach to constrained non-monotone submodular maximization to the (online) secretary setting, where elements arrive one at a time in random order, and the algorithm must make irrevocable decisions about whether or not to select each element as it arrives. We give constant approximations in this secretary setting when the algorithm is constrained subject to a uniform matroid or a partition matroid, and give an O(log k) approximation when it is constrained by a general matroid of rank k.},
archivePrefix = {arXiv},
arxivId = {1003.1517},
author = {Gupta, Anupam and Roth, Aaron and Schoenebeck, Grant and Talwar, Kunal},
booktitle = {WINE},
doi = {10.1007/978-3-642-17572-5_20},
eprint = {1003.1517},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta et al. - 2010 - Constrained non-monotone submodular maximization Offline and secretary algorithms.pdf:pdf},
isbn = {3642175716},
issn = {03029743},
pages = {246--257},
title = {{Constrained non-monotone submodular maximization: Offline and secretary algorithms}},
volume = {6484 LNCS},
year = {2010}
}
@inproceedings{Fahrbach2018,
abstract = {Submodular maximization is a general optimization problem with a wide range of applications in machine learning (e.g., active learning, clustering, and feature selection). In large-scale optimization, the parallel running time of an algorithm is governed by its adaptivity, which measures the number of sequential rounds needed if the algorithm can execute polynomially-many independent oracle queries in parallel. While low adaptivity is ideal, it is not sufficient for an algorithm to be efficient in practice—there are many applications of distributed submodular optimization where the number of function evaluations becomes prohibitively expensive. Motivated by these applications, we study the adaptivity and query complexity of submodular maximization. In this paper, we give the first constant-factor approximation algorithm for maximizing a nonmonotone submodular function subject to a cardinality constraint A; that runs in 0(log(n)) adaptive rounds and makes 0(n log(fc)) oracle queries in expectation. In our empirical study, we use three real-world applications to compare our algorithm with several benchmarks for non-monotone submodular maximization. The results demonstrate that our algorithm finds competitive solutions using significantly fewer rounds and queries.},
archivePrefix = {arXiv},
arxivId = {1808.06932},
author = {Fahrbach, Matthew and Mirrokni, Vahab and Zadimoghaddam, Morteza},
booktitle = {ACM-SIAM Symposium on Discrete Algorithms (SODA)},
eprint = {1808.06932},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fahrbach, Mirrokni, Zadimoghaddam - 2019 - Submodular Maximization with Nearly Optimal Approximation, Adaptivity, and Query Complexity.pdf:pdf},
isbn = {9781510886988},
pages = {255--273},
title = {{Submodular Maximization with Nearly Optimal Approximation, Adaptivity, and Query Complexity}},
year = {2019}
}
@article{Kuhnle2019b,
abstract = {{\textcopyright} 2018, Springer-Verlag London Ltd., part of Springer Nature. We study scalable approximation algorithms for the k-cycle transversal problem, which is to find a minimum-size set of edges that intersects all simple cycles of length k in a network. This problem is relevant to network reliability through the important metric of network clustering coefficient of order k. We formulate two algorithms to be both scalable and have good solution quality in practice: CARL and DARC. DARC is able to efficiently update its solution under dynamic node and edge insertion and removal to the network. In our experimental evaluation, we demonstrate that DARC is able to run on networks with billions of 3-cycles within 2 h and is able to dynamically update its solution in microseconds.},
author = {Kuhnle, A. and Crawford, V.G. and Thai, M.T.},
doi = {10.1007/s10115-018-1296-5},
issn = {02193116},
journal = {Knowledge and Information Systems},
keywords = {Cycle transversal,Dynamic networks,Scalable algorithms,Triangle interdiction},
number = {1},
title = {{Scalable approximations to k-cycle transversal problems on dynamic networks}},
volume = {61},
year = {2019}
}
@article{Lee2010a,
author = {Lee, Jon and Mirrokni, Vahab and Nagarajan, Viswanath and Sviridenko, Maxim},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2010 - Maximizing Nonmonotone Submodular Functions under Matroid or Knapsack Constraints.pdf:pdf},
isbn = {0001405101},
journal = {Siam Journal of Discrete Math},
keywords = {15a03,15a18,15a21,15a69,15a72,ams subject classifications,br,candecomp,decomposition,eckart,egman divergence of tensors,generic,hyperdeterminants,low-rank tensor approximations,maximal symmetric rank,multidimensional arrays,multiway arrays,numerical multilinear algebra,outer product decomposition,parafac,principal component analysis,quantics,symmetric outer product,symmetric rank,symmetric tensor rank,tensor decompositions,tensor rank,tensors,young theorem},
number = {4},
pages = {2053--2078},
title = {{Maximizing Nonmonotone Submodular Functions under Matroid or Knapsack Constraints}},
volume = {23},
year = {2010}
}
@article{Vondrak2008a,
author = {Vondr{\'{a}}k, Jan},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vondr{\'{a}}k - 2008 - Symmetry and Approximability of Submodular Maximization Problems.pdf:pdf},
keywords = {15a03,15a18,15a21,15a69,15a72,ams subject classifications,br,candecomp,decomposition,eckart,egman divergence of tensors,generic,hyperdeterminants,low-rank tensor approximations,maximal symmetric rank,multidimensional arrays,multiway arrays,numerical multilinear algebra,outer product decomposition,parafac,principal component analysis,quantics,symmetric outer product,symmetric rank,symmetric tensor rank,tensor decompositions,tensor rank,tensors,young theorem},
number = {3},
pages = {265--304},
title = {{Symmetry and Approximability of Submodular Maximization Problems}},
volume = {30},
year = {2008}
}
@article{Mitrovic2017,
abstract = {Many data summarization applications are captured by the general framework of submodular maximization. As a consequence, a wide range of efficient approximation algorithms have been developed. However, when such applications involve sensitive data about individuals, their privacy concerns are not automatically addressed. To remedy this problem, we propose a general and systematic study of differentially private submodular maximization. We present privacy-preserving algorithms for both monotone and non-monotone submodular maximization under cardinality, matroid, and p-extendible system constraints, with guarantees that are competitive with optimal. Along the way, we analyze a new algorithm for non-monotone submodular maximization, which is the first (even non-privately) to achieve a constant approximation ratio while running in linear time. We additionally provide two concrete experiments to validate the efficacy of these algorithms.},
author = {Mitrovic, Marko and Bun, Mark and Krause, Andreas and Karbasi, Amin},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitrovic et al. - 2017 - Differentially Private Submodular Maximization Data Summarization in Disguise.pdf:pdf},
isbn = {9781510855144},
issn = {1938-7228},
journal = {Proceedings of the 34th International Conference on Machine Learning (ICML)},
pages = {2478--2487},
title = {{Differentially Private Submodular Maximization: Data Summarization in Disguise}},
url = {http://proceedings.mlr.press/v70/mitrovic17a.html},
volume = {70},
year = {2017}
}
@article{Cui2018,
abstract = {We propose a population-based Evolutionary Stochastic Gradient Descent (ESGD) framework for optimizing deep neural networks. ESGD combines SGD and gradient-free evolutionary algorithms as complementary algorithms in one framework in which the optimization alternates between the SGD step and evolution step to improve the average fitness of the population. With a back-off strategy in the SGD step and an elitist strategy in the evolution step, it guarantees that the best fitness in the population will never degrade. In addition, individuals in the population optimized with various SGD-based optimizers using distinct hyper-parameters in the SGD step are considered as competing species in a coevolution setting such that the complementarity of the optimizers is also taken into account. The effectiveness of ESGD is demonstrated across multiple applications including speech recognition, image recognition and language modeling, using networks with a variety of deep architectures.},
archivePrefix = {arXiv},
arxivId = {1810.06773},
author = {Cui, Xiaodong and Zhang, Wei and T{\"{u}}ske, Zolt{\'{a}}n and Picheny, Michael},
eprint = {1810.06773},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cui et al. - 2018 - Evolutionary Stochastic Gradient Descent for Optimization of Deep Neural Networks.pdf:pdf},
isbn = {1810.06773v1},
number = {Nips},
title = {{Evolutionary Stochastic Gradient Descent for Optimization of Deep Neural Networks}},
url = {http://arxiv.org/abs/1810.06773},
year = {2018}
}
@article{Sze2017,
abstract = {While the continued development of high-throughput sequencing has facilitated studies of entire transcriptomes in non-model organisms, the incorporation of an increasing amount of RNA-Seq libraries has made de novo transcriptome assembly difficult. Although algorithms that can assemble a large amount of RNA-Seq data are available, they are generally very memory-intensive and can only be used to construct small assemblies. We develop a divide-and-conquer strategy that allows these algorithms to be utilized, by subdividing a large RNA-Seq data set into small libraries. Each individual library is assembled independently by an existing algorithm, and a merging algorithm is developed to combine these assemblies by picking a subset of high quality transcripts to form a large transcriptome. When compared to existing algorithms that return a single assembly directly, this strategy achieves comparable or increased accuracy as memory-efficient algorithms that can be used to process a large amount of RNA-Seq data, and comparable or decreased accuracy as memory-intensive algorithms that can only be used to construct small assemblies. Our divide-and-conquer strategy allows memory-intensive de novo transcriptome assembly algorithms to be utilized to construct large assemblies.},
author = {Sze, Sing Hoi and Parrott, Jonathan J. and Tarone, Aaron M.},
doi = {10.1186/s12864-017-4270-9},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sze, Parrott, Tarone - 2017 - A divide-and-conquer algorithm for large-scale de novo transcriptome assembly through combining small asse.pdf:pdf},
isbn = {9781509041992},
issn = {14712164},
journal = {BMC genomics},
keywords = {Divide-and-conquer,RNA-Seq,de novo transcriptome assembly},
number = {Suppl 10},
pages = {895},
title = {{A divide-and-conquer algorithm for large-scale de novo transcriptome assembly through combining small assemblies from existing algorithms}},
volume = {18},
year = {2017}
}
@techreport{,
abstract = {The problem of selecting a group of vertices under certain constraints that maximize their joint centrality arises in many practical scenarios. In this paper, we extend the notion of current flow close-ness centrality (CFCC) to a set of vertices in a graph, and investigate the problem of selecting a subset S to maximizes its CFCC C(S), with the cardinality constraint |S | = k. We show the NP-hardness of the problem, but propose two greedy algorithms to minimize the reciprocal of C(S). We prove the approximation ratios by showing the monotonicity and supermodularity. A proposed deterministic greedy algorithm has an approximation factor (1 − k k−1 {\textperiodcentered} 1 e) and cubic running time. To compare with, a proposed randomized algorithm gives (1 − k k −1 {\textperiodcentered} 1 e − ϵ)-approximation in nearly-linear time, for any ϵ > 0. Extensive experiments on model and real networks demonstrate the effectiveness and efficiency of the proposed algorithms , with the randomized algorithm being applied to massive networks with more than a million vertices.},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2019 - Maximizing Current Flow Closeness under Cardinality Constraints.pdf:pdf},
keywords = {CCS CONCEPTS • Theory of computation → Graph algorithms analysis,Dis-crete optimization,KEYWORDS Social Network, Centrality, Combinatorial Optimization, Algorith-mic Spectral Graph Theory,• Information systems → Data mining},
title = {{Maximizing Current Flow Closeness under Cardinality Constraints}},
url = {https://doi.org/10.475/123_4},
year = {2019}
}
@article{Saramaki2005,
abstract = {The local structure of unweighted complex networks can be characterized by the occurrence frequencies of subgraphs in the network. Frequently occurring subgraphs, motifs, have been related to the functionality of many natural and man-made networks. Here, we generalize this approach for weighted networks, presenting two novel measures: the intensity of a subgraph, defined as the geometric mean of its link weights, and the coherence, depicting the homogeneity of the weights. The concept of motif scores is then generalized to weighted networks using these measures. We also present a definition for the weighted clustering coefficient, which emerges naturally from the proposed framework. Finally, we demonstrate the concepts by applying them to financial and metabolic networks.},
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0408629v3},
author = {Saram{\"{a}}ki, Jari and Onnela, Jukka Pekka and Kert{\'{e}}sz, Janos and Kaski, Kimmo},
doi = {10.1063/1.1985382},
eprint = {0408629v3},
isbn = {0735402620},
issn = {0094243X},
journal = {AIP Conference Proceedings},
keywords = {Clustering coefficient,Motifs,Weighted complex networks},
pages = {108--117},
pmid = {1000172881},
primaryClass = {arXiv:cond-mat},
title = {{Characterizing motifs in weighted complex networks}},
volume = {776},
year = {2005}
}
@techreport{Author2019,
abstract = {In this work, the maximization of influence in a social network under partial incentives is considered. We provide the first approximation algorithm for this problem that takes into account error due to sampling; this error is bounded by the algorithm as a loss factor in the approximation ratio from sampling error. As building blocks, an extension of reverse influence sampling to partial influence and a novel polynomial-time algorithm for maximizing a weakly submodular, non-negative, and monotonic function on the integer lattice under an approximate oracle are used. The influence algorithm is validated by an experimental evaluation in which our algorithm is demonstrated to scale to large networks and outperforms all previous heuristics for this problem.},
author = {Author, Anonymous},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Author - 2019 - Influence Maximization under Partial Incentives Approximately Weakly Submodular Functions on the Integer Lattice.pdf:pdf},
keywords = {Approx-imation algorithms,CCS CONCEPTS • Mathematics of computing → Graph al,KEYWORDS Influence Maximization, Approximation alg,• Information systems → Social adver-tising,• Networks → Network economics},
title = {{Influence Maximization under Partial Incentives: Approximately Weakly Submodular Functions on the Integer Lattice}},
url = {https://doi.org/10.475/123_4},
year = {2019}
}
@techreport{,
abstract = {Predicting the popularity of online topics in online social networks (OSNs) is essential for many applications. Although many researches have been done, the evolving feature of information diffusion hasn't been well treated, including the promising direction of group-level popularity prediction. To this end, we identify the Incremental Group-level Popularity Prediction (IGPP) problem, and propose a novel model IGP-P to address it. We first conduct preprocess on the target topic being predicted, so as to build the initial group-level popularity tensor. Then, we predict the group-level popularity incrementally by exploiting the incremental CP decomposition algorithm. To reduce the cumulative error by incremental prediction, we propose two strategies to restart the CP decomposition. Finally, we conduct extensive experiments in two real datasets. The results show significant improvements of the IGPP method over other works both in the prediction accuracy and the efficiency. CCS CONCEPTS • Networks → Social media networks; Online social networks; • Human-centered computing → Social network analysis;},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2018 - Incremental Group-level Popularity Prediction in Online Social Networks.pdf:pdf},
title = {{Incremental Group-level Popularity Prediction in Online Social Networks}},
url = {https://doi.org/10.475/123},
year = {2018}
}
@techreport{,
abstract = {Predicting the popularity of online topics in online social networks (OSNs) is essential for many applications. Although many researches have been done, the evolving feature of information diffusion hasn't been well treated, including the promising direction of group-level popularity prediction. To this end, we identify the Incremental Group-level Popularity Prediction (IGPP) problem, and propose a novel model IGP-P to address it. We first conduct preprocess on the target topic being predicted, so as to build the initial group-level popularity tensor. Then, we predict the group-level popularity incrementally by exploiting the incremental CP decomposition algorithm. To reduce the cumulative error by incremental prediction, we propose two strategies to restart the CP decomposition. Finally, we conduct extensive experiments in two real datasets. The results show significant improvements of the IGPP method over other works both in the prediction accuracy and the efficiency. CCS CONCEPTS • Networks → Social media networks; Online social networks; • Human-centered computing → Social network analysis;},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2018 - Incremental Group-level Popularity Prediction in Online Social Networks.pdf:pdf},
title = {{Incremental Group-level Popularity Prediction in Online Social Networks}},
url = {https://doi.org/10.475/123},
year = {2018}
}
@article{Lakin2017,
abstract = {Antimicrobial resistance has become an imminent concern for public health. As methods for detection and characterization of antimicrobial resistance move from targeted culture and polymerase chain reaction to high throughput metagenomics, appropriate resources for the analysis of large-scale data are required. Currently, antimicrobial resistance databases are tailored to smaller-scale, functional profiling of genes using highly descriptive annotations. Such characteristics do not facilitate the analysis of large-scale, ecological sequence datasets such as those produced with the use of metagenomics for surveillance. In order to overcome these limitations, we present MEGARes (https://megares.meglab.org), a hand-curated antimicrobial resistance database and annotation structure that provides a foundation for the development of high throughput acyclical classifiers and hierarchical statistical analysis of big data. MEGARes can be browsed as a stand-alone resource through the website or can be easily integrated into sequence analysis pipelines through download. Also via the website, we provide documentation for AmrPlusPlus, a user-friendly Galaxy pipeline for the analysis of high throughput sequencing data that is pre-packaged for use with the MEGARes database.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Lakin, Steven M. and Dean, Chris and Noyes, Noelle R. and Dettenwanger, Adam and Ross, Anne Spencer and Doster, Enrique and Rovira, Pablo and Abdo, Zaid and Jones, Kenneth L. and Ruiz, Jaime and Belk, Keith E. and Morley, Paul S. and Boucher, Christina},
doi = {10.1093/nar/gkw1009},
eprint = {arXiv:1011.1669v3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lakin et al. - 2017 - MEGARes An antimicrobial resistance database for high throughput sequencing.pdf:pdf},
isbn = {0305-1048},
issn = {13624962},
journal = {Nucleic Acids Research},
number = {D1},
pages = {D574--D580},
pmid = {27899569},
title = {{MEGARes: An antimicrobial resistance database for high throughput sequencing}},
volume = {45},
year = {2017}
}
@article{Zhou2018,
archivePrefix = {arXiv},
arxivId = {1807.07531},
author = {Zhou, Song and Swati, Gupta and Madeleine, Udell},
eprint = {1807.07531},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou, Swati, Madeleine - 2018 - Limited memory Kelley ' s Method Converges for Composite Convex and Submodular Objectives.pdf:pdf},
journal = {arXiv preprint},
keywords = {90c25,90c27,90c30,ams subject classifications,asz extension,fully corrective frank-wolfe,kelley,limited,lov,memory simplicial method,s cutting plane method,submodular functions},
pages = {1--11},
title = {{Limited memory Kelley ' s Method Converges for Composite Convex and Submodular Objectives}},
year = {2018}
}
@techreport{,
abstract = {TODO},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Pareto Optimization with Bins for Submodular Cover and Submodular Maximization with Weighted Costs.pdf:pdf},
title = {{Pareto Optimization with Bins for Submodular Cover and Submodular Maximization with Weighted Costs}}
}
@article{Bilmes2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1311.2106v1},
author = {Bilmes, Jeff},
eprint = {arXiv:1311.2106v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bilmes - 2013 - Submodular Optimization with Submodular Cover and Submodular Knapsack Constraints.pdf:pdf},
pages = {1--23},
title = {{Submodular Optimization with Submodular Cover and Submodular Knapsack Constraints}},
volume = {2},
year = {2013}
}
@inproceedings{Ene2016a,
author = {Ene, Alina and Nguyen, Huy L.},
booktitle = {Symposium on Foundations of Computer Science (FOCS)},
doi = {10.1109/FOCS.2016.34},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ene, Nguyen - 2016 - Constrained Submodular Maximization Beyond 1e.pdf:pdf},
keywords = {-submodular functions,maximization},
title = {{Constrained Submodular Maximization: Beyond 1/e}},
year = {2016}
}
@article{Svitkina2010,
archivePrefix = {arXiv},
arxivId = {arXiv:0805.1071v3},
author = {Svitkina, Zoya and Fleischer, Lisa},
eprint = {arXiv:0805.1071v3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Svitkina, Fleischer - 2010 - Submodular Approximation Sampling-based Algorithms and.pdf:pdf},
title = {{Submodular Approximation : Sampling-based Algorithms and}},
year = {2010}
}
@article{Mitzenmacher,
author = {Mitzenmacher, Michael and Richa, Andrea W},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitzenmacher, Richa - Unknown - The Power of Two Random Choices A Survey of Techniques and Results 1 Introduction.pdf:pdf},
number = {1},
pages = {1--60},
title = {{The Power of Two Random Choices : A Survey of Techniques and Results 1 Introduction}},
volume = {1}
}
@article{Buchbinder2018,
author = {Buchbinder, Niv and Feldman, Moran},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buchbinder, Feldman - 2018 - Deterministic Algorithms for Submodular Maximization.pdf:pdf},
journal = {ACM Transactions on Algorithms},
number = {3},
title = {{Deterministic Algorithms for Submodular Maximization}},
volume = {14},
year = {2018}
}
@inproceedings{Balkanskia,
archivePrefix = {arXiv},
arxivId = {arXiv:1807.11462v1},
author = {Balkanski, Eric and Breuer, Adam and Singer, Yaron},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
eprint = {arXiv:1807.11462v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balkanski, Breuer, Singer - 2018 - Non-monotone Submodular Maximization in Exponentially Fewer Iterations.pdf:pdf},
title = {{Non-monotone Submodular Maximization in Exponentially Fewer Iterations}},
year = {2018}
}
@article{Chena,
archivePrefix = {arXiv},
arxivId = {arXiv:1808.09363v3},
author = {Chen, Wei},
eprint = {arXiv:1808.09363v3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen - Unknown - An Issue in the Martingale Analysis of the Influence Maximization Algorithm IMM.pdf:pdf},
pages = {1--12},
title = {{An Issue in the Martingale Analysis of the Influence Maximization Algorithm IMM}}
}
@inproceedings{Buchbinder,
author = {Buchbinder, Niv and Feldman, Moran and Naor, Joseph Seffi and Schwartz, Roy},
booktitle = {Symposium on Discrete Algorithms (SODA)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buchbinder et al. - 2014 - Submodular Maximization with Cardinality Constraints(2).pdf:pdf},
publisher = {ACM},
title = {{Submodular Maximization with Cardinality Constraints}},
year = {2014}
}
@inproceedings{Naor2012,
author = {Buchbinder, Niv and Feldman, Moran and Naor, Joseph Seffi and Schwartz, Roy},
booktitle = {Symposium on Foundations of Computer Science (FOCS)},
doi = {10.1109/FOCS.2012.73},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buchbinder et al. - 2012 - A Tight Linear Time (1 2)-Approximation for Unconstrained Submodular Maximization.pdf:pdf},
keywords = {-submodular},
title = {{A Tight Linear Time (1 / 2)-Approximation for Unconstrained Submodular Maximization}},
year = {2012}
}
@inproceedings{He2016,
abstract = {We study the problem of learning influence functions under incomplete observations of node activations. Incomplete observations are a major concern as most (online and real-world) social networks are not fully observable. We establish both proper and improper PAC learnability of influence functions under randomly missing observations. Proper PAC learnability under the Discrete-Time Linear Threshold (DLT) and Discrete-Time Independent Cascade (DIC) models is established by reducing incomplete observations to complete observations in a modified graph. Our improper PAC learnability result applies for the DLT and DIC models as well as the Continuous-Time Independent Cascade (CIC) model. It is based on a parametrization in terms of reachability features, and also gives rise to an efficient and practical heuristic. Experiments on synthetic and real-world datasets demonstrate the ability of our method to compensate even for a fairly large fraction of missing observations.},
archivePrefix = {arXiv},
arxivId = {1611.02305},
author = {He, Xinran and Xu, Ke and Kempe, David and Liu, Yan},
booktitle = {NIPS},
eprint = {1611.02305},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - 2016 - Learning Influence Functions from Incomplete Observations.pdf:pdf},
issn = {10495258},
title = {{Learning Influence Functions from Incomplete Observations}},
url = {http://arxiv.org/abs/1611.02305},
year = {2016}
}
@article{Makinen2010,
abstract = {A repetitive sequence collection is a set of sequences which are small variations of each other. A prominent example are genome sequences of individuals of the same or close species, where the differences can be expressed by short lists of basic edit operations. Flexible and efficient data analysis on such a typically huge collection is plausible using suffix trees. However, the suffix tree occupies much space, which very soon inhibits in-memory analyses. Recent advances in full-text indexing reduce the space of the suffix tree to, essentially, that of the compressed sequences, while retaining its functionality with only a polylogarithmic slowdown. However, the underlying compression model considers only the predictability of the next sequence symbol given the k previous ones, where k is a small integer. This is unable to capture longer-term repetitiveness. For example, r identical copies of an incompressible sequence will be incompressible under this model. We develop new static and dynamic full-text indexes that are able of capturing the fact that a collection is highly repetitive, and require space basically proportional to the length of one typical sequence plus the total number of edit operations. The new indexes can be plugged into a recent dynamic fully-compressed suffix tree, achieving full functionality for sequence analysis, while retaining the reduced space and the polylogarithmic slowdown. Our experimental results confirm the practicality of our proposal.},
author = {M{\"{a}}kinen, Veli and Navarro, Gonzalo and Sir{\'{e}}n, Jouni and V{\"{a}}lim{\"{a}}ki, Niko},
doi = {10.1089/cmb.2009.0169},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\"{a}}kinen et al. - 2010 - Storage and retrieval of highly repetitive sequence collections.pdf:pdf},
isbn = {1557-8666 (Electronic)\n1066-5277 (Linking)},
issn = {1557-8666},
journal = {Journal of Computational Biology},
keywords = {Base Sequence,Computational Biology,Computational Biology: methods,Humans,Information Storage and Retrieval,Mutation,Mutation: genetics,Nucleic Acid,Nucleic Acid: genetics,Repetitive Sequences,Time Factors},
number = {3},
pages = {281--308},
pmid = {20377446},
title = {{Storage and retrieval of highly repetitive sequence collections.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20377446},
volume = {17},
year = {2010}
}
@article{Schneeberger2009,
abstract = {Genome resequencing with short reads generally relies on alignments against a single reference. GenomeMapper supports simultaneous mapping of short reads against multiple genomes by integrating related genomes (e.g., individuals of the same species) into a single graph structure. It constitutes the first approach for handling multiple references and introduces representations for alignments against complex structures. Demonstrated benefits include access to polymorphisms that cannot be identified by alignments against the reference alone. Download GenomeMapper at http://1001genomes.org.},
author = {Schneeberger, Korbinian and Hagmann, J{\"{o}}rg and Ossowski, Stephan and Warthmann, Norman and Gesing, Sandra and Kohlbacher, Oliver and Weigel, Detlef},
doi = {10.1186/gb-2009-10-9-r98},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schneeberger et al. - 2009 - Simultaneous alignment of short reads against multiple genomes.pdf:pdf},
isbn = {1465-6906},
issn = {14747596},
journal = {Genome Biology},
number = {9},
pmid = {19761611},
title = {{Simultaneous alignment of short reads against multiple genomes}},
volume = {10},
year = {2009}
}
@inproceedings{Maciuca2016,
abstract = {We show how positional markers can be used to encode genetic variation within a Burrows-Wheeler Transform (BWT), and use this to construct a generalisation of the traditional ``reference genome'', incorporating known variation within a species. Our goal is to support the inference of the closest mosaic of previously known sequences to the genome(s) under analysis. Our scheme results in an increased alphabet size, and by using a wavelet tree encoding of the BWT we reduce the performance impact on rank operations. We give a specialised form of the backward search that allows variation-aware exact matching. We implement this, and demonstrate the cost of constructing an index of the whole human genome with 8 million genetic variants is 25 GB of RAM. We also show that inferring a closer reference can close large kilobase-scale coverage gaps in P. falciparum.},
address = {Cham},
author = {Maciuca, Sorina and {del Ojo Elias}, Carlos and McVean, Gil and Iqbal, Zamin},
booktitle = {Workshop on Algorithms in Bioinformatics},
editor = {Frith, Martin and {Storm Pedersen}, Christian N{\o}rgaard},
isbn = {978-3-319-43681-4},
pages = {222--233},
publisher = {Springer International Publishing},
title = {{A Natural Encoding of Genetic Variation in a Burrows-Wheeler Transform to Enable Mapping and Genome Inference}},
year = {2016}
}
@article{Huang2013a,
abstract = {Women's participation in slut shaming is often viewed as internalized oppression: they apply disadvantageous sexual double standards established by men. This perspective grants women little agency and neglects their simultaneous location in other social structures. In this article we synthesize insights from social psychology, gender, and culture to argue that undergrad- uate women use slut stigma to draw boundaries around status groups linked to social class—while also regulating sexual behavior and gender performance. High-status women employ slut discourse to assert class advantage, defining themselves as classy rather than tra- shy, while low-status women express class resentment—deriding rich, bitchy sluts for their exclusivity. Slut discourse enables, rather than constrains, sexual experimentation for the high-status women whose definitions prevail in the dominant social scene. This is a form of sexual privilege. In contrast, low-status women risk public shaming when they attempt to enter dominant social worlds.},
author = {Huang, Lin and Popic, Victoria and Batzoglou, Serafim},
doi = {10.1093/bioinformatics/btt215},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Popic, Batzoglou - 2013 - Short read alignment with populations of genomes.pdf:pdf},
isbn = {1367-4811 (Electronic)\r1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
number = {13},
pmid = {23813006},
title = {{Short read alignment with populations of genomes}},
volume = {29},
year = {2013}
}
@article{Balcan2012,
abstract = {Episodes of mass psychogenic illness are challenging under the best of circumstances. Typically incubated in an atmosphere of fear and uncertainty, the initial diagnoses are often contentious, an...},
archivePrefix = {arXiv},
arxivId = {1008.2159},
author = {Balcan, Maria Florina and Harvey, Nicholas J.A.},
doi = {10.1007/978-3-642-33486-3_61},
eprint = {1008.2159},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balcan, Harvey - 2012 - Learning submodular functions.pdf:pdf},
isbn = {9783642334856},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 2},
pages = {846--849},
pmid = {22790560},
title = {{Learning submodular functions}},
volume = {7524 LNAI},
year = {2012}
}
@article{Gagie2009,
author = {Gagie, Travis and Navarro, Gonzalo},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gagie, Navarro - 2009 - Compressed Indexes for Repetitive Textual Datasets.pdf:pdf},
title = {{Compressed Indexes for Repetitive Textual Datasets}},
year = {2009}
}
@article{Wandelt2013,
author = {Wandelt, Sebastian and Starlinger, Johannes and Bux, Marc and Leser, Ulf},
doi = {10.14778/2536258.2536265},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wandelt et al. - 2013 - RCSI Scalable similarity search in thousand(s) of genomes.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
number = {13},
pages = {1534--1545},
title = {{RCSI: Scalable similarity search in thousand(s) of genomes}},
url = {http://dl.acm.org/citation.cfm?doid=2536258.2536265},
volume = {6},
year = {2013}
}
@article{Ferrada2018,
abstract = {Hybrid indexing is a recent approach to text indexing that allows the space-usage of conventional text indexes (e.g., suffix trees, suffix arrays, FM-indexes) to scale well with the text size, n, when z, the size of the Lempel-Ziv parsing of the text, is small relative to n. The price for this improved scalability is that an upper bound M on the pattern length that can be searched for must be declared at index construction time. Because the size of the resulting index contains an O(M z) term, M must be kept reasonably small, though it has been shown that M ≈ 100 leads to acceptable performance in some genomic applications. However, despite its promise, the practical performance of hybrid indexing relative to other compressed index data structures is poorly understood. This paper addresses that need, detailing experiments that show hybrid indexing — when carefully implemented — to be significantly smaller and faster than alternative approaches on a broad range of data of different levels of compressibility. We also describe practical extensions to hybrid indexing that obviate the restriction on M , supporting search for patterns of arbitrary length.},
author = {Ferrada, H{\'{e}}ctor and Kempa, Dominik and Puglisi, Simon J.},
doi = {10.1137/1.9781611975055.1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferrada, Kempa, Puglisi - 2018 - Hybrid Indexing Revisited.pdf:pdf},
isbn = {9781611975055},
issn = {21640300},
journal = {ALENEX 2018},
pages = {1--8},
title = {{Hybrid Indexing Revisited}},
url = {http://epubs.siam.org/doi/10.1137/1.9781611975055.1},
year = {2018}
}
@inproceedings{Du2014,
abstract = {Abstract: Can we learn the influence of a set of people in a social network from cascades of information diffusion ? This question is often addressed by a two-stage approach: first learn a diffusion model, and then calculate the influence based on the learned model. Thus, the ...},
author = {Du, Nan and Liang, Yingyu and Balcan, Maria and Song, Le},
booktitle = {ICML},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Du et al. - 2014 - Influence function learning in information diffusion networks. In International Conference on Machine Learning.pdf:pdf},
isbn = {9781634393973},
pages = {2016--2024},
title = {{Influence function learning in information diffusion networks. In International Conference on Machine Learning}},
url = {http://machinelearning.wustl.edu/mlpapers/papers/icml2014c2_du14},
year = {2014}
}
@article{Narasimhan2015,
abstract = {We establish PAC learnability of influence functions for three common influence models, namely, the Linear Threshold (LT), Independent Cascade (IC) and Voter models, and present concrete sample complexity results in each case. Our results for the LT model are based on interesting connections with neural networks; those for the IC model are based an interpretation of the influence function as an expectation over random draw of a subgraph and use covering number arguments; and those for the Voter model are based on a reduction to linear regression. We show these results for the case in which the cascades are only partially observed and we do not see the time steps in which a node has been influenced. We also provide efficient polynomial time learning algorithms for a setting with full observation, i.e. where the cascades also contain the time steps in which nodes are influenced.},
author = {Narasimhan, Harikrishna and Parkes, David C. and Singer, Yaron},
doi = {10.1016/B978-0-08-097086-8.43111-9},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Narasimhan, Parkes, Singer - 2015 - Learnability of Influence in Networks.pdf:pdf},
isbn = {9780080970868},
issn = {10495258},
journal = {Proceedings of the 29th Annual Conference on Neural Information Processing Systems (NIPS 2015)},
pages = {3168--3176},
title = {{Learnability of Influence in Networks}},
url = {http://econcs.seas.harvard.edu/files/econcs/files/narasimhan_nips15.pdf},
year = {2015}
}
@misc{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - SDBBootCampletters of recommend.pdf.pdf:pdf},
title = {{SDBBootCampletters of recommend.pdf}}
}
@article{Valenzuela2017,
author = {Valenzuela, Daniel and Veli, M},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Valenzuela, Veli - 2017 - CHIC a short read aligner for pan-genomic references.pdf:pdf},
journal = {bioRxiv},
title = {{CHIC: a short read aligner for pan-genomic references}},
year = {2017}
}
@article{Valenzuela2018,
abstract = {Background: Typical human genome differs from the reference genome at 4-5 million sites. This diversity is increasingly catalogued in repositories such as ExAC/gnomAD, consisting of >15,000 whole-genomes and >126,000 exome sequences from different individuals. Despite this enormous diversity, resequencing data workflows are still based on a single human reference genome. Identification and genotyping of genetic variants is typically carried out on short-read data aligned to a single reference, disregarding the underlying variation. Results: We propose a new unified framework for variant calling with short-read data utilizing a representation of human genetic variation-a pan-genomic reference. We provide a modular pipeline that can be seamlessly incorporated into existing sequencing data analysis workflows. Our tool is open source and available online: https://gitlab.com/dvalenzu/PanVC. Conclusions: Our experiments show that by replacing a standard human reference with a pan-genomic one we achieve an improvement in single-nucleotide variant calling accuracy and in short indel calling accuracy over the widely adopted Genome Analysis Toolkit (GATK) in difficult genomic regions.},
author = {Valenzuela, Daniel and Norri, Tuukka and V{\"{a}}lim{\"{a}}ki, Niko and Pitk{\"{a}}nen, Esa and M{\"{a}}kinen, Veli},
doi = {10.1186/s12864-018-4465-8},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Valenzuela et al. - 2018 - Towards pan-genome read alignment to improve variation calling.pdf:pdf},
isbn = {1286401844},
issn = {14712164},
journal = {BMC Genomics},
keywords = {Pan-genome reference,Read alignment,Variation calling},
number = {Suppl 2},
pmid = {29764365},
title = {{Towards pan-genome read alignment to improve variation calling}},
volume = {19},
year = {2018}
}
@article{Siren2014,
author = {Siren, Jouni and Valimaki, Niko and Makinen, Veli},
doi = {10.1109/TCBB.2013.2297101},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Siren, Valimaki, Makinen - 2014 - Indexing Graphs for Path Queries with Applications in Genome Research.pdf:pdf},
issn = {1545-5963},
journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
number = {2},
pages = {375--388},
title = {{Indexing Graphs for Path Queries with Applications in Genome Research}},
volume = {11},
year = {2014}
}
@inproceedings{Karkkainen2015,
author = {K{\"{a}}rkk{\"{a}}inen, J. and Kempa, D. and Puglisi, S. J.},
booktitle = {Combinatorial Pattern Matching (CPM)},
title = {{Parallel External Memory Suffix Sorting}},
year = {2015}
}
@article{Deorowicz2015,
abstract = {Motivation: Building the histogram of occurrences of every $k$-symbol long substring of nucleotide data is a standard step in many bioinformatics applications, known under the name of $k$-mer counting. Its applications include developing de Bruijn graph genome assemblers, fast multiple sequence alignment and repeat detection. The tremendous amounts of NGS data require fast algorithms for $k$-mer counting, preferably using moderate amounts of memory. Results: We present a novel method for $k$-mer counting, on large datasets at least twice faster than the strongest competitors (Jellyfish$\sim$2, KMC$\sim$1), using about 12\,GB (or less) of RAM memory. Our disk-based method bears some resemblance to MSPKmerCounter, yet replacing the original minimizers with signatures (a carefully selected subset of all minimizers) and using $(k, x)$-mers allows to significantly reduce the I/O, and a highly parallel overall architecture allows to achieve unprecedented processing speeds. For example, KMC$\sim$2 allows to count the 28-mers of a human reads collection with 44-fold coverage (106\,GB of compressed size) in about 20 minutes, on a 6-core Intel i7 PC with an SSD. Availability: KMC$\sim$2 is freely available at http://sun.aei.polsl.pl/kmc. Contact: sebastian.deorowicz@polsl.pl},
archivePrefix = {arXiv},
arxivId = {1407.1507},
author = {Deorowicz, Sebastian and Kokot, Marek and Grabowski, Szymon and Debudaj-Grabysz, Agnieszka},
doi = {10.1093/bioinformatics/btv022},
eprint = {1407.1507},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deorowicz et al. - 2015 - KMC 2 Fast and resource-frugal k-mer counting.pdf:pdf},
isbn = {1367-4811 (Electronic)\r1367-4803 (Linking)},
issn = {14602059},
journal = {Bioinformatics},
number = {10},
pages = {1569--1576},
pmid = {25609798},
title = {{KMC 2: Fast and resource-frugal k-mer counting}},
volume = {31},
year = {2015}
}
@book{Gagie2018a,
abstract = {We consider the problem of inferring an edge-labeled graph from the sequence of edge labels seen in a walk of that graph. It has been known that this problem is solvable in $O(n \log n)$ time when the targets are path or cycle graphs. This paper presents an online algorithm for the problem of this restricted case that runs in $O(n)$ time, based on Manacher's algorithm for computing all the maximal palindromes in a string.},
archivePrefix = {arXiv},
arxivId = {1806.09806},
author = {Gagie, Travis},
doi = {10.1007/978-3-030-00479-8},
eprint = {1806.09806},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gagie - 2018 - SPIRE 2018 PROCEEDINGS.pdf:pdf},
isbn = {9783030004798},
issn = {03029743},
title = {{SPIRE 2018 PROCEEDINGS}},
url = {http://arxiv.org/abs/1806.09806},
year = {2018}
}
@article{Ferrada2014,
abstract = {Advances in DNA sequencing mean databases of thousands of human genomes will soon be commonplace. In this paper we introduce a simple technique for reducing the size of conventional indexes on such highly repetitive texts. Given upper bounds on pattern lengths and edit distances, we preprocess the text with LZ77 to obtain a filtered text, for which we store a conventional index. Later, given a query, we find all matches in the filtered text, then use their positions and the structure of the LZ77 parse to find all matches in the original text. Our experiments show this also significantly reduces query times.},
archivePrefix = {arXiv},
arxivId = {1306.4037},
author = {Ferrada, H. and Gagie, T. and Hirvola, T. and Puglisi, S. J.},
doi = {10.1098/rsta.2013.0137},
eprint = {1306.4037},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferrada et al. - 2014 - Hybrid indexes for repetitive datasets.pdf:pdf},
issn = {1364503X},
journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
keywords = {Approximate pattern matching,Indexing,LZ77},
number = {2016},
pages = {1--9},
pmid = {24751871},
title = {{Hybrid indexes for repetitive datasets}},
volume = {372},
year = {2014}
}
@article{Gagie2015,
abstract = {The rapid advance of DNA sequencing technologies has yielded databases of thousands of genomes. To search and index these databases effectively, it is important that we take advantage of the similarity between those genomes. Several authors have recently suggested searching or indexing only one reference genome and the parts of the other genomes where they differ. In this paper we survey the twenty-year history of this idea and discuss its relation to kernelization in parameterized complexity.},
archivePrefix = {arXiv},
arxivId = {1412.1591},
author = {Gagie, Travis and Puglisi, Simon J.},
doi = {10.3389/fbioe.2015.00012},
eprint = {1412.1591},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gagie, Puglisi - 2015 - Searching and Indexing Genomic Databases via Kernelization.pdf:pdf},
issn = {2296-4185},
journal = {Frontiers in Bioengineering and Biotechnology2},
keywords = {access reading,approximate pattern matching,approximate pattern matching, data compression, ge,data compression,ge,genomic databases,indexing,kernelization,random-,string algorithms},
number = {February},
pages = {10--13},
pmid = {25710001},
title = {{Searching and Indexing Genomic Databases via Kernelization}},
url = {http://arxiv.org/abs/1412.1591},
volume = {3},
year = {2015}
}
@article{Danek2014,
abstract = {Abstract The availability of thousands of individual genomes of one species should boost rapid progress in personalized medicine or understanding of the interaction between genotype and phenotype, to name a few applications. A key operation useful in such ... \n},
archivePrefix = {arXiv},
arxivId = {1403.7481},
author = {Danek, Agnieszka and Deorowicz, Sebastian and Grabowski, Szymon},
doi = {10.1371/journal.pone.0109384},
eprint = {1403.7481},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Danek, Deorowicz, Grabowski - 2014 - Indexes of large genome collections on a PC.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {10},
pmid = {25289699},
title = {{Indexes of large genome collections on a PC}},
volume = {9},
year = {2014}
}
@article{Peng2012,
abstract = {MOTIVATION: Next-generation sequencing allows us to sequence reads from a microbial environment using single-cell sequencing or metagenomic sequencing technologies. However, both technologies suffer from the problem that sequencing depth of different regions of a genome or genomes from different species are highly uneven. Most existing genome assemblers usually have an assumption that sequencing depths are even. These assemblers fail to construct correct long contigs.\n\nRESULTS: We introduce the IDBA-UD algorithm that is based on the de Bruijn graph approach for assembling reads from single-cell sequencing or metagenomic sequencing technologies with uneven sequencing depths. Several non-trivial techniques have been employed to tackle the problems. Instead of using a simple threshold, we use multiple depthrelative thresholds to remove erroneous k-mers in both low-depth and high-depth regions. The technique of local assembly with paired-end information is used to solve the branch problem of low-depth short repeat regions. To speed up the process, an error correction step is conducted to correct reads of high-depth regions that can be aligned to highconfident contigs. Comparison of the performances of IDBA-UD and existing assemblers (Velvet, Velvet-SC, SOAPdenovo and Meta-IDBA) for different datasets, shows that IDBA-UD can reconstruct longer contigs with higher accuracy.\n\nAVAILABILITY: The IDBA-UD toolkit is available at our website http://www.cs.hku.hk/$\sim$alse/idba_ud},
author = {Peng, Yu and Leung, Henry C M and Yiu, S. M. and Chin, Francis Y L},
doi = {10.1093/bioinformatics/bts174},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peng et al. - 2012 - IDBA-UD A de novo assembler for single-cell and metagenomic sequencing data with highly uneven depth.pdf:pdf},
isbn = {1367-4811 (Electronic)\n1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
number = {11},
pages = {1420--1428},
pmid = {22495754},
title = {{IDBA-UD: A de novo assembler for single-cell and metagenomic sequencing data with highly uneven depth}},
volume = {28},
year = {2012}
}
@techreport{Deblasio,
author = {Deblasio, Dan and Kececioglu, John},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deblasio, Kececioglu - Unknown - Computational Biology Parameter Advising for Multiple Sequence Alignment.pdf:pdf},
title = {{Computational Biology Parameter Advising for Multiple Sequence Alignment}},
url = {http://www.springer.com/series/5769}
}
@inproceedings{Marcais2018,
abstract = {OBJECTIVES: OK-432 has been widely used to treat lymphangioma and ranula; however, there are few studies for its use in treatment of branchial cleft cyst (BCC). We conducted this study to evaluate the effectiveness of sclerotherapy using OK-432 in treatment of BCC.\n\nSTUDY DESIGN AND SETTING: Case series with planned data collection.\n\nSUBJECTS AND METHODS: From 2004 to 2007, we treated 23 patients with BCC using OK-432 sclerotherapy. Of these 23 patients, 18 had unilocular cysts and five had multilocular cysts. The sizes of the BCCs were measured and compared before and after treatment.\n\nRESULTS: Of the 23 cases, 14 (60.8%) showed complete regression; all of these were unilocular cysts. Of the remaining individuals with unilocular cysts, only one patient failed to show any response. This individual subsequently underwent surgical excision. A total of five patients with multilocular cysts showed no or partial response and subsequently underwent surgical excision. Minor adverse effects including fever and local pain were reported by 13 (56.5%) patients.\n\nCONCLUSION: These results suggest that sclerotherapy using OK-432 is an effective and safe treatment modality for BCC, especially for unilocular cysts. Sclerosing of unilocular BCC with OK-432 should therefore be considered before surgical excision.},
author = {Mar{\c{c}}ais, Guillaume and Deblasio, Dan and Kingsford, Carl},
booktitle = {Bioinformatics},
doi = {10.1093/bioinformatics/bty258},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mar{\c{c}}ais, Deblasio, Kingsford - 2018 - Asymptotically optimal minimizers schemes.pdf:pdf},
issn = {14602059},
pmid = {19716008},
title = {{Asymptotically optimal minimizers schemes}},
year = {2018}
}
@article{Fernandez2015,
abstract = {BACKGROUND: It is well understood that distinct communities of bacteria are present at different sites of the body, and that changes in the structure of these communities have strong implications for human health. Yet, challenges remain in understanding the complex interconnections between the bacterial taxa within these microbial communities and how they change during the progression of diseases. Many recent studies attempt to analyze the human microbiome using traditional ecological measures and cataloging differences in bacterial community membership. In this paper, we show how to push metagenomic analyses beyond mundane questions related to the bacterial taxonomic profiles that differentiate one sample from another.\n\nMETHODS: We develop tools and techniques that help us to investigate the nature of social interactions in microbial communities, and demonstrate ways of compactly capturing extensive information about these networks and visually conveying them in an effective manner. We define the concept of bacterial "social clubs", which are groups of taxa that tend to appear together in many samples. More importantly, we define the concept of "rival clubs", entire groups that tend to avoid occurring together in many samples. We show how to efficiently compute social clubs and rival clubs and demonstrate their utility with the help of examples including a smokers' dataset and a dataset from the Human Microbiome Project (HMP).\n\nRESULTS: The tools developed provide a framework for analyzing relationships between bacterial taxa modeled as bacterial co-occurrence networks. The computational techniques also provide a framework for identifying clubs and rival clubs and for studying differences in the microbiomes (and their interactions) of two or more collections of samples.\n\nCONCLUSIONS: Microbial relationships are similar to those found in social networks. In this work, we assume that strong (positive or negative) tendencies to co-occur or co-infect is likely to have biological, physiological, or ecological significance, possibly as a result of cooperation or competition. As a consequence of the analysis, a variety of biological interpretations are conjectured. In the human microbiome context, the pattern of strength of interactions between bacterial taxa is unique to body site.},
author = {Fernandez, Mitch and Riveros, Juan D. and Campos, Michael and Mathee, Kalai and Narasimhan, Giri},
doi = {10.1186/1471-2164-16-S11-S6},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fernandez et al. - 2015 - Microbial social networks.pdf:pdf},
isbn = {1471-2164},
issn = {14712164},
journal = {BMC Genomics},
keywords = {Bacterial clubs,Club leader,Co-occurrence networks,Microbiome,Rival clubs},
pmid = {26576770},
title = {{Microbial "social networks"}},
year = {2015}
}
@article{Bender2017,
abstract = {Databases need to allocate and free blocks of storage on disk. Freed blocks introduce holes where no data is stored. Allocation systems attempt to reuse such deallocated regions in order to minimize the footprint on disk. If previously allocated blocks cannot be moved, the problem is called the memory allocation problem, which is known to have a logarithmic overhead in the footprint. This paper defines the storage reallocation problem, where previously allocated blocks can be moved, or reallocated, but at some cost. The algorithms presented here are cost oblivious, in that they work for a broad and reasonable class of cost functions, even when they do not know what the cost function is. The objective is to minimize the storage footprint, that is, the largest memory address containing an allocated object, while simultaneously minimizing the reallocation costs. This paper gives asymptotically optimal algorithms for storage reallocation, in which the storage footprint is at most (1+epsilon) times optimal, and the reallocation cost is at most (1/epsilon) times the original allocation cost, which is also optimal. The algorithms are cost oblivious as long as the allocation/reallocation cost function is subadditive.},
archivePrefix = {arXiv},
arxivId = {1404.2019},
author = {Bender, Michael A. and Farach-Colton, Mart{\'{i}}n and Fekete, S{\'{a}}ndor P. and Fineman, Jeremy T. and Gilbert, Seth},
doi = {10.1145/3070693},
eprint = {1404.2019},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bender et al. - 2017 - Cost-Oblivious Storage Reallocation.pdf:pdf},
isbn = {9781450323758},
issn = {15496325},
journal = {ACM Transactions on Algorithms},
title = {{Cost-Oblivious Storage Reallocation}},
year = {2017}
}
@inproceedings{Kraska2018,
abstract = {Indexes are models: a B-Tree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a BitMap-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term learned indexes. The key idea is that a model can learn the sort order or structure of lookup keys and use this signal to effectively predict the position or existence of records. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show, that by using neural nets we are able to outperform cache-optimized B-Trees by up to 70% in speed while saving an order-of-magnitude in memory over several real-world data sets. More importantly though, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work just provides a glimpse of what might be possible.},
archivePrefix = {arXiv},
arxivId = {1712.01208},
author = {Kraska, Tim and Beutel, Alex and Chi, Ed H. and Dean, Jeffrey and Polyzotis, Neoklis},
booktitle = {SIGMOD},
doi = {10.1177/1363461513487666},
eprint = {1712.01208},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kraska et al. - 2018 - The Case for Learned Index Structures.pdf:pdf},
isbn = {9781450314725},
issn = {1461-7471},
pmid = {23690445},
title = {{The Case for Learned Index Structures}},
year = {2018}
}
@article{Cickovski2017,
abstract = {The notion of centrality is used to identify “important” nodes in social networks. Importance of nodes is not well-defined, and many different notions exist in the literature. The challenge of defining centrality in meaningful ways when network edges can be positively or negatively weighted has not been adequately addressed in the literature. Existing centrality algorithms also have a second shortcoming, i.e., the list of the most central nodes are often clustered in a specific region of the network and are not well represented across the network. We address both by proposing Ablatio Triadum (ATria), an iterative centrality algorithm that uses the concept of “payoffs” from economic theory. We compare our algorithm with other known centrality algorithms and demonstrate how ATria overcomes several of their shortcomings. We demonstrate the applicability of our algorithm to synthetic networks as well as biological networks including bacterial co-occurrence networks, sometimes referred to as microbial social networks. We show evidence that ATria identifies three different kinds of “important” nodes in microbial social networks with different potential roles in the community.},
author = {Cickovski, Trevor and Peake, Eli and Aguiar-Pulido, Vanessa and Narasimhan, Giri},
doi = {10.1186/s12859-017-1659-z},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cickovski et al. - 2017 - ATria A novel centrality algorithm applied to biological networks.pdf:pdf},
isbn = {9781467396639},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Biological network,Centrality,Economic payoff,Microbial social network},
pmid = {28617231},
title = {{ATria: A novel centrality algorithm applied to biological networks}},
year = {2017}
}
@article{Jain,
abstract = {Emerging single-molecule sequencing technologies from Pacific Biosciences and Oxford Nanopore have revived interest in long read mapping algorithms. Alignment-based seed-and-extend methods demonstrate good accuracy, but face limited scalability, while faster alignment-free methods typically trade decreased precision for efficiency. In this paper, we combine a fast approximate read mapping algorithm based on minimizers with a novel MinHash identity estimation technique to achieve both scalability and precision. In contrast to prior methods, we develop a mathematical framework that defines the types of mapping targets we uncover, establish probabilistic estimates of p-value and sensitivity , and demonstrate tolerance for alignment error rates up to 20%. With this framework, our algorithm automatically adapts to different minimum length and identity requirements and provides both positional and identity estimates for each mapping reported. For mapping human PacBio reads to the hg38 reference, our method is 290x faster than BWA-MEM with a lower memory footprint and recall rate of 96%. We further demonstrate the scalability of our method by mapping noisy PacBio reads (each ≥ 5 kbp in length) to the complete NCBI RefSeq database containing 838 Gbp of sequence and > 60, 000 genomes.},
author = {Jain, Chirag and Dilthey, Alexander and Koren, Sergey and Aluru, Srinivas and Phillippy, Adam M},
doi = {10.1101/103812},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jain et al. - Unknown - A Fast Approximate Algorithm for Mapping Long Reads to Large Reference Databases.pdf:pdf},
keywords = {Jaccard,Long read mapping,MinHash,Mini-mizers,Nanopore,PacBio,Sketching,Winnowing},
title = {{A Fast Approximate Algorithm for Mapping Long Reads to Large Reference Databases}},
url = {http://dx.doi.org/10.1101/103812}
}
@article{Kempa2017,
abstract = {A well-known fact in the field of lossless text compression is that high-order entropy is a weak model when the input contains long repetitions. Motivated by this fact, decades of research have generated myriads of so-called dictionary compressors: algorithms able to reduce the text's size by exploiting its repetitiveness. Lempel-Ziv 77 is probably one of the most successful and known tools of this kind, followed by straight-line programs, run-length Burrows-Wheeler transform, and other less-known schemes. In this paper, we show that these techniques are different solutions to the same, elegant, combinatorial problem: to find a small set of positions capturing all distinct text's substrings. We call such a set a string attractor. We first show reductions between dictionary compressors and string attractors. This gives us the approximation ratios of dictionary compressors with respect to the smallest string attractor and allows us to solve several open problems related to the asymptotic relations between the output sizes of different dictionary compressors. We then show that the k-attractor problem - that is, deciding whether a text has a size-t set of positions capturing all substrings of length at most k - is NP-complete for k >= 3. We provide approximation techniques for the smallest k-attractor, show that the problem is APX-complete for constant k, and give strong inapproximability results. To conclude, we provide matching lower- and upper- bounds for the random access problem on string attractors. Our optimal data structure is universal: by our reductions to string attractors, it supports random access on any dictionary-compression scheme. In particular, our solution matches the lower bound also on LZ77, straight-line programs, collage systems, and macro schemes, and therefore essentially closes (at once) the random access problem for all these compressors.},
archivePrefix = {arXiv},
arxivId = {1710.10964},
author = {Kempa, Dominik and Prezza, Nicola},
doi = {10.1145/3188745.3188814},
eprint = {1710.10964},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kempa, Prezza - 2017 - At the Roots of Dictionary Compression String Attractors.pdf:pdf},
isbn = {9781450355599},
issn = {07378017},
title = {{At the Roots of Dictionary Compression: String Attractors}},
year = {2017}
}
@article{Gagie2017a,
abstract = {The famous Burrows–Wheeler Transform (BWT) was originally defined for a single string but variations have been developed for sets of strings, labeled trees, de Bruijn graphs, etc. In this paper we propose a framework that includes many of these variations and that we hope will simplify the search for more. We first define Wheeler graphs and show they have a property we call path coherence. We show that if the state diagram of a finite-state automaton is a Wheeler graph then, by its path coherence, we can order the nodes such that, for any string, the nodes reachable from the initial state or states by processing that string are consecutive. This means that even if the automaton is non-deterministic, we can still store it compactly and process strings with it quickly. We then rederive several variations of the BWT by designing straightforward finite-state automata for the relevant problems and showing that their state diagrams are Wheeler graphs.},
author = {Gagie, Travis and Manzini, Giovanni and Sir{\'{e}}n, Jouni},
doi = {10.1016/j.tcs.2017.06.016},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gagie, Manzini, Sir{\'{e}}n - 2017 - Wheeler graphs A framework for BWT-based data structures.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Burrows–Wheeler transform,Compressed data structures,Pattern matching},
title = {{Wheeler graphs: A framework for BWT-based data structures}},
year = {2017}
}
@article{,
abstract = {We propose an external memory algorithm for the computation of the BWT and LCP array for a collection of sequences. Our algorithm takes the amount of available memory as an input parameter, and tries to make the best use of it by splitting the input collection into subcollections sufficiently small that it can compute their BWT in RAM using an optimal linear time algorithm. Next, it merges the partial BWTs in external memory and in the process it also computes the LCP values. We prove that our algorithm performs O(n AveLcp) sequential I/Os, where n is the total length of the collection, and AveLcp is the average Longest Common Prefix of the collection. This bound is an improvement over the known algorithms for the same task. The experimental results show that our algorithm outperforms the current best algorithm for collections of sequences with different lengths and for collections with relatively small average Longest Common Prefix. In the second part of the paper, we show that our algorithm can be modified to output two additional arrays that, used with the BWT and LCP arrays, provide simple, scan based, external memory algorithms for three well known problems in bioinformatics: the computation of maximal repeats, the all pairs suffix-prefix overlaps, and the construction of succinct de Bruijn graphs. To our knowledge, there are no other known external memory algorithms for these problems.},
archivePrefix = {arXiv},
arxivId = {1805.06821},
doi = {10.4230/LIPIcs.CVIT.2016.23},
eprint = {1805.06821},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2018 - Assembling Omnitigs using Hidden-Order de Bruijn Graphs.pdf:pdf},
isbn = {0000000329},
issn = {18688969},
title = {{Assembling Omnitigs using Hidden-Order de Bruijn Graphs}},
year = {2018}
}
@techreport{Saad,
abstract = {We introduce GCIS, a grammar compression algorithm based on the induced suffix sorting algorithm SAIS, presented by Nong et al. in 2009. Our solution builds on the factorization performed by SAIS during suffix sorting. We construct a context-free grammar on the input string which can be further reduced into a shorter string by substituting each substring by its corresponding factor. The resulting grammar is encoded by exploring some redundancies, such as common prefixes between suffix rules, which are sorted according to SAIS framework. When compared to well-known compression tools such as RePair and 7-zip under repetitive sequences, our algorithm is faster at compressing and achieves compression ratio close to that of RePair , at the cost of being the slowest at decompressing.},
author = {Saad, Daniel and Nunes, Nogueira and Louza, Felipe A and Gog, Simon and Ayala-Rinc{\'{o}}n, Mauricio and Navarro, Gonzalo},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saad et al. - Unknown - A Grammar Compression Algorithm based on Induced Suffix Sorting.pdf:pdf},
title = {{A Grammar Compression Algorithm based on Induced Suffix Sorting}}
}
@article{Hernandez2017,
abstract = {Many proteins work together with others in groups called complexes in order to achieve a specific function. Discovering protein complexes is important for understanding biological processes and predict protein functions in living organisms. Large-scale and throughput techniques have made possible to compile protein-protein interaction networks (PPI networks), which have been used in several computational approaches for detecting protein complexes. Those predictions might guide future biologic experimental research. Some approaches are topology-based, where highly connected proteins are predicted to be complexes; some propose different clustering algorithms using partitioning, overlaps among clusters for networks modeled with unweighted or weighted graphs; and others use density of clusters and information based on protein functionality. However, some schemes still require much processing time or the quality of their results can be improved. Furthermore, most of the results obtained with computational tools are not accompanied by an analysis of false positives. We propose an effective and efficient mining algorithm for discovering highly connected subgraphs, which is our base for defining protein complexes. Our representation is based on transforming the PPI network into a directed acyclic graph that reduces the number of represented edges and the search space for discovering subgraphs. Our approach considers weighted and unweighted PPI networks. We compare our best alternative using PPI networks from Saccharomyces cerevisiae (yeast) and Homo sapiens (human) with state-of-the-art approaches in terms of clustering, biological metrics and execution times, as well as three gold standards for yeast and two for human. Furthermore, we analyze false positive predicted complexes searching the PDBe (Protein Data Bank in Europe) database in order to identify matching protein complexes that have been purified and structurally characterized. Our analysis shows that more than 50 yeast protein complexes and more than 300 human protein complexes found to be false positives according to our prediction method, i.e., not described in the gold standard complex databases, in fact contain protein complexes that have been characterized structurally and documented in PDBe. We also found that some of these protein complexes have recently been classified as part of a Periodic Table of Protein Complexes. The latest version of our software is publicly available at http://doi.org/10.6084/m9.figshare.5297314.v1.},
author = {Hernandez, Cecilia and Mella, Carlos and Navarro, Gonzalo and Olivera-Nappa, Alvaro and Araya, Jaime},
doi = {10.1371/journal.pone.0183460},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hernandez et al. - 2017 - Protein complex prediction via dense subgraphs and false positive analysis.pdf:pdf},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS ONE},
pmid = {28937982},
title = {{Protein complex prediction via dense subgraphs and false positive analysis}},
year = {2017}
}
@article{Gagie2018b,
abstract = {We present the first solution to $\tau$-majorities on tree paths. Given a tree of $n$ nodes, each with a label from $[1..\sigma]$, and a fixed threshold $0<\tau<1$, such a query gives two nodes $u$ and $v$ and asks for all the labels that appear more than $\tau \cdot |P_{uv}|$ times in the path $P_{uv}$ from $u$ to $v$. Note that the answer to any query is of size up to $1/\tau$. On a $w$-bit RAM machine, we obtain a linear-space data structure that lists all the majorities in time $O((1/\tau)\log^* n \log\log_w \sigma)$. For any $\kappa > 1$, we can also build a data structure that uses $O(n\log^{[\kappa]} n)$ space, where $\log^{[\kappa]} n$ is the iterated logarithm, and answers queries in time $O((1/\tau)\log\log_w \sigma)$. The construction time of both data structures is $O(n\log n)$. We also describe succinct-space solutions, both reaching the same query time of the linear-space structure. One uses $2nH + 4n + o(n)(H+1)$ bits, where $H \le \lg\sigma$ is the entropy of the distribution of labels in $T$, and can be built in $O(n\log n)$ time. The other uses $nH + O(n) + o(nH)$ bits and is built in $O(n\log n)$ randomized time.},
archivePrefix = {arXiv},
arxivId = {1806.01804},
author = {Gagie, Travis and He, Meng and Navarro, Gonzalo},
doi = {10.4230/LIPIcs},
eprint = {1806.01804},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gagie, He, Navarro - 2018 - Tree Path Majority Data Structures.pdf:pdf},
title = {{Tree Path Majority Data Structures}},
year = {2018}
}
@inproceedings{Gagie2018c,
abstract = {Shannon's entropy is a clear lower bound for statistical compression. The situation is not so well understood for dictionary-based compression. A plausible lower bound is b, the least number of phrases of a general bidirectional parse of a text, where phrases can be copied from anywhere else in the text. Since computing b is NP-complete, a popular gold standard is z, the number of phrases in the Lempel-Ziv parse of the text, which is the optimal one when phrases can be copied only from the left. While z can be computed in linear time with a greedy algorithm, almost nothing has been known for decades about its approximation ratio with respect to b. In this paper we prove that z = O(b log(n/b)), where n is the text length. We also show that the bound is tight as a function of n, by exhibiting a string family where z = {\Omega}(b log n). Our upper bound is obtained by building a run-length context-free grammar based on a locally consistent parsing of the text. Our lower bound is obtained by relating b with r, the number of equal-letter runs in the Burrows-Wheeler transform of the text. We proceed by observing that Lempel-Ziv is just one particular case of greedy parse, and introduce a new parse where phrases can only be copied from lexicographically smaller text locations. We prove that the size v of the smallest parse of this kind has properties similar to z, including the same approximation ratio with respect to b. Interestingly, we also show that v = O(r), whereas r = o(z) holds on some particular classes of strings. On our way, we prove other relevant bounds between compressibility measures.},
archivePrefix = {arXiv},
arxivId = {1803.09517},
author = {Gagie, Travis and Navarro, Gonzalo and Prezza, Nicola},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-77404-6_36},
eprint = {1803.09517},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gagie, Navarro, Prezza - 2018 - On the approximation ratio of Lempel-Ziv parsing.pdf:pdf},
isbn = {9783319774039},
issn = {16113349},
title = {{On the approximation ratio of Lempel-Ziv parsing}},
year = {2018}
}
@article{Gagie2017b,
abstract = {Indexing highly repetitive texts --- such as genomic databases, software repositories and versioned text collections --- has become an important problem since the turn of the millennium. A relevant compressibility measure for repetitive texts is $r$, the number of runs in their Burrows-Wheeler Transform (BWT). One of the earliest indexes for repetitive collections, the Run-Length FM-index, used $O(r)$ space and was able to efficiently count the number of occurrences of a pattern of length $m$ in the text (in loglogarithmic time per pattern symbol, with current techniques). However, it was unable to locate the positions of those occurrences efficiently within a space bounded in terms of $r$. Since then, a number of other indexes with space bounded by other measures of repetitiveness --- the number of phrases in the Lempel-Ziv parse, the size of the smallest grammar generating the text, the size of the smallest automaton recognizing the text factors --- have been proposed for efficiently locating, but not directly counting, the occurrences of a pattern. In this paper we close this long-standing problem, showing how to extend the Run-Length FM-index so that it can locate the $occ$ occurrences efficiently within $O(r)$ space (in loglogarithmic time each), and reaching optimal time $O(m+occ)$ within $O(r\log(n/r))$ space, on a RAM machine of $w=\Omega(\log n)$ bits. Within $O(r\log (n/r))$ space, our index can also count in optimal time $O(m)$. Raising the space to $O(r w\log_\sigma(n/r))$, we support count and locate in $O(m\log(\sigma)/w)$ and $O(m\log(\sigma)/w+occ)$ time, which is optimal in the packed setting and had not been obtained before in compressed space. We also describe a structure using $O(r\log(n/r))$ space that replaces the text and extracts any text substring of length $\ell$ in almost-optimal time $O(\log(n/r)+\ell\log(\sigma)/w)$. (...continues...)},
archivePrefix = {arXiv},
arxivId = {1705.10382},
author = {Gagie, Travis and Navarro, Gonzalo and Prezza, Nicola},
doi = {10.1137/1.9781611975031.96},
eprint = {1705.10382},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gagie, Navarro, Prezza - 2017 - Optimal-Time Text Indexing in BWT-runs Bounded Space(2).pdf:pdf},
isbn = {9781611975031},
title = {{Optimal-Time Text Indexing in BWT-runs Bounded Space}},
year = {2017}
}
@article{Tong2018,
abstract = {The widespread online misinformation could cause public panic and serious economic damages. The misinformation containment problem aims at limiting the spread of misinformation in online social networks by launching competing campaigns. Motivated by realistic scenarios, we present the first analysis of the misinformation containment problem for the case when an arbitrary number of cascades are allowed. This paper makes four contributions. First, we provide a formal model for multi-cascade diffusion and introduce an important concept called as cascade priority. Second, we show that the misinformation containment problem cannot be approximated within a factor of $\Omega(2^{\log^{1-\epsilon}n^4})$ in polynomial time unless $NP \subseteq DTIME(n^{\polylog{n}})$. Third, we introduce several types of cascade priority that are frequently seen in real social networks. Finally, we design novel algorithms for solving the misinformation containment problem. The effectiveness of the proposed algorithm is supported by encouraging experimental results.},
archivePrefix = {arXiv},
arxivId = {1809.06486},
author = {Tong, Guangmo and Wu, Weili and Du, Ding-Zhu},
eprint = {1809.06486},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tong, Wu, Du - 2018 - On Misinformation Containment in Online Social Networks.pdf:pdf},
number = {Nips},
pages = {1--15},
title = {{On Misinformation Containment in Online Social Networks}},
url = {http://arxiv.org/abs/1809.06486},
year = {2018}
}
@article{Chouldechova2017,
abstract = {Recidivism prediction instruments (RPI's) provide decision makers with an assessment of the likelihood that a criminal defendant will reoffend at a future point in time. While such instruments are gaining increasing popularity across the country, their use is attracting tremendous controversy. Much of the controversy concerns potential discriminatory bias in the risk assessments that are produced. This paper discusses several fairness criteria that have recently been applied to assess the fairness of recidivism prediction instruments. We demonstrate that the criteria cannot all be simultaneously satisfied when recidivism prevalence differs across groups. We then show how disparate impact can arise when a recidivism prediction instrument fails to satisfy the criterion of error rate balance.},
archivePrefix = {arXiv},
arxivId = {1703.00056},
author = {Chouldechova, Alexandra},
doi = {10.1089/big.2016.0047},
eprint = {1703.00056},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chouldechova - 2017 - Fair prediction with disparate impact A study of bias in recidivism prediction instruments.pdf:pdf},
issn = {2167-6461},
journal = {Big Data},
keywords = {bias,disparate impact,fair machine learning,recidivism prediction,risk assessment},
number = {2},
pages = {153--163},
title = {{Fair prediction with disparate impact: A study of bias in recidivism prediction instruments}},
url = {http://arxiv.org/abs/1703.00056},
volume = {5},
year = {2017}
}
@inproceedings{Alipanahi2018,
author = {Alipanahi, Bahar and Kuhnle, Alan and Boucher, Christina},
booktitle = {Symposium on String Processing and Information Retrieval (SPIRE)},
title = {{Recoloring the Colored de Bruijn Graph}},
year = {2018}
}
@inproceedings{Zhang2016e,
author = {Zhang, Huiling and Kuhnle, Alan and Zhang, Huiyuan and Thai, My T},
booktitle = {International Conference on Advances in Social Networks Analysis and Mining (ASONAM)},
publisher = {IEEE},
title = {{Detecting Misinformation in Online Social Networks Before it is Too Late}},
year = {2016}
}
@article{Wang2017,
abstract = {As computer science (CS) education expands at the K–12 level, we must be careful to ensure that CS neither exacerbates existing equity gaps in education nor hinders efforts to diversify the field of CS. In this paper, we discuss structural and social barriers that influence Blacks, Hispanics, and girls, based on surveys of 1,672 students, 1,677 parents, 1,008 teachers, 9,805 principals, and 2,307 superintendents in the United States. We find that despite higher interest in CS among Black and Hispanic students and parents, these students experience greater structural barriers in accessing computers and CS classes than White students. And while girls have the same access as boys, social barriers exist with girls reporting lower awareness of CS opportunities outside of classes, less encouragement from teachers and parents, and less exposure to CS role models in the media. It is critical for expanding CS opportunities to address the unique issues for each group.},
author = {Wang, Jennifer and Moghadam, Sepehr Hejazi},
doi = {10.1145/3017680.3017734},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Moghadam - 2017 - Diversity Barriers in K–12 Computer Science Education Structural and Social.pdf:pdf},
isbn = {9781450346986},
journal = {Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education},
keywords = {African American,Black,Hispanic,K–12,Latino/a,access,encouragement,ethnicity,exposure,gender,girls,interest,parents,pathways,perceptions,pre-university,race,students,teachers},
pages = {3--8},
title = {{Diversity Barriers in K–12 Computer Science Education: Structural and Social}},
year = {2017}
}
@inproceedings{Franklin2013,
author = {Franklin, Diana},
booktitle = {Synthesis Lectures on Professionalism and Career Advancement for Scientists and Engineers},
title = {{A practical guide to gender diversity for computer science faculty}},
year = {2013}
}
@book{Etzkowitz2000,
author = {Etzkowitz, Henry and Kemelgor, Carol and Uzzi, Brian},
publisher = {Cambridge University Press},
title = {{Athena unbound: The advancement of women in science and technology}},
year = {2000}
}
@inproceedings{Zhang2018,
author = {Zhang, Huiling and Kuhnle, Alan and Smith, J. David and Thai, My T.},
booktitle = {International Conference on Advances in Social Networks Analysis and Mining (ASONAM)},
publisher = {IEEE},
title = {{Restraining Misinformation and Pushing out the Truth}},
year = {2018}
}
@article{Colbeck2013,
author = {Colbeck, Carol L and Cabrera, Alberto F and Terenzini, Patrick T},
doi = {10.1353/rhe.2000.0028},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Colbeck, Cabrera, Terenzini - 2013 - Learning Professional Confidence Linking Teaching Practices, Students' Self-Perceptions, and Gender.pdf:pdf},
journal = {The Review of Higher Education},
number = {2},
pages = {173--191},
title = {{Learning Professional Confidence: Linking Teaching Practices, Students' Self-Perceptions, and Gender}},
volume = {24},
year = {2013}
}
@article{Johnson2014,
abstract = {Evidence shows that women are less self-assured than men—and that to succeed, confidence matters as much as competence. Here's why, and what to do about it.},
author = {Kay, Katty and Shipman, Claire},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kay, Shipman - 2014 - The confidence gap.pdf:pdf},
isbn = {9781921518966 (pbk.)},
issn = {00158259},
journal = {Fortune},
number = {5},
pages = {121},
title = {{The confidence gap}},
volume = {170},
year = {2014}
}
@article{Ferragina2005,
abstract = {We design two compressed data structures for the full-text indexing problem that support efficient substring searches using roughly the space required for storing the text in compressed form. Our first compressed data structure retrieves the occ occurrences of a pattern P[1, p] within a text T [1, n] in O(p + occ log 1+ n) time for any chosen , 0 < < < 1. This data structure uses at most 5n H k (T) + o(n) bits of storage, where H k (T) is the kth order empirical entropy of T . The space usage is (n) bits in the worst case and o(n) bits for compressible texts. This data structure exploits the relationship between suffix arrays and the Burrows–Wheeler Transform, and can be regarded as a compressed suffix array. Our second compressed data structure achieves O(p + occ) query time using O(n H k (T) log n) + o(n) bits of storage for any chosen , 0 < < < 1. Therefore, it provides optimal output-sensitive query time using o(n log n) bits in the worst case. This second data structure builds upon the first one and exploits the interplay between two compressors: the Burrows–Wheeler Transform and the LZ78 algorithm. The work of P. Ferragina was partially supported by the Italian MIUR projects " Algorithmics for Internet and the Web (ALINWEB) " , " Algorithms for the Next Generation Internet and Web (ALGO-NEXT) " , and " Enhanced Content Delivery (ECD) " . The work of G. Manzini was partially supported by the Italian MIUR projects " Algorithmics for Internet and the Web (ALINWEB) " and " Enhanced Content Delivery (ECD) " .},
author = {Ferragina, Paolo and Manzini, Giovanni},
doi = {10.1145/1082036.1082039},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferragina, Manzini - 2005 - Indexing Compressed Text.pdf:pdf},
issn = {00045411},
journal = {Journal of the ACM},
keywords = {Algorithms,Burrows–Wheeler transform,Categories and Subject Descriptors,Content Analysis and Indexing,D42 [Operating Systems],Data compaction and com-pression,Design,E1 [Data Structures],E4 [Coding and Information Theory],E5 [Files],H31 [Information Storage and Retrieval],H32 [Information Storage and Retrieval],H33 [Information Storage and Retrieval],Information Storage,Lempel–Ziv compressor,Sorting/searching,Storage Management,Theory Additional Key Words and Phrases,arrays,full-text indexing,indexing data structure,pattern searching,suffix array,suffix tree,tables,text compression},
number = {4},
pages = {552--581},
title = {{Indexing Compressed Text}},
volume = {52},
year = {2005}
}
@article{Blickenstaff2005,
abstract = {Women are under-represented in science, technology, engineering and mathematics (STEM) majors and careers in most industrialized countries around the world. This paper explores the broad array of explanations for the absence of women in STEM put forth in the literature of the last 30 years. It is argued that some proposed explanations are without merit and are in fact dangerous, while others do play a part in a complex interaction of factors. It is suggested that the very nature of science may contribute to the removal of women from the ‘pipeline'. Recommendations for reform in science education to address this problem are also provided.},
author = {Blickenstaff, Jacob Clark},
doi = {10.1080/09540250500145072},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blickenstaff - 2005 - Women and science careers Leaky pipeline or gender filter.pdf:pdf},
isbn = {0954-0253},
issn = {09540253},
journal = {Gender and Education},
number = {4},
pages = {369--386},
pmid = {17588999},
title = {{Women and science careers: Leaky pipeline or gender filter?}},
volume = {17},
year = {2005}
}
@inproceedings{Nguyen2018,
author = {Nguyen, Lan N. and Smith, J. David and Kang, Jungmin and Thai, My T.},
booktitle = {IEEE International Conference on Communications},
doi = {10.1109/ICC.2018.8423020},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen et al. - 2018 - Optimal Auditing on Smart-Grid Networks.pdf:pdf},
isbn = {9781538631805},
issn = {15503607},
title = {{Optimal Auditing on Smart-Grid Networks}},
year = {2018}
}
@article{Dagum2000,
author = {Dagum, P. and Karp, R. and Luby, M. and Ross, S.},
doi = {10.1109/SFCS.1995.492471},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dagum et al. - 2000 - An optimal algorithm for Monte Carlo estimation.pdf:pdf},
isbn = {0-8186-7183-1},
journal = {SIAM Journal on Computing},
keywords = {60g40,60g44,ams subject classifications,approximation algorithm,mation,monte carlo estimation,pii,s0097539797315306,sequential esti-,stochastic approximation,stopping rule},
number = {5},
pages = {1484--1496},
title = {{An optimal algorithm for Monte Carlo estimation}},
url = {http://ieeexplore.ieee.org/document/492471/},
volume = {29},
year = {2000}
}
@inproceedings{Li2017,
abstract = {One of the most central problems in viral marketing is Influence Maximization (IM), which finds a set of $k$ seed users who can influence the maximum number of users in online social networks. Unfortunately, all existing algorithms to IM, including the state of the art SSA and IMM, have an approximation ratio of $(1 - 1/e - \epsilon)$. Recently, a generalization of IM, Cost-aware Target Viral Marketing (CTVM), asks for the most cost-effective users to influence the most relevant users, has been introduced. The current best algorithm for CTVM has an approximation ratio of $(1 - 1 /\sqrt{e} - \epsilon)$. In this paper, we study the CTVM problem, aiming to optimally solve the problem. We first highlight that using a traditional two stage stochastic programming to exactly solve CTVM is not possible because of scalability. We then propose an almost exact algorithm TipTop, which has an approximation ratio of $(1 - \epsilon)$. This result significantly improves the current best solutions to both IM and CTVM. At the heart of TipTop lies an innovative technique that reduces the number of samples as much as possible. This allows us to exactly solve CTVM on a much smaller space of generated samples using Integer Programming. While obtaining an almost exact solution, TipTop is very scalable, running on billion-scale networks such as Twitter under three hours. Furthermore, TipTop lends a tool for researchers to benchmark their solutions against the optimal one in large-scale networks, which is currently not available.},
archivePrefix = {arXiv},
arxivId = {1701.08462},
author = {Li, Xiang and Smith, J. David and Dinh, Thang N. and Thai, My T.},
booktitle = {IEEE International Conference on Computer Communications (INFOCOM)},
doi = {10.1109/INFOCOM.2017.8057069},
eprint = {1701.08462},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2017 - Why approximate when you can get the exact Optimal Targeted Viral Marketing at Scale.pdf:pdf;:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2017 - Why approximate when you can get the exact Optimal targeted viral marketing at scale.pdf:pdf},
isbn = {9781509053360},
issn = {0743166X},
keywords = {Algorithms,Influence Maximization,Online Social Networks,Optimization,Viral Marketing,algo-,influence maximization,online social networks,optimization,rithms,viral marketing},
title = {{Why approximate when you can get the exact? Optimal Targeted Viral Marketing at Scale}},
url = {http://arxiv.org/abs/1701.08462},
year = {2017}
}
@article{Egidi2018,
abstract = {We propose an external memory algorithm for the computation of the BWT and LCP array for a collection of sequences. Our algorithm takes the amount of available memory as an input parameter, and tries to make the best use of it by splitting the input collection into subcollections sufficiently small that it can compute their BWT in RAM using an optimal linear time algorithm. Next, it merges the partial BWTs in external memory and in the process it also computes the LCP values. We prove that our algorithm performs O(n AveLcp) sequential I/Os, where n is the total length of the collection, and AveLcp is the average Longest Common Prefix of the collection. This bound is an improvement over the known algorithms for the same task. The experimental results show that our algorithm outperforms the current best algorithm for collections of sequences with different lengths and for collections with relatively small average Longest Common Prefix. In the second part of the paper, we show that our algorithm can be modified to output two additional arrays that, used with the BWT and LCP arrays, provide simple, scan based, external memory algorithms for three well known problems in bioinformatics: the computation of maximal repeats, the all pairs suffix-prefix overlaps, and the construction of succinct de Bruijn graphs. To our knowledge, there are no other known external memory algorithms for these problems.},
archivePrefix = {arXiv},
arxivId = {1805.06821},
author = {Egidi, Lavinia and Louza, Felipe A. and Manzini, Giovanni and Telles, Guilherme P.},
doi = {10.4230/LIPIcs.CVIT.2016.23},
eprint = {1805.06821},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Egidi et al. - 2018 - External memory BWT and LCP computation for sequence collections with applications(2).pdf:pdf},
isbn = {0000000329},
issn = {18688969},
title = {{External memory BWT and LCP computation for sequence collections with applications}},
year = {2018}
}
@article{Belazzougui2016a,
abstract = {The Lempel-Ziv parsing of a string (LZ77 for short) is one of the most important and widely-used algorithmic tools in data compression and string processing. We show that the Lempel-Ziv parsing of a string of length $n$ on an alphabet of size $\sigma$ can be computed in $O(n\log\log\sigma)$ time ($O(n)$ time if we allow randomization) using $O(n\log\sigma)$ bits of working space; that is, using space proportional to that of the input string in bits. The previous fastest algorithm using $O(n\log\sigma)$ space takes $O(n(\log\sigma+\log\log n))$ time. We also consider the important rightmost variant of the problem, where the goal is to associate with each phrase of the parsing its most recent occurrence in the input string. We solve this problem in $O(n(1 + (\log\sigma/\sqrt{\log n}))$ time, using the same working space as above. The previous best solution for rightmost parsing uses $O(n(1+\log\sigma/\log\log n))$ time and $O(n\log n)$ space. As a bonus, in our solution for rightmost parsing we provide a faster construction method for efficient 2D orthogonal range reporting, which is of independent interest.},
archivePrefix = {arXiv},
arxivId = {arXiv:1507.07080v1},
author = {Belazzougui, Djamal and Puglisi, Simon J},
doi = {10.1137/1.9781611974331.ch143},
eprint = {arXiv:1507.07080v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Belazzougui, Puglisi - 2016 - Range Predecessor and Lempel-Ziv Parsing ⋆.pdf:pdf},
isbn = {978-1-611974-33-1},
journal = {SIAM ACM Symposium on Discrete Algorithms (SODA'16)},
keywords = {Unauthorized reproduction of this article is prohi},
pages = {2053--2071},
title = {{Range Predecessor and Lempel-Ziv Parsing ⋆}},
year = {2016}
}
@article{Prezza2018,
abstract = {In this paper we develop a theory describing how the extended Burrows-Wheeler Transform (eBWT) of a collection of DNA fragments tends to cluster together the copies of nucleotides sequenced from a genome G. Our theory accurately predicts how many copies of any nucleotide are expected inside each such cluster, and how an elegant and precise LCP array based procedure can locate these clusters in the eBWT. Our findings are very general and can be applied to a wide range of different problems. In this paper, we consider the case of alignment-free and reference-free SNPs discovery in multiple collections of reads. We note that, in accordance with our theoretical results, SNPs are clustered in the eBWT of the reads collection, and we develop a tool finding SNPs with a simple scan of the eBWT and LCP arrays. Preliminary results show that our method requires much less coverage than state-of-the-art tools while drastically improving precision and sensitivity.},
archivePrefix = {arXiv},
arxivId = {1805.01876},
author = {Prezza, Nicola and Pisanti, Nadia and Sciortino, Marinella and Rosone, Giovanna},
doi = {10.4230/LIPIcs.WABI.2018.3},
eprint = {1805.01876},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prezza et al. - 2018 - Detecting Mutations by eBWT.pdf:pdf},
isbn = {9783959770828},
issn = {18688969},
keywords = {2018,3,4230,and phrases bwt,assembly-free,com,digital object identifier 10,ebwtclust,funding g,github,lcp array,lipics,m,n,nicolaprezza,pisanti,prezza is supported by,reference-free,rosone,sciortino are partially and,snps,supplement material https,the,wabi},
number = {3},
pages = {1--3},
title = {{Detecting Mutations by eBWT}},
url = {http://arxiv.org/abs/1805.01876},
year = {2018}
}
@article{Egidi2018a,
abstract = {We propose an external memory algorithm for the computation of the BWT and LCP array for a collection of sequences. Our algorithm takes the amount of available memory as an input parameter, and tries to make the best use of it by splitting the input collection into subcollections sufficiently small that it can compute their BWT in RAM using an optimal linear time algorithm. Next, it merges the partial BWTs in external memory and in the process it also computes the LCP values. We prove that our algorithm performs O(n AveLcp) sequential I/Os, where n is the total length of the collection, and AveLcp is the average Longest Common Prefix of the collection. This bound is an improvement over the known algorithms for the same task. The experimental results show that our algorithm outperforms the current best algorithm for collections of sequences with different lengths and for collections with relatively small average Longest Common Prefix. In the second part of the paper, we show that our algorithm can be modified to output two additional arrays that, used with the BWT and LCP arrays, provide simple, scan based, external memory algorithms for three well known problems in bioinformatics: the computation of maximal repeats, the all pairs suffix-prefix overlaps, and the construction of succinct de Bruijn graphs. To our knowledge, there are no other known external memory algorithms for these problems.},
archivePrefix = {arXiv},
arxivId = {1805.06821},
author = {Egidi, Lavinia and Louza, Felipe A. and Manzini, Giovanni and Telles, Guilherme P.},
doi = {10.4230/LIPIcs.CVIT.2016.23},
eprint = {1805.06821},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Egidi et al. - 2018 - External memory BWT and LCP computation for sequence collections with applications.pdf:pdf},
isbn = {0000000329},
issn = {18688969},
keywords = {10,2018,4230,all pairs,and phrases burrows-wheeler transform,digital object identifier 10,lipics,longest common prefix array,maximal repeats,succinct de bruijn graph,suffix-prefix overlaps,wabi},
number = {10},
pages = {1--10},
title = {{External memory BWT and LCP computation for sequence collections with applications}},
url = {http://arxiv.org/abs/1805.06821},
year = {2018}
}
@article{Muggli2018,
author = {Muggli, Martin D and Boucher, Christina},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Muggli, Boucher - 2018 - A Succinct Solution to Rmap Alignment.pdf:pdf},
journal = {Wabi 2018},
keywords = {and phrases optical mapping,fm-index,graph al-,index based data structures},
number = {12},
pages = {1--12},
title = {{A Succinct Solution to Rmap Alignment}},
year = {2018}
}
@article{Sczyrba2017,
abstract = {The Critical Assessment of Metagenome Interpretation (CAMI) community initiative presents results from its first challenge, a rigorous benchmarking of software for metagenome assembly, binning and taxonomic profiling.},
author = {Sczyrba, Alexander and Hofmann, Peter and Belmann, Peter and Koslicki, David and Janssen, Stefan and Dr{\"{o}}ge, Johannes and Gregor, Ivan and Majda, Stephan and Fiedler, Jessika and Dahms, Eik and Bremges, Andreas and Fritz, Adrian and Garrido-Oter, Ruben and J{\o}rgensen, Tue Sparholt and Shapiro, Nicole and Blood, Philip D. and Gurevich, Alexey and Bai, Yang and Turaev, Dmitrij and Demaere, Matthew Z. and Chikhi, Rayan and Nagarajan, Niranjan and Quince, Christopher and Meyer, Fernando and Balvo{\v{c}}iutė, Monika and Hansen, Lars Hestbjerg and S{\o}rensen, S{\o}ren J. and Chia, Burton K.H. and Denis, Bertrand and Froula, Jeff L. and Wang, Zhong and Egan, Robert and {Don Kang}, Dongwan and Cook, Jeffrey J. and Deltel, Charles and Beckstette, Michael and Lemaitre, Claire and Peterlongo, Pierre and Rizk, Guillaume and Lavenier, Dominique and Wu, Yu Wei and Singer, Steven W. and Jain, Chirag and Strous, Marc and Klingenberg, Heiner and Meinicke, Peter and Barton, Michael D. and Lingner, Thomas and Lin, Hsin Hung and Liao, Yu Chieh and Silva, Genivaldo Gueiros Z. and Cuevas, Daniel A. and Edwards, Robert A. and Saha, Surya and Piro, Vitor C. and Renard, Bernhard Y. and Pop, Mihai and Klenk, Hans Peter and G{\"{o}}ker, Markus and Kyrpides, Nikos C. and Woyke, Tanja and Vorholt, Julia A. and Schulze-Lefert, Paul and Rubin, Edward M. and Darling, Aaron E. and Rattei, Thomas and McHardy, Alice C.},
doi = {10.1038/nmeth.4458},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sczyrba et al. - 2017 - Critical Assessment of Metagenome Interpretation - A benchmark of metagenomics software.pdf:pdf},
isbn = {1548-7105 (Electronic) 1548-7091 (Linking)},
issn = {15487105},
journal = {Nature Methods},
pmid = {28967888},
title = {{Critical Assessment of Metagenome Interpretation - A benchmark of metagenomics software}},
year = {2017}
}
@misc{Ghurye2016,
abstract = {Advances in sequencing technologies have led to the increased use of high throughput sequencing in characterizing the microbial communities associated with our bodies and our environment. Critical to the analysis of the resulting data are sequence assembly algorithms able to reconstruct genes and organisms from complex mixtures. Metagenomic assembly involves new computational challenges due to the specific characteristics of the metagenomic data. In this survey, we focus on major algorithmic approaches for genome and metagenome assembly, and discuss the new challenges and opportunities afforded by this new field. We also review several applications of metagenome assembly in addressing interesting biological problems.},
archivePrefix = {arXiv},
arxivId = {1707.04192},
author = {Ghurye, Jay S. and Cepeda-Espinoza, Victoria and Pop, Mihai},
booktitle = {Yale Journal of Biology and Medicine},
doi = {10.1016/j.joca.2013.10.019},
eprint = {1707.04192},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghurye, Cepeda-Espinoza, Pop - 2016 - Metagenomic assembly Overview, challenges and applications.pdf:pdf},
isbn = {1551-4056 (Electronic)\r0044-0086 (Linking)},
issn = {00440086},
keywords = {Assembly,Metagenomics,Microbiome},
pmid = {27698619},
title = {{Metagenomic assembly: Overview, challenges and applications}},
year = {2016}
}
@article{Sternberg,
abstract = {Network propagation is a powerful transformation that amplifies signal-to-noise ratio in biological and other data. To date, most of its applications in the biological domain employed standard techniques for its computation that require O(m) time for a network with n vertices and m edges. When applied in a dynamic setting where the network is constantly modified, the cost of these computations becomes prohibitive. Here we study, for the first time in the biological context, the complexity of dynamic algorithms for network propagation. We develop a vertex decremental algorithm that is motivated by various biological applications and can maintain propagation scores over general weights at an amortized cost of O(m/n 1/4) per update. In application to real networks, the dynamic algorithm achieves significant, 50-to 100-fold, speedups over conventional static methods for network propagation, demonstrating its great potential in practice. 2012 ACM Subject Classification Theory of computation → Dynamic graph algorithms},
author = {Sternberg, Barak and Sharan, Roded},
doi = {10.4230/LIPIcs.WABI.2018.7},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sternberg, Sharan - Unknown - A Dynamic Algorithm for Network Propagation.pdf:pdf},
keywords = {Dynamic graph algorithm,and phrases Network propagation,protein-protein inter-action network},
title = {{A Dynamic Algorithm for Network Propagation}}
}
@article{Brubach2017,
abstract = {Comparing a string to a large set of sequences is a key subroutine in greedy heuristics for clustering genomic data. Clustering 16S rRNA gene sequences into operational taxonomic units (OTUs) is a common method used in studying microbial communities. We present a new approach to greedy clustering using a trie-like data structure and Four Russians speedup. We evaluate the running time of our method in terms of the number of comparisons it makes during clustering and show in experimental results that the number of comparisons grows linearly with the size of the dataset as opposed to the quadratic running time of other methods. We compare the clusters output by our method to the popular greedy clustering tool UCLUST. We show that the clusters we generate can be both tighter and larger. 1998 ACM Subject Classification B.2.4 Algorithms The problem of comparing a string against a large set of sequences is of central importance in domains such as computational biology, information retrieval, and databases. Solving this problem is a key subroutine in many greedy clustering heuristics, wherein we iteratively choose a cluster center and form a cluster by recruiting all strings which are similar to the center. In computational biology, sequence similarity search is used to group biological sequences that are closely related. We will use this domain as a motivating example throughout the paper. Traditionally, clustering 16S rRNA gene [11] sequences involved building a multiple sequence alignment of all sequences, computing a pairwise distance matrix of sequences based on the multiple sequence alignment, and clustering this matrix [17]. However, finding the best multiple sequence alignment is computationally intractable and belongs to the class of *},
author = {Brubach, Brian and Ghurye, Jay and Pop, Mihai and Srinivasan, Aravind},
doi = {10.4230/LIPIcs.WABI.2017.3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brubach et al. - 2017 - Better Greedy Sequence Clustering with Fast Banded Alignment † 1 Introduction.pdf:pdf},
keywords = {Metagenomics,String Algorithms,and phrases Sequence Clustering},
title = {{Better Greedy Sequence Clustering with Fast Banded Alignment * † 1 Introduction}},
year = {2017}
}
@article{Ghurye2017,
abstract = {Long read technologies have made a revolution in de novo genome assembly by generating contigs of size orders of magnitude more than that of short read assemblies. Although the assembly contiguity has increased, it still does not span a chromosome or an arm of the chromosome, resulting in an unfinished chromosome level assembly. To address this problem, we develop a scalable and computationally efficient scaffolding method that can boost the contiguity of the assembly by a large extent using genome wide chromatin interaction data such as Hi-C. Particularly, we demonstrate an algorithm that uses Hi-C data for longer-range scaffolding of de novo long read genome assemblies. We tested our methods on two long read assemblies of different organisms. We compared our method with previously developed method and show that our approach performs better in terms of accuracy of scaffolding. The software is available for free use and can be downloaded from here:https://github.com/machinegun/hi-c-scaffold

},
author = {Ghurye, Jay and Pop, Mihai and Koren, Sergey and Bickhart, Derek and Chin, Chen Shan},
doi = {10.1186/s12864-017-3879-z},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghurye et al. - 2017 - Scaffolding of long read assemblies using long range contact information.pdf:pdf},
isbn = {1471-2164 (Electronic)
1471-2164 (Linking)},
issn = {14712164},
journal = {BMC Genomics},
keywords = {Assembly,Hi-C,Long reads,Scaffolding},
pmid = {28701198},
title = {{Scaffolding of long read assemblies using long range contact information}},
year = {2017}
}
@techreport{Cox2016,
abstract = {Relative Lempel-Ziv (RLZ) is a popular algorithm for compressing databases of genomes from individuals of the same species when fast random access is desired. With Kuruppu et al.'s (SPIRE 2010) original implementation, a reference genome is selected and then the other genomes are greedily parsed into phrases exactly matching substrings of the reference. Deorowicz and Grabowski (Bioinformatics, 2011) pointed out that letting each phrase end with a mismatch character usually gives better compression because many of the differences between individuals' genomes are single-nucleotide substitutions. Ferrada et al. (SPIRE 2014) then pointed out that also using relative pointers and run-length compressing them usually gives even better compression. In this paper we generalize Ferrada et al.'s idea to handle well also short insertions, deletions and multi-character substitutions. We show experimentally that our generalization achieves better compression than Ferrada et al.'s implementation with comparable random-access times.},
archivePrefix = {arXiv},
arxivId = {arXiv:1605.04421v1},
author = {Cox, Anthony J and Farruggia, Andrea and Gagie, Travis and Puglisi, Simon J and Sir{\'{e}}n, Jouni},
eprint = {arXiv:1605.04421v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cox et al. - 2016 - RLZAP Relative Lempel-Ziv with Adaptive Pointers ⋆.pdf:pdf},
title = {{RLZAP: Relative Lempel-Ziv with Adaptive Pointers ⋆}},
url = {http://github.com/farruggia/rlzap},
year = {2016}
}
@misc{Chen2018,
abstract = {{\textcopyright} 2018 Springer Science+Business Media, LLC, part of Springer Nature Let G = (V, E) be a simple graph and (Formula presented.) assign each edge e ∈ E a positive integer weight w(e). A subset of E that intersects every triangle of G is called a triangle cover of (G, w), and its weight is the total weight of its edges. A collection of triangles in G (repetition allowed) is called a triangle packing of (G, w) if each edge e ∈ E appears in at most w(e) members of the collection. Let $\tau$ t (G, w) and $\nu$ t (G, w) denote the minimum weight of a triangle cover and the maximum cardinality of a triangle packing of (G, w), respectively. Generalizing Tuza's conjecture for unit weight, Chapuy et al. conjectured that $\tau$ t (G, w)/$\nu$ t (G, w) ≤ 2 holds for every simple graph G and every (Formula presented.). In this paper, using a hypergraph approach, we design polynomial-time combinatorial algorithms for finding triangle covers of small weights. These algorithms imply new sufficient conditions for the conjecture of Chapuy et al. More precisely, given (G, w), suppose that all edges of G are covered by the set (Formula presented.) consisting of edge sets of triangles in G. Let (Formula presented.) and (Formula presented.) denote the weighted numbers of edges and triangles in (G, w), respectively. We show that a triangle cover of (G, w) of weight at most 2$\nu$ t (G, w) can be found in strongly polynomial time if one of the following conditions is satisfied: (i) (Formula presented.), (ii) (Formula presented.), (iii) (Formula presented.).},
author = {Chen, Xujin and Diao, Zhuo and Hu, Xiaodong and Tang, Zhongzheng},
booktitle = {Theory of Computing Systems},
doi = {10.1007/s00224-018-9860-7},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2018 - Covering Triangles in Edge-Weighted Graphs.pdf:pdf},
issn = {14330490},
keywords = {Combinatorial algorithms,Linear 3-uniform hypergraphs,Triangle cover,Triangle packing},
title = {{Covering Triangles in Edge-Weighted Graphs}},
year = {2018}
}
@inproceedings{Fuentes-Sepulveda2018,
abstract = {Given a string of length $n$ that is composed of $r$ runs of letters from the alphabet $\{0,1,\ldots,\sigma{-}1\}$ such that $2 \le \sigma \le r$, we describe a data structure that, provided $r \le n / \log^{\omega(1)} n$, stores the string in $r\log\frac{n\sigma}{r} + o(r\log\frac{n\sigma}{r})$ bits and supports select and access queries in $O(\log\frac{\log(n/r)}{\log\log n})$ time and rank queries in $O(\log\frac{\log(n\sigma/r)}{\log\log n})$ time. We show that $r\log\frac{n(\sigma-1)}{r}$ bits are necessary for any such data structure and, thus, our solution is succinct. We also describe a data structure that uses $(1 + \epsilon)r\log\frac{n\sigma}{r} + O(r)$ bits, where $\epsilon > 0$ is an arbitrary constant, with the same query times but without the restriction $r \le n / \log^{\omega(1)} n$. By simple reductions to the colored predecessor problem, we show that the query times are optimal in the important case $r \ge 2^{\log^\delta n}$, for an arbitrary constant $\delta > 0$. We implement our solution and compare it with the state of the art, showing that the closest competitors consume 31-46% more space.},
archivePrefix = {arXiv},
arxivId = {1711.02910},
author = {Fuentes-Sepulveda, Jose and Karkkainen, Juha and Kosolobov, Dmitry and Puglisi, Simon},
booktitle = {2018 Data Compression Conference},
doi = {10.1109/DCC.2018.00040},
eprint = {1711.02910},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fuentes-Sepulveda et al. - 2018 - Run Compressed RankSelect for Large Alphabets.pdf:pdf},
isbn = {978-1-5386-4883-4},
issn = {10680314},
title = {{Run Compressed Rank/Select for Large Alphabets}},
year = {2018}
}
@article{Libbrecht2017,
author = {Libbrecht, Maxwell W and Bilmes, Jeffrey A and Stafford, William},
doi = {10.1002/prot.25461},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Libbrecht, Bilmes, Stafford - 2017 - Choosing non-redundant representative subsets of protein sequence data sets using submodular optimi.pdf:pdf},
journal = {Proteins: Structure, Function, and Bioinformatics},
keywords = {department of electrical engineering,seattle,university of washington},
number = {July 2017},
pages = {454--466},
title = {{Choosing non-redundant representative subsets of protein sequence data sets using submodular optimization}},
year = {2017}
}
@article{Lao2018,
author = {Lao, Bin and Nong, Ge and Chan, Wai Hong},
doi = {10.1007/s11227-018-2395-5},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lao, Nong, Chan - 2018 - Fast induced sorting suffixes on a multicore machine.pdf:pdf},
issn = {1573-0484},
journal = {The Journal of Supercomputing},
keywords = {Suffix array,Induced sorting,Parallel algorithm,Mu},
number = {7},
pages = {3468--3485},
publisher = {Springer US},
title = {{Fast induced sorting suffixes on a multicore machine}},
url = {https://doi.org/10.1007/s11227-018-2395-5},
volume = {74},
year = {2018}
}
@article{Bingmann2016,
author = {Bingmann, Timo and Fischer, Johannes and Osipov, Vitaly},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bingmann, Fischer, Osipov - 2016 - Inducing Suffix and LCP Arrays in External Memory.pdf:pdf},
number = {2},
title = {{Inducing Suffix and LCP Arrays in External Memory}},
volume = {21},
year = {2016}
}
@article{Karkkainen,
author = {K{\"{a}}rkk{\"{a}}inen, Juha and Puglisi, Simon J},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/K{\"{a}}rkk{\"{a}}inen, Puglisi - Unknown - Engineering External Memory Induced Suffix Sorting ∗.pdf:pdf},
pages = {98--108},
title = {{Engineering External Memory Induced Suffix Sorting ∗}}
}
@article{Juha,
author = {Juha, K and Kempa, Dominik and Puglisi, Simon J},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Juha, Kempa, Puglisi - Unknown - Slashing the Time for BWT Inversion.pdf:pdf},
pages = {1--10},
title = {{Slashing the Time for BWT Inversion}},
volume = {118653}
}
@article{Agarwal,
author = {Agarwal, Sakshi},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Agarwal - Unknown - Multi-perspective Elicitation of Influential Parameters and Measures in Social Network.pdf:pdf},
title = {{Multi-perspective Elicitation of Influential Parameters and Measures in Social Network}}
}
@article{Karbasi2018,
author = {Karbasi, Amin and Hesam, Amir and Vetterli, Martin},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karbasi, Hesam, Vetterli - 2018 - Learning neural connectivity from firing activity efficient algorithms with provable guarantees on to.pdf:pdf},
keywords = {Functional connectivity,Synaptic connectivity,Neur,action editor,ch,data related to this,epfl,functional connectivity,http,ksv2017,liam paninski,neural network,neural signal processing,paper,paper is available at,rr,synaptic connectivity,the code and the},
pages = {253--272},
publisher = {Journal of Computational Neuroscience},
title = {{Learning neural connectivity from firing activity : efficient algorithms with provable guarantees on topology}},
year = {2018}
}
@article{Zitnik2018,
author = {Zitnik, Marinka and Leskovec, Jure},
doi = {10.1093/bioinformatics/btx252},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zitnik, Leskovec - 2018 - Predicting multicellular function through multi-layer tissue networks.pdf:pdf},
number = {July},
pages = {190--198},
title = {{Predicting multicellular function through multi-layer tissue networks}},
year = {2018}
}
@article{Hamilton,
author = {Hamilton, William L and Ying, Rex},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hamilton, Ying - Unknown - Representation Learning on Graphs Methods and Applications.pdf:pdf},
pages = {1--23},
title = {{Representation Learning on Graphs : Methods and Applications}}
}
@article{Kipf2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1609.02907v4},
author = {Kipf, Thomas N and Welling, Max},
eprint = {arXiv:1609.02907v4},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kipf, Welling - 2017 - Semi-Supervised Classification with Graph Convolutional Networks.pdf:pdf},
pages = {1--14},
title = {{Semi-Supervised Classification with Graph Convolutional Networks}},
year = {2017}
}
@article{Hamilton2017,
author = {Hamilton, William L},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hamilton - 2017 - Inductive Representation Learning on Large Graphs.pdf:pdf},
number = {Nips},
pages = {1--11},
title = {{Inductive Representation Learning on Large Graphs}},
year = {2017}
}
@article{Brockschmidt2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1511.05493v4},
author = {Brockschmidt, Marc and Tarlow, Daniel},
eprint = {arXiv:1511.05493v4},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brockschmidt, Tarlow - 2016 - Gated Graph Sequence Neural Networks.pdf:pdf},
number = {1},
pages = {1--20},
title = {{Gated Graph Sequence Neural Networks}},
year = {2016}
}
@article{Learning2018,
author = {Learning, Representation},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Learning - 2018 - Part 2 Graph Neural Networks.pdf:pdf},
title = {{Part 2 : Graph Neural Networks}},
year = {2018}
}
@article{Wong2018,
author = {Wong, Serene W H and Kotlyar, Max and Faloutsos, Christos and Jurisica, Igor},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wong et al. - 2018 - SDREGION Fast Spoting of Changing Communities in Biological Networks.pdf:pdf},
isbn = {9781450355520},
keywords = {acm reference format,decreasing density subgraph detection,density subgraph detection,dynamic graphs,dynamic graphs, decreasing density subgraph detect,increasing,temporal data},
pages = {867--875},
title = {{SDREGION : Fast Spoting of Changing Communities in Biological Networks}},
year = {2018}
}
@article{Papalexakis2016,
author = {Papalexakis, Evangelos E and Faloutsos, Christos and Sidiropoulos, Nicholas D},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Papalexakis, Faloutsos, Sidiropoulos - 2016 - Tensors for Data Mining and Data Fusion Models , Applications , and Scalable Algorithms r.pdf:pdf},
number = {2},
title = {{Tensors for Data Mining and Data Fusion : Models , Applications , and Scalable Algorithms r r r}},
volume = {8},
year = {2016}
}
@article{Learning2018a,
author = {Learning, Representation},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Learning - 2018 - Part 1 Node Embeddings.pdf:pdf},
title = {{Part 1 : Node Embeddings}},
year = {2018}
}
@article{Learning2018b,
author = {Learning, Representation},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Learning - 2018 - Part 3 Applications.pdf:pdf},
title = {{Part 3 : Applications}},
year = {2018}
}
@article{Leskovec2018,
author = {Leskovec, Jure and Hamilton, William L and Ying, Rex and Sosic, Rok},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leskovec et al. - 2018 - on Networks Why networks Networks are a general.pdf:pdf},
title = {{on Networks Why networks ? Networks are a general}},
year = {2018}
}
@article{Cheng2018,
author = {Cheng, Justin and Kleinberg, Jon and Leskovec, Jure and Liben-nowell, David and State, Bogdan and Subbian, Karthik and Adamic, Lada},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheng et al. - 2018 - Do Diffusion Protocols Govern Cascade Growth.pdf:pdf},
title = {{Do Diffusion Protocols Govern Cascade Growth ?}},
year = {2018}
}
@article{Zitnik2018a,
author = {Zitnik, Marinka and Agrawal, Monica and Leskovec, Jure},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zitnik, Agrawal, Leskovec - 2018 - Modeling Polypharmacy Side Effects with Graph Convolutional Networks.pdf:pdf},
pages = {1--9},
title = {{Modeling Polypharmacy Side Effects with Graph Convolutional Networks}},
year = {2018}
}
@article{You2018,
author = {You, Jiaxuan and Ying, Rex and Ren, Xiang and Hamilton, William L and Leskovec, Jure},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/You et al. - 2018 - GraphRNN Generating Realistic Graphs with Deep Auto-regressive Models.pdf:pdf},
title = {{GraphRNN : Generating Realistic Graphs with Deep Auto-regressive Models}},
year = {2018}
}
@article{Biohub2018,
author = {Biohub, Chan Zuckerberg and Francisco, San},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Biohub, Francisco - 2018 - Large-scale analysis of disease pathways in the human interactome.pdf:pdf},
keywords = {disease pathways,disease protein discovery,protein-protein interaction networks},
pages = {111--122},
title = {{Large-scale analysis of disease pathways in the human interactome}},
year = {2018}
}
@article{Zitnik2017,
author = {Zitnik, Marinka and Leskovec, Jure},
doi = {10.1093/bioinformatics/btx252},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zitnik, Leskovec - 2017 - Predicting multicellular function through multi-layer tissue networks.pdf:pdf},
number = {2},
pages = {190--198},
title = {{Predicting multicellular function through multi-layer tissue networks}},
year = {2017}
}
@article{Mirzasoleiman,
author = {Mirzasoleiman, Baharan and Krause, Andreas},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mirzasoleiman, Krause - Unknown - Distributed Submodular Cover Succinctly Summarizing Massive Data.pdf:pdf},
pages = {1--9},
title = {{Distributed Submodular Cover : Succinctly Summarizing Massive Data}}
}
@article{Zitnik2018b,
author = {Zitnik, Marinka and Sosi, Rok and Leskovec, Jure},
doi = {10.1038/s41467-018-04948-5},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zitnik, Sosi, Leskovec - 2018 - Prioritizing network communities.pdf:pdf},
journal = {Nature Communications},
number = {2018},
pages = {1--9},
title = {{Prioritizing network communities}},
year = {2018}
}
@article{Tabei2016,
author = {Tabei, Yasuo and Puglisi, Simon J},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tabei, Puglisi - 2016 - Scalable Partial Least Squares Regression on Grammar-Compressed Data Matrices.pdf:pdf},
isbn = {9781450342322},
title = {{Scalable Partial Least Squares Regression on Grammar-Compressed Data Matrices}},
year = {2016}
}
@article{Prezza2018a,
author = {Prezza, Nicola},
doi = {10.1137/1.9781611975031.98},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prezza - 2018 - In-Place Sparse Suffix Sorting.pdf:pdf},
isbn = {9781611975031},
journal = {Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms},
pages = {1496--1508},
title = {{In-Place Sparse Suffix Sorting}},
url = {http://epubs.siam.org/doi/10.1137/1.9781611975031.98},
year = {2018}
}
@inproceedings{Ene,
archivePrefix = {arXiv},
arxivId = {arXiv:1804.05379v1},
author = {Ene, Alina and Nguyen, Huy L},
booktitle = {ACM-SIAM Symposium on Discrete Algorithms (SODA)},
eprint = {arXiv:1804.05379v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ene, Nguyen - 2019 - Submodular Maximization with Nearly-optimal Approximation and Adaptivity in Nearly-linear Time.pdf:pdf},
title = {{Submodular Maximization with Nearly-optimal Approximation and Adaptivity in Nearly-linear Time}},
year = {2019}
}
@inproceedings{Balkanski,
archivePrefix = {arXiv},
arxivId = {arXiv:1804.06355v1},
author = {Balkanski, Eric and Rubinstein, Aviad and Singer, Yaron},
booktitle = {ACM-SIAM Symposium on Discrete Algorithms (SODA)},
eprint = {arXiv:1804.06355v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balkanski, Rubinstein, Singer - 2019 - An Exponential Speedup in Parallel Running Time for Submodular Maximization without Loss in Appro.pdf:pdf},
title = {{An Exponential Speedup in Parallel Running Time for Submodular Maximization without Loss in Approximation}},
year = {2019}
}
@article{Hassidim2017,
abstract = {In this paper we analyze the robustness of stochastic variants of the greedy algorithm for submodular maximization. Our main result shows that for maximizing a monotone submodular function under a cardinality constraint, iteratively selecting an element whose marginal contribution is approximately maximal in expectation is a sufficient condition to obtain the optimal approximation guarantee with exponentially high probability, assuming the cardinality is sufficiently large. One consequence of our result is that the linear-time STOCHASTIC-GREEDY algorithm recently proposed in (Mirzasoleiman et al.,2015) achieves the optimal running time while maintaining an optimal approximation guarantee. We also show that high probability guarantees cannot be obtained for stochastic greedy algorithms under matroid constraints, and prove an approximation guarantee which holds in expectation. In contrast to the guarantees of the greedy algorithm, we show that the approximation ratio of stochastic local search is arbitrarily bad, with high probability, as well as in expectation.},
author = {Hassidim, Avinatan and Singer, Yaron},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hassidim, Singer - 2017 - Robust Guarantees of Stochastic Greedy Algorithms.pdf:pdf},
isbn = {9781510855144},
journal = {International Conference on Machine Learning (ICML)},
title = {{Robust Guarantees of Stochastic Greedy Algorithms}},
url = {http://proceedings.mlr.press/v70/hassidim17a.html},
year = {2017}
}
@article{Qian,
author = {Qian, Chao and Li, Guiying and Feng, Chao and Tang, Ke},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qian et al. - Unknown - Distributed Pareto Optimization for Subset Selection.pdf:pdf},
title = {{Distributed Pareto Optimization for Subset Selection}}
}
@article{Qian2016,
author = {Qian, Chao and Feng, Chao and Tang, Ke},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qian, Feng, Tang - 2016 - Sequence Selection by Pareto Optimization.pdf:pdf},
title = {{Sequence Selection by Pareto Optimization}},
year = {2016}
}
@article{Kuhnled,
author = {Kuhnle, Alan},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhnle - Unknown - Ideas for nonsubmodularity and curvature on the integer lattice.pdf:pdf},
pages = {1--3},
title = {{Ideas for nonsubmodularity and curvature on the integer lattice}}
}
@article{Crawford2018,
abstract = {The de Bruijn graph is fundamental to the analysis of next generation sequencing data and so, as datasets of DNA reads grow rapidly, it becomes more important to represent de Bruijn graphs compactly while still supporting fast assembly. Previous implementations of compact de Bruijn graphs have not supported node or edge deletion, however, which is important for pruning spurious elements from the graph.},
author = {Crawford, Victoria and Kuhnle, Alan and Boucher, Christina and Chikhi, Rayan and Gagie, Travis},
doi = {10.1093/bioinformatics/bty500},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Crawford et al. - 2018 - Practical Dynamic de Bruijn Graphs.pdf:pdf},
journal = {Bioinformatics},
title = {{Practical Dynamic de Bruijn Graphs}},
url = {http://doi.org/10.1093/bioinformatics/bty500},
year = {2018}
}
@article{Kuhnle2018b,
author = {Kuhnle, Alan and Crawford, Victoria G and Thai, My T},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhnle, Crawford, Thai - 2018 - Network Resilience and the Length-Bounded Multicut Problem Reaching the Dynamic Billion-Scale with Guara.pdf:pdf},
journal = {Proc. ACM Meas. Anal. Comput. Syst.},
keywords = {Scalable algorithms,length-bounded multicut},
number = {1},
title = {{Network Resilience and the Length-Bounded Multicut Problem: Reaching the Dynamic Billion-Scale with Guarantees}},
volume = {2},
year = {2018}
}
@inproceedings{Balkanski2018,
author = {Balkanski, Eric and Singer, Yaron},
booktitle = {ACM SIGACT Symposium on Theory of Computing (STOC)},
doi = {10.1145/3188745.3188752},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balkanski, Singer - 2018 - The adaptive complexity of maximizing a submodular function.pdf:pdf},
isbn = {9781450355599},
title = {{The adaptive complexity of maximizing a submodular function}},
year = {2018}
}
@article{Qian2017a,
abstract = {Subset selection is a fundamental problem in many areas, which aims to select the best subset of size at most k from a universe. Greedy algorithms are widely used for subset selection, and have shown good approximation performances in deterministic situations. However, their behaviors are stochas-tic in many realistic situations (e.g., large-scale and noisy). For general stochastic greedy algo-rithms, bounded approximation guarantees were obtained only for subset selection with monotone submodular objective functions, while real-world applications often involve non-monotone or non-submodular objective functions and can be subject to a more general constraint than a size constraint. This work proves their approximation guarantees in these cases, and thus largely extends the applicabil-ity of stochastic greedy algorithms.},
author = {Qian, Chao and Yu, Yang and Tang, Ke},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qian, Yu, Tang - 2017 - Approximation Guarantees of Stochastic Greedy Algorithms for Subset Selection.pdf:pdf},
keywords = {Heuristic Search and Game Playing: Combinatorial S,Heuristic Search and Game Playing: Heuristic Searc},
title = {{Approximation Guarantees of Stochastic Greedy Algorithms for Subset Selection}},
url = {https://www.ijcai.org/proceedings/2018/0205.pdf},
year = {2017}
}
@inproceedings{Kuhnle2018a,
abstract = {The optimization of submodular functions on the integer lattice has received much attention recently, but the objective functions of many applications are non-submodular. We provide two approximation algorithms for maximizing a non-submodular function on the integer lattice subject to a cardinality constraint; these are the first algorithms for this purpose that have polynomial query complexity. We propose a general framework for influence maximization on the integer lattice that generalizes prior works on this topic, and we demonstrate the efficiency of our algorithms in this context.},
archivePrefix = {arXiv},
arxivId = {1805.06990},
author = {Kuhnle, Alan and Smith, J. David and Crawford, Victoria G. and Thai, My T.},
booktitle = {International Conference on Machine Learning (ICML)},
eprint = {1805.06990},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhnle et al. - 2018 - Fast Maximization of Non-Submodular, Monotonic Functions on the Integer Lattice.pdf:pdf},
title = {{Fast Maximization of Non-Submodular, Monotonic Functions on the Integer Lattice}},
url = {http://arxiv.org/abs/1805.06990},
year = {2018}
}
@article{Bhattacharya2017,
abstract = {We consider the problem of maintaining an approximately maximum (fractional) matching and an approximately minimum vertex cover in a dynamic graph. Starting with the seminal paper by Onak and Rubinfeld [STOC 2010], this problem has received significant attention in recent years. There remains, however, a polynomial gap between the best known worst case update time and the best known amortised update time for this problem, even after allowing for randomisation. Specifically, Bernstein and Stein [ICALP 2015, SODA 2016] have the best known worst case update time. They present a deterministic data structure with approximation ratio $(3/2+\epsilon)$ and worst case update time $O(m^{1/4}/\epsilon^2)$, where $m$ is the number of edges in the graph. In recent past, Gupta and Peng [FOCS 2013] gave a deterministic data structure with approximation ratio $(1+\epsilon)$ and worst case update time $O(\sqrt{m}/\epsilon^2)$. No known randomised data structure beats the worst case update times of these two results. In contrast, the paper by Onak and Rubinfeld [STOC 2010] gave a randomised data structure with approximation ratio $O(1)$ and amortised update time $O(\log^2 n)$, where $n$ is the number of nodes in the graph. This was later improved by Baswana, Gupta and Sen [FOCS 2011] and Solomon [FOCS 2016], leading to a randomised date structure with approximation ratio $2$ and amortised update time $O(1)$. We bridge the polynomial gap between the worst case and amortised update times for this problem, without using any randomisation. We present a deterministic data structure with approximation ratio $(2+\epsilon)$ and worst case update time $O(\log^3 n)$, for all sufficiently small constants $\epsilon$.},
archivePrefix = {arXiv},
arxivId = {1704.02844},
author = {Bhattacharya, Sayan},
doi = {10.1137/1.9781611974782.30},
eprint = {1704.02844},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhattacharya - 2017 - Fully Dynamic Approximate Maximum Matching and Minimum Vertex Cover in O ( log 3 n ) Worst Case Update Time.pdf:pdf},
isbn = {9781611974782},
journal = {Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA'17)},
number = {340506},
pages = {470--489},
title = {{Fully Dynamic Approximate Maximum Matching and Minimum Vertex Cover in O ( log 3 n ) Worst Case Update Time}},
url = {http://arxiv.org/abs/1704.02844},
year = {2017}
}
@inproceedings{Gupta2017,
abstract = {In this paper, we study the set cover problem in the fully dynamic model. In this model, the set of active elements, i.e., those that must be covered at any given time, can change due to element arrivals and departures. The goal is to maintain an algorithmic solution that is competitive with respect to the current optimal solution. This model is popular in both the dynamic algorithms and online algorithms communities. The difference is in the restriction placed on the algorithm: in dynamic algorithms, the running time of the algorithm making updates (called update time) is bounded, while in online algorithms, the number of updates made to the solution (called recourse) is limited. In this paper we show the following results: In the update time setting, we obtain O(log n)-competitiveness with O(f log n) amortized update time, and O(f^3)-competitiveness with O(f^2) update time. The O(log n)-competitive algorithm is the first one to achieve a competitive ratio independent of f in this setting. In the recourse setting, we show a competitive ratio of O(min{log n,f}) with constant amortized recourse. Note that this matches the best offline bounds with just constant recourse, something that is impossible in the classical online model. Our results are based on two algorithmic frameworks in the fully-dynamic model that are inspired by the classic greedy and primal-dual algorithms for offline set cover. We show that both frameworks can be used for obtaining both recourse and update time bounds, thereby demonstrating algorithmic techniques common to these strands of research.},
archivePrefix = {arXiv},
arxivId = {1611.05646},
author = {Gupta, Anupam and Krishnaswamy, Ravishankar and Kumar, Amit and Panigrahi, Debmalya},
booktitle = {Symposium on the Theory of Computing (STOC)},
doi = {10.1145/3055399.3055493},
eprint = {1611.05646},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta et al. - 2017 - Online and Dynamic Algorithms for Set Cover.pdf:pdf},
isbn = {9781450345286},
issn = {07378017},
keywords = {acm reference format,algorithms,competitive ratio,dynamic algorithms,graph matching,hypergraph matching,online,recourse,set cover,vertex cover},
pages = {537--550},
title = {{Online and Dynamic Algorithms for Set Cover}},
url = {http://arxiv.org/abs/1611.05646},
year = {2017}
}
@article{Laber1992,
author = {Laber, Eduardo S and Molinaro, Marco and Mello, Felipe De A},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laber, Molinaro, Mello - 1992 - Binary Partitions with Approximate Minimum Impurity.pdf:pdf},
title = {{Binary Partitions with Approximate Minimum Impurity}},
year = {1992}
}
@article{Bhattacharya2015,
abstract = {We develop a dynamic version of the primal-dual method for optimization problems, and apply it to obtain the following results. (1) For the dynamic set-cover problem, we maintain an $O(f^2)$-approximately optimal solution in $O(f \cdot \log (m+n))$ amortized update time, where $f$ is the maximum "frequency" of an element, $n$ is the number of sets, and $m$ is the maximum number of elements in the universe at any point in time. (2) For the dynamic $b$-matching problem, we maintain an $O(1)$-approximately optimal solution in $O(\log^3 n)$ amortized update time, where $n$ is the number of nodes in the graph.},
archivePrefix = {arXiv},
arxivId = {1604.05337},
author = {Bhattacharya, Sayan and Henzinger, Monika and Italiano, Giuseppe F.},
doi = {10.1007/978-3-662-47672-7_17},
eprint = {1604.05337},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhattacharya, Henzinger, Italiano - 2015 - Design of dynamic algorithms via primal-dual method.pdf:pdf},
isbn = {9783662476710},
issn = {16113349},
journal = {International Colloquium on Automata, Languages, and Programming (Lecture Notes in Computer Science)},
pages = {206--218},
title = {{Design of dynamic algorithms via primal-dual method}},
volume = {9134},
year = {2015}
}
@article{Agrawal2018,
author = {Agrawal, Shipra and Mirrokni, Vahab and Zadimoghaddam, Morteza},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Agrawal, Mirrokni, Zadimoghaddam - 2018 - Proportional Allocation Simple , Distributed , and Diverse Matching with High Entropy.pdf:pdf},
keywords = {Machine Learning, ICML},
title = {{Proportional Allocation : Simple , Distributed , and Diverse Matching with High Entropy}},
year = {2018}
}
@article{Rosenfeld2018,
abstract = {Submodular functions have become a ubiquitous tool in machine learning. They are learnable from data, and can be optimized efficiently and with guarantees. Nonetheless, recent negative results show that optimizing learned surrogates of submodular functions can result in arbitrarily bad approximations of the true optimum. Our goal in this paper is to highlight the source of this hardness, and propose an alternative criterion for optimizing general combinatorial functions from sampled data. We prove a tight equivalence showing that a class of functions is optimizable if and only if it can be learned. We provide efficient and scalable optimization algorithms for several function classes of interest, and demonstrate their utility on the task of optimally choosing trending social media items.},
author = {Rosenfeld, Nir and Balkanski, Eric and Globerson, Amir and Singer, Yaron},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rosenfeld et al. - 2018 - Learning to Optimize Combinatorial Functions.pdf:pdf},
number = {1},
title = {{Learning to Optimize Combinatorial Functions}},
year = {2018}
}
@inproceedings{Mitrovic2018,
abstract = {The sheer scale of modern datasets has resulted in a dire need for summarization techniques that identify representative elements in a dataset. Fortunately, the vast majority of data summarization tasks satisfy an intuitive diminishing returns condition known as submodularity, which allows us to find nearly-optimal solutions in linear time. We focus on a two-stage submodular framework where the goal is to use some given training functions to reduce the ground set so that optimizing new functions (drawn from the same distribution) over the reduced set provides almost as much value as optimizing them over the entire ground set. In this paper, we develop the first streaming and distributed solutions to this problem. In addition to providing strong theoretical guarantees, we demonstrate both the utility and efficiency of our algorithms on real-world tasks including image summarization and ride-share optimization.},
archivePrefix = {arXiv},
arxivId = {1806.02815},
author = {Mitrovic, Marko and Kazemi, Ehsan and Zadimoghaddam, Morteza and Karbasi, Amin},
booktitle = {International Conference on Machine Learning (ICML)},
eprint = {1806.02815},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitrovic et al. - 2018 - Data Summarization at Scale A Two-Stage Submodular Approach.pdf:pdf},
title = {{Data Summarization at Scale: A Two-Stage Submodular Approach}},
url = {http://arxiv.org/abs/1806.02815},
year = {2018}
}
@article{Liu2012,
abstract = {Many graphs in practical applications are not deterministic, but are probabilistic in nature because the existence of the edges is inferred with the use of a variety of statistical approaches. In this paper, we will examine the problem of clustering uncertain graphs. Uncertain graphs are best clustered with the use of a possible worlds model in which the most reliable clusters are discovered in the presence of uncertainty. Reliable clusters are those which are not likely to be disconnected in the context of different instantiations of the uncertain graph. We present experimental results which illustrate the effectiveness of our model and approach.},
author = {Liu, Lin and Jin, Ruoming and Aggarwal, Charu and Shen, Yelong},
doi = {10.1109/ICDM.2012.11},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2012 - Reliable clustering on uncertain graphs.pdf:pdf},
isbn = {9780769549057},
issn = {15504786},
journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
keywords = {Clustering,Reliability,Uncertain graph},
pages = {459--468},
title = {{Reliable clustering on uncertain graphs}},
year = {2012}
}
@article{Zaki2013,
abstract = {BACKGROUND: Predicting protein complexes from protein-protein interaction data is becoming a fundamental problem in computational biology. The identification and characterization of protein complexes implicated are crucial to the understanding of the molecular events under normal and abnormal physiological conditions. On the other hand, large datasets of experimentally detected protein-protein interactions were determined using High-throughput experimental techniques. However, experimental data is usually liable to contain a large number of spurious interactions. Therefore, it is essential to validate these interactions before exploiting them to predict protein complexes.\n\nRESULTS: In this paper, we propose a novel graph mining algorithm (PEWCC) to identify such protein complexes. Firstly, the algorithm assesses the reliability of the interaction data, then predicts protein complexes based on the concept of weighted clustering coefficient. To demonstrate the effectiveness of the proposed method, the performance of PEWCC was compared to several methods. PEWCC was able to detect more matched complexes than any of the state-of-the-art methods with higher quality scores.\n\nCONCLUSIONS: The higher accuracy achieved by PEWCC in detecting protein complexes is a valid argument in favor of the proposed method. The datasets and programs are freely available at http://faculty.uaeu.ac.ae/nzaki/Research.htm.},
author = {Zaki, Nazar and Efimov, Dmitry and Berengueres, Jose},
doi = {10.1186/1471-2105-14-163},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zaki, Efimov, Berengueres - 2013 - Protein complex detection using interaction reliability assessment and weighted clustering coefficien.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
number = {1},
pages = {1--9},
pmid = {23688127},
title = {{Protein complex detection using interaction reliability assessment and weighted clustering coefficient}},
volume = {14},
year = {2013}
}
@inproceedings{Chen2017,
abstract = {Submodular functions are a broad class of set functions, which naturally arise in diverse areas. Many algorithms have been suggested for the maximization of these functions. Unfortunately, once the function deviates from submodularity, the known algorithms may perform arbitrarily poorly. Amending this issue, by obtaining approximation results for set functions generalizing submodular functions, has been the focus of recent works. One such class, known as weakly submodular functions, has received a lot of attention. A key result proved by Das and Kempe (2011) showed that the approximation ratio of the greedy algorithm for weakly submodular maximization subject to a cardinality constraint degrades smoothly with the distance from submodularity. However, no results have been obtained for maximization subject to constraints beyond cardinality. In particular, it is not known whether the greedy algorithm achieves any non-trivial approximation ratio for such constraints. In this paper, we prove that a randomized version of the greedy algorithm (previously used by Buchbinder et al. (2014) for a different problem) achieves an approximation ratio of $(1 + 1/\gamma)^{-2}$ for the maximization of a weakly submodular function subject to a general matroid constraint, where $\gamma$ is a parameter measuring the distance of the function from submodularity. Moreover, we also experimentally compare the performance of this version of the greedy algorithm on real world problems against natural benchmarks, and show that the algorithm we study performs well also in practice. To the best of our knowledge, this is the first algorithm with a non-trivial approximation guarantee for maximizing a weakly submodular function subject to a constraint other than the simple cardinality constraint. In particular, it is the first algorithm with such a guarantee for the important and broad class of matroid constraints.},
archivePrefix = {arXiv},
arxivId = {1707.04347},
author = {Chen, Lin and Feldman, Moran and Karbasi, Amin},
booktitle = {International Conference on Machine Learning (ICML)},
eprint = {1707.04347},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Feldman, Karbasi - 2018 - Weakly Submodular Maximization Beyond Cardinality Constraints Does Randomization Help Greedy.pdf:pdf},
title = {{Weakly Submodular Maximization Beyond Cardinality Constraints: Does Randomization Help Greedy?}},
url = {http://arxiv.org/abs/1707.04347},
year = {2018}
}
@article{Koriche,
author = {Koriche, Frederic},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koriche - Unknown - Compiling Combinatorial Prediction Games.pdf:pdf},
title = {{Compiling Combinatorial Prediction Games}}
}
@article{Bhaskara2018,
author = {Bhaskara, Aditya and Wijewardena, Maheshakya},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhaskara, Wijewardena - 2018 - Distributed Clustering via LSH Based Data Partitioning.pdf:pdf},
title = {{Distributed Clustering via LSH Based Data Partitioning}},
year = {2018}
}
@article{Balkanski2018a,
abstract = {In this paper we analyze an adaptive sampling approach for submodular maximization. Adap-tive sampling is a technique that has recently been shown to achieve a constant factor approximation guarantee for submodular maximization under a cardinality constraint with exponentially fewer adaptive rounds than any previously studied con-stant factor approximation algorithm for this prob-lem. Adaptivity quantifies the number of sequen-tial rounds that an algorithm makes when function evaluations can be executed in parallel and is the parallel running time of an algorithm, up to low order terms. Adaptive sampling achieves its expo-nential speedup at the expense of approximation. In theory, it is guaranteed to produce a solution that is a 1/3 approximation to the optimum. Nev-ertheless, experiments show that adaptive sam-pling techniques achieve far better values in prac-tice. In this paper we provide theoretical justifica-tion for this phenomenon. In particular, we show that under very mild conditions of curvature of a function, adaptive sampling techniques achieve an approximation arbitrarily close to 1/2 while maintaining their low adaptivity. Furthermore, we show that the approximation ratio approaches 1 in direct relationship to a homogeneity property of the submodular function. In addition, we con-duct experiments on real data sets in which the curvature and homogeneity properties can be eas-ily manipulated and demonstrate the relationship between approximation and curvature, as well as the effectiveness of adaptive sampling in practice.},
author = {Balkanski, Eric and Singer, Yaron},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balkanski, Singer - 2018 - Approximation Guarantees for Adaptive Sampling.pdf:pdf},
title = {{Approximation Guarantees for Adaptive Sampling}},
url = {https://scholar.harvard.edu/files/ericbalkanski/files/approximation-guarantees-for-adaptive-sampling.pdf},
year = {2018}
}
@article{Andreas2018,
author = {Andreas, Jan-hendrik Lange and Bjoern, Karrenbauer},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andreas, Bjoern - 2018 - Partial Optimality and Fast Lower Bounds for Weighted Correlation Clustering.pdf:pdf},
number = {1989},
title = {{Partial Optimality and Fast Lower Bounds for Weighted Correlation Clustering}},
year = {2018}
}
@article{Mokhtari2018,
abstract = {In this paper, we showcase the interplay between discrete and continuous optimization in network-structured settings. We propose the first fully decentralized optimization method for a wide class of non-convex objective functions that possess a diminishing returns property. More specifically, given an arbitrary connected network and a global continuous submodular function, formed by a sum of local functions, we develop Decentralized Continuous Greedy (DCG), a message passing algorithm that converges to the tight (1-1/e) approximation factor of the optimum global solution using only local computation and communication. We also provide strong convergence bounds as a function of network size and spectral characteristics of the underlying topology. Interestingly, DCG readily provides a simple recipe for decentralized discrete submodular maximization through the means of continuous relaxations. Formally, we demonstrate that by lifting the local discrete functions to continuous domains and using DCG as an interface we can develop a consensus algorithm that also achieves the tight (1-1/e) approximation guarantee of the global discrete solution once a proper rounding scheme is applied.},
archivePrefix = {arXiv},
arxivId = {1802.03825},
author = {Mokhtari, Aryan and Hassani, Hamed and Karbasi, Amin},
eprint = {1802.03825},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mokhtari, Hassani, Karbasi - 2018 - Decentralized Submodular Maximization Bridging Discrete and Continuous Settings.pdf:pdf},
title = {{Decentralized Submodular Maximization: Bridging Discrete and Continuous Settings}},
url = {http://arxiv.org/abs/1802.03825},
year = {2018}
}
@article{Mehrabi2018,
abstract = {<p>The approximation power of general feedforward neural networks with piecewise
linear activation functions is investigated. First, lower bounds on the size of
a network are established in terms of the approximation error and network depth
and width. These bounds improve upon state-of-the-art bounds for certain
classes of functions, such as strongly convex functions. Second, an upper bound
is established on the difference of two neural networks with identical weights
but different activation functions.
</p>},
archivePrefix = {arXiv},
arxivId = {arXiv:1806.11416v1},
author = {Mehrabi, Mohammad and Tchamkerten, Aslan and Yousefi, Mansoor I},
doi = {arXiv:1806.11416v1},
eprint = {arXiv:1806.11416v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mehrabi, Tchamkerten, Yousefi - 2018 - Bounds on the Approximation Power of Feedforward Neural Networks.pdf:pdf},
journal = {arXiv Information Theory (cs.IT)},
title = {{Bounds on the Approximation Power of Feedforward Neural Networks.}},
url = {http://arxiv.org/abs/1806.11416},
year = {2018}
}
@article{Balcan2018,
abstract = {Tree search algorithms, such as branch-and-bound, are the most widely used tools for solving combinatorial and nonconvex problems. For example, they are the foremost method for solving (mixed) integer programs and constraint satisfaction problems. Tree search algorithms recursively partition the search space to find an optimal solution. In order to keep the tree size small, it is crucial to carefully decide, when expanding a tree node, which question (typically variable) to branch on at that node in order to partition the remaining space. Numerous partitioning techniques (e.g., variable selection) have been proposed, but there is no theory describing which technique is optimal. We show how to use machine learning to determine an optimal weighting of any set of partitioning procedures for the instance distribution at hand using samples from the distribution. We provide the first sample complexity guarantees for tree search algorithm configuration. These guarantees bound the number of samples sufficient to ensure that the empirical performance of an algorithm over the samples nearly matches its expected performance on the unknown instance distribution. This thorough theoretical investigation naturally gives rise to our learning algorithm. Via experiments, we show that learning an optimal weighting of partitioning procedures can dramatically reduce tree size, and we prove that this reduction can even be exponential. Through theory and experiments, we show that learning to branch is both practical and hugely beneficial.},
archivePrefix = {arXiv},
arxivId = {1803.10150},
author = {Balcan, Maria-Florina and Dick, Travis and Sandholm, Tuomas and Vitercik, Ellen},
eprint = {1803.10150},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balcan et al. - 2018 - Learning to Branch.pdf:pdf},
title = {{Learning to Branch}},
url = {http://arxiv.org/abs/1803.10150},
year = {2018}
}
@article{Cotter2018,
author = {Cotter, Andrew and Milani, Mahdi and Seungil, Fard and Maya, You and Jeff, Gupta},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cotter et al. - 2018 - Constrained Interacting Submodular Groupings.pdf:pdf},
title = {{Constrained Interacting Submodular Groupings}},
year = {2018}
}
@article{Lykouris2018,
abstract = {Traditional online algorithms encapsulate decision making under uncertainty, and give ways to hedge against all possible future events, while guaranteeing a nearly optimal solution as compared to an offline optimum. On the other hand, machine learning algorithms are in the business of extrapolating patterns found in the data to predict the future, and usually come with strong guarantees on the expected generalization error. In this work we develop a framework for augmenting online algorithms with a machine learned oracle to achieve competitive ratios that provably improve upon unconditional worst case lower bounds when the oracle has low error. Our approach treats the oracle as a complete black box, and is not dependent on its inner workings, or the exact distribution of its errors. We apply this framework to the traditional caching problem -- creating an eviction strategy for a cache of size $k$. We demonstrate that naively following the oracle's recommendations may lead to very poor performance, even when the average error is quite low. Instead we show how to modify the Marker algorithm to take into account the oracle's predictions, and prove that this combined approach achieves a competitive ratio that both (i) decreases as the oracle's error decreases, and (ii) is always capped by $O(\log k)$, which can be achieved without any oracle input. We complement our results with an empirical evaluation of our algorithm on real world datasets, and show that it performs well empirically even using simple off-the-shelf predictions.},
archivePrefix = {arXiv},
arxivId = {1802.05399},
author = {Lykouris, Thodoris and Vassilvitskii, Sergei},
eprint = {1802.05399},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lykouris, Vassilvitskii - 2018 - Competitive caching with machine learned advice.pdf:pdf},
title = {{Competitive caching with machine learned advice}},
url = {http://arxiv.org/abs/1802.05399},
year = {2018}
}
@inproceedings{Jakub2018,
abstract = {Many tasks in machine learning and data mining, such as data diversification, non-parametric learning, kernel machines, clustering etc., require extracting a small but representative summary from a massive dataset. Often, such problems can be posed as maximizing a submodular set function subject to a cardinality constraint. We consider this question in the streaming setting, where elements arrive over time at a fast pace and thus we need to design an efficient, lowmemory algorithm. One such method, proposed by Badanidiyuru et al. (2014), always finds a 0.5-approximate solution. Can this approximation factor be improved? We answer this question affirmatively by designing a new algorithm Salsa for streaming submodular maximization. It is the first low-memory, single-pass algorithm that improves the factor 0.5, under the natural assumption that elements arrive in a random order. We also show that this assumption is necessary, i.e., that there is no such algorithm with better than 0.5-approximation when elements arrive in arbitrary order. Our experiments demonstrate that salsa significantly outperforms the stale of the art in applications related to exemplar-based clustering, social graph analysis, and recommender systems.},
author = {Norouzi-Fard, Ashkan and Tarnawski, Jakub and Mitrovic, Slobodan and Zandieh, Amir and Mousavifar, Aidasadat and Svensson, Ola},
booktitle = {International Conference on Machine Learning (ICML)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Norouzi-Fard et al. - 2018 - Beyond 12-Approximation for Submodular Maximization on Massive Data Streams.pdf:pdf},
isbn = {9781510867963},
title = {{Beyond 1/2-Approximation for Submodular Maximization on Massive Data Streams}},
volume = {9},
year = {2018}
}
@article{Kazemi2018,
author = {Kazemi, Ehsan and Zadimoghaddam, Morteza and Karbasi, Amin},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kazemi, Zadimoghaddam, Karbasi - 2018 - Scalable Deletion-Robust Submodular Maximization Data Summarization with Privacy and Fairness C.pdf:pdf},
title = {{Scalable Deletion-Robust Submodular Maximization : Data Summarization with Privacy and Fairness Constraints}},
year = {2018}
}
@article{Bai2018,
abstract = {We analyze the performance of the greedy algorithm, and also a discrete semi-gradient based algorithm, for maximizing the sum of a suBmodular and suPermodular (BP) function (both of which are non-negative monotone non-decreasing) under two types of constraints, either a cardinality constraint or $p\geq 1$ matroid independence constraints. These problems occur naturally in several real-world applications in data science, machine learning, and artificial intelligence. The problems are ordinarily inapproximable to any factor (as we show). Using the curvature $\kappa_f$ of the submodular term, and introducing $\kappa^g$ for the supermodular term (a natural dual curvature for supermodular functions), however, both of which are computable in linear time, we show that BP maximization can be efficiently approximated by both the greedy and the semi-gradient based algorithm. The algorithms yield multiplicative guarantees of $\frac{1}{\kappa_f}\left[1-e^{-(1-\kappa^g)\kappa_f}\right]$ and $\frac{1-\kappa^g}{(1-\kappa^g)\kappa_f + p}$ for the two types of constraints respectively. For pure monotone supermodular constrained maximization, these yield $1-\kappa^g$ and $(1-\kappa^g)/p$ for the two types of constraints respectively. We also analyze the hardness of BP maximization and show that our guarantees match hardness by a constant factor and by $O(\ln(p))$ respectively. Computational experiments are also provided supporting our analysis.},
archivePrefix = {arXiv},
arxivId = {1801.07413},
author = {Bai, Wenruo and Bilmes, Jeffrey A.},
eprint = {1801.07413},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bai, Bilmes - 2018 - Greed is Still Good Maximizing Monotone SubmodularSupermodular Functions.pdf:pdf},
title = {{Greed is Still Good: Maximizing Monotone Submodular+Supermodular Functions}},
url = {http://arxiv.org/abs/1801.07413},
year = {2018}
}
@article{Narisada,
author = {Narisada, Shintaro and Hendrian, Diptarama and Yoshinaka, Ryo and Shinohara, Ayumi},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Narisada et al. - Unknown - Linear-Time Online Algorithm Inferring the Shortest Path from a Walk.pdf:pdf},
keywords = {graph inference,palindrome,walk},
number = {Table 1},
pages = {1--18},
title = {{Linear-Time Online Algorithm Inferring the Shortest Path from a Walk}}
}
@article{Algorithms2017a,
author = {Algorithms, Approximation and Analysis, Concentration and Approximation, Average},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Algorithms, Analysis, Approximation - 2017 - Cyber-epidemics in Billion-scale Networks Optimal Interdiction via Cutting a Few Edges(2).pdf:pdf},
keywords = {approximation algorithms,average approximation,concentration analysis,cyber-epidemics,optimization,sample},
pages = {1--32},
title = {{Cyber-epidemics in Billion-scale Networks : Optimal Interdiction via Cutting a Few Edges}},
year = {2017}
}
@article{Hoffmann2017,
abstract = {Motivated by the study of controlling (curing) epidemics, we consider the spread of an SI process on a known graph, where we have a limited budget to use to transition infected nodes back to the susceptible state (i.e., to cure nodes). Recent work has demonstrated that under perfect information (which nodes are/are not infected), the budget required for curing a graph precisely depends on its CutWidth. We develop a model for observation uncertainty, and show that even a minor degradation in the assumption of perfect knowledge of the state of the infection drastically alters the landscape -- infections that could previously be cured in sublinear time, now may require exponential time to cure. Our main result characterizes the necessary curing budget required as a function of the per-node observation uncertainty.},
archivePrefix = {arXiv},
arxivId = {1711.00167},
author = {Hoffmann, Jessica},
eprint = {1711.00167},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoffmann - 2017 - The Cost of Uncertainty in Curing Epidemics.pdf:pdf},
journal = {arXiv:1711.00167 [cs]},
number = {1},
pages = {1--35},
title = {{The Cost of Uncertainty in Curing Epidemics}},
url = {http://arxiv.org/abs/1711.00167},
year = {2017}
}
@article{Drakopoulos2014,
abstract = {We provide a dynamic policy for the rapid containment of a contagion process modeled as an SIS epidemic on a bounded degree undirected graph with     nodes. We show that if the budget     of curing resources available at each time is    , where     is the CutWidth of the graph, and also of order    , then the expected time until the extinction of the epidemic is of order   , which is within a constant factor from optimal, as well as sublinear in the number of nodes. Furthermore, if the CutWidth increases only sublinearly with    , a sublinear expected time to extinction is possible with a sublinearly increasing budget   .},
archivePrefix = {arXiv},
arxivId = {arXiv:1407.2241v1},
author = {Drakopoulos, Kimon and Ozdaglar, Asuman and Tsitsiklis, John},
doi = {10.1109/CDC.2014.7040083},
eprint = {arXiv:1407.2241v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Drakopoulos, Ozdaglar, Tsitsiklis - 2014 - An efficient curing policy for epidemics on graphs.pdf:pdf},
isbn = {9781467360883},
issn = {07431546},
journal = {Proceedings of the IEEE Conference on Decision and Control},
number = {February},
pages = {4447--4454},
title = {{An efficient curing policy for epidemics on graphs}},
volume = {2015-Febru},
year = {2014}
}
@article{Liang2018,
author = {Liang, Qingkai and Modiano, Eytan},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang, Modiano - 2018 - Minimizing Queue Length Regret Under Adversarial Network Models.pdf:pdf},
number = {1},
title = {{Minimizing Queue Length Regret Under Adversarial Network Models}},
volume = {2},
year = {2018}
}
@article{Rabinowitz2018,
abstract = {Theory of mind (ToM; Premack & Woodruff, 1978) broadly refers to humans' ability to represent the mental states of others, including their desires, beliefs, and intentions. We propose to train a machine to build such models too. We design a Theory of Mind neural network -- a ToMnet -- which uses meta-learning to build models of the agents it encounters, from observations of their behaviour alone. Through this process, it acquires a strong prior model for agents' behaviour, as well as the ability to bootstrap to richer predictions about agents' characteristics and mental states using only a small number of behavioural observations. We apply the ToMnet to agents behaving in simple gridworld environments, showing that it learns to model random, algorithmic, and deep reinforcement learning agents from varied populations, and that it passes classic ToM tasks such as the "Sally-Anne" test (Wimmer & Perner, 1983; Baron-Cohen et al., 1985) of recognising that others can hold false beliefs about the world. We argue that this system -- which autonomously learns how to model other agents in its world -- is an important step forward for developing multi-agent AI systems, for building intermediating technology for machine-human interaction, and for advancing the progress on interpretable AI.},
archivePrefix = {arXiv},
arxivId = {1802.07740},
author = {Rabinowitz, Neil C. and Perbet, Frank and Song, H. Francis and Zhang, Chiyuan and Eslami, S. M. Ali and Botvinick, Matthew},
eprint = {1802.07740},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rabinowitz et al. - 2018 - Machine Theory of Mind.pdf:pdf},
title = {{Machine Theory of Mind}},
url = {http://arxiv.org/abs/1802.07740},
year = {2018}
}
@article{Hong2018,
abstract = {In this work, we study two first-order primal-dual based algorithms, the Gradient Primal-Dual Algorithm (GPDA) and the Gradient Alternating Direction Method of Multipliers (GADMM), for solving a class of linearly constrained non-convex optimization problems. We show that with random initialization of the primal and dual variables, both algorithms are able to compute second-order stationary solutions (ss2) with probability one. This is the first result showing that primal-dual algorithm is capable of finding ss2 when only using first-order information, it also extends the existing results for first-order, but primal-only algorithms. An important implication of our result is that it also gives rise to the first global convergence result to the ss2, for two classes of unconstrained distributed non-convex learning problems over multi-agent networks.},
archivePrefix = {arXiv},
arxivId = {1802.08941},
author = {Hong, Mingyi and Lee, Jason D. and Razaviyayn, Meisam},
eprint = {1802.08941},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hong, Lee, Razaviyayn - 2018 - Gradient Primal-Dual Algorithm Converges to Second-Order Stationary Solutions for Nonconvex Distributed O.pdf:pdf},
pages = {1--28},
title = {{Gradient Primal-Dual Algorithm Converges to Second-Order Stationary Solutions for Nonconvex Distributed Optimization}},
url = {http://arxiv.org/abs/1802.08941},
year = {2018}
}
@article{Subramanian2018,
author = {Subramanian, Kausik and Antoni, Loris D and Akella, Aditya},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Subramanian, Antoni, Akella - 2018 - Synthesis of Fault-Tolerant Distributed Router Configurations.pdf:pdf},
keywords = {Fault Tolerance,Hierarchical network control plane,Network Management,Routing protocols,Synthesis,Zeppelin},
number = {1},
title = {{Synthesis of Fault-Tolerant Distributed Router Configurations}},
volume = {2},
year = {2018}
}
@article{Pignolet2017,
author = {Pignolet, Yvonne-Anne and Schmid, Stefan and Tredan, Gilles},
doi = {10.1145/3154501},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pignolet, Schmid, Tredan - 2017 - Tomographic Node Placement Strategies and the Impact of the Routing Model.pdf:pdf},
issn = {24761249},
journal = {Proceedings of the ACM on Measurement and Analysis of Computing Systems},
keywords = {Network Tomography, Complexity},
number = {2},
pages = {1--23},
title = {{Tomographic Node Placement Strategies and the Impact of the Routing Model}},
url = {http://dl.acm.org/citation.cfm?doid=3175501.3154501},
volume = {1},
year = {2017}
}
@article{Tan2018,
author = {Tan, Zhaowei and Li, Yuanjie and Li, Qianru and Zhang, Zhehui and Li, Zhehan and Lu, Songwu},
doi = {10.1145/3179411},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tan et al. - 2018 - Supporting Mobile VR in LTE Networks.pdf:pdf},
issn = {24761249},
journal = {Proceedings of the ACM on Measurement and Analysis of Computing Systems},
number = {1},
pages = {1--31},
title = {{Supporting Mobile VR in LTE Networks}},
url = {http://dl.acm.org/citation.cfm?doid=3203302.3179411},
volume = {2},
year = {2018}
}
@article{Yang2017,
author = {Yang, Sen and He, Yan and Ge, Zihui and Wang, Dongmei and Xu, Jun},
doi = {10.1145/3154488},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2017 - Predictive Impact Analysis for Designing a Resilient Cellular Backhaul Network.pdf:pdf},
issn = {24761249},
journal = {Proceedings of the ACM on Measurement and Analysis of Computing Systems},
keywords = {Tower outage impact prediction,cellular network},
number = {2},
pages = {1--33},
title = {{Predictive Impact Analysis for Designing a Resilient Cellular Backhaul Network}},
url = {http://dl.acm.org/citation.cfm?doid=3175501.3154488},
volume = {1},
year = {2017}
}
@article{Tang2018,
abstract = {CMO Council reports that 71\% of internet users in the U.S. were influenced by coupons and discounts when making their purchase decisions. It has also been shown that offering coupons to a small fraction of users (called seed users) may affect the purchase decisions of many other users in a social network. This motivates us to study the optimal coupon allocation problem, and our objective is to allocate coupons to a set of users so as to maximize the expected cascade. Different from existing studies on influence maximizaton (IM), our framework allows a general utility function and a more complex set of constraints. In particular, we formulate our problem as an approximate submodular maximization problem subject to matroid and knapsack constraints. Existing techniques relying on the submodularity of the utility function, such as greedy algorithm, can not work directly on a non-submodular function. We use $\epsilon$ to measure the difference between our function and its closest submodular function and propose a novel approximate algorithm with approximation ratio $\beta(\epsilon)$ with $\lim_{\epsilon\rightarrow 0}\beta(\epsilon)=1-1/e$. This is the best approximation guarantee for approximate submodular maximization subject to a partition matroid and knapsack constraints, our results apply to a broad range of optimization problems that can be formulated as an approximate submodular maximization problem.},
archivePrefix = {arXiv},
arxivId = {1802.00526},
author = {Tang, Shaojie},
eprint = {1802.00526},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tang - 2018 - Toward Optimal Coupon Allocation in Social Networks An Approximate Submodular Optimization Approach.pdf:pdf},
number = {1},
title = {{Toward Optimal Coupon Allocation in Social Networks: An Approximate Submodular Optimization Approach}},
url = {http://arxiv.org/abs/1802.00526},
year = {2018}
}
@article{Olson,
author = {Olson, Daniel and Wheeler, Travis},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Olson, Wheeler - Unknown - ULTRA A Model Based Tool to Detect Tandem Repeats Extended Abstract.pdf:pdf},
keywords = {annotation error,sequence alignment,tandem repeats},
title = {{ULTRA : A Model Based Tool to Detect Tandem Repeats Extended Abstract}}
}
@article{Riverside,
author = {Riverside, California Riverside},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Riverside - Unknown - mClass Cancer type classification with somatic point mutation data.pdf:pdf},
isbn = {1234567245},
keywords = {2018,acm reference format,cancer classification,cancer type,genomics,mclass,md abid hasan and,somatic point mutation,stefano lonardi},
title = {{mClass : Cancer type classification with somatic point mutation data}}
}
@inproceedings{Badanidiyuru2014a,
abstract = {How can one summarize a massive data set "on the fly", i.e., without even having seen it in its entirety? In this paper, we address the problem of extracting representative elements from a large stream of data. I.e., we would like to select a subset},
author = {Badanidiyuru, Ashwinkumar and Mirzasoleiman, Baharan and Karbasi, Amin and Krause, Andreas},
booktitle = {ACM SIGKDD Knowledge Discovery and Data Mining (KDD)},
doi = {10.1145/2623330.2623637},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Badanidiyuru et al. - 2014 - Streaming Submodular Maximization Massive Data Summarization on the Fly.pdf:pdf},
isbn = {9781450329569},
keywords = {streaming algorithms,submodular functions},
pages = {671--680},
title = {{Streaming Submodular Maximization: Massive Data Summarization on the Fly}},
url = {http://www.cs.cornell.edu/$\sim$ashwin85/docs/kdd-streaming-finalversion.pdf},
year = {2014}
}
@inproceedings{Bogunovic2018,
abstract = {We study the problem of maximizing a monotone set function subject to a cardinality constraint $k$ in the setting where some number of elements $\tau$ is deleted from the returned set. The focus of this work is on the worst-case adversarial setting. While there exist constant-factor guarantees when the function is submodular, there are no guarantees for non-submodular objectives. In this work, we present a new algorithm Oblivious-Greedy and prove the first constant-factor approximation guarantees for a wider class of non-submodular objectives. The obtained theoretical bounds are the first constant-factor bounds that also hold in the linear regime, i.e. when the number of deletions $\tau$ is linear in $k$. Our bounds depend on established parameters such as the submodularity ratio and some novel ones such as the inverse curvature. We bound these parameters for two important objectives including support selection and variance reduction. Finally, we numerically demonstrate the robust performance of Oblivious-Greedy for these two objectives on various datasets.},
archivePrefix = {arXiv},
arxivId = {1802.07073},
author = {Bogunovic, Ilija and Zhao, Junyao and Cevher, Volkan},
booktitle = {Proceedings of the 21st International Conference on Artificial Intelligence and Statistics (AISTATS)},
eprint = {1802.07073},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bogunovic, Zhao, Cevher - 2018 - Robust Maximization of Non-Submodular Objectives.pdf:pdf},
title = {{Robust Maximization of Non-Submodular Objectives}},
url = {http://arxiv.org/abs/1802.07073},
year = {2018}
}
@inproceedings{Qian2018,
author = {Qian, Chao and Zhang, Yibo and Tang, Ke and Yao, Xin},
booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence (AAAI)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qian et al. - 2018 - On Multiset Selection with Size Constraints.pdf:pdf},
isbn = {2017030317},
keywords = {Heuristic Search and Optimization Track},
pages = {1395--1402},
title = {{On Multiset Selection with Size Constraints}},
year = {2018}
}
@inproceedings{Elenberg2017,
abstract = {In many machine learning applications, it is important to explain the predictions of a black-box classifier. For example, why does a deep neural network assign an image to a particular class? We cast interpretability of black-box classifiers as a combinatorial maximization problem and propose an efficient streaming algorithm to solve it subject to cardinality constraints. By extending ideas from Badanidiyuru et al. [2014], we provide a constant factor approximation guarantee for our algorithm in the case of random stream order and a weakly submodular objective function. This is the first such theoretical guarantee for this general class of functions, and we also show that no such algorithm exists for a worst case stream order. Our algorithm obtains similar explanations of Inception V3 predictions $10$ times faster than the state-of-the-art LIME framework of Ribeiro et al. [2016].},
archivePrefix = {arXiv},
arxivId = {1703.02647},
author = {Elenberg, Ethan R. and Dimakis, Alexandros G. and Feldman, Moran and Karbasi, Amin},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
eprint = {1703.02647},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elenberg et al. - 2017 - Streaming Weak Submodularity Interpreting Neural Networks on the Fly.pdf:pdf},
issn = {10495258},
title = {{Streaming Weak Submodularity: Interpreting Neural Networks on the Fly}},
url = {http://arxiv.org/abs/1703.02647},
year = {2017}
}
@article{Khot2001,
abstract = {In this paper, we present improved inapproximability results for three\nproblems : the problem of finding the maximum clique size in a graph,\nthe problem of finding the chromatic number of a graph, and the problem\nof coloring a graph with a small chromatic number with a small number of\ncolors.\nHastad's celebrated result {[}13] shows that the maximum clique size in\na graph with n vertices is inapproximable in polynomial time within a\nfactor n(1-epsilon) for arbitrarily small constant epsilon > 0 unless\nNP=ZPP. In this paper, we aim at getting the best subconstant value of\nepsilon in Hastad's result. We prove that clique size is inapproximable\nwithin a factor n/2((log n)1 - gamma) (corresponding to epsilon = 1/(log\nn)(gamma) ) for some constant gamma > 0 unless NP subset of or equal to\nZPTIME(2((log n)O(1))). This improves the previous best\ninapproximability factor of n/2(O(log n/root log log n)) (corresponding\nto epsilon = O(1/root log log n)) due to Engebretsen and Holmerin {[}7].\nA similar result is obtained for the problem of approximating chromatic\nnumber of a graph. Feige and Kilian {[}10] prove that chromatic number\nis hard to approximate within factor n(1-epsilon) for any constant\nepsilon > 0 unless NP=ZPP. We use some of their techniques to give a\nmuch simpler proof of the same result and also improve the hardness\nfactor to - n for some constant gamma > 0. The above two results n/2(log\nn)(1 - gamma) are obtained by constructing a new Hadamard code based PCP\ninner verifier.\nWe also present a new hardness result for approximate graph coloring. We\nshow that for all sufficiently large constants k, it is NP-hard to color\na k-colorable graph with k1/25((log k)) colors. This improves a result\nof Furer {[}11] that for arbitrarily small constant epsilon > 0, for\nsufficiently large constants k, it is hard to color a k-colorable graph\nwith k(3/2-epsilon) colors.},
author = {Khot, S},
doi = {10.1109/SFCS.2001.959936},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khot - 2001 - Improved Inapproximability Results for MaxClique, Chromatic Number and Approximate Graph Coloring.pdf:pdf},
isbn = {0-7695-1390-5; 0-7695-1391-3},
issn = {0272-5428},
journal = {42Nd Annual Symposium on Foundations of Computer Science, Proceedings},
pages = {600--609},
title = {{Improved Inapproximability Results for MaxClique, Chromatic Number and Approximate Graph Coloring}},
year = {2001}
}
@article{Gagie2017,
abstract = {Indexing highly repetitive texts --- such as genomic databases, software repositories and versioned text collections --- has become an important problem since the turn of the millennium. A relevant compressibility measure for repetitive texts is $r$, the number of runs in their Burrows-Wheeler Transform (BWT). One of the earliest indexes for repetitive collections, the Run-Length FM-index, used $O(r)$ space and was able to efficiently count the number of occurrences of a pattern of length $m$ in the text (in loglogarithmic time per pattern symbol, with current techniques). However, it was unable to locate the positions of those occurrences efficiently within a space bounded in terms of $r$. Since then, a number of other indexes with space bounded by other measures of repetitiveness --- the number of phrases in the Lempel-Ziv parse, the size of the smallest grammar generating the text, the size of the smallest automaton recognizing the text factors --- have been proposed for efficiently locating, but not directly counting, the occurrences of a pattern. In this paper we close this long-standing problem, showing how to extend the Run-Length FM-index so that it can locate the $occ$ occurrences efficiently within $O(r)$ space (in loglogarithmic time each), and reaching optimal time $O(m+occ)$ within $O(r\log(n/r))$ space, on a RAM machine of $w=\Omega(\log n)$ bits. Within $O(r\log (n/r))$ space, our index can also count in optimal time $O(m)$. Raising the space to $O(r w\log_\sigma(n/r))$, we support count and locate in $O(m\log(\sigma)/w)$ and $O(m\log(\sigma)/w+occ)$ time, which is optimal in the packed setting and had not been obtained before in compressed space. We also describe a structure using $O(r\log(n/r))$ space that replaces the text and extracts any text substring of length $\ell$ in almost-optimal time $O(\log(n/r)+\ell\log(\sigma)/w)$. (...continues...)},
archivePrefix = {arXiv},
arxivId = {1705.10382},
author = {Gagie, Travis and Navarro, Gonzalo and Prezza, Nicola},
eprint = {1705.10382},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gagie, Navarro, Prezza - 2017 - Optimal-Time Text Indexing in BWT-runs Bounded Space.pdf:pdf},
pages = {1--43},
title = {{Optimal-Time Text Indexing in BWT-runs Bounded Space}},
url = {http://arxiv.org/abs/1705.10382},
year = {2017}
}
@article{Cnrs1993,
abstract = {Motivated by the problem of designing large packet radio networks, we show that the Kautz and de Bruijn digraphs with in‐ and outdegree d have arc‐chromatic index 2d. In order to do this, we introduce the concept of even 1‐factorizations. An even 1‐factor of a digraph is a spanning subgraph consisting of vertex disjoint loops and even cycles; an even 1‐factorization is a partition of the arcs into even 1‐factors. We prove that if a digraph admits an even 1‐factorization, then so does its line digraph. (In fact, we show that the line digraph admits an even 1‐factorization even under a weaker assumption discussed below.) As a consequence, we derive the above property of the Kautz and de Bruijn digraphs relevant to packet radio networks. {\textcopyright} 1993 John Wiley & Sons, Inc. Copyright {\textcopyright} 1993 Wiley Periodicals, Inc., A Wiley Company},
author = {Bermond, Jean-Claude and Hell, Pavol},
doi = {10.1002/jgt.3190170512},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bermond, Hell - 1993 - On even factorizations and the chromatic index of the Kautz and de Bruijn digraphs.pdf:pdf},
issn = {10970118},
journal = {Journal of Graph Theory},
number = {5},
pages = {647--655},
title = {{On even factorizations and the chromatic index of the Kautz and de Bruijn digraphs}},
volume = {17},
year = {1993}
}
@inproceedings{Feige1996,
author = {Feige, Uriel and Kilian, Joe},
booktitle = {Conference on Computational Complexity},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feige, Kilian - 1996 - Zero Knowledge and the Chromatic Number.pdf:pdf},
pages = {278--287},
title = {{Zero Knowledge and the Chromatic Number}},
year = {1996}
}
@article{Short,
author = {Short, Motivation and Mapping, Read},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Short, Mapping - Unknown - Burrows-Wheeler Transform.pdf:pdf},
title = {{Burrows-Wheeler Transform}}
}
@article{Siren2016,
abstract = {In order to avoid the reference bias introduced by mapping reads to a reference genome, bioinformaticians are investigating reference-free methods for analyzing sequenced genomes. With large projects sequencing thousands of individuals, this raises the need for tools capable of handling terabases of sequence data. A key method is the Burrows-Wheeler transform (BWT), which is widely used for compressing and indexing reads. We propose a practical algorithm for building the BWT of a large read collection by merging the BWTs of subcollections. With our 2.4 Tbp datasets, the algorithm can merge 600 Gbp/day on a single system, using 30 gigabytes of memory overhead on top of the run-length encoded BWTs.},
archivePrefix = {arXiv},
arxivId = {1511.00898},
author = {Siren, Jouni},
doi = {10.1109/DCC.2016.17},
eprint = {1511.00898},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Siren - 2016 - Burrows-Wheeler Transform for Terabases.pdf:pdf},
isbn = {9781509018536},
issn = {10680314},
journal = {Data Compression Conference Proceedings},
pages = {211--220},
title = {{Burrows-Wheeler Transform for Terabases}},
year = {2016}
}
@article{Navarro2014,
author = {Navarro, Gonzalo and Sadakane, Kunihiko},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Navarro, Sadakane - 2014 - Fully Functional Static and Dynamic Succinct Trees.pdf:pdf},
number = {3},
pages = {1--39},
title = {{Fully Functional Static and Dynamic Succinct Trees}},
volume = {10},
year = {2014}
}
@article{Navarro,
author = {Navarro, Gonzalo and Nekrich, Yakov},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Navarro, Nekrich - Unknown - Optimal dynamic sequence representations ∗.pdf:pdf},
pages = {1--26},
title = {{Optimal dynamic sequence representations ∗}}
}
@article{Prezza2017,
archivePrefix = {arXiv},
arxivId = {1701.07238},
author = {Prezza, Nicola},
doi = {10.4230/LIPIcs.SEA.2017.11},
eprint = {1701.07238},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prezza - 2017 - A framework of dynamic data structures for string processing.pdf:pdf},
isbn = {9783959770361},
issn = {18688969},
journal = {Proceedings of the 16th International Symposium on Experimental Algorithms (SEA)},
keywords = {11,2017,4230,and phrases c,bitvector,compression,data structure,digital object identifier 10,dynamic,lipics,sea,string},
number = {11},
pages = {11:1--11:15},
title = {{A framework of dynamic data structures for string processing}},
volume = {75},
year = {2017}
}
@article{Alipanahi,
author = {Alipanahi, Bahar and Boucher, Christina},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alipanahi, Boucher - Unknown - Recoloring the Colored de Bruijn Graph.pdf:pdf},
title = {{Recoloring the Colored de Bruijn Graph}}
}
@article{Gagie2018,
author = {Gagie, Travis and Navarro, Gonzalo and Prezza, Nicola},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gagie, Navarro, Prezza - 2018 - Optimal-Time Text Indexing in BWT-runs Bounded Space.pdf:pdf},
pages = {1459--1477},
title = {{Optimal-Time Text Indexing in BWT-runs Bounded Space}},
year = {2018}
}
@inproceedings{Boucher2018,
archivePrefix = {arXiv},
arxivId = {arXiv:1803.11245v3},
author = {Boucher, Christina and Gagie, Travis and Kuhnle, Alan and Manzini, Giovanni},
booktitle = {18th International Workshop on Algorithms in Bioinformatics (WABI)},
eprint = {arXiv:1803.11245v3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boucher et al. - 2018 - Prefix-Free Parsing for Building Big BWTs.pdf:pdf},
keywords = {2018,23,4230,acknowledgements the authors would,and phrases burrows-wheeler transform,compression-aware al-,digital object identifier 10,genomic databases,gorithms,j{\"{a}}rvinen for explaining rsync,like to thank risto,lipics,prefix-free parsing,s,wabi},
title = {{Prefix-Free Parsing for Building Big BWTs}},
year = {2018}
}
@article{Puglisi,
author = {Puglisi, Simon J},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Puglisi - Unknown - Dynamic Succinct Data Structures and Compressed Random Access Memory ⋆.pdf:pdf},
isbn = {9788001061930},
keywords = {dynamic data structures,hash table,in the past 20,structures have matured to,succinct and compact data,succinct data structures,the point,trie,years},
pages = {294143},
title = {{Dynamic Succinct Data Structures and Compressed Random Access Memory ⋆}}
}
@article{Transform,
archivePrefix = {arXiv},
arxivId = {arXiv:1704.05233v2},
author = {Transform, Burrows-wheeler and Ohno, Tatsuya},
eprint = {arXiv:1704.05233v2},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Transform, Ohno - Unknown - A Faster Implementation of Online Run-Length.pdf:pdf},
pages = {1--8},
title = {{A Faster Implementation of Online Run-Length}}
}
@article{Salson2009,
author = {Salson, M and Lecroq, T and L{\'{e}}onard, M and Mouchard, L},
doi = {10.1016/j.tcs.2009.07.016},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Salson et al. - 2009 - A four-stage algorithm for updating a Burrows – Wheeler transform.pdf:pdf},
issn = {0304-3975},
journal = {Theoretical Computer Science},
keywords = {burrows,wheeler transform},
number = {43},
pages = {4350--4359},
title = {{A four-stage algorithm for updating a Burrows – Wheeler transform}},
url = {http://dx.doi.org/10.1016/j.tcs.2009.07.016},
volume = {410},
year = {2009}
}
@article{Pandey2017,
author = {Pandey, Prashant and Almodaresi, Fatemeh and Bender, Michael A and Ferdman, Michael and Johnson, Rob and Patro, Rob},
doi = {10.1101/217372},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pandey et al. - 2017 - Mantis A Fast , Small , and Exact Large-Scale Sequence-Search Index.pdf:pdf},
number = {Section 2},
title = {{Mantis : A Fast , Small , and Exact Large-Scale Sequence-Search Index}},
year = {2017}
}
@inproceedings{Bowe2012,
author = {Bowe, Alexander and Onodera, Taku and Sadakane, Kunihiko and Shibuya, Tetsuo},
booktitle = {Workshop on Algorithms in Bioinformatics (WABI)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bowe et al. - 2012 - Succinct de Bruijn Graphs.pdf:pdf},
pages = {225--235},
title = {{Succinct de Bruijn Graphs}},
year = {2012}
}
@article{Kuhnle2018,
abstract = {IEEE Motivated by online social networks that are linked together through overlapping users, we study the influence maximization problem on a multiplex, with each layer endowed with its own model of influence diffusion. This problem is a novel version of the influence maximization problem that necessitates new analysis incorporating the type of propagation on each layer of the multiplex. We identify a new property, generalized deterministic submodular, which when satisfied by the propagation in each layer, ensures that the propagation on the multiplex overall is submodular-for this case, we formulate influential seed finder (ISF), the greedy algorithm with approximation ratio (1-1/e). Since the size of a multiplex comprising multiple OSNs may encompass billions of users, we formulate an algorithm knapsack seeding of network (KSN) that runs on each layer of the multiplex in parallel. KSN takes an  & #x03B1;-approximation algorithm A for the influence maximization problem on a single network as input, and has approximation ratio ((1 -  & #x03B5;)  & #x03B1;)/((o + 1)k) for arbitrary  & #x03B5;  & #x003E; 0, o is the number of overlapping users, and k is the number of layers in the multiplex. Experiments on real and synthesized multiplexes validate the efficacy of the proposed algorithms for the problem of influence maximization in the heterogeneous multiplex. Implementations of ISF and KSN are available at http://www.alankuhnle.com/papers/mim/mim.html.},
author = {Kuhnle, A. and Alim, M.A. and Li, X. and Zhang, H. and Thai, M.T.},
doi = {10.1109/TCSS.2018.2813262},
issn = {2329924X},
journal = {IEEE Transactions on Computational Social Systems},
keywords = {Approximation algorithms,Computational modeling,Facebook,Integrated circuit modeling,Multiplexing,Twitter,heterogeneous networks},
title = {{Multiplex Influence Maximization in Online Social Networks With Heterogeneous Diffusion Models}},
year = {2018}
}
@inproceedings{Pan2017a,
abstract = {{\textcopyright} 2017 IEEE. Online Social Networks (OSNs) are effective platforms for viral marketing. Due to their importance, viral marketing related problems in OSNs have been extensively studied in the past decade. However, none of the existing works can cope with the situation that the propagation rate dynamically increases for popular topics, as they all assume known propagation rates. In this paper, to better describe realistic information propagation in OSNs, we propose a novel model, Dynamic Influence Propagation (DIP), that allows propagation rate to change during the diffusion. We then define a new research problem: Threshold Activation Problem under DIP (TAP-DIP) to study the impact of DIP. TAP-DIP adds extra complexity on the already #P-hard TAP problem. Despite it hardness, we are able to approximate TAP-DIP with O(log|V|) ratio. Sitting in the core of our algorithm are the Lipschitz optimization technique and a novel solution to the general version of TAP, the Multi-TAP problem. Using various real OSN datasets, we experimentally demonstrate the impact of DIP and that our solution not only generates high-quality seed sets when being aware of the rate increase, but also is scalable.},
author = {Pan, T. and Kuhnle, A. and Li, X. and Thai, M.T.},
booktitle = {Proceedings - IEEE International Conference on Data Mining, ICDM},
doi = {10.1109/ICDM.2017.132},
isbn = {9781538638347},
issn = {15504786},
title = {{Dynamic propagation rates: new dimension to viral marketing in online social networks}},
volume = {2017-Novem},
year = {2017}
}
@inproceedings{Kuhnle2017c,
abstract = {{\textcopyright} 2017 IEEE. Motivated by the relevance of clustering or transitivity to a variety of network applications, we study the Triangle Interdiction Problem (TIP), which is to find a minimum-size set of edges that intersects all triangles of a network. As existing approximation algorithms for this NP-hard problem either do not scale well to massive networks or have poor solution quality, we formulate two algorithms, TARL and DART, with worst-case guarantees 5/2 and 3 with respect to optimal, respectively. Furthermore, DART is able to efficiently maintain its worst-case guarantee under dynamic edge insertion and removal to the network. In our comprehensive experimental evaluation, we demonstrate that DART is able to run on networks with billions of triangles within 2 hours and is able to dynamically update its solution in microseconds.},
author = {Kuhnle, A. and Crawford, V.G. and Thai, M.T.},
booktitle = {IEEE International Conference on Data Mining (ICDM)},
doi = {10.1109/ICDM.2017.33},
isbn = {9781538638347},
issn = {15504786},
keywords = {Cycle Transversal,Scalable approximation,Triangle Interdiction},
title = {{Scalable and Adaptive Algorithms for the Triangle Interdiction Problem on Billion-Scale Networks}},
year = {2017}
}
@inproceedings{Qian2017,
abstract = {The problem of selecting the best k-element subset from a universe is involved in many applications. While previous studies assumed a noise-free environment or a noisy monotone submodular objective function, this paper considers a more realistic and general situation where the evaluation of a subset is a noisy monotone function (not necessarily submodular), with both multiplicative and additive noises. To understand the impact of the noise, we firstly show the approximation ratio of the greedy algorithm and POSS, two powerful algorithms for noise-free subset selection, in the noisy environments. We then propose to incorporate a noise-aware strategy into POSS, resulting in the new PONSS algorithm. We prove that PONSS can achieve a better approximation ratio under some assumption such as i.i.d. noise distribution. The empirical results on influence maximization and sparse regression problems show the superior performance of PONSS.},
author = {Qian, Chao and Shi, Jing-cheng and Yu, Yang and Tang, Ke and Zhou, Zhi-hua},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qian et al. - 2017 - Subset Selection under Noise.pdf:pdf},
title = {{Subset Selection under Noise}},
year = {2017}
}
@article{Singla2015,
abstract = {We address the problem of maximizing an unknown submodular function that can only be accessed via noisy evaluations. Our work is motivated by the task of summarizing content, e.g., image collections, by leveraging users' feedback in form of clicks or ratings. For summarization tasks with the goal of maximizing coverage and diversity, submodular set functions are a natural choice. When the underlying submodular function is unknown, users' feedback can provide noisy evaluations of the function that we seek to maximize. We provide a generic algorithm -- \submM{} -- for maximizing an unknown submodular function under cardinality constraints. This algorithm makes use of a novel exploration module -- \blbox{} -- that proposes good elements based on adaptively sampling noisy function evaluations. \blbox{} is able to accommodate different kinds of observation models such as value queries and pairwise comparisons. We provide PAC-style guarantees on the quality and sampling cost of the solution obtained by \submM{}. We demonstrate the effectiveness of our approach in an interactive, crowdsourced image collection summarization application.},
archivePrefix = {arXiv},
arxivId = {1511.07211},
author = {Singla, a and Tschiatschek, S and Krause, a},
eprint = {1511.07211},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Singla, Tschiatschek, Krause - 2015 - Noisy Submodular Maximization via Adaptive Sampling with Applications to Crowdsourced Image Col(2).pdf:pdf},
isbn = {9781577357605},
journal = {arXiv preprint arXiv:1511.07211},
pages = {2037--2043},
title = {{Noisy Submodular Maximization via Adaptive Sampling with Applications to Crowdsourced Image Collection Summarization}},
url = {http://arxiv.org/abs/1511.07211},
year = {2015}
}
@article{Singla2015a,
abstract = {We address the problem of maximizing an unknown submodular function that can only be accessed via noisy evaluations. Our work is motivated by the task of summarizing content, e.g., image collections, by leveraging users' feedback in form of clicks or ratings. For summarization tasks with the goal of maximizing coverage and diversity, submodular set functions are a natural choice. When the underlying submodular function is unknown, users' feedback can provide noisy evaluations of the function that we seek to maximize. We provide a generic algorithm -- \submM{} -- for maximizing an unknown submodular function under cardinality constraints. This algorithm makes use of a novel exploration module -- \blbox{} -- that proposes good elements based on adaptively sampling noisy function evaluations. \blbox{} is able to accommodate different kinds of observation models such as value queries and pairwise comparisons. We provide PAC-style guarantees on the quality and sampling cost of the solution obtained by \submM{}. We demonstrate the effectiveness of our approach in an interactive, crowdsourced image collection summarization application.},
archivePrefix = {arXiv},
arxivId = {1511.07211},
author = {Singla, a and Tschiatschek, S and Krause, a},
eprint = {1511.07211},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Singla, Tschiatschek, Krause - 2015 - Noisy Submodular Maximization via Adaptive Sampling with Applications to Crowdsourced Image Collec.pdf:pdf},
isbn = {9781577357605},
journal = {arXiv preprint arXiv:1511.07211},
pages = {2037--2043},
title = {{Noisy Submodular Maximization via Adaptive Sampling with Applications to Crowdsourced Image Collection Summarization}},
url = {http://arxiv.org/abs/1511.07211},
year = {2015}
}
@article{Nguyen2008,
abstract = {We present a technique for transforming classical approximation algorithms into constant-time algorithms that approximate the size of the optimal solution. Our technique is applicable to a certain subclass of algorithms that compute a solution in a constant number of phases. The technique is based on greedily considering local improvements in random order.The problems amenable to our technique include vertex cover, maximum matching, maximum weight matching, set cover, and minimum dominating set. For example, for maximum matching, we give the first constant-time algorithm that for the class of graphs of degree bounded by d, computes the maximum matching size to within epsivn, for any epsivn &gt; 0, where n is the number of nodes in the graph. The running time of the algorithm is independent of n, and only depends on d and epsiv.},
author = {Nguyen, Huy N. and Onak, Krzysztof},
doi = {10.1109/FOCS.2008.81},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen, Onak - 2008 - Constant-time approximation algorithms via local improvements.pdf:pdf},
isbn = {9780769534367},
issn = {02725428},
journal = {Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS},
pages = {327--336},
title = {{Constant-time approximation algorithms via local improvements}},
year = {2008}
}
@article{Goos2014,
abstract = {K{\"{o}}nig's theorem states that on bipartite graphs the size of a maximum matching equals the size of a minimum vertex cover. It is known from prior work that for every $\epsilon$ > 0 there exists a constant-time distributed algorithm that finds a (1+$\epsilon$)-approximation of a maximum matching on bounded-degree graphs. In this work, we show—somewhat surprisingly—that no sublogarithmic-time approximation scheme exists for the dual problem: there is a constant $\delta$ > 0 so that no randomised distributed algorithm with running time o(log n) can find a (1+$\delta$)-approximation of a minimum vertex cover on 2-coloured graphs of maximum degree 3. In fact, a simple application of the Linial–Saks (1993) decomposition demonstrates that this run-time lower bound is tight. Our lower-bound construction is simple and, to some extent, independent of previous techniques. Along the way we prove that a certain cut minimisation problem, which might be of independent interest, is hard to approximate locally on expander graphs.},
archivePrefix = {arXiv},
arxivId = {1205.4605},
author = {G{\"{o}}{\"{o}}s, Mika and Suomela, Jukka},
doi = {10.1007/s00446-013-0194-z},
eprint = {1205.4605},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\"{o}}{\"{o}}s, Suomela - 2014 - No sublogarithmic-time approximation scheme for bipartite vertex cover.pdf:pdf},
isbn = {9783642336508},
issn = {01782770},
journal = {Distributed Computing},
keywords = {Distributed graph algorithms,Local approximation,Lower bounds,Vertex cover},
number = {6},
pages = {435--443},
title = {{No sublogarithmic-time approximation scheme for bipartite vertex cover}},
volume = {27},
year = {2014}
}
@article{Shi2017,
abstract = {This paper studies randomized approximation algorithm for a variant of the set cover problem called minimum submodular cost partial multi-cover (SCPMC), in which each element $e$ has a covering requirement $r_e$ and a profit $p_e$, and the cost function on sub-collection of sets is submodular, the goal is to find a minimum cost sub-collection of sets which fully covers at least $q$-percentage of total profit, where an element $e$ is fully covered by sub-collection $S'$ if and only if it belongs to at least $r_e$ sets of $\mathcal S'$. Previous work shows that such a combination enormously increases the difficulty of studies, even when the cost function is linear. In this paper, assuming that the maximum covering requirement $r_{\max}=\max_e r_e$ is a constant and the cost function is nonnegative, monotone nondecreasing, and submodular, we give the first randomized bicriteria algorithm for SCPMC the output of which fully covers at least $(q-\varepsilon)$-percentage of all elements and the performance ratio is $O(b/\varepsilon)$ with a high probability, where $b=\max_e\binom{f}{r_{e}}$ and $f$ is the maximum number of sets containing a common element. The algorithm is based on a novel non-linear program. Furthermore, in the case when the covering requirement $r\equiv 1$, a bicriteria $O(f/\varepsilon)$-approximation can be achieved even when monotonicity requirement is dropped off from the cost function.},
archivePrefix = {arXiv},
arxivId = {1701.05339},
author = {Shi, Yishuo and Zhang, Zhao and Du, Ding-Zhu},
eprint = {1701.05339},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shi, Zhang, Du - 2017 - Randomized Bicriteria Approximation Algorithm for Minimum Submodular Cost Partial Multi-Cover Problem.pdf:pdf},
pages = {1--17},
title = {{Randomized Bicriteria Approximation Algorithm for Minimum Submodular Cost Partial Multi-Cover Problem}},
url = {http://arxiv.org/abs/1701.05339},
year = {2017}
}
@article{Balkanski2017,
abstract = {In this paper we consider the problem of minimizing a submodular function from training data. Submodular functions can be efficiently minimized and are conse-quently heavily applied in machine learning. There are many cases, however, in which we do not know the function we aim to optimize, but rather have access to training data that is used to learn it. In this paper we consider the question of whether submodular functions can be minimized when given access to its training data. We show that even learnable submodular functions cannot be minimized within any non-trivial approximation when given access to polynomially-many sam-ples. Specifically, we show that there is a class of submodular functions with range in [0, 1] such that, despite being PAC-learnable and minimizable in polynomial-time, no algorithm can obtain an approximation strictly better than 1/2 o(1) using polynomially-many samples drawn from any distribution. Furthermore, we show that this bound is tight via a trivial algorithm that obtains an approximation of 1/2.},
author = {Balkanski, Eric and Singer, Yaron},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Balkanski, Singer - 2017 - Minimizing a Submodular Function from Samples.pdf:pdf},
journal = {Advances in Neural Information Processing Systems 30},
number = {Nips},
pages = {814--822},
title = {{Minimizing a Submodular Function from Samples}},
url = {http://papers.nips.cc/paper/6683-minimizing-a-submodular-function-from-samples.pdf},
year = {2017}
}
@article{Nguyen2017b,
author = {Nguyen, Hung T. and Thai, My T. and Dinh, Thang N.},
doi = {10.1109/TNET.2017.2691544},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen, Thai, Dinh - 2017 - A Billion-Scale Approximation Algorithm for Maximizing Benefit in Viral Marketing.pdf:pdf},
issn = {10636692},
journal = {IEEE/ACM Transactions on Networking},
keywords = {Influence maximization,Viral marketing,sampling Alg},
number = {4},
pages = {2419--2429},
title = {{A Billion-Scale Approximation Algorithm for Maximizing Benefit in Viral Marketing}},
volume = {25},
year = {2017}
}
@article{Rahman2013,
author = {Rahman, Ashfaqur and Mohsenian-rad, Hamed},
doi = {10.1109/PESMG.2013.6672638},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rahman, Mohsenian-rad - 2013 - False Data Injection Attacks Against Nonlinear State Estimation in Smart Power Grids.pdf:pdf},
isbn = {9781479913039},
journal = {IEEE Power and Energy Society General Meeting},
keywords = {false data injection attacks,non-linear state estimation,perfect and imperfect attacks,smart grid security},
number = {1},
pages = {1--5},
title = {{False Data Injection Attacks Against Nonlinear State Estimation in Smart Power Grids}},
year = {2013}
}
@article{Cai2010,
author = {Cai, Jian-Feng and Candes, Emmanual J. and Shen, Zuowei},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cai, Candes, Shen - 2010 - A Singular Value Thresholding Algorithm for Matrix Completion.pdf:pdf},
journal = {SIAM Journal of Optimization},
keywords = {080738970,10,1137,15a83,65k05,90c25,ams subject classifications,doi,grange dual function,la-,linearized bregman iteration,matrix completion,nuclear norm minimization,s algorithm,singular value thresholding,uzawa},
number = {4},
pages = {1956--1982},
title = {{A Singular Value Thresholding Algorithm for Matrix Completion}},
volume = {20},
year = {2010}
}
@inproceedings{Yang2016,
author = {Yang, Yu and Mao, Xiangbo and Pei, Jian and He, Xiaofei},
booktitle = {Proceedings of the 2016 International Conference on Management of Data (SIGMOD)},
doi = {10.1145/2882903.2882961},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2016 - Continuous Influence Maximization What Discounts Should We Offer to Social Network Users.pdf:pdf},
isbn = {9781450335317},
issn = {07308078},
keywords = {and a yahoo,coordinate descent,discovery grant,in part by an,influence maximization,mao and pei,nserc,program,s research is supported,the canada research chair,yang},
pages = {727--741},
publisher = {ACM},
title = {{Continuous Influence Maximization: What Discounts Should We Offer to Social Network Users?}},
url = {http://www.sfu.ca/$\sim$yya119/papers/CIM.pdf},
year = {2016}
}
@inproceedings{Demaine2014a,
abstract = {We study the power of fractional allocations of resources to maximize influence in a network. This work extends in a natural way the well-studied model by Kempe, Kleinberg, and Tardos (2003), where a designer selects a (small) seed set of nodes in a social network to influence directly, this influence cascades when other nodes reach certain thresholds of neighbor influence, and the goal is to maximize the final number of influenced nodes. Despite extensive study from both practical and theoretical viewpoints, this model limits the designer to a binary choice for each node, with no way to apply intermediate levels of influence. This model captures some settings precisely, e.g. exposure to an idea or pathogen, but it fails to capture very relevant concerns in others, for example, a manufacturer promoting a new product by distributing five "20% off" coupons instead of giving away one free product. While fractional versions of problems tend to be easier to solve than integral versions, for influence maximization, we show that the two versions have essentially the same computational complexity. On the other hand, the two versions can have vastly different solutions: the added flexibility of fractional allocation can lead to significantly improved influence. Our main theoretical contribution is to show how to adapt the major positive results from the integral case to the fractional case. Specifically, Mossel and Roch (2006) used the submodularity of influence to obtain their integral results; we introduce a new notion of continuous submodularity, and use this to obtain matching fractional results. We conclude that we can achieve the same greedy $(1-1/e-\epsilon)$-approximation for the fractional case as the integral case. In practice, we find that the fractional model performs substantially better than the integral model, according to simulations on real-world social network data.},
archivePrefix = {arXiv},
arxivId = {1401.7970},
author = {Demaine, Erik D. and Hajiaghayi, MohammadTaghi and Mahini, Hamid and Malec, David L. and Raghavan, S. and Sawant, Anshul and Zadimoghadam, Morteza},
booktitle = {Proceeding of the 23rd International Conference on Word Wide Web},
eprint = {1401.7970},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Demaine et al. - 2014 - How to Influence People with Partial Incentives(2).pdf:pdf},
publisher = {ACM},
title = {{How to Influence People with Partial Incentives}},
url = {http://arxiv.org/abs/1401.7970},
year = {2014}
}
@article{Ghiassi-Farrokhfal2013,
abstract = {The high variability of solar power due to intrinsic diurnal variability, as well as additional stochastic variations due to cloud cover, have made it difficult for solar farms to participate in electricity markets that require pre-committed constant power generation. We study the use of battery storage to 'firm' solar power, that is, to remove variability so that such a pre-commitment can be made. Due to the high cost of storage, it is necessary to size the battery parsimoniously, choosing the minimum size to meet a certain reliability guarantee. Inspired by recent work that identifies an isomorphism between batteries and network buffers, we introduce a new model for solar power generation that models it as a stochastic traffic source. This permits us to use techniques from the stochastic network calculus to both size storage and to maximize the revenue that a solar farm owner can make from the day-ahead power market. Using a 10-year of recorded solar irradiance, we show that our approach attains 93% of the maximum revenue in a summer day that would have been achieved in daily market had the entire solar irradiance trace been known ahead of time.},
author = {Ghiassi-Farrokhfal, Y. and Keshav, S. and Ciucu, F.},
doi = {10.1145/2494232.2465744},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghiassi-Farrokhfal, Keshav, Ciucu - 2013 - Firming solar power.pdf:pdf},
isbn = {9781450319003},
issn = {01635999},
journal = {Performance Evaluation Review},
keywords = {Electricity market,Solar power modelling},
number = {1 SPEC. ISS.},
pages = {357--358},
title = {{Firming solar power}},
volume = {41},
year = {2013}
}
@article{Liang2017,
abstract = {With rapid advances in sensor, computer and communication networks, modern power systems have become complicated cyber-physical systems. Assessing and enhancing cyber-physical system security is therefore of utmost importance for the future electricity grid. In a successful false data injection attack (FDIA), an attacker compromises measurements from grid sensors in such a way that undetected errors are introduced into estimates of state variables such as bus voltage angles and magnitudes. In evading detection by commonly employed residue-based bad data detection tests, FDIAs are capable of severely threatening power system security. Since the first published research on FDIAs in 2009, research into FDIA-based cyber-attacks has been extensive. This paper gives a comprehensive review of state-of-the-art in FDIAs against modern power systems. The paper first summarizes the theoretical basis of FDIAs, and then discusses both the physical and economic impacts of a successful FDIA. The paper presents the basic defense strategies against FDIAs, and discusses some potential future research directions in this field.},
author = {Liang, G. and Zhao, J. and Luo, F. and Weller, S.R. and Dong, Z.Y.},
doi = {10.1109/TSG.2015.2495133},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang et al. - 2017 - A Review of False Data Injection Attacks Against Modern Power Systems.pdf:pdf},
isbn = {1949-3053 VO - 8},
issn = {19493053},
journal = {IEEE Transactions on Smart Grid},
keywords = {Cyber-physical security,false data injection attacks,power system,state estimation},
number = {4},
pages = {1630--1638},
title = {{A Review of False Data Injection Attacks Against Modern Power Systems}},
volume = {8},
year = {2017}
}
@article{Gan2013,
abstract = {Real-time demand response is essential for handling the uncertainties of renewable generation. Traditionally, demand response has been focused on large industrial and commercial loads, however it is expected that a large number of small residential loads such as air conditioners, dish washers, and electric vehicles will also participate in the coming years. The electricity consumption of these smaller loads, which we call deferrable loads, can be shifted over time, and thus be used (in aggregate) to compensate for the random fluctuations in renewable generation. In this paper, we propose a real-time distributed deferrable load control algorithm to reduce the variance of aggregate load (load minus renewable generation) by shifting the power consumption of deferrable loads to periods with high renewable generation. At every time step, the algorithm minimizes the expected variance to go with updated predictions. We prove that suboptimality of the algorithm vanishes as time horizon expands. Further, we evaluate the algorithm via trace-based simulations.},
author = {Gan, Lingwen and Wierman, Adam and Topcu, Ufuk and Chen, Niangjun and Low, Steven H.},
doi = {10.1145/2567529.2567553},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gan et al. - 2013 - Real-time deferrable load control handling the uncertainties of renewable generation.pdf:pdf},
isbn = {9781450320528},
issn = {01635999},
journal = {Proceedings of the Fourth International Conference on Future Energy Systems (e-Energy '13)},
keywords = {deferrable load control,demand response,model,smart grid},
pages = {113--124},
title = {{Real-time deferrable load control: handling the uncertainties of renewable generation}},
url = {http://dl.acm.org/citation.cfm?id=2487179},
year = {2013}
}
@inproceedings{Soltan2017,
author = {Soltan, Saleh and Zussman, Gil},
booktitle = {Proceedings IEEE PES-GM 17},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soltan, Zussman - 2017 - Power Grid State Estimation after a Cyber-Physical Attack under the AC Power Flow Model.pdf:pdf},
isbn = {9781538622124},
title = {{Power Grid State Estimation after a Cyber-Physical Attack under the AC Power Flow Model}},
year = {2017}
}
@article{Abur2008,
author = {Abur, Ali},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abur - 2008 - Power System State Estimation with Synchronized Phasor Measurements.pdf:pdf},
isbn = {9781509018369},
number = {Cdc},
pages = {2403--2410},
title = {{Power System State Estimation with Synchronized Phasor Measurements}},
year = {2008}
}
@article{Hug2012,
abstract = {This paper introduces new analytical techniques for performing vulnerability analysis of state estimation when it is subject to a hidden false data injection cyber-attack on a power grid's SCADA system. Specifically, we consider ac state estimation and describe how the physical properties of the system can be used as an advantage in protecting the power system from such an attack. We present an algorithm based on graph theory which allows determining how many and which measurement signals an attacker will attack in order to minimize his efforts in keeping the attack hidden from bad data detection. This provides guidance on which measurements are vulnerable and need increased protection. Hence, this paper provides insights into the vulnerabilities but also the inherent strengths provided by ac state estimation and network topology features such as buses without power injections. {\textcopyright} 2010-2012 IEEE.},
author = {Hug, Gabriela and Giampapa, Joseph Andrew},
doi = {10.1109/TSG.2012.2195338},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hug, Giampapa - 2012 - Vulnerability assessment of AC state estimation with respect to false data injection cyber-attacks.pdf:pdf},
isbn = {1949-3053},
issn = {19493053},
journal = {IEEE Transactions on Smart Grid},
keywords = {Cyber security,SCADA systems,false data injection attacks,graph theory,state estimation},
number = {3},
pages = {1362--1370},
title = {{Vulnerability assessment of AC state estimation with respect to false data injection cyber-attacks}},
volume = {3},
year = {2012}
}
@article{Nguyen2017c,
archivePrefix = {arXiv},
arxivId = {arXiv:1602.05561v1},
author = {Nguyen, Hung T and Nguyen, Tri P and Vu, Tam N and Dinh, Thang N},
doi = {10.1145/3084457},
eprint = {arXiv:1602.05561v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen et al. - 2017 - Outward Influence and Cascade Size Estimation in Billion-scale Networks.pdf:pdf},
isbn = {9781450335423},
issn = {2476-1249},
journal = {Proc. ACM Meas. Anal. Comput. Syst.},
keywords = {approximation algorithms,fpras,outward influence},
number = {1},
pages = {20:1----20:30},
title = {{Outward Influence and Cascade Size Estimation in Billion-scale Networks}},
url = {http://doi.acm.org/10.1145/3084457},
volume = {1},
year = {2017}
}
@inproceedings{Li2017b,
abstract = {Influence maximization is the problem of selecting k nodes in a social network to maximize their influence spread. The problem has been extensively studied but most works focus on the submodular influence diffusion models. In this paper, motivated by empirical evidences, we explore influence maximization in the non-submodular regime. In particular, we study the general threshold model in which a fraction of nodes have non-submodular threshold functions, but their threshold functions are closely upper-and lower-bounded by some submodular functions (we call them $\epsilon$-almost submodular). We first show a strong hardness result: there is no 1/n $\gamma$/c approximation for influence maximization (unless P = NP) for all networks with up to n $\gamma$ $\epsilon$-almost submodular nodes, where $\gamma$ is in (0,1) and c is a parameter depending on $\epsilon$. This indicates that influence maximization is still hard to approximate even though threshold functions are close to submodular. We then provide (1 − $\epsilon$) (1 − 1/e) approximation algorithms when the number of $\epsilon$-almost submodular nodes is . Finally, we conduct experiments on a number of real-world datasets, and the results demonstrate that our approximation algorithms outperform other baseline algorithms.},
author = {Li, Qiang and Chen, Wei and Sun, Xiaoming and Zhang, Jialin},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2017 - Influence Maximization with $\epsilon$-Almost Submodular Threshold Functions.pdf:pdf},
title = {{Influence Maximization with $\epsilon$-Almost Submodular Threshold Functions}},
year = {2017}
}
@article{Khuller1999a,
abstract = {The budgeted maximum coverage problem is: given a collection of sets with associated costs defined over a domain of weighted elements, and a budget L, find a subset of such that the total cost of sets in does not exceed L, and the total weight of elements covered by is maximized. This problem is NP-hard. For the special case of this problem, where each set has unit cost, a -approximation is known. Yet, prior to this work, no approximation results were known for the general cost version. The contribution of this paper is a -approximation algorithm for the budgeted maximum coverage problem. We also argue that this approximation factor is the best possible, unless .},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Khuller, Samir and Moss, Anna and Naor, Joseph (Seffi)},
doi = {10.1016/S0020-0190(99)00031-9},
eprint = {arXiv:1011.1669v3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khuller, Moss, Naor - 1999 - The budgeted maximum coverage problem(2).pdf:pdf},
isbn = {9783527316519},
issn = {00200190},
journal = {Information Processing Letters},
keywords = {Algorithms,Maximum coverage problem,Performance guarantee},
number = {1},
pages = {39--45},
pmid = {20314319},
title = {{The budgeted maximum coverage problem}},
volume = {70},
year = {1999}
}
@article{Wang2015,
abstract = {In social networks, link prediction predicts missing links in current networks and new or dissolution links in future networks, is important for mining and analyzing the evolution of social networks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1411.5118v2},
author = {Wang, Peng and Xu, BaoWen and Wu, YuRong and Zhou, XiaoYu},
doi = {10.1007/s11432-014-5237-y},
eprint = {arXiv:1411.5118v2},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2015 - Link prediction in social networks the state-of-the-art.pdf:pdf},
issn = {1674-733X},
journal = {Science China Information Sciences},
keywords = {dynamic network,learning model,link prediction,similarity metric,social network},
number = {1},
pages = {1--38},
title = {{Link prediction in social networks: the state-of-the-art}},
url = {http://link.springer.com/10.1007/s11432-014-5237-y},
volume = {58},
year = {2015}
}
@article{Kim2011,
abstract = {While the social and information networks have become ubiquitous, the challenge of collecting complete network data still persists. Many times the collected network data is incomplete with nodes and edges missing. Com- monly, only a part of the network can be observed and we would like to infer the unobserved part of the network. We address this issue by studying the Network Completion Problem: Given a network with missing nodes and edges, can we complete the missing part? We cast the problem in the Expectation Maximization (EM) framework where we use the observed part of the network to fit a model of network structure, and then we estimate the missing part of the network us- ing the model, re-estimate the parameters and so on. We combine the EM with the Kronecker graphs model and design a scalable Metropolized Gibbs sampling ap- proach that allows for the estimation of the model pa- rameters as well as the inference about missing nodes and edges of the network. Experiments on synthetic and several real-world networks show that our approach can effectively recover the network even when about half of the nodes in the network are missing. Our algorithm outperforms not only classical link-prediction approaches but also the state of the art Stochastic block modeling approach. Furthermore, our algorithm easily scales to networks with tens of thousands of nodes.},
author = {Kim, Myunghwan and Leskovec, Jure},
doi = {10.1137/1.9781611972818.5},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Leskovec - 2011 - The Network Completion Problem Inferring Missing Nodes and Edges in Networks.pdf:pdf},
isbn = {9780898719925},
journal = {Proceedings of the 2011 SIAM International Conference on Data Mining},
pages = {47--58},
title = {{The Network Completion Problem: Inferring Missing Nodes and Edges in Networks}},
url = {http://epubs.siam.org/doi/abs/10.1137/1.9781611972818.5},
year = {2011}
}
@article{Recht2009,
abstract = {This paper provides the best bounds to date on the number of randomly sampled entries required to reconstruct an unknown low rank matrix. These results improve on prior work by Candes and Recht, Candes and Tao, and Keshavan, Montanari, and Oh. The reconstruction is accomplished by minimizing the nuclear norm, or sum of the singular values, of the hidden matrix subject to agreement with the provided entries. If the underlying matrix satisfies a certain incoherence condition, then the number of entries required is equal to a quadratic logarithmic factor times the number of parameters in the singular value decomposition. The proof of this assertion is short, self contained, and uses very elementary analysis. The novel techniques herein are based on recent work in quantum information theory.},
archivePrefix = {arXiv},
arxivId = {0910.0651},
author = {Recht, Benjamin},
eprint = {0910.0651},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Recht - 2009 - A Simpler Approach to Matrix Completion.pdf:pdf},
isbn = {1532-4435},
issn = {1532-4435},
keywords = {compressed sensing,convex optimization,low-rank matrices,matrix completion,nuclear norm minimiza-,operator chernoff bound,random matrices,tion},
pages = {3413--3430},
title = {{A Simpler Approach to Matrix Completion}},
url = {http://arxiv.org/abs/0910.0651},
volume = {12},
year = {2009}
}
@article{Lin2011,
abstract = {Low-rank representation (LRR) is an effective method for subspace clustering and has found wide applications in computer vision and machine learning. The existing LRR solver is based on the alternating direction method (ADM). It suffers from $O(n^3)$ computation complexity due to the matrix-matrix multiplications and matrix inversions, even if partial SVD is used. Moreover, introducing auxiliary variables also slows down the convergence. Such a heavy computation load prevents LRR from large scale applications. In this paper, we generalize ADM by linearizing the quadratic penalty term and allowing the penalty to change adaptively. We also propose a novel rule to update the penalty such that the convergence is fast. With our linearized ADM with adaptive penalty (LADMAP) method, it is unnecessary to introduce auxiliary variables and invert matrices. The matrix-matrix multiplications are further alleviated by using the skinny SVD representation technique. As a result, we arrive at an algorithm for LRR with complexity $O(rn^2)$, where $r$ is the rank of the representation matrix. Numerical experiments verify that for LRR our LADMAP method is much faster than state-of-the-art algorithms. Although we only present the results on LRR, LADMAP actually can be applied to solving more general convex programs.},
archivePrefix = {arXiv},
arxivId = {1109.0367},
author = {Lin, Zhouchen and Liu, Risheng and Su, Zhixun},
doi = {10.1007/s10107-007-0133-5},
eprint = {1109.0367},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin, Liu, Su - 2011 - Linearized Alternating Direction Method with Adaptive Penalty for Low-Rank Representation.pdf:pdf},
isbn = {9781618395993},
issn = {00255610},
number = {1},
pages = {1--9},
title = {{Linearized Alternating Direction Method with Adaptive Penalty for Low-Rank Representation}},
url = {http://arxiv.org/abs/1109.0367},
year = {2011}
}
@article{Wu2016,
abstract = {{\textcopyright} Copyright 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. In multi-label learning, there are two main challenges: missing labels and class imbalance (CIB). The former assumes that only a partial set of labels are provided for each training instance while other labels are missing. CIB is observed from two perspectives: first, the number of negative labels of each instance is much larger than its positive labels; second, the rate of positive instances (i.e. the number of positive instances divided by the total number of instances) of different classes are significantly different. Both missing labels and CIB lead to significant performance degradation. In this work, we propose a new method to handle these two challenges simultaneously. We formulate the problem as a constrained submodular minimization that is composed of a submodular objective function that encourages label consistency and smoothness, as well as, class cardinality bound constraints to handle class imbalance. We further present a convex approximation based on the Lovasz extension of submodular functions, leading to a linear program, which can be efficiently solved by the alternative direction method of multipliers (ADMM). Experimental results on several benchmark datasets demonstrate the improved performance of our method over several state-of-the-art methods.},
author = {Wu, Baoyuan and Ghanem, Bernard},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu, Ghanem - 2016 - Constrained Submodular Minimization Towards Missing Labels and Class Imbalance in Multi-label Learning ( Supplementa.pdf:pdf},
isbn = {9781577357605},
journal = {Proceedings of the 30th Conference on Artificial Intelligence (AAAI 2016)},
keywords = {Technical Papers: Machine Learning Methods},
pages = {2229--2236},
title = {{Constrained Submodular Minimization Towards Missing Labels and Class Imbalance in Multi-label Learning ( Supplementary Material )}},
year = {2016}
}
@article{Cabral2011,
abstract = {We develop and demonstrate automatic image description methods using a large captioned photo collection. One contribution is our technique for the automatic collection of this new dataset performing a huge number of Flickr queries and then filtering the noisy results down to 1 million images with associated visually relevant captions. Such a collection allows us to approach the extremely challenging problem of description generation using relatively simple non-parametric methods and produces surprisingly effective results. We also develop methods incorporating many state of the art, but fairly noisy, estimates of image content to produce even more pleasing results. Finally we introduce a new objective performance measure for image captioning.},
author = {Cabral, Ricardo S and De, Fernando and Jo{\~{a}}o, Torre and Bernardino, Alexandre},
doi = {10.1109/TPAMI.2014.2343234},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cabral et al. - 2011 - Matrix Completion for Multi-label Image Classification.pdf:pdf},
isbn = {9781618395993},
issn = {0162-8828},
journal = {Science},
number = {1},
pages = {1--9},
pmid = {26353213},
title = {{Matrix Completion for Multi-label Image Classification}},
url = {http://www.humansensing.cs.cmu.edu/projects/complete/nips2011.pdf},
volume = {6},
year = {2011}
}
@article{Hu2013,
abstract = {Recovering a large matrix from a small subset of its entries is a challenging problem arising in many real applications, such as image inpainting and recommender systems. Many existing approaches formulate this problem as a general low-rank matrix approximation problem. Since the rank operator is nonconvex and discontinuous, most of the recent theoretical studies use the nuclear norm as a convex relaxation. One major limitation of the existing approaches based on nuclear norm minimization is that all the singular values are simultaneously minimized, and thus the rank may not be well approximated in practice. In this paper, we propose to achieve a better approximation to the rank of matrix by truncated nuclear norm, which is given by the nuclear norm subtracted by the sum of the largest few singular values. In addition, we develop a novel matrix completion algorithm by minimizing the Truncated Nuclear Norm. We further develop three efficient iterative procedures, TNNR-ADMM, TNNR-APGL, and TNNR-ADMMAP, to solve the optimization problem. TNNR-ADMM utilizes the alternating direction method of multipliers (ADMM), while TNNR-AGPL applies the accelerated proximal gradient line search method (APGL) for the final optimization. For TNNR-ADMMAP, we make use of an adaptive penalty according to a novel update rule for ADMM to achieve a faster convergence rate. Our empirical study shows encouraging results of the proposed algorithms in comparison to the state-of-the-art matrix completion algorithms on both synthetic and real visual datasets.},
author = {Hu, Yao and Zhang, Debing and Ye, Jieping and Li, Xuelong and He, Xiaofei},
doi = {10.1109/TPAMI.2012.271},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu et al. - 2013 - Fast and accurate matrix completion via truncated nuclear norm regularization.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Matrix completion,accelerated proximal gradient method,alternating direction method of multipliers,nuclear norm minimization},
number = {9},
pages = {2117--2130},
pmid = {23868774},
title = {{Fast and accurate matrix completion via truncated nuclear norm regularization}},
volume = {35},
year = {2013}
}
@article{Alameda-Pineda2016,
abstract = {Advanced computer vision and machine learning techniques tried to automatically categorize the emotions elicited by abstract paintings with limited success. Since the annotation of the emotional content is highly resourceconsuming, datasets of abstract paintings are either constrained in size or partially annotated. Consequently, it is natural to address the targeted task within a transductive framework. Intuitively, the use of multi-label classification techniques is desirable so to synergically exploit the relations between multiple latent variables, such as emotional content, technique, author, etc. A very popular approach for transductive multi-label recognition under linear classification settings is matrix completion. In this study we introduce non-linear matrix completion (NLMC), thus extending classical linear matrix completion techniques to the non-linear case. Together with the theory grounding the model, we propose an efficient optimization solver. As shown by our extensive experimental validation on two publicly available datasets, NLMC outperforms state-of-the-art methods when recognizing emotions from abstract paintings.},
author = {Alameda-Pineda, Xavier and Ricci, Elisa and Yan, Yan and Sebe, Nicu},
doi = {10.1109/CVPR.2016.566},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alameda-Pineda et al. - 2016 - Recognizing Emotions from Abstract Paintings Using Non-Linear Matrix Completion.pdf:pdf},
isbn = {978-1-4673-8851-1},
issn = {10636919},
journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
pages = {5240--5248},
title = {{Recognizing Emotions from Abstract Paintings Using Non-Linear Matrix Completion}},
url = {http://ieeexplore.ieee.org/document/7780935/},
year = {2016}
}
@article{Shang2017,
abstract = {IEEE Network measures derived from empirical observations are often poor estimators of the true structure of system as it is impossible to observe all components and all interactions in many real world complex systems. Here, we study attack robustness of complex networks with data missing caused by: 1) a uniform random sampling and 2) a nonuniform random sampling. By introducing the subgraph robustness problem, we develop analytically a framework to investigate robustness properties of the two types of subgraphs under random attacks, localized attacks, and targeted attacks. Interestingly, we find that the benchmark models, such as Erd & #x0151;s-R & #x00E9;nyi graphs, random regular networks, and scale-free networks possess distinct characteristic subgraph robustness features. We show that the network robustness depends on several factors including network topology, attack mode, sampling method and the amount of data missing, generalizing some well-known robustness principles of complex networks. Our results offer insight into the structural effect of missing data in networks and highlight the significance of understanding different sampling processes and their consequences on attack robustness, which may be instrumental in designing robust systems.},
author = {Shang, Yilun},
doi = {10.1109/TSMC.2017.2733545},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shang - 2017 - Subgraph Robustness of Complex Networks Under Attacks.pdf:pdf},
isbn = {21682216 (ISSN)},
issn = {21682232},
journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
keywords = {Attack robustness,Complex networks,Complex systems,Robustness,Sampling methods,Social network services,complex networks,complex systems,sampling},
pages = {1--12},
title = {{Subgraph Robustness of Complex Networks Under Attacks}},
year = {2017}
}
@article{Kiraly2016,
abstract = {We propose an algebraic combinatorial framework for the problem of completing partially observed low-rank matrices. We show that the intrinsic properties of the problem, including which entries can be reconstructed, and the degrees of freedom in the reconstruction, do not depend on the values of the observed entries, but only on their position. We associate combinatorial and algebraic objects, differen- tials and matroids, which are descriptors of the particular reconstruction task, to the set of observed entries, and apply them to obtain reconstruction bounds. We show how similar techniques can be used to obtain reconstruction bounds on general compressed sensing problems with algebraic compression constraints. Using the new theory, we develop several algorithms for low-rank matrix completion, which allow to determine which set of entries can be potentially reconstructed and which not, and how, and we present algorithms which apply algebraic combinatorial methods in order to reconstruct the missing entries.},
archivePrefix = {arXiv},
arxivId = {1211.4116},
author = {Kir{\'{a}}ly, Franz J and Theran, Louis and Tomioka, Ryota and Uno, Takeaki},
eprint = {1211.4116},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kir{\'{a}}ly et al. - 2016 - The Algebraic Combinatorial Approach for Low-Rank Matrix Completion.pdf:pdf},
isbn = {1211.4116},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
number = {247029},
pages = {102},
title = {{The Algebraic Combinatorial Approach for Low-Rank Matrix Completion}},
url = {http://arxiv.org/abs/1211.4116},
volume = {16},
year = {2016}
}
@article{Goldberg2010,
abstract = {We pose transductive classification as a matrix completion problem. By assuming the underlying matrix has a low rank, our formulation is able to handle three problems simultaneously: i) multi-label learning, where each item has more than one label, ii) transduction, where most of these labels are unspecified, and iii) missing data, where a large number of features are missing. We obtained satisfactory results on several real-world tasks, suggesting that the low rank assumption may not be as restrictive as it seems. Our method allows for different loss functions to apply on the feature and label entries of the matrix. The resulting nuclear norm minimization problem is solved with a modified fixed-point continuation method that is guaranteed to find the global optimum.},
author = {Goldberg, a and Recht, Benjamin},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goldberg, Recht - 2010 - Transduction with matrix completion Three birds with one stone.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
pages = {1--9},
title = {{Transduction with matrix completion: Three birds with one stone}},
year = {2010}
}
@article{Candes2009,
abstract = {We consider a problem of considerable practical interest: the recovery of a data matrix from a sampling of its entries. Suppose that we observe m entries selected uniformly at random from a matrix M. Can we complete the matrix and recover the entries that we have not seen? We show that one can perfectly recover most low-rank matrices from what appears to be an incomplete set of entries. We prove that if the number m of sampled entries obeys m >= C n^{1.2} r log n for some positive numerical constant C, then with very high probability, most n by n matrices of rank r can be perfectly recovered by solving a simple convex optimization program. This program finds the matrix with minimum nuclear norm that fits the data. The condition above assumes that the rank is not too large. However, if one replaces the 1.2 exponent with 1.25, then the result holds for all values of the rank. Similar results hold for arbitrary rectangular matrices as well. Our results are connected with the recent literature on compressed sensing, and show that objects other than signals and images can be perfectly reconstructed from very limited information.},
archivePrefix = {arXiv},
arxivId = {0805.4471},
author = {Cand{\`{e}}s, Emmanuel J. and Recht, Benjamin},
doi = {10.1007/s10208-009-9045-5},
eprint = {0805.4471},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cand{\`{e}}s, Recht - 2009 - Exact matrix completion via convex optimization.pdf:pdf},
isbn = {0001-0782},
issn = {16153375},
journal = {Foundations of Computational Mathematics},
keywords = {Compressed sensing,Convex optimization,Decoupling,Duality in optimization,Low-rank matrices,Matrix completion,Noncommutative Khintchine inequality,Nuclear norm minimization,Random matrices},
number = {6},
pages = {717--772},
pmid = {45507089},
title = {{Exact matrix completion via convex optimization}},
volume = {9},
year = {2009}
}
@article{Soundarajan,
abstract = {No maaer how meticulously constructed, network datasets are ooen partially observed and incomplete. For example, most of the publicly available data from online social networking services (such as Facebook and Twiier) are collected via apps, users who make their accounts public, and/or the resources available to the researcher/practitioner. Such incompleteness can lead to inaccurate ndings. We introduce the Adaptive Edge Probing problem. Suppose that one has observed a networked phenomenon via some form of sampling and has a budget to enhance the incomplete network by asking for additional information about speciic nodes, with the ultimate goal of obtaining the most valuable information about the network as a whole. Which nodes should be further explored? We present ϵ-WGX, a network-based explore-exploit algorithm for identifying which nodes in the incomplete network to probe. Aggregated over multiple datasets and a wide range of probing budgets, we end that ϵ-WGX outperforms other explore-exploit strategies and baseline probing strategies. For example, for the task of adding as many nodes as possible, over incomplete networks observed via four popular sampling methods, ϵ-WGX outperforms the best comparison strategy by 12%-23% on average.},
author = {Soundarajan, Sucheta and Eliassi-Rad, Tina and Gallagher, Brian and Pinar, Ali},
doi = {10.1145/3091478.3091492},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soundarajan et al. - Unknown - ϵ-WGX Adaptive Edge Probing for Enhancing Incomplete Networks.pdf:pdf},
keywords = {adaptive probing,graph exploration,incomplete networks},
title = {{ϵ-WGX: Adaptive Edge Probing for Enhancing Incomplete Networks}}
}
@inproceedings{Soundarajan2016,
author = {Soundarajan, Sucheta and Eliassi-Rad, Tina and Gallagher, Brian and Pinar, Ali},
booktitle = {Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2016},
doi = {10.1109/ASONAM.2016.7752227},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soundarajan et al. - 2016 - MaxReach Reducing network incompleteness through node probes.pdf:pdf},
isbn = {9781509028467},
title = {{MaxReach: Reducing network incompleteness through node probes}},
year = {2016}
}
@article{Masrour,
abstract = {—This paper investigates the network completion problem, where it is assumed that only a small sample of a network (e.g., a complete or partially observed subgraph of a social graph) is observed and we would like to infer the unobserved part of the network. In this paper, we assume that besides the observed subgraph, side information about the nodes such as the pairwise similarity between them is also provided. In contrast to the original network completion problem where the standard methods such as matrix completion is inapplicable due the non-uniform sampling of observed links, we show that by effectively exploiting the side information, it is possible to accurately predict the unobserved links. In contrast to existing matrix completion methods with side information such as shared subsapce learning and matrix completion with transduction, the proposed algorithm decouples the completion from transduction to effectively exploit the similarity information. This crucial difference greatly boosts the performance when appropriate similarity information is used. The recovery error of the proposed algorithm is theoretically analyzed based on the richness of the similarity information and the size of the observed submatrix. To the best of our knowledge, this is the first algorithm that addresses the network completion with similarity of nodes with provable guarantees. Experiments on synthetic and real networks from Facebook and Google+ show that the proposed two-stage method is able to accurately reconstruct the network and outperforms other methods.},
author = {Masrour, Farzan and Barjesteh, Iman and Forsati, Rana and Esfahanian, Abdol-Hossein and Radha, Hayder},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Masrour et al. - Unknown - Network Completion with Node Similarity A Matrix Completion Approach with Provable Guarantees.pdf:pdf},
keywords = {Transduction,—Network and Matrix Completion},
title = {{Network Completion with Node Similarity: A Matrix Completion Approach with Provable Guarantees}}
}
@inproceedings{Kuhnle2017b,
author = {Kuhnle, Alan and Crawford, Victoria G. and Thai, My T.},
booktitle = {International Conference on Data Mining (ICDM)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhnle, Crawford, Thai - 2017 - Scalable and Adaptive Algorithms for the Triangle Interdiction Problem on Billion-Scale Networks.pdf:pdf},
title = {{Scalable and Adaptive Algorithms for the Triangle Interdiction Problem on Billion-Scale Networks}},
year = {2017}
}
@article{JMLR:v18:16-391,
author = {Durante, Daniele and Mukherjee, Nabanita and Steorts, Rebecca C},
journal = {Journal of Machine Learning Research},
number = {43},
pages = {1--29},
title = {{Bayesian Learning of Dynamic Multilayer Networks}},
url = {http://jmlr.org/papers/v18/16-391.html},
volume = {18},
year = {2017}
}
@inproceedings{10.1007/978-3-319-33461-5_27,
abstract = {The problem of maximizing non-negative monotone submodular functions under a certain constraint has been intensively studied in the last decade. In this paper, we address the problem for functions defined over the integer lattice.},
address = {Cham},
author = {Soma, Tasuku and Yoshida, Yuichi},
booktitle = {Integer Programming and Combinatorial Optimization},
editor = {Louveaux, Quentin and Skutella, Martin},
isbn = {978-3-319-33461-5},
pages = {325--336},
publisher = {Springer International Publishing},
title = {{Maximizing Monotone Submodular Functions over the Integer Lattice}},
year = {2016}
}
@incollection{NIPS2017_6652,
author = {Bian, An and Levy, Kfir and Krause, Andreas and Buhmann, Joachim M},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {Guyon, I and Luxburg, U V and Bengio, S and Wallach, H and Fergus, R and Vishwanathan, S and Garnett, R},
pages = {486--496},
publisher = {Curran Associates, Inc.},
title = {{Non-monotone Continuous DR-submodular Maximization: Structure and Algorithms}},
url = {http://papers.nips.cc/paper/6652-non-monotone-continuous-dr-submodular-maximization-structure-and-algorithms.pdf},
year = {2017}
}
@inproceedings{Bian2017a,
abstract = {DR-submodular continuous functions are important objectives with wide real-world applications spanning MAP inference in determinantal point processes (DPPs), and mean-field inference for probabilistic submodular models, amongst others. DR-submodularity captures a subclass of non-convex functions that enables both exact minimization and approximate maximization in polynomial time. In this work we study the problem of maximizing non-monotone DR-submodular continuous functions under general down-closed convex constraints. We start by investigating geometric properties that underlie such objectives, e.g., a strong relation between (approximately) stationary points and global optimum is proved. These properties are then used to devise two optimization algorithms with provable guarantees. Concretely, we first devise a "two-phase" algorithm with $1/4$ approximation guarantee. This algorithm allows the use of existing methods for finding (approximately) stationary points as a subroutine, thus, harnessing recent progress in non-convex optimization. Then we present a non-monotone Frank-Wolfe variant with $1/e$ approximation guarantee and sublinear convergence rate. Finally, we extend our approach to a broader class of generalized DR-submodular continuous functions, which captures a wider spectrum of applications. Our theoretical findings are validated on synthetic and real-world problem instances.},
archivePrefix = {arXiv},
arxivId = {1711.02515},
author = {Bian, An and Levy, Kfir Y. and Krause, Andreas and Buhmann, Joachim M.},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
eprint = {1711.02515},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bian et al. - 2017 - Non-monotone Continuous DR-submodular Maximization Structure and Algorithms.pdf:pdf},
pages = {486--496},
title = {{Non-monotone Continuous DR-submodular Maximization: Structure and Algorithms}},
url = {http://arxiv.org/abs/1711.02515 http://papers.nips.cc/paper/6652-non-monotone-continuous-dr-submodular-maximization-structure-and-algorithms.pdf},
year = {2017}
}
@inproceedings{Soma2015a,
abstract = {The problem of maximizing non-negative monotone submodular functions under a certain constraint has been intensively studied in the last decade. In this paper, we address the problem for functions defined over the integer lattice. Suppose that a non-negative monotone submodular function $f:\mathbb{Z}_+^n \to \mathbb{R}_+$ is given via an evaluation oracle. Assume further that $f$ satisfies the diminishing return property, which is not an immediate consequence of submodularity when the domain is the integer lattice. Given this, we design polynomial-time $(1-1/e-\epsilon)$-approximation algorithms for a cardinality constraint, a polymatroid constraint, and a knapsack constraint. For a cardinality constraint, we also provide a $(1-1/e-\epsilon)$-approximation algorithm with slightly worse time complexity that does not rely on the diminishing return property.},
address = {Cham},
archivePrefix = {arXiv},
arxivId = {1503.01218},
author = {Soma, Tasuku and Yoshida, Yuichi},
booktitle = {Integer Programming and Combinatorial Optimization},
editor = {Louveaux, Quentin and Skutella, Martin},
eprint = {1503.01218},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soma, Yoshida - 2015 - Maximizing Monotone Submodular Functions over the Integer Lattice.pdf:pdf},
isbn = {978-3-319-33461-5},
keywords = {dr-submodular functions,integer lattice,submodular functions},
pages = {325--336},
publisher = {Springer International Publishing},
title = {{Maximizing Monotone Submodular Functions over the Integer Lattice}},
url = {http://arxiv.org/abs/1503.01218},
year = {2016}
}
@article{Bai2016,
abstract = {We investigate a new optimization problem involving minimizing the Ratio of Submodular (RS) functions. We argue that this problem occurs naturally in several real world applications. We then show the connection between this problem and several related problems, including minimizing the difference of submodular functions, and to submodular optimization subject to submodular constraints. We show RS that optimization can be solved within bounded approximation factors. We also provide a hardness bound and show that our tightest algorithm matches the lower bound up to a \log factor. Finally, we empirically demonstrate the performance and good scalability properties of our algorithms.},
author = {Bai, Wenruo and Iyer, Rishabh and Wei, Kai and Bilmes, Jeff},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bai et al. - 2016 - Algorithms for Optimizing the Ratio of Submodular Functions.pdf:pdf},
isbn = {9781510829008},
journal = {Proceedings of The 33rd International Conference on Machine Learning},
pages = {2751--2759},
title = {{Algorithms for Optimizing the Ratio of Submodular Functions}},
url = {http://proceedings.mlr.press/v48/baib16.html},
volume = {48},
year = {2016}
}
@article{Narasimhan2005,
abstract = {In this paper, we present an algorithm for minimizing the difference between two sub-modular functions using a variational frame-work which is based on (an extension of) the concave-convex procedure [17]. Because several commonly used metrics in machine learning, like mutual information and con-ditional mutual information, are submodu-lar, the problem of minimizing the differ-ence of two submodular problems arises natu-rally in many machine learning applications. Two such applications are learning discrimi-natively structured graphical models and fea-ture selection under computational complex-ity constraints. A commonly used metric for measuring discriminative capacity is the EAR measure which is the difference between two conditional mutual information terms. Feature selection taking complexity consider-ations into account also fall into this frame-work because both the information that a set of features provide and the cost of comput-ing and using the features can be modeled as submodular functions. This problem is NP-hard, and we give a polynomial time heuris-tic for it. We also present results on synthetic data to show that classifiers based on discrim-inative graphical models using this algorithm can significantly outperform classifiers based on generative graphical models.},
archivePrefix = {arXiv},
arxivId = {1207.1404},
author = {Narasimhan, Mukund and Bilmes, Ja},
eprint = {1207.1404},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Narasimhan, Bilmes - 2005 - A submodular-supermodular procedure with applications to discriminative structure learning.pdf:pdf},
isbn = {0-9749039-1-4},
journal = {Proceedings of the 21st Conference on Uncertainty in Artificial Intelligence},
pages = {404--412},
title = {{A submodular-supermodular procedure with applications to discriminative structure learning}},
url = {http://arxiv.org/abs/1207.1404},
year = {2005}
}
@article{Gottschalk2015,
abstract = {The problem of maximizing non-negative submodular functions has been studied extensively in the last few years. However, most papers consider submodular set functions. Recently, several advances have been made for the more general case of submodular functions on the integer lattice. In this paper, we present a deterministic $\frac{1}{3}$-approximation for maximizing a submodular function on a bounded integer lattice $\{0, \ldots, C\}^n$ using a Double Greedy framework. Moreover, we show that the analysis is tight and that other ideas used for approximating set functions cannot easily be extended. In contrast to set functions, submodularity on the integer lattice does not imply the so-called diminishing returns property. Assuming this property, it was shown that many results for set functions can also be obtained for the integer lattice. In this paper, we consider a further generalization. Instead of the integer lattice, we consider a distributive lattice as the function domain and assume the diminishing returns (DR) property. On the one hand, we show that some approximation algorithms match the set functions setting. In particular, we can obtain a $\frac{1}{2}$-approximation for unconstrained maximization, a $(1-\frac{1}{e})$-approximation for monotone functions under a cardinality constraint and a $\frac{1}{2}$-approximation for a poset matroid constraint. On the other hand, for a knapsack constraint, the problem becomes significantly harder: even for monotone DR-submodular functions, we show that there is no $2^{(\log (n^{1/2} - 1))^\delta - 1}$-approximation for every $\delta > 0$ under the assumption that $3-SAT$ cannot be solved in time $2^{n^{3/4 + \epsilon}}$.},
archivePrefix = {arXiv},
arxivId = {1505.05423},
author = {Gottschalk, Corinna and Peis, Britta},
eprint = {1505.05423},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gottschalk, Peis - 2016 - Submodular Function Maximization over Distributive and Integer Lattices.pdf:pdf},
journal = {arXiv preprint arXiv:1505:05423},
title = {{Submodular Function Maximization over Distributive and Integer Lattices}},
url = {http://arxiv.org/abs/1505.05423},
year = {2016}
}
@inproceedings{Mirzasoleiman2014,
abstract = {Is it possible to maximize a monotone submodular function faster than the widely used lazy greedy algorithm (also known as accelerated greedy), both in theory and practice? In this paper, we develop the first linear-time algorithm for maximizing a general monotone submodular function subject to a cardinality constraint. We show that our randomized algorithm, STOCHASTIC-GREEDY, can achieve a $(1-1/e-\varepsilon)$ approximation guarantee, in expectation, to the optimum solution in time linear in the size of the data and independent of the cardinality constraint. We empirically demonstrate the effectiveness of our algorithm on submodular functions arising in data summarization, including training large-scale kernel methods, exemplar-based clustering, and sensor placement. We observe that STOCHASTIC-GREEDY practically achieves the same utility value as lazy greedy but runs much faster. More surprisingly, we observe that in many practical scenarios STOCHASTIC-GREEDY does not evaluate the whole fraction of data points even once and still achieves indistinguishable results compared to lazy greedy.},
archivePrefix = {arXiv},
arxivId = {1409.7938},
author = {Mirzasoleiman, Baharan and Badanidiyuru, Ashwinkumar and Karbasi, Amin and Vondrak, Jan and Krause, Andreas},
booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
eprint = {1409.7938},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mirzasoleiman et al. - 2015 - Lazier Than Lazy Greedy.pdf:pdf},
isbn = {9781577357018},
title = {{Lazier Than Lazy Greedy}},
url = {http://arxiv.org/abs/1409.7938},
year = {2015}
}
@inproceedings{Iyer2012,
abstract = {We extend the work of Narasimhan and Bilmes [30] for minimizing set functions representable as a difference between submodular functions. Similar to [30], our new algorithms are guaranteed to monotonically reduce the objective function at every step. We empirically and theoretically show that the per-iteration cost of our algorithms is much less than [30], and our algorithms can be used to efficiently minimize a difference between submodular functions under various combinatorial constraints, a problem not previously addressed. We provide computational bounds and a hardness result on the mul- tiplicative inapproximability of minimizing the difference between submodular functions. We show, however, that it is possible to give worst-case additive bounds by providing a polynomial time computable lower-bound on the minima. Finally we show how a number of machine learning problems can be modeled as minimizing the difference between submodular functions. We experimentally show the validity of our algorithms by testing them on the problem of feature selection with submodular cost features.},
archivePrefix = {arXiv},
arxivId = {1207.0560},
author = {Iyer, Rishabh and Bilmes, Jeff},
booktitle = {Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence},
eprint = {1207.0560},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iyer, Bilmes - 2012 - Algorithms for Approximate Minimization of the Difference Between Submodular Functions, with Applications.pdf:pdf},
isbn = {9780974903989},
title = {{Algorithms for Approximate Minimization of the Difference Between Submodular Functions, with Applications}},
url = {http://arxiv.org/abs/1207.0560},
year = {2012}
}
@article{Wang2016,
author = {Wang, Daniel and Luse, Andy and Burkman, Jim},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Luse, Burkman - 2016 - Dynamic Visualization of Time-Based Changes to Data Generated by Reddit . com The Real Time Conversation P.pdf:pdf},
journal = {American Journal of Undergraduate Research},
keywords = {gephi,network analysis,reddit,social network,visualization},
number = {4},
pages = {59--68},
title = {{Dynamic Visualization of Time-Based Changes to Data Generated by Reddit . com : The Real Time Conversation Project}},
volume = {13},
year = {2016}
}
@article{Maehara2015,
author = {Maehara, Takanori},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maehara - 2015 - Budget Allocation Problem with Multiple Advertisers A Game Theoretic View.pdf:pdf},
isbn = {9781510810587},
journal = {Icml},
title = {{Budget Allocation Problem with Multiple Advertisers : A Game Theoretic View}},
year = {2015}
}
@article{Demaine2014,
abstract = {We study the power of fractional allocations of resources to maximize influence in a network. This work extends in a natural way the well-studied model by Kempe, Kleinberg, and Tardos (2003), where a designer selects a (small) seed set of nodes in a social network to influence directly, this influence cascades when other nodes reach certain thresholds of neighbor influence, and the goal is to maximize the final number of influenced nodes. Despite extensive study from both practical and theoretical viewpoints, this model limits the designer to a binary choice for each node, with no way to apply intermediate levels of influence. This model captures some settings precisely, e.g. exposure to an idea or pathogen, but it fails to capture very relevant concerns in others, for example, a manufacturer promoting a new product by distributing five "20% off" coupons instead of giving away one free product. While fractional versions of problems tend to be easier to solve than integral versions, for influence maximization, we show that the two versions have essentially the same computational complexity. On the other hand, the two versions can have vastly different solutions: the added flexibility of fractional allocation can lead to significantly improved influence. Our main theoretical contribution is to show how to adapt the major positive results from the integral case to the fractional case. Specifically, Mossel and Roch (2006) used the submodularity of influence to obtain their integral results; we introduce a new notion of continuous submodularity, and use this to obtain matching fractional results. We conclude that we can achieve the same greedy $(1-1/e-\epsilon)$-approximation for the fractional case as the integral case. In practice, we find that the fractional model performs substantially better than the integral model, according to simulations on real-world social network data.},
archivePrefix = {arXiv},
arxivId = {1401.7970},
author = {Demaine, Erik D. and Hajiaghayi, Mohammad T. and Mahini, Hamid and Malec, David L. and Raghavan, S. and Sawant, Anshul and Zadimoghadam, Morteza},
doi = {10.1145/2566486.2568039},
eprint = {1401.7970},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Demaine et al. - 2014 - How to Influence People with Partial Incentives.pdf:pdf},
isbn = {9781450327442},
journal = {Proceedings of the 23rd International Conference on World Wide Web (WWW)},
keywords = {fractional,influence maximization,social networks,submodularity},
pages = {937--948},
title = {{How to Influence People with Partial Incentives}},
url = {http://dl.acm.org/citation.cfm?id=2568039},
year = {2014}
}
@article{Krause2008a,
abstract = {The problem of deploying sensors in a large water distribution network is considered, in order to detect the malicious introduction of contaminants. It is shown that a large class of realistic objective functions-such as reduction of detection time and the population protected from consuming contaminated water-exhibits an important diminishing returns effect called submodularity. The submodularity of these objectives is exploited in order to design efficient placement algorithms with provable performance guarantees. The algorithms presented in this paper do not rely on mixed integer programming, and scale well to networks of arbitrary size. The problem instances considered in the approach presented in this paper are orders of magnitude (a factor of 72) larger than the largest problems solved in the literature. It is shown how the method presented here can be extended to multicriteria optimization, selecting placements robust to sensor failures and optimizing minimax criteria. Extensive empirical evidence on the effectiveness of the method presented in this paper on two benchmark distribution networks, and an actual drinking water distribution system of greater than 21,000 nodes, is presented.},
author = {Krause, Andreas and Leskovec, Jure and Guestrin, Carlos and VanBriesen, Jeanne M. and Faloutsos, Christos},
doi = {10.1061/(ASCE)0733-9496(2008)134:6(516)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krause et al. - 2008 - Efficient sensor placement optimization for securing large water distribution networks.pdf:pdf},
isbn = {0733-9496},
issn = {0733-9496/2008/6-516–526},
journal = {Journal of Water Resources Planning and Management},
keywords = {Algorithms,Optimization,Water distribution systems,Water pollution},
number = {6},
pages = {516--526},
title = {{Efficient sensor placement optimization for securing large water distribution networks}},
url = {http://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-9496(2008)134:6(516)},
volume = {134},
year = {2008}
}
@article{Muggli2017,
abstract = {Recently, there has been significant amount of effort in developing space-efficient and succinct data structures for storing and building the traditional de Bruijn graph and its variants, including the colored de Bruijn graph. However, a problem not yet considered is developing a means to merge succinct representations of the de Bruijn graph\---|a challenge is necessary for constructing the de Bruijn graph on very-large datasets. We create VARIMERGE, for building the colored de Bruijn graph on a very-large dataset through partitioning the data into smaller subsets, building the colored de Bruijn graph using a FM-index based representation, and merging these representations in an iterative format. This last step is an algorithmic challenge for which we present an algorithm in this paper. Lastly, we demonstrate the utility of VARIMERGE by demonstrating: a four-fold reduction in working space when constructing an 8,000 color dataset, and the construction of population graph two orders of magnitude larger than previous reported methods.},
author = {Muggli, Martin D and Boucher, Christina},
doi = {10.1101/229641},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Muggli, Boucher - 2017 - Succinct De Bruijn Graph Construction for Massive Populations Through Space-Efficient Merging.pdf:pdf},
journal = {bioRxiv},
pages = {229641},
title = {{Succinct De Bruijn Graph Construction for Massive Populations Through Space-Efficient Merging}},
url = {https://www.biorxiv.org/content/early/2017/12/06/229641},
year = {2017}
}
@inproceedings{Feige2013,
author = {Feige, Uriel and Izsak, Rani},
booktitle = {Proceedings of the 4th conference on Innovations in Theoretical Computer Science (ITCS)},
doi = {10.1145/2422436.2422466},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feige, Izsak - 2013 - Welfare Maximization and the Supermodular Degree.pdf:pdf},
isbn = {9781450318594},
keywords = {approximation algorithms,combinatorial auctions,submod-},
pages = {247--256},
title = {{Welfare Maximization and the Supermodular Degree}},
url = {http://dl.acm.org/citation.cfm?doid=2422436.2422466},
year = {2013}
}
@article{Ene2016,
abstract = {A function f : Z E + → R + is DRsubmodular if it satisfies f (x+$\chi$ i)−f (x) ≥ f (y+$\chi$ i)−f (y) for all x ≤ y, i ∈ E. Recently, the problem of maximizing a DRsubmodular function f : Z E + → R + subject to a budget constraint 1 ≤ B as well as additional constraints has received significant attention [6, 7, 5, 8]. In this note, we give a generic reduction from the DRsubmodular setting to the submodular setting. The running time of the reduction and the size of the resulting submodular instance depends only logarithmically on B. Using this reduction, one can translate the results for unconstrained and constrained submodular maximization to the DRsubmodular setting for many types of constraints in a unified manner.},
archivePrefix = {arXiv},
arxivId = {arXiv:1606.08362v1},
author = {Ene, Alina and Nguyen, Huy L.},
eprint = {arXiv:1606.08362v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ene, Nguyen - 2016 - A Reduction for Optimizing Lattice Submodular Functions with Diminishing Returns.pdf:pdf},
journal = {arXiv preprint arXiv:1606.08362v1},
title = {{A Reduction for Optimizing Lattice Submodular Functions with Diminishing Returns}},
year = {2016}
}
@inproceedings{Krause2008,
abstract = {When monitoring spatial phenomena, which can often be modeled as Gaussian processes (GPs), choosing sensor locations is a fundamental task. There are several common strategies to address this task, for example, geometry or disk models, placing sensors at the points of highest entropy (vari-ance) in the GP model, and A-, D-, or E-optimal design. In this paper, we tackle the combinatorial optimization problem of maximizing the mutual information between the chosen locations and the locations which are not selected. We prove that the problem of finding the configuration that max-imizes mutual information is NP-complete. To address this issue, we describe a polynomial-time approximation that is within (1 − 1/e) of the optimum by exploiting the submodularity of mutual information. We also show how submodularity can be used to obtain online bounds, and design branch and bound search procedures. We then extend our algorithm to exploit lazy evaluations and local structure in the GP, yielding significant speedups. We also extend our approach to find placements which are robust against node failures and uncertainties in the model. These extensions are again associated with rigorous theoretical approximation guarantees, exploiting the submodu-larity of the objective function. We demonstrate the advantages of our approach towards optimizing mutual information in a very extensive empirical study on two real-world data sets.},
author = {Krause, Andreas and Singh, Ajit and Guestrin, Carlos},
booktitle = {Journal of Machine Learning Research},
doi = {10.1145/1102351.1102385},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krause, Singh, Guestrin - 2008 - Near-Optimal Sensor Placements in Gaussian Processes Theory, Efficient Algorithms and Empirical Studies.pdf:pdf},
isbn = {1390681139},
issn = {15324435},
keywords = {Gaussian processes,active learning,experimental design,sensor networks,spatial learning},
pages = {235--284},
title = {{Near-Optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies}},
volume = {9},
year = {2008}
}
@article{Borodin2014,
abstract = {Submodular functions are well-studied in combinatorial optimization, game theory and economics. The natural diminishing returns property makes them suitable for many applications. We study an extension of monotone submodular functions, which we call weekly submodular functions. We show several natural functions belong to this class. We study optimization problem of maximizing a weakly submodular function subject to uniform matroid and general matroid constraints. For uniform matroid constraint, the "standard greedy algorithm" achieves an approximation ratio 5.95. For general matroid constraint, a simple local search algorithm achieves a constant approximation ratio where the constant converges to 10.22 as the rank of the matroid increases.},
archivePrefix = {arXiv},
arxivId = {1401.6697},
author = {Borodin, Allan and Le, Dai Tri Man and Ye, Yuli},
eprint = {1401.6697},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Borodin, Le, Ye - 2014 - Weakly Submodular Functions.pdf:pdf},
journal = {arXiv preprint arXiv:1401.6697},
keywords = {altera corporation,amazon,amazon inc,bor,com,cs,dept of computer science,edu,greedy algorithms,ledt,local search,max-sum dispersion,science,submodular functions,the department of computer,toronto,university of toronto,work done while at,yeyuli},
title = {{Weakly Submodular Functions}},
url = {http://arxiv.org/abs/1401.6697},
year = {2014}
}
@article{Vondrak2008,
abstract = {In the Submodular Welfare Problem, m items are to be distributed among n players with utility functions wi: 2[m] → R+. The utility functions are assumed to be monotone and submodular. Assuming that player i receives a set of items Si, we wish to maximize the total utility \Sigmai=1n wi(Si). In this paper, we work in the value oracle model where the only access to the utility functions is through a black box returning wi(S) for a given set S. Submodular Welfare is in fact a special case of the more general problem of submodular maximization subject to a matroid constraint: maxf(S): S ∈ I, where f is monotone submodular and I is the collection of independent sets in some matroid. For both problems, a greedy algorithm is known to yield a 1/2-approximation [21, 16]. In special cases where the matroid is uniform (I = S: \textbarS\textbar ≤ k) [20] or the submodular function is of a special type [4, 2], a (1-1/e)-approximation has been achieved and this is optimal for these problems in the value oracle model [22, 6, 15]. A (1-1/e)-approximation for the general Submodular Welfare Problem has been known only in a stronger demand oracle model [4], where in fact 1-1/e can be improved [9]. In this paper, we develop a randomized continuous greedy algorithm which achieves a (1-1/e)-approximation for the Submodular Welfare Problem in the value oracle model. We also show that the special case of n equal players is approximation resistant, in the sense that the optimal (1-1/e)-approximation is achieved by a uniformly random solution. Using the pipage rounding technique [1, 2], we obtain a (1-1/e)-approximation for submodular maximization subject to any matroid constraint. The continuous greedy algorithm has a potential of wider applicability, which we demonstrate on the examples of the Generalized Assignment Problem and the AdWords Assignment Problem.},
author = {Vondrak, Jan},
doi = {10.1145/1374376.1374389},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vondrak - 2008 - Optimal approximation for the submodular welfare problem in the value oracle model.pdf:pdf},
isbn = {9781605580470},
issn = {07378017},
journal = {Proceedings of the fourtieth annual ACM symposium on Theory of computing - STOC 08},
keywords = {combinatorial auctions,matroids,submodular functions},
pages = {67},
title = {{Optimal approximation for the submodular welfare problem in the value oracle model}},
url = {http://dl.acm.org/citation.cfm?doid=1374376.1374389},
year = {2008}
}
@article{Lehmann2006,
abstract = {In most of microeconomic theory, consumers are assumed to exhibit decreasing marginal utilities. This paper considers combinatorial auctions among such submodular buyers. The valuations of such buyers are placed within a hierarchy of valuations that exhibit no complementarities, a hierarchy that includes also OR and XOR combinations of singleton valuations, and valuations satisfying the gross substitutes property. Those last valuations are shown to form a zero-measure subset of the submodular valuations that have positive measure. While we show that the allocation problem among submodular valuations is NP-hard, we present an efficient greedy 2-approximation algorithm for this case and generalize it to the case of limited complementarities. No such approximation algorithm exists in a setting allowing for arbitrary complementarities. Some results about strategic aspects of combinatorial auctions among players with decreasing marginal utilities are also presented. {\textcopyright} 2005 Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {cs/0202015},
author = {Lehmann, Benny and Lehmann, Daniel and Nisan, Noam},
doi = {10.1016/j.geb.2005.02.006},
eprint = {0202015},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lehmann, Lehmann, Nisan - 2006 - Combinatorial auctions with decreasing marginal utilities.pdf:pdf},
isbn = {1581133871},
issn = {08998256},
journal = {Games and Economic Behavior},
keywords = {Combinatorial auctions,Decreasing marginal utilities,Winner determination},
number = {2},
pages = {270--296},
primaryClass = {cs},
title = {{Combinatorial auctions with decreasing marginal utilities}},
volume = {55},
year = {2006}
}
@article{Das2012,
author = {Das, Abhimanyu and Dasgupta, a and Kumar, R},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Das, Dasgupta, Kumar - 2012 - Selecting Diverse Features via Spectral Regularization.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
journal = {Nips},
pages = {1--9},
title = {{Selecting Diverse Features via Spectral Regularization.}},
url = {https://papers.nips.cc/paper/4689-selecting-diverse-features-via-spectral-regularization.pdf},
year = {2012}
}
@article{Krause2010,
abstract = {We consider the problem of extracting infor-mative exemplars from a data stream. Ex-amples of this problem include exemplar-based clustering and nonparametric inference such as Gaussian process regression on mas-sive data sets. We show that these prob-lems require maximization of a submodular function that captures the informativeness of a set of exemplars, over a data stream. We develop an efficient algorithm, Stream-Greedy, which is guaranteed to obtain a constant fraction of the value achieved by the optimal solution to this NP-hard optimiza-tion problem. We extensively evaluate our algorithm on large real-world data sets.},
author = {Krause, Andreas and Gomes, Ryan G},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krause, Gomes - 2010 - Budgeted nonparametric learning from data streams.pdf:pdf},
isbn = {9781605589077},
journal = {Icml},
pages = {391--398},
title = {{Budgeted nonparametric learning from data streams}},
url = {https://s3.amazonaws.com/academia.edu.documents/30760193/icml-budget-long.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1512629470&Signature=EtbAAh8kDmgjW51Xk3ysmhId3sE%3D&response-content-disposition=inline%3B filename%3DBudgeted_nonparametric_learning},
year = {2010}
}
@inproceedings{Soma2014,
abstract = {Abstract We consider the budget allocation problem over bipartite influence model proposed by Alon et al. This problem can be viewed as the well-known influence maximization problem with budget constraints. We first show that this problem and its much more ... \n},
author = {Soma, Tasuku and Kakimura, Naonori and Inaba, Kazuhiro and Ken-ichi, Kawarabayashi},
booktitle = {International Conference on Machine Learning (ICML)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soma et al. - 2014 - Optimal Budget Allocation Theoretical Guarantee and Efficient Algorithm.pdf:pdf},
isbn = {9781634393973},
keywords = {submodular},
pages = {351--359},
title = {{Optimal Budget Allocation: Theoretical Guarantee and Efficient Algorithm}},
url = {http://jmlr.org/proceedings/papers/v32/soma14.html%5Cnpapers3://publication/uuid/E0072966-60F0-4BE3-8E5E-75689F85E877},
volume = {32},
year = {2014}
}
@article{Alon2012,
abstract = {Brands and agencies use marketing as a tool to influence customers. One of the major decisions in a marketing plan deals with the allocation of a given budget among media channels in order to maximize the impact on a set of potential customers. A similar situation occurs in a social network, where a marketing budget needs to be distributed among a set of potential influencers in a way that provides high-impact. We introduce several probabilistic models to capture the above scenarios. The common setting of these models consists of a bipartite graph of source and target nodes. The objective is to allocate a fixed budget among the source nodes to maximize the expected number of influenced target nodes. The concrete way in which source nodes influence target nodes depends on the underlying model. We primarily consider two models: a source-side influence model, in which a source node that is allocated a budget of k makes k independent trials to influence each of its neighboring target nodes, and a target-side influence model, in which a target node becomes influenced according to a specified rule that depends on the overall budget allocated to its neighbors. Our main results are an optimal (1 - 1/e)-approximation algorithm for the source-side model, and several inapproximability results for the target-side model, establishing that influence maximization in the latter model is provably harder.},
author = {Alon, Noga and Gamzu, Iftah and Tennenholtz, Moshe},
doi = {10.1145/2187836.2187888},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alon, Gamzu, Tennenholtz - 2012 - Optimizing budget allocation among channels and influencers.pdf:pdf},
isbn = {9781450312295},
journal = {Proceedings of the 21st International Conference on World Wide Web (WWW)},
keywords = {approximation algorithms,budget allocation,influence mod-},
pages = {381--388},
title = {{Optimizing budget allocation among channels and influencers}},
url = {http://dl.acm.org/citation.cfm?doid=2187836.2187888},
year = {2012}
}
@article{Goyal2011,
author = {Goyal, Amit and Lu, Wei and Lakshmanan, Laks V.S.},
doi = {10.1145/1963192.1963217},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goyal, Lu, Lakshmanan - 2011 - Celf.pdf:pdf},
isbn = {9781450306379},
journal = {Proceedings of the 20th international conference companion on World wide web - WWW '11},
keywords = {celf,greedy algorithm,influence propagation,marketing,social networks,submodularity,viral},
pages = {47},
title = {{Celf++}},
url = {http://portal.acm.org/citation.cfm?doid=1963192.1963217},
year = {2011}
}
@article{Huang2017,
author = {Huang, Keke and Wang, Sibo and Bevilacqua, Glenn and Xiao, Xiaokui and Lakshmanan, Laks V S},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2017 - Revisiting the Stop-and-Stare Algorithms for Influence Maximization.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
number = {9},
pages = {913--924},
title = {{Revisiting the Stop-and-Stare Algorithms for Influence Maximization}},
volume = {10},
year = {2017}
}
@inproceedings{Pan2017,
abstract = {Although influence propagation of Online Social Networks (OSNs) is widely studied in literature, none of the existing works can cope with the situation that the propagation rate dynamically increases for popular topics. Instead, they all assumed known rates (either constants or drawn from known distributions) for influence propagation models. However, such models cannot correctly describe influence diffusion in reality. In this paper, we propose a novel model, Dynamic Influence Propagation (DIP), that allows propagation rate to change during the diffusion, based on which we define a new problem: Threshold Activation Problem under DIP (TAP-DIP), which adds another layer of complexity over the already \#P-Hard TAP problem. Despite the hardness of TAP-DIP, we are able to design a Lipschitz Optimization scheme (LOS) that can solve TAP-DIP with $O(\log|V|)$ ratio where $V$ is the set of nodes in the OSN. Using various real OSN datasets, we experimentally demonstrate that LOS not only generates high-quality yet much smaller seed sets when being aware of the rate increase, but also scalable.},
archivePrefix = {arXiv},
arxivId = {1702.01844},
author = {Pan, Tianyi and Kuhnle, Alan and Li, Xiang and Thai, My T.},
booktitle = {International Conference on Data Mining (ICDM)},
eprint = {1702.01844},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pan et al. - 2017 - Popular Topics Spread Faster New Dimension for Influence Propagation in Online Social Networks.pdf:pdf},
pages = {1--11},
title = {{Popular Topics Spread Faster: New Dimension for Influence Propagation in Online Social Networks}},
url = {http://arxiv.org/abs/1702.01844},
year = {2017}
}
@article{Kuhnleb,
author = {Kuhnle, Alan and Alim, Abdul and Thai, My T},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhnle, Alim, Thai - Unknown - Multiplex Influence Maximization in Online Social Networks with Heterogeneous Diffusion Models(3).pdf:pdf},
number = {Ic},
title = {{Multiplex Influence Maximization in Online Social Networks with Heterogeneous Diffusion Models}}
}
@inproceedings{Zhang2016d,
abstract = {{\textcopyright} 2016 IEEE. Information propagation in online social networks (OSNs), which helps shaping consumers' purchasing decisions, has received a lot of attention. The ultimate goal of marketing and advertising in OSNs is to massively influence audiences and enlarge the number of product adoptions. Most of existing works focus on maximizing the influence of a single product or promoting the adoption of one product in competing campaigns. However, in reality, the majority of companies produce various products for supplying customers with different needs. Therefore, it is truly significant and also challenging to wisely distribute limited budget across multiple products in viral marketing. In this paper, we investigate a Profit Maximization with Multiple Adoptions (PM2A) problem, which aims at maximizing the overall profit across all products. The natural greedy fails to provide a bounded result. In order to select high quality seeds for information propagation, we first proposed the PMCE algorithm, which has a ratio 1/2 (1 - 1/e2). Moreover, we further improve this ratio to (1-1/e) by proposing the PMIS algorithm. Comprehensive experiments on three real social networks are conducted. And results show that our algorithms outperform other heuristics, and better distribute the budget in terms of profit maximization.},
author = {Zhang, H. and Zhang, H. and Kuhnle, A. and Thai, M.T.},
booktitle = {Proceedings - IEEE INFOCOM},
doi = {10.1109/INFOCOM.2016.7524470},
isbn = {9781467399531},
issn = {0743166X},
keywords = {Approximation Algorithm,Social Networks,Viral Marketing},
title = {{Profit maximization for multiple products in online social networks}},
volume = {2016-July},
year = {2016}
}
@inproceedings{Zhang2016c,
abstract = {{\textcopyright} 2016 IEEE. While online social networks provide access to a massive information source, they also enable wide dissemination of false or inaccurate content. Undesirable results caused by misinformation propagation make its timely detection very imperative. An important question is how many monitors are required to detect all misinformation cascades at their early stage. To answer this question, we define a Time Constrained Misinformation Detection (TCMD) problem. As we have proved, there is no polynomial time (1 - ϵ) ln n-approximation for the TCMD problem. The large number of independent misinformation cascades and heterogeneous delays make misinformation detection more challenging. Our approach includes stochastic programming and an O(ln(1 + n)) approximation algorithm for one-hop detection. This approach can provide a lower bound on the number of required monitors for general detection. Furthermore, we propose a network-compression based solution, whose effectiveness is validated by extensive experimental results.},
author = {Zhang, H. and Kuhnle, A. and Zhang, H. and Thai, M.T.},
booktitle = {IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)},
doi = {10.1109/ASONAM.2016.7752288},
isbn = {9781509028467},
keywords = {Misinformation Detection,Monitor Placement,Social Networks},
title = {{Detecting misinformation in online social networks before it is too late}},
year = {2016}
}
@article{Austrin2009,
abstract = {We study the inapproximability of Vertex Cover and Independent Set on degree d graphs. We prove that: (1) Vertex Cover is Unique Games-hard to approximate to within a factor 2 - (2 + od(1)) log log d/log d. This exactly matches the algorit.....},
author = {Austrin, Per and Khot, Subhash and Safra, Muli},
doi = {10.1109/CCC.2009.38},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Austrin, Khot, Safra - 2009 - Inapproximability of vertex cover and independent set in bounded degree graphs.pdf:pdf},
isbn = {9780769537177},
issn = {10930159},
journal = {Proceedings of the Annual IEEE Conference on Computational Complexity},
pages = {74--80},
title = {{Inapproximability of vertex cover and independent set in bounded degree graphs}},
year = {2009}
}
@inproceedings{Kuhnle2017d,
abstract = {{\textcopyright} 2017 IEEE. We consider the Threshold Activation Problem (TAP): given social network G and positive threshold T, find a minimum-size seed set A that can trigger expected activation of at least T. We introduce the first scalable, parallelizable algorithm with performance guarantee for TAP suitable for datasets with millions of nodes and edges; we exploit the bicriteria nature of solutions to TAP to allow the user to control the running time versus accuracy of our algorithm through a parameter $\alpha$ (0, 1): given $\eta$  >  0, with probability 1 - $\eta$ our algorithm returns a solution A with expected activation greater than T - 2$\alpha$Τ, and the size of the solution A is within factor 1-h 4$\alpha$Τ + log(T) of the optimal size. The algorithm runs in time O ($\alpha$ -2 log (n/$\eta$) (n + m)A), where n, m, refer to the number of nodes, edges in the network. The performance guarantee holds for the general triggering model of internal influence and also incorporates external influence, provided a certain condition is met on the cost-effectivity of seed selection.},
author = {Kuhnle, A. and Pan, T. and Alim, M.A. and Thai, M.T.},
booktitle = {Proceedings - IEEE INFOCOM},
doi = {10.1109/INFOCOM.2017.8057068},
isbn = {9781509053360},
issn = {0743166X},
title = {{Scalable bicriteria algorithms for the threshold activation problem in online social networks}},
year = {2017}
}
@article{Klar2000,
author = {Klar, Bernhard},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Klar - 2000 - Bounds on Tail Probabilities.pdf:pdf},
journal = {Probability in the Engineering and Informational Sciences},
pages = {161--171},
title = {{Bounds on Tail Probabilities}},
year = {2000}
}
@article{Koura2009,
abstract = {The independent set problem is known to be NP-hard. A fundamental theorem of Tur{\'{a}}n [P. Tur{\'{a}}n, On an extremal problem in graph theory, Mat. Fiz. Lapok 48 (1941) 436-452] states that any graph with n vertices and average degree over(d, ̄) contains an independent set of size at least n / (over(d, ̄) + 1), which is known as Tur{\'{a}}n bound. The greedy algorithm with minimum-degree pivoting rule is well-known method for attaining Tur{\'{a}}n bound. Based on this result, Hochbaum [D.S. Hochbaum, Approximating covering and packing problems: Set cover, vertex cover, independent set, and related problems, in: D.S. Hochbaum (Ed.), Approximation Algorithms for NP-Hard Problems, PWS Publishing Company, 1997, pp. 94-143] showed that the greedy algorithm combined with LP attains performance ratio (over(d, ̄) + 1) / 2. This paper shows that if the input graph is assumed to be Ck-free then the greedy algorithm obtains an independent set of size at least 2 n / (over(d, ̄) + 1 + k). It also proves that the LP-based algorithm has the performance ratio (over(d, ̄) + 1 + k) / 4. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Koura, Ippei and Ono, Takao and Hirata, Tomio},
doi = {10.1016/j.ipl.2009.01.009},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koura, Ono, Hirata - 2009 - A note on the Greedy algorithm for finding independent sets of Ck-free graphs.pdf:pdf},
issn = {00200190},
journal = {Information Processing Letters},
keywords = {Analysis of algorithms,Approximation algorithms,Maximum independent set},
number = {10},
pages = {485--489},
publisher = {Elsevier B.V.},
title = {{A note on the Greedy algorithm for finding independent sets of Ck-free graphs}},
url = {http://dx.doi.org/10.1016/j.ipl.2009.01.009},
volume = {109},
year = {2009}
}
@article{Alipanahi2017,
author = {Alipanahi, Bahar and Muggli, Martin D and Jundi, Musa and Noyes, Noelle and Boucher, Christina},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alipanahi et al. - 2017 - Resistome SNP Calling via Read Colored de Bruijn Graphs.pdf:pdf},
pages = {1--15},
title = {{Resistome SNP Calling via Read Colored de Bruijn Graphs}},
year = {2017}
}
@inproceedings{Badanidiyuru2014,
abstract = {There has been much progress recently on improved approximations for problems involving submodular objective functions, and many interesting techniques have been developed. However, the resulting algorithms are often slow and impractical. In this paper we develop algorithms that match the best known approximation guarantees, but with significantly improved running times, for maximizing a monotone submodular function f: 2[n] → R+ subject to various constraints. As in previous work, we measure the number of oracle calls to the objective function which is the dominating term in the running time. Our first result is a simple algorithm that gives a (1--1/e -- $\epsilon$)-approximation for a cardinality constraint using O(n/$\epsilon$ log n/$\epsilon$) queries, and a 1/(p + 2ℓ + 1 + $\epsilon$)-approximation for the intersection of a p-system and ℓ knapsack (linear) constraints using O (n/$\epsilon$2 log2 n/$\epsilon$) queries. This is the first approximation for a p-system combined with linear constraints. (We also show that the factor of p cannot be improved for maximizing over a p-system.) The main idea behind these algorithms serves as a building block in our more sophisticated algorithms. Our main result is a new variant of the continuous greedy algorithm, which interpolates between the classical greedy algorithm and a truly continuous algorithm. We show how this algorithm can be implemented for matroid and knapsack constraints using {\~{O}}(n2) oracle calls to the objective function. (Previous variants and alternative techniques were known to use at least {\~{O}}(n4) oracle calls.) This leads to an O(n2/$\epsilon$4 log2 n/$\epsilon$)-time (1--1/e -- $\epsilon$)-approximation for a matroid constraint. For a knapsack constraint, we develop a more involved (1--1/e -- $\epsilon$)-approximation algorithm that runs in time O(n2(1/$\epsilon$ log n)poly(1/$\epsilon$)).},
author = {Badanidiyuru, Ashwinkumar and Vondr{\'{a}}k, Jan},
booktitle = {ACM-SIAM Symposium on Discrete Algorithms (SODA)},
doi = {10.1137/1.9781611973402.110},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Badanidiyuru, Vondr{\'{a}}k - 2014 - Fast algorithms for maximizing submodular functions.pdf:pdf},
isbn = {9781611973389},
title = {{Fast algorithms for maximizing submodular functions}},
year = {2014}
}
@article{Soma2015,
abstract = {The problem of maximizing non-negative monotone submodular functions under a certain constraint has been intensively studied in the last decade. In this paper, we address the problem for functions defined over the integer lattice. Suppose that a non-negative monotone submodular function $f:\mathbb{Z}_+^n \to \mathbb{R}_+$ is given via an evaluation oracle. Furthermore, we assume that $f$ satisfies the diminishing return property, which is not an immediate consequence of the submodularity when the domain is the integer lattice. Then, we show (i) a $(1-1/e-\epsilon)$-approximation algorithm for a cardinality constraint with $\widetilde{O}(\frac{n}{\epsilon}\log \frac{r}{\epsilon})$ queries, where $r$ is the maximum cardinality of feasible solutions, (ii) a $(1-1/e-\epsilon)$-approximation algorithm for a polymatroid constraint with $\widetilde{O}(\frac{nr}{\epsilon^4}+n^6)$ queries, where $r$ is the rank of the polymatroid, and (iii) a $(1-1/e-\epsilon)$-approximation algorithm for a knapsack constraint with $\widetilde{O}(\frac{n^2}{\epsilon^{18}}\log \frac{1}{w})(\frac{1}{\epsilon})^{O(1/\epsilon^8)}$ queries, where $w$ is the minumum weight of elements. Our algorithms for polymatroid constraints and knapsack constraints first extend the domain of the objective function to the Euclidean space and then run the continuous greedy algorithm. We give two different kinds of continuous extensions, one is for knapsack constraints and the other is for polymatroid constraints, which might be of independent interest.},
archivePrefix = {arXiv},
arxivId = {1503.01218},
author = {Soma, Tasuku and Yoshida, Yuichi},
eprint = {1503.01218},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soma, Yoshida - 2015 - A Generalization of Submodular Cover via the Diminishing Return Property on the Integer Lattice.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems (NIPS)},
title = {{A Generalization of Submodular Cover via the Diminishing Return Property on the Integer Lattice}},
year = {2015}
}
@inproceedings{Horel2016,
abstract = {We study the problem of maximizing a function that is approximately submodular under a cardinality constraint. Approximate submodularity implicitly appears in a wide range of applications as in many cases errors in evaluation of a submodular function break submodularity. Say that $F$ is $\eps$-approximately submodular if there exists a submodular function $f$ such that $(1-\eps)f(S) \leq F(S)\leq (1+\eps)f(S)$ for all subsets $S$. We are interested in characterizing the query-complexity of maximizing $F$ subject to a cardinality constraint $k$ as a function of the error level $\eps > 0$. We provide both lower and upper bounds: for $\eps > n^{-1/2}$ we show an exponential query-complexity lower bound. In contrast, when $\eps < {1}/{k}$ or under a stronger bounded curvature assumption, we give constant approximation algorithms.},
author = {Horel, Thibaut and Singer, Yaron},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Horel, Singer - 2016 - Maximization of Approximately Submodular Functions.pdf:pdf},
issn = {10495258},
title = {{Maximization of Approximately Submodular Functions}},
year = {2016}
}
@article{Beraldi2002,
author = {Beraldi, Patrizia and Ruszczy, Andrzej and Beraldi, Patrizia},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beraldi, Ruszczy, Beraldi - 2002 - The Probabilistic Set-Covering Problem THE PROBABILISTIC SET-COVERING PROBLEM.pdf:pdf},
number = {October 2017},
title = {{The Probabilistic Set-Covering Problem THE PROBABILISTIC SET-COVERING PROBLEM}},
year = {2002}
}
@article{Deshpande2013,
abstract = {Stochastic Boolean Function Evaluation is the problem of determining the value of a given Boolean function f on an unknown input x, when each bit of x_i of x can only be determined by paying an associated cost c_i. The assumption is that x is drawn from a given product distribution, and the goal is to minimize the expected cost. This problem has been studied in Operations Research, where it is known as "sequential testing" of Boolean functions. It has also been studied in learning theory in the context of learning with attribute costs. We consider the general problem of developing approximation algorithms for Stochastic Boolean Function Evaluation. We give a 3-approximation algorithm for evaluating Boolean linear threshold formulas. We also present an approximation algorithm for evaluating CDNF formulas (and decision trees) achieving a factor of O(log kd), where k is the number of terms in the DNF formula, and d is the number of clauses in the CNF formula. In addition, we present approximation algorithms for simultaneous evaluation of linear threshold functions, and for ranking of linear functions. Our function evaluation algorithms are based on reductions to the Stochastic Submodular Set Cover (SSSC) problem. This problem was introduced by Golovin and Krause. They presented an approximation algorithm for the problem, called Adaptive Greedy. Our main technical contribution is a new approximation algorithm for the SSSC problem, which we call Adaptive Dual Greedy. It is an extension of the Dual Greedy algorithm for Submodular Set Cover due to Fujito, which is a generalization of Hochbaum's algorithm for the classical Set Cover Problem. We also give a new bound on the approximation achieved by the Adaptive Greedy algorithm of Golovin and Krause.},
archivePrefix = {arXiv},
arxivId = {1303.0726},
author = {Deshpande, Amol and Hellerstein, Lisa and Kletenik, Devorah},
doi = {10.1137/1.9781611973402.107},
eprint = {1303.0726},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deshpande, Hellerstein, Kletenik - 2013 - Approximation Algorithms for Stochastic Boolean Function Evaluation and Stochastic Submodular.pdf:pdf},
isbn = {9781611973389},
issn = {15496325},
journal = {arXiv preprint arXiv:1303.0726},
pages = {1453--1467},
title = {{Approximation Algorithms for Stochastic Boolean Function Evaluation and Stochastic Submodular Set Cover}},
url = {http://arxiv.org/abs/1303.0726%5Cnhttp://epubs.siam.org/doi/abs/10.1137/1.9781611973402.107},
year = {2013}
}
@inproceedings{Soma2017,
archivePrefix = {arXiv},
arxivId = {1612.00960},
author = {Soma, Tasuku and Yoshida, Yuichi},
booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence (AAAI)},
eprint = {1612.00960},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soma, Yoshida - 2017 - Non-­‐monotone DR-­‐Submodular Function Maximization.pdf:pdf},
keywords = {Heuristic Search and Optimization},
pages = {898--904},
title = {{Non-­‐monotone DR-­‐Submodular Function Maximization}},
year = {2017}
}
@article{Ahmed2013,
abstract = {We consider two variants of a probabilistic set covering (PSC) problem. The first variant assumes that there is uncertainty regarding whether a selected set can cover an item, and the objective is to determine a minimum-cost combination of sets so that each item is covered with a prespecified probability. The second variant seeks to maximize the minimum probability that a selected set can cover all items. To date, literature on this problem has focused on the special case in which uncertainties are independent. In this paper, we formulate deterministic mixed-integer programming models for distributionally robust PSC problems with correlated uncertainties. By exploiting the supermodularity of certain substructures and analyzing their polyhedral properties, we develop strong valid inequalities to strengthen the formulations. Computational results illustrate that our modeling approach can outperform formulations in which correlations are ignored and that our algorithms can significantly reduce overall computation time. [ABSTRACT FROM AUTHOR]},
author = {Ahmed, Shabbir and Papageorgiou, Dimitri J},
doi = {10.1287/opre.1120.1135},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed, Papageorgiou - 2013 - Probabilistic Set Covering with Correlations.pdf:pdf},
isbn = {0030-364X},
issn = {0030-364X},
journal = {Operations Research},
keywords = {CORRELATION (Statistics),INTEGER programming,MATHEMATICAL optimization,PROBABILITY theory},
number = {2},
pages = {438--452},
title = {{Probabilistic Set Covering with Correlations}},
url = {http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=87084329&site=ehost-live&scope=site},
volume = {61},
year = {2013}
}
@article{Algorithms2017,
author = {Algorithms, Approximation and Analysis, Concentration and Approximation, Average},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Algorithms, Analysis, Approximation - 2017 - Cyber-epidemics in Billion-scale Networks Optimal Interdiction via Cutting a Few Edges.pdf:pdf},
keywords = {approximation algorithms,average approximation,concentration analysis,cyber-epidemics,optimization,sample},
pages = {1--32},
title = {{Cyber-epidemics in Billion-scale Networks : Optimal Interdiction via Cutting a Few Edges}},
year = {2017}
}
@article{Nguyen2017a,
abstract = {Cyber-epidemics, the widespread of fake news or propaganda through social media, can cause devastating economic and political consequences. A common countermeasure against cyber-epidemics is to disable a small subset of suspected social connections or accounts to effectively contain the epidemics. An example is the recent shutdown of 125,000 ISIS-related Twitter accounts. Despite many proposed methods to identify such subset, none are scalable enough to provide high-quality solutions in nowadays billion-size networks. To this end, we investigate the Spread Interdiction problems that seek most effective links (or nodes) for removal under the well-known Linear Threshold model. We propose novel CPU-GPU methods that scale to networks with billions of edges, yet, possess rigorous theoretical guarantee on the solution quality. At the core of our methods is an $O(1)$-space out-of-core algorithm to generate a new type of random walks, called Hitting Self-avoiding Walks (HSAWs). Such a low memory requirement enables handling of big networks and, more importantly, hiding latency via scheduling of millions of threads on GPUs. Comprehensive experiments on real-world networks show that our algorithms provides much higher quality solutions and are several order of magnitude faster than the state-of-the art. Comparing to the (single-core) CPU counterpart, our GPU implementations achieve significant speedup factors up to 177x on a single GPU and 338x on a GPU pair.},
archivePrefix = {arXiv},
arxivId = {1702.05854},
author = {Nguyen, Hung T. and Cano, Alberto and Vu, Tam and Dinh, Thang N.},
eprint = {1702.05854},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen et al. - 2017 - Blocking Self-avoiding Walks Stops Cyber-epidemics A Scalable GPU-based Approach.pdf:pdf},
keywords = {approximation algorithm,gpus,spread interdiction},
title = {{Blocking Self-avoiding Walks Stops Cyber-epidemics: A Scalable GPU-based Approach}},
url = {http://arxiv.org/abs/1702.05854},
year = {2017}
}
@article{Lin2017,
abstract = {The majority of influence maximization (IM) studies focus on targeting influential seeders to trigger substantial information spread in social networks. In this paper, we consider a new and complementary problem of how to further increase the influence spread of given seeders. Our study is motivated by the observation that direct incentives could "boost" users so that they are more likely to be influenced by friends. We study the $k$-boosting problem which aims to find $k$ users to boost so that the final "boosted" influence spread is maximized. The $k$-boosting problem is different from the IM problem because boosted users behave differently from seeders: boosted users are initially uninfluenced and we only increase their probability to be influenced. Our work also complements the IM studies because we focus on triggering larger influence spread on the basis of given seeders. Both the NP-hardness of the problem and the non-submodularity of the objective function pose challenges to the $k$-boosting problem. To tackle the problem on general graphs, we devise two efficient algorithms with the data-dependent approximation ratio. For the $k$-boosting problem on bidirected trees, we present an efficient greedy algorithm and a rounded dynamic programming that is a fully polynomial-time approximation scheme. We conduct extensive experiments using real social networks and synthetic bidirected trees. We show that boosting solutions returned by our algorithms achieves boosts of influence that are up to several times higher than those achieved by boosting solutions returned by intuitive baselines, which have no guarantee of solution quality. We also explore the "budget allocation" problem in our experiments. Compared with targeting seeders with all budget, larger influence spread is achieved when we allocation the budget to both seeders and boosted users.},
archivePrefix = {arXiv},
arxivId = {1602.03111},
author = {Lin, Yishi and Chen, Wei and Lui, John C.S.},
doi = {10.1109/ICDE.2017.137},
eprint = {1602.03111},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin, Chen, Lui - 2017 - Boosting information spread An algorithmic approach.pdf:pdf},
isbn = {9781509065431},
issn = {10844627},
journal = {Proceedings of the International Conference on Data Engineering (ICDE)},
pages = {883--894},
title = {{Boosting information spread: An algorithmic approach}},
year = {2017}
}
@article{Hoeffding1963,
author = {Hoeffding, Wassily},
doi = {10.1137/1116071},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoeffding - 1963 - Probability Inequalities for Sums of Bounded Random Variables.pdf:pdf},
issn = {0040-585X},
journal = {Journal of the American Statistical Association},
number = {301},
pages = {13--30},
title = {{Probability Inequalities for Sums of Bounded Random Variables}},
volume = {58},
year = {1963}
}
@incollection{Dvořák2015,
abstract = {We show that the minimal length-bounded {$}{$}L{$}{$} -cut can be computed in linear time with respect to {$}{$}L{$}{$} and the tree-width of the input graph as parameters. We derive an FPT algorithm for a more general multi-commodity length bounded cut problem when parameterized by the number of terminals also. For the former problem we show a {$}{$}{$\$}mathsf {{}W{}}[1]{$}{$} -hardness result when the parameterization is done by the path-width only (instead of the tree-width).},
address = {Cham},
author = {Dvo$\$vr{\'{a}}k, Pavel and Knop, Du{\v{s}}an},
booktitle = {Theory and Applications of Models of Computation: 12th Annual Conference, TAMC 2015, Singapore, May 18-20, 2015, Proceedings},
doi = {10.1007/978-3-319-17142-5_37},
editor = {Jain, Rahul and Jain, Sanjay and Stephan, Frank},
isbn = {978-3-319-17142-5},
pages = {441--452},
publisher = {Springer International Publishing},
title = {{Parametrized Complexity of Length-Bounded Cuts and Multi-cuts}},
url = {https://doi.org/10.1007/978-3-319-17142-5_37},
year = {2015}
}
@inproceedings{Leskovec2005,
abstract = {How do real graphs evolve over time? What are "normal" growth patterns in social, technological, and information networks? Many studies have discovered patterns in static graphs, identifying properties in a single snapshot of a large network, or in a very small number of snapshots; these include heavy tails for in- and out-degree distributions, communities, small-world phenomena, and others. However, given the lack of information about network evolution over long periods, it has been hard to convert these findings into statements about trends over time.},
author = {Leskovec, Jure and Kleinberg, Jon and Faloutsos, Christos},
booktitle = {ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)},
doi = {10.1.1.59.8209},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leskovec, Kleinberg, Faloutsos - 2005 - Graphs over Time Densification Laws, Shrinking Diameters and Possible Explanations.pdf:pdf},
isbn = {159593135X},
issn = {159593135X},
keywords = {densification power laws,graph generators,graph mining,heavy-tailed distributions,small-world phenomena},
pages = {177--187},
title = {{Graphs over Time: Densification Laws, Shrinking Diameters and Possible Explanations}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.8209},
year = {2005}
}
@article{VandenBosch2016,
abstract = {One of the determining factors of the quality of Web search engines is the size of their index. In addition to its influence on search result quality, the size of the indexed Web can also tell us something about which parts of the WWW are directly accessible to the everyday user. We propose a novel method of estimating the size of a Web search engine's index by extrapolating from document frequencies of words observed in a large static corpus of Web pages. In addition, we provide a unique longitudinal perspective on the size of Google and Bing's indices over a nine-year period, from March 2006 until January 2015. We find that index size estimates of these two search engines tend to vary dramatically over time, with Google generally possessing a larger index than Bing. This result raises doubts about the reliability of previous one-off estimates of the size of the indexed Web. We find that much, if not all of this variability can be explained by changes in the indexing and ranking infrastructure of Google and Bing. This casts further doubt on whether Web search engines can be used reliably for cross-sectional webometric studies.},
author = {van den Bosch, Antal and Bogers, Toine and de Kunder, Maurice},
doi = {10.1007/s11192-016-1863-z},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/van den Bosch, Bogers, de Kunder - 2016 - Estimating search engine index size variability a 9-year longitudinal study.pdf:pdf},
issn = {15882861},
journal = {Scientometrics},
keywords = {Longitudinal study,Search engine index,Webometrics},
number = {2},
pages = {839--856},
pmid = {27122648},
publisher = {Springer Netherlands},
title = {{Estimating search engine index size variability: a 9-year longitudinal study}},
volume = {107},
year = {2016}
}
@article{Hart1968,
abstract = {Abstract-Although the problem of determining the minimum cost path through a graph arises naturally in a number of interesting applications, there has been no underlying theory to guide the development of efficient search procedures. Moreover, there is no adequate conceptual framework within which the various ad hoc search strategies proposed to date can be compared. This paper describes how heuristic information from the problem domain can be incorporated into a formal mathematical theory of graph searching and demonstrates an optimality property of a class of search strate- gies.},
author = {Hart, Peter E. and Nilsson, Nils J. and Raphael, Bertram},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hart, Nilsson, Raphael - 1968 - Formal Basis for the Heuristic Determination of Minimum Cost Paths.pdf:pdf},
journal = {Systems Science and Cybernetics},
number = {2},
pages = {100--107},
title = {{Formal Basis for the Heuristic Determination of Minimum Cost Paths}},
volume = {4},
year = {1968}
}
@inproceedings{Sen2009,
abstract = {The studies in fault-tolerance in networks mostly focus on the connectivity of the graph as the metric of fault-tolerance. If the underlying graph is k-connected, it can tolerate up to k - 1 failures. In measuring the fault tolerance in terms of connectivity, no assumption regarding the locations of the faulty nodes are made - the failed nodes may be close to each other or far from each other. In other words, the connectivity metric has no way of capturing the notion of locality of faults. However in many networks, faults may be highly localized. This is particularly true in military networks, where an enemy bomb may inflict massive but localized damage to the network. To capture the notion of locality of faults in a network, a new metric region-based connectivity (RBC) was introduced in. It was shown that RBC can achieve the same level of fault-tolerance as the metric connectivity, with much lower networking resources. The study in was restricted to single region fault model (SRFM), where faults are confined to one region only. In this paper, we extend the notion of RBC to multiple region fault model (MRFM), where faults are no longer confined to a single region. As faults in MRFM are still confined to regions, albeit multiple of them, it is different from unconstrained fault model where no constraint on locality of faults is imposed. The MRFM leads to several new concepts, such as region-disjoint paths and region cuts. We show that the classical result, the maximum number of node-disjoint paths between a pair of nodes is equal to the minimum number of nodes whose removal disconnects the pair, is no longer valid when region-disjoint paths and region cuts are considered. We prove that the problems of finding (i) the maximum number of region-disjoint paths between a pair of nodes, and (ii) minimum number of regions whose removal disconnect a pair of nodes, are both NP-complete. We provide heuristic solution to these two problems and evaluate their efficacy by compari-\nng the results with optimal solutions.},
author = {Sen, Arunabha and Murthy, Sudheendra and Banerjee, Sujogya},
booktitle = {2009 International Conference on High Performance Switching and Routing, HPSR 2009},
doi = {10.1109/HPSR.2009.5307417},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sen, Murthy, Banerjee - 2009 - Region-based connectivity - A new paradigm for design of fault-tolerant networks.pdf:pdf},
isbn = {9781424451746},
title = {{Region-based connectivity - A new paradigm for design of fault-tolerant networks}},
year = {2009}
}
@inproceedings{Brinkhoff2000,
author = {Brinkhoff, Thomas},
booktitle = {IEEE 12th International Conference on Scientific and Statistical Database Management},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brinkhoff - 2000 - Generating Network-Based Moving Objects.pdf:pdf},
pages = {8--10},
title = {{Generating Network-Based Moving Objects}},
year = {2000}
}
@article{Zhu2014a,
abstract = {In this paper, we present three experimental proof-of-concepts: First, we demonstrate a Ubiquitous Computing Framework (UCF), which is a network of interacting technologies that support humans ubiquitously. We then present practical work based on this UCF framework: TalkingPoints, which was originally developed for use at trading fairs in order to identify each participant and company via transponder and provide specific information during and after use. Finally, we propose GARFID, a concept for using advanced technologies for teaching young children. The main outcome of this research is that the concept of UCF raises a lot of possibilities, which can bring value and benefits for end-users. When one follows the Working-is-Learning paradigm, it can be seen that the implementation of this type of technology can support Life Long Learning, thereby providing evidence that technology can benefit everybody and make life easier.},
archivePrefix = {arXiv},
arxivId = {arXiv:1405.1155v1},
author = {Zhu, Chunsheng and Shu, Lei and Hara, Takahiro and Wang, Lei and Nishio, Shojiro and Yang, Laurence T.},
doi = {10.1002/wcm},
eprint = {arXiv:1405.1155v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2014 - A survey on communication and data management issues in mobile sensor networks.pdf:pdf},
isbn = {1530-8677},
issn = {15308669},
journal = {Wireless Communications and Mobile Computing},
keywords = {10.1002/wcm.2356 and generative models,Markov models,burst error statistics,deterministic fading processes,digital wireless channels,generative models,markov models},
pages = {19--36},
title = {{A survey on communication and data management issues in mobile sensor networks}},
url = {http://eprints.soton.ac.uk/266684/},
volume = {14},
year = {2014}
}
@misc{Amazon.com,
author = {Amazon.com},
title = {{Amazon.com Help: Guaranteed Delivery Terms and Conditions}},
url = {https://www.amazon.com/gp/help/customer/display.html?ie=UTF8&nodeId=201910260},
urldate = {2017-10-01}
}
@article{Zhang2017,
abstract = {With the rapid advances of sensing technologies and wireless communications, large amounts of dynamic data pertaining to industrial production are being collected from many sensor nodes deployed in the industrial Internet of Things. Analyzing those data effectively can help to improve the industrial services and mitigate the system unprepared breakdowns. As an important technique of data analysis, clustering attempts to find the underlying pattern structures embedded in unlabeled information. Unfortunately, most of the current clustering techniques that could only deal with static data become infeasible to cluster a significant volume of data in the dynamic industrial applications. To tackle this problem, an incremental clustering algorithm by fast finding and searching of density peaks based on k-mediods is proposed in this paper. In the proposed algorithm, two cluster operations, namely cluster creating and cluster merging, are defined to integrate the current pattern into the previous one for the final clustering result, and k-mediods is employed to modify the clustering centers according to the new arriving objects. Finally, experiments are conducted to validate the proposed scheme on three popular UCI datasets and two real datasets collected from industrial Internet of Things in terms of clustering accuracy and computational time.},
author = {Zhang, Qingchen and Zhu, Chunsheng and Yang, Laurence T and Chen, Zhikui and Zhao, Liang and Li, Peng},
doi = {10.1109/TII.2017.2684807},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - An Incremental CFS Algorithm for Clustering Large Data in Industrial Internet of Things.pdf:pdf},
issn = {1551-3203},
journal = {IEEE Transactions on Industrial Informatics},
keywords = {$K$ -mediods,CFS clustering,Internet of Things,UCI datasets,cluster creating,cluster merging,data analysis,density peaks,dynamic data,incremental CFS algorithm,incremental clustering,incremental clustering algorithm,industrial Internet of Things,industrial Internet of Things (IoT),industrial services,k-mediods,large data clustering,pattern clustering,pattern structures,production engineering computing,sensing technologies,sensor nodes,static data,system unprepared breakdowns,unlabeled information,wireless communications},
number = {3},
pages = {1193--1201},
title = {{An Incremental CFS Algorithm for Clustering Large Data in Industrial Internet of Things}},
volume = {13},
year = {2017}
}
@article{Malik1989,
abstract = {The k most vital arcs in a network are those whose removal from the network results in the greatest increase in the shortest distance between two specified nodes. An exact algorithm is proposed to determine the k most vital arcs. Furthermore, an algorithm of time complexity equal to that of Dijkstra's algorithm for the shortest path problem is developed to solve the single most vital arc problem. ?? 1989.},
author = {Malik, K. and Mittal, A. K. and Gupta, S. K.},
doi = {10.1016/0167-6377(89)90065-5},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Malik, Mittal, Gupta - 1989 - The k most vital arcs in the shortest path problem.pdf:pdf},
issn = {01676377},
journal = {Operations Research Letters},
keywords = {distance algorithm,networks,shortest paths,vital arcs},
number = {4},
pages = {223--227},
title = {{The k most vital arcs in the shortest path problem}},
volume = {8},
year = {1989}
}
@article{Jing-QuanLi2006,
abstract = {This article introduces a new family of Cayley graphs, called k-degree Cayley graphs, for building interconnection networks. The k-degree Cayley graph possesses many valuable topological properties, such as regularity with degree k, logarithmic diameter, and maximal fault tolerance. We present an optimal shortest path routing algorithm for the k-degree Cayley graph. Cycle- embedding and clique-embedding are also discussed.},
author = {{Jing-Quan Li}, Pitu B. Mirchandani and Denis Borenstein},
doi = {10.1002/net},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jing-Quan Li - 2006 - The k -Degree Cayley Graph and its Topological Properties.pdf:pdf},
isbn = {0028-3045},
issn = {1097-0037},
journal = {Networks},
keywords = {embedding,graph-theoretic interconnection networks,network topology,shortest path routing algorithm,topological properties},
number = {1},
pages = {26--36},
title = {{The k -Degree Cayley Graph and its Topological Properties}},
volume = {47},
year = {2006}
}
@article{Brown2006a,
abstract = {We apply new bilevel and trilevel optimization models to make critical infrastructure more resilient against terrorist attacks. Each model features an intelligent attacker (terrorists) and a defender (us), information transparency, and sequential actions by attacker and defender. We illustrate with examples of the US Strategic Petroleum Reserve, the US Border Patrol at Yuma, Arizona, and an electrical transmission system. We conclude by reporting insights gained from the modeling experience and many "red-team" exercises. Each exercise gathers open-source data on a real-world infrastructure system, develops an appropriate bilevel or trilevel model, and uses these to identify vulnerabilities in the system or to plan an optimal defense.},
author = {Brown, Gerald and Carlyle, Matthew and Salmer{\'{o}}n, Javier and Wood, Kevin},
doi = {10.1287/inte.1060.0252},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brown et al. - 2006 - Defending critical infrastructure(2).pdf:pdf},
isbn = {0092-2102},
issn = {00922102},
journal = {Interfaces},
keywords = {Bilevel program,Critical infrastructure protection,Homeland defense,Homeland security,Mixed-integer program,Trilevel program},
number = {6},
pages = {530--544},
title = {{Defending critical infrastructure}},
volume = {36},
year = {2006}
}
@article{Yates2012,
author = {Yates, Justin and Casas, Irene},
doi = {10.1007/s12061-010-9057-1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yates, Casas - 2012 - Role of Spatial Data in the Protection of Critical Infrastructure and Homeland Defense.pdf:pdf},
issn = {1874463X},
journal = {Applied Spatial Analysis and Policy},
keywords = {GIS,Homeland security,Network interdiction,Optimization},
number = {1},
pages = {1--23},
title = {{Role of Spatial Data in the Protection of Critical Infrastructure and Homeland Defense}},
volume = {5},
year = {2012}
}
@article{Young1995,
abstract = {We introduce a new technique called oblivious rounding --- a variant of randomized rounding that avoids the bottleneck of first solving the linear program. Avoiding this bottleneck yields more efficient algorithms and brings probabilistic methods to bear on a new class of problems. We give oblivious rounding algorithms that approximately solve general packing and covering problems, including a parallel algorithm to find sparse strategies for matrix games.},
archivePrefix = {arXiv},
arxivId = {cs/0205036},
author = {Young, Neal E.},
eprint = {0205036},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Young - 1995 - Randomized rounding without solving the linear program.pdf:pdf},
isbn = {0898713498},
journal = {Proceedings of the Sixth Annual ACM-SIAM Symposium on Discrete Algorithms},
number = {c},
pages = {170--178},
primaryClass = {cs},
title = {{Randomized rounding without solving the linear program}},
volume = {178},
year = {1995}
}
@misc{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - 17-00176.org:org},
title = {17-00176}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Minimum Cost Seed Set for Threshold Influence Problem under Competitive Models.pdf:pdf},
title = {{Minimum Cost Seed Set for Threshold Influence Problem under Competitive Models}}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Reachability Preserved Cut on Graph Complexity , Algorithm and Application in Network.pdf:pdf},
title = {{Reachability Preserved Cut on Graph : Complexity , Algorithm and Application in Network}}
}
@article{Zhangb,
author = {Zhang, Guiqing and Cheng, Yongxi and Xu, Yinfeng},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Cheng, Xu - Unknown - A randomized competitive group testing procedure.pdf:pdf},
journal = {JOCO},
keywords = {corresponding author},
number = {11101326},
title = {{A randomized competitive group testing procedure}}
}
@incollection{Dvořák2015,
abstract = {We show that the minimal length-bounded {$}{$}L{$}{$} -cut can be computed in linear time with respect to {$}{$}L{$}{$} and the tree-width of the input graph as parameters. We derive an FPT algorithm for a more general multi-commodity length bounded cut problem when parameterized by the number of terminals also. For the former problem we show a {$}{$}{\}mathsf {{}W{}}[1]{$}{$} -hardness result when the parameterization is done by the path-width only (instead of the tree-width).},
address = {Cham},
author = {Dvo\vr{\'{a}}k, Pavel and Knop, Du{\v{s}}an},
booktitle = {Theory and Applications of Models of Computation: 12th Annual Conference, TAMC 2015, Singapore, May 18-20, 2015, Proceedings},
doi = {10.1007/978-3-319-17142-5_37},
editor = {Jain, Rahul and Jain, Sanjay and Stephan, Frank},
isbn = {978-3-319-17142-5},
pages = {441--452},
publisher = {Springer International Publishing},
title = {{Parametrized Complexity of Length-Bounded Cuts and Multi-cuts}},
url = {https://doi.org/10.1007/978-3-319-17142-5_37},
year = {2015}
}
@article{Kolman2017,
abstract = {Given a graph $G=(V,E)$ with two distinguished vertices $s,t\in V$ and an integer parameter $L>0$, an $L$-bounded cut is a subset $F$ of edges (nodes) such that the every path between $s$ and $t$ in $G\setminus F$ has length more than $L$. The task is to find an $L$-bounded cut of minimum cardinality. Though the problem is very simple to state and has been studied since the beginning of the 70's, it is not much understood yet. The problem is known to be $\cal{NP}$-hard to approximate within a small constant factor even for $L\geq 4$ (for $L\geq 5$ for the node cuts). On the other hand, the best known approximation algorithm for general graphs has approximation ratio only $\mathcal{O}({n^{2/3}})$ in the edge case, and $\mathcal{O}({\sqrt{n}})$ in the node case, where $n$ denotes the number of nodes. We show that for planar graphs, it is possible to solve both the edge- and the node-version of the problem optimally in time $\mathcal{O}(L^{3L}n)$. That is, the problem is fixed parameter tractable (FPT) with respect to $L$ on planar graphs. Furthermore, we show that the problem remains FPT even for bounded genus graphs, a super class of planar graphs. Our second contribution is an $\mathcal{O}(\tau\sqrt{\log \tau}\log n)$-approximation algorithm for the node version of the problem on graphs with treewidth bounded by $\tau$. For graphs with treewidth bounded by $\mathcal{O}(n^{1/2-\epsilon})$ for any $\epsilon>0$, but not by a constant, this is the best approximation in terms of$\sim$$n$ that we are aware of.},
archivePrefix = {arXiv},
arxivId = {1705.02390},
author = {Kolman, Petr},
eprint = {1705.02390},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kolman - 2017 - On Algorithms for $L$-bounded Cut Problem.pdf:pdf},
title = {{On Algorithms for $L$-bounded Cut Problem}},
url = {http://arxiv.org/abs/1705.02390},
year = {2017}
}
@article{Dinh2016,
abstract = {Many social networks and complex systems are found to be naturally divided into clusters of densely connected nodes, known as community structure (CS). Finding CS is one of fundamental yet challenging topics in network science. One of the most popular classes of methods for this problem is to maximize Newman's modularity. However, there is a little understood on how well we can approximate the maximum modularity as well as the implications of finding community structure with provable guarantees. In this paper, we settle definitely the approximability of modularity clustering, proving that approximating the problem within any (multiplicative) positive factor is intractable, unless P = NP. Yet we propose the first additive approximation algorithm for modularity clustering with a constant factor. Moreover, we provide a rigorous proof that a CS with modularity arbitrary close to maximum modularity QOPT might bear no similarity to the optimal CS of maximum modularity. Thus even when CS with near-optimal modularity are found, other verification methods are needed to confirm the significance of the structure.},
archivePrefix = {arXiv},
arxivId = {1602.01016},
author = {Dinh, Thang N. and Li, Xiang and Thai, My T.},
doi = {10.1109/ICDM.2015.139},
eprint = {1602.01016},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dinh, Li, Thai - 2016 - Network clustering via maximizing modularity Approximation algorithms and theoretical limits.pdf:pdf},
isbn = {9781467395038},
issn = {15504786},
journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
keywords = {Approximation algorithm,Community structure,Complex networks,Inapproximability,Newman's modularity},
pages = {101--110},
title = {{Network clustering via maximizing modularity: Approximation algorithms and theoretical limits}},
volume = {2016-Janua},
year = {2016}
}
@article{Eppstein1998,
author = {Eppstein, David},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Eppstein - 1998 - Finding the k Shortest Paths.pdf:pdf},
journal = {SIAM Journal on Computing},
keywords = {05c12,05c85,94c15,ams subject classifications,dynamic programming,genealogy,inscribed polygon,knapsack problem,near-optimal solutions,network programming,path enumeration,pii,s0097539795290477,sequence alignment,shortest paths},
number = {2},
pages = {652--673},
title = {{Finding the k Shortest Paths}},
volume = {28},
year = {1998}
}
@article{Hershberger2007,
abstract = {We describe a new algorithm to enumerate the k shortest simple (loopless) paths in a directed graph and report on its implementation. Our algorithm is based on a replacement paths algorithm proposed by Hershberger and Suri [2001], and can yield a factor &Theta;( n ) improvement for this problem. But there is a caveat: The fast replacement paths subroutine is known to fail for some directed graphs. However, the failure is easily detected, and so our k shortest paths algorithm optimistically uses the fast subroutine, then switches to a slower but correct algorithm if a failure is detected. Thus, the algorithm achieves its &Theta;( n ) speed advantage only when the optimism is justified. Our empirical results show that the replacement paths failure is a rare phenomenon, and the new algorithm outperforms the current best algorithms; the improvement can be substantial in large graphs. For instance, on GIS map data with about 5,000 nodes and 12,000 edges, our algorithm is 4--8 times faster. In synthetic graphs modeling wireless ad hoc networks, our algorithm is about 20 times faster.},
author = {Hershberger, John and Maxel, Matthew and Suri, Subhash},
doi = {10.1145/1290672.1290682},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hershberger, Maxel, Suri - 2007 - Finding the iki shortest simple paths A new algorithm and its implementation.pdf:pdf},
issn = {1549-6325},
journal = {ACM Trans. Algorithms},
keywords = {k_shortest_path,ksp,tracking},
number = {4},
pages = {45+},
title = {{Finding the <i>k</i> shortest simple paths: A new algorithm and its implementation}},
url = {http://dx.doi.org/10.1145/1290672.1290682},
volume = {3},
year = {2007}
}
@article{Gao2010,
abstract = {With the wide applications of large scale graph data such as social networks, the problem of finding the top-k shortest paths attracts increasing attention. This paper focuses on the discovery of the top-k simple shortest paths (paths without loops). The well known algorithm for this problem is due to Yen, and the provided worst-case bound O(kn(m + nlogn)), which comes from O(n) times single-source shortest path discovery for each of k shortest paths, remains unbeaten for 30 years, where n is the number of nodes and m is the number of edges. In this paper, we observe that there are shared sub-paths among O(kn) single-source shortest paths. The basic idea behind our method is to pre-compute the shortest paths to the target node, and utilize them to reduce the discovery cost at running time. Specifically, we transform the original graph by encoding the pre-computed paths, and prove that the shortest path discovered over the transformed graph is equivalent to that in the original graph. Most importantly, the path discovery over the transformed graph can be terminated much earlier than before. In addition, two optimization strategies are presented. One is to reduce the total iteration times for shortest path discovery, and the other is to prune the search space in each iteration with an adaptively-determined threshold. Although the worst-case complexity cannot be lowered, our method is proven to be much more efficient in a general case. The final extensive experimental results (on both real and synthetic graphs) also show that our method offers a significant performance improvement over the existing ones. {\textcopyright} 2010 ACM.},
author = {Gao, Jun and Qiu, Huida and Jiang, Xiao and Wang, Tengjiao and Yang, Dongqing},
doi = {10.1145/1871437.1871504},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gao et al. - 2010 - Fast top-k simple shortest paths discovery in graphs.pdf:pdf},
isbn = {9781450300995},
journal = {Proceedings of the 19th ACM international conference on Information and knowledge management},
keywords = {graphs,shortest-paths,top-k},
pages = {509--518},
title = {{Fast top-k simple shortest paths discovery in graphs}},
url = {http://portal.acm.org/citation.cfm?id=1871437.1871504},
year = {2010}
}
@article{Das2011,
abstract = {We study the problem of selecting a subset of k random variables from a large set, in order to obtain the best linear prediction of another variable of interest. This problem can be viewed in the context of both feature selection and sparse approximation. We analyze the performance of widely used greedy heuristics, using insights from the maximization of submodular functions and spectral analysis. We introduce the submodularity ratio as a key quantity to help understand why greedy algorithms perform well even when the variables are highly correlated. Using our techniques, we obtain the strongest known approximation guarantees for this problem, both in terms of the submodularity ratio and the smallest k-sparse eigenvalue of the covariance matrix. We further demonstrate the wide applicability of our techniques by analyzing greedy algorithms for the dictionary selection problem, and significantly improve the previously known guarantees. Our theoretical analysis is complemented by experiments on real-world and synthetic data sets; the experiments show that the submodularity ratio is a stronger predictor of the performance of greedy algorithms than other spectral parameters.},
archivePrefix = {arXiv},
arxivId = {1102.3975},
author = {Das, Abhimanyu and Kempe, David},
eprint = {1102.3975},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Das, Kempe - 2011 - Submodular meets Spectral Greedy Algorithms for Subset Selection, Sparse Approximation and Dictionary Selection.pdf:pdf},
isbn = {978-1-4503-0619-5},
issn = {<null>},
journal = {Proceedings of the 28th International Conference on Machine Learning (ICML)},
title = {{Submodular meets Spectral: Greedy Algorithms for Subset Selection, Sparse Approximation and Dictionary Selection}},
url = {http://arxiv.org/abs/1102.3975},
year = {2011}
}
@article{Vondrak2010,
author = {Vondrak, Jan},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vondrak - 2010 - Submodularity and Curvature The Optimal Algorithm.pdf:pdf},
keywords = {approximation algorithms,curvature,matroid,submodular function},
pages = {253--266},
title = {{Submodularity and Curvature : The Optimal Algorithm}},
volume = {23},
year = {2010}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bian et al. - 2017 - Guarantees for Greedy Maximization of Non-submodular Functions with Applications(2).pdf:pdf},
title = {{A. Organization of the Appendix}},
volume = {0}
}
@article{Conforti1984,
abstract = {For the problem maxlcub;Z(S): S is an independent set in the matroid Xrcub;, it is well-known that the greedy algorithm finds an optimal solution when Z is an additive set function (Rado-Edmonds theorem). Fisher, Nemhauser and Wolsey have shown that, when Z is a nondecreasing submodular set function satisfying Z(???)=0, the greedy algorithm finds a solution with value at least half the optimum value. In this paper we show that it finds a solution with value at least 1/(1 + ??) times the optimum value, where ?? is a parameter which represents the 'total curvature' of Z. This parameter satisfies 0????????1 and ??=0 if and only if the set function Z is additive. Thus the theorems of Rado-Edmonds and Fisher-Nemhauser-Wolsey are both contained in the bound 1/(1 + ??). We show that this bound is best possible in terms of ??. Another bound which generalizes the Rado-Edmonds theorem is given in terms of a 'greedy curvature' of the set function. Unlike the first bound, this bound can prove the optimality of the greedy algorithm even in instances where Z is not additive. A third bound, in terms of the rank and the girth of X, unifies and generalizes the bounds (e-1)/e known for uniform matroids and 1 2 for general matroids. We also analyze the performance of the greedy algorithm when X is an independence system instead of a matroid. Then we derive two bounds, both tight: The first one is [1-(1-??/K)k]/?? where K and k are the sizes of the largest and smallest maximal independent sets in X respectively; the second one is 1/(p+??) where p is the minimum number of matroids that must be intersected to obtain X. ?? 1984.},
author = {Conforti, Michele and Cornu{\'{e}}jols, G{\'{e}}rard},
doi = {10.1016/0166-218X(84)90003-9},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Conforti, Cornu{\'{e}}jols - 1984 - Submodular set functions, matroids and the greedy algorithm Tight worst-case bounds and some generalizati.pdf:pdf},
issn = {0166218X},
journal = {Discrete Applied Mathematics},
number = {3},
pages = {251--274},
title = {{Submodular set functions, matroids and the greedy algorithm: Tight worst-case bounds and some generalizations of the Rado-Edmonds theorem}},
volume = {7},
year = {1984}
}
@article{Fisher1978,
abstract = {LetN be a finite set andz be a real-valued function defined on the set of subsets ofN that satisfies z (S)+ z (T)= z (S? T)+ z (S? T) for allS, T inN. Such a function is called submodular. We consider the problem max S? N {a (S):| S|= K, z (S) submodular}.},
author = {Fisher, M.L. and Nemhauser, G.L. and Wolsey, L.A.},
doi = {10.1007/BF01588971},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fisher, Nemhauser, Wolsey - 1978 - An analysis of approximations for maximizing submodular set functions-II.pdf:pdf},
isbn = {9783642007903},
issn = {00255610},
journal = {Mathematical Programming},
keywords = {Greedy Algorithm,Heuristics,Interchange Algorithm,Linear Programming,Matroid Optimization,Submodular Set Functions},
pages = {73--87},
title = {{An analysis of approximations for maximizing submodular set functions-II}},
volume = {8},
year = {1978}
}
@article{Fluschnik2015,
abstract = {Bodlaender et al.'s [SIDMA 2014] cross-composition technique is a popular method for excluding polynomial-size problem kernels for NP-hard parameterized problems. We present a new technique exploiting triangle-based fractal structures for extending the range of applicability of cross-compositions. Our technique makes it possible to prove new no-polynomial-kernel results for a number of problems dealing with length-bounded cuts. In particular, answering an open question of Golovach and Thilikos [Discrete Optim. 2011], we show that, unless a collapse in the Polynomial Hierarchy occurs, the NP-hard Length-Bounded Edge-Cut problem (delete at most $k$ edges such that the resulting graph has no $s$-$t$ path of length shorter than $\ell$) parameterized by the combined $k$ and $\ell$ has no polynomial-size problem kernel. Our framework applies to planar as well as directed variants of the basic problems and also applies to both edge and vertex deletion problems. Key words: Fixed-parameter tractability; polynomial kernels; kernelization; kernel lower bounds; cross-compositions; graph modification problems; fractals.},
archivePrefix = {arXiv},
arxivId = {1512.00333},
author = {Fluschnik, Till and Hermelin, Danny and Nichterlein, Andr{\'{e}} and Niedermeier, Rolf},
eprint = {1512.00333},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fluschnik et al. - 2015 - Fractals for Kernelization Lower Bounds, With an Application to Length-Bounded Cut Problems.pdf:pdf},
keywords = {bounds,cross-compositions,fixed-parameter tractability,fractals,graph modification problems,kernel lower,kernelization,polynomial kernels},
number = {February 2016},
pages = {1--22},
title = {{Fractals for Kernelization Lower Bounds, With an Application to Length-Bounded Cut Problems}},
url = {http://arxiv.org/abs/1512.00333},
year = {2015}
}
@article{Guruswami2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1302.5877},
author = {Guruswami, Venkatesan and Lee, Euiwoong},
doi = {10.1137/090750688},
eprint = {arXiv:1302.5877},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guruswami, Lee - 2017 - Inapproximability of H-TransversalPacking.pdf:pdf},
isbn = {0001405101},
journal = {SIAM Journal of Discrete Math},
keywords = {10,1137,16m1063824,35l65,65c20,65l06,65m08,76p05,82c40,ams subject classifications,asymptotic preserving schemes,boltzmann equation,compressible navier,doi,equations,implicit-explicit linear multistep methods,stiff differential,stokes limit},
number = {3},
pages = {1552--1571},
title = {{Inapproximability of H-Transversal/Packing}},
volume = {31},
year = {2017}
}
@article{Marx2008,
abstract = {Approximation algorithms and parameterized complexity are usually considered to be two separate ways of dealing with hard algorithmic problems. In this paper, our aim is to investigate how these two fields can be combined to achieve better algorithms than what any of the two theories could offer. We discuss the different ways parameterized complexity can be extended to approximation algorithms, survey results of this type, and propose directions for future research.},
author = {Marx, D{\'{a}}niel},
doi = {10.1093/comjnl/bxh000},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marx - 2008 - Parameterized complexity and approximation algorithms.pdf:pdf},
isbn = {0010-4620},
issn = {0010-4620},
journal = {The Computer Journal},
keywords = {algorithms,applications,learning,random neural network,rnn,rnn extension models,survey},
number = {1},
pages = {60--78},
title = {{Parameterized complexity and approximation algorithms}},
url = {http://comjnl.oxfordjournals.org/content/51/1/60.short},
volume = {51},
year = {2008}
}
@article{Golovach2011,
abstract = {We study the parameterized complexity of two families of problems: the bounded length disjoint paths problem and the bounded length cut problem. From Menger's theorem both problems are equivalent (and computationally easy) in the unbounded case for single source, single target paths. However, in the bounded case, they are combinatorially distinct and are both NP-hard, even to approximate. Our results indicate that a more refined landscape appears when we study these problems with respect to their parameterized complexity. For this, we consider several parameterizations (with respect to the maximum length l of paths, the number k of paths or the size of a cut, and the treewidth of the input graph) of all variants of both problems (edge/vertex-disjoint paths or cuts, directed/undirected). We provide FPT-algorithms (for all variants) when parameterized by both k and l and hardness results when the parameter is only one of k and l. Our results indicate that the bounded length disjoint-path variants are structurally harder than their bounded length cut counterparts. Also, it appears that the edge variants are harder than their vertex-disjoint counterparts when parameterized by the treewidth of the input graph. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {Golovach, Petr A. and Thilikos, Dimitrios M.},
doi = {10.1016/j.disopt.2010.09.009},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Golovach, Thilikos - 2011 - Paths of bounded length and their cuts Parameterized complexity and algorithms.pdf:pdf},
isbn = {3642112684},
issn = {15725286},
journal = {Discrete Optimization},
keywords = {Bounded length cuts,Bounded length disjoint paths,Parameterized algorithms,Parameterized complexity},
number = {1},
pages = {72--86},
publisher = {Elsevier B.V.},
title = {{Paths of bounded length and their cuts: Parameterized complexity and algorithms}},
url = {http://dx.doi.org/10.1016/j.disopt.2010.09.009},
volume = {8},
year = {2011}
}
@inproceedings{Knop2015,
abstract = {We show that the Minimal Length-Bounded L-But problem can be computed in linear time with respect to L and the tree-width of the input graph as parameters. In this problem the task is to find a set of edges of a graph such that after removal of this set, the shortest path between two prescribed vertices is at least L long. We derive an FPT algorithm for a more general multi-commodity length bounded cut problem when parameterized by the number of terminals also. For the former problem we show a W[1]-hardness result when the parameterization is done by the path-width only (instead of the tree-width) and that this problem does not admit polynomial kernel when parameterized by tree-width and L. We also derive an FPT algorithm for the Minimal Length-Bounded Cut problem when parameterized by the tree-depth. Thus showing an interesting paradigm for this problem and parameters tree-depth and path-width.},
archivePrefix = {arXiv},
arxivId = {1511.02801},
author = {Dvorak, Pavel and Knop, Dusan},
booktitle = {Theory and Applications of Models of Computation: 12th Annual Conference},
eprint = {1511.02801},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dvorak, Knop - 2015 - Parameterized Complexity of Length-Bounded Cuts and Multi-cuts.pdf:pdf},
keywords = {-hardness,1,length bounded cuts,parameterized algorithms,w},
pages = {441----452},
publisher = {Springer International Publishing},
title = {{Parameterized Complexity of Length-Bounded Cuts and Multi-cuts}},
url = {http://arxiv.org/abs/1511.02801},
year = {2015}
}
@article{Zhu2015,
author = {Zhu, Rong and Zou, Zhaonian and Li, Jianzhong},
doi = {10.1109/TKDE.2017.2725275},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu, Zou, Li - 2015 - Top-k Reliability Search on Uncertain Graphs.pdf:pdf},
isbn = {978-1-4673-9504-5},
issn = {1041-4347},
journal = {IEEE International Conference on Data Mining},
pages = {1--1},
title = {{Top-k Reliability Search on Uncertain Graphs}},
url = {http://ieeexplore.ieee.org/document/7973074/},
year = {2015}
}
@book{Sipser2006,
author = {Sipser, Michael},
edition = {Second},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sipser - 2006 - Introduction to the Theory of Computation.pdf:pdf},
isbn = {0534950973},
publisher = {Thomson Course Technology},
title = {{Introduction to the Theory of Computation}},
year = {2006}
}
@book{Rothe2013,
abstract = {This book presents sequential decision theory from a novel algorithmic information theory perspective. While the former is suited for active agents in known environments, the latter is suited for passive prediction in unknown environments. The book introduces these two well-known but very different ideas and removes the limitations by unifying them to one parameter-free theory of an optimal reinforcement learning agent embedded in an arbitrary unknown environment. Most if not all AI problems can easily be formulated within this theory, which reduces the conceptual problems to pure computational ones. Considered problem classes include sequence prediction, strategic games, function minimization, reinforcement and supervised learning. The discussion includes formal definitions of intelligence order relations, the horizon problem and relations to other approaches to AI. One intention of this book is to excite a broader AI audience about abstract algorithmic information theory concepts, and conversely to inform theorists about exciting applications to AI.},
author = {Rothe},
doi = {10.1007/978-3-642-16533-7},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rothe - 2013 - Complexity Theory and Cryptology.pdf:pdf},
isbn = {9783540299523},
pages = {1--288},
title = {{Complexity Theory and Cryptology}},
year = {2013}
}
@misc{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Garey, Johnson - Computers and Intracbility (1) (BookZZ.org).pdf.pdf:pdf},
title = {{Garey, Johnson - Computers and Intracbility (1) (BookZZ.org).pdf}}
}
@article{Arora2006,
abstract = {Computational complexity theory has developed rapidly in the past three decades. The list of surprising and fundamental results proved since 1990 alone could fill a book: these include new probabilistic definitions of classi- cal complexity classes (IP = PSPACE and the PCP Theorems) and their implications for the field of approximation algorithms; Shor's algorithm to factor integers using a quantum computer; an understanding of why current approaches to the famous P versus NP will not be successful; a theory of de- randomization and pseudorandomness based upon computational hardness; and beautiful constructions of pseudorandom objects such as extractors and expanders. This book aims to describe such recent achievements of complexity the- ory in the context of the classical results. It is intended to be a text and as well as a reference for self-study. This means it must simultaneously cater to many audiences, and it is carefully designed with that goal. Through- out the book we explain the context in which a certain notion is useful, and why things are defined in a certain way. Examples and solved exercises accompany key definitions},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Arora, Manish},
doi = {10.1088/1742-6596/1/1/035},
eprint = {arXiv:1011.1669v3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arora - 2006 - Computational Complexity A Modern Approach.pdf:pdf},
isbn = {0521424267},
issn = {17426588},
number = {August},
pages = {155--160},
pmid = {25246403},
title = {{Computational Complexity: A Modern Approach}},
url = {http://books.google.com/books?hl=en&lr=&id=8Wjqvsoo48MC&oi=fnd&pg=PR7&dq=Computational+Complexity:+A+Modern+Approach&ots=zmNW1gZjKC&sig=W7PpLSU6JBA9HAtfaHpHctbKcUU%5Cnhttp://stacks.iop.org/1742-6596/1/i=1/a=035?key=crossref.bdba4c77c62f2301977d65c84b2fc24},
volume = {1},
year = {2006}
}
@book{Kurose2013,
abstract = {Computer Networking continues with an early emphasis on application-layer paradigms and application programming interfaces (the top layer), encouraging a hands-on experience with protocols and networking concepts, before working down the protocol stack to more abstract layers. This book has become the dominant book for this course because of the authors' reputations, the precision of explanation, the quality of the art program, and the value of their own supplements. - See more at: http://www.pearsonhighered.com/educator/product/Computer-Networking-A-TopDown-Approach-6E/9780132856201.page#sthash.WYZBzrpy.dpuf},
archivePrefix = {arXiv},
arxivId = {8177588788},
author = {Kurose, James F. and Ross, Keith W.},
booktitle = {Pearson},
doi = {10.1017/CBO9781107415324.004},
eprint = {8177588788},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kurose, Ross - 2013 - Computer Networking A Top-Down Approach.pdf:pdf},
isbn = {9780132856201},
issn = {0889-5899},
number = {5},
pages = {4},
pmid = {8717009},
title = {{Computer Networking A Top-Down Approach}},
year = {2013}
}
@book{Bishop2006,
abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. A forthcoming companion volume will deal with practical aspects of pattern recognition and machine learning, and will include free software implementations of the key algorithms along with example data sets and demonstration programs. Christopher Bishop is Assistant Director at Microsoft Research Cambridge, and also holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, and was recently elected Fellow of the Royal Academy of Engineering. The author's previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Bishop, Christopher M CM Christopher M.},
booktitle = {Pattern Recognition},
doi = {10.1117/1.2819119},
eprint = {0-387-31073-8},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bishop - 2006 - Pattern Recognition and Machine Learning.pdf:pdf},
isbn = {978-0387310732},
issn = {10179909},
number = {4},
pages = {738},
pmid = {8943268},
title = {{Pattern Recognition and Machine Learning}},
url = {http://soic.iupui.edu/syllabi/semesters/4142/INFO_B529_Liu_s.pdf%5Cnhttp://www.library.wisc.edu/selectedtocs/bg0137.pdf%5Cnhttp://www.library.wisc.edu/selectedtocs/bg0137.pdf},
volume = {4},
year = {2006}
}
@book{Coppin2004,
abstract = {This book is intended for students of computer science at the college level, or students of other subjects that cover Artificial Intelligence. It also is intended to be an interesting and relevant introduction to the subject for other students or individuals who simply have an interest in the subject.},
author = {Coppin, Ben},
booktitle = {Expert Systems},
doi = {10.1049/esn.1987.0009},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Coppin - 2004 - Artificial Intelligence Illuminated.pdf:pdf},
isbn = {0763732303},
issn = {02650096},
pages = {768},
title = {{Artificial Intelligence Illuminated}},
year = {2004}
}
@misc{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Vapnik.djvu:djvu},
title = {{ Vapnik}}
}
@book{Saparbaev1988,
abstract = {A new method for obtaining the recombinant DNA based on heteroduplex-initiated site-directed insertion of alien nucleotide sequences is proposed. To generate a single-stranded region, plasmid DNA was nicked with restriction endonuclease in the presence of ethidium bromide with subsequent exonuclease III controlled digestion. The inserted DNA sequences flanked by nucleotide sequences complementary to single-stranded region were annealed with plasmid DNA and E. coli cells were transformed by the resulting heteroduplex molecules. The presented data show the possibility to insert as many as 200 nucleotides. The yield of recombinant DNA varied from 16 to 0.7% as the number of nucleotides inserted correspondingly varied from 15 to 200. The site of insertion does not depend crucially on the localization of the restriction site used.},
archivePrefix = {arXiv},
arxivId = {2010 (ret. 29.4.2010)},
author = {Saparbaev, M K and Mazin, a V and Ovchinnikova, L P and Dianov, G L and Salganik, R I},
booktitle = {Molekuliarnaia genetika, mikrobiologiia i virusologiia},
doi = {10.1163/9789004256064_hao_introduction},
eprint = {2010 (ret. 29.4.2010)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saparbaev et al. - 1988 - Introduction of new DNA sequences into previously selected regions of a plasmid genome by means of the formati.pdf:pdf},
isbn = {9780262033848},
issn = {0208-0613},
keywords = {Base Sequence,Cloning, Molecular,DNA Restriction Enzymes,DNA, Recombinant,Escherichia coli,Escherichia coli: genetics,Molecular,Nucleic Acid Heteroduplexes,Nucleic Acid Hybridization,Plasmids,Recombinant},
number = {2},
pages = {12--6},
pmid = {2836723},
title = {{[Introduction of new DNA sequences into previously selected regions of a plasmid genome by means of the formation of heteroduplexes].}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2560149&tool=pmcentrez&rendertype=abstract},
year = {1988}
}
@article{Valiant1986,
abstract = {For every known NP-complete problem, the number of solutions of its instances varies over a large range, from zero to exponentially many. It is therefore natural to ask if the inherent intractability of NP-complete problem is caused by this wide variation. We give a negative answer to this question using the notion of randomized polynomial time reducibility. We show that the problems of distinguishing between instances of SAT having zero or one solution, or of finding solutions to instances of SAT having a unique solution, are as hard as SAT, under randomized reductions. Several corollaries about the difficulty of specific problems follow. For example, computing the parity of the number of solutions of a SAT formula is shown to be NP-hard, and deciding if a SAT formula has a unique solution is shown to be Dp-hard, under randomized reduction. Central to the study of cryptography is the question as to whether there exist NP-problems whose instances have solutions that are unique but are hard to find. Our result can be interpreted as strengthening the belief that such problems exist. ?? 1986.},
author = {Valiant, L. G. and Vazirani, V. V.},
doi = {10.1016/0304-3975(86)90135-0},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Valiant, Vazirani - 1986 - NP is as easy as detecting unique solutions.pdf:pdf},
isbn = {0897911512},
issn = {03043975},
journal = {Theoretical Computer Science},
number = {C},
pages = {85--93},
title = {{NP is as easy as detecting unique solutions}},
volume = {47},
year = {1986}
}
@inproceedings{Bian2017,
abstract = {We investigate the performance of the Greedy algorithm for cardinality constrained maximization of non-submodular nondecreasing set functions. While there are strong theoretical guarantees on the performance of Greedy for maximizing submodular functions, there are few guarantees for non-submodular ones. However, Greedy enjoys strong empirical performance for many important non-submodular functions, e.g., the Bayesian A-optimality objective in experimental design. We prove theoretical guarantees supporting the empirical performance. Our guarantees are characterized by the (generalized) submodularity ratio $\gamma$ and the (generalized) curvature $\alpha$. In particular, we prove that Greedy enjoys a tight approximation guarantee of $\frac{1}{\alpha}(1- e^{-\gamma\alpha})$ for cardinality constrained maximization. In addition, we bound the submodularity ratio and curvature for several important real-world objectives, e.g., the Bayesian A-optimality objective, the determinantal function of a square submatrix and certain linear programs with combinatorial constraints. We experimentally validate our theoretical findings for several real-world applications.},
archivePrefix = {arXiv},
arxivId = {1703.02100},
author = {Bian, Andrew An and Buhmann, Joachim M. and Krause, Andreas and Tschiatschek, Sebastian},
booktitle = {Proceedings of the 34th International Conference on Machine Learning (ICML)},
eprint = {1703.02100},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bian et al. - 2017 - Guarantees for Greedy Maximization of Non-submodular Functions with Applications.pdf:pdf;:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bian et al. - 2017 - Guarantees for Greedy Maximization of Non-submodular Functions with Applications(2).pdf:pdf},
title = {{Guarantees for Greedy Maximization of Non-submodular Functions with Applications}},
year = {2017}
}
@article{Wan2010,
author = {Wan, Peng Jun and Du, Ding Zhu and Pardalos, Panos and Wu, Weili},
doi = {10.1007/s10589-009-9269-y},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wan et al. - 2010 - Greedy approximations for minimum submodular cover with submodular cost.pdf:pdf},
issn = {09266003},
journal = {Computational Optimization and Applications},
keywords = {Greedy approximations,Minimum submodular cover},
number = {2},
pages = {463--474},
title = {{Greedy approximations for minimum submodular cover with submodular cost}},
volume = {45},
year = {2010}
}
@article{Hamann2015,
abstract = {We introduce FlowCutter, a novel algorithm to compute a set of edge cuts or node separators that optimize cut size and balance in the Pareto-sense. Our core algorithm solves the balanced connected st-edge-cut problem, where two given nodes s and t must be separated by removing edges to obtain two connected parts. Using the core algorithm we build variants that compute node-cuts and are independent of s and t. Using the Pareto-set we can identify cuts with a particularly good trade-off that can be used to compute contraction and minimum fill-in orders. Our core algorithm has a running time in O(cm) where m is the number of edges and c the cut size. This makes it well-suited for large graphs with very small cuts, such as road graphs, which are our primary application.},
archivePrefix = {arXiv},
arxivId = {1504.03812},
author = {Hamann, Michael and Strasser, Ben},
eprint = {1504.03812},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hamann, Strasser - 2015 - Graph Bisection with Pareto-Optimization.pdf:pdf},
isbn = {9781510819689},
issn = {21640300},
pages = {1--20},
title = {{Graph Bisection with Pareto-Optimization}},
url = {http://arxiv.org/abs/1504.03812},
year = {2015}
}
@article{Delling2015,
author = {Delling, Daniel and Goldberg, Andrew V and Pajor, Thomas and Werneck, Renato F and Delling, Daniel and Goldberg, Andrew V and Pajor, Thomas and Werneck, Renato F},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Delling et al. - 2015 - Customizable Route Planning in Road Networks Customizable Route Planning in Road Networks.pdf:pdf},
keywords = {accepted,alternative routes,august 2014,bing maps,history,in advance,july 2013,published online in articles,received,road networks,route planning,routing in traffic,shortest paths},
number = {November},
pages = {1--31},
title = {{Customizable Route Planning in Road Networks Customizable Route Planning in Road Networks}},
year = {2015}
}
@article{Geisberger2012,
abstract = {Contraction hierarchies are a simple approach for fast routing in road networks. Our algorithm calculates exact shortest paths and handles road networks of whole continents. During a preprocessing step, we exploit the inherent hierarchical structure of road networks by adding shortcut edges. A subsequent modified bidirectional Dijkstra algorithm can then find a shortest path in a fraction of a millisecond, visiting only a few hundred nodes. This small search space makes it suitable to implement it on a mobile device. We present a mobile implementation that also handles changes in the road network, like traffic jams, and that allows instantaneous routing without noticeable delay for the user. Also, an algorithm to calculate large distance tables is currently the fastest if based on contraction hierarchies.},
author = {Geisberger, Robert and Sanders, Peter and Schultes, Dominik and Vetter, Christian},
doi = {10.1287/trsc.1110.0401},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Geisberger et al. - 2012 - Exact Routing in Large Road Networks Using Contraction Hierarchies.pdf:pdf},
issn = {0041-1655},
journal = {Transportation Science},
keywords = {algorithm engineering,route planning,shortest paths},
number = {3},
pages = {388--404},
title = {{Exact Routing in Large Road Networks Using Contraction Hierarchies}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/trsc.1110.0401},
volume = {46},
year = {2012}
}
@inproceedings{Kuhnle2017a,
abstract = {{\textcopyright} 2017 ACM. Based upon the idea that network functionality is impaired if two nodes in a network are sufficiently separated in terms of a given metric, we introduce two combinatorial pseudocut problems generalizing the classical min-cut and multi-cut problems. We expect the pseudocut problems will find broad relevance to the study of network reliability.We comprehensively analyze the computational complexity of the pseudocut problems and provide three approximation algorithms for these problems. Motivated by applications in communication networks with strict Quality-of-Service (QoS) requirements, we demonstrate the utility of the pseudocut problems by proposing a targeted vulnerability assessment for the structure of communication networks using QoS metrics; we perform experimental evaluations of our proposed approximation algorithms in this context.},
author = {Kuhnle, A. and Pan, T. and Crawford, V.G. and Alim, M.A. and Thai, M.T.},
booktitle = {Proceedings of the 2017 ACM SIGMETRICS / International Conference on Measurement and Modeling of Computer Systems},
doi = {10.1145/3078505.3078538},
isbn = {9781450350327},
keywords = {Approximation algorithms,Network cutting problems},
title = {{Pseudo-Separation for Assessment of Structural Vulnerability of a Network}},
year = {2017}
}
@article{Zak,
author = {Zak, Michail},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zak - Unknown - Computational Social Networks Search for dynamical origin of social networks .pdf:pdf},
title = {{Computational Social Networks Search for dynamical origin of social networks .}}
}
@article{Strasser2017,
author = {Strasser, Ben},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Strasser - 2017 - Computing Tree Decompositions with FlowCutter.pdf:pdf},
keywords = {2016,23,4230,5 keywords,and phrases dummy keyword,cvit,digital object identifier 10,lipics,please provide 1},
number = {23},
pages = {1--12},
title = {{Computing Tree Decompositions with FlowCutter :}},
year = {2017}
}
@article{Lia,
author = {Li, Xiang and Member, Student and Smith, J David and Member, Student and Pan, Tianyi and Dinh, Thang N and Thai, My},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - Unknown - Quantifying Privacy Vulnerability to Socialbot Attacks An Adaptive Non-Submodular Model.pdf:pdf},
pages = {1--12},
title = {{Quantifying Privacy Vulnerability to Socialbot Attacks : An Adaptive Non-Submodular Model}}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Breaking the Bonds of Submodularity Approximation Bounds for Non-Submodular Greedy Maximization.pdf:pdf},
title = {{Breaking the Bonds of Submodularity : Approximation Bounds for Non-Submodular Greedy Maximization}}
}
@article{Pallottino2003,
abstract = {We propose the first algorithmic approach which reoptimizes the shortest paths when any subset of arcs of the input graph is affected by a change of the costs, which can be either lower or higher than the old ones. This situation is more general than the ones addressed in the literature so far. We analyze the worst-case time complexity of the algorithm as a function of both the input size and the overall cost perturbation, and discuss cases for which the proposed reoptimization method theoretically outperforms the approach of applying a standard shortest path algorithm after the change of the arc costs. ?? 2002 Elsevier Science B.V. All rights reserved.},
author = {Pallottino, Stefano and Scutell{\`{a}}, Maria Grazia},
doi = {10.1016/S0167-6377(02)00192-X},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pallottino, Scutell{\`{a}} - 2003 - A new algorithm for reoptimizing shortest paths when the arc costs change.pdf:pdf},
issn = {01676377},
journal = {Operations Research Letters},
keywords = {Flow algorithms,Reoptimization,Shortest paths},
number = {2},
pages = {149--160},
title = {{A new algorithm for reoptimizing shortest paths when the arc costs change}},
volume = {31},
year = {2003}
}
@article{Gallo1980,
author = {Gallo, G.},
doi = {10.1007/BF02092136},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gallo - 1980 - Reoptimization procedures in shortest path problem.pdf:pdf},
issn = {15938883},
journal = {Rivista di Matematica per le Scienze Economiche e Sociali},
keywords = {Networks,Shortest Path},
number = {1},
pages = {3--13},
title = {{Reoptimization procedures in shortest path problem}},
volume = {3},
year = {1980}
}
@article{Italia1986,
author = {Italia, Corso},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Italia - 1986 - Gallo_Pallotino_unified_Approach.pdf:pdf},
keywords = {shortest path},
pages = {38--64},
title = {{Gallo_Pallotino_unified_Approach}},
volume = {26},
year = {1986}
}
@article{Frigioni2000,
abstract = {We propose fully dynamic algorithms for maintaining the distances and the shortest paths from a single source in either a directed or an undirected graph with positive real edge weights, handling insertions, deletions, and weight updates of edges. The algorithms require linear space and optimal query time. The cost of the update operations depends on the class of the considered graph and on the number of the output updates, i.e., on the number of vertices that, due to an edge modification, either change the distance from the source or change the parent in the shortest paths tree. We first show that, if we deal only with updates on the weights of edges, then the update procedures require O(logn) worst case time per output update for several classes of graphs, as in the case of graphs with bounded genus, bounded arboricity, bounded degree, bounded treewidth, and bounded pagenumber. For general graphs with n vertices and m edges the algorithms require O(mlogn) worst case time per output update. We also show that, if insertions and deletions of edges are allowed, then similar amortized bounds hold.},
author = {Frigioni, Daniele and Marchetti-Spaccamela, Alberto and Nanni, Umberto},
doi = {10.1006/jagm.1999.1048},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frigioni, Marchetti-Spaccamela, Nanni - 2000 - Fully Dynamic Algorithms for Maintaining Shortest Paths Trees.pdf:pdf},
issn = {01966774},
journal = {Journal of Algorithms},
number = {2},
pages = {251--281},
title = {{Fully Dynamic Algorithms for Maintaining Shortest Paths Trees}},
url = {http://www.sciencedirect.com/science/article/pii/S0196677499910489},
volume = {34},
year = {2000}
}
@article{Ramalingam1996,
abstract = {The grammar problem, a generalization of the single-source shortest-path problem introduced by D. E. Knuth (Inform. Process. Lett. 6(1) (1977), 1-5) is to compute the minimum-cost derivation of a terminal string from each nonterminal of a given context-free grammar, with the cost of a derivation being suitably defined. This problem also subsumes the problem of finding optimal hyperpaths in directed hypergraphs (under varying optimization criteria) that has received attention recently. In this paper we present an incremental algorithm for a version of the grammar problem. As a special case of this algorithm we obtain an efficient incremental algorithm for the single-source shortest-path problem with positive edge lengths. The aspect of our work that distinguishes it from other work on the dynamic shortest-path problem is its ability to handle ''multiple heterogeneous modifications'': between updates, the input graph is allowed to be restructured by an arbitrary mixture of edge insertions, edge deletions, and edge-length changes. (C) 1996 Academic Press, Inc.},
author = {Ramalingam, G. and Reps, Thomas},
doi = {10.1006/jagm.1996.0046},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramalingam, Reps - 1996 - An Incremental Algorithm for a Generalization of the Shortest-Path Problem.pdf:pdf},
issn = {01966774},
journal = {Journal of Algorithms},
number = {2},
pages = {267--305},
title = {{An Incremental Algorithm for a Generalization of the Shortest-Path Problem}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0196677496900462},
volume = {21},
year = {1996}
}
@misc{Even1975,
abstract = {An algorithm of Dinic for finding the maximum flow in a network is described. It is then shown that if the vertex capacities are all equal to one, the algorithm requires at most $O(|V|^{1/2} \cdot |E|)$ time, and if the edge capacities are all equal to one, the algorithm requires at most $O(|V|^{2/3} \cdot |E|)$ time. Also, these bounds are tight for Dinic's algorithm. These results are used to test the vertex connectivity of a graph in $O(|V|^{1/2} \cdot |E|^2 )$ time and the edge connectivity in $O(|V|^{5/3} \cdot |E|)$ time.},
author = {Even, Shimon and Tarjan, R. Endre},
booktitle = {SIAM Journal on Computing},
doi = {10.1137/0204043},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Even, Tarjan - 1975 - Network Flow and Testing Graph Connectivity.pdf:pdf},
issn = {0097-5397},
number = {4},
pages = {507--518},
title = {{Network Flow and Testing Graph Connectivity}},
url = {http://epubs.siam.org/doi/abs/10.1137/0204043},
volume = {4},
year = {1975}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Model and Short Paths between Pair a $\sim$ -edge.pdf:pdf},
title = {{Model and Short Paths between Pair a $\sim$ -edge}}
}
@article{Chekuri2003,
abstract = {The approximability of the maximum edge disjoint paths problem (EDP) in directed graphs was seemingly settled by the )-hardness result of Guruswami et al. [10] and the O( m) approximation achievable via both the natural LP relaxation [19] and the greedy algorithm [11, 12]. Here m is the number of edges in the graph. However, we observe that the hardness of approximation shown in [10] applies to sparse graphs and hence when expressed as a function of n, the number of vertices, only an...},
author = {Chekuri, C.\ and Khanna, S.\},
doi = {10.1145/1290672.1290683},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chekuri, Khanna - 2003 - Edge disjoint paths revisited.pdf:pdf},
issn = {15496325},
journal = {Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms (Baltimore, MD, 2003)},
pages = {628--637},
title = {{Edge disjoint paths revisited}},
year = {2003}
}
@article{Mathematica1978,
author = {Mathematica, Periodica and Vol, Hungarica},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mathematica, Vol - 1978 - MENGERIAN THEOREMS FOR PATHS OF.pdf:pdf},
keywords = {and phrases,disjoint paths,menger,minimum cut-sets,s theorem},
number = {4},
pages = {269--276},
title = {{MENGERIAN THEOREMS FOR PATHS OF}},
volume = {9},
year = {1978}
}
@article{Lee,
archivePrefix = {arXiv},
arxivId = {arXiv:1607.05133v1},
author = {Lee, Euiwoong},
eprint = {arXiv:1607.05133v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee - 2016 - Improved Hardness for Cut, Interdiction, and Firefighter Problems.pdf:pdf},
journal = {Arxiv preprint arxiv:1607.05133v1},
title = {{Improved Hardness for Cut, Interdiction, and Firefighter Problems}},
year = {2016}
}
@article{Guruswami2003,
author = {Guruswami, Venkatesan and Khanna, Sanjeev and Rajaraman, {\~{A}} Rajmohan and Shepherd, Bruce and Yannakakis, Mihalis},
doi = {10.1016/S0022-0000(03)00066-7},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guruswami et al. - 2003 - Near-optimal hardness results and approximation algorithms for edge-disjoint paths and related problems $.pdf:pdf},
keywords = {approximation,approximation algorithms,bounded length edge-disjoint paths,edge-disjoint paths,hardness of,multicommodity flow,network routing,unsplittable flow,vertex-disjoint paths},
pages = {473--496},
title = {{Near-optimal hardness results and approximation algorithms for edge-disjoint paths and related problems $}},
volume = {67},
year = {2003}
}
@article{Boucher2012,
author = {Boucher, Christina and Lo, Christine},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boucher, Lo - 2012 - Consensus Patterns ( Probably ) Has no EPTAS.pdf:pdf},
title = {{Consensus Patterns ( Probably ) Has no EPTAS}},
year = {2012}
}
@article{Baier2010,
author = {Baier, Georg and Erlebach, Thomas and Hall, Alexander and Koehler, Ekkehard and Kolman, Petr and Pangrac, Ondrej and Schilling, Heiko and Skutella, Martin},
doi = {10.1145/1868237.1868241},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baier et al. - 2010 - Length-Bounded Cuts and Flows.pdf:pdf},
journal = {ACM Transactions on Algorithms},
number = {1},
pages = {1--27},
title = {{Length-Bounded Cuts and Flows}},
volume = {7},
year = {2010}
}
@book{Hutchison,
author = {Hutchison, David and Mitchell, John C},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hutchison, Mitchell - Unknown - Lecture Notes in Computer Science.pdf:pdf},
isbn = {9783540359043},
title = {{Lecture Notes in Computer Science}}
}
@misc{Casella,
author = {Casella, George and Berger, Roger L.},
booktitle = {Population trends},
doi = {10.1057/pt.2010.23},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Casella, Berger - Unknown - Statistical Inference.pdf:pdf},
isbn = {0534243126},
issn = {0307-4463},
number = {141},
pages = {;sf},
pmid = {20927031},
title = {{Statistical Inference}}
}
@article{Brandes2005,
abstract = {We consider variations of two well-known centrality measures, betweenness and closeness, witha different model of information spread. Rather than along shortest paths only, it is assumed that information spreads efficiently like an electrical current. We prove that the current-flow variant of closeness centrality is identical with another known measure, information centrality, and give improved algorithms for computing bothmeasures exactly. Since running times and space requirements are prohibitive for large networks, we also present a randomized approximation scheme for current-flow betweenness.},
author = {Brandes, Ulrik and Fleischer, Daniel},
doi = {10.1007/978-3-540-31856-9_44},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brandes, Fleischer - 2005 - Centrality measures based on current flow.pdf:pdf},
isbn = {3540249982},
issn = {03029743},
journal = {Lecture Notes in Computer Science},
pages = {533--544},
title = {{Centrality measures based on current flow}},
url = {http://www.inf.uni-konstanz.de/algo/publications/bf-cmbcf-05.pdf},
year = {2005}
}
@article{Svensson2012,
author = {Svensson, Ola},
doi = {10.1007/978-3-642-32512-0_26},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Svensson - 2012 - Hardness of vertex deletion and project scheduling.pdf:pdf},
isbn = {9783642325113},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {301--312},
title = {{Hardness of vertex deletion and project scheduling}},
volume = {7408 LNCS},
year = {2012}
}
@article{Bansal2010,
author = {Bansal, Nikhil and Khot, Subhash},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bansal, Khot - 2010 - Inapproximability of Hypergraph Vertex Cover and Applications to Scheduling Problems.pdf:pdf},
pages = {250--261},
title = {{Inapproximability of Hypergraph Vertex Cover and Applications to Scheduling Problems}},
volume = {1},
year = {2010}
}
@article{Li2017a,
author = {Li, Xiang and Smith, J. David and Dinh, Thang N. and Thai, My T.},
doi = {10.1109/WI.2016.0051},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2017 - Privacy Issues in Light of Reconnaissance Attacks with Incomplete Information.pdf:pdf},
isbn = {9781509044702},
journal = {Proceedings - 2016 IEEE/WIC/ACM International Conference on Web Intelligence, WI 2016},
keywords = {Adaptive Algorithms,Incomplete Topology,Social Networks Analysis,Target Reconnaissance Attacks},
pages = {311--318},
title = {{Privacy Issues in Light of Reconnaissance Attacks with Incomplete Information}},
year = {2017}
}
@article{Ying2016,
author = {Ying, Lei},
doi = {10.1145/2896377.2901463},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ying - 2016 - On the Approximation Error of Mean-Field Models.pdf:pdf},
isbn = {9781450342667},
issn = {0163-5999},
journal = {Proceedings of the 2016 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Science - SIGMETRICS '16},
number = {1},
pages = {285--297},
title = {{On the Approximation Error of Mean-Field Models}},
url = {http://dl.acm.org/citation.cfm?doid=2896377.2901463},
volume = {44},
year = {2016}
}
@inproceedings{Lu2016,
author = {Lu, Ning and Li, Bin and Srikant, R and Ying, Lei},
booktitle = {IEEE 55th Conference on Decision and Control (CDC)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu et al. - 2016 - Optimal Distributed Scheduling of Real-Time Traffic with Hard Deadlines.pdf:pdf},
isbn = {9781509018369},
title = {{Optimal Distributed Scheduling of Real-Time Traffic with Hard Deadlines}},
year = {2016}
}
@article{Zhu2016,
abstract = {This paper studies the problem of detecting the information source in a network in which the spread of information follows the popular Susceptible-Infected-Recovered (SIR) model. We assume all nodes in the network are in the susceptible state initially except the information source which is in the infected state. Susceptible nodes may then be infected by infected nodes, and infected nodes may recover and will not be infected again after recovery. Given a snapshot of the network, from which we know all infected nodes but cannot distinguish susceptible nodes and recovered nodes, the problem is to find the information source based on the snapshot and the network topology. We develop a sample path based approach where the estimator of the information source is chosen to be the root node associated with the sample path that most likely leads to the observed snapshot. We prove for infinite-trees, the estimator is a node that minimizes the maximum distance to the infected nodes. A reverse-infection algorithm is proposed to find such an estimator in general graphs. We prove that for $g$-regular trees such that $gq>1,$ where $g$ is the node degree and $q$ is the infection probability, the estimator is within a constant distance from the actual source with a high probability, independent of the number of infected nodes and the time the snapshot is taken. Our simulation results show that for tree networks, the estimator produced by the reverse-infection algorithm is closer to the actual source than the one identified by the closeness centrality heuristic. We then further evaluate the performance of the reverse infection algorithm on several real world networks.},
archivePrefix = {arXiv},
arxivId = {1206.5421},
author = {Zhu, Kai and Ying, Lei},
doi = {10.1109/TNET.2014.2364972},
eprint = {1206.5421},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu, Ying - 2016 - Information Source Detection in the SIR Model A Sample-Path-Based Approach.pdf:pdf},
isbn = {978-1-4673-4647-4},
issn = {10636692},
journal = {IEEE/ACM Transactions on Networking},
keywords = {Information source detection,Susceptible-Infected-Recovered (SIR) model,sample-path-based approach},
number = {1},
pages = {408--421},
title = {{Information Source Detection in the SIR Model: A Sample-Path-Based Approach}},
volume = {24},
year = {2016}
}
@article{Ying2017,
author = {Ying, Lei},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ying - 2017 - Stein's Method for Mean-Field Approximations in Light and Heavy Traffic Regimes.pdf:pdf},
isbn = {9781450350327},
pages = {3078592},
title = {{Stein's Method for Mean-Field Approximations in Light and Heavy Traffic Regimes}},
year = {2017}
}
@article{Wang2016c,
author = {Wang, Weina and Ying, Lei and Zhang, Junshan},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Ying, Zhang - 2016 - On the Relation Between Identifiability, Differential Privacy, and Mutual-Information Privacy.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
number = {9},
pages = {5018--5029},
title = {{On the Relation Between Identifiability, Differential Privacy, and Mutual-Information Privacy}},
volume = {62},
year = {2016}
}
@inproceedings{Gravina2016a,
abstract = {Low latency analytics on geographically distributed dat- asets (across datacenters, edge clusters) is an upcoming and increasingly important challenge. The dominant approach of aggregating all the data to a single data- center significantly inflates the timeliness of analytics. At the same time, running queries over geo-distributed inputs using the current intra-DC analytics frameworks also leads to high query response times because these frameworks cannot cope with the relatively low and variable capacity of WAN links. We present Iridium, a system for low latency geo-distri- buted analytics. Iridium achieves low query response times by optimizing placement of both data and tasks of the queries. The joint data and task placement op- timization, however, is intractable. Therefore, Iridium uses an online heuristic to redistribute datasets among the sites prior to queries' arrivals, and places the tasks to reduce network bottlenecks during the query's ex- ecution. Finally, it also contains a knob to budget WAN usage. Evaluation across eight worldwide EC2 re- gions using production queries show that Iridium speeds up queries by 3× − 19× and lowers WAN usage by 15%−64% compared to existing baselines.},
archivePrefix = {arXiv},
arxivId = {arXiv:1602.05561v1},
author = {Gravina, Daniele and Liapis, Antonios and Yannakakis, Georgio},
booktitle = {KDD},
doi = {10.475/123},
eprint = {arXiv:1602.05561v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gravina, Liapis, Yannakakis - 2016 - FASCINATE Fast Cross-Layer Dependency Inference on Multi-layered Networks.pdf:pdf},
isbn = {9781450335423},
issn = {0146-4833},
keywords = {WAN analytics,data analytics,geo-distributed,low latency,network aware},
title = {{FASCINATE: Fast Cross-Layer Dependency Inference on Multi-layered Networks}},
url = {Microsoft Research%5CnUniversity of California at Berkeley%5CnUniversity of Wisconsin at Madison},
year = {2016}
}
@article{Rysz,
author = {Rysz, Maciej and Krokhmal, Pavlo A and Pasiliao, Eduardo L},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rysz, Krokhmal, Pasiliao - Unknown - Detecting Resilient Structures in Stochastic Networks A Two-Stage Stochastic Optimization Approach.pdf:pdf},
keywords = {combinatorial branch-and-bound algorithm,maximum subgraph problem,resilience of subgraphs,stochastic graphs,stochastic maximum clique,stochastic optimization,two-stage},
pages = {1--26},
title = {{Detecting Resilient Structures in Stochastic Networks : A Two-Stage Stochastic Optimization Approach}}
}
@article{Gast2015,
author = {Gast, Nicolas and Gast, Nicolas and Power, The and Gast, Nicolas},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gast et al. - 2015 - The Power of Two Choices on Graphs the Pair-Approximation is Accurate To cite this version The Power of Two Choic.pdf:pdf},
title = {{The Power of Two Choices on Graphs : the Pair-Approximation is Accurate To cite this version : The Power of Two Choices on Graphs : the Pair-Approximation is Accurate}},
year = {2015}
}
@article{Aydin2016,
abstract = {Balanced partitioning is often a crucial first step in solving large-scale graph optimization problems: in some cases, a big graph is chopped into pieces that fit on one machine to be processed independently before stitching the results together, leading to certain suboptimality from the interaction among different pieces. In other cases, links between different parts may show up in the running time and/or network communications cost, hence the desire to have small cut size. We study a distributed balanced partitioning problem where the goal is to partition the vertices of a given graph into k pieces, minimizing the total cut size. Our algorithm is composed of a few steps that are easily implementable in distributed computation frameworks, e.g., MapReduce. The algorithm first embeds nodes of the graph onto a line, and then processes nodes in a distributed manner guided by the linear embedding order. We examine various ways to find the first embedding, e.g., via a hierarchical clustering or Hilbert curves. Then we apply four different techniques such as local swaps, minimum cuts on partition boundaries, as well as contraction and dynamic programming. Our empirical study compares the above techniques with each other, and to previous work in distributed algorithms, e.g., a label propagation method [34], FENNEL [32] and Spinner [23]. We report our results both on a private map graph and several public social networks, and show that our results beat previous distributed algorithms: we notice, e.g., 15-25% reduction in cut size over [34]. We also observe that our algorithms allow for scalable distributed implementation for any number of partitions. Finally, we apply our techniques for the Google Maps Driving Directions to minimize the number of multi-shard queries with the goal of saving in CPU usage. During live experiments, we observe an ≈ 40% drop in the number of multi-shard queries when comparing our method with a standard geography-based method. {\textcopyright} 2016 Copyright held by the owner/author(s).},
archivePrefix = {arXiv},
arxivId = {1512.02727},
author = {Aydin, Kevin and Bateni, MohammadHossein and Mirrokni, Vahab},
doi = {10.1145/2835776.2835829},
eprint = {1512.02727},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aydin, Bateni, Mirrokni - 2016 - Distributed Balanced Partitioning via Linear Embedding.pdf:pdf},
isbn = {9781450337168},
journal = {Proceedings of the Ninth ACM International Conference on Web Search and Data Mining - WSDM '16},
keywords = {cut minimization,embedding to line,imbalance,local im-,mapreduce,maps,partitioning,provement,social networks},
pages = {387--396},
title = {{Distributed Balanced Partitioning via Linear Embedding}},
url = {http://dl.acm.org/citation.cfm?doid=2835776.2835829},
year = {2016}
}
@article{Esfandiari2015,
author = {Esfandiari, Hossein and Korula, Nitish and Mirrokni, Vahab},
doi = {10.1145/2764468.2764536},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Esfandiari, Korula, Mirrokni - 2015 - Online Allocation with Traffic Spikes Mixing Adversarial and Stochastic Models.pdf:pdf},
isbn = {9781450334105},
journal = {Proceedings of the Sixteenth ACM Conference on Economics and Computation},
pages = {169--186},
title = {{Online Allocation with Traffic Spikes: Mixing Adversarial and Stochastic Models}},
year = {2015}
}
@article{Detection,
author = {Detection, Hierarchical Community and Nonnegative, Symmetric and Factorization, Matrix},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Detection, Nonnegative, Factorization - Unknown - Hierarchical Community Detection via Rank-2 Symmetric Nonnegative Matrix Factorization.pdf:pdf},
title = {{Hierarchical Community Detection via Rank-2 Symmetric Nonnegative Matrix Factorization}}
}
@article{Fiorini,
author = {Fiorini, Samuel and Schaudt, Oliver},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fiorini, Schaudt - Unknown - A 7 3-Approximation Algorithm for Cluster Vertex Deletion.pdf:pdf},
title = {{A 7 / 3-Approximation Algorithm for Cluster Vertex Deletion}}
}
@article{Bafna1999,
author = {Bafna, Vineet and Berman, Piotr and Fujito, Toshihiro},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bafna, Berman, Fujito - 1999 - A 2-Approximation Algorithm for the Undirected Feedback Vertex Set Problem.pdf:pdf},
journal = {Siam Journal of Discrete Math},
keywords = {finite-volume method,multiphase,multiscale physics,subsurface flow,upscaling},
number = {3},
pages = {289--297},
title = {{A 2-Approximation Algorithm for the Undirected Feedback Vertex Set Problem}},
volume = {12},
year = {1999}
}
@article{Xia2012,
abstract = {We present new kernelization results for two problems, s-cycle transversal and (???s)-cycle transversal, when s is 4 or 5. We show that 4-cycle transversal and ???4-cycle transversal admit 6 k2 vertex kernels in general graphs. We then prove NP-completeness of s-cycle transversal and (???s)-cycle transversal in planar graphs for s>3. We show the following linear vertex kernels in planar graphsa 74k vertex kernel for 4-cycle transversal; a 32k vertex kernel for (???4)-cycle transversal; a 266k vertex kernel for (???5)-cycle transversal. ?? 2011 Elsevier B.V. All rights reserved.},
author = {Xia, Ge and Zhang, Yong},
doi = {10.1016/j.dam.2011.12.024},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xia, Zhang - 2012 - Kernelization for cycle transversal problems.pdf:pdf},
isbn = {3642143547},
issn = {0166218X},
journal = {Discrete Applied Mathematics},
keywords = {Cycle transversal,Kernelization,Planar graphs},
number = {7-8},
pages = {1224--1231},
title = {{Kernelization for cycle transversal problems}},
volume = {160},
year = {2012}
}
@misc{snapnets,
author = {Leskovec, Jure and Krevl, Andrej},
booktitle = {http://snap.stanford.edu/data},
howpublished = {\url{http://snap.stanford.edu/data}},
month = {jun},
title = {{{SNAP Datasets}: {Stanford} Large Network Dataset Collection}},
year = {2020}
}
@article{Zhang,
author = {Zhang, Huiling and Kuhnle, Alan and Zhang, Huiyuan and Thai, My T and Members, Senior},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - Unknown - Detect Misinformation Cascades before They Go Viral in Online Social Networks.pdf:pdf},
pages = {1--12},
title = {{Detect Misinformation Cascades before They Go Viral in Online Social Networks}}
}
@article{Grajales2014,
abstract = {BACKGROUND: Social media are dynamic and interactive computer-mediated communication tools that have high penetration rates in the general population in high-income and middle-income countries. However, in medicine and health care, a large number of stakeholders (eg, clinicians, administrators, professional colleges, academic institutions, ministries of health, among others) are unaware of social media's relevance, potential applications in their day-to-day activities, as well as the inherent risks and how these may be attenuated and mitigated. OBJECTIVE: We conducted a narrative review with the aim to present case studies that illustrate how, where, and why social media are being used in the medical and health care sectors. METHODS: Using a critical-interpretivist framework, we used qualitative methods to synthesize the impact and illustrate, explain, and provide contextual knowledge of the applications and potential implementations of social media in medicine and health care. Both traditional (eg, peer-reviewed) and nontraditional (eg, policies, case studies, and social media content) sources were used, in addition to an environmental scan (using Google and Bing Web searches) of resources. RESULTS: We reviewed, evaluated, and synthesized 76 articles, 44 websites, and 11 policies/reports. Results and case studies are presented according to 10 different categories of social media: (1) blogs (eg, WordPress), (2) microblogs (eg, Twitter), (3) social networking sites (eg, Facebook), (4) professional networking sites (eg, LinkedIn, Sermo), (5) thematic networking sites (eg, 23andMe), (6) wikis (eg, Wikipedia), (7) mashups (eg, HealthMap), (8) collaborative filtering sites (eg, Digg), (9) media sharing sites (eg, YouTube, Slideshare), and others (eg, SecondLife). Four recommendations are provided and explained for stakeholders wishing to engage with social media while attenuating risk: (1) maintain professionalism at all times, (2) be authentic, have fun, and do not be afraid, (3) ask for help, and (4) focus, grab attention, and engage. CONCLUSIONS: The role of social media in the medical and health care sectors is far reaching, and many questions in terms of governance, ethics, professionalism, privacy, confidentiality, and information quality remain unanswered. By following the guidelines presented, professionals have a starting point to engage with social media in a safe and ethical manner. Future research will be required to understand the synergies between social media and evidence-based practice, as well as develop institutional policies that benefit patients, clinicians, public health practitioners, and industry alike.},
author = {Grajales, Francisco Jose and Sheps, Samuel and Ho, Kendall and Novak-Lauscher, Helen and Eysenbach, Gunther},
doi = {10.2196/jmir.2912},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grajales et al. - 2014 - Social media A review and tutorial of applications in medicine and health care.pdf:pdf},
isbn = {1438-8871},
issn = {14388871},
journal = {Journal of Medical Internet Research},
keywords = {Blogging,Social media,Social network},
number = {2},
pmid = {24518354},
title = {{Social media: A review and tutorial of applications in medicine and health care}},
volume = {16},
year = {2014}
}
@article{Heldman2013,
abstract = {Social media are designed to be engaging, but often are used as a mechanism by public health organizations and practitioners for mass information dissemination rather than engaging audiences in true multi-way conversations and interactions. In this article we define and discuss social media engagement for public health communication. We examine different levels of engagement for public health communication and consider the potential risks, benefits, and challenges of truly embracing the social component in public health practice. Some implications of engagement for public health communication via social media are addressed, and recommendations for future work and research are proposed. [PUBLICATION ABSTRACT]},
author = {Heldman, Amy and Schindelar, Jessica and Weaver, James},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Heldman, Schindelar, Weaver - 2013 - Social Media Engagement and Public Health Communication Implications for Public Health Organization.pdf:pdf},
issn = {21076952},
journal = {Public Health Reviews},
keywords = {Disease Prevention,Public Health,Social Networks,Social Research,Verbal Communication},
number = {1},
pages = {1--18},
title = {{Social Media Engagement and Public Health Communication: Implications for Public Health Organizations Being Truly "Social"}},
volume = {35},
year = {2013}
}
@article{Merolli2013,
abstract = {Whilst the future for social media in chronic disease management appears to be optimistic, there is limited concrete evidence indicating whether and how social media use significantly improves patient outcomes. This review examines the health outcomes and related effects of using social media, while also exploring the unique affordances underpinning these effects. Few studies have investigated social media's potential in chronic disease, but those we found indicate impact on health status and other effects are positive, with none indicating adverse events. Benefits have been reported for psychosocial management via the ability to foster support and share information; however, there is less evidence of benefits for physical condition management. We found that studies covered a very limited range of social media platforms and that there is an ongoing propensity towards reporting investigations of earlier social platforms, such as online support groups (OSG), discussion forums and message boards. Finally, it is hypothesized that for social media to form a more meaningful part of effective chronic disease management, interventions need to be tailored to the individualized needs of sufferers. The particular affordances of social media that appear salient in this regard from analysis of the literature include: identity, flexibility, structure, narration and adaptation. This review suggests further research of high methodological quality is required to investigate the affordances of social media and how these can best serve chronic disease sufferers. Evidence-based practice (EBP) using social media may then be considered. ?? 2013 Elsevier Inc.},
author = {Merolli, Mark and Gray, Kathleen and Martin-Sanchez, Fernando},
doi = {10.1016/j.jbi.2013.04.010},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Merolli, Gray, Martin-Sanchez - 2013 - Health outcomes and related effects of using social media in chronic disease management A literat.pdf:pdf},
isbn = {1532-0464},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Affordances,Chronic disease,Health outcomes,Social media,Web 2.0},
number = {6},
pages = {957--969},
pmid = {23702104},
publisher = {Elsevier Inc.},
title = {{Health outcomes and related effects of using social media in chronic disease management: A literature review and analysis of affordances}},
url = {http://dx.doi.org/10.1016/j.jbi.2013.04.010},
volume = {46},
year = {2013}
}
@article{Weitzman2011,
abstract = {OBJECTIVE: To foster informed decision-making about health social networking (SN) by patients and clinicians, the authors evaluated the quality/safety of SN sites' policies and practices.\n\nDESIGN: Multisite structured observation of diabetes-focused SN sites. Measurements 28 indicators of quality and safety covering: (1) alignment of content with diabetes science and clinical practice recommendations; (2) safety practices for auditing content, supporting transparency and moderation; (3) accessibility of privacy policies and the communication and control of privacy risks; and (4) centralized sharing of member data and member control over sharing.\n\nRESULTS: Quality was variable across n=10 sites: 50% were aligned with diabetes science/clinical practice recommendations with gaps in medical disclaimer use (30% have) and specification of relevant glycosylated hemoglobin levels (0% have). Safety was mixed with gaps in external review approaches (20% used audits and association links) and internal review approaches (70% use moderation). Internal safety review offers limited protection: misinformation about a diabetes 'cure' was found on four moderated sites. Of nine sites with advertising, transparency was missing on five; ads for unfounded 'cures' were present on three. Technological safety was poor with almost no use of procedures for secure data storage and transmission; only three sites support member controls over personal information. Privacy policies' poor readability impedes risk communication. Only three sites (30%) demonstrated better practice. Limitations English-language diabetes sites only.\n\nCONCLUSION: The quality/safety of diabetes SN is variable. Observed better practice suggests improvement is feasible. Mechanisms for improvement are recommended that engage key stakeholders to balance autonomy, community ownership, conditions for innovation, and consumer protection.},
author = {Weitzman, Elissa R and Cole, Emily and Kaci, Liljana and Mandl, Kenneth D},
doi = {10.1136/jamia.2010.009712},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weitzman et al. - 2011 - Social but safe Quality and safety of diabetes-related online social networks.pdf:pdf},
isbn = {1067-5027},
issn = {1527-974X},
journal = {Journal of the American Medical Informatics Association : JAMIA},
keywords = {Computer Security,Confidentiality,Consumer Health Information,Diabetes Mellitus,Diabetes Mellitus: therapy,Humans,Information Dissemination,Internet,Quality of Health Care,Safety,Social Support,United States},
number = {3},
pages = {292--7},
pmid = {21262920},
title = {{Social but safe? Quality and safety of diabetes-related online social networks.}},
url = {http://jamia.oxfordjournals.org/content/18/3/292.abstract},
volume = {18},
year = {2011}
}
@article{Mooney2016,
author = {Mooney, Stephen J and Westreich, Daniel J and El-sayed, Abdulrahman M},
doi = {10.1097/EDE.0000000000000274.Epidemiology},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mooney, Westreich, El-sayed - 2016 - Epidemiology in the Era of Big Data.pdf:pdf},
isbn = {0000000000000},
journal = {HHS Public Access},
keywords = {big data,computer programming,emerging technologies,epidemiologic training,population},
number = {3},
pages = {390--394},
title = {{Epidemiology in the Era of Big Data}},
volume = {26},
year = {2016}
}
@article{Vandelanotte2016,
abstract = {Because physical inactivity and unhealthy diets are highly prevalent, there is a need for cost-effective interventions that can reach large populations. Electronic health (eHealth) and mobile health (mHealth) solutions have shown promising outcomes and have expanded rapidly in the past decade. The purpose of this report is to provide an overview of the state of the evidence for the use of eHealth and mHealth in improving physical activity and nutrition behaviors in general and special populations. The role of theory in eHealth and mHealth interventions is addressed, as are methodological issues. Key recommendations for future research in the field of eHealth and mHealth are provided.},
author = {Vandelanotte, Corneel and Mueller, Andre M. and Short, Camille E. and Hingle, Melanie and Nathan, Nicole and Williams, Susan L. and Lopez, Michael L. and Parekh, Sanjoti and Maher, Carol A.},
doi = {10.1016/j.jneb.2015.12.006},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vandelanotte et al. - 2016 - Past, Present, and Future of eHealth and mHealth Research to Improve Physical Activity and Dietary Behavior.pdf:pdf},
isbn = {1499-4046},
issn = {14994046},
journal = {Journal of Nutrition Education and Behavior},
keywords = {Behavior change,Diet,Intervention,Nutrition,Physical activity},
number = {3},
pages = {219--228.e1},
pmid = {26965100},
title = {{Past, Present, and Future of eHealth and mHealth Research to Improve Physical Activity and Dietary Behaviors}},
volume = {48},
year = {2016}
}
@article{Chambers2012,
abstract = {<sec><title>Background</title><p>Social network analysis (SNA) has been widely used across a range of disciplines but is most commonly applied to help improve the effectiveness and efficiency of decision making processes in commercial organisations. We are utilising SNA to inform the development and implementation of tailored behaviour-change interventions to improve the uptake of evidence into practice in the English National Health Service. To inform this work, we conducted a systematic scoping review to identify and evaluate the use of SNA as part of an intervention to support the implementation of change in healthcare settings.</p></sec><sec><title>Methods and Findings</title><p>We searched ten bibliographic databases to October 2011. We also searched reference lists, hand searched selected journals and websites, and contacted experts in the field. To be eligible for the review, studies had to describe and report the results of an SNA performed with healthcare professionals (e.g. doctors, nurses, pharmacists, radiographers etc.) and others involved in their professional social networks. We included 52 completed studies, reported in 62 publications. Almost all of the studies were limited to cross sectional descriptions of networks; only one involved using the results of the SNA as part of an intervention to change practice.</p></sec><sec><title>Conclusions</title><p>We found very little evidence for the potential of SNA being realised in healthcare settings. However, it seems unlikely that networks are less important in healthcare than other settings. Future research should seek to go beyond the merely descriptive to implement and evaluate SNA-based interventions.</p></sec>},
author = {Chambers, Duncan and Wilson, Paul and Thompson, Carl and Harden, Melissa},
doi = {10.1371/journal.pone.0041911},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chambers et al. - 2012 - Social network analysis in healthcare settings A systematic scoping review.pdf:pdf},
isbn = {1932-6203 (Electronic)\r1932-6203 (Linking)},
issn = {19326203},
journal = {PLoS ONE},
number = {8},
pmid = {22870261},
title = {{Social network analysis in healthcare settings: A systematic scoping review}},
volume = {7},
year = {2012}
}
@article{Hawn2009,
abstract = {If you want a glimpse of what health care could look like a few years from now, consider "Hello Health," the Brooklyn-based primary care practice that is fast becoming an emblem of modern medicine. A paperless, concierge practice that eschews the limitations of insurance-based medicine, Hello Health is popular and successful, largely because of the powerful and cost-effective communication tools it employs: Web-based social media. Indeed, across the health care industry, from large hospital networks to patient support groups, new media tools like weblogs, instant messaging platforms, video chat, and social networks are reengineering the way doctors and patients interact.},
author = {Hawn, Carleen},
doi = {10.1377/hlthaff.28.2.361},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hawn - 2009 - Report from the field Take two aspirin and tweet me in the morning How twitter, facebook, and other social media are resha.pdf:pdf},
isbn = {1544-5208 (Electronic)\n0278-2715 (Linking)},
issn = {02782715},
journal = {Health Affairs},
number = {2},
pages = {361--368},
pmid = {19275991},
title = {{Report from the field: Take two aspirin and tweet me in the morning: How twitter, facebook, and other social media are reshaping health care}},
volume = {28},
year = {2009}
}
@article{Christakis2010,
author = {Christakis, Nicholas A and Fowler, James H and New, The and Journal, England},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Christakis et al. - 2010 - The Collective Dynamics of Smoking in a Large Social Network.pdf:pdf},
journal = {New England Journal of Medicine},
pages = {2249--2258},
title = {{The Collective Dynamics of Smoking in a Large Social Network}},
year = {2010}
}
@article{Christakis2007,
abstract = {BACKGROUND: The prevalence of obesity has increased substantially over the past 30 years. We performed a quantitative analysis of the nature and extent of the person-to-person spread of obesity as a possible factor contributing to the obesity epidemic. METHODS: We evaluated a densely interconnected social network of 12,067 people assessed repeatedly from 1971 to 2003 as part of the Framingham Heart Study. The body-mass index was available for all subjects. We used longitudinal statistical models to examine whether weight gain in one person was associated with weight gain in his or her friends, siblings, spouse, and neighbors. RESULTS: Discernible clusters of obese persons (body-mass index [the weight in kilograms divided by the square of the height in meters], > or =30) were present in the network at all time points, and the clusters extended to three degrees of separation. These clusters did not appear to be solely attributable to the selective formation of social ties among obese persons. A person's chances of becoming obese increased by 57% (95% confidence interval [CI], 6 to 123) if he or she had a friend who became obese in a given interval. Among pairs of adult siblings, if one sibling became obese, the chance that the other would become obese increased by 40% (95% CI, 21 to 60). If one spouse became obese, the likelihood that the other spouse would become obese increased by 37% (95% CI, 7 to 73). These effects were not seen among neighbors in the immediate geographic location. Persons of the same sex had relatively greater influence on each other than those of the opposite sex. The spread of smoking cessation did not account for the spread of obesity in the network. CONCLUSIONS: Network phenomena appear to be relevant to the biologic and behavioral trait of obesity, and obesity appears to spread through social ties. These findings have implications for clinical and public health interventions.},
archivePrefix = {arXiv},
arxivId = {-},
author = {Christakis, Nicholas A. and Fowler, James H.},
doi = {10.1056/NEJMsa066082},
eprint = {-},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Christakis, Fowler - 2007 - The Spread of Obesity in a Large Social Network over 32 Years.pdf:pdf},
isbn = {1533-4406 (Electronic)\r0028-4793 (Linking)},
issn = {0028-4793},
journal = {New England Journal of Medicine},
number = {4},
pages = {370--379},
pmid = {17652652},
title = {{The Spread of Obesity in a Large Social Network over 32 Years}},
url = {http://www.nejm.org/doi/abs/10.1056/NEJMsa066082},
volume = {357},
year = {2007}
}
@article{Centola2010a,
abstract = {... There are four advantages of this experimental design over observational data. ... effects of topology on diffusion when, for example, the local structure of a social network correlates with greater resources for learning about or adopting an innovation (11 ... iii) This study eliminates the ...},
author = {Centola, D.},
doi = {10.1126/science.1185231},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Centola - 2010 - The Spread of Behavior in an Online Social Network Experiment(2).pdf:pdf},
isbn = {0036-8075},
issn = {0036-8075},
journal = {Science},
number = {5996},
pages = {1194--1197},
pmid = {20813952},
title = {{The Spread of Behavior in an Online Social Network Experiment}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1185231},
volume = {329},
year = {2010}
}
@article{Tasselli2014,
abstract = {In this article, we provide an overview of social network research in health care, with a focus on social interactions between professionals in organizations. We begin by introducing key concepts defining the social network approach, including network density, centrality, and brokerage. We then review past and current research on the antecedents of health care professionals' social networks - including demographic attributes, professional groups, and organizational arrangements - and their consequences - including satisfaction at work, leadership, behaviors, knowledge transfer, diffusion of innovation, and performance. Finally, we examine future directions for social network research in health care, focusing on micro-macro linkages and network dynamics.},
author = {Tasselli, S.},
doi = {10.1177/1077558714557079},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tasselli - 2014 - Social Networks of Professionals in Health Care Organizations A Review.pdf:pdf},
isbn = {1077-5587},
issn = {1077-5587},
journal = {Medical Care Research and Review},
keywords = {health care professionals,knowledge transfer,network,performance,social networks},
number = {6},
pages = {619--660},
title = {{Social Networks of Professionals in Health Care Organizations: A Review}},
url = {http://mcr.sagepub.com/cgi/doi/10.1177/1077558714557079},
volume = {71},
year = {2014}
}
@article{Christakis2013,
abstract = {Here, we review the research we have conducted on social contagion. We describe the methods we have employed (and the assumptions they have entailed) to examine several datasets with complementary strengths and weaknesses, including the Framingham Heart Study, the National Longitudinal Study of Adolescent Health, and other observational and experimental datasets that we and others have collected. We describe the regularities that led us to propose that human social networks may exhibit a 'three degrees of influence' property, and we review statistical approaches we have used to characterize interpersonal influence with respect to phenomena as diverse as obesity, smoking, cooperation, and happiness. We do not claim that this work is the final word, but we do believe that it provides some novel, informative, and stimulating evidence regarding social contagion in longitudinally followed networks. Along with other scholars, we are working to develop new methods for identifying causal effects using social network data, and we believe that this area is ripe for statistical development as current methods have known and often unavoidable limitations. (copyright) 2012 John Wiley & Sons, Ltd.},
archivePrefix = {arXiv},
arxivId = {1109.5235},
author = {Christakis, Nicholas A. and Fowler, James H.},
doi = {10.1002/sim.5408},
eprint = {1109.5235},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Christakis, Fowler - 2013 - Social contagion theory Examining dynamic social networks and humanbehavior.pdf:pdf},
isbn = {1097-0258 (Electronic)\r0277-6715 (Linking)},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {Causal interence,Contagion,Homophily,Human behavior,Social networks},
number = {4},
pages = {556--577},
pmid = {22711416},
title = {{Social contagion theory: Examining dynamic social networks and humanbehavior}},
volume = {32},
year = {2013}
}
@article{Moreno2013,
abstract = {Use of social media is nearly ubiquitous among todays young adults. Popular social media sites among young adults include Facebook, Linkedln, and Twitter. The rise of these new sites provides new benefits, including exposure to new ideas and experiences. However, there are also risks to use of social media, including exposure to influential information about substance use and other risky health behaviors. Future work is needed in order to investigate how social media can be used to promote healthy decisions and opportunities for young adults. Copyright {\textcopyright} 2013 American Academy of Pediatrics. All rights reserved.},
author = {Moreno, Megan A. and Gannon, Kerry},
doi = {10.1136/bmj.f3007},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moreno, Gannon - 2013 - Social media and health.pdf:pdf},
isbn = {1934-4287},
issn = {19344287},
journal = {Adolescent Medicine: State of the Art Reviews},
number = {3},
pages = {538--552},
pmid = {23697672},
title = {{Social media and health}},
volume = {24},
year = {2013}
}
@article{Greene2011,
abstract = {BACKGROUND: Several disease-specific information exchanges now exist on Facebook and other online social networking sites. These new sources of knowledge, support, and engagement have become important for patients living with chronic disease, yet the quality and content of the information provided in these digital arenas are poorly understood. OBJECTIVE: To qualitatively evaluate the content of communication in Facebook communities dedicated to diabetes. DESIGN: We identified the 15 largest Facebook groups focused on diabetes management. For each group, we downloaded the 15 most recent "wall posts" and the 15 most recent discussion topics from the 10 largest groups. PATIENTS: Four hundred eighty unique users were identified in a series of 690 comments from wall posts and discussion topics. MAIN MEASURES: Posts were abstracted and aggregated into a database. Two investigators evaluated the posts, developed a thematic coding scheme, and applied codes to the data. KEY RESULTS: Patients with diabetes, family members, and their friends use Facebook to share personal clinical information, to request disease-specific guidance and feedback, and to receive emotional support. Approximately two-thirds of posts included unsolicited sharing of diabetes management strategies, over 13% of posts provided specific feedback to information requested by other users, and almost 29% of posts featured an effort by the poster to provide emotional support to others as members of a community. Approximately 27% of posts featured some type of promotional activity, generally presented as testimonials advertising non-FDA approved, "natural" products. Clinically inaccurate recommendations were infrequent, but were usually associated with promotion of a specific product or service. Thirteen percent of posts contained requests for personal information from Facebook participants. CONCLUSIONS: Facebook provides a forum for reporting personal experiences, asking questions, and receiving direct feedback for people living with diabetes. However, promotional activity and personal data collection are also common, with no accountability or checks for authenticity.},
author = {Greene, Jeremy A. and Choudhry, Niteesh K. and Kilabuk, Elaine and Shrank, William H.},
doi = {10.1007/s11606-010-1526-3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Greene et al. - 2011 - Online social networking by patients with diabetes A qualitative evaluation of communication with Facebook.pdf:pdf},
isbn = {1525-1497 (Electronic)\n0884-8734 (Linking)},
issn = {08848734},
journal = {Journal of General Internal Medicine},
keywords = {Facebook,diabetes,disease management,information seeking behavior,online social media,social networks},
number = {3},
pages = {287--292},
pmid = {20945113},
title = {{Online social networking by patients with diabetes: A qualitative evaluation of communication with Facebook}},
volume = {26},
year = {2011}
}
@article{Laranjo2014,
abstract = {Results The database search retrieved 4656 citations; 12 studies (7411 participants) met the inclusion criteria. Facebook was the most utilized SNS, followed by health- specific SNSs, and Twitter. Eight randomized controlled trials were combined in a meta-analysis. A positive effect of SNS interventions on health behavior outcomes was found (Hedges' g 0.24; 95% CI 0.04 to 0.43). There was considerable heterogeneity (I2=84.0%; T2=0.058) and no evidence of publication bias. Discussion To the best of our knowledge, this is the first meta-analysis evaluating the effectiveness of SNS interventions in changing health-related behaviors. Most studies evaluated multi-component interventions, posing problems in isolating the specific effect of the SNS. Health behavior change theories were seldom mentioned in the included articles, but two particularly innovative studies used ‘network alteration', showing a positive effect. Overall, SNS interventions appeared to be effective in promoting changes in health-related behaviors, and further research regarding the application of these promising tools is warranted. Conclusions Our study showed a positive effect of SNS interventions on health behavior-related outcomes, but there was considerable heterogeneity.},
author = {Laranjo, L. and Arguel, A. and Neves, A. L. and Gallagher, A. M. and Kaplan, R. and Mortimer, N. and Mendes, G. A. and Lau, A. Y. S.},
doi = {10.1136/amiajnl-2014-002841},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laranjo et al. - 2014 - The influence of social networking sites on health behavior change a systematic review and meta-analysis.pdf:pdf},
isbn = {1527-974X (Electronic)\r1067-5027 (Linking)},
issn = {1067-5027},
journal = {Journal of the American Medical Informatics Association},
keywords = {as web-based platforms that,background and significance,behavior change,consumer health,enon,have become a global,phenom-,snss,social media,social network,social networking site,social networking sites,they are generally defined},
pages = {243--256},
pmid = {25005606},
title = {{The influence of social networking sites on health behavior change: a systematic review and meta-analysis}},
url = {https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2014-002841},
year = {2014}
}
@article{Fowler2010,
abstract = {heoretical models that social networks influence the suggest evolution of cooperation, but to date there have been few exper imental studies. Observational data suggest that a wide variety of behaviors may spread in human social networks, but subjects in such studies can choose to befriend people with similar behaviors, posing difficulty for causal inference. Here, we exploit a seminal set of laboratory experiments that originally showed that voluntary costly punishment can help sustain cooperation. In these experiments, subjects were randomly assigned to a sequence of different groups to play a series of single-shot public goods games with strangers; this feature allowed us to draw networks of interactions to explore how cooperative and uncooperative behaviors spread from person to person to person. We show that, in both an ordinary public goods game and in a public goods game with punishment focal individuals are influenced by fellow group members' contribution behavior in future interactions with other individuals who were not a party to the initial interaction. Furthermore, this influence persists for multiple periods and spreads up to three degrees of separation (f rpm person to person to person to person). The results suggest that each additional contribution a subject makes to the public good in the first period is tripled over the course of the experiment by other subjects who are directly or indirectly influenced to contribute more as a consequence. These results show experimentally that cooperative behavior cascades in human social netowrks.},
author = {Fowler, J. H. and Christakis, N. A.},
doi = {10.1073/pnas.0913149107},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fowler, Christakis - 2010 - Cooperative behavior cascades in human social networks.pdf:pdf},
isbn = {0027-8424},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {12},
pages = {5334--5338},
pmid = {20212120},
title = {{Cooperative behavior cascades in human social networks}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0913149107},
volume = {107},
year = {2010}
}
@article{Nabi2013,
abstract = {.There is clear evidence that interpersonal social support impacts stress levels and, in turn, degree of physical illness and psychological well-being. This study examines whether mediated social networks serve the same palliative function. A survey of 401 undergraduate Facebook users revealed that, as predicted, number of Facebook friends associated with stronger perceptions of social support, which in turn associated with reduced stress, and in turn less physical illness and greater well-being. This effect was minimized when interpersonal network size was taken into consideration. However, for those who have experienced many objective life stressors, the number of Facebook friends emerged as the stronger predictor of perceived social support. The "more-friends-the-better" heuristic is proposed as the most likely explanation for these findings.},
author = {Nabi, Robin L. and Prestin, Abby and So, Jiyeon},
doi = {10.1089/cyber.2012.0521},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nabi, Prestin, So - 2013 - Facebook Friends with (Health) Benefits Exploring Social Network Site Use and Perceptions of Social Support,.pdf:pdf},
isbn = {2152-2715},
issn = {2152-2715},
journal = {Cyberpsychology, Behavior, and Social Networking},
number = {10},
pages = {721--727},
pmid = {23790356},
title = {{Facebook Friends with (Health) Benefits? Exploring Social Network Site Use and Perceptions of Social Support, Stress, and Well-Being}},
url = {http://online.liebertpub.com/doi/abs/10.1089/cyber.2012.0521},
volume = {16},
year = {2013}
}
@article{Ricciardi2013,
abstract = {Patient-centered care is considered one pillar of a high-performing, high-quality health care system. It is a key component of many efforts to transform care and achieve better population health. Expansion of health information technology and consumer e-health tools--electronic tools and services such as secure e-mail messaging between patients and providers, or mobile health apps--have created new opportunities for individuals to participate actively in monitoring and directing their health and health care. The Office of the National Coordinator for Health Information Technology in the Department of Health and Human Services leads the strategy to increase electronic access to health information, support the development of tools that enable people to take action with that information, and shift attitudes related to the traditional roles of patients and providers. In this article we review recent evidence in support of consumer e-health and present the federal strategy to promote advances in consumer e-health to increase patient engagement, improve individual health, and achieve broader health care system improvements.},
author = {Ricciardi, Lygeia and Mostashari, Farzad and Murphy, Judy and Daniel, Jodi G. and Siminerio, Erin P.},
doi = {10.1377/hlthaff.2012.1216},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ricciardi et al. - 2013 - A national action plan to support consumer engagement via e-health.pdf:pdf},
isbn = {1544-5208 (Electronic) 0278-2715 (Linking)},
issn = {15445208},
journal = {Health affairs (Project Hope)},
number = {2},
pages = {376--384},
pmid = {23381531},
title = {{A national action plan to support consumer engagement via e-health}},
volume = {32},
year = {2013}
}
@article{Paul2011,
abstract = {Analyzing user messages in social media can measure different population characteristics, including public health measures. For example, recent work has correlated Twitter messages with influenza rates in the United States; but this has largely been the extent of mining Twitter for public health. In this work, we consider a broader range of public health applications for Twitter. We apply the recently introduced Ailment Topic Aspect Model to over one and a half million health related tweets and discover mentions of over a dozen ailments, including allergies, obesity and insomnia. We introduce extensions to incorporate prior knowledge into this model and apply it to several tasks: tracking illnesses over times (syndromic surveillance), measuring behavioral risk factors, localizing illnesses by geographic region, and analyzing symptoms and medication usage. We show quantitative correlations with public health data and qualitative evaluations of model output. Our results suggest that Twitter has broad applicability for public health research.},
author = {Paul, Michael J and Dredze, Mark},
doi = {10.1.1.224.9974},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paul, Dredze - 2011 - You are what you Tweet Analyzing Twitter for public health.pdf:pdf},
journal = {Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media},
keywords = {2011,Full Technical Papers,ailment topic aspect model,atam,created a data set,flu tweets,general model,open question with a,or statistical classifier for,paul and dredze,previous work introduced atam,the newly introduced,we ask an},
pages = {265--272},
title = {{You are what you Tweet: Analyzing Twitter for public health}},
url = {http://www.aaai.org/ocs/index.php/ICWSM/ICWSM11/paper/viewFile/2880/3264.},
year = {2011}
}
@misc{Blinded,
author = {Blinded},
title = {{Source code link}}
}
@article{Zhanga,
author = {Zhang, Jianan and Modiano, Eytan},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Modiano - Unknown - Robust Routing in Interdependent Networks.pdf:pdf},
pages = {2529--2537},
title = {{Robust Routing in Interdependent Networks}}
}
@inproceedings{Kuhnle2017a,
address = {Urbana-Champaign, IL},
author = {Kuhnle, Alan and Pan, Tianyi and Crawford, Victoria G and Alim, Md Abdul and Thai, My T},
booktitle = {Proceedings of SIGMETRICS '17},
doi = {https://doi.org/10.1145/3078505.3078538},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhnle et al. - 2017 - Pseudo-Separation for Assessment of Structural Vulnerability of a Network.pdf:pdf},
isbn = {9781450350327},
keywords = {acm reference format,alan kuhnle,and my t,approximation algorithms,crawford,md abdul alim,network cutting problems,tianyi pan,victoria g},
title = {{Pseudo-Separation for Assessment of Structural Vulnerability of a Network}},
year = {2017}
}
@article{Nguyen2017,
abstract = {In this paper, we study crucial elements of a complex network, namely its nodes and connections, which play a key role in maintaining the network's structure and function under unexpected structural perturbations of nodes and edges removal. Specifically, we want to identify vital nodes and edges whose failure (either random or intentional) will break the most number of connected triples (or triangles) in the network. This problem is extremely important because connected triples form the foundation of strong connections in many real-world systems, such as mutual relationships in social networks, reliable data transmission in communication networks, and stable routing strategies in mobile networks. Disconnected triples, analog to broken mutual connections, can greatly affect the network's structure and disrupt its normal function, which can further lead to the corruption of the entire system. The analysis of such crucial elements will shed light on key factors behind the resilience and robustness of many complex systems in practice. We formulate the analysis under multiple optimization problems and show their intractability. We next propose efficient approximation algorithms, namely DAK-n and DAK-e, which guarantee an $(1-1/e)$-approximate ratio (compared to the overall optimal solutions) while having the same time complexity as the best triangle counting and listing algorithm on power-law networks. This advantage makes our algorithms scale extremely well even for very large networks. In an application perspective, we perform comprehensive experiments on real social traces with millions of nodes and billions of edges. These empirical experiments indicate that our approaches achieve comparably better results while are up to 100x faster than current state-of-the-art methods.},
archivePrefix = {arXiv},
arxivId = {1702.01451},
author = {Nguyen, Hung T. and Nguyen, Nam P. and Vu, Tam and Hoang, Huan X. and Dinh, Thang N.},
doi = {10.1109/ACCESS.2017.2672666},
eprint = {1702.01451},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen et al. - 2017 - Transitivity Demolition and the Fall of Social Networks.pdf:pdf},
issn = {2169-3536},
journal = {IEEE Access},
number = {99},
pages = {1},
title = {{Transitivity Demolition and the Fall of Social Networks}},
url = {http://arxiv.org/abs/1702.01451},
volume = {PP},
year = {2017}
}
@article{Alpes,
author = {Alpes, Grenoble and Inp, Grenoble and France, Grenoble},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alpes, Inp, France - Unknown - Distributed and Adaptive Routing Based on Game Theory.pdf:pdf},
title = {{Distributed and Adaptive Routing Based on Game Theory}}
}
@inproceedings{Torres-Tram??n2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1602.05561v1},
author = {Nguyen, H.T. and Nguyen, T.P. and Vu, T.N. and Dinh, T.N.},
booktitle = {SIGMETRICS},
doi = {10.475/123},
eprint = {arXiv:1602.05561v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen et al. - 2017 - Outward Influence and Cascade Size Estimation.pdf:pdf},
isbn = {9781450335423},
issn = {16130073},
keywords = {Entity linking,Information extraction,Twitter},
title = {{Outward Influence and Cascade Size Estimation}},
year = {2017}
}
@inproceedings{Schank2001,
abstract = {In the past, the fundamental graph problem of triangle counting and listing has been studied intensively from a theoretical point of view. Recently, triangle counting has also become a widely used tool in network analysis. Due to the very large size of networks like the Internet, WWW or social networks, the efficiency of algorithms for triangle counting and listing is an important issue. The main intention of this work is to evaluate the practicability of triangle counting and listing in very large graphs with various degree distributions. We give a surprisingly simple enhancement of a well known algorithm that performs best, and makes triangle listing and counting in huge networks feasible. This paper is a condensed presentation of [SW05].},
author = {Schank, Thomas and Wagner, Dorothea},
booktitle = {International Workshop on Experimental and Efficient Algorithms2},
doi = {10.1007/b136461},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schank, Wagner - 2005 - Finding, Counting and Listing all Triangles in Large Graphs, An Experimental Study.pdf:pdf},
isbn = {978-3-540-25920-6},
issn = {03029743},
pages = {606--609},
publisher = {Springer Berlin Heidelberg},
title = {{Finding, Counting and Listing all Triangles in Large Graphs, An Experimental Study}},
year = {2005}
}
@article{Ronald2011,
author = {Ronald, J and Sciences, Geographical and Planning, Urban},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ronald, Sciences, Planning - 2011 - r P Fo ee r R ev ie w On r P Fo r R w On.pdf:pdf},
keywords = {ac,com,dundee,http,ijrs-administrator,manuscriptcentral,mc,tres email,uk,user defined},
title = {{r P Fo ee r R ev ie w On r P Fo r R w On}},
year = {2011}
}
@article{Tong2008,
abstract = {Low-rank approximations of the adjacency matrix of a graph are essential in finding patterns (such as communities) and detecting anomalies. Additionally, it is desirable to track the low-rank structure as the graph evolves over time, efficiently and within limited storage. Real graphs typically have thousands or millions of nodes, but are usually very sparse. However, standard decompositions such as SVD do not preserve sparsity. This has led to the development of methods such as CUR and CMD, which seek a non-orthogonal basis by sampling the columns and/or rows of the sparse matrix.},
author = {Tong, Hanghang and Papadimitriou, Spiros and Sun, Jimeng and Yu, Philip S. and Faloutsos, Christos},
doi = {10.1145/1401890.1401973},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tong et al. - 2008 - Colibri Fast Mining of Large Static and Dynamic Graphs.pdf:pdf},
isbn = {9781605581934},
journal = {KDD '08: Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
keywords = {all or part of,graph mining,is granted without fee,low-rank approximation,or hard copies of,permission to make digital,personal or classroom use,provided that copies are,scalability,this work for},
pages = {686--694},
title = {{Colibri: Fast Mining of Large Static and Dynamic Graphs}},
year = {2008}
}
@article{Schieber2017,
author = {Schieber, Tiago A. and Carpi, Laura and D{\'{i}}az-Guilera, Albert and Pardalos, Panos M. and Masoller, Cristina and Ravetti, Mart{\'{i}}n G. and Kelmans, A. K. and IEEE, T. and Bunke, H. Pattern Anal and Shearer, K. and Fernandez, M. L. and Valiente, G. and Luo, B. and Hancock, E. R. and Raymond, J. W. and Gardiner, E. J. and Willett, P. and Conte, D. and Dehmer, M. and Przulj, N. and Zager, L. A. and Verghese, G. C. and Gao, X. and Xiao, B. and Tao, D. and Li, X. and Fischer, A. and Aliakbary, S. and Savage, N. and Boccaletti, S. and Arenas, A. and Barabasi, A. L. and Gulbahce, N. and Loscalzo, J. and Carpi, L. and Schieber, T. A. and Ravetti, M. G. and Taylor, D. and Orsini, C. and Domenico, M. De and Nicosia, V. and Arenas, A. and Latora, V. and Menche, J. and Schieber, T. A. and Verma, T. and Russmann, F. and Ara{\'{u}}jo, N. A. M. and Nagler, J. and Herrmann, H. J. and {\c{C}}olak, S. and Lima, A. and Gonz{\'{a}}lez, M. C. and Calderone, A. and Morrow, J. K. and Tian, L. and Zhang, S. and Costa, L. and Hamming, R. W. and Sanfeliu, A. and Fu, K. S. and Lin, J. and Erd{\"{o}}s, P. and R{\'{e}}nyi, A. and Watts, D. J. and Strogatz, S. H. and Bonacich, P. and Dijkstra, E. W. and Fredman, M. L. and Tarjan, R. E. and Albert, R. and Barab{\'{a}}si, A. and Carpi, L. and Newman, M. E. J. and Ziff, R. M. and Radicchi, F. and Molloy, M. and Reed, B. and Maslov, S. and Sneppen, K. and Newman, M. E. J. and Park, J. and Subelj, L. and Bajec, M. and Luque, B. and Lacasa, L. and Ballesteros, F. and Luque, J. and Gon{\c{c}}alves, B. A. and Carpi, L. and Rosso, O. A. and Ravetti, M. G. and Joudaki, A. and Salehi, N. and Jalili, M. and Knyazeva, M. G.},
doi = {10.1038/ncomms13928},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Note et al. - Unknown - The node-distance distribution is a set of probability distributions that associates to each node i = 1 , 2 , ..pdf:pdf;:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schieber et al. - 2017 - Quantification of network structural dissimilarities.pdf:pdf},
issn = {2041-1723},
journal = {Nature Communications},
number = {May 2016},
pages = {13928},
title = {{Quantification of network structural dissimilarities}},
url = {http://www.nature.com/doifinder/10.1038/ncomms13928},
volume = {8},
year = {2017}
}
@article{Note,
author = {Note, Supplementary and Of, Properties and Node, T H E and Distribution, Distance},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Note et al. - Unknown - The node-distance distribution is a set of probability distributions that associates to each node i = 1 , 2 , ..pdf:pdf},
pages = {1--19},
title = {{The node-distance distribution is a set of probability distributions that associates to each node i = 1 , 2 , . . . , N a probability distribution P}}
}
@article{Brown2006,
abstract = {We apply new bilevel and trilevel optimization models to make critical infrastructure more resilient against terrorist attacks. Each model features an intelligent attacker (terrorists) and a defender (us), information transparency, and sequential actions by attacker and defender. We illustrate with examples of the US Strategic Petroleum Reserve, the US Border Patrol at Yuma, Arizona, and an electrical transmission system. We conclude by reporting insights gained from the modeling experience and many "red-team" exercises. Each exercise gathers open-source data on a real-world infrastructure system, develops an appropriate bilevel or trilevel model, and uses these to identify vulnerabilities in the system or to plan an optimal defense.},
author = {Brown, Gerald and Carlyle, Matthew and Salmer{\'{o}}n, Javier and Wood, Kevin},
doi = {10.1287/inte.1060.0252},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brown et al. - 2006 - Defending critical infrastructure.pdf:pdf},
isbn = {0092-2102},
issn = {00922102},
journal = {Interfaces},
keywords = {Bilevel program,Critical infrastructure protection,Homeland defense,Homeland security,Mixed-integer program,Trilevel program},
number = {6},
pages = {530--544},
title = {{Defending critical infrastructure}},
volume = {36},
year = {2006}
}
@article{Scaparra2008,
abstract = {Vulnerability to sudden service disruptions due to deliberate sabotage and terrorist attacks is one of the major threats of today. In this paper, we present a bilevel formulation of the r-interdiction median problem with fortification (RIMF). RIMF identifies the most cost-effective way of allocating protective resources among the facilities of an existing but vulnerable system so that the impact of the most disruptive attack to r unprotected facilities is minimized. The model is based upon the classical p-median location model and assumes that the efficiency of the system is measured in terms of accessibility or service provision costs. In the bilevel formulation, the top level problem involves the decisions about which facilities to fortify in order to minimize the worst-case efficiency reduction due to the loss of unprotected facilities. Worst-case scenario losses are modeled in the lower-level interdiction problem. We solve the bilevel problem through an implicit enumeration (IE) algorithm, which relies on the efficient solution of the lower-level interdiction problem. Extensive computational results are reported, including comparisons with earlier results obtained by a single-level approach to the problem. ?? 2006 Elsevier Ltd. All rights reserved.},
author = {Scaparra, Maria P. and Church, Richard L.},
doi = {10.1016/j.cor.2006.09.019},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Scaparra, Church - 2008 - A bilevel mixed-integer program for critical infrastructure protection planning.pdf:pdf},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Bilevelprogramming,Medianlocationproblems,Protectionmodels},
number = {6},
pages = {1905--1923},
title = {{A bilevel mixed-integer program for critical infrastructure protection planning}},
volume = {35},
year = {2008}
}
@article{Newman2005b,
abstract = {Betweenness is a measure of the centrality of a node in a network, and is normally calculated as the fraction of shortest paths between node pairs that pass through the node of interest. Betweenness is, in some sense, a measure of the influence a node has over the spread of information through the network. By counting only shortest paths, however, the conventional definition implicitly assumes that information spreads only along those shortest paths. Here, we propose a betweenness measure that relaxes this assumption, including contributions from essentially all paths between nodes, not just the shortest, although it still gives more weight to short paths. The measure is based on random walks, counting how often a node is traversed by a random walk between two other nodes. We show how our measure can be calculated using matrix methods, and give some examples of its application to particular networks. ?? 2004 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0309045},
author = {Newman, M. E J},
doi = {10.1016/j.socnet.2004.11.009},
eprint = {0309045},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Newman - 2005 - A measure of betweenness centrality based on random walks(2).pdf:pdf},
isbn = {0378-8733},
issn = {03788733},
journal = {Social Networks},
keywords = {Betweenness,Centrality,Current flow,Random walks},
number = {1},
pages = {39--54},
primaryClass = {cond-mat},
title = {{A measure of betweenness centrality based on random walks}},
volume = {27},
year = {2005}
}
@inproceedings{Guruswami2014,
abstract = {The Feedback Vertex Set problem (FVS), where the goal is to find a small subset of vertices that intersects every cycle in an input directed graph, is among the fundamental problems whose approximability is not well-understood. One can efficiently find an O(logn) factor approximation, and while a constant-factor approximation is ruled out under the Unique Games Conjecture (UGC), the best NP-hardness result is only a factor of about 1.36 (via a simple reduction from Vertex Cover). This work studies a natural variant of the Feedback Vertex Set problem (FVS), where the goal is to find a small subset of vertices that intersects every cycle of *bounded length*. For this variant, we prove strong *NP-hardness* of approximation results: For any integer constant k3 and 0, it is hard to find a (k−1−)-approximate solution to the problem of intersecting every cycle of length at most k. The hardness result almost matches the trivial factor k approximation algorithm for the problem. In fact, the hardness holds also for the problem of hitting every cycle of length at most a parameter kk where k can be taken to be (lognloglogn). Taking k=(lognloglogn) would be enough to prove a hardness for FVS (for arbitrary length cycles). Our work thus identifies the problem of hitting cycles of length logn as the key towards resolving the approximability of FVS. Our result is based on reductions from k-uniform Hypergraph Vertex Cover with random matching and labeling techniques. As byproducts of our techniques, we also prove a factor (k−1−) hardness of approximation result for k-Clique Transversal, where one must hit every k-clique in the graph with fewest possible vertices, and a factor (k) hardness result for finding a minimum-sized set of *edges* to hit all k-cycles. We also obtain almost tight (k) factor hardness results for the dual problem of packing vertex-disjoint k-cycles and k-cliques in a graph, albeit relying on the UGC for k-Cycle Packing (but we do get a weaker factor (k) NP-hardness result).},
author = {Guruswami, Venkatesan and Lee, Euiwoong},
booktitle = {Electronic Colloquium on Computation Complexity (ECCC)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guruswami, Lee - 2014 - Inapproximability of Feedback Vertex Set for Bounded Length Cycles.pdf:pdf},
keywords = {Feedback Arc Set,NP-hardness of approximation,cycle packing,cycle transversal,hypergraph vertex cover},
number = {6},
pages = {2},
title = {{Inapproximability of Feedback Vertex Set for Bounded Length Cycles}},
url = {http://eccc.hpi-web.de/report/2014/006/},
volume = {21},
year = {2014}
}
@article{Kourtellis2013,
abstract = {This paper proposes an alternative way to identify nodes with high betweenness centrality. It introduces a new metric, ?-path centrality, and a randomized algorithm for estimating it, and shows empirically that nodes with high ?-path centrality have high node betweenness centrality. The randomized algorithm runs in time O(?3 n 2-2alog n) and outputs, for each vertex v, an estimate of its ?-path centrality up to additive error of �n 1/2+a with probability 1 - 1/n 2. Experimental evaluations on real and synthetic social networks show improved accuracy in detecting high betweenness centrality nodes and significantly reduced execution time when compared with existing randomized algorithms.},
archivePrefix = {arXiv},
arxivId = {1702.06087},
author = {Kourtellis, Nicolas and Alahakoon, Tharaka and Simha, Ramanuja and Iamnitchi, Adriana and Tripathi, Rahul},
doi = {10.1007/s13278-012-0076-6},
eprint = {1702.06087},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kourtellis et al. - 2013 - Identifying high betweenness centrality nodes in large social networks.pdf:pdf},
isbn = {1813974535},
issn = {18695469},
journal = {Social Network Analysis and Mining},
keywords = {Algorithms,Betweenness centrality,Experimental evaluation,Social network analysis},
number = {4},
pages = {899--914},
title = {{Identifying high betweenness centrality nodes in large social networks}},
volume = {3},
year = {2013}
}
@article{Riondato2016,
abstract = {Betweenness centrality is a fundamental measure in social network analysis, expressing the importance or influence of individual vertices (or edges) in a network in terms of the fraction of shortest paths that pass through them. Since exact computation in large networks is prohibitively expensive, we present two efficient randomized algorithms for betweenness estimation. The algorithms are based on random sampling of shortest paths and offer probabilistic guarantees on the quality of the approximation. The first algorithm estimates the betweenness of all vertices (or edges): all approximate values are within an additive factor $\${\backslash}varepsilon {\}in (0,1)$$ $\epsilon$ ∈ ( 0 , 1 ) from the real values, with probability at least $$1-{\}delta $$ 1 - $\delta$ . The second algorithm focuses on the top-K vertices (or edges) with highest betweenness and estimate their betweenness value to within a multiplicative factor $\${\backslash}varepsilon $$ $\epsilon$ , with probability at least $$1-{\}delta $$ 1 - $\delta$ . This is the first algorithm that can compute such approximation for the top-K vertices (or edges). By proving upper and lower bounds to the VC-dimension of a range set associated with the problem at hand, we can bound the sample size needed to achieve the desired approximations. We obtain sample sizes that are independent from the number of vertices in the network and only depend on a characteristic quantity that we call the vertex-diameter, that is the maximum number of vertices in a shortest path. In some cases, the sample size is completely independent from any quantitative property of the graph. An extensive experimental evaluation on real and artificial networks shows that our algorithms are significantly faster and much more scalable as the number of vertices grows than other algorithms with similar approximation guarantees.},
author = {Riondato, Matteo and Kornaropoulos, Evgenios M.},
doi = {10.1007/s10618-015-0423-0},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Riondato, Kornaropoulos - 2016 - Fast approximation of betweenness centrality through sampling.pdf:pdf},
isbn = {9781450323512},
issn = {1573756X},
journal = {Data Mining and Knowledge Discovery},
keywords = {Approximation algorithms,Betweenness centrality,Sampling,Social network analysis,VC-dimension},
number = {2},
pages = {438--475},
publisher = {Springer US},
title = {{Fast approximation of betweenness centrality through sampling}},
volume = {30},
year = {2016}
}
@misc{Borwein1985,
author = {Borwein},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Borwein - 1985 - On the Complexity of Calculating Factorials.pdf:pdf},
title = {{On the Complexity of Calculating Factorials}},
year = {1985}
}
@article{Soltan2015a,
abstract = {This paper focuses on line failures in the transmission system of power grids. Recent large-scale power outages demonstrated the limitations of percolation- and epidemic-based tools in modeling failures and cascades in power grids. Hence, we study failures and cascades by using computational tools and a linearized power flow model. We first obtain results regarding the Moore-Penrose pseudo-inverse of the power grid admittance matrix. Based on these results, we analytically study the impact of a single line failure on the flows on other lines and introduce metrics to evaluate the robustness of grids to failures. We also illustrate via simulation the impact of the distance and resistance distance on the flow increase following a failure, and discuss the difference from the epidemic models. We use the pseudoinverse of admittance matrix to develop an efficient algorithm to identify the cascading failure evolution, which can be a building block for cascade mitigation. Finally, we show that finding the lines whose removal results in the minimum yield (the fraction of demand satisfied after the cascade) is NP-Hard and present a simple heuristic for finding such a set . Overall, the results demonstrate that using the resistance distance and the pseudoinverse of admittance matrix provides important insights and can support the development of algorithms for designing robust power grids and controlling the evolution of a cascade upon failures.},
author = {Soltan, Saleh and Mazauric, Dorian and Zussman, Gil},
doi = {10.1109/TCNS.2015.2498464},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soltan, Mazauric, Zussman - 2015 - Analysis of failures in power grids.pdf:pdf},
issn = {23255870},
journal = {IEEE Transactions on Control of Network Systems},
keywords = {Cascading Failures.,Power Grid,Pseudo-inverse},
number = {99},
pages = {1--13},
title = {{Analysis of failures in power grids}},
volume = {PP},
year = {2015}
}
@article{Boucher2015,
abstract = {The de Bruijn graph $G_K$ of a set of strings $S$ is a key data structure in genome assembly that represents overlaps between all the $K$-length substrings of $S$. Construction and navigation of the graph is a space and time bottleneck in practice and the main hurdle for assembling large, eukaryote genomes. This problem is compounded by the fact that state-of-the-art assemblers do not build the de Bruijn graph for a single order (value of $K$) but for multiple values of $K$. More precisely, they build $d$ de Bruijn graphs, each with a specific order, i.e., $G_{K_1}, G_{K_2}, ..., G_{K_d}$. Although, this paradigm increases the quality of the assembly produced, it increases the memory by a factor of $d$ in most cases. In this paper, we show how to augment a succinct de Bruijn graph representation by Bowe et al. (Proc. WABI, 2012) to support new operations that let us change order on the fly, effectively representing all de Bruijn graphs of order up to some maximum $K$ in a single data structure. Our experiments show our variable-order de Bruijn graph only modestly increases space usage, construction time, and navigation time compared to a single order graph.},
archivePrefix = {arXiv},
arxivId = {1411.2718},
author = {Boucher, Christina and Bowe, Alex and Gagie, Travis and Puglisi, Simon J. and Sadakane, Kunihiko},
doi = {10.1109/DCC.2015.70},
eprint = {1411.2718},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boucher et al. - 2015 - Variable-Order de Bruijn Graphs.pdf:pdf},
isbn = {9781479984305},
issn = {10680314},
journal = {Data Compression Conference Proceedings},
pages = {383--392},
title = {{Variable-Order de Bruijn Graphs}},
volume = {2015-July},
year = {2015}
}
@article{Donmez2011,
abstract = {As whole genome sequencing has become a routine biological experiment, algorithms for assembly of whole genome shotgun data has become a topic of extensive research, with a plethora of off-the-shelf methods that can reconstruct the genomes of many organisms. Simultaneously, several recently sequenced genomes exhibit very high polymorphism rates. For these organisms genome assembly remains a challenge as most assemblers are unable to handle highly divergent haplotypes in a single individual. In this paper we describe Hapsembler, an assembler for highly polymorphic genomes, which makes use of paired reads. Our experiments show that Hapsembler produces accurate and contiguous assemblies of highly polymorphic genomes, while performing on par with the leading tools on haploid genomes. Hapsembler is available for download at http://compbio.cs.toronto.edu/hapsembler. {\textcopyright} 2011 Springer-Verlag.},
author = {Donmez, Nilgun and Brudno, Michael},
doi = {10.1007/978-3-642-20036-6_5},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Donmez, Brudno - 2011 - Hapsembler An assembler for highly polymorphic genomes.pdf:pdf},
isbn = {9783642200359},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Genome assembly,polymorphism},
pages = {38--52},
title = {{Hapsembler: An assembler for highly polymorphic genomes}},
volume = {6577 LNBI},
year = {2011}
}
@article{Jan1993a,
abstract = {This paper considers network topological optimization with a reliability\nconstraint. The objective is to find the topological layout of links, at\na minimal cost, under the constraint that the network reliability is not\nless than a given level of system reliability. A decomposition method,\nbased on branch & bound, is used for solving the problem. In order to\nspeed-up the procedure, an upper bound on system reliability in terms of\nnode degrees is applied. A numerical example illustrates, and shows the\neffectiveness of the method.\nIf a{*}, an important parameter, is close to the minimal number of links\nin a network which satisfy the reliability constraint, then a better\nstarting solution can be obtained, and many searching steps can be\nsaved. In our method, the lower bound a{*} is close to its actual value\nif the operational reliability of the link is close enough to 1. Also,\nif we can find the maximal increasing value of the reliability when a\nset of links is added to a specified topology, the efficiency of the\nbranch & bound algorithm is improved.},
author = {Jan, Rong Hong and Hwang, Fung Jen and Cheng, Sheng Tzong},
doi = {10.1109/24.210272},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jan, Hwang, Cheng - 1993 - Topological Optimization of a Communication Network Subject to a Reliability Constraint(2).pdf:pdf},
issn = {15581721},
journal = {IEEE Transactions on Reliability},
keywords = {Network design,Network planning,Network reliability},
number = {1},
pages = {63--70},
title = {{Topological Optimization of a Communication Network Subject to a Reliability Constraint}},
volume = {42},
year = {1993}
}
@article{Yates2011,
abstract = {A modified shortest path network interdiction model is approximated in this work by a constrained binary knapsack which uses aggregated arc maximum flow as the objective function coefficient. In the modified shortest path network interdiction problem, an attacker selects a path of highest non-detection probability on a network with multiple origins and multiple available targets. A defender allocates a limited number of resources within the geographic region of the network to reduce the maximum network non-detection probability between all origin-target pairs by reducing arc non-detection probabilities and where path non-detection probability is modeled as a product of all arc non-detection probabilities on that path. Traditional decomposition methods to solve the shortest path network interdiction problem are sensitive to problem size and network/regional complexity. The goal of this paper is to develop a method for approximating the regional allocation of defense resources that maintains accuracy while reducing both computational effort and the sensitivity of computation time to network/regional properties. Statistical and spatial analysis methods are utilized to verify approximation performance of the knapsack method in two real-world networks. {\textcopyright} 2011 Elsevier Ltd. All rights reserved.},
author = {Yates, Justin and Lakshmanan, Kavitha},
doi = {10.1016/j.cie.2011.06.011},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yates, Lakshmanan - 2011 - A constrained binary knapsack approximation for shortest path network interdiction.pdf:pdf},
issn = {03608352},
journal = {Computers and Industrial Engineering},
keywords = {Approximation techniques,Homeland security,Integer programming,Network interdiction},
number = {4},
pages = {981--992},
publisher = {Elsevier Ltd},
title = {{A constrained binary knapsack approximation for shortest path network interdiction}},
url = {http://dx.doi.org/10.1016/j.cie.2011.06.011},
volume = {61},
year = {2011}
}
@inproceedings{Cui2016,
author = {Cui, Yi and Xiao, Di and Loguinov, Dmitri},
booktitle = {IEEE 16th Internatiohnal Conference on Data Mining},
doi = {10.1109/ICDM.2016.118},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cui, Xiao, Loguinov - 2016 - On Efficient External-Memory Triangle Listing.pdf:pdf},
publisher = {IEEEj},
title = {{On Efficient External-Memory Triangle Listing}},
year = {2016}
}
@article{Dean2010,
author = {Dean, Brian C and Griffis, Adam and Parekh, Ojas and Whitley, Adam},
doi = {10.1007/s00453-010-9408-y},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dean et al. - 2010 - Approximation Algorithms for k -hurdle Problems.pdf:pdf},
pages = {449--460},
title = {{Approximation Algorithms for k -hurdle Problems}},
year = {2010}
}
@article{Yuster2012a,
author = {Yuster, Raphael},
doi = {10.1017/S0963548312000235},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuster - 2012 - Dense Graphs With A Large Triangle Cover Have A Large Triangle Packing(2).pdf:pdf},
issn = {0963-5483},
journal = {Combinatorics, Probability & Computing},
number = {6},
pages = {952--962},
title = {{Dense Graphs With A Large Triangle Cover Have A Large Triangle Packing}},
volume = {21},
year = {2012}
}
@article{Israeli2002,
abstract = {We study the problem of interdicting the arcs in a network in order to maximize the shortest s–t path length. “Interdiction” is an attack on an arc that destroys the arc or increases its effective length; there is a limited interdiction budget. We formulate this bilevel, max–min problem as a mixed-integer program (MIP), which can be solved directly, but we develop more efficient decomposition algorithms. One algorithm enhances Benders decomposition by adding generalized integer cutting planes, called “supervalid inequalities” (SVIs), to the master problem. A second algorithm exploits a unique set-covering master problem. Computational results demonstrate orders-of-magnitude improvements of the decomposition algorithms over direct solution of the MIP and show that SVIs also help solve the original MIP faster.},
author = {Israeli, Eitan and Wood, R. Kevin},
doi = {10.1002/net.10039},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Israeli, Wood - 2002 - Shortest-Path Network Interdiction.pdf:pdf},
isbn = {00283045 (ISSN)},
issn = {00283045},
journal = {Networks},
keywords = {Benders decomposition,Bilevel program,Interdiction,Shortest paths},
number = {2},
pages = {97--111},
title = {{Shortest-Path Network Interdiction}},
volume = {40},
year = {2002}
}
@article{Zhang2016b,
abstract = {Device-to-Device (D2D) communication has been recognized as a promising technique to offload the traffic for the evolved Node B (eNB). However, the D2D transmission as an underlay causes severe interference to both the cellular and other D2D links, which imposes a great technical challenge to radio resource allocation. Conventional graph based resource allocation methods typically consider the interference between two user equipments (UEs), but they cannot model the interference from multiple UEs to completely characterize the interference. In this paper, we study channel allocation using hypergraph theory to coordinate the interference between D2D pairs and cellular UEs, where an arbitrary number of D2D pairs are allowed to share the uplink channels with the cellular UEs. Hypergraph coloring is used to model the cumulative interference from multiple D2D pairs, and thus, eliminate the mutual interference. Simulation results show that the system capacity is significantly improved using the proposed hypergraph method in comparison to the conventional graph based one.},
archivePrefix = {arXiv},
arxivId = {1604.03246},
author = {Zhang, Hongliang and Song, Lingyang and Han, Zhu},
doi = {10.1109/TWC.2016.2547862},
eprint = {1604.03246},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Song, Han - 2016 - Radio Resource Allocation for Device-to-Device Underlay Communication Using Hypergraph Theory.pdf:pdf},
issn = {15361276},
journal = {IEEE Transactions on Wireless Communications},
keywords = {Device-to-device communications,hypergraph coloring,resource allocation},
number = {7},
pages = {4852--4861},
title = {{Radio Resource Allocation for Device-to-Device Underlay Communication Using Hypergraph Theory}},
volume = {15},
year = {2016}
}
@article{Biggs2012,
author = {Biggs, Reinette and Schlueter, Maja and Biggs, Duan and Bohensky, Erin L. and BurnSilver, Shauna and Cundill, Georgina and Dakos, Vasilis and Daw, Tim M. and Evans, Louisa S. and Kotschy, Karen and Leitch, Anne M. and Meek, Chanda and Quinlan, Allyson and Raudsepp-Hearne, Ciara and Robards, Martin D. and Schoon, Michael L. and Schultz, Lisen and West, Paul C.},
journal = {Annual Review of Environment and Resources},
pages = {421--448},
title = {{Toward Principles for Enhancing the Resilience of Ecosystem Services}},
volume = {37},
year = {2012}
}
@article{Suweis2015,
author = {Suweis, Samir and Carr, Joel A. and Maritan, Amos and Rinaldo, Andrea and D'Odorico, Paolo},
journal = {Proceedings of the National Academy of Sciences},
number = {22},
pages = {6902--7},
title = {{Resilience and reactivity of global food security}},
volume = {112},
year = {2015}
}
@article{Portmann2010,
author = {Portmann, Felix T. and Siebert, Stefan and Doell, Petra},
journal = {Global biogeochemical cycles},
number = {1},
title = {{Global monthly irrigated and rainfed crop areas around the year 2000: A new high-resolution data set for agricultural and hydrological modeling}},
volume = {24},
year = {2010}
}
@article{Ridoutt2010,
author = {Ridoutt, Bradley G. and Pfister, Stephan},
journal = {Global Environmental Change},
number = {1},
pages = {113--120},
title = {{A revised approach to water footprinting to make transparent the impacts of consumption and production on global freshwater scarcity}},
volume = {20},
year = {2010}
}
@article{Monfreda2008,
author = {Monfreda, C. and Ramankutty, N. and Foley, J. A.},
journal = {Global biogeochemical cycles},
number = {1},
title = {{Farming the planet: 2. Geographic distribution of crop areas, yields, physiological types, and net primary production in the year 2000}},
volume = {22},
year = {2008}
}
@article{Qubbaj2015,
author = {Qubbaj, M. R. and Shutters, S. T. and Muneepeerakul, R.},
journal = {Bulletin of Mathematical Biology},
number = {2},
pages = {390--407},
title = {{Living in a network of scaling cities and finite resources}},
volume = {77},
year = {2015}
}
@article{Famiglietti2014,
abstract = {Groundwater depletion the world over poses a far greater threat to global water security than is currently acknowledged.},
author = {Famiglietti, J. S.},
doi = {10.1038/nclimate2425},
isbn = {1758-678X},
issn = {1758-678X},
journal = {Nature Climate Change},
number = {11},
pages = {945--948},
title = {{The global groundwater crisis}},
url = {http://www.nature.com/doifinder/10.1038/nclimate2425},
volume = {4},
year = {2014}
}
@article{You2014,
author = {You, Liangzhi and Wood, Stanley and Wood-Sichra, Ulrike and Wu, Wenbin},
journal = {Agricultural Systems},
pages = {53--60},
title = {{Generating global crop distribution maps: from census to grid}},
volume = {127},
year = {2014}
}
@article{Puma2015,
author = {Puma, Michael J. and Bose, Satyajit and Chon, So Young and Cook, Benjamin I.},
journal = {Environmental Research Letters},
number = {2},
title = {{Assessing the evolving fragility of the global food system}},
volume = {10},
year = {2015}
}
@book{Glantz1999,
address = {Cambridge, UK, and New York, NY},
author = {Glantz, M. H.},
publisher = {Cambridge University Press},
title = {{Creeping Environmental Problems and Sustainable Development in the Aral Sea Basin}},
year = {1999}
}
@article{Mauser2015,
author = {Mauser, W. and Klepper, G. and Zabel, F. and Delzeit, R. and Hank, T. and Putzenlechner, B. and Calzadilla, A.},
journal = {Nature communications},
title = {{Global biomass production potentials exceed expected future demand without the need for cropland expansion}},
volume = {6},
year = {2015}
}
@techreport{Nations,
author = {Nations, United},
institution = {United Nations, Department of Economic and Social Affairs},
title = {{Population Division: World Urbanization Prospects, the 2014 Revision}}
}
@article{Fang2017a,
author = {Fang, Y. and Ceola, S. and Paik, K. and McGrath, G. and Rao, P. S. C. and Montanari, A. and Jawitz, J. W.},
journal = {In review},
title = {{Globally universal pattern of human settlements in river networks}},
year = {2017}
}
@article{Rodell2009,
author = {Rodell, M. and Velicogna, I. and Famiglietti, J. S.},
journal = {Nature},
number = {7258},
pages = {999--1002},
title = {{Satellite-based estimates of groundwater depletion in India}},
volume = {460},
year = {2009}
}
@article{Tilman2011,
author = {Tilman, D. and Balzer, C. and Hill, J. and Befort, B. L.},
journal = {Proceeding of the National Academy of Sciences},
number = {50},
pages = {20260--20264},
title = {{Global food demand and the sustainable intensification of agriculture}},
volume = {108},
year = {2011}
}
@techreport{Siebert2013,
author = {Siebert, Stefan and Heinrich, Verena and Frenken, Karen and Burke, Jacob},
institution = {FAO},
title = {{Global map of irrigation areas, version 5}},
year = {2013}
}
@article{Fang2017b,
author = {Fang, Y. and Jawitz, J. W.},
journal = {In review},
title = {{Are we getting closer to or farther from water?}},
year = {2017}
}
@book{Lappe1986,
address = {New York},
author = {Lappe, F. M. and Collins, J.},
publisher = {Grove},
title = {{World Hunger: Twelve Myths}},
year = {1986}
}
@article{Hoff2014,
author = {Hoff, H. and Doll, P. and Fader, M. and Gerten, D. and Hauser, S. and S., Siebert},
journal = {Hydrology and Earth System Sciences},
pages = {213--226},
title = {{Water footprints of cities -- indicators for sustainable consumption and production}},
volume = {18},
year = {2014}
}
@article{Fang2017,
author = {Fang, Y and Jawitz, J. W.},
journal = {Palgrave Communications (under review)},
title = {{Human population distribution in the conterminous United States: High resolution reconstruction 1790-2010}},
year = {2017}
}
@article{Hemmati2014,
author = {Hemmati, Mehdi and Smith, J. Cole and Thai, My T.},
journal = {Computational Optimization and Applications},
number = {1},
pages = {71--104},
title = {{A cutting-plane algorithm for solving a weighted influence interdiction problem}},
volume = {57},
year = {2014}
}
@article{Lenzen2012,
author = {Lenzen, M. and Moran, D. and Kanemoto, K. and Foran, B. and Lobefaro, L. and Geschke, A.},
journal = {Nature},
pages = {109--112},
title = {{International trade drives biodiversity threats in developing nations}},
volume = {486},
year = {2012}
}
@article{DeFries2013,
author = {DeFries, Ruth and Herold, Martin and Verchot, Louis and Macedo, Marcia N. and Shimabukuro, Yosio},
journal = {Philosophical Transactions of the Royal Society, B},
number = {1619},
pages = {20120173},
title = {{Export-oriented deforestation in Mato Grosso: harbinger or exception for other tropical forests?}},
volume = {368},
year = {2013}
}
@article{Dalin2012,
author = {Dalin, Carole and Konar, Megan and Hanasaki, Naota and Rinaldo, Andrea and Rodriguez-Iturbe, Ignacio},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {16},
pages = {5989----5994},
title = {{Evolution of the global virtual water trade network}},
volume = {109},
year = {2012}
}
@article{Chapagain2008,
author = {Chapagain, A K and Hoekstra, A Y},
journal = {Water International},
number = {1},
pages = {19----32},
title = {{The global component of freshwater demand and supply: An assessment of virtual water flows between nations as a result of trade in agricultural and industrial products}},
volume = {33},
year = {2008}
}
@article{Alexandratos2012,
abstract = {Comprehensive and authoritative assessment of the prospects for agriculture and food supply throughout the world from the UN Food and Agriculture Organization. Examines all forms of agriculture and acquaculture and the economic, technological and environmental factors affecting them. An indispensable reference for agriculturalists, economists, policy-makers, development and environment professionals worldwide.A detailed assessment of the long-term outlook for the world's food supplies, nutrition and agriculture from the world's foremost agricultural research institute. It examines outcomes from 2015 to 2030, covering supply and demand for all the major agricultural commodities and sectors, including fisheries and forestry. From this analysis, it examines the implications for trade, for nutrition and for undernourishment, and the impact of future production on the environment and resource base, and how technology can contribute to more sustainable development. One main finding is that, without a massive effort to improve development and relieve food security problems, there is little chance of meeting the target of halving the number of undernourished people by 2015. Agriculture is crucial to development, especially where it employs a majority of the population, and additional resources will have to be mobilized.},
author = {Alexandratos, N. and Bruinsma, J.},
doi = {10.1016/S0264-8377(03)00047-4},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alexandratos, Bruinsma - 2012 - World agriculture towards 20152030 an FAO perspective.pdf:pdf},
isbn = {9781844070077},
issn = {02648377},
journal = {ESA Working Paper No. 12-03. FAO: Rome},
keywords = {agricultural outlook,crop production,crop yields.,food demand,global outlook,irrigation,land use,nutrition,production growth},
pmid = {13463888},
title = {{World agriculture: towards 2015/2030: an FAO perspective}},
year = {2012}
}
@article{Pellow2016,
abstract = {It has recently been found that some RNA functions are determined by the actual folding kinetics and not just the RNA's nucleotide sequence or its native structure. We present new computational tools for simulating and analyzing RNA folding kinetic metrics such as population kinetics, folding rates, and the folding of particular subsequences. Our method first builds an approximate representation (called a map) of the RNA's folding energy landscape, and then uses specialized analysis techniques to extract folding kinetics from the map. We provide a new sampling strategy called Probabilistic Boltzmann Sampling (PBS) that enables us to approximate the folding landscape with much smaller maps, typically by several orders of magnitude. We also describe a new analysis technique, Map-based Monte Carlo (MMC) simulation, to stochastically extract folding pathways from the map. We demonstrate that our technique can be applied to large RNA (e.g., 200+ nucleotides), where representing the full landscape is infeasible, and that our tools provide results comparable to other simulation methods that work on complete energy landscapes. We present results showing that our approach computes the same relative functional rates as seen in experiments for the relative plasmid replication rates of ColE1 RNAII and its mutants, and for the relative gene expression rates of MS2 phage RNA and its mutants.},
author = {Pellow, David and Filippova, Darya and Kingsford, Carl},
doi = {10.1007/978-3-319-31957-5_10},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pellow, Filippova, Kingsford - 2016 - Improving Bloom Filter Performance on Sequence Data Using kk-mer Bloom Filters.pdf:pdf},
isbn = {978-3-319-31957-5},
issn = {0302-9743},
journal = {Research in Computational Molecular Biology},
keywords = {Computer Science},
pages = {137--151},
title = {{Improving Bloom Filter Performance on Sequence Data Using kk-mer Bloom Filters}},
url = {http://dx.doi.org/10.1007/978-3-319-31957-5_10%5Cnhttp://www.springerlink.com/content/433u3k75472v4542/},
volume = {4453},
year = {2016}
}
@article{Drezen2014,
abstract = {MOTIVATION: Efficient and fast next-generation sequencing (NGS) algorithms are essential to analyze the terabytes of data generated by the NGS machines. A serious bottleneck can be the design of such algorithms, as they require sophisticated data structures and advanced hardware implementation. RESULTS: We propose an open-source library dedicated to genome assembly and analysis to fasten the process of developing efficient software. The library is based on a recent optimized de-Bruijn graph implementation allowing complex genomes to be processed on desktop computers using fast algorithms with low memory footprints. Availability and implementation: The GATB library is written in C++ and is available at the following Web site http://gatb.inria.fr under the A-GPL license. CONTACT: lavenier@irisa.fr Supplementary information: Supplementary data are available at Bioinformatics online.},
author = {Drezen, Erwan and Rizk, Guillaume and Chikhi, Rayan and Deltel, Charles and Lemaitre, Claire and Peterlongo, Pierre and Lavenier, Dominique},
doi = {10.1093/bioinformatics/btu406},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Drezen et al. - 2014 - GATB Genome Assembly & Analysis Tool Box.pdf:pdf},
issn = {13674811},
journal = {Bioinformatics (Oxford, England)},
number = {20},
pages = {2959--2961},
pmid = {24990603},
title = {{GATB: Genome Assembly & Analysis Tool Box}},
volume = {30},
year = {2014}
}
@article{Yuster2012,
author = {Yuster, Raphael},
doi = {10.1017/S0963548312000235},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuster - 2012 - Dense Graphs With A Large Triangle Cover Have A Large Triangle Packing.pdf:pdf},
issn = {0963-5483},
journal = {Combinatorics, Probability & Computing},
number = {6},
pages = {952--962},
title = {{Dense Graphs With A Large Triangle Cover Have A Large Triangle Packing}},
volume = {21},
year = {2012}
}
@article{Xia2011,
abstract = {We consider the problem of finding a k-edge transversal set that intersects all (simple) cycles of length at most s in a planar graph, where s<3 is a constant. This problem, referred to as Small Cycle Transversal, is known to be NP-complete. We present a polynomialtime algorithm that computes a kernel of size 36
                        s3k for Small Cycle Transversal. In order to achieve this kernel, we extend the region decomposition technique of Alber et al. (2004) [1] by considering a unique region decomposition that is defined by shortest paths. Our kernel size is a significant improvement in terms of s over the kernel size obtained under the meta-kernelization framework by Bodlaender et al. (2009) [7]. ?? 2011 Elsevier B.V. All rights reserved.},
author = {Xia, Ge and Zhang, Yong},
doi = {10.1016/j.tcs.2011.02.040},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xia, Zhang - 2011 - On the small cycle transversal of planar graphs.pdf:pdf},
isbn = {3642169252},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Cycle transversal,Kernelization,Parameterized complexity,Planar graphs},
number = {29},
pages = {3501--3509},
publisher = {Elsevier B.V.},
title = {{On the small cycle transversal of planar graphs}},
url = {http://dx.doi.org/10.1016/j.tcs.2011.02.040},
volume = {412},
year = {2011}
}
@article{Krivelevich1995,
abstract = {Zs. Tuza conjectured that if a simple graph G does not contain more than k pairwise edge disjoint triangles, then there exists a set of at most 2k edges which meets all triangles in G. We prove this conjecture for K3, 3-free graphs (graphs that do not contain a homeomorph of K3, 3). Two fractional versions of the conjecture are also proved. ?? 1995.},
author = {Krivelevich, Michael},
doi = {10.1016/0012-365X(93)00228-W},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krivelevich - 1995 - On a conjecture of Tuza about packing and covering of triangles.pdf:pdf},
issn = {0012365X},
journal = {Discrete Mathematics},
number = {1-3},
pages = {281--286},
title = {{On a conjecture of Tuza about packing and covering of triangles}},
volume = {142},
year = {1995}
}
@article{Brugmann2009,
abstract = {We show that the problem to decide whether a graph can be made triangle-free with at most k edge deletions remains NP-complete even when restricted to planar graphs of maximum degree seven. In addition, we provide polynomial-time data reduction rules for this problem and obtain problem kernels consisting of 6k vertices for general graphs and 11k/3 vertices for planar graphs. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Br{\"{u}}gmann, D. and Komusiewicz, C. and Moser, H.},
doi = {10.1016/j.endm.2009.02.008},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Br{\"{u}}gmann, Komusiewicz, Moser - 2009 - On Generating Triangle-Free Graphs.pdf:pdf},
issn = {15710653 15710653},
journal = {Electronic Notes in Discrete Mathematics},
keywords = {[kernelization, NP-complete problem, parameterized},
number = {C},
title = {{On Generating Triangle-Free Graphs}},
volume = {32},
year = {2009}
}
@article{Kortsarz2010,
author = {Kortsarz, Guy},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kortsarz - 2010 - Approximating Maximum Subgraphs without Short Cycles.pdf:pdf},
journal = {Siam Journal of Discrete Math},
keywords = {090780122,10,1137,35j25,65m12,65n15,65n30,a posteriori error estimation,ams subject classifications,convergence,doi,greedy sampling,h -type,hp,p -type,parameter domain decomposition,reduced basis},
number = {1},
pages = {255--269},
title = {{Approximating Maximum Subgraphs without Short Cycles}},
volume = {24},
year = {2010}
}
@article{Shen2013,
abstract = {The assessment of network vulnerability is of great importance in the presence of unexpected disruptive events or adversarial attacks targeting on critical network links and nodes. In this paper, we study Critical Link Disruptor (CLD) and Critical Node Disruptor (CND) optimization problems to identify critical links and nodes in a network whose removals maximally destroy the network's functions. We provide a comprehensive complexity analysis of CLD and CND on general graphs and show that they still remain NP-complete even on unit disk graphs and power-law graphs. Furthermore, the CND problem is shown NP-hard to be approximated within &#x03A9;([(<i>n</i>-<i>k</i>)/(<i>n</i><sup>&#x03B5;</sup>)] ) on general graphs with <i>n</i> vertices and <i>k</i> critical nodes. Despite the intractability of these problems, we propose HILPR, a novel LP-based rounding algorithm, for efficiently solving CLD and CND problems in a timely manner. The effectiveness of our solutions is validated on various synthetic and real-world networks.},
author = {Shen, Yilin and Nguyen, Nam P. and Xuan, Ying and Thai, My T.},
doi = {10.1109/TNET.2012.2215882},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shen et al. - 2013 - On the discovery of critical links and nodes for assessing network vulnerability.pdf:pdf},
isbn = {1063-6692},
issn = {10636692},
journal = {IEEE/ACM Transactions on Networking},
keywords = {Computational complexity,experiments,inapproximability,network Vulnerability},
number = {3},
pages = {963--973},
title = {{On the discovery of critical links and nodes for assessing network vulnerability}},
volume = {21},
year = {2013}
}
@article{Wu2011,
abstract = {Motivated by detecting false friend links in online social networks, we define two optimization problems based on the balance theory for structural transitivity in social networks. We give a polynomial time algorithm for one problem and show the NP-hardness of the other. For the NP-hard problem, we show some polynomial time solvable cases and give a 2-approximation algorithm for a restricted version. We also propose a heuristic algorithm for a more general version of the problem.},
author = {Wu, Bang Ye},
doi = {10.1007/978-3-642-22616-8_19},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu - 2011 - On the maximum locally clustered subgraph and some related problems.pdf:pdf},
isbn = {9783642226151},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {NP-hard,algorithm,approximation algorithm,social network analysis,time complexity},
pages = {234--246},
title = {{On the maximum locally clustered subgraph and some related problems}},
volume = {6831 LNCS},
year = {2011}
}
@article{Gupta2016,
abstract = {In this paper, we study the set cover problem in the fully dynamic model. In this model, the set of active elements, i.e., those that must be covered at any given time, can change due to element arrivals and departures. The goal is to maintain an algorithmic solution that is competitive with respect to the current optimal solution. This model is popular in both the dynamic algorithms and online algorithms communities. The difference is in the restriction placed on the algorithm: in dynamic algorithms, the running time of the algorithm making updates (called update time) is bounded, while in online algorithms, the number of updates made to the solution (called recourse) is limited. In this paper we show the following results: In the update time setting, we obtain O(log n)-competitiveness with O(f log n) amortized update time, and O(f^3)-competitiveness with O(f^2) update time. The O(log n)-competitive algorithm is the first one to achieve a competitive ratio independent of f in this setting. In the recourse setting, we show a competitive ratio of O(min{log n,f}) with constant amortized recourse. Note that this matches the best offline bounds with just constant recourse, something that is impossible in the classical online model. Our results are based on two algorithmic frameworks in the fully-dynamic model that are inspired by the classic greedy and primal-dual algorithms for offline set cover. We show that both frameworks can be used for obtaining both recourse and update time bounds, thereby demonstrating algorithmic techniques common to these strands of research.},
archivePrefix = {arXiv},
arxivId = {1611.05646},
author = {Gupta, Anupam and Krishnaswamy, Ravishankar and Kumar, Amit and Panigrahi, Debmalya},
eprint = {1611.05646},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta et al. - 2016 - Online and Dynamic Algorithms for Set Cover.pdf:pdf},
title = {{Online and Dynamic Algorithms for Set Cover}},
url = {http://arxiv.org/abs/1611.05646},
year = {2016}
}
@article{Hagerup2010,
author = {Hagerup, Torben and Tholey, Torsten and Goethe-universit, Johann Wolfgang},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hagerup, Tholey, Goethe-universit - 2010 - E ffi cient Minimal Perfect Hashing in Nearly Minimal Space.pdf:pdf},
keywords = {algorithms and,computational and structural complexity,data structures,perfect hashing,space complexity,sparse tables},
pages = {317--326},
title = {{E ffi cient Minimal Perfect Hashing in Nearly Minimal Space}},
year = {2010}
}
@article{Anonymous,
author = {Anonymous, Anonymous},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anonymous - Unknown - Online Traffic Volume Estimation for Streams and Sliding Windows.pdf:pdf},
title = {{Online Traffic Volume Estimation for Streams and Sliding Windows}},
volume = {paper 63}
}
@article{Eden2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1504.00954v1},
author = {Eden, Talya and Levi, Amit and Ron, Dana and Seshadhri, C.},
doi = {10.1109/FOCS.2015.44},
eprint = {arXiv:1504.00954v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Eden et al. - 2015 - Approximately Counting Triangles in Sublinear Time.pdf:pdf},
isbn = {9781467381918},
issn = {02725428},
journal = {Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS},
keywords = {Sublinear Approximation Algorithm,Triangles Counting},
pages = {614--633},
title = {{Approximately Counting Triangles in Sublinear Time}},
volume = {2015-Decem},
year = {2015}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - On the Performance Anomalies of Multi-Source File Downloading.pdf:pdf},
title = {{On the Performance Anomalies of Multi-Source File Downloading}}
}
@article{Wu2016,
author = {Wu, Bin and Yi, Ke and Li, Zhenguo},
doi = {10.1109/TKDE.2016.2556663},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu, Yi, Li - 2016 - Counting triangles in large graphs by random sampling.pdf:pdf},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Triangle counting,random sampling},
number = {8},
pages = {2013--2026},
title = {{Counting triangles in large graphs by random sampling}},
volume = {28},
year = {2016}
}
@article{Bulteau2016,
abstract = {Estimating the number of triangles in graph streams using a limited amount of memory has become a popular topic in the last decade. Di erent variations of the problem have been studied depending on whether the graph edges are provided in arbitrary order or as incidence lists. However, with a few exceptions, the algorithms have considered insert-only streams. We present a new algorithm estimating the number of triangles in dynamic graph streams where edges can be both inserted and deleted. We show that our algorithm achieves better time and space complexity than previous solutions for various graph classes, for example sparse graphs with a relatively small number of triangles. Also, for graphs with constant transitivity coecient, a common situation in real graphs, this is the rst algorithm achieving constant processing time per edge.},
archivePrefix = {arXiv},
arxivId = {1404.4696},
author = {Bulteau, Laurent and Froese, Vincent and Kutzkov, Konstantin and Pagh, Rasmus},
doi = {10.1007/s00453-015-0036-4},
eprint = {1404.4696},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bulteau et al. - 2016 - Triangle Counting in Dynamic Graph Streams.pdf:pdf},
isbn = {9783319084039},
issn = {14320541},
journal = {Algorithmica},
keywords = {Randomized approximation algorithms,Streaming algorithms,Triangle counting},
number = {1},
pages = {259--278},
title = {{Triangle Counting in Dynamic Graph Streams}},
volume = {76},
year = {2016}
}
@article{Wang2016b,
abstract = {This paper initiates the studies of parallel algorithms for core maintenance in dynamic graphs. The core number is a fundamental index reflecting the cohesiveness of a graph, which are widely used in large-scale graph analytics. The core maintenance problem requires to update the core numbers of vertices after a set of edges and vertices are inserted into or deleted from the graph. We investigate the parallelism in the core update process when multiple edges and vertices are inserted or deleted. Specifically, we discover a structure called superior edge set, the insertion or deletion of edges in which can be processed in parallel. Based on the structure of superior edge set, efficient parallel algorithms are then devised for incremental and decremental core maintenance respectively. To the best of our knowledge, the proposed algorithms are the first parallel ones for the fundamental core maintenance problem. The algorithms show a significant speedup in the processing time compared with previous results that sequentially handle edge and vertex insertions/deletions. Finally, extensive experiments are conducted on different types of real-world and synthetic datasets, and the results illustrate the efficiency, stability and scalability of the proposed algorithms.},
archivePrefix = {arXiv},
arxivId = {1612.09368},
author = {Wang, Na and Yu, Dongxiao and Jin, Hai and Qian, Chen and Xie, Xia and Hua, Qiang-Sheng},
eprint = {1612.09368},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2016 - Parallel Algorithms for Core Maintenance in Dynamic Graphs.pdf:pdf},
title = {{Parallel Algorithms for Core Maintenance in Dynamic Graphs}},
url = {http://arxiv.org/abs/1612.09368},
year = {2016}
}
@article{Tsourakakis2009,
abstract = {Counting the number of triangles in a graph is a beautiful algorithmic problem which has gained importance over the last years due to its significant role in complex network analysis. Metrics frequently computed such as the clustering coefficient and the transitivity ratio involve the execution of a triangle counting algorithm. Furthermore, several interesting graph mining applications rely on computing the number of triangles in the graph of interest. In this paper, we focus on the problem of counting triangles in a graph. We propose a practical method, out of which all triangle counting algorithms can potentially benefit. Using a straightforward triangle counting algorithm as a black box, we performed 166 experiments on real-world networks and on synthetic datasets as well, where we show that our method works with high accuracy, typically more than 99% and gives significant speedups, resulting in even 130 times faster performance.},
author = {Tsourakakis, Charalampos E and Kang, U and Miller, Gary L and Faloutsos, Christos},
doi = {http://doi.acm.org/10.1145/1557019.1557111},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsourakakis et al. - 2009 - DOULION Counting Triangles in Massive Graphs with a Coin.pdf:pdf},
isbn = {9781605584959},
issn = {10120394},
journal = {KDD '09: 15th International Conference on Knowledge Discovery and Data Mining},
keywords = {algorithm,citation},
pages = {837--846},
title = {{DOULION: Counting Triangles in Massive Graphs with a Coin}},
year = {2009}
}
@article{Hu2013,
abstract = {This paper studies I/O-efficient algorithms for settling the classic triangle listing problem, whose solution is a basic operator in dealing with many other graph problems. Specifically, given an undirected graph G, the objective of triangle listing is to find all the cliques involving 3 vertices in G. The problem has been well studied in internal memory, but remains an urgent difficult challenge when G does not fit in memory, rendering any algorithm to entail frequent I/O accesses. Although previous research has attempted to tackle the challenge, the state-of-the-art solutions rely on a set of crippling assumptions to guarantee good performance. Motivated by this, we develop a new algorithm that is provably I/O and CPU efficient at the same time, without making any assumption on the input G at all. The algorithm uses ideas drastically different from all the previous approaches, and outperformed the existing competitors by a factor over an order of magnitude in our extensive experimentation.},
author = {Hu, Xiaocheng and Tao, Yufei and Chung, Chin-Wan},
doi = {10.1145/2463676.2463704},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu, Tao, Chung - 2013 - Massive graph triangulation.pdf:pdf},
isbn = {9781450320375},
issn = {07308078},
journal = {Proceedings of the 2013 international conference on Management of data - SIGMOD '13},
keywords = {graph,i,i/o-efficient algorithm,o-efficient algorithm,triangle},
pages = {325--336},
title = {{Massive graph triangulation}},
url = {http://dl.acm.org/citation.cfm?id=2463676.2463704%5Cnhttp://dl.acm.org/citation.cfm?doid=2463676.2463704},
year = {2013}
}
@article{Jha2013,
abstract = {We design a space efficient algorithm that approximates the transitivity (global clustering coefficient) and total triangle count with only a single pass through a graph given as a stream of edges. Our procedure is based on the classic probabilistic result, the birthday paradox. When the transitivity is constant and there are more edges than wedges (common properties for social networks), we can prove that our algorithm requires $O(\sqrt{n})$ space ($n$ is the number of vertices) to provide accurate estimates. We run a detailed set of experiments on a variety of real graphs and demonstrate that the memory requirement of the algorithm is a tiny fraction of the graph. For example, even for a graph with 200 million edges, our algorithm stores just 60,000 edges to give accurate results. Being a single pass streaming algorithm, our procedure also maintains a real-time estimate of the transitivity/number of triangles of a graph, by storing a minuscule fraction of edges.},
archivePrefix = {arXiv},
arxivId = {1212.2264},
author = {Jha, Madhav and Seshadhri, C. and Pinar, Ali},
doi = {10.1145/2487575.2487678},
eprint = {1212.2264},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jha, Seshadhri, Pinar - 2013 - A Space Efficient Streaming Algorithm for Triangle Counting Using the Birthday Paradox.pdf:pdf},
isbn = {9781450321747},
issn = {9781450321747},
journal = {Kdd},
keywords = {sandia national labs},
number = {212},
pages = {589--597},
title = {{A Space Efficient Streaming Algorithm for Triangle Counting Using the Birthday Paradox}},
url = {http://arxiv.org/abs/1212.2264},
volume = {V},
year = {2013}
}
@article{Tsourakakis2011,
author = {Tsourakakis, Charalampos E and Kolountzakis, Mihail and Miller, Gary L},
doi = {10.7155/jgaa.00245},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsourakakis, Kolountzakis, Miller - 2011 - Triangle Sparsifiers.pdf:pdf},
issn = {1526-1719},
journal = {Journal of Graph Theory and Applications},
number = {6},
pages = {703--726},
title = {{Triangle Sparsifiers}},
volume = {15},
year = {2011}
}
@inproceedings{Chu2011,
author = {Chu, S and Cheng, J},
booktitle = {17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.},
doi = {10.1145/2382577.2382581},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chu, Cheng - 2011 - Triangle Listing in Massive Networks and Its Applications.pdf:pdf},
isbn = {9781450308137},
issn = {15564681},
keywords = {clustering coefficient,graphs,large,massive networks,triangle counting,triangle listing},
publisher = {ACM},
title = {{Triangle Listing in Massive Networks and Its Applications}},
year = {2011}
}
@article{Becchetti2008,
abstract = {In this paper we study the problem of local triangle counting in large graphs. Namely, given a large graph G = (V;E) we want to estimate as accurately as possible the number of triangles incident to every node $\upsilon$ ∈ V in the graph. The problem of computing the global number of triangles in a graph has been considered before, but to our knowledge this is the first paper that addresses the problem of local triangle counting with a focus on the efficiency issues arising in massive graphs. The distribution of the local number of triangles and the related local clustering coefficient can be used in many interesting applications. For example, we show that the measures we compute can help to detect the presence of spamming activity in large-scale Web graphs, as well as to provide useful features to assess content quality in social networks. For computing the local number of triangles we propose two approximation algorithms, which are based on the idea of min-wise independent permutations (Broder et al. 1998). Our algorithms operate in a semi-streaming fashion, using O(jV j) space in main memory and performing O(log jV j) sequential scans over the edges of the graph. The first algorithm we describe in this paper also uses O(jEj) space in external memory during computation, while the second algorithm uses only main memory. We present the theoretical analysis as well as experimental results in massive graphs demonstrating the practical efficiency of our approach.},
author = {Becchetti, Luca and Boldi, Paolo and Castillo, Carlos and Gionis, Aristides},
doi = {10.1145/1401890.1401898},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Becchetti et al. - 2008 - Efficient Semi-streaming Algorithms for Local Triangle Counting in Massive Graphs.pdf:pdf},
isbn = {9781605581934},
journal = {Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining},
keywords = {graph mining,probabilistic algorithms,semi-streaming},
pages = {16--24},
title = {{Efficient Semi-streaming Algorithms for Local Triangle Counting in Massive Graphs}},
year = {2008}
}
@inproceedings{Tsourakakis,
author = {Tsourakakis, Charalampos E},
booktitle = {Eighth IEEE International Conference on Data Mining (ICDM)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsourakakis - 2008 - Fast Counting of Triangles in Large Real Networks.pdf:pdf},
publisher = {IEEE},
title = {{Fast Counting of Triangles in Large Real Networks}},
year = {2008}
}
@inproceedings{Calinescu2007,
abstract = {Let $f:2^{N} \rightarrow \cal R^{+}$ be a non-decreasing submodular set function, and let $(N,\cal I)$ be a matroid. We consider the problem $\max_{S \in \cal I} f(S)$. It is known that the greedy algorithm yields a 1/2-approximation [9] for this problem. It is also known, via a reduction from the max-k-cover problem, that there is no (1 {\"{i}}¾¿ 1/e+ {\"{i}}¾¿)-approximation for any constant {\"{i}}¾¿> 0, unless P= NP[6]. In this paper, we improve the 1/2-approximation to a (1 {\"{i}}¾¿ 1/e)-approximation, when fis a sum of weighted rank functions of matroids. This class of functions captures a number of interesting problems including set coverage type problems. Our main tools are the pipage rounding technique of Ageev and Sviridenko [1] and a probabilistic lemma on monotone submodular functions that might be of independent interest. We show that the generalized assignment problem (GAP) is a special case of our problem; although the reduction requires |N| to be exponential in the original problem size, we are able to interpret the recent (1 {\"{i}}¾¿ 1/e)-approximation for GAP by Fleischer et al.[10] in our framework. This enables us to obtain a (1 {\"{i}}¾¿ 1/e)-approximation for variants of GAP with more complex constraints.},
archivePrefix = {arXiv},
arxivId = {9780201398298},
author = {Calinescu, Gruia and Chekuri, Chandra and P{\'{a}}l, Martin and Vondr{\'{a}}k, Jan},
booktitle = {Integer Programming and Combinatorial Optimization (IPCO)},
doi = {10.1007/978-3-540-72792-7},
eprint = {9780201398298},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Calinescu et al. - 2007 - Maximizing a Submodular Set Function subject to a Matroid Constraint.pdf:pdf},
isbn = {978-3-540-72791-0},
issn = {0097-5397},
keywords = {approximation algorithm,generalized assign-,matroid,ment problem,monotone submodular set function,social welfare},
pages = {182--196},
pmid = {4520227},
title = {{Maximizing a Submodular Set Function subject to a Matroid Constraint}},
url = {http://dl.acm.org/citation.cfm?id=1419497.1419517%5Cnhttp://link.springer.com/10.1007/978-3-540-72792-7},
year = {2007}
}
@inproceedings{Belazzougui2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1607.04909v1},
author = {Belazzougui, Djamal and Gagie, Travis and Maekinen, Veli and Previtali, Marco},
booktitle = {String Processing and Information Retrieval},
eprint = {arXiv:1607.04909v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Belazzougui et al. - 2016 - Fully Dynamic de Bruijn Graphs.pdf:pdf},
pages = {145--152},
title = {{Fully Dynamic de Bruijn Graphs}},
year = {2016}
}
@book{Du2012,
author = {Du, Ding-Zhu and Ko, Ker-I and Hu, Xiaodong},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Du, Ko, Hu - 2012 - Design and Analysis of Approximation Algorithms.pdf:pdf},
isbn = {9781461417002},
title = {{Design and Analysis of Approximation Algorithms}},
year = {2012}
}
@inproceedings{Le2015,
author = {Le, Long T and Eliassi-rad, Tin and Tong, Hanghang},
booktitle = {SIAM International Conference on Data Mining},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Le, Eliassi-rad, Tong - 2015 - MET A Fast Algorithm for Minimizing Propagation in Large Graphs.pdf:pdf},
title = {{MET : A Fast Algorithm for Minimizing Propagation in Large Graphs}},
year = {2015}
}
@article{Feige2011,
author = {Feige, Uriel and Mirrokni, Vahab and Vondr{\'{a}}k, Jan},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feige, Mirrokni, Vondr{\'{a}}k - 2011 - Maximizing non-monotone submodular functions.pdf:pdf},
journal = {SIAM Journal on Computing},
title = {{Maximizing non-monotone submodular functions}},
year = {2011}
}
@article{Buchbinder2014,
author = {Buchbinder, Niv and Feldman, Moran and Naor, Joseph (Seffi) and Schwartz, Roy},
doi = {10.1137/1.9781611973402.106},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buchbinder et al. - 2014 - Submodular Maximization with Cardinality Constraints.pdf:pdf},
isbn = {<null>},
journal = {ACM-SIAM Symposium on Discrete Algorithms (SODA)},
pages = {1433--1452},
title = {{Submodular Maximization with Cardinality Constraints}},
url = {http://epubs.siam.org/doi/abs/10.1137/1.9781611973402.106},
year = {2014}
}
@article{Ran2015,
abstract = {The largest eigenvalue of the adjacency matrix of a network (referred to as the spectral radius) is an important metric in its own right. Further, for several models of epidemic spread on networks (e.g., the ‘flu-like' SISmodel), it has been shown that an epidemic dies out quickly if the spectral radius of the graph is below a certain threshold that depends on themodel parameters. This motivates a strategy to control epidemic spread by reducing the spectral radius of the underlying network. In this paper, we develop a suite of provable approxima- tion algorithms for reducing the spectral radius by removing the minimum cost set of edges (modeling quarantining) or nodes (modeling vaccinations), with different time and qual- ity tradeoffs. Our main algorithm, GreedyWalk, is based on the idea of hitting closed walks of a given length, and gives an O(log2 n)-approximation, where n denotes the number of nodes; it also performs much better in practice compared to all prior heuristics proposed for this problem. We further present a novel sparsification method to improve its running time. In addition, we give a new primal-dual based algorithm with an even better approximation guarantee (O(log n)), albeit with slower running time. We also give lower bounds on the worst-case performance of some of the popular heuristics. Finally we demonstrate the applicability of our algorithms and the properties of our solutions via extensive experiments on multiple synthetic and real networks},
archivePrefix = {arXiv},
arxivId = {1501.0661},
author = {Ran, Shi-Ju and Peng, Cheng and Li, Wei and Su, Gang},
doi = {10.1137/1.9781611974010.64},
eprint = {1501.0661},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ran et al. - 2015 - Approximation Algorithms for Reducing the Spectral Radius To Control Epidemic Spread.pdf:pdf},
isbn = {9781510811522},
keywords = {eigenvalue,remove edges,sparsification,spectral radius},
pages = {3},
title = {{Approximation Algorithms for Reducing the Spectral Radius To Control Epidemic Spread}},
url = {http://arxiv.org/abs/1501.0661},
year = {2015}
}
@book{Du2009,
abstract = {This book provides a complete and comprehensive reference/guide to Pyomo (Python Optimization Modeling Objects) for both beginning and advanced modelers, including students at the undergraduate and graduate levels, academic researchers, and practitioners. The text illustrates the breadth of the modeling and analysis capabilities that are supported by the software and support of complex real-world applications. Pyomo is an open source software package for formulating and solving large-scale optimization and operations research problems. The text begins with a tutorial on simple linear and integer programming models. A detailed reference of Pyomo's modeling components is illustrated with extensive examples, including a discussion of how to load data from data sources like spreadsheets and databases. Chapters describing advanced modeling capabilities for nonlinear and stochastic optimization are also included. The Pyomo software provides familiar modeling features within Python, a powerful dynamic programming language that has a very clear, readable syntax and intuitive object orientation. Pyomo includes Python classes for defining sparse sets, parameters, and variables, which can be used to formulate algebraic expressions that define objectives and constraints. Moreover, Pyomo can be used from a command-line interface and within Python's interactive command environment, which makes it easy to create Pyomo models, apply a variety of optimizers, and examine solutions. The software supports a different modeling approach than commercial AML (Algebraic Modeling Languages) tools, and is designed for flexibility, extensibility, portability, and maintainability but also maintains the central ideas in modern AMLs.},
author = {Du, Ding-Zhu and Ko, Ker-I and Hu, Xiaodong},
booktitle = {Advances in Modeling Agricultural Systems},
doi = {10.1007/978-0-387-73669-3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Du, Ko, Hu - 2009 - Design and Analysis of Approximation Algorithms.pdf:pdf},
isbn = {9781461437727},
pages = {1--22},
title = {{Design and Analysis of Approximation Algorithms}},
url = {papers2://publication/doi/10.1007/978-0-387-75181-8_21},
volume = {25},
year = {2009}
}
@article{Kuhlman2013,
abstract = {Eliminating interactions among individuals is an important means of blocking contagion spread, e.g., closing schools during an epidemic or shutting down electronic communication channels during social unrest. We study contagion blocking in networked populations by identifying edges to remove from a network, thus blocking contagion transmission pathways. We formulate various problems to minimize contagion spread and show that some are efficiently solvable while others are formally hard. We also compare our hardness results to those from node blocking problems and show interesting differences between the two. Our main problem is not only hard, but also has no approximation guarantee, unless P=NP. Therefore, we devise a heuristic for the problem and compare its performance to state-of-the-art heuristics from the literature. We show, through results of 12 (network, heuristic) combinations on three real social networks, that our method offers considerable improvement in the ability to block contagions in weighted and unweighted networks. We also conduct a parametric study to understand the limitations of our approach. {\textcopyright} 2013 IEEE.},
author = {Kuhlman, Chris J. and Tuli, Gaurav and Swarup, Samarth and Marathe, Madhav V. and Ravi, S. S.},
doi = {10.1109/ICDM.2013.47},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhlman et al. - 2013 - Blocking simple and complex contagion by edge removal.pdf:pdf},
isbn = {15504786 (ISSN)},
issn = {15504786},
journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
keywords = {complex contagion,contagion blocking,simple contagion},
pages = {399--408},
title = {{Blocking simple and complex contagion by edge removal}},
year = {2013}
}
@article{Bil2016,
author = {Bil, Vittorio and Caruso, Antonio and Conference, Seventeen Italian and Computer, Theoretical and Lecce, Science},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bil et al. - 2016 - ICTCS 2016.pdf:pdf},
title = {{ICTCS 2016}},
year = {2016}
}
@article{Zhang2016cont,
abstract = {Given a network with groups, such as a contact-network grouped by ages, which are the best groups to immunize to control the epidemic? Equivalently, how to best choose communities in social networks like Facebook to stop rumors from spreading? Immunization is an important problem in multiple different domains like epidemiology, public health, cyber security and social media. Additionally, clearly immunization at group scale (like schools and communities) is more realistic due to constraints in implementations and compliance (e.g., it is hard to ensure specific individuals take the adequate vaccine). Hence efficient algorithms for such a "group-based" problem can help public-health experts take more practical decisions. However most prior work has looked into individual-scale immunization. In this paper, we study the problem of controlling propagation at group scale. We formulate novel so-called Group Immunization problems for multiple natural settings (for both threshold and cascade-based contagion models under both node-level and edge-level interventions) and develop multiple efficient algorithms, including provably approximate solutions. Finally, we show the effectiveness of our methods via extensive experiments on real and synthetic datasets.},
author = {Zhang, Yao and Adiga, Abhijin and Vullikanti, Anil and Prakash, B. Aditya},
doi = {10.1109/ICDM.2015.59},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2016 - Controlling propagation at group scale on networks.pdf:pdf},
isbn = {9781467395038},
issn = {15504786},
journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
pages = {619--628},
title = {{Controlling propagation at group scale on networks}},
volume = {2016-Janua},
year = {2016}
}
@article{Khalil2014,
abstract = {How can we optimize the topology of a networked system to bring a flu under control, propel a video to popularity, or stifle a network malware in its infancy? Previous work on information diffusion has focused on modeling the diffusion dynamics and selecting nodes to maximize/minimize influence. Only a paucity of recent studies have attempted to address the network modification problems, where the goal is to either facilitate desirable spreads or curtail undesirable ones by adding or deleting a small subset of network nodes or edges. In this paper, we focus on the widely studied linear threshold diffusion model, and prove, for the first time, that the network modification problems under this model have supermodular objective functions. This surprising property allows us to design efficient data structures and scalable algorithms with provable approximation guarantees, despite the hardness of the problems in question. Both the time and space complexities of our algorithms are linear in the size of the network, which allows us to experiment with millions of nodes and edges. We show that our algorithms outperform an array of heuristics in terms of their effectiveness in controlling diffusion processes, often beating the next best by a significant margin.},
author = {Khalil, Elias Boutros and Dilkina, Bistra and Song, Le},
doi = {10.1145/2623330.2623704},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khalil, Dilkina, Song - 2014 - Scalable diffusion-aware optimization of network topology.pdf:pdf},
isbn = {9781450329569},
journal = {Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '14},
keywords = {approximation,diffusion networks,network optimization,permodularity,su-},
pages = {1226--1235},
title = {{Scalable diffusion-aware optimization of network topology}},
url = {http://dl.acm.org/citation.cfm?doid=2623330.2623704},
year = {2014}
}
@article{Centola2015,
abstract = {Recent research on social contagion has demonstrated significant ef-fects of network topology on the dynamics of diffusion. However, net-work topologies are not given a priori. Rather, they are patterns of re-lations that emerge from individual and structural features of society, such as population composition, group heterogeneity, homophily, and social consolidation. Following Blau and Schwartz, the author devel-ops a model of social network formation that explores how social and structural constraints on tie formation generate emergent social topol-ogies and then explores the effectiveness of these social networks for the dynamics of social diffusion. Results show that, at one extreme, high levels of consolidation can create highly balkanized communities with poor integration of shared norms and practices. As suggested by Blau and Schwartz, reducing consolidation creates more crosscut-ting circles and significantly improves the dynamics of social diffusion across the population. However, the author finds that further reduc-ing consolidation creates highly intersecting social networks that fail to support the widespread diffusion of norms and practices, indicating that successful social diffusion can depend on moderate to high levels of structural consolidation. Recent theoretical and empirical studies on the spread of social norms have identified the importance of network topology—the large-scale pattern of ties within a population—for determining both the rate and extent of dif-fusion processes ðWatts and This content downloaded from 165.123.34.86 on Mon, 1 Jun 2015 01:08:35 AM All use subject to JSTOR Terms and Conditions man, Barabasi, and Watts 2006; Centola and Macy 2007; Centola 2010Þ. While much of the literature on networks treats the topological features of social structure as given quantities, networks do not emerge ex nihilo, but are endogenously formed patterns of relationships that are created by individual and institutional forces that constrain and direct everyday in-teractions ðBlau 1977; McPherson and Smith-Lovin 1987; McPherson, Po-pielarz, and Drobnic 1992; Popielarz and McPherson 1995; Watts, Dodds, and Newman 2002; Kossinets and Watts 2009Þ. For instance, at the indi-vidual level, choice homophily—people's preference to form social con-nections with others who are like themselves—is a powerful force that controls the formation of social ties ðVerbrugge 1977; Blau and Schwartz 1984; Shrum, Cheek, and Hunter 1988; McPherson, Smith-Lovin, and Cook 2001; Reagans 2005; Currarini, Jackson, and Pin 2010; Centola and van de Rijt 2015Þ. At the level of social structure, organizational and in-stitutional contexts form the basis for social interaction ðBlau 1977; Mc-Pherson et al. 1992; McPherson 2004Þ, and the distribution and consolida-tion of characteristics across a population determine the frequency with which people with diverse characteristics come in contact with one another ðBlau 1977; Blau and Schwartz 1984; McPherson et al. 1992Þ. Together, these forces help to shape the collective pattern of network ties that emerges within a society. These individual and institutional forces can thereby indirectly affect the potential for social integration. Classic work by Blau and Schwartz ð1984Þ on the relationship between social institutions and emergent network struc-tures found that " consolidated " societies—where one's friends, colleagues, and neighbors are all the same people—limit social integration across the society by preventing the formation of " cross-cutting social ties " between diverse social groups. I take Blau and Schwartz's structural theory one step further by investigating social integration as a diffusion process—in particular, the spread of shared cultural practices and social norms throughout a popu-lation ðBoyd and Richerson 1985; Castro and Toro 2004; Centola and Macy 2007Þ. The central goal of this article is to explore how changes in a society's population structure affect these forms of social diffusion. I proceed by first investigating how the " primitive " structural parame-ters of homophily and consolidation ðSkvoretz 1983; Blau and Schwartz 1984Þ control the formation of social networks with distinct topological properties—such as clustering, path length, and bridge width. I then explore the effectiveness of these emergent networks for promoting the spread of},
author = {Centola, Damon},
doi = {10.1086/681275},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Centola - 2015 - The Social Origins of Networks and Diffusion.pdf:pdf},
isbn = {00029602},
issn = {00029602},
journal = {American Journal of Sociology},
number = {5},
pages = {1295--1338},
pmid = {26421341},
title = {{The Social Origins of Networks and Diffusion}},
volume = {120},
year = {2015}
}
@article{Morrison2008,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Morrison, B. B. and Weaver},
doi = {10.1109/MC.2008.61},
eprint = {arXiv:1011.1669v3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Morrison, Weaver - 2008 - Social Networking.pdf:pdf},
isbn = {978160558012X},
issn = {0018-9162},
journal = {Computer},
keywords = {diffusion source,influencers,information diffusion,social networks},
number = {2},
pages = {97--100},
pmid = {21485286},
title = {{Social Networking}},
volume = {41},
year = {2008}
}
@article{Hill,
abstract = {This paper demonstrates a cluster-based method to isolate influence in social network-based observational data, where "influence" is defined to mean that one person posts about a topic online and a second person posts about the same topic because he or she read the first post. Isolating influence in observational data is difficult, because we may observe that con-nected people discuss the same topic in proximate periods for reasons other than influence, in-cluding homophily–connected people are similar–and exogenous shock; they may have learned of the topic from some external source. We employ a matched sample estimation technique that has been used in the past to measure influence by controlling for demographic and usage based homophily, and add to the matching scheme a cluster ID. Our contribution is two-fold: First, we provide preliminary evidence that social network-based clusters capture homophily, indicating that a network-based attribute approach may not only capture homophily but also may be used in lieu of using demographic attributes for matching similar users in scenarios when privacy preservation is a concern. Second, we show that by adding a network position attribute, a cluster ID, when matching similar users, we can isolate influence better. We be-lieve that our approach to isolate influence can have a broad impact on problems where social networks and associated behaviors can be observed over time.},
author = {Hill, Shawndra and Benton, Adrian and Ungar, Lyle and Macskassy, Sofus and Chung, Annie and Holmes, John H},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hill et al. - Unknown - A Cluster-based Method for Isolating Influence on Twitter.pdf:pdf},
title = {{A Cluster-based Method for Isolating Influence on Twitter}}
}
@article{Bakshy2012,
abstract = {Online social networking technologies enable individuals to simultaneously share information with any number of peers. Quantifying the causal effect of these mediums on the dis- semination of information requires not only identification of who influences whom, but also of whether individuals would still propagate information in the absence of social sig- nals about that information. We examine the role of social networks in online information diffusion with a large-scale field experiment that randomizes exposure to signals about friends' information sharing among 253 million subjects in situ. Those who are exposed are significantly more likely to spread information, and do so sooner than those who are not exposed. We further examine the relative role of strong and weak ties in information propagation. We show that, although stronger ties are individually more influential, it is the more abundant weak ties who are responsible for the propagation of novel information. This suggests that weak ties may play a more dominant role in the dissemination of information online than currently believed. Categories},
archivePrefix = {arXiv},
arxivId = {1201.4145},
author = {Bakshy, Eytan and Rosenn, Itamar and Marlow, Cameron and Adamic, Lada},
doi = {10.1145/2187836.2187907},
eprint = {1201.4145},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bakshy et al. - 2012 - The role of social networks in information diffusion.pdf:pdf},
isbn = {9781450312295},
issn = {1450312292},
journal = {WWW 2012 - Session: Information Diffusion in Social Networks April 16-20, 2012, Lyon, France},
keywords = {Experimentation,Human Factors,Measurement,causality,social influence,tie strength},
pages = {519--528},
pmid = {17466816},
title = {{The role of social networks in information diffusion}},
year = {2012}
}
@article{Cozzo2013,
abstract = {We develop a theoretical framework for the study of epidemiclike social contagion in large scale social systems. We consider the most general setting in which different communication platforms or categories form multiplex networks. Specifically, we propose a contact-based information spreading model, and show that the critical point of the multiplex system associated with the active phase is determined by the layer whose contact probability matrix has the largest eigenvalue. The framework is applied to a number of different situations, including a real multiplex system. Finally, we also show that when the system through which information is disseminating is inherently multiplex, working with the graph that results from the aggregation of the different layers is inaccurate.},
archivePrefix = {arXiv},
arxivId = {arXiv:1307.1656v2},
author = {Cozzo, Emanuele and Ba{\~{n}}os, Raquel A. and Meloni, Sandro and Moreno, Yamir},
doi = {10.1103/PhysRevE.88.050801},
eprint = {arXiv:1307.1656v2},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cozzo et al. - 2013 - Contact-based social contagion in multiplex networks.pdf:pdf},
issn = {15393755},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {5},
pages = {1--5},
title = {{Contact-based social contagion in multiplex networks}},
volume = {88},
year = {2013}
}
@article{Pei2015,
abstract = {Information spreading in online social communities has attracted tremendous attention due to its utmost practical values in applications. Despite that several individual-level diffusion data have been investigated, we still lack the detailed understanding of the spreading pattern of information. Here, by comparing information flows and social links in a blog community, we find that the diffusion processes are induced by three different spreading mechanisms: social spreading, self-promotion and broadcast. Although numerous previous studies have employed epidemic spreading models to simulate information diffusion, we observe that such models fail to reproduce the realistic diffusion pattern. In respect to users behaviors, strikingly, we find that most users would stick to one specific diffusion mechanism. Moreover, our observations indicate that the social spreading is not only crucial for the structure of diffusion trees, but also capable of inducing more subsequent individuals to acquire the information. Our findings suggest new directions for modeling of information diffusion in social systems, and could inform design of efficient propagation strategies based on users behaviors.},
archivePrefix = {arXiv},
arxivId = {1504.00495},
author = {Pei, Sen and Muchnik, Lev and Tang, Shaoting and Zheng, Zhiming and Makse, Hern{\'{a}}n A.},
doi = {10.1371/journal.pone.0126894},
eprint = {1504.00495},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pei et al. - 2015 - Exploring the complex pattern of information spreading in online blog communities.pdf:pdf},
isbn = {1932-6203},
issn = {19326203},
journal = {PLoS ONE},
number = {5},
pages = {1--18},
pmid = {25985081},
title = {{Exploring the complex pattern of information spreading in online blog communities}},
volume = {10},
year = {2015}
}
@article{Lewis2012,
abstract = {Disentangling the effects of selection and influence is one of social science's greatest unsolved puzzles: Do people befriend others who are similar to them, or do they become more similar to their friends over time? Recent advances in stochastic actor-based modeling, combined with self-reported data on a popular online social network site, allow us to address this question with a greater degree of precision than has heretofore been possible. Using data on the Facebook activity of a cohort of college students over 4 years, we find that students who share certain tastes in music and in movies, but not in books, are significantly likely to befriend one another. Meanwhile, we find little evidence for the diffusion of tastes among Facebook friends-except for tastes in classical/jazz music. These findings shed light on the mechanisms responsible for observed network homogeneity; provide a statistically rigorous assessment of the coevolution of cultural tastes and social relationships; and suggest important qualifications to our understanding of both homophily and contagion as generic social processes.},
author = {Lewis, Kevin and Gonzalez, Marco and Kaufman, Jason},
doi = {10.1073/pnas.1109739109},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lewis, Gonzalez, Kaufman - 2012 - Social selection and peer influence in an online social network.pdf:pdf},
isbn = {1109739109},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {1},
pages = {68--72},
pmid = {22184242},
title = {{Social selection and peer influence in an online social network}},
volume = {109},
year = {2012}
}
@article{Hamari2015,
abstract = {Today, people use a variety of social and gameful (mobile) applications in order to motivate themselves and others to maintain difficult habits such as exercise, sustainable consumption and healthy eating. However, we have yet lacked understanding of how social influence affects willingness to maintain these difficult habits with the help of gamification services. In order to investigate this phenomenon, we measured how social influence predicts attitudes, use and further exercise in the context of gamification of exercise. Our results show that people indeed do "work out for likes", or in other words, social influence, positive recognition and reciprocity have a positive impact on how much people are willing to exercise as well as their attitudes and willingness to use gamification services. Moreover, we found that the more friends a user has in the service, the larger the effects are. Furthermore, the findings of the empirical study further provide new understanding on the phenomenon of social influence in technology adoption/use continuance in general by showing, in addition to subjective norms, how getting recognized, receiving reciprocal benefits and network effects contribute to use continuance.},
author = {Hamari, Juho and Koivisto, Jonna},
doi = {10.1016/j.chb.2015.04.018},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hamari, Koivisto - 2015 - Working out for likes An empirical study on social influence in exercise gamification.pdf:pdf},
isbn = {0747-5632},
issn = {07475632},
journal = {Computers in Human Behavior},
keywords = {Continued use,Gamification,Social influence,Social networking,eHealth,mHealth},
pages = {333--347},
title = {{"Working out for likes": An empirical study on social influence in exercise gamification}},
volume = {50},
year = {2015}
}
@article{Wang2015,
abstract = {A key ingredient in social contagion dynamics is reinforcement, as adopting a certain social behavior requires verification of its credibility and legitimacy. Memory of nonredundant information plays an important role in reinforcement, which so far has eluded theoretical analysis. We first propose a general social contagion model with reinforcement derived from nonredundant information memory. Then, we develop a unified edge-based compartmental theory to analyze this model, and a remarkable agreement with numerics is obtained on some specific models. We use a spreading threshold model as a specific example to understand the memory effect, in which each individual adopts a social behavior only when the cumulative pieces of information that the individual received from his or her neighbors exceeds an adoption threshold. Through analysis and numerical simulations, we find that the memory characteristic markedly affects the dynamics as quantified by the final adoption size. Strikingly, we uncover a transition phenomenon in which the dependence of the final adoption size on some key parameters, such as the transmission probability, can change from being discontinuous to being continuous. The transition can be triggered by proper parameters and structural perturbations to the system, such as decreasing individuals' adoption threshold, increasing initial seed size, or enhancing the network heterogeneity.},
archivePrefix = {arXiv},
arxivId = {1505.04077v1},
author = {Wang, Wei and Tang, Ming and Zhang, Hai Feng and Lai, Ying Cheng},
doi = {10.1103/PhysRevE.92.012820},
eprint = {1505.04077v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2015 - Dynamics of social contagions with memory of nonredundant information.pdf:pdf},
issn = {15502376},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {1},
pages = {1--12},
pmid = {26274238},
title = {{Dynamics of social contagions with memory of nonredundant information}},
volume = {92},
year = {2015}
}
@article{Sharpanskykh2014,
abstract = {In this paper an agent-based social contagion model with an underlying dynamic network is proposed and analyzed. In contrast to the existing social contagion models, the strength of links between agents changes gradually rather than abruptly based on a threshold mechanism. An essential feature of the model - the ability to form clusters - is extensively investigated in the paper analytically and by simulation. Specifically, the distribution of clusters in random and scale-free networks is investigated, the dynamics of links within and between clusters are determined, the minimal distance between two clusters is identified. Moreover, model abstraction methods are proposed by using which aggregated opinion states of clusters of agents can be approximated with a high accuracy. These techniques also improve the computational efficiency of social contagion models (up to 6 times). ?? 2014 Elsevier B.V.},
author = {Sharpanskykh, Alexei and Treur, Jan},
doi = {10.1016/j.neucom.2014.03.069},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sharpanskykh, Treur - 2014 - Modelling and analysis of social contagion in dynamic networks.pdf:pdf},
isbn = {9783642404948},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Agent-based simulation,Dynamic networks,Social contagion models,Social decision making},
pages = {140--150},
publisher = {Elsevier},
title = {{Modelling and analysis of social contagion in dynamic networks}},
url = {http://dx.doi.org/10.1016/j.neucom.2014.03.069},
volume = {146},
year = {2014}
}
@article{Lu2011,
abstract = {Spreading dynamics of information and diseases are usually analyzed by using a unified framework and analogous models. In this paper, we propose a model to emphasize the essential difference between information spreading and epidemic spreading, where the memory effects, the social reinforcement and the non-redundancy of contacts are taken into account. Under certain conditions, the information spreads faster and broader in regular networks than in random networks, which to some extent supports the recent experimental observation of spreading in online society [D. Centola, Science {\bf 329}, 1194 (2010)]. At the same time, simulation result indicates that the random networks tend to be favorable for effective spreading when the network size increases. This challenges the validity of the above-mentioned experiment for large-scale systems. More significantly, we show that the spreading effectiveness can be sharply enhanced by introducing a little randomness into the regular structure, namely the small-world networks yield the most effective information spreading. Our work provides insights to the understanding of the role of local clustering in information spreading.},
archivePrefix = {arXiv},
arxivId = {1107.0429},
author = {L{\"{u}}, Linyuan and Chen, Duan Bing and Zhou, Tao},
doi = {10.1088/1367-2630/13/12/123005},
eprint = {1107.0429},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/L{\"{u}}, Chen, Zhou - 2011 - The small world yields the most effective information spreading.pdf:pdf},
isbn = {1367-2630},
issn = {13672630},
journal = {New Journal of Physics},
title = {{The small world yields the most effective information spreading}},
volume = {13},
year = {2011}
}
@article{Zhou2013,
author = {Zhou, Yang and Liu, Ling},
doi = {10.1145/2487575.2487640},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou, Liu - 2013 - Social influence based clustering of heterogeneous information networks.pdf:pdf},
isbn = {9781450321747},
journal = {Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '13},
keywords = {graph clustering,heterogeneous network,social influence},
pages = {338},
title = {{Social influence based clustering of heterogeneous information networks}},
url = {http://dl.acm.org/citation.cfm?doid=2487575.2487640},
year = {2013}
}
@article{Romero2011,
abstract = {There is a widespread intuitive sense that different kinds of information spread differently on-line, but it has been difficult to evaluate this question quantitatively since it requires a setting where many different kinds of information spread in a shared environment. Here we study this issue on Twitter, analyzing the ways in which tokens known as hashtags spread on a network defined by the interactions among Twitter users. We find significant variation in the ways that widely-used hashtags on different topics spread. Our results show that this variation is not attributable simply to differences in "stickiness," the probability of adoption based on one or more exposures, but also to a quantity that could be viewed as a kind of "persistence" - the relative extent to which repeated exposures to a hashtag continue to have significant marginal effects. We find that hashtags on politically controversial topics are particularly persistent, with repeated exposures continuing to have unusually large marginal effects on adoption; this provides, to our knowledge, the first large-scale validation of the "complex contagion" principle from sociology, which posits that repeated exposures to an idea are particularly crucial when the idea is in some way controversial or contentious. Among other findings, we discover that hashtags representing the natural analogues of Twitter idioms and neologisms are particularly non-persistent, with the effect of multiple exposures decaying rapidly relative to the first exposure. We also study the subgraph structure of the initial adopters for different widely-adopted hashtags, again finding structural differences across topics. We develop simulation-based and generative models to analyze how the adoption dynamics interact with the network structure of the early adopters on which a hashtag spreads.},
author = {Romero, Daniel M and Meeder, Brendan and Kleinberg, Jon},
doi = {10.1145/1963405.1963503},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Romero, Meeder, Kleinberg - 2011 - Differences in the mechanics of information diffusion across topics.pdf:pdf},
isbn = {9781450306324},
issn = {14602059},
journal = {Proceedings of the 20th international conference on World wide web - WWW '11},
keywords = {Social media,information diffusion,social contagion},
pages = {695},
title = {{Differences in the mechanics of information diffusion across topics}},
url = {http://dl.acm.org/citation.cfm?id=1963503%5Cnhttp://portal.acm.org/citation.cfm?doid=1963405.1963503},
year = {2011}
}
@article{Zheng2013,
abstract = {Some epidemic spreading models are usually applied to analyze the propagation of opinions or news. However, the dynamics of epidemic spreading and information or behavior spreading are essentially different in many aspects. Centola's experiments [Science 329, 1194 (2010)] on behavior spreading in online social networks showed that the spreading is faster and broader in regular networks than in random networks. This result contradicts with the former understanding that random networks are preferable for spreading than regular networks. To describe the spreading in online social networks, a unknown-known-approved-exhausted four-status model was proposed, which emphasizes the effect of social reinforcement and assumes that the redundant signals can improve the probability of approval (i.e., the spreading rate). Performing the model on regular and random networks, it is found that our model can well explain the results of Centola's experiments on behavior spreading and some former studies on information spreading in different parameter space. The effects of average degree and network size on behavior spreading process are further analyzed. The results again show the importance of social reinforcement and are accordant with Centola's anticipation that increasing the network size or decreasing the average degree will enlarge the difference of the density of final approved nodes between regular and random networks. Our work complements the former studies on spreading dynamics, especially the spreading in online social networks where the information usually requires individuals' confirmations before being transmitted to others.},
author = {Zheng, Muhua and L{\"{u}}, Linyuan and Zhao, Ming},
doi = {10.1103/PhysRevE.88.012818},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zheng, L{\"{u}}, Zhao - 2013 - Spreading in online social networks The role of social reinforcement.pdf:pdf},
isbn = {1539-3755},
issn = {15393755},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {1},
pages = {1--7},
pmid = {23944529},
title = {{Spreading in online social networks: The role of social reinforcement}},
volume = {88},
year = {2013}
}
@article{Kuhnle2017,
archivePrefix = {arXiv},
arxivId = {arXiv:submit/1791422},
author = {Kuhnle, Alan and Nguyen, Nam P and Dinh, Thang N and Thai, My T},
doi = {10.1007/s13278-017-0426-5},
eprint = {1791422},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhnle et al. - 2017 - Vulnerability of clustering under node failure in complex networks.pdf:pdf},
journal = {Social Network Analysis and Mining},
number = {8},
primaryClass = {arXiv:submit},
title = {{Vulnerability of clustering under node failure in complex networks}},
volume = {7},
year = {2017}
}
@article{Tong2012,
abstract = {Controlling the dissemination of an entity (e.g., meme, virus, etc) on a large graph is an interesting problem in many disciplines. Ex- amples include epidemiology, computer security, marketing, etc. So far, previous studies have mostly focused on removing or inoc- ulating nodes to achieve the desired outcome. We shift the problem to the level of edges and ask: which edges should we add or delete in order to speed-up or contain a dissem- ination? First, we propose effective and scalable algorithms to solve these dissemination problems. Second, we conduct a theo- retical study of the two problems and our methods, including the hardness of the problem, the accuracy and complexity of our meth- ods, and the equivalence between the different strategies and prob- lems. Third and lastly, we conduct experiments on real topologies of varying sizes to demonstrate the effectiveness and scalability of our approaches.},
author = {Tong, Hanghang and Prakash, B Aditya and Eliassi-Rad, Tina and Faloutsos, Michalis and Faloutsos, Christos},
doi = {10.1145/2396761.2396795},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tong et al. - 2012 - Gelling, and melting, large graphs by edge manipulation.pdf:pdf},
isbn = {9781450311564},
issn = {9781450311564},
journal = {21st ACM international conference on Information and knowledge management},
keywords = {edge manipulation,graph mining,immunization,scalability},
pages = {245},
title = {{Gelling, and melting, large graphs by edge manipulation}},
url = {http://dl.acm.org/citation.cfm?doid=2396761.2396795},
year = {2012}
}
@article{Previtali,
archivePrefix = {arXiv},
arxivId = {arXiv:1607.04909v1},
author = {Previtali, Marco},
eprint = {arXiv:1607.04909v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Previtali - Unknown - Fully Dynamic de Bruijn Graphs.pdf:pdf},
title = {{Fully Dynamic de Bruijn Graphs}}
}
@inproceedings{Wang2003,
author = {Wang, Yang and Chakrabarti, Deepayan and Wang, Chenxi and Faloutsos, Christos},
booktitle = {22nd International Conference on Reliable Distributed Systems},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2003 - Epidemic Spreading in Real Networks An Eigenvalue Viewpoint.pdf:pdf},
title = {{Epidemic Spreading in Real Networks: An Eigenvalue Viewpoint}},
year = {2003}
}
@inproceedings{Dinh2012c,
author = {Dinh, Thang N. and Nguyen, D. T. and Thai, My T.},
booktitle = {23rd ACM Conference on Hypertext and Social Media},
title = {{Cheap, easy, and massively effective viral marketing in social networks: truth or fiction?}},
year = {2012}
}
@article{Dinh2013,
author = {Dinh, Thang N. and Zhang, Huiyuan and Nguyen, Dzung T. and Thai, My T.},
journal = {Transactions on Networking},
number = {6},
pages = {2001--2011},
title = {{Cost-Effective Viral Marketing for Time-Critical Campaigns in Large-Scale Social Networks}},
volume = {22},
year = {2013}
}
@inproceedings{Nguyen2010,
author = {Nguyen, N. P. and Xuan, Y. and Thai, M. T.},
booktitle = {Military Communications Conference},
pages = {2180--2185},
title = {{A novel method for worm containment on dynamic social networks}},
year = {2010}
}
@inproceedings{Nguyen2016a,
author = {Nguyen, H.T. and Thai, M. T. and Dinh, T. N.},
booktitle = {Proceedings of the 2016 International Conference on Management of Data (SIGMOD)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen, Thai, Dinh - 2016 - Stop-and-Stare Optimal Sampling Algorithms for Viral Marketing in Billion-Scale Networks.pdf:pdf},
title = {{Stop-and-Stare: Optimal Sampling Algorithms for Viral Marketing in Billion-Scale Networks}},
year = {2016}
}
@inproceedings{Nguyen2016,
author = {Nguyen, H. T. and Dinh, T. N. and Thai, M. T.},
booktitle = {IEEE International Conference on Computer Communications},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen, Dinh, Thai - 2016 - Cost-aware Targeted Viral Marketing in Billion-scale Networks.pdf:pdf},
title = {{Cost-aware Targeted Viral Marketing in Billion-scale Networks}},
year = {2016}
}
@inproceedings{Nguyen2011,
author = {Nguyen, Nam P. and Dinh, T. N. and Nguyen, D. T. and Thai, M. T.},
booktitle = {Privacy, Security, Risk, and Trust (PASSAT) and 2011 Third International Conference on Social Computing},
title = {{Overlapping community structures and their detection on social networks}},
year = {2011}
}
@article{Skowron2014,
author = {Skowron, Piotr and Faliszewski, Piotr},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Skowron, Faliszewski - 2014 - Fully Proportional Representation with Approval Ballots Approximating the MaxCover Problem with Bounded F.pdf:pdf},
keywords = {Multiagent Systems Track},
pages = {2124--2130},
title = {{Fully Proportional Representation with Approval Ballots : Approximating the MaxCover Problem with Bounded Frequencies in FPT Time}},
year = {2014}
}
@article{Belazzougui2016,
abstract = {We present a space- and time-efficient fully dynamic implementation de Bruijn graphs, which can also support fixed-length jumbled pattern matching.},
archivePrefix = {arXiv},
arxivId = {1607.04909},
author = {Belazzougui, Djamal and Gagie, Travis and M??kinen, Veli and Previtali, Marco},
doi = {10.1007/978-3-319-46049-9_14},
eprint = {1607.04909},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Belazzougui et al. - 2016 - Fully dynamic de Bruijn graphs.pdf:pdf},
isbn = {9783319460482},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {145--152},
title = {{Fully dynamic de Bruijn graphs}},
volume = {9954 LNCS},
year = {2016}
}
@article{Cicalese2015,
abstract = {Given a network represented by a weighted directed graph G, we consider the problem of finding a bounded cost set of nodes S such that the influence spreading from S in G, within a given time bound, is as large as possible. The dynamics that governs the spread of influence is the following: initially only elements in S are influenced; subsequently at each round, the set of influenced elements is augmented by all nodes in the network that have a sufficiently large number of already influenced neighbors. We prove that the problem is NP-hard, even in simple networks like complete graphs and trees. We also derive a series of positive results. We present exact pseudo-polynomial time algorithms for general trees, that become polynomial time in case the trees are unweighted. This last result improves on previously published results. We also design polynomial time algorithms for general weighted paths and cycles, and for unweighted complete graphs.},
archivePrefix = {arXiv},
arxivId = {1502.05599},
author = {Cicalese, Ferdinando and Cordasco, Gennaro and Gargano, Luisa and Milani{\v{c}}, Martin and Peters, Joseph and Vaccaro, Ugo},
doi = {10.1016/j.tcs.2015.02.032},
eprint = {1502.05599},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cicalese et al. - 2015 - Spread of influence in weighted networks under time and budget constraints.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Dynamic monopolies,Exact pseudo-polynomial time algorithms,Social networks,Spread of influence,Viral marketing},
pages = {40--58},
title = {{Spread of influence in weighted networks under time and budget constraints}},
volume = {586},
year = {2015}
}
@article{Fennell2016,
abstract = {Continuous-time Markov process models of contagions are widely studied, not least because of their utility in predicting the evolution of real-world contagions and in formulating control measures. It is often the case, however, that discrete-time approaches are employed to analyze such models or to simulate them numerically. In such cases, time is discretized into uniform steps and transition rates between states are replaced by transition probabilities. In this paper, we illustrate potential limitations to this approach. We show how discretizing time leads to a restriction on the values of the model parameters that can accurately be studied. We examine numerical simulation schemes employed in the literature, showing how synchronous-type updating schemes can bias discrete-time formalisms when compared against continuous-time formalisms. Event-based simulations, such as the Gillespie algorithm, are proposed as optimal simulation schemes both in terms of replicating the continuous-time process and computational speed. Finally, we show how discretizing time can affect the value of the epidemic threshold for large values of the infection rate and the recovery rate, even if the ratio between the former and the latter is small.},
archivePrefix = {arXiv},
arxivId = {1603.01132},
author = {Fennell, Peter G. and Melnik, Sergey and Gleeson, James P.},
doi = {10.1103/PhysRevE.94.052125},
eprint = {1603.01132},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fennell, Melnik, Gleeson - 2016 - Limitations of discrete-time approaches to continuous-time contagion dynamics.pdf:pdf},
issn = {15502376},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {5},
pages = {1--9},
title = {{Limitations of discrete-time approaches to continuous-time contagion dynamics}},
volume = {94},
year = {2016}
}
@article{Qin2016,
author = {Qin, Yadong and Ma, Jun and Gao, Shuai},
doi = {10.1007/s00500-016-2068-3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qin, Ma, Gao - 2016 - Efficient influence maximization under TSCM a suitable diffusion model in online social networks.pdf:pdf},
isbn = {0050001620},
issn = {14337479},
journal = {Soft Computing},
keywords = {Diffusion models,Influence maximization,Social networks,Three degrees of influence},
pages = {1--12},
publisher = {Springer Berlin Heidelberg},
title = {{Efficient influence maximization under TSCM: a suitable diffusion model in online social networks}},
year = {2016}
}
@article{Klaise2016,
abstract = {Trophic coherence, a measure of the extent to which the nodes of a directed network are organised in levels, has recently been shown to be closely related to many structural and dynamical aspects of complex systems, including graph eigenspectra, the prevalence or absence of feed-back cycles, and linear stability. Furthermore, non-trivial trophic structures have been observed in networks of neurons, species, genes, metabolites, cellular signalling, concatenated words, P2P users, and world trade. Here we consider two simple yet apparently quite different dynamical models -- one a Susceptible-Infected-Susceptible (SIS) epidemic model adapted to include complex contagion, the other an Amari-Hopfield neural network -- and show that in both cases the related spreading processes are modulated in similar ways by the trophic coherence of the underlying networks. To do this, we propose a network assembly model which can generate structures with tunable trophic coherence, limiting in either perfectly stratified networks or random graphs. We find that trophic coherence can exert a qualitative change in spreading behaviour, determining whether a pulse of activity will percolate through the entire network or remain confined to a subset of nodes, and whether such activity will quickly die out or endure indefinitely. These results could be important for our understanding of phenomena such as epidemics, rumours, shocks to ecosystems, neuronal avalanches, and many other spreading processes.},
archivePrefix = {arXiv},
arxivId = {1603.00670},
author = {Klaise, Janis and Johnson, Samuel},
doi = {10.1063/1.4953160},
eprint = {1603.00670},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Klaise, Johnson - 2016 - From neurons to epidemics How trophic coherence affects spreading processes.pdf:pdf},
issn = {10541500},
journal = {Chaos},
number = {6},
title = {{From neurons to epidemics: How trophic coherence affects spreading processes}},
url = {http://dx.doi.org/10.1063/1.4953160},
volume = {26},
year = {2016}
}
@article{Curato2016,
abstract = {We use the linear threshold model to study the diffusion of information on a network generated by the stochastic block model. We focus our analysis on a two community structure where the initial set of informed nodes lies only in one of the two communities and we look for optimal network structures, i.e. those maximizing the asymptotic extent of the diffusion. We find that, constraining the mean degree and the fraction of initially informed nodes, the optimal structure can be assortative (modular), core-periphery, or even disassortative. We then look for minimal cost structures, i.e. those such that a minimal fraction of initially informed nodes is needed to trigger a global cascade. We find that the optimal networks are assortative but with a structure very close to a core-periphery graph, i.e. a very dense community linked to a much more sparsely connected periphery.},
archivePrefix = {arXiv},
arxivId = {1605.08241},
author = {Curato, Gianbiagio and Lillo, Fabrizio},
doi = {10.1103/PhysRevE.94.032310},
eprint = {1605.08241},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Curato, Lillo - 2016 - Optimal information diffusion in stochastic block models.pdf:pdf},
issn = {15502376},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {3},
pages = {1--8},
title = {{Optimal information diffusion in stochastic block models}},
volume = {94},
year = {2016}
}
@article{Farajtabar2015,
abstract = {Information diffusion in online social networks is affected by the underlying network topology, but it also has the power to change it. Online users are constantly creating new links when exposed to new information sources, and in turn these links are alternating the way information spreads. However, these two highly intertwined stochastic processes, information diffusion and network evolution, have been predominantly studied separately, ignoring their co-evolutionary dynamics. We propose a temporal point process model, COEVOLVE, for such joint dynamics, allowing the intensity of one process to be modulated by that of the other. This model allows us to efficiently simulate interleaved diffusion and network events, and generate traces obeying common diffusion and network patterns observed in real-world networks. Furthermore, we also develop a convex optimization framework to learn the parameters of the model from historical diffusion and network evolution traces. We experimented with both synthetic data and data gathered from Twitter, and show that our model provides a good fit to the data as well as more accurate predictions than alternatives.},
archivePrefix = {arXiv},
arxivId = {1507.02293},
author = {Farajtabar, Mehrdad and Wang, Yichen and Rodriguez, Manuel Gomez and Li, Shuang and Zha, Hongyuan and Song, Le},
eprint = {1507.02293},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Farajtabar et al. - 2015 - COEVOLVE A Joint Point Process Model for Information Diffusion and Network Co-evolution.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {1--20},
title = {{COEVOLVE: A Joint Point Process Model for Information Diffusion and Network Co-evolution}},
url = {http://arxiv.org/abs/1507.02293},
year = {2015}
}
@article{Li2015a,
abstract = {Information flow in social network is assumed to be transmitted from node to node through the edges of network. In real world, however, people are influenced not only by local social neighbors but also by out-of-network services and sources, such as mass media and external websites. As a consequence, in addition to spreading by social edges, information can also reach a long-distance node by "jumping" cross the network. Then one of important issues coming out of the phenomenon is: how do these external services affect the diffusion process in social network? In this paper we develop an algorithm which allows us to distinguish the effects of external influence in diffusion process. By applying the algorithm to millions of diffusion cascades, we find that, although only a small portion of reshare activities arise from external influence directly, external influence plays a significant role in information diffusion. In particular, external influence affects nearly 50% to 70% of cascade node in average, and the effects become stronger as the cascade becomes larger. In addition, we characterize external influence as two categories, and show that one category mainly affects the size of diffusion tree and the other focuses on affecting the depth. Finally, we find that, due to the external services, the influentials become less important and more large cascades can be triggered by ordinary people. Together, these observations suggest new directions for modeling diffusion process and constructing more useful viral marketing strategy.},
author = {Li, Jiang and Xiong, Jiagui and Wang, Xiaojie},
doi = {10.1109/MDM.2015.30},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Xiong, Wang - 2015 - Measuring the External Influence in Information Diffusion.pdf:pdf},
isbn = {9781479999729},
issn = {15516245},
journal = {Proceedings - IEEE International Conference on Mobile Data Management},
pages = {92--97},
title = {{Measuring the External Influence in Information Diffusion}},
volume = {2},
year = {2015}
}
@article{OSullivan2015,
abstract = {BACKGROUND: The spreading of behavior, such as the adoption of a new innovation, is influenced by the structure of social networks that interconnect the population. In the experiments of Centola [15], adoption of new behavior was shown to spread further and faster across clustered-lattice networks than across corresponding random networks. This implies that the “complex contagion” effects of social reinforcement are important in such diffusion, in contrast to “simple” contagion models of disease-spread which predict that epidemics would grow more efficiently on random networks than on clustered networks. To accurately model complex contagion on clustered networks remains a challenge because the usual assumptions (e.g., of mean-field theory) regarding tree-like networks are invalidated by the presence of triangles in the network; the triangles are, however, crucial to the social reinforcement mechanism, which posits an increased probability of a person adopting behavior that has been adopted by two or more neighbors. In this paper we modify the analytical approach that was introduced by H{\'{e}}bert-Dufresne et al. [19], to study disease-spread on clustered networks. We show how the approximation method can be adapted to a complex contagion model, and confirm the accuracy of the method with numerical simulations. The analytical results of the model enable us to quantify the level of social reinforcement that is required to observe—as in Centola's experiments—faster diffusion on clustered topologies than on random networks.},
author = {O'Sullivan, David J. P. and O'Keeffe, Gary James and Fennell, Peter G and Gleeson, James P},
doi = {10.3389/fphy.2015.00071},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/O'Sullivan et al. - 2015 - Mathematical modeling of complex contagion on clustered networks.pdf:pdf},
isbn = {2296-424X},
issn = {2296-424X},
journal = {Frontiers in Physics},
keywords = {clique approximation,clique netw,clique networks,clustered networks,complex contagion,diffusion of behavior,social reinforcement},
number = {September},
title = {{Mathematical modeling of complex contagion on clustered networks}},
url = {http://www.frontiersin.org/Journal/Abstract.aspx?s=1433&name=interdisciplinary_physics&ART_DOI=10.3389/fphy.2015.00071%5Cnhttp://journal.frontiersin.org/Article/10.3389/fphy.2015.00071/abstract},
volume = {3},
year = {2015}
}
@misc{,
title = {{CSoNet - International Conference on Computational Social Networks}},
url = {http://optnetsci.cise.ufl.edu/CSoNet/}
}
@misc{,
title = {{WIDN 2015}},
url = {http://optnetsci.cise.ufl.edu/widn2015/}
}
@article{Mendis2016a,
author = {Mendis, J},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mendis - 2016 - Real-time Detection of False Data Injection Attacks in Smart Grid A Deep Learning-Based Intelligent Mechanism(2).pdf:pdf},
title = {{Real-time Detection of False Data Injection Attacks in Smart Grid: A Deep Learning-Based Intelligent Mechanism}},
year = {2016}
}
@misc{Bodik2004,
author = {Bodik, Peter and Hong, Wei and Guestrin, Carlos and Madden, Sam and Paskin, Mark and Thibaux, Romain},
title = {{Intel Lab Data}},
urldate = {2017-01-06},
year = {2004}
}
@inproceedings{Barsocchi2007,
author = {Barsocchi, Paolo and Oligeri, Gabriele and Potorti, Francesco},
booktitle = {International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks and Workshops},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barsocchi, Oligeri, Potorti - 2007 - Frame error model in rural Wi-Fi networks.pdf:pdf},
title = {{Frame error model in rural Wi-Fi networks}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4480105},
year = {2007}
}
@inproceedings{Kuhnle2017j,
author = {Kuhnle, Alan and Pan, Tianyi and Alim, Md Abdul and Thai, My T.},
booktitle = {IEEE International Conference on Computer Communications (INFOCOM)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhnle et al. - 2017 - Scalable Bicriteria Algorithms for the Threshold Activation Problem in Online Social Networks.pdf:pdf},
title = {{Scalable Bicriteria Algorithms for the Threshold Activation Problem in Online Social Networks}},
year = {2017}
}
@article{Battiston2014,
abstract = {Many real-world complex systems consist of a set of elementary units connected by relationships of different kinds. All such systems are better described in terms of multiplex networks, where the links at each layer represent a different type of interaction between the same set of nodes, rather than in terms of (single-layer) networks. In this paper we present a general framework to describe and study multiplex networks, whose links are either unweighted or weighted. In particular we propose a series of measures to characterize the multiplexicity of the systems in terms of: i) basic node and link properties such as the node degree, and the edge overlap and reinforcement, ii) local properties such as the clustering coefficient and the transitivity, iii) global properties related to the navigability of the multiplex across the different layers. The measures we introduce are validated on a genuine multiplex data set of Indonesian terrorists, where information among 78 individuals are recorded with respect to mutual trust, common operations, exchanged communications and business relationships.},
archivePrefix = {arXiv},
arxivId = {1308.3182},
author = {Battiston, Federico and Nicosia, Vincenzo and Latora, Vito},
doi = {10.1103/PhysRevE.89.032804},
eprint = {1308.3182},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Battiston, Nicosia, Latora - 2014 - Structural measures for multiplex networks.pdf:pdf},
issn = {15502376},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {3},
pages = {1--14},
pmid = {24730896},
title = {{Structural measures for multiplex networks}},
volume = {89},
year = {2014}
}
@article{Caldarelli2004,
abstract = {We study the properties of quantities aimed at the characterization of grid-like ordering in complex networks. These quantities are based on the global and local behavior of cycles of order four, which are the minimal structures able to identify rectangular clustering. The analysis of data from real networks reveals the ubiquitous presence of a statistically high level of grid-like ordering that is non-trivially correlated with the local degree properties. These observations provide new insights on the hierarchical structure of complex networks},
archivePrefix = {arXiv},
arxivId = {cond-mat/0212026},
author = {Caldarelli, G. and Pastor-Satorras, R. and Vespignani, A.},
doi = {10.1140/epjb/e2004-00020-6},
eprint = {0212026},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Caldarelli, Pastor-Satorras, Vespignani - 2004 - Structure of cycles and local ordering in complex networks.pdf:pdf},
isbn = {1434-6028},
issn = {14346028},
journal = {European Physical Journal B},
number = {2},
pages = {183--186},
pmid = {221447300007},
primaryClass = {cond-mat},
title = {{Structure of cycles and local ordering in complex networks}},
volume = {38},
year = {2004}
}
@article{Watts1998,
abstract = {Networks of coupled dynamical systems have been used to model biological oscillators(1-4), Josephson junction arrays(5,6), excitable media(7), neural networks(8-10), spatial games(11), genetic control networks(12) and many other self-organizing systems. Ordinarily, the connection topology is assumed to be either completely regular or completely random. But many biological, technological and social networks lie somewhere between these two extremes. Here we explore simple models of networks that can be tuned through this middle ground: regular networks 'rewired' to introduce increasing amounts of disorder. We find that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs. We call them 'small-world' networks, by analogy with the small-world phenomenon(13,14) (popularly known as six degrees of separation(15)). The neural network of the worm Caenorhabditis elegans, the power grid of the western United States, and the collaboration graph of film actors are shown to be small-world networks. Models of dynamical systems with small-world coupling display enhanced signal-propagation speed, computational power, and synchronizability. In particular, infectious diseases spread more easily in small-world networks than in regular lattices.},
archivePrefix = {arXiv},
arxivId = {0803.0939v1},
author = {Watts, D J and Strogatz, S H},
doi = {Doi 10.1038/30918},
eprint = {0803.0939v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Watts, Strogatz - 1998 - Collective dynamics of'small-world' networks.pdf:pdf},
isbn = {0028-0836},
issn = {0028-0836},
journal = {Nature},
keywords = {chaos,disease,pulse-coupled oscillators,spread,synchronization},
number = {6684},
pages = {440--442},
pmid = {9623998},
title = {{Collective dynamics of'small-world' networks}},
volume = {393},
year = {1998}
}
@article{Onnela2005,
abstract = {The local structure of unweighted networks can be characterized by the number of times a subgraph appears in the network. The clustering coefficient, reflecting the local configuration of triangles, can be seen as a special case of this approach. In this paper we generalize this method for weighted networks. We introduce subgraph "intensity" as the geometric mean of its link weights "coherence" as the ratio of the geometric to the corresponding arithmetic mean. Using these measures, motif scores and clustering coefficient can be generalized to weighted networks. To demonstrate these concepts, we apply them to financial and metabolic networks and find that inclusion of weights may considerably modify the conclusions obtained from the study of unweighted characteristics.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0408629},
author = {Onnela, Jukka Pekka and Saram{\"{a}}ki, Jari and Kert{\'{e}}sz, J{\'{a}}nos and Kaski, Kimmo},
doi = {10.1103/PhysRevE.71.065103},
eprint = {0408629},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Onnela et al. - 2005 - Intensity and coherence of motifs in weighted complex networks.pdf:pdf},
isbn = {1539-3755},
issn = {15393755},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {6},
pages = {1--4},
pmid = {16089800},
primaryClass = {cond-mat},
title = {{Intensity and coherence of motifs in weighted complex networks}},
volume = {71},
year = {2005}
}
@article{Radicchi2004,
abstract = {The investigation of community structures in networks is an important issue in many domains and disciplines. This problem is relevant for social tasks (objective analysis of relationships on the web), biological inquiries (functional studies in metabolic and protein networks), or technological problems (optimization of large infrastructures). Several types of algorithms exist for revealing the community structure in networks, but a general and quantitative definition of community is not implemented in the algorithms, leading to an intrinsic difficulty in the interpretation of the results without any additional nontopological information. In this article we deal with this problem by showing how quantitative definitions of community are implemented in practice in the existing algorithms. In this way the algorithms for the identification of the community structure become fully self-contained. Furthermore, we propose a local algorithm to detect communities which outperforms the existing algorithms with respect to computational cost, keeping the same level of reliability. The algorithm is tested on artificial and real-world graphs. In particular, we show how the algorithm applies to a network of scientific collaborations, which, for its size, cannot be attacked with the usual methods. This type of local algorithm could open the way to applications to large-scale technological and biological systems.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0309488},
author = {Radicchi, Filippo and Castellano, Claudio and Cecconi, Federico and Loreto, Vittorio and Parisi, Domenico},
doi = {10.1073/pnas.0400054101},
eprint = {0309488},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Radicchi et al. - 2004 - Defining and identifying communities in networks.pdf:pdf},
isbn = {0027-8424 (Print)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {9},
pages = {2658--2663},
pmid = {14981240},
primaryClass = {cond-mat},
title = {{Defining and identifying communities in networks.}},
volume = {101},
year = {2004}
}
@article{Badham2010,
abstract = {Epidemic models have successfully included many aspects of the complex contact structure apparent in real-world populations. However, it is difficult to accommodate variations in the number of contacts, clustering coefficient and assortativity. Investigations of the relationship between these properties and epidemic behaviour have led to inconsistent conclusions and have not accounted for their interrelationship. In this study, simulation is used to estimate the impact of social network structure on the probability of an SIR (susceptible-infective-removed) epidemic occurring and, if it does, the final size. Increases in assortativity and clustering coefficient are associated with smaller epidemics and the impact is cumulative. Derived values of the basic reproduction ratio (R0) over networks with the highest property values are more than 20% lower than those derived from simulations with zero values of these network properties. ?? 2009 Elsevier Inc. All rights reserved.},
author = {Badham, Jennifer and Stocker, Rob},
doi = {10.1016/j.tpb.2009.11.003},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Badham, Stocker - 2010 - The impact of network clustering and assortativity on epidemic behaviour.pdf:pdf},
isbn = {1096-0325 (Electronic)\r0040-5809 (Linking)},
issn = {00405809},
journal = {Theoretical Population Biology},
keywords = {Assortativity,Clustering coefficient,Disease spread,Social networks,Transmission networks},
number = {1},
pages = {71--75},
pmid = {19948179},
publisher = {Elsevier Inc.},
title = {{The impact of network clustering and assortativity on epidemic behaviour}},
url = {http://dx.doi.org/10.1016/j.tpb.2009.11.003},
volume = {77},
year = {2010}
}
@article{Candellero2012a,
abstract = {In this paper we model user behaviour in Twitter to capture the emergence of trending topics. For this purpose, we first extensively analyse tweet datasets of several different events. In particular, for these datasets, we construct and investigate the retweet graphs. We find that the retweet graph for a trending topic has a relatively dense largest connected component (LCC). Next, based on the insights obtained from the analyses of the datasets, we design a mathematical model that describes the evolution of a retweet graph by three main parameters. We then quantify, analytically and by simulation, the influence of the model parameters on the basic characteristics of the retweet graph, such as the density of edges and the size and density of the LCC. Finally, we put the model in practice, estimate its parameters and compare the resulting behavior of the model to our datasets.},
archivePrefix = {arXiv},
arxivId = {1502.00166},
author = {Candellero, Elisabetta},
doi = {10.1007/978-3-642-30541-2},
eprint = {1502.00166},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Candellero - 2012 - Algorithms and Models for the Web Graph(2).pdf:pdf},
isbn = {978-3-642-30540-5},
issn = {0302-9743},
journal = {Waw},
keywords = {link prediction},
pages = {54--65},
title = {{Algorithms and Models for the Web Graph}},
url = {http://dblp.uni-trier.de/db/conf/waw/waw2012.html#AvrachenkovLST12},
volume = {7323},
year = {2012}
}
@article{Huang2015a,
abstract = {Most community detection methods use network topology and edge density to identify optimal communities. However, in these methods, several objects that are connected by high weights may be decomposed into different communities, even when they intuitively belong to a single community. In this case, it is more effective to classify the objects into the same community because they perform important roles in controlling and understanding the network. To achieve this goal, in this paper, we propose a method of detecting optimal community structures in a complex network using interaction-based edge clustering. Our approach is to consider network topology as well as interaction density when identifying overlapping and hierarchical communities. Additionally, we measure the differences between the quantity and quality of intra- and inter-community interactions to evaluate the quality of the community structure. We test our method on several benchmark networks with known community structures. Additionally, after applying our method to several real-world complex networks, we evaluate our method through comparison with other methods. We find that the community quality and the overlap quality for our method surpass the results of the other methods.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Huang, Zhenhua and Wang, Zhenyu and Zhang, Zhiwei},
doi = {10.1007/978-981-10-0080-5_17},
eprint = {arXiv:1011.1669v3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Wang, Zhang - 2015 - Detecting overlapping and hierarchical communities in complex network based on maximal cliques.pdf:pdf},
isbn = {9789811000799},
issn = {18650929},
journal = {Communications in Computer and Information Science},
keywords = {Community detection,Fitness function,Hierarchical,Maximal cliques,Overlapping},
pages = {184--191},
pmid = {17410175},
publisher = {Elsevier B.V.},
title = {{Detecting overlapping and hierarchical communities in complex network based on maximal cliques}},
url = {http://dx.doi.org/10.1016/j.physa.2014.09.035},
volume = {568},
year = {2015}
}
@article{Nocaj2016,
abstract = {Small-world networks have characteristically low pairwise shortest-path distances, causing distance-based layout methods to generate hairball drawings. Recent approaches thus aim at finding a sparser representation of the graph to amplify variations in pairwise distances. Since the effect of sparsification on the layout is difficult to describe analytically, the incorporated filtering parameters of these approaches typically have to be selected manually and individually for each input instance. We here propose the use of graph invariants to determine suitable parameters automatically. This allows us to perform adaptive filtering to obtain drawings in which the cluster structure is most prominent. The approach is based on an empirical relationship between input and output characteristics that is derived from real and synthetic networks. Experimental evaluation shows the effectiveness of our approach and suggests that it can be used by default to increase the robustness of force-directed layout methods.},
author = {Nocaj, Arlind and Ortmann, Mark and Brandes, Ulrik},
doi = {10.1109/TVCG.2016.2534559},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nocaj, Ortmann, Brandes - 2016 - Adaptive Disentanglement Based on Local Clustering in Small-World Network Visualization.pdf:pdf},
isbn = {1077-2626},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Adaptive Edge Filtering,Automatic Parameter Selection,Force-directed Layout,Graph Simplification,Network Visualization,Small-World Networks},
number = {6},
pages = {1662--1671},
title = {{Adaptive Disentanglement Based on Local Clustering in Small-World Network Visualization}},
volume = {22},
year = {2016}
}
@article{Serrano2006,
abstract = {We develop a full theoretical approach to clustering in complex networks. A key concept is introduced, the edge multiplicity, that measures the number of triangles passing through an edge. This quantity extends the clustering coefficient in that it involves the properties of two-and not just one-vertices. The formalism is completed with the definition of a three-vertex correlation function, which is the fundamental quantity describing the properties of clustered networks. The formalism suggests different metrics that are able to thoroughly characterize transitive relations. A rigorous analysis of several real networks, which makes use of this formalism and the metrics, is also provided. It is also found that clustered networks can be classified into two main groups: the weak and the strong transitivity classes. In the first class, edge multiplicity is small, with triangles being disjoint. In the second class, edge multiplicity is high and so triangles share many edges. As we shall see in the following paper, the class a network belongs to has strong implications in its percolation properties.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0608336},
author = {Serrano, M. {\'{A}}ngeles and Bogun{\'{a}}, Mari{\'{a}}n},
doi = {10.1103/PhysRevE.74.056114},
eprint = {0608336},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Serrano, Bogun{\'{a}} - 2006 - Clustering in complex networks. I. General formalism.pdf:pdf},
isbn = {1539-3755},
issn = {15393755},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {5},
pages = {1--9},
pmid = {17279975},
primaryClass = {cond-mat},
title = {{Clustering in complex networks. I. General formalism}},
volume = {74},
year = {2006}
}
@article{OstroumovaProkhorenkova2016a,
author = {{Ostroumova Prokhorenkova}, Liudmila},
doi = {10.1007/s11590-016-1030-8},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ostroumova Prokhorenkova - 2016 - General results on preferential attachment and clustering coefficient.pdf:pdf},
issn = {18624480},
journal = {Optimization Letters},
keywords = {Clustering coefficient,Networks,Power-law degree distribution,Preferential attachment,Random graph models},
pages = {1--20},
publisher = {Springer Berlin Heidelberg},
title = {{General results on preferential attachment and clustering coefficient}},
year = {2016}
}
@article{OstroumovaProkhorenkova2016,
author = {{Ostroumova Prokhorenkova}, Liudmila},
doi = {10.1080/15427951.2015.1092482},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ostroumova Prokhorenkova - 2016 - Global Clustering Coefficient in Scale-Free Weighted and Unweighted Networks.pdf:pdf},
issn = {1542-7951},
journal = {Internet Mathematics},
number = {1-2},
pages = {54--67},
title = {{Global Clustering Coefficient in Scale-Free Weighted and Unweighted Networks}},
url = {http://www.tandfonline.com/doi/full/10.1080/15427951.2015.1092482},
volume = {12},
year = {2016}
}
@article{AngelesSerrano2005,
abstract = {We present a generator of random networks where both the degree-dependent clustering coefficient and the degree distribution are tunable. Following the same philosophy as in the configuration model, the degree distribution and the clustering coefficient for each class of nodes of degree k are fixed ad hoc and a priori. The algorithm generates corresponding topologies by applying first a closure of triangles and second the classical closure of remaining free stubs. The procedure unveils an universal relation among clustering and degree-degree correlations for all networks, where the level of assortativity establishes an upper limit to the level of clustering. Maximum assortativity ensures no restriction on the decay of the clustering coefficient whereas disassortativity sets a stronger constraint on its behavior. Correlation measures in real networks are seen to observe this structural bound.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0507535},
author = {{{\'{A}}ngeles Serrano}, M. and Bogu{\~{n}}{\'{a}}, Mari{\'{a}}n},
doi = {10.1103/PhysRevE.72.036133},
eprint = {0507535},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/{\'{A}}ngeles Serrano, Bogu{\~{n}}{\'{a}} - 2005 - Tuning clustering in random networks with arbitrary degree distributions.pdf:pdf},
issn = {15393755},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {3},
pages = {1--8},
pmid = {16241541},
primaryClass = {cond-mat},
title = {{Tuning clustering in random networks with arbitrary degree distributions}},
volume = {72},
year = {2005}
}
@article{Phan2013,
abstract = {Measures that estimate the clustering coefficients of ego and overall social networks are important to social network studies. Existing measures differ in how they define and estimate triplet clustering with implications for how network theoretic properties are reflected. In this paper, we propose a novel definition of triplet clustering for weighted and undirected social networks that explicitly considers the relative strength of the tie connecting the two alters of the ego in the triplet. We argue that our proposed definition better reflects theorized effects of the important third tie in the social network literature. We also develop new methods for estimating triplet, local and global clustering. Three different types of mathematical means, i.e. arithmetic, geometric, and quadratic, are used to reflect alternative theoretical assumptions concerning the marginal effect of tie substitution. ?? 2013 Elsevier B.V.},
author = {Phan, Binh and Eng??-Monsen, Kenth and Fjeldstad, ??ystein D.},
doi = {10.1016/j.socnet.2013.02.007},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phan, Eng-Monsen, Fjeldstad - 2013 - Considering clustering measures Third ties, means, and triplets.pdf:pdf},
isbn = {0378-8733, 0378-8733},
issn = {03788733},
journal = {Social Networks},
keywords = {Clustering measure,Network clustering,Social network,Tie strength,Triplet clustering},
number = {3},
pages = {300--308},
publisher = {Elsevier B.V.},
title = {{Considering clustering measures: Third ties, means, and triplets}},
url = {http://dx.doi.org/10.1016/j.socnet.2013.02.007},
volume = {35},
year = {2013}
}
@article{Candellero2012,
abstract = {In this paper we model user behaviour in Twitter to capture the emergence of trending topics. For this purpose, we first extensively analyse tweet datasets of several different events. In particular, for these datasets, we construct and investigate the retweet graphs. We find that the retweet graph for a trending topic has a relatively dense largest connected component (LCC). Next, based on the insights obtained from the analyses of the datasets, we design a mathematical model that describes the evolution of a retweet graph by three main parameters. We then quantify, analytically and by simulation, the influence of the model parameters on the basic characteristics of the retweet graph, such as the density of edges and the size and density of the LCC. Finally, we put the model in practice, estimate its parameters and compare the resulting behavior of the model to our datasets.},
archivePrefix = {arXiv},
arxivId = {1502.00166},
author = {Candellero, Elisabetta},
doi = {10.1007/978-3-642-30541-2},
eprint = {1502.00166},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Candellero - 2012 - Algorithms and Models for the Web Graph.pdf:pdf},
isbn = {978-3-642-30540-5},
issn = {0302-9743},
journal = {Waw},
keywords = {link prediction},
pages = {54--65},
title = {{Algorithms and Models for the Web Graph}},
url = {http://dblp.uni-trier.de/db/conf/waw/waw2012.html#AvrachenkovLST12},
volume = {7323},
year = {2012}
}
@article{Xue-Qi2010,
abstract = {Edges in a network can be divided into two kinds according to their different roles: some enhance the locality like the ones inside a cluster while others contribute to the global connectivity like the ones connecting two clusters. A recent study by Onnela et al uncovered the weak ties effects in mobile communication. In this paper, we provide complementary results on document networks, that is, the edges connecting less similar nodes in content are more significant in maintaining the global connectivity. We propose an index called bridgeness to quantify the edge significance in maintaining connectivity, which only depends on local information of the network topology. We compare the bridgeness with content similarity and some other structural indices according to an edge percolation process. Experimental results on document networks show that the bridgeness outperforms content similarity in characterizing the edge significance. Furthermore, extensive numerical results on disparate networks indicate that the bridgeness is also better than some well-known indices on edge significance, including the Jaccard coefficient, degree product and betweenness centrality.},
archivePrefix = {arXiv},
arxivId = {1005.2652},
author = {Xue-Qi, Cheng and Fu-Xin, Ren and Hua-Wei, Shen and Zi-Ke, Zhang and Tao, Zhou},
doi = {10.1088/1742-5468/2010/10/P10011},
eprint = {1005.2652},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xue-Qi et al. - 2010 - Bridgeness a local index on edge significance in maintaining global connectivity.pdf:pdf},
isbn = {1742-5468},
issn = {1742-5468},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
number = {10},
pages = {P10011},
title = {{Bridgeness: a local index on edge significance in maintaining global connectivity}},
url = {http://stacks.iop.org/1742-5468/2010/i=10/a=P10011%5Cnhttp://iopscience.iop.org/1742-5468/2010/10/P10011/pdf/1742-5468_2010_10_P10011.pdf},
volume = {2010},
year = {2010}
}
@article{Soffer2005,
abstract = {The clustering coefficient quantifies how well connected are the neighbors of a vertex in a graph. In real networks it decreases with the vertex degree, which has been taken as a signature of the network hierarchical structure. Here we show that this signature of hierarchical structure is a consequence of degree-correlation biases in the clustering coefficient definition. We introduce a definition in which the degree-correlation biases are filtered out, and provide evidence that in real networks the clustering coefficient is constant or decays logarithmically with vertex degree.},
author = {Soffer, Sara Nadiv and V{\'{a}}zquez, Alexei},
doi = {10.1103/PhysRevE.71.057101},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soffer, V{\'{a}}zquez - 2005 - Network clustering coefficient without degree-correlation biases.pdf:pdf},
isbn = {1539-3755 1550-2376},
issn = {15393755},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {5},
pages = {2--5},
pmid = {16089694},
title = {{Network clustering coefficient without degree-correlation biases}},
volume = {71},
year = {2005}
}
@article{Chen2013,
abstract = {Identifying influential nodes in very large-scale directed networks is a big challenge relevant to disparate applications, such as accelerating information propagation, controlling rumors and diseases, designing search engines, and understanding hierarchical organization of social and biological networks. Known methods range from node centralities, such as degree, closeness and betweenness, to diffusion-based processes, like PageRank and LeaderRank. Some of these methods already take into account the influences of a node's neighbors but do not directly make use of the interactions among it's neighbors. Local clustering is known to have negative impacts on the information spreading. We further show empirically that it also plays a negative role in generating local connections. Inspired by these facts, we propose a local ranking algorithm named ClusterRank, which takes into account not only the number of neighbors and the neighbors' influences, but also the clustering coefficient. Subject to the susceptible-infected-recovered (SIR) spreading model with constant infectivity, experimental results on two directed networks, a social network extracted from delicious.com and a large-scale short-message communication network, demonstrate that the ClusterRank outperforms some benchmark algorithms such as PageRank and LeaderRank. Furthermore, ClusterRank can also be applied to undirected networks where the superiority of ClusterRank is significant compared with degree centrality and k-core decomposition. In addition, ClusterRank, only making use of local information, is much more efficient than global methods: It takes only 191 seconds for a network with about [Formula: see text] nodes, more than 15 times faster than PageRank.},
author = {Chen, Duan Bing and Gao, Hui and L{\"{u}}, Linyuan and Zhou, Tao},
doi = {10.1371/journal.pone.0077455},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2013 - Identifying influential nodes in large-scale directed networks The role of clustering.pdf:pdf},
isbn = {1932-6203},
issn = {19326203},
journal = {PLoS ONE},
number = {10},
pages = {1--10},
pmid = {24204833},
title = {{Identifying influential nodes in large-scale directed networks: The role of clustering}},
volume = {8},
year = {2013}
}
@article{Foster2011,
abstract = {Clustering, assortativity, and communities are key features of complex networks. We probe dependencies between these attributes and find that ensembles with strong clustering display both high assortativity by degree and prominent community structure, while ensembles with high assortativity are much less biased towards clustering or community structure. Further, clustered networks can amplify small homophilic bias for trait assortativity. This marked asymmetry suggests that transitivity, rather than homophily, drives the standard nonsocial/social network dichotomy.},
archivePrefix = {arXiv},
arxivId = {1012.2384},
author = {Foster, David V. and Foster, Jacob G. and Grassberger, Peter and Paczuski, Maya},
doi = {10.1103/PhysRevE.84.066117},
eprint = {1012.2384},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Foster et al. - 2011 - Clustering drives assortativity and community structure in ensembles of networks.pdf:pdf},
issn = {15393755},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {6},
pages = {1--5},
title = {{Clustering drives assortativity and community structure in ensembles of networks}},
volume = {84},
year = {2011}
}
@article{Nascimento2014,
abstract = {The community detection problem in networks consists of determining a clustering of "related" vertices in a graph or network. Nowadays, studies involving this problem are primarily composed of modularity maximization based heuristics. In this paper, the author proposes a spectral heuristic based on a measure known as clustering coefficient to detect communities in networks. This measure favors clusterings with a strong neighborhood structure inside clusters, apparently, overcoming the scale deficiency of the modularity maximization problem. The computational experiments indicate a very successful performance by the proposed heuristic in comparison with other community detection heuristics in the literature. ?? 2014 Elsevier B.V. All rights reserved.},
author = {Nascimento, Mari{\'{a}} C V},
doi = {10.1016/j.dam.2013.09.017},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nascimento - 2014 - Community detection in networks via a spectral heuristic based on the clustering coefficient.pdf:pdf},
issn = {0166218X},
journal = {Discrete Applied Mathematics},
keywords = {Clustering coefficient,Community detection in networks,Graph clustering,Spectral heuristic,Unweighted graphs},
pages = {89--99},
publisher = {Elsevier B.V.},
title = {{Community detection in networks via a spectral heuristic based on the clustering coefficient}},
url = {http://dx.doi.org/10.1016/j.dam.2013.09.017},
volume = {176},
year = {2014}
}
@article{Opsahl2013,
abstract = {As the vast majority of network measures are defined for one-mode networks, two-mode networks often have to be projected onto one-mode networks to be analyzed. A number of issues arise in this transformation process, especially when analyzing ties among nodes' contacts. For example, the values attained by the global and local clustering coefficients on projected random two-mode networks deviate from the expected values in corresponding classical one-mode networks. Moreover, both the local clustering coefficient and constraint (structural holes) are inversely associated to nodes' two-mode degree. To overcome these issues, this paper proposes redefinitions of the clustering coefficients for two-mode networks. ?? 2011 Elsevier B.V.},
archivePrefix = {arXiv},
arxivId = {1006.0887},
author = {Opsahl, Tore},
doi = {10.1016/j.socnet.2011.07.001},
eprint = {1006.0887},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Opsahl - 2013 - Triadic closure in two-mode networks Redefining the global and local clustering coefficients.pdf:pdf},
isbn = {0378-8733},
issn = {03788733},
journal = {Social Networks},
keywords = {Clustering coefficient,Random networks,Triadic closure,Two-mode networks},
number = {2},
pages = {159--167},
pmid = {25246403},
publisher = {Elsevier B.V.},
title = {{Triadic closure in two-mode networks: Redefining the global and local clustering coefficients}},
url = {http://dx.doi.org/10.1016/j.socnet.2011.07.001},
volume = {35},
year = {2013}
}
@article{Opsahl2009,
abstract = {In recent years, researchers have investigated a growing number of weighted networks where ties are differentiated according to their strength or capacity. Yet, most network measures do not take weights into consideration, and thus do not fully capture the richness of the information contained in the data. In this paper, we focus on a measure originally defined for unweighted networks: the global clustering coefficient. We propose a generalization of this coefficient that retains the information encoded in the weights of ties. We then undertake a comparative assessment by applying the standard and generalized coefficients to a number of network datasets. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:1006.0887},
author = {Opsahl, Tore and Panzarasa, Pietro},
doi = {10.1016/j.socnet.2009.02.002},
eprint = {arXiv:1006.0887},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Opsahl, Panzarasa - 2009 - Clustering in weighted networks.pdf:pdf},
isbn = {0378-8733},
issn = {03788733},
journal = {Social Networks},
keywords = {Clustering,Transitivity,Weighted networks},
number = {2},
pages = {155--163},
title = {{Clustering in weighted networks}},
volume = {31},
year = {2009}
}
@article{Lind2005,
abstract = {We investigate the clustering coefficient in bipartite networks where cycles of size three are absent and therefore the standard definition of clustering coefficient cannot be used. Instead, we use another coefficient given by the fraction of cycles with size four, showing that both coefficients yield the same clustering properties. The new coefficient is computed for two networks of sexual contacts, one bipartite and another where no distinction between the nodes is made (monopartite). In both cases the clustering coefficient is similar. Furthermore, combining both clustering coefficients we deduce an expression for estimating cycles of larger size, which improves previous estimations and is suitable for either monopartite and multipartite networks, and discuss the applicability of such analytical estimations.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0504241},
author = {Lind, Pedro G. and Gonz{\~{a}}lez, Marta C. and Herrmann, Hans J.},
doi = {10.1103/PhysRevE.72.056127},
eprint = {0504241},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lind, Gonz{\~{a}}lez, Herrmann - 2005 - Cycles and clustering in bipartite networks.pdf:pdf},
issn = {15393755},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {5},
pages = {1--9},
pmid = {16383708},
primaryClass = {cond-mat},
title = {{Cycles and clustering in bipartite networks}},
volume = {72},
year = {2005}
}
@article{Zhang2008,
abstract = {Many real-world networks display natural bipartite structure, where the basic cycle is a square. In this paper, with the similar consideration of standard clustering coefficient in binary networks, a definition of the clustering coefficient for bipartite networks based on the fraction of squares is proposed. In order to detect community structures in bipartite networks, two different edge clustering coefficients L C4 and L C3 of bipartite networks are defined, which are based on squares and triples respectively. With the algorithm of cutting the edge with the least clustering coefficient, communities in artificial and real world networks are identified. The results reveal that investigating bipartite networks based on the original structure can show the detailed properties that is helpful to get deep understanding about the networks. ?? 2008 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {0710.0117},
author = {Zhang, Peng and Wang, Jinliang and Li, Xiaojia and Li, Menghui and Di, Zengru and Fan, Ying},
doi = {10.1016/j.physa.2008.09.006},
eprint = {0710.0117},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2008 - Clustering coefficient and community structure of bipartite networks.pdf:pdf},
isbn = {0378-4371},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {Bipartite network,Clustering coefficient,Community structure},
number = {27},
pages = {6869--6875},
publisher = {Elsevier B.V.},
title = {{Clustering coefficient and community structure of bipartite networks}},
url = {http://dx.doi.org/10.1016/j.physa.2008.09.006},
volume = {387},
year = {2008}
}
@article{Bitam2013,
abstract = {A vehicular ad hoc network (VANET) is a subclass of mobile ad hoc networks, considered as one of the most important approach of intelligent transportation systems (ITS). It allows inter-vehicle communication in which their movement is restricted by a VANET mobility model and supported by some roadside base stations as fixed infrastructures. Multicasting provides different traffic information to a limited number of vehicle drivers by a parallel transmission. However, it represents a very important challenge in the application of vehicular ad hoc networks especially, in the case of the network scalability. In the applications of this sensitive field, it is very essential to transmit correct data anywhere and at any time. Consequently, the VANET routing protocols should be adapted appropriately and meet effectively the quality of service (QoS) requirements in an optimized multicast routing. In this paper, we propose a novel bee colony optimization algorithm called bees life algorithm (BLA) applied to solve the quality of service multicast routing problem (QoS-MRP) for vehicular ad hoc networks as NP-Complete problem with multiple constraints. It is considered as swarm-based algorithm which imitates closely the life of the colony. It follows the two important behaviors in the nature of bees which are the reproduction and the food foraging. BLA is applied to solve QoS-MRP with four objectives which are cost, delay, jitter, and bandwidth. It is also submitted to three constraints which are maximum allowed delay, maximum allowed jitter and minimum requested bandwidth. In order to evaluate the performance and the effectiveness of this realized proposal using C++ and integrated at the routing protocol level, a simulation study has been performed using the network simulator (NS2) based on a mobility model of VANET. The comparisons of the experimental results show that the proposed algorithm outperformed in an efficient way genetic algorithm (GA), bees algorithm (BA) and marriage in honey bees optimization (MBO) algorithm as state-of-the-art conventional metaheuristics applied to QoS-MRP problem with the same simulation parameters. ?? 2013 Published by Elsevier Ltd.},
author = {Bitam, Salim and Mellouk, Abdelhamid},
doi = {10.1016/j.jnca.2012.01.023},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bitam, Mellouk - 2013 - Bee life-based multi constraints multicast routing optimization for vehicular ad hoc networks.pdf:pdf},
isbn = {10848045 (ISSN)},
issn = {10848045},
journal = {Journal of Network and Computer Applications},
keywords = {Bees life algorithm,Multi-objective,Multicast routing problem,Quality of service,Swarm bee optimization,Vehicular ad hoc network},
number = {3},
pages = {981--991},
publisher = {Elsevier},
title = {{Bee life-based multi constraints multicast routing optimization for vehicular ad hoc networks}},
url = {http://dx.doi.org/10.1016/j.jnca.2012.01.023},
volume = {36},
year = {2013}
}
@book{Rohlfshagen2013,
author = {Rohlfshagen, Philipp and Lehre, Per Kristian and Yao, Xin},
booktitle = {Evolutionary Computation for DOPs},
doi = {10.1007/978-3-642-38416-5},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rohlfshagen, Lehre, Yao - 2013 - Genetic Algorithms for Dynamic Routing Problems in Mobile Ad Hoc Networks.pdf:pdf},
isbn = {978-3-642-38415-8},
number = {Cci},
pages = {221--240},
title = {{Genetic Algorithms for Dynamic Routing Problems in Mobile Ad Hoc Networks}},
url = {http://link.springer.com/10.1007/978-3-642-38416-5},
volume = {490},
year = {2013}
}
@article{Cozzo2015a,
abstract = {Recent advances in the study of networked systems have highlighted that our interconnected world is composed of networks that are coupled to each other through different ‘layers' that each represent one of many possible subsystems or types of interactions. Nevertheless, it is traditional to aggregate multilayer networks into a single weighted network in order to take advantage of existing tools. This is admittedly convenient, but it is also extremely problematic, as important information can be lost as a result. It is therefore important to develop multilayer generalizations of network concepts. In this paper, we analyze triadic relations and generalize the idea of transitivity to multiplex networks. By focusing on triadic relations, which yield the simplest type of transitivity, we generalize the concept and computation of clustering coefficients to multiplex networks. We show how the layered structure of such networks introduces a new degree of freedom that has a fundamental effect on transitivity. We compute multiplex clustering coefficients for several real multiplex networks and illustrate why one must take great care when generalizing standard network concepts to multiplex networks. We also derive analytical expressions for our clustering coefficients for ensemble averages of networks in a family of random multiplex networks. Our analysis illustrates that social networks have a strong tendency to promote redundancy by closing triads at every layer and that they thereby have a different type of multiplex transitivity from transportation networks, which do not exhibit such a tendency. These insights are invisible if one only studies aggregated networks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1307.6780v1},
author = {Cozzo, Emanuele and Kivel{\"{a}}, Mikko and Domenico, Manlio De and Sol{\'{e}}-Ribalta, Albert and Arenas, Alex and G{\'{o}}mez, Sergio and Porter, Mason A. and Moreno, Yamir},
doi = {10.1088/1367-2630/17/7/073029},
eprint = {arXiv:1307.6780v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cozzo et al. - 2015 - Structure of triadic relations in multiplex networks.pdf:pdf},
isbn = {doi:10.1088/1367-2630/17/7/073029},
issn = {13672630},
journal = {New Journal of Physics},
keywords = {complex systems,multilayer networks,transitivity},
number = {7},
publisher = {IOP Publishing},
title = {{Structure of triadic relations in multiplex networks}},
volume = {17},
year = {2015}
}
@article{Guo2007,
abstract = {To explore the advantages of power saving offered by the wireless multicast advantage property, we consider the case of source-initiated multicast traffic. Current research activity for the minimum energy multicast (MEM) problem has been focused on devising efficient centralized greedy algorithms for static ad hoc networks. In this paper, we consider mobile ad hoc networks (MANETs) that use omnidirectional antennas and have limited energy resources. We propose the design and initial evaluation of the distributed minimum energy multicast (DMEM) algorithm for MANETs that attempts to reduce as much as possible the total RF energy required by the multicast communication. Several localized operations are presented for the DMEM algorithm, in which each node requires only the knowledge of and distances to all neighboring tree nodes. Through extensive simulation studies, we show that these operations are very efficient both in terms of energy saving and operation overhead},
author = {Guo, Song and Yang, Oliver},
doi = {10.1109/TPDS.2007.27},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guo, Yang - 2007 - Localized operations for distributed Minimum Energy Multicast algorithm in mobile ad hoc networks.pdf:pdf},
issn = {10459219},
journal = {IEEE Transactions on Parallel and Distributed Systems},
keywords = {Energy efficient multicast,Localized algorithm,Mobile ad hoc networks},
number = {2},
pages = {186--198},
title = {{Localized operations for distributed Minimum Energy Multicast algorithm in mobile ad hoc networks}},
volume = {18},
year = {2007}
}
@article{Fagiolo2007,
abstract = {Many empirical networks display an inherent tendency to cluster, i.e. to form circles of connected nodes. This feature is typically measured by the clustering coefficient (CC). The CC, originally introduced for binary, undirected graphs, has been recently generalized to weighted, undirected networks. Here we extend the CC to the case of (binary and weighted) directed networks and we compute its expected value for random graphs. We distinguish between CCs that count all directed triangles in the graph (independently of the direction of their edges) and CCs that only consider particular types of directed triangles (e.g., cycles). The main concepts are illustrated by employing empirical data on world-trade flows. PACS},
archivePrefix = {arXiv},
arxivId = {arXiv:physics/0612169v3},
author = {Fagiolo, Giorgio},
doi = {10.1103/PhysRevE.76.026107},
eprint = {0612169v3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fagiolo - 2007 - Clustering in complex directed networks.pdf:pdf},
isbn = {978-3-540-22354-2},
issn = {15393755},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {2},
pages = {1--8},
pmid = {17930104},
primaryClass = {arXiv:physics},
title = {{Clustering in complex directed networks}},
volume = {76},
year = {2007}
}
@article{Oliveira2005,
abstract = {In multicasting routing, the main objective is to send data from one or more sources to multiple destinations, while at the same time minimizing the usage of resources. Examples of resources which can be minimized include bandwidth, time and connection costs. In this paper, we survey applications of combinatorial optimization to multicast routing. We discuss the most important problems considered in this area, as well as their models. Algorithms for each of the main problems are also presented. ?? 2003 Elsevier Ltd. All rights reserved.},
author = {Oliveira, Carlos A S and Pardalos, Panos M.},
doi = {10.1016/j.cor.2003.12.007},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oliveira, Pardalos - 2005 - A survey of combinatorial optimization problems in multicast routing.pdf:pdf},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Combinatorial optimization,Multicast routing,Networks},
number = {8},
pages = {1953--1981},
title = {{A survey of combinatorial optimization problems in multicast routing}},
volume = {32},
year = {2005}
}
@article{Leon2010,
abstract = {Cognitive radio is a promising technology aiming to improve the utilization of the radio electromagnetic spectrum. A cognitive radio device uses general purpose computer processors that run radio applications software to perform signal processing. The use of this software enables the device to sense and understand its environment and actively change its mode of operation based on its observations. Unfortunately, this solution entails new security challenges. Our objective in this paper is to analyze the security issues of the main recent developments and architectures of cognitive radio networks. We present vulnerabilities inherent to those systems, identify novel types of abuse, classify attacks, and analyze their impact on the operation of cognitive radio-based systems. Moreover, we discuss and propose security solutions to mitigate such threats. Copyright {\textcopyright} 2010 John Wiley & Sons, Ltd.},
archivePrefix = {arXiv},
arxivId = {arXiv:1309.7735v4},
author = {Le{\'{o}}n, O. and Hern{\'{a}}ndez-Serrano, J. and Soriano, M.},
doi = {10.1002/dac},
eprint = {arXiv:1309.7735v4},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Le{\'{o}}n, Hern{\'{a}}ndez-Serrano, Soriano - 2010 - Multicast routing based on data envelopment analysis with multiple Quality of Service parame.pdf:pdf},
isbn = {10745351},
issn = {10745351},
journal = {International Journal of Communication Systems},
keywords = {Cognitive radio,Cognitive radio network,Security},
number = {5},
pages = {633--652},
pmid = {15487673},
title = {{Multicast routing based on data envelopment analysis with multiple Quality of Service parameters}},
volume = {23},
year = {2010}
}
@article{Bueno2013,
author = {Bueno, Marcos L. P. and Oliveira, Gina M. B.},
doi = {10.1109/SMC.2013.149},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bueno, Oliveira - 2013 - A Dynamic Multiobjective Evolutionary Algorithm for Multicast Routing Problem.pdf:pdf},
isbn = {978-1-4799-0652-9},
journal = {2013 IEEE International Conference on Systems, Man, and Cybernetics},
keywords = {-evolutionary computation,mization,multicast routing,multiobjective opti-,pareto optimality},
pages = {841--846},
title = {{A Dynamic Multiobjective Evolutionary Algorithm for Multicast Routing Problem}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6721901},
year = {2013}
}
@article{Silva2015,
abstract = {This article introduces a new family of Cayley graphs, called k-degree Cayley graphs, for building interconnection networks. The k-degree Cayley graph possesses many valuable topological properties, such as regularity with degree k, logarithmic diameter, and maximal fault tolerance. We present an optimal shortest path routing algorithm for the k-degree Cayley graph. Cycle- embedding and clique-embedding are also discussed.},
author = {Silva, Jaime and Gomes, Teresa and Tipper, David and Martins, Lucia and Kounev, Velin},
doi = {10.1002/net},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Silva et al. - 2015 - An Effective Algorithm for Computing All-Terminal Reliability Bounds.pdf:pdf},
isbn = {0028-3045},
issn = {1097-0037},
journal = {Networks},
keywords = {embedding,graph-theoretic interconnection networks,network topology,shortest path routing algorithm,topological properties},
number = {4},
title = {{An Effective Algorithm for Computing All-Terminal Reliability Bounds}},
volume = {66},
year = {2015}
}
@article{Camacho-Vallejo2015,
author = {Camacho-Vallejo, Jos{\'{e}}-Fernando and Mar-Ortiz, Julio and L{\'{o}}pez-Ramos, Francisco and Rodr{\'{i}}guez, Ricardo Pedraza},
doi = {10.1371/journal.pone.0128067},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Camacho-Vallejo et al. - 2015 - A Genetic Algorithm for the Bi-Level Topological Design of Local Area Networks.pdf:pdf},
issn = {1932-6203},
journal = {Plos One},
number = {6},
pages = {e0128067},
title = {{A Genetic Algorithm for the Bi-Level Topological Design of Local Area Networks}},
url = {http://dx.plos.org/10.1371/journal.pone.0128067},
volume = {10},
year = {2015}
}
@article{Elshqeirat2015,
abstract = {This paper addresses an NP-hard problem, refered to as Network Topology Design with minimum Cost subject to a Reliability constraint (NTD-CR), to design a minimal-cost communication network topology that satisfies a pre-defined reliability constraint. The paper describes a dynamic programming (DP) scheme to solve the NTD-CR problem, and proposes a DP approach, called Dynamic Programming Algorithm to solve NTD-CR (DPCR-ST), to generate the topology using a selected sequence of spanning trees of the network, STXmin The paper shows that our DPCR-ST approach always provides a feasible solution, and produces an optimal topology given an optimal order of spanning trees. The paper proves that the problem of optimally ordering the spanning trees is NP-complete, and proposes three greedy heuristics to generate and order only spanning trees of the network. Each heuristic allows the DPCR-ST approach to generate STXmin using only spanning trees, which improves the time complexity while producing a near optimal topology. Simulations based on fully connected networks that contain up to 2.3 x 10(9) spanning trees show the merits of using the ordering methods and the effectiveness of our algorithm vis-a-vis to four existing state-of-the-art techniques. Our DPCR-ST approach is able to generate 81.5% optimal results, while using only 0.77% of the spanning trees contained in networks. Further, for a typical 2 100 grid network that contains up to 1.899(102) spanning trees, DPCR-ST approach requires only k = 1214 spanning trees to generate a topology with a reliability no larger than 5.05% off from optimal.},
author = {Elshqeirat, Basima and Soh, Sieteng and Rai, Suresh and Lazarescu, Mihai},
doi = {10.1109/TR.2014.2338253},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elshqeirat et al. - 2015 - Topology design with minimal cost subject to network reliability constraint.pdf:pdf},
issn = {00189529},
journal = {IEEE Transactions on Reliability},
keywords = {Dynamic programming,network optimization,network reliability,network topology design},
number = {1},
pages = {118--131},
title = {{Topology design with minimal cost subject to network reliability constraint}},
volume = {64},
year = {2015}
}
@article{Hoblos2000,
abstract = {The selection of measurements is one of the most important problems in the design of process instrumentation. This paper is concerned with the design of sensor networks such that the observability of the variables which are necessav for the process control remains satisfied in the presence of sensor failures. Pseudo-minimal and minimal sensor sets are organized into an oriented graph which contains all the possible reconfiguration paths for which those variables remain observable. A bottom-up analysis of this graph allows to compute reliabiliw functions which evaluate the robustness of the observability properq with respect to sensor failures. The design of optimal sensor networh thus resumes to finding pseudo- minimal sensor sets such that the mean time bqore loosing the Observability property is larger than a predefined value.},
author = {Hoblos, G. and Staroswiecki, M. and Aitouche, A.},
doi = {10.1109/CCA.2000.897468},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoblos, Staroswiecki, Aitouche - 2000 - Optimal design of fault tolerant sensor networks.pdf:pdf},
isbn = {0-7803-6562-3},
journal = {IEEE International Conference on Control Applications.},
keywords = {fault tolerance,pseudo-observability,reliability,sensor network design},
pages = {467--472},
title = {{Optimal design of fault tolerant sensor networks}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=897468%5Cnhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=897468},
year = {2000}
}
@article{Deeter1997,
abstract = {This paper describes a heuristic optimization approach using\ngenetic algorithms. The method solves general network design problems to\noptimality, or near-optimality, with respect to reliability. The\noptimization formulation in this paper relaxes the previous restrictions\nthat appear in the literature. Network design is expanded to include\nlinks of differing reliability and to select from multiple choices for\neach possible link component. This significantly expands the search\nspace, necessitating a heuristic approach, but also is much more\nreflective of actual communications network design problems. The\napproach can use either exact or approximate network reliability\ncalculations and its flexibility, effectiveness and efficiency are\ndemonstrated on a series of increasingly constrained all-terminal\nreliability test problems},
author = {Deeter, D.L. and Smith, A.E.},
doi = {10.1109/RAMS.1997.571705},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deeter, Smith - 1997 - Heuristic optimization of network design considering all-terminal reliability.pdf:pdf},
isbn = {0-7803-3783-2},
issn = {0149-144X},
journal = {Annual Reliability and Maintainability Symposium},
keywords = {all-terminal reliability,conclusions,genetic algorithms,heuristic optimization,heuristic optimization approach,network,network design,s u w r,the method solves general,this paper describes a,using genetic algorithms,y},
pages = {194--199},
title = {{Heuristic optimization of network design considering all-terminal reliability}},
year = {1997}
}
@article{Chen2007,
author = {Chen, Anthony and Kim, Juyoung and Zhou, Zhong and Chootinan, Piya},
doi = {10.3141/2029-06},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2007 - Alpha Reliable Network Design Problem.pdf:pdf},
isbn = {0361-1981},
issn = {0361-1981},
journal = {Transportation Research Record},
number = {-1},
pages = {49--57},
title = {{Alpha Reliable Network Design Problem}},
url = {http://trb.metapress.com/openurl.asp?genre=article&id=doi:10.3141/2029-06},
volume = {2029},
year = {2007}
}
@article{Jan1993,
abstract = {This paper considers network topological optimization with a reliability\nconstraint. The objective is to find the topological layout of links, at\na minimal cost, under the constraint that the network reliability is not\nless than a given level of system reliability. A decomposition method,\nbased on branch & bound, is used for solving the problem. In order to\nspeed-up the procedure, an upper bound on system reliability in terms of\nnode degrees is applied. A numerical example illustrates, and shows the\neffectiveness of the method.\nIf a{*}, an important parameter, is close to the minimal number of links\nin a network which satisfy the reliability constraint, then a better\nstarting solution can be obtained, and many searching steps can be\nsaved. In our method, the lower bound a{*} is close to its actual value\nif the operational reliability of the link is close enough to 1. Also,\nif we can find the maximal increasing value of the reliability when a\nset of links is added to a specified topology, the efficiency of the\nbranch & bound algorithm is improved.},
author = {Jan, Rong Hong and Hwang, Fung Jen and Cheng, Sheng Tzong},
doi = {10.1109/24.210272},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jan, Hwang, Cheng - 1993 - Topological Optimization of a Communication Network Subject to a Reliability Constraint.pdf:pdf},
issn = {15581721},
journal = {IEEE Transactions on Reliability},
keywords = {Network design,Network planning,Network reliability},
number = {1},
pages = {63--70},
title = {{Topological Optimization of a Communication Network Subject to a Reliability Constraint}},
volume = {42},
year = {1993}
}
@article{Chen2010b,
abstract = {Transportation network design problem (NDP) is inherently multi-objective in nature, because it involves a number of stakeholders with different needs. In addition, the decision-making process sometimes has to be made under uncertainty where certain inputs are not known exactly. In this paper, we develop three stochastic multi-objective models for designing transportation network under demand uncertainty. These three stochastic multi-objective NDP models are formulated as the expected value multi-objective programming (EVMOP) model, chance constrained multi-objective programming (CCMOP) model, and dependent chance multi-objective programming (DCMOP) model in a bi-level programming framework using different criteria to hedge against demand uncertainty. To solve these stochastic multi-objective NDP models, we develop a solution approach that explicitly optimizes all objectives under demand uncertainty by simultaneously generating a family of optimal solutions known as the Pareto optimal solution set. Numerical examples are also presented to illustrate the concept of the three stochastic multi-objective NDP models as well as the effectiveness of the solution approach.},
author = {Chen, Anthony and Kim, Juyoung and Lee, Seungjae and Kim, Youngchan},
doi = {10.1016/j.eswa.2009.06.048},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2010 - Stochastic multi-objective models for network design problem.pdf:pdf},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Bi-level program,Genetic algorithm,Multi-objective,Network design,Stochastic program,Traffic assignment,User equilibrium},
number = {2},
pages = {1608--1619},
publisher = {Elsevier Ltd},
title = {{Stochastic multi-objective models for network design problem}},
url = {http://dx.doi.org/10.1016/j.eswa.2009.06.048},
volume = {37},
year = {2010}
}
@article{Kounev2016,
author = {Kounev, Velin and L{\'{e}}vesque, Martin and Tipper, David and Gomes, Teresa},
doi = {10.1007/s10922-016-9375-y},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kounev et al. - 2016 - Reliable Communication Networks for Smart Grid Transmission Systems.pdf:pdf},
issn = {10647570},
journal = {Journal of Network and Systems Management},
keywords = {Availability,Network design,Smart grid},
pages = {1--24},
title = {{Reliable Communication Networks for Smart Grid Transmission Systems}},
year = {2016}
}
@article{Makarenko2004,
abstract = {This thesis is concerned with the Distributed Information Gathering (DIG) problem in which a Sensor Network is tasked with building a common representation of environment. The problem is motivated by the advantages offered by distributed autonomous sensing systems and the challenges they present. The focus of this study is on Macro Sensor Networks, characterized by platform mobility, heterogeneous teams, and long mission duration. The system under consideration may consist of an arbitrary number of mobile autonomous robots, stationary sensor platforms, and human operators, all linked in a network. This work describes a comprehensive framework called Active Sensor Network (ASN) which addresses the tasks of information fusion, decision making, system configuration, and user interaction. The main design objectives are scalability with the number of robotic platforms, maximum flexibility in implementation and deployment, and robustness to component and communication failure. The framework is described from three complementary points of view: architecture, algorithms, and implementation. The main contribution of this thesis is the development of the ASN architecture. Its design follows three guiding principles: decentralization, modularity, and locality of interactions. These principles are applied to all aspects of the architecture and the framework in general. To achieve flexibility, the design approach emphasizes interactions between components rather than the definition of the components themselves. The architecture specifies a small set of interfaces sufficient to implement a wide range of information gathering systems. In the area of algorithms, this thesis builds on the earlier work on Decentralized Data Fusion (DDF) and its extension to information-theoretic decision making. It presents the Bayesian Decentralized Data Fusion (BDDF) algorithm formulated for environment features represented by a general probability density function. Several specific representations are also considered: Gaussian, discrete, and the Certainty Grid map. Well known algorithms for these representations are shown to implement various aspects of the Bayesian framework. As part of the ASN implementation, a practical indoor sensor network has been developed and tested. Two series of experiments were conducted, utilizing two types of environment representation: 1) point features with Gaussian position uncertainty and 2) Certainty Grid maps. The network was operational for several days at a time, with individual platforms coming on and off-line. On several occasions, the network consisted of 39 software com- ponents. The lessons learned during the systems development may be applicable to other heterogeneous distributed systems with data-intensive algorithms.},
author = {Makarenko, A. and Brooks, A. and Williams, S. and Durrant-Whyte, H. and Grocholsky, B.},
doi = {10.1109/ROBOT.2004.1307971},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Makarenko et al. - 2004 - A decentralized architecture for Active Sensor Networks.pdf:pdf},
isbn = {0-7803-8232-3},
issn = {10504729},
journal = {IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004},
number = {November},
pages = {1097--1102 Vol.2},
title = {{A decentralized architecture for Active Sensor Networks}},
year = {2004}
}
@article{Chen2011a,
abstract = {This paper aims to provide a state-of-the-art review of the transport network design problem (NDP) under uncertainty and to present some new developments on a bi-objective-reliable NDP (BORNDP) model that explicitly optimizes the capacity reliability and travel time reliability under demand uncertainty. Both are useful performance measures that can describe the supply-side reliability and demand-side reliability of a road network. A simulation-based multi-objective genetic algorithm solution procedure, which consists of a traffic assignment algorithm, a genetic algorithm, a Pareto filter, and a Monte-Carlo simulation, is developed to solve the proposed BORNDP model. A numerical example based on the capacity enhancement problem is presented to demonstrate the tradeoff between capacity reliability and travel time reliability in the NDP.},
author = {Chen, Anthony and Zhou, Zhong and Chootinan, Piya and Ryu, Seungkyu and Yang, Chao and Wong, S. C.},
doi = {10.1080/01441647.2011.589539},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2011 - Transport Network Design Problem under Uncertainty A Review and New Developments.pdf:pdf},
isbn = {0144-1647},
issn = {0144-1647},
journal = {Transport Reviews},
number = {6},
pages = {743--768},
title = {{Transport Network Design Problem under Uncertainty: A Review and New Developments}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01441647.2011.589539},
volume = {31},
year = {2011}
}
@article{Chootinan2005,
abstract = {This paper presents a reliability-based network design problem. A network reliability concept is embedded into the continuous network design problem in which travelers' route choice behavior follows the stochastic user equilibrium assumption. A new capacity-reliability index is introduced to measure the probability that all of the network links are operated below their capacities when serving different traffic patterns deviating from the average condition. The reliability-based network design problem is formulated as a bi-level program in which the lower level sub-program is the probit-based stochastic user equilibrium problem and the upper level sub-program is the maximization of the new capacity reliability index. The lower level sub-program is solved by a variant of the method of successive averages using the exponential average to represent the learning process of network users on a daily basis that results in the daily variation of traffic-flow pattern, and Monte Carlo stochastic loading. The upper level sub-program is tackled by means of genetic algorithms. A numerical example is used to demonstrate the concept of the proposed framework.},
author = {Chootinan, Piya and Wong, S. C. and Chen, Anthony},
doi = {10.1002/atr.5670390303},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chootinan, Wong, Chen - 2005 - A reliability-based network design problem.pdf:pdf},
isbn = {2042-3195},
issn = {01976729},
journal = {Journal of Advanced Transportation},
keywords = {Bi-level program,Capacity reliability,Continuous network design problem,Reliability analysis,Stochastic user equilibrium},
number = {3},
pages = {247--270},
title = {{A reliability-based network design problem}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-27744457927&partnerID=tZOtx3y1},
volume = {39},
year = {2005}
}
@article{Watcharasitthiwat2009,
abstract = {Network design problem is a well-known NP-hard problem which involves the selection of a subset of possible links or a network topology in order to minimize the network cost subjected to the reliability constraint. To overcome the problem, this paper proposes a new efficiency algorithm based on the conventional ant colony optimization (ACO) to solve the communication network design when considering both economics and reliability. The proposed method is called improved ant colony optimizations (IACO) which introduces two addition techniques in order to improve the search process, i.e. neighborhood search and re-initialization process. To show its efficiency, IACO is applied to test with three different topology network systems and its results are compared with those obtained results from the conventional approaches, i.e. genetic algorithm (GA), tabu search algorithm (TSA) and ACO. Simulation results, obtained these test problems with various constraints, shown that the proposed approach is superior to the conventional algorithms both solution quality and computational time. ?? 2009 Elsevier Ltd. All rights reserved.},
author = {Watcharasitthiwat, Kanyapat and Wardkein, Paramote},
doi = {10.1016/j.compeleceng.2009.02.006},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Watcharasitthiwat, Wardkein - 2009 - Reliability optimization of topology communication network design using an improved ant colony opti.pdf:pdf},
issn = {00457906},
journal = {Computers and Electrical Engineering},
keywords = {Ant colony optimization,Genetic algorithm,Reliability optimization,Tabu search algorithm,Topology network design},
number = {5},
pages = {730--747},
publisher = {Elsevier Ltd},
title = {{Reliability optimization of topology communication network design using an improved ant colony optimization}},
url = {http://dx.doi.org/10.1016/j.compeleceng.2009.02.006},
volume = {35},
year = {2009}
}
@article{Saramaki2007,
abstract = {The recent high level of interest in weighted complex networks gives rise to a need to develop new measures and to generalize existing ones to take the weights of links into account. Here we focus on various generalizations of the clustering coefficient, which is one of the central characteristics in the complex network theory. We present a comparative study of the several suggestions introduced in the literature, and point out their advantages and limitations. The concepts are illustrated by simple examples as well as by empirical data of the world trade and weighted coauthorship networks.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0608670},
author = {Saram{\"{a}}ki, Jari and Kivel{\"{a}}, Mikko and Onnela, Jukka Pekka and Kaski, Kimmo and Kert{\'{e}}sz, J{\'{a}}nos},
doi = {10.1103/PhysRevE.75.027105},
eprint = {0608670},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saram{\"{a}}ki et al. - 2007 - Generalizations of the clustering coefficient to weighted complex networks.pdf:pdf},
isbn = {1539-3755},
issn = {15393755},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {2},
pages = {2--5},
pmid = {17358454},
primaryClass = {cond-mat},
title = {{Generalizations of the clustering coefficient to weighted complex networks}},
volume = {75},
year = {2007}
}
@article{Olfati-Saber2004,
abstract = {In this paper, we discuss consensus problems for networks of dynamic agents with fixed and switching topologies. We analyze three cases: 1) directed networks with fixed topology; 2) directed networks with switching topology; and 3) undirected networks with communication time-delays and fixed topology. We introduce two consensus protocols for networks with and without time-delays and provide a convergence analysis in all three cases. We establish a direct connection between the algebraic connectivity (or Fiedler eigenvalue) of the network and the performance (or negotiation speed) of a linear consensus protocol. This required the generalization of the notion of algebraic connectivity of undirected graphs to digraphs. It turns out that balanced digraphs play a key role in addressing average-consensus problems. We introduce disagreement functions for convergence analysis of consensus protocols. A disagreement function is a Lyapunov function for the disagreement network dynamics. We proposed a simple disagreement function that is a common Lyapunov function for the disagreement dynamics of a directed network with switching topology. A distinctive feature of this work is to address consensus problems for networks with directed information flow. We provide analytical tools that rely on algebraic graph theory, matrix theory, and control theory. Simulations are provided that demonstrate the effectiveness of our theoretical results.},
author = {Olfati-Saber, Reza and Murray, Richard M.},
doi = {10.1109/TAC.2004.834113},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Olfati-Saber, Murray - 2004 - Consensus problems in networks of agents with switching topology and time-delays.pdf:pdf},
isbn = {0018-9286},
issn = {00189286},
journal = {IEEE Transactions on Automatic Control},
number = {9},
pages = {1520--1533},
pmid = {22127797},
title = {{Consensus problems in networks of agents with switching topology and time-delays}},
volume = {49},
year = {2004}
}
@article{Morone2015,
abstract = {The whole frame of interconnections in complex networks hinges on a specific set of structural nodes, much smaller than the total size, which, if activated, would cause the spread of information to the whole network, or, if immunized, would prevent the diffusion of a large scale epidemic. Localizing this optimal, that is, minimal, set of structural nodes, called influencers, is one of the most important problems in network science. Despite the vast use of heuristic strategies to identify influential spreaders, the problem remains unsolved. Here we map the problem onto optimal percolation in random networks to identify the minimal set of influencers, which arises by minimizing the energy of a many-body system, where the form of the interactions is fixed by the non-backtracking matrix of the network. Big data analyses reveal that the set of optimal influencers is much smaller than the one predicted by previous heuristic centralities. Remarkably, a large number of previously neglected weakly connected nodes emerges among the optimal influencers. These are topologically tagged as low-degree nodes surrounded by hierarchical coronas of hubs, and are uncovered only through the optimal collective interplay of all the influencers in the network. The present theoretical framework may hold a larger degree of universality, being applicable to other hard optimization problems exhibiting a continuous transition from a known phase.},
archivePrefix = {arXiv},
arxivId = {1506.08326},
author = {Morone, Flaviano and Makse, Hern{\'{a}}n a. A},
doi = {10.1038/nature14604},
eprint = {1506.08326},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Morone, Makse - 2015 - Influence maximization in complex networks through optimal percolation.pdf:pdf},
isbn = {1476-4687 (Electronic)\r0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {7563},
pages = {65--68},
pmid = {26131931},
title = {{Influence maximization in complex networks through optimal percolation}},
url = {http://dx.doi.org/10.1038/nature14604%5Cnhttp://www.nature.com/doifinder/10.1038/nature14604%5Cnhttp://www.nature.com/doifinder/10.1038/nature14604},
volume = {524},
year = {2015}
}
@article{Ahmed2014,
abstract = {Developments in the wind power industry have enabled a new generation of wind turbines with longer blades, taller towers, higher efficiency, and lower maintenance costs due to the maturity of related technologies. Nevertheless, wind turbines are still blind machines because the control center is responsible for managing and controlling individual wind turbines that are turned on or off according to demand for electricity. In this paper, we propose a communication network architecture for smart-wind power farms (Smart-WPFs). The proposed architecture is designed for wind turbines to communicate directly and share sensing data in order to maximize power generation, WPF availability, and turbine efficiency. We also designed a sensor data frame structure to carry sensing data from different wind turbine parts such as the rotor, transformer, nacelle, etc. The data frame includes a logical node ID (LNID), sensor node ID (SNID), sensor type (ST), and sensor data based on the International Electrotechnical Commission (IEC) 61400-25 standard. We present an analytical model that describes upstream traffic between the wind turbines and the control center. Using a queueing theory approach, the upstream traffic is evaluated in view of bandwidth utilization and average queuing delay. The performance of the proposed network architectures are evaluated by using analytical and simulation models.},
author = {Ahmed, Mohamed A. and Kim, Young Chon},
doi = {10.3390/en7063900},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed, Kim - 2014 - Communication network architectures for smart-wind power farms.pdf:pdf},
issn = {19961073},
journal = {Energies},
keywords = {Communication network,Ethernet passive optical network (EPON),International electrotechnical commission (IEC) 61,Smart-wind power farms (smart-WPFs),Wind turbine,Wireless,ZigBee},
number = {6},
pages = {3900--3921},
title = {{Communication network architectures for smart-wind power farms}},
volume = {7},
year = {2014}
}
@article{Olfati-Saber2007,
abstract = {This paper provides a theoretical framework for analysis of consensus algorithms for multi-agent networked systems with an emphasis on the role of directed information flow, robustness to changes in network topology due to link/node failures, time-delays, and performance guarantees. An overview of basic concepts of information consensus in networks and methods of convergence and performance analysis for the algorithms are provided. Our analysis framework is based on tools from matrix theory, algebraic graph theory, and control theory. We discuss the connections between consensus problems in networked dynamic systems and diverse applications including synchronization of coupled oscillators, flocking, formation control, fast consensus in small-world networks, Markov processes and gossip-based algorithms, load balancing in networks, rendezvous in space, distributed sensor fusion in sensor networks, and belief propagation. We establish direct connections between spectral and structural properties of complex networks and the speed of information diffusion of consensus algorithms. A brief introduction is provided on networked systems with nonlocal information flow that are considerably faster than distributed systems with lattice-type nearest neighbor interactions. Simulation results are presented that demonstrate the role of small-world effects on the speed of consensus algorithms and cooperative control of multivehicle formations},
archivePrefix = {arXiv},
arxivId = {1009.6050},
author = {Olfati-Saber, Reza and Fax, J. Alex and Murray, Richard M.},
doi = {10.1109/JPROC.2006.887293},
eprint = {1009.6050},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Olfati-Saber, Fax, Murray - 2007 - Consensus and cooperation in networked multi-agent systems.pdf:pdf},
isbn = {0018-9219},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {Consensus algorithms,Cooperative control,Flocking,Graph Laplacians,Information fusion,Multi-agent systems,Networked control systems,Synchronization of coupled oscillators},
number = {1},
pages = {215--233},
pmid = {4118472},
title = {{Consensus and cooperation in networked multi-agent systems}},
volume = {95},
year = {2007}
}
@article{Gravina2016,
abstract = {Low latency analytics on geographically distributed dat- asets (across datacenters, edge clusters) is an upcoming and increasingly important challenge. The dominant approach of aggregating all the data to a single data- center significantly inflates the timeliness of analytics. At the same time, running queries over geo-distributed inputs using the current intra-DC analytics frameworks also leads to high query response times because these frameworks cannot cope with the relatively low and variable capacity of WAN links. We present Iridium, a system for low latency geo-distri- buted analytics. Iridium achieves low query response times by optimizing placement of both data and tasks of the queries. The joint data and task placement op- timization, however, is intractable. Therefore, Iridium uses an online heuristic to redistribute datasets among the sites prior to queries' arrivals, and places the tasks to reduce network bottlenecks during the query's ex- ecution. Finally, it also contains a knob to budget WAN usage. Evaluation across eight worldwide EC2 re- gions using production queries show that Iridium speeds up queries by 3× − 19× and lowers WAN usage by 15%−64% compared to existing baselines.},
archivePrefix = {arXiv},
arxivId = {arXiv:1602.05561v1},
author = {Gravina, Daniele and Liapis, Antonios and Yannakakis, Georgio},
doi = {10.475/123},
eprint = {arXiv:1602.05561v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gravina, Liapis, Yannakakis - 2016 - Surprise Search Beyond Objectives and Novelty.pdf:pdf},
isbn = {9781450335423},
issn = {0146-4833},
journal = {Gecco},
keywords = {WAN analytics,data analytics,geo-distributed,low latency,network aware},
pages = {421--434},
title = {{Surprise Search: Beyond Objectives and Novelty}},
url = {Microsoft Research%5CnUniversity of California at Berkeley%5CnUniversity of Wisconsin at Madison},
year = {2016}
}
@article{Huang,
author = {Huang, Xin and Lu, Wei and Lakshmanan, Laks V S},
doi = {10.1145/2882903.2882913},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Lu, Lakshmanan - Unknown - Truss Decomposition of Probabilistic Graphs Semantics and Algorithms.pdf:pdf},
isbn = {9781450335317},
issn = {07308078},
pages = {77--90},
title = {{Truss Decomposition of Probabilistic Graphs : Semantics and Algorithms}}
}
@article{Pan2011,
abstract = {We apply a variant of the explosive percolation procedure to large real-world networks and show with finite-size scaling that the university class, ordinary or explosive, of the resulting percolation transition depends on the structural properties of the network, as well as the number of unoccupied links considered for comparison in our procedure. We observe that in our social networks, the percolation clusters close to the critical point are related to the community structure. This relationship is further highlighted by applying the procedure to model networks with predefined communities.},
archivePrefix = {arXiv},
arxivId = {1010.3171},
author = {Pan, Raj Kumar and Kivel{\"{a}}, Mikko and Saram{\"{a}}ki, Jari and Kaski, Kimmo and Kert{\'{e}}sz, J{\'{a}}nos},
doi = {10.1103/PhysRevE.83.046112},
eprint = {1010.3171},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pan et al. - 2011 - Using explosive percolation in analysis of real-world networks.pdf:pdf},
issn = {15393755},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {4},
pages = {1--6},
pmid = {21599245},
title = {{Using explosive percolation in analysis of real-world networks}},
volume = {83},
year = {2011}
}
@article{DSouza2015,
abstract = {The emergence of large-scale connectivity on an underlying network or lattice, the so-called percolation transition, has a profound impact on the system's macroscopic behaviours. There is thus great interest in controlling the location of the percolation transition to either enhance or delay its onset and, more generally, in understanding the consequences of such control interventions. Here we review explosive percolation, the sudden emergence of large-scale connectivity that results fromrepeated, small interventions designed to delay the percolation transition.These transitions exhibit drastic, unanticipated and exciting consequences that make explosive percolation an emerging paradigm for modelling real-world systems ranging from social networks to nanotubes.},
archivePrefix = {arXiv},
arxivId = {1511.01800},
author = {D'Souza, Raissa M. and Nagler, Jan},
doi = {10.1038/NPHYS3378},
eprint = {1511.01800},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/D'Souza, Nagler - 2015 - Anomalous critical and supercritical phenomena in explosive percolation.pdf:pdf},
issn = {1745-2473},
journal = {Nature Physics},
number = {July},
pages = {531--538},
title = {{Anomalous critical and supercritical phenomena in explosive percolation}},
volume = {11},
year = {2015}
}
@article{DeDomenico2015a,
abstract = {Many complex systems can be represented as networks consisting of distinct types of interactions, which can be categorized as links belonging to different layers. For example, a good description of the full protein-protein interactome requires, for some organisms, up to seven distinct network layers, accounting for different genetic and physical interactions, each containing thousands of protein-protein relationships. A fundamental open question is then how many layers are indeed necessary to accurately represent the structure of a multilayered complex system. Here we introduce a method based on quantum theory to reduce the number of layers to a minimum while maximizing the distinguishability between the multilayer network and the corresponding aggregated graph. We validate our approach on synthetic benchmarks and we show that the number of informative layers in some real multilayer networks of protein-genetic interactions, social, economical and transportation systems can be reduced by up to 75%.},
archivePrefix = {arXiv},
arxivId = {1405.0425},
author = {{De Domenico}, Manlio and Nicosia, Vincenzo and Arenas, Alexandre and Latora, Vito},
doi = {10.1038/ncomms7864},
eprint = {1405.0425},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Domenico et al. - 2015 - Structural reducibility of multilayer networks.pdf:pdf},
isbn = {2041-1723 (Electronic)\r2041-1723 (Linking)},
issn = {2041-1723},
journal = {Nature communications},
keywords = {multi-layer},
pages = {6864},
pmid = {25904309},
publisher = {Nature Publishing Group},
title = {{Structural reducibility of multilayer networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25904309},
volume = {6},
year = {2015}
}
@article{Reis2014,
abstract = {Networks in nature do not act in isolation, but instead exchange information and depend on one another to function properly1, 2, 3. Theory has shown that connecting random networks may very easily result in abrupt failures3, 4, 5, 6. This finding reveals an intriguing paradox7, 8: if natural systems organize in interconnected networks, how can they be so stable? Here we provide a solution to this conundrum, showing that the stability of a system of networks relies on the relation between the internal structure of a network and its pattern of connections to other networks. Specifically, we demonstrate that if interconnections are provided by network hubs, and the connections between networks are moderately convergent, the system of networks is stable and robust to failure. We test this theoretical prediction on two independent experiments of functional brain networks (in task and resting states), which show that brain networks are connected with a topology that maximizes stability according to the theory},
archivePrefix = {arXiv},
arxivId = {1409.5510},
author = {Reis, Saulo D. S. and Hu, Yanqing and Babino, Andr{\'{e}}s and {Andrade Jr}, Jos{\'{e}} S. and Canals, Santiago and Sigman, Mariano and Makse, Hern{\'{a}}n A.},
doi = {10.1038/nphys3081},
eprint = {1409.5510},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reis et al. - 2014 - Avoiding catastrophic failure in correlated networks of networks.pdf:pdf},
isbn = {1745-2473},
issn = {1745-2473},
journal = {Nature Physics},
number = {September},
pages = {762--767},
title = {{Avoiding catastrophic failure in correlated networks of networks}},
url = {http://www.nature.com/doifinder/10.1038/nphys3081},
volume = {10},
year = {2014}
}
@article{DeDomenico2016,
abstract = {Epilepsy is the neurological disorder of the brain which is difficult to diagnose visually using Electroencephalogram (EEG) signals. Hence, an automated detection of epilepsy using EEG signals will be a useful tool in medical field. The automation of epilepsy detection using signal processing techniques such as wavelet transform and entropies may optimise the performance of the system. Many algorithms have been developed to diagnose the presence of seizure in the EEG signals. The entropy is a nonlinear parameter that reflects the complexity of the EEG signal. Many entropies have been used to differentiate normal, interictal and ictal EEG signals. This paper discusses various entropies used for an automated diagnosis of epilepsy using EEG signals. We have presented unique ranges for various entropies used to differentiate normal, interictal, and ictal EEG signals and also ranked them depending on the ability to discrimination ability of three classes. These entropies can be used to classify the different stages of epilepsy and can also be used for other biomedical applications.},
author = {{De Domenico}, Manlio and Granell, Clara and Porter, Mason A. and Arenas, Alex},
doi = {10.1038/nphys3865},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Domenico et al. - 2016 - The physics of spreading processes in multilayer networks.pdf:pdf},
issn = {1745-2473},
journal = {Nature Physics},
number = {August},
pages = {85--96},
title = {{The physics of spreading processes in multilayer networks}},
url = {http://www.nature.com/doifinder/10.1038/nphys3865},
volume = {1},
year = {2016}
}
@article{Radicchi2015,
abstract = {The function of a real network depends not only on the reliability of its own components, but is affected also by the simultaneous operation of other real networks coupled with it. Robustness of systems composed of interdependent network layers has been extensively studied in recent years. However, the theoretical frameworks developed so far apply only to special models in the limit of infinite sizes. These methods are therefore of little help in practical contexts, given that real interconnected networks have finite size and their structures are generally not compatible with those of graph toy models. Here, we introduce a theoretical method that takes as inputs the adjacency matrices of the layers to draw the entire phase diagram for the interconnected network, without the need of actually simulating any percolation process. We demonstrate that percolation transitions in arbitrary interdependent networks can be understood by decomposing these system into uncoupled graphs: the intersection among the layers, and the remainders of the layers. When the intersection dominates the remainders, an interconnected network undergoes a continuous percolation transition. Conversely, if the intersection is dominated by the contribution of the remainders, the transition becomes abrupt even in systems of finite size. We provide examples of real systems that have developed interdependent networks sharing a core of "high quality" edges to prevent catastrophic failures.},
archivePrefix = {arXiv},
arxivId = {1503.04655v1},
author = {Radicchi, Filippo},
doi = {10.1038/nphys3374},
eprint = {1503.04655v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Radicchi - 2015 - Percolation in real interdependent networks.pdf:pdf},
isbn = {1745-2473},
issn = {1745-2473},
journal = {Nature Physics},
keywords = {complex network,complexity},
number = {June},
pages = {1--7},
title = {{Percolation in real interdependent networks}},
url = {http://arxiv.org/abs/1503.04655},
volume = {11},
year = {2015}
}
@article{Faqeeh2015,
abstract = {We introduce network L-cloning, a technique for creating ensembles of random networks from any given real-world or artificial network. Each member of the ensemble is an L-cloned network constructed from L copies of the original network. The degree distribution of an L-cloned network and, more importantly, the degree-degree correlation between and beyond nearest neighbors are identical to those of the original network. The density of triangles in an L-cloned network, and hence its clustering coefficient, is reduced by a factor of L compared to those of the original network. Furthermore, the density of loops of any fixed length approaches zero for sufficiently large values of L. Other variants of L-cloning allow us to keep intact the short loops of certain lengths. As an application, we employ these network cloning methods to investigate the effect of short loops on dynamical processes running on networks and to inspect the accuracy of corresponding tree-based theories. We demonstrate that dynamics on L-cloned networks (with sufficiently large L) are accurately described by the so-called adjacency tree-based theories, examples of which include the message passing technique, some pair approximation methods, and the belief propagation algorithm used respectively to study bond percolation, SI epidemics, and the Ising model.},
archivePrefix = {arXiv},
arxivId = {1408.1294},
author = {Faqeeh, Ali and Melnik, Sergey and Gleeson, James P.},
doi = {10.1103/PhysRevE.91.052807},
eprint = {1408.1294},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Faqeeh, Melnik, Gleeson - 2015 - Network cloning unfolds the effect of clustering on dynamical processes.pdf:pdf},
issn = {15502376},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {5},
pages = {1--10},
pmid = {26066212},
title = {{Network cloning unfolds the effect of clustering on dynamical processes}},
volume = {91},
year = {2015}
}
@article{Li2015,
abstract = {As a generation of the classical percolation, clique percolation focuses on the connection of cliques in a graph, where the connection of two $k$-cliques means that they share at least $l<k$ vertices. In this paper, we develop a theoretical approach to study clique percolation in Erd\H{o}s-R\'{e}nyi graphs, which gives not only the exact solutions of the critical point, but also the corresponding order parameter. Based on this, we prove theoretically that the fraction $\psi$ of cliques in the giant clique cluster always makes a continuous phase transition as the classical percolation. However, the fraction $\phi$ of vertices in the giant clique cluster for $l>1$ makes a step-function-like discontinuous phase transition in the thermodynamic limit and a continuous phase transition for $l=1$. More interesting, our analysis shows that at the critical point, the order parameter $\phi_c$ for $l>1$ is neither $0$ nor $1$, but a constant depending on $k$ and $l$. All these theoretical findings are in agreement with the simulation results, which give theoretical support and clarification for previous simulation studies of clique percolation.},
archivePrefix = {arXiv},
arxivId = {1508.01878},
author = {Li, Ming and Deng, Youjin and Wang, Bing Hong},
doi = {10.1103/PhysRevE.92.042116},
eprint = {1508.01878},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Deng, Wang - 2015 - Clique percolation in random graphs.pdf:pdf},
issn = {15502376},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {4},
pages = {1--6},
title = {{Clique percolation in random graphs}},
volume = {92},
year = {2015}
}
@article{Chung2014,
abstract = {Social reinforcement and modular structure are two salient features observed in the spreading of behavior through social contacts. In order to investigate the interplay between these two features, we study the generalized epidemic process on modular networks with equal-sized finite communities and adjustable modularity. Using the analytical approach originally applied to clique-based random networks, we show that the system exhibits a bond-percolation type continuous phase transition for weak social reinforcement, whereas a discontinuous phase transition occurs for sufficiently strong social reinforcement. Our findings are numerically verified using the finite-size scaling analysis and the crossings of the bimodality coefficient.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.0573v2},
author = {Chung, Kihong and Baek, Yongjoo and Kim, Daniel and Ha, Meesoon and Jeong, Hawoong},
doi = {10.1103/PhysRevE.89.052811},
eprint = {arXiv:1312.0573v2},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chung et al. - 2014 - Generalized epidemic process on modular networks.pdf:pdf},
issn = {15502376},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {5},
pmid = {25353848},
title = {{Generalized epidemic process on modular networks}},
volume = {89},
year = {2014}
}
@article{Tian2014,
abstract = {• As coupling strength increases, the system changes from second order through hybrid order to first order phase transition. • For weak coupling strength, corresponding to second order transition, clustering has almost no effect on the robustness of network, but for strong coupling strength, corresponding to first order transition, the system that is more clustered is more vulnerable. • When the system is more clustered, the hybrid order region is almost unchangeable, the first order region becomes smaller, and the second order region is larger. a b s t r a c t In real world, most systems show significant clustering, and it is more practical to investigate the behaviors of clustered network. Previous studies are mostly focused on single clustered network and coupled clustered networks with dependency links. Here we study two clustered networks coupled with both interdependent and interconnected links by introducing generating function of the joint degree distribution. When the networks are fully dependent, we obtain the analytical solution of giant component P ∞ . We show rich phase transition phenomena and analyze their behaviors. We find that, as dependency coupling strength increases, the system changes from second order phase transition through hybrid transition to first order phase transition. For weak dependency coupling strength q A , corresponding to second order phase transition, we find that, clustering has almost no effect on the robustness of network, but for strong dependency coupling strength q A , corresponding to first order transition, the more clustered system is more vulnerable. At the same time, we notice that when the system is more clustered, the hybrid order region is almost unchangeable, the first order region becomes smaller, and the second order region is larger. Additionally, we can see that, the bigger the clustering coefficient c is, the bigger the second order region becomes. For the same c, the density of connectivity links between networks is higher, the second order region becomes smaller, and the density of connectivity links within each network is higher, the second order region becomes bigger.},
author = {Tian, Lixin and Huang, Yi and Dong, Gaogao and Du, Ruijin and Shi, Liu},
doi = {10.1016/j.physa.2014.05.063},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tian et al. - 2014 - Robustness of interdependent and interconnected clustered networks.pdf:pdf},
journal = {Physica A},
pages = {120126},
title = {{Robustness of interdependent and interconnected clustered networks}},
volume = {412},
year = {2014}
}
@article{Dong2014,
abstract = {• The robustness of clustered networks with partial support–dependence relations is studied by adopting two attack strategies. • The first order region becomes smaller as average degree or clustering coefficient increases. • The second order region becomes larger as average degree or clustering coefficient increases. • Clustering coefficient has a significant impact on robustness of the system for strong coupling strength. • For weak coupling strength, clustering coefficient has little influence, especially for attacking both networks. a b s t r a c t We carry out a study of percolation behaviors of clustered networks with partial support–dependence relations by adopting two different attacking strategies, attacking only one network and both networks, which help to further understand real coupled networks. For two different attacking strategies we find that the system changes from a secondorder phase transition to a firstorder phase transition as coupling strength q increases. We also notice that the firstorder region becomes smaller and the secondorder region becomes larger as average degree or clustering coefficient increases. And, as the average supported degree approaches infinity, coupled clustered networks become independent and only the secondorder transition is observed, which is similar to q = 0. Furthermore, we find that clustering coefficient has a significant impact on robustness of the system for strong coupling strength, but for weak coupling strength it has little influence, especially for attacking both networks. The study implies that we can obtain a more robust network by reducing clustering coefficient and increasing average degree for strong coupling strength. However, for weak coupling strength, a more robust network is obtained only by increasing average degree for the same support average degree. Additionally, we find that for attacking both networks the system becomes more vulnerable and difficult to defend compared to attacking only one network.},
author = {Dong, Gaogao and Tian, Lixin and Du, Ruijin and Fu, Min and Stanley, H Eugene},
doi = {10.1016/j.physa.2013.09.055},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dong et al. - 2014 - Analysis of percolation behaviors of clustered networks with partial support&#x2013dependence relations.pdf:pdf},
journal = {Physica A},
pages = {370378},
title = {{Analysis of percolation behaviors of clustered networks with partial support&#x2013;dependence relations}},
volume = {394},
year = {2014}
}
@article{Havlin2014,
abstract = {Our dependence on networks – be they infrastructure, economic, social or others – leaves us prone to crises caused by the vulnerabilities of these networks. There is a great need to develop new methods to protect infrastructure networks and prevent cascade of failures (especially in cases of coupled networks). Terrorist attacks on transportation networks have traumatized modern societies. With a single blast, it has become possible to paralyze airline traffic, electric power supply, ground transportation or Internet communication. How, and at which cost can one restructure the network such that it will become more robust against malicious attacks? The gradual increase in attacks on the networks society depends on – Internet, mobile phone, transportation, air travel, banking, etc. – emphasize the need to develop new strategies to protect and defend these crucial networks of communication and infrastructure networks. One example is the threat of liquid explosives a few years ago, which completely shut down air travel for days, and has created extreme changes in regulations. Such threats and dangers warrant the need for new tools and strategies to defend critical infrastructure. In this paper we review recent advances in the theoretical understanding of the vulnerabilities of interdependent networks with and without spatial embedding, attack strategies and their affect on such networks of networks as well as recently developed strategies to optimize and repair failures caused by such attacks.},
author = {Havlin, S and Kenett, D Y and Bashan, A and Gao, J and Stanley, H E},
doi = {10.1140/epjst/e2014022516},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Havlin et al. - 2014 - Vulnerability of network of networks.pdf:pdf},
journal = {Eur. Phys. J. Special Topics The European Physical Journal Special Topics},
pages = {20872106},
title = {{Vulnerability of network of networks}},
volume = {223},
year = {2014}
}
@article{Hackett2013,
abstract = {We present an analytical approach to determining the expected cascade size in a broad range of dynamical models on the class of highly clustered random graphs introduced by Gleeson [J. P. Gleeson, Phys. Rev. E 80, 036107 (2009)]. A condition for the existence of global cascades is also derived. Applications of this approach include analyses of percolation, and Watts's model. We show how our techniques can be used to study the effects of ingroup bias in cascades on social networks.},
author = {Hackett, Adam and Gleeson, James P},
doi = {10.1103/PhysRevE.87.062801},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hackett, Gleeson - 2013 - Cascades on cliquebased graphs.pdf:pdf},
journal = {PHYSICAL REVIEW E},
title = {{Cascades on cliquebased graphs}},
volume = {8723},
year = {2013}
}
@article{Shao2014,
abstract = {Clustering, or transitivity, a behavior observed in realworld networks, affects network structure and function. This property has been studied extensively, but most of this research has been limited to clustering in single networks. The effect of clustering on the robustness of coupled networks, on the other hand, has received much less attention. Only the case of a pair of fully coupled networks with clustering has recently received study. Here we generalize the study of clustering of a fully coupled pair of networks and apply it to a partially interdependent network of networks with clustering within the network components. We show, both analytically and numerically, how clustering within networks affects the percolation properties of interdependent networks, including the percolation threshold, the size of the giant component, and the critical coupling point at which the firstorder phase transition changes to a secondorder phase transition as the coupling between the networks is reduced. We study two types of clustering, one proposed by Newman [Phys. Rev. Lett. 103, 058701 (2009)] in which the average degree is kept constant while the clustering is changed, and the other by Hackett et al. [Phys. Rev. E 83, 056107 (2011)] in which the degree distribution is kept constant. The first type of clustering is studied both analytically and numerically, and the second is studied numerically.},
author = {Shao, Shuai and Huang, Xuqing and Stanley, H Eugene and Havlin, Shlomo},
doi = {10.1103/PhysRevE.89.032812},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shao et al. - 2014 - Robustness of a partially interdependent network formed of clustered networks.pdf:pdf},
journal = {PHYSICAL REVIEW E},
title = {{Robustness of a partially interdependent network formed of clustered networks}},
volume = {89},
year = {2014}
}
@article{Boccaletti2014,
author = {Boccaletti, S and Bianconi, G and Criado, R and del Genio, Ci and G{\'{o}}mezGarde{\~{n}}es, J and Romance, M and Sendi{\~{n}}aNadal, I and Wang, Z and Zanin, M},
doi = {10.1016/j.physrep.2014.07.001},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boccaletti et al. - 2014 - The structure and dynamics of multilayer networks.pdf:pdf},
journal = {Physics Reports},
pages = {1122},
title = {{The structure and dynamics of multilayer networks}},
volume = {544},
year = {2014}
}
@article{Kivela2014,
abstract = {In most natural and engineered systems, a set of entities interact with each other in complicated patterns that can encompass multiple types of relationships, change in time and include other types of complications. Such systems include multiple subsystems and layers of connectivity, and it is important to take such 'multilayer' features into account to try to improve our understanding of complex systems. Consequently, it is necessary to generalize 'traditional' network theory by developing (and validating) a framework and associated tools to study multilayer systems in a comprehensive fashion. The origins of such efforts date back several decades and arose in multiple disciplines, and now the study of multilayer networks has become one of the most important directions in network science. In this paper, we discuss the history of multilayer networks (and related concepts) and review the exploding body of work on such networks. To unify the disparate terminology in the large body of recent work, we discuss a general framework for multilayer networks, construct a dictionary of terminology to relate the numerous existing concepts to each other and provide a thorough discussion that compares, contrasts and translates between related notions such as multilayer networks, multiplex networks, interdependent networks, networks of networks and many others. We also survey and discuss existing data sets that can be represented as M. KIVEL{\"{A}} ET AL. multilayer networks. We review attempts to generalize singlelayernetwork diagnostics to multilayer networks. We also discuss the rapidly expanding research on multilayernetwork models and notions like community structure, connected components, tensor decompositions and various types of dynamical processes on multilayer networks. We conclude with a summary and an outlook.},
author = {Kivel{\"{a}}, Mikko and Arenas, Alex and Barthelemy, Marc and Gleeson, James P and Moreno, Yamir and Porter, Mason A},
doi = {10.1093/comnet/cnu016},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kivel{\"{a}} et al. - 2014 - Multilayer networks.pdf:pdf},
journal = {Journal of Complex Networks},
pages = {203271},
title = {{Multilayer networks}},
volume = {2},
year = {2014}
}
@article{Zhou2015,
abstract = {Nature Communications 7,  (2016). doi:10.1038/ncomms10168},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Zhou, Tao and Zhang, Qian-Ming and Uuml, Linyuan L and Stanley, H Eugene},
doi = {10.1038/ncomms10168},
eprint = {arXiv:1011.1669v3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2015 - The H-index of a network node and its relation to degree and coreness.pdf:pdf},
isbn = {0123145627},
issn = {2041-1723},
journal = {Nature Communications},
pages = {1--7},
pmid = {26754161},
title = {{The H-index of a network node and its relation to degree and coreness}},
url = {http://dx.doi.org/10.1038/ncomms10168%5Cnpapers3://publication/doi/10.1038/ncomms10168},
volume = {7},
year = {2015}
}
@article{Marino2015,
abstract = {Satisfiability of large random Boolean formulas with K variables per clause (random K-satisfiability) is a fundamental problem in combinatorial discrete optimization. Here we study random K -satisfiability for K = 3, 4 by the Backtracking Survey Propagation (BSP) algorithm, which is able to find, in a time almost linear in the problem size, solutions within a region never reached before: for K = 3 the algorithmic threshold practically coincides with the SAT-UNSAT threshold, while for K=4 it extrapolates beyond the rigidity threshold, where most of the solutions acquire a positive density of frozen variables. All solutions found by BSP have no frozen variables, thus supporting the conjecture that only unfrozen solutions can be found in linear time. The iterative algorithm for determining which variables are frozen in a solution (whitening) reaches the all-variables-unfrozen fixed point following a two step process and has a relaxation time diverging at the algorithmic threshold.},
archivePrefix = {arXiv},
arxivId = {1508.05117},
author = {Marino, Raffaele and Parisi, Giorgio and Ricci-Tersenghi, Federico},
doi = {10.1038/ncomms12996},
eprint = {1508.05117},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marino, Parisi, Ricci-Tersenghi - 2015 - The Backtracking Survey Propagation Algorithm for Solving Random K-SAT Problems.pdf:pdf},
issn = {2041-1723},
journal = {Nature Communications},
pages = {1--8},
publisher = {Nature Publishing Group},
title = {{The Backtracking Survey Propagation Algorithm for Solving Random K-SAT Problems}},
url = {http://arxiv.org/abs/1508.05117},
volume = {7},
year = {2015}
}
@article{Zhang2016a,
abstract = {The pervasive presence of interconnected objects enables new communication paradigms where devices can easily reach each other while interacting within their environment. The so-called Internet of Things (IoT) represents the integration of several computing and communications systems aiming at facilitating the interaction between these devices. Arduino is one of the most popular platforms used to prototype new IoT devices due to its open, flexible and easy-to-use archi- tecture. Ardunio Yun is a dual board microcontroller that supports a Linux distribution and it is currently one of the most versatile and powerful Arduino systems. This feature positions Arduino Yun as a popular platform for developers, but it also introduces unique infection vectors from the secu- rity viewpoint. In this work, we present a security analysis of Arduino Yun. We show that Arduino Yun is vulnerable to a number of attacks and we implement a proof of concept capable of exploiting some of them.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.06655v1},
author = {Zhang, Qian and Goncalves, Bruno},
doi = {10.1145/1235},
eprint = {arXiv:1508.06655v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Goncalves - 2016 - Security Analysis and Exploitation of Arduino devices in the Internet of Things.pdf:pdf},
isbn = {9781450321389},
issn = {9781450321389},
journal = {Acm},
keywords = {4d trajectory management,importance sampling,motion planning,separation assurance,tactical planning},
pages = {6},
title = {{Security Analysis and Exploitation of Arduino devices in the Internet of Things}},
year = {2016}
}
@article{Tong2015,
abstract = {—For the purpose of propagating information and ideas through a social network, a seeding strategy aims to find a small set of seed users that are able to maximize the spread of the influence, which is termed as influence maximization problem. Despite a large number of works have studied this problem, the existing seeding strategies are limited to the static social networks. In fact, due to the high speed data transmission and the large population of participants, the diffusion processes in real-world social networks have many aspects of uncertainness. Unfortunately, as shown in the experiments, in such cases the state-of-art seeding strategies are pessimistic as they fails to trace the dynamic changes in a social network. In this paper, we study the strategies selecting seed users in an adaptive manner. We first formally model the Dynamic Independent Cascade model and introduce the concept of adaptive seeding strategy. Then based on the proposed model, we show that a simple greedy adaptive seeding strategy finds an effective solution with a provable performance guarantee. Besides the greedy algorithm an efficient heuristic algorithm is provided in order to meet practical requirements. Extensive experiments have been performed on both the real-world networks and synthetic power-law networks. The results herein demonstrate the superiority of the adaptive seeding strategies to other standard methods. Index Terms—Social network influence, adaptive seeding strategy, stochastic submodular maximization.},
archivePrefix = {arXiv},
arxivId = {arXiv:1506.06294v1},
author = {Tong, Guangmo and Wu, Weili and Tang, Shaojie and Du, Ding-zhu},
eprint = {arXiv:1506.06294v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tong et al. - 2015 - Adaptive Influence Maximization in Dynamic Social Networks.pdf:pdf},
journal = {arXiv preprint arXiv:1506.06294},
pages = {1--12},
title = {{Adaptive Influence Maximization in Dynamic Social Networks}},
year = {2015}
}
@article{Li,
author = {Li, Xiang and Smith, J David},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Smith - Unknown - Privacy Issues in Light of Reconnaissance Attacks with Incomplete Information.pdf:pdf},
title = {{Privacy Issues in Light of Reconnaissance Attacks with Incomplete Information}}
}
@article{Seeman2013,
abstract = {The algorithmic challenge of maximizing information diffusion through word-of-mouth processes in social networks has been heavily studied in the past decade. While there has been immense progress and an impressive arsenal of techniques has been developed, the algorithmic frameworks make idealized assumptions regarding access to the network that can often result in poor performance of state-of-the-art techniques. In this paper we introduce a new framework which we call Adaptive Seeding. The framework is a two-stage stochastic optimization model designed to leverage the potential that typically lies in neighboring nodes of arbitrary samples of social networks. Our main result is an algorithm which provides a constant factor approximation to the optimal adaptive policy for any influence function in the Triggering model.},
author = {Seeman, Lior and Singer, Yaron},
doi = {10.1109/FOCS.2013.56},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seeman, Singer - 2013 - Adaptive seeding in social networks.pdf:pdf},
isbn = {9780769551357},
issn = {02725428},
journal = {Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS},
keywords = {Approximation algorithms,Influence maximization,Social networks,Stochastic optimization,Submodularity},
pages = {459--468},
title = {{Adaptive seeding in social networks}},
year = {2013}
}
@article{Lei2015,
abstract = {Social networks are commonly used for marketing purposes. For example, free samples of a product can be given to a few influential social network users (or "seed nodes"), with the hope that they will convince their friends to buy it. One way to formalize marketers' objective is through influence maximization (or IM), whose goal is to find the best seed nodes to activate under a fixed budget, so that the number of people who get influenced in the end is maximized. Recent solutions to IM rely on the influence probability that a user influences another one. However, this probability information may be unavailable or incomplete. In this paper, we study IM in the absence of complete information on influence probability. We call this problem Online Influence Maximization (OIM) since we learn influence probabilities at the same time we run influence campaigns. To solve OIM, we propose a multiple-trial approach, where (1) some seed nodes are selected based on existing influence information; (2) an influence campaign is started with these seed nodes; and (3) users' feedback is used to update influence information. We adopt the Explore-Exploit strategy, which can select seed nodes using either the current influence probability estimation (exploit), or the confidence bound on the estimation (explore). Any existing IM algorithm can be used in this framework. We also develop an incremental algorithm that can significantly reduce the overhead of handling users' feedback information. Our experiments show that our solution is more effective than traditional IM methods on the partial information.},
archivePrefix = {arXiv},
arxivId = {1506.01188},
author = {Lei, Siyu and Park, Science and Kong, Hong and Cheng, Reynold},
doi = {10.1145/2783258.2783271},
eprint = {1506.01188},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lei et al. - 2015 - Online Influence Maximization.pdf:pdf},
isbn = {9781450336642},
journal = {Kdd},
pages = {645--654},
title = {{Online Influence Maximization}},
year = {2015}
}
@article{Kuhnle2016,
abstract = {The pervasive presence of interconnected objects enables new communication paradigms where devices can easily reach each other while interacting within their environment. The so-called Internet of Things (IoT) represents the integration of several computing and communications systems aiming at facilitating the interaction between these devices. Arduino is one of the most popular platforms used to prototype new IoT devices due to its open, flexible and easy-to-use archi- tecture. Ardunio Yun is a dual board microcontroller that supports a Linux distribution and it is currently one of the most versatile and powerful Arduino systems. This feature positions Arduino Yun as a popular platform for developers, but it also introduces unique infection vectors from the secu- rity viewpoint. In this work, we present a security analysis of Arduino Yun. We show that Arduino Yun is vulnerable to a number of attacks and we implement a proof of concept capable of exploiting some of them.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.06655v1},
author = {et al. Kuhnle, Alan},
doi = {10.1145/1235},
eprint = {arXiv:1508.06655v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhnle - 2016 - QoS Vulnerability Assessment of Interdependent Communication Networks.pdf:pdf},
isbn = {9781450321389},
issn = {9781450321389},
journal = {Acm},
keywords = {4d trajectory management,importance sampling,motion planning,separation assurance,tactical planning},
pages = {6},
title = {{QoS Vulnerability Assessment of Interdependent Communication Networks}},
year = {2016}
}
@article{Gao2011,
abstract = {Almost all network research has been focused on the properties of a single network that does not interact and depends on other networks. In reality, many real-world networks interact with other networks. Here we develop an analytical framework for studying interacting networks and present an exact percolation law for a network of $n$ interdependent networks. In particular, we find that for $n$ Erd\H{o}s-R\'{e}nyi networks each of average degree $k$, the giant component, $P_{\infty}$, is given by $P_{\infty}=p[1-\exp(-kP_{\infty})]^n$ where $1-p$ is the initial fraction of removed nodes. Our general result coincides for $n=1$ with the known Erd\H{o}s-R\'{e}nyi second-order phase transition for a single network. For any $n \geq 2$ cascading failures occur and the transition becomes a first-order percolation transition. The new law for $P_{\infty}$ shows that percolation theory that is extensively studied in physics and mathematics is a limiting case ($n=1$) of a more general general and different percolation law for interdependent networks.},
archivePrefix = {arXiv},
arxivId = {1010.5829},
author = {Gao, Jianxi and Buldyrev, Sergey V. and Havlin, Shlomo and Stanley, H. Eugene},
doi = {10.1103/PhysRevLett.107.195701},
eprint = {1010.5829},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gao et al. - 2011 - Robustness of a network of networks.pdf:pdf},
isbn = {02666669},
issn = {00319007},
journal = {Physical Review Letters},
number = {19},
pages = {1--5},
pmid = {21706999},
title = {{Robustness of a network of networks}},
volume = {107},
year = {2011}
}
@article{Huang2013,
abstract = {It was recently found that cascading failures can cause the abrupt breakdown of a system of interdependent networks. Using the percolation method developed for single clustered networks by Newman (Phys. Rev. Lett., 103 (2009) 058701), we develop an analytical method for studying how clustering within the networks of a system of interdependent networks affects the system's robustness. We find that clustering significantly increases the vulnerability of the system, which is represented by the increased value of the percolation threshold pc in interdependent networks.},
archivePrefix = {arXiv},
arxivId = {1205.3188},
author = {Huang, Xuqing and Shao, Shuai and Wang, Huijuan and Buldyrev, Sergey V. and {Eugene Stanley}, H. and Havlin, Shlomo},
doi = {10.1209/0295-5075/101/18002},
eprint = {1205.3188},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2013 - The robustness of interdependent clustered networks.pdf:pdf},
issn = {0295-5075, 1286-4854},
journal = {EPL (Europhysics Letters)},
number = {1},
pages = {18002},
title = {{The robustness of interdependent clustered networks}},
url = {http://iopscience.iop.org/0295-5075/101/18002%5Cnhttp://iopscience.iop.org/0295-5075/101/1/18002/pdf/0295-5075_101_1_18002.pdf},
volume = {101},
year = {2013}
}
@article{Chan2014,
author = {Chan, Hau and Akoglu, Leman and Tong, Hanghang},
doi = {10.1137/1.9781611973440.37},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chan, Akoglu, Tong - 2014 - Make It or Break It Manipulating Robustness in Large Networks.pdf:pdf},
isbn = {978-1-61197-344-0},
journal = {Proceedings of the 2014 {SIAM} International Conference on Data Mining, Philadelphia, Pennsylvania, USA, April 24-26, 2014},
pages = {325--333},
title = {{Make It or Break It: Manipulating Robustness in Large Networks}},
url = {http://dx.doi.org/10.1137/1.9781611973440.37},
year = {2014}
}
@article{Chan2016,
author = {Chan, Hau and Akoglu, Leman},
doi = {10.1007/s10618-015-0447-5},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chan, Akoglu - 2016 - Optimizing network robustness by edge rewiring a general framework.pdf:pdf},
issn = {1573756X},
journal = {Data Mining and Knowledge Discovery},
keywords = {Attack tolerance,Edge rewiring,Graph robustness,Graph spectrum,Optimization algorithms,Robustnesss measures},
number = {5},
pages = {1--31},
publisher = {Springer US},
title = {{Optimizing network robustness by edge rewiring: a general framework}},
volume = {30},
year = {2016}
}
@article{Chemistry2009,
author = {Chemistry, Applied},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chemistry - 2009 - r P Fo ee r R ev ie w On r P Fo ee w On ly.pdf:pdf},
keywords = {user supplied},
title = {{r P Fo ee r R ev ie w On r P Fo ee w On ly}},
year = {2009}
}
@misc{Bixby1995,
abstract = {Combinatorics research, the branch of mathematics that deals with the study of discrete, usually finite, structures, covers a wide range of problems not only in mathematics but also in the biological sciences, engineering, and computer science. <i>The Handbook of Combinatorics</i> brings together almost every aspect of this enormous field and is destined to become a classic. Ronald L. Graham, Martin Gr?hel, and L{\'{a}}³{\textordmasculine}l{\'{o}} &#338;¯v{\'{a}}³{\textordmasculine}, three of the world's leading combinatorialists, have compiled a selection of articles that cover combinatorics in graph theory, theoretical computer science, optimization, and convexity theory, plus applications in operations research, electrical engineering, statistical mechanics, chemistry, molecular biology, pure mathematics, and computer science.<br /> <br /> The 20 articles in Volume 1 deal with structures while the 24 articles in Volume 2 focus on aspects, tools, applications, and horizons.},
author = {Bixby, R. E. and Cunningham, W. H.},
doi = {10.1103/PhysRevLett.80.3887},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bixby, Cunningham - 1995 - Matroid optimization and algorithms.pdf:pdf},
isbn = {026207169X},
pages = {551--609},
title = {{Matroid optimization and algorithms}},
url = {http://portal.acm.org/citation.cfm?id=233157.233193%5Cnhttp://portal.acm.org/citation.cfm?id=233193},
volume = {1},
year = {1995}
}
@article{Oxley2003,
abstract = {Matroids were introduced by Whitney in 1935 to try to capture abstractly the essence of dependence. Whitney's definition em-braces a surprising diversity of combinatorial structures. Moreover, ma-troids arise naturally in combinatorial optimization since they are pre-cisely the structures for which the greedy algorithm works. This survey paper introduces matroid theory, presents some of the main theorems in the subject, and identifies some of the major problems of current research interest.},
author = {Oxley, James},
doi = {10.1038/1351033a0},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oxley - 2003 - What Is a Matroid.pdf:pdf},
isbn = {9780895269799},
issn = {0028-0836},
journal = {Cubo Matem{\'{a}}tica Educacional},
pages = {179--218},
title = {{What Is a Matroid}},
volume = {5.3},
year = {2003}
}
@article{Gargano2009,
abstract = {We consider a problem related to the submodular set cover on polymatroids, when the ground set is the family of independent sets of a matroid. The achievement here is getting a strongly polynomial running time with respect to the ground set of the matroid even though the family of independent sets has exponential size. We also address the optimization problem of the maximization of submodular set functions on the independent sets of a matroid. ?? 2008 Elsevier B.V. All rights reserved.},
author = {Gargano, Luisa and Hammar, Mikael},
doi = {10.1016/j.disc.2008.05.019},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gargano, Hammar - 2009 - A note on submodular set cover on matroids.pdf:pdf},
issn = {0012365X},
journal = {Discrete Mathematics},
keywords = {Independent sets,Matroid,Set cover},
number = {18},
pages = {5739--5744},
publisher = {Elsevier B.V.},
title = {{A note on submodular set cover on matroids}},
url = {http://dx.doi.org/10.1016/j.disc.2008.05.019},
volume = {309},
year = {2009}
}
@article{Veremyev2015,
abstract = {This article introduces a new family of Cayley graphs, called k-degree Cayley graphs, for building interconnection networks. The k-degree Cayley graph possesses many valuable topological properties, such as regularity with degree k, logarithmic diameter, and maximal fault tolerance. We present an optimal shortest path routing algorithm for the k-degree Cayley graph. Cycle- embedding and clique-embedding are also discussed.},
author = {Veremyev, Alexander and Prokipyev, Oleg A. and Pasiliao, Eduardo L.},
doi = {10.1002/net},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Veremyev, Prokipyev, Pasiliao - 2015 - Critical Nodes for Distance-Based Connectivity and Related Problems in Graphs.pdf:pdf},
isbn = {0028-3045},
issn = {1097-0037},
journal = {Networks},
keywords = {embedding,graph-theoretic interconnection networks,network topology,shortest path routing algorithm,topological properties},
title = {{Critical Nodes for Distance-Based Connectivity and Related Problems in Graphs}},
year = {2015}
}
@article{Gomes2016,
author = {Gomes, Teresa and Esposito, Christian and Hutchison, David and Kuipers, Fernando and Rak, Jacek and Tornatore, Massimo},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gomes et al. - 2016 - A survey of strategies for communication networks to protect against large-scale natural disasters.pdf:pdf},
isbn = {9781467390231},
pages = {11--22},
title = {{A survey of strategies for communication networks to protect against large-scale natural disasters}},
volume = {2011},
year = {2016}
}
@article{Chen2016,
abstract = {Critical nodes in complex systems need to be identified for protection or removal. Removal of critical nodes decreases or minimizes a system's ability to diffuse entities such as information, goods, or diseases. Previous research suggested some vulnerability metrics, but there remains a lack of understanding how a metric changes (e.g., upper bound and lower bound) and how it is related to the structure of a complex system. This research designs three metrics to assess system vulnerability, and analyzes their characteristics over different system structures. A polynomial-time algorithm using the three metrics is developed to identify critical nodes step by step (local optima). Their performance are examined and compared to other algorithms. The three metrics designed in this article are informative and their characteristics are thoroughly analyzed for various system structures. The metrics and algorithm may be used by domain experts to effectively assess system vulnerability and identify critical nodes.},
author = {Chen, Xin},
doi = {10.1016/j.eswa.2016.08.051},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen - 2016 - System vulnerability assessment and critical nodes identification.pdf:pdf},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Complex system,Graph theory,Identification for control},
pages = {212--220},
publisher = {Elsevier Ltd},
title = {{System vulnerability assessment and critical nodes identification}},
url = {http://dx.doi.org/10.1016/j.eswa.2016.08.051},
volume = {65},
year = {2016}
}
@article{Veremyev2014,
author = {Veremyev, Alexander and Prokopyev, Oleg A. and Pasiliao, Eduardo L.},
doi = {10.1007/s10878-014-9730-4},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Veremyev, Prokopyev, Pasiliao - 2014 - An integer programming framework for critical elements detection in graphs.pdf:pdf},
issn = {15732886},
journal = {Journal of Combinatorial Optimization},
keywords = {Critical edge detection,Critical node detection,Mixed integer programming,Network interdiction},
number = {1},
pages = {233--273},
title = {{An integer programming framework for critical elements detection in graphs}},
volume = {28},
year = {2014}
}
@article{Hauge2014,
author = {Hauge, Mariann and Landmark, Lars and Amanowicz, Marek},
doi = {10.2478/eletel-2014-0001},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hauge, Landmark, Amanowicz - 2014 - Selected Issues of QoS Provision in Heterogenous Military Networks.pdf:pdf},
issn = {20818491},
journal = {International Journal of Electronics and Telecommunications},
keywords = {connectivity,e2e qos,heterogenous net-,routing},
number = {1},
pages = {7--13},
title = {{Selected Issues of QoS Provision in Heterogenous Military Networks}},
volume = {60},
year = {2014}
}
@article{Galhotra,
abstract = {The steady growth of graph data from social networks has resulted in widespread research in finding solutions to the influence maximization problem. In this paper, we propose a holistic solution to the influence maximization (IM) problem. (1) We introduce an opinioncuminteraction (OI) model that closely mirrors the realworld scenarios. Under the OI model, we introduce a novel problem of Maximizing the Effective Opinion (MEO) of influenced users. We prove that the MEO problem is NPhard and cannot be approximated within a constant ratio unless P=NP. (2) We propose a heuristic algorithm OSIM to efficiently solve the MEO problem. To better explain the OSIM heuristic, we first introduce EaSyIM – the opinionoblivious version of OSIM, a scalable algorithm capable of running within practical compute times on commodity hardware. In addition to serving as a fundamental building block for OSIM, EaSyIM is capable of addressing the scalability aspect – memory consumption and running time, of the IM problem as well. Empirically, our algorithms are capable of maintaining the deviation in the spread always within 5% of the best known methods in the literature. In addition, our experiments show that both OSIM and EaSyIM are effective, efficient, scalable and significantly enhance the ability to analyze real datasets.},
author = {Galhotra, Sainyam and Arora, Akhil and Roy, Shourya},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Galhotra, Arora, Roy - Unknown - Holistic Influence Maximization Combining Scalability and Efficiency with OpinionAware Models.pdf:pdf},
title = {{Holistic Influence Maximization: Combining Scalability and Efficiency with OpinionAware Models}}
}
@article{Fan,
abstract = {We propose a class of functional dependencies for graphs, referred to as GFDs. GFDs capture both attributevalue dependencies and topological structures of entities, and subsume conditional functional dependencies (CFDs) as a special case. We show that the satisfiability and implication problems for GFDs are coNPcomplete and NPcomplete, respectively, no worse than their CFD counterparts. We also show that the validation problem for GFDs is coNPcomplete. Despite the intractability, we develop parallel scalable algorithms for catching violations of GFDs in largescale graphs. Using reallife and synthetic data, we experimentally verify that GFDs provide an effective approach to detecting inconsistencies in knowledge and social graphs.},
author = {Fan, Wenfei and Wu, Yinghui and Xu, Jingbo},
doi = {10.1145/2882903.2915232},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fan, Wu, Xu - Unknown - Functional Dependencies for Graphs.pdf:pdf},
title = {{Functional Dependencies for Graphs}}
}
@article{Gurajada,
abstract = {In this paper, we focus on the efficient and scalable processing of setreachability queries over a distributed, directed data graph. A setreachability query is a generalized form of a reachability query, in which we consider two sets S and T of source and target vertices, respectively, to be given as the query. The result of a setreachability query are all pairs of source and target vertices (s, t), with s ∈ S and t ∈ T , where s is reachable to t (denoted as S ; T). In case the data graph is partitioned into multiple, edgeand vertexdisjoint subgraphs (e.g., when distributed across multiple compute nodes in a cluster), we refer to the resulting setreachability problem as distributed set reachability. The key goal in processing a distributed setreachability query over a partitioned data graph both efficiently and in a scalable manner is (1) to avoid redundant computations within the local compute nodes as much as possible, (2) to partially evaluate the local components of a setreachability query S ; T among all compute nodes in parallel, and (3) to minimize both the size and number of messages exchanged among the compute nodes. Distributed set reachability has a plethora of applications in graph analytics and for query processing. The current W3C recommendation for SPARQL 1.1, for example, introduces a notion of labeled property paths which resolves to processing a form of generalized graphpattern queries with setreachability predicates. Moreover, analyzing dependencies among socialnetwork communities inherently involves reachability checks between large sets of source and target vertices. Our experiments confirm very significant performance gains of our approach in comparison to stateoftheart graph engines such as Giraph ++ , and over a variety of graph collections with up to 1.4 billion edges.},
author = {Gurajada, Sairam and Theobald, Martin},
doi = {10.1145/2882903.2915226},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gurajada, Theobald - Unknown - Distributed Set Reachability.pdf:pdf},
title = {{Distributed Set Reachability}}
}
@article{Henin1980,
author = {Henin, Claude and Doutriaux, Jerome},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Henin, Doutriaux - 1980 - A Specialization of the Convex Simplex Method to Cubic Programming.pdf:pdf},
journal = {Rivista di matematica per le scienze economiche e sociali},
keywords = {computation time,convergence,convex simplex method,cubic programming,directions},
number = {2},
pages = {61--72},
title = {{A Specialization of the Convex Simplex Method to Cubic Programming}},
volume = {3},
year = {1980}
}
@article{Ertem2016,
abstract = {Clique relaxations are used in classical models of cohesive subgroups in social network analysis. Clustering coefficient was introduced more recently as a structural feature characterizing small-world networks. Noting that cohesive subgroups tend to have high clustering coefficients, this paper introduces a new clique relaxation, $\alpha$-cluster, defined by enforcing a lower bound $\alpha$ on the clustering coefficient in the corresponding induced subgraph. Two variations of the clustering coefficient are considered, namely, the local and global clustering coefficient. Certain structural properties of $\alpha$-clusters are analyzed and mathematical optimization models for determining $\alpha$-clusters of the largest size in a network are developed and validated using several real-life social networks. In addition, a network clustering algorithm based on local $\alpha$-clusters is proposed and successfully tested.},
author = {Ertem, Zeynep and Veremyev, Alexander and Butenko, Sergiy},
doi = {10.1016/j.socnet.2016.01.001},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ertem, Veremyev, Butenko - 2016 - Detecting large cohesive subgroups with high clustering coefficients in social networks.pdf:pdf},
issn = {03788733},
journal = {Social Networks},
keywords = {Clique relaxations,Clustering coefficient,Cohesive subgroups,Optimization},
pages = {1--10},
publisher = {Elsevier B.V.},
title = {{Detecting large cohesive subgroups with high clustering coefficients in social networks}},
url = {http://dx.doi.org/10.1016/j.socnet.2016.01.001},
volume = {46},
year = {2016}
}
@article{Bak1987,
abstract = {We show that dynamical systems with spatial degrees of freedom naturally evolve into a self-organized critical point. Flicker noise, or 1/f noise, can be identified with the dynamics of the critical state. This picture also yields insight into the origin of fractal objects.},
author = {Bak, Per and Tang, Chao and Wiesenfeld, Kurt},
doi = {10.1103/PhysRevLett.59.381},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bak, Tang, Wiesenfeld - 1987 - Self-organized criticality An explanation of the 1f noise.pdf:pdf},
isbn = {1079-7114 (Electronic)\r0031-9007 (Linking)},
issn = {00319007},
journal = {Physical Review Letters},
number = {4},
pages = {381--384},
pmid = {10035754},
title = {{Self-organized criticality: An explanation of the 1/f noise}},
volume = {59},
year = {1987}
}
@article{Manago2015,
abstract = {Human genetic studies have recently suggested that the postsynaptic activity-regulated cytoskeleton-associated protein (Arc) complex is a convergence signal for several genes implicated in schizophrenia. However, the functional significance of Arc in schizophrenia-related neurobehavioral phenotypes and brain circuits is unclear. Here, we find that, consistent with schizophrenia-related phenotypes, disruption of Arc in mice produces deficits in sensorimotor gating, cognitive functions, social behaviors, and amphetamine-induced psychomotor responses. Furthermore, genetic disruption of Arc leads to concomitant hypoactive mesocortical and hyperactive mesostriatal dopamine pathways. Application of a D1 agonist to the prefrontal cortex or a D2 antagonist in the ventral striatum rescues Arc-dependent cognitive or psychomotor abnormalities, respectively. Our findings demonstrate a role for Arc in the regulation of dopaminergic neurotransmission and related behaviors. The results also provide initial biological support implicating Arc in dopaminergic and behavioral abnormalities related to schizophrenia. Manag?? et al. find that, consistent with schizophrenia-related phenotypes, disruption of Arc in mice produces deficits in sensorimotor gating, cognitive functions, social behaviors, and amphetamine-induced psychomotor responses. Furthermore, genetic disruption of Arc leads to concomitant hypoactive mesocortical and hyperactive mesostriatal dopamine pathways.},
author = {Manag{\`{o}}, Francesca and Mereu, Maddalena and Mastwal, Surjeet and Mastrogiacomo, Rosa and Scheggia, Diego and Emanuele, Marco and {De Luca}, Maria A. and Weinberger, Daniel R. and Wang, Kuan Hong and Papaleo, Francesco},
doi = {10.1016/j.celrep.2016.07.044},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Manag{\`{o}} et al. - 2015 - Genetic Disruption of ArcArg3.1 in Mice Causes Alterations in Dopamine and Neurobehavioral Phenotypes Related to.pdf:pdf},
issn = {22111247},
journal = {Cell Reports},
pages = {2116--2128},
pmid = {27524619},
title = {{Genetic Disruption of Arc/Arg3.1 in Mice Causes Alterations in Dopamine and Neurobehavioral Phenotypes Related to Schizophrenia}},
year = {2015}
}
@article{Beggs2003,
abstract = {Networks of living neurons exhibit diverse patterns of activity, including oscillations, synchrony, and waves. Recent work in physics has shown yet another mode of activity in systems composed of many nonlinear units interacting locally. For example, avalanches, earthquakes, and forest fires all propagate in systems organized into a critical state in which event sizes show no characteristic scale and are described by power laws. We hypothesized that a similar mode of activity with complex emergent properties could exist in networks of cortical neurons. We investigated this issue in mature organotypic cultures and acute slices of rat cortex by recording spontaneous local field potentials continuously using a 60 channel multielectrode array. Here, we show that propagation of spontaneous activity in cortical networks is described by equations that govern avalanches. As predicted by theory for a critical branching process, the propagation obeys a power law with an exponent of -3/2 for event sizes, with a branching parameter close to the critical value of 1. Simulations show that a branching parameter at this value optimizes information transmission in feedforward networks, while preventing runaway network excitation. Our findings suggest that "neuronal avalanches" may be a generic property of cortical networks, and represent a mode of activity that differs profoundly from oscillatory, synchronized, or wave-like network states. In the critical state, the network may satisfy the competing demands of information transmission and network stability.},
author = {Beggs, John M and Plenz, Dietmar},
doi = {23/35/11167 [pii]},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beggs, Plenz - 2003 - Neuronal avalanches in neocortical circuits.pdf:pdf},
isbn = {1529-2401 (Electronic)},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Animals,Computer Simulation,Electrodes,Models,Neocortex,Neocortex: cytology,Neocortex: physiology,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurological,Neurons,Neurons: physiology,Rats,Synaptic Transmission,Synaptic Transmission: physiology},
number = {35},
pages = {11167--77},
pmid = {14657176},
title = {{Neuronal avalanches in neocortical circuits.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14657176},
volume = {23},
year = {2003}
}
@article{Shew2011,
abstract = {The repertoire of neural activity patterns that a cortical network can produce constrains the ability of the network to transfer and process information. Here, we measured activity patterns obtained from multisite local field potential recordings in cortex cultures, urethane-anesthetized rats, and awake macaque monkeys. First, we quantified the information capacity of the pattern repertoire of ongoing and stimulus-evoked activity using Shannon entropy. Next, we quantified the efficacy of information transmission between stimulus and response using mutual information. By systematically changing the ratio of excitation/inhibition (E/I) in vitro and in a network model, we discovered that both information capacity and information transmission are maximized at a particular intermediate E/I, at which ongoing activity emerges as neuronal avalanches. Next, we used our in vitro and model results to correctly predict in vivo information capacity and interactions between neuronal groups during ongoing activity. Close agreement between our experiments and model suggest that neuronal avalanches and peak information capacity arise because of criticality and are general properties of cortical networks with balanced E/I.},
archivePrefix = {arXiv},
arxivId = {1012.3623},
author = {Shew, Woodrow L and Yang, Hongdian and Yu, Shan and Roy, Rajarshi and Plenz, Dietmar},
doi = {10.1523/JNEUROSCI.4637-10.2011},
eprint = {1012.3623},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shew et al. - 2011 - Information capacity and transmission are maximized in balanced cortical networks with neuronal avalanches.pdf:pdf},
isbn = {1529-2401 (Electronic)\n0270-6474 (Linking)},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Analysis of Variance,Animals,Animals, Newborn,Cerebral Cortex,Cerebral Cortex: cytology,Computer Simulation,Dose-Response Relationship, Drug,Entropy,Evoked Potentials,Evoked Potentials: drug effects,Evoked Potentials: physiology,Excitatory Amino Acid Antagonists,Excitatory Amino Acid Antagonists: pharmacology,Female,GABA Antagonists,GABA Antagonists: pharmacology,Likelihood Functions,Macaca mulatta,Male,Microelectrodes,Models, Neurological,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Organ Culture Techniques,Picrotoxin,Picrotoxin: pharmacology,Quinoxalines,Quinoxalines: pharmacology,Rats,Synaptic Transmission,Synaptic Transmission: physiology,Valine,Valine: analogs & derivatives,Valine: pharmacology},
number = {1},
pages = {55--63},
pmid = {21209189},
title = {{Information capacity and transmission are maximized in balanced cortical networks with neuronal avalanches.}},
url = {https://www.researchgate.net/publication/49731639_Information_Capacity_and_Transmission_Are_Maximized_in_Balanced_Cortical_Networks_with_Neuronal_Avalanches},
volume = {31},
year = {2011}
}
@article{Bak2001,
abstract = {We describe a mechanism for biological learning and adaptation based on two simple principles: (i) Neuronal activity propagates only through the network's strongest synaptic connections (extremal dynamics), and (ii) the strengths of active synapses are reduced if mistakes are made, otherwise no changes occur (negative feedback). The balancing of those two tendencies typically shapes a synaptic landscape with configurations which are barely stable, and therefore highly flexible. This allows for swift adaptation to new situations. Recollection of past successes is achieved by punishing synapses which have once participated in activity associated with successful outputs much less than neurons that have never been successful. Despite its simplicity, the model can readily learn to solve complicated nonlinear tasks, even in the presence of noise. In particular, the learning time for the benchmark parity problem scales algebraically with the problem size N, with an exponent k∼1.4.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0009211},
author = {Bak, Per and Chialvo, Dante R.},
doi = {10.1103/PhysRevE.63.031912},
eprint = {0009211},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bak, Chialvo - 2001 - Adaptive learning by extremal dynamics and negative feedback.pdf:pdf},
isbn = {1539-3755 (Print)},
issn = {1063-651X},
journal = {Physical Review E},
number = {3},
pages = {031912},
pmid = {11308683},
primaryClass = {cond-mat},
title = {{Adaptive learning by extremal dynamics and negative feedback}},
url = {http://link.aps.org/doi/10.1103/PhysRevE.63.031912%5Cnhttp://pre.aps.org/pdf/PRE/v63/i3/e031912},
volume = {63},
year = {2001}
}
@article{Shew2015,
abstract = {A long-standing hypothesis at the interface of physics and neuroscience is that neural networks self-organize to the critical point of a phase transition, thereby optimizing aspects of sensory information processing1–3 . This idea is partially supported by strong evidence for critical dynamics observed in the cerebral cortex4–10 , but the impact of sensory input on these dynamics is largely unknown. Thus, the foundations of this hypothesis—the self-organization process and how it manifests during strong sensory input—remain unstudied experimentally. Here we show in visual cortex and in a computational model that strong sensory input initially elicits cortical network dynamics that are not critical, but adaptive changes in the network rapidly tune the system to criticality. This conclusion is based on observations of multifaceted scaling laws predicted to occur at criticality4,11 . Our findings establish sensory adaptation as a self-organizing mechanism that maintains criticality in visual cortex during sensory information processing.},
author = {Shew, Woodrow L. and Clawson, Wesley P. and Pobst, Jeff and Karimipanah, Yahya and Wright, Nathaniel C. and Wessel, Ralf},
doi = {10.1038/nphys3370},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shew et al. - 2015 - Adaptation to sensory input tunes visual cortex to criticality.pdf:pdf},
issn = {1745-2473},
journal = {Nature Physics},
number = {June},
pages = {22--27},
title = {{Adaptation to sensory input tunes visual cortex to criticality}},
url = {http://www.nature.com/doifinder/10.1038/nphys3370},
volume = {11},
year = {2015}
}
@article{,
abstract = {The eigenvector centrality has been traditionally used to quantify the importance of a node in a network. The main contribution of the eigenvector centrality is that it takes into account the importance of the node's neighbours by giving a score to the node that is proportional to the scores of all its connected nodes. In this way, the mathematical definition of the eigenvector centrality x k of a node k is related to an iterative process were the centrality is calculated as the sum of the centralities of its neighbours: x k = $\gamma$ −1 j G kj x j , (1) where $\gamma$ is a constant, x k is the eigenvector centrality of node k and G kj are the components of the adjacency matrix. In matrix notation Eq. S1 reads $\gamma$ x = G x so that x can be expressed as a linear combination of the eigenvectors v k of the adjacency matrix G, being $\gamma$ k the set of the corresponding eigenvalues. Note that Eq. S1 can be regarded as an iterative process that begins at t = 0 with a set of initial conditions x 0 . No matter what the values of x 0 are, the value of x k (t) at t → ∞ will be proportional to the eigenvector v 1 associated to the dominant eigenvalue $\gamma$ 1 . Therefore, the eigenvector centrality is directly obtained from the eigenvector v 1 of the adjacency matrix G. The concept of eigenvector centrality can be easily extended to weighted connectivity matrices, where the weight of the connections w kj is proportional to the amount of interaction between two nodes. In the case of a weighted connectivity matrix W, we have that $\lambda$ x = W x, and the eigenvector centrality will be, in this case, obtained from eigenvector u 1 of the weighted matrix W [1].},
doi = {10.1038/NPHYS2556},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Interplay between the eigenvector centrality and the dynam- ical properties of complex networks 1.1 Definition of ei.pdf:pdf},
title = {{Interplay between the eigenvector centrality and the dynam- ical properties of complex networks 1.1 Definition of eigenvector centrality}}
}
@article{Aguirre2013,
abstract = {Competitive interactions represent one of the driving forces behind evolution and natural selection in biological and sociological systems 1,2 . For example, animals in an ecosystem may vie for food or mates; in a market economy, firms may compete over the same group of customers; sensory stimuli may compete for limited neural resources to enter the focus of attention. Here, we derive rules based on the spectral properties of the network governing the competitive interactions between groups of agents organized in networks. In the scenario studied here the winner of the competition, and the time needed to prevail, essentially depend on the way a given network connects to its competitors and on its internal structure. Our results allow assessment of the extent to which real networks optimize the outcome of their interaction, but also provide strategies through which competing networks can improve on their situation. The proposed approach is applicable to a wide range of systems that can be modelled as networks 3 . Often, the outcome of a competitive process between agents is affected not only by their direct competitors but also by the specific network of connections in which they operate. Complex networks theory offers a large number of topological measures 3 , which can be derived in a simple way from the adjacency matrix G, containing the information on network connectivity. These measures can then be used to explain important dynamical and functional properties such as robustness 4,5 , synchronization 6 , spreading 7 or congestion 8,9 . Hitherto, the emphasis has been on the properties of single isolated networks. Typically, however, networks interact with other networks, while simultaneously retaining their original identity. Recently, a few studies have examined how global structural properties or dynamical processes are affected by the existence of connected networks, showing for instance that robustness 10–13 , synchronization 14 , cooperation 15,16 , transport 17 or epidemic spreading 18–21 change markedly when considering a network of networks 22 . Interestingly, although certain types of network interdependence may enhance vulnerability with respect to the case of isolated networks 10 , the addition of links between networks may also hinder cascading processes, such as failures in a power grid, on interconnected networks 23 . This holistic view requires a broad redefinition of classical network parameters 24 . Even more importantly, one of the major challenges lies in the identification of guidelines for how to best link networks 25 . If one considers the outcome of interaction from the perspective of a single network, which is either forced into or evaluates the benefits from interacting with another one, an important challenge arises: How can I make the most of my interaction with another network? To answer this question, we consider two separate networks competing for given limited resources, which in general are related to the structural properties of the network and to the outcome of a certain dynamical process. The two networks interact by creating common links, but retain their original identity.},
author = {Aguirre, J and Papo, D and Buld{\'{u}}, J M},
doi = {10.1038/NPHYS2556},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aguirre, Papo, Buld{\'{u}} - 2013 - Successful strategies for competing networks.pdf:pdf},
journal = {Nature Physics},
title = {{Successful strategies for competing networks}},
volume = {9},
year = {2013}
}
@article{Mendis2016,
author = {Mendis, J},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mendis - 2016 - Real-time Detection of False Data Injection Attacks in Smart Grid A Deep Learning-Based Intelligent Mechanism.pdf:pdf},
title = {{Real-time Detection of False Data Injection Attacks in Smart Grid : A Deep Learning-Based Intelligent Mechanism}},
year = {2016}
}
@article{Neel2009,
abstract = {Anyone who has worked with matroids has come away with the conviction that matroids are one of the richest and most useful ideas of our day. —Gian Carlo Rota [10] Why matroids? Have you noticed hidden connections between seemingly unrelated mathematical ideas? Strange that finding roots of polynomials can tell us important things about how to solve certain ordinary differential equations, or that computing a determinant would have anything to do with finding solutions to a linear system of equations. But this is one of the charming features of mathematics—that disparate objects share similar traits. Properties like independence appear in many contexts. Do you find independence everywhere you look? In 1933, three Harvard Junior Fellows unified this recurring theme in mathematics by defining a new mathematical object that they dubbed matroid [4]. Matroids are everywhere, if only we knew how to look. What led those junior-fellows to matroids? The same thing that will lead us: Ma-troids arise from shared behaviors of vector spaces and graphs. We explore this natural motivation for the matroid through two examples and consider how properties of in-dependence surface. We first consider the two matroids arising from these examples, and later introduce three more that are probably less familiar. Delving deeper, we can find matroids in arrangements of hyperplanes, configurations of points, and geometric lattices, if your tastes run in that direction. While tying together similar structures is important and enlightening, matroids do not reside merely in the halls of pure mathematics; they play an essential role in combinatorial optimization, and we consider their role in two contexts, constructing minimum-weight spanning trees and determining optimal schedules. What's that, you say? Minimum-weight what? The mathematical details will be-come clear later, but suppose you move your company into a new office building and your 25 employees need to connect their 25 computers to each other in a network. The cable needed to do this is expensive, so you want to connect them with the least cable possible; this will form a minimum-weight spanning tree, where by weight we mean the length of cable needed to connect the computers, by spanning we mean that we reach each computer, and by tree we mean we have no redundancy in the network. How do we find this minimum length? Test all possible networks for the minimum total cost? That would be 25 23 ≈ 1.4 × 10 32 networks to consider. (There are n n−2 possible trees on n vertices; Bogart [2] gives details.) A computer checking one billion configurations per second would take over a quadrillion years to complete the task. (That's 10 15 years—a very long time.) Matroids provide a more efficient method. VOL. 82, NO. 1, FEBRUARY 2009 27 Not only are matroids useful in these optimization settings, it turns out that they are the very characterizations of the problems. Recognizing that a problem involves a matroid tells us whether certain algorithms will return an optimal solution. Knowing that an algorithm effects a solution tells us whether we have a matroid. In the undergraduate curriculum, notions of independence arise in various contexts, yet are often not tied together. Matroids surface naturally in these situations. We pro-vide a brief, accessible introduction so that matroids can be included in undergraduate courses, and so that students (or faculty!) interested in matroids have a place to start. For further study of matroids, please see Oxley's Matroid Theory [9], especially its 61-page chapter, Brief Definitions and Examples. Only a cursory knowledge of linear algebra and graph theory is assumed, so take out your pencil and work along.},
author = {Neel, David L. and Neudauer, Nancy Ann},
doi = {10.4169/193009809X469020},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Neel, Neudauer - 2009 - Matroids You Have Known.pdf:pdf},
issn = {0025570X},
journal = {Mathematics Magazine},
number = {1},
pages = {26--41},
title = {{Matroids You Have Known}},
volume = {82},
year = {2009}
}
@article{Lee2010,
author = {Lee, Jon and Sviridenko, Maxim and Vondr{\'{a}}k, Jan},
doi = {10.1287/moor.1100.0463},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Sviridenko, Vondr{\'{a}}k - 2010 - Submodular Maximization over Multiple Matroids via Generalized Exchange Properties.pdf:pdf},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
number = {4},
pages = {795--806},
title = {{Submodular Maximization over Multiple Matroids via Generalized Exchange Properties}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/moor.1100.0463},
volume = {35},
year = {2010}
}
@article{Goldberg1988,
author = {Goldberg, Andrew V. Robert E. Tarjan.},
journal = {Journal of the ACM},
number = {4},
pages = {921--940},
title = {{A new approach to the maximum-flow problem}},
volume = {35},
year = {1988}
}
@misc{Makhorin2012,
author = {Makhorin, Andrew (Moscow Aviation Institute)},
booktitle = {Free Software Foundation.},
title = {{GLPK - GNU Project - Free Software Foundation (FSF)}},
url = {https://www.gnu.org/software/glpk/},
urldate = {2016-10-17},
year = {2012}
}
@misc{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - a new approach.pdf.pdf:pdf},
title = {a new approach.pdf}
}
@book{Vermesan2014,
author = {Vermesan, Ovidi and Friess, Peter.},
booktitle = {River Publishers},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vermesan, Friess - 2013 - Internet of Things -- From Research and Innovation to Market Deployment.pdf:pdf},
isbn = {9788793102941},
pages = {60},
title = {{Internet of Things -- From Research and Innovation to Market Deployment}},
year = {2013}
}
@misc{InstituteofElectricalandElectronicsEngineers,
author = {{Institute of Electrical and Electronics Engineers}, Inc.},
title = {{IEEE 802.1 Time-Sensitive Networking Task Group}},
url = {www.ieee802.org/1/pages/tsn.html},
urldate = {2016-10-16}
}
@article{Zuehlke2010,
abstract = {In 1991, Mark Weiser described the vision of a future world under the name of Ubiquitous Computing. Since then, many details of the described vision have become reality: Our mobile phones are powerful multimedia systems, our cars computer systems on wheels, and our homes are turning into smart living environments. All these advances must be turned into products for very cost-sensitive world markets in shorter cycles than ever before. Today, the resulting requirements for design, setup, and operation of our factories become crucial for success. In the past, we often increased the complexity in structures and control systems, resulting in inflexible monolithic production systems. But the future must become "lean"-not only in organization, but also in planning and technology!Wemust develop technologies which allow us to speed up planning and setup, to adapt to rapid product changes during operation, and to reduce the planning effort. To meet these challenges we should also make use of the smart technologies of our daily lives. But for industrial use, there are many open questions to be answered. The existing technologies may be acceptable for consumer use but not yet for industrial applications with high safety and security requirements. Therefore, the SmartFactoryKL initiative was founded by industrial and academic partners to create and operate a demonstration and research test bed for future factory technologies. Many projects develop, test, and evaluate new solutions. This presentation describes changes and challenges, and it summarizes the experience gained to date in the SmartFactoryKL. ?? 2010 Elsevier Ltd.},
author = {Zuehlke, Detlef},
doi = {10.1016/j.arcontrol.2010.02.008},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zuehlke - 2010 - SmartFactory-Towards a factory-of-things.pdf:pdf},
isbn = {1367-5788},
issn = {13675788},
journal = {Annual Reviews in Control},
keywords = {Digital factory,HMI,Internet-of-things,OPC,RFID,SoA,Wireless network},
number = {1},
pages = {129--138},
title = {{SmartFactory-Towards a factory-of-things}},
volume = {34},
year = {2010}
}
@article{Xu2014,
abstract = {Internet of Things (IoT) has provided a promising opportunity to build powerful industrial systems and applications by leveraging the growing ubiquity of RFID, wireless, mobile and sensor devices. A wide range of industrial IoT applications have been developed and deployed in recent years. In an effort to understand the development of IoT in industries, this paper reviews the current research of IoT, key enabling technologies, major IoT applications in industries and identifies research trends and challenges. A main contribution of this review paper is that it summarizes the current state-of-the-art of IoT in industries systematically.},
author = {Xu, Li Da and He, Wu and Li, Shancang},
doi = {10.1109/TII.2014.2300753},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu, He, Li - 2014 - Internet of things in industries A survey.pdf:pdf},
isbn = {1551-3203 VO - PP},
issn = {15513203},
journal = {IEEE Transactions on Industrial Informatics},
keywords = {Big data analytics,Wireless sensor networks (WSNs),enterprise systems,industrial informatics,information and communications technology (ICT),internet of things (IoT),near field communications,radio-frequency identification (RFID)},
number = {4},
pages = {2233--2243},
title = {{Internet of things in industries: A survey}},
volume = {10},
year = {2014}
}
@article{Henneke2016,
author = {Henneke, Dominik and Wisniewski, Lukasz and Jasperneite, Jurgen},
doi = {10.1109/WFCS.2016.7496525},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Henneke, Wisniewski, Jasperneite - 2016 - Analysis of realizing a future industrial network by means of Software-Defined Networking (SDN.pdf:pdf},
isbn = {9781509023394},
journal = {IEEE International Workshop on Factory Communication Systems - Proceedings, WFCS},
title = {{Analysis of realizing a future industrial network by means of Software-Defined Networking (SDN)}},
volume = {2016-June},
year = {2016}
}
@article{Sadeghi2015,
abstract = {The future Internet of Things as an intelligent collaboration of minia- turized sensors poses new challenges to security and end-user privacy. The ITU has identified that the protection of data and privacy of users is one of the key chal- lenges in the Internet of Things [Int05]: lack of confidence about privacy will result in decreased adoption among users and therefore is one of the driving factors in the success of the Internet of Things. This paper gives an overview, categorization, and analysis of security and privacy challenges in the Internet of Things.},
author = {Sadeghi, Ahmad-Reza and Wachsmann, Christian and Waidner, Michael},
doi = {10.1145/2744769.2747942},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sadeghi, Wachsmann, Waidner - 2015 - Security and Privacy Challenges in Industrial Internet of Things.pdf:pdf},
isbn = {9781450335201},
issn = {18632122},
journal = {Proceedings of the 52nd Annual Design Automation Conference on - DAC '15},
keywords = {future internet,global sensor networks,privacy,security},
pages = {1--6},
title = {{Security and Privacy Challenges in Industrial Internet of Things}},
url = {http://eceasst.cs.tu-berlin.de/index.php/eceasst/issue/view/24%5Cnhttp://dl.acm.org/citation.cfm?doid=2744769.2747942},
volume = {17},
year = {2015}
}
@article{Thrybom2009,
abstract = {As Industrial Ethernet evolves it will increasingly include integration with the {\^{A}}¿IT network{\^{A}}¿ in order to utilize the benefits which the use of Ethernet provides. This will result in a mixed protocol environment also in the industrial networks, which in turn will require proper usage of QoS in order to maintain the demanding requirements of latency, jitter and packet loss in the Industrial Ethernet protocols. This paper highlights the emerging need for using QoS as well as some other related technologies in Industrial Ethernet networks and outlines some guidelines to achieve well-performing networks and efficient communication both for real-time control data and other less time critical data.},
author = {Thrybom, Linus and Prytz, Gunnar},
doi = {10.1109/ETFA.2009.5346995},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thrybom, Prytz - 2009 - QoS in Switched Industrial Ethernet.pdf:pdf},
isbn = {9781424427284},
journal = {IEEE Conference on Emerging Technologies and Factory Automation},
title = {{QoS in Switched Industrial Ethernet}},
year = {2009}
}
@article{Atzori2010,
abstract = {This paper addresses the Internet of Things. Main enabling factor of this promising paradigm is the integration of several technologies and communications solutions. Identification and tracking technologies, wired and wireless sensor and actuator networks, enhanced communication protocols (shared with the Next Generation Internet), and distributed intelligence for smart objects are just the most relevant. As one can easily imagine, any serious contribution to the advance of the Internet of Things must necessarily be the result of synergetic activities conducted in different fields of knowledge, such as telecommunications, informatics, electronics and social science. In such a complex scenario, this survey is directed to those who want to approach this complex discipline and contribute to its development. Different visions of this Internet of Things paradigm are reported and enabling technologies reviewed. What emerges is that still major issues shall be faced by the research community. The most relevant among them are addressed in details. ?? 2010 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Atzori, Luigi and Iera, Antonio and Morabito, Giacomo},
doi = {10.1016/j.comnet.2010.05.010},
eprint = {arXiv:1011.1669v3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Atzori, Iera, Morabito - 2010 - The Internet of Things A survey.pdf:pdf},
isbn = {1389-1286},
issn = {13891286},
journal = {Computer Networks},
keywords = {Internet of Things,Pervasive computing,RFID systems},
number = {15},
pages = {2787--2805},
pmid = {25246403},
publisher = {Elsevier B.V.},
title = {{The Internet of Things: A survey}},
url = {http://dx.doi.org/10.1016/j.comnet.2010.05.010},
volume = {54},
year = {2010}
}
@inproceedings{Cheriyan,
author = {Cheriyan, Joseph and Karloff, Howard and Rabini, Yuval},
booktitle = {Proceedings 42nd IEEE Symposium on Foundations of Computer Science},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheriyan, Karloff, Rabini - 2001 - Approximating directed multicuts.pdf:pdf},
publisher = {IEEE},
title = {{Approximating directed multicuts}},
year = {2001}
}
@article{Ford1956,
author = {Ford, L. R. and Fulkerson, D. R.},
journal = {Canad. J. Math},
pages = {399--404},
title = {{Sur le probleme des courbes gauches en topologie}},
volume = {8},
year = {1956}
}
@article{Grubesic2008,
abstract = {A common theme in analysis and evaluation of network-based critical infrastructure is the assessment of system vulnerability. Graph theoretic, simulation, and optimization-based techniques have played a significant role in examining potential network vulnerabilities given the insights they can provide for mitigating facility loss and prioritizing fortification efforts. Central to these approaches is the concept of facility (arc—node) importance or criticality to system survivability. Assessments of network vulnerability can dramatically differ based on how facility importance is characterized. In this review, various approaches for assessing facility importance and network vulnerability are examined. The key differences in these approaches are the ways in which a facility's role in maintaining network operability is evaluated given arc—node disruption. Comparative results suggest significant differences exist among measures of facility importance and network performance. Furthermore, the subsequent incongruities in these measures and their implications need to be clearly understood to support interdiction risk and vulnerability assessment for critical infrastructures.},
author = {Grubesic, Tony H and Matisziw, Timothy C and Murray, Alan T and Snediker, Diane},
doi = {10.1177/0160017607308679},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grubesic et al. - 2008 - Comparative Approaches for Assessing Network Vulnerability.pdf:pdf},
isbn = {0160-0176},
issn = {0160-0176},
journal = {International Regional Science Review},
keywords = {critical infrastructure,graph theory,interdiction,networks,scale-free networks},
number = {1},
pages = {88--112},
title = {{Comparative Approaches for Assessing Network Vulnerability}},
url = {http://irx.sagepub.com/cgi/content/abstract/31/1/88},
volume = {31},
year = {2008}
}
@article{Dinur2005,
abstract = {We prove the Minimum Vertex Cover problem to be NP-hard to approximate to within a factor of 1.3606, extending on previous PCP and hardness of approximation technique. To that end, one needs to develop a new proof framework, and to borrow and extend ideas from several fields.},
author = {Dinur, Irit and Safra, Samuel},
doi = {10.4007/annals.2005.162.439},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dinur, Safra - 2005 - On the hardness of approximating vertex cover.pdf:pdf},
issn = {0003-486X},
journal = {Annals of Mathematics},
number = {1},
pages = {439--485},
title = {{On the hardness of approximating vertex cover}},
volume = {162},
year = {2005}
}
@article{Dinh2012b,
abstract = {Society relies heavily on its networked physical infrastructure and information systems. Accurately assessing the vulnerability of these systems against disruptive events is vital for planning and risk management. Existing approaches to vulnerability assessments of large-scale systems mainly focus on investigating inhomogeneous properties of the underlying graph elements. These measures and the associated heuristic solutions are limited in evaluating the vulnerability of large-scale network topologies. Furthermore, these approaches often fail to provide performance guarantees of the proposed solutions. In this paper, we propose a vulnerability measure, pairwise connectivity, and use it to formulate network vulnerability assessment as a graph-theoretical optimization problem, referred to as -disruptor. The objective is to identify the minimum set of critical network elements, namely nodes and edges, whose removal results in a specific degradation of the network global pairwise connectivity. We prove the NP-completeness and inapproximability of this problem and propose an pseudo-approximation algorithm to computing the set of critical nodes and an pseudo-approximation algorithm for computing the set of critical edges. The results of an extensive simulation-based experiment show the feasibility of our proposed vulnerability assessment framework and the efficiency of the proposed approximation algorithms in comparison to other approaches.},
author = {Dinh, Thang N. and Xuan, Ying and Thai, My T. and Pardalos, Panos M. and Znati, Taieb},
doi = {10.1109/TNET.2011.2170849},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dinh et al. - 2012 - On new approaches of assessing network vulnerability Hardness and approximation.pdf:pdf},
isbn = {1063-6692},
issn = {10636692},
journal = {IEEE/ACM Transactions on Networking},
keywords = {Approximation algorithm,hardness,network vulnerability,pairwise connectivity},
number = {2},
pages = {609--619},
title = {{On new approaches of assessing network vulnerability: Hardness and approximation}},
volume = {20},
year = {2012}
}
@book{Colbourn1987,
abstract = {This books deals with the analysis of networks where reliability is a principal design factor, as in computer communications, voice communications, computer architecture, command and control systems, and lifeline systems. Starting with a simple probabilistic network model, this monograph develops combinatorial tools which are useful for reliability analysis within the model. Basic results in combinatorial enumeration are reviewed, along with classical theorems on connectivity and cutsets. The presentation highlights combinatorial ideas with proofs or sketches of proofs for most of the main ideas, and details are presented wherever feasible.},
author = {Colbourn, C J},
booktitle = {Oxford University Press, Inc.},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Colbourn - 1987 - The Combinatorics of Network Reliability.pdf:pdf},
isbn = {0195049209},
keywords = {BIBLIOGRAPHIES (CI),BOOKS,C: CG7 SURVEYS,C: CM5.2 COMBINATORIAL MATHEMATICS/SET THEORY,C: CM9.1 PROPERTIES AND ATTRIBUTES OF SYSTEMS,Computer & Information Systems (CI),combinatorial mathematics,networks,proof theory,reliability},
title = {{The Combinatorics of Network Reliability.}},
url = {http://search.proquest.com/docview/24726015?accountid=14116%5Cnhttp://ensor.lib.strath.ac.uk/sfxlcl41?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ:computerinfo&atitle=The+Combinatorics+of+Network+Reliability.&ti},
year = {1987}
}
@article{Arulselvan2009,
abstract = {Identifying critical nodes in a graph is important to understand the structural characteristics and the connectivity properties of the network. In this paper, we focus on detecting critical nodes, or nodes whose deletion results in the minimum pair-wise connectivity among the remaining nodes. This problem, known as the critical node problem has applications in several fields including biomedicine, telecommunications, and military strategic planning. We show that the recognition version of the problem is NP-complete and derive a mathematical formulation based on integer linear programming. In addition, we propose a heuristic for the problem which exploits the combinatorial structure of the graph. The heuristic is then enhanced by the application of a local improvement method. A computational study is presented in which we apply the integer programming formulation and the heuristic to real and randomly generated data sets. For all instances tested, the heuristic is able to efficiently provide optimal solutions in a fraction of the time required by a commercial software package.},
author = {Arulselvan, Ashwin and Commander, Clayton W. and Elefteriadou, Lily and Pardalos, Panos M.},
doi = {10.1016/j.cor.2008.08.016},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arulselvan et al. - 2009 - Detecting critical nodes in sparse graphs.pdf:pdf},
isbn = {03050548},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Combinatorial optimization,Critical node detection,Heuristics,Integer linear programming,NP-complete},
number = {7},
pages = {2193--2200},
title = {{Detecting critical nodes in sparse graphs}},
volume = {36},
year = {2009}
}
@article{Xue2007,
abstract = {A fundamental problem in quality-of-service (QoS) routing is to find a path between a source-destination node pair that satisfies two or more end-to-end QoS constraints. We model this problem using a graph with n vertices and m edges with K additive QoS parameters associated with each edge, for any constant Kges2. This problem is known to be NP-hard. Fully polynomial time approximation schemes (FPTAS) for the case of K=2 have been reported in the literature. We concentrate on the general case and make the following contributions. 1) We present a very simple (Km+nlogn) time K-approximation algorithm that can be used in hop-by-hop routing protocols. 2) We present an FPTAS for one optimization version of the QoS routing problem with a time complexity of O(m(n/epsi)<sup>K-1</sup>). 3) We present an FPTAS for another optimization version of the QoS routing problem with a time complexity of O(nlogn+m(H/epsi)<sup>K-1</sup>) when there exists an H-hop path satisfying all QoS constraints. When K is reduced to 2, our results compare favorably with existing algorithms. The results of this paper hold for both directed and undirected graphs. For ease of presentation, undirected graph is used},
author = {Xue, Guoliang and Sen, Arunabha and Zhang, Weiyi and Tang, Jian and Thulasiraman, Krishnaiya},
doi = {10.1109/TNET.2006.890089},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xue et al. - 2007 - Finding a path subject to many additive QoS constraints.pdf:pdf},
issn = {10636692},
journal = {IEEE/ACM Transactions on Networking},
keywords = {Efficient approximation algorithms,Multiple additive constraints,QoS routing},
number = {1},
pages = {201--211},
title = {{Finding a path subject to many additive QoS constraints}},
volume = {15},
year = {2007}
}
@inproceedings{Medina2001,
abstract = {Effective engineering of the Internet is predicated upon a\ndetailed understanding of issues such as the large-scale structure of\nits underlying physical topology, the manner in which it evolves over\ntime, and the way in which its constituent components contribute to its\noverall function. Unfortunately, developing a deep understanding of\nthese issues has proven to be a challenging task, since it in turn\ninvolves solving difficult problems such as mapping the actual topology,\ncharacterizing it, and developing models that capture its emergent\nbehavior. Consequently, even though there are a number of topology\nmodels, it is an open question as to how representative the generated\ntopologies they generate are of the actual Internet. Our goal is to\nproduce a topology generation framework which improves the state of the\nart and is based on the design principles of representativeness,\ninclusiveness, and interoperability. Representativeness leads to\nsynthetic topologies that accurately reflect many aspects of the actual\nInternet topology (e.g. hierarchical structure, node degree\ndistribution, etc.). Inclusiveness combines the strengths of as many\ngeneration models as possible in a single generation tool.\nInteroperability provides interfaces to widely-used simulation\napplications such as ns and SSF and visualization tools like otter. We\ncall such a tool a universal topology generator},
author = {et al. Medina, Alberto},
booktitle = {Modeling, Analysis and Simulation of Computer and Telecommunication Systems, 2001. Proceedings. Ninth International Symposium on},
doi = {10.1109/MASCOT.2001.948886},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Medina - 2001 - BRITE An approach to universal topology generation.pdf:pdf},
isbn = {0-7695-1315-8},
issn = {1526-7639},
keywords = {accurate synthetic topologies,annotated topologies,be very useful to,for both,graph models,growth models,have topology generation tools,network ciated with generating,simulation groups it would,topology,topology generation},
pages = {346--353},
publisher = {IEEE},
title = {{BRITE: An approach to universal topology generation.}},
year = {2001}
}
@article{Xue2007,
abstract = {A fundamental problem in quality-of-service (QoS) routing is to find a path between a source-destination node pair that satisfies two or more end-to-end QoS constraints. We model this problem using a graph with n vertices and m edges with K additive QoS parameters associated with each edge, for any constant Kges2. This problem is known to be NP-hard. Fully polynomial time approximation schemes (FPTAS) for the case of K=2 have been reported in the literature. We concentrate on the general case and make the following contributions. 1) We present a very simple (Km+nlogn) time K-approximation algorithm that can be used in hop-by-hop routing protocols. 2) We present an FPTAS for one optimization version of the QoS routing problem with a time complexity of O(m(n/epsi)<sup>K-1</sup>). 3) We present an FPTAS for another optimization version of the QoS routing problem with a time complexity of O(nlogn+m(H/epsi)<sup>K-1</sup>) when there exists an H-hop path satisfying all QoS constraints. When K is reduced to 2, our results compare favorably with existing algorithms. The results of this paper hold for both directed and undirected graphs. For ease of presentation, undirected graph is used},
author = {Xue, Guoliang and Sen, Arunabha and Zhang, Weiyi and Tang, Jian and Thulasiraman, Krishnaiya},
doi = {10.1109/TNET.2006.890089},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xue et al. - 2007 - Finding a path subject to many additive QoS constraints.pdf:pdf},
issn = {10636692},
journal = {IEEE/ACM Transactions on Networking},
keywords = {Efficient approximation algorithms,Multiple additive constraints,QoS routing},
number = {1},
pages = {201--211},
title = {{Finding a path subject to many additive QoS constraints}},
volume = {15},
year = {2007}
}
@article{Wang2016a,
author = {Wang, Zengfu and Moran, Bill and Wang, Xuezhi},
doi = {10.1007/s10878-014-9707-3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Moran, Wang - 2016 - Approximation for maximizing monotone non-decreasing set functions with a greedy method.pdf:pdf},
issn = {1382-6905},
journal = {Journal of Combinatorial Optimization},
keywords = {Approximation algorithm,Matroid,Monotone submodular set function},
pages = {29--43},
publisher = {Springer US},
title = {{Approximation for maximizing monotone non-decreasing set functions with a greedy method}},
url = {http://dx.doi.org/10.1007/s10878-014-9707-3},
year = {2016}
}
@article{Bonchi2014,
abstract = {گرافهای غیرقطعی},
author = {Bonchi, Francesco and Gullo, Francesco and Kaltenbrunner, Andreas and Volkovich, Yana},
doi = {10.1145/2623330.2623655},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bonchi et al. - 2014 - Core decomposition of uncertain graphs.pdf:pdf},
isbn = {9781450329569},
journal = {Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '14},
keywords = {core decomposition,dense subgraph,uncertain graphs},
pages = {1316--1325},
title = {{Core decomposition of uncertain graphs}},
url = {http://dl.acm.org/citation.cfm?id=2623330.2623655},
year = {2014}
}
@inproceedings{Agarwal2007,
address = {New York, NY USA},
author = {Agarwal, Amit and Alon, Noga and Charikar, Moses S},
booktitle = {Proceedings of the thirty-ninth annual ACM symposium on Theory of Computing},
doi = {10.1145/1250790.1250888},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Agarwal, Alon, Charikar - 2007 - Improved approximation for directed cut problems.pdf:pdf},
isbn = {9781595936318},
issn = {07378017},
keywords = {approximation algorithm,directed multicut,directed spars-,est cut,grant ccr-0205594,linear programming relaxation,nsf ca-,supported by nsf itr},
pages = {671--680},
publisher = {ACM},
title = {{Improved approximation for directed cut problems}},
year = {2007}
}
@article{Garg1993a,
abstract = {Without Abstract},
annote = {This one should be cited for the T-multi-pcut NP-hardness.},
author = {Garg, Naveen and Vazirani, Vijay and Yannakakis, Mihalis},
doi = {10.1007/3-540-56939-1_62},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garg, Vazirani, Yannakakis - 1997 - Primal-dual approximation algorithms for integral flow and multicut in trees, with applications to m.pdf:pdf},
issn = {0178-4617},
journal = {Algorithmica1},
keywords = {1,and a list of,approximation algorithm,c,e,e e,edges separating each pair,find a m i,follows,given a graph g,i,i n t r,integral multicommcxlity flow,k,m is defined as,m weight set of,max snp-hard,multicut,n i m u,o b l e,o d u c,of,on every edge e,or capacity,pairs,si,t i o n,the multicut p r,ti,v,vertex,with a positive weight},
number = {3},
title = {{Primal-dual approximation algorithms for integral flow and multicut in trees, with applications to matching and set cover}},
volume = {18},
year = {1997}
}
@inproceedings{Gupta2003,
author = {Gupta, A},
booktitle = {Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta - 2003 - Improved results for directed multicut.pdf:pdf},
pages = {454--455},
title = {{Improved results for directed multicut}},
year = {2003}
}
@inproceedings{Garg1994,
address = {Berlin},
author = {Garg, Naveen and Vazirani, Vijay V. and Yannakakis, Mihalis},
booktitle = {International Colloquium on Automata, Languages, and Programming.},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garg, Vazirani, Yannakakis - 1994 - Multiway Cuts in Directed and Node Weighted Graphs.pdf:pdf},
publisher = {Springer-Verlag},
title = {{Multiway Cuts in Directed and Node Weighted Graphs}},
year = {1994}
}
@book{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Graph theory.pdf:pdf},
title = {{Graph theory}}
}
@article{Feige1998,
abstract = {Abstract. Given a collection ^ of subsets of S 5 {1, . . . , n}, set cover is the problem of selecting as few as possible subsets from ^ such that their union covers S, and max k-cover is the problem of selecting k subsets from ^ such that their union has maximum cardinality. Both these problems are NP-hard. We prove that (1 2 o(1)) ln n is a threshold below which set cover cannot be approximated efficiently, unless NP has slightly superpolynomial time algorithms. This closes the gap (up to low-order terms) between the ratio of approximation achievable by the greedy algorithm (which is (1 2 o(1)) ln n), and previous results of Lund and Yannakakis, that showed hardness of approximation within a ratio of (log2 n)/ 2 . 0.72 ln n. For max k-cover, we show an approximation threshold of (1 2 1/e) (up to low-order terms), under the assumption that P Þ NP.},
author = {Feige, Uriel},
doi = {10.1145/285055.285059},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feige - 1998 - A threshold of ln n for approximating set cover.pdf:pdf},
issn = {00045411},
journal = {Journal of the ACM},
number = {4},
pages = {634--652},
title = {{A threshold of ln n for approximating set cover}},
volume = {45},
year = {1998}
}
@article{Bertsimas1999,
author = {Bertsimas, Dimitris and Teo, Chung‐Piaw and Vohra, Rakesh},
doi = {10.1002/(SICI)1097-0037(199909)34:2<102::AID-NET3>3.3.CO;2-O},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsimas, Teo, Vohra - 1999 - Analysis of LP relaxations for multiway and multicut problems.pdf:pdf},
issn = {00283045},
journal = {Networks},
keywords = {lp relaxation,multicut problems,randomized rounding},
number = {2},
pages = {102--114},
title = {{Analysis of LP relaxations for multiway and multicut problems}},
url = {http://doi.wiley.com/10.1002/(SICI)1097-0037(199909)34:2%3C102::AID-NET3%3E3.3.CO;2-O},
volume = {34},
year = {1999}
}
@article{Trevisan2004,
author = {Trevisan, Luca},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Trevisan - 2004 - Inapproximability of Combinatorial Optimization Problems Introduction.pdf:pdf},
number = {65},
pages = {1--39},
title = {{Inapproximability of Combinatorial Optimization Problems Introduction}},
volume = {65},
year = {2004}
}
@article{Chawla2006,
abstract = {Abstract. We show that the Multicut, {Sparsest-Cut}, and {Min-2CNF} ≡ Deletion problems are {NP}-hard to approximate within every constant factor, assuming the Unique Games Conjecture of Khot (2002). A quantitatively stronger version of the conjecture implies an inapproximability factor of \\$\\$$\Omega$(\\sqrt\\log \\log n).\\$\\$},
author = {Chawla, Shuchi and Krauthgamer, Robert and Kumar, Ravi and Rabani, Yuval and Sivakumar, D.},
doi = {10.1007/s00037-006-0210-9},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chawla et al. - 2006 - On the hardness of approximating multicut and sparsest-cut.pdf:pdf},
isbn = {0769523641},
issn = {10163328},
journal = {Computational Complexity},
keywords = {Fourier analysis,Multicut,Sparsest-cut,Unique games conjecture},
number = {2},
pages = {94--114},
title = {{On the hardness of approximating multicut and sparsest-cut}},
volume = {15},
year = {2006}
}
@article{Cullina,
author = {Cullina, Daniel},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cullina - Unknown - Improved Achievability and Converse Bounds for Erd os-R{\'{e}}nyi Graph Matching.pdf:pdf},
isbn = {9781450342667},
pages = {63--72},
title = {{Improved Achievability and Converse Bounds for Erd os-R{\'{e}}nyi Graph Matching}}
}
@article{Garetto2016,
abstract = {Bootstrap percolation is a well-known activation process in a graph, in which a node becomes active when it has at least $r$ active neighbors. Such process, originally studied on regular structures, has been recently investigated also in the context of random graphs, where it can serve as a simple model for a wide variety of cascades, such as the spreading of ideas, trends, viral contents, etc. over large social networks. In particular, it has been shown that in $G(n,p)$ the final active set can exhibit a phase transition for a sub-linear number of seeds. In this paper, we propose a unique framework to study similar sub-linear phase transitions for a much broader class of graph models and epidemic processes. Specifically, we consider i) a generalized version of bootstrap percolation in $G(n,p)$ with random activation thresholds and random node-to-node influences; ii) different random graph models, including graphs with given degree sequence and graphs with community structure (block model). The common thread of our work is to show the surprising sensitivity of the critical seed set size to extreme values of distributions, which makes some systems dramatically vulnerable to large-scale outbreaks. We validate our results running simulation on both synthetic and real graphs.},
archivePrefix = {arXiv},
arxivId = {1603.04643},
author = {Garetto, Michele and Leonardi, Emilio and Torrisi, Giovanni Luca},
doi = {10.1145/2896377.2901455},
eprint = {1603.04643},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garetto, Leonardi, Torrisi - 2016 - Generalized threshold-based epidemics in random graphs the power of extreme values.pdf:pdf},
isbn = {9781450342667},
pages = {37--50},
title = {{Generalized threshold-based epidemics in random graphs: the power of extreme values}},
url = {http://arxiv.org/abs/1603.04643},
year = {2016}
}
@article{Buchnik2015,
abstract = {Distances in a network capture relations between nodes and are the basis of centrality, similarity, and influence measures. Often, however, the relevance of a node $u$ to a node $v$ is more precisely measured not by the magnitude of the distance, but by the number of nodes that are closer to $v$ than $u$. That is, by the {\em rank} of $u$ in an ordering of nodes by increasing distance from $v$. Accordingly, rank-based measures provide a semantically different alternative to distance-based measures. In contrast to single-source distances (and "forward" ranks), which can be computed in near-linear time by Dijkstra's algorithm, we show that {\em exact} reverse ranks for a single source are, in the worst-case, as hard to compute as all-pairs shortest paths, and thus can not be scalably computed even on a medium size graph. Our main contribution is the first scalable algorithm to compute {\em approximate} reverse ranks within a small relative error. Our design uses near-linear processing of the graph, after which we can perform "Dijkstra-like" single-source computations that return nodes in order of increasing approximate reverse rank. Another contribution we make that is of independent interest is a novel algorithm for computing all-distances sketches, which we use for preprocessing, on multi-core architectures. We conduct an experimental evaluation on graphs with hundreds of millions of edges, demonstrating both scalability and accuracy. Finally, we define reverse-rank influence, which naturally extends reverse nearest neighbors influence [Korn and Muthukrishnan 2000] and show how our reverse-rank single-source computation facilitates scalable greedy reverse-rank influence maximization.},
archivePrefix = {arXiv},
arxivId = {1506.02386},
author = {Buchnik, E and Cohen, E},
eprint = {1506.02386},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buchnik, Cohen - 2015 - Reverse Ranking by Graph Structure Model and Scalable Algorithms.pdf:pdf},
isbn = {9781450342667},
journal = {arXiv preprint arXiv:1506.02386},
pages = {51--62},
title = {{Reverse Ranking by Graph Structure: Model and Scalable Algorithms}},
url = {http://arxiv.org/abs/1506.02386},
year = {2015}
}
@article{Serra2014,
abstract = {There are many applications (e.g., counter-terrorism) where we can automatically learn a quantitative model from realworld data about terror group behavior. In this paper, we first provide a survey of quantitative models of terrorist groups. To date, however, the best-known quantitative models of terror group behavior are based on various types of quantitative logic programs. After our survey, we address an important question posed to us by Nobel laureate, Tom Schelling. Once a set of quantitative logic behavior rules about an adversary has been learned, should these rules be disclosed or not? We develop a game theoretic framework in order to answer this question with a defender who has to decide what rules to release publicly and which ones to keep hidden. We first study the attacker's optimal attack strategy, given a set of disclosed rules, and then we study the problem of which rules to disclose so that the attacker's optimal strategy has minimal effectiveness. We study the complexity of both problems, present algorithms to solve both, and then present a (1-1/e )-approximation algorithm that (under some restrictions) uses a submodularity property to compute the optimal defender strategy. Finally, we provide experimental results showing that our framework works well in practice-these results are also shown to be statistically significant.},
author = {Serra, Edoardo and Subrahmanian, V. S.},
doi = {10.1109/TCSS.2014.2307454},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Serra, Subrahmanian - 2014 - A Survey of Quantitative Models of Terror Group Behavior and an Analysis of Strategic Disclosure of Behavio.pdf:pdf},
isbn = {2329-924X VO  - 1},
issn = {2329-924X},
journal = {IEEE Transactions on Computational Social Systems},
number = {1},
pages = {66--88},
title = {{A Survey of Quantitative Models of Terror Group Behavior and an Analysis of Strategic Disclosure of Behavioral Models}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6804661},
volume = {1},
year = {2014}
}
@article{Ogura2016,
abstract = {We analyze the dynamics of spreading processes taking place over time-varying networks. A common heuristic is to use an aggregated static network based on time averages. Instead, we introduce a flexible and tractable random graph process that extends the family of Markovian random graphs (MRG). One of the main limitations of MRG's is that it can only replicate switching patterns with exponential inter-switching times. To overcome this limitation, we propose the family of aggregated-Markovian random graph processes, which is able to replicate, with arbitrary accuracy, any distribution of inter-switching times. We study the stability spreading processes in this extended family. We first show that a direct analysis based on the It\^o formula provide conditions in terms of the eigenvalues of a matrix whose size grows exponentially with the number of edges. Using alternative tools, we derive stability conditions involving the eigenvalues of a matrix whose size grows linearly with the number of nodes. Based on our results, we show that the aggregated static network approximates the epidemic threshold more accurately as the number of nodes grows, or the temporal volatility of the random graph process is reduced. Apart from these theoretical results, we illustrate our findings via numerical simulations.},
archivePrefix = {arXiv},
arxivId = {1507.07017},
author = {Ogura, Masaki and Preciado, Victor M.},
doi = {10.1109/TNSE.2016.2516346},
eprint = {1507.07017},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ogura, Preciado - 2016 - Stability of spreading processes over time-varying large-scale networks.pdf:pdf},
issn = {23274697},
journal = {IEEE Transactions on Network Science and Engineering},
keywords = {Complex networks,Dynamic random graphs,Epidemics,Random matrix theory,Stochastic processes},
number = {1},
pages = {44--57},
title = {{Stability of spreading processes over time-varying large-scale networks}},
volume = {3},
year = {2016}
}
@article{Santos2015,
abstract = {The paper studies the qualitative behavior of a set of ordinary differential equations (ODE) that models the dynamics of bi-virus epidemics over bilayer networks. Each layer is a weighted digraph associated with a strain of virus; the weights gz$\iota$́represent the rates of infection from node i to node j of strain z. We establish a sufficient condition on the g's that guarantees survival of the fittest-only one strain survives. We propose an ordering of the weighted digraphs, the *-order, and show that if the weighted digraph of strain y is *-dominated by the weighted digraph of strain x, then y dies out in the long run. We prove that the orbits of the ODE accumulate to an attractor that captures the survival of the fittest phenomenon. Due to the coupled nonlinear high-dimension nature of the ODEs, there is no natural Lyapunov function to study their global qualitative behavior. We prove our results by combining two important properties of these ODEs: (i) monotonicity under a partial ordering on the set of graphs; and (ii) dimension-reduction under symmetry of the graphs. Property (ii) allows us to fully address the survival of the fittest for regular graphs. Then, by bounding the epidemics dynamics for generic networks by the dynamics on regular networks, we prove the result for general networks.},
author = {Santos, Augusto and Moura, Jos?? M F and Xavier, Jo??o M F},
doi = {10.1109/TNSE.2015.2406252},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Santos, Moura, Xavier - 2015 - Bi-virus SIS epidemics over networks Qualitative analysis.pdf:pdf},
isbn = {9550101029},
issn = {23274697},
journal = {IEEE Transactions on Network Science and Engineering},
keywords = {Bi-virus epidemics,Qualitative analysis,Survival of the fittest},
number = {1},
pages = {17--29},
title = {{Bi-virus SIS epidemics over networks: Qualitative analysis}},
volume = {2},
year = {2015}
}
@inproceedings{Mirzasoleiman2015,
abstract = {How can one find a subset, ideally as small as possible, that well represents a massive dataset? I.e., its corresponding utility, measured according to a suitable utility function, should be comparable to that of the whole dataset. In this paper, we formalize this challenge as a submodular cover problem. Here, the utility is assumed to exhibit submodularity, a natural diminishing returns condition preva-lent in many data summarization applications. The classical greedy algorithm is known to provide solutions with logarithmic approximation guarantees compared to the optimum solution. However, this sequential, centralized approach is imprac-tical for truly large-scale problems. In this work, we develop the first distributed algorithm – DISCOVER – for submodular set cover that is easily implementable using MapReduce-style computations. We theoretically analyze our approach, and present approximation guarantees for the solutions returned by DISCOVER. We also study a natural trade-off between the communication cost and the num-ber of rounds required to obtain such a solution. In our extensive experiments, we demonstrate the effectiveness of our approach on several applications, includ-ing active set selection, exemplar based clustering, and vertex cover on tens of millions of data points using Spark.},
author = {Mirzasoleiman, Baharan and Krause, Andreas},
booktitle = {NeurIPS},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mirzasoleiman, Krause - 2015 - Distributed Submodular Cover Succinctly Summarizing Massive Data.pdf:pdf},
title = {{Distributed Submodular Cover : Succinctly Summarizing Massive Data}},
year = {2015}
}
@article{Guzman2014,
abstract = {Network science spans many different fields of study, ranging from psychology to biology to the social sciences. A number of descriptive network measures have been identified for use within these fields; however, little research examines the relationships of these measures for possible statistical dependence. The research presented in this paper uses Spearman's rank correlation coefficient to examine the statistical dependence between pairs of 24 widely accepted social network measures. Confidence intervals are compared to determine whether computation times between measures in the same correlation group are significantly different. We use a three-factor, four-level, full-factorial experimental design to construct a test set of 64 unique network topologies. The three factors of interest are the network structural properties of size, clusterability, and the scale-free parameter. A set of 320 networks are generated from a power law degree distribution using a random graph generation algorithm. Results indicate that there exists high correlation among 14 of the 24 tested network measures, many of which also exhibit statistically significant differences with respect to computation time. These findings are of interest to analysts seeking to identify measures that provide similar ranked outcomes and where computational efficiency is an important consideration.},
author = {Guzman, Joshua D and Deckro, Richard F and Robbins, Matthew J and Morris, James F and Ballester, Nicholas A},
doi = {10.1109/TCSS.2014.2307451},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guzman et al. - 2014 - An Analytical Comparison of Social Network Measures.pdf:pdf},
isbn = {2329-924X},
issn = {2329-924X},
journal = {IEEE Transactions on Computational Social Systems},
keywords = {Algorithm design and analysis,Clustering algorithm},
number = {1},
pages = {35--45},
title = {{An Analytical Comparison of Social Network Measures}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6797923},
volume = {1},
year = {2014}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2014 - Towards Tactical Military Software Defined Radio with the Assistance of Unmanned Aircraft Systems.pdf:pdf},
keywords = {electro-hydraulic proportional control,plc,precision panter,sowing depth,touch screen},
number = {1},
pages = {53--58},
title = {{Towards Tactical Military Software Defined Radio with the Assistance of Unmanned Aircraft Systems}},
volume = {162},
year = {2014}
}
@inproceedings{Leskovec2007,
abstract = {Given a water distribution network, where should we place\r\nsensors to quickly detect contaminants? Or, which blogs\r\nshould we read to avoid missing important stories?\r\nThese seemingly different problems share common structure:\r\nOutbreak detection can be modeled as selecting nodes\r\n(sensor locations, blogs) in a network, in order to detect the\r\nspreading of a virus or information as quickly as possible.\r\nWe present a general methodology for near optimal sensor\r\nplacement in these and related problems. We demonstrate\r\nthat many realistic outbreak detection objectives (e.g., detection\r\nlikelihood, population affected) exhibit the property\r\nof “submodularity”. We exploit submodularity to develop\r\nan efficient algorithm that scales to large problems,\r\nachieving near optimal placements, while being 700 times\r\nfaster than a simple greedy algorithm. We also derive online\r\nbounds on the quality of the placements obtained by\r\nany algorithm. Our algorithms and bounds also handle cases\r\nwhere nodes (sensor locations, blogs) have different costs.\r\nWe evaluate our approach on several large real-world problems,\r\nincluding a model of a water distribution network from\r\nthe EPA, and real blog data. The obtained sensor placements\r\nare provably near optimal, providing a constant fraction\r\nof the optimal solution. We show that the approach\r\nscales, achieving speedups and savings in storage of several\r\norders of magnitude. We also show how the approach leads\r\nto deeper insights in both applications, answering multicriteria\r\ntrade-off, cost-sensitivity and generalization questions.},
author = {Leskovec, Jure and Krause, Andreas and Guestrin, Carlos and Faloutsos, Christos and VanBriesen, Jeanne and Glance, Natalie},
booktitle = {ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)},
doi = {10.1145/1281192.1281239},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leskovec et al. - 2007 - Cost-effective Outbreak Detection in Networks.pdf:pdf},
isbn = {978-1-59593-609-7},
keywords = {Learning/Statistics & Optimisation,Theory & Algorithms},
title = {{Cost-effective Outbreak Detection in Networks}},
url = {http://eprints.pascal-network.org/archive/00005342/},
year = {2007}
}
@article{Nemhauser1978,
abstract = {LetN be a finite set andz be a real-valued function defined on the set of subsets ofN that satisfies z (S)+ z (T)= z (S? T)+ z (S? T) for allS, T inN. Such a function is called submodular. We consider the problem max S? N {a (S):| S|= K, z (S) submodular}.},
author = {Nemhauser, G. L. and Wolsey, L. A. and Fisher, M. L.},
doi = {10.1007/BF01588971},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nemhauser, Wolsey, Fisher - 1978 - An analysis of approximations for maximizing submodular set functions-I.pdf:pdf},
isbn = {9783642007903},
issn = {00255610},
journal = {Mathematical Programming},
keywords = {Greedy Algorithm,Heuristics,Interchange Algorithm,Linear Programming,Matroid Optimization,Submodular Set Functions},
number = {1},
pages = {265--294},
title = {{An analysis of approximations for maximizing submodular set functions-I}},
volume = {14},
year = {1978}
}
@article{Elomaa2010,
author = {Elomaa, Tapio and Kujala, Jussi},
doi = {10.1007/978-3-642-12476-1_7},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elomaa, Kujala - 2010 - Covering analysis of the greedy algorithm for partial cover.pdf:pdf},
isbn = {3642124755},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {102--113},
title = {{Covering analysis of the greedy algorithm for partial cover}},
volume = {6060 LNCS},
year = {2010}
}
@article{Kumar2000,
author = {Kumar, V S Anil and Arya, Sunil and Ramesh, H},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar, Arya, Ramesh - 2000 - Hardness of Set Cover with Intersection 1.pdf:pdf},
isbn = {9783540450221},
issn = {16113349},
number = {1},
pages = {624--635},
title = {{Hardness of Set Cover with Intersection 1}},
year = {2000}
}
@article{Instructor2009,
author = {Instructor, Approximation Algorithms and Lecture, Chandra Chekuri and Ene, Alina and Multicut, The and Cut, Multiway and Lp, The and For, P and Throughput, Maximum and Flow, Multicommodity},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Instructor et al. - 2009 - The Multicut Problem Notes.pdf:pdf},
title = {{The Multicut Problem Notes}},
year = {2009}
}
@inproceedings{Garg1993,
author = {Garg, Naveen and Vaziranit, Vijay V and Yannakakis, Mihalis},
booktitle = {Proceedings of the twenty-fifth annual ACM Symposium on Theory of Computing.},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garg, Vaziranit, Yannakakis - 1993 - Approximate max-flow min-(multi)cut theorems and their applications.pdf:pdf},
pages = {698--707},
title = {{Approximate max-flow min-(multi)cut theorems and their applications}},
year = {1993}
}
@misc{Al.,
author = {et Al., Dinur},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Al. - Unknown - New multilayered PCP and the Hardness of Hypergraph Vertex Cover.ps:ps},
title = {{New multilayered PCP and the Hardness of Hypergraph Vertex Cover}}
}
@article{Carr2000a,
author = {Carr, Robert D and Doddi, Srinivas and Konjevod, Goran and Marathe, Madhav},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Carr et al. - 2000 - On the Red-blue Set Cover Problem.pdf:pdf},
isbn = {0-89871-453-2},
journal = {Proceedings of the Eleventh Annual ACM-SIAM Symposium on Discrete Algorithms},
pages = {345--353},
title = {{On the Red-blue Set Cover Problem}},
url = {http://dl.acm.org/citation.cfm?id=338219.338271},
year = {2000}
}
@article{DEste2003,
abstract = {... Concepts of network  vulnerability and applications to the identification of critical elements of \ntransport infrastructure MAP Taylor, & GM D'Este Page 4 considered, in terms of a cut to the Eyre\nHighway and transcontinental rail line between Perth and Adelaide – for instance by ...\n},
author = {D'Este, G.M. and Taylor, M.a.P.},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/D'Este, Taylor - 2003 - Concepts of network vulnerability and applications to the identification of critical elements of transport infra.pdf:pdf},
journal = {26th Australasian Transport Research Forum Wellington, New Zealand},
pages = {1--15},
title = {{Concepts of network vulnerability and applications to the identification of critical elements of transport infrastructure}},
url = {http://trid.trb.org/view.aspx?id=701288},
year = {2003}
}
@article{White2001,
abstract = {A network is robust to the extent that it is not vulnerable to disconnection\nby removal of nodes.\n\nThe minimum number of nodes that need be removed to disconnect a pair\nof other nodes is called\n\nthe connectivity of the pair. It can be proved that the connectivity\nis also equal to the number\n\nof node-independent paths between nodes, and hence we can quantify\nnetwork robustness by\n\ncalculating numbers of node-independent paths. Unfortunately, computing\nsuch numbers is\n\nknown to be an NP-hard problem, taking exponentially long to run to\ncompletion. In this\n\npaper, we present an approximation algorithm which gives good lower\nbounds on numbers of\n\nnode-independent paths between any pair of nodes on a directed or\nundirected graph in worst-\n\ncase time which is linear in the graph size. A variant of the same\nalgorithm can also calculate\n\nall the k-components of a graph in the same approximation. Our algorithm\nis found empirically\n\nto work with better than 99% accuracy on random graphs and for several\nreal-world networks is\n\n100% accurate. As a demonstration of the algorithm, we apply it to\ntwo large graphs for which\n\nthe traditional NP-hard algorithm is entirely intractable|a network\nof collaborations between\n\nscientists and a network of business ties between biotechnology rms.},
author = {White, Douglas R and Newman, M E J},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/White, Newman - 2001 - Fast approximation algorithms for finding node-independent paths in networks(2).pdf:pdf},
journal = {Working Papers},
pages = {07--035},
title = {{Fast approximation algorithms for finding node-independent paths in networks}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.8287&rep=rep1&type=pdf},
volume = {1},
year = {2001}
}
@article{Chakraborty2016,
abstract = {In this work, we propose a novel information theoretic framework for dictionary learning (DL) and sparse coding (SC) on a statistical manifold (the manifold of probability distributions). Unlike the traditional DL and SC framework, our new formulation {\it does not explicitly incorporate any sparsity inducing norm in the cost function but yet yields SCs}. Moreover, we extend this framework to the manifold of symmetric positive definite matrices, $\mathcal{P}_n$. Our algorithm approximates the data points, which are probability distributions, by the weighted Kullback-Leibeler center (KL-center) of the dictionary atoms. The KL-center is the minimizer of the maximum KL-divergence between the unknown center and members of the set whose center is being sought. Further, {\it we proved that this KL-center is a sparse combination of the dictionary atoms}. Since, the data reside on a statistical manifold, the data fidelity term can not be as simple as in the case of the vector-space data. We therefore employ the geodesic distance between the data and a sparse approximation of the data element. This cost function is minimized using an acceleterated gradient descent algorithm. An extensive set of experimental results show the effectiveness of our proposed framework. We present several experiments involving a variety of classification problems in Computer Vision applications. Further, we demonstrate the performance of our algorithm by comparing it to several state-of-the-art methods both in terms of classification accuracy and sparsity.},
archivePrefix = {arXiv},
arxivId = {1604.06939},
author = {Chakraborty, Rudrasis and Banerjee, Monami and Crawford, Victoria and Vemuri, Baba C.},
eprint = {1604.06939},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chakraborty et al. - 2016 - An information theoretic formulation of the Dictionary Learning and Sparse Coding Problems on Statistical Ma.pdf:pdf},
number = {Dl},
pages = {1--18},
title = {{An information theoretic formulation of the Dictionary Learning and Sparse Coding Problems on Statistical Manifolds}},
url = {http://arxiv.org/abs/1604.06939},
year = {2016}
}
@article{Paper2013,
abstract = {Background To maintain the balance between the demand of the body and supply (cardiac output), cardiac performance is tightly regulated via the parasympathetic and sympathetic nervous systems. In heart failure, cardiac output (supply) is decreased due to pathologic remodeling of the heart. To meet the demands of the body, the sympathetic system is activated and catecholamines stimulate $\beta$-adrenergic receptors ($\beta$-ARs) to increase contractile performance and cardiac output. Although this is beneficial in the acute phase, chronic $\beta$-ARs stimulation initiates a cascade of alterations at the cellular level, resulting in a diminished contractile performance of the heart.},
author = {Paper, Original and Boer, De},
doi = {10.3837/tiis.0000.00.000},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paper, Boer - 2013 - r vi ew On r Fo Re vi ew On ly.pdf:pdf},
isbn = {1972952943},
issn = {1972952943},
pages = {0--34},
pmid = {25071666},
title = {{r vi ew On r Fo Re vi ew On ly}},
year = {2013}
}
@article{Ho2013,
author = {Ho, Jeffrey and Cheng, Guang and Salehian, Hesamoddin and Vemuri, Baba C},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ho et al. - 2013 - Recursive Karcher Expectation Estimators And Geometric Law of Large Numbers.pdf:pdf},
issn = {15337928},
journal = {Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics},
number = {2},
pages = {325--332},
title = {{Recursive Karcher Expectation Estimators And Geometric Law of Large Numbers}},
url = {http://jmlr.org/proceedings/papers/v31/ho13a.html},
volume = {31},
year = {2013}
}
@misc{Pecina1978,
author = {Pecina, P.},
booktitle = {Bulletin of the Astronomical Institutes of Czecheslovakia},
doi = {10.1002/2014GB005021},
isbn = {9781617796029},
number = {6},
title = {{Observation of the sporadic background in Nov. 1974}},
volume = {29},
year = {1978}
}
@article{Paper2013a,
abstract = {Background To maintain the balance between the demand of the body and supply (cardiac output), cardiac performance is tightly regulated via the parasympathetic and sympathetic nervous systems. In heart failure, cardiac output (supply) is decreased due to pathologic remodeling of the heart. To meet the demands of the body, the sympathetic system is activated and catecholamines stimulate $\beta$-adrenergic receptors ($\beta$-ARs) to increase contractile performance and cardiac output. Although this is beneficial in the acute phase, chronic $\beta$-ARs stimulation initiates a cascade of alterations at the cellular level, resulting in a diminished contractile performance of the heart.},
author = {Paper, Original and Boer, De},
doi = {10.3837/tiis.0000.00.000},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paper, Boer - 2013 - r vi ew On r Fo Re vi ew On ly.pdf:pdf},
isbn = {1972952943},
issn = {1972952943},
pages = {0--34},
pmid = {25071666},
title = {{r vi ew On r Fo Re vi ew On ly}},
year = {2013}
}
@article{Salehian2013,
abstract = {Symmetric positive-definite (SPD) matrices are ubiquitous in Computer Vision, Machine Learning and Medical Image Analysis. Finding the center/average of a population of such matrices is a common theme in many algorithms such as clustering, segmentation, principal geodesic analysis, etc. The center of a population of such matrices can be defined using a variety of distance/divergence measures as the minimizer of the sum of squared distances/divergences from the unknown center to the members of the population. It is well known that the computation of the Karcher mean for the space of SPD matrices which is a negatively-curved Riemannian manifold is computationally expensive. Recently, the LogDet divergence-based center was shown to be a computationally attractive alternative. However, the LogDet-based mean of more than two matrices can not be computed in closed form, which makes it computationally less attractive for large populations. In this paper we present a novel recursive estimator for center based on the Stein distance - which is the square root of the LogDet divergence - that is significantly faster than the batch mode computation of this center. The key theoretical contribution is a closed-form solution for the weighted Stein center of two SPD matrices, which is used in the recursive computation of the Stein center for a population of SPD matrices. Additionally, we show experimental evidence of the convergence of our recursive Stein center estimator to the batch mode Stein center. We present applications of our recursive estimator to K-means clustering and image indexing depicting significant time gains over corresponding algorithms that use the batch mode computations. For the latter application, we develop novel hashing functions using the Stein distance and apply it to publicly available data sets, and experimental results have shown favorable comparisons to other competing methods.},
author = {Salehian, H and Cheng, G and Vemuri, B C and Ho, J},
doi = {10.1109/ICCV.2013.225},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Salehian et al. - 2013 - Recursive Estimation of the Stein Center of SPD Matrices & its Applications.pdf:pdf},
isbn = {1550-5499 (Print)\r1550-5499 (Linking)},
issn = {1550-5499},
journal = {Proc IEEE Int Conf Comput Vis},
pages = {1793--1800},
pmid = {25350135},
title = {{Recursive Estimation of the Stein Center of SPD Matrices & its Applications}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25350135},
year = {2013}
}
@article{Korkmaz2001,
abstract = {Providing quality-of-service (QoS) guarantees in packet networks gives rise to several challenging issues. One of them is how to determine a feasible path that satisfies a set of constraints while maintaining high utilization of network resources. The latter objective implies the need to impose an additional optimality requirement on the feasibility problem. This can be done through a primary cost function (e.g., administrative weight, hop count) according to which the selected feasible path is optimal. In general, multi-constrained path selection, with or without optimization, is an NP-complete problem that cannot be exactly solved in polynomial-time. Heuristics and approximation algorithms with polynomial and pseudo-polynomial-time complexities are often used to deal with this problem. However, existing solutions suffer either from excessive computational complexities that cannot be used for online network operation or from low performance. Moreover, they only deal with special cases of the problem (e.g., two constraints without optimization, one constraint with optimization, etc.). For the feasibility problem under multiple constraints, some researchers have proposed a nonlinear cost function whose minimization provides a continuous spectrum of solutions ranging from a generalized linear approximation (GLA) to an asymptotically exact solution. We propose an efficient heuristic algorithm for the most general form of the problem. We first formalize the theoretical properties of the above nonlinear cost function. We then introduce our heuristic algorithm (H MCOP), which attempts to minimize both the nonlinear cost function (for the feasibility part) and the primary cost function (for the optimality part). We prove that H MCOP guarantees at least the performance of GLA and often improves upon it. H MCOP has the same order of complexity as Dijkstra's algorithm. Using extensive simulations on random graphs with correlated and uncorrelated link weights, we show that under the same level of computational complexity, H MCOP outperforms its (less general) contenders in its success rate in finding feasible paths and in the cost of such paths},
author = {Korkmaz, Turgay and Krunz, Marwan},
doi = {10.1109/INFCOM.2001.916274},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Korkmaz, Krunz - 2001 - Multi-constrained optimal path selection.pdf:pdf},
isbn = {0-7803-7016-3},
issn = {0743-166X},
journal = {Proceedings IEEE INFOCOM Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)},
keywords = {-shortest paths,multiple constraints,path selection,qos routing,routing,scalable},
pages = {834--843},
title = {{Multi-constrained optimal path selection}},
volume = {2},
year = {2001}
}
@article{Borodin2010,
author = {Borodin, Allan and Filmus, Yuval and Oren, Joel},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Borodin, Filmus, Oren - 2010 - Threshold Models for Competitive Influence in Social Networks.pdf:pdf},
journal = {Science},
pages = {1--15},
title = {{Threshold Models for Competitive Influence in Social Networks}},
year = {2010}
}
@article{Wiley,
author = {Wiley, John},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wiley - Unknown - r ee r P Fo ew vi Re r r P Fo ew vi Re.pdf:pdf},
pages = {1--48},
title = {{r ee r P Fo ew vi Re r r P Fo ew vi Re}}
}
@article{Bharathi2007,
abstract = {Social networks often serve as a medium for the diffusion of ideas or innovations. An individual's decision whether to adopt a product or innovation will be highly dependent on the choices made by the individual's peers or neighbors in the social network. In this work, we study the game of innovation diffusion with multiple competing innovations such as when multiple companies market competing products using viral marketing. Our first contribution is a natural and mathematically tractable model for the diffusion of multiple innovations in a network. We give a (1 − 1/e) approximation algorithm for computing the best response to an opponent's strategy, and prove that the “price of competition” of this game is at most 2. We also discuss “first mover” strategies which try to maximize the expected diffusion against perfect competition. Finally, we give an FPTAS for the problem of maximizing the influence of a single player when the underlying graph is a tree.},
author = {Bharathi, Shishir and Kempe, David and Salek, Mahyar},
doi = {10.1007/978-3-540-77105-0_31},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bharathi, Kempe, Salek - 2007 - Competitive influence maximization in social networks.pdf:pdf},
isbn = {978-3-540-77104-3},
issn = {03029743},
journal = {Internet and Network Economics},
pages = {306--311},
title = {{Competitive influence maximization in social networks}},
year = {2007}
}
@article{Reinhardt2011,
abstract = {Shortest path problems appear as subproblems in numerous optimization problems. In most papers concerning multiple objective shortest path problems, additivity of the objective is a de-facto assumption, but in many real-life situations objectives and criteria, can be non-additive. The purpose of this paper is to give a general framework for dominance tests for problems involving a number of non-additive criteria. These dominance tests can help to eliminate paths in a dynamic programming framework when using multiple objectives. Results on real-life multi-objective problems containing non-additive criteria are reported. We show that in many cases the framework can be used to efficiently reduce the number of generated paths. ?? 2010 Elsevier Ltd. All rights reserved.},
author = {Reinhardt, Line Blander and Pisinger, David},
doi = {10.1016/j.cor.2010.08.003},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reinhardt, Pisinger - 2011 - Multi-objective and multi-constrained non-additive shortest path problems.pdf:pdf},
isbn = {0305-0548},
issn = {03050548},
journal = {Computers and Operations Research},
keywords = {Dynamic programming,Multi objective programming,Non-additive objective,Shortest path problem},
number = {3},
pages = {605--616},
publisher = {Elsevier},
title = {{Multi-objective and multi-constrained non-additive shortest path problems}},
url = {http://dx.doi.org/10.1016/j.cor.2010.08.003},
volume = {38},
year = {2011}
}
@article{He2011,
abstract = {In many real-world situations, different and often opposite opinions, innovations, or products are competing with one another for their social influence in a networked society. In this paper, we study competitive influence propagation in social networks under the competitive linear threshold (CLT) model, an extension to the classic linear threshold model. Under the CLT model, we focus on the problem that one entity tries to block the influence propagation of its competing entity as much as possible by strategically selecting a number of seed nodes that could initiate its own influence propagation. We call this problem the influence blocking maximization (IBM) problem. We prove that the objective function of IBM in the CLT model is submodular, and thus a greedy algorithm could achieve 1-1/e approximation ratio. However, the greedy algorithm requires Monte-Carlo simulations of competitive influence propagation, which makes the algorithm not efficient. We design an efficient algorithm CLDAG, which utilizes the properties of the CLT model, to address this issue. We conduct extensive simulations of CLDAG, the greedy algorithm, and other baseline algorithms on real-world and synthetic datasets. Our results show that CLDAG is able to provide best accuracy in par with the greedy algorithm and often better than other algorithms, while it is two orders of magnitude faster than the greedy algorithm.},
archivePrefix = {arXiv},
arxivId = {1110.4723},
author = {He, Xinran and Song, Guojie and Chen, Wei and Jiang, Qingye},
doi = {CoRR abs/1110.4723},
eprint = {1110.4723},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - 2011 - Influence Blocking Maximization in Social Networks under the Competitive Linear Threshold Model.pdf:pdf},
isbn = {9781611972320},
journal = {Education},
keywords = {competitive linear,influence blocking maximization,social networks,threshold model},
pages = {Technical report CoRR abs/1110.4723},
title = {{Influence Blocking Maximization in Social Networks under the Competitive Linear Threshold Model}},
url = {http://research.microsoft.com/en-us/people/weic/sdm12_infblockingmax.pdf},
year = {2011}
}
@article{Dinh2012,
abstract = {With a rapid expansion of online social networks (OSNs), millions of users are tweeting and sharing their personal status daily without being aware of where that information eventually travels to. Likewise, with a huge magnitude of data available on OSNs, it poses a substantial challenge to track how a piece of information leaks to specific targets. In this paper, we study the problem of smartly sharing information to control the propagation of sensitive information in OSNs. In particular, we formulate and investigate the Maximum Circle of Trust problem of which we seek to construct a circle of trust on the fly so that OSN users can safely share their information knowing that it will not be propagated to their unwanted targets (whom they are not willing to share with). Since most of messages in OSNs are propagated within 2 to 5 hops, we first investigate this problem under 2-hop information propagation by showing the hardness of obtaining an optimal solution, along with an algorithm with proven performance guarantee. In a general case where information can be propagated more than two hops, the problem is #P-hard i.e. the problem cannot be solved in a polynomial time. Thus we propose a novel greedy algorithm, hybridizing the handy but costly sampling method with a novel cut-based estimation. The quality of the hybrid algorithm is comparable to that of the sampling method while taking only a tiny fraction of the time. We have validated the effectiveness of our solutions in many real-world traces. Such an extensive experiment also highlights several important observations on information leakage which help to sharpen the security of OSNs in the future.},
author = {Dinh, Thang N. and Shen, Yilin and Thai, My T.},
doi = {10.1145/2396761.2398451},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dinh, Shen, Thai - 2012 - The walls have ears optimize sharing for visibility and privacy in online social networks.pdf:pdf},
isbn = {9781450311564},
journal = {Proceedings of the 21st ACM international conference on Information and knowledge management},
keywords = {algorithms,circle of trust,complexity,social networks},
pages = {1452--1461},
title = {{The walls have ears: optimize sharing for visibility and privacy in online social networks}},
year = {2012}
}
@article{Xuan2010,
abstract = {How to assess the topology vulnerability of a network has attracted more and more attentions recently. Due to the rapid growing number of real-time internet applications developed since the last decade, the discovery of topology weakness related to its quality of service (QoS) is of more interest. In this paper, we provide a novel QoS-aware measurement for assessing the vulnerability of general network topologies. Specifically, we evaluate the vulnerability by detecting the minimum number of link failures that decrease the satisfactory level of the QoS-Optimal source-destination path to a given value, which means a topology with a smaller amount of such link failures is more vulnerable. We formulate this process as a graph optimization problem called QoSCE and provide several exact and heuristic algorithms for various QoS constraint amounts. To our best knowledge, this is the first graph-theoretical framework to evaluate QoS-aware topology vulnerability. Through extensive simulations, the performance of the proposed algorithms are validated in terms of assessment accuracy and time complexity.},
author = {Xuan, Ying and Shen, Yilin and Nguyen, Nam P. and Thai, My T.},
doi = {10.1109/GLOCOM.2010.5683938},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xuan et al. - 2010 - A graph-theoretic QoS-aware vulnerability assessment for network topologies.pdf:pdf},
isbn = {9781424456383},
issn = {1930-529X},
journal = {GLOBECOM - IEEE Global Telecommunications Conference},
title = {{A graph-theoretic QoS-aware vulnerability assessment for network topologies}},
year = {2010}
}
@article{Arora2009,
abstract = {We give a O(&sqrt;log n)-approximation algorithm for the sparsest cut, edge expansion, balanced separator, and graph conductance problems. This improves the O(log n)-approximation of Leighton and Rao (1988). We use a well-known semidefinite relaxation with triangle inequality constraints. Central to our analysis is a geometric theorem about projections of point sets in Rd, whose proof makes essential use of a phenomenon called measure concentration. We also describe an interesting and natural “approximate certificate” for a graph's expansion, which involves embedding an n-node expander in it with appropriate dilation and congestion. We call this an expander flow.},
author = {Arora, Sanjeev and Rao, Satish and Vazirani, Umesh},
doi = {10.1145/1502793.1502794},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arora, Rao, Vazirani - 2009 - Expander flows, geometric embeddings and graph partitioning.pdf:pdf},
isbn = {1581138520},
issn = {00045411},
journal = {Journal of the ACM},
keywords = {approximation algo-,beddings,clustering,conductance,em-,expander,graph partitioning,normalized cuts,rithms,semidefinite programming,sparsest cuts,spectral meth-},
number = {2},
pages = {1--37},
title = {{Expander flows, geometric embeddings and graph partitioning}},
volume = {56},
year = {2009}
}
@article{Levin2006,
abstract = {Let T = (V, E) be an undirected tree, in which each edge is associated with a non-negative cost, and let { s
                        1, t
                        1 }, ..., { s
                        k, t
                        k } be a collection of k distinct pairs of vertices. Given a requirement parameter t ??? k, the partial multicut on a tree problem asks to find a minimum cost set of edges whose removal from T disconnects at least t out of these k pairs. This problem generalizes the well-known multicut on a tree problem, in which we are required to disconnect all given pairs. The main contribution of this paper is an (frac(8, 3) + ??{lunate})-approximation algorithm for partial multicut on a tree, whose run time is strongly polynomial for any fixed ??{lunate} > 0. This result is achieved by introducing problem-specific insight to the general framework of using the Lagrangian relaxation technique in approximation algorithms. Our algorithm utilizes a heuristic for the closely related prize-collecting variant, in which we are not required to disconnect all pairs, but rather incur penalties for failing to do so. We provide a Lagrangian multiplier preserving algorithm for the latter problem, with an approximation factor of 2. Finally, we present a new 2-approximation algorithm for multicut on a tree, based on LP-rounding. ?? 2006.},
author = {Levin, Asaf and Segev, Danny},
doi = {10.1016/j.tcs.2006.09.018},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Levin, Segev - 2006 - Partial multicuts in trees.pdf:pdf},
isbn = {3540322078},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Approximation algorithms,Lagrangian relaxation,Multicut},
number = {1-3},
pages = {384--395},
title = {{Partial multicuts in trees}},
volume = {369},
year = {2006}
}
@inproceedings{Alim2014,
abstract = {{\textcopyright} 2014 IEEE. Many complex systems, from World Wide Web and online social networks to mobile networks, exhibit community structure in which nodes can be grouped into densely interconnected communities. This special structure has been exploited extensively to design better solutions for many operations and applications such as routing in wireless networks, worm containment and interest prediction in social networks. The outcome of these solutions are sensitive to the network structures, which raises an important question: can communities be broken easily in a network? To answer this question, we introduce a density-based problem formulation for analyzing the vulnerability of communities. Our approach includes the NP-completeness and a O(log k) approximation algorithm for solving the problem where k is the number of communities to be broken. Additionally, we analyze the vulnerability of communities in the context of arbitrary community detection algorithms. The empirical results show that communities are vulnerable to edge removal and in some cases the removal of a small fraction of edges can break the community structure.},
author = {Alim, M.A. and Kuhnle, A. and Thai, M.T.},
booktitle = {ASONAM 2014 - Proceedings of the 2014 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
doi = {10.1109/ASONAM.2014.6921603},
isbn = {9781479958771},
pages = {314--319},
title = {{Are communities as strong as we think?}},
year = {2014}
}
@article{Mishra2016,
abstract = {Smart grid addresses the problem of existing power grid's increasing complexity, growing demand, and requirement for greater reliability through two-way communication and automated residential load control among others. These features also make the smart grid a target for a number of cyber attacks. In this paper, we study the problem of price modification attack (PMA) through fabrication of price messages, which induces changes in load profiles of individual users and eventually causes major alteration in the load profile of the entire network. Combining with cascading failure, it ends up with a highly damaging attack. We prove that the problem is nondeterministic polynomial-time-complete and provide its inapproximability. We devise two approaches for the problem, the former deals with maximizing failure of lines with the given resource and then extending the effect with cascading failure, while the later takes cascading potential into account while choosing the lines to fail. We formulate new protection strategy against PMA and this includes two new algorithms, namely bi-level programming with new branching method and an effective heuristic to improve the running time. Empirical results on both IEEE bus data and real network help us evaluate our approaches under various settings of grid parameters.},
author = {Mishra, S. and Li, X. and Pan, T. and Kuhnle, A. and Thai, M. T. and Seo, J.},
doi = {10.1109/TSG.2015.2509945},
issn = {19493053},
journal = {IEEE Transactions on Smart Grid},
title = {{Price Modification Attack and Protection Scheme in Smart Grid}},
year = {2016}
}
@inproceedings{Mishra2015b,
abstract = {{\textcopyright} 2015 IEEE. Smart Grid addresses the problem of existing power grid's increasing complexity, growing demand and requirement for greater reliability, through two-way communication and automated residential load control among others. These features also makes the Smart Grid a target for a number of cyber attacks. In the paper, we study the problem of rate alteration attack (RAA) through fabrication of price messages which induces changes in load profiles of individual users and eventually causes major alteration in the load profile of the entire network. Combining with cascading failure, it ends up with a highly damaging attack. We prove that the problem is NP-Complete and provide its inapproximability. We devise two approaches for the problem, former deals with maximizing failure of lines with the given resource and then extending the effect with cascading failure while the later takes cascading potential into account while choosing the lines to fail. To get more insight into the impact of RAA, we also extend our algorithms to maximize number of node failures. Empirical results on both IEEE Bus data and real network help us evaluate our approaches under various settings of grid parameters.},
author = {Mishra, S. and Li, X. and Kuhnle, A. and Thai, M.T. and Seo, J.},
booktitle = {Proceedings - IEEE INFOCOM},
doi = {10.1109/INFOCOM.2015.7218623},
isbn = {9781479983810},
issn = {0743166X},
pages = {2353--2361},
title = {{Rate alteration attacks in smart grid}},
volume = {26},
year = {2015}
}
@article{Kuhnle2014,
abstract = {Device-to-device (D2D) communications has recently emerged as a promising technology for boosting the capacity of cellular systems. D2D enables direct communication between mobile devices over the cellular band without utilizing infrastructure nodes such as base stations, thereby reducing the load on cellular base stations and increasing network throughput through spatial reuse of radio resources. Hence it is important to optimally allocate these radio resources. Furthermore, since the composition of a cellular macro cell is highly dynamic, it is critical to adaptively update the resource allocation for D2D communications rather than recomputing it from scratch. In this work, we develop the first online algorithm, namely ODSRA, for dynamic resource allocation while maximizing spatial reuse. At the core of the resource allocation problem is the online set multicover problem, for which we present the first deterministic O (log n log m)-competitive online algorithm, where n is the number of elements, and m the number of sets. By simulation, we show the efficacy of ODSRA by analyzing network throughput and other metrics, obtaining a large improvement in running time over offline methods.},
author = {Kuhnle, Alan and Li, Xiang and Smith, J. David and Thai, My T.},
doi = {10.1109/MSN.2014.24},
isbn = {9781479973941},
journal = {Journal of Combinatorial Optimization},
keywords = {D2D communications,online algorithms,resource allocation,spatial reuse},
number = {4},
pages = {1237--1264},
title = {{Online set multicover algorithms for dynamic D2D communications}},
volume = {34},
year = {2017}
}
@misc{Schoone1985,
author = {Schoone, A. A. and Bodlaender, H. L. and van Leeuwen, J.},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schoone, Bodlaender, van Leeuwen - 1985 - Diameter Increase Caused By Edge Deletion.pdf:pdf},
title = {{Diameter Increase Caused By Edge Deletion}},
year = {1985}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2016 - Department of Computer & Information Science & Engineering Social Networks and Privacy Management Challenges and Oppor.pdf:pdf},
pages = {2016},
title = {{Department of Computer & Information Science & Engineering Social Networks and Privacy Management : Challenges and Opportunities for}},
year = {2016}
}
@article{Gandhi2004,
abstract = {We study a generalization of covering problems called partial covering. Here we wish to cover only a desired number of elements, rather than covering all elements as in standard covering problems. For example, in k-partial set cover, we wish to choose a minimum number of sets to cover at least k elements. For k-partial set cover, if each element occurs in at most f sets, then we derive a primal-dual f-approximation algorithm (thus implying a 2-approximation for k-partial vertex cover) in polynomial time. Without making any assumption about the number of sets an element is in, for instances where each set has cardinality at most three, we obtain an approximation of 4/3. We also present better-than-2-approximation algorithms for k-partial vertex cover on bounded degree graphs, and for vertex cover on expanders of bounded average degree. We obtain a polynomial-time approximation scheme for k-partial vertex cover on planar graphs, and for covering k points in Rd by disks. {\textcopyright} 2004 Elsevier Inc. All rights reserved.},
author = {Gandhi, Rajiv and Khuller, Samir and Srinivasan, Aravind},
doi = {10.1016/j.jalgor.2004.04.002},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gandhi, Khuller, Srinivasan - 2004 - Approximation algorithms for partial covering problems.pdf:pdf},
isbn = {3540422870},
issn = {01966774},
journal = {Journal of Algorithms},
keywords = {Approximation algorithms,Partial covering,Primal-dual methods,Randomized rounding,Set cover,Vertex cover},
number = {1},
pages = {55--84},
title = {{Approximation algorithms for partial covering problems}},
volume = {53},
year = {2004}
}
@inproceedings{Zhang2016,
author = {Zhang, Huiyuan and Zhang, Huiling and Kuhnle, Alan and Thai, My T},
booktitle = {IEEE International Conference on Computer Communications (INFOCOM)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2016 - Profit Maximization for Multiple Products in Online Social Networks.pdf:pdf},
title = {{Profit Maximization for Multiple Products in Online Social Networks}},
year = {2016}
}
@inproceedings{Golovin2009,
author = {Golovin, Daniel and Nagarajan, Viswanath and Singh, Mohit},
booktitle = {Proceedings of the seventeenth annual ACM-SIAM Symposium on Discrete Algorithm.},
doi = {10.1145/1109557.1109625},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Golovin, Nagarajan, Singh - 2006 - Approximating k-multicut problem.pdf:pdf},
isbn = {0898716055},
issn = {1539-3755},
pmid = {19518323},
title = {{Approximating k-multicut problem}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19518323},
year = {2006}
}
@article{Thai2010,
author = {Thai, My T},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thai - 2010 - Approximation Algorithms LP Relaxation, Rounding, and Randomized Rounding Techniques.pdf:pdf},
journal = {Synthectic Lectures on Optimization},
pages = {1--25},
title = {{Approximation Algorithms: LP Relaxation, Rounding, and Randomized Rounding Techniques}},
year = {2010}
}
@article{Jain2011,
author = {Jain, Kamal},
doi = {10.1016/j.ipl.2011.04.009},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jain - 2011 - A Factor 2 Approximation Algorithm for the Generalized Steiner Network Problem.pdf:pdf},
isbn = {0-8186-9172-7},
issn = {00200190},
journal = {Combinatorica},
keywords = {Approximation algorithm,Combinatorial optimization,Fixed-cost flow,Vertex cover Pn problem,set cover},
mendeley-tags = {Fixed-cost flow,set cover},
number = {1},
title = {{A Factor 2 Approximation Algorithm for the Generalized Steiner Network Problem}},
url = {http://www.sciencedirect.com/science/article/pii/S0020019011001153},
volume = {21},
year = {2011}
}
@article{Chuzhoy2006,
abstract = {We consider the classical vertex cover and set cover problems with the addition of hard capacity constraints. This means that a set (vertex) can only cover a limited number of its elements (adjacent edges) and the number of available copies of each set (vertex) is bounded. This is a natural generalization of the classical problems that also captures resource limitations in practical scenarios. We obtain the following results. For the unweighted vertex cover problem with hard capacities we give a 3-approximation algorithm which is based on randomized rounding with alterations. We prove that the weighted version is at least as hard as the set cover problem. This is an interesting separation between the approximability of weighted and unweighted versions of a "natural" graph problem. A logarithmic approximation factor for both the set cover and the weighted vertex cover problem with hard capacities follows from the work of Wolsey (1982) on submodular set cover. We provide in this paper a simple and intuitive proof for this bound.},
author = {Chuzhoy, J and {(Seffi) Naor}, J},
doi = {10.1137/S0097539703422479},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chuzhoy, (Seffi) Naor - 2006 - Covering Problems with Hard Capacities.pdf:pdf},
isbn = {0-7695-1822-2},
issn = {0097-5397},
journal = {SIAM Journal on Computing},
keywords = {1,10,1137,68q25,68w25,90c27,90c59,ams subject classifications,be,covering problem,doi,hard capacities,introduction,is the following,let e,n,s0097539703422479,set cover,submodular set cover,the set cover problem,vertex cover},
mendeley-tags = {covering problem,set cover},
number = {2},
pages = {498--515},
title = {{Covering Problems with Hard Capacities}},
url = {http://dx.doi.org/10.1137/S0097539703422479},
volume = {36},
year = {2006}
}
@article{Even2005,
abstract = {Network design problems, such as generalizations of the Steiner Tree Problem, can be cast as edge-cost-flow problems. An edge-cost flow problem is a min-cost flow problem in which the cost of the flow equals the sum of the costs of the edges carrying ...},
author = {Even, Guy and Kortsarz, Guy and Slany, Wolfgang},
doi = {10.1145/1077464.1077470},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Even, Kortsarz, Slany - 2005 - On network design problems fixed cost flows and the covering steiner problem.pdf:pdf},
isbn = {9783540438663},
issn = {15496325},
journal = {ACM Transactions on Algorithms},
keywords = {covering problem,fixed-cost flow},
mendeley-tags = {covering problem,fixed-cost flow},
number = {1},
pages = {74--101},
title = {{On network design problems: fixed cost flows and the covering steiner problem}},
volume = {1},
year = {2005}
}
@article{Carr2000,
author = {Carr, Robert D RD Robert D and Fleischer, Lisa K LK and Phillips, Cynthia A. and Leung, VJ},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Carr et al. - 2000 - Strengthening integrality gaps for capacitated network design and covering problems.pdf:pdf},
isbn = {0-89871-453-2},
journal = {the eleventh annual ACM-SIAM symposium on Discrete algorithms algorithms},
pages = {106--115},
title = {{Strengthening integrality gaps for capacitated network design and covering problems}},
url = {http://dl.acm.org/citation.cfm?id=338241},
year = {2000}
}
@article{Hajiaghayi2011,
author = {Hajiaghayi, Mohammadtaghi and Khandekar, Rohit and Kortsarz, Guy and Nutov, Zeev},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hajiaghayi et al. - 2011 - On the Fixed Cost k -Flow Problem and related problems.pdf:pdf},
keywords = {fixed-cost flow},
mendeley-tags = {fixed-cost flow},
number = {434923},
title = {{On the Fixed Cost k -Flow Problem and related problems}},
volume = {1176},
year = {2011}
}
@article{Chakrabarty2013,
author = {Chakrabarty, Deeparnab and Krishnaswamy, Ravishankar and Li, Shi and Narayanan, Srivatsan},
doi = {10.1007/978-3-642-40328-6_6},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chakrabarty et al. - 2013 - Capacitated network design on undirected graphs.pdf:pdf},
isbn = {9783642403279},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {71--80},
title = {{Capacitated network design on undirected graphs}},
volume = {8096 LNCS},
year = {2013}
}
@article{Rostami2014,
author = {Rostami, Reza and Ebrahimnejad, Ali},
doi = {10.1504/IJOR.2014.061773},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rostami, Ebrahimnejad - 2014 - An approximation algorithm for discrete minimum cost flows over time problem.pdf:pdf},
isbn = {3761835884},
issn = {1745-7645},
journal = {International Journal of Operational Research},
number = {2},
pages = {226},
title = {{An approximation algorithm for discrete minimum cost flows over time problem}},
url = {http://www.inderscience.com/link.php?id=61773},
volume = {20},
year = {2014}
}
@article{Chakrabarty2015,
abstract = {In the {\em capacitated} survivable network design problem (Cap-SNDP), we are given an undirected multi-graph where each edge has a capacity and a cost. The goal is to find a minimum cost subset of edges that satisfies a given set of pairwise minimum-cut requirements. Unlike its classical special case of SNDP when all capacities are unit, the approximability of Cap-SNDP is not well understood; even in very restricted settings no known algorithm achieves a $o(m)$ approximation, where $m$ is the number of edges in the graph. In this paper, we obtain several new results and insights into the approximability of Cap-SNDP.},
archivePrefix = {arXiv},
arxivId = {1009.5734},
author = {Chakrabarty, Deeparnab and Chekuri, Chandra and Khanna, Sanjeev and Korula, Nitish},
doi = {10.1007/s00453-013-9862-4},
eprint = {1009.5734},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chakrabarty et al. - 2015 - Approximability of Capacitated Network Design.pdf:pdf},
isbn = {9783642208065},
issn = {14320541},
journal = {Algorithmica},
keywords = {Approximation algorithms,Linear Programming Relaxations,Network design},
number = {2},
pages = {493--514},
title = {{Approximability of Capacitated Network Design}},
volume = {72},
year = {2015}
}
@article{Coene,
author = {Coene, S and Spieksma, FCR and Maya, P and S{\"{o}}rensen, K and Goos, P},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Coene et al. - Unknown - The Budget-Constrained Min Cost Flow Problem.pdf:pdf},
journal = {Orbel.Be},
title = {{The Budget-Constrained Min Cost Flow Problem}},
url = {http://www.orbel.be/orbel27/abstracts/The Budget-Constrained Min Cost Flow Problem.pdf}
}
@article{Terruggia2010,
author = {Terruggia, Roberta and Bobbio, Andrea},
doi = {10.1007/978-3-642-15651-9_4},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Terruggia, Bobbio - 2010 - QoS analysis of weighted multi-state probabilistic networks via decision diagrams.pdf:pdf},
isbn = {3642156509},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {41--54},
title = {{QoS analysis of weighted multi-state probabilistic networks via decision diagrams}},
volume = {6351 LNCS},
year = {2010}
}
@article{Leighton1988,
abstract = {A multicommodity flow problem is considered where for each pair of vertices (u, v) it is required to send f half-units of commodity (u, v) from u to v and f half-units of commodity (v, u) from v to u without violating capacity constraints. The main result is an algorithm for performing the task provided that the capacity of each cut exceeds the demand across the cut by a $\Theta$(log n) factor. The condition on cuts is required in the worst case, and is trivially within a $\Theta$(log n) factor of optimal for any flow problem. The result can be used to construct the first polylog-times optimal approximation algorithms for a wide variety of problems, including minimum quotient separators, 1/3-2/3 separators, bifurcators, crossing number, and VLSI layout area. It can also be used to route packets efficiently in arbitrary distributed networks},
author = {Leighton, T. and Rao, S.},
doi = {10.1109/SFCS.1988.21958},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leighton, Rao - 1988 - An approximate max-flow min-cut theorem for uniform multicommodity flow problems with applications to approximati.pdf:pdf},
isbn = {0-8186-0877-3},
issn = {02725428},
journal = {[Proceedings 1988] 29th Annual Symposium on Foundations of Computer Science},
keywords = {1/3-2/3 separators,Application software,Approximation algorithms,Bifurcation,Computer science,Constraint theory,Contracts,Laboratories,Linear programming,Mathematics,Particle separators,VLSI layout area,approximation algorithms,bifurcators,crossing number,distributed networks,graph theory,max-flow min-cut theorem,minimum quotient separators,multicommodity flow problems,optimal approximation},
pages = {422--431},
title = {{An approximate max-flow min-cut theorem for uniform multicommodity flow problems with applications to approximation algorithms}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=21958},
year = {1988}
}
@article{Hajiaghayi2006,
abstract = {We present a pure combinatorial problem whose solution determines max-flow min-cut ratio for directed multicommodity flows. In addition, this combinatorial problem has applications in improving the approximation factor of the greedy algorithm for the maximum edge disjoint path problem. More precisely, our upper bound improves the approximation factor for this problem to O(n3/4). ?? 2006 Elsevier B.V. All rights reserved.},
author = {Hajiaghayi, M. T. and Leighton, Tom},
doi = {10.1016/j.tcs.2005.10.037},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hajiaghayi, Leighton - 2006 - On the max-flow min-cut ratio for directed multicommodity flows.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Approximation algorithm,Directed graph,Multicommodity flow and multicut},
number = {1-3},
pages = {318--321},
title = {{On the max-flow min-cut ratio for directed multicommodity flows}},
volume = {352},
year = {2006}
}
@article{Chang2013,
author = {Chang, J and Khuller, S},
doi = {10.1137/1.9781611972931.2},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chang, Khuller - 2013 - A Min-Edge Cost Flow Framework for Capacitated Covering Problems.pdf:pdf},
isbn = {9781611972535},
issn = {21640300},
journal = {Alenex},
pages = {14--25},
title = {{A Min-Edge Cost Flow Framework for Capacitated Covering Problems.}},
url = {http://epubs.siam.org/doi/pdf/10.1137/1.9781611972931.2},
year = {2013}
}
@article{Slavik1997,
abstract = {algorithm is no worse ' Email: @math.buffalo  PAR TIAL  problem the ratio of  complete covers, and significantly  Kearns's estimate. },
author = {Slav{\'{i}}k, Petr},
doi = {10.1016/S0020-0190(97)00182-8},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Slav{\'{i}}k - 1997 - Improved performance of the greedy algorithm for partial cover.pdf:pdf},
issn = {00200190},
journal = {Information Processing Letters},
keywords = {approximation algorithms,combinatorial optimization,greedy algorithm,minimum cover,partial cover,set cover},
number = {5},
pages = {251--254},
title = {{Improved performance of the greedy algorithm for partial cover}},
volume = {64},
year = {1997}
}
@article{Leighton1999,
abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article. ACM has opted to expose the complete List rather than only correct and linked references.},
author = {Leighton, Tom and Rao, Satish},
doi = {10.1145/331524.331526},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leighton, Rao - 1999 - Multicommodity max-flow min-cut theorems and their use in designing approximation algorithms.pdf:pdf},
issn = {00045411},
journal = {Journal of the ACM},
number = {6},
pages = {787--832},
title = {{Multicommodity max-flow min-cut theorems and their use in designing approximation algorithms}},
volume = {46},
year = {1999}
}
@article{Attouch2011,
author = {Attouch, H and Svaiter, B F},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Attouch, Svaiter - 2011 - Downloaded 05 15 15 to 128 . 97 . 27 . 21 . Redistribution subject to SIAM license or copyright see httpww.pdf:pdf},
keywords = {34g25,47j25,47j30,47j35,49m15,49m37,65k15,90c25,absolutely continuous trajectories,ams subject classifications,dissipative dy-,gorithms,levenberg,lyapunov analysis,marquardt al-,maximal monotone operators,namical systems,newton-like algorithms,nonautonomous differential equations,numerical convex optimization,weak asymptotic convergence},
number = {2},
pages = {574--598},
title = {{Downloaded 05 / 15 / 15 to 128 . 97 . 27 . 21 . Redistribution subject to SIAM license or copyright ; see http://www.siam.org/journals/ojsa.php Copyright {\textcopyright} by SIAM . Unauthorized reproduction of this article is prohibited .}},
volume = {49},
year = {2011}
}
@article{Fujito2004,
author = {Fujito, Toshihiro},
doi = {10.1007/s10878-004-4836-8},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fujito - 2004 - On combinatorial approximation of covering 0-1 integer programs and partial set cover.pdf:pdf},
issn = {13826905},
journal = {Journal of Combinatorial Optimization},
keywords = {Approximation algorithm,Combinatorial optimization,Covering integer program,Partial cover},
number = {4},
pages = {439--452},
title = {{On combinatorial approximation of covering 0-1 integer programs and partial set cover}},
volume = {8},
year = {2004}
}
@inproceedings{Konemann2011,
abstract = {An instance of the generalized partial cover problem consists of a ground set U and a family of subsets S ⊆ 2 U . Each element e ∈ U is associated with a profit p(e), whereas each subset S ∈ S has a cost c(S). The objective is to find a minimum cost subcollection S ⊆ S such that the combined profit of the elements covered by S is at least P , a specified profit bound. In the prize-collecting version of this problem, there is no strict requirement to cover any element; however, if the subsets we pick leave an element e ∈ U uncovered, we incur a penalty of $\pi$(e). The goal is to identify a subcollection S ⊆ S that minimizes the cost of S plus the penalties of uncovered elements. Although problem-specific connections between the partial cover and the prize-collecting vari-ants of a given covering problem have been explored and exploited, a more general connection remained open. The main contribution of this paper is to establish a formal relationship between these two variants. As a result, we present a unified framework for approximating problems that can be formulated or interpreted as special cases of generalized partial cover. We demonstrate the applicability of our method on a diverse collection of covering problems, for some of which we obtain the first non-trivial approximability results.},
address = {Berlin},
author = {K{\"{o}}nemann, Jochen and Parekh, Ojas and Segev, Danny},
booktitle = {European Symposium on Algorithms},
doi = {10.1007/s00453-009-9317-0},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/K{\"{o}}nemann, Parekh, Segev - 2006 - A unified approach to approximating partial covering problems.pdf:pdf},
isbn = {978-3-540-38875-3},
issn = {01784617},
keywords = {Approximation algorithms,Lagrangian relaxation,Partial cover},
publisher = {Springer},
title = {{A unified approach to approximating partial covering problems}},
year = {2006}
}
@article{Svitkina2008,
abstract = {We introduce several generalizations of classical computer science problems obtained by replacing simpler objective functions with general submodular functions. The new problems include submodular load balancing, which generalizes load balancing or minimum-makespan scheduling, submodular sparsest cut and submodular balanced cut, which generalize their respective graph cut problems, as well as submodular function minimization with a cardinality lower bound. We establish upper and lower bounds for the approximability of these problems with a polynomial number of queries to a function-value oracle. The approximation guarantees that most of our algorithms achieve are of the order of $\sqrt{{n}/{\ln n}}$. We show that this is the inherent difficulty of the problems by proving matching lower bounds. We also give an improved lower bound for the problem of approximating a monotone submodular function everywhere. In addition, we present an algorithm for approximating submodular functions with a special structure, whose guarantee is close to the lower bound. Although quite restrictive, the class of functions with this structure includes the ones that are used for lower bounds both by us and in previous work},
archivePrefix = {arXiv},
arxivId = {0805.1071},
author = {Svitkina, Zoya and Fleischer, Lisa},
doi = {10.1109/FOCS.2008.66},
eprint = {0805.1071},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Svitkina, Fleischer - 2008 - Submodular approximation Sampling-based algorithms and lower bounds.pdf:pdf},
isbn = {9780769534367},
issn = {02725428},
journal = {Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS},
pages = {697--706},
title = {{Submodular approximation: Sampling-based algorithms and lower bounds}},
year = {2008}
}
@article{Hochbaum,
archivePrefix = {arXiv},
arxivId = {arXiv:1010.1945v1},
author = {Hochbaum, Dorit S},
eprint = {arXiv:1010.1945v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hochbaum - Unknown - Submodular problems - approximations and algorithms.pdf:pdf},
number = {Dmi},
pages = {1--14},
title = {{Submodular problems - approximations and algorithms}}
}
@article{Kolliopoulos2005,
abstract = {Given matrices A and B and vectors a, b, c and d, all with non-negative entries, we consider the problem of computing min{cTx:x∈Z+n,Ax≥a, Bx≤b,x≤d}. We give a bicriteria-approximation algorithm that, given $\epsilon$∈(0,1], finds a solution of cost O(ln(m)/$\epsilon$2) times optimal, meeting the covering constraints (Ax≥a) and multiplicity constraints (x≤d), and satisfying Bx≤(1+$\epsilon$)b+$\beta$, where $\beta$ is the vector of row sums $\beta$i=∑jBij. Here m denotes the number of rows of A. This gives an O(lnm)-approximation algorithm for CIP - minimum-cost covering integer programs with multiplicity constraints, i.e., the special case when there are no packing constraints Bx≤b. The previous best approximation ratio has been O(ln(maxj∑iAij)) since 1982. CIP contains the set cover problem as a special case, so O(lnm)-approximation is the best possible unless P=NP. {\textcopyright} 2005 Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {cs/0205030},
author = {Kolliopoulos, Stavros G. and Young, Neal E.},
doi = {10.1016/j.jcss.2005.05.002},
eprint = {0205030},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kolliopoulos, Young - 2005 - Approximation algorithms for coveringpacking integer programs.pdf:pdf},
issn = {00220000},
journal = {Journal of Computer and System Sciences},
keywords = {Approximation algorithms,Covering/packing integer programs,Multiplicity constraints,Set cover},
number = {4},
pages = {495--505},
primaryClass = {cs},
title = {{Approximation algorithms for covering/packing integer programs}},
volume = {71},
year = {2005}
}
@article{Koufogiannakis2013,
abstract = {This paper describes a greedy d--approximation algorithm for Monotone\nCovering, a generalization of many fundamental NP-hard covering problems. The\napproximation ratio d, is the maximum number of variables on which any\nconstraint depends. (For example, for Vertex Cover, d is 2.) The algorithm\nunifies, generalizes, and improves many previous algorithms for fundamental\ncovering problems such as vertex cover, set cover, facilities location, and\ninteger and mixed-integer covering linear programs with upper bound on the\nvariables.\nThe algorithm is also the first d-competitive algorithm for online monotone\ncovering, which generalizes online versions of the above-mentioned covering\nproblems as well as many fundamental online paging and caching problems. As\nsuch it also generalizes many classical online algorithms, including Lru, Fifo,\nFwf, Balance, Greedy-Dual, Greedy-Dual-Size (a.k.a. Landlord), and algorithms\nfor connection caching, where d is the cache size. It also gives new\nd-competitive algorithms for upgradable variants of these problems, which model\nchoosing the caching strategy and an appropriate hardware configuration (cache\nsize, CPU, bus, network, etc.).},
archivePrefix = {arXiv},
arxivId = {0807.0644v3},
author = {Koufogiannakis, Christos and Young, Neal E.},
doi = {10.1007/s00453-012-9629-3},
eprint = {0807.0644v3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koufogiannakis, Young - 2013 - Greedy -Approximation Algorithm for Covering with Arbitrary Constraints and Submodular Cost.pdf:pdf},
isbn = {3642029264},
issn = {01784617},
journal = {Algorithmica},
keywords = {Approximation algorithms,Caching,Competitive analysis,Covering,Integer linear programming,Linear programming,Local ratio,Online algorithms,Paging,Primal-dual,Set cover,Submodular cost,Vertex cover},
number = {1},
pages = {113--152},
title = {{Greedy ??-Approximation Algorithm for Covering with Arbitrary Constraints and Submodular Cost}},
volume = {66},
year = {2013}
}
@book{Chinchuluun2009,
abstract = {This book provides a complete and comprehensive reference/guide to Pyomo (Python Optimization Modeling Objects) for both beginning and advanced modelers, including students at the undergraduate and graduate levels, academic researchers, and practitioners. The text illustrates the breadth of the modeling and analysis capabilities that are supported by the software and support of complex real-world applications. Pyomo is an open source software package for formulating and solving large-scale optimization and operations research problems. The text begins with a tutorial on simple linear and integer programming models. A detailed reference of Pyomo's modeling components is illustrated with extensive examples, including a discussion of how to load data from data sources like spreadsheets and databases. Chapters describing advanced modeling capabilities for nonlinear and stochastic optimization are also included. The Pyomo software provides familiar modeling features within Python, a powerful dynamic programming language that has a very clear, readable syntax and intuitive object orientation. Pyomo includes Python classes for defining sparse sets, parameters, and variables, which can be used to formulate algebraic expressions that define objectives and constraints. Moreover, Pyomo can be used from a command-line interface and within Python's interactive command environment, which makes it easy to create Pyomo models, apply a variety of optimizers, and examine solutions. The software supports a different modeling approach than commercial AML (Algebraic Modeling Languages) tools, and is designed for flexibility, extensibility, portability, and maintainability but also maintains the central ideas in modern AMLs.},
author = {Chinchuluun, Radnaabazar and Lee, Won Suk and Bhorania, Jevin and Pardalos, Panos M},
booktitle = {Advances in Modeling Agricultural Systems},
doi = {10.1007/978-0-387-73669-3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chinchuluun et al. - 2009 - Springer Optimization and Its Applications.pdf:pdf},
isbn = {9781461437727},
pages = {1--22},
title = {{Springer Optimization and Its Applications}},
url = {papers2://publication/doi/10.1007/978-0-387-75181-8_21},
volume = {25},
year = {2009}
}
@article{Cao2015,
author = {Cao, Liqun and Li, Keqi and Luo, Jianlan and Wong, Yaushu},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cao et al. - 2015 - Downloaded 02 18 16 to 128 . 193 . 164 . 203 . Redistribution subject to SIAM license or copyright see httpwww.s.pdf:pdf},
keywords = {10,1137,140999694,65f10,78m05,ams subject classifications,composite,doi,edge finite element,fdtd,homogenization,materials,maxwell,multiscale asymptotic expansion,s equations},
number = {4},
pages = {1446--1477},
title = {{Downloaded 02 / 18 / 16 to 128 . 193 . 164 . 203 . Redistribution subject to SIAM license or copyright ; see http://www.siam.org/journals/ojsa.php Copyright {\textcopyright} by SIAM . Unauthorized reproduction of this article is prohibited .}},
volume = {13},
year = {2015}
}
@article{Agarwal2005,
author = {Agarwal, Amit and Charikar, Moses and Makarychev, Konstantin and Makarychev, Yury},
doi = {10.1145/1060590.1060675},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Agarwal et al. - 2005 - O(Vlog n) approximation algorithms for min UnCut, min 2CNF deletion, and directed cut problems.pdf:pdf},
isbn = {1581139608},
issn = {07378017},
journal = {Proceedings of the thirty-seventh annual ACM symposium on Theory of computing},
keywords = {ccr-0205594,ccr-0237113,directed balanced sepa-,directed sparsest cut,min 2cnf deletion,min multicut,min uncut,rator,supported by nsf grants},
pages = {573--581},
title = {{O(Vlog n) approximation algorithms for min UnCut, min 2CNF deletion, and directed cut problems}},
year = {2005}
}
@article{Hastad2001,
abstract = {We prove optimal, up to an arbitrary epsilon > 0, inapproximability results for Max-Ek-Sat for k greater than or equal to 3, maximizing the number of satisfied linear equations in an over-determined system of linear equations modulo a prime p and Set Splitting. As a consequence of these results we get improved lower bounds for the efficient approximability of many optimization problems studied previously. In particular, for Max-E2-Sat, Max-Cut, Max-di-Cut, and Vertex cover.},
author = {H{\aa}stad, Johan},
doi = {10.1145/502090.502098},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/H{\aa}stad - 2001 - Some optimal inapproximability results.pdf:pdf},
isbn = {0004-5411},
issn = {00045411},
journal = {Journal of the ACM},
number = {4},
pages = {798--859},
title = {{Some optimal inapproximability results}},
volume = {48},
year = {2001}
}
@article{Williamson2001,
author = {Williamson, David P},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Williamson - 2001 - Downloaded 04 22 15 to 193 . 0 . 108 . 41 . Redistribution subject to SIAM license or copyright see httpwww.siam..pdf:pdf},
keywords = {68q15,68q17,68w25,ams subject classifications,approximation algorithms,approximation classes,approximation-preserving re-,boolean constraint satisfaction problems,complete problems,ductions,hardness of approximation,pii,s0097539799349948},
number = {6},
pages = {1863--1920},
title = {{Downloaded 04 / 22 / 15 to 193 . 0 . 108 . 41 . Redistribution subject to SIAM license or copyright ; see http://www.siam.org/journals/ojsa.php THE APPROXIMABILITY OF CONSTRAINT SATISFACTION}},
volume = {30},
year = {2001}
}
@article{Newman2005,
abstract = {Betweenness is a measure of the centrality of a node in a network, and is normally calculated as the fraction of shortest paths between node pairs that pass through the node of interest. Betweenness is, in some sense, a measure of the influence a node has over the spread of information through the network. By counting only shortest paths, however, the conventional definition implicitly assumes that information spreads only along those shortest paths. Here, we propose a betweenness measure that relaxes this assumption, including contributions from essentially all paths between nodes, not just the shortest, although it still gives more weight to short paths. The measure is based on random walks, counting how often a node is traversed by a random walk between two other nodes. We show how our measure can be calculated using matrix methods, and give some examples of its application to particular networks.},
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0309045v1},
author = {Newman, M.E. J.},
doi = {10.1016/j.socnet.2004.11.009},
eprint = {0309045v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Newman - 2005 - A measure of betweenness centrality based on random walks.pdf:pdf},
issn = {03788733},
journal = {Social Networks},
keywords = {Betweenness,Centrality,Current flow,Random walks},
number = {1},
pages = {39--54},
primaryClass = {arXiv:cond-mat},
title = {{A measure of betweenness centrality based on random walks}},
url = {http://www.sciencedirect.com/science/article/pii/S0378873304000681},
volume = {27},
year = {2005}
}
@article{Teo2001,
author = {Teo, Chung-piaw},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Teo - 2001 - Downloaded 05 23 16 to 128 . 227 . 43 . 86 . Redistribution subject to SIAM license or copyright see httpwww.siam.orgjou.pdf:pdf},
keywords = {05c65,68q15,ams subject classifications,approximation algorithms,covering integer programs,discrete ham-sandwich theorems,flow,linear programming,multicommodity,packet routing,randomized algorithms,randomized rounding,rounding theorems},
number = {6},
pages = {2051--2068},
title = {{Downloaded 05 / 23 / 16 to 128 . 227 . 43 . 86 . Redistribution subject to SIAM license or copyright ; see http://www.siam.org/journals/ojsa.php A CONSTANT-FACTOR APPROXIMATION ALGORITHM FOR PACKET ROUTING AND BALANCING LOCAL VS . GLOBAL}},
volume = {30},
year = {2001}
}
@article{Freeman1991,
author = {Freeman, Linton C and White, Douglas R},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Freeman, White - 1991 - of Betweenness Based on Network Flow.pdf:pdf},
journal = {Social Networks},
pages = {141--154},
title = {{of Betweenness Based on Network Flow}},
volume = {13},
year = {1991}
}
@article{Newman2005a,
abstract = {Betweenness is a measure of the centrality of a node in a network, and is normally calculated as the fraction of shortest paths between node pairs that pass through the node of interest. Betweenness is, in some sense, a measure of the influence a node has over the spread of information through the network. By counting only shortest paths, however, the conventional definition implicitly assumes that information spreads only along those shortest paths. Here, we propose a betweenness measure that relaxes this assumption, including contributions from essentially all paths between nodes, not just the shortest, although it still gives more weight to short paths. The measure is based on random walks, counting how often a node is traversed by a random walk between two other nodes. We show how our measure can be calculated using matrix methods, and give some examples of its application to particular networks.},
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0309045v1},
author = {Newman, M.E. J.},
doi = {10.1016/j.socnet.2004.11.009},
eprint = {0309045v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Newman - 2005 - A measure of betweenness centrality based on random walks.pdf:pdf},
issn = {03788733},
journal = {Social Networks},
keywords = {Betweenness,Centrality,Current flow,Random walks},
number = {1},
pages = {39--54},
primaryClass = {arXiv:cond-mat},
title = {{A measure of betweenness centrality based on random walks}},
url = {http://www.sciencedirect.com/science/article/pii/S0378873304000681},
volume = {27},
year = {2005}
}
@article{Dinh2015a,
author = {Dinh, Thang N. and Thai, My T.},
doi = {10.1109/TNET.2014.2317486},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dinh, Thai - 2015 - Network under joint node and link attacks Vulnerability assessment methods and analysis.pdf:pdf},
issn = {10636692},
journal = {IEEE/ACM Transactions on Networking},
keywords = {Approximation algorithm,joint node and link attacks,vulnerability assessment},
number = {3},
pages = {1001--1011},
title = {{Network under joint node and link attacks: Vulnerability assessment methods and analysis}},
volume = {23},
year = {2015}
}
@article{Dinh2015,
abstract = {A considerable amount of research effort has focused on developing metrics and approaches to assess network vulnerability. However, most of them neglect the network uncertainty arisen due to various reasons such as mobility and dynamics of the network, or noise introduced in data collection process. To this end, we introduce a framework to assess vulnerability of networks with uncertainty, modeling such networks as probabilistic graphs. We adopt expected pairwise connectivity (EPC) as a measure to quantify global connectivity and use it to formulate vulnerability assessment as a stochastic optimization problem. The objective is to identify a few number of critical nodes whose removal minimizes EPC in the residual network. While solutions for stochastic optimization problems are often limited to small networks, we present a practical solution that works for larger networks. The key advantages of our solution include 1) the application of a weighted averaging technique that avoids considering all, exponentially many, possible realizations of probabilistic graphs and 2) a Fully Polynomial Time Randomized Approximation Scheme (FPRAS) to efficiently estimate the EPC with any desired accuracy. Extensive experiments demonstrate significant improvement on performance of our solution over other heuristic approaches.},
author = {Dinh, Thang N. and Thai, My T.},
doi = {10.1109/INFOCOM.2015.7218626},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dinh, Thai - 2015 - Assessing attack vulnerability in networks with uncertainty.pdf:pdf},
isbn = {9781479983810},
issn = {0743166X},
journal = {Proceedings - IEEE INFOCOM},
pages = {2380--2388},
title = {{Assessing attack vulnerability in networks with uncertainty}},
volume = {26},
year = {2015}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2016 - No Title(2).pdf:pdf},
pages = {2016},
title = {{No Title}},
year = {2016}
}
@article{Kolliopoulos2003,
author = {Kolliopoulos, Stavros G},
doi = {10.1016/S0166-218X(02)00598-X},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kolliopoulos - 2003 - Approximating covering integer programs with multiplicity constraints.pdf:pdf},
keywords = {approximation algorithms,covering integer programs,integrality gap,set multicover},
pages = {461--473},
title = {{Approximating covering integer programs with multiplicity constraints}},
volume = {129},
year = {2003}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2016 - No Title.pdf:pdf},
pages = {1--2},
title = {{No Title}},
year = {2016}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2016 - No Title.pdf:pdf},
pages = {1--2},
title = {{No Title}},
year = {2016}
}
@article{Roberts2007,
author = {Roberts, Ben and Kroese, Dirk P.},
doi = {10.7155/jgaa.00142},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roberts, Kroese - 2007 - Estimating the Number of s-t Paths in a Graph.pdf:pdf},
issn = {1526-1719},
journal = {Journal of Graph Algorithms and Applications},
number = {1},
pages = {195--214},
title = {{Estimating the Number of s-t Paths in a Graph}},
url = {http://www.cs.brown.edu/sites/jgaa/accepted/2007/RobertsKroese2007.11.1.pdf},
volume = {11},
year = {2007}
}
@book{Vazirani2001,
abstract = {This book covers the dominant theoretical approaches to the approximate solution of hard combinatorial optimization and enumeration problems. It contains elegant combinatorial theory, useful and interesting algorithms, and deep results about the intrinsic complexity of combinatorial problems. Its clarity of exposition and excellent selection of exercises will make it accessible and appealing to all those with a taste for mathematics and algorithms. Richard Karp,University Professor, University of California at Berkeley Following the development of basic combinatorial optimization techniques in the 1960s and 1970s, a main open question was to develop a theory of approximation algorithms. In the 1990s, parallel developments in techniques for designing approximation algorithms as well as methods for proving hardness of approximation results have led to a beautiful theory. The need to solve truly large instances of computationally hard problems, such as those arising from the Internet or the human genome project, has also increased interest in this theory. The field is currently very active, with the toolbox of approximation algorithm design techniques getting always richer. It is a pleasure to recommend Vijay Vazirani's well-written and comprehensive book on this important and timely topic. I am sure the reader will find it most useful both as an introduction to approximability as well as a reference to the many aspects of approximation algorithms. L&225;szl&243; Lov&225;sz, Senior Researcher, Microsoft Research},
author = {Vazirani, Vijay V},
doi = {10.1002/rsa.10038},
edition = {First},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vazirani - 2003 - Approximation Algorithms.pdf:pdf},
isbn = {3540653678},
issn = {15579964},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Approximation Algorithms}},
url = {http://books.google.de/books?hl=de&lr=&id=EILqAmzKgYIC&oi=fnd&pg=PA1&dq=approximation+algorithms+Vazirani&ots=XjcZIFWO71&sig=jJqn-M08BfJT0KVmzqDXBzV7D_Q},
year = {2003}
}
@book{Du2013a,
abstract = {Combinatorial (or discrete) optimization is one of the most active fields in the interface of operations research, computer science, and applied math ematics. Combinatorial optimization problems arise in various applications, including communications network design, VLSI design, machine vision, air line crew scheduling, corporate planning, computer-aided design and man ufacturing, database query design, cellular telephone frequency assignment, constraint directed reasoning, and computational biology. Furthermore, combinatorial optimization problems occur in many diverse areas such as linear and integer programming, graph theory, artificial intelligence, and number theory. All these problems, when formulated mathematically as the minimization or maximization of a certain function defined on some domain, have a commonality of discreteness. Historically, combinatorial optimization starts with linear programming. Linear programming has an entire range of important applications including production planning and distribution, personnel assignment, finance, alloca tion of economic resources, circuit simulation, and control systems. Leonid Kantorovich and Tjalling Koopmans received the Nobel Prize (1975) for their work on the optimal allocation of resources. Two important discover ies, the ellipsoid method (1979) and interior point approaches (1984) both provide polynomial time algorithms for linear programming. These algo rithms have had a profound effect in combinatorial optimization. Many polynomial-time solvable combinatorial optimization problems are special cases of linear programming (e.g. matching and maximum flow). In addi tion, linear programming relaxations are often the basis for many approxi mation algorithms for solving NP-hard problems (e.g. dual heuristics).},
archivePrefix = {arXiv},
arxivId = {1502.07718},
author = {Du, Hongwei and Wu, Weili and Wu, Lidong and Xing, Kai and Zhang, Xuefei and Li, Deying},
doi = {10.1007/978-1-4419-7997-1},
eprint = {1502.07718},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Du et al. - 2013 - Handbook of Combinatorial Optimization.pdf:pdf},
isbn = {978-1-4419-7996-4},
pages = {2359--2389},
title = {{Handbook of Combinatorial Optimization}},
url = {http://link.springer.com/10.1007/978-1-4419-7997-1},
year = {2013}
}
@article{Dinh2012a,
abstract = {Simultaneous attacks can cause devastating damage, breaking down communication networks into small fragments. To mitigate the risk and develop proactive responses, it is essential to assess the robustness of network in the worst-case scenarios. In this paper, we propose a spectral lower-bound on the number of removed links to incur a certain level of disruption in terms of pairwise connectivity. Our lower-bound explores the latent structural information in the network Laplacian spectrum, the set of eigenvalues of the Laplacian matrix, to provide guarantees on the robustness of the network against intentional attacks. Such guarantees often cannot be found in heuristic methods for identifying critical infrastructures. For the first time, the attack-resistant proofs of large scale communication networks against link attacks are presented. {\textcopyright} 2012 IEEE.},
author = {Dinh, Thang N. and Shen, Yilin and Thai, My T.},
doi = {10.1109/MILCOM.2012.6415860},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dinh, Shen, Thai - 2012 - An efficient spectral bound for link vulnerability assessment in large-scale networks.pdf:pdf},
isbn = {9781467317290},
journal = {Proceedings - IEEE Military Communications Conference MILCOM},
keywords = {Lower-bound method,pairwise connectivity,spectral algorithm,vulnerability assessment},
pages = {1--6},
title = {{An efficient spectral bound for link vulnerability assessment in large-scale networks}},
year = {2012}
}
@article{Riondato2014,
author = {Riondato, Matteo and Kornaropoulos, Evgenios M.},
doi = {10.1145/2556195.2556224},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Riondato, Kornaropoulos - 2014 - Fast approximation of betweenness centrality through sampling.pdf:pdf},
isbn = {9781450323512},
issn = {13845810},
journal = {Proceedings of the 7th ACM international conference on Web search and data mining - WSDM '14},
keywords = {Approximation algorithms,Betweenness centrality,Sampling,Social network analysis,VC-dimension},
pages = {413--422},
title = {{Fast approximation of betweenness centrality through sampling}},
url = {http://dl.acm.org/citation.cfm?doid=2556195.2556224},
year = {2014}
}
@article{Bergamini2014,
abstract = {Betweenness centrality ranks the importance of nodes by their participation in all shortest paths of the network. Therefore computing exact betweenness values is impractical in large networks. For static networks, approximation based on randomly sampled paths has been shown to be significantly faster in practice. However, for dynamic networks, no approximation algorithm for betweenness centrality is known that improves on static recomputation. We address this deficit by proposing two incremental approximation algorithms (for weighted and unweighted connected graphs) which provide a provable guarantee on the absolute approximation error. Processing batches of edge insertions, our algorithms yield significant speedups up to a factor of $10^4$ compared to restarting the approximation. This is enabled by investing memory to store and efficiently update shortest paths. As a building block, we also propose an asymptotically faster algorithm for updating the SSSP problem in unweighted graphs. Our experimental study shows that our algorithms are the first to make in-memory computation of a betweenness ranking practical for million-edge semi-dynamic networks. Moreover, our results show that the accuracy is even better than the theoretical guarantees in terms of absolutes errors and the rank of nodes is well preserved, in particular for those with high betweenness.},
archivePrefix = {arXiv},
arxivId = {1409.6241},
author = {Bergamini, Elisabetta and Meyerhenke, Henning and Staudt, Christian L.},
eprint = {1409.6241},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bergamini, Meyerhenke, Staudt - 2014 - Approximating Betweenness Centrality in Large Evolving Networks.pdf:pdf},
issn = {21640300},
journal = {Siam},
keywords = {algorithmic network analysis,approximation al-,betweenness centrality,gorithms,graph algorithms,shortest paths},
pages = {17},
title = {{Approximating Betweenness Centrality in Large Evolving Networks}},
url = {http://epubs.siam.org/doi/abs/10.1137/1.9781611973754.12%5Cnhttp://arxiv.org/abs/1409.6241},
year = {2014}
}
@article{White2001a,
abstract = {A network is robust to the extent that it is not vulnerable to disconnection\nby removal of nodes.\n\nThe minimum number of nodes that need be removed to disconnect a pair\nof other nodes is called\n\nthe connectivity of the pair. It can be proved that the connectivity\nis also equal to the number\n\nof node-independent paths between nodes, and hence we can quantify\nnetwork robustness by\n\ncalculating numbers of node-independent paths. Unfortunately, computing\nsuch numbers is\n\nknown to be an NP-hard problem, taking exponentially long to run to\ncompletion. In this\n\npaper, we present an approximation algorithm which gives good lower\nbounds on numbers of\n\nnode-independent paths between any pair of nodes on a directed or\nundirected graph in worst-\n\ncase time which is linear in the graph size. A variant of the same\nalgorithm can also calculate\n\nall the k-components of a graph in the same approximation. Our algorithm\nis found empirically\n\nto work with better than 99% accuracy on random graphs and for several\nreal-world networks is\n\n100% accurate. As a demonstration of the algorithm, we apply it to\ntwo large graphs for which\n\nthe traditional NP-hard algorithm is entirely intractable|a network\nof collaborations between\n\nscientists and a network of business ties between biotechnology rms.},
author = {White, Douglas R and Newman, M E J},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/White, Newman - 2001 - Fast approximation algorithms for finding node-independent paths in networks.pdf:pdf},
journal = {Working Papers},
pages = {07--035},
title = {{Fast approximation algorithms for finding node-independent paths in networks}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.8287&rep=rep1&type=pdf},
volume = {1},
year = {2001}
}
@article{Brandes2007,
abstract = {Centrality indices are an essential concept in network analysis. For those based on shortest-path distances the computation is at least quadratic in the number of nodes, since it usually involves solving the single-source shortest-paths (SSSP) problem from every node. Therefore, exact computation is infeasible for many large networks of interest today. Centrality scores can be estimated, however, from a limited number of SSSP computations. We present results from an experimental study of the quality of such estimates under various selection strategies for the source vertices.},
author = {Brandes, Ulrik and Pich, Christian},
doi = {10.1142/S0218127407018403},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brandes, Pich - 2007 - Centrality Estimation in Large Networks.pdf:pdf},
issn = {0218-1274},
journal = {International Journal of Bifurcation and Chaos},
number = {07},
pages = {2303--2318},
title = {{Centrality Estimation in Large Networks}},
volume = {17},
year = {2007}
}
@article{Kang2011,
abstract = {Node centrality measures are important in a large number of graph applications, from search and ranking to social and biological network analysis. In this paper we study node centrality for very large graphs, up to billions of nodes and edges. Various definitions for centrality have been proposed, ranging from very simple (e.g., node degree) to more elab- orate. However, measuring centrality in billion-scale graphs poses several challenges. Many of the traditional defini- tions such as closeness and betweenness were not designed with scalability in mind. Therefore, it is very difficult, if not impossible, to compute them both accurately and effi- ciently. In this paper, we propose centrality measures suit- able for very large graphs, as well as scalable methods to effectively compute them. More specifically, we propose effective closeness and LINERANK which are designed for billion-scale graphs. We also develop algorithms to compute the proposed centrality measures in MAPREDUCE, a mod- ern paradigm for large-scale, distributed data processing. We present extensive experimental results on both synthetic and real datasets, which demonstrate the scalability of our ap- proach to very large graphs, as well as interesting findings and anomalies.},
author = {Kang, U},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kang - 2011 - Centralities in Large Networks Algorithms and Observations.pdf:pdf},
isbn = {978-0-898719-92-5},
journal = {SIAM International Conference on Data},
pages = {119--130},
title = {{Centralities in Large Networks : Algorithms and Observations}},
url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Centralities+in+Large+Networks:+Algorithms+and+Observations#0},
year = {2011}
}
@article{Chen2015a,
abstract = {Cascading failure is one of the most central topics in the field of complex networks. In this paper, the cascading failure model is extended to the case of interdependent networks, and the effect of coupling preference on systems robustness is intensively investigated. It is found that the performance of coupling preference on robustness is dependent on coupling probability. Disassortative coupling is more robust for sparse coupling while assortative coupling performs better for dense coupling. We provide an explanation for this constructive phenomenon via examining cascading process from the microscopic point of view. Our work can be useful to the design and optimization of interdependent networked systems.},
author = {Chen, Zhen and Du, Wen Bo and Cao, Xian Bin and Zhou, Xing Lian},
doi = {10.1016/j.chaos.2015.03.005},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2015 - Cascading failure of interdependent networks with different coupling preference under targeted attack.pdf:pdf},
issn = {09600779},
journal = {Chaos, Solitons and Fractals},
pages = {7--12},
publisher = {Elsevier Ltd},
title = {{Cascading failure of interdependent networks with different coupling preference under targeted attack}},
url = {http://dx.doi.org/10.1016/j.chaos.2015.03.005},
volume = {80},
year = {2015}
}
@article{BELL2014,
abstract = {In this paper we examine natural generalizations of four widely used centrality measures to subgroups of nodes in a network. This allows for a division into local and global influence. As an example, we analyze a classic network and discuss previously hidden features made visible by these new techniques. Network-wide measures and centralization formulae are derived.},
author = {BELL, JOCELYN R.},
doi = {10.1017/nws.2014.15},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/BELL - 2014 - Subgroup centrality measures.pdf:pdf},
issn = {2050-1242},
journal = {Network Science},
keywords = {attribute subgroups,centrality,centralization},
number = {02},
pages = {277--297},
title = {{Subgroup centrality measures}},
url = {http://journals.cambridge.org/abstract_S2050124214000150},
volume = {2},
year = {2014}
}
@article{CHANG2015,
abstract = {In this paper, we develop a formal framework for what a good community should look like and how strong a community is (community strength). One of the key innovations is to incorporate the concept of relative centrality into structural analysis of networks. In our framework, relative centrality is a measure that measures how important a set of nodes in a network is with respect to another set of nodes, and it is a generalization of centrality. Building on top of relative centrality, the community strength for a set of nodes is measured by the difference between its relative centrality with respect to itself and its centrality. A community is then a set of nodes with a nonnegative community strength. We show that our community strength is related to conductance that is commonly used for measuring the strength of a small community. We define the modularity for a partition of a network as the average community strength for a randomly selected node. Such a definition generalizes the original Newman's modularity and recovers the stability in as special cases. For the local community detection problem, we also develop efficient agglomerative algorithms that guarantee the community strength of the detected local community.},
author = {Chang, Cheng-Shang and Chang, Chih-Jung and Hsieh, Wen-Ting and Lee, Duan-Shin and Liou, Li-Heng and Liao, Wanjiun},
doi = {10.1017/nws.2015.23},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chang et al. - 2015 - Relative centrality and local community detection.pdf:pdf},
isbn = {2050124215000},
issn = {2050-1242},
journal = {Network Science},
number = {04},
pages = {445--479},
title = {{Relative centrality and local community detection}},
url = {http://www.journals.cambridge.org/abstract_S2050124215000235},
volume = {3},
year = {2015}
}
@article{Saxena2016,
author = {Saxena, Akrati},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saxena - 2016 - Estimating the Degree Centrality Ranking.pdf:pdf},
isbn = {9781467396226},
pages = {1--2},
title = {{Estimating the Degree Centrality Ranking}},
year = {2016}
}
@article{Brandes2016,
abstract = {Betweenness centrality is generally regarded as a measure of others' dependence on a given node, and therefore as a measure of potential control. Closeness centrality is usually interpreted either as a measure of access efficiency or of independence from potential control by intermediaries. Betweenness and closeness are commonly assumed to be related for two reasons: first, because of their conceptual duality with respect to dependency, and second, because both are defined in terms of shortest paths. We show that the first of these ideas - the duality - is not only true in a general conceptual sense but also in precise mathematical terms. This becomes apparent when the two indices are expressed in terms of a shared dyadic dependency relation. We also show that the second idea - the shortest paths - is false because it is not preserved when the indices are generalized using the standard definition of shortest paths in valued graphs. This unveils that closeness-as-independence is in fact different from closeness-as-efficiency, and we propose a variant notion of distance that maintains the duality of closeness-as-independence with betweenness also on valued relations.},
author = {Brandes, Ulrik and Borgatti, Stephen P. and Freeman, Linton C.},
doi = {10.1016/j.socnet.2015.08.003},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brandes, Borgatti, Freeman - 2016 - Maintaining the duality of closeness and betweenness centrality.pdf:pdf},
isbn = {03788733},
issn = {03788733},
journal = {Social Networks},
keywords = {Betweenness centrality,Closeness centrality,Dependency,Derived relations,Duality},
pages = {153--159},
publisher = {Elsevier B.V.},
title = {{Maintaining the duality of closeness and betweenness centrality}},
url = {http://dx.doi.org/10.1016/j.socnet.2015.08.003},
volume = {44},
year = {2016}
}
@article{Phillips,
author = {Phillips, Cynthia and Sundberg, Eric},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phillips, Sundberg - Unknown - Multicriteria approximation through decomposition Sven Krumke y f S 2S that Ax g ( S ).pdf:pdf},
title = {{Multicriteria approximation through decomposition Sven Krumke y f : S 2S that Ax g ( S )}}
}
@article{Elsherif2015,
author = {Elsherif, Ahmed R and Chen, Wei-peng and Ito, Akira and Ding, Zhi},
doi = {10.1109/TCOMM.2015.2420676},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elsherif et al. - 2015 - Adaptive Resource Allocation for Interference Management in Small Cell Networks.pdf:pdf},
number = {6},
pages = {2107--2125},
title = {{Adaptive Resource Allocation for Interference Management in Small Cell Networks}},
volume = {63},
year = {2015}
}
@article{Centola2007,
abstract = {Random links between otherwise distant nodes can greatly facilitate the propagation of disease or information, provided contagion can be transmitted by a single active node. However, we show that when the propagation requires simultaneous exposure to multiple sources of activation, called complex propagation, the effect of random links can be just the opposite; it can make the propagation more difficult to achieve. We numerically calculate critical points for a threshold model using several classes of complex networks, including an empirical social network. We also provide an estimation of the critical values in terms of vulnerable nodes. ?? 2006 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {physics/0504165},
author = {Centola, Damon and Egu??luz, V??ctor M. and Macy, Michael W.},
doi = {10.1016/j.physa.2006.06.018},
eprint = {0504165},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Centola, Eguluz, Macy - 2007 - Cascade dynamics of complex propagation.pdf:pdf},
isbn = {0378-4371},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {Sociophysics},
number = {1},
pages = {449--456},
primaryClass = {physics},
title = {{Cascade dynamics of complex propagation}},
volume = {374},
year = {2007}
}
@article{Murray2007,
abstract = {Effective management of critical network infrastructure requires the assessment of potential interdiction scenarios. Optimization approaches have been essential for identifying and evaluating such scenarios in networked systems. Although a primary function of any network is the distribution of flow between origins and destinations, the complexity and difficulty of mathematically abstracting interdiction impacts on connectivity or flow has been a challenge for researchers. This paper presents an optimization approach for identifying interdiction bounds with respect to connectivity and/or flow associated with a system of origins and destinations. Application results for telecommunications flow are presented, illustrating the capabilities of this approach. [ABSTRACT FROM AUTHOR]},
author = {Murray, Alan T. and Matisziw, Timothy C. and Grubesic, Tony H.},
doi = {10.1007/s10109-006-0039-4},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Murray, Matisziw, Grubesic - 2007 - Critical network infrastructure analysis Interdiction and system flow.pdf:pdf},
isbn = {1435-5930},
issn = {14355930},
journal = {Journal of Geographical Systems},
number = {2},
pages = {103--117},
title = {{Critical network infrastructure analysis: Interdiction and system flow}},
volume = {9},
year = {2007}
}
@article{Barclay2013,
abstract = {BACKGROUND: Research suggests that the growing prevalence of obesity may be related to the influence of the health behaviours of peers. We look at clustering of exercise and eating health behaviours amongst a previously unstudied group, young adults in Sweden. Previous research has mainly been conducted in the United States and Britain, countries that have relatively high rates of obesity. METHODS: Using ego-alter dyads from the egocentric network data as the unit of analysis, we conduct logistic regressions to investigate the association between ego and alter exercise and eating behaviours. RESULTS: Respondents have a significantly greater probability of engaging in regular exercise and eating healthily if a nominated peer also does so. Furthermore, the degree to which this behavior is shared is modulated by the strength of the relationship between the two individuals, with a greater probability of engaging in these behaviours observed when the relationship with the nominated peer is strong relative to when the relationship is weak. However, we find that ego-alter homogeneity in terms of gender and migration status was not associated with a significantly greater probability of behaving in a similar manner to a nominated peer. Furthermore, the status of the nominated peer as a relative or not did not impact the probability that the ego would engage in similar health behaviours to that alter. CONCLUSIONS: We observe strong associations between ego and alter health behaviours for young adults, consistent with previous research. Although we cannot draw causal inferences, these results suggest that the health behaviours of an individual's peers may play a role in shaping their own health behaviours.},
author = {Barclay, Kieron J and Edling, Christofer and Rydgren, Jens},
doi = {10.1186/1471-2458-13-784},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barclay, Edling, Rydgren - 2013 - Peer Clustering of Exercise and Eating Behaviours Among Young Adults in Sweden A Cross-Sectional Study.pdf:pdf},
isbn = {1471-2458},
issn = {1471-2458},
journal = {BMC Public Health},
keywords = {behaviours,egocentric data,social clustering of health,social networks},
pages = {1--3},
pmid = {23981951},
title = {{Peer Clustering of Exercise and Eating Behaviours Among Young Adults in Sweden: A Cross-Sectional Study of Egocentric Network Data}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3765927&tool=pmcentrez&rendertype=abstract},
volume = {13},
year = {2013}
}
@article{Richardson2008,
author = {Richardson, Chris},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Richardson - 2008 - in Dynamic.pdf:pdf},
isbn = {6638194100},
number = {June},
pages = {487--496},
title = {{in Dynamic}},
year = {2008}
}
@article{Lu2011,
author = {Lu, Linyuan and Chen, Duan-Bing and Zhou, Tao},
doi = {10.1088/1367-2630/13/12/123005},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu, Chen, Zhou - 2011 - The small world yields the most effective information spreading.pdf:pdf},
journal = {New Journal of Physics},
pages = {123005},
title = {{The small world yields the most effective information spreading}},
volume = {13},
year = {2011}
}
@article{Malik2016,
author = {Malik, Nishant and Mucha, Peter J},
doi = {10.1063/1.4833995},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Malik, Mucha - 2016 - networks Role of social environment and social clustering in spread of opinions in coevolving networks.pdf:pdf},
number = {May},
title = {{networks Role of social environment and social clustering in spread of opinions in coevolving networks}},
volume = {043123},
year = {2016}
}
@article{Centola2010,
author = {Centola, Damon},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Centola - 2010 - The Spread of Behavior in an Online Social Network Experiment.pdf:pdf},
journal = {Science},
number = {5996},
pages = {1194--1197},
title = {{The Spread of Behavior in an Online Social Network Experiment}},
volume = {329},
year = {2010}
}
@article{Centola2011,
author = {Centola, Damon},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Centola - 2011 - An Experimental Study of Homophily in the Adoption of Health Behavior.pdf:pdf},
journal = {Science},
number = {December},
pages = {1269--1272},
title = {{An Experimental Study of Homophily in the Adoption of Health Behavior}},
volume = {334},
year = {2011}
}
@inproceedings{Chen2010a,
archivePrefix = {arXiv},
arxivId = {1204.4491},
author = {Chen, Wei and Wang, Chi and Wang, Yajun},
booktitle = {Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)},
doi = {10.1145/1835804.1835934},
eprint = {1204.4491},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Wang, Wang - 2010 - Scalable influence maximization for prevalent viral marketing in large-scale social networks.pdf:pdf},
isbn = {9781450300551},
issn = {02664348},
keywords = {influence maximization,social networks,viral marketing},
pages = {1029--1038},
title = {{Scalable influence maximization for prevalent viral marketing in large-scale social networks}},
url = {http://dl.acm.org/citation.cfm?doid=1835804.1835934},
year = {2010}
}
@article{Cohen2009,
author = {Cohen, Edith and Kaplan, H and Aviv, Tel},
doi = {10.1145/1555349.1555379},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen, Kaplan, Aviv - 2009 - Leveraging discarded samples for tighter estimation of multiple-set aggregates.pdf:pdf},
isbn = {9781605585116},
journal = {ACM SIGMETRICS Performance Evaluation Review},
number = {1},
pages = {251--262},
title = {{Leveraging discarded samples for tighter estimation of multiple-set aggregates}},
url = {http://dl.acm.org/citation.cfm?id=1555379},
volume = {37},
year = {2009}
}
@inproceedings{Golovin2007,
author = {Golovin, Daniel and Krause, Andreas},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Golovin, Krause - 2007 - Adaptive Submodularity A New Approach to Active Learning and Stochastic Optimization.pdf:pdf},
title = {{Adaptive Submodularity : A New Approach to Active Learning and Stochastic Optimization}},
year = {2007}
}
@article{Goyal2013,
abstract = {In recent years, study of influence propagation in social networks has gained tremendous attention. In this context, we can identify three orthogonal dimensions—the number of seed nodes activated at the beginning (known as budget ), the expected number of activated nodes at the end of the propagation (known as expected spread or coverage ), and the time taken for the propagation. We can constrain one or two of these and try to optimize the third. In their seminal paper, Kempe et al. constrained the budget, left time unconstrained, and maximized the coverage: this problem is known as Influence Maximization (or MAXINF for short). In this paper, we study alternative optimization problems which are naturally motivated by resource and time constraints on viral marketing campaigns. In the first problem, termed minimum target set selection (or MINTSS for short), a coverage threshold $\eta$ is given and the task is to find the minimum size seed set such that by activating it, at least $\eta$ nodes are eventually activated in the expected sense. This naturally captures the problem of deploying a viral campaign on a budget. In the second problem, termed MINTIME, the goal is to minimize the time in which a predefined coverage is achieved. More precisely, in MINTIME, a coverage threshold $\eta$ and a budget threshold k are given, and the task is to find a seed set of size at most k such that by activating it, at least $\eta$ nodes are activated in the expected sense, in the minimum possible time . This problem addresses the issue of timing when deploying viral campaigns. Both these problems are NP -hard, which motivates our interest in their approximation. For MINTSS, we develop a simple greedy algorithm and show that it provides a bicriteria approximation. We also establish a generic hardness result suggesting that improving this bicriteria approximation is likely to be hard. For MINTIME, we show that even bicriteria and tricriteria approximations are hard under several conditions. We show, however, that if we allow the budget for number of seeds k to be boosted by a logarithmic factor and allow the coverage to fall short, then the problem can be solved exactly in PTIME, i.e., we can achieve the required coverage within the time achieved by the optimal solution to MINTIME with budget k and coverage threshold $\eta$. Finally, we establish the value of the approximation algorithms, by conducting an experimental evaluation, comparing their quality against that achieved by various heuristics.},
author = {Goyal, Amit and Bonchi, Francesco and Lakshmanan, Laks V S and Venkatasubramanian, Suresh},
doi = {10.1007/s13278-012-0062-z},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goyal et al. - 2013 - On minimizing budget and time in influence propagation over social networks.pdf:pdf},
isbn = {1869-5450},
issn = {18695469},
journal = {Social Network Analysis and Mining},
keywords = {Approximation analysis,Influence propagation,MINTIME,MINTSS,Social influence,Social networks,Viral marketing},
number = {2},
pages = {179--192},
title = {{On minimizing budget and time in influence propagation over social networks}},
volume = {3},
year = {2013}
}
@inproceedings{Chen2015,
abstract = {In this paper, we propose the amphibious influence maximization (AIM) model that combines traditional marketing via content providers and viral marketing to consumers in social networks in a single framework. In AIM, a set of content providers and consumers form a bipartite network while consumers also form their social network, and influence propagates from the content providers to consumers and among consumers in the social network following the independent cascade model. An advertiser needs to select a subset of seed content providers and a subset of seed consumers, such that the influence from the seed providers passing through the seed consumers could reach a large number of consumers in the social network in expectation. We prove that the AIM problem is NP-hard to approximate to within any constant factor via a reduction from Feige's k-prover proof system for 3-SAT5. We also give evidence that even when the social network graph is trivial (i.e. has no edges), a polynomial time constant factor approximation for AIM is unlikely. However, when we assume that the weighted bi-adjacency matrix that describes the influence of content providers on consumers is of constant rank, a common assumption often used in recommender systems, we provide a polynomial-time algorithm that achieves approximation ratio of $(1-1/e-\epsilon)^3$ for any (polynomially small) $\epsilon > 0$. Our algorithmic results still hold for a more general model where cascades in social network follow a general monotone and submodular function.},
archivePrefix = {arXiv},
arxivId = {1507.03328},
author = {Chen, Wei and Li, Fu and Lin, Tian and Rubinstein, Aviad},
booktitle = {Proceedings of the 16th ACM Conference on Economics and Computation},
doi = {10.1145/2764468.2764480},
eprint = {1507.03328},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2015 - Combining Traditional Marketing and Viral Marketing with Amphibious Influence Maximization.pdf:pdf},
isbn = {6136113600},
pages = {779--796},
title = {{Combining Traditional Marketing and Viral Marketing with Amphibious Influence Maximization}},
url = {http://arxiv.org/abs/1507.03328},
year = {2015}
}
@inproceedings{Zhang2014,
abstract = {A topic propagating in a social network reaches its tipping point if the number of users discussing it in the network exceeds a critical threshold such that a wide cascade on the topic is likely to occur. In this paper, we consider the task of selecting initial seed users of a topic with minimum size so that {\em with a guaranteed probability} the number of users discussing the topic would reach a given threshold. We formulate the task as an optimization problem called {\em seed minimization with probabilistic coverage guarantee (SM-PCG)}. This problem departs from the previous studies on social influence maximization or seed minimization because it considers influence coverage with {\em probabilistic} guarantees instead of guarantees on {\em expected} influence coverage. We show that the problem is not submodular, and thus is harder than previously studied problems based on submodular function optimization. We provide an approximation algorithm and show that it approximates the optimal solution with both a multiplicative ratio and an additive error. The multiplicative ratio is tight while the additive error would be small if influence coverage distributions of certain seed sets are well concentrated. For one-way bipartite graphs we analytically prove the concentration condition and obtain an approximation algorithm with an $O(\log n)$ multiplicative ratio and an $O(\sqrt{n})$ additive error, where $n$ is the total number of nodes in the social graph. Moreover, we empirically verify the concentration condition in real-world networks and experimentally demonstrate the effectiveness of our proposed algorithm comparing to commonly adopted benchmark algorithms.},
archivePrefix = {arXiv},
arxivId = {arXiv:1402.5516v1},
author = {Zhang, Peng and Chen, Wei and Sun, Xiaoming and Wang, Yajun and Zhang, Jialin},
booktitle = {Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining},
doi = {10.1145/2623330.2623684},
eprint = {arXiv:1402.5516v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2014 - Minimizing Seed Set Selection with Probabilistic Coverage Guarantee in a Social Network.pdf:pdf},
isbn = {9781450329569},
keywords = {independent cascade model,influence diffusion,seed minimization,social networks},
pages = {1306--1315},
title = {{Minimizing Seed Set Selection with Probabilistic Coverage Guarantee in a Social Network}},
year = {2014}
}
@article{Myers2010,
abstract = {In many real-world scenarios, it is nearly impossible to collect explicit social network data. In such cases, whole networks must be inferred from underlying observations. Here, we formulate the problem of inferring latent social networks based on network diffusion or disease propagation data. We consider contagions propagating over the edges of an unobserved social network, where we only observe the times when nodes became infected, but not who infected them. Given such node infection times, we then identify the optimal network that best explains the observed data. We present a maximum likelihood approach based on convex programming with a l1-like penalty term that encourages sparsity. Experiments on real and synthetic data reveal that our method near-perfectly recovers the underlying network structure as well as the parameters of the contagion propagation model. Moreover, our approach scales well as it can infer optimal networks of thousands of nodes in a matter of minutes.},
archivePrefix = {arXiv},
arxivId = {1010.5504},
author = {Myers, Seth A. SA and Leskovec, Jure},
eprint = {1010.5504},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Myers, Leskovec - 2010 - On the Convexity of Latent Social Network Inference.pdf:pdf},
isbn = {9781617823800},
journal = {Icml},
pages = {1--9},
title = {{On the Convexity of Latent Social Network Inference}},
url = {http://arxiv.org/abs/1010.5504},
year = {2010}
}
@article{Lin2013,
abstract = {Learning of the information diffusion model is a fundamental problem in the study of information diffusion in social networks. Existing approaches learn the diffusion models from events in social networks. However, events in social networks may have different underlying reasons. Some of them may be caused by the social influence inside the network, while others may reflect external trends in the ``real world''. Most existing work on the learning of diffusion models does not distinguish the events caused by the social influence from those caused by external trends.  In this paper, we extract social events from data streams in social networks, and then use the extracted social events to improve the learning of information diffusion models. We propose a LADP (Latent Action Diffusion Path) model to incorporate the information diffusion model with the model of external trends, and then design an EM-based algorithm to infer the diffusion probabilities, the external trends and the sources of events efficiently.},
author = {Lin, Shuyang and Wang, Fengjiao and Hu, Qingbo and Yu, Philip S.},
doi = {10.1145/2487575.2487584},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin et al. - 2013 - Extracting social events for learning better information diffusion models.pdf:pdf},
isbn = {9781450321747},
journal = {Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '13},
keywords = {information diffusion,social event,social influence},
pages = {365},
title = {{Extracting social events for learning better information diffusion models}},
url = {http://dl.acm.org/citation.cfm?doid=2487575.2487584},
year = {2013}
}
@article{Saito2008,
abstract = {We address a problem of predicting diffusion probabilities in complex networks. As one approach to this problem, we focus on the independent cascade (IC) model, and define the likelihood for information diffusion episodes, where an episode means a sequence of newly active nodes. Then, we present a method for predicting diffusion probabilities by using the EM algorithm. Our experiments using a real network data set show the proposed method works well.},
author = {Saito, Kazumi and Nakano, Ryohei and Kimura, Masahiro},
doi = {10.1007/978-3-540-85567-5-9},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saito, Nakano, Kimura - 2008 - Prediction of information diffusion probabilities for independent cascade model.pdf:pdf},
isbn = {3540855661},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 3},
pages = {67--75},
title = {{Prediction of information diffusion probabilities for independent cascade model}},
volume = {5179 LNAI},
year = {2008}
}
@article{Khandekar2010,
abstract = {Long-Term Evolution (LTE) allows operators to use new and wider spectrum and complements 3G networks with higher data rates, lower latency and a flat IP-based architecture. To further improve broadband user experience in a ubiquitous and cost effective manner, 3GPP has been working on various aspects in the framework of LTE Advanced. Since radio link performance is approaching theoretical limits with 3G enhancements and LTE, the next performance leap in wireless networks will come from the network topology. LTE Advanced is about improving spectral efficiency per unit area. Using a mix of macro, pico, femto and relay base-stations, heterogeneous networks enable flexible and low-cost deployments and provide a uniform broadband experience to users anywhere in the network. This paper discusses the need for an alternative deployment model or topology using heterogeneous networks. To enhance the performance of these networks, advanced techniques are described which are needed to manage and control interference and deliver the full benefits of such networks. Range extension allows more user terminals to benefit directly from low-power base-stations such as picos, femtos, and relays. Adaptive inter-cell interference coordination provides smart resource allocation amongst interfering cells and improves inter-cell fairness in a heterogeneous network. In addition, the performance gains with heterogeneous networks using an example macro/pico network are shown.},
author = {Khandekar, Aamod and Bhushan, Naga and Tingfang, Ji and Vanghi, Vieri},
doi = {10.1109/EW.2010.5483516},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khandekar et al. - 2010 - LTE-advanced Heterogeneous networks.pdf:pdf},
isbn = {9781424459995},
journal = {2010 European Wireless Conference, EW 2010},
pages = {978--982},
title = {{LTE-advanced: Heterogeneous networks}},
year = {2010}
}
@article{When1982,
author = {Wolsey, Laurence A.},
doi = {10.1007/BF02579435},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wolsey - 1982 - An analysis of the greedy algorithm for the submodular set covering problem.pdf:pdf},
issn = {02099683},
journal = {October},
number = {4},
pages = {385--393},
title = {{An analysis of the greedy algorithm for the submodular set covering problem}},
volume = {2},
year = {1982}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2009 - 1 The Switching Lemma.pdf:pdf},
pages = {1--9},
title = {{1 The Switching Lemma}},
year = {2009}
}
@article{Fackler2005,
abstract = {Interesting results for Kronecker and Vector operators as well as differentiation results using them (summarized at the end)},
author = {Fackler, Paul L and Fackler, Paul L},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fackler, Fackler - 2005 - Notes on Matrix Calculus.pdf:pdf},
journal = {North},
pages = {1--14},
title = {{Notes on Matrix Calculus}},
year = {2005}
}
@inproceedings{Borgs2014,
abstract = {Diffusion is a fundamental graph process, underpinning such phenomena as epidemic disease contagion and the spread of innovation by word-of-mouth. We address the algorithmic problem of finding a set of k initial seed nodes in a network so that the expected size of the resulting cascade is maximized, under the standard independent cascade model of network diffusion. Runtime is a primary consideration for this problem due to the massive size of the relevant input networks. We provide a fast algorithm for the influence maximization problem, obtaining the near-optimal approximation factor of (1 - 1/e - epsilon), for any epsilon > 0, in time O((m+n)log(n) / epsilon^3). Our algorithm is runtime-optimal (up to a logarithmic factor) and substantially improves upon the previously best-known algorithms which run in time Omega(mnk POLY(1/epsilon)). Furthermore, our algorithm can be modified to allow early termination: if it is terminated after O(beta(m+n)log(n)) steps for some beta < 1 (which can depend on n), then it returns a solution with approximation factor O(beta). Finally, we show that this runtime is optimal (up to logarithmic factors) for any beta and fixed seed size k.},
archivePrefix = {arXiv},
arxivId = {arXiv:1212.0884v4},
author = {Borgs, Christian and Brautbar, Michael and Chayes, Jennifer and Lucier, Brendan},
booktitle = {Proceedings of the Twenty-Fifth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
doi = {10.1137/1.9781611973402.70},
eprint = {arXiv:1212.0884v4},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Borgs et al. - 2014 - Maximizing Social Influence in Nearly Optimal Time.pdf:pdf},
isbn = {978-1-61197-338-9, 978-1-61197-340-2},
pages = {946--957},
title = {{Maximizing Social Influence in Nearly Optimal Time}},
year = {2014}
}
@article{Rodriguez2011,
abstract = {Time plays an essential role in the diffusion of information, influence and disease over networks. In many cases we only observe when a node copies information, makes a decision or becomes infected -- but the connectivity, transmission rates between nodes and transmission sources are unknown. Inferring the underlying dynamics is of outstanding interest since it enables forecasting, influencing and retarding infections, broadly construed. To this end, we model diffusion processes as discrete networks of continuous temporal processes occurring at different rates. Given cascade data -- observed infection times of nodes -- we infer the edges of the global diffusion network and estimate the transmission rates of each edge that best explain the observed data. The optimization problem is convex. The model naturally (without heuristics) imposes sparse solutions and requires no parameter tuning. The problem decouples into a collection of independent smaller problems, thus scaling easily to networks on the order of hundreds of thousands of nodes. Experiments on real and synthetic data show that our algorithm both recovers the edges of diffusion networks and accurately estimates their transmission rates from cascade data.},
archivePrefix = {arXiv},
arxivId = {1105.0697},
author = {Rodriguez, Manuel Gomez and Balduzzi, David and Sch{\"{o}}lkopf, Bernhard},
eprint = {1105.0697},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rodriguez, Balduzzi, Sch{\"{o}}lkopf - 2011 - Uncovering the Temporal Dynamics of Diffusion Networks.pdf:pdf},
isbn = {978-1-4503-0619-5},
journal = {Proceedings of the 28th International Conference on Machine Learning},
keywords = {Brain Computer Interfaces,Computational,Information-Theoretic Learning with,Learning/Statistics & Optimisation,Theory & Algorithms},
pages = {561--568},
title = {{Uncovering the Temporal Dynamics of Diffusion Networks}},
url = {http://eprints.pascal-network.org/archive/00008675/%5Cnhttp://arxiv.org/abs/1105.0697},
year = {2011}
}
@article{Gomez-Rodriguez2010,
abstract = {Information diffusion and virus propagation are fundamental processes taking place in networks. While it is often possible to directly observe when nodes become infected with a virus or adopt the information, observing individual transmissions (i.e., who infects whom, or who influences whom) is typically very difficult. Furthermore, in many applications, the underlying network over which the diffusions and propagations spread is actually unobserved. We tackle these challenges by developing a method for tracing paths of diffusion and influence through networks and inferring the networks over which contagions propagate. Given the times when nodes adopt pieces of information or become infected, we identify the optimal network that best explains the observed infection times. Since the optimization problem is NP-hard to solve exactly, we develop an efficient approximation algorithm that scales to large datasets and finds provably near-optimal networks. We demonstrate the effectiveness of our approach by tracing information diffusion in a set of 170 million blogs and news articles over a one year period to infer how information flows through the online media space. We find that the diffusion network of news for the top 1,000 media sites and blogs tends to have a core-periphery structure with a small set of core media sites that diffuse information to the rest of the Web. These sites tend to have stable circles of influence with more general news media sites acting as connectors between them.},
archivePrefix = {arXiv},
arxivId = {1006.0234},
author = {Gomez-Rodriguez, Manuel and Leskovec, Jure and Krause, Andreas},
doi = {10.1145/1835804.1835933},
eprint = {1006.0234},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gomez-Rodriguez, Leskovec, Krause - 2010 - Inferring networks of diffusion and influence.pdf:pdf},
isbn = {9781450300551},
issn = {15564681},
journal = {Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '10},
keywords = {Data Structures and Algorithms,Machine Learning,Physics and Society,blogs,information cascades,meme-tracking,networks of diffusion,news media,social networks},
pages = {1019--1028},
title = {{Inferring networks of diffusion and influence}},
url = {http://dl.acm.org/citation.cfm?id=1835804.1835933%5Cnhttp://arxiv.org/abs/1006.0234},
year = {2010}
}
@inproceedings{Myers2012,
abstract = {Social networks play a fundamental role in the diffusion of information. However, there are two different ways of how information reaches a person in a network. Information reaches us through connections in our social networks, as well as through the influence external out-of-network sources, like the mainstream media. While most present models of information adoption in networks assume information only passes from a node to node via the edges of the underlying network, the recent availability of massive online social media data allows us to study this process in more detail. We present a model in which information can reach a node via the links of the social network or through the influence of external sources. We then develop an efficient model parameter fitting technique and apply the model to the emergence of URL mentions in the Twitter network. Using a complete one month trace of Twitter we study how information reaches the nodes of the network. We quantify the external influences over time and describe how these influences affect the information adoption. We discover that the information tends to "jump" across the network, which can only be explained as an effect of an unobservable external influence on the network. We find that only about 71% of the information volume in Twitter can be attributed to network diffusion, and the remaining 29% is due to external events and factors outside the network. {\textcopyright} 2012 ACM.},
archivePrefix = {arXiv},
arxivId = {1206.1331},
author = {Myers, Seth A. and Zhu, Chenguang and Leskovec, Jure},
booktitle = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/2339530.2339540},
eprint = {1206.1331},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Myers, Zhu, Leskovec - 2012 - Information diffusion and external influence in networks.pdf:pdf},
isbn = {9781450314626},
issn = {1450314627},
keywords = {a node,by a big circle,denoted,diffusion of innovations,external influence,figure 1,influence,infor-,information cascades,is exposed to information,mation diffusion,our model of external,social networks,through an external,twitter},
pages = {33--41},
title = {{Information diffusion and external influence in networks}},
url = {http://dl.acm.org/citation.cfm?doid=2339530.2339540%5Cnhttp://www.scopus.com/inward/record.url?eid=2-s2.0-84866021278&partnerID=tZOtx3y1},
year = {2012}
}
@article{Chen2010,
abstract = {Influence maximization is the problem of finding a small set of most influential nodes in a social network so that their aggregated influence in the network is maximized. In this paper, we study influence maximization in the linear threshold model, one of the important models formalizing the behavior of influence propagation in social networks. We first show that computing exact influence in general networks in the linear threshold model is #P-hard, which closes an open problem left in the seminal work on influence maximization by Kempe, Kleinberg, and Tardos, 2003. As a contrast, we show that computing influence in directed a cyclic graphs (DAGs) can be done in time linear to the size of the graphs. Based on the fast computation in DAGs, we propose the first scalable influence maximization algorithm tailored for the linear threshold model. We conduct extensive simulations to show that our algorithm is scalable to networks with millions of nodes and edges, is orders of magnitude faster than the greedy approximation algorithm proposed by Kempe et al. and its optimized versions, and performs consistently among the best algorithms while other heuristic algorithms not design specifically for the linear threshold model have unstable performances on different real-world networks.},
author = {Chen, Wei and Yuan, Yifei and Zhang, Li},
doi = {10.1109/ICDM.2010.118},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Yuan, Zhang - 2010 - Scalable influence maximization in social networks under the linear threshold model.pdf:pdf},
isbn = {9780769542560},
issn = {15504786},
journal = {Proceedings - IEEE International Conference on Data Mining, ICDM},
keywords = {Influence maximization,Linear threshold model,Social networks},
pages = {88--97},
title = {{Scalable influence maximization in social networks under the linear threshold model}},
year = {2010}
}
@article{Chen,
author = {Chen, Wei and Wang, Yajun},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Wang - Unknown - Efficient Influence Maximization in Social Networks Categories and Subject Descriptors.pdf:pdf},
isbn = {9781605584959},
keywords = {all or part of,heuristic algorithms,influence maximization,is granted without fee,or hard copies of,permission to make digital,personal or classroom use,provided that copies are,social networks,this work for},
pages = {199--207},
title = {{Efficient Influence Maximization in Social Networks Categories and Subject Descriptors}}
}
@article{Jaynes1963,
author = {Jaynes, Edwin T},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaynes - 1963 - Information Theory and Statistical Mechanics.pdf:pdf},
journal = {Statistical Physics},
pages = {181--218},
title = {{Information Theory and Statistical Mechanics}},
year = {1963}
}
@article{Hanley2008,
abstract = {Participants in this study attempted to name 44 famous people i n response to reading biographical information about them. Half of the celebrities had names that contained two words (e.g., Gwyneth Paltrow and Sean Penn), and half of them had names containing three words (e.g., Catherine Zeta Jones and Billy Bob Thornton). Half of the names had previously been judged to be of high familiarity (e.g., Gwyneth Paltrow), and half were of lower familiarity (e.g., Billy Bob Thornton). The results showed that when in a tip-of-the-tongue (TOT) state, the participants were able to estimate at above-chance rates whether a celebrity's name comprised two or three words. Accurate information about the number of words was not available to the participants unless they were in a TOT state or had already named the person. Attempts to identify celebrities whose name had three elements were associated with an increased number of TOTs, relative to celebrities whose name had two units, but there was no difference in the number of don't know responses for names containing two or three words. Calculations based on Gollan and Brown (2006) suggested that having three names impaired the phonological but not the semantic stage of lexical retrieval, whereas low familiarity impaired both semantic and phonological retrieval stages.},
author = {Hanley, J Richard and Chapman, Eleanor},
doi = {10.3758/PBR.15.1.156},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hanley, Chapman - 2008 - partial knowledge, entropy, and estimation.pdf:pdf},
issn = {1069-9384},
journal = {Psychonomic bulletin & review},
keywords = {Adolescent,Adult,Association Learning,Female,Humans,Male,Memory, Short-Term,Mental Recall,Names,Neural Networks (Computer),Reading,Recognition (Psychology),Retention (Psychology),Set (Psychology),Short-Term,Verbal Learning},
number = {1},
pages = {156--60},
pmid = {18605496},
title = {partial knowledge, entropy, and estimation},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21514402},
volume = {15},
year = {2008}
}
@article{Outcomes2010,
author = {Outcomes, Pharmaceutical and Drive, Newell and Building, Hpnp and Box, P O},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Outcomes et al. - 2010 - The Foundation for The Gator Nation.pdf:pdf},
isbn = {3528462000},
journal = {Building},
number = {863},
pages = {100496--100496},
title = {{The Foundation for The Gator Nation}},
year = {2010}
}
@article{Papadimitriou1991,
abstract = {We define a natural variant of NP, MAX NP, and also a subclass called MAX SNP. These are classes of optimization problems, and in fact contain several natural, well-studied ones. We show that problems in these classes can be approximated with some bounded error. Furthermore, we show that a number of common optimization problems are complete for MAX SNP under a kind of careful transformation (called L-reduction) that preserves approximability. It follows that such a complete problem has a polynomial-time approximation scheme iff the whole class does. These results may help explain the lack of progress on the approximability of a host of optimization problems. ?? 1991.},
author = {Papadimitriou, Christos H. and Yannakakis, Mihalis},
doi = {10.1016/0022-0000(91)90023-X},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Papadimitriou, Yannakakis - 1991 - Optimization, approximation, and complexity classes.pdf:pdf},
isbn = {0897912640},
issn = {10902724},
journal = {Journal of Computer and System Sciences},
number = {3},
pages = {425--440},
title = {{Optimization, approximation, and complexity classes}},
volume = {43},
year = {1991}
}
@article{Arora1998,
abstract = {Note: {OCR} errors may be found in this Reference List extracted from\nthe full text article. {ACM} has opted to expose the complete List\nrather than only correct and linked references.},
author = {Arora, Sanjeev},
doi = {10.1145/276698.276784},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arora - 1998 - The approximability of NP-hard problems.pdf:pdf},
isbn = {0897919629},
issn = {07349025},
journal = {Proceedings of the thirtieth annual ACM symposium on Theory of computing - STOC '98},
pages = {337--348},
title = {{The approximability of NP-hard problems}},
url = {http://portal.acm.org/citation.cfm?doid=276698.276784},
year = {1998}
}
@article{Cohen2015,
abstract = {Graph datasets with billions of edges, such as social and Web graphs, are prevalent. To be feasible, computation on such large graphs should scale linearly with graph size. All-distances sketches (ADSs) are emerging as a powerful tool for scalable computation of some basic properties of individual nodes or the whole graph. ADSs were first proposed two decades ago (Cohen 1994) and more recent algorithms include ANF (Palmer, Gibbons, and Faloutsos 2002) and hyperANF (Boldi, Rosa, and Vigna 2011). A sketch of logarithmic size is computed for each node in the graph and the computation in total requires only a near linear number of edge relaxations. From the ADS of a node, we can estimate its neighborhood cardinalities (the number of nodes within some query distance) and closeness centrality. We make several contributions. We provide, for the first time, a unified exposition of ADS algorithms and applications. We present the Historic Inverse Probability (HIP) estimators which are applied to the ADS of a node to estimate a large natural class of queries including neighborhood cardinalities and closeness centralities. We show that our HIP estimators have at most half the variance of previous neighborhood cardinality estimators and that this is essentially optimal. Moreover, HIP obtains a polynomial improvement for more general queries and the estimators are simple, flexible, unbiased, and elegant. We apply HIP for approximate distinct counting on streams by comparing HIP and the original estimators applied to the HyperLogLog Min-Hash sketches (Flajolet et al. 2007). We demonstrate significant improvement in estimation quality for this state-of-the-art practical algorithm and also illustrate the ease of applying HIP. Finally, we study the quality of ADS estimation of distance ranges, generalizing the near-linear time factor-2 approximation of the diameter.},
archivePrefix = {arXiv},
arxivId = {1306.3284},
author = {Cohen, Edith},
doi = {10.1109/TKDE.2015.2411606},
eprint = {1306.3284},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen - 2015 - All-Distances Sketches, Revisited HIP Estimators for Massive Graphs Analysis.pdf:pdf},
isbn = {9781450323758},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {All-distances sketches,HIP estimators,approximate counting,approximate distinct counting,closeness centrality,distance smoothing kernel},
number = {9},
pages = {2320--2334},
title = {{All-Distances Sketches, Revisited: HIP Estimators for Massive Graphs Analysis}},
volume = {27},
year = {2015}
}
@article{Gomez-Rodriguez2016,
author = {Gomez-Rodriguez, Manuel and Song, Le and Du, Nan and Zha, Hongyuan and Sch{\"{o}}lkopf, Bernhard},
doi = {10.1145/2824253},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gomez-Rodriguez et al. - 2016 - Influence Estimation and Maximization in Continuous-Time Diffusion Networks.pdf:pdf},
issn = {10468188},
journal = {ACM Transactions on Information Systems},
number = {2},
pages = {1--33},
title = {{Influence Estimation and Maximization in Continuous-Time Diffusion Networks}},
url = {http://dl.acm.org/citation.cfm?doid=2891107.2824253},
volume = {34},
year = {2016}
}
@article{Song2015a,
author = {Song, Chonggang and Hsu, Wynne and Lee, Mong Li},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Song, Hsu, Lee - 2015 - Node Immunization over Infectious Period(2).pdf:pdf},
isbn = {9781450337946},
journal = {Proceedings of the 24th ACM International Conference on Information and Knowledge Management},
pages = {831--840},
title = {{Node Immunization over Infectious Period}},
year = {2015}
}
@article{Cohen2014,
abstract = {We consider a cost model for diffusion in a network that captures both the scope of infection and its propagation time: The edges of the network have associated lengths which model transmission times, and influence scores are higher for faster propagation. We propose an intuitive measure of {\it timed influence}, which extends and unifies several classic measures, including the well-studied "binary" influence [Richardson and Domingos 2002; Kempe et al. 2003] (which only measures scope), a recently-studied {\it threshold} model of timed influence [Gomez-Rodriguez et al. 2011] (which considers a node influenced only within a fixed time horizon), and {\it closeness centrality} (which is extended from being defined for a single node to multiple seed nodes and from a fixed network to distributions). Finally, we provide the first highly scalable algorithms for timed influence computation and maximization. In particular, we improve by orders of magnitude the scalability of state-of-the-art threshold timed influence computation. Moreover, our design provides robust guarantees and is novel also as a theoretical contribution.},
archivePrefix = {arXiv},
arxivId = {1410.6976},
author = {Cohen, Edith and Delling, Daniel and Pajor, Thomas and Werneck, Renato F},
eprint = {1410.6976},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen et al. - 2014 - Timed Influence Computation and Maximization.pdf:pdf},
pages = {18},
title = {{Timed Influence: Computation and Maximization}},
url = {http://arxiv.org/abs/1410.6976},
year = {2014}
}
@article{Wang2016,
abstract = {The rapid growth of online social networks is important for viral marketing. Influence maximization refers to the process of finding influential users who make the most of information or product adoption. An independent cascade-based model for influence maximization, called IMIC-OC, was proposed to calculate positive influence. We assumed that influential users spread positive opinions. At the beginning, users held positive or negative opinions as their initial opinions. When more users became involved in the discussions, users balanced their own opinions and those of their neighbors. The number of users who did not change positive opinions was used to determine positive influence. Corresponding influential users who had maximum positive influence were then obtained. Experiments were conducted on three real networks, namely, Facebook, HEP-PH and Epinions, to calculate maximum positive influence based on the IMIC-OC model and two other baseline methods. The proposed model resulted in larger positive influence, thus indicating better performance compared with the baseline methods.},
author = {Wang, Qiyao and Jin, Yuehui and Lin, Zhen and Cheng, Shiduan and Yang, Tan},
doi = {10.1016/j.physa.2015.10.020},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2016 - Influence maximization in social networks under an independent cascade-based model.pdf:pdf},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {Independent cascade-based model,Influence maximization,Opinion change,Positive influence,Social networks},
number = {2},
pages = {20--34},
publisher = {Elsevier B.V.},
title = {{Influence maximization in social networks under an independent cascade-based model}},
url = {http://dx.doi.org/10.1016/j.physa.2015.10.020},
volume = {444},
year = {2016}
}
@inproceedings{Cohen2014a,
abstract = {Propagation of contagion through networks is a fundamental process. It is used to model the spread of information, influence, or a viral infection. Diffusion patterns can be specified by a probabilistic model, such as Independent Cascade (IC), or captured by a set of representative traces. Basic computational problems in the study of diffusion are influence queries (determining the potency of a specified seed set of nodes) and Influence Maximization (identifying the most influential seed set of a given size). Answering each influence query involves many edge traversals, and does not scale when there are many queries on very large graphs. The gold standard for Influence Maximization is the greedy algorithm, which iteratively adds to the seed set a node maximizing the marginal gain in influence. Greedy has a guaranteed approximation ratio of at least (1-1/e) and actually produces a sequence of nodes, with each prefix having approximation guarantee with respect to the same-size optimum. Since Greedy does not scale well beyond a few million edges, for larger inputs one must currently use either heuristics or alternative algorithms designed for a pre-specified small seed set size. We develop a novel sketch-based design for influence computation. Our greedy Sketch-based Influence Maximization (SKIM) algorithm scales to graphs with billions of edges, with one to two orders of magnitude speedup over the best greedy methods. It still has a guaranteed approximation ratio, and in practice its quality nearly matches that of exact greedy. We also present influence oracles, which use linear-time preprocessing to generate a small sketch for each node, allowing the influence of any seed set to be quickly answered from the sketches of its nodes.},
archivePrefix = {arXiv},
arxivId = {1408.6282},
author = {Cohen, Edith and Delling, Daniel and Pajor, Thomas and Werneck, Renato F.},
booktitle = {Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management (CIKM)},
doi = {10.1145/2661829.2662077},
eprint = {1408.6282},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen et al. - 2014 - Sketch-based Influence Maximization and Computation Scaling up with Guarantees.pdf:pdf},
isbn = {9781450325981},
pages = {629--638},
title = {{Sketch-based Influence Maximization and Computation: Scaling up with Guarantees}},
url = {http://arxiv.org/abs/1408.6282%5Cnhttp://dx.doi.org/10.1145/2661829.2662077},
year = {2014}
}
@inproceedings{Tang2015,
abstract = {برای همه مدلهای انتشار پیچیدگی زمانی و تقریب در حد TIM اما در عمل بهتر عمل میکند},
author = {Tang, Youze},
booktitle = {Proceedings of the 2015 International Conference on Management of Data (SIGMOD)},
doi = {10.1145/2723372.2723734},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tang - 2015 - Influence Maximization in Near-Linear Time A Martingale Approach.pdf:pdf},
isbn = {9781450327589},
keywords = {influence maximization,sampling},
pages = {1539--1554},
publisher = {ACM},
title = {{Influence Maximization in Near-Linear Time : A Martingale Approach}},
year = {2015}
}
@article{Xie2013,
abstract = {Existing dictionary learning algorithms are based on the assumption that the data are vectors in an Euclidean vector space ℝ (d) , and the dictionary is learned from the training data using the vector space structure of ℝ (d) and its Euclidean L (2)-metric. However, in many applications, features and data often originated from a Riemannian manifold that does not support a global linear (vector space) structure. Furthermore, the extrinsic viewpoint of existing dictionary learning algorithms becomes inappropriate for modeling and incorporating the intrinsic geometry of the manifold that is potentially important and critical to the application. This paper proposes a novel framework for sparse coding and dictionary learning for data on a Riemannian manifold, and it shows that the existing sparse coding and dictionary learning methods can be considered as special (Euclidean) cases of the more general framework proposed here. We show that both the dictionary and sparse coding can be effectively computed for several important classes of Riemannian manifolds, and we validate the proposed method using two well-known classification problems in computer vision and medical imaging analysis.},
author = {Xie, Yuchen and Ho, Jeffrey and Vemuri, Baba},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie, Ho, Vemuri - 2013 - On A Nonlinear Generalization of Sparse Coding and Dictionary Learning.pdf:pdf},
journal = {Machine learning : proceedings of the International Conference. International Conference on Machine Learning},
keywords = {Dictionary Learning,Differential G,Sparse Coding},
pages = {1480--1488},
pmid = {24129583},
title = {{On A Nonlinear Generalization of Sparse Coding and Dictionary Learning.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3796141&tool=pmcentrez&rendertype=abstract},
volume = {28},
year = {2013}
}
@article{Spellman2005,
abstract = { Image retrieval is a common problem in many computer vision applications and the literature abounds with techniques with impressive retrieval accuracies. Several of these techniques use probability distributions to represent the "objects" they intend to retrieve. We present a novel approach to search such collections of distributions efficiently. Like many standard data structures, our method uses an "average" to represent a large set (Le., cluster) of objects, thus allowing the search to disregard an unpromising subset with only one comparison to its average. Our contribution lies in choosing the average: Inspired by information theory, we choose a representative that is optimally "close" in a minimax sense to all members of its set when measured using the Kullback-Liebler (KL) divergence. We present a texture retrieval system and test it on the CUReT database, measuring accuracy and efficiency. We find that using the KL-center yields speed ups of more than a factor of three over an exhaustive search while guaranteeing identical accuracy. The KL-center also out-performs other commonly used representatives such as the arithmetic mean. Although we present results only in texture retrieval, our approach will likely aid image and shape retrieval as well.},
author = {Spellman, E. and Vemuri, B.C. and Rao, M.},
doi = {10.1109/CVPR.2005.363},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Spellman, Vemuri, Rao - 2005 - Using the KL-center for efficient and accurate retrieval of distributions arising from texture images.pdf:pdf},
isbn = {0-7695-2372-2},
issn = {1063-6919},
journal = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
title = {{Using the KL-center for efficient and accurate retrieval of distributions arising from texture images}},
volume = {1},
year = {2005}
}
@article{Xie2013a,
abstract = {In this paper, we propose a novel framework for computing single or multiple atlases (templates) from a large population of images. Unlike many existing methods, our proposed approach is distinguished by its emphasis on the sharpness of the computed atlases and the requirement of rotational invariance. In particular, we argue that sharp atlas images that retain crucial and important anatomical features with high fidelity are more useful for many medical imaging applications when compared with the blurry and fuzzy atlas images computed by most existing methods. The geometric notion that underlies our approach is the idea of manifold learning in a quotient space, the quotient space of the image space by the rotations. We present an extension of the existing manifold learning approach to quotient spaces by using invariant metrics, and utilizing the manifold structure for partitioning the images into more homogeneous sub-collections, each of which can be represented by a single atlas image. Specifically, we propose a three-step algorithm. First, we partition the input images into subgroups using unsupervised or semi-supervised learning methods on manifolds. Then we formulate a convex optimization problem in each subgroup to locate the atlases and determine the crucial neighbors that are used in the realization step to form the template images. We have evaluated our algorithm using whole brain MR volumes from OASIS database. Experimental results demonstrate that the atlases computed using the proposed algorithm not only discover the brain structural changes in different age groups but also preserve important structural details and generally enjoy better image quality.},
author = {Xie, Yuchen and Ho, Jeffrey and Vemuri, Baba C.},
doi = {10.1109/TMI.2013.2239654},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie, Ho, Vemuri - 2013 - Multiple atlas construction from a heterogeneous brain MR image collection.pdf:pdf},
isbn = {0278-0062 VO - 32},
issn = {02780062},
journal = {IEEE Transactions on Medical Imaging},
keywords = {Atlas construction,Manifolds,Optimization,Semi-supervised learning},
number = {3},
pages = {628--635},
pmid = {23335665},
title = {{Multiple atlas construction from a heterogeneous brain MR image collection}},
volume = {32},
year = {2013}
}
@article{Du2013,
abstract = {If a piece of information is released from a media site, can it spread, in 1 month, to a million web pages? This influence estimation problem is very challenging since both the time-sensitive nature of the problem and the issue of scalability need to be addressed simultaneously. In this paper, we propose a randomized algorithm for influence estimation in continuous-time diffusion networks. Our algorithm can estimate the influence of every node in a network with |\Vcal| nodes and |\Ecal| edges to an accuracy of ϵ using n=O(1/ϵ2) randomizations and up to logarithmic factors O(n|\Ecal|+n|\Vcal|) computations. When used as a subroutine in a greedy influence maximization algorithm, our proposed method is guaranteed to find a set of nodes with an influence of at least (1−1/e)OPT−2ϵ, where OPT is the optimal value. Experiments on both synthetic and real-world data show that the proposed method can easily scale up to networks of millions of nodes while significantly improves over previous state-of-the-arts in terms of the accuracy of the estimated influence and the quality of the selected nodes in maximizing the influence.},
archivePrefix = {arXiv},
arxivId = {1311.3669},
author = {Du, Nan and Song, Le and Gomez-Rodriguez, Manuel and Zha, Hongyuan},
eprint = {1311.3669},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Du et al. - 2013 - Scalable Influence Estimation in Continuous-Time Diffusion Networks.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems (NIPS)},
title = {{Scalable Influence Estimation in Continuous-Time Diffusion Networks}},
url = {http://papers.nips.cc/paper/4857-scalable-influence-estimation-in-continuous-time-diffusion-networks.pdf},
year = {2013}
}
@article{Cohen1997,
abstract = {Computing the transitive closure in directed graphs is a fundamental graph problem. We consider the more restricted problem of computing the number of nodes reachable from every node and the size of the transitive closure. The fastest known transitive closure algorithms run inO(min{mn, n2.38}) time, wherenis the number of nodes andmthe number of edges in the graph. We present anO(m) time randomized (Monte Carlo) algorithm that estimates, with small relative error, the sizes of all reachability sets and the transitive closure. Another ramification of our estimation scheme is a {\~{O}}(m) time algorithm for estimating sizes of neighborhoods in directed graphs with nonnegative edge lengths. Our size-estimation algorithms are much faster than performing the respective explicit computations.},
author = {Cohen, Edith},
doi = {10.1006/jcss.1997.1534},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen - 1997 - Size-Estimation Framework with Applications to Transitive Closure and Reachability.pdf:pdf},
issn = {00220000},
journal = {Journal of Computer and System Sciences},
number = {3},
pages = {441--453},
title = {{Size-Estimation Framework with Applications to Transitive Closure and Reachability}},
url = {http://dx.doi.org/10.1006/jcss.1997.1534},
volume = {55},
year = {1997}
}
@inproceedings{Tang2014,
abstract = {Given a social network G and a constant k, the influence maximization problem asks for k nodes in G that (directly and indirectly) influence the largest number of nodes under a pre-defined diffusion model. This problem finds important applications in viral marketing, and has been extensively studied in the literature. Existing algorithms for influence maximization, however, either trade approximation guarantees for practical efficiency, or vice versa. In particular, among the algorithms that achieve constant factor approximations under the prominent independent cascade (IC) model or linear threshold (LT) model, none can handle a million-node graph without incurring prohibitive overheads. This paper presents TIM, an algorithm that aims to bridge the theory and practice in influence maximization. On the theory side, we show that TIM runs in O((k+\ell) (n+m) \log n / \epsilon^2) expected time and returns a (1-1/e-\epsilon)-approximate solution with at least 1 - n^{-\ell} probability. The time complexity of TIM is near-optimal under the IC model, as it is only a \log n factor larger than the \Omega(m + n) lower-bound established in previous work (for fixed k, \ell, and \epsilon). Moreover, TIM supports the triggering model, which is a general diffusion model that includes both IC and LT as special cases. On the practice side, TIM incorporates novel heuristics that significantly improve its empirical efficiency without compromising its asymptotic performance. We experimentally evaluate TIM with the largest datasets ever tested in the literature, and show that it outperforms the state-of-the-art solutions (with approximation guarantees) by up to four orders of magnitude in terms of running time. In particular, when k = 50, \epsilon = 0.2, and \ell = 1, TIM requires less than one hour on a commodity machine to process a network with 41.6 million nodes and 1.4 billion edges.},
archivePrefix = {arXiv},
arxivId = {arXiv:1404.0900v1},
author = {Tang, Youze and Xiao, Xiaokui and Shi, Yanchen},
booktitle = {Proceedings of the 2014 International Conference on Mangement of Data (SIGMOD)},
doi = {10.1145/2588555.2593670},
eprint = {arXiv:1404.0900v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tang, Xiao, Shi - 2014 - Influence maximization Near-optimal time complexity meets practical efficiency.pdf:pdf},
isbn = {9781450323765},
issn = {07308078},
pages = {75--86},
publisher = {ACM},
title = {{Influence maximization: Near-optimal time complexity meets practical efficiency}},
url = {http://dl.acm.org/citation.cfm?doid=2588555.2593670},
year = {2014}
}
@article{Goel2015,
author = {Goel, Sharad and Anderson, Ashton and Hofman, Jake and Watts, Duncan J},
doi = {10.1145/0000000.0000000},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goel et al. - 2016 - The Structural Virality of Online Diffusion.pdf:pdf},
isbn = {9781450314152},
issn = {0025-1909},
journal = {Management Science},
keywords = {2013,2014,accepted november 26,by lorin hitt,diffusion,history,in advance,information systems,published online in articles,received august 14,twitter,viral media},
number = {1},
pages = {180--196},
title = {{The Structural Virality of Online Diffusion}},
url = {http://5harad.com/papers/twiral.pdf},
volume = {62},
year = {2016}
}
@article{Song2015,
author = {Song, Chonggang and Hsu, Wynne and Lee, Mong Li},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Song, Hsu, Lee - 2015 - Node Immunization over Infectious Period.pdf:pdf},
isbn = {9781450337946},
journal = {Proceedings of the 24th ACM International Conference on Information and Knowledge Management},
pages = {831--840},
title = {{Node Immunization over Infectious Period}},
year = {2015}
}
@article{Friggeri2014,
abstract = {Online social networks provide a rich substrate for rumor propagation. Information received via friends tends to be trusted, and online social networks allow individuals to transmit information to many friends at once. By referencing known rumors from Snopes.com, a popular website documenting memes and urban legends, we track the propagation of thousands of rumors appearing on Facebook. From this sample we infer the rates at which rumors from different categories and of varying truth value are uploaded and reshared. We find that rumor cascades run deeper in the social network than reshare cascades in general. We then examine the effect of individual reshares receiving a comment containing a link to a Snopes article on the evolution of the cascade. We find that receiving such a comment increases the likelihood that a reshare of a rumor will be deleted. Furthermore, large cascades are able to accumulate hundreds of Snopes comments while continuing to propagate. Finally, using a dataset of rumors copied and pasted from one status update to another, we show that rumors change over time and that different variants tend to dominate different bursts in popularity.},
author = {Friggeri, Adrien and Adamic, La and Eckles, Dean and Cheng, Justin},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Friggeri et al. - 2014 - Rumor Cascades.pdf:pdf},
isbn = {9781577356578},
journal = {ICWSM},
keywords = {Full Papers},
pages = {101--110},
title = {{Rumor Cascades}},
url = {http://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/download/8122/8110},
year = {2014}
}
@article{Clipping2015,
author = {Clipping, Screen},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Clipping - 2015 - ml Page 1.pdf:pdf},
pages = {1--4},
title = {{ml Page 1}},
year = {2015}
}
@article{Goel2012,
abstract = {Models of networked diffusion that are motivated by analogy with the spread of infectious disease have been applied to a wide range of social and economic adoption processes, including those related to new products, ideas, norms and behaviors. However, it is unknown how accurately these models account for the empirical structure of diffusion over networks. Here we describe the diffusion patterns arising from seven online domains, ranging from communications platforms to networked games to microblogging services, each involving distinct types of content and modes of sharing.We find strikingly similar patterns across all domains. In particular, the vast majority of cascades are small, and are described by a handful of simple tree structures that terminate within one degree of an initial adopting “seed.” In addition we find that structures other than these account for only a tiny fraction of total adoptions; that is, adoptions resulting from chains of referrals are extremely rare. Finally, even for the largest cascades that we observe, we find that the bulk of adoptions often takes place within one degree of a few dominant individuals. Together, these observations suggest new directions for modeling of online adoption processes.},
author = {Goel, Sharad and Watts, Duncan J and Goldstein, Daniel G},
doi = {10.1145/0000000.0000000},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goel, Watts, Goldstein - 2012 - The Structure of Online Diffusion Networks.pdf:pdf},
isbn = {9781450314152},
journal = {Proceedings of the 13th ACM Conference on Electronic Commerce},
number = {212},
pages = {623--638},
title = {{The Structure of Online Diffusion Networks}},
volume = {1},
year = {2012}
}
@article{Gonzalez-Bailon2013,
abstract = {This article explores the growth of online mobilizations using data from the indignados (outraged) movement in Spain, which emerged under the influence of the revolution in Egypt and as a precursor to the global Occupy mobilizations. The data track Twitter activity around the protests that took place in May 2011, which led to the formation of camp sites in dozens of cities all over the country and massive daily demonstrations during the week prior to the elections of May 22. We reconstruct the network of tens of thousands of users and monitor their message activity for a month (April 25, 2011, to May 25, 2011). Using both the structure of the network and levels of activity in message exchange, we identify four types of users and analyze their role in the growth of the protest. Drawing from theories of online activism and research on information diffusion in networks, this article centers on the following two questions: How does protest information spread in online networks? And how do different actors contribute to the growth of activity? The article aims to inform the theoretical debate on whether digital technologies are changing the logic of collective action and to provide evidence of how new media facilitates the emergence of massive offline mobilizations.},
archivePrefix = {arXiv},
arxivId = {1203.1868},
author = {Gonz{\'{a}}lez-Bail{\'{o}}n, Sandra and Borge-Holthoefer, Javier and Moreno, Yamir},
doi = {10.1177/0002764213479371},
eprint = {1203.1868},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gonz{\'{a}}lez-Bail{\'{o}}n, Borge-Holthoefer, Moreno - 2013 - Broadcasters and Hidden Influentials in Online Protest Diffusion.pdf:pdf},
isbn = {0002-7642},
issn = {0002-7642},
journal = {American Behavioral Scientist},
keywords = {collective action,information diffusion,networks,protests,social media},
pages = {943--965},
title = {{Broadcasters and Hidden Influentials in Online Protest Diffusion}},
url = {http://abs.sagepub.com/content/57/7/943.abstract},
volume = {57},
year = {2013}
}
@inproceedings{Myers2014,
abstract = {In online social media systems users are not only posting, consuming, and resharing content, but also creating new and destroying existing connections in the underlying social network. While each of these two types of dynamics has individually been studied in the past, much less is known about the connection between the two. How does user information posting and seeking behavior interact with the evolution of the underlying social network structure? Here, we study ways in which network structure reacts to users posting and sharing content. We examine the complete dynamics of the Twitter information network, where users post and reshare information while they also create and destroy connections. We find that the dynamics of network structure can be characterized by steady rates of change, interrupted by sudden bursts. Information diffusion in the form of cascades of post re-sharing often creates such sudden bursts of new connections, which significantly change users' local network structure. These bursts transform users' networks of followers to become structurally more cohesive as well as more homogenous in terms of follower interests. We also explore the effect of the information content on the dynamics of the network and find evidence that the appearance of new topics and real-world events can lead to significant changes in edge creations and deletions. Lastly, we develop a model that quantifies the dynamics of the network and the occurrence of these bursts as a function of the information spreading through the network. The model can successfully predict which information diffusion events will lead to bursts in network dynamics.},
archivePrefix = {arXiv},
arxivId = {1403.2732},
author = {Myers, Seth A. and Leskovec, Jure},
booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
doi = {10.1145/2566486.2568043},
eprint = {1403.2732},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Myers, Leskovec - 2014 - The bursty dynamics of the Twitter information network.pdf:pdf},
isbn = {978-1-4503-2744-2},
issn = {09255273},
keywords = {network dynamics,networks of diffusion,twitter},
pages = {913--924},
title = {{The bursty dynamics of the Twitter information network}},
url = {http://dl.acm.org/citation.cfm?id=2566486.2568043},
year = {2014}
}
@article{Falahati2014,
abstract = {The operation of power systems now relies on extensive applications of digital communication systems, known as cyber networks. These applications are categorized as having either direct or indirect interactions between cyber and power networks. We previously studied direct interdependencies inside cyber-power networks and proposed the state mapping based model to evaluate its impact on the power system reliability. This paper focuses on indirect interdependencies between cyber and power networks. Certain applications of indirect interdependencies in modern power systems are discussed, and a state updating-based model is proposed to quantitatively evaluate the reliability of cyber-power networks under indirect interdependencies. Two optimization models are used to maximize the data connectivity in the cyber network and minimize the load curtailment in the power network. A high-voltage substation equipped with both monitoring and protection systems is studied to show the effectiveness of the proposed solution model.},
author = {Falahati, Bamdad and Fu, Yong},
doi = {10.1109/TSG.2014.2310742},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Falahati, Fu - 2014 - Reliability assessment of smart grids considering indirect cyber-power interdependencies.pdf:pdf},
isbn = {1949-3053},
issn = {19493053},
journal = {IEEE Transactions on Smart Grid},
keywords = {Cyber-physical interdependency,power system monitoring and protection.,power system reliability},
number = {4},
pages = {1677--1685},
title = {{Reliability assessment of smart grids considering indirect cyber-power interdependencies}},
volume = {5},
year = {2014}
}
@article{Falahati2012,
abstract = {Smart grid initiatives are becoming more and more achievable through the use of information infrastructures that feature peer-to-peer communication, monitoring, protection and automated control. The analysis of smart grid operation requires considering the reliability of the cyber network as it is neither invulnerable nor failure free. This paper quantitatively evaluates the reliability of modern power systems, which incorporates the impact of cyber network failures on the reliability of the power network. In this paper, four types of interdependencies are defined and a new concept of state mapping is proposed to map the failures in the cyber network to the failures of the power network. Furthermore, in order to evaluate the impact of direct cyber-power interdependencies on the reliability indices, two optimization models are introduced to maximize the data connection in the cyber network and minimize the load shedding in the power network. The effectiveness of proposed reliability evaluation method is shown by a smart microgrid application. The methodology presented in this paper is a start point to optimize the future power grid which has increasingly interdependencies between cyber and power networks.},
author = {Falahati, Bamdad and Fu, Yong and Wu, Lei},
doi = {10.1109/TSG.2012.2194520},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Falahati, Fu, Wu - 2012 - Reliability assessment of smart grid considering direct cyber-power interdependencies.pdf:pdf},
isbn = {1949-3053},
issn = {19493053},
journal = {IEEE Transactions on Smart Grid},
keywords = {Interdependency,microgrid,power system reliability,smart grid},
number = {3},
pages = {1515--1524},
title = {{Reliability assessment of smart grid considering direct cyber-power interdependencies}},
volume = {3},
year = {2012}
}
@article{Mishra2015a,
author = {Mishra, Subhankar and Li, Xiang and Kuhnle, Alan and Thai, My T},
doi = {10.1109/INFOCOM.2015.7218623},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mishra et al. - 2015 - Rate Alteration Attacks in Smart Grid(2).pdf:pdf},
isbn = {9781479983810},
issn = {0743166X},
journal = {Ieee Infocom 2015},
pages = {2353--2361},
title = {{Rate Alteration Attacks in Smart Grid}},
year = {2015}
}
@misc{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Encrypted.Pdf.pdf:pdf},
title = {{Encrypted.Pdf}}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Definition. Let G = ( G 1 , . . . , G.pdf:pdf},
pages = {1--2},
title = {{Definition. Let G = ( G 1 , . . . , G}}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2014 - Kuhnle Alan 2014-15 CISE Annual Ph . D . Student Evaluation Personalized Note Exemp t.pdf:pdf},
pages = {2014},
title = {{Kuhnle Alan 2014-15 CISE Annual Ph . D . Student Evaluation Personalized Note Exemp t}},
year = {2014}
}
@article{Khuller1999,
abstract = {The budgeted maximum coverage problem is: given a collection of sets with associated costs defined over a domain of weighted elements, and a budget L, find a subset of such that the total cost of sets in does not exceed L, and the total weight of elements covered by is maximized. This problem is NP-hard. For the special case of this problem, where each set has unit cost, a -approximation is known. Yet, prior to this work, no approximation results were known for the general cost version. The contribution of this paper is a -approximation algorithm for the budgeted maximum coverage problem. We also argue that this approximation factor is the best possible, unless .},
author = {Khuller, Samir and Moss, Anna and Naor, Joseph (Seffi)},
doi = {10.1016/S0020-0190(99)00031-9},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khuller, Moss, Naor - 1999 - The budgeted maximum coverage problem.pdf:pdf},
issn = {00200190},
journal = {Information Processing Letters},
keywords = {Algorithms,Maximum coverage problem,Performance guarantee},
number = {1},
pages = {39--45},
pmid = {20314319},
title = {{The budgeted maximum coverage problem}},
volume = {70},
year = {1999}
}
@misc{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Unknown - Unknown - pdfInDatabase.pdf.pdf.pdf:pdf},
title = {{Unknown - Unknown - pdfInDatabase.pdf.pdf}}
}
@misc{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Unknown - Unknown - pdfInDatabase.pdf.pdf.pdf:pdf},
title = {{Unknown - Unknown - pdfInDatabase.pdf.pdf}}
}
@article{Thai,
author = {Thai, My T},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thai - Unknown - Scenario suggested by Paul.pdf:pdf},
pages = {1--2},
title = {{Scenario suggested by Paul}}
}
@article{Alim,
author = {Alim, Abdul and Kuhnle, Alan and Thai, My T},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alim, Kuhnle, Thai - Unknown - Influence Maximization in Multiple Online Social Networks with Heterogeneous Diffusion Models MODEL REPRE.pdf:pdf},
pages = {2--3},
title = {{Influence Maximization in Multiple Online Social Networks with Heterogeneous Diffusion Models MODEL REPRESENTATION AND PROB-}}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Chapter 6 Set Cover.pdf:pdf},
pages = {43--52},
title = {{Chapter 6 Set Cover}}
}
@article{Nguyen2013,
abstract = {We study the influence maximization problem (IMP) in multiple online social networks (OSNs). In contrast to most of the previous works on influence maximization which only focused on a single network, our work is the first one to evaluate the propagation of influence across multiple networks simultaneously. In this paper, we first propose a general representation for multiple networks using universal ids for the users. We next introduce a powerful coupling scheme which reduces the multiple networks into a single network without changing influencing properties, thereby allowing us to solve the problem in the reduced network. Moreover, the coupling scheme is also an efficient tool to investigate various aspects of the influence propagation on multiple OSNs. The extensive experiments on real-world and synthesized datasets not only confirm the quality of the solution but also reveal interesting insights into the behavior of influence propagation in and across the networks.},
author = {Nguyen, D T and Das, S and Thai, M T},
doi = {10.1109/GLOCOM.2013.6831541},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen, Das, Thai - 2013 - Influence maximization in multiple online social networks.pdf:pdf},
isbn = {VO  -},
journal = {Global Communications Conference (GLOBECOM), 2013 IEEE},
keywords = {Couplings,Facebook,IMP,Media,OSN,Optimized production technology,Three-dimensional displays,Twitter,coupling scheme,influence maximization problem,influence propagation,multiple online social networks,network theory (graphs),reduced network,social networking (online),synthesized datasets,universal ids},
pages = {3060--3065},
title = {{Influence maximization in multiple online social networks}},
year = {2013}
}
@article{Bott2014a,
abstract = {Mycotoxins are small (MW approximately 700), toxic chemical products formed as secondary metabolites by a few fungal species that readily colonise crops and contaminate them with toxins in the field or after harvest. Ochratoxins and Aflatoxins are mycotoxins of major significance and hence there has been significant research on broad range of analytical and detection techniques that could be useful and practical. Due to the variety of structures of these toxins, it is impossible to use one standard technique for analysis and/or detection. Practical requirements for high-sensitivity analysis and the need for a specialist laboratory setting create challenges for routine analysis. Several existing analytical techniques, which offer flexible and broad-based methods of analysis and in some cases detection, have been discussed in this manuscript. There are a number of methods used, of which many are lab-based, but to our knowledge there seems to be no single technique that stands out above the rest, although analytical liquid chromatography, commonly linked with mass spectroscopy is likely to be popular. This review manuscript discusses (a) sample pre-treatment methods such as liquid-liquid extraction (LLE), supercritical fluid extraction (SFE), solid phase extraction (SPE), (b) separation methods such as (TLC), high performance liquid chromatography (HPLC), gas chromatography (GC), and capillary electrophoresis (CE) and (c) others such as ELISA. Further currents trends, advantages and disadvantages and future prospects of these methods have been discussed.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bott, R},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {arXiv:1011.1669v3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bott - 2014 - No Title No Title(2).pdf:pdf},
isbn = {9780874216561},
issn = {0717-6163},
journal = {Igarss 2014},
keywords = {Bott},
number = {1},
pages = {1--5},
pmid = {15003161},
title = {{No Title No Title}},
year = {2014}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - No Title(2).pdf:pdf},
pages = {1--4},
title = {{No Title}}
}
@article{Bott2014,
abstract = {Mycotoxins are small (MW approximately 700), toxic chemical products formed as secondary metabolites by a few fungal species that readily colonise crops and contaminate them with toxins in the field or after harvest. Ochratoxins and Aflatoxins are mycotoxins of major significance and hence there has been significant research on broad range of analytical and detection techniques that could be useful and practical. Due to the variety of structures of these toxins, it is impossible to use one standard technique for analysis and/or detection. Practical requirements for high-sensitivity analysis and the need for a specialist laboratory setting create challenges for routine analysis. Several existing analytical techniques, which offer flexible and broad-based methods of analysis and in some cases detection, have been discussed in this manuscript. There are a number of methods used, of which many are lab-based, but to our knowledge there seems to be no single technique that stands out above the rest, although analytical liquid chromatography, commonly linked with mass spectroscopy is likely to be popular. This review manuscript discusses (a) sample pre-treatment methods such as liquid-liquid extraction (LLE), supercritical fluid extraction (SFE), solid phase extraction (SPE), (b) separation methods such as (TLC), high performance liquid chromatography (HPLC), gas chromatography (GC), and capillary electrophoresis (CE) and (c) others such as ELISA. Further currents trends, advantages and disadvantages and future prospects of these methods have been discussed.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bott, R},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {arXiv:1011.1669v3},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bott - 2014 - No Title No Title.pdf:pdf},
isbn = {9780874216561},
issn = {0717-6163},
journal = {Igarss 2014},
keywords = {Bott},
number = {1},
pages = {1--5},
pmid = {15003161},
title = {{No Title No Title}},
year = {2014}
}
@article{Hall2013,
author = {Hall, Tigert and Box, P O and Fl, Gainesville and Fl, Orlando and Hall, Tigert and Fl, Gainesville and Fl, Orlando and Fl, Orlando},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hall et al. - 2013 - W-2 Wage and Tax Statement VICTORIA G CRAWFORD W-2 Wage and Tax Statement W-2 Wage and Tax Statement W-2 Wage and T.pdf:pdf},
number = {12},
pages = {6002052},
title = {{W-2 Wage and Tax Statement VICTORIA G CRAWFORD W-2 Wage and Tax Statement W-2 Wage and Tax Statement W-2 Wage and Tax Statement 14107 NELL DR}},
year = {2013}
}
@article{Mishra,
author = {Mishra, Subhankar and Member, Student and Li, Xiang and Kuhnle, Alan and Thai, My T and Seo, Jungtaek},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mishra et al. - Unknown - Price Modification and Cascading Failures in Smart Grid.pdf:pdf},
pages = {1--12},
title = {{Price Modification and Cascading Failures in Smart Grid}}
}
@article{Kuhnlea,
author = {Kuhnle, Alan and Li, Xiang and Thai, My T},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhnle, Li, Thai - Unknown - Online Allocation of Resource to Maximize Spatial Reuse in Device-to-Device Communication.pdf:pdf},
pages = {1--6},
title = {{Online Allocation of Resource to Maximize Spatial Reuse in Device-to-Device Communication}}
}
@inproceedings{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - No Title.pdf:pdf},
title = {{No Title}}
}
@article{Optimization,
author = {Optimization, Convex},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Optimization - Unknown - 11 . Equality constrained minimization-Sunum.pdf:pdf},
pages = {1--19},
title = {{11 . Equality constrained minimization-Sunum}}
}
@article{Crawford2014,
author = {Crawford, Victoria},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Crawford - 2014 - NP-Complete Problems.pdf:pdf},
pages = {1--4},
title = {{NP-Complete Problems}},
year = {2014}
}
@article{Caruana2006,
abstract = {A number of supervised learning methods have been introduced in the last decade. Unfortunately, the last comprehensive empirical evaluation of supervised learning was the Statlog Project in the early 90's. We present a large-scale empirical comparison between ten supervised learning methods: SVMs, neural nets, logistic regression, naive bayes, memory-based learning, random forests, decision trees, bagged trees, boosted trees, and boosted stumps. We also examine the effect that calibrating the models via Platt Scaling and Isotonic Regression has on their performance. An important aspect of our study is the use of a variety of performance criteria to evaluate the learning methods.},
author = {Caruana, Rich and Niculescu-Mizil, Alexandru},
doi = {10.1145/1143844.1143865},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Caruana, Niculescu-Mizil - 2006 - An empirical comparison of supervised learning algorithms.pdf:pdf},
isbn = {1595933832},
issn = {1595933832},
journal = {Proceedings of the 23rd international conference on Machine learning},
number = {1},
pages = {161--168},
title = {{An empirical comparison of supervised learning algorithms}},
url = {http://portal.acm.org/citation.cfm?doid=1143844.1143865},
volume = {C},
year = {2006}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Kuhnle Alan 2013-14 CISE Annual Ph . D . Student Evaluation.pdf:pdf},
pages = {2013},
title = {{Kuhnle Alan 2013-14 CISE Annual Ph . D . Student Evaluation}},
year = {2013}
}
@article{Meerbergen2001,
author = {Meerbergen, Karl},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meerbergen - 2001 - Problem ∗.pdf:pdf},
keywords = {arnoldi method,backward error,ber,condition num-,davidson method,eigenvalue,eigenvector,gyroscopic system,jacobi,krylov methods,lanczos method,linearization,matrix polynomial,millennium footbridge,overdamped sys-,pseudospectrum,quadratic eigenvalue problem,second-order differential equation,tem,vibration,$\lambda$ -matrix},
number = {2},
pages = {235--286},
title = {{Problem ∗}},
volume = {43},
year = {2001}
}
@article{Mishra2015,
author = {Mishra, Subhankar and Li, Xiang and Kuhnle, Alan and Thai, My T},
doi = {10.1109/INFOCOM.2015.7218623},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mishra et al. - 2015 - Rate Alteration Attacks in Smart Grid.pdf:pdf},
isbn = {9781479983810},
issn = {0743166X},
journal = {Ieee Infocom 2015},
pages = {2353--2361},
title = {{Rate Alteration Attacks in Smart Grid}},
year = {2015}
}
@article{Saito,
author = {Saito, Kazumi and Kimura, Masahiro and Ohara, Kouzou and Motoda, Hiroshi},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saito et al. - Unknown - Selecting Information Di ff usion Models over Social Networks for Behavioral Analysis.pdf:pdf},
number = {Ic},
title = {{Selecting Information Di ff usion Models over Social Networks for Behavioral Analysis}}
}
@article{Lee2013,
author = {Lee, Dong Heon and Choi, Kae Won and Jeon, Wha Sook and Jeong, Dong Geun},
doi = {10.1109/WCNC.2013.6554548},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2013 - Resource allocation scheme for device-to-device communication for maximizing spatial reuse.pdf:pdf},
isbn = {9781467359399},
issn = {15253511},
journal = {IEEE Wireless Communications and Networking Conference, WCNC},
keywords = {Device-to-device communication,cellular networks,resource allocation,set covering problem,spatial reuse},
pages = {112--117},
title = {{Resource allocation scheme for device-to-device communication for maximizing spatial reuse}},
year = {2013}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Definition 1. Let { ( G.pdf:pdf}},
pages = {2},
title = {{Definition 1. Let { ( G}}}
}
@article{Pawgasame2015,
abstract = {As network centric warfare becoming the key concept in the modern military doctrine, tactical wireless networks have been used extensively throughout military operations for sharing crucial information among deployed units. Most tactical wireless networks are operating in a hostile environment, in which normal network operation cannot be easily achieved. In military operations, tactical wireless networks have high demands for robustness, responsiveness, reliability, availability and security. These requires continuous development of new technologies in order to cope with random behaviours of hostile environment. However, the random behaviour of tactical wireless networks under hostile environment has not been fully understood. This paper provides a survey on current issues, and research challenges in tactical wireless networks due to hostile environment. Several research gaps in performance, security, routing, and management of tactical wireless networks that are needed to be improved, are pointed out to pave the way for future research in this area. This paper provides insight understanding about the issues and trends for future development of tactical wireless networks.},
author = {Pawgasame, Wichai and Wipusitwarakun, Komwut},
doi = {10.1109/ACDT.2015.7111592},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pawgasame, Wipusitwarakun - 2015 - Tactical wireless networks A survey for issues and challenges.pdf:pdf},
isbn = {978-1-4799-8166-3},
journal = {2015 Asian Conference on Defence Technology (ACDT)},
keywords = {Mobile nodes,Reliability,Routing protocols,Security,Wireless networks,availability,hostile environment,military communication,military doctrine,network centric warfare,radio networks,tactical wireless network,telecommunication network management,telecommunication network reliability,telecommunication network routing,telecommunication security},
pages = {97--102},
title = {{Tactical wireless networks: A survey for issues and challenges}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7111592},
year = {2015}
}
@inproceedings{Lu2015,
author = {Lu, Zhuo and Wang, Cliff},
booktitle = {Military Communications Conference},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu, Wang - 2015 - On Detection and Concealment of Critical Roles in Tactical Wireless Networks.pdf:pdf},
isbn = {9781509000739},
pages = {909--914},
title = {{On Detection and Concealment of Critical Roles in Tactical Wireless Networks}},
year = {2015}
}
@article{Li2012,
abstract = {Smart grid has emerged as the next-generation power grid via the convergence of power system engineering and information and communication technology. In this article, we describe smart grid goals and tactics, and present a threelayer smart grid network architecture. Following a brief discussion about major challenges in smart grid development, we elaborate on smart grid cyber security issues. We define a taxonomy of basic cyber attacks, upon which sophisticated attack behaviors may be built. We then introduce fundamental security techniques, whose integration is essential for achieving full protection against existing and future sophisticated security attacks. By discussing some interesting open problems, we finally expect to trigger more research efforts in this emerging area.},
author = {Li, Xu and Liang, Xiaohui and Lu, Rongxing and Shen, Xuemin and Lin, Xiaodong and Zhu, Haojin},
doi = {10.1109/MCOM.2012.6257525},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2012 - Securing smart grid Cyber attacks, countermeasures, and challenges.pdf:pdf},
isbn = {0163-6804},
issn = {01636804},
journal = {IEEE Communications Magazine},
number = {8},
pages = {38--45},
title = {{Securing smart grid: Cyber attacks, countermeasures, and challenges}},
volume = {50},
year = {2012}
}
@article{Heinaaro,
author = {Hein{\"{a}}aro, Kimmo},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hein{\"{a}}aro - Unknown - Cyber Attacking Tactical Radio Networks.pdf:pdf},
keywords = {5,cyber,gnu radio,hackrf,metasploit,most important part of,network,of,penetration test,pentesting is the report,pentesting techniques are widely,sdr,tactical radio,used,usrp,vulnerabilities found},
title = {{Cyber Attacking Tactical Radio Networks}}
}
@article{LiXuInriaLille2012,
author = {et al. {Li Xu, Inria Lille}, Xiaohui Liang},
journal = {IEEE Communications Magazine},
month = {aug},
pages = {38----45},
title = {{Securing Smart Grid: Cyber Attacks, Countermeasure, and Challenges}},
year = {2012}
}
@article{Chen2011,
abstract = {We consider the problem of designing a network of minimum cost while satisfying a prescribed survivability criterion. The survivability criterion requires that a feasible flow must still exists (i.e. all demands can be satisfied without violating arc capacities) even after the disruption of a subset of the network's arcs. Specifically, we consider the case in which a disruption (random or malicious) can destroy a subset of the arcs, with the cost of the disruption not to exceed a disruption budget. This problem takes the form of a tri-level, two-player game, in which the network operator designs (or augments) the network, then the attacker launches a disruption that destroys a subset of arcs, and then the network operator attempts to find a feasible flow over the residual network. We first show how this can be modeled as a two-stage stochastic program from the network operator's perspective, with each of the exponential number of potential attacks considered as a disruption scenario. We then reformulate this problem, via a Benders decomposition, to consider the recourse decisions implicitly, greatly reducing the number of variables but at the expense of an exponential increase in the number of constraints. We next develop a cut-generation based algorithm. Rather than explicitly considering each disruption scenario to identify these Benders cuts, however, we develop a bi-level program and corresponding separation algorithm that enables us to implicitly evaluate the exponential set of disruption scenarios. Our computational results demonstrate the efficacy of this approach.},
archivePrefix = {arXiv},
arxivId = {1109.1801},
author = {Chen, Richard Li Yang and Cohn, Amy and Pinar, Ali},
doi = {10.1109/NSW.2011.6004644},
eprint = {1109.1801},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Cohn, Pinar - 2011 - An implicit optimization approach for survivable network design.pdf:pdf},
isbn = {9781457710490},
journal = {Proceedings of the 2011 IEEE 1st International Network Science Workshop, NSW 2011},
keywords = {decomposition,implicit optimization Survivable network design,separation,stochastic programming},
pages = {180--187},
title = {{An implicit optimization approach for survivable network design}},
year = {2011}
}
@article{Pinar2010,
author = {Pinar, A L I and Meza, Juan and Donde, Vaibhav and Lesieutre, Bernard},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pinar et al. - 2010 - Optimization Strategies for the Vulnerability Analysis of the Electric Power Grid.pdf:pdf},
journal = {SIAM Journal of Optimization},
keywords = {070708275,10,1137,90c11,90c27,90c30,90c90,ams subject classifications,doi,electric power flow,graph theory,integer linear programming,mixed,mixed integer nonlinear programming,network flow,network inhibition,network vulnerability},
number = {4},
pages = {1786--1810},
title = {{Optimization Strategies for the Vulnerability Analysis of the Electric Power Grid}},
volume = {20},
year = {2010}
}
@article{Xue2015,
author = {Xue, Yusheng and Ni, Ming and Member, Senior and Yu, He and Hu, Jianqiang},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xue et al. - 2015 - Study of the impact of communication failures on power system.pdf:pdf},
isbn = {9781467380409},
pages = {1--5},
title = {{Study of the impact of communication failures on power system}},
year = {2015}
}
@article{Huang2015,
author = {Huang, Zhen and Wang, Cheng and Zhu, Tieying and Nayak, Amiya},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2015 - Cascading Failures in Smart Grid Joint Effect of Load Propagation and Interdependence.pdf:pdf},
title = {{Cascading Failures in Smart Grid : Joint Effect of Load Propagation and Interdependence}},
volume = {3},
year = {2015}
}
@article{Das2015,
author = {Das, Arun and Zhou, Chenyang and Banerjee, Joydeep and Sen, Arunabha and Greenwald, Lloyd},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Das et al. - 2015 - On the Smallest Pseudo Target Set Identification Problem for Targeted Attack on Interdependent Power-Communication N.pdf:pdf},
isbn = {9781509000739},
pages = {1048--1053},
title = {{On the Smallest Pseudo Target Set Identification Problem for Targeted Attack on Interdependent Power-Communication Networks}},
year = {2015}
}
@article{Danziger2014,
abstract = {Many real-world phenomena can bemodelled using networks. Often, these networks interact with one another in non-trivial ways. Re- cently, a theory of interdependent networks has been developed which describes dependency between nodes across networks. Interdependent networks have a number of unique properties which are absent in sin- gle networks. In particular, systems of interdependent networks often undergo abrupt first-order percolation transitions induced by cascad- ing failures. Here we present an overview of recent developments and significant findings regarding interdependent networks and networks of networks.},
author = {Danziger, Michael M and Bashan, Amir and Berezin, Yehiel and Shekhtman, Louis M and Havlin, Shlomo},
doi = {10.1007/978-3-319-08672-9_24},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Danziger et al. - 2014 - An Introduction to Interdependent Networks Background From Single Networks to Networks of.pdf:pdf},
isbn = {978-3-319-08671-2},
issn = {18650929},
journal = {22nd International Conference Nonlinear Dynamics of Electronic Systems NDES 2014},
pages = {189--202},
title = {{An Introduction to Interdependent Networks Background : From Single Networks to Networks of}},
url = {http://link.springer.com/chapter/10.1007/978-3-319-08672-9_24},
volume = {438},
year = {2014}
}
@article{JinsubKim2013,
abstract = {Cyber attacks on a smart grid aiming at misleading the control center with incorrect topology information are considered. In such attacks, an adversary intercepts network and meter data from the remote terminal units, modifies part of them, and forwards the modified data to the control center. A necessary and sufficient condition for an undetectable topology attack is presented, and an undetectable attack that requires the modification of only a few meter data is proposed. When the adversary has limited local information, a heuristic attack strategy is proposed. The proposed attacks are tested with IEEE 14-bus and 118-bus systems, and their effect on real-time locational marginal pricing is examined.},
author = {{Jinsub Kim} and {Lang Tong}},
doi = {10.1109/ISGT.2013.6497834},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jinsub Kim, Lang Tong - 2013 - On topology attack of a smart grid.pdf:pdf},
isbn = {978-1-4673-4896-6},
journal = {2013 IEEE PES Innovative Smart Grid Technologies Conference (ISGT)},
pages = {1--6},
title = {{On topology attack of a smart grid}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6497834},
year = {2013}
}
@article{Zhu2014,
abstract = {Vulnerability analysis on the power grid has been widely conducted from the substation-only and transmission-line-only perspectives. In order words, it is considered that attacks can occur on substations or transmission lines separately. In this paper, we naturally extend existing two perspectives and introduce the joint-substation-transmission-line's perspective, which means attacks can concurrently occur on substations and transmission lines. Vulnerabilities are referred to as these multiple-component combinations that can yield large damage to the power grid. One such combination consists of substations, transmission lines, or both. The new perspective is promising to discover more power grid vulnerabilities. In particular, we conduct the vulnerability analysis on the IEEE 39 bus system. Compared with known substation-only/transmission-line-only vulnerabilities, joint-substation-transmission-line vulnerabilities account for the largest percentage. Referring to three-component vulnerabilities, for instance, joint-substation-transmission-line vulnerabilities account for 76.06%; substation-only and transmission-line-only vulnerabilities account for 10.96% and 12.98%, respectively. In addition, we adopt two existing metrics, degree and load, to study the joint-substation-transmission-line attack strategy. Generally speaking, the joint-substation-transmission-line attack strategy based on the load metric has better attack performance than comparison schemes.},
author = {Zhu, Yihai and Yan, Jun and Tang, Yufei and Sun, Y L and He, Haibo},
doi = {10.1109/GLOCOM.2014.7036882},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2014 - Coordinated attacks against substations and transmission lines in power grids.pdf:pdf},
isbn = {VO  -},
journal = {Global Communications Conference (GLOBECOM), 2014 IEEE},
keywords = {Attack,Benchmark testing,Cascading failures,IEEE 39 bus system,Measurement,Power grid security,Power grids,Power system faults,Power system protection,Power transmission lines,Substations,Vulnerability analysis,coordinated attacks,joint-substation-transmission-line perspective,joint-substation-transmission-line vulnerabilities,load metric,multiple-component combinations,power grid vulnerabilities,power grids,power transmission reliability,substations,vulnerability analysis},
pages = {655--661},
title = {{Coordinated attacks against substations and transmission lines in power grids}},
year = {2014}
}
@article{Gupta2014,
abstract = {The next generation power grid demands high reliability, robustness and real time communication of control information related to power flow in the grid. This paper proposes a probabilistic framework of smart grid power network with statistical decision theory to evaluate system performance in steady state as well as under dynamical case and identify the probable critical links which can cause cascade failure. Proposed model for cascade failure prediction has been tested on the IEEE 30 bus test bed system. Simulation results validated critical links in probabilistic model of power grid system with deterministic power flow analysis. The key contribution of this paper is, performance evaluation of smart grid power network and identification as well as prediction of critical links which may lead to system blackout. In addition to this, a graphical model has been developed using minimum spanning tree to analyze topology and structural connectivity of IEEE 30 bus system. {\textcopyright} 2014 IEEE.},
author = {Gupta, S R and Kazi, F S and Wagh, S R and Singh, N M},
doi = {10.1109/ISGT-Asia.2014.6873799},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta et al. - 2014 - Probabilistic framework for evaluation of smart grid resilience of cascade failure.pdf:pdf},
isbn = {9781479913008},
journal = {2014 IEEE Innovative Smart Grid Technologies - Asia, ISGT ASIA 2014},
keywords = {Cumulative distribution function; Minimum spannin,Electric network analysis; Electric power distribu,Electric power transmission networks},
pages = {255--260},
title = {{Probabilistic framework for evaluation of smart grid resilience of cascade failure}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84906716475&partnerID=40&md5=42d3c05f353344cfcdaec50a33f39638},
year = {2014}
}
@article{Zio2011,
author = {Zio, Enrico and Member, Senior and Sansavini, Giovanni},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zio, Member, Sansavini - 2011 - Modeling Interdependent Network Systems for Identifying Cascade-Safe Operating Margins.pdf:pdf},
number = {1},
pages = {94--101},
title = {{Modeling Interdependent Network Systems for Identifying Cascade-Safe Operating Margins}},
volume = {60},
year = {2011}
}
@article{Parandehgheibi2009,
archivePrefix = {arXiv},
arxivId = {arXiv:1304.0356v1},
author = {Parandehgheibi, Marzieh and Modiano, Eytan},
eprint = {arXiv:1304.0356v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parandehgheibi, Modiano - 2009 - Robustness of Interdependent Networks The case of communication networks and the power grid.pdf:pdf},
pages = {1--6},
title = {{Robustness of Interdependent Networks : The case of communication networks and the power grid}},
year = {2009}
}
@article{Soltan2015,
abstract = {Recent events demonstrated the vulnerability of power grids to cyber attacks and to physical attacks. Therefore, we focus on joint cyber and physical attacks and develop methods to retrieve the grid state information following such an attack. We consider a model in which an adversary attacks a zone by physically disconnecting some of its power lines and blocking the information flow from the zone to the grid's control center. We use tools from linear algebra and graph theory and leverage the properties of the power flow DC approximation to develop methods for information recovery. Using information observed outside the attacked zone, these methods recover information about the disconnected lines and the phase angles at the buses. We identify sufficient conditions on the zone structure and constraints on the attack characteristics such that these methods can recover the information. We also show that it is NP-hard to find an approximate solution to the problem of partitioning the power grid into the minimum number of attack-resilient zones. However, since power grids can often be represented by planar graphs, we develop a constant approximation partitioning algorithm for these graphs. Finally, we numerically study the relationships between the grid's resilience and its structural properties, and demonstrate the partitioning algorithm on real power grids. The results can provide insights into the design of a secure control network for the smart grid.},
author = {Soltan, Saleh and Yannakakis, Mihalis and Zussman, Gil},
doi = {10.1145/2745844.2745846},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soltan, Yannakakis, Zussman - 2015 - Joint cyber and physical attacks on power grids Graph theoretical approaches for information recov.pdf:pdf},
isbn = {978-1-4503-3486-0},
journal = {Proceedings of the 2015 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems - SIGMETRICS '15},
keywords = {algorithms,all or part of,cyber attacks,graph theory,information,or,or hard copies of,permission to make digital,physical attacks,power grids,recovery,this work for personal},
pages = {361--374},
title = {{Joint cyber and physical attacks on power grids : Graph theoretical approaches for information recovery categories and subject descriptors}},
url = {http://dl.acm.org/citation.cfm?doid=2745844.2745846},
year = {2015}
}
@article{Dong2013,
abstract = {When an initial failure of nodes occurs in interdependent networks, a cascade of failure between the networks occurs. Earlier studies focused on random initial failures. Here we study the robustness of interdependent networks under targeted attack on high or low degree nodes. We introduce a general technique which maps the targeted-attack problem in interdependent networks to the random-attack problem in a transformed pair of interdependent networks. We find that when the highly connected nodes are protected and have lower probability to fail, in contrast to single scale-free (SF) networks where the percolation threshold pc = 0, coupled SF networks are significantly more vulnerable with pc significantly larger than zero. The result implies that interdependent networks are difficult to defend by strategies such as protecting the high degree nodes that have been found useful to significantly improve robustness of single networks.},
archivePrefix = {arXiv},
arxivId = {1010.2160},
author = {Dong, Gaogao and Gao, Jianxi and Du, Ruijin and Tian, Lixin and Stanley, H. Eugene and Havlin, Shlomo},
doi = {10.1103/PhysRevE.87.052804},
eprint = {1010.2160},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dong et al. - 2013 - Robustness of network of networks under targeted attack.pdf:pdf},
issn = {15393755},
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics},
number = {5},
pages = {1--11},
pmid = {21797429},
title = {{Robustness of network of networks under targeted attack}},
volume = {87},
year = {2013}
}
@article{Bernstein2012,
abstract = {We consider power line outages in the transmission system of the power grid, and specifically those caused by a natural disaster or a large scale physical attack. In the transmission system, an outage of a line may lead to overload on other lines, thereby eventually leading to their outage. While such cascading failures have been studied before, our focus is on cascading failures that follow an outage of several lines in the same geographical area. We provide an analytical model of such failures, investigate the model's properties, and show that it differs from other models used to analyze cascades in the power grid (e.g., epidemic/percolation-based models). We then show how to identify the most vulnerable locations in the grid and perform extensive numerical experiments with real grid data to investigate the various effects of geographically correlated outages and the resulting cascades. These results allow us to gain insights into the relationships between various parameters and performance metrics, such as the size of the original event, the final number of connected components, and the fraction of demand (load) satisfied after the cascade. In particular, we focus on the timing and nature of optimal control actions used to reduce the impact of a cascade, in real time. We also compare results obtained by our model to the results of a real cascade that occurred during a major blackout in the San Diego area on Sept. 2011. The analysis and results presented in this paper will have implications both on the design of new power grids and on identifying the locations for shielding, strengthening, and monitoring efforts in grid upgrades.},
archivePrefix = {arXiv},
arxivId = {1206.1099},
author = {Bernstein, Andrey and Bienstock, Daniel and Hay, David and Uzunoglu, Meric and Zussman, Gil},
eprint = {1206.1099},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bernstein et al. - 2012 - Power Grid Vulnerability to Geographically Correlated Failures - Analysis and Control Implications.pdf:pdf},
isbn = {9781479933600},
keywords = {1,11,2011 san diego blackout,8,according,cascading failures,fig,geographically-correlated failures,in which it tripped,line represents the time,network science,power grid,sept,survivability,the,the color of each,the development of the,to},
pages = {2634--2642},
title = {{Power Grid Vulnerability to Geographically Correlated Failures - Analysis and Control Implications}},
url = {http://arxiv.org/abs/1206.1099},
year = {2012}
}
@article{Jonas2015,
author = {Jonas, W and Heegaard, Poul E},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jonas, Heegaard - 2015 - Interdependency in Smart Grid Recovery.pdf:pdf},
isbn = {9781467380515},
pages = {201--207},
title = {{Interdependency in Smart Grid Recovery}},
year = {2015}
}
@article{Golnari2015,
author = {Golnari, Golshan and Zhang, Zhi-li and Cities, Twin},
doi = {10.1109/INFCOMW.2015.7179464},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Golnari, Zhang, Cities - 2015 - The Effect of Different Couplings on Mitigating Failure Cascades in Interdependent Networks.pdf:pdf},
isbn = {9781467371315},
issn = {0743166X},
pages = {755--760},
title = {{The Effect of Different Couplings on Mitigating Failure Cascades in Interdependent Networks}},
year = {2015}
}
@article{Wang2015,
author = {Wang, Qi and Member, Student and Pipattanasomporn, Manisa and Member, Senior},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2015 - Impact Assessment of Communication Service Disruptions in Power System Applications.pdf:pdf},
isbn = {9781467380409},
pages = {1--5},
title = {{Impact Assessment of Communication Service Disruptions in Power System Applications}},
year = {2015}
}
@article{Barthelemy2011,
abstract = {Complex systems are very often organized under the form of networks where nodes and edges are embedded in space. Transportation and mobility networks, Internet, mobile phone networks, power grids, social and contact networks, and neural networks, are all examples where space is relevant and where topology alone does not contain all the information. Characterizing and understanding the structure and the evolution of spatial networks is thus crucial for many different fields, ranging from urbanism to epidemiology. An important consequence of space on networks is that there is a cost associated with the length of edges which in turn has dramatic effects on the topological structure of these networks. We will thoroughly explain the current state of our understanding of how the spatial constraints affect the structure and properties of these networks. We will review the most recent empirical observations and the most important models of spatial networks. We will also discuss various processes which take place on these spatial networks, such as phase transitions, random walks, synchronization, navigation, resilience, and disease spread. {\textcopyright} 2010 Elsevier B.V.},
archivePrefix = {arXiv},
arxivId = {1010.0302},
author = {Barth{\'{e}}lemy, Marc},
doi = {10.1016/j.physrep.2010.11.002},
eprint = {1010.0302},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barth{\'{e}}lemy - 2011 - Spatial networks.pdf:pdf},
isbn = {0370-1573},
issn = {03701573},
journal = {Physics Reports},
keywords = {Geography,Graphs,Networks,Spatial properties,Statistical physics,Urban systems},
number = {1-3},
pages = {1--101},
title = {{Spatial networks}},
url = {http://dx.doi.org/10.1016/j.physrep.2010.11.002},
volume = {499},
year = {2011}
}
@article{Yan2014,
abstract = {The security issue of complex networks has drawn significant concerns recently. While pure topological analyzes from a network security perspective provide some effective techniques, their inability to characterize the physical principles requires a more comprehensive model to approximate failure behavior of a complex network in reality. In this paper, based on an extended topological metric, we proposed an approach to examine the vulnerability of a specific type of complex network, i.e., the power system, against cascading failure threats. The proposed approach adopts a model called extended betweenness that combines network structure with electrical characteristics to define the load of power grid components. By using this power transfer distribution factor-based model, we simulated attacks on different components (buses and branches) in the grid and evaluated the vulnerability of the system components with an extended topological cascading failure simulator. Influence of different loading and overloading situations on cascading failures was also evaluated by testing different tolerance factors. Simulation results from a standard IEEE 118-bus test system revealed the vulnerability of network components, which was then validated on a dc power flow simulator with comparisons to other topological measurements. Finally, potential extensions of the approach were also discussed to exhibit both utility and challenge in more complex scenarios and applications.},
author = {Yan, Jun and He, Haibo and Sun, Yan},
doi = {10.1109/TIFS.2014.2299404},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yan, He, Sun - 2014 - Integrated Security Analysis on Cascading Failure in Complex Networks.pdf:pdf},
issn = {1556-6013},
journal = {IEEE Transactions on Information Forensics and Security},
keywords = {Analytical models,Complex network security,Complex networks,Power grids,Power system faults,Power system protection,Security,cascading failure,complex networks,extended topological analysis,extended topological metric,integrated security analysis,network security perspective,power grid components,power transfer distribution factor-based model,security of data,standard IEEE 118-bus test system,structural vulnerability,topology},
number = {3},
pages = {451--463},
title = {{Integrated Security Analysis on Cascading Failure in Complex Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6708453},
volume = {9},
year = {2014}
}
@inproceedings{Ponton2013,
author = {Ponton, Julien and Wei, Peng and Sun, Dengfeng},
booktitle = {IEEE European Control Conference (ECC)},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ponton, Wei, Sun - 2013 - Weighted Clustering Coefficient Maximization For Air Transportation Networks.pdf:pdf},
isbn = {9783952417348},
keywords = {Aerospace,Optimization algorithms,Transportation systems},
title = {{Weighted Clustering Coefficient Maximization For Air Transportation Networks}},
year = {2013}
}
@article{Cai2015,
author = {Cai, Ye and Cao, Yijia and Member, Senior and Li, Yong and Member, Senior and Huang, Tao},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cai et al. - 2015 - Interaction Between Power Grids and Communication Networks.pdf:pdf},
number = {1},
pages = {1--9},
title = {{Interaction Between Power Grids and Communication Networks}},
volume = {7},
year = {2015}
}
@article{Barmpoutis2010,
abstract = {We describe the structure of the graphs with the smallest average distance and the largest average clustering given their order and size. There is usually a unique graph with the largest average clustering, which at the same time has the smallest possible average distance. In contrast, there are many graphs with the same minimum average distance, ignoring their average clustering. The form of these graphs is shown with analytical arguments. Finally, we measure the sensitivity to rewiring of this architecture with respect to the clustering coefficient, and we devise a method to make these networks more robust with respect to vertex removal.},
archivePrefix = {arXiv},
arxivId = {1007.4031},
author = {Barmpoutis, Dionysios and Murray, Richard M},
eprint = {1007.4031},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barmpoutis, Murray - 2010 - Networks with the Smallest Average Distance and the Largest Average Clustering.pdf:pdf},
journal = {Arxiv preprint},
pages = {1--28},
title = {{Networks with the Smallest Average Distance and the Largest Average Clustering}},
url = {http://arxiv.org/abs/1007.4031},
year = {2010}
}
@article{Bajaj1999,
abstract = {Large-scale hybrid networks that include wireless, wired, and satellite based communications are becoming common in both military and commercial situations. This paper describes a scalable simulation environment called GloMoSim (for Global Mobile Information System Simulator) that effectively utilizes parallel execution to reduce the simulation time of detailed high-fidelity models of large communication networks. The paper also presents a set of case studies that evaluate the performance of large wireless networks with thousands of nodes and compares the impact of different lower layer protocols on the performance of typical applications. 1. Introduction High-level design problems for the digital communication infrastructure in the military and commercial environment, are extremely challenging in a number of dimensions: the scale is large, network traffic is a mix of voice, data, and imagery; connectivity can change dynamically in unpredictable ways, and the quality of service requi...},
author = {Bajaj, L and Takai, M and Ahuja, R and Tang, K},
doi = {10.1.1.45.7167},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bajaj et al. - 1999 - Glomosim A Scalable Network Simulation Environment.pdf:pdf},
journal = {Compare A Journal Of Comparative Education},
number = {1},
pages = {154 -- 161},
title = {{Glomosim: A Scalable Network Simulation Environment}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.45.7167&rep=rep1&type=pdf},
volume = {28},
year = {1999}
}
@article{Hines2008,
abstract = {We derive a measure of "electrical centrality" for AC power networks, which describes the structure of the network as a function of its electrical topology rather than its physical topology. We compare our centrality measure to conventional measures of network structure using the IEEE 300-bus network. We find that when measured electrically, power networks appear to have a scale-free network structure. Thus, unlike previous studies of the structure of power grids, we find that power networks have a number of highly-connected "hub" buses. This result, and the structure of power networks in general, is likely to have important implications for the reliability and security of power networks.},
author = {Hines, Paul and Blumsack, Seth},
doi = {10.1109/HICSS.2008.5},
isbn = {0769530753},
issn = {15301605},
journal = {Proceedings of the 41st Hawaii International Conference on System Sciences},
keywords = {Cascading failures,Connectivity,Network structure,Scale-free networks},
pages = {1--8},
title = {{A centrality measure for electrical networks}},
year = {2008}
}
@inproceedings{Ali2013,
author = {Ali, Syed R and Wexler, Richard S},
booktitle = {IEEE Military Communications Conference (MILCOM)},
doi = {10.1109/MILCOM.2013.246},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ali, Wexler - 2013 - Army Warfighter Information Network-Tactical ( Win-T ) Theory of Operation.pdf:pdf},
isbn = {9780769551241},
keywords = {-win-t,cotm,hnw,ncw},
publisher = {IEEE},
title = {{Army Warfighter Information Network-Tactical ( Win-T ) Theory of Operation}},
year = {2013}
}
@article{Viswanathan1993,
abstract = {Military communication has the added dimension of mobility and bandwidth conservation. The paper deals with the necessity of advanced concepts of communicating images. data and fax in addition to voice as dictated by the command and control requirements. The Integrated services digital network as applied to tactical network of the future is presented. The topics of routing, encryption, mobile access, digital links are briefly covered. The importance of standards of CCITT and contemporary techniques like B-ISDN, cellular radios are discussed. The relevance of network management and its main features are brought out.},
author = {Viswanathan, M S},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Viswanathan - 1993 - Tactical Military Communication Networks of the Future.pdf:pdf},
isbn = {0011748X},
journal = {Defence Science Journal},
keywords = {Sciences: Comprehensive Works; Command and control},
number = {1},
pages = {71},
title = {{Tactical Military Communication Networks of the Future}},
url = {http://search.proquest.com/docview/1415412321?accountid=15533},
volume = {43},
year = {1993}
}
@article{Das2014,
author = {Das, Arun and Banerjee, Joydeep and Sen, Arunabha},
doi = {10.1109/MILCOM.2014.156},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Das, Banerjee, Sen - 2014 - Root Cause Analysis of Failures in Interdependent Power-Communication Networks.pdf:pdf},
isbn = {9781479967704},
pages = {910--915},
title = {{Root Cause Analysis of Failures in Interdependent Power-Communication Networks}},
year = {2014}
}
@article{Xu2001,
abstract = { In the future automated battle field communications will be supported in part by a hierarchical wireless network that includes: ad hoc ground radio subnets; point to point wireless long haul backbone, and; unmanned aerial vehicles (UAVs). In such a hierarchical network, nodes are generally partitioned into groups. Each group has one or more backbone nodes that provide access points to the backbone network and to UAVs. Communications between groups can thus utilize links at higher level. A critical protocol in the operation of such a large mobile network is routing. Previous research of UAV based systems has generally assumed the use of a hierarchical routing scheme, for example, extended hierarchical state routing (EHSR). However, a hierarchical scheme like EHSR has some limitations. In this paper, we extend landmark ad hoc routing (LANMAR) to a hierarchical structure with backbone nodes, high quality backbone links and UAVs. We show that the basic LANMAR scheme can be extended to incorporate backbone and UAV links. We will also show how backbone links and UAV links are automatically discovered by the LANMAR routing algorithm and are used effectively to reach remote destinations (thus reducing the hop distance). In other words, our scheme will combine the benefits of "flat" LANMAR routing and physical network hierarchy, without suffering of the intrinsic EHSR limitations.},
author = {Xu, Kaixin Xu Kaixin and Hong, Xiaoyan Hong Xiaoyan and Gerla, Mario Gerla Mario and Ly, Henry and Gu, D.L. Daniel Lihui and Angeles, Los},
doi = {10.1109/MILCOM.2001.985795},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - 2001 - Landmark routing in large wireless battlefield networks using UAVs.pdf:pdf},
isbn = {0-7803-7225-5},
journal = {2001 MILCOM Proceedings Communications for Network-Centric Operations: Creating the Information Force (Cat. No.01CH37277)},
number = {c},
pages = {230--234},
title = {{Landmark routing in large wireless battlefield networks using UAVs}},
volume = {1},
year = {2001}
}
@article{Juarez2006,
abstract = {There is a continuing need for increased capacity for military applications, especially in network-centric operational concepts that promote the use of information as fundamental for gaining superiority on the battlefield. As an example, the access to, and distribution of, sensor data is a major tenet of network-centric warfare and yet radio frequency (RF) links will struggle to provide the needed capacity. Free-space optical communications (FSOC) has the potential to meet these emerging military needs by offering dramatic increases in capacity. However, there are many technical challenges al multiple layers of the communications protocol stack. This article describes these challenges and discusses some mitigation approaches to provide a path to realizing this capability on the battlefield},
author = {Juarez, Juan C. and Dwivedi, Anurag and Hammons, a. Roger and Jones, Steven D. and Weerackody, Vijitha and Nichols, Robert a.},
doi = {10.1109/MCOM.2006.248164},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Juarez et al. - 2006 - Free-space optical communications for next-generation military networks.pdf:pdf},
issn = {01636804},
journal = {IEEE Communications Magazine},
number = {November},
pages = {46--51},
title = {{Free-space optical communications for next-generation military networks}},
volume = {44},
year = {2006}
}
@article{Numanoglu2013,
author = {Numanoglu, Tolga and Karadeniz, Baris and Onat, Furuzan Atay and Kolagasioglu, Ahmet Ertugrul},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Numanoglu et al. - 2013 - An Embedded Radio Software Emulation Platform Using OPNET and VxWorks to Develop Distributed Algorithms for Mi.pdf:pdf},
title = {{An Embedded Radio Software Emulation Platform Using OPNET and VxWorks to Develop Distributed Algorithms for Military Ad-Hoc Networks}},
year = {2013}
}
@article{Nicholas2014,
author = {Nicholas, Paul J. and Tkacheff, Jeffrey C. and Kuhns, Chana M.},
doi = {10.1109/MILCOM.2014.157},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nicholas, Tkacheff, Kuhns - 2014 - Analysis of Throughput-Constrained Tactical Wireless Networks.pdf:pdf},
isbn = {978-1-4799-6770-4},
journal = {2014 IEEE Military Communications Conference},
pages = {916--921},
title = {{Analysis of Throughput-Constrained Tactical Wireless Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6956878},
year = {2014}
}
@article{DeDomenico2013,
author = {{De Domenico}, Manlio and Sol{\'{e}}-Ribalta, Albert and Cozzo, Emanuele and Kivel{\"{a}}, Mikko and Moreno, Yamir and Porter, Mason A. and G{\'{o}}mez, Sergio and Arenas, Alex},
doi = {10.1103/PhysRevX.3.041022},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Domenico et al. - 2013 - Mathematical Formulation of Multilayer Networks.pdf:pdf},
issn = {2160-3308},
journal = {Physical Review X},
keywords = {interdisciplinary physics},
number = {4},
pages = {041022},
title = {{Mathematical Formulation of Multilayer Networks}},
url = {http://link.aps.org/doi/10.1103/PhysRevX.3.041022},
volume = {3},
year = {2013}
}
@article{DeDomenico2015,
author = {{De Domenico}, Manlio and Sol{\'{e}}-Ribalta, Albert and Omodei, Elisa and G{\'{o}}mez, Sergio and Arenas, Alex},
doi = {10.1038/ncomms7868},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Domenico et al. - 2015 - Ranking in interconnected multilayer networks reveals versatile nodes.pdf:pdf},
issn = {2041-1723},
journal = {Nature Communications},
pages = {6868},
title = {{Ranking in interconnected multilayer networks reveals versatile nodes}},
url = {http://www.nature.com/doifinder/10.1038/ncomms7868},
volume = {6},
year = {2015}
}
@article{Suri2010,
abstract = {Tactical edge networks present extremely challenging environments for communications given their wireless ad hoc nature and the inherent node mobility. Military applications such as Blue Force Tracking, inter-team communications, remote unmanned vehicle control, and sensor data mining/fusion thus have to deal with unstable links with limited bandwidth and variable latency. The peculiar characteristics of tactical networks call for peer-to-peer approaches to realize complex, adaptive, and fault-tolerant applications to be deployed in the battlefield. This article reports on our observations from several tactical networking experiments in which we have deployed state-of-the-art applications and services that leverage P2P communications. More specifically, we discuss why P2P approaches are critical for tactical network environments and applications. We then analyze the requirements that should be satisfied by P2P middleware for tactical environments. Finally, we discuss a case study, the Agile Computing Middleware, and present experimental results that demonstrate its effectiveness.},
author = {Suri, Niranjan and Benincasa, Giacomo and Tortonesi, Mauro and Stefanelli, Cesare and Kovach, Jesse and Winkler, Robert and Kohler, U.S. and Hanna, James and Pochet, Louis and Watson, Scott},
doi = {10.1109/MCOM.2010.5594678},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Suri et al. - 2010 - Peer-to-peer communications for tactical environments Observations, requirements, and experiences.pdf:pdf},
isbn = {0163-6804},
issn = {0163-6804},
journal = {IEEE Communications Magazine},
keywords = {Ad hoc networks,Bandwidth,Military communication,Peer to peer computing,Robot sensing systems,Servers,agile computing middleware,blue force tracking,fault-tolerant applications,inherent node mobility,interteam communications,leverage P2P communications,middleware,peer-to-peer communications,peer-to-peer computing,remote unmanned vehicle control,sensor data mining-fusion,tactical network environments,wireless ad hoc nature},
number = {10},
pages = {60--69},
title = {{Peer-to-peer communications for tactical environments: Observations, requirements, and experiences}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5594678},
volume = {48},
year = {2010}
}
@article{Cozzo2013,
abstract = {Recent advances in the study of networked systems have highlighted that our interconnected world is composed of networks that are coupled to each other through different "layers" that each represent one of many possible subsystems or types of interactions. Nevertheless, it is traditional to aggregate multilayer networks into a single weighted network in order to take advantage of existing tools. This is admittedly convenient, but it is also extremely problematic, as important information can be lost as a result. It is therefore important to develop multilayer generalizations of network concepts. In this paper, we analyze triadic relations and generalize the idea of transitivity to multiplex networks. By focusing on triadic relations, which yield the simplest type of transitivity, we generalize the concept and computation of clustering coefficients to multiplex networks. We show how the layered structure of such networks introduces a new degree of freedom that has a fundamental effect on transitivity. We compute multiplex clustering coefficients for several real multiplex networks and illustrate why one must take great care when generalizing standard network concepts to multiplex networks. We also derive analytical expressions for our clustering coefficients for ensemble averages of networks in a family of random multiplex networks. Our analysis illustrates that social networks have a strong tendency to promote redundancy by closing triads at every layer and that they thereby have a different type of multiplex transitivity from transportation networks, which do not exhibit such a tendency. These insights are invisible if one only studies aggregated networks.},
archivePrefix = {arXiv},
arxivId = {1307.6780},
author = {Cozzo, Emanuele and Kivel{\"{a}}, Mikko and {De Domenico}, Manlio and Sol{\'{e}}, Albert and Arenas, Alex and G{\'{o}}mez, Sergio and Porter, Mason A. and Moreno, Yamir},
doi = {10.1088/1367-2630/17/7/073029},
eprint = {1307.6780},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cozzo et al. - 2013 - Structure of Triadic Relations in Multiplex Networks.pdf:pdf},
title = {{Structure of Triadic Relations in Multiplex Networks}},
url = {http://arxiv.org/abs/1307.6780 http://dx.doi.org/10.1088/1367-2630/17/7/073029},
year = {2013}
}
@article{Baderi2009,
author = {Bader{\^{i}}, Brett W},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bader{\^{i}} - 2009 - Tensor Decompositions and Applications i.pdf:pdf},
keywords = {65f99,ams subject classifications,candecomp,canonical decomposition,higher-order principal components analysis,higher-order singular value decomposition,hosvd,i5a69,multilinear algebra,multiway arrays,parafac,parallel factors,tensor decompositions,tucker},
number = {3},
pages = {455--500},
title = {{Tensor Decompositions and Applications * i}},
volume = {51},
year = {2009}
}
@article{Baderi2009a,
author = {Bader{\^{i}}, Brett W},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bader{\^{i}} - 2009 - Tensor Decompositions and Applications i(2).pdf:pdf},
keywords = {65f99,ams subject classifications,candecomp,canonical decomposition,higher-order principal components analysis,higher-order singular value decomposition,hosvd,i5a69,multilinear algebra,multiway arrays,parafac,parallel factors,tensor decompositions,tucker},
number = {3},
pages = {455--500},
title = {{Tensor Decompositions and Applications * i}},
volume = {51},
year = {2009}
}
@article{Gomez2013,
abstract = {We study the time scales associated with diffusion processes that take place on multiplex networks, i.e., on a set of networks linked through interconnected layers. To this end, we propose the construction of a supra-Laplacian matrix, which consists of a dimensional lifting of the Laplacian matrix of each layer of the multiplex network. We use perturbative analysis to reveal analytically the structure of eigenvectors and eigenvalues of the complete network in terms of the spectral properties of the individual layers. The spectrum of the supra-Laplacian allows us to understand the physics of diffusionlike processes on top of multiplex networks.},
archivePrefix = {arXiv},
arxivId = {1207.2788},
author = {G{\'{o}}mez, S. and D{\'{i}}az-Guilera, A. and G{\'{o}}mez-Garde{\~{n}}es, J. and P{\'{e}}rez-Vicente, C. J. and Moreno, Y. and Arenas, A.},
doi = {10.1103/PhysRevLett.110.028701},
eprint = {1207.2788},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\'{o}}mez et al. - 2013 - Diffusion Dynamics on Multiplex Networks.pdf:pdf},
isbn = {0031-9007},
issn = {00319007},
journal = {Physical Review Letters},
number = {2},
pages = {028701},
pmid = {23383947},
title = {{Diffusion Dynamics on Multiplex Networks}},
url = {http://link.aps.org/doi/10.1103/PhysRevLett.110.028701%5Cnhttp://prl.aps.org/pdf/PRL/v110/i2/e028701},
volume = {110},
year = {2013}
}
@article{Cozzo2015,
abstract = {Multilayer networks represent systems in which there are several topological levels each one representing one kind of interaction or interdependency between the systems' elements. These networks have attracted a lot of attention recently because their study allows considering different dynamical modes concurrently. Here, we revise the main concepts and tools developed up to date. Specifically, we focus on several metrics for multilayer network characterization as well as on the spectral properties of the system, which ultimately enable for the dynamical characterization of several critical phenomena. The theoretical framework is also applied for description of real-world multilayer systems.},
archivePrefix = {arXiv},
arxivId = {1504.05567},
author = {Cozzo, Emanuele and de Arruda, Guilherme Ferraz and Rodrigues, Francisco A. and Moreno, Yamir and Arruda, Guilherme Ferraz De and Rodrigues, Francisco A.},
eprint = {1504.05567},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cozzo et al. - 2015 - Multilayer networks metrics and spectral properties.pdf:pdf},
journal = {arXiv preprint},
title = {{Multilayer networks: metrics and spectral properties}},
url = {http://arxiv.org/abs/1504.05567},
year = {2015}
}
@article{Sanchez-Garcia2014,
abstract = {Network representations are useful for describing the structure of a large variety of complex systems. Although most studies of real-world networks suppose that nodes are connected by only a single type of edge, most natural and engineered systems include multiple subsystems and layers of connectivity. This new paradigm has attracted a great deal of attention and one fundamental challenge is to characterize multilayer networks both structurally and dynamically. One way to address this question is to study the spectral properties of such networks. Here, we apply the framework of graph quotients, which occurs naturally in this context, and the associated eigenvalue interlacing results, to the adjacency and Laplacian matrices of undirected multilayer networks. Specifically, we describe relationships between the eigenvalue spectra of multilayer networks and their two most natural quotients, the network of layers and the aggregate network, and show the dynamical implications of working with either of the two simplified representations. Our work thus contributes in particular to the study of dynamical processes whose critical properties are determined by the spectral properties of the underlying network.},
archivePrefix = {arXiv},
arxivId = {1311.1759},
author = {S{\'{a}}nchez-Garc{\'{i}}a, Rub{\'{e}}n J. and Cozzo, Emanuele and Moreno, Yamir},
doi = {10.1103/PhysRevE.89.052815},
eprint = {1311.1759},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/S{\'{a}}nchez-Garc{\'{i}}a, Cozzo, Moreno - 2014 - Dimensionality reduction and spectral properties of multilayer networks.pdf:pdf},
issn = {1539-3755},
journal = {Physical Review E},
number = {5},
pages = {052815},
title = {{Dimensionality reduction and spectral properties of multilayer networks}},
url = {http://arxiv.org/abs/1311.1759},
volume = {89},
year = {2014}
}
@article{Halu2013,
author = {Halu, Arda and Mondrag{\~{A}}³n, Ra{\~{A}}{\textordmasculine}l J. and Panzarasa, Pietro and Bianconi, Ginestra},
doi = {10.1371/journal.pone.0078293},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Halu et al. - 2013 - Multiplex PageRank.pdf:pdf},
issn = {1932-6203},
journal = {PLoS ONE},
number = {10},
pages = {e78293},
title = {{Multiplex PageRank}},
url = {http://dx.plos.org/10.1371/journal.pone.0078293},
volume = {8},
year = {2013}
}
@article{Goemans1997,
author = {Goemans, Mx and Williamson, Dp},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goemans, Williamson - 1997 - The primal-dual method for approximation algorithms and its application to network design problems.pdf:pdf},
isbn = {0534949681},
journal = {Approximation algorithms for NP- {\ldots}},
pages = {144--191},
title = {{The primal-dual method for approximation algorithms and its application to network design problems}},
url = {http://www.math.uwaterloo.ca/$\sim$cswamy/courses/co453/w07/gw-pdsurvey.pdf},
year = {1997}
}
@article{Wang2010,
abstract = {Centrality measures are used in network science to rank the relative importance of nodes and edges of a graph. Here we define new measures of centrality for power grid structure that are based on its functionality. We show that the relative importance analysis based on centrality in graph theory can be generalized to power grid network with its electrical parameters taken into account. In the paper we experiment with the proposed electrical centrality measures on the NYISO-2935 system and the IEEE 300-bus system. We analyze the centrality distribution in order to identify important nodes or branches in the system which are of essential importance in terms of system vulnerability. We also present and discuss a number of interesting discoveries regarding the importance rank of power grid nodes and branches.},
author = {Wang, Zhifang and Scaglione, Anna and Thomas, Robert J.},
doi = {10.1109/CDC.2010.5717964},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Scaglione, Thomas - 2010 - Electrical centrality measures for electric power grid vulnerability analysis.pdf:pdf},
isbn = {9781424477456},
issn = {01912216},
journal = {Proceedings of the IEEE Conference on Decision and Control},
number = {2009},
pages = {5792--5797},
title = {{Electrical centrality measures for electric power grid vulnerability analysis}},
year = {2010}
}
@inproceedings{Kempe2003,
abstract = {Models for the processes by which ideas and influence propagate through a social network have been studied in a number of domains, including the diffusion of medical and technological innovations, the sudden and widespread adoption of various strategies in game-theoretic settings, and the effects of “word of mouth” in the promotion of new products. Recently, motivated by the design of viral marketing strategies, Domingos and Richardson posed a fundamental algorithmic problem for such social network processes: if we can try to convince a subset of individuals to adopt a new product or innovation, and the goal is to trigger a large cascade of further adoptions, which set of individuals should we target? We consider this problem in several of the most widely studied models in social network analysis. The optimization problem of selecting the most influential nodes is NP-hard here, and we provide the first provable approximation guarantees for efficient algorithms. Using an analysis framework based on submodular functions, we show that a natural greedy strategy obtains a solution that is provably within 63% of optimal for several classes of models; our framework suggests a general approach for reasoning about the performance guarantees of algorithms for these types of influence problems in social networks. We also provide computational experiments on large collaboration networks, showing that in addition to their provable guarantees, our approximation algorithms significantly out-perform nodeselection heuristics based on the well-studied notions of degree centrality and distance centrality from the field of social networks.},
archivePrefix = {arXiv},
arxivId = {0806.2034v2},
author = {Kempe, David and Kleinberg, Jon and Tardos, {\'{E}}va},
booktitle = {ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)},
doi = {10.1145/956755.956769},
eprint = {0806.2034v2},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kempe, Kleinberg, Tardos - 2003 - Maximizing the spread of influence through a social network.pdf:pdf},
isbn = {1581137370},
issn = {1557-2862},
pmid = {17255001},
title = {{Maximizing the spread of influence through a social network}},
url = {http://portal.acm.org/citation.cfm?doid=956750.956769},
year = {2003}
}
@article{,
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Quantifying the impact of Adversarial Attacks on Networks Resilient Capacity and Approximation Algorithms.pdf:pdf},
title = {{Quantifying the impact of Adversarial Attacks on Networks : Resilient Capacity and Approximation Algorithms}}
}
@article{Chopade2016,
author = {Chopade},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chopade - 2016 - Vulnerability Analysis of Smart Power Grid Network Using Modified Eigenvector Centrality.pdf:pdf},
title = {{Vulnerability Analysis of Smart Power Grid Network Using Modified Eigenvector Centrality}},
year = {2016}
}
@article{Burch,
author = {Burch, Carl and Carr, Robert and Krumke, Sven and Phillips, Cynthia and Sundberg, Eric},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Burch et al. - Unknown - Chapter 3 PSEUDOAPPROXIMATION ALGORITHM FOR NETWORK FLOW INHIBITION.pdf:pdf},
title = {{Chapter 3 PSEUDOAPPROXIMATION ALGORITHM FOR NETWORK FLOW INHIBITION}}
}
@article{Buchbinder2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1501.05801v1},
author = {Buchbinder, Niv and Feldman, M and Schwartz, R},
doi = {10.1137/1.9781611973730.80},
eprint = {arXiv:1501.05801v1},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buchbinder, Feldman, Schwartz - 2015 - Online Submodular Maximization with Preemption.pdf:pdf},
journal = {Siam},
pages = {1202--1216},
title = {{Online Submodular Maximization with Preemption}},
url = {http://epubs.siam.org/doi/abs/10.1137/1.9781611973730.80},
year = {2015}
}
@article{Schieber2016,
author = {Schieber, Tiago A. and Carpi, Laura and Frery, Alejandro C. and Rosso, Osvaldo A. and Pardalos, Panos M. and Ravetti, Mart{\'{i}}n G.},
doi = {10.1016/j.physleta.2015.10.055},
file = {:home/alan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schieber et al. - 2016 - Information theory perspective on network robustness.pdf:pdf},
issn = {03759601},
journal = {Physics Letters A},
number = {3},
pages = {359--364},
publisher = {Elsevier B.V.},
title = {{Information theory perspective on network robustness}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0375960115009275},
volume = {380},
year = {2016}
}
