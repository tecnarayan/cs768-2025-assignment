@incollection{mnih2013atari,
  title = {Playing Atari With Deep Reinforcement Learning},
  author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
  booktitle = {NIPS Deep Learning Workshop},
  year = {2013}
}

@MISC{Schaal99isimitation,
    author = {Stefan Schaal},
    title = {Is imitation learning the route to humanoid robots?},
    year = {1999}
}

@inproceedings{laroche2019spibb,
  title={Safe Policy Improvement with Baseline Bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Des Combes, Remi Tachet},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2019}
}

@article{mahmood2015emphatic,
  title={Emphatic temporal-difference learning},
  author={Mahmood, A Rupam and Yu, Huizhen and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1507.01569},
  year={2015}
}

@INPROCEEDINGS{antos07value, 
author={Andr\"as {Antos} and Csaa {Szepesvari} and Remi {Munos}}, 
booktitle={2007 IEEE International Symposium on Approximate Dynamic Programming and Reinforcement Learning}, 
title={Value-Iteration Based Fitted Policy Iteration: Learning with a Single Trajectory}, 
year={2007}, 
volume={}, 
number={}, 
pages={330-337}, 
keywords={continuous systems;iterative methods;learning (artificial intelligence);Markov processes;policy iteration;single trajectory;batch reinforcement learning;continuous space;discounted-reward Markovian decision problem;action-value function;approximate value iteration;Learning;Training data;Algorithm design and analysis;Dynamic programming;Automation;Polynomials;State-space methods;Control systems;Interleaved codes;Extraterrestrial measurements}, 
doi={10.1109/ADPRL.2007.368207}, 
ISSN={2325-1824}, 
month={April},}


@inproceedings{impala2018,
  title={IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  year={2018}
}

@InProceedings{kalashnikov18qtopt,
  title = 	 {Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  author = 	 {Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and Levine, Sergey},
  booktitle = 	 {Proceedings of The 2nd Conference on Robot Learning},
  pages = 	 {651--673},
  year = 	 {2018},
  editor = 	 {},
  volume = 	 {87},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v87/kalashnikov18a/kalashnikov18a.pdf},
  url = 	 {},
  abstract = 	 {In this paper, we study the problem of learning vision-based dynamic manipulation skills using a scalable reinforcement learning approach. We study this problem in the context of grasping, a longstanding challenge in robotic manipulation. In contrast to static learning behaviors that choose a grasp point and then execute the desired grasp, our method enables closed-loop vision-based control, whereby the robot continuously updates its grasp strategy based on the most recent observations to optimize long-horizon grasp success. To that end, we introduce QT-Opt, a scalable self-supervised vision-based reinforcement learning framework that can leverage over 580k real-world grasp attempts to train a deep neural network Q-function with over 1.2M parameters to perform closed-loop, real-world grasping that generalizes to 96% grasp success on unseen objects. Aside from attaining a very high success rate, our method exhibits behaviors that are quite distinct from more standard grasping systems: using only RGB vision-based perception from an over-the-shoulder camera, our method automatically learns regrasping strategies, probes objects to find the most effective grasps, learns to reposition objects and perform other non-prehensile pre-grasp manipulations, and responds dynamically to disturbances and perturbations. }
}

@article{lillicrap2015ddpg,
  title={Continuous control with deep reinforcement learning},
  author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
  journal={CoRR},
  year={2015},
  volume={abs/1509.02971}
}

@incollection{anots08fitted,
title = {Fitted Q-iteration in continuous action-space MDPs},
author = {Andr\'{a}s Antos and Csaba Szepesv\'{a}ri and R\'{e}mi Munos},
booktitle = {Advances in Neural Information Processing Systems 20},
editor = {},
pages = {9--16},
year = {2008},
publisher = {Curran Associates, Inc.},
url = {}
}


@article{Schaul2016PrioritizedER,
  title={Prioritized Experience Replay},
  author={Tom Schaul and John Quan and Ioannis Antonoglou and David Silver},
  journal={CoRR},
  year={2016},
  volume={abs/1511.05952}
}

@article{gretton2012kernel,
 author = {Gretton, Arthur and Borgwardt, Karsten M. and Rasch, Malte J. and Sch\"{o}lkopf, Bernhard and Smola, Alexander},
 title = {A Kernel Two-sample Test},
 journal = {J. Mach. Learn. Res.},
 issue_date = {3/1/2012},
 volume = {13},
 month = mar,
 year = {2012},
 issn = {1532-4435},
 pages = {723--773},
 numpages = {51},
 url = {http://dl.acm.org/citation.cfm?id=2188385.2188410},
 acmid = {2188410},
 publisher = {JMLR.org},
 keywords = {hypothesis testing, integral probability metric, kernel methods, schema matching, two-sample test, uniform convergence bounds},
} 

@inproceedings{goodfellow2015advexamples,
title	= {Explaining and Harnessing Adversarial Examples},
author	= {Ian Goodfellow and Jonathon Shlens and Christian Szegedy},
year	= {2015},
URL	= {http://arxiv.org/abs/1412.6572},
booktitle	= {International Conference on Learning Representations}
}

@inproceedings{bennett2007netflix,
  title={The netflix prize},
  author={Bennett, James and Lanning, Stan and others},
  year={2007}
}

@inproceedings{DBLP:conf/iclr/GaoXLYLD18,
  author    = {Yang Gao and
               Huazhe Xu and
               Ji Lin and
               Fisher Yu and
               Sergey Levine and
               Trevor Darrell},
  title     = {Reinforcement Learning from Imperfect Demonstrations},
  booktitle = {{ICLR} (Workshop)},
  publisher = {OpenReview.net},
  year      = {2018}
}


@article{yu2018bdd,
  author    = {Fisher Yu and
               Wenqi Xian and
               Yingying Chen and
               Fangchen Liu and
               Mike Liao and
               Vashisht Madhavan and
               Trevor Darrell},
  title     = {{BDD100K:} {A} Diverse Driving Video Database with Scalable Annotation
               Tooling},
  journal   = {CoRR},
  volume    = {abs/1805.04687},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.04687},
  archivePrefix = {arXiv},
  eprint    = {1805.04687},
  timestamp = {Mon, 13 Aug 2018 16:47:46 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1805-04687},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{imagenet_cvpr09,
        AUTHOR = {Deng, Jia and Dong, Wei and Socher, Richard S. and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
        TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
        BOOKTITLE = {CVPR09},
        YEAR = {2009},
}

@article{he2016resnet,
  title={Deep Residual Learning for Image Recognition},
  author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={770-778}
}

@article{levine2018rlasinference,
  author    = {Sergey Levine},
  title     = {Reinforcement Learning and Control as Probabilistic Inference: Tutorial
               and Review},
  journal   = {CoRR},
  volume    = {abs/1805.00909},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.00909},
  archivePrefix = {arXiv},
  eprint    = {1805.00909},
  timestamp = {Mon, 13 Aug 2018 16:47:19 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1805-00909},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
grau-moya2018soft,
title={Soft Q-Learning with Mutual-Information Regularization},
author={Jordi Grau-Moya and Felix Leibfried and Peter Vrancx},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HyEtjoCqFX},
}

@article{bruno2015approximate,
  author  = {Bruno Scherrer and Mohammad Ghavamzadeh and Victor Gabillon and Boris Lesner and Matthieu Geist},
  title   = {Approximate Modified Policy Iteration and its Application to the Game of Tetris},
  journal = {Journal of Machine Learning Research},
  year    = {2015},
  volume  = {16},
  pages   = {1629-1676},
  url     = {http://jmlr.org/papers/v16/scherrer15a.html}
}


@book{suttonrlbook,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  edition = {Second}
}

@InProceedings{fujimoto18addressing,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1587--1596},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/fujimoto18a/fujimoto18a.pdf},
  url = 	 {},
  abstract = 	 {In value-based reinforcement learning methods such as deep Q-learning, function approximation errors are known to lead to overestimated value estimates and suboptimal policies. We show that this problem persists in an actor-critic setting and propose novel mechanisms to minimize its effects on both the actor and the critic. Our algorithm builds on Double Q-learning, by taking the minimum value between a pair of critics to limit overestimation. We draw the connection between target networks and overestimation bias, and suggest delaying policy updates to reduce per-update error and further improve performance. We evaluate our method on the suite of OpenAI gym tasks, outperforming the state of the art in every environment tested.}
}

@article{burda2018rnd,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@article{stadie2015incentivizing,
  title={Incentivizing exploration in reinforcement learning with deep predictive models},
  author={Stadie, Bradly C and Levine, Sergey and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1507.00814},
  year={2015}
}

@inproceedings{houthooft2016vime,
  title={Vime: Variational information maximizing exploration},
  author={Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1109--1117},
  year={2016}
}

@inproceedings{tang2017exploration,
  title={\# Exploration: A study of count-based exploration for deep reinforcement learning},
  author={Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Chen, OpenAI Xi and Duan, Yan and Schulman, John and DeTurck, Filip and Abbeel, Pieter},
  booktitle={Advances in neural information processing systems},
  pages={2753--2762},
  year={2017}
}

@inproceedings{fu2017ex2,
  title={Ex2: Exploration with exemplar models for deep reinforcement learning},
  author={Fu, Justin and Co-Reyes, John and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2577--2587},
  year={2017}
}

@inproceedings{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1471--1479},
  year={2016}
}

@inproceedings{precup2001offpol,
author = {Precup, Doina and Sutton, Richard S. and Dasgupta, Sanjoy},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Off-policy temporal-difference learning with function approximation}},
year = {2001}
}

@article{sutton2016etd,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@book{bertsekas1996ndp,
  title={Neuro-dynamic programming},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  publisher={Athena Scientific},
  year={1996}
}

@inproceedings{Baird1995,
annote = {Residual gradient = differentiating through target},
author = {Baird, Leemon},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Residual Algorithms : Reinforcement Learning with Function Approximation}},
year = {1995}
}


@article{majdik2017zurich,
  title={The Zurich urban micro aerial vehicle dataset},
  author={Majdik, Andr{\'a}s L and Till, Charles and Scaramuzza, Davide},
  journal={The International Journal of Robotics Research},
  volume={36},
  number={3},
  pages={269--273},
  year={2017},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{levine2018handeye,
  title={Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection},
  author={Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Ibarz, Julian and Quillen, Deirdre},
  journal={The International Journal of Robotics Research},
  volume={37},
  number={4-5},
  pages={421--436},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}


@InProceedings{hallak2017coptd,
  title = 	 {Consistent On-Line Off-Policy Evaluation},
  author = 	 {Assaf Hallak and Shie Mannor},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1372--1383},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  month = 	 {06--11 Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/hallak17a/hallak17a.pdf},
  url = 	 {http://proceedings.mlr.press/v70/hallak17a.html},
  abstract = 	 {The problem of on-line off-policy evaluation (OPE) has been actively studied in the last decade due to its importance both as a stand-alone problem and as a module in a policy improvement scheme. However, most Temporal Difference (TD) based solutions ignore the discrepancy between the stationary distribution of the behavior and target policies and its effect on the convergence limit when function approximation is applied. In this paper we propose the Consistent Off-Policy Temporal Difference (COP-TD($\lambda$, $\beta$)) algorithm that addresses this issue and reduces this bias at some computational expense. We show that COP-TD($\lambda$, $\beta$) can be designed to converge to the same value that would have been obtained by using on-policy TD($\lambda$) with the target policy. Subsequently, the proposed scheme leads to a related and promising heuristic we call log-COP-TD($\lambda$, $\beta$). Both algorithms have favorable empirical results to the current state of the art on-line OPE algorithms. Finally, our formulation sheds some new light on the recently proposed Emphatic TD learning.}
}

@article{gelada2019off,
  author    = {Carles Gelada and
               Marc G. Bellemare},
  title     = {Off-Policy Deep Reinforcement Learning by Bootstrapping the Covariate
               Shift},
  journal   = {CoRR},
  volume    = {abs/1901.09455},
  year      = {2019},
  url       = {},
  archivePrefix = {arXiv},
  eprint    = {1901.09455},
  timestamp = {Sat, 02 Feb 2019 16:56:00 +0100},
  biburl    = {},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{hester2018dqfd,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{antos07fitted,
 author = {Antos, Andr\'{a}s and Munos, R{\'e}mi and Szepesv\'{a}ri, Csaba},
 title = {Fitted Q-iteration in Continuous Action-space MDPs},
 booktitle = {Proceedings of the 20th International Conference on Neural Information Processing Systems},
 series = {NIPS'07},
 year = {2007},
 isbn = {978-1-60560-352-0},
 location = {Vancouver, British Columbia, Canada},
 pages = {9--16},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=2981562.2981564},
 acmid = {2981564},
 publisher = {Curran Associates Inc.},
 address = {USA},
} 


@inproceedings{deBruin2015importance,
author = {de Bruin, Tim and Kober, Jens and Tuyls, Karl and Babuska, Robert},
year = {2015},
month = {01},
pages = {},
title = {The importance of experience replay database composition in deep reinforcement learning}
}

@article{gu2016qprop,
  title={Q-prop: Sample-efficient policy gradient with an off-policy critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.02247},
  year={2016}
}

@article{haarnoja2018sac,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@inproceedings{henderson2018deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{fu2019diagnosing,
  title={Diagnosing Bottlenecks in Deep Q-learning Algorithms},
  author={Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
  journal={arXiv preprint arXiv:1902.10250},
  year={2019}
}

@article{fujimoto2018off,
  title={Off-Policy Deep Reinforcement Learning without Exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  journal={arXiv preprint arXiv:1812.02900},
  year={2018}
}

@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1054--1062},
  year={2016}
}

@inproceedings{farahmand2010error,
  title={Error propagation for approximate policy and value iteration},
  author={Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={568--576},
  year={2010}
}

@inproceedings{munos2003errorapi,
  title={Error bounds for approximate policy iteration},
  author={Munos, R{\'e}mi},
  booktitle={Proceedings of the Twentieth International Conference on International Conference on Machine Learning},
  pages={560--567},
  year={2003},
  organization={AAAI Press}
}

@inproceedings{munos2005erroravi,
  title={Error bounds for approximate value iteration},
  author={Munos, R{\'e}mi},
  year={2005},
  booktitle={Proceedings of the National Conference on Artificial Intelligence}
}

@inproceedings{ross2011dagger,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011}
}

@inproceedings{kakade2002cpi,
  title={Approximately Optimal Approximate Reinforcement Learning},
  author={Kakade, Sham and Langford, John},
  booktitle={Proceedings of the Nineteenth International Conference on Machine Learning},
  pages={267--274},
  year={2002},
  organization={Morgan Kaufmann Publishers Inc.}
}

@incollection{watters2017vin,
    title = {Visual Interaction Networks: Learning a Physics Simulator from Video},
    author = {Watters, Nicholas and Zoran, Daniel and Weber, Theophane and Battaglia, Peter and Pascanu, Razvan and Tacchetti, Andrea},
    booktitle = {NIPS},
    year = {2017}
}

@inproceedings{wu2017vda,
  title={Learning to See Physics via Visual De-animation},
  author={Wu, Jiajun and Lu, Erika and Kohli, Pushmeet and Freeman, William T and Tenenbaum, Joshua B},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{fragkiadaki2016billiards,
  title={Learning Visual Predictive Models of Physics for Playing Billiards},
  author={Katerina Fragkiadaki and
              Pulkit Agrawal and
              Sergey Levine and
              Jitendra Malik},
  booktitle={International Conference on Learning Representations},
  year={2016}
}

@article{lee2018savp,
  title={Stochastic Adversarial Video Prediction},
  author={Alex X. Lee and Richard Zhang and Frederik Ebert and Pieter Abbeel and Chelsea Finn and Sergey Levine},
  journal={arXiv preprint arXiv:1804.01523},
  year={2018}
}

@inproceedings{wu2017nsd,
  title={Neural Scene De-rendering},
  author={Wu, Jiajun and Tenenbaum, Joshua B and Kohli, Pushmeet},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2017}
}

@inproceedings{chang2016npe,
    title={A Compositional Object-Based Approach to Learning Physical Dynamics},
    author={Chang, Michael B and Ullman, Tomer and Torralba, Antonio and Tenenbaum, Joshua B},
    booktitle={ICLR},
    year={2016}
}

@inproceedings{hamrick2011physics,
  title={Internal physics models guide probabilistic judgments about object dynamics},
  author={Hamrick, Jessica B. and Battaglia, Peter and Tenenbaum, Joshua B.},
  booktitle={Proceedings of the 33rd annual conference of the cognitive science society},
  year={2011}
}

@inproceedings{lerer2016physnet,
 author = {Lerer, Adam and Gross, Sam and Fergus, Rob},
 title = {Learning Physical Intuition of Block Towers by Example},
 booktitle = {ICML},
 year={2016}
} 

@inproceedings{babaeizadeh2018sv2p,
    title={Stochastic Variational Video Prediction},
    author={Mohammad Babaeizadeh and Chelsea Finn and Dumitru Erhan and Roy H. Campbell and Sergey Levine},
    booktitle={ICLR},
    year={2018}
}

@article{ha2018worldmodels,
  author = {Ha, D. and Schmidhuber, J.},
  title  = {World Models},
  eprint = {arXiv:1803.10122},
  year   = {2018}
}

@inproceedings{higgins2017betavae,
    title={{$\beta$}-{VAE}: Learning Basic Visual Concepts with a Constrained Variational Framework},
    author={Irina Higgins and Loic Matthey and Arka Pal and Christopher Burgess and Xavier Glorot and Matthew Botvinick and Shakir Mohamed and Alexander Lerchner},
    booktitle={International Conference on Learning Representations},
    year={2017}
}

@inproceedings{chen2016infogan,
  title={InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets},
  author={Xi Chen and Yan Duan and Rein Houthooft and John Schulman and Ilya Sutskever and Pieter Abbeel},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@inproceedings{kulkarni2015dcign,
    author = {Kulkarni, Tejas D. and Whitney, William F. and Kohli, Pushmeet and Tenenbaum, Joshua B.},
    title = {Deep Convolutional Inverse Graphics Network},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2015}
}

@incollection{goodfellow2014gan,
    title = {Generative Adversarial Nets},
    author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2014}
}

@article{kingma2013vae,
  author    = {Diederik P. Kingma and
              Max Welling},
  title     = {Auto-Encoding Variational Bayes},
  journal   = {CoRR},
  volume    = {abs/1312.6114},
  year      = {2013}
}

@article{spelke2007core,
    author = {Spelke, Elizabeth S. and Kinzler, Katherine D.},
    title = {Core knowledge},
    journal = {Developmental Science},
    volume = {10},
    number = {1},
    pages = {89-96},
    year = {2007}
}

@phdthesis{winston1970structural,
	author = "Winston, Patrick Henry",
	year = "1970",
	title = "Learning structural descriptions from examples",
	institution = "Department of Electrical Engineering and Computer Science, 		
		Massachusetts Institute of Technology",
	type = "Technical Report",
	number = "MAC-TR-76"
}

@article{finn2017foresight,
  title={Deep visual foresight for planning robot motion},
  author={Chelsea Finn and Sergey Levine},
  journal={IEEE International Conference on Robotics and Automation},
  year={2017},
  pages={2786-2793}
}


@InProceedings{kansky2017schema,
  title = 	 {Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics},
  author = 	 {Ken Kansky and Tom Silver and David A. M{\'e}ly and Mohamed Eldawy and Miguel L{\'a}zaro-Gredilla and Xinghua Lou and Nimrod Dorfman and Szymon Sidor and Scott Phoenix and Dileep George},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  year = 	 {2017},
}

@inproceedings{diuk2008oomdp,
     author = {Diuk, Carlos and Cohen, Andre and Littman, Michael L.},
     title = {An Object-oriented Representation for Efficient Reinforcement Learning},
     booktitle = {Proceedings of the 25th International Conference on Machine Learning},
     year = {2008},
} 

@incollection{zaheer2017deepsets,
    title = {Deep Sets},
    author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan R and Smola, Alexander J},
    year = {2017}
}

@incollection{santoro2017clevr,
    title = {A simple neural network module for relational reasoning},
    author = {Santoro, Adam and Raposo, David and Barrett, David G and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Tim},
    year = {2017}
}

@inproceedings{johnson2016perceptual,
  title={Perceptual losses for real-time style transfer and super-resolution},
  author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  booktitle={ECCV},
  year={2016}
}

@inproceedings{ba2015adam,
  author    = {Kingma, Diederik P. and Ba, Jimmy},
  title     = {Adam: A Method for Stochastic Optimization},
  booktitle = {International Conference on Learning Representations},
  year      = {2015},
}

@inproceedings{gupta2010blocks,
   author="Abhinav Gupta and Alexei A. Efros and Martial Hebert", 
   title="Blocks World Revisited: Image Understanding Using Qualitative Geometry and Mechanics", 
   booktitle="European Conference on Computer Vision(ECCV)", 
   year="2010", 
}

@inproceedings{mottaghi2016newtonian,
    author = {Mottaghi, Roozbeh and Bagherinezhad, Hessam and Rastegari, Mohammad and Farhadi, Ali},
    title = {Newtonian Scene Understanding: Unfolding the Dynamics of Objects in Static Images},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
    year = {2016}
}

@inproceedings{li2017stability, 
    author={W. Li and A. Leonardis and M. Fritz}, 
    booktitle={IEEE International Conference on Robotics and Automation}, 
    title={Visual stability prediction for robotic manipulation}, 
    year={2017}, 
}

@ARTICLE{jia2015reasoning, 
    author={Z. Jia and A. C. Gallagher and A. Saxena and T. Chen}, 
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
    title={3D Reasoning from Blocks to Stability}, 
    year={2015}, 
}

@article{mottaghi2016what_happens_if,
  author    = {Roozbeh Mottaghi and
               Mohammad Rastegari and
               Abhinav Gupta and
               Ali Farhadi},
  title     = {"What happens if..." Learning to Predict the Effect of Forces
               in Images},
  journal   = {CoRR},
  volume    = {abs/1603.05600},
  year      = {2016}
}

@article{shao2014cuboid,
  title   = "Imagining the Unseen: Stability-based Cuboid Arrangements for Scene Understanding", 
  author  = "Tianjia Shao and Aron Monszpart and Youyi Zheng and Bongjin Koo and Weiwei Xu and Kun Zhou 
             and Niloy Mitra",
  year    = {2014},
  journal = {ACM SIGGRAPH Asia 2014},
  note    = {* Joint first authors}
}

@article{zheng2014safety,
  title={Scene Understanding by Reasoning Stability and Safety},
  author={Bo Zheng and Yibiao Zhao and Joey C. Yu and Katsushi Ikeuchi and Song-Chun Zhu},
  journal={International Journal of Computer Vision},
  year={2014}
}

@article{ehrhardt2017heightfields,
   author = {{S\'ebastien} Ehrhardt and Aron Monszpart and Niloy {J. Mitra} and Andrea Vedaldi},
    title = "{Taking Visual Motion Prediction To New Heightfields}",
  journal = {arXiv preprint arXiv:1712.09448},
archivePrefix = "arXiv",
     year = 2017
}

@incollection{eslami2016air,
    title = {Attend, Infer, Repeat: Fast Scene Understanding with Generative Models},
    author = {Eslami, S. M. Ali and Heess, Nicolas and Weber, Theophane and Tassa, Yuval and Szepesvari, David and Kavukcuoglu, Koray and Hinton, Geoffrey E},
    booktitle = {Advances in Neural Information Processing Systems 29},
    year = {2016}
}

@article{thomas2017factors,
  author    = {Valentin Thomas and
               Jules Pondard and
               Emmanuel Bengio and
               Marc Sarfati and
               Philippe Beaudoin and
               Marie{-}Jean Meurs and
               Joelle Pineau and
               Doina Precup and
               Yoshua Bengio},
  title     = {Independently Controllable Factors},
  journal   = {CoRR},
  volume    = {abs/1708.01289},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.01289},
  archivePrefix = {arXiv},
  eprint    = {1708.01289},
  timestamp = {Mon, 13 Aug 2018 16:49:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-01289},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{greff2017nem,
    title = {Neural Expectation Maximization},
    author = {Greff, Klaus and van Steenkiste, Sjoerd and Schmidhuber, J\"{u}rgen},
    booktitle = {Advances in Neural Information Processing Systems 30},
    editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
    year = {2017},
}

@inproceedings{guestrin2003relational,
     author = {Guestrin, Carlos and Koller, Daphne and Gearhart, Chris and Kanodia, Neal},
     title = {Generalizing Plans to New Environments in Relational MDPs},
     booktitle = {Proceedings of the 18th International Joint Conference on Artificial Intelligence},
     year = {2003}
} 

@article{brunskill2018soorl,
  title={Strategic Object Oriented Reinforcement Learning},
  author={Ramtin Keramati and Jay Whang and Patrick Cho and Emma Brunskill},
  journal={arXiv preprint arXiv:1806.00175},
  year={2018}
}

@inproceedings{wingate2014physicsmdp,
      title = 	 {A Physics-Based Model Prior for Object-Oriented MDPs},
      author = 	 {Jonathan Scholz and Martin Levihn and Charles Isbell and David Wingate},
      booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
      year = 	 {2014}
}

@article{devin2017deepobjects,
  title={Deep Object-Centric Representations for Generalizable Robot Learning},
  author={Coline Devin and Pieter Abbeel and Trevor Darrell and Sergey Levine},
  journal={CoRR},
  year={2017},
  volume={abs/1708.04225}
}

@article{goel2018segmentation,
  title={Unsupervised Video Object Segmentation for Deep Reinforcement Learning},
  author={Vik Goel and Jameson Weng and Pascal Poupart},
  journal={CoRR},
  year={2018},
  volume={abs/1805.07780}
}

@book{roberts1963thesis,
  author = {Roberts, Lawrence G.},
  series = {Outstanding Dissertations in the Computer Sciences},
  title = {Machine Perception of Three-Dimensional Solids},
  year = 1963
}





@InProceedings{wu19domain,
  title = 	 {Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment},
  author = 	 {Wu, Yifan and Winston, Ezra and Kaushik, Divyansh and Lipton, Zachary},
  booktitle = 	 {ICML 2019},
  abstract = 	 {Domain adaptation addresses the common situation in which the target distribution generating our test data differs from the source distribution generating our training data. While absent assumptions, domain adaptation is impossible, strict conditions, e.g. covariate or label shift, enable principled algorithms. Recently-proposed domain-adversarial approaches consist of aligning source and target encodings, an approach often motivated as minimizing two (of three) terms in a theoretical bound on target error. Unfortunately, this minimization can cause arbitrary increases in the third term, a problem guaranteed to arise under shifting label distributions. We propose asymmetrically-relaxed distribution alignment, a new approach that overcomes some limitations of standard domain-adversarial algorithms. Moreover, we characterize precise assumptions under which our algorithm is theoretically principled and demonstrate empirical benefits on both synthetic and real datasets.}
}

@article{jacques19way,
  author    = {Natasha Jaques and
               Asma Ghandeharioun and
               Judy Hanwen Shen and
               Craig Ferguson and
               {\`{A}}gata Lapedriza and
               Noah Jones and
               Shixiang Gu and
               Rosalind W. Picard},
  title     = {Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human
               Preferences in Dialog},
  journal   = {CoRR},
  volume    = {abs/1907.00456},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.00456},
  archivePrefix = {arXiv},
  eprint    = {1907.00456},
  timestamp = {Mon, 08 Jul 2019 14:12:33 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1907-00456},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{cem,
 author = {Rubinstein, Reuven Y. and Kroese, Dirk P.},
 title = {The Cross Entropy Method: A Unified Approach To Combinatorial Optimization, Monte-carlo Simulation (Information Science and Statistics)},
 year = {2004},
 isbn = {038721240X},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@article{wang2019random,
  author    = {Ruohan Wang and
               Carlo Ciliberto and
               Pierluigi Vito Amadori and
               Yiannis Demiris},
  title     = {Random Expert Distillation: Imitation Learning via Expert Policy Support
               Estimation},
  journal   = {CoRR},
  volume    = {abs/1905.06750},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.06750},
  archivePrefix = {arXiv},
  eprint    = {1905.06750},
  timestamp = {Tue, 28 May 2019 12:48:08 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1905-06750},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{mujoco,
  author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle = {IROS},
  pages = {5026-5033},
  title = {{MuJoCo}: A physics engine for model-based control.},
  year = 2012
}

@Article{vgg,
    author       = "Simonyan, K. and Zisserman, A.",
    title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    journal      = "CoRR",
    volume       = "abs/1409.1556",
    year         = "2014"
}

@inproceedings{
    van2018relational,
    title={Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions},
    author={Sjoerd van Steenkiste and Michael Chang and Klaus Greff and JÃ¼rgen Schmidhuber},
    booktitle={ICLR},
    year={2018},
}

@article{levine2016visuomotor,
 author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1532-4435},
 pages = {1334--1373},
 numpages = {40},
 acmid = {2946684},
 publisher = {JMLR.org},
 keywords = {neural networks, optimal control, reinforcement learning, vision},
} 


@article{mnih2015humanlevel,
  added-at = {2015-08-26T14:46:40.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/2fb15f4471c81dc2b9edf2304cb2f7083/hotho},
  description = {Human-level control through deep reinforcement learning - nature14236.pdf},
  interhash = {eac59980357d99db87b341b61ef6645f},
  intrahash = {fb15f4471c81dc2b9edf2304cb2f7083},
  issn = {00280836},
  journal = {Nature},
  keywords = {deep learning toread},
  month = feb,
  number = 7540,
  pages = {529--533},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp = {2015-08-26T14:46:40.000+0200},
  title = {Human-level control through deep reinforcement learning},
  volume = 518,
  year = 2015
}

@article{schulman2017ppo,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017}
}

@InProceedings{schulman2015trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {John Schulman and Sergey Levine and Pieter Abbeel and Michael Jordan and Philipp Moritz},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1889--1897},
  year = 	 {2015},
  editor = 	 {Francis Bach and David Blei},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher = 	 {PMLR},
}


@article{lake2016building,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
  biburl = {https://www.bibsonomy.org/bibtex/2576ae0ad88cf063408fafc9a55a961f3/dblp},
  ee = {http://arxiv.org/abs/1604.00289},
  interhash = {c8d2eb567dd89fc6f03c07b9db9490ac},
  intrahash = {576ae0ad88cf063408fafc9a55a961f3},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T12:23:49.000+0200},
  title = {Building Machines That Learn and Think Like People.},
  volume = {abs/1604.00289},
  year = 2016
}

@incollection{watter2015embed,
title = {Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images},
author = {Watter, Manuel and Springenberg, Jost and Boedecker, Joschka and Riedmiller, Martin},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {2746--2754},
year = {2015},
publisher = {Curran Associates, Inc.},
}

@article{kumar2016optimal,
  title={Optimal control with learned local models: Application to dexterous manipulation},
  author={Vikash Kumar and Emanuel Todorov and Sergey Levine},
  journal={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2016},
  pages={378-383}
}

@article{chua2018pets,
  title={Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
  author={Kurtland Chua and Roberto Calandra and Rowan McAllister and Sergey Levine},
  journal={CoRR},
  year={2018},
  volume={abs/1805.12114}
}

@inproceedings{
kurutach2018modelensemble,
title={Model-Ensemble Trust-Region Policy Optimization},
author={Thanard Kurutach and Ignasi Clavera and Yan Duan and Aviv Tamar and Pieter Abbeel},
booktitle={International Conference on Learning Representations},
year={2018},
}

@article{feinberg2018mve,
  author    = {Vladimir Feinberg and
               Alvin Wan and
               Ion Stoica and
               Michael I. Jordan and
               Joseph E. Gonzalez and
               Sergey Levine},
  title     = {Model-Based Value Estimation for Efficient Model-Free Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1803.00101},
  year      = {2018}
}


@incollection{i2a,
title = {Imagination-Augmented Agents for Deep Reinforcement Learning},
author = {Racani\`{e}re, S\'{e}bastien and Weber, Theophane and Reichert, David and Buesing, Lars and Guez, Arthur and Jimenez Rezende, Danilo and Puigdom\`{e}nech Badia, Adri\`{a} and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and Pascanu, Razvan and Battaglia, Peter and Hassabis, Demis and Silver, David and Wierstra, Daan},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {5690--5701},
year = {2017},
publisher = {Curran Associates, Inc.},
}

@InProceedings{gu2016mba,
  title = 	 {Continuous Deep Q-Learning with Model-based Acceleration},
  author = 	 {Shixiang Gu and Timothy Lillicrap and Ilya Sutskever and Sergey Levine},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {2829--2838},
  year = 	 {2016},
  editor = 	 {Maria Florina Balcan and Kilian Q. Weinberger},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher = 	 {PMLR},
}

@article{agarwal19striving,
  author    = {Rishabh Agarwal and
               Dale Schuurmans and
               Mohammad Norouzi},
  title     = {Striving for Simplicity in Off-policy Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1907.04543},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.04543},
  archivePrefix = {arXiv},
  eprint    = {1907.04543},
  timestamp = {Wed, 17 Jul 2019 10:27:36 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1907-04543},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{sutton1990dyna,
  title={Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
  author={Richard S. Sutton},
  booktitle={ML},
  year={1990}
}

@InProceedings{byrd19is,
  title = 	 {What is the Effect of Importance Weighting in Deep Learning?},
  author = 	 {Byrd, Jonathon and Lipton, Zachary},
  booktitle = 	 {ICML 2019},
}

% @InProceedings{sac,
%   title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
%   author = 	 {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
%   booktitle = 	 {ICML 2018},
% }

@article{alphagozero,
  author    = {David Silver and
               Thomas Hubert and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Matthew Lai and
               Arthur Guez and
               Marc Lanctot and
               Laurent Sifre and
               Dharshan Kumaran and
               Thore Graepel and
               Timothy P. Lillicrap and
               Karen Simonyan and
               Demis Hassabis},
  title     = {Mastering Chess and Shogi by Self-Play with a General Reinforcement
               Learning Algorithm},
  journal   = {CoRR},
  volume    = {abs/1712.01815},
  year      = {2017}
}

@article{kaelbling,
    author = "Leslie Pack Kaelbling and Michael L. Littman and Andrew P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
}

@article{haarnoja18sac,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
  timestamp = {Mon, 13 Aug 2018 16:48:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-01290},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={International Conference on machine learning (ICML)},
  pages={465--472},
  year={2011}
}

@article{asadi2018lipschitz,
  title={Lipschitz continuity in model-based reinforcement learning},
  author={Asadi, Kavosh and Misra, Dipendra and Littman, Michael L},
  journal={arXiv preprint arXiv:1804.07193},
  year={2018}
}