@article{hendrycks2019benchmarking,
  title={Benchmarking neural network robustness to common corruptions and perturbations},
  author={Hendrycks, Dan and Dietterich, Thomas},
  journal={arXiv preprint arXiv:1903.12261},
  year={2019}
}
@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}
@inproceedings{ovadia2019canyou,
 author = {Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, D. and Nowozin, Sebastian and Dillon, Joshua and Lakshminarayanan, Balaji and Snoek, Jasper},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Can you trust your model\textquotesingle s uncertainty?  {E}valuating predictive uncertainty under dataset shift},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/8558cb408c1d76621371888657d2eb1d-Paper.pdf},
 volume = {32},
 year = {2019}
}
@techreport{krizhevsky2009cifar,
  title={Learning Multiple Layers of Features from Tiny Images},
  author={Krizhevsky, Alex},
  year={2009}
}
@inproceedings{Le2015TinyIV,
  title={Tiny {ImageNet} Visual Recognition Challenge},
  author={Ya Le and Xuan S. Yang},
  year={2015}
}
@inproceedings{kwon2021asam,
  title={Asam: Adaptive sharpness-aware minimization for scale-invariant learning of deep neural networks},
  author={Kwon, Jungmin and Kim, Jeongseop and Park, Hyunseo and Choi, In Kwon},
  booktitle={International Conference on Machine Learning},
  pages={5905--5914},
  year={2021},
  organization={PMLR}
}
@inproceedings{mintun2021on,
  title={On Interaction Between Augmentations and Corruptions in Natural Corruption Robustness},
  author={Eric Mintun and Alexander Kirillov and Saining Xie},
  booktitle={Advances in Neural Information Processing Systems},
  editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
  year={2021},
url={https://openreview.net/forum?id=LOHyqjfyra}
}
@inproceedings{foret2021sharpnessaware,
  title={Sharpness-aware Minimization for Efficiently Improving Generalization},
  author={Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=6Tm1mposlrM}
}
@inproceedings{chen2022when,
  title={When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations},
  author={Xiangning Chen and Cho-Jui Hsieh and Boqing Gong},
  booktitle={International Conference on Learning Representations},
  year={2022},
  url={https://openreview.net/forum?id=LtKcMgGOeLt}
}
@inproceedings{keskar2017on,
  title={On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima},
  author={Nitish Shirish Keskar and Dheevatsa Mudigere and Jorge Nocedal and Mikhail Smelyanskiy and Ping Tak Peter Tang},
  booktitle={International Conference on Learning Representations},
  year={2017},
  url={https://openreview.net/forum?id=H1oyRlYgg}
}
@inproceedings{dosovitskiy2021an,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=YicbFdNTTy}
}
@inproceedings{deng2009,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  doi={10.1109/CVPR.2009.5206848}
}

@inproceedings{Jiang2020Fantastic,
  title={Fantastic Generalization Measures and Where to Find Them},
  author={Yiding Jiang and Behnam Neyshabur and Hossein Mobahi and Dilip Krishnan and Samy Bengio},
  booktitle={International Conference on Learning Representations},
  year={2020},
  url={https://openreview.net/forum?id=SJgIPJBFvH}
}
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={IEEE conference on Computer Vision and Pattern Recognition},
  year={2016}
}
@inproceedings{he2016identity,
  title={Identity mappings in deep residual networks},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={European Conference on Computer Vision},
  year={2016},
}
@article{michaelis2019dragon,
  title={Benchmarking Robustness in Object Detection: 
    Autonomous Driving when Winter is Coming},
  author={Michaelis, Claudio and Mitzkus, Benjamin and 
    Geirhos, Robert and Rusak, Evgenia and 
    Bringmann, Oliver and Ecker, Alexander S. and 
    Bethge, Matthias and Brendel, Wieland},
  journal={arXiv preprint arXiv:1907.07484},
  year={2019}
}
@article{beyer2022better,
  title={Better plain vit baselines for imagenet-1k},
  author={Beyer, Lucas and Zhai, Xiaohua and Kolesnikov, Alexander},
  journal={arXiv preprint arXiv:2205.01580},
  year={2022}
}
@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}
@inproceedings{yuan2021tokens,
  title={Tokens-to-token vit: Training vision transformers from scratch on imagenet},
  author={Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Jiang, Zi-Hang and Tay, Francis EH and Feng, Jiashi and Yan, Shuicheng},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={558--567},
  year={2021}
}
@article{chan2022does,
  title={How does frequency bias affect the robustness of neural image classifiers against common corruption and adversarial perturbations?},
  author={Chan, Alvin and Ong, Yew-Soon and Tan, Clement},
  journal={arXiv preprint arXiv:2205.04533},
  year={2022}
}
@inproceedings{wang2023robustness,
  title={Robustness to corruption in pre-trained Bayesian neural networks},
  author={Xi Wang and Laurence Aitchison},
  booktitle={The Eleventh International Conference on Learning Representations },
  year={2023},
  url={https://openreview.net/forum?id=kUI41mY8bHl}
}
@article{geirhos2018generalisation,
  title={Generalisation in humans and deep neural networks},
  author={Geirhos, Robert and Temme, Carlos RM and Rauber, Jonas and Sch{\"u}tt, Heiko H and Bethge, Matthias and Wichmann, Felix A},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@article{hendrycks2019augmix,
  title={Augmix: A simple data processing method to improve robustness and uncertainty},
  author={Hendrycks, Dan and Mu, Norman and Cubuk, Ekin D and Zoph, Barret and Gilmer, Justin and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:1912.02781},
  year={2019}
}
@article{lopes2019improving,
  title={Improving robustness without sacrificing accuracy with patch gaussian augmentation},
  author={Lopes, Raphael Gontijo and Yin, Dong and Poole, Ben and Gilmer, Justin and Cubuk, Ekin D},
  journal={arXiv preprint arXiv:1906.02611},
  year={2019}
}
@article{cubuk2018autoaugment,
  title={Autoaugment: Learning augmentation policies from data},
  author={Cubuk, Ekin D and Zoph, Barret and Mane, Dandelion and Vasudevan, Vijay and Le, Quoc V},
  journal={arXiv preprint arXiv:1805.09501},
  year={2018}
}
@article{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@InProceedings{dusenberry20a,
  title = 	 {Efficient and Scalable {B}ayesian Neural Nets with Rank-1 Factors},
  author =       {Dusenberry, Michael and Jerfel, Ghassen and Wen, Yeming and Ma, Yian and Snoek, Jasper and Heller, Katherine and Lakshminarayanan, Balaji and Tran, Dustin},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {2782--2792},
  year = 	 {2020},
  editor = 	 {III, Hal Daum√© and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/dusenberry20a/dusenberry20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/dusenberry20a.html},
}
@InProceedings{trinh22a,
  title = 	 {Tackling covariate shift with node-based {B}ayesian neural networks},
  author =       {Trinh, Trung and Heinonen, Markus and Acerbi, Luigi and Kaski, Samuel},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {21751--21775},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
}
@article{srivastava14a,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929--1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@InProceedings{pmlr-v28-wan13,
  title = 	 {Regularization of Neural Networks using DropConnect},
  author = 	 {Wan, Li and Zeiler, Matthew and Zhang, Sixin and Le Cun, Yann and Fergus, Rob},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {1058--1066},
  year = 	 {2013},
  editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v28/wan13.pdf},
  url = 	 {https://proceedings.mlr.press/v28/wan13.html},
}
@article{kingma2015variational,
  title={Variational dropout and the local reparameterization trick},
  author={Kingma, Durk P and Salimans, Tim and Welling, Max},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@InProceedings{pmlr-v48-gal16,
  title = 	 {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
  author = 	 {Gal, Yarin and Ghahramani, Zoubin},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1050--1059},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/gal16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/gal16.html},
}
@inproceedings{louizos2017multiplicative,
  title={Multiplicative normalizing flows for variational bayesian neural networks},
  author={Louizos, Christos and Welling, Max},
  booktitle={International Conference on Machine Learning},
  pages={2218--2227},
  year={2017},
  organization={PMLR}
}
@inproceedings{graves2011,
 author = {Graves, Alex},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Shawe-Taylor and R. Zemel and P. Bartlett and F. Pereira and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Practical Variational Inference for Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2011/file/7eb3c8be3d411e8ebfab08eba5f49632-Paper.pdf},
 volume = {24},
 year = {2011}
}
@inproceedings{blundell2015weight,
  title={Weight uncertainty in neural network},
  author={Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  booktitle={International conference on machine learning},
  pages={1613--1622},
  year={2015},
  organization={PMLR}
}
@article{izmailov2021dangers,
  title={Dangers of Bayesian model averaging under covariate shift},
  author={Izmailov, Pavel and Nicholson, Patrick and Lotfi, Sanae and Wilson, Andrew G},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={3309--3322},
  year={2021}
}
@article{rusak2020simple,
  title={A simple way to make neural networks robust against diverse image corruptions},
  author={Rusak, Evgenia and Schott, Lukas and Zimmermann, Roland S and Bitterwolf, Julian and Bringmann, Oliver and Bethge, Matthias and Brendel, Wieland},
  journal={arXiv preprint arXiv:2001.06057},
  year={2020}
}
@article{li2016revisiting,
  title={Revisiting batch normalization for practical domain adaptation},
  author={Li, Yanghao and Wang, Naiyan and Shi, Jianping and Liu, Jiaying and Hou, Xiaodi},
  journal={arXiv preprint arXiv:1603.04779},
  year={2016}
}
@article{nado2020evaluating,
  title={Evaluating prediction-time batch normalization for robustness under covariate shift},
  author={Nado, Zachary and Padhy, Shreyas and Sculley, D and D'Amour, Alexander and Lakshminarayanan, Balaji and Snoek, Jasper},
  journal={arXiv preprint arXiv:2006.10963},
  year={2020}
}

@article{schneider2020improving,
  title={Improving robustness against common corruptions by covariate shift adaptation},
  author={Schneider, Steffen and Rusak, Evgenia and Eck, Luisa and Bringmann, Oliver and Brendel, Wieland and Bethge, Matthias},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={11539--11551},
  year={2020}
}
@inproceedings{benz2021revisiting,
  title={Revisiting batch normalization for improving corruption robustness},
  author={Benz, Philipp and Zhang, Chaoning and Karjauv, Adil and Kweon, In So},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={494--503},
  year={2021}
}
@inproceedings{batchnorm2015,
author = {Ioffe, Sergey and Szegedy, Christian},
title = {Batch normalization: accelerating deep network training by reducing internal covariate shift},
year = {2015},
publisher = {JMLR.org},
abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82\% top-5 test error, exceeding the accuracy of human raters.},
booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
pages = {448‚Äì456},
numpages = {9},
location = {Lille, France},
series = {ICML'15}
}
@article{bohning1988monotonicity,
  title={Monotonicity of quadratic-approximation algorithms},
  author={B{\"o}hning, Dankmar and Lindsay, Bruce G},
  journal={Annals of the Institute of Statistical Mathematics},
  volume={40},
  number={4},
  pages={641--663},
  year={1988},
  publisher={Springer}
}
@InProceedings{imagenet-d,
    author    = {Zhang, Chenshuang and Pan, Fei and Kim, Junmo and Kweon, In So and Mao, Chengzhi},
    title     = {ImageNet-D: Benchmarking Neural Network Robustness on Diffusion Synthetic Object},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2024},
    pages     = {21752-21762}
}
@InProceedings{imagenet-a,
    author    = {Hendrycks, Dan and Zhao, Kevin and Basart, Steven and Steinhardt, Jacob and Song, Dawn},
    title     = {Natural Adversarial Examples},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {15262-15271}
}
@inproceedings{imagenet-sketch,
 author = {Wang, Haohan and Ge, Songwei and Lipton, Zachary and Xing, Eric P},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning Robust Global Representations by Penalizing Local Predictive Power},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/3eefceb8087e964f89c2d59e8a249915-Paper.pdf},
 volume = {32},
 year = {2019}
}
@inproceedings{imagenet-cartoon-drawing,
    title={ImageNet-Cartoon and ImageNet-Drawing: two domain shift datasets for ImageNet},
    author={Tiago Salvador and Adam M Oberman},
    booktitle={ICML 2022 Shift Happens Workshop},
    year={2022},
    url={https://openreview.net/forum?id=YlAUXhjwaQt}
}
@article{fgsm,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}
@article{
zhang2018mixup,
title={mixup: Beyond Empirical Risk Minimization},
author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N. and Lopez-Paz, David},
journal={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=r1Ddp1-Rb},
}
@inproceedings{cubuk2020randaugment,
  title={Randaugment: Practical automated data augmentation with a reduced search space},
  author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={702--703},
  year={2020}
}
