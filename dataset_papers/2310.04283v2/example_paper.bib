@article{pothen1990partitioning,
  title={Partitioning sparse matrices with eigenvectors of graphs},
  author={Pothen, Alex and Simon, Horst D and Liou, Kang-Pu},
  journal={SIAM journal on matrix analysis and applications},
  volume={11},
  number={3},
  pages={430--452},
  year={1990},
  publisher={SIAM}
}
@article{fedus2022switch,
  title={Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
  author={Fedus, William and Zoph, Barret and Shazeer, Noam},
  journal={The Journal of Machine Learning Research},
  volume={23},
  number={1},
  pages={5232--5270},
  year={2022},
  publisher={JMLRORG}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{johnstone2001distribution,
  title={On the distribution of the largest eigenvalue in principal components analysis},
  author={Johnstone, Iain M},
  journal={The Annals of statistics},
  volume={29},
  number={2},
  pages={295--327},
  year={2001},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{bhojanapalli2016dropping,
  title={Dropping convexity for faster semi-definite optimization},
  author={Bhojanapalli, Srinadh and Kyrillidis, Anastasios and Sanghavi, Sujay},
  booktitle={Conference on Learning Theory},
  pages={530--582},
  year={2016},
  organization={PMLR}
}

@article{johnstone2009sparse,
  title={Sparse principal components analysis},
  author={Johnstone, Iain M and Lu, Arthur Yu},
  journal={arXiv preprint arXiv:0901.4392},
  year={2009}
}

@article{mackey2008deflation,
  title={Deflation methods for sparse PCA},
  author={Mackey, Lester},
  journal={Advances in neural information processing systems},
  volume={21},
  year={2008}
}

@article{muntz1913solution,
  title={Direct solution of the {\'e}secular equation and of some transcendent analogous problems},
  author={M{\"u}ntz, Herman and others},
  journal={CR Acad. Sci. Paris},
  volume={156},
  pages={43--46},
  year={1913}
}

@article{weyl1912asymptotische,
  title={Das asymptotische Verteilungsgesetz der Eigenwerte linearer partieller Differentialgleichungen (mit einer Anwendung auf die Theorie der Hohlraumstrahlung)},
  author={Weyl, Hermann},
  journal={Mathematische Annalen},
  volume={71},
  number={4},
  pages={441--479},
  year={1912},
  publisher={Springer}
}

@book{vershynin2018high,
  title={High-dimensional probability: An introduction with applications in data science},
  author={Vershynin, Roman},
  volume={47},
  year={2018},
  publisher={Cambridge university press}
}

@article{johnstone2008multivariate,
  title={Multivariate analysis and Jacobi ensembles: Largest eigenvalue, Tracy--Widom limits and rates of convergence},
  author={Johnstone, Iain M},
  journal={Annals of statistics},
  volume={36},
  number={6},
  pages={2638},
  year={2008},
  publisher={NIH Public Access}
}

@article{anderson1963asymptotic,
  title={Asymptotic theory for principal component analysis},
  author={Anderson, Theodore Wilbur},
  journal={The Annals of Mathematical Statistics},
  volume={34},
  number={1},
  pages={122--148},
  year={1963},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{goujaud2022super,
  title={Super-acceleration with cyclical step-sizes},
  author={Goujaud, Baptiste and Scieur, Damien and Dieuleveut, Aymeric and Taylor, Adrien B and Pedregosa, Fabian},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3028--3065},
  year={2022},
  organization={PMLR}
}

@article{papyan2020traces,
  title={Traces of class/cross-class structure pervade deep learning spectra},
  author={Papyan, Vardan},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={10197--10260},
  year={2020},
  publisher={JMLRORG}
}

@inproceedings{papailiopoulos2014provable,
  title={Provable deterministic leverage score sampling},
  author={Papailiopoulos, Dimitris and Kyrillidis, Anastasios and Boutsidis, Christos},
  booktitle={Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={997--1006},
  year={2014}
}

@article{pearson1901liii,
  title={LIII. On lines and planes of closest fit to systems of points in space},
  author={Pearson, Karl},
  journal={The London, Edinburgh, and Dublin philosophical magazine and journal of science},
  volume={2},
  number={11},
  pages={559--572},
  year={1901},
  publisher={Taylor \& Francis}
}

@article{danisman2014comparison,
  title={A comparison of eigenvalue methods for principal component analysis},
  author={Danisman, Y and Yilmaz, MF and Ozkaya, A and Comlekciler, I},
  journal={Appl. and Comput. Math},
  volume={13},
  pages={316--331},
  year={2014}
}

@article{mises1929praktische,
  title={Praktische Verfahren der Gleichungsaufl{\"o}sung.},
  author={Mises, RV and Pollaczek-Geiringer, Hilda},
  journal={ZAMM-Journal of Applied Mathematics and Mechanics/Zeitschrift f{\"u}r Angewandte Mathematik und Mechanik},
  volume={9},
  number={1},
  pages={58--77},
  year={1929},
  publisher={Wiley Online Library}
}

@inproceedings{jiang2011anomaly,
	Author = {Jiang, Ruoyi and Fei, Hongliang and Huan, Jun},
	Booktitle = {Proceedings of the 17th ACM SIGKDD},
	Organization = {ACM},
	Pages = {886--894},
	Title = {Anomaly localization for network data streams with graph joint sparse PCA},
	Year = {2011}}

@inproceedings{wang2013sparse,
	Author = {Wang, Zhaoran and Han, Fang and Liu, Han},
	Booktitle = {Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics},
	Pages = {48--56},
	Title = {Sparse principal component analysis for high dimensional multivariate time series},
	Year = {2013}}

@book{zhang2006schur,
  title={The {S}chur complement and its applications},
  author={Zhang, Fuzhen},
  volume={4},
  year={2006},
  publisher={Springer Science \& Business Media}
} 


@inproceedings{sriperumbudur2007sparse,
  title={Sparse eigen methods by {DC} programming},
  author={Sriperumbudur, Bharath K and Torres, David A and Lanckriet, Gert RG},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={831--838},
  year={2007}
}

@article{hotelling1933analysis,
  title={Analysis of a complex of statistical variables into principal components.},
  author={Hotelling, Harold},
  journal={Journal of educational psychology},
  volume={24},
  number={6},
  pages={417},
  year={1933},
  publisher={Warwick \& York}
}

@article{white1958computation,
  title={The computation of eigenvalues and eigenvectors of a matrix},
  author={White, Paul A},
  journal={Journal of the Society for Industrial and Applied Mathematics},
  volume={6},
  number={4},
  pages={393--437},
  year={1958},
  publisher={SIAM}
}

@article{saad1988projection,
  title={Projection and deflation method for partial pole assignment in linear state feedback},
  author={Saad, Youcef},
  journal={IEEE Transactions on Automatic Control},
  volume={33},
  number={3},
  pages={290--297},
  year={1988},
  publisher={IEEE}
}

@inproceedings{asteris2015stay,
  title={Stay on path: PCA along graph paths},
  author={Asteris, Megasthenis and Kyrillidis, Anastasios and Dimakis, Alex and Yi, Han-Gyol and Chandrasekaran, Bharath},
  booktitle={International Conference on Machine Learning},
  pages={1728--1736},
  year={2015},
  organization={PMLR}
}

@article{asteris2015sparse_long,
  title={Sparse PCA via Bipartite Matchings},
  author={Asteris, Megasthenis and Papailiopoulos, Dimitris and Kyrillidis, Anastasios and Dimakis, Alexandros G},
  journal={arXiv preprint arXiv:1508.00625},
  year={2015}
}

@inproceedings{sigg:2008,
	Acmid = {1390277},
	Address = {New York, NY, USA},
	Author = {Sigg, Christian D. and Buhmann, Joachim M.},
	Booktitle = {Proceedings of the 25th International Conference on Machine Learning},
	Date-Added = {2015-05-17 05:48:12 +0000},
	Date-Modified = {2015-05-17 05:48:12 +0000},
	Location = {Helsinki, Finland},
	Numpages = {8},
	Optdoi = {10.1145/1390156.1390277},
	Optisbn = {978-1-60558-205-4},
	Opturl = {http://doi.acm.org/10.1145/1390156.1390277},
	Pages = {960--967},
	Publisher = {ACM},
	Series = {ICML '08},
	Title = {Expectation-maximization for Sparse and Non-negative PCA},
	Year = {2008}}



@article{yuan2013truncated,
	Author = {Yuan, Xiao-Tong and Zhang, Tong},
	Date-Added = {2015-04-23 07:37:32 +0000},
	Date-Modified = {2015-04-23 07:37:32 +0000},
	Journal = {The Journal of Machine Learning Research},
	Number = {1},
	Pages = {899--925},
	Publisher = {JMLR. org},
	Title = {Truncated power method for sparse eigenvalue problems},
	Volume = {14},
	Year = {2013}}


@article{zhang2012sparse,
	Author = {Zhang, Y. and d'Aspremont, A. and Ghaoui, L.E.},
	Date-Added = {2015-04-23 07:43:58 +0000},
	Date-Modified = {2015-04-23 07:43:58 +0000},
	Journal = {Handbook on Semidefinite, Conic and Polynomial Optimization},
	Pages = {915--940},
	Publisher = {Springer},
	Title = {Sparse PCA: Convex relaxations, algorithms and applications},
	Year = {2012}}


@article{d2008optimal,
	Author = {d'Aspremont, Alexandre and Bach, Francis and Ghaoui, Laurent El},
	Date-Added = {2015-04-23 07:37:32 +0000},
	Date-Modified = {2015-04-23 07:37:32 +0000},
	Journal = {The Journal of Machine Learning Research},
	Pages = {1269--1294},
	Publisher = {JMLR. org},
	Title = {Optimal solutions for sparse principal component analysis},
	Volume = {9},
	Year = {2008}}


@inproceedings{moghaddam2006generalized,
	Author = {Moghaddam, B. and Weiss, Y. and Avidan, S.},
	Booktitle = {Proceedings of the 23rd international conference on Machine learning},
	Date-Added = {2015-04-23 07:43:58 +0000},
	Date-Modified = {2015-04-23 07:43:58 +0000},
	Organization = {ACM},
	Pages = {641--648},
	Title = {Generalized spectral bounds for sparse LDA},
	Year = {2006}}

@article{moghaddam2006spectral,
	Author = {Moghaddam, B. and Weiss, Y. and Avidan, S.},
	Date-Added = {2015-04-23 07:43:58 +0000},
	Date-Modified = {2015-04-23 07:43:58 +0000},
	Journal = {NIPS},
	Pages = {915},
	Publisher = {MIT; 1998},
	Title = {Spectral bounds for sparse PCA: Exact and greedy algorithms},
	Volume = {18},
	Year = {2006}}
	
@article{journee2010generalized,
	Author = {Journ{\'e}e, M. and Nesterov, Y. and Richt{\'a}rik, P. and Sepulchre, R.},
	Date-Added = {2015-04-23 07:43:58 +0000},
	Date-Modified = {2015-04-23 07:43:58 +0000},
	Journal = {The Journal of Machine Learning Research},
	Pages = {517--553},
	Publisher = {JMLR. org},
	Title = {Generalized power method for sparse principal component analysis},
	Volume = {11},
	Year = {2010}}


@article{jolliffe1995rotation,
	Author = {Jolliffe, I.T.},
	Date-Added = {2015-04-23 07:43:58 +0000},
	Date-Modified = {2015-04-23 07:43:58 +0000},
	Journal = {Journal of Applied Statistics},
	Number = {1},
	Pages = {29--35},
	Publisher = {Taylor \& Francis},
	Title = {Rotation of principal components: choice of normalization constraints},
	Volume = {22},
	Year = {1995}}

@article{jolliffe2003modified,
	Author = {Jolliffe, I.T. and Trendafilov, N.T. and Uddin, M.},
	Date-Added = {2015-04-23 07:43:58 +0000},
	Date-Modified = {2015-04-23 07:43:58 +0000},
	Journal = {Journal of Computational and Graphical Statistics},
	Number = {3},
	Pages = {531--547},
	Publisher = {Taylor \& Francis},
	Title = {A modified principal component technique based on the LASSO},
	Volume = {12},
	Year = {2003}}

@article{kaiser1958varimax,
	Author = {Kaiser, H.F.},
	Date-Added = {2015-04-23 07:43:58 +0000},
	Date-Modified = {2015-04-23 07:43:58 +0000},
	Journal = {Psychometrika},
	Number = {3},
	Pages = {187--200},
	Publisher = {Springer},
	Title = {The varimax criterion for analytic rotation in factor analysis},
	Volume = {23},
	Year = {1958}}


@article{majumdar2009image,
	Author = {Majumdar, A},
	Journal = {Signal, image and video processing},
	Number = {1},
	Pages = {27--34},
	Publisher = {Springer},
	Title = {Image compression by sparse PCA coding in curvelet domain},
	Volume = {3},
	Year = {2009}}

@article{d2007direct,
	Author = {d'Aspremont, A. and El Ghaoui, L. and Jordan, M.I. and Lanckriet, G.R.G.},
	Date-Added = {2015-04-23 07:43:58 +0000},
	Date-Modified = {2015-04-23 07:43:58 +0000},
	Journal = {SIAM review},
	Number = {3},
	Pages = {434--448},
	Publisher = {SIAM},
	Title = {A direct formulation for sparse PCA using semidefinite programming},
	Volume = {49},
	Year = {2007}}

@article{zou2006sparse,
	Author = {Zou, Hui and Hastie, Trevor and Tibshirani, Robert},
	Date-Added = {2015-04-23 07:37:32 +0000},
	Date-Modified = {2015-04-23 07:37:32 +0000},
	Journal = {Journal of computational and graphical statistics},
	Number = {2},
	Pages = {265--286},
	Publisher = {Taylor \& Francis},
	Title = {Sparse principal component analysis},
	Volume = {15},
	Year = {2006}}
	
@book{james2013introduction,
  title={An introduction to statistical learning},
  author={James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  volume={6},
  year={2013},
  publisher={Springer}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT Press}
}

@misc{allenzhu2017efficient,
      title={First Efficient Convergence for Streaming k-PCA: a Global, Gap-Free, and Near-Optimal Rate}, 
      author={Zeyuan Allen-Zhu and Yuanzhi Li},
      year={2017},
      eprint={1607.07837},
      archivePrefix={arXiv},
      primaryClass={math.OC}
}

@inproceedings{
gemp2021eigengame,
title={EigenGame: {\{}PCA{\}} as a Nash Equilibrium},
author={Ian Gemp and Brian McWilliams and Claire Vernade and Thore Graepel},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=NzTU59SYbNq}
}

@misc{mitliagkas2013memory,
      title={Memory Limited, Streaming PCA}, 
      author={Ioannis Mitliagkas and Constantine Caramanis and Prateek Jain},
      year={2013},
      eprint={1307.0032},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{desa2017accelerated,
  title={Accelerated stochastic power iteration},
  author={Xu, Peng and He, Bryan and De Sa, Christopher and Mitliagkas, Ioannis and Re, Chris},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={58--67},
  year={2018},
  organization={PMLR}
}

krasulina1969method, oja1982simplified, oja1985stochastic

@article{oja1985stochastic,
  title={On stochastic approximation of the eigenvectors and eigenvalues of the expectation of a random matrix},
  author={Oja, Erkki and Karhunen, Juha},
  journal={Journal of mathematical analysis and applications},
  volume={106},
  number={1},
  pages={69--84},
  year={1985},
  publisher={Elsevier}
}

@article{oja1982simplified,
  title={Simplified neuron model as a principal component analyzer},
  author={Oja, Erkki},
  journal={Journal of mathematical biology},
  volume={15},
  number={3},
  pages={267--273},
  year={1982},
  publisher={Springer}
}

@article{krasulina1969method,
  title={The method of stochastic approximation for the determination of the least eigenvalue of a symmetrical matrix},
  author={Krasulina, TP},
  journal={USSR Computational Mathematics and Mathematical Physics},
  volume={9},
  number={6},
  pages={189--195},
  year={1969},
  publisher={Elsevier}
}

@article{mahdavi2013mixed,
  title={Mixed optimization for smooth functions},
  author={Mahdavi, Mehrdad and Zhang, Lijun and Jin, Rong},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}


@article{johnson2013accelerating,
  title={Accelerating stochastic gradient descent using predictive variance reduction},
  author={Johnson, Rie and Zhang, Tong},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@inproceedings{de2015global,
  title={Global convergence of stochastic gradient descent for some non-convex matrix problems},
  author={De Sa, Christopher and Re, Christopher and Olukotun, Kunle},
  booktitle={International conference on machine learning},
  pages={2332--2341},
  year={2015},
  organization={PMLR}
}

@article{arora2013stochastic,
  title={Stochastic optimization of {PCA} with capped {MSG}},
  author={Arora, Raman and Cotter, Andy and Srebro, Nati},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  year={2013}
}

@inproceedings{arora2012stochastic,
  title={Stochastic optimization for {PCA} and {PLS}},
  author={Arora, Raman and Cotter, Andrew and Livescu, Karen and Srebro, Nathan},
  booktitle={2012 50th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  pages={861--868},
  year={2012},
  organization={IEEE}
}

@inproceedings{shamir2015stochastic,
  title={A stochastic {PCA} and {SVD} algorithm with an exponential convergence rate},
  author={Shamir, Ohad},
  booktitle={International conference on machine learning},
  pages={144--152},
  year={2015},
  organization={PMLR}
}

@misc{jain2016streaming,
      title={Streaming PCA: Matching Matrix Bernstein and Near-Optimal Finite Sample Guarantees for Oja's Algorithm}, 
      author={Prateek Jain and Chi Jin and Sham M. Kakade and Praneeth Netrapalli and Aaron Sidford},
      year={2016},
      eprint={1602.06929},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{pca1901,
author = { Karl   Pearson   F.R.S. },
title = {LIII. On lines and planes of closest fit to systems of points in space},
journal = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
volume = {2},
number = {11},
pages = {559-572},
year  = {1901},
publisher = {Taylor & Francis},
doi = {10.1080/14786440109462720},

URL = { 
        https://doi.org/10.1080/14786440109462720
    
},
eprint = { 
        https://doi.org/10.1080/14786440109462720
    
}

}

@article{moller2006first,
  title={First-order approximation of {Gram--Schmidt} orthonormalization beats deflation in coupled {PCA} learning rules},
  author={M{\"o}ller, Ralf},
  journal={Neurocomputing},
  volume={69},
  number={13-15},
  pages={1582--1590},
  year={2006},
  publisher={Elsevier}
}

@book{golub2013matrix,
  title={Matrix computations},
  author={Golub, Gene H and Van Loan, Charles F},
  year={2013},
  publisher={JHU press}
}

@article{polyak1987introduction,
  title={Introduction to optimization},
  author={Polyak, Boris T},
  journal={Inc., Publications Division, New York},
  volume={1},
  pages={32},
  year={1987}
}

@book{nesterov2018lectures,
  title={Lectures on convex optimization},
  author={Nesterov, Yurii and others},
  volume={137},
  year={2018},
  publisher={Springer}
}

@inproceedings{garber2017communication,
  title={Communication-efficient algorithms for distributed stochastic principal component analysis},
  author={Garber, Dan and Shamir, Ohad and Srebro, Nathan},
  booktitle={International Conference on Machine Learning},
  pages={1203--1212},
  year={2017},
  organization={PMLR}
}

@inproceedings{boutsidis2016optimal,
  title={Optimal principal component analysis in distributed and streaming models},
  author={Boutsidis, Christos and Woodruff, David P and Zhong, Peilin},
  booktitle={Proceedings of the forty-eighth annual ACM symposium on Theory of Computing},
  pages={236--249},
  year={2016}
}

@article{liang2014improved,
  title={Improved distributed principal component analysis},
  author={Liang, Yingyu and Balcan, Maria-Florina F and Kanchanapally, Vandana and Woodruff, David},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{bhaskara2019distributed,
  title={On distributed averaging for stochastic $k$-{PCA}},
  author={Bhaskara, Aditya and Wijewardena, Pruthuvi Maheshakya},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}


@InProceedings{noboundspca2011,
author="Shi, Weiya
and Zhang, Wenhua",
editor="Zeng, Dehuai",
title="The Accelerated Power Method for Kernel Principal Component Analysis",
booktitle="Applied Informatics and Communication",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="563--570",
isbn="978-3-642-23220-6"
}

@misc{chen2020asymmetry,
      title={Asymmetry Helps: Eigenvalue and Eigenvector Analyses of Asymmetrically Perturbed Low-Rank Matrices}, 
      author={Yuxin Chen and Chen Cheng and Jianqing Fan},
      year={2020},
      eprint={1811.12804},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}

@misc{cheng2021tackling,
      title={Tackling small eigen-gaps: Fine-grained eigenvector estimation and inference under heteroscedastic noise}, 
      author={Chen Cheng and Yuting Wei and Yuxin Chen},
      year={2021},
      eprint={2001.04620},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}

@Book{GoluVanl96,
  Title                    = {Matrix Computations},
  Author                   = {Golub, Gene H. and Van Loan, Charles F.},
  Publisher                = {The Johns Hopkins University Press},
  Year                     = {1996},
  Edition                  = {Third}
}

@article{davis1970rotation,
 ISSN = {00361429},
 URL = {http://www.jstor.org/stable/2949580},
 abstract = {When a Hermitian linear operator is slightly perturbed, by how much can its invariant subspaces change? Given some approximations to a cluster of neighboring eigenvalues and to the corresponding eigenvectors of a real symmetric matrix, and given an estimate for the gap that separates the cluster from all other eigenvalues, how much can the subspace spanned by the eigenvectors differ from the subspace spanned by our approximations? These questions are closely related; both are investigated here. The difference between the two subspaces is characterized in terms of certain angles through which one subspace must be rotated in order most directly to reach the other. These angles unify the treatment of natural geometric, operator-theoretic and error-analytic questions concerning those subspaces. Sharp bounds upon trigonometric functions of these angles are obtained from the gap and from bounds upon either the perturbation (1st question) or a computable residual (2nd question). An example is included.},
 author = {Chandler Davis and W. M. Kahan},
 journal = {SIAM Journal on Numerical Analysis},
 number = {1},
 pages = {1--46},
 publisher = {Society for Industrial and Applied Mathematics},
 title = {The Rotation of Eigenvectors by a Perturbation. III},
 urldate = {2024-01-08},
 volume = {7},
 year = {1970}
}

@misc{eldridge2017unperturbed,
      title={Unperturbed: spectral analysis beyond Davis-Kahan}, 
      author={Justin Eldridge and Mikhail Belkin and Yusu Wang},
      year={2017},
      eprint={1706.06516},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{1950AnIM,
  title={An iterative method for the solution of the eigenvalue problem of linear differential and integral},
  author={Cornelius Lanczos},
  year={1950},
  url={https://api.semanticscholar.org/CorpusID:478182}
}


@InProceedings{xu2018accelerated,
  title = 	 {Accelerated Stochastic Power Iteration},
  author = 	 {Xu, Peng and He, Bryan and De Sa, Christopher and Mitliagkas, Ioannis and Re, Chris},
  booktitle = 	 {Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics},
  pages = 	 {58--67},
  year = 	 {2018},
  editor = 	 {Storkey, Amos and Perez-Cruz, Fernando},
  volume = 	 {84},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--11 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v84/xu18a/xu18a.pdf},
  url = 	 {https://proceedings.mlr.press/v84/xu18a.html},
  abstract = 	 {Principal component analysis (PCA) is one of the most powerful tools for analyzing matrices in machine learning. In this paper, we study methods to accelerate power iteration in the stochastic setting by adding a momentum term. While in the deterministic setting, power iteration with momentum has optimal iteration complexity, we show that naively adding momentum to a stochastic method does not always result in acceleration. We perform a novel, tight variance analysis that reveals a "breaking-point variance" beyond which this acceleration does not occur. Combining this insight with modern variance reduction techniques yields a simple version of power iteration with momentum that achieves the optimal iteration complexities in both the online and offline setting. Our methods are embarrassingly parallel and can produce wall-clock-time speedups. Our approach is very general and applies to many non-convex optimization problems that can now be accelerated using the same technique. }
}

@article{Hubert1985ComparingP,
  title={Comparing partitions},
  author={Lawrence J. Hubert and Phipps Arabie},
  journal={Journal of Classification},
  year={1985},
  volume={2},
  pages={193-218},
  url={https://api.semanticscholar.org/CorpusID:189915041}
}

@article{deng2012mnist,
  title={The mnist database of handwritten digit images for machine learning research},
  author={Deng, Li},
  journal={IEEE Signal Processing Magazine},
  volume={29},
  number={6},
  pages={141--142},
  year={2012},
  publisher={IEEE}
}

@ARTICLE{belkin2003eigenmap,
  author={Belkin, Mikhail and Niyogi, Partha},
  journal={Neural Computation}, 
  title={Laplacian Eigenmaps for Dimensionality Reduction and Data Representation}, 
  year={2003},
  volume={15},
  number={6},
  pages={1373-1396},
  keywords={},
  doi={10.1162/089976603321780317}}


@InProceedings{wang2020nearly,
  title = 	 {A Nearly-Linear Time Algorithm for Exact Community Recovery in Stochastic Block Model},
  author =       {Wang, Peng and Zhou, Zirui and So, Anthony Man-Cho},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {10126--10135},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/wang20ac/wang20ac.pdf},
  url = 	 {https://proceedings.mlr.press/v119/wang20ac.html},
  abstract = 	 {Learning community structures in graphs that are randomly generated by stochastic block models (SBMs) has received much attention lately. In this paper, we focus on the problem of exactly recovering the communities in a binary symmetric SBM, where a graph of $n$ vertices is partitioned into two equal-sized communities and the vertices are connected with probability $p = \alpha\log(n)/n$ within communities and $q = \beta\log(n)/n$ across communities for some $\alpha&gt;\beta&gt;0$. We propose a two-stage iterative algorithm for solving this problem, which employs the power method with a random starting point in the first-stage and turns to a generalized power method that can identify the communities in a finite number of iterations in the second-stage. It is shown that for any fixed $\alpha$ and $\beta$ such that $\sqrt{\alpha} - \sqrt{\beta} &gt; \sqrt{2}$, which is known to be the information-theoretical limit for exact recovery, the proposed algorithm exactly identifies the underlying communities in $\tilde{O}(n)$ running time with probability tending to one as $n\rightarrow\infty$. We also present numerical results of the proposed algorithm to support and complement our theoretical development.}
}

@article{kuczynski1992estimating,
  title={Estimating the largest eigenvalue by the power and Lanczos algorithms with a random start},
  author={Kuczynski, Jerzy and Wo{\'z}niakowski, Henryk},
  journal={SIAM Journal on Matrix Analysis and Applications},
  volume={13},
  number={4},
  pages={1094--1122},
  year={1992},
  publisher={SIAM}
}

@misc{coulaud2013deflation,
      title={Deflation and augmentation techniques in Krylov subspace methods for the solution of linear systems}, 
      author={Olivier Coulaud and Luc Giraud and Pierre Ramet and Xavier Vasseur},
      year={2013},
      eprint={1303.5692},
      archivePrefix={arXiv},
      primaryClass={math.NA}
}

@article{Fawzi2022,
  author = {Fawzi, Alhussein and Balog, Matej and Huang, Angela and et al.},
  title = {Discovering faster matrix multiplication algorithms with reinforcement learning},
  journal = {Nature},
  volume = {610},
  pages = {47–53},
  year = {2022},
  doi = {10.1038/s41586-022-05172-4},
  url = {https://doi.org/10.1038/s41586-022-05172-4}
}

