\begin{thebibliography}{}

\bibitem[Ahn et~al., 2022]{ahn2022can}
Ahn, M., Brohan, A., Brown, N., Chebotar, Y., Cortes, O., David, B., Finn, C., Fu, C., Gopalakrishnan, K., Hausman, K., et~al. (2022).
\newblock Do as i can, not as i say: Grounding language in robotic affordances.
\newblock {\em ArXiv preprint}, abs/2204.01691.

\bibitem[Anthropic, 2023]{claude}
Anthropic (2023).
\newblock Introducing claude.

\bibitem[Chase, 2022]{Chase_LangChain_2022}
Chase, H. (2022).
\newblock Langchain.

\bibitem[Chevalier{-}Boisvert et~al., 2019]{chevalier2018babyai}
Chevalier{-}Boisvert, M., Bahdanau, D., Lahlou, S., Willems, L., Saharia, C., Nguyen, T.~H., and Bengio, Y. (2019).
\newblock Babyai: {A} platform to study the sample efficiency of grounded language learning.
\newblock In {\em 7th International Conference on Learning Representations, {ICLR} 2019, New Orleans, LA, USA, May 6-9, 2019}. OpenReview.net.

\bibitem[Chiang et~al., 2023]{chiang2023vicuna}
Chiang, W.-L., Li, Z., Lin, Z., Sheng, Y., Wu, Z., Zhang, H., Zheng, L., Zhuang, S., Zhuang, Y., Gonzalez, J.~E., et~al. (2023).
\newblock Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality.
\newblock {\em See https://vicuna. lmsys. org (accessed 14 April 2023)}.

\bibitem[Cobbe et~al., 2021]{cobbe2021gsm8k}
Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., and Schulman, J. (2021).
\newblock Training verifiers to solve math word problems.
\newblock {\em arXiv preprint arXiv:2110.14168}.

\bibitem[DeepSeek-AI et~al., 2024]{deepseekai2024deepseek}
DeepSeek-AI, :, Bi, X., Chen, D., Chen, G., Chen, S., Dai, D., Deng, C., Ding, H., Dong, K., Du, Q., Fu, Z., Gao, H., Gao, K., Gao, W., Ge, R., Guan, K., Guo, D., Guo, J., Hao, G., Hao, Z., He, Y., Hu, W., Huang, P., Li, E., Li, G., Li, J., Li, Y., Li, Y.~K., Liang, W., Lin, F., Liu, A.~X., Liu, B., Liu, W., Liu, X., Liu, X., Liu, Y., Lu, H., Lu, S., Luo, F., Ma, S., Nie, X., Pei, T., Piao, Y., Qiu, J., Qu, H., Ren, T., Ren, Z., Ruan, C., Sha, Z., Shao, Z., Song, J., Su, X., Sun, J., Sun, Y., Tang, M., Wang, B., Wang, P., Wang, S., Wang, Y., Wang, Y., Wu, T., Wu, Y., Xie, X., Xie, Z., Xie, Z., Xiong, Y., Xu, H., Xu, R.~X., Xu, Y., Yang, D., You, Y., Yu, S., Yu, X., Zhang, B., Zhang, H., Zhang, L., Zhang, L., Zhang, M., Zhang, M., Zhang, W., Zhang, Y., Zhao, C., Zhao, Y., Zhou, S., Zhou, S., Zhu, Q., and Zou, Y. (2024).
\newblock Deep{S}eek {LLM}: Scaling open-source language models with longtermism.

\bibitem[Deng et~al., 2023]{deng2023mind2web}
Deng, X., Gu, Y., Zheng, B., Chen, S., Stevens, S., Wang, B., Sun, H., and Su, Y. (2023).
\newblock Mind2web: Towards a generalist agent for the web.
\newblock {\em ArXiv preprint}, abs/2306.06070.

\bibitem[Driess et~al., 2023]{driess2023palm}
Driess, D., Xia, F., Sajjadi, M.~S., Lynch, C., Chowdhery, A., Ichter, B., Wahid, A., Tompson, J., Vuong, Q., Yu, T., et~al. (2023).
\newblock Palm-e: An embodied multimodal language model.
\newblock {\em ArXiv preprint}, abs/2303.03378.

\bibitem[Dziri et~al., 2023]{dziri2023faith}
Dziri, N., Lu, X., Sclar, M., Li, X.~L., Jian, L., Lin, B.~Y., West, P., Bhagavatula, C., Bras, R.~L., Hwang, J.~D., et~al. (2023).
\newblock Faith and fate: Limits of transformers on compositionality.
\newblock {\em ArXiv preprint}, abs/2305.18654.

\bibitem[Gu et~al., 2022]{gu2022don}
Gu, Y., Deng, X., and Su, Y. (2022).
\newblock Don't generate, discriminate: A proposal for grounding language models to real-world environments.
\newblock {\em ArXiv preprint}, abs/2212.09736.

\bibitem[Hausknecht et~al., 2020]{hausknecht2020interactive}
Hausknecht, M.~J., Ammanabrolu, P., C{\^{o}}t{\'{e}}, M., and Yuan, X. (2020).
\newblock Interactive fiction games: {A} colossal adventure.
\newblock In {\em The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI} 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA, February 7-12, 2020}, pages 7903--7910. {AAAI} Press.

\bibitem[Hong et~al., 2023]{hong2023metagpt}
Hong, S., Zheng, X., Chen, J., Cheng, Y., Wang, J., Zhang, C., Wang, Z., Yau, S. K.~S., Lin, Z., Zhou, L., et~al. (2023).
\newblock Metagpt: Meta programming for multi-agent collaborative framework.
\newblock {\em arXiv preprint arXiv:2308.00352}.

\bibitem[Jiang et~al., 2023]{jiang2023mistral}
Jiang, A.~Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D.~S., Casas, D. d.~l., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., et~al. (2023).
\newblock Mistral 7b.
\newblock {\em ArXiv preprint}, abs/2310.06825.

\bibitem[Kaplan et~al., 2020]{kaplan2020scaling}
Kaplan, J., McCandlish, S., Henighan, T., Brown, T.~B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J., and Amodei, D. (2020).
\newblock Scaling laws for neural language models.
\newblock {\em arXiv preprint arXiv:2001.08361}.

\bibitem[Kinniment et~al., 2023]{kinniment2023evaluating}
Kinniment, M., Sato, L. J.~K., Du, H., Goodrich, B., Hasin, M., Chan, L., Miles, L.~H., Lin, T.~R., Wijk, H., Burget, J., et~al. (2023).
\newblock Evaluating language-model agents on realistic autonomous tasks.
\newblock {\em ArXiv preprint}, abs/2312.11671.

\bibitem[Kwon et~al., 2023]{kwon2023efficient}
Kwon, W., Li, Z., Zhuang, S., Sheng, Y., Zheng, L., Yu, C.~H., Gonzalez, J., Zhang, H., and Stoica, I. (2023).
\newblock Efficient memory management for large language model serving with pagedattention.
\newblock In {\em Proceedings of the 29th Symposium on Operating Systems Principles}, pages 611--626.

\bibitem[Lanham et~al., 2023]{lanham2023measuring}
Lanham, T., Chen, A., Radhakrishnan, A., Steiner, B., Denison, C., Hernandez, D., Li, D., Durmus, E., Hubinger, E., Kernion, J., et~al. (2023).
\newblock Measuring faithfulness in chain-of-thought reasoning.
\newblock {\em ArXiv preprint}, abs/2307.13702.

\bibitem[LeCun, 2022]{lecun2022path}
LeCun, Y. (2022).
\newblock A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27.
\newblock {\em Open Review}, 62.

\bibitem[Li et~al., 2023]{li2023api}
Li, M., Song, F., Yu, B., Yu, H., Li, Z., Huang, F., and Li, Y. (2023).
\newblock Api-bank: A benchmark for tool-augmented llms.
\newblock {\em ArXiv preprint}, abs/2304.08244.

\bibitem[Lin and Chen, 2023]{lin2023llm}
Lin, Y.-T. and Chen, Y.-N. (2023).
\newblock Llm-eval: Unified multi-dimensional automatic evaluation for open-domain conversations with large language models.
\newblock {\em ArXiv preprint}, abs/2305.13711.

\bibitem[Liu et~al., 2023a]{liu2023agentbench}
Liu, X., Yu, H., Zhang, H., Xu, Y., Lei, X., Lai, H., Gu, Y., Ding, H., Men, K., Yang, K., et~al. (2023a).
\newblock Agentbench: Evaluating llms as agents.
\newblock {\em ArXiv preprint}, abs/2308.03688.

\bibitem[Liu et~al., 2023b]{liu2023bolaa}
Liu, Z., Yao, W., Zhang, J., Xue, L., Heinecke, S., Murthy, R., Feng, Y., Chen, Z., Niebles, J.~C., Arpit, D., et~al. (2023b).
\newblock Bolaa: Benchmarking and orchestrating llm-augmented autonomous agents.
\newblock {\em ArXiv preprint}, abs/2308.05960.

\bibitem[Madaan et~al., 2023]{madaan2023self}
Madaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao, L., Wiegreffe, S., Alon, U., Dziri, N., Prabhumoye, S., Yang, Y., et~al. (2023).
\newblock Self-refine: Iterative refinement with self-feedback.
\newblock {\em ArXiv preprint}, abs/2303.17651.

\bibitem[Mialon et~al., 2023]{mialon2023gaia}
Mialon, G., Fourrier, C., Swift, C., Wolf, T., LeCun, Y., and Scialom, T. (2023).
\newblock Gaia: a benchmark for general ai assistants.
\newblock {\em ArXiv preprint}, abs/2311.12983.

\bibitem[OpenAI, 2022]{gpt-3.5}
OpenAI (2022).
\newblock Introducing chatgpt.

\bibitem[OpenAI, 2023]{openai2023gpt}
OpenAI (2023).
\newblock Gpt-4 technical report.
\newblock {\em arXiv}, pages 2303--08774.

\bibitem[Ouyang et~al., 2022]{ouyang2022training}
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et~al. (2022).
\newblock Training language models to follow instructions with human feedback.
\newblock {\em Advances in Neural Information Processing Systems}, 35:27730--27744.

\bibitem[Pourchot and Sigaud, 2019]{pourchot2018cem}
Pourchot, A. and Sigaud, O. (2019).
\newblock {CEM-RL:} combining evolutionary and gradient-based methods for policy search.
\newblock In {\em 7th International Conference on Learning Representations, {ICLR} 2019, New Orleans, LA, USA, May 6-9, 2019}. OpenReview.net.

\bibitem[Puterman, 1990]{puterman1990markov}
Puterman, M.~L. (1990).
\newblock Markov decision processes.
\newblock {\em Handbooks in operations research and management science}, 2:331--434.

\bibitem[Qin et~al., 2023a]{qin2023tool}
Qin, Y., Hu, S., Lin, Y., Chen, W., Ding, N., Cui, G., Zeng, Z., Huang, Y., Xiao, C., Han, C., et~al. (2023a).
\newblock Tool learning with foundation models.
\newblock {\em ArXiv preprint}, abs/2304.08354.

\bibitem[Qin et~al., 2023b]{qin2023toolllm}
Qin, Y., Liang, S., Ye, Y., Zhu, K., Yan, L., Lu, Y., Lin, Y., Cong, X., Tang, X., Qian, B., et~al. (2023b).
\newblock Toolllm: Facilitating large language models to master 16000+ real-world apis.
\newblock {\em ArXiv preprint}, abs/2307.16789.

\bibitem[Reed et~al., 2022]{reed2022generalist}
Reed, S., Zolna, K., Parisotto, E., Colmenarejo, S.~G., Novikov, A., Barth-Maron, G., Gimenez, M., Sulsky, Y., Kay, J., Springenberg, J.~T., et~al. (2022).
\newblock A generalist agent.
\newblock {\em ArXiv preprint}, abs/2205.06175.

\bibitem[Richards, 2023]{autogpt}
Richards, T.~B. (2023).
\newblock Significant-gravitas/autogpt: An experimental open-source attempt to make gpt-4 fully autonomous.

\bibitem[Roziere et~al., 2023]{roziere2023code}
Roziere, B., Gehring, J., Gloeckle, F., Sootla, S., Gat, I., Tan, X.~E., Adi, Y., Liu, J., Remez, T., Rapin, J., et~al. (2023).
\newblock Code llama: Open foundation models for code.
\newblock {\em ArXiv preprint}, abs/2308.12950.

\bibitem[Ruan et~al., 2024]{ruan2024observational}
Ruan, Y., Maddison, C.~J., and Hashimoto, T. (2024).
\newblock Observational scaling laws and the predictability of language model performance.
\newblock {\em arXiv preprint arXiv:2405.10938}.

\bibitem[Russell and Norvig, 2005]{russell2005ai}
Russell, S. and Norvig, P. (2005).
\newblock Ai a modern approach.
\newblock {\em Learning}, 2(3):4.

\bibitem[Shi et~al., 2017a]{Shi2017WorldOB}
Shi, T., Karpathy, A., Fan, L., Hernandez, J., and Liang, P. (2017a).
\newblock World of bits: An open-domain platform for web-based agents.
\newblock In Precup, D. and Teh, Y.~W., editors, {\em Proceedings of the 34th International Conference on Machine Learning, {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017}, volume~70 of {\em Proceedings of Machine Learning Research}, pages 3135--3144. {PMLR}.

\bibitem[Shi et~al., 2017b]{shi2017world}
Shi, T., Karpathy, A., Fan, L., Hernandez, J., and Liang, P. (2017b).
\newblock World of bits: An open-domain platform for web-based agents.
\newblock In Precup, D. and Teh, Y.~W., editors, {\em Proceedings of the 34th International Conference on Machine Learning, {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017}, volume~70 of {\em Proceedings of Machine Learning Research}, pages 3135--3144. {PMLR}.

\bibitem[Shinn et~al., 2023]{shinn2023reflexion}
Shinn, N., Cassano, F., Gopinath, A., Narasimhan, K.~R., and Yao, S. (2023).
\newblock Reflexion: Language agents with verbal reinforcement learning.
\newblock In {\em Thirty-seventh Conference on Neural Information Processing Systems}.

\bibitem[Shridhar et~al., 2021]{shridhar2020alfworld}
Shridhar, M., Yuan, X., C{\^{o}}t{\'{e}}, M., Bisk, Y., Trischler, A., and Hausknecht, M.~J. (2021).
\newblock Alfworld: Aligning text and embodied environments for interactive learning.
\newblock In {\em 9th International Conference on Learning Representations, {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021}. OpenReview.net.

\bibitem[Silver and Chitnis, 2020]{silver2020pddlgym}
Silver, T. and Chitnis, R. (2020).
\newblock Pddlgym: Gym environments from pddl problems.
\newblock {\em ArXiv preprint}, abs/2002.06432.

\bibitem[Song et~al., 2023]{song2023llm}
Song, C.~H., Wu, J., Washington, C., Sadler, B.~M., Chao, W.-L., and Su, Y. (2023).
\newblock Llm-planner: Few-shot grounded planning for embodied agents with large language models.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 2998--3009.

\bibitem[Touvron et~al., 2023]{touvron2023llama}
Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozi{\`e}re, B., Goyal, N., Hambro, E., Azhar, F., et~al. (2023).
\newblock Llama: Open and efficient foundation language models.
\newblock {\em ArXiv preprint}, abs/2302.13971.

\bibitem[Vallati et~al., 2015]{vallati20152014}
Vallati, M., Chrpa, L., Grze{\'s}, M., McCluskey, T.~L., Roberts, M., Sanner, S., et~al. (2015).
\newblock The 2014 international planning competition: Progress and trends.
\newblock {\em Ai Magazine}, 36(3):90--98.

\bibitem[Wang et~al., 2023a]{wang2023voyager}
Wang, G., Xie, Y., Jiang, Y., Mandlekar, A., Xiao, C., Zhu, Y., Fan, L., and Anandkumar, A. (2023a).
\newblock Voyager: An open-ended embodied agent with large language models.
\newblock {\em ArXiv preprint}, abs/2305.16291.

\bibitem[Wang et~al., 2022]{wang2022scienceworld}
Wang, R., Jansen, P., C{\^o}t{\'e}, M.-A., and Ammanabrolu, P. (2022).
\newblock {S}cience{W}orld: Is your agent smarter than a 5th grader?
\newblock In {\em Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing}, pages 11279--11298, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

\bibitem[Wang et~al., 2023b]{wang2023mint}
Wang, X., Wang, Z., Liu, J., Chen, Y., Yuan, L., Peng, H., and Ji, H. (2023b).
\newblock Mint: Evaluating llms in multi-turn interaction with tools and language feedback.
\newblock {\em ArXiv preprint}, abs/2309.10691.

\bibitem[Wei et~al., 2022]{wei2022emergent}
Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D., et~al. (2022).
\newblock Emergent abilities of large language models.
\newblock {\em ArXiv preprint}, abs/2206.07682.

\bibitem[Wu et~al., 2023]{wu2023smartplay}
Wu, Y., Tang, X., Mitchell, T.~M., and Li, Y. (2023).
\newblock Smartplay: A benchmark for llms as intelligent agents.
\newblock {\em ArXiv preprint}, abs/2310.01557.

\bibitem[Wu et~al., 2024]{wu2024copilot}
Wu, Z., Han, C., Ding, Z., Weng, Z., Liu, Z., Yao, S., Yu, T., and Kong, L. (2024).
\newblock Os-copilot: Towards generalist computer agents with self-improvement.
\newblock {\em arXiv preprint arXiv:2402.07456}.

\bibitem[Xie et~al., 2023]{xie2023openagents}
Xie, T., Zhou, F., Cheng, Z., Shi, P., Weng, L., Liu, Y., Hua, T.~J., Zhao, J., Liu, Q., Liu, C., et~al. (2023).
\newblock Openagents: An open platform for language agents in the wild.
\newblock {\em ArXiv preprint}, abs/2310.10634.

\bibitem[Xu et~al., 2023a]{xu2023gentopia}
Xu, B., Liu, X., Shen, H., Han, Z., Li, Y., Yue, M., Peng, Z., Liu, Y., Yao, Z., and Xu, D. (2023a).
\newblock Gentopia: A collaborative platform for tool-augmented llms.
\newblock {\em arXiv preprint arXiv:2308.04030}.

\bibitem[Xu et~al., 2023b]{xu2023tool}
Xu, Q., Hong, F., Li, B., Hu, C., Chen, Z., and Zhang, J. (2023b).
\newblock On the tool manipulation capability of open-source large language models.
\newblock {\em ArXiv preprint}, abs/2305.16504.

\bibitem[Xu et~al., 2023c]{xu2023lemur}
Xu, Y., Su, H., Xing, C., Mi, B., Liu, Q., Shi, W., Hui, B., Zhou, F., Liu, Y., Xie, T., et~al. (2023c).
\newblock Lemur: Harmonizing natural language and code for language agents.
\newblock {\em ArXiv preprint}, abs/2310.06830.

\bibitem[Yang et~al., 2023]{yang2023appagent}
Yang, Z., Liu, J., Han, Y., Chen, X., Huang, Z., Fu, B., and Yu, G. (2023).
\newblock Appagent: Multimodal agents as smartphone users.
\newblock {\em ArXiv preprint}, abs/2312.13771.

\bibitem[Yao et~al., 2022]{yao2022webshop}
Yao, S., Chen, H., Yang, J., and Narasimhan, K. (2022).
\newblock Webshop: Towards scalable real-world web interaction with grounded language agents.
\newblock {\em Advances in Neural Information Processing Systems}, 35:20744--20757.

\bibitem[Yao et~al., 2023]{yao2022react}
Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K.~R., and Cao, Y. (2023).
\newblock Re{A}ct: Synergizing reasoning and acting in language models.
\newblock In {\em The Eleventh International Conference on Learning Representations}.

\bibitem[Ye et~al., 2024]{ye2024tooleyes}
Ye, J., Li, G., Gao, S., Huang, C., Wu, Y., Li, S., Fan, X., Dou, S., Zhang, Q., Gui, T., et~al. (2024).
\newblock Tooleyes: Fine-grained evaluation for tool learning capabilities of large language models in real-world scenarios.
\newblock {\em ArXiv preprint}, abs/2401.00741.

\bibitem[Zheng et~al., 2024]{Zheng2024GPT4VisionIA}
Zheng, B., Gou, B., Kil, J., Sun, H., and Su, Y. (2024).
\newblock Gpt-4v(ision) is a generalist web agent, if grounded.
\newblock {\em ArXiv preprint}, abs/2401.01614.

\bibitem[Zhou et~al., 2023]{zhou2023webarena}
Zhou, S., Xu, F.~F., Zhu, H., Zhou, X., Lo, R., Sridhar, A., Cheng, X., Bisk, Y., Fried, D., Alon, U., et~al. (2023).
\newblock Webarena: A realistic web environment for building autonomous agents.
\newblock {\em ArXiv preprint}, abs/2307.13854.

\end{thebibliography}
