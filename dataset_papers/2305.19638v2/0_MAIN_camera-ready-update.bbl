\begin{thebibliography}{10}

\bibitem{ronneberger2015u}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In {\em International Conference on Medical Image Computing and
  Computer-assisted Intervention}, pages 234--241. Springer, 2015.

\bibitem{siddique2021u}
Nahian Siddique, Sidike Paheding, Colin~P Elkin, and Vijay Devabhaktuni.
\newblock U-net and its variants for medical image segmentation: A review of
  theory and applications.
\newblock {\em Ieee Access}, 9:82031--82057, 2021.

\bibitem{zhou2018unet++}
Zongwei Zhou, Md~Mahfuzur Rahman~Siddiquee, Nima Tajbakhsh, and Jianming Liang.
\newblock Unet++: A nested u-net architecture for medical image segmentation.
\newblock In {\em Deep Learning in Medical Image Analysis and Multimodal
  Learning for Clinical Decision Support: 4th International Workshop, DLMIA
  2018, and 8th International Workshop, ML-CDS 2018, Held in Conjunction with
  MICCAI 2018, Granada, Spain, September 20, 2018, Proceedings 4}, pages 3--11.
  Springer, 2018.

\bibitem{oktay2018attention}
Ozan Oktay, Jo~Schlemper, Loic~Le Folgoc, Matthew Lee, Mattias Heinrich,
  Kazunari Misawa, Kensaku Mori, Steven McDonagh, Nils~Y Hammerla, Bernhard
  Kainz, et~al.
\newblock Attention u-net: Learning where to look for the pancreas.
\newblock {\em arXiv preprint arXiv:1804.03999}, 2018.

\bibitem{landgraf2020comparing}
Zoe Landgraf, Fabian Falck, Michael Bloesch, Stefan Leutenegger, and Andrew~J
  Davison.
\newblock Comparing view-based and map-based semantic labelling in real-time
  slam.
\newblock In {\em 2020 IEEE International Conference on Robotics and Automation
  (ICRA)}, pages 6884--6890. IEEE, 2020.

\bibitem{pdearena}
Jayesh~K Gupta and Johannes Brandstetter.
\newblock Towards multi-spatiotemporal-scale generalized pde modeling.
\newblock {\em arXiv preprint arXiv:2209.15616}, 2022.

\bibitem{takamoto2022pdebench}
Makoto Takamoto, Timothy Praditia, Raphael Leiteritz, Daniel MacKinlay,
  Francesco Alesiani, Dirk Pfl{\"u}ger, and Mathias Niepert.
\newblock Pdebench: An extensive benchmark for scientific machine learning.
\newblock {\em Advances in Neural Information Processing Systems},
  35:1596--1611, 2022.

\bibitem{DDPM}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock {\em Advances in Neural Information Processing Systems},
  33:6840--6851, 2020.

\bibitem{DDIM}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{ImprovedDDPM}
Alex Nichol and Prafulla Dhariwal.
\newblock Improved denoising diffusion probabilistic models.
\newblock {\em arXiv preprint arXiv:2102.09672}, 2021.

\bibitem{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10684--10695, 2022.

\bibitem{de2021diffusion}
Valentin De~Bortoli, James Thornton, Jeremy Heng, and Arnaud Doucet.
\newblock Diffusion schr{\"o}dinger bridge with applications to score-based
  generative modeling.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~34, 2021.

\bibitem{amari1998natural}
Shun-Ichi Amari.
\newblock Natural gradient works efficiently in learning.
\newblock {\em Neural computation}, 10(2):251--276, 1998.

\bibitem{amari2020does}
Shun-ichi Amari, Jimmy Ba, Roger Grosse, Xuechen Li, Atsushi Nitanda, Taiji
  Suzuki, Denny Wu, and Ji~Xu.
\newblock When does preconditioning help or hurt generalization?
\newblock {\em arXiv preprint arXiv:2006.10732}, 2020.

\bibitem{resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{de2022riemannian}
Valentin De~Bortoli, Emile Mathieu, Michael Hutchinson, James Thornton,
  Yee~Whye Teh, and Arnaud Doucet.
\newblock Riemannian score-based generative modeling.
\newblock {\em arXiv preprint arXiv:2202.02763}, 2022.

\bibitem{zhao2021spherical}
Fenqiang Zhao, Zhengwang Wu, Li~Wang, Weili Lin, John~H Gilmore, Shunren Xia,
  Dinggang Shen, and Gang Li.
\newblock Spherical deformable u-net: Application to cortical surface
  parcellation and development prediction.
\newblock {\em IEEE transactions on medical imaging}, 40(4):1217--1228, 2021.

\bibitem{gao2019graph}
Hongyang Gao and Shuiwang Ji.
\newblock Graph u-nets.
\newblock In {\em international conference on machine learning}, pages
  2083--2092. PMLR, 2019.

\bibitem{dupont2021generative}
Emilien Dupont, Yee~Whye Teh, and Arnaud Doucet.
\newblock Generative models as distributions of functions.
\newblock {\em arXiv preprint arXiv:2102.04776}, 2021.

\bibitem{williamsFalck2022a}
Fabian Falck, Christopher Williams, Dominic Danks, George Deligiannidis,
  Christopher Yau, Chris~C Holmes, Arnaud Doucet, and Matthew Willetts.
\newblock A multi-resolution framework for u-nets with applications to
  hierarchical vaes.
\newblock volume~35, pages 15529--15544, 2022.

\bibitem{hornik1989multilayer}
Kurt Hornik, Maxwell Stinchcombe, and Halbert White.
\newblock Multilayer feedforward networks are universal approximators.
\newblock {\em Neural networks}, 2(5):359--366, 1989.

\bibitem{chen2018neural}
Ricky~TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David~K Duvenaud.
\newblock Neural ordinary differential equations.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{haar1909theorie}
Alfred Haar.
\newblock {\em Zur theorie der orthogonalen funktionensysteme}.
\newblock Georg-August-Universitat, Gottingen., 1909.

\bibitem{framelets2018}
Jong~Chul Ye, Yoseob Han, and Eunju Cha.
\newblock Deep convolutional framelets: A general deep learning framework for
  inverse problems.
\newblock {\em SIAM Journal on Imaging Sciences}, 11(2):991--1048, 2018.

\bibitem{ramzi2023wavelets}
Z.~Ramzi, K.~Michalewicz, JL. Starck, et~al.
\newblock Wavelets in the deep learning era.
\newblock {\em J Math Imaging Vis}, 65:240--251, 2023.

\bibitem{liu2018multi}
P.~Liu, H.~Zhang, K.~Zhang, L.~Lin, and W.~Zuo.
\newblock Multi-level wavelet-cnn for image restoration.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition workshops}, pages 773--782, 2018.

\bibitem{reed1973triangular}
William~H Reed and Thomas~R Hill.
\newblock Triangular mesh methods for the neutron transport equation.
\newblock Technical report, Los Alamos Scientific Lab., N. Mex.(USA), 1973.

\bibitem{talukder2010haar}
Kamrul~Hasan Talukder and Koichi Harada.
\newblock Haar wavelet based approach for image compression and quality
  assessment of compressed image.
\newblock {\em arXiv preprint arXiv:1010.4084}, 2010.

\bibitem{mallat1999wavelet}
St{\'e}phane Mallat.
\newblock {\em A Wavelet Tour of Signal Processing}.
\newblock Elsevier, 1999.

\bibitem{child2020very}
Rewon Child.
\newblock Very deep vaes generalize autoregressive models and can outperform
  them on images.
\newblock {\em arXiv preprint arXiv:2011.10650}, 2020.

\bibitem{agmon2010lectures}
Shmuel Agmon.
\newblock {\em Lectures on elliptic boundary value problems}, volume 369.
\newblock American Mathematical Soc., 2010.

\bibitem{brenner2008mathematical}
Susanne~C Brenner, L~Ridgway Scott, and L~Ridgway Scott.
\newblock {\em The mathematical theory of finite element methods}, volume~3.
\newblock Springer, 2008.

\bibitem{cockburn2000development}
Bernardo Cockburn, George~E Karniadakis, and Chi-Wang Shu.
\newblock {\em The development of discontinuous Galerkin methods}.
\newblock Springer, 2000.

\bibitem{boots2009spatial}
Barry Boots, Kokichi Sugihara, Sung~Nok Chiu, and Atsuyuki Okabe.
\newblock Spatial tessellations: concepts and applications of voronoi diagrams.
\newblock 2009.

\bibitem{delaunay1934sphere}
Boris Delaunay.
\newblock Sur la sph\`ere vide.
\newblock {\em Izv. Akad. Nauk SSSR, Otdelenie Matematicheskii i Estestvennyka
  Nauk}, 7(793-800):1--2, 1934.

\bibitem{lee1980two}
Der-Tsai Lee and Bruce~J Schachter.
\newblock Two algorithms for constructing a {D}elaunay triangulation.
\newblock {\em International Journal of Computer \& Information Sciences},
  9(3):219--242, 1980.

\bibitem{kinaSUR}
{Aryan Verma}.
\newblock {Triangulations Using Matplotlib}.
\newblock
  \url{https://www.scaler.com/topics/matplotlib/matplotlib-triangulation/}.

\bibitem{song2020score}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano
  Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock {\em arXiv preprint arXiv:2011.13456}, 2020.

\bibitem{diffusion_models_beat_gans}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~34, 2021.

\bibitem{Kingma2021VariationalModels}
Diederik~P. Kingma, Tim Salimans, Ben Poole, and Jonathan Ho.
\newblock {Variational Diffusion Models}.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~34, 2021.

\bibitem{saharia2022photorealistic}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily
  Denton, Seyed Kamyar~Seyed Ghasemipour, Burcu~Karagol Ayan, S~Sara Mahdavi,
  Rapha~Gontijo Lopes, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language
  understanding.
\newblock {\em arXiv preprint arXiv:2205.11487}, 2022.

\bibitem{guth2022wavelet}
Florentin Guth, Simon Coste, Valentin De~Bortoli, and Stephane Mallat.
\newblock Wavelet score-based generative modeling.
\newblock {\em arXiv preprint arXiv:2208.05003}, 2022.

\bibitem{donoho1995noising}
David~L Donoho.
\newblock De-noising by soft-thresholding.
\newblock {\em IEEE transactions on information theory}, 41(3):613--627, 1995.

\bibitem{fid}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{sorensen1948method}
Thorvald~A Sorensen.
\newblock A method of establishing groups of equal amplitude in plant sociology
  based on similarity of species content and its application to analyses of the
  vegetation on danish commons.
\newblock {\em Biol. Skar.}, 5:1--34, 1948.

\bibitem{dice1945measures}
Lee~R Dice.
\newblock Measures of the amount of ecologic association between species.
\newblock {\em Ecology}, 26(3):297--302, 1945.

\bibitem{lecun2010mnist}
Yann LeCun, Corinna Cortes, and C.~J. Burges.
\newblock {MNIST} handwritten digit database.
\newblock \url{http://yann.lecun.com/exdb/mnist/}, 2010.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{gupta2022towards}
Jayesh~K Gupta and Johannes Brandstetter.
\newblock Towards multi-spatiotemporal-scale generalized pde modeling.
\newblock {\em arXiv preprint arXiv:2209.15616}, 2022.

\bibitem{kuijf2019standardized}
Hugo~J Kuijf, J~Matthijs Biesbroek, Jeroen De~Bresser, Rutger Heinen, Simon
  Andermatt, Mariana Bento, Matt Berseth, Mikhail Belyaev, M~Jorge Cardoso,
  Adria Casamitjana, et~al.
\newblock Standardized assessment of automatic segmentation of white matter
  hyperintensities and results of the wmh segmentation challenge.
\newblock {\em IEEE transactions on medical imaging}, 38(11):2556--2568, 2019.

\bibitem{li2018fully}
Hongwei Li, Gongfa Jiang, Jianguo Zhang, Ruixuan Wang, Zhaolei Wang, Wei-Shi
  Zheng, and Bjoern Menze.
\newblock Fully convolutional network ensembles for white matter
  hyperintensities segmentation in mr images.
\newblock {\em NeuroImage}, 183:650--665, 2018.

\bibitem{li2020fourier}
Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik
  Bhattacharya, Andrew Stuart, and Anima Anandkumar.
\newblock Fourier neural operator for parametric partial differential
  equations.
\newblock {\em arXiv preprint arXiv:2010.08895}, 2020.

\bibitem{peebles2022scalable}
William Peebles and Saining Xie.
\newblock Scalable diffusion models with transformers.
\newblock {\em arXiv preprint arXiv:2212.09748}, 2022.

\bibitem{jabri2022scalable}
Allan Jabri, David Fleet, and Ting Chen.
\newblock Scalable adaptive computation for iterative generation.
\newblock {\em arXiv preprint arXiv:2212.11972}, 2022.

\bibitem{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{naeem2020reliable}
Muhammad~Ferjad Naeem, Seong~Joon Oh, Youngjung Uh, Yunjey Choi, and Jaejun
  Yoo.
\newblock Reliable fidelity and diversity metrics for generative models.
\newblock In {\em International Conference on Machine Learning}, pages
  7176--7185. PMLR, 2020.

\bibitem{sajjadi2018assessing}
Mehdi~SM Sajjadi, Olivier Bachem, Mario Lucic, Olivier Bousquet, and Sylvain
  Gelly.
\newblock Assessing generative models via precision and recall.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{barnsley2014fractals}
Michael~F Barnsley.
\newblock {\em Fractals everywhere}.
\newblock Academic press, 2014.

\bibitem{bandt2006open}
Christoph Bandt, Nguyen Hung, and Hui Rao.
\newblock On the open set condition for self-similar fractals.
\newblock {\em Proceedings of the american mathematical society},
  134(5):1369--1374, 2006.

\bibitem{hoogeboom2023simple}
Emiel Hoogeboom, Jonathan Heek, and Tim Salimans.
\newblock simple diffusion: End-to-end diffusion for high resolution images.
\newblock {\em arXiv preprint arXiv:2301.11093}, 2023.

\bibitem{behrmann2019invertible}
Jens Behrmann, Will Grathwohl, Ricky~TQ Chen, David Duvenaud, and
  J{\"o}rn-Henrik Jacobsen.
\newblock Invertible residual networks.
\newblock In {\em International Conference on Machine Learning}, pages
  573--582. PMLR, 2019.

\bibitem{cciccek20163d}
{\"O}zg{\"u}n {\c{C}}i{\c{c}}ek, Ahmed Abdulkadir, Soeren~S Lienkamp, Thomas
  Brox, and Olaf Ronneberger.
\newblock 3d u-net: learning dense volumetric segmentation from sparse
  annotation.
\newblock In {\em Medical Image Computing and Computer-Assisted
  Intervention--MICCAI 2016: 19th International Conference, Athens, Greece,
  October 17-21, 2016, Proceedings, Part II 19}, pages 424--432. Springer,
  2016.

\bibitem{isensee2021nnu}
Fabian Isensee, Paul~F Jaeger, Simon~AA Kohl, Jens Petersen, and Klaus~H
  Maier-Hein.
\newblock nnu-net: a self-configuring method for deep learning-based biomedical
  image segmentation.
\newblock {\em Nature methods}, 18(2):203--211, 2021.

\bibitem{isensee2018nnu}
Fabian Isensee, Jens Petersen, Andre Klein, David Zimmerer, Paul~F Jaeger,
  Simon Kohl, Jakob Wasserthal, Gregor Koehler, Tobias Norajitra, Sebastian
  Wirkert, et~al.
\newblock nnu-net: Self-adapting framework for u-net-based medical image
  segmentation.
\newblock {\em arXiv preprint arXiv:1809.10486}, 2018.

\bibitem{kohl2018probabilistic}
Simon Kohl, Bernardino Romera-Paredes, Clemens Meyer, Jeffrey De~Fauw, Joseph~R
  Ledsam, Klaus Maier-Hein, SM~Eslami, Danilo Jimenez~Rezende, and Olaf
  Ronneberger.
\newblock A probabilistic u-net for segmentation of ambiguous images.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{esser2018variational}
Patrick Esser, Ekaterina Sutter, and Bj{\"o}rn Ommer.
\newblock A variational u-net for conditional appearance and shape generation.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 8857--8866, 2018.

\bibitem{falk2019u}
Thorsten Falk, Dominic Mai, Robert Bensch, {\"O}zg{\"u}n {\c{C}}i{\c{c}}ek,
  Ahmed Abdulkadir, Yassine Marrakchi, Anton B{\"o}hm, Jan Deubner, Zoe
  J{\"a}ckel, Katharina Seiwald, et~al.
\newblock U-net: deep learning for cell counting, detection, and morphometry.
\newblock {\em Nature methods}, 16(1):67--70, 2019.

\bibitem{zhang2018road}
Zhengxin Zhang, Qingjie Liu, and Yunhong Wang.
\newblock Road extraction by deep residual u-net.
\newblock {\em IEEE Geoscience and Remote Sensing Letters}, 15(5):749--753,
  2018.

\bibitem{siddique2020u}
Nahian Siddique, Paheding Sidike, Colin Elkin, and Vijay Devabhaktuni.
\newblock U-net and its variants for medical image segmentation: theory and
  applications.
\newblock {\em arXiv preprint arXiv:2011.01118}, 2020.

\bibitem{ibtehaz2020multiresunet}
Nabil Ibtehaz and M~Sohel Rahman.
\newblock Multiresunet: Rethinking the u-net architecture for multimodal
  biomedical image segmentation.
\newblock {\em Neural networks}, 121:74--87, 2020.

\bibitem{lostar2020deep}
Mert Lostar and Islem Rekik.
\newblock Deep hypergraph u-net for brain graph embedding and classification.
\newblock {\em arXiv preprint arXiv:2008.13118}, 2020.

\bibitem{he2020curvanet}
Wenchong He, Zhe Jiang, Chengming Zhang, and Arpan~Man Sainju.
\newblock Curvanet: Geometric deep learning based on directional curvature for
  3d shape analysis.
\newblock In {\em Proceedings of the 26th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pages 2214--2224, 2020.

\bibitem{daubechies1992ten}
Ingrid Daubechies.
\newblock {\em Ten lectures on wavelets}.
\newblock SIAM, 1992.

\bibitem{benzi2002preconditioning}
Michele Benzi.
\newblock Preconditioning techniques for large linear systems: a survey.
\newblock {\em Journal of computational Physics}, 182(2):418--477, 2002.

\bibitem{wathen_2015}
A.~J. Wathen.
\newblock Preconditioning.
\newblock {\em Acta Numerica}, 24:329–376, 2015.

\bibitem{chen2005matrix}
Ke~Chen.
\newblock {\em Matrix preconditioning techniques and applications}, volume~19.
\newblock Cambridge University Press, 2005.

\bibitem{turkel1999preconditioning}
Eli Turkel.
\newblock Preconditioning techniques in computational fluid dynamics.
\newblock {\em Annual Review of Fluid Mechanics}, 31(1):385--416, 1999.

\bibitem{dahmen1992multilevel}
Wolfgang Dahmen and Angela Kunoth.
\newblock Multilevel preconditioning.
\newblock {\em Numerische Mathematik}, 63(1):315--344, 1992.

\bibitem{axclsson1989algebraic}
O~Axclsson and Panayot~S Vassilevski.
\newblock Algebraic multilevel preconditioning methods. i.
\newblock {\em Numerische Mathematik}, 56(2-3):157--177, 1989.

\bibitem{axelsson1990algebraic}
Owe Axelsson and Panayot~S Vassilevski.
\newblock Algebraic multilevel preconditioning methods, ii.
\newblock {\em SIAM Journal on Numerical Analysis}, 27(6):1569--1590, 1990.

\bibitem{zhang2023preconditioned}
Li~Zhang, Hengyuan Ma, Xiatian Zhu, and Jianfeng Feng.
\newblock Preconditioned score-based generative models.
\newblock {\em arXiv preprint arXiv:2302.06504}, 2023.

\bibitem{wandb}
Lukas Biewald.
\newblock Experiment tracking with weights and biases, 2020.
\newblock Software available from wandb.com.

\bibitem{pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock {PyTorch}: An imperative style, high-performance deep learning
  library.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  8024--8035, 2019.

\bibitem{cotter2020uses}
Fergal Cotter.
\newblock {\em Uses of complex wavelets in deep convolutional neural networks}.
\newblock PhD thesis, University of Cambridge, 2020.

\bibitem{lee2019pywavelets}
Gregory Lee, Ralf Gommers, Filip Waselewski, Kai Wohlfahrt, and Aaron O'Leary.
\newblock Pywavelets: A python package for wavelet analysis.
\newblock {\em Journal of Open Source Software}, 4(36):1237, 2019.

\bibitem{falcon}
William Falcon and {The PyTorch Lightning team}.
\newblock {PyTorch Lightning}, March 2019.

\bibitem{matplotlib}
J.~D. Hunter.
\newblock Matplotlib: A {2D} graphics environment.
\newblock {\em Computing in Science \& Engineering}, 9(3):90--95, 2007.

\bibitem{harris2020array}
Charles~R. Harris, K.~Jarrod Millman, St{\'e}fan~J. van~der Walt, Ralf Gommers,
  Pauli Virtanen, David Cournapeau, Eric Wieser, Julian Taylor, Sebastian Berg,
  Nathaniel~J. Smith, et~al.
\newblock Array programming with {NumPy}.
\newblock {\em Nature}, 585(7825):357--362, 2020.

\bibitem{tensorflow2015-whitepaper}
Mart\'{i}n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,
  Craig Citro, Greg~S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin,
  Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard,
  Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh
  Levenberg, Dandelion Man\'{e}, Rajat Monga, Sherry Moore, Derek Murray, Chris
  Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal
  Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi\'{e}gas,
  Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and
  Xiaoqiang Zheng.
\newblock {TensorFlow}: Large-scale machine learning on heterogeneous systems,
  2015.
\newblock Software available from tensorflow.org.

\bibitem{pyyaml}
pyyaml contributors.
\newblock pyyaml.
\newblock \url{https://github.com/yaml/pyyaml}, 2006.

\bibitem{tqdm}
tqdm contributors.
\newblock Imageio.
\newblock \url{https://github.com/tqdm/tqdm}, 2022.

\bibitem{scikit-learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock {\em Journal of Machine Learning Research}, 12:2825--2830, 2011.

\bibitem{pickle}
Guido Van~Rossum.
\newblock {\em The {Python} Library Reference, release 3.8.2}.
\newblock Python Software Foundation, 2020.

\bibitem{openai2023gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2023.

\end{thebibliography}
