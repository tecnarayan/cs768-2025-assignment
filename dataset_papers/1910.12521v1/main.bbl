\begin{thebibliography}{28}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ablin et~al.(2018)Ablin, Gramfort, Cardoso, and
  Bach]{ablin2018algorithms}
P.~Ablin, A.~Gramfort, J.-F. Cardoso, and F.~Bach.
\newblock {EM} algorithms for {ICA}.
\newblock \emph{arXiv preprint arXiv:1805.10054}, 2018.

\bibitem[Allen-Zhu and Hazan(2016)]{allen2016variance}
Z.~Allen-Zhu and E.~Hazan.
\newblock Variance reduction for faster non-convex optimization.
\newblock In \emph{International Conference on Machine Learning}, pages
  699--707, 2016.

\bibitem[Balakrishnan et~al.(2017)Balakrishnan, Wainwright, and
  Yu]{balakrishnan2017statistical}
S.~Balakrishnan, M.~J. Wainwright, and B.~Yu.
\newblock Statistical guarantees for the {EM} algorithm: From population to
  sample-based analysis.
\newblock \emph{Ann. Statist.}, 45\penalty0 (1):\penalty0 77--120, 02 2017.
\newblock \doi{10.1214/16-AOS1435}.

\bibitem[Blei et~al.({2017})Blei, Kucukelbir, and
  McAuliffe]{BleiVariational2017}
D.~M. Blei, A.~Kucukelbir, and J.~D. McAuliffe.
\newblock {Variational Inference: A Review for Statisticians}.
\newblock \emph{{Journal of the American statistical Association}},
  {112}\penalty0 ({518}):\penalty0 {859--877}, {JUN} {2017}.
\newblock ISSN {0162-1459}.
\newblock \doi{{10.1080/01621459.2017.1285773}}.

\bibitem[Capp{\'e} and Moulines(2009)]{cappe2009line}
O.~Capp{\'e} and E.~Moulines.
\newblock On-line expectation--maximization algorithm for latent data models.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 71\penalty0 (3):\penalty0 593--613, 2009.

\bibitem[Chen et~al.(2018)Chen, Zhu, Teh, and Zhang]{chen2018stochastic}
J.~Chen, J.~Zhu, Y.~W. Teh, and T.~Zhang.
\newblock Stochastic expectation maximization with variance reduction.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  7978--7988, 2018.

\bibitem[Csisz\'{a}r and Tusn\'{a}dy(1984)]{csiszar:tusnady:1984}
I.~Csisz\'{a}r and G.~Tusn\'{a}dy.
\newblock Information geometry and alternating minimization procedures.
\newblock \emph{Statist. Decisions}, suppl. 1:\penalty0 205--237, 1984.
\newblock ISSN 0721-2631.
\newblock Recent results in estimation theory and related topics.

\bibitem[Defazio et~al.(2014)Defazio, Bach, and
  Lacoste-Julien]{defazio2014saga}
A.~Defazio, F.~Bach, and S.~Lacoste-Julien.
\newblock Saga: A fast incremental gradient method with support for
  non-strongly convex composite objectives.
\newblock In \emph{Advances in neural information processing systems}, pages
  1646--1654, 2014.

\bibitem[Dempster et~al.(1977)Dempster, Laird, and Rubin]{dempster1977Maximum}
A.~P. Dempster, N.~M. Laird, and D.~B. Rubin.
\newblock Maximum likelihood from incomplete data via the {EM} algorithm.
\newblock \emph{Journal of the royal statistical society. Series B
  (methodological)}, pages 1--38, 1977.

\bibitem[Ghadimi and Lan(2013)]{ghadimi2013stochastic}
S.~Ghadimi and G.~Lan.
\newblock Stochastic first-and zeroth-order methods for nonconvex stochastic
  programming.
\newblock \emph{SIAM Journal on Optimization}, 23\penalty0 (4):\penalty0
  2341--2368, 2013.

\bibitem[Gunawardana and Byrne(2005)]{gunawardana2005convergence}
A.~Gunawardana and W.~Byrne.
\newblock Convergence theorems for generalized alternating minimization
  procedures.
\newblock \emph{Journal of Machine Learning Research}, 6:\penalty0 2049--2073,
  2005.

\bibitem[Hinton et~al.(2006)Hinton, Osindero, and Teh]{hinton2006fast}
G.~E. Hinton, S.~Osindero, and Y.-W. Teh.
\newblock A fast learning algorithm for deep belief nets.
\newblock \emph{Neural computation}, 18\penalty0 (7):\penalty0 1527--1554,
  2006.

\bibitem[Hofmann(1999)]{hofmann2017probabilistic}
T.~Hofmann.
\newblock Probabilistic latent semantic indexing.
\newblock In \emph{Proceedings of the 22Nd Annual International ACM SIGIR
  Conference on Research and Development in Information Retrieval}, SIGIR '99,
  pages 50--57, New York, NY, USA, 1999. ACM.
\newblock ISBN 1-58113-096-1.
\newblock \doi{10.1145/312624.312649}.

\bibitem[Johnson and Zhang(2013)]{johnson:zhang:2013}
R.~Johnson and T.~Zhang.
\newblock Accelerating stochastic gradient descent using predictive variance
  reduction.
\newblock In \emph{Advances in neural information processing systems}, pages
  315--323, 2013.

\bibitem[Karimi et~al.(2019)Karimi, Miasojedow, Moulines, and
  Wai]{karimi2019non}
B.~Karimi, B.~Miasojedow, E.~Moulines, and H.-T. Wai.
\newblock Non-asymptotic analysis of biased stochastic approximation schemes.
\newblock In \emph{Conference on Learning Theory}, 2019.

\bibitem[Mairal(2015)]{mairal2015incremental}
J.~Mairal.
\newblock Incremental majorization-minimization optimization with application
  to large-scale machine learning.
\newblock \emph{SIAM Journal on Optimization}, 25\penalty0 (2):\penalty0
  829--855, 2015.

\bibitem[McLachlan and Krishnan(2007)]{mclachlan2007algorithm}
G.~McLachlan and T.~Krishnan.
\newblock \emph{The {EM} algorithm and extensions}, volume 382.
\newblock John Wiley \& Sons, 2007.

\bibitem[Medelyan(2009)]{medelyan2009human}
O.~Medelyan.
\newblock \emph{Human-competitive automatic topic indexing}.
\newblock PhD thesis, The University of Waikato, 2009.

\bibitem[Neal and Hinton(1998)]{neal1998view}
R.~M. Neal and G.~E. Hinton.
\newblock A view of the {EM} algorithm that justifies incremental, sparse, and
  other variants.
\newblock In \emph{Learning in graphical models}, pages 355--368. Springer,
  1998.

\bibitem[Ng and McLachlan({2003})]{ngChoice2003}
S.~Ng and G.~McLachlan.
\newblock {On the choice of the number of blocks with the incremental {EM}
  algorithm for the fitting of normal mixtures}.
\newblock \emph{{Statistics and Computing}}, {13}\penalty0 ({1}):\penalty0
  {45--55}, {FEB} {2003}.
\newblock ISSN {0960-3174}.
\newblock \doi{{10.1023/A:1021987710829}}.

\bibitem[Reddi et~al.(2016{\natexlab{a}})Reddi, Hefny, Sra, Poczos, and
  Smola]{reddi2016stochastic}
S.~J. Reddi, A.~Hefny, S.~Sra, B.~Poczos, and A.~Smola.
\newblock Stochastic variance reduction for nonconvex optimization.
\newblock In \emph{International conference on machine learning}, pages
  314--323, 2016{\natexlab{a}}.

\bibitem[Reddi et~al.(2016{\natexlab{b}})Reddi, Sra, P{\'o}czos, and
  Smola]{reddi2016fast}
S.~J. Reddi, S.~Sra, B.~P{\'o}czos, and A.~Smola.
\newblock Fast incremental method for nonconvex optimization.
\newblock \emph{arXiv preprint arXiv:1603.06159}, 2016{\natexlab{b}}.

\bibitem[Thiesson et~al.({2001})Thiesson, Meek, and
  Heckerman]{ThiessonAccelerating2001}
B.~Thiesson, C.~Meek, and D.~Heckerman.
\newblock {Accelerating {EM} for large databases}.
\newblock \emph{{Machine Learning}}, {45}\penalty0 ({3}):\penalty0 {279--299},
  {2001}.
\newblock ISSN {0885-6125}.
\newblock \doi{{10.1023/A:1017986506241}}.

\bibitem[Wainwright et~al.(2008)Wainwright, Jordan,
  et~al.]{wainwright2008graphical}
M.~J. Wainwright, M.~I. Jordan, et~al.
\newblock Graphical models, exponential families, and variational inference.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  1\penalty0 (1--2):\penalty0 1--305, 2008.

\bibitem[Wang et~al.(2015)Wang, Gu, Ning, and Liu]{wang:gu:liu:2015}
Z.~Wang, Q.~Gu, Y.~Ning, and H.~Liu.
\newblock High dimensional em algorithm: Statistical optimization and
  asymptotic normality.
\newblock In C.~Cortes, N.~D. Lawrence, D.~D. Lee, M.~Sugiyama, and R.~Garnett,
  editors, \emph{Advances in Neural Information Processing Systems 28}, pages
  2521--2529. Curran Associates, Inc., 2015.

\bibitem[Wu et~al.(1983)]{wu1983convergence}
C.~J. Wu et~al.
\newblock On the convergence properties of the {EM} algorithm.
\newblock \emph{The Annals of statistics}, 11\penalty0 (1):\penalty0 95--103,
  1983.

\bibitem[Xu et~al.(2016)Xu, Hsu, and Maleki]{xu:hsu:maleki:2016}
J.~Xu, D.~J. Hsu, and A.~Maleki.
\newblock Global analysis of expectation maximization for mixtures of two
  gaussians.
\newblock In D.~D. Lee, M.~Sugiyama, U.~V. Luxburg, I.~Guyon, and R.~Garnett,
  editors, \emph{Advances in Neural Information Processing Systems 29}, pages
  2676--2684. Curran Associates, Inc., 2016.

\bibitem[Zhu et~al.(2017)Zhu, Wang, Zhai, and Gu]{zhu2017high}
R.~Zhu, L.~Wang, C.~Zhai, and Q.~Gu.
\newblock High-dimensional variance-reduced stochastic gradient
  expectation-maximization algorithm.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 4180--4188. JMLR. org, 2017.

\end{thebibliography}
