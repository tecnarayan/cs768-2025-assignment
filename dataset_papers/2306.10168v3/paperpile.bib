
@article{kuipers_spatial_2000,
	title = {The {Spatial} {Semantic} {Hierarchy}},
	volume = {119},
	journal = {Artif. Intell.},
	author = {Kuipers, B},
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {191--233},
}

@unpublished{guruswami_markov_2012,
	title = {Markov {Chains}},
	author = {Guruswami, V and Kannan, R},
	year = {2012},
	keywords = {merged\_fiete.bib},
}

@book{mohan_residue_2002,
	title = {Residue {Number} {Systems}: {Algorithms} and {Architectures}},
	publisher = {Kluwer Academic Pub, Boston},
	author = {Mohan, P V Ananda},
	year = {2002},
	keywords = {merged\_fiete.bib},
}

@misc{neher_part_1995,
	title = {Part 1: {Introduction} to {Patch} {Clamping}},
	publisher = {Plenum Press},
	editor = {Neher, Bert Sakmann and {Erwin}},
	year = {1995},
	note = {Edition: Second
Pages: 1–52
Publication Title: Single-Channel Recording
Section: 1 and 2},
	keywords = {merged\_fiete.bib},
}

@book{miller_waste_2002,
	title = {Waste {Sties} as {Biological} {Reactors}: {Characterization} and {Modeling}},
	publisher = {CRC Press},
	author = {Miller, P A and Clesceri, N L},
	year = {2002},
	keywords = {merged\_fiete.bib},
}

@article{geerligs_detecting_2021,
	title = {Detecting neural state transitions underlying event segmentation},
	volume = {236},
	abstract = {Segmenting perceptual experience into meaningful events is a key cognitive process that helps us make sense of what is happening around us in the moment, as well as helping us recall past events. Nevertheless, little is known about the underlying neural mechanisms of the event segmentation process. Recent work has suggested that event segmentation can be linked to regional changes in neural activity patterns. Accurate methods for identifying such activity changes are important to allow further investigation of the neural basis of event segmentation and its link to the temporal processing hierarchy of the brain. In this study, we introduce a new set of elegant and simple methods to study these mechanisms. We introduce a method for identifying the boundaries between neural states in a brain area and a complementary one for identifying the number of neural states. Furthermore, we present the results of a comprehensive set of simulations and analyses of empirical fMRI data to provide guidelines for reliable estimation of neural states and show that our proposed methods outperform the current state-of-the-art in the literature. This methodological innovation will allow researchers to make headway in investigating the neural basis of event segmentation and information processing during naturalistic stimulation.},
	journal = {Neuroimage},
	author = {Geerligs, Linda and van Gerven, Marcel and Güçlü, Umut},
	year = {2021},
	keywords = {Event segmentation, fMRI, Greedy search, Hidden Markov model, merged\_fiete.bib, Neural states, Timescales},
	pages = {118085},
}

@article{stevens_changes_1994,
	title = {Changes in reliability of synaptic function as a mechanism for plasticity},
	volume = {371},
	number = {6499},
	journal = {Nature},
	author = {Stevens, Charles F and Wang, Yanyan},
	month = oct,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {704--707},
}

@article{van_der_meulen_three-terminal_1971,
	title = {Three-{Terminal} {Communication} {Channels}},
	volume = {3},
	number = {1},
	journal = {Adv. Appl. Probab.},
	author = {van der Meulen, Edward C},
	year = {1971},
	keywords = {merged\_fiete.bib},
	pages = {120--154},
}

@book{hardy_introduction_2008,
	address = {Oxford; New York},
	title = {An introduction to the theory of numbers},
	publisher = {Oxford University Press},
	author = {Hardy, G H and {Wright} and Heath-Brown, D R and {Silverman}},
	year = {2008},
	keywords = {merged\_fiete.bib},
}

@article{oster_computation_2010,
	title = {Computation with {Spikes} in a {Winner}-{Take}-{All} {Network}},
	volume = {21},
	number = {9},
	journal = {Neural Comput.},
	author = {Oster, Matthias and Douglas, Rodney and Liu, Shih-Chii},
	month = dec,
	year = {2010},
	note = {Publisher: MIT Press},
	keywords = {merged\_fiete.bib},
	pages = {2437--2465},
}

@article{fenton_unmasking_nodate,
	title = {Unmasking the {CA1} {Ensemble} {Place} {Code} by {Exposures} to {Small} and {Large} {Environments}: {More} {Place} {Cells} and {Multiple}, {Irregularly} {Arranged}, and {Expanded} {Place} {Fields} in the {Larger} {Space}},
	volume = {28},
	abstract = {In standard experimental environments, a constant proportion of CA1 principal cells are place cells, each with a spatial receptive field called a place field. Although the properties of place cells are a basis for understanding the mammalian representation of spatial knowledge, there is no consensus on which of the two fundamental neural-coding hypotheses correctly accounts for how place cells encode spatial information. Within the dedicated-coding hypothesis, the current activity of each cell is an independent estimate of the location with respect to its place field. The average of the location estimates from many cells represents current location, so a dedicated place code would degrade if single cells had multiple place fields. Within the alternative, ensemble-coding hypothesis, the concurrent discharge of many place cells is a vector that represents current location. An ensemble place code is not degraded if single cells have multiple place fields as long as the discharge vector at each location is unique. Place cells with multiple place fields might be required to represent the substantially larger space in more natural environments. To distinguish between the dedicated-coding and ensemble-coding hypotheses, we compared the characteristics of CA1 place fields in a standard cylinder and an approximately six times larger chamber. Compared with the cylinder, in the chamber, more CA1 neurons were place cells, each with multiple, irregularly arranged, and enlarged place fields. The results indicate that multiple place fields is a fundamental feature of CA1 place cell activity and that, consequently, an ensemble place code is required for CA1 discharge to accurately signal location.},
	number = {44},
	journal = {Journal of Neuroscience},
	author = {Fenton, Andre A and Kao, Hsin-Yi and Neymotin, Samuel A and Olypher, Andrey and Vayntrub, Yevgeniy and Lytton, William W and Ludvig, Nandor},
	keywords = {merged\_fiete.bib},
	pages = {11250--11262},
}

@article{hahnloser_permitted_2010,
	title = {Permitted and {Forbidden} {Sets} in {Symmetric} {Threshold}-{Linear} {Networks}},
	volume = {15},
	number = {3},
	journal = {Neural Comput.},
	author = {Hahnloser, Richard H R and Seung, H Sebastian and Slotine, Jean-Jacques},
	month = dec,
	year = {2010},
	note = {Publisher: MIT Press},
	keywords = {merged\_fiete.bib},
	pages = {621--638},
}

@article{wu_computing_2010,
	title = {Computing with {Continuous} {Attractors}: {Stability} and {Online} {Aspects}},
	volume = {17},
	number = {10},
	journal = {Neural Comput.},
	author = {Wu, Si and Amari, Shun-Ichi},
	month = dec,
	year = {2010},
	note = {Publisher: MIT Press},
	keywords = {merged\_fiete.bib},
	pages = {2215--2239},
}

@article{amaral_neurons_1990,
	title = {Neurons, numbers and the hippocampal network},
	volume = {83},
	abstract = {Anatomists involved with studies of the hippocampal formation are being prodded by computational modelers and physiologists who demand detailed and quantitative information concerning hippocampal neurons and circuits. The beautiful camera lucida drawings of old, and the elegant descriptions of dendritic form that accompanied them are giving way to computer-reconstructed and three-dimensionally analyzed cells with rigorous determination of dendritic lengths and volumes, branching pattern and spine distribution. We will review certain quantitative aspects of hippocampal organization in the rat based on a survey of available literature and on our own intracellular labeling studies of granule cells of the dentate gyrus and pyramidal cells of the hippocampus. Some of the potential implications of these data for hippocampal information processing will be discussed.},
	language = {eng},
	journal = {Prog. Brain Res.},
	author = {Amaral, D G and Ishizuka, N and Claiborne, B},
	year = {1990},
	note = {Place: Salk Institute for Biological Studies, San Diego, CA 92138.},
	keywords = {Animals, Cell Count, Hippocampus/*cytology, merged\_fiete.bib, Nerve Net/*cytology, Nervous System/*cytology, Neural Pathways/cytology, Rats},
	pages = {1--11},
}

@article{bajard_full_2004,
	title = {A {Full} {RNS} {Implementation} of {RSA}},
	volume = {53(6)},
	journal = {IEEE Trans. Comput.},
	author = {Bajard, J-C and Imbert, L},
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {769--774},
}

@article{bassett_lesions_2007,
	title = {Lesions of the {Tegmentomammillary} {Circuit} in the {Head} {Direction} {System} {Disrupt} the {Head} {Direction} {Signal} in the {Anterior} {Thalamus}},
	volume = {27},
	abstract = {Head direction (HD) cells in the rodent limbic system are believed to correspond to a cognitive representation of directional heading in the environment. Lesions of vestibular hair cells disrupt the characteristic firing patterns of HD cells, and thus vestibular afference is a critical contributor to the HD signal. A subcortical pathway that may convey this information includes the dorsal tegmental nucleus of Gudden (DTN) and the lateral mammillary nucleus (LMN). To test the hypothesis that the DTN and LMN are critical components for generating HD cell activity, we made electrolytic lesions of the DTN or LMN in rats and screened for HD cell activity in the anterior thalamus. Directional activity was absent in all animals with complete LMN lesions and in animals with complete DTN lesions, although a few HD cells were isolated in animals with incomplete lesions. Some DTN-lesioned animals contained cells whose firing rates were modulated by angular head velocity. Although cells with bursting patterns of activity have been observed in the anterior dorsal nucleus of the thalamus of animals with disruption of vestibular inputs, this pattern of activity was not observed in either the LMN- or DTN-lesioned animals. The general absence of direction-specific activity in the anterior thalamus of animals with DTN or LMN lesions is consistent with the view that the DTN-LMN circuit is essential for the generation of HD cell activity.},
	number = {28},
	journal = {Journal of Neuroscience},
	author = {Bassett, Joshua P and Tullman, Matthew L and Taube, Jeffrey S},
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {7564--7577},
}

@article{bingman_neuronal_2006,
	title = {Neuronal {Implementation} of {Hippocampal}-{Mediated} {Spatial} {Behavior}: {A} {Comparative} {Evolutionary} {Perspective}},
	volume = {5},
	abstract = {The hippocampal formation (HF) of mammals and birds plays a strikingly similar role in the representation of space. This evolutionarily conserved property, however, belies the contrasting spatial ecology of animals such as rats and homing pigeons, differing spatial ecologies that should have promoted the evolution of group-specific adaptations to the HF representation of space. However, the spatial response properties of pigeon and rat HF neurons reveal surprising similarity in the contribution of position, direction, and trajectory toward explaining spatial variation in firing rate. By contrast, the asymmetrical distribution of neuronal response properties in the left and right HF of homing pigeons, but not rats, indicates a difference in network organization. The authors propose that hippocampal evolution may be characterized by inertia with respect to changes in the basic spatial elements that determine the response properties of neurons but considerable plasticity in how the neuronal response elements are organized into functional networks.},
	number = {2},
	journal = {Behav. Cogn. Neurosci. Rev.},
	author = {Bingman, Verner P and Sharp, Patricia E},
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {80--91},
}

@article{blum_model_1996,
	title = {A model of spatial map formation in the hippocampus of the rat},
	volume = {8},
	abstract = {Using experimental facts about long-term potentiation (LTP) and hippocampal place cells, we model how a spatial map of the environment can be created in the rat hippocampus. Sequential firing of place cells during exploration induces, in the model, a pattern of LTP between place cells that shifts the location coded by their ensemble activity away from the actual location of the animal. These shifts provide a navigational map that, in a simulation of the Morris maze, can guide the animal toward its goal. The model demonstrates how behaviorally generated modifications of synaptic strengths can be read out to affect subsequent behavior. Our results also suggest a way that navigational maps can be constructed from experimental recordings of hippocampal place cells.},
	language = {eng},
	number = {1},
	journal = {Neural Comput.},
	author = {Blum, K I and Abbott, L F},
	year = {1996},
	note = {Place: Center for Complex Systems, Brandeis University, Waltham, MA 02254, USA.},
	keywords = {*Models, Action Potentials/physiology, Animals, Brain Mapping/*methods, Cognition/*physiology, Hippocampus/*physiology, Long-Term Potentiation/*physiology, Maze Learning/*physiology, merged\_fiete.bib, Neurological, Rats},
	pages = {85--93},
}

@article{burgess_neuronal_1996,
	title = {Neuronal computations underlying the firing of place cells and their role in navigation},
	volume = {6},
	abstract = {Our model of the spatial and temporal aspects of place cell firing and their role in rat navigation is reviewed. The model provides a candidate mechanism, at the level of individual cells, by which place cell information concerning self-localization could be used to guide navigation to previously visited reward sites. The model embodies specific predictions regarding the formation of place fields, the phase coding of place cell firing with respect to the hippocampal theta rhythm, and the formation of neuronal population vectors downstream from the place cells that code for the directions of goals during navigation. Recent experiments regarding the spatial distribution of place cell firing have confirmed our initial modeling hypothesis, that place fields are formed from Gaussian tuning curve inputs coding for the distances from environmental features, and enabled us to further specify the functional form of these inputs. Other recent experiments regarding the temporal distribution of place cell firing in two-dimensional environments have confirmed our predictions based on the temporal aspects of place cell firing on linear tracks. Directions for further experiments and refinements to the model are outlined for the future.},
	language = {eng},
	number = {6},
	journal = {Hippocampus},
	author = {Burgess, N and O'Keefe, J},
	year = {1996},
	note = {Place: Department of Anatomy, University College London, England.},
	keywords = {*Models, Animal/physiology, Animals, Behavior, Evaluation Studies, Hippocampus/*cytology/*physiology, Learning/physiology, merged\_fiete.bib, Neurological, Neurons/*physiology, Rats, Spatial Behavior/*physiology},
	pages = {749--762},
}

@article{etienne_path_2004,
	title = {Path integration in mammals},
	volume = {14},
	abstract = {It is often assumed that navigation implies the use, by animals, of landmarks indicating the location of the goal. However, many animals (including humans) are able to return to the starting point of a journey, or to other goal sites, by relying on self-motion cues only. This process is known as path integration, and it allows an agent to calculate a route without making use of landmarks. We review the current literature on path integration and its interaction with external, location-based cues. Special importance is given to the correlation between observable behavior and the activity pattern of particular neural cell populations that implement the internal representation of space. In mammals, the latter may well be the first high-level cognitive representation to be understood at the neural level.},
	language = {eng},
	number = {2},
	journal = {Hippocampus},
	author = {Etienne, Ariane S and Jeffery, Kathryn J},
	year = {2004},
	note = {Place: Faculte de Psychologie et des Sciences de l'Education (FaPSE), University of Geneva, Geneva, Switzerland. ariane.etienne@pse.unige.ch},
	keywords = {Animals, Cues, Hippocampus/cytology/*physiology, Humans, Mammals/*physiology, merged\_fiete.bib, Orientation/*physiology, Space Perception/physiology},
	pages = {180--192},
}

@article{foo_humans_2007,
	title = {Humans do not switch between path knowledge and landmarks when learning a new environment},
	volume = {71},
	abstract = {Using a metric shortcut paradigm, we have found that like honeybees (Dyer in Animal Behaviour 41:239-246, 1991), humans do not seem to build a metric “cognitive map” from path integration. Instead, observers take novel shortcuts based on visual landmarks whenever they are available and reliable (Foo, Warren, Duchon, \& Tarr in Journal of Experimental Psychology-Learning Memory and Cognition 31(2):195-215, 2005). In the present experiment we examine whether humans, like ants (Wolf \& Wehner in Journal of Experimental Biology 203:857-868, 2000), first use survey-type path knowledge, built up from path integration, and then subsequently shift to reliance on landmarks. In our study participants walked in an immersive virtual environment while head position and orientation were recorded. During training, participants learned two legs of a triangle with feedback: paths from Home to Red and Home to Blue. A configuration of colored posts surrounded the Red location. To test reliance on landmarks, these posts were covertly translated, rotated, or left unchanged during six probe trials. These probe trials were interspersed during the training procedure to measure changes over learning. Dependence on visual landmarks was immediate and sustained during training, and no significant learning effects were observed other than a decrease in hesitation time. Our results suggest that while humans have at least two distinct navigational strategies available to them, unlike ants, a computationally-simpler landmark strategy dominates during novel shortcut navigation.},
	language = {eng},
	number = {3},
	journal = {Psychol. Res.},
	author = {Foo, Patrick and Duchon, Andrew and Warren, Jr, William H and Tarr, Michael J},
	year = {2007},
	note = {Place: Department of Psychology, One University Heights, University of North Carolina at Asheville, Asheville, NC 28804, USA. pfoo@unca.edu},
	keywords = {*Choice Behavior, *Environment, *Spatial Behavior, Adult, Female, Humans, Male, Memory, merged\_fiete.bib, Space Perception, User-Computer Interface},
	pages = {240--251},
}

@article{fyhn_hippocampal_2007,
	title = {Hippocampal remapping and grid realignment in entorhinal cortex},
	volume = {446},
	abstract = {A fundamental property of many associative memory networks is the ability to decorrelate overlapping input patterns before information is stored. In the hippocampus, this neuronal pattern separation is expressed as the tendency of ensembles of place cells to undergo extensive 'remapping' in response to changes in the sensory or motivational inputs to the hippocampus. Remapping is expressed under some conditions as a change of firing rates in the presence of a stable place code ('rate remapping'), and under other conditions as a complete reorganization of the hippocampal place code in which both place and rate of firing take statistically independent values ('global remapping'). Here we show that the nature of hippocampal remapping can be predicted by ensemble dynamics in place-selective grid cells in the medial entorhinal cortex, one synapse upstream of the hippocampus. Whereas rate remapping is associated with stable grid fields, global remapping is always accompanied by a coordinate shift in the firing vertices of the grid cells. Grid fields of co-localized medial entorhinal cortex cells move and rotate in concert during this realignment. In contrast to the multiple environment-specific representations coded by place cells in the hippocampus, local ensembles of grid cells thus maintain a constant spatial phase structure, allowing position to be represented and updated by the same translation mechanism in all environments encountered by the animal.},
	language = {eng},
	number = {7132},
	journal = {Nature},
	author = {Fyhn, Marianne and Hafting, Torkel and Treves, Alessandro and Moser, May-Britt and Moser, Edvard I},
	year = {2007},
	note = {Place: Centre for the Biology of Memory, Norwegian University of Science and Technology, NO-7489 Trondheim, Norway.},
	keywords = {Animals, Brain Mapping, Cues, Entorhinal Cortex/*cytology/*physiology, Hippocampus/cytology/*physiology, Long-Evans, merged\_fiete.bib, Models, Neurological, Rats, Synapses/metabolism/physiology},
	pages = {190--194},
}

@article{fyhn_spatial_2004,
	title = {Spatial representation in the entorhinal cortex},
	volume = {305},
	abstract = {As the interface between hippocampus and neocortex, the entorhinal cortex is likely to play a pivotal role in memory. To determine how information is represented in this area, we measured spatial modulation of neural activity in layers of medial entorhinal cortex projecting to the hippocampus. Close to the postrhinal-entorhinal border, entorhinal neurons had stable and discrete multipeaked place fields, predicting the rat's location as accurately as place cells in the hippocampus. Precise positional modulation was not observed more ventromedially in the entorhinal cortex or upstream in the postrhinal cortex, suggesting that sensory input is transformed into durable allocentric spatial representations internally in the dorsocaudal medial entorhinal cortex.},
	language = {eng},
	number = {5688},
	journal = {Science},
	author = {Fyhn, M and Molden, S and Witter, M P and Moser, E I and Moser, M-B},
	year = {2004},
	note = {Place: Centre for the Biology of Memory, Medical-Technical Research Centre, Norwegian University of Science and Technology, 7489 Trondheim, Norway.},
	keywords = {*Memory, *Space Perception, Action Potentials, Animals, Brain Mapping, Electrodes, Entorhinal Cortex/cytology/*physiology, Hippocampus/physiology, Implanted, Long-Evans, Male, merged\_fiete.bib, Nerve Net/*physiology, Neurons/*physiology, Rats},
	pages = {1258--1264},
}

@article{grah_path_2005,
	title = {Path integration in a three-dimensional maze: ground distance estimation keeps desert ants {Cataglyphis} fortis on course},
	volume = {208},
	abstract = {In this study, we investigate the ability of desert ants to gauge the ground distances of sloped sections in a three-dimensional (3D) outbound path. Ground distance estimation, as opposed to a simple measurement of walking distances, is a necessary prerequisite for precise path integration in undulating terrain. We trained ants to visit a feeder along a path that included an angular turn as well as a 'hill', resulting in an outbound path with a distinct 3D structure. We then observed the ants' return path in a test field on level ground. From the angles of the ants' return path on the test field one can infer which property of the hill segment was fed into the ants' path integration module, the actual walking distance or the ground distance. The results show clearly that it is the ground distance that Cataglyphis fortis feeds into its path integrator, and suggest that the ants are able to keep an accurate home vector also in hilly terrain.},
	language = {eng},
	number = {Pt 21},
	journal = {J. Exp. Biol.},
	author = {Grah, Gunnar and Wehner, Rudiger and Ronacher, Bernhard},
	year = {2005},
	note = {Place: Department of Biology, Humboldt-Universitat zu Berlin, Invalidenstrasse 43, D 10099 Berlin, Germany.},
	keywords = {Animals, Ants/*physiology, Desert Climate, Distance Perception/*physiology, Locomotion/*physiology, merged\_fiete.bib, Orientation/*physiology, Tunisia},
	pages = {4005--4011},
}

@article{hafting_microstructure_2005,
	title = {Microstructure of a spatial map in the entorhinal cortex},
	volume = {436},
	abstract = {The ability to find one's way depends on neural algorithms that integrate information about place, distance and direction, but the implementation of these operations in cortical microcircuits is poorly understood. Here we show that the dorsocaudal medial entorhinal cortex (dMEC) contains a directionally oriented, topographically organized neural map of the spatial environment. Its key unit is the 'grid cell', which is activated whenever the animal's position coincides with any vertex of a regular grid of equilateral triangles spanning the surface of the environment. Grids of neighbouring cells share a common orientation and spacing, but their vertex locations (their phases) differ. The spacing and size of individual fields increase from dorsal to ventral dMEC. The map is anchored to external landmarks, but persists in their absence, suggesting that grid cells may be part of a generalized, path-integration-based map of the spatial environment.},
	language = {eng},
	number = {7052},
	journal = {Nature},
	author = {Hafting, T and Fyhn, M and Molden, S and Moser, M-B and Moser, E I},
	year = {2005},
	note = {Place: Centre for the Biology of Memory, Norwegian University of Science and Technology, 7489 Trondheim, Norway.},
	keywords = {Action Potentials/physiology, Animals, Cues, Electrodes, Entorhinal Cortex/anatomy \& histology/*cytology/*physiology, Environment, Long-Evans, Male, merged\_fiete.bib, Models, Neurological, Neurons/cytology/physiology, Orientation/physiology, Rats, Space Perception/*physiology},
	pages = {801--806},
}

@article{kocsis_serotonergic_2006,
	title = {Serotonergic neuron diversity: {Identification} of raphe neurons with discharges time-locked to the hippocampal theta rhythm},
	volume = {103},
	abstract = {The serotonergic system plays a key role in the regulation of brain states, and many of the known features of serotonergic neurons appear to match this function. Midbrain raphe nuclei provide a diffuse projection to all regions of the forebrain, and raphe neurons exhibit a slow metronome-like activity that sets the ambient levels of serotonin across the sleep–wake cycle. Serotonergic cells have also been implicated, however, in a variety of more specific functions that can hardly be related to their low-rate monotonous patterns of discharges. The amazing variety of serotonergic receptors and their type-specific distribution on cortical neurons also raise the possibility of a more intimate coordination between the activity of serotonergic neurons and their target cortical circuits. Here we report an unexpected diversity in the behavior of immunohistochemically identified serotonergic neurons. Two outstanding subpopulations were identified by using the juxtacellular recording and labeling technique. The first subpopulation of serotonergic cells exhibited the classic clock-like activity with no apparent short timescale interaction with the hippocampal electroencephalogram. The other subpopulation discharged action potentials that were phase-locked to the hippocampal theta rhythm, the oscillatory pattern associated with acquisition of information and memory formation. These results indicate that the ascending serotonergic system comprises cells involved in complex information processing beyond the regulation of state transitions. The heterogeneity of serotonergic neuron behavior can also help to explain the complexity of symptoms associated with serotonergic dysfunction.},
	number = {4},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Kocsis, Bernat and Varga, Viktor and Dahan, Lionel and Sik, Attila},
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {1059--1064},
}

@article{maurer_self-motion_2005,
	title = {Self-motion and the origin of differential spatial scaling along the septo-temporal axis of the hippocampus},
	volume = {15},
	abstract = {Spatial scaling of place specific activity in the hippocampus varies systematically from the septal pole (high resolution) to the temporal pole (low resolution). Place fields get progressively larger, and the probability of observing a field in a given environment gets progressively smaller. It was previously found that decoupling movement in space from ambulation, by having the animal actively ride on a mobile platform, results in marked enlargement of the spatial scale factor in the dorsal hippocampus and a reduction in the increase in theta rhythm power with running speed, suggesting that a self-motion signal determines the spatial scale at which the hippocampal population vector updates. These results led to the hypothesis that the gain of the self-motion signal may vary systematically along the septo-temporal axis of the hippocampus. To test this hypothesis, EEG theta rhythm and ensembles of CA1 pyramidal cells and interneurons were recorded from the extreme dorsal and middle portions of the hippocampus. Pyramidal cell population vectors representing successive locations became decorrelated over substantially shorter distances in the dorsal than in the middle hippocampus. Dorsal pyramidal cells had smaller place fields, higher mean and peak firing rates, and higher intrinsic oscillation frequencies during track running than that of middle pyramidal cells. Both dorsal pyramidal cells and interneurons had more elevated mean rates during running, compared with rest, than that of the corresponding cell classes in the middle hippocampus, and both cell classes increased their rates more as a function of speed in the dorsal hippocampus.The amplitude, but not the frequency of fissure recorded theta rhythm, increased more as a function of running speed in the dorsal than in the middle hippocampus. We conclude that variation in the neuronal response to movement speed is the likely basis for the systematic variation in spatial scaling along the septo-temporal axis of the hippocampus.},
	language = {eng},
	number = {7},
	journal = {Hippocampus},
	author = {Maurer, Andrew P and Vanrhoads, Shea R and Sutherland, Gary R and Lipa, Peter and McNaughton, Bruce L},
	year = {2005},
	note = {Place: Neural Systems, Memory, and Aging, University of Arizona, Tucson, 85724, USA.},
	keywords = {Action Potentials/physiology, Animals, Exploratory Behavior/physiology, Hippocampus/*physiology, Inbred F344, Interneurons/*physiology, Male, merged\_fiete.bib, Motor Activity/*physiology, Neural Pathways/*physiology, Orientation/*physiology, Pyramidal Cells/*physiology, Rats, Septal Nuclei, Space Perception/*physiology, Synaptic Transmission/physiology, Theta Rhythm},
	pages = {841--852},
}

@article{mittelstaedt_homing_1980,
	title = {Homing by {Path} {Integration} in a {Mammal}},
	volume = {67},
	journal = {Naturwissenschaften},
	author = {Mittelstaedt, M L and Mittelstaedt, H},
	year = {1980},
	keywords = {merged\_fiete.bib},
	pages = {566--567},
}

@article{mulders_neuron_1997,
	title = {Neuron numbers in the presubiculum, parasubiculum, and entorhinal area of the rat},
	volume = {385},
	abstract = {Estimates of neuron numbers have been useful in studies of neurodegenerative disorders, and in their animal models, and in the computational modeling of hippocampal function. Although the retrohippocampal region (presubiculum, parasubiculum, and entorhinal area) is an integral part of the hippocampal circuitry and is affected selectively in a number of disorders, estimates of neuron numbers in the rat retrohippocampal region have yet to be published. Such data are necessary ingredients for computational models of the function of this region and will also facilitate a comparison of this region in rats and primates, which will help to determine how well we may expect rat models to predict function and dysfunction in primate brains. In the present study, we used the optical fractionator to estimate the number of neurons in the rat retrohippocampal region. The following estimates were obtained: 3.3 x 10(5) in presubicular layers II and III, 1.5 x 10(5) in parasubicular layers II and III, 2.2 x 10(5) in the combined pre- and parasubicular layers V and VI, 6.6 x 10(4) in medial entorhinal area (MEA) layer II, 1.3 x 10(5) in MEA layer III, 1.9 x 10(5) in MEA layers V and VI, 4.6 x 10(4) in lateral entorhinal area (LEA) layer II, 1.2 x 10(5) in LEA layer III, and 1.4 x 10(5) in LEA layers V and VI. A surprising finding was the large numbers of neurons in the pre- and parasubiculum, which indicate an important role of these areas in the control of the entorhino-hippocampal projection. A comparison of the numbers of neurons in the hippocampus and entorhinal areas in rats with similar estimates in humans revealed that gross input-output relations are largely conserved. Differences between rats and humans may be accounted for by more prominent entorhino-neocortical projections in primates and consequent increases in the number of neurons in the hippocampus and retrohippocampal region, which are dedicated to these projections.},
	language = {eng},
	number = {1},
	journal = {J. Comp. Neurol.},
	author = {Mulders, W H and West, M J and Slomianka, L},
	year = {1997},
	note = {Place: Department of Anatomy and Human Biology, University of Western Australia, Nedlands.},
	keywords = {Animals, Cell Count, Entorhinal Cortex/*cytology, Female, Hippocampus/anatomy \& histology/*cytology, merged\_fiete.bib, Neurons/*cytology, Rats, Wistar},
	pages = {83--94},
}

@article{pierre_development_1998,
	title = {Development of exploration and investigation in the {Norway} rat (rattus norvegicus)},
	volume = {125},
	number = {3},
	journal = {J. Gen. Psychol.},
	author = {Pierre, Peter J and Renner, Michael J},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {270--291},
}

@article{redish_role_1998,
	title = {The role of the hippocampus in solving the {Morris} water maze},
	volume = {10},
	abstract = {We suggest that the hippocampus plays two roles that allow rodents to solve the hidden-platform water maze: self-localization and route replay. When an animal explores an environment such as the water maze, the combination of place fields and correlational (Hebbian) long-term potentiation produces a weight matrix in the CA3 recurrent collaterals such that cells with overlapping place fields are more strongly interconnected than cells with nonoverlapping fields. When combined with global inhibition, this forms an attractor with coherent representations of position as stable states. When biased by local view information, this allows the animal to determine its position relative to the goal when it returns to the environment. We call this self-localization. When an animal traces specific routes within an environment, the weights in the CA3 recurrent collaterals become asymmetric. We show that this stores these routes in the recurrent collaterals. When primed with noise in the absence of sensory input, a coherent representation of position still forms in the CA3 population, but then that representation drifts, retracing a route. We show that these two mechanisms can coexist and form a basis for memory consolidation, explaining the anterograde and limited retrograde amnesia seen following hippocampal lesions.},
	language = {eng},
	number = {1},
	journal = {Neural Comput.},
	author = {Redish, A D and Touretzky, D S},
	year = {1998},
	note = {Place: Computer Science Department, Carnegie Mellon University, Pittsburgh, PA 15213-3891, USA.},
	keywords = {*Models, Amnesia/physiopathology, Animals, Computer Simulation, Hippocampus/*physiology, Humans, Maze Learning/*physiology, merged\_fiete.bib, Neurological, Sleep/physiology, Swimming},
	pages = {73--111},
}

@article{sargolini_conjunctive_2006,
	title = {Conjunctive representation of position, direction, and velocity in entorhinal cortex},
	volume = {312},
	abstract = {Grid cells in the medial entorhinal cortex (MEC) are part of an environment-independent spatial coordinate system. To determine how information about location, direction, and distance is integrated in the grid-cell network, we recorded from each principal cell layer of MEC in rats that explored two-dimensional environments. Whereas layer II was predominated by grid cells, grid cells colocalized with head-direction cells and conjunctive grid x head-direction cells in the deeper layers. All cell types were modulated by running speed. The conjunction of positional, directional, and translational information in a single MEC cell type may enable grid coordinates to be updated during self-motion-based navigation.},
	language = {eng},
	number = {5774},
	journal = {Science},
	author = {Sargolini, Francesca and Fyhn, Marianne and Hafting, Torkel and McNaughton, Bruce L and Witter, Menno P and Moser, May-Britt and Moser, Edvard I},
	year = {2006},
	note = {Place: Centre for the Biology of Memory, Norwegian University of Science and Technology, 7489 Trondheim, Norway.},
	keywords = {*Orientation, *Space Perception, Animals, Electrophysiology, Entorhinal Cortex/*cytology/*physiology, Exploratory Behavior, Locomotion, Long-Evans, Male, merged\_fiete.bib, Nerve Net/*physiology, Neurons/*physiology, Rats},
	pages = {758--762},
}

@article{sharp_anatomical_2001,
	title = {The anatomical and computational basis of the rat head-direction cell signal},
	volume = {24},
	abstract = {As a rat navigates through space, neurons called head-direction (HD) cells provide a signal of the rat's momentary directional heading. Although partly guided by landmarks, the cells also show a remarkable ability to track directional heading based on angular head movement. Theoretical models suggest that the HD cells are linked together to form an attractor network, and that cells which signal angular velocity update the directional setting of the attractor. Recently, cell types similar to those required theoretically have been discovered in the lateral mammillary and dorsal tegmental nuclei. Lesion and anatomical data suggest these nuclei might constitute the postulated attractor-path integration mechanism, and that they provide the HD cell signal to cortical areas where it has been observed.},
	language = {eng},
	number = {5},
	journal = {Trends Neurosci.},
	author = {Sharp, P E and Blair, H T and Cho, J},
	year = {2001},
	note = {Place: Dept of Biomedical Sciences, University of Illinois, College of Medicine at Rockford, 1601 Parkview Avenue, Rockford, IL 61107, USA. psharp@uic.edu},
	keywords = {Animals, Head Movements/*physiology, Hippocampus/*cytology/physiology, Mamillary Bodies/*cytology/physiology, merged\_fiete.bib, Neural Pathways, Neurons/*physiology, Rats, Space Perception/*physiology},
	pages = {289--294},
}

@article{terrazas_self-motion_2005,
	title = {Self-motion and the hippocampal spatial metric},
	volume = {25},
	abstract = {Self-motion signals are sufficient for animal navigation ({\textbackslash}textbackslashtt“path integration”) and for updating hippocampal location-specific firing. The contributions of ambulatory, vestibular, and optic self-motion signals to CA1 unit activity and EEG were studied while rats either walked or drove a car between locations on a circular track (referred to as WALK and CAR, respectively) or experienced pseudomotion, in which the animal was stationary and the environment was rotated (WORLD). Fewer pyramidal cells expressed place fields during CAR and those that did exhibited substantially larger place fields. The number of theta cycles required to traverse a place field increased, whereas the slope of the theta phase of firing versus position function was reduced. The presence and/or location of place fields were not well correlated between conditions. These effects were even more accentuated during WORLD. These results are not explainable by a simple “smearing out” of place fields but, in terms of size of place fields relative to the track size, are comparable with what would be observed if the track circumference was reduced and the animal moved around it at a correspondingly slower speed. Theta (and its 14-18 Hz harmonic) power were dependent on velocity, but the gain of this function was substantially reduced during CAR and WORLD, again as if the rat were moving more slowly. The spatial scale over which the hippocampal population vector is updated appears to be derived primarily from the gain of a self-motion velocity signal with approximately equal components derived from ambulation, vestibular, and optic-flow signals.},
	language = {eng},
	number = {35},
	journal = {J. Neurosci.},
	author = {Terrazas, Alejandro and Krause, Michael and Lipa, Peter and Gothard, Katalin M and Barnes, Carol A and McNaughton, Bruce L},
	year = {2005},
	note = {Place: Division of Neural Systems, Memory and Aging, University of Arizona, Tucson, Arizona 85724, USA.},
	keywords = {Animals, Hippocampus/*physiology, Inbred F344, Male, merged\_fiete.bib, Motion Perception/*physiology, Motor Activity/*physiology, Rats, Space Perception/*physiology, Theta Rhythm/methods},
	pages = {8085--8096},
}

@article{ulanovsky_hippocampal_2007,
	title = {Hippocampal cellular and network activity in freely moving echolocating bats},
	volume = {10},
	number = {2},
	journal = {Nat. Neurosci.},
	author = {Ulanovsky, Nachum and Moss, Cynthia F},
	year = {2007},
	note = {Publisher: Nature Publishing Group},
	keywords = {merged\_fiete.bib},
	pages = {224--233},
}

@article{whishaw_dead_2001,
	title = {Dead reckoning (path integration) requires the hippocampal formation: evidence from spontaneous exploration and spatial learning tasks in light (allothetic) and dark (idiothetic) tests},
	volume = {127},
	abstract = {Animals navigate using cues generated by their own movements (self-movement cues or idiothetic cues), as well as the cues they encounter in their environment (distal cues or allothetic cues). Animals use these cues to navigate in two different ways. When dead reckoning (deduced reckoning or path integration), they integrate self-movement cues over time to locate a present position or to return to a starting location. When piloting, they use allothetic cues as beacons, or they use the relational properties of allothetic cues to locate places in space. The neural structures involved in cue use and navigational strategies are still poorly understood, although considerable attention is directed toward the contributions of the hippocampal formation (hippocampus and associated pathways and structures, including the fimbria-fornix and the retrosplenial cortex). In the present study, using tests in allothetic and idiothetic paradigms, we present four lines of evidence to support the hypothesis that the hippocampal formation plays a central role in dead reckoning. (1) Control but not fimbria-fornix lesion rats can return to a novel refuge location in both light and dark (infrared) food carrying tasks. (2). Control but not fimbria-fornix lesion rats make periodic direct high velocity returns to a starting location in both light and dark exploratory tests. Control but not fimbria-fornix rats trained in the light to carry food from a fixed location to a refuge are able to maintain accurate outward and homebound trajectories when tested in the dark. (3). Control but not fimbria-fornix rats are able to correct an outward trajectory to a food source when the food source is moved when allothetic cues are present. These, tests of spontaneous exploration and foraging suggest a role for the hippocampal formation in dead reckoning.},
	language = {eng},
	number = {1-2},
	journal = {Behav. Brain Res.},
	author = {Whishaw, I Q and Hines, D J and Wallace, D G},
	year = {2001},
	note = {Place: Canadian Center for Behavioral Neuroscience, University of Lethbridge, 4401 University Drive, Lethbridge, Alberta, Canada T1K 3M4. whishaw@uleth.ca},
	keywords = {*Appetitive Behavior, *Exploratory Behavior, *Learning, *Orientation, *Space Perception, Animals, Cues, Female, Hippocampus/pathology/*physiology, Long-Evans, merged\_fiete.bib, Neural Pathways, Rats},
	pages = {49--69},
}

@article{witter_laminar_1984,
	title = {Laminar origin and septotemporal distribution of entorhinal and perirhinal projections to the hippocampus in the cat},
	volume = {224},
	abstract = {The projections of the entorhinal and perirhinal cortices to the hippocampus in the cat have been studied with retrograde and anterograde tracing techniques. Retrogradely transported tracers, which were injected at different levels along the septotemporal longitudinal hippocampal axis, result in labeled neurons in superficial entorhinal cortical layers II and III. Occasionally, labeled cells were also observed in the deepest entorhinal layer as well as in the superficial layers of the perirhinal area 35. It could further be shown that labeled neurons located superficially in the entorhinal cortex are topographically distributed in a lateromedial gradient, which corresponds to a septotemporal gradient along the longitudinal axis of the hippocampus. This topographical organization of the entorhinal-hippocampal projection system could be substantiated by the use of anterograde tracing of radioactively labeled amino acids. Injections in the entorhinal cortex produce labeled fibers in the hippocampus. Injections in the perirhinal area 35 result also in labeling over the hippocampus, whereas area 36 does not seem to distribute fibers to the hippocampus. As anticipated from the results of the retrograde tracing experiments, injections located laterally, in or close to the posterior rhinal sulcus, produce prominent labeling over the septal pole of the hippocampus, whereas progressively more medially located injections result in progressively more temporally located labeling. This topographical distribution of perforant path fibers along the septotemporal axis of the hippocampus, which is related to a lateromedial axis in the entorhinal cortex, has been observed following injections in the lateral entorhinal area (LEA) as well as in the medial entorhinal area (MEA). The present observations are discussed in regard of other connectional and putative functional differences between the septal and temporal hippocampus.},
	language = {eng},
	number = {3},
	journal = {J. Comp. Neurol.},
	author = {Witter, M P and Groenewegen, H J},
	year = {1984},
	keywords = {Animals, Brain Mapping, Cats, Female, Hippocampus/*anatomy \& histology, Limbic System/*anatomy \& histology, Male, merged\_fiete.bib, Neural Pathways/anatomy \& histology, Septum Pellucidum/*anatomy \& histology, Temporal Lobe/*anatomy \& histology},
	pages = {371--385},
}

@book{jezequel_turbo_2003,
	address = {London},
	title = {Turbo codes : error-correcting codes of widening application},
	publisher = {Kogan Page Science},
	author = {Jézéquel, Michel and Pyndiah, Ramesh},
	year = {2003},
	keywords = {merged\_fiete.bib},
}

@book{rovini_low-density_2004,
	address = {Noordwijk},
	title = {Low-density parity-check codes : a tutorial},
	volume = {245},
	publisher = {ESA Publications Division},
	author = {Rovini, Massimo},
	year = {2004},
	keywords = {merged\_fiete.bib},
}

@book{gallager_low-density_1963,
	address = {Cambridge},
	series = {M.{I}.{T}. {Press} research monographs},
	title = {Low-density parity-check codes},
	volume = {21st},
	publisher = {M.I.T. Press},
	author = {Gallager, Robert G},
	year = {1963},
	keywords = {merged\_fiete.bib},
}

@book{pless_introduction_1998,
	address = {New York},
	edition = {3rd ed},
	title = {Introduction to the theory of error-correcting codes},
	publisher = {Wiley},
	author = {Pless, Vera},
	year = {1998},
	keywords = {merged\_fiete.bib},
}

@book{lin_error_2004,
	address = {Upper Saddle River, N.J.},
	edition = {2nd ed},
	title = {Error control coding : fundamentals and applications},
	publisher = {Pearson-Prentice Hall},
	author = {Lin, Shu and Costello, Daniel J},
	year = {2004},
	keywords = {merged\_fiete.bib},
}

@inproceedings{recht_biology_1988,
	title = {The biology of domestic rats: telemetry yeilds insights for pest control},
	booktitle = {Proceedings of the {Thirteenth} {Vertebrate} {Pest} {Conference}},
	publisher = {University of Nebraska, Lincoln},
	author = {Recht, M A},
	year = {1988},
	keywords = {merged\_fiete.bib},
}

@inproceedings{sun_neural-like_1994,
	title = {A neural-like network approach to residue-to-decimal conversion},
	volume = {6},
	booktitle = {Neural {Networks}, 1994. {IEEE} {World} {Congress} on {Computational} {Intelligence}.},
	author = {Sun, Hong and Yao, Tian-Ren},
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {3883--3887},
}

@article{rao_mismatched_2000,
	title = {Mismatched {Appositions} of {Presynaptic} and {Postsynaptic} {Components} in {Isolated} {Hippocampal} {Neurons}},
	volume = {20},
	abstract = {To determine whether presynaptic input is necessary for postsynaptic differentiation, we isolated hippocampal neurons in microisland culture and thus deprived pyramidal cells of GABA input and GABAergic neurons of glutamate input. We find that glutamate input is necessary for clustering the AMPA-type glutamate receptor but not for clustering the NMDA receptor or the associated PSD-95 family scaffold in GABAergic cells; GABA input is not necessary for clustering the GABA(A) receptor or gephyrin in pyramidal cells. Isolated neurons showed a surprising mismatch of presynaptic and postsynaptic components. For example, in isolated pyramidal neurons, although GABA(A) receptor clusters covered {\textless}4\% of the dendritic surface and presynaptic boutons covered {\textless}12\%, a full two-thirds of the GABA(A) receptor clusters were localized inappropriately opposite the non-GABAergic, presumed glutamatergic, terminals. Furthermore, inhibitory and excitatory postsynaptic components were segregated into separate clusters in isolated cells and apposed to separate boutons of a single axon. Thus, GABA(A) receptors were clustered opposite some terminals, whereas NMDA receptors were clustered opposite other terminals of a single axon. These results suggest the involvement of a synaptogenic signal common to glutamate and GABA synapses that permits experimentally induced mismatching of presynaptic and postsynaptic components in isolated neurons, as well as a second specificity-conferring signal that mediates appropriate matching in mixed cultures.},
	number = {22},
	journal = {J. Neurosci.},
	author = {Rao, Anuradha and Cha, Eric M and Craig, Ann Marie},
	month = nov,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {8344--8353},
}

@article{warner_anatomy_1972,
	title = {The anatomy of the syrinx in passerine birds},
	volume = {168},
	abstract = {The macroscopical structure of the organ of voice in songbirds has long been known, but detailed information on the microscopical anatomy of the syrinx has generally been lacking. Observations based largely on macroscopical evidence have led to a number of erroneous interpretations of function of various syringeal components, and lacking microscopical information, the vocal mechanism of birds cannot be adequately understood. A wide variety of passeriform bird syrinxes have been studied by means of serial sections. Although there is much less variation in syringeal anatomy amongst songbirds than there is in the other orders of birds, and although all songbird syrinxes conform to the same basic pattern, there is nevertheless marked variation in various syringeal components between different passerine groups. Variations in syringeal structure within families Corvidae (Corvus corone, C. frugilegus), Sturnidae (Sturnus vulgaris, Gracula religiosa), Turdidae (Turdus merula, Erithacus rubecula), Hirundinidae (Delichon urbica), Ploceidae (Passer domesticus) and Paridae (Parus major, Aegithalos caudatus) are described and discussed. The significance of these findings in relation to bird sound production is discussed.},
	journal = {J. Zool. , Lond.},
	author = {Warner, Robert W},
	month = nov,
	year = {1972},
	keywords = {merged\_fiete.bib},
	pages = {381--393},
}

@article{raina_commentary_1999,
	title = {{COMMENTARY}: {Mitotic} {Neurons}: {A} {Dogma} {Succumbs}},
	volume = {159},
	number = {1},
	journal = {Exp. Neurol.},
	author = {Raina, Arun K and Takeda, Atsushi and Smith, Mark A},
	month = sep,
	year = {1999},
	keywords = {merged\_fiete.bib, Brewer, Commentary},
	pages = {248--249},
}

@book{gallager_low-density_1963-1,
	address = {Cambridge},
	series = {M.{I}.{T}. {Press} research monographs},
	title = {Low-density parity-check codes},
	volume = {21st},
	publisher = {M.I.T. Press},
	author = {Gallager, Robert G},
	year = {1963},
	keywords = {merged\_fiete.bib},
}

@article{sharp_angular_2001,
	title = {Angular velocity and head direction signals recorded from the dorsal tegmental nucleus of gudden in the rat: implications for path integration in the head direction cell circuit},
	volume = {115},
	abstract = {When a rat navigates through space, head direction (HD) cells provide an ongoing signal of the rat's directional heading. It is thought that these cells rely, in part, on angular path integration of the rat's head movements. This integration requires that the HD cell system receive information about angular head movements and that this information be combined with the current directional signal, to generate the next “predicted” direction. Recent data suggest that the dorsal tegmental nucleus (DTN) may play a critical role in helping to generate the HD cell signal. To test this, recordings were made from cells in the DTN in freely moving rats. The following cell types were found: (a) “classic” HD cells, (b) angular velocity cells, and (c) cells that fired as a function of both head direction and angular velocity. Thus, DTN cells exhibit firing characteristics that are critical to the neural circuit hypothesized for generation of the HD cell signal.},
	language = {eng},
	number = {3},
	journal = {Behav. Neurosci.},
	author = {Sharp, P E and Tinkelman, A and Cho, J},
	year = {2001},
	note = {Place: Department of Biomedical Sciences, University of Illinois, College of Medicine at Rockford, USA. PSHARP@uic.edu},
	keywords = {Animals, Rats, Male, merged\_fiete.bib, Orientation/*physiology, Brain Mapping, Long-Evans, Head Movements/*physiology, Acceleration, Cerebral/physiology, Dominance, Kinesthesis/*physiology, Neurons/physiology, Tegmentum Mesencephali/*physiology},
	pages = {571--588},
}

@article{ito_cerebellar_1982,
	title = {Cerebellar {Control} of the {Vestibulo}-{Ocular} {Reflex} – {Around} the {Flocculus} {Hypothesis}},
	volume = {5},
	abstract = {An introduction of the “flocculus hypothesis”, which brings together the Marr-Albus theories of cerebellar function, and the data as it relates to the vestobulo-ocular reflex. Cites all of the important data from before 1982, which includes the crucial anatomical and physiological studies of the vestibulo-ocular reflex. Dated, but very informative. Includes a nice figure of the VOR.},
	journal = {Annual Reviews of Neuroscience},
	author = {Ito, Masao},
	year = {1982},
	keywords = {merged\_fiete.bib, cerebellum, climbing fibers, flocculus, parallel fibers, purkinje neurons, vestibulo-ocular reflex},
	pages = {275--296},
}

@article{lac_learning_1995,
	title = {Learning and {Memory} in the {Vestibulo}-{Ocular} {Reflex}},
	volume = {18},
	abstract = {This review synthesizes the combined behavioral, physiological, anatomical, cellular and computational analyses needed to understand learning and memory in the VOR.},
	journal = {Annual Reviews of Neuroscience},
	author = {Lac, Sascha Du and Raymond, Jennifer L and Sejnowski, Terrence J and Lisberger, Stephen G},
	year = {1995},
	keywords = {merged\_fiete.bib, cerebellum, learning, memory, VOR},
	pages = {409--441},
}

@article{bizzi_computations_1991,
	title = {Computations {Underlying} the {Execution} of {Movement}: {A} {Biological} {Perspective}},
	volume = {253},
	number = {5017},
	journal = {Science},
	author = {Bizzi, Emilio and Mussa-Ivaldi, Ferdinando A and Giszter, Simon},
	month = jul,
	year = {1991},
	keywords = {Jun 12 import},
	pages = {287--291},
}

@article{fouad_restoring_2004,
	title = {Restoring walking after spinal cord injury},
	volume = {73},
	abstract = {One of the most obvious deficits following a spinal cord injury is the difficulty in walking, forcing many patients to use wheelchairs for locomotion. Over the past decade considerable effort has been directed at promoting the recovery of walking and to find effective treatments for spinal cord injury. Advances in our knowledge of the neuronal control of walking have led to the development of a promising rehabilitative strategy in patients with partial spinal cord injury, namely treadmill training with partial weight support. The current focus is on developing more efficient training protocols and automating the training to reduce the physical demand for the therapists. Mechanisms underlying training-induced improvements in walking have been revealed to some extent in animal studies. Another strategy for improving the walking in spinal cord injured patients is the use of functional electric stimulation of nerves and muscles to assist stepping movements. This field has advanced significantly over the past decade as a result of developments in computer technology and the miniaturization of electronics. Finally, basic research on animals with damaged spinal cords has focused on enhancing walking and other motor functions by promoting growth and regeneration of damaged axons. Numerous important findings have been reported yielding optimism that techniques for repairing the injured spinal cord will be developed in the near future. However, at present no strategy involving direct treatment of the injured spinal cord has been established for routine use in spinal cord injured patients. It now seems likely that any successful protocol in humans will require a combination of a treatment to promote re-establishing functional connections to neuronal networks in the spinal cord and specialized rehabilitation training to shape the motor patterns generated by these networks for specific behavioral tasks.},
	number = {2},
	journal = {Prog. Neurobiol.},
	author = {Fouad, Karim and Pearson, Keir},
	year = {2004},
	keywords = {Jun 12 import},
	pages = {107--126},
}

@article{beer_framing_1998,
	title = {Framing the {Debate} {Between} {Computational} and {Dynamical} {Approaches} to {Cognitive} {Science}},
	volume = {21},
	abstract = {van Gelder argues that computational and dynamical systems are mathematically distinct kinds of systems. While there are real experimental and theoretical differences between adopting a computational or dynamical perspective on cognition, and the dynamical approach has much to recommend it, the debate cannot be framed this rigorously. Instead, what�s needed is careful study of concrete models to improve our intuitions.},
	number = {5},
	journal = {Behav. Brain Sci.},
	author = {Beer, Randall D},
	year = {1998},
	keywords = {Jun 12 import},
	pages = {630},
}

@article{herrnstein_experiments_1991,
	title = {Experiments on {Stable} {Suboptimality} in {Individual} {Behavior}},
	volume = {81},
	abstract = {In several recent experiments, subjects made choices in a way that supports the idea that choice is governed, either sometimes or always, by a principle that does not necessarily maximize utility, as the subjects themselves would reckon their utility. In other words, they behaved irrationally, and their irrationalities seemed to be systematic and motivated, not just a matter of behaving carelessly or erroneously.},
	number = {2},
	journal = {Am. Econ. Rev.},
	author = {Herrnstein, R J},
	month = may,
	year = {1991},
	keywords = {Jun 12 import},
	pages = {360--364},
}

@article{beer_framing_1998-1,
	title = {Framing the {Debate} {Between} {Computational} and {Dynamical} {Approaches} to {Cognitive} {Science}},
	volume = {21},
	abstract = {van Gelder argues that computational and dynamical systems are mathematically distinct kinds of systems. While there are real experimental and theoretical differences between adopting a computational or dynamical perspective on cognition, and the dynamical approach has much to recommend it, the debate cannot be framed this rigorously. Instead, what�s needed is careful study of concrete models to improve our intuitions.},
	number = {5},
	journal = {Behav. Brain Sci.},
	author = {Beer, Randall D},
	year = {1998},
	keywords = {Psychology.bib},
	pages = {630},
}

@article{herrnstein_experiments_1991-1,
	title = {Experiments on {Stable} {Suboptimality} in {Individual} {Behavior}},
	volume = {81},
	abstract = {In several recent experiments, subjects made choices in a way that supports the idea that choice is governed, either sometimes or always, by a principle that does not necessarily maximize utility, as the subjects themselves would reckon their utility. In other words, they behaved irrationally, and their irrationalities seemed to be systematic and motivated, not just a matter of behaving carelessly or erroneously.},
	number = {2},
	journal = {Am. Econ. Rev.},
	author = {Herrnstein, R J},
	month = may,
	year = {1991},
	keywords = {Psychology.bib},
	pages = {360--364},
}

@article{molnar_mossy_1999,
	title = {Mossy {Fiber}–{Granule} {Cell} {Synapses} in the {Normal} and {Epileptic} {Rat} {Dentate} {Gyrus} {Studied} {With} {Minimal} {Laser} {Photostimulation}},
	volume = {82},
	abstract = {Dentate granule cells become synaptically interconnected in the hippocampus of persons with temporal lobe epilepsy, forming a recurrent mossy fiber pathway. This pathway may contribute to the development and propagation of seizures. The physiology of mossy fiber?granule cell synapses is difficult to characterize unambiguously, because electrical stimulation may activate other pathways and because there is a low probability of granule cell interconnection. These problems were addressed by the use of scanning laser photostimulation in slices of the caudal hippocampal formation. Glutamate was released from a caged precursor with highly focused ultraviolet light to evoke action potentials in a small population of granule cells. Excitatory synaptic currents were recorded in the presence of bicuculline. Minimal laser photostimulation evoked an apparently unitary excitatory postsynaptic current (EPSC) in 61\% of granule cells from rats that had experienced pilocarpine-induced status epilepticus followed by recurrent mossy fiber growth. An EPSC was also evoked in 13?16\% of granule cells from the control groups. EPSCs from status epilepticus and control groups had similar peak amplitudes (?30 pA), 20?80\% rise times (?1.2 ms), decay time constants (?10 ms), and half-widths (?8 ms). The mean failure rate was high (?70\%) in both groups, and in both groups activation of N-methyl-d-aspartate receptors contributed a small component to the EPSC. The strong similarity between responses from the status epilepticus and control groups suggests that they resulted from activation of a similar synaptic population. No EPSC was recorded when the laser beam was focused in the dentate hilus, suggesting that indirect activation of hilar mossy cells contributed little, if at all, to these results. Recurrent mossy fiber growth increases the density of mossy fiber?granule cell synapses in the caudal dentate gyrus by perhaps sixfold, but the new synapses appear to operate very similarly to preexisting mossy fiber?granule cell synapses.},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Molnár, Péter and Nadler, J Victor},
	month = oct,
	year = {1999},
	note = {Publisher: American Physiological Society},
	pages = {1883--1894},
}

@article{foster_replay_2017,
	title = {Replay {Comes} of {Age}},
	volume = {40},
	abstract = {Hippocampal place cells take part in sequenced patterns of reactivation after behavioral experience, known as replay. Since replay was first reported, nearly 20 years ago, many new results have been found, necessitating revision of the original interpretations. We review some of these results with a focus on the phenomenology of replay.},
	number = {1},
	journal = {Annu. Rev. Neurosci.},
	author = {Foster, David J},
	month = jul,
	year = {2017},
	note = {Publisher: Annual Reviews},
	pages = {581--602},
}

@book{mackay_information_2004,
	title = {Information {Theory}, {Inference}, and {Learning} {Algorithms}},
	publisher = {Cambridge University Press},
	author = {MacKay, D},
	year = {2004},
	keywords = {merged\_fiete.bib},
}

@techreport{scholkopf_statistical_2000,
	title = {Statistical {Learning} and {Kernel} {Methods}},
	abstract = {Lecture notes from a course to be taught at the Interdisciplinary College 2000.},
	institution = {Microsoft Research},
	author = {Scholkopf, Bernhard},
	month = feb,
	year = {2000},
	keywords = {MachineLearning.bib},
}

@misc{noauthor_child_nodate,
	title = {Child {Development}: {Learning} to {Walk}},
	abstract = {A collection of online articles about child development focusing on learning to walk},
	note = {Published: www.babycenter.com},
	keywords = {Jun 12 import},
}

@article{yu_temporal_1986,
	title = {Temporal hierarchical control of singing in birds},
	volume = {273},
	journal = {Science},
	author = {Yu, A C and Margoliash, D},
	year = {1986},
	keywords = {birdpaper.bib},
	pages = {1871--1875},
}

@article{welinder_unpublished_2008,
	title = {Unpublished observations},
	author = {Welinder, Peter E and Burak, Yoram and Fiete, Ila R},
	year = {2008},
	keywords = {merged\_fiete.bib},
}

@article{tesauro_temporal_1995,
	title = {Temporal {Difference} {Learning} and {TD}-{Gammon}},
	volume = {38},
	number = {3},
	journal = {Commun. ACM},
	author = {Tesauro, Gerald},
	month = mar,
	year = {1995},
	keywords = {Jun 12 import},
	pages = {58--68},
}

@article{jordan_introduction_nodate,
	title = {An introduction to variational methods for graphical models},
	author = {Jordan, M I},
	keywords = {Jun 12 import},
}

@book{jordan_learning_2001,
	series = {Adaptive {Computation} and {Machine} {Learning}},
	title = {Learning in {Graphical} {Models}},
	publisher = {MIT Press},
	editor = {Jordan, Michael I},
	year = {2001},
	keywords = {MachineLearning.bib},
}

@article{girosi_equivalence_1998,
	title = {An {Equivalence} between {Sparse} {Approximation} and {Support} {Vector} {Machines}},
	volume = {10},
	journal = {Neural Comput.},
	author = {Girosi, F},
	year = {1998},
	keywords = {Jun 12 import},
	pages = {1455--1480},
}

@phdthesis{levenick_knowledge_1985,
	type = {{PhD} {Thesis}},
	title = {Knowledge {Representation} and {Intelligent} {Systems}: {From} {Semantic} {Networks} to {Cognitive} {Maps}},
	author = {Levenick, James Richard},
	year = {1985},
	keywords = {Jun 12 import},
}

@book{bertsekas_neuro-dynamic_1996,
	series = {Optimization and {Neural} {Computation} {Series}},
	title = {Neuro-{Dynamic} {Programming}},
	publisher = {Athena Scientific},
	author = {Bertsekas, Dimitri P and Tsitsiklis, John N},
	month = oct,
	year = {1996},
	keywords = {Jun 12 import},
}

@phdthesis{chown_consolidation_1994,
	type = {{PhD} {Thesis}},
	title = {Consolidation and {Learning}: {A} {Connectionist} {Model} of {Human} {Credit} {Assignment}},
	author = {Chown, Eric Lance},
	year = {1994},
	keywords = {Jun 12 import},
}

@article{baxter_direct_1999,
	title = {Direct {Gradient}-{Based} {Reinforcement} {Learning}: {I}. {Gradient} {Estimation} {Algorithms}},
	author = {Baxter, J and Bartlett, P l},
	month = nov,
	year = {1999},
	keywords = {Jun 12 import},
	pages = {1--24},
}

@book{vapnik_nature_1999,
	title = {The {Nature} of {Statistical} {Learning} {Theory}},
	publisher = {Springer-Verlag New York, Incorporated},
	author = {Vapnik, Vladimir Naumovich},
	month = dec,
	year = {1999},
	keywords = {MachineLearning.bib},
}

@phdthesis{ten_hagen_continuous_2001,
	type = {{PhD} {Thesis}},
	title = {Continuous {State} {Space} {Q}-{Learning} for {Control} of {Nonlinear} {Systems}},
	author = {ten Hagen, Stephan H G},
	year = {2001},
	keywords = {Jun 12 import},
}

@article{doya_bifurcations_1992,
	title = {Bifurcations in the learning of recurrent neural networks},
	author = {Doya, Kenji},
	year = {1992},
	keywords = {Jun 12 import},
}

@incollection{kaplan_cognitive_1973,
	title = {Cognitive {Maps} in {Perception} and {Thought}},
	booktitle = {Image and {Environment}: {Cognitive} {Mapping} and {Spatial} {Behavior}},
	publisher = {Aldine Publishing Company},
	author = {Kaplan, Stephen},
	year = {1973},
	note = {Section: 4},
	keywords = {Jun 12 import},
	pages = {63--81},
}

@techreport{scholkopf_statistical_2000-1,
	title = {Statistical {Learning} and {Kernel} {Methods}},
	abstract = {Lecture notes from a course to be taught at the Interdisciplinary College 2000.},
	institution = {Microsoft Research},
	author = {Scholkopf, Bernhard},
	month = feb,
	year = {2000},
	keywords = {Jun 12 import},
}

@incollection{kaplan_environmental_1992,
	title = {Environmental {Preference} in a {Knowledge}-{Seeking}, {Knowledge}-{Using} {Organism}},
	author = {Kaplan, Stephen},
	year = {1992},
	note = {Section: 16},
	keywords = {Jun 12 import},
	pages = {581--598},
}

@book{bertsekas_dynamic_2000,
	edition = {2nd},
	title = {Dynamic {Programming} and {Optimal} {Control}},
	publisher = {Athena Scientific},
	author = {Bertsekas, Dimitri P},
	year = {2000},
	keywords = {MachineLearning.bib},
}

@book{jordan_learning_2001-1,
	series = {Adaptive {Computation} and {Machine} {Learning}},
	title = {Learning in {Graphical} {Models}},
	publisher = {MIT Press},
	editor = {Jordan, Michael I},
	year = {2001},
	keywords = {Jun 12 import},
}

@book{sutton_reinforcement_1998,
	title = {Reinforcement {Learning}: {An} {Introduction}},
	publisher = {MIT Press},
	author = {Sutton, Richard S and Barto, Andrew G},
	year = {1998},
	keywords = {MachineLearning.bib},
}

@book{vapnik_nature_1999-1,
	title = {The {Nature} of {Statistical} {Learning} {Theory}},
	publisher = {Springer-Verlag New York, Incorporated},
	author = {Vapnik, Vladimir Naumovich},
	month = dec,
	year = {1999},
	keywords = {Jun 12 import},
}

@book{rosen_elementary_2000,
	title = {Elementary number theory and its applications},
	publisher = {Addison-Wesley},
	author = {Rosen, K H},
	year = {2000},
	keywords = {merged\_fiete.bib},
}

@book{hanzo_turbo_2002,
	title = {Turbo coding, turbo equalisation and space-time coding},
	publisher = {Wiley-IEEE Press},
	author = {Hanzo, L and Liew, T H and Yeap, B L},
	year = {2002},
	keywords = {merged\_fiete.bib},
}

@incollection{kaplan_cognitive_1973-1,
	title = {Cognitive {Maps} in {Perception} and {Thought}},
	booktitle = {Image and {Environment}: {Cognitive} {Mapping} and {Spatial} {Behavior}},
	publisher = {Aldine Publishing Company},
	author = {Kaplan, Stephen},
	year = {1973},
	note = {Section: 4},
	keywords = {Psychology.bib},
	pages = {63--81},
}

@incollection{immelmann_notitle_1969,
	booktitle = {Bird {Vocalizations}},
	publisher = {Cambridge Univ. Press, New York},
	author = {Immelmann, K},
	editor = {Hinde, R A},
	year = {1969},
	keywords = {birdpaper.bib},
	pages = {61--74},
}

@book{braitenberg_vehicles_1984,
	title = {Vehicles: {Experiments} in {Synthetic} {Psychology}},
	publisher = {The MIT Press},
	author = {Braitenberg, Valentino},
	year = {1984},
	keywords = {Psychology.bib},
}

@incollection{noauthor_efficient_2021,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Efficient online inference for nonparametric mixture models},
	volume = {(to appear)},
	booktitle = {Conference on {Uncertainty} in {AI}},
	year = {2021},
	keywords = {merged\_fiete.bib},
}

@article{gardner_space_1988,
	title = {The space of interactions in neural network models},
	volume = {21},
	journal = {J. Phys. A Math. Gen.},
	author = {Gardner, E},
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {257--270},
}

@book{lee_introduction_2012,
	title = {Introduction to {Smooth} {Manifolds}},
	publisher = {Springer New York},
	author = {Lee, John M},
	year = {2012},
	keywords = {merged\_fiete.bib},
}

@book{cover_elements_2006,
	address = {Hoboken, N.J.},
	edition = {2nd},
	title = {Elements of information theory},
	publisher = {Wiley-Interscience},
	author = {{Cover} and Thomas, Joy A},
	year = {2006},
	keywords = {merged\_fiete.bib},
}

@article{flora_bouchacourt_flexible_2018,
	title = {A flexible model of working memory},
	journal = {bioRxiv doi. org/10. 1101/407700},
	author = {Flora Bouchacourt, Timothy J Buschman},
	year = {2018},
	keywords = {merged\_fiete.bib},
}

@incollection{widloski_grid_nodate,
	series = {{UT} {Ph}.{D}. {Theses} and {Dissertations}},
	title = {Grid cell attractor networks: development and implications},
	author = {Widloski, J E},
	keywords = {merged\_fiete.bib},
}

@book{kailath_linear_2000,
	title = {Linear estimation},
	publisher = {Prentice Hall},
	author = {Kailath, T and Sayed, A H and Hassibi, B},
	year = {2000},
	keywords = {merged\_fiete.bib},
}

@book{strogatz_nonlinear_1994,
	title = {Nonlinear {Dynamics} {And} {Chaos}: {With} {Applications} {To} {Physics}, {Biology}, {Chemistry}, {And} {Engineering}},
	publisher = {Westview Press},
	author = {Strogatz, S H},
	year = {1994},
	keywords = {merged\_fiete.bib},
}

@book{conway_sphere_1999,
	edition = {3rd},
	title = {Sphere {Packings}, {Lattices}, and {Groups}},
	publisher = {Springer},
	author = {Conway, J H and Sloane, N J A and Bannai, E},
	year = {1999},
	keywords = {merged\_fiete.bib},
}

@book{matlab_version_2012,
	title = {version 7.14.0.739 ({R2012a})},
	publisher = {The MathWorks Inc.},
	author = {{Matlab}},
	year = {2012},
	keywords = {merged\_fiete.bib},
}

@article{hayes_adaptive_1968,
	title = {Adaptive {Feedback} {Communications}},
	volume = {16},
	number = {1},
	journal = {Communication Technology, IEEE Transactions on},
	author = {Hayes, J},
	month = feb,
	year = {1968},
	keywords = {merged\_fiete.bib},
	pages = {29--34},
}

@article{turing_chemical_1952,
	title = {The chemical basis of morphogenesis},
	volume = {237},
	number = {641},
	journal = {Philos Trans R Soc Lond BB},
	author = {Turing, A M},
	year = {1952},
	keywords = {merged\_fiete.bib},
}

@article{goeckel_adaptive_1999,
	title = {Adaptive coding for time-varying channels using outdated fading estimates},
	volume = {47},
	number = {6},
	journal = {Communications, IEEE Transactions on},
	author = {Goeckel, D L},
	month = jun,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {844--855},
}

@book{shepard_synaptic_1998,
	title = {The {Synaptic} {Organization} of the brain},
	publisher = {Oxford Univ Press Inc,New York},
	author = {Shepard, G M},
	year = {1998},
	keywords = {merged\_fiete.bib},
}

@phdthesis{chung_construction_2000,
	type = {{PhD} {Thesis}},
	title = {On the {Construction} of {Some} {Capacity}-{Approaching} {Coding} {Schemes}},
	school = {M.I.T.},
	author = {Chung, S-Y},
	year = {2000},
	keywords = {merged\_fiete.bib, JSCC},
}

@book{andersen_hippocampus_2007,
	title = {The {Hippocampus} {Book}},
	publisher = {Oxford University Press},
	editor = {Andersen, P},
	year = {2007},
	keywords = {merged\_fiete.bib},
}

@article{hubel_receptive_1959,
	title = {Receptive fields of single neurones in the cat's striate cortex},
	volume = {148},
	journal = {J. Physiol.},
	author = {Hubel, D H \& T N Wiesel},
	year = {1959},
	keywords = {merged\_fiete.bib},
	pages = {574--591},
}

@article{akaike_new_1974,
	title = {A new look at the statistical model identification},
	volume = {19},
	journal = {IEEE Trans. Automat. Contr.},
	author = {Akaike, H},
	year = {1974},
	keywords = {merged\_fiete.bib},
	pages = {716--723},
}

@article{berg_physics_1977,
	title = {Physics of chemoreception},
	volume = {20},
	number = {2},
	journal = {Biophys. J.},
	author = {Berg, H C and Purcell, E M},
	year = {1977},
	note = {Publisher: Elsevier},
	keywords = {merged\_fiete.bib},
	pages = {193--219},
}

@article{vallee_lattice_2008,
	title = {Lattice reduction in two dimensions: analyses under realistic probabilistic models},
	number = {1},
	journal = {DMTCS Proceedings},
	author = {Vallée, Brigitte and Vera, Antonio},
	year = {2008},
	keywords = {merged\_fiete.bib},
}

@article{magnasco_chemical_1997,
	title = {Chemical kinetics is {Turing} universal},
	volume = {78},
	number = {6},
	journal = {Phys. Rev. Lett.},
	author = {Magnasco, M O},
	year = {1997},
	note = {Publisher: APS},
	keywords = {merged\_fiete.bib},
	pages = {1190--1193},
}

@article{goldenfeld_lectures_1992,
	title = {Lectures on phase transitions and the renormalization group},
	author = {Goldenfeld, Nigel},
	year = {1992},
	note = {Publisher: Addison-Wesley, Advanced Book Program, Reading},
	keywords = {merged\_fiete.bib},
}

@article{atay_distributed_2003,
	title = {Distributed delays facilitate amplitude death of coupled oscillators},
	volume = {91},
	number = {9},
	journal = {Phys. Rev. Lett.},
	author = {Atay, F M},
	year = {2003},
	note = {Publisher: APS},
	keywords = {merged\_fiete.bib},
	pages = {94101},
}

@article{lenstra_integer_1983,
	title = {Integer programming with a fixed number of variables},
	volume = {8},
	number = {4},
	journal = {Math. Oper. Res.},
	author = {Lenstra, Jr, Hendrik W},
	year = {1983},
	note = {Publisher: INFORMS},
	keywords = {merged\_fiete.bib},
	pages = {538--548},
}

@article{smolensky_information_1986,
	title = {Information processing in dynamical systems: {Foundations} of harmony theory},
	author = {Smolensky, Paul},
	year = {1986},
	note = {Publisher: Department of Computer Science, University of Colorado, Boulder},
	keywords = {merged\_fiete.bib},
}

@article{arrhenius_uber_1889,
	title = {Uber die {Dissociationswarme} und den {Einflus} der {Termperatur} auf den {Dissociationsgrad} der {Elktrolyte}},
	volume = {4},
	journal = {Physik. Chem.},
	author = {Arrhenius, S A},
	year = {1889},
	keywords = {merged\_fiete.bib},
	pages = {96--116},
}

@article{ott_low_2008,
	title = {Low dimensional behavior of large systems of globally coupled oscillators},
	journal = {Arxiv preprint arXiv:0806. 0004},
	author = {Ott, E and Antonsen, T M},
	year = {2008},
	keywords = {merged\_fiete.bib},
}

@article{stroud_population_1982,
	title = {Population dynamics of {Rattus} {Rattus} and {R}. {Norvegicus} in a riparian habitat},
	volume = {63},
	number = {1},
	journal = {Journal of Mammology},
	author = {Stroud, D},
	year = {1982},
	keywords = {merged\_fiete.bib},
	pages = {151--154},
}

@article{kumaran_which_2007,
	title = {Which computational mechanisms operate in the hippocampus during novelty detection?},
	volume = {17},
	number = {9},
	journal = {Hippocampus},
	author = {Kumaran, Dharshan and Maguire, Eleanor A},
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {735--748},
}

@article{cramer_contribution_1946,
	title = {A contribution to the theory of statistical estimation},
	volume = {29},
	journal = {Aktuariestidskrift},
	author = {Cramer, H},
	year = {1946},
	keywords = {merged\_fiete.bib},
	pages = {458--463},
}

@inproceedings{platt_analog_1986,
	title = {Analog decoding using neural networks},
	volume = {151},
	booktitle = {Neural networks for computing},
	publisher = {AIP Publishing},
	author = {Platt, J C and Hopfield, J J},
	year = {1986},
	keywords = {merged\_fiete.bib},
	pages = {364--369},
}

@article{russo_global_2010,
	title = {Global convergence of quorum-sensing networks},
	volume = {82},
	number = {4},
	journal = {Physical Review E},
	author = {Russo, G and Slotine, J J E},
	year = {2010},
	note = {Publisher: APS},
	keywords = {merged\_fiete.bib},
	pages = {041919},
}

@article{percus_equilibrium_1976,
	title = {Equilibrium state of a classical fluid of hard rods in an external field},
	volume = {15},
	journal = {J. Stat. Phys.},
	author = {Percus, Jerome},
	year = {1976},
	keywords = {merged\_fiete.bib},
}

@book{bishop_pattern_2006,
	title = {Pattern {Recognition} and {Machine} {Learning}},
	author = {Bishop, Chris},
	year = {2006},
	keywords = {merged\_fiete.bib},
}

@article{wilson_renormalization_1983,
	title = {The renormalization group and critical phenomena},
	volume = {55},
	number = {3},
	journal = {Rev. Mod. Phys.},
	author = {Wilson, Kenneth G},
	year = {1983},
	keywords = {merged\_fiete.bib},
	pages = {583--600},
}

@article{mahalanobis_generalized_nodate,
	title = {On the generalized distance in statistics},
	volume = {2050},
	journal = {Network},
	author = {Mahalanobis, P C},
	keywords = {merged\_fiete.bib},
	pages = {1},
}

@book{beard_chemical_2008,
	title = {Chemical biophysics: quantitative analysis of cellular systems},
	publisher = {Cambridge Univ Pr},
	author = {Beard, D A and Qian, H},
	year = {2008},
	keywords = {merged\_fiete.bib},
}

@article{wilson_renormalization_1974,
	title = {The renormalization group and the ? expansion},
	volume = {12},
	number = {2},
	journal = {Phys. Rep.},
	author = {Wilson, Kenneth G and Kogut, John},
	year = {1974},
	note = {Publisher: Elsevier},
	keywords = {merged\_fiete.bib},
	pages = {75--199},
}

@article{rao_information_1946,
	title = {Information and the accuracy attainable in the estimation of statistical parameters},
	volume = {37},
	journal = {Bull. Calcutta Math. Soc.},
	author = {Rao, C R},
	year = {1946},
	keywords = {merged\_fiete.bib},
	pages = {81--91},
}

@book{kadanoff_statics_2000,
	title = {Statics, {Dynamics} and {Renormalization}},
	publisher = {World Scientific},
	author = {Kadanoff, Leo P},
	year = {2000},
	keywords = {merged\_fiete.bib},
}

@article{gc_crowd_2005,
	title = {Crowd synchrony on the {Millennium} {Bridge}},
	volume = {438},
	journal = {Nature},
	author = {Gc, P},
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {3},
}

@phdthesis{fulan_hopfield_1988,
	type = {{PhD} {Thesis}},
	title = {A {Hopfield} network with exponential storage ability},
	school = {The Ohio State University},
	author = {Fulan, Mario Nicholas},
	year = {1988},
	keywords = {merged\_fiete.bib},
}

@book{ingham_distribution_1932,
	title = {The distribution of prime numbers},
	publisher = {Cambridge University Press},
	author = {Ingham, Albert Edward},
	year = {1932},
	keywords = {merged\_fiete.bib},
}

@article{bengio_learning_2009,
	title = {Learning deep architectures for {AI}},
	volume = {2},
	number = {1},
	journal = {Foundations and trends® in Machine Learning},
	author = {Bengio, Yoshua},
	year = {2009},
	note = {Publisher: Now Publishers Inc.},
	keywords = {merged\_fiete.bib},
	pages = {1--127},
}

@book{jackson_wild_1982,
	title = {Wild {Mammals} of {North} {America}},
	publisher = {Johns Hopkins University Press, Baltimore MD},
	author = {Jackson, W},
	year = {1982},
	keywords = {merged\_fiete.bib},
}

@article{rabiner_tutorial_1989,
	title = {A tutorial on hidden {Markov} models and selected applications in speech recognition},
	journal = {Proc. IEEE},
	author = {Rabiner, Lawrence},
	year = {1989},
	keywords = {merged\_fiete.bib},
	pages = {257--286},
}

@article{gilmore_introduction_2006,
	title = {Introduction to {NF}-{kB}: players, pathways, perspectives},
	volume = {25},
	journal = {Oncogene},
	author = {Gilmore, T D},
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {6680--6684},
}

@article{kosko_bidirectional_1988,
	title = {Bidirectional associative memories},
	volume = {18},
	number = {1},
	journal = {Systems, Man and Cybernetics, IEEE Transactions on},
	author = {Kosko, Bart},
	year = {1988},
	note = {Publisher: IEEE},
	keywords = {merged\_fiete.bib},
	pages = {49--60},
}

@book{strogatz_sync_2003,
	title = {Sync: {The} emerging science of spontaneous order},
	publisher = {Hyperion},
	author = {Strogatz, S H},
	year = {2003},
	keywords = {merged\_fiete.bib},
}

@article{bennett_thermodynamics_1982,
	title = {The thermodynamics of computation—a review},
	volume = {21},
	number = {12},
	journal = {Int. J. Theor. Phys.},
	author = {Bennett, C H},
	year = {1982},
	note = {Publisher: Springer},
	keywords = {merged\_fiete.bib},
	pages = {905--940},
}

@book{leff_maxwells_2003,
	title = {Maxwell's {Demon} 2: {Entropy}, {Classical} and {Quantum} {Information}, {Computing}},
	publisher = {Institute of Physics (Bristol)},
	author = {Leff, H S and Rex, A F},
	year = {2003},
	keywords = {merged\_fiete.bib},
}

@article{shannon_mathematical_1948,
	title = {A {Mathematical} {Theory} of {Communication}},
	volume = {27},
	journal = {The Bell System Technical Journal},
	author = {Shannon, C E},
	year = {1948},
	keywords = {merged\_fiete.bib},
	pages = {379--423, 623--656},
}

@misc{mackay_gallager_1999,
	title = {Gallager codes - {Recent} {Results}},
	author = {Mackay, David J C},
	year = {1999},
	keywords = {merged\_fiete.bib},
}

@article{brunel_mutual_1998,
	title = {Mutual {Information}, {Fisher} {Information}, and {Population} {Coding}},
	volume = {10},
	number = {7},
	journal = {Neural Comput.},
	author = {Brunel, N and Nadal, J-P},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {1731--1757},
}

@article{smith_information_1971,
	title = {The information capacity of amplitude- and variance-constrained sclar gaussian channels},
	volume = {18},
	number = {3},
	journal = {Information and Control},
	author = {Smith, J G},
	year = {1971},
	keywords = {merged\_fiete.bib},
	pages = {203--219},
}

@article{kish_end_2002,
	title = {End of {Moore}'s {Law}: {Thermal} ({Noise}) {Death} of {Integration} in {Micro} and {Nano} {Electronics}},
	volume = {305},
	journal = {Phys. Lett. A},
	author = {Kish, L},
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {144--149},
}

@article{zhang_neuronal_1999,
	title = {Neuronal tuning: to sharpen or broaden?},
	volume = {11},
	number = {1},
	journal = {Neural Comput.},
	author = {Zhang, K and Sejnowski, T},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {75--84},
}

@book{cover_elements_1991,
	title = {Elements of {Information} {Theory}},
	publisher = {Wiley \& Sons},
	author = {Cover, Thomas M and Thomas, Joy A},
	year = {1991},
	keywords = {merged\_fiete.bib},
}

@inproceedings{oster_spiking_2005,
	title = {Spiking {Inputs} to a {Winner}-take-all {Network}},
	booktitle = {{NIPS}},
	author = {Oster, Matthias and Liu, Shih-Chii},
	year = {2005},
	keywords = {merged\_fiete.bib},
}

@article{szilard_reduction_1929,
	title = {On the reduction of entropy in a thermodynamic system by the interference of intelligent beings},
	volume = {53},
	journal = {Z. Physik},
	author = {Szilard, L},
	year = {1929},
	keywords = {merged\_fiete.bib},
	pages = {840--856},
}

@book{feynman_feynman_1963,
	title = {The {Feynman} {Lectures} on {Physics}},
	publisher = {Addison Wesley},
	author = {Feynman, Richard and Leighton, Robert and Sands, Matthew},
	year = {1963},
	keywords = {merged\_fiete.bib},
}

@article{taplin_reverse_1998,
	title = {The reverse {Kalman} filter},
	volume = {27},
	number = {10},
	journal = {Commun. Statist. – Theory methods},
	author = {Taplin, Ross H},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {2547--2558},
}

@article{landauer_inadequacy_1975,
	title = {Inadequacy of entropy and entropy derivatives in characterizing the steady state},
	volume = {12},
	number = {2},
	journal = {Phys. Rev. A},
	author = {Landauer, Rolf},
	year = {1975},
	keywords = {merged\_fiete.bib},
	pages = {636--638},
}

@article{hayman_generating_2008,
	title = {Generating hippocampal place fields from entorhinal grids},
	volume = {18},
	number = {12},
	journal = {Hippocampus},
	author = {Hayman, R and Jeffery, Kathryn J},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {XXX--XXX},
}

@book{vankampen_stochastic_1981,
	title = {Stochastic {Processes} in {Physics} and {Chemistry}},
	publisher = {Elsevier},
	author = {VanKampen, N G},
	year = {1981},
	keywords = {merged\_fiete.bib},
}

@article{moser_metric_2008,
	title = {A metric for space},
	volume = {18},
	number = {12},
	journal = {Hippocampus},
	author = {Moser, Edvard I and Moser, M-B},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {X--XX},
}

@book{cardy_scaling_1996,
	title = {Scaling and renormalization in statistical physics},
	volume = {5},
	publisher = {Cambridge University Press},
	author = {Cardy, John},
	year = {1996},
	keywords = {merged\_fiete.bib},
}

@book{kuramoto_chemical_2003,
	title = {Chemical oscillations, waves, and turbulence},
	publisher = {Dover Pubns},
	author = {Kuramoto, Y},
	year = {2003},
	keywords = {merged\_fiete.bib},
}

@article{bengio_scaling_2007,
	title = {Scaling learning algorithms towards {AI}},
	volume = {34},
	journal = {Large-scale kernel machines},
	author = {Bengio, Yoshua and Yann, Lecun},
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {1--41},
}

@inproceedings{c_roth_kernel_2019,
	title = {Kernel {RNN} {Learning} ({KeRNL})},
	booktitle = {{ICLR}},
	author = {C. Roth, I. Kanitscheider, I R Fiete},
	year = {2019},
	keywords = {merged\_fiete.bib},
}

@article{kropff_emergence_2008,
	title = {The emergence of grid cells: intelligent design or just adaptation?},
	volume = {18},
	number = {12},
	journal = {Hippocampus},
	author = {Kropff, E and Treves, A},
	year = {2008},
	keywords = {merged\_fiete.bib},
}

@article{wasserman_topological_2018,
	title = {Topological data analysis},
	volume = {5},
	journal = {Annual Reviews of Statistics and Its Application},
	author = {Wasserman, L},
	year = {2018},
	keywords = {merged\_fiete.bib},
}

@article{cavers_variable-rate_1972,
	title = {Variable-{Rate} {Transmission} for {Rayleigh} {Fading} {Channels}},
	volume = {20},
	number = {1},
	journal = {Communications, IEEE Transactions on},
	author = {Cavers, J},
	month = feb,
	year = {1972},
	keywords = {merged\_fiete.bib},
	pages = {15--22},
}

@book{el_gamal_network_2011,
	title = {Network {Information} {Theory}},
	publisher = {Cambridge University Press},
	author = {El Gamal, A and Kim, Y H},
	year = {2011},
	keywords = {merged\_fiete.bib},
}

@article{burgess_grid_2008,
	title = {Grid cells and theta as oscillatory interference: theory and predictions},
	volume = {18},
	number = {12},
	journal = {Hippocampus},
	author = {Burgess, Neil},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {XXX--XXX},
}

@book{galbraith_mathematics_2012,
	title = {Mathematics of public key cryptography},
	publisher = {Cambridge University Press},
	author = {Galbraith, Steven D},
	year = {2012},
	keywords = {merged\_fiete.bib},
}

@book{dragotti_distributed_2009,
	title = {Distributed {Source} {Coding}: {Theory}, {Algorithms} and {Applications}},
	publisher = {Academic Press},
	author = {Dragotti, Pier Luigi and Gastpar, Michael},
	year = {2009},
	keywords = {merged\_fiete.bib},
}

@article{bengio_justifying_2009,
	title = {Justifying and generalizing contrastive divergence},
	volume = {21},
	number = {6},
	journal = {Neural Comput.},
	author = {Bengio, Y and Delalleau, O},
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {1601--1621},
}

@book{hubel_eye_1988,
	title = {Eye, {Brain}, and {Vision}},
	publisher = {Scientific American Library},
	author = {Hubel, David},
	year = {1988},
	keywords = {merged\_fiete.bib},
}

@article{noauthor_homing_2003,
	title = {Homing by path integration in a new environment},
	volume = {65},
	journal = {Animal Behavior},
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {185--194},
}

@article{robinson_effect_1974,
	title = {The effect of cerebellectomy on the cat's bestibulo-ocular integrator},
	volume = {71},
	number = {2-3},
	journal = {Brain Res.},
	author = {Robinson, D A},
	month = may,
	year = {1974},
	keywords = {merged\_fiete.bib},
	pages = {195--207},
}

@article{long_using_2008,
	title = {Using temperature to analyse temporal dynamics in the songbird motor pathway},
	volume = {456},
	journal = {Nature},
	author = {Long, M A and Fee, M S},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {189--194},
}

@article{noauthor_calcium_2000,
	title = {Calcium stores regulate the polarity and input specificity of synaptic modifcation},
	volume = {408},
	journal = {Nature},
	year = {2000},
	keywords = {merged\_fiete.bib},
}

@book{murray_mathematical_1993,
	address = {Berlin},
	edition = {2nd},
	title = {Mathematical {Biology}},
	publisher = {Springer},
	author = {Murray, James Dickson},
	year = {1993},
	keywords = {merged\_fiete.bib},
}

@article{sharp_computer_1991,
	title = {Computer simulation of hippocampal place cells},
	volume = {19},
	journal = {Psychobiology},
	author = {Sharp, P E},
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {103--115},
}

@article{abbot_synaptic_2000,
	title = {Synaptic plasticity: taming the beast},
	volume = {3},
	journal = {Nature},
	author = {Abbot, L and Nelson, S},
	year = {2000},
	keywords = {merged\_fiete.bib},
}

@article{prescott_spatial_1996,
	title = {Spatial representation for navigation in animats},
	volume = {4},
	number = {2},
	journal = {Adapt. Behav.},
	author = {Prescott, T J},
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {85--123},
}

@inproceedings{heys_cellular_2014,
	title = {Cellular resolution optical imaging of medial entorhinal cortex},
	booktitle = {{SFN} {Poster}},
	author = {Heys, J and Dombeck, D},
	year = {2014},
	keywords = {merged\_fiete.bib},
}

@incollection{noauthor_intrinsic_1999,
	series = {Advances in {Oto}-{Rhino}-{Laryngology}},
	title = {Intrinsic {Physiological} and {Pharmacological} {Properties} of {Central} {Vestibular} {Neurons}},
	volume = {55},
	booktitle = {Vestibular {Dysfunction} and {Its} {Therapy}},
	publisher = {Karger},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {26--81},
}

@article{hasselmo_role_2006,
	title = {The role of acetylcholine in learning and memory},
	volume = {16},
	journal = {Curr. Opin. Neurobiol.},
	author = {Hasselmo, M E},
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {710--715},
}

@misc{sloane_-line_nodate,
	title = {The {On}-{Line} {Encyclopedia} of {Integer} {Sequences}},
	author = {Sloane, N J A},
	keywords = {merged\_fiete.bib},
}

@article{goodman_developmental_1993,
	title = {Developmental mechanisms that generate precise patterns of neuronal connectivity},
	volume = {72 Suppl},
	journal = {Cell},
	author = {Goodman, C S and Shatz, C J},
	month = jan,
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {77--98},
}

@incollection{sudan_applied_2001,
	title = {Applied {Algebra}, {Algebraic} {Algorithms} and {Error}-{Correcting} {Codes}},
	volume = {2227},
	publisher = {Springer Berlin/Heidelberg},
	author = {Sudan, Madhu},
	year = {2001},
	note = {Section: Ideal Error-Correcting Codes: Unifying Algebraic and Number-Theoretic Algorithms},
	keywords = {merged\_fiete.bib},
	pages = {36--45},
}

@article{lavenex_olfactory_1998,
	title = {Olfactory traces and spatial learning in rats},
	volume = {56},
	number = {5},
	journal = {Animal Behavior},
	author = {Lavenex, P and Schenk, F},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {1129--1136},
}

@article{barry_z_2012,
	title = {From {A} to {Z}: a potential role for grid cells in spatial navigation},
	volume = {2},
	journal = {Neural Syst. Circuits},
	author = {Barry, C and Bush, D},
	year = {2012},
	keywords = {merged\_fiete.bib},
}

@article{laing_spiking_nodate,
	title = {A spiking neuron model for binocular rivalry},
	author = {Laing, Carlo and Chow, Carson},
	keywords = {merged\_fiete.bib},
}

@book{abeles_corticonics_1991,
	title = {Corticonics},
	publisher = {London: Cambridge University Press},
	author = {Abeles, M},
	year = {1991},
	keywords = {merged\_fiete.bib},
}

@incollection{wang_relaxation_1999,
	title = {Relaxation {Oscillators} and {Networks}},
	volume = {18},
	booktitle = {Wiley {Encyclopedia} of {Electrical} and {Electronics} {Engineering}},
	publisher = {Wiley \& Sons},
	author = {Wang, Deliang},
	editor = {Webster, J G},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {396--405},
}

@article{hasselmo_grid_2008,
	title = {Grid cell mechanisms and function: {Contributions} of entorhinal persistent spiking and phase resetting},
	volume = {18},
	number = {12},
	journal = {Hippocampus},
	author = {Hasselmo, Michael E},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {XXX--XXX},
}

@book{koch_biophysics_1999,
	address = {New York, New York 10016},
	title = {Biophysics of {Computation}: {Information} {Processing} in {Single} {Neurons}},
	publisher = {Oxford University Press},
	author = {Koch, Christof},
	year = {1999},
	keywords = {merged\_fiete.bib},
}

@book{cordo_movement_1994,
	title = {Movement {Control}},
	publisher = {Cambridge University Press},
	editor = {Cordo, Paul and Harnad, Stevan},
	year = {1994},
	keywords = {Jun 12 import},
}

@article{hadeler_stationary_1987,
	title = {Stationary states of the {Hartline}-{Ratliff} model},
	volume = {56},
	number = {5/6},
	journal = {Biological-Cybernetics},
	author = {Hadeler, K p and Kuhn, D},
	year = {1987},
	keywords = {merged\_fiete.bib},
	pages = {411--447},
}

@book{darwin_descent_1871,
	title = {The descent of man, and selection in relation to sex},
	publisher = {London: John Murray},
	author = {Darwin, C R},
	year = {1871},
	keywords = {merged\_fiete.bib},
}

@book{bishop_neural_1995,
	title = {Neural networks for pattern recognition},
	publisher = {Oxford Univ Press Inc,New York},
	author = {Bishop, C M},
	year = {1995},
	keywords = {merged\_fiete.bib},
}

@inproceedings{niebur_control_1996,
	title = {Control of {Selective} {Visual} {Attention}: {Modeling} the “{Where}” {Pathway}},
	publisher = {David Touretzky, Michael Mozer, Mark Hasselmo (eds), MIT Press},
	author = {Niebur, E and Koch, C},
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {802, volume 8},
}

@article{robinson_integrating_1989,
	title = {Integrating with neurons},
	volume = {12},
	journal = {Annu. Rev. Neurosci.},
	author = {Robinson, D A},
	year = {1989},
	keywords = {merged\_fiete.bib},
	pages = {33--45},
}

@article{hadeler_theory_1974,
	title = {On the theory of lateral inhibition},
	volume = {14},
	number = {3},
	journal = {Kybernetik},
	author = {Hadeler, Kp},
	month = mar,
	year = {1974},
	keywords = {merged\_fiete.bib},
	pages = {161--165},
}

@inproceedings{stevens_when_1996,
	title = {When is an {Integrate}-and-fire {Neuron} like a {Poisson} {Neuron}?},
	booktitle = {In},
	publisher = {MIT Press},
	author = {Stevens, Charles and Zador, Anthony},
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {103--109},
}

@book{dayan_theoretical_2001,
	title = {Theoretical {Neuroscience}},
	publisher = {MIT Press},
	author = {Dayan, Peter and Abbott, Larry},
	year = {2001},
	keywords = {merged\_fiete.bib},
}

@article{wickelgren_teaching_1998,
	title = {Teaching the spinal cord to walk},
	volume = {279},
	number = {5349},
	journal = {Science},
	author = {Wickelgren, I},
	month = jan,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {319--321},
}

@book{mcmahon_muscles_1984,
	title = {Muscles, {Reflexes}, and {Locomotion}},
	publisher = {Princeton University Press},
	author = {McMahon, Thomas A},
	month = may,
	year = {1984},
	keywords = {Jun 12 import},
}

@incollection{immelmann_notitle_1969-1,
	booktitle = {Bird {Vocalizations}},
	publisher = {Cambridge Univ. Press, New York},
	author = {Immelmann, K},
	editor = {Hinde, R A},
	year = {1969},
	keywords = {Jun 12 import},
	pages = {61--74},
}

@article{kuo_optimal_1995,
	title = {An {Optimal} {Control} {Model} for {Analyzing} {Human} {Postural} {Balance}},
	volume = {42},
	number = {1},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Kuo, Arthur D},
	month = jan,
	year = {1995},
	keywords = {Jun 12 import},
	pages = {87--101},
}

@article{marr_theory_1969,
	title = {A theory of cerebellar cortex},
	volume = {202},
	number = {2},
	journal = {J. Physiol.},
	author = {Marr, D},
	month = jun,
	year = {1969},
	keywords = {Jun 12 import},
	pages = {437--470},
}

@article{yu_temporal_1986-1,
	title = {Temporal hierarchical control of singing in birds},
	volume = {273},
	journal = {Science},
	author = {Yu, A C and Margoliash, D},
	year = {1986},
	keywords = {Jun 12 import},
	pages = {1871--1875},
}

@article{robinson_use_1981,
	title = {The {Use} of {Control} {Systems} {Analysis} in the {Neurophysiology} of {Eye} {Movements}},
	volume = {4},
	journal = {Annual Reviews of Neuroscience},
	author = {Robinson, D A},
	year = {1981},
	keywords = {Jun 12 import},
	pages = {463--503},
}

@article{atkeson_learning_1989,
	title = {Learning {Arm} {Kinematics} and {Dynamics}},
	volume = {12},
	journal = {Annu. Rev. Neurosci.},
	author = {Atkeson, Christopher G},
	year = {1989},
	keywords = {Jun 12 import},
	pages = {157--183},
}

@book{brooks_neural_1999,
	edition = {1st},
	title = {The {Neural} {Basis} of {Motor} {Control}},
	publisher = {Oxford University Press, Inc.},
	author = {Brooks, Vernon B},
	month = apr,
	year = {1999},
	keywords = {Jun 12 import},
}

@phdthesis{todorov_studies_1998,
	type = {{PhD} {Thesis}},
	title = {Studies of {Goal} {Directed} {Movements}},
	author = {Todorov, Emanuel},
	year = {1998},
	keywords = {Jun 12 import},
}

@article{leonardo_uncorrelated_2002,
	title = {Uncorrelated neural ensembles encode similar vocal outputs in a songbird},
	journal = {In preparation},
	author = {Leonardo, A and Fee, M S},
	year = {2002},
	keywords = {Jun 12 import},
}

@misc{whittle_review_2001,
	title = {Review {Articles} in {Gait} and {Posture}},
	author = {Whittle, Michael W},
	year = {2001},
	note = {Publication Title: Gait and Posture},
	keywords = {Jun 12 import},
}

@article{borst_how_1990,
	title = {How {Do} {Flies} {Land}? {From} behavior to neuronal circuits},
	volume = {40},
	number = {4},
	journal = {Bioscience},
	author = {Borst, Alexander},
	month = apr,
	year = {1990},
	keywords = {Jun 12 import},
	pages = {292--299},
}

@article{bizzi_acquisition_1998,
	title = {The {Acquisition} of {Motor} {Behavior}},
	volume = {127},
	number = {2},
	journal = {Daedalus},
	author = {Bizzi, Emilio and Mussa-Ivaldi, Ferdinando},
	year = {1998},
	keywords = {Jun 12 import},
	pages = {217--232},
}

@article{eliasmith_unified_2005,
	title = {A unified approach to building and controlling spiking attractor networks},
	volume = {17},
	journal = {Neural Comput.},
	author = {Eliasmith, C},
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {1276--1314},
}

@article{schmajuk_role_1990,
	title = {Role of the hippocampus in temporal and spatial navigation: an adaptive neural network},
	volume = {39},
	journal = {Behav. Brain Res.},
	author = {Schmajuk, N A},
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {205--229},
}

@article{kempter_hebbian_1999,
	title = {Hebbian learning and spiking neurons},
	volume = {59},
	number = {4},
	journal = {Phys Rev E},
	author = {Kempter, R and Gerstner, W and van Hemmen, J L},
	year = {1999},
	keywords = {merged\_fiete.bib},
}

@book{gerstner_spking_2002,
	title = {Spking {Neuron} {Models}},
	publisher = {Cambridge University Press},
	author = {Gerstner, Gerstner and Kistler, Werner M},
	year = {2002},
	keywords = {merged\_fiete.bib},
}

@article{das_orientation_nodate,
	title = {Orientation in visual cortex: a simple mechanism emerges},
	author = {Das, A},
	keywords = {merged\_fiete.bib},
}

@book{noauthor_httpenwikipediaorgwikierror-correcting_code_2009,
	title = {http://en.wikipedia.org/wiki/{Error}-correcting\_code},
	publisher = {Wikipedia},
	year = {2009},
	keywords = {merged\_fiete.bib},
}

@article{rossier_notitle_nodate,
	author = {Rossier, J and {H}},
	keywords = {merged\_fiete.bib},
}

@article{hammer_identified_1993,
	title = {An identified neuron mediates the unconditioned stimulus in associative olfactory learning in honeybees},
	volume = {366},
	journal = {Nature},
	author = {Hammer, M},
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {59--63},
}

@article{heeger_normalization_1992,
	title = {Normalization of cell responses in cat striate cortex},
	volume = {9},
	journal = {Vis. Neurosci.},
	author = {Heeger, D J},
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {181--197},
}

@article{cross_pattern_1993,
	title = {Pattern formation outside of equilibrium},
	volume = {65},
	number = {3},
	journal = {Rev. Mod. Phys.},
	author = {Cross, M C and Hohenberg, P C},
	year = {1993},
	keywords = {merged\_fiete.bib},
}

@article{feldman_spike-timing_2012,
	title = {The spike-timing dependence of plasticity},
	volume = {75},
	journal = {Neuron},
	author = {Feldman, D E},
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {556--571},
}

@article{hinton_training_2002,
	title = {Training products of experts by minimizing contrastive divergence},
	volume = {14},
	number = {1771-1800},
	journal = {Neural Comput.},
	author = {Hinton, G E},
	year = {2002},
	keywords = {merged\_fiete.bib},
}

@article{noauthor_multiple_nodate,
	title = {Multiple bumps in working model of working memory},
	keywords = {merged\_fiete.bib},
}

@article{noauthor_two_1997,
	title = {Two {Distinct} {Forms} of {Long}-{Term} {Depression} {Coexist} in {CA1} {Hippocampal} {Pyramidal} {Cells}},
	volume = {18},
	journal = {Neuron},
	month = jun,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {969--982},
}

@article{reynolds_normalization_2009,
	title = {The normalization model of attention},
	volume = {61},
	journal = {Neuron},
	author = {Reynolds, J H and Heeger, D J},
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {168--185},
}

@article{feldman_timing-based_2000,
	title = {Timing-based {LTP} and {LTD} at vertical inputs to layer {II}/{III} pyramidal cells in rat barrel cortex},
	volume = {27},
	journal = {Neuron},
	author = {Feldman, D E},
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {45--56},
}

@article{boynton_visual_1970,
	title = {Visual adaption in monkey cones: recordings of late receptor potentials},
	volume = {170},
	journal = {Science},
	author = {Boynton, R M and Whitten, D N},
	year = {1970},
	keywords = {merged\_fiete.bib},
	pages = {1423--1426},
}

@book{okeefe_hippocampus_1978,
	title = {The hippocampus as a cognitive map},
	publisher = {Oxford University Press, Oxford},
	author = {O'Keefe, J and Nadel, L},
	year = {1978},
	keywords = {merged\_fiete.bib},
}

@article{zipser_computational_1985,
	title = {A computational model of hippocampal place fields},
	volume = {99},
	number = {5},
	journal = {Behav. Neurosci.},
	author = {Zipser, D},
	year = {1985},
	keywords = {merged\_fiete.bib},
	pages = {1006--1018},
}

@article{florian_reinforcement_2007,
	title = {Reinforcement {Learning} {Through} {Modulation} of {Spike}-{Timing}-{Dependent} {Synaptic} {Plasticity}},
	volume = {19},
	journal = {Neural Comput.},
	author = {Florian, Razvan V},
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {1468--1502},
}

@article{reid_functional_2012,
	title = {From {Functional} {Architecture} to {Functional} {Connectomics}},
	volume = {75},
	journal = {Neuron},
	author = {Reid, R Clay},
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {209--217},
}

@book{murray_mathematical_2003,
	address = {Berlin},
	title = {Mathematical {Biology}},
	publisher = {Springer},
	author = {Murray, James Dickson},
	year = {2003},
	keywords = {merged\_fiete.bib},
}

@article{stuart_determinants_2001,
	title = {Determinants of {Spike} {Timing}-{Dependent} {Synaptic} {Plasticity}},
	volume = {32},
	journal = {Neuron},
	author = {Stuart, Greg J},
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {966--968},
}

@article{brecht_microcircuits_2011,
	title = {Microcircuits of {Functionally} {Identified} {Neurons} in the {Rat} {Medial} {Entorhinal} {Cortex}},
	volume = {70},
	journal = {Neuron},
	author = {Brecht, Michael},
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {773--786},
}

@book{abbott_neural_1999,
	title = {Neural {Codes} and {Distributed} {Representations}},
	publisher = {MIT Press, Cambridge},
	editor = {Abbott, L and Sejnowski, T J},
	year = {1999},
	keywords = {merged\_fiete.bib},
}

@article{leonardo_uncorrelated_2002-1,
	title = {Uncorrelated neural ensembles encode similar vocal outputs in a songbird},
	journal = {In preparation},
	author = {Leonardo, A and Fee, M S},
	year = {2002},
	keywords = {birdpaper.bib},
}

@article{albus_theory_1971,
	title = {A {Theory} of {Cerebellar} {Function}},
	volume = {10},
	journal = {Math. Biosci.},
	author = {Albus, James S},
	year = {1971},
	keywords = {Jun 12 import},
	pages = {25--61},
}

@book{bernstein_coordination_1967,
	title = {The {Coordination} and {Regulation} of {Movement}},
	publisher = {London: Pergamon Press},
	author = {Bernstein, N},
	year = {1967},
	keywords = {Jun 12 import},
}

@article{winter_human_1995,
	title = {Human balance and posture control during standing and walking},
	volume = {3},
	number = {4},
	journal = {Gait and Posture},
	author = {Winter, D A},
	year = {1995},
	keywords = {Jun 12 import},
	pages = {193--214},
}

@book{leigh_neurology_1999,
	edition = {Third},
	title = {The {Neurology} of {Eye} {Movements}},
	publisher = {Oxford University Press},
	editor = {Leigh, R John and Zee, David S},
	year = {1999},
	keywords = {Jun 12 import},
}

@book{alexander_mechanics_1977,
	title = {Mechanics and {Energetics} of {Animal} {Locomotion}},
	publisher = {Chapman \& Hall},
	editor = {Alexander, R Mcneill and Goldspink, Geoffrey},
	month = oct,
	year = {1977},
	keywords = {Jun 12 import},
}

@incollection{jordan_computational_1996,
	title = {Computational aspects of motor control and motor learning},
	booktitle = {Handbook of {Perception} and {Action}: {Motor} {Skills}},
	publisher = {New York: Academic Press},
	author = {Jordan, Michael I},
	year = {1996},
	keywords = {Jun 12 import},
}

@article{feldman_once_1986,
	title = {Once {More} on the {Equilibrium}-{Point} {Hypothesis} ({Lambda} {Model}) for {Motor} {Control}},
	volume = {18},
	number = {1},
	journal = {J. Mot. Behav.},
	author = {Feldman, Anatol G},
	year = {1986},
	keywords = {Jun 12 import},
	pages = {17--54},
}

@article{robinson_is_1986,
	title = {Is the oculomotor system a cartoon of motor control?},
	volume = {64},
	journal = {Prog. Brain Res.},
	author = {Robinson, David A},
	year = {1986},
	keywords = {Jun 12 import},
	pages = {411--417},
}

@misc{slotine_study_2003,
	title = {A {Study} of {Synchronization} and {Group} {Cooperation} {Using} {Partial} {Contraction} {Theory}},
	author = {Slotine, Jean-Jacques E and Wang, Wei},
	year = {2003},
	note = {Published: Block Island Workshop on Cooperative Control, Kumar V. Editor, Springer-Verlag, 2003.},
	keywords = {merged\_fiete.bib},
}

@book{gerstner_spiking_2002,
	title = {Spiking {Neuron} {Models}},
	publisher = {Cambridge University Press},
	author = {Gerstner, W and Kistler, W M},
	year = {2002},
	keywords = {merged\_fiete.bib},
}

@article{noauthor_dynamics_2001,
	title = {Dynamics of travelling waves in visual perception},
	journal = {Nature},
	year = {2001},
	keywords = {merged\_fiete.bib},
}

@incollection{seung_amplification_2003,
	title = {Amplification, {Attenuation}, and {Integration}},
	booktitle = {The {Handbook} of {Brain} {Theory} and {Neural} {Networks}: {Second} {Edition}},
	publisher = {MIT Press},
	author = {Seung, H S},
	editor = {Arbib, M A},
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {94--97},
}

@article{marler_culturally_1964,
	title = {Culturally transmitted patterns of vocal behavior in sparrows},
	volume = {146},
	journal = {Science},
	author = {Marler, P and Tamura, M},
	month = dec,
	year = {1964},
	keywords = {merged\_fiete.bib},
	pages = {1483--6.},
}

@inproceedings{buice_fluctuations_2012,
	title = {Fluctuations in attractor networks},
	booktitle = {{CoSyNe} {Abstracts}},
	author = {Buice, M A and Fiete, I R},
	year = {2012},
	keywords = {merged\_fiete.bib},
}

@incollection{lifshitz_introduction_1995,
	title = {Introduction to {Fourier}-space crystallography},
	booktitle = {Lecture notes for the {International} {School} on {Quasicrystals}},
	author = {Lifshitz, R},
	year = {1995},
	keywords = {merged\_fiete.bib},
}

@article{katz_quasiperiodic_1985,
	title = {Quasiperiodic {Patterns}},
	volume = {46},
	number = {12},
	journal = {Journal de Physique},
	author = {Katz, A and Duneau, M},
	year = {1985},
	keywords = {merged\_fiete.bib},
	pages = {C8--31},
}

@book{ashby_introduction_1957,
	edition = {Internet (1999)},
	title = {An {Introduction} to {Cybernetics}},
	publisher = {Chapman \& Hall},
	author = {Ashby, W Ross},
	year = {1957},
	keywords = {merged\_fiete.bib},
}

@article{amari_competition_1977,
	title = {Competition and {Cooperation} in {Neural} {Nets}},
	journal = {Systems Neuroscience, Academic Press, J. Metzler (ed).},
	author = {Amari, Shun-Ichi and Arbib, Michael A},
	year = {1977},
	keywords = {merged\_fiete.bib},
	pages = {119--165},
}

@book{klopf_hedonistic_1982,
	title = {The hedonistic neuron: a theory of memory, learning, and intelligence},
	publisher = {Hemisphere/Harper \& Row, Washington, D.C.},
	author = {Klopf, A H},
	year = {1982},
	keywords = {merged\_fiete.bib},
}

@article{rosen_theoretical_1972,
	title = {A theoretical neural integrator},
	volume = {19},
	number = {5},
	journal = {IEEE Trans. Biomed. Eng.},
	author = {Rosen, Mj},
	month = sep,
	year = {1972},
	keywords = {merged\_fiete.bib},
	pages = {362--367},
}

@book{alexander_optima_1996,
	edition = {Revised},
	title = {Optima for {Animals}},
	publisher = {Princeton University Press},
	author = {Alexander, R Mcneill},
	year = {1996},
	keywords = {Jun 12 import},
}

@book{latash_neurophysiological_1980,
	edition = {1st},
	title = {Neurophysiological {Basis} of {Movement}},
	publisher = {Human Kinetics Publishers},
	author = {Latash, Mark L},
	month = jan,
	year = {1980},
	keywords = {Jun 12 import},
}

@article{todorov_optimality_2004,
	title = {Optimality principles in sensorimotor control},
	volume = {7},
	number = {9},
	journal = {Nat. Neurosci.},
	author = {Todorov, Emanuel},
	year = {2004},
	keywords = {Jun 12 import},
	pages = {907--915},
}

@article{edwards_notitle_1976,
	volume = {9},
	journal = {J Physics A},
	author = {Edwards, S F and Jones, R C},
	year = {1976},
	keywords = {Jun 12 import},
	pages = {1595},
}

@book{sutton_reinforcement_1998-1,
	title = {Reinforcement {Learning}: {An} {Introduction}},
	publisher = {MIT Press},
	author = {Sutton, Richard S and Barto, Andrew G},
	year = {1998},
	keywords = {Jun 12 import},
}

@book{duda_pattern_1997,
	edition = {2nd},
	title = {Pattern {Classifcation}},
	author = {Duda, Richard O and Hart, Peter E and Stork, David G},
	month = sep,
	year = {1997},
	keywords = {Jun 12 import},
}

@article{tsung_phase-space_1995,
	title = {Phase-space learning},
	journal = {NIPS},
	author = {Tsung, Fu-Sheng and Cottrell, Garrison W},
	year = {1995},
	keywords = {Jun 12 import},
}

@article{baxter_direct_1999-1,
	title = {Direct {Gradient}-{Based} {Reinforcement} {Learning}: {II}. {Gradient} {Ascent} {Algorithms} and {Experiments}},
	author = {Baxter, J},
	month = nov,
	year = {1999},
	keywords = {Jun 12 import},
	pages = {1--29},
}

@article{girosi_equivalence_1998-1,
	title = {An {Equivalence} between {Sparse} {Approximation} and {Support} {Vector} {Machines}},
	volume = {10},
	journal = {Neural Comput.},
	author = {Girosi, F},
	year = {1998},
	keywords = {MachineLearning.bib},
	pages = {1455--1480},
}

@unpublished{nikovski_fast_1997,
	title = {Fast reinforcement learning in continuous action spaces},
	author = {Nikovski, Daniel N},
	year = {1997},
	keywords = {Jun 12 import},
}

@book{duda_pattern_1997-1,
	edition = {2nd},
	title = {Pattern {Classifcation}},
	author = {Duda, Richard O and Hart, Peter E and Stork, David G},
	month = sep,
	year = {1997},
	keywords = {MachineLearning.bib},
}

@book{fogel_evolutionary_2000,
	edition = {Second},
	title = {Evolutionary {Computation}: {Toward} a {New} {Philosophy} of {Machine} {Intelligence} (chapter 4)},
	publisher = {IEEE Press},
	author = {Fogel, David B},
	year = {2000},
	keywords = {Jun 12 import},
}

@article{beer_dynamical_2000,
	title = {Dynamical {Approaches} to {Cognitive} {Science}},
	volume = {4},
	number = {3},
	journal = {Trends Cogn. Sci.},
	author = {Beer, Randall D},
	year = {2000},
	keywords = {Jun 12 import},
	pages = {91--99},
}

@article{kaplan_clarity_1999,
	title = {The {Clarity} {Mechanism}: {Negotiating} a {Potentially} {Overwhelming} {World}},
	author = {Kaplan, Stephen and Ivancich, John Eric},
	month = feb,
	year = {1999},
	keywords = {Jun 12 import},
}

@phdthesis{iii_reinforcement_1999,
	type = {{PhD} {Thesis}},
	title = {Reinforcement {Learning} {Through} {Gradient} {Descent}},
	author = {Iii, Leemon C Baird},
	year = {1999},
	keywords = {Jun 12 import},
}

@article{dayan_feudal_nodate,
	title = {Feudal {Reinforcement} {Learning}},
	journal = {NIPS},
	author = {Dayan, Peter and Hinton, Geoffrey E},
	keywords = {Jun 12 import},
}

@article{cauwenberghs_fast_1993,
	title = {A fast stochastic error-descent algorithm for supervised learning and optimization},
	journal = {NIPS},
	author = {Cauwenberghs, G},
	year = {1993},
	keywords = {Jun 12 import},
}

@book{bertsekas_dynamic_2000-1,
	edition = {2nd},
	title = {Dynamic {Programming} and {Optimal} {Control}},
	publisher = {Athena Scientific},
	author = {Bertsekas, Dimitri P},
	year = {2000},
	keywords = {Jun 12 import},
}

@article{g_stochastic_1993,
	title = {On stochastic dynamics of supervised learning},
	volume = {26},
	journal = {J Physics A},
	author = {G, Radons},
	year = {1993},
	keywords = {Jun 12 import},
	pages = {3455},
}

@phdthesis{booker_learning_1982,
	type = {{PhD} {Thesis}},
	title = {Learning as an {Adaptation} to the {Task} {Environment}},
	author = {Booker, Lashon Bernard},
	year = {1982},
	keywords = {Jun 12 import},
}

@mastersthesis{vaughan_evolution_2003,
	title = {Evolution of 3-{Dimensional} {Bipedal} {Walking} with {Hips} and {Ankles}},
	school = {Sussex University},
	author = {Vaughan, Eric D},
	year = {2003},
	keywords = {Jun 12 import},
}

@phdthesis{weaver_active-symbol_1993,
	type = {{PhD} {Thesis}},
	title = {An {Active}-{Symbol} {Connectionist} {Model} of {Concept} {Representation} and {Concept} {Learning}},
	author = {Weaver, Mark},
	year = {1993},
	keywords = {Jun 12 import},
}

@book{bertsekas_neuro-dynamic_1996-1,
	series = {Optimization and {Neural} {Computation} {Series}},
	title = {Neuro-{Dynamic} {Programming}},
	publisher = {Athena Scientific},
	author = {Bertsekas, Dimitri P and Tsitsiklis, John N},
	month = oct,
	year = {1996},
	keywords = {MachineLearning.bib},
}

@book{braitenberg_vehicles_1984-1,
	title = {Vehicles: {Experiments} in {Synthetic} {Psychology}},
	publisher = {The MIT Press},
	author = {Braitenberg, Valentino},
	year = {1984},
	keywords = {Jun 12 import},
}

@phdthesis{booker_learning_1982-1,
	type = {{PhD} {Thesis}},
	title = {Learning as an {Adaptation} to the {Task} {Environment}},
	author = {Booker, Lashon Bernard},
	year = {1982},
	keywords = {Psychology.bib},
}

@article{doya_bifurcations_1992-1,
	title = {Bifurcations in the learning of recurrent neural networks},
	author = {Doya, Kenji},
	year = {1992},
	keywords = {MachineLearning.bib},
}

@book{kaplan_cognition_1989,
	title = {Cognition and {Environment}: {Functioning} in an {Uncertain} {World}},
	publisher = {Ulrich's Bookstore},
	author = {Kaplan, Stephen and Kaplan, Rachel},
	month = nov,
	year = {1989},
	keywords = {Jun 12 import},
}

@incollection{thorndike_animal_1911,
	title = {Animal {Intelligence}},
	publisher = {Macmillan, New York},
	author = {Thorndike, E l},
	year = {1911},
	keywords = {Psychology.bib},
	pages = {244},
}

@incollection{thorndike_animal_1911-1,
	title = {Animal {Intelligence}},
	publisher = {Macmillan, New York},
	author = {Thorndike, E l},
	year = {1911},
	keywords = {Jun 12 import},
	pages = {244},
}

@book{hebb_organization_1949,
	title = {Organization of {Behavior}: {A} {Neuropsychological} {Theory}},
	publisher = {Wiley, Inc.},
	author = {Hebb, Donald O},
	month = jan,
	year = {1949},
	keywords = {Jun 12 import},
}

@phdthesis{chown_consolidation_1994-1,
	type = {{PhD} {Thesis}},
	title = {Consolidation and {Learning}: {A} {Connectionist} {Model} of {Human} {Credit} {Assignment}},
	author = {Chown, Eric Lance},
	year = {1994},
	keywords = {Psychology.bib},
}

@phdthesis{weaver_active-symbol_1993-1,
	type = {{PhD} {Thesis}},
	title = {An {Active}-{Symbol} {Connectionist} {Model} of {Concept} {Representation} and {Concept} {Learning}},
	author = {Weaver, Mark},
	year = {1993},
	keywords = {Psychology.bib},
}

@article{beer_dynamical_2000-1,
	title = {Dynamical {Approaches} to {Cognitive} {Science}},
	volume = {4},
	number = {3},
	journal = {Trends Cogn. Sci.},
	author = {Beer, Randall D},
	year = {2000},
	keywords = {Psychology.bib},
	pages = {91--99},
}

@phdthesis{levenick_knowledge_1985-1,
	type = {{PhD} {Thesis}},
	title = {Knowledge {Representation} and {Intelligent} {Systems}: {From} {Semantic} {Networks} to {Cognitive} {Maps}},
	author = {Levenick, James Richard},
	year = {1985},
	keywords = {Psychology.bib},
}

@incollection{kaplan_environmental_1992-1,
	title = {Environmental {Preference} in a {Knowledge}-{Seeking}, {Knowledge}-{Using} {Organism}},
	author = {Kaplan, Stephen},
	year = {1992},
	note = {Section: 16},
	keywords = {Psychology.bib},
	pages = {581--598},
}

@article{tsung_phase-space_1995-1,
	title = {Phase-space learning},
	journal = {NIPS},
	author = {Tsung, Fu-Sheng and Cottrell, Garrison W},
	year = {1995},
	keywords = {MachineLearning.bib},
}

@book{kaplan_cognition_1989-1,
	title = {Cognition and {Environment}: {Functioning} in an {Uncertain} {World}},
	publisher = {Ulrich's Bookstore},
	author = {Kaplan, Stephen and Kaplan, Rachel},
	month = nov,
	year = {1989},
	keywords = {Psychology.bib},
}

@phdthesis{sonntag_learning_1991,
	type = {{PhD} {Thesis}},
	title = {Learning {Sequences} in an {Associative} {Network}: {A} {Step} {Towards} {Cognitive} {Structure}},
	author = {Sonntag, Martin},
	year = {1991},
	keywords = {Psychology.bib},
}

@book{james_psychology_1892,
	title = {Psychology: {The} {Briefer} {Course}},
	publisher = {Henry Holt and Company},
	author = {James, William},
	year = {1892},
	keywords = {Psychology.bib},
}

@unpublished{nikovski_fast_1997-1,
	title = {Fast reinforcement learning in continuous action spaces},
	author = {Nikovski, Daniel N},
	year = {1997},
	keywords = {MachineLearning.bib},
}

@article{g_stochastic_1993-1,
	title = {On stochastic dynamics of supervised learning},
	volume = {26},
	journal = {J Physics A},
	author = {G, Radons},
	year = {1993},
	keywords = {MachineLearning.bib},
	pages = {3455},
}

@phdthesis{ten_hagen_continuous_2001-1,
	type = {{PhD} {Thesis}},
	title = {Continuous {State} {Space} {Q}-{Learning} for {Control} of {Nonlinear} {Systems}},
	author = {ten Hagen, Stephan H G},
	year = {2001},
	keywords = {MachineLearning.bib},
}

@article{jordan_introduction_nodate-1,
	title = {An introduction to variational methods for graphical models},
	author = {Jordan, M I},
	keywords = {MachineLearning.bib},
}

@article{dayan_feudal_nodate-1,
	title = {Feudal {Reinforcement} {Learning}},
	journal = {NIPS},
	author = {Dayan, Peter and Hinton, Geoffrey E},
	keywords = {MachineLearning.bib},
}

@mastersthesis{vaughan_evolution_2003-1,
	title = {Evolution of 3-{Dimensional} {Bipedal} {Walking} with {Hips} and {Ankles}},
	school = {Sussex University},
	author = {Vaughan, Eric D},
	year = {2003},
	keywords = {MachineLearning.bib},
}

@book{fogel_evolutionary_2000-1,
	edition = {Second},
	title = {Evolutionary {Computation}: {Toward} a {New} {Philosophy} of {Machine} {Intelligence} (chapter 4)},
	publisher = {IEEE Press},
	author = {Fogel, David B},
	year = {2000},
	keywords = {MachineLearning.bib},
}

@article{cauwenberghs_fast_1993-1,
	title = {A fast stochastic error-descent algorithm for supervised learning and optimization},
	journal = {NIPS},
	author = {Cauwenberghs, G},
	year = {1993},
	keywords = {MachineLearning.bib},
}

@phdthesis{iii_reinforcement_1999-1,
	type = {{PhD} {Thesis}},
	title = {Reinforcement {Learning} {Through} {Gradient} {Descent}},
	author = {Iii, Leemon C Baird},
	year = {1999},
	keywords = {MachineLearning.bib},
}

@book{abramovitz_handbook_1964,
	title = {Handbook of {Mathematical} {Functions} with {Formulas}, {Graphs}, and {Mathematical} {Tables}},
	publisher = {New York: Dover},
	author = {Abramovitz, Milton and Stegun, Irene},
	year = {1964},
	keywords = {merged\_fiete.bib},
}

@article{kaplan_clarity_1999-1,
	title = {The {Clarity} {Mechanism}: {Negotiating} a {Potentially} {Overwhelming} {World}},
	author = {Kaplan, Stephen and Ivancich, John Eric},
	month = feb,
	year = {1999},
	keywords = {Psychology.bib},
}

@article{magnasco_feynmans_1998,
	title = {Feynman's {Ratchet} and {Pawl}},
	volume = {93},
	number = {3-4},
	journal = {J. Stat. Phys.},
	author = {Magnasco, M O and Stolovitzky, G},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {615},
}

@article{baxter_direct_1999-2,
	title = {Direct {Gradient}-{Based} {Reinforcement} {Learning}: {I}. {Gradient} {Estimation} {Algorithms}},
	author = {Baxter, J and Bartlett, P l},
	month = nov,
	year = {1999},
	keywords = {MachineLearning.bib},
	pages = {1--24},
}

@article{tesauro_temporal_1995-1,
	title = {Temporal {Difference} {Learning} and {TD}-{Gammon}},
	volume = {38},
	number = {3},
	journal = {Commun. ACM},
	author = {Tesauro, Gerald},
	month = mar,
	year = {1995},
	keywords = {MachineLearning.bib},
	pages = {58--68},
}

@phdthesis{sonntag_learning_1991-1,
	type = {{PhD} {Thesis}},
	title = {Learning {Sequences} in an {Associative} {Network}: {A} {Step} {Towards} {Cognitive} {Structure}},
	author = {Sonntag, Martin},
	year = {1991},
	keywords = {Jun 12 import},
}

@book{hebb_textbook_1958,
	title = {A {Textbook} of {Psychology}},
	publisher = {Saunders},
	author = {Hebb, Donald O},
	year = {1958},
	keywords = {Psychology.bib},
}

@article{edwards_notitle_1976-1,
	volume = {9},
	journal = {J Physics A},
	author = {Edwards, S F and Jones, R C},
	year = {1976},
	keywords = {birdpaper.bib},
	pages = {1595},
}

@book{james_psychology_1892-1,
	title = {Psychology: {The} {Briefer} {Course}},
	publisher = {Henry Holt and Company},
	author = {James, William},
	year = {1892},
	keywords = {Jun 12 import},
}

@article{baxter_direct_1999-3,
	title = {Direct {Gradient}-{Based} {Reinforcement} {Learning}: {II}. {Gradient} {Ascent} {Algorithms} and {Experiments}},
	author = {Baxter, J},
	month = nov,
	year = {1999},
	keywords = {MachineLearning.bib},
	pages = {1--29},
}

@book{hebb_organization_1949-1,
	title = {Organization of {Behavior}: {A} {Neuropsychological} {Theory}},
	publisher = {Wiley, Inc.},
	author = {Hebb, Donald O},
	month = jan,
	year = {1949},
	keywords = {Psychology.bib},
}

@book{hebb_textbook_1958-1,
	title = {A {Textbook} of {Psychology}},
	publisher = {Saunders},
	author = {Hebb, Donald O},
	year = {1958},
	keywords = {Jun 12 import},
}

@book{goldsmith_wireless_2005,
	title = {Wireless {Communications}},
	publisher = {Cambridge University Press},
	author = {Goldsmith, A},
	year = {2005},
	keywords = {merged\_fiete.bib},
}

@article{platt_sequential_1998,
	title = {Sequential {Minimal} {Optimization}: {A} {Fast} {Algorithm} for {Training} {Support} {Vector} {Machines}},
	journal = {Microsoft Research Technical Report MSR-TR-98-14},
	author = {Platt, J C},
	year = {1998},
	keywords = {merged\_fiete.bib},
}

@article{noauthor_olfactory_nodate,
	title = {Olfactory input to the mushroom body in a complete electron},
	journal = {https://jscholarship.library.jhu.edu › handlehttps://jscholarship.library.jhu.edu › handle},
}

@article{yoo_optimal_2015,
	title = {Optimal tuning curve widths for multi-periodic multipopulation codes},
	journal = {Unpublished manuscript},
	author = {Yoo, Y-S and Fiete, I R},
	year = {2015},
	keywords = {merged\_fiete.bib},
}

@misc{noauthor_grid_nodate,
	title = {Grid {Modules} {Nature} v2 submission},
	url = {https://www.overleaf.com/project/6435ccd09b0292f33e6bff7f},
	abstract = {An online LaTeX editor that's easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
	language = {en},
}

@article{thomas_mapk_2004,
	title = {{MAPK} cascade signalling and synaptic plasticity},
	volume = {5},
	language = {en},
	number = {3},
	journal = {Nat. Rev. Neurosci.},
	author = {Thomas, Gareth M and Huganir, Richard L},
	month = mar,
	year = {2004},
	pages = {173--183},
}

@article{noauthor_notitle_nodate,
}

@article{magnussen_linear_1980,
	title = {Linear summation of tilt illusion and tilt aftereffect},
	volume = {20},
	number = {1},
	journal = {Vision Res.},
	author = {Magnussen, S and Kurtenbach, W},
	year = {1980},
	keywords = {merged\_fiete.bib},
	pages = {39--42},
}

@article{fiete_binary_nodate,
	title = {A binary {Hopfield} network with information rate and applications to grid cell decoding},
	author = {Fiete, I R and Schwab, D S and Tran, N M},
}

@book{hebb_organization_1949-2,
	title = {The {Organization} of {Behavior}},
	publisher = {John Wiley \& Sons.},
	author = {Hebb, Donald O},
	year = {1949},
	keywords = {merged\_fiete.bib},
}

@article{landauer_irreversibility_1961,
	title = {Irreversibility and heat generation in the computing process},
	volume = {5},
	journal = {IBM J. Res. Dev.},
	author = {Landauer, R},
	year = {1961},
	keywords = {merged\_fiete.bib},
	pages = {183--191},
}

@book{koch_biophysics_1999-1,
	title = {Biophysics of {Computation}: {Information} {Process} in {Single} {Neurons} (from chapter 11)},
	publisher = {Oxford University Press},
	author = {Koch, Christof},
	year = {1999},
	keywords = {merged\_fiete.bib},
}

@article{tishby_information_2000,
	title = {The information bottleneck method},
	journal = {arXiv Physics preprint},
	author = {Tishby, N and Pereira, F C and Bialek, W},
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {0004057},
}

@article{abbott_decoding_1994,
	title = {Decoding neuronal firing and modelling neural networks},
	volume = {27},
	number = {3},
	journal = {Q. Rev. Biophys.},
	author = {Abbott, Lf},
	month = aug,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {291--331},
}

@article{linden_return_1999,
	title = {The {Return} of the {Spike}: {Postsynaptic} {Action} {Potentials} and the {Induction} of {LTP} and {LTD}},
	volume = {22},
	journal = {Neuron},
	author = {Linden, David J},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {661--666},
}

@article{f_informational_1954,
	title = {Some informational aspects of visual perception},
	volume = {61},
	number = {3},
	journal = {Psychol. Rev.},
	author = {F, Attneave},
	year = {1954},
	keywords = {merged\_fiete.bib},
	pages = {183--193},
}

@article{enriquez_mind_2019,
	title = {Mind your mouse strain},
	volume = {1},
	language = {en},
	number = {1},
	journal = {Nat Metab},
	author = {Enríquez, José Antonio},
	month = jan,
	year = {2019},
	pages = {5--7},
}

@misc{noauthor_brain_2021,
	title = {Brain {Initiative} {Cell} {Census} {Network}},
	url = {https://www.nature.com/collections/cicghheddj},
	abstract = {Generating a multimodal cell census and atlas of primary motor cortex through collaborative data collection, tool development and analysis.},
	language = {en},
	month = oct,
	year = {2021},
	note = {Publication Title: Nature},
}

@misc{noauthor_ostp_2022,
	title = {{OSTP} {Issues} {Guidance} to {Make} {Federally} {Funded} {Research} {Freely} {Available} {Without} {Delay}},
	url = {https://www.whitehouse.gov/ostp/news-updates/2022/08/25/ostp-issues-guidance-to-make-federally-funded-research-freely-available-without-delay/},
	abstract = {Today, the White House Office of Science and Technology Policy (OSTP) updated U.S. policy guidance to make the results of taxpayer-supported research immediately available to the American public at no cost. In a memorandum to federal departments and agencies, Dr. Alondra Nelson, the head of OSTP, delivered guidance for agencies to update their public access…},
	language = {en},
	month = aug,
	year = {2022},
	note = {Publication Title: The White House},
	keywords = {Scientific Publishing},
}

@article{noauthor_notitle_nodate-1,
	keywords = {merged\_fiete.bib},
}

@incollection{noauthor_notitle_nodate-2,
	keywords = {merged\_fiete.bib},
}

@incollection{noauthor_notitle_nodate-3,
	keywords = {merged\_fiete.bib},
}

@article{noauthor_notitle_nodate-4,
	keywords = {merged\_fiete.bib},
}

@article{hunt_regionally_2010,
	title = {Regionally localized recurrent excitation in the dentate gyrus of a cortical contusion model of posttraumatic epilepsy},
	volume = {103},
	abstract = {Posttraumatic epilepsy is a frequent consequence of brain trauma, but relatively little is known about how neuronal circuits are chronically altered after closed head injury. We examined whether local recurrent excitatory synaptic connections form between dentate granule cells in mice 8-12 wk after cortical contusion injury. Mice were monitored for behavioral seizures shortly after brain injury and {\textless} or = 10 wk postinjury. Injury-induced seizures were observed in 15\% of mice, and spontaneous seizures were observed weeks later in 40\% of mice. Timm's staining revealed mossy fiber sprouting into the inner molecular layer of the dorsal dentate gyrus ipsilateral to the injury in 95\% of mice but not contralateral to the injury or in uninjured controls. Whole cell patch-clamp recordings were made from granule cells in isolated hippocampal brain slices. Cells in slices with posttraumatic mossy fiber sprouting had an increased excitatory postsynaptic current (EPSC) frequency compared with cells in slices without sprouting from injured and control animals (P {\textless} 0.001). When perfused with Mg(2+)-free artificial cerebrospinal fluid containing 100 microM picrotoxin, these cells had spontaneous bursts of EPSCs and action potentials. Focal glutamate photostimulation of the granule cell layer evoked a burst of EPSCs and action potentials indicative of recurrent excitatory connections in granule cells of slices with mossy fiber sprouting. In granule cells of slices without sprouting from injured animals and controls, spontaneous or photostimulation-evoked epileptiform activity was never observed. These results suggest that a new regionally localized excitatory network forms between dentate granule cells near the injury site within weeks after cortical contusion head injury.},
	language = {en},
	number = {3},
	journal = {J. Neurophysiol.},
	author = {Hunt, Robert F and Scheff, Stephen W and Smith, Bret N},
	month = mar,
	year = {2010},
	pages = {1490--1500},
}

@article{anderson_more_1972,
	title = {More {Is} {Different}},
	volume = {177},
	number = {4047},
	journal = {Science},
	author = {Anderson, P W},
	year = {1972},
	keywords = {merged\_fiete.bib, complexity emergence},
	pages = {393--396},
}

@book{james_principles_1890,
	title = {The {Principles} of {Psychology}},
	abstract = {William James is usually considered the founder of modern American psychology. Yet James openly rejected experimental psychology and the methods of the laboratory. His attitudes toward experimentation are discussed and the reasons for them explored. Even with these attitudes, James and his “Principles of Psychology” (1890) influenced early experimental psychology. These influences are traced.},
	publisher = {Henry Holt \& Co.},
	author = {James, William},
	year = {1890},
	keywords = {merged\_fiete.bib},
}

@article{zheng_neurons_2022,
	title = {Neurons detect cognitive boundaries to structure episodic memories in humans},
	volume = {25},
	number = {3},
	journal = {Nat. Neurosci.},
	author = {Zheng, Jie and Schjetnan, Andrea G P and Yebra, Mar and Gomes, Bernard A and Mosher, Clayton P and Kalia, Suneil K and Valiante, Taufik A and Mamelak, Adam N and Kreiman, Gabriel and Rutishauser, Ueli},
	month = mar,
	year = {2022},
	note = {Publisher: Springer Science and Business Media LLC},
	keywords = {merged\_fiete.bib},
	pages = {358--368},
}

@article{xiao_conjunctive_2020,
	title = {Conjunctive reward-place coding properties of dorsal distal {CA1} hippocampus cells},
	volume = {114},
	abstract = {Autonomous motivated spatial navigation in animals or robots requires the association between spatial location and value. Hippocampal place cells are involved in goal-directed spatial navigation and the consolidation of spatial memories. Recently, Gauthier and Tank (Neuron 99(1):179-193, 2018. https://doi.org/10.1016/j.neuron.2018.06.008) have identified a subpopulation of hippocampal cells selectively activated in relation to rewarded goals. However, the relationship between these cells' spiking activity and goal representation remains elusive. We analyzed data from experiments in which rats underwent five consecutive tasks in which reward locations and spatial context were manipulated. We found CA1 populations with properties continuously ranging from place cells to reward cells. Specifically, we found typical place cells insensitive to reward locations, reward cells that only fired at correct rewarded feeders in each task regardless of context, and “hybrid cells” that responded to spatial locations and change of reward locations. Reward cells responded mostly to the reward delivery rather than to its expectation. In addition, we found a small group of neurons that transitioned between place and reward cells properties within the 5-task session. We conclude that some pyramidal cells (if not all) integrate both spatial and reward inputs to various degrees. These results provide insights into the integrative coding properties of CA1 pyramidal cells, focusing on their abilities to carry both spatial and reward information in a mixed and plastic manner. This conjunctive coding property prompts a re-thinking of current computational models of spatial navigation in which hippocampal spatial and subcortical value representations are independent.},
	number = {2},
	journal = {Biol. Cybern.},
	author = {Xiao, Zhuocheng and Lin, Kevin and Fellous, Jean-Marc},
	year = {2020},
	keywords = {Reward, merged\_fiete.bib, Autonomous spatial navigation, Place cells},
	pages = {285--301},
}

@article{kahana_computational_2020,
	title = {Computational {Models} of {Memory} {Search}},
	volume = {71},
	number = {1},
	journal = {Annu. Rev. Psychol.},
	author = {Kahana, Michael J},
	month = jan,
	year = {2020},
	note = {Publisher: Annual Reviews},
	keywords = {merged\_fiete.bib},
	pages = {107--138},
}

@article{khona_spontaneous_2021,
	title = {Spontaneous emergence of topologically robust grid cell modules: {A} multiscale instability theory},
	journal = {bioRxiv},
	author = {Khona, +mikail and Chandra, +sarthak and Fiete, +ila},
	year = {2021},
	keywords = {merged\_fiete.bib},
}

@article{nadasdy_context-dependent_2017,
	title = {Context-dependent spatially periodic activity in the human entorhinal cortex},
	volume = {114},
	abstract = {The spatially periodic activity of grid cells in the entorhinal cortex (EC) of the rodent, primate, and human provides a coordinate system that, together with the hippocampus, informs an individual of its location relative to the environment and encodes the memory of that location. Among the most defining features of grid-cell activity are the 60 {\textasciicircum}{\textbackslash}circ rotational symmetry of grids and preservation of grid scale across environments. Grid cells, however, do display a limited degree of adaptation to environments. It remains unclear if this level of environment invariance generalizes to human grid-cell analogs, where the relative contribution of visual input to the multimodal sensory input of the EC is significantly larger than in rodents. Patients diagnosed with nontractable epilepsy who were implanted with entorhinal cortical electrodes performing virtual navigation tasks to memorized locations enabled us to investigate associations between grid-like patterns and environment. Here, we report that the activity of human entorhinal cortical neurons exhibits adaptive scaling in grid period, grid orientation, and rotational symmetry in close association with changes in environment size, shape, and visual cues, suggesting scale invariance of the frequency, rather than the wavelength, of spatially periodic activity. Our results demonstrate that neurons in the human EC represent space with an enhanced flexibility relative to neurons in rodents because they are endowed with adaptive scalability and context dependency.},
	number = {17},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Nadasdy, Zoltan and Nguyen, T Peter and Török, Ágoston and Shen, Jason Y and Briggs, Deborah E and Modur, Pradeep N and Buchanan, Robert J},
	year = {2017},
	keywords = {entorhinal cortex, merged\_fiete.bib, grid cell, human, single unit, spatial memory},
	pages = {E3516--E3525},
}

@article{bill_hierarchical_2020,
	title = {Hierarchical structure is employed by humans during visual motion perception},
	volume = {117},
	abstract = {In the real world, complex dynamic scenes often arise from the composition of simpler parts. The visual system exploits this structure by hierarchically decomposing dynamic scenes: When we see a person walking on a train or an animal running in a herd, we recognize the individual's movement as nested within a reference frame that is, itself, moving. Despite its ubiquity, surprisingly little is understood about the computations underlying hierarchical motion perception. To address this gap, we developed a class of stimuli that grant tight control over statistical relations among object velocities in dynamic scenes. We first demonstrate that structured motion stimuli benefit human multiple object tracking performance. Computational analysis revealed that the performance gain is best explained by human participants making use of motion relations during tracking. A second experiment, using a motion prediction task, reinforced this conclusion and provided fine-grained information about how the visual system flexibly exploits motion structure.},
	number = {39},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Bill, Johannes and Pailian, Hrag and Gershman, Samuel J and Drugowitsch, Jan},
	year = {2020},
	keywords = {motion perception, merged\_fiete.bib, Bayesian inference, generative models, hierarchical structure, multiple object tracking},
	pages = {24581--24589},
}

@article{ghosh_learning_2012,
	title = {Learning from open source software projects to improve scientific review},
	volume = {6},
	journal = {Front. Comput. Neurosci.},
	author = {Ghosh, Satrajit S and Klein, Arno and Avants, Brian and Millman, K Jarrod},
	year = {2012},
	note = {Publisher: Frontiers Media SA},
	keywords = {merged\_fiete.bib},
}

@article{sandewall_maintaining_2012,
	title = {Maintaining {Live} {Discussion} in {Two}-{Stage} {Open} {Peer} {Review}},
	volume = {6},
	journal = {Front. Comput. Neurosci.},
	author = {Sandewall, Erik},
	year = {2012},
	note = {Publisher: Frontiers Media SA},
	keywords = {merged\_fiete.bib},
}

@article{wei_principle_2015,
	title = {A principle of economy predicts the functional architecture of grid cells},
	volume = {4},
	abstract = {Grid cells in the brain respond when an animal occupies a periodic lattice of 'grid fields' during navigation. Grids are organized in modules with different periodicity. We propose that the grid system implements a hierarchical code for space that economizes the number of neurons required to encode location with a given resolution across a range equal to the largest period. This theory predicts that (i) grid fields should lie on a triangular lattice, (ii) grid scales should follow a geometric progression, (iii) the ratio between adjacent grid scales should be {\textbackslash}surde for idealized neurons, and lie between 1.4 and 1.7 for realistic neurons, (iv) the scale ratio should vary modestly within and between animals. These results explain the measured grid structure in rodents. We also predict optimal organization in one and three dimensions, the number of modules, and, with added assumptions, the ratio between grid periods and field widths.},
	journal = {Elife},
	author = {Wei, Xue-Xin and Prentice, Jason and Balasubramanian, Vijay},
	month = sep,
	year = {2015},
	keywords = {grid cells, merged\_fiete.bib, efficient coding, neuroscience, rat, spatial cognition, theoretical neuroscience},
	pages = {e08362},
}

@article{longuet-higgins_holographic_1968,
	title = {Holographic {Model} of {Temporal} {Recall}},
	volume = {217},
	number = {5123},
	journal = {Nature},
	author = {Longuet-Higgins, H C},
	month = jan,
	year = {1968},
	note = {Publisher: Springer Science and Business Media LLC},
	keywords = {merged\_fiete.bib},
	pages = {104--104},
}

@article{tanni_state_2021,
	title = {State transitions in the statistically stable place cell population are determined by rate of perceptual change},
	journal = {bioRxiv},
	author = {Tanni, +sander and de+Cothi, +william and Barry, +caswell},
	year = {2021},
	keywords = {merged\_fiete.bib},
}

@article{fiete_spike-time-dependent_2010,
	title = {Spike-time-dependent plasticity and heterosynaptic competition organize networks to produce long scale-free sequences of neural activity},
	volume = {65},
	abstract = {Sequential neural activity patterns are as ubiquitous as the outputs they drive, which include motor gestures and sequential cognitive processes. Neural sequences are long, compared to the activation durations of participating neurons, and sequence coding is sparse. Numerous studies demonstrate that spike-time-dependent plasticity (STDP), the primary known mechanism for temporal order learning in neurons, cannot organize networks to generate long sequences, raising the question of how such networks are formed. We show that heterosynaptic competition within single neurons, when combined with STDP, organizes networks to generate long unary activity sequences even without sequential training inputs. The network produces a diversity of sequences with a power law length distribution and exponent -1, independent of cellular time constants. We show evidence for a similar distribution of sequence lengths in the recorded premotor song activity of songbirds. These results suggest that neural sequences may be shaped by synaptic constraints and network circuitry rather than cellular time constants.},
	number = {4},
	journal = {Neuron},
	author = {Fiete, Ila R and Senn, Walter and Wang, Claude Z H and Hahnloser, Richard H R},
	month = feb,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {563--576},
}

@article{wicherts_letting_2012,
	title = {Letting the daylight in: {Reviewing} the reviewers and other ways to maximize transparency in science},
	volume = {6},
	journal = {Front. Comput. Neurosci.},
	author = {Wicherts, Jelte M and Kievit, Rogier A and Bakker, Marjan and Borsboom, Denny},
	year = {2012},
	note = {Publisher: Frontiers Media SA},
	keywords = {merged\_fiete.bib},
}

@article{hartshorne_tracking_2012,
	title = {Tracking {Replicability} as a {Method} of {Post}-{Publication} {Open} {Evaluation}},
	volume = {6},
	journal = {Front. Comput. Neurosci.},
	author = {Hartshorne, Joshua K and Schachner, Adena},
	year = {2012},
	note = {Publisher: Frontiers Media SA},
	keywords = {merged\_fiete.bib},
}

@article{brown_hebb_2021,
	title = {The {Hebb} {Synapse} {Before} {Hebb}: {Theories} of {Synaptic} {Function} in {Learning} and {Memory} {Before} , {With} a {Discussion} of the {Long}-{Lost} {Synaptic} {Theory} of {William} {McDougall}},
	volume = {15},
	abstract = {Since the work of Semon was rediscovered by Schacter in 1978, there has been a renewed interest is searching for the “engram” as the locus of memory in the brain and Hebb's cell assembly has been equated with Semon's engram. There have been many theories of memory involving some concept of synaptic change, culminating in the “Hebb Synapse” theory in 1949. However, Hebb said that the idea that any two cells or systems of cells that are repeatedly active at the same time will tend to become “associated,” was not his idea, but an old one. In this manuscript we give an overview of some of the theories of the neural basis of learning and memory before Hebb and describe the synaptic theory of William McDougall, which appears to have been an idea ahead of its time; so far ahead of its time that it was completely ignored by his contemporaries. We conclude by examining some critiques of McDougall's theory of inhibition and with a short discussion on the fate of neuroscientists whose ideas were neglected when first presented but were accepted as important many decades later.},
	journal = {Front. Behav. Neurosci.},
	author = {Brown, Richard E and Bligh, Thaddeus W B and Garden, Jessica F},
	year = {2021},
	keywords = {merged\_fiete.bib, cell assembly, engram, history, ideas before their time, synaptic theory},
	pages = {732195},
}

@article{birukou_alternatives_2011,
	title = {Alternatives to {Peer} {Review}: {Novel} {Approaches} for {Research} {Evaluation}},
	volume = {5},
	journal = {Front. Comput. Neurosci.},
	author = {Birukou, Aliaksandr and Wakeling, Joseph Rushton and Bartolini, Claudio and Casati, Fabio and Marchese, Maurizio and Mirylenka, Katsiaryna and Osman, Nardine and Ragone, Azzurra and Sierra, Carles and Wassef, Aalam},
	year = {2011},
	note = {Publisher: Frontiers Media SA},
	keywords = {merged\_fiete.bib},
}

@article{poschl_multi-stage_2012,
	title = {Multi-{Stage} {Open} {Peer} {Review}: {Scientific} {Evaluation} {Integrating} the {Strengths} of {Traditional} {Peer} {Review} with the {Virtues} of {Transparency} and {Self}-{Regulation}},
	volume = {6},
	journal = {Front. Comput. Neurosci.},
	author = {Pöschl, Ulrich},
	year = {2012},
	note = {Publisher: Frontiers Media SA},
	keywords = {merged\_fiete.bib},
}

@article{kreiman_nine_2011,
	title = {Nine {Criteria} for a {Measure} of {Scientific} {Output}},
	volume = {5},
	journal = {Front. Comput. Neurosci.},
	author = {Kreiman, Gabriel and Maunsell, John H R},
	year = {2011},
	note = {Publisher: Frontiers Media SA},
	keywords = {merged\_fiete.bib},
}

@article{bilkey_neural_2021,
	title = {Neural {Markers} of {Event} {Boundaries}},
	volume = {13},
	abstract = {The continuous flow of sensorimotor experience is segmented into events that are stored in memory as discrete representations. These events are subsequently available for reconstruction into episodic memories or to be recombined for future thinking, prediction and imagination. Here we briefly review the patterns of brain activity that accompany the processing of events, and the transitions between them, with an aim to identifying signals that would serve as event boundary markers (EBMs). Since many previous studies have highlighted a role for the hippocampus in episodic memory function, consolidation and future thinking, we focus on activity in this region. In particular, we describe the brief bursts of hippocampal activity known as sharp-wave ripples (SWRs), which tend to occur following the cessation of units of behavior, making them putative EBM candidates. While most current models of SWR function tend to focus on a potential role in memory consolidation or preplay linked to future thinking, here we consider an interpretation that incorporates an EBM component.},
	number = {1},
	journal = {Top. Cogn. Sci.},
	author = {Bilkey, David K and Jensen, Charlotte},
	year = {2021},
	keywords = {Hippocampus, Memory, merged\_fiete.bib, Episodic, Event boundary, Ripples, Sharp-wave},
	pages = {128--141},
}

@article{klukas_fragmented_2021,
	title = {Fragmented {Spatial} {Maps}: {State} {Abstraction} and {Efficient} {Planning} from {Surprisal}},
	journal = {bioRxiv},
	author = {Klukas, Mirko and Sharma, Sugandha and Du, Yilun and Lozano-Perez, Tomas and Kaelbling, Leslie P Leslie and Fiete, Ila},
	year = {2021},
	keywords = {merged\_fiete.bib},
}

@article{sanders_efficient_2020,
	title = {Efficient {Inference} in {Structured} {Spaces}},
	volume = {183},
	abstract = {Whittington et al. demonstrate how network architectures defined in a spatial context may be useful for inference on different types of relational knowledge. These architectures allow for learning the structure of the environment and then transferring that knowledge to allow prediction of novel transitions.},
	number = {5},
	journal = {Cell},
	author = {Sanders, Honi and Wilson, Matthew and Klukas, Mirko and Sharma, Sugandha and Fiete, Ila},
	year = {2020},
	keywords = {merged\_fiete.bib},
	pages = {1147--1148},
}

@article{mcdougall_seat_1901,
	title = {{ON} {THE} {SEAT} {OF} {THE} {PSYCHO}-{PHYSICAL} {PROCESSES}},
	volume = {24},
	number = {4},
	journal = {Brain},
	author = {Mcdougall, W},
	year = {1901},
	keywords = {merged\_fiete.bib},
	pages = {579--630},
}

@article{khona_attractor_2021,
	title = {Attractor and integrator networks in the brain},
	abstract = {Attractor neural networks are some of the most-studied circuit models of brain function. We discuss the utility of low-dimensional attractors for computation in the brain, provide a mechanistically unifying view of models for the construction of these attractors, and discuss why it is now possible to rigorously claim that the brain constructs and uses such systems for computation. We describe notable examples of brain systems in which continuous attractor dynamics have been concretely identified. Finally, we highlight recent advances in understanding how the fundamental tradeoffs between robustness and capacity and between structure and flexibility can be overcome by reusing the same attractor for multiple functions and by multiple modular attractors working together to produce vastly more representations that are structurally constrained and robust but also flexible.},
	author = {Khona, Mikail and Fiete, Ila R},
	year = {2021},
	keywords = {merged\_fiete.bib},
}

@article{kim_cellular_2015,
	title = {Cellular evidence for efference copy in {Drosophila} visuomotor processing},
	volume = {18},
	abstract = {Each time a locomoting fly turns, the visual image sweeps over the retina and generates a motion stimulus. Classic behavioral experiments suggested that flies use active neural-circuit mechanisms to suppress the perception of self-generated visual motion during intended turns. Direct electrophysiological evidence, however, has been lacking. We found that visual neurons in Drosophila receive motor-related inputs during rapid flight turns. These inputs arrived with a sign and latency appropriate for suppressing each targeted cell's visual response to the turn. Precise measurements of behavioral and neuronal response latencies supported the idea that motor-related inputs to optic flow-processing cells represent internal predictions of the expected visual drive induced by voluntary turns. Motor-related inputs to small object-selective visual neurons could reflect either proprioceptive feedback from the turn or internally generated signals. Our results in Drosophila echo the suppression of visual perception during rapid eye movements in primates, demonstrating common functional principles of sensorimotor processing across phyla.},
	number = {9},
	journal = {Nat. Neurosci.},
	author = {Kim, Anmo J and Fitzgerald, Jamie K and Maimon, Gaby},
	month = sep,
	year = {2015},
	keywords = {merged\_fiete.bib},
	pages = {1247--1255},
}

@article{curtis_persistent_2003,
	title = {Persistent activity in the prefrontal cortex during working memory},
	volume = {7},
	abstract = {The dorsolateral prefrontal cortex (DLPFC) plays a crucial role in working memory. Notably, persistent activity in the DLPFC is often observed during the retention interval of delayed response tasks. The code carried by the persistent activity remains unclear, however. We critically evaluate how well recent findings from functional magnetic resonance imaging studies are compatible with current models of the role of the DLFPC in working memory. These new findings suggest that the DLPFC aids in the maintenance of information by directing attention to internal representations of sensory stimuli and motor plans that are stored in more posterior regions.},
	number = {9},
	journal = {Trends Cogn. Sci.},
	author = {Curtis, Clayton E and D'Esposito, Mark},
	month = sep,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {415--423},
}

@article{quiroga_invariant_2005,
	title = {Invariant visual representation by single neurons in the human brain},
	volume = {435},
	abstract = {It takes a fraction of a second to recognize a person or an object even when seen under strikingly different conditions. How such a robust, high-level representation is achieved by neurons in the human brain is still unclear. In monkeys, neurons in the upper stages of the ventral visual pathway respond to complex images such as faces and objects and show some degree of invariance to metric properties such as the stimulus size, position and viewing angle. We have previously shown that neurons in the human medial temporal lobe (MTL) fire selectively to images of faces, animals, objects or scenes. Here we report on a remarkable subset of MTL neurons that are selectively activated by strikingly different pictures of given individuals, landmarks or objects and in some cases even by letter strings with their names. These results suggest an invariant, sparse and explicit code, which might be important in the transformation of complex visual percepts into long-term and more abstract memories.},
	number = {7045},
	journal = {Nature},
	author = {Quiroga, R Quian and Reddy, L and Kreiman, G and Koch, C and Fried, I},
	month = jun,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {1102--1107},
}

@article{green_neural_2017,
	title = {A neural circuit architecture for angular integration in {Drosophila}},
	volume = {546},
	abstract = {Many animals keep track of their angular heading over time while navigating through their environment. However, a neural-circuit architecture for computing heading has not been experimentally defined in any species. Here we describe a set of clockwise- and anticlockwise-shifting neurons in the Drosophila central complex whose wiring and physiology provide a means to rotate an angular heading estimate based on the fly's angular velocity. We show that each class of shifting neurons exists in two subtypes, with spatiotemporal activity profiles that suggest different roles for each subtype at the start and end of tethered-walking turns. Shifting neurons are required for the heading system to properly track the fly's heading in the dark, and stimulation of these neurons induces predictable shifts in the heading signal. The central features of this biological circuit are analogous to those of computational models proposed for head-direction cells in rodents and may shed light on how neural systems, in general, perform integration.},
	number = {7656},
	journal = {Nature},
	author = {Green, Jonathan and Adachi, Atsuko and Shah, Kunal K and Hirokawa, Jonathan D and Magani, Pablo S and Maimon, Gaby},
	year = {2017},
	keywords = {merged\_fiete.bib},
	pages = {101--106},
}

@article{gauthier_dedicated_2018,
	title = {A {Dedicated} {Population} for {Reward} {Coding} in the {Hippocampus}},
	volume = {99},
	abstract = {The hippocampus plays a critical role in goal-directed navigation. Across different environments, however, hippocampal maps are randomized, making it unclear how goal locations could be encoded consistently. To address this question, we developed a virtual reality task with shifting reward contingencies to distinguish place versus reward encoding. In mice performing the task, large-scale recordings in CA1 and subiculum revealed a small, specialized cell population that was only active near reward yet whose activity could not be explained by sensory cues or stereotyped reward anticipation behavior. Across different virtual environments, most cells remapped randomly, but reward encoding consistently arose from a single pool of cells, suggesting that they formed a dedicated channel for reward. These observations represent a significant departure from the current understanding of CA1 as a relatively homogeneous ensemble without fixed coding properties and provide a new candidate for the cellular basis of goal memory in the hippocampus.},
	number = {1},
	journal = {Neuron},
	author = {Gauthier, Jeffrey L and Tank, David W},
	year = {2018},
	keywords = {hippocampus, place cells, merged\_fiete.bib, CA1, navigation, place fields, reward, subiculum, virtual reality},
	pages = {179--193.e7},
}

@article{funahashi_mnemonic_1989,
	title = {Mnemonic coding of visual space in the monkey's dorsolateral prefrontal cortex},
	volume = {61},
	abstract = {1. An oculomotor delayed-response task was used to examine the spatial memory functions of neurons in primate prefrontal cortex. Monkeys were trained to fixate a central spot during a brief presentation (0.5 s) of a peripheral cue and throughout a subsequent delay period (1-6 s), and then, upon the extinction of the fixation target, to make a saccadic eye movement to where the cue had been presented. Cues were usually presented in one of eight different locations separated by 45 degrees. This task thus requires monkeys to direct their gaze to the location of a remembered visual cue, controls the retinal coordinates of the visual cues, controls the monkey's oculomotor behavior during the delay period, and also allows precise measurement of the timing and direction of the relevant behavioral responses. 2. Recordings were obtained from 288 neurons in the prefrontal cortex within and surrounding the principal sulcus (PS) while monkeys performed this task. An additional 31 neurons in the frontal eye fields (FEF) region within and near the anterior bank of the arcuate sulcus were also studied. 3. Of the 288 PS neurons, 170 exhibited task-related activity during at least one phase of this task and, of these, 87 showed significant excitation or inhibition of activity during the delay period relative to activity during the intertrial interval. 4. Delay period activity was classified as directional for 79\% of these 87 neurons in that significant responses only occurred following cues located over a certain range of visual field directions and were weak or absent for other cue directions. The remaining 21\% were omnidirectional, i.e., showed comparable delay period activity for all visual field locations tested. Directional preferences, or lack thereof, were maintained across different delay intervals (1-6 s). 5. For 50 of the 87 PS neurons, activity during the delay period was significantly elevated above the neuron's spontaneous rate for at least one cue location; for the remaining 37 neurons only inhibitory delay period activity was seen. Nearly all (92\%) neurons with excitatory delay period activity were directional and few (8\%) were omnidirectional. Most (62\%) neurons with purely inhibitory delay period activity were directional, but a substantial minority (38\%) was omnidirectional. 6. Fifteen of the neurons with excitatory directional delay period activity also had significant inhibitory delay period activity for other cue directions. These inhibitory responses were usually strongest for, or centered about, cue directions roughly opposite those optimal for excitatory responses.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Funahashi, S and Bruce, C J and Goldman-Rakic, P S},
	month = feb,
	year = {1989},
	keywords = {merged\_fiete.bib},
	pages = {331--349},
}

@article{josselyn_heroes_2017,
	title = {Heroes of the {Engram}},
	volume = {37},
	abstract = {In 1904, Richard Semon introduced the term “engram” to describe the neural substrate responsible for (or at least important in) storing and recalling memories (i.e., a memory trace). The recent introduction of a vast array of powerful new tools to probe and manipulate memory function at the cell and neuronal circuit level has spurred an explosion of interest in studying the engram. However, the present “engram renaissance” was not borne in isolation but rather builds on a long tradition of memory research. We believe it is important to acknowledge the debts our current generation of scientists owes to those scientists who have offered key ideas, persevered through failed experiments and made important discoveries before us. Examining the past can also offer a fresh perspective on the present state and future promise of the field. Given the large amount of empirical advances made in recent years, it seems particularly timely to look back and review the scientists who introduced the seminal terminology, concepts, methodological approaches, and initial data pertaining to engrams. Rather than simply list their many accomplishments, here we color in some details of the lives and milestone contributions of our seven personal heroes of the engram (Richard Semon, Karl Lashley, Donald Hebb, Wilder Penfield, Brenda Milner, James McConnell, and Richard Thompson). In reviewing their historic role, we also illustrate how their work remains relevant to today's studies.},
	number = {18},
	journal = {J. Neurosci.},
	author = {Josselyn, Sheena A and Köhler, Stefan and Frankland, Paul W},
	year = {2017},
	keywords = {merged\_fiete.bib},
	pages = {4647--4657},
}

@article{tsao_integrating_2018,
	title = {Integrating time from experience in the lateral entorhinal cortex},
	volume = {561},
	abstract = {The encoding of time and its binding to events are crucial for episodic memory, but how these processes are carried out in hippocampal-entorhinal circuits is unclear. Here we show in freely foraging rats that temporal information is robustly encoded across time scales from seconds to hours within the overall population state of the lateral entorhinal cortex. Similarly pronounced encoding of time was not present in the medial entorhinal cortex or in hippocampal areas CA3-CA1. When animals' experiences were constrained by behavioural tasks to become similar across repeated trials, the encoding of temporal flow across trials was reduced, whereas the encoding of time relative to the start of trials was improved. The findings suggest that populations of lateral entorhinal cortex neurons represent time inherently through the encoding of experience. This representation of episodic time may be integrated with spatial inputs from the medial entorhinal cortex in the hippocampus, allowing the hippocampus to store a unified representation of what, where and when.},
	number = {7721},
	journal = {Nature},
	author = {Tsao, Albert and Sugar, Jørgen and Lu, Li and Wang, Cheng and Knierim, James J and Moser, May-Britt and Moser, Edvard I},
	year = {2018},
	keywords = {merged\_fiete.bib},
	pages = {57--62},
}

@article{tomov_discovery_2020,
	title = {Discovery of hierarchical representations for efficient planning},
	volume = {16},
	abstract = {We propose that humans spontaneously organize environments into clusters of states that support hierarchical planning, enabling them to tackle challenging problems by breaking them down into sub-problems at various levels of abstraction. People constantly rely on such hierarchical presentations to accomplish tasks big and small-from planning one's day, to organizing a wedding, to getting a PhD-often succeeding on the very first attempt. We formalize a Bayesian model of hierarchy discovery that explains how humans discover such useful abstractions. Building on principles developed in structure learning and robotics, the model predicts that hierarchy discovery should be sensitive to the topological structure, reward distribution, and distribution of tasks in the environment. In five simulations, we show that the model accounts for previously reported effects of environment structure on planning behavior, such as detection of bottleneck states and transitions. We then test the novel predictions of the model in eight behavioral experiments, demonstrating how the distribution of tasks and rewards can influence planning behavior via the discovered hierarchy, sometimes facilitating and sometimes hindering performance. We find evidence that the hierarchy discovery process unfolds incrementally across trials. Finally, we propose how hierarchy discovery and hierarchical planning might be implemented in the brain. Together, these findings present an important advance in our understanding of how the brain might use Bayesian inference to discover and exploit the hidden hierarchical structure of the environment.},
	number = {4},
	journal = {PLoS Comput. Biol.},
	author = {Tomov, Momchil S and Yagati, Samyukta and Kumar, Agni and Yang, Wanqian and Gershman, Samuel J},
	year = {2020},
	keywords = {merged\_fiete.bib},
	pages = {e1007594},
}

@article{korpel_gabor_1982,
	title = {Gabor: frequency, time, and memory},
	volume = {21},
	abstract = {Dennis Gabor is well-known as the inventor of holography. Less well-known, perhaps, are his contributions to other areas. Yet they are important and, like holography, characteristic of his foresight. In the field of communications, Gabor investigated the classic dichotomy of time and frequency. Guided by analogies to quantum mechanics, he postulated a set of elementary signals and made brilliant use of time-frequency diagrams to analyze communication systems. Applying his theories to acoustics, he researched the mechanism of hearing, defining acoustical quanta in the process and inventing early prototype frequency compressors and expanders. In a completely different field, Gabor, inspired by some early work of Longuet-Higgins on models for holographic temporal recall in the brain, suggested novel approaches which contributed significantly to the understanding of associative memories. In this paper we describe Gabor's pioneering work in these areas and trace the subsequent development by himself and others.},
	number = {20},
	journal = {Appl. Opt.},
	author = {Korpel, A},
	month = oct,
	year = {1982},
	keywords = {merged\_fiete.bib},
	pages = {3624--3632},
}

@article{lee_open_2012,
	title = {Open {Peer} {Review} by a {Selected}-{Papers} {Network}},
	volume = {6},
	journal = {Front. Comput. Neurosci.},
	author = {Lee, Christopher},
	year = {2012},
	note = {Publisher: Frontiers Media SA},
	keywords = {merged\_fiete.bib},
}

@article{kravitz_toward_2011,
	title = {Toward a {New} {Model} of {Scientific} {Publishing}: {Discussion} and a {Proposal}},
	volume = {5},
	journal = {Front. Comput. Neurosci.},
	author = {Kravitz, Dwight J and Baker, Chris I},
	year = {2011},
	note = {Publisher: Frontiers Media SA},
	keywords = {Scientific Publishing},
}

@inproceedings{sharma_content_2022,
	title = {Content addressable memory without catastrophic forgetting by heteroassociation with a fixed scaffold},
	volume = {abs/2202.00159},
	booktitle = {{ICML}},
	author = {Sharma, Sugandha and Chandra, Sarthak and Fiete, Ila R},
	year = {2022},
	keywords = {merged\_fiete.bib},
}

@article{matula_sparsest_1990,
	title = {Sparsest cuts and bottlenecks in graphs},
	volume = {27},
	abstract = {The problem of determining a sparsest cut in a graph is characterized and its computation shown to be NP-hard. A class of sparsest cuts, termed bottlenecks, is characterized by a dual relation to a particular polynomial time computable multicommodity flow problem. Efficient computational techniques for determining bottlenecks in a broad class of instances are presented.},
	number = {1},
	journal = {Discrete Appl. Math.},
	author = {Matula, David W and Shahrokhi, Farhad},
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {113--123},
}

@article{alexander_egocentric_2020,
	title = {Egocentric boundary vector tuning of the retrosplenial cortex},
	volume = {6},
	abstract = {The retrosplenial cortex is reciprocally connected with multiple structures implicated in spatial cognition, and damage to the region itself produces numerous spatial impairments. Here, we sought to characterize spatial correlates of neurons within the region during free exploration in two-dimensional environments. We report that a large percentage of retrosplenial cortex neurons have spatial receptive fields that are active when environmental boundaries are positioned at a specific orientation and distance relative to the animal itself. We demonstrate that this vector-based location signal is encoded in egocentric coordinates, is localized to the dysgranular retrosplenial subregion, is independent of self-motion, and is context invariant. Further, we identify a subpopulation of neurons with this response property that are synchronized with the hippocampal theta oscillation. Accordingly, the current work identifies a robust egocentric spatial code in retrosplenial cortex that can facilitate spatial coordinate system transformations and support the anchoring, generation, and utilization of allocentric representations.},
	number = {8},
	journal = {Sci Adv},
	author = {Alexander, Andrew S and Carstensen, Lucas C and Hinman, James R and Raudies, Florian and Chapman, G William and Hasselmo, Michael E},
	year = {2020},
	keywords = {merged\_fiete.bib},
	pages = {eaaz2322},
}

@article{bunge_analogical_2005,
	title = {Analogical reasoning and prefrontal cortex: evidence for separable retrieval and integration mechanisms},
	volume = {15},
	abstract = {The present study examined the contributions of prefrontal cortex (PFC) subregions to two component processes underlying verbal analogical reasoning: semantic retrieval and integration. Event-related functional magnetic resonance imaging data were acquired while subjects performed propositional analogy and semantic decision tasks. On each trial, subjects viewed a pair of words (pair 1), followed by an instructional cue and a second word pair (pair 2). On analogy trials, subjects evaluated whether pair 2 was semantically analogous to pair 1. On semantic trials, subjects indicated whether the pair 2 words were semantically related to each other. Thus, analogy–but not semantic–trials required integration across multiple retrieved relations. To identify regions involved in semantic retrieval, we manipulated the associative strength of pair 1 words in both tasks. Anterior left inferior PFC (aLIPC) was modulated by associative strength, consistent with a role in controlled semantic retrieval. Left frontopolar cortex was insensitive to associative strength, but was more sensitive to integration demands than was aLIPC, consistent with a role in integrating the products of semantic retrieval to evaluate whether distinct representations are analogous. Right dorsolateral PFC exhibited a profile consistent with a role in response selection rather than retrieval or integration. These findings indicate that verbal analogical reasoning depends on multiple, PFC-mediated computations.},
	number = {3},
	journal = {Cereb. Cortex},
	author = {Bunge, Silvia A and Wendelken, Carter and Badre, David and Wagner, Anthony D},
	month = mar,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {239--249},
}

@article{ocko_emergent_2018,
	title = {Emergent elasticity in the neural code for space},
	volume = {115},
	number = {50},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Ocko, Samuel A and Hardcastle, Kiah and Giocomo, Lisa M and Ganguli, Surya},
	month = nov,
	year = {2018},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	keywords = {merged\_fiete.bib},
}

@article{waltz_system_1999,
	title = {A {System} for {Relational} {Reasoning} in {Human} {Prefrontal} {Cortex}},
	volume = {10},
	number = {2},
	journal = {Psychol. Sci.},
	author = {Waltz, James A and Knowlton, Barbara J and Holyoak, Keith J and Boone, Kyle B and Mishkin, Fred S and de Menezes Santos, Marcia and Thomas, Carmen R and Miller, Bruce L},
	month = mar,
	year = {1999},
	note = {Publisher: SAGE Publications},
	keywords = {merged\_fiete.bib},
	pages = {119--125},
}

@article{bush_what_2014,
	title = {What do grid cells contribute to place cell firing?},
	volume = {37},
	abstract = {The unitary firing fields of hippocampal place cells are commonly assumed to be generated by input from entorhinal grid cell modules with differing spatial scales. Here, we review recent research that brings this assumption into doubt. Instead, we propose that place cell spatial firing patterns are determined by environmental sensory inputs, including those representing the distance and direction to environmental boundaries, while grid cells provide a complementary self-motion related input that contributes to maintaining place cell firing. In this view, grid and place cell firing patterns are not successive stages of a processing hierarchy, but complementary and interacting representations that work in combination to support the reliable coding of large-scale space.},
	number = {3},
	journal = {Trends Neurosci.},
	author = {Bush, Daniel and Barry, Caswell and Burgess, Neil},
	month = mar,
	year = {2014},
	keywords = {grid cells, hippocampus, place cells, merged\_fiete.bib, border cells, boundary vector cells},
	pages = {136--145},
}

@article{kim_quantitative_2017,
	title = {Quantitative {Predictions} {Orchestrate} {Visual} {Signaling} in {Drosophila}},
	volume = {168},
	abstract = {Vision influences behavior, but ongoing behavior also modulates vision in animals ranging from insects to primates. The function and biophysical mechanisms of most such modulations remain unresolved. Here, we combine behavioral genetics, electrophysiology, and high-speed videography to advance a function for behavioral modulations of visual processing in Drosophila. We argue that a set of motion-sensitive visual neurons regulate gaze-stabilizing head movements. We describe how, during flight turns, Drosophila perform a set of head movements that require silencing their gaze-stability reflexes along the primary rotation axis of the turn. Consistent with this behavioral requirement, we find pervasive motor-related inputs to the visual neurons, which quantitatively silence their predicted visual responses to rotations around the relevant axis while preserving sensitivity around other axes. This work proposes a function for a behavioral modulation of visual processing and illustrates how the brain can remove one sensory signal from a circuit carrying multiple related signals.},
	number = {1-2},
	journal = {Cell},
	author = {Kim, Anmo J and Fenk, Lisa M and Lyu, Cheng and Maimon, Gaby},
	month = jan,
	year = {2017},
	keywords = {electrophysiology, neural circuits, merged\_fiete.bib, action initiation, corollary discharge, Drosophila, efference copy, eye movements, patch-clamp, vision, visuomotor processing},
	pages = {280--294.e12},
}

@article{jacobs_direct_2013,
	title = {Direct recordings of grid-like neuronal activity in human spatial navigation},
	volume = {16},
	abstract = {Grid cells in the entorhinal cortex appear to represent spatial location via a triangular coordinate system. Such cells, which have been identified in rats, bats and monkeys, are believed to support a wide range of spatial behaviors. Recording neuronal activity from neurosurgical patients performing a virtual-navigation task, we identified cells exhibiting grid-like spiking patterns in the human brain, suggesting that humans and simpler animals rely on homologous spatial-coding schemes.},
	number = {9},
	journal = {Nat. Neurosci.},
	author = {Jacobs, Joshua and Weidemann, Christoph T and Miller, Jonathan F and Solway, Alec and Burke, John F and Wei, Xue-Xin and Suthana, Nanthia and Sperling, Michael R and Sharan, Ashwini D and Fried, Itzhak and Kahana, Michael J},
	month = sep,
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {1188--1190},
}

@article{van_wijngaarden_entorhinal-retrosplenial_2020,
	title = {Entorhinal-retrosplenial circuits for allocentric-egocentric transformation of boundary coding},
	volume = {9},
	abstract = {Spatial navigation requires landmark coding from two perspectives, relying on viewpoint-invariant and self-referenced representations. The brain encodes information within each reference frame but their interactions and functional dependency remains unclear. Here we investigate the relationship between neurons in the rat's retrosplenial cortex (RSC) and entorhinal cortex (MEC) that increase firing near boundaries of space. Border cells in RSC specifically encode walls, but not objects, and are sensitive to the animal's direction to nearby borders. These egocentric representations are generated independent of visual or whisker sensation but are affected by inputs from MEC that contains allocentric spatial cells. Pharmaco- and optogenetic inhibition of MEC led to a disruption of border coding in RSC, but not vice versa, indicating allocentric-to-egocentric transformation. Finally, RSC border cells fire prospective to the animal's next motion, unlike those in MEC, revealing the MEC-RSC pathway as an extended border coding circuit that implements coordinate transformation to guide navigation behavior.},
	journal = {Elife},
	author = {van Wijngaarden, Joeri Bg and Babl, Susanne S and Ito, Hiroshi T},
	year = {2020},
	keywords = {entorhinal cortex, merged\_fiete.bib, neuroscience, rat, border cell, egocentric-allocentric transformation, retrosplenial cortex},
}

@article{van_noorden_open_2013,
	title = {Open access: {The} true cost of science publishing},
	volume = {495},
	number = {7442},
	journal = {Nature},
	author = {Van Noorden, Richard},
	month = mar,
	year = {2013},
	note = {Publisher: Springer Science and Business Media LLC},
	keywords = {merged\_fiete.bib, Scientific Publishing},
	pages = {426--429},
}

@article{da_silva_need_2013,
	title = {The need for post-publication peer review in plant science publishing},
	volume = {4},
	journal = {Front. Plant Sci.},
	author = {da Silva, Jaime A Teixeira},
	year = {2013},
	note = {Publisher: Frontiers Media SA},
	keywords = {merged\_fiete.bib, Scientific Publishing},
}

@article{zylberberg_mechanisms_2017,
	title = {Mechanisms of {Persistent} {Activity} in {Cortical} {Circuits}: {Possible} {Neural} {Substrates} for {Working} {Memory}},
	volume = {40},
	abstract = {A commonly observed neural correlate of working memory is firing that persists after the triggering stimulus disappears. Substantial effort has been devoted to understanding the many potential mechanisms that may underlie memory-associated persistent activity. These rely either on the intrinsic properties of individual neurons or on the connectivity within neural circuits to maintain the persistent activity. Nevertheless, it remains unclear which mechanisms are at play in the many brain areas involved in working memory. Herein, we first summarize the palette of different mechanisms that can generate persistent activity. We then discuss recent work that asks which mechanisms underlie persistent activity in different brain areas. Finally, we discuss future studies that might tackle this question further. Our goal is to bridge between the communities of researchers who study either single-neuron biophysical, or neural circuit, mechanisms that can generate the persistent activity that underlies working memory.},
	journal = {Annu. Rev. Neurosci.},
	author = {Zylberberg, Joel and Strowbridge, Ben W},
	year = {2017},
	keywords = {persistent activity, merged\_fiete.bib, attractor network, bistability, feedback, neocortex, plateau potential, short-term memory, synaptic transmission},
	pages = {603--627},
}

@article{sharma_map_2022,
	title = {Map {Induction}: {Compositional} spatial submap learning for efficient exploration in novel environments},
	abstract = {Humans are expert explorers. Understanding the computational cognitive mechanisms that support this efficiency can advance the study of the human mind and enable more efficient exploration algorithms. We hypothesize that humans explore new environments efficiently by inferring the structure of unobserved spaces using spatial information collected from previously explored spaces. This cognitive process can be modeled computationally using program induction in a Hierarchical Bayesian framework that explicitly reasons about uncertainty with strong spatial priors. Using a new behavioral Map Induction Task, we demonstrate that this computational framework explains human exploration behavior better than non-inductive models and outperforms state-of-the-art planning algorithms when applied to a realistic spatial navigation domain.},
	journal = {ICLR},
	author = {Sharma, Sugandha and Curtis, Aidan and Kryven, Marta and Tenenbaum, Josh and Fiete, Ila},
	year = {2022},
	keywords = {merged\_fiete.bib},
}

@article{donoso_human_2014,
	title = {Human cognition. {Foundations} of human reasoning in the prefrontal cortex},
	volume = {344},
	abstract = {The prefrontal cortex (PFC) subserves reasoning in the service of adaptive behavior. Little is known, however, about the architecture of reasoning processes in the PFC. Using computational modeling and neuroimaging, we show here that the human PFC has two concurrent inferential tracks: (i) one from ventromedial to dorsomedial PFC regions that makes probabilistic inferences about the reliability of the ongoing behavioral strategy and arbitrates between adjusting this strategy versus exploring new ones from long-term memory, and (ii) another from polar to lateral PFC regions that makes probabilistic inferences about the reliability of two or three alternative strategies and arbitrates between exploring new strategies versus exploiting these alternative ones. The two tracks interact and, along with the striatum, realize hypothesis testing for accepting versus rejecting newly created strategies.},
	number = {6191},
	journal = {Science},
	author = {Donoso, Maël and Collins, Anne G E and Koechlin, Etienne},
	month = jun,
	year = {2014},
	keywords = {merged\_fiete.bib},
	pages = {1481--1486},
}

@article{da_silva_problems_2014,
	title = {Problems with {Traditional} {Science} {Publishing} and {Finding} a {Wider} {Niche} for {Post}-{Publication} {Peer} {Review}},
	volume = {22},
	number = {1},
	journal = {Account. Res.},
	author = {da Silva, Jaime A Teixeira and Dobránszki, Judit},
	month = oct,
	year = {2014},
	note = {Publisher: Informa UK Limited},
	keywords = {merged\_fiete.bib, Scientific Publishing},
	pages = {22--40},
}

@article{walther_fose_2012,
	title = {{FOSE}: a framework for open science evaluation},
	volume = {6},
	journal = {Front. Comput. Neurosci.},
	author = {Walther, Alexander and van den Bosch, Jasper J F},
	year = {2012},
	note = {Publisher: Frontiers Media SA},
	keywords = {merged\_fiete.bib},
}

@article{churchland_decision-making_2008,
	title = {Decision-making with multiple alternatives},
	volume = {11},
	abstract = {Simple perceptual tasks have laid the groundwork for understanding the neurobiology of decision-making. Here, we examined this foundation to explain how decision-making circuitry adjusts in the face of a more difficult task. We measured behavioral and physiological responses of monkeys on a two- and four-choice direction-discrimination decision task. For both tasks, firing rates in the lateral intraparietal area appeared to reflect the accumulation of evidence for or against each choice. Evidence accumulation began at a lower firing rate for the four-choice task, but reached a common level by the end of the decision process. The larger excursion suggests that the subjects required more evidence before making a choice. Furthermore, on both tasks, we observed a time-dependent rise in firing rates that may impose a deadline for deciding. These physiological observations constitute an effective strategy for handling increased task difficulty. The differences appear to explain subjects' accuracy and reaction times.},
	number = {6},
	journal = {Nat. Neurosci.},
	author = {Churchland, Anne K and Kiani, Roozbeh and Shadlen, Michael N},
	month = jun,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {693--702},
}

@article{lee_statistical_2020,
	title = {The {Statistical} {Structure} of the {Hippocampal} {Code} for {Space} as a {Function} of {Time}, {Context}, and {Value}},
	volume = {183},
	abstract = {Hippocampal activity represents many behaviorally important variables, including context, an animal's location within a given environmental context, time, and reward. Using longitudinal calcium imaging in mice, multiple large virtual environments, and differing reward contingencies, we derived a unified probabilistic model of CA1 representations centered on a single feature-the field propensity. Each cell's propensity governs how many place fields it has per unit space, predicts its reward-related activity, and is preserved across distinct environments and over months. Propensity is broadly distributed-with many low, and some very high, propensity cells-and thus strongly shapes hippocampal representations. This results in a range of spatial codes, from sparse to dense. Propensity varied ∼10-fold between adjacent cells in salt-and-pepper fashion, indicating substantial functional differences within a presumed cell type. Intracellular recordings linked propensity to cell excitability. The stability of each cell's propensity across conditions suggests this fundamental property has anatomical, transcriptional, and/or developmental origins.},
	number = {3},
	journal = {Cell},
	author = {Lee, Jae Sung and Briguglio, John J and Cohen, Jeremy D and Romani, Sandro and Lee, Albert K},
	year = {2020},
	keywords = {hippocampus, merged\_fiete.bib, memory, calcium imaging, excitability, gain modulation, intracellular recording, place cell, place field, propensity, sparse coding},
	pages = {620--635.e22},
}

@article{harland_dorsal_2021,
	title = {Dorsal {CA1} hippocampal place cells form a multi-scale representation of megaspace},
	volume = {31},
	number = {10},
	author = {Harland, Bruce and Contreras, Marco and Souder, Madeline and Fellous, Jean-Marc},
	month = may,
	year = {2021},
	note = {Publisher: Elsevier BV},
	keywords = {merged\_fiete.bib},
	pages = {2178--2190.e6},
}

@article{nosek_preregistration_2018,
	title = {The preregistration revolution},
	volume = {115},
	abstract = {Progress in science relies in part on generating hypotheses with existing observations and testing hypotheses with new observations. This distinction between postdiction and prediction is appreciated conceptually but is not respected in practice. Mistaking generation of postdictions with testing of predictions reduces the credibility of research findings. However, ordinary biases in human reasoning, such as hindsight bias, make it hard to avoid this mistake. An effective solution is to define the research questions and analysis plan before observing the research outcomes-a process called preregistration. Preregistration distinguishes analyses and outcomes that result from predictions from those that result from postdictions. A variety of practical strategies are available to make the best possible use of preregistration in circumstances that fall short of the ideal application, such as when the data are preexisting. Services are now available for preregistration across all disciplines, facilitating a rapid increase in the practice. Widespread adoption of preregistration will increase distinctiveness between hypothesis generation and hypothesis testing and will improve the credibility of research findings.},
	number = {11},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Nosek, Brian A and Ebersole, Charles R and DeHaven, Alexander C and Mellor, David T},
	year = {2018},
	keywords = {merged\_fiete.bib, confirmatory analysis, exploratory analysis, methodology, open science, preregistration},
	pages = {2600--2606},
}

@article{hardcastle_environmental_2015,
	title = {Environmental boundaries as an error correction mechanism for grid cells},
	volume = {86},
	abstract = {Medial entorhinal grid cells fire in periodic, hexagonally patterned locations and are proposed to support path-integration-based navigation. The recursive nature of path integration results in accumulating error and, without a corrective mechanism, a breakdown in the calculation of location. The observed long-term stability of grid patterns necessitates that the system either performs highly precise internal path integration or implements an external landmark-based error correction mechanism. To distinguish these possibilities, we examined grid cells in behaving rodents as they made long trajectories across an open arena. We found that error accumulates relative to time and distance traveled since the animal last encountered a boundary. This error reflects coherent drift in the grid pattern. Further, interactions with boundaries yield direction-dependent error correction, suggesting that border cells serve as a neural substrate for error correction. These observations, combined with simulations of an attractor network grid cell model, demonstrate that landmarks are crucial to grid stability.},
	number = {3},
	journal = {Neuron},
	author = {Hardcastle, Kiah and Ganguli, Surya and Giocomo, Lisa M},
	month = may,
	year = {2015},
	keywords = {merged\_fiete.bib},
	pages = {827--839},
}

@article{grieves_irregular_2021,
	title = {Irregular distribution of grid cell firing fields in rats exploring a {3D} volumetric space},
	abstract = {We investigated how entorhinal grid cells encode volumetric space. On a horizontal surface, grid cells usually produce multiple, spatially focal, approximately circular firing fields that are evenly sized and spaced to form a regular, close-packed, hexagonal array. This spatial regularity has been suggested to underlie navigational computations. In three dimensions, theoretically the equivalent firing pattern would be a regular, hexagonal close packing of evenly sized spherical fields. In the present study, we report that, in rats foraging in a cubic lattice, grid cells maintained normal temporal firing characteristics and produced spatially stable firing fields. However, although most grid fields were ellipsoid, they were sparser, larger, more variably sized and irregularly arranged, even when only fields abutting the lower surface (equivalent to the floor) were considered. Thus, grid self-organization is shaped by the environment's structure and/or movement affordances, and grids may not need to be regular to support spatial computations.},
	journal = {Nat. Neurosci.},
	author = {Grieves, Roddy M and Jedidi-Ayoub, Selim and Mishchanchuk, Karyna and Liu, Anyi and Renaudineau, Sophie and Duvelle, Éléonore and Jeffery, Kate J},
	month = aug,
	year = {2021},
	keywords = {merged\_fiete.bib},
}

@article{hayman_grid_2015,
	title = {Grid cells on steeply sloping terrain: evidence for planar rather than volumetric encoding},
	volume = {6},
	abstract = {Neural encoding of navigable space involves a network of structures centered on the hippocampus, whose neurons -place cells - encode current location. Input to the place cells includes afferents from the entorhinal cortex, which contains grid cells. These are neurons expressing spatially localized activity patches, or firing fields, that are evenly spaced across the floor in a hexagonal close-packed array called a grid. It is thought that grids function to enable the calculation of distances. The question arises as to whether this odometry process operates in three dimensions, and so we queried whether grids permeate three-dimensional (3D) space - that is, form a lattice - or whether they simply follow the environment surface. If grids form a 3D lattice then this lattice would ordinarily be aligned horizontally (to explain the usual hexagonal pattern observed). A tilted floor would transect several layers of this putative lattice, resulting in interruption of the hexagonal pattern. We model this prediction with simulated grid lattices, and show that the firing of a grid cell on a 40 {\textasciicircum}{\textbackslash}circ-tilted surface should cover proportionally less of the surface, with smaller field size, fewer fields, and reduced hexagonal symmetry. However, recording of real grid cells as animals foraged on a 40 {\textasciicircum}{\textbackslash}circ-tilted surface found that firing of grid cells was almost indistinguishable, in pattern or rate, from that on the horizontal surface, with if anything increased coverage and field number, and preserved field size. It thus appears unlikely that the sloping surface transected a lattice. However, grid cells on the slope displayed slightly degraded firing patterns, with reduced coherence and slightly reduced symmetry. These findings collectively suggest that the grid cell component of the metric representation of space is not fixed in absolute 3D space but is influenced both by the surface the animal is on and by the relationship of this surface to the horizontal, supporting the hypothesis that the neural map of space is “multi-planar” rather than fully volumetric.},
	journal = {Front. Psychol.},
	author = {Hayman, Robin M A and Casali, Giulio and Wilson, Jonathan J and Jeffery, Kate J},
	year = {2015},
	keywords = {grid cells, place cells, merged\_fiete.bib, spatial cognition, navigation, dimensions, theoretical model},
	pages = {925},
}

@article{ginosar_locally_2021,
	title = {Locally ordered representation of {3D} space in the entorhinal cortex},
	volume = {596},
	abstract = {As animals navigate on a two-dimensional surface, neurons in the medial entorhinal cortex (MEC) known as grid cells are activated when the animal passes through multiple locations (firing fields) arranged in a hexagonal lattice that tiles the locomotion surface1. However, although our world is three-dimensional, it is unclear how the MEC represents 3D space2. Here we recorded from MEC cells in freely flying bats and identified several classes of spatial neurons, including 3D border cells, 3D head-direction cells, and neurons with multiple 3D firing fields. Many of these multifield neurons were 3D grid cells, whose neighbouring fields were separated by a characteristic distance-forming a local order-but lacked any global lattice arrangement of the fields. Thus, whereas 2D grid cells form a global lattice-characterized by both local and global order-3D grid cells exhibited only local order, creating a locally ordered metric for space. We modelled grid cells as emerging from pairwise interactions between fields, which yielded a hexagonal lattice in 2D and local order in 3D, thereby describing both 2D and 3D grid cells using one unifying model. Together, these data and model illuminate the fundamental differences and similarities between neural codes for 3D and 2D space in the mammalian brain.},
	number = {7872},
	journal = {Nature},
	author = {Ginosar, Gily and Aljadeff, Johnatan and Burak, Yoram and Sompolinsky, Haim and Las, Liora and Ulanovsky, Nachum},
	month = aug,
	year = {2021},
	keywords = {merged\_fiete.bib},
	pages = {404--409},
}

@article{krupic_grid_2015,
	title = {Grid cell symmetry is shaped by environmental geometry},
	volume = {518},
	abstract = {Grid cells represent an animal's location by firing in multiple fields arranged in a striking hexagonal array. Such an impressive and constant regularity prompted suggestions that grid cells represent a universal and environmental-invariant metric for navigation. Originally the properties of grid patterns were believed to be independent of the shape of the environment and this notion has dominated almost all theoretical grid cell models. However, several studies indicate that environmental boundaries influence grid firing, though the strength, nature and longevity of this effect is unclear. Here we show that grid orientation, scale, symmetry and homogeneity are strongly and permanently affected by environmental geometry. We found that grid patterns orient to the walls of polarized enclosures such as squares, but not circles. Furthermore, the hexagonal grid symmetry is permanently broken in highly polarized environments such as trapezoids, the pattern being more elliptical and less homogeneous. Our results provide compelling evidence for the idea that environmental boundaries compete with the internal organization of the grid cell system to drive grid firing. Notably, grid cell activity is more local than previously thought and as a consequence cannot provide a universal spatial metric in all environments.},
	number = {7538},
	journal = {Nature},
	author = {Krupic, Julija and Bauza, Marius and Burton, Stephen and Barry, Caswell and O'Keefe, John},
	month = feb,
	year = {2015},
	keywords = {merged\_fiete.bib},
	pages = {232--235},
}

@article{tenenbaum_global_2000,
	title = {A {Global} {Geometric} {Framework} for {Nonlinear} {Dimensionality} {Reduction}},
	volume = {290},
	number = {5500},
	journal = {Science},
	author = {Tenenbaum, J B},
	year = {2000},
	note = {Publisher: American Association for the Advancement of Science (AAAS)},
	keywords = {merged\_fiete.bib},
	pages = {2319--2323},
}

@article{blei_distance_2011,
	title = {Distance {Dependent} {Chinese} {Restaurant} {Processes}},
	volume = {12},
	number = {74},
	journal = {J. Mach. Learn. Res.},
	author = {Blei, David M and Frazier, Peter I},
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {2461--2488},
}

@article{gershman_distance_2015,
	title = {Distance {Dependent} {Infinite} {Latent} {Feature} {Models}},
	volume = {37},
	abstract = {Latent feature models are widely used to decompose data into a small number of components. Bayesian nonparametric variants of these models, which use the Indian buffet process (IBP) as a prior over latent features, allow the number of features to be determined from the data. We present a generalization of the IBP, the distance dependent Indian buffet process (dd-IBP), for modeling non-exchangeable data. It relies on distances defined between data points, biasing nearby data to share more features. The choice of distance measure allows for many kinds of dependencies, including temporal and spatial. Further, the original IBP is a special case of the dd-IBP. We develop the dd-IBP and theoretically characterize its feature-sharing properties. We derive a Markov chain Monte Carlo sampler for a linear Gaussian model with a dd-IBP prior and study its performance on real-world non-exchangeable data.},
	number = {2},
	journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
	author = {Gershman, Samuel J and Frazier, Peter I and Blei, David M},
	month = feb,
	year = {2015},
	keywords = {merged\_fiete.bib},
	pages = {334--345},
}

@article{foster_reverse_2006,
	title = {Reverse replay of behavioural sequences in hippocampal place cells during the awake state},
	volume = {440},
	abstract = {The hippocampus has long been known to be involved in spatial navigational learning in rodents, and in memory for events in rodents, primates and humans. A unifying property of both navigation and event memory is a requirement for dealing with temporally sequenced information. Reactivation of temporally sequenced memories for previous behavioural experiences has been reported in sleep in rats. Here we report that sequential replay occurs in the rat hippocampus during awake periods immediately after spatial experience. This replay has a unique form, in which recent episodes of spatial experience are replayed in a temporally reversed order. This replay is suggestive of a role in the evaluation of event sequences in the manner of reinforcement learning models. We propose that such replay might constitute a general mechanism of learning and memory.},
	number = {7084},
	journal = {Nature},
	author = {Foster, David J and Wilson, Matthew A},
	month = mar,
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {680--683},
}

@article{roux_sharp_2017,
	title = {Sharp wave ripples during learning stabilize the hippocampal spatial map},
	volume = {20},
	abstract = {Cognitive representation of the environment requires a stable hippocampal map, but the mechanisms maintaining a given map are unknown. Because sharp wave-ripples (SPW-R) orchestrate both retrospective and prospective spatial information, we hypothesized that disrupting neuronal activity during SPW-Rs affects spatial representation. Mice learned new sets of three goal locations daily in a multiwell maze. We used closed-loop SPW-R detection at goal locations to trigger optogenetic silencing of a subset of CA1 pyramidal neurons. Control place cells (nonsilenced or silenced outside SPW-Rs) largely maintained the location of their place fields after learning and showed increased spatial information content. In contrast, the place fields of SPW-R-silenced place cells remapped, and their spatial information remained unaltered. SPW-R silencing did not impact the firing rates or proportions of place cells. These results suggest that interference with SPW-R-associated activity during learning prevents stabilization and refinement of hippocampal maps.},
	number = {6},
	journal = {Nat. Neurosci.},
	author = {Roux, Lisa and Hu, Bo and Eichler, Ronny and Stark, Eran and Buzsáki, György},
	month = jun,
	year = {2017},
	keywords = {merged\_fiete.bib},
	pages = {845--853},
}

@article{buzsaki_hippocampal_2015,
	title = {Hippocampal sharp wave-ripple: {A} cognitive biomarker for episodic memory and planning},
	volume = {25},
	abstract = {Sharp wave ripples (SPW-Rs) represent the most synchronous population pattern in the mammalian brain. Their excitatory output affects a wide area of the cortex and several subcortical nuclei. SPW-Rs occur during “off-line” states of the brain, associated with consummatory behaviors and non-REM sleep, and are influenced by numerous neurotransmitters and neuromodulators. They arise from the excitatory recurrent system of the CA3 region and the SPW-induced excitation brings about a fast network oscillation (ripple) in CA1. The spike content of SPW-Rs is temporally and spatially coordinated by a consortium of interneurons to replay fragments of waking neuronal sequences in a compressed format. SPW-Rs assist in transferring this compressed hippocampal representation to distributed circuits to support memory consolidation; selective disruption of SPW-Rs interferes with memory. Recently acquired and pre-existing information are combined during SPW-R replay to influence decisions, plan actions and, potentially, allow for creative thoughts. In addition to the widely studied contribution to memory, SPW-Rs may also affect endocrine function via activation of hypothalamic circuits. Alteration of the physiological mechanisms supporting SPW-Rs leads to their pathological conversion, “p-ripples,” which are a marker of epileptogenic tissue and can be observed in rodent models of schizophrenia and Alzheimer's Disease. Mechanisms for SPW-R genesis and function are discussed in this review.},
	number = {10},
	journal = {Hippocampus},
	author = {Buzsáki, György},
	month = oct,
	year = {2015},
	keywords = {planning, merged\_fiete.bib, learning, memory, epilepsy, imagining},
	pages = {1073--1188},
}

@article{joo_hippocampal_2018,
	title = {The hippocampal sharp wave-ripple in memory retrieval for immediate use and consolidation},
	volume = {19},
	abstract = {Various cognitive functions have long been known to require the hippocampus. Recently, progress has been made in identifying the hippocampal neural activity patterns that implement these functions. One such pattern is the sharp wave-ripple (SWR), an event associated with highly synchronous neural firing in the hippocampus and modulation of neural activity in distributed brain regions. Hippocampal spiking during SWRs can represent past or potential future experience, and SWR-related interventions can alter subsequent memory performance. These findings and others suggest that SWRs support both memory consolidation and memory retrieval for processes such as decision-making. In addition, studies have identified distinct types of SWR based on representational content, behavioural state and physiological features. These various findings regarding SWRs suggest that different SWR types correspond to different cognitive functions, such as retrieval and consolidation. Here, we introduce another possibility - that a single SWR may support more than one cognitive function. Taking into account classic psychological theories and recent molecular results that suggest that retrieval and consolidation share mechanisms, we propose that the SWR mediates the retrieval of stored representations that can be utilized immediately by downstream circuits in decision-making, planning, recollection and/or imagination while simultaneously initiating memory consolidation processes.},
	number = {12},
	journal = {Nat. Rev. Neurosci.},
	author = {Joo, Hannah R and Frank, Loren M},
	year = {2018},
	keywords = {merged\_fiete.bib},
	pages = {744--757},
}

@article{low_probing_2018,
	title = {Probing variability in a cognitive map using manifold inference from neural dynamics},
	journal = {bioRxiv},
	author = {Low, Ryan J and Lewallen, Sam and Aronov, Dmitriy and Nevers, Rhino and Tank, David W},
	year = {2018},
	keywords = {merged\_fiete.bib},
}

@article{nieh_geometry_2021,
	title = {Geometry of abstract learned knowledge in the hippocampus},
	volume = {595},
	abstract = {Hippocampal neurons encode physical variables1-7 such as space1 or auditory frequency6 in cognitive maps8. In addition, functional magnetic resonance imaging studies in humans have shown that the hippocampus can also encode more abstract, learned variables9-11. However, their integration into existing neural representations of physical variables12,13 is unknown. Here, using two-photon calcium imaging, we show that individual neurons in the dorsal hippocampus jointly encode accumulated evidence with spatial position in mice performing a decision-making task in virtual reality14-16. Nonlinear dimensionality reduction13 showed that population activity was well-described by approximately four to six latent variables, which suggests that neural activity is constrained to a low-dimensional manifold. Within this low-dimensional space, both physical and abstract variables were jointly mapped in an orderly manner, creating a geometric representation that we show is similar across mice. The existence of conjoined cognitive maps suggests that the hippocampus performs a general computation-the creation of task-specific low-dimensional manifolds that contain a geometric representation of learned knowledge.},
	number = {7865},
	journal = {Nature},
	author = {Nieh, Edward H and Schottdorf, Manuel and Freeman, Nicolas W and Low, Ryan J and Lewallen, Sam and Koay, Sue Ann and Pinto, Lucas and Gauthier, Jeffrey L and Brody, Carlos D and Tank, David W},
	year = {2021},
	keywords = {merged\_fiete.bib},
	pages = {80--84},
}

@article{duvelle_hippocampal_2021,
	title = {Hippocampal place cells encode global location but not connectivity in a complex space},
	volume = {31},
	abstract = {Flexible navigation relies on a cognitive map of space, thought to be implemented by hippocampal place cells: neurons that exhibit location-specific firing. In connected environments, optimal navigation requires keeping track of one's location and of the available connections between subspaces. We examined whether the dorsal CA1 place cells of rats encode environmental connectivity in four geometrically identical boxes arranged in a square. Rats moved between boxes by pushing saloon-type doors that could be locked in one or both directions. Although rats demonstrated knowledge of environmental connectivity, their place cells did not respond to connectivity changes, nor did they represent doorways differently from other locations. Place cells coded location in a global reference frame, with a different map for each box and minimal repetitive fields despite the repetitive geometry. These results suggest that CA1 place cells provide a spatial map that does not explicitly include connectivity.},
	number = {6},
	journal = {Curr. Biol.},
	author = {Duvelle, Éléonore and Grieves, Roddy M and Liu, Anyi and Jedidi-Ayoub, Selim and Holeniewska, Joanna and Harris, Adam and Nyberg, Nils and Donnarumma, Francesco and Lefort, Julie M and Jeffery, Kate J and Summerfield, Christopher and Pezzulo, Giovanni and Spiers, Hugo J},
	month = mar,
	year = {2021},
	keywords = {hippocampus, place cells, merged\_fiete.bib, rat, navigation, detour, four-room maze, place field repetition, spatial connectivity, topology, transitions},
	pages = {1221--1233.e9},
}

@article{spiers_place_2015,
	title = {Place field repetition and purely local remapping in a multicompartment environment},
	volume = {25},
	abstract = {Hippocampal place cells support spatial memory using sensory information from the environment and self-motion information to localize their firing fields. Currently, there is disagreement about whether CA1 place cells can use pure self-motion information to disambiguate different compartments in environments containing multiple visually identical compartments. Some studies report that place cells can disambiguate different compartments, while others report that they do not. Furthermore, while numerous studies have examined remapping, there has been little examination of remapping in different subregions of a single environment. Is remapping purely local or do place fields in neighboring, unaffected, regions detect the change? We recorded place cells as rats foraged across a 4-compartment environment and report 3 new findings. First, we find that, unlike studies in which rats foraged in 2 compartments, place fields showed a high degree of spatial repetition with a slight degree of rate-based discrimination. Second, this repetition does not diminish with extended experience. Third, remapping was found to be purely local for both geometric change and contextual change. Our results reveal the limited capacity of the path integrator to drive pattern separation in hippocampal representations, and suggest that doorways may play a privileged role in segmenting the neural representation of space.},
	number = {1},
	journal = {Cereb. Cortex},
	author = {Spiers, Hugo J and Hayman, Robin M A and Jovalekic, Aleksandar and Marozzi, Elizabeth and Jeffery, Kathryn J},
	month = jan,
	year = {2015},
	keywords = {grid cells, place cells, merged\_fiete.bib, spatial memory, rat, path integration},
	pages = {10--25},
}

@article{yoganarasimha_head_2006,
	title = {Head direction cell representations maintain internal coherence during conflicting proximal and distal cue rotations: comparison with hippocampal place cells},
	volume = {26},
	abstract = {Place cells of the hippocampal formation encode a spatial representation of the environment, and the orientation of this representation is apparently governed by the head direction cell system. The representation of a well explored environment by CA1 place cells can be split when there is conflicting information from salient proximal and distal cues, because some place fields rotate to follow the distal cues, whereas others rotate to follow the proximal cues (Knierim, 2002a). In contrast, the CA3 representation is more coherent than CA1, because the place fields in CA3 tend to rotate in the same direction (Lee et al., 2004). The present study tests whether the head direction cell network produces a split representation or remains coherent under these conditions by simultaneously recording both CA1 place cells and head direction cells from the thalamus. In agreement with previous studies, split representations of the environment were observed in ensembles of CA1 place cells in approximately 75\% of the mismatch sessions, in which some fields followed the counterclockwise rotation of proximal cues and other fields followed the clockwise rotation of distal cues. However, of 225 recording sessions, there was not a single instance of the head direction cell ensembles revealing a split representation of head direction. Instead, in most of the mismatch sessions, the head direction cell tuning curves rotated as an ensemble clockwise (94\%) and in a few sessions rotated counterclockwise (6\%). The findings support the notion that the head direction cells may be part of an attractor network bound more strongly to distal landmarks than proximal landmarks, even under conditions in which the CA1 place representation loses its coherence.},
	number = {2},
	journal = {J. Neurosci.},
	author = {Yoganarasimha, D and Yu, Xintian and Knierim, James J},
	month = jan,
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {622--631},
}

@article{dordek_extracting_2016,
	title = {Extracting grid cell characteristics from place cell inputs using non-negative principal component analysis},
	volume = {5},
	abstract = {Many recent models study the downstream projection from grid cells to place cells, while recent data have pointed out the importance of the feedback projection. We thus asked how grid cells are affected by the nature of the input from the place cells. We propose a single-layer neural network with feedforward weights connecting place-like input cells to grid cell outputs. Place-to-grid weights are learned via a generalized Hebbian rule. The architecture of this network highly resembles neural networks used to perform Principal Component Analysis (PCA). Both numerical results and analytic considerations indicate that if the components of the feedforward neural network are non-negative, the output converges to a hexagonal lattice. Without the non-negativity constraint, the output converges to a square lattice. Consistent with experiments, grid spacing ratio between the first two consecutive modules is -1.4. Our results express a possible linkage between place cell to grid cell interactions and PCA.},
	journal = {Elife},
	author = {Dordek, Yedidyah and Soudry, Daniel and Meir, Ron and Derdikman, Dori},
	month = mar,
	year = {2016},
	keywords = {hippocampus, merged\_fiete.bib, grid cell, human, neuroscience, rat, navigation, place cell, bat, entorhinal, mouse},
	pages = {e10094},
}

@inproceedings{sorscher_unified_2019,
	title = {A unified theory for the origin of grid cells through the lens of pattern formation},
	volume = {32},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Sorscher, Ben and Mel, Gabriel and Ganguli, Surya and Ocko, Samuel},
	editor = {Wallach, H and Larochelle, H and Beygelzimer, A and d{\textbackslash}textbackslashtextquotesingle Alché-Buc, F and Fox, E and Garnett, R},
	year = {2019},
	keywords = {merged\_fiete.bib},
}

@article{antunes_novel_2012,
	title = {The novel object recognition memory: neurobiology, test procedure, and its modifications},
	volume = {13},
	abstract = {Animal models of memory have been considered as the subject of many scientific publications at least since the beginning of the twentieth century. In humans, memory is often accessed through spoken or written language, while in animals, cognitive functions must be accessed through different kind of behaviors in many specific, experimental models of memory and learning. Among them, the novel object recognition test can be evaluated by the differences in the exploration time of novel and familiar objects. Its application is not limited to a field of research and enables that various issues can be studied, such as the memory and learning, the preference for novelty, the influence of different brain regions in the process of recognition, and even the study of different drugs and their effects. This paper describes the novel object recognition paradigms in animals, as a valuable measure of cognition. The purpose of this work was to review the neurobiology and methodological modifications of the test commonly used in behavioral pharmacology.},
	number = {2},
	journal = {Cogn. Process.},
	author = {Antunes, M and Biala, G},
	month = may,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {93--110},
}

@article{lee_role_2005,
	title = {The role of hippocampal subregions in detecting spatial novelty},
	volume = {119},
	abstract = {Previous literature suggests that the hippocampus subserves processes associated with the encoding of novel information. To investigate the role of different subregions of the hippocampus, the authors made neurotoxic lesions in different subregions of the dorsal hippocampus (i.e., CA1, dentate gyrus [DG], or CA3) of rats, followed by tests using a spontaneous object exploration paradigm. All lesion groups explored normally an object newly introduced in a familiar location. However, when some of the familiar objects were moved to novel locations, both DG and CA3 lesion groups were severely impaired in reexploring the displaced objects, whereas the CA1 lesion group was only mildly impaired in reexploration. The results suggest that the DG-CA3 network is essential in detecting novelty for spatial, but not for individual object, information.},
	number = {1},
	journal = {Behav. Neurosci.},
	author = {Lee, Inah and Hunsaker, Michael R and Kesner, Raymond P},
	month = feb,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {145--153},
}

@article{kumaran_tracking_2009,
	title = {Tracking the emergence of conceptual knowledge during human decision making},
	volume = {63},
	abstract = {Concepts lie at the very heart of intelligence, providing organizing principles with which to comprehend the world. Surprisingly little, however, is understood about how we acquire and deploy concepts. Here, we show that a functionally coupled circuit involving the hippocampus and ventromedial prefrontal cortex (vMPFC) underpins the emergence of conceptual knowledge and its effect on choice behavior. Critically, the hippocampus alone supported the efficient transfer of knowledge to a perceptually novel setting. These findings provide compelling evidence that the hippocampus supports conceptual learning through the networking of discrete memories and reveal the nature of its interaction with downstream valuation modules such as the vMPFC. Our study offers neurobiological insights into the remarkable capacity of humans to discover the conceptual structure of related experiences and use this knowledge to solve exacting decision problems.},
	number = {6},
	journal = {Neuron},
	author = {Kumaran, Dharshan and Summerfield, Jennifer J and Hassabis, Demis and Maguire, Eleanor A},
	month = sep,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {889--901},
}

@article{kumaran_unexpected_2006,
	title = {An unexpected sequence of events: mismatch detection in the human hippocampus},
	volume = {4},
	abstract = {The ability to identify and react to novelty within the environment is fundamental to survival. Computational models emphasize the potential role of the hippocampus in novelty detection, its unique anatomical circuitry making it ideally suited to act as a comparator between past and present experience. The hippocampus, therefore, is viewed to detect associative mismatches between what is expected based on retrieval of past experience and current sensory input. However, direct evidence that the human hippocampus performs such operations is lacking. We explored brain responses to novel sequences of objects using functional magnetic resonance imaging (fMRI), while subjects performed an incidental target detection task. Our results demonstrate that hippocampal activation was maximal when prior predictions concerning which object would appear next in a sequence were violated by sensory reality. In so doing, we establish the biological reality of associative match-mismatch computations within the human hippocampus, a process widely held to play a cardinal role in novelty detection. Our results also suggest that the hippocampus may generate predictions about how future events will unfold, and critically detect when these expectancies are violated, even when task demands do not require it. The present study also offers broader insights into the nature of essential computations carried out by the hippocampus, which may also underpin its unique contribution to episodic memory.},
	number = {12},
	journal = {PLoS Biol.},
	author = {Kumaran, Dharshan and Maguire, Eleanor A},
	month = nov,
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {e424},
}

@article{knight_contribution_1996,
	title = {Contribution of human hippocampal region to novelty detection},
	volume = {383},
	abstract = {The ability to respond to unexpected stimuli (the 'orienting response') is a fundamental characteristic of mammalian behaviour, but the brain mechanisms by which novelty is detected remain poorly defined. Electrophysiological recordings of scalp and intracranial event-related potentials (ERPs) have shown that novel stimuli activate a distributed network involving prefrontal and posterior association cortex. In addition, ERP and single-neuron recordings, as well as neuroimaging and modelling studies, have suggested that temporal cortical regions, including the hippocampus, are also involved. To examine further the role of the medial temporal lobe in novelty processing, I measured physiological responses to novel auditory and tactile stimuli in patients with damage to the posterior hippocampal region. In normal control subjects, unexpected novel stimuli produce a characteristic ERP signal, accompanied by an autonomic skin response. Both responses are reduced in hippocampal lesion patients, whereas the response to expected control stimuli is unaffected. Thus the hippocampal region, in addition to its known role in memory formation, is an essential component of the distributed limbic-cortical network that detects and responds to novel stimuli.},
	number = {6597},
	journal = {Nature},
	author = {Knight, R},
	month = sep,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {256--259},
}

@article{sahay_pattern_2011,
	title = {Pattern separation: a common function for new neurons in hippocampus and olfactory bulb},
	volume = {70},
	abstract = {While adult-born neurons in the olfactory bulb (OB) and the dentate gyrus (DG) subregion of the hippocampus have fundamentally different properties, they may have more in common than meets the eye. Here, we propose that new granule cells in the OB and DG may function as modulators of principal neurons to influence pattern separation and that adult neurogenesis constitutes an adaptive mechanism to optimally encode contextual or olfactory information. See the related Perspective from Aimone, Deng, and Gage, “Resolving New Memories: A Critical Look at the Dentate Gyrus, Adult Neurogenesis, and Pattern Separation,” in this issue of Neuron.},
	number = {4},
	journal = {Neuron},
	author = {Sahay, Amar and Wilson, Donald A and Hen, René},
	month = may,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {582--588},
}

@article{denny_hippocampal_2014,
	title = {Hippocampal memory traces are differentially modulated by experience, time, and adult neurogenesis},
	volume = {83},
	abstract = {Memory traces are believed to be ensembles of cells used to store memories. To visualize memory traces, we created a transgenic line that allows for the comparison between cells activated during encoding and expression of a memory. Mice re-exposed to a fear-inducing context froze more and had a greater percentage of reactivated cells in the dentate gyrus (DG) and CA3 than mice exposed to a novel context. Over time, these differences disappeared, in keeping with the observation that memories become generalized. Optogenetically silencing DG or CA3 cells that were recruited during encoding of a fear-inducing context prevented expression of the corresponding memory. Mice with reduced neurogenesis displayed less contextual memory and less reactivation in CA3 but, surprisingly, normal reactivation in the DG. These studies suggest that distinct memory traces are located in the DG and in CA3 but that the strength of the memory is related to reactivation in CA3.},
	number = {1},
	journal = {Neuron},
	author = {Denny, Christine A and Kheirbek, Mazen A and Alba, Eva L and Tanaka, Kenji F and Brachman, Rebecca A and Laughman, Kimberly B and Tomm, Nicole K and Turi, Gergely F and Losonczy, Attila and Hen, René},
	month = jul,
	year = {2014},
	keywords = {merged\_fiete.bib},
	pages = {189--201},
}

@article{richmond_constructing_2017,
	title = {Constructing {Experience}: {Event} {Models} from {Perception} to {Action}},
	volume = {21},
	abstract = {Mental representations of everyday experience are rich, structured, and multimodal. In this article we consider the adaptive pressures that led to human construction of such representations, arguing that structured event representations enable cognitive systems to more effectively predict the trajectory of naturalistic everyday activity. We propose an account of how cortical systems and the hippocampus (HPC) interact to construct, maintain, and update event representations. This analysis throws light on recent research on story comprehension, event segmentation, episodic memory, and action planning. It also suggests how the growing science base can be deployed to diagnose impairments in event perception and memory, and to improve memory for everyday events.},
	number = {12},
	journal = {Trends Cogn. Sci.},
	author = {Richmond, Lauren L and Zacks, Jeffrey M},
	month = dec,
	year = {2017},
	keywords = {merged\_fiete.bib, action planning, binding, episodic memory, event cognition, event segmentation},
	pages = {962--980},
}

@article{radvansky_walking_2006,
	title = {Walking through doorways causes forgetting: situation models and experienced space},
	volume = {34},
	abstract = {We investigated the ability of people to retrieve information about objects as they moved through rooms in a virtual space. People were probed withobject names that were either associated withthe person (i.e., carried) or dissociated from the person (i.e., just set down). Also, people either did or did not shift spatial regions (i.e., go to a new room). Information about objects was less accessible when the objects were dissociated from the person. Furthermore, information about an object was also less available when there was a spatial shift. However, the spatial shift had a larger effect on memory for the currently associated object. These data are interpreted as being more supportive of a situation model explanation, following on work using narratives and film. Simpler memory-based accounts that do not take into account the context in which a person is embedded cannot adequately account for the results.},
	number = {5},
	journal = {Mem. Cognit.},
	author = {Radvansky, Gabriel A and Copeland, David E},
	month = jul,
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {1150--1156},
}

@article{zacks_prediction_2011,
	title = {Prediction error associated with the perceptual segmentation of naturalistic events},
	volume = {23},
	abstract = {Predicting the near future is important for survival and plays a central role in theories of perception, language processing, and learning. Prediction failures may be particularly important for initiating the updating of perceptual and memory systems and, thus, for the subjective experience of events. Here, we asked observers to make predictions about what would happen 5 sec later in a movie of an everyday activity. Those points where prediction was more difficult corresponded with subjective boundaries in the stream of experience. At points of unpredictability, midbrain and striatal regions associated with the phasic release of the neurotransmitter dopamine transiently increased in activity. This activity could provide a global updating signal, cuing other brain systems that a significant new event has begun.},
	number = {12},
	journal = {J. Cogn. Neurosci.},
	author = {Zacks, Jeffrey M and Kurby, Christopher A and Eisenberg, Michelle L and Haroutunian, Nayiri},
	month = dec,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {4057--4066},
}

@article{ezzyat_what_2011,
	title = {What constitutes an episode in episodic memory?},
	volume = {22},
	abstract = {The idea of episodic memory implies the existence of a process that segments experience into episodes so that they can be stored in memory. It is therefore surprising that the link between event segmentation and the organization of experiences into episodes in memory has not been addressed. We found that after participants read narratives containing temporal event boundaries at varying locations in the narrative, their long-term associative memory for information across event boundaries was lower than their memory for information within an event. This suggests that event segmentation during encoding resulted in segmentation of those same events in memory. Further, functional imaging data revealed that, across participants, brain activity consistent with the ongoing integration of information within events correlated with this pattern of mnemonic segmentation. These data are the first to address the mechanisms that support the organization of experiences into episodes in long-term memory.},
	number = {2},
	journal = {Psychol. Sci.},
	author = {Ezzyat, Youssef and Davachi, Lila},
	month = feb,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {243--252},
}

@article{baldassano_discovering_2017,
	title = {Discovering {Event} {Structure} in {Continuous} {Narrative} {Perception} and {Memory}},
	volume = {95},
	abstract = {During realistic, continuous perception, humans automatically segment experiences into discrete events. Using a novel model of cortical event dynamics, we investigate how cortical structures generate event representations during narrative perception and how these events are stored to and retrieved from memory. Our data-driven approach allows us to detect event boundaries as shifts between stable patterns of brain activity without relying on stimulus annotations and reveals a nested hierarchy from short events in sensory regions to long events in high-order areas (including angular gyrus and posterior medial cortex), which represent abstract, multimodal situation models. High-order event boundaries are coupled to increases in hippocampal activity, which predict pattern reinstatement during later free recall. These areas also show evidence of anticipatory reinstatement as subjects listen to a familiar narrative. Based on these results, we propose that brain activity is naturally structured into nested events, which form the basis of long-term memory representations.},
	number = {3},
	journal = {Neuron},
	author = {Baldassano, Christopher and Chen, Janice and Zadbood, Asieh and Pillow, Jonathan W and Hasson, Uri and Norman, Kenneth A},
	month = aug,
	year = {2017},
	keywords = {fMRI, hippocampus, merged\_fiete.bib, memory, event segmentation, event model, Hidden Markov Model, narrative, perception, recall, reinstatement, situation model},
	pages = {709--721.e5},
}

@article{swallow_event_2009,
	title = {Event boundaries in perception affect memory encoding and updating},
	volume = {138},
	abstract = {Memory for naturalistic events over short delays is important for visual scene processing, reading comprehension, and social interaction. The research presented here examined relations between how an ongoing activity is perceptually segmented into events and how those events are remembered a few seconds later. In several studies, participants watched movie clips that presented objects in the context of goal-directed activities. Five seconds after an object was presented, the clip paused for a recognition test. Performance on the recognition test depended on the occurrence of perceptual event boundaries. Objects that were present when an event boundary occurred were better recognized than other objects, suggesting that event boundaries structure the contents of memory. This effect was strongest when an object's type was tested but was also observed for objects' perceptual features. Memory also depended on whether an event boundary occurred between presentation and test; this variable produced complex interactive effects that suggested that the contents of memory are updated at event boundaries. These data indicate that perceptual event boundaries have immediate consequences for what, when, and how easily information can be remembered.},
	number = {2},
	journal = {J. Exp. Psychol. Gen.},
	author = {Swallow, Khena M and Zacks, Jeffrey M and Abrams, Richard A},
	month = may,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {236--257},
}

@article{zacks_human_2001,
	title = {Human brain activity time-locked to perceptual event boundaries},
	volume = {4},
	abstract = {Temporal structure has a major role in human understanding of everyday events. Observers are able to segment ongoing activity into temporal parts and sub-parts that are reliable, meaningful and correlated with ecologically relevant features of the action. Here we present evidence that a network of brain regions is tuned to perceptually salient event boundaries, both during intentional event segmentation and during naive passive viewing of events. Activity within this network may provide a basis for parsing the temporally evolving environment into meaningful units.},
	number = {6},
	journal = {Nat. Neurosci.},
	author = {Zacks, J M and Braver, T S and Sheridan, M A and Donaldson, D I and Snyder, A Z and Ollinger, J M and Buckner, R L and Raichle, M E},
	month = jun,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {651--655},
}

@article{julian_occipital_2016,
	title = {The {Occipital} {Place} {Area} {Is} {Causally} {Involved} in {Representing} {Environmental} {Boundaries} during {Navigation}},
	volume = {26},
	abstract = {Thirty years of research suggests that environmental boundaries-e.g., the walls of an experimental chamber or room-exert powerful influence on navigational behavior, often to the exclusion of other cues [1-9]. Consistent with this behavioral work, neurons in brain structures that instantiate spatial memory often exhibit firing fields that are strongly controlled by environmental boundaries [10-15]. Despite the clear importance of environmental boundaries for spatial coding, however, a brain region that mediates the perception of boundary information has not yet been identified. We hypothesized that the occipital place area (OPA), a scene-selective region located near the transverse occipital sulcus [16], might provide this perceptual source by extracting boundary information from visual scenes during navigation. To test this idea, we used transcranial magnetic stimulation (TMS) to interrupt processing in the OPA while subjects performed a virtual-reality memory task that required them to learn the spatial locations of test objects that were either fixed in place relative to the boundary of the environment or moved in tandem with a landmark object. Consistent with our prediction, we found that TMS to the right OPA impaired spatial memory for boundary-tethered, but not landmark-tethered, objects. Moreover, this effect was found when the boundary was defined by a wall, but not when it was defined by a marking on the ground. These results show that the OPA is causally involved in boundary-based spatial navigation and suggest that the OPA is the perceptual source of the boundary information that controls navigational behavior.},
	number = {8},
	journal = {Curr. Biol.},
	author = {Julian, Joshua B and Ryan, Jack and Hamilton, Roy H and Epstein, Russell A},
	year = {2016},
	keywords = {merged\_fiete.bib},
	pages = {1104--1109},
}

@article{murphy_balanced_2009,
	title = {Balanced amplification: a new mechanism of selective amplification of neural activity patterns},
	volume = {61},
	abstract = {In cerebral cortex, ongoing activity absent a stimulus can resemble stimulus-driven activity in size and structure. In particular, spontaneous activity in cat primary visual cortex (V1) has structure significantly correlated with evoked responses to oriented stimuli. This suggests that, from unstructured input, cortical circuits selectively amplify specific activity patterns. Current understanding of selective amplification involves elongation of a neural assembly's lifetime by mutual excitation among its neurons. We introduce a new mechanism for selective amplification without elongation of lifetime: “balanced amplification.” Strong balanced amplification arises when feedback inhibition stabilizes strong recurrent excitation, a pattern likely to be typical of cortex. Thus, balanced amplification should ubiquitously contribute to cortical activity. Balanced amplification depends on the fact that individual neurons project only excitatory or only inhibitory synapses. This leads to a hidden feedforward connectivity between activity patterns. We show in a detailed biophysical model that this can explain the cat V1 observations.},
	number = {4},
	journal = {Neuron},
	author = {Murphy, Brendan K and Miller, Kenneth D},
	month = feb,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {635--648},
}

@article{erdem_biologically_2014,
	title = {A biologically inspired hierarchical goal directed navigation model},
	volume = {108},
	abstract = {We propose an extended version of our previous goal directed navigation model based on forward planning of trajectories in a network of head direction cells, persistent spiking cells, grid cells, and place cells. In our original work the animat incrementally creates a place cell map by random exploration of a novel environment. After the exploration phase, the animat decides on its next movement direction towards a goal by probing linear look-ahead trajectories in several candidate directions while stationary and picking the one activating place cells representing the goal location. In this work we present several improvements over our previous model. We improve the range of linear look-ahead probes significantly by imposing a hierarchical structure on the place cell map consistent with the experimental findings of differences in the firing field size and spacing of grid cells recorded at different positions along the dorsal to ventral axis of entorhinal cortex. The new model represents the environment at different scales by populations of simulated hippocampal place cells with different firing field sizes. Among other advantages this model allows simultaneous constant duration linear look-ahead probes at different scales while significantly extending each probe range. The extension of the linear look-ahead probe range while keeping its duration constant also limits the degrading effects of noise accumulation in the network. We show the extended model's performance using an animat in a large open field environment.},
	number = {1},
	journal = {J. Physiol. Paris},
	author = {Erdem, Uğur M and Hasselmo, Michael E},
	month = feb,
	year = {2014},
	keywords = {Hippocampus, merged\_fiete.bib, Entorhinal cortex, Grid cell, Navigation, Place cell},
	pages = {28--37},
}

@article{erdem_hierarchical_2015,
	title = {A hierarchical model of goal directed navigation selects trajectories in a visual environment},
	volume = {117},
	abstract = {We have developed a Hierarchical Look-Ahead Trajectory Model (HiLAM) that incorporates the firing pattern of medial entorhinal grid cells in a planning circuit that includes interactions with hippocampus and prefrontal cortex. We show the model's flexibility in representing large real world environments using odometry information obtained from challenging video sequences. We acquire the visual data from a camera mounted on a small tele-operated vehicle. The camera has a panoramic field of view with its focal point approximately 5 cm above the ground level, similar to what would be expected from a rat's point of view. Using established algorithms for calculating perceptual speed from the apparent rate of visual change over time, we generate raw dead reckoning information which loses spatial fidelity over time due to error accumulation. We rectify the loss of fidelity by exploiting the loop-closure detection ability of a biologically inspired, robot navigation model termed RatSLAM. The rectified motion information serves as a velocity input to the HiLAM to encode the environment in the form of grid cell and place cell maps. Finally, we show goal directed path planning results of HiLAM in two different environments, an indoor square maze used in rodent experiments and an outdoor arena more than two orders of magnitude larger than the indoor maze. Together these results bridge for the first time the gap between higher fidelity bio-inspired navigation models (HiLAM) and more abstracted but highly functional bio-inspired robotic mapping systems (RatSLAM), and move from simulated environments into real-world studies in rodent-sized arenas and beyond.},
	journal = {Neurobiol. Learn. Mem.},
	author = {Erdem, Uğur M and Milford, Michael J and Hasselmo, Michael E},
	month = jan,
	year = {2015},
	keywords = {Hippocampus, merged\_fiete.bib, Grid cell, Navigation, Place cell, Path planning, RatSLAM, SLAM},
	pages = {109--121},
}

@article{erdem_goal-directed_2012,
	title = {A goal-directed spatial navigation model using forward trajectory planning based on grid cells},
	volume = {35},
	abstract = {A goal-directed navigation model is proposed based on forward linear look-ahead probe of trajectories in a network of head direction cells, grid cells, place cells and prefrontal cortex (PFC) cells. The model allows selection of new goal-directed trajectories. In a novel environment, the virtual rat incrementally creates a map composed of place cells and PFC cells by random exploration. After exploration, the rat retrieves memory of the goal location, picks its next movement direction by forward linear look-ahead probe of trajectories in several candidate directions while stationary in one location, and finds the one activating PFC cells with the highest reward signal. Each probe direction involves activation of a static pattern of head direction cells to drive an interference model of grid cells to update their phases in a specific direction. The updating of grid cell spiking drives place cells along the probed look-ahead trajectory similar to the forward replay during waking seen in place cell recordings. Directions are probed until the look-ahead trajectory activates the reward signal and the corresponding direction is used to guide goal-finding behavior. We report simulation results in several mazes with and without barriers. Navigation with barriers requires a PFC map topology based on the temporal vicinity of visited place cells and a reward signal diffusion process. The interaction of the forward linear look-ahead trajectory probes with the reward diffusion allows discovery of never-before experienced shortcuts towards a goal location.},
	number = {6},
	journal = {Eur. J. Neurosci.},
	author = {Erdem, Uğur M and Hasselmo, Michael},
	month = mar,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {916--931},
}

@article{olafsdottir_role_2018,
	title = {The {Role} of {Hippocampal} {Replay} in {Memory} and {Planning}},
	volume = {28},
	abstract = {The mammalian hippocampus is important for normal memory function, particularly memory for places and events. Place cells, neurons within the hippocampus that have spatial receptive fields, represent information about an animal's position. During periods of rest, but also during active task engagement, place cells spontaneously recapitulate past trajectories. Such 'replay' has been proposed as a mechanism necessary for a range of neurobiological functions, including systems memory consolidation, recall and spatial working memory, navigational planning, and reinforcement learning. Focusing mainly, but not exclusively, on work conducted in rodents, we describe the methodologies used to analyse replay and review evidence for its putative roles. We identify outstanding questions as well as apparent inconsistencies in existing data, making suggestions as to how these might be resolved. In particular, we find support for the involvement of replay in disparate processes, including the maintenance of hippocampal memories and decision making. We propose that the function of replay changes dynamically according to task demands placed on an organism and its current level of arousal.},
	number = {1},
	journal = {Curr. Biol.},
	author = {Ólafsdóttir, H Freyja and Bush, Daniel and Barry, Caswell},
	year = {2018},
	keywords = {merged\_fiete.bib},
	pages = {R37--R50},
}

@article{karlsson_awake_2009,
	title = {Awake replay of remote experiences in the hippocampus},
	volume = {12},
	number = {7},
	journal = {Nat. Neurosci.},
	author = {Karlsson, Mattias P and Frank, Loren M},
	month = jun,
	year = {2009},
	note = {Publisher: Springer Science and Business Media LLC},
	keywords = {merged\_fiete.bib},
	pages = {913--918},
}

@article{ji_coordinated_2007,
	title = {Coordinated memory replay in the visual cortex and hippocampus during sleep},
	volume = {10},
	abstract = {Sleep replay of awake experience in the cortex and hippocampus has been proposed to be involved in memory consolidation. However, whether temporally structured replay occurs in the cortex and whether the replay events in the two areas are related are unknown. Here we studied multicell spiking patterns in both the visual cortex and hippocampus during slow-wave sleep in rats. We found that spiking patterns not only in the cortex but also in the hippocampus were organized into frames, defined as periods of stepwise increase in neuronal population activity. The multicell firing sequences evoked by awake experience were replayed during these frames in both regions. Furthermore, replay events in the sensory cortex and hippocampus were coordinated to reflect the same experience. These results imply simultaneous reactivation of coherent memory traces in the cortex and hippocampus during sleep that may contribute to or reflect the result of the memory consolidation process.},
	number = {1},
	journal = {Nat. Neurosci.},
	author = {Ji, Daoyun and Wilson, Matthew A},
	month = jan,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {100--107},
}

@article{levy_hippocampal_2020,
	title = {Hippocampal spatial memory representations in mice are heterogeneously stable},
	volume = {31},
	number = {3},
	journal = {Hippocampus},
	author = {Levy, Samuel J and Kinsky, Nathaniel R and Mau, William and Sullivan, David W and Hasselmo, Michael E},
	month = oct,
	year = {2020},
	note = {Publisher: Wiley},
	keywords = {merged\_fiete.bib},
	pages = {244--260},
}

@incollection{dudchenko_splitter_2014,
	title = {Splitter {Cells}: {Hippocampal} {Place} {Cells} {Whose} {Firing} {Is} {Modulated} by {Where} the {Animal} {Is} {Going} or {Where} {It} {Has} {Been}},
	booktitle = {Space,{Time} and {Memory} in the {Hippocampal} {Formation}},
	publisher = {Springer Vienna},
	author = {Dudchenko, Paul A and Wood, Emma R},
	year = {2014},
	keywords = {merged\_fiete.bib},
	pages = {253--272},
}

@article{dong_distinct_2021,
	title = {Distinct place cell dynamics in {CA1} and {CA3} encode experience in new environments},
	volume = {12},
	number = {1},
	journal = {Nat. Commun.},
	author = {Dong, Can and Madar, Antoine D and Sheffield, Mark E J},
	month = may,
	year = {2021},
	note = {Publisher: Springer Science and Business Media LLC},
	keywords = {merged\_fiete.bib},
}

@article{kinsky_trajectory-modulated_2020,
	title = {Trajectory-modulated hippocampal neurons persist throughout memory-guided navigation},
	volume = {11},
	number = {1},
	journal = {Nat. Commun.},
	author = {Kinsky, Nathaniel R and Mau, William and Sullivan, David W and Levy, Samuel J and Ruesch, Evan A and Hasselmo, Michael E},
	month = may,
	year = {2020},
	note = {Publisher: Springer Science and Business Media LLC},
	keywords = {merged\_fiete.bib},
}

@incollection{widloski_how_2014,
	title = {How does the brain solve the computational problems of spatial navigation?},
	booktitle = {Space,{Time} and {Memory} in the {Hippocampal} {Formation}},
	publisher = {Springer Vienna},
	author = {Widloski, John and Fiete, Ila},
	editor = {Derdikman, Dori and Knierim, James J},
	year = {2014},
	keywords = {merged\_fiete.bib},
}

@article{welinder_grid_2008,
	title = {Grid cells: {The} position code, neural network models of activity, and the problem of learning},
	volume = {18},
	number = {12},
	journal = {Hippocampus},
	author = {Welinder, Peter E and Burak, Yoram and Fiete, Ila R},
	month = dec,
	year = {2008},
	note = {Publisher: Wiley},
	keywords = {merged\_fiete.bib},
	pages = {1283--1300},
}

@article{yim_place-cell_2021,
	title = {Place-cell capacity and volatility with grid-like inputs},
	volume = {10},
	abstract = {What factors constrain the arrangement of the multiple fields of a place cell? By modeling place cells as perceptrons that act on multiscale periodic grid-cell inputs, we analytically enumerate a place cell's repertoire - how many field arrangements it can realize without external cues while its grid inputs are unique - and derive its capacity - the spatial range over which it can achieve any field arrangement. We show that the repertoire is very large and relatively noise-robust. However, the repertoire is a vanishing fraction of all arrangements, while capacity scales only as the sum of the grid periods so field arrangements are constrained over larger distances. Thus, grid-driven place field arrangements define a large response scaffold that is strongly constrained by its structured inputs. Finally, we show that altering grid-place weights to generate an arbitrary new place field strongly affects existing arrangements, which could explain the volatility of the place code.},
	journal = {Elife},
	author = {Yim, Man Yi and Sadun, Lorenzo A and Fiete, Ila R and Taillefumier, Thibaud},
	month = may,
	year = {2021},
	keywords = {grid cells, place cells, merged\_fiete.bib, neuroscience, capacity, computational biology, linear separability, none, perceptron, systems biology, volatility},
}

@article{mckenzie_preexisting_2021,
	title = {Preexisting hippocampal network dynamics constrain optogenetically induced place fields},
	volume = {109},
	abstract = {Memory models often emphasize the need to encode novel patterns of neural activity imposed by sensory drive. Prior learning and innate architecture likely restrict neural plasticity, however. Here, we test how the incorporation of synthetic hippocampal signals is constrained by preexisting circuit dynamics. We optogenetically stimulated small groups of CA1 neurons as mice traversed a chosen segment of a linear track, mimicking the emergence of place fields. Stimulation induced persistent place field remapping in stimulated and non-stimulated neurons. The emergence of place fields could be predicted from sporadic firing in the new place field location and the temporal relationship to peer neurons before the optogenetic perturbation. Circuit modification was reflected by altered spike transmission between connected pyramidal cells and inhibitory interneurons, which persisted during post-experience sleep. We hypothesize that optogenetic perturbation unmasked sub-threshold place fields. Plasticity in recurrent/lateral inhibition may drive learning through the rapid association of existing states.},
	number = {6},
	journal = {Neuron},
	author = {McKenzie, Sam and Huszár, Roman and English, Daniel F and Kim, Kanghwan and Christensen, Fletcher and Yoon, Euisik and Buzsáki, György},
	year = {2021},
	keywords = {place cells, Memory, merged\_fiete.bib, learning, blank slate, consolidation, inhibition, optogenetics, plasticity, preconfigured brain, sharp wave ripples},
	pages = {1040--1054.e7},
}

@article{bouffard_temporal_2018,
	title = {Temporal encoding strategies result in boosts to final free recall performance comparable to spatial ones},
	volume = {46},
	abstract = {The method of loci is a highly effective mnemonic that recruits existing salient memory for spatial locations and uses the information as a scaffold for remembering a list of items (Yates, 1966). One possible account for the effectiveness of the spatial method of loci comes from the perspective that it utilizes evolutionarily preserved mechanisms for spatial navigation within the hippocampus (Maguire et al. in Proceedings of the National Academy of Sciences, 97(8), 4398-4403, 2000; O'Keefe \& Nadel, 1978; Rodriguez et al. in Brain Research Bulletin, 57(3), 499-503, 2002). Recently, though, neurons representing temporal information have also been described within the hippocampus (Eichenbaum in Nature Reviews Neuroscience, 15(11), 732-744, 2014; Itskov, Curto, Pastalkova, \& Buzsáki in The Journal of Neuroscience, 31(8), 2828-2834, 2011; MacDonald, Lepage, Eden, \& Eichenbaum in Neuron, 71(4), 737-749, 2011; Mankin et al. in Proceedings of the National Academy of Sciences, 109(47), 19462-19467, 2012; Meck, Church, \& Matell in Behavioral Neuroscience, 127(5), 642, 2013), challenging the primacy of spatial-based functions to hippocampal processing. Given the presence of both spatial and temporal coding mechanisms within the hippocampus, we predicted that primarily temporal encoding strategies might also enhance memory. In two different experiments, we asked participants to learn lists of unrelated nouns using the (spatial) method of loci (i.e., the layout of their home as the organizing feature) or using two novel temporal methods (i.e., autobiographical memories or using the steps to making a sandwich). Participants' final free recall performance showed comparable boosts to the method of loci for both temporal encoding strategies, with all three scaffolding approaches demonstrating performance well above uninstructed free recall. Our findings suggest that primarily temporal representations can be used effectively to boost memory performance, comparable to spatial methods, with some caveats related to the relative ease with which participants appear to master the spatial versus temporal methods.},
	number = {1},
	journal = {Mem. Cognit.},
	author = {Bouffard, Nichole and Stokes, Jared and Kramer, Hannah J and Ekstrom, Arne D},
	year = {2018},
	keywords = {merged\_fiete.bib, Episodic memory, Method of loci, Sequence learning, Spatial navigation, Temporal},
	pages = {17--31},
}

@inproceedings{andreas_neural_2016,
	title = {Neural {Module} {Networks}},
	booktitle = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
	month = jun,
	year = {2016},
	keywords = {merged\_fiete.bib},
}

@article{kraus_hippocampal_2013,
	title = {Hippocampal {Time} {Cells}: {Time} versus {Path} {Integration}},
	volume = {78},
	number = {6},
	journal = {Neuron},
	author = {Kraus, Benjamin J and Robinson, Robert J and White, John A and Eichenbaum, Howard and Hasselmo, Michael E},
	month = jun,
	year = {2013},
	note = {Publisher: Elsevier BV},
	keywords = {merged\_fiete.bib},
	pages = {1090--1101},
}

@article{pastalkova_internally_2008,
	title = {Internally {Generated} {Cell} {Assembly} {Sequences} in the {Rat} {Hippocampus}},
	volume = {321},
	number = {5894},
	journal = {Science},
	author = {Pastalkova, +eva and Itskov, +vladimir and Amarasingham, +asohan and Buzsáki, +györgy},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {1322--1327},
}

@article{hoydal_object-vector_2019,
	title = {Object-vector coding in the medial entorhinal cortex},
	volume = {568},
	number = {7752},
	journal = {Nature},
	author = {Høydal, Øyvind Arne and Skytøen, Emilie Ranheim and Andersson, Sebastian Ola and Moser, May-Britt and Moser, Edvard I},
	month = apr,
	year = {2019},
	note = {Publisher: Springer Science and Business Media LLC},
	keywords = {merged\_fiete.bib},
	pages = {400--404},
}

@inproceedings{badino_visual_2011,
	title = {Visual topometric localization},
	booktitle = {2011 {IEEE} {Intelligent} {Vehicles} {Symposium} ({IV})},
	author = {Badino, H and Huber, D and Kanade, T},
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {794--799},
}

@inproceedings{simsek_using_2004,
	title = {Using relative novelty to identify useful temporal abstractions in reinforcement learning},
	booktitle = {Twenty-first international conference on {Machine} learning - {ICML} {\textbackslash}textbackslashtextquotesingle04},
	publisher = {ACM Press},
	author = {Şimşek, Özgür and Barto, Andrew G},
	year = {2004},
	keywords = {merged\_fiete.bib},
}

@inproceedings{pathak_curiosity-driven_2017,
	title = {Curiosity-{Driven} {Exploration} by {Self}-{Supervised} {Prediction}},
	booktitle = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR}) {Workshops}},
	author = {Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
	month = jul,
	year = {2017},
	keywords = {merged\_fiete.bib},
}

@article{sutton_between_1999,
	title = {Between {MDPs} and semi-{MDPs}: {A} framework for temporal abstraction in reinforcement learning},
	volume = {112},
	abstract = {Learning, planning, and representing knowledge at multiple levels of temporal abstraction are key, longstanding challenges for AI. In this paper we consider how these challenges can be addressed within the mathematical framework of reinforcement learning and Markov decision processes (MDPs). We extend the usual notion of action in this framework to include options—closed-loop policies for taking action over a period of time. Examples of options include picking up an object, going to lunch, and traveling to a distant city, as well as primitive actions such as muscle twitches and joint torques. Overall, we show that options enable temporally abstract knowledge and action to be included in the reinforcement learning framework in a natural and general way. In particular, we show that options may be used interchangeably with primitive actions in planning methods such as dynamic programming and in learning methods such as Q-learning. Formally, a set of options defined over an MDP constitutes a semi-Markov decision process (SMDP), and the theory of SMDPs provides the foundation for the theory of options. However, the most interesting issues concern the interplay between the underlying MDP and the SMDP and are thus beyond SMDP theory. We present results for three such cases: (1) we show that the results of planning with options can be used during execution to interrupt options and thereby perform even better than planned, (2) we introduce new intra-option methods that are able to learn about an option from fragments of its execution, and (3) we propose a notion of subgoal that can be used to improve the options themselves. All of these results have precursors in the existing literature; the contribution of this paper is to establish them in a simpler and more general setting with fewer changes to the existing reinforcement learning framework. In particular, we show that these results can be obtained without committing to (or ruling out) any particular approach to state abstraction, hierarchy, function approximation, or the macro-utility problem.},
	number = {1},
	journal = {Artif. Intell.},
	author = {Sutton, Richard S and Precup, Doina and Singh, Satinder},
	year = {1999},
	keywords = {merged\_fiete.bib, Hierarchical planning, Intra-option learning, Macroactions, Macros, Markov decision processes, Options, Reinforcement learning, Semi-Markov decision processes, Subgoals, Temporal abstraction},
	pages = {181--211},
}

@article{squire_legacy_2009,
	title = {The legacy of patient {H}.{M}. for neuroscience},
	volume = {61},
	abstract = {H.M. is probably the best known single patient in the history of neuroscience. His severe memory impairment, which resulted from experimental neurosurgery to control seizures, was the subject of study for five decades until his death in December 2008. Work with H.M. established fundamental principles about how memory functions are organized in the brain.},
	number = {1},
	journal = {Neuron},
	author = {Squire, Larry R},
	month = jan,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {6--9},
}

@article{kang_geometric_2019,
	title = {A geometric attractor mechanism for self-organization of entorhinal grid modules},
	volume = {8},
	abstract = {Grid cells in the medial entorhinal cortex (MEC) respond when an animal occupies a periodic lattice of 'grid fields' in the environment. The grids are organized in modules with spatial periods, or scales, clustered around discrete values separated on average by ratios in the range 1.4-1.7. We propose a mechanism that produces this modular structure through dynamical self-organization in the MEC. In attractor network models of grid formation, the grid scale of a single module is set by the distance of recurrent inhibition between neurons. We show that the MEC forms a hierarchy of discrete modules if a smooth increase in inhibition distance along its dorso-ventral axis is accompanied by excitatory interactions along this axis. Moreover, constant scale ratios between successive modules arise through geometric relationships between triangular grids and have values that fall within the observed range. We discuss how interactions required by our model might be tested experimentally.},
	journal = {Elife},
	author = {Kang, Louis and Balasubramanian, Vijay},
	year = {2019},
	keywords = {entorhinal cortex, merged\_fiete.bib, grid cell, neuroscience, none, continuous attractor, geometry, grid module, physics of living systems, self-organization},
}

@article{urdapilleta_self_2017,
	title = {Self organization of modular activity of grid cells},
	volume = {27},
	abstract = {A unique topographical representation of space is found in the concerted activity of grid cells in the rodent medial entorhinal cortex. Many among the principal cells in this region exhibit a hexagonal firing pattern, in which each cell expresses its own set of place fields (spatial phases) at the vertices of a triangular grid, the spacing and orientation of which are typically shared with neighboring cells. Grid spacing, in particular, has been found to increase along the dorso-ventral axis of the entorhinal cortex but in discrete steps, that is, with a modular structure. In this study, we show that such a modular activity may result from the self-organization of interacting units, which individually would not show discrete but rather continuously varying grid spacing. Within our “adaptation” network model, the effect of a continuously varying time constant, which determines grid spacing in the isolated cell model, is modulated by recurrent collateral connections, which tend to produce a few subnetworks, akin to magnetic domains, each with its own grid spacing. In agreement with experimental evidence, the modular structure is tightly defined by grid spacing, but also involves grid orientation and distortion, due to interactions across modules. Thus, our study sheds light onto a possible mechanism, other than simply assuming separate networks a priori, underlying the formation of modular grid representations.},
	number = {11},
	journal = {Hippocampus},
	author = {Urdapilleta, Eugenio and Si, Bailu and Treves, Alessandro},
	year = {2017},
	keywords = {grid cells, merged\_fiete.bib, self-organization, modules},
	pages = {1204--1213},
}

@inproceedings{alet_modular_2018,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Modular meta-learning},
	volume = {87},
	abstract = {Many prediction problems, such as those that arise in the context of robotics, have a simplifying underlying structure that, if known, could accelerate learning. In this paper, we present a strategy for learning a set of neural network modules that can be combined in different ways. We train different modular structures on a set of related tasks and generalize to new tasks by composing the learned modules in new ways. By reusing modules to generalize we achieve combinatorial generalization, akin to the ”infinite use of finite means” displayed in language. Finally, we show this improves performance in two robotics-related problems.},
	booktitle = {Proceedings of {The} 2nd {Conference} on {Robot} {Learning}},
	publisher = {PMLR},
	author = {Alet, Ferran and Lozano-Perez, Tomas and Kaelbling, Leslie P},
	editor = {Billard, Aude and Dragan, Anca and Peters, Jan and Morimoto, Jun},
	year = {2018},
	keywords = {merged\_fiete.bib},
	pages = {856--868},
}

@article{kashtan_spontaneous_2005,
	title = {Spontaneous evolution of modularity and network motifs},
	volume = {102},
	abstract = {Biological networks have an inherent simplicity: they are modular with a design that can be separated into units that perform almost independently. Furthermore, they show reuse of recurring patterns termed network motifs. Little is known about the evolutionary origin of these properties. Current models of biological evolution typically produce networks that are highly nonmodular and lack understandable motifs. Here, we suggest a possible explanation for the origin of modularity and network motifs in biology. We use standard evolutionary algorithms to evolve networks. A key feature in this study is evolution under an environment (evolutionary goal) that changes in a modular fashion. That is, we repeatedly switch between several goals, each made of a different combination of subgoals. We find that such “modularly varying goals” lead to the spontaneous evolution of modular network structure and network motifs. The resulting networks rapidly evolve to satisfy each of the different goals. Such switching between related goals may represent biological evolution in a changing environment that requires different combinations of a set of basic biological functions. The present study may shed light on the evolutionary forces that promote structural simplicity in biological networks and offers ways to improve the evolutionary design of engineered systems.},
	number = {39},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Kashtan, Nadav and Alon, Uri},
	month = sep,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {13773--13778},
}

@article{wagner_road_2007,
	title = {The road to modularity},
	volume = {8},
	abstract = {A network of interactions is called modular if it is subdivided into relatively autonomous, internally highly connected components. Modularity has emerged as a rallying point for research in developmental and evolutionary biology (and specifically evo-devo), as well as in molecular systems biology. Here we review the evidence for modularity and models about its origin. Although there is an emerging agreement that organisms have a modular organization, the main open problem is the question of whether modules arise through the action of natural selection or because of biased mutational mechanisms.},
	number = {12},
	journal = {Nat. Rev. Genet.},
	author = {Wagner, Günter P and Pavlicev, Mihaela and Cheverud, James M},
	month = dec,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {921--931},
}

@article{hasan_topological_2010,
	title = {Topological insulators},
	volume = {82},
	number = {4},
	journal = {Rev. Mod. Phys.},
	author = {Hasan, M Z},
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {3045--3067},
}

@inproceedings{parascandolo_learning_2018,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Learning {Independent} {Causal} {Mechanisms}},
	volume = {80},
	abstract = {Statistical learning relies upon data sampled from a distribution, and we usually do not care what actually generated it in the first place. From the point of view of causal modeling, the structure of each distribution is induced by physical mechanisms that give rise to dependences between observables. Mechanisms, however, can be meaningful autonomous modules of generative models that make sense beyond a particular entailed data distribution, lending themselves to transfer between problems. We develop an algorithm to recover a set of independent (inverse) mechanisms from a set of transformed data points. The approach is unsupervised and based on a set of experts that compete for data generated by the mechanisms, driving specialization. We analyze the proposed method in a series of experiments on image data. Each expert learns to map a subset of the transformed data back to a reference distribution. The learned mechanisms generalize to novel domains. We discuss implications for transfer learning and links to recent trends in generative modeling.},
	booktitle = {Proceedings of the 35th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Parascandolo, Giambattista and Kilbertus, Niki and Rojas-Carulla, Mateo and Schölkopf, Bernhard},
	editor = {Dy, Jennifer and Krause, Andreas},
	year = {2018},
	keywords = {merged\_fiete.bib},
	pages = {4036--4044},
}

@article{chaudhuri_diversity_2014,
	title = {A diversity of localized timescales in network activity},
	volume = {3},
	abstract = {Neurons show diverse timescales, so that different parts of a network respond with disparate temporal dynamics. Such diversity is observed both when comparing timescales across brain areas and among cells within local populations; the underlying circuit mechanism remains unknown. We examine conditions under which spatially local connectivity can produce such diverse temporal behavior. In a linear network, timescales are segregated if the eigenvectors of the connectivity matrix are localized to different parts of the network. We develop a framework to predict the shapes of localized eigenvectors. Notably, local connectivity alone is insufficient for separate timescales. However, localization of timescales can be realized by heterogeneity in the connectivity profile, and we demonstrate two classes of network architecture that allow such localization. Our results suggest a framework to relate structural heterogeneity to functional diversity and, beyond neural dynamics, are generally applicable to the relationship between structure and dynamics in biological networks. DOI: http://dx.doi.org/10.7554/eLife.01239.001.},
	journal = {Elife},
	author = {Chaudhuri, Rishidev and Bernacchia, Alberto and Wang, Xiao-Jing},
	year = {2014},
	keywords = {neural networks, merged\_fiete.bib, network dynamics, timescales},
	pages = {e01239},
}

@article{george_clone-structured_2021,
	title = {Clone-structured graph representations enable flexible learning and vicarious evaluation of cognitive maps},
	volume = {12},
	abstract = {Cognitive maps are mental representations of spatial and conceptual relationships in an environment, and are critical for flexible behavior. To form these abstract maps, the hippocampus has to learn to separate or merge aliased observations appropriately in different contexts in a manner that enables generalization and efficient planning. Here we propose a specific higher-order graph structure, clone-structured cognitive graph (CSCG), which forms clones of an observation for different contexts as a representation that addresses these problems. CSCGs can be learned efficiently using a probabilistic sequence model that is inherently robust to uncertainty. We show that CSCGs can explain a variety of cognitive map phenomena such as discovering spatial relations from aliased sensations, transitive inference between disjoint episodes, and formation of transferable schemas. Learning different clones for different contexts explains the emergence of splitter cells observed in maze navigation and event-specific responses in lap-running experiments. Moreover, learning and inference dynamics of CSCGs offer a coherent explanation for disparate place cell remapping phenomena. By lifting aliased observations into a hidden space, CSCGs reveal latent modularity useful for hierarchical abstraction and planning. Altogether, CSCG provides a simple unifying framework for understanding hippocampal function, and could be a pathway for forming relational abstractions in artificial intelligence.},
	number = {1},
	journal = {Nat. Commun.},
	author = {George, Dileep and Rikhye, Rajeev V and Gothoskar, Nishad and Guntupalli, J Swaroop and Dedieu, Antoine and Lázaro-Gredilla, Miguel},
	year = {2021},
	keywords = {merged\_fiete.bib},
	pages = {2392},
}

@article{carpenter_grid_2015,
	title = {Grid cells form a global representation of connected environments},
	volume = {25},
	abstract = {The firing patterns of grid cells in medial entorhinal cortex (mEC) and associated brain areas form triangular arrays that tessellate the environment [1, 2] and maintain constant spatial offsets to each other between environments [3, 4]. These cells are thought to provide an efficient metric for navigation in large-scale space [5-8]. However, an accurate and universal metric requires grid cell firing patterns to uniformly cover the space to be navigated, in contrast to recent demonstrations that environmental features such as boundaries can distort [9-11] and fragment [12] grid patterns. To establish whether grid firing is determined by local environmental cues, or provides a coherent global representation, we recorded mEC grid cells in rats foraging in an environment containing two perceptually identical compartments connected via a corridor. During initial exposures to the multicompartment environment, grid firing patterns were dominated by local environmental cues, replicating between the two compartments. However, with prolonged experience, grid cell firing patterns formed a single, continuous representation that spanned both compartments. Thus, we provide the first evidence that in a complex environment, grid cell firing can form the coherent global pattern necessary for them to act as a metric capable of supporting large-scale spatial navigation.},
	number = {9},
	journal = {Curr. Biol.},
	author = {Carpenter, Francis and Manson, Daniel and Jeffery, Kate and Burgess, Neil and Barry, Caswell},
	month = may,
	year = {2015},
	keywords = {merged\_fiete.bib},
	pages = {1176--1182},
}

@article{machado_laplacian_2017,
	title = {A {Laplacian} {Framework} for {Option} {Discovery} in {Reinforcement} {Learning}},
	volume = {abs/1703.00956},
	journal = {CoRR},
	author = {Machado, Marlos C and Bellemare, Marc G and Bowling, Michael H},
	year = {2017},
	keywords = {merged\_fiete.bib},
}

@article{stachenfeld_hippocampus_2017,
	title = {The hippocampus as a predictive map},
	volume = {20},
	abstract = {A cognitive map has long been the dominant metaphor for hippocampal function, embracing the idea that place cells encode a geometric representation of space. However, evidence for predictive coding, reward sensitivity and policy dependence in place cells suggests that the representation is not purely spatial. We approach this puzzle from a reinforcement learning perspective: what kind of spatial representation is most useful for maximizing future reward? We show that the answer takes the form of a predictive representation. This representation captures many aspects of place cell responses that fall outside the traditional view of a cognitive map. Furthermore, we argue that entorhinal grid cells encode a low-dimensionality basis set for the predictive representation, useful for suppressing noise in predictions and extracting multiscale structure for hierarchical planning.},
	number = {11},
	journal = {Nat. Neurosci.},
	author = {Stachenfeld, Kimberly L and Botvinick, Matthew M and Gershman, Samuel J},
	month = nov,
	year = {2017},
	keywords = {merged\_fiete.bib},
	pages = {1643--1653},
}

@article{julian_neurocognitive_2018,
	title = {The {Neurocognitive} {Basis} of {Spatial} {Reorientation}},
	volume = {28},
	abstract = {The ability to recover one's bearings when lost is a skill that is fundamental for spatial navigation. We review the cognitive and neural mechanisms that underlie this ability, with the aim of linking together previously disparate findings from animal behavior, human psychology, electrophysiology, and cognitive neuroscience. Behavioral work suggests that reorientation involves two key abilities: first, the recovery of a spatial reference frame (a cognitive map) that is appropriate to the current environment; and second, the determination of one's heading and location relative to that reference frame. Electrophysiological recording studies, primarily in rodents, have revealed potential correlates of these operations in place, grid, border/boundary, and head-direction cells in the hippocampal formation. Cognitive neuroscience studies, primarily in humans, suggest that the perceptual inputs necessary for these operations are processed by neocortical regions such as the retrosplenial complex, occipital place area and parahippocampal place area, with the retrosplenial complex mediating spatial transformations between the local environment and the recovered spatial reference frame, the occipital place area supporting perception of local boundaries, and the parahippocampal place area processing visual information that is essential for identification of the local spatial context. By combining results across these various literatures, we converge on a unified account of reorientation that bridges the cognitive and neural domains.},
	number = {17},
	journal = {Curr. Biol.},
	author = {Julian, Joshua B and Keinath, Alexandra T and Marchette, Steven A and Epstein, Russell A},
	year = {2018},
	keywords = {merged\_fiete.bib},
	pages = {R1059--R1073},
}

@article{olveczky_vocal_2005,
	title = {Vocal experimentation in the juvenile songbird requires a basal ganglia circuit},
	volume = {3},
	abstract = {Songbirds learn their songs by trial-and-error experimentation, producing highly variable vocal output as juveniles. By comparing their own sounds to the song of a tutor, young songbirds gradually converge to a stable song that can be a remarkably good copy of the tutor song. Here we show that vocal variability in the learning songbird is induced by a basal-ganglia-related circuit, the output of which projects to the motor pathway via the lateral magnocellular nucleus of the nidopallium (LMAN). We found that pharmacological inactivation of LMAN dramatically reduced acoustic and sequence variability in the songs of juvenile zebra finches, doing so in a rapid and reversible manner. In addition, recordings from LMAN neurons projecting to the motor pathway revealed highly variable spiking activity across song renditions, showing that LMAN may act as a source of variability. Lastly, pharmacological blockade of synaptic inputs from LMAN to its target premotor area also reduced song variability. Our results establish that, in the juvenile songbird, the exploratory motor behavior required to learn a complex motor sequence is dependent on a dedicated neural circuit homologous to cortico-basal ganglia circuits in mammals.},
	number = {5},
	journal = {PLoS Biol.},
	author = {Olveczky, Bence P and Andalman, Aaron S and Fee, Michale S},
	month = may,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {e153},
}

@article{banino_vector-based_2018,
	title = {Vector-based navigation using grid-like representations in artificial agents},
	volume = {557},
	abstract = {Deep neural networks have achieved impressive successes in fields ranging from object recognition to complex games such as Go1,2. Navigation, however, remains a substantial challenge for artificial agents, with deep neural networks trained by reinforcement learning3-5 failing to rival the proficiency of mammalian spatial behaviour, which is underpinned by grid cells in the entorhinal cortex 6 . Grid cells are thought to provide a multi-scale periodic representation that functions as a metric for coding space7,8 and is critical for integrating self-motion (path integration)6,7,9 and planning direct trajectories to goals (vector-based navigation)7,10,11. Here we set out to leverage the computational functions of grid cells to develop a deep reinforcement learning agent with mammal-like navigational abilities. We first trained a recurrent network to perform path integration, leading to the emergence of representations resembling grid cells, as well as other entorhinal cell types 12 . We then showed that this representation provided an effective basis for an agent to locate goals in challenging, unfamiliar, and changeable environments-optimizing the primary objective of navigation through deep reinforcement learning. The performance of agents endowed with grid-like representations surpassed that of an expert human and comparison agents, with the metric quantities necessary for vector-based navigation derived from grid-like units within the network. Furthermore, grid-like representations enabled agents to conduct shortcut behaviours reminiscent of those performed by mammals. Our findings show that emergent grid-like representations furnish agents with a Euclidean spatial metric and associated vector operations, providing a foundation for proficient navigation. As such, our results support neuroscientific theories that see grid cells as critical for vector-based navigation7,10,11, demonstrating that the latter can be combined with path-based strategies to support navigation in challenging environments.},
	number = {7705},
	journal = {Nature},
	author = {Banino, Andrea and Barry, Caswell and Uria, Benigno and Blundell, Charles and Lillicrap, Timothy and Mirowski, Piotr and Pritzel, Alexander and Chadwick, Martin J and Degris, Thomas and Modayil, Joseph and Wayne, Greg and Soyer, Hubert and Viola, Fabio and Zhang, Brian and Goroshin, Ross and Rabinowitz, Neil and Pascanu, Razvan and Beattie, Charlie and Petersen, Stig and Sadik, Amir and Gaffney, Stephen and King, Helen and Kavukcuoglu, Koray and Hassabis, Demis and Hadsell, Raia and Kumaran, Dharshan},
	year = {2018},
	keywords = {merged\_fiete.bib},
	pages = {429--433},
}

@article{melo_modularity_2016,
	title = {Modularity: genes, development and evolution},
	volume = {47},
	abstract = {Modularity has emerged as a central concept for evolutionary biology, providing the field with a theory of organismal structure and variation. This theory has reframed long standing questions and serves as a unified conceptual framework for genetics, developmental biology and multivariate evolution. Research programs in systems biology and quantitative genetics are bridging the gap between these fields. While this synthesis is ongoing, some major themes have emerged and empirical evidence for modularity has become abundant. In this review, we look at modularity from an historical perspective, highlighting its meaning at different levels of biological organization and the different methods that can be used to detect it. We then explore the relationship between quantitative genetic approaches to modularity and developmental genetic studies. We conclude by investigating the dynamic relationship between modularity and the adaptive landscape and how this potentially shapes evolution and can help bridge the gap between micro- and macroevolution.},
	journal = {Annu. Rev. Ecol. Evol. Syst.},
	author = {Melo, Diogo and Porto, Arthur and Cheverud, James M and Marroig, Gabriel},
	year = {2016},
	keywords = {merged\_fiete.bib, adaptive landscape, G-matrix, genotype-phenotype map, macroevolution, morphological integration},
	pages = {463--486},
}

@article{st_johnston_origin_1992,
	title = {The origin of pattern and polarity in the {Drosophila} embryo},
	volume = {68},
	number = {2},
	journal = {Cell},
	author = {St Johnston, D and Nüsslein-Volhard, C},
	month = jan,
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {201--219},
}

@article{wang_macroscopic_2020,
	title = {Macroscopic gradients of synaptic excitation and inhibition in the neocortex},
	volume = {21},
	abstract = {With advances in connectomics, transcriptome and neurophysiological technologies, the neuroscience of brain-wide neural circuits is poised to take off. A major challenge is to understand how a vast diversity of functions is subserved by parcellated areas of mammalian neocortex composed of repetitions of a canonical local circuit. Areas of the cerebral cortex differ from each other not only in their input-output patterns but also in their biological properties. Recent experimental and theoretical work has revealed that such variations are not random heterogeneities; rather, synaptic excitation and inhibition display systematic macroscopic gradients across the entire cortex, and they are abnormal in mental illness. Quantitative differences along these gradients can lead to qualitatively novel behaviours in non-linear neural dynamical systems, by virtue of a phenomenon mathematically described as bifurcation. The combination of macroscopic gradients and bifurcations, in tandem with biological evolution, development and plasticity, provides a generative mechanism for functional diversity among cortical areas, as a general principle of large-scale cortical organization.},
	number = {3},
	journal = {Nat. Rev. Neurosci.},
	author = {Wang, Xiao-Jing},
	year = {2020},
	keywords = {merged\_fiete.bib},
	pages = {169--178},
}

@article{wilson_mechanisms_2005,
	title = {The mechanisms of dorsoventral patterning in the vertebrate neural tube},
	volume = {282},
	abstract = {We describe the essential features of and the molecules involved in dorsoventral (DV) patterning in the neural tube. The neural tube is, from its very outset, patterned in this axis as there is a roof plate, floor plate, and differing numbers and types of neuroblasts. These neuroblasts develop into different types of neurons which express a different range of marker genes. Early embryological experiments identified the notochord and the somites as being responsible for the DV patterning of the neural tube and we now know that 4 signaling molecules are involved and are generated by these surrounding structures. Fibroblast growth factors (FGFs) are produced by the caudal mesoderm and must be down-regulated before neural differentiation can occur. Retinoic acid (RA) is produced by the paraxial mesoderm and is an inducer of neural differentiation and patterning and is responsible for down-regulating FGF. Sonic hedgehog (Shh) is produced by the notochord and floor plate and is responsible for inducing ventral neural cell types in a concentration-dependent manner. Bone morphogenetic proteins (BMPs) are produced by the roof plate and are responsible for inducing dorsal neural cell types in a concentration-dependent manner. Subsequently, RA is used twice more. Once from the somites for motor neuron differentiation and secondly RA is used to define the motor neuron subtypes, but in the latter case it is generated within the neural tube from differentiating motor neurons rather than from outside. These 4 signaling molecules also interact with each other, generally in a repressive fashion, and DV patterning shows how complex these interactions can be.},
	number = {1},
	journal = {Dev. Biol.},
	author = {Wilson, Leigh and Maden, Malcolm},
	month = jun,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {1--13},
}

@article{almuedo-castillo_scale-invariant_2018,
	title = {Scale-invariant patterning by size-dependent inhibition of {Nodal} signalling},
	volume = {20},
	abstract = {Individuals can vary substantially in size, but the proportions of their body plans are often maintained. We generated smaller zebrafish by removing 30\% of their cells at the blastula stages and found that these embryos developed into normally patterned individuals. Strikingly, the proportions of all germ layers adjusted to the new embryo size within 2 hours after cell removal. As Nodal-Lefty signalling controls germ-layer patterning, we performed a computational screen for scale-invariant models of this activator-inhibitor system. This analysis predicted that the concentration of the highly diffusive inhibitor Lefty increases in smaller embryos, leading to a decreased Nodal activity range and contracted germ-layer dimensions. In vivo studies confirmed that Lefty concentration increased in smaller embryos, and embryos with reduced Lefty levels or with diffusion-hindered Lefty failed to scale their tissue proportions. These results reveal that size-dependent inhibition of Nodal signalling allows scale-invariant patterning.},
	number = {9},
	journal = {Nat. Cell Biol.},
	author = {Almuedo-Castillo, María and Bläßle, Alexander and Mörsdorf, David and Marcon, Luciano and Soh, Gary H and Rogers, Katherine W and Schier, Alexander F and Müller, Patrick},
	year = {2018},
	keywords = {merged\_fiete.bib},
	pages = {1032--1042},
}

@article{rogers_morphogen_2011,
	title = {Morphogen gradients: from generation to interpretation},
	volume = {27},
	abstract = {Morphogens are long-range signaling molecules that pattern developing tissues in a concentration-dependent manner. The graded activity of morphogens within tissues exposes cells to different signal levels and leads to region-specific transcriptional responses and cell fates. In its simplest incarnation, a morphogen signal forms a gradient by diffusion from a local source and clearance in surrounding tissues. Responding cells often transduce morphogen levels in a linear fashion, which results in the graded activation of transcriptional effectors. The concentration-dependent expression of morphogen target genes is achieved by their different binding affinities for transcriptional effectors as well as inputs from other transcriptional regulators. Morphogen distribution and interpretation are the result of complex interactions between the morphogen and responding tissues. The response to a morphogen is dependent not simply on morphogen concentration but also on the duration of morphogen exposure and the state of the target cells. In this review, we describe the morphogen concept and discuss the mechanisms that underlie the generation, modulation, and interpretation of morphogen gradients.},
	journal = {Annu. Rev. Cell Dev. Biol.},
	author = {Rogers, Katherine W and Schier, Alexander F},
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {377--407},
}

@article{schweisguth_self-organization_2019,
	title = {Self-{Organization} in {Pattern} {Formation}},
	volume = {49},
	abstract = {Self-organization is pervasive in development, from symmetry breaking in the early embryo to tissue patterning and morphogenesis. For a few model systems, the underlying molecular and cellular processes are now sufficiently characterized that mathematical models can be confronted with experiments, to explore the dynamics of pattern formation. Here, we review selected systems, ranging from cyanobacteria to mammals, where different forms of cell-cell communication, acting alone or together with positional cues, drive the patterning of cell fates, highlighting the insights that even very simple models can provide as well as the challenges on the path to a predictive understanding of development.},
	number = {5},
	journal = {Dev. Cell},
	author = {Schweisguth, François and Corson, Francis},
	year = {2019},
	keywords = {merged\_fiete.bib, self-organization, cell fate, mathematical modeling, patterning, Turing},
	pages = {659--677},
}

@article{lake_building_2017,
	title = {Building machines that learn and think like people},
	volume = {40},
	abstract = {Recent progress in artificial intelligence has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats that of humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn and how they learn it. Specifically, we argue that these machines should (1) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (2) ground learning in intuitive theories of physics and psychology to support and enrich the knowledge that is learned; and (3) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes toward these goals that can combine the strengths of recent neural network advances with more structured cognitive models.},
	journal = {Behav. Brain Sci.},
	author = {Lake, Brenden M and Ullman, Tomer D and Tenenbaum, Joshua B and Gershman, Samuel J},
	month = jan,
	year = {2017},
	keywords = {merged\_fiete.bib},
	pages = {e253},
}

@article{frankland_concepts_2020,
	title = {Concepts and {Compositionality}: {In} {Search} of the {Brain}'s {Language} of {Thought}},
	volume = {71},
	abstract = {Imagine Genghis Khan, Aretha Franklin, and the Cleveland Cavaliers performing an opera on Maui. This silly sentence makes a serious point: As humans, we can flexibly generate and comprehend an unbounded number of complex ideas. Little is known, however, about how our brains accomplish this. Here we assemble clues from disparate areas of cognitive neuroscience, integrating recent research on language, memory, episodic simulation, and computational models of high-level cognition. Our review is framed by Fodor's classic language of thought hypothesis, according to which our minds employ an amodal, language-like system for combining and recombining simple concepts to form more complex thoughts. Here, we highlight emerging work on combinatorial processes in the brain and consider this work's relation to the language of thought. We review evidence for distinct, but complementary, contributions of map-like representations in subregions of the default mode network and sentence-like representations of conceptual relations in regions of the temporal and prefrontal cortex.},
	journal = {Annu. Rev. Psychol.},
	author = {Frankland, Steven M and Greene, Joshua D},
	year = {2020},
	keywords = {grid cells, merged\_fiete.bib, artificial intelligence, compositionality, conceptual combination, default mode network, language of thought},
	pages = {273--303},
}

@article{fodor_connectionism_1988,
	title = {Connectionism and cognitive architecture: a critical analysis},
	volume = {28},
	number = {1-2},
	journal = {Cognition},
	author = {Fodor, J A and Pylyshyn, Z W},
	month = mar,
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {3--71},
}

@inproceedings{humboldt_diversity_2005,
	title = {On the {Diversity} of {Human} {Language} {Construction} and its {Influence} on the {Mental} {Development} of the {Human} {Species}},
	publisher = {Cambridge University Press},
	author = {Humboldt, Wilhelm von},
	editor = {(Ed.), Michael Losonsky},
	year = {2005},
	keywords = {merged\_fiete.bib},
}

@article{boyd_thermodynamics_2018,
	title = {Thermodynamics of {Modularity}: {Structural} {Costs} {Beyond} the {Landauer} {Bound}},
	volume = {8},
	journal = {Phys. Rev. X},
	author = {Boyd, Alexander B and Mandal, Dibyendu and Crutchfield, James P},
	month = aug,
	year = {2018},
	note = {Publisher: American Physical Society},
	keywords = {merged\_fiete.bib},
	pages = {031036},
}

@article{ellefsen_neural_2015,
	title = {Neural modularity helps organisms evolve to learn new skills without forgetting old skills},
	volume = {11},
	abstract = {A long-standing goal in artificial intelligence is creating agents that can learn a variety of different skills for different problems. In the artificial intelligence subfield of neural networks, a barrier to that goal is that when agents learn a new skill they typically do so by losing previously acquired skills, a problem called catastrophic forgetting. That occurs because, to learn the new task, neural learning algorithms change connections that encode previously acquired skills. How networks are organized critically affects their learning dynamics. In this paper, we test whether catastrophic forgetting can be reduced by evolving modular neural networks. Modularity intuitively should reduce learning interference between tasks by separating functionality into physically distinct modules in which learning can be selectively turned on or off. Modularity can further improve learning by having a reinforcement learning module separate from sensory processing modules, allowing learning to happen only in response to a positive or negative reward. In this paper, learning takes place via neuromodulation, which allows agents to selectively change the rate of learning for each neural connection based on environmental stimuli (e.g. to alter learning in specific locations based on the task at hand). To produce modularity, we evolve neural networks with a cost for neural connections. We show that this connection cost technique causes modularity, confirming a previous result, and that such sparsely connected, modular networks have higher overall performance because they learn new skills faster while retaining old skills more and because they have a separate reinforcement learning module. Our results suggest (1) that encouraging modularity in neural networks may help us overcome the long-standing barrier of networks that cannot learn new skills without forgetting old ones, and (2) that one benefit of the modularity ubiquitous in the brains of natural animals might be to alleviate the problem of catastrophic forgetting.},
	number = {4},
	journal = {PLoS Comput. Biol.},
	author = {Ellefsen, Kai Olav and Mouret, Jean-Baptiste and Clune, Jeff},
	year = {2015},
	keywords = {merged\_fiete.bib},
	pages = {e1004128},
}

@article{guimaraes_freezing_2020,
	title = {Freezing {Degrees} of {Freedom} {During} {Motor} {Learning}: {A} {Systematic} {Review}},
	volume = {24},
	abstract = {According to Bernstein, the central nervous system solution to the human body's enormous variation in movement choice and control when directing movement-the problem of degrees of freedom (DF)-is to freeze the number of possibilities at the beginning of motor learning. However, different strategies of freezing DF are observed in literature, and the means of selection of the control strategy during learning is not totally clear. This review investigated the possible effects of the class and objectives of the skill practiced on DF control strategies. The results of this review suggest that freezing or releasing the DF at the beginning of learning does not depend on the class (e.g., discrete skill class: football kick, dart throwing; continuous skill class: athletic march, handwriting) or objective of the skill (e.g., balance, velocity, and accuracy), in isolation. However, an interaction between these two skill elements seems to exist and influences the selection of the DF control strategy.},
	number = {3},
	journal = {Motor Control},
	author = {Guimarães, Anderson Nascimento and Ugrinowitsch, Herbert and Dascal, Juliana Bayeux and Porto, Alessandra Beggiato and Okazaki, Victor Hugo Alves},
	month = mar,
	year = {2020},
	keywords = {merged\_fiete.bib, joint coordination, motor behavior, motor skill, skill acquisition, task constraints},
	pages = {457--471},
}

@article{turvey_coordination_1990,
	title = {Coordination},
	volume = {45},
	abstract = {The Russian physiologist Bernstein (1967) defined coordination as a problem of mastering the very many degrees of freedom involved in a particular movement–of reducing the number of independent variables to be controlled. The initial theorizing and experimentation on “Bernstein's problem” was conducted largely in terms of how a device of very many independent variables might be regulated without ascribing excessive responsibility to an executive subsystem. A second round of theory and research on Bernstein's problem is now under way. This second round is motivated by similarities between coordination and physical processes in which multiple components become collectively self-organized; it is directed at an explanation of coordination in terms of very general laws and principles. The major achievements of the first round of efforts to address Bernstein's problem are summarized, and six examples of the theory and research typifying the second round are presented.},
	number = {8},
	journal = {Am. Psychol.},
	author = {Turvey, M T},
	month = aug,
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {938--953},
}

@article{sporns_solving_1993,
	title = {Solving {Bernstein}'s problem: a proposal for the development of coordinated movement by selection},
	volume = {64},
	abstract = {In recent years, many established concepts in the theory of human motor development have undergone profound change, and our knowledge has increased greatly. Nevertheless, some outstanding problems remain unsolved. A central problem concerns the redundancy of effective movements, first pointed out by N. A. Bernstein. The human motor system is mechanically complex and can make use of a large number of degrees of freedom. The controlled operation of such a system requires a reduction of mechanical redundancy, effectively by reducing the number of degrees of freedom. More recent work has shown that this problem is hard to solve explicitly by computing solutions to the equations of motion of the system. Equally challenging to traditional computational approaches is the fact the motor systems show remarkable adaptability and flexibility in the presence of changing biomechanical properties of motor organs during development and when faced with different environmental conditions or tasks. Solutions to these problems would have a large impact on a variety of issues in child development. In this article, we stress the importance of the somatic selection of neuronal groups in maps for the progressive transformation of a primary movement repertoire into a set of motor synergies and adaptive action patterns. We present results from computer simulations of a simple motor system that works according to such selectional principles. This approach suggests a provisional solution to Bernstein's problem and provides new parameters to guide experimental approaches to the development of sensorimotor coordination.},
	number = {4},
	journal = {Child Dev.},
	author = {Sporns, O and Edelman, G M},
	month = aug,
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {960--981},
}

@article{meunier_modular_2014,
	title = {Modular structure of functional networks in olfactory memory},
	volume = {95},
	abstract = {Graph theory enables the study of systems by describing those systems as a set of nodes and edges. Graph theory has been widely applied to characterize the overall structure of data sets in the social, technological, and biological sciences, including neuroscience. Modular structure decomposition enables the definition of sub-networks whose components are gathered in the same module and work together closely, while working weakly with components from other modules. This processing is of interest for studying memory, a cognitive process that is widely distributed. We propose a new method to identify modular structure in task-related functional magnetic resonance imaging (fMRI) networks. The modular structure was obtained directly from correlation coefficients and thus retained information about both signs and weights. The method was applied to functional data acquired during a yes-no odor recognition memory task performed by young and elderly adults. Four response categories were explored: correct (Hit) and incorrect (False alarm, FA) recognition and correct and incorrect rejection. We extracted time series data for 36 areas as a function of response categories and age groups and calculated condition-based weighted correlation matrices. Overall, condition-based modular partitions were more homogeneous in young than elderly subjects. Using partition similarity-based statistics and a posteriori statistical analyses, we demonstrated that several areas, including the hippocampus, caudate nucleus, and anterior cingulate gyrus, belonged to the same module more frequently during Hit than during all other conditions. Modularity values were negatively correlated with memory scores in the Hit condition and positively correlated with bias scores (liberal/conservative attitude) in the Hit and FA conditions. We further demonstrated that the proportion of positive and negative links between areas of different modules (i.e., the proportion of correlated and anti-correlated areas) accounted for most of the observed differences in signed modularity. Taken together, our results provided some evidence that the neural networks involved in odor recognition memory are organized into modules and that these modular partitions are linked to behavioral performance and individual strategies.},
	journal = {Neuroimage},
	author = {Meunier, David and Fonlupt, Pierre and Saive, Anne-Lise and Plailly, Jane and Ravel, Nadine and Royet, Jean-Pierre},
	month = jul,
	year = {2014},
	keywords = {Functional connectivity, merged\_fiete.bib, Graph theory, Modularity, Neural network, Olfactory memory, Signal detection theory},
	pages = {264--275},
}

@article{meunier_modular_2010,
	title = {Modular and hierarchically modular organization of brain networks},
	volume = {4},
	abstract = {Brain networks are increasingly understood as one of a large class of information processing systems that share important organizational principles in common, including the property of a modular community structure. A module is topologically defined as a subset of highly inter-connected nodes which are relatively sparsely connected to nodes in other modules. In brain networks, topological modules are often made up of anatomically neighboring and/or functionally related cortical regions, and inter-modular connections tend to be relatively long distance. Moreover, brain networks and many other complex systems demonstrate the property of hierarchical modularity, or modularity on several topological scales: within each module there will be a set of sub-modules, and within each sub-module a set of sub-sub-modules, etc. There are several general advantages to modular and hierarchically modular network organization, including greater robustness, adaptivity, and evolvability of network function. In this context, we review some of the mathematical concepts available for quantitative analysis of (hierarchical) modularity in brain networks and we summarize some of the recent work investigating modularity of structural and functional brain networks derived from analysis of human neuroimaging data.},
	journal = {Front. Neurosci.},
	author = {Meunier, David and Lambiotte, Renaud and Bullmore, Edward T},
	year = {2010},
	keywords = {merged\_fiete.bib, cortex, fractal, graph, near-decomposability, partition},
	pages = {200},
}

@article{meunier_hierarchical_2009,
	title = {Hierarchical modularity in human brain functional networks},
	volume = {3},
	abstract = {The idea that complex systems have a hierarchical modular organization originated in the early 1960s and has recently attracted fresh support from quantitative studies of large scale, real-life networks. Here we investigate the hierarchical modular (or “modules-within-modules”) decomposition of human brain functional networks, measured using functional magnetic resonance imaging in 18 healthy volunteers under no-task or resting conditions. We used a customized template to extract networks with more than 1800 regional nodes, and we applied a fast algorithm to identify nested modular structure at several hierarchical levels. We used mutual information, 0 {\textless} I {\textless} 1, to estimate the similarity of community structure of networks in different subjects, and to identify the individual network that is most representative of the group. Results show that human brain functional networks have a hierarchical modular organization with a fair degree of similarity between subjects, I = 0.63. The largest five modules at the highest level of the hierarchy were medial occipital, lateral occipital, central, parieto-frontal and fronto-temporal systems; occipital modules demonstrated less sub-modular organization than modules comprising regions of multimodal association cortex. Connector nodes and hubs, with a key role in inter-modular connectivity, were also concentrated in association cortical areas. We conclude that methods are available for hierarchical modular decomposition of large numbers of high resolution brain functional networks using computationally expedient algorithms. This could enable future investigations of Simon's original hypothesis that hierarchy or near-decomposability of physical symbol systems is a critical design feature for their fast adaptivity to changing environmental conditions.},
	journal = {Front. Neuroinform.},
	author = {Meunier, David and Lambiotte, Renaud and Fornito, Alex and Ersche, Karen D and Bullmore, Edward T},
	year = {2009},
	keywords = {hierarchy, merged\_fiete.bib, near-decomposability, brain, graph theory, information, modularity, network},
	pages = {37},
}

@article{pena_transverse_2003,
	title = {Transverse instabilities in chemical {Turing} patterns of stripes},
	volume = {68},
	abstract = {We present a theoretical and experimental study of the sideband instabilities in Turing patterns of stripes. We compare numerical computations of the Brusselator model with experiments in a chlorine dioxide-iodine-malonic acid (CDIMA) reaction in a thin gel layer reactor in contact with a continuously refreshed reservoir of reagents. Spontaneously evolving Turing structures in both systems typically exhibit many defects that break the symmetry of the pattern. Therefore, the study of sideband instabilities requires a method of forcing perfect, spatially periodic Turing patterns with the desired wave number. This is easily achieved in numerical simulations. In experiments, the photosensitivity of the CDIMA reaction permits control and modulation of Turing structures by periodic spatial illumination with a wave number outside the stability region. When a too big wave number is imposed on the pattern, the Eckhaus instability may arise, while for too small wave numbers an instability sets in forming zigzags. By means of the amplitude equation formalism we show that, close to the hexagon-stripe transitions, these sideband instabilities may be preceded by an amplitude instability that grows transient spots locally before reconnecting with stripes. This prediction is tested in both the reaction-diffusion model and the experiment.},
	number = {5 Pt 2},
	journal = {Phys. Rev. E Stat. Nonlin. Soft Matter Phys.},
	author = {Peña, B and Pérez-García, C and Sanz-Anchelergues, A and Míguez, D G and Muñuzuri, A P},
	month = nov,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {056206},
}

@article{weber_self-organizing_2019,
	title = {Self-organizing hair peg-like structures from dissociated skin progenitor cells: {New} insights for human hair follicle organoid engineering and {Turing} patterning in an asymmetric morphogenetic field},
	volume = {28},
	abstract = {Human skin progenitor cells will form new hair follicles, although at a low efficiency, when injected into nude mouse skin. To better study and improve upon this regenerative process, we developed an in vitro system to analyse the morphogenetic cell behaviour in detail and modulate physical-chemical parameters to more effectively generate hair primordia. In this three-dimensional culture, dissociated human neonatal foreskin keratinocytes self-assembled into a planar epidermal layer while fetal scalp dermal cells coalesced into stripes, then large clusters, and finally small clusters resembling dermal condensations. At sites of dermal clustering, subjacent epidermal cells protruded to form hair peg-like structures, molecularly resembling hair pegs within the sequence of follicular development. The hair peg-like structures emerged in a coordinated, formative wave, moving from periphery to centre, suggesting that the droplet culture constitutes a microcosm with an asymmetric morphogenetic field. In vivo, hair follicle populations also form in a progressive wave, implying the summation of local periodic patterning events with an asymmetric global influence. To further understand this global patterning process, we developed a mathematical simulation using Turing activator-inhibitor principles in an asymmetric morphogenetic field. Together, our culture system provides a suitable platform to (a) analyse the self-assembly behaviour of hair progenitor cells into periodically arranged hair primordia and (b) identify parameters that impact the formation of hair primordia in an asymmetric morphogenetic field. This understanding will enhance our future ability to successfully engineer human hair follicle organoids.},
	number = {4},
	journal = {Exp. Dermatol.},
	author = {Weber, Erin L and Woolley, Thomas E and Yeh, Chao-Yuan and Ou, Kuang-Ling and Maini, Philip K and Chuong, Cheng-Ming},
	year = {2019},
	keywords = {merged\_fiete.bib, hair follicle, organogenesis, periodic pattern formation, skin reconstitution, tissue engineering},
	pages = {355--366},
}

@inproceedings{chaudhuri_bipartite_2019,
	title = {Bipartite expander {Hopfield} networks as self-decoding high-capacity error correcting codes},
	volume = {32},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Chaudhuri, Rishidev and Fiete, Ila},
	editor = {Wallach, H and Larochelle, H and Beygelzimer, A and d{\textbackslash}textbackslashtextquotesingle Alché-Buc, F and Fox, E and Garnett, R},
	year = {2019},
	keywords = {merged\_fiete.bib},
}

@article{welch_modularity_2003,
	title = {Modularity and the cost of complexity},
	volume = {57},
	abstract = {In this work we consider the geometrical model of R. A. Fisher, in which individuals are characterized by a number of phenotypic characters under optimizing selection. Recent work on this model by H. A. Orr has demonstrated that as the number of characters increases, there is a significant reduction in the rate of adaptation. Orr has dubbed this a “cost of complexity.” Although there is little evidence as to whether such a cost applies in the natural world, we suggest that the prediction is surprising, at least naively. With this in mind, we examine the robustness of Orr's prediction by modifiying the model in various ways that might reduce or remove the cost. In particular, we explore the suggestion that modular pleiotropy, in which mutations affect only a subset of the traits, could play an important role. We conclude that although modifications of the model can mitigate the cost to a limited extent, Orr's finding is robust.},
	number = {8},
	journal = {Evolution},
	author = {Welch, John J and Waxman, David},
	month = aug,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {1723--1734},
}

@article{tegmark_pareto-optimal_2019,
	title = {Pareto-{Optimal} {Data} {Compression} for {Binary} {Classification} {Tasks}},
	volume = {22},
	abstract = {The goal of lossy data compression is to reduce the storage cost of a data set X while retaining as much information as possible about something (Y) that you care about. For example, what aspects of an image X contain the most information about whether it depicts a cat? Mathematically, this corresponds to finding a mapping X {\textbackslash}rightarrow Z {\textbackslash}equiv f ( X ) that maximizes the mutual information I ( Z , Y ) while the entropy H ( Z ) is kept below some fixed threshold. We present a new method for mapping out the Pareto frontier for classification tasks, reflecting the tradeoff between retained entropy and class information. We first show how a random variable X (an image, say) drawn from a class Y ın 1 , {\textbackslash}textbackslashldots , n can be distilled into a vector W = f ( X ) ın R n - 1 losslessly, so that I ( W , Y ) = I ( X , Y ) ; for example, for a binary classification task of cats and dogs, each image X is mapped into a single real number W retaining all information that helps distinguish cats from dogs. For the n = 2 case of binary classification, we then show how W can be further compressed into a discrete variable Z = g β ( W ) ın 1 , {\textbackslash}textbackslashldots , m β by binning W into m β bins, in such a way that varying the parameter β sweeps out the full Pareto frontier, solving a generalization of the discrete information bottleneck (DIB) problem. We argue that the most interesting points on this frontier are “corners” maximizing I ( Z , Y ) for a fixed number of bins m = 2 , 3 , {\textbackslash}textbackslashldots which can conveniently be found without multiobjective optimization. We apply this method to the CIFAR-10, MNIST and Fashion-MNIST datasets, illustrating how it can be interpreted as an information-theoretically optimal image clustering algorithm. We find that these Pareto frontiers are not concave, and that recently reported DIB phase transitions correspond to transitions between these corners, changing the number of clusters.},
	number = {1},
	journal = {Entropy},
	author = {Tegmark, Max and Wu, Tailin},
	month = dec,
	year = {2019},
	keywords = {merged\_fiete.bib, information, bottleneck, classification, compression},
}

@article{tikhonov_model_2020,
	title = {A model for the interplay between plastic tradeoffs and evolution in changing environments},
	volume = {117},
	abstract = {Performance tradeoffs are ubiquitous in both ecological and evolutionary modeling, yet they are usually postulated and built into fitness and ecological landscapes. However, tradeoffs depend on genetic background and evolutionary history and can themselves evolve. We present a simple model capable of capturing the key feedback loop: evolutionary history shapes tradeoff strength, which, in turn, shapes evolutionary future. One consequence of this feedback is that genomes with identical fitness can have different evolutionary properties shaped by prior environmental exposure. Another is that, generically, the best adaptations to one environment may evolve in another. Our simple framework bridges the gap between the phenotypic Fisher's Geometric Model and the genotypic properties, such as modularity and evolvability, and can serve as a rich playground for investigating evolution in multiple or changing environments.},
	number = {16},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Tikhonov, Mikhail and Kachru, Shamit and Fisher, Daniel S},
	year = {2020},
	keywords = {merged\_fiete.bib, changing environment, evolution, performance tradeoff},
	pages = {8934--8940},
}

@article{clune_evolutionary_2013,
	title = {The evolutionary origins of modularity},
	volume = {280},
	abstract = {A central biological question is how natural organisms are so evolvable (capable of quickly adapting to new environments). A key driver of evolvability is the widespread modularity of biological networks–their organization as functional, sparsely connected subunits–but there is no consensus regarding why modularity itself evolved. Although most hypotheses assume indirect selection for evolvability, here we demonstrate that the ubiquitous, direct selection pressure to reduce the cost of connections between network nodes causes the emergence of modular networks. Computational evolution experiments with selection pressures to maximize network performance and minimize connection costs yield networks that are significantly more modular and more evolvable than control experiments that only select for performance. These results will catalyse research in numerous disciplines, such as neuroscience and genetics, and enhance our ability to harness evolution for engineering purposes.},
	number = {1755},
	journal = {Proc. Biol. Sci.},
	author = {Clune, Jeff and Mouret, Jean-Baptiste and Lipson, Hod},
	month = mar,
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {20122863},
}

@article{gardner_is_2003,
	title = {Is evolvability involved in the origin of modular variation?},
	volume = {57},
	abstract = {Lipson et al. (2002) presented an elegant linear algebraic formalism to define and study the evolution of modularity in an artificial evolving system. They employed simulation data to support their suggestion that modularity arises spontaneously in temporally fluctuating systems in response to selection for enhanced evolvability. We show analytically and by simulation that their correlate of modularity is itself under selection and so is not a reliable indicator of selection for modularity per se. In addition, we question the relation between modularity and evolvability in their simulations, suggesting that this modularity cannot confer enhanced evolvability.},
	number = {6},
	journal = {Evolution},
	author = {Gardner, Andy and Zuidema, Willem},
	month = jun,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {1448--1450},
}

@article{lipson_origin_2002,
	title = {On the origin of modular variation},
	volume = {56},
	abstract = {We study the dynamics of modularization in a minimal substrate. A module is a functional unit relatively separable from its surrounding structure. Although it is known that modularity is useful both for robustness and for evolvability (Wagner 1996), there is no quantitative model describing how such modularity might originally emerge. Here we suggest, using simple computer simulations, that modularity arises spontaneously in evolutionary systems in response to variation, and that the amount of modular separation is logarithmically proportional to the rate of variation. Consequently, we predict that modular architectures would appear in correlation with high environmental change rates. Because this quantitative model does not require any special substrate to occur, it may also shed light on the origin of modular variation in nature. This observed relationship also indicates that modular design is a generic phenomenon that might be applicable to other fields, such as engineering: Engineering design methods based on evolutionary simulation would benefit from evolving to variable, rather than stationary, fitness criteria, as a weak and problem-independent method for inducing modularity.},
	number = {8},
	journal = {Evolution},
	author = {Lipson, Hod and Pollack, Jordan B and Suh, Nam P},
	month = aug,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {1549--1556},
}

@article{cheng_structure_2011,
	title = {The structure of networks that produce the transformation from grid cells to place cells},
	volume = {197},
	abstract = {Since grid cells were discovered in the medial entorhinal cortex, several models have been proposed for the transformation from periodic grids to the punctate place fields of hippocampal place cells. These prior studies have each focused primarily on a particular model structure. By contrast, the goal of this study is to understand the general nature of the solutions that generate the grids-to-places transformation, and to exploit this insight to solve problems that were previously unsolved. First, we derive a family of feedforward networks that generate the grids-to-places transformations. These networks have in common an inverse relationship between the synaptic weights and a grid property that we call the normalized offset. Second, we analyze the solutions of prior models in terms of this novel measure and found to our surprise that almost all prior models yield solutions that can be described by this family of networks. The one exception is a model that is unrealistically sensitive to noise. Third, with this insight into the structure of the solutions, we then construct explicitly solutions for the grids-to-places transformation with multiple spatial maps, that is, with place fields in arbitrary locations either within the same (multiple place fields) or in different (global remapping) enclosures. These multiple maps are possible because the weights are learned or assigned in such a way that a group of weights contributes to spatial specificity in one context but remains spatially unstructured in another context. Fourth, we find parameters such that global remapping solutions can be found by synaptic learning in spiking neurons, despite previous suggestions that this might not be possible. In conclusion, our results demonstrate the power of understanding the structure of the solutions and suggest that we may have identified the structure that is common to all robust solutions of the grids-to-places transformation.},
	journal = {Neuroscience},
	author = {Cheng, S and Frank, L M},
	month = dec,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {293--306},
}

@article{neher_grid_2017,
	title = {From grid cells to place cells with realistic field sizes},
	volume = {12},
	abstract = {While grid cells in the medial entorhinal cortex (MEC) of rodents have multiple, regularly arranged firing fields, place cells in the cornu ammonis (CA) regions of the hippocampus mostly have single spatial firing fields. Since there are extensive projections from MEC to the CA regions, many models have suggested that a feedforward network can transform grid cell firing into robust place cell firing. However, these models generate place fields that are consistently too small compared to those recorded in experiments. Here, we argue that it is implausible that grid cell activity alone can be transformed into place cells with robust place fields of realistic size in a feedforward network. We propose two solutions to this problem. Firstly, weakly spatially modulated cells, which are abundant throughout EC, provide input to downstream place cells along with grid cells. This simple model reproduces many place cell characteristics as well as results from lesion studies. Secondly, the recurrent connections between place cells in the CA3 network generate robust and realistic place fields. Both mechanisms could work in parallel in the hippocampal formation and this redundancy might account for the robustness of place cell responses to a range of disruptions of the hippocampal circuitry.},
	number = {7},
	journal = {PLoS One},
	author = {Neher, Torsten and Azizi, Amir Hossein and Cheng, Sen},
	year = {2017},
	keywords = {merged\_fiete.bib},
	pages = {e0181618},
}

@article{huycke_genetic_2019,
	title = {Genetic and {Mechanical} {Regulation} of {Intestinal} {Smooth} {Muscle} {Development}},
	volume = {179},
	abstract = {The gastrointestinal tract is enveloped by concentric and orthogonally aligned layers of smooth muscle; however, an understanding of the mechanisms by which these muscles become patterned and aligned in the embryo has been lacking. We find that Hedgehog acts through Bmp to delineate the position of the circumferentially oriented inner muscle layer, whereas localized Bmp inhibition is critical for allowing formation of the later-forming, longitudinally oriented outer layer. Because the layers form at different developmental stages, the muscle cells are exposed to unique mechanical stimuli that direct their alignments. Differential growth within the early gut tube generates residual strains that orient the first layer circumferentially, and when formed, the spontaneous contractions of this layer align the second layer longitudinally. Our data link morphogen-based patterning to mechanically controlled smooth muscle cell alignment and provide a mechanistic context for potentially understanding smooth muscle organization in a wide variety of tubular organs.},
	number = {1},
	journal = {Cell},
	author = {Huycke, Tyler R and Miller, Bess M and Gill, Hasreet K and Nerurkar, Nandan L and Sprinzak, David and Mahadevan, L and Tabin, Clifford J},
	year = {2019},
	keywords = {merged\_fiete.bib, patterning, Bmp, cell orientation, differentiation, gut development, Hedgehog, mechanical forces, morphogenesis, smooth muscle},
	pages = {90--105.e21},
}

@article{larson_biophysical_2020,
	title = {Biophysical principles of choanoflagellate self-organization},
	volume = {117},
	abstract = {Inspired by the patterns of multicellularity in choanoflagellates, the closest living relatives of animals, we quantify the biophysical processes underlying the morphogenesis of rosette colonies in the choanoflagellate Salpingoeca rosetta We find that rosettes reproducibly transition from an early stage of 2-dimensional (2D) growth to a later stage of 3D growth, despite the underlying variability of the cell lineages. Our perturbative experiments demonstrate the fundamental importance of a basally secreted extracellular matrix (ECM) for rosette morphogenesis and show that the interaction of the ECM with cells in the colony physically constrains the packing of proliferating cells and, thus, controls colony shape. Simulations of a biophysically inspired model that accounts for the size and shape of the individual cells, the fraction of ECM, and its stiffness relative to that of the cells suffices to explain our observations and yields a morphospace consistent with observations across a range of multicellular choanoflagellate colonies. Overall, our biophysical perspective on rosette development complements previous genetic perspectives and, thus, helps illuminate the interplay between cell biology and physics in regulating morphogenesis.},
	number = {3},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Larson, Ben T and Ruiz-Herrero, Teresa and Lee, Stacey and Kumar, Sanjay and Mahadevan, L and King, Nicole},
	year = {2020},
	keywords = {merged\_fiete.bib, morphogenesis, extracellular matrix, morphospace, multicellularity, quantitative cell biology},
	pages = {1303--1311},
}

@article{nagarkar_elastic-instability-enabled_2021,
	title = {Elastic-instability-enabled locomotion},
	volume = {118},
	abstract = {Locomotion of an organism interacting with an environment is the consequence of a symmetry-breaking action in space-time. Here we show a minimal instantiation of this principle using a thin circular sheet, actuated symmetrically by a pneumatic source, using pressure to change shape nonlinearly via a spontaneous buckling instability. This leads to a polarized, bilaterally symmetric cone that can walk on land and swim in water. In either mode of locomotion, the emergence of shape asymmetry in the sheet leads to an asymmetric interaction with the environment that generates movement–via anisotropic friction on land, and via directed inertial forces in water. Scaling laws for the speed of the sheet of the actuator as a function of its size, shape, and the frequency of actuation are consistent with our observations. The presence of easily controllable reversible modes of buckling deformation further allows for a change in the direction of locomotion in open arenas and the ability to squeeze through confined environments–both of which we demonstrate using simple experiments. Our simple approach of harnessing elastic instabilities in soft structures to drive locomotion enables the design of novel shape-changing robots and other bioinspired machines at multiple scales.},
	number = {8},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Nagarkar, Amit and Lee, Won-Kyu and Preston, Daniel J and Nemitz, Markus P and Deng, Nan-Nan and Whitesides, George M and Mahadevan, L},
	month = feb,
	year = {2021},
	keywords = {locomotion, merged\_fiete.bib, buckling, elastic instability},
}

@article{irvine_mechanical_2017,
	title = {Mechanical control of growth: ideas, facts and challenges},
	volume = {144},
	abstract = {In his classic book On Growth and Form, D'Arcy Thompson discussed the necessity of a physical and mathematical approach to understanding the relationship between growth and form. The past century has seen extraordinary advances in our understanding of biological components and processes contributing to organismal morphogenesis, but the mathematical and physical principles involved have not received comparable attention. The most obvious entry of physics into morphogenesis is via tissue mechanics. In this Review, we discuss the fundamental role of mechanical interactions between cells induced by growth in shaping a tissue. Non-uniform growth can lead to accumulation of mechanical stress, which in the context of two-dimensional sheets of tissue can specify the shape it assumes in three dimensions. A special class of growth patterns - conformal growth - does not lead to the accumulation of stress and can generate a rich variety of planar tissue shapes. Conversely, mechanical stress can provide a regulatory feedback signal into the growth control circuit. Both theory and experiment support a key role for mechanical interactions in shaping tissues and, via mechanical feedback, controlling epithelial growth.},
	number = {23},
	journal = {Development},
	author = {Irvine, Kenneth D and Shraiman, Boris I},
	year = {2017},
	keywords = {merged\_fiete.bib, Growth, Hippo, Mechanics, Stress},
	pages = {4238--4248},
}

@article{durrieu_bicoid_2018,
	title = {Bicoid gradient formation mechanism and dynamics revealed by protein lifetime analysis},
	volume = {14},
	abstract = {Embryogenesis relies on instructions provided by spatially organized signaling molecules known as morphogens. Understanding the principles behind morphogen distribution and how cells interpret locally this information remains a major challenge in developmental biology. Here, we introduce morphogen-age measurements as a novel approach to test models of morphogen gradient formation. Using a tandem fluorescent timer as a protein age sensor, we find a gradient of increasing age of Bicoid along the anterior-posterior axis in the early Drosophila embryo. Quantitative analysis of the protein age distribution across the embryo reveals that the synthesis-diffusion-degradation model is the most likely model underlying Bicoid gradient formation, and rules out other hypotheses for gradient formation. Moreover, we show that the timer can detect transitions in the dynamics associated with syncytial cellularization. Our results provide new insight into Bicoid gradient formation and demonstrate how morphogen-age information can complement knowledge about movement, abundance, and distribution, which should be widely applicable to other systems.},
	number = {9},
	journal = {Mol. Syst. Biol.},
	author = {Durrieu, Lucia and Kirrmaier, Daniel and Schneidt, Tatjana and Kats, Ilia and Raghavan, Sarada and Hufnagel, Lars and Saunders, Timothy E and Knop, Michael},
	year = {2018},
	keywords = {merged\_fiete.bib, Drosophila melanogaster, embryogenesis, fluorescent timers, morphogen gradient, SPIM},
	pages = {e8355},
}

@article{hawrylycz_canonical_2015,
	title = {Canonical genetic signatures of the adult human brain},
	volume = {18},
	abstract = {The structure and function of the human brain are highly stereotyped, implying a conserved molecular program responsible for its development, cellular structure and function. We applied a correlation-based metric called differential stability to assess reproducibility of gene expression patterning across 132 structures in six individual brains, revealing mesoscale genetic organization. The genes with the highest differential stability are highly biologically relevant, with enrichment for brain-related annotations, disease associations, drug targets and literature citations. Using genes with high differential stability, we identified 32 anatomically diverse and reproducible gene expression signatures, which represent distinct cell types, intracellular components and/or associations with neurodevelopmental and neurodegenerative disorders. Genes in neuron-associated compared to non-neuronal networks showed higher preservation between human and mouse; however, many diversely patterned genes displayed marked shifts in regulation between species. Finally, highly consistent transcriptional architecture in neocortex is correlated with resting state functional connectivity, suggesting a link between conserved gene expression and functionally relevant circuitry.},
	number = {12},
	journal = {Nat. Neurosci.},
	author = {Hawrylycz, Michael and Miller, Jeremy A and Menon, Vilas and Feng, David and Dolbeare, Tim and Guillozet-Bongaarts, Angela L and Jegga, Anil G and Aronow, Bruce J and Lee, Chang-Kyu and Bernard, Amy and Glasser, Matthew F and Dierker, Donna L and Menche, Jörg and Szafer, Aaron and Collman, Forrest and Grange, Pascal and Berman, Kenneth A and Mihalas, Stefan and Yao, Zizhen and Stewart, Lance and Barabási, Albert-László and Schulkin, Jay and Phillips, John and Ng, Lydia and Dang, Chinh and Haynor, David R and Jones, Allan and Van Essen, David C and Koch, Christof and Lein, Ed},
	month = dec,
	year = {2015},
	keywords = {merged\_fiete.bib},
	pages = {1832--1844},
}

@article{van_essen_modular_1990,
	title = {Modular and hierarchical organization of extrastriate visual cortex in the macaque monkey},
	volume = {55},
	journal = {Cold Spring Harb. Symp. Quant. Biol.},
	author = {Van Essen, D C and Felleman, D J and DeYoe, E A and Olavarria, J and Knierim, J},
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {679--696},
}

@article{sporns_modular_2016,
	title = {Modular {Brain} {Networks}},
	volume = {67},
	abstract = {The development of new technologies for mapping structural and functional brain connectivity has led to the creation of comprehensive network maps of neuronal circuits and systems. The architecture of these brain networks can be examined and analyzed with a large variety of graph theory tools. Methods for detecting modules, or network communities, are of particular interest because they uncover major building blocks or subnetworks that are particularly densely connected, often corresponding to specialized functional components. A large number of methods for community detection have become available and are now widely applied in network neuroscience. This article first surveys a number of these methods, with an emphasis on their advantages and shortcomings; then it summarizes major findings on the existence of modules in both structural and functional brain networks and briefly considers their potential functional roles in brain evolution, wiring minimization, and the emergence of functional specialization and complex dynamics.},
	journal = {Annu. Rev. Psychol.},
	author = {Sporns, Olaf and Betzel, Richard F},
	year = {2016},
	keywords = {merged\_fiete.bib, graph theory, clustering, connectome, functional connectivity, hubs, resting state},
	pages = {613--640},
}

@article{hasenstaub_state_2007,
	title = {State changes rapidly modulate cortical neuronal responsiveness},
	volume = {27},
	abstract = {The responsiveness of cortical neurons is strongly and rapidly influenced by changes in the level of local network activity. In rodent somatosensory cortex, increases in network activity increase neuronal responsiveness to the intracellular injection of brief conductance stimuli but paradoxically decrease responsiveness to brief whisker deflections. However, whisker stimulation frequently evokes long-lasting changes in the level of local circuit activity. The ability of stimuli to successfully evoke prolonged increases in circuit activity is associated with both an increase in the amount of conductance evoked by a whisker stimulus and an increase in action potential responsiveness to whisker stimulation. In addition, brief whisker stimuli presented during periods of high network activity evoke postsynaptic potentials containing a greater proportion of inhibition, consistent with an increased efficiency in the activation of inhibitory mechanisms during the Up state. In contrast, during prolonged and variable whisker stimulation, increased network activity is associated with an increase in overall responsiveness, dynamic range, output gain, and correlation between action potential response and speed of whisker movement. We conclude that stimulus-evoked or spontaneous alterations in cortical state can influence neuronal responsiveness in a complex manner, resulting in large changes in which, and how, sensory stimuli are represented.},
	number = {36},
	journal = {J. Neurosci.},
	author = {Hasenstaub, Andrea and Sachdev, Robert N S and McCormick, David A},
	month = sep,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {9607--9622},
}

@article{wang_brain_2013,
	title = {Brain mechanisms for simple perception and bistable perception},
	volume = {110},
	abstract = {When faced with ambiguous sensory inputs, subjective perception alternates between the different interpretations in a stochastic manner. Such multistable perception phenomena have intrigued scientists and laymen alike for over a century. Despite rigorous investigations, the underlying mechanisms of multistable perception remain elusive. Recent studies using multivariate pattern analysis revealed that activity patterns in posterior visual areas correlate with fluctuating percepts. However, increasing evidence suggests that vision–and perception at large–is an active inferential process involving hierarchical brain systems. We applied searchlight multivariate pattern analysis to functional magnetic resonance imaging signals across the human brain to decode perceptual content during bistable perception and simple unambiguous perception. Although perceptually reflective activity patterns during simple perception localized predominantly to posterior visual regions, bistable perception involved additionally many higher-order frontoparietal and temporal regions. Moreover, compared with simple perception, both top-down and bottom-up influences were dramatically enhanced during bistable perception. We further studied the intermittent presentation of ambiguous images–a condition that is known to elicit perceptual memory. Compared with continuous presentation, intermittent presentation recruited even more higher-order regions and was accompanied by further strengthened top-down influences but relatively weakened bottom-up influences. Taken together, these results strongly support an active top-down inferential process in perception.},
	number = {35},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Wang, Megan and Arteaga, Daniel and He, Biyu J},
	month = aug,
	year = {2013},
	keywords = {fMRI, merged\_fiete.bib, ambiguous images, Granger causality, MVPA, visual perception},
	pages = {E3350--9},
}

@article{sanchez-vives_shaping_2017,
	title = {Shaping the {Default} {Activity} {Pattern} of the {Cortical} {Network}},
	volume = {94},
	abstract = {Slow oscillations have been suggested as the default emergent activity of the cortical network. This is a low complexity state that integrates neuronal, synaptic, and connectivity properties of the cortex. Shaped by variations of physiological parameters, slow oscillations provide information about the underlying healthy or pathological network. We review how this default activity is shaped, how it acts as a powerful attractor, and how getting out of it is necessary for the brain to recover the levels of complexity associated with conscious states. We propose that slow oscillations provide a robust unifying paradigm for the study of cortical function.},
	number = {5},
	journal = {Neuron},
	author = {Sanchez-Vives, Maria V and Massimini, Marcello and Mattia, Maurizio},
	month = jun,
	year = {2017},
	keywords = {merged\_fiete.bib, attractors, complexity, consciousness, homeostasis, slow oscillations, slow waves, unconsciousness},
	pages = {993--1001},
}

@article{scarpetta_alternation_2014,
	title = {Alternation of up and down states at a dynamical phase-transition of a neural network with spatiotemporal attractors},
	volume = {8},
	abstract = {Complex collective activity emerges spontaneously in cortical circuits in vivo and in vitro, such as alternation of up and down states, precise spatiotemporal patterns replay, and power law scaling of neural avalanches. We focus on such critical features observed in cortical slices. We study spontaneous dynamics emerging in noisy recurrent networks of spiking neurons with sparse structured connectivity. The emerging spontaneous dynamics is studied, in presence of noise, with fixed connections. Note that no short-term synaptic depression is used. Two different regimes of spontaneous activity emerge changing the connection strength or noise intensity: a low activity regime, characterized by a nearly exponential distribution of firing rates with a maximum at rate zero, and a high activity regime, characterized by a nearly Gaussian distribution peaked at a high rate for high activity, with long-lasting replay of stored patterns. Between this two regimes, a transition region is observed, where firing rates show a bimodal distribution, with alternation of up and down states. In this region, one observes neuronal avalanches exhibiting power laws in size and duration, and a waiting time distribution between successive avalanches which shows a non-monotonic behavior. During periods of high activity (up states) consecutive avalanches are correlated, since they are part of a short transient replay initiated by noise focusing, and waiting times show a power law distribution. One can think at this critical dynamics as a reservoire of dynamical patterns for memory functions.},
	journal = {Front. Syst. Neurosci.},
	author = {Scarpetta, Silvia and de Candia, Antonio},
	year = {2014},
	keywords = {merged\_fiete.bib, associative memory, criticality, neural avalanches, phase transition, spatiotemporal pattern replay, STDP, up and down states},
	pages = {88},
}

@article{reichman_challenges_2011,
	title = {Challenges and {Opportunities} of {Open} {Data} in {Ecology}},
	volume = {331},
	number = {6018},
	journal = {Science},
	author = {Reichman, O J and Jones, M B and Schildhauer, M P},
	month = feb,
	year = {2011},
	note = {Publisher: American Association for the Advancement of Science (AAAS)},
	keywords = {merged\_fiete.bib},
	pages = {703--705},
}

@article{bachmann_fair_2011,
	title = {Fair and {Open} {Evaluation} {May} {Call} for {Temporarily} {Hidden} {Authorship}, {Caution} {When} {Counting} the {Votes}, and {Transparency} of the {Full} {Pre}-publication {Procedure}},
	volume = {5},
	journal = {Front. Comput. Neurosci.},
	author = {Bachmann, Talis},
	year = {2011},
	note = {Publisher: Frontiers Media SA},
	keywords = {merged\_fiete.bib},
}

@article{kriegeskorte_emerging_2012,
	title = {An emerging consensus for open evaluation: 18 visions for the future of scientific publishing},
	volume = {6},
	journal = {Front. Comput. Neurosci.},
	author = {Kriegeskorte, Nikolaus and Walther, Alexander and Deca, Diana},
	year = {2012},
	note = {Publisher: Frontiers Media SA},
	keywords = {Scientific Publishing},
}

@article{nosek_scientific_2012,
	title = {Scientific {Utopia}: {I}. {Opening} {Scientific} {Communication}},
	volume = {23},
	number = {3},
	journal = {Psychol. Inq.},
	author = {Nosek, Brian A and Bar-Anan, Yoav},
	month = jul,
	year = {2012},
	note = {Publisher: Informa UK Limited},
	keywords = {merged\_fiete.bib},
	pages = {217--243},
}

@article{gardner_toroidal_2021,
	title = {Toroidal topology of population activity in grid cells},
	author = {Gardner, Richard J and Hermansen, Erik and Pachitariu, Marius and Burak, Yoram and Baas, Nils A and Dunn, Benjamin A and Moser, May-Britt and Moser, Edvard I},
	month = feb,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory},
	keywords = {merged\_fiete.bib},
}

@article{grienberger_imaging_2012,
	title = {Imaging calcium in neurons},
	volume = {73},
	abstract = {Calcium ions generate versatile intracellular signals that control key functions in all types of neurons. Imaging calcium in neurons is particularly important because calcium signals exert their highly specific functions in well-defined cellular subcompartments. In this Primer, we briefly review the general mechanisms of neuronal calcium signaling. We then introduce the calcium imaging devices, including confocal and two-photon microscopy as well as miniaturized devices that are used in freely moving animals. We provide an overview of the classical chemical fluorescent calcium indicators and of the protein-based genetically encoded calcium indicators. Using application examples, we introduce new developments in the field, such as calcium imaging in awake, behaving animals and the use of calcium imaging for mapping single spine sensory inputs in cortical neurons in vivo. We conclude by providing an outlook on the prospects of calcium imaging for the analysis of neuronal signaling and plasticity in various animal models.},
	number = {5},
	journal = {Neuron},
	author = {Grienberger, Christine and Konnerth, Arthur},
	month = mar,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {862--885},
}

@article{mcnaughton_stereotrode_1983,
	title = {The stereotrode: a new technique for simultaneous isolation of several single units in the central nervous system from multiple unit records},
	volume = {8},
	abstract = {A new method is described for the recording and discrimination of extracellular action potentials in CNS regions with high cellular packing density or where there is intrinsic variation in action potential amplitude during burst discharge. The method is based on the principle that cells with different ratios of distances from two electrode tips will have different spike-amplitude ratios when recorded on two channels. The two channel amplitude ratio will remain constant regardless of intrinsic variation in the absolute amplitude of the signals. The method has been applied to the rat hippocampal formation, from which up to 5 units have been simultaneously isolated. The construction of the electrodes is simple, relatively fast, and reliable, and their low tip impedances result in excellent signal to noise characteristics.},
	number = {4},
	journal = {J. Neurosci. Methods},
	author = {McNaughton, B L and O'Keefe, J and Barnes, C A},
	month = aug,
	year = {1983},
	keywords = {merged\_fiete.bib},
	pages = {391--397},
}

@article{amit_storing_1985,
	title = {Storing {Infinite} {Numbers} of {Patterns} in a {Spin}-{Glass} {Model} of {Neural} {Networks}},
	volume = {55},
	number = {14},
	journal = {Phys. Rev. Lett.},
	author = {Amit, Daniel J},
	year = {1985},
	keywords = {merged\_fiete.bib},
	pages = {1530--1533},
}

@article{amit_statistical_1987,
	title = {Statistical mechanics of neural networks near saturation},
	volume = {173},
	abstract = {The Hopfield model of a neural network is studied near its saturation, i.e., when the number p of stored patterns increases with the size of the network N, as p = αN. The mean-field theory for this system is described in detail. The system possesses, at low α, both a spin-glass phase and 2p dynamically stable degenerate ferromagnetic phases. The latter have essentially full macroscopic overlaps with the memorized patterns, and provide effective associative memory, despite the spin-glass features. The network can retrieve patterns, at T = 0, with an error of less than 1.5\% for α {\textless}αc = 0.14. At αc the ferromagnetic (FM) retrieval states disappear discontinuously. Numerical simulations show that even above αc the overlaps with the sored patterns are not zero, but the level of error precludes meaningful retrieval. The difference between the statistical mechanics and the simulations is discussed. As α decreases below 0.05 the FM retrieval states become ground states of the system, and for α {\textless} 0.03 mixture states appear. The level of storage creates noise, akin to temperature at finite p. Replica symmetry breaking is found to be salient in the spin-glass state, but in the retrieval states it appears at extremely low temperatures, and is argued to have a very weak effect. This is corroborated by simulations. The study is extended to survey the phase diagram of the system in the presence of stochastic synaptic noise (temperature), and the effect of external fields (neuronal thresholds) coupled to groups of patterns. It is found that a field coupled to many patterns has a very limited utility in enhancing their learning. Finally, we discuss the robustness of the network to the relaxation of various underlying assumptions, as well as some new trends in the study of neural networks.},
	number = {1},
	journal = {Ann. Phys.},
	author = {Amit, Daniel J and Gutfreund, Hanoch and Sompolinsky, H},
	year = {1987},
	keywords = {merged\_fiete.bib},
	pages = {30--67},
}

@article{gierer_theory_1972,
	title = {A theory of biological pattern formation},
	volume = {12},
	number = {1},
	journal = {Kybernetik},
	author = {Gierer, A and Meinhardt, H},
	month = dec,
	year = {1972},
	note = {Publisher: Springer Science and Business Media LLC},
	keywords = {merged\_fiete.bib},
	pages = {30--39},
}

@article{major_plasticity_2004,
	title = {Plasticity and tuning by visual feedback of the stability of a neural integrator},
	volume = {101},
	abstract = {Persistent neural firing is of fundamental importance to working memory and other brain functions because it allows information to be held “online” following an input and to be integrated over time. Many models of persistent activity rely on some kind of positive feedback internal to the neural circuit concerned; however, too much feedback causes runaway firing (instability), and too little results in loss of persistence (leak). This parameter sensitivity leads to the hypothesis that the brain uses an error signal (external feedback) to tune the stability of persistent firing by adjusting the amount of internal feedback. We test this hypothesis by manipulating external visual feedback, a putative sensory error signal, in a model system for persistent firing, the goldfish oculomotor neural integrator. Over tens of minutes to hours, electronically controlled visual feedback consistent with a leaky or unstable integrator can drive the integrator progressively more unstable or leaky, respectively. Eye fixation time constants can be reduced {\textgreater}100-fold to {\textless}1 s. Normal visual feedback gradually retunes the integrator back to stability. Changes in the phase of the sinusoidal vestibulo-ocular response are consistent with integrator detuning, as are changes in ocular drift following eye position shifts compensating for brief passive head movements during fixations. Corresponding changes in persistent firing of integrator neurons are presented in the accompanying article. The presence, strength, and reversibility of the plasticity demonstrate that, in this system, external visual feedback plays a vital role in gradually tuning the stability of the neural integrator.},
	number = {20},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Major, Guy and Baker, Robert and Aksay, Emre and Mensh, Brett and Seung, H Sebastian and Tank, David W},
	month = may,
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {7739--7744},
}

@article{rolls_attractor_2007,
	title = {An attractor network in the hippocampus: theory and neurophysiology},
	volume = {14},
	abstract = {A quantitative computational theory of the operation of the CA3 system as an attractor or autoassociation network is described. Based on the proposal that CA3-CA3 autoassociative networks are important for episodic or event memory in which space is a component (place in rodents and spatial view in primates), it has been shown behaviorally that the CA3 supports spatial rapid one-trial learning and learning of arbitrary associations and pattern completion where space is a component. Consistent with the theory, single neurons in the primate CA3 respond to combinations of spatial view and object, and spatial view and reward. Furthermore, single CA3 neurons reflect the recall of a place from an object in a one-trial object-place event memory task. CA3 neurons also reflect in their firing a memory of spatial view that is retained and updated by idiothetic information to implement path integration when the spatial view is obscured. Based on the computational proposal that the dentate gyrus produces sparse representations by competitive learning and via the mossy fiber pathway forces new representations on the CA3 during learning (encoding), it has been shown behaviorally that the dentate gyrus supports spatial pattern separation during learning, and that the mossy fiber system to CA3 connections are involved in learning but not in recall. The perforant path input to CA3 is quantitatively appropriate to provide the cue for recall in CA3. The concept that the CA1 recodes information from CA3 and sets up associatively learned back-projections to neocortex to allow subsequent retrieval of information to neocortex provides a quantitative account of the large number of hippocampo-neocortical back-projections.},
	number = {11},
	journal = {Learn. Mem.},
	author = {Rolls, Edmund T},
	month = nov,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {714--731},
}

@article{gao_simplicity_2015,
	title = {On simplicity and complexity in the brave new world of large-scale neuroscience},
	volume = {32},
	abstract = {Technological advances have dramatically expanded our ability to probe multi-neuronal dynamics and connectivity in the brain. However, our ability to extract a simple conceptual understanding from complex data is increasingly hampered by the lack of theoretically principled data analytic procedures, as well as theoretical frameworks for how circuit connectivity and dynamics can conspire to generate emergent behavioral and cognitive functions. We review and outline potential avenues for progress, including new theories of high dimensional data analysis, the need to analyze complex artificial networks, and methods for analyzing entire spaces of circuit models, rather than one model at a time. Such interplay between experiments, data analysis and theory will be indispensable in catalyzing conceptual advances in the age of large-scale neuroscience.},
	journal = {Curr. Opin. Neurobiol.},
	author = {Gao, Peiran and Ganguli, Surya},
	month = jun,
	year = {2015},
	keywords = {merged\_fiete.bib},
	pages = {148--155},
}

@article{davidson_hippocampal_2009,
	title = {Hippocampal replay of extended experience},
	volume = {63},
	abstract = {During pauses in exploration, ensembles of place cells in the rat hippocampus re-express firing sequences corresponding to recent spatial experience. Such “replay” co-occurs with ripple events: short-lasting (approximately 50-120 ms), high-frequency (approximately 200 Hz) oscillations that are associated with increased hippocampal-cortical communication. In previous studies, rats exploring small environments showed replay anchored to the rat's current location and compressed in time into a single ripple event. Here, we show, using a neural decoding approach, that firing sequences corresponding to long runs through a large environment are replayed with high fidelity and that such replay can begin at remote locations on the track. Extended replay proceeds at a characteristic virtual speed of approximately 8 m/s and remains coherent across trains of ripple events. These results suggest that extended replay is composed of chains of shorter subsequences, which may reflect a strategy for the storage and flexible expression of memories of prolonged experience.},
	number = {4},
	journal = {Neuron},
	author = {Davidson, Thomas J and Kloosterman, Fabian and Wilson, Matthew A},
	month = aug,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {497--507},
}

@article{skaggs_replay_1996,
	title = {Replay of neuronal firing sequences in rat hippocampus during sleep following spatial experience},
	volume = {271},
	abstract = {The correlated activity of rat hippocampal pyramidal cells during sleep reflects the activity of those cells during earlier spatial exploration. Now the patterns of activity during sleep have also been found to reflect the order in which the cells fired during spatial exploration. This relation was reliably stronger for sleep after the behavioral session than before it; thus, the activity during sleep reflects changes produced by experience. This memory for temporal order of neuronal firing could be produced by an interaction between the temporal integration properties of long-term potentiation and the phase shifting of spike activity with respect to the hippocampal theta rhythm.},
	number = {5257},
	journal = {Science},
	author = {Skaggs, W E and McNaughton, B L},
	month = mar,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {1870--1873},
}

@article{lee_memory_2002,
	title = {Memory of sequential experience in the hippocampus during slow wave sleep},
	volume = {36},
	abstract = {Rats repeatedly ran through a sequence of spatial receptive fields of hippocampal CA1 place cells in a fixed temporal order. A novel combinatorial decoding method reveals that these neurons repeatedly fired in precisely this order in long sequences involving four or more cells during slow wave sleep (SWS) immediately following, but not preceding, the experience. The SWS sequences occurred intermittently in brief ( approximately 100 ms) bursts, each compressing the behavioral sequence in time by approximately 20-fold. This rapid encoding of sequential experience is consistent with evidence that the hippocampus is crucial for spatial learning in rodents and the formation of long-term memories of events in time in humans.},
	number = {6},
	journal = {Neuron},
	author = {Lee, Albert K and Wilson, Matthew A},
	month = dec,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {1183--1194},
}

@article{pfeiffer_hippocampal_2013,
	title = {Hippocampal place-cell sequences depict future paths to remembered goals},
	volume = {497},
	abstract = {Effective navigation requires planning extended routes to remembered goal locations. Hippocampal place cells have been proposed to have a role in navigational planning, but direct evidence has been lacking. Here we show that before goal-directed navigation in an open arena, the rat hippocampus generates brief sequences encoding spatial trajectories strongly biased to progress from the subject's current location to a known goal location. These sequences predict immediate future behaviour, even in cases in which the specific combination of start and goal locations is novel. These results indicate that hippocampal sequence events characterized previously in linearly constrained environments as 'replay' are also capable of supporting a goal-directed, trajectory-finding mechanism, which identifies important places and relevant behavioural paths, at specific times when memory retrieval is required, and in a manner that could be used to control subsequent navigational behaviour.},
	number = {7447},
	journal = {Nature},
	author = {Pfeiffer, Brad E and Foster, David J},
	month = may,
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {74--79},
}

@article{wilson_reactivation_1994,
	title = {Reactivation of hippocampal ensemble memories during sleep},
	volume = {265},
	abstract = {Simultaneous recordings were made from large ensembles of hippocampal “place cells” in three rats during spatial behavioral tasks and in slow-wave sleep preceding and following these behaviors. Cells that fired together when the animal occupied particular locations in the environment exhibited an increased tendency to fire together during subsequent sleep, in comparison to sleep episodes preceding the behavioral tasks. Cells that were inactive during behavior, or that were active but had non-overlapping spatial firing, did not show this increase. This effect, which declined gradually during each post-behavior sleep session, may result from synaptic modification during waking experience. Information acquired during active behavior is thus re-expressed in hippocampal circuits during sleep, as postulated by some theories of memory consolidation.},
	number = {5172},
	journal = {Science},
	author = {Wilson, M A and McNaughton, B L},
	month = jul,
	year = {1994},
	keywords = {merged\_fiete.bib, Non-programmatic},
	pages = {676--679},
}

@article{von_der_heydt_illusory_1984,
	title = {Illusory contours and cortical neuron responses},
	volume = {224},
	abstract = {Figures in which human observers perceive “illusory contours” were found to evoke responses in cells of area 18 in the visual cortex of alert monkeys. The cells responded as if the contours were formed by real lines or edges. Modifications that weakened the perception of contours also reduced the neuronal responses. In contrast, cells in area 17 were apparently unable to “see” these contours.},
	number = {4654},
	journal = {Science},
	author = {von der Heydt, R and Peterhans, E and Baumgartner, G},
	month = jun,
	year = {1984},
	keywords = {merged\_fiete.bib},
	pages = {1260--1262},
}

@article{grosof_macaque_1993,
	title = {Macaque {V1} neurons can signal 'illusory' contours},
	volume = {365},
	abstract = {We describe here a new view of primary visual cortex (V1) based on measurements of neural responses in V1 to patterns called 'illusory contours' (Fig. 1a, b). Detection of an object's boundary contours is a fundamental visual task. Boundary contours are defined by discontinuities not only in luminance and colour, but also in texture, disparity and motion. Two theoretical approaches can account for illusory contour perception. The cognitive approach emphasizes top-down processes. An alternative emphasizes bottom-up processing. This latter view is supported by (1) stimulus constraints for illusory contour perception and (2) the discovery by von der Heydt and Peterhans of neurons in extrastriate visual area V2 (but not in V1) of macaque monkeys that respond to illusory contours. Using stimuli different from those used previously, we found illusory contour responses in about half the neurons studied in V1 of macaque monkeys. Therefore, there are neurons as early as V1 with the computational power to detect illusory contours and to help distinguish figure from ground.},
	number = {6446},
	journal = {Nature},
	author = {Grosof, D H and Shapley, R M and Hawken, M J},
	month = oct,
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {550--552},
}

@article{nijhawan_motion_1994,
	title = {Motion extrapolation in catching},
	volume = {370},
	number = {6487},
	journal = {Nature},
	author = {Nijhawan, R},
	month = jul,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {256--257},
}

@article{purushothaman_moving_1998,
	title = {Moving ahead through differential visual latency},
	volume = {396},
	number = {6710},
	journal = {Nature},
	author = {Purushothaman, G and Patel, S S and Bedell, H E and Ogmen, H},
	month = dec,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {424},
}

@article{thorpe_speed_1996,
	title = {Speed of processing in the human visual system},
	volume = {381},
	abstract = {How long does it take for the human visual system to process a complex natural image? Subjectively, recognition of familiar objects and scenes appears to be virtually instantaneous, but measuring this processing time experimentally has proved difficult. Behavioural measures such as reaction times can be used, but these include not only visual processing but also the time required for response execution. However, event-related potentials (ERPs) can sometimes reveal signs of neural processing well before the motor output. Here we use a go/no-go categorization task in which subjects have to decide whether a previously unseen photograph, flashed on for just 20 ms, contains an animal. ERP analysis revealed a frontal negativity specific to no-go trials that develops roughly 150 ms after stimulus onset. We conclude that the visual processing needed to perform this highly demanding task can be achieved in under 150 ms.},
	number = {6582},
	journal = {Nature},
	author = {Thorpe, S and Fize, D and Marlot, C},
	month = jun,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {520--522},
}

@article{hennequin_dynamical_2018,
	title = {The {Dynamical} {Regime} of {Sensory} {Cortex}: {Stable} {Dynamics} around a {Single} {Stimulus}-{Tuned} {Attractor} {Account} for {Patterns} of {Noise} {Variability}},
	volume = {98},
	abstract = {Correlated variability in cortical activity is ubiquitously quenched following stimulus onset, in a stimulus-dependent manner. These modulations have been attributed to circuit dynamics involving either multiple stable states (“attractors”) or chaotic activity. Here we show that a qualitatively different dynamical regime, involving fluctuations about a single, stimulus-driven attractor in a loosely balanced excitatory-inhibitory network (the stochastic “stabilized supralinear network”), best explains these modulations. Given the supralinear input/output functions of cortical neurons, increased stimulus drive strengthens effective network connectivity. This shifts the balance from interactions that amplify variability to suppressive inhibitory feedback, quenching correlated variability around more strongly driven steady states. Comparing to previously published and original data analyses, we show that this mechanism, unlike previous proposals, uniquely accounts for the spatial patterns and fast temporal dynamics of variability suppression. Specifying the cortical operating regime is key to understanding the computations underlying perception.},
	number = {4},
	journal = {Neuron},
	author = {Hennequin, Guillaume and Ahmadian, Yashar and Rubin, Daniel B and Lengyel, Máté and Miller, Kenneth D},
	year = {2018},
	keywords = {merged\_fiete.bib, theoretical neuroscience, circuit dynamics, cortical variability, MT, noise correlations, V1, variability quenching},
	pages = {846--860.e5},
}

@article{kim_generation_2019,
	title = {Generation of stable heading representations in diverse visual scenes},
	volume = {576},
	abstract = {Many animals rely on an internal heading representation when navigating in varied environments1-10. How this representation is linked to the sensory cues that define different surroundings is unclear. In the fly brain, heading is represented by 'compass' neurons that innervate a ring-shaped structure known as the ellipsoid body3,11,12. Each compass neuron receives inputs from 'ring' neurons that are selective for particular visual features13-16; this combination provides an ideal substrate for the extraction of directional information from a visual scene. Here we combine two-photon calcium imaging and optogenetics in tethered flying flies with circuit modelling, and show how the correlated activity of compass and visual neurons drives plasticity17-22, which flexibly transforms two-dimensional visual cues into a stable heading representation. We also describe how this plasticity enables the fly to convert a partial heading representation, established from orienting within part of a novel setting, into a complete heading representation. Our results provide mechanistic insight into the memory-related computations that are essential for flexible navigation in varied surroundings.},
	number = {7785},
	journal = {Nature},
	author = {Kim, Sung Soo and Hermundstad, Ann M and Romani, Sandro and Abbott, L F and Jayaraman, Vivek},
	year = {2019},
	keywords = {merged\_fiete.bib},
	pages = {126--131},
}

@article{scheffer_connectome_2020,
	title = {A connectome and analysis of the adult {Drosophila} central brain},
	volume = {9},
	abstract = {The neural circuits responsible for animal behavior remain largely unknown. We summarize new methods and present the circuitry of a large fraction of the brain of the fruit fly Drosophila melanogaster. Improved methods include new procedures to prepare, image, align, segment, find synapses in, and proofread such large data sets. We define cell types, refine computational compartments, and provide an exhaustive atlas of cell examples and types, many of them novel. We provide detailed circuits consisting of neurons and their chemical synapses for most of the central brain. We make the data public and simplify access, reducing the effort needed to answer circuit questions, and provide procedures linking the neurons defined by our analysis with genetic reagents. Biologically, we examine distributions of connection strengths, neural motifs on different scales, electrical consequences of compartmentalization, and evidence that maximizing packing density is an important criterion in the evolution of the fly's brain.},
	journal = {Elife},
	author = {Scheffer, Louis K and Xu, C Shan and Januszewski, Michal and Lu, Zhiyuan and Takemura, Shin-Ya and Hayworth, Kenneth J and Huang, Gary B and Shinomiya, Kazunori and Maitlin-Shepard, Jeremy and Berg, Stuart and Clements, Jody and Hubbard, Philip M and Katz, William T and Umayam, Lowell and Zhao, Ting and Ackerman, David and Blakely, Tim and Bogovic, John and Dolafi, Tom and Kainmueller, Dagmar and Kawase, Takashi and Khairy, Khaled A and Leavitt, Laramie and Li, Peter H and Lindsey, Larry and Neubarth, Nicole and Olbris, Donald J and Otsuna, Hideo and Trautman, Eric T and Ito, Masayoshi and Bates, Alexander S and Goldammer, Jens and Wolff, Tanya and Svirskas, Robert and Schlegel, Philipp and Neace, Erika and Knecht, Christopher J and Alvarado, Chelsea X and Bailey, Dennis A and Ballinger, Samantha and Borycz, Jolanta A and Canino, Brandon S and Cheatham, Natasha and Cook, Michael and Dreher, Marisa and Duclos, Octave and Eubanks, Bryon and Fairbanks, Kelli and Finley, Samantha and Forknall, Nora and Francis, Audrey and Hopkins, Gary Patrick and Joyce, Emily M and Kim, Sungjin and Kirk, Nicole A and Kovalyak, Julie and Lauchie, Shirley A and Lohff, Alanna and Maldonado, Charli and Manley, Emily A and McLin, Sari and Mooney, Caroline and Ndama, Miatta and Ogundeyi, Omotara and Okeoma, Nneoma and Ordish, Christopher and Padilla, Nicholas and Patrick, Christopher M and Paterson, Tyler and Phillips, Elliott E and Phillips, Emily M and Rampally, Neha and Ribeiro, Caitlin and Robertson, Madelaine K and Rymer, Jon Thomson and Ryan, Sean M and Sammons, Megan and Scott, Anne K and Scott, Ashley L and Shinomiya, Aya and Smith, Claire and Smith, Kelsey and Smith, Natalie L and Sobeski, Margaret A and Suleiman, Alia and Swift, Jackie and Takemura, Satoko and Talebi, Iris and Tarnogorska, Dorota and Tenshaw, Emily and Tokhi, Temour and Walsh, John J and Yang, Tansy and Horne, Jane Anne and Li, Feng and Parekh, Ruchi and Rivlin, Patricia K and Jayaraman, Vivek and Costa, Marta and Jefferis, Gregory Sxe and Ito, Kei and Saalfeld, Stephan and George, Reed and Meinertzhagen, Ian A and Rubin, Gerald M and Hess, Harald F and Jain, Viren and Plaza, Stephen M},
	year = {2020},
	keywords = {merged\_fiete.bib, neuroscience, computational biology, systems biology, connectome, brain regions, cell types, connectome reconstuction methods, D. melanogaster, graph properties, synapse detecton},
}

@article{yoder_both_2011,
	title = {Both visual and idiothetic cues contribute to head direction cell stability during navigation along complex routes},
	volume = {105},
	abstract = {Successful navigation requires a constantly updated neural representation of directional heading, which is conveyed by head direction (HD) cells. The HD signal is predominantly controlled by visual landmarks, but when familiar landmarks are unavailable, self-motion cues are able to control the HD signal via path integration. Previous studies of the relationship between HD cell activity and path integration have been limited to two or more arenas located in the same room, a drawback for interpretation because the same visual cues may have been perceptible across arenas. To address this issue, we tested the relationship between HD cell activity and path integration by recording HD cells while rats navigated within a 14-unit T-maze and in a multiroom maze that consisted of unique arenas that were located in different rooms but connected by a passageway. In the 14-unit T-maze, the HD signal remained relatively stable between the start and goal boxes, with the preferred firing directions usually shifting {\textless}45 {\textasciicircum}{\textbackslash}circ during maze traversal. In the multiroom maze in light, the preferred firing directions also remained relatively constant between rooms, but with greater variability than in the 14-unit maze. In darkness, HD cell preferred firing directions showed marginally more variability between rooms than in the lighted condition. Overall, the results indicate that self-motion cues are capable of maintaining the HD cell signal in the absence of familiar visual cues, although there are limits to its accuracy. In addition, visual information, even when unfamiliar, can increase the precision of directional perception.},
	number = {6},
	journal = {J. Neurophysiol.},
	author = {Yoder, Ryan M and Clark, Benjamin J and Brown, Joel E and Lamia, Mignon V and Valerio, Stephane and Shinder, Michael E and Taube, Jeffrey S},
	month = jun,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {2989--3001},
}

@article{yoder_visual_2015,
	title = {Visual landmark information gains control of the head direction signal at the lateral mammillary nuclei},
	volume = {35},
	abstract = {The neural representation of directional heading is conveyed by head direction (HD) cells located in an ascending circuit that includes projections from the lateral mammillary nuclei (LMN) to the anterodorsal thalamus (ADN) to the postsubiculum (PoS). The PoS provides return projections to LMN and ADN and is responsible for the landmark control of HD cells in ADN. However, the functional role of the PoS projection to LMN has not been tested. The present study recorded HD cells from LMN after bilateral PoS lesions to determine whether the PoS provides landmark control to LMN HD cells. After the lesion and implantation of electrodes, HD cell activity was recorded while rats navigated within a cylindrical arena containing a single visual landmark or while they navigated between familiar and novel arenas of a dual-chamber apparatus. PoS lesions disrupted the landmark control of HD cells and also disrupted the stability of the preferred firing direction of the cells in darkness. Furthermore, PoS lesions impaired the stable HD cell representation maintained by path integration mechanisms when the rat walked between familiar and novel arenas. These results suggest that visual information first gains control of the HD cell signal in the LMN, presumably via the direct PoS {\textbackslash}rightarrow LMN projection. This visual landmark information then controls HD cells throughout the HD cell circuit.},
	number = {4},
	journal = {J. Neurosci.},
	author = {Yoder, Ryan M and Peck, James R and Taube, Jeffrey S},
	month = jan,
	year = {2015},
	keywords = {merged\_fiete.bib, rat, navigation, landmark, mammillary, spatial orientation, visual},
	pages = {1354--1367},
}

@article{yoder_vestibular_2014,
	title = {The vestibular contribution to the head direction signal and navigation},
	volume = {8},
	abstract = {Spatial learning and navigation depend on neural representations of location and direction within the environment. These representations, encoded by place cells and head direction (HD) cells, respectively, are dominantly controlled by visual cues, but require input from the vestibular system. Vestibular signals play an important role in forming spatial representations in both visual and non-visual environments, but the details of this vestibular contribution are not fully understood. Here, we review the role of the vestibular system in generating various spatial signals in rodents, focusing primarily on HD cells. We also examine the vestibular system's role in navigation and the possible pathways by which vestibular information is conveyed to higher navigation centers.},
	journal = {Front. Integr. Neurosci.},
	author = {Yoder, Ryan M and Taube, Jeffrey S},
	year = {2014},
	keywords = {merged\_fiete.bib, navigation, spatial orientation, otolith organs, semicircular canals, vestibular},
	pages = {32},
}

@article{hulse_mechanisms_2020,
	title = {Mechanisms {Underlying} the {Neural} {Computation} of {Head} {Direction}},
	volume = {43},
	abstract = {Many animals use an internal sense of direction to guide their movements through the world. Neurons selective to head direction are thought to support this directional sense and have been found in a diverse range of species, from insects to primates, highlighting their evolutionary importance. Across species, most head-direction networks share four key properties: a unique representation of direction at all times, persistent activity in the absence of movement, integration of angular velocity to update the representation, and the use of directional cues to correct drift. The dynamics of theorized network structures called ring attractors elegantly account for these properties, but their relationship to brain circuits is unclear. Here, we review experiments in rodents and flies that offer insights into potential neural implementations of ring attractor networks. We suggest that a theory-guided search across model systems for biological mechanisms that enable such dynamics would uncover general principles underlying head-direction circuit function.},
	journal = {Annu. Rev. Neurosci.},
	author = {Hulse, Brad K and Jayaraman, Vivek},
	year = {2020},
	keywords = {merged\_fiete.bib, navigation, path integration, angular velocity, central complex, head-direction cells, ring attractor},
	pages = {31--54},
}

@article{fisher_sensorimotor_2019,
	title = {Sensorimotor experience remaps visual input to a heading-direction network},
	volume = {576},
	abstract = {In the Drosophila brain, 'compass' neurons track the orientation of the body and head (the fly's heading) during navigation 1,2. In the absence of visual cues, the compass neuron network estimates heading by integrating self-movement signals over time3,4. When a visual cue is present, the estimate of the network is more accurate1,3. Visual inputs to compass neurons are thought to originate from inhibitory neurons called R neurons (also known as ring neurons); the receptive fields of R neurons tile visual space5. The axon of each R neuron overlaps with the dendrites of every compass neuron6, raising the question of how visual cues are integrated into the compass. Here, using in vivo whole-cell recordings, we show that a visual cue can evoke synaptic inhibition in compass neurons and that R neurons mediate this inhibition. Each compass neuron is inhibited only by specific visual cue positions, indicating that many potential connections from R neurons onto compass neurons are actually weak or silent. We also show that the pattern of visually evoked inhibition can reorganize over minutes as the fly explores an altered virtual-reality environment. Using ensemble calcium imaging, we demonstrate that this reorganization causes persistent changes in the compass coordinate frame. Taken together, our data suggest a model in which correlated pre- and postsynaptic activity triggers associative long-term synaptic depression of visually evoked inhibition in compass neurons. Our findings provide evidence for the theoretical proposal that associative plasticity of sensory inputs, when combined with attractor dynamics, can reconcile self-movement information with changing external cues to generate a coherent sense of direction7-12.},
	number = {7785},
	journal = {Nature},
	author = {Fisher, Yvette E and Lu, Jenny and D'Alessandro, Isabel and Wilson, Rachel I},
	year = {2019},
	keywords = {merged\_fiete.bib},
	pages = {121--125},
}

@article{fiete_binary_2014,
	title = {A binary {Hopfield} network with 1/{\textbackslash}log(n) information rate and applications to grid cell decoding},
	abstract = {A Hopfield network is an auto-associative, distributive model of neural memory storage and retrieval. A form of error-correcting code, the Hopfield network can learn a set of patterns as stable points of the network dynamic, and retrieve them from noisy inputs – thus Hopfield networks are their own decoders. Unlike in coding theory, where the information rate of a good code (in the Shannon sense) is finite but the cost of decoding does not play a role in the rate, the information rate of Hopfield networks trained with state-of-the-art learning algorithms is of the order {\textbackslash}log(n)/n, a quantity that tends to zero asymptotically with n, the number of neurons in the network. For specially constructed networks, the best information rate currently achieved is of order 1/{\textbackslash}sqrtn. In this work, we design simple binary Hopfield networks that have asymptotically vanishing error rates at an information rate of 1/{\textbackslash}log(n). These networks can be added as the decoders of any neural code with noisy neurons. As an example, we apply our network to a binary neural decoder of the grid cell code to attain information rate 1/{\textbackslash}log(n).},
	author = {Fiete, Ila and Schwab, David J and Tran, Ngoc M},
	year = {2014},
	keywords = {merged\_fiete.bib},
}

@article{chen_map_2017,
	title = {A {Map} of {Anticipatory} {Activity} in {Mouse} {Motor} {Cortex}},
	volume = {94},
	abstract = {Activity in the mouse anterior lateral motor cortex (ALM) instructs directional movements, often seconds before movement initiation. It is unknown whether this preparatory activity is localized to ALM or widely distributed within motor cortex. Here we imaged activity across motor cortex while mice performed a whisker-based object localization task with a delayed, directional licking response. During tactile sensation and the delay epoch, object location was represented in motor cortex areas that are medial and posterior relative to ALM, including vibrissal motor cortex. Preparatory activity appeared first in deep layers of ALM, seconds before the behavioral response, and remained localized to ALM until the behavioral response. Later, widely distributed neurons represented the outcome of the trial. Cortical area was more predictive of neuronal selectivity than laminar location or axonal projection target. Motor cortex therefore represents sensory, motor, and outcome information in a spatially organized manner.},
	number = {4},
	journal = {Neuron},
	author = {Chen, Tsai-Wen and Li, Nuo and Daie, Kayvon and Svoboda, Karel},
	month = may,
	year = {2017},
	keywords = {motor planning, motor cortex, persistent activity, merged\_fiete.bib, short-term memory, calcium, decision, gcamp, gcamp6, two-photon},
	pages = {866--879.e4},
}

@article{daie_targeted_2021,
	title = {Targeted photostimulation uncovers circuit motifs supporting short-term memory},
	volume = {24},
	abstract = {Short-term memory is associated with persistent neural activity that is maintained by positive feedback between neurons. To explore the neural circuit motifs that produce memory-related persistent activity, we measured coupling between functionally characterized motor cortex neurons in mice performing a memory-guided response task. Targeted two-photon photostimulation of small ({\textless}10) groups of neurons produced sparse calcium responses in coupled neurons over approximately 100 μm. Neurons with similar task-related selectivity were preferentially coupled. Photostimulation of different groups of neurons modulated activity in different subpopulations of coupled neurons. Responses of stimulated and coupled neurons persisted for seconds, far outlasting the duration of the photostimuli. Photostimuli produced behavioral biases that were predictable based on the selectivity of the perturbed neuronal population, even though photostimulation preceded the behavioral response by seconds. Our results suggest that memory-related neural circuits contain intercalated, recurrently connected modules, which can independently maintain selective persistent activity.},
	number = {2},
	journal = {Nat. Neurosci.},
	author = {Daie, Kayvon and Svoboda, Karel and Druckmann, Shaul},
	year = {2021},
	keywords = {merged\_fiete.bib},
	pages = {259--265},
}

@article{mante_context-dependent_2013,
	title = {Context-dependent computation by recurrent dynamics in prefrontal cortex},
	volume = {503},
	abstract = {Prefrontal cortex is thought to have a fundamental role in flexible, context-dependent behaviour, but the exact nature of the computations underlying this role remains largely unknown. In particular, individual prefrontal neurons often generate remarkably complex responses that defy deep understanding of their contribution to behaviour. Here we study prefrontal cortex activity in macaque monkeys trained to flexibly select and integrate noisy sensory inputs towards a choice. We find that the observed complexity and functional roles of single neurons are readily understood in the framework of a dynamical process unfolding at the level of the population. The population dynamics can be reproduced by a trained recurrent neural network, which suggests a previously unknown mechanism for selection and integration of task-relevant inputs. This mechanism indicates that selection and integration are two aspects of a single dynamical process unfolding within the same prefrontal circuits, and potentially provides a novel, general framework for understanding context-dependent computations.},
	number = {7474},
	journal = {Nature},
	author = {Mante, Valerio and Sussillo, David and Shenoy, Krishna V and Newsome, William T},
	month = nov,
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {78--84},
}

@article{weisenburger_guide_2018,
	title = {A {Guide} to {Emerging} {Technologies} for {Large}-{Scale} and {Whole}-{Brain} {Optical} {Imaging} of {Neuronal} {Activity}},
	volume = {41},
	abstract = {The mammalian brain is a densely interconnected network that consists of millions to billions of neurons. Decoding how information is represented and processed by this neural circuitry requires the ability to capture and manipulate the dynamics of large populations at high speed and high resolution over a large area of the brain. Although the use of optical approaches by the neuroscience community has rapidly increased over the past two decades, most microscopy approaches are unable to record the activity of all neurons comprising a functional network across the mammalian brain at relevant temporal and spatial resolutions. In this review, we survey the recent development in optical technologies for Ca2+ imaging in this regard and provide an overview of the strengths and limitations of each modality and its potential for scalability. We provide guidance from the perspective of a biological user driven by the typical biological applications and sample conditions. We also discuss the potential for future advances and synergies that could be obtained through hybrid approaches or other modalities.},
	journal = {Annu. Rev. Neurosci.},
	author = {Weisenburger, Siegfried and Vaziri, Alipasha},
	year = {2018},
	keywords = {merged\_fiete.bib, Ca2+ imaging, functional brain network, high-speed optical neuronal recording, large-scale imaging, neural circuit dynamics, volumetric imaging},
	pages = {431--452},
}

@article{grosenick_closed-loop_2015,
	title = {Closed-loop and activity-guided optogenetic control},
	volume = {86},
	abstract = {Advances in optical manipulation and observation of neural activity have set the stage for widespread implementation of closed-loop and activity-guided optical control of neural circuit dynamics. Closing the loop optogenetically (i.e., basing optogenetic stimulation on simultaneously observed dynamics in a principled way) is a powerful strategy for causal investigation of neural circuitry. In particular, observing and feeding back the effects of circuit interventions on physiologically relevant timescales is valuable for directly testing whether inferred models of dynamics, connectivity, and causation are accurate in vivo. Here we highlight technical and theoretical foundations as well as recent advances and opportunities in this area, and we review in detail the known caveats and limitations of optogenetic experimentation in the context of addressing these challenges with closed-loop optogenetic control in behaving animals.},
	number = {1},
	journal = {Neuron},
	author = {Grosenick, Logan and Marshel, James H and Deisseroth, Karl},
	month = apr,
	year = {2015},
	keywords = {merged\_fiete.bib},
	pages = {106--139},
}

@article{aimon_fast_2019,
	title = {Fast near-whole-brain imaging in adult {Drosophila} during responses to stimuli and behavior},
	volume = {17},
	abstract = {Whole-brain recordings give us a global perspective of the brain in action. In this study, we describe a method using light field microscopy to record near-whole brain calcium and voltage activity at high speed in behaving adult flies. We first obtained global activity maps for various stimuli and behaviors. Notably, we found that brain activity increased on a global scale when the fly walked but not when it groomed. This global increase with walking was particularly strong in dopamine neurons. Second, we extracted maps of spatially distinct sources of activity as well as their time series using principal component analysis and independent component analysis. The characteristic shapes in the maps matched the anatomy of subneuropil regions and, in some cases, a specific neuron type. Brain structures that responded to light and odor were consistent with previous reports, confirming the new technique's validity. We also observed previously uncharacterized behavior-related activity as well as patterns of spontaneous voltage activity.},
	number = {2},
	journal = {PLoS Biol.},
	author = {Aimon, Sophie and Katsuki, Takeo and Jia, Tongqiu and Grosenick, Logan and Broxton, Michael and Deisseroth, Karl and Sejnowski, Terrence J and Greenspan, Ralph J},
	year = {2019},
	keywords = {merged\_fiete.bib},
	pages = {e2006732},
}

@article{steinmetz_neuropixels_2020,
	title = {Neuropixels 2.0: {A} miniaturized high-density probe for stable, long-term brain recordings},
	author = {Steinmetz, Nicholas A and Aydin, Cagatay and Lebedeva, Anna and Okun, Michael and Pachitariu, Marius and Bauza, Marius and Beau, Maxime and Bhagat, Jai and Böhm, Claudia and Broux, Martijn and Chen, Susu and Colonell, Jennifer and Gardner, Richard J and Karsh, Bill and Kostadinov, Dimitar and Mora-Lopez, Carolina and Park, Junchol and Putzeys, Jan and Sauerbrei, Britton and van Daal, Rik J J and Vollan, Abraham Z and Welkenhuysen, Marleen and Ye, Zhiwen and Dudman, Joshua and Dutta, Barundeb and Hantman, Adam W and Harris, Kenneth D and Lee, Albert K and Moser, Edvard I and O'Keefe, John and Renart, Alfonso and Svoboda, Karel and Häusser, Michael and Haesler, Sebastian and Carandini, Matteo and Harris, Timothy D},
	month = oct,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory},
	keywords = {merged\_fiete.bib},
}

@article{vattikuti_canonical_2016,
	title = {Canonical {Cortical} {Circuit} {Model} {Explains} {Rivalry}, {Intermittent} {Rivalry}, and {Rivalry} {Memory}},
	volume = {12},
	abstract = {It has been shown that the same canonical cortical circuit model with mutual inhibition and a fatigue process can explain perceptual rivalry and other neurophysiological responses to a range of static stimuli. However, it has been proposed that this model cannot explain responses to dynamic inputs such as found in intermittent rivalry and rivalry memory, where maintenance of a percept when the stimulus is absent is required. This challenges the universality of the basic canonical cortical circuit. Here, we show that by including an overlooked realistic small nonspecific background neural activity, the same basic model can reproduce intermittent rivalry and rivalry memory without compromising static rivalry and other cortical phenomena. The background activity induces a mutual-inhibition mechanism for short-term memory, which is robust to noise and where fine-tuning of recurrent excitation or inclusion of sub-threshold currents or synaptic facilitation is unnecessary. We prove existence conditions for the mechanism and show that it can explain experimental results from the quartet apparent motion illusion, which is a prototypical intermittent rivalry stimulus.},
	number = {5},
	journal = {PLoS Comput. Biol.},
	author = {Vattikuti, Shashaank and Thangaraj, Phyllis and Xie, Hua W and Gotts, Stephen J and Martin, Alex and Chow, Carson C},
	year = {2016},
	keywords = {merged\_fiete.bib},
	pages = {e1004903},
}

@article{jercog_up-down_2017,
	title = {{UP}-{DOWN} cortical dynamics reflect state transitions in a bistable network},
	volume = {6},
	abstract = {In the idling brain, neuronal circuits transition between periods of sustained firing (UP state) and quiescence (DOWN state), a pattern the mechanisms of which remain unclear. Here we analyzed spontaneous cortical population activity from anesthetized rats and found that UP and DOWN durations were highly variable and that population rates showed no significant decay during UP periods. We built a network rate model with excitatory (E) and inhibitory (I) populations exhibiting a novel bistable regime between a quiescent and an inhibition-stabilized state of arbitrarily low rate. Fluctuations triggered state transitions, while adaptation in E cells paradoxically caused a marginal decay of E-rate but a marked decay of I-rate in UP periods, a prediction that we validated experimentally. A spiking network implementation further predicted that DOWN-to-UP transitions must be caused by synchronous high-amplitude events. Our findings provide evidence of bistable cortical networks that exhibit non-rhythmic state transitions when the brain rests.},
	journal = {Elife},
	author = {Jercog, Daniel and Roxin, Alex and Barthó, Peter and Luczak, Artur and Compte, Albert and de la Rocha, Jaime},
	year = {2017},
	keywords = {merged\_fiete.bib, neuroscience, rat, bistability, computational network model, cortical circuit, up down states},
}

@article{roxin_oscillations_2016,
	title = {Oscillations in the bistable regime of neuronal networks},
	volume = {94},
	abstract = {Bistability between attracting fixed points in neuronal networks has been hypothesized to underlie persistent activity observed in several cortical areas during working memory tasks. In network models this kind of bistability arises due to strong recurrent excitation, sufficient to generate a state of high activity created in a saddle-node (SN) bifurcation. On the other hand, canonical network models of excitatory and inhibitory neurons (E-I networks) robustly produce oscillatory states via a Hopf (H) bifurcation due to the E-I loop. This mechanism for generating oscillations has been invoked to explain the emergence of brain rhythms in the β to γ bands. Although both bistability and oscillatory activity have been intensively studied in network models, there has not been much focus on the coincidence of the two. Here we show that when oscillations emerge in E-I networks in the bistable regime, their phenomenology can be explained to a large extent by considering coincident SN and H bifurcations, known as a codimension two Takens-Bogdanov bifurcation. In particular, we find that such oscillations are not composed of a stable limit cycle, but rather are due to noise-driven oscillatory fluctuations. Furthermore, oscillations in the bistable regime can, in principle, have arbitrarily low frequency.},
	number = {1-1},
	journal = {Phys Rev E},
	author = {Roxin, Alex and Compte, Albert},
	month = jul,
	year = {2016},
	keywords = {merged\_fiete.bib},
	pages = {012410},
}

@article{moreno-bote_noise-induced_2007,
	title = {Noise-induced alternations in an attractor network model of perceptual bistability},
	volume = {98},
	abstract = {When a stimulus supports two distinct interpretations, perception alternates in an irregular manner between them. What causes the bistable perceptual switches remains an open question. Most existing models assume that switches arise from a slow fatiguing process, such as adaptation or synaptic depression. We develop a new, attractor-based framework in which alternations are induced by noise and are absent without it. Our model goes beyond previous energy-based conceptualizations of perceptual bistability by constructing a neurally plausible attractor model that is implemented in both firing rate mean-field and spiking cell-based networks. The model accounts for known properties of bistable perceptual phenomena, most notably the increase in alternation rate with stimulation strength observed in binocular rivalry. Furthermore, it makes a novel prediction about the effect of changing stimulus strength on the activity levels of the dominant and suppressed neural populations, a prediction that could be tested with functional MRI or electrophysiological recordings. The neural architecture derived from the energy-based model readily generalizes to several competing populations, providing a natural extension for multistability phenomena.},
	number = {3},
	journal = {J. Neurophysiol.},
	author = {Moreno-Bote, Rubén and Rinzel, John and Rubin, Nava},
	month = sep,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {1125--1139},
}

@article{josselyn_memory_2020,
	title = {Memory engrams: {Recalling} the past and imagining the future},
	volume = {367},
	abstract = {In 1904, Richard Semon introduced the term “engram” to describe the neural substrate for storing memories. An experience, Semon proposed, activates a subset of cells that undergo off-line, persistent chemical and/or physical changes to become an engram. Subsequent reactivation of this engram induces memory retrieval. Although Semon's contributions were largely ignored in his lifetime, new technologies that allow researchers to image and manipulate the brain at the level of individual neurons has reinvigorated engram research. We review recent progress in studying engrams, including an evaluation of evidence for the existence of engrams, the importance of intrinsic excitability and synaptic plasticity in engrams, and the lifetime of an engram. Together, these findings are beginning to define an engram as the basic unit of memory.},
	number = {6473},
	journal = {Science},
	author = {Josselyn, Sheena A and Tonegawa, Susumu},
	year = {2020},
	keywords = {merged\_fiete.bib},
}

@article{lin_sparse_2014,
	title = {Sparse, decorrelated odor coding in the mushroom body enhances learned odor discrimination},
	volume = {17},
	abstract = {Sparse coding may be a general strategy of neural systems for augmenting memory capacity. In Drosophila melanogaster, sparse odor coding by the Kenyon cells of the mushroom body is thought to generate a large number of precisely addressable locations for the storage of odor-specific memories. However, it remains untested how sparse coding relates to behavioral performance. Here we demonstrate that sparseness is controlled by a negative feedback circuit between Kenyon cells and the GABAergic anterior paired lateral (APL) neuron. Systematic activation and blockade of each leg of this feedback circuit showed that Kenyon cells activated APL and APL inhibited Kenyon cells. Disrupting the Kenyon cell-APL feedback loop decreased the sparseness of Kenyon cell odor responses, increased inter-odor correlations and prevented flies from learning to discriminate similar, but not dissimilar, odors. These results suggest that feedback inhibition suppresses Kenyon cell activity to maintain sparse, decorrelated odor coding and thus the odor specificity of memories.},
	number = {4},
	journal = {Nat. Neurosci.},
	author = {Lin, Andrew C and Bygrave, Alexei M and de Calignon, Alix and Lee, Tzumin and Miesenböck, Gero},
	month = apr,
	year = {2014},
	keywords = {merged\_fiete.bib},
	pages = {559--568},
}

@article{stevens_what_2015,
	title = {What the fly's nose tells the fly's brain},
	volume = {112},
	abstract = {The fly olfactory system has a three-layer architecture: The fly's olfactory receptor neurons send odor information to the first layer (the encoder) where this information is formatted as combinatorial odor code, one which is maximally informative, with the most informative neurons firing fastest. This first layer then sends the encoded odor information to the second layer (decoder), which consists of about 2,000 neurons that receive the odor information and “break” the code. For each odor, the amplitude of the synaptic odor input to the 2,000 second-layer neurons is approximately normally distributed across the population, which means that only a very small fraction of neurons receive a large input. Each odor, however, activates its own population of large-input neurons and so a small subset of the 2,000 neurons serves as a unique tag for the odor. Strong inhibition prevents most of the second-stage neurons from firing spikes, and therefore spikes from only the small population of large-input neurons is relayed to the third stage. This selected population provides the third stage (the user) with an odor label that can be used to direct behavior based on what odor is present.},
	number = {30},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Stevens, Charles F},
	month = jul,
	year = {2015},
	keywords = {merged\_fiete.bib, fly brain, Marr motif, olfaction, theory},
	pages = {9460--9465},
}

@article{espinoza_parvalbumin_2018,
	title = {Parvalbumin+ interneurons obey unique connectivity rules and establish a powerful lateral-inhibition microcircuit in dentate gyrus},
	volume = {9},
	abstract = {Parvalbumin-positive (PV+) GABAergic interneurons in hippocampal microcircuits are thought to play a key role in several higher network functions, such as feedforward and feedback inhibition, network oscillations, and pattern separation. Fast lateral inhibition mediated by GABAergic interneurons may implement a winner-takes-all mechanism in the hippocampal input layer. However, it is not clear whether the functional connectivity rules of granule cells (GCs) and interneurons in the dentate gyrus are consistent with such a mechanism. Using simultaneous patch-clamp recordings from up to seven GCs and up to four PV+ interneurons in the dentate gyrus, we find that connectivity is structured in space, synapse-specific, and enriched in specific disynaptic motifs. In contrast to the neocortex, lateral inhibition in the dentate gyrus (in which a GC inhibits neighboring GCs via a PV+ interneuron) is 10-times more abundant than recurrent inhibition (in which a GC inhibits itself). Thus, unique connectivity rules may enable the dentate gyrus to perform specific higher-order computations.},
	number = {1},
	journal = {Nat. Commun.},
	author = {Espinoza, Claudia and Guzman, Segundo Jose and Zhang, Xiaomin and Jonas, Peter},
	year = {2018},
	keywords = {merged\_fiete.bib},
	pages = {4605},
}

@article{kurt_auditory_2008,
	title = {Auditory cortical contrast enhancing by global winner-take-all inhibitory interactions},
	volume = {3},
	abstract = {Brains decompose the world into discrete objects of perception, thereby facing the problem of how to segregate and selectively address similar objects that are concurrently present in a scene. Theoretical models propose that this could be achieved by neuronal implementations of so-called winner-take-all algorithms where neuronal representations of objects or object features interact in a competitive manner. Here we present evidence for the existence of such a mechanism in an animal species. We present electrophysiological, neuropharmacological and neuroanatomical data which suggest a novel view of the role of GABA(A)-mediated inhibition in primary auditory cortex (AI), where intracortical GABA(A)-mediated inhibition operates on a global scale within a circular map of sound periodicity representation in AI, with functionally inhibitory projections of similar effect from any location throughout the whole map. These interactions could underlie the proposed competitive “winner-take-all” algorithm to support object segregation, e.g., segregation of different speakers in cocktail-party situations.},
	number = {3},
	journal = {PLoS One},
	author = {Kurt, Simone and Deutscher, Anke and Crook, John M and Ohl, Frank W and Budinger, Eike and Moeller, Christoph K and Scheich, Henning and Schulze, Holger},
	month = mar,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {e1735},
}

@article{de_almeida_input-output_2009,
	title = {The input-output transformation of the hippocampal granule cells: from grid cells to place fields},
	volume = {29},
	abstract = {Grid cells in the rat medial entorhinal cortex fire (periodically) over the entire environment. These cells provide input to hippocampal granule cells whose output is characterized by one or more small place fields. We sought to understand how this input-output transformation occurs. Available information allows simulation of this process with no freely adjustable parameters. We first examined the spatial distribution of excitation in granule cells produced by the convergence of excitatory inputs from randomly chosen grid cells. Because the resulting summation depends on the number of inputs, it is necessary to use a realistic number (approximately 1200) and to take into consideration their 20-fold variation in strength. The resulting excitation maps have only modest peaks and valleys. To analyze how this excitation interacts with inhibition, we used an E\%-max (percentage of maximal suprathreshold excitation) winner-take-all rule that describes how gamma-frequency inhibition affects firing. We found that simulated granule cells have firing maps that have one or more place fields whose size and number approximates those observed experimentally. A substantial fraction of granule cells have no place fields, as observed experimentally. Because the input firing rates and synaptic properties are known, the excitatory charge into granule cells could be calculated (2-3 pC) and was found to be only somewhat larger than required to fire granule cells (1 pC). We conclude that the input-output transformation of dentate granule does not depend strongly on synaptic modification; place field formation can be understood in terms of simple summation of randomly chosen excitatory inputs, in conjunction with a winner-take-all network mechanism.},
	number = {23},
	journal = {J. Neurosci.},
	author = {de Almeida, Licurgo and Idiart, Marco and Lisman, John E},
	month = jun,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {7504--7512},
}

@article{mosheiff_velocity_2019,
	title = {Velocity coupling of grid cell modules enables stable embedding of a low dimensional variable in a high dimensional neural attractor},
	volume = {8},
	abstract = {Grid cells in the medial entorhinal cortex (MEC) encode position using a distributed representation across multiple neural populations (modules), each possessing a distinct spatial scale. The modular structure of the representation confers the grid cell neural code with large capacity. Yet, the modularity poses significant challenges for the neural circuitry that maintains the representation, and updates it based on self motion. Small incompatible drifts in different modules, driven by noise, can rapidly lead to large, abrupt shifts in the represented position, resulting in catastrophic readout errors. Here, we propose a theoretical model of coupled modules. The coupling suppresses incompatible drifts, allowing for a stable embedding of a two-dimensional variable (position) in a higher dimensional neural attractor, while preserving the large capacity. We propose that coupling of this type may be implemented by recurrent synaptic connectivity within the MEC with a relatively simple and biologically plausible structure.},
	journal = {Elife},
	author = {Mosheiff, Noga and Burak, Yoram},
	year = {2019},
	keywords = {neural networks, entorhinal cortex, grid cells, merged\_fiete.bib, neuroscience, rat, mouse, neural attractors, neural coding, short term memory},
}

@article{pfeiffer_place_2015,
	title = {{PLACE} {CELLS}. {Autoassociative} dynamics in the generation of sequences of hippocampal place cells},
	volume = {349},
	abstract = {Neuronal circuits produce self-sustaining sequences of activity patterns, but the precise mechanisms remain unknown. Here we provide evidence for autoassociative dynamics in sequence generation. During sharp-wave ripple (SWR) events, hippocampal neurons express sequenced reactivations, which we show are composed of discrete attractors. Each attractor corresponds to a single location, the representation of which sharpens over the course of several milliseconds, as the reactivation focuses at that location. Subsequently, the reactivation transitions rapidly to a spatially discontiguous location. This alternation between sharpening and transition occurs repeatedly within individual SWRs and is locked to the slow-gamma (25 to 50 hertz) rhythm. These findings support theoretical notions of neural network function and reveal a fundamental discretization in the retrieval of memory in the hippocampus, together with a function for gamma oscillations in the control of attractor dynamics.},
	number = {6244},
	journal = {Science},
	author = {Pfeiffer, Brad E and Foster, David J},
	month = jul,
	year = {2015},
	keywords = {merged\_fiete.bib},
	pages = {180--183},
}

@article{maboudi_uncovering_2018,
	title = {Uncovering temporal structure in hippocampal output patterns},
	volume = {7},
	abstract = {Place cell activity of hippocampal pyramidal cells has been described as the cognitive substrate of spatial memory. Replay is observed during hippocampal sharp-wave-ripple-associated population burst events (PBEs) and is critical for consolidation and recall-guided behaviors. PBE activity has historically been analyzed as a phenomenon subordinate to the place code. Here, we use hidden Markov models to study PBEs observed in rats during exploration of both linear mazes and open fields. We demonstrate that estimated models are consistent with a spatial map of the environment, and can even decode animals' positions during behavior. Moreover, we demonstrate the model can be used to identify hippocampal replay without recourse to the place code, using only PBE model congruence. These results suggest that downstream regions may rely on PBEs to provide a substrate for memory. Additionally, by forming models independent of animal behavior, we lay the groundwork for studies of non-spatial memory.},
	journal = {Elife},
	author = {Maboudi, Kourosh and Ackermann, Etienne and de Jong, Laurel Watkins and Pfeiffer, Brad E and Foster, David and Diba, Kamran and Kemere, Caleb},
	year = {2018},
	keywords = {hippocampus, merged\_fiete.bib, neuroscience, rat, sharp wave ripples, hidden Markov models, replay},
}

@article{bogacz_basal_2007,
	title = {The basal ganglia and cortex implement optimal decision making between alternative actions},
	volume = {19},
	abstract = {Neurophysiological studies have identified a number of brain regions critically involved in solving the problem of action selection or decision making. In the case of highly practiced tasks, these regions include cortical areas hypothesized to integrate evidence supporting alternative actions and the basal ganglia, hypothesized to act as a central switch in gating behavioral requests. However, despite our relatively detailed knowledge of basal ganglia biology and its connectivity with the cortex and numerical simulation studies demonstrating selective function, no formal theoretical framework exists that supplies an algorithmic description of these circuits. This article shows how many aspects of the anatomy and physiology of the circuit involving the cortex and basal ganglia are exactly those required to implement the computation defined by an asymptotically optimal statistical test for decision making: the multihypothesis sequential probability ratio test (MSPRT). The resulting model of basal ganglia provides a new framework for understanding the computation in the basal ganglia during decision making in highly practiced tasks. The predictions of the theory concerning the properties of particular neuronal populations are validated in existing experimental data. Further, we show that this neurobiologically grounded implementation of MSPRT outperforms other candidates for neural decision making, that it is structurally and parametrically robust, and that it can accommodate cortical mechanisms for decision making in a way that complements those in basal ganglia.},
	number = {2},
	journal = {Neural Comput.},
	author = {Bogacz, Rafal and Gurney, Kevin},
	month = feb,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {442--477},
}

@article{agmon_theory_2020,
	title = {A theory of joint attractor dynamics in the hippocampus and the entorhinal cortex accounts for artificial remapping and grid cell field-to-field variability},
	volume = {9},
	abstract = {The representation of position in the mammalian brain is distributed across multiple neural populations. Grid cell modules in the medial entorhinal cortex (MEC) express activity patterns that span a low-dimensional manifold which remains stable across different environments. In contrast, the activity patterns of hippocampal place cells span distinct low-dimensional manifolds in different environments. It is unknown how these multiple representations of position are coordinated. Here, we develop a theory of joint attractor dynamics in the hippocampus and the MEC. We show that the system exhibits a coordinated, joint representation of position across multiple environments, consistent with global remapping in place cells and grid cells. In addition, our model accounts for recent experimental observations that lack a mechanistic explanation: variability in the firing rate of single grid cells across firing fields, and artificial remapping of place cells under depolarization, but not under hyperpolarization, of layer II stellate cells of the MEC.},
	journal = {Elife},
	author = {Agmon, Haggai and Burak, Yoram},
	year = {2020},
	keywords = {entorhinal cortex, merged\_fiete.bib, spatial memory, neuroscience, rat, theoretical neuroscience, mouse, attractor networks, computational neuroscience, hippcampus},
}

@article{ziv_long-term_2013,
	title = {Long-term dynamics of {CA1} hippocampal place codes},
	volume = {16},
	abstract = {Using Ca imaging in freely behaving mice that repeatedly explored a familiar environment, we tracked thousands of CA1 pyramidal cells' place fields over weeks. Place coding was dynamic, as each day the ensemble representation of this environment involved a unique subset of cells. However, cells in the ∼15-25\% overlap between any two of these subsets retained the same place fields, which sufficed to preserve an accurate spatial representation across weeks.},
	number = {3},
	journal = {Nat. Neurosci.},
	author = {Ziv, Yaniv and Burns, Laurie D and Cocker, Eric D and Hamel, Elizabeth O and Ghosh, Kunal K and Kitch, Lacey J and El Gamal, Abbas and Schnitzer, Mark J},
	month = mar,
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {264--266},
}

@article{attardo_long-term_2018,
	title = {Long-{Term} {Consolidation} of {Ensemble} {Neural} {Plasticity} {Patterns} in {Hippocampal} {Area} {CA1}},
	volume = {25},
	abstract = {Neural network remodeling underpins the ability to remember life experiences, but little is known about the long-term plasticity of neural populations. To study how the brain encodes episodic events, we used time-lapse two-photon microscopy and a fluorescent reporter of neural plasticity based on an enhanced form of the synaptic activity-responsive element (E-SARE) within the Arc promoter to track thousands of CA1 hippocampal pyramidal cells over weeks in mice that repeatedly encountered different environments. Each environment evokes characteristic patterns of ensemble neural plasticity, but with each encounter, the set of activated cells gradually evolves. After repeated exposures, the plasticity patterns evoked by an individual environment progressively stabilize. Compared with young adults, plasticity patterns in aged mice are less specific to individual environments and less stable across repeat experiences. Long-term consolidation of hippocampal plasticity patterns may support long-term memory formation, whereas weaker consolidation in aged subjects might reflect declining memory function.},
	number = {3},
	journal = {Cell Rep.},
	author = {Attardo, Alessio and Lu, Ju and Kawashima, Takashi and Okuno, Hiroyuki and Fitzgerald, James E and Bito, Haruhiko and Schnitzer, Mark J},
	year = {2018},
	keywords = {hippocampus, merged\_fiete.bib, plasticity, aging, immediate-early genes, representations, two-photon imaging},
	pages = {640--650.e2},
}

@article{witter_anatomical_2000,
	title = {Anatomical organization of the parahippocampal-hippocampal network},
	volume = {911},
	abstract = {The anatomical organization of the parahippocampal-hippocampal network indicates that it consists of different parallel circuits. Considering the topographical distribution of sensory cortical inputs, the hypothesis is that the major parallel circuits carry functionally different information. These functionally different parallel routes reach different portions of the hippocampal network along the longitudinal axis of all fields as well as along the perpendicularly oriented transverse axis of CA1 and the subiculum. In the remaining fields of the hippocampal formation, that is, the dentate gyrus and CA2/CA3, separation along the transverse axis is not present. By contrast, here the functionally different pathways converge onto the same neuronal population. The entorhinal cortex holds a pivotal position among the cortices that make up the parahippocampal region. By way of the networks of the superficial and deep layers, it mediates, respectively, the input and output streams of the hippocampal formation. Moreover, the intrinsic entorhinal network, particularly the interconnections between the deep and superficial layers, may mediate the comparison of hippocampal input and output signals. As such, the entorhinal cortex may form part of a novelty detection network. In addition, the organization of the entorhinal-hippocampal network may facilitate the holding of information. Finally, the terminal organization of the presubicular input to the medial entorhinal cortex indicates that the interactions between the deep and superficial entorhinal layers may be influenced by this input.},
	journal = {Ann. N. Y. Acad. Sci.},
	author = {Witter, M P and Wouterlood, F G and Naber, P A and Van Haeften, T},
	month = jun,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1--24},
}

@article{steward_cells_1976,
	title = {Cells of origin of entorhinal cortical afferents to the hippocampus and fascia dentata of the rat},
	volume = {169},
	abstract = {The pathway from the entorhinal cortical region to the hippocampal formation has previously been shown to be comprised of two sub-systems, one of which projects predominantly to the ipsilateral fascia dentata and regio inferior of the hippocampus proper, and a second which projects bilaterally to regio superior. The goal of the present investigation was to determine if these two pathways might originate from different cell populations within the entorhinal area. The cells of origin of these entorhinal pathways were identified by retrograde labeling with horseradish peroxidase (HRP). Injections which labeled the entorhinal terminal fields in both the fascia dentata and regio superior resulted in the retrograde labeling of two populations of cells in the entorhinal area. Ipsilateral to the injection, HRP reaction product was found in the cells of layer II (predominantly stellate cells) and the cells of layer III (predominantly pyramidal cells). Contralateral to the injections, however, the reaction product was found almost exclusively in the cells of layer III. With selective injections of the entorhinal terminal field in regio superior, only the cells of layer III were labeled, but these were labeled bilaterally. Selective injection of the entorhinal terminal field in the fascia dentata, however, resulted in the labeling of cells of layer II, but not of layer III, and these cells of layer II were labeled almost exclusively ipsilaterally. A very small number of labeled cells in layer II were, however, found contralateral to the injection as well. No labeled cells were found either in the presubiculum or parasubiculum following injections of the hippocampal formation. These cell populations were found capable of retrograde transport of HRP, however, since cells in both presubiculum and parasubiculum were labeled following HRP injections into the contralateral entorhinal area. These results suggest that the projections to the fascia dentata originate from the cells of layer II, while the projections to regio superior originate from the cells of layer III of the entorhinal region proper. The very slight crossed projection from the entorhinal area to the contralateral area dentata probably originates from the small population of cells in layer II which are labeled following HRP injections in the contralateral area dentata.},
	number = {3},
	journal = {J. Comp. Neurol.},
	author = {Steward, O and Scoville, S A},
	month = oct,
	year = {1976},
	keywords = {merged\_fiete.bib},
	pages = {347--370},
}

@article{crauel_random_1997,
	title = {Random attractors},
	volume = {9},
	number = {2},
	journal = {J. Dynam. Differential Equations},
	author = {Crauel, H and Debussche, A and Flandoli, F},
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {57--72},
}

@article{suh_entorhinal_2011,
	title = {Entorhinal cortex layer {III} input to the hippocampus is crucial for temporal association memory},
	volume = {334},
	abstract = {Associating temporally discontinuous elements is crucial for the formation of episodic and working memories that depend on the hippocampal-entorhinal network. However, the neural circuits subserving these associations have remained unknown. The layer III inputs of the entorhinal cortex to the hippocampus may contribute to this process. To test this hypothesis, we generated a transgenic mouse in which these inputs are specifically inhibited. The mutant mice displayed significant impairments in spatial working-memory tasks and in the encoding phase of trace fear-conditioning. These results indicate a critical role of the entorhinal cortex layer III inputs to the hippocampus in temporal association memory.},
	number = {6061},
	journal = {Science},
	author = {Suh, Junghyup and Rivest, Alexander J and Nakashiba, Toshiaki and Tominaga, Takashi and Tonegawa, Susumu},
	month = dec,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {1415--1420},
}

@article{witter_entorhinal_1991,
	title = {Entorhinal cortex of the monkey: {V}. {Projections} to the dentate gyrus, hippocampus, and subicular complex},
	volume = {307},
	abstract = {The topographic and laminar organization of entorhinal projections to the dentate gyrus, hippocampus, and subicular complex was investigated in the Macaca fascicularis monkey. Injections of 3H-amino acids were placed at various positions within the entorhinal cortex and the distribution of anterogradely labeled fibers and terminals within the other fields of the hippocampal formation was determined. Injections of the retrograde tracers Fast blue, Diamidino yellow, and wheat germ agglutinin-horseradish peroxidase (WGA-HRP) were also placed into the dentate gyrus, hippocampus, and subicular complex, and the distribution of retrogradely labeled cells in the entorhinal cortex was plotted using a computer-aided digitizing system. The entorhinal cortex gave rise to projections that terminated in the subiculum, in the CA1, CA2, and CA3 fields of the hippocampus, and in the dentate gyrus. Projections to the dentate gyrus, and fields CA3 and CA2 of the hippocampus, originated preferentially in layers II and VI of the entorhinal cortex whereas projections to CA1 and to the subiculum originated mainly in layers III and V. Anterograde tracing experiments demonstrated that all regions of the entorhinal cortex project to the outer two-thirds of the molecular layer of the dentate gyrus and to much of the radial extent of the stratum lacunosum-moleculare of CA3 and CA2. While the terminal distributions of entorhinal projections to the dentate gyrus, CA3, and CA2 were not as clearly laminated as in the rat, projections from rostral levels of the entorhinal cortex preferentially innervated the outer portion of the molecular layer and stratum lacunosum-moleculare, whereas more caudal levels of the entorhinal cortex projected relatively more heavily to the deeper portions of the entorhinal terminal zones. The entorhinal projection to the CA1 field of the hippocampus and to the subiculum followed a transverse rather than radial gradient of distribution. Rostral levels of the entorhinal cortex terminated most heavily at the border of CA1 and the subiculum. More caudal levels of the entorhinal cortex projected to progressively more distal portions of the subiculum (towards the presubiculum) and more proximal portions of CA1 (towards CA2). Lateral portions of the entorhinal cortex projected to caudal levels of the recipient fields and more medial parts of the entorhinal cortex projected to progressively more rostral portions of the fields.},
	number = {3},
	journal = {J. Comp. Neurol.},
	author = {Witter, M P and Amaral, D G},
	month = may,
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {437--459},
}

@article{amaral_emerging_1993,
	title = {Emerging principles of intrinsic hippocampal organization},
	volume = {3},
	abstract = {The hippocampal formation has a unique and highly distributed network of intrinsic connections. What are the principles of organization that govern information flow through this system? The notion that information processing in the hippocampal formation is segregated in autonomous chips or lamellae appears to be inconsistent with the extremely divergent nature of many of the intrinsic connections. Recent neuroanatomical data suggest, however, that information may be segregated in other ways as it negotiates the links from one hippocampal region to the next.},
	number = {2},
	journal = {Curr. Opin. Neurobiol.},
	author = {Amaral, D G},
	month = apr,
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {225--229},
}

@article{monaco_modular_2011,
	title = {Modular realignment of entorhinal grid cell activity as a basis for hippocampal remapping},
	volume = {31},
	abstract = {Hippocampal place fields, the local regions of activity recorded from place cells in exploring rodents, can undergo large changes in relative location during remapping. This process would appear to require some form of modulated global input. Grid-cell responses recorded from layer II of medial entorhinal cortex in rats have been observed to realign concurrently with hippocampal remapping, making them a candidate input source. However, this realignment occurs coherently across colocalized ensembles of grid cells (Fyhn et al., 2007). The hypothesized entorhinal contribution to remapping depends on whether this coherence extends to all grid cells, which is currently unknown. We study whether dividing grid cells into small numbers of independently realigning modules can both account for this localized coherence and allow for hippocampal remapping. To do this, we construct a model in which place-cell responses arise from network competition mediated by global inhibition. We show that these simulated responses approximate the sparsity and spatial specificity of hippocampal activity while fully representing a virtual environment without learning. Place-field locations and the set of active place cells in one environment can be independently rearranged by changes to the underlying grid-cell inputs. We introduce new measures of remapping to assess the effectiveness of grid-cell modularity and to compare shift realignments with other geometric transformations of grid-cell responses. Complete hippocampal remapping is possible with a small number of shifting grid modules, indicating that entorhinal realignment may be able to generate place-field randomization despite substantial coherence.},
	number = {25},
	journal = {J. Neurosci.},
	author = {Monaco, Joseph D and Abbott, L F and Abbott, Larry F},
	month = jun,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {9414--9425},
}

@article{lee_statistical_2020-1,
	title = {The {Statistical} {Structure} of the {Hippocampal} {Code} for {Space} as a {Function} of {Time}, {Context}, and {Value}},
	volume = {183},
	abstract = {Hippocampal activity represents many behaviorally important variables, including context, an animal's location within a given environmental context, time, and reward. Using longitudinal calcium imaging in mice, multiple large virtual environments, and differing reward contingencies, we derived a unified probabilistic model of CA1 representations centered on a single feature-the field propensity. Each cell's propensity governs how many place fields it has per unit space, predicts its reward-related activity, and is preserved across distinct environments and over months. Propensity is broadly distributed-with many low, and some very high, propensity cells-and thus strongly shapes hippocampal representations. This results in a range of spatial codes, from sparse to dense. Propensity varied ∼10-fold between adjacent cells in salt-and-pepper fashion, indicating substantial functional differences within a presumed cell type. Intracellular recordings linked propensity to cell excitability. The stability of each cell's propensity across conditions suggests this fundamental property has anatomical, transcriptional, and/or developmental origins.},
	number = {3},
	journal = {Cell},
	author = {Lee, Jae Sung and Briguglio, John J and Cohen, Jeremy D and Romani, Sandro and Lee, Albert K},
	month = oct,
	year = {2020},
	keywords = {hippocampus, merged\_fiete.bib, memory, calcium imaging, excitability, gain modulation, intracellular recording, place cell, place field, propensity, sparse coding},
	pages = {620--635.e22},
}

@article{whittington_tolman-eichenbaum_2020,
	title = {The {Tolman}-{Eichenbaum} {Machine}: {Unifying} {Space} and {Relational} {Memory} through {Generalization} in the {Hippocampal} {Formation}},
	volume = {183},
	abstract = {The hippocampal-entorhinal system is important for spatial and relational memory tasks. We formally link these domains, provide a mechanistic understanding of the hippocampal role in generalization, and offer unifying principles underlying many entorhinal and hippocampal cell types. We propose medial entorhinal cells form a basis describing structural knowledge, and hippocampal cells link this basis with sensory representations. Adopting these principles, we introduce the Tolman-Eichenbaum machine (TEM). After learning, TEM entorhinal cells display diverse properties resembling apparently bespoke spatial responses, such as grid, band, border, and object-vector cells. TEM hippocampal cells include place and landmark cells that remap between environments. Crucially, TEM also aligns with empirically recorded representations in complex non-spatial tasks. TEM also generates predictions that hippocampal remapping is not random as previously believed; rather, structural knowledge is preserved across environments. We confirm this structural transfer over remapping in simultaneously recorded place and grid cells.},
	number = {5},
	journal = {Cell},
	author = {Whittington, James C R and Muller, Timothy H and Mark, Shirley and Chen, Guifen and Barry, Caswell and Burgess, Neil and Behrens, Timothy E J},
	month = nov,
	year = {2020},
	keywords = {generalization, neural networks, entorhinal cortex, grid cells, hippocampus, non-spatial reasoning, place cells, representation learning, merged\_fiete.bib},
	pages = {1249--1263.e23},
}

@article{sanders_hippocampal_2020,
	title = {Hippocampal remapping as hidden state inference},
	volume = {9},
	abstract = {Cells in the hippocampus tuned to spatial location (place cells) typically change their tuning when an animal changes context, a phenomenon known as remapping. A fundamental challenge to understanding remapping is the fact that what counts as a ”context change” has never been precisely defined. Furthermore, different remapping phenomena have been classified on the basis of how much the tuning changes after different types and degrees of context change, but the relationship between these variables is not clear. We address these ambiguities by formalizing remapping in terms of hidden state inference. According to this view, remapping does not directly reflect objective, observable properties of the environment, but rather subjective beliefs about the hidden state of the environment. We show how the hidden state framework can resolve a number of puzzles about the nature of remapping.},
	journal = {Elife},
	author = {Sanders, Honi and Wilson, Matthew A and Gershman, Samuel J},
	year = {2020},
	keywords = {hippocampus, merged\_fiete.bib, learning, neuroscience, place cell, none, bayesian inference, context, hidden state},
}

@article{alme_place_2014,
	title = {Place cells in the hippocampus: eleven maps for eleven rooms},
	volume = {111},
	abstract = {The contribution of hippocampal circuits to high-capacity episodic memory is often attributed to the large number of orthogonal activity patterns that may be stored in these networks. Evidence for high-capacity storage in the hippocampus is missing, however. When animals are tested in pairs of environments, different combinations of place cells are recruited, consistent with the notion of independent representations. However, the extent to which representations remain independent across larger numbers of environments has not been determined. To investigate whether spatial firing patterns recur when animals are exposed to multiple environments, we tested rats in 11 recording boxes, each in a different room, allowing for 55 comparisons of place maps in each animal. In each environment, activity was recorded from neuronal ensembles in hippocampal area CA3, with an average of 30 active cells per animal. Representations were highly correlated between repeated tests in the same room but remained orthogonal across all combinations of different rooms, with minimal overlap in the active cell samples from each environment. A low proportion of cells had activity in many rooms but the firing locations of these cells were completely uncorrelated. Taken together, the results suggest that the number of independent spatial representations stored in hippocampal area CA3 is large, with minimal recurrence of spatial firing patterns across environments.},
	number = {52},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Alme, Charlotte B and Miao, Chenglin and Jezek, Karel and Treves, Alessandro and Moser, Edvard I and Moser, May-Britt},
	month = dec,
	year = {2014},
	keywords = {hippocampus, place cells, merged\_fiete.bib, memory, space},
	pages = {18428--18435},
}

@article{vogels_gating_2009,
	title = {Gating multiple signals through detailed balance of excitation and inhibition in spiking networks},
	volume = {12},
	abstract = {Recent theoretical work has provided a basic understanding of signal propagation in networks of spiking neurons, but mechanisms for gating and controlling these signals have not been investigated previously. Here we introduce an idea for the gating of multiple signals in cortical networks that combines principles of signal propagation with aspects of balanced networks. Specifically, we studied networks in which incoming excitatory signals are normally cancelled by locally evoked inhibition, leaving the targeted layer unresponsive. Transmission can be gated 'on' by modulating excitatory and inhibitory gains to upset this detailed balance. We illustrate gating through detailed balance in large networks of integrate-and-fire neurons. We show successful gating of multiple signals and study failure modes that produce effects reminiscent of clinically observed pathologies. Provided that the individual signals are detectable, detailed balance has a large capacity for gating multiple signals.},
	number = {4},
	journal = {Nat. Neurosci.},
	author = {Vogels, Tim P and Abbott, L F},
	month = apr,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {483--491},
}

@article{park_map_2020,
	title = {Map {Making}: {Constructing}, {Combining}, and {Inferring} on {Abstract} {Cognitive} {Maps}},
	abstract = {Cognitive maps enable efficient inferences from limited experience that can guide novel decisions. We tested whether the hippocampus (HC), entorhinal cortex (EC), and ventromedial prefrontal cortex (vmPFC)/medial orbitofrontal cortex (mOFC) organize abstract and discrete relational information into a cognitive map to guide novel inferences. Subjects learned the status of people in two unseen 2D social hierarchies, with each dimension learned on a separate day. Although one dimension was behaviorally relevant, multivariate activity patterns in HC, EC, and vmPFC/mOFC were linearly related to the Euclidean distance between people in the mentally reconstructed 2D space. Hubs created unique comparisons between the hierarchies, enabling inferences between novel pairs. We found that both behavior and neural activity in EC and vmPFC/mOFC reflected the Euclidean distance to the retrieved hub, which was reinstated in HC. These findings reveal how abstract and discrete relational structures are represented, are combined, and enable novel inferences in the human brain.},
	journal = {Neuron},
	author = {Park, Seongmin A and Miller, Douglas S and Nili, Hamed and Ranganath, Charan and Boorman, Erie D},
	month = jul,
	year = {2020},
	keywords = {Hippocampus, merged\_fiete.bib, Entorhinal cortex, 2D space, Cognitive map, Euclidean, Generalization, Inference, Model based, Orbitofrontal cortex, Social network},
}

@article{pillow_spatio-temporal_2008,
	title = {Spatio-temporal correlations and visual signalling in a complete neuronal population},
	volume = {454},
	abstract = {Statistical dependencies in the responses of sensory neurons govern both the amount of stimulus information conveyed and the means by which downstream neurons can extract it. Although a variety of measurements indicate the existence of such dependencies, their origin and importance for neural coding are poorly understood. Here we analyse the functional significance of correlated firing in a complete population of macaque parasol retinal ganglion cells using a model of multi-neuron spike responses. The model, with parameters fit directly to physiological data, simultaneously captures both the stimulus dependence and detailed spatio-temporal correlations in population responses, and provides two insights into the structure of the neural code. First, neural encoding at the population level is less noisy than one would expect from the variability of individual neurons: spike times are more precise, and can be predicted more accurately when the spiking of neighbouring neurons is taken into account. Second, correlations provide additional sensory information: optimal, model-based decoding that exploits the response correlation structure extracts 20\% more information about the visual scene than decoding under the assumption of independence, and preserves 40\% more visual information than optimal linear decoding. This model-based approach reveals the role of correlated activity in the retinal coding of visual stimuli, and provides a general framework for understanding the importance of correlated activity in populations of neurons.},
	number = {7207},
	journal = {Nature},
	author = {Pillow, Jonathan W and Shlens, Jonathon and Paninski, Liam and Sher, Alexander and Litke, Alan M and Chichilnisky, E J and Simoncelli, Eero P},
	month = aug,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {995--999},
}

@article{metz_meta-learning_2019,
	title = {Meta-learning update rules for unsupervised representation learning},
	journal = {ICLR},
	author = {Metz, L and Maheswaranathan, N and Cheung, B and Sohl-Dickstein, J},
	year = {2019},
	keywords = {merged\_fiete.bib},
}

@article{finn_online_2019,
	title = {Online {Meta}-learning},
	volume = {97},
	journal = {J. Mach. Learn. Res.},
	author = {Finn, C and Rajeswaran, A and Kakade, A and Levine, S},
	year = {2019},
	keywords = {merged\_fiete.bib},
}

@article{mccloskey_catastrophic_1989,
	title = {Catastrophic interference in connectionist networks: {The} sequential learning problem},
	journal = {In: The Psychology of Learning and Motivation (G. H. Bower, ed. )},
	author = {McCloskey, M and Cohen, N},
	year = {1989},
	keywords = {merged\_fiete.bib},
}

@article{ratcliff_connectionist_1990,
	title = {Connectionist models of recognition memory: constraints imposed by learning and forgetting functions},
	volume = {97},
	abstract = {Multilayer connectionist models of memory based on the encoder model using the backpropagation learning rule are evaluated. The models are applied to standard recognition memory procedures in which items are studied sequentially and then tested for retention. Sequential learning in these models leads to 2 major problems. First, well-learned information is forgotten rapidly as new information is learned. Second, discrimination between studied items and new items either decreases or is nonmonotonic as a function of learning. To address these problems, manipulations of the network within the multilayer model and several variants of the multilayer model were examined, including a model with prelearned memory and a context model, but none solved the problems. The problems discussed provide limitations on connectionist models applied to human memory and in tasks where information to be learned is not all available during learning.},
	number = {2},
	journal = {Psychol. Rev.},
	author = {Ratcliff, R},
	month = apr,
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {285--308},
}

@article{nguyen_whole-brain_2016,
	title = {Whole-brain calcium imaging with cellular resolution in freely behaving {Caenorhabditis} elegans},
	volume = {113},
	abstract = {The ability to acquire large-scale recordings of neuronal activity in awake and unrestrained animals is needed to provide new insights into how populations of neurons generate animal behavior. We present an instrument capable of recording intracellular calcium transients from the majority of neurons in the head of a freely behaving Caenorhabditis elegans with cellular resolution while simultaneously recording the animal's position, posture, and locomotion. This instrument provides whole-brain imaging with cellular resolution in an unrestrained and behaving animal. We use spinning-disk confocal microscopy to capture 3D volumetric fluorescent images of neurons expressing the calcium indicator GCaMP6s at 6 head-volumes/s. A suite of three cameras monitor neuronal fluorescence and the animal's position and orientation. Custom software tracks the 3D position of the animal's head in real time and two feedback loops adjust a motorized stage and objective to keep the animal's head within the field of view as the animal roams freely. We observe calcium transients from up to 77 neurons for over 4 min and correlate this activity with the animal's behavior. We characterize noise in the system due to animal motion and show that, across worms, multiple neurons show significant correlations with modes of behavior corresponding to forward, backward, and turning locomotion.},
	number = {8},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Nguyen, Jeffrey P and Shipley, Frederick B and Linder, Ashley N and Plummer, George S and Liu, Mochi and Setru, Sagar U and Shaevitz, Joshua W and Leifer, Andrew M},
	month = feb,
	year = {2016},
	keywords = {merged\_fiete.bib, calcium imaging, behavior, C. elegans, large-scale recording, microscopy},
	pages = {E1074--81},
}

@article{litwin-kumar_slow_2012,
	title = {Slow dynamics and high variability in balanced cortical networks with clustered connections},
	volume = {15},
	abstract = {Anatomical studies demonstrate that excitatory connections in cortex are not uniformly distributed across a network but instead exhibit clustering into groups of highly connected neurons. The implications of clustering for cortical activity are unclear. We studied the effect of clustered excitatory connections on the dynamics of neuronal networks that exhibited high spike time variability owing to a balance between excitation and inhibition. Even modest clustering substantially changed the behavior of these networks, introducing slow dynamics during which clusters of neurons transiently increased or decreased their firing rate. Consequently, neurons exhibited both fast spiking variability and slow firing rate fluctuations. A simplified model shows how stimuli bias networks toward particular activity states, thereby reducing firing rate variability as observed experimentally in many cortical areas. Our model thus relates cortical architecture to the reported variability in spontaneous and evoked spiking activity.},
	number = {11},
	journal = {Nat. Neurosci.},
	author = {Litwin-Kumar, Ashok and Doiron, Brent},
	month = nov,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {1498--1505},
}

@article{babichev_topological_2016,
	title = {A {Topological} {Model} of the {Hippocampal} {Cell} {Assembly} {Network}},
	volume = {10},
	abstract = {It is widely accepted that the hippocampal place cells' spiking activity produces a cognitive map of space. However, many details of this representation's physiological mechanism remain unknown. For example, it is believed that the place cells exhibiting frequent coactivity form functionally interconnected groups-place cell assemblies-that drive readout neurons in the downstream networks. However, the sheer number of coactive combinations is extremely large, which implies that only a small fraction of them actually gives rise to cell assemblies. The physiological processes responsible for selecting the winning combinations are highly complex and are usually modeled via detailed synaptic and structural plasticity mechanisms. Here we propose an alternative approach that allows modeling the cell assembly network directly, based on a small number of phenomenological selection rules. We then demonstrate that the selected population of place cell assemblies correctly encodes the topology of the environment in biologically plausible time, and may serve as a schematic model of the hippocampal network.},
	journal = {Front. Comput. Neurosci.},
	author = {Babichev, Andrey and Ji, Daoyun and Mémoli, Facundo and Dabaghian, Yuri A},
	year = {2016},
	keywords = {hippocampus, place cells, merged\_fiete.bib, topology, cell assemblies, cognitive map},
	pages = {50},
}

@article{edvardsen_navigating_2020,
	title = {Navigating with grid and place cells in cluttered environments},
	volume = {30},
	abstract = {Hippocampal formation contains several classes of neurons thought to be involved in navigational processes, in particular place cells and grid cells. Place cells have been associated with a topological strategy for navigation, while grid cells have been suggested to support metric vector navigation. Grid cell-based vector navigation can support novel shortcuts across unexplored territory by providing the direction toward the goal. However, this strategy is insufficient in natural environments cluttered with obstacles. Here, we show how navigation in complex environments can be supported by integrating a grid cell-based vector navigation mechanism with local obstacle avoidance mediated by border cells and place cells whose interconnections form an experience-dependent topological graph of the environment. When vector navigation and object avoidance fail (i.e., the agent gets stuck), place cell replay events set closer subgoals for vector navigation. We demonstrate that this combined navigation model can successfully traverse environments cluttered by obstacles and is particularly useful where the environment is underexplored. Finally, we show that the model enables the simulated agent to successfully navigate experimental maze environments from the animal literature on cognitive mapping. The proposed model is sufficiently flexible to support navigation in different environments, and may inform the design of experiments to relate different navigational abilities to place, grid, and border cell firing.},
	number = {3},
	journal = {Hippocampus},
	author = {Edvardsen, Vegard and Bicanski, Andrej and Burgess, Neil},
	month = mar,
	year = {2020},
	keywords = {entorhinal cortex, grid cells, hippocampus, place cells, merged\_fiete.bib, spatial navigation},
	pages = {220--232},
}

@article{khona_attractor_2020,
	title = {Attractor and integrator networks in the brain},
	volume = {(in review)},
	journal = {Nat. Rev. Neurosci.},
	author = {Khona, M and Fiete, I R},
	year = {2020},
	keywords = {merged\_fiete.bib},
}

@article{eichenbaum_prefrontal-hippocampal_2017,
	title = {Prefrontal-hippocampal interactions in episodic memory},
	volume = {18},
	abstract = {The roles of the hippocampus and prefrontal cortex (PFC) in memory processing - individually or in concert - are a major topic of interest in memory research. These brain areas have distinct and complementary roles in episodic memory, and their interactions are crucial for learning and remembering events. Considerable evidence indicates that the PFC and hippocampus become coupled via oscillatory synchrony that reflects bidirectional flow of information. Furthermore, newer studies have revealed specific mechanisms whereby neural representations in the PFC and hippocampus are mediated through direct connections or through intermediary regions. These findings suggest a model of how the hippocampus and PFC, along with their intermediaries, operate as a system that uses the current context of experience to retrieve relevant memories.},
	number = {9},
	journal = {Nat. Rev. Neurosci.},
	author = {Eichenbaum, Howard},
	month = sep,
	year = {2017},
	keywords = {merged\_fiete.bib},
	pages = {547--558},
}

@article{preston_interplay_2013,
	title = {Interplay of hippocampus and prefrontal cortex in memory},
	volume = {23},
	abstract = {Recent studies on the hippocampus and the prefrontal cortex have considerably advanced our understanding of the distinct roles of these brain areas in the encoding and retrieval of memories, and of how they interact in the prolonged process by which new memories are consolidated into our permanent storehouse of knowledge. These studies have led to a new model of how the hippocampus forms and replays memories and how the prefrontal cortex engages representations of the meaningful contexts in which related memories occur, as well as how these areas interact during memory retrieval. Furthermore, they have provided new insights into how interactions between the hippocampus and prefrontal cortex support the assimilation of new memories into pre-existing networks of knowledge, called schemas, and how schemas are modified in this process as the foundation of memory consolidation.},
	number = {17},
	journal = {Curr. Biol.},
	author = {Preston, Alison R and Eichenbaum, Howard},
	month = sep,
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {R764--73},
}

@article{godsil_hippocampal-prefrontal_2013,
	title = {The hippocampal-prefrontal pathway: the weak link in psychiatric disorders?},
	volume = {23},
	abstract = {While the hippocampal formation and the prefrontal cortex each have a well-established role in cognitive and mnemonic processes, the extent and manner in which these structures interact to achieve these functions has not been fully delineated. Recent research in rodents compellingly supports the idea that the projection of neurons extending from the CA1 region of the hippocampus and from the subiculum to the prefrontal cortex, referred to here as the H-PFC pathway, is critically involved in aspects of cognition related to executive function and to emotional regulation. Concurrently, it is becoming evident that persons suffering from schizophrenia, depression, and post-traumatic stress disorder display structural anomalies and aberrant functional coupling within the hippocampal-prefrontal circuit. Considering that these disorders involve varying degrees of cognitive impairment and emotional dysregulation, dysfunction in the H-PFC pathway might therefore be the common element of their pathophysiology. This overlap might also be intertwined with the pathway's evident susceptibility to stress and with its relationship to the amygdala. In consequence, the H-PFC pathway is a potentially crucial element of the pathophysiology of several psychiatric diseases, and it offers a specific target for therapeutic intervention, which is consistent with the recent emphasis on reframing psychiatric diseases in terms of brain circuits.},
	number = {10},
	journal = {Eur. Neuropsychopharmacol.},
	author = {Godsil, Bill P and Kiss, Janos P and Spedding, Michael and Jay, Thérèse M},
	month = oct,
	year = {2013},
	keywords = {Hippocampus, merged\_fiete.bib, Depression, Pathophysiology, Post-traumatic stress disorder, Prefrontal cortex, Schizophrenia},
	pages = {1165--1181},
}

@article{yang_task_2019,
	title = {Task representations in neural networks trained to perform many cognitive tasks},
	volume = {22},
	abstract = {The brain has the ability to flexibly perform many tasks, but the underlying mechanism cannot be elucidated in traditional experimental and modeling studies designed for one task at a time. Here, we trained single network models to perform 20 cognitive tasks that depend on working memory, decision making, categorization, and inhibitory control. We found that after training, recurrent units can develop into clusters that are functionally specialized for different cognitive processes, and we introduce a simple yet effective measure to quantify relationships between single-unit neural representations of tasks. Learning often gives rise to compositionality of task representations, a critical feature for cognitive flexibility, whereby one task can be performed by recombining instructions for other tasks. Finally, networks developed mixed task selectivity similar to recorded prefrontal neurons after learning multiple tasks sequentially with a continual-learning technique. This work provides a computational platform to investigate neural representations of many cognitive tasks.},
	number = {2},
	journal = {Nat. Neurosci.},
	author = {Yang, Guangyu Robert and Joglekar, Madhura R and Song, H Francis and Newsome, William T and Wang, Xiao-Jing},
	year = {2019},
	keywords = {merged\_fiete.bib},
	pages = {297--306},
}

@article{buonomano_harnessing_2009,
	title = {Harnessing chaos in recurrent neural networks},
	volume = {63},
	abstract = {In this issue of Neuron, Sussillo and Abbott describe a new learning rule that helps harness the computational power of recurrent neural networks.},
	number = {4},
	journal = {Neuron},
	author = {Buonomano, Dean V},
	month = aug,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {423--425},
}

@article{sussillo_generating_2009,
	title = {Generating coherent patterns of activity from chaotic neural networks},
	volume = {63},
	abstract = {Neural circuits display complex activity patterns both spontaneously and when responding to a stimulus or generating a motor output. How are these two forms of activity related? We develop a procedure called FORCE learning for modifying synaptic strengths either external to or within a model neural network to change chaotic spontaneous activity into a wide variety of desired activity patterns. FORCE learning works even though the networks we train are spontaneously chaotic and we leave feedback loops intact and unclamped during learning. Using this approach, we construct networks that produce a wide variety of complex output patterns, input-output transformations that require memory, multiple outputs that can be switched by control inputs, and motor patterns matching human motion capture data. Our results reproduce data on premovement activity in motor and premotor cortex, and suggest that synaptic plasticity may be a more rapid and powerful modulator of network activity than generally appreciated.},
	number = {4},
	journal = {Neuron},
	author = {Sussillo, David and Abbott, L F},
	month = aug,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {544--557},
}

@article{depasquale_full-force_2018,
	title = {full-{FORCE}: {A} target-based method for training recurrent networks},
	volume = {13},
	abstract = {Trained recurrent networks are powerful tools for modeling dynamic neural computations. We present a target-based method for modifying the full connectivity matrix of a recurrent network to train it to perform tasks involving temporally complex input/output transformations. The method introduces a second network during training to provide suitable “target” dynamics useful for performing the task. Because it exploits the full recurrent connectivity, the method produces networks that perform tasks with fewer neurons and greater noise robustness than traditional least-squares (FORCE) approaches. In addition, we show how introducing additional input signals into the target-generating network, which act as task hints, greatly extends the range of tasks that can be learned and provides control over the complexity and nature of the dynamics of the trained, task-performing network.},
	number = {2},
	journal = {PLoS One},
	author = {DePasquale, Brian and Cueva, Christopher J and Rajan, Kanaka and Escola, G Sean and Abbott, L F},
	year = {2018},
	keywords = {merged\_fiete.bib},
	pages = {e0191527},
}

@article{flower_summed_1992,
	title = {Summed {Weight} {Neuron} {Perturbation}: {An} {O}({N}) {Improvement} {Over} {Weight} {Perturbation}},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Flower, B and Jabri, M},
	year = {1992},
	keywords = {merged\_fiete.bib},
}

@article{kanitscheider_training_2017,
	title = {Training recurrent networks to generate hypotheses about how the brain solves hard navigation problems},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Kanitscheider, I and Fiete, I R},
	year = {2017},
	keywords = {merged\_fiete.bib},
}

@article{schaeffer_reverse-engineering_2020,
	title = {Reverse-engineering {Recurrent} {Neural} {Network} solutions to a hierarchical inference task for mice},
	volume = {(in review)},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Schaeffer, R and Khona, M and Meshulam, L and Laboratory, The International Brain and Fiete, I R},
	year = {2020},
	keywords = {merged\_fiete.bib},
}

@article{kriener_robust_2020,
	title = {Robust parallel decision-making in neural circuits with nonlinear inhibition},
	volume = {(to appear)},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Kriener, B and Chaudhuri, R and Fiete, I R},
	year = {2020},
	keywords = {merged\_fiete.bib},
}

@article{gardner_correlation_2019,
	title = {Correlation structure of grid cells is preserved during sleep},
	volume = {22},
	abstract = {The network of grid cells in the medial entorhinal cortex (MEC) forms a fixed reference frame for mapping physical space. The mechanistic origin of the grid representation is unknown, but continuous attractor network models explain multiple fundamental features of grid cell activity. An untested prediction of these models is that the grid cell network should exhibit an activity correlation structure that transcends behavioral states. By recording from MEC cell ensembles during navigation and sleep, we found that spatial phase offsets of grid cells predict arousal-state-independent spike rate correlations. Similarly, state-invariant correlations between conjunctive grid-head direction and pure head direction cells were predicted by their head direction tuning offsets during awake behavior. Grid cells were only weakly correlated across grid modules, and module scale relationships disintegrated during slow-wave sleep, suggesting that grid modules function as independent attractor networks. Collectively, our observations imply that network states in MEC are expressed universally across brain and behavior states.},
	number = {4},
	journal = {Nat. Neurosci.},
	author = {Gardner, Richard J and Lu, Li and Wernle, Tanja and Moser, May-Britt and Moser, Edvard I},
	year = {2019},
	keywords = {merged\_fiete.bib},
	pages = {598--608},
}

@article{noauthor_correction_2017,
	title = {Correction for {Burak} and {Fiete}, {Fundamental} limits on persistent activity in networks of noisy neurons},
	volume = {114},
	number = {20},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	year = {2017},
	keywords = {merged\_fiete.bib},
	pages = {E4117},
}

@article{international_brain_laboratory_electronic_address_churchlandcshledu_international_2017,
	title = {An {International} {Laboratory} for {Systems} and {Computational} {Neuroscience}},
	volume = {96},
	abstract = {The neural basis of decision-making has been elusive and involves the coordinated activity of multiple brain structures. This NeuroView, by the International Brain Laboratory (IBL), discusses their efforts to develop a standardized mouse decision-making behavior, to make coordinated measurements of neural activity across the mouse brain, and to use theory and analyses to uncover the neural computations that support decision-making.},
	number = {6},
	journal = {Neuron},
	author = {{International Brain Laboratory. Electronic address: churchland@cshl.edu} and {International Brain Laboratory}},
	year = {2017},
	keywords = {merged\_fiete.bib},
	pages = {1213--1218},
}

@article{yoon_grid_2016,
	title = {Grid {Cell} {Responses} in {1D} {Environments} {Assessed} as {Slices} through a {2D} {Lattice}},
	volume = {89},
	abstract = {Grid cells, defined by their striking periodic spatial responses in open 2D arenas, appear to respond differently on 1D tracks: the multiple response fields are not periodically arranged, peak amplitudes vary across fields, and the mean spacing between fields is larger than in 2D environments. We ask whether such 1D responses are consistent with the system's 2D dynamics. Combining analytical and numerical methods, we show that the 1D responses of grid cells with stable 1D fields are consistent with a linear slice through a 2D triangular lattice. Further, the 1D responses of comodular cells are well described by parallel slices, and the offsets in the starting points of the 1D slices can predict the measured 2D relative spatial phase between the cells. From these results, we conclude that the 2D dynamics of these cells is preserved in 1D, suggesting a common computation during both types of navigation behavior.},
	number = {5},
	journal = {Neuron},
	author = {Yoon, K J and Lewallen, S and Kinkhabwala, A A and Tank, D W and Fiete, I R},
	month = mar,
	year = {2016},
	keywords = {merged\_fiete.bib},
	pages = {1086--1099},
}

@article{welinder_grid_2008-1,
	title = {Grid cells: the position code, neural network models of activity, and the problem of learning},
	volume = {18},
	abstract = {We review progress on the modeling and theoretical fronts in the quest to unravel the computational properties of the grid cell code and to explain the mechanisms underlying grid cell dynamics. The goals of the review are to outline a coherent framework for understanding the dynamics of grid cells and their representation of space; to critically present and draw contrasts between recurrent network models of grid cells based on continuous attractor dynamics and independent-neuron models based on temporal interference; and to suggest open questions for experiment and theory.},
	number = {12},
	journal = {Hippocampus},
	author = {Welinder, Peter E and Burak, Yoram and Fiete, Ila R},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {1283--1300},
}

@article{fiete_what_2008,
	title = {What grid cells convey about rat location},
	volume = {28},
	abstract = {We characterize the relationship between the simultaneously recorded quantities of rodent grid cell firing and the position of the rat. The formalization reveals various properties of grid cell activity when considered as a neural code for representing and updating estimates of the rat's location. We show that, although the spatially periodic response of grid cells appears wasteful, the code is fully combinatorial in capacity. The resulting range for unambiguous position representation is vastly greater than the approximately 1-10 m periods of individual lattices, allowing for unique high-resolution position specification over the behavioral foraging ranges of rats, with excess capacity that could be used for error correction. Next, we show that the merits of the grid cell code for position representation extend well beyond capacity and include arithmetic properties that facilitate position updating. We conclude by considering the numerous implications, for downstream readouts and experimental tests, of the properties of the grid cell code.},
	number = {27},
	journal = {J. Neurosci.},
	author = {Fiete, Ila R and Burak, Yoram and Brookings, Ted},
	month = jul,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {6858--6871},
}

@article{fiete_losing_2010,
	title = {Losing phase},
	volume = {66},
	abstract = {In this issue of Neuron, Remme and colleagues examine the biophysics of synchronization between oscillating dendrites and soma. Their findings suggest that oscillators will quickly phase-lock when weakly coupled. These findings are at odds with assumptions of an influential model of grid cell response generation and have implications for grid cell response mechanisms.},
	number = {3},
	journal = {Neuron},
	author = {Fiete, Ila R},
	month = may,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {331--334},
}

@article{sreenivasan_grid_2011,
	title = {Grid cells generate an analog error-correcting code for singularly precise neural computation},
	volume = {14},
	abstract = {Entorhinal grid cells in mammals fire as a function of animal location, with spatially periodic response patterns. This nonlocal periodic representation of location, a local variable, is unlike other neural codes. There is no theoretical explanation for why such a code should exist. We examined how accurately the grid code with noisy neurons allows an ideal observer to estimate location and found this code to be a previously unknown type of population code with unprecedented robustness to noise. In particular, the representational accuracy attained by grid cells over the coding range was in a qualitatively different class from what is possible with observed sensory and motor population codes. We found that a simple neural network can effectively correct the grid code. To the best of our knowledge, these results are the first demonstration that the brain contains, and may exploit, powerful error-correcting codes for analog variables.},
	number = {10},
	journal = {Nat. Neurosci.},
	author = {Sreenivasan, Sameet and Fiete, Ila},
	month = sep,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {1330--1337},
}

@article{widloski_model_2014,
	title = {A model of grid cell development through spatial exploration and spike time-dependent plasticity},
	volume = {83},
	abstract = {Grid cell responses develop gradually after eye opening, but little is known about the rules that govern this process. We present a biologically plausible model for the formation of a grid cell network. An asymmetric spike time-dependent plasticity rule acts upon an initially unstructured network of spiking neurons that receive inputs encoding animal velocity and location. Neurons develop an organized recurrent architecture based on the similarity of their inputs, interacting through inhibitory interneurons. The mature network can convert velocity inputs into estimates of animal location, showing that spatially periodic responses and the capacity of path integration can arise through synaptic plasticity, acting on inputs that display neither. The model provides numerous predictions about the necessity of spatial exploration for grid cell development, network topography, the maturation of velocity tuning and neural correlations, the abrupt transition to stable patterned responses, and possible mechanisms to set grid period across grid modules.},
	number = {2},
	journal = {Neuron},
	author = {Widloski, John and Fiete, Ila R},
	month = jul,
	year = {2014},
	keywords = {merged\_fiete.bib},
	pages = {481--495},
}

@article{chen_bias_2015,
	title = {Bias in {Human} {Path} {Integration} {Is} {Predicted} by {Properties} of {Grid} {Cells}},
	volume = {25},
	abstract = {Accurate wayfinding is essential to the survival of many animal species and requires the ability to maintain spatial orientation during locomotion. One of the ways that humans and other animals stay spatially oriented is through path integration, which operates by integrating self-motion cues over time, providing information about total displacement from a starting point. The neural substrate of path integration in mammals may exist in grid cells, which are found in dorsomedial entorhinal cortex and presubiculum and parasubiculum in rats. Grid cells have also been found in mice, bats, and monkeys, and signatures of grid cell activity have been observed in humans. We demonstrate that distance estimation by humans during path integration is sensitive to geometric deformations of a familiar environment and show that patterns of path integration error are predicted qualitatively by a model in which locations in the environment are represented in the brain as phases of arrays of grid cells with unique periods and decoded by the inverse mapping from phases to locations. The periods of these grid networks are assumed to expand and contract in response to expansions and contractions of a familiar environment. Biases in distance estimation occur when the periods of the encoding and decoding grids differ. Our findings explicate the way in which grid cells could function in human path integration.},
	number = {13},
	journal = {Curr. Biol.},
	author = {Chen, Xiaoli and He, Qiliang and Kelly, Jonathan W and Fiete, Ila R and McNamara, Timothy P},
	month = jun,
	year = {2015},
	keywords = {merged\_fiete.bib},
	pages = {1771--1776},
}

@article{chaudhuri_computational_2016,
	title = {Computational principles of memory},
	volume = {19},
	abstract = {The ability to store and later use information is essential for a variety of adaptive behaviors, including integration, learning, generalization, prediction and inference. In this Review, we survey theoretical principles that can allow the brain to construct persistent states for memory. We identify requirements that a memory system must satisfy and analyze existing models and hypothesized biological substrates in light of these requirements. We also highlight open questions, theoretical puzzles and problems shared with computer science and information theory.},
	number = {3},
	journal = {Nat. Neurosci.},
	author = {Chaudhuri, Rishidev and Fiete, Ila},
	month = mar,
	year = {2016},
	keywords = {merged\_fiete.bib},
	pages = {394--403},
}

@article{koyluoglu_fundamental_2017,
	title = {Fundamental bound on the persistence and capacity of short-term memory stored as graded persistent activity},
	volume = {6},
	abstract = {It is widely believed that persistent neural activity underlies short-term memory. Yet, as we show, the degradation of information stored directly in such networks behaves differently from human short-term memory performance. We build a more general framework where memory is viewed as a problem of passing information through noisy channels whose degradation characteristics resemble those of persistent activity networks. If the brain first encoded the information appropriately before passing the information into such networks, the information can be stored substantially more faithfully. Within this framework, we derive a fundamental lower-bound on recall precision, which declines with storage duration and number of stored items. We show that human performance, though inconsistent with models involving direct (uncoded) storage in persistent activity networks, can be well-fit by the theoretical bound. This finding is consistent with the view that if the brain stores information in patterns of persistent activity, it might use codes that minimize the effects of noise, motivating the search for such codes in the brain.},
	journal = {Elife},
	author = {Koyluoglu, Onur Ozan and Pertzov, Yoni and Manohar, Sanjay and Husain, Masud and Fiete, Ila R},
	year = {2017},
	keywords = {merged\_fiete.bib, human, neuroscience, computational biology, systems biology, short term memory, forgetting, information theory},
}

@article{stangl_sources_2020,
	title = {Sources of path integration error in young and aging humans},
	volume = {11},
	abstract = {Path integration plays a vital role in navigation: it enables the continuous tracking of one's position in space by integrating self-motion cues. Path integration abilities vary widely across individuals, and tend to deteriorate in old age. The specific causes of path integration errors, however, remain poorly characterized. Here, we combine tests of path integration performance in participants of different ages with an analysis based on the Langevin equation for diffusive dynamics, which allows us to decompose errors into distinct causes that can corrupt path integration computations. We show that, across age groups, the dominant error source is unbiased noise that accumulates with travel distance not elapsed time, suggesting that the noise originates in the velocity input rather than within the integrator. Age-related declines are primarily traced to a growth in this noise. These findings shed light on the contributors to path integration error and the mechanisms underlying age-related navigational deficits.},
	number = {1},
	journal = {Nat. Commun.},
	author = {Stangl, Matthias and Kanitscheider, Ingmar and Riemer, Martin and Fiete, Ila and Wolbers, Thomas},
	year = {2020},
	keywords = {merged\_fiete.bib},
	pages = {2626},
}

@article{gu_map-like_2018,
	title = {A {Map}-like {Micro}-{Organization} of {Grid} {Cells} in the {Medial} {Entorhinal} {Cortex}},
	volume = {175},
	abstract = {How the topography of neural circuits relates to their function remains unclear. Although topographic maps exist for sensory and motor variables, they are rarely observed for cognitive variables. Using calcium imaging during virtual navigation, we investigated the relationship between the anatomical organization and functional properties of grid cells, which represent a cognitive code for location during navigation. We found a substantial degree of grid cell micro-organization in mouse medial entorhinal cortex: grid cells and modules all clustered anatomically. Within a module, the layout of grid cells was a noisy two-dimensional lattice in which the anatomical distribution of grid cells largely matched their spatial tuning phases. This micro-arrangement of phases demonstrates the existence of a topographical map encoding a cognitive variable in rodents. It contributes to a foundation for evaluating circuit models of the grid cell network and is consistent with continuous attractor models as the mechanism of grid formation.},
	number = {3},
	journal = {Cell},
	author = {Gu, Yi and Lewallen, Sam and Kinkhabwala, Amina A and Domnisoru, Cristina and Yoon, Kijung and Gauthier, Jeffrey L and Fiete, Ila R and Tank, David W},
	year = {2018},
	keywords = {merged\_fiete.bib, grid cell, virtual reality, calcium imaging, grid module, continuous attractor network models, grid phase, medial entorhinal cortex, microprism, pyramidal cell, stellate cell},
	pages = {736--750.e30},
}

@article{trettel_grid_2019,
	title = {Grid cell co-activity patterns during sleep reflect spatial overlap of grid fields during active behaviors},
	volume = {22},
	abstract = {Continuous-attractor network models of grid formation posit that recurrent connectivity between grid cells controls their patterns of co-activation. Grid cells from a common module exhibit stable offsets in their periodic spatial tuning curves across environments, and this may reflect recurrent connectivity or correlated sensory inputs. Here we explore whether cell-cell relationships predicted by attractor models persist during sleep states in which spatially informative sensory inputs are absent. We recorded ensembles of grid cells in superficial layers of medial entorhinal cortex during active exploratory behaviors and overnight sleep. Per grid cell pair and collectively, and across waking, rapid eye movement sleep and non-rapid eye movement sleep, we found preserved patterns of spike-time correlations that reflected the spatial tuning offsets between these grid cells during active exploration. The preservation of cell-cell relationships across waking and sleep states was not explained by theta oscillations or activity in hippocampal subregion CA1. These results indicate that recurrent connectivity within the grid cell network drives grid cell activity across behavioral states.},
	number = {4},
	journal = {Nat. Neurosci.},
	author = {Trettel, S G and Trimper, J B and Hwaun, E and Fiete, I R and Colgin, L L},
	year = {2019},
	keywords = {merged\_fiete.bib},
	pages = {609--617},
}

@article{chaudhuri_intrinsic_2019,
	title = {The intrinsic attractor manifold and population dynamics of a canonical cognitive circuit across waking and sleep},
	volume = {22},
	abstract = {Neural circuits construct distributed representations of key variables-external stimuli or internal constructs of quantities relevant for survival, such as an estimate of one's location in the world-as vectors of population activity. Although population activity vectors may have thousands of entries (dimensions), we consider that they trace out a low-dimensional manifold whose dimension and topology match the represented variable. This manifold perspective enables blind discovery and decoding of the represented variable using only neural population activity (without knowledge of the input, output, behavior or topography). We characterize and directly visualize manifold structure in the mammalian head direction circuit, revealing that the states form a topologically nontrivial one-dimensional ring. The ring exhibits isometry and is invariant across waking and rapid eye movement sleep. This result directly demonstrates that there are continuous attractor dynamics and enables powerful inference about mechanism. Finally, external rather than internal noise limits memory fidelity, and the manifold approach reveals new dynamical trajectories during sleep.},
	number = {9},
	journal = {Nat. Neurosci.},
	author = {Chaudhuri, Rishidev and Gerçek, Berk and Pandey, Biraj and Peyrache, Adrien and Fiete, Ila},
	year = {2019},
	keywords = {merged\_fiete.bib},
	pages = {1512--1520},
}

@article{widloski_inferring_2018,
	title = {Inferring circuit mechanisms from sparse neural recording and global perturbation in grid cells},
	volume = {7},
	abstract = {A goal of systems neuroscience is to discover the circuit mechanisms underlying brain function. Despite experimental advances that enable circuit-wide neural recording, the problem remains open in part because solving the 'inverse problem' of inferring circuity and mechanism by merely observing activity is hard. In the grid cell system, we show through modeling that a technique based on global circuit perturbation and examination of a novel theoretical object called the distribution of relative phase shifts (DRPS) could reveal the mechanisms of a cortical circuit at unprecedented detail using extremely sparse neural recordings. We establish feasibility, showing that the method can discriminate between recurrent versus feedforward mechanisms and amongst various recurrent mechanisms using recordings from a handful of cells. The proposed strategy demonstrates that sparse recording coupled with simple perturbation can reveal more about circuit mechanism than can full knowledge of network activity or the synaptic connectivity matrix.},
	journal = {Elife},
	author = {Widloski, John and Marder, Michael P and Fiete, Ila R},
	year = {2018},
	keywords = {grid cells, merged\_fiete.bib, neuroscience, none, attractor dynamics, circuit perturbation, recurrent networks},
}

@article{warren_non-euclidean_2019,
	title = {Non-{Euclidean} navigation},
	volume = {222},
	abstract = {A basic set of navigation strategies supports navigational tasks ranging from homing to novel detours and shortcuts. To perform these last two tasks, it is generally thought that humans, mammals and perhaps some insects possess Euclidean cognitive maps, constructed on the basis of input from the path integration system. In this article, I review the rationale and behavioral evidence for this metric cognitive map hypothesis, and find it unpersuasive: in practice, there is little evidence for truly novel shortcuts in animals, and human performance is highly unreliable and biased by environmental features. I develop the alternative hypothesis that spatial knowledge is better characterized as a labeled graph: a network of paths between places augmented with local metric information. What distinguishes such a cognitive graph from a metric cognitive map is that this local information is not embedded in a global coordinate system, so spatial knowledge is often geometrically inconsistent. Human path integration appears to be better suited to piecewise measurements of path lengths and turn angles than to building a consistent map. In a series of experiments in immersive virtual reality, we tested human navigation in non-Euclidean environments and found that shortcuts manifest large violations of the metric postulates. The results are contrary to the Euclidean map hypothesis and support the cognitive graph hypothesis. Apparently Euclidean behavior, such as taking novel detours and approximate shortcuts, can be explained by the adaptive use of non-Euclidean strategies.},
	number = {Pt Suppl 1},
	journal = {J. Exp. Biol.},
	author = {Warren, William H},
	year = {2019},
	keywords = {merged\_fiete.bib, Cognitive map, abstract cognitive grid cells non-spatial hippocampus Cognitive graph, Path integration, Spatial cognition, Wayfinding},
}

@article{giusti_clique_2015,
	title = {Clique topology reveals intrinsic geometric structure in neural correlations},
	volume = {112},
	abstract = {Detecting meaningful structure in neural activity and connectivity data is challenging in the presence of hidden nonlinearities, where traditional eigenvalue-based methods may be misleading. We introduce a novel approach to matrix analysis, called clique topology, that extracts features of the data invariant under nonlinear monotone transformations. These features can be used to detect both random and geometric structure, and depend only on the relative ordering of matrix entries. We then analyzed the activity of pyramidal neurons in rat hippocampus, recorded while the animal was exploring a 2D environment, and confirmed that our method is able to detect geometric organization using only the intrinsic pattern of neural correlations. Remarkably, we found similar results during nonspatial behaviors such as wheel running and rapid eye movement (REM) sleep. This suggests that the geometric structure of correlations is shaped by the underlying hippocampal circuits and is not merely a consequence of position coding. We propose that clique topology is a powerful new tool for matrix analysis in biological settings, where the relationship of observed quantities to more meaningful variables is often nonlinear and unknown.},
	number = {44},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Giusti, Chad and Pastalkova, Eva and Curto, Carina and Itskov, Vladimir},
	month = nov,
	year = {2015},
	keywords = {topological data analysis, merged\_fiete.bib, neural coding, Betti curves, clique topology, structure of neural correlation},
	pages = {13455--13460},
}

@article{behrens_what_2018,
	title = {What {Is} a {Cognitive} {Map}? {Organizing} {Knowledge} for {Flexible} {Behavior}},
	volume = {100},
	abstract = {It is proposed that a cognitive map encoding the relationships between entities in the world supports flexible behavior, but the majority of the neural evidence for such a system comes from studies of spatial navigation. Recent work describing neuronal parallels between spatial and non-spatial behaviors has rekindled the notion of a systematic organization of knowledge across multiple domains. We review experimental evidence and theoretical frameworks that point to principles unifying these apparently disparate functions. These principles describe how to learn and use abstract, generalizable knowledge and suggest that map-like representations observed in a spatial context may be an instance of general coding mechanisms capable of organizing knowledge of all kinds. We highlight how artificial agents endowed with such principles exhibit flexible behavior and learn map-like representations observed in the brain. Finally, we speculate on how these principles may offer insight into the extreme generalizations, abstractions, and inferences that characterize human cognition.},
	number = {2},
	journal = {Neuron},
	author = {Behrens, Timothy E J and Muller, Timothy H and Whittington, James C R and Mark, Shirley and Baram, Alon B and Stachenfeld, Kimberly L and Kurth-Nelson, Zeb},
	year = {2018},
	keywords = {merged\_fiete.bib, Generalization, Inference, Cognitive Map, Decision Making, Hippocampal Formation, Prefrontal Cortex, Reinforcement Learning, Spatial Cognition, Statistical Learning, Structure Learning},
	pages = {490--509},
}

@article{klukas_efficient_2020,
	title = {Efficient and flexible representation of higher-dimensional cognitive variables with grid cells},
	volume = {16},
	abstract = {We shed light on the potential of entorhinal grid cells to efficiently encode variables of dimension greater than two, while remaining faithful to empirical data on their low-dimensional structure. Our model constructs representations of high-dimensional inputs through a combination of low-dimensional random projections and “classical” low-dimensional hexagonal grid cell responses. Without reconfiguration of the recurrent circuit, the same system can flexibly encode multiple variables of different dimensions while maximizing the coding range (per dimension) by automatically trading-off dimension with an exponentially large coding range. It achieves high efficiency and flexibility by combining two powerful concepts, modularity and mixed selectivity, in what we call “mixed modular coding”. In contrast to previously proposed schemes, the model does not require the formation of higher-dimensional grid responses, a cell-inefficient and rigid mechanism. The firing fields observed in flying bats or climbing rats can be generated by neurons that combine activity from multiple grid modules, each representing higher-dimensional spaces according to our model. The idea expands our understanding of grid cells, suggesting that they could implement a general circuit that generates on-demand coding and memory states for variables in high-dimensional vector spaces.},
	number = {4},
	journal = {PLoS Comput. Biol.},
	author = {Klukas, Mirko and Lewis, Marcus and Fiete, Ila},
	year = {2020},
	keywords = {merged\_fiete.bib, abstract cognitive grid cells non-spatial hippocampus},
	pages = {e1007796},
}

@article{jin_startstop_2010,
	title = {Start/stop signals emerge in nigrostriatal circuits during sequence learning},
	volume = {466},
	abstract = {Learning new action sequences subserves a plethora of different abilities such as escaping a predator, playing the piano, or producing fluent speech. Proper initiation and termination of each action sequence is critical for the organization of behaviour, and is compromised in nigrostriatal disorders like Parkinson's and Huntington's diseases. Using a self-paced operant task in which mice learn to perform a particular sequence of actions to obtain an outcome, we found neural activity in nigrostriatal circuits specifically signalling the initiation or the termination of each action sequence. This start/stop activity emerged during sequence learning, was specific for particular actions, and did not reflect interval timing, movement speed or action value. Furthermore, genetically altering the function of striatal circuits disrupted the development of start/stop activity and selectively impaired sequence learning. These results have important implications for understanding the functional organization of actions and the sequence initiation and termination impairments observed in basal ganglia disorders.},
	number = {7305},
	journal = {Nature},
	author = {Jin, Xin and Costa, Rui M},
	month = jul,
	year = {2010},
	keywords = {merged\_fiete.bib, sequences in brain learning hierarchy},
	pages = {457--462},
}

@article{jin_basal_2014,
	title = {Basal ganglia subcircuits distinctively encode the parsing and concatenation of action sequences},
	volume = {17},
	abstract = {Chunking allows the brain to efficiently organize memories and actions. Although basal ganglia circuits have been implicated in action chunking, little is known about how individual elements are concatenated into a behavioral sequence at the neural level. Using a task in which mice learned rapid action sequences, we uncovered neuronal activity encoding entire sequences as single actions in basal ganglia circuits. In addition to neurons with activity related to the start/stop activity signaling sequence parsing, we found neurons displaying inhibited or sustained activity throughout the execution of an entire sequence. This sustained activity covaried with the rate of execution of individual sequence elements, consistent with motor concatenation. Direct and indirect pathways of basal ganglia were concomitantly active during sequence initiation, but behaved differently during sequence performance, revealing a more complex functional organization of these circuits than previously postulated. These results have important implications for understanding the functional organization of basal ganglia during the learning and execution of action sequences.},
	number = {3},
	journal = {Nat. Neurosci.},
	author = {Jin, Xin and Tecuapetla, Fatuel and Costa, Rui M},
	month = mar,
	year = {2014},
	keywords = {merged\_fiete.bib, sequences in brain learning},
	pages = {423--430},
}

@article{karni_acquisition_1998,
	title = {The acquisition of skilled motor performance: fast and slow experience-driven changes in primary motor cortex},
	volume = {95},
	abstract = {Behavioral and neurophysiological studies suggest that skill learning can be mediated by discrete, experience-driven changes within specific neural representations subserving the performance of the trained task. We have shown that a few minutes of daily practice on a sequential finger opposition task induced large, incremental performance gains over a few weeks of training. These gains did not generalize to the contralateral hand nor to a matched sequence of identical component movements, suggesting that a lateralized representation of the learned sequence of movements evolved through practice. This interpretation was supported by functional MRI data showing that a more extensive representation of the trained sequence emerged in primary motor cortex after 3 weeks of training. The imaging data, however, also indicated important changes occurring in primary motor cortex during the initial scanning sessions, which we proposed may reflect the setting up of a task-specific motor processing routine. Here we provide behavioral and functional MRI data on experience-dependent changes induced by a limited amount of repetitions within the first imaging session. We show that this limited training experience can be sufficient to trigger performance gains that require time to become evident. We propose that skilled motor performance is acquired in several stages: “fast” learning, an initial, within-session improvement phase, followed by a period of consolidation of several hours duration, and then “slow” learning, consisting of delayed, incremental gains in performance emerging after continued practice. This time course may reflect basic mechanisms of neuronal plasticity in the adult brain that subserve the acquisition and retention of many different skills.},
	number = {3},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Karni, A and Meyer, G and Rey-Hipolito, C and Jezzard, P and Adams, M M and Turner, R and Ungerleider, L G},
	month = feb,
	year = {1998},
	keywords = {merged\_fiete.bib, sequences in brain learning motor},
	pages = {861--868},
}

@article{diba_forward_2007,
	title = {Forward and reverse hippocampal place-cell sequences during ripples},
	volume = {10},
	abstract = {We report that temporal spike sequences from hippocampal place neurons of rats on an elevated track recurred in reverse order at the end of a run, but in forward order in anticipation of the run, coinciding with sharp waves. Vector distances between the place fields were reflected in the temporal structure of these sequences. This bidirectional re-enactment of temporal sequences may contribute to the establishment of higher-order associations in episodic memory.},
	number = {10},
	journal = {Nat. Neurosci.},
	author = {Diba, Kamran and Buzsáki, György},
	month = oct,
	year = {2007},
	keywords = {merged\_fiete.bib, sequences in brain learning replay key paper},
	pages = {1241--1242},
}

@article{hsieh_hippocampal_2014,
	title = {Hippocampal activity patterns carry information about objects in temporal context},
	volume = {81},
	abstract = {The hippocampus is critical for human episodic memory, but its role remains controversial. One fundamental question concerns whether the hippocampus represents specific objects or assigns context-dependent representations to objects. Here, we used multivoxel pattern similarity analysis of fMRI data during retrieval of learned object sequences to systematically investigate hippocampal coding of object and temporal context information. Hippocampal activity patterns carried information about the temporal positions of objects in learned sequences, but not about objects or temporal positions in random sequences. Hippocampal activity patterns differentiated between overlapping object sequences and between temporally adjacent objects that belonged to distinct sequence contexts. Parahippocampal and perirhinal cortex showed different pattern information profiles consistent with coding of temporal position and object information, respectively. These findings are consistent with models proposing that the hippocampus represents objects within specific temporal contexts, a capability that might explain its critical role in episodic memory.},
	number = {5},
	journal = {Neuron},
	author = {Hsieh, Liang-Tien and Gruber, Matthias J and Jenkins, Lucas J and Ranganath, Charan},
	month = mar,
	year = {2014},
	keywords = {merged\_fiete.bib, sequences in brain hippocampus non-spatial},
	pages = {1165--1178},
}

@article{doyon_experience-dependent_2002,
	title = {Experience-dependent changes in cerebellar contributions to motor sequence learning},
	volume = {99},
	abstract = {Studies in experimental animals and humans have stressed the role of the cerebellum in motor skill learning. Yet, the relative importance of the cerebellar cortex and deep nuclei, as well as the nature of the dynamic functional changes occurring between these and other motor-related structures during learning, remains in dispute. Using functional magnetic resonance imaging and a motor sequence learning paradigm in humans, we found evidence of an experience-dependent shift of activation from the cerebellar cortex to the dentate nucleus during early learning, and from a cerebellar-cortical to a striatal-cortical network with extended practice. The results indicate that intrinsic modulation within the cerebellum, in concert with activation of motor-related cortical regions, serves to set up a procedurally acquired sequence of movements that is then maintained elsewhere in the brain.},
	number = {2},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Doyon, Julien and Song, Allen W and Karni, Avi and Lalonde, Francois and Adams, Michelle M and Ungerleider, Leslie G},
	month = jan,
	year = {2002},
	keywords = {merged\_fiete.bib, sequences in brain learning},
	pages = {1017--1022},
}

@article{farooq_emergence_2019,
	title = {Emergence of preconfigured and plastic time-compressed sequences in early postnatal development},
	volume = {363},
	abstract = {When and how hippocampal neuronal ensembles first organize to support encoding and consolidation of memory episodes, a critical cognitive function of the brain, are unknown. We recorded electrophysiological activity from large ensembles of hippocampal neurons starting on the first day after eye opening as naïve rats navigated linear environments and slept. We found a gradual age-dependent, navigational experience-independent assembly of preconfigured trajectory-like sequences from persistent, location-depicting ensembles during postnatal week 3. Adult-like compressed binding of adjacent locations into trajectories during navigation and their navigational experience-dependent replay during sleep emerged in concert from spontaneous preconfigured sequences only during early postnatal week 4. Our findings reveal ethologically relevant distinct phases in the development of hippocampal preconfigured and experience-dependent sequential patterns thought to be important for episodic memory formation.},
	number = {6423},
	journal = {Science},
	author = {Farooq, U and Dragoi, G},
	year = {2019},
	keywords = {merged\_fiete.bib},
	pages = {168--173},
}

@article{dragoi_preplay_2011,
	title = {Preplay of future place cell sequences by hippocampal cellular assemblies},
	volume = {469},
	abstract = {During spatial exploration, hippocampal neurons show a sequential firing pattern in which individual neurons fire specifically at particular locations along the animal's trajectory (place cells). According to the dominant model of hippocampal cell assembly activity, place cell firing order is established for the first time during exploration, to encode the spatial experience, and is subsequently replayed during rest or slow-wave sleep for consolidation of the encoded experience. Here we report that temporal sequences of firing of place cells expressed during a novel spatial experience occurred on a significant number of occasions during the resting or sleeping period preceding the experience. This phenomenon, which is called preplay, occurred in disjunction with sequences of replay of a familiar experience. These results suggest that internal neuronal dynamics during resting or sleep organize hippocampal cellular assemblies into temporal sequences that contribute to the encoding of a related novel experience occurring in the future.},
	number = {7330},
	journal = {Nature},
	author = {Dragoi, George and Tonegawa, Susumu},
	month = jan,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {397--401},
}

@article{liu_preconfigured_2019,
	title = {Preconfigured patterns are the primary driver of offline multi-neuronal sequence replay},
	volume = {29},
	abstract = {Spontaneous neuronal ensemble activity in the hippocampus is believed to result from a combination of preconfigured internally generated dynamics and the unique patterns of activity driven by recent experience. Previous research has established that preconfigured sequential neuronal patterns (i.e., preplay) contribute to the expression of future place cell sequences, which in turn contribute to the sequential neuronal patterns expressed post-experience (i.e., replay). The relative contribution of preconfigured and of experience-related factors to replay and to overall sequential activity during post-run sleep is believed to be highly biased toward the recent run experience, despite never being tested directly. Here, we use multi-neuronal sequence analysis unbiased by firing rate to compute and directly compare the contributions of internally generated and of recent experience-driven factors to the sequential neuronal activity in post-run sleep in naïve adult rats. We find that multi-neuronal sequences during post-run sleep are dominantly contributed by the pre-run preconfigured patterns and to a much smaller extent by the place cell sequences and associated awake rest multi-neuronal sequences experienced during de novo run session, which are weakly and similarly correlated with pre- and post-run sleep multi-neuronal sequences. These findings indicate a robust default internal organization of the hippocampal network into sequential neuronal ensembles that withstands a de novo spatial experience and suggest that integration of novel information during de novo experience leading to lasting changes in sequential network patterns is much more subtle than previously assumed.},
	number = {3},
	journal = {Hippocampus},
	author = {Liu, Kefei and Sibille, Jeremie and Dragoi, George},
	month = mar,
	year = {2019},
	keywords = {merged\_fiete.bib, representations, multi-neuronal sequences, neuronal ensembles, preplay, sleep},
	pages = {275--283},
}

@article{dragoi_distinct_2013,
	title = {Distinct preplay of multiple novel spatial experiences in the rat},
	volume = {110},
	abstract = {The activity of ensembles of hippocampal place cells represents a hallmark of an animal's spatial experience. The neuronal mechanisms that enable the rapid expression of novel place cell sequences are not entirely understood. Here we report that during sleep or rest, distinct sets of hippocampal temporal sequences in the rat preplay multiple corresponding novel spatial experiences with high specificity. These findings suggest that the place cell sequence of a novel spatial experience is determined, in part, by an online selection of a subset of cellular firing sequences from a larger repertoire of preexisting temporal firing sequences in the hippocampal cellular assembly network that become rapidly bound to the novel experience. We estimate that for the given context, the recorded hippocampal network activity has the capacity to preplay an extended repertoire of at least 15 future spatial experiences of similar distinctiveness and complexity.},
	number = {22},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Dragoi, George and Tonegawa, Susumu},
	month = may,
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {9100--9105},
}

@article{dragoi_selection_2014,
	title = {Selection of preconfigured cell assemblies for representation of novel spatial experiences},
	volume = {369},
	abstract = {Internal representations about the external world can be driven by the external stimuli or can be internally generated in their absence. It has been a matter of debate whether novel stimuli from the external world are instructive over the brain network to create de novo representations or, alternatively, are selecting from existing pre-representations hosted in preconfigured brain networks. The hippocampus is a brain area necessary for normal internally generated spatial-temporal representations and its dysfunctions have resulted in anterograde amnesia, impaired imagining of new experiences, and hallucinations. The compressed temporal sequence of place cell activity in the rodent hippocampus serves as an animal model of internal representation of the external space. Based on our recent results on the phenomenon of novel place cell sequence preplay, we submit that the place cell sequence of a novel spatial experience is determined, in part, by a selection of a set of cellular firing sequences from a repertoire of existing temporal firing sequences in the hippocampal network. Conceptually, this indicates that novel stimuli from the external world select from their pre-representations rather than create de novo our internal representations of the world.},
	number = {1635},
	journal = {Philos. Trans. R. Soc. Lond. B Biol. Sci.},
	author = {Dragoi, George and Tonegawa, Susumu},
	month = feb,
	year = {2014},
	keywords = {hippocampus, merged\_fiete.bib, preplay, cellular assemblies, internal representation, temporal order diagrams, temporal sequence},
	pages = {20120522},
}

@article{macready_criticality_1996,
	title = {Criticality and parallelism in combinatorial optimization},
	volume = {271},
	abstract = {Local search methods constitute one of the most successful approaches to solving large-scale combinatorial optimization problems. As these methods are increasingly parallelized, optimization performance initially improves but then abruptly degrades to no better than that of random search beyond a certain point. The existence of this transition is demonstrated for a family of generalized spin-glass models and the traveling salesman problem. Finite-size scaling is used to characterize size-dependent effects near the transition, and analytical insight is obtained through a mean-field approximation.},
	number = {5245},
	journal = {Science},
	author = {Macready, W G and Siapas, A G and Kauffman, S A},
	month = jan,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {56--59},
}

@article{sherman_thalamus_2016,
	title = {Thalamus plays a central role in ongoing cortical functioning},
	volume = {19},
	abstract = {Several challenges to current views of thalamocortical processing are offered here. Glutamatergic pathways in thalamus and cortex are divided into two distinct classes: driver and modulator. We suggest that driver inputs are the main conduits of information and that modulator inputs modify how driver inputs are processed. Different driver sources reveal two types of thalamic relays: first order relays receive subcortical driver input (for example, retinal input to the lateral geniculate nucleus), whereas higher order relays (for example, pulvinar) receive driver input from layer 5 of cortex and participate in cortico-thalamo-cortical (or transthalamic) circuits. These transthalamic circuits represent an unappreciated aspect of cortical functioning, which I discuss here. Direct corticocortical connections are often paralleled by transthalamic ones. Furthermore, driver inputs to thalamus, both first and higher order, typically arrive via branching axons, and the transthalamic branch often innervates subcortical motor centers, leading to the suggestion that these inputs to thalamus serve as efference copies.},
	number = {4},
	journal = {Nat. Neurosci.},
	author = {Sherman, S Murray},
	month = apr,
	year = {2016},
	keywords = {merged\_fiete.bib},
	pages = {533--541},
}

@article{sherman_functioning_2017,
	title = {Functioning of {Circuits} {Connecting} {Thalamus} and {Cortex}},
	volume = {7},
	abstract = {Glutamatergic pathways in thalamus and cortex are divided into two distinct classes: driver, which carries the main information between cells, and modulator, which modifies how driver inputs function. Identifying driver inputs helps to reveal functional computational circuits, and one set of such circuits identified by this approach are cortico-thalamo-cortical (or transthalamic corticocortical) circuits. This, in turn, leads to the conclusion that there are two types of thalamic relay: first order nuclei (such as the lateral geniculate nucleus) that relay driver input from a subcortical source (i.e., retina), and higher order nuclei (such as the pulvinar) which are involved in these transthalamic pathways by relaying driver input from layer 5 of one cortical area to another. This thalamic division is also seen in other sensory pathways and beyond these so that most of thalamus by volume consists of higher-order relays. Many, and perhaps all, direct driver connections between cortical areas are paralleled by an indirect cortico-thalamo-cortical (transthalamic) driver route involving higher order thalamic relays. Such thalamic relays represent a heretofore unappreciated role in cortical functioning, and this assessment challenges and extends conventional views regarding both the role of thalamus and mechanisms of corticocortical communication. Finally, many and perhaps the vast majority of driver inputs relayed through thalamus arrive via branching axons, with extrathalamic targets often being subcortical motor centers. This raises the possibility that inputs relayed by thalamus to cortex also serve as efference copies, and this may represent an important feature of information relayed up the cortical hierarchy via transthalamic circuits. {\textbackslash}copyright 2017 American Physiological Society. Compr Physiol 7:713-739, 2017.},
	number = {2},
	journal = {Compr. Physiol.},
	author = {Sherman, S Murray},
	year = {2017},
	keywords = {merged\_fiete.bib},
	pages = {713--739},
}

@article{rikhye_thalamic_2018,
	title = {Thalamic regulation of switching between cortical representations enables cognitive flexibility},
	volume = {21},
	abstract = {Interactions between the prefrontal cortex (PFC) and mediodorsal thalamus are critical for cognitive flexibility, yet the underlying computations are unknown. To investigate frontothalamic substrates of cognitive flexibility, we developed a behavioral task in which mice switched between different sets of learned cues that guided attention toward either visual or auditory targets. We found that PFC responses reflected both the individual cues and their meaning as task rules, indicating a hierarchical cue-to-rule transformation. Conversely, mediodorsal thalamus responses reflected the statistical regularity of cue presentation and were required for switching between such experimentally specified cueing contexts. A subset of these thalamic responses sustained context-relevant PFC representations, while another suppressed the context-irrelevant ones. Through modeling and experimental validation, we find that thalamic-mediated suppression may not only reduce PFC representational interference but could also preserve unused cortical traces for future use. Overall, our study provides a computational foundation for thalamic engagement in cognitive flexibility.},
	number = {12},
	journal = {Nat. Neurosci.},
	author = {Rikhye, Rajeev V and Gilra, Aditya and Halassa, Michael M},
	year = {2018},
	keywords = {merged\_fiete.bib},
	pages = {1753--1763},
}

@article{milner_medial_2005,
	title = {The medial temporal-lobe amnesic syndrome},
	volume = {28},
	abstract = {This article has attempted to show how early evidence of the existence of multiple memory systems in the brain arose from the study of a few patients with bilateral damage to the medial structures of the temporal lobe in the hippocampal region, as in the case of the now famous patient HM. Such patients exhibit a profound anterograde amnesia for the experiences of daily life, whereas previously acquired knowledge is well preserved and immediate or primary memory is intact, and other cognitive abilities, including language, perception, and reasoning also are unaffected by the lesion. Despite the seemingly global nature of HM's memory loss, it was possible to show by the appropriate choice of behavioral tasks that many implicit,procedural forms of learning were preserved, and these forms are now known to be mediated by different brain systems. The first major finding was the demonstration of normal acquisition of a motor skill by HM, although he remained unaware that he had done the task before. This finding was followed by the demonstration of preserved perceptual learning,and since then the examples of preserved learning in amnesia have multiplied. In addition, after many false starts, a convincing animal model has now been achieved, with convergent findings for human and nonhuman primates. Although considerable progress has been made since the early 1950s, many questions remain unanswered; particularly, the distinct contributions of the various medial temporal-lobe structures to memory processes and the interaction of these structures with other brain areas need to be clarified. As in the past, the solution of such problems will call for a multidisciplinary approach.},
	number = {3},
	journal = {Psychiatr. Clin. North Am.},
	author = {Milner, Brenda},
	month = sep,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {599--611, 609},
}

@article{das_systematic_2020,
	title = {Systematic errors in connectivity inferred from activity in strongly recurrent networks},
	volume = {(accepted)},
	journal = {Nat. Neurosci.},
	author = {Das, A and Fiete, I R},
	year = {2020},
	keywords = {merged\_fiete.bib},
}

@article{stangl_sources_2018,
	title = {Sources of path integration error in young and aging humans},
	journal = {bioRxiv},
	author = {Stangl, +matthias and Kanitscheider, +ingmar and Riemer, +martin and Fiete, +ila and Wolbers, +thomas},
	year = {2018},
	keywords = {merged\_fiete.bib},
}

@article{kanitscheider_emergence_2017,
	title = {Emergence of dynamically reconfigurable hippocampal responses by learning to perform probabilistic spatial reasoning},
	journal = {bioRxiv},
	author = {Kanitscheider, +ingmar and Fiete, +ila},
	year = {2017},
	keywords = {hippocampus, merged\_fiete.bib, probabilistic, slam},
}

@article{squire_memory_2015,
	title = {Memory consolidation},
	volume = {7},
	abstract = {Conscious memory for a new experience is initially dependent on information stored in both the hippocampus and neocortex. Systems consolidation is the process by which the hippocampus guides the reorganization of the information stored in the neocortex such that it eventually becomes independent of the hippocampus. Early evidence for systems consolidation was provided by studies of retrograde amnesia, which found that damage to the hippocampus-impaired memories formed in the recent past, but typically spared memories formed in the more remote past. Systems consolidation has been found to occur for both episodic and semantic memories and for both spatial and nonspatial memories, although empirical inconsistencies and theoretical disagreements remain about these issues. Recent work has begun to characterize the neural mechanisms that underlie the dialogue between the hippocampus and neocortex (e.g., “neural replay,” which occurs during sharp wave ripple activity). New work has also identified variables, such as the amount of preexisting knowledge, that affect the rate of consolidation. The increasing use of molecular genetic tools (e.g., optogenetics) can be expected to further improve understanding of the neural mechanisms underlying consolidation.},
	number = {8},
	journal = {Cold Spring Harb. Perspect. Biol.},
	author = {Squire, Larry R and Genzel, Lisa and Wixted, John T and Morris, Richard G},
	month = aug,
	year = {2015},
	keywords = {merged\_fiete.bib, hippocampus non-spatial},
	pages = {a021766},
}

@article{epstein_cognitive_2017,
	title = {The cognitive map in humans: spatial navigation and beyond},
	volume = {20},
	abstract = {The 'cognitive map' hypothesis proposes that brain builds a unified representation of the spatial environment to support memory and guide future action. Forty years of electrophysiological research in rodents suggest that cognitive maps are neurally instantiated by place, grid, border and head direction cells in the hippocampal formation and related structures. Here we review recent work that suggests a similar functional organization in the human brain and yields insights into how cognitive maps are used during spatial navigation. Specifically, these studies indicate that (i) the human hippocampus and entorhinal cortex support map-like spatial codes, (ii) posterior brain regions such as parahippocampal and retrosplenial cortices provide critical inputs that allow cognitive maps to be anchored to fixed environmental landmarks, and (iii) hippocampal and entorhinal spatial codes are used in conjunction with frontal lobe mechanisms to plan routes during navigation. We also discuss how these three basic elements of cognitive map based navigation-spatial coding, landmark anchoring and route planning-might be applied to nonspatial domains to provide the building blocks for many core elements of human thought.},
	number = {11},
	journal = {Nat. Neurosci.},
	author = {Epstein, Russell A and Patai, Eva Zita and Julian, Joshua B and Spiers, Hugo J},
	year = {2017},
	keywords = {merged\_fiete.bib},
	pages = {1504--1513},
}

@article{eichenbaum_role_2017,
	title = {The role of the hippocampus in navigation is memory},
	volume = {117},
	abstract = {There is considerable research on the neurobiological mechanisms within the hippocampal system that support spatial navigation. In this article I review the literature on navigational strategies in humans and animals, observations on hippocampal function in navigation, and studies of hippocampal neural activity in animals and humans performing different navigational tasks and tests of memory. Whereas the hippocampus is essential to spatial navigation via a cognitive map, its role derives from the relational organization and flexibility of cognitive maps and not from a selective role in the spatial domain. Correspondingly, hippocampal networks map multiple navigational strategies, as well as other spatial and nonspatial memories and knowledge domains that share an emphasis on relational organization. These observations suggest that the hippocampal system is not dedicated to spatial cognition and navigation, but organizes experiences in memory, for which spatial mapping and navigation are both a metaphor for and a prominent application of relational memory organization.},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Eichenbaum, Howard},
	year = {2017},
	keywords = {merged\_fiete.bib, hippocampus non-spatial, Untitled},
	pages = {1785--1796},
}

@article{eichenbaum_is_1996,
	title = {Is the rodent hippocampus just for 'place'?},
	volume = {6},
	abstract = {The prominent view that the rodent hippocampus is dedicated to spatial memory has been challenged recently by observations that both limit the nature of hippocampal spatial representation and extend its scope beyond literal space. These findings reveal that the rodent hippocampus mediates memory representations on the basis of non-spatial, as well as spatial, relations among items in memory, and supports access to these memories in a variety of situations. Therefore, the defining features of hippocampal representation in rodents, as in humans, lie not in the modality of the information processed, but in the organization of the information that supports a capacity for flexible memory expression.},
	number = {2},
	journal = {Curr. Opin. Neurobiol.},
	author = {Eichenbaum, H},
	month = apr,
	year = {1996},
	keywords = {merged\_fiete.bib, hippocampus non-spatial},
	pages = {187--195},
}

@article{mcechron_hippocampal_1999,
	title = {Hippocampal encoding of non-spatial trace conditioning},
	volume = {9},
	abstract = {Trace eyeblink classical conditioning is a non-spatial learning paradigm that requires an intact hippocampus. This task is hippocampus-dependent because the auditory tone conditioned stimulus (CS) is temporally separated from the corneal airpuff unconditioned stimulus (US) by a 500-ms trace interval. Our laboratory has performed a series of neurophysiological experiments that have examined the activity of pyramidal cells in the CA1 area of the hippocampus during trace eyeblink conditioning. We have found that the non-spatial stimuli involved in this paradigm are encoded in the hippocampus in a logical order that is necessary for their association and the subsequent expression of behavioral learning. Although there were many profiles of single neurons responding to the CS-US trial during training, the majority of the neurons showed an increase in activity to the airpuff-US. Prior to learning, it appears that hippocampal cells and ensembles of cells were preferentially attending to the stimulus with immediate behavioral importance, the US. Hippocampal cells then began to respond to the associated neutral stimulus, the CS. Shortly thereafter, animals began to show increases in the behavioral expression of CRs. In some experiments, hippocampal neurons from aged animals exhibited impairments in the encoding of CS and US information. These aged animals were not able to associate these stimuli and acquire trace eyeblink CRs. Our findings along with the findings of other spatial learning studies, suggest that the hippocampus is involved in encoding information about discontiguous sets of stimuli, either spatial or nonspatial, especially early in the learning process.},
	number = {4},
	journal = {Hippocampus},
	author = {McEchron, M D and Disterhoft, J F},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {385--396},
}

@article{lisman_prediction_2009,
	title = {Prediction, sequences and the hippocampus},
	volume = {364},
	abstract = {Recordings of rat hippocampal place cells have provided information about how the hippocampus retrieves memory sequences. One line of evidence has to do with phase precession, a process organized by theta and gamma oscillations. This precession can be interpreted as the cued prediction of the sequence of upcoming positions. In support of this interpretation, experiments in two-dimensional environments and on a cue-rich linear track demonstrate that many cells represent a position ahead of the animal and that this position is the same irrespective of which direction the rat is coming from. Other lines of investigation have demonstrated that such predictive processes also occur in the non-spatial domain and that retrieval can be internally or externally cued. The mechanism of sequence retrieval and the usefulness of this retrieval to guide behaviour are discussed.},
	number = {1521},
	journal = {Philos. Trans. R. Soc. Lond. B Biol. Sci.},
	author = {Lisman, John and Redish, A D},
	month = may,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {1193--1201},
}

@article{eichenbaum_what_2018,
	title = {What {Versus} {Where}: {Non}-spatial {Aspects} of {Memory} {Representation} by the {Hippocampus}},
	volume = {37},
	abstract = {Since the discovery of place cells and other findings indicating strong involvement of the hippocampus in spatial information processing, there has been continued controversy about the extent to which the hippocampus also processes non-spatial aspects of experience. In recent years, many experiments studying the effects of hippocampal damage and characterizing hippocampal neural activity in animals and humans have revealed a clear and specific role of the hippocampus in the processing of non-spatial information. Here this evidence is reviewed in support of the notion that the hippocampus organizes the contents of memory in space, in time, and in networks of related memories.},
	journal = {Curr. Top. Behav. Neurosci.},
	author = {Eichenbaum, Howard},
	year = {2018},
	keywords = {merged\_fiete.bib, hippocampus non-spatial},
	pages = {101--117},
}

@article{moskovitz_feedback_2018,
	title = {Feedback alignment in deep convolutional networks},
	abstract = {Ongoing studies have identified similarities between neural representations in biological networks and in deep artificial neural networks. This has led to renewed interest in developing analogies between the backpropagation learning algorithm used to train artificial networks and the synaptic plasticity rules operative in the brain. These efforts are challenged by biologically implausible features of backpropagation, one of which is a reliance on symmetric forward and backward synaptic weights. A number of methods have been proposed that do not rely on weight symmetry but, thus far, these have failed to scale to deep convolutional networks and complex data. We identify principal obstacles to the scalability of such algorithms and introduce several techniques to mitigate them. We demonstrate that a modification of the feedback alignment method that enforces a weaker form of weight symmetry, one that requires agreement of weight sign but not magnitude, can achieve performance competitive with backpropagation. Our results complement those of Bartunov et al. (2018) and Xiao et al. (2018b) and suggest that mechanisms that promote alignment of feedforward and feedback weights are critical for learning in deep networks.},
	journal = {arXiv:1812. 06488},
	author = {Moskovitz, Theodore H and Litwin-Kumar, Ashok and Abbott, L F},
	year = {2018},
	keywords = {merged\_fiete.bib},
}

@article{berry_structure_1997,
	title = {The structure and precision of retinal spike trains},
	volume = {94},
	abstract = {Assessing the reliability of neuronal spike trains is fundamental to an understanding of the neural code. We measured the reproducibility of retinal responses to repeated visual stimuli. In both tiger salamander and rabbit, the retinal ganglion cells responded to random flicker with discrete, brief periods of firing. For any given cell, these firing events covered only a small fraction of the total stimulus time, often less than 5\%. Firing events were very reproducible from trial to trial: the timing jitter of individual spikes was as low as 1 msec, and the standard deviation in spike count was often less than 0.5 spikes. Comparing the precision of spike timing to that of the spike count showed that the timing of a firing event conveyed several times more visual information than its spike count. This sparseness and precision were general characteristics of ganglion cell responses, maintained over the broad ensemble of stimulus waveforms produced by random flicker, and over a range of contrasts. Thus, the responses of retinal ganglion cells are not properly described by a firing probability that varies continuously with the stimulus. Instead, these neurons elicit discrete firing events that may be the fundamental coding symbols in retinal spike trains.},
	number = {10},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Berry, M J and Warland, D K and Meister, M},
	month = may,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {5411--5416},
}

@article{gire_temporal_2013,
	title = {Temporal processing in the olfactory system: can we see a smell?},
	volume = {78},
	abstract = {Sensory processing circuits in the visual and olfactory systems receive input from complex, rapidly changing environments. Although patterns of light and plumes of odor create different distributions of activity in the retina and olfactory bulb, both structures use what appears on the surface similar temporal coding strategies to convey information to higher areas in the brain. We compare temporal coding in the early stages of the olfactory and visual systems, highlighting recent progress in understanding the role of time in olfactory coding during active sensing by behaving animals. We also examine studies that address the divergent circuit mechanisms that generate temporal codes in the two systems, and find that they provide physiological information directly related to functional questions raised by neuroanatomical studies of Ramon y Cajal over a century ago. Consideration of differences in neural activity in sensory systems contributes to generating new approaches to understand signal processing.},
	number = {3},
	journal = {Neuron},
	author = {Gire, David H and Restrepo, Diego and Sejnowski, Terrence J and Greer, Charles and De Carlos, Juan A and Lopez-Mascaraque, Laura},
	month = may,
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {416--432},
}

@article{sejnowski_language_2012,
	title = {The language of the brain},
	volume = {307},
	number = {4},
	journal = {Sci. Am.},
	author = {Sejnowski, Terry and Delbruck, Tobi},
	month = oct,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {54--59},
}

@article{chenkov_memory_2017,
	title = {Memory replay in balanced recurrent networks},
	volume = {13},
	abstract = {Complex patterns of neural activity appear during up-states in the neocortex and sharp waves in the hippocampus, including sequences that resemble those during prior behavioral experience. The mechanisms underlying this replay are not well understood. How can small synaptic footprints engraved by experience control large-scale network activity during memory retrieval and consolidation? We hypothesize that sparse and weak synaptic connectivity between Hebbian assemblies are boosted by pre-existing recurrent connectivity within them. To investigate this idea, we connect sequences of assemblies in randomly connected spiking neuronal networks with a balance of excitation and inhibition. Simulations and analytical calculations show that recurrent connections within assemblies allow for a fast amplification of signals that indeed reduces the required number of inter-assembly connections. Replay can be evoked by small sensory-like cues or emerge spontaneously by activity fluctuations. Global-potentially neuromodulatory-alterations of neuronal excitability can switch between network states that favor retrieval and consolidation.},
	number = {1},
	journal = {PLoS Comput. Biol.},
	author = {Chenkov, Nikolay and Sprekeler, Henning and Kempter, Richard},
	year = {2017},
	keywords = {merged\_fiete.bib},
	pages = {e1005359},
}

@article{shaham_slow_2017,
	title = {Slow diffusive dynamics in a chaotic balanced neural network},
	volume = {13},
	abstract = {It has been proposed that neural noise in the cortex arises from chaotic dynamics in the balanced state: in this model of cortical dynamics, the excitatory and inhibitory inputs to each neuron approximately cancel, and activity is driven by fluctuations of the synaptic inputs around their mean. It remains unclear whether neural networks in the balanced state can perform tasks that are highly sensitive to noise, such as storage of continuous parameters in working memory, while also accounting for the irregular behavior of single neurons. Here we show that continuous parameter working memory can be maintained in the balanced state, in a neural circuit with a simple network architecture. We show analytically that in the limit of an infinite network, the dynamics generated by this architecture are characterized by a continuous set of steady balanced states, allowing for the indefinite storage of a continuous parameter. In finite networks, we show that the chaotic noise drives diffusive motion along the approximate attractor, which gradually degrades the stored memory. We analyze the dynamics and show that the slow diffusive motion induces slowly decaying temporal cross correlations in the activity, which differ substantially from those previously described in the balanced state. We calculate the diffusivity, and show that it is inversely proportional to the system size. For large enough (but realistic) neural population sizes, and with suitable tuning of the network connections, the proposed balanced network can sustain continuous parameter values in memory over time scales larger by several orders of magnitude than the single neuron time scale.},
	number = {5},
	journal = {PLoS Comput. Biol.},
	author = {Shaham, Nimrod and Burak, Yoram},
	year = {2017},
	keywords = {merged\_fiete.bib},
	pages = {e1005505},
}

@article{rubin_balanced_2017,
	title = {Balanced excitation and inhibition are required for high-capacity, noise-robust neuronal selectivity},
	volume = {114},
	abstract = {Neurons and networks in the cerebral cortex must operate reliably despite multiple sources of noise. To evaluate the impact of both input and output noise, we determine the robustness of single-neuron stimulus selective responses, as well as the robustness of attractor states of networks of neurons performing memory tasks. We find that robustness to output noise requires synaptic connections to be in a balanced regime in which excitation and inhibition are strong and largely cancel each other. We evaluate the conditions required for this regime to exist and determine the properties of networks operating within it. A plausible synaptic plasticity rule for learning that balances weight configurations is presented. Our theory predicts an optimal ratio of the number of excitatory and inhibitory synapses for maximizing the encoding capacity of balanced networks for given statistics of afferent activations. Previous work has shown that balanced networks amplify spatiotemporal variability and account for observed asynchronous irregular states. Here we present a distinct type of balanced network that amplifies small changes in the impinging signals and emerges automatically from learning to perform neuronal and network functions robustly.},
	number = {44},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Rubin, Ran and Abbott, L F and Sompolinsky, Haim},
	year = {2017},
	keywords = {merged\_fiete.bib, associative memory, E/I balance, synaptic learning},
	pages = {E9366--E9375},
}

@article{sato_excitatory_2016,
	title = {An excitatory basis for divisive normalization in visual cortex},
	volume = {19},
	abstract = {Neurons in visual cortex are connected not only locally, but also through networks of distal connectivity. These distal networks recruit both excitatory and inhibitory synapses and result in divisive normalization. Normalization is traditionally thought to result from increases in synaptic inhibition. By combining optogenetic stimulation and intracellular recordings in mouse visual cortex, we found that, on the contrary, normalization is a result of a decrease in synaptic excitation.},
	number = {4},
	journal = {Nat. Neurosci.},
	author = {Sato, Tatsuo K and Haider, Bilal and Häusser, Michael and Carandini, Matteo},
	month = apr,
	year = {2016},
	keywords = {merged\_fiete.bib},
	pages = {568--570},
}

@article{carandini_normalization_2011,
	title = {Normalization as a canonical neural computation},
	volume = {13},
	abstract = {There is increasing evidence that the brain relies on a set of canonical neural computations, repeating them across brain regions and modalities to apply similar operations to different problems. A promising candidate for such a computation is normalization, in which the responses of neurons are divided by a common factor that typically includes the summed activity of a pool of neurons. Normalization was developed to explain responses in the primary visual cortex and is now thought to operate throughout the visual system, and in many other sensory modalities and brain regions. Normalization may underlie operations such as the representation of odours, the modulatory effects of visual attention, the encoding of value and the integration of multisensory information. Its presence in such a diversity of neural systems in multiple species, from invertebrates to mammals, suggests that it serves as a canonical neural computation.},
	number = {1},
	journal = {Nat. Rev. Neurosci.},
	author = {Carandini, Matteo and Heeger, David J},
	month = nov,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {51--62},
}

@article{bhatia_precise_2019,
	title = {Precise excitation-inhibition balance controls gain and timing in the hippocampus},
	volume = {8},
	abstract = {Excitation-inhibition (EI) balance controls excitability, dynamic range, and input gating in many brain circuits. Subsets of synaptic input can be selected or 'gated' by precise modulation of finely tuned EI balance, but assessing the granularity of EI balance requires combinatorial analysis of excitatory and inhibitory inputs. Using patterned optogenetic stimulation of mouse hippocampal CA3 neurons, we show that hundreds of unique CA3 input combinations recruit excitation and inhibition with a nearly identical ratio, demonstrating precise EI balance at the hippocampus. Crucially, the delay between excitation and inhibition decreases as excitatory input increases from a few synapses to tens of synapses. This creates a dynamic millisecond-range window for postsynaptic excitation, controlling membrane depolarization amplitude and timing via subthreshold divisive normalization. We suggest that this combination of precise EI balance and dynamic EI delays forms a general mechanism for millisecond-range input gating and subthreshold gain control in feedforward networks.},
	journal = {Elife},
	author = {Bhatia, Aanchal and Moza, Sahil and Bhalla, Upinder Singh},
	month = apr,
	year = {2019},
	keywords = {merged\_fiete.bib, neuroscience, mouse},
}

@article{barak_persistent_2007,
	title = {Persistent activity in neural networks with dynamic synapses},
	volume = {3},
	abstract = {Persistent activity states (attractors), observed in several neocortical areas after the removal of a sensory stimulus, are believed to be the neuronal basis of working memory. One of the possible mechanisms that can underlie persistent activity is recurrent excitation mediated by intracortical synaptic connections. A recent experimental study revealed that connections between pyramidal cells in prefrontal cortex exhibit various degrees of synaptic depression and facilitation. Here we analyze the effect of synaptic dynamics on the emergence and persistence of attractor states in interconnected neural networks. We show that different combinations of synaptic depression and facilitation result in qualitatively different network dynamics with respect to the emergence of the attractor states. This analysis raises the possibility that the framework of attractor neural networks can be extended to represent time-dependent stimuli.},
	number = {2},
	journal = {PLoS Comput. Biol.},
	author = {Barak, Omri and Tsodyks, Misha},
	month = feb,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {e35},
}

@article{kunin_loss_2019,
	title = {Loss {Landscapes} of {Regularized} {Linear} {Autoencoders}},
	journal = {arXiv:1901. 08168},
	author = {Kunin, Daniel and Bloom, Jonathan M and Goeva, Aleksandrina and Seed, Cotton},
	year = {2019},
	keywords = {merged\_fiete.bib},
}

@article{minden_biologically_2019,
	title = {Biologically {Plausible} {Online} {Principal} {Component} {Analysis} {Without} {Recurrent} {Neural} {Dynamics}},
	abstract = {Artificial neural networks that learn to perform Principal Component Analysis (PCA) and related tasks using strictly local learning rules have been previously derived based on the principle of similarity matching: similar pairs of inputs should map to similar pairs of outputs. However, the operation of these networks (and of similar networks) requires a fixed-point iteration to determine the output corresponding to a given input, which means that dynamics must operate on a faster time scale than the variation of the input. Further, during these fast dynamics such networks typically “disable” learning, updating synaptic weights only once the fixed-point iteration has been resolved. Here, we derive a network for PCA-based dimensionality reduction that avoids this fast fixed-point iteration. The key novelty of our approach is a modification of the similarity matching objective to encourage near-diagonality of a synaptic weight matrix. We then approximately invert this matrix using a Taylor series approximation, replacing the previous fast iterations. In the offline setting, our algorithm corresponds to a dynamical system, the stability of which we rigorously analyze. In the online setting (i.e., with stochastic gradients), we map our algorithm to a familiar neural network architecture and give numerical results showing that our method converges at a competitive rate. The computational complexity per iteration of our online algorithm is linear in the total degrees of freedom, which is in some sense optimal.},
	author = {Minden, Victor and Pehlevan, Cengiz and Chklovskii, Dmitri B},
	year = {2019},
	keywords = {merged\_fiete.bib},
}

@article{pehlevan_hebbiananti-hebbian_2019,
	title = {A {Hebbian}/{Anti}-{Hebbian} {Network} {Derived} from {Online} {Non}-{Negative} {Matrix} {Factorization} {Can} {Cluster} and {Discover} {Sparse} {Features}},
	abstract = {Despite our extensive knowledge of biophysical properties of neurons, there is no commonly accepted algorithmic theory of neuronal function. Here we explore the hypothesis that single-layer neuronal networks perform online symmetric nonnegative matrix factorization (SNMF) of the similarity matrix of the streamed data. By starting with the SNMF cost function we derive an online algorithm, which can be implemented by a biologically plausible network with local learning rules. We demonstrate that such network performs soft clustering of the data as well as sparse feature discovery. The derived algorithm replicates many known aspects of sensory anatomy and biophysical properties of neurons including unipolar nature of neuronal activity and synaptic weights, local synaptic plasticity rules and the dependence of learning rate on cumulative neuronal activity. Thus, we make a step towards an algorithmic theory of neuronal function, which should facilitate large-scale neural circuit simulations and biologically inspired artificial intelligence.},
	journal = {arXiv Physics preprint},
	author = {Pehlevan, Cengiz and Chklovskii, Dmitri B},
	year = {2019},
	keywords = {merged\_fiete.bib},
}

@article{chen_self-calibrating_nodate,
	title = {Self-calibrating {Neural} {Networks} for {Dimensionality} {Reduction}},
	abstract = {Recently, a novel family of biologically plausible online algorithms for reducing the dimensionality of streaming data has been derived from the similarity matching principle. In these algorithms, the number of output dimensions can be determined adaptively by thresholding the singular values of the input data matrix. However, setting such threshold requires knowing the magnitude of the desired singular values in advance. Here we propose online algorithms where the threshold is self-calibrating based on the singular values computed from the existing observations. To derive these algorithms from the similarity matching cost function we propose novel regularizers. As before, these online algorithms can be implemented by Hebbian/anti-Hebbian neural networks in which the learning rule depends on the chosen regularizer. We demonstrate both mathematically and via simulation the effectiveness of these online algorithms in various settings.},
	author = {Chen, Yuansi and Pehlevan, Cengiz and Chklovskii, Dmitri B},
	keywords = {merged\_fiete.bib},
}

@article{pehlevan_optimization_2019,
	title = {Optimization theory of {Hebbian}/anti-{Hebbian} networks for {PCA} and whitening},
	abstract = {In analyzing information streamed by sensory organs, our brains face challenges similar to those solved in statistical signal processing. This suggests that biologically plausible implementations of online signal processing algorithms may model neural computation. Here, we focus on such workhorses of signal processing as Principal Component Analysis (PCA) and whitening which maximize information transmission in the presence of noise. We adopt the similarity matching framework, recently developed for principal subspace extraction, but modify the existing objective functions by adding a decorrelating term. From the modified objective functions, we derive online PCA and whitening algorithms which are implementable by neural networks with local learning rules, i.e. synaptic weight updates that depend on the activity of only pre- and postsynaptic neurons. Our theory offers a principled model of neural computations and makes testable predictions such as the dropout of underutilized neurons.},
	journal = {arXiv Physics preprint},
	author = {Pehlevan, Cengiz and Chklovskii, Dmitri B},
	year = {2019},
	keywords = {merged\_fiete.bib},
}

@article{wimmer_thalamic_2015,
	title = {Thalamic control of sensory selection in divided attention},
	volume = {526},
	abstract = {How the brain selects appropriate sensory inputs and suppresses distractors is unknown. Given the well-established role of the prefrontal cortex (PFC) in executive function, its interactions with sensory cortical areas during attention have been hypothesized to control sensory selection. To test this idea and, more generally, dissect the circuits underlying sensory selection, we developed a cross-modal divided-attention task in mice that allowed genetic access to this cognitive process. By optogenetically perturbing PFC function in a temporally precise window, the ability of mice to select appropriately between conflicting visual and auditory stimuli was diminished. Equivalent sensory thalamocortical manipulations showed that behaviour was causally dependent on PFC interactions with the sensory thalamus, not sensory cortex. Consistent with this notion, we found neurons of the visual thalamic reticular nucleus (visTRN) to exhibit PFC-dependent changes in firing rate predictive of the modality selected. visTRN activity was causal to performance as confirmed by bidirectional optogenetic manipulations of this subnetwork. Using a combination of electrophysiology and intracellular chloride photometry, we demonstrated that visTRN dynamically controls visual thalamic gain through feedforward inhibition. Our experiments introduce a new subcortical model of sensory selection, in which the PFC biases thalamic reticular subnetworks to control thalamic sensory gain, selecting appropriate inputs for further processing.},
	number = {7575},
	journal = {Nature},
	author = {Wimmer, Ralf D and Schmitt, L Ian and Davidson, Thomas J and Nakajima, Miho and Deisseroth, Karl and Halassa, Michael M},
	month = oct,
	year = {2015},
	keywords = {merged\_fiete.bib},
	pages = {705--709},
}

@article{halassa_thalamic_2017,
	title = {Thalamic functions in distributed cognitive control},
	volume = {20},
	abstract = {Cognition can be conceptualized as a set of algorithmic control functions whose real-time deployment determines how an organism stores and uses information to guide thought and action. A subset of these functions is required for goal-directed selection and amplification of sensory signals-broadly referred to as attention-and for its flexible control and its interaction with processes such as working memory and decision making. While the contribution of recurrent cortical microcircuits to cognition has been extensively studied, the role of the thalamus is just beginning to be elucidated. Here we highlight recent studies across rodents and primates showing how thalamus contributes to attentional control. In addition to high-fidelity information relay to or between cortical regions, thalamic circuits shift and sustain functional interactions within and across cortical areas. This thalamic process enables rapid coordination of spatially segregated cortical computations, thereby constructing task-relevant functional networks. Because such function may be critical for cognitive flexibility, clarifying its mechanisms will likely expand our basic understanding of cognitive control and its perturbation in disease.},
	number = {12},
	journal = {Nat. Neurosci.},
	author = {Halassa, Michael M and Kastner, Sabine},
	month = dec,
	year = {2017},
	keywords = {merged\_fiete.bib},
	pages = {1669--1679},
}

@article{rikhye_toward_2018,
	title = {Toward an {Integrative} {Theory} of {Thalamic} {Function}},
	volume = {41},
	abstract = {The thalamus has long been suspected to have an important role in cognition, yet recent theories have favored a more corticocentric view. According to this view, the thalamus is an excitatory feedforward relay to or between cortical regions, and cognitively relevant computations are exclusively cortical. Here, we review anatomical, physiological, and behavioral studies along evolutionary and theoretical dimensions, arguing for essential and unique thalamic computations in cognition. Considering their architectural features as well as their ability to initiate, sustain, and switch cortical activity, thalamic circuits appear uniquely suited for computing contextual signals that rapidly reconfigure task-relevant cortical representations. We introduce a framework that formalizes this notion, show its consistency with several findings, and discuss its prediction of thalamic roles in perceptual inference and behavioral flexibility. Overall, our framework emphasizes an expanded view of the thalamus in cognitive computations and provides a roadmap to test several of its theoretical and experimental predictions.},
	journal = {Annu. Rev. Neurosci.},
	author = {Rikhye, Rajeev V and Wimmer, Ralf D and Halassa, Michael M},
	year = {2018},
	keywords = {thalamus, merged\_fiete.bib, neocortex, brain development, cognition, cortical microcircuits, predictive coding},
	pages = {163--183},
}

@article{aronov_mapping_2017,
	title = {Mapping of a non-spatial dimension by the hippocampal-entorhinal circuit},
	volume = {543},
	abstract = {During spatial navigation, neural activity in the hippocampus and the medial entorhinal cortex (MEC) is correlated to navigational variables such as location, head direction, speed, and proximity to boundaries. These activity patterns are thought to provide a map-like representation of physical space. However, the hippocampal-entorhinal circuit is involved not only in spatial navigation, but also in a variety of memory-guided behaviours. The relationship between this general function and the specialized spatial activity patterns is unclear. A conceptual framework reconciling these views is that spatial representation is just one example of a more general mechanism for encoding continuous, task-relevant variables. Here we tested this idea by recording from hippocampal and entorhinal neurons during a task that required rats to use a joystick to manipulate sound along a continuous frequency axis. We found neural representation of the entire behavioural task, including activity that formed discrete firing fields at particular sound frequencies. Neurons involved in this representation overlapped with the known spatial cell types in the circuit, such as place cells and grid cells. These results suggest that common circuit mechanisms in the hippocampal-entorhinal system are used to represent diverse behavioural tasks, possibly supporting cognitive processes beyond spatial navigation.},
	number = {7647},
	journal = {Nature},
	author = {Aronov, Dmitriy and Nevers, Rhino and Tank, David W},
	year = {2017},
	keywords = {merged\_fiete.bib, abstract cognitive grid cells non-spatial hippocampus},
	pages = {719--722},
}

@article{meister_neurons_2018,
	title = {Neurons in {Primate} {Entorhinal} {Cortex} {Represent} {Gaze} {Position} in {Multiple} {Spatial} {Reference} {Frames}},
	volume = {38},
	abstract = {Primates rely predominantly on vision to gather information from the environment and neurons representing visual space and gaze position are found in many brain areas. Within the medial temporal lobe, a brain region critical for memory, neurons in the entorhinal cortex of macaque monkeys exhibit spatial selectivity for gaze position. Specifically, the firing rate of single neurons reflects fixation location within a visual image (Killian et al., 2012). In the rodents, entorhinal cells such as grid cells, border cells, and head direction cells show spatial representations aligned to visual environmental features instead of the body (Hafting et al., 2005; Sargolini et al., 2006; Solstad et al., 2008; Diehl et al., 2017). However, it is not known whether similar allocentric representations exist in primate entorhinal cortex. Here, we recorded neural activity in the entorhinal cortex in two male rhesus monkeys during a naturalistic, free-viewing task. Our data reveal that a majority of entorhinal neurons represent gaze position and that simultaneously recorded neurons represent gaze position relative to distinct spatial reference frames, with some neurons aligned to the visual image and others aligned to the monkey's head position. Our results also show that entorhinal neural activity can be used to predict gaze position with a high degree of accuracy. These findings demonstrate that visuospatial representation is a fundamental property of entorhinal neurons in primates and suggest that entorhinal cortex may support relational memory and motor planning by coding attentional locus in distinct, behaviorally relevant frames of reference.SIGNIFICANCE STATEMENT The entorhinal cortex, a brain area important for memory, shows striking spatial activity in rodents through grid cells, border cells, head direction cells, and nongrid spatial cells. The majority of entorhinal neurons signal the location of a rodent relative to visual environmental cues, representing the location of the animal relative to space in the world instead of the body. Recently, we found that entorhinal neurons can signal location of gaze while a monkey explores images visually. Here, we report that spatial entorhinal neurons are widespread in the monkey and these neurons are capable of showing a world-based spatial reference frame locked to the bounds of explored images. These results help connect the extensive findings in rodents to the primate.},
	number = {10},
	journal = {J. Neurosci.},
	author = {Meister, Miriam L R and Buffalo, Elizabeth A},
	month = mar,
	year = {2018},
	keywords = {entorhinal cortex, merged\_fiete.bib, memory, grid cell, medial temporal lobe, primate, reference frame},
	pages = {2430--2441},
}

@article{killian_grid_2018,
	title = {Grid cells map the visual world},
	volume = {21},
	number = {2},
	journal = {Nat. Neurosci.},
	author = {Killian, Nathaniel J and Buffalo, Elizabeth A},
	month = feb,
	year = {2018},
	keywords = {merged\_fiete.bib, abstract cognitive grid cells non-spatial hippocampus},
	pages = {161--162},
}

@article{wilming_entorhinal_2018,
	title = {Entorhinal cortex receptive fields are modulated by spatial attention, even without movement},
	volume = {7},
	abstract = {Grid cells in the entorhinal cortex allow for the precise decoding of position in space. Along with potentially playing an important role in navigation, grid cells have recently been hypothesized to make a general contribution to mental operations. A prerequisite for this hypothesis is that grid cell activity does not critically depend on physical movement. Here, we show that movement of covert attention, without any physical movement, also elicits spatial receptive fields with a triangular tiling of space. In monkeys trained to maintain central fixation while covertly attending to a stimulus moving in the periphery we identified a significant population (20/141, 14\% neurons at a FDR {\textless}5\%) of entorhinal cells with spatially structured receptive fields. This contrasts with recordings obtained in the hippocampus, where grid-like representations were not observed. Our results provide evidence that neurons in macaque entorhinal cortex do not rely on physical movement.},
	journal = {Elife},
	author = {Wilming, Niklas and König, Peter and König, Seth and Buffalo, Elizabeth A},
	year = {2018},
	keywords = {merged\_fiete.bib, abstract cognitive grid cells non-spatial hippocampus attention},
}

@article{constantinescu_organizing_2016,
	title = {Organizing conceptual knowledge in humans with a gridlike code},
	volume = {352},
	abstract = {It has been hypothesized that the brain organizes concepts into a mental map, allowing conceptual relationships to be navigated in a manner similar to that of space. Grid cells use a hexagonally symmetric code to organize spatial representations and are the likely source of a precise hexagonal symmetry in the functional magnetic resonance imaging signal. Humans navigating conceptual two-dimensional knowledge showed the same hexagonal signal in a set of brain regions markedly similar to those activated during spatial navigation. This gridlike signal is consistent across sessions acquired within an hour and more than a week apart. Our findings suggest that global relational codes may be used to organize nonspatial conceptual representations and that these codes may have a hexagonal gridlike pattern when conceptual knowledge is laid out in two continuous dimensions.},
	number = {6292},
	journal = {Science},
	author = {Constantinescu, Alexandra O and O'Reilly, Jill X and Behrens, Timothy E J},
	month = jun,
	year = {2016},
	keywords = {merged\_fiete.bib, abstract cognitive grid cells non-spatial hippocampus},
	pages = {1464--1468},
}

@article{wang_disinhibitory_2018,
	title = {A disinhibitory circuit motif and flexible information routing in the brain},
	volume = {49},
	abstract = {In the mammalian neocortex, an area typically receives inputs from, and projects to, dozens of other areas. Mechanisms are needed to flexibly route information to the right place at the right time, which we term 'pathway gating'. For instance, a region in your brain that receives signals from both visual and auditory pathways may want to 'gate in' the visual pathway while 'gating out' the auditory pathway when you try to read a book surrounded by people in a noisy café. In this review, we marshall experimental and computational evidence in support of a circuit mechanism for flexible pathway gating realized by a disinhibitory motif. Moreover, recent work shows an increasing preponderance of this disinhibitory motif from sensory areas to association areas of the mammalian cortex. Pathway input gating is briefly compared with alternative or complementary gating mechanisms. Predictions and open questions for future research on this puzzle about the complex brain system will be discussed.},
	journal = {Curr. Opin. Neurobiol.},
	author = {Wang, Xiao-Jing and Yang, Guangyu Robert},
	year = {2018},
	keywords = {merged\_fiete.bib},
	pages = {75--83},
}

@article{murray_linking_2014,
	title = {Linking microcircuit dysfunction to cognitive impairment: effects of disinhibition associated with schizophrenia in a cortical working memory model},
	volume = {24},
	abstract = {Excitation-inhibition balance (E/I balance) is a fundamental property of cortical microcircuitry. Disruption of E/I balance in prefrontal cortex is hypothesized to underlie cognitive deficits observed in neuropsychiatric illnesses such as schizophrenia. To elucidate the link between these phenomena, we incorporated synaptic disinhibition, via N-methyl-D-aspartate receptor perturbation on interneurons, into a network model of spatial working memory (WM). At the neural level, disinhibition broadens the tuning of WM-related, stimulus-selective persistent activity patterns. The model predicts that this change at the neural level leads to 2 primary behavioral deficits: 1) increased behavioral variability that degrades the precision of stored information and 2) decreased ability to filter out distractors during WM maintenance. We specifically tested the main model prediction, broadened WM representation under disinhibition, using behavioral data from human subjects performing a spatial WM task combined with ketamine infusion, a pharmacological model of schizophrenia hypothesized to induce disinhibition. Ketamine increased errors in a pattern predicted by the model. Finally, as proof-of-principle, we demonstrate that WM deteriorations in the model can be ameliorated by compensations that restore E/I balance. Our findings identify specific ways by which cortical disinhibition affects WM, suggesting new experimental designs for probing the brain mechanisms of WM deficits in schizophrenia.},
	number = {4},
	journal = {Cereb. Cortex},
	author = {Murray, John D and Anticevic, Alan and Gancsos, Mark and Ichinose, Megan and Corlett, Philip R and Krystal, John H and Wang, Xiao-Jing},
	month = apr,
	year = {2014},
	keywords = {merged\_fiete.bib, disinhibition, NMDAR hypofunction, prefrontal cortex, schizophrenia, working memory},
	pages = {859--872},
}

@article{yang_dendritic_2016,
	title = {A dendritic disinhibitory circuit mechanism for pathway-specific gating},
	volume = {7},
	abstract = {While reading a book in a noisy café, how does your brain 'gate in' visual information while filtering out auditory stimuli? Here we propose a mechanism for such flexible routing of information flow in a complex brain network (pathway-specific gating), tested using a network model of pyramidal neurons and three classes of interneurons with connection probabilities constrained by data. We find that if inputs from different pathways cluster on a pyramidal neuron dendrite, a pathway can be gated-on by a disinhibitory circuit motif. The branch-specific disinhibition can be achieved despite dense interneuronal connectivity, even with random connections. Moreover, clustering of input pathways on dendrites can naturally emerge through synaptic plasticity regulated by dendritic inhibition. This gating mechanism in a neural circuit is further demonstrated by performing a context-dependent decision-making task. The model suggests that cognitive flexibility engages top-down signalling of behavioural rule or context that targets specific classes of inhibitory neurons.},
	journal = {Nat. Commun.},
	author = {Yang, Guangyu Robert and Murray, John D and Wang, Xiao-Jing},
	year = {2016},
	keywords = {merged\_fiete.bib},
	pages = {12815},
}

@article{mel_synaptic_2017,
	title = {Synaptic plasticity in dendrites: complications and coping strategies},
	volume = {43},
	abstract = {The elaborate morphology, nonlinear membrane mechanisms and spatiotemporally varying synaptic activation patterns of dendrites complicate the expression, compartmentalization and modulation of synaptic plasticity. To grapple with this complexity, we start with the observation that neurons in different brain areas face markedly different learning problems, and dendrites of different neuron types contribute to the cell's input-output function in markedly different ways. By committing to specific assumptions regarding a neuron's learning problem and its input-output function, specific inferences can be drawn regarding the synaptic plasticity mechanisms and outcomes that we 'ought' to expect for that neuron. Exploiting this assumption-driven approach can help both in interpreting existing experimental data and designing future experiments aimed at understanding the brain's myriad learning processes.},
	journal = {Curr. Opin. Neurobiol.},
	author = {Mel, Bartlett W and Schiller, Jackie and Poirazi, Panayiota},
	year = {2017},
	keywords = {merged\_fiete.bib},
	pages = {177--186},
}

@article{poirazi_impact_2001,
	title = {Impact of active dendrites and structural plasticity on the memory capacity of neural tissue},
	volume = {29},
	abstract = {We consider the combined effects of active dendrites and structural plasticity on the storage capacity of neural tissue. We compare capacity for two different modes of dendritic integration: (1) linear, where synaptic inputs are summed across the entire dendritic arbor, and (2) nonlinear, where each dendritic compartment functions as a separately thresholded neuron-like summing unit. We calculate much larger storage capacities for cells with nonlinear subunits and show that this capacity is accessible to a structural learning rule that combines random synapse formation with activity-dependent stabilization/elimination. In a departure from the common view that memories are encoded in the overall connection strengths between neurons, our results suggest that long-term information storage in neural tissue could reside primarily in the selective addressing of synaptic contacts onto dendritic subunits.},
	number = {3},
	journal = {Neuron},
	author = {Poirazi, P and Mel, B W},
	month = mar,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {779--796},
}

@article{silver_neuronal_2010,
	title = {Neuronal arithmetic},
	volume = {11},
	abstract = {The vast computational power of the brain has traditionally been viewed as arising from the complex connectivity of neural networks, in which an individual neuron acts as a simple linear summation and thresholding device. However, recent studies show that individual neurons utilize a wealth of nonlinear mechanisms to transform synaptic input into output firing. These mechanisms can arise from synaptic plasticity, synaptic noise, and somatic and dendritic conductances. This tool kit of nonlinear mechanisms confers considerable computational power on both morphologically simple and more complex neurons, enabling them to perform a range of arithmetic operations on signals encoded ina variety of different ways.},
	number = {7},
	journal = {Nat. Rev. Neurosci.},
	author = {Silver, R Angus},
	month = jul,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {474--489},
}

@article{georgopoulos_relations_1982,
	title = {On the relations between the direction of two-dimensional arm movements and cell discharge in primate motor cortex},
	volume = {2},
	abstract = {The activity of single cells in the motor cortex was recorded while monkeys made arm movements in eight directions (at 45 degrees intervals) in a two-dimensional apparatus. These movements started from the same point and were of the same amplitude. The activity of 606 cells related to proximal arm movements was examined in the task; 323 of the 606 cells were active in that task and were studied in detail. The frequency of discharge of 241 of the 323 cells (74.6\%) varied in an orderly fashion with the direction of movement. Discharge was most intense with movements in a preferred direction and was reduced gradually when movements were made in directions farther and farther away from the preferred one. This resulted in a bell-shaped directional tuning curve. These relations were observed for cell discharge during the reaction time, the movement time, and the period that preceded the earliest changes in the electromyographic activity (approximately 80 msec before movement onset). In about 75\% of the 241 directionally tuned cells, the frequency of discharge, D, was a sinusoidal function of the direction of movement, theta: D = b0 + b1 sin theta + b2cos theta, or, in terms of the preferred direction, theta 0: D = b0 + c1cos (theta - theta0), where b0, b1, b2, and c1 are regression coefficients. Preferred directions differed for different cells so that the tuning curves partially overlapped. The orderly variation of cell discharge with the direction of movement and the fact that cells related to only one of the eight directions of movement tested were rarely observed indicate that movements in a particular direction are not subserved by motor cortical cells uniquely related to that movement. It is suggested, instead, that a movement trajectory in a desired direction might be generated by the cooperation of cells with overlapping tuning curves. The nature of this hypothetical population code for movement direction remains to be elucidated.},
	number = {11},
	journal = {J. Neurosci.},
	author = {Georgopoulos, A P and Kalaska, J F and Caminiti, R and Massey, J T},
	month = nov,
	year = {1982},
	keywords = {merged\_fiete.bib},
	pages = {1527--1537},
}

@article{taube_head-direction_1990,
	title = {Head-direction cells recorded from the postsubiculum in freely moving rats. {II}. {Effects} of environmental manipulations},
	volume = {10},
	abstract = {The discharge characteristics of postsubicular head-direction cells in a fixed environment were described in the previous paper (Taube et al., 1990). This paper reports changes in the firing properties of head-direction cells following changes in the animal's environment. Head-direction cells were recorded from rats as they moved freely in a 76-cm-diameter gray cylinder. A white card, occupying 100 degrees of arc, was taped to the inside wall of the cylinder and served as the major orienting spatial cue in the animal's environment. Rotation of the cue card produced near-equal rotation in the preferred firing direction of head-direction cells, with minimal changes in peak firing rate, directional firing range, or asymmetry of the firing-rate/head-direction function. Card removal had no effect on peak firing rate or range of firing, but in 8/13 cells the preferred direction rotated by at least 24 degrees. Similarly, changing the shape of the environment to a rectangular or square enclosure caused the preferred firing direction to rotate by at least 48 degrees for 8/10 cells in the rectangle and 3/8 cells in the square, with minimal changes in the peak firing rate or directional firing range. Hand holding the animals and moving them around the cylinder had no effect on the preferred direction or firing range of the cell, but decreased the maximal firing rate in 7/9 cells. On 2 occasions, 2 head-direction cells were recorded simultaneously. The rotation of the preferred firing direction for one cell was the same as the rotation of the preferred direction for the second cell after each environmental manipulation. These results demonstrate that specific visual cues in the environment can exert control over the preferred firing direction and indicate that head-direction cell firing is not a simple sensory response to visual cues, but rather represents more abstract information concerning the animal's spatial relationship with its environment. The constancy of the angle between the preferred firing directions of pairs of simultaneously recorded head-direction cells suggests that there is a fixed mapping of the population onto direction within the environment. Thus, environmental manipulations appear to cause only a change in the reference direction, but leave all other discharge characteristics of directional cells unchanged. In the discussion, comparisons are drawn between the responses of head-direction cells and hippocampal place cells to similar environmental manipulations (Muller and Kubie, 1987), and ways in which these 2 spatial systems interact in navigation are discussed.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {2},
	journal = {J. Neurosci.},
	author = {Taube, J S and Muller, R U and Ranck, Jr, J B},
	month = feb,
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {436--447},
}

@article{yaeli_error-based_2010,
	title = {Error-based analysis of optimal tuning functions explains phenomena observed in sensory neurons},
	volume = {4},
	abstract = {Biological systems display impressive capabilities in effectively responding to environmental signals in real time. There is increasing evidence that organisms may indeed be employing near optimal Bayesian calculations in their decision-making. An intriguing question relates to the properties of optimal encoding methods, namely determining the properties of neural populations in sensory layers that optimize performance, subject to physiological constraints. Within an ecological theory of neural encoding/decoding, we show that optimal Bayesian performance requires neural adaptation which reflects environmental changes. Specifically, we predict that neuronal tuning functions possess an optimal width, which increases with prior uncertainty and environmental noise, and decreases with the decoding time window. Furthermore, even for static stimuli, we demonstrate that dynamic sensory tuning functions, acting at relatively short time scales, lead to improved performance. Interestingly, the narrowing of tuning functions as a function of time was recently observed in several biological systems. Such results set the stage for a functional theory which may explain the high reliability of sensory systems, and the utility of neuronal adaptation occurring at multiple time scales.},
	journal = {Front. Comput. Neurosci.},
	author = {Yaeli, Steve and Meir, Ron},
	year = {2010},
	keywords = {population coding, merged\_fiete.bib, Bayesian decoding, Fisher information, neural encoding, optimal width, tuning functions},
	pages = {130},
}

@article{paradiso_theory_1988,
	title = {A theory for the use of visual orientation information which exploits the columnar structure of striate cortex},
	volume = {58},
	number = {1},
	journal = {Biol. Cybern.},
	author = {Paradiso, M A},
	year = {1988},
	note = {Publisher: Springer Berlin / Heidelberg},
	keywords = {merged\_fiete.bib, Computer Science},
	pages = {35--49},
}

@article{seung_simple_1993,
	title = {Simple models for reading neuronal population codes},
	volume = {90},
	abstract = {In many neural systems, sensory information is distributed throughout a population of neurons. We study simple neural network models for extracting this information. The inputs to the networks are the stochastic responses of a population of sensory neurons tuned to directional stimuli. The performance of each network model in psychophysical tasks is compared with that of the optimal maximum likelihood procedure. As a model of direction estimation in two dimensions, we consider a linear network that computes a population vector. Its performance depends on the width of the population tuning curves and is maximal for width, which increases with the level of background activity. Although for narrowly tuned neurons the performance of the population vector is significantly inferior to that of maximum likelihood estimation, the difference between the two is small when the tuning is broad. For direction discrimination, we consider two models: a perceptron with fully adaptive weights and a network made by adding an adaptive second layer to the population vector network. We calculate the error rates of these networks after exhaustive training to a particular direction. By testing on the full range of possible directions, the extent of transfer of training to novel stimuli can be calculated. It is found that for threshold linear networks the transfer of perceptual learning is nonmonotonic. Although performance deteriorates away from the training stimulus, it peaks again at an intermediate angle. This nonmonotonicity provides an important psychophysical test of these models.},
	number = {22},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Seung, H S and Sompolinsky, H},
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {10749--10753},
}

@article{cover_capacity_1979,
	title = {Capacity theorems for the relay channel},
	volume = {25},
	number = {5},
	journal = {IEEE Trans. Inf. Theory},
	author = {Cover, T and Gamal, A E},
	month = sep,
	year = {1979},
	keywords = {Statistics, Information theory, merged\_fiete.bib, Chaotic communication, Error correction, Error correction codes, Fast Fourier transforms, Feedback, Information rates, Relays, Repeaters, Signal representations, Spectroscopy},
	pages = {572--584},
}

@article{hargreaves_major_2005,
	title = {Major {Dissociation} {Between} {Medial} and {Lateral} {Entorhinal} {Input} to {Dorsal} {Hippocampus}},
	volume = {308},
	number = {5729},
	journal = {Science},
	author = {Hargreaves, Eric L and Rao, Geeta and Lee, Inah and Knierim, James J},
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {1792--1794},
}

@book{dayan_theoretical_2001-1,
	address = {Cambridge, Mass.},
	title = {Theoretical neuroscience : computational and mathematical modeling of neural systems},
	publisher = {Massachusetts Institute of Technology Press},
	author = {Dayan, Peter and Abbott, L F},
	year = {2001},
	keywords = {merged\_fiete.bib},
}

@inproceedings{roumy_rate-adaptive_2007,
	title = {Rate-adaptive turbo-syndrome scheme for {Slepian}-{Wolf} {Coding}},
	booktitle = {Signals, {Systems} and {Computers}, 2007. {ACSSC} 2007. {Conference} {Record} of the {Forty}-{First} {Asilomar} {Conference} on},
	author = {Roumy, A and Lajnef, K and Guillemot, C},
	year = {2007},
	keywords = {merged\_fiete.bib, Bit error rate, Convolutional codes, Decoding, Degradation, distributed source coding, Entropy, Image coding, optimal decoding, Parity check codes, rate-adaptive turbo-syndrome scheme, Slepian-Wolf coding, source coding, Source coding, Turbo codes, Video compression},
	pages = {545--549},
}

@article{liveris_compression_2002,
	title = {Compression of binary sources with side information at the decoder using {LDPC} codes},
	volume = {6},
	number = {10},
	journal = {Communications Letters, IEEE},
	author = {Liveris, A D and Xiong, Zixiang and Georghiades, C N},
	year = {2002},
	keywords = {merged\_fiete.bib, LDPC},
	pages = {440--442},
}

@inproceedings{santhi_analog_2003,
	title = {Analog codes on graphs},
	booktitle = {Information {Theory}, 2003. {Proceedings}. {IEEE} {International} {Symposium} on},
	author = {Santhi, N and Vardy, A},
	year = {2003},
	keywords = {merged\_fiete.bib, information theory, Degradation, additive white Gaussian noise, Additive white noise, analog code, AWGN channels, band-limited AWGN channel, bandwidth efficient code, binary codes, Binary codes, broadcast channel, broadcast channels, Broadcasting, capacity-approaching code, channel capacity, combined coding, combined modulation, Gaussian noise, information rate degradation, iterative decoder, iterative decoding, Iterative decoding, Modulation coding, MPSK cutoff rate, multiple phase shift keying, phase shift keying, Shannon capacity, Signal to noise ratio, signal-to-noise ratio, SNR, Sum product algorithm, sum-product algorithm, superposition strategy},
	pages = {13--},
}

@article{wilson_joint_2010,
	title = {Joint {Source} {Channel} {Coding} {With} {Side} {Information} {Using} {Hybrid} {Digital} {Analog} {Codes}},
	volume = {56},
	number = {10},
	journal = {IEEE Trans. Inf. Theory},
	author = {Wilson, M P and Narayanan, K and Caire, G},
	year = {2010},
	keywords = {merged\_fiete.bib, Decoding, Signal to noise ratio, bandwidth compression, Channel coding, channel signal-to-noise ratio mismatch, combined source-channel coding, Costa coding schemes, Dirty paper coding, Gaussian channel, Gaussian channels, Gaussian source, hybrid digital analog codes, hybrid digital analog coding, Interference, joint source channel coding, Joints, lossy multicasting, mean-squared error distortion, Quantization, random coding, side information, Wyner-Ziv coding schemes, Wyner–Ziv coding},
	pages = {4922--4940},
}

@article{pradhan_distributed_2003,
	title = {Distributed source coding using syndromes ({DISCUS}): design and construction},
	volume = {49},
	number = {3},
	journal = {IEEE Trans. Inf. Theory},
	author = {Pradhan, S S and Ramchandran, K},
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {626--643},
}

@article{slepian_noiseless_1973,
	title = {Noiseless coding of correlated information sources},
	volume = {19},
	number = {4},
	journal = {IEEE Trans. Inf. Theory},
	author = {Slepian, D and Wolf, J K},
	year = {1973},
	keywords = {merged\_fiete.bib, Decoding, Source coding, Block codes, Error probability, Probability distribution, Random variables, Region 9},
	pages = {471--480},
}

@inproceedings{yoo_dynamic_2012,
	title = {Dynamic shift-map coding with side information at the decoder},
	booktitle = {Communication, {Control}, and {Computing} ({Allerton}), 2012 50th {Annual} {Allerton} {Conference} on},
	author = {Yoo, Yongseok and Koyluoglu, O O and Vishwanath, S and Fiete, I},
	year = {2012},
	keywords = {merged\_fiete.bib, Decoding, Signal to noise ratio, signal-to-noise ratio, SNR, Channel coding, combined source-channel coding, Joints, side information, continuous source codes, decoder, decoding, dynamic shift-map coding scheme, encoding process, fixed encoding scheme, Hypercubes, joint source-channel codes, mean square error, redundant residue number systems, RRNS-map codes},
	pages = {632--639},
}

@inproceedings{sun_neural-like_1994-1,
	title = {A neural-like network approach to residue-to-decimal conversion},
	volume = {6},
	booktitle = {Neural {Networks}, 1994. {IEEE} {World} {Congress} on {Computational} {Intelligence}., 1994 {IEEE} {International} {Conference} on},
	author = {Sun, Hong and Yao, Tian-Ren},
	year = {1994},
	keywords = {merged\_fiete.bib, neural chips, neural-like network, residue number systems, residue reduction, residue-to-decimal conversion},
	pages = {3883--3887 vol.6},
}

@article{cover_multiple_1980,
	title = {Multiple access channels with arbitrarily correlated sources},
	volume = {26},
	number = {6},
	journal = {IEEE Trans. Inf. Theory},
	author = {Cover, T and Gamal, A E and Salehi, M},
	year = {1980},
	keywords = {merged\_fiete.bib, Source coding, Data compression, Multiple-access communications},
	pages = {648--657},
}

@inproceedings{soundararajan_communicating_2009,
	title = {Communicating the {Difference} of {Correlated} {Gaussian} {Sources} over a {MAC}},
	booktitle = {Data {Compression} {Conference}},
	author = {Soundararajan, R and Vishwanath, S},
	year = {2009},
	keywords = {merged\_fiete.bib, access protocols, additive Gaussian noise multiple access channel, alternative lattice coding scheme, correlated Gaussian sources, Gaussian processes, MAC, mean square error methods, multi-access systems, multiple access channel, signal to noise ratio},
	pages = {282--291},
}

@article{gastpar_uncoded_2008,
	title = {Uncoded {Transmission} {Is} {Exactly} {Optimal} for a {Simple} {Gaussian} {Sensor} {Network}},
	volume = {54},
	number = {11},
	journal = {IEEE Trans. Inf. Theory},
	author = {Gastpar, M},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {5247--5251},
}

@article{goblick_theoretical_1965,
	title = {Theoretical limitations on the transmission of data from analog sources},
	volume = {11},
	number = {4},
	journal = {IEEE Trans. Inf. Theory},
	author = {Goblick, T, Jr},
	month = oct,
	year = {1965},
	keywords = {Information theory, merged\_fiete.bib, Modulation/demodulation, Rate-distortion theory},
	pages = {558--567},
}

@article{gastpar_code_2003,
	title = {To code, or not to code: lossy source-channel communication revisited},
	volume = {49},
	number = {5},
	journal = {IEEE Trans. Inf. Theory},
	author = {Gastpar, M and Rimoldi, B and Vetterli, M},
	month = may,
	year = {2003},
	keywords = {merged\_fiete.bib, broadcast channels, combined source-channel coding, decoder, decoding, channel conditional distribution, channel input cost function, channel input symbol, closed-form necessary expression, closed-form sufficient expression, codes, communication, distortion measure, encoder, joint source-channel coding, lossy source-channel communication, multiuser channels, multiuser communication, nonergodic scenario, optimal cost-distortion tradeoff, optimal single-source broadcast communication, optimal uncoded communication, optimisation, probabilistic matching, probability, separation-based approach, single-letter codes, source distribution, source output symbol, source reconstruction symbol, source-channel communication system},
	pages = {1147--1158},
}

@article{sun_coding_1992,
	title = {A coding theory approach to error control in redundant residue number systems. {II}. {Multiple} error detection and correction},
	volume = {39},
	number = {1},
	journal = {Circuits and Systems II: Analog and Digital Signal Processing, IEEE Transactions on},
	author = {Sun, J-D and Krishna, H},
	month = jan,
	year = {1992},
	keywords = {merged\_fiete.bib, decoding, redundant residue number systems, coding theory, computational complexity, computationally efficient algorithms, digital arithmetic, encoding, error control, error correction codes, error detection, error detection codes, multiple errors, redundancy, single-burst-error},
	pages = {18--34},
}

@article{krishna_coding_1992,
	title = {A coding theory approach to error control in redundant residue number systems. {I}. {Theory} and single error correction},
	volume = {39},
	number = {1},
	journal = {Circuits and Systems II: Analog and Digital Signal Processing, IEEE Transactions on},
	author = {Krishna, H and Lin, K-Y and Sun, J-D},
	month = jan,
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {8--17},
}

@article{watson_self-checked_1966,
	title = {Self-checked computation using residue arithmetic},
	volume = {54},
	number = {12},
	journal = {Proc. IEEE},
	author = {Watson, R W and Hastings, C W},
	year = {1966},
	keywords = {merged\_fiete.bib},
	pages = {1920--1931},
}

@article{baake_remarks_1994,
	title = {Some remarks on the visible points of a lattice},
	volume = {27},
	abstract = {We comment on the set of visible points of a lattice and its Fourier transform, thus continuing and generalizing previous work by Schroeder (1982) and Mosseri (1992). A closed formula in terms of Dirichlet series is obtained for the Bragg part of the Fourier transform. We compare this calculation with the outcome of an optical Fourier transform of the visible points of the 2D square lattice.},
	number = {8},
	journal = {J. Phys. A Math. Gen.},
	author = {Baake, M and Grimm, U and Warrington, D H},
	year = {1994},
	keywords = {merged\_fiete.bib},
}

@article{forney_modulation_1998,
	title = {Modulation and coding for linear {Gaussian} channels},
	volume = {44},
	number = {6},
	journal = {IEEE Trans. Inf. Theory},
	author = {Forney, G.D, Jr and Ungerboeck, G},
	month = oct,
	year = {1998},
	keywords = {merged\_fiete.bib, channel capacity, SNR, Gaussian channels, decoding, encoding, binary coding, combined coding/precoding, high-signal-to-noise ratio, intersymbol-interference channels, linear Gaussian channels, low-signal-to-noise ratio, modulation, multilevel coding, nonbinary coding, orthogonal minimum-bandwidth modulation, review, reviews, turbo coding, turbo decoding},
	pages = {2384--2415},
}

@book{soderstrand_residue_1986,
	address = {Piscataway, NJ, USA},
	title = {Residue number system arithmetic: modern applications in digital signal processing},
	publisher = {IEEE Press},
	editor = {Soderstrand, Michael A and Jenkins, W Kenneth and Jullien, Graham A and Taylor, Fred J},
	year = {1986},
	keywords = {merged\_fiete.bib},
}

@article{wyner_rate-distortion_1976,
	title = {The rate-distortion function for source coding with side information at the decoder},
	volume = {22},
	number = {1},
	journal = {IEEE Trans. Inf. Theory},
	author = {Wyner, A and Ziv, J},
	year = {1976},
	keywords = {merged\_fiete.bib, Rate-distortion theory},
	pages = {1--10},
}

@article{wyner_source_1975,
	title = {On source coding with side information at the decoder},
	volume = {21},
	number = {3},
	journal = {IEEE Trans. Inf. Theory},
	author = {Wyner, A},
	year = {1975},
	keywords = {merged\_fiete.bib, Source coding},
	pages = {294--300},
}

@article{okeefe_hippocampus_1979,
	title = {The hippocampus as a cognitive map},
	volume = {2},
	number = {04},
	journal = {Behav. Brain Sci.},
	author = {O'Keefe, John and Nadel, Lynn},
	year = {1979},
	keywords = {hippocampus, merged\_fiete.bib, memory, cognitive map, spatial representation},
	pages = {487--494},
}

@article{barber_quickhull_1996,
	title = {The {Quickhull} algorithm for convex hulls},
	volume = {22},
	number = {4},
	journal = {ACM Trans. Math. Softw.},
	author = {Barber, C Bradford and Dobkin, David P and Huhdanpaa, Hannu},
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {469--483},
}

@article{shannon_communication_1949,
	title = {Communication in the {Presence} of {Noise}},
	volume = {37},
	abstract = {A method is developed for representing any communication system geometrically. Messages and the corresponding signals are points in two “function spaces,” and the modulation process is a mapping of one space into the other. Using this representation, a number of results in communication theory are deduced concerning expansion and compression of bandwidth and the threshold effect. Formulas are found for the maxmum rate of transmission of binary digits over a system when the signal is perturbed by various types of noise. Some of the properties of “ideal” systems which transmit at this maxmum rate are discussed. The equivalent number of binary digits per second for certain information sources is calculated.},
	number = {1},
	journal = {Proceedings of the IRE},
	author = {Shannon, C E},
	year = {1949},
	keywords = {merged\_fiete.bib, capacity, bandwidth, noise, power, shannon},
	pages = {10--21},
}

@article{ziv_behavior_1970,
	title = {The behavior of analog communication systems},
	volume = {16},
	number = {5},
	journal = {IEEE Trans. Inf. Theory},
	author = {Ziv, J},
	year = {1970},
	keywords = {merged\_fiete.bib, Modulation/demodulation, Rate-distortion theory},
	pages = {587--594},
}

@article{gordon_values_1941,
	title = {Values of {Mills}' {Ratio} of {Area} to {Bounding} {Ordinate} and of the {Normal} {Probability} {Integral} for {Large} {Values} of the {Argument}},
	volume = {12},
	number = {3},
	journal = {Ann. Math. Stat.},
	author = {Gordon, Robert D},
	month = sep,
	year = {1941},
	keywords = {merged\_fiete.bib},
	pages = {364--366},
}

@article{goldsmith_capacity_1997,
	title = {Capacity of fading channels with channel side information},
	volume = {43},
	number = {6},
	journal = {IEEE Trans. Inf. Theory},
	author = {Goldsmith, A J and Varaiya, P P},
	month = nov,
	year = {1997},
	keywords = {merged\_fiete.bib, channel capacity, Shannon capacity, decoding, encoding, capacity penalty, channel side information, fading, log-normal fading, Nakagami fading, optimal power adaptation, radio receivers, radio transmitters, Rayleigh channels, Rayleigh fading, receiver, time-invariant frequency-selective fading channels, transmitter, water-pouring in frequency, water-pouring in time},
	pages = {1986--1992},
}

@inproceedings{chung_degrees_2001,
	title = {Degrees of freedom in adaptive modulation: a unified view},
	volume = {2},
	booktitle = {Vehicular {Technology} {Conference}, 2001. {VTC} 2001 {Spring}. {IEEE} {VTS} 53rd},
	author = {Chung, Seong Taek and Goldsmith, A},
	year = {2001},
	keywords = {merged\_fiete.bib, adaptive modulation, average BER constraints, channel quality, continuous-rate adaptation, data rate, degrees of freedom, discrete-rate adaptation, error statistics, fading channels, flat-fading channels, instantaneous BER, next generation wireless systems, radio links, spectral efficiency maximization, transmit power},
	pages = {1267--1271 vol.2},
}

@article{vaishampayan_curves_2003,
	title = {Curves on a sphere, shift-map dynamics, and error control for continuous alphabet sources},
	volume = {49},
	number = {7},
	journal = {IEEE Trans. Inf. Theory},
	author = {Vaishampayan, V A and Costa, S I R},
	year = {2003},
	keywords = {merged\_fiete.bib, source coding, Gaussian channel, Gaussian channels, decoding, error control, error correction codes, channel signal-to-noise ratio, continuous alphabet sources, decoding algorithm, discrete time systems, discrete-time source, dynamical systems, exponentially chirped modulation codes, fixed bandwidth expansion, geometric parameters, homogeneous spherical code, lattice, linear dynamical system, mean squared error, modulation coding, modulation systems, scaling behavior, shift-map dynamics},
	pages = {1658--1672},
}

@article{chen_analog_1998,
	title = {Analog error-correcting codes based on chaotic dynamical systems},
	volume = {46},
	number = {7},
	journal = {Communications, IEEE Transactions on},
	author = {Chen, B and Wornell, G W},
	month = jul,
	year = {1998},
	keywords = {merged\_fiete.bib, broadcast channels, signal-to-noise ratio, decoding, error correction codes, fading, analog error-correcting codes, channel coding, chaos, chaotic dynamical systems, digital codes, fast decoding algorithm, linear modulation, low delay communication, multiple channels, nonlinear dynamical systems, nonlinear state-space system, optimization, practical communication applications, state-space methods, tent map dynamics, time-varying channels, time-varying SNR channels},
	pages = {881--890},
}

@article{taherzadeh_single-sample_2012,
	title = {Single-{Sample} {Robust} {Joint} {Source}-{Channel} {Coding}: {Achieving} {Asymptotically} {Optimum} {Scaling} of {SDR} {Versus} {SNR}},
	volume = {58},
	number = {3},
	journal = {IEEE Trans. Inf. Theory},
	author = {Taherzadeh, M and Khandani, A K K},
	month = mar,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {1565--1577},
}

@article{grossberg_contour_1973,
	title = {Contour enhancement, short-term memory, and constancies in reverberating neural networks},
	volume = {52},
	number = {213-257},
	journal = {Stud. Appl. Math.},
	author = {Grossberg, S},
	year = {1973},
	keywords = {merged\_fiete.bib},
}

@article{brown_optimal_2006,
	title = {Optimal {Neuronal} {Tuning} for {Finite} {Stimulus} {Spaces}},
	volume = {18},
	number = {7},
	journal = {Neural Comput.},
	author = {Brown, W and Bäcker, A},
	month = jul,
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {1511--1526},
}

@article{alon_robustness_1999,
	title = {Robustness in bacterial chemotaxis},
	volume = {397},
	number = {6715},
	journal = {Nature},
	author = {Alon, U and Surette, M G and Barkai, N and Leibler, S},
	year = {1999},
	note = {Publisher: Nature Publishing Group},
	keywords = {merged\_fiete.bib},
	pages = {168--171},
}

@article{balasubramanian_statistical_1997,
	title = {Statistical {Inference}, {Occam}'s {Razor}, and {Statistical} {Mechancs} of the {Space} of {Probability} {Distributions}},
	volume = {9},
	number = {3},
	journal = {Neural Comput.},
	author = {Balasubramanian, V},
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {349--368},
}

@article{bengio_greedy_2007,
	title = {Greedy layer-wise training of deep networks},
	volume = {19},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Bengio, Yoshua and Lamblin, Pascal and Popovici, Dan and Larochelle, Hugo},
	year = {2007},
	note = {Publisher: MIT; 1998},
	keywords = {merged\_fiete.bib},
	pages = {153},
}

@article{le_building_2012,
	title = {Building high-level features using large scale unsupervised learning},
	journal = {International Conference in Machine Learning},
	author = {Le, Quoc and Ranzato, Marc'aurelio and Monga, Rajat and Devin, Matthieu and Chen, Kai and Corrado, Greg and Dean, Jeff and Ng, Andrew},
	year = {2012},
	keywords = {merged\_fiete.bib},
}

@article{krizhevsky_imagenet_2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	journal = {Advances in Neural Information Processing Systems 25},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	year = {2012},
	note = {Publisher: Curran Associates, Inc.},
	keywords = {merged\_fiete.bib},
	pages = {1097--1105},
}

@article{sarikaya_application_2014,
	title = {Application of {Deep} {Belief} {Networks} for {Natural} {Language} {Understanding}},
	journal = {IEEE Trans. Audio Speech Lang. Processing},
	author = {Sarikaya, Ruhi and Hinton, Geoffrey and Deoras, Anoop},
	year = {2014},
	keywords = {merged\_fiete.bib},
}

@article{hinton_deep_2012,
	title = {Deep neural networks for acoustic modeling in speech recognition: {The} shared views of four research groups},
	volume = {29},
	number = {6},
	journal = {Signal Processing Magazine},
	author = {Hinton, Geoff and Deng, Li and Yu, Dong and Dahl, G E and Mohamed, A and Jaitly, N and Senior, A and Vanhoucke, V and Nguyen, P and Sainath, T N and Kingsbury, B},
	year = {2012},
	note = {Publisher: IEEE},
	keywords = {merged\_fiete.bib},
	pages = {82--97},
}

@article{schneidman_weak_2006,
	title = {Weak pairwise correlations imply strongly correlated neural states in a neural population},
	volume = {440},
	journal = {Nature},
	author = {Schneidman, Elad and Berry, M J and Segev, R and Bialek, W},
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {1007},
}

@article{bialek_physical_2005,
	title = {Physical limits to biochemical signaling},
	volume = {102},
	number = {29},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Bialek, W and Setayeshgar, S},
	year = {2005},
	note = {Publisher: National Acad Sciences},
	keywords = {merged\_fiete.bib},
	pages = {10040},
}

@article{balasubramanian_metabolically_2001,
	title = {Metabolically efficient information processing},
	volume = {13},
	number = {4},
	journal = {Neural Comput.},
	author = {Balasubramanian, V and Kimber, D and Ii, M J B},
	year = {2001},
	note = {Publisher: MIT Press},
	keywords = {merged\_fiete.bib},
	pages = {799--815},
}

@article{baum_maximization_1970,
	title = {A {Maximization} {Technique} {Occurring} in the {Statistical} {Analysis} of {Probabilistic} {Functions} of {Markov} {Chains}},
	volume = {41},
	number = {1},
	journal = {Ann. Math. Stat.},
	author = {Baum, Leonard E and Petrie, Ted and Soules, George and Weiss, Norman},
	year = {1970},
	keywords = {merged\_fiete.bib},
	pages = {164--171},
}

@article{berg_selection_1988,
	title = {Selection of {DNA} binding sites by regulatory proteins},
	volume = {13},
	number = {6},
	journal = {Trends Biochem. Sci.},
	author = {Berg, Otto G and von Hippel, Peter},
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {207--211},
}

@article{bengio_representation_2013,
	title = {Representation learning: {A} review and new perspectives},
	volume = {35},
	number = {8},
	journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
	author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	year = {2013},
	note = {Publisher: IEEE},
	keywords = {merged\_fiete.bib},
	pages = {1798--1828},
}

@article{danino_synchronized_2010,
	title = {A synchronized quorum of genetic clocks},
	volume = {463},
	number = {7279},
	journal = {Nature},
	author = {Danino, T and Mondragón-Palomino, O and Tsimring, L and Hasty, J},
	year = {2010},
	note = {Publisher: Nature Publishing Group},
	keywords = {merged\_fiete.bib},
	pages = {326--330},
}

@article{de_monte_dynamical_2007,
	title = {Dynamical quorum sensing: {Population} density encoded in cellular dynamics},
	volume = {104},
	number = {47},
	journal = {Proceedings of the National Academy of Sciences},
	author = {De Monte, S and d'Ovidio, F and Danø, S and Sørensen, P G},
	year = {2007},
	note = {Publisher: National Acad Sciences},
	keywords = {merged\_fiete.bib},
	pages = {18377},
}

@article{del_rio_thermodynamic_2011,
	title = {The thermodynamic meaning of negative entropy},
	volume = {474},
	number = {7349},
	journal = {Nature},
	author = {Del Rio, L and Berg, J and Renner, R and Dahlsten, O and Vedral, V},
	year = {2011},
	note = {Publisher: Nature Publishing Group},
	keywords = {merged\_fiete.bib},
	pages = {61--63},
}

@article{detwiler_engineering_2000,
	title = {Engineering aspects of enzymatic signal transduction: photoreceptors in the retina},
	volume = {79},
	number = {6},
	journal = {Biophys. J.},
	author = {Detwiler, P B and Ramanathan, S and Sengupta, A and Shraiman, B I},
	year = {2000},
	note = {Publisher: Elsevier},
	keywords = {merged\_fiete.bib},
	pages = {2801--2817},
}

@article{djordjevic_biophysical_2003,
	title = {A {Biophysical} {Approach} to {Transcription} {Factor} {Binding} {Site} {Discovery}},
	volume = {13},
	number = {11},
	journal = {Genome Res.},
	author = {Djordjevic, Marko and Sengupta, Anirvan M and Shraiman, Boris I},
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {2381--2390},
}

@article{drawid_ohmm_2009,
	title = {{OHMM}: a {Hidden} {Markov} {Model} accurately predicting the occupancy of a transcription factor with a self-overlapping binding motif},
	volume = {10},
	number = {1},
	journal = {BMC Bioinformatics},
	author = {Drawid, Amar and Gupta, Nupur and Nagaraj, Vijayalakshmi and Gelinas, Celine and Sengupta, Anirvan},
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {208},
}

@article{eckhardt_modeling_2007,
	title = {Modeling walker synchronization on the {Millennium} {Bridge}},
	volume = {75},
	number = {2},
	journal = {Physical Review E},
	author = {Eckhardt, B and Ott, E and Strogatz, S H and Abrams, D M and McRobie, A},
	year = {2007},
	note = {Publisher: APS},
	keywords = {merged\_fiete.bib},
	pages = {021110},
}

@article{efrati_real-space_2014,
	title = {Real-space renormalization in statistical mechanics},
	volume = {86},
	number = {2},
	journal = {Rev. Mod. Phys.},
	author = {Efrati, Efi and Wang, Zhe and Kolan, Amy and Kadanoff, Leo P},
	year = {2014},
	note = {Publisher: APS},
	keywords = {merged\_fiete.bib},
	pages = {647},
}

@article{endres_maximum_2009,
	title = {Maximum likelihood and the single receptor},
	volume = {103},
	number = {15},
	journal = {Phys. Rev. Lett.},
	author = {Endres, R G and Wingreen, N S},
	year = {2009},
	note = {Publisher: APS},
	keywords = {merged\_fiete.bib},
	pages = {158101},
}

@article{endres_accuracy_2008,
	title = {Accuracy of direct gradient sensing by single cells},
	volume = {105},
	number = {41},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Endres, R G and Wingreen, N S},
	year = {2008},
	note = {Publisher: National Acad Sciences},
	keywords = {merged\_fiete.bib},
	pages = {15749},
}

@article{fuller_external_2010,
	title = {External and internal constraints on eukaryotic chemotaxis},
	volume = {107},
	number = {21},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Fuller, D and Chen, W and Adler, M and Groisman, A and Levine, H and Rappel, W J and Loomis, W F},
	year = {2010},
	note = {Publisher: National Acad Sciences},
	keywords = {merged\_fiete.bib},
	pages = {9656},
}

@article{hu_physical_2010,
	title = {Physical limits on cellular sensing of spatial gradients},
	volume = {105},
	number = {4},
	journal = {Phys. Rev. Lett.},
	author = {Hu, B and Chen, W and Rappel, W J and Levine, H},
	year = {2010},
	note = {Publisher: APS},
	keywords = {merged\_fiete.bib},
	pages = {48104},
}

@article{garcia-ojalvo_modeling_2004,
	title = {Modeling a synthetic multicellular clock: repressilators coupled by quorum sensing},
	volume = {101},
	number = {30},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Garcia-Ojalvo, J and Elowitz, M B and Strogatz, S H},
	year = {2004},
	note = {Publisher: National Acad Sciences},
	keywords = {merged\_fiete.bib},
	pages = {10955},
}

@article{gregor_onset_2010,
	title = {The onset of collective behavior in social amoebae},
	volume = {328},
	number = {5981},
	journal = {Sci. STKE},
	author = {Gregor, T and Fujimoto, K and Masaki, N and Sawai, S},
	year = {2010},
	note = {Publisher: AAAS},
	keywords = {merged\_fiete.bib},
	pages = {1021},
}

@article{hinton_reducing_2006,
	title = {Reducing the dimensionality of data with neural networks},
	volume = {313},
	number = {5786},
	journal = {Science},
	author = {Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
	year = {2006},
	note = {Publisher: American Association for the Advancement of Science},
	keywords = {merged\_fiete.bib},
	pages = {504--507},
}

@article{hinton_fast_2006,
	title = {A fast learning algorithm for deep belief nets},
	volume = {18},
	number = {7},
	journal = {Neural Comput.},
	author = {Hinton, Geoffrey and Osindero, Simon and Teh, Yee-Whye},
	year = {2006},
	note = {Publisher: MIT Press},
	keywords = {merged\_fiete.bib},
	pages = {1527--1554},
}

@article{weigt_identification_2009,
	title = {Identification of direct residue contacts in protein-protein interactions by message passing},
	volume = {106},
	journal = {Proceedings of the National Academy of Science},
	author = {Weigt, M and White, R A and Szurmant, H and Hoch, J A and Hwa, T},
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {67--72},
}

@article{indest_workshop_2009,
	title = {Workshop {Report}: {Modeling} the {Molecular} {Mechanism} of {Bacterial} {Spore} {Germination} and {Elucidating} {Reasons} for {Germination} {Heterogeneity}},
	volume = {74},
	number = {6},
	journal = {J. Food Sci.},
	author = {Indest, K J and Buchholz, W G and Faeder, J R and Setlow, P},
	year = {2009},
	note = {Publisher: Wiley Online Library},
	keywords = {merged\_fiete.bib},
	pages = {R73--R78},
}

@article{iyer-biswas_stochasticity_2009,
	title = {Stochasticity of gene products from transcriptional pulsing},
	volume = {79},
	number = {3},
	journal = {Physical Review E},
	author = {Iyer-Biswas, S and Hayot, F and Jayaprakash, C},
	year = {2009},
	note = {Publisher: APS},
	keywords = {merged\_fiete.bib},
	pages = {031911},
}

@article{jeffreys_invariant_1946,
	title = {An {Invariant} {Form} for the {Prior} {Probability} in {Estimation} {Problems}},
	volume = {186},
	number = {1007},
	journal = {Proc. R. Soc. Lond. A Math. Phys. Sci.},
	author = {Jeffreys, Harold},
	year = {1946},
	keywords = {merged\_fiete.bib},
	pages = {453--461},
}

@article{kadanoff_variational_1976,
	title = {Variational approximations for renormalization group transformations},
	volume = {14},
	number = {2},
	journal = {J. Stat. Phys.},
	author = {Kadanoff, Leo P and Houghton, Anthony and Yalabik, Mehmet C},
	year = {1976},
	note = {Publisher: Springer},
	keywords = {merged\_fiete.bib},
	pages = {171--203},
}

@article{laub_specificity_2007,
	title = {Specificity in two-component signal transduction pathways},
	volume = {41},
	journal = {Annu. Rev. Genet.},
	author = {Laub, M T and Goulian, M},
	year = {2007},
	note = {Publisher: Annual Reviews},
	keywords = {merged\_fiete.bib},
	pages = {121--145},
}

@article{kinney_precise_2007,
	title = {Precise physical models of protein‚Äì{DNA} interaction from high-throughput data},
	volume = {104},
	number = {2},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Kinney, Justin B and Tkaƒçik, {\textasciicircum}{\textbackslash}circper, Ga{\textbackslash}approx{\textbackslash} and Callan, Curtis G},
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {501--506},
}

@article{lan_energy-speed-accuracy_2012,
	title = {The energy-speed-accuracy trade-off in sensory adaptation},
	volume = {8},
	number = {5},
	journal = {Nat. Phys.},
	author = {Lan, G and Sartori, P and Neumann, S and Sourjik, V and Tu, Y},
	year = {2012},
	note = {Publisher: Nature Publishing Group},
	keywords = {merged\_fiete.bib},
	pages = {422--428},
}

@article{laughlin_energy_2001,
	title = {Energy as a constraint on the coding and processing of sensory information},
	volume = {11},
	number = {4},
	journal = {Curr. Opin. Neurobiol.},
	author = {Laughlin, S B},
	year = {2001},
	note = {Publisher: Elsevier},
	keywords = {merged\_fiete.bib},
	pages = {475--480},
}

@article{laughlin_metabolic_1998,
	title = {The metabolic cost of neural information},
	volume = {1},
	number = {1},
	journal = {Nat. Neurosci.},
	author = {Laughlin, S B and van Steveninck, R R R and Anderson, J C},
	year = {1998},
	note = {Publisher: Nature Publishing Group},
	keywords = {merged\_fiete.bib},
	pages = {36--41},
}

@article{le_roux_representational_2008,
	title = {Representational power of restricted {Boltzmann} machines and deep belief networks},
	volume = {20},
	number = {6},
	journal = {Neural Comput.},
	author = {Le Roux, Nicolas and Bengio, Yoshua},
	year = {2008},
	note = {Publisher: MIT Press},
	keywords = {merged\_fiete.bib},
	pages = {1631--1649},
}

@article{le_roux_deep_2010,
	title = {Deep {Belief} {Networks} {Are} {Compact} {Universal} {Approximators}},
	volume = {22},
	number = {8},
	journal = {Neural Comput.},
	author = {Le Roux, Nicolas and Bengio, Yoshua},
	year = {2010},
	note = {Publisher: MIT Press},
	keywords = {merged\_fiete.bib},
	pages = {2192--2207},
}

@article{lebowitz_gallavotticohen-type_1999,
	title = {A {Gallavotti}–{Cohen}-type symmetry in the large deviation functional for stochastic dynamics},
	volume = {95},
	number = {1},
	journal = {J. Stat. Phys.},
	author = {Lebowitz, J L and Spohn, H},
	year = {1999},
	note = {Publisher: Springer},
	keywords = {merged\_fiete.bib},
	pages = {333--365},
}

@article{long_quantifying_2009,
	title = {Quantifying the integration of quorum-sensing signals with single-cell resolution},
	volume = {7},
	number = {3},
	journal = {PLoS Biol.},
	author = {Long, T and Tu, K C and Wang, Y and Mehta, P and Ong, N P and Bassler, B L and Wingreen, N S},
	year = {2009},
	note = {Publisher: Public Library of Science},
	keywords = {merged\_fiete.bib},
	pages = {e1000068},
}

@article{leung_one_2004,
	title = {One {Nucleotide} in a {kB} {Site} {Can} {Determine} {Cofactor} {Specificity} for {NF}-{kB} {Dimers}},
	volume = {118},
	journal = {Cell},
	author = {Leung, Thomas H and Hoffmann, Alexander and Baltimore, David},
	year = {2004},
	keywords = {merged\_fiete.bib},
}

@inproceedings{larochelle_classification_2008,
	title = {Classification using discriminative restricted {Boltzmann} machines},
	booktitle = {Proceedings of the 25th international conference on {Machine} learning},
	publisher = {ACM},
	author = {Larochelle, Hugo and Bengio, Yoshua},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {536--543},
}

@article{martens_exact_2009,
	title = {Exact results for the {Kuramoto} model with a bimodal frequency distribution},
	volume = {79},
	number = {2},
	journal = {Physical Review E},
	author = {Martens, E A and Barreto, E and Strogatz, S H and Ott, E and So, P and Antonsen, T M},
	year = {2009},
	note = {Publisher: APS},
	keywords = {merged\_fiete.bib},
	pages = {026204},
}

@article{mather_delay-induced_2009,
	title = {Delay-{Induced} {Degrade}-and-{Fire} {Oscillations} in {Small} {Genetic} {Circuits}},
	volume = {102},
	number = {6},
	journal = {Phys. Rev. Lett.},
	author = {Mather, William and Bennett, Matthew R and Hasty, Jeff and Tsimring, Lev S},
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {068105},
}

@article{matthews_dynamics_1991,
	title = {Dynamics of a large system of coupled nonlinear oscillators},
	volume = {52},
	number = {2-3},
	journal = {Physica D},
	author = {Matthews, P C and Mirollo, R E and Strogatz, S H},
	year = {1991},
	note = {Publisher: Elsevier},
	keywords = {merged\_fiete.bib},
	pages = {293--331},
}

@article{mcmillen_synchronizing_2002,
	title = {Synchronizing genetic relaxation oscillators by intercell signaling},
	volume = {99},
	number = {2},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {McMillen, D and Kopell, N and Hasty, J and Collins, J J},
	year = {2002},
	note = {Publisher: National Acad Sciences},
	keywords = {merged\_fiete.bib},
	pages = {679},
}

@article{mehta_quantitative_2008,
	title = {A quantitative comparison of {sRNA}-based and protein-based gene regulation},
	volume = {4},
	number = {1},
	journal = {Mol. Syst. Biol.},
	author = {Mehta, P and Goyal, S and Wingreen, N S},
	year = {2008},
	note = {Publisher: Nature Publishing Group},
	keywords = {merged\_fiete.bib},
}

@article{mehta_information_2009,
	title = {Information processing and signal integration in bacterial quorum sensing},
	volume = {5},
	number = {1},
	journal = {Mol. Syst. Biol.},
	author = {Mehta, P and Goyal, S and Long, T and Bassler, B L and Wingreen, N S},
	year = {2009},
	note = {Publisher: Nature Publishing Group},
	keywords = {merged\_fiete.bib},
}

@article{mehta_approaching_2010,
	title = {Approaching the molecular origins of collective dynamics in oscillating cell populations},
	journal = {Curr. Opin. Genet. Dev.},
	author = {Mehta, P and Gregor, T},
	year = {2010},
	note = {Publisher: Elsevier},
	keywords = {merged\_fiete.bib},
}

@article{mora_maximum_2010,
	title = {Maximum {Entropy} {Models} for {Antibody} {Diversity}},
	volume = {107},
	number = {12},
	journal = {Proceedings of the National Academy of Science},
	author = {Mora, Thierry and Walczak, Alecksandra and Bialek, William and Callan, Curt G},
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {5405--5410},
}

@article{mora_limits_2010,
	title = {Limits of sensing temporal concentration changes by single cells},
	volume = {104},
	number = {24},
	journal = {Phys. Rev. Lett.},
	author = {Mora, T and Wingreen, N S},
	year = {2010},
	note = {Publisher: APS},
	keywords = {merged\_fiete.bib},
	pages = {248101},
}

@article{morozov_extrinsic_2008,
	title = {Extrinsic and intrinsic nucleosome positioning signals},
	journal = {Arxiv:0805. 4017},
	author = {Morozov, A V and K, Fortney and Gaykalova, D A and Studitsky, V M and Widom, J and Siggia, E D},
	year = {2008},
	keywords = {merged\_fiete.bib},
}

@article{powell_proneural_2004,
	title = {The {Proneural} {Proteins} {Atonal} and {Scute} {Regulate} {Neural} {Target} {Genes} through {Different} {E}-{Box} {Binding} {Sites}},
	volume = {24},
	number = {21},
	journal = {Mol. Cell. Biol.},
	author = {Powell, Lynn M and zur Lage, Petra I and Prentice, David R A and Senthinathan, Biruntha and Jarman, Andrew P},
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {9517--9526},
}

@article{qian_thermodynamic_2003,
	title = {Thermodynamic and kinetic analysis of sensitivity amplification in biological signal transduction},
	volume = {105},
	number = {2-3},
	journal = {Biophys. Chem.},
	author = {Qian, H},
	year = {2003},
	note = {Publisher: Elsevier},
	keywords = {merged\_fiete.bib},
	pages = {585--593},
}

@article{qian_thermodynamics_2005,
	title = {Thermodynamics of stoichiometric biochemical networks in living systems far from equilibrium},
	volume = {114},
	number = {2-3},
	journal = {Biophys. Chem.},
	author = {Qian, H and Beard, D A},
	year = {2005},
	note = {Publisher: Elsevier},
	keywords = {merged\_fiete.bib},
	pages = {213--220},
}

@article{qian_nonequilibrium_2005,
	title = {Nonequilibrium thermodynamics and nonlinear kinetics in a cellular signaling switch},
	volume = {94},
	number = {2},
	journal = {Phys. Rev. Lett.},
	author = {Qian, H and Reluga, T C},
	year = {2005},
	note = {Publisher: APS},
	keywords = {merged\_fiete.bib},
	pages = {28101},
}

@article{ramana_reddy_time_1999,
	title = {Time delay effects on coupled limit cycle oscillators at {Hopf} bifurcation},
	volume = {129},
	number = {1-2},
	journal = {Physica D},
	author = {Ramana Reddy, D V and Sen, A and Johnston, G L},
	year = {1999},
	note = {Publisher: Elsevier},
	keywords = {merged\_fiete.bib},
	pages = {15--34},
}

@article{rajewsky_computational_2002,
	title = {Computational detection of genomic cis-regulatory modules applied to body patterning in the early {Drosophila} embryo},
	volume = {3},
	number = {1},
	journal = {BMC Bioinformatics},
	author = {Rajewsky, Nikolaus and Vergassola, Massimo and Gaul, Ulrike and Siggia, Eric},
	year = {2002},
	keywords = {merged\_fiete.bib},
}

@article{halabi_protein_2009,
	title = {Protein {Sectors}: {Evolutionary} {Units} in {Three}-{Dimensional} {Structure}},
	volume = {138},
	journal = {Cell},
	author = {Halabi, N and Rivoire, O and Leibler, S and Ranganathan, R},
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {774--786},
}

@inproceedings{salakhutdinov_restricted_2007,
	title = {Restricted {Boltzmann} machines for collaborative filtering},
	booktitle = {Proceedings of the 24th international conference on {Machine} learning},
	publisher = {ACM},
	author = {Salakhutdinov, Ruslan and Mnih, Andriy and Hinton, Geoffrey},
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {791--798},
}

@inproceedings{saxe_learning_2013,
	title = {Learning hierarchical category structure in deep neural networks},
	booktitle = {Proceedings of the 35th {Annual} {Conference} of the {Cognitive} {Science} {Society}},
	author = {Saxe, Andrew M and McClelland, James L and Ganguli, Surya},
	year = {2013},
	keywords = {merged\_fiete.bib},
}

@article{saxe_exact_2013,
	title = {Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
	journal = {arXiv preprint arXiv:1312. 6120},
	author = {Saxe, Andrew M and McClelland, James L and Ganguli, Surya},
	year = {2013},
	keywords = {merged\_fiete.bib},
}

@article{schwab_nucleosome_2008,
	title = {Nucleosome {Switches}},
	volume = {100},
	journal = {Phys. Rev. Lett.},
	author = {Schwab, David J and Bruinsma, Robijn and Rudnick, Joseph and Widom, J},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {228105},
}

@article{schwab_dynamical_2010,
	title = {Dynamical quorum-sensing and synchronization of nonlinear oscillators coupled through an external medium},
	journal = {Arxiv preprint arXiv:1012. 4863},
	author = {Schwab, D J and Baetica, A and Mehta, P},
	year = {2010},
	keywords = {merged\_fiete.bib},
}

@article{schwab_rhythmogenic_2010,
	title = {Rhythmogenic neuronal networks, emergent leaders, and k-cores},
	volume = {82},
	number = {5},
	journal = {Physical Review E},
	author = {Schwab, D J and Bruinsma, R F and Feldman, J L and Levine, A J},
	year = {2010},
	note = {Publisher: APS},
	keywords = {merged\_fiete.bib},
	pages = {051911},
}

@article{segal_genomic_2006,
	title = {A {Genomic} {Code} for {Nucleosome} {Positioning}},
	volume = {442},
	journal = {Nature},
	author = {Segal, Eran and Fondufe-Mittendorf, Yvonne and Chen, Lingyi and Thstrm, Annchristine and Field, Yair and Moore, Irene K and Wang, Ji-Ping Z and Widom, Jonathan},
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {772--778},
}

@article{sinha_probabilistic_2003,
	title = {A probabilistic method to detect regulatory modules},
	volume = {19},
	number = {suppl\_1},
	journal = {Bioinformatics},
	author = {Sinha, Saurabh and van Nimwegen, Erik and Siggia, Eric D},
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {i292--301},
}

@article{stormo_specificity_1998,
	title = {Specificity, free energy and information content in protein-{DNA} interactions},
	volume = {23},
	number = {3},
	journal = {Trends Biochem. Sci.},
	author = {Stormo, G D and Fields, D S},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {109--113},
}

@article{stricker_fast_2008,
	title = {A fast, robust and tunable synthetic gene oscillator},
	volume = {456},
	number = {7221},
	journal = {Nature},
	author = {Stricker, J and Cookson, S and Bennett, M R and Mather, W H and Tsimring, L S and Hasty, J},
	year = {2008},
	note = {Publisher: Nature Publishing Group},
	keywords = {merged\_fiete.bib},
	pages = {516--519},
}

@article{strogatz_stability_1991,
	title = {Stability of incoherence in a population of coupled oscillators},
	volume = {63},
	number = {3},
	journal = {J. Stat. Phys.},
	author = {Strogatz, S H and Mirollo, R E},
	year = {1991},
	note = {Publisher: Springer},
	keywords = {merged\_fiete.bib},
	pages = {613--635},
}

@article{strogatz_kuramoto_2000,
	title = {From {Kuramoto} to {Crawford}: exploring the onset of synchronization in populations of coupled oscillators},
	volume = {143},
	number = {1-4},
	journal = {Physica D},
	author = {Strogatz, S H},
	year = {2000},
	note = {Publisher: Elsevier},
	keywords = {merged\_fiete.bib},
	pages = {1--20},
}

@article{taylor_dynamical_2009,
	title = {Dynamical quorum sensing and synchronization in large populations of chemical oscillators},
	volume = {323},
	number = {5914},
	journal = {Science},
	author = {Taylor, A F and Tinsley, M R and Wang, F and Huang, Z and Showalter, K},
	year = {2009},
	note = {Publisher: AAAS},
	keywords = {merged\_fiete.bib},
	pages = {614},
}

@article{teh_rate-coded_2001,
	title = {Rate-coded restricted {Boltzmann} machines for face recognition},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Teh, Yee Whye and Hinton, Geoffrey E},
	year = {2001},
	note = {Publisher: MIT; 1998},
	keywords = {merged\_fiete.bib},
	pages = {908--914},
}

@article{tinsley_dynamical_2010,
	title = {Dynamical quorum sensing and synchronization in collections of excitable and oscillatory catalytic particles},
	volume = {239},
	number = {11},
	journal = {Physica D},
	author = {Tinsley, M R and Taylor, A F and Huang, Z and Wang, F and Showalter, K},
	year = {2010},
	note = {Publisher: Elsevier},
	keywords = {merged\_fiete.bib},
	pages = {785--790},
}

@article{tu_nonequilibrium_2008,
	title = {The nonequilibrium mechanism for ultrasensitivity in a biological switch: {Sensing} by {Maxwell}'s demons},
	volume = {105},
	number = {33},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Tu, Y},
	year = {2008},
	note = {Publisher: National Acad Sciences},
	keywords = {merged\_fiete.bib},
	pages = {11737},
}

@article{visco_statistical_2009,
	title = {Statistical physics of a model binary genetic switch with linear feedback},
	volume = {79},
	number = {3},
	journal = {Physical Review E},
	author = {Visco, P and Allen, R J and Evans, M R},
	year = {2009},
	note = {Publisher: APS},
	keywords = {merged\_fiete.bib},
	pages = {031923},
}

@article{von_hippel_specificity_1986,
	title = {On the specificity of {DNA}-protein interactions},
	volume = {83},
	number = {6},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {von Hippel, P H and Berg, O G},
	year = {1986},
	keywords = {merged\_fiete.bib},
	pages = {1608--1612},
}

@article{bronson_learning_2009,
	title = {Learning {Rates} and {States} from {Biophysics} {Time} {Series}: {A} {Bayesian} {Approach} to {Model} {Selection} and {Single}-{Molecule} {FRET} {Data}},
	volume = {97},
	number = {12},
	journal = {Biophysics Journal},
	author = {Bronson, J and Fei, J and Hofman, J and Gonzales, Jr, R and Wiggins, C},
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {3196--3205},
}

@article{yeung_time_1999,
	title = {Time delay in the {Kuramoto} model of coupled oscillators},
	volume = {82},
	number = {3},
	journal = {Phys. Rev. Lett.},
	author = {Yeung, M K S and Strogatz, S H},
	year = {1999},
	note = {Publisher: APS},
	keywords = {merged\_fiete.bib},
	pages = {648--651},
}

@article{yi_synergism_2011,
	title = {Synergism between {Different} {Germinant} {Receptors} in the {Germination} of {Bacillus} subtilis {Spores}},
	volume = {193},
	number = {18},
	journal = {J. Bacteriol.},
	author = {Yi, X and Liu, J and Faeder, J R and Setlow, P},
	year = {2011},
	note = {Publisher: Am Soc Microbiol},
	keywords = {merged\_fiete.bib},
	pages = {4664--4671},
}

@article{zamora-munt_crowd_2010,
	title = {Crowd synchrony and quorum sensing in delay-coupled lasers},
	volume = {105},
	number = {26},
	journal = {Phys. Rev. Lett.},
	author = {Zamora-Munt, J and Masoller, C and Garcia-Ojalvo, J and Roy, R},
	year = {2010},
	note = {Publisher: APS},
	keywords = {merged\_fiete.bib},
	pages = {264101},
}

@article{weisbuch_scaling_1985,
	title = {Scaling laws for the attractors of {Hopfield} networks},
	volume = {46},
	number = {14},
	journal = {Journal de Physique Lettres},
	author = {Weisbuch, Gérard and Fogelman-Soulié, Françoise},
	year = {1985},
	note = {Publisher: Les Editions de Physique},
	keywords = {merged\_fiete.bib},
	pages = {623--630},
}

@article{mceliece_capacity_1987,
	title = {The capacity of the {Hopfield} associative memory},
	volume = {33},
	number = {4},
	journal = {IEEE Trans. Inf. Theory},
	author = {McEliece, Robert J and Posner, Edward C and Rodemich, Eugene R and Venkatesh, Santosh S},
	year = {1987},
	note = {Publisher: IEEE},
	keywords = {merged\_fiete.bib},
	pages = {461--482},
}

@article{hopfield_neural_1982,
	title = {Neural networks and physical systems with emergent collective computational abilities},
	volume = {79},
	number = {8},
	journal = {Proceedings of the national academy of sciences},
	author = {Hopfield, John J},
	year = {1982},
	note = {Publisher: National Acad Sciences},
	keywords = {merged\_fiete.bib},
	pages = {2554--2558},
}

@article{abu-mostafa_information_1985,
	title = {Information capacity of the {Hopfield} model},
	volume = {31},
	number = {4},
	journal = {IEEE Trans. Inf. Theory},
	author = {Abu-Mostafa, Yaser S and St Jacques, J},
	year = {1985},
	note = {Publisher: IEEE},
	keywords = {merged\_fiete.bib},
	pages = {461--464},
}

@article{mceliece_number_1985,
	title = {The number of stable points of an infinite-range spin glass memory},
	volume = {42},
	journal = {Telecommunications and Data Acquisition Progress Report},
	author = {McEliece, R J and Posner, E C},
	year = {1985},
	keywords = {merged\_fiete.bib},
	pages = {83},
}

@article{tanaka_analytic_1980,
	title = {Analytic theory of the ground state properties of a spin glass. {I}. {Ising} spin glass},
	volume = {10},
	number = {12},
	journal = {J. Phys. F: Met. Phys.},
	author = {Tanaka, F and Edwards, S F},
	year = {1980},
	note = {Publisher: IOP Publishing},
	keywords = {merged\_fiete.bib},
	pages = {2769},
}

@article{hillar_robust_2012,
	title = {Robust exponential binary pattern storage in {Little}-{Hopfield} networks},
	journal = {arXiv preprint arXiv:1206. 2081},
	author = {Hillar, Christopher and Tran, Ngoc and Koepsell, Kilian},
	year = {2012},
	keywords = {merged\_fiete.bib},
}

@article{gripon_sparse_2011,
	title = {Sparse neural networks with large learning diversity},
	volume = {22},
	number = {7},
	journal = {IEEE Trans. Neural Netw.},
	author = {Gripon, Vincent and Berrou, Claude},
	year = {2011},
	note = {Publisher: IEEE},
	keywords = {merged\_fiete.bib},
	pages = {1087--1096},
}

@inproceedings{goldreich_chinese_1999,
	title = {Chinese remaindering with errors},
	booktitle = {Proceedings of the thirty-first annual {ACM} symposium on {Theory} of computing},
	publisher = {ACM},
	author = {Goldreich, Oded and Ron, Dana and Sudan, Madhu},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {225--234},
}

@article{wang_closed-form_2010,
	title = {A closed-form robust {Chinese} remainder theorem and its performance analysis},
	volume = {58},
	number = {11},
	journal = {Signal Processing, IEEE Transactions on},
	author = {Wang, Wenjie and Xia, Xiang-Gen},
	year = {2010},
	note = {Publisher: IEEE},
	keywords = {merged\_fiete.bib},
	pages = {5655--5666},
}

@article{shparlinski_noisy_2004,
	title = {Noisy {Chinese} remaindering in the {Lee} norm},
	volume = {20},
	number = {2},
	journal = {J. Complex.},
	author = {Shparlinski, Igor E and Steinfeld, Ron},
	year = {2004},
	note = {Publisher: Elsevier},
	keywords = {merged\_fiete.bib},
	pages = {423--437},
}

@article{jonides_mind_2008,
	title = {The mind and brain of short-term memory},
	volume = {59},
	number = {1},
	journal = {Annu. Rev. Psychol.},
	author = {Jonides, John and Lewis, Richard L and Nee, Derek E and Lustig, Cindy A and Berman, Marc G and Moore, Katherine S},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {193--224},
}

@incollection{atkinson_human_1968,
	address = {London},
	title = {Human memory: {A} proposed system and its control processes},
	volume = {8},
	booktitle = {The psychology of learning and motivation},
	publisher = {Academic Press},
	author = {Atkinson, R C and Shiffrin, R M},
	editor = {Spence, K W and Spence, J T},
	year = {1968},
	keywords = {merged\_fiete.bib},
}

@article{bays_temporal_2011,
	title = {Temporal dynamics of encoding, storage, and reallocation of visual working memory},
	volume = {11},
	abstract = {The process of encoding a visual scene into working memory has previously been studied using binary measures of recall. Here, we examine the temporal evolution of memory resolution, based on observers' ability to reproduce the orientations of objects presented in brief, masked displays. Recall precision was accurately described by the interaction of two independent constraints: an encoding limit that determines the maximum rate at which information can be transferred into memory and a separate storage limit that determines the maximum fidelity with which information can be maintained. Recall variability decreased incrementally with time, consistent with a parallel encoding process in which visual information from multiple objects accumulates simultaneously in working memory. No evidence was observed for a limit on the number of items stored. Cuing one display item with a brief flash led to rapid development of a recall advantage for that item. This advantage was short-lived if the cue was simply a salient visual event but was maintained if it indicated an object of particular relevance to the task. These cuing effects were observed even for items that had already been encoded into memory, indicating that limited memory resources can be rapidly reallocated to prioritize salient or goal-relevant information.},
	number = {10},
	journal = {J. Vis.},
	author = {Bays, Paul M and Gorgoraptis, Nikos and Wee, Natalie and Marshall, Louise and Husain, Masud},
	year = {2011},
	keywords = {merged\_fiete.bib},
}

@article{cowan_what_2008,
	title = {What are the differences between long-term, short-term, and working memory?},
	volume = {169},
	abstract = {In the recent literature there has been considerable confusion about the three types of memory: long-term, short-term, and working memory. This chapter strives to reduce that confusion and makes up-to-date assessments of these types of memory. Long- and short-term memory could differ in two fundamental ways, with only short-term memory demonstrating (1) temporal decay and (2) chunk capacity limits. Both properties of short-term memory are still controversial but the current literature is rather encouraging regarding the existence of both decay and capacity limits. Working memory has been conceived and defined in three different, slightly discrepant ways: as short-term memory applied to cognitive tasks, as a multi-component system that holds and manipulates information in short-term memory, and as the use of attention to manage short-term memory. Regardless of the definition, there are some measures of memory in the short term that seem routine and do not correlate well with cognitive aptitudes and other measures (those usually identified with the term “working memory”) that seem more attention demanding and do correlate well with these aptitudes. The evidence is evaluated and placed within a theoretical framework depicted in Fig. 1.},
	journal = {Prog. Brain Res.},
	author = {Cowan, Nelson},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {323--338},
}

@article{harrison_decoding_2009,
	title = {Decoding reveals the contents of visual working memory in early visual areas},
	volume = {458},
	abstract = {Visual working memory provides an essential link between perception and higher cognitive functions, allowing for the active maintenance of information about stimuli no longer in view. Research suggests that sustained activity in higher-order prefrontal, parietal, inferotemporal and lateral occipital areas supports visual maintenance, and may account for the limited capacity of working memory to hold up to 3-4 items. Because higher-order areas lack the visual selectivity of early sensory areas, it has remained unclear how observers can remember specific visual features, such as the precise orientation of a grating, with minimal decay in performance over delays of many seconds. One proposal is that sensory areas serve to maintain fine-tuned feature information, but early visual areas show little to no sustained activity over prolonged delays. Here we show that orientations held in working memory can be decoded from activity patterns in the human visual cortex, even when overall levels of activity are low. Using functional magnetic resonance imaging and pattern classification methods, we found that activity patterns in visual areas V1-V4 could predict which of two oriented gratings was held in memory with mean accuracy levels upwards of 80\%, even in participants whose activity fell to baseline levels after a prolonged delay. These orientation-selective activity patterns were sustained throughout the delay period, evident in individual visual areas, and similar to the responses evoked by unattended, task-irrelevant gratings. Our results demonstrate that early visual areas can retain specific information about visual features held in working memory, over periods of many seconds when no physical stimulus is present.},
	number = {7238},
	journal = {Nature},
	author = {Harrison, Stephenie A and Tong, Frank},
	month = apr,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {632--635},
}

@article{berens_reassessing_2011,
	title = {Reassessing optimal neural population codes with neurometric functions},
	volume = {108},
	abstract = {Cortical circuits perform the computations underlying rapid perceptual decisions within a few dozen milliseconds with each neuron emitting only a few spikes. Under these conditions, the theoretical analysis of neural population codes is challenging, as the most commonly used theoretical tool–Fisher information–can lead to erroneous conclusions about the optimality of different coding schemes. Here we revisit the effect of tuning function width and correlation structure on neural population codes based on ideal observer analysis in both a discrimination and a reconstruction task. We show that the optimal tuning function width and the optimal correlation structure in both paradigms strongly depend on the available decoding time in a very similar way. In contrast, population codes optimized for Fisher information do not depend on decoding time and are severely suboptimal when only few spikes are available. In addition, we use the neurometric functions of the ideal observer in the classification task to investigate the differential coding properties of these Fisher-optimal codes for fine and coarse discrimination. We find that the discrimination error for these codes does not decrease to zero with increasing population size, even in simple coarse discrimination tasks. Our results suggest that quite different population codes may be optimal for rapid decoding in cortical computations than those inferred from the optimization of Fisher information.},
	number = {11},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Berens, Philipp and Ecker, Alexander S and Gerwinn, Sebastian and Tolias, Andreas S and Bethge, Matthias},
	month = mar,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {4423--4428},
}

@article{pasternak_working_2005,
	title = {Working memory in primate sensory systems},
	volume = {6},
	abstract = {Sensory working memory consists of the short-term storage of sensory stimuli to guide behaviour. There is increasing evidence that elemental sensory dimensions - such as object motion in the visual system or the frequency of a sound in the auditory system - are stored by segregated feature-selective systems that include not only the prefrontal and parietal cortex, but also areas of sensory cortex that carry out relatively early stages of processing. These circuits seem to have a dual function: precise sensory encoding and short-term storage of this information. New results provide insights into how activity in these circuits represents the remembered sensory stimuli.},
	number = {2},
	journal = {Nat. Rev. Neurosci.},
	author = {Pasternak, Tatiana and Greenlee, Mark W},
	month = feb,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {97--107},
}

@article{chen_time_2011,
	title = {Time course of allocentric decay, egocentric decay, and allocentric-to-egocentric conversion in memory-guided reach},
	volume = {49},
	abstract = {Allocentric cues can be used to encode locations in visuospatial memory, but it is not known how and when these representations are converted into egocentric commands for behaviour. Here, we tested the influence of different memory intervals on reach performance toward targets defined in either egocentric or allocentric coordinates, and then compared this to performance in a task where subjects were implicitly free to choose when to convert from allocentric to egocentric representations. Reach and eye positions were measured using Optotrak and Eyelink Systems, respectively, in fourteen subjects. Our results confirm that egocentric representations degrade over a delay of several seconds, whereas allocentric representations remained relatively stable over the same time scale. Moreover, when subjects were free to choose, they converted allocentric representations into egocentric representations as soon as possible, despite the apparent cost in reach precision in our experimental paradigm. This suggests that humans convert allocentric representations into egocentric commands at the first opportunity, perhaps to optimize motor noise and movement timing in real-world conditions.},
	number = {1},
	journal = {Neuropsychologia},
	author = {Chen, Ying and Byrne, Patrick and Crawford, J Douglas},
	month = jan,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {49--60},
}

@article{landauer_irreversibility_1961-1,
	title = {Irreversibility and heat generation in the computing process},
	volume = {5},
	number = {3},
	journal = {IBM J. Res. Dev.},
	author = {Landauer, R},
	year = {1961},
	note = {Publisher: IBM},
	keywords = {merged\_fiete.bib},
	pages = {183--191},
}

@article{lisman_storage_2001,
	title = {Storage, recall, and novelty detection of sequences by the hippocampus: {Elaborating} on the {SOCRATIC} model to account for normal and aberrant effects of dopamine},
	volume = {11},
	number = {5},
	journal = {Hippocampus},
	author = {Lisman, John E and Otmakhova, Nonna A},
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {551--568},
}

@article{melloni_synchronization_2007,
	title = {Synchronization of neural activity across cortical areas correlates with conscious perception},
	volume = {27},
	abstract = {Subliminal stimuli can be deeply processed and activate similar brain areas as consciously perceived stimuli. This raises the question which signatures of neural activity critically differentiate conscious from unconscious processing. Transient synchronization of neural activity has been proposed as a neural correlate of conscious perception. Here we test this proposal by comparing the electrophysiological responses related to the processing of visible and invisible words in a delayed matching to sample task. Both perceived and nonperceived words caused a similar increase of local (gamma) oscillations in the EEG, but only perceived words induced a transient long-distance synchronization of gamma oscillations across widely separated regions of the brain. After this transient period of temporal coordination, the electrographic signatures of conscious and unconscious processes continue to diverge. Only words reported as perceived induced (1) enhanced theta oscillations over frontal regions during the maintenance interval, (2) an increase of the P300 component of the event-related potential, and (3) an increase in power and phase synchrony of gamma oscillations before the anticipated presentation of the test word. We propose that the critical process mediating the access to conscious perception is the early transient global increase of phase synchrony of oscillatory activity in the gamma frequency range.},
	language = {eng},
	number = {11},
	journal = {J. Neurosci.},
	author = {Melloni, Lucia and Molina, Carlos and Pena, Marcela and Torres, David and Singer, Wolf and Rodriguez, Eugenio},
	year = {2007},
	note = {Place: Laboratorio de Neurociencias, Escuela de Psicologia, Pontificia Universidad Catolica de Chile, Vicuna Mackenna 4860, San Joaquin, 8940000 Santiago, Chile. melloni@mpih-frankfurt.mpg.de},
	keywords = {Humans, Male, Adult, Female, merged\_fiete.bib, Neurons/*physiology, *Cortical Synchronization, Cerebral Cortex/*physiology, Consciousness/*physiology, Perception/*physiology, Psychomotor Performance/physiology, Reaction Time/physiology},
	pages = {2858--2865},
}

@article{engel_dynamic_2001,
	title = {Dynamic predictions: oscillations and synchrony in top-down processing},
	volume = {2},
	abstract = {Classical theories of sensory processing view the brain as a passive, stimulus-driven device. By contrast, more recent approaches emphasize the constructive nature of perception, viewing it as an active and highly selective process. Indeed, there is ample evidence that the processing of stimuli is controlled by top-down influences that strongly shape the intrinsic dynamics of thalamocortical networks and constantly create predictions about forthcoming sensory events. We discuss recent experiments indicating that such predictions might be embodied in the temporal structure of both stimulus-evoked and ongoing activity, and that synchronous oscillations are particularly important in this process. Coherence among subthreshold membrane potential fluctuations could be exploited to express selective functional relationships during states of expectancy or attention, and these dynamic patterns could allow the grouping and selection of distributed neuronal responses for further processing.},
	language = {eng},
	number = {10},
	journal = {Nat. Rev. Neurosci.},
	author = {Engel, A K and Fries, P and Singer, W},
	year = {2001},
	note = {Place: Cellular Neurobiology Group, Institute for Medicine, Research Centre Julich, 52425 Julich, Germany. a.k.engel@fz-juelich.de},
	keywords = {Pattern Recognition, Humans, Animals, Time Factors, merged\_fiete.bib, Neurological, Neurons/*physiology, Models, Brain/*physiology, Haplorhini, Mental Processes, Motor Activity/physiology, Oscillometry, Visual, Visual Cortex/physiology},
	pages = {704--716},
}

@article{lomber_cryoloop_1999,
	title = {The cryoloop: an adaptable reversible cooling deactivation method for behavioral or electrophysiological assessment of neural function},
	volume = {86},
	abstract = {We describe a very adaptable reversible inactivation technique for the behavioral or electrophysiological analysis of neural circuits. The cryoloop device can be permanently implanted or topically applied in an acute preparation to apply cold to discrete surface regions of the central nervous system (e.g. cerebral cortex or midbrain). The cryoloop consists of a custom shaped, stainless steel, hypodermic tubing and cooling is effected by passing chilled methanol through the lumen of the tubing. Cryoloop temperature is monitored by a microthermocouple attached to the union of the loop, and can be maintained within +/- 1 degrees C of a desired temperature. In chronic preparations, implanted cryoloops have been maintained in cats and monkeys for periods in excess of 2 years. After this period there are no structural, metabolic of functional changes in the deactivated tissue, and full reversibility of cooling-induced effects is maintained. Operation of multiple cryoprobes provides great flexibility of experimental protocols, permits double and triple functional dissociations to be made, and strengthens experimental design considerably.},
	language = {eng},
	number = {2},
	journal = {J. Neurosci. Methods},
	author = {Lomber, S G and Payne, B R and Horel, J A},
	year = {1999},
	note = {Place: Department of Anatomy and Neurobiology, Boston University School of Medicine, MA 02118, USA. slomber@bu.edu},
	keywords = {Psychology, Animals, merged\_fiete.bib, Behavior, Neurons/*physiology, Cats, Haplorhini, *Cold, Animal/*physiology, Body Temperature, Cerebral Cortex/anatomy \& histology/physiology, Electrophysiology/*instrumentation, Experimental/*instrumentation, Prostheses and Implants},
	pages = {179--194},
}

@article{lomber_behavioral_2001,
	title = {Behavioral cartography of visual functions in cat parietal cortex: areal and laminar dissociations},
	volume = {134},
	abstract = {The purpose of this review is to: (1) compare and contrast the relative contributions that the four principle regions in cat extrastriate parietal cortex make to a battery of visual tasks which require motion, spatial, or attentional processing; and (2) examine the laminar parcellation of visual behaviors within one of these parietal regions which mediates multiple visual behaviors. We examined a battery of visual tasks presumed to be mediated by parietal cortex, including direction of motion, differential motion, and landmark discriminations, and visual orienting to moving stimuli. As a control, we also examined performance on form (pattern and object) recognition tasks mediated by the temporal processing stream. The four regions of parietal cortex we examined included the: middle suprasylvian (MS) gyrus (area 7), anterior middle suprasylvian (aMS) sulcus (AMLS, ALLS), posterior middle suprasylvian (pMS) sulcus (PMLS, PLLS), and the dorsal posterior suprasylvian (dPS) gyrus (area 21a). The contributions made to each of the six different behavioral tasks was examined before, during, and after reversible cooling deactivation of each cortical area. Deactivation of pMS sulcal cortex resulted in deficits on all four tasks that required motion, spatial or attentional processing. Deactivation of aMS sulcal cortex resulted in deficits on only tasks that required motion processing. Deactivation of neither aMS nor pMS sulcal cortex yielded any deficits on the form recognition tasks. In contrast, deactivation of dPS cortex only produced deficits on the form recognition tasks. This finding confirmed our early hypothesis that dPS cortex is a key component of the temporal, and not the parietal, processing stream. Regardless of the task, no deficits were identified on any of the six tasks during deactivation of the MS gyrus. We then more closely examined pMS sulcal cortex to determine if its multiple functions could be dissociated on a laminar level. We found that cooling deactivation of the superficial layers (I-III) of pMS sulcal cortex selectively and completely impaired performance on the direction of motion discrimination task, while leaving visual attention unimpaired. Additional deactivation of the deeper layers (IV-VI) resulted in impaired visual attention as assessed with visual orienting. These results show a functional bipartite division of labor between upper and lower cortical layers of pMS sulcal cortex. Therefore, spatial, motion and attentional functions can be localized within visuoparietal cortex on both an areal and laminar level.},
	language = {eng},
	journal = {Prog. Brain Res.},
	author = {Lomber, S G},
	year = {2001},
	note = {Place: Laboratory for Visual Perception and Cognition, Department of Anatomy and Neurobiology, Boston University School of Medicine, 700 Albany Street, Boston, MA 02118, USA. lomber@utdallas.edu},
	keywords = {Humans, Animals, merged\_fiete.bib, Behavior, Space Perception/physiology, Visual Cortex/physiology, Animal/*physiology, *Brain Mapping, Attention/physiology, Discrimination (Psychology)/physiology, Motion Perception/physiology, Parietal Lobe/*physiology, Visual Perception/*physiology},
	pages = {265--284},
}

@article{liu_defining_2007,
	title = {Defining cortical frequency tuning with recurrent excitatory circuitry},
	volume = {10},
	abstract = {Neurons in the recipient layers of sensory cortices receive excitatory input from two major sources: the feedforward thalamocortical and recurrent intracortical inputs. To address their respective functional roles, we developed a new method for silencing cortex by competitively activating GABA(A) while blocking GABA(B) receptors. In the rat primary auditory cortex, in vivo whole-cell recording from the same neuron before and after local cortical silencing revealed that thalamic input occupied the same area of frequency-intensity tonal receptive field as the total excitatory input, but showed a flattened tuning curve. In contrast, excitatory intracortical input was sharply tuned with a tuning curve that closely matched that of suprathreshold responses. This can be attributed to a selective amplification of cortical cells' responses at preferred frequencies by intracortical inputs from similarly tuned neurons. Thus, weakly tuned thalamocortical inputs determine the subthreshold responding range, whereas intracortical inputs largely define the tuning. Such circuits may ensure a faithful conveyance of sensory information.},
	language = {eng},
	number = {12},
	journal = {Nat. Neurosci.},
	author = {Liu, Bao-Hua and Wu, Guangying K and Arbuckle, Robert and Tao, Huizhong W and Zhang, Li I},
	year = {2007},
	note = {Place: Zilkha Neurogenetic Institute, University of Southern California, 1501 San Pablo Street, Los Angeles, California 90033, USA.},
	keywords = {Animals, Rats, Female, merged\_fiete.bib, Acoustic Stimulation/methods, Action Potentials/drug effects/physiology/radiation effects, Auditory Cortex/*cytology, Auditory Pathways/*physiology/radiation effects, Baclofen/pharmacology, Dose-Response Relationship, Drug Interactions, Excitatory Postsynaptic Potentials/drug effects/physiology/radiation effects, GABA Agonists/pharmacology, Morpholines/pharmacology, Muscimol/pharmacology, Neural Inhibition/drug effects/*physiology/radiation effects, Neurons/drug effects/*physiology/radiation effects, Patch-Clamp Techniques, Radiation, Sprague-Dawley},
	pages = {1594--1600},
}

@article{koulakov_orientation_2001,
	title = {Orientation preference patterns in mammalian visual cortex: a wire length minimization approach},
	volume = {29},
	abstract = {In the visual cortex of many mammals, orientation preference changes smoothly along the cortical surface, with the exception of singularities such as pinwheels and fractures. The reason for the existence of these singularities has remained elusive, suggesting that they are developmental artifacts. We show that singularities reduce the length of intracortical neuronal connections for some connection rules. Therefore, pinwheels and fractures could be evolutionary adaptations keeping cortical volume to a minimum. Wire length minimization approach suggests that interspecies differences in orientation preference maps reflect differences in intracortical neuronal circuits, thus leading to experimentally testable predictions. We discuss application of our model to direction preference maps.},
	language = {eng},
	number = {2},
	journal = {Neuron},
	author = {Koulakov, A A and Chklovskii, D B},
	year = {2001},
	note = {Place: The Salk Institute, 10010 North Torrey Pines Road, La Jolla, CA 92037, USA.},
	keywords = {Animals, merged\_fiete.bib, *Models, Neurological, Neurons/*physiology, Orientation/*physiology, Mammals/physiology, Species Specificity, Visual Cortex/*physiology},
	pages = {519--527},
}

@article{ohki_highly_2006,
	title = {Highly ordered arrangement of single neurons in orientation pinwheels},
	volume = {442},
	abstract = {In the visual cortex of higher mammals, neurons are arranged across the cortical surface in an orderly map of preferred stimulus orientations. This map contains 'orientation pinwheels', structures that are arranged like the spokes of a wheel such that orientation changes continuously around a centre. Conventional optical imaging first demonstrated these pinwheels, but the technique lacked the spatial resolution to determine the response properties and arrangement of cells near pinwheel centres. Electrophysiological recordings later demonstrated sharply selective neurons near pinwheel centres, but it remained unclear whether they were arranged randomly or in an orderly fashion. Here we use two-photon calcium imaging in vivo to determine the microstructure of pinwheel centres in cat visual cortex with single-cell resolution. We find that pinwheel centres are highly ordered: neurons selective to different orientations are clearly segregated even in the very centre. Thus, pinwheel centres truly represent singularities in the cortical map. This highly ordered arrangement at the level of single cells suggests great precision in the development of cortical circuits underlying orientation selectivity.},
	language = {eng},
	number = {7105},
	journal = {Nature},
	author = {Ohki, Kenichi and Chung, Sooyoung and Kara, Prakash and Hubener, Mark and Bonhoeffer, Tobias and Reid, R Clay},
	year = {2006},
	note = {Place: Department of Neurobiology, Harvard Medical School, Boston, Massachusetts 02115, USA.},
	keywords = {Animals, merged\_fiete.bib, Neurological, Models, Electrophysiology, Cats, Morphogenesis, Neurons/*cytology/*physiology, Photic Stimulation, Visual Cortex/*cytology/growth \& development/*physiology},
	pages = {925--928},
}

@article{white_vision_2007,
	title = {Vision and cortical map development},
	volume = {56},
	abstract = {Functional maps arise in developing visual cortex as response selectivities become organized into columnar patterns of population activity. Recent studies of developing orientation and direction maps indicate that both are sensitive to visual experience, but not to the same degree or duration. Direction maps have a greater dependence on early vision, while orientation maps remain sensitive to experience for a longer period of cortical maturation. There is also a darker side to experience: abnormal vision through closed lids produces severe impairments in neuronal selectivity, rendering these maps nearly undetectable. Thus, the rules that govern their formation and the construction of the underlying neural circuits are modulated-for better or worse-by early vision. Direction maps, and possibly maps of other properties that are dependent upon precise conjunctions of spatial and temporal signals, are most susceptible to the potential benefits and maladaptive consequences of early sensory experience.},
	language = {eng},
	number = {2},
	journal = {Neuron},
	author = {White, Leonard E and Fitzpatrick, David},
	year = {2007},
	note = {Place: Department of Neurobiology, Duke University Medical Center, Durham, NC 27710, USA. len.white@duke.edu},
	keywords = {Humans, Animals, merged\_fiete.bib, Vision/*physiology, Visual Cortex/growth \& development/*physiology, Visual Pathways/growth \& development/*physiology, Visual Perception/physiology},
	pages = {327--338},
}

@article{bonhoeffer_iso-orientation_1991,
	title = {Iso-orientation domains in cat visual cortex are arranged in pinwheel-like patterns},
	volume = {353},
	abstract = {The mammalian cortex is organized in a columnar fashion: neurons lying below each other from the pia to the white matter usually share many functional properties. Across the cortical surface, cells with similar response properties are also clustered together, forming elongated bands or patches. Some response properties, such as orientation preference in the visual cortex, change gradually across the cortical surface forming 'orientation maps'. To determine the precise layout of iso-orientation domains, knowledge of responses not only to one but to many stimulus orientations is essential. Therefore, the exact depiction of orientation maps has been hampered by technical difficulties and remained controversial for almost thirty years. Here we use in vivo optical imaging based on intrinsic signals to gather information on the responses of a piece of cortex to gratings in many different orientations. This complete set of responses then provides detailed information on the structure of the orientation map in a large patch of cortex from area 18 of the cat. We find that cortical regions that respond best to one orientation form highly ordered patches rather than elongated bands. These iso-orientation patches are organized around 'orientation centres', producing pinwheel-like patterns in which the orientation preference of cells is changing continuously across the cortex. We have also analysed our data for fast changes in orientation preference and find that these 'fractures' are limited to the orientation centres. The pinwheels and orientation centres are such a prominent organizational feature that it should be important to understand their development as well as their function in the processing of visual information.},
	language = {eng},
	number = {6343},
	journal = {Nature},
	author = {Bonhoeffer, T and Grinvald, A},
	year = {1991},
	note = {Place: Rockefeller University, Laboratory of Neurobiology, New York, New York 10021.},
	keywords = {Animals, merged\_fiete.bib, Orientation/*physiology, Visual Perception/*physiology, Brain Mapping/methods, Cats/*anatomy \& histology/physiology, Computer-Assisted, Image Processing, Visual Cortex/*anatomy \& histology/physiology},
	pages = {429--431},
}

@inproceedings{raginsky_information_2008,
	title = {On the information capacity of {Gaussian} channels under small peak power constraints {On} the information capacity of {Gaussian} channels under small peak power {constraintsOn} the information capacity of {Gaussian} channels under small peak power constraints {On} the information capacity of {Gaussian} channels under small peak power constraints {On} the information capacity of {Gaussian} channels under small peak power constraints},
	booktitle = {Forty-{Sixth} {Annual} {Allerton} {Conference} on {Communication}, {Control}, and {Computing}},
	author = {Raginsky, M},
	year = {2008},
	keywords = {merged\_fiete.bib},
}

@article{pertzov_rapid_2012,
	title = {Rapid forgetting prevented by retrospective attention cues},
	volume = {doi: 10.1037/a0030947},
	journal = {J. Exp. Psychol. Hum. Percept. Perform.},
	author = {Pertzov, Y and Bays, P M and Joseph, S and Husain, M},
	year = {2012},
	keywords = {merged\_fiete.bib},
}

@article{fuster_inferotemporal_1981,
	title = {Inferotemporal neurons distinguish and retain behaviorally relevant features of visual stimuli},
	volume = {212},
	abstract = {Single-cell activity was recorded in the inferotemporal cortex of monkeys performing a task that requires perception and temporary retention of colored stimuli. Many cells reacted differentially to the stimuli. By changing the relevance of certain features of compound stimuli, it was found that the reactions of some cells to color depend critically on whether or not the task demands that the animal pay attention to color. A substantial number of cells showed color-dependent differences in frequency of discharge during the retention periods of the task. The temporal characteristics of differential discharge and its dissolution when memory is no longer required indicate that the cells that display it are involved in retaining visual information.},
	number = {4497},
	journal = {Science},
	author = {Fuster, J M and Jervey, J P},
	month = may,
	year = {1981},
	keywords = {merged\_fiete.bib},
	pages = {952--955},
}

@article{wang_synaptic_2001,
	title = {Synaptic reverberation underlying mnemonic persistent activity},
	volume = {24},
	abstract = {Stimulus-specific persistent neural activity is the neural process underlying active (working) memory. Since its discovery 30 years ago, mnemonic activity has been hypothesized to be sustained by synaptic reverberation in a recurrent circuit. Recently, experimental and modeling work has begun to test the reverberation hypothesis at the cellular level. Moreover, theory has been developed to describe memory storage of an analog stimulus (such as spatial location or eye position), in terms of continuous 'bump attractors' and 'line attractors'. This review summarizes new studies, and discusses insights and predictions from biophysically based models. The stability of a working memory network is recognized as a serious problem; stability can be achieved if reverberation is largely mediated by NMDA receptors at recurrent synapses.},
	number = {8},
	journal = {Trends Neurosci.},
	author = {Wang, X J},
	month = aug,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {455--463},
}

@article{fuster_neuron_1971,
	title = {Neuron activity related to short-term memory},
	volume = {173},
	abstract = {Nerve cells in the monkey's prefrontal cortex and nucleus medialis dorsalis of the thalamus show changes of firing frequency associated with the performance of a delayed response test. Most cells increase firing during the cue presentation period or at the beginning of the ensuing delay; spike discharge highler than that in intertrial periods is present in some cells throughout the delay. These changes are interpreted as suggestive evidence of a role of frontothalamic circuits in the attentive process involved in short-term memory},
	number = {3997},
	journal = {Science},
	author = {Fuster, J M and Alexander, G E},
	month = aug,
	year = {1971},
	keywords = {merged\_fiete.bib},
	pages = {652--654},
}

@article{jun_heterogenous_2010,
	title = {Heterogenous population coding of a short-term memory and decision task},
	volume = {30},
	abstract = {We examined neural spike recordings from prefrontal cortex (PFC) while monkeys performed a delayed somatosensory discrimination task. In general, PFC neurons displayed great heterogeneity in response to the task. That is, although individual cells spiked reliably in response to task variables from trial-to-trial, each cell had idiosyncratic combinations of response properties. Despite the great variety in response types, some general patterns held. We used linear regression analysis on the spike data to both display the full heterogeneity of the data and classify cells into categories. We compared different categories of cells and found little difference in their ability to carry information about task variables or their correlation to behavior. This suggests a distributed neural code for the task rather than a highly modularized one. Along this line, we compared the predictions of two theoretical models to the data. We found that cell types predicted by both models were not represented significantly in the population. Our study points to a different class of models that should embrace the inherent heterogeneity of the data, but should also account for the nonrandom features of the population.},
	number = {3},
	journal = {J. Neurosci.},
	author = {Jun, Joseph K and Miller, Paul and Hernández, Adrián and Zainos, Antonio and Lemus, Luis and Brody, Carlos D and Romo, Ranulfo},
	month = jan,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {916--929},
}

@article{matell_heterogeneous_2011,
	title = {A heterogeneous population code for elapsed time in rat medial agranular cortex},
	volume = {125},
	abstract = {The neural mechanisms underlying the temporal control of behavior are largely unknown. Here we recorded from medial agranular cortex neurons in rats while they freely behaved in a temporal production task, the peak-interval procedure. Due to variability in estimating the time of food availability, robust responding typically bracketed the expected duration, starting some time before and ending some time after the signaled delay. These response periods provided analytic “steady state” windows during which subjects actively indicated their temporal expectation of food availability. Remarkably, during these response periods, a variety of firing patterns were seen that could be broadly described as ramps, peaks, and dips, with different slopes, directions, and times at which maxima or minima occur. Regularized linear discriminant analysis indicated that these patterns provided sufficiently reliable information to discriminate the elapsed duration of responding within these response periods. Modeling this across neuron variability showed that the utilization of ramps, dips, and peaks, with different slopes and minimal/maximal rates at different times, led to a substantial improvement in temporal prediction errors, suggesting that heterogeneity in the neural representation of elapsed time may facilitate temporally controlled behavior.},
	number = {1},
	journal = {Behav. Neurosci.},
	author = {Matell, Matthew S and Shea-Brown, Eric and Gooch, Cindy and Wilson, A George and Rinzel, John},
	month = feb,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {54--73},
}

@article{super_neural_2001,
	title = {A neural correlate of working memory in the monkey primary visual cortex},
	volume = {293},
	abstract = {The brain frequently needs to store information for short periods. In vision, this means that the perceptual correlate of a stimulus has to be maintained temporally once the stimulus has been removed from the visual scene. However, it is not known how the visual system transfers sensory information into a memory component. Here, we identify a neural correlate of working memory in the monkey primary visual cortex (V1). We propose that this component may link sensory activity with memory activity.},
	number = {5527},
	journal = {Science},
	author = {Supèr, H and Spekreijse, H and Lamme, V A},
	month = jul,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {120--124},
}

@article{funahashi_prefrontal_2006,
	title = {Prefrontal cortex and working memory processes},
	volume = {139},
	abstract = {Working memory is a mechanism for short-term active maintenance of information as well as for processing maintained information. The dorsolateral prefrontal cortex has been known to participate in working memory. The analysis of task-related dorsolateral prefrontal cortex activity while monkeys performed a variety of working memory tasks revealed that delay-period activity is a neural correlate of a mechanism for temporary active maintenance of information, because this activity persisted throughout the delay period, showed selectivity to a particular visual feature, and was related to correct behavioral performances. Information processing can be considered as a change of the information represented by a population of neural activities during the progress of the trial. Using population vectors calculated by a population of task-related dorsolateral prefrontal cortex activities, we demonstrated the temporal change of information represented by a population of dorsolateral prefrontal cortex activities during performances of spatial working memory tasks. Cross-correlation analysis using spike firings of simultaneously isolated pairs of neurons reveals widespread functional interactions among neighboring neurons, especially neurons having delay-period activity, and their dynamic modulation depending on the context of the trial. Functional interactions among neurons and their dynamic modulation could be a mechanism of information processing in the dorsolateral prefrontal cortex.},
	number = {1},
	journal = {J. Neurosci.},
	author = {Funahashi, S},
	month = apr,
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {251--261},
}

@article{barak_neuronal_2010,
	title = {Neuronal population coding of parametric working memory},
	volume = {30},
	abstract = {Comparing two sequentially presented stimuli is a widely used experimental paradigm for studying working memory. The delay activity of many single neurons in the prefrontal cortex (PFC) of monkeys was found to be stimulus-specific, however, population dynamics of stimulus representation has not been elucidated. We analyzed the population state of a large number of PFC neurons during a somatosensory discrimination task. Using the tuning curves of the neurons, we derived a compact characterization of the population state. Stimulus representation by the population was found to degrade after stimulus termination, and emerge in a different form toward the end of the delay. Specifically, the tuning properties of neurons were found to change during the task. We suggest a mechanism whereby information about the stimulus is contained in activity-dependent synaptic facilitation of recurrent connections.},
	number = {28},
	journal = {J. Neurosci.},
	author = {Barak, Omri and Tsodyks, Misha and Romo, Ranulfo},
	month = jul,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {9424--9430},
}

@article{mongillo_synaptic_2008,
	title = {Synaptic theory of working memory},
	volume = {319},
	abstract = {It is usually assumed that enhanced spiking activity in the form of persistent reverberation for several seconds is the neural correlate of working memory. Here, we propose that working memory is sustained by calcium-mediated synaptic facilitation in the recurrent connections of neocortical networks. In this account, the presynaptic residual calcium is used as a buffer that is loaded, refreshed, and read out by spiking activity. Because of the long time constants of calcium kinetics, the refresh rate can be low, resulting in a mechanism that is metabolically efficient and robust. The duration and stability of working memory can be regulated by modulating the spontaneous activity in the network.},
	number = {5869},
	journal = {Science},
	author = {Mongillo, Gianluigi and Barak, Omri and Tsodyks, Misha},
	month = mar,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {1543--1546},
}

@article{wei_distributed_2012,
	title = {From distributed resources to limited slots in multiple-item working memory: a spiking network model with normalization},
	volume = {32},
	abstract = {Recent behavioral studies have given rise to two contrasting models for limited working memory capacity: a “discrete-slot” model in which memory items are stored in a limited number of slots, and a “shared-resource” model in which the neural representation of items is distributed across a limited pool of resources. To elucidate the underlying neural processes, we investigated a continuous network model for working memory of an analog feature. Our model network fundamentally operates with a shared resource mechanism, and stimuli in cue arrays are encoded by a distributed neural population. On the other hand, the network dynamics and performance are also consistent with the discrete-slot model, because multiple objects are maintained by distinct localized population persistent activity patterns (bump attractors). We identified two phenomena of recurrent circuit dynamics that give rise to limited working memory capacity. As the working memory load increases, a localized persistent activity bump may either fade out (so the memory of the corresponding item is lost) or merge with another nearby bump (hence the resolution of mnemonic representation for the merged items becomes blurred). We identified specific dependences of these two phenomena on the strength and tuning of recurrent synaptic excitation, as well as network normalization: the overall population activity is invariant to set size and delay duration; therefore, a constant neural resource is shared by and dynamically allocated to the memorized items. We demonstrate that the model reproduces salient observations predicted by both discrete-slot and shared-resource models, and propose testable predictions of the merging phenomenon.},
	number = {33},
	journal = {J. Neurosci.},
	author = {Wei, Ziqiang and Wang, Xiao-Jing and Wang, Da-Hui},
	month = aug,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {11228--11240},
}

@article{elmore_visual_2011,
	title = {Visual short-term memory compared in rhesus monkeys and humans},
	volume = {21},
	abstract = {Change detection is a popular task to study visual short-term memory (STM) in humans [1-4]. Much of this work suggests that STM has a fixed capacity of 4 {\textbackslash}pm 1 items [1-6]. Here we report the first comparison of change-detection memory between humans and a species closely related to humans, the rhesus monkey. Monkeys and humans were tested in nearly identical procedures with overlapping display sizes. Although the monkeys' STM was well fit by a one-item fixed-capacity memory model, other monkey memory tests with four-item lists have shown performance impossible to obtain with a one-item capacity [7]. We suggest that this contradiction can be resolved using a continuous-resource approach more closely tied to the neural basis of memory [8, 9]. In this view, items have a noisy memory representation whose noise level depends on display size as a result of the distributed allocation of a continuous resource. In accord with this theory, we show that performance depends on the perceptual distance between items before and after the change, and d' depends on display size in an approximately power-law fashion. Our results open the door to combining the power of psychophysics, computation, and physiology to better understand the neural basis of STM.},
	number = {11},
	journal = {Curr. Biol.},
	author = {Elmore, L Caitlin and Ma, Wei Ji and Magnotti, John F and Leising, Kenneth J and Passaro, Antony D and Katz, Jeffrey S and Wright, Anthony A},
	month = jun,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {975--979},
}

@article{van_den_berg_variability_2012,
	title = {Variability in encoding precision accounts for visual short-term memory limitations},
	volume = {109},
	abstract = {It is commonly believed that visual short-term memory (VSTM) consists of a fixed number of “slots” in which items can be stored. An alternative theory in which memory resource is a continuous quantity distributed over all items seems to be refuted by the appearance of guessing in human responses. Here, we introduce a model in which resource is not only continuous but also variable across items and trials, causing random fluctuations in encoding precision. We tested this model against previous models using two VSTM paradigms and two feature dimensions. Our model accurately accounts for all aspects of the data, including apparent guessing, and outperforms slot models in formal model comparison. At the neural level, variability in precision might correspond to variability in neural population gain and doubly stochastic stimulus representation. Our results suggest that VSTM resource is continuous and variable rather than discrete and fixed and might explain why subjective experience of VSTM is not all or none.},
	number = {22},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {van den Berg, Ronald and Shin, Hongsup and Chou, Wen-Chuang and George, Ryan and Ma, Wei Ji},
	month = may,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {8780--8785},
}

@article{lewandowsky_no_2009,
	title = {No temporal decay in verbal short-term memory},
	volume = {13},
	abstract = {Many models of short-term memory (STM) ascribe an important role to temporal decay and forgetting because of the passage of time alone. We argue against decay as the primary form of forgetting from STM, and suggest that new experimental methodologies and recent models provide new perspectives on the old issue of the causes of forgetting. We show that several classic sources of evidence for time-based forgetting can be re-interpreted in terms of an interference-based view, and that new experiments provide compelling evidence against decay. We conclude that progress requires moving beyond demonstrations of qualitative effects and focusing instead on testing quantitative predictions of models.},
	number = {3},
	journal = {Trends Cogn. Sci.},
	author = {Lewandowsky, Stephan and Oberauer, Klaus and Brown, Gordon D A},
	month = mar,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {120--126},
}

@article{barrouillet_time_2012,
	title = {Time causes forgetting from working memory},
	volume = {19},
	abstract = {Although forgetting in the short term is a ubiquitous phenomenon, its exact causes remain undecided. The aim of the present study was to test the temporal decay hypothesis according to which memory traces fade away with time when attention is diverted by concurrent activities. In two experiments involving complex span tasks, adults were asked to remember series of items (either letters or spatial locations) while verifying multiplications. The duration of processing was manipulated by presenting multiplications either in word (three {\textbackslash}times four = twelve) or digit (3 {\textbackslash}times 4 = 12) format, the former taking longer to solve, while the time available to restore memory traces after each operation was kept constant across conditions. In line with the temporal decay hypothesis, the longer solution times elicited by solving word multiplications resulted in poorer recall performance. The fact that longer processing times had a comparable effect on both verbal and visuospatial memory and that the difference between conditions remained stable from the first to the last trials makes it difficult to account for these findings by assuming that forgetting is exclusively due to representation-based interference or buildup of proactive interference.},
	number = {1},
	journal = {Psychon. Bull. Rev.},
	author = {Barrouillet, Pierre and De Paepe, Annick and Langerock, Naomi},
	month = feb,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {87--92},
}

@article{luck_capacity_1997,
	title = {The capacity of visual working memory for features and conjunctions},
	volume = {390},
	abstract = {Short-term memory storage can be divided into separate subsystems for verbal information and visual information, and recent studies have begun to delineate the neural substrates of these working-memory systems. Although the verbal storage system has been well characterized, the storage capacity of visual working memory has not yet been established for simple, suprathreshold features or for conjunctions of features. Here we demonstrate that it is possible to retain information about only four colours or orientations in visual working memory at one time. However, it is also possible to retain both the colour and the orientation of four objects, indicating that visual working memory stores integrated objects rather than individual features. Indeed, objects defined by a conjunction of four features can be retained in working memory just as well as single-feature objects, allowing sixteen individual features to be retained when distributed across four objects. Thus, the capacity of visual working memory must be understood in terms of integrated objects rather than individual features, which places significant constraints on cognitive and neurobiological models of the temporary storage of visual information.},
	number = {6657},
	journal = {Nature},
	author = {Luck, S J and Vogel, E K},
	month = nov,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {279--281},
}

@article{zhang_sudden_2009,
	title = {Sudden death and gradual decay in visual working memory},
	volume = {20},
	abstract = {General Douglas MacArthur remarked that “old soldiers never die; they just fade away.” For decades, researchers have concluded that visual working memories, like old soldiers, fade away gradually, becoming progressively less precise as they are retained for longer periods of time. However, these conclusions were based on threshold-estimation procedures in which the complete termination of a memory could artifactually produce the appearance of lower precision. Here, we use a recall-based visual working memory paradigm that provides separate measures of the probability that a memory is available and the precision of the memory when it is available. Using this paradigm, we demonstrate that visual working memory representations may be retained for several seconds with little or no loss of precision, but that they may terminate suddenly and completely during this period.},
	number = {4},
	journal = {Psychol. Sci.},
	author = {Zhang, Weiwei and Luck, Steven J},
	month = apr,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {423--428},
}

@article{zhang_discrete_2008,
	title = {Discrete fixed-resolution representations in visual working memory},
	volume = {453},
	abstract = {Limits on the storage capacity of working memory significantly affect cognitive abilities in a wide range of domains, but the nature of these capacity limits has been elusive. Some researchers have proposed that working memory stores a limited set of discrete, fixed-resolution representations, whereas others have proposed that working memory consists of a pool of resources that can be allocated flexibly to provide either a small number of high-resolution representations or a large number of low-resolution representations. Here we resolve this controversy by providing independent measures of capacity and resolution. We show that, when presented with more than a few simple objects, human observers store a high-resolution representation of a subset of the objects and retain no information about the others. Memory resolution varied over a narrow range that cannot be explained in terms of a general resource pool but can be well explained by a small set of discrete, fixed-resolution representations.},
	number = {7192},
	journal = {Nature},
	author = {Zhang, Weiwei and Luck, Steven J},
	month = may,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {233--235},
}

@article{berut_experimental_2012,
	title = {Experimental verification of {Landauer}'s principle linking information and thermodynamics},
	volume = {483},
	abstract = {In 1961, Rolf Landauer argued that the erasure of information is a dissipative process. A minimal quantity of heat, proportional to the thermal energy and called the Landauer bound, is necessarily produced when a classical bit of information is deleted. A direct consequence of this logically irreversible transformation is that the entropy of the environment increases by a finite amount. Despite its fundamental importance for information theory and computer science, the erasure principle has not been verified experimentally so far, the main obstacle being the difficulty of doing single-particle experiments in the low-dissipation regime. Here we experimentally show the existence of the Landauer bound in a generic model of a one-bit memory. Using a system of a single colloidal particle trapped in a modulated double-well potential, we establish that the mean dissipated heat saturates at the Landauer bound in the limit of long erasure cycles. This result demonstrates the intimate link between information theory and thermodynamics. It further highlights the ultimate physical limit of irreversible computation.},
	number = {7388},
	journal = {Nature},
	author = {Bérut, Antoine and Arakelyan, Artak and Petrosyan, Artyom and Ciliberto, Sergio and Dillenschneider, Raoul and Lutz, Eric},
	month = mar,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {187--189},
}

@article{heath_defect-tolerant_1998,
	title = {A {Defect}-{Tolerant} {Computer} {Architecture}: {Opportunities} for {Nanotechnology}},
	journal = {Science},
	author = {Heath, James R and Kuekes, Philip J and Snider, Gregory S and Williams, R Stanley},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {1716--1721},
}

@article{vankampen_diffusion_1987,
	title = {Diffusion in inhomogeneous media},
	volume = {68},
	number = {2-3},
	journal = {UPB Bul. Stiint. Ser. B: Chem. Mater. Sci.},
	author = {VanKampen, N G},
	year = {1987},
	keywords = {merged\_fiete.bib},
	pages = {135--138},
}

@article{yau_error_1973,
	title = {Error {Correction} in {Redundant} {Residue} {Number} {Systems}},
	volume = {22},
	number = {1},
	journal = {IEEE Trans. Comput.},
	author = {Yau, S S-S and Liu, Yu-Cheng},
	month = jan,
	year = {1973},
	keywords = {merged\_fiete.bib, redundant residue number systems, burst residue errors, conditions for moduli, error correction, memory requirement, null Algorithms, single residue errors, speed.},
	pages = {5--11},
}

@article{baum_internal_1988,
	title = {Internal representations for associative memory},
	volume = {59},
	abstract = {We describe a class of feed forward neural network models for associative content addressable memory (ACAM) which utilize sparse internal representations for stored data. In addition to the input and output layers, our networks incorporate an intermediate processing layer which serves to label each stored memory and to perform error correction and association. We study two classes of internal label representations: the unary representation and various sparse, distributed representations. Finally, we consider storage of sparse data and sparsification of data. These models are found to have advantages in terms of storage capacity, hardware efficiency, and recall reliability when compared to the Hopfield model, and to possess analogies to both biological neural networks and standard digital computer memories.},
	number = {4},
	journal = {Biol. Cybern.},
	author = {Baum, E and Moody, J and Wilczek, F},
	month = jul,
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {217--228},
}

@article{lever_what_2002,
	title = {What can the hippocampal representation of environmental geometry tell us about {Hebbian} learning?},
	volume = {87},
	number = {5},
	journal = {Biol. Cybern.},
	author = {Lever, Colin and Burgess, Neil and Cacucci, Francesca and Hartley, Tom and O'Keefe, John},
	month = dec,
	year = {2002},
	note = {Publisher: Springer Berlin / Heidelberg},
	keywords = {merged\_fiete.bib, Computer Science},
	pages = {356--372},
}

@article{ahmed_hippocampal_2009,
	title = {The hippocampal rate code: anatomy, physiology and theory},
	volume = {32},
	abstract = {Since the days of Cajal, the CA1 pyramidal cell has arguably received more attention than any other neuron in the mammalian brain. Hippocampal CA1 pyramidal cells fire spikes with remarkable spatial and temporal precision, giving rise to the hippocampal rate and temporal codes. However, little is known about how different inputs interact during spatial behavior to generate such robust firing patterns. Here, we review the properties of the rodent hippocampal rate code and synthesize work from several disciplines to understand the functional anatomy and excitation-inhibition balance that can produce the rate-coded outputs of the CA1 pyramidal cell. We argue that both CA3 and entorhinal inputs are crucial for the formation of sharp, sparse CA1 place fields and that precisely timed and dominant inhibition is an equally important factor.},
	language = {eng},
	number = {6},
	journal = {Trends Neurosci.},
	author = {Ahmed, Omar J and Mehta, Mayank R},
	year = {2009},
	note = {Place: Department of Neuroscience, Brown University, Providence, RI 02912, USA. omar@brown.edu},
	keywords = {Animals, Rats, merged\_fiete.bib, Action Potentials/physiology, Neurological, Models, Entorhinal Cortex/*anatomy \& histology/*physiology, Hippocampus/*anatomy \& histology/*physiology, Interneurons/physiology, Neural Inhibition, Neural Pathways/anatomy \& histology/physiology, Pyramidal Cells/cytology/*physiology, Spatial Behavior/physiology, Synapses/physiology},
	pages = {329--338},
}

@article{carr_hippocampal_2011,
	title = {Hippocampal replay in the awake state: a potential substrate for memory consolidation and retrieval},
	volume = {14},
	abstract = {The hippocampus is required for the encoding, consolidation and retrieval of event memories. Although the neural mechanisms that underlie these processes are only partially understood, a series of recent papers point to awake memory replay as a potential contributor to both consolidation and retrieval. Replay is the sequential reactivation of hippocampal place cells that represent previously experienced behavioral trajectories and occurs frequently in the awake state, particularly during periods of relative immobility. Awake replay may reflect trajectories through either the current environment or previously visited environments that are spatially remote. The repetition of learned sequences on a compressed time scale is well suited to promote memory consolidation in distributed circuits beyond the hippocampus, suggesting that consolidation occurs in both the awake and sleeping animal. Moreover, sensory information can influence the content of awake replay, suggesting a role for awake replay in memory retrieval.},
	language = {eng},
	number = {2},
	journal = {Nat. Neurosci.},
	author = {Carr, Margaret F and Jadhav, Shantanu P and Frank, Loren M},
	year = {2011},
	note = {Place: Department of Physiology, University of California, San Francisco, San Francisco, California, USA.},
	keywords = {Humans, merged\_fiete.bib, Hippocampus/*physiology, Sleep/physiology, Neurons/physiology, Memory/*physiology, Wakefulness/*physiology},
	pages = {147--153},
}

@article{paradiso_theory_1988-1,
	title = {A theory for the use of visual orientation information which exploits the columnar structure of striate cortex},
	volume = {58},
	abstract = {A neural model is constructed based on the structure of a visual orientation hypercolumn in mammalian striate cortex. It is then assumed that the perceived orientation of visual contours is determined by the pattern of neuronal activity across orientation columns. Using statistical estimation theory, limits on the precision of orientation estimation and discrimination are calculated. These limits are functions of single unit response properties such as orientation tuning width, response amplitude and response variability, as well as the degree of organization in the neural network. It is shown that a network of modest size, consisting of broadly orientation selective units, can reliably discriminate orientation with a precision equivalent to human performance. Of the various network parameters, the discrimination threshold depends most critically on the number of cells in the hypercolumn. The form of the dependence on cell number correctly predicts the results of psychophysical studies of orientation discrimination. The model system's performance is also consistent with psychophysical data in two situations in which human performance is not optimal. First, interference with orientation discrimination occurs when multiple stimuli activate cells in the same hypercolumn. Second, systematic errors in the estimation of orientation can occur when a stimulus is composed of intersecting lines. The results demonstrate that it is possible to relate neural activity to visual performance by an examination of the pattern of activity across orientation columns. This provides support for the hypothesis that perceived orientation is determined by the distributed pattern of neural activity. The results also encourage the view that limits on visual discrimination are determined by the responses of many neurons rather than the sensitivity of individual cells.},
	language = {eng},
	number = {1},
	journal = {Biol. Cybern.},
	author = {Paradiso, M A},
	year = {1988},
	note = {Place: Neurobiology Group, University of California, Berkeley 94720.},
	keywords = {Humans, Animals, merged\_fiete.bib, *Models, Neurological, *Orientation, Visual Perception/*physiology, Visual Cortex/*physiology, Discrimination (Psychology)},
	pages = {35--49},
}

@article{langston_development_2010,
	title = {Development of the spatial representation system in the rat},
	volume = {328},
	abstract = {In the adult brain, space and orientation are represented by an elaborate hippocampal-parahippocampal circuit consisting of head-direction cells, place cells, and grid cells. We report that a rudimentary map of space is already present when 2 1/2-week-old rat pups explore an open environment outside the nest for the first time. Head-direction cells in the pre- and parasubiculum have adultlike properties from the beginning. Place and grid cells are also present but evolve more gradually. Grid cells show the slowest development. The gradual refinement of the spatial representation is accompanied by an increase in network synchrony among entorhinal stellate cells. The presence of adultlike directional signals at the onset of navigation raises the possibility that such signals are instrumental in setting up networks for place and grid representation.},
	language = {eng},
	number = {5985},
	journal = {Science},
	author = {Langston, Rosamund F and Ainge, James A and Couey, Jonathan J and Canto, Cathrin B and Bjerknes, Tale L and Witter, Menno P and Moser, Edvard I and Moser, May-Britt},
	year = {2010},
	note = {Place: Kavli Institute for Systems Neuroscience and Centre for the Biology of Memory, Medical Technical Research Center, Norwegian University of Science and Technology, Olav Kyrres gate 9, 7489 Trondheim, Norway.},
	keywords = {Orientation, Animals, Action Potentials, Neural Pathways, Rats, Male, Female, merged\_fiete.bib, Neurons/*physiology, *Spatial Behavior, Brain Mapping, Long-Evans, *Space Perception, Electrodes, Entorhinal Cortex/cytology/*physiology, Implanted, Exploratory Behavior, Patch-Clamp Techniques, Aging, CA1 Region, Hippocampal/*physiology, Nerve Net/physiology, Parahippocampal Gyrus/cytology/*physiology},
	pages = {1576--1580},
}

@article{henriksen_spatial_2010,
	title = {Spatial representation along the proximodistal axis of {CA1}},
	volume = {68},
	abstract = {CA1 cells receive direct input from space-responsive cells in medial entorhinal cortex (MEC), such as grid cells, as well as more nonspatial cells in lateral entorhinal cortex (LEC). Because MEC projects preferentially to the proximal part of the CA1, bordering CA2, whereas LEC innervates only the distal part, bordering subiculum, we asked if spatial tuning is graded along the transverse axis of CA1. Tetrodes were implanted along the entire proximodistal axis of dorsal CA1 in rats. Data were recorded in cylinders large enough to elicit firing at more than one location in many neurons. Distal CA1 cells showed more dispersed firing and had a larger number of firing fields than proximal cells. Phase-locking of spikes to MEC theta oscillations was weaker in distal CA1 than in proximal CA1. The findings suggest that spatial firing in CA1 is organized transversally, with the strongest spatial modulation occurring in the MEC-associated proximal part.},
	language = {eng},
	number = {1},
	journal = {Neuron},
	author = {Henriksen, Espen J and Colgin, Laura L and Barnes, Carol A and Witter, Menno P and Moser, May-Britt and Moser, Edvard I},
	year = {2010},
	note = {Place: Kavli Institute for Systems Neuroscience, Norwegian University of Science and Technology, Trondheim, Norway.},
	keywords = {Animals, Rats, Male, merged\_fiete.bib, Action Potentials/physiology, Behavior, Spatial Behavior/*physiology, Brain Mapping, Long-Evans, Electrodes, Exploratory Behavior/physiology, CA1 Region, Animal, Electroencephalography/methods, Entorhinal Cortex/physiology, Hippocampal/*cytology/*physiology, Neural Pathways/physiology, Neurons/classification/*physiology, Periodicity},
	pages = {127--137},
}

@article{burgess_grid_2008-1,
	title = {Grid cells and theta as oscillatory interference: theory and predictions},
	volume = {18},
	abstract = {The oscillatory interference model [Burgess et al. (2007) Hippocampus 17:801-802] of grid cell firing is reviewed as an algorithmic level description of path integration and as an implementation level description of grid cells and their inputs. New analyses concern the relationships between the variables in the model and the theta rhythm, running speed, and the intrinsic firing frequencies of grid cells. New simulations concern the implementation of velocity-controlled oscillators (VCOs) with different preferred directions in different neurons. To summarize the model, the distance traveled along a specific direction is encoded by the phase of a VCO relative to a baseline frequency. Each VCO is an intrinsic membrane potential oscillation whose frequency increases from baseline as a result of depolarization by synaptic input from speed modulated head-direction cells. Grid cell firing is driven by the VCOs whose preferred directions match the current direction of motion. VCOs are phase-reset by location-specific input from place cells to prevent accumulation of error. The baseline frequency is identified with the local average of VCO frequencies, while EEG theta frequency is identified with the global average VCO frequency and comprises two components: the frequency at zero speed and a linear response to running speed. Quantitative predictions are given for the inter-relationships between a grid cell's intrinsic firing frequency and grid scale, the two components of theta frequency, and the running speed of the animal. Qualitative predictions are given for the properties of the VCOs, and the relationship between environmental novelty, the two components of theta, grid scale and place cell remapping.},
	language = {eng},
	number = {12},
	journal = {Hippocampus},
	author = {Burgess, Neil},
	year = {2008},
	note = {Place: Institute of Cognitive Neuroscience, University College London. n.burgess@ucl.ac.uk},
	keywords = {Animals, Computer Simulation, merged\_fiete.bib, Neurons/*physiology, Space Perception/physiology, Nerve Net/*physiology, Synaptic Transmission/physiology, *Theta Rhythm, Action Potentials/*physiology, Biological Clocks/*physiology, Entorhinal Cortex/*physiology},
	pages = {1157--1174},
}

@article{deneve_efficient_2001,
	title = {Efficient computation and cue integration with noisy population codes},
	volume = {4},
	abstract = {The brain represents sensory and motor variables through the activity of large populations of neurons. It is not understood how the nervous system computes with these population codes, given that individual neurons are noisy and thus unreliable. We focus here on two general types of computation, function approximation and cue integration, as these are powerful enough to handle a range of tasks, including sensorimotor transformations, feature extraction in sensory systems and multisensory integration. We demonstrate that a particular class of neural networks, basis function networks with multidimensional attractors, can perform both types of computation optimally with noisy neurons. Moreover, neurons in the intermediate layers of our model show response properties similar to those observed in several multimodal cortical areas. Thus, basis function networks with multidimensional attractors may be used by the brain to compute efficiently with population codes.},
	number = {8},
	journal = {Nat. Neurosci.},
	author = {Deneve, S and Latham, P E and Pouget, A},
	month = aug,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {826--831},
}

@article{deneve_reading_1999,
	title = {Reading population codes: a neural implementation of ideal observers},
	volume = {2},
	abstract = {Many sensory and motor variables are encoded in the nervous system by the activities of large populations of neurons with bell-shaped tuning curves. Extracting information from these population codes is difficult because of the noise inherent in neuronal responses. In most cases of interest, maximum likelihood (ML) is the best read-out method and would be used by an ideal observer. Using simulations and analysis, we show that a close approximation to ML can be implemented in a biologically plausible model of cortical circuitry. Our results apply to a wide range of nonlinear activation functions, suggesting that cortical areas may, in general, function as ideal observers of activity in preceding areas.},
	number = {8},
	journal = {Nat. Neurosci.},
	author = {Deneve, S and Latham, P E and Pouget, A},
	month = aug,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {740--745},
}

@article{ludvig_place_1999,
	title = {Place cells can flexibly terminate and develop their spatial firing. {A} new theory for their function},
	volume = {67},
	abstract = {In this study, hippocampal place cells were recorded in a behavioral paradigm previously not employed in place-cell research. Rats were exposed to the same fixed environment for as long as 8-24 h without interruption, while the firing of CA1 and CA3 place cells was monitored continuously. The first finding was that all place cells that were detected at the beginning of the recording sessions ceased to produce location-specific firing in their original firing fields within 2-12 h. This was observed despite the fact that the animals kept visiting the original firing fields, the hippocampal EEG was virtually unchanged, and the discriminated action potentials of the cells could be clearly recorded. The second finding was that some complex-spike cells that produced no spatially selective firing pattern at the beginning of the recording sessions developed location-specific discharges within 3-12 h. Thus, place cells can flexibly terminate and develop their spatial firing. even in a fixed environment and during similar behaviors, if that environment is explored continuously for a prolonged period. To explain this phenomenon, a new place-cell theory is outlined. Accordingly, the high-frequency discharges of these neurons may serve to create, under multiple extrahippocampal control and within limited periods, stable engrams for specific spatial sites in the association cortex where the cognitive map probably resides. After the creation of a stable engram, or in the absence of favorable extrahippocampal inputs, place cells may suspend their location-specific firing in the original field, and initiate the processing of another spatial site.},
	language = {eng},
	number = {1},
	journal = {Physiol. Behav.},
	author = {Ludvig, N},
	year = {1999},
	note = {Place: Department of Physiology and Pharmacology, State University of New York, Health Science Center at Brooklyn, 11203, USA. ludvin10@bmec.hcsbklyn.edu},
	keywords = {Animals, Rats, Male, merged\_fiete.bib, Hippocampus/*physiology, Spatial Behavior/*physiology, Brain Mapping, Long-Evans, Exploratory Behavior/physiology, Neurons/physiology, Neural Pathways/physiology, Cerebral Cortex/physiology, Long-Term Potentiation/physiology, Mental Recall/*physiology, Social Environment, Synaptic Transmission/*physiology},
	pages = {57--67},
}

@article{fenton_unmasking_2008,
	title = {Unmasking the {CA1} ensemble place code by exposures to small and large environments: more place cells and multiple, irregularly arranged, and expanded place fields in the larger space},
	volume = {28},
	abstract = {In standard experimental environments, a constant proportion of CA1 principal cells are place cells, each with a spatial receptive field called a place field. Although the properties of place cells are a basis for understanding the mammalian representation of spatial knowledge, there is no consensus on which of the two fundamental neural-coding hypotheses correctly accounts for how place cells encode spatial information. Within the dedicated-coding hypothesis, the current activity of each cell is an independent estimate of the location with respect to its place field. The average of the location estimates from many cells represents current location, so a dedicated place code would degrade if single cells had multiple place fields. Within the alternative, ensemble-coding hypothesis, the concurrent discharge of many place cells is a vector that represents current location. An ensemble place code is not degraded if single cells have multiple place fields as long as the discharge vector at each location is unique. Place cells with multiple place fields might be required to represent the substantially larger space in more natural environments. To distinguish between the dedicated-coding and ensemble-coding hypotheses, we compared the characteristics of CA1 place fields in a standard cylinder and an approximately six times larger chamber. Compared with the cylinder, in the chamber, more CA1 neurons were place cells, each with multiple, irregularly arranged, and enlarged place fields. The results indicate that multiple place fields is a fundamental feature of CA1 place cell activity and that, consequently, an ensemble place code is required for CA1 discharge to accurately signal location.},
	language = {eng},
	number = {44},
	journal = {J. Neurosci.},
	author = {Fenton, Andre A and Kao, Hsin-Yi and Neymotin, Samuel A and Olypher, Andrey and Vayntrub, Yevgeniy and Lytton, William W and Ludvig, Nandor},
	year = {2008},
	note = {Place: Department of Physiology and Pharmacology, State University of New York, Brooklyn, NY, New York 11203, USA. afenton@downstate.edu},
	keywords = {Animals, Rats, Male, merged\_fiete.bib, Action Potentials/physiology, Neurons/*physiology, *Environment, Long-Evans, Space Perception/*physiology, Extracellular Space/*physiology, Hippocampus/cytology/physiology},
	pages = {11250--11262},
}

@article{barry_boundary_2006,
	title = {The boundary vector cell model of place cell firing and spatial memory},
	volume = {17},
	abstract = {We review evidence for the boundary vector cell model of the environmental determinants of the firing of hippocampal place cells. Preliminary experimental results are presented concerning the effects of addition or removal of environmental boundaries on place cell firing and evidence that boundary vector cells may exist in the subiculum. We review and update computational simulations predicting the location of human search within a virtual environment of variable geometry, assuming that boundary vector cells provide one of the input representations of location used in mammalian spatial memory. Finally, we extend the model to include experience-dependent modification of connection strengths through a BCM-like learning rule - the size and sign of strength change is influenced by historic activity of the postsynaptic cell. Simulations are compared to experimental data on the firing of place cells under geometrical manipulations to their environment. The relationship between neurophysiological results in rats and spatial behaviour in humans is discussed.},
	language = {eng},
	number = {1-2},
	journal = {Rev. Neurosci.},
	author = {Barry, Caswell and Lever, Colin and Hayman, Robin and Hartley, Tom and Burton, Stephen and O'Keefe, John and Jeffery, Kate and Burgess, Neil},
	year = {2006},
	note = {Place: Institute of Cognitive Neuroscience, University College London, UK. caswell.barry@ucl.ac.uk},
	keywords = {Humans, Animals, Rats, merged\_fiete.bib, Neurological, Learning/physiology, Neurons/*physiology, Models, Orientation/physiology, Space Perception/*physiology, Memory/*physiology, Action Potentials/*physiology, Hippocampus/anatomy \& histology/*physiology, Neural Pathways/anatomy \& histology/*physiology, Neuronal Plasticity/physiology},
	pages = {71--97},
}

@article{karlsson_network_2008,
	title = {Network dynamics underlying the formation of sparse, informative representations in the hippocampus},
	volume = {28},
	abstract = {During development, activity-dependent processes increase the specificity of neural responses to stimuli, but the role that this type of process plays in adult plasticity is unclear. We examined the dynamics of hippocampal activity as animals learned about new environments to understand how neural selectivity changes with experience. Hippocampal principal neurons fire when the animal is located in a particular subregion of its environment, and in any given environment the hippocampal representation is sparse: less than half of the neurons in areas CA1 and CA3 are active whereas the rest are essentially silent. Here we show that different dynamics govern the evolution of this sparsity in CA1 and upstream area CA3. CA1, but not CA3, produces twice as many spikes in novel compared with familiar environments. This high rate firing continues during sharp wave ripple events in a subsequent rest period. The overall CA1 population rate declines and the number of active cells decreases as the environment becomes familiar and task performance improves, but the decline in rate is not uniform across neurons. Instead, the activity of cells with initial peak spatial rates above approximately 12 Hz is enhanced, whereas the activity of cells with lower initial peak rates is suppressed. The result of these changes is that the active CA1 population comes to consist of a relatively small group of cells with strong spatial tuning. This process is not evident in CA3, indicating that a region-specific and long timescale process operates in CA1 to create a sparse, spatially informative population of neurons.},
	language = {eng},
	number = {52},
	journal = {J. Neurosci.},
	author = {Karlsson, Mattias P and Frank, Loren M},
	year = {2008},
	note = {Place: W. M. Keck Center for Integrative Neuroscience and Department of Physiology, University of California, San Francisco, San Francisco, California 94143-0444, USA.},
	keywords = {Animals, Rats, Male, Time Factors, merged\_fiete.bib, Spatial Behavior/*physiology, Brain Mapping, Long-Evans, Nerve Net/*physiology, Environment, Pyramidal Cells/*physiology, Hippocampus/*cytology/physiology, Neural Pathways/physiology, *Nonlinear Dynamics, Maze Learning/physiology},
	pages = {14271--14281},
}

@article{maass_computational_2000,
	title = {On the computational power of winner-take-all},
	volume = {12},
	abstract = {This article initiates a rigorous theoretical analysis of the computational power of circuits that employ modules for computing winner-take-all. Computational models that involve competitive stages have so far been neglected in computational complexity theory, although they are widely used in computational brain models, artificial neural networks, and analog VLSI. Our theoretical analysis shows that winner-take-all is a surprisingly powerful computational module in comparison with threshold gates (also referred to as McCulloch-Pitts neurons) and sigmoidal gates. We prove an optimal quadratic lower bound for computing winner-take-all in any feedforward circuit consisting of threshold gates. In addition we show that arbitrary continuous functions can be approximated by circuits employing a single soft winner-take-all gate as their only nonlinear operation. Our theoretical analysis also provides answers to two basic questions raised by neurophysiologists in view of the well-known asymmetry between excitatory and inhibitory connections in cortical circuits: how much computational power of neural networks is lost if only positive weights are employed in weighted sums and how much adaptive capability is lost if only the positive weights are subject to plasticity.},
	language = {eng},
	number = {11},
	journal = {Neural Comput.},
	author = {Maass, W},
	year = {2000},
	note = {Place: Institute for Theoretical Computer Science, Technische Universitat Graz, Austria.},
	keywords = {Animals, merged\_fiete.bib, *Models, Neurological, Models, *Neural Networks (Computer), Brain/physiology, Neuronal Plasticity, Theoretical},
	pages = {2519--2535},
}

@article{stevens_changes_1994-1,
	title = {Changes in reliability of synaptic function as a mechanism for plasticity},
	volume = {371},
	abstract = {Synaptic transmission in the hippocampus is rather unreliable, with many presynaptic action potentials failing to release neurotransmitter. How is this unreliability affected by the alterations in synaptic strength seen in long-term potentiation (LTP) and long-term depression (LTD)? We find that LTP increases synaptic reliability, and LTD decreases it, both without a change in the size of those postsynaptic currents that do occur. Thus LTD is a functional inverse of LTP.},
	number = {6499},
	journal = {Nature},
	author = {Stevens, C F and Wang, Y},
	month = oct,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {704--707},
}

@article{stevens_facilitation_1995,
	title = {Facilitation and depression at single central synapses},
	volume = {14},
	abstract = {Using whole-cell recording from CA1 hippocampal pyramidal neurons and minimal stimulation of Schaffer collaterals, we have studied what seem to be single synapses. Although the transmission at a putative single synapses is quite unreliable, the synapse can be made to release transmitter reliably in response to the second stimulus in a pair of stimuli that re presented in rapid succession (e.g., 50 ms separation). Statistical analysis of transsmision failures seen with such paired pulse stimulation reveals that the majority of stimulus-evoked synaptic currents ({\textgreater} 90\%) are produced by a single synapse under the conditions of minimal stimulation, even if multiple synapses are actually present. Individual synapses appear to release either zero or one quantum; that is, a single synapse seems to have only one functional release sit at any time. After the release site has been used, approximately 20 ms is required to refill the site so that it can be used again.},
	number = {4},
	journal = {Neuron},
	author = {Stevens, C F and Wang, Y},
	month = apr,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {795--802},
}

@article{stevens_neurotransmitter_2003,
	title = {Neurotransmitter release at central synapses},
	volume = {40},
	abstract = {Our understanding of synaptic transmission has grown dramatically during the 15 years since the first issue of Neuron was published, a growth rate expected from the rapid progress in modern biology. As in all of biology, new techniques have led to major advances in the cell and molecular biology of synapses, and the subject has evolved in ways (like the production of genetically engineered mice) that could not even be imagined 15 years ago. My plan for this review is to summarize what we knew about neurotransmitter release when Neuron first appeared and what we recognized we did not know, and then to describe how our views have changed in the intervening decade and a half. Some things we knew about synapses–“knew” in the sense that the field had reached a consensus–are no longer accepted, but for the most part, impressive advances have led to a new consensus on many issues. What I find fascinating is that in certain ways nothing has changed–many of the old arguments persist or recur in a different guise–but in other ways the field would be unrecognizable to a neurobiologist time-transported from 1988 to 2003.},
	language = {eng},
	number = {2},
	journal = {Neuron},
	author = {Stevens, Charles F},
	year = {2003},
	note = {Place: The Salk Institute, 10010 North Torrey Pines Road, La Jolla, CA 92037, USA. stevens@salk.edu},
	keywords = {Humans, Animals, merged\_fiete.bib, Synaptic Transmission/physiology, Neurotransmitter Agents/metabolism/*secretion, Synapses/metabolism/*secretion},
	pages = {381--388},
}

@article{lever_boundary_2009,
	title = {Boundary vector cells in the subiculum of the hippocampal formation},
	volume = {29},
	abstract = {{\textbackslash}textbackslashtt“Boundary vector cells{\textbackslash}textbackslashtt” were predicted to exist by computational models of the environmental inputs underlying the spatial firing patterns of hippocampal place cells (O'Keefe and Burgess, 1996; Burgess et al., 2000; Hartley et al., 2000). Here, we report the existence of cells fulfilling this description in recordings from the subiculum of freely moving rats. These cells may contribute environmental information to place cell firing, complementing path integrative information. Their relationship to other cell types, including medial entorhinal “border cells,” is discussed.},
	language = {eng},
	number = {31},
	journal = {J. Neurosci.},
	author = {Lever, Colin and Burton, Stephen and Jeewajee, Ali and O'Keefe, John and Burgess, Neil},
	year = {2009},
	note = {Place: Behavioural Neuroscience Laboratory, Institute of Psychological Sciences, University of Leeds, Leeds LS2 9JT, United Kingdom. c.lever@leeds.ac.uk},
	keywords = {Animals, Action Potentials, Rats, Time Factors, merged\_fiete.bib, Hippocampus/cytology/*physiology, *Environment, Electrodes, Implanted, Space Perception/*physiology, Motor Activity/physiology, Neurons/cytology/*physiology},
	pages = {9771--9777},
}

@article{remondes_molecular_2003,
	title = {Molecular mechanisms contributing to long-lasting synaptic plasticity at the temporoammonic-{CA1} synapse},
	volume = {10},
	abstract = {The hippocampus and the nearby medial temporal lobe structures are required for the formation, consolidation, and retrieval of episodic memories. Sensory information enters the hippocampus via two inputs from entorhinal cortex (EC): One input (perforant path) makes synapses on the dendrites of dentate granule cells as the first set of synapses in the trisynaptic circuit, the other (temporoammonic; TA) makes synapses on the distal dendrites of CA1 neurons. Here we demonstrate that TA-CA1 synapses undergo both early- and late-phase long-term potentiation (LTP) in rat hippocampal slices. LTP at TA-CA1 synapses requires both NMDA receptor and voltage-gated Ca2+ channel activity. Furthermore, TA-CA1 LTP is insensitive to the blockade of fast inhibitory transmission (GABAA-mediated) and, interestingly, is dependent on GABAB-dependent slow inhibitory transmission. These findings indicate that the TA-CA1 synapses may rely on a refined modulation of inhibition to exhibit LTP.},
	language = {eng},
	number = {4},
	journal = {Learn. Mem.},
	author = {Remondes, Miguel and Schuman, Erin M},
	year = {2003},
	note = {Place: Caltech/HHMI, Division of Biology, Pasadena, California 91125, USA.},
	keywords = {Animals, Rats, Male, merged\_fiete.bib, Hippocampus/*physiology, Electrophysiology, Sprague-Dawley, Neural Inhibition, Neuronal Plasticity, *Long-Term Potentiation, Calcium Channels/*physiology, Excitatory Postsynaptic Potentials, GABA-A/physiology, GABA-B/physiology, GABA/*physiology, N-Methyl-D-Aspartate/*physiology, Receptors, Temporal Lobe/*physiology},
	pages = {247--252},
}

@article{womelsdorf_modulation_2007,
	title = {Modulation of neuronal interactions through neuronal synchronization},
	volume = {316},
	abstract = {Brain processing depends on the interactions between neuronal groups. Those interactions are governed by the pattern of anatomical connections and by yet unknown mechanisms that modulate the effective strength of a given connection. We found that the mutual influence among neuronal groups depends on the phase relation between rhythmic activities within the groups. Phase relations supporting interactions between the groups preceded those interactions by a few milliseconds, consistent with a mechanistic role. These effects were specific in time, frequency, and space, and we therefore propose that the pattern of synchronization flexibly determines the pattern of neuronal interactions.},
	language = {eng},
	number = {5831},
	journal = {Science},
	author = {Womelsdorf, Thilo and Schoffelen, Jan-Mathijs and Oostenveld, Robert and Singer, Wolf and Desimone, Robert and Engel, Andreas K and Fries, Pascal},
	year = {2007},
	note = {Place: F. C. Donders Centre for Cognitive Neuroimaging, Radboud University Nijmegen, 6525 EN Nijmegen, Netherlands. thilo.womelsdorf@fcdonders.ru.nl},
	keywords = {Animals, Action Potentials, Male, Visual Pathways, merged\_fiete.bib, Neurons/*physiology, Electrodes, Implanted, Electrophysiology, Cats, Nerve Net/physiology, Macaca nemestrina, Parietal Lobe/anatomy \& histology/*physiology, Temporal Lobe/anatomy \& histology/*physiology},
	pages = {1609--1612},
}

@article{xie_selectively_2002,
	title = {Selectively grouping neurons in recurrent networks of lateral inhibition},
	volume = {14},
	abstract = {Winner-take-all networks have been proposed to underlie many of the brain's fundamental computational abilities. However, not much is known about how to extend the grouping of potential winners in these networks beyond single neuron or uniformly arranged groups of neurons. We show that competition between arbitrary groups of neurons can be realized by organizing lateral inhibition in linear threshold networks. Given a collection of potentially overlapping groups (with the exception of some degenerate cases), the lateral inhibition results in network dynamics such that any permitted set of neurons that can be coactivated by some input at a stable steady state is contained in one of the groups. The information about the input is preserved in this operation. The activity level of a neuron in a permitted set corresponds to its stimulus strength, amplified by some constant. Sets of neurons that are not part of a group cannot be coactivated by any input at a stable steady state. We analyze the storage capacity of such a network for random groups–the number of random groups the network can store as permitted sets without creating too many spurious ones. In this framework, we calculate the optimal sparsity of the groups (maximizing group entropy). We find that for dense inputs, the optimal sparsity is unphysiologically small. However, when the inputs and the groups are equally sparse, we derive a more plausible optimal sparsity. We believe our results are the first steps toward attractor theories in hybrid analog-digital networks.},
	language = {eng},
	number = {11},
	journal = {Neural Comput.},
	author = {Xie, Xiaohui and Hahnloser, Richard H R and Seung, H Sebastian},
	year = {2002},
	note = {Place: Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. xhx@ai.mit.edu},
	keywords = {merged\_fiete.bib, *Models, Neurological, Neurons/physiology, *Neural Networks (Computer), Brain/cytology/*physiology, Neural Inhibition/*physiology},
	pages = {2627--2646},
}

@article{douglas_neuronal_2004,
	title = {Neuronal circuits of the neocortex},
	volume = {27},
	abstract = {We explore the extent to which neocortical circuits generalize, i.e., to what extent can neocortical neurons and the circuits they form be considered as canonical? We find that, as has long been suspected by cortical neuroanatomists, the same basic laminar and tangential organization of the excitatory neurons of the neocortex is evident wherever it has been sought. Similarly, the inhibitory neurons show characteristic morphology and patterns of connections throughout the neocortex. We offer a simple model of cortical processing that is consistent with the major features of cortical circuits: The superficial layer neurons within local patches of cortex, and within areas, cooperate to explore all possible interpretations of different cortical input and cooperatively select an interpretation consistent with their various cortical and subcortical inputs.},
	language = {eng},
	journal = {Annu. Rev. Neurosci.},
	author = {Douglas, Rodney J and Martin, Kevan A C},
	year = {2004},
	note = {Place: Institute of Neuroinformatics, University/ETH Zurich, Zurich 8057, Switzerland. rjd@ini.phys.ethz.ch},
	keywords = {Humans, Animals, merged\_fiete.bib, Neurological, Neurons/*physiology, Models, Synaptic Transmission/physiology, Cell Size/physiology, Neocortex/cytology/*physiology, Nerve Net/cytology/*physiology, Neural Inhibition/physiology, Neural Pathways/cytology/*physiology},
	pages = {419--451},
}

@article{hahnloser_permitted_2003,
	title = {Permitted and forbidden sets in symmetric threshold-linear networks},
	volume = {15},
	abstract = {The richness and complexity of recurrent cortical circuits is an inexhaustible source of inspiration for thinking about high-level biological computation. In past theoretical studies, constraints on the synaptic connection patterns of threshold-linear networks were found that guaranteed bounded network dynamics, convergence to attractive fixed points, and multistability, all fundamental aspects of cortical information processing. However, these conditions were only sufficient, and it remained unclear which were the minimal (necessary) conditions for convergence and multistability. We show that symmetric threshold-linear networks converge to a set of attractive fixed points if and only if the network matrix is copositive. Furthermore, the set of attractive fixed points is nonconnected (the network is multiattractive) if and only if the network matrix is not positive semidefinite. There are permitted sets of neurons that can be coactive at a stable steady state and forbidden sets that cannot. Permitted sets are clustered in the sense that subsets of permitted sets are permitted and supersets of forbidden sets are forbidden. By viewing permitted sets as memories stored in the synaptic connections, we provide a formulation of long-term memory that is more general than the traditional perspective of fixed-point attractor networks. There is a close correspondence between threshold-linear networks and networks defined by the generalized Lotka-Volterra equations.},
	language = {eng},
	number = {3},
	journal = {Neural Comput.},
	author = {Hahnloser, Richard H R and Seung, H Sebastian and Slotine, Jean-Jacques},
	year = {2003},
	note = {Place: Howard Hughes Medical Institute, Department of Brain and Cognitive Sciences, MIT E25-210, Cambridge, MA 02139, U.S.A. rhahnloser@mit.edu},
	keywords = {Humans, Animals, merged\_fiete.bib, *Models, Neurological, Nerve Net/*physiology, Cerebral Cortex/*physiology, *Linear Models, Differential Threshold},
	pages = {621--638},
}

@article{dombeck_functional_2010,
	title = {Functional imaging of hippocampal place cells at cellular resolution during virtual navigation},
	volume = {13},
	abstract = {Spatial navigation is often used as a behavioral task in studies of the neuronal circuits that underlie cognition, learning and memory in rodents. The combination of in vivo microscopy with genetically encoded indicators has provided an important new tool for studying neuronal circuits, but has been technically difficult to apply during navigation. Here we describe methods for imaging the activity of neurons in the CA1 region of the hippocampus with subcellular resolution in behaving mice. Neurons that expressed the genetically encoded calcium indicator GCaMP3 were imaged through a chronic hippocampal window. Head-restrained mice performed spatial behaviors in a setup combining a virtual reality system and a custom-built two-photon microscope. We optically identified populations of place cells and determined the correlation between the location of their place fields in the virtual environment and their anatomical location in the local circuit. The combination of virtual reality and high-resolution functional imaging should allow a new generation of studies to investigate neuronal circuit dynamics during behavior.},
	language = {eng},
	number = {11},
	journal = {Nat. Neurosci.},
	author = {Dombeck, Daniel A and Harvey, Christopher D and Tian, Lin and Looger, Loren L and Tank, David W},
	year = {2010},
	note = {Place: Department of Molecular Biology and Princeton Neuroscience Institute, Princeton University, Princeton, New Jersey, USA. ddombeck@princeton.edu},
	keywords = {Animals, Male, merged\_fiete.bib, Hippocampus/*cytology, Action Potentials/physiology, Spatial Behavior/*physiology, User-Computer Interface, Space Perception/*physiology, Image Processing, Cerebral Cortex/physiology, Calcium/metabolism, Computer-Assisted/methods, Dendrites/physiology, Genetic/methods, Inbred C57BL, Membrane Potentials/drug effects/physiology, Mice, Neurons/classification/cytology/*physiology, Nonlinear Dynamics, Patch-Clamp Techniques/methods, Synapsins/genetics/metabolism, Transduction},
	pages = {1433--1440},
}

@article{goblick_theoretical_1965-1,
	title = {Theoretical limitations on the transmission of data from analog sources},
	volume = {11},
	number = {4},
	journal = {IEEE Trans. Inf. Theory},
	author = {Goblick, T J},
	year = {1965},
	keywords = {merged\_fiete.bib},
	pages = {558--567},
}

@article{mackay_near_1996,
	title = {Near {Shannon} limit performance of low density parity check codes},
	volume = {32},
	journal = {Electron. Lett.},
	author = {MacKay, D J C and Neal, R M},
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {1645--1646},
}

@article{pouget_information_2000,
	title = {Information processing with population codes},
	volume = {1},
	abstract = {Information is encoded in the brain by populations or clusters of cells, rather than by single cells. This encoding strategy is known as population coding. Here we review the standard use of population codes for encoding and decoding information, and consider how population codes can be used to support neural computations such as noise removal and nonlinear mapping. More radical ideas about how population codes may directly represent information about stimulus uncertainty are also discussed.},
	language = {eng},
	number = {2},
	journal = {Nat. Rev. Neurosci.},
	author = {Pouget, A and Dayan, P and Zemel, R},
	year = {2000},
	note = {Place: Department of Brain and Cognitive Sciences, Meliora Hall, University of Rochester, Rochester, New York 14627, USA. alex@bcs.rochester.edu},
	keywords = {Humans, Animals, merged\_fiete.bib, *Models, Neurological, Neurons/physiology, Brain/*physiology, Nonlinear Dynamics, *Mental Processes/*physiology, Likelihood Functions},
	pages = {125--132},
}

@article{abbott_effect_1999,
	title = {The effect of correlated variability on the accuracy of a population code},
	volume = {11},
	abstract = {We study the impact of correlated neuronal firing rate variability on the accuracy with which an encoded quantity can be extracted from a population of neurons. Contrary to widespread belief, correlations in the variabilities of neuronal firing rates do not, in general, limit the increase in coding accuracy provided by using large populations of encoding neurons. Furthermore, in some cases, but not all, correlations improve the accuracy of a population code.},
	language = {eng},
	number = {1},
	journal = {Neural Comput.},
	author = {Abbott, L F and Dayan, P},
	year = {1999},
	note = {Place: Volen Center, Brandeis University, Waltham MA 02254, USA. abbott@volen.brandeis.edu},
	keywords = {merged\_fiete.bib, *Models, Neurons/*physiology, Electrophysiology, Biological},
	pages = {91--101},
}

@article{knierim_interactions_1998,
	title = {Interactions between idiothetic cues and external landmarks in the control of place cells and head direction cells},
	volume = {80},
	abstract = {Two types of neurons in the rat brain have been proposed to participate in spatial learning and navigation: place cells, which fire selectively in specific locations of an environment and which may constitute key elements of cognitive maps, and head direction cells, which fire selectively when the rat's head is pointed in a specific direction and which may serve as an internal compass to orient the cognitive map. The spatially and directionally selective properties of these cells arise from a complex interaction between input from external landmarks and from idiothetic cues; however, the exact nature of this interaction is poorly understood. To address this issue, directional information from visual landmarks was placed in direct conflict with directional information from idiothetic cues. When the mismatch between the two sources of information was small (45 degrees), the visual landmarks had robust control over the firing properties of place cells; when the mismatch was larger, however, the firing fields of the place cells were altered radically, and the hippocampus formed a new representation of the environment. Similarly, the visual cues had control over the firing properties of head direction cells when the mismatch was small (45 degrees), but the idiothetic input usually predominated over the visual landmarks when the mismatch was larger. Under some conditions, when the visual landmarks predominated after a large mismatch, there was always a delay before the visual cues exerted their control over head direction cells. These results support recent models proposing that prewired intrinsic connections enable idiothetic cues to serve as the primary drive on place cells and head direction cells, whereas modifiable extrinsic connections mediate a learned, secondary influence of visual landmarks.},
	language = {eng},
	number = {1},
	journal = {J. Neurophysiol.},
	author = {Knierim, J J and Kudrimoti, H S and McNaughton, B L},
	year = {1998},
	note = {Place: Division of Neural Systems, Memory, and Aging, University of Arizona, Arizona Research Laboratories, Tucson, Arizona 85724, USA.},
	keywords = {Orientation, Animals, Vision, Rats, Male, Rotation, merged\_fiete.bib, Neurological, Neurons/*physiology, Models, Inbred F344, Head Movements/*physiology, *Brain Mapping, *Cues, *Visual Perception, Aging/*physiology, Brain/growth \& development/*physiology, Cognition, Darkness, Light, Ocular},
	pages = {425--446},
}

@article{hargreaves_major_2005-1,
	title = {Major dissociation between medial and lateral entorhinal input to dorsal hippocampus},
	volume = {308},
	abstract = {Hippocampal place cells are a model system of how the brain constructs cognitive representations and of how these representations support complex behavior, learning, and memory. There is, however, a lack of detailed knowledge about the properties of hippocampal afferents. We recorded multiple single units from the hippocampus and the medial and lateral entorhinal areas of behaving rats. Although many medial entorhinal neurons had highly specific place fields, lateral entorhinal neurons displayed weak spatial specificity. This finding demonstrates a fundamental dissociation between the information conveyed to the hippocampus by its major input streams, with spatial information represented by the medial and nonspatial information represented by the lateral entorhinal cortex.},
	language = {eng},
	number = {5729},
	journal = {Science},
	author = {Hargreaves, Eric L and Rao, Geeta and Lee, Inah and Knierim, James J},
	year = {2005},
	note = {Place: Department of Neurobiology and Anatomy, W. M. Keck Center for the Neurobiology of Learning and Memory, Post Office Box 20708, University of Texas Medical School at Houston, Houston, TX 77225, USA.},
	keywords = {Animals, Neural Pathways, Rats, Male, merged\_fiete.bib, Hippocampus/*physiology, Behavior, Neurons/*physiology, Cues, Brain Mapping, Long-Evans, Electrodes, Implanted, Animal, Entorhinal Cortex/*physiology, Learning/*physiology, Pyramidal Cells/physiology},
	pages = {1792--1794},
}

@article{chen_analog_1998-1,
	title = {Analog {Error}-{Correcting} {Codes} {Based} on {Chaotic} {Dynamical} {Systems}},
	volume = {46},
	number = {7},
	journal = {IEEE Trans. Commun.},
	author = {Chen, B and Wornell, G W},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {881--890},
}

@article{tanaka_representation_1996,
	title = {Representation of {Visual} {Features} of {Objects} in the {Inferotemporal} {Cortex}},
	volume = {9},
	abstract = {Cells in area TE of the inferotemporal cortex of the monkey brain selectively respond to various moderately complex object features, and those that respond to similar features cluster in a columnar region elongated vertical to the cortical surface. Columns representing related but different features partially overlap, and at least in some cases they comprise a continuous map of a piece of complex feature space. This continuous mapping is likely used for various computations, such as production of the image of the object at different viewing angles, illumination conditions, and articulation poses. Copyright 1996 Elsevier Science Ltd.},
	language = {ENG},
	number = {8},
	journal = {Neural Netw.},
	author = {Tanaka, K},
	year = {1996},
	note = {Place: The Institute of Physical and Chemical Research (RIKEN), Japan},
	keywords = {merged\_fiete.bib},
	pages = {1459--1475},
}

@article{tanaka_inferotemporal_1996,
	title = {Inferotemporal cortex and object vision},
	volume = {19},
	abstract = {Cells in area TE of the inferotemporal cortex of the monkey brain selectively respond to various moderately complex object features, and those that cluster in a columnar region that runs perpendicular to the cortical surface respond to similar features. Although cells within a column respond to similar features, their selectivity is not necessarily identical. The data of optical imaging in TE have suggested that the borders between neighboring columns are not discrete; a continuous mapping of complex feature space within a larger region contains several partially overlapped columns. This continuous mapping may be used for various computations, such as production of the image of the object at different viewing angles, illumination conditions, and articulation poses.},
	language = {eng},
	journal = {Annu. Rev. Neurosci.},
	author = {Tanaka, K},
	year = {1996},
	note = {Place: The Institute of Physical and Chemical Research (RIKEN), Saitama, Japan.},
	keywords = {Orientation, Animals, merged\_fiete.bib, Neurons/*physiology, Haplorhini, *Brain Mapping, Visual Cortex/*physiology, Temporal Lobe/*physiology, *Visual Perception, Ocular, *Vision, Axonal Transport},
	pages = {109--139},
}

@article{schiltz_holistic_2010,
	title = {Holistic perception of individual faces in the right middle fusiform gyrus as evidenced by the composite face illusion},
	volume = {10},
	abstract = {The perception of a facial feature (e.g., the eyes) is influenced by the position and identity of other features (e.g., the mouth) supporting an integrated, or holistic, representation of individual faces in the human brain. Here we used an event-related adaptation paradigm in functional magnetic resonance imaging (fMRI) to clarify the regions representing faces holistically across the whole brain. In each trial, observers performed the same/different task on top halves (aligned or misaligned) of two faces presented sequentially. For each face pair, the identity of top and bottom parts could be both identical, both different, or different only for the bottom half. The latter manipulation resulted in a composite face illusion, i.e., the erroneous perception of identical top parts as being different, only for aligned faces. Release from adaptation in this condition was found in two sub-areas of the right middle fusiform gyrus responding preferentially to faces, including the “fusiform face area” (“FFA”). There were no significant effects in homologous regions of the left hemisphere or in the inferior occipital cortex. Altogether, these observations indicate that face-sensitive populations of neurons in the right middle fusiform gyrus are optimally tuned to represent individual exemplars of faces holistically.},
	language = {eng},
	number = {2},
	journal = {J. Vis.},
	author = {Schiltz, Christine and Dricot, Laurence and Goebel, Rainer and Rossion, Bruno},
	year = {2010},
	note = {Place: Educational Measurement and Applied Cognitive Science Unit, University of Luxembourg, Walferdange, Luxembourg. christine.schiltz@uni.lu},
	keywords = {merged\_fiete.bib},
	pages = {25.1--16},
}

@article{schreiner_modular_2000,
	title = {Modular organization of frequency integration in primary auditory cortex},
	volume = {23},
	abstract = {Two fundamental aspects of frequency analysis shape the functional organization of primary auditory cortex. For one, the decomposition of complex sounds into different frequency components is reflected in the tonotopic organization of auditory cortical fields. Second, recent findings suggest that this decomposition is carried out in parallel for a wide range of frequency resolutions by neurons with frequency receptive fields of different sizes (bandwidths). A systematic representation of the range of frequency resolution and, equivalently, spectral integration shapes the functional organization of the iso-frequency domain. Distinct subregions, or “modules,” along the iso-frequency domain can be demonstrated with various measures of spectral integration, including pure-tone tuning curves, noise masking, and electrical cochlear stimulation. This modularity in the representation of spectral integration is expressed by intrinsic cortical connections. This organization has implications for our understanding of psychophysical spectral integration measures such as the critical band and general cortical coding strategies.},
	language = {eng},
	journal = {Annu. Rev. Neurosci.},
	author = {Schreiner, C E and Read, H L and Sutter, M L},
	year = {2000},
	note = {Place: Coleman Memorial Laboratory, W.M. Keck Center for Integrative Neuroscience, University of California, San Francisco 94143-0732, USA. chris@phy.ucsf.edu},
	keywords = {Animals, merged\_fiete.bib, Brain Mapping, Auditory Cortex/*physiology, Auditory Pathways/physiology, Auditory Perception/*physiology},
	pages = {501--529},
}

@article{romanski_primate_2009,
	title = {The primate cortical auditory system and neural representation of conspecific vocalizations},
	volume = {32},
	abstract = {Over the past decade, renewed interest in the auditory system has resulted in a surge of anatomical and physiological research in the primate auditory cortex and its targets. Anatomical studies have delineated multiple areas in and around primary auditory cortex and demonstrated connectivity among these areas, as well as between these areas and the rest of the cortex, including prefrontal cortex. Physiological recordings of auditory neurons have found that species-specific vocalizations are useful in probing the selectivity and potential functions of acoustic neurons. A number of cortical regions contain neurons that are robustly responsive to vocalizations, and some auditory responsive neurons show more selectivity for vocalizations than for other complex sounds. Demonstration of selectivity for vocalizations has prompted the question of which features are encoded by higher-order auditory neurons. Results based on detailed studies of the structure of these vocalizations, as well as the tuning and information-coding properties of neurons sensitive to these vocalizations, have begun to provide answers to this question. In future studies, these and other methods may help to define the way in which cells, ensembles, and brain regions process communication sounds. Moreover, the discovery that several nonprimary auditory cortical regions may be multisensory and responsive to vocalizations with corresponding facial gestures may change the way in which we view the processing of communication information by the auditory system.},
	language = {eng},
	journal = {Annu. Rev. Neurosci.},
	author = {Romanski, Lizabeth M and Averbeck, Bruno B},
	year = {2009},
	note = {Place: Department of Neurobiology and Anatomy, University of Rochester School of Medicine, Rochester, New York 14642, USA. Liz\_romanski@urmc.rochester.edu},
	keywords = {Humans, Animals, merged\_fiete.bib, Neurons/physiology, Animal/*physiology, Auditory Perception/*physiology, *Social Behavior, Auditory Cortex/anatomy \& histology/*physiology, Auditory Pathways/anatomy \& histology/*physiology, Nerve Net/anatomy \& histology/physiology, Prefrontal Cortex/anatomy \& histology/physiology, Sexual Behavior, Vocalization},
	pages = {315--346},
}

@article{weliky_systematic_1996,
	title = {A systematic map of direction preference in primary visual cortex},
	volume = {379},
	abstract = {Neurons in the primary visual cortex respond selectively to the orientation of edges and their direction of motion. Orientation preference is mapped in a systematic fashion across the cortical surface, such that neurons in adjacent columns have similar but slightly shifted preferred orientations. Microelectrode studies have suggested that direction preference is also arranged in a systematic fashion, but exactly how this response property is mapped remains unclear. Here we show by optical imaging of intrinsic signals in ferret cortical area 17 that there is a mosaic-like map of direction preference. This map consists of numerous regions within which direction preference changes in a slow, continuous fashion. These regions are separated by winding boundaries (fractures) across which direction preference shifts abruptly, often by 180 degrees. Comparison of direction and orientation preference maps shows that these fractures subdivide iso-orientation domains into regions selective for opposite directions of motion.},
	language = {eng},
	number = {6567},
	journal = {Nature},
	author = {Weliky, M and Bosking, W H and Fitzpatrick, D},
	year = {1996},
	note = {Place: Department of Neurobiology, Duke University Medical Center, Durham, North Carolina 27710, USA.},
	keywords = {Animals, merged\_fiete.bib, Motion Perception/*physiology, Neurons/physiology, Visual, *Brain Mapping, Visual Cortex/*physiology, Computer-Assisted, Image Processing, Evoked Potentials, Ferrets},
	pages = {725--728},
}

@article{hasselmo_grid_2007,
	title = {Grid cell firing may arise from interference of theta frequency membrane potential oscillations in single neurons},
	volume = {17},
	abstract = {Intracellular recording and computational modelling suggest that interactions of subthreshold membrane potential oscillation frequency in different dendritic branches of entorhinal cortex stellate cells could underlie the functional coding of continuous dimensions of space and time. Among other things, these interactions could underlie properties of grid cell field spacing. The relationship between experimental data on membrane potential oscillation frequency (f) and grid cell field spacing (G) indicates a constant scaling factor H = fG. This constant scaling factor between temporal oscillation frequency and spatial periodicity provides a starting constraint that is used to derive the model of Burgess et al. (Hippocampus, 2007). This model provides a consistent quantitative link between single cell physiological properties and properties of spiking units in awake behaving animals. Further properties and predictions of this model about single cell and network physiological properties are analyzed. In particular, the model makes quantitative predictions about the change in membrane potential, single cell oscillation frequency, and network oscillation frequency associated with speed of movement, about the independence of single cell properties from network theta rhythm oscillations, and about the effect of variations in initial oscillatory phase on the pattern of grid cell firing fields. These same mechanisms of subthreshold oscillations may play a more general role in memory function, by providing a method for learning arbitrary time intervals in memory sequences.},
	number = {12},
	journal = {Hippocampus},
	author = {Hasselmo, Michael E and Giocomo, Lisa M and Zilli, Eric A},
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {1252--1271},
}

@article{zilli_evaluation_2009,
	title = {Evaluation of the oscillatory interference model of grid cell firing through analysis and measured period variance of some biological oscillators},
	volume = {5},
	abstract = {Models of the hexagonally arrayed spatial activity pattern of grid cell firing in the literature generally fall into two main categories: continuous attractor models or oscillatory interference models. Burak and Fiete (2009, PLoS Comput Biol) recently examined noise in two continuous attractor models, but did not consider oscillatory interference models in detail. Here we analyze an oscillatory interference model to examine the effects of noise on its stability and spatial firing properties. We show analytically that the square of the drift in encoded position due to noise is proportional to time and inversely proportional to the number of oscillators. We also show there is a relatively fixed breakdown point, independent of many parameters of the model, past which noise overwhelms the spatial signal. Based on this result, we show that a pair of oscillators are expected to maintain a stable grid for approximately t = 5mu(3)/(4pisigma)(2) seconds where mu is the mean period of an oscillator in seconds and sigma(2) its variance in seconds(2). We apply this criterion to recordings of individual persistent spiking neurons in postsubiculum (dorsal presubiculum) and layers III and V of entorhinal cortex, to subthreshold membrane potential oscillation recordings in layer II stellate cells of medial entorhinal cortex and to values from the literature regarding medial septum theta bursting cells. All oscillators examined have expected stability times far below those seen in experimental recordings of grid cells, suggesting the examined biological oscillators are unfit as a substrate for current implementations of oscillatory interference models. However, oscillatory interference models can tolerate small amounts of noise, suggesting the utility of circuit level effects which might reduce oscillator variability. Further implications for grid cell models are discussed.},
	number = {11},
	journal = {PLoS Comput. Biol.},
	author = {Zilli, Eric A and Yoshida, Motoharu and Tahvildari, Babak and Giocomo, Lisa M and Hasselmo, Michael E},
	month = nov,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {e1000573},
}

@article{griffin_spatial_2007,
	title = {Spatial representations of hippocampal {CA1} neurons are modulated by behavioral context in a hippocampus-dependent memory task},
	volume = {27},
	abstract = {Although it is well known that hippocampal neurons code spatial information, it is less clear how these spatial representations are influenced by memory demands, especially in hippocampus-dependent tasks. Recently, our laboratory has demonstrated that hippocampal spatial representations are influenced by mnemonic factors in a T-maze continuous alternation task. Another unique experimental approach that might reveal the ways in which task-related factors impact hippocampal spatial representations is to compare firing patterns between events that require distinct episodic memory processes. Therefore, we recorded from CA1 single neurons during a discrete trial delayed-nonmatch-to-place task that allowed within-trial comparison between an encoding (sample) phase and a retrieval (choice) phase. A large subset of neurons that fired on the central stem of the maze showed dramatic selectivity for either the sample or choice phase of the trial. However, surprisingly, there were fewer neurons that showed differential firing rates between left- and right-bound trajectories. Our results suggest that trial-phase-selective coding is common in tasks that require rapid alternation between encoding and retrieval processes.},
	number = {9},
	journal = {J. Neurosci.},
	author = {Griffin, Amy L and Eichenbaum, Howard and Hasselmo, Michael E},
	month = feb,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {2416--2423},
}

@article{ang_hippocampal_2005,
	title = {Hippocampal {CA1} circuitry dynamically gates direct cortical inputs preferentially at theta frequencies},
	volume = {25},
	abstract = {Hippocampal CA1 pyramidal neurons receive intrahippocampal and extrahipppocampal inputs during theta cycle, whose relative timing and magnitude regulate the probability of CA1 pyramidal cell spiking. Extrahippocampal inputs, giving rise to the primary theta dipole in CA1 stratum lacunosum moleculare, are conveyed by the temporoammonic pathway. The temporoammonic pathway impinging onto the CA1 distal apical dendritic tuft is the most electrotonically distant from the perisomatic region yet is critical in regulating CA1 place cell activity during theta cycles. How does local hippocampal circuitry regulate the integration of this essential, but electrotonically distant, input within the theta period? Using whole-cell somatic recording and voltage-sensitive dye imaging with simultaneous dendritic recording of CA1 pyramidal cell responses, we demonstrate that temporoammonic EPSPs are normally compartmentalized to the apical dendritic tuft by feedforward inhibition. However, when this input is preceded at a one-half theta cycle interval by proximally targeted Schaffer collateral activity, temporoammonic EPSPs propagate to the soma through a joint, codependent mechanism involving activation of Schaffer-specific NMDA receptors and presynaptic inhibition of GABAergic terminals. These afferent interactions, tuned for synaptic inputs arriving one-half theta interval apart, are in turn modulated by feedback inhibition initiated via axon collaterals of pyramidal cells. Therefore, CA1 circuit integration of excitatory inputs endows the CA1 principal cell with a novel property: the ability to function as a temporally specific “AND” gate that provides for sequence-dependent readout of distal inputs.},
	number = {42},
	journal = {J. Neurosci.},
	author = {Ang, Chyze W and Carlson, Gregory C and Coulter, Douglas A},
	month = oct,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {9567--9580},
}

@article{jarsky_conditional_2005,
	title = {Conditional dendritic spike propagation following distal synaptic activation of hippocampal {CA1} pyramidal neurons},
	volume = {8},
	abstract = {The perforant-path projection to the hippocampus forms synapses in the apical tuft of CA1 pyramidal neurons. We used computer modeling to examine the function of these distal synaptic inputs, which led to three predictions that we confirmed in experiments using rat hippocampal slices. First, activation of CA1 neurons by the perforant path is limited, a result of the long distance between these inputs and the soma. Second, activation of CA1 neurons by the perforant path depends on the generation of dendritic spikes. Third, the forward propagation of these spikes is unreliable, but can be facilitated by modest activation of Schaffer-collateral synapses in the upper apical dendrites. This 'gating' of dendritic spike propagation may be an important activation mode of CA1 pyramidal neurons, and its modulation by neurotransmitters or long-term, activity-dependent plasticity may be an important feature of dendritic integration during mnemonic processing in the hippocampus.},
	number = {12},
	journal = {Nat. Neurosci.},
	author = {Jarsky, Tim and Roxin, Alex and Kath, William L and Spruston, Nelson},
	month = dec,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {1667--1676},
}

@article{takahashi_pathway_2009,
	title = {Pathway interactions and synaptic plasticity in the dendritic tuft regions of {CA1} pyramidal neurons},
	volume = {62},
	abstract = {Input comparison is thought to occur in many neuronal circuits, including the hippocampus, where functionally important interactions between the Schaffer collateral and perforant pathways have been hypothesized. We investigated this idea using multisite, whole-cell recordings and Ca2+ imaging and found that properly timed, repetitive stimulation of both pathways results in the generation of large plateau potentials in distal dendrites of CA1 pyramidal neurons. These dendritic plateau potentials produce widespread Ca2+ influx, large after-depolarizations, burst firing output, and long-term potentiation of perforant path synapses. Plateau duration is directly related to the strength and temporal overlap of pathway activation and involves back-propagating action potentials and both NMDA receptors and voltage-gated Ca2+ channels. Thus, the occurrence of highly correlated SC and PP input to CA1 is signaled by a dramatic change in output mode and an increase in input efficacy, all induced by a large plateau potential in the distal dendrites of CA1 pyramidal neurons.},
	number = {1},
	journal = {Neuron},
	author = {Takahashi, Hiroto and Magee, Jeffrey C},
	month = apr,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {102--111},
}

@article{mizuseki_theta_2009,
	title = {Theta oscillations provide temporal windows for local circuit computation in the entorhinal-hippocampal loop},
	volume = {64},
	abstract = {Theta oscillations are believed to play an important role in the coordination of neuronal firing in the entorhinal (EC)-hippocampal system but the underlying mechanisms are not known. We simultaneously recorded from neurons in multiple regions of the EC-hippocampal loop and examined their temporal relationships. Theta-coordinated synchronous spiking of EC neuronal populations predicted the timing of current sinks in target layers in the hippocampus. However, the temporal delays between population activities in successive anatomical stages were longer (typically by a half theta cycle) than expected from axon conduction velocities and passive synaptic integration of feed-forward excitatory inputs. We hypothesize that the temporal windows set by the theta cycles allow for local circuit interactions and thus a considerable degree of computational independence in subdivisions of the EC-hippocampal loop.},
	number = {2},
	journal = {Neuron},
	author = {Mizuseki, Kenji and Sirota, Anton and Pastalkova, Eva and Buzsáki, György},
	month = oct,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {267--280},
}

@article{giladi_eulerian_1994,
	title = {Eulerian {Number} {Asymptotics}},
	volume = {445},
	number = {1924},
	journal = {Proc. R. Soc. Lond. A Math. Phys. Sci.},
	author = {Giladi, E and Keller, J B},
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {291--303},
}

@article{montemurro_optimal_2006,
	title = {Optimal tuning widths in population coding of periodic variables},
	volume = {18},
	abstract = {We study the relationship between the accuracy of a large neuronal population in encoding periodic sensory stimuli and the width of the tuning curves of individual neurons in the population. By using general simple models of population activity, we show that when considering one or two periodic stimulus features, a narrow tuning width provides better population encoding accuracy. When encoding more than two periodic stimulus features, the information conveyed by the population is instead maximal for finite values of the tuning width. These optimal values are only weakly dependent on model parameters and are similar to the width of tuning to orientation or motion direction of real visual cortical neurons. A very large tuning width leads to poor encoding accuracy, whatever the number of stimulus features encoded. Thus, optimal coding of periodic stimuli is different from that of nonperiodic stimuli, which, as shown in previous studies, would require infinitely large tuning widths when coding more than two stimulus features.},
	language = {eng},
	number = {7},
	journal = {Neural Comput.},
	author = {Montemurro, Marcelo A and Panzeri, Stefano},
	year = {2006},
	note = {Place: Faculty of Life Sciences, University of Manchester, UK. m.montemurro@manchester.ac.uk},
	keywords = {Neurons, Animals, merged\_fiete.bib, *Models, Action Potentials/physiology, Neurological, Orientation/*physiology, Nerve Net/*physiology, Afferent/*physiology, Information Theory, Sensory Thresholds/physiology, Statistical Distributions},
	pages = {1555--1576},
}

@article{doi_robust_2007,
	title = {Robust coding over noisy overcomplete channels},
	volume = {16},
	abstract = {We address the problem of robust coding in which the signal information should be preserved in spite of intrinsic noise in the representation. We present a theoretical analysis for 1- and 2-D cases and characterize the optimal linear encoder and decoder in the mean-squared error sense. Our analysis allows for an arbitrary number of coding units, thus including both under- and over-complete representations, and provides insights into optimal coding strategies. In particular, we show how the form of the code adapts to the number of coding units and to different data and noise conditions in order to achieve robustness. We also present numerical solutions of robust coding for high-dimensional image data, demonstrating that these codes are substantially more robust than other linear image coding methods such as PCA, ICA, and wavelets.},
	language = {eng},
	number = {2},
	journal = {IEEE Trans. Image Process.},
	author = {Doi, Eizaburo and Balcan, Doru C and Lewicki, Michael S},
	year = {2007},
	note = {Place: Center for the Neural Basis of Cognition, Carnegie Mellon University, Pittsburgh, PA 15213, USA. edoi@cnbc.cmu.edu},
	keywords = {merged\_fiete.bib, Computer-Assisted, *Algorithms, *Artifacts, *Signal Processing, Computer-Assisted/*methods, Data Compression/*methods, Image Enhancement/*methods, Image Interpretation, Numerical Analysis},
	pages = {442--452},
}

@article{remme_democracy-independence_2010,
	title = {Democracy-independence trade-off in oscillating dendrites and its implications for grid cells},
	volume = {66},
	abstract = {Dendritic democracy and independence have been characterized for near-instantaneous processing of synaptic inputs. However, a wide class of neuronal computations requires input integration on long timescales. As a paradigmatic example, entorhinal grid fields have been thought to be generated by the democratic summation of independent dendritic oscillations performing direction-selective path integration. We analyzed how multiple dendritic oscillators embedded in the same neuron integrate inputs separately and determine somatic membrane voltage jointly. We found that the interaction of dendritic oscillations leads to phase locking, which sets an upper limit on the timescale for independent input integration. Factors that increase this timescale also decrease the influence that the dendritic oscillations exert on somatic voltage. In entorhinal stellate cells, interdendritic coupling dominates and causes these cells to act as single oscillators. Our results suggest a fundamental trade-off between local and global processing in dendritic trees integrating ongoing signals.},
	language = {eng},
	number = {3},
	journal = {Neuron},
	author = {Remme, Michiel W H and Lengyel, Mate and Gutkin, Boris S},
	year = {2010},
	note = {Place: Group for Neural Theory, Departement d'Etudes Cognitives, Ecole Normale Superieure, 29 rue d'Ulm, 75005 Paris, France. michiel.remme@nyu.edu},
	keywords = {merged\_fiete.bib},
	pages = {429--437},
}

@article{fiete_losing_2010-1,
	title = {Losing phase},
	volume = {66},
	abstract = {In this issue of Neuron, Remme and colleagues examine the biophysics of synchronization between oscillating dendrites and soma. Their findings suggest that oscillators will quickly phase-lock when weakly coupled. These findings are at odds with assumptions of an influential model of grid cell response generation and have implications for grid cell response mechanisms.},
	language = {eng},
	number = {3},
	journal = {Neuron},
	author = {Fiete, Ila R},
	year = {2010},
	note = {Place: Center for Learning and Memory, The University of Texas at Austin, Austin, TX 78712, USA. ilafiete@mail.clm.utexas.edu},
	keywords = {merged\_fiete.bib},
	pages = {331--334},
}

@article{williams_simple_1992,
	title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
	volume = {8},
	abstract = {This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms, while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms.},
	journal = {Mach. Learn.},
	author = {Williams, R J},
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {229--256},
}

@article{resulaj_changes_2009,
	title = {Changes of mind in decision-making},
	volume = {461},
	abstract = {A decision is a commitment to a proposition or plan of action based on evidence and the expected costs and benefits associated with the outcome. Progress in a variety of fields has led to a quantitative understanding of the mechanisms that evaluate evidence and reach a decision. Several formalisms propose that a representation of noisy evidence is evaluated against a criterion to produce a decision. Without additional evidence, however, these formalisms fail to explain why a decision-maker would change their mind. Here we extend a model, developed to account for both the timing and the accuracy of the initial decision, to explain subsequent changes of mind. Subjects made decisions about a noisy visual stimulus, which they indicated by moving a handle. Although they received no additional information after initiating their movement, their hand trajectories betrayed a change of mind in some trials. We propose that noisy evidence is accumulated over time until it reaches a criterion level, or bound, which determines the initial decision, and that the brain exploits information that is in the processing pipeline when the initial decision is made to subsequently either reverse or reaffirm the initial decision. The model explains both the frequency of changes of mind as well as their dependence on both task difficulty and whether the initial decision was accurate or erroneous. The theoretical and experimental findings advance the understanding of decision-making to the highly flexible and cognitive acts of vacillation and self-correction.},
	language = {eng},
	number = {7261},
	journal = {Nature},
	author = {Resulaj, Arbora and Kiani, Roozbeh and Wolpert, Daniel M and Shadlen, Michael N},
	year = {2009},
	note = {Place: Computational and Biological Learning Laboratory, Department of Engineering, University of Cambridge, Trumpington Street, Cambridge CB2 1PZ, UK.},
	keywords = {Humans, Computers, Reaction Time, Male, Time Factors, Female, Movement, merged\_fiete.bib, Neurological, Cues, Models, Photic Stimulation, Decision Making/*physiology, Hand/physiology, Motion, Psychological, Psychomotor Performance},
	pages = {263--266},
}

@article{buck_olfactory_2004,
	title = {Olfactory receptors and odor coding in mammals},
	volume = {62},
	abstract = {Humans and other mammals perceive a vast number of volatile chemicals as having distinct odors. This ability derives from the existence of a large family of olfactory receptors that number about 350 in man and 1000 in mice. Individual odorants activate distinct combinations of olfactory receptors, generating an immense array of combinatorial receptor codes that define odorant identities. Sensory neurons in the nose express only one receptor type each and connect to the olfactory bulb in a spatially organized manner that yields a stereotyped sensory map. A secondary projection from the bulb to the cortex transforms receptor inputs, generating another, different stereotyped map that may permit the integration of inputs from combinations of receptors. Another olfactory structure in the nasal septum of animals, the vomeronasal organ, has two additional receptor families that detect pheromones and induce hormonal and behavioral responses through a different projection to the brain.},
	language = {eng},
	number = {11 Pt 2},
	journal = {Nutr. Rev.},
	author = {Buck, Linda B},
	year = {2004},
	note = {Place: Basic Sciences Division, Fred Hutchinson Cancer Research Center, Seattle, Washington, USA.},
	keywords = {Neurons, Humans, Animals, merged\_fiete.bib, Receptors, *Odors, Afferent/physiology, Nose/innervation, Odorant/*physiology, Olfactory Bulb/physiology, Olfactory Pathways/physiology, Pheromones, Smell/physiology, Vomeronasal Organ/chemistry/physiology},
	pages = {S184--8; discussion S224--41},
}

@article{marr_theory_1969-1,
	title = {A theory of cerebellar cortex},
	volume = {202},
	abstract = {1. A detailed theory of cerebellar cortex is proposed whose consequence is that the cerebellum learns to perform motor skills. Two forms of input-output relation are described, both consistent with the cortical theory. One is suitable for learning movements (actions), and the other for learning to maintain posture and balance (maintenance reflexes).2. It is known that the cells of the inferior olive and the cerebellar Purkinje cells have a special one-to-one relationship induced by the climbing fibre input. For learning actions, it is assumed that:(a) each olivary cell responds to a cerebral instruction for an elemental movement. Any action has a defining representation in terms of elemental movements, and this representation has a neural expression as a sequence of firing patterns in the inferior olive; and(b) in the correct state of the nervous system, a Purkinje cell can initiate the elemental movement to which its corresponding olivary cell responds.3. Whenever an olivary cell fires, it sends an impulse (via the climbing fibre input) to its corresponding Purkinje cell. This Purkinje cell is also exposed (via the mossy fibre input) to information about the context in which its olivary cell fired; and it is shown how, during rehearsal of an action, each Purkinje cell can learn to recognize such contexts. Later, when the action has been learnt, occurrence of the context alone is enough to fire the Purkinje cell, which then causes the next elemental movement. The action thus progresses as it did during rehearsal.4. It is shown that an interpretation of cerebellar cortex as a structure which allows each Purkinje cell to learn a number of contexts is consistent both with the distributions of the various types of cell, and with their known excitatory or inhibitory natures. It is demonstrated that the mossy fibre-granule cell arrangement provides the required pattern discrimination capability.5. The following predictions are made.(a) The synapses from parallel fibres to Purkinje cells are facilitated by the conjunction of presynaptic and climbing fibre (or post-synaptic) activity.(b) No other cerebellar synapses are modifiable.(c) Golgi cells are driven by the greater of the inputs from their upper and lower dendritic fields.6. For learning maintenance reflexes, 2(a) and 2(b) are replaced by2'. Each olivary cell is stimulated by one or more receptors, all of whose activities are usually reduced by the results of stimulating the corresponding Purkinje cell.7. It is shown that if (2') is satisfied, the circuit receptor –{\textgreater} olivary cell –{\textgreater} Purkinje cell –{\textgreater} effector may be regarded as a stabilizing reflex circuit which is activated by learned mossy fibre inputs. This type of reflex has been called a learned conditional reflex, and it is shown how such reflexes can solve problems of maintaining posture and balance.8. 5(a), and either (2) or (2') are essential to the theory: 5(b) and 5(c) are not absolutely essential, and parts of the theory could survive the disproof of either.},
	language = {eng},
	number = {2},
	journal = {J. Physiol.},
	author = {Marr, D},
	year = {1969},
	keywords = {Humans, Animals, merged\_fiete.bib, Cats, Synapses/physiology, Dendrites/physiology, Axons/physiology, Cerebellar Cortex/*physiology, Learning, Motor Skills, Olivary Nucleus/physiology, Postural Balance, Posture, Purkinje Cells/cytology/physiology, Reflex, Sensory Receptor Cells/physiology, Stellate Ganglion/physiology},
	pages = {437--470},
}

@article{harvey_intracellular_2009,
	title = {Intracellular dynamics of hippocampal place cells during virtual navigation},
	volume = {461},
	abstract = {Hippocampal place cells encode spatial information in rate and temporal codes. To examine the mechanisms underlying hippocampal coding, here we measured the intracellular dynamics of place cells by combining in vivo whole-cell recordings with a virtual-reality system. Head-restrained mice, running on a spherical treadmill, interacted with a computer-generated visual environment to perform spatial behaviours. Robust place-cell activity was present during movement along a virtual linear track. From whole-cell recordings, we identified three subthreshold signatures of place fields: an asymmetric ramp-like depolarization of the baseline membrane potential, an increase in the amplitude of intracellular theta oscillations, and a phase precession of the intracellular theta oscillation relative to the extracellularly recorded theta rhythm. These intracellular dynamics underlie the primary features of place-cell rate and temporal codes. The virtual-reality system developed here will enable new experimental approaches to study the neural circuits underlying navigation.},
	language = {eng},
	number = {7266},
	journal = {Nature},
	author = {Harvey, Christopher D and Collman, Forrest and Dombeck, Daniel A and Tank, David W},
	year = {2009},
	note = {Place: Princeton Neuroscience Institute, New Jersey 08544, USA.},
	keywords = {merged\_fiete.bib},
	pages = {941--946},
}

@article{moser_place_2008,
	title = {Place cells, grid cells, and the brain's spatial representation system},
	volume = {31},
	abstract = {More than three decades of research have demonstrated a role for hippocampal place cells in representation of the spatial environment in the brain. New studies have shown that place cells are part of a broader circuit for dynamic representation of self-location. A key component of this network is the entorhinal grid cells, which, by virtue of their tessellating firing fields, may provide the elements of a path integration-based neural map. Here we review how place cells and grid cells may form the basis for quantitative spatiotemporal representation of places, routes, and associated experiences during behavior and in memory. Because these cell types have some of the most conspicuous behavioral correlates among neurons in nonsensory cortical systems, and because their spatial firing structure reflects computations internally in the system, studies of entorhinal-hippocampal representations may offer considerable insight into general principles of cortical network dynamics.},
	language = {eng},
	journal = {Annu. Rev. Neurosci.},
	author = {Moser, Edvard I and Kropff, Emilio and Moser, May-Britt},
	year = {2008},
	note = {Place: Kavli Institute for Systems Neuroscience and Centre for the Biology of Memory, Norwegian University of Science and Technology, 7489 Trondheim, Norway. edvard.moser@cbm.ntnu.no},
	keywords = {Humans, Animals, merged\_fiete.bib, Neurons/*physiology, Hippocampus/cytology/*physiology, Orientation/physiology, Space Perception/*physiology, Action Potentials/*physiology, Nerve Net/cytology/*physiology, Entorhinal Cortex/cytology/physiology, Memory/physiology, Neural Pathways/cytology/physiology},
	pages = {69--89},
}

@article{colgin_frequency_2009,
	title = {Frequency of gamma oscillations routes flow of information in the hippocampus},
	volume = {462},
	abstract = {Gamma oscillations are thought to transiently link distributed cell assemblies that are processing related information, a function that is probably important for network processes such as perception, attentional selection and memory. This 'binding' mechanism requires that spatially distributed cells fire together with millisecond range precision; however, it is not clear how such coordinated timing is achieved given that the frequency of gamma oscillations varies substantially across space and time, from approximately 25 to almost 150 Hz. Here we show that gamma oscillations in the CA1 area of the hippocampus split into distinct fast and slow frequency components that differentially couple CA1 to inputs from the medial entorhinal cortex, an area that provides information about the animal's current position, and CA3, a hippocampal subfield essential for storage of such information. Fast gamma oscillations in CA1 were synchronized with fast gamma in medial entorhinal cortex, and slow gamma oscillations in CA1 were coherent with slow gamma in CA3. Significant proportions of cells in medial entorhinal cortex and CA3 were phase-locked to fast and slow CA1 gamma waves, respectively. The two types of gamma occurred at different phases of the CA1 theta rhythm and mostly on different theta cycles. These results point to routeing of information as a possible function of gamma frequency variations in the brain and provide a mechanism for temporal segregation of potentially interfering information from different sources.},
	language = {ENG},
	number = {7271},
	journal = {Nature},
	author = {Colgin, L L and Denninger, T and Fyhn, M and Hafting, T and Bonnevie, T and Jensen, O and Moser, M B and Moser, E I},
	year = {2009},
	note = {Place: Kavli Institute for Systems Neuroscience and Centre for the Biology of Memory, MTFS, Olav Kyrres gate 9, Norwegian University of Science and Technology, NO-7489 Trondheim, Norway.},
	keywords = {merged\_fiete.bib},
	pages = {353--357},
}

@article{tenenbaum_theory-based_2006,
	title = {Theory-based {Bayesian} models of inductive learning and reasoning},
	volume = {10},
	abstract = {Inductive inference allows humans to make powerful generalizations from sparse data when learning about word meanings, unobserved properties, causal relationships, and many other aspects of the world. Traditional accounts of induction emphasize either the power of statistical learning, or the importance of strong constraints from structured domain knowledge, intuitive theories or schemas. We argue that both components are necessary to explain the nature, use and acquisition of human knowledge, and we introduce a theory-based Bayesian framework for modeling inductive learning and reasoning as statistical inferences over structured knowledge representations.},
	language = {eng},
	number = {7},
	journal = {Trends Cogn. Sci.},
	author = {Tenenbaum, Joshua B and Griffiths, Thomas L and Kemp, Charles},
	year = {2006},
	note = {Place: Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA, USA. jtb@mit.edu},
	keywords = {Humans, merged\_fiete.bib, *Models, Cognition/*physiology, Brain/physiology, Learning/*physiology, *Bayes Theorem, Association Learning/physiology, Comprehension/physiology, Concept Formation/physiology, Generalization (Psychology)/*physiology, Intuition/physiology, Probability Theory, Problem Solving/*physiology, Statistical, Verbal Learning/physiology},
	pages = {309--318},
}

@article{sompolinsky_population_2001,
	title = {Population coding in neuronal systems with correlated noise},
	volume = {64},
	abstract = {Neuronal representations of external events are often distributed across large populations of cells. We study the effect of correlated noise on the accuracy of these neuronal population codes. Our main question is whether the inherent error in the population code can be suppressed by increasing the size of the population N in the presence of correlated noise. We address this issue using a model of a population of neurons that are broadly tuned to an angular variable in two dimensions. The fluctuations in the neuronal activities are modeled as Gaussian noises with pairwise correlations that decay exponentially with the difference between the preferred angles of the correlated cells. We assume that the system is broadly tuned, which means that both the correlation length and the width of the tuning curves of the mean responses span a substantial fraction of the entire system length. The performance of the system is measured by the Fisher information (FI), which bounds its estimation error. By calculating the FI in the limit of a large N, we show that positive correlations decrease the estimation capability of the network, relative to the uncorrelated population. The information capacity saturates to a finite value as the number of cells in the population grows. In contrast, negative correlations substantially increase the information capacity of the neuronal population. These results are supplemented by the effect of correlations on the mutual information of the system. Our analysis provides an estimate of the effective number of statistically independent degrees of freedom, denoted N(eff), that a large correlated system can have. According to our theory N(eff) remains finite in the limit of a large N. Estimating the parameters of the correlations and tuning curves from experimental data in some cortical areas that code for angles, we predict that the number of effective degrees of freedom embedded in localized populations in these areas is less than or of the order of approximately 10(2).},
	language = {eng},
	number = {5 Pt 1},
	journal = {Phys. Rev. E Stat. Nonlin. Soft Matter Phys.},
	author = {Sompolinsky, H and Yoon, H and Kang, K and Shamir, M},
	year = {2001},
	note = {Place: Racah Institute of Physics and Center for Neural Computation, The Hebrew University of Jerusalem, Jerusalem 91904, Israel.},
	keywords = {Animals, merged\_fiete.bib, *Models, Neurological, Neurons/*physiology, Haplorhini, Biophysical Phenomena, Biophysics, Visual Cortex/cytology/physiology},
	pages = {051904},
}

@article{seung_simple_1993-1,
	title = {Simple models for reading neuronal population codes},
	volume = {90},
	abstract = {In many neural systems, sensory information is distributed throughout a population of neurons. We study simple neural network models for extracting this information. The inputs to the networks are the stochastic responses of a population of sensory neurons tuned to directional stimuli. The performance of each network model in psychophysical tasks is compared with that of the optimal maximum likelihood procedure. As a model of direction estimation in two dimensions, we consider a linear network that computes a population vector. Its performance depends on the width of the population tuning curves and is maximal for width, which increases with the level of background activity. Although for narrowly tuned neurons the performance of the population vector is significantly inferior to that of maximum likelihood estimation, the difference between the two is small when the tuning is broad. For direction discrimination, we consider two models: a perceptron with fully adaptive weights and a network made by adding an adaptive second layer to the population vector network. We calculate the error rates of these networks after exhaustive training to a particular direction. By testing on the full range of possible directions, the extent of transfer of training to novel stimuli can be calculated. It is found that for threshold linear networks the transfer of perceptual learning is nonmonotonic. Although performance deteriorates away from the training stimulus, it peaks again at an intermediate angle. This nonmonotonicity provides an important psychophysical test of these models.},
	language = {eng},
	number = {22},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Seung, H S and Sompolinsky, H},
	year = {1993},
	note = {Place: AT\&T Bell Laboratories, Murray Hill, NJ 07974.},
	keywords = {Neurons, Humans, Nerve Net, Animals, merged\_fiete.bib, Models, Orientation/physiology, Perception/*physiology, Theoretical, Likelihood Functions, Afferent/*physiology, Stochastic Processes},
	pages = {10749--10753},
}

@article{latham_optimal_2003,
	title = {Optimal computation with attractor networks},
	volume = {97},
	abstract = {We investigate the ability of multi-dimensional attractor networks to perform reliable computations with noisy population codes. We show that such networks can perform computations as reliably as possible–meaning they can reach the Cramer-Rao bound–so long as the noise is small enough. “Small enough” depends on the properties of the noise, especially its correlational structure. For many correlational structures, noise in the range of what is observed in the cortex is sufficiently small that biologically plausible networks can compute optimally. We demonstrate that this result applies to computations that involve cues of varying reliability, such as the position of an object on the retina in bright versus dim light.},
	language = {eng},
	number = {4-6},
	journal = {J. Physiol. Paris},
	author = {Latham, Peter E and Deneve, Sophie and Pouget, Alexandre},
	year = {2003},
	note = {Place: Department of Neurobiology, University of California at Los Angeles, Los Angeles, CA 90095-1763, USA. pel@gatsby.ucl.ac.uk},
	keywords = {Humans, Animals, merged\_fiete.bib, *Models, Neurological, Neurons/*physiology},
	pages = {683--694},
}

@article{ma_bayesian_2006,
	title = {Bayesian inference with probabilistic population codes},
	volume = {9},
	abstract = {Recent psychophysical experiments indicate that humans perform near-optimal Bayesian inference in a wide variety of tasks, ranging from cue integration to decision making to motor control. This implies that neurons both represent probability distributions and combine those distributions according to a close approximation to Bayes' rule. At first sight, it would seem that the high variability in the responses of cortical neurons would make it difficult to implement such optimal statistical inference in cortical circuits. We argue that, in fact, this variability implies that populations of neurons automatically represent probability distributions over the stimulus, a type of code we call probabilistic population codes. Moreover, we demonstrate that the Poisson-like variability observed in cortex reduces a broad class of Bayesian inference to simple linear combinations of populations of neural activity. These results hold for arbitrary probability distributions over the stimulus, for tuning curves of arbitrary shape and for realistic neuronal variability.},
	language = {eng},
	number = {11},
	journal = {Nat. Neurosci.},
	author = {Ma, Wei Ji and Beck, Jeffrey M and Latham, Peter E and Pouget, Alexandre},
	year = {2006},
	note = {Place: Department of Brain and Cognitive Sciences, Meliora Hall, University of Rochester, Rochester, New York 14627, USA.},
	keywords = {Algorithms, Humans, merged\_fiete.bib, *Models, Neurological, Cerebral Cortex/*physiology, Nerve Net/cytology/*physiology, *Bayes Theorem, Statistical, Normal Distribution, Poisson Distribution},
	pages = {1432--1438},
}

@article{gold_neural_2007,
	title = {The neural basis of decision making},
	volume = {30},
	abstract = {The study of decision making spans such varied fields as neuroscience, psychology, economics, statistics, political science, and computer science. Despite this diversity of applications, most decisions share common elements including deliberation and commitment. Here we evaluate recent progress in understanding how these basic elements of decision formation are implemented in the brain. We focus on simple decisions that can be studied in the laboratory but emphasize general principles likely to extend to other settings.},
	language = {eng},
	journal = {Annu. Rev. Neurosci.},
	author = {Gold, Joshua I and Shadlen, Michael N},
	year = {2007},
	note = {Place: Department of Neuroscience, University of Pennsylvania, Philadelphia, Pennsylvania 19104-6074, USA. jigold@mail.med.upenn.edu},
	keywords = {Humans, Animals, merged\_fiete.bib, Cognition/*physiology, Neurological, Models, Decision Making/*physiology, Brain/anatomy \& histology/*physiology, Movement/physiology, Perception/physiology, Psychomotor Performance/*physiology, Psychophysics, Volition/physiology},
	pages = {535--574},
}

@article{georgopoulos_neuronal_1986,
	title = {Neuronal population coding of movement direction},
	volume = {233},
	abstract = {Although individual neurons in the arm area of the primate motor cortex are only broadly tuned to a particular direction in three-dimensional space, the animal can very precisely control the movement of its arm. The direction of movement was found to be uniquely predicted by the action of a population of motor cortical neurons. When individual cells were represented as vectors that make weighted contributions along the axis of their preferred direction (according to changes in their activity during the movement under consideration) the resulting vector sum of all cell vectors (population vector) was in a direction congruent with the direction of movement. This population vector can be monitored during various tasks, and similar measures in other neuronal populations could be of heuristic value where there is a neural representation of variables with vectorial attributes.},
	number = {4771},
	journal = {Science},
	author = {Georgopoulos, A P and Schwartz, A B and Kettner, R E},
	year = {1986},
	keywords = {merged\_fiete.bib},
	pages = {1416--1419},
}

@article{fyhn_grid_2008,
	title = {Grid cells in mice},
	volume = {18},
	abstract = {The medial entorhinal cortex (EC) is a part of the neural network for the representation of self-location in the rat. The key cell type of this system is the grid cell, whose multiple firing fields span the environment in a remarkably regular triangular or hexagonal pattern. The basic properties of grid cells and other cell types have been described, but the neuronal mechanisms responsible for the formation and maintenance of the place code remain elusive. These mechanisms can be investigated by genetic intervention strategies, where specific components of the entorhinal-hippocampal network are activated or silenced. Because of the common use of knockout mice for such targeted interventions, we asked if grid activity is expressed also in the mouse. Principal neurons in the superficial layers of mouse medial EC had stable grid fields similar to those of the rat. Neighboring grid cells shared a common spacing and orientation but had a different spatial phase, such that a small number of grid cells collectively represented all locations in the environment. The spacing of the grid increased with distance from the dorsal border of the medial EC. The lowest values for grid spacing, recorded at the dorsal end, were comparable to those of the rat, suggesting that grid fields do not scale up proportionally with body size. Grid cells were colocalized with head-direction cells and conjunctive place x head-direction cells, as in the rat. The demonstration of grid cells in mice prepares the ground for transgenic analyses of the entorhinal-hippocampal network.},
	language = {eng},
	number = {12},
	journal = {Hippocampus},
	author = {Fyhn, Marianne and Hafting, Torkel and Witter, Menno P and Moser, Edvard I and Moser, May-Britt},
	year = {2008},
	note = {Place: Kavli Institute for Systems Neuroscience and Centre for the Biology of Memory, Norwegian University of Science and Technology, Trondheim, Norway.},
	keywords = {Animals, Male, merged\_fiete.bib, Neurons/*physiology, Brain Mapping, Entorhinal Cortex/cytology/*physiology, Orientation/physiology, Space Perception/*physiology, Electrophysiology, Species Specificity, Action Potentials/*physiology, Nerve Net/cytology/*physiology, Mice, Memory/physiology, Movement/physiology, Head Movements/physiology},
	pages = {1230--1238},
}

@article{varshney_structural_2009,
	title = {Structural properties of the {C}. elegans neuronal network},
	journal = {submitted},
	author = {Varshney, L R and Chen, B L and Paniagua, E and Hall, D H and Chklovskii, D B},
	year = {2009},
	keywords = {merged\_fiete.bib},
}

@article{kumbhani_precision_2007,
	title = {Precision, reliability, and information-theoretic analysis of visual thalamocortical neurons},
	volume = {98},
	abstract = {High-order statistics of neural responses allow one to gain insight into neural function that may not be evident from firing rate alone. In this study, we compared the precision, reliability, and information content of spike trains from X- and Y-cells in the lateral geniculate nucleus (LGN) and layer IV simple cells of area 17 in the cat. To a stochastic, contrast-modulated Gabor patch, layer IV simple cells responded as precisely as their primary inputs, LGN X-cells, but less reliably. LGN Y-cells were more precise and reliable than LGN X-cells. Also, within each LGN cell type, 1) responses to the same stimulus were nearly identical if they shared the same center sign and 2) responses of neurons with the same center sign were nearly identical to the responses of neurons of opposite center sign if the stimulus' contrasts were inverted. These results suggest simple cells receive highly precise and synchronous LGN input, resulting in precise responses. Nonetheless, the response precision of simple cells was greater than expected. Finally, information-theoretic calculations of our cell responses revealed that 1) LGN X-cells encoded information at half the rate of LGN Y-cells but 2.5 times the rate of layer IV simple cells; 2) LGN cells encoded information in their responses using temporal patterns, whereas simple cells did not; and 3) simple cells used more of their information capacity than LGN X-cells. We propose mechanisms that simple cells might use to ensure high precision.},
	language = {eng},
	number = {5},
	journal = {J. Neurophysiol.},
	author = {Kumbhani, Romesh D and Nolt, Mark J and Palmer, Larry A},
	year = {2007},
	note = {Place: Department of Neuroscience, University of Pennsylvania School of Medicine, 215 Stemmler Hall, Philadelphia, PA 19104-6074, USA.},
	keywords = {Reaction Time, Animals, Male, Time Factors, Reproducibility of Results, Sensitivity and Specificity, merged\_fiete.bib, *Models, Action Potentials/physiology, Neurological, Cats, Visual Perception/*physiology, Neurons/classification/*physiology, Geniculate Bodies/*cytology, Photic Stimulation/methods, Visual Cortex/*cytology, Visual Pathways/physiology},
	pages = {2647--2663},
}

@article{friedrich_multiplexing_2004,
	title = {Multiplexing using synchrony in the zebrafish olfactory bulb},
	volume = {7},
	abstract = {In the olfactory bulb (OB) of zebrafish and other species, odors evoke fast oscillatory population activity and specific firing rate patterns across mitral cells (MCs). This activity evolves over a few hundred milliseconds from the onset of the odor stimulus. Action potentials of odor-specific MC subsets phase-lock to the oscillation, defining small and distributed ensembles within the MC population output. We found that oscillatory field potentials in the zebrafish OB propagate across the OB in waves. Phase-locked MC action potentials, however, were synchronized without a time lag. Firing rate patterns across MCs analyzed with low temporal resolution were informative about odor identity. When the sensitivity for phase-locked spiking was increased, activity patterns became progressively more informative about odor category. Hence, information about complementary stimulus features is conveyed simultaneously by the same population of neurons and can be retrieved selectively by biologically plausible mechanisms, indicating that seemingly alternative coding strategies operating on different time scales may coexist.},
	language = {eng},
	number = {8},
	journal = {Nat. Neurosci.},
	author = {Friedrich, Rainer W and Habermann, Christopher J and Laurent, Gilles},
	year = {2004},
	note = {Place: Max-Planck-Institute for Medical Research, Department of Biomedical Optics, Jahnstr. 29, 69120 Heidelberg, Germany. Rainer.Friedrich@mpimf-heidelberg.mpg.de},
	keywords = {Animals, merged\_fiete.bib, Action Potentials/physiology, Neurons/*physiology, *Cortical Synchronization, *Brain Mapping, Patch-Clamp Techniques, Nose/innervation, Olfactory Bulb/*physiology, Zebrafish/*physiology},
	pages = {862--871},
}

@article{neuenschwander_feed-forward_2002,
	title = {Feed-forward synchronization: propagation of temporal patterns along the retinothalamocortical pathway},
	volume = {357},
	abstract = {Visual responses in the cortex and lateral geniculate nucleus (LGN) are often associated with synchronous oscillatory patterning. In this short review, we examine the possible relationships between subcortical and cortical synchronization mechanisms. Our results obtained from simultaneous multi-unit recordings show strong synchronization of oscillatory responses between retina, LGN and cortex, indicating that cortical neurons can be synchronized by oscillatory activity relayed through the LGN. This feed-forward synchronization mechanism operating in the 60 to 120 Hz frequency range was observed mostly for static stimuli. In response to moving stimuli, by contrast, cortical synchronization was independent of oscillatory inputs from the LGN, with oscillation frequency in the range of 30 to 60 Hz. The functional implications of synchronization of activity from parallel channels are discussed, in particular its significance for signal transmission and cortical integration processes.},
	language = {eng},
	number = {1428},
	journal = {Philos. Trans. R. Soc. Lond. B Biol. Sci.},
	author = {Neuenschwander, Sergio and Castelo-Branco, Miguel and Baron, Jerome and Singer, Wolf},
	year = {2002},
	note = {Place: Max-Planck-Institut fur Hirnforschung, Deutschordenstrasse 46, 60528 Frankfurt am Main, Germany.},
	keywords = {Animals, merged\_fiete.bib, Neurological, Models, Feedback, Visual Cortex/*physiology, Photic Stimulation, Neural Pathways/physiology, Geniculate Bodies/physiology, Retina/*physiology, Thalamus/*physiology},
	pages = {1869--1876},
}

@article{castelo-branco_synchronization_1998,
	title = {Synchronization of visual responses between the cortex, lateral geniculate nucleus, and retina in the anesthetized cat},
	volume = {18},
	abstract = {Synchronization of spatially distributed responses in the cortex is often associated with periodic activity. Recently, synchronous oscillatory patterning was described for visual responses in retinal ganglion cells that is reliably transmitted by the lateral geniculate nucleus (LGN), raising the question of whether oscillatory inputs contribute to synchronous oscillatory responses in the cortex. We have made simultaneous multi-unit recordings from visual areas 17 and 18 as well as the LGN and the retina to examine the interactions between subcortical and cortical synchronization mechanisms. Strong correlations of oscillatory responses were observed between retina, LGN, and cortex, indicating that cortical neurons can become synchronized by oscillatory activity relayed through the LGN. This feedforward synchronization occurred with oscillation frequencies in the range of 60-120 Hz and was most pronounced for responses to stationary flashed stimuli and more frequent for cells in area 18 than in area 17. In response to moving stimuli, by contrast, subcortical and cortical oscillations dissociated, proving the existence of independent subcortical and cortical mechanisms. Subcortical oscillations maintained their high frequencies but became transient. Cortical oscillations were now dominated by a cortical synchronizing mechanism operating in the 30-60 Hz frequency range. When the cortical mechanism dominated, LGN responses could become phase-locked to the cortical oscillations via corticothalamic feedback. In summary, synchronization of cortical responses can result from two independent but interacting mechanisms. First, a transient feedforward synchronization to high-frequency retinal oscillations, and second, an intracortical mechanism, which operates in a lower frequency range and induces more sustained synchronization.},
	language = {eng},
	number = {16},
	journal = {J. Neurosci.},
	author = {Castelo-Branco, M and Neuenschwander, S and Singer, W},
	year = {1998},
	note = {Place: Max-Planck-Institut fur Hirnforschung, Deutschordenstrabetae 46, 60528 Frankfurt am Main, Germany.},
	keywords = {Animals, Time Factors, merged\_fiete.bib, Cats, Reaction Time/physiology, Oscillometry, Visual Perception/*physiology, Visual Cortex/*physiology, Photic Stimulation/methods, Retina/*physiology, Geniculate Bodies/*physiology},
	pages = {6395--6410},
}

@article{ghose_oscillatory_1992,
	title = {Oscillatory discharge in the visual system: does it have a functional role?},
	volume = {68},
	abstract = {1. The discharge of individual neurons in the visual cortex and lateral geniculate nucleus (LGN) of anesthetized and paralyzed cats and kittens was examined for the presence of oscillatory activity. Neural firing was evoked through the monoptic or dichoptic presentation of drifting gratings and random sequences of flashed bars. The degree to which different oscillatory frequencies were present in neural discharge was quantified by computation of the power spectra of impulse train responses. 2. Action potentials from single cells were recorded extracellularly and isolated on the basis of amplitude. Receptive-field properties of the neurons under study were characterized initially by their discharge in response to gratings of sinusoidal luminance. By varying orientation and spatial frequency, optimal stimulus characteristics were determined. Oscillation analysis was performed on spike trains acquired during repeated presentations of the optimal stimulus by identification of power spectra peaks in the frequency range of rhythmic potentials observed in electroencephalograph studies (30-80 Hz). The amplitude and frequency of the largest peak in this range was used to characterize oscillatory strength and frequency. All discharge in which the peak amplitude exceeded the high-frequency noise by a factor {\textgreater} 1.5 was classified as oscillatory. 3. Of the 342 cortical cells examined, 147 cells displayed oscillatory activity in the 30 to 80-Hz range during portions of their visual response. Sixty out of 169 simple cells, 82 out of 166 complex cells, and 5 out of 7 special complex cells exhibited oscillations. There was no laminar bias in the distribution of oscillatory cells; the proportions of oscillatory cells were similar in all layers. All oscillatory discharge was variable with respect to frequency and strength between successive presentations of the same optimal stimulus. In as little as 10 s, for example, peak frequencies shifted by a factor of two. For many cells, these trial-to-trial variations obscured detectable oscillations when all trials were averaged together. 4. The potential role of neuronal maturation in the generation of oscillatory activity was investigated by studying neuronal responses from kittens at 4 wk postnatal. Of the 80 kitten cells studied, 27 exhibited oscillatory discharge. Although oscillations in the kitten visual cortex spanned the same frequency range as that seen in the adult, oscillations in the midfrequency range (36-44 Hz) are more common in the adult cortex. 5. To explore the possibility that oscillations might play a functional role in vision, we investigated the dependence of oscillations on different stimulus parameters.(ABSTRACT TRUNCATED AT 400 WORDS)},
	language = {eng},
	number = {5},
	journal = {J. Neurophysiol.},
	author = {Ghose, G M and Freeman, R D},
	year = {1992},
	note = {Place: Group in Biophysics, School of Optometry, University of California, Berkeley 94720.},
	keywords = {Animals, Vision, Electroencephalography, merged\_fiete.bib, Neurological, Models, Electrodes, Implanted, Cats, Neurons/physiology, Photic Stimulation, Evoked Potentials, Geniculate Bodies/physiology, Binocular/physiology, Monocular/physiology, Ocular/*physiology, Visual Cortex/cytology/*physiology, Visual Fields/physiology, Visual/physiology},
	pages = {1558--1574},
}

@article{kara_efficacy_2003,
	title = {Efficacy of retinal spikes in driving cortical responses},
	volume = {23},
	abstract = {How does a single retinal ganglion cell (RGC) affect the firing of simple cells in the visual cortex? Although much is known of the functional connections between the retina and the lateral geniculate nucleus (LGN) and between LGN and visual cortex, it is hard to infer the effect of disynaptic connections from retina to visual cortex. Most importantly, there is considerable divergence from retina to LGN, so cortical neurons might be influenced by ganglion cells through multiple feedforward pathways. We recorded simultaneously from ganglion cells in the retina and cortical simple cells in the striate cortex with overlapping receptive fields and evaluated disynaptic connections with cross-correlation analysis. In all disynaptically connected pairs, the retinal receptive field center and overlapping cortical subregion always shared the same sign (either both ON or both OFF). Connected pairs were similar in other respects, such as relative position and timing of their receptive fields, and thus obeyed the same rules of connectivity found previously for retinothalamic and thalamocortical connections. We found that a single RGC directly contributed on average to approximately 3\% of the activity of its cortical target. The relative timing of pairs of spikes from the retinal cell affected their efficacy in driving the cortical cell. When two retinal spikes were closely spaced ({\textless}10 msec), the second spike was several times more likely to drive the cortical target. The relative magnitude of this disynaptic paired spike enhancement was considerably larger than has been found previously for retinogeniculate and geniculocortical connections. The amplified paired spike enhancement from retina to cortex ensures that signal transmission from retina to cortex is particularly effective when the retina fires a series of closely spaced action potentials.},
	language = {eng},
	number = {24},
	journal = {J. Neurosci.},
	author = {Kara, Prakash and Reid, R Clay},
	year = {2003},
	note = {Place: Department of Neurobiology, Harvard Medical School, Boston, Massachusetts 02115, USA. pkara@hms.harvard.edu},
	keywords = {Animals, merged\_fiete.bib, Synaptic Transmission/physiology, Electrophysiology, Cats, Reaction Time/physiology, Visual Cortex/*physiology, Photic Stimulation, Computer-Assisted, Action Potentials/*physiology, Visual Pathways/physiology, Geniculate Bodies/physiology, Visual Fields/physiology, Retinal Ganglion Cells/physiology, Signal Processing},
	pages = {8547--8557},
}

@article{reinagel_temporal_2000,
	title = {Temporal coding of visual information in the thalamus},
	volume = {20},
	abstract = {The amount of information a sensory neuron carries about a stimulus is directly related to response reliability. We recorded from individual neurons in the cat lateral geniculate nucleus (LGN) while presenting randomly modulated visual stimuli. The responses to repeated stimuli were reproducible, whereas the responses evoked by nonrepeated stimuli drawn from the same ensemble were variable. Stimulus-dependent information was quantified directly from the difference in entropy of these neural responses. We show that a single LGN cell can encode much more visual information than had been demonstrated previously, ranging from 15 to 102 bits/sec across our sample of cells. Information rate was correlated with the firing rate of the cell, for a consistent rate of 3.6 +/- 0.6 bits/spike (mean +/- SD). This information can primarily be attributed to the high temporal precision with which firing probability is modulated; many individual spikes were timed with better than 1 msec precision. We introduce a way to estimate the amount of information encoded in temporal patterns of firing, as distinct from the information in the time varying firing rate at any temporal resolution. Using this method, we find that temporal patterns sometimes introduce redundancy but often encode visual information. The contribution of temporal patterns ranged from -3.4 to +25.5 bits/sec or from -9.4 to +24.9\% of the total information content of the responses.},
	language = {eng},
	number = {14},
	journal = {J. Neurosci.},
	author = {Reinagel, P and Reid, R C},
	year = {2000},
	note = {Place: Department of Neurobiology, Harvard Medical School, Boston, Massachusetts 02115, USA.},
	keywords = {Neurons, Reaction Time, Animals, Computer Simulation, Action Potentials, merged\_fiete.bib, Cats, Entropy, Visual Perception/*physiology, Photic Stimulation, Afferent/physiology, Poisson Distribution, Visual Pathways/physiology, Thalamus/*physiology, Geniculate Bodies/*physiology, Artifacts},
	pages = {5392--5400},
}

@article{kara_low_2000,
	title = {Low response variability in simultaneously recorded retinal, thalamic, and cortical neurons},
	volume = {27},
	abstract = {The response of a cortical cell to a repeated stimulus can be highly variable from one trial to the next. Much lower variability has been reported of retinal cells. We recorded visual responses simultaneously from three successive stages of the cat visual system: retinal ganglion cells (RGCs), thalamic (LGN) relay cells, and simple cells in layer 4 of primary visual cortex. Spike count variability was lower than that of a Poisson process at all three stages but increased at each stage. Absolute and relative refractory periods largely accounted for the reliability at all three stages. Our results show that cortical responses can be more reliable than previously thought. The differences in reliability in retina, LGN, and cortex can be explained by (1) decreasing firing rates and (2) decreasing absolute and relative refractory periods.},
	language = {eng},
	number = {3},
	journal = {Neuron},
	author = {Kara, P and Reinagel, P and Reid, R C},
	year = {2000},
	note = {Place: Department of Neurobiology, Harvard Medical School, Boston, Massachusetts 02115, USA.},
	keywords = {Animals, Electroencephalography, Reproducibility of Results, merged\_fiete.bib, Action Potentials/physiology, Electrodes, Implanted, Cats, Reaction Time/physiology, Photic Stimulation, Poisson Distribution, Visual Cortex/cytology/*physiology, Electroretinography, Geniculate Bodies/cytology/physiology, Retinal Ganglion Cells/cytology/*physiology, Thalamus/cytology/*physiology, Visual Pathways/*physiology},
	pages = {635--646},
}

@article{erez_achieving_2004,
	title = {Achieving (1/2)log(1+{SNR}) on the {AWGN} {Channel} with {Lattice} {Encoding} and {Decoding}},
	volume = {50},
	number = {10},
	journal = {IEEE Trans. Inf. Theory},
	author = {Erez, U},
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {2293--2314},
}

@article{murthy_testing_2008,
	title = {Testing odor response stereotypy in the {Drosophila} mushroom body},
	volume = {59},
	abstract = {The mushroom body is an insect brain structure required for olfactory learning. Its principal neurons, the Kenyon cells (KCs), form a large cell population. The neuronal populations from which their olfactory input derives (olfactory sensory and projection neurons) can be identified individually by genetic, anatomical, and physiological criteria. We ask whether KCs are similarly identifiable individually, using genetic markers and whole-cell patch-clamp in vivo. We find that across-animal responses are as diverse within the genetically labeled subset as across all KCs in a larger sample. These results combined with those from a simple model, using projection neuron odor responses as inputs, suggest that the precise circuit specification seen at earlier stages of odor processing is likely absent among the mushroom body KCs.},
	language = {eng},
	number = {6},
	journal = {Neuron},
	author = {Murthy, Mala and Fiete, Ila and Laurent, Gilles},
	year = {2008},
	note = {Place: Division of Biology, California Institute of Technology, Pasadena, CA 91125, USA.},
	keywords = {Neurons, Animals, merged\_fiete.bib, Animal/physiology, Behavior, Patch-Clamp Techniques, Synapses/physiology, Synaptic Transmission/*physiology, Afferent/physiology, Association Learning/*physiology, Drosophila/*physiology, Efferent/physiology, Evoked Potentials/physiology, Genetic Markers/physiology, Genetically Modified, Mushroom Bodies/cytology/*physiology, Olfactory Pathways/cytology/*physiology, Smell/*physiology, Stereotyped Behavior/physiology},
	pages = {1009--1023},
}

@article{sharp_lesions_2008,
	title = {Lesions of the mammillary body region alter hippocampal movement signals and theta frequency: implications for path integration models},
	volume = {18},
	abstract = {Cells throughout the hippocampal formation are involved in processing spatial information. These same cells also show an influence of locomotor activity, and these movement signals are thought to be critical for the path integration abilities of these cells. Nuclei in the mammillary region provide ascending influences to the hippocampal formation and have been implicated in influencing both hippocampal spatial and theta signals. Here, we report the effects of mammillary lesions on movement-related signals in several hippocampal subregions. We find first, as predicted by earlier work, these lesions cause an approximately 1 Hz reduction in the frequency of theta modulation of cell firing. According to recent theoretical work, this might, in turn, be expected to influence the size of hippocampal place fields. Our data do not confirm this prediction for any of the hippocampal regions examined. Second, we report lesion effects on the relationship between firing rate and running speed for the hippocampal cells. These lesions caused a reduction in both the slope and intercept of rate-by-speed functions for cells in the hippocampus and postsubiculum. Surprisingly, cells in subiculum showed an opposite effect, so that the excitatory influence of locomotion was enhanced. Path integration theories predict that the speed at which path integration occurs is related to the strength of this movement signal. In remarkable accordance with this prediction, we report that the timing of the place cell signals is slowed following mammillary lesions for hippocampal and postsubicular cells, but, in contrast, is speeded up for subicular cells. In fact, the timing for place signals across lesion condition and brain region is predicted by a single linear function which relates timing to the strength of the running speed signal. Thus, these data provide remarkable support for some aspects of current path integration theory, while posing a challenge for other aspects of these same theories.},
	language = {eng},
	number = {9},
	journal = {Hippocampus},
	author = {Sharp, Patricia E and Koester, Kate},
	year = {2008},
	note = {Place: Department of Psychology, Bowling Green State University, Bowling Green, OH 43403, USA. psharp@bgnet.bgsu.edu},
	keywords = {Animals, Rats, merged\_fiete.bib, Action Potentials/physiology, Hippocampus/*physiology, Neural Pathways/physiology, Mamillary Bodies/*physiology, Movement/*physiology, Theta Rhythm/*methods},
	pages = {862--878},
}

@article{kocsis_characterization_1994,
	title = {Characterization of neurons of the supramammillary nucleus and mammillary body that discharge rhythmically with the hippocampal theta rhythm in the rat},
	volume = {14},
	abstract = {We examined the activity of single cells of the supramammillary nucleus (SUM), the mammillary body (MB), and adjacent regions of the diencephalon with respect to the hippocampal electroencephalogram (EEG) in urethane-anesthetized rats. Twenty-nine of 170 cells were found to discharge synchronously with the theta rhythm of the hippocampus (theta-related neurons). All of the 29 theta-related cells were localized to the SUM or MB. A subset of theta-related cells of SUM and MB discharged in short-duration bursts comparable to the pyramidal complex spike cells of the hippocampus. In contrast to hippocampal complex spikes, however, which predominantly exhibit this mode of firing during non-theta states, the burst firing of SUM/MB cells was strongly correlated with the theta rhythm. The proportion of bursting neurons was higher in MB than in SUM. Using partial coherence analysis, we examined the relationship between SUM/MB theta-related cells and the two generators of theta of the dorsal hippocampus. The theta-related cells of MB showed a stronger correlation with “CA1” than with “dentate” theta, whereas no such asymmetry was found in the relationship between neuronal firing of SUM cells and the two generators of theta in the hippocampus. The foregoing suggests that the theta-related cells of MB are driven by descending projections from the hippocampal formation (CA1), whereas those of the SUM are not. The SUM and MB are intimately connected with the hippocampal formation–the SUM mainly via ascending projections to the dentate gyrus, and the MB via direct descending projections from the subiculum. Theta-related SUM/MB cells may be directly involved in the generation of theta and/or the transfer of theta rhythmicity to various parts of the limbic system and forebrain.},
	language = {eng},
	number = {11 Pt 2},
	journal = {J. Neurosci.},
	author = {Kocsis, B and Vertes, R P},
	year = {1994},
	note = {Place: Center for Complex Systems, Florida Atlantic University, Boca Raton 33431.},
	keywords = {Animals, Rats, Male, Electroencephalography, merged\_fiete.bib, Action Potentials/physiology, Hippocampus/*physiology, Neurons/*physiology, Brain Mapping, Sprague-Dawley, *Theta Rhythm, Diencephalon/cytology/physiology, Hypothalamus, Mamillary Bodies/cytology/physiology, Posterior/cytology/*physiology},
	pages = {7040--7052},
}

@article{stringer_self-organizing_2006,
	title = {Self-organizing path integration using a linked continuous attractor and competitive network: path integration of head direction},
	volume = {17},
	abstract = {A key issue is how networks in the brain learn to perform path integration, that is update a represented position using a velocity signal. Using head direction cells as an example, we show that a competitive network could self-organize to learn to respond to combinations of head direction and angular head rotation velocity. These combination cells can then be used to drive a continuous attractor network to the next head direction based on the incoming rotation signal. An associative synaptic modification rule with a short term memory trace enables preceding combination cell activity during training to be associated with the next position in the continuous attractor network. The network accounts for the presence of neurons found in the brain that respond to combinations of head direction and angular head rotation velocity. Analogous networks in the hippocampal system could self-organize to perform path integration of place and spatial view representations.},
	language = {eng},
	number = {4},
	journal = {Network},
	author = {Stringer, Simon M and Rolls, Edmund T},
	year = {2006},
	note = {Place: Centre for Computational Neuroscience, Department of Experimental Psychology, Oxford University, South Parks Road, Oxford, UK.},
	keywords = {Animals, Computer Simulation, Time Factors, merged\_fiete.bib, *Models, Action Potentials/physiology, Neurological, Neurons/*physiology, Space Perception/physiology, Nerve Net/*physiology, Synapses/physiology, *Neural Networks (Computer), *Head Movements},
	pages = {419--445},
}

@article{maaswinkel_homing_1999,
	title = {Homing with locale, taxon, and dead reckoning strategies by foraging rats: sensory hierarchy in spatial navigation},
	volume = {99},
	abstract = {Studies on foraging rats suggest that they can use visual, olfactory, and self-movement cues for spatial guidance, but their relative reliance on these different cues is not well understood. In the present study, rats left a hidden refuge to search for a large food pellet located somewhere on a circular table, and the accuracy with which they returned to the refuge with the food pellet was measured. Cue use was manipulated by administering probe trials from novel locations, blindfolding, moving the home cage relative to the table, rotating the table and using combinations of these manipulations. When visual cues were available and a consistent starting location used, a visual strategy dominated performance. When blindfolded, the rats used olfactory cues from the surface of the table and from the starting hole. When olfactory stimuli were made uninformative, by changing the starting hole and rotating the table, the rats still homed accurately, suggesting they used self-movement cues. In a number of cue combinations, in which cues gave conflicting information, performance degraded. The results suggest that rats display a hierarchical preference in using visual, olfactory and self-movement cues while at the same time being able to reaffirm or switch between various cue combinations. The results are discussed in relation to ideas concerning the neural basis of spatial navigation.},
	language = {eng},
	number = {2},
	journal = {Behav. Brain Res.},
	author = {Maaswinkel, H and Whishaw, I Q},
	year = {1999},
	note = {Place: Department of Psychology and Neuroscience, University of Lethbridge, Alta, Canada.},
	keywords = {Animals, Vision, Rats, Female, merged\_fiete.bib, Cues, Orientation/*physiology, Long-Evans, Space Perception/*physiology, Smell/physiology, Movement/physiology, Feeding Behavior/*physiology, Food, Hearing/physiology, Ocular/physiology, Sensory Deprivation/physiology},
	pages = {143--152},
}

@article{hasselmo_foreword_2008,
	title = {Foreword: {Special} issue on grid cells},
	volume = {18},
	language = {eng},
	number = {12},
	journal = {Hippocampus},
	author = {Hasselmo, Michael E and Moser, Edvard I and Moser, May-Britt},
	year = {2008},
	note = {Place: Department of Psychology and Program in Neuroscience, Center for Memory and Brain, Boston University, Boston, MA, USA. hasselmo@bu.edu},
	keywords = {Animals, merged\_fiete.bib, Neurological, Neurons/*physiology, Space Perception/physiology, Models, Entorhinal Cortex/cytology/*physiology, Orientation/physiology, Action Potentials/*physiology, Nerve Net/cytology/*physiology, Mice, Neural Pathways/cytology/physiology, Biological Clocks/physiology},
	pages = {1141},
}

@article{samu_robust_2009,
	title = {Robust path integration in the entorhinal grid cell system with hippocampal feed-back},
	abstract = {Animals are able to update their knowledge about their current position solely by integrating the speed and the direction of their movement, which is known as path integration. Recent discoveries suggest that grid cells in the medial entorhinal cortex might perform some of the essential underlying computations of path integration. However, a major concern over path integration is that as the measurement of speed and direction is inaccurate, the representation of the position will become increasingly unreliable. In this paper, we study how allothetic inputs can be used to continually correct the accumulating error in the path integrator system. We set up the model of a mobile agent equipped with the entorhinal representation of idiothetic (grid cell) and allothetic (visual cells) information and simulated its place learning in a virtual environment. Due to competitive learning, a robust hippocampal place code emerges rapidly in the model. At the same time, the hippocampo-entorhinal feed-back connections are modified via Hebbian learning in order to allow hippocampal place cells to influence the attractor dynamics in the entorhinal cortex. We show that the continuous feed-back from the integrated hippocampal place representation is able to stabilize the grid cell code.},
	language = {ENG},
	journal = {Biol. Cybern.},
	author = {Samu, D and Eros, P and Ujfalussy, B and Kiss, T},
	year = {2009},
	note = {Place: Department of Biophysics, KFKI Research Institute for Particle and Nuclear Physics, Hungarian Academy of Sciences, Konkoly-Thegeut 29 - 33, 1121, Budapest, Hungary.},
	keywords = {merged\_fiete.bib},
}

@article{hatsopoulos_decoding_2004,
	title = {Decoding continuous and discrete motor behaviors using motor and premotor cortical ensembles},
	volume = {92},
	abstract = {Decoding motor behavior from neuronal signals has important implications for the development of a brain-machine interface (BMI) but also provides insights into the nature of different movement representations within cortical ensembles. Motor control can be hierarchically characterized as the selection and planning of discrete movement classes and/or postures followed by the execution of continuous limb trajectories. Based on simultaneous recordings in primary motor (MI) and dorsal premotor (PMd) cortices in behaving monkeys, we demonstrate that an MI ensemble can reconstruct hand or joint trajectory more accurately than an equally sized PMd ensemble. In contrast, PMd can more precisely predict the future occurrence of one of several discrete targets to be reached. This double dissociation suggests that a general-purpose BMI could take advantage of multiple cortical areas to control a wider variety of motor actions. These results also support the hierarchical view that MI ensembles are involved in lower-level movement execution, whereas PMd populations represent the early intention to move to visually presented targets.},
	language = {eng},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Hatsopoulos, Nicholas and Joshi, Jignesh and O'Leary, John G},
	year = {2004},
	note = {Place: Dept. of Organismal Biology and Anatomy, University of Chicago, Chicago, IL 60637, USA. nicho@uchicago.edu},
	keywords = {Animals, merged\_fiete.bib, Behavior, Models, Electrophysiology, Animal/*physiology, Biological, Hand/physiology, Statistical, Psychomotor Performance/*physiology, Arm/physiology, Joints/physiology, Macaca mulatta, Motor Cortex/*physiology},
	pages = {1165--1174},
}

@article{hatsopoulos_cortically_2005,
	title = {Cortically controlled brain-machine interface},
	volume = {7},
	abstract = {Over the past ten years, we have tested and helped develop a multi-electrode array for chronic cortical recordings in behaving non-human primates. We have found that it is feasible to record from dozens of single units in the motor cortex for extended periods of time and that these signals can be decoded in a closedloop, real-time system to generate goal-directed behavior of external devices. This work has culminated in a FDA clinical trial that has demonstrated that a tetraplegic patient can voluntarily modulate motor cortical activity in order to move a computer cursor to visual targets. Further advances in BMI technology using non-human primates have focused on using multiple modes of control from signals in different cortical areas. We demonstrate that primary motor cortical activity may be optimized for continuous movement control whereas signals from the premotor cortex may be better suited for discrete target selection. We propose a hybrid BMI whereby decoding can be voluntarily switched from discrete to continuous control modes.},
	language = {ENG},
	number = {1},
	journal = {Conf. Proc. IEEE Eng. Med. Biol. Soc.},
	author = {Hatsopoulos, N and Mukand, J and Polykoff, G and Friehs, G and Donoghue, J},
	year = {2005},
	note = {Place: Dept. of Organismal Biology and Anatomy, University of Chicago, Chicago, IL, Brown University, Providence, RI, Sargent Rehabilitation Center, Providence, RI, Massachusetts General Hospital, Boston, MA, Rhode Island Hospital, Providence, RI, Cyberkinetics, Inc. Foxboro, MA.},
	keywords = {merged\_fiete.bib},
	pages = {7660--7663},
}

@article{acharya_decoding_2008,
	title = {Decoding individuated finger movements using volume-constrained neuronal ensembles in the {M1} hand area},
	volume = {16},
	abstract = {Individuated finger and wrist movements can be decoded using random subpopulations of neurons that are widely distributed in the primary motor (M1) hand area. This work investigates 1) whether it is possible to decode dexterous finger movements using spatially-constrained volumes of neurons as typically recorded from a microelectrode array; and 2) whether decoding accuracy differs due to the configuration or location of the array within the M1 hand area. Single-unit activities were sequentially recorded from task-related neurons in two rhesus monkeys as they performed individuated movements of the fingers and the wrist. Simultaneous neuronal ensembles were simulated by constraining these activities to the recording field dimensions of conventional microelectrode array architectures. Artificial neural network (ANN) based filters were able to decode individuated finger movements with greater than 90\% accuracy for the majority of movement types, using as few as 20 neurons from these ensemble activities. Furthermore, for the large majority of cases there were no significant differences (p {\textless} 0.01) in decoding accuracy as a function of the location of the recording volume. The results suggest that a brain-machine interface (BMI) for dexterous control of individuated fingers and the wrist can be implemented using microelectrode arrays placed broadly in the M1 hand area.},
	language = {eng},
	number = {1},
	journal = {IEEE Trans. Neural Syst. Rehabil. Eng.},
	author = {Acharya, Soumyadipta and Tenore, Francesco and Aggarwal, Vikram and Etienne-Cummings, Ralph and Schieber, Marc H and Thakor, Nitish V},
	year = {2008},
	note = {Place: Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD 21205, USA. acharya@jhu.edu},
	keywords = {Algorithms, Animals, Computer Simulation, Male, merged\_fiete.bib, Models, Nonlinear Dynamics, Statistical, Movement/*physiology, Macaca mulatta, Motor Cortex/*physiology, Conditioning, Efferent Pathways/cytology/*physiology, Fingers/*innervation/*physiology, Hand/innervation/*physiology, Microelectrodes, Motor Neurons/*physiology, Operant/physiology, Prosthesis Design, Wrist/innervation/physiology},
	pages = {15--23},
}

@article{li_unscented_2009,
	title = {Unscented {Kalman} filter for brain-machine interfaces},
	volume = {4},
	abstract = {Brain machine interfaces (BMIs) are devices that convert neural signals into commands to directly control artificial actuators, such as limb prostheses. Previous real-time methods applied to decoding behavioral commands from the activity of populations of neurons have generally relied upon linear models of neural tuning and were limited in the way they used the abundant statistical information contained in the movement profiles of motor tasks. Here, we propose an n-th order unscented Kalman filter which implements two key features: (1) use of a non-linear (quadratic) model of neural tuning which describes neural activity significantly better than commonly-used linear tuning models, and (2) augmentation of the movement state variables with a history of n-1 recent states, which improves prediction of the desired command even before incorporating neural activity information and allows the tuning model to capture relationships between neural activity and movement at multiple time offsets simultaneously. This new filter was tested in BMI experiments in which rhesus monkeys used their cortical activity, recorded through chronically implanted multielectrode arrays, to directly control computer cursors. The 10th order unscented Kalman filter outperformed the standard Kalman filter and the Wiener filter in both off-line reconstruction of movement trajectories and real-time, closed-loop BMI operation.},
	language = {eng},
	number = {7},
	journal = {PLoS One},
	author = {Li, Zheng and O'Doherty, Joseph E and Hanson, Timothy L and Lebedev, Mikhail A and Henriquez, Craig S and Nicolelis, Miguel A L},
	year = {2009},
	note = {Place: Department of Computer Science, Duke University, Durham, North Carolina, United States of America.},
	keywords = {merged\_fiete.bib},
	pages = {e6243},
}

@article{cacucci_place_2008,
	title = {Place cell firing correlates with memory deficits and amyloid plaque burden in {Tg2576} {Alzheimer} mouse model},
	volume = {105},
	abstract = {Alzheimer's disease (AD) is associated with progressive memory decline. Hippocampal place cells are a well understood candidate for the neural basis of one type of memory in rodents; these cells identify the animal's location in an environment and are crucial for spatial memory and navigation. We have recorded place cells in the Tg2576 mouse model of AD, and we report that aged (16 mo) but not young (3 mo) transgenic mice show degraded neuronal representations of the environment. The level of place cell degradation correlates with the animals' (poorer) spatial memory as tested in a forced-choice spatial alternation T-maze task and with hippocampal, but not neocortical, amyloid plaque burden. Place cell recording provides a sensitive assay for measuring the amount and rate of functional deterioration in animal models of dementia as well as providing a quantifiable physiological indication of the beneficial effects of potential therapies.},
	language = {eng},
	number = {22},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Cacucci, Francesca and Yi, Ming and Wills, Thomas J and Chapman, Paul and O'Keefe, John},
	year = {2008},
	note = {Place: Department of Anatomy and Developmental Biology, University College London, London WC1E 6BT, United Kingdom.},
	keywords = {Humans, Animals, merged\_fiete.bib, Animal, Mice, Age Factors, Alzheimer Disease/*pathology/physiopathology, Amyloid beta-Protein/analysis/genetics/*metabolism, Disease Models, Maze Learning, Memory Disorders/*pathology/physiopathology, Pyramidal Cells/*pathology/physiopathology, Senile Plaques/*pathology, Transgenic},
	pages = {7863--7868},
}

@article{laczo_spatial_2009,
	title = {Spatial navigation testing discriminates two types of amnestic mild cognitive impairment},
	volume = {202},
	abstract = {The hippocampus is essential for consolidation of declarative information and spatial navigation. Alzheimer's disease (AD) diagnosis tends to be preceded by a long prodromal period and mild cognitive impairment (MCI). Our goal was to test whether amnestic MCI comprises two different subgroups, with hippocampal and non-hippocampal memory impairment, that vary with respect to spatial navigation ability. A total of 52 patients were classified into two subgroups: non-amnestic MCI (naMCI) (n=10) and amnestic MCI (aMCI) (n=42). The aMCI subgroup was further stratified into memory impairment of hippocampal type-hippocampal aMCI (HaMCI) (n=10) (potential preclinical AD) and isolated retrieval impairment-non-hippocampal (NHaMCI) (n=32). Results were compared to control (n=28) and AD (n=21) groups. We used the Hidden Goal Task, a human analogue of the Morris Water Maze, to examine spatial navigation either dependent (egocentric) or independent of individual's position (allocentric). Overall, the HaMCI group performed poorer on spatial navigation than the NHaMCI group, especially in the latter trials when the HaMCI group exhibited limited capacity to learn and the NHaMCI group exhibited a learning effect. Finally, the HaMCI group performed almost identically as the AD group. Spatial navigation deficit is particularly pronounced in individuals with hippocampus-related memory impairment and may signal preclinical AD.},
	language = {eng},
	number = {2},
	journal = {Behav. Brain Res.},
	author = {Laczo, Jan and Vlcek, Kamil and Vyhnalek, Martin and Vajnerova, Olga and Ort, Michael and Holmerova, Iva and Tolar, Martin and Andel, Ross and Bojar, Martin and Hort, Jakub},
	year = {2009},
	note = {Place: Memory Disorders Clinic, Department of Neurology, 2nd Medical School, Charles University in Prague, Prague, Czech Republic. JanLaczo@seznam.cz},
	keywords = {merged\_fiete.bib},
	pages = {252--259},
}

@article{pihlajamaki_structural_2009,
	title = {Structural and functional {MRI} in mild cognitive impairment},
	volume = {6},
	abstract = {Mild cognitive impairment (MCI), and the amnestic subtype of MCI in particular, is the most recent concept used to describe the intermediary state between healthy aging and Alzheimer's disease (AD). It is hoped that research focusing on MCI would yield markers for early identification of individuals with prodromal AD at such a pre-dementia stage when potential disease modifying therapies would be most efficacious. Magnetic resonance imaging (MRI) combined with various data analysis methods provides tools to investigate alterations in brain structure and function in vivo. Structurally, MCI is characterized by atrophy of the medial temporal lobe (MTL) structures such as the hippocampus and entorhinal cortex, and the amount of atrophy in MCI is intermediate between healthy aging and AD. Additionally, atrophy of the posteromedial cortices such as the posterior cingulum and precuneus as well as of the lateral temporal cortices has been reported. The pattern of atrophy appears to vary according to the subtype of MCI. Functional MRI studies in MCI, compared to healthy aging and AD, have demonstrated both increased and decreased MTL activity during encoding novel visually presented material. Differences in the MTL activation pattern in MCI subjects may relate to differences in the severity of cognitive decline. There is some evidence that increased MTL activity observed during encoding may be compensatory due to incipient atrophy in the MTL structures. The resting state (or, “default mode”) network, and the posteromedial cortical regions in particular, appear to malfunction in MCI. It is suggested that both altered MTL and posteromedial cortical function may be indicative of future cognitive decline from MCI to clinical AD.},
	language = {eng},
	number = {2},
	journal = {Curr. Alzheimer Res.},
	author = {Pihlajamaki, Maija and Jauhiainen, Anne M and Soininen, Hilkka},
	year = {2009},
	note = {Place: Department of Neurology, Kuopio University Hospital Kuopio, Finland.},
	keywords = {Humans, merged\_fiete.bib, Brain Mapping, Image Processing, Computer-Assisted/methods, Atrophy/etiology, Cerebral Cortex/*blood supply/pathology, Cognition Disorders/*pathology/*physiopathology, Magnetic Resonance Imaging/*methods, Oxygen/blood, Rest/physiology},
	pages = {179--185},
}

@article{savioz_contribution_2009,
	title = {Contribution of neural networks to {Alzheimer} disease's progression},
	abstract = {The neuropathology of Alzheimer disease is characterized by senile plaques, neurofibrillary tangles and cell death. These hallmarks develop according to the differential vulnerability of brain networks, senile plaques accumulating preferentially in the associative cortical areas and neurofibrillary tangles in the entorhinal cortex and the hippocampus. We suggest that the main aetiological hypotheses such as the beta-amyloid cascade hypothesis or its variant, the synaptic beta-amyloid hypothesis, will have to consider neural networks not just as targets of degenerative processes but also as contributors of the disease's progression and of its phenotype. Three domains of research are highlighted in this review. First, the cerebral reserve and the redundancy of the network's elements are related to brain vulnerability. Indeed, an enriched environment appears to increase the cerebral reserve as well as the threshold of disease's onset. Second, disease's progression and memory performance cannot be explained by synaptic or neuronal loss only, but also by the presence of compensatory mechanisms, such as synaptic scaling, at the microcircuit level. Third, some phenotypes of Alzheimer disease, such as hallucinations, appear to be related to progressive dysfunction of neural networks as a result, for instance, of a decreased signal to noise ratio, involving a diminished activity of the cholinergic system. Overall, converging results from studies of biological as well as artificial neural networks lead to the conclusion that changes in neural networks contribute strongly to Alzheimer disease's progression.},
	language = {ENG},
	journal = {Brain Res. Bull.},
	author = {Savioz, A and Leuba, G and Vallet, P G and Walzer, C},
	year = {2009},
	note = {Place: Department of Psychiatry, University Hospital of Geneva, CH-1225 Geneva, Switzerland; Geneva Neuroscience Center, Geneva University, CH-1211 Geneva, Switzerland.},
	keywords = {merged\_fiete.bib},
}

@article{nguyen_micro-drive_2009,
	title = {Micro-drive array for chronic in vivo recording: tetrode assembly},
	abstract = {The tetrode, a bundle of four electrodes, has proven to be a valuable tool for the simultaneous recording of multiple neurons in-vivo. The differential amplitude of action potential signatures over the channels of a tetrode allows for the isolation of single-unit activity from multi-unit signals. The ability to precisely control the stereotaxic location and depth of the tetrode is critical for studying coordinated neural activity across brain regions. In combination with a micro-drive array, it is possible to achieve precise placement and stable control of many tetrodes over the course of days to weeks. In this protocol, we demonstrate how to fabricate and condition tetrodes using basic tools and materials, install the tetrodes into a multi-drive tetrode array for chronic in-vivo recording in the rat, make ground wire connections to the micro-drive array, and attach a protective cone onto the micro-drive array in order to protect the tetrodes from physical contact with the environment.},
	language = {eng},
	number = {26},
	journal = {J. Vis. Exp.},
	author = {Nguyen, David P and Layton, Stuart P and Hale, Gregory and Gomperts, Stephen N and Davidson, Thomas J and Kloosterman, Fabian and Wilson, Matthew A},
	year = {2009},
	note = {Place: Department of Brain and Cognitive Science, Massachusetts Institute of Technology, USA. dpnguyen@mit.edu},
	keywords = {merged\_fiete.bib, Neurons/*physiology, Brain/*physiology, *Microelectrodes, Electrophysiology/*instrumentation/methods, Microarray Analysis/*instrumentation/methods},
}

@article{lansink_split_2007,
	title = {A split microdrive for simultaneous multi-electrode recordings from two brain areas in awake small animals},
	volume = {162},
	abstract = {Complex cognitive operations such as memory formation and decision-making are thought to be mediated not by single, isolated brain structures but by multiple, connected brain areas. To facilitate studies on the neural communication between connected brain structures, we developed a multi-electrode microdrive for chronically recording ensembles of neurons in two different brain areas simultaneously. The “split drive” contains 14 independently movable microdrivers that were designed to hold tetrodes and to permit day-to-day adjustment of dorsoventral position in the brain. The limited weight of the drive allowed rats to adjust well to the headstage after recovering from surgery and permitted stable recording sessions across at least several weeks. In addition to describing the design and assembly of the split drive, we also discuss some important individual parts of microdrives used for tetrode recordings in general. Furthermore, the split drive was applied to two widely separated and connected brain structures, the hippocampus and ventral striatum. From these two areas, stable ensemble recordings were conducted in rats performing a reward-searching task on a triangular track, yielding group sizes of about 15 and 25 units in the dorsal hippocampus and ventral striatum, respectively.},
	language = {eng},
	number = {1-2},
	journal = {J. Neurosci. Methods},
	author = {Lansink, Carien S and Bakker, Mattijs and Buster, Wietze and Lankelma, Jan and van der Blom, Ruud and Westdorp, Rinus and Joosten, Ruud N J M A and McNaughton, Bruce L and Pennartz, Cyriel M A},
	year = {2007},
	note = {Place: Center for Neuroscience, Swammerdam Institute for Life Sciences, Faculty of Science, Universiteit van Amsterdam, P.O. Box 94084, Kruislaan 320, 1090 GB Amsterdam, The Netherlands.},
	keywords = {Animals, Rats, merged\_fiete.bib, Wistar, Wakefulness/*physiology, Electrophysiology/*instrumentation/methods, Brain/anatomy \& histology/cytology/*physiology},
	pages = {129--138},
}

@article{seung_reading_2009,
	title = {Reading the book of memory: sparse sampling versus dense mapping of connectomes},
	volume = {62},
	abstract = {Many theories of neural networks assume rules of connection between pairs of neurons that are based on their cell types or functional properties. It is finally becoming feasible to test such pairwise models of connectivity, due to emerging advances in neuroanatomical techniques. One method will be to measure the functional properties of connected pairs of neurons, sparsely sampling pairs from many specimens. Another method will be to find a “connectome,” a dense map of all connections in a single specimen, and infer functional properties of neurons through computational analysis. For the latter method, the most exciting prospect would be to decode the memories that are hypothesized to be stored in connectomes.},
	language = {eng},
	number = {1},
	journal = {Neuron},
	author = {Seung, H Sebastian},
	year = {2009},
	note = {Place: Howard Hughes Medical Institute, Brain and Cognitive Sciences Department, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. seung@mit.edu},
	keywords = {Humans, Animals, Neural Pathways, merged\_fiete.bib, *Models, Neurological, Neurons/*physiology, *Brain Mapping, Memory/*physiology, Nerve Net/physiology, Brain/cytology/*physiology, Caenorhabditis elegans/physiology, Neural Networks (Computer), Retina/cytology/physiology, Synaptic Transmission},
	pages = {17--29},
}

@article{lichtman_technicolour_2008,
	title = {A technicolour approach to the connectome},
	volume = {9},
	abstract = {A central aim of neuroscience is to map neural circuits, in order to learn how they account for mental activities and behaviours and how alterations in them lead to neurological and psychiatric disorders. However, the methods that are currently available for visualizing circuits have severe limitations that make it extremely difficult to extract precise wiring diagrams from histological images. Here we review recent advances in this area, along with some of the opportunities that these advances present and the obstacles that remain.},
	language = {eng},
	number = {6},
	journal = {Nat. Rev. Neurosci.},
	author = {Lichtman, Jeff W and Livet, Jean and Sanes, Joshua R},
	year = {2008},
	note = {Place: Department of Molecular and Cellular Biology and Center for Brain Science, Harvard University, Cambridge, Massachusetts 02138, USA. jeff@mcb.harvard.edu},
	keywords = {Humans, Animals, merged\_fiete.bib, Brain Mapping/*methods, Neurons/physiology, Genetically Modified, Brain/*physiology/ultrastructure, Coloring Agents/diagnostic use, Electron, Luminescent Proteins/diagnostic use/genetics, Microscopy, Neural Pathways/physiology/ultrastructure, Neurosciences/*methods/*trends, Staining and Labeling, Transgenes},
	pages = {417--422},
}

@article{van_strien_anatomy_2009,
	title = {The anatomy of memory: an interactive overview of the parahippocampal-hippocampal network},
	volume = {10},
	abstract = {Converging evidence suggests that each parahippocampal and hippocampal subregion contributes uniquely to the encoding, consolidation and retrieval of declarative memories, but their precise roles remain elusive. Current functional thinking does not fully incorporate the intricately connected networks that link these subregions, owing to their organizational complexity; however, such detailed anatomical knowledge is of pivotal importance for comprehending the unique functional contribution of each subregion. We have therefore developed an interactive diagram with the aim to display all of the currently known anatomical connections of the rat parahippocampal-hippocampal network. In this Review, we integrate the existing anatomical knowledge into a concise description of this network and discuss the functional implications of some relatively underexposed connections.},
	language = {eng},
	number = {4},
	journal = {Nat. Rev. Neurosci.},
	author = {van Strien, N M and Cappaert, N L M and Witter, M P},
	year = {2009},
	note = {Place: Department of Anatomy and Neurosciences, VU University Medical Center, Amsterdam, The Netherlands. n.vanstrien@temporal-lobe.com},
	keywords = {Humans, Animals, merged\_fiete.bib, Nerve Net/*physiology, Memory/*physiology, Cell Adhesion/physiology, Cell Communication/*physiology},
	pages = {272--282},
}

@article{nagahara_entorhinal-perirhinal_1995,
	title = {Entorhinal-perirhinal lesions impair performance of rats on two versions of place learning in the {Morris} water maze},
	volume = {109},
	abstract = {The effects of entorhinal-perirhinal lesions in rats were studied with 2 versions of a place learning task in the Morris water maze. These lesions impaired performance on a multiple-trial task (3 days of 6 trials and a probe trial). This assessment was followed by a task in which rats were repeatedly trained to find novel locations with a variable delay (30 s or 5 min) imposed between each sample trial and retention test. Entorhinal-perirhinal damage produced a delay-dependent deficit in spatial memory: Rats with lesions were impaired at the 5-min delay relative to the control group and to their own performance at 30 s. These findings are discussed in relationship to memory impairment after entorhinal damage and spatial learning deficits observed after hippocampal damage.},
	language = {eng},
	number = {1},
	journal = {Behav. Neurosci.},
	author = {Nagahara, A H and Otto, T and Gallagher, M},
	year = {1995},
	note = {Place: Department of Psychology, University of North Carolina at Chapel Hill, USA.},
	keywords = {Animals, Memory, Rats, Male, merged\_fiete.bib, Maze Learning/*physiology, Orientation/*physiology, Brain Mapping, Hippocampus/physiology, Neurons/physiology, Entorhinal Cortex/*physiology, Mental Recall/*physiology, Retention (Psychology)/physiology, Short-Term/physiology},
	pages = {3--9},
}

@article{blair_role_1998,
	title = {Role of the lateral mammillary nucleus in the rat head direction circuit: a combined single unit recording and lesion study},
	volume = {21},
	abstract = {We recorded head direction (HD) cells from the lateral mammillary nucleus (LMN) and anterior thalamus (ATN) of freely behaving rats and also made bilateral lesions of LMN while recording HD cells from ATN. We discovered that the tuning functions of LMN HD cells become narrower during contraversive head turns, but not ipsiversive head turns, compared to when the head is not turning. This narrowing effect does not occur for ATN HD cells. We also found that the HD signal in LMN leads that in ATN by about 15-20 ms. When LMN was lesioned bilaterally, HD cells in ATN immediately lost their directional firing properties and never recovered them. Based on these findings, we argue that LMN may be an essential component of an attractor-integrator network that participates in generating the HD signal.},
	language = {eng},
	number = {6},
	journal = {Neuron},
	author = {Blair, H T and Cho, J and Sharp, P E},
	year = {1998},
	note = {Place: Department of Psychology, Yale University, New Haven, Connecticut 06520, USA. tad@cns.nyu.edu},
	keywords = {Animals, Rats, Male, merged\_fiete.bib, Neurological, Neurons/*physiology, Long-Evans, Models, Head Movements/*physiology, *Brain Mapping, Posture, Thalamus/*physiology, Mamillary Bodies/*physiology, Functional Laterality},
	pages = {1387--1397},
}

@article{sharp_subicular_1997,
	title = {Subicular cells generate similar spatial firing patterns in two geometrically and visually distinctive environments: comparison with hippocampal place cells},
	volume = {85},
	abstract = {Cells in both the hippocampus and the subiculum show location related firing patterns, so that the momentary firing rate of a cell is related to the spatial location of a freely moving rat as it navigates in an environment. Since the subiculum receives a strong anatomical projection from the hippocampus, it seems possible that the subicular cell spatial patterns are simply driven by the spatial signals from hippocampal place cells. Data presented here, however, suggest that the two areas code space in fundamentally different ways. Here, spatial firing patterns of individual hippocampal and subicular cells were studied as rats navigated in two different environments. The two chambers were a cylinder and a square, of equal area. For some rats the two chambers were painted to have similar visual stimulus characteristics, while for others, the two were very different. The subicular cells showed very similar firing patterns in the two chambers, regardless of whether they were visually similar or different. In contrast, as predicted based on the findings of earlier studies, hippocampal place cells showed different patterns in the two (again, regardless of their visual similarity). These results suggest that the subicular cells have the ability to transfer a single, abstract spatial representation from one environment to another. This pattern is stretched to fit within the boundaries of the current environment. Thus, the subicular cells seem to provide a generic representation of the geometric relationships between different locations in an environment. It seems possible that this representation may contribute to some navigational abilities exhibited by animals, such as dead reckoning, and novel route generation in unfamiliar environments. In contrast, it appears that hippocampal place cells provide a spatial representation-which is unique for each environment and which is strongly influenced by the exact details and overall context of the situation.},
	language = {eng},
	number = {1},
	journal = {Behav. Brain Res.},
	author = {Sharp, P E},
	year = {1997},
	note = {Place: Department of Psychology, Yale University, New Haven, CT 06520-8205, USA. psharp@minerva.cis.yale.edu},
	keywords = {Animals, Rats, Female, merged\_fiete.bib, Neurons/*physiology, Hippocampus/cytology/*physiology, *Environment, Electrodes, Implanted, Orientation/physiology, Space Perception/*physiology, Electrophysiology, Conditioning, Operant/physiology},
	pages = {71--92},
}

@article{aksay_vivo_2001,
	title = {In vivo intracellular recording and perturbation of persistent activity in a neural integrator},
	volume = {4},
	abstract = {To investigate the mechanisms of persistent neural activity, we obtained in vivo intracellular recordings from neurons in an oculomotor neural integrator of the goldfish during spontaneous saccades and fixations. Persistent changes in firing rate following saccades were associated with step changes in interspike membrane potential that were correlated with changes in eye position. Perturbation of persistent activity with brief intracellular current pulses designed to mimic saccadic input only induced transient changes of firing rate and membrane potential. When neurons were hyperpolarized below action potential threshold, position-correlated step changes in membrane potential remained. Membrane potential fluctuations were greater during more depolarized steps. These results suggest that sustained changes in firing rate are supported not by either membrane multistability or changes in pacemaker currents, but rather by persistent changes in the rate or amplitude of synaptic inputs.},
	language = {eng},
	number = {2},
	journal = {Nat. Neurosci.},
	author = {Aksay, E and Gamkrelidze, G and Seung, H S and Baker, R and Tank, D W},
	year = {2001},
	note = {Place: Biological Computation Research Department, Bell Laboratories, Lucent Technologies, 700 Mountain Avenue, Murray Hill, New Jersey 07974, USA.},
	keywords = {Animals, merged\_fiete.bib, Action Potentials/physiology, Neurons/*physiology, Reaction Time/physiology, Differential Threshold, Ocular/physiology, Electric Stimulation, Fixation, Goldfish, Intracellular Membranes/physiology, Membrane Potentials/physiology, Ocular Physiological Phenomena, Oculomotor Muscles/*innervation, Saccades/physiology},
	pages = {184--193},
}

@article{huk_neural_2005,
	title = {Neural activity in macaque parietal cortex reflects temporal integration of visual motion signals during perceptual decision making},
	volume = {25},
	abstract = {Decision-making often requires the accumulation and maintenance of evidence over time. Although the neural signals underlying sensory processing have been studied extensively, little is known about how the brain accrues and holds these sensory signals to guide later actions. Previous work has suggested that neural activity in the lateral intraparietal area (LIP) of the monkey brain reflects the formation of perceptual decisions in a random dot direction-discrimination task in which monkeys communicate their decisions with eye-movement responses. We tested the hypothesis that decision-related neural activity in LIP represents the time integral of the momentary motion “evidence.” By briefly perturbing the strength of the visual motion stimulus during the formation of perceptual decisions, we tested whether this LIP activity reflected a persistent, integrated “memory” of these brief sensory events. We found that the responses of LIP neurons reflected substantial temporal integration. Brief pulses had persistent effects on both the monkeys' choices and the responses of neurons in LIP, lasting up to 800 ms after appearance. These results demonstrate that LIP is involved in neural time integration underlying the accumulation of evidence in this task. Additional analyses suggest that decision-related LIP responses, as well as behavioral choices and reaction times, can be explained by near-perfect time integration that stops when a criterion amount of evidence has been accumulated. Temporal integration may be a fundamental computation underlying higher cognitive functions that are dissociated from immediate sensory inputs or motor outputs.},
	language = {eng},
	number = {45},
	journal = {J. Neurosci.},
	author = {Huk, Alexander C and Shadlen, Michael N},
	year = {2005},
	note = {Place: Center for Perceptual Systems, Department of Psychology, University of Texas, Austin, Texas 78712, USA. huk@mail.utexas.edu},
	keywords = {Animals, Male, Time Factors, merged\_fiete.bib, Action Potentials/physiology, Behavior, Orientation/physiology, Motor Activity/*physiology, Motion Perception/*physiology, Reaction Time/physiology, Discrimination (Psychology)/physiology, Animal, Neurons/classification/*physiology, Nonlinear Dynamics, Decision Making/*physiology, Photic Stimulation/methods, Macaca mulatta, Analysis of Variance, Cell Count/methods, Eye Movements/physiology, Parietal Lobe/*cytology, Psychometrics/methods},
	pages = {10420--10436},
}

@article{koulakov_model_2002,
	title = {Model for a robust neural integrator},
	volume = {5},
	abstract = {Integrator circuits in the brain show persistent firing that reflects the sum of previous excitatory and inhibitory inputs from external sources. Integrator circuits have been implicated in parametric working memory, decision making and motor control. Previous work has shown that stable integrator function can be achieved by an excitatory recurrent neural circuit, provided synaptic strengths are tuned with extreme precision (better than 1\% accuracy). Here we show that integrator circuits can function without fine tuning if the neuronal units have bistable properties. Two specific mechanisms of bistability are analyzed, one based on local recurrent excitation, and the other on the voltage-dependence of the NMDA (N-methyl-D-aspartate) channel. Neither circuit requires fine tuning to perform robust integration, and the latter actually exploits the variability of neuronal conductances.},
	language = {eng},
	number = {8},
	journal = {Nat. Neurosci.},
	author = {Koulakov, Alexei A and Raghavachari, Sridhar and Kepecs, Adam and Lisman, John E},
	year = {2002},
	note = {Place: Salk Institute for Biological Studies, 10010 North Torrey Pines Road, La Jolla, California 92037, USA. akula@physics.utah.edu},
	keywords = {Reproducibility of Results, merged\_fiete.bib, *Models, Neurological, Neurons/*physiology, *Neural Networks (Computer), N-Methyl-D-Aspartate/*physiology, Receptors, *Computer Simulation},
	pages = {775--782},
}

@article{rorie_general_2005,
	title = {A general mechanism for decision-making in the human brain?},
	volume = {9},
	abstract = {A new fMRI study by Heekeren and colleagues suggests that left dorsolateral prefrontal cortex (DLPFC) contains a region that integrates sensory evidence supporting perceptual decisions. DLPFC meets two criteria posited by Heekeren et al. for such a region: (1) its activity is correlated in time with the output of sensory areas of the visual cortex measured simultaneously, and (2) as expected of an integrator, its activity is greater on trials for which the sensory evidence is substantial than on trials for which the sensory evidence is weak. Complementary experiments in humans and monkeys now offer a realistic hope of elucidating decision-making networks in the primate brain.},
	language = {eng},
	number = {2},
	journal = {Trends Cogn. Sci.},
	author = {Rorie, Alan E and Newsome, William T},
	year = {2005},
	note = {Place: Howard Hughes Medical Institute and Department of Neurobiology, Stanford University School of Medicine, Stanford, CA 94305, USA. rorie@stanford.edu},
	keywords = {Humans, Animals, merged\_fiete.bib, Haplorhini, *Brain Mapping, Motion Perception/physiology, Visual Perception/*physiology, Photic Stimulation, Decision Making/*physiology, Eye Movements/physiology, Magnetic Resonance Imaging, Mental Processes/*physiology, Prefrontal Cortex/*physiology},
	pages = {41--43},
}

@article{huerta_bidirectional_1995,
	title = {Bidirectional synaptic plasticity induced by a single burst during cholinergic theta oscillation in {CA1} in vitro},
	volume = {15},
	abstract = {In standard protocols, the frequency of synaptic stimulation determines whether CA1 hippocampal synapses undergo long-term potentiation or depression. Here we show that during cholinergically induced theta oscillation (theta) synaptic plasticity is greatly sensitized and can be induced by a single burst (4 pulses, 100 Hz). A burst given at the peak of theta induces homosynaptic LTP; the same burst at a trough induces homosynaptic LTD of previously potentiated synapses. Heterosynaptic LTD is produced at inactive synapses when others undergo LTP. The synaptic modifications during theta require NMDA receptors and muscarinic receptors. The enhancement is cooperative and occludes with standard LTP. These results suggest that the similar bursts observed during theta rhythm in vivo may be a natural stimulus for inducing LTP/LTD.},
	language = {eng},
	number = {5},
	journal = {Neuron},
	author = {Huerta, P T and Lisman, J E},
	month = nov,
	year = {1995},
	note = {Place: Department of Biology, Brandeis University, Waltham, Massachusetts 02254, USA.},
	keywords = {merged\_fiete.bib},
	pages = {1053--1063},
}

@article{wespatat_phase_2004,
	title = {Phase sensitivity of synaptic modifications in oscillating cells of rat visual cortex},
	volume = {24},
	abstract = {Synaptic modifications depend on the amplitude and temporal relations of presynaptic and postsynaptic activation. The interactions among these variables are complex and hard to predict when neurons engage in synchronized high-frequency oscillations in the beta and gamma frequency range, as is often observed during signal processing in the cerebral cortex. Here we investigate in layer II/III pyramidal cells of rat visual cortex slices how synapses change when synchronized, oscillatory multifiber activity impinges on postsynaptic neurons during membrane potential (V(m)) oscillations at 20 and 40 Hz. Synapses underwent long-term potentiation (LTP) when EPSPs coincided with the peaks of the V(m) oscillations but exhibited long-term depression (LTD) when EPSPs coincided with the troughs. The induction of LTP but not of LTD was NMDA receptor dependent, required additional activation of muscarinic receptors in older animals, and persisted in a kainate-driven increased conductance state. Thus, even when neuronal networks engage in high-frequency oscillations, synaptic plasticity remains exquisitely sensitive to the timing of discharges. This is an essential prerequisite for theories which assume that precise synchronization of discharges serves as signature of relatedness in distributed processing.},
	language = {eng},
	number = {41},
	journal = {J. Neurosci.},
	author = {Wespatat, Valerie and Tennigkeit, Frank and Singer, Wolf},
	month = oct,
	year = {2004},
	note = {Place: Department of Neurophysiology, Max-Planck-Institute for Brain Research, D-60528 Frankfurt/Main, Germany.},
	keywords = {merged\_fiete.bib},
	pages = {9067--9075},
}

@article{blair_anticipatory_1995,
	title = {Anticipatory head direction signals in anterior thalamus: evidence for a thalamocortical circuit that integrates angular head motion to compute head direction},
	volume = {15},
	abstract = {Several regions in the rat brain contain neurons known as head-direction cells, which fire only when the rat's head is facing in a specific direction. Head-direction cells are influenced only by the direction of the head with respect to the static environmental surroundings, and not by the position of the head relative to the body. Each head-direction cell has its own preferred direction of firing, so that together, the population of cells provides a continuous signal of momentary directional heading. Here, head-direction cells were recorded from the post-subicular cortex (PSC) and anterodorsal nucleus (ADN) of the thalamus of freely moving rats. Cell activity was analyzed in relation to both momentary head direction, and the angular velocity of head turns. Head-direction cells in PSC maintained the same directional firing preference, regardless of the angular head velocity. By contrast, head-direction cells in ADN systematically shifted their directional firing preference, as a function of angular head velocity. The ADN cells always shifted their directional tuning peak to the left during clockwise head turns, and to the right during counterclockwise head turns. These results suggest that ADN neurons anticipate the future direction of the head, whereas PSC neurons encode the present direction of the head. Based on these findings, we hypothesize that neurons in PSC and ADN are reciprocally connected to form a thalamocortical circuit, which computes the directional position of the rat's head by integrating the angular motion of the head over time.},
	language = {eng},
	number = {9},
	journal = {J. Neurosci.},
	author = {Blair, H T and Sharp, P E},
	month = sep,
	year = {1995},
	note = {Place: Department of Psychology, Yale University, New Haven, Connecticut 06520-8205, USA.},
	keywords = {merged\_fiete.bib},
	pages = {6260--6270},
}

@article{hinton_fast_2006-1,
	title = {A fast learning algorithm for deep belief nets},
	volume = {18},
	abstract = {We show how to use “complementary priors” to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.},
	language = {eng},
	number = {7},
	journal = {Neural Comput.},
	author = {Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye},
	month = jul,
	year = {2006},
	note = {Place: Department of Computer Science, University of Toronto, Canada. hinton@cs.toronto.edu},
	keywords = {merged\_fiete.bib},
	pages = {1527--1554},
}

@article{kao_contributions_2005,
	title = {Contributions of an avian basal ganglia-forebrain circuit to real-time modulation of song},
	volume = {433},
	abstract = {Cortical-basal ganglia circuits have a critical role in motor control and motor learning. In songbirds, the anterior forebrain pathway (AFP) is a basal ganglia-forebrain circuit required for song learning and adult vocal plasticity but not for production of learned song. Here, we investigate functional contributions of this circuit to the control of song, a complex, learned motor skill. We test the hypothesis that neural activity in the AFP of adult birds can direct moment-by-moment changes in the primary motor areas responsible for generating song. We show that song-triggered microstimulation in the output nucleus of the AFP induces acute and specific changes in learned parameters of song. Moreover, under both natural and experimental conditions, variability in the pattern of AFP activity is associated with variability in song structure. Finally, lesions of the output nucleus of the AFP prevent naturally occurring modulation of song variability. These findings demonstrate a previously unappreciated capacity of the AFP to direct real-time changes in song. More generally, they suggest that frontal cortical and basal ganglia areas may contribute to motor learning by biasing motor output towards desired targets or by introducing stochastic variability required for reinforcement learning.},
	language = {eng},
	number = {7026},
	journal = {Nature},
	author = {Kao, Mimi H and Doupe, Allison J and Brainard, Michael S},
	year = {2005},
	note = {Place: Keck Center for Integrative Neuroscience, Department of Physiology, University of California, San Francisco, California 94143-0444, USA. mimi@phy.ucsf.edu},
	keywords = {Animals, Male, Time Factors, merged\_fiete.bib, Learning/physiology, Models, Biological, Stochastic Processes, *Animal Communication, *Sound, Acoustic Stimulation, Basal Ganglia/*physiology, Finches/*physiology, Prosencephalon/*physiology},
	pages = {638--643},
}

@article{seung_learning_2003,
	title = {Learning in spiking neural networks by reinforcement of stochastic synaptic transmission},
	volume = {40},
	abstract = {It is well-known that chemical synaptic transmission is an unreliable process, but the function of such unreliability remains unclear. Here I consider the hypothesis that the randomness of synaptic transmission is harnessed by the brain for learning, in analogy to the way that genetic mutation is utilized by Darwinian evolution. This is possible if synapses are “hedonistic,” responding to a global reward signal by increasing their probabilities of vesicle release or failure, depending on which action immediately preceded reward. Hedonistic synapses learn by computing a stochastic approximation to the gradient of the average reward. They are compatible with synaptic dynamics such as short-term facilitation and depression and with the intricacies of dendritic integration and action potential generation. A network of hedonistic synapses can be trained to perform a desired computation by administering reward appropriately, as illustrated here through numerical simulations of integrate-and-fire model neurons.},
	language = {eng},
	number = {6},
	journal = {Neuron},
	author = {Seung, H Sebastian},
	year = {2003},
	note = {Place: Howard Hughes Medical Institute and Brain and Cognitive Sciences Department, Massachusetts Institute of Technology, Cambridge, MA 02139, USA. seung@mit.edu},
	keywords = {merged\_fiete.bib, Action Potentials/*physiology, Synaptic Transmission/*physiology, *Neural Networks (Computer), Learning/*physiology, Stochastic Processes, *Reinforcement (Psychology)},
	pages = {1063--1073},
}

@article{amaral_three-dimensional_1989,
	title = {The three-dimensional organization of the hippocampal formation: a review of anatomical data},
	volume = {31},
	abstract = {In the early 1970s, Andersen and colleagues proposed that the principal excitatory pathways of the hippocampal formation were organized in a lamellar fashion. This proposition, based heavily on the physiological studies of the proponents, indicated that “a point source of entorhinal activity projects its impulses through the four membered pathway (of the hippocampal formation) along a slice or lamella, of hippocampal tissue oriented normally to the alvear surface” [Anderson P., Bliss V.P. and Skrede K. K. (1971) Expl Brain Res. 13, 222-238] and perpendicular to the long axis of the hippocampus. Andersen et al. further suggested that, “By means of this lamellar organization, small strips of the hippocampal cortex may operate as independent functional units, although excitatory and inhibitory transverse connections may modify the behavior of neighboring lamellae.” The “lamellar hypothesis” of hippocampal anatomical organization has had tremendous influence on the conceptualization of hippocampal information processing and was largely responsible for prompting the establishment of the in vitro hippocampal slice technology. While the “lamellar hypothesis” was consistent with the known neuroanatomy, subsequent neuroanatomical investigations, using a variety of modern tracing techniques, have invariably demonstrated that all of the major hippocampal projections, except for those arising from the granule cells of the dentate gyrus, are much more divergent than would be consistent with a strict interpretation of the lamellar hypothesis. This has become particularly clear in ongoing studies of the intrinsic hippocampal projections using the recently introduced anterograde tracer, Phaseolus vulgaris leucoagglutinin. Citing the conclusions from several papers dealing with the anatomical organization of the hippocampal formation and using examples from recent Phaseolus vulgaris leucoagglutinin mapping studies, the following are demonstrated. (1) That the major hippocampal projections are as extensive and highly organized in the long or septotemporal axis of the hippocampus as in the transverse axis. (2) That at least some of the hippocampal projections, such as the associational projections arising from the dentate gyrus, appear to be specifically organized to integrate distant levels of the hippocampal formation. (3) That the physiological data of Anderson et al. can be re-interpreted in the light of these new anatomical data to show how the stimulation and recording protocols used at the time would, in fact, generate the appearance of a lamellar organization. It is concluded that it is heuristically most reasonable to consider the hippocampal formation as a three-dimensional cortical region with important information processing taking place in both the transverse and long axes.(ABSTRACT TRUNCATED AT 400 WORDS)},
	language = {eng},
	number = {3},
	journal = {Neuroscience},
	author = {Amaral, D G and Witter, M P},
	year = {1989},
	note = {Place: Salk Institute for Biological Studies, San Diego, CA 92138.},
	keywords = {Animals, Rats, merged\_fiete.bib, Hippocampus/*anatomy \& histology},
	pages = {571--591},
}

@article{lubenov_hippocampal_2009,
	title = {Hippocampal theta oscillations are travelling waves},
	volume = {459},
	abstract = {Theta oscillations clock hippocampal activity during awake behaviour and rapid eye movement (REM) sleep. These oscillations are prominent in the local field potential, and they also reflect the subthreshold membrane potential and strongly modulate the spiking of hippocampal neurons. The prevailing view is that theta oscillations are synchronized throughout the hippocampus, despite the lack of conclusive experimental evidence. In contrast, here we show that in freely behaving rats, theta oscillations in area CA1 are travelling waves that propagate roughly along the septotemporal axis of the hippocampus. Furthermore, we find that spiking in the CA1 pyramidal cell layer is modulated in a consistent travelling wave pattern. Our results demonstrate that theta oscillations pattern hippocampal activity not only in time, but also across anatomical space. The presence of travelling waves indicates that the instantaneous output of the hippocampus is topographically organized and represents a segment, rather than a point, of physical space.},
	language = {eng},
	number = {7246},
	journal = {Nature},
	author = {Lubenov, Evgueniy V and Siapas, Athanassios G},
	year = {2009},
	note = {Place: Division of Biology, Division of Engineering and Applied Science, California Institute of Technology, Pasadena, California 91125, USA. lubenov@caltech.edu},
	keywords = {merged\_fiete.bib},
	pages = {534--539},
}

@article{buzsaki_theta_2002,
	title = {Theta oscillations in the hippocampus},
	volume = {33},
	abstract = {Theta oscillations represent the {\textbackslash}textbackslashtt“on-line{\textbackslash}textbackslashtt” state of the hippocampus. The extracellular currents underlying theta waves are generated mainly by the entorhinal input, CA3 (Schaffer) collaterals, and voltage-dependent Ca(2+) currents in pyramidal cell dendrites. The rhythm is believed to be critical for temporal coding/decoding of active neuronal ensembles and the modification of synaptic weights. Nevertheless, numerous critical issues regarding both the generation of theta oscillations and their functional significance remain challenges for future research.},
	language = {eng},
	number = {3},
	journal = {Neuron},
	author = {Buzsaki, Gyorgy},
	year = {2002},
	note = {Place: Center for Molecular and Behavioral Neuroscience, Rutgers, The State University of New Jersey and Neurological Institute of New Jersey, Newark, NJ 07102, USA. buzsaki@axon.rutgers.edu},
	keywords = {Humans, Animals, merged\_fiete.bib, Action Potentials/physiology, Neurological, Hippocampus/cytology/*physiology, Models, *Theta Rhythm, Neuronal Plasticity/physiology, Receptors, Biological Clocks/physiology, Cholinergic/metabolism, Dentate Gyrus/physiology, GABA-A/metabolism, N-Methyl-D-Aspartate/metabolism},
	pages = {325--340},
}

@article{klam_population_2008,
	title = {Population coding with motion energy filters: the impact of correlations},
	volume = {20},
	abstract = {The codes obtained from the responses of large populations of neurons are known as population codes. Several studies have shown that the amount of information conveyed by such codes, and the format of this information, is highly dependent on the pattern of correlations. However, very little is known about the impact of response correlations (as found in actual cortical circuits) on neural coding. To address this problem, we investigated the properties of population codes obtained from motion energy filters, which provide one of the best models for motion selectivity in early visual areas. It is therefore likely that the correlations that arise among energy filters also arise among motion-selective neurons. We adopted an ideal observer approach to analyze filter responses to three sets of images: noisy sine gratings, random dots kinematograms, and images of natural scenes. We report that in our model, the structure of the population code varies with the type of image. We also show that for all sets of images, correlations convey a large fraction of the information: 40\% to 90\% of the total information. Moreover, ignoring those correlations when decoding leads to considerable information loss-from 50\% to 93\%, depending on the image type. Finally we show that it is important to consider a large population of motion energy filters in order to see the impact of correlations. Study of pairs of neurons, as is often done experimentally, can underestimate the effect of correlations.},
	language = {eng},
	number = {1},
	journal = {Neural Comput.},
	author = {Klam, F and Zemel, R S and Pouget, A},
	year = {2008},
	note = {Place: Vision Center Laboratory, Salk Institute, La Jolla, CA 92037, USA. fklam@salk.edu},
	keywords = {Algorithms, Pattern Recognition, Humans, Animals, Computer Simulation, merged\_fiete.bib, Neurons/*physiology, Nerve Net/*physiology, Synaptic Transmission/physiology, Motion Perception/*physiology, Visual Cortex/*physiology, Photic Stimulation, Action Potentials/*physiology, *Neural Networks (Computer), Visual/physiology, Fourier Analysis},
	pages = {146--175},
}

@article{nishikawa_population_2008,
	title = {Population coding of song element sequence in the {Bengalese} finch {HVC}},
	volume = {27},
	abstract = {Birdsong is a complex vocalization composed of various song elements organized according to sequential rules. Two alternative views exist that explain the neural representation of song element sequences in the songbird brain. The finding of sequential selective neurons supports the idea that the song element sequence is encoded in a chain of rigid selective neurons. Alternatively, song structure could be encoded in an ensemble of relatively broad selective neurons arranged in a distributed manner. Here we attempted to determine which neural representation actually occurs in the song system by recording neural responses to various stimuli and performing information-theoretic analysis on the data obtained. We recorded the neural responses to all possible element pairs of stimuli in the Bengalese finch brain nucleus high vocal centre (HVC). Our results showed that each neuron has broad but differential response properties to element sequences beyond the structure of self-generated song. To quantify the transmitted information by such a broadly tuned neural population, we calculated the time course of mutual information between auditory stimuli and neural activities. Confounded information, which represents the relationship between present and previous elements, increased significantly immediately after stimulus presentation. These results indicate that the song element sequence is encoded in a neural ensemble in the HVC via population coding. These findings give us a new encoding scheme for the song element sequence using a distributed neural representation rather than the chain model of rigid selective neurons.},
	language = {eng},
	number = {12},
	journal = {Eur. J. Neurosci.},
	author = {Nishikawa, Jun and Okada, Masato and Okanoya, Kazuo},
	year = {2008},
	note = {Place: RIKEN Brain Science Institute, 2-1 Hirosawa, Wako, Saitama 351-0198, Japan.},
	keywords = {Animals, Male, merged\_fiete.bib, *Models, Action Potentials/physiology, Neurological, Neurons/*physiology, Animal/*physiology, Auditory Perception/*physiology, Vocalization, Acoustic Stimulation, Finches/*physiology, High Vocal Center/cytology/*physiology},
	pages = {3273--3283},
}

@article{georgopoulos_primate_1988,
	title = {Primate motor cortex and free arm movements to visual targets in three-dimensional space. {II}. {Coding} of the direction of movement by a neuronal population},
	volume = {8},
	abstract = {We describe a code by which a population of motor cortical neurons could determine uniquely the direction of reaching movements in three-dimensional space. The population consisted of 475 directionally tuned cells whose functional properties are described in the preceding paper (Schwartz et al., 1988). Each cell discharged at the highest rate with movements in its “preferred direction” and at progressively lower rates with movements in directions away from the preferred one. The neuronal population code assumes that for a particular movement direction each cell makes a vectorial contribution (“votes”) with direction in the cell's preferred direction and magnitude proportional to the change in the cell's discharge rate associated with the particular direction of movement. The vector sum of these contributions is the outcome of the population code (the “neuronal population vector”) and points in the direction of movement in space well before the movement begins.},
	language = {eng},
	number = {8},
	journal = {J. Neurosci.},
	author = {Georgopoulos, A P and Kettner, R E and Schwartz, A B},
	year = {1988},
	note = {Place: Philip Bard Laboratories of Neurophysiology, Department of Neuroscience, Johns Hopkins University, School of Medicine, Baltimore, Maryland 21205.},
	keywords = {Animals, Movement, merged\_fiete.bib, Neurological, Neurons/*physiology, Models, Psychomotor Performance/*physiology, Arm, Macaca mulatta/*physiology, Macaca/*physiology, Motor Cortex/cytology/*physiology},
	pages = {2928--2937},
}

@article{averbeck_poisson_2009,
	title = {Poisson or not {Poisson}: differences in spike train statistics between parietal cortical areas},
	volume = {62},
	abstract = {The variability of neuronal responses is proportional to the mean in many brain areas, which suggests that neural responses might follow a Poisson distribution. In this issue of Neuron, Maimon and Assad document a surprising violation of Poisson firing. Specifically, they show that there are differences in the amount of periodic structure in spike trains across cortical areas, with multimodal sensory areas being more regular than visual areas.},
	language = {eng},
	number = {3},
	journal = {Neuron},
	author = {Averbeck, Bruno B},
	year = {2009},
	note = {Place: Sobell Department of Motor Neuroscience and Movement Disorders, Institute of Neurology, University College London, London, UK. b.averbeck@ion.ucl.ac.uk},
	keywords = {Humans, Animals, merged\_fiete.bib, Brain Mapping/*methods, Neurons/*physiology, Models, Action Potentials/*physiology, Biological, Poisson Distribution, Parietal Lobe/cytology/*physiology},
	pages = {310--311},
}

@article{franks_independent_2003,
	title = {Independent sources of quantal variability at single glutamatergic synapses},
	volume = {23},
	abstract = {Variability in the size of single postsynaptic responses is a feature of most central neurons, although the source of this variability is not completely understood. The dominant source of variability could be either intersynaptic or intrasynaptic. To quantitatively examine this question, a biophysically realistic model of an idealized central axospinous synapse was used to assess mechanisms underlying synaptic variability measurements. Three independent sources of variability were considered: stochasticity of postsynaptic receptors (“channel noise”), variations of glutamate concentration in the synaptic cleft (Deltaq), and differences in the potency of vesicles released from different locations on the active zone [release-location dependence (RLD)]. As expected, channel noise was small (8\% of the total variance) and Deltaq was the dominant source of variability (58\% of total variance). Surprisingly, RLD accounted for a significant amount of variability (36\%). Our simulations show that potency of release sites decreased with a length constant of approximately 100 nm, and that receptors were not activated by release events {\textgreater}300 nm away, which is consistent with the observation that single active zones are rarely {\textgreater}300 nm. RLD also predicts that the manner in which receptors are added or removed from synapses can dramatically affect the nature of the synaptic response, with increasing receptor density being more efficient than merely increasing synaptic area. Saturation levels and synaptic geometry were also important in determining the size and shape of the distribution of amplitudes recorded at different synapses.},
	language = {eng},
	number = {8},
	journal = {J. Neurosci.},
	author = {Franks, Kevin M and Stevens, Charles F and Sejnowski, Terrence J},
	year = {2003},
	note = {Place: Howard Hughes Medical Institute, La Jolla, California 92037, USA.},
	keywords = {Computer Simulation, Reproducibility of Results, merged\_fiete.bib, *Models, Neurological, Synaptic Transmission/*physiology, Receptors, Stochastic Processes, N-Methyl-D-Aspartate/metabolism, *Monte Carlo Method, AMPA/metabolism, Biophysics/methods, Excitatory Postsynaptic Potentials/physiology, Glutamic Acid/*metabolism, Particle Size, Synapses/metabolism/*physiology, Synaptic Vesicles/metabolism},
	pages = {3186--3195},
}

@article{bennett_statistics_2000,
	title = {Statistics of transmitter release at nerve terminals},
	volume = {60},
	abstract = {This review presents an historical account of the developments of the statistical analysis of quantal transmission over the past half century and of the progress made in using this approach to reveal new properties of nerve terminals. In the early 1950s, Katz and his colleagues showed that evoked transmitter release occurred in quanta at the neuromuscular junction, opening up the study of transmitter release at nerve terminals to statistical analysis. In the subsequent two decades attempts were made to see if evoked quantal release could be described by binomial or compound binomial statistics, as originally suggested by Katz, and to relate the parameters of the statistic to various structures of the nerve terminal. During this period two hypotheses were enunciated, namely the 'vesicle hypothesis', which states that quanta arise as a consequence of the packaging of transmitter in vesicles; and the 'active zone hypothesis', which states that vesicles undergo exocytosis at discrete sites on the nerve terminal. Unsuccessful attempts were made to relate the binomial parameter n to the elements in these hypotheses, that is to the number of active zones possessed by the terminal or the number of vesicles available for release at these zones. This difficulty was part resolved in the late 1970s with the application of non-uniform binomial statistics to transmitter release from nerve terminals, in which n is the number of active zones each with their individual probabilities, p(j). Autocorrelation functions were subsequently introduced to detect if transmitter release is quantised at a particular nerve terminal. Statistical methods which would allow discrimination between different models of transmitter release over the active zones of a terminal were then developed. The introduction of maximum likelihood estimation procedures then allowed estimates to be made of the parameters in the statistical models of quantal release. The application of these procedures to experimental data from a variety of nerve terminals provided evidence for the concept that each synapse, taken as possessing a single active zone, possesses its own individual probability of secretion of a quantum by the exocytosis of a vesicle. In the late 1960s Stevens introduced the first stochastic approach to the analysis of the kinetics of the release of a quantum of transmitter at the neuromuscular junction following an impulse. In the subsequent decades this was developed into an explicit theory for the interaction of proteins involved in regulated exocytosis of a vesicle at an active zone. The parameters were the number of transition steps in the release process (k), each occurring at the same rate (alpha), with the possibility of each of these steps becoming blocked at the same rate (gamma). Maximum likelihood estimation procedures could then be used to obtain these parameter values. The discovery was made in the 1990s of the core proteins of the SNARE complex that govern regulated exocytosis. This offers the possibility in the near future of identifying the kinetic interaction of these proteins with the parameters of the stochastic process of exocytosis which confer a particular probability on individual synapses.},
	language = {eng},
	number = {6},
	journal = {Prog. Neurobiol.},
	author = {Bennett, M R and Kearns, J L},
	year = {2000},
	note = {Place: Department of Physiology, Institute for Biomedical Research, University of Sydney, NSW, Australia. maxb@physiol.usyd.edu.au},
	keywords = {Animals, merged\_fiete.bib, *Models, Neurological, Likelihood Functions, Kinetics, Nerve Endings/*metabolism, Neuromuscular Junction/metabolism, Neurotransmitter Agents/*metabolism},
	pages = {545--606},
}

@article{barrett_quantal_1972,
	title = {Quantal independence and uniformity of presynaptic release kinetics at the frog neuromuscular junction},
	volume = {227},
	abstract = {1. Amplitude and latency fluctuations of the end-plate potential at the frog neuromuscular junction were studied simultaneously at low temperatures, using intracellular or focal extracellular recording techniques and average quantal contents between 0.5 and 3.2. At the release rates studied, the evoked release of one quantum has in most cases no significant effect on the probability of subsequent quantal release to the same stimulus, confirming the mutual independence of quantal releases in this preparation.3. An equation derived from Poisson's law was applied to a histogram of the latencies of the first quantum released on each of a series of trials, to predict the average quantal content of end-plate responses originating at various times after nerve stimulation. The shape of the predicted time distribution of quantal contents usually agreed closely with that of the experimentally observed time distribution of end-plate response amplitudes. This agreement demonstrates that both the amplitude and the latency fluctuations of the end-plate response result from one presynaptic stochastic process that is uniform in magnitude and time course after each stimulus.4. Analysis of extracellular records from synaptic regions with a history of extensive activity often suggested the existence of depressive interaction among quantal releases, perhaps caused by depletion of the supply of releasable quanta.},
	language = {eng},
	number = {3},
	journal = {J. Physiol.},
	author = {Barrett, E F and Stevens, C F},
	year = {1972},
	keywords = {Animals, Time Factors, merged\_fiete.bib, Electrophysiology, Electric Stimulation, Anura, Cold Temperature, Neuromuscular Junction/*physiology, Neurotransmitter Agents/secretion, Probability, Rana pipiens, Secretory Rate, Synapses/*secretion},
	pages = {665--689},
}

@article{han_multiple-color_2007,
	title = {Multiple-color optical activation, silencing, and desynchronization of neural activity, with single-spike temporal resolution},
	volume = {2},
	abstract = {The quest to determine how precise neural activity patterns mediate computation, behavior, and pathology would be greatly aided by a set of tools for reliably activating and inactivating genetically targeted neurons, in a temporally precise and rapidly reversible fashion. Having earlier adapted a light-activated cation channel, channelrhodopsin-2 (ChR2), for allowing neurons to be stimulated by blue light, we searched for a complementary tool that would enable optical neuronal inhibition, driven by light of a second color. Here we report that targeting the codon-optimized form of the light-driven chloride pump halorhodopsin from the archaebacterium Natronomas pharaonis (hereafter abbreviated Halo) to genetically-specified neurons enables them to be silenced reliably, and reversibly, by millisecond-timescale pulses of yellow light. We show that trains of yellow and blue light pulses can drive high-fidelity sequences of hyperpolarizations and depolarizations in neurons simultaneously expressing yellow light-driven Halo and blue light-driven ChR2, allowing for the first time manipulations of neural synchrony without perturbation of other parameters such as spiking rates. The Halo/ChR2 system thus constitutes a powerful toolbox for multichannel photoinhibition and photostimulation of virally or transgenically targeted neural circuits without need for exogenous chemicals, enabling systematic analysis and engineering of the brain, and quantitative bioengineering of excitable cells.},
	language = {eng},
	number = {3},
	journal = {PLoS One},
	author = {Han, Xue and Boyden, Edward S},
	year = {2007},
	note = {Place: Stanford University School of Medicine, Stanford, California, United States of America.},
	keywords = {merged\_fiete.bib},
	pages = {e299},
}

@article{hausser_neuroscience_2007,
	title = {Neuroscience: controlling neural circuits with light},
	volume = {446},
	language = {eng},
	number = {7136},
	journal = {Nature},
	author = {Hausser, Michael and Smith, Spencer L},
	year = {2007},
	keywords = {Humans, Animals, merged\_fiete.bib, *Light, Action Potentials/physiology/radiation effects, Caenorhabditis elegans/cytology/physiology/radiation effects, Calcium/analysis/metabolism, Halorhodopsins/genetics/*metabolism, Nerve Net/physiology/radiation effects, Neural Pathways/*physiology/*radiation effects, Neurons/physiology/radiation effects, Rhodopsin/genetics/*metabolism},
	pages = {617--619},
}

@article{arenkiel_vivo_2007,
	title = {In vivo light-induced activation of neural circuitry in transgenic mice expressing channelrhodopsin-2},
	volume = {54},
	abstract = {Channelrhodopsin-2 (ChR2) is a light-gated, cation-selective ion channel isolated from the green algae Chlamydomonas reinhardtii. Here, we report the generation of transgenic mice that express a ChR2-YFP fusion protein in the CNS for in vivo activation and mapping of neural circuits. Using focal illumination of the cerebral cortex and olfactory bulb, we demonstrate a highly reproducible, light-dependent activation of neurons and precise control of firing frequency in vivo. To test the feasibility of mapping neural circuits, we exploited the circuitry formed between the olfactory bulb and the piriform cortex in anesthetized mice. In the olfactory bulb, individual mitral cells fired action potentials in response to light, and their firing rate was not influenced by costimulated glomeruli. However, in piriform cortex, the activity of target neurons increased as larger areas of the bulb were illuminated to recruit additional glomeruli. These results support a model of olfactory processing that is dependent upon mitral cell convergence and integration onto cortical cells. More broadly, these findings demonstrate a system for precise manipulation of neural activity in the intact mammalian brain with light and illustrate the use of ChR2 mice in exploring functional connectivity of complex neural circuits in vivo.},
	language = {eng},
	number = {2},
	journal = {Neuron},
	author = {Arenkiel, Benjamin R and Peca, Joao and Davison, Ian G and Feliciano, Catia and Deisseroth, Karl and Augustine, George J and Ehlers, Michael D and Feng, Guoping},
	year = {2007},
	note = {Place: Howard Hughes Medical Institute, Duke University Medical Center, Durham, NC 27710, USA.},
	keywords = {Animals, Cell Count, Immunohistochemistry, merged\_fiete.bib, Electrophysiology, Neurons/physiology, Photic Stimulation, Mice, Light, Olfactory Bulb/physiology, Transgenic, Microscopy, Cerebral Cortex/cytology/physiology, Confocal, Ion Channels/*biosynthesis/*genetics, Luminescent Proteins/biosynthesis, Neural Pathways/cytology/*metabolism/*radiation effects, Promoter Regions (Genetics)/genetics},
	pages = {205--218},
}

@article{alonso_neuronal_1987,
	title = {Neuronal sources of theta rhythm in the entorhinal cortex of the rat. {II}. {Phase} relations between unit discharges and theta field potentials},
	volume = {67},
	abstract = {The discharge patterns and layer distribution of entorhinal cortex (EC) units were investigated in paralysed and locally anesthetized rats injected with physostigmine in order to induce theta (theta) rhythm. Entorhinal unit activity and field potentials were recorded simultaneously with the same micropipette. Hippocampal CA1 theta rhythm was used as reference. Statistical analysis included auto- and cross-correlations and interval histograms. Results showed: a. the existence of rhythmic and non-rhythmic cells, both tending to fire in a constant phase relationship with theta rhythm; b. in all EC subdivisions, most rhythmic cells were located in superficial cell layers (II-III); c. on the average, rhythmic cells from the medial EC fired synchronously; d. non-rhythmic cells tended also to fire synchronously but with an opposite phase relationship with respect to rhythmic neurons. Although a complex organization in the rhythmicity of EC units is revealed, it is concluded that the neuronal sources of theta activity in the EC are located in superficial cell layers, and it is strongly suggested that the EC output through the perforant path may rhythmically modulate the discharge pattern of hippocampal pyramidal and dentate granule cells.},
	language = {eng},
	number = {3},
	journal = {Exp. Brain Res.},
	author = {Alonso, A and Garcia-Austt, E},
	year = {1987},
	note = {Place: Departamento de Investigacion, Hospital Ramon y Cajal, Madrid, Spain.},
	keywords = {Animals, Action Potentials, Rats, Male, merged\_fiete.bib, Neurons/*physiology, *Theta Rhythm, *Electroencephalography, Inbred Strains, Limbic System/cytology/*physiology},
	pages = {502--509},
}

@article{alonso_differential_1993,
	title = {Differential electroresponsiveness of stellate and pyramidal-like cells of medial entorhinal cortex layer {II}},
	volume = {70},
	abstract = {1. The electroresponsive properties of neurons from layer II of the rat medial entorhinal cortex (MEC) were studied by intracellular recording under current clamp in an in vitro brain slice preparation. From a total of 184 cells that fulfilled our criteria for recording stability, two groups of projection neurons were distinguished on the basis of their intrinsic biophysical properties and morphological characteristics (demonstrated by intracellular biocytin injection; n = 34). 2. Stellate cells (SCs) were the most abundant (69\%). They were highly electroresponsive, and minimal changes (1-3 mV) of membrane potential generated an active response. Subthreshold depolarizing or hyperpolarizing current pulse injection always caused the membrane potential to attain an early peak and then sag to a lower level. Depolarization-induced “sags” were larger and determined early firing in all cells. The voltage-current relationship of SCs was markedly non-linear, demonstrating robust inward rectification in the hyperpolarizing and depolarizing range. 3. SCs generated persistent rhythmic subthreshold voltage oscillations on DC depolarization positive to -60 mV. The mean frequency of the oscillations was 8.6 Hz (theta range) at a membrane potential of approximately -55 mV, at which level occasional single spiking also occurred. At slightly more positive potentials, a striking 1- to 3-Hz repetitive bursting pattern emerged. This consisted of nonadapting trains of spikes (“clusters”) interspersed with subthreshold oscillations that had a mean frequency of 21.7 Hz (beta range). 4. Nonstellate cells (39\%; mostly pyramidal-like) displayed time-dependent inward rectification that was less pronounced than that of SCs, and minimal depolarization-induced sags. On threshold depolarization, firing was always preceded by a slowly rising ramp depolarization and thus occurred with a long delay. Inward rectification in the depolarizing range was very pronounced. However, non-SCs did not generate persistent rhythmic subthreshold oscillatory activity or spike clusters. 5. Of the electrophysiological parameters quantified, spike threshold, spike duration, depolarizing afterpotential amplitude and apparent membrane time constant demonstrated statistically significant differences between SCs and non-SCs. 6. The repetitive hiring properties in response to square current pulses of short duration ({\textless} 500 ms) were also different between SCs and non-SCs. First, most SCs displayed a bilinear frequency-current (f-I) relationship for only the first interspike interval, whereas most non-SCs displayed a bilinear relationship for all intervals. Second, SCs had a much steeper primary f-I slope for early intervals than non-SCs. Finally, SCs displayed more pronounced and faster spike frequency adaptation than non-SCs.(ABSTRACT TRUNCATED AT 400 WORDS)},
	language = {eng},
	number = {1},
	journal = {J. Neurophysiol.},
	author = {Alonso, A and Klink, R},
	year = {1993},
	note = {Place: Department of Neurology and Neurosurgery, McGill University, Montreal, Quebec, Canada.},
	keywords = {Animals, Rats, Male, merged\_fiete.bib, Hippocampus/*physiology, Interneurons/*physiology, Wistar, Neurons/physiology, Cerebral Cortex/*physiology, Synapses/physiology, Synaptic Transmission/*physiology, Sensory Thresholds/physiology, Evoked Potentials/physiology, Electric Stimulation, Membrane Potentials/physiology, Afferent Pathways/physiology, Culture Techniques, Limbic System/*physiology},
	pages = {128--143},
}

@article{alonso_subthreshold_1989,
	title = {Subthreshold {Na}⁺-dependent theta-like rhythmicity in stellate cells of entorhinal cortex layer {II}.},
	volume = {342},
	abstract = {The oscillation of membrane potential in mammalian central neurons is of interest because it relates to the role of oscillations in brain function. It has been proposed that the entorhinal cortex (EC), particularly the stellate cells of layer II (ECIIscs), plays an important part in the genesis of the theta rhythm. These neurons occupy a key position in the neocortex-hippocampus-neocortex circuit, a crucial crossroad in memory functions. Neuronal oscillations typically rely on the activation of voltage-dependent Ca2+ conductances and the Ca2+ -dependent K+ conductance that usually follows, as seen in other limbic subcortical structures generating theta rhythmicity. Here we report, however, that similar oscillations are generated in ECIIscs by a Na+ conductance. The finding of a subthreshold, voltage-gated, Na+ -dependent rhythmic membrane oscillation in mammalian neurons indicates that rhythmicity in heterogeneous neuronal networks may be supported by different sets of intrinsic ionic mechanisms in each of the neuronal elements involved.},
	language = {eng},
	number = {6246},
	journal = {Nature},
	author = {Alonso, A and Llinas, R R},
	year = {1989},
	note = {Place: Department of Physiology and Biophysics, New York University Medical Center, New York 10016.},
	keywords = {merged\_fiete.bib},
	pages = {175--177},
}

@article{alyan_hippocampectomized_1999,
	title = {Hippocampectomized rats are capable of homing by path integration},
	volume = {113},
	abstract = {Navigation in rodents is mediated by at least 3 mechanisms: guidance, path integration, and landmark learning. The hippocampus is necessary for spatial learning based on distal landmarks, and it has been suggested that the hippocampal formation performs a form of path integration in updating place cell firing; however, the necessity of the hippocampus for path integration has not been clearly established. Rats with extensive neurotoxin lesions of the hippocampus and control rats were trained on 2 tasks in which they were required to move in total darkness from one location to another and then return to the start point. Hippocampal and control rats both used path integration in solving these tasks and did not differ in terms of the distributions of their arrival points on the return paths. We conclude that neuronal circuits sufficient for computing a homing vector using path integration are located outside the hippocampus.},
	language = {eng},
	number = {1},
	journal = {Behav. Neurosci.},
	author = {Alyan, S and McNaughton, B L},
	year = {1999},
	note = {Place: Department of Psychology, University of Arizona, Tucson 85724, USA.},
	keywords = {Animals, Rats, Male, merged\_fiete.bib, Hippocampus/*physiology, Orientation/*physiology, Brain Mapping, Inbred F344, Mental Recall/*physiology, Problem Solving/*physiology, Homing Behavior/*physiology, Inbred BN},
	pages = {19--31},
}

@article{anderson_heterogeneous_2003,
	title = {Heterogeneous modulation of place cell firing by changes in context},
	volume = {23},
	abstract = {Hippocampal place cells show spatially localized activity that can be modulated by both geometric information (e.g., the distances and directions of features in the environment) and nongeometric information (e.g., colors, odors, and possibly behaviors). Nongeometric information may allow the discrimination of different spatial contexts. Understanding how nongeometric (or contextual) information affects hippocampal activity is important in light of proposals that the hippocampus may play a role in constructing a representation of spatial context. We investigated the contextual modulation of place cell activity by recording hippocampal place cells while rats foraged in compound contexts comprising black or white color paired with lemon or vanilla odor. Some cells responded to the color or odor changes alone, but most responded to varying combinations of both. Thus, we demonstrate, for the first time, that there is a heterogeneous input by contextual inputs into the hippocampus. We propose a model of contextual remapping of place cells in which the geometric inputs are selectively activated by subsets of contextual stimuli. Because it appears that different place cells are affected by different subsets of contextual stimuli, the representation of the entire context would require activity at the population level, supporting a role for the hippocampus in constructing a representation of spatial context.},
	language = {eng},
	number = {26},
	journal = {J. Neurosci.},
	author = {Anderson, Michael I and Jeffery, Kathryn J},
	year = {2003},
	note = {Place: Department of Psychology, University College London, London, WC1H OAP, United Kingdom.},
	keywords = {merged\_fiete.bib},
	pages = {8827--8835},
}

@article{barry_experience-dependent_2007,
	title = {Experience-dependent rescaling of entorhinal grids},
	volume = {10},
	abstract = {The firing pattern of entorhinal 'grid cells' is thought to provide an intrinsic metric for space. We report a strong experience-dependent environmental influence: the spatial scales of the grids (which are aligned and have fixed relative sizes within each animal) vary parametrically with changes to a familiar environment's size and shape. Thus grid scale reflects an interaction between intrinsic, path-integrative calculation of location and learned associations to the external environment.},
	language = {eng},
	number = {6},
	journal = {Nat. Neurosci.},
	author = {Barry, Caswell and Hayman, Robin and Burgess, Neil and Jeffery, Kathryn J},
	year = {2007},
	note = {Place: Institute of Cognitive Neuroscience, University College London, 17 Queen Square, London WC1N 3AR, UK.},
	keywords = {merged\_fiete.bib},
	pages = {682--684},
}

@article{blair_conversion_2008,
	title = {Conversion of a phase-coded to rate-coded position signal by a three-stage model of theta cells, grid cells, and place cells},
	volume = {18},
	number = {12},
	journal = {Hippocampus},
	author = {Blair, H T and Kishan, G and Zhang, K},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {XXX--XXX},
}

@article{broadbent_spatial_2004,
	title = {Spatial memory, recognition memory, and the hippocampus},
	volume = {101},
	abstract = {There is wide agreement that spatial memory is dependent on the integrity of the hippocampus, but the importance of the hippocampus for nonspatial tasks, including tasks of object recognition memory is not as clear. We examined the relationship between hippocampal lesion size and both spatial memory and object recognition memory in rats. Spatial memory was impaired after bilateral dorsal hippocampal lesions that encompassed 30-50\% total volume, and as lesion size increased from 50\% to approximately 100\% of total hippocampal volume, performance was similarly impaired. In contrast, object recognition was intact after dorsal hippocampal lesions that damaged 50-75\% of total hippocampal volume and was impaired only after larger lesions that encompassed 75-100\% of hippocampal volume. Last, ventral hippocampal lesions that encompassed approximately 50\% of total hippocampal volume impaired spatial memory but did not affect object recognition memory. These findings show that the hippocampus is important for both spatial memory and recognition memory. However, spatial memory performance requires more hippocampal tissue than does recognition memory.},
	language = {eng},
	number = {40},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Broadbent, Nicola J and Squire, Larry R and Clark, Robert E},
	year = {2004},
	note = {Place: Veterans Affairs Medical Center, San Diego, CA 92161, USA.},
	keywords = {merged\_fiete.bib, hippocampus non-spatial},
	pages = {14515--14520},
}

@article{brooks_visual_1985,
	title = {Visual map making for a mobile robot},
	journal = {IEEE Int. Conf. Robot. Autom.},
	author = {Brooks, R A},
	year = {1985},
	note = {Place: St. Louis
Publisher: IEEE},
	keywords = {merged\_fiete.bib},
	pages = {824--829},
}

@article{brown_concordant_2002,
	title = {Concordant and discordant coding of spatial location in populations of hippocampal {CA1} pyramidal cells},
	volume = {88},
	abstract = {Pyramidal cells in the rat hippocampus commonly show place-related activity, but it has been difficult to understand the factors that govern them. A particularly important question is whether individual cells have identifiable correlates that can be manipulated independently of the correlates of other cells. Recently Tanila et al. examined the activity of small ensembles of hippocampal cells in rats running on a plus-maze with distinct intra- and extramaze cues. When the two sets of cues were rotated 90 degrees in opposite directions, some cells followed the intramaze cues, others followed the extramaze cues, and others “remapped” unpredictably; moreover, all possible combinations were seen within simultaneously recorded ensembles. In the current study, CA1 pyramidal cell population activity was recorded from four rats in a similar paradigm, using a recording system that permitted the analysis of ensembles of 4-70 simultaneously recorded units. The results were consistent with the data from the earlier study in showing an increase in remapping over time and in showing some place fields following one of the defined sets of cues while others remapped. When the possibility of random remapping was controlled for, however, the analysis did not show significant numbers of place fields following both sets of cues simultaneously. Furthermore, all rats initially showed fully concordant responses with all place fields following the local cues. For two rats, this pattern continued until a new configuration was introduced at which time all fields switched to follow the distal cues. Taken together, the results are difficult to reconcile with the hypothesis that individual hippocampal cells encode information about different subsets of cues in the environment.},
	language = {eng},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Brown, Joel E and Skaggs, William E},
	year = {2002},
	note = {Place: Department of Neuroscience and Center for the Neural Basis of Cognition, University of Pittsburgh, Pittsburgh, Pennsylvania 15260, USA.},
	keywords = {merged\_fiete.bib},
	pages = {1605--1613},
}

@article{brun_place_2002,
	title = {Place cells and place recognition maintained by direct entorhinal-hippocampal circuitry},
	volume = {296},
	abstract = {Place cells in hippocampal area CA1 may receive positional information from the intrahippocampal associative network in area CA3 or directly from the entorhinal cortex. To determine whether direct entorhinal connections support spatial firing and spatial memory, we removed all input from areas CA3 to CA1, thus isolating the CA1 area. Pyramidal cells in the isolated CA1 area developed sharp and stable place fields. Rats with an isolated CA1 area showed normal acquisition of an associative hippocampal-dependent spatial recognition task. Spatial recall was impaired. These results suggest that the hippocampus contains two functionally separable memory circuits: The direct entorhinal-CA1 system is sufficient for recollection-based recognition memory, but recall depends on intact CA3-CA1 connectivity.},
	language = {eng},
	number = {5576},
	journal = {Science},
	author = {Brun, Vegard H and Otnass, Mona K and Molden, Sturla and Steffenach, Hill-Aina and Witter, Menno P and Moser, May-Britt and Moser, Edvard I},
	year = {2002},
	note = {Place: Neuroscience Unit, Medical-Technical Research Centre, Norwegian University of Science and Technology, 7489 Trondheim, Norway.},
	keywords = {merged\_fiete.bib},
	pages = {2243--2246},
}

@article{burgess_oscillatory_2007,
	title = {An oscillatory interference model of grid cell firing},
	volume = {17},
	abstract = {We expand upon our proposal that the oscillatory interference mechanism proposed for the phase precession effect in place cells underlies the grid-like firing pattern of dorsomedial entorhinal grid cells (O'Keefe and Burgess (2005) Hippocampus 15:853-866). The original one-dimensional interference model is generalized to an appropriate two-dimensional mechanism. Specifically, dendritic subunits of layer II medial entorhinal stellate cells provide multiple linear interference patterns along different directions, with their product determining the firing of the cell. Connection of appropriate speed- and direction-dependent inputs onto dendritic subunits could result from an unsupervised learning rule which maximizes postsynaptic firing (e.g. competitive learning). These inputs cause the intrinsic oscillation of subunit membrane potential to increase above theta frequency by an amount proportional to the animal's speed of running in the “preferred” direction. The phase difference between this oscillation and a somatic input at theta-frequency essentially integrates velocity so that the interference of the two oscillations reflects distance traveled in the preferred direction. The overall grid pattern is maintained in environmental location by phase reset of the grid cell by place cells receiving sensory input from the environment, and environmental boundaries in particular. We also outline possible variations on the basic model, including the generation of grid-like firing via the interaction of multiple cells rather than via multiple dendritic subunits. Predictions of the interference model are given for the frequency composition of EEG power spectra and temporal autocorrelograms of grid cell firing as functions of the speed and direction of running and the novelty of the environment.},
	language = {eng},
	number = {9},
	journal = {Hippocampus},
	author = {Burgess, Neil and Barry, Caswell and O'Keefe, John},
	year = {2007},
	note = {Place: Institute of Cognitive Neuroscience, University College London, 17 Queen Square, London, United Kingdom. n.burgess@ucl.ac.uk},
	keywords = {Pattern Recognition, Animals, merged\_fiete.bib, *Models, Neurological, Behavior, Photic Stimulation, Animal, *Theta Rhythm, Action Potentials/*physiology, Neurons/cytology/*physiology, Dendrites/physiology, Entorhinal Cortex/cytology, Visual/*physiology},
	pages = {801--812},
}

@article{chrobak_gamma_1998,
	title = {Gamma oscillations in the entorhinal cortex of the freely behaving rat},
	volume = {18},
	abstract = {Gamma frequency field oscillations (40-100 Hz) are nested within theta oscillations in the dentate-hilar and CA1-CA3 regions of the hippocampus during exploratory behaviors. These oscillations reflect synchronized synaptic potentials that entrain the discharge of neuronal populations within the approximately 10-25 msec range. Using multisite recordings in freely behaving rats, we examined gamma oscillations within the superficial layers (I-III) of the entorhinal cortex. These oscillations increased in amplitude and regularity in association with entorhinal theta waves. Gamma waves showed an amplitude minimum and reversed in phase near the perisomatic region of layer II, indicating that they represent synchronized synaptic potentials impinging on layer II-III neurons. Theta and gamma oscillations in the entorhinal cortex were coupled with theta and gamma oscillations in the dentate hilar region. The majority of layer II-III neurons discharged irregularly but were phase-related to the negative peak of the local (layer II-III) gamma field oscillation. These findings demonstrate that layer II-III neurons discharge in temporally defined gamma windows (approximately 10-25 msec) coupled to the theta cycle. This transient temporal framework, which emerges in both the entorhinal cortex and the hippocampus, may allow spatially distributed subpopulations to form temporally defined ensembles. We speculate that the theta-gamma pattern in the discharge of these neurons is essential for effective neuronal communication and synaptic plasticity in the perforant pathway.},
	language = {eng},
	number = {1},
	journal = {J. Neurosci.},
	author = {Chrobak, J J and Buzsaki, G},
	year = {1998},
	note = {Place: Center for Molecular and Behavioral Neuroscience, Rutgers, The State University of New Jersey, Newark, New Jersey 07102, USA.},
	keywords = {merged\_fiete.bib},
	pages = {388--398},
}

@article{cohen_absolute_1983,
	title = {Absolute stability of global pattern-formation and parallel memory storage by competitive neural networks},
	volume = {13},
	journal = {IEEE Trans. Syst. Man Cybern.},
	author = {Cohen, M A and Grossberg, S},
	year = {1983},
	keywords = {merged\_fiete.bib},
	pages = {815--826},
}

@article{della_santina_orientation_2005,
	title = {Orientation of human semicircular canals measured by three-dimensional multiplanar {CT} reconstruction},
	volume = {6},
	abstract = {Analysis of vestibulo-ocular reflex experiments requires knowledge of the absolute orientations (with respect to skull landmarks) of semicircular canals (SCC). Data relating SCC orientations to accessible skull landmarks in humans are sparse, apart from a classic study of 10 skulls, which concluded that the horizontal and anterior SCC are not mutually orthogonal (111 +/- 7.6 degrees). Multiple studies of isolated labyrinths have shown the inter-SCC angles are close to 90 degrees. We hypothesized that a larger sample would yield mean absolute SCC orientations closer to the mutual orthogonality demonstrated for isolated labyrinths. We measured canal orientations with respect to accessible skull landmarks using 3-D multiplanar reconstructions of computerized tomography scans of the temporal bones of 22 human subjects. Images were acquired with 0.5-mm thickness and reconstructed with in-plane resolution of 234 microm. There was no significant difference between the left and a mirror image of the right (p {\textgreater} 0.57 on multiway ANOVA of orientation vector coefficients), so data were pooled for the 44 labyrinths. The angle between the anterior and posterior SCC was 94.0 +/- 4.0 degrees (mean +/- SD). The angle between the anterior and horizontal SCC was 90.6 +/- 6.2 degrees. The angle between the horizontal and posterior SCC was 90.4 +/- 4.9 degrees. The direction angles between a vector normal to the left horizontal SCC and the positive Reid's stereotaxic X (+nasal), Y (+left), and Z (+superior) axes were 108.7 +/- 7.5 degrees, 92.2 +/- 5.7 degrees, and 19.9 +/- 7.0 degrees, respectively. The angles between a vector normal to the left anterior SCC and the positive Reid's stereotaxic X, Y, and Z axes were 125.9 +/- 5.2 degrees, 38.4 +/- 5.1 degrees, and 100.1 +/- 6.2 degrees, respectively. The angles between a vector normal to the left posterior SCC and the positive Reid's stereotaxic X, Y, and Z axes were 133.6 +/- 5.3 degrees, 131.5 +/- 5.1 degrees, and 105.6 +/- 6.6 degrees, respectively. The mean anterior SCC-contralateral posterior SCC angle was 15.3 +/- 7.2 degrees. The absolute orientations of human SCC are more nearly orthogonal than previously reported.},
	language = {eng},
	number = {3},
	journal = {J. Assoc. Res. Otolaryngol.},
	author = {Della Santina, Charles C and Potyagaylo, Valeria and Migliaccio, Americo A and Minor, Lloyd B and Carey, John P},
	year = {2005},
	note = {Place: Department of Otolaryngology-Head \& Neck Surgery, Johns Hopkins School of Medicine, 601 North Caroline Street, Rm. JHOC 6253, Baltimore, MD 21287, USA. charley.dellasantina@jhu.edu},
	keywords = {Humans, Male, Adult, Female, Middle Aged, merged\_fiete.bib, Orientation/physiology, Computer-Assisted, Reflex, *Image Processing, Semicircular Canals/*anatomy \& histology/physiology/*radiography, Tomography, Vestibulo-Ocular/physiology, X-Ray Computed/*methods},
	pages = {191--206},
}

@article{dickson_evidence_2000,
	title = {Evidence for spatial modules mediated by temporal synchronization of carbachol-induced gamma rhythm in medial entorhinal cortex},
	volume = {20},
	abstract = {Fast (gamma) oscillations in the cortex underlie the rapid temporal coordination of large-scale neuronal assemblies in the processing of sensory stimuli. Cortical gamma rhythm is modulated in vivo by cholinergic innervation from the basal forebrain and can be generated in vitro after exogenous cholinergic stimulation. Using the isolated guinea pig brain, an in vitro preparation that allows for the study of an intact cerebrum, we studied the spatial features of gamma activity evoked by the cholinomimetic carbachol (CCh) in the medial entorhinal cortex (mEC). gamma activity induced by either arterial perfusion or intraparenchymal application of CCh showed a phase reversal across mEC layer II and was reduced or abolished in a spatially localized region by focal infusions of atropine, bicuculline, and CNQX. In addition, a spatially restricted zone of gamma activity could be induced by passive diffusion of CCh from a recording pipette. Finally, gamma oscillations recorded at multiple sites across the surface of the mEC using array electrodes during arterial perfusion of CCh demonstrated a decline in synchronization (coherence) as the interelectrode distance increased. This effect was independent of the signal amplitude and was specific for gamma as opposed to theta-like activity induced by CCh in the same experiments. These results suggest that CCh-induced gamma oscillations in the mEC are mediated through direct muscarinic excitation of a highly localized reciprocal inhibitory-excitatory network located in superficial layers. We propose that functional cortical modules of highly synchronous gamma oscillations may organize incoming (cortical) and outgoing (hippocampal) information in the mEC.},
	language = {eng},
	number = {20},
	journal = {J. Neurosci.},
	author = {Dickson, C T and Biella, G and de Curtis, M},
	year = {2000},
	note = {Place: Department of Experimental Neurophysiology, Istituto Nazionale Neurologico “Carlo Besta”, Milan 20133, Italy.},
	keywords = {merged\_fiete.bib},
	pages = {7846--7854},
}

@article{dombeck_imaging_2007,
	title = {Imaging large-scale neural activity with cellular resolution in awake, mobile mice},
	volume = {56},
	abstract = {We report a technique for two-photon fluorescence imaging with cellular resolution in awake, behaving mice with minimal motion artifact. The apparatus combines an upright, table-mounted two-photon microscope with a spherical treadmill consisting of a large, air-supported Styrofoam ball. Mice, with implanted cranial windows, are head restrained under the objective while their limbs rest on the ball's upper surface. Following adaptation to head restraint, mice maneuver on the spherical treadmill as their heads remain motionless. Image sequences demonstrate that running-associated brain motion is limited to approximately 2-5 microm. In addition, motion is predominantly in the focal plane, with little out-of-plane motion, making the application of a custom-designed Hidden-Markov-Model-based motion correction algorithm useful for postprocessing. Behaviorally correlated calcium transients from large neuronal and astrocytic populations were routinely measured, with an estimated motion-induced false positive error rate of {\textless}5\%.},
	language = {eng},
	number = {1},
	journal = {Neuron},
	author = {Dombeck, Daniel A and Khabbaz, Anton N and Collman, Forrest and Adelman, Thomas L and Tank, David W},
	year = {2007},
	note = {Place: Department of Molecular Biology, Carl Icahn Labs, Princeton University, Princeton, NJ 08544, USA.},
	keywords = {merged\_fiete.bib},
	pages = {43--57},
}

@article{dragoi_temporal_2006,
	title = {Temporal encoding of place sequences by hippocampal cell assemblies},
	volume = {50},
	abstract = {Both episodic memory and spatial navigation require temporal encoding of the relationships between events or locations. In a linear maze, ordered spatial distances between sequential locations were represented by the temporal relations of hippocampal place cell pairs within cycles of theta oscillation in a compressed manner. Such correlations could arise due to spike “phase precession” of independent neurons driven by common theta pacemaker or as a result of temporal coordination among specific hippocampal cell assemblies. We found that temporal correlation between place cell pairs was stronger than predicted by a pacemaker drive of independent neurons, indicating a critical role for synaptic interactions and precise timing within and across cell assemblies in place sequence representation. CA1 and CA3 ensembles, identifying spatial locations, were active preferentially on opposite phases of theta cycles. These observations suggest that interleaving CA3 neuronal sequences bind CA1 assemblies representing overlapping past, present, and future locations into single episodes.},
	language = {eng},
	number = {1},
	journal = {Neuron},
	author = {Dragoi, George and Buzsaki, Gyorgy},
	year = {2006},
	note = {Place: Center for Molecular and Behavioral Neuroscience, Rutgers, The State University of New Jersey, Newark, New Jersey 07102, USA. gdragoi@mit.edu},
	keywords = {merged\_fiete.bib},
	pages = {145--157},
}

@article{durrant-whyte_simultaneous_2006,
	title = {Simultaneous localization and mapping: part {I}},
	volume = {13},
	number = {2},
	journal = {IEEE Robot. Autom. Mag.},
	author = {Durrant-Whyte, H and Bailey, T},
	year = {2006},
	keywords = {merged\_fiete.bib},
}

@article{eichenbaum_hippocampus_1999,
	title = {The hippocampus, memory, and place cells: is it spatial memory or a memory space?},
	volume = {23},
	language = {eng},
	number = {2},
	journal = {Neuron},
	author = {Eichenbaum, H and Dudchenko, P and Wood, E and Shapiro, M and Tanila, H},
	year = {1999},
	note = {Place: Department of Psychology, Boston University, Massachusetts 02215, USA. hbe@bu.edu},
	keywords = {merged\_fiete.bib, hippocampus non-spatial},
	pages = {209--226},
}

@article{eichenbaum_towards_2008,
	title = {Towards a functional organization of the medial temporal lobe memory system: {Role} of the parahippocampal and medial entorhinal cortical areas},
	volume = {18},
	number = {12},
	journal = {Hippocampus},
	author = {Eichenbaum, H and Lipton, P A},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {XXX--XXX},
}

@article{eichenbaum_organization_1989,
	title = {The organization of spatial coding in the hippocampus: a study of neural ensemble activity},
	volume = {9},
	abstract = {Neural activity was recorded from local groups of hippocampal single units in rats performing a spatial-memory task. The organization of functional correlates in these neural ensembles was investigated by examining the spatial relationships among the place fields of single units in each ensemble. The distance and overlap between place fields were determined together with the tuning of cellular activity to behavioral variables, including direction, speed, and turning angle during movements within place fields. The place fields of recorded neural ensembles were significantly clustered: closer in space and considerably more overlapped than chance when compared statistically with Monte Carlo simulations. Just as single units often have significant firing in more than one distinct location in the environment (subfields), the ensembles had multiple and distinct clusters of overlapping subfields. In addition, proximity and overlap between place fields were significantly, but weakly, correlated with similarity in optimal movement tuning parameters. These results suggest that the hippocampus maintains a local organization with respect to place fields despite having no apparent large-scale isomorphism with the spatial environment. The organization of multiple, clustered place fields with correlated movement tuning properties in small neural ensembles suggests the existence of functional neural ensembles serving to encode multiple sensory and behavioral aspects of a place or event. Such an organization is similar to that observed for neocortical association areas afferent to the hippocampal system.},
	language = {eng},
	number = {8},
	journal = {J. Neurosci.},
	author = {Eichenbaum, H and Wiener, S I and Shapiro, M L and Cohen, N J},
	year = {1989},
	note = {Place: Department of Biological Sciences, Wellesley College, Massachusetts 02181.},
	keywords = {Animals, Rats, merged\_fiete.bib, Hippocampus/cytology/*physiology, Space Perception/*physiology, Electrophysiology, Neurons/physiology, Motor Activity/physiology},
	pages = {2764--2775},
}

@article{etienne_brief_2000,
	title = {A brief view of known landmarks reorientates path integration in hamsters},
	volume = {87},
	abstract = {In darkness, hamsters commute between their nest and a feeding site through path integration only, and therefore show cumulative errors in the return direction to the nest. We examined whether a brief presentation of familiar room cues could reset the path integrator. The hamsters could see the room cues either during, or at the end of, the outward journey to the food place, in a conflict situation where motion cues and visual information were set at variance. In both conditions, the animals used mainly visual information to return home. Thus, hamsters can determine their azimuth, and possibly their location, through a visual fix, and can reset their path integrator through the fix. This allows them to update their position during further locomotion in the dark and thus to compute a correct homing vector with respect to a visually induced reference frame. Taking episodic positional fixes may greatly enhance the functional value of path integration.},
	language = {eng},
	number = {11},
	journal = {Naturwissenschaften},
	author = {Etienne, A S and Boulens, V and Maurer, R and Rowe, T and Siegrist, C},
	year = {2000},
	note = {Place: Laboratory of Ethology, University of Geneva, 54 route des Acacias, 1227 Geneva, Switzerland. ariane.etienne@pse.unige.ch},
	keywords = {Pattern Recognition, Animals, Female, merged\_fiete.bib, Orientation/*physiology, Visual, Conflict (Psychology), Cricetinae/*physiology, Maternal Behavior, Motor Activity},
	pages = {494--498},
}

@article{etienne_navigation_1998,
	title = {Navigation through vector addition},
	volume = {396},
	abstract = {During short foraging excursions away from their home, central place foragers update their position relative to their point of departure by processing signals generated by locomotion. They therefore can home along a self-generated vector without using learned references. In rodents and other mammals, this path integration process (dead reckoning) can occur on the basis of purely internal signals, such as vestibular or proprioceptive (re)afferences. We report here that hamsters are also capable of proceeding to a previously learned feeding site through vector information from locomotion only. The subjects compute the direction and distance to the goal by subtracting their current-position vector from the stored nest-to-goal vector. This computation pertains to locations per se and therefore occurs in absolute space, independently of landmark objects. If available, prominent visual cues merely serve to confirm the path planned through the addition of self-generated vectors, whereas visual as well as nonvisual references confirm that the subject has arrived at the goal site.},
	language = {eng},
	number = {6707},
	journal = {Nature},
	author = {Etienne, A S and Maurer, R and Berlie, J and Reverdin, B and Rowe, T and Georgakopoulos, J and Seguinot, V},
	year = {1998},
	note = {Place: Laboratoire d'Ethologie, FPSE, Universite de Geneve, Carouge, Switzerland. Ariane.Etienne@pse.unige.ch},
	keywords = {merged\_fiete.bib},
	pages = {161--164},
}

@article{etienne_path_1996,
	title = {Path integration in mammals and its interaction with visual landmarks},
	volume = {199},
	abstract = {During locomotion, mammals update their position with respect to a fixed point of reference, such as their point of departure, by processing inertial cues, proprioceptive feedback and stored motor commands generated during locomotion. This so-called path integration system (dead reckoning) allows the animal to return to its home, or to a familiar feeding place, even when external cues are absent or novel. However, without the use of external cues, the path integration process leads to rapid accumulation of errors involving both the direction and distance of the goal. Therefore, even nocturnal species such as hamsters and mice rely more on previously learned visual references than on the path integration system when the two types of information are in conflict. Recent studies investigate the extent to which path integration and familiar visual cues cooperate to optimize the navigational performance.},
	language = {eng},
	number = {Pt 1},
	journal = {J. Exp. Biol.},
	author = {Etienne, A S and Maurer, R and Seguinot, V},
	year = {1996},
	note = {Place: Laboratoire d'Ethologie, FPSE, Universite de Geneve, Carouge, Switzerland.},
	keywords = {Humans, Animals, Rats, merged\_fiete.bib, Mammals/*physiology, Locomotion/*physiology, Visual Perception/*physiology, Mice, Visual Pathways/*physiology, Cognition/physiology, Cricetinae, Gerbillinae, Mesocricetus, Proprioception/physiology},
	pages = {201--209},
}

@article{fee_active_2000,
	title = {Active stabilization of electrodes for intracellular recording in awake behaving animals},
	volume = {27},
	abstract = {Intracellular recording is a powerful electrophysiology technique that has revealed much of what is known about the biophysical properties of neurons. However, neuronal properties are strongly affected by activity dependent and modulatory influences, making it essential, ultimately, to study these properties in behaving animals. Unfortunately, intracellular recording has only been widely applied in vitro, since cardiac and respiratory pulsations make intracellular recording difficult in vivo. In awake behaving animals, spontaneous movements make intracellular recording nearly impossible. Here I present a novel technique to dynamically stabilize the position of a recording electrode relative to the brain. Physiological signals that are predictive of brain motion at the recording site, such as the electrocardiogram (EKG), respiratory pressure, or cranial motion, are used to control a piezoelectric manipulator, making possible stable intracellular recordings in awake active animals.},
	language = {eng},
	number = {3},
	journal = {Neuron},
	author = {Fee, M S},
	year = {2000},
	note = {Place: Biological Computation Research Department, Lucent Technologies, New Jersey 07974, USA. fee@lucent.com},
	keywords = {merged\_fiete.bib},
	pages = {461--468},
}

@article{fiete_model_2007,
	title = {Model of birdsong learning based on gradient estimation by dynamic perturbation of neural conductances},
	abstract = {We propose a model of songbird learning that focuses on avian brain areas HVC and RA, involved in song production, and area LMAN, important for generating song variability. Plasticity at HVC{\textbackslash}toRA synapses is driven by hypothetical ;;rules” depending on three signals: activation of HVC–{\textgreater}RA synapses, activation of LMAN–{\textgreater}RA synapses, and reinforcement from an internal critic that compares the bird's own song with a memorized template of an adult tutor's song. Fluctuating glutamatergic input to RA from LMAN generates behavioral variability for trial-and-error learning. The plasticity rules perform gradient-based reinforcement learning in a spiking neural network model of song production. Although the reinforcement signal is delayed, temporally imprecise, and binarized, the model learns in a reasonable amount of time in numerical simulations. Varying the number of neurons in HVC and RA has little effect on learning time. The model makes specific predictions for the induction of bidirectional long-term plasticity at HVC–{\textgreater}RA synapses.},
	language = {ENG},
	journal = {J. Neurophysiol.},
	author = {Fiete, I R and Fee, M S and Seung, H S},
	year = {2007},
	note = {Place: Division of Biology, Caltech, Pasadena, California, United States.},
	keywords = {merged\_fiete.bib},
}

@article{fiete_temporal_2004,
	title = {Temporal sparseness of the premotor drive is important for rapid learning in a neural network model of birdsong},
	volume = {92},
	abstract = {Sparse neural codes have been widely observed in cortical sensory and motor areas. A striking example of sparse temporal coding is in the song-related premotor area high vocal center (HVC) of songbirds: The motor neurons innervating avian vocal muscles are driven by premotor nucleus robustus archistriatalis (RA), which is in turn driven by nucleus HVC. Recent experiments reveal that RA-projecting HVC neurons fire just one burst per song motif. However, the function of this remarkable temporal sparseness has remained unclear. Because birdsong is a clear example of a learned complex motor behavior, we explore in a neural network model with the help of numerical and analytical techniques the possible role of sparse premotor neural codes in song-related motor learning. In numerical simulations with nonlinear neurons, as HVC activity is made progressively less sparse, the minimum learning time increases significantly. Heuristically, this slowdown arises from increasing interference in the weight updates for different synapses. If activity in HVC is sparse, synaptic interference is reduced, and is minimized if each synapse from HVC to RA is used only once in the motif, which is the situation observed experimentally. Our numerical results are corroborated by a theoretical analysis of learning in linear networks, for which we derive a relationship between sparse activity, synaptic interference, and learning time. If songbirds acquire their songs under significant pressure to learn quickly, this study predicts that HVC activity, currently measured only in adults, should also be sparse during the sensorimotor phase in the juvenile bird. We discuss the relevance of these results, linking sparse codes and learning speed, to other multilayered sensory and motor systems.},
	language = {eng},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Fiete, I R and Hahnloser, R H R and Fee, M S and Seung, H S},
	year = {2004},
	note = {Place: Department of Physics, Harvard University, Cambridge, MA 02138, USA.},
	keywords = {Algorithms, Animals, Computer Simulation, merged\_fiete.bib, Neurological, Models, Animal/*physiology, *Neural Networks (Computer), Brain/physiology, Nonlinear Dynamics, Vocalization, *Artificial Intelligence, Birds/*physiology, Linear Models, Motor Neurons/physiology, Muscle, Skeletal/innervation/physiology},
	pages = {2274--2282},
}

@article{fiete_gradient_2006,
	title = {Gradient learning in spiking neural networks by dynamic perturbation of conductances},
	volume = {97},
	abstract = {We present a method of estimating the gradient of an objective function with respect to the synaptic weights of a spiking neural network. The method works by measuring the fluctuations in the objective function in response to dynamic perturbation of the membrane conductances of the neurons. It is compatible with recurrent networks of conductance-based model neurons with dynamic synapses. The method can be interpreted as a biologically plausible synaptic learning rule, if the dynamic perturbations are generated by a special class of “empiric” synapses driven by random spike trains from an external source.},
	language = {eng},
	number = {4},
	journal = {Phys. Rev. Lett.},
	author = {Fiete, I R and Seung, H S},
	year = {2006},
	note = {Place: Kavli Institute for Theoretical Physics, University of California, Santa Barbara, California 93106, USA.},
	keywords = {Humans, Animals, Computer Simulation, merged\_fiete.bib, *Models, Neurological, Neurons/*physiology, Nerve Net/*physiology, Action Potentials/*physiology, Biological Clocks/*physiology, Synaptic Transmission/*physiology, Linear Models, Cell Membrane/*physiology, Electric Conductivity},
	pages = {048104},
}

@article{foster_model_2000,
	title = {A model of hippocampally dependent navigation, using the temporal difference learning rule},
	volume = {10},
	abstract = {This paper presents a model of how hippocampal place cells might be used for spatial navigation in two watermaze tasks: the standard reference memory task and a delayed matching-to-place task. In the reference memory task, the escape platform occupies a single location and rats gradually learn relatively direct paths to the goal over the course of days, in each of which they perform a fixed number of trials. In the delayed matching-to-place task, the escape platform occupies a novel location on each day, and rats gradually acquire one-trial learning, i.e., direct paths on the second trial of each day. The model uses a local, incremental, and statistically efficient connectionist algorithm called temporal difference learning in two distinct components. The first is a reinforcement-based “actor-critic” network that is a general model of classical and instrumental conditioning. In this case, it is applied to navigation, using place cells to provide information about state. By itself, the actor-critic can learn the reference memory task, but this learning is inflexible to changes to the platform location. We argue that one-trial learning in the delayed matching-to-place task demands a goal-independent representation of space. This is provided by the second component of the model: a network that uses temporal difference learning and self-motion information to acquire consistent spatial coordinates in the environment. Each component of the model is necessary at a different stage of the task; the actor-critic provides a way of transferring control to the component that performs best. The model successfully captures gradual acquisition in both tasks, and, in particular, the ultimate development of one-trial learning in the delayed matching-to-place task. Place cells report a form of stable, allocentric information that is well-suited to the various kinds of learning in the model.},
	language = {eng},
	number = {1},
	journal = {Hippocampus},
	author = {Foster, D J and Morris, R G and Dayan, P},
	year = {2000},
	note = {Place: Centre for Neuroscience, University of Edinburgh, Scotland, UK.},
	keywords = {Reward, Animals, Rats, merged\_fiete.bib, *Models, Hippocampus/*physiology, Neurological, Animal/physiology, Behavior, Space Perception/*physiology, Maze Learning/physiology, Memory/physiology, *Computer Simulation, Conditioning (Psychology)/physiology, Locomotion/physiology},
	pages = {1--16},
}

@article{frank_trajectory_2000,
	title = {Trajectory encoding in the hippocampus and entorhinal cortex},
	volume = {27},
	abstract = {We recorded from single neurons in the hippocampus and entorhinal cortex (EC) of rats to investigate the role of these structures in navigation and memory representation. Our results revealed two novel phenomena: first, many cells in CA1 and the EC fired at significantly different rates when the animal was in the same position depending on where the animal had come from or where it was going. Second, cells in deep layers of the EC, the targets of hippocampal outputs, appeared to represent the similarities between locations on spatially distinct trajectories through the environment. Our findings suggest that the hippocampus represents the animal's position in the context of a trajectory through space and that the EC represents regularities across different trajectories that could allow for generalization across experiences.},
	language = {eng},
	number = {1},
	journal = {Neuron},
	author = {Frank, L M and Brown, E N and Wilson, M},
	year = {2000},
	note = {Place: Center for Learning and Memory, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge 02139, USA. loren@srlb4.mgh.harvard.edu},
	keywords = {merged\_fiete.bib},
	pages = {169--178},
}

@article{frank_comparison_2001,
	title = {A comparison of the firing properties of putative excitatory and inhibitory neurons from {CA1} and the entorhinal cortex},
	volume = {86},
	abstract = {The superficial layers of the entorhinal cortex (EC) provide the majority of the neocortical input to the hippocampus, and the deep layers of the EC receive the majority of neocortically bound hippocampal outputs. To characterize information transmission through the hippocampal and EC circuitry, we recorded simultaneously from neurons in the superficial EC, the CA1 region of hippocampus, and the deep EC while rodents ran for food reward in two environments. Spike waveform analysis allowed us to classify units as fast-spiking (FS) putative inhibitory cells or putative excitatory (PE) cells. PE and FS units' firing were often strongly correlated at short time scales, suggesting the presence a monosynaptic connection from the PE to FS units. EC PE units, unlike those found in CA1, showed little or no tendency to fire in bursts. We also found that the firing of FS and PE units from all regions was modulated by the approximately 8 Hz theta rhythm, although the firing of deep EC FS units tended to be less strongly modulated than that of the other types of units. When we examined the spatial specificity of FS units, we determined that FS units in all three regions showed low specificity. At the same time, retrospective coding, in which firing rates were related to past position, was present in FS units from all three regions and deep EC FS units often fired in a “path equivalent” manner in that they were active in physically different, but behaviorally related positions both within and across environments. Our results suggest that while the firing of FS units from CA1 and the EC show similarly low levels of position specificity, FS units from each region differ from one another in that they mirrored the associated PE units in terms of their tendency to show more complex positional firing properties like retrospective coding and path equivalence.},
	language = {eng},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Frank, L M and Brown, E N and Wilson, M A},
	year = {2001},
	note = {Place: Center for Learning and Memory, RIKEN-MIT Neuroscience Research Center and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA.},
	keywords = {merged\_fiete.bib},
	pages = {2029--2040},
}

@article{franzius_grids_2007,
	title = {From grids to places},
	volume = {22},
	abstract = {Hafting et al. (2005) described grid cells in the dorsocaudal region of the medial entorhinal cortex (dMEC). These cells show a strikingly regular grid-like firing-pattern as a function of the position of a rat in an enclosure. Since the dMEC projects to the hippocampal areas containing the well-known place cells, the question arises whether and how the localized responses of the latter can emerge based on the output of grid cells. Here, we show that, starting with simulated grid-cells, a simple linear transformation maximizing sparseness leads to a localized representation similar to place fields.},
	language = {eng},
	number = {3},
	journal = {J. Comput. Neurosci.},
	author = {Franzius, M and Vollgraf, R and Wiskott, L},
	year = {2007},
	note = {Place: Institute for Theoretical Biology, Humboldt-University, Berlin, Germany. m.franzius@biologie.hu-berlin.de},
	keywords = {Humans, Animals, merged\_fiete.bib, Action Potentials/physiology, Neurons/*physiology, Space Perception/physiology, Nerve Net/*physiology, Orientation/physiology, Synaptic Transmission/physiology, Hippocampus/anatomy \& histology/*physiology, Neural Pathways/anatomy \& histology/*physiology, Linear Models, Entorhinal Cortex/anatomy \& histology/*physiology},
	pages = {297--299},
}

@article{fuhs_spin_2006,
	title = {A spin glass model of path integration in rat medial entorhinal cortex},
	volume = {26},
	abstract = {Electrophysiological recording studies in the dorsocaudal region of medial entorhinal cortex (dMEC) of the rat reveal cells whose spatial firing fields show a remarkably regular hexagonal grid pattern (Fyhn et al., 2004; Hafting et al., 2005). We describe a symmetric, locally connected neural network, or spin glass model, that spontaneously produces a hexagonal grid of activity bumps on a two-dimensional sheet of units. The spatial firing fields of the simulated cells closely resemble those of dMEC cells. A collection of grids with different scales and/or orientations forms a basis set for encoding position. Simulations show that the animal's location can easily be determined from the population activity pattern. Introducing an asymmetry in the model allows the activity bumps to be shifted in any direction, at a rate proportional to velocity, to achieve path integration. Furthermore, information about the structure of the environment can be superimposed on the spatial position signal by modulation of the bump activity levels without significantly interfering with the hexagonal periodicity of firing fields. Our results support the conjecture of Hafting et al. (2005) that an attractor network in dMEC may be the source of path integration information afferent to hippocampus.},
	language = {eng},
	number = {16},
	journal = {J. Neurosci.},
	author = {Fuhs, Mark C and Touretzky, David S},
	year = {2006},
	note = {Place: Computer Science Department, Center for the Neural Basis of Cognition, Carnegie Mellon University, Pittsburgh, Pennsylvania 15213, USA.},
	keywords = {Animals, Rats, merged\_fiete.bib, Nerve Net/*physiology, Entorhinal Cortex/*physiology, *Neural Networks (Computer)},
	pages = {4266--4276},
}

@article{giocomo_computation_2008,
	title = {Computation by oscillations: {Implications} of experimental data for theoretical models of grid cells},
	volume = {18},
	number = {12},
	journal = {Hippocampus},
	author = {Giocomo, Lisa M and Hasselmo, Michael E},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {XXX--XXX},
}

@article{giocomo_temporal_2007,
	title = {Temporal frequency of subthreshold oscillations scales with entorhinal grid cell field spacing},
	volume = {315},
	abstract = {Grid cells in layer II of rat entorhinal cortex fire to spatial locations in a repeating hexagonal grid, with smaller spacing between grid fields for neurons in more dorsal anatomical locations. Data from in vitro whole-cell patch recordings showed differences in frequency of subthreshold membrane potential oscillations in entorhinal neurons that correspond to different positions along the dorsal-to-ventral axis, supporting a model of physiological mechanisms for grid cell responses.},
	language = {eng},
	number = {5819},
	journal = {Science},
	author = {Giocomo, Lisa M and Zilli, Eric A and Fransen, Erik and Hasselmo, Michael E},
	year = {2007},
	note = {Place: Center for Memory and Brain, Department of Psychology, Program in Neuroscience, Boston University, 2 Cummington Street, Boston, MA 02215, USA. giocomo@bu.edu},
	keywords = {merged\_fiete.bib},
	pages = {1719--1722},
}

@article{goodridge_modeling_2000,
	title = {Modeling attractor deformation in the rodent head-direction system},
	volume = {83},
	abstract = {We present a model of the head-direction circuit in the rat that improves on earlier models in several respects. First, it provides an account of some of the unique characteristics of head-direction (HD) cell firing in the lateral mammillary nucleus and the anterior thalamus. Second, the model functions without making physiologically unrealistic assumptions. In particular, it implements attractor dynamics in postsubiculum and lateral mammillary nucleus without directionally tuned inhibitory neurons, which have never been observed in vivo, and it integrates angular velocity without the use of multiplicative synapses. The model allows us to examine the relationships among three HD areas and various properties of their representations. A surprising result is that certain combinations of purported HD cell properties are mutually incompatible, suggesting that the lateral mammillary nucleus may not be the primary source of head direction input to anterior thalamic HD cells.},
	language = {eng},
	number = {6},
	journal = {J. Neurophysiol.},
	author = {Goodridge, J P and Touretzky, D S},
	year = {2000},
	note = {Place: Center for the Neural Basis of Cognition, Carnegie Mellon University, Pittsburgh, Pennsylvania 15213-3891, USA.},
	keywords = {merged\_fiete.bib},
	pages = {3402--3410},
}

@article{gorchetchnikov_space_2007,
	title = {Space, time and learning in the hippocampus: how fine spatial and temporal scales are expanded into population codes for behavioral control},
	volume = {20},
	abstract = {The hippocampus participates in multiple functions, including spatial navigation, adaptive timing and declarative (notably, episodic) memory. How does it carry out these particular functions? The present article proposes that hippocampal spatial and temporal processing are carried out by parallel circuits within entorhinal cortex, dentate gyrus and CA3 that are variations of the same circuit design. In particular, interactions between these brain regions transform fine spatial and temporal scales into population codes that are capable of representing the much larger spatial and temporal scales that are needed to control adaptive behaviors. Previous models of adaptively timed learning propose how a spectrum of cells tuned to brief but different delays are combined and modulated by learning to create a population code for controlling goal-oriented behaviors that span hundreds of milliseconds or even seconds. Here it is proposed how projections from entorhinal grid cells can undergo a similar learning process to create hippocampal place cells that can cover a space of many meters that are needed to control navigational behaviors. The suggested homology between spatial and temporal processing may clarify how spatial and temporal information may be integrated into an episodic memory. The model proposes how a path integration process activates a spatial map of grid cells. Path integration has a limited spatial capacity, and must be reset periodically, leading to the observed grid cell periodicity. Integration-to-map transformations have been proposed to exist in other brain systems. These include cortical mechanisms for numerical representation in the parietal cortex. As in the grid-to-place cell spatial expansion, the analog representation of number is extended by additional mechanisms to represent much larger numbers. The model also suggests how visual landmarks may influence grid cell activities via feedback projections from hippocampal place cells to the entorhinal cortex.},
	language = {eng},
	number = {2},
	journal = {Neural Netw.},
	author = {Gorchetchnikov, Anatoli and Grossberg, Stephen},
	year = {2007},
	note = {Place: Department of Cognitive and Neural Systems, Center for Adaptive Systems, Boston University, 677 Beacon Street, Boston, MA 02215, United States.},
	keywords = {Animals, merged\_fiete.bib, *Models, Neurological, Hippocampus/cytology/*physiology, Space Perception/*physiology, Neurons/physiology, Neural Pathways/physiology, Learning/*physiology, Behavior/*physiology, Time Perception/*physiology},
	pages = {182--193},
}

@article{gothard_dentate_2001,
	title = {Dentate gyrus and {CA1} ensemble activity during spatial reference frame shifts in the presence and absence of visual input},
	volume = {21},
	abstract = {In rats shuttling between a variably placed landmark of origin and a fixed goal, place fields of hippocampal CA1 cells encode location in two spatial reference frames. On the initial part of the outbound journey, place fields encode location with respect to the origin while on the final segment, place fields are aligned with the goal (Gothard et al., 1996b). An abrupt switch of reference frame can be induced experimentally by shortening the distance between the origin and the goal. Two linked hypotheses concerning this effect were addressed: (1) that the persistent, landmark-referenced firing results from some internal dynamic process (e.g., path integration or “momentum”) and is not a result of maintained sensory input from the landmark of origin; and (2) that this hypothetical process is generated by connections either within CA3 or between CA3 and CA1, in which case the effect might be absent from the dentate gyrus. Neuronal ensemble recordings were made simultaneously from CA1 and the dentate gyrus as rats shuttled on a linear track between a variably located box and a goal, under light or dark conditions. The box-referenced firing persisted significantly longer in the dark in both hippocampal subfields, suggesting a competitive interaction between an internal dynamic process and external sensory cues. The similarity between reference frame transitions in the dentate gyrus and the CA1 region suggests that this process probably occurs before CA3, possibly in the entorhinal cortex or subiculum.},
	language = {eng},
	number = {18},
	journal = {J. Neurosci.},
	author = {Gothard, K M and Hoffman, K L and Battaglia, F P and McNaughton, B L},
	year = {2001},
	note = {Place: Department of Psychiatry, California Regional Primate Research Center, University of California Davis, Davis, California 95616, USA.},
	keywords = {Animals, Rats, Male, Electroencephalography, merged\_fiete.bib, Action Potentials/physiology, Hippocampus/*physiology, Animal/physiology, Behavior, Cues, Orientation/*physiology, Electrodes, Implanted, Space Perception/*physiology, Inbred F344, Motor Activity/physiology, Darkness, Light, Photic Stimulation/methods, Dentate Gyrus/physiology, Appetitive Behavior/*physiology, Exploratory Behavior/*physiology, Neurons/classification/physiology},
	pages = {7284--7292},
}

@article{guanella_model_2007,
	title = {A model of grid cells based on a twisted torus topology},
	volume = {17},
	abstract = {The grid cells of the rat medial entorhinal cortex (MEC) show an increased firing frequency when the position of the animal correlates with multiple regions of the environment that are arranged in regular triangular grids. Here, we describe an artificial neural network based on a twisted torus topology, which allows for the generation of regular triangular grids. The association of the activity of pre-defined hippocampal place cells with entorhinal grid cells allows for a highly robust-to-noise calibration mechanism, suggesting a role for the hippocampal back-projections to the entorhinal cortex.},
	language = {eng},
	number = {4},
	journal = {Int. J. Neural Syst.},
	author = {Guanella, Alexis and Kiper, Daniel and Verschure, Paul},
	year = {2007},
	note = {Place: Institute of Neuroinformatics, Swiss Federal Institute of Technology (ETH), 190 Winterthurerstrasse, 8057 Zurich, Switzerland. guanella@ini.phys.ethz.ch},
	keywords = {Orientation, Animals, Neural Pathways, Rats, merged\_fiete.bib, *Models, Action Potentials/physiology, Neurological, Neurons/*physiology, Brain Mapping, Environment, Computer-Assisted, Synapses/physiology, *Neural Networks (Computer), Numerical Analysis, Entorhinal Cortex/cytology},
	pages = {231--240},
}

@article{haas_spike-timing-dependent_2006,
	title = {Spike-timing-dependent plasticity of inhibitory synapses in the entorhinal cortex},
	volume = {96},
	abstract = {Actions of inhibitory interneurons organize and modulate many neuronal processes, yet the mechanisms and consequences of plasticity of inhibitory synapses remain poorly understood. We report on spike-timing-dependent plasticity of inhibitory synapses in the entorhinal cortex. After pairing presynaptic stimulations at time t(pre) with evoked postsynaptic spikes at time t(post) under pharmacological blockade of excitation we found, via whole cell recordings, an asymmetrical timing rule for plasticity of the remaining inhibitory responses. Strength of response varied as a function of the time interval Deltat = t(post) - t(pre): for Deltat {\textgreater} 0 inhibitory responses potentiated, peaking at a delay of 10 ms. For Deltat {\textless} 0, the synaptic coupling depressed, again with a maximal effect near 10 ms of delay. We also show that changes in synaptic strength depend on changes in intracellular calcium concentrations and demonstrate that the calcium enters the postsynaptic cell through voltage-gated channels. Using network models, we demonstrate how this novel form of plasticity can sculpt network behavior efficiently and with remarkable flexibility.},
	language = {eng},
	number = {6},
	journal = {J. Neurophysiol.},
	author = {Haas, Julie S and Nowotny, Thomas and Abarbanel, H D I},
	year = {2006},
	note = {Place: Institute for Nonlinear Science, University of California-San Diego, 9500 Gilman Dr. MC0402, La Jolla, CA 92093-0402, USA. julie.haas@gmail.com},
	keywords = {merged\_fiete.bib},
	pages = {3305--3313},
}

@article{hafting_phase_2006,
	title = {Phase precession and phase locking in entorhinal grid cells},
	volume = {68.8},
	journal = {Soc Neurosci Abstr},
	author = {{Hafting} and Fyhn, M and Moser, M B and Moser, E I},
	year = {2006},
	keywords = {merged\_fiete.bib},
}

@article{hafting_data_2006,
	title = {Data posted at: http://www.ntnu.no/cbm/moser/gridcell},
	journal = {(last checked on May 2008)},
	author = {Hafting, T and {Fyhn} and {Molden} and {Moser} and Moser, E I},
	year = {2006},
	keywords = {merged\_fiete.bib},
}

@article{hafting_hippocampus-independent_2008,
	title = {Hippocampus-independent phase precession in entorhinal grid cells},
	volume = {453},
	abstract = {Theta-phase precession in hippocampal place cells is one of the best-studied experimental models of temporal coding in the brain. Theta-phase precession is a change in spike timing in which the place cell fires at progressively earlier phases of the extracellular theta rhythm as the animal crosses the spatially restricted firing field of the neuron. Within individual theta cycles, this phase advance results in a compressed replication of the firing sequence of consecutively activated place cells along the animal's trajectory, at a timescale short enough to enable spike-time-dependent plasticity between neurons in different parts of the sequence. The neuronal circuitry required for phase precession has not yet been established. The fact that phase precession can be seen in hippocampal output stuctures such as the prefrontal cortex suggests either that efferent structures inherit the precession from the hippocampus or that it is generated locally in those structures. Here we show that phase precession is expressed independently of the hippocampus in spatially modulated grid cells in layer II of medial entorhinal cortex, one synapse upstream of the hippocampus. Phase precession is apparent in nearly all principal cells in layer II but only sparsely in layer III. The precession in layer II is not blocked by inactivation of the hippocampus, suggesting that the phase advance is generated in the grid cell network. The results point to possible mechanisms for grid formation and raise the possibility that hippocampal phase precession is inherited from entorhinal cortex.},
	language = {ENG},
	journal = {Nature},
	author = {Hafting, T and Fyhn, M and Bonnevie, T and Moser, M B and Moser, E I},
	year = {2008},
	note = {Place: [1] Kavli Institute for Systems Neuroscience and Centre for the Biology of Memory, Norwegian University of Science and Technology, NO-7489 Trondheim, Norway [2] These authors contributed equally to this work.},
	keywords = {merged\_fiete.bib},
	pages = {1248--1252},
}

@article{hahnloser_emergence_2003,
	title = {Emergence of neural integration in the head-direction system by visual supervision},
	volume = {120},
	abstract = {Head-direction (HD) cells in subcortical areas of the mammalian brain are tuned to a particular head direction in space; a population of such neurons forms a neural compass that may be relevant for spatial navigation. The development of neural circuits constituting the head-direction system is poorly understood. Inspired by electrophysiological experiments about the role of recurrent synaptic connections, we investigate a learning rule that teaches neurons to amplify feed-forward inputs. We simulate random head movements of a rat, during which neurons receive both visual and vestibular (head-velocity) inputs. Remarkably, as recurrent connections learn to amplify exclusively the visual inputs, a neural network emerges that performs spatio-temporal integration. That is, during head movements in darkness, neurons resemble HD cells by maintaining a fixed tuning to head direction. The proposed learning rule exhibits similarities with known forms of anti-Hebbian synaptic plasticity. We conclude that selective amplification could serve as a general principle for the synaptic development of multimodal feedback circuits in the brain.},
	language = {eng},
	number = {3},
	journal = {Neuroscience},
	author = {Hahnloser, R H R},
	year = {2003},
	note = {Place: Bell Labs 1C-456, Lucent Technologies, 600 Mountain Avenue, Murray Hill, NJ 07974, USA. rhahnloser@lucent.com},
	keywords = {merged\_fiete.bib},
	pages = {877--891},
}

@article{hahnloser_ultra-sparse_2002,
	title = {An ultra-sparse code underlies the generation of neural sequences in a songbird},
	volume = {419},
	abstract = {Sequences of motor activity are encoded in many vertebrate brains by complex spatio-temporal patterns of neural activity; however, the neural circuit mechanisms underlying the generation of these pre-motor patterns are poorly understood. In songbirds, one prominent site of pre-motor activity is the forebrain robust nucleus of the archistriatum (RA), which generates stereotyped sequences of spike bursts during song and recapitulates these sequences during sleep. We show that the stereotyped sequences in RA are driven from nucleus HVC (high vocal centre), the principal pre-motor input to RA. Recordings of identified HVC neurons in sleeping and singing birds show that individual HVC neurons projecting onto RA neurons produce bursts sparsely, at a single, precise time during the RA sequence. These HVC neurons burst sequentially with respect to one another. We suggest that at each time in the RA sequence, the ensemble of active RA neurons is driven by a subpopulation of RA-projecting HVC neurons that is active only at that time. As a population, these HVC neurons may form an explicit representation of time in the sequence. Such a sparse representation, a temporal analogue of the 'grandmother cell' concept for object recognition, eliminates the problem of temporal interference during sequence generation and learning attributed to more distributed representations.},
	language = {eng},
	number = {6902},
	journal = {Nature},
	author = {Hahnloser, Richard H R and Kozhevnikov, Alexay A and Fee, Michale S},
	year = {2002},
	note = {Place: Biological Computation Research Department, Bell Laboratories, Lucent Technologies, Murray Hill, New Jersey 07974, USA.},
	keywords = {Animals, Action Potentials, Male, merged\_fiete.bib, Neurons/*physiology, Sleep/physiology, Electrophysiology, Animal/*physiology, Interneurons/physiology, Vocalization, Brain/anatomy \& histology/cytology/*physiology, Songbirds/anatomy \& histology/*physiology},
	pages = {65--70},
}

@article{hampson_hippocampal_1996,
	title = {Hippocampal place fields: relationship between degree of field overlap and cross-correlations within ensembles of hippocampal neurons},
	volume = {6},
	abstract = {The capacity to record from multiple neurons in awake freely moving animals provides a means for characterizing organizational principles of place field encoding within ensembles of hippocampal neurons. In this study, cross-correlations between pairs of hippocampal place cells and degree of overlap between their respective place fields were analyzed during behavioral performance of delayed matching (DMS) or non-matching sample (DNMS) tasks, or while the same rats chased pellets in a different environment. The relationship between field overlap and cross-correlations of neural spike activity within ensembles was shown to be a positive, exponentially increasing, function. Place fields from the same neurons were markedly “remapped” between the Delay and Pellet-chasing tasks, with respect to physical location and size of fields. However individual pairs of place cells within each ensemble retained nearly the same degree of overlap and cross-correlation even though the spatial environment and the tasks differed markedly. This suggested that place cells were organized in functional “clusters” which exhibited the same inter-relations with respect to place field overlap and cross-correlations, irrespective of actual field of location. When cross-correlations between place cells were compared to placement of the array recording electrodes within the hippocampus, the strongest correlations were found along previously defined posterior-projecting fiber gradients between CA3 and CA1 subfields (Ishizuka et al. [1990], J Comp Neurol 295:580-623; Li et al. [1994] (J Comp Neurol 339:181-208). These findings suggest that the functional organization of place fields conforms to anatomical principles suspected to operate within hippocampal ensembles.},
	language = {eng},
	number = {3},
	journal = {Hippocampus},
	author = {Hampson, R E and Byrd, D R and Konstantopoulos, J K and Bunn, T and Deadwyler, S A},
	year = {1996},
	note = {Place: Department of Physiology and Pharmacology, Bowman Gray School of Medicine, Wake Forest University, Winston-Salem, North Carolina 27157-1083, USA.},
	keywords = {Animals, Rats, Male, merged\_fiete.bib, Animal/physiology, Behavior, Hippocampus/*cytology/*physiology, Neurons/*physiology, Orientation/*physiology, Space Perception/physiology, Brain Mapping, Electrodes, Implanted, Electrophysiology, Sprague-Dawley, Cell Communication/physiology, Videotape Recording},
	pages = {281--293},
}

@article{hanke_pigmentarchitectonic_1997,
	title = {Pigmentarchitectonic subfields of the entorhinal region as revealed in tangential sections},
	volume = {38},
	abstract = {The entorhinal region is an important center of the limbic system involved in many dementing disorders. The boundaries of the entorhinal region of the left and right hemispheres were investigated in tangential sections (5 individuals, age range 21 to 29 years). This method preserves the rostral portion of the entorhinal region which is usually lost in coronal sectioning. The sections were stained with the pigment-Nissl-method. The superficial cellular layer of the centromedial part of the entorhinal region consists of large heavily pigmented neurons forming islands clearly separated from each other. The anterior and posterior parts of the entorhinal region display an opposite pattern consisting of small islands and stripes with ill-defined boundaries. The islands contain small and sparsely pigmented neurons surrounded by large and well pigmented cells. Close to the adjacent proisocortex, the small cell containing islands confluent while the large and well pigmented neurons disappear. Hence, the medial side of the entorhinal region extends up to the uncus and the lateral side into the main branch of the rhinal sulcus. The entorhinal region covers the frontal portion of the parahippocampal gyrus up to the periamygdaloid cortex and the posterior part ends acute-angled within the medial portion of the parahippocampal gyrus.},
	language = {eng},
	number = {4},
	journal = {J. Hirnforsch.},
	author = {Hanke, J and Yilmazer-Hanke, D M},
	year = {1997},
	note = {Place: Department of Anatomy 1, Hannover Medical School, Germany.},
	keywords = {merged\_fiete.bib},
	pages = {427--432},
}

@article{hartley_modeling_2000,
	title = {Modeling place fields in terms of the cortical inputs to the hippocampus},
	volume = {10},
	abstract = {A model of place-cell firing is presented that makes quantitative predictions about specific place cells' spatial receptive fields following changes to the rat's environment. A place cell's firing rate is modeled as a function of the rat's location by the thresholded sum of the firing rates of a number of putative cortical inputs. These inputs are tuned to respond whenever an environmental boundary is at a particular distance and allocentric direction from the rat. The initial behavior of a place cell in any environment is simply determined by its set of inputs and its threshold; learning is not necessary. The model is shown to produce a good fit to the firing of individual place cells, and populations of place cells across environments of differing shape. The cells' behavior can be predicted for novel environments of arbitrary size and shape, or for manipulations such as introducing a barrier. The model can be extended to make behavioral predictions regarding spatial memory.},
	language = {eng},
	number = {4},
	journal = {Hippocampus},
	author = {Hartley, T and Burgess, N and Lever, C and Cacucci, F and O'Keefe, J},
	year = {2000},
	note = {Place: Institute of Cognitive Neuroscience, University College London, UK. t.hartley@ucl.ac.uk},
	keywords = {Animals, merged\_fiete.bib, *Models, Hippocampus/*physiology, Neurological, Space Perception/*physiology, Cerebral Cortex/*physiology, Afferent Pathways/physiology},
	pages = {369--379},
}

@article{hasselmo_linking_2008,
	title = {Linking {Cellular} {Mechanisms} to {Behavior}: {Entorhinal} {Persistent} {Spiking} and {Membrane} {Potential} {Oscillations} {May} {Underlie} {Path} {Integration}, {Grid} {Cell} {Firing}, and {Episodic} {Memory},},
	volume = {2008},
	number = {Article ID 658323},
	journal = {Neural Plast.},
	author = {Hasselmo, Michael E and Brandon, Mark P},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {1--12},
}

@article{helmchen_miniature_2001,
	title = {A miniature head-mounted two-photon microscope. high-resolution brain imaging in freely moving animals},
	volume = {31},
	abstract = {Two-photon microscopy has enabled anatomical and functional fluorescence imaging in the intact brain of rats. Here, we extend two-photon imaging from anesthetized, head-stabilized to awake, freely moving animals by using a miniaturized head-mounted microscope. Excitation light is conducted to the microscope in a single-mode optical fiber, and images are scanned using vibrations of the fiber tip. Microscope performance was first characterized in the neocortex of anesthetized rats. We readily obtained images of vasculature filled with fluorescently labeled blood and of layer 2/3 pyramidal neurons filled with a calcium indicator. Capillary blood flow and dendritic calcium transients were measured with high time resolution using line scans. In awake, freely moving rats, stable imaging was possible except during sudden head movements.},
	language = {eng},
	number = {6},
	journal = {Neuron},
	author = {Helmchen, F and Fee, M S and Tank, D W and Denk, W},
	year = {2001},
	note = {Place: Biological Computation Research Department, Bell Laboratories, Lucent Technologies, Murray Hill, NJ 07974, USA.},
	keywords = {merged\_fiete.bib},
	pages = {903--912},
}

@article{hevner_entorhinal_1992,
	title = {Entorhinal cortex of the human, monkey, and rat: metabolic map as revealed by cytochrome oxidase},
	volume = {326},
	abstract = {The entorhinal cortex (EC) is a medial temporal lobe area involved in memory consolidation. Results from previous studies suggest that the upper layers of the EC may be organized into anatomical-neurochemical modules associated with pathways through the neuron clusters in layers II and III. To study metabolic patterns in the EC and to look for correlates of the proposed modules, we examined the distribution of cytochrome oxidase (CO) in the human, monkey, and rat EC. CO is a mitochondrial enzyme that has been used to study modules in other cortical areas. In all three species, the neuron clusters in layers II-III were darkly CO-reactive, whereas most of the neuropil between clusters was lightly or moderately CO-reactive. However, some neuropil regions directly adjacent to the neuron clusters were also darkly CO-reactive, especially in the human; these neuropil areas included portions of layers I and II. In tangential sections through layers I-II, the areas of dark staining formed a consistent pattern, comprised of partially interconnected islands and stripes associated with the neuron clusters. In the EC from one human hemisphere, approximately 200-250 CO-reactive layer II islands were present. EC layers other than I-III also showed characteristic CO staining intensities, but no evidence of modularity. Our results indicate that CO staining labels distinct compartments related to the neuron clusters in the upper EC layers. We propose that these compartments may represent modules for cortical processing, analogous to the CO-labeled modules in some other areas of cortex.},
	language = {eng},
	number = {3},
	journal = {J. Comp. Neurol.},
	author = {Hevner, R F and Wong-Riley, M T},
	year = {1992},
	note = {Place: Department of Cellular Biology and Anatomy, Medical College of Wisconsin, Milwaukee 53226.},
	keywords = {merged\_fiete.bib},
	pages = {451--469},
}

@article{hollup_accumulation_2001,
	title = {Accumulation of hippocampal place fields at the goal location in an annular watermaze task},
	volume = {21},
	abstract = {To explore the plastic representation of information in spatially selective hippocampal pyramidal neurons, we made multiple single-unit recordings in rats trained to find a hidden platform at a constant location in a hippocampal-dependent annular watermaze task. Hippocampal pyramidal cells exhibited place-related firing in the watermaze. Place fields tended to accumulate near the platform, even in probe trials without immediate escape. The percentage of cells with peak activity around the hidden platform was more than twice the percentage firing in equally large areas elsewhere in the arena. The effect was independent of the actual position of the platform in the room frame. It was dissociable from ongoing motor behavior and was not related to linear or angular speed, swim direction, or variation in hippocampal theta activity. There was no accumulation of firing in any particular region in rats that were trained with a variable platform location. These training-dependent effects suggest that regions of particular behavioral significance may be over-represented in the hippocampal spatial map, even when these regions are completely unmarked.},
	language = {eng},
	number = {5},
	journal = {J. Neurosci.},
	author = {Hollup, S A and Molden, S and Donnett, J G and Moser, M B and Moser, E I},
	year = {2001},
	note = {Place: Department of Psychology, Norwegian University of Science and Technology, 7491 Trondheim, Norway.},
	keywords = {Animals, Rats, Male, Electroencephalography, merged\_fiete.bib, Action Potentials/physiology, Hippocampus/*physiology, Maze Learning/*physiology, Animal/physiology, Behavior, Long-Evans, Electrodes, Implanted, Pyramidal Cells/*physiology, Motor Activity/physiology, Computer-Assisted, Spatial Behavior/physiology, Neuronal Plasticity/physiology, Signal Processing, Appetitive Behavior/physiology},
	pages = {1635--1644},
}

@article{holscher_rats_2005,
	title = {Rats are able to navigate in virtual environments},
	volume = {208},
	abstract = {Virtual reality (VR) systems are useful tools that enable users to alter environmental settings and the location of landmarks in an accurate and fast way. Primates have been shown to be able to navigate in virtual environments. For rodents, however, all previous attempts to develop VR systems in which rats behave in the same way as in corresponding 3-D environments have failed. The question arises as to whether, in principle, rodents can be trained to navigate in a properly designed virtual environment (VE), or whether this peculiarity is limited to primates and humans. We built a virtual reality set-up that takes the wide-angle visual system of rats into account. We show for the first time that rats learn spatial tasks in this VE quite readily. This set-up opens up new opportunities for investigations of information processing in navigation (e.g. the importance of optic flow or vestibular input).},
	language = {eng},
	number = {Pt 3},
	journal = {J. Exp. Biol.},
	author = {Holscher, C and Schnee, A and Dahmen, H and Setia, L and Mallot, H A},
	year = {2005},
	note = {Place: School of Biomedical Sciences, University of Ulster, Coleraine BT52 1SA, Northern Ireland.},
	keywords = {merged\_fiete.bib},
	pages = {561--569},
}

@article{hopfield_neurons_1984,
	title = {Neurons with graded response have collective computational properties like those of two-state neurons},
	volume = {81},
	abstract = {A model for a large network of {\textbackslash}textbackslashtt“neurons{\textbackslash}textbackslashtt” with a graded response (or sigmoid input-output relation) is studied. This deterministic system has collective properties in very close correspondence with the earlier stochastic model based on McCulloch - Pitts neurons. The content- addressable memory and other emergent collective properties of the original model also are present in the graded response model. The idea that such collective properties are used in biological systems is given added credence by the continued presence of such properties for more nearly biological “neurons.” Collective analog electrical circuits of the kind described will certainly function. The collective states of the two models have a simple correspondence. The original model will continue to be useful for simulations, because its connection to graded response systems is established. Equations that include the effect of action potentials in the graded response system are also developed.},
	language = {eng},
	number = {10},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Hopfield, J J},
	year = {1984},
	keywords = {Animals, Action Potentials, merged\_fiete.bib, *Models, Neurological, Neurons/*physiology, Electric Conductivity, Mathematics},
	pages = {3088--3092},
}

@article{huber_sparse_2008,
	title = {Sparse optical microstimulation in barrel cortex drives learned behaviour in freely moving mice},
	volume = {451},
	abstract = {Electrical microstimulation can establish causal links between the activity of groups of neurons and perceptual and cognitive functions. However, the number and identities of neurons microstimulated, as well as the number of action potentials evoked, are difficult to ascertain. To address these issues we introduced the light-gated algal channel channelrhodopsin-2 (ChR2) specifically into a small fraction of layer 2/3 neurons of the mouse primary somatosensory cortex. ChR2 photostimulation in vivo reliably generated stimulus-locked action potentials at frequencies up to 50 Hz. Here we show that naive mice readily learned to detect brief trains of action potentials (five light pulses, 1 ms, 20 Hz). After training, mice could detect a photostimulus firing a single action potential in approximately 300 neurons. Even fewer neurons (approximately 60) were required for longer stimuli (five action potentials, 250 ms). Our results show that perceptual decisions and learning can be driven by extremely brief epochs of cortical activity in a sparse subset of supragranular cortical pyramidal neurons.},
	language = {eng},
	number = {7174},
	journal = {Nature},
	author = {Huber, Daniel and Petreanu, Leopoldo and Ghitani, Nima and Ranade, Sachin and Hromadka, Tomas and Mainen, Zach and Svoboda, Karel},
	year = {2008},
	note = {Place: Howard Hughes Medical Institute, Janelia Farm Research Campus, Ashburn, Virginia 20147, USA.},
	keywords = {merged\_fiete.bib},
	pages = {61--64},
}

@article{jeffery_preserved_2003,
	title = {Preserved performance in a hippocampal-dependent spatial task despite complete place cell remapping},
	volume = {13},
	abstract = {The spatially localized firing of hippocampal place cells is thought to underlie the navigational function of the hippocampus. Performance on a spatial task learned using a particular place cell map should therefore deteriorate if the map is disrupted. To test this prediction, we trained rats on a hippocampal-dependent spatial task in a black box and tested them in a white box. Although the change from black to white induced remapping of most place cells, navigational performance remained essentially intact. Furthermore, place cell activity was also unrelated to specific aspects of the task such as tone onset, response, or goal location. Together, these results imply that the spatial information needed to solve this navigation task is represented outside the hippocampus and suggest that the place cells encode some other aspect, such as the spatial context.},
	language = {eng},
	number = {2},
	journal = {Hippocampus},
	author = {Jeffery, Kathryn J and Gilbert, Alexandra and Burton, Stephen and Strudwick, Anna},
	year = {2003},
	note = {Place: Department of Psychology, University College London, London, UK. k.jeffery@ucl.ac.uk},
	keywords = {merged\_fiete.bib},
	pages = {175--189},
}

@article{jones_basket-like_1993,
	title = {Basket-like interneurones in layer {II} of the entorhinal cortex exhibit a powerful {NMDA}-mediated synaptic excitation},
	volume = {149},
	abstract = {Spiny stellate neurones of layer II of the entorhinal cortex (EC) provide the perforant path input to the dentate gyrus. Previous studies have shown that synaptic responses of these neurones are dominated by GABAergic inhibition. The present study describes intracellular recordings from 'fast-spiking' interneurones in layer II which may be the basis of the synaptic inhibition. Lucifer yellow fills of fast-spiking cells revealed neurones with a widespread axonal arborization forming basket-like complexes around unlabelled cells in layer II. Synaptic activation of the fast-spiking cells evoked long duration excitations which were mediated largely by NMDA receptors. A fast AMPA/kainate EPSP was also detectable. These neurones have morphological and physiological properties which make them well-suited to exert a widespread inhibitory control over the efferent output of layer II to the dentate gyrus.},
	language = {eng},
	number = {1},
	journal = {Neurosci. Lett.},
	author = {Jones, R S and Buhl, E H},
	year = {1993},
	note = {Place: University Department of Pharmacology, University of Oxford, UK.},
	keywords = {merged\_fiete.bib},
	pages = {35--39},
}

@article{kahn_response_2008,
	title = {Response properties of avian hippocampal formation cells in an environment with unstable goal locations},
	volume = {191},
	number = {2},
	journal = {Behav. Brain Res.},
	author = {Kahn, Meghan C and Siegel, Jennifer J and Jechura, Tammy J and Bingman, Verner P},
	year = {2008},
	keywords = {Hippocampus, merged\_fiete.bib, Spatial cognition, Columba livia, Pigeon},
	pages = {153--163},
}

@article{kishimoto_hippocampal_2006,
	title = {Hippocampal {CA3} {NMDA} receptors are crucial for adaptive timing of trace eyeblink conditioned response},
	volume = {26},
	abstract = {Classical conditioning of the eyeblink reflex is a simple form of associative learning for motor responses. To examine the involvement of hippocampal CA3 NMDA receptors (NRs) in nonspatial associative memory, mice lacking an NR1 subunit selectively in adult CA3 pyramidal cells [CA3-NR1 knock-out (KO) mice] were subjected to eyeblink conditioning paradigms. Mice received paired presentations of an auditory conditioned stimulus (CS) and a periorbital shock unconditioned stimulus (US). With repeated presentation of the CS followed by the US, wild-type mice learned to blink in anticipation of the US before its onset. We first confirmed that wild-type mice require an intact hippocampus in the trace version of eyeblink conditioning in which the CS and US do not overlap, creating a stimulus-free time gap of 500 ms. Under the same condition, CA3-NR1 KO mice successfully acquired conditioned responses (CRs) during the 10 d acquisition sessions, whereas the extinction of CRs was impaired on the first day of extinction sessions. Importantly, CA3-NR1 KO mice were impaired in the formation of an adaptively timed CR during the first five trials in the daily acquisition sessions. The aberrantly timed CR was also observed in the extinction sessions in accordance with the impaired extinction of CRs. These results indicate that CA3-NR1 KO mice are unable to rapidly retrieve adaptive CR timing, suggesting that CA3 NRs play a crucial role in the memory of adaptive CR timing in trace conditioning.},
	language = {eng},
	number = {5},
	journal = {J. Neurosci.},
	author = {Kishimoto, Yasushi and Nakazawa, Kazu and Tonegawa, Susumu and Kirino, Yutaka and Kano, Masanobu},
	year = {2006},
	note = {Place: Department of Cellular Neurophysiology, Graduate School of Medical Science, Kanazawa University, Kanazawa 920-8640, Japan.},
	keywords = {merged\_fiete.bib},
	pages = {1562--1570},
}

@article{knierim_place_1995,
	title = {Place cells, head direction cells, and the learning of landmark stability},
	volume = {15},
	abstract = {Previous studies have shown that hippocampal place fields are controlled by the salient sensory cues in the environment, in that rotation of the cues causes an equal rotation of the place fields. We trained rats to forage for food pellets in a gray cylinder with a single salient directional cue, a white card covering 90 degrees of the cylinder wall. Half of the rats were disoriented before being placed in the cylinder, in order to disrupt their internal sense of direction. The other half were not disoriented before being placed in the cylinder; for these rats, there was presumably a consistent relationship between the cue card and their internal direction sense. We subsequently recorded hippocampal place cells and thalamic head direction cells from both groups of rats as they moved in the cylinder; between some sessions the cylinder and cue card were rotated to a new direction. All rats were disoriented before recording. Under these conditions, the cue card had much weaker control over the place fields and head direction cells in the rats that had been disoriented during training than in the rats that had not been disoriented. For the former group, the place fields often rotated relative to the cue card or completely changed their firing properties between sessions. In all recording sessions, the head direction cells and place cells were strongly coupled. It appears that the strength of cue control over place cells and head direction cells depends on the rat's learned perception of the stability of the cues.},
	language = {eng},
	number = {3 Pt 1},
	journal = {J. Neurosci.},
	author = {Knierim, J J and Kudrimoti, H S and McNaughton, B L},
	year = {1995},
	note = {Place: Arizona Research Laboratories, Division of Neural Systems, Memory, and Aging, University of Arizona, Tucson 85724.},
	keywords = {merged\_fiete.bib},
	pages = {1648--1659},
}

@article{kolton_cartesian_1995,
	title = {Cartesian representation of stimulus direction: parallel processing by two sets of giant interneurons in the cockroach},
	volume = {176},
	abstract = {The cockroach Periplaneta americana responds to wind puffs by turning away, both on the ground and when flying. While on the ground, the ventral giant interneurons (ventrals) encode the wind direction and specify turn direction, whereas while flying the dorsal giant interneurons (dorsals) appear to do so. We report here on responses of these cells to controlled wind stimuli of different directions. Using improved methods of wind stimulation and of positioning the animal revealed important principles of organization not previously observed. All six cells of largest axonal diameter on each side respond preferentially to ipsilateral winds. One of these cells, previously thought to respond non-directionally (giant interneuron 2), was found to have a restricted directional response (Fig. 3). The organization of directional coding among the ventral giant interneurons is nearly identical to that among the dorsals (Fig. 2). Each group contains, on each side, one cell that responds primarily to wind from the ipsilateral front, another primarily in the ipsilateral rear, and a third responding more broadly to ipsilateral front and rear. These results are discussed in terms of the mechanisms of directional localization by the assembly of giant interneurons.},
	language = {eng},
	number = {5},
	journal = {J. Comp. Physiol. A},
	author = {Kolton, L and Camhi, J M},
	year = {1995},
	note = {Place: Department of Cell and Animal Biology, Hebrew University, Jerusalem, Israel.},
	keywords = {Animals, Male, merged\_fiete.bib, Electrophysiology, Escape Reaction/physiology, Interneurons/cytology/*physiology, Periplaneta/*physiology, Physical Stimulation, Wind},
	pages = {691--702},
}

@article{laurent_odor_2001,
	title = {Odor encoding as an active, dynamical process: experiments, computation, and theory},
	volume = {24},
	abstract = {We examine early olfactory processing in the vertebrate and insect olfactory systems, using a computational perspective. What transformations occur between the first and second olfactory processing stages? What are the causes and consequences of these transformations? To answer these questions, we focus on the functions of olfactory circuit structure and on the role of time in odor-evoked integrative processes. We argue that early olfactory relays are active and dynamical networks, whose actions change the format of odor-related information in very specific ways, so as to refine stimulus identification. Finally, we introduce a new theoretical framework (“winnerless competition”) for the interpretation of these data.},
	language = {eng},
	journal = {Annu. Rev. Neurosci.},
	author = {Laurent, G and Stopfer, M and Friedrich, R W and Rabinovich, M I and Volkovskii, A and Abarbanel, H D},
	year = {2001},
	note = {Place: Division of Biology 139-74, California Institute of Technology, Pasadena, California 91125, USA. laurentg@caltech.edu},
	keywords = {Humans, Animals, merged\_fiete.bib, Neurological, Models, *Odors, Olfactory Pathways/physiology, Olfactory Bulb/*physiology, Smell/*physiology},
	pages = {263--297},
}

@article{lee_whole-cell_2006,
	title = {Whole-cell recordings in freely moving rats},
	volume = {51},
	abstract = {Intracellular recording, which allows direct measurement of the membrane potential and currents of individual neurons, requires a very mechanically stable preparation and has thus been limited to in vitro and head-immobilized in vivo experiments. This restriction constitutes a major obstacle for linking cellular and synaptic physiology with animal behavior. To overcome this limitation we have developed a method for performing whole-cell recordings in freely moving rats. We constructed a miniature head-mountable recording device, with mechanical stabilization achieved by anchoring the recording pipette rigidly in place after the whole-cell configuration is established. We obtain long-duration recordings (mean of approximately 20 min, maximum 60 min) in freely moving animals that are remarkably insensitive to mechanical disturbances, then reconstruct the anatomy of the recorded cells. This head-anchored whole-cell recording technique will enable a wide range of new studies involving detailed measurement and manipulation of the physiological properties of identified cells during natural behaviors.},
	language = {eng},
	number = {4},
	journal = {Neuron},
	author = {Lee, Albert K and Manns, Ian D and Sakmann, Bert and Brecht, Michael},
	year = {2006},
	note = {Place: Department of Neuroscience, Erasmus MC, Dr. Molewaterplein 50, 3015 GE Rotterdam, The Netherlands. a.lee@erasmusmc.nl},
	keywords = {merged\_fiete.bib},
	pages = {399--407},
}

@article{leutgeb_pattern_2007,
	title = {Pattern separation in the dentate gyrus and {CA3} of the hippocampus},
	volume = {315},
	abstract = {Theoretical models have long pointed to the dentate gyrus as a possible source of neuronal pattern separation. In agreement with predictions from these models, we show that minimal changes in the shape of the environment in which rats are exploring can substantially alter correlated activity patterns among place-modulated granule cells in the dentate gyrus. When the environments are made more different, new cell populations are recruited in CA3 but not in the dentate gyrus. These results imply a dual mechanism for pattern separation in which signals from the entorhinal cortex can be decorrelated both by changes in coincidence patterns in the dentate gyrus and by recruitment of nonoverlapping cell assemblies in CA3.},
	language = {eng},
	number = {5814},
	journal = {Science},
	author = {Leutgeb, Jill K and Leutgeb, Stefan and Moser, May-Britt and Moser, Edvard I},
	year = {2007},
	note = {Place: Centre for the Biology of Memory, Norwegian University of Science and Technology, 7489 Trondheim, Norway.},
	keywords = {merged\_fiete.bib},
	pages = {961--966},
}

@article{leutgeb_place_2005,
	title = {Place cells, spatial maps and the population code for memory},
	volume = {15},
	abstract = {The study of population dynamics in hippocampal place cells has emerged as one of the most powerful tools for understanding the encoding, storage and retrieval of declarative memory. Recent work has laid out the contours of an attractor-based hippocampal population code for memory in recurrent circuits of the hippocampus. The code is based on inputs from a topographically organized, path-integration-dependent spatial map that lies upstream in the medial entorhinal cortex. The recurrent networks of the hippocampal formation enable these spatial inputs to be synthesized with nonspatial event-related information.},
	language = {eng},
	number = {6},
	journal = {Curr. Opin. Neurobiol.},
	author = {Leutgeb, Stefan and Leutgeb, Jill K and Moser, May-Britt and Moser, Edvard I},
	year = {2005},
	note = {Place: Centre for the Biology of Memory, Norwegian University of Science and Technology, NO-7489 Trondheim, Norway.},
	keywords = {Humans, Animals, merged\_fiete.bib, Brain Mapping, Hippocampus/physiology, Memory/*physiology, Nerve Net/physiology, Brain/cytology/*physiology},
	pages = {738--746},
}

@article{lopez-barneo_neuronal_1982,
	title = {Neuronal activity in prepositus nucleus correlated with eye movement in the alert cat},
	volume = {47},
	abstract = {1. In nine alert chronically prepared cats the activity of 177 neurons was recorded in the prepositus nucleus during either spontaneous eye movement or that induced by natural vestibular and optokinetic stimulation. 2. In 116 cells, eye position and/or eye velocity was precisely and unequivocally encoded whatever the origin of the eye movement. These cells were separated into different populations according to the eye movement variable encoded and the directionality of the neuronal response. The firing rates of the remaining 61 cells were loosely related to eye movements because a variety of discharge patterns were observed during identical eye movements. In the latter case, some other unmeasured variable (e.g., neck or visual) was suggested to be encoded in the firing frequency. 3. Discharge rate changed before the eyes began to move and reached a new steady level during fixation following a saccade into a particular direction of the orbit. The ondirection was horizontal for 59\% of the neurons, vertical for 17\%, and oblique for 24\%. 4. Regardless of their preferred direction, the discharge rate in 19\% of the neurons was closely proportional to eye position. The range in sensitivity was from 1.1 to 7.5 spikes X s-1/deg. Weak velocity responses were occasionally observed during the slow phase of vestibular and optokinetic nystagmus including during saccades. This class of neurons exhibited a very regular interspike interval for a given position of fixation. Since mainly eye position was encoded, these cells were called position neurons. 5. Other prepositus neurons showed both position and velocity sensitivity during saccades and fixation. Their firing rate encoded eye position over the same range as above and also coded velocity during the slow phase of vestibular and optokinetic nystagmus. Depending on the weighting between the position and velocity proportionality constants, these neurons were classified into position-velocity (48\%) or velocity-position (33\%) groups. 6. The distribution of the above responses led to the conclusion that the prepositus nucleus plays a role in vertical and horizontal spatial integration. The predominance of horizontal activity suggested that the nucleus may be a significant site underlying genesis of horizontal eye position.},
	language = {eng},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Lopez-Barneo, J and Darlot, C and Berthoz, A and Baker, R},
	year = {1982},
	keywords = {Animals, merged\_fiete.bib, Neurons/*physiology, Cats, Brain/*physiology, Visual, Photic Stimulation, Evoked Potentials, *Eye Movements, Oculomotor Nerve/physiology, Sensory Thresholds, Visual Perception},
	pages = {329--352},
}

@article{louie_temporally_2001,
	title = {Temporally structured replay of awake hippocampal ensemble activity during rapid eye movement sleep},
	volume = {29},
	abstract = {Human dreaming occurs during rapid eye movement (REM) sleep. To investigate the structure of neural activity during REM sleep, we simultaneously recorded the activity of multiple neurons in the rat hippocampus during both sleep and awake behavior. We show that temporally sequenced ensemble firing rate patterns reflecting tens of seconds to minutes of behavioral experience are reproduced during REM episodes at an equivalent timescale. Furthermore, within such REM episodes behavior-dependent modulation of the subcortically driven theta rhythm is also reproduced. These results demonstrate that long temporal sequences of patterned multineuronal activity suggestive of episodic memory traces are reactivated during REM sleep. Such reactivation may be important for memory processing and provides a basis for the electrophysiological examination of the content of dream states.},
	language = {eng},
	number = {1},
	journal = {Neuron},
	author = {Louie, K and Wilson, M A},
	year = {2001},
	note = {Place: Department of Biology, Department of Brain and Cognitive Sciences, Center for Learning and Memory, RIKEN-MIT Neuroscience Research Center, Massachusetts Institute of Technology, Cambridge, MA 02139, USA.},
	keywords = {merged\_fiete.bib},
	pages = {145--156},
}

@article{maaswinkel_hippocampectomized_1999,
	title = {Hippocampectomized rats are impaired in homing by path integration},
	volume = {9},
	abstract = {Theoretical, behavioral, and electrophysiologic evidence suggests that the hippocampal formation may play a role in path integration, a form of spatial navigation in which an animal can return to a starting point by integrating self-movement cues generated on its outward journey. The present study examined whether the hippocampus (Ammon's horn and the dentate gyrus) is involved in this form of spatial behavior. Control rats and rats with selective ibotenic acid lesions of the hippocampus were tested in a foraging task in which they retrieved large food pellets from an open field, which when found, they carried to a refuge for consumption. The experiments measured the rats' homing accuracy, returning to the starting location, under conditions in which visual, surface, and self-movement cues; surface and self-movement cues; or only self-movement cues were available. Although both control rats and rats without a hippocampus could use visual and surface cues, only control rats appeared to be able to use self-movement cues. The finding that hippocampal rats are impaired under conditions requiring the use of self-movement cues suggests that the hippocampus plays an essential role in path integration.},
	language = {eng},
	number = {5},
	journal = {Hippocampus},
	author = {Maaswinkel, H and Jarrard, L E and Whishaw, I Q},
	year = {1999},
	note = {Place: Department of Psychology and Neuroscience, University of Lethbridge, Alberta, Canada.},
	keywords = {Animals, Rats, Male, merged\_fiete.bib, Spatial Behavior/*physiology, Cues, Orientation/*physiology, Long-Evans, Dentate Gyrus/physiology, Motor Activity, Visual Perception, Hippocampus/drug effects/pathology/*physiology, Ibotenic Acid/toxicity, Regression Analysis, Video Recording},
	pages = {553--561},
}

@article{markram_regulation_1997,
	title = {Regulation of synaptic efficacy by coincidence of postsynaptic {APs} and {EPSPs}},
	volume = {275},
	abstract = {Activity-driven modifications in synaptic connections between neurons in the neocortex may occur during development and learning. In dual whole-cell voltage recordings from pyramidal neurons, the coincidence of postsynaptic action potentials (APs) and unitary excitatory postsynaptic potentials (EPSPs) was found to induce changes in EPSPs. Their average amplitudes were differentially up- or down-regulated, depending on the precise timing of postsynaptic APs relative to EPSPs. These observations suggest that APs propagating back into dendrites serve to modify single active synaptic connections, depending on the pattern of electrical activity in the pre- and postsynaptic neurons.},
	language = {eng},
	number = {5297},
	journal = {Science},
	author = {Markram, H and Lubke, J and Frotscher, M and Sakmann, B},
	month = jan,
	year = {1997},
	note = {Place: Max-Planck-Institut fur Medizinische Forschung, Abteilung Zellphysiologie, Jahnstrasse 29, D-69120 Heidelberg, Germany. bnmark@weizmann.weizmann.ac.il},
	keywords = {merged\_fiete.bib},
	pages = {213--215},
}

@article{markus_interactions_1995,
	title = {Interactions between location and task affect the spatial and directional firing of hippocampal neurons},
	volume = {15},
	abstract = {When rats forage for randomly dispersed food in a high walled cylinder the firing of their hippocampal “place” cells exhibits little dependence on the direction faced by the rat. On radial arm mazes and similar tasks, place cells are strongly directionally selective within their fields. These tasks differ in several respects, including the visual environment, configuration of the traversable space, motor behavior (e.g., linear and angular velocities), and behavioral context (e.g., presence of specific, consistent goal locations within the environment). The contributions of these factors to spatial and directional tuning of hippocampal neurons was systematically examined in rats performing several tasks in either an enriched or a sparse visual environment, and on different apparati. Place fields were more spatially and directionally selective on a radial maze than on an open, circular platform, regardless of the visual environment. On the platform, fields were more directional when the rat searched for food at fixed locations, in a stereotypic and directed manner, than when the food was scattered randomly. Thus, it seems that place fields are more directional when the animal is planning or following a route between points of special significance. This might be related to the spatial focus of the rat's attention (e.g., a particular reference point). Changing the behavioral task was also accompanied by a change in firing location in about one-third of the cells. Thus, hippocampal neuronal activity appears to encode a complex interaction between locations, their significance and the behaviors the rat is called upon to execute.},
	language = {eng},
	number = {11},
	journal = {J. Neurosci.},
	author = {Markus, E J and Qin, Y L and Leonard, B and Skaggs, W E and McNaughton, B L and Barnes, C A},
	year = {1995},
	note = {Place: ARL Division of Neural Systems, University of Arizona, Tucson 85724, USA.},
	keywords = {Animals, Rats, Male, merged\_fiete.bib, Animal/physiology, Behavior, Neurons/*physiology, Hippocampus/cytology/*physiology, Brain Mapping, Environment, Space Perception/*physiology, Inbred F344, Electrophysiology, Maze Learning/physiology},
	pages = {7079--7094},
}

@article{mcnaughton_deciphering_1996,
	title = {Deciphering the hippocampal polyglot: the hippocampus as a path integration system},
	volume = {199},
	abstract = {Hippocampal 'place' cells and the head-direction cells of the dorsal presubiculum and related neocortical and thalamic areas appear to be part of a preconfigured network that generates an abstract internal representation of two-dimensional space whose metric is self-motion. It appears that viewpoint-specific visual information (e.g. landmarks) becomes secondarily bound to this structure by associative learning. These associations between landmarks and the preconfigured path integrator serve to set the origin for path integration and to correct for cumulative error. In the absence of familiar landmarks, or in darkness without a prior spatial reference, the system appears to adopt an initial reference for path integration independently of external cues. A hypothesis of how the path integration system may operate at the neuronal level is proposed.},
	language = {eng},
	number = {Pt 1},
	journal = {J. Exp. Biol.},
	author = {McNaughton, B L and Barnes, C A and Gerrard, J L and Gothard, K and Jung, M W and Knierim, J J and Kudrimoti, H and Qin, Y and Skaggs, W E and Suster, M and Weaver, K L},
	year = {1996},
	note = {Place: Arizona Research Laboratories, University of Arizona, Tucson 85724, USA.},
	keywords = {Animals, Rats, merged\_fiete.bib, Cognition/*physiology, Hippocampus/*physiology, Space Perception/*physiology, Neuronal Plasticity, Visual Pathways/*physiology, Movement/*physiology, Head/*physiology},
	pages = {173--185},
}

@article{mcnaughton_contributions_1983,
	title = {The contributions of position, direction, and velocity to single unit activity in the hippocampus of freely-moving rats},
	volume = {52},
	abstract = {Isolated single units in rat dorsal hippocampus and fascia dentata were classified as 'Theta' or 'Complex-Spike' cells, and their firing characteristics were examined with respect to position, direction and velocity of movement during forced choice, food rewarded search behavior on a radial eight arm maze. Most spikes from CS cells occurred when the animal was located within a particular place on the maze and moving in a particular direction. Theta cells had very low spatial selectivity. Both cell categories had discharge probabilities which increased somewhat as a function of running velocity but tended to asymptote well before half-maximal velocity. The place/direction specificity of CS cells was significantly higher in CA1 than in CA3 and CA3 CS cells exhibited a striking preference for the inward radial direction. The pronounced directional selectivity of CS cells, at least in the present environment, suggests that they fire in response to complex, but specific, stimulus features in the extramaze world rather than to absolute place in a non-egocentric space. An alternative possibility is that the geometrical constraints of the maze surface have a profound influence on the shapes of the response fields of CS cells.},
	language = {eng},
	number = {1},
	journal = {Exp. Brain Res.},
	author = {McNaughton, B L and Barnes, C A and O'Keefe, J},
	year = {1983},
	keywords = {Animals, Rats, Male, merged\_fiete.bib, Neurons/*physiology, Hippocampus/cytology/*physiology, Inbred F344, Motor Activity/*physiology, Electrophysiology},
	pages = {41--49},
}

@article{mcnaughton_path_2006,
	title = {Path integration and the neural basis of the `cognitive map'},
	volume = {7},
	abstract = {The hippocampal formation can encode relative spatial location, without reference to external cues, by the integration of linear and angular self-motion (path integration). Theoretical studies, in conjunction with recent empirical discoveries, suggest that the medial entorhinal cortex (MEC) might perform some of the essential underlying computations by means of a unique, periodic synaptic matrix that could be self-organized in early development through a simple, symmetry-breaking operation. The scale at which space is represented increases systematically along the dorsoventral axis in both the hippocampus and the MEC, apparently because of systematic variation in the gain of a movement-speed signal. Convergence of spatially periodic input at multiple scales, from so-called grid cells in the entorhinal cortex, might result in non-periodic spatial firing patterns (place fields) in the hippocampus.},
	language = {eng},
	number = {8},
	journal = {Nat. Rev. Neurosci.},
	author = {McNaughton, Bruce L and Battaglia, Francesco P and Jensen, Ole and Moser, Edvard I and Moser, May-Britt},
	year = {2006},
	note = {Place: Arizona Research Laboratories Division of Neural Systems, Memory \& Aging, and Department of Psychology, University of Arizona, Tucson 85724, USA. bruce@nsma.arizona.edu},
	keywords = {Humans, Animals, merged\_fiete.bib, Brain Mapping/*methods, Cognition/*physiology, Hippocampus/*physiology, Nerve Net/*physiology, Neural Pathways/physiology},
	pages = {663--678},
}

@article{mehta_role_2002,
	title = {Role of experience and oscillations in transforming a rate code into a temporal code},
	volume = {417},
	abstract = {In the vast majority of brain areas, the firing rates of neurons, averaged over several hundred milliseconds to several seconds, can be strongly modulated by, and provide accurate information about, properties of their inputs. This is referred to as the rate code. However, the biophysical laws of synaptic plasticity require precise timing of spikes over short timescales ({\textless}10 ms). Hence it is critical to understand the physiological mechanisms that can generate precise spike timing in vivo, and the relationship between such a temporal code and a rate code. Here we propose a mechanism by which a temporal code can be generated through an interaction between an asymmetric rate code and oscillatory inhibition. Consistent with the predictions of our model, the rate and temporal codes of hippocampal pyramidal neurons are highly correlated. Furthermore, the temporal code becomes more robust with experience. The resulting spike timing satisfies the temporal order constraints of hebbian learning. Thus, oscillations and receptive field asymmetry may have a critical role in temporal sequence learning.},
	language = {eng},
	number = {6890},
	journal = {Nature},
	author = {Mehta, M R and Lee, A K and Wilson, M A},
	year = {2002},
	note = {Place: Center for Learning \& Memory, Department of Brain \& Cognitive Sciences, RIKEN-MIT Neuroscience Center, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA. mayank@mit.edu},
	keywords = {merged\_fiete.bib},
	pages = {741--746},
}

@article{meister_wireless_2007,
	title = {Wireless {Recording} from {Rat} {Hippocampus}},
	journal = {(Poster) Computational and Systems Neuroscience (COSYNE)},
	author = {Meister, Markus and Szuts, Tobi A and Grivich, Matthew I and Sher, Alexander and Kachiguine, Sergei and Lubenov, Evgueniy V and Siapas, Athanassios G and Litke, Alan},
	year = {2007},
	keywords = {merged\_fiete.bib},
}

@article{mitchell_generation_1980,
	title = {Generation of theta rhythm in medial entorhinal cortex of freely moving rats},
	volume = {189},
	abstract = {A regular slow wave theta rhythm can be recorded in the medial entorhinal cortex (MEC) of freely moving rats during voluntary behaviors and paradoxical sleep. Electrode penetrations normal to the cortical layers proceeding from the deeper to the more superficial layers reveal a continuous theta rhythm in layers IV-III (deep MEC theta rhythm) with an amplitude maximum in layer III, a null between the outer one-third of layer III and the inner one-half of layer I, and a continuous phase-reversed theta rhythm in layers II-I (superficial MEC theta rhythm) with an amplitude maximum there. Deep MEC theta rhythm is similar in phase and wave shape to CA1 theta rhythm; superficial MEC theta rhythm is similar in phase to DG theta rhythm. Laminar profiles throughout MEC show that the theta rhythm is generated there; it is not volume conducted from hippocampus.},
	language = {eng},
	number = {1},
	journal = {Brain Res.},
	author = {Mitchell, S J and Ranck, Jr, J B},
	year = {1980},
	keywords = {Animals, Sleep, Rats, Male, Movement, merged\_fiete.bib, Hippocampus/physiology, *Theta Rhythm, Cerebral Cortex/physiology, Brain/anatomy \& histology/*physiology, Microelectrodes, *Electroencephalography, REM},
	pages = {49--66},
}

@article{molter_organization_2007,
	title = {Organization of hippocampal place cells by enthorinal cortex grid cells. {A} functional role for the phase precession mechanism},
	journal = {Proc. Int. Jt. Conf. Neural Netw.},
	author = {Molter, C and Yamaguchi, Y},
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {944--949},
}

@article{morris_place_1982,
	title = {Place navigation impaired in rats with hippocampal lesions},
	volume = {297},
	language = {eng},
	number = {5868},
	journal = {Nature},
	author = {Morris, R G and Garrud, P and Rawlins, J N and O'Keefe, J},
	year = {1982},
	keywords = {merged\_fiete.bib},
	pages = {681--683},
}

@article{moser_spatial_1993,
	title = {Spatial learning impairment parallels the magnitude of dorsal hippocampal lesions, but is hardly present following ventral lesions},
	volume = {13},
	abstract = {The hippocampus plays an essential role in spatial learning. To investigate whether the whole structure is equally important, we compared the effects of variously sized and localized hippocampal aspiration lesions on spatial learning in a Morris water maze. The volume of all hippocampal lesions was determined. Dorsal hippocampal lesions consistently impaired spatial learning more than equally large ventral lesions. The dorsal lesions had to be larger than 20\% of the total hippocampal volume to prolong final escape latencies. The acquisition rate and precision on a probe test without platform were sensitive to even smaller dorsal lesions. The degree of impairment correlated with the lesion volume. In contrast, the lesions of the ventral half of the hippocampus spared both the rate and the precision of learning unless nearly all of the ventral half was removed. There was no significant effect of the location (dorsal or ventral) of damage to the overlying neocortex only. In conclusion, the dorsal half of the hippocampus appears more important for spatial learning than the ventral half. The spatial learning ability seems related to the amount of damaged dorsal hippocampal tissue, with a threshold at about 20\% of the total hippocampal volume, under which normal learning can occur.},
	language = {eng},
	number = {9},
	journal = {J. Neurosci.},
	author = {Moser, E and Moser, M B and Andersen, P},
	year = {1993},
	note = {Place: Department of Neurophysiology, University of Oslo, Norway.},
	keywords = {merged\_fiete.bib},
	pages = {3916--3925},
}

@article{moser_spatial_1995,
	title = {Spatial learning with a minislab in the dorsal hippocampus},
	volume = {92},
	abstract = {We have determined the volume and location of hippocampal tissue required for normal acquisition of a spatial memory task. Ibotenic acid was used to make bilateral symmetric lesions of 20-100\% of hippocampal volume. Even a small transverse block (minislab) of the hippocampus (down to 26\% of the total) could support spatial learning in a water maze, provided it was at the septal (dorsal) pole of the hippocampus. Lesions of the septal pole, leaving 60\% of the hippocampi intact, caused a learning deficit, although normal electrophysiological responses, synaptic plasticity, and preserved acetylcholinesterase staining argue for adequate function of the remaining tissue. Thus, with an otherwise normal brain, hippocampal-dependent spatial learning only requires a minislab of dorsal hippocampal tissue.},
	language = {eng},
	number = {21},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Moser, M B and Moser, E I and Forrest, E and Andersen, P and Morris, R G},
	year = {1995},
	note = {Place: Centre for Neuroscience, University of Edinburgh, United Kingdom.},
	keywords = {merged\_fiete.bib},
	pages = {9697--9701},
}

@article{muller_spatial_1987,
	title = {Spatial firing patterns of hippocampal complex-spike cells in a fixed environment},
	volume = {7},
	abstract = {A TV/computer technique was used to simultaneously track a rat's position in a simple apparatus and record the firing of single hippocampal complex-spike neurons. The primary finding is that many of these neurons behave as “place cells,” as first described by O'Keefe and Dostrovsky (1971) and O'Keefe (1976). Each place cell fires rapidly only when the rat is in a delimited portion of the apparatus (the cell's “firing field”). In agreement with O'Keefe (1976) and many other authors, we have seen that the firing of place cells is highly correlated with the animal's position and is remarkably independent of other aspects of the animal's behavioral state. Several properties of firing fields were characterized. Firing fields are stable over long time intervals (days) if the environment is constant. They come in several shapes when the animal is in a cylindrical apparatus; moreover, the set of field shapes is different when the animal is in a rectangular apparatus. It also seems that a single cell may have more than one field in a given apparatus. By collecting a sample of 40 place cells in a fixed environment, it has been possible to describe certain features of the place cell population, including the spatial distribution of fields within the apparatus, the average size of fields, and the “intensity” of fields (as measured by maximum firing rate). We also tested the hypothesis that the firing rate of each place cell signals the animal's distance from a point (the field center) so that a weighted average of the firing of the individual cells encodes the animal's position within the apparatus. The animal's position, calculated according to this “distance hypothesis,” is systematically different from the animal's true position; this implies that the hypothesis in its simplest form is wrong.},
	language = {eng},
	number = {7},
	journal = {J. Neurosci.},
	author = {Muller, R U and Kubie, J L and Ranck, Jr, J B},
	year = {1987},
	keywords = {Animals, Action Potentials, Rats, Female, merged\_fiete.bib, Hippocampus/cytology/*physiology, Orientation/physiology, Motor Activity/*physiology, Neurons/classification/physiology, Automatic Data Processing, Computer Systems, Television},
	pages = {1935--1950},
}

@article{okeefe_hippocampal_1999,
	title = {Do hippocampal pyramidal cells signal non-spatial as well as spatial information?},
	volume = {9},
	abstract = {It is generally agreed that the rat hippocampus is involved in spatial memory. Whether this is its sole or primary function, or merely one component of a broader function, is still debated. It has been suggested, for example, that the hippocampus stores information about flexible relations between stimuli, both spatial and non-spatial. In this paper, I reiterate the basic tenet of the cognitive map theory that the processing and storage of spatial information is the primary and perhaps the exclusive role of the hippocampus in the rat, and that data that appear to contradict this have been misinterpreted. These data are found in reports of non-spatial correlates of unit activity recorded in the awake animals and reports of deficits on non-spatial tasks following hippocampal lesions. In this paper, I examine both claims and suggest alternative explanations of the data. The first part of the paper contains a review of some of the properties of hippocampal place cells, which might be misinterpreted as non-spatial in “non-spatial” tasks. For example, if an animal is trained to carry out a sequence of stereotyped actions in different parts of an environment, there will be a strong correlation between the performance of each behaviour and the animal's location, and it is necessary to rule out the locational correlate as the cause of the firing pattern. The second part of the paper looks at the results of experiments on conditioning and non-spatial discrimination tasks and concludes that the results are less supportive of a more general relational theory of hippocampal function than has been suggested. Furthermore, there is often a discrepancy between the correlates of unit firing in non-spatial tasks and the absence of an effect of hippocampal damage on these same or similar tasks. It is concluded that, contrary to the claims of its detractors, the cognitive map theory is still the theory of hippocampal function that is most clearly specified, makes the most testable predictions, and for which there is the strongest experimental support.},
	language = {eng},
	number = {4},
	journal = {Hippocampus},
	author = {O'Keefe, J},
	year = {1999},
	note = {Place: Department of Anatomy and Developmental Biology, University College London, United Kingdom. j.okeefe@ucl.ac.uk},
	keywords = {merged\_fiete.bib},
	pages = {352--364},
}

@article{okeefe_dual_2005,
	title = {Dual phase and rate coding in hippocampal place cells: theoretical significance and relationship to entorhinal grid cells},
	volume = {15},
	abstract = {We review the ideas and data behind the hypothesis that hippocampal pyramidal cells encode information by their phase of firing relative to the theta rhythm of the EEG. Particular focus is given to the further hypothesis that variations in firing rate can encode information independently from that encoded by firing phase. We discuss possible explanation of the phase-precession effect in terms of interference between two independent oscillatory influences on the pyramidal cell membrane potential, and the extent to which firing phase reflects internal dynamics or external (environmental) variables. Finally, we propose a model of the firing of the recently discovered “grid cells” in entorhinal cortex as part of a path-integration system, in combination with place cells and head-direction cells.},
	language = {eng},
	number = {7},
	journal = {Hippocampus},
	author = {O'Keefe, John and Burgess, Neil},
	year = {2005},
	note = {Place: Department of Anatomy and Developmental Biology, University College London. j.okeefe@ucl.ac.uk},
	keywords = {Humans, Animals, merged\_fiete.bib, Hippocampus/*physiology, Neurons/*physiology, Space Perception/physiology, Orientation/physiology, Synaptic Transmission/physiology, *Theta Rhythm, Action Potentials/*physiology, Entorhinal Cortex/*physiology, Biological Clocks/physiology},
	pages = {853--866},
}

@article{okeefe_geometric_1996,
	title = {Geometric determinants of the place fields of hippocampal neurons},
	volume = {381},
	abstract = {The human hippocampus has been implicated in memory, in particular episodic or declarative memory. In rats, hippocampal lesions cause selective spatial deficits, and hippocampal complex spike cells (place cells) exhibit spatially localized firing, suggesting a role in spatial memory, although broader functions have also been suggested. Here we report the identification of the environmental features controlling the location and shape of the receptive fields (place fields) of the place cells. This was done by recording from the same cell in four rectangular boxes that differed solely in the length of one or both sides. Most of our results are explained by a model in which the place field is formed by the summation of gaussian tuning curves, each oriented perpendicular to a box wall and peaked at a fixed distance from it.},
	language = {eng},
	number = {6581},
	journal = {Nature},
	author = {O'Keefe, J and Burgess, N},
	year = {1996},
	note = {Place: Department of Anatomy, University College London, UK.},
	keywords = {Animals, Rats, Electroencephalography, merged\_fiete.bib, Neurological, Models, Space Perception/*physiology, Pyramidal Cells/*physiology, Hippocampus/anatomy \& histology/cytology/*physiology},
	pages = {425--428},
}

@article{okeefe_hippocampus_1971,
	title = {The hippocampus as a spatial map. {Preliminary} evidence from unit activity in the freely-moving rat},
	volume = {34},
	language = {eng},
	number = {1},
	journal = {Brain Res.},
	author = {O'Keefe, J and Dostrovsky, J},
	year = {1971},
	keywords = {Animals, Vision, Sleep, Rats, merged\_fiete.bib, Hippocampus/*physiology, Behavior, Neurons/*physiology, Cues, Electrodes, Implanted, *Orientation, Electrophysiology, Locomotion, Animal, Cognition, Light, Motor Activity, Acoustics, Arousal, Feeding Behavior, Grooming, Hearing, Homing Behavior, Limbic System/physiology, Odors, Smell, Touch},
	pages = {171--175},
}

@article{okeefe_phase_1993,
	title = {Phase relationship between hippocampal place units and the {EEG} theta rhythm},
	volume = {3},
	abstract = {Many complex spike cells in the hippocampus of the freely moving rat have as their primary correlate the animal's location in an environment (place cells). In contrast, the hippocampal electroencephalograph theta pattern of rhythmical waves (7-12 Hz) is better correlated with a class of movements that change the rat's location in an environment. During movement through the place field, the complex spike cells often fire in a bursting pattern with an interburst frequency in the same range as the concurrent electroencephalograph theta. The present study examined the phase of the theta wave at which the place cells fired. It was found that firing consistently began at a particular phase as the rat entered the field but then shifted in a systematic way during traversal of the field, moving progressively forward on each theta cycle. This precession of the phase ranged from 100 degrees to 355 degrees in different cells. The effect appeared to be due to the fact that individual cells had a higher interburst rate than the theta frequency. The phase was highly correlated with spatial location and less well correlated with temporal aspects of behavior, such as the time after place field entry. These results have implications for several aspects of hippocampal function. First, by using the phase relationship as well as the firing rate, place cells can improve the accuracy of place coding. Second, the characteristics of the phase shift constrain the models that define the construction of place fields. Third, the results restrict the temporal and spatial circumstances under which synapses in the hippocampus could be modified.},
	language = {eng},
	number = {3},
	journal = {Hippocampus},
	author = {O'Keefe, J and Recce, M L},
	year = {1993},
	note = {Place: Department of Anatomy and Developmental Biology, University College London, U.K.},
	keywords = {merged\_fiete.bib},
	pages = {317--330},
}

@article{pan_supramammillary_2004,
	title = {The supramammillary area: it's organization, functions, and relationship to the hippocampus},
	volume = {74},
	journal = {Prog. Neurobiol.},
	author = {Pan, W X and McNaughton, B L},
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {127--166},
}

@article{parron_evidence_2004,
	title = {Evidence for entorhinal and parietal cortices involvement in path integration in the rat},
	volume = {159},
	abstract = {Rats with lesions of the entorhinal or parietal cortex were tested in a homing task on a circular platform containing food cups and surrounded by curtains. The animals had to leave a refuge, explore the platform to find a hidden piece of food and carry it back to the refuge. Once the rats were proficient at performing the procedural aspects of the task, they were tested in two successive types of trials in which the food pellet was either always located in the central cup (food at center, “FAC” trials) or placed in a randomly chosen cup (food at random, “FAR” trials). Except in the first FAC trials, all groups displayed similar outward paths in FAC and FAR trials, showing that both types of trials involved equivalent path integration demand. Analysis of the homing accuracy showed that rats with entorhinal cortex or parietal cortex lesions exhibited inaccurate returns to the starting hole, suggesting that these two cortical areas are part of a neural network mediating path integration.},
	language = {eng},
	number = {3},
	journal = {Exp. Brain Res.},
	author = {Parron, Carole and Save, Etienne},
	year = {2004},
	note = {Place: Laboratory of Neurobiology and Cognition, CNRS-Universite de Provence, 31 chemin Joseph-Aiguier, 13402 Marseille Cedex 20, France.},
	keywords = {Animals, Rats, Male, Time Factors, merged\_fiete.bib, Behavior, Spatial Behavior/*physiology, Space Perception/physiology, Long-Evans, Orientation/physiology, Animal, Parietal Lobe/anatomy \& histology/*physiology, Movement/*physiology, Homing Behavior/*physiology, Entorhinal Cortex/anatomy \& histology/*physiology, Chi-Square Distribution, Feeding Behavior/physiology, Random Allocation},
	pages = {349--359},
}

@article{parsons_temporary_2008,
	title = {Temporary inactivation of dorsal hippocampus attenuates explicitly nonspatial, unimodal, contextual fear conditioning},
	volume = {In press.},
	abstract = {The current study examined the effects of temporary inactivation of the DH on freezing, rearing, ambulating, grooming, and whisking behavior in an explicitly nonspatial contextual fear conditioning paradigm in which olfactory stimuli served as temporally and spatially diffuse contexts. Prior either to training, testing, or both, male Sprague-Dawley rats received bilateral microinfusions of saline or the GABA(A) agonist muscimol into the DH. Results indicate that temporary inactivation of DH produced both anterograde and retrograde deficits in contextually conditioned freezing, while sparing the acquisition and expression of freezing to a discrete auditory or olfactory CS. These data suggest that there is a decidedly nonspatial component to the role of DH in contextual conditioning, and that olfactory contextual conditioning is a fruitful means of further exploring this function.},
	language = {ENG},
	journal = {Neurobiol. Learn. Mem.},
	author = {Parsons, T C and Otto, T},
	year = {2008},
	note = {Place: Program in Behavioral Neuroscience, Department of Psychology, Rutgers, The State University of New Jersey, New Brunswick, NJ 08903, USA.},
	keywords = {merged\_fiete.bib},
}

@article{pastor_discharge_1991,
	title = {Discharge characteristics of medial rectus and abducens motoneurons in the goldfish},
	volume = {66},
	abstract = {1. The discharge of antidromically identified medial rectus and abducens motoneurons was recorded in restrained unanesthesized goldfish during spontaneous eye movements and in response to vestibular and optokinetic stimulation. 2. All medial rectus and abducens motoneurons exhibited a similar discharge pattern. A burst of spikes accompanied spontaneous saccades and fast phases during vestibular and optokinetic nystagmus in the ON-direction. Firing rate decreased for the same eye movements in the OFF-direction. All units showed a steady firing rate proportional to eye position beyond their recruitment threshold. 3. Motoneuronal position (ks) and velocity (rs) sensitivity for spontaneous eye movements were calculated from the slope of the rate-position and rate-velocity linear regression lines, respectively. The averaged ks and rs values of medial rectus motoneurons were higher than those of abducens motoneurons. The differences in motoneuronal sensitivity coupled with structural variations in the lateral versus the medial rectus muscle suggest that symmetric nasal and temporal eye movements are preserved by different motor unit composition. Although the abducens nucleus consists of distinct rostral and caudal subgroups, mean ks and rs values were not significantly different between the two populations. 4. Every abducens and medial rectus motoneuron fired an intense burst of spikes during its corresponding temporal or nasal activation phase of the “eye blink.” This eye movement consisted of a sequential, rather than a synergic, contraction of both vertical and horizontal extraocular muscles. The eye blink could act neither as a protective reflex nor as a goal-directed eye movement because it could not be evoked in response to sensory stimuli. We propose a role for the blink in recentering eye position. 5. Motoneuronal firing rate after ON-directed saccades decreased exponentially before reaching the sustained discharge proportional to the new eye position. Time constants of the exponential decay ranged from 50 to 300 ms. Longer time constants after the saccade were associated with backward drifts of eye position and shorter time constants with onward drifts. These postsaccadic slide signals are suggested to encode the transition of eye position to the new steady level. 6. Motoneurons modulated sinusoidally in response to sinusoidal head rotation in the dark, but for a part of the cycle they went into cutoff, dependent on their eye position recruitment threshold. Eye position (kv) and velocity (rv) sensitivity during vestibular stimulation were measured at frequencies between 1/16 and 2 Hz. Motoneuronal time constants (tau v = rv/kv) decreased on the average by 25\% with the frequency of vestibular stimulation.(ABSTRACT TRUNCATED AT 400 WORDS)},
	language = {eng},
	number = {6},
	journal = {J. Neurophysiol.},
	author = {Pastor, A M and Torres, B and Delgado-Garcia, J M and Baker, R},
	year = {1991},
	note = {Place: Departamento de Fisiologia y Biologia Animal, Facultad de Biologia, Universidad de Sevilla, Spain.},
	keywords = {merged\_fiete.bib},
	pages = {2125--2140},
}

@article{perez-orive_oscillations_2002,
	title = {Oscillations and sparsening of odor representations in the mushroom body},
	volume = {297},
	abstract = {In the insect olfactory system, oscillatory synchronization is functionally relevant and reflects the coherent activation of dynamic neural assemblies. We examined the role of such oscillatory synchronization in information transfer between networks in this system. The antennal lobe is the obligatory relay for olfactory afferent signals and generates oscillatory output. The mushroom body is responsible for formation and retrieval of olfactory and other memories. The format of odor representations differs significantly across these structures. Whereas representations are dense, dynamic, and seemingly redundant in the antennal lobe, they are sparse and carried by more selective neurons in the mushroom body. This transformation relies on a combination of oscillatory dynamics and intrinsic and circuit properties that act together to selectively filter and synthesize the output from the antennal lobe. These results provide direct support for the functional relevance of correlation codes and shed some light on the role of oscillatory synchronization in sensory networks.},
	language = {eng},
	number = {5580},
	journal = {Science},
	author = {Perez-Orive, Javier and Mazor, Ofer and Turner, Glenn C and Cassenaer, Stijn and Wilson, Rachel I and Laurent, Gilles},
	year = {2002},
	note = {Place: Division of Biology, 139-74, California Institute of Technology, Pasadena, CA 91125, USA.},
	keywords = {Animals, Action Potentials, Male, Time Factors, Female, merged\_fiete.bib, Neurons/*physiology, Electrodes, Nerve Net/*physiology, Patch-Clamp Techniques, Interneurons/physiology, Neural Inhibition, Excitatory Postsynaptic Potentials, Evoked Potentials, *Odors, Smell/*physiology, Synaptic Transmission, Electric Stimulation, gamma-Aminobutyric Acid/physiology, Grasshoppers, Mushroom Bodies/*cytology/*physiology, Picrotoxin/pharmacology},
	pages = {359--365},
}

@article{quirk_firing_1990,
	title = {The firing of hippocampal place cells in the dark depends on the rat's recent experience},
	volume = {10},
	abstract = {Hippocampal “place cells” fire when a freely moving rat is in a given location. The firing of these cells is controlled by visual and nonvisual environmental cues. The effects of darkness on the firing of place cells was studied using the task of Muller et al. (1987), in which rats were trained to chase randomly scattered food pellets in a cylindrical drum with a white cue-card attached to the wall. The position of the rats was tracked via an infrared LED on the headstage with a video system linked to computer. Two experimental protocols were used: in the first, lights were turned off after the rat had already been placed in the chamber; in the second, the rat was placed in the darkened chamber. The dark segments produced by these 2 methods were identical with respect to light and other cues but differed with respect to the rat's experience. The firing patterns of 24 of 28 cells were unaffected by darkness when it was preceded by a light period. In contrast, the firing patterns of 14 of 22 cells changed dramatically when the rats were put into the darkened chamber. Furthermore, the majority of cells that changed their firing pattern in initial darkness maintained that change when the lights were turned on. These results show that place cells can fire differently in identical cue situations and that the best predictor of firing pattern is a combination of current cues and the rat's recent experience. The results are discussed in terms of mnemonic properties of hippocampal cells and “remapping” of place cell representations.},
	language = {eng},
	number = {6},
	journal = {J. Neurosci.},
	author = {Quirk, G J and Muller, R U and Kubie, J L},
	year = {1990},
	note = {Place: Department of Physiology, State University of New York, Brooklyn 11203.},
	keywords = {merged\_fiete.bib},
	pages = {2008--2017},
}

@article{redish_hippocampal_2001,
	title = {The hippocampal debate: are we asking the right questions?},
	volume = {127},
	abstract = {For years, the debate has been: {\textbackslash}textbackslashtt“Is the hippocampus the cognitive map?{\textbackslash}textbackslashtt” or “Is the hippocampus the core of memory?” These two hypotheses derived their original power from two key experiments–the cognitive map theory from the remarkable spatial correlates seen in recordings of hippocampal pyramidal cells and the memory theory from the profound amnesias seen in the patient H.M. Both of these key experiments have been reinterpreted over the years: hippocampal cells are correlated with much more than place and H.M. is missing much more than just his hippocampus. However, both theories are still debated today. The hippocampus clearly plays a role in both navigation and memory processing. The question that must be addressed is rather: “What is the role played by the hippocampus in the navigation and memory systems?” By looking at the navigation system as a whole, one can identify the major role played by the hippocampus as correcting for accumulation errors that occur within idiothetic navigation systems. This is most clearly experimentally evident as reorientation when an animal is lost. Carrying this over to a more general process, this becomes a role of recalling a context, bridging a contextual gap, or, in other words, it becomes a form of recognition memory. I will review recent experimental data which seems to support this theory over the more general spatial or memory theories traditionally applied to hippocampus.},
	language = {eng},
	number = {1-2},
	journal = {Behav. Brain Res.},
	author = {Redish, A D},
	year = {2001},
	note = {Place: Department of Neuroscience, University of Minnesota, 6-145 Jackson Hall, Minneapolis, MN 55455, USA. redish@ahc.umn.edu},
	keywords = {Humans, Animals, Rats, merged\_fiete.bib, Cognition/*physiology, Neurological, Hippocampus/cytology/*physiology, Models, Orientation/physiology, Space Perception/*physiology, Pyramidal Cells/physiology, Memory/physiology},
	pages = {81--98},
}

@article{redish_cognitive_1997,
	title = {Cognitive maps beyond the hippocampus},
	volume = {7},
	abstract = {We present a conceptual framework for the role of the hippocampus and its afferent and efferent structures in rodent navigation. Our proposal is compatible with the behavioral, neurophysiological, anatomical, and neuropharmacological literature, and suggests a number of practical experiments that could support or refute it. We begin with a review of place cells and how the place code for an environment might be aligned with sensory cues and updated by self-motion information. The existence of place fields in the dark suggests that location information is maintained by path integration, which requires an internal representation of direction of motion. This leads to a consideration of the organization of the rodent head direction system, and thence into a discussion of the computational structure and anatomical locus of the path integrator. If the place code is used in navigation, there must be a mechanism for selecting an action based on this information. We review evidence that the nucleus accumbens subserves this function. From there, we move to interactions between the hippocampal system and the environment, emphasizing mechanisms for learning novel environments and for aligning the various subsystems upon re-entry into familiar environments. We conclude with a discussion of the relationship between navigation and declarative memory.},
	language = {eng},
	number = {1},
	journal = {Hippocampus},
	author = {Redish, A D and Touretzky, D S},
	year = {1997},
	note = {Place: Computer Science Department, Carnegie Mellon University, Pittsburgh, Pennsylvania 15213-3891, USA.},
	keywords = {Animals, Space Perception, merged\_fiete.bib, *Models, Cognition/*physiology, Hippocampus/*physiology, Neurological, Neurons/*physiology, Brain/*physiology, *Brain Mapping, Psychological, Afferent Pathways/physiology, Acetylcholine/physiology, Serotonin/physiology},
	pages = {15--35},
}

@article{reichhardt_dynamical_2003,
	title = {Dynamical {Ordering} of {Driven} {Stripe} {Phases} in {Quenched} {Disorder}},
	volume = {90},
	journal = {Phys. Rev. Lett.},
	author = {Reichhardt, C and Reichhardt, C J Olson and Martin, I and Bishop, A R},
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {026401},
}

@article{robinson_systems_1986,
	title = {The systems approach to the oculomotor system},
	volume = {26},
	abstract = {Recent progress in understanding the oculomotor system is briefly reviewed. This progress is largely due to technological advances such as the ability to record from neurons in behaving animals. Furthermore, parts of the oculomotor system are now well-enough understood that the techniques of exact science, such as quantitation and mathematical description, are becoming useful. This, in turn, leads to the use of the language of systems analysis, and the vestibulo-ocular reflex is examined as an example of such a description. Systems analysis not only organizes current knowledge but leads to predictions by way of hypotheses known as models. A model of time integration by neurons is given as an example. It is put forward to illustrate that our biggest problem at the moment is an inability to test such models at the neuronal network level.},
	language = {eng},
	number = {1},
	journal = {Vision Res.},
	author = {Robinson, D A},
	year = {1986},
	keywords = {merged\_fiete.bib},
	pages = {91--99},
}

@article{rolls_entorhinal_2006,
	title = {Entorhinal cortex grid cells can map to hippocampal place cells by competitive learning},
	volume = {17},
	abstract = {'Grid cells' in the dorsocaudal medial entorhinal cortex (dMEC) are activated when a rat is located at any of the vertices of a grid of equilateral triangles covering the environment. dMEC grid cells have different frequencies and phase offsets. However, cells in the dentate gyrus (DG) and hippocampal area CA3 of the rodent typically display place fields, where individual cells are active over only a single portion of the space. In a model of the hippocampus, we have shown that the connectivity from the entorhinal cortex to the dentate granule cells could allow the dentate granule cells to operate as a competitive network to recode their inputs to produce sparse orthogonal representations, and this includes spatial pattern separation. In this paper we show that the same computational hypothesis can account for the mapping of EC grid cells to dentate place cells. We show that the learning in the competitive network is an important part of the way in which the mapping can be achieved. We further show that incorporation of a short term memory trace into the associative learning can help to produce the relatively broad place fields found in the hippocampus.},
	language = {eng},
	number = {4},
	journal = {Network},
	author = {Rolls, Edmund T and Stringer, Simon M and Elliot, Thomas},
	year = {2006},
	note = {Place: Centre for Computational Neuroscience, Department of Experimental Psychology, Oxford University, South Parks Road, Oxford, UK.},
	keywords = {Animals, merged\_fiete.bib, Hippocampus/*cytology, Action Potentials/physiology, Neurons/*physiology, Neural Pathways/*physiology, Entorhinal Cortex/*cytology, *Brain Mapping, Computer-Assisted, Learning/*physiology, Numerical Analysis, Neural Networks (Computer)},
	pages = {447--465},
}

@article{roudi_balanced_2007,
	title = {A balanced memory network},
	volume = {3},
	abstract = {A fundamental problem in neuroscience is understanding how working memory–the ability to store information at intermediate timescales, like tens of seconds–is implemented in realistic neuronal networks. The most likely candidate mechanism is the attractor network, and a great deal of effort has gone toward investigating it theoretically. Yet, despite almost a quarter century of intense work, attractor networks are not fully understood. In particular, there are still two unanswered questions. First, how is it that attractor networks exhibit irregular firing, as is observed experimentally during working memory tasks? And second, how many memories can be stored under biologically realistic conditions? Here we answer both questions by studying an attractor neural network in which inhibition and excitation balance each other. Using mean-field analysis, we derive a three-variable description of attractor networks. From this description it follows that irregular firing can exist only if the number of neurons involved in a memory is large. The same mean-field analysis also shows that the number of memories that can be stored in a network scales with the number of excitatory connections, a result that has been suggested for simple models but never shown for realistic ones. Both of these predictions are verified using simulations with large networks of spiking neurons.},
	language = {eng},
	number = {9},
	journal = {PLoS Comput. Biol.},
	author = {Roudi, Yasser and Latham, Peter E},
	year = {2007},
	note = {Place: Gatsby Computational Neuroscience Unit, University College London, London, United Kingdom. yasser@gatsby.ucl.ac.uk},
	keywords = {Computer Simulation, merged\_fiete.bib, *Models, Neurological, Neurons/*physiology, Nerve Net/*physiology, Memory/*physiology, Action Potentials/*physiology, Synaptic Transmission/*physiology, Information Storage and Retrieval/methods, Neuronal Plasticity/*physiology},
	pages = {1679--1700},
}

@article{russell_intercepting_2005,
	title = {Intercepting the first rat ashore},
	volume = {437},
	abstract = {A single Norway rat released on to a rat-free island was not caught for more than four months, despite intensive efforts to trap it. The rat first explored the 9.5-hectare island and then swam 400 metres across open water to another rat-free island, evading capture for 18 weeks until an aggressive combination of detection and trapping methods were deployed simultaneously. The exceptional difficulty of this capture indicates that methods normally used to eradicate rats in dense populations are unlikely to be effective on small numbers, a finding that could have global implications for conservation on protected islands.},
	language = {eng},
	number = {7062},
	journal = {Nature},
	author = {Russell, James C and Towns, David R and Anderson, Sandra H and Clout, Mick N},
	year = {2005},
	note = {Place: School of Biological Sciences, Private Bag 92019, Auckland, New Zealand. j.russell@auckland.ac.nz},
	keywords = {Animals, merged\_fiete.bib, Locomotion/*physiology, *Geography, Animal Identification Systems, Conservation of Natural Resources, New Zealand, Rats/*physiology, Swimming/physiology},
	pages = {1107},
}

@article{samsonovich_path_1997,
	title = {Path integration and cognitive mapping in a continuous attractor neural network model},
	volume = {17},
	abstract = {A minimal synaptic architecture is proposed for how the brain might perform path integration by computing the next internal representation of self-location from the current representation and from the perceived velocity of motion. In the model, a place-cell assembly called a “chart” contains a two-dimensional attractor set called an “attractor map” that can be used to represent coordinates in any arbitrary environment, once associative binding has occurred between chart locations and sensory inputs. In hippocampus, there are different spatial relations among place fields in different environments and behavioral contexts. Thus, the same units may participate in many charts, and it is shown that the number of uncorrelated charts that can be encoded in the same recurrent network is potentially quite large. According to this theory, the firing of a given place cell is primarily a cooperative effect of the activity of its neighbors on the currently active chart. Therefore, it is not particularly useful to think of place cells as encoding any particular external object or event. Because of its recurrent connections, hippocampal field CA3 is proposed as a possible location for this “multichart” architecture; however, other implementations in anatomy would not invalidate the main concepts. The model is implemented numerically both as a network of integrate-and-fire units and as a “macroscopic” (with respect to the space of states) description of the system, based on a continuous approximation defined by a system of stochastic differential equations. It provides an explanation for a number of hitherto perplexing observations on hippocampal place fields, including doubling, vanishing, reshaping in distorted environments, acquiring directionality in a two-goal shuttling task, rapid formation in a novel environment, and slow rotation after disorientation. The model makes several new predictions about the expected properties of hippocampal place cells and other cells of the proposed network.},
	language = {eng},
	number = {15},
	journal = {J. Neurosci.},
	author = {Samsonovich, A and McNaughton, B L},
	year = {1997},
	note = {Place: Arizona Research Laboratories Division of Neural Systems, Memory and Aging, The University of Arizona, Tucson, Arizona 85749, USA.},
	keywords = {Animals, Rats, merged\_fiete.bib, Hippocampus/*physiology, Brain Mapping, *Neural Networks (Computer)},
	pages = {5900--5920},
}

@article{savelli_influence_2008,
	title = {Influence of boundary removal on the spatial representations of the medial entorhinal cortex},
	volume = {18},
	number = {12},
	journal = {Hippocampus},
	author = {Savelli, F and Yoganarasimha, D and Knierim, J J},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {XXX--XXX},
}

@article{seung_how_1996,
	title = {How the brain keeps the eyes still},
	volume = {93},
	abstract = {The brain can hold the eyes still because it stores a memory of eye position. The brain's memory of horizontal eye position appears to be represented by persistent neural activity in a network known as the neural integrator, which is localized in the brainstem and cerebellum. Existing experimental data are reinterpreted as evidence for an “attractor hypothesis” that the persistent patterns of activity observed in this network form an attractive line of fixed points in its state space. Line attractor dynamics can be produced in linear or nonlinear neural networks by learning mechanisms that precisely tune positive feedback.},
	language = {eng},
	number = {23},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Seung, H S},
	year = {1996},
	note = {Place: Bell Laboratories, Lucent Technologies, Murray Hill, NJ 07974, USA.},
	keywords = {merged\_fiete.bib},
	pages = {13339--13344},
}

@article{seung_stability_2000,
	title = {Stability of the memory of eye position in a recurrent network of conductance-based model neurons},
	volume = {26},
	abstract = {Studies of the neural correlates of short-term memory in a wide variety of brain areas have found that transient inputs can cause persistent changes in rates of action potential firing, through a mechanism that remains unknown. In a premotor area that is responsible for holding the eyes still during fixation, persistent neural firing encodes the angular position of the eyes in a characteristic manner: below a threshold position the neuron is silent, and above it the firing rate is linearly related to position. Both the threshold and linear slope vary from neuron to neuron. We have reproduced this behavior in a biophysically plausible network model. Persistence depends on precise tuning of the strength of synaptic feedback, and a relatively long synaptic time constant improves the robustness to mistuning.},
	language = {eng},
	number = {1},
	journal = {Neuron},
	author = {Seung, H S and Lee, D D and Reis, B Y and Tank, D W},
	year = {2000},
	note = {Place: Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge 02139, USA.},
	keywords = {merged\_fiete.bib},
	pages = {259--271},
}

@article{shadlen_noise_1994,
	title = {Noise, neural codes and cortical organization},
	volume = {4},
	abstract = {Cortical circuitry must facilitate information transfer in accordance with a neural code. In this article we examine two candidate neural codes: information is represented in the spike rate of neurons, or information is represented in the precise timing of individual spikes. These codes can be distinguished by examining the physiological basis of the highly irregular interspike intervals typically observed in cerebral cortex. Recent advances in our understanding of cortical microcircuitry suggest that the timing of neuronal spikes conveys little, if any, information. The cortex is likely to propagate a noisy rate code through redundant, patchy interconnections.},
	language = {eng},
	number = {4},
	journal = {Curr. Opin. Neurobiol.},
	author = {Shadlen, M N and Newsome, W T},
	year = {1994},
	note = {Place: Department of Neurobiology, Sherman Fairchild Labs, Stanford University School of Medicine, California 94305.},
	keywords = {Humans, Animals, Action Potentials, merged\_fiete.bib, Neurons/*physiology, Neural Pathways/*physiology, Synapses/physiology, Cerebral Cortex/cytology/*physiology},
	pages = {569--579},
}

@article{sharp_complimentary_1999,
	title = {Complimentary roles for hippocampal versus subicular/entorhinal place cells in coding place, context, and events},
	volume = {9},
	abstract = {At least two important questions are posed by the existence of hippocampal place cells. The first of these has to do with how the complex, abstract properties exhibited by these cells can be explained mechanistically. The second has to do with the implications of place cells for our conception of the broader role of the hippocampus in spatial and other behaviors. Here, evidence is reviewed that: (1) Hippocampal cells show different “maps” (place cell representations) for each environment the animal visits and, in fact, can show multiple maps even for any one environment. The choice of the current map for any one environment depends on environmental, contextual, and event-related variables. (2) Cells in the subiculum and entorhinal cortex also show location-specific firing patterns (like hippocampal place cells), but show the same pattern for each environment the animal visits. A model is presented that is a variant of hippocampus-based path integration models developed by McNaughton and colleagues. In this version, the subiculum and entorhinal cortex work together to form a single, universal map that is used for each environment, and that can exhibit path integration abilities. The universal subicular/entorhinal representation is postulated to assist the hippocampal layer to rapidly form new environment and context specific “maps” for each new environment/temporal context (“episode”) the animal experiences. In this view, hippocampal layer activity is always obligatorily spatial, due to the input from the entorhinal universal “map.” However, the fact that the hippocampus generates a new map in response to global, non-spatial, contextual attributes of each situation, means that the hippocampus is always coding non-spatial aspects of a situation using its obligatorily spatial code. This brings the hippocampal place cell activity in to line with the broader role that has been postulated for the hippocampus in learning and memory functions.},
	language = {eng},
	number = {4},
	journal = {Hippocampus},
	author = {Sharp, P E},
	year = {1999},
	note = {Place: Department of Psychology, Yale University, New Haven, Connecticut 06520-8205, USA. psharp@minerva.cis.yale.edu},
	keywords = {Animals, merged\_fiete.bib, Hippocampus/cytology/*physiology, Space Perception/physiology, Entorhinal Cortex/cytology/*physiology, Neurons/physiology, Memory/physiology},
	pages = {432--443},
}

@article{smith_hippocampal_2006,
	title = {Hippocampal place cells, context, and episodic memory},
	volume = {16},
	abstract = {Although most observers agree that the hippocampus has a critical role in learning and memory, there remains considerable debate about the precise functional contribution of the hippocampus to these processes. Two of the most influential accounts hold that the primary function of the hippocampus is to generate cognitive maps and to mediate episodic memory processes. The well-documented spatial firing patterns (place fields) of hippocampal neurons in rodents, along with the spatial learning impairments observed with hippocampal damage support the cognitive mapping hypothesis. The amnesia for personally experienced events seen in humans with hippocampal damage and the data of animal models, which show severe memory deficits associated with hippocampal lesions, support the episodic memory account. Although an extensive literature supports each of these hypotheses, a specific contribution of place cells to episodic memory has not been clearly demonstrated. Recent data from our laboratory, together with previous findings, indicate that hippocampal place fields and neuronal responses to task-relevant stimuli are highly sensitive to the context, even when the contexts are defined by abstract task demands rather than the spatial geometry of the environment. On the basis of these findings, it is proposed that place fields reflect a more general context processing function of the hippocampus. Hippocampal context representations could serve to differentiate contexts and prime the relevant memories and behaviors. Since episodic memories, by definition, include information about the time and place where the episode occurred, contextual information is a necessary prerequisite for any episodic memory. Thus, place fields contribute importantly to episodic memory as part of the needed context representations. Additionally, recent findings indicate that hippocampal neurons differentiate contexts at progressively finer levels of detail, suggesting a hierarchical coding scheme which, if combined with temporal information, could provide a means of differentiating memory episodes.},
	language = {eng},
	number = {9},
	journal = {Hippocampus},
	author = {Smith, David M and Mizumori, Sheri J Y},
	year = {2006},
	note = {Place: Department of Psychology, University of Washington, Seattle, Washington 98195, USA. dmsmith4@u.washington.edu},
	keywords = {merged\_fiete.bib},
	pages = {716--729},
}

@article{softky_highly_1993,
	title = {The highly irregular firing of cortical cells is inconsistent with temporal integration of random {EPSPs}},
	volume = {13},
	abstract = {How random is the discharge pattern of cortical neurons? We examined recordings from primary visual cortex (V1; Knierim and Van Essen, 1992) and extrastriate cortex (MT; Newsome et al., 1989a) of awake, behaving macaque monkey and compared them to analytical predictions. For nonbursting cells firing at sustained rates up to 300 Hz, we evaluated two indices of firing variability: the ratio of the variance to the mean for the number of action potentials evoked by a constant stimulus, and the rate-normalized coefficient of variation (Cv) of the interspike interval distribution. Firing in virtually all V1 and MT neurons was nearly consistent with a completely random process (e.g., Cv approximately 1). We tried to model this high variability by small, independent, and random EPSPs converging onto a leaky integrate-and-fire neuron (Knight, 1972). Both this and related models predicted very low firing variability (Cv {\textless}{\textless} 1) for realistic EPSP depolarizations and membrane time constants. We also simulated a biophysically very detailed compartmental model of an anatomically reconstructed and physiologically characterized layer V cat pyramidal cell (Douglas et al., 1991) with passive dendrites and active soma. If independent, excitatory synaptic input fired the model cell at the high rates observed in monkey, the Cv and the variability in the number of spikes were both very low, in agreement with the integrate-and-fire models but in strong disagreement with the majority of our monkey data. The simulated cell only produced highly variable firing when Hodgkin-Huxley-like currents (INa and very strong IDR) were placed on distal dendrites. Now the simulated neuron acted more as a millisecond-resolution detector of dendritic spike coincidences than as a temporal integrator. We argue that neurons that act as temporal integrators over many synaptic inputs must fire very regularly. Only in the presence of either fast and strong dendritic nonlinearities or strong synchronization among individual synaptic events will the degree of predicted variability approach that of real cortical neurons.},
	language = {eng},
	number = {1},
	journal = {J. Neurosci.},
	author = {Softky, W R and Koch, C},
	year = {1993},
	note = {Place: Division of Physics, Mathematics, and Astronomy, California Institute of Technology, Pasadena 91125.},
	keywords = {Humans, Reaction Time, Animals, Computer Simulation, merged\_fiete.bib, Neurological, Models, Neurons/physiology, Action Potentials/*physiology, Dendrites/physiology, Visual Cortex/cytology/*physiology, Random Allocation, Synapses/*physiology},
	pages = {334--350},
}

@article{solodkin_entorhinal_1996,
	title = {Entorhinal cortex modules of the human brain},
	volume = {365},
	abstract = {Much is known about modular organization in the cerebral cortex, but this knowledge is skewed markedly toward primary sensory areas, and in fact, it has been difficult to demonstrate elsewhere. In this report, we test the hypothesis that a unique form of modules exists in the entorhinal area of the human cortex (Brodmann's area 28). We examined this issue using classic cyto- and myeloarchitectonic stains, immunolabeling for various neurochemicals, and histochemistry for certain enzymes. The findings reveal that the entorhinal cortex in the human is formed by a mosaic of cellular aggregates whose most conspicuous elements are the cell islands of layer II and myelinated fibers around the cell islands, the disposition of glutamic acid decarboxylase-positive neurons and processes, cytochrome oxidase staining, and the pattern of cholinergic afferent fibers. The neuropathology of Alzheimer's disease cases highlights the modules, but inversely so, by destroying their features. The findings are of interest because 1) anatomically defined modules are shown to be present in areas other than the sensory and motor cortices, 2) the modules are morphological entities likely to reflect functions of the entorhinal cortex, and 3) the destruction of entorhinal cortex modules may account disproportionately for the severity of memory impairments in Alzheimer's disease.},
	language = {eng},
	number = {4},
	journal = {J. Comp. Neurol.},
	author = {Solodkin, A and Van Hoesen, G W},
	year = {1996},
	note = {Place: Department of Anatomy, University of Iowa College of Medicine, Iowa City 52242, USA. solodkin@blue.weeg.uiowa.edu},
	keywords = {merged\_fiete.bib},
	pages = {610--617},
}

@article{solstad_grid_2006,
	title = {From grid cells to place cells: a mathematical model},
	volume = {16},
	abstract = {Anatomical connectivity and recent neurophysiological results imply that grid cells in the medial entorhinal cortex are the principal cortical inputs to place cells in the hippocampus. The authors propose a model in which place fields of hippocampal pyramidal cells are formed by linear summation of appropriately weighted inputs from entorhinal grid cells. Single confined place fields could be formed by summing input from a modest number (10-50) of grid cells with relatively similar grid phases, diverse grid orientations, and a biologically plausible range of grid spacings. When the spatial phase variation in the grid-cell input was higher, multiple, and irregularly spaced firing fields were formed. These observations point to a number of possible constraints in the organization of functional connections between grid cells and place cells.},
	language = {eng},
	number = {12},
	journal = {Hippocampus},
	author = {Solstad, Trygve and Moser, Edvard I and Einevoll, Gaute T},
	year = {2006},
	note = {Place: Center for the Biology of Memory, Norwegian University of Science and Technology, Trondheim, Norway.},
	keywords = {Animals, merged\_fiete.bib, Hippocampus/*cytology, *Models, Neurological, Neurons/*physiology, Entorhinal Cortex/*cytology, Theoretical},
	pages = {1026--1031},
}

@article{steffenach_spatial_2005,
	title = {Spatial memory in the rat requires the dorsolateral band of the entorhinal cortex},
	volume = {45},
	abstract = {The extensive connections of the entorhinal cortex with the hippocampus and the neocortex point to this region as a major interface in the hippocampal-neocortical interactions underlying memory. We asked whether hippocampal-dependent recall of spatial memory depends on the entorhinal cortex, and, if so, which parts are critical. After training in a Morris water maze, rats received fiber-sparing lesions in the dorsolateral band of the entorhinal cortex, which mediates much of the visuospatial input to the dorsal hippocampus. These lesions entirely disrupted retention and retarded new learning. Spatial memory was spared by lesions in the ventromedial band, which connects primarily with ventral hippocampus, but these lesions reduced defensive behavior on an elevated plus maze, mirroring the effects of damage to ventral hippocampus. The results suggest that the functional differences between dorsal and ventral hippocampus reflect their connectivity with modules of the entorhinal cortex that are differently linked to the rest of the cortex.},
	language = {eng},
	number = {2},
	journal = {Neuron},
	author = {Steffenach, Hill-Aina and Witter, Menno and Moser, May-Britt and Moser, Edvard I},
	year = {2005},
	note = {Place: Centre for the Biology of Memory, Norwegian University of Science and Technology, NO-7489 Trondheim, Norway.},
	keywords = {merged\_fiete.bib},
	pages = {301--313},
}

@article{stringer_self-organizing_2005,
	title = {Self-organizing continuous attractor network models of hippocampal spatial view cells},
	volume = {83},
	abstract = {Single neuron recording studies have demonstrated the existence of hippocampal spatial view neurons which encode information about the spatial location at which a primate is looking in the environment. These neurons are able to maintain their firing even in the absence of visual input. The standard neuronal network approach to model networks with memory that represent continuous spaces is that of continuous attractor networks. It has recently been shown how idiothetic (self-motion) inputs could update the activity packet of neuronal firing for a one-dimensional case (head direction cells), and for a two-dimensional case (place cells which represent the place where a rat is located). In this paper, we describe three models of primate hippocampal spatial view cells, which not only maintain their spatial firing in the absence of visual input, but can also be updated in the dark by idiothetic input. The three models presented in this paper represent different ways in which a continuous attractor network could integrate a number of different kinds of velocity signal (e.g., head rotation and eye movement) simultaneously. The first two models use velocity information from head angular velocity and from eye velocity cells, and make use of a continuous attractor network to integrate this information. A fundamental feature of the first two models is their use of a 'memory trace' learning rule which incorporates a form of temporal average of recent cell activity. Rules of this type are able to build associations between different patterns of neural activities that tend to occur in temporal proximity, and are incorporated in the model to enable the recent change in the continuous attractor to be associated with the contemporaneous idiothetic input. The third model uses positional information from head direction cells and eye position cells to update the representation of where the agent is looking in the dark. In this case the integration of idiothetic velocity signals is performed in the earlier layer of head direction cells.},
	language = {eng},
	number = {1},
	journal = {Neurobiol. Learn. Mem.},
	author = {Stringer, S M and Rolls, E T and Trappenberg, T P},
	year = {2005},
	note = {Place: Department of Experimental Psychology, Centre for Computational Neuroscience, Oxford University, South Parks Road, Oxford OX1 3UD, UK.},
	keywords = {merged\_fiete.bib},
	pages = {79--92},
}

@article{stringer_self-organizing_2003,
	title = {Self-organizing continuous attractor networks and motor function},
	volume = {16},
	abstract = {Motor skill learning may involve training a neural system to automatically perform sequences of movements, with the training signals provided by a different system, used mainly during training to perform the movements, that operates under visual sensory guidance. We use a dynamical systems perspective to show how complex motor sequences could be learned by the automatic system. The network uses a continuous attractor network architecture to perform path integration on an efference copy of the motor signal to keep track of the current state, and selection of which motor cells to activate by a movement selector input where the selection depends on the current state being represented in the continuous attractor network. After training, the correct motor sequence may be selected automatically by a single movement selection signal. A feature of the model presented is the use of 'trace' learning rules which incorporate a form of temporal average of recent cell activity. This form of temporal learning underlies the ability of the networks to learn temporal sequences of behaviour. We show that the continuous attractor network models developed here are able to demonstrate the key features of motor function. That is, (i) the movement can occur at arbitrary speeds; (ii) the movement can occur with arbitrary force; (iii) the agent spends the same relative proportions of its time in each part of the motor sequence; (iv) the agent applies the same relative force in each part of the motor sequence; and (v) the actions always occur in the same sequence.},
	language = {eng},
	number = {2},
	journal = {Neural Netw.},
	author = {Stringer, S M and Rolls, E T and Trappenberg, T P and de Araujo, I E T},
	year = {2003},
	note = {Place: Department of Experimental Psychology, Centre for Computational Neuroscience, Oxford University, South Parks Road, Oxford OX1 3UD, UK.},
	keywords = {merged\_fiete.bib, *Neural Networks (Computer), Excitatory Postsynaptic Potentials/physiology, Motor Skills/*physiology},
	pages = {161--182},
}

@article{taube_head_1995,
	title = {Head direction cells recorded in the anterior thalamic nuclei of freely moving rats},
	volume = {15},
	abstract = {Previous studies have identified neurons in the postsubiculum which discharge as a function of the animal's head direction in the horizontal plane, independent of its behavior and location in the environment. Anatomical studies have shown that the postsubiculum contains reciprocal connections with the anterior thalamic nuclei (ATN). In order to determine how the head direction (HD) cell signal is processed in the brain, single-unit recordings were monitored in the ATN of freely moving rats in order to characterize their behavioral and spatial correlates. Animals were trained to retrieve food pellets thrown randomly into a cylindrical apparatus containing a single orientation cue. Single unit recordings in the ATN showed that approximately 60\% of the recorded cells discharged in relation to the animal's head direction in the horizontal plane. Observation of the animal and quantitative analyses showed that HD cell firing was not dependent on the animal's behavior, trunk position, linear speed, angular head velocity, or location in the environment. Most of these cells were localized to the anterior dorsal thalamic nucleus. Each HD cell contained only one head direction at which the cell discharged maximally and the firing rate decreased linearly away from this preferred direction. The preferred firing directions from all cells recorded were distributed over a 360 degrees range. Quantitative analysis showed that these cells contained similar discharge parameters (peak firing rate, directional firing range) to values reported previously for postsubicular HD cells (Taube et al., 1990a). Experiments involving rotation of the orientation cue showed that the preferred firing direction could be controlled by a salient visual cue. In contrast to postsubicular HD cells, passive rotation of a restrained animal showed that most ATN HD cells ceased discharging when the animal's head was oriented in the preferred direction. These findings demonstrate the presence of HD cells in the ATN and indicate the potential importance of this area for spatial navigation. The origin of the head direction signal is discussed and it is concluded that because of the presence of reciprocal connections between the postsubiculum and the ATN, further studies are required in order to determine the direction in which this head-directional information is flowing. Finally, ATN HD cells differ from postsubicular HD cells by appearing to require volitional motoric input.},
	language = {eng},
	number = {1 Pt 1},
	journal = {J. Neurosci.},
	author = {Taube, J S},
	year = {1995},
	note = {Place: Department of Psychology, Dartmouth College, Hanover, New Hampshire 03755.},
	keywords = {merged\_fiete.bib},
	pages = {70--86},
}

@article{taube_processing_1996,
	title = {Processing the head direction cell signal: a review and commentary},
	volume = {40},
	abstract = {Animals require information about their location and directional heading in order to navigate. Directional information is provided by a population of cells in the postsubiculum and the anterior thalamic nuclei that encode a very accurate, continual representation of the animal's directional heading in the horizontal plane, which is independent of the animal's location. Recent studies indicate that this signal 1) arises either in the anterior thalamic nuclei or in structures upstream from it; 2) is not dependent on an intact hippocampus; 3) receives sensory inputs from both idiothetic and landmark systems; and 4) correlates well with the animal's behavior in a spatial reference memory task. Furthermore, HD cells in the anterior thalamic nuclei appear to encode what the animal's directional heading will be about 40 ms in the future, while HD cells in the postsubiculum encode the animal's current directional heading. Both the electrophysiological and anatomical data suggest that the anterior thalamic nuclei and/or the lateral mammillary nuclei may be the sites of convergence for spatial information derived from landmarks and internally-generated cues. Current evidence also indicates that the vestibular system plays a crucial role in the generation of the HD cell signal. However, the notion that the vestibular system is the sole contributor to the signal generator is difficult to reconcile with several findings; these latter findings are better accounted for with a motor efference copy signal.},
	language = {eng},
	number = {5-6},
	journal = {Brain Res. Bull.},
	author = {Taube, J S and Goodridge, J P and Golob, E J and Dudchenko, P A and Stackman, R W},
	year = {1996},
	note = {Place: Department of Psychology, Dartmouth College, Hanover, NH 03755, USA.},
	keywords = {merged\_fiete.bib},
	pages = {477--484},
}

@article{taube_head-direction_1990-1,
	title = {Head-direction cells recorded from the postsubiculum in freely moving rats. {I}. {Description} and quantitative analysis},
	volume = {10},
	abstract = {This paper is a study of the behavioral and spatial firing correlates of neurons in the rat postsubiculum. Recordings were made from postsubicular neurons as rats moved freely throughout a cylindrical chamber, where the major cue for orientation was a white card taped to the inside wall. An automatic video/computer system monitored cell discharge while simultaneously tracking the position of 2 colored light emitting diodes (LEDs) secured to the animal's head. The animal's location was calculated from the position of one of the LEDs and head direction in the horizontal plane calculated from the relative positions of the 2 LEDs. Approximately 26\% of the cells were classified as head-direction cells because they discharged as a function of the animal's head direction in the horizontal plane, independent of the animal's behavior, location, or trunk position. For each head-direction cell, vectors drawn in the direction of maximal firing were parallel throughout the recording chamber and did not converge toward a single point. Plots of firing rate versus head direction showed that each firing-rate/head-direction function was adequately described by a triangular function. Each cell's maximum firing rate occurred at only one (the preferred) head direction; firing rates at head directions on either side of the preferred direction decreased linearly with angular deviation from the preferred direction. Results from 24 head-direction cells in 7 animals showed an equal distribution of preferred firing directions over a 360 degrees angle. The peak firing rate of head-direction cells varied from 5 to 115 spikes/sec (mean: 35). The range of head-direction angles over which discharge was elevated (directional firing range) was usually about 90 degrees, with little, if any, discharge at head directions outside this range. Quantitative analysis showed the location of the animal within the cylinder had minimal effect on directional cell firing. For each head-direction cell, the preferred direction, peak firing rate, and directional firing range remained stable for days. These results identify a new cell type that signals the animal's head direction in its environment.},
	language = {eng},
	number = {2},
	journal = {J. Neurosci.},
	author = {Taube, J S and Muller, R U and Ranck, Jr, J B},
	year = {1990},
	note = {Place: Department of Physiology, SUNY Health Sciences Center, Brooklyn 11203.},
	keywords = {Animals, Rats, Time Factors, Female, merged\_fiete.bib, Neurons/*physiology, Hippocampus/cytology/*physiology, *Orientation, Electrophysiology, Inbred Strains, Head/*physiology},
	pages = {420--435},
}

@article{touretzky_theory_1996,
	title = {Theory of rodent navigation based on interacting representations of space},
	volume = {6},
	abstract = {We present a computational theory of navigation in rodents based on interacting representations of place, head direction, and local view. An associated computer model is able to replicate a variety of behavioral and neurophysiological results from the rodent navigation literature. The theory and model generate predictions that are testable with current technologies.},
	language = {eng},
	number = {3},
	journal = {Hippocampus},
	author = {Touretzky, D S and Redish, A D},
	year = {1996},
	note = {Place: Computer Science Department, Carnegie Mellon University, Pittsburgh, Pennsylvania 15213-3891, USA.},
	keywords = {Animals, merged\_fiete.bib, *Models, Neurological, Neurons/*physiology, Cues, Hippocampus/cytology/*physiology, Orientation/*physiology, Space Perception/*physiology, Darkness, Head Movements/physiology, Visual Fields/physiology, Rodentia},
	pages = {247--270},
}

@article{tsodyks_attractor_1999,
	title = {Attractor neural network models of spatial maps in hippocampus},
	volume = {9},
	abstract = {Hippocampal pyramidal neurons in rats are selectively activated at specific locations in an environment (O'Keefe and Dostrovsky, Brain Res 1971;34:171-175). Different cells are active in different places, therefore providing a faithful representation of the environment in which every spatial location is mapped to a particular population state of activity of place cells (Wilson and McNaughton, Science 1993;261:1055-1058; Zhang et al., J Neurosci 1998;79:1017-1044). We describe a theory of the hippocampus, according to which the map results from the cooperative dynamics of network, in which the strength of synaptic interaction between the neurons depends on the distance between their place fields. This synaptic structure guarantees that the network possesses a quasi-continuous set of stable states (attractors) that are localized in the space of neuronal variables reflecting their synaptic interactions, rather than their physical location in the hippocampus. As a consequence of the stable states, the network can exhibit place selective activity even without relying on input from external sensory cues.},
	language = {eng},
	number = {4},
	journal = {Hippocampus},
	author = {Tsodyks, M},
	year = {1999},
	note = {Place: Department of Neurobiology, Weizmann Institute of Science, Rehovot, Israel. bnmisha@wicc.weizmann.ac.il},
	keywords = {Animals, Rats, merged\_fiete.bib, *Models, Neurological, Hippocampus/cytology/*physiology, Space Perception/*physiology, Pyramidal Cells/*physiology, *Brain Mapping, *Neural Networks (Computer)},
	pages = {481--489},
}

@article{tsodyks_associative_1995,
	title = {Associative memory and hippocampal place cells},
	volume = {6},
	journal = {Int. J. Neural Syst.},
	author = {Tsodyks, M and Sejnowski, T},
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {81--86},
}

@article{vertes_brainstem-diencephalo-septohippocampal_1997,
	title = {Brainstem-diencephalo-septohippocampal systems controlling the theta rhythm of the hippocampus},
	volume = {81},
	abstract = {We present a new model for the generation of theta rhythm of the hippocampus. We propose that theta at CA1 involves extracellular current fluxes produced by alternating depolarizing and hyperpolarizing membrane potential fluctuations of large populations of hippocampal pyramidal cells. Pyramidal cells are, in turn, controlled by rhythmically bursting cholinergic and GABAergic cells of the medial septum/vertical limb of the diagonal band. We postulate that septal cholinergic and GABAergic rhythmically bursting cells fire in relative synchrony; their coordinated burst discharge (burst mode) drives the positive-going phase of intracellular theta and associated firing of pyramidal cells; their synchronized pauses (interburst mode) give rise to the negative-going phase of intracellular theta and an inhibition of pyramidal cells. We further demonstrate that the theta rhythm is controlled by a network of cells extending from the brainstem to the septum/hippocampus. During theta, tonically discharging cells of the nucleus reticularis pontis oralis activate neurons of the supramammillary nucleus; the supramammillary nucleus, in turn, converts this steady barrage into a rhythmical pattern of discharge which is relayed to GABAergic/ cholinergic rhythmically bursting cells of the medial septum. The septal rhythmically bursting cells modulate subsets of hippocampal interneurons and principal cells in the generation of the theta rhythm. We review evidence showing that the serotonin-containing neurons of the median raphe nucleus desynchronize the hippocampal electroencephalogram, presumably by disrupting the rhythmical discharge of septal cholinergic and GABAergic neurons. Finally, we summarize recent work indicating that the theta rhythm is critically involved in memory functions of the hippocampus and that its disruption (electroencephalographic desynchronization) may block or temporarily suspend mnemonic processes of the hippocampus.},
	number = {4},
	journal = {Neuroscience},
	author = {Vertes, R P and Kocsis, B},
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {893--926},
}

@article{vertes_theta-rhythmically_2001,
	title = {Theta-rhythmically firing neurons in the anterior thalamus: implications for mnemonic functions of {Papez}'s circuit},
	volume = {104},
	abstract = {In 1937 Papez described an anatomical circuit (or loop) beginning and ending in the hippocampal formation that he proposed subserved emotional experience (Papez, 1937). Specifically, the projections of the circuit were as follows: hippocampal formation–{\textgreater} mammillary bodies–{\textgreater} anterior thalamus–{\textgreater} cingulate cortex–{\textgreater} parahippocampal gyrus–{\textgreater} hippocampal formation. Although the circuit has been refined based on subsequent anatomical findings (Amaral and Witter, 1995; Shibata, 1992; Van Groen and Wyss, 1995), the major links of the circuit unquestionably represent a prominent system of connections in the mammalian brain. Hence, the enduring nature of 'Papez's circuit'. Unlike, however, its persistence as anatomical entity, the proposed functional role for the circuit has been less resilient. The early notion that Papez's circuit subserves emotional experience/expression has been abandoned (LeDoux, 1993) and replaced by the proposal that it is primarily involved in mnemonic functions (Aggleton and Brown, 1999). Lesions of each of the major components of the circuit have been shown to disrupt memory (Aggleton and Brown, 1999; Sutherland et al., 1988; Sziklas and Petrides, 1993). The mammillary bodies represent a major output from the hippocampus in Papez's circuit (Amaral and Witter, 1995). It has recently been shown that cells of mammillary body fire rhythmically in bursts synchronous with the theta rhythm of the hippocampus (Bland et al., 1995; Kirk et al., 1996; Kocsis and Vertes, 1994, 1997) and that this rhythmical activity is dependent upon the action of the hippocampus on the mammillary bodies (Bland et al., 1995; Kirk et al., 1996). It is well established that the mammillary bodies project massively to the anterior thalamus (Shibata, 1992), which taken together with the demonstration that mammillary body cells fire synchronously with theta, suggests that the mammillary bodies may act on the anterior thalamus, possibly in the manner that the hippocampus acts on the mammillary bodies, to rhythmically activate cells of the anterior thalamus at theta frequency. We demonstrated that approximately 75\% of cells of the anterior ventral nucleus of the thalamus fire rhythmically synchronous with the hippocampal theta rhythm and the activity of 46\% of these anterior ventral neurons was highly correlated with theta.These findings, together with demonstration of theta-rhythmically firing cells in other structures of Papez's circuit, indicate that a theta-rhythmic signal may resonate throughout Papez's circuit, possibly involved in the control of mnemonic functions of the circuit.},
	number = {3},
	journal = {Neuroscience},
	author = {Vertes, R P and Albo, Z and Viana Di Prisco, G},
	year = {2001},
	keywords = {hippocampus, merged\_fiete.bib, memory, cingulate cortex, diencephalic amnesia, head direction cells, mammillary body},
	pages = {619--625},
}

@article{whishaw_rats_1998,
	title = {Rats with fimbria-fornix lesions are impaired in path integration: a role for the hippocampus in “sense of direction”},
	volume = {18},
	abstract = {Animals can locate their present position in relation to a starting point and return to that starting point using cues generated by self-movement, a navigation strategy called dead-reckoning. Because contemporary research on spatial navigation suggests that some aspects of spatial navigation depend on the integrity of the hippocampal formation, whereas others do not, the present study examined whether dead-reckoning is hippocampally dependent. The task capitalized on the proclivity of foraging rats to carry large food pellets to a shelter for eating. Control rats and rats with fimbria-fornix (FF) lesions left a hidden burrow to search for one piece of food located somewhere on a circular table. The accuracy with which they returned to the burrow with the food was measured. In three experiments, rats received probe trials in which they (1) started from novel locations, (2) wore blindfolds to obscure visual cues, and (3) foraged under a condition in which surface cues, e.g., odors left by their outward searches, were displaced. Both sighted control and FF rats preferentially used visual cues for guidance when foraging from a familiar location. Control rats were accurate and FF rats were impaired in returning to novel starting locations (1) when sighted, (2) when blindfolded, and (3) when blindfolded in tests in which surface cues were displaced. These results, as well as detailed observations on the behavior of the animals, are consistent with the hypothesis that rats can use dead-reckoning to solve spatial problems, and this ability depends on the integrity of the hippocampal formation.},
	language = {eng},
	number = {8},
	journal = {J. Neurosci.},
	author = {Whishaw, I Q and Maaswinkel, H},
	year = {1998},
	note = {Place: Department of Psychology and Neuroscience, University of Lethbridge, Lethbridge, Alberta, Canada T1K 3M4.},
	keywords = {Animals, Rats, Female, merged\_fiete.bib, Animal/physiology, Behavior, Spatial Behavior/*physiology, Hippocampus/pathology/*physiology, Smell/physiology, Sensory Deprivation/physiology, Inbred Strains, Conditioning (Psychology)/*physiology, Vision/physiology},
	pages = {3050--3058},
}

@article{wilson_dynamics_1993,
	title = {Dynamics of the hippocampal ensemble code for space},
	volume = {261},
	abstract = {Ensemble recordings of 73 to 148 rat hippocampal neurons were used to predict accurately the animals' movement through their environment, which confirms that the hippocampus transmits an ensemble code for location. In a novel space, the ensemble code was initially less robust but improved rapidly with exploration. During this period, the activity of many inhibitory cells was suppressed, which suggests that new spatial information creates conditions in the hippocampal circuitry that are conducive to the synaptic modification presumed to be involved in learning. Development of a new population code for a novel environment did not substantially alter the code for a familiar one, which suggests that the interference between the two spatial representations was very small. The parallel recording methods outlined here make possible the study of the dynamics of neuronal interactions during unique behavioral events.},
	language = {eng},
	number = {5124},
	journal = {Science},
	author = {Wilson, M A and McNaughton, B L},
	year = {1993},
	note = {Place: Department of Psychology, University of Arizona, Tucson 85724.},
	keywords = {Animals, Rats, Male, merged\_fiete.bib, Hippocampus/*physiology, Behavior, Neurons/*physiology, *Memory, *Space Perception, Inbred F344, Exploratory Behavior, Interneurons/physiology, Animal},
	pages = {1055--1058},
}

@article{witter_spatial_2006,
	title = {Spatial representation and the architecture of the entorhinal cortex},
	volume = {29},
	abstract = {It has recently been recognized that the entorhinal cortex has a crucial role in spatial representation and navigation. How the position of an animal is computed within the entorhinal circuitry remains to be determined, but the architectural organization of this brain area might provide some clues. Here, we review three organizational principles–recurrent connectivity, interlaminar connectivity and modular organization–and propose how each of them might contribute to the emergence and maintenance of positional representations in entorhinal neural networks.},
	language = {eng},
	number = {12},
	journal = {Trends Neurosci.},
	author = {Witter, Menno P and Moser, Edvard I},
	year = {2006},
	note = {Place: Research Institute Neurosciences, Department of Anatomy and Neurosciences, VU University Medical Center, Amsterdam, The Netherlands. mp.witter@vumc.nl},
	keywords = {merged\_fiete.bib},
	pages = {671--678},
}

@article{xie_double-ring_2002,
	title = {Double-ring network model of the head-direction system},
	volume = {66},
	abstract = {In the head-direction system, the orientation of an animal's head in space is encoded internally by persistent activities of a pool of cells whose firing rates are tuned to the animal's directional heading. To maintain an accurate representation of the heading information when the animal moves, the system integrates horizontal angular head-velocity signals from the vestibular nuclei and updates the representation of directional heading. The integration is a difficult process, given that head velocities can vary over a large range and the neural system is highly nonlinear. Previous models of integration have relied on biologically unrealistic mechanisms, such as instantaneous changes in synaptic strength, or very fast synaptic dynamics. In this paper, we propose a different integration model with two populations of neurons, which performs integration based on the differential input of the vestibular nuclei to these two populations. We mathematically analyze the dynamics of the model and demonstrate that with carefully tuned synaptic connections it can accurately integrate a large range of the vestibular input, with potentially slow synapses.},
	language = {eng},
	number = {4 Pt 1},
	journal = {Phys. Rev. E Stat. Nonlin. Soft Matter Phys.},
	author = {Xie, Xiaohui and Hahnloser, Richard H R and Seung, H Sebastian},
	year = {2002},
	note = {Place: Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, E25-210, 45 Carleton Street, Cambridge, MA 02139, USA. xhx@ai.mit.edu},
	keywords = {merged\_fiete.bib},
	pages = {041902},
}

@book{ristic_beyond_2004,
	title = {Beyond the {Kalman} filter: {Particle} filters for tracking applications},
	publisher = {Artech House Radar Library},
	author = {Ristic, B and Arulampalam, S and Gordon, N},
	year = {2004},
	keywords = {merged\_fiete.bib},
}

@book{soderstrand_residue_1986-1,
	title = {Residue {Number} {System} {Arithmetic}: {Modern} {Applications} in {Digital} {Signal} {Processing}},
	publisher = {IEEE Press, New York},
	author = {Soderstrand, M A and Jenkins, W K and Jullien, G A and F. J. Taylor, Eds},
	year = {1986},
	keywords = {merged\_fiete.bib},
}

@inproceedings{berrou_near_1993,
	title = {Near {Shannon} limit error-correcting coding and decoding: turbo-codes},
	booktitle = {{IEEE} {Trans}. {Commun}.},
	author = {Berrou, C and Glavieux, A and Tthitimajshima, P},
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {1064--1070},
}

@inproceedings{jain_representing_2006,
	title = {Representing part-whole relationships in recurrent neural networks},
	volume = {18},
	booktitle = {Adv. {Neural} {Info}. {Proc}. {Syst}.},
	author = {Jain, V and Zhigulin, V and Seung, H S},
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {563--570},
}

@inproceedings{carreira-perpinan_contrastive_2005,
	title = {On contrastive divergence learning},
	booktitle = {Proceedings of the {Tenth} {International} {Workshop} on {Artificial} {Intelligence} and {Statistics}},
	author = {Carreira-Perpinan, M A and Hinton, G E},
	editor = {Cowell, R G and Ghahramani, Z},
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {33--40},
}

@inproceedings{foldiak_sparse_2002,
	title = {Sparse coding in the primate cortex},
	booktitle = {The {Handbook} of {Brain} {Theory} and {Neural} {Networks}, {Second} {Edition}},
	publisher = {MIT Press, Cambridge},
	author = {Foldiak, P},
	editor = {Arbib, M A},
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {1064--1068},
}

@article{tang_pyramidal_2014,
	title = {Pyramidal and stellate cell specifity of grid and border representations in layer 2 of medial entorhinal cortex},
	volume = {84},
	journal = {Neuron},
	author = {Tang, Q and Burgalossi, A and Ebbesen, C L and Ray, S and Naumann, R and Schmidt, H and Spicher, D and Brecht, M},
	month = dec,
	year = {2014},
	keywords = {merged\_fiete.bib},
	pages = {1191--1197},
}

@article{zhang_optogenetic_2013,
	title = {Optogenetic dissection of entorhinal-hippocampal functional connectivity},
	volume = {340},
	journal = {Science},
	author = {Zhang, S and Ye, J and Miao, C and Tsao, A and Cerniauskas, I and Ledergerber, D and Moser, M B and Moser, E I},
	year = {2013},
	keywords = {merged\_fiete.bib},
}

@article{hinton_training_2002-1,
	title = {Training products of experts by minimizing contrastive divergence},
	volume = {14},
	number = {8},
	journal = {Neural Comput.},
	author = {Hinton, Geoffrey E},
	year = {2002},
	note = {Publisher: MIT Press},
	keywords = {merged\_fiete.bib},
	pages = {1771--1800},
}

@inproceedings{hardcastle_error_2014,
	title = {Error accumulation and landmark-based error correction in grid cells},
	booktitle = {{SFN} {Poster}},
	author = {Hardcastle, K and Ganguli, S and Giocomo, L},
	year = {2014},
	keywords = {merged\_fiete.bib},
}

@article{hodgkin_effect_1949,
	title = {The effect of temperature on the electrical activity of the giant axon of the squid},
	volume = {109},
	journal = {J. Physiol.},
	author = {Hodgkin, A L and Katz, B},
	year = {1949},
	keywords = {merged\_fiete.bib},
	pages = {240--249},
}

@article{otis_modulation_1992,
	title = {Modulation of decay kinetics and frequency of {GABAa} receptor-mediated spontaneous inhibitory postsynaptic currents in hippocampal neurons},
	volume = {49},
	journal = {Neuroscience},
	author = {Otis, T S and Mody, I},
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {13--32},
}

@article{gage_effects_1975,
	title = {Effects of membrane potential, temperature and neostigmine on the conductance change caused by a quantum of acetylcholine at the toad neuromuscular junction},
	volume = {244},
	journal = {J. Physiol.},
	author = {Gage, P W and McBurney, R N},
	year = {1975},
	keywords = {merged\_fiete.bib},
	pages = {385--407},
}

@article{zilli_models_2012,
	title = {Models of grid cell spatial firing published 2005-2011},
	volume = {6},
	abstract = {Since the discovery of grid cells in rat entorhinal cortex, many models of their hexagonally arrayed spatial firing fields have been suggested. We review the models and organize them according to the mechanisms they use to encode position, update the positional code, read it out in the spatial grid pattern, and learn any patterned synaptic connections needed. We mention biological implementations of the models, but focus on the models on Marr's algorithmic level, where they are not things to individually prove or disprove, but rather are a valuable collection of metaphors of the grid cell system for guiding research that are all likely true to some degree, with each simply emphasizing different aspects of the system. For the convenience of interested researchers, MATLAB implementations of the discussed grid cell models are provided at ModelDB accession 144006 or http://people.bu.edu/zilli/gridmodels.html.},
	journal = {Front. Neural Circuits},
	author = {Zilli, Eric A},
	year = {2012},
	keywords = {merged\_fiete.bib, place cell, path integration, self-organization, ring attractor, medial temporal lobe},
	pages = {16},
}

@article{hasselmo_model_2012,
	title = {A model combining oscillations and attractor dynamics for generation of grid cell firing},
	volume = {6},
	abstract = {Different models have been able to account for different features of the data on grid cell firing properties, including the relationship of grid cells to cellular properties and network oscillations. This paper describes a model that combines elements of two major classes of models of grid cells: models using interactions of oscillations and models using attractor dynamics. This model includes a population of units with oscillatory input representing input from the medial septum. These units are termed heading angle cells because their connectivity depends upon heading angle in the environment as well as the spatial phase coded by the cell. These cells project to a population of grid cells. The sum of the heading angle input results in standing waves of circularly symmetric input to the grid cell population. Feedback from the grid cell population increases the activity of subsets of the heading angle cells, resulting in the network settling into activity patterns that resemble the patterns of firing fields in a population of grid cells. The properties of heading angle cells firing as conjunctive grid-by-head-direction cells can shift the grid cell firing according to movement velocity. The pattern of interaction of oscillations requires use of separate populations that fire on alternate cycles of the net theta rhythmic input to grid cells.},
	journal = {Front. Neural Circuits},
	author = {Hasselmo, Michael E and Brandon, Mark P},
	year = {2012},
	keywords = {entorhinal cortex, merged\_fiete.bib, spatial navigation, oscillatory interference, stellate cells, whole-cell patch recording},
	pages = {30},
}

@article{grossberg_beta_2009,
	title = {Beta oscillations and hippocampal place cell learning during exploration of novel environments},
	volume = {19},
	number = {9},
	journal = {Hippocampus},
	author = {Grossberg, Stephen},
	month = sep,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {881--885},
}

@article{moser_network_2013,
	title = {Network mechanisms of grid cells},
	volume = {369},
	number = {1635},
	journal = {Philos. Trans. R. Soc. Lond. B Biol. Sci.},
	author = {Moser, E I and Moser, M B and Roudi, Y},
	year = {2013},
	keywords = {merged\_fiete.bib},
}

@article{brecht_isomorphic_2014,
	title = {An isomorphic mapping hypothesis of the grid representation},
	volume = {369},
	journal = {Philos. Trans. R. Soc. Lond. B Biol. Sci.},
	author = {Brecht, M and Ray, S and Burgalossi, A and Tang, Q and Schmidt, H and Naumann, R},
	year = {2014},
	keywords = {merged\_fiete.bib},
}

@article{rudolph_analysis_2004,
	title = {Analysis of {GABAA} receptor function and dissection of the pharmacology of benzodiazepines and general anesthetics through mouse genetics},
	volume = {44},
	abstract = {GABAA receptors are molecular substrates for the regulation of vigilance, anxiety, muscle tension, epileptogenic activity, and memory functions, and the enhancement of GABAA receptor-mediated fast synaptic inhibition is the basis for the pharmacotherapy of various neurological and psychiatric disorders. Two kinds of GABAA receptor-targeted mutant mice have been generated: (a) knockout mice that lack individual GABAA receptor subunits (alpha1, alpha5, alpha6, beta2, beta3, gamma2, delta, and rho1) and (b) knockin mice that carry point mutations affecting the action of modulatory drugs [alpha1(H101R), alpha2(H101R), alpha3(H126R), alpha5(H105R), and beta3(N265M)]. Whereas the knockout mice have provided information primarily with respect to the regulation of subunit gene transcription, receptor assembly, and some physiological functions of individual receptor subtypes, the point-mutated knockin mice in which specific GABAA receptor subtypes are insensitive to diazepam or some general anesthetics have revealed the specific contribution of individual receptor subtypes to the pharmacological spectrum of diazepam and general anesthetics.},
	journal = {Annu. Rev. Pharmacol. Toxicol.},
	author = {Rudolph, Uwe and Möhler, Hanns},
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {475--498},
}

@article{moser_conserved_1994,
	title = {Conserved spatial learning in cooled rats in spite of slowing of dentate field potentials},
	volume = {14},
	number = {7},
	journal = {J. Neurosci.},
	author = {Moser, E I and Anderson, P},
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {4458--4466},
}

@article{buetfering_parvalbumin_2014,
	title = {Parvalbumin interneurons provide grid cell-driven recurrent inhibition in the medial entorhinal cortex},
	volume = {17},
	abstract = {Grid cells in the medial entorhinal cortex (MEC) generate metric spatial representations. Recent attractor-network models suggest an essential role for GABAergic interneurons in the emergence of the grid-cell firing pattern through recurrent inhibition dependent on grid-cell phase. To test this hypothesis, we studied identified parvalbumin-expressing (PV(+)) interneurons that are the most likely candidate for providing this recurrent inhibition onto grid cells. Using optogenetics and tetrode recordings in mice, we found that PV(+) interneurons exhibited high firing rates, low spatial sparsity and no spatial periodicity. PV(+) interneurons inhibited all functionally defined cell types in the MEC and were in turn recruited preferentially by grid cells. To our surprise, we found that individual PV(+) interneurons received input from grid cells with various phases, which most likely accounts for the broadly tuned spatial firing activity of PV(+) interneurons. Our data argue against the notion that PV(+) interneurons provide phase-dependent recurrent inhibition and challenge recent attractor-network models of grid cells.},
	number = {5},
	journal = {Nat. Neurosci.},
	author = {Buetfering, C and Allen, K and Monyer, H},
	month = may,
	year = {2014},
	keywords = {merged\_fiete.bib},
	pages = {710--718},
}

@inproceedings{stensola_grip_2013,
	title = {The grip map anchors systematically to environment geometry},
	booktitle = {{SFN} {Poster}},
	author = {Stensola, T and Stensola, H and Moser, M B and Moser, E I},
	year = {2013},
	keywords = {merged\_fiete.bib},
}

@article{mathis_optimal_2012,
	title = {Optimal population codes for space: grid cells outperform place cells},
	volume = {24},
	journal = {Neural Comput.},
	author = {Mathis, A and Herz, A and Stemmler, M},
	year = {2012},
	keywords = {merged\_fiete.bib, grid cells exponential capacity},
	pages = {2280--2317},
}

@article{bush_hybrid_2014,
	title = {A hybrid oscillatory interference/continuous attractor network model of grid cell firing},
	volume = {34},
	number = {14},
	journal = {J. Neurosci.},
	author = {Bush, D and Burgess, N},
	year = {2014},
	keywords = {merged\_fiete.bib},
	pages = {5065--5079},
}

@article{holmgren_coincident_2001,
	title = {Coincident spiking activity induces long-term changes in inhibition of neocortical pyramidal cells},
	volume = {21},
	number = {20},
	journal = {J. Neurosci.},
	author = {Holmgren, C. Zilberter, Y},
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {8270--8277},
}

@article{stewart_boundary_2014,
	title = {Boundary coding in the rat subiculum},
	volume = {369},
	journal = {Philos. Trans. R. Soc. Lond. B Biol. Sci.},
	author = {Stewart, S and Jeewajee, A and Wills, T J and Burgess, N and Lever, C},
	year = {2014},
	keywords = {merged\_fiete.bib},
}

@article{giocomo_topography_2014,
	title = {Topography of head direction cells in medial entorhinal cortex},
	volume = {24},
	journal = {Cell},
	author = {Giocomo, L M and Stensola, T and Bonnevie, T and Van Cauter, T and Moser, M B and Moser, E I},
	year = {2014},
	keywords = {merged\_fiete.bib},
	pages = {252--262},
}

@article{bjerknes_representation_2014,
	title = {Representation of geometric borders in the developing rat},
	volume = {82},
	journal = {Neuron},
	author = {Bjerknes, T L and Moser, E I and Moser, M B},
	year = {2014},
	keywords = {merged\_fiete.bib},
	pages = {1--8},
}

@article{brun_progressive_2008,
	title = {Progressive increase in grid scale from dorsal to ventral medial entorhinal cortex},
	volume = {18},
	abstract = {Grid cells are topographically organized in the sense that, within the dorsal part of the medial entorhinal cortex, the scale of the grid increases systematically with anatomical distance from the dorsal border of this brain area. The ventral limit of the spatial map is currently not known. To determine if the grid map extends into the intermediate and ventral parts of the medial entorhinal cortex, we recorded activity from entorhinal principal cells at multiple dorsoventral levels while rats shuttled back and forth on an 18 m long linear track. The recordings spanned a range of more than 3 mm, covering approximately three quarters of the dorsoventral extent of the medial entorhinal cortex. Distinct periodic firing fields were observed at all recording levels. The average interpeak distance between the fields increased from approximately 50 cm in the most dorsal part to approximately 3 m at the most ventral recording positions. The increase in grid scale was accompanied by a decrease in the frequency of theta modulation and the rate of phase precession. The increase in average spacing and field size was approximately linear but this relationship coincided with a substantial increase in the variability of each measure. Taken together, the observations suggest that the spatial scale of the grid representation increases progressively along most of the dorsoventral axis of the medial entorhinal cortex, mirroring the topographical scale expansion observed in place cells in the hippocampus.},
	number = {12},
	journal = {Hippocampus},
	author = {Brun, Vegard Heimly and Solstad, Trygve and Kjelstrup, Kirsten Brun and Fyhn, Marianne and Witter, Menno P and Moser, Edvard I and Moser, May-Britt},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {1200--1212},
}

@article{lamsa_spike-timing_2010,
	title = {Spike-timing dependent plasticity in inhibitory circuits},
	volume = {2},
	abstract = {Inhibitory circuits in the brain rely on GABA-releasing interneurons. For long, inhibitory circuits were considered weakly plastic in the face of patterns of neuronal activity that trigger long-term changes in the synapses between excitatory principal cells. Recent studies however have shown that GABAergic circuits undergo various forms of long-term plasticity. For the purpose of this review, we identify three major long-term plasticity expression sites. The first locus is the glutamatergic synapses that excite GABAergic inhibitory cells and drive their activity. Such synapses, on many but not all inhibitory interneurons, exhibit long-term potentiation (LTP) and depression (LTD). Second, GABAergic synapses themselves can undergo changes in GABA release probability or postsynaptic GABA receptors. The third site of plasticity is in the postsynaptic anion gradient of GABAergic synapses; coincident firing of GABAergic axons and postsynaptic neurons can cause a long-lasting change in the reversal potential of GABA(A) receptors mediating fast inhibitory postsynaptic potentials. We review the recent literature on these forms of plasticity by asking how they may be triggered by specific patterns of pre- and postsynaptic action potentials, although very few studies have directly examined spike-timing dependent plasticity (STDP) protocols in inhibitory circuits. Plasticity of interneuron recruitment and of GABAergic signaling provides for a rich flexibility in inhibition that may be central to many aspects of brain function. We do not consider plasticity at glutamatergic synapses on Purkinje cells and other GABAergic principal cells.},
	journal = {Front. Synaptic Neurosci.},
	author = {Lamsa, Karri P and Kullmann, Dimitri M and Woodin, Melanie A},
	year = {2010},
	keywords = {merged\_fiete.bib, chloride, fast-spiking, GABA, interneuron, KCC2, NKCC1, oscillation},
	pages = {8},
}

@article{lamsa_anti-hebbian_2007,
	title = {Anti-{Hebbian} long-term potentiation in the hippocampal feedback inhibitory circuit},
	volume = {315},
	abstract = {Long-term potentiation (LTP), which approximates Hebb's postulate of associative learning, typically requires depolarization-dependent glutamate receptors of the NMDA (N-methyl-D-aspartate) subtype. However, in some neurons, LTP depends instead on calcium-permeable AMPA-type receptors. This is paradoxical because intracellular polyamines block such receptors during depolarization. We report that LTP at synapses on hippocampal interneurons mediating feedback inhibition is “anti-Hebbian”:Itis induced by presynaptic activity but prevented by postsynaptic depolarization. Anti-Hebbian LTP may occur in interneurons that are silent during periods of intense pyramidal cell firing, such as sharp waves, and lead to their altered activation during theta activity.},
	number = {5816},
	journal = {Science},
	author = {Lamsa, Karri P and Heeroma, Joost H and Somogyi, Peter and Rusakov, Dmitri A and Kullmann, Dimitri M},
	month = mar,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {1262--1266},
}

@article{kullman_plasticity_2012,
	title = {Plasticity of inhibition},
	volume = {75},
	journal = {Neuron},
	author = {Kullman, D M and Moreau, A W and Bakiri, Y and Nicholson, E},
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {951--962},
}

@article{fino_spike-timing_2011,
	title = {Spike-timing dependent plasticity in striatal interneurons},
	volume = {60},
	abstract = {Basal ganglia, an ensemble of interconnected subcortical nuclei, are involved in adaptive motor planning and procedural learning. Striatum, the primary input nucleus of basal ganglia, extracts the pertinent cortical and thalamic information from background noise in relation with the environmental stimuli and motivation. The striatum comprises different neuronal populations: the GABAergic striatal output neurons, three classes of GABAergic interneurons and the cholinergic cells. Striatal interneurons exert a powerful control of striatal output neuron excitability and therefore shape the cortico-basal ganglia information processing. Besides output neurons, striatal interneurons also receive directly cortical information and are able to adapt their behavior depending on the level of cortical and striatal activation. In this review, we focus on the corticostriatal long-term synaptic efficacy changes occurring in interneurons, and especially the spike-timing dependent plasticity (STDP), as a Hebbian synaptic learning rule. Combined with the striatal local interactions between interneurons and output neurons, we will consider the functional consequences of the interneuron plasticity on the striatal output. This article is part of a Special Issue entitled 'Synaptic Plasticity \& Interneurons'.},
	number = {5},
	journal = {Neuropharmacology},
	author = {Fino, Elodie and Venance, Laurent},
	month = apr,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {780--788},
}

@article{markram_history_2011,
	title = {A history of spike-timing-dependent plasticity},
	volume = {3},
	abstract = {How learning and memory is achieved in the brain is a central question in neuroscience. Key to today's research into information storage in the brain is the concept of synaptic plasticity, a notion that has been heavily influenced by Hebb's (1949) postulate. Hebb conjectured that repeatedly and persistently co-active cells should increase connective strength among populations of interconnected neurons as a means of storing a memory trace, also known as an engram. Hebb certainly was not the first to make such a conjecture, as we show in this history. Nevertheless, literally thousands of studies into the classical frequency-dependent paradigm of cellular learning rules were directly inspired by the Hebbian postulate. But in more recent years, a novel concept in cellular learning has emerged, where temporal order instead of frequency is emphasized. This new learning paradigm - known as spike-timing-dependent plasticity (STDP) - has rapidly gained tremendous interest, perhaps because of its combination of elegant simplicity, biological plausibility, and computational power. But what are the roots of today's STDP concept? Here, we discuss several centuries of diverse thinking, beginning with philosophers such as Aristotle, Locke, and Ribot, traversing, e.g., Lugaro's plasticità and Rosenblatt's perceptron, and culminating with the discovery of STDP. We highlight interactions between theoretical and experimental fields, showing how discoveries sometimes occurred in parallel, seemingly without much knowledge of the other field, and sometimes via concrete back-and-forth communication. We point out where the future directions may lie, which includes interneuron STDP, the functional impact of STDP, its mechanisms and its neuromodulatory regulation, and the linking of STDP to the developmental formation and continuous plasticity of neuronal networks.},
	journal = {Front. Synaptic Neurosci.},
	author = {Markram, Henry and Gerstner, Wulfram and Sjöström, Per Jesper},
	year = {2011},
	keywords = {merged\_fiete.bib, learning, memory, history, bidirectional plasticity, long term depression, long term plasticity, spike-timing-dependent plasticity, synaptic plasticity},
	pages = {4},
}

@article{lamsa_hebbian_2005,
	title = {Hebbian {LTP} in feed-forward inhibitory interneurons and the temporal fidelity of input discrimination},
	volume = {8},
	abstract = {Cortical information processing requires a delicate balance of excitatory and inhibitory signaling. How is this balance preserved during hippocampal memory encoding, which involves NMDA receptor-dependent long term potentiation (LTP)? This form of LTP occurs at synapses between pyramidal neurons but has not been detected in feed-forward inhibitory interneurons. We show that paired pre- and postsynaptic activity evokes pathway-specific LTP in half of rat stratum radiatum interneurons if cytoplasmic integrity is preserved. LTP occurs in aspiny feed-forward interneurons and propagates to pyramidal neurons as an enhancement of disynaptic inhibition. We also show that when LTP is restricted to synapses on pyramidal neurons, the temporal fidelity of synaptic integration and action potential generation in pyramidal cells is compromised. However, when LTP also occurs at synapses on feed-forward interneurons, temporal fidelity is preserved. We propose that Hebbian LTP at synapses driving disynaptic inhibition is necessary to maintain information processing without degradation during memory encoding.},
	number = {7},
	journal = {Nat. Neurosci.},
	author = {Lamsa, Karri and Heeroma, Joost H and Kullmann, Dimitri M},
	month = jul,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {916--924},
}

@article{tzounopoulos_cell-specific_2004,
	title = {Cell-specific, spike timing-dependent plasticities in the dorsal cochlear nucleus},
	volume = {7},
	abstract = {In the dorsal cochlear nucleus, long-term synaptic plasticity can be induced at the parallel fiber inputs that synapse onto both fusiform principal neurons and cartwheel feedforward inhibitory interneurons. Here we report that in mouse fusiform cells, spikes evoked 5 ms after parallel-fiber excitatory postsynaptic potentials (EPSPs) led to long-term potentiation (LTP), whereas spikes evoked 5 ms before EPSPs led to long-term depression (LTD) of the synapse. The EPSP-spike protocol led to LTD in cartwheel cells, but no synaptic changes resulted from the reverse sequence (spike-EPSP). Plasticity in fusiform and cartwheel cells therefore followed Hebbian and anti-Hebbian learning rules, respectively. Similarly, spikes generated by summing EPSPs from different groups of parallel fibers produced LTP in fusiform cells, and LTD in cartwheel cells. LTD could also be induced in glutamatergic inputs of cartwheel cells by pairing parallel-fiber EPSPs with depolarizing glycinergic PSPs from neighboring cartwheel cells. Thus, synaptic learning rules vary with the postsynaptic cell, and may require the interaction of different transmitter systems.},
	number = {7},
	journal = {Nat. Neurosci.},
	author = {Tzounopoulos, Thanos and Kim, Yuil and Oertel, Donata and Trussell, Laurence O},
	month = jul,
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {719--725},
}

@article{letzkus_learning_2006,
	title = {Learning rules for spike timing-dependent plasticity depend on dendritic synapse location},
	volume = {26},
	abstract = {Previous studies focusing on the temporal rules governing changes in synaptic strength during spike timing-dependent synaptic plasticity (STDP) have paid little attention to the fact that synaptic inputs are distributed across complex dendritic trees. During STDP, propagation of action potentials (APs) back to the site of synaptic input is thought to trigger plasticity. However, in pyramidal neurons, backpropagation of single APs is decremental, whereas high-frequency bursts lead to generation of distal dendritic calcium spikes. This raises the question whether STDP learning rules depend on synapse location and firing mode. Here, we investigate this issue at synapses between layer 2/3 and layer 5 pyramidal neurons in somatosensory cortex. We find that low-frequency pairing of single APs at positive times leads to a distance-dependent shift to long-term depression (LTD) at distal inputs. At proximal sites, this LTD could be converted to long-term potentiation (LTP) by dendritic depolarizations suprathreshold for BAC-firing or by high-frequency AP bursts. During AP bursts, we observed a progressive, distance-dependent shift in the timing requirements for induction of LTP and LTD, such that distal synapses display novel timing rules: they potentiate when inputs are activated after burst onset (negative timing) but depress when activated before burst onset (positive timing). These findings could be explained by distance-dependent differences in the underlying dendritic voltage waveforms driving NMDA receptor activation during STDP induction. Our results suggest that synapse location within the dendritic tree is a crucial determinant of STDP, and that synapses undergo plasticity according to local rather than global learning rules.},
	number = {41},
	journal = {J. Neurosci.},
	author = {Letzkus, Johannes J and Kampa, Björn M and Stuart, Greg J},
	month = oct,
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {10420--10429},
}

@article{sjostrom_cooperative_2006,
	title = {A cooperative switch determines the sign of synaptic plasticity in distal dendrites of neocortical pyramidal neurons},
	volume = {51},
	abstract = {Pyramidal neurons in the cerebral cortex span multiple cortical layers. How the excitable properties of pyramidal neuron dendrites allow these neurons to both integrate activity and store associations between different layers is not well understood, but is thought to rely in part on dendritic backpropagation of action potentials. Here we demonstrate that the sign of synaptic plasticity in neocortical pyramidal neurons is regulated by the spread of the backpropagating action potential to the synapse. This creates a progressive gradient between LTP and LTD as the distance of the synaptic contacts from the soma increases. At distal synapses, cooperative synaptic input or dendritic depolarization can switch plasticity between LTD and LTP by boosting backpropagation of action potentials. This activity-dependent switch provides a mechanism for associative learning across different neocortical layers that process distinct types of information.},
	number = {2},
	journal = {Neuron},
	author = {Sjöström, Per Jesper and Häusser, Michael},
	month = jul,
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {227--238},
}

@article{froemke_spike-timing-dependent_2005,
	title = {Spike-timing-dependent synaptic plasticity depends on dendritic location},
	volume = {434},
	abstract = {Most plant species are resistant to most potential pathogens. It is not known why most plant-microbe interactions do not lead to disease, although recent work indicates that this basic disease resistance is multi-factorial. Here we show that the exudation of root-derived antimicrobial metabolites by Arabidopsis thaliana confers tissue-specific resistance to a wide range of bacterial pathogens. However, a Pseudomonas syringae strain that is both at least partly resistant to these compounds and capable of blocking their synthesis/exudation is able to infect the roots and cause disease. We also show that the ability of this P. syringae strain to block antimicrobial exudation is dependent on the type III secretory system.},
	journal = {Nature},
	author = {Froemke, R C and Poo, Mu-Ming and Dan, Y},
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {221--225},
}

@article{sjostrom_rate_2001,
	title = {Rate, timing, and cooperativity jointly determine cortical synaptic plasticity},
	volume = {32},
	abstract = {Cortical long-term plasticity depends on firing rate, spike timing, and cooperativity among inputs, but how these factors interact during realistic patterns of activity is unknown. Here we monitored plasticity while systematically varying the rate, spike timing, and number of coincident afferents. These experiments demonstrate a novel form of cooperativity operating even when postsynaptic firing is evoked by current injection, and reveal a complex dependence of LTP and LTD on rate and timing. Based on these data, we constructed and tested three quantitative models of cortical plasticity. One of these models, in which spike-timing relationships causing LTP “win” out over those favoring LTD, closely fits the data and accurately predicts the build-up of plasticity during random firing. This provides a quantitative framework for predicting the impact of in vivo firing patterns on synaptic strength.},
	number = {6},
	journal = {Neuron},
	author = {Sjöström, P J and Turrigiano, G G and Nelson, S B},
	month = dec,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {1149--1164},
}

@article{debanne_long-term_1998,
	title = {Long-term synaptic plasticity between pairs of individual {CA3} pyramidal cells in rat hippocampal slice cultures},
	volume = {507},
	number = {1},
	journal = {J. Physiol.},
	author = {Debanne, D and Gahwiler, B H and Thompson, S M},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {237--247},
}

@article{butts_retinal_2002,
	title = {Retinal waves: {Implications} for synaptic learning rules during development},
	volume = {8},
	number = {3},
	journal = {Neuroscientist},
	author = {Butts, D A},
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {243--253},
}

@article{fino_spike-timing_2010,
	title = {Spike-timing dependent plasticity in the striatum},
	volume = {2},
	abstract = {The striatum is the major input nucleus of basal ganglia, an ensemble of interconnected sub-cortical nuclei associated with fundamental processes of action-selection and procedural learning and memory. The striatum receives afferents from the cerebral cortex and the thalamus. In turn, it relays the integrated information towards the basal ganglia output nuclei through which it operates a selected activation of behavioral effectors. The striatal output neurons, the GABAergic medium-sized spiny neurons (MSNs), are in charge of the detection and integration of behaviorally relevant information. This property confers to the striatum the ability to extract relevant information from the background noise and select cognitive-motor sequences adapted to environmental stimuli. As long-term synaptic efficacy changes are believed to underlie learning and memory, the corticostriatal long-term plasticity provides a fundamental mechanism for the function of the basal ganglia in procedural learning. Here, we reviewed the different forms of spike-timing dependent plasticity (STDP) occurring at corticostriatal synapses. Most of the studies have focused on MSNs and their ability to develop long-term plasticity. Nevertheless, the striatal interneurons (the fast-spiking GABAergic, NO-synthase and cholinergic interneurons) also receive monosynaptic afferents from the cortex and tightly regulated corticostriatal information processing. Therefore, it is important to take into account the variety of striatal neurons to fully understand the ability of striatum to develop long-term plasticity. Corticostriatal STDP with various spike-timing dependence have been observed depending on the neuronal sub-populations and experimental conditions. This complexity highlights the extraordinary potentiality in term of plasticity of the corticostriatal pathway.},
	journal = {Front. Synaptic Neurosci.},
	author = {Fino, Elodie and Venance, Laurent},
	year = {2010},
	keywords = {merged\_fiete.bib, basal ganglia, cholinergic interneurons, corticostriatal, GABAergic interneurons, LTD, LTP, spike-timing dependent plasticity, striatum},
	pages = {6},
}

@article{huang_adrenergic_2013,
	title = {Adrenergic gating of {Hebbian} spike-timing-dependent plasticity in cortical interneurons},
	volume = {33},
	abstract = {In pyramidal cells, the induction of spike-dependent plasticity (STDP) follows a simple Hebbian rule in which the order of presynaptic and postsynaptic firing dictates the induction of LTP or LTD. In contrast, cortical fast spiking (FS) interneurons, which control the rate and timing of pyramidal cell firing, reportedly express timing-dependent LTD, but not timing-dependent LTP. Because a mismatch in STDP rules could impact the maintenance of the excitation/inhibition balance, we examined the neuromodulation of STDP in FS cells of mouse visual cortex. We found that stimulation of adrenergic receptors enables the induction of Hebbian bidirectional STDP in FS cells in a manner consistent with a pull-push mechanism previously characterized in pyramidal cells. However, in pyramidal cells, STDP induction depends on NMDA receptors, whereas in FS cells it depends on mGluR5 receptors. We propose that neuromodulators control the polarity of STDP in different synapses in the same manner, and independently of the induction mechanism, by acting downstream in the plasticity cascade. By doing so, neuromodulators may allow coordinated plastic changes in FS and pyramidal cells.},
	number = {32},
	journal = {J. Neurosci.},
	author = {Huang, Shiyong and Huganir, Richard L and Kirkwood, Alfredo},
	month = aug,
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {13171--13178},
}

@article{lu_spike-timing-dependent_2007,
	title = {Spike-timing-dependent plasticity of neocortical excitatory synapses on inhibitory interneurons depends on target cell type},
	volume = {27},
	abstract = {Repetitive correlated spiking can induce long-term potentiation (LTP) and long-term depression (LTD) of many excitatory synapses on glutamatergic neurons, in a manner that depends on the timing of presynaptic and postsynaptic spiking. However, it is mostly unknown whether and how such spike-timing-dependent plasticity (STDP) operates at neocortical excitatory synapses on inhibitory interneurons, which have diverse physiological and morphological characteristics. In this study, we found that these synapses exhibit target-cell-dependent STDP. In layer 2/3 of the somatosensory cortex, the pyramidal cell (PC) forms divergent synapses on fast spiking (FS) and low-threshold spiking (LTS) interneurons that exhibit short-term synaptic depression and facilitation in response to high-frequency stimulation, respectively. At PC-LTS synapses, repetitive correlated spiking induced LTP or LTD, depending on the timing of presynaptic and postsynaptic spiking. However, regardless of the timing and frequency of spiking, correlated activity induced only LTD at PC-FS synapses. This target-cell-specific STDP was not caused by the difference in the short-term plasticity between these two types of synapses. Activation of postsynaptic NMDA subtype of glutamate receptors (NMDARs) was required for LTP induction at PC-LTS synapses, whereas activation of metabotropic glutamate receptors was required for LTD induction at both PC-LTS and PC-FS synapses. Additional analysis of synaptic currents suggests that LTP and LTD of PC-LTS synapses, but not LTD of PC-FS synapses, involves presynaptic modifications. Such dependence of both the induction and expression of STDP on the type of postsynaptic interneurons may contribute to differential processing and storage of information in cortical local circuits.},
	number = {36},
	journal = {J. Neurosci.},
	author = {Lu, Jiang-Teng and Li, Cheng-Yu and Zhao, Jian-Ping and Poo, Mu-Ming and Zhang, Xiao-Hui},
	month = sep,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {9711--9720},
}

@article{beed_inhibitory_2013,
	title = {Inhibitory gradient along the dorsoventral axis in the medial entorhinal cortex},
	volume = {79},
	journal = {Neuron},
	author = {Beed, P and Gundlfinger, A and Schneiderbauer, S and Song, J and Bohm, C and Burgalossi, A and Brecht, M and Vida, I and Schmitz, D},
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {1197--1207},
}

@article{brun_impaired_2008,
	title = {Impaired spatial representation in {CA1} after lesion of direct input from entorhinal cortex},
	volume = {57},
	abstract = {Place-specific firing in the hippocampus is determined by path integration-based spatial representations in the grid-cell network of the medial entorhinal cortex. Output from this network is conveyed directly to CA1 of the hippocampus by projections from principal neurons in layer III, but also indirectly by axons from layer II to the dentate gyrus and CA3. The direct pathway is sufficient for spatial firing in CA1, but it is not known whether similar firing can also be supported by the input from CA3. To test this possibility, we made selective lesions in layer III of medial entorhinal cortex by local infusion of the neurotoxin gamma-acetylenic GABA. Firing fields in CA1 became larger and more dispersed after cell loss in layer III, whereas CA3 cells, which receive layer II input, still had sharp firing fields. Thus, the direct projection is necessary for precise spatial firing in the CA1 place cell population.},
	number = {2},
	journal = {Neuron},
	author = {Brun, Vegard Heimly and Leutgeb, Stefan and Wu, Hui-Qiu and Schwarcz, Robert and Witter, Menno P and Moser, Edvard I and Moser, May-Britt},
	month = jan,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {290--302},
}

@article{colgin_attractor-map_2010,
	title = {Attractor-map versus autoassociation based attractor dynamics in the hippocampal network},
	volume = {104},
	abstract = {The autoassociative memory model of hippocampal field CA3 postulates that Hebbian associations among external input features produce attractor states embedded in a recurrent synaptic matrix. In contrast, the attractor-map model postulates that a two-dimensional continuum of attractor states is preconfigured in the network during development and that transitions among these states are governed primarily by self-motion information (“path-integration”), giving rise to the strong spatial characteristic of hippocampal activity. In this model, learned associations between “coordinates” on the attractor map and external cues can result in abrupt jumps between states, in the case of mismatches between the current input and previous associations between internal coordinates and external landmarks. Both models predict attractor dynamics, but for fundamentally different reasons; however, the two models are not a priori mutually exclusive. We contrasted these two models by comparing the dynamics of state transitions when two previously learned environmental shapes were morphed between their endpoints, in animals that had first experienced the environments either at the same location, or at two different locations, connected by a passageway through which they walked. As predicted from attractor-map theory, the latter animals expressed abrupt transitions between representations at the midpoint of the morph series. Contrary to the predictions of autoassociation theory, the former group expressed no evidence of attractor dynamics during the morph series; there was only a gradual transition between endpoints. The results of this critical test thus cast the autoassociator theory for CA3 into doubt and indicate the need for a new theory for this structure.},
	number = {1},
	journal = {J. Neurophysiol.},
	author = {Colgin, L L and Leutgeb, S and Jezek, K and Leutgeb, J K and Moser, E and McNaughton, B and Moser, M},
	month = jul,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {35--50},
}

@article{yoshida_frequency_2011,
	title = {Frequency of subthreshold oscillations at different membrane potential voltages in neurons at different anatomical positions on the dorsoventral axis in the rat medial entorhinal cortex},
	volume = {31},
	abstract = {Neurons from layer II of the medial entorhinal cortex show subthreshold membrane potential oscillations (SMPOs) which could contribute to theta-rhythm generation in the entorhinal cortex and to generation of grid cell firing patterns. However, it is unclear whether single neurons have a fixed unique oscillation frequency or whether their frequency varies depending on the mean membrane potential in a cell. We therefore examined the frequency of SMPOs at different membrane potentials in layer II stellate-like cells of the rat medial entorhinal cortex in vitro. Using whole-cell patch recordings, we found that the fluctuations in membrane potential show a broad band of low power frequencies near resting potential that transition to more narrowband oscillation frequencies with depolarization. The transition from broadband to narrowband frequencies depends on the location of the neuron along the dorsoventral axis in the entorhinal cortex, with dorsal neurons transitioning to higher-frequency oscillations relative to ventral neurons transitioning to lower-frequency oscillations. Once SMPOs showed a narrowband frequency, systematic frequency changes were not observed with further depolarization. Using a Hodgkin-Huxley-style model of membrane currents, we show that differences in the influence of depolarization on the frequency of SMPOs at different dorsal to ventral positions could arise from differences in the properties of the h current. The properties of frequency changes in this data are important for evaluating models of the generation of grid cell firing fields with different spacings along the dorsal-to-ventral axis of medial entorhinal cortex.},
	number = {35},
	journal = {J. Neurosci.},
	author = {Yoshida, Motoharu and Giocomo, Lisa M and Boardman, Ian and Hasselmo, Michael E},
	month = aug,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {12683--12694},
}

@article{leutgeb_fast_2006,
	title = {Fast rate coding in hippocampal {CA3} cell ensembles},
	volume = {16},
	abstract = {Environments with overlapping features are represented by distinct patterns of activity in the hippocampus, enabling information to be stored and retrieved with minimal interference. This orthogonalization of correlated inputs is thought to take place within the hippocampus itself. However, the orthogonalization process has been shown to take days to develop in CA1. This prolonged time course is in striking contrast to the fast encoding of behavioral memory by the hippocampus. To explore this apparent paradox, we asked whether orthogonalization depended on the type of remapping exhibited by the hippocampal network. We have previously distinguished two types of remapping, global remapping, which results in the activation of different assemblies of place fields, and rate remapping, which encodes differences between cue constellations by substantial changes in firing rate without a change in the place code. Global remapping has previously been shown to be expressed immediately at novel locations. Here we asked if rate remapping follows a slower time course. Ensemble activity was recorded simultaneously from CA3 and CA1 in rats exposed to two similar, novel environments. It was found that rate changes in response to novel sensory cue configurations can form immediately, just as during global remapping, in particular in CA3. The fast encoding of both spatial and nonspatial information in CA3 is consistent with a role for the autoassociative CA3 circuitry in the acquisition and expression of episodic memories.},
	number = {9},
	journal = {Hippocampus},
	author = {Leutgeb, S and Leutgeb, J and Moser, E and Moser, M},
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {765--774},
}

@article{lee_double_2004,
	title = {A double dissociation between hippocampal subfields: differential time course of {CA3} and {CA1} place cells for processing changed environments},
	volume = {42},
	abstract = {Computational theories have suggested different functions for the hippocampal subfields (e.g., CA1 and CA3) in memory. However, it has been difficult to find dissociations relevant to these hypothesized functions in investigations of the hippocampal correlates of space (“place fields”) in freely behaving animals. The current study demonstrates a double dissociation between the shifts in the center of mass (COM) of the place fields that were simultaneously recorded in CA1 and CA3 when familiar cue configurations were dynamically changed over days. The COM of CA3 place fields shifted backward in the first experience of the cue-changed environment, whereas the COM of CA1 place fields did not display the backward shift until the next day. These results support the hypothesis that CA3 plays a key role in the rapid formation of representations of new spatiotemporal sequences, whereas CA1 may be more important for comparing currently experienced sequence information with stored sequences in the CA3 network.},
	number = {5},
	journal = {Neuron},
	author = {Lee, I and Rao, G and Knierim, J},
	month = jun,
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {803--815},
}

@article{lee_comparison_2004,
	title = {Comparison of population coherence of place cells in hippocampal subfields {CA1} and {CA3}},
	volume = {430},
	journal = {Nature},
	author = {Lee, I and Yoganarasimha, D and Rao, G and Knierim, J J},
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {456--459},
}

@article{leutgeb_distinct_2004,
	title = {Distinct ensemble codes in hippocampal areas {CA3} and {CA1}},
	volume = {305},
	abstract = {The hippocampus has differentiated into an extensively connected recurrent stage (CA3) followed by a feed-forward stage (CA1). We examined the function of this structural differentiation by determining how cell ensembles in rat CA3 and CA1 generate representations of rooms with common spatial elements. In CA3, distinct subsets of pyramidal cells were activated in each room, regardless of the similarity of the testing enclosure. In CA1, the activated populations overlapped, and the overlap increased in similar enclosures. After exposure to a novel room, ensemble activity developed slower in CA3 than CA1, suggesting that the representations emerged independently.},
	number = {5688},
	journal = {Science},
	author = {Leutgeb, S and Leutgeb, J and Treves, A and Moser, M and Moser, E},
	month = aug,
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {1295--1298},
}

@article{abbott_theoretical_2008,
	title = {Theoretical neuroscience rising},
	volume = {60},
	abstract = {Theoretical neuroscience has experienced explosive growth over the past 20 years. In addition to bringing new researchers into the field with backgrounds in physics, mathematics, computer science, and engineering, theoretical approaches have helped to introduce new ideas and shape directions of neuroscience research. This review presents some of the developments that have occurred and the lessons they have taught us.},
	number = {3},
	journal = {Neuron},
	author = {Abbott, L F},
	month = nov,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {489--495},
}

@article{scott_maturational_2010,
	title = {Maturational dynamics of hippocampal place cells in immature rats},
	volume = {21},
	journal = {Hippocampus},
	author = {Scott, R C and Richard, G R and Holmes, G L and Lenck-Santini, P P},
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {346--353},
}

@article{deshmukh_influence_2013,
	title = {Influence of local objects on hippocampal representations: {Landmark} vectors and memory},
	volume = {23},
	abstract = {The hippocampus is thought to represent nonspatial information in the context of spatial information. An animal can derive both spatial information as well as nonspatial information from the objects (landmarks) it encounters as it moves around in an environment. In this article, correlates of both object-derived spatial as well as nonspatial information in the hippocampus of rats foraging in the presence of objects are demonstrated. A new form of CA1 place cells, called landmark-vector cells, that encode spatial locations as a vector relationship to local landmarks is described. Such landmark vector relationships can be dynamically encoded. Of the 26 CA1 neurons that developed new fields in the course of a day's recording sessions, in eight cases, the new fields were located at a similar distance and direction from a landmark as the initial field was located relative to a different landmark. In addition, object-location memory in the hippocampus is also described. When objects were removed from an environment or moved to new locations, a small number of neurons in CA1 and CA3 increased firing at the locations where the objects used to be. In some neurons, this increase occurred only in one location, indicating object + place conjunctive memory; in other neurons, the increase in firing was seen at multiple locations where an object used to be. Taken together, these results demonstrate that the spatially restricted firing of hippocampal neurons encode multiple types of information regarding the relationship between an animal's location and the location of objects in its environment. {\textbackslash}copyright 2013 Wiley Periodicals, Inc.},
	number = {4},
	journal = {Hippocampus},
	author = {Deshmukh, S S and Knierim, J J},
	month = feb,
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {253--267},
}

@article{hasselmo_cholinergic_1995,
	title = {Cholinergic modulation of activity-dependent synaptic plasticity in rat piriform cortex},
	volume = {15},
	number = {10},
	journal = {J. Neurosci.},
	author = {Hasselmo, M E and Barkai, E},
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {6592--6604},
}

@article{barry_grid_2012,
	title = {Grid cell firing patterns signal environmental novelty by expansion},
	volume = {109},
	abstract = {The hippocampal formation plays key roles in representing an animal's location and in detecting environmental novelty to create or update those representations. However, the mechanisms behind this latter function are unclear. Here, we show that environmental novelty causes the spatial firing patterns of grid cells to expand in scale and reduce in regularity, reverting to their familiar scale as the environment becomes familiar. Simultaneously recorded place cell firing fields remapped and showed a smaller, temporary expansion. Grid expansion provides a potential mechanism for novelty signaling and may enhance the formation of new hippocampal representations, whereas the subsequent slow reduction in scale provides a potential familiarity signal.},
	number = {43},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Barry, C and Ginzberg, L L and O'Keefe, J and Burgess, N},
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {17687--17692},
}

@article{dembo_cover_2004,
	title = {Cover times for brownian motion and random walks in two dimensions},
	volume = {160},
	journal = {Ann. Math.},
	author = {Dembo, A and Peres, Y and Rosen, J and Zeitouni, O},
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {433--464},
}

@article{stella_associative_2011,
	title = {Associative memory storage and retrieval: involvement of theta oscillations in hippocampal information processing},
	volume = {2011},
	abstract = {Theta oscillations are thought to play a critical role in neuronal information processing, especially in the hippocampal region, where their presence is particularly salient. A detailed description of theta dynamics in this region has revealed not only a consortium of layer-specific theta dipoles, but also within-layer differences in the expression of theta. This complex and articulated arrangement of current flows is reflected in the way neuronal firing is modulated in time. Several models have proposed that these different theta modulators flexibly coordinate hippocampal regions, to support associative memory formation and retrieval. Here, we summarily review different approaches related to this issue and we describe a mechanism, based on experimental and simulation results, for memory retrieval in CA3 involving theta modulation.},
	journal = {Neural Plast.},
	author = {Stella, Federico and Treves, Alessandro},
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {683961},
}

@incollection{chokshi_learning_2003,
	title = {Learning localization based on landmarks using self-organization},
	booktitle = {Artificial {Neural} {Networks} and {Neural} {Information} {Processing}},
	publisher = {Springer-Verlag},
	author = {Chokshi, K and Wermter, S and Weber, C},
	editor = {Kaynak, O and Alpaydin, E and Oja, E and Xu, L},
	year = {2003},
	keywords = {merged\_fiete.bib},
}

@article{ohshiro_normalization_2011,
	title = {A normalization model of multisensory integration},
	volume = {6},
	journal = {Nat. Neurosci.},
	author = {Ohshiro, T and Angelaki, D E and DeAngelis, G C},
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {775--782},
}

@article{naka_s-potentials_1966,
	title = {S-potentials from luminosity units in the retina of fish ({Cyprinidae})},
	volume = {185},
	journal = {J. Physiol.},
	author = {Naka, K I and Rushton, W A},
	year = {1966},
	keywords = {merged\_fiete.bib},
	pages = {587--599},
}

@article{baylor_electrical_1970,
	title = {Electrical responses of single cones in the retina of the turtle},
	volume = {297},
	journal = {J. Physiol.},
	author = {Baylor, D A and Fuortes, M G F},
	year = {1970},
	keywords = {merged\_fiete.bib},
	pages = {77--92},
}

@article{albrecht_motion_1991,
	title = {Motion sensitivity and the contrast-response function of simple cells in the visual cortex},
	volume = {7},
	journal = {Vis. Neurosci.},
	author = {Albrecht, D G and Geisler, W S},
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {531--546},
}

@article{cho_retrograde_1995,
	title = {Retrograde and anterograde amnesia for spatial discrimination in rats: role of hippocampus, entorhinal cortex, and parietal cortex},
	volume = {23},
	number = {3},
	journal = {Psychobiology},
	author = {Cho, Y H and Kesner, R P and Brodale, S},
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {185--194},
}

@article{navratilova_phase_2012,
	title = {Phase precession and variable spatial scaling in a periodic attractor map model of medial entorhinal grid cells with realistic after-spike dynamics},
	volume = {22},
	abstract = {We present a model that describes the generation of the spatial (grid fields) and temporal (phase precession) properties of medial entorhinal cortical (MEC) neurons by combining network and intrinsic cellular properties. The model incorporates network architecture derived from earlier attractor map models, and is implemented in 1D for simplicity. Periodic driving of conjunctive (position {\textbackslash}times head-direction) layer-III MEC cells at theta frequency with intensity proportional to the rat's speed, moves an 'activity bump' forward in network space at a corresponding speed. The addition of prolonged excitatory currents and simple after-spike dynamics resembling those observed in MEC stellate cells (for which new data are presented) accounts for both phase precession and the change in scale of grid fields along the dorso-ventral axis of MEC. Phase precession in the model depends on both synaptic connectivity and intrinsic currents, each of which drive neural spiking either during entry into, or during exit out of a grid field. Thus, the model predicts that the slope of phase precession changes between entry into and exit out of the field. The model also exhibits independent variation in grid spatial period and grid field size, which suggests possible experimental tests of the model.},
	number = {4},
	journal = {Hippocampus},
	author = {Navratilova, Zaneta and Giocomo, Lisa M and Fellous, Jean-Marc and Hasselmo, Michael E and McNaughton, Bruce L},
	month = apr,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {772--789},
}

@article{song_role_2005,
	title = {Role of active movement in place-specific firing of hippocampal neurons},
	volume = {15},
	abstract = {The extent of external and internal factors contributing to location-specific firing of hippocampal place cells is currently unclear. We investigated the role of active movement in location-specific firing by comparing spatial firing patterns of hippocampal neurons, while rats either ran freely or rode a motorized cart on the same circular track. Most neurons changed their spatial firing patterns across the two navigation conditions (“remapping”), and they were stably maintained across repeated active or passive navigation sessions. These results show that active movement is a critical factor in determining place-specific firing of hippocampal neurons. This could explain why passive displacement is not an effective way of acquiring spatial knowledge for subsequent active navigation in an unfamiliar environment.},
	number = {1},
	journal = {Hippocampus},
	author = {Song, Eun Young and Kim, Yun Bok and Kim, Young Ho and Jung, Min Whan},
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {8--17},
}

@article{stackman_passive_2003,
	title = {Passive transport disrupts directional path integration by rat head direction cells},
	volume = {90},
	journal = {J. Neurophysiol.},
	author = {Stackman, R W and Golob, E J and Bassett, J P and Taube, J S},
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {2862--2874},
}

@article{mehta_active_2007,
	title = {Active spatial perception in the vibrissa scanning sensorimotor system},
	volume = {5},
	number = {2},
	journal = {PLoS Comput. Biol.},
	author = {Mehta, S B and Whitmer, D and Figueroa, R and Williams, B A and Kleinfeld, D},
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {e 15},
}

@article{clark_hippocampus_2005,
	title = {Hippocampus and remote spatial memory in rats},
	volume = {15},
	journal = {Hippocampus},
	author = {Clark, R E and Broadbent, N J and Squire, L R},
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {260--272},
}

@article{kubie_hippocampal_1999,
	title = {Hippocampal lesions produce a temporally graded retrograde amnesia on a dry version of the {Morris} swimming task},
	volume = {27},
	journal = {Psychobiology},
	author = {Kubie, J L and Sutherland, R J and Muller, R U},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {313--330},
}

@inproceedings{kruge_grid_2013,
	title = {Grid cells of animals raised in spherical environments},
	booktitle = {{SFN} {Poster}},
	author = {Kruge, I U and Wernle, T and Moser, E I and Moser, M B},
	year = {2013},
	keywords = {merged\_fiete.bib},
}

@article{kunec_encoding_2005,
	title = {Encoding and retrieval in the {CA3} region of the hippocampus: a model of theta-phase separation},
	volume = {94},
	abstract = {Past research conducted by Hasselmo et al. in 2002 suggests that some fundamental tasks are better accomplished if memories are encoded and recovered during different parts of the theta cycle. A model of the CA3 subfield of the hippocampus is presented, using biophysical representations of the major cell types including pyramidal cells and two types of interneurons. Inputs to the network come from the septum and the entorhinal cortex (directly and by the dentate gyrus). A mechanism for parsing the theta rhythm into two epochs is proposed and simulated: in the first half, the strong, proximal input from the dentate to a subset of CA3 pyramidal cells and coincident, direct input from the entorhinal cortex to other pyramidal cells creates an environment for strengthening synapses between cells, thus encoding information. During the second half of theta, cueing signals from the entorhinal cortex, by the dentate, activate previously strengthened synapses, retrieving memories. Slow inhibitory neurons (O-LM cells) play a role in the disambiguation during retrieval. We compare and contrast our computational results with existing experimental data and other contemporary models.},
	number = {1},
	journal = {J. Neurophysiol.},
	author = {Kunec, Steve and Hasselmo, Michael E and Kopell, Nancy},
	month = jul,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {70--82},
}

@article{hasselmo_proposed_2002,
	title = {A proposed function of hippocampal theta rhythm: separate phases of encoding and retrieval enhance reversal of prior learning},
	volume = {14},
	journal = {Neural Comput.},
	author = {Hasselmo, M E and Bodelon, C and Wyble, B P},
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {793--817},
}

@article{villarreal_modulation_2007,
	title = {Modulation of {CA3} afferent inputs by novelty and theta rhythm},
	volume = {27},
	journal = {J. Neurosci.},
	author = {Villarreal, D M and Gross, A L and Derric, B E},
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {13457--13467},
}

@article{hasselmo_encoding_1996,
	title = {Encoding and retrieval of episodic memories: role of cholinergic and {GABAergic} moudlation in the hippocampus},
	volume = {6},
	journal = {Hippocampus},
	author = {Hasselmo, M E and Wyble, B P and Wallenstein, G V},
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {693--708},
}

@inproceedings{wyble_phase_2001,
	title = {Phase relationship of {LTP} induction and behavior to theta rhythm in the rat hippocampus},
	booktitle = {{SFN} {Poster}},
	author = {Wyble, B P and Hyman, J M and Goyal, V},
	year = {2001},
	keywords = {merged\_fiete.bib},
}

@article{orr_hippocampal_2001,
	title = {Hippocampal synaptic plasticity is modulated by theta rhythm in the fascia dentata of adult and aged freely behaving rats},
	volume = {11},
	abstract = {A modulatory role for the hippocampal theta rhythm in synaptic plasticity is suggested by the observations that theta occurs during exploratory behaviors, spatial learning is impaired when the theta rhythm is disrupted, and excitation of hippocampal principal cells is phase-coupled to the theta wave. The theta phase affects the nature of the plasticity induced in urethane-anesthetized rats and in the carbachol-treated in vitro slice preparation, but these oscillations are phenomenologically different from natural theta, and the effects of theta phase on plasticity under natural conditions have not been reported. We therefore examined the effects of theta phase on the magnitude of long-term potentiation (LTP) in awake rats running on a linear track for a food reward. Twelve adult and 10 aged F344 male rats were implanted with a stimulating electrode in the perforant path and a recording electrode in the hilus of the fascia dentata. Stimuli were delivered at the peak or trough of the hilar theta rhythm. In both adult and aged, memory-impaired rats, LTP lasting at least 48 h was induced when stimuli were delivered at the positive theta peak, whereas LTP was not induced when stimuli were delivered at the negative troughs. Consistent with the finding that the threshold for LTP induction is increased at this synapse in old rats, the magnitude of LTP induced at the peak of theta rhythm was significantly lower in old animals. These data confirm that LTP can be modulated by locomotion-induced theta, and that this modulation is at least qualitatively preserved across age.},
	number = {6},
	journal = {Hippocampus},
	author = {Orr, G and Rao, G and Houston, F P and McNaughton, B L and Barnes, C A},
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {647--654},
}

@article{holscher_stimulation_1997,
	title = {Stimulation on the positive phase of hippocampal theta rhythm induces long-term potentiation that can be depotentiated by stimulation on the negative phase in area {CA1} in vivo},
	volume = {17},
	number = {16},
	journal = {J. Neurosci.},
	author = {Holscher, C and Anwyl, R and Rowan, M J},
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {6470--6477},
}

@article{pavlides_long-term_1988,
	title = {Long-term potentiation in the dentate gyrus is induced preferentially on the positive phase of theta-rhythm},
	volume = {439},
	abstract = {Long-term potentiation (LTP), a long lasting enhancement of synaptic efficacy is considered a model for learning and memory. In anesthetized rats, theta-rhythm was induced in the dentate gyrus by midbrain stimulation. Short trains of pulses were applied to the perforant pathway either at the peak of theta-rhythm or its trough. Trains applied at the peak of theta-rhythm induced LTP while trains applied at the trough produced a decrease of synaptic efficacy or had no effect. Thus, theta-rhythm may play a modulating role in the induction of LTP, suggesting a possible mnemonic function for the rhythm during the behaviors in which it occurs.},
	number = {1-2},
	journal = {Brain Res.},
	author = {Pavlides, C and Greenstein, Y J and Grudman, M and Winson, J},
	month = jan,
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {383--387},
}

@inproceedings{carreira-perpignan_contrastive_2005,
	title = {On contrastive divergence learning},
	booktitle = {Proceedings of the {Tenth} {International} {Workshop} on {Artificial} {Intelligence} and {Statistics} {In} {Proceedings} of the {Tenth} {International} {Workshop} on {Artificial} {Intelligence} and {Statistics}, {Jan} 6-8, 2005, {Savannah} {Hotel}, {Barbados} (2005), pp. 33-40 {Key}: citeulike:635169},
	author = {Carreira-Perpignan, M A and Hinton, G E},
	editor = {Cowell, R G and Ghahramani, Z},
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {33--40},
}

@inproceedings{giocomo_topographical_2013,
	title = {Topographical organization of head direction signals in medial entorhinal cortex},
	author = {Giocomo, L M and Bonnevie, T and Stensola, T and Van Cauter, T and Moser, E I and Moser, M B},
	year = {2013},
	keywords = {merged\_fiete.bib},
}

@article{giocomo_grid_2011,
	title = {Grid cells use {HCN1} channels for spatial scaling},
	volume = {147},
	abstract = {Entorhinal grid cells have periodic, hexagonally patterned firing locations that scale up progressively along the dorsal-ventral axis of medial entorhinal cortex. This topographic expansion corresponds with parallel changes in cellular properties dependent on the hyperpolarization-activated cation current (Ih), which is conducted by hyperpolarization-activated cyclic nucleotide-gated (HCN) channels. To test the hypothesis that grid scale is determined by Ih, we recorded grid cells in mice with forebrain-specific knockout of HCN1. We find that, although the dorsal-ventral gradient of the grid pattern was preserved in HCN1 knockout mice, the size and spacing of the grid fields, as well as the period of the accompanying theta modulation, was expanded at all dorsal-ventral levels. There was no change in theta modulation of simultaneously recorded entorhinal interneurons. These observations raise the possibility that, during self-motion-based navigation, Ih contributes to the gain of the transformation from movement signals to spatial firing fields.},
	number = {5},
	journal = {Cell},
	author = {Giocomo, Lisa M and Hussaini, Syed A and Zheng, Fan and Kandel, Eric R and Moser, May-Britt and Moser, Edvard I},
	month = nov,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {1159--1170},
}

@article{koenig_spatial_2011,
	title = {The spatial periodicity of grid cells is not sustained during reduced theta oscillations},
	volume = {332},
	abstract = {Grid cells in parahippocampal cortices fire at vertices of a periodic triangular grid that spans the entire recording environment. Such precise neural computations in space have been proposed to emerge from equally precise temporal oscillations within cells or within the local neural circuitry. We found that grid-like firing patterns in the entorhinal cortex vanished when theta oscillations were reduced after intraseptal lidocaine infusions in rats. Other spatially modulated cells in the same cortical region and place cells in the hippocampus retained their spatial firing patterns to a larger extent during these periods without well-organized oscillatory neuronal activity. Precisely timed neural activity within single cells or local networks is thus required for periodic spatial firing but not for single place fields.},
	number = {6029},
	journal = {Science},
	author = {Koenig, J and Linder, A N and Leutgeb, J K and Leutgeb, S},
	month = apr,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {592--595},
}

@article{coogan_hierarchical_1993,
	title = {Hierarchical organization of areas in rat visual cortex},
	volume = {13},
	number = {9},
	journal = {J. Neurosci.},
	author = {Coogan, T A and Burkhalter, A},
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {3749--3772},
}

@article{lu_velocity-related_2010,
	title = {The velocity-related firing property of hippocampal place cells is dependent on self-movement},
	volume = {20},
	abstract = {Hippocampal place cells have the interesting property of increasing their firing rate when a freely moving animal increases its running speed through the cell's place field. A previous study from this laboratory showed that this movement-related firing property is disrupted by lesions of the perirhinal cortex (PrhC). It is possible, therefore, that PrhC lesions disrupt speed-modulated sensory information such as optic flow or motor efferent or proprioceptive input that might be available to the hippocampus from the PrhC. To test this hypothesis, rats with single unit recording electrodes implanted in the CA1 region of the hippocampus received different levels of optic flow stimulation in both a freely moving and a passive movement condition. The effects of PrhC lesions were also tested. Although increasing the amount of optic flow information available decreased place field size, it had no discernable effect on the movement-firing rate relationship in the place cells of control animals run in the free-movement condition. In lesioned animals the relationship was disrupted, replicating our previous results. In the passive movement condition many place cells stopped firing. In those cells that did fire, however, the movement-firing rate relationship was no longer evident. These data indicate that the movement-firing rate relationship is not driven by vestibular or optic flow cues, but rather depends on either motor efferent or proprioceptive input, or that it results from some other form of input that may be modulated by self-motion, such as from the vibrissae.},
	number = {5},
	journal = {Hippocampus},
	author = {Lu, Xiaodong and Bilkey, David K},
	month = may,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {573--583},
}

@article{canto_all_2012,
	title = {All layers of medial entorhinal cortex receive presubicular and parasubicular inputs},
	volume = {32},
	abstract = {The medial entorhinal cortex (MEC), presubiculum (PrS), and parasubiculum (PaS) are interconnected components of the hippocampal-parahippocampal spatial-representation system. Principal cells in all layers of MEC show signs of directional tuning, overt in head direction cells present in all layers except for layer II, and covert in grid cells, which are the major spatially modulated cell type in layer II. Directional information likely originates in the head direction-vestibular system and PrS and PaS are thought to provide this information to MEC. Efferents from PaS and PrS show a selective laminar terminal distribution in MEC superficial layers II and III, respectively. We hypothesized that this anatomically determined laminar distribution does not preclude monosynaptic interaction with neurons located in deeper layers of MEC in view of the extensive apical dendrites from deeper cells reaching layers II and III. This hypothesis was tested in the rat using tilted in vitro slices in which origins and terminations of PrS and PaS fibers were maintained, as assessed using anterograde anatomical tracing. Based on voltage-sensitive dye imaging, multipatch single-cell recordings, and scanning photostimulation of caged glutamate, we report first that principal neurons in all layers of MEC receive convergent monosynaptic inputs from PrS and PaS and second, that elicited responses show layer-specific decay times and frequency-dependent facilitation. These results indicate that regardless of their selective laminar terminal distribution, PrS and PaS inputs may monosynaptically convey directional information to principal neurons in all layers of MEC through synapses on their extensive dendritic arbors.},
	number = {49},
	journal = {J. Neurosci.},
	author = {Canto, Cathrin B and Koganezawa, Noriko and Beed, Prateep and Moser, Edvard I and Witter, Menno P},
	month = dec,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {17620--17631},
}

@article{burwell_cortical_1998,
	title = {Cortical afferents of the perirhinal, postrhinal, and entorhinal cortices of the rat},
	volume = {398},
	journal = {J. Comp. Neurol.},
	author = {Burwell, R D and Amaral, D G},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {179--205},
}

@article{hinton_wake-sleep_1995,
	title = {The “wake-sleep“ algorithm for unsupervised neural networks},
	volume = {268},
	journal = {Science},
	author = {Hinton, G E and Dayan, P and Frey, B J and Neal, R M},
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {1158--1161},
}

@article{martin_development_2002,
	title = {Development of spatial firing in the hippocampus of young rats},
	volume = {12},
	abstract = {The hippocampal formation participates in learning and memory, particularly that of a spatial nature. In adult rats, individual CA1 pyramidal neurons only fire when the animal visits specific locations in an environment, the “place field” of the neuron. Other structures (postsubiculum, thalamus, cingulum) contain neurons that code for the animal's instantaneous head direction. Previous work has shown that the rat hippocampal formation undergoes anatomical and neurophysiological maturation during the first 2 months of life and that rats {\textless}40 days of age are impaired in spatial navigation tasks. Here we show that the locational firing of CA1 pyramidal neurons is both less specific and less stable in animals aged {\textless}50 days. However, preliminary results indicate that head directional firing recorded around day 30 is essentially identical to that seen in adult animals. Therefore, the development of reliable, spatially specific place cell activity parallels the developmental time course of spatial navigational ability, but head directional firing appears before full maturation of the hippocampus.},
	number = {4},
	journal = {Hippocampus},
	author = {Martin, Patrick D and Berthoz, Alain},
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {465--480},
}

@article{tomlinson_hamsters_1991,
	title = {Hamsters remember spatial information derived from olfactory cues},
	volume = {19},
	journal = {Anim. Learn. Behav.},
	author = {Tomlinson, W T and Johnston, T D},
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {185--190},
}

@article{levenex_integration_1996,
	title = {Integration of olfactory information in a spatial representation enabling accurate arm choice in the radial arm maze},
	volume = {2},
	journal = {Learn. Mem.},
	author = {Levenex, P and Schenk, F},
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {299--319},
}

@article{lavenex_olfactory_1997,
	title = {Olfactory cues potentiate learning of distant visuospatial information},
	volume = {68},
	journal = {Neurobiol. Learn. Mem.},
	author = {Lavenex, P and Schenk, F},
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {140--153},
}

@article{schenk_influence_1995,
	title = {Influence of local environmental olfactory cues on place learning in rats},
	volume = {58},
	number = {6},
	journal = {Physiol. Behav.},
	author = {Schenk, F and Lavenex, P},
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {1059--1066},
}

@article{franz_learning_1998,
	title = {Learning view graphs for robot navigation},
	volume = {5},
	journal = {Auton. Robots},
	author = {Franz, M O and Scholkopf, B and Mallot, H A and Bulthoff, H H},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {111--125},
}

@article{andalman_control_2011,
	title = {Control of vocal and respiratory patterns in birdsong: dissection of forebrain and brainstem mechanisms using temperature},
	volume = {6},
	abstract = {Learned motor behaviors require descending forebrain control to be coordinated with midbrain and brainstem motor systems. In songbirds, such as the zebra finch, regular breathing is controlled by brainstem centers, but when the adult songbird begins to sing, its breathing becomes tightly coordinated with forebrain-controlled vocalizations. The periods of silence (gaps) between song syllables are typically filled with brief breaths, allowing the bird to sing uninterrupted for many seconds. While substantial progress has been made in identifying the brain areas and pathways involved in vocal and respiratory control, it is not understood how respiratory and vocal control is coordinated by forebrain motor circuits. Here we combine a recently developed technique for localized brain cooling, together with recordings of thoracic air sac pressure, to examine the role of cortical premotor nucleus HVC (proper name) in respiratory-vocal coordination. We found that HVC cooling, in addition to slowing all song timescales as previously reported, also increased the duration of expiratory pulses (EPs) and inspiratory pulses (IPs). Expiratory pulses, like song syllables, were stretched uniformly by HVC cooling, but most inspiratory pulses exhibited non-uniform stretch of pressure waveform such that the majority of stretch occurred late in the IP. Indeed, some IPs appeared to change duration by the earlier or later truncation of an underlying inspiratory event. These findings are consistent with the idea that during singing the temporal structure of EPs is under the direct control of forebrain circuits, whereas that of IPs can be strongly influenced by circuits downstream of HVC, likely in the brainstem. An analysis of the temporal jitter of respiratory and vocal structure suggests that IPs may be initiated by HVC at the end of each syllable and terminated by HVC immediately before the onset of the next syllable.},
	number = {9},
	journal = {PLoS One},
	author = {Andalman, Aaron S and Foerster, Jakob N and Fee, Michale S},
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {e25461},
}

@article{krupic_neural_2012,
	title = {Neural representations of location composed of spatially periodic bands},
	volume = {337},
	abstract = {The mammalian hippocampal formation provides neuronal representations of environmental location, but the underlying mechanisms are poorly understood. Here, we report a class of cells whose spatially periodic firing patterns are composed of plane waves (or bands) drawn from a discrete set of orientations and wavelengths. The majority of cells recorded in parasubicular and medial entorhinal cortices of freely moving rats belonged to this class and included grid cells, an important subset that corresponds to three bands at 60 {\textasciicircum}{\textbackslash}circ orientations and has the most stable firing pattern. Occasional changes between hexagonal and nonhexagonal patterns imply a common underlying mechanism. Our results indicate a Fourier-like spatial analysis underlying neuronal representations of location, and suggest that path integration is performed by integrating displacement along a restricted set of directions.},
	number = {6096},
	journal = {Science},
	author = {Krupic, Julija and Burgess, Neil and O'Keefe, John},
	month = aug,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {853--857},
}

@article{brandon_reduction_2011,
	title = {Reduction of theta rhythm dissociates grid cell spatial periodicity from directional tuning},
	volume = {332},
	abstract = {Grid cells recorded in the medial entorhinal cortex of freely moving rats exhibit firing at regular spatial locations and temporal modulation with theta rhythm oscillations (4 to 11 hertz). We analyzed grid cell spatial coding during reduction of network theta rhythm oscillations caused by medial septum (MS) inactivation with muscimol. During MS inactivation, grid cells lost their spatial periodicity, whereas head-direction cells maintained their selectivity. Conjunctive grid-by-head-direction cells lost grid cell spatial periodicity but retained head-direction specificity. All cells showed reduced rhythmicity in autocorrelations and cross-correlations. This supports the hypothesis that spatial coding by grid cells requires theta oscillations, and dissociates the mechanisms underlying the generation of entorhinal grid cell periodicity and head-direction selectivity.},
	number = {6029},
	journal = {Science},
	author = {Brandon, M and Bogaard, A and Libby, C and Connerney, M and Gupta, K and Hasselmo, M},
	month = apr,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {595--599},
}

@article{hasselmo_dynamics_1995,
	title = {Dynamics of learning and recall at excitatory recurrent synapses and cholinergic modulation in rat hippocampal region {CA3}},
	volume = {15},
	journal = {J. Neurosci.},
	author = {Hasselmo, M E and Schnell, E and Barkai, E},
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {5249--5262},
}

@article{hasselmo_cholinergic_1992,
	title = {Cholinergic suppression specific to intrinsic not afferent fiber synapses in rat piriform (olfactory) cortex},
	volume = {67},
	number = {5},
	journal = {J. Neurophysiol.},
	author = {Hasselmo, M E and Bower, J M},
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {1222--1229},
}

@article{grossberg_how_2012,
	title = {How entorhinal grid cells may learn multiple spatial scales from a dorsoventral gradient of cell response rates in a self-organizing map},
	volume = {8},
	abstract = {Place cells in the hippocampus of higher mammals are critical for spatial navigation. Recent modeling clarifies how this may be achieved by how grid cells in the medial entorhinal cortex (MEC) input to place cells. Grid cells exhibit hexagonal grid firing patterns across space in multiple spatial scales along the MEC dorsoventral axis. Signals from grid cells of multiple scales combine adaptively to activate place cells that represent much larger spaces than grid cells. But how do grid cells learn to fire at multiple positions that form a hexagonal grid, and with spatial scales that increase along the dorsoventral axis? In vitro recordings of medial entorhinal layer II stellate cells have revealed subthreshold membrane potential oscillations (MPOs) whose temporal periods, and time constants of excitatory postsynaptic potentials (EPSPs), both increase along this axis. Slower (faster) subthreshold MPOs and slower (faster) EPSPs correlate with larger (smaller) grid spacings and field widths. A self-organizing map neural model explains how the anatomical gradient of grid spatial scales can be learned by cells that respond more slowly along the gradient to their inputs from stripe cells of multiple scales, which perform linear velocity path integration. The model cells also exhibit MPO frequencies that covary with their response rates. The gradient in intrinsic rhythmicity is thus not compelling evidence for oscillatory interference as a mechanism of grid cell firing. A response rate gradient combined with input stripe cells that have normalized receptive fields can reproduce all known spatial and temporal properties of grid cells along the MEC dorsoventral axis. This spatial gradient mechanism is homologous to a gradient mechanism for temporal learning in the lateral entorhinal cortex and its hippocampal projections. Spatial and temporal representations may hereby arise from homologous mechanisms, thereby embodying a mechanistic “neural relativity” that may clarify how episodic memories are learned.},
	number = {10},
	journal = {PLoS Comput. Biol.},
	author = {Grossberg, Stephen and Pilly, Praveen K},
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {e1002648},
}

@article{killian_map_2012,
	title = {A map of visual space in the primate entorhinal cortex},
	volume = {491},
	abstract = {Place-modulated activity among neurons in the hippocampal formation presents a means to organize contextual information in the service of memory formation and recall. One particular spatial representation, that of grid cells, has been observed in the entorhinal cortex (EC) of rats and bats, but has yet to be described in single units in primates. Here we examined spatial representations in the EC of head-fixed monkeys performing a free-viewing visual memory task. Individual neurons were identified in the primate EC that emitted action potentials when the monkey fixated multiple discrete locations in the visual field in each of many sequentially presented complex images. These firing fields possessed spatial periodicity similar to a triangular tiling with a corresponding well-defined hexagonal structure in the spatial autocorrelation. Further, these neurons showed theta-band oscillatory activity and changing spatial scale as a function of distance from the rhinal sulcus, which is consistent with previous findings in rodents. These spatial representations may provide a framework to anchor the encoding of stimulus content in a complex visual scene. Together, our results provide a direct demonstration of grid cells in the primate and suggest that EC neurons encode space during visual exploration, even without locomotion.},
	number = {7426},
	journal = {Nature},
	author = {Killian, Nathaniel J and Jutras, Michael J and Buffalo, Elizabeth A},
	month = nov,
	year = {2012},
	keywords = {merged\_fiete.bib, abstract cognitive grid cells non-spatial hippocampus},
	pages = {761--764},
}

@article{zhang_representation_1996,
	title = {Representation of spatial orientation by the intrinsic dynamics of the head-direction cell ensemble: a theory},
	volume = {15},
	journal = {J. Neurosci.},
	author = {Zhang, K},
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {2112--2126},
}

@article{schmidt-hieber_cellular_2013,
	title = {Cellular mechanisms of spatial navigation in the medial entorhinal cortex},
	volume = {16},
	number = {3},
	journal = {Nat. Neurosci.},
	author = {Schmidt-Hieber, C and Hausser, M},
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {325--331},
}

@article{blair_scale-invariant_2007,
	title = {Scale-invariant memory representations emerge from moiré interference between grid fields that produce theta oscillations: a computational model},
	volume = {27},
	abstract = {The dorsomedial entorhinal cortex (dMEC) of the rat brain contains a remarkable population of spatially tuned neurons called grid cells (Hafting et al., 2005). Each grid cell fires selectively at multiple spatial locations, which are geometrically arranged to form a hexagonal lattice that tiles the surface of the rat's environment. Here, we show that grid fields can combine with one another to form moiré interference patterns, referred to as “moiré grids,” that replicate the hexagonal lattice over an infinite range of spatial scales. We propose that dMEC grids are actually moiré grids formed by interference between much smaller “theta grids,” which are hypothesized to be the primary source of movement-related theta rhythm in the rat brain. The formation of moiré grids from theta grids obeys two scaling laws, referred to as the length and rotational scaling rules. The length scaling rule appears to account for firing properties of grid cells in layer II of dMEC, whereas the rotational scaling rule can better explain properties of layer III grid cells. Moiré grids built from theta grids can be combined to form yet larger grids and can also be used as basis functions to construct memory representations of spatial locations (place cells) or visual images. Memory representations built from moiré grids are automatically endowed with size invariance by the scaling properties of the moiré grids. We therefore propose that moiré interference between grid fields may constitute an important principle of neural computation underlying the construction of scale-invariant memory representations.},
	number = {12},
	journal = {J. Neurosci.},
	author = {Blair, Hugh T and Welday, Adam C and Zhang, Kechen},
	month = mar,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {3211--3229},
}

@article{domnisoru_membrane_2013,
	title = {Membrane potential dynamics of grid cells},
	volume = {495},
	number = {7440},
	journal = {Nature},
	author = {Domnisoru, C and Kinkhabwala, A A and Tank, D A},
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {199--204},
}

@article{yoon_specific_2013,
	title = {Specific evidence of low-dimensional continuous attractor dynamics in grid cells},
	volume = {16},
	abstract = {We examined simultaneously recorded spikes from multiple rat grid cells, to explain mechanisms underlying their activity. Among grid cells with similar spatial periods, the population activity was confined to lie close to a two-dimensional (2D) manifold: grid cells differed only along two dimensions of their responses and otherwise were nearly identical. Relationships between cell pairs were conserved despite extensive deformations of single-neuron responses. Results from novel environments suggest such structure is not inherited from hippocampal or external sensory inputs. Across conditions, cell-cell relationships are better conserved than responses of single cells. Finally, the system is continually subject to perturbations that, were the 2D manifold not attractive, would drive the system to inhabit a different region of state space than observed. These findings have strong implications for theories of grid-cell activity and substantiate the general hypothesis that the brain computes using low-dimensional continuous attractors.},
	number = {8},
	journal = {Nat. Neurosci.},
	author = {Yoon, K J and Buice, M A and Barry, C.and Hayman, R and Burgess, N and Fiete, I R},
	month = aug,
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {1077--1084},
}

@article{yartsev_grid_2011,
	title = {Grid cells without theta oscillations in the entorhinal cortex of bats},
	volume = {479},
	abstract = {Grid cells provide a neural representation of space, by discharging when an animal traverses through the vertices of a periodic hexagonal grid spanning the environment. Although grid cells have been characterized in detail in rats, the fundamental question of what neural dynamics give rise to the grid structure remains unresolved. Two competing classes of models were proposed: network models, based on attractor dynamics, and oscillatory interference models, which propose that interference between somatic and dendritic theta-band oscillations (4-10 Hz) in single neurons transforms a temporal oscillation into a spatially periodic grid. So far, these models could not be dissociated experimentally, because rodent grid cells always co-exist with continuous theta oscillations. Here we used a novel animal model, the Egyptian fruit bat, to refute the proposed causal link between grids and theta oscillations. On the basis of our previous finding from bat hippocampus, of spatially tuned place cells in the absence of continuous theta oscillations, we hypothesized that grid cells in bat medial entorhinal cortex might also exist without theta oscillations. Indeed, we found grid cells in bat medial entorhinal cortex that shared remarkable similarities to rodent grid cells. Notably, the grids existed in the absence of continuous theta-band oscillations, and with almost no theta modulation of grid-cell spiking–both of which are essential prerequisites of the oscillatory interference models. Our results provide a direct demonstration of grid cells in a non-rodent species. Furthermore, they strongly argue against a major class of computational models of grid cells.},
	number = {7371},
	journal = {Nature},
	author = {Yartsev, M M and Witter, M P and Ulanovsky, N},
	month = nov,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {103--107},
}

@article{doeller_evidence_2010,
	title = {Evidence for grid cells in a human memory network},
	volume = {463},
	abstract = {Grid cells in the entorhinal cortex of freely moving rats provide a strikingly periodic representation of self-location which is indicative of very specific computational mechanisms. However, the existence of grid cells in humans and their distribution throughout the brain are unknown. Here we show that the preferred firing directions of directionally modulated grid cells in rat entorhinal cortex are aligned with the grids, and that the spatial organization of grid-cell firing is more strongly apparent at faster than slower running speeds. Because the grids are also aligned with each other, we predicted a macroscopic signal visible to functional magnetic resonance imaging (fMRI) in humans. We then looked for this signal as participants explored a virtual reality environment, mimicking the rats' foraging task: fMRI activation and adaptation showing a speed-modulated six-fold rotational symmetry in running direction. The signal was found in a network of entorhinal/subicular, posterior and medial parietal, lateral temporal and medial prefrontal areas. The effect was strongest in right entorhinal cortex, and the coherence of the directional signal across entorhinal cortex correlated with spatial memory performance. Our study illustrates the potential power of combining single-unit electrophysiology with fMRI in systems neuroscience. Our results provide evidence for grid-cell-like representations in humans, and implicate a specific type of neural representation in a network of regions which supports spatial cognition and also autobiographical memory.},
	number = {7281},
	journal = {Nature},
	author = {Doeller, Christian F and Barry, Caswell and Burgess, Neil},
	month = feb,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {657--661},
}

@article{garden_tuning_2008,
	title = {Tuning of synaptic integration in the medial entorhinal cortex to the organization of grid cell firing fields},
	volume = {60},
	abstract = {Neurons important for cognitive function are often classified by their morphology and integrative properties. However, it is unclear if within a single class of neuron these properties tune synaptic responses to the salient features of the information that each neuron represents. We demonstrate that for stellate neurons in layer II of the medial entorhinal cortex, the waveform of postsynaptic potentials, the time window for detection of coincident inputs, and responsiveness to gamma frequency inputs follow a dorsal-ventral gradient similar to the topographical organization of grid-like spatial firing fields of neurons in this area. We provide evidence that these differences are due to a membrane conductance gradient mediated by HCN and leak potassium channels. These findings suggest key roles for synaptic integration in computations carried out within the medial entorhinal cortex and imply that tuning of neural information processing by membrane ion channels is important for normal cognitive function.},
	number = {5},
	journal = {Neuron},
	author = {Garden, Derek L F and Dodson, Paul D and O'Donnell, Cian and White, Melanie D and Nolan, Matthew F},
	month = dec,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {875--889},
}

@article{bonnevie_grid_2013,
	title = {Grid cells require excitatory drive from the hippocampus},
	volume = {16},
	abstract = {To determine how hippocampal backprojections influence spatially periodic firing in grid cells, we recorded neural activity in the medial entorhinal cortex (MEC) of rats after temporary inactivation of the hippocampus. We report two major changes in entorhinal grid cells. First, hippocampal inactivation gradually and selectively extinguished the grid pattern. Second, the same grid cells that lost their grid fields acquired substantial tuning to the direction of the rat's head. This transition in firing properties was contingent on a drop in the average firing rate of the grid cells and could be replicated by the removal of an external excitatory drive in an attractor network model in which grid structure emerges by velocity-dependent translation of activity across a network with inhibitory connections. These results point to excitatory drive from the hippocampus, and possibly other regions, as one prerequisite for the formation and translocation of grid patterns in the MEC.},
	journal = {Nat. Neurosci.},
	author = {Bonnevie, T and Dunn, B and Fyhn, M and Hafting, T and Derdikman, D and Kubie, J L and Roudi, Y and Moser, E and Moser, M},
	month = jan,
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {309--317},
}

@article{dhillon_laminar_2000,
	title = {Laminar differences in recurrent excitatory transmission in the rat entorhinal cortex in vitro},
	volume = {99},
	abstract = {Paired intracellular recordings were used to investigate recurrent excitatory transmission in layers II, III and V of the rat entorhinal cortex in vitro. There was a relatively high probability of finding a recurrent connection between pairs of pyramidal neurons in both layer V (around 12\%) and layer III (around 9\%). In complete contrast, we have failed to find any recurrent synaptic connections between principal neurons in layer II, and this may be an important factor in the relative resistance of this layer in generating synchronized epileptiform activity. In general, recurrent excitatory postsynaptic potentials in layers III and V of the entorhinal cortex had similar properties to those recorded in other cortical areas, although the probabilities of connection are among the highest reported. Recurrent excitatory postsynaptic potentials recorded in layer V were smaller with faster rise times than those recorded in layer III. In both layers, the recurrent potentials were mediated by glutamate primarily acting at alpha-amino-3-hydroxy-5-methyl-4-isoxazole receptors, although there appeared to be a slow component mediated by N-methyl-D-aspartate receptors. In layer III, recurrent transmission failed on about 30\% of presynaptic action potentials evoked at 0.2Hz. This failure rate increased markedly with increasing (2, 3Hz) frequency of activation. In layer V the failure rate at low frequency was less (19\%), and although it increased at higher frequencies this effect was less pronounced than in layer III. Finally, in layer III, there was evidence for a relatively high probability of electrical coupling between pyramidal neurons. We have previously suggested that layers IV/V of the entorhinal cortex readily generate synchronized epileptiform discharges, whereas layer II is relatively resistant to seizure generation. The present demonstration that recurrent excitatory connections are widespread in layer V but not layer II could support this proposal. The relatively high degree of recurrent connections and electrical coupling between layer III cells may be a factor in it's susceptibility to neurodegeneration during chronic epileptic conditions.},
	number = {3},
	journal = {Neuroscience},
	author = {Dhillon, A and Jones, R S},
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {413--422},
}

@article{couey_recurrent_2013,
	title = {Recurrent inhibitory circuitry as a mechanism for grid formation},
	volume = {16},
	abstract = {Grid cells in layer II of the medial entorhinal cortex form a principal component of the mammalian neural representation of space. The firing pattern of a single grid cell has been hypothesized to be generated through attractor dynamics in a network with a specific local connectivity including both excitatory and inhibitory connections. However, experimental evidence supporting the presence of such connectivity among grid cells in layer II is limited. Here we report recordings from more than 600 neuron pairs in rat entorhinal slices, demonstrating that stellate cells, the principal cell type in the layer II grid network, are mainly interconnected via inhibitory interneurons. Using a model attractor network, we demonstrate that stable grid firing can emerge from a simple recurrent inhibitory network. Our findings thus suggest that the observed inhibitory microcircuitry between stellate cells is sufficient to generate grid-cell firing patterns in layer II of the medial entorhinal cortex.},
	number = {3},
	journal = {Nat. Neurosci.},
	author = {Couey, J J and Witoelar, A and Zhang, S and Zheng, K and Ye, J and Dunn, B and Czajkowski, R and Moser, M and Moser, E and Roudi, Y and Witter, M},
	month = mar,
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {318--324},
}

@article{pastoll_feedback_2013,
	title = {Feedback {Inhibition} {Enables} {Theta}-{Nested} {Gamma} {Oscillations} and {Grid} {Firing} {Fields}},
	volume = {77},
	journal = {Cell},
	author = {Pastoll, H and Solanka, L and van Rossum, M C W and Nolan, M F},
	year = {2013},
	keywords = {merged\_fiete.bib},
	pages = {141--154},
}

@article{barry_boundary_2006-1,
	title = {The boundary vector cell model of place cell firing and spatial memory},
	volume = {17},
	journal = {Rev. Neurosci.},
	author = {Barry, C and Lever, C and Hayman, R and Hartley, T and Burton, S and O'Keefe, J and Jeffery, K and Burgess, N},
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {71--97},
}

@article{benhamou_model_1995,
	title = {A model of place navigation in mammals},
	volume = {173},
	journal = {J. Theor. Biol.},
	author = {Benhamou, S and Bovet, P and Poucet, B},
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {163--178},
}

@article{burgess_model_1994,
	title = {A model of hippocampal function},
	volume = {7},
	journal = {Neural Netw.},
	author = {Burgess, N and Recce, M and O'Keefe, J},
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {1065--1081},
}

@article{schmajuk_place_1993,
	title = {Place learning and the dynamics of spatial navigation: a neural network approach},
	volume = {1},
	number = {3},
	journal = {Adapt. Behav.},
	author = {Schmajuk, N A and Blair, H T},
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {353--385},
}

@article{mcnaughton_cortical-hippocampal_1989,
	title = {Cortical-hippocampal interactions and cognitive mapping: {A} hypothesis based on reintegration of the parietal and inferotemporal pathways for visual processing},
	volume = {17},
	number = {3},
	journal = {Psychobiology},
	author = {McNaughton, B L and Leonard, B and Chen, L},
	year = {1989},
	keywords = {merged\_fiete.bib},
	pages = {230--235},
}

@article{arleo_spatial_2000,
	title = {Spatial cognition and neuro-mimetic navigation: a model of hippocampal place cell activity},
	volume = {83},
	journal = {Biol. Cybern.},
	author = {Arleo, A and Gerstner, W},
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {287--299},
}

@article{stringer_self-organizing_2002,
	title = {Self-organizing continuous attractor networks and path integration: one-dimensional models of head direction cells},
	volume = {13},
	journal = {Network: Comput in Neural Sys},
	author = {Stringer, S M and Trappenberg, T P and Rolls, E T and Araujo, I E T},
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {217--242},
}

@article{wills_abrupt_2012,
	title = {The abrupt development of adult-like grid cell firing in the medial entorhinal cortex},
	volume = {6},
	abstract = {Understanding the development of the neural circuits subserving specific cognitive functions such as navigation remains a central problem in neuroscience. Here, we characterize the development of grid cells in the medial entorhinal cortex, which, by nature of their regularly spaced firing fields, are thought to provide a distance metric to the hippocampal neural representation of space. Grid cells emerge at the time of weaning in the rat, at around 3 weeks of age. We investigated whether grid cells in young rats are functionally equivalent to those observed in the adult as soon as they appear, or if instead they follow a gradual developmental trajectory. We find that, from the very youngest ages at which reproducible grid firing is observed (postnatal day 19): grid cells display adult-like firing fields that tessellate to form a coherent map of the local environment; that this map is universal, maintaining its internal structure across different environments; and that grid cells in young rats, as in adults, also encode a representation of direction and speed. To further investigate the developmental processes leading up to the appearance of grid cells, we present data from individual medial entorhinal cortex cells recorded across more than 1 day, spanning the period before and after the grid firing pattern emerged. We find that increasing spatial stability of firing was correlated with increasing gridness.},
	journal = {Front. Neural Circuits},
	author = {Wills, Thomas J and Barry, Caswell and Cacucci, Francesca},
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {1--13},
}

@article{renart_robust_2003,
	title = {Robust spatial working memory through homeostatic synaptic scaling in heterogeneous cortical networks},
	volume = {38},
	abstract = {The concept of bell-shaped persistent neural activity represents a cornerstone of the theory for the internal representation of analog quantities, such as spatial location or head direction. Previous models, however, relied on the unrealistic assumption of network homogeneity. We investigate this issue in a network model where fine tuning of parameters is destroyed by heterogeneities in cellular and synaptic properties. Heterogeneities result in the loss of stored spatial information in a few seconds. Accurate encoding is recovered when a homeostatic mechanism scales the excitatory synapses to each cell to compensate for the heterogeneity in cellular excitability and synaptic inputs. Moreover, the more realistic model produces a wide diversity of tuning curves, as commonly observed in recordings from prefrontal neurons. We conclude that recurrent attractor networks in conjunction with appropriate homeostatic mechanisms provide a robust, biologically plausible theoretical framework for understanding the neural circuit basis of spatial working memory.},
	number = {3},
	journal = {Neuron},
	author = {Renart, Alfonso and Song, Pengcheng and Wang, Xiao-Jing},
	month = may,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {473--485},
}

@article{wilt_advances_2009,
	title = {Advances in light microscopy for neuroscience},
	volume = {32},
	abstract = {Since the work of Golgi and Cajal, light microscopy has remained a key tool for neuroscientists to observe cellular properties. Ongoing advances have enabled new experimental capabilities using light to inspect the nervous system across multiple spatial scales, including ultrastructural scales finer than the optical diffraction limit. Other progress permits functional imaging at faster speeds, at greater depths in brain tissue, and over larger tissue volumes than previously possible. Portable, miniaturized fluorescence microscopes now allow brain imaging in freely behaving mice. Complementary progress on animal preparations has enabled imaging in head-restrained behaving animals, as well as time-lapse microscopy studies in the brains of live subjects. Mouse genetic approaches permit mosaic and inducible fluorescence-labeling strategies, whereas intrinsic contrast mechanisms allow in vivo imaging of animals and humans without use of exogenous markers. This review surveys such advances and highlights emerging capabilities of particular interest to neuroscientists.},
	journal = {Annu. Rev. Neurosci.},
	author = {Wilt, Brian A and Burns, Laurie D and Wei Ho, Eric Tatt and Ghosh, Kunal K and Mukamel, Eran A and Schnitzer, Mark J},
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {435--506},
}

@article{greenberg_population_2008,
	title = {Population imaging of ongoing neuronal activity in the visual cortex of awake rats},
	volume = {11},
	abstract = {It is unclear how the complex spatiotemporal organization of ongoing cortical neuronal activity recorded in anesthetized animals relates to the awake animal. We therefore used two-photon population calcium imaging in awake and subsequently anesthetized rats to follow action potential firing in populations of neurons across brain states, and examined how single neurons contributed to population activity. Firing rates and spike bursting in awake rats were higher, and pair-wise correlations were lower, compared with anesthetized rats. Anesthesia modulated population-wide synchronization and the relationship between firing rate and correlation. Overall, brain activity during wakefulness cannot be inferred using anesthesia.},
	number = {7},
	journal = {Nat. Neurosci.},
	author = {Greenberg, David S and Houweling, Arthur R and Kerr, Jason N D},
	month = jul,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {749--751},
}

@article{compte_synaptic_2000,
	title = {Synaptic mechanisms and network dynamics underlying spatial working memory in a cortical network model},
	volume = {10},
	journal = {Cereb. Cortex},
	author = {Compte, Albert and Brunel, Nicolas and Goldman-Rakic, Patricia S and Wang, Xiao-Jing},
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {910--923},
}

@article{kerr_functional_2007,
	title = {Functional neuroanatomy of the parahippocampal region: the lateral and medial entorhinal areas},
	volume = {17},
	abstract = {The entorhinal cortex (EC) serves a pivotal role in corticohippocampal interactions, but a complete description of its extrinsic connections has not been presented. Here, we have summarized the cortical, subcortical, and hippocampal connections of the lateral entorhinal area (LEA) and the medial entorhinal area (MEA) in the rat. We found that the targets and relative strengths of the entorhinal connections are strikingly different for the LEA and MEA. For example, the LEA receives considerably heavier input from the piriform and insular cortices, whereas the MEA is more heavily targeted by the visual, posterior parietal, and retrosplenial cortices. Regarding subcortical connections, the LEA receives heavy input from the amygdala and olfactory structures, whereas the MEA is targeted by the dorsal thalamus, primarily the midline nuclei and also the dorsolateral and dorsoanterior thalamic nuclei. Differences in the LEA and MEA connections with hippocampal and parahippocampal structures are also described. In addition, because the EC is characterized by bands of intrinsic connectivity that span the LEA and MEA and project to different septotemporal levels of the dentate gyrus, special attention was paid to the efferents and afferents of those bands. Finally, we summarized the connections of the dorsocaudal MEA, the region in which the entorhinal “grid cells” were discovered. The subregional differences in entorhinal connectivity described here provide further evidence for functional diversity within the EC. It is hoped that these findings will inform future studies of the role of the EC in learning and memory.},
	number = {9},
	journal = {Hippocampus},
	author = {Kerr, Kristin M and Agster, Kara L and Furtak, Sharon C and Burwell, Rebecca D},
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {697--708},
}

@article{ohki_functional_2005,
	title = {Functional imaging with cellular resolution reveals precise micro- {Functional} imaging with cellular resolution reveals precise micro-architecture in visual cortex},
	volume = {433},
	journal = {Nature},
	author = {Ohki, Kenichi and Chung, Sooyoung and Ch'ng, Yeang H and Kara, Prakash and Reid, R Clay},
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {597--603},
}

@article{van_haeften_morphological_2003,
	title = {Morphological and numerical analysis of synaptic interactions between neurons in deep and superficial layers of the entorhinal cortex of the rat},
	volume = {13},
	abstract = {Neurons providing connections between the deep and superficial layers of the entorhinal cortex (EC) constitute a pivotal link in the network underlying reverberation and gating of neuronal activity in the entorhinal-hippocampal system. To learn more of these deep-to-superficial neurons and their targets, we applied the tracer Neurobiotin pericellularly in layer V of the medial EC of 12 rats. Labeled axons in the superficial layers were studied with light and electron microscopy, and their synaptic organization recorded. Neurobiotin-labeled layer V neurons displayed “Golgi-like” staining. Two major cell types were distinguished among these neurons: (1) pyramidal neurons with apical spiny dendrites traversing all layers and ramifying in layer I, and (2) horizontal neurons with dendrites confined to the deep layers. Labeled axons ramified profusely in layer III, superficially in layer II and deep in layer I. Analysis of labeled axon terminals in layers I-II and III showed that most synapses (95\%) were asymmetrical. Of these synapses, 56\% occurred with spines (presumably belonging to principal neurons) and 44\% with dendritic shafts (presumably interneurons). A small fraction of the synapses (5\%) was of the symmetrical type. Such synapses were mainly seen on dendritic shafts. We found in two sections a symmetrical synapse on a spine. These findings suggest that the deep to superficial projection is mainly excitatory in nature, and that these fibers subserve both excitation and feed-forward inhibition. There is an additional, much weaker, inhibitory component in this projection, which may have a disinhibitory effect on the entorhinal network in the superficial layers.},
	number = {8},
	journal = {Hippocampus},
	author = {van Haeften, Theo and Baks-te-Bulte, Luciënne and Goede, Peter H and Wouterlood, Floris G and Witter, Menno P},
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {943--952},
}

@article{kleinfeld_large-scale_2011,
	title = {Large-scale automated histology in the pursuit of connectomes},
	volume = {31},
	abstract = {How does the brain compute? Answering this question necessitates neuronal connectomes, annotated graphs of all synaptic connections within defined brain areas. Further, understanding the energetics of the brain's computations requires vascular graphs. The assembly of a connectome requires sensitive hardware tools to measure neuronal and neurovascular features in all three dimensions, as well as software and machine learning for data analysis and visualization. We present the state of the art on the reconstruction of circuits and vasculature that link brain anatomy and function. Analysis at the scale of tens of nanometers yields connections between identified neurons, while analysis at the micrometer scale yields probabilistic rules of connection between neurons and exact vascular connectivity.},
	number = {45},
	journal = {J. Neurosci.},
	author = {Kleinfeld, David and Bharioke, Arjun and Blinder, Pablo and Bock, Davi D and Briggman, Kevin L and Chklovskii, Dmitri B and Denk, Winfried and Helmstaedter, Moritz and Kaufhold, John P and Lee, Wei-Chung Allen and Meyer, Hanno S and Micheva, Kristina D and Oberlaender, Marcel and Prohaska, Steffen and Reid, R Clay and Smith, Stephen J and Takemura, Shinya and Tsai, Philbert S and Sakmann, Bert},
	month = nov,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {16125--16138},
}

@article{welday_cosine_2011,
	title = {Cosine directional tuning of theta cell burst frequencies: evidence for spatial coding by oscillatory interference},
	volume = {31},
	abstract = {The rodent septohippocampal system contains “theta cells,” which burst rhythmically at 4-12 Hz, but the functional significance of this rhythm remains poorly understood (Buzsáki, 2006). Theta rhythm commonly modulates the spike trains of spatially tuned neurons such as place (O'Keefe and Dostrovsky, 1971), head direction (Tsanov et al., 2011a), grid (Hafting et al., 2005), and border cells (Savelli et al., 2008; Solstad et al., 2008). An “oscillatory interference” theory has hypothesized that some of these spatially tuned neurons may derive their positional firing from phase interference among theta oscillations with frequencies that are modulated by the speed and direction of translational movements (Burgess et al., 2005, 2007). This theory is supported by studies reporting modulation of theta frequency by movement speed (Rivas et al., 1996; Geisler et al., 2007; Jeewajee et al., 2008a), but modulation of theta frequency by movement direction has never been observed. Here we recorded theta cells from hippocampus, medial septum, and anterior thalamus of freely behaving rats. Theta cell burst frequencies varied as the cosine of the rat's movement direction, and this directional tuning was influenced by landmark cues, in agreement with predictions of the oscillatory interference theory. Computer simulations and mathematical analysis demonstrated how a postsynaptic neuron can detect location-dependent synchrony among inputs from such theta cells, and thereby mimic the spatial tuning properties of place, grid, or border cells. These results suggest that theta cells may serve a high-level computational function by encoding a basis set of oscillatory signals that interfere with one another to synthesize spatial memory representations.},
	number = {45},
	journal = {J. Neurosci.},
	author = {Welday, Adam C and Shlifer, I Gary and Bloom, Matthew L and Zhang, Kechen and Blair, Hugh T},
	month = nov,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {16157--16176},
}

@article{brandon_head_2012,
	title = {Head direction cells in the postsubiculum do not show replay of prior waking sequences during sleep},
	volume = {22},
	abstract = {During slow-wave sleep (SWS) and rapid eye movement (REM) sleep, hippocampal place cells in the rat show replay of sequences previously observed during waking. We tested the hypothesis from computational modeling that the temporal structure of REM sleep replay could arise from an interplay of place cells with head direction cells in the postsubiculum. Physiological single-unit recording was performed simultaneously from five or more head direction or place by head direction cells in the postsubiculum during running on a circular track allowing sampling of a full range of head directions, and during sleep periods before and after running on the circular track. Data analysis compared the spiking activity during individual REM periods with waking as in previous analysis procedures for REM sleep. We also used a new procedure comparing groups of similar runs during waking with REM sleep periods. There was no consistent evidence for a statistically significant correlation of the temporal structure of spiking during REM sleep with spiking during waking running periods. Thus, the spiking activity of head direction cells during REM sleep does not show replay of head direction cell activity occurring during a previous waking period of running on the task. In addition, we compared the spiking of postsubiculum neurons during hippocampal sharp wave ripple events. We show that head direction cells are not activated during sharp wave ripples, whereas neurons responsive to place in the postsubiculum show reliable spiking at ripple events.},
	number = {3},
	journal = {Hippocampus},
	author = {Brandon, Mark P and Bogaard, Andrew R and Andrews, Chris M and Hasselmo, Michael E},
	month = mar,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {604--618},
}

@article{agster_cortical_2009,
	title = {Cortical efferents of the perirhinal, postrhinal, and entorhinal cortices of the rat},
	volume = {19},
	abstract = {We investigated the cortical efferents of the parahippocampal region by placing injections of the anterograde tracers, Phaseolus vulgaris-leuccoagglutinin, and biotinylated dextran amine, throughout the perirhinal (PER), postrhinal (POR), and entorhinal cortices of the rat brain. The resulting density of labeled fibers was evaluated in 25 subregions of the piriform, frontal, insular, temporal, cingulate, parietal, and occipital areas. The locations of labeled terminal fibers differed substantially depending on whether the location of the injection site was in PER area 35, PER area 36, POR, or the lateral or the medial entorhinal (LEA and MEA). The differences were greater for sensory regions. For example, the POR efferents preferentially target visual and spatial regions, whereas the PER efferents target all sensory modalities. The cortical efferents of each region largely reciprocate the cortical afferents, though the degree of reciprocity varied across originating and target regions. The laminar pattern of terminal fibers was consistent with the notion that the efferents are feedback projections. The density and amount of labeled fibers also differed substantially depending on the regional location of injection sites. PER area 36 and POR give rise to a greater number of heavy projections, followed by PER area 35. LEA also gives rise to widespread cortical efferents, arising mainly from a narrow band of cortex adjacent to the PER. In contrast, the remainder of the LEA and the MEA provides only weak efferents to cortical regions. Prior work has shown that nonspatial and spatial information is transmitted to the hippocampus via the PER-LEA and POR-MEA pathways, respectively. Our findings suggest that the return projections follow the same pathways, though perhaps with less segregration.},
	number = {12},
	journal = {Hippocampus},
	author = {Agster, Kara L and Burwell, Rebecca D},
	month = dec,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {1159--1186},
}

@article{taube_head_2007,
	title = {The head direction signal: origins and sensory-motor integration},
	volume = {30},
	abstract = {Navigation first requires accurate perception of one's spatial orientation within the environment, which consists of knowledge about location and directional heading. Cells within several limbic system areas of the mammalian brain discharge allocentrically as a function of the animal's directional heading, independent of the animal's location and ongoing behavior. These cells are referred to as head direction (HD) cells and are believed to encode the animal's perceived directional heading with respect to its environment. Although HD cells are found in several areas, the principal circuit for generating this signal originates in the dorsal tegmental nucleus and projects serially, with some reciprocal connections, to the lateral mammillary nucleus –{\textgreater} anterodorsal thalamus –{\textgreater} PoS, and terminates in the entorhinal cortex. HD cells receive multimodal information about landmarks and self-generated movements. Vestibular information appears critical for generating the directional signal, but motor/proprioceptive and landmark information are important for updating it.},
	journal = {Annu. Rev. Neurosci.},
	author = {Taube, Jeffrey S},
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {181--207},
}

@article{burwell_positional_2003,
	title = {Positional firing properties of postrhinal cortex neurons},
	volume = {119},
	abstract = {Hippocampal cell firing in awake, behaving rats is often spatially selective, and such cells have been called place cells. Similar spatial correlates have also been described for neurons in the medial entorhinal and perirhinal cortices. All three regions receive sensory associational input from postrhinal cortex, which, in turn, is heavily interconnected with visuospatial neocortical regions. The spatial selectivity of postrhinal cells, however, has never been examined. Here, we report the activity of neurons in postrhinal cortex of freely moving rats performing a spatial task on a four-arm radial maze. Data are also reported for visual association cortex neurons. The four-arm radial maze was defined by multisensory cues on the surfaces of the maze arms (proximal) and complex visual cues at the surround (distal). On each recording day, rats were run in three conditions: baseline, double cue rotation (proximal +90 degrees; distal -90 degrees ), and baseline. In this task, hippocampal place field activity is robust and can be controlled by proximal or distal cues. The majority of postrhinal neurons (64\%) exhibited positional correlates during performance on the task; however, characteristics of these postrhinal cells were substantially different from those previously described for hippocampal place cells. Most postrhinal cells with firing fields exhibited split or multiple subfields (93\%). Unlike hippocampal place fields, the large majority of postrhinal firing fields (84\%) adopted new spatial correlates when experimental cues were rotated, but did so neither predictably nor concordantly. This is the first report of positional firing correlates in the postrhinal cortex. The data are consistent with the idea that postrhinal cortex participates in visuospatial functions by monitoring changes in environmental stimuli rather than encoding stable spatial cues. Thus, postrhinal neurons appear to participate in higher-level perceptual functions rather than mnemonic functions. We propose that the response properties of postrhinal neurons represent an early step in a spatial pathway that culminates in the specific and stable place fields of the hippocampus.},
	number = {2},
	journal = {Neuroscience},
	author = {Burwell, R D and Hafeman, D M},
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {577--588},
}

@article{chklovskii_wire_2000,
	title = {A wire length minimization approach to ocular dominance patterns in mammalian visual cortex},
	volume = {284},
	journal = {Physica A},
	author = {Chklovskii, Dmitri B and Koulakov, Alexei A},
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {318--334},
}

@article{fabian_kloosterman_electrophysiological_2003,
	title = {Electrophysiological characterization of interlaminar entorhinal connections: an essential link for re-entrance in the hippocampal{\textbackslash}pmentorhinal system},
	volume = {18},
	journal = {Eur. J. Neurosci.},
	author = {Fabian Kloosterman, Theo van Haeften, Menno P Witter and da Silva, Fernando H Lopes},
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {3037--3052},
}

@article{jain_machines_2010,
	title = {Machines that learn to segment images: a crucial technology for connectomics},
	volume = {20},
	abstract = {Connections between neurons can be found by checking whether synapses exist at points of contact, which in turn are determined by neural shapes. Finding these shapes is a special case of image segmentation, which is laborious for humans and would ideally be performed by computers. New metrics properly quantify the performance of a computer algorithm using its disagreement with 'true' segmentations of example images. New machine learning methods search for segmentation algorithms that minimize such metrics. These advances have reduced computer errors dramatically. It should now be faster for a human to correct the remaining errors than to segment an image manually. Further reductions in human effort are expected, and crucial for finding connectomes more complex than that of Caenorhabditis elegans.},
	number = {5},
	journal = {Curr. Opin. Neurobiol.},
	author = {Jain, Viren and Seung, H Sebastian and Turaga, Srinivas C},
	month = oct,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {653--666},
}

@article{milford_solving_2010,
	title = {Solving navigational uncertainty using grid cells on robots},
	volume = {6},
	abstract = {To successfully navigate their habitats, many mammals use a combination of two mechanisms, path integration and calibration using landmarks, which together enable them to estimate their location and orientation, or pose. In large natural environments, both these mechanisms are characterized by uncertainty: the path integration process is subject to the accumulation of error, while landmark calibration is limited by perceptual ambiguity. It remains unclear how animals form coherent spatial representations in the presence of such uncertainty. Navigation research using robots has determined that uncertainty can be effectively addressed by maintaining multiple probabilistic estimates of a robot's pose. Here we show how conjunctive grid cells in dorsocaudal medial entorhinal cortex (dMEC) may maintain multiple estimates of pose using a brain-based robot navigation system known as RatSLAM. Based both on rodent spatially-responsive cells and functional engineering principles, the cells at the core of the RatSLAM computational model have similar characteristics to rodent grid cells, which we demonstrate by replicating the seminal Moser experiments. We apply the RatSLAM model to a new experimental paradigm designed to examine the responses of a robot or animal in the presence of perceptual ambiguity. Our computational approach enables us to observe short-term population coding of multiple location hypotheses, a phenomenon which would not be easily observable in rodent recordings. We present behavioral and neural evidence demonstrating that the conjunctive grid cells maintain and propagate multiple estimates of pose, enabling the correct pose estimate to be resolved over time even without uniquely identifying cues. While recent research has focused on the grid-like firing characteristics, accuracy and representational capacity of grid cells, our results identify a possible critical and unique role for conjunctive grid cells in filtering sensory uncertainty. We anticipate our study to be a starting point for animal experiments that test navigation in perceptually ambiguous environments.},
	number = {11},
	journal = {PLoS Comput. Biol.},
	author = {Milford, Michael J and Wiles, Janet and Wyeth, Gordon F},
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {1--14},
}

@article{kirkpatrick_optimization_1983,
	title = {Optimization by {Simulated} {Annealing}},
	volume = {220},
	number = {4598},
	journal = {Science},
	author = {Kirkpatrick, S and C. D. Gelatt, Jr and Vecchi, M P},
	year = {1983},
	keywords = {merged\_fiete.bib},
	pages = {671--680},
}

@article{mishchenko_ultrastructural_2010,
	title = {Ultrastructural analysis of hippocampal neuropil from the connectomics perspective},
	volume = {67},
	abstract = {Complete reconstructions of vertebrate neuronal circuits on the synaptic level require new approaches. Here, serial section transmission electron microscopy was automated to densely reconstruct four volumes, totaling 670 μm(3), from the rat hippocampus as proving grounds to determine when axo-dendritic proximities predict synapses. First, in contrast with Peters' rule, the density of axons within reach of dendritic spines did not predict synaptic density along dendrites because the fraction of axons making synapses was variable. Second, an axo-dendritic touch did not predict a synapse; nevertheless, the density of synapses along a hippocampal dendrite appeared to be a universal fraction, 0.2, of the density of touches. Finally, the largest touch between an axonal bouton and spine indicated the site of actual synapses with about 80\% precision but would miss about half of all synapses. Thus, it will be difficult to predict synaptic connectivity using data sets missing ultrastructural details that distinguish between axo-dendritic touches and bona fide synapses.},
	number = {6},
	journal = {Neuron},
	author = {Mishchenko, Yuriy and Hu, Tao and Spacek, Josef and Mendenhall, John and Harris, Kristen M and Chklovskii, Dmitri B},
	month = sep,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {1009--1020},
}

@article{bock_network_2011,
	title = {Network anatomy and in vivo physiology of visual cortical neurons},
	volume = {471},
	abstract = {In the cerebral cortex, local circuits consist of tens of thousands of neurons, each of which makes thousands of synaptic connections. Perhaps the biggest impediment to understanding these networks is that we have no wiring diagrams of their interconnections. Even if we had a partial or complete wiring diagram, however, understanding the network would also require information about each neuron's function. Here we show that the relationship between structure and function can be studied in the cortex with a combination of in vivo physiology and network anatomy. We used two-photon calcium imaging to characterize a functional property–the preferred stimulus orientation–of a group of neurons in the mouse primary visual cortex. Large-scale electron microscopy of serial thin sections was then used to trace a portion of these neurons' local network. Consistent with a prediction from recent physiological experiments, inhibitory interneurons received convergent anatomical input from nearby excitatory neurons with a broad range of preferred orientations, although weak biases could not be rejected.},
	number = {7337},
	journal = {Nature},
	author = {Bock, Davi D and Lee, Wei-Chung Allen and Kerlin, Aaron M and Andermann, Mark L and Hood, Greg and Wetzel, Arthur W and Yurgenson, Sergey and Soucy, Edward R and Kim, Hyon Suk and Reid, R Clay},
	month = mar,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {177--182},
}

@article{briggman_wiring_2011,
	title = {Wiring specificity in the direction-selectivity circuit of the retina},
	volume = {471},
	abstract = {The proper connectivity between neurons is essential for the implementation of the algorithms used in neural computations, such as the detection of directed motion by the retina. The analysis of neuronal connectivity is possible with electron microscopy, but technological limitations have impeded the acquisition of high-resolution data on a large enough scale. Here we show, using serial block-face electron microscopy and two-photon calcium imaging, that the dendrites of mouse starburst amacrine cells make highly specific synapses with direction-selective ganglion cells depending on the ganglion cell's preferred direction. Our findings indicate that a structural (wiring) asymmetry contributes to the computation of direction selectivity. The nature of this asymmetry supports some models of direction selectivity and rules out others. It also puts constraints on the developmental mechanisms behind the formation of synaptic connections. Our study demonstrates how otherwise intractable neurobiological questions can be addressed by combining functional imaging with the analysis of neuronal connectivity using large-scale electron microscopy.},
	number = {7337},
	journal = {Nature},
	author = {Briggman, Kevin L and Helmstaedter, Moritz and Denk, Winfried},
	month = mar,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {183--188},
}

@article{derdikman_fragmentation_2009,
	title = {Fragmentation of grid cell maps in a multicompartment environment},
	volume = {12},
	abstract = {To determine whether entorhinal spatial representations are continuous or fragmented, we recorded neural activity in grid cells while rats ran through a stack of interconnected, zig-zagged compartments of equal shape and orientation (a hairpin maze). The distribution of spatial firing fields was markedly similar across all compartments in which running occurred in the same direction, implying that the grid representation was fragmented into repeating submaps. Activity at neighboring positions was least correlated at the transitions between different arms, indicating that the map split regularly at the turning points. We saw similar discontinuities among place cells in the hippocampus. No fragmentation was observed when the rats followed similar trajectories in the absence of internal walls, implying that stereotypic behavior alone cannot explain the compartmentalization. These results indicate that spatial environments are represented in entorhinal cortex and hippocampus as a mosaic of discrete submaps that correspond to the geometric structure of the space.},
	number = {10},
	journal = {Nat. Neurosci.},
	author = {Derdikman, Dori and Whitlock, Jonathan R and Tsao, Albert and Fyhn, Marianne and Hafting, Torkel and Moser, May-Britt and Moser, Edvard I},
	month = oct,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {1325--1332},
}

@article{lichtman_big_2011,
	title = {The big and the small: challenges of imaging the brain's circuits},
	volume = {334},
	abstract = {The relation between the structure of the nervous system and its function is more poorly understood than the relation between structure and function in any other organ system. We explore why bridging the structure-function divide is uniquely difficult in the brain. These difficulties also explain the thrust behind the enormous amount of innovation centered on microscopy in neuroscience. We highlight some recent progress and the challenges that remain.},
	number = {6056},
	journal = {Science},
	author = {Lichtman, Jeff W and Denk, Winfried},
	month = nov,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {618--623},
}

@article{s_m_stringer_self-organizing_2002,
	title = {Self-organizing continuous attractor networks and path integration: two-dimensional models of place cells},
	volume = {13},
	journal = {Network: Comput. Neural Syst.},
	author = {S M Stringer, E T Rolls, T P Trappenberg and de Araujo, I E T},
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {429--446},
}

@article{giocomo_computational_2011,
	title = {Computational models of grid cells},
	volume = {71},
	abstract = {Grid cells are space-modulated neurons with periodic firing fields. In moving animals, the multiple firing fields of an individual grid cell form a triangular pattern tiling the entire space available to the animal. Collectively, grid cells are thought to provide a context-independent metric representation of the local environment. Since the discovery of grid cells in 2005, a number of models have been proposed to explain the formation of spatially repetitive firing patterns as well as the conversion of these signals to place signals one synapse downstream in the hippocampus. The present article reviews the most recent developments in our understanding of how grid patterns are generated, maintained, and transformed, with particular emphasis on second-generation computational models that have emerged during the past 2-3 years in response to criticism and new data.},
	number = {4},
	journal = {Neuron},
	author = {Giocomo, Lisa M and Moser, May-Britt and Moser, Edvard I},
	month = aug,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {589--603},
}

@article{deshmukh_representation_2011,
	title = {Representation of non-spatial and spatial information in the lateral entorhinal cortex},
	volume = {5},
	abstract = {Some theories of memory propose that the hippocampus integrates the individual items and events of experience within a contextual or spatial framework. The hippocampus receives cortical input from two major pathways: the medial entorhinal cortex (MEC) and the lateral entorhinal cortex (LEC). During exploration in an open field, the firing fields of MEC grid cells form a periodically repeating, triangular array. In contrast, LEC neurons show little spatial selectivity, and it has been proposed that the LEC may provide non-spatial input to the hippocampus. Here, we recorded MEC and LEC neurons while rats explored an open field that contained discrete objects. LEC cells fired selectively at locations relative to the objects, whereas MEC cells were weakly influenced by the objects. These results provide the first direct demonstration of a double dissociation between LEC and MEC inputs to the hippocampus under conditions of exploration typically used to study hippocampal place cells.},
	journal = {Front. Behav. Neurosci.},
	author = {Deshmukh, Sachin S and Knierim, James J},
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {1--33},
}

@article{lisman_role_2007,
	title = {Role of the dual entorhinal inputs to hippocampus: a hypothesis based on cue/action (non-self/self) couplets},
	volume = {163},
	abstract = {The hippocampus sits at the highest level of memory processing circuits and receives two major inputs, one coming from the lateral entorhinal cortex and one coming from the medial entorhinal cortex. This duality must be of fundamental importance, but its functional meaning remains unclear. A computational model used for robot navigation (Verschure, P.F., et al. (2003). Nature, 425: 620-624) has a dual information structure that may provide insight. In this model, information is stored as couplets consisting of information about the current sensory cues and information about the current action of the robot. Sequences of such couplets are stored in a short-term memory buffer and transferred to a long-term memory store whenever a goal is found. The overall system enhances the ability of the robot to find reward sites because stored sequences enable the robot to retrace the path to a goal site whenever any of the cues along the path to a goal is subsequently encountered. A review of the literature suggests that the idea of cue/action couplets can be usefully mapped onto the function of the entorhinal cortex. Cue information may be supplied by the lateral entorhinal cortex whereas action (motor) information may be supplied by the medial entorhinal cortex. However, given that self-position information is prominent in the medial pathway and that this is not directly related to action, a modified formulation of the duality is proposed in which the fundamental distinction is between information about non-self vs. information about self. According to this view, the lateral entorhinal pathway carries information about external (non-self) cues and their positions (in egocentric coordinates) whereas the medial entorhinal pathway carries information about the organism itself, including its position (in allocentric coordinates), motor actions and goals.},
	journal = {Prog. Brain Res.},
	author = {Lisman, John E},
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {615--625},
}

@article{solstad_representation_2008,
	title = {Representation of {Geometric} {Borders} in the {Entorhinal} {Cortex}},
	volume = {322},
	journal = {Science},
	author = {Solstad, Trygve and Boccara, Charlotte N and Kropff, Emilio and Moser, May-Britt and Moser, Edvard I},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {1865--1868},
}

@article{jeewajee_grid_2008,
	title = {Grid cells and theta as oscillatory interference: electrophysiological data from freely moving rats},
	volume = {18},
	abstract = {The oscillatory interference model (Burgess et al. (2007) Hippocampus 17:801-812) explains the generation of spatially stable, regular firing patterns by medial entorhinal cortical (mEC) grid cells in terms of the interference between velocity-controlled oscillators (VCOs) with different preferred directions. This model predicts specific relationships between the intrinsic firing frequency and spatial scale of grid cell firing, the EEG theta frequency, and running speed (Burgess,2008). Here, we use spectral analyses of EEG and of spike autocorrelograms to estimate the intrinsic firing frequency of grid cells, and the concurrent theta frequency, in mEC Layer II in freely moving rats. The intrinsic firing frequency of grid cells increased with running speed and decreased with grid scale, according to the quantitative prediction of the model. Similarly, theta frequency increased with running speed, which was also predicted by the model. An alternative Moiré interference model (Blair et al.,2007) predicts a direction-dependent variation in intrinsic firing frequency, which was not found. Our results suggest that interference between VCOs generates the spatial firing patterns of entorhinal grid cells according to the oscillatory interference model. They also provide specific constraints on this model of grid cell firing and have more general implications for viewing neuronal processing in terms of interfering oscillatory processes.},
	number = {12},
	journal = {Hippocampus},
	author = {Jeewajee, A and Barry, C and O'Keefe, J and Burgess, N},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {1175--1185},
}

@article{woodin_coincident_2003,
	title = {Coincident pre- and postsynaptic activity modifies {GABAergic} synapses by postsynaptic changes in {Cl}- transporter activity},
	volume = {39},
	abstract = {Coincident pre- and postsynaptic activation is known to induce long-term modification of glutamatergic synapses. We report here that, in both hippocampal cultures and acute hippocampal slices, repetitive postsynaptic spiking within 20 ms before and after the activation of GABAergic synapses also led to a persistent change in synaptic strength. This synaptic modification required Ca2+ influx through postsynaptic L-type Ca2+ channels and was due to a local decrease in K+-Cl- cotransport activity, effectively reducing the strength of inhibition. Thus, GABAergic synapses can detect and be modified by coincident pre- and postsynaptic spiking, allowing the level of inhibition to be modulated in accordance to the temporal pattern of postsynaptic excitation.},
	number = {5},
	journal = {Neuron},
	author = {Woodin, Melanie A and Ganguly, Karunesh and Poo, Mu-Ming},
	month = aug,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {807--820},
}

@article{lisman_thetagamma_2005,
	title = {The theta/gamma discrete phase code occuring during the hippocampal phase precession may be a more general brain coding scheme},
	volume = {15},
	abstract = {In the hippocampus, oscillations in the theta and gamma frequency range occur together and interact in several ways, indicating that they are part of a common functional system. It is argued that these oscillations form a coding scheme that is used in the hippocampus to organize the readout from long-term memory of the discrete sequence of upcoming places, as cued by current position. This readout of place cells has been analyzed in several ways. First, plots of the theta phase of spikes vs. position on a track show a systematic progression of phase as rats run through a place field. This is termed the phase precession. Second, two cells with nearby place fields have a systematic difference in phase, as indicated by a cross-correlation having a peak with a temporal offset that is a significant fraction of a theta cycle. Third, several different decoding algorithms demonstrate the information content of theta phase in predicting the animal's position. It appears that small phase differences corresponding to jitter within a gamma cycle do not carry information. This evidence, together with the finding that principle cells fire preferentially at a given gamma phase, supports the concept of theta/gamma coding: a given place is encoded by the spatial pattern of neurons that fire in a given gamma cycle (the exact timing within a gamma cycle being unimportant); sequential places are encoded in sequential gamma subcycles of the theta cycle (i.e., with different discrete theta phase). It appears that this general form of coding is not restricted to readout of information from long-term memory in the hippocampus because similar patterns of theta/gamma oscillations have been observed in multiple brain regions, including regions involved in working memory and sensory integration. It is suggested that dual oscillations serve a general function: the encoding of multiple units of information (items) in a way that preserves their serial order. The relationship of such coding to that proposed by Singer and von der Malsburg is discussed; in their scheme, theta is not considered. It is argued that what theta provides is the absolute phase reference needed for encoding order. Theta/gamma coding therefore bears some relationship to the concept of “word” in digital computers, with word length corresponding to the number of gamma cycles within a theta cycle, and discrete phase corresponding to the ordered “place” within a word.},
	number = {7},
	journal = {Hippocampus},
	author = {Lisman, John},
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {913--922},
}

@article{senior_gamma_2008,
	title = {Gamma oscillatory firing reveals distinct populations of pyramidal cells in the {CA1} region of the hippocampus},
	volume = {28},
	abstract = {Hippocampal place cells that fire together within the same cycle of theta oscillations represent the sequence of positions (movement trajectory) that a rat traverses on a linear track. Furthermore, it has been suggested that the encoding of these and other types of temporal memory sequences is organized by gamma oscillations nested within theta oscillations. Here, we examined whether gamma-related firing of place cells permits such discrete temporal coding. We found that gamma-modulated CA1 pyramidal cells separated into two classes on the basis of gamma firing phases during waking theta periods. These groups also differed in terms of their spike waveforms, firing rates, and burst firing tendency. During gamma oscillations one group's firing became restricted to theta phases associated with the highest gamma power. Consequently, on the linear track, cells in this group often failed to fire early in theta-phase precession (as the rat entered the place field) if gamma oscillations were present. The second group fired throughout the theta cycle during gamma oscillations, and maintained gamma-modulated firing at different stages of theta-phase precession. Our results suggest that the two different pyramidal cell classes may support different types of population codes within a theta cycle: one in which spike sequences representing movement trajectories occur across subsequent gamma cycles nested within each theta cycle, and another in which firing in synchronized gamma discharges without temporal sequences encode a representation of location. We propose that gamma oscillations during theta-phase precession organize the mnemonic recall of population patterns representing places and movement paths.},
	number = {9},
	journal = {J. Neurosci.},
	author = {Senior, Timothy J and Huxter, John R and Allen, Kevin and O'Neill, Joseph and Csicsvari, Jozsef},
	month = feb,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {2274--2286},
}

@article{zilli_coupled_2010,
	title = {Coupled noisy spiking neurons as velocity-controlled oscillators in a model of grid cell spatial firing},
	volume = {30},
	abstract = {One of the two primary classes of models of grid cell spatial firing uses interference between oscillators at dynamically modulated frequencies. Generally, these models are presented in terms of idealized oscillators (modeled as sinusoids), which differ from biological oscillators in multiple important ways. Here we show that two more realistic, noisy neural models (Izhikevich's simple model and a biophysical model of an entorhinal cortex stellate cell) can be successfully used as oscillators in a model of this type. When additive noise is included in the models such that uncoupled or sparsely coupled cells show realistic interspike interval variance, both synaptic and gap-junction coupling can synchronize networks of cells to produce comparatively less variable network-level oscillations. We show that the frequency of these oscillatory networks can be controlled sufficiently well to produce stable grid cell spatial firing on the order of at least 2-5 min, despite the high noise level. Our results suggest that the basic principles of oscillatory interference models work with more realistic models of noisy neurons. Nevertheless, a number of simplifications were still made and future work should examine increasingly realistic models.},
	number = {41},
	journal = {J. Neurosci.},
	author = {Zilli, Eric A and Hasselmo, Michael E},
	month = oct,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {13850--13860},
}

@article{hasselmo_grid_2008-1,
	title = {Grid cell mechanisms and function: contributions of entorhinal persistent spiking and phase resetting},
	volume = {18},
	abstract = {This article presents a model of grid cell firing based on the intrinsic persistent firing shown experimentally in neurons of entorhinal cortex. In this model, the mechanism of persistent firing allows individual neurons to hold a stable baseline firing frequency. Depolarizing input from speed-modulated head direction cells transiently shifts the frequency of firing from baseline, resulting in a shift in spiking phase in proportion to the integral of velocity. The convergence of input from different persistent firing neurons causes spiking in a grid cell only when the persistent firing neurons are within similar phase ranges. This model effectively simulates the two-dimensional firing of grid cells in open field environments, as well as the properties of theta phase precession. This model provides an alternate implementation of oscillatory interference models. The persistent firing could also interact on a circuit level with rhythmic inhibition and neurons showing membrane potential oscillations to code position with spiking phase. These mechanisms could operate in parallel with computation of position from visual angle and distance of stimuli. In addition to simulating two-dimensional grid patterns, models of phase interference can account for context-dependent firing in other tasks. In network simulations of entorhinal cortex, hippocampus, and postsubiculum, the reset of phase effectively replicates context-dependent firing by entorhinal and hippocampal neurons during performance of a continuous spatial alternation task, a delayed spatial alternation task with running in a wheel during the delay period (Pastalkova et al., Science, 2008), and a hairpin maze task.},
	number = {12},
	journal = {Hippocampus},
	author = {Hasselmo, Michael E},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {1213--1229},
}

@article{giocomo_time_2008,
	title = {Time constants of h current in layer ii stellate cells differ along the dorsal to ventral axis of medial entorhinal cortex},
	volume = {28},
	abstract = {Chronic recordings in the medial entorhinal cortex of behaving rats have found grid cells, neurons that fire when the rat is in a hexagonal array of locations. Grid cells recorded at different dorsal-ventral anatomical positions show systematic changes in size and spacing of firing fields. To test possible mechanisms underlying these differences, we analyzed properties of the hyperpolarization-activated cation current I(h) in voltage-clamp recordings from stellate cells in entorhinal slices from different dorsal-ventral locations. The time constant of h current was significantly different between dorsal and ventral neurons. The time constant of h current correlated with membrane potential oscillation frequency and the time constant of the sag potential in the same neurons. Differences in h current could underlie differences in membrane potential oscillation properties and contribute to grid cell periodicity along the dorsal-ventral axis of medial entorhinal cortex.},
	number = {38},
	journal = {J. Neurosci.},
	author = {Giocomo, Lisa M and Hasselmo, Michael E},
	month = sep,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {9414--9425},
}

@article{mhatre_grid_2012,
	title = {Grid cell hexagonal patterns formed by fast self-organized learning within entorhinal cortex},
	volume = {22},
	abstract = {Grid cells in the dorsal segment of the medial entorhinal cortex (dMEC) show remarkable hexagonal activity patterns, at multiple spatial scales, during spatial navigation. It has previously been shown how a self-organizing map can convert firing patterns across entorhinal grid cells into hippocampal place cells that are capable of representing much larger spatial scales. Can grid cell firing fields also arise during navigation through learning within a self-organizing map? This article describes a simple and general mathematical property of the trigonometry of spatial navigation which favors hexagonal patterns. The article also develops a neural model that can learn to exploit this trigonometric relationship. This GRIDSmap self-organizing map model converts path integration signals into hexagonal grid cell patterns of multiple scales. GRIDSmap creates only grid cell firing patterns with the observed hexagonal structure, predicts how these hexagonal patterns can be learned from experience, and can process biologically plausible neural input and output signals during navigation. These results support an emerging unified computational framework based on a hierarchy of self-organizing maps for explaining how entorhinal-hippocampal interactions support spatial navigation. {\textbackslash}copyright 2010 Wiley-Liss, Inc.},
	journal = {Hippocampus},
	author = {Mhatre, Himanshu and Gorchetchnikov, Anatoli and Grossberg, Stephen},
	month = dec,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {320--334},
}

@article{wagatsuma_neural_2007,
	title = {Neural dynamics of the cognitive map in the hippocampus},
	volume = {1},
	abstract = {The rodent hippocampus has been thought to represent the spatial environment as a cognitive map. In the classical theory, the cognitive map has been explained as a consequence of the fact that different spatial regions are assigned to different cell populations in the framework of rate coding. Recently, the relation between place cell firing and local field oscillation theta in terms of theta phase precession was experimentally discovered and suggested as a temporal coding mechanism leading to memory formation of behavioral sequences accompanied with asymmetric Hebbian plasticity. The cognitive map theory is apparently outside of the sequence memory view. Therefore, theoretical analysis is necessary to consider the biological neural dynamics for the sequence encoding of the memory of behavioral sequences, providing the cognitive map formation. In this article, we summarize the theoretical neural dynamics of the real-time sequence encoding by theta phase precession, called theta phase coding, and review a series of theoretical models with the theta phase coding that we previously reported. With respect to memory encoding functions, instantaneous memory formation of one-time experience was first demonstrated, and then the ability of integration of memories of behavioral sequences into a network of the cognitive map was shown. In terms of memory retrieval functions, theta phase coding enables the hippocampus to represent the spatial location in the current behavioral context even with ambiguous sensory input when multiple sequences were coded. Finally, for utilization, retrieved temporal sequences in the hippocampus can be available for action selection, through the process of reverting theta rhythm-dependent activities to information in the behavioral time scale. This theoretical approach allows us to investigate how the behavioral sequences are encoded, updated, retrieved and used in the hippocampus, as the real-time interaction with the external environment. It may indeed be the bridge to the episodic memory function in human hippocampus.},
	number = {2},
	journal = {Cogn. Neurodyn.},
	author = {Wagatsuma, Hiroaki and Yamaguchi, Yoko},
	month = jun,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {119--141},
}

@article{young_cortical_2007,
	title = {Cortical reorganization consistent with spike timing-but not correlation-dependent plasticity},
	volume = {10},
	abstract = {The receptive fields of neurons in primary visual cortex that are inactivated by retinal damage are known to 'shift' to nondamaged retinal locations, seemingly due to the plasticity of intracortical connections. We have observed in cats that these shifts occur in a pattern that is highly convergent, even among receptive fields that are separated by large distances before inactivation. Here we show, using a computational model of primary visual cortex, that the observed convergent shifts are inconsistent with the common assumption that the underlying intracortical connection plasticity is dependent on the temporal correlation of pre- and postsynaptic action potentials. The shifts are, however, consistent with the hypothesis that this plasticity is dependent on the temporal order of pre- and postsynaptic action potentials. This convergent reorganization seems to require increased neuronal gain, revealing a mechanism that networks may use to selectively facilitate the didactic transfer of neuronal response properties.},
	number = {7},
	journal = {Nat. Neurosci.},
	author = {Young, Joshua M and Waleszczyk, Wioletta J and Wang, Chun and Calford, Michael B and Dreher, Bogdan and Obermayer, Klaus},
	month = jul,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {887--895},
}

@article{sen_song_competitive_2000,
	title = {Competitive {Hebbian} learning through spike-timing-dependent synaptic plasticity},
	volume = {3},
	number = {9},
	journal = {Nature},
	author = {Sen Song, Kenneth D Miller and Abbott, L F},
	year = {2000},
	keywords = {merged\_fiete.bib},
}

@article{lengyel_matching_2005,
	title = {Matching storage and recall: hippocampal spike timing-dependent plasticity and phase response curves},
	volume = {8},
	abstract = {Hippocampal area CA3 is widely considered to function as an autoassociative memory. However, it is insufficiently understood how it does so. In particular, the extensive experimental evidence for the importance of carefully regulated spiking times poses the question as to how spike timing-based dynamics may support memory functions. Here, we develop a normative theory of autoassociative memory encompassing such network dynamics. Our theory specifies the way that the synaptic plasticity rule of a memory constrains the form of neuronal interactions that will retrieve memories optimally. If memories are stored by spike timing-dependent plasticity, neuronal interactions should be formalized in terms of a phase response curve, indicating the effect of presynaptic spikes on the timing of postsynaptic spikes. We show through simulation that such memories are competent analog autoassociators and demonstrate directly that the attributes of phase response curves of CA3 pyramidal cells recorded in vitro qualitatively conform with the theory.},
	number = {12},
	journal = {Nat. Neurosci.},
	author = {Lengyel, Máté and Kwag, Jeehyun and Paulsen, Ole and Dayan, Peter},
	month = dec,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {1677--1683},
}

@article{lisman_long-term_2003,
	title = {Long-term potentiation: outstanding questions and attempted synthesis},
	volume = {358},
	abstract = {This article attempts an overview of the mechanism of NMDAR-dependent long-term potentiation (LTP) and its role in hippocampal networks. Efforts are made to integrate information, often in speculative ways, and to identify unresolved issues about the induction, expression and molecular storage processes. The pre/post debate about LTP expression has been particularly difficult to resolve. The following hypothesis attempts to reconcile the available physiological evidence as well as anatomical evidence that LTP increases synapse size. It is proposed that synapses are composed of a variable number of trans-synaptic modules, each having presynaptic release sites and a postsynaptic structure that can be AMPAfied by the addition of a hyperslot assembly that anchors 10-20 AMPA channels. According to a newly developed view of transmission, the quantal response is generated by AMPA channels near the site of vesicle release and so will depend on whether the module where release occurs has been AMPAfied. LTP expression may involve two structurally mediated processes: (i) the AMPAfication of existing modules by addition of hyperslot assemblies: this is a purely postsynaptic process and produces an increase in the probability of an AMPA response, with no change in the NMDA component; and (ii) the addition of new modules: this is a structurally coordinated pre/post process that leads to LTP-induced synapse enlargement and potentiation of the NMDA component owing to an increase in the number of release sites (the number of NMDA channels is assumed to be fixed). The protocol used for LTP induction appears to affect the proportion of these two processes; pairing protocols that involve low-frequency presynaptic stimulation induce only AMPAfication, making LTP purely postsynaptic, whereas high-frequency stimulation evokes both processes, giving rise to a presynaptic component. This model is capable of reconciling much of the seemingly contradictory evidence in the pre/post debate. The structural nature of the postulated changes is relevant to a second debate: whether a CaMKII switch or protein-dependent structural change is the molecular memory mechanism. A possible reconciliation is that a reversible CaMKII switch controls the construction of modules and hyperslot assemblies from newly synthesized proteins.},
	number = {1432},
	journal = {Philos. Trans. R. Soc. Lond. B Biol. Sci.},
	author = {Lisman, John},
	month = apr,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {829--842},
}

@article{bell_synaptic_1997,
	title = {Synaptic plasticity in a cerebellum-like structure depends on temporal order},
	volume = {387},
	journal = {Nature},
	author = {Bell, C and Han, V and Sugawara, Y and Grant, K},
	year = {1997},
	keywords = {merged\_fiete.bib},
}

@article{hayashi_ltd_2009,
	title = {{LTD} windows of the {STDP} learning rule and synaptic connections having a large transmission delay enable robust sequence learning amid background noise},
	volume = {3},
	abstract = {Spike-timing-dependent synaptic plasticity (STDP) is a simple and effective learning rule for sequence learning. However, synapses being subject to STDP rules are readily influenced in noisy circumstances because synaptic conductances are modified by pre- and postsynaptic spikes elicited within a few tens of milliseconds, regardless of whether those spikes convey information or not. Noisy firing existing everywhere in the brain may induce irrelevant enhancement of synaptic connections through STDP rules and would result in uncertain memory encoding and obscure memory patterns. We will here show that the LTD windows of the STDP rules enable robust sequence learning amid background noise in cooperation with a large signal transmission delay between neurons and a theta rhythm, using a network model of the entorhinal cortex layer II with entorhinal-hippocampal loop connections. The important element of the present model for robust sequence learning amid background noise is the symmetric STDP rule having LTD windows on both sides of the LTP window, in addition to the loop connections having a large signal transmission delay and the theta rhythm pacing activities of stellate cells. Above all, the LTD window in the range of positive spike-timing is important to prevent influences of noise with the progress of sequence learning.},
	number = {2},
	journal = {Cogn. Neurodyn.},
	author = {Hayashi, Hatsuo and Igarashi, Jun},
	month = jun,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {119--130},
}

@article{moser_test_2005,
	title = {A test of the reverberatory activity hypothesis for hippocampal 'place' cells},
	volume = {130},
	abstract = {One of several tenable hypotheses that can be proposed to explain the complex dynamics of spatially selective hippocampal neural activity postulates that the region of space over which a given cell receives its external input is actually much smaller than the classical 'place field.' According to this notion, the later portions of the field reflect some form of network hysteresis resulting from 'reverberatory' activity within reentrant, synaptically coupled cell assemblies within the hippocampus. This hypothesis predicts that transient, global inhibition, induced after the onset of firing, might truncate the remainder of the place field. To test this hypothesis, principal afferents to the hippocampus were stimulated bilaterally in rats running on a circular track, evoking widespread inhibition throughout the hippocampus, and abolishing all spike activity from simultaneously recorded populations of CA1 pyramidal cells for periods of 150-300 ms. Stimulation at any point within the place field of a given cell suppressed firing only for such brief intervals, followed by an immediate resumption for the remainder of the field. These results suggest that without additional cellular and/or synaptic mechanisms, reverberatory activity alone within the hippocampus does not account for the shape and spatial extent of place fields.},
	number = {2},
	journal = {Neuroscience},
	author = {Moser, E I and Moser, M-B and Lipa, P and Newton, M and Houston, F P and Barnes, C A and McNaughton, B L},
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {519--526},
}

@article{yamaguchi_theory_2003,
	title = {A theory of hippocampal memory based on theta phase precession},
	volume = {89},
	abstract = {The neural dynamics of the hippocampal network for memory encoding of novel temporal sequences is proposed based on the theta rhythm modulated firing of place cells called theta phase precession. It is hypothesized that theta phase precession is generated at the entorhinal cortex by phase locking between local field theta oscillation and neural oscillators and that the hippocampal closed network with feedforward and backward projections employ theta phase precession to create selectivity in the associative connections needed for temporal sequence storage. Our analyses and computer experiments reveal that the phase precession generated by phase locking instantaneously endows stable phase relations among neural activities in the successively changing neural population. It is concluded that theta phase precession provides biologically plausible dynamics for the memory encoding of novel temporal sequences as episodic events.},
	number = {1},
	journal = {Biol. Cybern.},
	author = {Yamaguchi, Yoko},
	month = jul,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {1--9},
}

@article{tsodkys_associative_1995,
	title = {Associative memory and hippocampus place cells},
	journal = {Int. J. Neural Syst.},
	author = {Tsodkys, M and Sejnowski, T},
	year = {1995},
	keywords = {merged\_fiete.bib},
}

@article{mayank_r_mehta_experience-dependent_1997,
	title = {Experience-dependent, asymmetric expansion of hippocampal place fields},
	volume = {94},
	journal = {Proc. Natl. Acad. Sci.},
	author = {{Mayank R. Mehta} and Mcnaughton, Bruce L},
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {8918--8921},
}

@article{kentros_increased_2004,
	title = {Increased attention to spatial context increases both place field stability and spatial memory},
	volume = {42},
	abstract = {The hippocampal formation is critical for the acquisition and consolidation of memories. When recorded in freely moving animals, hippocampal pyramidal neurons fire in a location-specific manner: they are “place” cells, comprising a hippocampal representation of the animal's environment. To explore the relationship between place cells and spatial memory, we recorded from mice in several behavioral contexts. We found that long-term stability of place cell firing fields correlates with the degree of attentional demands and that successful spatial task performance was associated with stable place fields. Furthermore, conditions that maximize place field stability greatly increase orientation to novel cues. This suggests that storage and retrieval of place cells is modulated by a top-down cognitive process resembling attention and that place cells are neural correlates of spatial memory. We propose a model whereby attention provides the requisite neuromodulatation to switch short-term homosynaptic plasticity to long-term heterosynaptic plasticity, and we implicate dopamine in this process.},
	number = {2},
	journal = {Neuron},
	author = {Kentros, Clifford G and Agnihotri, Naveen T and Streater, Samantha and Hawkins, Robert D and Kandel, Eric R},
	month = apr,
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {283--295},
}

@article{leutgeb_independent_2005,
	title = {Independent codes for spatial and episodic memory in hippocampal neuronal ensembles},
	volume = {309},
	abstract = {Hippocampal neurons were recorded under conditions in which the recording chamber was varied but its location remained unchanged versus conditions in which an identical chamber was encountered in different places. Two forms of neuronal pattern separation occurred. In the variable cue-constant place condition, the firing rates of active cells varied, often over more than an order of magnitude, whereas the location of firing remained constant. In the variable place-constant cue condition, both location and rates changed, so that population vectors for a given location in the chamber were statistically independent. These independent encoding schemes may enable simultaneous representation of spatial and episodic memory information.},
	number = {5734},
	journal = {Science},
	author = {Leutgeb, Stefan and Leutgeb, Jill K and Barnes, Carol A and Moser, Edvard I and McNaughton, Bruce L and Moser, May-Britt},
	month = jul,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {619--623},
}

@article{_henry_c_tuckwell_inhibition_2009,
	title = {Inhibition of rhythmic neural spiking by noise: the occurrence of a minimum in activity with increasing noise},
	journal = {Naturwissenschaften},
	author = {\& Henry C. Tuckwell, Boris S Gutkin \& Jürgen Jost},
	year = {2009},
	keywords = {merged\_fiete.bib},
}

@article{quirk_interaction_1999,
	title = {Interaction between spike waveform classification and temporal sequence detection},
	volume = {94},
	abstract = {In vivo extracellular recordings have allowed researchers to study the response properties of neurons to behaviorally relevant stimuli. In this paper we use multiple tetrode recordings from the hippocampus of the freely behaving rat to show that the action potential amplitude of a given cell can vary in a systematic and activity dependent manner over behaviorally relevant time scales. Since the discrimination algorithms used by experimenters to isolate cells from extracellular recordings are based on differences in waveforms, we show how these systematic changes in waveform shape can lead to non-random errors in single cell isolation. We further demonstrate that these non-random errors can lead to apparent temporal ordering effects between neurons in the absence of any specific temporal relationship. A firm understanding of these naturally occurring physiological changes is therefore critical for the evaluation of higher order phenomena such as the temporally correlated firing of ensembles of neurons.},
	number = {1},
	journal = {J. Neurosci. Methods},
	author = {Quirk, M C and Wilson, M A},
	month = dec,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {41--52},
}

@article{maurer_network_2007,
	title = {Network and intrinsic cellular mechanisms underlying theta phase precession of hippocampal neurons},
	volume = {30},
	abstract = {Hippocampal 'place cells' systematically shift their phase of firing in relation to the theta rhythm as an animal traverses the 'place field'. These dynamics imply that the neural ensemble begins each theta cycle at a point in its state-space that might 'represent' the current location of the rat, but that the ensemble 'looks ahead' during the rest of the cycle. Phase precession could result from intrinsic cellular dynamics involving interference of two oscillators of different frequencies, or from network interactions, similar to Hebb's 'phase sequence' concept, involving asymmetric synaptic connections. Both models have difficulties accounting for all of the available experimental data, however. A hybrid model, in which the look-ahead phenomenon implied by phase precession originates in superficial entorhinal cortex by some form of interference mechanism and is enhanced in the hippocampus proper by asymmetric synaptic plasticity during sequence encoding, seems to be consistent with available data, but as yet there is no fully satisfactory theoretical account of this phenomenon. This review is part of the INMED/TINS special issue Physiogenic and pathogenic oscillations: the beauty and the beast, based on presentations at the annual INMED/TINS symposium (http://inmednet.com).},
	number = {7},
	journal = {Trends Neurosci.},
	author = {Maurer, Andrew P and McNaughton, Bruce L},
	month = jul,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {325--333},
}

@article{zugaro_spike_2005,
	title = {Spike phase precession persists after transient intrahippocampal perturbation},
	volume = {8},
	abstract = {Oscillatory spike timing in the hippocampus is regarded as a temporal coding mechanism for space, but the underlying mechanisms are poorly understood. To contrast the predictions of the different models of phase precession, we transiently turned off neuronal discharges for up to 250 ms and reset the phase of theta oscillations by stimulating the commissural pathway in rats. After recovery from silence, phase precession continued. The phase of spikes for the first theta cycle after the perturbation was more advanced than the phase of spikes for the last theta cycle just before the perturbation. These findings indicate that phase advancement that emerges within hippocampal circuitry may be updated at the beginning of each theta cycle by extrahippocampal inputs.},
	number = {1},
	journal = {Nat. Neurosci.},
	author = {Zugaro, Michaël B and Monconduit, Lénaïc and Buzsáki, György},
	month = jan,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {67--71},
}

@article{moser_metric_2008-1,
	title = {A metric for space},
	volume = {18},
	abstract = {Not all areas of neuronal systems investigation have matured to the stage where computation can be understood at the microcircuit level. In mammals, insights into cortical circuit functions have been obtained for the early stages of sensory systems, where signals can be followed through networks of increasing complexity from the receptors to the primary sensory cortices. These studies have suggested how neurons and neuronal networks extract features from the external world, but how the brain generates its own codes, in the higher-order nonsensory parts of the cortex, has remained deeply mysterious. In this terra incognita, a path was opened by the discovery of grid cells, place-modulated entorhinal neurons whose firing locations define a periodic triangular or hexagonal array covering the entirety of the animal's available environment. This array of firing is maintained in spite of ongoing changes in the animal's speed and direction, suggesting that grid cells are part of the brain's metric for representation of space. Because the crystal-like structure of the firing fields is created within the nervous system itself, grid cells may provide scientists with direct access to some of the most basic operational principles of cortical circuits.},
	number = {12},
	journal = {Hippocampus},
	author = {Moser, Edvard I and Moser, May-Britt},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {1142--1156},
}

@article{kjelstrup_finite_2008,
	title = {Finite scale of spatial representation in the hippocampus},
	volume = {321},
	abstract = {To determine how spatial scale is represented in the pyramidal cell population of the hippocampus, we recorded neural activity at multiple longitudinal levels of this brain area while rats ran back and forth on an 18-meter-long linear track. CA3 cells had well-defined place fields at all levels. The scale of representation increased almost linearly from {\textless}1 meter at the dorsal pole to approximately 10 meters at the ventral pole. The results suggest that the place-cell map includes the entire hippocampus and that environments are represented in the hippocampus at a topographically graded but finite continuum of scales.},
	number = {5885},
	journal = {Science},
	author = {Kjelstrup, Kirsten Brun and Solstad, Trygve and Brun, Vegard Heimly and Hafting, Torkel and Leutgeb, Stefan and Witter, Menno P and Moser, Edvard I and Moser, May-Britt},
	month = jul,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {140--143},
}

@article{colgin_understanding_2008,
	title = {Understanding memory through hippocampal remapping},
	volume = {31},
	abstract = {Memory interference is a common cause of forgetting. Interference is a byproduct of the need to balance the formation of well-differentiated representations against the ability to retrieve memories from cues that are not identical to the original experience. How the brain accomplishes this has remained elusive. Here we review how insights can be gained from studies of an apparently unrelated phenomenon in the rodent brain–remapping in hippocampal place cells. Remapping refers to the formation of distinct representations in populations of place cells after minor changes in inputs to the hippocampus. Remapping might reflect processes involved generally in decorrelation of overlapping signals. These processes might be crucial for storing large numbers of similar experiences with only minimal interference.},
	number = {9},
	journal = {Trends Neurosci.},
	author = {Colgin, Laura Lee and Moser, Edvard I and Moser, May-Britt},
	month = sep,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {469--477},
}

@article{morris_elements_2003,
	title = {Elements of a neurobiological theory of the hippocampus: the role of activity-dependent synaptic plasticity in memory},
	volume = {358},
	abstract = {The hypothesis that synaptic plasticity is a critical component of the neural mechanisms underlying learning and memory is now widely accepted. In this article, we begin by outlining four criteria for evaluating the 'synaptic plasticity and memory (SPM)' hypothesis. We then attempt to lay the foundations for a specific neurobiological theory of hippocampal (HPC) function in which activity-dependent synaptic plasticity, such as long-term potentiation (LTP), plays a key part in the forms of memory mediated by this brain structure. HPC memory can, like other forms of memory, be divided into four processes: encoding, storage, consolidation and retrieval. We argue that synaptic plasticity is critical for the encoding and intermediate storage of memory traces that are automatically recorded in the hippocampus. These traces decay, but are sometimes retained by a process of cellular consolidation. However, we also argue that HPC synaptic plasticity is not involved in memory retrieval, and is unlikely to be involved in systems-level consolidation that depends on HPC-neocortical interactions, although neocortical synaptic plasticity does play a part. The information that has emerged from the worldwide focus on the mechanisms of induction and expression of plasticity at individual synapses has been very valuable in functional studies. Progress towards a comprehensive understanding of memory processing will also depend on the analysis of these synaptic changes within the context of a wider range of systems-level and cellular mechanisms of neuronal transmission and plasticity.},
	number = {1432},
	journal = {Philos. Trans. R. Soc. Lond. B Biol. Sci.},
	author = {Morris, R G M and Moser, E I and Riedel, G and Martin, S J and Sandin, J and Day, M and O'Carroll, C},
	month = apr,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {773--786},
}

@article{sun_missing_2007,
	title = {The missing piece in the “use it or lose it” puzzle: is inhibition regulated by activity or does it act on its own accord?},
	volume = {18},
	journal = {Rev. Neurosci.},
	author = {Sun, Qian-Quan},
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {295--310},
}

@article{collingridge_long-term_2010,
	title = {Long-term depression in the {CNS}},
	volume = {11},
	abstract = {Long-term depression (LTD) in the CNS has been the subject of intense investigation as a process that may be involved in learning and memory and in various pathological conditions. Several mechanistically distinct forms of this type of synaptic plasticity have been identified and their molecular mechanisms are starting to be unravelled. Most studies have focused on forms of LTD that are triggered by synaptic activation of either NMDARs (N-methyl-D-aspartate receptors) or metabotropic glutamate receptors (mGluRs). Converging evidence supports a crucial role of LTD in some types of learning and memory and in situations in which cognitive demands require a flexible response. In addition, LTD may underlie the cognitive effects of acute stress, the addictive potential of some drugs of abuse and the elimination of synapses in neurodegenerative diseases.},
	number = {7},
	journal = {Nat. Rev. Neurosci.},
	author = {Collingridge, Graham L and Peineau, Stephane and Howland, John G and Wang, Yu Tian},
	month = jul,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {459--473},
}

@article{habib_low-frequency-induced_2010,
	title = {Low-frequency-induced synaptic potentiation: a paradigm shift in the field of memory-related plasticity mechanisms?},
	volume = {20},
	abstract = {Long-term potentiation (LTP) and long-term depression (LTD) are two forms of synaptic plasticity thought to play functional roles in learning and memory processes. It is generally assumed that the direction of synaptic modifications (i.e., up- or down-regulation of synaptic strength) depends on the specific pattern of afferent inputs, with high frequency activity or stimulation effectively inducing LTP, while low-frequency patterns often elicit LTD. This dogma (“high frequency-LTP, low frequency-LTD”) has recently been challenged by evidence demonstrating low frequency stimulation (LFS)-induced synaptic potentiation in the rodent hippocampus and amygdala. Extensive work in the past decades has focused on deciphering the mechanisms by which high frequency stimulation of afferent fiber systems results in LTP. With this review, we will compare and contrast the well-known synaptic and cellular mechanisms underlying classical, high-frequency-induced LTP to those mediating the more recently discovered phenomena of LFS-induced synaptic enhancement. In addition, we argue that LFS protocols provide a means to more accurately mimic some endogenous, oscillatory activity patterns present in hippocampal and extra-hippocampal (especially neocortical) circuits during periods of memory consolidation. Consequently, LFS-induced synaptic potentiation offers a novel and important avenue to investigate cellular and systems-level mechanisms mediating the encoding, consolidation, and transfer of information throughout multiple forebrain networks implicated in learning and memory processes. (c) 2009 Wiley-Liss, Inc.},
	number = {1},
	journal = {Hippocampus},
	author = {Habib, Diala and Dringenberg, Hans C},
	month = jan,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {29--35},
}

@article{feldman_synaptic_2009,
	title = {Synaptic mechanisms for plasticity in neocortex},
	volume = {32},
	abstract = {Sensory experience and learning alter sensory representations in cerebral cortex. The synaptic mechanisms underlying sensory cortical plasticity have long been sought. Recent work indicates that long-term cortical plasticity is a complex, multicomponent process involving multiple synaptic and cellular mechanisms. Sensory use, disuse, and training drive long-term potentiation and depression (LTP and LTD), homeostatic synaptic plasticity and plasticity of intrinsic excitability, and structural changes including formation, removal, and morphological remodeling of cortical synapses and dendritic spines. Both excitatory and inhibitory circuits are strongly regulated by experience. This review summarizes these findings and proposes that these mechanisms map onto specific functional components of plasticity, which occur in common across the primary somatosensory, visual, and auditory cortices.},
	journal = {Annu. Rev. Neurosci.},
	author = {Feldman, Daniel E},
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {33--55},
}

@article{royer_distinct_2010,
	title = {Distinct representations and theta dynamics in dorsal and ventral hippocampus},
	volume = {30},
	abstract = {Although anatomical, lesion, and imaging studies of the hippocampus indicate qualitatively different information processing along its septo-temporal axis, physiological mechanisms supporting such distinction are missing. We found fundamental differences between the dorsal (dCA3) and the ventral-most parts (vCA3) of the hippocampus in both environmental representation and temporal dynamics. Discrete place fields of dCA3 neurons evenly covered all parts of the testing environments. In contrast, vCA3 neurons (1) rarely showed continuous two-dimensional place fields, (2) differentiated open and closed arms of a radial maze, and (3) discharged similar firing patterns with respect to the goals, both on multiple arms of a radial maze and during opposite journeys in a zigzag maze. In addition, theta power and the fraction of theta-rhythmic neurons were substantially reduced in the ventral compared with dorsal hippocampus. We hypothesize that the spatial representation in the septo-temporal axis of the hippocampus is progressively decreased. This change is paralleled with a reduction of theta rhythm and an increased representation of nonspatial information.},
	number = {5},
	journal = {J. Neurosci.},
	author = {Royer, Sébastien and Sirota, Anton and Patel, Jagdish and Buzsáki, György},
	month = feb,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {1777--1787},
}

@article{manns_evolution_2006,
	title = {Evolution of declarative memory},
	volume = {16},
	abstract = {The present review considers research on the hippocampus and related areas from humans and experimental animals and makes three main points. First, many of the anatomical details of the hippocampus and adjacent cortical areas in the parahippocampal region are conserved across mammals. Second, the functional role of these areas in declarative memory is also conserved across species. Third, an evolutionary approach will be key to understanding exactly how the local circuitry of the hippocampus and parahippocampal region supports declarative memory. To highlight the utility of this approach, a schematic model is described in which separate streams of spatial and nonspatial information converge on the hippocampus. By this view, a fundamental function of the mammalian hippocampus is to combine incoming information about spatial context from the postrhinal (parahippocampal in primates) cortex and medial entorhinal area with incoming information about nonspatial items from the perirhinal cortex and lateral entorhinal area. The underlying neurobiological computations that arise from local circuitry enable item-in-context memory and are proposed to be fundamental to many examples of declarative memory, including episodic memory in humans and spatial memory in experimental animals.},
	number = {9},
	journal = {Hippocampus},
	author = {Manns, Joseph R and Eichenbaum, Howard},
	year = {2006},
	keywords = {merged\_fiete.bib, hippocampus non-spatial},
	pages = {795--808},
}

@article{hasselmo_hippocampal_2005,
	title = {Hippocampal mechanisms for the context-dependent retrieval of episodes},
	volume = {18},
	abstract = {Behaviors ranging from delivering newspapers to waiting tables depend on remembering previous episodes to avoid incorrect repetition. Physiologically, this requires mechanisms for long-term storage and selective retrieval of episodes based on the time of occurrence, despite variable intervals and similarity of events in a familiar environment. Here, this process has been modeled based on the physiological properties of the hippocampal formation, including mechanisms for sustained activity in entorhinal cortex and theta rhythm oscillations in hippocampal subregions. The model simulates the context-sensitive firing properties of hippocampal neurons including trial-specific firing during spatial alternation and trial by trial changes in theta phase precession on a linear track. This activity is used to guide behavior, and lesions of the hippocampal network impair memory-guided behavior. The model links data at the cellular level to behavior at the systems level, describing a physiologically plausible mechanism for the brain to recall a given episode which occurred at a specific place and time.},
	number = {9},
	journal = {Neural Netw.},
	author = {Hasselmo, Michael E and Eichenbaum, Howard},
	month = nov,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {1172--1190},
}

@article{oscillators_caroline_2007,
	title = {Caroline {Geisler}, {David} {Robbe}, {Michae} l {Zugaro}, {Anton} {Sirota}, and {Gyorgy} {Buzsaki}},
	volume = {104},
	number = {19},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Oscillators, Hippocampal Place Cell Assemblies Are Speed-Controlled},
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {8149--8154},
}

@article{eichenbaum_hippocampus_2004,
	title = {Hippocampus: cognitive processes and neural representations that underlie declarative memory},
	volume = {44},
	abstract = {The hippocampus serves a critical role in declarative memory–our capacity to recall everyday facts and events. Recent studies using functional brain imaging in humans and neuropsychological analyses of humans and animals with hippocampal damage have revealed some of the elemental cognitive processes mediated by the hippocampus. In addition, recent characterizations of neuronal firing patterns in behaving animals and humans have suggested how neural representations in the hippocampus underlie those elemental cognitive processes in the service of declarative memory.},
	number = {1},
	journal = {Neuron},
	author = {Eichenbaum, Howard},
	month = sep,
	year = {2004},
	keywords = {merged\_fiete.bib, hippocampus non-spatial},
	pages = {109--120},
}

@article{yoganarasimha_lateral_2010,
	title = {Lateral entorhinal neurons are not spatially selective in cue-rich environments},
	abstract = {The hippocampus is a brain region that is critical for spatial learning, context-dependent memory, and episodic memory. It receives major inputs from the medial entorhinal cortex (MEC) and the lateral EC (LEC). MEC neurons show much greater spatial firing than LEC neurons in a recording chamber with a single, salient landmark. The MEC cells are thought to derive their spatial tuning through path integration, which permits spatially selective firing in such a cue-deprived environment. In accordance with theories that postulate two spatial mapping systems that provide input to the hippocampus-an internal, path-integration system and an external, landmark-based system-it was possible that LEC neurons can also convey a spatial signal, but that the signal requires multiple landmarks to define locations, rather than movement integration. To test this hypothesis, neurons from the MEC and LEC were recorded as rats foraged for food in cue-rich environments. In both environments, LEC neurons showed little spatial specificity, whereas many MEC neurons showed a robust spatial signal. These data strongly support the notion that the MEC and LEC convey fundamentally different types of information to the hippocampus, in terms of their spatial firing characteristics, under various environmental and behavioral conditions. {\textbackslash}copyright 2010 Wiley-Liss, Inc.},
	journal = {Hippocampus},
	author = {Yoganarasimha, D and Rao, Geeta and Knierim, James J},
	month = sep,
	year = {2010},
	keywords = {merged\_fiete.bib},
}

@article{hasselmo_neuromodulation_2002,
	title = {Neuromodulation, theta rhythm and rat spatial navigation},
	volume = {15},
	abstract = {Cholinergic and GABAergic innervation of the hippocampus plays an important role in human memory function and rat spatial navigation. Drugs which block acetylcholine receptors or enhance GABA receptor activation cause striking impairments in the encoding of new information. Lesions of the cholinergic innervation of the hippocampus reduce the amplitude of hippocampal theta rhythm and cause impairments in spatial navigation tasks, including the Morris water maze, eight-arm radial maze, spatial reversal and delayed alternation. Here, we review previous work on the role of cholinergic modulation in memory function, and we present a new model of the hippocampus and entorhinal cortex describing the interaction of these regions for goal-directed spatial navigation in behavioral tasks. These mechanisms require separate functional phases for: (1) encoding of pathways without interference from retrieval, and (2) retrieval of pathways for guiding selection of the next movement. We present analysis exploring how phasic changes in physiological variables during hippocampal theta rhythm could provide these different phases and enhance spatial navigation function.},
	number = {4-6},
	journal = {Neural Netw.},
	author = {Hasselmo, Michael E and Hay, Jonathan and Ilyn, Maxim and Gorchetchnikov, Anatoli},
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {689--707},
}

@article{kumaran_human_2005,
	title = {The human hippocampus: cognitive maps or relational memory?},
	volume = {25},
	abstract = {The hippocampus is widely accepted to play a pivotal role in memory. Two influential theories offer competing accounts of its fundamental operating mechanism. The cognitive map theory posits a special role in mapping large-scale space, whereas the relational theory argues it supports amodal relational processing. Here, we pit the two theories against each other using a novel paradigm in which the relational processing involved in navigating in a city was matched with similar navigational and relational processing demands in a nonspatial (social) domain. During functional magnetic resonance imaging, participants determined the optimal route either between friends' homes or between the friends themselves using social connections. Separate brain networks were engaged preferentially during the two tasks, with hippocampal activation driven only by spatial relational processing. We conclude that the human hippocampus appears to have a bias toward the processing of spatial relationships, in accordance with the cognitive map theory. Our results both advance our understanding of the nature of the hippocampal contribution to memory and provide insights into how social networks are instantiated at the neural level.},
	number = {31},
	journal = {J. Neurosci.},
	author = {Kumaran, Dharshan and Maguire, Eleanor A},
	month = aug,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {7254--7259},
}

@article{lubenov_hippocampal_2009-1,
	title = {Hippocampal theta oscillations are travelling waves},
	volume = {459},
	abstract = {Theta oscillations clock hippocampal activity during awake behaviour and rapid eye movement (REM) sleep. These oscillations are prominent in the local field potential, and they also reflect the subthreshold membrane potential and strongly modulate the spiking of hippocampal neurons. The prevailing view is that theta oscillations are synchronized throughout the hippocampus, despite the lack of conclusive experimental evidence. In contrast, here we show that in freely behaving rats, theta oscillations in area CA1 are travelling waves that propagate roughly along the septotemporal axis of the hippocampus. Furthermore, we find that spiking in the CA1 pyramidal cell layer is modulated in a consistent travelling wave pattern. Our results demonstrate that theta oscillations pattern hippocampal activity not only in time, but also across anatomical space. The presence of travelling waves indicates that the instantaneous output of the hippocampus is topographically organized and represents a segment, rather than a point, of physical space.},
	number = {7246},
	journal = {Nature},
	author = {Lubenov, Evgueniy V and Siapas, Athanassios G},
	month = may,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {534--539},
}

@article{canto_what_2008,
	title = {What does the anatomical organization of the entorhinal cortex tell us?},
	volume = {2008},
	abstract = {The entorhinal cortex is commonly perceived as a major input and output structure of the hippocampal formation, entertaining the role of the nodal point of cortico-hippocampal circuits. Superficial layers receive convergent cortical information, which is relayed to structures in the hippocampus, and hippocampal output reaches deep layers of entorhinal cortex, that project back to the cortex. The finding of the grid cells in all layers and reports on interactions between deep and superficial layers indicate that this rather simplistic perception may be at fault. Therefore, an integrative approach on the entorhinal cortex, that takes into account recent additions to our knowledge database on entorhinal connectivity, is timely. We argue that layers in entorhinal cortex show different functional characteristics most likely not on the basis of strikingly different inputs or outputs, but much more likely on the basis of differences in intrinsic organization, combined with very specific sets of inputs. Here, we aim to summarize recent anatomical data supporting the notion that the traditional description of the entorhinal cortex as a layered input-output structure for the hippocampal formation does not give the deserved credit to what this structure might be contributing to the overall functions of cortico-hippocampal networks.},
	journal = {Neural Plast.},
	author = {Canto, Cathrin B and Wouterlood, Floris G and Witter, Menno P},
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {381243},
}

@article{geisler_temporal_2010,
	title = {Temporal delays among place cells determine the frequency of population theta oscillations in the hippocampus},
	volume = {107},
	abstract = {Driven either by external landmarks or by internal dynamics, hippocampal neurons form sequences of cell assemblies. The coordinated firing of these active cells is organized by the prominent “theta” oscillations in the local field potential (LFP): place cells discharge at progressively earlier theta phases as the rat crosses the respective place field (“phase precession”). The faster oscillation frequency of active neurons and the slower theta LFP, underlying phase precession, creates a paradox. How can faster oscillating neurons comprise a slower population oscillation, as reflected by the LFP? We built a mathematical model that allowed us to calculate the population activity analytically from experimentally derived parameters of the single neuron oscillation frequency, firing field size (duration), and the relationship between within-theta delays of place cell pairs and their distance representations (“compression”). The appropriate combination of these parameters generated a constant frequency population rhythm along the septo-temporal axis of the hippocampus, while allowing individual neurons to vary their oscillation frequency and field size. Our results suggest that the faster-than-theta oscillations of pyramidal cells are inherent and that phase precession is a result of the coordinated activity of temporally shifted cell assemblies, relative to the population activity, reflected by the LFP.},
	number = {17},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Geisler, Caroline and Diba, Kamran and Pastalkova, Eva and Mizuseki, Kenji and Royer, Sebastien and Buzsáki, György},
	month = apr,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {7957--7962},
}

@article{stratton_calibration_2010,
	title = {Calibration of the head direction network: a role for symmetric angular head velocity cells},
	volume = {28},
	abstract = {Continuous attractor networks require calibration. Computational models of the head direction (HD) system of the rat usually assume that the connections that maintain HD neuron activity are pre-wired and static. Ongoing activity in these models relies on precise continuous attractor dynamics. It is currently unknown how such connections could be so precisely wired, and how accurate calibration is maintained in the face of ongoing noise and perturbation. Our adaptive attractor model of the HD system that uses symmetric angular head velocity (AHV) cells as a training signal shows that the HD system can learn to support stable firing patterns from poorly-performing, unstable starting conditions. The proposed calibration mechanism suggests a requirement for symmetric AHV cells, the existence of which has previously been unexplained, and predicts that symmetric and asymmetric AHV cells should be distinctly different (in morphology, synaptic targets and/or methods of action on postsynaptic HD cells) due to their distinctly different functions.},
	number = {3},
	journal = {J. Comput. Neurosci.},
	author = {Stratton, Peter and Wyeth, Gordon and Wiles, Janet},
	month = jun,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {527--538},
}

@article{boccara_grid_2010,
	title = {Grid cells in pre- and parasubiculum},
	volume = {13},
	abstract = {Allocentric space is mapped by a widespread brain circuit of functionally specialized cell types located in interconnected subregions of the hippocampal-parahippocampal cortices. Little is known about the neural architectures required to express this variety of firing patterns. In rats, we found that one of the cell types, the grid cell, was abundant not only in medial entorhinal cortex (MEC), where it was first reported, but also in pre- and parasubiculum. The proportion of grid cells in pre- and parasubiculum was comparable to deep layers of MEC. The symmetry of the grid pattern and its relationship to the theta rhythm were weaker, especially in presubiculum. Pre- and parasubicular grid cells intermingled with head-direction cells and border cells, as in deep MEC layers. The characterization of a common pool of space-responsive cells in architecturally diverse subdivisions of parahippocampal cortex constrains the range of mechanisms that might give rise to their unique functional discharge phenotypes.},
	number = {8},
	journal = {Nat. Neurosci.},
	author = {Boccara, Charlotte N and Sargolini, Francesca and Thoresen, Veslemøy Hult and Solstad, Trygve and Witter, Menno P and Moser, Edvard I and Moser, May-Britt},
	month = aug,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {987--994},
}

@article{savelli_hebbian_2010,
	title = {Hebbian {Analysis} of the {Transformation} of {Medial} {Entorhinal} {Grid}-{Cell} {Inputs} to {Hippocampal} {Place} {Fields}},
	volume = {103},
	journal = {J. Neurophysiol.},
	author = {Savelli, F and Knierim, J J},
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {3167--3183},
}

@article{stringer_self-organising_2004,
	title = {Self-organising continuous attractor networks with multiple activity packets, and the representation of space},
	volume = {17},
	abstract = {'Continuous attractor' neural networks can maintain a localised packet of neuronal activity representing the current state of an agent in a continuous space without external sensory input. In applications such as the representation of head direction or location in the environment, only one packet of activity is needed. For some spatial computations a number of different locations, each with its own features, must be held in memory. We extend previous approaches to continuous attractor networks (in which one packet of activity is maintained active) by showing that a single continuous attractor network can maintain multiple packets of activity simultaneously, if each packet is in a different state space or map. We also show how such a network could by learning self-organise to enable the packets in each space to be moved continuously in that space by idiothetic (motion) inputs. We show how such multi-packet continuous attractor networks could be used to maintain different types of feature (such as form vs colour) simultaneously active in the correct location in a spatial representation. We also show how high-order synapses can improve the performance of these networks, and how the location of a packet could be read by motor networks. The multiple packet continuous attractor networks described here may be used for spatial representations in brain areas such as the parietal cortex and hippocampus.},
	number = {1},
	journal = {Neural Netw.},
	author = {Stringer, S M and Rolls, E T and Trappenberg, T P},
	month = jan,
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {5--27},
}

@article{wills_development_2010,
	title = {Development of the hippocampal cognitive map in preweanling rats},
	volume = {328},
	abstract = {Orienting in large-scale space depends on the interaction of environmental experience and preconfigured, possibly innate, constructs. Place, head-direction, and grid cells in the hippocampal formation provide allocentric representations of space. Here we show how these cognitive representations emerge and develop as rat pups first begin to explore their environment. Directional, locational, and rhythmic organization of firing are present during initial exploration, including adultlike directional firing. The stability and precision of place cell firing continue to develop throughout juvenility. Stable grid cell firing appears later but matures rapidly to adult levels. Our results demonstrate the presence of three neuronal representations of space before extensive experience and show how they develop with age.},
	number = {5985},
	journal = {Science},
	author = {Wills, Tom J and Cacucci, Francesca and Burgess, Neil and O'Keefe, John},
	month = jun,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {1573--1576},
}

@article{hasselmo_grid_2007-1,
	title = {Grid cell firing may arise from interference of theta frequency membrane potential oscillations in single neurons},
	volume = {17},
	abstract = {Intracellular recording and computational modelling suggest that interactions of subthreshold membrane potential oscillation frequency in different dendritic branches of entorhinal cortex stellate cells could underlie the functional coding of continuous dimensions of space and time. Among other things, these interactions could underlie properties of grid cell field spacing. The relationship between experimental data on membrane potential oscillation frequency (f) and grid cell field spacing (G) indicates a constant scaling factor H = fG. This constant scaling factor between temporal oscillation frequency and spatial periodicity provides a starting constraint that is used to derive the model of Burgess et al. (Hippocampus, 2007). This model provides a consistent quantitative link between single cell physiological properties and properties of spiking units in awake behaving animals. Further properties and predictions of this model about single cell and network physiological properties are analyzed. In particular, the model makes quantitative predictions about the change in membrane potential, single cell oscillation frequency, and network oscillation frequency associated with speed of movement, about the independence of single cell properties from network theta rhythm oscillations, and about the effect of variations in initial oscillatory phase on the pattern of grid cell firing fields. These same mechanisms of subthreshold oscillations may play a more general role in memory function, by providing a method for learning arbitrary time intervals in memory sequences.},
	number = {12},
	journal = {Hippocampus},
	author = {Hasselmo, Michael E and Giocomo, Lisa M and Zilli, Eric A},
	year = {2007},
	keywords = {Neurons, Animals, Computer Simulation, Time Factors, merged\_fiete.bib, Neurological, Brain Mapping, Models, Theta Rhythm, Dendrites, Membrane Potentials, Predictive Value of Tests},
	pages = {1252--1271},
}

@article{stensola_entorhinal_2012,
	title = {The entorhinal grid map is discretized},
	volume = {492},
	abstract = {The medial entorhinal cortex (MEC) is part of the brain's circuit for dynamic representation of self-location. The metric of this representation is provided by grid cells, cells with spatial firing fields that tile environments in a periodic hexagonal pattern. Limited anatomical sampling has obscured whether the grid system operates as a unified system or a conglomerate of independent modules. Here we show with recordings from up to 186 grid cells in individual rats that grid cells cluster into a small number of layer-spanning anatomically overlapping modules with distinct scale, orientation, asymmetry and theta-frequency modulation. These modules can respond independently to changes in the geometry of the environment. The discrete topography of the grid-map, and the apparent autonomy of the modules, differ from the graded topography of maps for continuous variables in several sensory systems, raising the possibility that the modularity of the grid map is a product of local self-organizing network dynamics.},
	number = {7427},
	journal = {Nature},
	author = {Stensola, H and Stensola, T and Solstad, T and Fröland, K and Moser, M and Moser, E},
	month = dec,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {72--78},
}

@article{mhatre_grid_2010,
	title = {Grid cell hexagonal patterns formed by fast self-organized learning within entorhinal cortex},
	volume = {22},
	abstract = {Grid cells in the dorsal segment of the medial entorhinal cortex (dMEC) show remarkable hexagonal activity patterns, at multiple spatial scales, during spatial navigation. It has previously been shown how a self-organizing map can convert firing patterns across entorhinal grid cells into hippocampal place cells that are capable of representing much larger spatial scales. Can grid cell firing fields also arise during navigation through learning within a self-organizing map? This article describes a simple and general mathematical property of the trigonometry of spatial navigation which favors hexagonal patterns. The article also develops a neural model that can learn to exploit this trigonometric relationship. This GRIDSmap self-organizing map model converts path integration signals into hexagonal grid cell patterns of multiple scales. GRIDSmap creates only grid cell firing patterns with the observed hexagonal structure, predicts how these hexagonal patterns can be learned from experience, and can process biologically plausible neural input and output signals during navigation. These results support an emerging unified computational framework based on a hierarchy of self-organizing maps for explaining how entorhinal-hippocampal interactions support spatial navigation. {\textbackslash}copyright 2010 Wiley-Liss, Inc.},
	journal = {Hippocampus},
	author = {Mhatre, Himanshu and Gorchetchnikov, Anatoli and Grossberg, Stephen},
	month = dec,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {320--334},
}

@article{aksay_anatomy_2000,
	title = {Anatomy and discharge properties of pre-motor neurons in the goldfish medulla that have eye-position signals during fixations},
	volume = {84},
	abstract = {Previous work in goldfish has suggested that the oculomotor velocity-to-position neural integrator for horizontal eye movements may be confined bilaterally to a distinct group of medullary neurons that show an eye-position signal. To establish this localization, the anatomy and discharge properties of these position neurons were characterized with single-cell Neurobiotin labeling and extracellular recording in awake goldfish while monitoring eye movements with the scleral search-coil method. All labeled somata (n = 9) were identified within a region of a medially located column of the inferior reticular formation that was approximately 350 microm in length, approximately 250 microm in depth, and approximately 125 microm in width. The dendrites of position neurons arborized over a wide extent of the ventral half of the medulla with especially heavy ramification in the initial 500 microm rostral of cell somata (n = 9). The axons either followed a well-defined ventral pathway toward the ipsilateral abducens (n = 4) or crossed the midline (n = 2) and projected toward the contralateral group of position neurons and the contralateral abducens. A mapping of the somatic region using extracellular single unit recording revealed that position neurons (n {\textgreater} 120) were the dominant eye-movement-related cell type in this area. Position neurons did not discharge below a threshold value of horizontal fixation position of the ipsilateral eye. Above this threshold, firing rates increased linearly with increasing temporal position [mean position sensitivity = 2.8 (spikes/s)/ degrees, n = 44]. For a given fixation position, average rates of firing were higher after a temporal saccade than a nasal one (n = 19/19); the magnitude of this hysteresis increased with increasing position sensitivity. Transitions in firing rate accompanying temporal saccades were overshooting (n = 43/44), beginning, on average, 17.2 ms before saccade onset (n = 17). Peak firing rate change accompanying temporal saccades was correlated with eye velocity (n = 36/41). The anatomical findings demonstrate that goldfish medullary position neurons have somata that are isolated from other parts of the oculomotor system, have dendritic fields overlapping with axonal terminations of neurons with velocity signals, and have axons that are capable of relaying commands to the abducens. The physiological findings demonstrate that the signals carried by position neurons could be used by motoneurons to set the fixation position of the eye. These results are consistent with a role for position neurons as elements of the velocity-to-position neural integrator for horizontal eye movements.},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Aksay, E and Baker, R and Seung, H S and Tank, D W},
	month = aug,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1035--1049},
}

@article{liu_variability_1999,
	title = {Variability of {Neurotransmitter} {Concentration} and {Nonsaturation} of {Postsynaptic} {AMPA} {Receptors} at {Synapses} in {Hippocampal} {Cultures} and {Slices}},
	volume = {22},
	abstract = {To understand the elementary unit of synaptic communication between CNS neurons, one must know what causes the variability of quantal postsynaptic currents and whether unitary packets of transmitter saturate postsynaptic receptors. We studied single excitatory synapses between hippocampal neurons in culture. Focal glutamate application at individual postsynaptic sites evoked currents (Iglu) with little variability compared with quantal excitatory postsynaptic currents (EPSCs). The maximal Iglu was 2-fold larger than the median EPSC. Thus, variations in [glu]cleft are the main source of variability in EPSC size, and glutamate re-ceptors are generally far from saturation during quantal transmission. This conclusion was verified by molecular antagonism experiments in hippocampal cultures activity-and slices. The general lack of glutamate receptor saturation leaves room for increases in [glu]cleft as a mechanism for synaptic plasticity.},
	journal = {Neuron},
	author = {Liu, Guogsong and Choi, Sukwoo and Tsien, Richard W},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {395--409},
}

@article{markram_differential_1998,
	title = {Differential signaling via the same axon of neocortical pyramidal neurons},
	volume = {95},
	abstract = {The nature of information stemming from a single neuron and conveyed simultaneously to several hun-dred target neurons is not known. Triple and quadruple neuron recordings revealed that each synaptic connection established by neocortical pyramidal neurons is potentially unique. Specifically, synaptic connections onto the same mor-phological class differed in the numbers and dendritic loca-tions of synaptic contacts, their absolute synaptic strengths, as well as their rates of synaptic depression and recovery from depression. The same axon of a pyramidal neuron innervating another pyramidal neuron and an interneuron mediated frequency-dependent depression and facilitation, respectively, during high frequency discharges of presynaptic action po-tentials, suggesting that the different natures of the target neurons underlie qualitative differences in synaptic proper-ties. Facilitating-type synaptic connections established by three pyramidal neurons of the same class onto a single interneuron, were all qualitatively similar with a combination of facilitation and depression mechanisms. The time courses of facilitation and depression, however, differed for these convergent connections, suggesting that different pre-postsynaptic interactions underlie quantitative differences in synaptic properties. Mathematical analysis of the transfer functions of frequency-dependent synapses revealed supra-linear, linear, and sub-linear signaling regimes in which mixtures of presynaptic rates, integrals of rates, and deriva-tives of rates are transferred to targets depending on the precise values of the synaptic parameters and the history of presynaptic action potential activity. Heterogeneity of synap-tic transfer functions therefore allows multiple synaptic rep-resentations of the same presynaptic action potential train and suggests that these synaptic representations are regulated in a complex manner. It is therefore proposed that differential signaling is a key mechanism in neocortical information processing, which can be regulated by selective synaptic modifications.},
	journal = {Proc. Natl. Acad. Sci.},
	author = {Markram, Henry and Wang, Yun and Tsodyks, Misha},
	month = apr,
	year = {1998},
	keywords = {merged\_fiete.bib, facilitation and depression and synaptic and plasticity},
	pages = {5323--5328},
}

@article{schikorski_quantitative_1997,
	title = {Quantitative ultrastructural analysis of hippocampal excitatory synapses},
	volume = {17},
	abstract = {From three-dimensional reconstructions of CA1 excitatory synapses in the rodent hippocampus and in culture, we have estimated statistical distributions of active zone and postsynaptic density (PSD) sizes (average area approximately 0.04 micron2), the number of active zones per bouton (usually one), the number of docked vesicles per active zone (approximately 10), and the total number of vesicles per bouton (approximately 200), and we have determined relationships between these quantities, all of which vary from synapse to synapse but are highly correlated. These measurements have been related to synaptic physiology. In particular, we propose that the distribution of active zone areas can account for the distribution of synaptic release probabilities and that each active zone constitutes a release site as identified in the standard quantal theory attributable to Katz (1969).},
	number = {15},
	journal = {J. Neurosci.},
	author = {Schikorski, T and Stevens, C F},
	month = aug,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {5858--5867},
}

@article{ramckinney_miniature_1999,
	title = {Miniature synaptic events maintain dendritic spines via {AMPA} receptor activation},
	volume = {2},
	abstract = {We investigated the influence of synaptically released glutamate on postsynaptic structure by comparing the effects of deafferentation, receptor antagonists and blockers of glutamate release in hippocampal slice cultures. CA1 pyramidal cell spine density and length decreased after transection of Schaffer collaterals and after application of AMPA receptor antagonists or botulinum toxin to unlesioned cultures. Loss of spines induced by lesion or by botulinum toxin was prevented by simultaneous AMPA application. Tetrodotoxin did not affect spine density. Synaptically released glutamate thus exerts a trophic effect on spines by acting at AMPA receptors. We conclude that AMPA receptor activation by spontaneous vesicular glutamate release is sufficient to maintain dendritic spines.},
	number = {1},
	journal = {Nat. Neurosci.},
	author = {{R.A.McKinney} and {M.Capogna} and {R.Durr} and {B.H.Gahwiler} and {S.M.Thompson}},
	month = jan,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {44--49},
}

@article{takagi_effects_1998,
	title = {Effects of {Lesions} of the {Oculomotor} {Vermis} on {Eye} {Movements} in {Primate}: {Saccades}},
	volume = {80},
	abstract = {We studied the effects on saccades of ablation of the dorsal cerebellar vermis (lesions centered on lobules VI and VII) in three monkeys in which the deep cerebellar nuclei were spared. One animal, with a symmetrical lesion, showed bilateral hypometric horizontal saccades. Two animals, with asymmetrical lesions, showed hypometric ipsilateral saccades, and saccades to vertically positioned targets were misdirected, usually deviating away from the side to which horizontal saccades were hypometric. Postlesion, all animals showed an increase (2- to 5-fold) in trial-to-trial variability of saccade amplitude. They also showed a change in the ratio of the amplitudes of centripetal to centrifugal saccades (orbital-position effect); usually centrifugal saccades became smaller. In the two animals with asymmetrical lesions, for saccades in the hypometric direction, latencies were markedly increased (up to approximately 500 ms). There was also an absence of express and anticipatory saccades in the hypometric direction. When overall saccade latency was increased, centrifugal saccades became relatively more delayed than centripetal saccades. The dynamic characteristics of saccades were affected to some extent in all monkeys with changes in peak velocity, eye acceleration, and especially eye deceleration. There was relatively little effect of orbital position on saccade dynamics, however, with the exception of one animal that showed an orbital position effect for eye acceleration. In a double-step adaptation paradigm, animals showed an impaired ability to adaptively adjust saccade amplitude, though increased amplitude variability postlesion may have played a role in this deficit. During a single training session, however, the latency to corrective saccades-which had been increased postlesion-gradually decreased and so enabled the animal to reach the final position of the target more quickly. Overall, both in the early postlesion period and during recovery, changes in saccade amplitude and latency tended to vary together but not with changes in saccade dynamics or adaptive capability, both of which behaved relatively independently. These findings suggest that the cerebellum can adjust saccade amplitude and saccade dynamics independently. Our results implicate the cerebellar vermis directly in every aspect of the on-line control of saccades: initiation (latency), accuracy (amplitude and direction), and dynamics (velocity and acceleration) and also in the acquisition of adaptive ocular motor behavior.},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Takagi, Mineo and Zee, David S and Tamargo, Rafael J},
	month = oct,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {1911--1931},
}

@article{brody_relief_2000,
	title = {Relief of {G}-protein inhibition of calcium channels and short-term synaptic facilitation in cultured hippocampal neurons},
	volume = {20},
	abstract = {G-protein inhibition of voltage-gated calcium channels can be transiently relieved by repetitive physiological stimuli. Here, we provide evidence that such relief of inhibition contributes to short-term synaptic plasticity in microisland-cultured hippocampal neurons. With G-protein inhibition induced by the GABA(B) receptor agonist baclofen or the adenosine A1 receptor agonist 2-chloroadenosine, short-term synaptic facilitation emerged during action potential trains. The facilitation decayed with a time constant of approximately 100 msec. However, addition of the calcium channel inhibitor Cd(2+) at 2-3 microM had no such effect and did not alter baseline synaptic depression. As expected of facilitation from relief of channel inhibition, analysis of miniature EPSCs implicated presynaptic modulation, and elevating presynaptic Ca(2+) entry blunted the facilitation. Most telling was the near occlusion of synaptic facilitation after selective blockade of P/Q- but not N-type calcium channels. This was as predicted from experiments using recombinant calcium channels expressed in human embryonic kidney (HEK) 293 cells; we found significantly stronger relief of G-protein inhibition in recombinant P/Q- versus N-type channels during action potential trains. G-protein inhibition in HEK 293 cells was induced via recombinant M2 muscarinic acetylcholine receptors activated by carbachol, an acetylcholine analog. Thus, relief of G-protein inhibition appears to produce a novel form of short-term synaptic facilitation in cultured neurons. Similar short-term synaptic plasticity may be present at a wide variety of synapses, as it could occur during autoreceptor inhibition by glutamate or GABA, heterosynaptic inhibition by GABA, tonic adenosine inhibition, and in many other instances.},
	number = {3},
	journal = {J. Neurosci.},
	author = {Brody, D L and Yue, D T},
	month = feb,
	year = {2000},
	keywords = {merged\_fiete.bib, Autapse, short-term plasticity},
	pages = {889--898},
}

@article{boehm_presynaptic_1999,
	title = {Presynaptic alpha2-adrenoceptors control excitatory, but not inhibitory, transmission at rat hippocampal synapses},
	volume = {519},
	abstract = {1. The effects of noradrenaline on neurotransmission at rat hippocampal synapses were investigated by recording autaptic currents in single neurons isolated on glial microislands. Noradrenaline reduced excitatory, but not inhibitory, autaptic currents in a pertussis toxin-sensitive manner, but the amine did not affect glutamate-evoked currents. 2. The inhibition of excitatory autaptic currents by noradrenaline was half-maximal at 0. 11 +/- 0.06 microM. The alpha2-adrenoceptor agonists UK 14 304 and clonidine were equipotent to noradrenaline in reducing these currents, whereas the alpha1-adrenoceptor agonist methoxamine and the beta-adrenoceptor agonist isoprenaline (isoproterenol) were ineffective. The reduction of excitatory autaptic currents by noradrenaline was not altered by the alpha1-adrenergic antagonist urapidil or the beta-antagonist propranolol, but reduced by the alpha2-antagonist yohimbine. The subtype-preferring antagonists rauwolscine and phentolamine (both at 0.3 microM) caused 9-fold and 36-fold rightward shifts in the concentration-response curve for the noradrenaline-dependent reduction of excitatory autaptic currents, respectively. Prazosine (1 microM) did not affect this concentration-response curve. 3. Noradrenaline reduced voltage-activated Ca2+ currents in excitatory, but not in inhibitory, microisland neurons. For comparison, the GABAB agonist baclofen reduced both excitatory and inhibitory autaptic currents and diminished voltage-activated Ca2+ currents in both types of neurons. The inhibition of Ca2+ currents by noradrenaline was half-maximal at 0.17 +/- 0.05 microM, and UK 14 304 and clonidine were equipotent to noradrenaline in reducing these currents. The noradrenaline-induced reduction of Ca2+ currents was antagonized by yohimbine, but not by urapidil or propranolol; the subtype-preferring alpha2-adrenergic antagonists displayed the following rank order of activity: phentolamine {\textgreater} rauwolscine {\textgreater} prazosine. 4. Noradrenaline did not affect K+ currents and failed to alter the frequency of miniature excitatory postsynaptic currents measured in mass cultures of hippocampal neurons. 5. These results show that noradrenaline regulates transmission at glutamatergic, but not at GABAergic, hippocampal synapses via presynaptic alpha2-adrenoceptors of the alpha2A/D subtype. This inhibitory action involves an inhibition of voltage-activated Ca2+ currents, but no modulation of spontaneous vesicle exocytosis or of voltage-activated K+ currents.},
	number = {Part 2},
	journal = {J. Physiol.},
	author = {Boehm, S},
	month = sep,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {439--449},
}

@article{kimura_presynaptically_1997,
	title = {Presynaptically silent synapses: spontaneously active terminals without stimulus-evoked release demonstrated in cortical autapses},
	volume = {77},
	abstract = {This study addresses the question of whether synapses that are capable of releasing transmitters spontaneously can also release them in an excitation-dependent manner. For this purpose, whole cell patch recordings were performed for a total of 48 excitatory solitary neurons in a microisland culture to observe excitatory autaptic currents elicited by spontaneous transmitter release as well as by somatic excitation. A somatic Na+-spike, induced in response to a short voltage step, evoked excitatory postsynaptic currents (EPSCs) of various amplitudes through the autapses; in some cases, no response was noticeable. To make sure that the recorded autaptic spontaneous EPSCs (sEPSCs) under a voltage clamp resulted from independent release of transmitters and were not associated with action potentials, sEPSCS in the presence and absence of tetrodotoxin (TTX) were compared in six cells. In the presence of TTX the evoked EPSCs were completely eliminated, whereas the sEPSCs were still observed and the amplitude distribution histograms were statistically not different from those recorded in the absence of TTX. A quantitative analysis of the sEPSCs (presumably miniature EPSCs) showed that the amplitude of stimulus-evoked EPSCs did not correlate with either the frequency or median amplitudes of the sEPSCs or the age of the culture. To identify whether the absence of stimulus-evoked response was caused either by conduction failure of excitation along the axons or by impairment of the release machinery that links the terminal depolarization to vesicle exocytosis, we examined whether high K+ and hypertonic solutions could facilitate the spontaneous release of transmitters. Although the hypertonic solution increased the spontaneous release in all cells tested (n = 18), the high K+ solution had a differential effect in increasing spontaneous release, i.e., the cells with larger evoked responses were more readily facilitated by the high K+ solution. Because the high K+ solution induced depolarization of presynaptic terminals, the present results indicated that the smaller evoked responses were due to the larger number of impaired or “silent” presynaptic terminals that were unable to link presynaptic depolarization to transmitter release. In summary, the present experiments provided evidence that at least some of the presynaptic terminals are silent in response to stimuli, while remaining spontaneously active at the same time. Because this phenomenon is due to the lack of sensitivity to depolarization at the terminals, these synaptic terminals seem incapable of linking terminal depolarization to transmitter release.},
	number = {5},
	journal = {J. Neurophysiol.},
	author = {Kimura, F and Otsu, Y and Tsumoto, T},
	month = may,
	year = {1997},
	keywords = {merged\_fiete.bib, saccade fixation lesion},
	pages = {2805--2815},
}

@article{goda_long-term_1996,
	title = {Long-{Term} {Depression} {Properties} in a {Simple} {System}},
	volume = {16},
	abstract = {Long-term depression (LTD) in pairs of cultured rodent hippocampal neurons was examined to study the molecular basis of this form of synaptic plasticity. We have previously characterized two components of transmitter release: a synchronous, fast phase that requires synaptotagmin I, and an asynchronous, slow component that persists in the absence of synaptotagmin I. Are these two release components differentially affected by the presynaptic changes of LTD, or is the mechanism of plasticity common to both? We find that LTD is expressed as parallel changes in the fast and slow components of release, and that this form of synaptic plasticity is still seen in the absence of functional synaptotagmin I. Any alterations in the presynaptic release machinery observed during LTD thus involve mechanisms shared by both modes of release.},
	journal = {Neuron},
	author = {Goda, Yukiko and Stevens, Charles F},
	month = jan,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {103--111},
}

@article{mennerick_passive_1995,
	title = {Passive and synaptic properties of hippocampal neurons grown in microcultures and in mass cultures},
	volume = {73},
	abstract = {1. We used whole cell recordings to compare passive membrane properties and synaptic properties of postnatal rat hippocampal neurons grown for 7-15 days in either conventional mass cultures or on physically restricted microisland cultures. Despite matching microisland and mass culture cell across several variables, there were significant differences between neurons in the two groups regarding passive membrane characteristics and synaptic properties. 2. Microisland neurons displayed significantly faster charging of the membrane capacitance than mass culture counterparts matched with microisland neurons for age, somal diameter, and transmitter phenotype. When we used a two-compartment equivalent circuit model to quantify this result, microisland neurons displayed approximately half the distal capacitance of mass culture neurons. These data suggest that microisland neurons elaborate less extensive neuritic arborizations than mass culture neurons. 3. Evoked synaptic responses were enhanced on microislands compared with mass cultures. Excitatory and inhibitory autaptic currents were more frequent and displayed larger amplitudes on single-neuron microislands than in matched mass culture neurons. 4. In recordings from pairs of neurons in the two environments, we observed a significantly higher probability of obtaining a monosynaptic response on two-neuron microislands than in matched mass culture pairs (85\% vs. 42\%). Evoked excitatory postsynaptic currents were also significantly larger in the microisland environment, with evoked excitatory synaptic currents from two-neuron microislands exhibiting a mean amplitude 20-fold larger than mass culture monosynaptic responses. 5. The differences in evoked synaptic responses were not reflected in differences in the amplitude or frequency of spontaneous miniature excitatory postsynaptic currents (mEPSCs). Analysis of mEPSC rise times, decay times, and peak amplitudes within individual cells suggests that electrotonic filtering is not an important contributor to the variability of peak amplitudes and decay times of synaptic currents in cells of either culture environment. However, composite data across neurons in both cultures reveal a significant correlation between mEPSC rise and decay times. 6. Out results suggest that the microisland preparation may be a useful tool for exploring factors that influence synapse formation and development. Additionally, the preparation is a particularly convenient model for the study of single-neuron-mediated synaptic events.},
	number = {1},
	journal = {J. Neurophysiol.},
	author = {Mennerick, S and Que, J and Benz, A and Zorumski, C F},
	month = jan,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {320--332},
}

@article{murthy_reversal_1999,
	title = {Reversal of synaptic vesicle docking at central synapses},
	volume = {2},
	abstract = {We used quantitative fluorescence imaging of vesicles labeled with membrane-soluble dyes to determine rates of undocking and spontaneous exocytosis of vesicles docked to the active zone of hippocampal synapses in culture. Individual vesicles undock about once per two minutes and spontaneously exocytose about once per eight minutes. Thus, not only does undocking occur, but it is over threefold faster than spontaneous fusion.},
	number = {6},
	journal = {Nat. Neurosci.},
	author = {Murthy, V N and Stevens, C F},
	month = jun,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {503--507},
}

@article{taniguchi_actions_2000,
	title = {Actions of brain-derived neurotrophic factor on evoked and spontaneous {EPSCs} dissociate with maturation of neurones cultured from rat visual cortex},
	volume = {527},
	abstract = {1. To address the question of whether brain-derived neurotrophic factor (BDNF) directly enhances excitatorysynaptic transmission, we recorded excitatory postsynaptic currents (EPSCs) from solitary neurones cultured onglial microislands for 7-38 days, and observed changes in EPSCs after the application of BDNF. In this preparationthe possible action of BDNF on GABAergic inhibition was not involved, and evoked and spontaneous (miniature)EPSCs were derived from the same group of synapses (autapses).2. The application of BDNF at a concentration of 200 ng ml(-1) rapidly enhanced the frequency of miniatureEPSCs (mEPSCs) in almost all the neurones tested. On the other hand, the amplitude of mEPSCs did not change atall, suggesting that the site of BDNF action is presynaptic.3. In contrast to the enhanced frequency of mEPSCs, evoked EPSCs were not potentiated in 61\% of the cells tested.Most of these BDNF-insensitive EPSCs had a peak amplitude larger than 1 nA, while most of the otherBDNF-sensitive EPSCs had a smaller amplitude. The former EPSCs had smaller coefficients of variation (CVs) ofamplitude, while the latter had larger CVs, suggesting the possibility that the presynaptic release probability for theformer groups of EPSCs might have beeen saturated so that the BDNF action was occluded.4. To test, this possibility we applied a low Ca2+ solution to 17 cells and reduced the amplitude of their evokedEPSCs to less than or near to 1 nA. It was found, however, that BDNF did not enhance these EPSCs. Rather, evokedEPSCs of almost all the cells cultured for less than 15 days were enhanced by BDNF, while those of most of the cellscultured for longer than 16 days were not enhanced.5. These results suggest that BDNF enhances transmitter release from presynaptic sites through its action on therelease machinery, which can be differentiated into a BDNF-insensitive form for evoked release and aBDNF-sensitive form for spontaneous release with maturation of synapses.},
	number = {3},
	journal = {JOURNAL OF PHYSIOLOGY-LONDON},
	author = {Taniguchi, N and Takada, N and Kimura, F and Tsumoto, T},
	month = sep,
	year = {2000},
	keywords = {merged\_fiete.bib, BDNF KNOCKOUT MICE, CA1 REGION, HIPPOCAMPAL-NEURONS, LONG-TERM POTENTIATION, MICROCULTURES, MODULATION, PRESYNAPTICENHANCEMENT, SILENT SYNAPSES, SYNAPTICTRANSMISSION, TRUNCATED TRKB RECEPTORS},
	pages = {579--592},
}

@article{verderio_astrocytes_1999,
	title = {Astrocytes are required for the oscillatory activity in cultured hippocampal neurons},
	volume = {11},
	abstract = {Synchronous oscillations of intracellular calcium concentration ([Ca2+](i)) and of membrane potential occurred in alimited population of glutamatergic hippocampal neurons grown in primary cultures. The oscillatory activityoccurred in synaptically connected cells only when they were in the presence of astrocytes. Microculturescontaining only one or a few neurons also displayed oscillatory activity, provided that glial cells participated in thenetwork. The glutamate-transporter inhibitors L-trans-pyrrolidine-2,4-dicarboxylic acid (PDC) anddihydrokainate, which produce an accumulation of glutamate in the synaptic microenvironment, impaired theoscillatory activity. Moreover, in neurons not spontaneously oscillating, though in the presence of astrocytes,oscillations were induced by exogenous L-glutamate, but not by the stereoisomer D-glutamate, which is not takenup by glutamate transporters. These data demonstrate that astrocytes are essential for neuronal oscillatory activityand provide evidence that removal of glutamate from the synaptic environment is one of the major mechanisms bywhich glial cells allow the repetitive excitation of the postsynaptic cell.},
	number = {8},
	journal = {Eur. J. Neurosci.},
	author = {Verderio, C and Bacci, A and Coco, S and Pravettoni, E and Fumagalli, G and Matteoli, M},
	month = aug,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {2793--2800},
}

@article{bacci_synaptic_1999,
	title = {Synaptic and intrinsic mechanisms shape synchronous oscillations in hippocampal neurons in culture},
	volume = {11},
	abstract = {We have detected spontaneous, synchronous calcium oscillations, associated with variations in membrane potential, in hippocampal neurons maintained in primary culture. The oscillatory activity is synaptically driven, as it is blocked by tetrodotoxin, by the glutamate receptor antagonist 6-cyano-7-nitroquinoxaline-2,3-dione (CNQX) and by toxins inhibiting neurotransmitter release from presynaptic nerve endings. Neuronal oscillations do not require for their expression the presence of a polyneuronal network and are not primarily influenced by the gamma-aminobutyric acid (GABA(A)) receptor antagonist picrotoxin, suggesting that they entirely rely on glutamatergic neurotransmission. Synaptic and intrinsic conductances shape the synchronized oscillations in hippocampal neurons. The concomitant activation of N-methyl-D-aspartate (NMDA) receptors and voltage-activated L-type calcium channels allows calcium entering from the extracellular medium and sustaining the long depolarization, which shapes every single calcium wave.},
	number = {2},
	journal = {Eur. J. Neurosci.},
	author = {Bacci, Alberto and Verderio, Claudia and Pravettoni, Elena and Matteoli, Michela},
	month = feb,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {389--397},
}

@article{sanchez-vives_cellular_2000,
	title = {Cellular and network mechanisms of rhythmic recurrent activity in neocortex},
	volume = {3},
	abstract = {The neocortex generates periods of recurrent activity, such as the slow (0.1-0.5 Hz) oscillation during slow-wave sleep. Here we demonstrate that slices of ferret neocortex maintained in vitro generate this slow ({\textless} 1 Hz) rhythm when placed in a bathing medium that mimics the extracellular ionic composition in situ. This slow oscillation seems to be initiated in layer 5 as an excitatory interaction between pyramidal neurons and propagates through the neocortex. Our results demonstrate that the cerebral cortex generates an 'up' or depolarized state through recurrent excitation that is regulated by inhibitory networks, thereby allowing local cortical circuits to enter into temporarily activated and self-maintained excitatory states. The spontaneous generation and failure of this self-excited state may account for the generation of a subset of cortical rhythms during sleep.},
	number = {10},
	journal = {Nat. Neurosci.},
	author = {Sanchez-Vives, V M and McCormick, D A},
	month = oct,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1027--1034},
}

@article{mettens_effect_1994,
	title = {Effect of {Muscimol} {Microinjections} {Into} the {Prepositus} {Hypoglossi} and the {Medial} {Vestibular} {Nuclei} on {Cat} {Eye} {Movements}},
	volume = {72},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Mettens, P and Godaux, E and Cheron, G and Galiana, H L},
	month = aug,
	year = {1994},
	keywords = {merged\_fiete.bib, MVN NPH neural integrator eye movement},
	pages = {785--802},
}

@article{hartwich-young_perihypoglossal_1990,
	title = {The {Perihypoglossal} {Projections} to the {Superior} {Colliculus} in the {Rhesus} {Monkey}},
	volume = {4},
	abstract = {The projections of the perihypoglossal(PH) complex to the SC in the rhesus monkey was investigated using the retrograde transport of wheat germ agglutinin conjugated to horseradish peroxidase (WGA-HRP). Following physiological identification by electrical stimulation and multiunit recording, small injections of the tracer were placed within the SC of three monkeys. THe largest numbers of retrogradely labeled neurons within the PH complex were found in the contralateral NPH, in the laterally adjacent MVN, and in the ventrally adjacent reticular formation (the nucleus reticularis supragigantocellularis). These labeled neurons are strikingly heterogeneous in size and morphology. The nuclei supragenualis and intercalatus also contain numerous labeled neurons in the 2 cases in which the injections involve the caudal SC. Large numbers of retrogradely neurons as well as anterogradely transported WGA-HRP are observed also throughtout the pontine and medullary reticular formation, including the midline raphe. The PH complex, particularly the NPH, is known to be involved in the coding of eye postition and has been hypothesized to be a critical component of the “neural integrator”. Our data demonstrate the existence of a robust projection from the PH complex to the contralateral SC in the rhesus monkey. This projections may serve as the anatomical substrate by which a corollary of eye postition could reach the SC. Such a signal is a prerequisite for the computation, at the collicular level, of saccadic motor error signals observed in the SC of rhesus monkeys.},
	number = {1},
	journal = {Vis. Neurosci.},
	author = {Hartwich-Young, Rosi and Nelson, Jon S and Sparks, David L},
	month = jan,
	year = {1990},
	keywords = {merged\_fiete.bib, NPH and superior colliculus and agglutinin-horseradish peroxidase and saccadic motor error and eyeposition signal and neural integrator},
	pages = {29--42},
}

@article{m_discharge_1996,
	title = {Discharge properties of brain stem neurons projecting to the flocculus in the alert cat. {II}. {Prepositus} hypoglossal nucleus},
	volume = {76},
	abstract = {1. The aim of this study was to characterize the signals transmitted by the neurons of the nucleus prepositus hypoglossal (NPH) to the middle zone of the flocculus of the cat. The methods, the behavioral testing, and the animals used in this study were the same as those used in the accompanying paper on medial vestibular nucleus neurons. 2. The rostral two-thirds of the NPH was explored in alert animals with microelectrodes during stimulation of the middle zone of both flocculi. Discharges of neurons were analyzed during spontaneous eye movements (head fixed) and during horizontal vestibuloocular reflex (VOR) activity elicited by sinusoidal stimulation (10, 20, 30, or 40 degrees at 0.1 Hz). Forty neurons were found to be antidromically activated from only one or the other of the two flocculi (latency: 0.99 +/- 0.17 ms, mean +/- SD): 37 from the contralateral flocculus and 3 from the ipsilateral one. None of the neurons could be activated antidromically from both flocculi. Floccular stimulation never resulted in direct inhibition of these NPH neurons. 3. Of the 37 units antidromically activated from the contralateral flocculus, 26 were recorded sufficiently long to allow full quantitative analysis. Most of these (20 neurons) were classified as burst-tonic (BT) neurons. The BT neurons exhibited during each saccade made in one direction (the ON direction) a burst of spikes, and during postsaccadic fixation a tonic activity that increased with gaze displacement in the ON direction. The mean sensitivity of the neurons to eye velocity during the “ON” saccades was 3.3 +/- 1.6 spikes.s-1.deg-1.s-1. During intersaccadic fixation, the mean sensitivity to eye position was 3.6 +/- 2.5 spikes.s-1.deg-1. During the VOR, the majority showed modulation in relation to both eye position and eye velocity. The mean sensitivity to eye position during the VOR was 3.4 +/- 2.6 spikes.s-1.deg-1 (range: 0.2-8.1 spikes.s-1.deg-1). The mean sensitivity to eye velocity during the VOR was 2.1 +/- 1.3 spikes.s-1.deg-1.s-1. The mean phase lead of with respect to eye position was 16.4 +/- 6.8 degrees (range: 6.0-28.9 degrees). Eighty percent of the BT neurons behaved as type I neurons. Forty-seven percent of the BT neurons also presented some head velocity sensitivity (1.48 +/- 0.6 spikes.s-1.deg-1.s-1, mean +/- SD). 4. Other NPH cells antidromically activated from the contralateral flocculus were classified in two groups: bidirectional burst (BB) neurons (n = 4) and burst-driving (BD) neurons (n = 2). The BB neurons were characterized by a burst discharge during every horizontal saccade or VOR quick phase, irrespective of the direction. The mean sensitivity of the BB neurons to eye velocity during saccades was 3.3 +/- 7.8 (SD) spikes.s-1.deg-1.s-1. Both BD neurons increased their firing rate during the slow VOR phases induced by an ipsilateral rotation (type I neurons) and exhibited high-frequency bursts in association with ipsilaterally directed quick phases. 5. The results indicate that the main projection of the NPH onto the middle zone of the flocculus comes from contralaterally located type I BT neurons. Signals transmitted in this path associate a high sensitivity for eye velocity with a high sensitivity for eye position. This type of input is consistent with the suggestion that the main function of the flocculus is to control the gain of downstream reflexes and to perform a fine adjustment of the gaze holding command. PMID: 8890291, UI: 97045233},
	number = {3},
	journal = {J. Neurophysiol.},
	author = {M, Escudero and G, Cheron and E., Godaux},
	month = sep,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {1775--1785},
}

@article{kumura_brain-derived_2000,
	title = {Brain-derived neurotrophic factor blocks long-term depression in solitary neurones cultured from rat visual cortex},
	volume = {524 Pt 1},
	abstract = {1. To address questions of whether long-term depression (LTD) in the visual cortex is expressed in pre- or postsynaptic sites, whether brain-derived neurotrophic factor (BDNF) exerts its LTD-blocking action without involvement of GABAergic inhibition, and whether the action of BDNF is pre- or postsynaptic, we observed excitatory postsynaptic currents (EPSCs) from solitary neurones cultured on glial microislands. In this preparation GABAergic inhibition is not involved and a group of synapses (autapses) which generate evoked EPSCs is thought to be the same as those generating spontaneous EPSCs. 2. A short depolarising voltage step to the soma generated Na+ spikes which were followed by autaptic EPSCs. When this somatic activation was paired with prolonged depolarisation for 100 ms to -30 mV and repeated at 1 Hz for 5 min, LTD was induced in all of the nine cells tested. Then, the frequency of spontaneous EPSCs decreased, but the amplitude did not change, suggesting that the site of LTD expression is presynaptic. 3. Application of BDNF at 50 ng ml-1 blocked the depression of evoked EPSCs and the decrease in the frequency of spontaneous EPSCs. An inhibitor for receptor tyrosine kinases, K252a, antagonised the action of BDNF, suggesting an involvement of BDNF receptors, TrkB. 4. These results suggest that BDNF prevents low-frequency inputs from inducing LTD of excitatory synaptic transmission through presynaptic mechanisms in the developing visual cortex.},
	journal = {J. Physiol.},
	author = {Kumura, E and Kimura, F and Taniguchi, N and Tsumoto, T},
	month = apr,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {195--204},
}

@article{reid_n-_1998,
	title = {N- and {P}/{Q}-type {Ca2}+ channels mediate transmitter release with a similar cooperativity at rat hippocampal autapses},
	volume = {18},
	abstract = {The relationship between extracellular Ca2+ concentration and EPSC amplitude was investigated at excitatory autapses on cultured hippocampal neurons. This relationship was steeply nonlinear, implicating the cooperative involvement of several Ca2+ ions in the release of each vesicle of transmitter. The cooperativity was estimated to be 3.1 using a power function fit and 3.3 using a Hill equation fit. However, simulations suggest that these values underestimate the true cooperativity. The role of different Ca2+ channel subtypes in shaping the Ca2+ dose-response relationship was studied using the selective Ca2+ channel blockers omega-agatoxin GIVA (omega-Aga), which blocks P/Q-type channels, and omega-conotoxin GVIA (omega-CTx), which blocks N-type channels. Both blockers broadened the dose-response relationship, and the Hill coefficient was reduced to 2.5 by omega-Aga and to 2.6 by omega-CTx. This broadening is consistent with a nonuniform distribution of Ca2+ channel subtypes across presynaptic terminals. The similar Hill coefficients in omega-Aga or omega-CTx suggest that there was no difference in the degree of cooperativity for transmitter release mediated via N- or P/Q-type Ca2+ channels. A model of the role of calcium in transmitter release is developed. It is based on a modified Dodge-Rahamimoff equation that includes a nonlinear relationship between extracellular and intracellular Ca2+ concentration, has a cooperativity of 4, and incorporates a nonuniform distribution of Ca2+ channel subtypes across presynaptic terminals. The model predictions are consistent with all of the results reported in this study.},
	number = {8},
	journal = {J. Neurosci.},
	author = {Reid, C A and Bekkers, J M and Clements, J D},
	month = apr,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {2849--2855},
}

@article{pan_nitric_1996,
	title = {Nitric oxide-related species inhibit evoked neurotransmission but enhance spontaneous miniature synaptic currents in central neuronal cultures},
	volume = {93},
	abstract = {Nitric oxide (NO.) does not react significantly with thiol groups under physiological conditions, whereas a variety of endogenous NO donor molecules facilitate rapid transfer to thiol of nitrosonium ion (NO+, with one less electron than NO.). Here, nitrosonium donors are shown to decrease the efficacy of evoked neurotransmission while increasing the frequency of spontaneous miniature excitatory postsynaptic currents (mEPSCs). In contrast, pure NO donors have little effect (displaying at most only a slight increase) on the amplitude of evoked EPSCs and frequency of spontaneous mEPSCs in our preparations. These findings may help explain heretofore paradoxical observations that the NO moiety can either increase, decrease, or have no net effect on synaptic activity in various preparations.},
	number = {26},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Pan, Z H and Segal, M M and Lipton, S A},
	month = dec,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {15423--15428},
}

@article{cheron_discharge_1996,
	title = {Discharge properties of brain stem neurons projecting to the flocculus in the alert cat. {I}. {Medical} vestibular nucleus},
	volume = {76},
	abstract = {1. The aim of this study was to characterize the signals transmitted by neurons of the medial vestibular nucleus (MVN) to the middle zone of the flocculus in alert cats. 2. Bipolar stimulating electrodes were implanted into the middle zone of each flocculus, because this zone is known to be involved in the control of horizontal eye movements. Correct implantation of the stimulating electrodes was ensured by 1) recording of Purkinje cells whose activity was related to horizontal eye movements and 2) elicitation of slow abduction of the ipsilateral eye upon electrical stimulation. 3. The rostral two-thirds of the MVN were investigated by microelectrodes during stimulation of both flocculi. Antidromically activated neurons were found only in the central part of the explored area. Forty-four units were activated from the contralateral, eight from the ipsilateral flocculus. Neurons could never be activated from both flocculi. 4. Neurons included in this study were MVN neurons that had 1) to be antidromically activated from one flocculus and 2) to modulate their firing rate during the horizontal vestibuloocular reflex (VOR) elicited by sinusoidal stimulation (0.1 Hz; 10, 20, 30 or 40 degrees). The 39 neurons matching both criteria were classified in 2 groups: 22 neurons changed their firing rate during spontaneous horizontal eye movements (EM-neurons), 17 modulated their activity only during head rotation and were labeled vestibular-only neurons (VO-neurons). 5. Sufficient data were obtained from 13 EM-neurons to allow a quantitative analysis. Among those, 12 were activated from the contralateral and 1 from the ipsilateral flocculus. Their sensitivity to horizontal eye position during intersaccadic fixation was 3.54 +/- 2.75 (SD) spikes.s-1/deg. Eight EM-neurons behaved as type I neurons, five as type II neurons. During the slow phases of the VOR, all of these neurons combined some head-velocity sensitivity (1.50 +/- 0.43 spikes.s-1/deg.s-1) with some horizontal eye-position sensitivity (3.61 +/- 2.45 spikes.s-1/deg). Additionally, seven of these neurons presented a sensitivity to eye velocity (1.34 +/- 0.55 spikes.s-1/deg.s-1). The phase difference between the modulation of firing rate and eye position varied substantially between neurons. The observed phase lead with respect to eye position ranged from 2 to 110 degrees (41.9 +/- 31.8 degrees). 6. Sufficient data were obtained from 10 VO-neurons to allow a quantitative analysis. Among those, nine were activated from the contralateral and one from the ipsilateral flocculus. All of these neurons behaved as type I neurons. The sensitivity to head velocity was 1.64 +/- 1.07 spikes.s-1/deg.s-1. The phase lead of the modulation of spike activity with respect to head velocity ranged from 4.5 to 30.5 degrees (16.4 +/- 8.9 degrees). 7. We conclude that the MVN provides the horizontal zone of the flocculus (with a strong contralateral preference) with information about head velocity (through VO-neurons and EM-neurons) and about eye velocity and position (through EM-neurons).},
	number = {3},
	journal = {J. Neurophysiol.},
	author = {Cheron, G and Escudero, M and Godaux, E},
	month = sep,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {1759--1774},
}

@article{sherwood_long-term_1999,
	title = {Long-term enhancement of central synaptic transmission by chronic brain-derived neurotrophic factor treatment},
	volume = {19},
	abstract = {Acute effects of neurotrophins on synaptic plasticity have recently received much attention, but the roles of these factors in regulating long-lasting changes in synaptic function remain unclear. To address this issue we studied the long-term (days to weeks) and short-term (minutes to hours) effects of brain-derived neurotrophic factor (BDNF) on excitatory synaptic transmission in autaptic cultures of hippocampal CA1 neurons. We found that BDNF induced long-term enhancement of the strength of non-NMDA receptor-mediated glutamatergic transmission. This upregulation of EPSC amplitude occurred via an increase in the size of unitary synaptic currents, with no significant contribution from other aspects of neuronal electrical and synaptic function including cell size, voltage-gated sodium and potassium current levels, the number and size of synaptic contacts, and the frequency of spontaneous neurotransmitter release. Chronic BDNF treatment also decreased the degree of synaptic depression measured in response to paired stimuli. Thus, BDNF induced long-term synaptic enhancement of both basal and use-dependent synaptic transmission via specific changes to the synapse rather than through generalized potentiation of neuronal growth and differentiation. Finally, we showed that the long-term effects of BDNF are functionally and mechanistically distinct from its acute effects on synaptic transmission, suggesting that, in vivo, BDNF activation of Trk receptors can have different functional effects depending on the time course of its action.},
	number = {16},
	journal = {J. Neurosci.},
	author = {Sherwood, N T and Lo, D C},
	month = aug,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {7025--7036},
}

@article{sudhof_synaptic_2000,
	title = {The synaptic {VesicleCycle} revisited},
	volume = {28},
	abstract = {Howard Hughes Medical Institute The Center for Basic Neuroscience and Department of Molecular Genetics The University of Texas Southwestern Medical School 6000 Harry Hines Boulevard NA4.118 75390, Dallas, TX, USA.},
	number = {2},
	journal = {Neuron},
	author = {Sudhof, T C},
	month = nov,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {317--320},
}

@article{waters_phorbol_2000,
	title = {Phorbol esters potentiate evoked and spontaneous release by different presynaptic mechanisms},
	volume = {20},
	abstract = {Phorbol esters enhance release from a variety of cell types. The mechanism by which phorbol esters potentiate presynaptic release from central neurons is unclear, although effects of phorbol esters both on the readily releasable pool of vesicles and on presynaptic calcium channels have been shown. Using confocal microscopy and the fluorescent styryl dye FM 1-43, we have examined the effects of phorbol-12,13-dibutyrate (PDBu) on presynaptic vesicle turnover at individually identified synapses in dissociated cultures obtained from neonatal rat hippocampus. Using different dye staining and destaining protocols we were able to resolve two effects of PDBu. Potentiation of evoked release by PDBu was insensitive to calcium channel antagonists, suggesting that this effect results from an increased number of vesicles in the readily releasable pool. Since we observed no effect of PDBu on the size of the total recycling vesicle pool, we conclude that phorbol esters alter the equilibrium between reserve and readily releasable pools. An additional effect of PDBu on spontaneous release was observed. This effect was antagonized by nifedipine but not omega-conotoxin GVIA or omega-agatoxin IVA. We conclude that PDBu influences spontaneous and evoked release by two different mechanisms: through L-type calcium channels and through an increase in the proportion of recycling vesicles in the readily releasable pool. In addition to further clarifying the mechanism of action of phorbol esters, these results suggest that phorbol esters may be a useful tool with which to probe the function of the readily releasable pool of presynaptic vesicles at CNS synapses.},
	number = {21},
	journal = {J. Neurosci.},
	author = {Waters, J and Smith, S J},
	month = nov,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {7863--7870},
}

@article{prange_correlation_1999,
	title = {Correlation of miniature synaptic activity and evoked release probability in cultures of cortical neurons},
	volume = {19},
	abstract = {Spontaneous miniature synaptic activity is caused by action potential (AP)-independent release of transmitter vesicles and is regulated at the level of single synapses. In cultured cortical neurons we have used this spontaneous vesicle turnover to load the styryl dye FM1-43 into synapses with high rates of miniature synaptic activity. Automated selection procedures restricted analysis to synapses with sufficient levels of miniature activity-mediated FM1-43 uptake. After FM1-43 loading, vesicular FM1-43 release in response to AP stimulation was recorded at single synapses as a measure of release probability. We find that synapses with high rates of miniature activity possess significantly enhanced evoked release rates compared with a control population. Because the difference in release rates between the two populations is [Ca(2+)](o)-dependent, it is most likely caused by a difference in release probability. Within the subpopulation of synapses with high miniature activity, we find that the probabilities for miniature and AP-evoked release are correlated at single synaptic sites. Furthermore, the degree of miniature synaptic activity is correlated with the vesicle pool size. These findings suggest that both evoked and miniature vesicular release are regulated in parallel and that the frequency of miniature synaptic activity can be used as an indicator for evoked release efficacy.},
	number = {15},
	journal = {J. Neurosci.},
	author = {Prange, O and Murphy, T H},
	month = aug,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {6427--6438},
}

@article{mccormick_brain_2001,
	title = {Brain calculus: neural integration and persistent activity},
	volume = {4 no 2},
	abstract = {Tank and colleagues make in vivo intracellular recordings from neurons in a neural integrator of the goldfish involved in maintaining eye position. In this circuit, working memory may be the result of persistent changes in the state of the local network.},
	number = {2},
	journal = {Nat. Neurosci.},
	author = {McCormick, David A},
	month = feb,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {113--115},
}

@article{fee_role_1998,
	title = {The role of nonlinear dynamics of the syrinx in the vocalizations of a songbird},
	volume = {395},
	abstract = {Birdsong is characterized by the modulation of sound properties over a wide range of timescales. Understanding the mechanisms by which the brain organizes this complex temporal behaviour is a central motivation in the study of the song control and learning system. Here we present evidence that, in addition to central neural control, a further level of temporal organization is provided by nonlinear oscillatory dynamics that are intrinsic to the avian vocal organ. A detailed temporal and spectral examination of song of the zebra finch (Taeniopygia guttata) reveals a class of rapid song modulations that are consistent with transitions in the dynamical state of the syrinx. Furthermore, in vitro experiments show that the syrinx can produce a sequence of oscillatory states that are both spectrally and temporally complex in response to the slow variation of respiratory or syringeal parameters. As a consequence, simple variations in a small number of neural signals can result in a complex acoustic sequence.},
	journal = {Nature},
	author = {Fee, M S and Shraiman, B and Pesaran, B and Mitra, P P},
	month = sep,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {67--71},
}

@article{goldin_functional_2001,
	title = {Functional {Plasticity} {Triggers} {Formation} and {Pruning} of {Dendritic} {Spines} in {Cultured} {Hippocampal} {Networks}},
	volume = {21},
	abstract = {Despite widespread interest in dendritic spines, little is known about the mechanisms responsible for spine formation, retraction, or stabilization. We have now found that a brief exposure of cultured hippocampal neurons to a conditioning medium that favors activation of the NMDA receptor produces long-term modification of their spontaneous network activity. The conditioning protocol enhances correlated activity of neurons in the culture, in a process requiring an increase in [Ca(2+)](i) and is associated with both formation of novel dendritic spines and pruning of others. The novel spines are likely to be touched by a presynaptic terminal, labeled with FM4-64 dye, whereas the absence of such terminals increases the likelihood of spine pruning. These results indicate that long-term functional changes are correlated with morphological modifications of dendritic spines of neurons in a network.},
	number = {1},
	journal = {J. Neurosci.},
	author = {Goldin, M and Segal, M and Avignone, E},
	month = jan,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {186--193},
}

@article{graziano_coding_1997,
	title = {Coding the locations of objects in the dark},
	volume = {277},
	abstract = {The ventral premotor cortex in primates is thought to be involved in sensory-motor integration. Many of its neurons respond to visual stimuli in the space near the arms or face. In this study on the ventral premotor cortex of monkeys, an object was presented within the visual receptive fields of individual neurons, then the lights were turned off and the object was silently removed. A subset of the neurons continued to respond in the dark as if the object were still present and visible. Such cells exhibit “object permanence,” encoding the presence of an object that is no longer visible. These cells may underlie the ability to reach toward or avoid objects that are no longer directly visible.},
	number = {5323},
	journal = {Science},
	author = {Graziano, M S and Hu, X T and Gross, C G},
	month = jul,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {239--241},
}

@article{kamioka_spontaneous_1996,
	title = {Spontaneous periodic synchronized bursting during formation of mature patterns of connections in cortical cultures},
	volume = {206},
	abstract = {Long-term recording of spontaneous activity in cultured cortical neuronal networks was carried out using substrates containing multi-electrode arrays. Spontaneous uncorrelated firing appeared within the first 3 days and transformed progressively into synchronized bursting within a week. By 30 days from the establishment of the culture, the network exhibited a complicated non-periodic, synchronized activity pattern which showed no changes for more than 2 months and thus represented the mature state of the network. Pharmacological inhibition of activity only during the period when regular synchronized bursting was observed was capable of producing a different mature activity pattern from the control. These results suggest that periodic synchronized bursting plays a critical role in the development of synaptic connections.},
	number = {2-3},
	journal = {Neurosci. Lett.},
	author = {Kamioka, H and Maeda, E and Jimbo, Y and Robinson, H P and Kawana, A},
	month = mar,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {109--112},
}

@article{la_l_analytical_1996,
	title = {Analytical characterization of spontaneous activity evolution during hippocampal development in the rabbit},
	volume = {218},
	abstract = {We have analyzed the postnatal evolution of the spontaneous electrical activity in pyramidal neurons from rabbit hippocampal slices. The firing mode of CA1 neurons changes from bursting to regular spiking along the first postnatal month. Interspike intervals (ISIs) were used to account for the dynamical structure of the firing behavior. Histograms and joint interval scattergrams show that the firing mode from (P0-P7) cells has a different distribution from that obtained in (P15-P25) neurons. We have used a mathematical measure called the product of inertia to quantify this difference. Our findings demonstrate that the spontaneous activity changes along the maturational process.},
	number = {3},
	journal = {Neurosci. Lett.},
	author = {la L, de Menendez Prida and Bolea, S and Andres, Sanchez-Jv},
	month = nov,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {185--187},
}

@article{murthy_heterogeneous_1997,
	title = {Heterogeneous release properties of visualized individual hippocampal synapses},
	volume = {18},
	abstract = {We have used endocytotic uptake of the styryl dye FM1-43 at synaptic terminals (Betz and Bewick, 1992) to study properties of individual synapses formed by axons of single hippocampal neurons in tissue culture. The distribution of values for probability of evoked transmitter release p estimated by dye uptake is continuous, with a preponderance of low p synapses and a broad spread of probabilities. We have validated this method by demonstrating that the optically estimated distribution of p at autapses in single-neuron microislands predicts, with no free parameters, the rate of blocking of NMDA responses by the noncompetitive antagonist MK-801 at the same synapses. Different synapses made by a single axon exhibited varying amounts of paired-pulse modulation; synapses with low p tended to be facilitated more than those with high p. The increment in release probability produced by increasing external calcium ion concentration also depended on a synapse's initial p value. The size of the recycling pool of vesicles was strongly correlated with p as well, suggesting that synapses with higher release probabilities had more vesicles. Finally, p values of neighboring synapses were correlated, indicating local interactions in the dendrite or axon, or both.},
	number = {4},
	journal = {Neuron},
	author = {Murthy, V N and Sejnowski, T J and Stevens, C F},
	month = apr,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {599--612},
}

@article{zheng_functional_1999,
	title = {Functional selection of adaptive auditory space map by {GABAA}-mediated inhibition},
	volume = {284},
	abstract = {The external nucleus of the inferior colliculus in the barn owl contains an auditory map of space that is based on the tuning of neurons for interaural differences in the timing of sound. In juvenile owls, this region of the brain can acquire alternative maps of interaural time difference as a result of abnormal experience. It has been found that, in an external nucleus that is expressing a learned, abnormal map, the circuitry underlying the normal map still exists but is functionally inactivated by inhibition mediated by gamma-aminobutyric acid type A (GABAA) receptors. This inactivation results from disproportionately strong inhibition of specific input channels to the network. Thus, experience-driven changes in patterns of inhibition, as well as adjustments in patterns of excitation, can contribute critically to adaptive plasticity in the central nervous system.},
	number = {5416},
	journal = {Science},
	author = {Zheng, W and Knudsen, E I},
	month = may,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {962--965},
}

@article{zhang_critical_1998,
	title = {A critical window for cooperation and competition among developing retinotectal synapses},
	volume = {395},
	abstract = {In the developing frog visual system, topographic refinement of the retinotectal projection depends on electrical activity. In vivo whole-cell recording from developing Xenopus tectal neurons shows that convergent retinotectal synapses undergo activity-dependent cooperation and competition following correlated pre- and postsynaptic spiking within a narrow time window. Synaptic inputs activated repetitively within 20 ms before spiking of the tectal neuron become potentiated, whereas subthreshold inputs activated within 20 ms after spiking become depressed. Thus both the initial synaptic strength and the temporal order of activation are critical for heterosynaptic interactions among convergent synaptic inputs during activity-dependent refinement of developing neural networks.},
	number = {6697},
	journal = {Nature},
	author = {Zhang, L I and Tao, H W and Holt, C E and Harris, W A and Poo, M},
	month = sep,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {37--44},
}

@article{turrigiano_activity-dependent_1998,
	title = {Activity-dependent scaling of quantal amplitude in neocortical neurons},
	volume = {391},
	abstract = {Information is stored in neural circuits through long-lasting changes in synaptic strengths. Most studies of information storage have focused on mechanisms such as long-term potentiation and depression (LTP and LTD), in which synaptic strengths change in a synapse-specific manner. In contrast, little attention has been paid to mechanisms that regulate the total synaptic strength of a neuron. Here we describe a new form of synaptic plasticity that increases or decreases the strength of all of a neuron's synaptic inputs as a function of activity. Chronic blockade of cortical culture activity increased the amplitude of miniature excitatory postsynaptic currents (mEPSCs) without changing their kinetics. Conversely, blocking GABA (gamma-aminobutyric acid)-mediated inhibition initially raised firing rates, but over a 48-hour period mESPC amplitudes decreased and firing rates returned to close to control values. These changes were at least partly due to postsynaptic alterations in the response to glutamate, and apparently affected each synapse in proportion to its initial strength. Such 'synaptic scaling' may help to ensure that firing rates do not become saturated during developmental changes in the number and strength of synaptic inputs, as well as stabilizing synaptic strengths during Hebbian modification and facilitating competition between synapses.},
	number = {6670},
	journal = {Nature},
	author = {Turrigiano, G G and Leslie, K R and Desai, N S and Rutherford, L C and Nelson, S B},
	month = feb,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {892--896},
}

@article{morales_actin-dependent_2000,
	title = {Actin-dependent regulation of neurotransmitter release at central synapses},
	volume = {27},
	abstract = {Depolymerization of actin by latrunculin A transiently promotes neurotransmitter release. The mean rate of mEPSCs increases by a Ca2+-independent process, without a concomitant change in the mean amplitude. The readily releasable vesicle pool size and the rate of refilling of the readily releasable pool remain unaltered by latrunculin treatment. Evoked neurotransmitter release also increases in a manner consistent with an increase in vesicle release probability. The observed enhancement of neurotransmitter release is specific to actin depolymerization mediated by latrunculin A and is not caused by cytochalasin D. Our findings indicate that actin participates in a regulatory mechanism that restrains fusion of synaptic vesicles at the active zone.},
	number = {3},
	journal = {Neuron},
	author = {Morales, M and Colicos, M A and Goda, Y},
	month = sep,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {539--550},
}

@article{treue_attentional_1996,
	title = {Attentional modulation of visual motion processing in cortical areas {MT} and {MST}},
	volume = {382},
	abstract = {The visual system is constantly inundated with information received by the eyes, only a fraction of which seems to reach visual awareness. This selection process is one of the functions ascribed to visual attention. Although many studies have investigated the role of attention in shaping neuronal representations in the visual cortex, few have focused on attentional modulation of neuronal signals related to visual motion. Here we report that the responses of direction-selective neurons in monkey visual cortex are greatly influenced by attention, and that this modulation occurs as early in the cortical hierarchy as the level of the middle temporal visual area (MT). Our finding demonstrates a stronger and earlier influence of attention on motion processing along the dorsal visual pathway than previously recognized.},
	number = {6591},
	journal = {Nature},
	author = {Treue, S and Maunsell, J H},
	month = aug,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {539--541},
}

@article{cannon_loss_1987,
	title = {Loss of the neural integrator of the oculomotor system from brain stem lesions in monkey},
	volume = {57},
	number = {5},
	journal = {J. Neurophysiol.},
	author = {Cannon, C and Robinson, D A},
	month = may,
	year = {1987},
	keywords = {merged\_fiete.bib},
	pages = {1383--1409},
}

@article{treue_effects_1999,
	title = {Effects of attention on the processing of motion in macaque middle temporal and medial superior temporal visual cortical areas},
	volume = {19},
	abstract = {The visual system is continually inundated with information received by the eyes. Only a fraction of this information appears to reach visual awareness. This process of selection is one of the functions ascribed to visual attention. Although many studies have investigated the role of attention in shaping neuronal representations in cortical areas, few have focused on attentional modulation of neuronal signals related to visual motion. We recorded from 89 direction-selective neurons in middle temporal (MT) and medial superior temporal (MST) visual cortical areas of two macaque monkeys using identical sensory stimulation under various attentional conditions. Neural responses in both areas were greatly influenced by attention. When attention was directed to a stimulus inside the receptive field of a neuron, responses in MT and MST were enhanced an average of 20 and 40\% compared with a condition in which attention was directed outside the receptive field. Even stronger average enhancements (70\% in MT and 100\% in MST) were observed when attention was switched from a stimulus moving in the nonpreferred direction inside the receptive field to another stimulus in the receptive field that was moving in the preferred direction. These findings show that attention modulates motion processing from stages early in the dorsal visual pathway by selectively enhancing the representation of attended stimuli and simultaneously reducing the influence of unattended stimuli.},
	number = {17},
	journal = {J. Neurosci.},
	author = {Treue, S and Maunsell, J H},
	month = sep,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {7591--7602},
}

@article{anderson_stimulus_2000,
	title = {Stimulus dependence of two-state fluctuations of membrane potential in cat visual cortex},
	volume = {3},
	abstract = {Membrane potentials of cortical neurons fluctuate between a hyperpolarized ('down') state and a depolarized ('up') state which may be separated by up to 30 mV, reflecting rapid but infrequent transitions between two patterns of synaptic input. Here we show that such fluctuations may contribute to representation of visual stimuli by cortical cells. In complex cells of anesthetized cats, where such fluctuations are most prominent, prolonged visual stimulation increased the probability of the up state. This probability increase was related to stimulus strength: its dependence on stimulus orientation and contrast matched each cell's averaged membrane potential. Thus large fluctuations in membrane potential are not simply noise on which visual responses are superimposed, but may provide a substrate for encoding sensory information.},
	number = {6},
	journal = {Nat. Neurosci.},
	author = {Anderson, J and Lampl, I and Carandini, M and Ferster, D},
	month = jun,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {617--621},
}

@article{marsh_normal_1997,
	title = {Normal and adapted visuooculomotor reflexes in goldfish},
	volume = {77},
	abstract = {Under normal physiological conditions, whole field visual motion generally occurs in response to either active or passive self-motion. In the laboratory, selective movement of the visual surround produces an optokinetic response (OKR) that acts primarily to support the vestibuloocular reflex (VOR). During visual world motion, however, the OKR can be viewed as operating independently over frequency and amplitude ranges insufficient for vestibular activation. The goal of the present study was to characterize this isolated behavior of the OKR in goldfish as an essential step for studying central neuronal correlates of visual-vestibular interactions and the mechanisms underlying oculomotor adaptation. After presentation of either binocular sinusoidal or step visual stimuli, conjugate eye movements were elicited with an amplitude and phase profile similar to that of other vertebrates. An early and a delayed component were measured with different dynamics that could be altered independently by visual training. The ensuing visuomotor plasticity was robust and exhibited five major characteristics. First, the gain of both early and delayed components of the OKR increased {\textgreater} 100\%. Second, eye velocity decreased 0.5-2.0 s before the change in direction of stimulus velocity. Third, on lengthening the duration of a constant velocity visual stimulus (e.g., from 8 to 16 s), eye velocity decreased toward 0 degrees/s. This behavior was correlated with the direction and period as opposed to the frequency of the visual stimulus (“period tuning”). Fourth, visual stimulus training increased VOR eye velocity with a ratio of 0.6 to 1 to that measured for the OKR. Fifth, the OKR adaptation, eye velocity consistently oscillated in a conjugate, symmetrical fashion at 2.4 Hz in the light, whereas in the dark, a rhythmical low-amplitude eye velocity occurred at the visual training frequency. We conclude that the frequency and amplitude of visual stimuli for eliciting the goldfish OKR are well suited for complementing the VOR. Unlike most mammals, OKR adaptive modifications significantly alter VOR gain, whereas the effects of VOR training are much less on OKR gain. These observations suggest that both distributed circuits and discrete neuronal populations control visuo- and vestibulomotor performance. Finally, the existence of a rhythmic, “period tuned” visuomotor behavior provides a unique opportunity to examine the neuronal mechanisms of adaptive plasticity.},
	number = {3},
	journal = {J. Neurophysiol.},
	author = {Marsh, E and Baker, R},
	month = mar,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {1099--1118},
}

@article{prida_nonlinear_1999,
	title = {Nonlinear frequency-dependent synchronization in the developing hippocampus},
	volume = {82},
	abstract = {Synchronous population activity is present both in normal and pathological conditions such as epilepsy. In the immature hippocampus, synchronous bursting is an electrophysiological conspicuous event. These bursts, known as giant depolarizing potentials (GDPs), are generated by the synchronized activation of interneurons and pyramidal cells via GABAA, N-methyl-D-aspartate, and AMPA receptors. Nevertheless the mechanism leading to this synchronization is still controversial. We have investigated the conditions under which synchronization arises in developing hippocampal networks. By means of simultaneous intracellular recordings, we show that GDPs result from local cooperation of active cells within an integration period prior to their onset. During this time interval, an increase in the number of excitatory postsynaptic potentials (EPSPs) takes place building up full synchronization between cells. These EPSPs are correlated with individual action potentials simultaneously occurring in neighboring cells. We have used EPSP frequency as an indicator of the neuronal activity underlying GDP generation. By comparing EPSP frequency with the occurrence of synchronized GDPs between CA3 and the fascia dentata (FD), we found that GDPs are fired in an all-or-none manner, which is characterized by a specific threshold of EPSP frequency from which synchronous GDPs emerge. In FD, the EPSP frequency-threshold for GDP onset is 17 Hz. GDPs are triggered similarly in CA3 by appropriate periodic stimulation of mossy fibers. The frequency threshold for CA3 GDP onset is 12 Hz. These findings clarify the local mechanism of synchronization underlying bursting in the developing hippocampus, indicating that GDPs are fired when background levels of EPSPs or action potentials have built up full synchronization by firing at specific frequencies ({\textgreater}12 Hz). Our results also demonstrate that spontaneous EPSPs and action potentials are important for the initiation of synchronous bursts in the developing hippocampus.},
	number = {1},
	journal = {J. Neurophysiol.},
	author = {Prida, L M and Andres, Sanchez-Jv},
	month = jul,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {202--208},
}

@article{dan_efficient_1996,
	title = {Efficient {Coding} of {Natural} {Scenes} in the {Lateral} {Geniculate} {Nucleus}: {Experimental} {Test} of a {Computational} {Theory}},
	volume = {16},
	number = {10},
	journal = {J. Neurosci.},
	author = {Dan, Y and Atick, J J and Reid, R C},
	month = may,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {3351--3362},
}

@article{lapeyre_glycinergic_1995,
	title = {Glycinergic inhibition of spontaneously active guinea-pig medial vestibular nucleus neurons in vitro},
	volume = {188},
	abstract = {Effects of glycine on the spontaneous activity of medial vestibular nucleus (MVN) neurons recorded extracellularly from guinea-pig brainstem slices were investigated. Glycine produced a dose-dependent decrease in the resting discharge rate of all MVN neurons tested, with a mean EC50 of 3.9 x 10(-4) M. The inhibitory effect of glycine was reversibly blocked by strychnine and persisted in a low calcium/high magnesium-containing saline solution. These findings suggest the existence of a direct strychnine-sensitive inhibitory effect of glycine on guinea-pig MVN neurons.},
	number = {3},
	journal = {Neurosci. Lett.},
	author = {Lapeyre, P N and C, Waele De},
	month = mar,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {155--158},
}

@article{vibert_effects_1995,
	title = {Effects of baclofen on medial vestibular nucleus neurones in guinea-pig brainstem slices},
	volume = {183},
	abstract = {Using intracellular recordings of medial vestibular nucleus neurones (MVNn) in guinea-pig brainstem slices, the effects of baclofen, a specific agonist of the metabotropic GABAB receptors, were tested on the three main types of MVNn (A, B and B + LTS MVNn) that were previously identified in this nucleus. Regardless of their type, almost all MVNn were hyperpolarized and inhibited by baclofen. These hyperpolarizing effects persisted following either the addition of tetrodotoxin (TTX) in the perfusion medium, or in the presence of a high Mg2+/low Ca2+ solution known to block synaptic transmission. These results demonstrate that all types of MVNn are endowed with postsynaptic GABAB receptors.},
	number = {3},
	journal = {Neurosci. Lett.},
	author = {Vibert, N and Serafin, M and Vidal, P P and Muhlethaler, M},
	month = jan,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {193--197},
}

@article{arnold_nystagmus_1999,
	title = {Nystagmus induced by pharmacological inactivation of the brainstem ocular motor integrator in monkey},
	volume = {39},
	abstract = {A common cause of pathological nystagmus is malfunction of the mechanism by which the brain integrates eye velocity signals to produce eye position commands. For horizontal gaze, neurons in the nucleus prepositus hypoglossi-medial vestibular nucleus region (NPH-MVN) play a vital role in this neural integrator function. We studied the effects on gaze stability of pharmacological intervention in the NPH-MVN of monkeys by microinjections of eight drugs. Agents with agonist or antagonist actions at gamma-aminobutyric acid (GABA), glutamate, and kainate receptors all caused gaze-evoked nystagmus with centripetal eye drifts; glycine and strychnine had no effect. When the GABAA-agonist muscimol was injected near the center of MVN, the eyes drifted away from the central position with increasing-velocity waveforms, implying an unstable neural integrator. The observed effects of these drugs on gaze stability may be related to inactivation either of neurons within NPH-MVN or the cerebellar projections to them that control the fidelity of neural integration. Drugs that influence GABA or glutamine transmission may have a role in the treatment of nystagmus due to an abnormal neural integrator.},
	number = {25},
	journal = {Vision Res.},
	author = {Arnold, D B and Robinson, D A and Leigh, R J},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {4286--4295},
}

@article{smith_evidence_1991,
	title = {Evidence for inhibitory amino acid receptors on guinea pig medial vestibular nucleus neurons in vitro},
	volume = {121},
	abstract = {There is little evidence to indicate the identity of the inhibitory receptors which mediate inhibitory interaction between the two medial vestibular nuclei ('brainstem commissural inhibition'). In the present study we tested the hypothesis that medial vestibular nucleus (MVN) neurons have gamma-aminobutyric acid (GABA) or glycine receptors by recording from single MVN neurons in isolated guinea pig MVN slices maintained in vitro while superfusing with GABA (10(-8) M) and the non-competitive GABAA antagonist picrotoxin (10(-6) M or 2 x 10(-6) M), or glycine (10(-6) M) and the competitive glycine antagonist strychnine (10(-6) M). Forty-four \% (16/36) of the neurons tested with GABA showed a decrease in firing; in 7 out of 8 cases in which a decrease in firing occurred, the addition of the antagonist picrotoxin completely blocked the effect of the GABA alone. Fifty \% (7/14) of the neurons tested with glycine showed a decrease in firing; in 4 out of 6 cases where a decrease occurred, the addition of the antagonist strychnine completely blocked the effect of the glycine alone. In one case only did a cell respond both to GABA and glycine (8 neurons tested with both). These results are consistent with the hypothesis that some MVN neurons have GABA or glycine receptors (but in most cases not both), which may mediate brainstem commissural inhibition.},
	number = {1-2},
	journal = {Neurosci. Lett.},
	author = {Smith, P F and Darlington, C L and Hubbard, J I},
	month = jan,
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {244--246},
}

@article{hutchinson_further_1995,
	title = {Further evidence on the contribution of {GABAA} receptors to the {GABA}-mediated inhibition of medial vestibular nucleus neurones in vitro},
	volume = {6},
	abstract = {The present study investigated the electrophysiological effects of the selective and potent GABAA receptor agonist, isoguvacine, on guinea-pig medial vestibular nucleus (MVN) neurones in brainstem slices. The results confirm that many MVN neurones have GABAA receptors and that, even at concentrations as low as 10(-8) M, GABA is capable of exerting a powerful inhibitory effect on these neurones via GABAA receptors. The finding that {\textgreater} 50\% of neurones did not respond to isoguvacine, even at concentrations of 10(-6) M, suggested that only a specific subset of MVN neurones have GABAA receptors. Since many type I MVN neurones are believed to have postsynaptic GABAA receptors, it is possible that selective agonists such as isoguvacine may be useful in identifying type I neurones in vitro.},
	number = {12},
	journal = {Neuroreport},
	author = {Hutchinson, M and Smith, P F and Darlington, C L},
	month = aug,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {1649--1652},
}

@article{spencer_evidence_1989,
	title = {Evidence for glycine as an inhibitory neurotransmitter of vestibular, reticular, and prepositus hypoglossi neurons that project to the cat abducens nucleus},
	volume = {9},
	abstract = {The localization and distribution of brain-stem afferent neurons to the cat abducens nucleus has been examined by high-affinity uptake and retrograde transport of 3H-glycine. Injections of 3H-glycine selectively labeled (by autoradiography) only neurons located predominantly in the ipsilateral medial vestibular and contralateral prepositus hypoglossi nuclei, and in the contralateral dorsomedial reticular formation, the latter corresponding to the location of inhibitory burst neurons. The specificity of uptake and retrograde transport of 3H-glycine was indicated by the absence of labeling of the dorsomedial medullary reticular neurons ipsilateral and in close proximity to the injection site, where local uptake by diffusion could have occurred. The selectivity of uptake and transport was demonstrated by the absence of retrograde labeling following injections of 3H-GABA or 3H-leucine into the abducens nucleus. The immunohistochemical localization of glycine and GABA revealed a differential distribution of the 2 inhibitory neurotransmitter candidates in the extraocular motor nuclei. Glycine-immunoreactive staining of synaptic endings in the abducens nucleus was dense with a widespread soma-dendritic distribution but was sparse in the trochlear and oculomotor nuclei. By contrast, GABA-immunoreactive staining within the oculomotor and trochlear nuclei was associated with synaptic endings that were particularly prominent on the somata of motoneurons. GABA-immunoreactive staining in the abducens nucleus, however, was sparse. These differences between glycine- and GABA-immunoreactive staining in the extraocular motor nuclei were correlated with differences in the immunoreactivity of axons in the descending (glycine) and ascending (GABA) limbs of the medial longitudinal fasciculus. Glycine-immunoreactive neurons, furthermore, were observed in the same locations as neurons that were labeled autoradiographically by retrograde transport of 3H-glycine from the abducens nucleus. Electrophysiological recordings from abducens motoneurons and internuclear neurons revealed a marked reduction in the slow positivity of the orthodromic extracellular potential elicited by ipsilateral vestibular nerve stimulation following systemic administration of strychnine, an antagonist of glycine. Intracellular recordings demonstrated that the vestibular-evoked disynaptic inhibitory postsynaptic potentials in abducens neurons were effectively blocked by strychnine but were unaffected by picrotoxin, an antagonist of GABA.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {8},
	journal = {J. Neurosci.},
	author = {Spencer, R F and Wenthold, R J and Baker, R},
	month = aug,
	year = {1989},
	keywords = {merged\_fiete.bib},
	pages = {2718--2736},
}

@article{bekkers_origin_1990,
	title = {Origin of variability in quantal size in cultured hippocampal neurons and hippocampal slices},
	volume = {87},
	abstract = {The size of synaptic quanta has been found to display considerable variation in cultured hippocampal neurons, but the source of this variability was previously unknown. We have now compared the properties of locally evoked miniature excitatory postsynaptic currents in cultured hippocampal neurons and in thin hippocampal slices using whole-cell patch-clamp recordings. The variability in miniature excitatory postsynaptic current size was similar in both preparations and occurred in cultured neurons when only one or a few synaptic boutons were stimulated. Thus, the variability in miniature excitatory postsynaptic current amplitude is not an artifact of cultured neurons and arises predominantly from variability within a single bouton. Possible origins of this variability are discussed.},
	number = {14},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Bekkers, J M and Richerson, G B and Stevens, C F},
	month = jul,
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {5359--5362},
}

@article{coppola_extraordinarily_1996,
	title = {The extraordinarily rapid disappearance of entopic images},
	volume = {93},
	abstract = {It has been known for more than 40 years that images fade from perception when they are kept at the same position on the retina by abrogating eye movements. Although aspects of this phenomenon were described earlier, the use of close-fitting contact lenses in the 1950s made possible a series of detailed observations on eye movements and visual continuity. In the intervening decades, many investigators have studied the role of image motion on visual perception. Although several controversies remain, it is clear that images deteriorate and in some cases disappear following stabilization; eye movements are, therefore, essential to sustained exoptic vision. The time course of image degradation has generally been reported to be a few seconds to a minute or more, depending upon the conditions. Here we show that images of entoptic vascular shadows can disappear in less than 80 msec. The rapid vanishing of these images implies an active mechanism of image erasure and creation as the basis of normal visual processing.},
	number = {15},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Coppola, D and Purves, D},
	month = jul,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {8001--8004},
}

@article{scholl_ordered_2000,
	title = {Ordered networks of rat hippocampal neurons attached to silicon oxide surfaces},
	volume = {104},
	abstract = {The control of neuronal cell position and outgrowth is of fundamental interest in the development of applications ranging from cellular biosensors to tissue engineering. We have produced rectangular networks of functional rat hippocampal neurons on silicon oxide surfaces. Attachment and network formation of neurons was guided by a geometrical grid pattern of the adhesion peptide PA22-2 which matches in sequence a part of the A-chain of laminin. PA22-2 was applied by contact printing onto the functionalised silicon oxide surface and was immobilised by hetero-bifunctional cross-linking with sulfo-GMBS. Geometric pattern matching was achieved by microcontact printing using a polydimethylsiloxane (PDMS) stamp. In this way the produced grid pattern ranged from 3 to 20 microm in line width and from 50 to 100 microm in line distances. As shown by atomic force microscopy (AFM), line widths and line distances of the peptide pattern differ less than 0.5 microm from the used PDMS stamp. The height of the layer of immobilised PA22-2 was approximately 3.5 nm implying the layer to be monomolecular. Immobilised PA22-2 was capable of binding anti-PA22-2 antibodies indicating that the function of the peptide was not compromised by immobilisation. Rat hippocampal neurons, cultured at low density in serum-free medium, were applied to the growth matrix of PA22-2-coated substrates and, within 1-3 h of culture, formed a network-like pattern that more or less matched the printed grid. Reliability and reproducibility of neuronal network formation depended on the geometry, line width and node diameter of the grid pattern. The immobilised neurons showed resting membrane potentials comparable with controls and, already after 1 day of culture, were capable of eliciting action potentials. The suitability of the immobilised neurons for the study of man-made neural networks and for multi-site recordings from a functional neuronal network is discussed.},
	number = {1},
	journal = {J. Neurosci. Methods},
	author = {Scholl, M and Sprossler, C and Denyer, M and Krause, M and Nakajima, K and Maelicke, A and Knoll, W and Offenhausser, A},
	month = dec,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {65--75},
}

@article{jimbo_simultaneous_1999,
	title = {Simultaneous induction of pathway-specific potentiation and depression in networks of cortical neurons},
	volume = {76},
	abstract = {Activity-dependent modification of synaptic efficacy is widely recognized as a cellular basis of learning, memory, and developmental plasticity. Little is known, however, of the consequences of such modification on network activity. Using electrode arrays, we examined how a single, localized tetanic stimulus affects the firing of up to 72 neurons recorded simultaneously in cultured networks of cortical neurons, in response to activation through 64 different test stimulus pathways. The same tetanus produced potentiated transmission in some stimulus pathways and depressed transmission in others. Unexpectedly, responses were homogeneous: for any one stimulus pathway, neuronal responses were either all enhanced or all depressed. Cross-correlation of responses with the responses elicited through the tetanized site revealed that both enhanced and depressed responses followed a common principle: activity that was closely correlated before tetanus with spikes elicited through the tetanized pathway was enhanced, whereas activity outside a 40-ms time window of correlation to tetanic pathway spikes was depressed. Response homogeneity could result from pathway-specific recurrently excitatory circuits, whose gain is increased or decreased by the tetanus, according to its cross-correlation with the tetanized pathway response. The results show how spatial responses following localized tetanic stimuli, although complex, can be accounted for by a simple rule for activity-dependent modification.},
	number = {2},
	journal = {Biophys. J.},
	author = {Jimbo, Y and Tateno, T and Robinson, H P},
	month = feb,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {670--678},
}

@article{yuste_neuronal_1995,
	title = {Neuronal domains in developing neocortex: mechanisms of coactivation},
	volume = {14},
	abstract = {The mammalian neocortex consists of columnar circuits, whose development may be controlled by patterns of spontaneous activity. Columnar domains of spontaneously coactive neurons were previously described using Ca2+ imaging of slices from developing rat neocortex. We have now investigated the cellular mechanisms responsible for the coactivation of these domains. The activation starts in the center of a domain and spreads at speeds of approximately 100 microns/s. Domains occur in the presence of tetrodotoxin but are blocked by the gap junction blockers halothane and octanol. Simultaneous intracellular and optical recordings from dye-coupled cells reveal functional coupling between developing neocortical neurons. These data support the hypothesis that a neuronal domain results from the spontaneous excitation of one or a few trigger neurons that subsequently activate, either electrically or biochemically, the rest of the cells via gap junctions.},
	number = {1},
	journal = {Neuron},
	author = {Yuste, R and Nelson, D A and Rubin, W W and Katz, L C},
	month = jan,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {7--17},
}

@article{maeda_mechanisms_1995,
	title = {The mechanisms of generation and propagation of synchronized bursting in developing networks of cortical neurons},
	volume = {15},
	abstract = {The characteristics and mechanisms of synchronized firing in developing networks of cultured cortical neurons were studied using multisite recording through planar electrode arrays (PEAs). With maturation of the network (from 3 to 40 d after plating), the frequency and propagation velocity of bursts increased markedly (approximately from 0.01 to 0.5 Hz and from 5 to 100 mm/sec, respectively), and the sensitivity to extracellular magnesium concentration (0-10 mM) decreased. The source of spontaneous bursts, estimated from the relative delay of onset of activity between electrodes, varied randomly with each burst. Physical separation of synchronously bursting networks into several parts using an ultraviolet laser, divided synchronous bursting into different frequencies and phases in each part. Focal stimulation through the PEA was effective at multiple sites in eliciting bursts, which propagated over the network from the site of stimulation. Stimulated bursts exhibited both an absolute refractory period and a relative refractory period, in which partially propagating bursts could be elicited. Periodic electrical stimulation (at 1 to 30 sec intervals) produced slower propagation velocities and smaller numbers of spikes per burst at shorter stimulation intervals. These results suggest that the generation and propagation of spontaneous synchronous bursts in cultured cortical neurons is governed by the level of spontaneous presynaptic firing, by the degree of connectivity of the network, and by a distributed balance between excitation and recovery processes.},
	number = {10},
	journal = {J. Neurosci.},
	author = {Maeda, E and Robinson, H P and Kawana, A},
	month = oct,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {6834--6845},
}

@article{zhu_postnatal_2000,
	title = {Postnatal synaptic potentiation: delivery of {GluR4}-containing {AMPA} receptors by spontaneous activity},
	volume = {3},
	abstract = {To examine how functional circuits are established in the brain, we studied excitatory transmission in early postnatal hippocampus. Spontaneous neural activity was sufficient to selectively deliver GluR4-containing AMPA receptors (AMPA-Rs) into synapses. This delivery allowed non-functional connections to transmit at resting potentials and required NMDA receptors (NMDA-Rs) but not CaMKII activation. Subsequently, these delivered receptors were exchanged with non-synaptic GluR2-containing AMPA-Rs in a manner requiring little neuronal activity. The enhanced transmission resulting from this delivery and subsequent exchange was maintained for at least several days and required an interaction between GluR2 and NSF. Thus, this sequence of subunit-specific trafficking events triggered by spontaneous activity in early postnatal development may be crucial for initial establishment of long-lasting functional circuitry.},
	number = {11},
	journal = {Nat. Neurosci.},
	author = {Zhu, J J and Esteban, J A and Hayashi, Y and Malinow, R},
	month = nov,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1098--1106},
}

@article{feller_spontaneous_1999,
	title = {Spontaneous correlated activity in developing neural circuits},
	volume = {22},
	abstract = {Synapse Formation and Function Unit, National Institute of Neurological Disorders and Stroke, National Institutes of Health, Bethesda, Maryland 20892, USA. marla@codon.nih.gov},
	number = {4},
	journal = {Neuron},
	author = {Feller, M B},
	month = apr,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {653--656},
}

@article{donovan_origin_1999,
	title = {The origin of spontaneous activity in developing networks of the vertebrate nervous system},
	volume = {9},
	abstract = {Spontaneous neuronal activity has been detected in many parts of the developing vertebrate nervous system. Recent studies suggest that this activity depends on properties that are probably shared by all developing networks. Of particular importance is the high excitability of recurrently connected, developing networks and the presence of activity-induced transient depression of network excitability. In the spinal cord, it has been proposed that the interaction of these properties gives rise to spontaneous, periodic activity.},
	number = {1},
	journal = {Curr. Opin. Neurobiol.},
	author = {Donovan, O'mj},
	month = feb,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {94--104},
}

@article{garaschuk_developmental_1998,
	title = {Developmental profile and synaptic origin of early network oscillations in the {CA1} region of rat neonatal hippocampus},
	volume = {507},
	abstract = {1. By applying fura-2-based fluorometric calcium imaging to neonatal rat hippocampal slices we identified a developmentally regulated spontaneous neuronal activity in the CA1 region of the hippocampus. The activity consisted of bursts of intracellular Ca2+ transients recurring synchronously at a slow rate of 0.4-2 min-1 in the entire population of pyramidal neurones and interneurones. 2. These early network oscillations (ENOs) were present during a restricted period of postnatal development. Thus, they were not detected at the day of birth (P0), at P1-P4 they consisted of bursts of large (up to 1.5 microM) Ca2+ transients, gradually transforming into regularly occurring, smaller Ca2+ transients during the subsequent week. Beyond P15-P16 no ENOs were detected. 3. The ENOs were blocked by tetrodotoxin (TTX) and by a reduction in temperature from 33-35 degrees C to 20-22 degrees C. By combining fluorometric imaging with whole-cell current-clamp recordings, we found that each ENO-related Ca2+ transient was associated with a high-frequency (up to 100 Hz) train of action potentials riding on a depolarizing wave. 4. Recordings in the voltage-clamp mode revealed barrages of synaptic currents that were strictly correlated with the ENO-associated Ca2+ transients in neighbouring pyramidal neurones. Perfusing the cells with an intracellular solution that allowed for a discrimination between GABAA and glutamate receptor-mediated currents showed that these barrages of synaptic currents were predominantly of GABAergic origin. 5. The ENOs were totally blocked by the GABAA receptor antagonist bicuculline and they were also substantially reduced by the glutamatergic antagonists D,L-2-amino-5-phosphonovaleric acid (D, L-APV) and 6-cyano-7-nitroquinoxaline-2,3-dione (CNQX). 6. Synaptic stimulation and application of the GABAA receptor agonist muscimol mimicked the spontaneous Ca2+ transients in pyramidal neurones. The efficacy of muscimol in evoking Ca2+ transients decreased during development in parallel with the gradual disappearance of the ENOs. 7. The developmental decrease in the amplitude of ENO-associated Ca2+ transients occurred in parallel with the transformation of the excitatory synaptic transmission in the hippocampus from the immature GABAergic to the mature glutamatergic form. Thus, at the beginning of the first postnatal week single-shock synaptic stimulation produced Ca2+ transients that were completely blocked by bicuculline. At the end of the second postnatal week the same type of evoked synaptic stimulation produced a Ca2+ transient that was little affected by bicuculline but was abolished by the combined application of D,L-APV and CNQX. 8. These results demonstrate the presence of periodic and spontaneous Ca2+ transients in the majority of pyramidal cells and interneurones of the neonatal CA1 hippocampal network. These ENOs exhibit a highly region-specific developmental profile and may control the activity-dependent wiring of the synaptic connectivity during early postnatal development.},
	number = {Pt 1},
	journal = {J. Physiol.},
	author = {Garaschuk, O and Hanse, E and Konnerth, A},
	month = feb,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {219--236},
}

@article{staley_presynaptic_1998,
	title = {Presynaptic modulation of {CA3} network activity},
	volume = {1},
	abstract = {The simultaneous discharge of hippocampal CA3 pyramidal cells is a widely studied in vitro model of physiological and pathological network synchronization. This network is rapidly activated because of extensive positive feedback mediated by recurrent axon collaterals. Here we show that population-burst duration is limited by depletion of the releasable glutamate pool at these recurrent synapses. Postsynaptic inhibitory conductances further limit burst duration but are not necessary for burst termination. The interval between bursts in vitro depends on the rate of replenishment of releasable glutamate vesicles and the probability of release of those vesicles at recurrent synapses. Therefore presynaptic factors controlling glutamate release at recurrent synapses regulate the probability and duration of synchronous discharges of the CA3 network.},
	number = {3},
	journal = {Nat. Neurosci.},
	author = {Staley, K J and Longacher, M and Bains, J S and Yee, A},
	month = jul,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {201--209},
}

@article{fries_rapid_2001,
	title = {Rapid feature selective neuronal synchronization through correlated latency shifting},
	volume = {4},
	abstract = {Spontaneous brain activity could affect processing if it were structured. We show that neuron pairs in cat primary visual cortex exhibited correlated fluctuations in response latency, particularly when they had overlapping receptive fields or similar orientation preferences. Correlations occurred within and across hemispheres, but only when local field potentials (LFPs) oscillated in the gamma-frequency range (40-70 Hz). In this range, LFP fluctuations preceding response onset predicted response latencies; negative (positive) LFPs were associated with early (late) responses. Oscillations below 10 Hz caused covariations in response amplitude, but exhibited no columnar selectivity or coordinating effect on latencies. Thus, during high gamma activity, spontaneous activity exhibits distinct, column-specific correlation patterns. Consequently, cortical cells undergo coherent fluctuations in excitability that enhance temporal coherence of responses to contours that are spatially contiguous or have similar orientation. Because synchronized responses are more likely than dispersed responses to undergo rapid and joint processing, spontaneous activity may be important in early visual processes.},
	number = {2},
	journal = {Nat. Neurosci.},
	author = {Fries, P and Neuenschwander, S and Engel, A K and Goebel, R and Singer, W},
	month = feb,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {194--200},
}

@article{madison_control_1984,
	title = {Control of the repetitive discharge of rat {CA} 1 pyramidal neurones in vitro},
	volume = {354},
	abstract = {Experiments using intracellular recording techniques were performed on rat hippocampal neurones in vitro, to study the discharge properties of these cells. When CA 1 pyramidal cells were excited by injecting long depolarizing current pulses (approximately 600-800 ms), they responded with an initial rapid action potential discharge which slowed, or accommodated, and then stopped after 200-300 ms. The train of action potentials was followed by a hyperpolarization which was due primarily to calcium-activated potassium conductance (GK(Ca]. The amplitude of this hyperpolarization increased with an increasing number of action potentials in the initial discharge. Blocking the calcium-activated potassium conductance, by injecting EGTA into the cell, by bathing the cell in cadmium, a calcium channel blocker, or by bathing the cell in calcium-free medium, reduced the after-hyperpolarization (a.h.p.) and accommodation such that the frequency of action potential discharge increased and the duration of this discharge was prolonged. Blocking the calcium-activated potassium conductance had a greater effect on discharge frequency later in the action potential train, as late interspike intervals were shortened more than early ones by the application of cadmium or of calcium-free medium. This was presumably because the calcium-activated potassium conductance was more developed later in the train. Accommodation was not completely abolished in the absence of calcium and presence of cadmium, suggesting that other factors, in addition to calcium-activated potassium conductance, contributed to this process. This remaining accommodation was reduced by low doses of carbachol, suggesting that the M-current also plays a role in accommodation. We conclude that accommodation of the action potential discharge of hippocampal pyramidal cells may be regulated by at least two potassium currents: the calcium-activated potassium current and the M-current. Both of these currents are turned on during excitation of the neurone and act in an inhibitory manner on that neurone to limit further action potential discharge.},
	journal = {J. Physiol.},
	author = {Madison, D V and Nicoll, R A},
	month = sep,
	year = {1984},
	keywords = {merged\_fiete.bib},
	pages = {319--331},
}

@article{warman_reconstruction_1994,
	title = {Reconstruction of hippocampal {CA1} pyramidal cell electrophysiology by computer simulation},
	volume = {71},
	abstract = {1. We have developed a 16-compartment model that reproduces most of the features of the CA1 pyramidal cell electrophysiology observed experimentally. The model was constructed using seven active ionic conductances: gNa, gCa, gDR, gCT, gA, gM, and gAHP whose kinetics have been, inferred, in most cases, from the available voltage-clamp data obtained from these cells. We focussed the simulation on the initial and late accommodation, the slow depolarization potential and the spike broadening during repetitive firing, because their mechanisms are not well understood. 2. Current-clamp records were reproduced by iterative adjustments to the ionic maximum conductances, scaling and/or “reshaping” of the gates' time constant within the experimental voltage-clamp data, and shifting the position of the steady-state gate opening. The final properties of the ionic channels were not significantly different from the voltage-clamp experiments. 3. The resulting model reproduces all four after-potentials that have been recorded to follow activation of the cell. The fast, medium, and slow after-hyperpolarization potentials (AHPs) were, respectively, generated by ICT, IM, and IAHP. Furthermore, the model suggests that the mechanisms underlying the depolarization after potential (DAP) is mostly due to passive recharging of the soma by the dendrites. 4. The model also reproduces most of the firing features experimentally observed during injection of long current pulses. Model responses showed a small initial decrease in the firing frequency during a slow underlying depolarization potential, followed by a more significant frequency decrease. Moreover, a gradual broadening of the action potential and loss of the fast AHP were also observed during the initial high-frequency firing, followed, as the firing frequency decreased, by a gradual recovery of the spikes' original width and fast AHP amplitude increase. 5. A large reduction of the K repolarizing current was required to reproduce the spike broadening and reduction of the fast AHP experimentally observed in CA1 cells during repetitive firing responses. The incorporation of a transient Ca- and voltage-dependent K current (ICT) into the model successfully reproduced these experimental observations. In contrast, we were unable to reproduce this phenomenon when a large persistent Ca- and voltage-dependent K current (generally named IC) was included in the model. These results suggest that there is a strong contribution to action-potential repolarization and fast AHP by a transient Ca- and voltage-dependent K current (ICT). 6. The two accommodation steps were induced by a progressively enlargement of two K currents IM (initial) and IAHP (late).(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {6},
	journal = {J. Neurophysiol.},
	author = {Warman, E N and Durand, D M and Yuen, G L},
	month = jun,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {2033--2045},
}

@article{dobrunz_heterogeneity_1997,
	title = {Heterogeneity of release probability, facilitation, and depletion at central synapses},
	volume = {18},
	abstract = {Previous studies of short-term plasticity in central nervous systems synapses have largely focused on average synaptic properties. In this study, we use recordings from putative single synaptic release sites in hippocampal slices to show that significant heterogeneity exists in facilitation and depletion among synapses. In particular, the amount of paired-pulse facilitation is inversely related to the initial release probability of the synapse. We also examined depletion at individual synapses using high frequency stimulation, and estimated the size of the readily releasable vesicle pool, which averaged 5.0 +/- 3.0 quanta (n = 13 synapses). In addition, these experiments demonstrate that the release probability at a synapse is directly correlated with the size of its readily releasable vesicle pool.},
	number = {6},
	journal = {Neuron},
	author = {Dobrunz, L E and Stevens, C F},
	month = jun,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {995--1008},
}

@article{katz_synaptic_1996,
	title = {Synaptic activity and the construction of cortical circuits},
	volume = {274},
	abstract = {Vision is critical for the functional and structural maturation of connections in the mammalian visual system. Visual experience, however, is a subset of a more general requirement for neural activity in transforming immature circuits into the organized connections that subserve adult brain function. Early in development, internally generated spontaneous activity sculpts circuits on the basis of the brain's “best guess” at the initial configuration of connections necessary for function and survival. With maturation of the sense organs, the developing brain relies less on spontaneous activity and increasingly on sensory experience. The sequential combination of spontaneously generated and experience-dependent neural activity endows the brain with an ongoing ability to accommodate to dynamically changing inputs during development and throughout life.},
	number = {5290},
	journal = {Science},
	author = {Katz, L C and Shatz, C J},
	month = nov,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {1133--1138},
}

@article{bi_synaptic_1998,
	title = {Synaptic modifications in cultured hippocampal neurons: dependence on spike timing, synaptic strength, and postsynaptic cell type},
	volume = {18},
	abstract = {In cultures of dissociated rat hippocampal neurons, persistent potentiation and depression of glutamatergic synapses were induced by correlated spiking of presynaptic and postsynaptic neurons. The relative timing between the presynaptic and postsynaptic spiking determined the direction and the extent of synaptic changes. Repetitive postsynaptic spiking within a time window of 20 msec after presynaptic activation resulted in long-term potentiation (LTP), whereas postsynaptic spiking within a window of 20 msec before the repetitive presynaptic activation led to long-term depression (LTD). Significant LTP occurred only at synapses with relatively low initial strength, whereas the extent of LTD did not show obvious dependence on the initial synaptic strength. Both LTP and LTD depended on the activation of NMDA receptors and were absent in cases in which the postsynaptic neurons were GABAergic in nature. Blockade of L-type calcium channels with nimodipine abolished the induction of LTD and reduced the extent of LTP. These results underscore the importance of precise spike timing, synaptic strength, and postsynaptic cell type in the activity-induced modification of central synapses and suggest that Hebb's rule may need to incorporate a quantitative consideration of spike timing that reflects the narrow and asymmetric window for the induction of synaptic modification.},
	number = {24},
	journal = {J. Neurosci.},
	author = {Bi, G Q and Poo, M M},
	month = dec,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {10464--10472},
}

@article{michael_j_odonovan_population_1997,
	title = {Population behavior and self-organization in the genesis of spontaneous rhythmic activity by developing spinal networks},
	volume = {8},
	abstract = {During development spinal networks generate recurring episodes of rhythmic bursting that can be recorded from motoneurons and interneurons. Optical imaging has identified a set of propriospinal interneurons that may be important in the production of this activity. These neurons are rhythmically active, are recurrently interconnected and have powerful projections to motoneurons. The excitability of this propriospinal network is depressed by activity and recovers in the interval between episodes. These and other observations have been formulated into a qualitative model in which population behavior and self-organization are responsible for the spontaneous activity generated by developing spinal networks.},
	number = {1},
	journal = {Semin. Cell Dev. Biol.},
	author = {Michael J. O'Donovan, Nikolai Chub},
	month = feb,
	year = {1997},
	keywords = {merged\_fiete.bib, self-organization, development, rhythm generation, spinal cord},
	pages = {21--28},
}

@article{chamberlin_role_1990,
	title = {Role of {EPSPs} in initiation of spontaneous synchronized burst firing in rat hippocampal neurons bathed in high potassium},
	volume = {64},
	abstract = {1. Spontaneous discharges that resemble interictal spikes arise in area CA3 b/c of rat hippocampal slices bathed in 8.5 mM [K+]o. Excitatory postsynaptic potentials (EPSPs) also appear at irregular intervals in these cells. The role of local synaptic excitation in burst initiation was examined with intracellular and extracellular recordings from CA3 pyramidal neurons. 2. Most (70\%) EPSPs were small (less than 2 mV in amplitude), suggesting that they were the product of quantal release or were evoked by a single presynaptic action potential in another cell. It is unlikely that most EPSPs were evoked by a presynaptic burst of action potentials. Indeed, intrinsic burst firing was not prominent in CA3 b/c pyramidal cells perfused in 8.5 mM [K+]o. 3. The likelihood of occurrence and the amplitude of EPSPs were higher in the 50-ms interval just before the onset of each burst than during a similar interval 250 ms before the burst. This likely reflects increased firing probability of CA3 neurons as they emerge from the afterhyperpolarization (AHP) and conductance shunt associated with the previous burst. 4. Perfusion with 2 microM 6-cyano-7-nitroquinoxaline-2,3-dione (CNQX), a potent quisqualate receptor antagonist, decreased the frequency of EPSPs in CA3 b/c neurons from 3.6 +/- 0.9 to 0.9 +/- 0.3 (SE) Hz. Likewise, CNQX reversibly reduced the amplitude of evoked EPSPs in CA3 b/c cells. 5. Spontaneous burst firing in 8.5 mM [K+]o was abolished in 11 of 31 slices perfused with 2 microM CNQX.(ABSTRACT TRUNCATED AT 250 WORDS)},
	number = {3},
	journal = {J. Neurophysiol.},
	author = {Chamberlin, N L and Traub, R D and Dingledine, R},
	month = sep,
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {1000--1008},
}

@article{robinson_periodic_1993,
	title = {Periodic synchronized bursting and intracellular calcium transients elicited by low magnesium in cultured cortical neurons},
	volume = {70},
	abstract = {1. In Mg(2+)-free external solution, rat cortical neurons in cultured networks entered a stable firing mode, consisting of regular bursts of action potentials superimposed on long-lasting depolarizations. The average separation between bursts varied from culture to culture, but was usually between 5 and 20 s. The distribution of burst intervals followed a Gaussian or normal distribution, with a standard deviation of typically 10\% of the average burst period. 2. A gradually depolarizing pacemaker potential was never observed between bursts, but the threshold for action potentials during the quiescent phase was {\textgreater} or = 10 mV above the resting potential. No progressive change in conductance or excitability was observed during the quiescent period. Intracellular stimulation of action potentials did not reproduce the long-lasting depolarization. 3. Switching from current clamp to voltage clamp at the resting potential revealed large postsynaptic currents, mainly excitatory but with a small inhibitory component, at the same phase and frequency as the spike bursts, showing that periodic synaptic input is responsible for the burst-depolarizations. The current could be eliminated by local application of 2-amino-5-phosphonovaleric acid (APV) or 6-cyano-7-nitroquinoxaline-2,3-dione (CNQX) to the postsynaptic cell. In the presence of tetrodotoxin, irregular miniature excitatory postsynaptic currents were observed. 4. A fluorescent calcium indicator (fluo-3, 100 microM) was included in the whole-cell pipette solution, to allow simultaneous electrical and calcium measurements in the same cell. In current clamp, transient intracellular calcium increases were found, which were synchronized to the spike bursts. The Ca2+ rise lasted as long as the action potential burst, and was followed by an exponential decay considerably slower than that of the membrane potential. Calcium transients disappeared during voltage clamp at the resting potential, suggesting that calcium influx through voltage-dependent calcium channels greatly exceeds that through synaptic channels. 5. Multisite Ca2+ recording, after loading with fluo-3 acetoxymethyl (AM) ester, revealed that the onsets of burst-related calcium transients were synchronized in all active cells of each view-field, to within approximately 20 ms. Occasionally, secondary rhythms were observed in which only a subset of cells participated. The times to peak and the decay times of calcium transients varied among synchronized cells. 6. The pharmacology of the burst-related calcium transients was investigated by bath application of a variety of compounds.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Robinson, H P and Kawahara, M and Jimbo, Y and Torimitsu, K and Kuroda, Y and Kawana, A},
	month = oct,
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {1606--1616},
}

@article{murphy_spontaneous_1992,
	title = {Spontaneous synchronous synaptic calcium transients in cultured cortical neurons},
	volume = {12},
	abstract = {The firing pattern displayed by neuronal aggregates is thought to play a key role in cortical development and physiology. In this study, we have employed optical recording of intracellular calcium to monitor activity of multiple neurons simultaneously in primary cortical cultures. With this approach, we have observed spontaneous synchronous calcium transients among adjacent cortical neurons. These transients appear to be mediated by prominent spontaneous synaptic excitation, as they are enhanced by picrotoxin, a blocker of inhibitory GABAergic transmission, and reduced by antagonism of glutamate receptors or addition of TTX. After picrotoxin treatment, the calcium transients exhibit regular frequency and amplitude, and occur in synchrony with bursts of excitatory synaptic potentials every 10-20 sec. Using electrical stimulation, we have identified a relative refractory period, extending up to 5 sec after a synchronous burst, that may play a role in cell synchronization. NMDA receptor antagonists or reduced extracellular calcium levels lower the amplitude of the calcium transients yet fail to alter their frequency, suggesting that intracellular calcium levels may not be a major determinant of burst frequency. In contrast, mild depolarization with kainic acid (0.5-1 microM) increased burst frequency up to fivefold, suggesting a critical dependence of rhythmic activity on membrane potential. Chronic blockade of electrical activity with TTX beginning a few days after plating of cultures dampens the amplitude and significantly increases the frequency of calcium transients in mature cultures. These studies demonstrate that aggregates of cultured cortical neurons express synchronous firing activity in vitro and that this network activity is dependent in part on neuronal firing during development.},
	number = {12},
	journal = {J. Neurosci.},
	author = {Murphy, T H and Blatter, L A and Wier, W G and Baraban, J M},
	month = dec,
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {4834--4845},
}

@article{voigt_synchronization_1997,
	title = {Synchronization of neuronal activity promotes survival of individual rat neocortical neurons in early development},
	volume = {9},
	abstract = {Neural activity is thought to play a significant role during the development of the cerebral cortex. In this study, we examined the effects of global activity block or enhancement and the effects of patterned firing on the ability of cultured rat neocortical neurons to survive during the second week in vitro, beyond the beginning of synaptogenesis. Blockade of neuronal activity by adding tetrodotoxin (TTX) and increasing magnesium concentration in the medium strongly reduced the survival of cortical cells. Increasing neuronal activity by raising the external potassium concentration significantly improved the survival of cortical neurons. We postulated that in a developing neuronal network the survival of nerve cells is regulated by synaptically mediated events that involve changes in the intracellular calcium concentration. To examine this question further, we monitored the activity of the developing network by optically recording the intracellular calcium signals of many neurons simultaneously. These recordings show that in low magnesium neocortical neurons express synchronized oscillation of their intracellular calcium concentration. The ability of a network to synchronize the changes in intracellular calcium of multiple cells appeared gradually during the second week in culture, paralleled by both an increase in the synaptic density and a decline in the number of surviving neurons. By examining the fate of identified cells several days after a recording session, we found that those nerve cells that were co-activated with other neurons had a significantly higher chance to survive than cells that did not participate in synchronized events. These experiments demonstrate that during early cortical network development cortical neurons show synchronized firing activity and that the survival of neurons is at least partially dependent on this pattern of neuronal activity.},
	number = {5},
	journal = {Eur. J. Neurosci.},
	author = {Voigt, T and Baier, H and Lima, de Dolabela A},
	month = may,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {990--999},
}

@article{malgaroli_glutamate-induced_1992,
	title = {Glutamate-induced long-term potentiation of the frequency of miniature synaptic currents in cultured hippocampal neurons},
	volume = {357},
	abstract = {Glutamate application at synapses between hippocampal neurons in culture produces long-term potentiation of the frequency of spontaneous miniature synaptic currents, together with long-term potentiation of evoked synaptic currents. The mini frequency potentiation is initiated postsynaptically and requires activity of NMDA receptors. Although the frequency of unitary quantal responses increases strongly, their amplitude remains little changed with potentiation. Tests of postsynaptic responsiveness rule out recruitment of latent glutamate receptor clusters. Thus, postsynaptic induction can lead to enhancement of presynaptic transmitter release. The sustained potentiation of mini frequency is expressed even in the absence of Ca2+ entry into presynaptic terminals.},
	number = {6374},
	journal = {Nature},
	author = {Malgaroli, A and Tsien, R W},
	month = may,
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {134--139},
}

@article{bouron_modulation_2001,
	title = {Modulation of spontaneous quantal release of neurotransmitters in the hippocampus},
	volume = {63},
	abstract = {Presynaptic action potentials trigger the exocytosis of neurotransmitters. However, even in the absence of depolarisation-dependent Ca(2+) entry nearby release sites, spontaneous vesicular release still occurs. Even though this happens at low rate, such spontaneous release may play a trophic role in maintaining the shape of dendritic structures. Like evoked responses, action potential-independent release is subject to modulation. This review describes some of the regulatory factors that rapidly and presynaptically regulate the ongoing Ca(2+)-independent release of neurotransmitters in the hippocampus. For instance, the electrical activity of the nerve ending, neurotransmitters, hypertonic solutions, neurotoxins, polycations, neurotrophic factors, immunoglobulins, cyclothiazide and psychotropic drugs can all modify the rate of spontaneous release. This can be achieved through various mechanisms that can be Ca(2+)-dependent or Ca(2+)-independent, protein kinase-dependent or independent. Since action potential-independent release contributes to the maintenance of dendritic structures, neuromodulators are likely to influence the density and/or length of dendritic spines, which in turn may modulate information processing in the central nervous system (CNS).},
	number = {6},
	journal = {Prog. Neurobiol.},
	author = {Bouron, A},
	month = apr,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {613--635},
}

@article{cormier_bidirectional_2001,
	title = {Bidirectional synaptic plasticity correlated with the magnitude of dendritic calcium transients above a threshold},
	volume = {85},
	abstract = {The magnitude of postsynaptic Ca(2+) transients is thought to affect activity-dependent synaptic plasticity associated with learning and memory. Large Ca(2+) transients have been implicated in the induction of long-term potentiation (LTP), while smaller Ca(2+) transients have been associated with long-term depression (LTD). However, a direct relationship has not been demonstrated between Ca(2+) measurements and direction of synaptic plasticity in the same cells, using one induction protocol. Here, we used glutamate iontophoresis to induce Ca(2+) transients in hippocampal CA1 neurons injected with the Ca(2+)-indicator fura-2. Test stimulation of one or two synaptic pathways before and after iontophoresis showed that the direction of synaptic plasticity correlated with glutamate-induced Ca(2+) levels above a threshold, below which no plasticity occurred (approximately 180 nM). Relatively low Ca(2+) levels (180-500 nM) typically led to LTD of synaptic transmission and higher levels ({\textgreater}500 nM) often led to LTP. Failure to show plasticity correlated with Ca(2+) levels in two distinct ranges: {\textless}180 nM and approximately 450-600 nM, while only LTD occurred between these ranges. Our data support a class of models in which failure of Ca(2+) transients to affect transmission may arise either from insufficient Ca(2+) to affect Ca(2+)-sensitive proteins regulating synaptic strength through opposing activities or from higher Ca(2+) levels that reset activities of such proteins without affecting the net balance of activities. Our estimates of the threshold Ca(2+) level for LTD (approximately 180 nM) and for the transition from LTD to LTP (approximately 540 nM) may assist in constraining the molecular details of such models.},
	number = {1},
	journal = {J. Neurophysiol.},
	author = {Cormier, R J and Greenwood, A C and Connor, J A},
	month = jan,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {399--406},
}

@article{carroll_rapid_1999,
	title = {Rapid redistribution of glutamate receptors contributes to long-term depression in hippocampal cultures},
	volume = {2},
	abstract = {Synaptic strength can be altered by a variety of pre- or postsynaptic modifications. Here we test the hypothesis that long-term depression (LTD) involves a decrease in the number of glutamate receptors that are clustered at individual synapses in primary cultures of hippocampal neurons. Similar to a prominent form of LTD observed in hippocampal slices, LTD in hippocampal cultures required NMDA receptor activation and was accompanied by a decrease in the amplitude and frequency of miniature excitatory postsynaptic currents. Immunocytochemical analysis revealed that induction of LTD caused a concurrent decrease in the number of AMPA receptors clustered at synapses but had no effect on synaptic NMDA receptor clusters. These results suggest that a subtype-specific redistribution of synaptic glutamate receptors contributes to NMDA receptor-dependent LTD.},
	number = {5},
	journal = {Nat. Neurosci.},
	author = {Carroll, R C and Lissin, D V and von M, Zastrow and Nicoll, R A and Malenka, R C},
	month = may,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {454--460},
}

@article{tong_long-term_1996,
	title = {Long-term potentiation in cultures of single hippocampal granule cells: a presynaptic form of plasticity},
	volume = {16},
	abstract = {We have explored the mechanisms of mossy fiber long-term potentiation (LTP) at autapses in single-cell cultures of guinea pig hippocampal dentate granule cells. L-AP4-sensitive, but not insensitive, cells responded to a brief tetanus with a sustained potentiation in the synaptic responses. The induction of this LTP appeared identical to that observed in hippocampal mossy fiber synapses in situ, in that it required a rise in presynaptic Ca2+ and activation of protein kinase A. Its expression also appeared to be presynaptic and was due, at least in part, to events that occurred after the entry of Ca2+ and to the switching on of previously silent release sites.},
	number = {6},
	journal = {Neuron},
	author = {Tong, G and Malenka, R C and Nicoll, R A},
	month = jun,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {1147--1157},
}

@article{m_brain-derived_2000,
	title = {Brain-derived neurotrophic factor differentially regulates excitatory and inhibitory synaptic transmission in hippocampal cultures},
	volume = {20},
	abstract = {Brain-derived neurotrophic factor (BDNF) has been postulated to be a key signaling molecule in regulating synaptic strength and overall circuit activity. In this context, we have found that BDNF dramatically increases the frequency of spontaneously initiated action potentials in hippocampal neurons in dissociated culture. Using analysis of unitary synaptic transmission and immunocytochemical methods, we determined that chronic treatment with BDNF potentiates both excitatory and inhibitory transmission, but that it does so via different mechanisms. BDNF strengthens excitation primarily by augmenting the amplitude of AMPA receptor-mediated miniature EPSCs (mEPSCs) but enhances inhibition by increasing the frequency of mIPSC and increasing the size of GABAergic synaptic terminals. In contrast to observations in other systems, BDNF-mediated increases in AMPA-receptor mediated mEPSC amplitudes did not require activity, because blocking action potentials with tetrodotoxin for the entire duration of BDNF treatment had no effect on the magnitude of this enhancement. These forms of synaptic regulations appear to be a selective action of BDNF because intrinsic excitability, synapse number, and neuronal survival are not affected in these cultures. Thus, although BDNF induces a net increase in overall circuit activity, this results from potentiation of both excitatory and inhibitory synaptic drive through distinct and selective physiological mechanisms.},
	number = {9},
	journal = {J. Neurosci.},
	author = {M, Bolton Mclean and Pittman, A J and Lo, D C},
	month = may,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {3221--3232},
}

@article{gomperts_distinct_2000,
	title = {Distinct roles for ionotropic and metabotropic glutamate receptors in the maturation of excitatory synapses},
	volume = {20},
	abstract = {We used the single-cell culture preparation to study the role of activity in the development of glutamatergic synapses in vitro. Rat hippocampal cells grown in isolation on glial islands formed functional autaptic connections and continued to elaborate new synapses throughout the 2 week investigation, resulting in increases in both the evoked AMPA receptor (AMPAR) and NMDA receptor (NMDAR) components of the EPSC. Synaptogenesis was not prevented by chronic blockade of sodium channels or all of the known glutamate receptors. Analysis of miniature EPSCs revealed that AMPAR quantal size doubled over time in vitro whereas NMDAR quantal size remained constant. However, the proportion of synaptic responses mediated only by NMDARs increased over time in vitro. The increase in AMPAR quantal size was prevented by TTX and ionotropic glutamate receptor antagonists, whereas the increase in the proportion of NMDAR-only synapses was prevented by metabotropic glutamate receptor antagonists. Notably, chronic NMDAR blockade incubation did not block the formation of the AMPAR EPSC, indicating that NMDAR-dependent plasticity is not necessary for the onset of AMPAR synaptic transmission in this system. We conclude that action potentials and ionotropic glutamate receptor activation are necessary for the developmental increase in AMPAR quantal size and that metabotropic glutamate receptor activation is required for the production of NMDAR-only synapses, but none of these is essential for synapse formation.},
	number = {6},
	journal = {J. Neurosci.},
	author = {Gomperts, S N and Carroll, R and Malenka, R C and Nicoll, R A},
	month = mar,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {2229--2237},
}

@article{miyashita_neuronal_1988,
	title = {Neuronal correlate of pictorial short-term memory in the primate temporal cortex},
	volume = {331},
	abstract = {It has been proposed that visual-memory traces are located in the temporal lobes of the cerebral cortex, as electric stimulation of this area in humans results in recall of imagery. Lesions in this area also affect recognition of an object after a delay in both humans and monkeys, indicating a role in short-term memory of images. Single-unit recordings from the temporal cortex have shown that some neurons continue to fire when one of two or four colours are to be remembered temporarily. But neuronal responses selective to specific complex objects, including hands and faces, cease soon after the offset of stimulus presentation. These results led to the question of whether any of these neurons could serve the memory of complex objects. We report here a group of shape-selective neurons in an anterior ventral part of the temporal cortex of monkeys that exhibited sustained activity during the delay period of a visual short-term memory task. The activity was highly selective for the pictorial information to be memorized and was independent of the physical attributes such as size, orientation, colour or position of the object. These observations show that the delay activity represents the short-term memory of the categorized percept of a picture.},
	number = {6151},
	journal = {Nature},
	author = {Miyashita, Y and Chang, H S},
	month = jan,
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {68--70},
}

@article{best_spatial_2001,
	title = {Spatial processing in the brain: the activity of hippocampal place cells},
	volume = {24},
	abstract = {The startling discovery by O'Keefe \& Dostrovsky (Brain Res. 1971; 34: 171-75) that hippocampal neurons fire selectively in different regions or “place fields” of an environment and the subsequent development of the comprehensive theory by O'Keefe \& Nadel (The Hippocampus as a Cognitive Map. Oxford, UK: Clarendon, 1978) that the hippocampus serves as a cognitive map have stimulated a substantial body of literature on the characteristics of hippocampal “place cells” and their relevance for our understanding of the mechanisms by which the brain processes spatial information. This paper reviews the major dimensions of the empirical research on place-cell activity and the development of computational models to explain various characteristics of place fields.},
	journal = {Annu. Rev. Neurosci.},
	author = {Best, P J and White, A M and Minai, A},
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {459--486},
}

@article{graves_sleep_2001,
	title = {Sleep and memory: a molecular perspective},
	volume = {24},
	abstract = {This review synthesizes data from behavioral studies examining the role of sleep in memory storage with what is known about the molecular mechanisms of memory consolidation. There are striking similarities in the effects on memory storage of post-training pharmacological manipulations and post-training manipulations of sleep. For example, inhibition of protein synthesis is most effective if it occurs at a time post-training when rapid eye movement (REM) sleep is required for memory consolidation. The neurochemical changes that occur across sleep/wake states, especially the cholinergic changes that occur in the hippocampus during REM sleep, might provide a mechanism by which sleep modulates specific cellular signaling pathways involved in hippocampus-dependent memory storage.},
	number = {4},
	journal = {Trends Neurosci.},
	author = {Graves, L and Pack, A and Abel, T},
	month = apr,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {237--243},
}

@article{stickgold_sleep_1998,
	title = {Sleep: off-line memory reprocessing},
	volume = {2},
	abstract = {Behavioral studies of memory and learning in both humans and animals support a role for sleep in the consolidation and integration of memories. Physiological studies of hippocampal and cortical activity as well as of brainstem neuromodulatory systems demonstrate the state-dependence of communication both between and within the neocortex and hippocampus. These findings are consonant with observed cognition during sleep and immediately following awakening.},
	number = {12},
	journal = {Trends Cogn. Sci.},
	author = {Stickgold, Robert},
	month = dec,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {484--492},
}

@article{kudrimoti_reactivation_1999,
	title = {Reactivation of hippocampal cell assemblies: effects of behavioral state, experience, and {EEG} dynamics},
	volume = {19},
	abstract = {During slow wave sleep (SWS), traces of neuronal activity patterns from preceding behavior can be observed in rat hippocampus and neocortex. The spontaneous reactivation of these patterns is manifested as the reinstatement of the distribution of pairwise firing-rate correlations within a population of simultaneously recorded neurons. The effects of behavioral state [quiet wakefulness, SWS, and rapid eye movement (REM)], interactions between two successive spatial experiences, and global modulation during 200 Hz electroencephalographic (EEG) “ripples” on pattern reinstatement were studied in CA1 pyramidal cell population recordings. Pairwise firing-rate correlations during often repeated experiences accounted for a significant proportion of the variance in these interactions in subsequent SWS or quiet wakefulness and, to a lesser degree, during SWS before the experience on a given day. The latter effect was absent for novel experiences, suggesting that a persistent memory trace develops with experience. Pattern reinstatement was strongest during sharp wave-ripple oscillations, suggesting that these events may reflect system convergence onto attractor states corresponding to previous experiences. When two different experiences occurred in succession, the statistically independent effects of both were evident in subsequent SWS. Thus, the patterns of neural activity reemerge spontaneously, and in an interleaved manner, and do not necessarily reflect persistence of an active memory (i.e., reverberation). Firing-rate correlations during REM sleep were not related to the preceding familiar experience, possibly as a consequence of trace decay during the intervening SWS. REM episodes also did not detectably influence the correlation structure in subsequent SWS, suggesting a lack of strengthening of memory traces during REM sleep, at least in the case of familiar experiences.},
	number = {10},
	journal = {J. Neurosci.},
	author = {Kudrimoti, H S and Barnes, C A and McNaughton, B L},
	month = may,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {4090--4101},
}

@article{martin_synaptic_2000,
	title = {Synaptic plasticity and memory: an evaluation of the hypothesis},
	volume = {23},
	abstract = {Changing the strength of connections between neurons is widely assumed to be the mechanism by which memory traces are encoded and stored in the central nervous system. In its most general form, the synaptic plasticity and memory hypothesis states that “activity-dependent synaptic plasticity is induced at appropriate synapses during memory formation and is both necessary and sufficient for the information storage underlying the type of memory mediated by the brain area in which that plasticity is observed.” We outline a set of criteria by which this hypothesis can be judged and describe a range of experimental strategies used to investigate it. We review both classical and newly discovered properties of synaptic plasticity and stress the importance of the neural architecture and synaptic learning rules of the network in which it is embedded. The greater part of the article focuses on types of memory mediated by the hippocampus, amygdala, and cortex. We conclude that a wealth of data supports the notion that synaptic plasticity is necessary for learning and memory, but that little data currently supports the notion of sufficiency.},
	journal = {Annu. Rev. Neurosci.},
	author = {Martin, S J and Grimwood, P D and Morris, R G},
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {649--711},
}

@article{mcgaugh_memorycentury_2000,
	title = {Memory–a century of consolidation},
	volume = {287},
	abstract = {The memory consolidation hypothesis proposed 100 years ago by Muller and Pilzecker continues to guide memory research. The hypothesis that new memories consolidate slowly over time has stimulated studies revealing the hormonal and neural influences regulating memory consolidation, as well as molecular and cellular mechanisms. This review examines the progress made over the century in understanding the time-dependent processes that create our lasting memories.},
	number = {5451},
	journal = {Science},
	author = {McGaugh, J L},
	month = jan,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {248--251},
}

@article{parker_sense_1998,
	title = {Sense and the single neuron: probing the physiology of perception},
	volume = {21},
	abstract = {The newly defined field of cognitive neuroscience attempts to draw together the study of all brain mechanisms that underlie our mental life. Historically, the major sensory pathways have provided the most trustworthy insights into how the brain supports cognitive functions such as perception, attention, and short-term memory. The links between neural activity and perception, in particular, have been studied revealingly in recent decades. Here we review the striking progress in this area, giving particular emphasis to the kinds of neural events that underlie the perceptual judgments of conscious observers.},
	journal = {Annu. Rev. Neurosci.},
	author = {Parker, A J and Newsome, W T},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {227--277},
}

@article{wong_retinal_1999,
	title = {Retinal waves and visual system development},
	volume = {22},
	abstract = {Many pathways in the developing visual system are restructured and become highly organized even before vision occurs. Yet the developmental processes underlying the remodeling of visual connectivity are crucially dependent on retinal activity. Surprisingly, the immature and light-insensitive retina spontaneously generates a pattern of rhythmic bursting activity during the period when the connectivity patterns of retinal ganglion cells are shaped. Spatially, the activity is seen to spread across the retina in the form of waves that bring into synchrony the bursts of neighboring cells. Waves are present in the developing retina of higher and lower vertebrates, which suggests that this form of activity may be a common and fundamental mechanism employed in the activity-dependent refinement of early patterns of visual connections. Unraveling the cues encoded by the waves promises to provide important insights into how interactions driven by specific patterns of activity could lead to the modification of connectivity during development.},
	journal = {Annu. Rev. Neurosci.},
	author = {Wong, R O},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {29--47},
}

@article{klostermann_patterns_1999,
	title = {Patterns of spontaneous activity and morphology of interneuron types in organotypic cortex and thalamus-cortex cultures},
	volume = {92},
	abstract = {The physiological and morphological properties of interneurons in infragranular layers of rat visual cortex have been studied in organotypic cortex monocultures and thalamus-cortex co-cultures using intracellular recordings and biocytin injections. Cultures were prepared at the day of birth and maintained for up to 20 weeks. Twenty-nine interneurons of different types were characterized, in addition to 170 pyramidal neurons. The cultures developed a considerable degree of synaptically driven “spontaneous” bioelectric activity without epileptiform activity. Interneurons in cortex monocultures and thalamus-cortex co-cultures had the same physiological and morphological properties, and also pyramidal cell properties were not different in the two culture conditions. All interneurons and the majority of pyramidal cells displayed synaptically driven action potentials. The physiological group of fast-spiking interneurons included large basket cells, columnar basket cells (two cells with an arcade axon) and horizontally bitufted cells. The physiological group of slow-spiking interneurons included Martinotti cells and a “long-axon” cell. Analyses of the temporal patterns of activity revealed that fast-spiking interneurons have higher rates of spontaneous activity than slow-spiking interneurons and pyramidal cells. Furthermore, fast-spiking interneurons fired spontaneous bursts of action potentials in the gamma frequency range. We conclude from these findings that physiological and morphological properties of interneurons in organotypic mono- and co-cultures match those of interneurons characterized in vivo or in acute slice preparations, and they maintain in long-term cultures a well-balanced state of excitation and inhibition. This suggests that cortex-intrinsic or cell-autonomous mechanisms are sufficient for the expression of cell type-specific electrophysiological properties in the absence of afferents or sensory input.},
	number = {4},
	journal = {Neuroscience},
	author = {Klostermann, O and Wahle, P},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {1243--1259},
}

@article{moschovakis_microscopic_1996,
	title = {The microscopic anatomy and physiology of the mammalian saccadic system},
	volume = {50},
	abstract = {A central goal of the Neurosciences is to provide an account of how the brain works in terms of cell groups organised into pattern generating networks. This review focuses on the neural network that generates the rapid movements of the eyes that are called saccades. A brief description of the metrical and dynamical properties of saccades is provided first. Data obtained from lesion and electrical stimulation experiments are then described; these indicate that the relevant neural machinery spreads over at least 10 distinct cortical and subcortical regions of the brain. Each one of these regions harbors several distinct classes of saccade related cells (i.e. cells whose discharge encodes the metrical and often dynamical properties of saccades). The morphological and physiological properties of about 30 saccade related cell classes are described. To generate the signals they carry, and therefore saccades, distinct classes of cells influence each other in a non-random manner. Anatomical evidence is provided that indicates the existence of about 100 distinct connections established between saccade related neurons. The overall picture of the saccadic system that emerges from these studies is one of intricate complexity. In part this is due to the presence of at least 3, multiply interconnected negative feedback loops. Several computational models of the saccadic system have been proposed in an attempt to understand the functional significance of the simultaneous operation of these loops. An evaluation of these models demonstrates that besides providing a coherent summary of the data that concern it, successful models of the saccadic system generate realistic saccades (in precise quantitative psychophysical terms) when their elements are stimulated, produce abnormal saccades, reminiscent of those encountered in the clinic, when their elements are disabled, while their constituent units display realistic discharge patterns and are connected in a manner that respects anatomy.},
	number = {2-3},
	journal = {Prog. Neurobiol.},
	author = {Moschovakis, A K and Scudder, C A and Highstein, S M},
	month = oct,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {133--254},
}

@book{kandel_principles_2000,
	edition = {Fourth},
	title = {Principles of {Neural} {Science}},
	publisher = {McGraw-Hill Companies},
	editor = {Kandel, Eric R and Schwartz, James H and Jessell, Thomas M},
	year = {2000},
	keywords = {merged\_fiete.bib},
}

@article{sylvestre_quantitative_1999,
	title = {Quantitative analysis of abducens neuron discharge dynamics during saccadic and slow eye movements},
	volume = {82},
	abstract = {The mechanics of the eyeball and its surrounding tissues, which together form the oculomotor plant, have been shown to be the same for smooth pursuit and saccadic eye movements. Hence it was postulated that similar signals would be carried by motoneurons during slow and rapid eye movements. In the present study, we directly addressed this proposal by determining which eye movement-based models best describe the discharge dynamics of primate abducens neurons during a variety of eye movement behaviors. We first characterized abducens neuron spike trains, as has been classically done, during fixation and sinusoidal smooth pursuit. We then systematically analyzed the discharge dynamics of abducens neurons during and following saccades, during step-ramp pursuit and during high velocity slow-phase vestibular nystagmus. We found that the commonly utilized first-order description of abducens neuron firing rates (FR = b + kE + r, where FR is firing rate, E and are eye position and velocity, respectively, and b, k, and r are constants) provided an adequate model of neuronal activity during saccades, smooth pursuit, and slow phase vestibular nystagmus. However, the use of a second-order model, which included an exponentially decaying term or “slide” (FR = b + kE + r + uE - c), notably improved our ability to describe neuronal activity when the eye was moving and also enabled us to model abducens neuron discharges during the postsaccadic interval. We also found that, for a given model, a single set of parameters could not be used to describe neuronal firing rates during both slow and rapid eye movements. Specifically, the eye velocity and position coefficients (r and k in the above models, respectively) consistently decreased as a function of the mean (and peak) eye velocity that was generated. In contrast, the bias (b, firing rate when looking straight ahead) invariably increased with eye velocity. Although these trends are likely to reflect, in part, nonlinearities that are intrinsic to the extraocular muscles, we propose that these results can also be explained by considering the time-varying resistance to movement that is generated by the antagonist muscle. We conclude that to create realistic and meaningful models of the neural control of horizontal eye movements, it is essential to consider the activation of the antagonist, as well as agonist motoneuron pools.},
	number = {5},
	journal = {J. Neurophysiol.},
	author = {Sylvestre, P A and Cullen, K E},
	month = nov,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {2612--2632},
}

@article{delgado-garcia_behavior_1986,
	title = {Behavior of neurons in the abducens nucleus of the alert cat–{I}. {Motoneurons}},
	volume = {17},
	abstract = {The activity of 53 antidromically identified abducens motoneurons was analyzed in alert cats during spontaneous and vestibular induced eye movements. Conduction velocities ranged from 13 to 70 m/s and all motoneurons increased their discharge rates with successive eye positions in the abducting direction. Motoneurons were recruited from -19 degrees to +7 degrees. Within the oculomotor range frequency saturation was never observed for any cell. The slope of rate-position (k) relationships ranged from 2 to 17.7 spikes/s/deg (n = 40, mean 8.7 +/- 2.5). Regression analysis showed that the rate-position plots could be fit by straight lines but in most cases exponential curves produced slightly better statistical fits. Steeper slopes suggest that successively larger increases in k are required for the lateral rectus muscle to maintain more eccentric fixations in the on direction. Interspike intervals for a constant eye position exhibited low variability (less than 3.5\%) for fixations shorter than 1 s. Over longer periods, variability increased in proportion to the duration of the fixation in exponential-like fashion up to 14\%. Abducens motoneurons showed considerable variability in frequency during repeated fixations of the same eye position. Discharge rates were found to depend upon both the direction of the previous eye movement and, more importantly, the animal's level of alertness. The rate-position regression lines for fixation periods after saccades in the on direction significantly differed in slopes (100\%) and thresholds (20\%) from those in the off direction. The observed static hysteresis in abducens motoneuron behavior was in opposite direction to that previously described for the mechanical properties of the lateral rectus. This suggests both neural and mechanical factors are significantly involved in determining final eye position. The animal's level of alertness was evaluated in this study by counting the number of saccadic movements/s occurring in “alert” (1 +/- 0.2 saccades/s), and “drowsy” (0.5 +/- 0.2 saccades/s) circumstances. Comparison of the rate-position regression lines between the two conditions showed a significant decrease in slopes (100\%) and elevation of thresholds (70\%). Discharge rate of abducens motoneurons increased abruptly 8.9 +/- 2.8 ms prior to saccades in the horizontal on direction, and decreased 14.8 +/- 4.05 m before saccades in the off direction. During purely vertical saccades the firing frequency of abducens motoneurons did not change. Burst frequency did not saturate during saccades, but increased with saccadic velocity in a linear fashion.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {4},
	journal = {Neuroscience},
	author = {Delgado-Garcia, J M and del F, Pozo and Baker, R},
	month = apr,
	year = {1986},
	keywords = {merged\_fiete.bib},
	pages = {929--952},
}

@article{delgado-garcia_behavior_1986-1,
	title = {Behavior of neurons in the abducens nucleus of the alert cat–{II}. {Internuclear} neurons},
	volume = {17},
	abstract = {The activity of 43 antidromically identified abducens internuclear neurons with conduction velocities ranging from 14 to 54 m/s was analyzed in alert cats during spontaneous and vestibular induced eye movements. The discharge rate of internuclear neurons significantly increased with successive adducting positions of the contralateral eye. Slopes of rate-position (k) relationships ranged from 3.1 to 17.9 spikes/deg (mean 12.01 +/- 3.1). Threshold ranged from -19 degrees to +3 degrees. Frequency saturation was never observed for any internuclear neuron within the oculomotor range. Although straight lines were selected to illustrate the rate-position relationships, exponential curves always provided the best statistical fit demonstrating that an enhancement in frequency potentiation (k) must accompany more eccentric fixations in the on direction. Internuclear neurons showed a low variability in firing rate (less than 3.0\%) for fixations less than 1 s. Variability increased with both longer and repeated fixations of the same eye position. Discharge rates were found to depend upon both the direction of the preceding eye movement and the animal's level of alertness. Separate regression lines of rate-position relations following saccades in the on and off directions differed significantly in slope (100\%), but not threshold. The observed static hysteresis in an identified non-motoneuron shows this property to be in a central neural circuit prior to the extraocular motoneuron. The slopes (k) of rate-position plots for all internuclear neurons decreased significantly (100\%) when level of alertness changed from “alert” (1 +/- 0.2 saccades/s) to “drowsy” (0.5 +/- 0.2 saccades/s). Thresholds, however, were not significantly altered. Discharge rate of abducens internuclear neurons increased abruptly 10.4 +/- 2.5 ms preceding saccades in the on direction, and decreased 20.5 +/- 7.8 ms before saccades in the off direction. Internuclear neuronal activity was not affected by pure vertical saccades. During on direction saccades, firing frequency did not saturate, but increased with velocity in a linear fashion. Exponential functions often fit the data better due to the difference in slopes of rate-velocity plots for on vs off direction saccades. Slopes (rs) of rate-velocity regression lines during spontaneous saccades ranged from 0.99 to 4.10 spikes/s/deg/s (mean 2.16 +/- 0.93). During saccades in the off direction activity always decreased, but it seldom ceased. Rate-velocity regression lines measured during the fast phase of vestibular nystagmus (rsv = 2.09 +/- 0.88) showed no significant differences from rs slopes in 82\% of the cases.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {4},
	journal = {Neuroscience},
	author = {Delgado-Garcia, J M and del F, Pozo and Baker, R},
	month = apr,
	year = {1986},
	keywords = {merged\_fiete.bib},
	pages = {953--973},
}

@article{fuchs_discharge_1988,
	title = {Discharge patterns and recruitment order of identified motoneurons and internuclear neurons in the monkey abducens nucleus},
	volume = {60},
	abstract = {1. Single neurons in the abducens nucleus were recorded extracellularly in alert rhesus macaques trained to make a variety of eye movements. An abducens neurons was identified as a motoneuron (MN) if its action potentials triggered an averaged EMG potential in the lateral rectus muscle. Abducens internuclear neurons (INNs) that project to the oculomotor nucleus were identified by collision block of spontaneous with antidromic action potentials evoked with a stimulating electrode placed in the medial rectus subdivision of the contralateral oculomotor nucleus. 2. All abducens MNs and INNs had qualitatively similar discharge patterns consisting of a burst of spikes for lateral saccades and a steady firing whose rate increased with lateral eye position in excess of a certain threshold. 3. For both MNs and INNs the firing rates associated with different, constant eye positions could be described accurately by a straight line with slope, K (the eye position sensitivity in spikes.s-1.deg-1), and intercept, T (the eye position threshold for steady firing). For different MNs, K increased as T varied from more medial to more lateral values. In contrast, the majority of INNs already were active for values of T more medial than 20 degrees and showed little evidence of recruitment according to K. 4. During horizontal sinusoidal smooth-pursuit eye movements, both MNs and INNs exhibited a sinusoidal modulation in firing rate whose peak preceded eye position. From these firing rate patterns, the component of firing rate related to eye velocity, R (the eye velocity sensitivity in spikes.s-1.deg-1.s-1), was determined. The R for INNs was, on average, 78\% larger than that for MNs. Furthermore, R increased with T for MNs, whereas INNs showed no evidence of recruitment according to R. If, as in the cat, the INNs of monkeys provide the major input to medial rectus MNs and if simian medial rectus MNs behave like our abducens MNs, then recruitment order, which is absent in INNs, must be established at the MN pool itself. 5. Unexpectedly, the R of MNs decreased with the frequency of the smooth-pursuit movement. Furthermore, the eye position sensitivity, K, obtained during steady fixations was usually less than that determined during smooth pursuit. Therefore, conclusions about the roles of MNs and premotor neurons based on how their R and K values differ must be viewed with caution if the data have been obtained under different tracking conditions.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {6},
	journal = {J. Neurophysiol.},
	author = {Fuchs, A F and Scudder, C A and Kaneko, C R},
	month = dec,
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {1874--1895},
}

@article{stahl_dynamics_1995,
	title = {Dynamics of abducens nucleus neurons in the awake rabbit},
	volume = {73},
	abstract = {1. We recorded abducens neurons, identified by electrical stimulation as internuclear neurons or motoneurons, in awake rabbits. The relationship of firing rate to eye movement was determined from responses during stable fixations, sinusoidal rotation in the light (0.05-0.8 Hz), and triangular optokinetic stimulation at 0.1 Hz. 2. All abducens neurons were excited during temporal movement of the ipsilateral eye. Temporal and nasal saccades were associated with bursts or pauses, respectively, in the firing rate. 3. Motoneurons and internuclear neurons are qualitatively indistinguishable. There was no significant quantitative difference between the phase and sensitivity of the two groups for 0.2-Hz sinusoidal rotation in the light. 4. On the basis of the response to stable eye positions, we determined static eye position sensitivity of the abducens neuron pool to be 8.2 +/- 2.5 (SD) spikes.s-1/0, with a static hysteresis of 8.9 spikes/s (1.14 +/- 0.37 degrees). 5. We determined apparent eye position sensitivity (k) and apparent eye velocity sensitivity (r) from the responses to sinusoidal rotation in the light. k increases and r decreases with stimulus frequency, which indicates that the simplest transfer function mediating conversion of abducens nucleus (VI) firing rate to eye position (E) has two poles and one zero. 6. The VI–{\textgreater}E relationship has an “amplitude nonlinearity,” manifest as a tendency for k, r, and firing rate phase lead to decrease as eye movement amplitude increases at a fixed frequency. On a percentage basis, phase is less affected than are the sensitivities. The nonlinearity becomes less pronounced for stimulus amplitudes {\textgreater} 2.5 degrees, and consequently a linear model of the VI–{\textgreater}E transformation remains useful, provided that consideration is restricted to the appropriate range of stimulus/response amplitudes. 7. We determined time constants of the linear two-pole, one-zero transfer function from the variation of r/k versus stimulus frequency. The pole time constants were T1 = 3.4 s and T2 = 0.28 s, and the zero time constant (Tz) = 1.6 s. The magnitude of Tz was corroborated by measuring the time constant of the exponential decay in firing rate after step changes in eye position. This transient method yielded a Tz of 1.1 s. 8. The time constants of the VI–{\textgreater}E transfer function are roughly 10 times larger than those reported for the rhesus macaque. The difference is attributable to the reported 10-fold lower stiffness of the rabbit oculomotor plant, which may in turn relate to rabbits postulated lower degree of activation of extraocular muscles at any given position.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Stahl, J S and Simpson, J I},
	month = apr,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {1383--1395},
}

@article{sharp_anticipatory_1997,
	title = {Anticipatory time intervals of head-direction cells in the anterior thalamus of the rat: implications for path integration in the head-direction circuit},
	volume = {78},
	abstract = {Head-direction cells are neurons that signal a rat's directional heading in the horizontal plane. Head-direction cells in the anterior thalamus are anticipatory, so that their firing rate is better correlated with the rat's future head direction than with the present or past head direction. We recorded single-unit activity from head-direction cells in the anterior thalamus of freely moving rats. We measured the time interval by which each individual cell anticipated the rat's future head direction, which we refer to as the cell's anticipatory time interval (ATI). Head-direction cells in the anterior thalamus anticipated the rat's future head direction by an average ATI of approximately 17 ms. However, different anterior thalamic cells consistently anticipated the future head direction by different ATIs ranging between 0 and 50 ms. We found that the ATI of an anterior thalamic head-direction cell was correlated with several parameters of the cell's directional tuning function. First, cells with long ATIs sometimes appeared to have two peaks in their directional tuning function, whereas cells with short ATIs always had only one peak. Second, the ATI of a cell was negatively correlated with the cell's peak firing rate, so that cells with longer ATIs fired at a slower rate than cells with shorter ATIs. Third, a cell's ATI was correlated with the width of its directional tuning function, so that cells with longer ATIs had broader tuning widths than cells with shorter ATIs. These relationships between a cell's ATI and its directional tuning parameters could not be accounted for by artifactual broadening of the tuning function, which occurs for cells that fire in correlation with the future (rather than present) head direction. We found that when the rat's head is turning, the shape of an anterior thalamic head-direction cell's tuning function changes in a systematic way, becoming taller, narrower, and skewed. This systematic change in the shape of the tuning function may be what causes anterior thalamic cells to effectively anticipate the rat's future head direction. We propose a neural circuit mechanism to account for the firing behavior we have observed in our experiments, and we discuss how this circuit might serve as a functional component of a neural system for path integration of the rat's directional heading.},
	number = {1},
	journal = {J. Neurophysiol.},
	author = {Sharp, Ht Blair and Lipscomb, Bw and {Pe}},
	month = jul,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {145--159},
}

@article{cho_anatomical_2001,
	title = {The anatomical and computational basis of the rat head-direction cell signal},
	volume = {24},
	abstract = {As a rat navigates through space, neurons called head-direction (HD) cells provide a signal of the rat's momentary directional heading. Although partly guided by landmarks, the cells also show a remarkable ability to track directional heading based on angular head movement. Theoretical models suggest that the HD cells are linked together to form an attractor network, and that cells which signal angular velocity update the directional setting of the attractor. Recently, cell types similar to those required theoretically have been discovered in the lateral mammillary and dorsal tegmental nuclei. Lesion and anatomical data suggest these nuclei might constitute the postulated attractor-path integration mechanism, and that they provide the HD cell signal to cortical areas where it has been observed.},
	number = {5},
	journal = {Trends Neurosci.},
	author = {Cho, Pe Sharp and Blair, Ht and {J}},
	month = may,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {289--294},
}

@article{smith_characterisation_2000,
	title = {Characterisation of inhibitory and excitatory postsynaptic currents of the rat medial superior olive},
	volume = {529 Pt 3},
	abstract = {The medial superior olive (MSO) is part of the binaural auditory pathway, receiving excitatory projections from both cochlear nuclei and an inhibitory input from the ipsilateral medial nucleus of the trapezoid body (MNTB). We characterised the excitatory and inhibitory synaptic currents of MSO neurones in 3- to 14-day-old rats using whole-cell patch-clamp methods in a brain slice preparation.A dual component EPSC was mediated by AMPA and NMDA receptors. The AMPA receptor-mediated EPSC decayed with a time constant of 1.99+/-0.16 ms (n = 8). Following blockade of glutamate receptors, a monosynaptic strychnine-sensitive response was evoked on stimulation of the MNTB, indicative of a glycine receptor-mediated IPSC. GABAA receptors contributed to IPSCs in rats under 6 days old (bicuculline blocked 30\% of the IPSC). In older rats little or no bicuculline-sensitive component was detectable, except in the presence of flunitrazepam. These glycinergic IPSCs showed a reversal potential that varied with changes in [Cl-]i, as predicted by the Nernst equation. The IPSC exhibited two developmentally relevant changes. (i) At around postnatal day 6, the GABAA receptor-mediated component declined, leaving a predominant glycine-mediated IPSC. The isolated glycinergic IPSC decayed with time constants of 7.8+/-0.3 and 38.3+/-1.7 ms, with the slower component contributing 7.8+/-0.6\% of the peak amplitude (n = 121, 3-11 days old, -70 mV, 25 deg C). (ii) After day 11 the IPSC fast decay accelerated to 3.9+/-0.3 ms (n = 12) and the magnitude of the slow component declined to less than 1\%. Spontaneous miniature glycinergic IPSCs (mIPSCs) were variable in amplitude and were of large conductance (1.83+/-0.19 nS, n = 8). The amplitude was unchanged on lowering [Ca2+]o. The time course of evoked and spontaneous miniature glycinergic IPSCs were compared. The 10-90\% rise times were 0.7 and 0.6 ms, respectively. The evoked IPSC decayed with a fast time constant of 7.2+/-0.7 ms, while the mIPSC decayed with a fast time constant of 5.3+/-0.4 ms in the same seven cells.The glycinergic IPSC decay was voltage dependent with an e-fold change over 118 mV. The temperature dependence of the IPSC decay indicated a Q10 value of 2.Picrotoxin and cyanotriphenylborate had little or no effect on IPSCs from 6- to 14-day-old animals, implying homomeric channels are rare. We conclude that the MSO receives excitatory inputs mediated by AMPA and NMDA receptors and a strong glycinergic IPSC which has a significant contribution from GABAA receptors in neonatal rats. Functionally, the IPSC could increase membrane conductance during the decay of binaural glutamatergic EPSCs, thus refining coincidence detection and interaural timing differences.},
	journal = {J. Physiol.},
	author = {Smith, Aj and Owens, S and Forsythe, Id},
	month = dec,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {681--698},
}

@article{thorpe_speed_1996-1,
	title = {Speed of processing in the human visual system},
	volume = {381},
	abstract = {How long does it take for the human visual system to process a complex natural image? Subjectively, recognition of familiar objects and scenes appears to be virtually instantaneous, but measuring this processing time experimentally has proved difficult. Behavioural measures such as reaction times can be used, but these include not only visual processing but also the time required for response execution. However, event-related potentials (ERPs) can sometimes reveal signs of neural processing well before the motor output. Here we use a go/no-go categorization task in which subjects have to decide whether a previously unseen photograph, flashed on for just 20 ms, contains an animal. ERP analysis revealed a frontal negativity specific to no-go trials that develops roughly 150 ms after stimulus onset. We conclude that the visual processing needed to perform this highly demanding task can be achieved in under 150 ms.},
	number = {6582},
	journal = {Nature},
	author = {Thorpe, S and Fize, D and Marlot, C},
	month = jun,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {520--522},
}

@article{salzman_neural_1994,
	title = {Neural mechanisms for forming a perceptual decision},
	volume = {264},
	abstract = {Cognitive and behavioral responses to environmental stimuli depend on an evaluation of sensory signals within the cerebral cortex. The mechanism by which this occurs in a specific visual task was investigated with a combination of physiological and psychophysical techniques. Rhesus monkeys discriminated among eight possible directions of motion while directional signals were manipulated in visual area MT. One directional signal was generated by a visual stimulus and a second signal was introduced by electrically stimulating neurons that encoded a specific direction of motion. The decisions made by the monkeys in response to the two signals allowed a distinction to be made between two possible mechanisms for interpreting directional signals in MT. The monkeys tended to cast decisions in favor of one or the other signal, indicating that the signals exerted independent effects on performance and that an interactive mechanism such as vector averaging of the two signals was not operative. Thus, the data suggest a mechanism in which monkeys chose the direction encoded by the largest signal in the representation of motion direction, a “winner-take-all” decision process.},
	number = {5156},
	journal = {Science},
	author = {Salzman, Cd and Newsome, Wt},
	month = apr,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {231--237},
}

@article{spiro_long-range_1999,
	title = {Long-{Range} {Inhibition} {Within} the {Zebra} {Finch} {Song} {Nucleus} {RA} {Can} {Coordinate} the {Firing} of {Multiple} {Projection} {Neurons}},
	volume = {81},
	abstract = {The zebra finch forebrain song control nucleus RA (robust nucleus of the archistriatum) generates a phasic and temporally precise neural signal that drives vocal and respiratory motoneurons during singing. RA's output during singing predicts individual notes, even though afferent drive to RA from the song nucleus HVc is more tonic, and predicts song syllables, independent of the particular notes that comprise the syllable. Therefore RA's intrinsic circuitry transforms neural activity from HVc into a highly precise premotor output. To understand how RA's intrinsic circuitry effects this transformation, we characterized RA interneurons and projection neurons using intracellular recordings in brain slices. RA interneurons fired fast action potentials with steep current-frequency relationships and had small somata with thin aspinous processes that extended throughout large portions of the nucleus; the similarity of their fine processes to those labeled with a glutamic acid decarboxylase (GAD) antibody strongly suggests that these interneurons are GABAergic. Electrical stimulation revealed that RA interneurons receive excitatory inputs from RA's afferents, the lateral magnocellular nucleus of the anterior neostriatum (LMAN) and HVc, and from local axon collaterals of RA projection neurons. To map the functional connections that RA interneurons make onto RA projection neurons, we focally uncaged glutamate, revealing long-range inhibitory connections in RA. Thus these interneurons provide fast feed-forward and feedback inhibition to RA projection neurons and could help create the phasic pattern of bursts and pauses that characterizes RA output during singing. Furthermore, selectively activating the inhibitory network phase locks the firing of otherwise unconnected pairs of projection neurons, suggesting that local inhibition could coordinate RA output during singing.},
	number = {6},
	journal = {J. Neurophysiol.},
	author = {Spiro, John E and Dalva, Matthew B and Mooney, Richard},
	month = jun,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {3007--3020},
}

@article{treue_seeing_2000,
	title = {Seeing multiple directions of motion-physiology and psychophysics},
	volume = {3},
	abstract = {Dot patterns sliding transparently across one another are normally perceived as independently moving surfaces. Recordings from direction-selective neurons in area MT of the macaque suggested that this perceptual segregation did not depend on the presence of two peaks in the population activity. Rather, the visual system seemed to use overall shape of the population response to determine the number and directions of motion components. This approach explained a number of perceptual phenomena, including susceptibility of the motion system to direction metamers, motion patterns combining three or five directions incorrectly perceived by subjects as comprising only two directions. Our findings offer insights into the coding of multi-valued sensory signals and provide constraints for biologically based computational models.},
	number = {3},
	journal = {Nat. Neurosci.},
	author = {Treue, S and Hol, K and Rauber, Hj},
	month = mar,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {270--276},
}

@article{marshak_mutual_1979,
	title = {Mutual repulsion between moving visual targets},
	volume = {205},
	abstract = {When two spatially intermingled sets of random dots move in different directions, the direction of each set may be misperceived. Observers report that each set of dots appears to move in a direction displaced by as much as 20 degrees from the direction of its companion set. Probably the result of inhibitory interactions, this mutual repulsion occurs at a central site in the visual system and may normally enhance discrimination of direction.},
	number = {4413},
	journal = {Science},
	author = {Marshak, W and Sekuler, R},
	month = sep,
	year = {1979},
	keywords = {merged\_fiete.bib},
	pages = {1399--1401},
}

@article{raymond_learning_1998,
	title = {Learning in the oculomotor system: from molecules to behavior},
	volume = {8},
	abstract = {A combination of system-level and cellular-molecular approaches is moving studies of oculomotor learning rapidly toward the goal of linking synaptic plasticity at specific sites in oculomotor circuits with changes in the signal-processing functions of those circuits, and, ultimately, with changes in eye movement behavior. Recent studies of saccadic adaptation illustrate how careful behavioral analysis can provide constraints on the neural loci of plasticity. Studies of vestibulo-ocular adaptation are beginning to examine the molecular pathways contributing to this form of cerebellum-dependent learning.},
	number = {6},
	journal = {Curr. Opin. Neurobiol.},
	author = {Raymond, Jl},
	month = dec,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {770--776},
}

@article{straube_characteristics_1997,
	title = {Characteristics of saccadic gain adaptation in rhesus macaques},
	volume = {77},
	abstract = {We adapted the saccadic gain (saccadic amplitude/target step amplitude) by requiring monkeys to track a small spot that stepped to one side by 5, 10, or 15 degrees and then, during the initial targeting saccade, jumped either forward or backward by a fixed percentage of the initial step. Saccadic gain increased or decreased, respectively, as a function of the number of adapting saccades made in that direction. The relation between gain and the number of adapting saccades was fit with an exponential function, yielding an asymptotic gain and a rate constant (the number of saccades to achieve 63\% of the total change in gain). Backward intrasaccadic target jumps of 15, 30, and 50\% of the initial target step reduced the asymptotic gain by an average of 12.2, 23.1, and 36.4\%, respectively, with average rate constants of 163, 368, and 827 saccades, respectively. During 50\% backward jumps, some saccades, especially those to larger target steps, became slower and lasted longer. Forward intrasaccadic jumps of 30\% increased the asymptotic gain by 23.3\% (average rate constant of 1,178 saccades). After we had caused adaptation, we induced recovery of gain toward normal by requiring the animal to track target steps without intrasaccadic jumps. Recovery following forward adaptation required about one third fewer saccades than the preceding gain increase. Recovery following backward adaptation required about the same average number of saccades as the preceding gain decrease. The first saccades of recovery were slightly less adapted than the last saccades of adaptation, suggesting that a small part of adaptation might have been strategic. After 50\% backward jumps had reduced saccadic gain, the hypometric primary saccades during recovery were followed by hypometric corrective saccades, suggesting that they too had been adapted. When saccades of only one size underwent gain reduction, saccades to target steps of other amplitudes showed much less adaptation. Also, saccades in the direction opposite to that adapted were not adapted. Gain reductions endured if an adapted animal was placed in complete darkness for 20 h. These data indicate that saccadic gain adaptation is relatively specific to the adapted step and does not produce parametric changes of all saccades. Furthermore, adaptation is not a strategy, but involves enduring neuronal reorganization in the brain. We suggest that this paradigm engages mechanisms that determine saccadic gain in real life and therefore offers a reversible means to study their neuronal substrate.},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Straube, A and Fuchs, Af and Usher, S and Robinson, Fr},
	month = feb,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {874--895},
}

@article{raymond_neural_1998,
	title = {Neural learning rules for the vestibulo-ocular reflex},
	volume = {18},
	abstract = {Mechanisms for the induction of motor learning in the vestibulo-ocular reflex (VOR) were evaluated by recording the patterns of neural activity elicited in the cerebellum by a range of stimuli that induce learning. Patterns of climbing-fiber, vestibular, and Purkinje cell simple-spike signals were examined during sinusoidal head movement paired with visual image movement at stimulus frequencies from 0.5 to 10 Hz. A comparison of simple-spike and vestibular signals contained the information required to guide learning only at low stimulus frequencies, and a comparison of climbing-fiber and simple-spike signals contained the information required to guide learning only at high stimulus frequencies. Learning could be guided by comparison of climbing-fiber and vestibular signals at all stimulus frequencies tested, but only if climbing fiber responses were compared with the vestibular signals present 100 msec earlier. Computational analysis demonstrated that this conclusion is valid even if there is a broad range of vestibular signals at the site of plasticity. Simulations also indicated that the comparison of vestibular and climbing-fiber signals across the 100 msec delay must be implemented by a subcellular “eligibility” trace rather than by neural circuits that delay the vestibular inputs to the site of plasticity. The results suggest two alternative accounts of learning in the VOR. Either there are multiple mechanisms of learning that use different combinations of neural signals to drive plasticity, or there is a single mechanism tuned to climbing-fiber activity that follows activity in vestibular pathways by approximately 100 msec.},
	number = {21},
	journal = {J. Neurosci.},
	author = {Raymond, Jl and Lisberger, Sg},
	month = nov,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {9112--9129},
}

@article{galiana_comparison_1995,
	title = {Comparison of linear vs. non-linear methods for analysing the vestibulo-ocular reflex ({VOR})},
	volume = {115},
	abstract = {The vestibulo-ocular reflex (VOR) is traditionally evaluated by the gain (sensitivity) and offset (bias) of nystagmus slow phases during sinusoidal, passive, head rotation in the dark. The analysis methods used are typically only truly applicable to linear systems, but are widely used despite the fact that the VOR has been known to be non-linear since the 19th century. We show here that the parameters obtained by linear methods, with data derived from a non-linear system, can be very noisy and unreliable. The questions are: under what conditions can linear approximations be tolerated, or justified, and can an analysis approach be devised which inherently tolerates non-linearities? Using both simulated and experimental data, it is found that assuming linear analysis methods can produce variable VOR gains and erroneous estimates of the VOR bias. changing with the selected oscillation protocol. Examples of' parameter distortions in bias and VOR gain are first given using simulated data relating slow phase eye velocity to head velocity, at different peak velocities. The relevance of these distortions is then illustrated with selected examples from a database of recordings on normals and unilateral vestibular patients, during rotations in the dark 1/6 Hz and maximum speeds of 90 to 180 degrees/s. More consistent estimates of the gain and bias can be found by properly correcting for phase differences between head and eve velocity, and allowing for non-linear reflex properties. Special indices are suggested to decide whether a particular subject's VOR should be considered non-linear, in order to select the appropriate representation in each case, before estimating VOR characteristics. Selecting the appropriate model (linear or non-linear) will contribute to a better unmasking of parametric trends in the VOR, when comparing normal vs. acute-lesioned subjects, or acute vs, compensated patients. These results have many implications for the design of clinical vestibular protocols and in the evaluation of patient functional deficits.},
	number = {5},
	journal = {Acta Otolaryngol.},
	author = {Galiana, Hl and Smith, Hl and Katsarkas, A},
	month = sep,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {585--596},
}

@article{fukushima_neuronal_1992,
	title = {The neuronal substrate of integration in the oculomotor system},
	volume = {39},
	number = {6},
	journal = {Prog. Neurobiol.},
	author = {Fukushima, K and Kaneko, Cr and Fuchs, Af},
	month = dec,
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {609--639},
}

@article{rush_potassium_1995,
	title = {The {Potassium} {A}-current, low firing rates and rebound excitation in {Hodgkin}-{Huxley} models},
	volume = {57},
	abstract = {It is widely believed, following the work of Connor and Stevens (1971, J. Physiol. Lond. 214, 31-53) that the ability to fire action potentials over a wide frequency range, especially down to very low rates, is due to the transient, potassium A-current (IA). Using a reduction of the classical Hodgkin-Huxley model, we study the effects of IA on steady firing rate, especially in the near-threshold regime for the onset of firing. A minimum firing rate of zero corresponds to a homoclinic bifurcation of periodic solutions at a critical level of stimulating current. It requires that the membrane's steady-state current-voltage relation be N-shaped rather than monotonic. For experimentally based generic IA parameters, the model does not fire at arbitrarily low rates, although it can for the more atypical IA parameters given by Connor and Stevens for the crab axon. When the IA inactivation rate is slow, we find that the transient potassium current can mediate more complex firing patterns, such as periodic bursting in some parameter regimes. The number of spikes per burst increases as gA decreases and as inactivation rate decreases. We also study how IA affects properties of transient voltage responses, such as threshold and firing latency for anodal break excitation. We provide mathematical explanations for several of these dynamic behaviors using bifurcation theory and averaging methods.},
	number = {6},
	journal = {Bull. Math. Biol.},
	author = {Rush, Maureen E and Rinzel, John},
	month = nov,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {899--929},
}

@article{rao_destruction_nodate,
	title = {Destruction and creation of spatial tuning by disinhibition: {GABA}({A}) blockade of prefrontal cortical neurons engaged by working memory},
	abstract = {Local circuit neurons in the dorsolateral prefrontal cortex (dPFC) of monkeys have been implicated in the cellular basis of working memory. To further elucidate the role of inhibition in spatial tuning, we iontophoresed bicuculline methiodide (BMI) onto functionally characterized neurons in the dPFC of monkeys performing an oculomotor delayed response task. This GABA(A) blockade revealed that both putative interneurons and pyramidal cells possess significant inhibitory tone in the awake, behaving monkey. In addition, BMI application primarily resulted in the loss of previously extant spatial tuning in both cell types through reduction of both isodirectional and cross-directional inhibition. This tuning loss occurred in both the sensorimotor and mnemonic phases of the task, although the delay activity of prefrontal neurons appeared to be particularly affected. Finally, application of BMI also created significant spatial tuning in a sizable minority of units that were untuned in the control condition. Visual field analysis of such tuning suggests that it is likely caused by the unmasking of normally suppressed spatially tuned excitatory input. These findings provide the first direct evidence of directional inhibitory modulation of pyramidal cell and interneuron firing in both the mnemonic and sensorimotor phases of the working memory process, and they implicate a further role for GABAergic interneurons in the construction of spatial tuning in prefrontal cortex.},
	author = {Rao, Sg and Williams, Gv and Rakic, Goldman-Ps},
	keywords = {merged\_fiete.bib},
}

@article{malenka_long-term_nodate,
	title = {Long-term potentiation–a decade of progress},
	abstract = {Long-term potentiation of synaptic transmission in the hippocampus is the leading experimental model for the synaptic changes that may underlie learning and memory. This review presents a current understanding of the molecular mechanisms of this long-lasting increase in synaptic strength and describes a simple model that unifies much of the data that previously were viewed as contradictory.},
	author = {Malenka, Rc and Nicoll, Ra},
	keywords = {merged\_fiete.bib},
}

@article{albright_neural_nodate,
	title = {Neural science: a century of progress and the mysteries that remain},
	author = {Albright, Td and Jessell, Tm and Kandel, Er and Posner, Mi},
	keywords = {merged\_fiete.bib},
}

@article{muller_information_nodate,
	title = {Information conveyed by onset transients in responses of striate cortical neurons},
	abstract = {Normal eye movements ensure that the visual world is seen episodically, as a series of often stationary images. In this paper we characterize the responses of neurons in striate cortex to stationary grating patterns presented with abrupt onset. These responses are distinctive. In most neurons the onset of a grating gives rise to a transient discharge that decays with a time constant of 100 msec or less. The early stages of response have higher contrast gain and higher response gain than later stages. Moreover, the variability of discharge during the onset transient is disproportionately low. These factors together make the onset transient an information-rich component of response, such that the detectability and discriminability of stationary gratings grows rapidly to an early peak, within 150 msec of the onset of the response in most neurons. The orientation selectivity of neurons estimated from the first 150 msec of discharge to a stationary grating is indistinguishable from the orientation selectivity estimated from longer segments of discharge to moving gratings. Moving gratings are ultimately more detectable than stationary ones, because responses to the former are continuously renewed. The principal characteristics of the response of a neuron to a stationary grating-the initial high discharge rate, which decays rapidly, and the change of contrast gain with time-are well captured by a model in which each excitatory synaptic event leads to an immediate reduction in synaptic gain, from which recovery is slow.},
	author = {Muller, Jr and Metha, Ab and Krauskopf, J and Lennie, P},
	keywords = {merged\_fiete.bib},
}

@article{lamme_distinct_nodate,
	title = {The distinct modes of vision offered by feedforward and recurrent processing},
	abstract = {An analysis of response latencies shows that when an image is presented to the visual system, neuronal activity is rapidly routed to a large number of visual areas. However, the activity of cortical neurons is not determined by this feedforward sweep alone. Horizontal connections within areas, and higher areas providing feedback, result in dynamic changes in tuning. The differences between feedforward and recurrent processing could prove pivotal in understanding the distinctions between attentive and pre-attentive vision as well as between conscious and unconscious vision. The feedforward sweep rapidly groups feature constellations that are hardwired in the visual brain, yet is probably incapable of yielding visual awareness; in many cases, recurrent processing is necessary before the features of an object are attentively grouped and the stimulus can enter consciousness.},
	author = {Lamme, Va and Roelfsema, Pr},
	keywords = {merged\_fiete.bib},
}

@article{nelson_orientation_nodate,
	title = {Orientation selectivity of cortical neurons during intracellular blockade of inhibition},
	abstract = {Neurons in the primary visual cortex of the cat are selectively activated by stimuli with particular orientations. This selectivity can be disrupted by the application of antagonists of the inhibitory neurotransmitter gamma-aminobutyric acid (GABA) to a local region of the cortex. In order to determine whether inhibitory inputs are necessary for a single cortical neuron to show orientation selectivity, GABA receptors were blocked intracellularly during whole cell recording. Although the membrane potential, spontaneous activity, subfield antagonism, and directional selectivity of neurons were altered after they were perfused internally with the blocking solution, 18 out of 18 neurons remained selective for stimulus orientation. These results indicate that excitatory inputs are sufficient to generate orientation selectivity.},
	author = {Nelson, S and Toth, L and Sheth, B and Sur, M},
	keywords = {merged\_fiete.bib},
}

@article{ferster_neural_nodate,
	title = {Neural mechanisms of orientation selectivity in the visual cortex},
	abstract = {The origin of orientation selectivity in the responses of simple cells in cat visual cortex serves as a model problem for understanding cortical circuitry and computation. The feed-forward model posits that this selectivity arises simply from the arrangement of thalamic inputs to a simple cell. Much evidence, including a number of recent intracellular studies, supports a primary role of the thalamic inputs in determining simple cell response properties, including orientation tuning. This mechanism alone, however, cannot explain the invariance of orientation tuning to changes in stimulus contrast. Simple cells receive push-pull inhibition: ON inhibition in OFF subregions and vice versa. Addition of such inhibition to the feed-forward model can account for this contrast invariance, provided the inhibition is sufficiently strong. The predictions of “normalization” and “feedback” models are reviewed and compared with the predictions of this modified feed-forward model and with experimental results. The modified feed-forward and the feedback models ascribe fundamentally different functions to cortical processing.},
	author = {Ferster, D and Miller, Kd},
	keywords = {merged\_fiete.bib},
}

@article{ferster_orientation_nodate,
	title = {Orientation selectivity of thalamic input to simple cells of cat visual cortex},
	abstract = {More than 30 years after Hubel and Wiesel first described orientation selectivity in the mammalian visual cortex, the mechanism that gives rise to this property is still controversial. Hubel and Wiesel proposed a simple model for the origin of orientation tuning, in which the circularly symmetrical receptive fields of neurons in the lateral geniculate nucleus that excite a cortical simple cell are arranged in rows. Since this model was proposed, several experiments and neuronal simulations have suggested that the connectivity between the lateral geniculate nucleus and the cortex is not well organized in an orientation-specific fashion, and that orientation tuning arises instead from extensive interactions within the cortex. To test these models we have recorded visually evoked synaptic potentials in simple cells while cooling the cortex, which largely inactivates the cortical network, but leaves geniculate synaptic input functional. We report that the orientation tuning of these potentials is almost unaffected by cooling the cortex, in agreement with Hubel and Wiesel's original proposal.},
	author = {Ferster, D and Chung, S and Wheat, H},
	keywords = {merged\_fiete.bib},
}

@article{sompolinsky_new_nodate,
	title = {New perspectives on the mechanisms for orientation selectivity},
	abstract = {Since the discovery of orientation selectivity by Hubel and Wiesel, the mechanisms responsible for this remarkable operation in the visual cortex have been controversial. Experimental studies over the past year have highlighted the contribution of feedforward thalamo-cortical afferents, as proposed originally by Hubel and Wiesel, but they have also indicated that this contribution alone is insufficient to account for the sharp orientation tuning observed in the visual cortex. Recent advances in understanding the functional architecture of local cortical circuitry have led to new proposals for the involvement of intracortical recurrent excitation and inhibition in orientation selectivity. Establishing how these two mechanisms work together remains an important experimental and theoretical challenge.},
	author = {Sompolinsky, H and Shapley, R},
	keywords = {merged\_fiete.bib},
}

@article{ringach_dynamics_nodate,
	title = {Dynamics of orientation tuning in macaque primary visual cortex},
	abstract = {Orientation tuning of neurons is one of the chief emergent characteristics of the primary visual cortex, V1. Neurons of the lateral geniculate nucleus, which comprise the thalamic input to V1, are not orientation-tuned, but the majority of V1 neurons are quite selective. How orientation tuning arises within V1 is still controversial. To study this problem, we measured how the orientation tuning of neurons evolves with time using a new method: reverse correlation in the orientation domain. Orientation tuning develops after a delay of 30-45 milliseconds and persists for 40-85 ms. Neurons in layers 4C alpha or 4C beta, which receive direct input from the thalamus, show a single orientation preference which remains unchanged throughout the response period. In contrast, the preferred orientations of output layer neurons (in layers 2, 3, 4B, 5 or 6) usually change with time, and in many cases the orientation tuning may have more than one peak. This difference in dynamics is accompanied by a change in the sharpness of orientation tuning; cells in the input layers are more broadly tuned than cells in the output layers. Many of these observed properties of output layer neurons cannot be explained by simple feedforward models, whereas they arise naturally in feedback networks. Our results indicate that V1 is more than a bank of static oriented filters; the dynamics of output layer cells appear to be shaped by intracortical feedback.},
	author = {Ringach, Dl and Hawken, Mj and Shapley, R},
	keywords = {merged\_fiete.bib},
}

@article{anderson_contribution_nodate,
	title = {The contribution of noise to contrast invariance of orientation tuning in cat visual cortex},
	abstract = {Feedforward models of visual cortex appear to be inconsistent with a well-known property of cortical cells: contrast invariance of orientation tuning. The models' fixed threshold broadens orientation tuning as contrast increases, whereas in real cells tuning width is invariant with contrast. We have compared the orientation tuning of spike and membrane potential responses in single cells. Both are contrast invariant, yet a threshold-linear relation applied to the membrane potential accurately predicts the orientation tuning of spike responses. The key to this apparent paradox lies in the noisiness of the membrane potential. Responses that are subthreshold on average are still capable of generating spikes on individual trials. Unlike the iceberg effect, contrast invariance remains intact even as threshold narrows orientation selectivity. Noise may, by extension, smooth the average relation between membrane potential and spike rate throughout the brain.},
	author = {Anderson, Js and Lampl, I and Gillespie, Dc and Ferster, D},
	keywords = {merged\_fiete.bib},
}

@article{lampl_prediction_nodate,
	title = {Prediction of orientation selectivity from receptive field architecture in simple cells of cat visual cortex},
	abstract = {From the intracellularly recorded responses to small, rapidly flashed spots, we have quantitatively mapped the receptive fields of simple cells in the cat visual cortex. We then applied these maps to a feedforward model of orientation selectivity. Both the preferred orientation and the width of orientation tuning of the responses to oriented stimuli were well predicted by the model. Where tested, the tuning curve was well predicted at different spatial frequencies. The model was also successful in predicting certain features of the spatial frequency selectivity of the cells. It did not successfully predict the amplitude of the responses to drifting gratings. Our results show that the spatial organization of the receptive field can account for a large fraction of the orientation selectivity of simple cells.},
	author = {Lampl, I and Anderson, Js and Gillespie, Dc and Ferster, D},
	keywords = {merged\_fiete.bib},
}

@article{gillespie_dynamics_nodate,
	title = {Dynamics of the orientation-tuned membrane potential response in cat primary visual cortex},
	abstract = {Neurons in the primary visual cortex are highly selective for stimulus orientation, whereas their thalamic inputs are not. Much controversy has been focused on the mechanism by which cortical orientation selectivity arises. Although an increasing amount of evidence supports a linear model in which orientation selectivity is conferred upon visual cortical cells by the alignment of the receptive fields of their thalamic inputs, the controversy has recently been rekindled with the suggestion that late cortical input-delayed by multiple synapses-could lead to sharpening of orientation selectivity over time. Here we used intracellular recordings in vivo to examine temporal properties of the orientation-selective response to flashed gratings. Bayesian parameter estimation demonstrated that both preferred orientation and tuning width were stable throughout the response to a single stimulus.},
	author = {Gillespie, Dc and Lampl, I and Anderson, Js and Ferster, D},
	keywords = {merged\_fiete.bib},
}

@article{wenner_mechanisms_nodate,
	title = {Mechanisms that initiate spontaneous network activity in the developing chick spinal cord},
	abstract = {Many developing networks exhibit a transient period of spontaneous activity that is believed to be important developmentally. Here we investigate the initiation of spontaneous episodes of rhythmic activity in the embryonic chick spinal cord. These episodes recur regularly and are separated by quiescent intervals of many minutes. We examined the role of motoneurons and their intraspinal synaptic targets (R-interneurons) in the initiation of these episodes. During the latter part of the inter-episode interval, we recorded spontaneous, transient ventral root depolarizations that were accompanied by small, spatially diffuse fluorescent signals from interneurons retrogradely labeled with a calcium-sensitive dye. A transient often could be resolved at episode onset and was accompanied by an intense pre-episode ( 500 ms) motoneuronal discharge (particularly in adductor and sartorius) but not by interneuronal discharge monitored from the ventrolateral funiculus (VLF). An important role for this pre-episode motoneuron discharge was suggested by the finding that electrical stimulation of motor axons, sufficient to activate R-interneurons, could trigger episodes prematurely. This effect was mediated through activation of R-interneurons because it was prevented by pharmacological blockade of either the cholinergic motoneuronal inputs to R-interneurons or the GABAergic outputs from R-interneurons to other interneurons. Whole-cell recording from R-interneurons and imaging of calcium dye-labeled interneurons established that R-interneuron cell bodies were located dorsomedial to the lateral motor column (R-interneuron region). This region became active before other labeled interneurons when an episode was triggered by motor axon stimulation. At the beginning of a spontaneous episode, whole-cell recordings revealed that R-interneurons fired a high-frequency burst of spikes and optical recordings demonstrated that the R-interneuron region became active before other labeled interneurons. In the presence of cholinergic blockade, however, episode initiation slowed and the inter-episode interval lengthened. In addition, optical activity recorded from the R-interneuron region no longer led that of other labeled interneurons. Instead the initial activity occurred bilaterally in the region medial to the motor column and encompassing the central canal. These findings are consistent with the hypothesis that transient depolarizations and firing in motoneurons, originating from random fluctuations of interneuronal synaptic activity, activate R-interneurons, which then trigger the recruitment of the rest of the spinal interneuronal network. This unusual function for R-interneurons is likely to arise because the output of these interneurons is functionally excitatory during development.},
	author = {Wenner, P and Donovan, O'mj},
	keywords = {merged\_fiete.bib},
}

@article{priesol_frequency-dependent_2000,
	title = {Frequency-dependent effects of glutamate antagonists on the vestibulo-ocular reflex of the cat},
	volume = {857},
	abstract = {In the central nervous system, sensory and motor signals at different frequencies are transmitted most effectively by neural elements that have different dynamic characteristics. Dynamic differences may be due, in part, to the dynamics of neurotransmitter receptors. For example, N-methyl-D-aspartate (NMDA) receptors are thought to be a component of the “neural integrator” of the vestibulo-ocular reflex (VOR), which generates a signal proportional to eye position. We measured the effects of blockade of NMDA and AMPA/kainate receptors on the gain and phase of the VOR at frequencies between 0.1 and 8 Hz in alert cats. The competitive NMDA antagonist, APV, and the non-competitive antagonists, MK-801 and ketamine, all caused a pronounced reduction in VOR gain. Gain was more strongly attenuated at low frequencies (0.1-1 Hz) than at higher frequencies (2-8 Hz). The phase lead of the eye with respect to the head was increased up to 30 degrees. In contrast, the reduction in gain associated with drowsiness or surgical anesthesia was not frequency-dependent. Blockade of AMPA/kainate receptors by the competitive antagonists, CNQX and NBQX, reduced the gain of the VOR at all frequencies tested. We evaluated our results using a control systems model. Our data are consistent with participation of NMDA receptors in neural integration, but suggest that NMDA receptors also participate in transmission by other components of the VOR pathway, and that neural integration also employs other receptors. One possibility is that between 0.1 and 10 Hz, higher-frequency signals are transmitted primarily by AMPA/kainate receptors, and lower frequencies by NMDA receptors. This arrangement would provide a biological substrate for selective motor learning within a small frequency range.},
	number = {1-2},
	journal = {Brain Res.},
	author = {Priesol, Aj and Jones, Ge and Tomlinson, Rd and Broussard, Dm},
	month = feb,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {252--264},
}

@article{broussard_dynamics_1999,
	title = {The dynamics of the vestibulo-ocular reflex after peripheral vestibular damage. {II}. {Comparison} with dynamics after optically induced learning},
	volume = {125},
	abstract = {The vestibulo-ocular reflex (VOR) stabilizes gaze adequately under a variety of conditions because it is capable of a simple form of motor learning. Learning is induced by changed visual conditions or to compensate for vestibular sensory loss. We asked whether the mechanisms that are triggered by visual signals can fully account for recovery from vestibular damage. We addressed this question by comparing the effects of optically induced motor learning (i.e., changes in gain induced by telescopic lenses) and recovery from a unilateral horizontal canal plug on the dynamics of the cat VOR. Optically induced learning modified the gain of the VOR more effectively for rotation at low frequencies (below 5 Hz) than for higher-frequency stimuli. During recovery from a plug, the gain of the VOR increased at all frequencies tested, with a similar time course for all frequencies. After recovery the gain for rotation at 5 Hz or above was relatively enhanced. After recovery reached its upper limit, optically induced learning could bring about further changes in gain. The results are interpreted with respect to partially (but not completely) shared mechanisms for optically induced learning and recovery after a unilateral canal plug.},
	number = {3},
	journal = {Exp. Brain Res.},
	author = {Broussard, Dm and Bhatia, Jk and Hong, Ja},
	month = apr,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {365--374},
}

@article{broussard_dynamics_1999-1,
	title = {The dynamics of the vestibulo-ocular reflex after peripheral vestibular damage. {I}. {Frequency}-dependent asymmetry},
	volume = {125},
	abstract = {Accurate performance by the vestibulo-ocular reflex (VOR) is necessary to stabilize visual fixation during head movements. VOR performance is severely affected by peripheral vestibular damage; after one horizontal semicircular canal is plugged, the horizontal VOR is asymmetric and its amplitude is reduced. The VOR recovers partially. We investigated the limits of recovery by measuring the VOR's response to ipsilesional and contralesional rotation after unilateral peripheral damage in cats. We found that the VOR's response to rotation at high frequencies remained asymmetric after recovery was complete. When the stimulus was a pulse of head velocity comprising a dynamic overshoot followed by a plateau, gain was partially restored and symmetry completely restored within 30 days after the plug, but only for the plateau response. The overshoot in eye velocity remained asymmetric. The asymmetry was independent of stimulus velocity throughout the known linear velocity range of primary vestibular afferents. Sinusoidal rotation at 0.05-8 Hz revealed that, within this range, the persistent asymmetry was significant only at frequencies above 2 Hz. Asymmetry was independent of the peak head acceleration over the range of 50-500 degrees/s2. When both horizontal canals were plugged, a small residual VOR was observed, suggesting residual signal transduction by plugged semicircular canals. However, transduction by plugged canals could not explain the enhancement of the VOR gain, at high frequencies, for rotation away from the plugged side compared with rotation toward the plug. Also, the high-frequency asymmetry was present after recovery from a unilateral labyrinthectomy. These results suggest that high-frequency asymmetry after unilateral damage is not due to residual function in the plugged canal. The findings are discussed in the context of a bilateral model of the VOR that includes central filtering.},
	number = {3},
	journal = {Exp. Brain Res.},
	author = {Broussard, Dm and Bhatia, Jk and Jones, Ge},
	month = apr,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {353--364},
}

@article{anderson_orientation_2000,
	title = {Orientation tuning of input conductance, excitation, and inhibition in cat primary visual cortex},
	volume = {84},
	abstract = {The input conductance of cells in the cat primary visual cortex (V1) has been shown recently to grow substantially during visual stimulation. Because increasing conductance can have a divisive effect on the synaptic input, theoretical proposals have ascribed to it specific functions. According to the veto model, conductance increases would serve to sharpen orientation tuning by increasing most at off-optimal orientations. According to the normalization model, conductance increases would control the cell's gain, by being independent of stimulus orientation and by growing with stimulus contrast. We set out to test these proposals and to determine the visual properties and possible synaptic origin of the conductance increases. We recorded the membrane potential of cat V1 cells while injecting steady currents and presenting drifting grating patterns of varying contrast and orientation. Input conductance grew with stimulus contrast by 20-300\%, generally more in simple cells (40-300\%) than in complex cells (20-120\%), and in simple cells was strongly modulated in time. Conductance was invariably maximal for stimuli of the preferred orientation. Thus conductance changes contribute to a gain control mechanism, but the strength of this gain control does not depend uniquely on contrast. By assuming that the conductance changes are entirely synaptic, we further derived the excitatory and inhibitory synaptic conductances underlying the visual responses. In simple cells, these conductances were often arranged in push-pull: excitation increased when inhibition decreased and vice versa. Excitation and inhibition had similar preferred orientations and did not appear to differ in tuning width, suggesting that the intracortical synaptic inputs to simple cells of cat V1 originate from cells with similar orientation tuning. This finding is at odds with models where orientation tuning in simple cells is achieved by inhibition at off-optimal orientations or sharpened by inhibition that is more broadly tuned than excitation.},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Anderson, Js and Carandini, M and Ferster, D},
	month = aug,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {909--926},
}

@article{celebrini_dynamics_1993,
	title = {Dynamics of orientation coding in area {V1} of the awake primate},
	volume = {10},
	abstract = {To investigate the importance of feedback loops in visual information processing, we have analyzed the dynamic aspects of neuronal responses to oriented gratings in cortical area V1 of the awake primate. If recurrent feedback is important in generating orientation selectivity, the initial part of the neuronal response should be relatively poorly selective, and full orientation selectivity should only appear after a delay. Thus, by examining the dynamics of the neuronal responses it should be possible to assess the importance of feedback processes in the development of orientation selectivity. The results were base on a sample of 259 cells recorded in two monkeys, of which 89\% were visually responsive. Of these, approximately two-thirds were orientation selective. Response latency varied considerably between neurons, ranging from a minimum of 41 ms to over 150 ms, although most had latencies of 50-70 ms. Orientation tuning (defined as the bandwidth at half-height) ranged from 16 deg to over 90 deg, with a mean value of around 55 deg. By examining the selectivity of these different neurons by 10-ms time slices, starting at the onset of the neuronal response, we found that the orientation selectivity of virtually every neuron was fully developed at the very start of the neuronal response. Indeed, many neurons showed a marked tendency to respond at somewhat longer latencies to stimuli that were nonoptimally oriented, with the result that orientation selectivity was highest at the very start of the neuronal response. Furthermore, there was no evidence that the neurons with the shortest onset latencies were less selective. Such evidence is inconsistent with the hypothesis that recurrent intracortical feedback plays an important role in the generation of orientation selectivity. Instead, we suggest that orientation selectivity is primarily generated using feedforward mechanisms, including feedforward inhibition. Such a strategy has the advantage of allowing orientation to be computed rapidly, and avoids the initially poorly selective neuronal responses that characterize processing involving recurrent loops.},
	number = {5},
	journal = {Vis. Neurosci.},
	author = {Celebrini, S and Thorpe, S and Trotter, Y and Imbert, M},
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {811--825},
}

@article{mao_dynamics_2001,
	title = {Dynamics of {Spontaneous} {Activity} in {Neocortical} {Slices}},
	volume = {32},
	abstract = {The flow of activity in the cortical microcircuitry is poorly understood. We use calcium imaging to reconstruct, with millisecond and single-cell resolution, the spontaneous activity of populations of neurons in unstimulated slices from mouse visual cortex. We find spontaneous activity correlated among networks of layer 5 pyramidal cells. Synchronous ensembles occupy overlapping territories, often share neurons, and are repeatedly activated. Sets of neurons are also sequentially activated numerous times. Network synchronization and sequential correlations are blocked by glutamatergic antagonists, even though spontaneous firing persists in many ”autonomously active” neurons. This autonomous activity is periodic and depends on hyperpolarization-activated cationic (H) and persistent sodium (Nap) currents. We conclude that the isolated neocortical microcircuit generates spontaneous activity, mediated by a combination of intrinsic and circuit mechanisms, and that this activity can be temporally precise.},
	journal = {Neuron},
	author = {Mao, Bu-Qing and Hamzei-sichani, Farid and Aronov, Dmitriy and Froemke, Robert C and Yuste, Rafael},
	month = dec,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {883--898},
}

@article{hammond_neural_1988,
	title = {Neural correlates of motion after-effects in cat striate cortical neurones: interocular transfer},
	volume = {72},
	abstract = {Interocular transfer of motion after-effects was assessed in the lightly-anaesthetized feline striate cortex. Neurones were adapted with square-wave gratings of optimal orientation and spatial frequency, or with randomly textured fields, drifting continuously at optimal velocity in their preferred or null directions. Neural after-effects were assessed as consequent changes in directional bias, using similar test patterns swept back-and-forth in the same directions and presented to the same or opposite eyes. All results were compared with controls, embodying similar tests following a period of exposure to a uniform background or stationary textured field. The majority of binocularly-driven complex and simple cells tested evinced positive interocular transfer of after-effects. After-effects, whether elicited monocularly or interocularly, were direction-specific. With gratings, after-effects elicited interocularly were always weaker than those obtained monocularly. After-effects evoked monocularly by texture adaptation were weak in comparison to those evoked by gratings; interocular transfer in this case was negligible. In neurones strongly dominated by one eye, adaptation of the non-driving eye yielded, at best, extremely weak after-effects through the other eye. In purely monocular neurones, no transfer could be induced. These results confirm the expectation that motion after-effects arise cortically rather than precortically. The partial interocular transfer seen in binocularly-driven cortical cells suggests that these neurones represent a second-stage processing of inputs from lower-order complex (or simple) cells, themselves driven monocularly or strongly dominated by one eye.},
	number = {1},
	journal = {Exp. Brain Res.},
	author = {Hammond, P and Mouat, Gs},
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {21--28},
}

@article{verstraten_recovery_1994,
	title = {Recovery from motion adaptation is delayed by successively presented orthogonal motion},
	volume = {34},
	abstract = {Following a period of adaptation to a pattern moving in a particular direction, a subsequently viewed stationary pattern appears to move in the opposite direction for some time: the movement after effect (MAE). The MAE lasts longer when the test pattern is not immediately or not continuously presented after adaptation. This phenomenon is called storage. So far research indicates that storage only occurs when textured visual stimulation is absent during part of the test phase or if the processing of a stationary test stimulus is prevented (e.g. by binocular rivalry). We present evidence that storage-like phenomena can occur even while a textured and moving visual stimulus is phenomenally present. We adapted binocularly to uni-directional motion of a random-pixel array M1 for 60 sec. This stimulus was immediately followed by another moving pattern M2. Its motion direction was orthogonal to that of M1. The presentation time of M2 was the independent variable. A stationary pattern was presented immediately after presentation of M2. The direction of the resulting integrated uni-directional MAE was measured. For short presentation times of M2 there is an integrated uni-directional MAE, which shows an interaction of the output of units stimulated by both moving patterns. However, it appeared that the effect of M1 on the direction of this combined uni-directional MAE is much longer present than would be expected from the MAE duration of M1, when tested in isolation.},
	number = {9},
	journal = {Vision Res.},
	author = {Verstraten, Fa and Fredericksen, Re and Grusser, Oj and Grind, De Van Wa},
	month = may,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {1149--1155},
}

@article{wiesenfelder_binocular_1992,
	title = {Binocular rivalry suppression disrupts recovery from motion adaptation},
	volume = {9},
	abstract = {The motion aftereffect (MAE) lasts longer when the test period does not immediately follow adaptation, a phenomenon called storage. Does storage of the MAE occur if the test target is present but rendered phenomenally invisible owing to the presence of a rival target presented to the other eye during the storage period? Our experiment addressed this question. Following adaptation to a drifting grating, an intervening period preceded testing with a stationary grating. During this period, the adapted eye either viewed the test target immediately or was occluded, and the unadapted eye either viewed a high-contrast rival target or was occluded. Thus four conditions were employed. The duration of the residual MAE was found to be longer for the rivalry condition (grating and rival target viewed) than for the normal MAE condition (grating viewed), and comparable to that in the stored MAE condition (both eyes occluded). Thus, the MAE is stored when the test target is rendered invisible due to binocular rivalry, indicating that a suppressed target is ineffective at promoting decay of the MAE. So while suppression does not prevent information about the adapting grating from reaching the site of generation of the MAE (Lehmkuhle \& Fox, 1975), it can prevent information about the test target from reaching the site of the stored MAE. Current models attribute the MAE to reduced responsiveness of direction-selective cortical neurons (Sutherland, 1961; Barlow \& Hill, 1963). Thus, storage should reflect a differential return of these adapted cells to preadapted response levels, dependent on postadaptation stimulation.(ABSTRACT TRUNCATED AT 250 WORDS)},
	number = {2},
	journal = {Vis. Neurosci.},
	author = {Wiesenfelder, H and Blake, R},
	month = aug,
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {143--148},
}

@article{hammond_neural_1989,
	title = {Neural motion after-effects in the cat's striate cortex: orientation selectivity},
	volume = {29},
	abstract = {Single striate cortical neurones were recorded from adult cats, lightly anaesthetized with N2O/O2/halothane. The receptive fields for the dominant eye were subjected to direction-specific adaptation by a square-wave grating of optimal spatial frequency and velocity, drifting continuously in each neurone's preferred direction. Recovery of the neural motion after-effect induced by prior adaptation was assessed with the same grating pattern which now moved alternately in the preferred and opposite directions. In controls the same tests for recovery followed a period of exposure to a uniform field of identical luminance to the adapting grating. Three sets of measurements were made to establish whether the adaptation was orientation- as well as direction-specific. In the first, test grating orientation was maintained constant and optimal for each neurone whilst adapting orientation was systematically varied. In the second, test orientation was varied whilst maintaining adapting orientation constant. In the third set, adapting and test orientations were initially fixed at each neurone's optimum; they were next set, non-optimally to one side of the optimum. Results from the latter configuration were compared with similar tests in which the test grating remained at that non-optimal orientation whilst the orientation of the adapting grating was now altered to a new point on the other flank of each neurone's orientation tuning curve that was matched for strength of adaptation. Thus the degree of adaptation was identical in each case, but zero orientation difference between adapting and test gratings in one case was contrasted with a substantial orientation difference in the other. The results from all three sets of data were unequivocal: in simple neurones, and in standard and intermediate classes of complex neurones, but not in special complex neurones, the sequential effects of adapting gratings on the responses and sensitivity to subsequently presented test gratings were maximal when their orientations were matched and optimal for each neurone, less marked when orientations were matched but non-optimal. In conclusion, adaptation induced by pattern motion was orientation- as well as direction-specific only in standard (length summating) and intermediate complex neurones, and in simple cells; in special complex neurones it was not.},
	number = {12},
	journal = {Vision Res.},
	author = {Hammond, P and Pomfrett, Cj and Ahmed, B},
	year = {1989},
	keywords = {merged\_fiete.bib},
	pages = {1671--1683},
}

@article{verstraten_recovery_1996,
	title = {Recovery from adaptation for dynamic and static motion aftereffects: evidence for two mechanisms},
	volume = {36},
	abstract = {The motion aftereffect (MAE) is an illusory drift of a physically stationary pattern induced by prolonged viewing of a moving pattern. Depending on the nature of the test pattern the MAE can be phenomenally different. This difference in appearance has led to the suggestion that different underlying mechanisms may be responsible and several reports show that this might be the case. Here, we tested whether differences in MAE duration obtained with stationary test patterns and dynamic test patterns can be explained by a single underlying mechanism. We find the results support the existence of (at least) two mechanisms. The two mechanisms show different characteristics: the static MAE (i.e. the MAE tested with a static test pattern) is almost completely stored when the static test is preceded by a dynamic test; in contradistinction, the dynamic MAE is not stored when dynamic testing is preceded by a static test pattern.},
	number = {3},
	journal = {Vision Res.},
	author = {Verstraten, Fa and Fredericksen, Re and Van Rj, Wezel and Lankheet, Mj and Grind, De Van Wa},
	month = feb,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {421--424},
}

@article{markram_physiology_1997,
	title = {Physiology and anatomy of synaptic connections between thick tufted pyramidal neurones in the developing rat neocortex},
	volume = {500.2},
	journal = {J. Physiol.},
	author = {Markram, H and Lubke, J and Frotscher, M and Roth, A and Sakmann, B},
	month = apr,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {409--440},
}

@article{gupta_organizing_2000,
	title = {Organizing principles for a diversity of {GABAergic} interneurons and synapses in the neocortex},
	volume = {287},
	abstract = {A puzzling feature of the neocortex is the rich array of inhibitory interneurons. Multiple neuron recordings revealed numerous electrophysiological-anatomical subclasses of neocortical gamma-aminobutyric acid-ergic (GABAergic) interneurons and three types of GABAergic synapses. The type of synapse used by each interneuron to influence its neighbors follows three functional organizing principles. These principles suggest that inhibitory synapses could shape the impact of different interneurons according to their specific spatiotemporal patterns of activity and that GABAergic interneuron and synapse diversity may enable combinatorial inhibitory effects in the neocortex.},
	number = {5451},
	journal = {Science},
	author = {Gupta, A and Wang, Y and Markram, H},
	month = jan,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {273--278},
}

@article{bi_synaptic_2001,
	title = {Synaptic {Modification} by {Correlated} {Activity}: {Hebb}'s {Postulate} {Revisited}},
	number = {24},
	journal = {Annu. Rev. Neurosci.},
	author = {Bi, G and Poo, M},
	year = {2001},
	keywords = {merged\_fiete.bib, LTD, LTP, Hebbian synapse, input specificity, spike timing},
	pages = {139--166},
}

@article{gulbis_structure_2000,
	title = {Structure of the cytoplasmic beta subunit-{T1} assembly of voltage-dependent {K}+ channels},
	volume = {289},
	abstract = {The structure of the cytoplasmic assembly of voltage-dependent K+ channels was solved by x-ray crystallography at 2.1 angstrom resolution. The assembly includes the cytoplasmic (T1) domain of the integral membrane alpha subunit together with the oxidoreductase beta subunit in a fourfold symmetric T1(4)beta4 complex. An electrophysiological assay showed that this complex is oriented with four T1 domains facing the transmembrane pore and four beta subunits facing the cytoplasm. The transmembrane pore communicates with the cytoplasm through lateral, negatively charged openings above the T1(4)beta4 complex. The inactivation peptides of voltage-dependent K(+) channels reach their site of action by entering these openings.},
	number = {5476},
	journal = {Science},
	author = {Gulbis, Jm and Zhou, M and Mann, S and Mackinnon, R},
	month = jul,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {123--127},
}

@article{sigman_common_2001,
	title = {On a common circle: natural scenes and {Gestalt} rules},
	volume = {98},
	abstract = {To understand how the human visual system analyzes images, it is essential to know the structure of the visual environment. In particular, natural images display consistent statistical properties that distinguish them from random luminance distributions. We have studied the geometric regularities of oriented elements (edges or line segments) present in an ensemble of visual scenes, asking how much information the presence of a segment in a particular location of the visual scene carries about the presence of a second segment at different relative positions and orientations. We observed strong long-range correlations in the distribution of oriented segments that extend over the whole visual field. We further show that a very simple geometric rule, cocircularity, predicts the arrangement of segments in natural scenes, and that different geometrical arrangements show relevant differences in their scaling properties. Our results show similarities to geometric features of previous physiological and psychophysical studies. We discuss the implications of these findings for theories of early vision.},
	number = {4},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Sigman, M and Cecchi, Ga and Gilbert, Cd and Magnasco, Mo},
	month = feb,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {1935--1940},
}

@article{colicos_remodeling_2001,
	title = {Remodeling of synaptic actin induced by photoconductive stimulation},
	volume = {107},
	abstract = {Use-dependent synapse remodeling is thought to provide a cellular mechanism for encoding durable memories, yet whether activity triggers an actual structural change has remained controversial. We use photoconductive stimulation to demonstrate activity-dependent morphological synaptic plasticity by video imaging of GFP-actin at individual synapses. A single tetanus transiently moves presynaptic actin toward and postsynaptic actin away from the synaptic junction. Repetitive spaced tetani induce glutamate receptor-dependent stable restructuring of synapses. Presynaptic actin redistributes and forms new puncta that label for an active synapse marker FM5-95 within 2 hr. Postsynaptic actin sprouts projections toward the new presynaptic actin puncta, resembling the axon-dendrite interaction during synaptogenesis. Our results indicate that activity-dependent presynaptic structural plasticity facilitates the formation of new active presynaptic terminals.},
	number = {5},
	journal = {Cell},
	author = {Colicos, Ma and Collins, Be and Sailor, Mj and Goda, Y},
	month = nov,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {605--616},
}

@article{haggard_relation_1999,
	title = {On the relation between brain potentials and the awareness of voluntary movements},
	volume = {126},
	abstract = {We investigated the relation between neural events and the perceived time of voluntary actions or the perceived time of initiating those actions using the method of Libet. No differences were found in either movement-related potentials or perceived time of motor events between a fixed movement condition, where subjects made voluntary movements of a single finger in each block, and a free movement condition, in which subjects chose whether to respond with the left or the right index finger on each trial. We next calculated both the readiness potential (RP) and lateralised readiness potential (LRP) for trials with early and late times of awareness. The RP tended to occur later on trials with early awareness of movement initiation than on trials with late awareness, ruling out the RP as a cause of our awareness of movement initiation. However, the LRP occurred significantly earlier on trials with early awareness than on trials with late awareness, suggesting that the processes underlying the LRP may cause our awareness of movement initiation.},
	number = {1},
	journal = {Exp. Brain Res.},
	author = {Haggard, P and Eimer, M},
	month = may,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {128--133},
}

@article{woldorff_effects_1991,
	title = {The effects of channel-selective attention on the mismatch negativity wave elicited by deviant tones},
	volume = {28},
	abstract = {The mismatch negativity (MMN) is an event-related brain potential elicited by infrequent, physically deviant sounds in a sequence of repetitive auditory stimuli. Two dichotic listening experiments that were designed to optimize the selective focusing of attention provided a strong test of Naatanen's proposal that the MMN is unaffected by attention and reflects the operation of a strongly automatic mismatch detection system. In Experiment 1, tones were presented at intervals of 120-320 ms, and the deviant tones (intensity decrements) in both the attended and unattended ears elicited negative waves consistent in waveshape, latency, and distribution with previously described MMNs. In contrast to previous reports, however, the MMN elicited by the unattended-channel deviant was markedly reduced (peak amplitude of less than 1 microV) relative to the corresponding negative wave elicited by the attended-channel deviants (3-4 microV), as well as relative to previously reported MMNs (3-6 microV) elicited by comparable deviations in stimulus intensity. In Experiment 2, which employed interstimulus intervals of 65-205 ms, the unattended-channel MMN elicited by the deviant fainter tones was barely discernible, whereas the corresponding attended-channel negativity was again about 3-4 microV. These findings call into question the assertion that the auditory mismatch detection process and the associated MMN wave are wholly independent of attentional influence. Rather, these data provide evidence that the processing of stimuli in unattended channels can be attenuated or gated at an early sensory level under conditions of highly focused auditory selective attention.},
	number = {1},
	journal = {Psychophysiology},
	author = {Woldorff, Mg and Hackley, Sa and Hillyard, Sa},
	month = jan,
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {30--42},
}

@article{boettiger_developmentally_2001,
	title = {Developmentally restricted synaptic plasticity in a songbird nucleus required for song learning},
	volume = {31},
	abstract = {We provide evidence here of long-term synaptic plasticity in a songbird forebrain area required for song learning, the lateral magnocellular nucleus of the anterior neostriatum (LMAN). Pairing postsynaptic bursts in LMAN principal neurons with stimulation of recurrent collateral synapses had two effects: spike timing- and NMDA receptor-dependent LTP of the recurrent synapses, and LTD of thalamic afferent synapses that were stimulated out of phase with the postsynaptic bursting. Both types of plasticity were restricted to the sensory critical period for song learning, consistent with a role for each in sensory learning. The properties of the observed plasticity are appropriate to establish recurrent circuitry within LMAN that reflects the spatiotemporal pattern of thalamic afferent activity evoked by tutor song. Such circuit organization could represent a tutor song memory suitable for reinforcing particular vocal sequences during sensorimotor learning.},
	number = {5},
	journal = {Neuron},
	author = {Boettiger, C A and Doupe, A J},
	month = sep,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {809--818},
}

@article{iyengar_role_2002,
	title = {The role of auditory experience in the formation of neural circuits underlying vocal learning in zebra finches},
	volume = {22},
	abstract = {The initial establishment of topographic mapping within developing neural circuits is thought to be shaped by innate mechanisms and is primarily independent of experience. Additional refinement within topographic maps leads to precise matching between presynaptic and postsynaptic neurons and is thought to depend on experiential factors during specific sensitive periods in the animal's development. In male zebra finches, axonal projections of the cortical lateral magnocellular nucleus of the anterior neostriatum (lMAN) are critically important for vocal learning. Overall patterns of topographic organization in the majority of these circuits are adult-like throughout the sensitive period for vocal learning and remain stable despite large-scale functional and morphological changes. However, topographic organization within the projection from the core subregion of lMAN (lMAN(core)) to the motor cortical robust nucleus of the archistriatum (RA) is lacking at the onset of song development and emerges during the early stages of vocal learning. To study the effects of song-related experience on patterns of axonal connectivity within different song-control circuits, we disrupted song learning by deafening juvenile zebra finches or exposing them to loud white noise throughout the sensitive period for song learning. Depriving juvenile birds of normal auditory experience delayed the emergence of topographic specificity within the lMAN(core)–{\textgreater}RA circuit relative to age-matched controls, whereas topographic organization within all other projections to and from lMAN was not affected. The projection from lMAN(core) to RA therefore provides an unusual example of experience-dependent modification of large-scale patterns of brain circuitry, in the sense that auditory deprivation influences the development of overall topographic organization in this pathway.},
	number = {3},
	journal = {J. Neurosci.},
	author = {Iyengar, S and Bottjer, S W},
	month = feb,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {946--958},
}

@article{hough_short-term_2002,
	title = {Short-term and long-term effects of vocal distortion on song maintenance in zebra finches},
	volume = {22},
	abstract = {Adult zebra finch song is irreversibly altered when birds are deprived of correct feedback by deafening or denervation of the syrinx. To clarify the role of feedback in song maintenance, we developed a reversible technique to distort vocal output without damaging the auditory or vocal systems. We implanted flexible beads adjacent to the syrinx to alter its biomechanics. Immediate song aberrations included low volume, frequency shifts, missing harmonics, and production of click-like syllables. After a few weeks, seven of nine birds stopped producing some syllables. In six of these birds, the gaps left by the silenced syllables gradually shortened, and the lost syllables did not return when beads were removed 16 weeks after treatment began. The nondeleted syllables of all birds regained their preimplant morphology, insofar as could be detected, within 9 d after bead removal. In four other birds, we removed the beads as soon as syllables were deleted, when the silent intervals were still full length. In these birds, all deleted syllables returned within 1 week. Our results indicate that both silenced syllables and syllable morphology can recover as long as the song's temporal structure is maintained, but once altered, changes in the song sequence can be permanent. A hierarchical organization of the song production system has recently been described (Margoliash, 1997). Reversible disruption of song production by our method appears to permanently alter the higher levels of the system that encode song sequence, but not the lower levels that encode individual syllable structure.},
	number = {3},
	journal = {J. Neurosci.},
	author = {Hough, 2nd, G E and Volman, S F},
	month = feb,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {1177--1186},
}

@article{iyengar_development_2002,
	title = {Development of individual axon arbors in a thalamocortical circuit necessary for song learning in zebra finches},
	volume = {22},
	abstract = {Individual axon arbors within developing neural circuits are remodeled during restricted sensitive periods, leading to the emergence of precise patterns of connectivity and specialized adaptive behaviors. In male zebra finches, the circuit connecting the medial dorsolateral nucleus of the thalamus (DLM) and its cortical target, the lateral magnocellular nucleus of the anterior neostriatum (lMAN), is crucial for the acquisition of a normal vocal pattern during the sensitive period for song learning. The shell subregion of lMAN as well as the entire terminal field of DLM axons within lMAN undergo a striking increase in overall volume during early stages of vocal learning followed by an equally substantial decrease by adulthood, by which time birds have acquired stable song patterns. Because the total number of DLM neurons remains stable throughout this period, the dramatic changes within the overall DLM–{\textgreater}lMAN circuit are presumably attributable to dynamic rearrangements at the level of individual DLM axon arbors over the course of vocal learning. To study such rearrangements directly, we reconstructed individual DLM axon arbors in three dimensions at different stages during vocal learning. Unlike axon arbors in other model systems, in which the number of branches increases during development, DLM arbors are unusual in that they have the greatest number of branches at the onset of vocal learning and undergo large-scale retraction during the sensitive period for song learning. Decreases in the degree of overlap between DLM arbors apparently contribute to the increased overall volume of the DLM–{\textgreater}lMAN circuit during vocal learning. These developmental changes in DLM axon arbors occur at the height of the sensitive period for vocal learning, and hence may represent either a morphological correlate of song learning or a necessary prerequisite for acquisition of song.},
	number = {3},
	journal = {J. Neurosci.},
	author = {Iyengar, S and Bottjer, S W},
	month = feb,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {901--911},
}

@article{moore_spatio-temporal_1998,
	title = {Spatio-temporal subthreshold receptive fields in the vibrissa representation of rat primary somatosensory cortex},
	volume = {80},
	abstract = {Spatio-temporal subthreshold receptive fields in the vibrissa representation of rat primary somatosensory cortex. J. Neurophysiol. 80: 2882-2892, 1998. Whole cell recordings of synaptic responses evoked by deflection of individual vibrissa were obtained from neurons within adult rat primary somatosensory cortex. To define the spatial and temporal properties of subthreshold receptive fields, the spread, amplitude, latency to onset, rise time to half peak amplitude, and the balance of excitation and inhibition of subthreshold input were quantified. The convergence of information onto single neurons was found to be extensive: inputs were consistently evoked by vibrissa one- and two-away from the vibrissa that evoked the largest response (the “primary vibrissa”). Latency to onset, rise time, and the incidence and strength of inhibitory postsynaptic potentials (IPSPs) varied as a function of position within the receptive field and the strength of evoked excitatory input. Nonprimary vibrissae evoked smaller amplitude subthreshold responses [primary vibrissa, 9.1 +/- 0.84 (SE) mV, n = 14; 1-away, 5. 1 +/- 0.5 mV, n = 38; 2-away, 3.7 +/- 0.59 mV, n = 22; 3-away, 1.3 +/- 0.70 mV, n = 8] with longer latencies (primary vibrissa, 10.8 +/- 0.80 ms; 1-away, 15.0 +/- 1.2 ms; 2-away, 15.7 +/- 2.0 ms). Rise times were significantly faster for inputs that could evoke action potential responses (suprathreshold, 4.1 +/- 1.3 ms, n = 8; subthreshold, 12.4 +/- 1.5 ms, n = 61). In a subset of cells, sensory evoked IPSPs were examined by deflecting vibrissa during injection of hyperpolarizing and depolarizing current. The strongest IPSPs were evoked by the primary vibrissa (n = 5/5), but smaller IPSPs also were evoked by nonprimary vibrissae (n = 8/13). Inhibition peaked by 10-20 ms after the onset of the fastest excitatory input to the cortex. This pattern of inhibitory activity led to a functional reversal of the center of the receptive field and to suppression of later-arriving and slower-rising nonprimary inputs. Together, these data demonstrate that subthreshold receptive fields are on average large, and the spatio-temporal dynamics of these receptive fields vary as a function of position within the receptive field and strength of excitatory input. These findings constrain models of suprathreshold receptive field generation, multivibrissa interactions, and cortical plasticity.},
	number = {6},
	journal = {J. Neurophysiol.},
	author = {Moore, Ci and Nelson, Sb},
	month = dec,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {2882--2892},
}

@article{moore_dynamics_1999,
	title = {Dynamics of neuronal processing in rat somatosensory cortex},
	volume = {22},
	abstract = {Recently, the study of sensory cortex has focused on the context-dependent evolution of receptive fields and cortical maps over millisecond to second time-scales. This article reviews advances in our understanding of these processes in the rat primary somatosensory cortex (SI). Subthreshold input to individual rat SI neurons is extensive, spanning several vibrissae from the center of the receptive field, and arrives within 25 ms of vibrissa deflection. These large subthreshold receptive fields provide a broad substrate for rapid excitatory and inhibitory multi-vibrissa interactions. The 'whisking' behavior, an approximately 8 Hz ellipsoid movement of the vibrissae, introduces a context-dependent change in the pattern of vibrissa movement during tactile exploration. Stimulation of vibrissae over this frequency range modulates the pattern of activity in thalamic and cortical neurons, and, at the level of the cortical map, focuses the extent of the vibrissa representation relative to lower frequency stimulation (1 Hz). These findings suggest that one function of whisking is to reset cortical organization to improve tactile discrimination. Recent discoveries in primary visual cortex (VI) demonstrate parallel non-linearities in center-surround interactions in rat SI and VI, and provide a model for the rapid integration of multi-vibrissa input. The studies discussed in this article suggest that, despite its original conception as a uniquely segregated cortex, rat SI has a wide array of dynamic interactions, and that the study of this region will provide insight into the general mechanisms of cortical dynamics engaged by sensory systems.},
	number = {11},
	journal = {Trends Neurosci.},
	author = {Moore, Ci and Nelson, Sb and Sur, M},
	month = nov,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {513--520},
}

@article{dragoi_stability_2001,
	title = {Stability of cortical responses and the statistics of natural scenes},
	volume = {32},
	abstract = {The primary visual cortex (V1) of higher mammals contains maps of stimulus features; how these maps influence vision remains unknown. We have examined the functional significance of an asymmetry in the orientation map in cat V1, i.e., the fact that a larger area of V1 is preferentially activated by vertical and horizontal contours than by contours at oblique orientations. Despite the fact that neurons tuned to cardinal and oblique orientations have indistinguishable tuning characteristics, cardinal neurons remain more stable in their response properties after selective perturbation induced by adaptation. Similarly, human observers report different adaptation-induced changes in orientation tuning between cardinal and oblique axes. We suggest that the larger cortical area devoted to cardinal orientations imposes stability on the processing of cardinal contours during visual perception, by retaining invariant cortical responses along cardinal axes.},
	number = {6},
	journal = {Neuron},
	author = {Dragoi, V and Turcu, Cm and Sur, M},
	month = dec,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {1181--1192},
}

@article{dragoi_foci_2001,
	title = {Foci of orientation plasticity in visual cortex},
	volume = {411},
	abstract = {Cortical areas are generally assumed to be uniform in their capacity for adaptive changes or plasticity. Here we demonstrate, however, that neurons in the cat striate cortex (V1) show pronounced adaptation-induced short-term plasticity of orientation tuning primarily at specific foci. V1 neurons are clustered according to their orientation preference in iso-orientation domains that converge at singularities or pinwheel centres. Although neurons in pinwheel centres have similar orientation tuning and responses to those in iso-orientation domains, we find that they differ markedly in their capacity for adaptive changes. Adaptation with an oriented drifting grating stimulus alters responses of neurons located at and near pinwheel centres to a broad range of orientations, causing repulsive shifts in orientation preference and changes in response magnitude. In contrast, neurons located in iso-orientation domains show minimal changes in their tuning properties after adaptation. The anisotropy of adaptation-induced orientation plasticity is probably mediated by inhomogeneities in local intracortical interactions that are overlaid on the map of orientation preference in V1.},
	number = {6833},
	journal = {Nature},
	author = {Dragoi, V and Rivadulla, C and Sur, M},
	month = may,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {80--86},
}

@article{rivadulla_specific_2001,
	title = {Specific roles of {NMDA} and {AMPA} receptors in direction-selective and spatial phase-selective responses in visual cortex},
	volume = {21},
	abstract = {Cells in the superficial layers of primary visual cortex (area 17) are distinguished by feedforward input from thalamic-recipient layers and by massive recurrent excitatory connections between neighboring cells. The connections use glutamate as transmitter, and the postsynaptic cells contain both NMDA and AMPA receptors. The possible role of these receptor types in generating emergent responses of neurons in the superficial cortical layers is unknown. Here, we show that NMDA and AMPA receptors are both involved in the generation of direction-selective responses in layer 2/3 cells of area 17 in cats. NMDA receptors contribute prominently to responses in the preferred direction, and their contribution to responses in the nonpreferred direction is reduced significantly by GABAergic inhibition. AMPA receptors decrease spatial phase-selective simple cell responses and generate phase-invariant complex cell responses.},
	number = {5},
	journal = {J. Neurosci.},
	author = {Rivadulla, C and Sharma, J and Sur, M},
	month = mar,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {1710--1719},
}

@article{dragoi_adaptation-induced_2000,
	title = {Adaptation-induced plasticity of orientation tuning in adult visual cortex},
	volume = {28},
	abstract = {A key emergent property of the primary visual cortex (V1) is the orientation selectivity of its neurons. The extent to which adult visual cortical neurons can exhibit changes in orientation selectivity is unknown. Here we use single-unit recording and intrinsic signal imaging in V1 of adult cats to demonstrate systematic repulsive shifts in orientation preference following short-term exposure (adaptation) to one stimulus orientation. In contrast to the common view of adaptation as a passive process by which responses around the adapting orientation are reduced, we show that changes in orientation tuning also occur due to response increases at orientations away from the adapting stimulus. Adaptation-induced orientation plasticity is thus an active time-dependent process that involves network interactions and includes both response depression and enhancement.},
	number = {1},
	journal = {Neuron},
	author = {Dragoi, V and Sharma, J and Sur, M},
	month = oct,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {287--298},
}

@article{dragoi_dynamic_2000,
	title = {Dynamic properties of recurrent inhibition in primary visual cortex: contrast and orientation dependence of contextual effects},
	volume = {83},
	abstract = {A fundamental feature of neural circuitry in the primary visual cortex (V1) is the existence of recurrent excitatory connections between spiny neurons, recurrent inhibitory connections between smooth neurons, and local connections between excitatory and inhibitory neurons. We modeled the dynamic behavior of intermixed excitatory and inhibitory populations of cells in V1 that receive input from the classical receptive field (the receptive field center) through feedforward thalamocortical afferents, as well as input from outside the classical receptive field (the receptive field surround) via long-range intracortical connections. A counterintuitive result is that the response of oriented cells can be facilitated beyond optimal levels when the surround stimulus is cross-oriented with respect to the center and suppressed when the surround stimulus is iso-oriented. This effect is primarily due to changes in recurrent inhibition within a local circuit. Cross-oriented surround stimulation leads to a reduction of presynaptic inhibition and a supraoptimal response, whereas iso-oriented surround stimulation has the opposite effect. This mechanism is used to explain the orientation and contrast dependence of contextual interactions in primary visual cortex: responses to a center stimulus can be both strongly suppressed and supraoptimally facilitated as a function of surround orientation, and these effects diminish as stimulus contrast decreases.},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Dragoi, V and Sur, M},
	month = feb,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1019--1030},
}

@article{kozloski_stereotyped_2001,
	title = {Stereotyped position of local synaptic targets in neocortex},
	volume = {293},
	abstract = {The microcircuitry of the mammalian neocortex remains largely unknown. Although the neocortex could be composed of scores of precise circuits, an alternative possibility is that local connectivity is probabilistic or even random. To examine the precision and degree of determinism in the neocortical microcircuitry, we used optical probing to reconstruct microcircuits in layer 5 from mouse primary visual cortex. We stimulated “trigger” cells, isolated from a homogenous population of corticotectal pyramidal neurons, while optically detecting “follower” neurons directly driven by the triggers. Followers belonged to a few selective anatomical classes with stereotyped physiological and synaptic responses. Moreover, even the position of the followers appeared determined across animals. Our data reveal precisely organized cortical microcircuits.},
	number = {5531},
	journal = {Science},
	author = {Kozloski, J and Sichani, Hamzei-F and Yuste, R},
	month = aug,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {868--872},
}

@article{rankin_context_2000,
	title = {Context conditioning in habituation in the nematode {Caenorhabditis} elegans},
	volume = {114},
	abstract = {Habituation has traditionally been considered a nonassociative form of learning. However, recent research suggests that retention of this nonassociative form of learning may be aided by associations formed during training. An example of this is context conditioning, in which animals that are trained and tested in the presence of a contextual cue show greater retention than animals trained and tested in different environments. This article reports context conditioning in habituation in the nematode Caenorhabditis elegans. The results showed that retention of habituation to tap at both 10- and 60-s interstimulus intervals was significantly greater if training and testing occurred in the presence of the same chemosensory cue (NaCH3COO). This context conditioning showed both extinction and latent inhibition, demonstrating that these simple worms with only 302 neurons are capable of associative context conditioning.},
	number = {3},
	journal = {Behav. Neurosci.},
	author = {Rankin, Ch},
	month = jun,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {496--505},
}

@article{wicks_effects_1997,
	title = {Effects of tap withdrawal response habituation on other withdrawal behaviors: the localization of habituation in the nematode {Caenorhabditis} elegans},
	volume = {111},
	abstract = {Four experiments were conducted to identify the possible loci of habituation of the nematode tap withdrawal response (TWR) by characterizing the effects of TWR habituation on other nonmechanosensory withdrawal behaviors that are mediated by overlapping sets of neurons. Experiments 1-2 established behavioral and anatomical relationships between spontaneous and tap-induced backward locomotion in the worm. Experiment 3 demonstrated that habituation of the TWR affected neither the magnitude nor frequency of spontaneous reversal activity. Experiment 4 extended this result to an evoked response: Habituation of the TWR had no effect on reversals evoked by a thermal stimulus. These studies, which show that the loci of change associated with habituation of the TWR are presynaptic to the interneurons and motor neurons that control locomotion, probably distributed among the mechanosensory neurons, illustrate that a complete understanding of plasticity requires a knowledge of both the anatomical and molecular substrates of change.},
	number = {2},
	journal = {Behav. Neurosci.},
	author = {Wicks, Sr and Rankin, Ch},
	month = apr,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {342--353},
}

@article{wicks_recovery_1996,
	title = {Recovery from habituation in {Caenorhabditis} elegans is dependent on interstimulus interval and not habituation kinetics},
	volume = {110},
	abstract = {The habituation of the tap withdrawal reflex of Caenorhabditis elegans was assessed to determine whether the kinetics of recovery from habituation were dependent on the interstimulus interval (ISI) used during habituation training, or alternately, on the rate and asymptotic level of habituation produced at a given ISI. Two groups of intact animals were trained at either a 10-s (CON10) or a 60-s (CON60) ISI. Laser ablation was used to alter the habituation kinetics in one further group of animals (PLM10), independent of ISI. Although the PLM10 animals trained at a 10-s ISI habituated like CON60 worms, the recovery from habituation of the PLM10 animals very closely resembled the recovery of the CON10 worms. Thus recovery kinetics are dictated by consequences of a given ISI, which do not impact upon habituation rate and asymptote. This suggests the recruitment of multiple ISI-dependent processes during habituation in C. elegans.},
	number = {4},
	journal = {Behav. Neurosci.},
	author = {Wicks, Sr and Rankin, Ch},
	month = aug,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {840--844},
}

@article{broster_effects_1994,
	title = {Effects of changing interstimulus interval during habituation in {Caenorhabditis} elegans},
	volume = {108},
	abstract = {The role of the interstimulus interval (ISI) in habituation in Caenorhabditis elegans was explored by examining the effect of changing the ISI on habituation and on spontaneous recovery from habituation. When habituation stimuli were delivered at variable ISIs with an average of 10 s, recovery was slower than when habituation stimuli were delivered at fixed 10-s intervals. There were no differences in recovery following either fixed or variable stimulation at a 60-s ISI. The effect of shifting to a different ISI during habituation training was also explored. A 60-s ISI affected habituation at a 10-s ISI, but a 10-s ISI did not influence habituation at a 60-s ISI. Therefore, habituation must be viewed as an ongoing equilibrium of a number of cellular processes–some decrementing some facilitating–that are differentially activated at different ISIs.},
	number = {6},
	journal = {Behav. Neurosci.},
	author = {Broster, Bs and Rankin, Ch},
	month = dec,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {1019--1029},
}

@article{rankin_factors_1992,
	title = {Factors affecting habituation and recovery from habituation in the nematode {Caenorhabditis} elegans},
	volume = {106},
	abstract = {In four experiments, the factors that affect the rate of habituation, the degree of habituation, and the rate of recovery from habituation in a simple reflex circuit in Caenorhabditis elegans were investigated. The results showed that habituation was more pronounced and faster, and that recovery from habituation was more rapid, with short interstimulus intervals (ISIs) than with longer ISIs. Rate of recovery differed in animals that had reached asymptotic response levels when compared with animals still in the descending portion of the habituation curve. Once animals reached asymptotic response levels, rate of recovery appeared to be determined by ISI and not by additional stimuli.},
	number = {2},
	journal = {Behav. Neurosci.},
	author = {Rankin, Ch and Broster, Bs},
	month = apr,
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {239--249},
}

@article{martina_distal_2000,
	title = {Distal initiation and active propagation of action potentials in interneuron dendrites},
	volume = {287},
	abstract = {Fast and reliable activation of inhibitory interneurons is critical for the stability of cortical neuronal networks. Active conductances in dendrites may facilitate interneuron activation, but direct experimental evidence was unavailable. Patch-clamp recordings from dendrites of hippocampal oriens-alveus interneurons revealed high densities of voltage-gated sodium and potassium ion channels. Simultaneous recordings from dendrites and somata suggested that action potential initiation occurs preferentially in the axon with long threshold stimuli, but can be shifted to somatodendritic sites when brief stimuli are applied. After initiation, action potentials propagate over the somatodendritic domain with constant amplitude, high velocity, and reliability, even during high-frequency trains.},
	number = {5451},
	journal = {Science},
	author = {Martina, M and Vida, I and Jonas, P},
	month = jan,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {295--300},
}

@article{csicsvari_reliability_1998,
	title = {Reliability and state dependence of pyramidal cell-interneuron synapses in the hippocampus: an ensemble approach in the behaving rat},
	volume = {21},
	abstract = {Spike transmission probability between pyramidal cells and interneurons in the CA1 pyramidal layer was investigated in the behaving rat by the simultaneous recording of neuronal ensembles. Population synchrony was strongest during sharp wave (SPW) bursts. However, the increase was three times larger for pyramidal cells than for interneurons. The contribution of single pyramidal cells to the discharge of interneurons was often large (up to 0.6 probability), as assessed by the presence of significant ({\textless}3 ms) peaks in the cross-correlogram. Complex-spike bursts were more effective than single spikes. Single cell contribution was higher between SPW bursts than during SPWs or theta activity. Hence, single pyramidal cells can reliably discharge interneurons, and the probability of spike transmission is behavior dependent.},
	number = {1},
	journal = {Neuron},
	author = {Csicsvari, J and Hirase, H and Czurko, A and Buzsaki, G},
	month = jul,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {179--189},
}

@article{nadasdy_spike_2000,
	title = {Spike sequences and their consequences},
	volume = {94},
	abstract = {Spatio-temporal patterns of spikes have an advantage of representing information by their spike composition similar to words of languages. First we review the models of neuronal coding, then we discuss technical aspects of detecting spatio-temporal spike patterns. We argue by presenting data from rat hippocampus that spike trains recorded simultaneously from multiple pyramidal cells are not independent. Their hidden dependency structure can be revealed by spike 'sequences', defined as a set of neurons which fire in a specific temporal order with certain delay between successive spikes. The only way to prove their existence in vivo is to show that they recur with higher than by-chance frequency. We observed that 'sequences' possess 'compositional' features and that a given spike composition is time scale invariant. We illustrate that the same neuron can be a part of different 'sequences' and 'sequences' recur in a temporally compressed fashion during slow wave sleep. The statistical significance of 'sequences' is testable. Their biological significance has been implicated by experiments where recurrence rate of the sequences during different behavioral sessions were compared. As consistent with the 'replay hypothesis' of memory consolidation, new sequences generated during the wake state are persistent during the subsequent sleep. Thus, information acquired during the wake state and represented by spatio-temporal patterns of spikes may transfer to the neocortex during sleep. Our results suggest that 'sequences' reflect the activation of specific but configurable circuitries during exploratory behavior, followed by spontaneous re-activation of the same circuitry during sleep. Whether the delay structure of spikes as a combination is an effective input to single neurons downstream or 'sequence' components are being processed in parallel pathways and evaluated independently is an open question.},
	number = {5-6},
	journal = {J. Physiol. Paris},
	author = {Nadasdy, Z},
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {505--524},
}

@article{johnson_quantifying_2002,
	title = {Quantifying song bout production during zebra finch sensory-motor learning suggests a sensitive period for vocal practice},
	volume = {131},
	abstract = {Using an event-triggered recording system, the quantity of daily song bout production was measured weekly in male zebra finches (Taeniopygia guttata) during sensory-motor learning and at one year of age. Our aim was to ask whether the development of a stereotyped vocal pattern involves a practice-driven component. If so, we hypothesized that juvenile males learning song should sing more often than adults reciting a vocal pattern they had already learned, and that greater levels of juvenile singing should be associated with improvement in the quality of the adult song. Across the period measured (36-365 days of age), subjects showed an inverted U-shaped pattern of daily song bout production. Song bout production was lowest during subsong, with increased production associated with plastic song and song crystallization, although individual differences were large. Daily song bout production decreased in adulthood. Higher levels of song bout production during plastic song correlated with fewer sequencing errors in adult song patterns (r(2)=0.77). In contrast, quantity of singing during song crystallization showed no relationship to vocal stereotypy (r(2)=0.002). Our data suggest a sensitive period for vocal practice during zebra finch sensory-motor learning with consequences for the note-sequence fidelity of the adult vocal pattern.},
	number = {1-2},
	journal = {Behav. Brain Res.},
	author = {Johnson, F and Soderstrom, K and Whitney, O},
	month = apr,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {57--65},
}

@article{sjostrom_rate_2001-1,
	title = {Rate, {Timing}, and {Cooperativity} {Jointly} {Determine} {Cortical} {Synaptic} {Plasticity}},
	volume = {32},
	journal = {Neuron},
	author = {Sjostrom, Per Jesper and Turrigiano, Gina G and Nelson, Sacha B},
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {1149--1116},
}

@article{leonardo_decrystallization_1999,
	title = {Decrystallization of adult birdsong by perturbation of auditory feedback},
	volume = {399},
	abstract = {Young birds learn to sing by using auditory feedback to compare their own vocalizations to a memorized or innate song pattern; if they are deafened as juveniles, they will not develop normal songs. The completion of song development is called crystallization. After this stage, song shows little variation in its temporal or spectral properties. However, the mechanisms underlying this stability are largely unknown. Here we present evidence that auditory feedback is actively used in adulthood to maintain the stability of song structure. We found that perturbing auditory feedback during singing in adult zebra finches caused their song to deteriorate slowly. This 'decrystallization' consisted of a marked loss of the spectral and temporal stereotypy seen in crystallized song, including stuttering, creation, deletion and distortion of song syllables. After normal feedback was restored, these deviations gradually disappeared and the original song was recovered. Thus, adult birds that do not learn new songs nevertheless retain a significant amount of plasticity in the brain.},
	number = {6735},
	journal = {Nature},
	author = {Leonardo, A and Konishi, M},
	month = jun,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {466--470},
}

@article{brainard_interruption_2000,
	title = {Interruption of a basal ganglia-forebrain circuit prevents plasticity of learned vocalizations},
	volume = {404},
	abstract = {Birdsong, like speech, is a learned vocal behaviour that relies greatly on hearing; in both songbirds and humans the removal of auditory feedback by deafening leads to a gradual deterioration of adult vocal production. Here we investigate the neural mechanisms that contribute to the processing of auditory feedback during the maintenance of song in adult zebra finches. We show that the deleterious effects on song production that normally follow deafening can be prevented by a second insult to the nervous system–the lesion of a basal ganglia-forebrain circuit. The results suggest that the removal of auditory feedback leads to the generation of an instructive signal that actively drives non-adaptive changes in song; they also suggest that this instructive signal is generated within (or conveyed through) the basal ganglia-forebrain pathway. Our findings provide evidence that cortical-basal ganglia circuits may participate in the evaluation of sensory feedback during calibration of motor performance, and demonstrate that damage to such circuits can have little effect on previously learned behaviour while conspicuously disrupting the capacity to adaptively modify that behaviour.},
	number = {6779},
	journal = {Nature},
	author = {Brainard, M S and Doupe, A J},
	month = apr,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {762--766},
}

@article{sugase_global_1999,
	title = {Global and fine information coded by single neurons in the temporal visual cortex},
	volume = {400},
	abstract = {When we see a person's face, we can easily recognize their species, individual identity and emotional state. How does the brain represent such complex information? A substantial number of neurons in the macaque temporal cortex respond to faces. However, the neuronal mechanisms underlying the processing of complex information are not yet clear. Here we recorded the activity of single neurons in the temporal cortex of macaque monkeys while presenting visual stimuli consisting of geometric shapes, and monkey and human faces with various expressions. Information theory was used to investigate how well the neuronal responses could categorize the stimuli. We found that single neurons conveyed two different scales of facial information in their firing patterns, starting at different latencies. Global information, categorizing stimuli as monkey faces, human faces or shapes, was conveyed in the earliest part of the responses. Fine information about identity or expression was conveyed later, beginning on average 51 ms after global information. We speculate that global information could be used as a 'header' to prepare destination areas for receiving more detailed information.},
	number = {6747},
	journal = {Nature},
	author = {Sugase, Y and Yamane, S and Ueno, S and Kawano, K},
	month = aug,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {869--873},
}

@article{macleod_who_1998,
	title = {Who reads temporal information contained across synchronized and oscillatory spike trains},
	volume = {395},
	abstract = {Our inferences about brain mechanisms underlying perception rely on whether it is possible for the brain to 'reconstruct' a stimulus from the information contained in the spike trains from many neurons. How the brain actually accomplishes this reconstruction remains largely unknown. Oscillatory and synchronized activities in the brain of mammals have been correlated with distinct behavioural states or the execution of complex cognitive tasks and are proposed to participate in the 'binding' of individual features into more complex percepts. But if synchronization is indeed relevant, what senses it? In insects, oscillatory synchronized activity in the early olfactory system seems to be necessary for fine odour discrimination and enables the encoding of information about a stimulus in spike times relative to the oscillatory 'clock. Here we study the decoding of these coherent oscillatory signals. We identify a population of neurons downstream from the odour-activated, synchronized neuronal assemblies. These downstream neurons show odour responses whose specificity is degraded when their inputs are desynchronized. This degradation of selectivity consists of the appearance of responses to new odours and a loss of discrimination of spike trains evoked by different odours. Such loss of information is never observed in the upstream neurons whose activity is desynchronized. These results indicate that information encoded in time across ensembles of neurons converges onto single neurons downstream in the pathway.},
	number = {6703},
	journal = {Nature},
	author = {Macleod, K and Backer, A and Laurent, G},
	month = oct,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {693--698},
}

@article{laurent_systems_1999,
	title = {A systems perspective on early olfactory coding},
	volume = {286},
	abstract = {This review critically examines neuronal coding strategies and how they might apply to olfactory processing. Basic notions such as identity, spatial, temporal, and correlation codes are defined and different perspectives are brought to the study of neural codes. Odors as physical stimuli and their processing by the early olfactory system, one or two synapses away from the receptors, are discussed. Finally, the concept of lateral inhibition, as usually understood and applied to odor coding by mitral (or equivalent) cells, is challenged and extended to a broader context, possibly more appropriate for olfactory processing.},
	number = {5440},
	journal = {Science},
	author = {Laurent, G},
	month = oct,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {723--728},
}

@article{stopfer_short-term_1999,
	title = {Short-term memory in olfactory network dynamics},
	volume = {402},
	abstract = {Neural assemblies in a number of animal species display self-organized, synchronized oscillations in response to sensory stimuli in a variety of brain areas. In the olfactory system of insects, odour-evoked oscillatory synchronization of antennal lobe projection neurons (PNs) is superimposed on slower and stimulus-specific temporal activity patterns. Hence, each odour activates a specific and dynamic projection neuron assembly whose evolution during a stimulus is locked to the oscillation clock. Here we examine, using locusts, the changes in population dynamics of projection-neuron assemblies over repeated odour stimulations, as would occur when an animal first encounters and then repeatedly samples an odour for identification or localization. We find that the responses of these assemblies rapidly decrease in intensity, while they show a marked increase in spike time precision and inter-neuronal oscillatory coherence. Once established, this enhanced precision in the representation endures for several minutes. This change is stimulus-specific, and depends on events within the antennal lobe circuits, independent of olfactory receptor adaptation: it may thus constitute a form of sensory memory. Our results suggest that this progressive change in olfactory network dynamics serves to converge, over repeated odour samplings, on a more precise and readily classifiable odour representation, using relational information contained across neural assemblies.},
	number = {6762},
	journal = {Nature},
	author = {Stopfer, M and Laurent, G},
	month = dec,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {664--668},
}

@article{wehr_odour_1996,
	title = {Odour encoding by temporal sequences of firing in oscillating neural assemblies},
	volume = {384},
	abstract = {Stimulus-evoked oscillatory synchronization of activity has been observed in many neural systems, including the cerebral cortex of mammals and the brain of insects. The possible functions of such rhythmic synchronization in neural coding, however, remain largely speculative. In the locust, odours evoke activity in dynamic (evolving) ensembles of transiently synchronized neurons. We report here that the active neurons composing these ensembles change in a stimulus-specific manner and with a high degree of reliability on a cycle-by-cycle basis during an odour response. Hence, information about an odour is contained not only in the neural assembly active at each oscillation cycle, but also in the precise temporal sequence in which these assemblies are updated during an odour response. Neural coding with oscillations thus allows combinatorial representations in time as well as in space.},
	number = {6605},
	journal = {Nature},
	author = {Wehr, M and Laurent, G},
	month = nov,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {162--166},
}

@article{stopfer_impaired_1997,
	title = {Impaired odour discrimination on desynchronization of odour-encoding neural assemblies},
	volume = {390},
	abstract = {Stimulus-evoked oscillatory synchronization of neural assemblies has been described in the olfactory and visual systems of several vertebrates and invertebrates. In locusts, information about odour identity is contained in the timing of action potentials in an oscillatory population response, suggesting that oscillations may reflect a common reference for messages encoded in time. Although the stimulus-evoked oscillatory phenomenon is reliable, its roles in sensation, perception, memory formation and pattern recognition remain to be demonstrated–a task requiring a behavioural paradigm. Using honeybees, we now demonstrate that odour encoding involves, as it does in locusts, the oscillatory synchronization of assemblies of projection neurons and that this synchronization is also selectively abolished by picrotoxin, an antagonist of the GABA(A) (gamma-aminobutyric acid) receptor. By using a behavioural learning paradigm, we show that picrotoxin-induced desynchronization impairs the discrimination of molecularly similar odorants, but not that of dissimilar odorants. It appears, therefore, that oscillatory synchronization of neuronal assemblies is functionally relevant, and essential for fine sensory discrimination. This suggests that oscillatory synchronization and the kind of temporal encoding it affords provide an additional dimension by which the brain could segment spatially overlapping stimulus representations.},
	number = {6655},
	journal = {Nature},
	author = {Stopfer, M and Bhagavan, S and Smith, B H and Laurent, G},
	month = nov,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {70--74},
}

@article{bekkers_presynaptic_1990,
	title = {Presynaptic mechanism for long-term potentiation in the hippocampus},
	volume = {346},
	abstract = {Experiments analysing the statistical properties of synaptic transmission, before and after the induction of long-term potentiation (LTP), suggest that expression of LTP largely arises in a presynaptic mechanism–an increased probability of transmitter release.},
	number = {6286},
	journal = {Nature},
	author = {Bekkers, Jm and Stevens, Cf},
	month = aug,
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {724--729},
}

@article{bekkers_nmda_1989,
	title = {{NMDA} and non-{NMDA} receptors are co-localized at individual excitatory synapses in cultured rat hippocampus},
	volume = {341},
	abstract = {A CENTRAL assumption about long-term potentiation in the hippocampus is that the two classes of glutamate-receptor ion channel, the N-methyl-D-aspartate (NMDA) and the kainate/quisqualate (non-NMDA) subtypes, are co-localized at individual excitatory synapses. This assumption is important because of the perceived interplay between NMDA and non-NMDA receptors in the induction and expression of long-term potentiation: the NMDA class, by virtue of its voltage-dependent channel block by magnesium and calcium permeability, provides the trigger for the induction of long-term potentiation, whereas the actual enhancement of synaptic efficacy is thought to be provided by the non-NMDA class. If both receptor subtypes are present at the one synapse, such cross-modulation could occur rapidly and locally through diffusible factors. By measuring miniature synaptic currents in cultured hippocampal neurons we show that the majority (approximately 70\%) of the excitatory synapses on a postsynaptic cell possess both kinds of receptor, although to different extents. Of the remaining excitatory synapses, approximately 20\% contain only the non-NMDA subtype and the rest possess only NMDA receptors. This finding provides direct evidence for co-localization of glutamate-receptor subtypes at individual synapses, and also points to the possibility that long-term potentiation might be differentially expressed at each synapse according to the mix of receptor subtypes at that synapse.},
	number = {6239},
	journal = {Nature},
	author = {Bekkers, Jm and Stevens, Cf},
	month = sep,
	year = {1989},
	keywords = {merged\_fiete.bib},
	pages = {230--233},
}

@article{arancio_activity-dependent_1995,
	title = {Activity-dependent long-term enhancement of transmitter release by presynaptic 3',5'-cyclic {GMP} in cultured hippocampal neurons},
	volume = {376},
	abstract = {Long-term potentiation (LTP) in hippocampus is a type of synaptic plasticity that is thought to be involved in learning and memory. Several lines of evidence suggest that LTP involves 3',5'-cyclic GMP (cGMP), perhaps as an activity-dependent presynaptic effector of one or more retrograde messengers (refs 2-12, but see ref. 13). However, previous results are also consistent with postsynaptic effects of cGMP. This is difficult to test in hippocampal slices, but more rigorous tests are possible in dissociated cell culture. We have therefore developed a reliable method for producing N-methyl-D-aspartate (NMDA) receptor-dependent LTP at synapses between individual hippocampal pyramidal neurons in culture. We report that inhibitors of guanylyl cyclase or of cGMP-dependent protein kinase block potentiation by either tetanic stimulation or low-frequency stimulation paired with postsynaptic depolarization. Conversely, application of 8-Br-cGMP to the bath or injection of cGMP into the presynaptic neuron produces activity-dependent long-lasting potentiation. The potentiation by cGMP involves an increase in transmitter release that is in part independent of changes in the presynaptic action potential. These results support a presynaptic role for cGMP in LTP.},
	number = {6535},
	journal = {Nature},
	author = {Arancio, O and Kandel, Er and Hawkins, Rd},
	month = jul,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {74--80},
}

@article{sawamura_numerical_2002,
	title = {Numerical representation for action in the parietal cortex of the monkey},
	volume = {415},
	abstract = {The anterior part of the parietal association area in the cerebral cortex of primates has been implicated in the integration of somatosensory signals, which generate neural images of body parts and apposed objects and provide signals for sensorial guidance of movements. Here we show that this area is active in primates performing numerically based behavioural tasks. We required monkeys to select and perform movement A five times, switch to movement B for five repetitions, and return to movement A, in a cyclical fashion. Cellular activity in the superior parietal lobule reflected the number of self-movement executions. For the most part, the number-selective activity was also specific for the type of movement. This type of numerical representation of self-action was seen less often in the inferior parietal lobule, and rarely in the primary somatosensory cortex. Such activity in the superior parietal lobule is useful for processing numerical information, which is necessary to provide a foundation for the forthcoming motor selection.},
	number = {6874},
	journal = {Nature},
	author = {Sawamura, H and Shima, K and Tanji, J},
	month = feb,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {918--922},
}

@article{barry_liquid_1991,
	title = {Liquid junction potentials and small cell effects in patch-clamp analysis},
	volume = {121},
	number = {2},
	journal = {J. Membr. Biol.},
	author = {Barry, Ph and Lynch, Jw},
	month = apr,
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {101--117},
}

@article{marshall_hippocampal_2002,
	title = {Hippocampal pyramidal cell-interneuron spike transmission is frequency dependent and responsible for place modulation of interneuron discharge},
	volume = {22},
	abstract = {The interplay between principal cells and interneurons plays an important role in timing the activity of individual cells. We investigated the influence of single hippocampal CA1 pyramidal cells on putative interneurons. The activity of CA1 pyramidal cells was controlled intracellularly by current injection, and the activity of neighboring interneurons was recorded extracellularly in the urethane-anesthetized rat. Spike transmission probability between monosynaptically connected pyramidal cell-interneuron pairs was frequency dependent and highest between 5 and 25 Hz. In the awake animal, interneurons were found that had place-modulated firing rates, with place maps similar to their presynaptic pyramidal neuron. Thus, single pyramidal neurons can effectively determine the firing patterns of their interneuron targets.},
	number = {2},
	journal = {J. Neurosci.},
	author = {Marshall, L and Henze, Da and Hirase, H and Leinekugel, X and Dragoi, G and Buzsaki, G},
	month = jan,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {RC197},
}

@article{henze_action_2001,
	title = {Action potential threshold of hippocampal pyramidal cells in vivo is increased by recent spiking activity},
	volume = {105},
	abstract = {Understanding the mechanisms that influence the initiation of action potentials in single neurons is an important step in determining the way information is processed by neural networks. Therefore, we have investigated the properties of action potential thresholds for hippocampal neurons using in vivo intracellular recording methods in Sprague-Dawley rats. The use of in vivo recording has the advantage of the presence of naturally occurring spatio-temporal patterns of synaptic activity which lead to action potential initiation. We have found there is a large variability in the threshold voltage (5.7+/-1.7 mV; n=22) of individual action potentials. We have identified two separate factors that contribute to this variation in threshold: (1) fast rates of membrane potential change prior to the action potential are associated with more hyperpolarized thresholds (increased excitability) and (2) the occurrence of other action potentials in the 1 s prior to any given action potential is associated with more depolarized thresholds (decreased excitability). We suggest that prior action potentials cause sodium channel inactivation that recovers with approximately a 1-s time constant and thus depresses action potential threshold during this period.},
	number = {1},
	journal = {Neuroscience},
	author = {Henze, Da and Buzsaki, G},
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {121--130},
}

@article{friedrich_dynamic_2001,
	title = {Dynamic optimization of odor representations by slow temporal patterning of mitral cell activity},
	volume = {291},
	abstract = {Mitral cells (MCs) in the olfactory bulb (OB) respond to odors with slow temporal firing patterns. The representation of each odor by activity patterns across the MC population thus changes continuously throughout a stimulus, in an odor-specific manner. In the zebrafish OB, we found that this distributed temporal patterning progressively reduced the similarity between ensemble representations of related odors, thereby making each odor's representation more specific over time. The tuning of individual MCs was not sharpened during this process. Hence, the individual responses of MCs did not become more specific, but the odor-coding MC assemblies changed such that their overlap decreased. This optimization of ensemble representations did not occur among olfactory afferents but resulted from OB circuit dynamics. Time can therefore gradually optimize stimulus representations in a sensory network.},
	number = {5505},
	journal = {Science},
	author = {Friedrich, R W and Laurent, G},
	month = feb,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {889--894},
}

@article{kay_odor-_1999,
	title = {Odor- and context-dependent modulation of mitral cell activity in behaving rats},
	volume = {2},
	abstract = {The projections and odor responses of mammalian olfactory receptor neurons, as well as the physiology of the bulb's principal neurons-the mitral cells (MCs)-are known from studies in slices and anesthetized animals. In behaving rats trained to discriminate between two odors associated with different reinforcers, we examined MC responses following alternated odor-reinforcer pairings. Whereas only 11\% of the recorded MCs showed changes in odor-selective firing rate during the odor-sampling phase, 94\% of MCs modulated activity during specific behaviors surrounding odor sampling. These cell- and odor-selective responses were not primary sensory responses; rather, they depended (reversibly) on the predictive value of each odor. MC activity thus depends critically on efferent influences linked to the animal's experience and behavior.},
	number = {11},
	journal = {Nat. Neurosci.},
	author = {Kay, L M and Laurent, G},
	month = nov,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {1003--1009},
}

@article{laurent_temporal_1996,
	title = {Temporal representations of odors in an olfactory network},
	volume = {16},
	abstract = {The responses of projection neurons in the antennal lobe of the locust brain (the functional analog of mitral-tufted cells in the vertebrate olfactory bulb) to natural blends and simple odors were studied with multiple intra- and extracellular recordings in vivo. Individual odors evoked complex temporal response patterns in many neurons. These patterns differed across odors for a given neuron and across neurons for a given odor, but were stable for each neuron over repeated presentations (separated by seconds to minutes) of the same odor. The response of individual neurons to an odor was superimposed on an odor-specific coherent oscillatory population activity. Each neuron usually participated in the coherent oscillations during one or more specific epochs of the ensemble activity. These epochs of phase locking were reliable for each neuron over tens of repeated presentations of one odor. The timing of these epochs of synchronization differed across neurons and odors. Correlated activity of specific pairs of neurons, hence, generally occurred transiently during the population response, at times that were specific to these pairs and to the odor smelled. The field potential oscillations, therefore, fail to reveal a progressive transformation of the synchronized ensemble as the response to the odor unfolds. We propose that (1) odors are represented by spatially and temporally distributed ensembles of coherently firing neurons, and (2) the field potential oscillations that characterize odor responses in the olfactory system occur, at least in this animal, in parallel with a slower dynamic odor representation.},
	number = {12},
	journal = {J. Neurosci.},
	author = {Laurent, G and Wehr, M and Davidowitz, H},
	month = jun,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {3837--3847},
}

@article{wehr_relationship_1999,
	title = {Relationship between afferent and central temporal patterns in the locust olfactory system},
	volume = {19},
	abstract = {Odors evoke synchronized oscillations and slow temporal patterns in antennal lobe neurons and fast oscillations in the mushroom body local field potential (LFP) of the locust. What is the contribution of primary afferents in the generation of these dynamics? We addressed this question in two ways. First, we recorded odor-evoked afferent activity in both isolated antennae and intact preparations. Odor-evoked population activity in the antenna and the antennal nerve consisted of a slow potential deflection, similar for many odors. This deflection contained neither oscillatory nor odor-specific slow temporal patterns, whereas simultaneously recorded mushroom body LFPs exhibited clear 20-30 Hz oscillations. This suggests that the temporal patterning of antennal lobe and mushroom body neurons is generated downstream of the olfactory receptor axons. Second, we electrically stimulated arrays of primary afferents in vivo. A brief shock to the antennal nerve produced compound PSPs in antennal lobe projection neurons, with two peaks at an approximately 50 msec interval. Prolonged afferent stimulation with step, ramp, or slow sine-shaped voltage waveforms evoked sustained 20-30 Hz oscillations in projection neuron membrane potential and in the mushroom body LFP. Projection neuron and mushroom body oscillations were phase-locked and reliable across trials. Synchronization of projection neurons was seen directly in paired intracellular recordings. Pressure injection of picrotoxin into the antennal lobe eliminated the oscillations evoked by electrical stimulation. Different projection neurons could express different temporal patterns in response to the same electrical stimulus, as seen for odor-evoked responses. Conversely, individual projection neurons could express different temporal patterns of activity in response to step stimulation of different spatial arrays of olfactory afferents. These patterns were reliable and remained distinct across different stimulus intensities. We conclude that oscillatory synchronization of olfactory neurons originates in the antennal lobe and that slow temporal patterns in projection neurons can arise in the absence of temporal patterning of the afferent input.},
	number = {1},
	journal = {J. Neurosci.},
	author = {Wehr, M and Laurent, G},
	month = jan,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {381--390},
}

@article{macleod_distinct_1996,
	title = {Distinct mechanisms for synchronization and temporal patterning of odor-encoding neural assemblies},
	volume = {274},
	abstract = {Stimulus-evoked oscillatory synchronization of neural assemblies and temporal patterns of neuronal activity have been observed in many sensory systems, such as the visual and auditory cortices of mammals or the olfactory system of insects. In the locust olfactory system, single odor puffs cause the immediate formation of odor-specific neural assemblies, defined both by their transient synchronized firing and their progressive transformation over the course of a response. The application of an antagonist of ionotropic gamma-aminobutyric acid (GABA) receptors to the first olfactory relay neuropil selectively blocked the fast inhibitory synapse between local and projection neurons. This manipulation abolished the synchronization of the odor-coding neural ensembles but did not affect each neuron's temporal response patterns to odors, even when these patterns contained periods of inhibition. Fast GABA-mediated inhibition, therefore, appears to underlie neuronal synchronization but not response tuning in this olfactory system. The selective desynchronization of stimulus-evoked oscillating neural assemblies in vivo is now possible, enabling direct functional tests of their significance for sensation and perception.},
	number = {5289},
	journal = {Science},
	author = {Macleod, K and Laurent, G},
	month = nov,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {976--979},
}

@article{laurent_dynamical_1996,
	title = {Dynamical representation of odors by oscillating and evolving neural assemblies},
	volume = {19},
	abstract = {Although smells are some of the most evocative and emotionally charged sensory inputs known to us, we still understand relatively little about olfactory processing and odor representation in the brain. This review summarizes physiological results obtained from an insect olfactory system and presents a functional scheme for odor coding that is compatible with data from other animals, including mammals. This coding scheme consists of three main and concurrent odor-induced phenomena: 20-30 Hz oscillatory mass activity; patterned and odor-specific neuronal responses; and transient, dynamic synchronization of odor-specific neural assemblies. When these phenomena are considered together, odors appear to be represented combinatorially by dynamical neural assemblies, defined partly by the transient but stimulus-specific synchronization of their neuronal components.},
	number = {11},
	journal = {Trends Neurosci.},
	author = {Laurent, G},
	month = nov,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {489--496},
}

@article{nadasdy_replay_1999,
	title = {Replay and time compression of recurring spike sequences in the hippocampus},
	volume = {19},
	abstract = {Information in neuronal networks may be represented by the spatiotemporal patterns of spikes. Here we examined the temporal coordination of pyramidal cell spikes in the rat hippocampus during slow-wave sleep. In addition, rats were trained to run in a defined position in space (running wheel) to activate a selected group of pyramidal cells. A template-matching method and a joint probability map method were used for sequence search. Repeating spike sequences in excess of chance occurrence were examined by comparing the number of repeating sequences in the original spike trains and in surrogate trains after Monte Carlo shuffling of the spikes. Four different shuffling procedures were used to control for the population dynamics of hippocampal neurons. Repeating spike sequences in the recorded cell assemblies were present in both the awake and sleeping animal in excess of what might be predicted by random variations. Spike sequences observed during wheel running were “replayed” at a faster timescale during single sharp-wave bursts of slow-wave sleep. We hypothesize that the endogenously expressed spike sequences during sleep reflect reactivation of the circuitry modified by previous experience. Reactivation of acquired sequences may serve to consolidate information.},
	number = {21},
	journal = {J. Neurosci.},
	author = {Nadasdy, Z and Hirase, H and Czurko, A and Csicsvari, J and Buzsaki, G},
	month = nov,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {9497--9507},
}

@article{riehle_dynamical_2000,
	title = {Dynamical changes and temporal precision of synchronized spiking activity in monkey motor cortex during movement preparation},
	volume = {94},
	abstract = {Movement preparation is considered to be based on central processes which are responsible for improving motor performance. For instance, it has been shown that motor cortical neurones change their activity selectively in relation to prior information about movement parameters. However, it is not clear how groups of neurones dynamically organize their activity to cope with computational demands. The aim of the study was to compare the firing rate of multiple simultaneously recorded neurones with the interaction between them by describing not only the frequency of occurrence of epochs of significant synchronization, but also its modulation in time and its changes in temporal precision during an instructed delay. Multiple single-neurone activity was thus recorded in monkey motor cortex during the performance of two different delayed multi-directional pointing tasks. In order to detect conspicuous spike coincidences in simultaneously recorded spike trains by tolerating temporal jitter ranging from 0 to 20 ms and to calculate their statistical significance, a modified method of the 'Unitary Events' analysis was used. Two main results were obtained. First, simultaneously recorded neurones synchronize their spiking activity in a highly dynamic way. Synchronization becomes significant only during short periods (about 100 to 200 ms). Several such periods occurred during a behavioural trial more or less regularly. Second, in many pairs of neurones, the temporal precision of synchronous activity was highest at the end of the preparatory period. As a matter of fact, at the beginning of this period, after the presentation of the preparatory signal, neurones significantly synchronize their spiking activity, but with low temporal precision. As time advances, significant synchronization becomes more precise. Data indicate that not only the discharge rate is involved in preparatory processes, but also temporal aspects of neuronal activity as expressed in the precise synchronization of individual action potentials.},
	number = {5-6},
	journal = {J. Physiol. Paris},
	author = {Riehle, A and Grammont, F and Diesmann, M and Grun, S},
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {569--582},
}

@article{riehle_spike_1997,
	title = {Spike synchronization and rate modulation differentially involved in motor cortical function},
	volume = {278},
	abstract = {It is now commonly accepted that planning and execution of movements are based on distributed processing by neuronal populations in motor cortical areas. It is less clear, though, how these populations organize dynamically to cope with the momentary computational demands. Simultaneously recorded activities of neurons in the primary motor cortex of monkeys during performance of a delayed-pointing task exhibited context-dependent, rapid changes in the patterns of coincident action potentials. Accurate spike synchronization occurred in relation to external events (stimuli, movements) and was commonly accompanied by discharge rate modulations but without precise time locking of the spikes to these external events. Spike synchronization also occurred in relation to purely internal events (stimulus expectancy), where firing rate modulations were distinctly absent. These findings indicate that internally generated synchronization of individual spike discharges may subserve the cortical organization of cognitive motor processes.},
	number = {5345},
	journal = {Science},
	author = {Riehle, A and Grun, S and Diesmann, M and Aertsen, A},
	month = dec,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {1950--1953},
}

@article{baker_precise_2000,
	title = {Precise spatiotemporal repeating patterns in monkey primary and supplementary motor areas occur at chance levels},
	volume = {84},
	abstract = {Precise spatiotemporal patterns in neural discharge are a possible mechanism for information encoding in the brain. Previous studies have found that such patterns repeat and appear to relate to key behavioral events. Whether these patterns occur above chance levels remains controversial. To address this question, we have made simultaneous recordings from between two and nine neurons in the primary motor cortex and supplementary motor area of three monkeys while they performed a precision grip task. Out of a total of 67 neurons, 46 were antidromically identified as pyramidal tract neurons. Sections of recordings 60 s long were searched for patterns involving three or more spikes that repeated at least twice. The allowed jitter for pattern repetition was 3 ms, and the pattern length was limited to 192 ms. In all 11 recordings analyzed, large numbers of repeating patterns were found. To assess the expected chance level of patterns, “surrogate” datasets were generated. These had the same moment-by-moment modulation in firing rate as the experimental spike trains, and matched their interspike interval distribution, but did not preserve the precise timing of individual spikes. The number of repeating patterns in 10 randomly generated surrogates was used to form 99\% confidence limits on the repeating pattern count expected by chance. There was close agreement between these confidence limits and the number of patterns seen in the experimental data. Analysis of high complexity patterns was carried out in four long recordings (mean duration 23.2 min, mean number of neurons simultaneously recorded 7.5). This analysis logged only patterns composed of a larger number (7-11) of spikes. The number of patterns seen in the surrogate datasets showed a small but significant excess over those seen in the original experimental data; this is discussed in the context of surrogate generation. The occurrence of repeating patterns in the experimental data were strongly associated with particular phases of the precision grip task; however, a similar task dependence was seen for the surrogate data. When a repeating pattern was used as a template to find inexact matches, in which up to half of the component spikes could be missing, similar numbers of matches were found in experimental and surrogate data, and the time of occurrence of such matches showed the same task dependence. We conclude that the existence of precise repeating patterns in our data are not due to cortical mechanisms that favor this form of coding, since as many, if not more, patterns are produced by spike trains constructed only to modulate their firing rate in the same way as the experimental data, and to match the interspike interval histograms. The task dependence of pattern occurrence is explicable as an artifact of the modulation of neural firing rate. The consequences for theories of temporal coding in the cortex are discussed.},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Baker, Sn and Lemon, Rn},
	month = oct,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1770--1780},
}

@article{baker_precise_2000-1,
	title = {Precise spatiotemporal repeating patterns in monkey primary and supplementary motor areas occur at chance levels},
	volume = {84},
	abstract = {Precise spatiotemporal patterns in neural discharge are a possible mechanism for information encoding in the brain. Previous studies have found that such patterns repeat and appear to relate to key behavioral events. Whether these patterns occur above chance levels remains controversial. To address this question, we have made simultaneous recordings from between two and nine neurons in the primary motor cortex and supplementary motor area of three monkeys while they performed a precision grip task. Out of a total of 67 neurons, 46 were antidromically identified as pyramidal tract neurons. Sections of recordings 60 s long were searched for patterns involving three or more spikes that repeated at least twice. The allowed jitter for pattern repetition was 3 ms, and the pattern length was limited to 192 ms. In all 11 recordings analyzed, large numbers of repeating patterns were found. To assess the expected chance level of patterns, “surrogate” datasets were generated. These had the same moment-by-moment modulation in firing rate as the experimental spike trains, and matched their interspike interval distribution, but did not preserve the precise timing of individual spikes. The number of repeating patterns in 10 randomly generated surrogates was used to form 99\% confidence limits on the repeating pattern count expected by chance. There was close agreement between these confidence limits and the number of patterns seen in the experimental data. Analysis of high complexity patterns was carried out in four long recordings (mean duration 23.2 min, mean number of neurons simultaneously recorded 7.5). This analysis logged only patterns composed of a larger number (7-11) of spikes. The number of patterns seen in the surrogate datasets showed a small but significant excess over those seen in the original experimental data; this is discussed in the context of surrogate generation. The occurrence of repeating patterns in the experimental data were strongly associated with particular phases of the precision grip task; however, a similar task dependence was seen for the surrogate data. When a repeating pattern was used as a template to find inexact matches, in which up to half of the component spikes could be missing, similar numbers of matches were found in experimental and surrogate data, and the time of occurrence of such matches showed the same task dependence. We conclude that the existence of precise repeating patterns in our data are not due to cortical mechanisms that favor this form of coding, since as many, if not more, patterns are produced by spike trains constructed only to modulate their firing rate in the same way as the experimental data, and to match the interspike interval histograms. The task dependence of pattern occurrence is explicable as an artifact of the modulation of neural firing rate. The consequences for theories of temporal coding in the cortex are discussed.},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Baker, Sn and Lemon, Rn},
	month = oct,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1770--1780},
}

@article{buzsaki_hippocampal_2001,
	title = {Hippocampal {GABAergic} interneurons: a physiological perspective},
	volume = {26},
	abstract = {Oscillations within and across neuronal systems are believed to serve various complex functions, such as perception, cognition, movement initiation, plasticity and memory. GABAergic interneurons and their inhibitory synapses play a major role in these oscillatory patterns. Networks of inhibitory interneurons impose a coordinated oscillatory “context” for the “content” carried by networks of principal cells. This hypothesis implies that GABAergic neuronal “supernetworks” may cooperatively entrain large populations of pyramidal cells throughout the forebrain. Experiments on hippocampal interneurons are reviewed and possible solutions for some of these complex functions are illustrated.},
	number = {8-9},
	journal = {Neurochem. Res.},
	author = {Buzsaki, G},
	month = sep,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {899--905},
}

@article{christensen_multi-unit_2000,
	title = {Multi-unit recordings reveal context-dependent modulation of synchrony in odor-specific neural ensembles},
	volume = {3},
	abstract = {We used neural ensemble recording to examine odor-evoked ensemble patterns in the moth antennal (olfactory) lobe. Different odors are thought to evoke unique spatiotemporal patterns of glomerular activity, but little is known about the population dynamics underlying formation of these patterns. Using a silicon multielectrode array, we observed dynamic network interactions within and between glomeruli. Whereas brief odor pulses repeatedly triggered activity in the same coding ensemble, the temporal pattern of synchronous activity superimposed on the ensemble was neither oscillatory nor odor specific. Rather, synchrony strongly depended on contextual variables such as odor intensity and intermittency. Also, because of emergent inhibitory circuit interactions, odor blends evoked temporal ensemble patterns that could not be predicted from the responses to the individual odorants. Thus even at this early stage of information processing, the timing of odor-evoked neural representations is modulated by key stimulus factors unrelated to the molecular identity of the odor.},
	number = {9},
	journal = {Nat. Neurosci.},
	author = {Christensen, Ta and Pawlowski, Vm and Lei, H and Hildebrand, Jg},
	month = sep,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {927--931},
}

@article{galarreta_spike_2001,
	title = {Spike transmission and synchrony detection in networks of {GABAergic} interneurons},
	volume = {292},
	abstract = {The temporal pattern and relative timing of action potentials among neocortical neurons may carry important information. However, how cortical circuits detect or generate coherent activity remains unclear. Using paired recordings in rat neocortical slices, we found that the firing of fast-spiking cells can reflect the spiking pattern of single-axon pyramidal inputs. Moreover, this property allowed groups of fast-spiking cells interconnected by electrical and gamma-aminobutyric acid (GABA)-releasing (GABAergic) synapses to detect the relative timing of their excitatory inputs. These results indicate that networks of fast-spiking cells may play a role in the detection and promotion of synchronous activity within the neocortex.},
	number = {5525},
	journal = {Science},
	author = {Galarreta, M and Hestrin, S},
	month = jun,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {2295--2299},
}

@article{vickers_odour-plume_2001,
	title = {Odour-plume dynamics influence the brain's olfactory code},
	volume = {410},
	abstract = {The neural computations used to represent olfactory information in the brain have long been investigated. Recent studies in the insect antennal lobe suggest that precise temporal and/or spatial patterns of activity underlie the recognition and discrimination of different odours, and that these patterns may be strengthened by associative learning. It remains unknown, however, whether these activity patterns persist when odour intensity varies rapidly and unpredictably, as often occurs in nature. Here we show that with naturally intermittent odour stimulation, spike patterns recorded from moth antennal-lobe output neurons varied predictably with the fine-scale temporal dynamics and intensity of the odour. These data support the hypothesis that olfactory circuits compensate for contextual variations in the stimulus pattern with high temporal precision. The timing of output neuron activity is constantly modulated to reflect ongoing changes in stimulus intensity and dynamics that occur on a millisecond timescale.},
	number = {6827},
	journal = {Nature},
	author = {Vickers, Nj and Christensen, Ta and Baker, Tc and Hildebrand, Jg},
	month = mar,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {466--470},
}

@article{williams_changes_1999,
	title = {Changes in adult zebra finch song require a forebrain nucleus that is not necessary for song production},
	volume = {39},
	abstract = {Male zebra finches normally crystallize song at approximately 90 days and do not show vocal plasticity as adults. However, changes to adult song do occur after unilateral tracheosyringeal (ts) nerve injury, which denervates one side of the vocal organ. We examined the effect of placing bilateral lesions in LMAN (a nucleus required for song development but not for song maintenance in adults) upon the song plasticity that is induced by ts nerve injury in adults. The songs of birds that received bilateral lesions within LMAN followed by right ts nerve injury silenced, on average, 0.25 syllables, and added 0.125 syllables (for an average turnover of 0.375 syllables), and changed neither the frequency with which individual syllables occurred within songs nor the motif types they used most often. In contrast, the songs of birds that received sham lesions followed by ts nerve injury lost, on average, 1.625 syllables, silenced 0.125 syllables, and added 0.75 syllables, turning over an average of 2.5 syllables. They also significantly changed both the frequency with which individual syllables were included in songs and the motif variants used. Thus, song plasticity induced in adult zebra finches with crystallized songs requires the presence of LMAN, a nucleus which had been thought to play a role in vocal production only during song learning. Although the changes to adult songs induced by nerve transection are more limited than those that arise during song development, the same circuitry appears to underlie both types of plasticity.},
	number = {1},
	journal = {J. Neurobiol.},
	author = {Williams, H and Mehta, N},
	month = apr,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {14--28},
}

@article{wild_neural_1997,
	title = {Neural pathways for the control of birdsong production},
	volume = {33},
	abstract = {As in humans, song production in birds involves the intricate coordination of at least three major groups of muscles: namely, those of the syrinx, the respiratory apparatus, and the upper vocal tract, including the jaw. The pathway in songbirds that controls the syrinx originates in the telencephalon and projects via the occipitomesencephalic tract directly upon vocal motoneurons in the medulla. Activity in this pathway configures the syrinx into phonatory positions for the production of species typical vocalizations. Another component of this pathway mediates control of respiration during vocalization, since it projects upon both expiratory and inspiratory groups of premotor neurons in the ventrolateral medulla, as well as upon several other nuclei en route. This pathway appears to be primarily involved with the control of the temporal pattern of song, but is also importantly involved in the control of vocal intensity, mediated via air sac pressure. There are extensive interconnections between the vocal and respiratory pathways, especially at brain-stem levels, and it may be these that ensure the necessary temporal coordination of syringeal and respiratory activity. The pathway mediating control of the jaw appears to be different from those mediating control of the syrinx and respiratory muscles. It originates in a different part of the archistriatum and projects upon premotor neurons in the medulla that appear to be separate from those projecting upon the syringeal motor nucleus. The separateness of this pathway may reflect the imperfect correlation of jaw movements with the dynamic and acoustic features of song. The brainstem pathways mediating control of vocalization and respiration in songbirds have distinct similarities to those in mammals such as cats and monkeys. However, songbirds, like humans, but unlike most other non-songbirds, have developed a telencephalic vocal control system for the production of learned vocalizations.},
	number = {5},
	journal = {J. Neurobiol.},
	author = {Wild, Jm},
	month = nov,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {653--670},
}

@article{nordeen_projection_1988,
	title = {Projection neurons within a vocal motor pathway are born during song learning in zebra finches},
	volume = {334},
	abstract = {Many birds learn song during a restricted 'sensitive' period. Juveniles memorize a song model, and then learn the pattern of muscle contractions necessary to reproduce the song. Of the neural changes accompanying avian song learning, perhaps the most remarkable is the production of new neurons which are inserted into the hyperstriatum ventralis pars caudalis (HVc), a region critical for song production. We report here that in young male zebra finches many of the new neurons incorporated into the HVc innervate the robust nucleus of the archistriatum (RA) which projects to motor neurons controlling the vocal musculature. Furthermore, far fewer of these new neurons are incorporated into the HVc of either adult males that are beyond the sensitive learning period, or young females (who do not develop song). Thus, a major portion of the vocal motor pathway is actually created during song learning. This may enable early sensory experience and vocal practice to not only modify existing neuronal circuits, but also shape the insertion and initial synaptic contacts of neurons controlling adult song.},
	number = {6178},
	journal = {Nature},
	author = {Nordeen, Kw and Nordeen, Ej},
	month = jul,
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {149--151},
}

@article{tchernichovski_dynamics_2001,
	title = {Dynamics of the vocal imitation process: how a zebra finch learns its song},
	volume = {291},
	abstract = {Song imitation in birds provides good material for studying the basic biology of vocal learning. Techniques were developed for inducing the rapid onset of song imitation in young zebra finches and for tracking trajectories of vocal change over a 7-week period until a match to a model song was achieved. Exposure to a model song induced the prompt generation of repeated structured sounds (prototypes) followed by a slow transition from repetitive to serial delivery of syllables. Tracking this transition revealed two phenomena: (i) Imitations of dissimilar sounds can emerge from successive renditions of the same prototype, and (ii) developmental trajectories for some sounds followed paths of increasing acoustic mismatch until an abrupt correction occurred by period doubling. These dynamics are likely to reflect underlying neural and articulatory constraints on the production and imitation of sounds.},
	number = {5513},
	journal = {Science},
	author = {Tchernichovski, O and Mitra, P P and Lints, T and Nottebohm, F},
	month = mar,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {2564--2569},
}

@article{vives_cellular_2000,
	title = {Cellular mechanisms of long-lasting adaptation in visual cortical neurons in vitro},
	volume = {20},
	abstract = {The cellular mechanisms of spike-frequency adaptation during prolonged discharges and of the slow afterhyperpolarization (AHP) that follows, as occur in vivo with contrast adaptation, were investigated with intracellular recordings of cortical neurons in slices of ferret primary visual cortex. Intracellular injection of 2 Hz sinusoidal or constant currents for 20 sec resulted in a slow (tau = 1-10 sec) spike-frequency adaptation, the degree of which varied widely among neurons. Reducing either [Ca(2+)](o) or [Na(+)](o) reduced the rate of spike-frequency adaptation. After the prolonged discharge was a slow (12-75 sec) AHP that was associated with an increase in membrane conductance and a rightward shift in the discharge frequency versus injected current relationship. The reversal potential of the slow AHP was sensitive to changes in [K(+)](o), indicating that it was mediated by a K(+) current. Blockade of transmembrane Ca(2+) conductances did not reduce the slow AHP. In contrast, reductions of [Na(+)](o) reduced the slow AHP, even in the presence of pronounced Ca(2+) spikes. We suggest that the activation of Na(+)-activated and Ca(2+)-activated K(+) currents plays an important role in prolonged spike-frequency adaptation and therefore may contribute to contrast adaptation and other forms of adaptation in the visual system in vivo.},
	number = {11},
	journal = {J. Neurosci.},
	author = {Vives, Sanchez-Mv and Nowak, Lg and Mccormick, Da},
	month = jun,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {4286--4299},
}

@article{vives_membrane_2000,
	title = {Membrane mechanisms underlying contrast adaptation in cat area 17 in vivo},
	volume = {20},
	abstract = {Contrast adaptation is a psychophysical phenomenon, the neuronal bases of which reside largely in the primary visual cortex. The cellular mechanisms of contrast adaptation were investigated in the cat primary visual cortex in vivo through intracellular recording and current injections. Visual cortex cells, and to a much less extent, dorsal lateral geniculate nucleus (dLGN) neurons, exhibited a reduction in firing rate during prolonged presentations of a high-contrast visual stimulus, a process we termed high-contrast adaptation. In a majority of cortical and dLGN cells, the period of adaptation to high contrast was followed by a prolonged (5-80 sec) period of reduced responsiveness to a low-contrast stimulus (postadaptation suppression), an effect that was associated, and positively correlated, with a hyperpolarization of the membrane potential and an increase in apparent membrane conductance. In simple cells, the period of postadaptation suppression was not consistently associated with a decrease in the grating modulated component of the evoked synaptic barrages (the F1 component). The generation of the hyperpolarization appears to be at least partially intrinsic to the recorded cells, because the induction of neuronal activity with the intracellular injection of current resulted in both a hyperpolarization of the membrane potential and a decrease in the spike response to either current injections or visual stimuli. Conversely, high-contrast visual stimulation could suppress the response to low-intensity sinusoidal current injection. We conclude that control of the membrane potential by intrinsic neuronal mechanisms contributes importantly to the adaptation of neuronal responsiveness to varying levels of contrast. This feedback mechanism, internal to cortical neurons, provides them with the ability to continually adjust their responsiveness as a function of their history of synaptic and action potential activity.},
	number = {11},
	journal = {J. Neurosci.},
	author = {Vives, Sanchez-Mv and Nowak, Lg and Mccormick, Da},
	month = jun,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {4267--4285},
}

@article{ram_new_2002,
	title = {A new form of cerebellar long-term potentiation is postsynaptic and depends on nitric oxide but not {cAMP}},
	volume = {99},
	abstract = {Long-term depression (LTD) at cerebellar parallel fiber (PF)-Purkinje cell synapses must be balanced by long-term potentiation (LTP) to prevent saturation and allow reversal of motor learning. The only previously analyzed form of cerebellar LTP is induced by 4-8 Hz PF stimulation and requires cAMP but not nitric oxide. It is a poor candidate to reverse LTD because it is presynaptically expressed whereas LTD is postsynaptic. We now characterize a new form of LTP induced by 1 Hz PF stimulation for at least 300 s. This LTP is postsynaptically expressed, enhanced by chelating postsynaptic Ca(2+), and depends on nitric oxide but not cAMP or cGMP, making it a plausible anti-Hebbian counterpart to Hebbian LTD.},
	number = {12},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Ram, Lev-V and Wong, St and Storm, Dr and Tsien, Ry},
	month = jun,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {8389--8393},
}

@article{lisberger_cerebellar_1998,
	title = {Cerebellar {LTD}: a molecular mechanism of behavioral learning},
	volume = {92},
	abstract = {Department of Physiology and W. M. Keck Foundation Center for Integrative Neuroscience, University of California, San Francisco 94143-0444, USA.},
	number = {6},
	journal = {Cell},
	author = {Lisberger, Sg},
	month = mar,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {701--704},
}

@article{mauk_does_1998,
	title = {Does cerebellar {LTD} mediate motor learning? {Toward} a resolution without a smoking gun},
	volume = {20},
	abstract = {W. M. Keck Center for the Neurobiology of Learning and Memory and Department of Neurobiology and Anatomy, University of Texas Medical School, Houston 77030, USA.},
	number = {3},
	journal = {Neuron},
	author = {Mauk, Md and Garcia, Ks and Medina, Jf and Steele, Pm},
	month = mar,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {359--362},
}

@article{clifford_orthogonal_2001,
	title = {Orthogonal adaptation improves orientation discrimination},
	volume = {41},
	abstract = {We investigated the effect of adaptation on orientation discrimination using two experienced observers, then replicated the main effects using a total of 50 naive subjects. Orientation discrimination around vertical improved after adaptation to either horizontal or vertical gratings, but was impaired by adaptation at 7.5 or 15 degrees from vertical. Improvement was greatest when adapter and test were orthogonal. We show that the results can be understood in terms of a functional model of adaptation in cortical vision.},
	number = {2},
	journal = {Vision Res.},
	author = {Clifford, Cw and Wyatt, Am and Arnold, Dh and Smith, St and Wenderoth, P},
	month = jan,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {151--159},
}

@article{tateno_analytical_2002,
	title = {Analytical characterization of spontaneous firing in networks of developing rat cultured cortical neurons},
	volume = {65},
	abstract = {We have used a multiunit electrode array in extracellular recording to investigate changes in the firing patterns in networks of developing rat cortical neurons. The spontaneous activity of continual asynchronous firing or the alternation of asynchronous spikes and synchronous bursts changed over time so that activity in the later stages consisted exclusively of synchronized bursts. The spontaneous coordinated activity in bursts produced a variability in interburst interval (IBI) sequences that is referred to as “form.” The stochastic and nonlinear dynamical analysis of IBI sequences revealed that these sequences reflected a largely random process and that the form for relatively immature neurons was largely oscillatory while the form for the more mature neurons was Poisson-like. The observed IBI sequences thus showed changes in form associated with both the intrinsic properties of the developing cells and the neural response to correlated synaptic inputs due to interaction between the developing neural circuits},
	journal = {Physical Review E},
	author = {Tateno, Takashi and Kawana, Akio and Jimbo, Yasuhiko},
	month = jun,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {051924},
}

@article{priebe_constraints_2002,
	title = {Constraints on the {Source} of {Short}-{Term} {Motion} {Adaptation} in {Macaque} {Area} {MT}. {I}. {The} {Role} of {Input} and {Intrinsic} {Mechanisms}},
	volume = {88},
	abstract = {Neurons in area MT, a motion-sensitive area of extrastriate cortex, respond to a step of target velocity with a transient-sustained firing pattern. The transition from a high initial firing rate to a lower sustained rate occurs over a time course of 20-80 ms and is considered a form of short-term adaptation. The present paper asks whether adaptation is due to input-specific mechanisms such as short-term synaptic depression or if it results from intrinsic cellular mechanisms such as spike-rate adaptation. We assessed the contribution of input-specific mechanisms by using a condition/test paradigm to measure the spatial scale of adaptation. Conditioning and test stimuli were placed within MT receptive fields but were spatially segregated so that the two stimuli would activate different populations of inputs from the primary visual cortex (V1). Conditioning motion at one visual location caused a reduction of the transient firing to subsequent test motion at a second location. The adaptation field, estimated as the region of visual space where conditioning motion caused adaptation, was always larger than the MT receptive field. Use of the same stimulus configuration while recording from direction-selective neurons in V1 failed to demonstrate either adaptation or the transient-sustained response pattern that is the signature of short-term adaptation in MT. We conclude that the shift from transient to sustained firing in MT cells does not result from an input-specific mechanism applied to inputs from V1 because it operates over a wider range of the visual field than is covered by receptive fields of V1 neurons. We used a direct analysis of MT neuron spike trains for many repetitions of the same motion stimulus to assess the contribution to adaptation of intrinsic cellular mechanisms related to spiking. On a trial-by-trial basis, there was no correlation between number of spikes in the transient interval and the interval immediately after the transient period. This is opposite the prediction that there should be a correlation if spikes cause adaptation directly. Further, the transient was suppressed or extinguished, not delayed, in trials in which the neuron emitted zero spikes during the interval that showed a transient in average firing rate. We conclude that the transition from transient to sustained firing in neurons in area MT is caused by mechanisms that are neither input-specific nor controlled by the spiking of the adapting neuron. We propose that the short-term adaptation observed in area MT emerges from the intracortical circuit within MT.},
	number = {1},
	journal = {J. Neurophysiol.},
	author = {Priebe, Nj and Churchland, Mm and Lisberger, Sg},
	month = jul,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {354--369},
}

@article{azouz_physiological_1997,
	title = {Physiological properties of inhibitory interneurons in cat striate cortex},
	volume = {7},
	abstract = {Physiological and morphological properties of identified interneurons in the striate cortex of the cat were studied in vivo by intracellular recording and staining with biocytin. In conformity with in vitro studies, these non-pyramidal fast spiking cells have very brief action potentials associated with a high rate of fall, and a large hyperpolarizing afterpotential. These cells show high discharge rates, little or no spike frequency adaptation in response to depolarizing current injection, as well as a diverse range of firing patterns. Three of the cells were labeled and were found to be aspiny or sparsely spiny basket cells, with bitufted or radial dendritic arrangements, in layers II-IV. Their axonal arborizations were more dense near their somata and extended horizontally or vertically. Of 13 visually responsive cells tested, the receptive field properties of six cells and the orientation and direction preferences of eight cells were determined. Five of the successfully mapped cells had simple receptive fields while one had a complex receptive field type. The orientation and direction tuning properties of the overlapping set of eight cells showed a broad spectrum ranging from unselective to tightly tuned. The majority exhibited a clear preference for orientation and none of the cells were clearly direction selective. Quantitative analysis of the temporal properties of the spike trains during visual stimulation and spontaneous activity revealed that these cells do not exhibit any significant periodic activity, and fired at rates that were well below their maximum in response to depolarizing current pulses.},
	number = {6},
	journal = {Cereb. Cortex},
	author = {Azouz, R and Gray, Cm and Nowak, Lg and Mccormick, Da},
	month = sep,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {534--545},
}

@article{ahmed_estimates_1998,
	title = {Estimates of the net excitatory currents evoked by visual stimulation of identified neurons in cat visual cortex},
	volume = {8},
	abstract = {The action potential discharge response of single neurons to both visual stimulation and injections of current were obtained during intracellular recordings in cat visual cortex in order to estimate the net excitatory current arriving at the soma during visual stimulation. Of 45 neurons recorded intracellularly, 19 pyramidal neurons and one basket cell were labelled with horseradish peroxidase. The discharge of all neurons adapted to constant current. For 40 neurons, a single exponential provided a good fit to the adapting discharge (r2 = 0.73 +/- 0.03) for all current intensities. Superficial layer neurons were significantly faster adapting [P {\textless} 0.001, mean (+/- SEM) time constant of adaptation = 11.5 +/- 1.3 ms; n = 20] than deep layer neurons (mean time constant of adaptation = 51.4 +/- 6.4 ms; n = 10). The percentage adaptation of the spike frequency, \%(peak - adapted rate)/peak, was determined from the fitted exponential. Superficial layer neurons adapted significantly more strongly (P {\textless} 0.01, mean = 67 +/- 3\%) than deep layer neurons (mean = 51 +/- 5\%). The mean firing frequency in response to a current step of 320 ms duration had a linear relationship to the amplitude of the injected current (slope 66 spikes/s/nA; origin zero, mean r2 = 0.94; n = 33). This relationship provided a means of estimating the net peak excitatory current generated by visual stimuli. The estimated mean peak somatic current during the passage of a bar across the receptive field was 1.1 nA and the average current for the duration of the visually evoked discharge was 0.64 nA (n = 17). The transfer response of real and model neurons was obtained by differentiating the discharge response to a step input current and was then used to predict the output of the neuron following an arbitrary input. When these transfer responses were convolved with known input signals in model neurons, the predicted output was close to the simulated response of the model neuron to the same input waveforms. The transfer response was calculated for eight real neurons. Estimates of the net excitatory current arriving at the soma during visual stimulation was obtained by deconvolution. The mean peak somatic current for these neurons was 0.62 nA.},
	number = {5},
	journal = {Cereb. Cortex},
	author = {Ahmed, B and Anderson, Jc and Douglas, Rj and Martin, Ka and Whitteridge, D},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {462--476},
}

@article{priebe_constraints_2002-1,
	title = {Constraints on the {Source} of {Short}-{Term} {Motion} {Adaptation} in {Macaque} {Area} {MT}. {II}. {Tuning} of {Neural} {Circuit} {Mechanisms}},
	volume = {88},
	abstract = {Neurons in area MT, a motion-sensitive area of extrastriate cortex, respond to a step of target velocity with a transient-sustained firing pattern. The transition from a high initial firing rate to a lower sustained rate occurs over a time course of 20-80 ms and is considered a form of short-term adaptation. In the present paper, we compared the tuning of the adaptation to the neuron's tuning to direction and speed. The tuning of adaptation was measured with a condition/test paradigm in which a testing motion of the preferred direction and speed of the neuron under study was preceded by a conditioning motion: the direction and speed of the conditioning motion were varied systematically. The response to the test motion depended strongly on the direction of the conditioning motion. It was suppressed in almost all neurons by conditioning motion in the same direction and could be either suppressed or enhanced by conditioning motion in the opposite direction. Even in neurons that showed suppression for target motion in the nonpreferred direction, the adaptation and response direction tuning were the same. The speed tuning of adaptation was linked much less tightly to the speed tuning of the response of the neuron under study. For just more than 50\% of neurons, the preferred speed of adaptation was more than 1 log unit different from the preferred response speed. Many neurons responded best when slow motions were followed by faster motions (acceleration) or vice versa (deceleration), suggesting that MT neurons may encode information about the change of target velocity over time. Finally, adaptation by conditioning motions of different directions, but not different speeds, altered the latency of the response to the test motion. The adaptation of latency recovered with shorter intervals between the conditioning and test motions than did the adaptation of response size, suggesting that latency and amplitude adaptation are mediated by separate mechanisms. Taken together with the companion paper, our data suggest that short-term motion adaptation in MT is a consequence of the neural circuit in MT and is not mediated by either input-specific mechanisms or intrinsic mechanisms related to the spiking of individual neurons. The circuit responsible for adaptation is tuned for both speed and direction and has the same direction tuning as the circuit responsible for the initial response of MT neurons.},
	number = {1},
	journal = {J. Neurophysiol.},
	author = {Priebe, Nj and Lisberger, Sg},
	month = jul,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {370--382},
}

@article{ringach_orientation_2002,
	title = {Orientation {Selectivity} in {Macaque} {V1}: {Diversity} and {Laminar} {Dependence}},
	volume = {22},
	abstract = {We studied the steady-state orientation selectivity of single neurons in macaque primary visual cortex (V1). To analyze the data, two measures of orientation tuning selectivity, circular variance and orientation bandwidth, were computed from the tuning curves. Circular variance is a global measure of the shape of the tuning curve, whereas orientation bandwidth is a local measure of the sharpness of the tuning curve around its peak. Circular variance in V1 was distributed broadly, indicating a great diversity of orientation selectivity. This diversity was also reflected in the individual cortical layers. However, there was a tendency for neurons with high circular variance, meaning low selectivity for orientation, to be concentrated in layers 4C, 3B, and 5. The relative variation of orientation bandwidth across the cortical layers was less than for circular variance, but it showed a similar laminar dependence. Neurons with large orientation bandwidth were found predominantly in layers 4C and 3B. There was a weak correlation between orientation selectivity and the level of spontaneous activity of the neurons. We also assigned a response modulation ratio for each cell, which is a measure of the linearity of spatial summation. Cells with low modulation ratios tended to have higher circular variance and bandwidth than those with high modulation ratios. These findings suggest a revision to the classical view that nonoriented receptive fields are principally found in layer 4C and the cytochrome oxidase-rich blobs in layer 2/3. Instead, a broad distribution of tuning selectivity is found in all cortical layers, and neurons that are weakly tuned for orientation are ubiquitous in V1 cortex.},
	number = {13},
	journal = {J. Neurosci.},
	author = {Ringach, Dl and Shapley, Rm and Hawken, Mj},
	month = jul,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {5639--5651},
}

@article{fries_oscillatory_2002,
	title = {Oscillatory neuronal synchronization in primary visual cortex as a correlate of stimulus selection},
	volume = {22},
	abstract = {Spike and local field potential activity were recorded simultaneously from multiple sites in primary visual cortex of strabismic cats, while monocular stimulation alternated with dichoptic stimulation, inducing interocular rivalry. During interocular rivalry, there is competition between the two nonfusible stimuli presented to the two eyes, and only one stimulus is selected at any time. We biased this competition in three different ways: (1) we exploited the condition that in strabismic cats there is often one dominant eye that is selected for most of the time. (2) We presented the two stimuli with a temporal offset, which biases competition in favor of the newly appearing stimulus. (3) We presented the two stimuli with highly different contrasts, which biases competition in favor of the stimulus with higher contrast. Whenever competition was biased in favor of the stimulus activating the recorded neurons, gamma-frequency synchronization of the respective responses was enhanced, and vice versa. Firing rates showed some differences between stimulation conditions. However, when present, these changes were inversely related to a competitive advantage of the respective stimulus. We hypothesize that enhanced gamma-frequency synchronization in primary visual cortex is a correlate of stimulus selection. Synchronization is likely to be translated into firing rate changes at later processing stages.},
	number = {9},
	journal = {J. Neurosci.},
	author = {Fries, P and Schroder, Jh and Roelfsema, Pr and Singer, W and Engel, Ak},
	month = may,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {3739--3754},
}

@article{bair_timing_2002,
	title = {The timing of response onset and offset in macaque visual neurons},
	volume = {22},
	abstract = {We used fast, pseudorandom temporal sequences of preferred and antipreferred stimuli to drive neuronal firing rates rapidly between minimal and maximal across the visual system. Stimuli were tailored to the preferences of cells recorded in the lateral geniculate nucleus (magnocellular and parvocellular), primary visual cortex (simple and complex), and the extrastriate motion area MT. We found that cells took longer to turn on (to increase their firing rate) than to turn off (to reduce their rate). The latency difference (onset minus offset) varied from several to tens of milliseconds across cell type and stimulus class and was correlated with spontaneous or driven firing rates for most cell classes. The delay for response onset depended on the nature of the stimulus present before the preferred stimulus appeared, and may result from persistent inhibition caused by antipreferred stimuli or from suppression that followed the offset of the preferred stimulus. The onset delay showed three distinct types of dependence on the temporal sequence of stimuli across classes of cells, implying that suppression may accumulate or wear off with time. Onset latency is generally longer, can be more variable, and has marked stimulus dependence compared with offset latency. This suggests an important role for offset latency in assessing the speed of information transmission in the visual system and raises the possibility that signal offsets provide a timing reference for visual processing. We discuss the origin of the delay in onset latency compared with offset latency and consider how it may limit the utility of certain feedforward circuits.},
	number = {8},
	journal = {J. Neurosci.},
	author = {Bair, W and Cavanaugh, Jr and Smith, Ma and Movshon, Ja},
	month = apr,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {3189--3205},
}

@article{bredfeldt_dynamics_2002,
	title = {Dynamics of spatial frequency tuning in macaque {V1}},
	volume = {22},
	abstract = {Spatial frequency tuning in the lateral geniculate nucleus of the thalamus (LGN) and primary visual cortex (V1) differ substantially. LGN responses are largely low-pass in spatial frequency, whereas the majority of V1 neurons have bandpass characteristics. To study this transformation in spatial selectivity, we measured the dynamics of spatial frequency tuning using a reverse correlation technique. We find that a large proportion of V1 cells show inseparable responses in spatial frequency and time. In several cases, tuning becomes more selective over the course of the response, and the preferred spatial frequency shifts from low to higher frequencies. Many responses also show suppression at low spatial frequencies, which correlates with the increases in response selectivity and the shifts of preferred spatial frequency. These results indicate that suppression plays an important role in the generation of bandpass selectivity in V1.},
	number = {5},
	journal = {J. Neurosci.},
	author = {Bredfeldt, Ce and Ringach, Dl},
	month = mar,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {1976--1984},
}

@article{ringach_suppression_2002,
	title = {Suppression of neural responses to nonoptimal stimuli correlates with tuning selectivity in macaque {V1}},
	volume = {87},
	abstract = {Neural responses in primary visual cortex (area V1) are selective for the orientation and spatial frequency of luminance-modulated sinusoidal gratings. Selectivity could arise from enhancement of the cell's response by preferred stimuli, suppression by nonoptimal stimuli, or both. Here, we report that the majority of V1 neurons do not only elevate their activity in response to preferred stimuli, but their firing rates are also suppressed by nonoptimal stimuli. The magnitude of suppression is similar to that of enhancement. There is a tendency for net response suppression to peak at orientations near orthogonal to the optimal for the cell, but cases where suppression peaks at oblique orientations are observed as well. Interestingly, selectivity and suppression correlate in V1: orientation and spatial frequency selectivity are higher for neurons that are suppressed by nonoptimal stimuli than for cells that are not. This finding is consistent with the idea that suppression plays an important role in the generation of sharp cortical selectivity. We show that nonlinear suppression is required to account for the data. However, the precise structure of the neural circuitry generating the suppressive signal remains unresolved. Our results are consistent with both feedback and (nonlinear) feed-forward inhibition.},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Ringach, Dl and Bredfeldt, Ce and Shapley, Rm and Hawken, Mj},
	month = feb,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {1018--1027},
}

@article{mazer_spatial_2002,
	title = {Spatial frequency and orientation tuning dynamics in area {V1}},
	volume = {99},
	abstract = {Spatial frequency (SF) and orientation tuning are intrinsic properties of neurons in primary visual cortex (area V1). To investigate the neural mechanisms mediating selectivity in the awake animal, we measured the temporal dynamics of SF and orientation tuning. We adapted a high-speed reverse-correlation method previously used to characterize orientation tuning dynamics in anesthetized animals to estimate efficiently the complete spatiotemporal receptive fields in area V1 of behaving macaques. We found that SF and orientation tuning are largely separable over time in single neurons. However, spatiotemporal receptive fields also contain a small nonseparable component that reflects a significant difference in response latency for low and high SF stimuli. The observed relationship between stimulus SF and latency represents a dynamic shift in SF tuning, and suggests that single V1 neurons might receive convergent input from the magno- and parvocellular processing streams. Although previous studies with anesthetized animals suggested that orientation tuning could change dramatically over time, we find no substantial evidence of dynamic changes in orientation tuning.},
	number = {3},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Mazer, Ja and Vinje, We and Mcdermott, J and Schiller, Ph and Gallant, Jl},
	month = feb,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {1645--1650},
}

@article{reich_independent_2001,
	title = {Independent and redundant information in nearby cortical neurons},
	volume = {294},
	abstract = {In the primary visual cortex (V1), nearby neurons are tuned to similar stimulus features, and, depending on the manner and time scale over which neuronal signals are analyzed, the resulting redundancy may mitigate deleterious effects of response variability. We estimated information rates in the short-time scale responses of clusters of up to six simultaneously recorded nearby neurons in monkey V1. Responses were almost independent if we kept track of which neuron fired each spike but were redundant if we summed responses over the cluster. Redundancy was independent of cluster size. Summing neuronal responses to reduce variability discards potentially useful information, and the discarded information increases with cluster size.},
	number = {5551},
	journal = {Science},
	author = {Reich, Ds and Mechler, F and Victor, Jd},
	month = dec,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {2566--2568},
}

@article{brewer_viable_1996,
	title = {Viable cultured neurons in ambient carbon dioxide and hibernation storage for a month},
	volume = {7},
	abstract = {Neurobasal is a bicarbonate-buffered medium optimized for the growth of embryonic rat hippocampal neurons at pH 7.3 in 5\% CO2. Neurons die within hours in this or in other 26 mM bicarbonate buffers when transferred to ambient CO2 (0.2\%). Death is associated with a rapid rise in medium pH to 8.1. A new CO2-independent modification of Neurobasal (Hibernate E), when supplemented with B27, can maintain neuron viability for at least 2 days in ambient CO2. This same medium can also be used to store viable brain tissue for up to a month with refrigeration. These advances should facilitate studies of neuron physiology outside the incubator as well as storing and transporting neuronal tissue.},
	number = {9},
	journal = {Neuroreport},
	author = {Brewer, G j and Price, P j},
	month = jun,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {1509--1512},
}

@article{brewer_optimized_1993,
	title = {Optimized survival of hippocampal neurons in {B27}-supplemented {Neurobasal}, a new serum-free medium combination},
	volume = {35},
	abstract = {We have systematically optimized the concentrations of 20 components of a previously published serum-free medium (Brewer and Cotman, Brain Res 494: 65-74, 1989) for survival of rat embryonic hippocampal neurons after 4 days in culture. This serum-free medium supplement, B27, produced neuron survival above 60\%, independent of plating density above 160 plated cells/mm2. For isolated cells ({\textless} 100 cells/mm2), survival at 4 days was still above 45\%, but could be rescued to the 60\% level at 40 cells/mm2 by simply applying a coverslip on top of the cells. This suggests a need for additional trophic factors. High survival was achieved with osmolarity lower than found in Dulbecco's Modified Eagle's Medium (DMEM), and by reducing cysteine and glutamine concentrations and by the elimination of toxic ferrous sulphate found in DME/F12. Neurobasal is a new medium that incorporates these modifications to DMEM. In B27/Neurobasal, glial growth is reduced to less than 0.5\% of the nearly pure neuronal population, as judged by immunocytochemistry for glial fibrillary acidic protein and neuron-specific enolase. Excellent long-term viability is achieved after 4 weeks in culture with greater than 90\% viability for cells plated at 640/mm2 and greater than 50\% viability for cells plated at 160/mm2. Since the medium also supports the growth of neurons from embryonic rat striatum, substantia nigra, septum, and cortex, and neonatal dentate gyrus and cerebellum (Brewer, in preparation), support for other neuron types is likely. B27/Neurobasal should be useful for in vitro studies of neuronal toxicology, pharmacology, electrophysiology, gene expression, development, and effects of growth factors and hormones.},
	number = {5},
	journal = {J. Neurosci. Res.},
	author = {Brewer, G J and Torricelli, J R and Evege, E K and Price, P J},
	month = aug,
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {567--576},
}

@article{brewer_regeneration_1999,
	title = {Regeneration and proliferation of embryonic and adult rat hippocampal neurons in culture},
	volume = {159},
	abstract = {Adult mammalian CNS neurons appear to be terminally differentiated and postmitotic. However, this conclusion may be due to nonpermissive conditions in the brain or in culture media. If embryonic rat hippocampal neurons are cultured in Neurobasal/B27 with FGF2, nearly all neurons proliferated until a maximum density was reached. Similarly, adult neurons can be cultured that fire action potentials and display immunoreactivity for neurofilament, MAP2, tau, and glutamate. Seventy percent of the 3000 isolated adult cells per milligram of brain tissue began to proliferate after 3 days in culture and incorporated BrdU. By 4 days of regeneration in culture, virtually all neuron-like cells with asymmetric processes were glutamate positive and immunoreactive for neurofilament. Immunoreactivity of the intermediate filament stem cell marker nestin increased in adult cells to levels present in freshly isolated embryonic neurons. These are the first studies to demonstrate that over 50\% of adult CNS cells with neuron-like characteristics retain regenerative and proliferative potential.},
	number = {1},
	journal = {Exp. Neurol.},
	author = {Brewer, G J},
	month = sep,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {237--247},
}

@article{brewer_serum-free_1995,
	title = {Serum-free {B27}/neurobasal medium supports differentiated growth of neurons from the striatum, substantia nigra, septum, cerebral cortex, cerebellum, and dentate gyrus},
	volume = {42},
	abstract = {Two fundamental questions about neuron cell culture were addressed. Can one serum-free medium that was developed for optimum growth of hippocampal neurons support the growth of neurons from other regions of the brain? Is the region specific state of differentiation maintained in culture? To answer these questions, we isolated neurons from six other rat brain regions, placed them in culture in B27/Neurobasal defined medium, and analyzed their morphology and growth dependence on cell density after 4 days in culture. Neuronal identity was confirmed by immunostaining with antibodies to neurofilament 200. Neurons from each brain region maintained distinctive morphologies in culture in the virtual absence of glia. Cells isolated from embryonic day 18 cerebral cortex by digestion with papain showed the same high survival as hippocampal neurons, e.g., 70\% survival for cells plated at 160/mm2. At this age and density, neurons from the septum showed slightly lower survival, 45\%. Survival of dentate granule neurons from postnatal day four brains was 30-40\%, significantly lower, and relatively independent of plating density. This suggests an absence of dependence on trophic factors or contact for dentate granule neurons. Growth of cerebellar granule neurons isolated from postnatal day 7, 8, or 9 brains in B27/Neurobasal was compared to growth in BME/10\% serum. Viability in serum-free medium at 4 days was much better than that in serum, did not require KCl elevated to 25 mM, and occurred without substantial growth of glia. Cerebellar granule neurons plated at 1,280 cells/mm2 were maintained in culture for three weeks with 17\% of the original cell density surviving. Survival of cells isolated from embryonic day 18 substantia nigra was 50\% at 160 cells/mm2 after 4 days, similar to that of striatum, but slightly less than hippocampal neuron survival. The dopaminergic phenotype of the substantia nigral neurons was maintained over 2 weeks in culture as judged by immunoreactivity with antibodies to tyrosine hydroxylase. During this time, immunoreactivity was found in the processes as they grew out from the soma. Together, these studies suggest that B27/Neurobasal will be a useful medium for maintaining the differentiated growth of neurons from many brain regions. Potential applications of a common growth medium for different neurons are discussed.},
	number = {5},
	journal = {J. Neurosci. Res.},
	author = {Brewer, G J},
	month = dec,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {674--683},
}

@article{evans_electrophysiology_1998,
	title = {Electrophysiology of embryonic, adult and aged rat hippocampal neurons in serum-free culture},
	volume = {79},
	abstract = {Methods were recently developed for culturing neurons from adult rat hippocampus using the serum-free medium Neurobasal with B27 supplement. To determine whether adult cultured neurons have normal electrical properties, we studied cultures from rats of three age groups: (1) embryonic; (2) 10-11 months old and (3) 35-36 months old. Neurons had a polarized morphology with a large branching apical dendrite and small basal dendrites. Mean resting potentials were similar in the three age groups. All neurons had nonlinear current-voltage relationships, indicating the presence of voltage-sensitive ion channels. Most neurons had a voltage-sensitive inward current followed by a sustained voltage-sensitive outward current. Tetrodotoxin blocked the inward current, which is likely to be a sodium current. The sustained outward current, which is likely to be a potassium current, reversed at -71 mV. Most neurons exhibited anomalous rectification. Calcium currents were present in both embryonic and adult neurons. Embryonic neurons would sometimes fire multiple action potentials but adult neurons fired only single action potentials. Our results indicate that both embryonic and adult cultured neurons retain a clearly neuronal electrophysiological phenotype in Neurobasal/B27 serum-free medium.},
	number = {1},
	journal = {J. Neurosci. Methods},
	author = {Evans, M Steven and Collings, Melissa A and Brewer, Gregory J},
	month = jan,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {37--46},
}

@article{owicki_light-addressable_1994,
	title = {The {Light}-{Addressable} {Potentiometric} {Sensor}: {Principles} and {Biological} {Applications}},
	volume = {23},
	abstract = {(No abstract.) Introduction: Semiconductor technology and biotechnology are two major technical disciplines that have large practical ramifications. This review describes the fruits of a research and development project that combines the two fields: the light-addressable potentiometric sensor (LAPS) and its bioanalytical applications.},
	journal = {Annu. Rev. Biophys. Biomol. Struct.},
	author = {Owicki, John C and Bousse, Luc J and Hafeman, Dean G and Kirk, Gregory L and Olson, John D and Wada, H Garrett and Parce, J Wallace},
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {87--113},
}

@article{nargeot_vitro_1999,
	title = {In vitro analog of operant conditioning in aplysia. {I}. {Contingent} reinforcement modifies the functional dynamics of an identified neuron},
	volume = {19},
	abstract = {Previously, an analog of operant conditioning in Aplysia was developed using the rhythmic motor activity in the isolated buccal ganglia. This analog expressed a key feature of operant conditioning, namely a selective enhancement in the occurrence of a designated motor pattern by contingent reinforcement. Different motor patterns generated by the buccal central pattern generator were induced by monotonic stimulation of a peripheral nerve (i.e., n.2,3). Phasic stimulation of the esophageal nerve (E n.) was used as an analog of reinforcement. The present study investigated the neuronal mechanisms associated with the genesis of different motor patterns and their modifications by contingent reinforcement. The genesis of different motor patterns was related to changes in the functional states of the pre-motor neuron B51. During rhythmic activity, B51 dynamically switched between inactive and active states. Bursting activity in B51 was associated with, and predicted, characteristic features of a specific motor pattern (i.e., pattern I). Contingent reinforcement of pattern I modified the dynamical properties of B51 by decreasing its resting conductance and threshold for eliciting plateau potentials and thus increased the occurrences of pattern I-related activity in B51. These modifications were not observed in preparations that received either noncontingent reinforcement (i.e., yoke control) or no reinforcement (i.e., control). These results suggest that a contingent reinforcement paradigm can regulate the dynamics of neuronal activity that is centrally programmed by the intrinsic cellular properties of neurons.},
	number = {6},
	journal = {J. Neurosci.},
	author = {Nargeot, R and Baxter, Da and Byrne, Jh},
	month = mar,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {2247--2260},
}

@article{nargeot_vitro_1999-1,
	title = {In vitro analog of operant conditioning in aplysia. {II}. {Modifications} of the functional dynamics of an identified neuron contribute to motor pattern selection},
	volume = {19},
	number = {6},
	journal = {J. Neurosci.},
	author = {Nargeot, R and Baxter, Da and Byrne, Jh},
	month = mar,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {2261--2272},
}

@article{schuett_pairing-induced_2001,
	title = {Pairing-induced changes of orientation maps in cat visual cortex},
	volume = {32},
	abstract = {We have studied the precise temporal requirements for plasticity of orientation preference maps in kitten visual cortex. Pairing a brief visual stimulus with electrical stimulation in the cortex, we found that the relative timing determines the direction of plasticity: a shift in orientation preference toward the paired orientation occurs if the cortex is activated first visually and then electrically; the cortical response to the paired orientation is diminished if the sequence of visual and electrical activation is reversed. We furthermore show that pinwheel centers are less affected by the pairing than the pinwheel surround. Thus, plasticity is not uniformly distributed across the cortex, and, most importantly, the same spike time-dependent learning rules that have been found in single-cell in vitro studies are also valid on the level of cortical maps.},
	number = {2},
	journal = {Neuron},
	author = {Schuett, S and Bonhoeffer, T and Hubener, M},
	month = oct,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {325--337},
}

@article{yao_stimulus_2001,
	title = {Stimulus timing-dependent plasticity in cortical processing of orientation},
	volume = {32},
	abstract = {The relative timing of presynaptic and postsynaptic spikes plays a critical role in activity-induced synaptic modification. Here we examined whether plasticity of orientation selectivity in the visual cortex depends on stimulus timing. Repetitive pairing of visual stimuli at two orientations induced a shift in orientation tuning of cat cortical neurons, with the direction of the shift depending on the temporal order of the pair. Induction of a significant shift required that the interval between the pair fall within +/-40 ms, reminiscent of the temporal window for spike timing-dependent synaptic plasticity. Mirroring the plasticity found in cat visual cortex, similar conditioning also induced a shift in perceived orientation by human subjects, further suggesting functional relevance of this phenomenon. Thus, relative timing of visual stimuli can play a critical role in dynamic modulation of adult cortical function, perhaps through spike timing-dependent synaptic plasticity.},
	number = {2},
	journal = {Neuron},
	author = {Yao, H and Dan, Y},
	month = oct,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {315--323},
}

@article{fu_temporal_2002,
	title = {Temporal specificity in the cortical plasticity of visual space representation},
	volume = {296},
	abstract = {The circuitry and function of mammalian visual cortex are shaped by patterns of visual stimuli, a plasticity likely mediated by synaptic modifications. In the adult cat, asynchronous visual stimuli in two adjacent retinal regions controlled the relative spike timing of two groups of cortical neurons with high precision. This asynchronous pairing induced rapid modifications of intracortical connections and shifts in receptive fields. These changes depended on the temporal order and interval between visual stimuli in a manner consistent with spike timing-dependent synaptic plasticity. Parallel to the cortical modifications found in the cat, such asynchronous visual stimuli also induced shifts in human spatial perception.},
	number = {5575},
	journal = {Science},
	author = {Fu, Yx and Djupsund, K and Gao, H and Hayden, B and Shen, K and Dan, Y},
	month = jun,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {1999--2003},
}

@article{carandini_tonic_1997,
	title = {A tonic hyperpolarization underlying contrast adaptation in cat visual cortex},
	volume = {276},
	abstract = {The firing rate responses of neurons in the primary visual cortex grow with stimulus contrast, the variation in the luminance of an image relative to the mean luminance. These responses, however, are reduced after a cell is exposed for prolonged periods to high-contrast visual stimuli. This phenomenon, known as contrast adaptation, occurs in the cortex and is not present at earlier stages of visual processing. To investigate the cellular mechanisms underlying cortical adaptation, intracellular recordings were performed in the visual cortex of cats, and the effects of prolonged visual stimulation were studied. Surprisingly, contrast adaptation barely affected the stimulus-driven modulations in the membrane potential of cortical cells. Moreover, it did not produce sizable changes in membrane resistance. The major effect of adaptation, evident both in the presence and in the absence of a visual stimulus, was a tonic hyperpolarization. Adaptation affects a class of synaptic inputs, most likely excitatory in nature, that exert a tonic influence on cortical cells.},
	number = {5314},
	journal = {Science},
	author = {Carandini, M and Ferster, D},
	month = may,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {949--952},
}

@article{stepnoski_noninvasive_1991,
	title = {Noninvasive detection of changes in membrane potential in cultured neurons by light scattering},
	volume = {88},
	abstract = {We report a procedure to detect electrical activity in cultured neurons by changes in their intrinsic optical properties. Using dark-field microscopy to detect scattered light, we observe an optical signal that is linearly proportional to the change in the membrane potential. Action potentials can be recorded without signal averaging. We use the dark-field method to show that there are substantial time delays between activity in the soma and in fine distal processes of identified Aplysia neurons. The biophysical basis for the change in optical properties of the neuron was deduced from measurements of the angular distribution of scattered laser light. An analysis of the data indicates that the radial component of the index of refraction of the membrane increases and the tangential components decrease concomitant with an increase in membrane potential. This is suggestive of a rapid reorientation of dipoles in the membrane during an action potential.},
	number = {21},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Stepnoski, R A and Laporta, A and Raccuia-behling, F and Blonder, G E and Slusher, R E and Kleinfeld, D},
	month = nov,
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {9382--9386},
}

@article{mccormick_model_1992,
	title = {A {Model} of the {Electrophysiological} {Properties} of {Thalamocortical} {Relay} {Neurons}},
	volume = {68},
	abstract = {1. A model of the electrophysiological properties of single thalamocortical relay neurons in the rodent and cat dorsal lateral geniculate nucleus was constructed, based in part on the voltage dependence and kinetics of ionic currents detailed with voltage-clamp techniques. The model made the simplifying assumption of a single uniform compartment and incorporated a fast and transient Na+ current, INa; a persistent, depolarization-activated Na+ current, INap; a low-threshold Ca2+ current, I(T); a high-threshold Ca2+ current, IL; a Ca(2+)-activated K+ current, IC; a transient and depolarization-activated K+ current, IA; a slowly inactivating and depolarization-activated K+ current, IK2; a hyperpolarization-activated cation current, Ih; and K+ and Na+ leak currents IKleak and INaleak. 2. The effects of the various ionic currents on the electrophysiological properties of thalamocortical relay neurons were initially investigated through examining the effect of each current individually on passive membrane responses. The two leak currents, IKleak and INaleak, determined in large part the resting membrane potential and the apparent input resistance of the model neuron. Addition of IA resulted in a delay in the response of the model cell to a depolarizing current pulse, whereas addition of IK2, or IL combined with IC, resulted in a marked and prolonged decrease in the response to depolarization. Addition of Ih resulted in a depolarizing “sag” in response to hyperpolarization, whereas addition of IT resulted in a large rebound Ca2+ spike after hyperpolarization. Finally, addition of INap resulted in enhancement of depolarization. 3. The low-threshold Ca2+ spike of rodent neurons was successfully modeled with the active currents I(T), IL, IA, IC, and IK2. The low-threshold Ca2+ current I(T) generated the low-threshold Ca2+ spike. The transient K+ current IA slowed the rate of rise and reduced the peak amplitude of the low-threshold Ca2+ spike, whereas the slowly inactivating K+ current IK2 contributed greatly to the repolarization of the Ca2+ spike. Activation of IL during the peak of the Ca2+ spike led to activation of IC, which also contributed to the repolarization of the Ca2+ spike. Reduction of any one of the K+ currents resulted in an increase in the other two, thereby resulting in substantially smaller changes in the Ca2+ spike than would be expected on the basis of the amplitude of each ionic current alone.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Mccormick, David A and Huguenard, John R},
	month = oct,
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {1384--1400},
}

@article{konishi_role_1965,
	title = {The role of auditory feedback in the control of vocalization in the white-crowned sparrow},
	volume = {22},
	number = {7},
	journal = {Z. Tierpsychol.},
	author = {Konishi, M},
	month = dec,
	year = {1965},
	keywords = {merged\_fiete.bib},
	pages = {770--783},
}

@article{doupe_birdsong_1999,
	title = {Birdsong and human speech: common themes and mechanisms},
	volume = {22},
	abstract = {Human speech and birdsong have numerous parallels. Both humans and songbirds learn their complex vocalizations early in life, exhibiting a strong dependence on hearing the adults they will imitate, as well as themselves as they practice, and a waning of this dependence as they mature. Innate predispositions for perceiving and learning the correct sounds exist in both groups, although more evidence of innate descriptions of species-specific signals exists in songbirds, where numerous species of vocal learners have been compared. Humans also share with songbirds an early phase of learning that is primarily perceptual, which then serves to guide later vocal production. Both humans and songbirds have evolved a complex hierarchy of specialized forebrain areas in which motor and auditory centers interact closely, and which control the lower vocal motor areas also found in nonlearners. In both these vocal learners, however, how auditory feedback of self is processed in these brain areas is surprisingly unclear. Finally, humans and songbirds have similar critical periods for vocal learning, with a much greater ability to learn early in life. In both groups, the capacity for late vocal learning may be decreased by the act of learning itself, as well as by biological factors such as the hormones of puberty. Although some features of birdsong and speech are clearly not analogous, such as the capacity of language for meaning, abstraction, and flexible associations, there are striking similarities in how sensory experience is internalized and used to shape vocal outputs, and how learning is enhanced during a critical period of development. Similar neural mechanisms may therefore be involved.},
	journal = {Annu. Rev. Neurosci.},
	author = {Doupe, A J and Kuhl, P K},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {567--631},
}

@article{nottebohm_connections_1982,
	title = {Connections of vocal control nuclei in the canary telencephalon},
	volume = {207},
	abstract = {Connections of two telencephalic vocal control nuclei, the hyperstriatum ventrale, pars caudale (HVc), and robust nucleus of the archistriatum (RA), were investigated in adult canaries. Methods used were transport of horseradish peroxidase and 3H-adenosine and silver staining of degenerating axons. Three nuclei project to HVc: medial nucleus magnocellularis of the anterior neostriatum (MAN), nucleus interfacialis (NIf) of midneostriatum, and nucleus uvaeformis (Uva) of the diecephalon. Uva also projects to NIf. NIf and Uva have not been described previously. HVc projects to area X of lobus parolfactorius, to RA, and to field Avalanche of hyperstriatum ventrale. Nucleus RA receives projections from HVc and from lateral MAN. All these projections are ipsilateral. No gross male/female differences were apparent in the projections to and from HVc. Uptake of HRP by cell somata in HVc following localized injections of this substance into RA or HVc suggests that HVc is composed of rostrocaudally organized clusters of cells, with little lateral communication between them.},
	number = {4},
	journal = {J. Comp. Neurol.},
	author = {Nottebohm, F and Kelley, D B and Paton, J A},
	month = jun,
	year = {1982},
	keywords = {merged\_fiete.bib},
	pages = {344--357},
}

@article{sigworth_design_1995,
	title = {Design of the {EPC}-9, a computer-controlled patch-clamp amplifier: 1) {Hardware}},
	volume = {56},
	abstract = {The EPC-9 patch-clamp amplifier is a digitally controlled analog device for recording currents in membrane patches and in small cells. It has neither front-panel controls nor internal trim adjustments; instead all gain, range-changing, transient cancellation, calibration and other functions are computer controlled. Novel aspects of the circuit design of this instrument are discussed, with special reference to the issues of allowing computer control of all functions.},
	number = {2},
	journal = {J. Neurosci. Methods},
	author = {Sigworth, F J},
	month = feb,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {195--202},
}

@article{sigworth_design_1995-1,
	title = {Design of the {EPC}-9, a computer-controlled patch-clamp amplifier: 2) {Software}},
	volume = {56},
	abstract = {The EPC-9 computer-controlled amplifier has no front-panel controls; therefore the user interface to the EPC-9 patch-clamp amplifier is defined entirely by software. This paper describes various user interfaces that have been implemented, including a high-level programming interface, a user interface based on the PostScript language, and graphical user interfaces that control the EPC-9 from data-acquisition programs. Also described are the algorithms used for automatic adjustment of the C-Fast and C-Slow transient cancellation circuitry. An overview of the procedures that perform automatic testing and calibration is given.},
	number = {2},
	journal = {J. Neurosci. Methods},
	author = {Sigworth, F J and Affolter, H and Neher, E},
	month = feb,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {203--215},
}

@article{bekkers_excitatory_1991,
	title = {Excitatory and inhibitory autaptic currents in isolated hippocampal neurons maintained in cell culture},
	volume = {88},
	abstract = {Individual rat hippocampal neurons, grown in isolation from other neurons on small spots of permissive substrate, were studied in order to characterize the electrical properties of the synapses that such cells formed with themselves (autapses). Excitatory (probably glutamatergic) or inhibitory (probably type A gamma-aminobutyratergic) autapses were frequently found. Excitatory autaptic currents reversed near the potential expected for monovalent cations were blocked by the glutamatergic antagonist kynurenic acid, and possessed a slow component with the pharmacological profile of N-methyl-D-aspartate-type channels. These currents also exhibited trial-to-trial statistical fluctuations in their amplitudes, this being well-described by quantal analysis. Inhibitory autaptic currents reversed at hyperpolarized potentials, as expected for chloride-permeable pores and were blocked by picrotoxin, a type A gamma-aminobutyric receptor antagonist. It is concluded that autaptic currents in culture are identical to those found at synapses.},
	number = {17},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Bekkers, J M and Stevens, C F},
	month = sep,
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {7834--7838},
}

@article{bousse_investigation_1994,
	title = {Investigation of carrier transport through silicon wafers by photocurrent measurements},
	volume = {75},
	abstract = {Measurement of the ac photocurrent in metal/insulator/semiconductor capacitators can be used as a tool to measure minority-carrier diffusion and lifetime. The amplitude of the ac photocurrent generated at a silicon surface biased into inversion depends on the number of excess minority carriers present at that surface. By comparing this amplitude when intensity-modulated light is directed to each side of the same device, minority-carrier diffusion from the back to the front of the device can be characterized. An analytical model of this transport process predicts the dependence of the ac photocurrent on frequency and wafer thickness, and allows the determination of a value of the bulk lifetime free of the influence of surface recombination. Measurements under low-light intensity levels are presented on n-type silicon wafers with lifetimes in the 10-100 us range. Lifetimes are found about a factor of 2 lower than those measured with noncontact photoconductive decay, at high-light intensity levels. This is expected due to the difference between high- and low-level minority-carrier injection. Fitting the data to the model also yields a value of 115 um for the average depth at which carriers are generated and diffuse to the front with backside illumination at 940 nm.},
	number = {8},
	journal = {J. Appl. Phys.},
	author = {Bousse, Luc and Mostarshed, Shahriar and Hafeman, Dean and Sartore, Marco and Adami, Manuela and Nicolini, Claudio},
	month = apr,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {4000--4008},
}

@unpublished{potter_distributed_2001,
	title = {Distributed processing in cultured neuronal networks},
	abstract = {(No abstract.) Introduction. Thanks to a number of recent technical advances, it will become increasingly popular to study the very basics of distributed information processing using cultured neuronal networks. Most researchers studying population coding are working with intact, living animals. Clearly, cultured neuronal networks lack many features of real brains, but they retain many others. They develop organotypic synaptic connections and exhibit a rich variety of distributed patterns of electrical activity. Progress in multi-electrode array technology, optical recording, and multi-photon microscopy, has made it possible that every cell in a cultured monolayer network can be observed, monitored, stimulated, and manipulated with temporal resolution in the submillisecond range, in a non-destructive manner. At present, such detailed and complete analysis of neural circuits is not feasible in living animals, or even brain slices. It is an open question, however, whether any of the 'processing' done by cultured neurons is relevant to that carried out by intact brains. This chapter serves to present efforts from a number of groups that lay the groundwork for an in vitro approach to studying population coding. I will suggest what it might take to advance the state of the art to the point where we can consider studying learning, memory, and distributed information processign in vitro.},
	author = {Potter, Steve M},
	year = {2001},
	keywords = {merged\_fiete.bib},
}

@article{potter_new_2001,
	title = {A new approach to neural cell culture for long-term studies},
	volume = {110},
	abstract = {We have developed a new method for culturing cells that maintains their health and sterility for many months. Using conventional techniques, primary neuron cultures seldom survive more than 2 months. Increases in the osmotic strength of media due to evaporation are a large and underappreciated contributor to the gradual decline in the health of these cultures. Because of this and the ever-present likelihood of contamination by airborne pathogens, repeated or extended experiments on any given culture have until now been difficult, if not impossible. We surmounted survival problems by using culture dish lids that form a gas-tight seal, and incorporate a transparent hydrophobic membrane (fluorinated ethylene-propylene) that is selectively permeable to oxygen (O(2)) and carbon dioxide (CO(2)), and relatively impermeable to water vapor. This prevents contamination and greatly reduces evaporation, allowing the use of a non-humidified incubator. We have employed this technique to grow dissociated cortical cultures from rat embryos on multi-electrode arrays. After more than a year in culture, the neurons still exhibit robust spontaneous electrical activity. The combination of sealed culture dishes with extracellular multi-electrode recording and stimulation enables study of development, adaptation, and very long-term plasticity, across months, in cultured neuronal networks. Membrane-sealed dishes will also be useful for the culture of many other cell types susceptible to evaporation and contamination.},
	number = {1-2},
	journal = {J. Neurosci. Methods},
	author = {Potter, Steve M and Demarse, Thomas B},
	month = sep,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {17--24},
}

@article{gallese_action_1996,
	title = {Action recognition in the premotor cortex},
	volume = {119},
	abstract = {We recorded electrical activity from 532 neurons in the rostral part of inferior area 6 (area F5) of two macaque monkeys. Previous data had shown that neurons of this area discharge during goal-directed hand and mouth movements. We describe here the properties of a newly discovered set of F5 neurons (“mirror neurons', n = 92) all of which became active both when the monkey performed a given action and when it observed a similar action performed by the experimenter. Mirror neurons, in order to be visually triggered, required an interaction between the agent of the action and the object of it. The sight of the agent alone or of the object alone (three-dimensional objects, food) were ineffective. Hand and the mouth were by far the most effective agents. The actions most represented among those activating mirror neurons were grasping, manipulating and placing. In most mirror neurons (92\%) there was a clear relation between the visual action they responded to and the motor response they coded. In approximately 30\% of mirror neurons the congruence was very strict and the effective observed and executed actions corresponded both in terms of general action (e.g. grasping) and in terms of the way in which that action was executed (e.g. precision grip). We conclude by proposing that mirror neurons form a system for matching observation and execution of motor actions. We discuss the possible role of this system in action recognition and, given the proposed homology between F5 and human Brocca's region, we posit that a matching system, similar to that of mirror neurons exists in humans and could be involved in recognition of actions as well as phonetic gestures.},
	number = {Pt 2},
	journal = {Brain},
	author = {Gallese, V and Fadiga, L and Fogassi, L and Rizzolatti, G},
	month = apr,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {593--609},
}

@article{fadiga_visuomotor_2000,
	title = {Visuomotor neurons: ambiguity of the discharge or 'motor' perception},
	volume = {35},
	abstract = {The cortical motor system has been classically considered as the unitary, output stage of the brain processing of sensory information. According to this idea, the motor cortex - the acting brain - receives the result of the perceptual processing (visual, acoustical, tactile, etc.) elaborated by the 'associative cortex'. During the last two decades this perspective has been challenged by a series of anatomical, hodological, and neurophysiological data. This converging evidence delineates a dramatically changed picture. Far from being unitary, the cortical motor system appears to be constituted by a constellation of distinct areas, each of those endowed with specific functional properties and linked by reciprocal connections with distinct sectors of the parietal cortex. Furthermore, several 'motor' neurons in addition to their motor discharge, are also activated by somatosensory and visual stimulation (somatomotor and visuomotor neurons). In the present paper we will discuss the functional properties of those sensorimotor neurons located in the ventral part of the monkey premotor cortex. On the basis of electrophysiological data, we will propose that the apparent parodox stemming from the coexistence within the same neuron of motor and sensory properties can be solved by postulating that the motor system not only executes actions but also internally represents them in terms of 'motor ideas'. These motor ideas may provide the neurobiological basis for space representation, understanding of actions made by others and, possibly, semantic categorization of objects.},
	number = {2-3},
	journal = {Int. J. Psychophysiol.},
	author = {Fadiga, L and Fogassi, L and Gallese, V and Rizzolatti, G},
	month = mar,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {165--177},
}

@article{yousef_orientation_1999,
	title = {Orientation topography of layer 4 lateral networks revealed by optical imaging in cat visual cortex (area 18)},
	volume = {11},
	abstract = {The functional specificity of corticocortical connections with respect to the topography of orientation selectivity was studied by optical imaging of intrinsic signals and bulk injections of fluorescent latex beads (green and red) and biocytin into layer 4. The distributions of retrogradely labelled cells and anterogradely labelled axon terminals were histologically reconstructed from all cortical laminae, and the resulting anatomical maps compared with the optically imaged functional maps. Layer 4 injections produced extensive horizontal labelling up to 2-3 mm from the injection centres albeit without the clear patchy pattern described after layer 2/3 injections (Gilbert \& Wiesel 1989, J. Neurosci., 9, 2432-2442; Kisvarday et al. 1997, Cerebral Cortex, 7, 605-618). The functional (orientation) distribution of the labelled projections was analysed according to laminar location and lateral spread. With regard to the former, no major difference in the orientation topography between supragranular- (upper tier), granular- (middle tier) and infragranular (lower tier) layers was seen. Laterally, proximal and distal projections were distinguished and further dissected into three orientation categories, iso- (+/- 30 degrees ), oblique- (+/- 30-60 degrees ) and cross-orientations (+/- 60-90 degrees ) with respect to the orientation preference at the injection sites. The majority of distal connections (retrograde and anterograde) was equally distributed across orientations (35.4\% iso-, 33.7\% oblique-, and 30.9\% cross-orientations) that are equivalent with a preponderance to dissimilar orientations (oblique- and cross-orientations, 64.6\%). In one case, distal excitatory and inhibitory connections could be morphologically distinguished. For both categories, a marked bias to dissimilar orientations was found (excitatory, 63.7\%; inhibitory, 86.6\%). Taken together, these results suggest that the long-range layer 4 circuitry has a different functional role from that of the iso-orientation biased (52.9\%, Kisvarday et al. 1997, Cerebral Cortex, 7, 605-618) layer 2/3 circuitry, and is perhaps involved in feature difference-based mechanisms, e.g. figure ground segregation.},
	number = {12},
	journal = {Eur. J. Neurosci.},
	author = {Yousef, T and Bonhoeffer, T and Kim, Ds and Eysel, Ut and Toth, E and Kisvarday, Zf},
	month = dec,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {4291--4308},
}

@article{rao_optically_1997,
	title = {Optically imaged maps of orientation preference in primary visual cortex of cats and ferrets},
	volume = {387},
	abstract = {Feature maps in the cerebral cortex constitute orderly representations of response features created within the cortex; an example is the mapping of orientation-selective neurons in visual cortex. We have compared the properties of orientation maps in area 17 of cats and ferrets, obtained by optical imaging of intrinsic signals. Orientation maps in both species contain a quasi-periodic distribution of iso-orientation domains that are organized into a lattice of pinwheels. However, the spatial density of orientation domains and of pinwheels in ferret area 17 is nearly twice that in cat area 17. The ferret map also contains more discontinuities, or fractures, where orientation changes abruptly. The size of orientation domains scales with interdomain spacing, so that the ratio of the two is approximately the same in both species. Consistent with this finding, the orientation tuning width of individual pixels is similar in the two. The magnitude of orientation preference, however, is much lower in ferret compared to cat. The greater incidence of fractures in ferret appears to be due to proportionately greater overlap between domains of different orientations, particularly along fracture lines that link pinwheel centers. We hypothesize that a key determinant of orientation maps, the relationship between orientation domain size and spacing, expresses an anatomical link between sizes of thalamocortical arbors and horizontal intracortical connections in area 17.},
	number = {3},
	journal = {J. Comp. Neurol.},
	author = {Rao, Sc and Toth, Lj and Sur, M},
	month = oct,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {358--370},
}

@article{bosking_orientation_1997,
	title = {Orientation selectivity and the arrangement of horizontal connections in tree shrew striate cortex},
	volume = {17},
	abstract = {Horizontal connections, formed primarily by the axon collaterals of pyramidal neurons in layer 2/3 of visual cortex, extend for millimeters parallel to the cortical surface and form patchy terminations. Previous studies have provided evidence that the patches formed by horizontal connections exhibit modular specificity, preferentially linking columns of neurons with similar response characteristics, such as preferred orientation. The issue of how these connections are distributed with respect to the topographic map of visual space, however, has not been resolved. Here we combine optical imaging of intrinsic signals with small extracellular injections of biocytin to assess quantitatively the specificity of horizontal connections with respect to both the map of orientation preference and the map of visual space in tree shrew V1. Our results indicate that horizontal connections outside a radius of 500 microm from the injection site exhibit not only modular specificity, but also specificity for axis of projection. Labeled axons extend for longer distances, and give off more terminal boutons, along an axis in the map of visual space that corresponds to the preferred orientation of the injection site. Inside of 500 microm, the pattern of connections is much less specific, with boutons found along every axis, contacting sites with a wide range of preferred orientations. The system of long-range horizontal connections can be summarized as preferentially linking neurons with co-oriented, co-axially aligned receptive fields. These observations suggest specific ways that horizontal circuits contribute to the response properties of layer 2/3 neurons and to mechanisms of visual perception.},
	number = {6},
	journal = {J. Neurosci.},
	author = {Bosking, Wh and Zhang, Y and Schofield, B and Fitzpatrick, D},
	month = mar,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {2112--2127},
}

@article{budd_local_2001,
	title = {Local lateral connectivity of inhibitory clutch cells in layer 4 of cat visual cortex (area 17)},
	volume = {140},
	abstract = {To characterise spatially a major component of the anatomical basis of local lateral inhibition in layer 4 of cat visual cortex (area 17), we analysed the lateral distribution of neuronal somata postsynaptic to electrophysiologically characterised GABAergic clutch (basket) cell axons (CC1 and CC2). We report two main results. First, the clutch cell axons appear to show isotropic lateral connectivity near their cell body (less than 50 microm radius), but beyond this core region they show anisotropic lateral connectivity, preferring particular angular sectors around their cell body. Second, we estimated the probability of lateral connection for each axon arbor as a function of radial distance from the parent soma. We found that this radial function has a brief rising phase, to a peak at 30-45 microm, and a longer, exponential decaying phase, with a space constant of around 50 microm. The shape of the radial connection probability function suggests that most lateral inhibitory connections of clutch cells are formed with neurons in nearest-neighbour cortical columns. Taken together, the results suggest that these individual layer-4 clutch cell axons may inhibit all (isotropic) nearest-neighbour cortical columns with a relatively high probability of connection, but outside this core region may provide a type of anisotropic lateral inhibition of cortical columns with a radially decreasing probability of connection.},
	number = {2},
	journal = {Exp. Brain Res.},
	author = {Budd, Jm and Kisvarday, Zf},
	month = sep,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {245--250},
}

@article{buzas_axonal_2001,
	title = {Axonal topography of cortical basket cells in relation to orientation, direction, and ocular dominance maps},
	volume = {437},
	abstract = {The axonal (bouton) distributions of a layer 4 clutch cell (CC), two layer 3 medium-sized basket cells (MBC), and a layer 3 large basket cell (LBC) to orientation, direction, and ocular dominance maps were studied quantitatively. 1) The CC provided exclusively local projections (313 microm and {\textgreater}418 microm), which encountered cross-orientation sites (14\% and 12\%) and isoorientation sites (7\% and 5\%). Their direction preferences were mainly perpendicular to or opposite those of local projections. 3) The LBC provided the majority (60\%) of its boutons to long-range distances ({\textgreater}437 microm). Locally, LBC boutons showed a rather balanced contribution to isoorientations (19\%) and cross-orientations (12\%) and preferred isodirections. Remotely, however, cross-orientation sites were preferred (31\% vs. 23\%) and the directional output was balanced. 4) Monte Carlo simulations revealed that the differences between the orientation specificity of local and long-range projections cannot be explained by a homogeneous lateral distribution of the boutons. 5) There was a similar eye preference in the local and long-range projection fields of the MBCs. The LBC contacted both contra- and ipsilateral eye domains. 6) The basket axons showed little laminar difference in orientation and direction topography. The results suggest that an individual basket cell can mediate a wide range of effects depending on the size and termination pattern of the axonal field. Copyright 2001 Wiley-Liss, Inc.},
	number = {3},
	journal = {J. Comp. Neurol.},
	author = {Buzas, P and Eysel, Ut and Adorjan, P and Kisvarday, Zf},
	month = aug,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {259--285},
}

@article{kisvarday_combined_2000,
	title = {Combined physiological-anatomical approaches to study lateral inhibition},
	volume = {103},
	abstract = {In the visual cortex, large basket cells form the cellular basis of long-range lateral inhibition. The present paper focuses on combinations of methods with which large basket cells can be studied in the context of extensive neuronal representations. In the first approach, the topographic relationship between large basket axons and known functional representations such as orientation, direction, and ocular dominance is analysed. Functional mapping is carried out using extracellular electrode recordings or optical imaging of intrinsic signals followed by 3-dimensional anatomical reconstruction of biocytin stained large basket cells in the same regions. In the second approach, the contribution of lateral inhibition to orientation and direction selectivity is assessed using the GABA inactivation paradigm and direct inhibitory projections from the inactivation to recording sites are demonstrated with biocytin staining and injections of [3H]nipecotic acid, a radioactive marker for GABAergic cells. The limitation of these approaches is that they can only be used in cortical regions which lie on the surface of the brain.},
	number = {1},
	journal = {J. Neurosci. Methods},
	author = {Kisvarday, Zf and Crook, Jm and Buzas, P and Eysel, Ut},
	month = nov,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {91--106},
}

@article{white_contribution_2001,
	title = {The contribution of sensory experience to the maturation of orientation selectivity in ferret visual cortex},
	volume = {411},
	abstract = {Sensory experience begins when neural circuits in the cerebral cortex are still immature; however, the contribution of experience to cortical maturation remains unclear. In the visual cortex, the selectivity of neurons for oriented stimuli at the time of eye opening is poor and increases dramatically after the onset of visual experience. Here we investigate whether visual experience has a significant role in the maturation of orientation selectivity and underlying cortical circuits using two forms of deprivation: dark rearing, which completely eliminates experience, and binocular lid suture, which alters the pattern of sensory driven activity. Orientation maps were present in dark-reared ferrets, but fully mature levels of tuning were never attained. In contrast, only rudimentary levels of orientation selectivity were observed in lid-sutured ferrets. Despite these differences, horizontal connections in both groups were less extensive and less clustered than normal, suggesting that long-range cortical processing is not essential for the expression of orientation selectivity, but may be needed for the full maturation of tuning. Thus, experience is beneficial or highly detrimental to cortical maturation, depending on the pattern of sensory driven activity.},
	number = {6841},
	journal = {Nature},
	author = {White, Le and Coppola, Dm and Fitzpatrick, D},
	month = jun,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {1049--1052},
}

@article{fitzpatrick_seeing_2000,
	title = {Seeing beyond the receptive field in primary visual cortex},
	volume = {10},
	abstract = {Recent studies on the response properties of neurons in primary visual cortex emphasize the dynamics and the complexities of facilitatory and suppressive interactions between the receptive field center and surrounding areas of visual space. These observations raise new questions about the circuitry responsible for receptive field surround effects and their contribution to visual perception.},
	number = {4},
	journal = {Curr. Opin. Neurobiol.},
	author = {Fitzpatrick, D},
	month = aug,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {438--443},
}

@article{godde_plasticity_2002,
	title = {Plasticity of orientation preference maps in the visual cortex of adult cats},
	volume = {99},
	abstract = {In contrast to the high degree of experience-dependent plasticity usually exhibited by cortical representational maps, a number of experiments performed in visual cortex suggest that the basic layout of orientation preference maps is only barely susceptible to activity-dependent modifications. In fact, most of what we know about activity-dependent plasticity in adults comes from experiments in somatosensory, auditory, or motor cortex. Applying a stimulation protocol that has been proven highly effective in other cortical areas, we demonstrate here that enforced synchronous cortical activity induces major changes of orientation preference maps (OPMs) in adult cats. Combining optical imaging of intrinsic signals and electrophysiological single-cell recordings, we show that a few hours of intracortical microstimulation (ICMS) lead to an enlargement of the cortical representational zone at the ICMS site and an extensive restructuring of the entire OPM layout up to several millimeters away, paralleled by dramatic changes of pinwheel numbers and locations. At the single-cell level, we found that the preferred orientation was shifted toward the orientation of the ICMS site over a region of up to 4 mm. Our results show that manipulating the synchronicity of cortical activity locally without invoking training, attention, or reinforcement, OPMs undergo large-scale reorganization reminiscent of plastic changes observed for nonvisual cortical maps. However, changes were much more widespread and enduring. Such large-scale restructuring of the visual cortical networks indicates a substantial capability for activity-dependent plasticity of adult visual cortex and may provide the basis for cognitive learning processes.},
	number = {9},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Godde, B and Leonhardt, R and Cords, Sm and Dinse, Hr},
	month = apr,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {6352--6357},
}

@article{sengpiel_orientation_2002,
	title = {Orientation specificity of contrast adaptation in visual cortical pinwheel centres and iso-orientation domains},
	volume = {15},
	abstract = {Exposure to a high-contrast visual stimulus causes adaptation, a psychophysical phenomenon that is quite selective for stimulus orientation. Its mechanism is largely cortical but the underlying circuitry is still not unambiguously resolved. It has been suggested that adaptation could be the result of integration of inputs from cells within a large local pool, effectively scaling their outputs with respect to local contrast. In this case, orientation selectivity of neuronal adaptation should depend on the location of neurons within the cortical map of orientation preference. We tested this hypothesis by quantifying adaptation to optimally oriented and to orthogonal-to-optimum gratings among neurons recorded either from iso-orientation domains or orientation pinwheel centres, as identified by optical imaging of cat visual cortex. We did not find a significant difference in adaptation characteristics for these two populations of cells, implying that these characteristics do not depend on the local functional architecture. Surprisingly, however, we additionally observed that under isoflurane (but not halothane) anaesthesia, most neurons exhibited adaptation by cross-oriented gratings, regardless of their location within the orientation map. It seems likely that, under isoflurane, inputs became visible that were masked by the commonly used, deeper halothane anaesthesia. For individual cells, the presence of these inputs was independent of their location within the cortical orientation map.},
	number = {5},
	journal = {Eur. J. Neurosci.},
	author = {Sengpiel, F and Bonhoeffer, T},
	month = mar,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {876--886},
}

@article{maldonado_orientation_1997,
	title = {Orientation selectivity in pinwheel centers in cat striate cortex},
	volume = {276},
	abstract = {In primary visual cortex of higher mammals neurons are grouped according to their orientation preference, forming “pinwheels” around “orientation centers.” Although the general structure of orientation maps is largely resolved, the microscopic arrangement of neuronal response properties in the orientation centers has remained elusive. The tetrode technique, enabling multiple single-unit recordings, in combination with intrinsic signal imaging was used to reveal the fine-grain structure of orientation maps in these locations. The results show that orientation centers represent locations where orientation columns converge containing normal, sharply tuned neurons of different orientation preference lying in close proximity.},
	number = {5318},
	journal = {Science},
	author = {Maldonado, Pe and Godecke, I and Gray, Cm and Bonhoeffer, T},
	month = jun,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {1551--1555},
}

@article{luebke_gain_1994,
	title = {Gain changes of the cat's vestibulo-ocular reflex after flocculus deactivation},
	volume = {98},
	abstract = {Motor learning can be demonstrated in the vestibulo-ocular reflex (VOR) by changing its gain (eye velocity/head velocity) with goggles and optokinetic (OK) drums. It is known that the flocculus is essential for this plasticity but there is controversy about whether the modifiable synapses mainly responsible are in the flocculus. To investigate this further we utilized the known reciprocal relationship between complex spikes and simple spikes in Purkinje cell discharges. By stimulating climbing fibers from the olive to the flocculus at 7 Hz, the simple spike rate of almost all recorded floccular cells could be driven to zero. This was termed floccular shutdown and it felt to effect a functional, reversible flocculectomy. Sixty single units in the flocculi of four cats were recorded. Stimulation of the climbing fibers at 7 Hz caused the discharge rate to decrease to zero in 95\% of these cells. The gain of the horizontal VOR in three cats was driven repeatedly to twice or half its normal value by rotation within a moving OK drum and also by wearing magnifying or fixed-field goggles; this process required 3 days. If, on the 4th day, the cat was exposed to an OK drum rotating in the opposite direction, the gain was driven back to normal in 30 min. If, however, the climbing fibers were stimulated at 7 Hz during these 30 min, the gain did not return–learning was blocked. This verified that loss of floccular activity by this method abolishes VOR gain plasticity. Moreover, when 7 Hz stimulation first began, after 3 days of adaptation, the adapted gain remained at its adapted value, either half or twice normal, even in the face of floccular shutdown. This result appears incompatible with the hypothesis that the modifiable synapses are in the flocculus.},
	number = {3},
	journal = {Exp. Brain Res.},
	author = {Luebke, A E and Robinson, D A},
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {379--390},
}

@article{robinson_adaptive_1976,
	title = {Adaptive gain control of vestibuloocular reflex by the cerebellum},
	volume = {39},
	abstract = {1. The gain of the vestibuloocular reflex (slow-phase eye velocity/head velocity) was measured in 17 adult cats. 2. The gain of the reflex, in the dark, was 0.90 (+/-0.15 SD) over the frequency range 0.03-1.2 Hz. 3. In the range 0.01-0.15 Hz, the phase behaved as though the overall reflex time constant were 12 s or greater. The cupula time constant is 4 s. Therefore, the central part of the reflex must manipulate the canal signal to improve its low-frequency response by a factor of at least three. 4. When the cats wore left-right reversing prisms chronically and were also rotated for 2 h every day, the reflex underwent large, plastic changes. The gain, tested in the dark, decreased by 93\% at 0.05 Hz and 55\% at 1.2 Hz. In effect, the low-frequency response was abolished. The process took about 8 days. 5. In the light, with reversed vision, the gain decreased further and, at low frequencies, the eye movements did reverse in direction. 6. When the vestibulocerebellum was removed, the gain, in the dark, rose to about 1.17 and the plastic changes caused by reversing prisms were completely abolished. 7. Reversing prisms create vestibuloocular dysmetria. The change in gain they produce is considered to be an adaptive response designed to reduce image motion on the retina during head movements. The vestibulocerebellum is necessary for this adaptive process. It is proposed that detecting and repairing dysmetria (of natural origin) is an important cerebellar function.},
	number = {5},
	journal = {J. Neurophysiol.},
	author = {Robinson, D A},
	month = sep,
	year = {1976},
	keywords = {merged\_fiete.bib},
	pages = {954--969},
}

@article{lund_local_1997,
	title = {Local circuit neurons of macaque monkey striate cortex: {IV}. {Neurons} of laminae 1-{3A}},
	volume = {384},
	abstract = {We continue our Golgi studies (Lund [1987] J. Comp. Neurol. 257:60-92; Lund et al. [1988] J. Comp. Neurol. 276:1-29; Lund and Yoshioka [1991] J. Comp. Neurol. 331:234-258) of the organization of local circuit, largely gamma-aminobutyric acid (GABA)-containing neurons in macaque monkey visual cortex, area V1, with this account of the local circuit neurons lying in layers 1 and 2/3A. These layers receive intrinsic interlaminar excitatory and inhibitory relays from layers 3B, 4A, 4B, and 5. We describe seven varieties of local circuit neurons with somata within layers 1-2/3A, and we compare the lateral scale of spread of the axons and dendrites of these neurons with the size of the columnar connectional patch domains made by the laterally spreading axon collaterals of pyramidal neurons within the superficial layers (Lund et al. [1993] Cerebral Cortex 3:148-162). We conclude from this comparison that all of the neurons have dendritic fields that are limited to single patch domains. Furthermore, only two of the seven local circuit neuron varieties have sufficient axon spread to influence territory beyond single domains, reaching into neighboring territory likely to differ in function from that occupied by their dendrites. We have identified descending projections from particular varieties to layers 3B, 4A, 4B, and 5 and to the white matter. We discuss the contributions that these interneurons may make to function within the superficial cortical layers, and we summarize our overall conclusions, so far, from our set of studies on interneurons within area V1 of the macaque.},
	number = {1},
	journal = {J. Comp. Neurol.},
	author = {Lund, Js and Wu, Cq},
	month = jul,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {109--126},
}

@article{stark_two-stage_1999,
	title = {Two-stage, input-specific synaptic maturation in a nucleus essential for vocal production in the zebra finch},
	volume = {19},
	abstract = {In most songbirds, vocal learning occurs through two experience-dependent phases, culminating in a reduction of behavioral plasticity called song crystallization. At ends of developmentally plastic periods in other systems, synaptic properties change in a fashion appropriate to limit plasticity. Maturation of glutamatergic synapses often involves a reduction in duration of NMDA receptor (NMDAR)-mediated synaptic responses and a coincident reduction in the contribution of NMDARs to synaptic transmission. We hypothesized that similar changes in the zebra finch song system help limit behavioral plasticity during song development. Nucleus robustus archistriatalis (RA) is a key nucleus in the forebrain song motor pathway and receives glutamatergic input from the motor nucleus HVc. RA also receives glutamatergic input, mediated primarily by NMDARs, from the lateral magnocellular nucleus of the anterior neostriatum, which is part of a circuit essential for learning but not song production. We examined whether synaptic maturation occurs in either input to RA by recording synaptic currents in brain slices prepared from zebra finches of different ages. We find the motor input from HVc to RA uses both AMPA receptors (AMPARs) and NMDARs, and synaptic maturation occurs in two phases: an early reduction in duration of NMDAR-mediated synaptic currents in both inputs, and a later reduction in the NMDAR contribution to synaptic responses in the motor pathway. Although NMDAR kinetics change too early to account for crystallization, the reduction of the relative NMDAR contribution to synaptic transmission could contribute to the onset of crystallization. Thus, synaptic maturation events can be temporally distinct and input-specific and may play different roles in behavioral plasticity.},
	number = {20},
	journal = {J. Neurosci.},
	author = {Stark, L L and Perkel, D J},
	month = oct,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {9107--9116},
}

@article{das_topography_1999,
	title = {Topography of contextual modulations mediated by short-range interactions in primary visual cortex},
	volume = {399},
	abstract = {Neurons in primary visual cortex (V1) respond differently to a simple visual element presented in isolation from when it is embedded within a complex image. This difference, a specific modulation by surrounding elements in the image, is mediated by short- and long-range connections within V1 and by feedback from other areas. Here we study the role of short-range connections in this process, and relate it to the layout of local inhomogeneities in the cortical maps of orientation and space. By measuring correlation between neuron pairs located in optically imaged maps of V1 orientation columns we show that the strength of local connections between cells is a graded function of lateral separation across cortex, largely radially symmetrical and relatively independent of orientation preferences. We then show the contextual influence of flanking visual elements on neuronal responses varies systematically with a neuron's position within the cortical orientation map. The strength of this contextual influence on a neuron can be predicted from a model of local connections based on simple overlap with particular features of the orientation map. This indicates that local intracortical circuitry could endow neurons with a graded specialization for processing angular visual features such as corners and T junctions, and this specialization could have its own functional cortical map, linked with the orientation map.},
	number = {6737},
	journal = {Nature},
	author = {Das, A and Gilbert, C D},
	month = jun,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {655--661},
}

@article{xiang_synaptic_2002,
	title = {Synaptic inhibition of pyramidal cells evoked by different interneuronal subtypes in layer v of rat visual cortex},
	volume = {88},
	abstract = {Properties of GABA(A) receptor-mediated unitary inhibitory postsynaptic currents (uIPSCs) in pyramidal (P) cells, evoked by fast spiking (FS) and low-threshold spike (LTS) subtypes of interneurons in layer V of rat visual cortex slices were examined using dual whole cell recordings. uIPSCs evoked by FS cells were larger and faster rising than those evoked by LTS cells, consistent with the known primary projections of FS and LTS cell axons to perisomatic and distal dendritic areas of layer V pyramidal cells, respectively, and the resulting electrotonic attenuation for LTS-P synaptic events. Unexpectedly, the decay time constants for LTS-P and FS-P uIPSCs were not significantly different. Modeling results were consistent with differences in the underlying GABA(A) receptor-mediated conductance at LTS-P and FS-P synapses. Paired-pulse depression (PPD), present at both synapses, was associated with an increase in failure rate and a decrease in coefficient of variation, indicating that presynaptic mechanisms were involved. Furthermore, the second and first uIPSC amplitudes during PPD were not inversely correlated, suggesting that PPD at both synapses is independent of previous release and might not result from depletion of the releasable pool of synaptic vesicles. Short, 20-Hz trains of action potentials in presynaptic interneurons evoked trains of uIPSCs with exponentially decreasing amplitudes at both FS-P and LTS-P synapses. FS-P uIPSC amplitudes declined more slowly than those of LTS-P uIPSCs. Thus FS and LTS cells, with their differences in firing properties, synaptic connectivity with layer V P cells, and short-term synaptic dynamics, might play distinct roles in regulating the input-output relationship of the P cells.},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Xiang, Z and Huguenard, Jr and Prince, Da},
	month = aug,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {740--750},
}

@article{hornoch_intracortical_1999,
	title = {Intracortical excitation of spiny neurons in layer 4 of cat striate cortex in vitro},
	volume = {9},
	abstract = {Recordings were made from pairs of neurons in cat striate visual cortex in vitro to study the AMPA-channel-mediated components of intracortical excitatory synaptic connections between layer 4 spiny neurons and between layer 6 and layer 4 spiny neurons. Forty-six of the 72 cells recorded were identified morphologically. They consisted of spiny stellate and pyramidal cells in layer 4, and pyramidal cells in layer 6. Connections between layer 4 excitatory cells involve excitatory postsynaptic potentials (EPSPs) averaging 949 microV, with an average coefficient of variation of 0.21 (n = 30). The synapses operate at very high release probabilities (0.69-0.98). With repetitive stimulation these EPSPs show varying degrees of depression, largely mediated by presynaptic changes in release probability. Four pairs of layer 4 cells were reciprocally connected. The connections from layer 6 to layer 4 involve smaller, more variable EPSPs, with an average amplitude of 214 microV, and average coefficient of variation 0.72 (n = 7). These synapses operate at moderately high release probabilities (0.37-0.56). They show facilitation with repetitive stimulation, mediated largely by presynaptic changes in release probability. One excitatory connection from a layer 4 neuron to a layer 6 pyramidal cell was also detected. Thus, layer 4 spiny neurons receive effective excitation from two intracortical sources that have different synaptic dynamics and are likely to contribute significantly to the temporal properties of these cells in vivo.},
	number = {8},
	journal = {Cereb. Cortex},
	author = {Hornoch, Tarczy-K and Martin, Ka and Stratford, Kj and Jack, Jj},
	month = dec,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {833--843},
}

@article{varela_differential_1999,
	title = {Differential depression at excitatory and inhibitory synapses in visual cortex},
	volume = {19},
	abstract = {The function of cortical circuits depends critically on the balance between excitation and inhibition. This balance reflects not only the relative numbers of excitatory and inhibitory synapses but also their relative strengths. Recent studies of excitatory synapses in visual and somatosensory cortices have emphasized that synaptic strength is not a fixed quantity but is a dynamic variable that reflects recent presynaptic activity. Here, we compare the dynamics of synaptic transmission at excitatory and inhibitory synapses onto visual cortical pyramidal neurons. We find that inhibitory synapses show less overall depression than excitatory synapses and that the kinetics of recovery from depression also differ between the two classes of synapse. When excitatory and inhibitory synapses are stimulated concurrently, this differential depression produces a time- and frequency-dependent shift in the reversal potential of the composite postsynaptic current. These results indicate that the balance between excitation and inhibition can change dynamically as a function of activity.},
	number = {11},
	journal = {J. Neurosci.},
	author = {Varela, Ja and Song, S and Turrigiano, Gg and Nelson, Sb},
	month = jun,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {4293--4304},
}

@article{hornoch_synaptic_1998,
	title = {Synaptic interactions between smooth and spiny neurones in layer 4 of cat visual cortex in vitro},
	volume = {508},
	abstract = {1. Dual intracellular recording was used to examine the interactions between neighbouring spiny (excitatory) and smooth (inhibitory) neurones in layer 4 of cat visual cortex in vitro. Synaptic connections were found in seventeen excitatory-inhibitory neurone pairs, along with one inhibitory-inhibitory connection. 2. Fast excitatory inputs onto smooth neurones (basket cells) from spiny cells (spiny stellate or pyramidal cells) (n = 6) produce large excitatory postsynaptic potentials (EPSPs) of up to 4 mV mean amplitude, whereas basket cells evoke slower inhibitory postsynaptic potentials (IPSPs) in their postsynaptic targets (n = 17), of smaller amplitude (up to 1.6 mV at membrane potentials of -60 mV). 3. Both types of PSP appear to be multiquantal, and both may exhibit depression of up to 60 \% during short trains of presynaptic spikes. This depression can involve presynaptic and/or postsynaptic factors. 4. One-third (n = 5) of the spiny cell-smooth cell pairs tested were reciprocally connected, and in the one pair for which the suprathreshold interactions were comprehensively investigated, the pattern of basket cell firing was strongly influenced by the activity in the connected excitatory neurone. The basket cell was only effective in inhibiting spiny cell firing when the excitatory neurone was weakly driven.},
	number = {Pt 2},
	journal = {J. Physiol.},
	author = {Hornoch, Tarczy-K and Martin, Ka and Jack, Jj and Stratford, Kj},
	month = apr,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {351--363},
}

@article{freeman_suppression_2002,
	title = {Suppression without {Inhibition} in {Visual} {Cortex}},
	volume = {35},
	abstract = {Neurons in primary visual cortex (V1) are thought to receive inhibition from other V1 neurons selective for a variety of orientations. Evidence for this inhibition is commonly found in cross-orientation suppression: responses of a V1 neuron to optimally oriented bars are suppressed by superimposed mask bars of different orientation. We show, however, that suppression is unlikely to result from intracortical inhibition. First, suppression can be obtained with masks drifting too rapidly to elicit much of a response in cortex. Second, suppression is immune to hyperpolarization (through visual adaptation) of cortical neurons responding to the mask. Signals mediating suppression might originate in thalamus, rather than in cortex. Thalamic neurons exhibit some suppression; additional suppression might arise from depression at thalamocortical synapses. The mechanisms of suppression are subcortical and possibly include the very first synapse into cortex.},
	number = {4},
	journal = {Neuron},
	author = {Freeman, T and Durand, S and Kiper, D and Carandini, M},
	month = aug,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {759},
}

@article{chung_short-term_2002,
	title = {Short-term depression at thalamocortical synapses contributes to rapid adaptation of cortical sensory responses in vivo},
	volume = {34},
	abstract = {In vivo whole-cell recordings revealed that during repeated stimulation, synaptic responses to deflection of facial whiskers rapidly adapt. Extracellular recordings in the somatosensory thalamus revealed that part of the adaptation occurs subcortically, but because cortical adaptation is stronger and recovers more slowly, cortical mechanisms must also contribute. Trains of sensory stimuli that produce profound sensory adaptation did not alter intrinsic membrane properties, including resting membrane potential, input resistance, and current-evoked firing. Synaptic input evoked via intracortical stimulation was also unchanged; however, synaptic input from the somatosensory thalamus was depressed by sensory stimulation, and this depression recovered with a time course matching that of the recovery of sensory responsiveness. These data strongly suggest that synaptic depression of thalamic input to the cortex contributes to the dynamic regulation of neuronal sensitivity during rapid changes in sensory input.},
	number = {3},
	journal = {Neuron},
	author = {Chung, S and Li, X and Nelson, Sb},
	month = apr,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {437--446},
}

@article{martinez_laminar_2002,
	title = {Laminar processing of stimulus orientation in cat visual cortex},
	volume = {540},
	abstract = {One of the most salient features to emerge in visual cortex is sensitivity to stimulus orientation. Here we asked if orientation selectivity, once established, is altered by successive stages of cortical processing. We measured patterns of orientation selectivity at all depths of the cat's visual cortex by making whole-cell recordings with dye-filled electrodes. Our results show that the synaptic representation of orientation indeed changes with position in the microcircuit, as information passes from layer 4 to layer 2+3 to layer 5. At the earliest cortical stage, for simple cells in layer 4, orientation tuning curves for excitation (depolarization) and inhibition (hyperpolarization) had similar peaks (within 0-7 deg, n = 11) and bandwidths. Further, the sharpness of orientation selectivity covaried with receptive field geometry (r = 0.74) - the more elongated the strongest subregion, the shaper the tuning. Tuning curves for complex cells in layer 2+3 also had similar peaks (within 0-4 deg, n = 7) and bandwidths. By contrast, at a later station, layer 5, the preferred orientation for excitation and inhibition diverged such that the peaks of the tuning curves could be as far as 90 deg apart (average separation, 54 deg; n = 6). Our results support the growing consensus that orientation selectivity is generated at the earliest cortical level and structured similarly for excitation and inhibition. Moreover, our novel finding that the relative tuning of excitation and inhibition changes with laminar position helps resolve prior controversy about orientation selectivity at later phases of processing and gives a mechanistic view of how the cortical circuitry recodes orientation.},
	number = {Pt 1},
	journal = {J. Physiol.},
	author = {Martinez, Lm and Alonso, Jm and Reid, Rc and Hirsch, Ja},
	month = apr,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {321--333},
}

@article{keat_predicting_2001,
	title = {Predicting every spike: a model for the responses of visual neurons},
	volume = {30},
	abstract = {In the early visual system, neuronal responses can be extremely precise. Under a wide range of stimuli, cells in the retina and thalamus fire spikes very reproducibly, often with millisecond precision on subsequent stimulus repeats. Here we develop a mathematical description of the firing process that, given the recent visual input, accurately predicts the timing of individual spikes. The formalism is successful in matching the spike trains from retinal ganglion cells in salamander, rabbit, and cat, as well as from lateral geniculate nucleus neurons in cat. It adapts to many different response types, from very precise to highly variable. The accuracy of the model allows a compact description of how these neurons encode the visual stimulus.},
	number = {3},
	journal = {Neuron},
	author = {Keat, J and Reinagel, P and Reid, Rc and Meister, M},
	month = jun,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {803--817},
}

@article{alonso_rules_2001,
	title = {Rules of connectivity between geniculate cells and simple cells in cat primary visual cortex},
	volume = {21},
	abstract = {Hundreds of thalamic axons ramify within a column of cat visual cortex; yet each layer 4 neuron receives input from only a fraction of them. We have examined the specificity of these connections by recording simultaneously from layer 4 simple cells and cells in the lateral geniculate nucleus with spatially overlapping receptive fields (n = 221 cell pairs). Because of the precise retinotopic organization of visual cortex, the geniculate axons and simple-cell dendrites of these cell pairs should have overlapped within layer 4. Nevertheless, monosynaptic connections were identified in only 33\% of all cases, as estimated by cross-correlation analysis. The visual responses of monosynaptically connected geniculate cells and simple cells were closely related. The probability of connection was greatest when a geniculate center overlapped a strong simple-cell subregion of the same sign (ON or OFF) near the center of the subregion. This probability was further increased when the time courses of the visual responses were similar. In addition, the connections were strongest when the simple-cell subregion and the geniculate center were matched in position, sign, and size. The rules of connectivity between geniculate afferents and simple cells resemble those found for retinal afferents to geniculate cells. The connections along the retinogeniculocortical pathway, therefore, show a precision that goes beyond simple retinotopy to include many other response properties, such as receptive-field sign, timing, subregion strength, and size. This specificity in wiring emphasizes the need for developmental mechanisms (presumably correlation-based) that can select among afferents that differ only slightly in their response properties.},
	number = {11},
	journal = {J. Neurosci.},
	author = {Alonso, Jm and Usrey, Wm and Reid, Rc},
	month = jun,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {4002--4015},
}

@article{usrey_synchronous_1999,
	title = {Synchronous activity in the visual system},
	volume = {61},
	abstract = {Synchronous activity among ensembles of neurons is a robust phenomenon observed in many regions of the brain. With the increased use of multielectrode recording techniques, synchronous firing of ensembles of neurons has been found at all levels in the mammalian visual pathway, from the retina to the extrastriate cortex. Here we distinguish three categories of synchrony in the visual system, (a) synchrony from anatomical divergence, (b) stimulus-dependent synchrony, and (c) emergent synchrony (oscillations). Although all three categories have been well documented, their functional significance remains uncertain. We discuss several lines of evidence both for and against a role for synchrony in visual processing: the perceptual consequences of synchronous activity, its ability to carry information, and the transmission of synchronous neural events to subsequent stages of processing.},
	journal = {Annu. Rev. Physiol.},
	author = {Usrey, Wm and Reid, Rc},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {435--456},
}

@article{mooney_different_2000,
	title = {Different subthreshold mechanisms underlie song selectivity in identified {HVc} neurons of the zebra finch},
	volume = {20},
	abstract = {Songbirds learn and maintain their songs via auditory experience. Neurons in many telencephalic nuclei important to song production and development are song selective, firing more to forward auditory playback of the bird's own song (BOS) than to reverse BOS or conspecific songs. Elucidating circuits that generate these responses can localize where auditory experience influences vocalization, bridging cellular and systems analyses of song learning. Song-selective responses in many song nuclei, including the vocal premotor nucleus robustus archistriatalis (RA) and the basal ganglia homolog area X, are thought to originate in nucleus HVc (used as a proper name), which contains interneurons and relay cells that innervate either RA or area X. Previous studies indicated that only X-projecting neurons have auditory responses, leaving open the source of RA's auditory input and the degree to which song selectivity may be refined in HVc. Here, in vivo intracellular recordings from morphologically and electrophysiologically identified HVc neurons revealed that both relay cell types fire song-selectively. However, their firing arises via markedly different subthreshold processes, and only X-projecting neurons appear to be sites for auditory refinement. RA-projecting neurons exhibited purely depolarizing subthreshold responses that were highly song selective and that were excitatory. In contrast, subthreshold responses of X-projecting neurons included less-selective depolarizing and highly selective hyperpolarizing components. Within individual birds, these BOS-evoked hyperpolarizations closely matched interneuronal firing, suggesting that HVc interneurons make restricted inputs onto X-projecting neurons. Because of the two relay cell types' subthreshold differences, factors affecting their resting membrane potentials could enable them to transmit distinct song representations to their targets.},
	number = {14},
	journal = {J. Neurosci.},
	author = {Mooney, R},
	month = jul,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {5420--5436},
}

@article{deangelis_functional_1999,
	title = {Functional micro-organization of primary visual cortex: receptive field analysis of nearby neurons},
	volume = {19},
	abstract = {It is well established that multiple stimulus dimensions (e.g., orientation and spatial frequency) are mapped onto the surface of striate cortex. However, the detailed organization of neurons within a local region of striate cortex remains unclear. Within a vertical column, do all neurons have the same response selectivities? And if not, how do they most commonly differ and why? To address these questions, we recorded from nearby pairs of simple cells and made detailed spatiotemporal maps of their receptive fields. From these maps, we extracted and analyzed a variety of response metrics. Our results provide new insights into the local organization of striate cortex. First, we show that nearby neurons seldom have very similar receptive fields, when these fields are characterized in space and time. Thus, there may be less redundancy within a column than previously thought. Moreover, we show that correlated discharge increases with receptive field similarity; thus, the local dissimilarity between neurons may allow for noise reduction by response pooling. Second, we show that several response variables are clustered within striate cortex, including some that have not received much attention such as response latency and temporal frequency. We also demonstrate that other parameters are not clustered, including the spatial phase (or symmetry) of the receptive field. Third, we show that spatial phase is the single parameter that accounts for most of the difference between receptive fields of nearby neurons. We consider the implications of this local diversity of spatial phase for population coding and construction of higher-order receptive fields.},
	number = {10},
	journal = {J. Neurosci.},
	author = {Deangelis, Gc and Ghose, Gm and Ohzawa, I and Freeman, Rd},
	month = may,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {4046--4064},
}

@article{deangelis_functional_1999-1,
	title = {Functional micro-organization of primary visual cortex: receptive field analysis of nearby neurons},
	volume = {19},
	abstract = {It is well established that multiple stimulus dimensions (e.g., orientation and spatial frequency) are mapped onto the surface of striate cortex. However, the detailed organization of neurons within a local region of striate cortex remains unclear. Within a vertical column, do all neurons have the same response selectivities? And if not, how do they most commonly differ and why? To address these questions, we recorded from nearby pairs of simple cells and made detailed spatiotemporal maps of their receptive fields. From these maps, we extracted and analyzed a variety of response metrics. Our results provide new insights into the local organization of striate cortex. First, we show that nearby neurons seldom have very similar receptive fields, when these fields are characterized in space and time. Thus, there may be less redundancy within a column than previously thought. Moreover, we show that correlated discharge increases with receptive field similarity; thus, the local dissimilarity between neurons may allow for noise reduction by response pooling. Second, we show that several response variables are clustered within striate cortex, including some that have not received much attention such as response latency and temporal frequency. We also demonstrate that other parameters are not clustered, including the spatial phase (or symmetry) of the receptive field. Third, we show that spatial phase is the single parameter that accounts for most of the difference between receptive fields of nearby neurons. We consider the implications of this local diversity of spatial phase for population coding and construction of higher-order receptive fields.},
	number = {10},
	journal = {J. Neurosci.},
	author = {Deangelis, Gc and Ghose, Gm and Ohzawa, I and Freeman, Rd},
	month = may,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {4046--4064},
}

@article{iyengar_development_1999,
	title = {Development of topography within song control circuitry of zebra finches during the sensitive period for song learning},
	volume = {19},
	abstract = {Refinement of topographic maps during sensitive periods of development is a characteristic feature of diverse sensory and motor circuits in the nervous system. Within the neural system that controls vocal learning and behavior in zebra finches, axonal connections of the cortical nucleus lMAN demonstrate striking functional and morphological changes during vocal development in juvenile males. These circuits are uniquely important for song production during the sensitive period for vocal learning, and the overall size of these brain regions and their patterns of axonal connectivity undergo dramatic growth and regression during this time. Axonal connections to and from lMAN are topographically organized in adult males that have already learned song. We wondered whether the large-scale changes seen in lMAN circuitry during the time that vocal behavior is being learned and refined could be accompanied by the emergence of topographic mapping. However, results presented herein demonstrate that most of these song-control circuits show the same broad patterns of axonal connectivity between subregions of individual nuclei at the onset of song learning as seen in adult birds. Thus, coarse topographic organization is not dependent on the types of experience that are crucial for vocal learning. Furthermore, this maintenance of topographic organization throughout the period of song learning is clearly not achieved by maintenance of static axonal arbors. In fact, because the volumes of song-control nuclei are growing (or regressing), topography must be maintained by active remodeling of axonal arbors to adapt to the changes in overall size of postsynaptic targets. A salient exception to this pattern of conserved topography is the projection from lMAN to the motor cortical region RA: this pathway is diffusely organized at the onset of song learning but undergoes substantial refinement during early stages of song learning, suggesting that remodeling of axonal connections within this projection during the period of vocal learning may signify the production of increasingly refined vocal utterances.},
	number = {14},
	journal = {J. Neurosci.},
	author = {Iyengar, S and Viswanathan, S S and Bottjer, S W},
	month = jul,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {6037--6057},
}

@article{perkel_electrophysiological_2002,
	title = {Electrophysiological analysis of a songbird basal ganglia circuit essential for vocal plasticity},
	volume = {57},
	abstract = {The discrete, interconnected nuclei of the songbird brain, collectively termed the song system, underlie the learning and production of song. Two main forebrain pathways have been identified that contribute to song production, learning, and adult plasticity. A posterior “motor pathway” including nucleus HVc (used as the proper name), the robust nucleus of the archistriatum (RA) and descending projections to the brainstem, is essential for song production. An “anterior forebrain pathway,” arising from HVc, passing through area X of the lobus parolfactorius, the medial portion of the dorsolateral nucleus of the anterior thalamus and the lateral magnocellular nucleus of the anterior neostriatum, and finally terminating in RA, is essential for song learning and adult plasticity. The fact that the lobus parolfactorius is thought to form a part of the avian striatum implies several predictions for the connections of area X and for the properties of its neurons. Here, we review the existing anatomical and electrophysiological data bearing on the nature of area X as a striatal structure. In general, the data strongly favor the notion that area X is striatal. One set of observations, however, is at odds with that idea, and we provide and partially test the hypothesis that area X also contains a pallidal component. We discuss further tests of this idea and implications for thinking of the song system as a basal ganglia loop similar to that described in mammals.},
	number = {3-4},
	journal = {Brain Res. Bull.},
	author = {Perkel, D J and Farries, M A and Luo, M and Ding, L},
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {529--532},
}

@article{flogel_visual_2002,
	title = {Visual cortex: suppression by depression},
	volume = {12},
	abstract = {The response of a neuron in the visual cortex to an oriented light bar is strongly reduced by concurrent presentation of a stimulus with a different orientation. New data suggest this 'cross-orientation suppression' is caused, not by intracortical inhibition, but by rapid depression of thalamocortical synapses.},
	number = {16},
	journal = {Curr. Biol.},
	author = {Flogel, Mrsic-T and Hubener, M},
	month = aug,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {R547},
}

@article{das_distortions_1997,
	title = {Distortions of visuotopic map match orientation singularities in primary visual cortex},
	volume = {387},
	abstract = {The map of orientation columns in primary visual cortex (V1) is known to show strong local distortions, with a generally smooth progression of orientation preference across extended regions of cortex, interrupted by sharp jumps (fractures) and point singularities. The map of visual space on V1, in contrast, has been assumed to be locally smooth and isotropic. We find, on the contrary, that the map of visual space on cat V1 shows strong and systematic local distortions in register with inhomogeneities in the orientation map, with the rate of receptive field movement across cortex being largely proportional to the local rate of change of orientation. This suggests possible systematic local variations in the functional connectivity of short-range lateral connections that underlie local cortical processing.},
	number = {6633},
	journal = {Nature},
	author = {Das, A and Gilbert, Cd},
	month = jun,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {594--598},
}

@article{martin_microcircuits_2002,
	title = {Microcircuits in visual cortex},
	volume = {12},
	abstract = {The microcircuity of the neocortex is bewildering in its anatomical detail, but seen through the filters of physiology, some simple circuits have been suggested. Intensive investigations of the cortical representation of orientation, however, show how difficult it is to achieve any consensus on what the circuits are, how they develop, and how they work. New developments in modeling allied with powerful experimental tools are changing this. Experimental work combining optical imaging with anatomy and physiology has revealed a rich local cortical circuitry. Whereas older models of cortical circuits have concentrated on simple 'feedforward' circuits, newer theoretical work has explored more the role of the recurrent cortical circuits, which are more realistic representations of the actual circuits and are computationally richer.},
	number = {4},
	journal = {Curr. Opin. Neurobiol.},
	author = {Martin, Ka},
	month = aug,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {418--425},
}

@article{sharon_dynamics_2002,
	title = {Dynamics and constancy in cortical spatiotemporal patterns of orientation processing},
	volume = {295},
	abstract = {How does the high selectivity to stimulus orientation emerge in the visual cortex? Thalamic feedforward-dominated models of orientation selectivity predict constant selectivity during the visual response, whereas intracortical recurrent models predict dynamic improvement in selectivity. We imaged the cat visual cortex with voltage-sensitive dyes to measure orientation-tuning dynamics of a large neuronal population. Tuning-curve width did not narrow after response onset, whereas the difference between preferred and orthogonal responses (modulation depth) first increased, then declined. We identified a suppression of the evoked responses, referred to as the evoked deceleration-acceleration (DA) notch, which was larger for the orthogonal response. Furthermore, peak selectivity of the tuning curves was contemporaneous with the evoked DA notch. These findings suggest that in the cat brain, sustained visual cortical processing does not narrow orientation tuning; rather, intracortical interactions may amplify modulation depth and suppress the orthogonal response relatively more than the preferred. Thus, feedforward models and recurrent models of orientation selectivity must be combined.},
	number = {5554},
	journal = {Science},
	author = {Sharon, D and Grinvald, A},
	month = jan,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {512--515},
}

@article{walker_disinhibition_2002,
	title = {Disinhibition outside receptive fields in the visual cortex},
	volume = {22},
	abstract = {By definition, the region outside the classical receptive field (CRF) of a neuron in the visual cortex does not directly activate the cell. However, the response of a neuron can be influenced by stimulation of the surrounding area. In previous work, we showed that this influence is mainly suppressive and that it is generally limited to a local region outside the CRF. In the experiments reported here, we investigate the mechanisms of the suppressive effect. Our approach is to find the position of a grating patch that is most effective in suppressing the response of a cell. We then use a masking stimulus at different contrasts over the grating patch in an attempt to disinhibit the response. We find that suppressive effects may be partially or completely reversed by use of the masking stimulus. This disinhibition suggests that effects from outside the CRF may be local. Although they do not necessarily underlie the perceptual analysis of a figure-ground visual scene, they may provide a substrate for this process.},
	number = {13},
	journal = {J. Neurosci.},
	author = {Walker, Ga and Ohzawa, I and Freeman, Rd},
	month = jul,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {5659--5668},
}

@article{kasamatsu_colinear_2001,
	title = {Colinear facilitation promotes reliability of single-cell responses in cat striate cortex},
	volume = {138},
	abstract = {Behavior is controlled by neural activity in the brain. The final outcome of this neural control may critically depend on the firing reliability of individual neurons. A nearly constant, proportional relationship is usually found between the response mean and response variance. Here we asked whether lateral interactions within striate cortex that modulate response magnitude also proportionately modify the response variance of cortical neurons. In many cases, response variability depended on stimulus organization: discrete flankers colinearly placed well outside the neuron's receptive field increased response magnitude without a proportional increase in variance, thus improving the neuron's response reliability. Since colinear flanker facilitation is often seen near the neuron's firing threshold, increased response reliability for weak stimuli may contribute to enhancing perceptual saliency.},
	number = {2},
	journal = {Exp. Brain Res.},
	author = {Kasamatsu, T and Polat, U and Pettet, Mw and Norcia, Am},
	month = may,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {163--172},
}

@article{maldonado_dynamics_2000,
	title = {Dynamics of striate cortical activity in the alert macaque: {II}. {Fast} time scale synchronization},
	volume = {10},
	abstract = {Synchronous neuronal activity with millisecond precision has been postulated to contribute to the process of visual perceptual grouping. We have performed multineuron recordings in striate cortex of two alert macaque monkeys to determine if the occurrence and properties of this form of activity are consistent with the minimal requirements of this theory. We find that neuronal synchronization with millisecond precision is a prevalent and robust feature of stimulus-evoked activity in striate cortex. It occurs among adjacent cells recorded by the same electrode ({\textless}120 microm), among cells recorded at separate but nearby sites (300-400 microm) and between cells recorded at locations separated by 3-4 mm. The magnitude and probability of synchronous firing is inversely related to the spatial separation between the cells and it occurs within and between groups of cells that are both tuned and untuned for stimulus orientation and direction. Among those tuned for orientation, cell pairs separated by {\textless}400 microm showed no clear dependence of correlated firing on orientation preference. The occurrence of gamma-band (20-70 Hz) oscillations in the cellular firing patterns was a strong predictor of synchronous firing at each of the spatial scales. Nearly 90\% of the cell pairs showing significant correlation also showed oscillatory firing in one or both cells of the pair. These results are consistent with some, but not all, of the previous reports of synchronous activity in striate cortex of both cat and primates. The similarities in the properties of synchronous oscillations in the monkey and cat suggest that this form of neuronal activity is a general property of mammalian striate cortex. The relation between correlation and oscillation suggests that neuronal rhythmicity is an important mechanism contributing to synchronization.},
	number = {11},
	journal = {Cereb. Cortex},
	author = {Maldonado, Pe and Hill, Friedman-S and Gray, Cm},
	month = nov,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1117--1131},
}

@article{polonsky_neuronal_2000,
	title = {Neuronal activity in human primary visual cortex correlates with perception during binocular rivalry},
	volume = {3},
	abstract = {During binocular rivalry, two incompatible monocular images compete for perceptual dominance, with one pattern temporarily suppressed from conscious awareness. We measured fMRI signals in early visual cortex while subjects viewed rival dichoptic images of two different contrasts; the contrast difference served as a 'tag' for the neuronal representations of the two monocular images. Activity in primary visual cortex (V1) increased when subjects perceived the higher contrast pattern and decreased when subjects perceived the lower contrast pattern. These fluctuations in V1 activity during rivalry were about 55\% as large as those evoked by alternately presenting the two monocular images without rivalry. The rivalry-related fluctuations in V1 activity were roughly equal to those observed in other visual areas (V2, V3, V3a and V4v). These results challenge the view that the neuronal mechanisms responsible for binocular rivalry occur primarily in later visual areas.},
	number = {11},
	journal = {Nat. Neurosci.},
	author = {Polonsky, A and Blake, R and Braun, J and Heeger, Dj},
	month = nov,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1153--1159},
}

@article{kapadia_spatial_2000,
	title = {Spatial distribution of contextual interactions in primary visual cortex and in visual perception},
	volume = {84},
	abstract = {To examine the role of primary visual cortex in visuospatial integration, we studied the spatial arrangement of contextual interactions in the response properties of neurons in primary visual cortex of alert monkeys and in human perception. We found a spatial segregation of opposing contextual interactions. At the level of cortical neurons, excitatory interactions were located along the ends of receptive fields, while inhibitory interactions were strongest along the orthogonal axis. Parallel psychophysical studies in human observers showed opposing contextual interactions surrounding a target line with a similar spatial distribution. The results suggest that V1 neurons can participate in multiple perceptual processes via spatially segregated and functionally distinct components of their receptive fields.},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Kapadia, Mk and Westheimer, G and Gilbert, Cd},
	month = oct,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {2048--2062},
}

@article{kittelberger_lesions_1999,
	title = {Lesions of an avian forebrain nucleus that disrupt song development alter synaptic connectivity and transmission in the vocal premotor pathway},
	volume = {19},
	abstract = {The avian forebrain nucleus, the lateral magnocellular nucleus of the anterior neostriatum (LMAN), is necessary for normal song development because LMAN lesions made in juvenile birds disrupt song production but do not disrupt song when made in adults. Although these age-limited behavioral effects implicate LMAN in song learning, a potential confound is that LMAN lesions could disrupt normal vocal motor function independent of any learning role by altering LMAN's premotor target, the song nucleus, the robust nucleus of the archistriatum (RA). To date, however, no studies have examined directly the effects of LMAN lesions on the circuitry of the RA. We report here that juvenile LMAN lesions rapidly and profoundly affect RA, altering synaptic connectivity within this nucleus, including descending inputs from the song nucleus HVc. Specifically, morphological assays of the dendritic spines of RA projection neurons and axon terminal boutons arising from HVc show a numerical decline in the density of connections in RA in LMAN-lesioned juveniles compared with controls. Concurrently, LMAN lesions alter excitatory transmission within the juvenile RA: after LMAN lesions, the stimulus-response relationship between HVc fibers and RA neurons steepens, and the amplitude of spontaneous monophasic EPSCs increases. Rather than arresting RA in a juvenile state, LMAN lesions transform the structure and function of RA and its connections, such that it is distinct from that of the normal juvenile. In many ways, RA circuitry in LMAN-lesioned juveniles resembles that of normal adults, suggesting that LMAN lesions induce a premature maturation of the vocal motor pathway, which may lead to a loss of behavioral plasticity and abnormal song development.},
	number = {21},
	journal = {J. Neurosci.},
	author = {Kittelberger, J M and Mooney, R},
	month = nov,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {9385--9398},
}

@article{perrett_ltd_2001,
	title = {{LTD} induction in adult visual cortex: role of stimulus timing and inhibition},
	volume = {21},
	abstract = {One Hertz stimulation of afferents for 15 min with constant interstimulus intervals (regular stimulation) can induce long-term depression (LTD) of synaptic strength in the neocortex. However, it is unknown whether natural patterns of low-frequency afferent spike activity induce LTD. Although neurons in the neocortex can fire at overall rates as low as 1 Hz, the intervals between spikes are irregular. This irregular spike activity (and thus, presumably, irregular activation of the synapses of that neuron onto postsynaptic targets) can be approximated by stimulation with Poisson-distributed interstimulus intervals (Poisson stimulation). Therefore, if low-frequency presynaptic spike activity in the intact neocortex is sufficient to induce a generalized LTD of synaptic transmission, then Poisson stimulation, which mimics this spike activity, should induce LTD in slices. We tested this hypothesis by comparing changes in the strength of synapses onto layer 2/3 pyramidal cells induced by regular and Poisson stimulation in slices from adult visual cortex. We find that regular stimulation induces LTD of excitatory synaptic transmission as assessed by field potentials and intracellular postsynaptic potentials (PSPs) with inhibition absent. However, Poisson stimulation does not induce a net LTD of excitatory synaptic transmission. When the PSP contained an inhibitory component, neither Poisson nor regular stimulation induced LTD. We propose that the short bursts of synaptic activity that occur during a Poisson train have potentiating effects that offset the induction of LTD that is favored with regular stimulation. Thus, natural (i.e., irregular) low-frequency activity in the adult neocortex in vivo should not consistently induce LTD.},
	number = {7},
	journal = {J. Neurosci.},
	author = {Perrett, Sp and Dudek, Sm and Eagleman, D and Montague, Pr and Friedlander, Mj},
	month = apr,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {2308--2319},
}

@article{dragoi_dynamics_2002,
	title = {Dynamics of neuronal sensitivity in visual cortex and local feature discrimination},
	volume = {5},
	abstract = {A striking aspect of natural scenes is that image features such as line orientation are strongly correlated at neighboring spatial locations but not at distant locations. Thus, during the viewing of a scene, eye movements are often accompanied by a change in the orientation structure of the image. How does this behavior influence the discrimination of local features and their encoding by visual cortical neurons? Here we examined the perceived changes in orientation induced by brief exposure to oriented image patterns in monkeys and humans, and then used reverse correlation to investigate dynamic changes in neuronal sensitivity in the primary visual cortex (V1) of behaving monkeys. Whereas brief adaptation to an oriented grating impaired identification of nearby orientations by broadening orientation selectivity and changing the preferred orientation of individual V1 neurons, it actually enhanced the identification of orthogonal orientations by sharpening neuronal selectivity. Hence, successive exposure to image patches of dissimilar spatial structure enhances both the ability to discriminate local features and the encoding of these features by V1 neurons.},
	number = {9},
	journal = {Nat. Neurosci.},
	author = {Dragoi, V and Sharma, J and Miller, Ek and Sur, M},
	month = sep,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {883--891},
}

@article{greenlee_saturation_1987,
	title = {Saturation of the tilt aftereffect},
	volume = {27},
	abstract = {The tilt aftereffect increases as a logarithmic function of adapting time, reaches saturation after approx 1 hr and decays on a symmetric, logarithmic time-course. This is similar to the time-course of contrast threshold elevation, suggesting that threshold and suprathreshold aftereffects are based on similar type of adaptation processes.},
	number = {6},
	journal = {Vision Res.},
	author = {Greenlee, Mw and Magnussen, S},
	year = {1987},
	keywords = {merged\_fiete.bib},
	pages = {1041--1043},
}

@article{skottun_tilt_1981,
	title = {Tilt aftereffect with small adapting angles},
	volume = {30},
	number = {2},
	journal = {Percept. Psychophys.},
	author = {Skottun, Bc and Johnsen, T and Magnussen, S},
	month = aug,
	year = {1981},
	keywords = {merged\_fiete.bib},
	pages = {199--200},
}

@article{magnussen_adapting_1980,
	title = {Adapting to two orientations: disinhibition in a visual aftereffect},
	volume = {207},
	abstract = {The tilt aftereffect of adapating to two different orientations simultaneously is weaker than the aftereffect of adapting to the more effective of the two orientations alone. This finding is consistent with explanations of orientational after-effects in terms of lateral inhibition between cortical orientation detectors, but not with explanations in terms of neural “fatigue” from excitation.},
	number = {4433},
	journal = {Science},
	author = {Magnussen, S and Kurtenbach, W},
	month = feb,
	year = {1980},
	keywords = {merged\_fiete.bib},
	pages = {908--909},
}

@article{magnussen_temporal_1986,
	title = {Temporal aspects of spatial adaptation. {A} study of the tilt aftereffect},
	volume = {26},
	abstract = {Growth and decay characteristics of the tilt aftereffect were studied for aftereffects induced by normal or continuous adaptation routines, and for aftereffects induced by successive or spaced adaptation to the same or different orientations on an adapt-partial decay-readapt schedule. In the continuous adaptation condition, growth and decay of the aftereffect were logarithmic functions of time. There was no evidence for saturation after 30 min adaptation. Aftereffect decay following spaced adaptation progresses as by continuous adaptation, but an adapting stimulus introduced during recovery from previous adaptation is more effective on the time scale than when introduced to a fully recovered system, summing approximately linearly with the residual aftereffect and off-setting the recovery process to zero. A second adapting stimulus whose orientation is of opposite sign (ccw vs cw) induces a two-phased decay process consisting of an early cancellation and a later enhancement of the original aftereffect. A two-stage model of adaptation is proposed.},
	number = {4},
	journal = {Vision Res.},
	author = {Magnussen, S and Johnsen, T},
	year = {1986},
	keywords = {merged\_fiete.bib},
	pages = {661--672},
}

@article{magnussen_contrast_1986,
	title = {Contrast threshold elevation following continuous and interrupted adaptation},
	volume = {26},
	abstract = {Contrast thresholds for a 6 c/deg sinewave grating were measured following continuous and interrupted adaptation of 10 min duration to a high-contrast (0.6) sinewave grating of the same spatial frequency. Interrupted adaptation was administered as five 2-min segments, and the interadaptation interval (IAI) was varied from 10 to 180 sec. The results indicate that adaptation to spatial contrast can be described by a two-staged process, each stage having a different time constant of adaptation decay.},
	number = {4},
	journal = {Vision Res.},
	author = {Magnussen, S and Greenlee, Mw},
	year = {1986},
	keywords = {merged\_fiete.bib},
	pages = {673--675},
}

@article{britten_tuning_1998,
	title = {Tuning bandwidths for near-threshold stimuli in area {MT}},
	volume = {80},
	abstract = {It is not known whether psychophysical performance depends primarily on small numbers of neurons optimally tuned to specific visual stimuli, or on larger populations of neurons that vary widely in their properties. Tuning bandwidths of single cells can provide important insight into this issue, yet most bandwidth measurements have been made using suprathreshold visual stimuli, whereas psychophysical measurements are frequently obtained near threshold. We therefore examined the directional tuning of cells in the middle temporal area (MT, or V5) using perithreshold, stochastic motion stimuli that we have employed extensively in combined psychophysical and physiological studies. The strength of the motion signal (coherence) in these displays can be varied independently of its direction. For each MT neuron, we characterized the directional bandwidth by fitting Gaussian functions to directional tuning data obtained at each of several motion coherences. Directional bandwidth increased modestly as the coherence of the stimulus was reduced. We then assessed the ability of MT neurons to discriminate opposed directions of motion along six equally spaced axes of motion spanning 180 degrees. A signal detection analysis yielded neurometric functions for each axis of motion, from which neural thresholds could be extracted. Neural thresholds remained surprisingly low as the axis of motion diverged from the neuron's preferred-null axis, forming a plateau of high to medium sensitivity that extended approximately 45 degrees on either side of the preferred-null axis. We conclude that directional tuning remains broad in MT when motion signals are reduced to near-threshold values. Thus directional information is widely distributed in MT, even near the limits of psychophysical performance. These observations support models in which relatively large numbers of signals are pooled to inform psychophysical decisions.},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Britten, Kh and Newsome, Wt},
	month = aug,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {762--770},
}

@article{wenderoth_neural_1999,
	title = {Neural substrates of the tilt illusion},
	volume = {27},
	abstract = {PURPOSE: It has been suggested that direct and indirect tilt illusions and after-effects have different mechanisms, namely that the direct effects arise in VI and are sensitive to differences in spatial and temporal parameters between test and inducing stimuli, whereas indirect effects arise in extrastriate cortex and are insensitive to such parameters. When Wolfe (Vision Research 1984; 24: 1959-64) reported that large direct tilt after-effects occurred with short test flashes, he postulated that either there are distinct mechanisms which process brief and longer duration stimuli or that there are distinct mechanisms that are not primarily concerned with duration but are differentially responsive to temporal parameters amongst several others. RESULTS: In three experiments we demonstrate that large direct tilt illusions can be induced when parameters other than duration are manipulated, including contrast and spatial frequency, and that such large effects can occur when stimulus parameters are chosen to favour preferentially either the transient (magnocellular-like) system or the sustained (parvocellular-like) system. CONCLUSIONS: These results are thus consistent with Wolfe's second hypothesis. None of these stimulus manipulations had any effect on indirect tilt illusions, consistent with previous findings and hypotheses about the different mechanisms of the direct and indirect effects.},
	number = {3-4},
	journal = {Aust. N. Z. J. Ophthalmol.},
	author = {Wenderoth, P and Smith, S},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {271--274},
}

@article{clifford_functional_2000,
	title = {A functional angle on some after-effects in cortical vision},
	volume = {267},
	abstract = {The question of how our brains and those of other animals code sensory information is of fundamental importance to neuroscience research. Visual illusions offer valuable insight into the mechanisms of perceptual coding. One such illusion, the tilt after-effect (TAE), has been studied extensively since the 1930s, yet a full explanation of the effect has remained elusive. Here, we put forward an explanation of the TAE in terms of a functional role for adaptation in the visual cortex. The proposed model accounts not only for the phenomenology of the TAE, but also for spatial interactions in perceived tilt and the effects of adaptation on the perception of direction of motion and colour. We discuss the implications of the model for understanding the effects of adaptation and surround stimulation on the response properties of cortical neurons.},
	number = {1454},
	journal = {Proc. R. Soc. Lond. B Biol. Sci.},
	author = {Clifford, Cw and Wenderoth, P and Spehar, B},
	month = sep,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1705--1710},
}

@article{huk_neuronal_2001,
	title = {Neuronal basis of the motion aftereffect reconsidered},
	volume = {32},
	abstract = {Several fMRI studies have reported MT+ response increases correlated with perception of the motion aftereffect (MAE). However, attention can strongly affect MT+ responses, and subjects may naturally attend more to the MAE than control trials without MAE. We found that requiring subjects to attend to motion on both MAE and control trials produced equal levels of MT+ response, suggesting that attention may have confounded the interpretation of previous experiments; in our data, attention accounts for the entire effect. After eliminating this confound, we observed that direction-selective motion adaptation produced a direction-selective imbalance in MT+ responses (and earlier visual areas), and yielded a corresponding asymmetry in speed discrimination thresholds. These findings provide physiological evidence that population level response imbalances underlie the MAE, and quantify the relative proportions of direction-selective neurons across human visual areas.},
	number = {1},
	journal = {Neuron},
	author = {Huk, Ac and Ress, D and Heeger, Dj},
	month = oct,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {161--172},
}

@article{he_orientation-selective_2001,
	title = {Orientation-selective adaptation and tilt after-effect from invisible patterns},
	volume = {411},
	abstract = {Exposure to visual patterns of high contrast (for example, gratings formed by alternating white and black bars) creates after-effects in perception. We become temporarily insensitive to faint test patterns that resemble the pre-exposed pattern (such as gratings of the same orientation), and we require more contrast to detect them. Moreover, if the test pattern is slightly tilted relative to the pre-exposed one, this tilt may be perceptually exaggerated: we experience a tilt after-effect. Here we show that these visual after-effects occur even if the pre-exposed grating is too fine to be perceptually resolved. After looking at a very fine grating, so high in spatial frequency that it was perceptually indistinguishable from a uniform field, observers required more contrast to detect a test grating presented at the same orientation than one presented at the orthogonal orientation. They also experienced a tilt after-effect that depended on the relation of the test pattern's tilt to the unseen orientation of the pre-exposed pattern. Because these after-effects are due to changes in orientation-sensitive mechanisms in visual cortex, our observations imply that extremely fine details, even those too fine to be seen, can penetrate the visual system as far as the cortex, where they are represented neurally without conscious awareness.},
	number = {6836},
	journal = {Nature},
	author = {He, S and Macleod, Di},
	month = may,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {473--476},
}

@article{skaggs_theta_1996,
	title = {Theta phase precession in hippocampal neuronal populations and the compression of temporal sequences},
	volume = {6},
	abstract = {O'Keefe and Recce [1993] Hippocampus 3:317-330 described an interaction between the hippocampal theta rhythm and the spatial firing of pyramidal cells in the CA1 region of the rat hippocampus: they found that a cell's spike activity advances to earlier phases of the theta cycle as the rat passes through the cell's place field. The present study makes use of large-scale parallel recordings to clarify and extend this finding in several ways: 1) Most CA1 pyramidal cells show maximal activity at the same phase of the theta cycle. Although individual units exhibit deeper modulation, the depth of modulation of CA1 population activity is about 50\%. The peak firing of inhibitory interneurons in CA1 occurs about 60 degrees in advance of the peak firing of pyramidal cells, but different interneurons vary widely in their peak phases. 2) The first spikes, as the rat enters a pyramidal cell's place field, come 90 degrees-120 degrees after the phase of maximal pyramidal cell population activity, near the phase where inhibition is least. 3) The phase advance is typically an accelerating, rather than linear, function of position within the place field. 4) These phenomena occur both on linear tracks and in two-dimensional environments where locomotion is not constrained to specific paths. 5) In two-dimensional environments, place-related firing is more spatially specific during the early part of the theta cycle than during the late part. This is also true, to a lesser extent, on a linear track. Thus, spatial selectivity waxes and wanes over the theta cycle. 6) Granule cells of the fascia dentata are also modulated by theta. The depth of modulation for the granule cell population approaches 100\%, and the peak activity of the granule cell population comes about 90 degrees earlier in the theta cycle than the peak firing of CA1 pyramidal cells. 7) Granule cells, like pyramidal cells, show robust phase precession. 8) Cross-correlation analysis shows that portions of the temporal sequence of CA1 pyramidal cell place fields are replicated repeatedly within individual theta cycles, in highly compressed form. The compression ratio can be as much as 10:1. These findings indicate that phase precession is a very robust effect, distributed across the entire hippocampal population, and that it is likely to be inherited from the fascia dentata or an earlier stage in the hippocampal circuit, rather than generated intrinsically within CA1. It is hypothesized that the compression of temporal sequences of place fields within individual theta cycles permits the use of long-term potentiation for learning of sequential structure, thereby giving a temporal dimension to hippocampal memory traces.},
	number = {2},
	journal = {Hippocampus},
	author = {Skaggs, We and Mcnaughton, Bl and Wilson, Ma and Barnes, Ca},
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {149--172},
}

@article{nakazawa_requirement_2002,
	title = {Requirement for hippocampal {CA3} {NMDA} receptors in associative memory recall},
	volume = {297},
	abstract = {Pattern completion, the ability to retrieve complete memories on the basis of incomplete sets of cues, is a crucial function of biological memory systems. The extensive recurrent connectivity of the CA3 area of hippocampus has led to suggestions that it might provide this function. We have tested this hypothesis by generating and analyzing a genetically engineered mouse strain in which the N-methyl-D-asparate (NMDA) receptor gene is ablated specifically in the CA3 pyramidal cells of adult mice. The mutant mice normally acquired and retrieved spatial reference memory in the Morris water maze, but they were impaired in retrieving this memory when presented with a fraction of the original cues. Similarly, hippocampal CA1 pyramidal cells in mutant mice displayed normal place-related activity in a full-cue environment but showed a reduction in activity upon partial cue removal. These results provide direct evidence for CA3 NMDA receptor involvement in associative memory recall.},
	number = {5579},
	journal = {Science},
	author = {Nakazawa, K and Quirk, Mc and Chitwood, Ra and Watanabe, M and Yeckel, Mf and Sun, Ld and Kato, A and Carr, Ca and Johnston, D and Wilson, Ma and Tonegawa, S},
	month = jul,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {211--218},
}

@article{zeng_forebrain-specific_2001,
	title = {Forebrain-specific calcineurin knockout selectively impairs bidirectional synaptic plasticity and working/episodic-like memory},
	volume = {107},
	abstract = {Calcineurin is a calcium-dependent protein phosphatase that has been implicated in various aspects of synaptic plasticity. By using conditional gene-targeting techniques, we created mice in which calcineurin activity is disrupted specifically in the adult forebrain. At hippocampal Schaffer collateral-CA1 synapses, LTD was significantly diminished, and there was a significant shift in the LTD/LTP modification threshold in mutant mice. Strikingly, although performance was normal in hippocampus-dependent reference memory tasks, including contextual fear conditioning and the Morris water maze, the mutant mice were impaired in hippocampus-dependent working and episodic-like memory tasks, including the delayed matching-to-place task and the radial maze task. Our results define a critical role for calcineurin in bidirectional synaptic plasticity and suggest a novel mechanistic distinction between working/episodic-like memory and reference memory.},
	number = {5},
	journal = {Cell},
	author = {Zeng, H and Chattarji, S and Barbarosie, M and Reig, Rondi-L and Philpot, Bd and Miyakawa, T and Bear, Mf and Tonegawa, S},
	month = nov,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {617--629},
}

@article{dantzker_laminar_2000,
	title = {Laminar sources of synaptic input to cortical inhibitory interneurons and pyramidal neurons},
	volume = {3},
	abstract = {The functional role of an individual neuron within a cortical circuit is largely determined by that neuron's synaptic input. We examined the laminar sources of local input to subtypes of cortical neurons in layer 2/3 of rat visual cortex using laser scanning photostimulation. We identified three distinct laminar patterns of excitatory input that correspond to physiological and morphological subtypes of neurons. Fast-spiking inhibitory basket cells and excitatory pyramidal neurons received strong excitatory input from middle cortical layers. In contrast, adapting inhibitory interneurons received their strongest excitatory input either from deep layers or laterally from within layer 2/3. Thus, differential laminar sources of excitatory inputs contribute to the functional diversity of cortical inhibitory interneurons.},
	number = {7},
	journal = {Nat. Neurosci.},
	author = {Dantzker, Jl and Callaway, Em},
	month = jul,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {701--707},
}

@article{sawatari_diversity_2000,
	title = {Diversity and cell type specificity of local excitatory connections to neurons in layer {3B} of monkey primary visual cortex},
	volume = {25},
	abstract = {In the primary visual cortex of macaque monkeys, laminar and columnar axonal specificity are correlated with functional differences between locations. We describe evidence that embedded within this anatomical framework is finer specificity of functional connections. Photostimulation-based mapping of functional input to 31 layer 3B neurons revealed that input sources to individual cells were highly diverse. Although some input differences were correlated with neuronal anatomy, no 2 neurons received excitatory input from the same cortical layers. Thus, input diversity reveals far more cell types than does anatomical diversity. This implies relatively little functional redundancy; despite trends related to laminar or columnar position, pools of neurons contributing uniquely to visual processing are likely relatively small. These results also imply that similarities in the anatomy of circuits in different cortical areas or species may not indicate similar functional connectivity.},
	number = {2},
	journal = {Neuron},
	author = {Sawatari, A and Callaway, Em},
	month = feb,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {459--471},
}

@article{callaway_local_1998,
	title = {Local circuits in primary visual cortex of the macaque monkey},
	volume = {21},
	abstract = {The basic laminar organization of excitatory local circuitry in the primary visual cortex of the macaque monkey is similar to that described previously in the cat's visual cortex (Gilbert 1983). This circuitry is described here in the context of a two-level model that distinguishes between feedforward and feedback connections. Embedded within this basic framework is a more complex organization. Within the strictly feedforward pathway, these circuits distribute unique combinations of magno-, parvo-, and koniocellular input from the lateral geniculate nucleus (LGN) to neurons in layers 2-4B. Their input is dependent on the extrastriate cortical areas they target. The local feedback connections from deep layers (5 and 6) arise from a diverse population of pyramidal neurons. Each type forms local connections with a unique relationship to more superficial layers. In the case of layer 6 neurons, these connections are closely related to layer 4 subdivisions receiving input from different functional streams.},
	journal = {Annu. Rev. Neurosci.},
	author = {Callaway, Em},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {47--74},
}

@article{hirsch_synaptic_2002,
	title = {Synaptic physiology of the flow of information in the cat's visual cortex in vivo},
	volume = {540},
	abstract = {Each stage of the striate cortical circuit extracts novel information about the visual environment. We asked if this analytic process reflected laminar variations in synaptic physiology by making whole-cell recording with dye-filled electrodes from the cat's visual cortex and thalamus; the stimuli were flashed spots. Thalamic afferents terminate in layer 4, which contains two types of cell, simple and complex, distinguished by the spatial structure of the receptive field. Previously, we had found that the postsynaptic and spike responses of simple cells reliably followed the time course of flash-evoked thalamic activity. Here we report that complex cells in layer 4 (or cells intermediate between simple and complex) similarly reprised thalamic activity (response/trial, 99 +/- 1.9 \%; response duration 159 +/- 57 ms; latency 25 +/- 4 ms; average +/- standard deviation; n = 7). Thus, all cells in layer 4 share a common synaptic physiology that allows secure integration of thalamic input. By contrast, at the second cortical stage (layer 2+3), where layer 4 directs its output, postsynaptic responses did not track simple patterns of antecedent activity. Typical responses to the static stimulus were intermittent and brief (response/trial, 31 +/- 40 \%; response duration 72 +/- 60 ms, latency 39 +/- 7 ms; n = 11). Only richer stimuli like those including motion evoked reliable responses. All told, the second level of cortical processing differs markedly from the first. At that later stage, ascending information seems strongly gated by connections between cortical neurons. Inputs must be combined in newly specified patterns to influence intracortical stages of processing.},
	number = {Pt 1},
	journal = {J. Physiol.},
	author = {Hirsch, Ja and Martinez, Lm and Alonso, Jm and Desai, K and Pillai, C and Pierre, C},
	month = apr,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {335--350},
}

@article{martinez_construction_2001,
	title = {Construction of complex receptive fields in cat primary visual cortex},
	volume = {32},
	abstract = {In primary visual cortex, neurons are classified into simple cells and complex cells based on their response properties. Although the role of these two cell types in vision is still unknown, an attractive hypothesis is that simple cells are necessary to construct complex receptive fields. This hierarchical model puts forward two main predictions. First, simple cells should connect monosynaptically to complex cells. Second, complex cells should become silent when simple cells are inactivated. We have recently provided evidence for the first prediction, and here we do the same for the second. In summary, our results suggest that the receptive fields of most layer 2+3 complex cells are generated by a mechanism that requires simple cell inputs.},
	number = {3},
	journal = {Neuron},
	author = {Martinez, Lm and Alonso, Jm},
	month = nov,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {515--525},
}

@article{hirsch_synaptic_1998,
	title = {Synaptic integration in striate cortical simple cells},
	volume = {18},
	abstract = {Simple cells in the visual cortex respond to the precise position of oriented contours (Hubel and Wiesel, 1962). This sensitivity reflects the structure of the simple receptive field, which exhibits two sorts of antagonism between on and off inputs. First, simple receptive fields are divided into adjacent on and off subregions; second, within each subregion, stimuli of the reverse contrast evoke responses of the opposite sign: push-pull (Hubel and Wiesel, 1962; Palmer and Davis, 1981; Jones and Palmer, 1987; Ferster, 1988). We have made whole-cell patch recordings from cat area 17 during visual stimulation to examine the generation and integration of excitation (push) and suppression (pull) in the simple receptive field. The temporal structure of the push reflected the pattern of thalamic inputs, as judged by comparing the intracellular cortical responses to extracellular recordings made in the lateral geniculate nucleus. Two mechanisms have been advanced to account for the pull-withdrawal of thalamic drive and active, intracortical inhibition (Hubel and Wiesel, 1962; Heggelund, 1968; Ferster, 1988). Our results suggest that intracortical inhibition is the dominant, and perhaps sole, mechanism of suppression. The inhibitory influences operated within a wide dynamic range. When inhibition was strong, the membrane conductance could be doubled or tripled. Furthermore, if a stimulus confined to one subregion was enlarged so that it extended into the next, the sign of response often changed from depolarizing to hyperpolarizing. In other instances, the inhibition modulated neuronal output subtly, by elevating spike threshold or altering firing rate at a given membrane voltage.},
	number = {22},
	journal = {J. Neurosci.},
	author = {Hirsch, Ja and Alonso, Jm and Reid, Rc and Martinez, Lm},
	month = nov,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {9517--9528},
}

@article{hirsch_ascending_1998,
	title = {Ascending projections of simple and complex cells in layer 6 of the cat striate cortex},
	volume = {18},
	abstract = {Receptive field properties vary systematically across the different layers of the cat striate cortex. Understanding how these functional differences emerge requires a precise description of the interlaminar connections and the quality of information that they transmit. This study examines the contribution of the two physiological types of neuron in layer 6, simple and complex, to the cortical microcircuit. The approach was to make whole-cell recordings with dye-filled electrodes in vivo to correlate visual response property with intracortical projection pattern. The two simple cells we stained projected to layer 4, as previously reported (Gilbert and Wiesel, 1979; Martin and Whitteridge, 1984). Six of the eight complex cells that we labeled projected to the superficial layers, a pathway not previously described in the cat. The remaining two cells targeted the infragranular layers. Layer 4 is dominated by simple cells, whereas layers 5 and 2+3 are mainly composed of complex cells (Hubel and Wiesel, 1962; Gilbert, 1977). Hence, our results indicate that the ascending projections of simple cells in layer 6 target other simple cells. In parallel, the ascending projections of a population of complex cells in layer 6 favor other complex cells. Anatomical experiments in several species (Lund and Boothe,1975; Burkhalter,1989; Usrey and Fitzpatrick, 1996; Wiser and Callaway, 1996) had also demonstrated that layer 6 gives rise to two separate intracortical pathways. Pooling the results of these anatomical studies with our own suggests a common feature of the laminar organization: cells that project to different intracortical targets have distinct functional characteristics.},
	number = {19},
	journal = {J. Neurosci.},
	author = {Hirsch, Ja and Gallagher, Ca and Alonso, Jm and Martinez, Lm},
	month = oct,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {8086--8094},
}

@article{crook_gaba-inactivation_2002,
	title = {{GABA}-inactivation attenuates colinear facilitation in cat primary visual cortex},
	volume = {143},
	abstract = {Neurons in primary visual cortex (V1) respond preferentially to stimuli of a particular orientation falling within a circumscribed region of visual space known as their receptive field (RF). However, the response to an optimally oriented stimulus presented within the RF can be enhanced by the simultaneous presentation of co-oriented, co-linearly aligned flank stimuli falling outside the RF which, when presented alone, fail to activate the cell. This type of contextual effect, termed colinear facilitation, presumably forms the physiological substrate for the integration of the line elements of a contour and the perceptual saliency of a contour in a complex environment. Here we show that colinear facilitation in single cells of cat area V1 can be substantially reduced or abolished by focal inactivation of laterally remote cells in the same area which respond strongly to the co-oriented, colinear flank stimulus inducing the facilitatory effect. The results provide evidence that horizontal intrinsic connections between cells with co-oriented and co-linearly aligned RFs make a major contribution to colinear facilitation in V1. They imply that the neuronal circuitry underlying contour integration and saliency is already present at the earliest stage of visual cortical information processing.},
	number = {3},
	journal = {Exp. Brain Res.},
	author = {Crook, Jm and Engelmann, R and Lowel, S},
	month = apr,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {295--302},
}

@article{crook_gaba-inactivation_2002-1,
	title = {{GABA}-inactivation attenuates colinear facilitation in cat primary visual cortex},
	volume = {143},
	abstract = {Neurons in primary visual cortex (V1) respond preferentially to stimuli of a particular orientation falling within a circumscribed region of visual space known as their receptive field (RF). However, the response to an optimally oriented stimulus presented within the RF can be enhanced by the simultaneous presentation of co-oriented, co-linearly aligned flank stimuli falling outside the RF which, when presented alone, fail to activate the cell. This type of contextual effect, termed colinear facilitation, presumably forms the physiological substrate for the integration of the line elements of a contour and the perceptual saliency of a contour in a complex environment. Here we show that colinear facilitation in single cells of cat area V1 can be substantially reduced or abolished by focal inactivation of laterally remote cells in the same area which respond strongly to the co-oriented, colinear flank stimulus inducing the facilitatory effect. The results provide evidence that horizontal intrinsic connections between cells with co-oriented and co-linearly aligned RFs make a major contribution to colinear facilitation in V1. They imply that the neuronal circuitry underlying contour integration and saliency is already present at the earliest stage of visual cortical information processing.},
	number = {3},
	journal = {Exp. Brain Res.},
	author = {Crook, Jm and Engelmann, R and Lowel, S},
	month = apr,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {295--302},
}

@article{fletcher_bird_1988,
	title = {Bird {Song} - {A} {Quantitative} {Acoustic} {Model}},
	volume = {135},
	abstract = {A detailed quantitative physical model is developed which gives a successful quantitative account of the “voiced” song of birds such as ravens. Using available anatomical and physiological data, the model allows calculation of syringeal membrane motion, volume flow waveform, tracheal pressure waveform, radiated acoustic power, and acoustic energy spectrum. Computed results for radiated acoustic powere as a function of air-sac pressure and volume flow are in good agreement with measured values in the literature. The radiated power spectrum consists of exactly harmonic components at multiples of the vibration frequency of the syringeal membrane, the inharmonic modes of which are locked into frequency and phase coherence by the non-linearity of the driving force when the membrane strikes against the cartilage of the opposing air-passage wall. The spectral envelope has formant bands at the “closed-pipe” resonance frequencies of the trachea, supplemented by formant bands at slightly below the “open-pipe” resonance frequencies. The strengths and origins of these bands are made clear by the model. The computed power spectrum is in excellent agreement with the Sonagraph spectrum of Corvus mellori when anatomical parameters for this bird are used. While the model is also able to produce inharmonic “screeched” song, attempts to produce a nearly pure-tone output by restricting the motion of the membrane so that it does not strike against the opposing cartilage have proved unsuccessful, the acoustic output being low in intensity and still exhibiting many overtones of the membrane frequency. This failure suggests that “whistled” song is produced in an entirely different manner from voiced song.},
	journal = {J. Theor. Biol.},
	author = {Fletcher, N H},
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {455--481},
}

@article{goller_new_1997,
	title = {A new mechanism of sound generation in songbirds},
	volume = {94},
	abstract = {Our current understanding of the sound-generating mechanism in the songbird vocal organ, the syrinx, is based on indirect evidence and theoretical treatments. The classical avian model of sound production postulates that the medial tympaniform membranes (MTM) are the principal sound generators. We tested the role of the MTM in sound generation and studied the songbird syrinx more directly by filming it endoscopically. After we surgically incapacitated the MTM as a vibratory source, zebra finches and cardinals were not only able to vocalize, but sang nearly normal song. This result shows clearly that the MTM are not the principal sound source. The endoscopic images of the intact songbird syrinx during spontaneous and brain stimulation-induced vocalizations illustrate the dynamics of syringeal reconfiguration before phonation and suggest a different model for sound production. Phonation is initiated by rostrad movement and stretching of the syrinx. At the same time, the syrinx is closed through movement of two soft tissue masses, the medial and lateral labia, into the bronchial lumen. Sound production always is accompanied by vibratory motions of both labia, indicating that these vibrations may be the sound source. However, because of the low temporal resolution of the imaging system, the frequency and phase of labial vibrations could not be assessed in relation to that of the generated sound. Nevertheless, in contrast to the previous model, these observations show that both labia contribute to aperture control and strongly suggest that they play an important role as principal sound generators.},
	number = {26},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Goller, F and Larsen, On},
	month = dec,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {14787--14791},
}

@article{lavenex_vocal_1999,
	title = {Vocal production mechanisms in the budgerigar ({Melopsittacus} undulatus): the presence and implications of amplitude modulation},
	volume = {106},
	abstract = {In this paper acoustic evidence is presented for the presence of amplitude modulation in budgerigar (Melopsittacus undulatus) contact calls and learned English vocalizations. Previously, acoustic analyses of budgerigar vocalizations have consisted solely of visual inspection of spectrograms or power spectra (derived from Fourier transformation). Such analyses have led researchers to conclude that budgerigar vocalizations are primarily frequency-modulated, harmonic vocalizations. Although budgerigar calls have been shown to contain regions that are modulated in amplitude, the implications of this fact have been largely ignored. Amplitude modulation, the nonlinear interaction between two separate signals that results in the creation of new, heterodyne (sum and difference) frequencies, can produce a very complex Fourier spectrum that may resemble that produced by a harmonic vocalization. In this paper, the acoustic principles necessary for identifying amplitude modulation present in signals are outlined, and followed by data demonstrating that amplitude modulation is a prominent feature not only of natural budgerigar contact calls, but also of their learned English vocalizations. It is illustrated how analyzing a vocalization that contains amplitude modulation as if it were harmonic can result in misinterpretations of the acoustic and physical properties of the sound and sound source. The implications of amplitude modulation for studies of the ontogenetic, physical, and neural basis of budgerigar vocalizations are discussed, and a potential model for how the budgerigar syrinx may function to produce amplitude modulation is proposed.},
	number = {1},
	journal = {J. Acoust. Soc. Am.},
	author = {Lavenex, Pb},
	month = jul,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {491--505},
}

@article{angelucci_circuits_2002,
	title = {Circuits for local and global signal integration in primary visual cortex},
	volume = {22},
	abstract = {Contrast-dependent changes in spatial summation and contextual modulation of primary visual cortex (V1) neuron responses to stimulation of their receptive field reveal long-distance integration of visual signals within V1, well beyond the classical receptive field (cRF) of single neurons. To identify the cortical circuits mediating these long-distance computations, we have used a combination of anatomical and physiological recording methods to determine the spatial scale and retinotopic logic of intra-areal V1 horizontal connections and inter-areal feedback connections to V1. We have then compared the spatial scales of these connectional systems to the spatial dimensions of the cRF, spatial summation field (SF), and modulatory surround field of macaque V1 neurons. We find that monosynaptic horizontal connections within area V1 are of an appropriate spatial scale to mediate interactions within the SF of V1 neurons and to underlie contrast-dependent changes in SF size. Contrary to common beliefs, these connections cannot fully account for the dimensions of the surround field. The spatial scale of feedback circuits from extrastriate cortex to V1 is, instead, commensurate with the full spatial range of center-surround interactions. Thus these connections could represent an anatomical substrate for contextual modulation and global-to-local integration of visual signals. Feedback projections connect corresponding and equal-sized regions of the visual field in striate and extrastriate cortices and cover anisotropic parts of visual space, unlike V1 horizontal connections that are isotropic in the macaque. V1 isotropic connectivity demonstrates that anisotropic horizontal connections are not necessary to generate orientation selectivity. Anisotropic feedback connections may play a role in contour completion.},
	number = {19},
	journal = {J. Neurosci.},
	author = {Angelucci, A and Levitt, Jb and Walton, Ej and Hupe, Jm and Bullier, J and Lund, Js},
	month = oct,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {8633--8646},
}

@article{graham_visual_1998,
	title = {Visual input evokes transient and strong shunting inhibition in visual cortical neurons},
	volume = {393},
	abstract = {The function and nature of inhibition of neurons in the visual cortex have been the focus of both experimental and theoretical investigations. There are two ways in which inhibition can suppress synaptic excitation. In hyperpolarizing inhibition, negative and positive currents sum linearly to produce a net change in membrane potential. In contrast, shunting inhibition acts nonlinearly by causing an increase in membrane conductance; this divides the amplitude of the excitatory response. Visually evoked changes in membrane conductance have been reported to be nonsignificant or weak, supporting the hyperpolarization mode of inhibition. Here we present a new approach to studying inhibition that is based on in vivo whole-cell voltage clamping. This technique allows the continuous measurement of conductance dynamics during visual activation. We show, in neurons of cat primary visual cortex, that the response to optimally orientated flashed bars can increase the somatic input conductance to more than three times that of the resting state. The short latency of the visually evoked peak of conductance, and its apparent reversal potential suggest a dominant contribution from gamma-aminobutyric acid ((GABA)A) receptor-mediated synapses. We propose that nonlinear shunting inhibition may act during the initial stage of visual cortical processing, setting the balance between opponent 'On' and 'Off' responses in different locations of the visual receptive field.},
	number = {6683},
	journal = {Nature},
	author = {Graham, Borg-Lj and Monier, C and Fregnac, Y},
	month = may,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {369--373},
}

@article{lund_inhibitory_2001,
	title = {Inhibitory synapse cover on the somata of excitatory neurons in macaque monkey visual cortex},
	volume = {11},
	abstract = {Electron microscopy was used in macaque monkey cortical area V1 to investigate what factors might determine the proportion of somatic membrane covered by inhibitory type 2 synapses. In a sample of 4654 excitatory neurons, synapse cover did not correlate consistently with cell variety (pyramid or spiny stellate), soma size, synaptic apposition length or thalamic input. There were significant differences in somatic synapse cover per layer, but the pattern of differences in cover among layers differed significantly between animals, suggesting that laminar environment alone is not a generally applicable determinant of amount of inhibitory synapse cover. The pattern of cover for cells in different layers was, however, similar between the two hemispheres of an individual monkey. Measures of inhibitory synapse cover on four sets of pyramidal neurons in layers 5 and 6, each with different efferent projection targets, showed that the sets differed significantly from other cells in their respective layers, and differed significantly from each other. These findings demonstrate that there is unique circuitry for different subsystems within single layers of cortex and provide a rationale for the rich variety of cortical GABAergic interneurons within single layers.},
	number = {9},
	journal = {Cereb. Cortex},
	author = {Lund, Js and Griffiths, S and Rumberger, A and Levitt, Jb},
	month = sep,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {783--795},
}

@article{cavanaugh_nature_2002,
	title = {Nature and interaction of signals from the receptive field center and surround in macaque v1 neurons},
	volume = {88},
	abstract = {Information is integrated across the visual field to transform local features into a global percept. We now know that V1 neurons provide more spatial integration than originally thought due to the existence of their nonclassical inhibitory surrounds. To understand spatial integration in the visual cortex, we have studied the nature and extent of center and surround influences on neuronal response. We used drifting sinusoidal gratings in circular and annular apertures to estimate the sizes of the receptive field's excitatory center and suppressive surround. We used combinations of stimuli inside and outside the receptive field to explore the nature of the surround influence on the receptive field center as a function of the relative and absolute contrast of stimuli in the two regions. We conclude that the interaction is best explained as a divisive modulation of response gain by signals from the surround. We then develop a receptive field model based on the ratio of signals from Gaussian-shaped center and surround mechanisms. We show that this model can account well for the variations in receptive field size with contrast that we and others have observed and for variations in size with the state of contrast adaptation. The model achieves this success by simple variations in the relative gain of the two component mechanisms of the receptive field. This model thus offers a parsimonious explanation of a variety of phenomena involving changes in apparent receptive field size and accounts for these phenomena purely in terms of two receptive field mechanisms that do not themselves change in size. We used the extent of the center mechanism in our model as an indicator of the spatial extent of the central excitatory portion of the receptive field. We compared the extent of the center to measurements of horizontal connections within V1 and determined that horizontal intracortical connections are well matched in extent to the receptive field center mechanism. Input to the suppressive surround may come in part from feedback signals from higher areas.},
	number = {5},
	journal = {J. Neurophysiol.},
	author = {Cavanaugh, Jr and Bair, W and Movshon, Ja},
	month = nov,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {2530--2546},
}

@article{miles_plasticity_1981,
	title = {Plasticity in the vestibulo-ocular reflex: a new hypothesis},
	volume = {4},
	abstract = {The vestibulo-ocular reflex functions to prevent head movements from disturbing retinal images by generating compensatory eye movements to offset the head movements. In the monkey–the species mainly under consideration here–this reflex is machine-like and very effective. In the short-term, the VOR operates as an open-loop control system without the benefit of feedback and its performance is fixed and immutable: No matter what pattern of eye-head coordination the animal uses to view external objects, there is a continuing need for the VOR and it continues to operate; however, should the VOR consistently fail to stabilize the retinal images during head turns, it will gradually undergo long-term adaptive gain changes that restore, that stability. This adaptive capability is ultimately dependent upon vision, and a variety of optical devices that disturb the visual input normally associated with lead turns have been used to induce large changes in the reflex. Insofar as the monkey is concerned, all of the available evidence suggests to us that the modifiable elements underlying these long-term adjustments are located in the brainstem vestibular pathways and not, as previously suggested by others, in the floccular lobes of the cerebellum. However, the flocculus does appear to have an important, inductive role in the adaptive process providing at least part of the error signal guiding the long-term adjustments in the brainstem. In our view, the VOR is a particularly well-defined example of a plastic system and promises to be a most useful model for studying the cellular mechanisms underlying memory and learning the central nervous system.},
	journal = {Annu. Rev. Neurosci.},
	author = {Miles, Fa and Lisberger, Sg},
	year = {1981},
	keywords = {merged\_fiete.bib},
	pages = {273--299},
}

@article{swindale_orientation_1998,
	title = {Orientation tuning curves: empirical description and estimation of parameters},
	volume = {78},
	abstract = {This paper compares the ability of some simple model functions to describe orientation tuning curves obtained in extracellular single-unit recordings from area 17 of the cat visual cortex. It also investigates the relationships between three methods currently used to estimate preferred orientation from tuning curve data: (a) least-squares curve fitting, (b) the vector sum method and (c) the Fourier transform method (Worgotter and Eysel 1987). The results show that the best fitting model function for single-unit orientation tuning curves is a von Mises circular function with a variable degree of skewness. However, other functions, such as a wrapped Gaussian, fit the data nearly as well. A cosine function provides a poor description of tuning curves in almost all instances. It is demonstrated that the vector sum and Fourier methods of determining preferred orientation are equivalent, and identical to calculating a least-square fit of a cosine function to the data. Least-squares fitting of a better model function, such as a von Mises function or a wrapped Gaussian, is therefore likely to be a better method for estimating preferred orientation. Monte-Carlo simulations confirmed this, although for broad orientation tuning curves sampled at 45 degree intervals, as is typical in optical recording experiments, all the methods gave similarly accurate estimates of preferred orientation. The sampling interval, the estimated error in the response measurements and the probable shape of the underlying response function all need to be taken into account in deciding on the best method of estimating referred orientation from physiological measurements of orientation tuning data.},
	number = {1},
	journal = {Biol. Cybern.},
	author = {Swindale, Nv},
	month = jan,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {45--56},
}

@article{budd_inhibitory_2000,
	title = {Inhibitory basket cell synaptic input to layer {IV} simple cells in cat striate visual cortex (area 17): a quantitative analysis of connectivity},
	volume = {17},
	abstract = {In the absence of a direct and specific marker for basket cells, the aim of this paper was to use available data to estimate the density of basket cell synaptic input to smooth and spiny neurons within layer IV of cat striate visual cortex (area 17). A linear quantitative analysis of layer IV basket cell connectivity data suggests that on average basket cells (1) comprise 25-35\% of all GABAergic neurons in layer IV (3552-4736 cells mm(-3)), (2) account for 30-41\% of all putative inhibitory dendritic synapses of layer IV spiny stellate cells (145-195 synapses cell(-1)) and a similar proportion of layer IV basket cells (25-37\%, 71-107 synapses cell(-1)), and (3) provide each layer IV spiny cell with 13-45 axons and each layer IV basket cell with 6-29 axons. These estimates suggest that basket cells may be less common and provide a smaller proportion of the dendritic synaptic input to layer IV spiny and smooth neurons than previously thought. In addition, the analysis indicates that a layer IV spiny stellate cell may receive on average as many synapses and axons from layer IV basket cells as from lateral geniculate relay cells. Based on this potential numerical similarity, a geniculate-basket synaptic pairing in a spine-shaft microcircuit is hypothesized. This microcircuit could implement a type of local (dendritic) push-pull interaction underlying subfield antagonism.},
	number = {3},
	journal = {Vis. Neurosci.},
	author = {Budd, Jm},
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {331--343},
}

@article{bosking_spatial_2002,
	title = {Spatial coding of position and orientation in primary visual cortex},
	volume = {5},
	abstract = {We examined the spatial distribution of population activity in primary visual cortex (V1) of tree shrews with optical imaging and electrophysiology. A line stimulus, thinner than the average V1 receptive field, evoked a broad strip of neural activity of nearly constant size for all stimulus locations tested within the central 10 degrees of visual space. Stimuli in adjacent positions activated highly overlapping populations of neurons; nevertheless, small changes in stimulus position produced orderly changes in the location of the peak of the population response. Statistically significant shifts in the population response were found for stimulus displacements an order of magnitude smaller than receptive field width, down to the limit of optical imaging resolution. Based on the pattern of population activity, we conclude that the map of visual space in V1 is orderly at a fine scale and has uniform coverage of position and orientation without local relationships in the mapping of these features.},
	number = {9},
	journal = {Nat. Neurosci.},
	author = {Bosking, Wh and Crowley, Jc and Fitzpatrick, D},
	month = sep,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {874--882},
}

@article{vidyasagar_multiple_1996,
	title = {Multiple mechanisms underlying the orientation selectivity of visual cortical neurones},
	volume = {19},
	abstract = {For over three decades, the mechanism of orientation selectivity of visual cortical neurones has been hotly debated. While intracortical inhibition has been implicated as playing a vital role, it has been difficult to observe it clearly. On the basis of recent findings, we propose a model in which the visual cortex brings together a number of different mechanisms for generating orientation-selective responses. Orientation biases in the thalamo-cortical input fibres provide an initial weak selectivity either directly in the excitatory input or by acting via cortical interneurones. This weak selectivity of postsynaptic potentials is then amplified by voltage-sensitive conductances of the cell membrane and excitatory and inhibitory intracortical circuitry, resulting in the sharp tuning seen in the spike discharges of visual cortical cells.},
	number = {7},
	journal = {Trends Neurosci.},
	author = {Vidyasagar, Tr and Pei, X and Volgushev, M},
	month = jul,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {272--277},
}

@article{roerig_relationships_2002,
	title = {Relationships of local inhibitory and excitatory circuits to orientation preference maps in ferret visual cortex},
	volume = {12},
	abstract = {The contribution and precise role of intracortical circuits in generating orientation tuned responses in visual cortical neurons is still controversial. To address this question, the relationship between excitatory and inhibitory synaptic connections and orientation maps in ferret striate cortex was investigated by combining in vivo optical imaging and in vitro scanning laser photostimulation. Excitatory and inhibitory inputs to pyramidal cells originated preferentially from regions with similar orientation preference. Prominent cross-orientation inhibition was not observed, arguing against cross-orientation models of orientation selectivity. The tuning of inhibitory inputs was significantly broader in both layer 2/3 and layer 5/6 pyramidal neurons compared to the tuning of excitatory inputs. Local excitatory inputs were more prominent in the 0-20 degrees tuning difference range between pre- and postsynaptic cells than inhibitory inputs, whereas inhibition dominated in the 20-40 degrees tuning difference range. These differences in tuning of excitatory and inhibitory inputs onto individual cells are consistent with the predictions of recurrent models of orientation selectivity.},
	number = {2},
	journal = {Cereb. Cortex},
	author = {Roerig, B and Chen, B},
	month = feb,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {187--198},
}

@article{laurent_olfactory_2002,
	title = {Olfactory network dynamics and the coding of multidimensional signals},
	volume = {3},
	abstract = {California Institute of Technology, Division of Biology 139-74, 1201 East California Boulevard, Pasadena, California 91125, USA. laurentg@caltech.edu},
	number = {11},
	journal = {Nat. Rev. Neurosci.},
	author = {Laurent, G},
	month = nov,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {884--895},
}

@article{packard_learning_2002,
	title = {Learning and memory functions of the {Basal} {Ganglia}},
	volume = {25},
	abstract = {Although the mammalian basal ganglia have long been implicated in motor behavior, it is generally recognized that the behavioral functions of this subcortical group of structures are not exclusively motoric in nature. Extensive evidence now indicates a role for the basal ganglia, in particular the dorsal striatum, in learning and memory. One prominent hypothesis is that this brain region mediates a form of learning in which stimulus-response (S-R) associations or habits are incrementally acquired. Support for this hypothesis is provided by numerous neurobehavioral studies in different mammalian species, including rats, monkeys, and humans. In rats and monkeys, localized brain lesion and pharmacological approaches have been used to examine the role of the basal ganglia in S-R learning. In humans, study of patients with neurodegenerative diseases that compromise the basal ganglia, as well as research using brain neuroimaging techniques, also provide evidence of a role for the basal ganglia in habit learning. Several of these studies have dissociated the role of the basal ganglia in S-R learning from those of a cognitive or declarative medial temporal lobe memory system that includes the hippocampus as a primary component. Evidence suggests that during learning, basal ganglia and medial temporal lobe memory systems are activated simultaneously and that in some learning situations competitive interference exists between these two systems.},
	journal = {Annu. Rev. Neurosci.},
	author = {Packard, Mg and Knowlton, Bj},
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {563--593},
}

@article{tunstall_inhibitory_2002,
	title = {Inhibitory interactions between spiny projection neurons in the rat striatum},
	volume = {88},
	abstract = {The spiny projection neurons are by far the most numerous type of striatal neuron. In addition to being the principal projection neurons of the striatum, the spiny projection neurons also have an extensive network of local axon collaterals by which they make synaptic connections with other striatal projection neurons. However, up to now there has been no direct physiological evidence for functional inhibitory interactions between spiny projection neurons. Here we present new evidence that striatal projection neurons are interconnected by functional inhibitory synapses. To examine the physiological properties of unitary inhibitory postsynaptic potentials (IPSPs), dual intracellular recordings were made from pairs of spiny projection neurons in brain slices of adult rat striatum. Synaptic interactions were found in 9 of 45 pairs of neurons using averages of 200 traces that were triggered by a single presynaptic action potential. In all cases, synaptic interactions were unidirectional, and no bidirectional interactions were detected. Unitary IPSPs evoked by a single presynaptic action potential had a peak amplitude ranging from 157 to 319 microV in different connections (mean: 277 +/- 46 microV, n = 9). The percentage of failures of single action potentials to evoke a unitary IPSP was estimated and ranged from 9 to 63\% (mean: 38 +/- 14\%, n = 9). Unitary IPSPs were reversibly blocked by bicuculline (n = 4) and had a reversal potential of -62.4 +/- 0.7 mV (n = 5), consistent with GABA-mediated inhibition. The findings of the present study correlate very well with anatomical evidence for local synaptic connectivity between spiny projection neurons and suggest that lateral inhibition plays a significant role in the information processing operations of the striatum.},
	number = {3},
	journal = {J. Neurophysiol.},
	author = {Tunstall, Mj and Oorschot, De and Kean, A and Wickens, Jr},
	month = sep,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {1263--1269},
}

@article{wickens_regulation_1998,
	title = {Regulation of action-potential firing in spiny neurons of the rat neostriatum in vivo},
	volume = {79},
	abstract = {Both silent and spontaneously firing spiny projection neurons have been described in the neostriatum, but the reason for their differences in firing activity are unknown. We compared properties of spontaneously firing and silent spiny neurons in urethan-anesthetized rats. Neurons were identified as spiny projection neurons after labeling by intracellular injection of biocytin. The threshold for action-potential firing was measured under three different conditions: 1) electrical stimulation of the contralateral cerebral cortex, 2) brief directly applied current pulses, and 3) spontaneous action-potentials occurring during spontaneous episodes of depolarization ( state). The average membrane potential and the amplitude of noiselike fluctuations of membrane potential in the state were determined by fitting a Gaussian curve to the membrane-potential distribution. All neurons in the sample exhibited spontaneous membrane potential shifts between a hyperpolarized state and a depolarized state, but not all fired action potentials while in the state. The difference between the spontaneously firing and the silent spiny neurons was in the average membrane potential in the state, which was significantly more depolarized in the spontaneously firing than in the silent spiny neurons. There were no significant differences in the threshold, the amplitude of the noiselike fluctuations of membrane potential in the state, or in the proportion of time that the membrane potential was in the state. In both spontaneously firing and silent neurons, the threshold for action potentials evoked by current pulses was significantly higher than for those evoked by cortical stimulation. Application of more intense current pulses that reproduced the excitatory postsynaptic potential rate of rise produced firing at correspondingly lower thresholds. Because the membrane potential in the state is mainly determined by the balance between the synaptic drive and the outward potassium conductances activated in the subthreshold range of membrane potentials, either or both of these factors may determine whether firing occurs in response to spontaneous afferent activity.},
	number = {5},
	journal = {J. Neurophysiol.},
	author = {Wickens, Jr and Wilson, Cj},
	month = may,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {2358--2364},
}

@article{tanji_sequential_2001,
	title = {Sequential organization of multiple movements: involvement of cortical motor areas},
	volume = {24},
	abstract = {Much of our normal behavior depends on the sequential execution of multiphased movements, or the execution of multiple movements arranged in a correct temporal order. This article deals with the issue of motor selection to arrange multiple movements in an appropriate temporal order, rather than the issue of constructing spatio-temporal structures in a single action. Planning, generating, and controlling the sequential motor behavior involves multiple cortical and subcortical neural structures. Studies on human subjects and nonhuman primates, however, have revealed that the medial motor areas in the frontal cortex and the basal ganglia play particularly important roles in the temporal sequencing of multiple movements. Cellular activity observed in the supplementary and presupplementary motor areas while performing specifically designed motor tasks suggests the way in which these areas take part in constructing the time structure for the sequential execution of multiple movements.},
	journal = {Annu. Rev. Neurosci.},
	author = {Tanji, J},
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {631--651},
}

@article{csicsvari_mechanisms_2003,
	title = {Mechanisms of gamma oscillations in the hippocampus of the behaving rat},
	volume = {37},
	abstract = {Gamma frequency oscillations (30-100 Hz) have been suggested to underlie various cognitive and motor functions. Here, we examine the generation of gamma oscillation currents in the hippocampus, using two-dimensional, 96-site silicon probes. Two gamma generators were identified, one in the dentate gyrus and another in the CA3-CA1 regions. The coupling strength between the two oscillators varied during both theta and nontheta states. Both pyramidal cells and interneurons were phase-locked to gamma waves. Anatomical connectivity, rather than physical distance, determined the coupling strength of the oscillating neurons. CA3 pyramidal neurons discharged CA3 and CA1 interneurons at latencies indicative of monosynaptic connections. Intrahippocampal gamma oscillation emerges in the CA3 recurrent system, which entrains the CA1 region via its interneurons.},
	number = {2},
	journal = {Neuron},
	author = {Csicsvari, J and Jamieson, B and Wise, Kd and Buzsaki, G},
	month = jan,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {311--322},
}

@article{harris_spike_2002,
	title = {Spike train dynamics predicts theta-related phase precession in hippocampal pyramidal cells},
	volume = {417},
	abstract = {According to the temporal coding hypothesis, neurons encode information by the exact timing of spikes. An example of temporal coding is the hippocampal phase precession phenomenon, in which the timing of pyramidal cell spikes relative to the theta rhythm shows a unidirectional forward precession during spatial behaviour. Here we show that phase precession occurs in both spatial and non-spatial behaviours. We found that spike phase correlated with instantaneous discharge rate, and processed unidirectionally at high rates, regardless of behaviour. The spatial phase precession phenomenon is therefore a manifestation of a more fundamental principle governing the timing of pyramidal cell discharge. We suggest that intrinsic properties of pyramidal cells have a key role in determining spike times, and that the interplay between the magnitude of dendritic excitation and rhythmic inhibition of the somatic region is responsible for the phase assignment of spikes.},
	number = {6890},
	journal = {Nature},
	author = {Harris, Kd and Henze, Da and Hirase, H and Leinekugel, X and Dragoi, G and Czurko, A and Buzsaki, G},
	month = jun,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {738--741},
}

@article{reiner_functional_2002,
	title = {Functional circuitry of the avian basal ganglia: implications for basal ganglia organization in stem amniotes},
	volume = {57},
	abstract = {Histochemical, pathway tracing, and neuropeptide/neurotransmitter localization studies in birds, reptiles and mammals during the 1970s and 80s clearly showed that the telencephalon in all amniotes consists of a prominent ventrally situated subpallial region termed the basal ganglia, and a large overlying region involved in higher order information processing termed the pallium or cortex. These studies also showed that the basal ganglia in all extant amniote groups possessed neurochemically and hodologically distinct striatal and pallidal territories. More recently, studies of the localization of genes controlling regional brain development have confirmed the homology of the basal ganglia among amniotes. In our ongoing studies, we have identified several aspects of the functional organization of the basal ganglia that birds also share with mammals. These include: (1) an extensive glutamatergic “cortico”-striatal input and distinctive, cell-type specific localization of glutamate receptor subtypes; (2) an extensive, presumptively glutamatergic intralaminar thalamic input to striatal neurons; (3) an extensive dopaminergic input from the midbrain targeting both substance P (SP) type and enkephalin (ENK) type striatal projection neurons, with SP-type striatal neurons seemingly richer in the D-1 type dopamine receptor; and (4) SP+ and ENK+ striatal outputs giving rise to functionally distinct so-called direct and indirect motor output pathways, with the direct pathway having a pallido-thalamo-motor cortex loop and the indirect pathway relaying back to the direct circuit via the subthalamic nucleus. These findings suggest that the major aspects of the cellular organization and functional circuitry of the basal ganglia in stem amniotes were already as observed in living amniotes, as therefore presumably was its key role in movement control. Because the organization of the basal ganglia of anamniotes is clearly less elaborate than in amniotes, and because the basal ganglia and cortex in amniotes are clearly extensively interconnected structures, it seems likely that stem amniotes were characterized by a major step forward in the grade of telencephalic organization of both the basal ganglia and the pallium.},
	number = {3-4},
	journal = {Brain Res. Bull.},
	author = {Reiner, A},
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {513--528},
}

@article{reiner_structural_1998,
	title = {Structural and functional evolution of the basal ganglia in vertebrates},
	volume = {28},
	abstract = {While a basal ganglia with striatal and pallidal subdivisions is 1 clearly present in many extant anamniote species, this basal ganglia is cell sparse and receives only a relatively modest tegmental dopaminergic input and little if any cortical input. The major basal ganglia influence on motor functions in anamniotes appears to be exerted via output circuits to the tectum. In contrast, in modern mammals, birds, and reptiles (i.e., modern amniotes), the striatal and pallidal parts of the basal ganglia are very neuron-rich, both consist of the same basic populations of neurons in all amniotes, and the striatum receives abundant tegmental dopaminergic and cortical input. The functional circuitry of the basal ganglia also seems very similar in all amniotes, since the major basal ganglia influences on motor functions appear to be exerted via output circuits to both cerebral cortex and tectum in sauropsids (i.e., birds and reptiles) and mammals. The basal ganglia, output circuits to the cortex, however, appear to be considerably more developed in mammals than in birds and reptiles. The basal ganglia, thus, appears to have undergone a major elaboration during the evolutionary transition from amphibians to reptiles. This elaboration may have enabled amniotes to learn and/or execute a more sophisticated repertoire of behaviors and movements, and this ability may have been an important element of the successful adaptation of amniotes to a fully terrestrial habitat. The mammalian lineage appears, however, to have diverged somewhat from the sauropsid lineage with respect to the emergence of the cerebral cortex as the major target of the basal ganglia circuitry devoted to executing the basal ganglia-mediated control of movement. Copyright 1998 Elsevier Science B.V.},
	number = {3},
	journal = {Brain Res. Brain Res. Rev.},
	author = {Reiner, A and Medina, L and Veenman, Cl},
	month = dec,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {235--285},
}

@article{ng_transmission_2002,
	title = {Transmission of olfactory information between three populations of neurons in the antennal lobe of the fly},
	volume = {36},
	abstract = {Three classes of neurons form synapses in the antennal lobe of Drosophila, the insect counterpart of the vertebrate olfactory bulb: olfactory receptor neurons, projection neurons, and inhibitory local interneurons. We have targeted a genetically encoded optical reporter of synaptic transmission to each of these classes of neurons and visualized population responses to natural odors. The activation of an odor-specific ensemble of olfactory receptor neurons leads to the activation of a symmetric ensemble of projection neurons across the glomerular synaptic relay. Virtually all excited glomeruli receive inhibitory input from local interneurons. The extent, odor specificity, and partly interglomerular origin of this input suggest that inhibitory circuits assemble combinatorially during odor presentations. These circuits may serve as dynamic templates that extract higher order features from afferent activity patterns.},
	number = {3},
	journal = {Neuron},
	author = {Ng, M and Roorda, Rd and Lima, Sq and Zemelman, Bv and Morcillo, P and Miesenbock, G},
	month = oct,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {463--474},
}

@article{theunissen_synchrony_2003,
	title = {From synchrony to sparseness},
	volume = {26},
	abstract = {The neurons in the antennal lobe of the locust had been shown to encode the identity of odorants using spatially distributed synchronized patterns of neural activity. Recent work describes how such neural patterns are detected. By using non-linear membrane properties, one set of target neurons, the Kenyon cells of the mushroom bodies, are able to act as coincidence detectors, sensitive to synchronized activity. In addition, the specific circuitry between the antennal lobe and the mushroom body refines the spatial-temporal selectivity of the Kenyon cells. In this process, the neural representation of odor identity is transformed from a dense spatial-temporal code into a sparse code.},
	number = {2},
	journal = {Trends Neurosci.},
	author = {Theunissen, Fe},
	month = feb,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {61--64},
}

@article{perez-orive_oscillations_2002-1,
	title = {Oscillations and sparsening of odor representations in the mushroom body},
	volume = {297},
	abstract = {In the insect olfactory system, oscillatory synchronization is functionally relevant and reflects the coherent activation of dynamic neural assemblies. We examined the role of such oscillatory synchronization in information transfer between networks in this system. The antennal lobe is the obligatory relay for olfactory afferent signals and generates oscillatory output. The mushroom body is responsible for formation and retrieval of olfactory and other memories. The format of odor representations differs significantly across these structures. Whereas representations are dense, dynamic, and seemingly redundant in the antennal lobe, they are sparse and carried by more selective neurons in the mushroom body. This transformation relies on a combination of oscillatory dynamics and intrinsic and circuit properties that act together to selectively filter and synthesize the output from the antennal lobe. These results provide direct support for the functional relevance of correlation codes and shed some light on the role of oscillatory synchronization in sensory networks.},
	number = {5580},
	journal = {Science},
	author = {Perez-Orive, J and Mazor, O and Turner, G C and Cassenaer, S and Wilson, R I and Laurent, G},
	month = jul,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {359--365},
}

@article{doiron_inhibitory_2003,
	title = {Inhibitory feedback required for network oscillatory responses to communication but not prey stimuli},
	volume = {421},
	abstract = {Stimulus-induced oscillations occur in visual, olfactory and somatosensory systems. Several experimental and theoretical studies have shown how such oscillations can be generated by inhibitory connections between neurons. But the effects of realistic spatiotemporal sensory input on oscillatory network dynamics and the overall functional roles of such oscillations in sensory processing are poorly understood. Weakly electric fish must detect electric field modulations produced by both prey (spatially localized) and communication (spatially diffuse) signals. Here we show, through in vivo recordings, that sensory pyramidal neurons in these animals produce an oscillatory response to communication-like stimuli, but not to prey-like stimuli. On the basis of well-characterized circuitry, we construct a network model of pyramidal neurons that predicts that diffuse delayed inhibitory feedback is required to achieve oscillatory behaviour only in response to communication-like stimuli. This prediction is experimentally verified by reversible blockade of feedback inhibition that removes oscillatory behaviour in the presence of communication-like stimuli. Our results show that a sensory system can use inhibitory feedback as a mechanism to 'toggle' between oscillatory and non-oscillatory firing states, each associated with a naturalistic stimulus.},
	number = {6922},
	journal = {Nature},
	author = {Doiron, B and Chacron, Mj and Maler, L and Longtin, A and Bastian, J},
	month = jan,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {539--543},
}

@article{bullier_parallel_1995,
	title = {Parallel versus serial processing: new vistas on the distributed organization of the visual system},
	volume = {5},
	abstract = {Recent functional studies question the validity of the hierarchical model of organization for processing visual information in cortical areas. The results of these studies suggest that beyond the primary visual cortex (V1), information is not serially processed through successive cortical areas, but that it is simultaneously processed in several areas. The idea that visual information is functionally segregated into different, parallel channels as it circulates through V1 and V2 towards V4 and the middle temporal visual area is also challenged by recent studies that report a smaller degree of functional specialization within the visual areas than previously thought.},
	number = {4},
	journal = {Curr. Opin. Neurobiol.},
	author = {Bullier, J and Nowak, Lg},
	month = aug,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {497--503},
}

@article{lisberger_responses_1994,
	title = {Responses during eye movements of brain stem neurons that receive monosynaptic inhibition from the flocculus and ventral paraflocculus in monkeys},
	volume = {72},
	abstract = {1. We have identified a group of brain stem cells called “flocculus target neurons” (or FTNs) because they are inhibited at monosynaptic latencies by stimulation of the flocculus and the ventral paraflocculus with single electrical pulses. We report the responses of FTNs, as well as those of other brain stem cells, during horizontal eye movements with the head stationary and during natural vestibular stimulation in monkeys. 2. FTNs discharged primarily in relation to eye movements. The majority (71\%) showed increased firing for eye movement away from the side of the recording (“contraversive”), which is consistent with their inhibition by Purkinje cells that show increased firing for eye movement toward the side of recording. However, a significant and surprisingly large percentage (29\%) of FTNs showed increased firing for eye movement toward the side of recording (“ipsiversive”). 3. The firing rate of FTNs showed strong modulation during pursuit of sinusoidal target motion with the head stationary and during the compensatory eye movements evoked by fixation of an earth-stationary target with sinusoidal head rotation. In addition, firing rate was related to eye position during steady fixation at different positions. Of the FTNs that showed increased firing for contraversive eye motion during pursuit with the head stationary, most had an infection in the relationship between firing rate and eye position so that the sensitivity to eye position was low for eye positions ipsilateral to straight-ahead gaze and high for eye positions contralateral to straight-ahead gaze. 4. When the monkey canceled the vestibuloocular reflex (VOR) by tracking a target that moved exactly with him during sinusoidal head rotation, the firing rate of FTNs was modulated much less strongly than during pursuit with the head stationary. In the FTNs that showed increased firing for contraversive eye motion during pursuit, firing rate during cancellation of the VOR increased for contraversive head motion during sinusoidal vestibular rotation at 0.4 Hz but was only weakly modulated during rotation at 0.2 Hz. 5. The position-vestibular-pause cells (PVP-cells), previously identified as interneurons in the disynaptic VOR pathways, were not inhibited by stimulation of the flocculus and ventral paraflocculus and had response properties that were different from FTNs. The majority (69\%) showed increased firing for contraversive eye motion during pursuit and for ipsiversive head motion during cancellation of the VOR, whereas some (31\%) showed the opposite direction preferences under both conditions.(ABSTRACT TRUNCATED AT 250 WORDS)},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Lisberger, Sg and Pavelko, Ta and Broussard, Dm},
	month = aug,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {909--927},
}

@article{lisberger_neural_1994,
	title = {Neural basis for motor learning in the vestibuloocular reflex of primates. {I}. {Changes} in the responses of brain stem neurons},
	volume = {72},
	abstract = {1. We recorded from neurons in the brain stem of monkeys before and after they had worn magnifying or miniaturizing spectacles to cause changes in the gain of the vestibuloocular reflex (VOR). The gain of the VOR was estimated as eye speed divided by head speed during passive horizontal head rotation in darkness. Electrical stimulation in the cerebellum was used to identify neurons that receive inhibition at monosynaptic latencies from the flocculus and ventral paraflocculus (flocculus target neurons or FTNs). Cells were studied during smooth pursuit eye movements with the head stationary, fixation of different positions, cancellation of the VOR, and the VOR evoked by rapid changes in head velocity. 2. FTNs were divided into two populations according to their responses during pursuit with the head stationary. The two groups showed increased firing during smooth eye motion toward the side of recording (Eye-ipsiversive or E-i) or away from the side of recording (Eye-contraversive or E-c). A higher percentage of FTNs showed increased firing rate for contraversive pursuit when the gain of the VOR was high ({\textgreater} or = 1.6) than when the gain of the VOR was low ({\textless} or = 0.4). 3. Changes in the gain of the VOR had a striking effect on the responses during the VOR for the FTNs that were E-c during pursuit with the head stationary. Firing rate increased during contraversive VOR eye movements when the gain of the VOR was high or normal and decreased during contraversive VOR eye movements when the gain of the VOR was low. Changes in the gain of the VOR caused smaller changes in the responses during the VOR of FTNs that were E-i during pursuit with the head stationary. We argue that motor learning in the VOR is the result of changes in the responses of individual FTNs. 4. The responses of E-i and E-c FTNS during cancellation of the VOR depended on the gain of the VOR. Responses tended to be in phase with contraversive head motion when the gain of the VOR was low and in phase with ipsiversive head motion when the gain of the VOR was high. Comparison of the effect of motor learning on the responses of FTNs during cancellation of the VOR with the results of similar experiments on horizontal-gaze velocity Purkinje cells in the flocculus and ventral paraflocculus suggests that the brain stem vestibular inputs to FTNs are one site of motor learning in the VOR.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Lisberger, Sg and Pavelko, Ta and Broussard, Dm},
	month = aug,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {928--953},
}

@article{lisberger_neural_1994-1,
	title = {Neural basis for motor learning in the vestibuloocular reflex of primates. {II}. {Changes} in the responses of horizontal gaze velocity {Purkinje} cells in the cerebellar flocculus and ventral paraflocculus},
	volume = {72},
	abstract = {1. We made extracellular recordings from Purkinje cells in the flocculus and ventral paraflocculus of awake monkeys before and after motor learning in the vestibuloocular reflex (VOR). Three samples were recorded 1) after miniaturizing spectacles had reduced the gain of the VOR (eye speed divided by head speed) to 0.4; 2) when the gain of the VOR was near 1.0; and 3) after magnifying spectacles had increased the gain of the VOR to 1.6. 2. We studied Purkinje cells that showed stronger modulation of simple-spike firing rate during horizontal than during vertical pursuit. These cells corresponded to the previously identified “horizontal gaze velocity Purkinje cells” or HGVP-cells. During pursuit of smooth target motion with the head stationary, HGVP-cells showed strong modulation of firing rate with increases for ipsiversive eye motion (toward the side of recording). When the monkey canceled his VOR by tracking a target that moved exactly with him during sinusoidal head rotation in the horizontal plane, HGVP-cells again showed strong modulation of firing rate with increases for ipsiversive head motion. 3. The responses of HGVP-cells during pursuit with the head stationary and during cancellation of the VOR reveal separate components of firing rate related to eye and head velocity. We used these two behavioral conditions to test for effects of motor learning on the head and eye velocity components of the simple-spike firing of HGVP-cells. Our data confirm the previous observation that motor learning causes the sensitivity to head velocity to be larger when the gain of the VOR is high and smaller when the gain of the VOR is low. Thus we agree with the previous conclusion that changes in the vestibular sensitivity of HGVP-cells, measured during sinusoidal head motion at low frequencies, are in the wrong direction to cause changes in the gain of the VOR. 4. To determine whether the simple-spike output from the HGVP-cells plays a role in the VOR after motor learning, we recorded simple-spike firing during the VOR evoked by transient, rapid changes in head velocity in darkness. When the gain of the VOR was low, firing rate increased during the VOR evoked by ipsiversive head motion and decreased during the VOR evoked by contraversive head motion. When the gain of the VOR was high, the direction selectivity of the responses was reversed.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Lisberger, Sg and Pavelko, Ta and Stewart, Bronte-Hm and Stone, Ls},
	month = aug,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {954--973},
}

@article{hochstein_view_2002,
	title = {View from the top: hierarchies and reverse hierarchies in the visual system},
	volume = {36},
	abstract = {We propose that explicit vision advances in reverse hierarchical direction, as shown for perceptual learning. Processing along the feedforward hierarchy of areas, leading to increasingly complex representations, is automatic and implicit, while conscious perception begins at the hierarchy's top, gradually returning downward as needed. Thus, our initial conscious percept–vision at a glance–matches a high-level, generalized, categorical scene interpretation, identifying “forest before trees.” For later vision with scrutiny, reverse hierarchy routines focus attention to specific, active, low-level units, incorporating into conscious perception detailed information available there. Reverse Hierarchy Theory dissociates between early explicit perception and implicit low-level vision, explaining a variety of phenomena. Feature search “pop-out” is attributed to high areas, where large receptive fields underlie spread attention detecting categorical differences. Search for conjunctions or fine discriminations depends on reentry to low-level specific receptive fields using serial focused attention, consistent with recently reported primary visual cortex effects.},
	number = {5},
	journal = {Neuron},
	author = {Hochstein, S and Ahissar, M},
	month = dec,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {791--804},
}

@article{czubayko_fast_2002,
	title = {Fast synaptic transmission between striatal spiny projection neurons},
	volume = {99},
	abstract = {Striatal inhibition plays an important role in models of cortex-basal ganglia function and is altered in many basal ganglia diseases. The gamma-aminobutyric acid ergic spiny projection neuron comprises {\textgreater}95\% of striatal neurons, but despite strong anatomical evidence, the electrophysiological properties and functions of their local axon collaterals are unknown. We simultaneously recorded from adjacent spiny projection neurons (14 Hz and showed considerable short-term plasticity, including paired-pulse depression at intervals {\textless}25 ms, intraburst facilitation, and interburst augmentation. This activity-dependent collateral interaction provides the basis for a new class of basal ganglia models in which striatal neurons cooperate as well as compete during processing of cortical inputs.},
	number = {24},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Czubayko, U and Plenz, D},
	month = nov,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {15764--15769},
}

@article{royer_conservation_2003,
	title = {Conservation of total synaptic weight through balanced synaptic depression and potentiation},
	volume = {422},
	abstract = {Memory is believed to depend on activity-dependent changes in the strength of synapses. In part, this view is based on evidence that the efficacy of synapses can be enhanced or depressed depending on the timing of pre- and postsynaptic activity. However, when such plastic synapses are incorporated into neural network models, stability problems may develop because the potentiation or depression of synapses increases the likelihood that they will be further strengthened or weakened. Here we report biological evidence for a homeostatic mechanism that reconciles the apparently opposite requirements of plasticity and stability. We show that, in intercalated neurons of the amygdala, activity-dependent potentiation or depression of particular glutamatergic inputs leads to opposite changes in the strength of inputs ending at other dendritic sites. As a result, little change in total synaptic weight occurs, even though the relative strength of inputs is modified. Furthermore, hetero- but not homosynaptic alterations are blocked by intracellular dialysis of drugs that prevent Ca(2+) release from intracellular stores. Thus, in intercalated neurons at least, inverse heterosynaptic plasticity tends to compensate for homosynaptic long-term potentiation and depression, thus stabilizing total synaptic weight.},
	number = {6931},
	journal = {Nature},
	author = {Royer, S and Pare, D},
	month = apr,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {518--522},
}

@article{bolshakov_notitle_1995,
	volume = {269},
	abstract = {Developmental changes in rat hippocampal transmitter release and synaptic plasticity were investigated. Recordings from pairs of pyramidal neurons in slices showed that an action potential in a CA3 neuron released only a single quantum of transmitter onto a CA1 neuron. Failures of synaptic transmission reflected probabilistic transmitter release. The probability of release (Pr) was 0.9 in 4- to 8-day-old rats and decreased to less than 0.5 at 2 to 3 weeks. Long-term potentiation (LTP) in 2- to 3-week-old rats was associated with an increase in Pr from a single synaptic site. The high initial Pr in 4- to 8-day-old rats normally occludes the expression of LTP at this stage.},
	number = {5231},
	journal = {Science},
	author = {Bolshakov, Vadim Y and Siegelbaum, Steven A},
	month = sep,
	year = {1995},
	keywords = {hippocampus, merged\_fiete.bib, CA1, LTP, CA3, quantal analysis},
	pages = {1730--1734},
}

@article{poggio_mechanisms_1995,
	title = {Mechanisms of {Stereopsis} in {Monkey} {Visual} {Cortex}},
	volume = {3},
	abstract = {A substantial proportion of neurons in the striate and prestriate cortex of monkeys have stereoscopic properties; that is, they respond differentially to binocular stimuli that are known in humans to provide cues for stereoscopic depth perception. Stereoscopic neurons, as these cells may be called, are selective for horizontal positional disparity (i.e., display disparity selectivity) and for the textural correlation between images over their receptive fields (i.e., they show correlation selectivity). Many neurons have tuned disparity response profiles that collectively cover the entire range of physiological disparities. Neurons with peak responses at or about the zero disparity (“tuned zero neurons,” excitatory or inhibitory) have narrow and symmetrical profiles. Neurons that are tuned to larger disparities, either crossed (“tuned near neurons”) or uncrossed (“tuned far neurons”), have broader excitatory profiles that are asymmetrically wider toward the smaller disparities, and commonly include an inhibitory component about the zero disparity. Other stereoscopic neurons have reciprocal profiles (“near” or “far” neurons, respectively) in the sense that they respond with excitation to crossed or uncrossed disparities, and with suppression to disparities of opposite sign. Stereoscopic neurons can also signal the textural correlation between paired retinal images by giving different responses to random-dot patterns that have, and to those that do not have, the same dot distribution over the neuron's left and right receptive fields. Tuned-zero excitatory neurons characteristically respond to uncorrelation with suppression; tuned-zero inhibitory neurons, with excitation; and both types give the opposite responses to correlated stereopatterns. Neurons selective for nonzero disparities, both tuned and reciprocal, also give excitatory responses to uncorrelated stimuli, but these responses are smaller and more variable than those evoked by correlated patterns at the effective disparities. These findings suggest that stereoscopic neurons in the visual cortex of the macaque comprise three operational systems: (1) a zero-disparity system that is involved in fine depth discrimination with the obligatory singleness of vision, and the maintenance of vergence; and (2) a near-, and (3) a far-disparity system that together signal qualitative estimates of depth with double vision, and vergence responses to large disparities.},
	number = {3},
	journal = {Cereb. Cortex},
	author = {Poggio, Gian E},
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {193--204},
}

@article{parker_cortical_2001,
	title = {Cortical mechanisms of binocular stereoscopic vision},
	volume = {134},
	abstract = {The early neurophysiology of binocular vision is largely dominated by measurements of disparity selectivity in cortical neurons in various visual areas. Incisive progress has been made by the intensive study of the mechanism of disparity selectivity of V1 in cortical neurons and the development of a number of tests for the involvement of single neurons in the perception of stereoscopic depth. The picture that now emerges is that cortical area V1 must be a preliminary processing stage for the analysis of stereoscopic depth, whereas some of the extrastriate areas may actually be responsible for the generation of neuronal signals that underlie the perception of binocular depth.},
	journal = {Prog. Brain Res.},
	author = {Parker, A J and Cumming, B G},
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {205--216},
}

@article{leigh_effect_1989,
	title = {Effect of {Monocular} {Visual} {Loss} upon {Stability} of {Gaze}},
	volume = {30},
	abstract = {Using the eye-coil/magnetic field method, we measured horizontal and vertical movements of both eyes in four patients with monocular loss of vision while they attempted steady, binocular fixation of a visual target. We also measured gaze stability in two normal subjects while they fixed upon a target monocularly, and in one patient with congenital, bilateral blindness. In the patients with monocular visual loss, gaze instability was greater in the blind eye, both vertically and horizontally, compared either with their seeing eye or with nonviewing eyes of control subjects. Gaze instability due to monocular blindness resulted from: (1) low-frequency, low-amplitude, bidirectional drifts that were more prominent vertically; and (2) unidirectional drifts, with nystagmus, that were more prominent in the horizontal plane. Gaze-evoked nystagmus, however, was not a feature of monocular blindness. Thus, the gaze instability of monocular blindness may reflect disruption of: (1) a monocular visual stabilization system; (2) fusional vergence mechanisms; or (3) both. In contrast, bilateral congenital blindness led to nystagmus with horizontal and vertical components and a wandering null point, indicative of an abnormal neural integrator.},
	number = {2},
	journal = {Invest. Ophthalmol. Vis. Sci.},
	author = {Leigh, R John and Thurston, Stephen E and Tomsak, Robert L and Grossman, Gerald E and Lanska, Douglas J},
	month = feb,
	year = {1989},
	keywords = {merged\_fiete.bib},
	pages = {288--292},
}

@article{kramer_short-term_1995,
	title = {Short-term adaptation of the phase of the vestibulo-ocular reflex ({VOR}) in normal human subjects},
	volume = {106},
	abstract = {We investigated the effects of short-term vestibulo-ocular reflex (VOR) adaptation on the gain and phase of the VOR, and on eccentric gaze-holding in darkness, in five normal human subjects. For 1 h, subjects sat in a chair that rotated sinusoidally at 0.2 Hz while surrounded by a visual stimulus (optokinetic drum). The drum was rotated relative to the chair, to require a VOR with either a phase lead or lag of 45 deg (with respect to a compensatory phase of zero) with no change in gain, or a gain of 1.7 or 0.5 with no change in phase. Immediately before and after each training session, VOR gain and phase were measured in the dark with 0.2 Hz sinusoidal rotation. Gaze-holding was evaluated following 20 deg eccentric saccades in darkness. Adaptation paradigms that called only for a phase lead produced an adapted VOR with 33\% of the required amount of phase change, a 20\% decrease in VOR gain, and an increased centripetal drift after eccentric saccades made in darkness. Adaptation paradigms that called for a phase lag produced an adapted VOR with 29\% of the required amount of phase change, no significant change in VOR gain, and a centrifugal drift after eccentric saccades. Adaptation paradigms requiring a gain of 1.7 produced a 15\% increase in VOR gain with small increases in phase and in centripetal drift. Adaptation paradigms requiring a gain of 0.5 produced a 31\% decrease in VOR gain with a 6 deg phase lag and a centrifugal drift. The changes in drift and phase were well correlated across all adaptation paradigms; the changes in phase and gain were not. We attribute the effects on phase and gaze-holding to changes in the time constant of the velocity-to-position ocular motor neural integrator. Phase leads and the corresponding centripetal drift are due to a leaky integrator, and phase lags and the corresponding centrifugal drift are due to an unstable integrator. These results imply that in the short-term adaptation paradigm used here, the control of drift and VOR phase are tightly coupled through the neural integrator, whereas VOR gain is controlled by another mechanism.},
	number = {2},
	journal = {Exp. Brain Res.},
	author = {Kramer, Phillip D and Shelhamer, Mark and Zee, David S},
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {318--326},
}

@article{feller_presynaptic_1996,
	title = {Presynaptic {Calcium} {Dynamics} at the {Frog} {Retinotectal} {Synapse}},
	volume = {76},
	abstract = {1. We characterized the kinetics of presynaptic Ca2+ ion concentration in optic nerve fibers and terminals of the optic tectum in Rana pipiens with the use of microfluorimetry. Isolated frog brains were incubated with the membrane-permeant tetraacetoxymethyl ester (AM) of the Ca2+ indicator fura-2. An optic nerve shock caused a transient decrease in the 380-nm excited fluorescence in the optic tectum with a rise time of {\textless}15 ms and a recovery to prestimulus levels on a time scale of seconds. 2. In normal saline, the amplitude of the fluorescence transients was dependent on stimulus intensity and at all levels it was directly correlated with the amplitude of postsynaptic field potentials produced by activation of unmyelinated optic nerve fibers. In the presence of the non-N-methyl-D-aspartate glutamate receptor antagonist 6-cyano-7-nitroquinoxaline-2,3-dione, the amplitude and time course of fluorescence transients remained essentially unchanged while postsynaptic field potential amplitude was greatly reduced. Replacing extracellular Ca2+ with Ba2+ blocked unfacilitated postsynaptic field potentials while fluorescence transients remained significant. In reduced-Ca2+ salines ({\textless}1 mM), the amplitude of fluorescence transients increased approximately linearly with extracellular [Ca2+], whereas the amplitude the corresponding field potential was nonlinearly related to the fluorescent transient amplitude (approximately 2.5 power). In thin sections of labeled tecta, fluorescence labeling was localized to 1-micron puncta in the termination zone of optic nerve fibers in the superficial layers. Taken together, these results provide strong evidence that the fluorescence transients correspond to an increase in Ca2+ in presynaptic terminals of unmyelinated optic nerve fibers. 3. During trains of optic nerve stimulation, the amplitude of fluorescence transients to succeeding action potentials became smaller. The decrement of the amplitudes was not observed in mag-fura-5-labeled tecta, when the intracellular Ca2+ buffering capacity of fura-2-labeled terminals was increased by incubation with bis-(o-aminophenoxy)-N,N,N',N'-tetraacetic acid (BAPTA)-AM or ethylene glycol-bis (beta-aminoethyl ether)-N,N,N',N'-tetraacetic acid (EGTA)-AM, or in low-Ca2+ saline. We conclude that the Ca2+ influx per action potential is constant during the train and that the reduced response was produced by saturation of the fura-2. We provide a mathematical analysis of this saturation effect and use it to estimate the Ca2+ change per action potential. 4. Both BAPTA-AM and EGTA-AM reduced the overall amplitude of fura-2-measured Ca2+ transients and reduced the saturation effect in action potential trains. However, there was a qualitative difference in their effects on the shape of the transient. Incubation with the fast buffer BAPTA prolonged the decay to baseline. In contrast, the slow buffer EGTA (or EDTA) produced an initial decay faster than the control condition while also producing the slower subsequent phase observed with BAPTA. We demonstrate that these results are consistent with numerical simulations of Ca2+ dynamics in a single-compartment model where the fast initial decay is produced by the forward rate of Ca2+ binding to EGTA. 5. Ca2+ influx into tectal presynaptic structures, and also into unmyelinated axons in the isolated optic nerve, was diminished (60-70\%) in the presence of the voltage-activated Ca2+ channel blocker omega-conotoxin GVIA, but was only weakly affected (approximately 10\%) by omega-agatoxin IVA. 6. After 10- to 50-Hz stimulus trains, synaptic enhancement of unmyelinated fibers decayed with a characteristic time similar to fura-2 fluorescence decays. Incubation with EDTA-AM or EGTA-AM produced little effect on evoked release but reduced both the amplitude of the fura-2-measured Ca2+ transient and the amplitude of short-term synaptic enhancement.},
	number = {1},
	journal = {J. Neurophysiol.},
	author = {Feller, Marla B and Delaney, Kerry R and Tank, David W},
	month = jul,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {381--400},
}

@article{erisir_function_1999,
	title = {Function of specific {K}(+) channels in sustained high-frequency firing of fast-spiking neocortical interneurons},
	volume = {82},
	abstract = {Fast-spiking GABAergic interneurons of the neocortex and hippocampus fire high-frequency trains of brief action potentials with little spike-frequency adaptation. How these striking properties arise is unclear, although recent evidence suggests K(+) channels containing Kv3.1-Kv3.2 proteins play an important role. We investigated the role of these channels in the firing properties of fast-spiking neocortical interneurons from mouse somatosensory cortex using a pharmacological and modeling approach. Low tetraethylammonium (TEA) concentrations ({\textless}/=1 mM), which block only a few known K(+) channels including Kv3.1-Kv3.2, profoundly impaired action potential repolarization and high-frequency firing. Analysis of the spike trains evoked by steady depolarization revealed that, although TEA had little effect on the initial firing rate, it strongly reduced firing frequency later in the trains. These effects appeared to be specific to Kv3.1 and Kv3.2 channels, because blockade of dendrotoxin-sensitive Kv1 channels and BK Ca(2+)-activated K(+) channels, which also have high TEA sensitivity, produced opposite or no effects. Voltage-clamp experiments confirmed the presence of a Kv3.1-Kv3.2-like current in fast-spiking neurons, but not in other interneurons. Analysis of spike shape changes during the spike trains suggested that Na(+) channel inactivation plays a significant role in the firing-rate slowdown produced by TEA, a conclusion that was supported by computer simulations. These findings indicate that the unique properties of Kv3.1-Kv3.2 channels enable sustained high-frequency firing by facilitating the recovery of Na(+) channel inactivation and by minimizing the duration of the afterhyperpolarization in neocortical interneurons.},
	number = {5},
	journal = {J. Neurophysiol.},
	author = {Erisir, A and Lau, D and Rudy, B and Leonard, Cs},
	month = nov,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {2476--2489},
}

@article{schultz_predictive_1998,
	title = {Predictive {Reward} {Signal} of {Dopamine} {Neurons}},
	volume = {80},
	abstract = {The effects of lesions, receptor blocking, electrical self-stimulation, and drugs of abuse suggest that midbrain dopamine systems are involved in processing reward information and learning approach behavior. Most dopamine neurons show phasic activations after primary liquid and food rewards and conditioned, reward-predicting visual and auditory stimuli. They show biphasic, activation-depression responses after stimuli that resemble reward-predicting stimuli or are novel or particularly salient. However, only few phasic activations follow aversive stimuli. Thus dopamine neurons label environmental stimuli with appetitive value, predict and detect rewards and signal alerting and motivating events. By failing to discriminate between different rewards, dopamine neurons appear to emit an alerting message about the surprising presence or absence of rewards. All responses to rewards and reward-predicting stimuli depend on event predictability. Dopamine neurons are activated by rewarding events that are better than predicted, remain uninfluenced by events that are as good as predicted, and are depressed by events that are worse than predicted. By signaling rewards according to a prediction error, dopamine responses have the formal characteristics of a teaching signal postulated by reinforcement learning theories. Dopamine responses transfer during learning from primary rewards to reward-predicting stimuli. This may contribute to neuronal mechanisms underlying the retrograde action of rewards, one of the main puzzles in reinforcement learning. The impulse response releases a short pulse of dopamine onto many dendrites, thus broadcasting a rather global reinforcement signal to postsynaptic neurons. This signal may improve approach behavior by providing advance reward information before the behavior occurs, and may contribute to learning by modifying synaptic transmission. The dopamine reward signal is supplemented by activity in neurons in striatum, frontal cortex, and amygdala, which process specific reward information but do not emit a global reward prediction error signal. A cooperation between the different reward signals may assure the use of specific rewards for selectively reinforcing behaviors. Among the other projection systems, noradrenaline neurons predominantly serve attentional mechanisms and nucleus basalis neurons code rewards heterogeneously. Cerebellar climbing fibers signal errors in motor performance or errors in the prediction of aversive events to cerebellar Purkinje cells. Most deficits following dopamine-depleting lesions are not easily explained by a defective reward signal but may reflect the absence of a general enabling function of tonic levels of extracellular dopamine. Thus dopamine systems may have two functions, the phasic transmission of reward information and the tonic enabling of postsynaptic neurons.},
	number = {1},
	journal = {J. Neurophysiol.},
	author = {Schultz, Wolfram},
	month = jul,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {1--27},
}

@article{steege_operant_1982,
	title = {Operant conditioning of single unit activity in parietal cortex},
	volume = {231},
	abstract = {Two rhesus monkeys were trained to control firing patterns of single neurons in parietal cortex (areas 1, 2, 3, 5, 7) using an operant task previously applied to the study of precentral units. Twenty-four of 56 (43\%) postcentral cells were controlled in contrast to 71 of 136 (52\%) precentral units from these and 4 other rhesus monkeys. In addition, monkeys were able to drive precentral units to more sustained tonic firing rates than they could parietal units. An analysis of interspike interval (ISI) distributions showed that, in contrast to precentral units with modal ISIs of 25-50 ms, 50\% of parietal units have modal ISIs of 2 ms. Such short ISIs may account for fewer postcentral units reaching control criteria for this particular operant task. Other factors that may contribute to the reduced control of postcentral cells are discussed, particularly the more complex afferent connections to parietal units when compared to precentral pyramidal tract neurons. The data indirectly support conclusions from previous studies that imply that operant control of cortical units is peripherally mediated and does not primarily involve a 'central' or 'open loop' system.},
	number = {2},
	journal = {Brain Res.},
	author = {Steege, Td and Robbins, Ca and Wyler, Ar},
	month = jan,
	year = {1982},
	keywords = {merged\_fiete.bib},
	pages = {309--24.},
}

@article{pastor_eye_1994,
	title = {Eye position and eye velocity integrators reside in separate brainstem nuclei},
	volume = {91},
	abstract = {Two types of central nervous system integrators are critical for oculomotor performance. The first integrates velocity commands to create position signals that hold fixation of the eye. The second stores relative velocity of the head and visual surround to stabilize gaze both during and after the occurrence of continuous self and world motion. We have used recordings from single neurons to establish that the “position” and “velocity” integrators for horizontal eye movement occupy adjacent, but nonoverlapping, locations in the goldfish medulla. Lidocaine inactivation of each integrator results in the eye movement deficits expected if horizontal eye position and velocity signals are processed separately. These observations also indicate that each brainstem compartment generates and stores these signals. Consequently, each integrator exhibits functional autonomy. Therefore, we propose that the intrinsic electrophysiological properties of the constituent neurons in each brainstem subnucleus may be sufficient for producing integrator rhythmicity.},
	number = {2},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Pastor, Am and Cruz, La De Rr and Baker, R},
	month = jan,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {807--11.},
}

@article{stein_cellular_1989,
	title = {Cellular investigations of behavioral reinforcement},
	volume = {13},
	abstract = {Using the hippocampal-slice preparation, we attempted to demonstrate operant conditioning of pyramidal cell activity using local micropressure applications of transmitters and drugs as reinforcement; the same injections administered independently of bursting provided a control for direct pharmacological stimulation or facilitation of firing. The results suggested that the spontaneous bursting of individual CA1 pyramidal neurons may be reinforced with activity-contingent injections of dopamine and cocaine, whereas, CA3-bursting responses may be reinforced with contingently-applied dynorphin A. We sought to confirm these indications of cellular reinforcement at the behavioral level in studies of hippocampal self-administration (despite the fact that the hippocampus has been ignored as a brain site for chemical self-administration experiments). The results suggested that dynorphin A is a powerful reinforcer of hippocampal self-administration behavior when injected in the CA3 field; experiments still in progress suggest that dopamine can reinforce self-administration behavior when injected in the CA1 field. Successful prediction of new behavioral data from operant-conditioning data at the cellular level helps to validate the cellular data by providing suggestive evidence of interrelationship between cellular and behavioral operant conditioning processes.},
	number = {2-3},
	journal = {Neurosci. Biobehav. Rev.},
	author = {Stein, L and Belluzzi, Jd},
	year = {1989},
	keywords = {merged\_fiete.bib},
	pages = {69--80.},
}

@article{milner_brain-stimulation_1991,
	title = {Brain-stimulation reward: a review},
	volume = {45},
	abstract = {During most of the first half of this century psychologists knew what they wanted to do but had no idea how to do it, and during the second half they have, for the most part, been so preoccupied with how to do it that they have forgotten what they wanted to do. When J. Olds and Milner (1954) announced that rats would stimulate themselves in the septal area, it appeared to open the door to understanding motivation and reinforcement in terms of the underlying physiology. In the ensuing 36 years some progress has been made in that direction, though far outstripped by the progress in methodology. In this review I trace the efforts that have been made to locate the structures involved in self-stimulation by lesions, drugs, determinations of their neurophysiological characteristics, and other more sophisticated methods. I then review experiments, none very recent, comparing brain-stimulation reward to natural rewards and finally indicate how the information so far collected may be incorporated into theories of learning and motivation.},
	number = {1},
	journal = {Can. J. Psychol.},
	author = {Milner, Pm},
	month = mar,
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {1--36.},
}

@article{nottebohm_brain_1981,
	title = {Brain space for a learned task},
	volume = {213},
	abstract = {Forty-six adult male and female canaries were sacrificed, their brains were weighed and the volume of several brain nuclei reconstructed from the cresyl violet-stained material. Two forebrain vocal control nuclei, hyperstriatum ventrale, pars caudale (HVc) and nucleus robustus archistriatalis (RA), were approximately 4 and 3 times larger, respectively, in males than in females, confirming previous findings. There was no consistent right-left asymmetry in the volume of these nuclei in males and females. Twenty-five male birds in this study had their song repertoire recorded during the peak of the singing season. They were sacrificed 3 to 4 months later. The size of the song repertoire, measured as number of different syllable types, showed a positive and significant correlation with the size of HVc and RA. There was no significant correlation between size of the syllable repertoire and age, brain weight or the volume of two brain nuclei not involved in song control. This is the first time that the amount of brain allotted to a specific learned skill has been shown to correlate positively with the amount of that skill that is learned. Interestingly, too, there was a positive and significant correlation between testis weight at the end of the breeding season and the volume of RA at that time, suggesting a hormone-mediated seasonal modulation of part of the brain space occupied by song control pathways. This material seems well suited for studying the relation between space and learning, and the manner in which this relation is influenced by gonadal hormones.},
	number = {1},
	journal = {Brain Res.},
	author = {Nottebohm, F and Kasparian, S and Pandazis, C},
	month = may,
	year = {1981},
	keywords = {merged\_fiete.bib},
	pages = {99--109.},
}

@article{devoogd_relations_1993,
	title = {Relations between song repertoire size and the volume of brain nuclei related to song: comparative evolutionary analyses amongst oscine birds},
	volume = {254},
	abstract = {Song and brain structure are compared amongst 41 species of oscine birds by using the method of independent evolutionary contrasts. We find a significant correlation between the relative volume of the song control centre, the high vocal centre (HVC), and the number of song types typically found in the repertoire. Relative HVC volume is not correlated with the number of different syllable types per song bout. The relative volume of a second song nucleus, area X, is not significantly correlated with either measure. Relative HVC volume is uncorrelated with relative volume of the hippocampus, a brain area involved in other forms of memory. This is the first evidence for repeated independent evolution of an association between complexity of learned song and the relative volume of one of the song control nuclei though to be involved in song learning.},
	number = {1340},
	journal = {Proc. R. Soc. Lond. B Biol. Sci.},
	author = {Devoogd, T J and Krebs, J R and Healy, S D and Purvis, A},
	month = nov,
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {75--82.},
}

@article{ward_individual_1998,
	title = {Individual variation in neuron number predicts differences in the propensity for avian vocal imitation},
	volume = {95},
	abstract = {Avian song learning involves memorizing and reproducing song material produced by conspecifics. In several species song repertoire size correlates with the overall volume of two song-related brain regions, the HVc (acronym used as the proper name) and the robust nucleus of the archistriatum (RA). We raised male zebra finches with two adult tutors and found that individual differences in HVc volume and neuron number correlated positively with differences in the number of tutor syllables accurately copied. These results were replicated in a second study. The relationship between RA volume and song learning was similar, but less robust. Importantly, total repertoire size (number of song syllables) did not correlate significantly with anatomical measures of either the HVc or RA. Because previous work suggests that the volume and neuron number of these regions are not regulated by song learning, it is possible that naturally occurring variation in neuron number constrains how much song material can be copied or reproduced.},
	number = {3},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Ward, B C and Nordeen, E J and Nordeen, K W},
	month = feb,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {1277--82.},
}

@article{lewicki_mechanisms_1995,
	title = {Mechanisms underlying the sensitivity of songbird forebrain neurons to temporal order},
	volume = {92},
	abstract = {Neurons in the songbird forebrain area HVc (hyperstriatum ventrale pars caudale or high vocal center) are sensitive to the temporal structure of the bird's own song and are capable of integrating auditory information over a period of several hundred milliseconds. Extracellular studies have shown that the responses of some HVc neurons depend on the combination and temporal order of syllables from the bird's own song, but little is known about the mechanisms underlying these response properties. To investigate these mechanisms, we recorded intracellular responses to a set of auditory stimuli designed to assess the degree of dependence of the responses on temporal context. This report provides evidence that HVc neurons encode information about temporal structure by using a variety of mechanisms including syllable-specific inhibition, excitatory postsynaptic potentials with a range of different time courses, and burst-firing nonlinearity. The data suggest that the sensitivity of HVc neurons to temporal combinations of syllables results from the interactions of several cells and does not arise in a single step from afferent inputs alone.},
	number = {12},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Lewicki, Ms and Konishi, M},
	month = jun,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {5582--6.},
}

@article{margoliash_temporal_1992,
	title = {Temporal and harmonic combination-sensitive neurons in the zebra finch's {HVc}},
	volume = {12},
	abstract = {Song learning shapes the response properties of auditory neurons in the song system to become highly selective for the individual bird's own (“autogenous”) song. The auditory representation of autogenous song is achieved in part by neurons that exhibit facilitated responses to combinations of components of song. To understand the circuits that underlie these complex properties, the combination sensitivity of single units in the hyperstriatum ventrale, pars caudale (HVc) of urethane-anesthetized zebra finches was studied. Some neurons exhibited nonlinear temporal summation, spectral summation, or both. The majority of these neurons exhibited low spontaneous rates and phasic responses. Most combination-sensitive neurons required highly accurate copies of sounds derived from the autogenous song and responded weakly to tone bursts, combinations of simple stimuli, or conspecific songs. Temporal combination-sensitive (TCS) neurons required either two or more segments of a single syllable, or two or more syllables of the autogenous song, to elicit a facilitated, excitatory response. TCS neurons integrated auditory input over periods ranging from 80 to 350 msec, although this represents a lower limit. Harmonic combination-sensitive (HCS) neurons required combinations of two harmonics with particular frequency and temporal characteristics that were similar to autogenous song syllables. Both TCS and HCS neurons responded much more weakly when the dynamical spectral features of the autogenous song or syllables were modified than when the dynamical amplitude (waveform) features of the songs were modified. These results suggest that understanding the temporal dynamics of auditory responses in HVc may provide insight into neuronal circuits modified by song learning.},
	number = {11},
	journal = {J. Neurosci.},
	author = {Margoliash, D and Fortune, E S},
	month = nov,
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {4309--26.},
}

@article{margoliash_preference_1986,
	title = {Preference for autogenous song by auditory neurons in a song system nucleus of the white-crowned sparrow},
	volume = {6},
	abstract = {Neuronal activity in the hyperstriatum ventrale, pars caudale (HVc) is associated with and necessary for the production of song by songbirds. HVc neurons also respond to acoustic stimuli. The present investigation assessed the auditory response properties of neurons in HVc by testing with the individual bird's own (autogenous) song and the songs of conspecific birds. Throughout HVc, multiunit clusters preferentially responded to autogenous song. Selectivity for autogenous song was apparent even when compared to similar intradialect songs, and neuronal clusters preferred autogenous song over the (tutor) song model that birds heard during the impressionable phase early in life. The responses to autogenous song were stable in the adult. HVc neurons were sensitive to the acoustic parameters of autogenous song and consistently exhibited a diminished response to modified song. In contrast, field L neurons, which are presumed to be a source of auditory input to HVc, did not exhibit selectivity for autogenous song and showed no special sensitivity to the acoustic parameters of autogenous song. These observations implicate song (motor) learning in shaping the response properties of HVc, but not field L, auditory neurons. It is proposed that HVc auditory neurons may contribute to a bird's ability to discriminate among conspecific songs by acting as an “autogenous reference” during perception of those songs.},
	number = {6},
	journal = {J. Neurosci.},
	author = {Margoliash, D},
	month = jun,
	year = {1986},
	keywords = {merged\_fiete.bib},
	pages = {1643--61.},
}

@article{volman_development_1993,
	title = {Development of neural selectivity for birdsong during vocal learning},
	volume = {13},
	abstract = {Juvenile white-crowned sparrows learn to sing by first memorizing an adult's song and then progressively matching their vocalizations to this model during plastic song. Previous studies have shown that neurons in the song-system nucleus HVC of adult sparrows respond preferentially to a bird's own song. In this study, the auditory selectivity of HVC neurons in subadult birds was examined. In young, nonsinging birds who had been song tutored, these cells responded to song stimuli, and at some recording sites had distinct preferences for one song or another. As a population, however, HVC neurons in these birds showed no preference for familiar song. They were no more likely to prefer normal tutor song to reversed tutor song or to the song of another white-crowned subspecies. By contrast, in birds producing plastic song, HVC neurons were selective for the bird's own songs, even in preference to their tutor song. Therefore, during song learning the response properties of HVC neurons appear to be dynamically modified, perhaps by auditory feedback from the bird's own vocalizations. The emergence of song selectivity during plastic song may be significant both for song learning and for song perception in adult birds.},
	number = {11},
	journal = {J. Neurosci.},
	author = {Volman, Sf},
	month = nov,
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {4737--47.},
}

@article{brainard_auditory_2000,
	title = {Auditory feedback in learning and maintenance of vocal behaviour},
	volume = {1},
	abstract = {Songbirds are one of the best-studied examples of vocal learners. Learning of both human speech and birdsong depends on hearing. Once learned, adult song in many species remains unchanging, suggesting a reduced influence of sensory experience. Recent studies have revealed, however, that adult song is not always stable, extending our understanding of the mechanisms involved in song maintenance, and their similarity to those active during song learning. Here we review some of the processes that contribute to song learning and production, with an emphasis on the role of auditory feedback. We then consider some of the possible neural substrates involved in these processes, particularly basal ganglia circuitry. Although a thorough treatment of human speech is beyond the scope of this article, we point out similarities between speech and song learning, and ways in which studies of these disparate behaviours complement each other in developing an understanding of general principles that contribute to learning and maintenance of vocal behaviour.},
	number = {1},
	journal = {Nat. Rev. Neurosci.},
	author = {Brainard, M S and Doupe, A J},
	month = oct,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {31--40.},
}

@article{benardo_dopamine_1982,
	title = {Dopamine modulates a {Ca2}+ -activated potassium conductance in mammalian hippocampal pyramidal cells},
	volume = {297},
	abstract = {Dopamine (DA) is a neurotransmitter in the mammalian central nervous system which has proven or potential importance in such neurological disorders as parkinsonism, Huntington's chorea and epilepsy. Most of the electrophysiological data concerning the actions of DA in the brain have been obtained from studies in the caudate nucleus where DA produces neuronal depolarization and increased spike discharge, slow depolarization with decreased spike discharge and an increase in apparent input resistance and hyperpolarization with reduced firing rate. The mechanisms underlying these effects have not been examined. The evidence suggests that the hippocampus receives a dopaminergic projection and that DA inhibits most hippocampal neurones. We have studied the effects of DA on CA1 hippocampal pyramidal cells (HPCs) in vitro and report here that DA causes prolonged inhibition associated with hyperpolarization and increased conductance. These effects seem to derive from induction of a Ca2+ -activated K+ conductance, and would make DA effective in modulating the high frequency firing and burst generation which occurs normally in some neurones, and pathologically in HPCs during epileptogenesis.},
	number = {5861},
	journal = {Nature},
	author = {Benardo, L S and Prince, D A},
	month = may,
	year = {1982},
	keywords = {merged\_fiete.bib},
	pages = {76--79},
}

@article{scharff_comparative_1991,
	title = {A comparative study of the behavioral deficits following lesions of various parts of the zebra finch song system: implications for vocal learning},
	volume = {11},
	abstract = {Song production in song birds is controlled by an efferent pathway. Appended to this pathway is a “recursive loop” that is necessary for song acquisition but not for the production of learned song. Since zebra finches learn their song by imitating external models, we speculated that the importance of the recursive loop for learning might derive from its processing of auditory feedback during song acquisition. This hypothesis was tested by comparing the effects on song in birds deafened early in life and birds with early lesions in either of two nuclei–Area X and the lateral magnocellular nucleus of the anterior neostriatum (LMAN). These nuclei are part of the recursive loop. The three treatments affected song development differently, as reflected by various parameters of the adult song of these birds. Whereas LMAN lesions resulted in songs with monotonous repetitions of a single note complex, songs of Area X-lesioned birds consisted of rambling series of unusually long and variable notes. Furthermore, whereas song of LMAN lesioned birds stabilized early, song stability as seen in intact birds was never achieved in Area X-lesioned birds. Early deafness also resulted in poorly structured and unstable song. We conclude that Area X and LMAN contribute differently to song acquisition: the song variability that is typical of vocal development persists following early deafness or lesions of Area X but ends abruptly following removal of LMAN. Apparently, LMAN plays a crucial role in fostering the kinds of circuit plasticity necessary for learning.},
	number = {9},
	journal = {J. Neurosci.},
	author = {Scharff, C and Nottebohm, F},
	month = sep,
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {2896--913.},
}

@article{scharff_comparative_1991-1,
	title = {A {Comparative} {Study} of the {Behavioral} {Deficits} following {Lesions} of {Various} {Parts} of the {Zebra} {Finch} {Song} {System}: {Implications} for {Vocal} {Learning}},
	volume = {11},
	abstract = {Song production in song birds is controlled by an efferent pathway. Appended to this pathway is a “recursive loop” that is necessary for song acquisition but not for the production of learned song. Since zebra finches learn their song by imitating external models, we speculated that the importance of the recursive loop for learning might derive from its processing of auditory feedback during song acquisition. This hypothesis was tested by comparing the effects on song in birds deafened early in life and birds with early lesions in either of two nuclei–Area X and the lateral magnocellular nucleus of the anterior neostriatum (LMAN). These nuclei are part of the recursive loop. The three treatments affected song development differently, as reflected by various parameters of the adult song of these birds. Whereas LMAN lesions resulted in songs with monotonous repetitions of a single note complex, songs of Area X-lesioned birds consisted of rambling series of unusually long and variable notes. Furthermore, whereas song of LMAN lesioned birds stabilized early, song stability as seen in intact birds was never achieved in Area X-lesioned birds. Early deafness also resulted in poorly structured and unstable song. We conclude that Area X and LMAN contribute differently to song acquisition: the song variability that is typical of vocal development persists following early deafness or lesions of Area X but ends abruptly following removal of LMAN. Apparently, LMAN plays a crucial role in fostering the kinds of circuit plasticity necessary for learning.},
	number = {9},
	journal = {J. of Neuroscience},
	author = {Scharff, C and Nottebohm, F},
	month = sep,
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {2896--2913},
}

@article{herrmann_development_1991,
	title = {The development of afferent projections to the robust archistriatal nucleus in male zebra finches: a quantitative electron microscopic study},
	volume = {11},
	abstract = {Because the projections into the robust nucleus of the archistriatum (RA) are thought to play important roles in song learning and sexual differentiation of the zebra finch (Poephila guttata), quantitative electron microscopic techniques were used to measure the development of synaptic input to the neuropil of RA in this species. Two nuclei [hyperstriatum ventrale pars caudalis (HVc) and lateral magnocellular nucleus of the anterior neostriatum (IMAN)] that send projections to RA were lesioned at each of three different ages: 25 d after hatching, 53 d, and adulthood. In tissue from RA processed for conventional electron microscopy, lesion-induced degeneration was used to identify synapses from either HVc or IMAN. Axosomatic synapses were excluded from analysis. In control (unlesioned) animals, the density of synapses in neuropil increased slightly between days 28 and 56 and remained constant thereafter. Because of a large increase in the volume of RA, the total number of synapses in neuropil of RA tripled between days 28 and 56 and decreased significantly between day 56 and adulthood. The density and total number of synapses in neuropil originating from HVc increased significantly between days 25 and 53, but did not change significantly thereafter. In contrast, the density and total number of synapses from IMAN decreased significantly between days 25 and 53 and did not change thereafter. Presynaptic terminals from IMAN were larger than those from HVc. These data demonstrate that the most rapid phase of song learning is accompanied by a major rearrangement of synaptic contacts into RA that stem from HVc and IMAN.},
	number = {7},
	journal = {J. Neurosci.},
	author = {Herrmann, K and Arnold, A P},
	month = jul,
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {2063--74.},
}

@article{sakaguchi_developmental_1996,
	title = {Developmental changes in axon terminals visualized by immunofluorescence for the growth-associated protein, {GAP}-43, in the robust nucleus of the archistriatum of the zebra finch},
	volume = {95},
	abstract = {Two afferents to the robust nucleus of the archistriatum (RA) are important for song learning by the zebra finch. The growth-associated protein-43 (GAP-43) has been used as a molecular marker for axonal growth. In these experiments, the axon terminals were visualized by immunofluorescence with antibodies against GAP-43 and we studied the developmental processes in the zebra finch after the invasion of the RA by afferent fibers. After waiting at the dorsal border of the RA before invading the RA, the axon terminals from the higher vocal center (HVc) first contacted the soma, and then redistributed and established synapses on the dendrites. This initial contact with the soma may be closely related to the neurotrophic properties of the axon terminals from the HVc neurons.},
	number = {2},
	journal = {Brain Res. Dev. Brain Res.},
	author = {Sakaguchi, H and Saito, N},
	month = sep,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {245--51.},
}

@article{bottjer_forebrain_1984,
	title = {Forebrain lesions disrupt development but not maintenance of song in passerine birds},
	volume = {224},
	abstract = {The magnocellular nucleus of the anterior neostriatum is a forebrain nucleus of passerine birds that accumulates testosterone and makes monosynaptic connections with other telencephalic nuclei that control song production in adult birds. Lesions in the magnocellular nucleus disrupted song development in juvenile male zebra finches but did not affect maintenance of stable song patterns by adult birds. These results represent an instance in which lesions of a discrete brain region during only a restricted phase in the development of a learned behavior cause permanent impairment. Because cells of the magnocellular nucleus accumulate androgens these findings raise the possibility that this learning is mediated by hormones.},
	number = {4651},
	journal = {Science},
	author = {Bottjer, S W and Miesner, E A and Arnold, A P},
	month = may,
	year = {1984},
	keywords = {merged\_fiete.bib},
	pages = {901--3.},
}

@article{sakaguchi_developmental_1996-1,
	title = {Developmental changes in axon terminals visualized by immunofluorescence for the growth-associated protein, {GAP}-43, in the robust nucleus of the archistriatum of the zebra finch},
	volume = {95},
	abstract = {Two afferents to the robust nucleus of the archistriatum (RA) are important for song learning by the zebra finch. The growth-associated protein-43 (GAP-43) has been used as a molecular marker for axonal growth. In these experiments, the axon terminals were visualized by immunofluorescence with antibodies against GAP-43 and we studied the developmental processes in the zebra finch after the invasion of the RA by afferent fibers. After waiting at the dorsal border of the RA before invading the RA, the axon terminals from the higher vocal center (HVc) first contacted the soma, and then redistributed and established synapses on the dendrites. This initial contact with the soma may be closely related to the neurotrophic properties of the axon terminals from the HVc neurons.},
	number = {2},
	journal = {Brain Res. Dev. Brain Res.},
	author = {Sakaguchi, H and Saito, N},
	month = sep,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {245--51.},
}

@article{wilson_origins_1996,
	title = {The origins of two-state spontaneous membrane potential fluctuations of neostriatal spiny neurons},
	volume = {16},
	abstract = {In vivo intracellular recordings of spontaneous activity of neostriatal spiny cells revealed two-state behavior, i.e., characteristic shifts of membrane potential between two preferred levels. The more polarized level, called the Down state, varied among neurons from -61 to -94 mV. The more depolarized level, called the Up state, varied among neurons form -71 to -40 mV. For any one neuron, the membrane potential in the Up and Down states was constant over the period of observation (from 15 min to 4 hr), and the cells spent little time in transition between states. The level of membrane potential noise was higher in the Up state than in the Down state. Spontaneous membrane potential fluctuations were not abolished by experimental alteration of the membrane potential, but the time spent in each state was altered when intracellular current was used to vary the baseline membrane potential. Neither the sodium nor the calcium action potential that could be evoked by depolarization of spiny neurons was required for the occurrence of spontaneous shifts of membrane potential. Blockade of these action potentials using intracellular injection of QX314 and D890, respectively, altered neither the incidence of the membrane potential shifts nor the preferred membrane potential in either state. In contrast, antagonism of voltage-dependent potassium channels with intracellular cesium altered membrane potential shifts. In the presence of QX314 and D890, intracellular injection of cesium caused little or no change in the Down state and a large depolarizing shift in the Up state (to about -20 mV). Under these circumstances, the neuron responded to current in a nearly linear manner, and membrane conductance was found to be increased in the Up state, attributable to a membrane conductance with the same reversal potential as that of the synaptic potential evoked by cortical stimulation. These results indicate that the event underlying the Up state is a maintained barrage of synaptic excitation, but that the membrane potential achieved during the Up state in neostriatal spiny neurons is determined by dendritic potassium channels that clamp the membrane potential at a level determined by their voltage sensitivity. Neostriatal spiny neurons ordinarily receive enormously powerful excitation, which would drive the cells to saturation, and probably destroy them, if it were not for these potassium currents.},
	number = {7},
	journal = {J. Neurosci.},
	author = {Wilson, C J and Kawaguchi, Y},
	month = apr,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {2397--410.},
}

@article{nisenbaum_potassium_1995,
	title = {Potassium currents responsible for inward and outward rectification in rat neostriatal spiny projection neurons},
	volume = {15},
	abstract = {Many of the nonlinear membrane properties displayed by neostriatal spiny projection neurons are conferred by their voltage-gated potassium (K+) currents, including an inwardly rectifying current (IKir), fast (IAt), and slowly (IAs)-inactivating A-currents, and a slow, noninactivating current. The relative contribution of these K+ currents to the pronounced inward and outward rectification of the current-voltage (I-V) relationship of spiny neurons was investigated in a neostriatal slice preparation. Manipulation of the equilibrium potential for K+ (EK) showed that the voltage dependence of activation of inward rectification was identical to that of IKir. In addition, application of barium (100 microM), which is known to reduce IKir in a time- and voltage-dependent manner, had equivalent effects on inward rectification. Subsequent application of cesium (3 mM) or tetraethylammonium (TEA, 25 mM) blocked inward rectification in a solely voltage-dependent fashion consistent with the action of these blockers on IKir. Administration of 4-aminopyridine (4-AP, 100 microM) at concentrations that selectively depress IAs, reduced outward rectification of spiny neurons at subthreshold membrane potentials. Higher concentrations of 4-AP (2 mM), which block both IAs and IAt, revealed an early transient overshoot in voltage deflections at potentials near spike threshold, but rectification persisted at the end of the responses. The transient overshoot and the residual rectification were eliminated by TEA (25 mM), a blocker of the slow, noninactivating K+ current. Collectively, these results indicate that all three depolarization-activated K+ currents contribute to outward rectification at different times and membrane potentials defined by their voltage dependence of activation and kinetics of inactivation. The spontaneous activity of neostriatal spiny neurons recorded in intact animals is characterized by sustained and limited shifts in membrane potential from relatively hyperpolarized potentials to depolarized potentials near spike threshold. The present data suggest that the hyperpolarized state is determined principally by IKir and the limits on the depolarized state are defined by IAf, IAs, and the noninactivating current. These outward K+ currents also are hypothesized to govern the spike discharge characteristics once the depolarized state has been reached.},
	number = {6},
	journal = {J. Neurosci.},
	author = {Nisenbaum, Es and Wilson, Cj},
	month = jun,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {4449--63.},
}

@article{nisenbaum_contribution_1994,
	title = {Contribution of a slowly inactivating potassium current to the transition to firing of neostriatal spiny projection neurons},
	volume = {71},
	abstract = {1. Neostriatal spiny projection neurons display a prominent slowly depolarizing (ramp) potential and long latency to spike discharge in response to intracellular current pulses. The contribution of a slowly inactivating A-current (IAs) to this delayed excitation was investigated in a neostriatal slice preparation using current pulse protocols incorporating information based on the known voltage dependence, kinetics, and pharmacological properties of IAs. 2. Depolarizing intracellular current pulses evoked a slowly developing ramp potential that could last for seconds without reaching steady state and continued until either the pulse was terminated or spike threshold was reached. The slope of the ramp potential was dependent on the level of depolarization achieved by the membrane, and the apparent activation threshold for this ramp depolarization was approximately -65 mV. 3. Application of low concentrations of 4-aminopyridine (4-AP, 30-100 microM) or dendrotoxin (DTX, 30 nM), which are known to selectively block IAs, reduced both the slope of the ramp potential and the latency to first spike discharge. As has been described previously, blockade of inward Na+ and Ca2+ currents with tetrodotoxin (TTX, 1 microM) and cadmium (400 microM) also reduced the slope of the ramp depolarization. 4. A conditioning-test pulse protocol was used to examine the voltage dependence of inactivation of the ramp potential and long first spike latency. In the absence of a conditioning pulse, the test pulse evoked a slowly rising ramp potential and a spike with a long latency to discharge. A conditioning depolarization to approximately -60 mV decreased the slope of the ramp potential and the latency to first spike discharge evoked by the test pulse. A conditioning hyperpolarization to potentials below -100 mV, increased first spike latency. Application of a low concentration of 4-AP (100 microM) abolished the influence of prior membrane potential on the slope of the ramp depolarization and the latency to first spike discharge. 5. The kinetics of recovery from inactivation of the 4-AP-sensitive current were studied in the presence of TTX and cadmium by depolarizing cells to approximately -50 mV and then stepping to approximately -90 mV for increasing periods of time (0.5-5.0 s) before delivering a test pulse. The amplitude of the test pulse response decreased as a function of the hyperpolarizing step duration. When the test pulse response amplitudes were plotted against the hyperpolarizing step duration, the points reflected an exponential decay with an average time constant of 2.05 +/- 1.38 (SD) s.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {3},
	journal = {J. Neurophysiol.},
	author = {Nisenbaum, Es and Xu, Zc and Wilson, Cj},
	month = mar,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {1174--89.},
}

@article{beckers_pure-tone_2003,
	title = {Pure-tone birdsong by resonance filtering of harmonic overtones},
	volume = {100},
	abstract = {Pure-tone song is a common and widespread phenomenon in birds. The mechanistic origin of this type of phonation has been the subject of long-standing discussion. Currently, there are three hypotheses. (i) A vibrating valve in the avian vocal organ, the syrinx, generates a multifrequency harmonic source sound, which is filtered to a pure tone by a vocal tract filter (“source-filter” model, analogous to human speech production). (ii) Vocal tract resonances couple with a vibrating valve source, suppressing the normal production of harmonic overtones at this source (“soprano” model, analogous to human soprano singing). (iii) Pure-tone sound is produced as such by a sound-generating mechanism that is fundamentally different from a vibrating valve. Here we present direct evidence of a source-filter mechanism in the production of pure-tone birdsong. Using tracheal thermistors and air sac pressure cannulae, we recorded sound signals close to the syringeal sound source during spontaneous, pure-tone vocalizations of two species of turtledove. The results show that pure-tone dove vocalizations originate through filtering of a multifrequency harmonic sound source.},
	number = {12},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Beckers, G J and Suthers, R A and ten Cate, C},
	month = jun,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {7372--6. Epub 2003 May 22.},
}

@article{nowicki_vocal_nodate,
	title = {Vocal tract resonances in oscine bird sound production: evidence from birdsongs in a helium atmosphere},
	volume = {325},
	abstract = {The complexity and dependence on learning of many bird sounds have suggested parallels between birdsong and human speech, but the mechanisms by which each is produced have been supposed to differ markedly. In human speech, resonances of the vocal tract are thought to modulate in complex ways the sound produced by vibration of the vocal folds. The current theory of birdsong production holds that all variation in sound quality arises from the primary sound-producing organ, the syrinx, and that resonances of the vocal tract play no part. Here I present evidence, obtained from acoustic analyses of birdsongs recorded in a helium atmosphere, which contradicts this hypothesis. Not only does the songbird's vocal tract act as an acoustic filter, but its filter characteristics are actively coordinated with the output of the syrinx. Songbird and human phonation are thus more analogous than previously thought, in that both require coordination of an array of diverse motor systems.},
	number = {6099},
	journal = {Nature},
	author = {Nowicki, S},
	keywords = {merged\_fiete.bib},
	pages = {53--5.},
}

@article{canady_effect_1988,
	title = {Effect of testosterone on input received by an identified neuron type of the canary song system: {A} {Golgi}/electron microscopy/degeneration study},
	volume = {8},
	abstract = {Combinations of the Golgi stain, anterograde degeneration, and electron microscopy are used to further characterize the hormone-sensitive “type IV” neuron of the forebrain nucleus robustus archistriatalis (RA) of adult female canaries. Anterograde degeneration was used to “stain,” at the electron-microscopic level, the axon terminals of neurons projecting to RA from hyperstriatum ventralis, pars caudalis (HVc) and from the lateral magnocellular nucleus of the anterior neostriatum (L-MAN). The HVc neurons projecting to RA type IV cells form synapses predominantly on the dendritic spines of those cells, while L-MAN neurons that project to RA type IV cells form a 2.5:1 mixture of shaft and spine synapses. There were about 1000 synapses from HVc neurons (about 30\% of all spine synapses) on typical type IV cells and about 50 synapses from L-MAN neurons. Earlier work had shown that in female canaries the dendrites of type IV neurons of the avian song control nucleus RA increase in total length after systemic testosterone treatment, and that this increase in dendritic length was accompanied by the development of malelike song. We now show that testosterone treatment also increases the number of dendritic spines present in type IV neurons. Presumably this is accompanied by an increase in the number of synaptic inputs received by type IV cells. Earlier evidence suggested that the testosterone-induced addition of extra dendritic length to type IV cells occurred at existing dendritic tips. We tested the hypothesis that these added peripheral ends received a special subset of inputs, which might then account for the change in behavior, and found it to be false. Mapping and counts of degenerating synapses resulting from lesion of HVc and L-MAN suggest that under the influence of hormone, new synapses are added throughout the dendritic tree, with no special distribution or change in ratio of inputs occurring at the tip of dendrites. Under the influence of testosterone, each type IV cell may receive only “more of the same” inputs it received before onset of treatment. We speculate on how such changes in circuitry may relate to song stability and learning.},
	number = {10},
	journal = {J. Neurosci.},
	author = {Canady, R A and Burd, G D and Devoogd, T J and Nottebohm, F},
	month = oct,
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {3770--84.},
}

@article{dulac_novel_1995,
	title = {A {Novel} {Family} of {Genes} {Encoding} {Putative} {Pheromone} {Receptors} in {Mammals}},
	volume = {83},
	abstract = {In mammals, olfactory sensory perception is mediated by two anatomically and functionally distinct sensory organs: the main olfactory epithelium (MOE) and the vomeronasal organ (VNO). Pheromones activate the VNO and elicit a characteristic array of innate reproductive and social behaviors, along with dramatic neuroendocrine responses. Differential screening of cDNA libraries constructed from single sensory neurons from the rat VNO has led to the isolation of a family of about 30 putative receptor genes. Sequence analysis indicates that these genes comprise a novel family of seven transmembrane domain proteins unrelated to the receptors expressed in the MOE. Moreover, the expression of each member of the gene family is restricted to a small subpopulation of VNO neurons. These genes are likely to encode mammalian pheromone receptors.},
	number = {2},
	journal = {Cell},
	author = {Dulac, C and Axel, R},
	month = oct,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {195--206},
}

@article{lombardino_age_2000,
	title = {Age at deafening affects the stability of learned song in adult male zebra finches},
	volume = {20},
	abstract = {Male zebra finches (Taeniopygia guttata) master the imitation of a song model 80-90 d after hatching and retain it with little change for the rest of their lives. Acquisition and maintenance of this imitation require intact hearing. A previous report showed that male zebra finches deafened as adults start to lose some of the acoustic and temporal features of their song a few weeks after deafening and that by 16 weeks the learned song is severely degraded (Nordeen and Nordeen, 1992). However, this previous study noted no correlation between the age at deafening and the subsequent timing and extent of song loss. We deafened adult male zebra finches ranging in age from 81 d to 6 years. The song of birds deafened at the younger ages (81-175 d) deteriorated severely after a few weeks, and within that age bracket, the older the bird was at deafening, the longer it took for this degradation to occur and the slower the subsequent process of song deterioration. The song of birds deafened at 2 years and older showed little change during the first 51 weeks after deafening but was grossly altered by 100 weeks. We suggest (1) that this age effect could be independent of experience or (2) that each time a bird sings, a little bit of learning-motor engrainment-occurs, adding to memory duration in a cumulative manner.},
	number = {13},
	journal = {J. Neurosci.},
	author = {Lombardino, A J and Nottebohm, F},
	month = jul,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {5054--64.},
}

@article{sanfey_neural_2003,
	title = {The neural basis of economic decision-making in the {Ultimatum} {Game}},
	volume = {300},
	abstract = {The nascent field of neuroeconomics seeks to ground economic decision making in the biological substrate of the brain. We used functional magnetic resonance imaging of Ultimatum Game players to investigate neural substrates of cognitive and emotional processes involved in economic decision-making. In this game, two players split a sum of money;one player proposes a division and the other can accept or reject this. We scanned players as they responded to fair and unfair proposals. Unfair offers elicited activity in brain areas related to both emotion (anterior insula) and cognition (dorsolateral prefrontal cortex). Further, significantly heightened activity in anterior insula for rejected unfair offers suggests an important role for emotions in decision-making.},
	number = {5626},
	journal = {Science},
	author = {Sanfey, Ag and Rilling, Jk and Aronson, Ja and Nystrom, Le and Cohen, Jd},
	month = jun,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {1755--8.},
}

@article{hessler_social_1999,
	title = {Social context modulates singing-related neural activity in the songbird forebrain},
	volume = {2},
	number = {3},
	journal = {Nat. Neurosci.},
	author = {Hessler, N A and Doupe, A J},
	month = mar,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {209--11.},
}

@article{deangelis_receptive-field_1995,
	title = {Receptive-field dynamics in the central visual pathways},
	volume = {18},
	abstract = {Neurons in the central visual pathways process visual images within a localized region of space, and a restricted epoch of time. Although the receptive field (RF) of a visually responsive neuron is inherently a spatiotemporal entity, most studies have focused exclusively on spatial aspects of RF structure. Recently, however, the application of sophisticated RF-mapping techniques has enabled neurophysiologists to characterize RFs in the joint domain of space and time. Studies that use these techniques have revealed that neurons in the geniculostriate pathway exhibit striking RF dynamics. For a majority of cells, the spatial structure of the RF changes as a function of time; thus, these RFs can be characterized adequately only in the space-time domain. In this review, the spatiotemporal RF structure of neurons in the lateral geniculate nucleus and primary visual cortex is discussed.},
	number = {10},
	journal = {Trends Neurosci.},
	author = {Deangelis, Gc and Ohzawa, I and Freeman, Rd},
	month = oct,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {451--8.},
}

@article{weliky_coding_2003,
	title = {Coding of natural scenes in primary visual cortex},
	volume = {37},
	abstract = {Natural scene coding in ferret visual cortex was investigated using a new technique for multi-site recording of neuronal activity from the cortical surface. Surface recordings accurately reflected radially aligned layer 2/3 activity. At individual sites, evoked activity to natural scenes was weakly correlated with the local image contrast structure falling within the cells' classical receptive field. However, a population code, derived from activity integrated across cortical sites having retinotopically overlapping receptive fields, correlated strongly with the local image contrast structure. Cell responses demonstrated high lifetime sparseness, population sparseness, and high dispersal values, implying efficient neural coding in terms of information processing. These results indicate that while cells at an individual cortical site do not provide a reliable estimate of the local contrast structure in natural scenes, cell activity integrated across distributed cortical sites is closely related to this structure in the form of a sparse and dispersed code.},
	number = {4},
	journal = {Neuron},
	author = {Weliky, M and Fiser, J and Hunt, Rh and Wagner, Dn},
	month = feb,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {703--18.},
}

@article{deweese_binary_2003,
	title = {Binary spiking in auditory cortex},
	volume = {23},
	abstract = {Neurons are often assumed to operate in a highly unreliable manner: a neuron can signal the same stimulus with a variable number of action potentials. However, much of the experimental evidence supporting this view was obtained in the visual cortex. We have, therefore, assessed trial-to-trial variability in the auditory cortex of the rat. To ensure single-unit isolation, we used cell-attached recording. Tone-evoked responses were usually transient, often consisting of, on average, only a single spike per stimulus. Surprisingly, the majority of responses were not just transient, but were also binary, consisting of 0 or 1 action potentials, but not more, in response to each stimulus; several dramatic examples consisted of exactly one spike on 100\% of trials, with no trial-to-trial variability in spike count. The variability of such binary responses differs from comparably transient responses recorded in visual cortical areas such as area MT, and represent the lowest trial-to-trial variability mathematically possible for responses of a given firing rate. Our study thus establishes for the first time that transient responses in auditory cortex can be described as a binary process, rather than as a highly variable Poisson process. These results demonstrate that cortical architecture can support a more precise control of spike number than was previously recognized, and they suggest a re-evaluation of models of cortical processing that assume noisiness to be an inevitable feature of cortical codes.},
	number = {21},
	journal = {J. Neurosci.},
	author = {Deweese, Mr and Wehr, M and Zador, Am},
	month = aug,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {7940--9.},
}

@article{turner_corticostriatal_2000,
	title = {Corticostriatal activity in primary motor cortex of the macaque},
	volume = {20},
	abstract = {Although input from corticostriatal neurons (CSNs) plays a critical role in basal ganglia functions, little is known about CSN activity during behavior. We compared the properties of antidromically identified CSNs with those of antidromically identified neurons that project via the cerebral peduncle to distant targets. Both types of neurons were recorded in primary motor cortex (M1) of two monkeys as they performed a step-tracking task in which static loads opposed or assisted simple and precued movements of the elbow or wrist. Multiple lines of evidence suggested that CSNs and corticopeduncular neurons (CPNs) belong to distinct populations. No cells were activated from both striatum and peduncle. Compared with CPNs, CSNs had slow conduction velocities and low spontaneous rates, and the activity of most was unmodulated by sensory testing or within the tasks used. CSN activity resembled that described for M1-recipient striatal neurons: perimovement firing was small in magnitude, strongly directional, and rarely showed muscle-like load effects. Contrary to a previous report, perimovement activity in most CSNs began before movement onset. CSN activity was more selective than that of CPNs: CSN sensory responses and perimovement activities were often directionally specific, CSNs were often activated exclusively by sensory stimulation, active movement, or movement preparation, and a substantial fraction of CSNs (19\%) was unresponsive to any task or manipulation. Thus, CSNs transmit signals distinct from those sent to spinal cord/brainstem. The highly selective activity of CSNs suggests that a discrete (i.e., sparse) code is used to signal cortical activation states to striatum.},
	number = {18},
	journal = {J. Neurosci.},
	author = {Turner, Rs and Delong, Mr},
	month = sep,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {7096--108.},
}

@article{omi_long-lasting_2004,
	title = {Long-lasting {RNAi} activity in mammalian neurons},
	volume = {558},
	abstract = {The effect of RNA interference (RNAi) induced by synthetic small interfering RNAs (siRNAs) on proliferating mammalian cells appears to last for approximately 3-7 days after its induction. Here we show that the RNAi activity induced by a synthetic 21-nucleotide siRNA duplex in postmitotic neurons, mouse primary hippocampal neurons and neurons that differentiated from mouse embryonal carcinoma P19 cells persists for at least 3 weeks, suggesting long-lasting RNAi activity in mammalian neurons. In addition, we also show that an apoptotic (or antiviral) pathway triggered by long dsRNAs is generated during neuronal differentiation of P19 cells, by which the sequence-specific RNAi activity involving long dsRNA appears to be masked.},
	number = {1-3},
	journal = {FEBS Lett.},
	author = {Omi, K and Tokunaga, K and Hohjoh, H},
	month = jan,
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {89--95.},
}

@article{callaway_competition_nodate,
	title = {Competition favouring inactive over active motor neurons during synapse elimination},
	volume = {328},
	abstract = {During normal postnatal maturation, mammalian muscles undergo an orderly process of synapse elimination, whereby each muscle fibre loses all but one of the multiple inputs with which it is endowed at birth. Experimental perturbations that increase or decrease the overall activity of nerve and/or muscle cause a corresponding increase or decrease in the overall rate of neuromuscular synapse elimination. On other grounds it has been suggested that competition among motor neurons is important in determining which synapses survive and which are eliminated. Would a difference in activity among the terminals at the same endplate affect the outcome of the competition and not just its rate? We investigated this issue by blocking activity for four days in a small fraction of the motor neurons innervating the neonatal rabbit soleus muscle. Twitch tensions of motor units were subsequently measured for both the active and inactive populations of neurons to assess whether the inactive neurons had lost fewer or more synapses than is normal. We found that inactive motor neurons have a significant advantage compared to active counterparts in control experiments, a finding opposite to that expected if the neuromuscular junction operated by classical 'Hebbian' rules of competition.},
	number = {6129},
	journal = {Nature},
	author = {Callaway, Em and Soha, Jm and Van Dc, Essen},
	keywords = {merged\_fiete.bib},
	pages = {422--6.},
}

@article{bliss_long-lasting_1973,
	title = {Long-lasting potentiation of synaptic transmission in the dentate area of the anaesthetized rabbit following stimulation of the perforant path},
	volume = {232},
	number = {2},
	journal = {J. Physiol.},
	author = {Bliss, Tv and Lomo, T},
	month = jul,
	year = {1973},
	keywords = {merged\_fiete.bib},
	pages = {331--56.},
}

@article{bi_temporal_2002,
	title = {Temporal asymmetry in spike timing-dependent synaptic plasticity},
	volume = {77},
	abstract = {Activity-dependent synaptic modification is critical for the development and function of the nervous system. Recent experimental discoveries suggest that both the extent and the direction of modification may depend on the precise timing of pre- and postsynaptic action potentials (spikes). This phenomenon, termed spike timing-dependent plasticity (STDP), provides a new, quantitative interpretation of Hebb's rule and raises intriguing questions regarding the fundamental processes of cellular signaling. In this article, we summarize previous results obtained in a hippocampal culture system, where an asymmetric window of spike timing was found for paired pre- and postsynaptic spiking to induce STDP. We also discuss our recent studies using a “triplet-spiking” paradigm that reveals nonlinear, temporally asymmetric integration of STDP.},
	number = {4-5},
	journal = {Physiol. Behav.},
	author = {Bi, Gq and Wang, Hx},
	month = dec,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {551--5.},
}

@article{schwaerzel_dopamine_2003,
	title = {Dopamine and octopamine differentiate between aversive and appetitive olfactory memories in {Drosophila}},
	volume = {23},
	abstract = {The catecholamines play a major role in the regulation of behavior. Here we investigate, in the fly Drosophila melanogaster, the role of dopamine and octopamine (the presumed arthropod homolog of norepinephrine) during the formation of appetitive and aversive olfactory memories. We find that for the formation of both types of memories, cAMP signaling is necessary and sufficient within the same subpopulation of mushroom-body intrinsic neurons. On the other hand, memory formation can be distinguished by the requirement for different catecholamines, dopamine for aversive and octopamine for appetitive conditioning. Our results suggest that in associative conditioning, different memories are formed of the same odor under different circumstances, and that they are linked to the respective motivational systems by their specific modulatory pathways.},
	number = {33},
	journal = {J. Neurosci.},
	author = {Schwaerzel, M and Monastirioti, M and Scholz, H and Grelin, Friggi-F and Birman, S and Heisenberg, M},
	month = nov,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {10495--502.},
}

@article{hammer_multiple_1998,
	title = {Multiple sites of associative odor learning as revealed by local brain microinjections of octopamine in honeybees},
	volume = {5},
	abstract = {In a classical conditioning procedure, honeybees associate an odor with sucrose resulting in the capacity of the odor to evoke an appetitive response, the extension of the proboscis (PER). Here, we study the effects of pairing an odor with injections of octopamine (OA) as a substitute for sucrose into three putative brain sites of odor/sucrose convergence. OA injected into the mushroom body (MB) calyces or the antennal lobe but not the lateral protocerebral lobe produces a lasting, pairing-specific enhancement of PER. During pairings, OA injected into the MB calyces results in an additional pairing-specific effect, because it does not lead to an acquisition but a consolidation after conditioning. These results suggest that the neuromodulator OA has the capacity of inducing associative learning in an insect brain. Moreover, they suggest the antennal lobes and the calyces as at least partially independent sites of associating odors that may contribute differently to learning and memory consolidation.},
	number = {1-2},
	journal = {Learn. Mem.},
	author = {Hammer, M and Menzel, R},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {146--56.},
}

@article{hammer_neural_1997,
	title = {The neural basis of associative reward learning in honeybees},
	volume = {20},
	abstract = {Appetitive learning of food-predicting stimuli, an essential part of foraging behavior in honeybees, follows the rules of associative learning. In the learning of odors as reward-predicting stimuli, an individual neuron, one of a small group of large ascending neurons that serve principal brain neuropiles, mediates the reward and has experience-dependent response properties. This implies that this neuron functions as an integral part of associative memory, might underlie more complex features of learning, and could participate in the implementation of learning rules. Moreover, its structural properties suggest that it organizes the interaction of functionally different neural nets during learning and experience-dependent behavior.},
	number = {6},
	journal = {Trends Neurosci.},
	author = {Hammer, M},
	month = jun,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {245--52.},
}

@article{feenstra_dopamine_2001,
	title = {Dopamine and noradrenaline efflux in the rat prefrontal cortex after classical aversive conditioning to an auditory cue},
	volume = {13},
	abstract = {We used bilateral microdialysis in the medial prefrontal cortex (PFC) of awake, freely moving rats to study aversive conditioning to an auditory cue in the controlled environment of the Skinner box. The presentation of the explicit conditioned stimuli (CS), previously associated with foot shocks, caused increased dopamine (DA) and noradrenaline (NA) efflux. This conditioned response was dependent on the immediate pairing of the two stimuli; in the pseudoconditioned group that received an equal number of both stimuli, but in an unpaired fashion, no conditioned increases in efflux were observed.},
	number = {5},
	journal = {Eur. J. Neurosci.},
	author = {Feenstra, Mg and Vogel, M and Botterblom, Mh and Joosten, Rn and Jp, Bruin De},
	month = mar,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {1051--4.},
}

@article{mirenowicz_preferential_1996,
	title = {Preferential activation of midbrain dopamine neurons by appetitive rather than aversive stimuli},
	volume = {379},
	abstract = {Midbrain dopamine systems are crucially involved in motivational processes underlying the learning and execution of goal-directed behaviour. Dopamine neurons in monkeys are uniformly activated by unpredicted appetitive stimuli such as food and liquid rewards and conditioned, reward-predicting stimuli. By contrast, fully predicted stimuli are ineffective, and the omission of predicted reward depresses their activity. These characteristics follow associative-learning rules, suggesting that dopamine responses report an error in reward prediction. Accordingly, neural network models are efficiently trained using a dopamine-like reinforcement signal. However, it is unknown whether the responses to environmental stimuli concern specific motivational attributes or reflect more general stimulus salience. To resolve this, we have compared dopamine impulse responses to motivationally opposing appetitive and aversive stimuli. In contrast to appetitive events, primary and conditioned non-noxious aversive stimuli either failed to activate dopamine neurons or, in cases of close resemblance with appetitive stimuli, induced weaker responses than appetitive stimuli. Thus, dopamine neurons preferentially report environmental stimuli with appetitive rather than aversive motivational value.},
	number = {6564},
	journal = {Nature},
	author = {Mirenowicz, J and Schultz, W},
	month = feb,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {449--51.},
}

@article{schultz_getting_2002,
	title = {Getting formal with dopamine and reward},
	volume = {36},
	abstract = {Recent neurophysiological studies reveal that neurons in certain brain structures carry specific signals about past and future rewards. Dopamine neurons display a short-latency, phasic reward signal indicating the difference between actual and predicted rewards. The signal is useful for enhancing neuronal processing and learning behavioral reactions. It is distinctly different from dopamine's tonic enabling of numerous behavioral processes. Neurons in the striatum, frontal cortex, and amygdala also process reward information but provide more differentiated information for identifying and anticipating rewards and organizing goal-directed behavior. The different reward signals have complementary functions, and the optimal use of rewards in voluntary behavior would benefit from interactions between the signals. Addictive psychostimulant drugs may exert their action by amplifying the dopamine reward signal.},
	number = {2},
	journal = {Neuron},
	author = {Schultz, W},
	month = oct,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {241--63.},
}

@article{wise_brain_2002,
	title = {Brain reward circuitry: insights from unsensed incentives},
	volume = {36},
	abstract = {The natural incentives that shape behavior reach the central circuitry of motivation trans-synaptically, via the five senses, whereas the laboratory rewards of intracranial stimulation or drug injections activate reward circuitry directly, bypassing peripheral sensory pathways. The unsensed incentives of brain stimulation and intracranial drug injections thus give us tools to identify reward circuit elements within the associational portions of the CNS. Such studies have implicated the mesolimbic dopamine system and several of its afferents and efferents in motivational function. Comparisons of natural and laboratory incentives suggest hypotheses as to why some habits become compulsive and give insights into the roles of reinforcement and of prediction of reinforcement in habit formation.},
	number = {2},
	journal = {Neuron},
	author = {Wise, Ra},
	month = oct,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {229--40.},
}

@article{bao_suppression_2003,
	title = {Suppression of cortical representation through backward conditioning},
	volume = {100},
	abstract = {Temporal stimulus reinforcement sequences have been shown to determine the directions of synaptic plasticity and behavioral learning. Here, we examined whether they also control the direction of cortical reorganization. Pairing ventral tegmental area stimulation with a sound in a backward conditioning paradigm specifically reduced representations of the paired sound in the primary auditory cortex (AI). This temporal sequence-dependent bidirectional cortical plasticity modulated by dopamine release hypothetically serves to prevent the over-representation of frequently occurring stimuli resulting from their random pairing with unrelated rewards.},
	number = {3},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Bao, S and Chan, Vt and Zhang, Li and Merzenich, Mm},
	month = feb,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {1405--8. Epub 2003 Jan 21.},
}

@article{bao_cortical_2001,
	title = {Cortical remodelling induced by activity of ventral tegmental dopamine neurons},
	volume = {412},
	abstract = {Representations of sensory stimuli in the cerebral cortex can undergo progressive remodelling according to the behavioural importance of the stimuli. The cortex receives widespread projections from dopamine neurons in the ventral tegmental area (VTA), which are activated by new stimuli or unpredicted rewards, and are believed to provide a reinforcement signal for such learning-related cortical reorganization. In the primary auditory cortex (AI) dopamine release has been observed during auditory learning that remodels the sound-frequency representations. Furthermore, dopamine modulates long-term potentiation, a putative cellular mechanism underlying plasticity. Here we show that stimulating the VTA together with an auditory stimulus of a particular tone increases the cortical area and selectivity of the neural responses to that sound stimulus in AI. Conversely, the AI representations of nearby sound frequencies are selectively decreased. Strong, sharply tuned responses to the paired tones also emerge in a second cortical area, whereas the same stimuli evoke only poor or non-selective responses in this second cortical field in naive animals. In addition, we found that strong long-range coherence of neuronal discharge emerges between AI and this secondary auditory cortical area.},
	number = {6842},
	journal = {Nature},
	author = {Bao, S and Chan, Vt and Merzenich, Mm},
	month = jul,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {79--83.},
}

@article{blake_neural_2002,
	title = {Neural correlates of instrumental learning in primary auditory cortex},
	volume = {99},
	abstract = {In instrumental learning, Thorndike's law of effect states that stimulus-response relations are strengthened if they occur prior to positive reinforcement and weakened if they occur prior to negative reinforcement. In this study, we demonstrate that neural correlates of Thorndike's law may be observed in the primary auditory cortex, A1. Adult owl monkeys learned to discriminate tones higher than a standard frequency. Responses recorded from implanted microelectrodes initially exhibited broad spectral selectivity over a four-to-five octave range. With training, frequency discrimination thresholds changed from close to one octave to about 1/12 octave. Physiological recordings during the week in which the monkey came under behavioral control signaled by a drop in measured threshold had stronger responses to all frequencies. During the same week, A1 neural responses to target stimuli increased relative to standard and nontarget stimuli. This emergent difference in responsiveness persisted throughout the subsequent weeks of behavioral training. These data suggest that behavioral responses to stimuli modulate responsiveness in primary cortical areas.},
	number = {15},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Blake, Dt and Strata, F and Churchland, Ak and Merzenich, Mm},
	month = jul,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {10114--9. Epub 2002 Jul 15.},
}

@article{kilgard_cortical_1998,
	title = {Cortical map reorganization enabled by nucleus basalis activity},
	volume = {279},
	abstract = {Little is known about the mechanisms that allow the cortex to selectively improve the neural representations of behaviorally important stimuli while ignoring irrelevant stimuli. Diffuse neuromodulatory systems may facilitate cortical plasticity by acting as teachers to mark important stimuli. This study demonstrates that episodic electrical stimulation of the nucleus basalis, paired with an auditory stimulus, results in a massive progressive reorganization of the primary auditory cortex in the adult rat. Receptive field sizes can be narrowed, broadened, or left unaltered depending on specific parameters of the acoustic stimulus paired with nucleus basalis activation. This differential plasticity parallels the receptive field remodeling that results from different types of behavioral training. This result suggests that input characteristics may be able to drive appropriate alterations of receptive fields independently of explicit knowledge of the task. These findings also suggest that the basal forebrain plays an active instructional role in representational plasticity.},
	number = {5357},
	journal = {Science},
	author = {Kilgard, Mp and Merzenich, Mm},
	month = mar,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {1714--8.},
}

@article{ungless_uniform_2004,
	title = {Uniform inhibition of dopamine neurons in the ventral tegmental area by aversive stimuli},
	volume = {303},
	abstract = {Dopamine neurons play a key role in reward-related behaviors. Reward coding theories predict that dopamine neurons will be inhibited by or will not respond to aversive stimuli. Paradoxically, between 3 and 49\% of presumed dopamine neurons are excited by aversive stimuli. We found that, in the ventral tegmental area of anesthetized rats, the population of presumed dopamine neurons that are excited by aversive stimuli is actually not dopaminergic. The identified dopamine neurons were inhibited by the aversive stimulus. These findings suggest that dopamine neurons are specifically excited by reward and that a population of nondopamine neurons is excited by aversive stimuli.},
	number = {5666},
	journal = {Science},
	author = {Ungless, Ma and Magill, Pj and Bolam, Jp},
	month = mar,
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {2040--2.},
}

@article{stark_dopaminergic_1997,
	title = {Dopaminergic and serotonergic neurotransmission systems are differentially involved in auditory cortex learning: a long-term microdialysis study of metabolites},
	volume = {68},
	abstract = {Auditory cortex has been shown to be a site of widespread neuronal learning processes even in the context of simple auditory conditioning behavior. In view of their presumed role in determining behavioral and motivational relevance of incoming information we investigated whether the dopaminergic and serotonergic systems are involved in auditory cortex learning. Using a chronic brain microdialysis technique over 4 days, samples from auditory cortex were obtained before, during, and after daily footshock avoidance training simultaneously from trained gerbils and passive control animals or pseudotrained animals. Because of detection limits of dopamine and serotonin in auditory cortex, the response profiles of extracellular homovanillic acid as the metabolite of the dopaminergic system and of 5-hydroxyindoleacetic acid as the metabolite of the serotonergic system were determined from consecutive dialysis samples each day. The response of the dopaminergic system appeared to reflect the initial formation of the behaviorally relevant association exclusively during the first training day, whereas the serotonergic response appeared to correlate with the stress level of animals.},
	number = {2},
	journal = {J. Neurochem.},
	author = {Stark, H and Scheich, H},
	month = feb,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {691--7.},
}

@article{bottjer_role_1984,
	title = {The role of feedback from the vocal organ. {I}. {Maintenance} of stereotypical vocalizations by adult zebra finches},
	volume = {4},
	abstract = {The stereotypical vocal patterns of adult male zebra finches (Poephila guttata) were examined before and after elimination of auditory feedback and/or feedback from the vocal organ (the syrinx). Elimination of auditory feedback was accomplished via bilateral removal of the cochleae, whereas feedback from the syrinx was eliminated by cutting hypoglossal afferent fibers while leaving hypoglossal efferents intact. Very little or no disruption of song was observed in birds which underwent deafening as well as unilateral deafferentation of the syrinx. Control experiments showed that the minor deficits observed were not attributable to lesion of pulmonary fibers in the descending branch of the vagus. There was also little deficit in song behavior of birds that were deafened and subjected to bilateral deafferentation of the syrinx. These results are consistent with the hypothesis that stable song patterns in adult passerine birds are not dependent on peripheral sources of feedback, but may be governed by a learned central control program.},
	number = {9},
	journal = {J. Neurosci.},
	author = {Bottjer, Sw and Arnold, Ap},
	month = sep,
	year = {1984},
	keywords = {merged\_fiete.bib},
	pages = {2387--96.},
}

@article{keating_nonclock_1995,
	title = {Nonclock behavior of inferior olive neurons: {Interspike} interval of {Purkinje} cell complex spike discharge in the awake behaving monkey is random},
	volume = {73},
	abstract = {1. Complex spikes of cerebellar Purkinje cells recorded from awake, behaving monkeys were studied to determine the extent to which their discharge could be quantified as periodic. Three Rhesus monkeys were trained to perform up to five different tasks involving rotation of the wrist in relation to a visual cue. Complex spike activity was recorded during task performance and intertrial time. Interspike intervals were determined from the discharge of each of 89 Purkinje cells located throughout lobules IV, V, and VI. Autocorrelation and Fourier transform of the autocorrelation function were performed on the data. In addition, the activity from one cell was transformed so that the discharge occurred on the beat of a 10-Hz clock, and in a further transformation, on the beat of a noisy 10-Hz clock. These transformed data were then analyzed as described above. 2. Fourier transform of the autocorrelogram function of the data that had been transformed to a 10-Hz clock, and that of the noisy 10-Hz clock, both showed a prominent peak at 10 Hz. However, the autocorrelograms and the Fourier transforms of the autocorrelogram functions failed to reveal a prominent periodicity for the actual discharge of any of cells, at any frequency up to 100 Hz: the discharge appeared random with respect to the interspike interval. The discharge was not random with respect to behavior. Complex spike activity was commonly time locked to the start of wrist movement. We examined this discharge to see whether oscillatory discharge could be seen after alignment of the data on the start of wrist movement, or after alignment of the data on the complex spike occurring peri-start of wrist movement. No oscillation was seen for either alignment. 3. The inferior olive, which sends its climbing fibers to the cerebellum, has been implicated in such different activities as 1) pathological tremor of the soft palate, 2) physiological tremor, 3) the normal initiation of all bodily movement, and 4) motor learning. Previous work in pharmacologically or surgically treated animals has shown that, under some conditions, the discharge of these neurons is periodic and synchronous. This firing pattern has been interpreted to support a role in the first two activities. But measurements reported here in the awake monkey show just the opposite: the discharge is aperiodic to the extent of being random. As such, the inferior olive cannot be a “motor clock” in the general role that has been proposed.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Keating, J G and Thach, W T},
	month = apr,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {1329--1340},
}

@article{schreurs_pairing-specific_1996,
	title = {Pairing-specific long-term depression of {Purkinje} cell excitatory postsynaptic potentials results from a classical conditioning procedure in the rabbit cerebellar slice},
	volume = {75},
	abstract = {1. Using a rabbit cerebellar slice preparation, we stimulated a classical conditioning procedure by stimulating parallel fiber inputs to Purkinje cells with the use of a brief, high-frequency train of eight constant-current pulses 80 ms before climbing fiber inputs to the same Purkinje cell were stimulated with the use of a brief, lower frequency train of three constant-current pulses. In all experiments, we assessed the effects of stimulation by measuring the peak amplitude of Purkinje cell excitatory postsynaptic potentials (EPSPs) to single parallel fiber test pulses. 2. Intradendritically recorded Purkinje cell EPSPs underwent a long-term ({\textgreater} 20 min) reduction in peak amplitude (30\%) after paired stimulation of the parallel and climbing fibers but not after unpaired or parallel fiber alone stimulation. We call this phenomenon pairing-specific long-term depression (PSD). 3. Facilitation of the peak amplitude of a second EPSP elicited by a parallel fiber train occurred both before and after paired stimulation suggesting that the locus of depression was not presynaptic. Depression of the peak amplitude of a depolarizing response to focal application of glutamate following pairings of parallel and climbing fiber stimulation added support to a suggested postsynaptic locus of the PSD effect. 4. The application of aniracetam potentiated EPSP peak amplitude by 40\%, but these values returned to baseline as a result of pairings. With the removal of aniracetam from the bath 20 min after pairings, normal levels of pairing-specific EPSP depression were observed, indicating that the effect did not result from direct desensitization of alpha-amino-3-hydroxy-5-methyl-4-isoxazole-proprionic acid (AMPA) receptors. 5. Incubation of slices in the protein kinase inhibitor H-7 potentiated EPSP peak amplitudes slightly (9\%), but peak amplitudes returned to baseline levels after pairings. The net reduction in EPSP peak amplitude of {\textless} 10\% after pairings suggested that H-7 partially blocked PSD and that, in turn, PSD involved protein kinases. 6. The means of induction and the specificity of those means suggest that the phenomenology of PSD is fundamentally different from that of long-term depression. PSD only occurs with pairings of trains of parallel fiber and climbing fiber stimulation; it occurs without the need for bicuculline; and it can overcome the blocking effects of aniracetam. 7. Nevertheless, the involvement of protein kinases and the potential role of calcium suggest that the mechanisms involved in the induction of PSD and long-term depression have a number of features in common. 8. Because of the pairing-specific nature of the long-term synaptic depression observed in these experiments, PSD provides a mechanism that may contribute to the role of the cerebellar cortex in classical conditioning.},
	number = {3},
	journal = {J. Neurophysiol.},
	author = {Schreurs, B G and Oh, M M and Alkon, D L},
	month = mar,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {1051--1060},
}

@article{chen_temporal_1995,
	title = {Temporal specificity of long-term depression in parallel fiber–{Purkinje} synapses in rat cerebellar slice},
	volume = {2},
	abstract = {The phenomenon of cerebellar long-term depression (LTD), a decrease of synaptic strength between the parallel fibers (PFs) and Purkinje cells after conjunctive activation of PFs and the climbing fibers (CFs), is implicated as a cellular mechanism for motor learning. We have characterized a field-potential recording technique in cerebellar slice and have used the technique to examine the temporal conditions for cerebellar LTD induction in an attempt to examine the relevance of LTD to associative conditioning. Interstimulus intervals (ISIs) between onsets of PF and CF activation and the number of paired stimuli (pairings) were examined. LTD has distinct temporal specificity that seems to be constrained by inhibitory interneurons and can be masked by excessive stimulation. When 100 paired stimuli were given to PFs and CFs, LTD was induced with an ISI of 250 msec (PF activation preceding CF activation). In contrast, a smaller forward (125 msec), simultaneous (0 msec), or backward (-250 msec) ISIs were not effective for inducing LTD. However, the blockade of GABAA receptor-mediated inhibition made it possible to induce LTD with 100 pairs of simultaneous stimulations. Furthermore, by increasing the number of pairings to 600, significant LTD was observed with all four interstimulus intervals. These results suggest that temporal conditions for LTD induction share some similarity to associative learning of discrete motor responses.},
	number = {3-4},
	journal = {Learn. Mem.},
	author = {Chen, C and Thompson, R F},
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {185--98.},
}

@article{mcnaughton_hippocampal_1989,
	title = {Hippocampal granule cells are necessary for normal spatial learning but not for spatially-selective pyramidal cell discharge},
	volume = {76},
	abstract = {The effects of massive destruction of granule cells of the fascia dentata on the spatial and temporal firing characteristics of pyramidal cells in the CA1 and CA3 subfields of the hippocampus were examined in freely moving rats. Microinjections of the neurotoxin colchicine were made at a number of levels along the septo-temporal axis of the dentate gyri of both hemispheres, resulting in destruction of over 75\% of the granule cells. By contrast there was relatively little damage to the pyramidal cell fields. As assessed by three different behavioral tests, the colchicine treatment resulted in severe spatial learning deficits. Single units were recorded from the CA1 and CA3 subfields using the stereotrode recording method while the animals performed a forced choice behavioral task on the radial 8-arm maze. Considering the extent of damage to the dentate gyrus, which has hitherto been considered to be the main source of afferent information to the CA fields, there was remarkably little effect on the spatial selectivity of “place cell” discharge on the maze, as compared to recordings from control animals. There was, however, a change in the temporal firing characteristics of these cells, which was manifested primarily as an increase in the likelihood of burst discharge. The main conclusion derived from these findings is that most of the spatial information exhibited by hippocampal pyramidal cells is likely to be transmitted from the cortex by routes other than the traditional “trisynaptic circuit”. These routes may include the direct projections from entorhinal layers II and III to CA3 and CA1, respectively.},
	number = {3},
	journal = {Exp. Brain Res.},
	author = {McNaughton, B L and Barnes, C A and Meltzer, J and Sutherland, R J},
	year = {1989},
	keywords = {merged\_fiete.bib},
	pages = {485--96.},
}

@article{jung_spatial_1993,
	title = {Spatial selectivity of unit activity in the hippocampal granular layer},
	volume = {3},
	abstract = {Single neuron activity was recorded in the granular layer of the fascia dentata in freely moving rats, while the animals performed a spatial “working” memory task on an eight-arm maze. Using recording methods that facilitate detection of units with low discharge rates, it was found that the majority (88\%) of cells in this layer have mean rates below 0.5 Hz, with a minimum of 0.01 Hz or less. The remaining recorded cells exhibited characteristics typical of the theta interneurons found throughout the hippocampus. Based on several criteria including relative proportion and the relation of their evoked discharges to the population spike elicited by perforant path stimulation, it was concluded that the low-rate cells correspond to granule cells. Granule cells exhibited clear spatially and directionally selective discharge that was at least as selective as that of a sample of CA3 pyramidal cells recorded under the same conditions. Granule cells had significantly smaller place fields than pyramidal cells, and tended to have more discontiguous subfields. There was no spatial correlation among simultaneously recorded adjacent granule cells. Granule cells also exhibited burst discharges reminiscent of complex spikes from pyramidal cells while the animals sat quietly; however, the spike duration of granule cells was significantly shorter than CA3 pyramidal cell spike durations. Under conditions of environmental stability, granule cell place fields were stable for at least several days. Following occasional maze rotations relative to the (somewhat impoverished) visual stimuli of the recording room, granule cell place fields were maintained relative to the distal spatial cues; however, frequent rotations of the maze sometimes resulted in a shift in the reference frame to the maze itself. These observations indicate that granule cells of the fascia dentata provide their CA3 targets with a high degree of spatial information, in the form of a sparsely coded, distributed representation.},
	number = {2},
	journal = {Hippocampus},
	author = {Jung, M W and McNaughton, B L},
	month = apr,
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {165--82.},
}

@article{hornung_human_2003,
	title = {The human raphe nuclei and the serotonergic system},
	volume = {26},
	abstract = {The raphe nuclei are distributed near the midline of the brainstem along its entire rostro-caudal extension. The serotonergic neurons are their main neuronal components, although a proportion of them lie in subdivisions of the lateral reticular formation. They develop from mesopontine and medullary primordia, and the resulting grouping into rostral and caudal clusters is maintained into adulthood, and is reflected in the connectivity. Thus, the mesencephalon and rostral pons, neurons within the rostral raphe complex (caudal linear, dorsal raphe, and median raphe nuclei) project primarily to the forebrain. By contrast, in the caudal pons and medulla oblongata, neurons within the caudal raphe complex (raphe magnus, raphe obscurus, raphe pallidus nuclei and parts of the adjacent lateral reticular formation) project to the brainstem nuclei and to the spinal cord. The median raphe and dorsal raphe nuclei provide parallel and overlapping projections to many forebrain structures with axon fibers exhibiting distinct structural and functional characteristics. The caudal group of the serotonergic system projects to the brainstem, and, by three parallel projections, to the dorsal, intermediate and ventral columns in the spinal cord. The serotonergic axons arborize over large areas comprising functionally diverse targets. Some projections form classical chemical synapses while many do not, thus contributing to the so-called paracrine or volume transmission. The serotonergic projections participate in the regulation of different functional (motor, somatosensory, limbic) systems; and have been associated with a wide range of neuropsychiatric and neurological disorders. Finally, recent experimental data support the role of serotonin in modulating brain development, such that a dysfunction in serotonergic transmission during early life could lead to long lasting structural and functional alterations.},
	number = {4},
	journal = {J. Chem. Neuroanat.},
	author = {Hornung, J P},
	month = dec,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {331--43.},
}

@article{dieudonne_serotonergic_2001,
	title = {Serotonergic neuromodulation in the cerebellar cortex: cellular, synaptic, and molecular basis},
	volume = {7},
	abstract = {The cerebellum, like most sensorimotor areas of the brain, receives a serotonergic innervation from neurons of the reticular formation. It is well established that local application of serotonin modulates the firing rate of cerebellar Purkinje cells in vivo and in vitro, but the mechanisms by which serotonin affects the cerebellar function are still poorly understood. Whereas interactions between serotonin, glutamate, and GABA have been reported to increase or decrease the firing frequency of Purkinje cells, there is little evidence for a modulation of excitatory and inhibitory synapses by serotonin in the cerebellar cortex. Changes in the intrinsic electrical properties of Purkinje cells upon application of serotonin have also been reported, but their impact on Purkinje cell firing is unclear. The recent finding that serotonin specifically modulates the activity of Lugaro cells, a class of inhibitory interneurons of the cerebellar cortex, offers new insights on the action of this neuromodulator. The peculiar axonal projection and specific interneuronal targets of the Lugaro cells suggest that the action of serotonin might occur upstream of Purkinje cells through a resetting of the computational properties of the cerebellar cortex. Understanding the mechanisms of the serotonergic modulation of the cerebellar cortex is of clinical relevance, as abnormal serotonin metabolism has been observed in animal models and pathological cases of motor disorders involving the cerebellum, and as chronic intravenous administration of L-5-hydroxytryptophan (5-HTP), a precursor of serotonin, was the first treatment shown to improve significantly cerebellar symptoms.},
	number = {3},
	journal = {Neuroscientist},
	author = {Dieudonne, S},
	month = jun,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {207--19.},
}

@article{tiliket_short-term_1994,
	title = {Short-term vestibulo-ocular reflex adaptation in humans. {I}. {Effect} on the ocular motor velocity-to-position neural integrator},
	volume = {100},
	abstract = {We investigated the effect of short-term vestibulo-ocular reflex (VOR) adaptation in normal human subjects on the dynamic properties of the velocity-to-position ocular motor integrator that holds positions of gaze. Subjects sat in a sinusoidally rotating chair surrounded by an optokinetic nystagmus drum. The movement of the visual surround (drum) was manipulated relative to the chair to produce an increase (x 1.7 viewing), decrease (x 0.5, x 0 viewing), or reversal (x (-2.5) viewing) of VOR gain. Before and after 1 h of training, VOR gain and gaze-holding after eccentric saccades in darkness were measured. Depending on the training paradigm, eccentric saccades could be followed by centrifugal drift (after x 0.5 viewing), implying an unstable integrator, or by centripetal drift [after x 1.7 or x (-2.5) viewing], implying a leaky integrator. The changes in the neural integrator appear to be context specific, so that when the VOR was tested in non-training head orientations, both the adaptive change in VOR gain and the changes in the neural integrator were much smaller. The changes in VOR gain were on the order of 10\% and the induced drift velocities were several degrees per second at 20 deg eccentric positions in the orbit. We propose that (1) the changes in the dynamic properties of the neural integrator reflect an attempt to modify the phase (timing) relationships of the VOR and (2) the relative directions of retinal slip and eye velocity during head rotation determine whether the integrator becomes unstable (and introduces more phase lag) or leaky (and introduces less phase lag).},
	number = {2},
	journal = {Exp. Brain Res.},
	author = {Tiliket, C and Shelhamer, M and Roberts, D and Zee, D S},
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {316--27.},
}

@article{hafeman_light-addressable_1988,
	title = {Light-addressable potentiometric sensor for biochemical systems},
	volume = {240},
	abstract = {Numerous biochemical reactions can be measured potentiometrically through changes in pH, redox potential, or transmembrane potential. An alternating photocurrent through an electrolyte-insulator-semiconductor interface provides a highly sensitive means to measure such potential changes. A spatially selectable photoresponse permits the determination of a multiplicity of chemical events with a single semiconductor device.},
	number = {4856},
	journal = {Science},
	author = {Hafeman, D G and Parce, J W and McConnell, H M},
	month = may,
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {1182--5.},
}

@article{suaud-chagny_uptake_1995,
	title = {Uptake of dopamine released by impulse flow in the rat mesolimbic and striatal systems in vivo},
	volume = {65},
	abstract = {The release of dopamine in the striatum, nucleus accumbens, and olfactory tubercle of anesthetized rats was evoked by electrical stimulation of the mesolimbic dopaminergic pathway (four pulses at 15 Hz or four pulses at 200 Hz). Carbon fiber electrodes were implanted in these regions to monitor evoked dopamine overflow by continuous amperometry. The kinetics of dopamine elimination were estimated by measuring the time to 50\% decay of the dopamine oxidation current after stimulation ceased. This time ranged from 64 ms in the striatum to 113 ms in the nucleus accumbens. Inhibition of dopamine uptake by nomifensine (2-20 mg/kg), GBR 12909 (20 mg/kg), cocaine (20 mg/kg), mazindol (10 mg/kg), or bupropion (25 mg/kg) enhanced this decay time by up to +602\%. Uptake inhibition also produced an increase in the maximal amplitude of dopamine overflow evoked by four pulses at 15 Hz. This latter effect was larger in the striatum (+420\%) than in mesolimbic areas (+140\%). These results show in vivo that these uptake inhibitors actually slow the clearance of dopamine released by action potentials and suggest that dopaminergic transmission is both prolonged and potentiated strongly by these drugs, in particular in the striatum.},
	number = {6},
	journal = {J. Neurochem.},
	author = {Suaud-Chagny, M F and Dugast, C and Chergui, K and Msghina, M and Gonon, F},
	month = dec,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {2603--11.},
}

@article{venton_real-time_2003,
	title = {Real-time decoding of dopamine concentration changes in the caudate-putamen during tonic and phasic firing},
	volume = {87},
	abstract = {The fundamental process that underlies volume transmission in the brain is the extracellular diffusion of neurotransmitters from release sites to distal target cells. Dopaminergic neurons display a range of activity states, from low-frequency tonic firing to bursts of high-frequency action potentials (phasic firing). However, it is not clear how this activity affects volume transmission on a subsecond time scale. To evaluate this, we developed a finite-difference model that predicts the lifetime and diffusion of dopamine in brain tissue. We first used this model to decode in vivo amperometric measurements of electrically evoked dopamine, and obtained rate constants for release and uptake as well as the extent of diffusion. Accurate predictions were made under a variety of conditions including different regions, different stimulation parameters and with uptake inhibited. Second, we used the decoded rate constants to predict how heterogeneity of dopamine release and uptake sites would affect dopamine concentration fluctuations during different activity states in the absence of an electrode. These simulations show that synchronous phasic firing can produce spatially and temporally heterogeneous concentration profiles whereas asynchronous tonic firing elicits uniform, steady-state dopamine concentrations.},
	number = {5},
	journal = {J. Neurochem.},
	author = {Venton, B J and Zhang, H and Garris, P A and Phillips, P E and Sulzer, D and Wightman, R M},
	month = dec,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {1284--95.},
}

@article{konishi_neuronal_nodate,
	title = {Neuronal growth, atrophy and death in a sexually dimorphic song nucleus in the zebra finch brain},
	volume = {315},
	abstract = {The song control nuclei of the zebra finch brain contain more neurones of larger diameter in the male than in the female. This sexual dimorphism is thought to result from differential growth of neurones in the two sexes. Using neurohistological techniques and radioactive tracers, we have studied the development of several forebrain nuclei involved in the control of song and find that the dimorphism arises from neuronal atrophy and death in the female brain as well as from an increase in cell-body size and afferent terminals from other forebrain nuclei in the male. Although the timing of these events varies from nucleus to nucleus, the sequence is essentially similar in all of them except area X. Here we describe the events in one of these nuclei, the robust nucleus of archistriatum (RA), as an example.},
	number = {6015},
	journal = {Nature},
	author = {Konishi, M and Akutagawa, E},
	keywords = {merged\_fiete.bib},
	pages = {145--7.},
}

@article{mooney_synaptic_1992,
	title = {Synaptic basis for developmental plasticity in a birdsong nucleus},
	volume = {12},
	abstract = {The development and adult production of birdsong are subserved by specialized brain nuclei, including the robust nucleus of the archistriatum (RA), and its afferents originating in the caudal nucleus of the ventral hyperstriatum (HVc) and the lateral portion of the magnocellular nucleus of the anterior neostriatum (L-MAN). An in vitro brain slice preparation was used to characterize the electrophysiological properties of L-MAN and HVc axonal synapses within RA and to examine how these synaptic connections change during the course of song development. Electrical stimulation of L-MAN and not HVc fibers evoked excitatory synaptic potentials from virtually all RA neurons in brain slices prepared from male and female zebra finches less than 25 d of age. These “L-MAN” EPSPs were blocked substantially by the NMDA receptor antagonist D(-)-2-amino-5-phosphonopentanoic acid (D-APV; 50-100 microM) and by hyperpolarization of the postsynaptic membrane. In contrast, when slices were prepared from male finches greater than 35 d of age, electrical stimulation of the L-MAN and the HVc fiber tracts evoked synaptic responses from over 70\% of RA neurons. Although the L-MAN EPSPs resembled those seen in RA before day 25, the “HVc” EPSPs were relatively insensitive to D-APV, but almost completely abolished by 6-cyano-7-nitroquinoxaline-2,3-dione, a non-NMDA glutamate receptor antagonist. These experiments indicate that L-MAN and HVc axons make pharmacologically distinct synapses on the same RA neurons, and that these synapses first form at different stages during development.},
	number = {7},
	journal = {J. Neurosci.},
	author = {Mooney, R},
	month = jul,
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {2464--77.},
}

@article{gurney_hormonal_1981,
	title = {Hormonal control of cell form and number in the zebra finch song system},
	volume = {1},
	abstract = {Administration of testosterone (T), 17 beta-estradiol (E2), or 5 alpha-dihydrotestosterone (DHT) to female zebra finch chicks (Poephila guttata) at hatching exerts effects on brain sexual differentiation. Within a telencephalic station (the nucleus robustus archistriatalis, RA) of the neural pathway which participates in the efferent control of song, masculinization of several indices of neuronal size is induced by exposure to T or E2. Within RA, a sensitive assay of a single neuron's sexually differentiated state is the diameter of its soma. By this criteria, all of the neurons within RA can be masculinized with a sufficient dose of T. As the dose of T is progressively decreased, the proportion of RA neurons which undergo the transition from female to male falls, while the magnitude of the change in soma size remains basically unaltered. Administration of T or DHT masculinizes the number of neurons in RA.},
	number = {6},
	journal = {J. Neurosci.},
	author = {Gurney, M E},
	month = jun,
	year = {1981},
	keywords = {merged\_fiete.bib},
	pages = {658--73.},
}

@article{robinson_detecting_2003,
	title = {Detecting subsecond dopamine release with fast-scan cyclic voltammetry in vivo},
	volume = {49},
	abstract = {BACKGROUND: Dopamine is a potent neuromodulator in the brain, influencing a variety of motivated behaviors and involved in several neurologic diseases. Measurements of extracellular dopamine in the brains of experimental animals have traditionally focused on a tonic timescale (minutes to hours). However, dopamine concentrations are now known to fluctuate on a phasic timescale (subseconds to seconds). APPROACH: Fast-scan cyclic voltammetry provides analytical chemical measurements of phasic dopamine signals in the rat brain. CONTENT: Procedural aspects of the technique are discussed, with regard to appropriate use and in comparison with other methods. Finally, examples of data collected using fast-scan cyclic voltammetry are summarized, including naturally occurring dopamine transients and signals arising from electrical stimulation of dopamine neurons. SUMMARY: Fast-scan cyclic voltammetry offers real-time measurements of changes in extracellular dopamine concentrations in vivo. With its subsecond time resolution, micrometer-dimension spatial resolution, and chemical selectivity, it is the most suitable technique currently available to measure transient concentration changes of dopamine.},
	number = {10},
	journal = {Clin. Chem.},
	author = {Robinson, D L and Venton, B J and Heien, M L and Wightman, R M},
	month = oct,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {1763--73.},
}

@article{chavkin_characterization_1985,
	title = {Characterization of the prodynorphin and proenkephalin neuropeptide systems in rat hippocampus},
	volume = {5},
	abstract = {Opioid peptides derived from prodynorphin were localized immunocytochemically to dentate granule cells and mossy fibers of the rat hippocampus with antisera against dynorphin A(1-17) and dynorphin B. Extracts of microdissected hippocampal regions were resolved by reverse phase and molecular exclusion chromatography to identify the molecular forms of the dynorphin A immunoreactivity and to quantify regional contents. Results demonstrated that the relative concentration of dynorphin A within each dissected region of hippocampus agreed well with the distribution of dynorphin A detected by immunocytochemical methods. Immunostaining of proenkephalin-derived opioid peptides, [Leu5]enkephalin and bovine adrenal medullary peptide-22P, was concentrated in cell bodies of the entorhinal cortex, nerve fibers in the perforant pathway, and terminals in the outer molecular layer of the dentate gyrus. Light immunostaining of granule cells and mossy fibers with these antisera was also found. The relative concentration of [Leu5]enkephalin immunoreactivity in each microdissected region of the hippocampus also agreed well with the distribution of [Leu5]enkephalin immunostaining. Chromatography of hippocampal regional extracts demonstrated that the immunoreactivity measured was due to the presence of authentic [Leu5]enkephalin. The probable neurotransmitter function of both [Leu5]enkephalin and dynorphin A was shown by their calcium-dependent release after in vitro depolarization of hippocampal tissue. The reported presence of beta-endorphin in hippocampus was not verified. Comparison of the hippocampal distribution and content of prodynorphin and proenkephalin-derived opioids suggests that separate populations of neurons containing these two peptide families form distinct neurotransmitter systems of roughly equal concentration.},
	number = {3},
	journal = {J. Neurosci.},
	author = {Chavkin, C and Shoemaker, W J and McGinty, J F and Bayon, A and Bloom, F E},
	month = mar,
	year = {1985},
	keywords = {merged\_fiete.bib},
	pages = {808--16.},
}

@article{benardo_dopamine_1982-1,
	title = {Dopamine action on hippocampal pyramidal cells},
	volume = {2},
	abstract = {Dopamine (DA) was applied to CA1 region pyramidal cells in slices of guinea pig hippocampus maintained in vitro in order to examine its electrophysiological effect on CNS neurons. DA induced hyperpolarization of membrane potential and an increased conductance in 75\% the 21 CA1 neurons to which it was applied. DA also augmented the afterhyperpolarizations and increased conductance which normally follow spike trains in these neurons. These effects were not altered by intracellular injections of Cl- but were blocked when slices were bathed in Mn2+ solutions. The Mn2+ blockade of DA-induced hyperpolarizations could be overcome when large amounts of agonists were applied. The DA effects were long lasting, were mimicked by the dopamine agonists apomorphine and Epinine, and were blocked by the dopamine antagonists flupenthixol and chlorpromazine. Extracellular or intracellular application of cyclic AMP mimicked the effects of DA. The results suggest that DA-induced hyperpolarization and conductance changes are mediated by a Ca2+-activated K+ conductance. DA may increase the intracellular Ca2+ concentration through effects on one of the Ca2+ buffering mechanisms. The long duration of these effects suggest that DA works though some intracellular intermediary, perhaps cyclic AMP, considering that the actions of cyclic AMP on membrane properties are similar to those of DA. The dopaminergic projection to the hippocampus should have a powerful inhibitory action, which would be most effective in modulating the activities of neurons exhibiting high levels of excitability, particularly cells involved in cyclical burst generation.},
	number = {4},
	journal = {J. Neurosci.},
	author = {Benardo, L S and Prince, D A},
	month = apr,
	year = {1982},
	keywords = {merged\_fiete.bib},
	pages = {415--23.},
}

@article{massobrio_light-addressable_1992,
	title = {Light-addressable chemical sensors: modelling and computer simulations},
	volume = {7},
	abstract = {A light-addressable potentiometric sensor (LAPS) has recently been proposed as a pH sensor. A LAPS description is presented that is suitable for direct applications as a built-in model in circuit-simulation programs, such as SPICE. The model equations describing the LAPS behavior have been formulated by modelling the electrolyte-insulator interface via site-binding theory, and by modelling, via semiconductor theory, the insulator-semiconductor structure under the photogeneration effects induced by an externally addressed light. Simulation results are presented, focused on the analysis of the detection of transient acidification phenomena.},
	journal = {Sens. Actuators B Chem.},
	author = {Massobrio, G and Martinoia, S and Grattarola, M},
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {484--487},
}

@article{jr_which_1975,
	title = {Which elements are excited in electrical stimulation of mammalian central nervous system: a review},
	volume = {98},
	abstract = {(1) There are data on the amount of current necessary to stimulate a myelinated fiber or cell body and/or its axon a given distance away from a monopolar electrode over the entire range of practical interest for intracranial stimulation. Data do not exist for other electrode configurations. (2) Currents from a monopolar cathode of more than 8 times threshold may block action potentials in axons. Therefore, only axons lying in a shell around the electrode are stimulated. Elements very close to the electrode may not be stimulated. Close to an electrode small diameter axons may be stimulated and larger ones may not be. (3) Most, and perhaps all, CNS myelinated fibers have chronaxies of 50-100 musec. When gray matter is stimulated, the chronaxie is often 200-700 musec. It is not clear what is being stimulated in this case. Current-duration relations should be determined for many more responses. (4) There are no current-distance or current-duration data for central finely myelinated or unmyelinated fibers. (5) It takes less cathodal current than anodal to stimulate a myelinated fiber passing by a monopolar electrode. When a monopolar electrode is near a cell body, on the opposite side from the axon, often the lowest threshold is anodal, but sometimes cathodal. Stimulation of a neuron near its cell body is not well understood, but in many cases the axon is probably stimulated. (6) Orientation of cell body and axons with respect to current flow is important. For an axon it is the component of the voltage gradient parallel to the fiber that is important. (7) The pia has a significant resistance and capacitance. Gray matter, white matter, and cerebrospinal fluid have different resistivities, which affect patterns of current flow. (8) More is known about stimulation of mammalian CNS than most workers are aware of. Much of what is unknown seems solvable with current methods.},
	number = {3},
	journal = {Brain Res.},
	author = {Jr, J B Ranck},
	month = nov,
	year = {1975},
	keywords = {merged\_fiete.bib},
	pages = {417--40.},
}

@article{sartore_minority_1992,
	title = {Minority carrier diffusion length effects on light-addressable potentiometric sensor ({LAPS}) devices},
	volume = {32},
	abstract = {Alternating photocurrent measurements with light-addressable potentiometric sensors (LAPSs) have been used to monitor pH, redox potential, and ionic concentrations at discrete locations in an electrolyte in contact with LAPS devices. We report here the results of AC photocurrent measurements with insulated semiconductor LAPS devices where the semiconductor either is illuminated through the insulator (frontside) or alternatively from the opposite side (backside). Such comparative AC photocurrent measurements were made with semiconductors of varied thickness, at varied frequency of light intensity modulation, and at several different photoexcitation wavelengths. The results are fit to a theoretical expression which predicts the dependence of photocurrent on modulation frequency, wafer thickness, bulk minority carrier lifetime, and surface recombination velocity. The results are useful to optimize the design of LAPS devices with regard to these parameters. The results also predict optimal conditions for minimal lateral spacing of adjacent sensing areas in LAPS devices.},
	journal = {Sens. Actuators A Phys.},
	author = {Sartore, M and Adami, M and Nicolini, C and Bousse, L and Mostarshed, S and Hafeman, D},
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {431--436},
}

@article{parak_lateral_1997,
	title = {Lateral resolution of light-addressable potentiometric sensors: an experimental and theoretical investigation},
	volume = {63},
	abstract = {The surface potential of semiconductor devices in contact with electrolyte solutions is an important part of signal transduction for a variety of bioanalytical devices. Here we have investigated the lateral resolution at which the surface potential may be measured with a semiconductor-based device, a light-addressable potentiometric sensor (LAPS). We have first established an experimental setup where a permanent charge pattern is generated in the oxide-nitride interface of an n-doped silicon wafer by UV irradiation. Using a laser beam to interrogate the LAPS, the charge pattern can be detected by measuring the local photocurrent at a resolution of better than 100 [small mu, Greek] m. A theoretical model based on the diffusion and recombination of photogenerated minority charge carriers has been developed and solved analytically; it is consistent with experiment. For Beer-Lambert law absorption of a sufficiently narrow beam of interrogating light, according to the theory the lateral resolution depends on the relative sizes of the penetration depth of the light, d, and the recombination-diffusion length of the carriers, L. When d {\textgreater} d, it is (2L{\textasciicircum}2){\textasciicircum}1/2 .},
	journal = {Sens. Actuators A Phys.},
	author = {Parak, W J and Hofmann, U G and Gaub, H E and Owicki, J C},
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {47--57},
}

@article{fallon_distribution_1986,
	title = {Distribution of dynorphin and enkephalin peptides in the rat brain},
	volume = {249},
	abstract = {The neuroanatomical distribution of dynorphin B-like immunoreactivity (DYN-B) was studied in the adult male and female albino rat. The distribution of DYN B in colchicine- and noncolchicine-treated animals was also compared to that of another opioid peptide derived from the prodynorphin precursor dynorphin A (1-8) (DYN 1-8), and an opioid peptide derived from the proenkephalin precursor met-enkephalin-arg-gly-leu (MERGL). DYN B cell bodies were present in nonpyramidal cells of neo- and allocortices, medium-sized cells of the caudate-putamen, nucleus accumbens, lateral part of the central nucleus of the amygdala, bed nucleus of the stria terminalis, preoptic area, and in sectors of nearly every hypothalamic nucleus and area, medial pretectal area, and nucleus of the optic tract, periaqueductal gray, raphe nuclei, cuneiform nucleus, sagulum, retrorubral nucleus, peripeduncular nucleus, lateral terminal nucleus, pedunculopontine nucleus, mesencephalic trigeminal nucleus, parabigeminal nucleus, dorsal nucleus of the lateral lemniscus, lateral superior olivary nucleus, superior paraolivary nucleus, medial superior olivary nucleus, ventral nucleus of the trapezoid body, lateral dorsal tegmental nucleus, accessory trigeminal nucleus, solitary nucleus, nucleus ambiguus, paratrigeminal nucleus, area postrema, lateral reticular nucleus, and ventrolateral region of the reticular formation. Fiber systems are present that conform to many of the known output systems of these nuclei, including major descending pathways (e.g., striatonigral, striatopallidal, reticulospinal, hypothalamospinal pathways), short projection systems (e.g., mossy fibers in hippocampus, hypothalamo-hypophyseal pathways), and local circuit pathways (e.g., in cortex, hypothalamus). The distribution of MERGL was, with a few notable exceptions, in the same nuclei as DYN B. From these neuroanatomical data, it appears that the dynorphin and enkephalin peptides are strategically located in brain regions that regulate extrapyramidal motor function, cardiovascular and water balance systems, eating, sensory processing, and pain perception.},
	number = {3},
	journal = {J. Comp. Neurol.},
	author = {Fallon, J H and Leslie, F M},
	month = jul,
	year = {1986},
	keywords = {merged\_fiete.bib},
	pages = {293--336.},
}

@article{gallistel_rat_2001,
	title = {The rat approximates an ideal detector of changes in rates of reward: implications for the law of effect},
	volume = {27},
	abstract = {Rats responded on 2 levers delivering brain stimulation reward on concurrent variable interval schedules. Following many successive sessions with unchanging relative rates of reward, subjects adjusted to an eventual change slowly and showed spontaneous reversions at the beginning of subsequent sessions. When changes in rates of reward occurred between and within every session, subjects adjusted to them about as rapidly as they could in principle do so, as shown by comparison to a Bayesian model of an ideal detector. This and other features of the adjustments to frequent changes imply that the behavioral effect of reinforcement depends on the subject's perception of incomes and changes in incomes rather than on the strengthening and weakening of behaviors in accord with their past effects or expected results. Models for the process by which perceived incomes determine stay durations and for the process that detects changes in rates are developed.},
	number = {4},
	journal = {J. Exp. Psychol. Anim. Behav. Process.},
	author = {Gallistel, C R and Mark, T A and King, A P and Latham, P E},
	month = oct,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {354--72.},
}

@article{nottebohm_central_1976,
	title = {Central control of song in the canary, {Serinus} canarius},
	volume = {165},
	abstract = {We have traced central nervous pathways controlling bird song in the canary using a combination of behavioral and anatomical techniques. Unilateral electrolytic brain lesions were made in adult male canaries whose song had been previously recorded and analysed on a sound spectrograph. After several days of postoperative recording, the birds were sacrificed and their brains processed histologically for degeneration staining with the Fink-Heimer technique. Although large lesions in the neostriatum and rostral hyperstriatum had no effect on song, severe song deficits followed damage to a discrete large-celled area in the caudal hyperstriatum ventrale (HVc). Degenerating fibers were traced from this region to two other discrete nuclei in the forebrain: one in the parolfactory lobe (area X, a teardrop-shaped small-celled nucleus); and a round large-celled nucleus in the archistriatum (RA). Unilateral lesion of X had no effect on song; lesions of RA, however, caused severe song deficits. Degenerating fibers from RA joined the occipitomesencephalic tract and had widespread ipsilateral projections to the thalamus, nucleus intercollicularis of the midbrain, reticular formation, and medulla. It is of particular interest that direct connections were found onto the cells of the motor nucleus innervating the syrinx, the organ of song production. Unilateral lesions of n. intercollicularis (previously implicated in the control of vocal behavior) had little effect on song. One bilateral lesion of HVc resulted in permanent (9 months) and complete elimination of the audible components of song, although the bird assumed the posture and movements typical of song. Preliminary data suggest that lesions of the left hemisphere result in greater deficits than lesions of the right one. This finding is consistent with earlier reports that the left syrinx controls the majority of song components. Results reported here suggest a localization of vocal control in the canary brain with an overlying left hemispheric dominance.},
	number = {4},
	journal = {J. Comp. Neurol.},
	author = {Nottebohm, F and Stokes, T M and Leonard, C M},
	month = feb,
	year = {1976},
	keywords = {merged\_fiete.bib},
	pages = {457--86.},
}

@article{collier_separable_1987,
	title = {Separable roles of hippocampal granule cells in forgetting and pyramidal cells in remembering spatial information},
	volume = {409},
	abstract = {To investigate the roles individual hippocampal cell groups play in processing of spatial information for memory, we administered low-intensity electrical stimulation to the granule cells, CA3 and CA1 pyramidal cells of the dorsal hippocampus at selected times before and after acquisition of the solution to a radial maze win-stay task. Stimulation of any of the 3 cells populations yielded a variable duration anterograde disruption of memory performance, while stimulation of dentate gyrus granule cells alone produced a declarative memory-specific retrograde amnesia. The amnestic effect of granule cell stimulation was not associated with after discharges in the hippocampus and was prevented by systemic administration of the opiate antagonist naloxone. Our results support the view that this electrical stimulus does not disrupt, but rather, activates the normal function of the granule cell system, resulting in erasure of information held in declarative memory. In contrast, similar activation of the pyramidal cell system does not yield retrograde amnesia, suggesting a normal role for these cells in promoting memory for spatial information.},
	number = {2},
	journal = {Brain Res.},
	author = {Collier, T J and Quirk, G J and Routtenberg, A},
	month = apr,
	year = {1987},
	keywords = {merged\_fiete.bib},
	pages = {316--28.},
}

@article{taube_head_1998,
	title = {Head direction cells and the neurophysiological basis for a sense of direction},
	volume = {55},
	abstract = {Animals require two types of fundamental information for accurate navigation: location and directional heading. Current theories hypothesize that animals maintain a neural representation, or cognitive map, of external space in the brain. Whereas cells in the rat hippocampus and parahippocampal regions encode information about location, a second type of allocentric spatial cell encodes information about the animal's directional heading, independent of the animal's on-going behaviors. These head direction (HD) cells are found in several areas of the classic Papez circuit. This review focuses on experimental studies conducted on HD cells and describes their discharge properties, functional significance, role in path integration, and responses to different environmental manipulations. The anterior dorsal thalamic nucleus appears critical for the generation of the directional signal. Both motor and vestibular cues also play important roles in the signal's processing. The neural network models proposed to account for HD cell firing are compared with known empirical findings. Examples from clinical cases of patients with topographical disorientation are also discussed. It is concluded that studying the neural mechanisms underlying the HD signal provides an excellent opportunity for understanding how the mammalian nervous system processes a high level cognitive signal.},
	number = {3},
	journal = {Prog. Neurobiol.},
	author = {Taube, J S},
	month = jun,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {225--56.},
}

@article{borst_visual_1988,
	title = {Visual information processing in the fly's landing system},
	volume = {163},
	abstract = {When approaching a landing site flies (Musca domestica) extend their legs in order to prevent crash-landing. Pattern expansion in front of a tethered fly can mimic an approach towards a landing site. Under these conditions landing is a rather stereotyped motor pattern. Only the latency of the onset of the landing response varies with the stimulus strength. Quantitative studies of the stimulus-latency relationship led to the formulation of a simple model which describes the way movement information at the fly's retina is processed in order to trigger landing. We propose that the output of local directionally selective movement detectors are spatially pooled and subsequently integrated in time. Whenever the level of this integrated signal reaches a fixed threshold landing is released.},
	journal = {J. Comp. Physiol. A},
	author = {Borst, Alexander and Bahde, Susanne},
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {167--173},
}

@article{hessler_singing-related_1999,
	title = {Singing-related neural activity in a dorsal forebrain-basal ganglia circuit of adult zebra finches},
	volume = {19},
	abstract = {The anterior forebrain pathway (AFP) of songbirds, a specialized dorsal forebrain-basal ganglia circuit, is crucial for song learning but has a less clear function in adults. We report here that neurons in two nuclei of the AFP, the lateral magnocellular nucleus of the anterior neostriatum (LMAN) and Area X, show marked changes in neurophysiological activity before and during singing in adult zebra finches. The presence of modulation before song output suggests that singing-related AFP activity originates, at least in part, in motor control nuclei. Some neurons in LMAN of awake birds also responded selectively to playback of the bird's own song, but neural activity during singing did not completely depend on auditory feedback in the short term, because neither the level nor the pattern of this activity was strongly affected by deafening. The singing-related activity of neurons in AFP nuclei of songbirds is consistent with a role of the AFP in adult singing or song maintenance, possibly related to the function of this circuit during initial song learning.},
	number = {23},
	journal = {J. Neurosci.},
	author = {Hessler, N A and Doupe, A J},
	month = dec,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {10461--81.},
}

@article{bardunias_three_2000,
	title = {Three dimensional path integration in the house mouse ({Mus} domestica)},
	volume = {87},
	abstract = {Previous studies have explored two-dimensional path integration in rodents by recording responses to passive rotation on a horizontal plane. This study adds the element of passive rotation in a vertical plane, necessitating the mouse to integrate positional information from three dimensions. Mice were trained to climb a wire mesh joining two horizontal planes. The whole arena was rotated 90 degrees while the mouse was vertically oriented as it moved between planes. Rotation was conducted both clockwise and counter-clockwise, controls being provided by rotation of the arena while the mouse was in its nest-box. All 16 mice tested altered their direction of travel subsequent to rotation in the vertical plane, compensating with a change in their path on the following horizontal plane.},
	number = {12},
	journal = {Naturwissenschaften},
	author = {Bardunias, P M and Jander, R},
	month = dec,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {532--4.},
}

@incollection{vaughan_choice_1982,
	title = {Choice and the {Rescorla}-{Wagner} {Model}},
	volume = {II},
	booktitle = {Quantitative {Analyses} of {Behavior}, {Volume} {II}: {Matching} and {Maximizing} {Accounts}},
	publisher = {Ballinger},
	author = {Vaughan, William and {Jr.}},
	editor = {Commons, M L and Herrnstein, R J and Rachlin, H},
	year = {1982},
	note = {Section: 12},
	keywords = {merged\_fiete.bib},
	pages = {263--279},
}

@article{kapoula_visually_1989,
	title = {Visually induced plasticity of postsaccadic ocular drift in normal humans},
	volume = {61},
	abstract = {1. Five human subjects viewed binocularly the interior of a full-field hemisphere filled with a random-dot pattern. During training, eye movements were recorded by the electrooculogram. A computer detected the end of every saccade and immediately moved the pattern horizontally either in the same or, in different experiments, the opposite direction as the saccade. The motion was exponential, its amplitude was 25\% of the horizontal component of the antecedent saccade, and its time constant was either 25, 50, or 100 ms in different experiments. Before and after 2-3 h of this experience, movements of both eyes were measured simultaneously by the eye-coil/magnetic-field method while subjects made saccades across the moveable pattern, looked between stationary targets, or made saccades in the dark, to see the effect of such adaptation on postsaccadic eye movements. 2. After 2-3 h (10,000-20,000 saccades) subjects developed a zero-latency, postsaccadic, ocular drift in the dark in the direction of the pattern motion. Three subjects were trained to backward drift, two to onward drift. Drift amplitude in the dark changed by 6\% of the saccade size (range: 2-11\%). The drift was exponential with an overall time constant of 108 ms. 3. After training, while viewing the adapting pattern motion, the change in the amplitude of the zero-latency drift was approximately 10\% (range: 6.5-14\%). 4. Increasing the time constant of the pattern motion produced significant increases in the time constant of the ocular drift. 5. The incidence of dynamic overshoot (a tiny, backward saccade immediately following a main saccade) was idiosyncratic and went up in some subjects and down in others with adaptation. These changes did not seem related to modifications of postsaccadic drift. 6. Normal human saccades are characterized by essentially no postsaccadic drift in the abducting eye and a pronounced onward drift (approximately 4\%) in the adducting eye. This adduction-adduction asymmetry is largely preserved through adaptation. Thus the changes in drift were conjugate and conformed to Hering's law of equal (change of) innervation. 7. These results agree with those previously demonstrated in the monkey and can similarly be explained by parametric changes in the pulse, slide, and step of normal saccadic innervation.},
	number = {5},
	journal = {J. Neurophysiol.},
	author = {Kapoula, Z and Optican, L M and Robinson, D A},
	month = may,
	year = {1989},
	keywords = {merged\_fiete.bib},
	pages = {879--91.},
}

@article{mainen_reliability_1995,
	title = {Reliability of spike timing in neocortical neurons},
	volume = {268},
	abstract = {It is not known whether the variability of neural activity in the cerebral cortex carries information or reflects noisy underlying mechanisms. In an examination of the reliability of spike generation using recordings from neurons in rat neocortical slices, the precision of spike timing was found to depend on stimulus transients. Constant stimuli led to imprecise spike trains, whereas stimuli with fluctuations resembling synaptic activity produced spike trains with timing reproducible to less than 1 millisecond. These data suggest a low intrinsic noise level in spike generation, which could allow cortical neurons to accurately transform synaptic input into spike sequences, supporting a possible role for spike timing in the processing of cortical information by the neocortex.},
	number = {5216},
	journal = {Science},
	author = {Mainen, Z F and Sejnowski, T J},
	month = jun,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {1503--6.},
}

@article{borst_temporal_1987,
	title = {Temporal {Modulation} of {Luminance} {Adapts} {Time} {Constant} of {Fly} {Movement} {Detectors}},
	volume = {56},
	abstract = {The time constant of movement detectors in the fly visual system has been proposed to adapt in response to moving stimuli (de Ruyter van Steveninck et al. 1986). The objective of the present study is to analyse, whether this adaptation can be induced as well, if the luminance of a stationary uniform field is modulated in time. The experiments were done on motion-sensitive wide-field neurones of the lobula plate, the posterior part of the third visual ganglion of the blowfly, 'Calliphora erythrocephala.' These cells are assumed to receive input from large retinotopic arrays of movement detectors. In order to demonstrate that our results concern the properties of the movement detectors rather than those of a particular wide-field cell we recorded from two different types of them, the H1- and the HSE-cell. Both cell types respond to a brief movement stimulus in their preferred direction with a transient excitation. This response decays about exponentially. The time constant of this decay reflects, in a first approximation, the time constant of the presynaptic movement detectors. It was determined after pre-stimulation of the cell by the following stimuli: (a) periodic stationary grating; (b) uniform field, the intensity of which was modulated sinusoidally in time (flicker stimulation); (c) periodic grating moving front-to-back; (d) periodic grating moving back-to-front. The decay of the response is significantly faster not only after movement but also after flicker stimulation as compared with pre-stimulation with a stationary stimulus. This is interpreted as an adaptation of the movement detector's time constant. The finding that flicker stimulation also leads to an adaptation shows that movement is not necessary for this process. Instead the adaptation of the time constant appears to be governed mainly by the temporal modulation (i.e., contrast frequency) of the signal in each visual channel.},
	journal = {Biol. Cybern.},
	author = {Borst, A and Egelhaaf, M},
	year = {1987},
	keywords = {merged\_fiete.bib},
	pages = {209--215},
}

@article{tanimoto_experimental_2004,
	title = {Experimental psychology: event timing turns punishment to reward},
	volume = {430},
	abstract = {Can relief from pain be a pleasure? If so, noxious events should–despite their typically aversive effects–also have a 'rewarding' after-effect. Through training fruitflies by using an electric shock paired with an odour, we show here that the shock can condition either avoidance of this odour or approach to it. These opposing behaviours depend on the relative timing of the shock and odour presentations during training, and indicate that a shock can act as either an aversive reinforcer or an appetitive one.},
	number = {7003},
	journal = {Nature},
	author = {Tanimoto, H and Heisenberg, M and Gerber, B},
	month = aug,
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {983.},
}

@article{miller_neural_1996,
	title = {Neural mechanisms of visual working memory in prefrontal cortex of the macaque},
	volume = {16},
	abstract = {Prefrontal (PF) cells were studied in monkeys performing a delayed matching to sample task, which requires working memory. The stimuli were complex visual patterns and to solve the task, the monkeys had to discriminate among the stimuli, maintain a memory of the sample stimulus during the delay periods, and evaluate whether a test stimulus matched the sample presented earlier in the trial. PF cells have properties consistent with a role in all three of these operations. Approximately 25\% of the cells responded selectively to different visual stimuli. Half of the cells showed heightened activity during the delay after the sample and, for many of these cells, the magnitude of delay activity was selective for different samples. Finally, more than half of the cells responded differently to the test stimuli depending on whether they matched the sample. Because inferior temporal (IT) cortex also is important for working memory, we compared PF cells with IT cells studied in the same task. Compared with IT cortex, PF responses were less often stimulus-selective but conveyed more information about whether a given test stimulus was a match to the sample. Furthermore, sample-selective delay activity in PF cortex was maintained throughout the trial even when other test stimuli intervened during the delay, whereas delay activity in IT cortex was disrupted by intervening stimuli. The results suggest that PF cortex plays a primary role in working memory tasks and may be a source of feedback inputs to IT cortex, biasing activity in favor of behaviorally relevant stimuli.},
	number = {16},
	journal = {J. Neurosci.},
	author = {Miller, E K and Erickson, C A and Desimone, R},
	month = aug,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {5154--5167},
}

@article{spitzer_oscillatory_2010,
	title = {Oscillatory correlates of vibrotactile frequency processing in human working memory},
	volume = {30},
	abstract = {Previous animal research has revealed neuronal activity underlying short-term retention of vibrotactile stimuli, providing evidence for a parametric representation of stimulus frequency in primate tactile working memory (Romo et al., 1999). Here, we investigated the neural correlates of vibrotactile frequency processing in human working memory, using noninvasive electroencephalography (EEG). Participants judged the frequencies of vibrotactile stimuli delivered to the fingertip in a delayed match-to-sample frequency discrimination task. As expected, vibrotactile stimulation elicited pronounced steady-state evoked potentials, which were source-localized in primary somatosensory cortex. Furthermore, parametric analysis of induced EEG responses revealed that the frequency of stimulation was reflected by systematic modulations of synchronized oscillatory activity in nonprimary cortical areas. Stimulus processing was accompanied by frequency-dependent alpha-band responses (8-12 Hz) over dorsal occipital cortex. The critical new finding was that, throughout the retention interval, the stimulus frequency held in working memory was systematically represented by a modulation in prefrontal beta activity (20-25 Hz), which was source-localized to the inferior frontal gyrus. This modulation in oscillatory activity during stimulus retention was related to successful frequency discrimination, thus reflecting behaviorally relevant information. Together, the results complement previous findings of parametric working memory correlates in nonhuman primates and suggest that the quantitative representation of vibrotactile frequency in sensory memory entails systematic modulations of synchronized neural activity in human prefrontal cortex.},
	number = {12},
	journal = {J. Neurosci.},
	author = {Spitzer, Bernhard and Wacker, Evelin and Blankenburg, Felix},
	month = mar,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {4496--4502},
}

@article{romo_neuronal_1999,
	title = {Neuronal correlates of parametric working memory in the prefrontal cortex},
	volume = {399},
	abstract = {Humans and monkeys have similar abilities to discriminate the difference in frequency between two mechanical vibrations applied sequentially to the fingertips. A key component of this sensory task is that the second stimulus is compared with the trace left by the first (base) stimulus, which must involve working memory. Where and how is this trace held in the brain? This question was investigated by recording from single neurons in the prefrontal cortex of monkeys while they performed the somatosensory discrimination task. Here we describe neurons in the inferior convexity of the prefrontal cortex whose discharge rates varied, during the delay period between the two stimuli, as a monotonic function of the base stimulus frequency. We describe this as 'monotonic stimulus encoding', and we suggest that the result may generalize: monotonic stimulus encoding may be the basic representation of one-dimensional sensory stimulus quantities in working memory. Thus we predict that other behavioural tasks that require ordinal comparisons between scalar analogue stimuli would give rise to monotonic responses similar to those reported here.},
	number = {6735},
	journal = {Nature},
	author = {Romo, R and Brody, C D and Hernández, A and Lemus, L},
	month = jun,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {470--473},
}

@article{martinez-conde_role_2004,
	title = {The role of fixational eye movements in visual perception},
	volume = {5},
	number = {3},
	journal = {Nat. Rev. Neurosci.},
	author = {Martinez-Conde, Susana and Macknik, Stephen L and Hubel, David H},
	month = mar,
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {229--240},
}

@article{churchland_variance_2011,
	title = {Variance as a signature of neural computations during decision making},
	volume = {69},
	abstract = {Traditionally, insights into neural computation have been furnished by averaged firing rates from many stimulus repetitions or trials. We pursue an analysis of neural response variance to unveil neural computations that cannot be discerned from measures of average firing rate. We analyzed single-neuron recordings from the lateral intraparietal area (LIP), during a perceptual decision-making task. Spike count variance was divided into two components using the law of total variance for doubly stochastic processes: (1) variance of counts that would be produced by a stochastic point process with a given rate, and loosely (2) the variance of the rates that would produce those counts (i.e., “conditional expectation”). The variance and correlation of the conditional expectation exposed several neural mechanisms: mixtures of firing rate states preceding the decision, accumulation of stochastic “evidence” during decision formation, and a stereotyped response at decision end. These analyses help to differentiate among several alternative decision-making models.},
	number = {4},
	journal = {Neuron},
	author = {Churchland, Anne K and Kiani, R and Chaudhuri, R and Wang, Xiao-Jing and Pouget, Alexandre and Shadlen, M N},
	month = feb,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {818--831},
}

@article{laurent_temporal_1996-1,
	title = {Temporal representations of odors in an olfactory network},
	volume = {16},
	abstract = {The study was designed to reveal occurrences of precise firing sequences (PFSs) in cortical activity and to test their behavioral relevance. Two monkeys were trained to perform a delayed-response paradigm and to open puzzle boxes. Extracellular activity was recorded from neurons in premotor and prefrontal areas with an array of six microelectrodes. An algorithm was developed to detect PFSs, defined as a set of three spikes and two intervals with a precision of +/-1 ms repeating significantly more than expected by chance. The expected level of repetition was computed based on the firing rate and the pairwise correlation of the participating units, assuming a Poisson distribution of event counts. Accordingly, the search for PFSs was corrected for rate modulations. PFSs were found in 24/25 recording sessions. Most PFSs (76\%) were composed of spikes of more than one unit but usually not more than two units (67\%). The PFSs spanned hundreds of milliseconds, and the average interval between two events within the PFSs was 200 ms. No traces of periodic oscillations were found in the PFS intervals. The bins of the matrix that were defined as PFSs were isolated temporally: the spikes that generated PFSs were not associated with high-frequency bursts or rapid coherent rate fluctuations. A given PFS tended to be correlated with the animal's behavior. Furthermore, for 19\% of the PFS pairs that shared the same unit composition, each member of the pair was associated with a different type of behavior. The PFSs often appeared in clusters that were associated with particular phases of the behavior. The firing rate of single units did not provide a full explanation for the timing and structure of these clusters. A reduced spike train (RST) was defined for each unit by taking all spikes of that unit that wereze odor responses in the olfactory system occur, at least in this animal, in parallel with a slower dynamic odor representation.},
	number = {12},
	journal = {J. Neurosci.},
	author = {Laurent, G and Wehr, M and Davidowitz, H},
	month = jun,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {3837--3847},
}

@article{keating_nonclock_1995-1,
	title = {Nonclock behavior of inferior olive neurons: {Interspike} interval of {Purkinje} cell complex spike discharge in the awake behaving monkey is random},
	volume = {73},
	abstract = {In instrumental learning, Thorndike's law of effect states tha clock, both showed a prominent peak at 10 Hz. However, the autocorrelograms and the Fourier transforms of the autocorrelogram functions failed to reveal a prominent periodicity for the actual discharge of any of cells, at any frequency up to 100 Hz: the discharge appeared random with respect to the interspike interval. The discharge was not random with respect to behavior. Complex spike activity was commonly time locked to the start of wrist movement. We examined this discharge to see whether oscillatory discharge could be seen after alignment of the data on the start of wrist movement, or after alignment of the data on the complex spike occurring peri-start of wrist movement. No oscillation was seen for either alignment. 3. The inferior olive, which sends its climbing fibers to the cerebellum, has been implicated in such different activities as 1) pathological tremor of the soft palate, 2) physiological tremor, 3) the normal initiation of all bodily movement, and 4) motor learning. Previous work in pharmacologically or surgically treated animals has shown that, under some conditions, the discharge of these neurons is periodic and synchronous. This firing pattern has been interpreted to support a role in the first two activities. But measurements reported here in the awake monkey show just the opposite: the discharge is aperiodic to the extent of being random. As such, the inferior olive cannot be a “motor clock” in the general role that has been proposed.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Keating, J G and Thach, W T},
	month = apr,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {1329--1340},
}

@article{hopfield_neural_1982-1,
	title = {Neural networks and physical systems with emergent collective computational abilities},
	volume = {79},
	abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.},
	number = {8},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Hopfield, J J},
	month = apr,
	year = {1982},
	keywords = {merged\_fiete.bib},
	pages = {2554--2558},
}

@article{geisler_optimal_2009,
	title = {Optimal stimulus encoders for natural tasks},
	volume = {9},
	abstract = {Determining the features of natural stimuli that are most useful for specific natural tasks is critical for understanding perceptual systems. A new approach is described that involves finding the optimal encoder for the natural task of interest, given a relatively small population of noisy “neurons” between the encoder and decoder. The optimal encoder, which necessarily specifies the most useful features, is found by maximizing accuracy in the natural task, where the decoder is the Bayesian ideal observer operating on the population responses. The approach is illustrated for a patch identification task, where the goal is to identify patches of natural image, and for a foreground identification task, where the goal is to identify which side of a natural surface boundary belongs to the foreground object. The optimal features (receptive fields) are intuitive and perform well in the two tasks. The approach also provides insight into general principles of neural encoding and decoding.},
	language = {eng},
	number = {13},
	journal = {J. Vis.},
	author = {Geisler, Wilson S and Najemnik, Jiri and Ing, Almon D},
	year = {2009},
	note = {Place: Center for Perceptual Systems and Department of Psychology, University of Texas at Austin, Austin, TX 78712, USA. geisler@psy.utexas.edu},
	keywords = {Humans, merged\_fiete.bib, Visual Perception/*physiology, Visual Cortex/*physiology, Photic Stimulation/methods, Visual Pathways/physiology, Bayes Theorem, Reaction Time/*physiology},
	pages = {17.1--16},
}

@article{jin_fast_2002,
	title = {Fast computation with spikes in a recurrent neural network},
	volume = {65},
	abstract = {Neural networks with recurrent connections are sometimes regarded as too slow at computation to serve as models of the brain. Here we analytically study a counterexample, a network consisting of N integrate-and-fire neurons with self excitation, all-to-all inhibition, instantaneous synaptic coupling, and constant external driving inputs. When the inhibition and/or excitation are large enough, the network performs a winner-take-all computation for all possible external inputs and initial states of the network. The computation is done very quickly: As soon as the winner spikes once, the computation is completed since no other neurons will spike. For some initial states, the winner is the first neuron to spike, and the computation is done at the first spike of the network. In general, there are M potential winners, corresponding to the top M external inputs. When the external inputs are close in magnitude, M tends to be larger. If M{\textgreater}1, the selection of the actual winner is strongly influenced by the initial states. If a special relation between the excitation and inhibition is satisfied, the network always selects the neuron with the maximum external input as the winner.},
	language = {eng},
	number = {5 Pt 1},
	journal = {Phys. Rev. E Stat. Nonlin. Soft Matter Phys.},
	author = {Jin, Dezhe Z and Seung, H Sebastian},
	year = {2002},
	note = {Place: Howard Hughes Medical Institute and Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA. djin@mit.edu},
	keywords = {merged\_fiete.bib},
	pages = {051922},
}

@article{shamir_temporal_2009,
	title = {The temporal winner-take-all readout},
	volume = {5},
	abstract = {How can the central nervous system make accurate decisions about external stimuli at short times on the basis of the noisy responses of nerve cell populations? It has been suggested that spike time latency is the source of fast decisions. Here, we propose a simple and fast readout mechanism, the temporal Winner-Take-All (tWTA), and undertake a study of its accuracy. The tWTA is studied in the framework of a statistical model for the dynamic response of a nerve cell population to an external stimulus. Each cell is characterized by a preferred stimulus, a unique value of the external stimulus for which it responds fastest. The tWTA estimate for the stimulus is the preferred stimulus of the cell that fired the first spike in the entire population. We then pose the questions: How accurate is the tWTA readout? What are the parameters that govern this accuracy? What are the effects of noise correlations and baseline firing? We find that tWTA sensitivity to the stimulus grows algebraically fast with the number of cells in the population, N, in contrast to the logarithmic slow scaling of the conventional rate-WTA sensitivity with N. Noise correlations in first-spike times of different cells can limit the accuracy of the tWTA readout, even in the limit of large N, similar to the effect that has been observed in population coding theory. We show that baseline firing also has a detrimental effect on tWTA accuracy. We suggest a generalization of the tWTA, the n-tWTA, which estimates the stimulus by the identity of the group of cells firing the first n spikes and show how this simple generalization can overcome the detrimental effect of baseline firing. Thus, the tWTA can provide fast and accurate responses discriminating between a small number of alternatives. High accuracy in estimation of a continuous stimulus can be obtained using the n-tWTA.},
	language = {eng},
	number = {2},
	journal = {PLoS Comput. Biol.},
	author = {Shamir, Maoz},
	year = {2009},
	note = {Place: Department of Physiology and the Zlotowski Center for Neuroscience, Ben-Gurion University of the Negev, Beer-Sheva, Israel. shmaoz@bgu.ac.il},
	keywords = {merged\_fiete.bib, *Models, Neurological, Models, Nerve Net/*physiology, Synaptic Transmission/physiology, Action Potentials/*physiology, Nonlinear Dynamics, Statistical, Neural Networks (Computer)},
	pages = {e1000286},
}

@article{mazurek_role_2003,
	title = {A role for neural integrators in perceptual decision making},
	volume = {13},
	abstract = {Decisions based on uncertain information may benefit from an accumulation of information over time. We asked whether such an accumulation process may underlie decisions about the direction of motion in a random dot kinetogram. To address this question we developed a computational model of the decision process using ensembles of neurons whose spiking activity mimics neurons recorded in the extrastriate visual cortex (area MT or V5) and a sensorimotor association area of the parietal lobe (area LIP). The model instantiates the hypothesis that neurons in sensorimotor association areas compute the time integral of sensory signals from the visual cortex, construed as evidence for or against a proposition, and that the decision is made when the integrated evidence reaches a threshold. The model explains a variety of behavioral and physiological measurements obtained from monkeys.},
	language = {eng},
	number = {11},
	journal = {Cereb. Cortex},
	author = {Mazurek, Mark E and Roitman, Jamie D and Ditterich, Jochen and Shadlen, Michael N},
	year = {2003},
	note = {Place: Howard Hughes Medical Institute, Department of Physiology and Biophysics, and National Primate Research Center, University of Washington, Seattle, WA 98195-7290, USA.},
	keywords = {Animals, merged\_fiete.bib, Perception/*physiology, Haplorhini, Visual Cortex/physiology, Discrimination (Psychology)/physiology, Action Potentials/*physiology, *Neural Networks (Computer), Decision Making/*physiology},
	pages = {1257--1269},
}

@article{maaswinkel_homing_1999-1,
	title = {Homing with locale, taxon, and dead reckoning strategies by foraging rats: sensory hierarchy in spatial navigation},
	volume = {99},
	abstract = {Studies on foraging rats suggest that they can use visual, olfactory, and self-movement cues for spatial guidance, but their relative reliance on these different cues is not well understood. In the present study, rats left a hidden refuge to search for a large food pellet located somewhere on a circular table, and the accuracy with which they returned to the refuge with the food pellet was measured. Cue use was manipulated by administering probe trials from novel locations, blindfolding, moving the home cage relative to the table, rotating the table and using combinations of these manipulations. When visual cues were available and a consistent starting location used, a visual strategy dominated performance. When blindfolded, the rats used olfactory cues from the surface of the table and from the starting hole. When olfactory stimuli were made uninformative, by changing the starting hole and rotating the table, the rats still homed accurately, suggesting they used self-movement cues. In a number of cue combinations, in which cues gave conflicting information, performance degraded. The results suggest that rats display a hierarchical preference in using visual, olfactory and self-movement cues while at the same time being able to reaffirm or switch between various cue combinations. The results are discussed in relation to ideas concerning the neural basis of spatial navigation.},
	language = {eng},
	number = {2},
	journal = {Behav. Brain Res.},
	author = {Maaswinkel, H and Whishaw, I Q},
	year = {1999},
	note = {Place: Department of Psychology and Neuroscience, University of Lethbridge, Alta, Canada.},
	keywords = {Animals, Vision, Rats, Female, merged\_fiete.bib, Cues, Orientation/*physiology, Long-Evans, Space Perception/*physiology, Smell/physiology, Movement/physiology, Feeding Behavior/*physiology, Food, Hearing/physiology, Ocular/physiology, Sensory Deprivation/physiology},
	pages = {143--152},
}

@article{van_hemmen_population_2008,
	title = {Population vector code: a geometric universal as actuator},
	volume = {98},
	abstract = {The population vector code relates directional tuning of single cells and global, directional motion incited by an assembly of neurons. In this paper three things are done. First, we analyze the population vector code as a purely geometric construct, focusing attention on its universality. Second, we generalize the algorithm on the basis of its geometrical realization so that the same construct that responds to sensation can function as an actuator for behavioral output. Third, we suggest at least a partial answer to the question of what many maps, neuronal representations of the outside sensory world in space-time, are good for: encoding vectorial input they enable a direct realization of the population vector code.},
	language = {eng},
	number = {6},
	journal = {Biol. Cybern.},
	author = {van Hemmen, J Leo and Schwartz, Andrew B},
	year = {2008},
	note = {Place: Physik Department, TU Munchen, 85747, Garching bei Munchen, Germany. lvh@tum.de},
	keywords = {Algorithms, Animals, merged\_fiete.bib, *Models, Action Potentials/physiology, Neurological, Animal/physiology, Behavior, Neurons/*physiology, Nerve Net/*physiology, Movement/*physiology, Sensation/*physiology},
	pages = {509--518},
}

@article{bennett_statistics_2000-1,
	title = {Statistics of transmitter release at nerve terminals},
	volume = {60},
	abstract = {This review presents an historical account of the developments of the statistical analysis of quantal transmission over the past half century and of the progress made in using this approach to reveal new properties of nerve terminals. In the early 1950s, Katz and his colleagues showed that evoked transmitter release occurred in quanta at the neuromuscular junction, opening up the study of transmitter release at nerve terminals to statistical analysis. In the subsequent two decades attempts were made to see if evoked quantal release could be described by binomial or compound binomial statistics, as originally suggested by Katz, and to relate the parameters of the statistic to various structures of the nerve terminal. During this period two hypotheses were enunciated, namely the 'vesicle hypothesis', which states that quanta arise as a consequence of the packaging of transmitter in vesicles; and the 'active zone hypothesis', which states that vesicles undergo exocytosis at discrete sites on the nerve terminal. Unsuccessful attempts were made to relate the binomial parameter n to the elements in these hypotheses, that is to the number of active zones possessed by the terminal or the number of vesicles available for release at these zones. This difficulty was part resolved in the late 1970s with the application of non-uniform binomial statistics to transmitter release from nerve terminals, in which n is the number of active zones each with their individual probabilities, p(j). Autocorrelation functions were subsequently introduced to detect if transmitter release is quantised at a particular nerve terminal. Statistical methods which would allow discrimination between different models of transmitter release over the active zones of a terminal were then developed. The introduction of maximum likelihood estimation procedures then allowed estimates to be made of the parameters in the statistical models of quantal release. The application of these procedures to experimental data from a variety of nerve terminals provided evidence for the concept that each synapse, taken as possessing a single active zone, possesses its own individual probability of secretion of a quantum by the exocytosis of a vesicle. In the late 1960s Stevens introduced the first stochastic approach to the analysis of the kinetics of the release of a quantum of transmitter at the neuromuscular junction following an impulse. In the subsequent decades this was developed into an explicit theory for the interaction of proteins involved in regulated exocytosis of a vesicle at an active zone. The parameters were the number of transition steps in the release process (k), each occurring at the same rate (alpha), with the possibility of each of these steps becoming blocked at the same rate (gamma). Maximum likelihood estimation procedures could then be used to obtain these parameter values. The discovery was made in the 1990s of the core proteins of the SNARE complex that govern regulated exocytosis. This offers the possibility in the near future of identifying the kinetic interaction of these proteins with the parameters of the stochastic process of exocytosis which confer a particular probability on individual synapses.},
	language = {eng},
	number = {6},
	journal = {Prog. Neurobiol.},
	author = {Bennett, M R and Kearns, J L},
	year = {2000},
	note = {Place: Department of Physiology, Institute for Biomedical Research, University of Sydney, NSW, Australia. maxb@physiol.usyd.edu.au},
	keywords = {Animals, merged\_fiete.bib, *Models, Neurological, Likelihood Functions, Kinetics, Nerve Endings/*metabolism, Neuromuscular Junction/metabolism, Neurotransmitter Agents/*metabolism},
	pages = {545--606},
}

@article{stringer_self-organizing_2005-1,
	title = {Self-organizing continuous attractor network models of hippocampal spatial view cells},
	volume = {83},
	abstract = {Single neuron recording studies have demonstrated the existence of hippocampal spatial view neurons which encode information about the spatial location at which a primate is looking in the environment. These neurons are able to maintain their firing even in the absence of visual input. The standard neuronal network approach to model networks with memory that represent continuous spaces is that of continuous attractor networks. It has recently been shown how idiothetic (self-motion) inputs could update the activity packet of neuronal firing for a one-dimensional case (head direction cells), and for a two-dimensional case (place cells which represent the place where a rat is located). In this paper, we describe three models of primate hippocampal spatial view cells, which not only maintain their spatial firing in the absence of visual input, but can also be updated in the dark by idiothetic input. The three models presented in this paper represent different ways in which a continuous attractor network could integrate a number of different kinds of velocity signal (e.g., head rotation and eye movement) simultaneously. The first two models use velocity information from head angular velocity and from eye velocity cells, and make use of a continuous attractor network to integrate this information. A fundamental feature of the first two models is their use of a 'memory trace' learning rule which incorporates a form of temporal average of recent cell activity. Rules of this type are able to build associations between different patterns of neural activities that tend to occur in temporal proximity, and are incorporated in the model to enable the recent change in the continuous attractor to be associated with the contemporaneous idiothetic input. The third model uses positional information from head direction cells and eye position cells to update the representation of where the agent is looking in the dark. In this case the integration of idiothetic velocity signals is performed in the earlier layer of head direction cells.},
	language = {eng},
	number = {1},
	journal = {Neurobiol. Learn. Mem.},
	author = {Stringer, S M and Rolls, E T and Trappenberg, T P},
	year = {2005},
	note = {Place: Department of Experimental Psychology, Centre for Computational Neuroscience, Oxford University, South Parks Road, Oxford OX1 3UD, UK.},
	keywords = {merged\_fiete.bib},
	pages = {79--92},
}

@article{baum_internal_1988-1,
	title = {Internal representations for associative memory},
	volume = {59},
	abstract = {We describe a class of feed forward neural network models for associative content addressable memory (ACAM) which utilize sparse internal representations for stored data. In addition to the input and output layers, our networks incorporate an intermediate processing layer which serves to label each stored memory and to perform error correction and association. We study two classes of internal label representations: the unary representation and various sparse, distributed representations. Finally, we consider storage of sparse data and sparsification of data. These models are found to have advantages in terms of storage capacity, hardware efficiency, and recall reliability when compared to the Hopfield model, and to possess analogies to both biological neural networks and standard digital computer memories.},
	number = {4},
	journal = {Biol. Cybern.},
	author = {Baum, E and Moody, J and Wilczek, F},
	month = jul,
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {217--228},
}

@article{hopfield_neural_nodate,
	title = {Neural networks and physical systems with emergent collective computational abilities},
	volume = {79},
	abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.},
	number = {8},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Hopfield, J J},
	keywords = {merged\_fiete.bib},
	pages = {2554--2558},
}

@article{usher_time_2001,
	title = {The time course of perceptual choice: the leaky, competing accumulator model},
	volume = {108},
	abstract = {The time course of perceptual choice is discussed in a model of gradual, leaky, stochastic, and competitive information accumulation in nonlinear decision units. Special cases of the model match a classical diffusion process, but leakage and competition work together to address several challenges to existing diffusion, random walk, and accumulator models. The model accounts for data from choice tasks using both time-controlled (e.g., response signal) and standard reaction time paradigms and its adequacy compares favorably with other approaches. A new paradigm that controls the time of arrival of information supporting different choice alternatives provides further support. The model captures choice behavior regardless of the number of alternatives, accounting for the log-linear relation between reaction time and number of alternatives (Hick's law) and explains a complex pattern of visual and contextual priming in visual word identification.},
	number = {3},
	journal = {Psychol. Rev.},
	author = {Usher, M and McClelland, J L},
	month = jul,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {550--592},
}

@article{itskov_short-term_2011,
	title = {Short-{Term} {Facilitation} may {Stabilize} {Parametric} {Working} {Memory} {Trace}},
	volume = {5},
	abstract = {Networks with continuous set of attractors are considered to be a paradigmatic model for parametric working memory (WM), but require fine tuning of connections and are thus structurally unstable. Here we analyzed the network with ring attractor, where connections are not perfectly tuned and the activity state therefore drifts in the absence of the stabilizing stimulus. We derive an analytical expression for the drift dynamics and conclude that the network cannot function as WM for a period of several seconds, a typical delay time in monkey memory experiments. We propose that short-term synaptic facilitation in recurrent connections significantly improves the robustness of the model by slowing down the drift of activity bump. Extending the calculation of the drift velocity to network with synaptic facilitation, we conclude that facilitation can slow down the drift by a large factor, rendering the network suitable as a model of WM.},
	journal = {Front. Comput. Neurosci.},
	author = {Itskov, Vladimir and Hansel, David and Tsodyks, Misha},
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {40},
}

@article{boerlin_spike-based_2011,
	title = {Spike-based population coding and working memory},
	volume = {7},
	abstract = {Compelling behavioral evidence suggests that humans can make optimal decisions despite the uncertainty inherent in perceptual or motor tasks. A key question in neuroscience is how populations of spiking neurons can implement such probabilistic computations. In this article, we develop a comprehensive framework for optimal, spike-based sensory integration and working memory in a dynamic environment. We propose that probability distributions are inferred spike-per-spike in recurrently connected networks of integrate-and-fire neurons. As a result, these networks can combine sensory cues optimally, track the state of a time-varying stimulus and memorize accumulated evidence over periods much longer than the time constant of single neurons. Importantly, we propose that population responses and persistent working memory states represent entire probability distributions and not only single stimulus values. These memories are reflected by sustained, asynchronous patterns of activity which make relevant information available to downstream neurons within their short time window of integration. Model neurons act as predictive encoders, only firing spikes which account for new information that has not yet been signaled. Thus, spike times signal deterministically a prediction error, contrary to rate codes in which spike times are considered to be random samples of an underlying firing rate. As a consequence of this coding scheme, a multitude of spike patterns can reliably encode the same information. This results in weakly correlated, Poisson-like spike trains that are sensitive to initial conditions but robust to even high levels of external neural noise. This spike train variability reproduces the one observed in cortical sensory spike trains, but cannot be equated to noise. On the contrary, it is a consequence of optimal spike-based inference. In contrast, we show that rate-based models perform poorly when implemented with stochastically spiking neurons.},
	number = {2},
	journal = {PLoS Comput. Biol.},
	author = {Boerlin, Martin and Denève, Sophie},
	month = feb,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {e1001080},
}

@article{plesser_noise_2000,
	title = {Noise in integrate-and-fire neurons: from stochastic input to escape rates},
	volume = {12},
	abstract = {We analyze the effect of noise in integrate-and-fire neurons driven by time-dependent input and compare the diffusion approximation for the membrane potential to escape noise. It is shown that for time-dependent subthreshold input, diffusive noise can be replaced by escape noise with a hazard function that has a gaussian dependence on the distance between the (noise-free) membrane voltage and threshold. The approximation is improved if we add to the hazard function a probability current proportional to the derivative of the voltage. Stochastic resonance in response to periodic input occurs in both noise models and exhibits similar characteristics.},
	number = {2},
	journal = {Neural Comput.},
	author = {Plesser, H E and Gerstner, W},
	month = feb,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {367--384},
}

@article{goldman_robust_2003,
	title = {Robust persistent neural activity in a model integrator with multiple hysteretic dendrites per neuron},
	volume = {13},
	number = {11},
	journal = {Cereb. Cortex},
	author = {Goldman, M S and Levine, J H and Major, G and Tank, D W and Seung, H S},
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {1185--1195},
}

@article{brody_basic_2003,
	title = {Basic mechanisms for graded persistent activity: discrete attractors, continuous attractors, and dynamic representations},
	volume = {13},
	abstract = {Persistent neural activity is observed in many systems, and is thought to be a neural substrate for holding memories over time delays of a few seconds. Recent work has addressed two issues. First, how can networks of neurons robustly hold such an active memory? Computer systems obtain significant robustness to noise by approximating analogue quantities with discrete digital representations. In a similar manner, theoretical models of persistent activity in spiking neurons have shown that the most robust and stable way to store the short-term memory of a continuous parameter is to approximate it with a discrete representation. This general idea applies very broadly to mechanisms that range from biochemical networks to single cells and to large circuits of neurons. Second, why is it commonly observed that persistent activity in the cortex can be strongly time-varying? This observation is almost ubiquitous, and therefore must be taken into account in our models and our understanding of how short-term memories are held in the cortex.},
	number = {2},
	journal = {Curr. Opin. Neurobiol.},
	author = {Brody, Carlos D and Romo, Ranulfo and Kepecs, Adam},
	month = apr,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {204--211},
}

@article{boucheny_continuous_2005,
	title = {A continuous attractor network model without recurrent excitation: maintenance and integration in the head direction cell system},
	volume = {18},
	abstract = {Motivated by experimental observations of the head direction system, we study a three population network model that operates as a continuous attractor network. This network is able to store in a short-term memory an angular variable (the head direction) as a spatial profile of activity across neurons in the absence of selective external inputs, and to accurately update this variable on the basis of angular velocity inputs. The network is composed of one excitatory population and two inhibitory populations, with inter-connections between populations but no connections within the neurons of a same population. In particular, there are no excitatory-to-excitatory connections. Angular velocity signals are represented as inputs in one inhibitory population (clockwise turns) or the other (counterclockwise turns). The system is studied using a combination of analytical and numerical methods. Analysis of a simplified model composed of threshold-linear neurons gives the conditions on the connectivity for (i) the emergence of the spatially selective profile, (ii) reliable integration of angular velocity inputs, and (iii) the range of angular velocities that can be accurately integrated by the model. Numerical simulations allow us to study the proposed scenario in a large network of spiking neurons and compare their dynamics with that of head direction cells recorded in the rat limbic system. In particular, we show that the directional representation encoded by the attractor network can be rapidly updated by external cues, consistent with the very short update latencies observed experimentally by Zugaro et al. (2003) in thalamic head direction cells.},
	number = {2},
	journal = {J. Comput. Neurosci.},
	author = {Boucheny, Christian and Brunel, Nicolas and Arleo, Angelo},
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {205--227},
}

@article{bogacz_physics_2006,
	title = {The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced-choice tasks},
	volume = {113},
	abstract = {In this article, the authors consider optimal decision making in two-alternative forced-choice (TAFC) tasks. They begin by analyzing 6 models of TAFC decision making and show that all but one can be reduced to the drift diffusion model, implementing the statistically optimal algorithm (most accurate for a given speed or fastest for a given accuracy). They prove further that there is always an optimal trade-off between speed and accuracy that maximizes various reward functions, including reward rate (percentage of correct responses per unit time), as well as several other objective functions, including ones weighted for accuracy. They use these findings to address empirical data and make novel predictions about performance under optimality.},
	number = {4},
	journal = {Psychol. Rev.},
	author = {Bogacz, Rafal and Brown, Eric and Moehlis, Jeff and Holmes, Philip and Cohen, Jonathan D},
	month = oct,
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {700--765},
}

@article{fung_moving_2010,
	title = {A moving bump in a continuous manifold: a comprehensive study of the tracking dynamics of continuous attractor neural networks},
	volume = {22},
	abstract = {Understanding how the dynamics of a neural network is shaped by the network structure and, consequently, how the network structure facilitates the functions implemented by the neural system is at the core of using mathematical models to elucidate brain functions. This study investigates the tracking dynamics of continuous attractor neural networks (CANNs). Due to the translational invariance of neuronal recurrent interactions, CANNs can hold a continuous family of stationary states. They form a continuous manifold in which the neural system is neutrally stable. We systematically explore how this property facilitates the tracking performance of a CANN, which is believed to have clear correspondence with brain functions. By using the wave functions of the quantum harmonic oscillator as the basis, we demonstrate how the dynamics of a CANN is decomposed into different motion modes, corresponding to distortions in the amplitude, position, width, or skewness of the network state. We then develop a perturbation approach that utilizes the dominating movement of the network's stationary states in the state space. This method allows us to approximate the network dynamics up to an arbitrary accuracy depending on the order of perturbation used. We quantify the distortions of a gaussian bump during tracking and study their effects on tracking performance. Results are obtained on the maximum speed for a moving stimulus to be trackable and the reaction time for the network to catch up with an abrupt change in the stimulus.},
	number = {3},
	journal = {Neural Comput.},
	author = {Fung, C C Alan and Wong, K Y Michael and Wu, Si},
	month = mar,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {752--792},
}

@article{wu_dynamics_2008,
	title = {Dynamics and computation of continuous attractors},
	volume = {20},
	abstract = {Continuous attractor is a promising model for describing the encoding of continuous stimuli in neural systems. In a continuous attractor, the stationary states of the neural system form a continuous parameter space, on which the system is neutrally stable. This property enables the neutral system to track time-varying stimuli smoothly, but it also degrades the accuracy of information retrieval, since these stationary states are easily disturbed by external noise. In this work, based on a simple model, we systematically investigate the dynamics and the computational properties of continuous attractors. In order to analyze the dynamics of a large-size network, which is otherwise extremely complicated, we develop a strategy to reduce its dimensionality by utilizing the fact that a continuous attractor can eliminate the noise components perpendicular to the attractor space very quickly. We therefore project the network dynamics onto the tangent of the attractor space and simplify it successfully as a one-dimensional Ornstein-Uhlenbeck process. Based on this simplified model, we investigate (1) the decoding error of a continuous attractor under the driving of external noisy inputs, (2) the tracking speed of a continuous attractor when external stimulus experiences abrupt changes, (3) the neural correlation structure associated with the specific dynamics of a continuous attractor, and (4) the consequence of asymmetric neural correlation on statistical population decoding. The potential implications of these results on our understanding of neural information processing are also discussed.},
	number = {4},
	journal = {Neural Comput.},
	author = {Wu, Si and Hamaguchi, Kosuke and Amari, Shun-Ichi},
	month = apr,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {994--1025},
}

@article{mettetal_predicting_2006,
	title = {Predicting stochastic gene expression dynamics in single cells},
	volume = {103},
	abstract = {Fluctuations in protein numbers (noise) due to inherent stochastic effects in single cells can have large effects on the dynamic behavior of gene regulatory networks. Although deterministic models can predict the average network behavior, they fail to incorporate the stochasticity characteristic of gene expression, thereby limiting their relevance when single cell behaviors deviate from the population average. Recently, stochastic models have been used to predict distributions of steady-state protein levels within a population but not to predict the dynamic, presteady-state distributions. In the present work, we experimentally examine a system whose dynamics are heavily influenced by stochastic effects. We measure population distributions of protein numbers as a function of time in the Escherichia coli lactose uptake network (lac operon). We then introduce a dynamic stochastic model and show that prediction of dynamic distributions requires only a few noise parameters in addition to the rates that characterize a deterministic model. Whereas the deterministic model cannot fully capture the observed behavior, our stochastic model correctly predicts the experimental dynamics without any fit parameters. Our results provide a proof of principle for the possibility of faithfully predicting dynamic population distributions from deterministic models supplemented by a stochastic component that captures the major noise sources.},
	number = {19},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Mettetal, Jerome T and Muzzey, Dale and Pedraza, Juan M and Ozbudak, Ertugrul M and van Oudenaarden, Alexander},
	month = may,
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {7304--7309},
}

@article{rosenfeld_gene_2005,
	title = {Gene regulation at the single-cell level},
	volume = {307},
	abstract = {The quantitative relation between transcription factor concentrations and the rate of protein production from downstream genes is central to the function of genetic networks. Here we show that this relation, which we call the gene regulation function (GRF), fluctuates dynamically in individual living cells, thereby limiting the accuracy with which transcriptional genetic circuits can transfer signals. Using fluorescent reporter genes and fusion proteins, we characterized the bacteriophage lambda promoter P(R) in Escherichia coli. A novel technique based on binomial errors in protein partitioning enabled calibration of in vivo biochemical parameters in molecular units. We found that protein production rates fluctuate over a time scale of about one cell cycle, while intrinsic noise decays rapidly. Thus, biochemical parameters, noise, and slowly varying cellular states together determine the effective single-cell GRF. These results can form a basis for quantitative modeling of natural gene circuits and for design of synthetic ones.},
	number = {5717},
	journal = {Science},
	author = {Rosenfeld, Nitzan and Young, Jonathan W and Alon, Uri and Swain, Peter S and Elowitz, Michael B},
	month = mar,
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {1962--1965},
}

@article{gregor_probing_2007,
	title = {Probing the limits to positional information},
	volume = {130},
	abstract = {The reproducibility and precision of biological patterning is limited by the accuracy with which concentration profiles of morphogen molecules can be established and read out by their targets. We consider four measures of precision for the Bicoid morphogen in the Drosophila embryo: the concentration differences that distinguish neighboring cells, the limits set by the random arrival of Bicoid molecules at their targets (which depends on absolute concentration), the noise in readout of Bicoid by the activation of Hunchback, and the reproducibility of Bicoid concentration at corresponding positions in multiple embryos. We show, through a combination of different experiments, that all of these quantities are approximately 10\%. This agreement among different measures of accuracy indicates that the embryo is not faced with noisy input signals and readout mechanisms; rather, the system exerts precise control over absolute concentrations and responds reliably to small concentration differences, approaching the limits set by basic physical principles.},
	number = {1},
	journal = {Cell},
	author = {Gregor, Thomas and Tank, David W and Wieschaus, Eric F and Bialek, William},
	month = jul,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {153--164},
}

@article{elowitz_stochastic_2002,
	title = {Stochastic gene expression in a single cell},
	volume = {297},
	abstract = {Clonal populations of cells exhibit substantial phenotypic variation. Such heterogeneity can be essential for many biological processes and is conjectured to arise from stochasticity, or noise, in gene expression. We constructed strains of Escherichia coli that enable detection of noise and discrimination between the two mechanisms by which it is generated. Both stochasticity inherent in the biochemical process of gene expression (intrinsic noise) and fluctuations in other cellular components (extrinsic noise) contribute substantially to overall variation. Transcription rate, regulatory dynamics, and genetic factors control the amplitude of noise. These results establish a quantitative foundation for modeling noise in genetic networks and reveal how low intracellular copy numbers of molecules can fundamentally limit the precision of gene regulation.},
	number = {5584},
	journal = {Science},
	author = {Elowitz, Michael B and Levine, Arnold J and Siggia, Eric D and Swain, Peter S},
	month = aug,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {1183--1186},
}

@article{ginzburg_theory_1994,
	title = {Theory of correlations in stochastic neural networks},
	volume = {50},
	number = {4},
	journal = {Phys. Rev. E Stat. Phys. Plasmas Fluids Relat. Interdiscip. Topics},
	author = {Ginzburg, I and {Sompolinsky}},
	month = oct,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {3171--3191},
}

@article{wong_neural_2007,
	title = {Neural circuit dynamics underlying accumulation of time-varying evidence during perceptual decision making},
	volume = {1},
	abstract = {How do neurons in a decision circuit integrate time-varying signals, in favor of or against alternative choice options? To address this question, we used a recurrent neural circuit model to simulate an experiment in which monkeys performed a direction-discrimination task on a visual motion stimulus. In a recent study, it was found that brief pulses of motion perturbed neural activity in the lateral intraparietal area (LIP), and exerted corresponding effects on the monkey's choices and response times. Our model reproduces the behavioral observations and replicates LIP activity which, depending on whether the direction of the pulse is the same or opposite to that of a preferred motion stimulus, increases or decreases persistently over a few hundred milliseconds. Furthermore, our model accounts for the observation that the pulse exerts a weaker influence on LIP neuronal responses when the pulse is late relative to motion stimulus onset. We show that this violation of time-shift invariance (TSI) is consistent with a recurrent circuit mechanism of time integration. We further examine time integration using two consecutive pulses of the same or opposite motion directions. The induced changes in the performance are not additive, and the second of the paired pulses is less effective than its standalone impact, a prediction that is experimentally testable. Taken together, these findings lend further support for an attractor network model of time integration in perceptual decision making.},
	journal = {Front. Comput. Neurosci.},
	author = {Wong, Kong-Fatt and Huk, Alexander C and Shadlen, Michael N and Wang, Xiao-Jing},
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {6},
}

@article{walczak_optimizing_2010,
	title = {Optimizing information flow in small genetic networks. {II}. {Feed}-forward interactions},
	volume = {81},
	abstract = {Central to the functioning of a living cell is its ability to control the readout or expression of information encoded in the genome. In many cases, a single transcription factor protein activates or represses the expression of many genes. As the concentration of the transcription factor varies, the target genes thus undergo correlated changes, and this redundancy limits the ability of the cell to transmit information about input signals. We explore how interactions among the target genes can reduce this redundancy and optimize information transmission. Our discussion builds on recent work [Tkacik, Phys. Rev. E 80, 031920 (2009)], and there are connections to much earlier work on the role of lateral inhibition in enhancing the efficiency of information transmission in neural circuits; for simplicity we consider here the case where the interactions have a feed forward structure, with no loops. Even with this limitation, the networks that optimize information transmission have a structure reminiscent of the networks found in real biological systems.},
	number = {4 Pt 1},
	journal = {Phys. Rev. E Stat. Nonlin. Soft Matter Phys.},
	author = {Walczak, Aleksandra M and Tkacik, Gasper and Bialek, William},
	month = apr,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {041905},
}

@article{tkacik_optimizing_2009,
	title = {Optimizing information flow in small genetic networks},
	volume = {80},
	abstract = {In order to survive, reproduce, and (in multicellular organisms) differentiate, cells must control the concentrations of the myriad different proteins that are encoded in the genome. The precision of this control is limited by the inevitable randomness of individual molecular events. Here we explore how cells can maximize their control power in the presence of these physical limits; formally, we solve the theoretical problem of maximizing the information transferred from inputs to outputs when the number of available molecules is held fixed. We start with the simplest version of the problem, in which a single transcription factor protein controls the readout of one or more genes by binding to DNA. We further simplify by assuming that this regulatory network operates in steady state, that the noise is small relative to the available dynamic range, and that the target genes do not interact. Even in this simple limit, we find a surprisingly rich set of optimal solutions. Importantly, for each locally optimal regulatory network, all parameters are determined once the physical constraints on the number of available molecules are specified. Although we are solving an oversimplified version of the problem facing real cells, we see parallels between the structure of these optimal solutions and the behavior of actual genetic regulatory networks. Subsequent papers will discuss more complete versions of the problem.},
	number = {3 Pt 1},
	journal = {Phys. Rev. E Stat. Nonlin. Soft Matter Phys.},
	author = {Tkacik, Gasper and Walczak, Aleksandra M and Bialek, William},
	month = sep,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {031920},
}

@article{white_short-term_2004,
	title = {Short-term memory in orthogonal neural networks},
	volume = {92},
	abstract = {We study the ability of linear recurrent networks obeying discrete time dynamics to store long temporal sequences that are retrievable from the instantaneous state of the network. We calculate this temporal memory capacity for both distributed shift register and random orthogonal connectivity matrices. We show that the memory capacity of these networks scales with system size.},
	number = {14},
	journal = {Phys. Rev. Lett.},
	author = {White, Olivia L and Lee, Daniel D and Sompolinsky, Haim},
	month = apr,
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {148102},
}

@article{ganguli_memory_2008,
	title = {Memory traces in dynamical systems},
	volume = {105},
	abstract = {To perform nontrivial, real-time computations on a sensory input stream, biological systems must retain a short-term memory trace of their recent inputs. It has been proposed that generic high-dimensional dynamical systems could retain a memory trace for past inputs in their current state. This raises important questions about the fundamental limits of such memory traces and the properties required of dynamical systems to achieve these limits. We address these issues by applying Fisher information theory to dynamical systems driven by time-dependent signals corrupted by noise. We introduce the Fisher Memory Curve (FMC) as a measure of the signal-to-noise ratio (SNR) embedded in the dynamical state relative to the input SNR. The integrated FMC indicates the total memory capacity. We apply this theory to linear neuronal networks and show that the capacity of networks with normal connectivity matrices is exactly 1 and that of any network of N neurons is, at most, N. A nonnormal network achieving this bound is subject to stringent design constraints: It must have a hidden feedforward architecture that superlinearly amplifies its input for a time of order N, and the input connectivity must optimally match this architecture. The memory capacity of networks subject to saturating nonlinearities is further limited, and cannot exceed square root N. This limit can be realized by feedforward structures with divergent fan out that distributes the signal across neurons, thereby avoiding saturation. We illustrate the generality of the theory by showing that memory in fluid systems can be sustained by transient nonnormal amplification due to convective instability or the onset of turbulence.},
	number = {48},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Ganguli, Surya and Huh, Dongsung and Sompolinsky, Haim},
	month = dec,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {18970--18975},
}

@article{miller_recurrent_2003,
	title = {A recurrent network model of somatosensory parametric working memory in the prefrontal cortex},
	volume = {13},
	abstract = {A parametric working memory network stores the information of an analog stimulus in the form of persistent neural activity that is monotonically tuned to the stimulus. The family of persistent firing patterns with a continuous range of firing rates must all be realizable under exactly the same external conditions (during the delay when the transient stimulus is withdrawn). How this can be accomplished by neural mechanisms remains an unresolved question. Here we present a recurrent cortical network model of irregularly spiking neurons that was designed to simulate a somatosensory working memory experiment with behaving monkeys. Our model reproduces the observed positively and negatively monotonic persistent activity, and heterogeneous tuning curves of memory activity. We show that fine-tuning mathematically corresponds to a precise alignment of cusps in the bifurcation diagram of the network. Moreover, we show that the fine-tuned network can integrate stimulus inputs over several seconds. Assuming that such time integration occurs in neural populations downstream from a tonically persistent neural population, our model is able to account for the slow ramping-up and ramping-down behaviors of neurons observed in prefrontal cortex.},
	number = {11},
	journal = {Cereb. Cortex},
	author = {Miller, Paul and Brody, Carlos D and Romo, Ranulfo and Wang, Xiao-Jing},
	month = nov,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {1208--1218},
}

@article{machens_design_2008,
	title = {Design of continuous attractor networks with monotonic tuning using a symmetry principle},
	volume = {20},
	abstract = {Neurons that sustain elevated firing in the absence of stimuli have been found in many neural systems. In graded persistent activity, neurons can sustain firing at many levels, suggesting a widely found type of network dynamics in which networks can relax to any one of a continuum of stationary states. The reproduction of these findings in model networks of nonlinear neurons has turned out to be nontrivial. A particularly insightful model has been the “bump attractor,” in which a continuous attractor emerges through an underlying symmetry in the network connectivity matrix. This model, however, cannot account for data in which the persistent firing of neurons is a monotonic – rather than a bell-shaped – function of a stored variable. Here, we show that the symmetry used in the bump attractor network can be employed to create a whole family of continuous attractor networks, including those with monotonic tuning. Our design is based on tuning the external inputs to networks that have a connectivity matrix with Toeplitz symmetry. In particular, we provide a complete analytical solution of a line attractor network with monotonic tuning and show that for many other networks, the numerical tuning of synaptic weights reduces to the computation of a single parameter.},
	number = {2},
	journal = {Neural Comput.},
	author = {Machens, Christian K and Brody, Carlos D},
	month = feb,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {452--485},
}

@article{goldman_memory_2009,
	title = {Memory without feedback in a neural network},
	volume = {61},
	abstract = {Memory storage on short timescales is thought to be maintained by neuronal activity that persists after the remembered stimulus is removed. Although previous work suggested that positive feedback is necessary to maintain persistent activity, here it is demonstrated how neuronal responses can instead be maintained by a purely feedforward mechanism in which activity is passed sequentially through a chain of network states. This feedforward form of memory storage is shown to occur both in architecturally feedforward networks and in recurrent networks that nevertheless function in a feedforward manner. The networks can be tuned to be perfect integrators of their inputs or to reproduce the time-varying firing patterns observed during some working memory tasks but not easily reproduced by feedback-based attractor models. This work illustrates a mechanism for maintaining short-term memory in which both feedforward and feedback processes interact to govern network behavior.},
	number = {4},
	journal = {Neuron},
	author = {Goldman, Mark S},
	month = feb,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {621--634},
}

@article{bethge_optimal_2002,
	title = {Optimal short-term population coding: when {Fisher} information fails},
	volume = {14},
	abstract = {Efficient coding has been proposed as a first principle explaining neuronal response properties in the central nervous system. The shape of optimal codes, however, strongly depends on the natural limitations of the particular physical system. Here we investigate how optimal neuronal encoding strategies are influenced by the finite number of neurons N (place constraint), the limited decoding time window length T (time constraint), the maximum neuronal firing rate f(max) (power constraint), and the maximal average rate (f)(max) (energy constraint). While Fisher information provides a general lower bound for the mean squared error of unbiased signal reconstruction, its use to characterize the coding precision is limited. Analyzing simple examples, we illustrate some typical pitfalls and thereby show that Fisher information provides a valid measure for the precision of a code only if the dynamic range (f(min)T, f(max)T) is sufficiently large. In particular, we demonstrate that the optimal width of gaussian tuning curves depends on the available decoding time T. Within the broader class of unimodal tuning functions, it turns out that the shape of a Fisher-optimal coding scheme is not unique. We solve this ambiguity by taking the minimum mean square error into account, which leads to flat tuning curves. The tuning width, however, remains to be determined by energy constraints rather than by the principle of efficient coding.},
	language = {eng},
	number = {10},
	journal = {Neural Comput.},
	author = {Bethge, M and Rotermund, D and Pawelzik, K},
	year = {2002},
	note = {Place: Institute of Theoretical Physics, University of Bremen, Bremen, D-28334 Germany. mbethge@physik.uni-bremen.de},
	keywords = {merged\_fiete.bib, *Models, Neurological, Neurons/*physiology, Artifacts, Monte Carlo Method},
	pages = {2317--2351},
}

@article{amari_learning_1972,
	title = {Learning patterns and pattern sequences by selforganizing nets of threshold elements},
	volume = {21},
	journal = {IEEE Trans. Comput.},
	author = {Amari, S I},
	year = {1972},
	keywords = {merged\_fiete.bib},
	pages = {1197--1206},
}

@incollection{doya_novel_1995,
	title = {A novel reinforcement model of birdsong vocalization learning},
	booktitle = {Advances in {Neural} {Info} {Proc} {Sys} 7},
	publisher = {MIT Press},
	author = {Doya, K and Sejnowski, T J},
	editor = {Tesauro, G and Touretzky, D S and Leen, T K},
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {101--108},
}

@incollection{fiete_biophysical_2005,
	title = {A biophysical network model for the emergence of ultrasparse sequences in {HVC} of the songbird},
	booktitle = {Abstract viewer},
	publisher = {Society for Neuroscience, Washington, DC},
	author = {Fiete, I R and Burger, L and Senn, W and Hahnloser, R H R},
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {79.12},
}

@incollection{jun_self-organized_2005,
	title = {Self-organized learning of spatiotemporal sequences in songbird {HVC} using spike time-dependent plasticity},
	booktitle = {Abstract viewer},
	publisher = {Society for Neuroscience, Washington, DC},
	author = {Jun, J K and Jin, D Z},
	year = {2005},
	keywords = {merged\_fiete.bib},
	pages = {688.12},
}

@article{fiete_enforcing_2007,
	title = {Enforcing global coding constraints by synaptic competition - a model for the formation of long ultrasparse sequences in the songbird},
	journal = {Submitted},
	author = {Fiete, I R and Burger, L and Senn, W and Hahnloser, R H R},
	year = {2007},
	keywords = {merged\_fiete.bib},
}

@incollection{fiete_reinforcement_2003,
	title = {Reinforcement learning of songbird premotor representations in a spiking neural network model},
	booktitle = {Abstracts from {CoSyNe} – {Computation} in {Neural} {Systems}},
	publisher = {Snowbird, Utah},
	author = {Fiete, I R and Hahnloser, R H R and Kozhevnikov, A and Fee, M S and Seung, H S},
	year = {2003},
	keywords = {merged\_fiete.bib},
}

@article{jun_development_2007,
	title = {Development of neural circuitry for precise temporal sequences through spontaneous activity, axon remodeling, and synaptic plasticity},
	volume = {2(8): e723},
	journal = {PLoS One},
	author = {Jun, J K and Jin, D Z},
	year = {2007},
	keywords = {merged\_fiete.bib},
}

@article{jin_intrinsic_2007,
	title = {Intrinsic bursting enhances the robustness of a neural network model of sequence generation by avian brain area {HVC}},
	journal = {J. Comput Neurosci, In press},
	author = {Jin, D Z and Ramazanoglu, F and Seung, H S},
	year = {2007},
	keywords = {merged\_fiete.bib},
}

@article{li_stable_2006,
	title = {Stable propagation of a burst through a one-dimensional homogeneous excitatory chain model of songbird nucleus {HVC}},
	volume = {74(1.1)},
	journal = {Phys Rev E},
	author = {Li, M and Greenside, H},
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {011918},
}

@article{skaggs_model_1995,
	title = {A model of the neural basis of the rat's sense of direction},
	volume = {7},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Skaggs, W E and Knierim, J J and Kudrimoti, H S and McNaughton, B L},
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {173--180},
}

@article{seung_autapse_2000,
	title = {The autapse: a simple illustration of short-term analog memory storage by tuned synaptic feedback},
	volume = {9},
	abstract = {According to a popular hypothesis, short-term memories are stored as persistent neural activity maintained by synaptic feedback loops. This hypothesis has been formulated mathematically in a number of recurrent network models. Here we study an abstraction of these models, a single neuron with a synapse onto itself, or autapse. This abstraction cannot simulate the way in which persistent activity patterns are distributed over neural populations in the brain. However, with proper tuning of parameters, it does reproduce the continuously graded, or analog, nature of many examples of persistent activity. The conditions for tuning are derived for the dynamics of a conductance-based model neuron with a slow excitatory autapse. The derivation uses the method of averaging to approximate the spiking model with a nonspiking, reduced model. Short-term analog memory storage is possible if the reduced model is approximately linear, and its feedforward bias and autapse strength are precisely tuned.},
	journal = {J. Comput. Neurosci.},
	author = {Seung, H Sebastian and Lee, Daniel D and Reis, Ben Y and Tank, David W},
	year = {2000},
	keywords = {merged\_fiete.bib, short-term memory, persistent neural activity, reverberating circuit, synaptic feedback},
	pages = {171--185},
}

@article{seung_learning_1998,
	title = {Learning continuous attractors in recurrent networks},
	volume = {10},
	abstract = {One approach to invariant object recognition employs a recurrent neural network as an associative memory. In the standard depiction of the network's state space, memories of objects are stored as attractive fixed points of the dynamics. I argue for a modification of this picture: if an object has a continuous family of instantiations, it should be represented by a continuous attractor. This idea is illustrated with a network that learns to complete patterns. To perform the task of filling in missing information, the network develops a continuous attractor that models the manifold from which the patterns are drawn. From a statistical viewpoint, the pattern completion task allows a formulation of unsupervised learning in terms of regression rather than density estimation.},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Seung, H Sebastian},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {654--660},
}

@techreport{bartlett_hebbian_1999,
	title = {Hebbian {Synaptic} {Modifications} in {Spiking} {Neurons} that {Learn}},
	abstract = {In this paper, we derive a new model of synaptic plasticity, based on recent algorithms for reinforcement learning (in which an agent attempts to learn appropriate actions to maximize its long-term average reward). We show that these direct reinforcement learning algorithms also give locally optimal performance for the problem of reinforcement learning with multiple agents, without any explicit communication between agents. By considering a network of spiking neurons as a collection of agents attempting to maximize the long-term average of the reward signal, we derive a synaptic update rule that is qualitatively similar to Hebb's postulate. This rule requires only simple computations, such as addition and leaky integration, and involves only quantities that are available in the vicinity of the synapse. Furthermore, it leads to synaptic connection strengths that give locally optimal values of the long-term average reward. The reinforcement learning paradigm is sufficiently broad to encompass many learning problems that are solved by the brain. We illustrate, with simulations, that the approach is effective for simple pattern classification and motor learning tasks.},
	author = {Bartlett, P L and Baxter, J},
	month = nov,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {1--21},
}

@article{ermentrout_linearization_1998,
	title = {Linearization of {F}-{I} {Curves} by {Adaptation}},
	volume = {10},
	abstract = {We show that negative feedback to highly nonlinear frequency-current (F-I) curves results in an effective linearization. (By highly nonlinear we mean that the slope at threshold is infinite or very steep.) We then apply this to a specific model for spiking neurons and show that the details of the adaptation mechanism do not affect the results. The crucial points are that the adaptation is slow compared to other processes and the unadapted F-I curve is highly nonlinear.},
	journal = {Neural Comput.},
	author = {Ermentrout, Bard},
	year = {1998},
	keywords = {merged\_fiete.bib, linearization and adaptation},
	pages = {1721--1729},
}

@article{tsodyks_neural_1998,
	title = {Neural {Networks} with {Dynamic} {Synapses}},
	volume = {10},
	abstract = {Transmission across neocortical synapses depends on the frequency of presynaptic activity (Thomson \& Deuchars, 1994). Inter-pyramidal synapses in layer V exhibit fast depression of synaptic transmission while other types of synapses exhibit facilitation of transmission. To study the role of dynamic synapses in a network computation, we propose a unified phenomenological model which allows computation of the post-synaptic current generated by both types of synapses when driven by an aribitrary pattern of action potential (AP) activity in a presynaptic population. Using this formalism we analyze different regimes of synaptic transmission and demonstrate that dynamic synapses transmit different aspects of the presynaptic activity depending on the average pre-synaptic frequency. The model also allows for derivation of mean-field equations which govern the activity of large interconnected networks. We show that dynamics of synaptic transmission results in complex sets of regular and irregular regimes of network activity.},
	journal = {Neural Comput.},
	author = {Tsodyks, M and Pawelzik, K and Markram, H},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {821--835},
}

@article{xie_spike-based_2000,
	title = {Spike-based learning rules and stabilization of persistent neural activity},
	volume = {12},
	abstract = {We analyze the conditions under which synaptic learning rules based on action potential timing can be approximated by learning rules based on firing rates. In particular, we consider a form of plasticity in which synapses depress when a presynaptic spike is followed by a postsynaptic spike, and potentiate with the opposite temporal ordering. Such differen-tial anti-Hebbian plasticity can be approximated under certain conditions by a learning rule that depends on the time derivative of the postsynaptic firing rate. Such a learning rule acts to stabilize persistent neural activity patterns in recurrent neural networks.},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Xie, Xiaohui and Seung, H Sebastian},
	year = {2000},
	keywords = {merged\_fiete.bib},
}

@article{feng_impact_2000,
	title = {Impact of {Correlated} {Inputs} on the {Output} of the {Integrate}-and-fire {Model}},
	volume = {12},
	abstract = {For the integrate-and-fire model with or without reversal potentials, we consider how correlated inputs affect the variability of cellular output. For both models the variability of efferent spike trains measured by coefficient of variation of the interspike interval (abbreviated to CV in the rest of the paper) is a nondecreasing function of input correlation. When the correlation coefficient is greater than 0.09, the CV of the integrate-and-fire model without reversal potentials is always above 0.5, no matter how strong the inhibitory inputs. Under a given condition on correlation coefficients we find that correlated Poisson processes can be decomposed into independent Poisson processes. We also develop a novel method to estimate the distribution density of the first passage time of the integrate-and-fire model.},
	journal = {Neural Comput.},
	author = {Feng, Jianfeng and Brown, David},
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {711--732},
}

@inproceedings{xie_learning_2000,
	title = {Learning winner-take-all competition between groups of neurons in lateral inhibitory networks},
	abstract = {It has long been known that lateral inhibition in neural networks can lead to a winner-take-all competition, so that only a single neuron is active at a steady state. Here we show how to organize lateral inhibition so that groups of neurons compete to be active. Given a collection of poten-tially overlapping groups, the inhibitory connectivity is set by a formula that can be interpreted as arising from a simple learning rule. Our analy-sis demonstrates that such inhibition generally results in winner-take-all competition between the given groups, with the exception of some de-generate cases. In a broader context, the network serves as a particular illustration of the general distinction between permitted and forbidden sets, which was introduced recently. From this viewpoint, the computa-tional function of our network is to store and retrieve memories as per-mitted sets of coactive neurons.},
	publisher = {NIPS},
	author = {Xie, Xiaohui and Hahnloser, Richard and Seung, H Sebastian},
	year = {2000},
	keywords = {merged\_fiete.bib},
}

@article{timofeev_origin_2000,
	title = {Origin of slow cortical oscillations in deafferented cortical slabs},
	volume = {10},
	abstract = {An in vivo preparation has been developed to study the mechanisms underlying spontaneous sleep oscillations. Dual and triple simultaneous intracellular recordings were made from neurons in small isolated cortical slabs (10 mm x 6 mm) in anesthetized cats. Spontaneously occurring slow sleep oscillations, present in the adjacent intact cortex, were absent in small slabs. However, the isolated slabs displayed brief active periods separated by long periods of silence, up to 60 s in duration. During these silent periods, 60\% of neurons showed non-linear amplification of low-amplitude depolarizing activity. Nearly 40\% of the cells, twice as many as in intact cortex, were classified as intrinsically bursting. In cortical network models based on Hodgkin-Huxley-like neurons, the summation of simulated spontaneous miniature excitatory postsynaptic potentials was sufficient to activate a persistent sodium current, initiating action potentials in single neurons that then spread through the network. Consistent with this model, enlarging the isolated cortical territory to an isolated gyrus (30 mm x 20 mm) increased the probability of initiating large-scale activity. In these larger territories, both the frequency and regularity of the slow oscillation approached that generated in intact cortex. The frequency of active periods in an analytical model of the cortical network accurately predicted the scaling observed in simulations and from recordings in cortical slabs of increasing size.},
	number = {12},
	journal = {Cereb. Cortex},
	author = {Timofeev, I and Grenier, F and Bazhenov, M and Sejnowski, T J and Steriade, M},
	month = dec,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1185--1199},
}

@article{seung_minimax_1998,
	title = {Minimax and {Hamiltonian} dynamics of excitatory-inhibitory networks},
	volume = {10},
	abstract = {A Lyapunov function for excitatory-inhibitory networks is constructed. The construction assumes symmetric interactions within excitatory and inhibitory populations of neurons, and antisymmetric interactions between populations. The Lyapunov function yields sufficient conditions for the global asymptotic stability of fixed points. If these conditions are violated, limit cycles may be stable. The relations of the Lyapunov function to optimization theory and classical mechanics are revealed by minimax and dissipative Hamiltonian forms of the network dynamics.},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Seung, H S and Richardson, T J and Lagarias, J C and Hopfield, J J},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {329--335},
}

@article{socci_rectified_1998,
	title = {The rectified {Gaussian} distribution},
	volume = {10},
	abstract = {A simple but powerful modification of the standard Gaussian distribution is studied. The variables of the rectified Gaussian are constrained to be nonnegative, enabling the use of nonconvex energy functions. Two multimodal examples, the competitive and cooperative distributions, illustrate the representational power of the rectified Gaussian. Since the cooperative distribution can represent the translations of a pattern, it demonstrates the potential of the rectified Gaussian for modeling pattern manifolds.},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Socci, N D and Lee, D D and Seung, H S},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {350--356},
}

@article{hinton_spiking_2000,
	title = {Spiking {Boltzmann} {Machines}},
	volume = {12},
	abstract = {We first show how to represent sharp posterior probability distributions using real valued coefficients on broadly-tuned basis functions. Then we show how the precise times of spikes can be used to convey the real-valued coefficients on the basis functions quickly and accurately. Finally we describe a simple simulation in which spiking neurons learn to model an image sequence by fitting a dynamic generative model.},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Hinton, Geoffrey E and Brown, Andrew D},
	year = {2000},
	keywords = {merged\_fiete.bib},
}

@article{diorio_single-transistor_1996,
	title = {A {Single}-{Transistor} {Silicon} {Synapse}},
	volume = {43},
	abstract = {We have developed a new floating-gate sili-con MOS transistor for analog learning applications. The memory storage is nonvolatile; hot-electron injection and electron tunneling permit bidirectional memory updates. Because these updates depend on both the stored memory value and the transistor terminal voltages, the synapse can implement a learning function. We have derived a memory- update rule from the physics of the tunneling and injection processes, and have investigated synapse learning in a prototype array. Unlike conventional EEPROM devices, the synapse allows simultaneous memory reading and writing. Synapse transistor arrays can therefore com-pute both the array output, and local memory updates, in parallel. The synapse is small, and typically is operated at subthreshold current levels; it will permit the development of dense, low-power silicon learning systems.},
	number = {11},
	journal = {IEEE Trans. Electron Devices},
	author = {Diorio, Chris and Hasler, Paul and Minch, Bradley A and Mead, Carver},
	month = nov,
	year = {1996},
	keywords = {merged\_fiete.bib},
}

@article{burkitt_analysis_1999,
	title = {Analysis of integrate and fire neurons: synchronization of synaptic input and spike output},
	volume = {11},
	abstract = {A new technique for analyzing the probability distribution of output spikes for the integrate and fire model is presented. This technique enables us to investigate models with arbitrary synaptic response functions that incorporate both leakage across the membrane and a rise time of the postsynaptic potential. The results, which are compared with numerical simulations, are exact in the limit of a large number of small amplitude inputs. This method is applied to the synchronization problem, in which we examine the relationship between the spread in arrival times of the inputs (the temporal jitter of the synaptic input) and the resultant spread in the times at which the output spikes are generated (output jitter). The results of previous studies, which indicated that the ratio of the output jitter to the input jitter is consistently less than one and that it decreases for increasing numbers of inputs, are confirmed for three classes of the integrate and re model. In addition to the previously identified factors of axonal propagation times and synaptic jitter, we identify the variation in the spike generating thresholds of the neurons and the variation in the number of active inputs as being important factors that determine the timing jitter in layered networks. Previously observed phase differences between optimally and suboptimally stimulated neurons may be understood in terms of the relative time taken to reach threshold.},
	journal = {Neural Comput.},
	author = {Burkitt, A N and Clark, G M},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {871--901},
}

@article{hermann_analysis_1995,
	title = {Analysis of {Synfire} {Chains}},
	volume = {6},
	abstract = {The biological implications of synfire chain neural networks are explored by studying two idealized models. In the first a network model is proposed with binary firing neurons and parallel updating. This model can be solved exactly in the thermodynamic limit using mean field theory. An explicit equation for the capacity is obtained. In the second model the synchrony of the pulse of activity along a synfire chain is investigated in the context of simple integrate-and-fire neurons. It is found that under natural assumptions a near synchronous wave of activity can stably propagate along a synfire chain. The relevance of this result to real systems is discussed.},
	number = {3},
	journal = {Network},
	author = {Hermann, M and Hertz, J A and Prugel-Bennett, A},
	month = aug,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {403--414},
}

@article{brunel_firing_1998,
	title = {Firing frequency of leaky intergrate-and-fire neurons with synaptic current dynamics},
	volume = {195},
	abstract = {We consider a model of an integrate-and-fire neuron with synaptic current dynamics, in which the synaptic time constant tau' is much smaller than the membrane time constant tau. We calculate analytically the firing frequency of such a neuron for inputs described by a random Gaussian process. We find that the first order correction to the frequency due to tau' is proportional to the square root of the ratio between these time constants radicaltau'/tau. This implies that the correction is important even when the synaptic time constant is small compared with that of the potential. The frequency of a neuron with tau'{\textgreater}0 can be reduced to that of the basic IF neuron (corresponding to tau'=1) using an “effective” threshold which has a linear dependence on radical tau'/tau. Numerical simulations show a very good agreement with the analytical result, and permit an extrapolation of the “effective” threshold to higher orders in radical tau'/tau. The obtained frequency agrees with simulation data for a wide range of parameters. Copyright 1998 Academic Press.},
	number = {1},
	journal = {J. Theor. Biol.},
	author = {Brunel, N and Sergi, S},
	month = nov,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {87--95},
}

@article{horn_distributed_2000,
	title = {Distributed {Synchrony} of {Spiking} {Neurons} in a {Hebbian} {Cell} {Assembly}},
	volume = {12},
	abstract = {We investigate the behavior of a Hebbian cell assembly of spiking neurons formed via a temporal synaptic learning curve. This learning function is based on recent experimental findings. It includes potentiation for short time delays between pre- and post-synaptic neuronal spiking, and depression for spiking events occurring in the reverse order. The coupling between the dynamics of the synaptic learning and of the neuronal activation leads to interesting results. We find that the cell assembly can fire asynchronously, but may also function in complete synchrony, or in distributed synchrony. The latter implies spontaneous division of the Hebbian cell assembly into groups of cells that fire in a cyclic manner. We investigate the behavior of distributed synchrony both by simulations and by analytic calculations of the resulting synaptic distributions.},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Horn, David and Levy, Nir and Meilijson, Isaac and Ruppin, Eytan},
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {129--135},
}

@article{hertz_learning_1996,
	title = {Learning {Synfire} {Chains}: {Turning} {Noise} into {Signal}},
	volume = {7},
	abstract = {We develop a model of cortical coding of stimuli by the sequences of activation patterns that they ignite in an initially random network. Hebbian learning then stabilizes these sequences, making them attractors of the dynamics. There is a competition between the capacity of the network and the stability of the sequences; for small stability parameter epsilon (the strength of the mean stabilizing PSP in the neurons in a learned sequence) the capacity is proportional to 1/epsilon{\textasciicircum}2. For epsilon of the order of or less than the PSPs of the untrained network, the capacity exceeds that for sequences learned from tabula rasa.},
	number = {4},
	journal = {Int. J. Neural Syst.},
	author = {Hertz, John and Prugel-Bennett, Adam},
	month = sep,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {445--450},
}

@article{hertz_learning_1995,
	title = {Learning {Synfire} {Chains} by {Self}-{Organization}},
	abstract = {A model of cortical neurons capable of sustaining a low level of spontaneous activity is investigated. Without learning the activity of the network is chaotic. We report on attempts to learn synfire chains in this type of network by introducing a Hebbian learning mechanism and exciting a small set of neurons at random intervals. We discuss the types of instabilities that can arise and prevent the formation of long synfire chains and also discuss various biologically plausible mechanisms which to some extent cure these instabilities.},
	journal = {Network},
	author = {Hertz, John and Prugel-Bennett, Adam},
	year = {1995},
	keywords = {merged\_fiete.bib},
}

@unpublished{hertz_modelling_1997,
	title = {Modelling {Synfire} {Networks}},
	abstract = {I review theoretical approaches to understanding how synfire processing works, including an analysis of the stability of spike synchronisation, a description of Hebbian learning of synfire chains, and an estimate of the capacity of a network the size of a cortical column. Most of the treatment is at the level of simple signal-to-noise analyses. NMDA-receptor synaptic currents are found not to affect the dynamical stability or the capacity severely.},
	author = {Hertz, John},
	year = {1997},
	keywords = {merged\_fiete.bib},
}

@article{hansel_numerical_1998,
	title = {On numerical simulations of integrate-and-fire neural networks},
	volume = {10},
	abstract = {It is shown that very small time steps are required to reproduce correctly the synchronization properties of large networks of integrate-and-fire neurons when the differential system describing their dynamics is integrated with the standard Euler or second-order Runge-Kutta algorithms. The reason for that behavior is analyzed, and a simple improvement of these algorithms is proposed.},
	number = {2},
	journal = {Neural Comput.},
	author = {Hansel, D and Mato, G and Meunier, C and Neltner, L},
	month = feb,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {467--483},
}

@article{burkitt_calculation_2000,
	title = {Calculation of interspike intervals for integrate-and-fire neurons with poisson distribution of synaptic inputs},
	volume = {12},
	abstract = {We present a new technique for calculating the interspike intervals of integrate-and-fire neurons. There are two new components to this technique. First, the probability density of the summed potential is calculated by integrating over the distribution of arrival times of the afferent post-synaptic potentials (PSPs), rather than using conventional stochastic differential equation techniques. A general formulation of this technique is given in terms of the probability distribution of the inputs and the time course of the postsynaptic response. The expressions are evaluated in the gaussian approximation, which gives results that become more accurate for large numbers of small-amplitude PSPs. Second, the probability density of output spikes, which are generated when the potential reaches threshold, is given in terms of an integral involving a conditional probability density. This expression is a generalization of the renewal equation, but it holds for both leaky neurons and situations in which there is no time-translational invariance. The conditional probability density of the potential is calculated using the same technique of integrating over the distribution of arrival times of the afferent PSPs. For inputs with a Poisson distribution, the known analytic solutions for both the perfect integrator model and the Stein model (which incorporates membrane potential leakage) in the diffusion limit are obtained. The interspike interval distribution may also be calculated numerically for models that incorporate both membrane potential leakage and a finite rise time of the postsynaptic response. Plots of the relationship between input and output firing rates, as well as the coefficient of variation, are given, and inputs with varying rates and amplitudes, including inhibitory inputs, are analyzed. The results indicate that neurons functioning near their critical threshold, where the inputs are just sufficient to cause firing, display a large variability in their spike timings.},
	number = {8},
	journal = {Neural Comput.},
	author = {Burkitt, A N and Clark, G M},
	month = aug,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1789--1820},
}

@article{pearlmutter_gradient_1995,
	title = {Gradient {Calculations} for {Dynamic} {Recurrent} {Neural} {Networks}: {A} {Survey}},
	volume = {6},
	number = {5},
	journal = {IEEE Trans. Neural Netw.},
	author = {Pearlmutter, Barak A},
	year = {1995},
	keywords = {Recurrent neural networks, merged\_fiete.bib, backpropagation through time, real time recurrent learning, trajectory learning},
	pages = {1212--1228},
}

@article{aertsen_propagation_1996,
	title = {Propagation of synchronous spiking activity in feedforward neural networks},
	volume = {90},
	abstract = {'Synfire' activity has been proposed as a model for the experimentally observed accurate spike patterns in cortical activity. We investigated the structural and dynamical aspects of this theory. To quantify the degree of synchrony in neural activity, we introduced the concept of 'pulse packets'. This enabled us to derive a novel neural transmission function which was used to assess the role of the single neuron dynamics and to characterize the stability conditions for propagating synfire activity. Thus, we could demonstrate that the cortical network is able to sustain synchronous spiking activity using local feedforward (synfire) connections. This new approach opens the way for a quantitative description of neural network dynamics, and enables us to test the synfire hypothesis on physiological data.},
	number = {3-4},
	journal = {J. Physiol. Paris},
	author = {Aertsen, A and Diesmann, M and Gewaltig, M O},
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {243--247},
}

@article{shadlen_variable_1998,
	title = {The variable discharge of cortical neurons: implications for connectivity, computation, and information coding},
	volume = {18},
	abstract = {Cortical neurons exhibit tremendous variability in the number and temporal distribution of spikes in their discharge patterns. Furthermore, this variability appears to be conserved over large regions of the cerebral cortex, suggesting that it is neither reduced nor expanded from stage to stage within a processing pathway. To investigate the principles underlying such statistical homogeneity, we have analyzed a model of synaptic integration incorporating a highly simplified integrate and fire mechanism with decay. We analyzed a “high-input regime” in which neurons receive hundreds of excitatory synaptic inputs during each interspike interval. To produce a graded response in this regime, the neuron must balance excitation with inhibition. We find that a simple integrate and fire mechanism with balanced excitation and inhibition produces a highly variable interspike interval, consistent with experimental data. Detailed information about the temporal pattern of synaptic inputs cannot be recovered from the pattern of output spikes, and we infer that cortical neurons are unlikely to transmit information in the temporal pattern of spike discharge. Rather, we suggest that quantities are represented as rate codes in ensembles of 50-100 neurons. These column-like ensembles tolerate large fractions of common synaptic input and yet covary only weakly in their spike discharge. We find that an ensemble of 100 neurons provides a reliable estimate of rate in just one interspike interval (10-50 msec). Finally, we derived an expression for the variance of the neural spike count that leads to a stable propagation of signal and noise in networks of neurons-that is, conditions that do not impose an accumulation or diminution of noise. The solution implies that single neurons perform simple algebra resembling averaging, and that more sophisticated computations arise by virtue of the anatomical convergence of novel combinations of inputs to the cortical column from external sources.},
	number = {10},
	journal = {J. Neurosci.},
	author = {Shadlen, M N and Newsome, W T},
	month = may,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {3870--3896},
}

@article{feng_coefficient_1999,
	title = {Coefficient of variation of interspike intervals greater than 0.5. {How} and when?},
	volume = {80},
	abstract = {Using Stein's model with and without reversal potentials, we investigated the mechanism of production of spike trains with a CV (ISI)(standard deviation/mean interspike interval) greater than 0.5, as observed in the visual cortex. When the attractor of the deterministic part of the dynamics is below the firing threshold, spike generation results primarily from random fluctuations. Using computer simulation for a range of membrane decay times and with other model parameters set to values appropriate for the visual cortex, we demonstrate that CV (ISI) is then usually greater than 0.5; if the attractor is above the threshold, spike generation is mainly due to deterministic forces, and CV (ISI) is then usually lower than 0.5. The critical value of the inhibitory postsynaptic potential (IPSP) rate at which CV (ISI) becomes greater than 0.5 is determined, resulting in specifications of how neurones might adjust their synaptic inputs to elicit irregular spike trains.},
	number = {5},
	journal = {Biol. Cybern.},
	author = {Feng, J F and Brown, D},
	month = may,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {291--297},
}

@article{feng_impact_1998,
	title = {Impact of temporal variation and the balance between excitation and inhibition on the output of the perfect integrate-and-fire model},
	volume = {78},
	abstract = {We consider how the output of the perfect integrate-and-fire (I\&F) model of a single neuron is affected by the properties of the input, first of all by the distribution of afferent excitatory and inhibitory postsynaptic potential (EPSP, IPSP) inter-arrival times, discriminating particularly between short- and long-tailed forms, and by the degree of balance between excitation and inhibition (as measured by the ratio, r, between the numbers of inhibitory and excitatory inputs). We find that the coefficient of variation (CV; standard deviation divided by mean) of efferent interspike interval (ISI) is an increasing function of the length of the tail of the distribution of EPSP inter-arrival times and the ratio r. There is a range of values of r in which the CV of output ISIs is between 0.5 and 1. Too tight a balance between EPSPs and IPSPs will cause the model to produce a CV outside the interval considered to correspond to the physiological range. Going to the extreme, an exact balance between EPSPs and IPSPs as considered in [24] ensures a long-tailed ISI output distribution for which the moments such as mean and variance cannot be defined. In this case it is meaningless to consider quantities like output jitter, CV, etc. of the efferent ISIs. The longer the tail of the input inter-arrival time distribution, the less is the requirement for balance between EPSPs and IPSPs in order to evoke output spike trains with a CV between 0.5 and 1. For a given short-tailed input distribution, the range of values of r in which the CV of efferent ISIs is between 0.5 and 1 is almost completely inside the range in which output jitter (standard deviation of efferent ISI) is greater than input jitter. Only when the CV is smaller than 0.5 or the input distribution is a long-tailed one is output less than input jitter [21]. The I\&F model tends to enlarge low input jitter and reduce high input jitter. We also provide a novel theoretical framework, based upon extreme value theory in statistics, for estimating output jitter, CV and mean firing time.},
	number = {5},
	journal = {Biol. Cybern.},
	author = {Feng, J and Brown, D},
	month = may,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {369--376},
}

@article{arnold_oculomotor_1997,
	title = {The oculomotor integrator: testing of a neural network model},
	volume = {113},
	abstract = {An important part of the vestibulo-ocular reflex is a group of cells in the caudal pons, known as the neural integrator, that converts eye-velocity commands, from the semicircular canals for example, to eye-position commands for the motoneurons of the extraocular muscles. Previously, a recurrently connected neural network model was developed by us that learns to simulate the signal processing done by the neural integrator, but it uses an unphysiological learning algorithm. We describe here a new network model that can learn the same task by using a local, Hebbian-like learning algorithm that is physiologically plausible. Through the minimization of a retinal slip error signal the model learns, given randomly selected initial synaptic weights, to both integrate simulated push-pull semicircular canal afferent signals and compensate for orbital mechanics as well. Approximately half of the model's 14 neurons are inhibitory, half excitatory. After learning, inhibitory cells tend to project contralaterally, thus forming an inhibitory commissure. The network can, of course, recover from lesions. The mature network is also able to change its gain by simulating abnormal visual-vestibular interactions. When trained with a sine wave at a single frequency, the network changed its gain at and near the training frequency but not at significantly higher or lower frequencies, in agreement with previous experimental observations. Commissural connections are essential to the functioning of this model, as was the case with our previous model. In order to determine whether a commissure plays a similar role in the real neural integrator, a series of electrical perturbations were performed on the midlines of awake, behaving juvenile rhesus monkeys and the effects on the monkeys' eye movements were examined. Eye movements were recorded using the coil system before, during, and after electrical stimulation in the midline of the pons just caudal to the abducens nuclei, which reversibly made the integrator leaky. Eye movements were also recorded from two of the monkeys before and after a midline electrolytic lesion was made at the location where stimulation produced a leaky integrator. This lesion disabled the integrator irreversibly. The eye movements that were produced by the monkeys as a result of these perturbations were then compared with eye movements produced by the model after analogous perturbations. The results are compatible with the hypothesis that integration comes about by positive feedback through lateral inhibition effected by an inhibitory commissure.},
	number = {1},
	journal = {Exp. Brain Res.},
	author = {Arnold, D B and Robinson, D A},
	month = jan,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {57--74},
}

@article{williams_learning_1989,
	title = {A {Learning} {Algorithm} for {Continually} {Running} {Fully} {Recurrent} {Neural} {Networks}},
	volume = {1},
	abstract = {The exact form of a gradient-following learning algorithm for completely recurrent networks running in continually sampled time is derived and used as the basis for practical algorithms for temporal supervised learning tasks. The algorithms have: (1) the advantage that they do not require a precisely defined training interval, operating while the network runs; and (2) the disadvantage that they require nonlocal communication in the network being trained and are computationally expensive. These algorithms are shown to allow networks having recurrent connections to learn complex tasks requiring the retention of information over time periods having either fixed or indefinte length.},
	journal = {Neural Comput.},
	author = {Williams, Ronald J and Zipser, David},
	year = {1989},
	keywords = {Teacher forcing, merged\_fiete.bib, trajectory learning},
	pages = {270--280},
}

@article{kleinfeld_associative_1988,
	title = {Associative neural network model for the generation of temporal patterns. {Theory} and application to central pattern generators},
	volume = {54},
	abstract = {Cyclic patterns of motor neuron activity are involved in the production of many rhythmic movements, such as walking, swimming, and scratching. These movements are controlled by neural circuits referred to as central pattern generators (CPGs). Some of these circuits function in the absence of both internal pacemakers and external feedback. We describe an associative neural network model whose dynamic behavior is similar to that of CPGs. The theory predicts the strength of all possible connections between pairs of neurons on the basis of the outputs of the CPG. It also allows the mean operating levels of the neurons to be deduced from the measured synaptic strengths between the pairs of neurons. We apply our theory to the CPG controlling escape swimming in the mollusk Tritonia diomedea. The basic rhythmic behavior is shown to be consistent with a simplified model that approximates neurons as threshold units and slow synaptic responses as elementary time delays. The model we describe may have relevance to other fixed action behaviors, as well as to the learning, recall, and recognition of temporally ordered information.},
	number = {6},
	journal = {Biophys. J.},
	author = {Kleinfeld, D and Sompolinsky, H},
	month = dec,
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {1039--1051},
}

@article{pearlmutter_learning_1989,
	title = {Learning {State} {Space} {Trajectories} in {Recurrent} {Neural} {Networks}},
	volume = {1},
	abstract = {Many neural network learning procedures compute gradients of the errors on the output layer of units after they have settled to their final values. We describe a procedure for finding {\textbackslash}partial E / {\textbackslash}partial w\_ij where E is an error functional of the temporal trajectory of the states of a continuous neural network and w\_ij are the weights of that network. Computing these quantities allows one to perform gradient descent in the weights to minimize E. Simulations in which networks are taught to move through limit cycles are shown. This type of recurrent network seems particularly suited for temporally continuous domains, such as signal processing, control, and speech.},
	journal = {Neural Comput.},
	author = {Pearlmutter, Barak},
	year = {1989},
	keywords = {merged\_fiete.bib},
	pages = {263--269},
}

@article{williams_experimental_1989,
	title = {Experimental {Analysis} of the {Real}-{Time} {Recurrent} {Learning} {Algorithm}},
	volume = {1},
	abstract = {The real-time recurrent learning algorithm is a gradient-following learning algorithm for completely recurrent networks running in continually sampled time. Here we use a series of simulation experiments to investigate the power and properties of this algorithm. In the recurrent networks studied here, any unit can be connected to any other, and any unit can recieve external input. These networks run continually in the sense that they sample their inputs on every update cycle, and any unit can have a training target on any cycle. The storage required and computation time on each step are independent of time and are completely determined by the size of the network, so no prior knowledge of the temporal structure of the task being learned is required. The algorithm is nonlocal in the sense that each unit must have knowledge of the complete recurrent weight matrix and error vector. The algorithm is computationally intensive in sequential computers, requiring a storage capacity of the order of the third power of the number of units and a computation time on each cycle of the order of the fourth power of the number of units. The simulations include examples in which networks are taught tasks not possible with tapped delay lines - that is, tasks that require the preservation of state over potentially unbounded periods of time. The most complex example of this kind is learning to emulate a Turing machine that does a parenthesis balancing problem. Examples are also given of networks that do feedforward computations with unknown delays, requiring them to organize into networks with the correct number of layers. Finally, examples are given in which networks are trained to oscillate in various ways, including sinusoidal oscillation.},
	number = {1},
	journal = {Conn. Sci.},
	author = {Williams, Ronald J and Zipser, David},
	year = {1989},
	keywords = {merged\_fiete.bib},
	pages = {87--111},
}

@article{troyer_physiological_1997,
	title = {Physiological gain leads to high {ISI} variability in a simple model of a cortical regular spiking cell},
	volume = {9},
	abstract = {To understand the interspike interval (ISI) variability displayed by visual cortical neurons (Softky \& Koch, 1993), it is critical to examine the dynamics of their neuronal integration, as well as the variability in their synaptic input current. Most previous models have focused on the latter factor. We match a simple integrate-and-fire model to the experimentally measured integrative properties of cortical regular spiking cells (McCormick, Connors, Lighthall, \& Prince, 1985). After setting RC parameters, the post-spike voltage reset is set to match experimental measurements of neuronal gain (obtained from in vitro plots of firing frequency versus injected current). Examination of the resulting model leads to an intuitive picture of neuronal integration that unifies the seemingly contradictory 1/square root of N and random walk pictures that have previously been proposed. When ISIs are dominated by postspike recovery, 1/square root of N arguments hold and spiking is regular; after the “memory” of the last spike becomes negligible, spike threshold crossing is caused by input variance around a steady state and spiking is Poisson. In integrate-and-fire neurons matched to cortical cell physiology, steady-state behavior is predominant, and ISIs are highly variable at all physiological firing rates and for a wide range of inhibitory and excitatory inputs.},
	number = {5},
	journal = {Neural Comput.},
	author = {Troyer, T W and Miller, K D},
	month = jul,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {971--983},
}

@article{hopfield_what_2001,
	title = {What is a moment? {Transient} synchrony as a collective mechanism for spatiotemporal integration},
	volume = {98},
	abstract = {A previous paper described a network of simple integrate-and-fire neurons that contained output neurons selective for specific spatiotemporal patterns of inputs; only experimental results were described. We now present the principles behind the operation of this network and discuss how these principles point to a general class of computational operations that can be carried out easily and naturally by networks of spiking neurons. Transient synchrony of the action potentials of a group of neurons is used to signal “recognition” of a space-time pattern across the inputs of those neurons. Appropriate synaptic coupling produces synchrony when the inputs to these neurons are nearly equal, leaving the neurons unsynchronized or only weakly synchronized for other input circumstances. When the input to this system comes from timed past events represented by decaying delay activity, the pattern of synaptic connections can be set such that synchronization occurs only for selected spatiotemporal patterns. We show how the recognition is invariant to uniform time warp and uniform intensity change of the input events. The fundamental recognition event is a transient collective synchronization, representing “many neurons now agree,” an event that is then detected easily by a cell with a small time constant. If such synchronization is used in neurobiological computation, its hallmark will be a brief burst of gamma-band electroencephalogram noise when and where such a recognition event or decision occurs.},
	number = {3},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Hopfield, J J and Brody, C D},
	month = jan,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {1282--1287},
}

@article{traub_model_1990,
	title = {Model of synchronized epileptiform bursts induced by high potassium in {CA3} region of rat hippocampal slice. {Role} of spontaneous {EPSPs} in initiation},
	volume = {64},
	abstract = {1. We constructed a computer model of the in vitro CA3 region of the rat hippocampal slice bathed in a high-potassium medium. Our aim was to understand better the mechanisms of initiation of synchronized bursts and the processes that regulate the interburst interval in the experimental system. 2. Our model began with a previously published model of the longitudinal CA3 hippocampal slice. The model contains three interconnected cell populations: 9,000 (excitatory) pyramidal cells; 450 inhibitory cells whose postsynaptic action is somatic and decays quickly, corresponding to chloride-dependent inhibition mediated by gamma-aminobutyric acid (GABA)A channels, and 450 inhibitory cells whose postsynaptic action is dendritic, of delayed onset and long lasting, that corresponds to K-dependent inhibition mediated by GABAB channels. 3. The model was then modified to account for specific features of the high-K experimental system: 1) the pyramidal cells do not generate intrinsic bursts; 2) EIPSP(CI) and EK are both shifted in a depolarizing direction; 3) spontaneous (i.e., not caused by presynaptic firing) excitatory postsynaptic potentials (EPSP)s were included; and 4) a steady current was injected into the pyramidal cells to depolarize them. 4. This model generates synchronized population bursts with interburst intervals of approximately 1.0-1.5 s. Bursts in individual pyramidal cells are preceded by barrages of EPSPs. These results agree with experiment. 5. Our model agrees with the following additional experiments: 1) synchronized bursts are abolished by partial blockade of excitatory synapses; 2) burst frequency is increased by partial blockade of a slow-intrinsic-K conductance; and 3) blockade of chloride-dependent inhibition leads to bursts of longer duration with longer interburst intervals. 6. The basic structural features of this model are similar to, but not identical to, the model of the disinhibited hippocampal slice. Spontaneous EPSPs appear to be critical in the high-K system for initiating, but not for synchronizing, population bursts. The experimental data and simulation results raise interesting questions about the role of spontaneous EPSPs in initiating synchronized discharges in other epileptic systems and on the possible role of spontaneous EPSPs in the normal brain.},
	number = {3},
	journal = {J. Neurophysiol.},
	author = {Traub, R D and Dingledine, R},
	month = sep,
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {1009--1018},
}

@article{vanier_comparative_1999,
	title = {A comparative survey of automated parameter-search methods for compartmental neural models},
	abstract = {One of the most difficult and time-consuming aspects of building compartmental models of single neurons is assigning values to free parameters to make models match experimental data. Automated parameter-search methods potentially represent a more rapid and less labor-intensive alternative to choosing parameters manually. Here we compare the performance of four different parameter-search methods on several single-neuron models. The methods compared are conjugate-gradient descent, genetic algorithms, simulated annealing, and stochastic search. Each method has been tested on five different neuronal models ranging from simple models with between 3 and 15 parameters to a realistic pyramidal cell model with 23 parameters. The results demonstrate that genetic algorithms and simulated annealing are generally the most effective methods. Simulated annealing was overwhelmingly the most effective method for simple models with small numbers of parameters, but the genetic algorithm method was equally effective for more complex models with larger numbers of parameters. The discussion considers possible explanations for these results and makes several specific recommendations for the use of parameter searches on neuronal models.},
	author = {Vanier, M C and Bower., J M},
	year = {1999},
	keywords = {merged\_fiete.bib},
}

@article{golomb_propagating_1997,
	title = {Propagating neuronal discharges in neocortical slices: computational and experimental study},
	abstract = {We studied the propagation of paroxysmal discharges in disinhibited neocortical slices by developing and analyzing a model of excitatory regular-spiking neocortical cells with spatially decaying synaptic efficacies and by field potential recording in rat slices. Evoked discharges may propagate both in the model and in the experiment. The model discharge propagates as a traveling pulse with constant velocity and shape. The discharge shape is determined by an interplay between the synaptic driving force and the neuron's intrinsic currents, in particular the slow potassium current. In the model, N-methyl-D-aspartate (NMDA) conductance contributes much less to the discharge velocity than amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid (AMPA) conductance. Blocking NMDA receptors experimentally with 2-amino-5-phosphonovaleric acid (APV) has no significant effect on the discharge velocity. In both model and experiments, propagation occurs for AMPA synaptic coupling gAMPA above a certain threshold, at which the velocity is finite (non-zero). The discharge velocity grows linearly with the gAMPA for gAMPA much above the threshold. In the experiments, blocking AMPA receptors gradually by increasing concentrations of 6-cyano-7-nitroquinoxaline-2,3-dione (CNQX) in the perfusing solution results in a gradual reduction of the discharge velocity until propagation stops altogether, thus confirming the model prediction. When discharges are terminated in the model by the slow potassium current, a network with the same parameter set may display discharges with several forms, which have different velocities and numbers of spikes; initial conditions select the exhibited pattern. When the discharge is also terminated by strong synaptic depression, there is only one discharge form for a particular parameter set; the velocity grows continuously with increased synaptic conductances. No indication for more than one discharge velocity was observed experimentally. If the AMPA decay rate increases while the maximal excitatory postsynaptic conductance (EPSC) a cell receives is kept fixed, the velocity increases by approximately 20\% until it reaches a saturated value. Therefore the discharge velocity is determined mainly by the cells' integration time of input EPSCs. We conclude, on the basis of both the experiments and the model, that the total amount of excitatory conductance a typical cell receives in a control slice exhibiting paroxysmal discharges is only approximately 5 times larger than the excitatory conductance needed for raising the potential of a resting cell above its action potential threshold.},
	author = {Golomb, D and Amitai., Y},
	year = {1997},
	keywords = {merged\_fiete.bib},
}

@article{wang_calcium_1998,
	title = {Calcium coding and adaptive temporal computation in cortical pyramidal neurons},
	abstract = {In this work, we present a quantitative theory of temporal spike-frequency adaptation in cortical pyramidal cells. Our model pyramidal neuron has two-compartments (a “soma” and a “dendrite”) with a voltage-gated Ca2+ conductance (gCa) and a Ca2+-dependent K+ conductance (gAHP) located at the dendrite or at both compartments. Its frequency-current relations are comparable with data from cortical pyramidal cells, and the properties of spike-evoked intracellular [Ca2+] transients are matched with recent dendritic [Ca2+] imaging measurements. Spike-frequency adaptation in response to a current pulse is characterized by an adaptation time constant tauadap and percentage adaptation of spike frequency Fadap [\% (peak - steady state)/peak]. We show how tauadap and Fadap can be derived in terms of the biophysical parameters of the neural membrane and [Ca2+] dynamics. Two simple, experimentally testable, relations between tauadap and Fadap are predicted. The dependence of tauadap and Fadap on current pulse intensity, electrotonic coupling between the two compartments, gAHP as well the [Ca2+] decay time constant tauCa, is assessed quantitatively. In addition, we demonstrate that the intracellular [Ca2+] signal can encode the instantaneous neuronal firing rate and that the conductance-based model can be reduced to a simple calcium-model of neuronal activity that faithfully predicts the neuronal firing output even when the input varies relatively rapidly in time (tens to hundreds of milliseconds). Extensive simulations have been carried out for the model neuron with random excitatory synaptic inputs mimicked by a Poisson process. Our findings include 1) the instantaneous firing frequency (averaged over trials) shows strong adaptation similar to the case with current pulses; 2) when the gAHP is blocked, the dendritic gCa could produce a hysteresis phenomenon where the neuron is driven to switch randomly between a quiescent state and a repetitive firing state. The firing pattern is very irregular with a large coefficient of variation of the interspike intervals (ISI CV {\textgreater} 1). The ISI distribution shows a long tail but is not bimodal. 3) By contrast, in an intrinsically bursting regime (with different parameter values), the model neuron displays a random temporal mixture of single action potentials and brief bursts of spikes. Its ISI distribution is often bimodal and its power spectrum has a peak. 4) The spike-adapting current IAHP, as delayed inhibition through intracellular Ca2+ accumulation, generates a “forward masking” effect, where a masking input dramatically reduces or completely suppresses the neuronal response to a subsequent test input. When two inputs are presented repetitively in time, this mechanism greatly enhances the ratio of the responses to the stronger and weaker inputs, fulfilling a cellular form of lateral inhibition in time. 5) The [Ca2+]-dependent IAHP provides a mechanism by which the neuron unceasingly adapts to the stochastic synaptic inputs, even in the stationary state following the input onset. This creates strong negative correlations between output ISIs in a frequency-dependent manner, while the Poisson input is totally uncorrelated in time. Possible functional implications of these results are discussed.},
	author = {Wang., X J},
	year = {1998},
	keywords = {merged\_fiete.bib},
}

@article{hopfield_learning_1987,
	title = {Learning algorithms and probability distributions in feed-forward and feed-back networks},
	volume = {84},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Hopfield, J J},
	month = dec,
	year = {1987},
	keywords = {merged\_fiete.bib},
	pages = {8429--8433},
}

@article{sejnowski_why_2000,
	title = {Why do we sleep},
	volume = {886},
	abstract = {Slow-wave sleep consists in slowly recurring waves that are associated with a large-scale spatio-temporal synchrony across neocortex. These slow-wave complexes alternate with brief episodes of fast oscillations, similar to the sustained fast oscillations that occur during the wake state. We propose that alternating fast and slow waves consolidate information acquired previously during wakefulness. Slow-wave sleep would thus begin with spindle oscillations that open molecular gates to plasticity, then proceed by iteratively 'recalling' and 'storing' information primed in neural assemblies. This scenario provides a biophysical mechanism consistent with the growing evidence that sleep serves to consolidate memories.},
	number = {1-2},
	journal = {Brain Res.},
	author = {Sejnowski, T J and Destexhe, A},
	month = dec,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {208--223},
}

@article{redish_coupled_1996,
	title = {A coupled attractor model of the rodent head direction system},
	volume = {7},
	abstract = {Abstract. Head direction (HD) cells, abundant in the rat postsubiculum and anterior thalamic nuclei, fire maximally when the rats head is facing a particular direction. The activity of a population of these cells forms a distributed representation of the animals current heading. We describe a neural network model that creates a stable, distributed representation of head direction and updates that representation in response to angular velocity information. In contrast to earlier models, our model of the head direction system accurately tracks a series of actual rat head rotations, and, using biologically plausible neurons, it fits the single-cell tuning curves of real HD cells recorded from rats executing those same rotations. The model makes neurophysiological predictions that can be tested using current technologies.},
	journal = {Network: Computation in Neural Systems},
	author = {Redish, David and Elga, Adam N and Touretzky, David S},
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {671685},
}

@article{wang_connectedness_2000,
	title = {On connectedness: a solution based on oscillatory correlation},
	volume = {12},
	abstract = {A long-standing problem in Neural Comp has been the problem of connectedness, first identified by Minsky and Papert (1969). This problem served as the cornerstone for them to establish analytically that perceptrons are fundamentally limited in computing geometrical (topological) properties. A solution to this problem is offered by a different class of neural networks: oscillator networks. To solve the problem, the representation of oscillatory correlation is employed, whereby one pattern is represented as a synchronized block of oscillators and different patterns are represented by distinct blocks that desynchronize from each other. Oscillatory correlation emerges from LEGION (locally excitatory globally inhibitory oscillator network), whose architecture consists of local excitation and global inhibition among neural oscillators. It is further shown that these oscillator networks exhibit sensitivity to topological structure, which may lay a neurocomputational foundation for explaining the psychophysical phenomenon of topological perception.},
	number = {1},
	journal = {Neural Comput.},
	author = {Wang, D L},
	month = jan,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {131--139},
}

@unpublished{hertz_basic_1999,
	title = {Some basic issues in neural network modelling},
	abstract = {In these lectures I use some simple neural network models to address a couple of basic issues in neural computation and neural network dynamics: (1) the intrinsic dynamics of local cortical circuitry, and (2) how a network can perform a fundamental cognitive computation: associative memory.},
	author = {Hertz, J A},
	month = may,
	year = {1999},
	keywords = {merged\_fiete.bib},
}

@article{abbott_asynchronous_1993,
	title = {Asynchronous states in networks of pulse-coupled oscillators},
	volume = {48},
	abstract = {We use a mean-field approach to analyze the stability of the asynchronous state in a population of all-to-all, pulse-coupled, nonlinear oscillators. We determine the conditions that must be satisfied by the time constants and phase dependence characterizing the coupling between the oscillators in order for the asynchronous state to be stable. We also consider the effects of noise. This work complements results on synchronous states in similar models and allows us to study the validity of firing-rate models commonly used for neural networks.},
	number = {2},
	journal = {Phys. Rev. E},
	author = {Abbott, L F and van Vreeswijk, Carl},
	month = aug,
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {1483--1490},
}

@article{1_modeling_2000,
	title = {Modeling {Attractor} {Deformation} in the {Rodent} {Head}-{Direction} {System}},
	volume = {83},
	journal = {J. Neurophysiol.},
	author = {{1} and David S. Touretzky, Jeremy P Goodridge},
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {3402--3410},
}

@article{pakdaman_periodically_2001,
	title = {Periodically forced leaky integrate-and-fire model},
	volume = {63},
	abstract = {The discharge pattern of periodically forced leaky integrate-and-fire models is studied. While previous analyses have been mainly concerned with the response of this model to sinusoidal stimulation, our results hold for arbitrary periodic inputs. It is shown that, for any periodic input, the map representing the relation between input phases at consecutive discharge times can be restricted to a piecewise continuous, orientation preserving circle map. This implies that (i) the rotation number is well defined and independent of the initial condition, and (ii) in the same way as for sinusoidal forcing, other forms of periodic stimuli can evoke only one of four types of response, namely, phase locking, quasiperiodic discharges, nonchaotic aperiodic firing, and termination of the discharge after a finite number of firings.},
	number = {4 Pt 1},
	journal = {Phys. Rev. E Stat. Phys. Plasmas Fluids Relat. Interdiscip. Topics},
	author = {Pakdaman, K},
	month = apr,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {041907},
}

@article{lumer_effects_2000,
	title = {Effects of spike timing on winner-take-all competition in model cortical circuits},
	volume = {12},
	abstract = {Synaptic interactions in cortical circuits involve strong recurrent excitation between nearby neurons and lateral inhibition that is more widely spread. This architecture is commonly thought to promote a winner-take-all competition, in which a small fraction of neuronal responses is selected for further processing. Here I report that such a competition is remarkably sensitive to the timing of neuronal action potentials. This is shown using simulations of model neurons and synaptic connections representing a patch of cortical tissue. In the simulations, uncorrelated discharge among neuronal units results in patterns of response dominance and suppression, that is, in a winner-take-all competition. Synchronization of firing, however, prevents such competition. These results demonstrate a novel property of recurrent cortical-like circuits, suggesting that the temporal patterning of cortical activity may play an important part in selection among stimuli competing for the control of attention and motor action.},
	number = {1},
	journal = {Neural Comput.},
	author = {Lumer, Ed},
	month = jan,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {181--194},
}

@article{coultrip_cortical_1992,
	title = {A {CORTICAL} {MODEL} {OF} {WINNER}-{TAKE}-{ALL} {COMPETITION} {VIA} {LATERAL} {INHIBITION}},
	volume = {5},
	abstract = {Simulations were performed of physiological interactions among excitatory and inhibitory neurons in anatomically realistic local-circuit architectures modeled after hippocampal field CA1. The simulated circuitry consists of several excitatory neurons jointly innervating and receiving feedback from a common inhibitory interneuron. Excitatory cells in the simulation receive input during a cycle of naturally-occurring rhythmic activity (the hippocampal theta rhythm), and the neuron receiving the most input activation is the first to reach its spiking threshold. Spiking excites the inhibitory cell, which in turn prevents other cells from responding. The result is the natural generation of a simple competitive or “winner-take-all” (WTA) mechanism, allowing only the most strongly-activated cell in a group or “patch” to respond with spiking activity. Formal mathematical characterization of the mechanism reveals specific physiological characteristics of the input to the network, which enable it to closely approximate an ideal winner-take-all mechanism. Unlike other, more abstract WTA mechanisms that have been proposed, the parameters of this biologically-derived WTA mechanism can be directly related to specific physiological and anatomical features of particular cortical circuits.},
	number = {1},
	journal = {Neural Netw.},
	author = {Coultrip, R and Granger, R and Lynch, G},
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {47--54},
}

@article{hopfield_rapid_1995,
	title = {Rapid local synchronization of action potentials: toward computation with coupled integrate-and-fire neurons},
	volume = {92},
	abstract = {The collective behavior of interconnected spiking nerve cells is investigated. It is shown that a variety of model systems exhibit the same short-time behavior and rapidly converge to (approximately) periodic firing patterns with locally synchronized action potentials. The dynamics of one model can be described by a downhill motion on an abstract energy landscape. Since an energy landscape makes it possible to understand and program computation done by an attractor network, the results will extend our understanding of collective computation from models based on a firing-rate description to biologically more realistic systems with integrate-and-fire neurons.},
	number = {15},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Hopfield, Jj and Herz, Av},
	month = jul,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {6655--6662},
}

@article{bressloff_dynamics_2000,
	title = {Dynamics of strongly-coupled spiking neurons},
	volume = {12},
	abstract = {We present a dynamical theory of integrate-and-fire neurons with strong synaptic coupling. We show how phase-locked states that are stable in the weak coupling regime can destabilize as the coupling is increased, leading to states characterized by spatiotemporal variations in the interspike intervals (ISIs). The dynamics is compared with that of a corresponding network of analog neurons in which the outputs of the neurons are taken to be mean firing rates. A fundamental result is that for slow interactions, there is good agreement between the two models (on an appropriately defined timescale). Various examples of desynchronization in the strong coupling regime are presented. First, a globally coupled network of identical neurons with strong inhibitory coupling is shown to exhibit oscillator death in which some of the neurons suppress the activity of others. However, the stability of the synchronous state persists for very large networks and fast synapses. Second, an asymmetric network with a mixture of excitation and inhibition is shown to exhibit periodic bursting patterns. Finally, a one-dimensional network of neurons with long-range interactions is shown to desynchronize to a state with a spatially periodic pattern of mean firing rates across the network. This is modulated by deterministic fluctuations of the instantaneous firing rate whose size is an increasing function of the speed of synaptic response.},
	number = {1},
	journal = {Neural Comput.},
	author = {Bressloff, Pc and Coombes, S},
	month = jan,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {91--129},
}

@article{bressloff_desynchronization_1998,
	title = {Desynchronization, {Mode} {Locking}, and {Bursting} in {Strongly} {Coupled} {Integrate}-and-{Fire} {Oscillators}},
	volume = {81},
	abstract = {We show how a synchronized pair of integrate-and-fire neural oscillators with noninstantaneous synaptic interactions can destabilize in the strong coupling regime resulting in non-phase-locked behavior. In the case of symmetric inhibitory coupling, desynchronization produces an inhomogeneous state in which one of the oscillators becomes inactive (oscillator death). On the other hand, for asymmetric excitatory/inhibitory coupling, mode locking can occur leading to periodic bursting patterns. The consequences for large globally coupled networks is discussed.},
	number = {10},
	journal = {Phys. Rev. Lett.},
	author = {Bressloff, P C and Coombes, S},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {2168--2171},
}

@article{chow_phase-locking_1998,
	title = {Phase-locking in weakly heterogeneous neuronal networks},
	volume = {118},
	abstract = {We examine analytically the existence and stability of phase-locked states in a weakly heterogeneous neuronal network. We consider a model of N neurons with all-to-all synaptic coupling where the heterogeneity is in the intrinsic firing frequency of the individual neurons. We consider both inhibitory and excitatory coupling. We derive the conditions under which stable phase-locking is possible. In homogeneous networks, many different periodic phase-locked states are possible. Their stability depends on the dynamics of the neuron and the coupling. For weak heterogeneity, the phase-locked states are perturbed from the homogeneous states and can remain stable if their homogeneous counterparts are stable. For enough heterogeneity, phase-locked solutions either lose stability or are destroyed completely. We analyze the possible states the network can take when phase-locking is broken.},
	number = {3-4},
	journal = {Physica D},
	author = {Chow, Carson C},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {343--370},
}

@article{gerstner_time_1995,
	title = {Time structure of the activity in neural network models},
	volume = {51},
	abstract = {Several neural network models in continuous time are reconsidered in the framework of a general mean-field theory which is exact in the limit of a large and fully connected network. The theory assumes pointlike spikes which are generated by a renewal process. The effect of spikes on a receiving neuron is described by a linear response kernel which is the dominant term in a weak-coupling expansion. It is shown that the resulting “spike response model” is the most general renewal model with linear inputs. The standard integrate-and-fire model forms a special case. In a network structure with several pools of identical spiking neurons, the global states and the dynamic evolution are determined by a nonlinear integral equation which describes the effective interaction within and between different pools. We derive explicit stability criteria for stationary (incoherent) and oscillatory (coherent) solutions. It is shown that the stationary state of noiseless systems is “almost always” unstable. Noise suppresses fast oscillations and stabilizes the system. Furthermore, collective oscillations are stable only if the firing occurs while the synaptic potential is increasing. In particular, collective oscillations in a network with delayless excitatory interaction are at most semistable. Inhibitory interactions with short delays or excitatory interactions with long delays lead to stable oscillations. Our general results allow a straightforward application to different network models with spiking neurons. Furthermore, the theory allows an estimation of the errors introduced in firing rate or “graded-response” models.},
	number = {1},
	journal = {Phys. Rev. E},
	author = {Gerstner, Wulfram},
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {738--758},
}

@article{toomarian_learning_1992,
	title = {Learning a {Trajectory} {Using} {Adjoint} {Functions} and {Teacher} {Forcing}},
	volume = {5},
	journal = {Neural Netw.},
	author = {Toomarian, Nekzad Benny and Barhen, Jacob},
	year = {1992},
	keywords = {Teacher forcing, merged\_fiete.bib, Adjoint operators, Recurrent networks., Temporal learning, Trajectory learning},
	pages = {473--484},
}

@article{wersing_competitive-layer_2001,
	title = {A competitive-layer model for feature binding and sensory segmentation},
	volume = {13},
	abstract = {We present a recurrent neural network for feature binding and sensory segmentation: the competitive-layer model (CLM). The CLM uses topographically structured competitive and cooperative interactions in a layered network to partition a set of input features into salient groups. The dynamics is formulated within a standard additive recurrent network with linear threshold neurons. Contextual relations among features are coded by pairwise compatibilities, which define an energy function to be minimized by the neural dynamics. Due to the usage of dynamical winner-take-all circuits, the model gains more flexible response properties than spin models of segmentation by exploiting amplitude information in the grouping process. We prove analytic results on the convergence and stable attractors of the CLM, which generalize earlier results on winner-take-all networks, and incorporate deterministic annealing for robustness against local minima. The piecewise linear dynamics of the CLM allows a linear eigensubspace analysis, which we use to analyze the dynamics of binding in conjunction with annealing. For the example of contour detection, we show how the CLM can integrate figure-ground segmentation and grouping into a unified model.},
	number = {2},
	journal = {Neural Comput.},
	author = {Wersing, H and Steil, Jj and Ritter, H},
	month = feb,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {357--387},
}

@article{diesmann_stable_1999,
	title = {Stable propagation of synchronous spiking in cortical neural networks},
	volume = {402},
	abstract = {The classical view of neural coding has emphasized the importance of information carried by the rate at which neurons discharge action potentials. More recent proposals that information may be carried by precise spike timing have been challenged by the assumption that these neurons operate in a noisy fashion–presumably reflecting fluctuations in synaptic input and, thus, incapable of transmitting signals with millisecond fidelity. Here we show that precisely synchronized action potentials can propagate within a model of cortical network activity that recapitulates many of the features of biological systems. An attractor, yielding a stable spiking precision in the (sub)millisecond range, governs the dynamics of synchronization. Our results indicate that a combinatorial neural code, based on rapid associations of groups of neurons co-ordinating their activity at the single spike level, is possible within a cortical-like network.},
	number = {6761},
	journal = {Nature},
	author = {Diesmann, M and Gewaltig, Mo and Aertsen, A},
	month = dec,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {529--533},
}

@article{hopfield_pattern_1995,
	title = {Pattern recognition computation using action potential timing for stimulus representation},
	volume = {376},
	abstract = {A computational model is described in which the sizes of variables are represented by the explicit times at which action potentials occur, rather than by the more usual 'firing rate' of neurons. The comparison of patterns over sets of analogue variables is done by a network using different delays for different information paths. This mode of computation explains how one scheme of neuroarchitecture can be used for very different sensory modalities and seemingly different computations. The oscillations and anatomy of the mammalian olfactory systems have a simple interpretation in terms of this representation, and relate to processing in the auditory system. Single-electrode recording would not detect such neural computing. Recognition 'units' in this style respond more like radial basis function units than elementary sigmoid units.},
	number = {6535},
	journal = {Nature},
	author = {Hopfield, Jj},
	month = jul,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {33--36},
}

@article{lee_attention_1999,
	title = {Attention activates winner-take-all competition among visual filters},
	volume = {2},
	abstract = {Shifting attention away from a visual stimulus reduces, but does not abolish, visual discrimination performance. This residual vision with 'poor' attention can be compared to normal vision with 'full' attention to reveal how attention alters visual perception. We report large differences between residual and normal visual thresholds for discriminating the orientation or spatial frequency of simple patterns, and smaller differences for discriminating contrast. A computational model, in which attention activates a winner-take-all competition among overlapping visual filters, quantitatively accounts for all observations. Our model predicts that the effects of attention on visual cortical neurons include increased contrast gain as well as sharper tuning to orientation and spatial frequency.},
	number = {4},
	journal = {Nat. Neurosci.},
	author = {Lee, Dk and Itti, L and Koch, C and Braun, J},
	month = apr,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {375--381},
}

@article{feng_qualitative_1996,
	title = {Qualitative behaviour of some simple networks},
	volume = {29},
	abstract = {Some classical neural network systems including the Hartline - Ratliff system, the Linsker system, and the general sigmoid dynamics, are reconsidered within a more general class of dynamical systems. For synchronous dynamics the existence, uniqueness, local and global stability of stationary points is investigated. For asynchronous dynamics a convergence theorem is proved. The application of the theory of quasimonotone flows leads to some insights so far not widespread in network theory.},
	number = {16},
	journal = {J. Phys. A Math. Gen.},
	author = {Feng, J and Hadeler, K P},
	month = aug,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {5019--5033},
}

@article{troyer_associational_2000,
	title = {An associational model of birdsong sensorimotor learning {I}. {Efference} copy and the learning of song syllables},
	volume = {84},
	abstract = {Birdsong learning provides an ideal model system for studying temporally complex motor behavior. Guided by the well-characterized functional anatomy of the song system, we have constructed a computational model of the sensorimotor phase of song learning. Our model uses simple Hebbian and reinforcement learning rules and demonstrates the plausibility of a detailed set of hypotheses concerning sensory-motor interactions during song learning. The model focuses on the motor nuclei HVc and robust nucleus of the archistriatum (RA) of zebra finches and incorporates the long-standing hypothesis that a series of song nuclei, the Anterior Forebrain Pathway (AFP), plays an important role in comparing the bird's own vocalizations with a previously memorized song, or “template.” This “AFP comparison hypothesis” is challenged by the significant delay that would be experienced by presumptive auditory feedback signals processed in the AFP. We propose that the AFP does not directly evaluate auditory feedback, but instead, receives an internally generated prediction of the feedback signal corresponding to each vocal gesture, or song “syllable.” This prediction, or “efference copy,” is learned in HVc by associating premotor activity in RA-projecting HVc neurons with the resulting auditory feedback registered within AFP-projecting HVc neurons. We also demonstrate how negative feedback “adaptation” can be used to separate sensory and motor signals within HVc. The model predicts that motor signals recorded in the AFP during singing carry sensory information and that the primary role for auditory feedback during song learning is to maintain an accurate efference copy. The simplicity of the model suggests that associational efference copy learning may be a common strategy for overcoming feedback delay during sensorimotor learning.},
	number = {3},
	journal = {J. Neurophysiol.},
	author = {Troyer, T W and Doupe, A J},
	month = sep,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1204--1223},
}

@article{troyer_associational_2000-1,
	title = {An associational model of birdsong sensorimotor learning {II}. {Temporal} hierarchies and the learning of song sequence},
	volume = {84},
	abstract = {Understanding the neural mechanisms underlying serially ordered behavior is a fundamental problem in motor learning. We present a computational model of sensorimotor learning in songbirds that is constrained by the known functional anatomy of the song circuit. The model subsumes our companion model for learning individual song “syllables” and relies on the same underlying assumptions. The extended model addresses the problem of learning to produce syllables in the correct sequence. Central to our approach is the hypothesis that the Anterior Forebrain Pathway (AFP) produces signals related to the comparison of the bird's own vocalizations and a previously memorized “template.” This “AFP comparison hypothesis” is challenged by the lack of a direct projection from the AFP to the song nucleus HVc, a candidate site for the generator of song sequence. We propose that sequence generation in HVc results from an associative chain of motor and sensory representations (motor –{\textgreater} sensory –{\textgreater} next motor. ) encoded within the two known populations of HVc projection neurons. The sensory link in the chain is provided, not by auditory feedback, but by a centrally generated efference copy that serves as an internal prediction of this feedback. The use of efference copy as a substitute for the sensory signal explains the ability of adult birds to produce normal song immediately after deafening. We also predict that the AFP guides sequence learning by biasing motor activity in nucleus RA, the premotor nucleus downstream of HVc. Associative learning then remaps the output of the HVc sequence generator. By altering the motor pathway in RA, the AFP alters the correspondence between HVc motor commands and the resulting sensory feedback and triggers renewed efference copy learning in HVc. Thus, auditory feedback-mediated efference copy learning provides an indirect pathway by which the AFP can influence sequence generation in HVc. The model makes predictions concerning the role played by specific neural populations during the sensorimotor phase of song learning and demonstrates how simple rules of associational plasticity can contribute to the learning of a complex behavior on multiple time scales.},
	number = {3},
	journal = {J. Neurophysiol.},
	author = {Troyer, T W and Doupe, A J},
	month = sep,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1224--1239},
}

@article{ermentrout_complex_1992,
	title = {Complex {Dynamics} in {Winner}-{Take}-{All} {Neural} {Nets} {With} {Slow} {Inhibition}},
	volume = {5},
	abstract = {WE consider a layer of excitatory neurons with small asymmetric excitatory connections and strong coupling to a single inhibitory interneuron. If the inhibition is fast, the network behaves as a winner-take-all network in which one cell fires at the expense of all others. As the inhibition slows down, oscillatory behavior begins. This is followed by a symmetric rotating solution in which neurons share the activity in a round-robin fashion. Finally, if the inhibition is sufficiently slower than excitation the neurons completely synchronize to a global periodic solution. Conditions guaranteeing stable synchrony are given.},
	journal = {Neural Netw.},
	author = {Ermentrout, Bard},
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {415--431},
}

@article{connor_neural_1977,
	title = {Neural repetitive firing: modifications of the {Hodgkin}-{Huxley} axon suggested by experimental results from crustacean axons},
	volume = {18},
	abstract = {The Hodgkin-Huxley equations for space-clamped squid axon (18 degrees C) have been modified to approximate voltage clamp data from repetitive-firing crustacean walking leg axons and activity in response to constant current stimulation has been computed. The m infinity and h infinity parameters of the sodium conductance system were shifted along the voltage axis in opposite directions so that their relative overlap was increased approximately 7 mV. Time constants tau m and tau h, were moved in a similar manner. Voltage-dependent parameters of delayed potassium conductance, n infinity and tau n, were shifted 4.3 mV in the positive direction and tau n was uniformly increased by a factor of 2. Leakage conductance and capacitance were unchanged. Repetitive activity of this modified circuit was qualitatively similar to that of the standard model. A fifth branch was added to the circuit representing a transient potassium conductance system present in the repetitive walking leg axons and in other repetitive neurons. This model, with various parameter choices, fired repetitively down to approximately 2 spikes/s and up to 350/s. The frequency vs. stimulus current plot could be fit well by a straight line over a decade of the low frequency range and the general appearance of the spike trains was similar to that of other repetitive neurons. Stimulus intensities were of the same order as those which produce repetitive activity in the standard Hodgkin-Huxley axon. The repetitive firing rate and first spike latency (utilization time) were found to be most strongly influenced by the inactivation time constant of the transient potassium conductance (tau b), the delayed potassium conductance (tau n), and the value of leakage conductance (gL). The model presents a mechanism by which stable low frequency discharge can be generated by millisecond-order membrane conductance changes.},
	number = {1},
	journal = {Biophys. J.},
	author = {Connor, J A and Walter, D and Mckown, R},
	month = apr,
	year = {1977},
	keywords = {merged\_fiete.bib},
	pages = {81--102},
}

@article{chen_wave_1998,
	title = {Wave propagation mediated by {GABAB} synapse and rebound excitation in an inhibitory network: a reduced model approach},
	volume = {5},
	abstract = {A reduction method is used to analyze a spatially structured network model of inhibitory neurons. This network model displays wave propagation of postinhibitory rebound activity, which depends on GABAB synaptic interactions among the neurons. The reduced model allows explicit solutions for the wavefronts and their velocity as a function of various parameters, such as the synaptic coupling strength. These predictions are shown to agree well with the numerical simulations of the conductance-based biophysical model.},
	number = {1},
	journal = {J. Comput. Neurosci.},
	author = {Chen, Z and Ermentrout, B and Wang, Xj},
	month = mar,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {53--69},
}

@article{brunel_dynamics_2000,
	title = {Dynamics of networks of randomly connected excitatory and inhibitory spiking neurons},
	volume = {94},
	abstract = {Recent advances in the understanding of the dynamics of populations of spiking neurones are reviewed. These studies shed light on how a population of neurones can follow arbitrary variations in input stimuli, how the dynamics of the population depends on the type of noise, and how recurrent connections influence the dynamics. The importance of inhibitory feedback for the generation of irregularity in single cell behaviour is emphasized. Examples of computation that recurrent networks with excitatory and inhibitory cells can perform are then discussed. Maintenance of a network state as an attractor of the system is discussed as a model for working memory function, in both object and spatial modalities. These models can be used to interpret and make predictions about electrophysiological data in the awake monkey.},
	journal = {J. Physiol.},
	author = {Brunel, N},
	year = {2000},
	keywords = {merged\_fiete.bib, inhibition, network, attractor dynamics, working memory, noise, dynamics, integrate-and-fire neurone, irregularity, models, synchronization},
	pages = {445--463},
}

@article{mazzoni_more_1991,
	title = {A more biologically plausible learning rule for neural networks},
	volume = {88},
	abstract = {Many recent studies have used artificial neural network algorithms to model how the brain might process information. However, back-propagation learning, the method that is generally used to train these networks, is distinctly “unbiological.” We describe here a more biologically plausible learning rule, using reinforcement learning, which we have applied to the problem of how area 7a in the posterior parietal cortex of monkeys might represent visual space in head-centered coordinates. The network behaves similarly to networks trained by using back-propagation and to neurons recorded in area 7a. These results show that a neural network does not require back propagation to acquire biologically interesting properties.},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {{Mazzoni} and {P.} and {Ersen} and {R.a.} and {Jordan} and {M.i.}},
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {4433--4437},
}

@article{1_intracortical_2001,
	title = {Intracortical origin of visual maps},
	volume = {4},
	abstract = {Previous experiments indicate that the shape of maps of preferred orientation in the primary visual cortex does not depend on visual experience. We propose a network model that demonstrates that the orientation and direction selectivity of individual units and the structure of the corresponding angle maps could emerge from local recurrent connections. Our model reproduces the structure of preferred orientation and direction maps, and explains the origin of their interrelationship. The model also provides an explanation for the correlation between position shifts of receptive fields and changes of preferred orientations of single neurons across the surface of the cortex.},
	journal = {Nat. Neurosci.},
	author = {1, U A Ernst and 1, K R Pawelzik and 2, C Sahar-Pikielny and {3} and 3, M V Tsodyks},
	month = apr,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {431},
}

@article{slotine_modularity_2001,
	title = {Modularity, {Evolution}, and the {Binding} {Problem}: {A} {View} from {Stability} {Theory}},
	volume = {14},
	abstract = {Any biological object, and specifically the brain, is the result of evolution. Evolution proceeds by accumulation and combination of stable intermediate states - as is well known, survival of the fittest really means survival of the stable. Simple examples abound: for instance, human emotional response involves both a fast archaic loop bypassing the cortex, and a slower cortical loop; motion control architecture in vertebrates is believed to involve combinations of simple motor primitives. However, in themselves, accumulations and combinations of stable elements have no reason to be stable. Hence the hypothesis that evolution will favor a particular form of stability, which automatically guarantees stability in combination. Such a form of stability, which we refer to as “contraction”, can be characterized mathematically. This, contraction theory may help guide functional modelling of the central nervous system, and conversely it provides a systematic method to build arbitrarily complex robots out of simpler elements. Furthermore, contraction theory may shed light on the problem of perceptual unity (binding problem) by providing simple models and conditions for the overall convergence of a large number of specialized processing elements connected through networks of feedback loops.},
	number = {2},
	journal = {Neural Netw.},
	author = {Slotine, J J E and Lohmiller, W},
	month = feb,
	year = {2001},
	keywords = {merged\_fiete.bib},
}

@article{suder_neural_nodate,
	title = {Neural field model of receptive field restructuring in primary visual cortex},
	abstract = {Receptive fields (RF) in the visual cortex can change their size depending on the state of the individual. This reflects a changing visual resolution according to different demands on information processing during drowsiness. So far, however, the possible mechanisms that underlie these size changes have not been tested rigorously. Only qualitatively has it been suggested that state-dependent lateral geniculate nucleus (LGN) firing patterns (burst versus tonic firing) are mainly responsible for the observed cortical receptive field restructuring. Here, we employ a neural field approach to describe the changes of cortical RF properties analytically. Expressions to describe the spatiotemporal receptive fields are given for pure feedforward networks. The model predicts that visual latencies increase nonlinearly with the distance of the stimulus location from the RF center. RF restructuring effects are faithfully reproduced. Despite the changing RF sizes, the model demonstrates that the width of the spatial membrane potential profile (as measured by the variance sigma of a gaussian) remains constant in cortex. In contrast, it is shown for recurrent networks that both the RF width and the width of the membrane potential profile generically depend on time and can even increase if lateral cortical excitatory connections extend further than fibers from LGN to cortex. In order to differentiate between a feedforward and a recurrent mechanism causing the experimental RF changes, we fitted the data to the analytically derived point-spread functions. Results of the fits provide estimates for model parameters consistent with the literature data and support the hypothesis that the observed RF sharpening is indeed mainly driven by input from LGN, not by recurrent intracortical connections.},
	author = {Suder, K and Worgotter, F and Wennekers, T},
	keywords = {merged\_fiete.bib},
}

@article{adorjan_statistical_1999,
	title = {A statistical neural field approach to orientation selectivity},
	volume = {26-7},
	abstract = {We apply the recently proposed statistical neural field approach [4,3] for modeling orientation selectivity in the primary visual cortex. Firstly, we demonstrate that the neural held approach is a powerful tool for modeling neural structures with specific lateral connections. Secondly, we test in a biologically more plausible way our hypothesis [1] that orientation bias and tuning in macaque striate cortex can be generated by the same lateral interactions. The spiking neural model shows that (i) contrast invariant tuning emerges and (ii) the tuning dynamics of the membrane potential and the firing rate are in accordance with observations which until now seemed to be contradictory [2,5-7].},
	journal = {Neurocomputing},
	author = {Adorjan, P and Barna, G and Erdi, P and Obermayer, K},
	month = jun,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {313--318},
}

@article{rabinovich_dynamical_nodate,
	title = {Dynamical encoding by networks of competing neuron groups: winnerless competition},
	abstract = {Following studies of olfactory processing in insects and fish, we investigate neural networks whose dynamics in phase space is represented by orbits near the heteroclinic connections between saddle regions (fixed points or limit cycles). These networks encode input information as trajectories along the heteroclinic connections. If there are N neurons in the network, the capacity is approximately e(N-1)!, i.e., much larger than that of most traditional network structures. We show that a small winnerless competition network composed of FitzHugh-Nagumo spiking neurons efficiently transforms input information into a spatiotemporal output.},
	author = {Rabinovich, M and Volkovskii, A and Lecanda, P and Huerta, R and Abarbanel, Hd and Laurent, G},
	keywords = {merged\_fiete.bib},
}

@article{ben-yishai_theory_1995,
	title = {Theory of orientation tuning in visual cortex},
	volume = {92},
	abstract = {The role of intrinsic cortical connections in processing sensory input and in generating behavioral output is poorly understood. We have examined this issue in the context of the tuning of neuronal responses in cortex to the orientation of a visual stimulus. We analytically study a simple network model that incorporates both orientation-selective input from the lateral geniculate nucleus and orientation-specific cortical interactions. Depending on the model parameters, the network exhibits orientation selectivity that originates from within the cortex, by a symmetry-breaking mechanism. In this case, the width of the orientation tuning can be sharp even if the lateral geniculate nucleus inputs are only weakly anisotropic. By using our model, several experimental consequences of this cortical mechanism of orientation tuning are derived. The tuning width is relatively independent of the contrast and angular anisotropy of the visual stimulus. The transient population response to changing of the stimulus orientation exhibits a slow “virtual rotation.” Neuronal cross-correlations exhibit long time tails, the sign of which depends on the preferred orientations of the cells and the stimulus orientation.},
	number = {9},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Ben-Yishai, R and Bar-Or, R L and Sompolinsky, H},
	month = apr,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {3844--3848},
}

@article{somers_emergent_1995,
	title = {An emergent model of orientation selectivity in cat visual cortical simple cells},
	volume = {15},
	abstract = {It is well known that visual cortical neurons respond vigorously to a limited range of stimulus orientations, while their primary afferent inputs, neurons in the lateral geniculate nucleus (LGN), respond well to all orientations. Mechanisms based on intracortical inhibition and/or converging thalamocortical afferents have previously been suggested to underlie the generation of cortical orientation selectivity; however, these models conflict with experimental data. Here, a 1:4 scale model of a 1700 microns by 200 microms region of layer IV of cat primary visual cortex (area 17) is presented to demonstrate that local intracortical excitation may provide the dominant source of orientation-selective input. In agreement with experiment, model cortical cells exhibit sharp orientation selectivity despite receiving strong iso-orientation inhibition, weak cross-orientation inhibition, no shunting inhibition, and weakly tuned thalamocortical excitation. Sharp tuning is provided by recurrent cortical excitation. As this tuning signal arises from the same pool of neurons that it excites, orientation selectivity in the model is shown to be an emergent property of the cortical feedback circuitry. In the model, as in experiment, sharpness of orientation tuning is independent of stimulus contrast and persists with silencing of ON-type subfields. The model also provides a unified account of intracellular and extracellular inhibitory blockade experiments that had previously appeared to conflict over the role of inhibition. It is suggested that intracortical inhibition acts nonspecifically and indirectly to maintain the selectivity of individual neurons by balancing strong intracortical excitation at the columnar level.},
	number = {8},
	journal = {J. Neurosci.},
	author = {Somers, Dc and Nelson, Sb and Sur, M},
	month = aug,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {5448--5465},
}

@techreport{frank_interactions_2001,
	title = {Interactions {Between} {Frontal} cortex and {Basal} {Ganglia} in {Working} {Memory}: {A} computational {Model}},
	abstract = {The frontal cortex and basal ganglia interact via a relatively well-unerstood and elaborate system of interconnections. In the context of motor function, these interconnections can be understood as disinhibiting or “releasing the brakes” on frontal motor action plans -the basal ganglia dectect appropriate contexts for performing motor actions, and enable the frontal cortex to execute such actions at the appropriate time. We build on this idea in the domain of working memory through the use of computational neural network models of this circuit. In our model, the frontal cortex exhibits memory representations to be rapidly updated in a task-relevant manner. We aply the model to a novel version of the continuous performance task (CPT) that requires subroutine-like selective working memory updating, and compare and contrast our model with other exisiting models and theories of frontal cortex-basal ganglia interactions.},
	institution = {University of Colorado, Boulder},
	author = {{Frank} and {M.} and {Loughry} and {B.} and O'reilly, \& and {R.}},
	month = apr,
	year = {2001},
	keywords = {merged\_fiete.bib},
}

@article{feng_stability_2001,
	title = {On the stability analysis of delayed neural networks systems},
	volume = {14},
	abstract = {In this paper, the problems of stability of delayed neural networks are investigated, including the stability of discrete and distributed delayed neural networks. Under the generalization of dropping the Lipschitzian hypotheses for output functions, some stability criteria are obtained by using the Liapunov functional method. We do not assume the symmetry of the connection matrix and we establish that the system admits a unique equilibrium point in which the output functions do not satisfy the Lipschitz conditions and do not require them to be differential or strictly monotonously increasing. These criteria can be used to analyze the dynamics of biological neural systems or to design globally stable artificial neural networks.},
	number = {9},
	journal = {Neural Netw.},
	author = {Feng, Chunhua and Plamondon, Réjean},
	month = nov,
	year = {2001},
	keywords = {Neural networks, merged\_fiete.bib, Global asymptotical stability, Liapunov functional, Time delays},
	pages = {1181--1188},
}

@article{mclaughlin_neuronal_2000,
	title = {A neuronal network model of macaque primary visual cortex ({V1}): orientation selectivity and dynamics in the input layer {4Calpha}},
	volume = {97},
	abstract = {In this paper, we offer an explanation for how selectivity for orientation could be produced by a model with circuitry that is based on the anatomy of V1 cortex. It is a network model of layer 4Calpha in macaque primary visual cortex (area V1). The model consists of a large number of integrate-and-fire conductance-based point neurons, both excitatory and inhibitory, which represent dynamics in a small patch of 4Calpha-1 mm(2) in lateral area-which contains four orientation hypercolumns. The physiological properties and coupling architectures of the model are derived from experimental data for layer 4Calpha of macaque. Convergent feed-forward input from many neurons of the lateral geniculate nucleus sets up an orientation preference, in a pinwheel pattern with an orientation preference singularity in the center of the pattern. Recurrent cortical connections cause the network to sharpen its selectivity. The pattern of local lateral connections is taken as isotropic, with the spatial range of monosynaptic excitation exceeding that of inhibition. The model (i) obtains sharpening, diversity in selectivity, and dynamics of orientation selectivity, each in qualitative agreement with experiment; and (ii) predicts more sharpening near orientation preference singularities.},
	number = {14},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Mclaughlin, D and Shapley, R and Shelley, M and Wielaard, Dj},
	month = jul,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {8087--8092},
}

@article{wielaard_how_2001,
	title = {How simple cells are made in a nonlinear network model of the visual cortex},
	volume = {21},
	abstract = {Simple cells in the striate cortex respond to visual stimuli in an approximately linear manner, although the LGN input to the striate cortex, and the cortical network itself, are highly nonlinear. Although simple cells are vital for visual perception, there has been no satisfactory explanation of how they are produced in the cortex. To examine this question, we have developed a large-scale neuronal network model of layer 4Calpha in V1 of the macaque cortex that is based on, and constrained by, realistic cortical anatomy and physiology. This paper has two aims: (1) to show that neurons in the model respond like simple cells. (2) To identify how the model generates this linearized response in a nonlinear network. Each neuron in the model receives nonlinear excitation from the lateral geniculate nucleus (LGN). The cells of the model receive strong (nonlinear) lateral inhibition from other neurons in the model cortex. Mathematical analysis of the dependence of membrane potential on synaptic conductances, and computer simulations, reveal that the nonlinearity of corticocortical inhibition cancels the nonlinear excitatory input from the LGN. This interaction produces linearized responses that agree with both extracellular and intracellular measurements. The model correctly accounts for experimental results about the time course of simple cell responses and also generates testable predictions about variation in linearity with position in the cortex, and the effect on the linearity of signal summation, caused by unbalancing the relative strengths of excitation and inhibition pharmacologically or with extrinsic current.},
	number = {14},
	journal = {J. Neurosci.},
	author = {Wielaard, Dj and Shelley, M and Mclaughlin, D and Shapley, R},
	month = jul,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {5203--5211},
}

@article{golomb_continuous_1999,
	title = {Continuous and lurching traveling pulses in neuronal networks with delay and spatially decaying connectivity},
	volume = {96},
	number = {23},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Golomb, David and Ermentrout, G Bard},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {13480--13485},
}

@article{wu_population_nodate,
	title = {Population {Coding} and {Decoding} in a {Neural} {Field}: {A} {Computational} {Study}},
	journal = {Neural Comput.},
	author = {Wu, S and Amari, S and Nakahara, H},
	keywords = {merged\_fiete.bib},
}

@article{battaglia_stable_1998,
	title = {Stable and rapid recurrent processing in realistic autoassociative memories},
	volume = {10},
	abstract = {It is shown that in those autoassociative memories that learn by storing multiple patterns of activity on their recurrent collateral connections, there is a fundamental conflict between dynamical stability and storage capacity. It is then found that the network can nevertheless retrieve many different memory patterns, as predicted by nondynamical analyses, if its firing is regulated by inhibition that is sufficiently multiplicative in nature. Simulations of a model network with integrate-and-fire units confirm that this is a realistic solution to the conflict. The simulations also confirm the earlier analytical result that cued-elicited memory retrieval, which follows an exponential time course, occurs in a time linearly related to the time constant for synaptic conductance inactivation and relatively independent of neuronal time constants and firing levels.},
	number = {2},
	journal = {Neural Comput.},
	author = {Battaglia, Fp and Treves, A},
	month = feb,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {431--450},
}

@article{trevesa_time_1997,
	title = {Time for retrieval in recurrent associative memories},
	volume = {107},
	abstract = {Experimental evidence shows that certain types of visual information processing, such as face recognition, may be extremely rapid: in a few tens of milliseconds a neuron may yield most of the information about a visual stimulus that can ever be extracted from the response of that neuron. These data might be taken to indicate that there is insufficient time for recurrent or feedback processing. However, a novel analytical method allows the analysis of the dynamics of an associative memory network of integrate-and-fire neurons, laterally connected through realistically modelled synapses. The analysis, supported by preliminary simulations, indicates that the network may retrieve information from memory over a time determined mainly by excitatory synaptic conductance time constants, that is in times in the order of tens of milliseconds. The results thus show that the dynamics of recurrent processing is sufficiently rapid for it to contribute to processing within the short times observed in neurophysiological experiments.},
	journal = {Physica D},
	author = {Trevesa, Alessandro and Rollsa, Edmund T and Simmena, Martin},
	month = sep,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {392--400},
}

@article{delorme_spikenet_1999,
	title = {{SpikeNET}: {A} simulator for modeling large networks of integrate and fire neurons},
	volume = {26-27},
	abstract = {SpikeNET is a simulator for modeling large networks of asynchronously spiking neurons. It uses simple integrate-and-fire neurons which undergo step-like changes in membrane potential when synaptic inputs arrive. If a threshold is exceeded, the potential is reset and the neuron added to a list to be propagated on the next time step. Using such spike lists greatly reduces the computations associated with large networks, and simplifies implementations using parallel hardware since inter-processor communication can be limited to sending lists of the neurons which just fired. We have used it to model complex multi-layer architectures based on the primate visual system that involve millions of neurons and billions of synaptic connections. Such models are not only biological but also efficient, robust and very fast, qualities which they share with the human visual system.},
	journal = {Neurocomputing},
	author = {Delorme, Arnaud and Gautrais, Jacques and Van Rullen, Rufin and {Simonthorpe}},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {989--996},
}

@article{hahnloser_digital_2000,
	title = {Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit},
	volume = {405},
	abstract = {Digital circuits such as the flip-flop use feedback to achieve multistability and nonlinearity to restore signals to logical levels, for example 0 and 1. Analogue feedback circuits are generally designed to operate linearly, so that signals are over a range, and the response is unique. By contrast, the response of cortical circuits to sensory stimulation can be both multistable and graded. We propose that the neocortex combines digital selection of an active set of neurons with analogue response by dynamically varying the positive feedback inherent in its recurrent connections. Strong positive feedback causes differential instabilities that drive the selection of a set of active neurons under the constraints embedded in the synaptic weights. Once selected, the active neurons generate weaker, stable feedback that provides analogue amplification of the input. Here we present our model of cortical processing as an electronic circuit that emulates this hybrid operation, and so is able to perform computations that are similar to stimulus selection, gain modulation and spatiotemporal pattern generation in the neocortex.},
	number = {6789},
	journal = {Nature},
	author = {Hahnloser, Rh and Sarpeshkar, R and Mahowald, Ma and Douglas, Rj and Seung, Hs},
	month = jun,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {947--951},
}

@inproceedings{thorpe_rank_1998,
	title = {Rank {Order} {Coding}},
	booktitle = {Computational {Neuroscience}: {Trends} in {Research}},
	publisher = {Plenum Press, New York},
	author = {Thorpe, Simon and Gautrais, Jacques},
	editor = {Bower, J},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {113--119},
}

@article{sommer_associative_2001,
	title = {Associative memory in networks of spiking neurons},
	volume = {14},
	abstract = {Here, we develop and investigate a computational model of a network of cortical neurons on the base of biophysically well constrained and tested two-compartmental neurons developed by Pinsky and Rinzel [Pinsky, P. F., \& Rinzel, J. (1994). Intrinsic and network rhythmogenesis in a reduced Traub model for CA3 neurons. Journal of Computational Neuroscience, 1, 39-60]. To study associative memory, we connect a pool of cells by a structured connectivity matrix. The connection weights are shaped by simple Hebbian coincidence learning using a set of spatially sparse patterns. We study the neuronal activity processes following an external stimulation of a stored memory. In two series of simulation experiments, we explore the effect of different classes of external input, tonic and flashed stimulation. With tonic stimulation, the addressed memory is an attractor of the network dynamics. The memory is displayed rhythmically, coded by phase-locked bursts or regular spikes. The participating neurons have rhythmic activity in the gamma-frequency range (30-80 Hz). If the input is switched from one memory to another, the network activity can follow this change within one or two gamma cycles. Unlike similar models in the literature, we studied the range of high memory capacity (in the order of 0.1 bit/synapse), comparable to optimally tuned formal associative networks. We explored the robustness of efficient retrieval varying the memory load, the excitation/inhibition parameters, and background activity. A stimulation pulse applied to the identical simulation network can push away ongoing network activity and trigger a phase-locked association event within one gamma period. Unlike as under tonic stimulation, the memories are not attractors. After one association process, the network activity moves to other states. Applying in close succession pulses addressing different memories, one can switch through the space of memory patterns. The readout speed can be increased up to the point where in every gamma cycle another pattern is displayed. With pulsed stimulation. bursts become relevant for coding, their occurrence can be used to discriminate relevant processes from background activity.},
	number = {6-7},
	journal = {Neural Netw.},
	author = {Sommer, Ft and Wennekers, T},
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {825--834},
}

@article{koch_simple_1992,
	title = {A {Simple} {Network} {Showing} {Burst} {Synchronization} without {Frequency} {Locking}},
	volume = {4},
	abstract = {The dynamic behavior of a network model consisting of all-to-all excitatory coupled binary neurons with global inhibition is studied analytically and numerically. We prove that for random input signals, the output of the network consists of schronized bursts with apparently random intermissions of noisy activity. We introduce the fraction of simultaneously firing neurons as a measure for synchrony and prove that its temporal correlation function displays, besides a delta peak at zero indicating random processes, strongly damped oscillations. Our results suggest that synchronous bursts can be generated by a simple neuronal architecture that amplifies incoming coincident signals. This synchronization process is accompanied by dampened oscillations that, by themselves, however, do not play any constructive role in this and can therefore be considered to be an epiphenomenon.},
	journal = {Neural Comput.},
	author = {Koch, Christof and Schuster, Heinz},
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {211--223},
}

@article{riesenhuber_hierarchical_1999,
	title = {Hierarchical models of object recognition in cortex},
	volume = {2},
	abstract = {Visual processing in cortex is classically modeled as a hierarchy of increasingly sophisticated representations, naturally extending the model of simple to complex cells of Hubel and Wiesel. Surprisingly, little quantitative modeling has been done to explore the biological feasibility of this class of models to explain aspects of higher-level visual processing such as object recognition. We describe a new hierarchical model consistent with physiological data from inferotemporal cortex that accounts for this complex visual task and makes testable predictions. The model is based on a MAX-like operation applied to inputs to certain cortical neurons that may have a general role in cortical function.},
	number = {11},
	journal = {Nat. Neurosci.},
	author = {Riesenhuber, M and Poggio, T},
	month = nov,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {1019--1025},
}

@article{van_c_chaotic_1998,
	title = {Chaotic balanced state in a model of cortical circuits},
	volume = {10},
	abstract = {The nature and origin of the temporal irregularity in the electrical activity of cortical neurons in vivo are not well understood. We consider the hypothesis that this irregularity is due to a balance of excitatory and inhibitory currents into the cortical cells. We study a network model with excitatory and inhibitory populations of simple binary units. The internal feedback is mediated by relatively large synaptic strengths, so that the magnitude of the total excitatory and inhibitory feedback is much larger than the neuronal threshold. The connectivity is random and sparse. The mean number of connections per unit is large, though small compared to the total number of cells in the network. The network also receives a large, temporally regular input from external sources. We present an analytical solution of the mean-field theory of this model, which is exact in the limit of large network size. This theory reveals a new cooperative stationary state of large networks, which we term a balanced state. In this state, a balance between the excitatory and inhibitory inputs emerges dynamically for a wide range of parameters, resulting in a net input whose temporal fluctuations are of the same order as its mean. The internal synaptic inputs act as a strong negative feedback, which linearizes the population responses to the external drive despite the strong nonlinearity of the individual cells. This feedback also greatly stabilizes the system's state and enables it to track a time-dependent input on time scales much shorter than the time constant of a single cell. The spatiotemporal statistics of the balanced state are calculated. It is shown that the autocorrelations decay on a short time scale, yielding an approximate Poissonian temporal statistics. The activity levels of single cells are broadly distributed, and their distribution exhibits a skewed shape with a long power-law tail. The chaotic nature of the balanced state is revealed by showing that the evolution of the microscopic state of the network is extremely sensitive to small deviations in its initial conditions. The balanced state generated by the sparse, strong connections is an asynchronous chaotic state. It is accompanied by weak spatial cross-correlations, the strength of which vanishes in the limit of large network size. This is in contrast to the synchronized chaotic states exhibited by more conventional network models with high connectivity of weak synapses.},
	number = {6},
	journal = {Neural Comput.},
	author = {Van C, Vreeswijk and Sompolinsky, H},
	month = aug,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {1321--1371},
}

@article{grunewald_orthogonal_1996,
	title = {Orthogonal motion after-effect illusion predicted by a model of cortical motion processing},
	volume = {384},
	abstract = {The motion after-effect occurs after prolonged viewing of motion; a subsequent stationary scene is perceived as moving in the opposite direction. This illusion is thought to arise because motion is represented by the differential activities of populations of cortical neurons tuned to opposite directions; fatigue in one population leads to an imbalance that favours the opposite direction once the stimulus ceases. Following adaptation to multiple directions of motion, the after-effect is unidirectional, indicating that motion signals are integrated across all directions. Yet humans can perceive several directions of motion simultaneously. The question therefore arises as to how the visual system can perform both sharp segregation and global integration of motion signals. Here we show in computer simulations that this can occur if excitatory interactions between different directions are sharply tuned while inhibitory interactions are broadly tuned. Our model predicts that adaptation to simultaneous motion in opposite directions will lead to an orthogonal motion after-effect. This prediction was confirmed in psychophysical experiments. Thus, broadly tuned inhibitory interactions are likely to be important in the integration and segregation of motion signals. These interactions may occur in the cortical area MT, which contains motion-sensitive neurons with properties similar to those required by our model.},
	number = {6607},
	journal = {Nature},
	author = {Grunewald, A and Lankheet, Mj},
	month = nov,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {358--360},
}

@article{neltner_synchrony_2000,
	title = {Synchrony in heterogeneous networks of spiking neurons},
	volume = {12},
	abstract = {The emergence of synchrony in the activity of large, heterogeneous networks of spiking neurons is investigated. We define the robustness of synchrony by the critical disorder at which the asynchronous state becomes linearly unstable. We show that at low firing rates, synchrony is more robust in excitatory networks than in inhibitory networks, but excitatory networks cannot display any synchrony when the average firing rate becomes too high. We introduce a new regime where all inputs, external and internal, are strong and have opposite effects that cancel each other when averaged. In this regime, the robustness of synchrony is strongly enhanced, and robust synchrony can be achieved at a high firing rate in inhibitory networks. On the other hand, in excitatory networks, synchrony remains limited in frequency due to the intrinsic instability of strong recurrent excitation.},
	number = {7},
	journal = {Neural Comput.},
	author = {Neltner, L and Hansel, D and Mato, G and Meunier, C},
	month = jul,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1607--1641},
}

@article{neltner_synchrony_2001,
	title = {On synchrony of weakly coupled neurons at low firing rate},
	volume = {13},
	abstract = {The dynamics of a pair of weakly interacting conductance-based neurons, firing at low frequency, nu, is investigated in the framework of the phase-reduction method. The stability of the antiphase and the in-phase locked state is studied. It is found that for a large class of conductance-based models, the antiphase state is stable (resp., unstable) for excitatory (resp., inhibitory) interactions if the synaptic time constant is above a critical value tau(c)(s), which scales as the absolute value of log nu when nu goes to zero.},
	number = {4},
	journal = {Neural Comput.},
	author = {Neltner, L and Hansel, D},
	month = apr,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {765--774},
}

@article{ermentrout_fine_1998,
	title = {Fine structure of neural spiking and synchronization in the presence of conduction delays},
	volume = {95},
	abstract = {Hippocampal networks of excitatory and inhibitory neurons that produce gamma-frequency rhythms display behavior in which the inhibitory cells produce spike doublets when there is strong stimulation at separated sites. It has been suggested that the doublets play a key role in the ability to synchronize over a distance. Here we analyze the mechanisms by which timing in the spike doublet can affect the synchronization process. The analysis describes two independent effects: one comes from the timing of excitation from separated local circuits to an inhibitory cell, and the other comes from the timing of inhibition from separated local circuits to an excitatory cell. We show that a network with both of these effects has different synchronization properties than a network with either excitatory or inhibitory type of coupling alone, and we give a rationale for the shorter space scales associated with inhibitory interactions.},
	number = {3},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Ermentrout, Gb and Kopell, N},
	month = feb,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {1259--1264},
}

@article{hansel_synchrony_1995,
	title = {Synchrony in excitatory neural networks},
	volume = {7},
	abstract = {Synchronization properties of fully connected networks of identical oscillatory neurons are studied, assuming purely excitatory interactions. We analyze their dependence on the time course of the synaptic interaction and on the response of the neurons to small depolarizations. Two types of responses are distinguished. In the first type, neurons always respond to small depolarization by advancing the next spike. In the second type, an excitatory postsynaptic potential (EPSP) received after the refractory period delays the firing of the next spike, while an EPSP received at a later time advances the firing. For these two types of responses we derive general conditions under which excitation destabilizes in-phase synchrony. We show that excitation is generally desynchronizing for neurons with a response of type I but can be synchronizing for responses of type II when the synaptic interactions are fast. These results are illustrated on three models of neurons: the Lapicque integrate-and-fire model, the model of Connor et al., and the Hodgkin-Huxley model. The latter exhibits a type II response, at variance with the first two models, that have type I responses. We then examine the consequences of these results for large networks, focusing on the states of partial coherence that emerge. Finally, we study the Lapicque model and the model of Connor et al. at large coupling and show that excitation can be desynchronizing even beyond the weak coupling regime.},
	number = {2},
	journal = {Neural Comput.},
	author = {Hansel, D and Mato, G and Meunier, C},
	month = mar,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {307--337},
}

@inproceedings{thorpe_spike_1990,
	title = {Spike arrival times: {A} highly effecient coding scheme for neural networks},
	booktitle = {Parallel processing in neural systems and computers},
	publisher = {Elsevier Science Pub. Co.},
	author = {Thorpe, S J},
	editor = {Hauske., Rolf Eckmiller and Hartmann, Georg and {Gert}},
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {91--94},
}

@article{schultz_neural_1997,
	title = {A {Neural} {Substrate} of {Prediction} and {Reward}},
	journal = {Science},
	author = {Schultz, Wolfram and Dayan, Peter and Montague*, P Read},
	year = {1997},
	keywords = {merged\_fiete.bib},
}

@article{barto_simulation_1982,
	title = {Simulation of anticipatory responses in classical conditioning by a neuron-like adaptive element},
	volume = {4},
	journal = {Behav. Brain Res.},
	author = {Barto, A g and Sutton, R s},
	year = {1982},
	keywords = {merged\_fiete.bib},
	pages = {221--235},
}

@article{blake_visual_nodate,
	title = {{VISUAL} {COMPETITION}},
	volume = {3 {\textbar} JANUARY 2002},
	abstract = {Binocular rivalry the alternations in perception that occur when different images are presented to the two eyes has been the subject of intensive investigation for more than 160 years. The psychophysical properties of binocular rivalry have been well described, but newer imaging and electrophysiological techniques have not resolved the issue of where in the brain rivalry occurs. The most recent evidence supports a view of rivalry as a series of processes, each of which is implemented by neural mechanisms at different levels of the visual hierarchy. Although unanswered questions remain, this view of rivalry might allow us to resolve some of the controversies and apparent contradictions that have emerged from its study.},
	journal = {Nat. Rev. Neurosci.},
	author = {Blake*, Randolph and !, Nikos K Logothetis},
	keywords = {merged\_fiete.bib},
}

@article{rubin_equilibrium_nodate,
	title = {Equilibrium {Properties} of {Temporally} {Asymmetric} {Hebbian} {Plasticity}},
	abstract = {A theory of temporally asymmetric Hebb rules, which depress or potentiate synapses depending upon whether the postsynaptic cell fires before or after the presynaptic one, is presented. Using the Fokker-Planck formalism, we show that the equilibrium synaptic distribution induced by such rules is highly sensitive to the manner in which bounds on the allowed range of synaptic values are imposed. In a biologically plausible multiplicative model, the synapses in asynchronous networks reach a distribution that is invariant to the firing rates of either the presynaptic or postsynaptic cells. When these cells are temporally correlated, the synaptic strength varies smoothly with the degree and phase of their synchrony.},
	journal = {PHYSICAL REVIEW LETTERS 8JANUARY 2001},
	author = {Rubin, Jonathan and Lee, 1 Daniel D and {2} and 2, H Sompolinsky and {3}},
	keywords = {merged\_fiete.bib},
}

@article{van_rossum_stable_nodate,
	title = {Stable {Hebbian} {Learning} from {Spike} {Timing}-{Dependent} {Plasticity}},
	abstract = {We explore a synaptic plasticity model that incorporates recent findings that potentiation and depression can be induced by precisely timed pairs of synaptic events and postsynaptic spikes. In addition we include the observation that strong synapses undergo relatively less potentiation than weak synapses, whereas depression is independent of synaptic strength. After random stimulation, the synaptic weights reach an equilibrium distribution which is stable, unimodal, and has positive skew. This weight distribution compares favorably to the distributions of quantal amplitudes and of receptor number observed exper-imentally in central neurons and contrasts to the distribution found in plasticity models without size-dependent potentiation. Also in contrast to those models, which show strong competition between the synapses, stable plasticity is achieved with little competition. Instead, competition can be introduced by including a separate mechanism that scales synaptic strengths multiplica-tively as a function of postsynaptic activity. In this model, syn-aptic weights change in proportion to how correlated they are with other inputs onto the same postsynaptic neuron. These results indicate that stable correlation-based plasticity can be achieved without introducing competition, suggesting that plas-ticity and competition need not coexist in all circuits or at all developmental stages. Key words: Hebbian plasticity; synaptic weights; synaptic com-petition; activity-dependent scaling; temporal learning; stochas-tic approaches},
	journal = {The Journal of Neuroscience, December 1, 2000, 20(23):88128821},
	author = {Van Rossum, M C W and Bi, 1 G Q and {2} and Turrigiano, G G},
	keywords = {merged\_fiete.bib},
}

@article{lechner_new_1998,
	title = {New {Perspectives} on {Classical} {Conditioning}: a {Synthesis} of {Hebbian} and {Non}-{Hebbian} {Mechanisms}},
	volume = {20},
	journal = {Neuron},
	author = {Lechner, Hilde A and Byrne, John H},
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {355--358},
}

@article{olshausen_wavelet-like_1996,
	title = {Wavelet-like receptive fields emerge from a network that learns sparse codes for natural images},
	journal = {Nature},
	author = {Olshausen, B A and Field, D J},
	year = {1996},
	keywords = {merged\_fiete.bib},
}

@article{gerstner_neural_1997,
	title = {Neural codes: firing rates and beyond},
	volume = {94},
	abstract = {Computational neuroscience has contributed significantly to our understanding of higher brain function by combining experimental neurobiology, psychophysics, modeling, and mathematical analysis. This article reviews recent advances in a key area: neural coding and information processing. It is shown that synapses are capable of supporting computations based on highly structured temporal codes. Such codes could provide a substrate for unambiguous representations of complex stimuli and be used to solve difficult cognitive tasks, such as the binding problem. Unsupervised learning rules could generate the circuitry required for precise temporal codes. Together, these results indicate that neural systems perform a rich repertoire of computations based on action potential timing.},
	number = {24},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Gerstner, W and Kreiter, Ak and Markram, H and Herz, Av},
	month = nov,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {12740--12741},
}

@article{rao_spike-timing-dependent_2001,
	title = {Spike-{Timing}-{Dependent} {Hebbian} {Plasticity} as {Temporal} {Difference} {Learning}},
	volume = {13},
	abstract = {A spike-timing-dependent Hebbian mechanism governs the plasticity of recurrent excitatory synapses in the neocortex: synapses that are ac-tivated a few milliseconds before a postsynaptic spike are potentiated, while those that are activated a few milliseconds after are depressed. We show that such a mechanism can implement a form of temporal difference learning for prediction of input sequences. Using a biophysical model of a cortical neuron, we show that a temporal difference rule used in con-junction with dendritic backpropagating action potentials reproduces the temporally asymmetric window of Hebbian plasticity observed physio-logically. Furthermore, the size and shape of the window vary with the distance of the synapse from the soma. Using a simple example, we show how a spike-timing-based temporal difference learning rule can allow a network of neocortical neurons to predict an input a few milliseconds before the inputs expected arrival.},
	journal = {Neural Comput.},
	author = {Rao, Rajesh P N and Sejnowski, Terrence J},
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {2221--2237},
}

@article{rubin_analysis_2000,
	title = {Analysis of clustered firing patterns in synaptically coupled networks of oscillators},
	volume = {41},
	abstract = {Oscillators in networks may display a variety of activity patterns. This paper presents a geometric singular perturbation analysis of clustering, or alternate firing of synchronized subgroups, among synaptically coupled oscillators. We consideroscillators in two types of networks: mutually coupled, with all-to-all inhibitory connections, and globally inhibitory, with one excitatory and one inhibitory population of oscillators, each of arbitrary size. Our analysis yields existence and stability conditions for clustered states, along with formulas for the periods of such firing patterns. By using two different approaches, we derive complementary conditions, the first set stated in terms of time lengths determined by intrinsic and synaptic properties of the oscillators and their coupling and the second set stated in terms of model parameters and phase space structures directly linked to parameters. These results suggest how biological components may interact to produce the spindle sleep rhythm in thalamocortical networks.},
	number = {6},
	journal = {J. Math. Biol.},
	author = {Rubin, J and Terman, D},
	month = dec,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {513--545},
}

@article{panzeri_speed_2001,
	title = {Speed of feedforward and recurrent processing in multilayer networks of integrate-and-fire neurons},
	volume = {12},
	abstract = {The speed of processing in the visual cortical areas can be fast, with for example the latency of neuronal responses increasing by only approximately 10 ms per area in the ventral visual system sequence V1 to V2 to V4 to inferior temporal visual cortex. This has led to the suggestion that rapid visual processing can only be based on the feedforward connections between cortical areas. To test this idea, we investigated the dynamics of information retrieval in multiple layer networks using a four-stage feedforward network modelled with continuous dynamics with integrate-and-fire neurons, and associative synaptic connections between stages with a synaptic time constant of 10 ms. Through the implementation of continuous dynamics, we found latency differences in information retrieval of only 5 ms per layer when local excitation was absent and processing was purely feedforward. However, information latency differences increased significantly when non-associative local excitation was included. We also found that local recurrent excitation through associatively modified synapses can contribute significantly to processing in as little as 15 ms per layer, including the feedforward and local feedback processing. Moreover, and in contrast to purely feed-forward processing, the contribution of local recurrent feedback was useful and approximately this rapid even when retrieval was made difficult by noise. These findings suggest that cortical information processing can benefit from recurrent circuits when the allowed processing time per cortical area is at least 15 ms long.},
	number = {4},
	journal = {Network},
	author = {Panzeri, S and Rolls, Et and Battaglia, F and Lavis, R},
	month = nov,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {423--440},
}

@article{spiridon_effect_2001,
	title = {Effect of lateral connections on the accuracy of the population code for a network of spiking neurons},
	volume = {12},
	abstract = {We study how neuronal connections in a population of spiking neurons affect the accuracy of stimulus estimation. Neurons in our model code for a one-dimensional orientation variable phi. Connectivity between two neurons depends on the absolute difference absolute value(phi - phi') between the preferred orientation of the two neurons. We derive an analytical expression of the activity profile for a population of neurons described by the spike response model with noisy threshold. We estimate the stimulus orientation and the trial-to-trial fluctuations using the population vector method. For stationary stimuli, uniform inhibitory connections produce a more reliable estimation of the stimulus than short-range excitatory connections with long-range inhibitions, although the latter interaction type produces a sharper tuning curve. These results are consistent with previous analytical studies of the Fisher information.},
	number = {4},
	journal = {Network},
	author = {Spiridon, M and Gerstner, W},
	month = nov,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {409--421},
}

@article{tsodyks_rapid_1995,
	title = {Rapid state switching in balanced cortical network models},
	volume = {6},
	abstract = {We have explored a network model of cortical microcircuits based on integrate-and-fire neurons in a regime where the reset following a spike is small, recurrent excitation is balanced by feedback inhibition, and the activity is highly irregular. This regime cannot be described by a mean-field theory based on average activity levels because essential features of the model depend on fluctuations from the average. We propose a new way of scaling the strength of synaptic interaction with the size of the network: rather than scale the amplitude of the synapse we scale the neurotransmitter release probabilities with the number of inputs to keep the average input constant. This is consistent with the low transmitter release probability observed in a majority of hippocampal synapses. Another prominent feature of this regime is the ability of the network to switch rapidly between different states, as demonstrated in a model based on an orientation columns in the mammalian visual cortex. Both network and intrinsic properties of neurons contribute to achieving the balance condition that allows rapid state switching.},
	journal = {Network},
	author = {Tsodyks, M V and Sejnowski, T},
	month = may,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {111--124},
}

@article{gerstner_population_2000,
	title = {Population dynamics of spiking neurons: fast transients, asynchronous states, and locking},
	volume = {12},
	abstract = {An integral equation describing the time evolution of the population activity in a homogeneous pool of spiking neurons of the integrate-and-fire type is discussed. It is analytically shown that transients from a state of incoherent firing can be immediate. The stability of incoherent firing is analyzed in terms of the noise level and transmission delay, and a bifurcation diagram is derived. The response of a population of noisy integrate-and-fire neurons to an input current of small amplitude is calculated and characterized by a linear filter L. The stability of perfectly synchronized“locked”solutions is analyzed.},
	number = {1},
	journal = {Neural Comput.},
	author = {Gerstner, W},
	month = jan,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {43--89},
}

@article{bazhenov_model_2001,
	title = {Model of cellular and network mechanisms for odor-evoked temporal patterning in the locust antennal lobe},
	volume = {30},
	abstract = {Locust antennal lobe (AL) projection neurons (PNs) respond to olfactory stimuli with sequences of depolarizing and hyperpolarizing epochs, each lasting hundreds of milliseconds. A computer simulation of an AL network was used to test the hypothesis that slow inhibitory connections between local neurons (LNs) and PNs are responsible for temporal patterning. Activation of slow inhibitory receptors on PNs by the same GABAergic synapses that underlie fast oscillatory synchronization of PNs was sufficient to shape slow response modulations. This slow stimulus- and neuron-specific patterning of AL activity was resistant to blockade of fast inhibition. Fast and slow inhibitory mechanisms at synapses between LNs and PNs can thus form dynamical PN assemblies whose elements synchronize transiently and oscillate collectively, as observed not only in the locust AL, but also in the vertebrate olfactory bulb.},
	number = {2},
	journal = {Neuron},
	author = {Bazhenov, M and Stopfer, M and Rabinovich, M and Abarbanel, Hd and Sejnowski, Tj and Laurent, G},
	month = may,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {569--581},
}

@article{brunel_fast_1999,
	title = {Fast global oscillations in networks of integrate-and-fire neurons with low firing rates},
	volume = {11},
	abstract = {We study analytically the dynamics of a network of sparsely connected inhibitory integrate-and-fire neurons in a regime where individual neurons emit spikes irregularly and at a low rate. In the limit when the number of neurons –{\textgreater} infinity, the network exhibits a sharp transition between a stationary and an oscillatory global activity regime where neurons are weakly synchronized. The activity becomes oscillatory when the inhibitory feedback is strong enough. The period of the global oscillation is found to be mainly controlled by synaptic times but depends also on the characteristics of the external input. In large but finite networks, the analysis shows that global oscillations of finite coherence time generically exist both above and below the critical inhibition threshold. Their characteristics are determined as functions of systems parameters in these two different regions. The results are found to be in good agreement with numerical simulations.},
	number = {7},
	journal = {Neural Comput.},
	author = {Brunel, N and Hakim, V},
	month = oct,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {1621--1671},
}

@article{brunel_effects_2001,
	title = {Effects of {Synaptic} {Noise} and {Filtering} on the {Frequency} {Response} of {Spiking} {Neurons}},
	volume = {86},
	abstract = {Noise can have a significant impact on the response dynamics of a nonlinear system. For neurons, the primary source of noise comes from background synaptic input activity. If this is approximated as white noise, the amplitude of the modulation of the firing rate in response to an input current oscillating at frequency decreases as 1/ and lags the input by 45° in phase. However, if filtering due to realistic synaptic dynamics is included, the firing rate is modulated by a finite amount even in the limit “ align=”bottom“{\textgreater} and the phase lag is eliminated. Thus, through its effect on noise inputs, realistic synaptic dynamics can ensure unlagged neuronal responses to high-frequency inputs.},
	number = {10},
	journal = {Phys. Rev. Lett.},
	author = {Brunel, Nicolas and Chance, Frances S and Fourcaud, Nicolas and Abbott, L F},
	month = mar,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {2186--2189},
}

@article{bazhenov_model_2001-1,
	title = {Model of transient oscillatory synchronization in the locust antennal lobe},
	volume = {30},
	abstract = {Transient pairwise synchronization of locust antennal lobe (AL) projection neurons (PNs) occurs during odor responses. In a Hodgkin-Huxley-type model of the AL, interactions between excitatory PNs and inhibitory local neurons (LNs) created coherent network oscillations during odor stimulation. GABAergic interconnections between LNs led to competition among them such that different groups of LNs oscillated with periodic Ca(2+) spikes during different 50-250 ms temporal epochs, similar to those recorded in vivo. During these epochs, LN-evoked IPSPs caused phase-locked, population oscillations in sets of postsynaptic PNs. The model shows how alternations of the inhibitory drive can temporally encode sensory information in networks of neurons without precisely tuned intrinsic oscillatory properties.},
	number = {2},
	journal = {Neuron},
	author = {Bazhenov, M and Stopfer, M and Rabinovich, M and Huerta, R and Abarbanel, Hd and Sejnowski, Tj and Laurent, G},
	month = may,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {553--567},
}

@article{van_vreeswijk_partial_1996,
	title = {Partial synchronization in populations of pulse-coupled oscillators},
	volume = {54},
	abstract = {I study the long-term behavior of populations of nonlinear oscillators with all-to-all, noninstantaneous, pulse coupling. With fast enough excitatory coupling both the fully synchronized and the asynchronous state are unstable. In this case individual units fire quasiperiodically even though the network as a whole shows a periodic firing pattern. The behavior of networks with three or more units is different in this regard from that of two-unit networks. With inhibitory coupling the network can break up into a variable number of fully synchronized clusters. For fast inhibition the number of clusters tends to be large, while the number of clusters is smaller for slow inhibition.},
	number = {5},
	journal = {Phys. Rev. E},
	author = {Van Vreeswijk, C},
	month = nov,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {5522--5537},
}

@article{van_c_patterns_2001,
	title = {Patterns of synchrony in neural networks with spike adaptation},
	volume = {13},
	abstract = {We study the emergence of synchronized burst activity in networks of neurons with spike adaptation. We show that networks of tonically firing adapting excitatory neurons can evolve to a state where the neurons burst in a synchronized manner. The mechanism leading to this burst activity is analyzed in a network of integrate-and-fire neurons with spike adaptation. The dependence of this state on the different network parameters is investigated, and it is shown that this mechanism is robust against inhomogeneities, sparseness of the connectivity, and noise. In networks of two populations, one excitatory and one inhibitory, we show that decreasing the inhibitory feedback can cause the network to switch from a tonically active, asynchronous state to the synchronized bursting state. Finally, we show that the same mechanism also causes synchronized burst activity in networks of more realistic conductance-based model neurons.},
	number = {5},
	journal = {Neural Comput.},
	author = {Van C, Vreeswijk and Hansel, D},
	month = may,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {959--992},
}

@article{gerstner_rapid_1996,
	title = {Rapid {Phase} {Locking} in {Systems} of {Pulse}-{Coupled} {Oscillators} with {Delays}},
	volume = {76},
	abstract = {The dynamical evolution of a system of integrate-and-fire units with delayed excitatory coupling is analyzed. The connectivity is arbitrary except for a normalization of the total input to each unit. It is shown that the system converges to a periodic solution where all units are phase locked but do not necessarily fire in unison. In the case of discrete and uniform delays, a periodic solution is reached after a finite time. For a delay distribution with finite support, an attractor is, in general, only reached asymptotically.},
	number = {10},
	journal = {Phys. Rev. Lett.},
	author = {Gerstner, Wulfram},
	month = mar,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {1755--1758},
}

@article{golomb_number_2000,
	title = {The number of synaptic inputs and the synchrony of large, sparse neuronal networks},
	volume = {12},
	abstract = {The prevalence of coherent oscillations in various frequency ranges in the central nervous system raises the question of the mechanisms that synchronize large populations of neurons. We study synchronization in models of large networks of spiking neurons with random sparse connectivity. Synchrony occurs only when the average number of synapses, M, that a cell receives is larger than a critical value, Mc. Below Mc, the system is in an asynchronous state. In the limit of weak coupling, assuming identical neurons, we reduce the model to a system of phase oscillators that are coupled via an effective interaction, gamma. In this framework, we develop an approximate theory for sparse networks of identical neurons to estimate Mc analytically from the Fourier coefficients of gamma. Our approach relies on the assumption that the dynamics of a neuron depend mainly on the number of cells that are presynaptic to it. We apply this theory to compute Mc for a model of inhibitory networks of integrate-and-fire (I\&F) neurons as a function of the intrinsic neuronal properties (e.g., the refractory period Tr), the synaptic time constants, and the strength of the external stimulus, Iext. The number Mc is found to be nonmonotonous with the strength of Iext. For Tr = 0, we estimate the minimum value of Mc over all the parameters of the model to be 363.8. Above Mc, the neurons tend to fire in smeared one-cluster states at high firing rates and smeared two-or-more-cluster states at low firing rates. Refractoriness decreases Mc at intermediate and high firing rates. These results are compared to numerical simulations. We show numerically that systems with different sizes, N, behave in the same way provided the connectivity, M, is such that 1/Meff = 1/M - 1/N remains constant when N varies. This allows extrapolating the large N behavior of a network from numerical simulations of networks of relatively small sizes (N = 800 in our case). We find that our theory predicts with remarkable accuracy the value of Mc and the patterns of synchrony above Mc, provided the synaptic coupling is not too large. We also study the strong coupling regime of inhibitory sparse networks. All of our simulations demonstrate that increasing the coupling strength reduces the level of synchrony of the neuronal activity. Above a critical coupling strength, the network activity is asynchronous. We point out a fundamental limitation for the mechanisms of synchrony relying on inhibition alone, if heterogeneities in the intrinsic properties of the neurons and spatial fluctuations in the external input are also taken into account.},
	number = {5},
	journal = {Neural Comput.},
	author = {Golomb, D and Hansel, D},
	month = may,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1095--1139},
}

@article{golomb_dynamics_nodate,
	title = {Dynamics of globally coupled inhibitory neurons with heterogeneity},
	abstract = {A model of many heterogeneous excitable neurons with a global slowly decaying inhibitory coupling is studied. When neuronal intrinsic excitability parameters are randomly distributed, the system exhibits four regimes of behavior. In addition to synchronized periodic and asynchronous regimes, we obtain two aperiodic regimes, with bursting rate a staircaselike function of neuron excitability. In one regime, the system is partially synchronized and in the second, partially antisynchronized. The transition between these two regimes is discontinuous as the disorder increases.},
	author = {Golomb, David and Rinzel, John},
	keywords = {merged\_fiete.bib},
}

@article{koch_complexity_1999,
	title = {Complexity and the nervous system},
	volume = {284},
	abstract = {Advances in the neurosciences have revealed the staggering complexity of even “simple” nervous systems. This is reflected in their function, their evolutionary history, their structure, and the coding schemes they use to represent information. These four viewpoints need all play a role in any future science of “brain complexity.”},
	number = {5411},
	journal = {Science},
	author = {Koch, C and Laurent, G},
	month = apr,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {96--98},
}

@article{tononi_consciousness_1998,
	title = {Consciousness and complexity},
	volume = {282},
	abstract = {Conventional approaches to understanding consciousness are generally concerned with the contribution of specific brain areas or groups of neurons. By contrast, it is considered here what kinds of neural processes can account for key properties of conscious experience. Applying measures of neural integration and complexity, together with an analysis of extensive neurological data, leads to a testable proposal-the dynamic core hypothesis-about the properties of the neural substrate of consciousness.},
	number = {5395},
	journal = {Science},
	author = {Tononi, G and Edelman, Gm},
	month = dec,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {1846--1851},
}

@article{hopfield_what_2000,
	title = {What is a moment? “{Cortical}” sensory integration over a brief interval},
	volume = {97},
	abstract = {Recognition of complex temporal sequences is a general sensory problem that requires integration of information over time. We describe a very simple “organism” that performs this task, exemplified here by recognition of spoken monosyllables. The network's computation can be understood through the application of simple but generally unexploited principles describing neural activity. The organism is a network of very simple neurons and synapses; the experiments are simulations. The network's recognition capabilities are robust to variations across speakers, simple masking noises, and large variations in system parameters. The network principles underlying recognition of short temporal sequences are applied here to speech, but similar ideas can be applied to aspects of vision, touch, and olfaction. In this article, we describe only properties of the system that could be measured if it were a real biological organism. We delay publication of the principles behind the network's operation as an intellectual challenge: the essential principles of operation can be deduced based on the experimental results presented here alone. An interactive web site (http://neuron.princeton.edu/ approximately moment) is available to allow readers to design and carry out their own experiments on the organism.},
	number = {25},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Hopfield, Jj and Brody, Cd},
	month = dec,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {13919--13924},
}

@article{miller_neural_2002,
	title = {Neural noise can explain expansive, power-law nonlinearities in neural response functions},
	volume = {87},
	abstract = {Many phenomenological models of the responses of simple cells in primary visual cortex have concluded that a cell's firing rate should be given by its input raised to a power greater than one. This is known as an expansive power-law nonlinearity. However, intracellular recordings have shown that a different nonlinearity, a linear-threshold function, appears to give a good prediction of firing rate from a cell's low-pass-filtered voltage response. Using a model based on a linear-threshold function, Anderson et al. showed that voltage noise was critical to converting voltage responses with contrast-invariant orientation tuning into spiking responses with contrast-invariant tuning. We present two separate results clarifying the connection between noise-smoothed linear-threshold functions and power-law nonlinearities. First, we prove analytically that a power-law nonlinearity is the only input-output function that converts contrast-invariant input tuning into contrast-invariant spike tuning. Second, we examine simulations of a simple model that assumes instantaneous spike rate is given by a linear-threshold function of voltage and voltage responses include significant noise. We show that the resulting average spike rate is well described by an expansive power law of the average voltage (averaged over multiple trials), provided that average voltage remains less than about 1.5 SDs of the noise above threshold. Finally, we use this model to show that the noise levels recorded by Anderson et al. are consistent with the degree to which the orientation tuning of spiking responses is more sharply tuned relative to the orientation tuning of voltage responses. Thus neuronal noise can robustly generate power-law input-output functions of the form frequently postulated for simple cells.},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Miller, Kd and Troyer, Tw},
	month = feb,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {653--659},
}

@article{le_cun_eigenvalues_1991,
	title = {Eigenvalues of covariance matrices: {Application} to neural-network learning},
	volume = {66},
	number = {18},
	journal = {Phys. Rev. Lett.},
	author = {Le Cun, Y and Kanter, I and Solla, S A},
	month = may,
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {2396--2399},
}

@article{chance_synaptic_1998,
	title = {Synaptic depression and the temporal response characteristics of {V1} cells},
	volume = {18},
	abstract = {We explore the effects of short-term synaptic depression on the temporal dynamics of V1 responses to visual images by constructing a model simple cell. Synaptic depression is modeled on the basis of previous detailed fits to experimental data. A component of synaptic depression operating in the range of hundreds of milliseconds can account for a number of the unique temporal characteristics of cortical neurons, including the bandpass nature of frequency-response curves, increases in response amplitude and in cutoff frequency for transient stimuli, nonlinear temporal summation, and contrast-dependent shifts in response phase. Synaptic depression also provides a mechanism for generating the temporal phase shifts needed to produce direction selectivity, and a model constructed along these lines matches both extracellular and intracellular data. A slower component of depression can reproduce the effects of contrast adaptation.},
	number = {12},
	journal = {J. Neurosci.},
	author = {Chance, Fs and Nelson, Sb and Abbott, Lf},
	month = jun,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {4785--4799},
}

@article{pugh_computational_2000,
	title = {Computational {Modeling} of {Orientation} {Tuning} {Dynamics} in {Monkey} {Primary} {Visual} {Cortex}},
	volume = {8},
	abstract = {In the primate visual pathway, orientation tuning of neurons is first observed in the primary visual cortex. The LGN cells that comprise the thalamic input to V1 are not orientation tuned, but some V1 neurons are quite selective. Two main classes of theoretical models have been offered to explain orientation selectivity: feedforward models, in which inputs from spatially aligned LGN cells are summed together by one cortical neuron; and feedback models, in which an initial weak orientation bias due to convergent LGN input is sharpened and amplified by intracortical feedback. Recent data on the dynamics of orientation tuning, obtained by a cross-correlation technique, may help to distinguish between these classes of models. To test this possibility, we simulated the measurement of orientation tuning dynamics on various receptive field models, including a simple Hubel-Wiesel type feedforward model: a linear spatiotemporal filter followed by an integrate-and-fire spike generator. The computational study reveals that simple feedforward models may account for some aspects of the experimental data but fail to explain many salient features of orientation tuning dynamics in V1 cells. A simple feedback model of interacting cells is also considered. This model is successful in explaining the appearance of Mexican-hat orientation profiles, but other features of the data continue to be unexplained.},
	number = {2},
	journal = {J. Comput. Neurosci.},
	author = {Pugh, M c and Ringach, D l and Shapley, R and Shelley, M j},
	month = mar,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {143--159},
}

@article{shelley_efficient_2001,
	title = {Efficient and {Accurate} {Time}-{Stepping} {Schemes} for {Integrate}-and-{Fire} {Neuronal} {Networks}},
	volume = {11},
	number = {2},
	journal = {J. Comput. Neurosci.},
	author = {Shelley, Michael J and Tao, Louis},
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {111--119},
}

@article{shelley_coarse-grained_2002,
	title = {Coarse-{Grained} {Reduction} and {Analysis} of a {Network} {Model} of {Cortical} {Response}: {I}. {Drifting} {Grating} {Stimuli}},
	volume = {12},
	abstract = {We present a reduction of a large-scale network model of visual cortex developed by McLaughlin, Shapley, Shelley, and Wielaard. The reduction is from many integrate-and-fire neurons to a spatially coarse-grained system for firing rates of neuronal subpopulations. It accounts explicitly for spatially varying architecture, ordered cortical maps (such as orientation preference) that vary regularly across the cortical layer, and disordered cortical maps (such as spatial phase preference or stochastic input conductances) that may vary widely from cortical neuron to cortical neuron. The result of the reduction is a set of nonlinear spatiotemporal integral equations for “phase-averaged” firing rates of neuronal subpopulations across the model cortex, derived asymptotically from the full model without the addition of any extra phenomological constants. This reduced system is used to study the response of the model to drifting grating stimuli-where it is shown to be useful for numerical investigations that reproduce, at far less computational cost, the salient features of the point-neuron network and for analytical investigations that unveil cortical mechanisms behind the responses observed in the simulations of the large-scale computational model. For example, the reduced equations clearly show (1) phase averaging as the source of the time-invariance of cortico-cortical conductances, (2) the mechanisms in the model for higher firing rates and better orientation selectivity of simple cells which are near pinwheel centers, (3) the effects of the length-scales of cortico-cortical coupling, and (4) the role of noise in improving the contrast invariance of orientation selectivity.},
	number = {2},
	journal = {J. Comput. Neurosci.},
	author = {Shelley, Michael and Mclaughlin, David},
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {97--122},
}

@article{cannon_proposed_1983,
	title = {A proposed neural network for the integrator of the oculomotor system},
	volume = {49},
	abstract = {Single-unit recordings, stimulation studies, and eye movement measurements all indicate that the firing patterns of many oculomotor neurons in the brain stem encode eye-velocity commands in premotor circuits while the firing patterns of extraocular motoneurons contain both eye-velocity and eye-position components. It is necessary to propose that the eye-position component is generated from the eye-velocity signal by a leaky hold element or temporal integrator. Prior models of this integrator suffer from two important problems. Since cells appear to have a steady, background signal when eye position and velocity are zero, how does the integrator avoid integrating this background rate? Most models employ some form of lumped, positive feedback the gain of which must be kept within totally unreasonable limits for proper operation. We propose a lateral inhibitory network of homogeneous neurons as a model for the neural integrator that solves both problems. Parameter sensitivity studies and lesion simulations are presented to demonstrate robustness of the model with respect to both the choice of parameter values and the consequences of pathological changes in a portion of the neural integrator pool.},
	number = {2},
	journal = {Biol. Cybern.},
	author = {Cannon, Sc and Robinson, Da and Shamma, S},
	year = {1983},
	keywords = {merged\_fiete.bib},
	pages = {127--136},
}

@article{adorjan_model_1999,
	title = {A model for the intracortical origin of orientation preference and tuning in macaque striate cortex},
	volume = {16},
	abstract = {We report results of numerical simulations for a model of generation of orientation selectivity in macaque striate cortex. In contrast to previous models, where the initial orientation bias is generated by convergent geniculate input to simple cells and subsequently sharpened by lateral circuits, our approach is based on anisotropic intracortical excitatory connections which provide both the initial orientation bias and its subsequent amplification. Our study shows that the emerging response properties are similar to the response properties that are observed experimentally, hence the hypothesis of an intracortical generation of orientation bias is a sensible alternative to the notion of an afferent bias by convergent geniculocortical projection patterns. In contrast to models based on an afferent orientation bias, however, the “intracortical hypothesis” predicts that orientation tuning gradually evolves from an initially nonoriented response and a complete loss of orientation tuning when the recurrent excitation is blocked, but new experiments must be designed to unambiguously decide between both hypotheses.},
	number = {2},
	journal = {Vis. Neurosci.},
	author = {Adorjan, P and Levitt, Jb and Lund, Js and Obermayer, K},
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {303--318},
}

@article{cannon_improved_1985,
	title = {An improved neural-network model for the neural integrator of the oculomotor system: more realistic neuron behavior},
	volume = {53},
	abstract = {The discharge rates of premotor, brain-stem neurons that create eye movements modulate in relation to eye velocity yet firing rates of extraocular motoneurons contain both eye-position and eye-velocity signals. The eye-position signal is derived from the eye-velocity command by means of a neural network which functions as a temporal integrator. We have previously proposed a network of lateral-inhibitory neurons that is capable of performing the required integration. That analysis centered on the temporal aspects of the signal processing for a limited class of idealized inputs. All of its cells were identical and carried only the integrated signal. Recordings in the brain stem, however, show that neurons in the region of the neural integrator have a variety of background firing rates, all carry some eye-velocity signal as well as the eye-position signal, and carry the former with different strengths depending on the type of eye movement being made. It was necessary to see if the proposed model could be modified to make its neurons more realistic. By modifying the spatial distribution of afferents to the network, we demonstrate that the same basic model functions properly in spite of afferents with nonuniform background firing rates. To introduce the eye-velocity signal a double-layer network, consisting of inhibitory and excitatory cells, was necessary. By presenting the velocity input to only local regions of this network it was shown that all cells in the network still carried the integrated signal and that its cells could carry different eye-velocity signals for different types of eye movements. Thus, this model stimulates quantitatively and qualitatively, the behavior of neurons seen in the region of the neural integrator.},
	number = {2},
	journal = {Biol. Cybern.},
	author = {Cannon, Sc and Robinson, Da},
	year = {1985},
	keywords = {merged\_fiete.bib},
	pages = {93--108},
}

@article{cugliandolo_capacity_1994,
	title = {Capacity of networks with correlated attractors},
	volume = {27},
	abstract = {We analyse the extensive loading of the neural network model proposed to describe neurophysiological experiments in which correlated attractors associated to uncorrelated patterns are found. The phase diagram is obtained and discussed. Some generalizations of the original model are also considered. In all the cases we demonstrate the existence of a region in the phase diagram with correlated attractors. Results from numerical simulations which confirm the mean-field theory results are also presented.},
	number = {3},
	journal = {J. Phys. A Math. Gen.},
	author = {Cugliandolo, L F and Tsodyks, M V},
	month = feb,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {741--756},
}

@article{keller_characteristics_1975,
	title = {Characteristics of head rotation and eye movement-related neurons in alert monkey vestibular nucleus},
	volume = {100},
	number = {1},
	journal = {Brain Res.},
	author = {Keller, El and Kamath, By},
	month = dec,
	year = {1975},
	keywords = {merged\_fiete.bib},
	pages = {182--187},
}

@article{bednar_tilt_2000,
	title = {Tilt aftereffects in a self-organizing model of the primary visual cortex},
	volume = {12},
	abstract = {RF-LISSOM, a self-organizing model of laterally connected orientation maps in the primary visual cortex, was used to study the psychological phenomenon known as the tilt aftereffect. The same self-organizing processes that are responsible for the long-term development of the map are shown to result in tilt aftereffects over short timescales in the adult. The model permits simultaneous observation of large numbers of neurons and connections, making it possible to relate high-level phenomena to low-level events, which is difficult to do experimentally. The results give detailed computational support for the long-standing conjecture that the direct tilt aftereffect arises from adaptive lateral interactions between feature detectors. They also make a new prediction that the indirect effect results from the normalization of synaptic efficacies during this process. The model thus provides a unified computational explanation of self-organization and both the direct and indirect tilt aftereffect in the primary visual cortex.},
	number = {7},
	journal = {Neural Comput.},
	author = {Bednar, Ja and Miikkulainen, R},
	month = jul,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1721--1740},
}

@article{ishizaka_synthesis_1972,
	title = {Synthesis of {Voiced} {Sounds} {From} a {Two}-{Mass} {Model} of the {Vocal} {Cords}},
	volume = {51},
	abstract = {A model of voiced-sound generation is derived in which the detailed acoustic behavior of the human vocal cords and the vocal tract is computed. The vocal cords are approximated by a self-oscillating source composed of two stiffness-coupled masses. The vocal tract is represented as a bilateral transmission line. One dimensional Bernoulli flow through the vocal cords and plane-wave propagation in the tract are used to establish acoustic factors dominant in the generation of voiced speech. A difference-equation description of the continuous system is derived, and the cord-tract system is programmed for interactive study on a DDP-516 computer. Sampled waveforms are calculated for: acoustic volume velocity through the cord opening (glottis); glottal area; and mouth-output sound pressure. Functional relations between fundamental voice frequency, subglottal (lung) pressure, cord tension, glottal area, and duty ratio of cord vibration are also determined. Results show that the two-mass model duplicates principal features of cord behavior in the human. The variation of fundamental frequency with subglottal pressure is found to be 2 to 3 Hz/cm H2O, and is essentially independent of vowel configuration in the programmed tract. Acoustic interaction between tract eigenfrequencies and glottal volume flow is strong. Phase difference in motion of the cord edges is in the range of 0 to 60 degrees, and control of cord tension leads to behavior analogous to chest/falsetto conditions in the human. Phonation-neutral, or rest area of cord opening, is shown to be a critical factor in establishing self-oscillation. Finally, the complete synthesis system suggests an efficient, physiological description of the speech signal, namely, in terms of subglottal pressure, cord tension, rest area of cord opening, and vocal-tract shape.},
	number = {6},
	journal = {Bell System Technical Journal},
	author = {Ishizaka, K and Flanagan, J L},
	year = {1972},
	keywords = {merged\_fiete.bib},
	pages = {1233--1268},
}

@article{carandini_synaptic_2002,
	title = {A synaptic explanation of suppression in visual cortex},
	volume = {22},
	abstract = {The responses of neurons in the primary visual cortex (V1) are suppressed by mask stimuli that do not elicit responses if presented alone. This suppression is widely believed to be mediated by intracortical inhibition. As an alternative, we propose that it can be explained by thalamocortical synaptic depression. This explanation correctly predicts that suppression is monocular, immune to cortical adaptation, and occurs for mask stimuli that elicit responses in the thalamus but not in the cortex. Depression also explains other phenomena previously ascribed to intracortical inhibition. It explains why responses saturate at high stimulus contrast, whereas selectivity for orientation and spatial frequency is invariant with contrast. It explains why transient responses to flashed stimuli are nonlinear, whereas spatial summation is primarily linear. These results suggest that the very first synapses into the cortex, and not the cortical network, may account for important response properties of V1 neurons.},
	number = {22},
	journal = {J. Neurosci.},
	author = {Carandini, M and Heeger, Dj and Senn, W},
	month = nov,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {10053--10065},
}

@article{jin_fast_2002-1,
	title = {Fast convergence of spike sequences to periodic patterns in recurrent networks},
	volume = {89},
	abstract = {The dynamical attractors are thought to underlie many biological functions of recurrent neural networks. Here we show that stable periodic spike sequences with precise timings are the attractors of the spiking dynamics of recurrent neural networks with global inhibition. Almost all spike sequences converge within a finite number of transient spikes to these attractors. The convergence is fast, especially when the global inhibition is strong. These results support the possibility that precise spatiotemporal sequences of spikes are useful for information encoding and processing in biological neural networks.},
	number = {20},
	journal = {Phys. Rev. Lett.},
	author = {Jin, Dz},
	month = nov,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {208102},
}

@article{salinas_correlated_2001,
	title = {Correlated neuronal activity and the flow of neural information},
	volume = {2},
	abstract = {Computational Neurobiology Laboratory, Howard Hughes Medical Institute, The Salk Institute for Biological Studies, 10010 North Torrey Pines Road, La Jolla, California 92037, USA.},
	number = {8},
	journal = {Nat. Rev. Neurosci.},
	author = {Salinas, E and Sejnowski, Tj},
	month = aug,
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {539--550},
}

@article{jin_fast_2002-2,
	title = {Fast convergence of spike sequences to periodic patterns in recurrent networks},
	volume = {89},
	abstract = {The dynamical attractors are thought to underlie many biological functions of recurrent neural networks. Here we show that stable periodic spike sequences with precise timings are the attractors of the spiking dynamics of recurrent neural networks with global inhibition. Almost all spike sequences converge within a finite number of transient spikes to these attractors. The convergence is fast, especially when the global inhibition is strong. These results support the possibility that precise spatiotemporal sequences of spikes are useful for information encoding and processing in biological neural networks.},
	number = {20},
	journal = {Phys. Rev. Lett.},
	author = {Jin, Dz},
	month = nov,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {208102},
}

@article{beiser_network_1997,
	title = {Network models of the basal ganglia},
	volume = {7},
	abstract = {Over the past year, a number of conceptual and mathematical models of the basal ganglia and their interactions with other areas of the brain have appeared in the literature. Even though the models each differ in significant ways, several computational principles, such as convergence, recurrence and competition, appear to have emerged as common themes of information processing in the basal ganglia. Simulation studies of these models have provoked new types of questions at the many levels of inquiry linking biophysics to behavior.},
	number = {2},
	journal = {Curr. Opin. Neurobiol.},
	author = {Beiser, Dg and Hua, Se and Houk, Jc},
	month = apr,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {185--190},
}

@article{berns_computational_1998,
	title = {A computational model of how the basal ganglia produce sequences},
	volume = {10},
	abstract = {We propose a systems-level computational model of the basal ganglia based closely on known anatomy and physiology. First, we assume that the thalamic targets, which relay ascending information to cortical action and planning areas, are tonically inhibited by the basal ganglia. Second, we assume that the output stage of the basal ganglia, the internal segment of the globus pallidus (Gpi), selects a single action from several competing actions via lateral interactions. Third, we propose that a form of local working memory exists in the form of reciprocal connections between the external globus pallidus (Gpe) and the subthalamic nucleus (STN). As a test of the model, the system was trained to learn a sequence of states that required the context of previous actions. The striatum, which was assumed to represent a conjunction of cortical states, directly selected the action in the GP during training. The STN-to-GP connection strengths were modified by an associative learning rule and came to encode the sequence after 20 to 40 iterations through the sequence. Subsequently, the system automatically reproduced the sequence when cued to the first action. The behavior of the model was found to be sensitive to the ratio of the striatal-nigral learning rate to the STN-GP learning rate. Additionally, the degree of striatal inhibition of the globus pallidus had a significant influence on both learning and the ability to select an action. Low learning rates, which would be hypothesized to reflect low levels of dopamine, as in Parkinson's disease, led to slow acquisition of contextual information. However, this could be partially offset by modeling a lesion of the globus pallidus that resulted in an increase in the gain of the STN units. The parameter sensitivity of the model is discussed within the framework of existing behavioral and lesion data.},
	number = {1},
	journal = {J. Cogn. Neurosci.},
	author = {Berns, Gs and Sejnowski, Tj},
	month = jan,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {108--121},
}

@article{gillies_computational_2000,
	title = {Computational models of the basal ganglia},
	volume = {15},
	abstract = {Computer simulation studies and mathematical analysis of models of the basal ganglia are being used increasingly to explore theories of basal ganglia function. We review the implications of these new models for a general understanding of basal ganglia function in normal as well as in diseased brains. The focus is on their functional similarities rather than on the details of mathematical methodologies and simulation techniques. Most of the models suggest a vital role for the basal ganglia in learning. Although this interest in learning is partly driven by experimental results associating the acute firing of dopamine cells with reward prediction in monkeys, some of the models have preceded the electrophysiological results. Another common theme of the models is selection. In this case, the striatum is seen as detecting and selecting cortical contexts for access to basal ganglia output. Although the behavioral consequences of this selection are hard to define, the models provide frameworks within which to explore these ideas empirically. This provides a means of refining our understanding of basal ganglia function and to consider dysfunction within the new logical frameworks.},
	number = {5},
	journal = {Mov. Disord.},
	author = {Gillies, A and Arbuthnott, G},
	month = sep,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {762--770},
}

@article{beiser_model_1998,
	title = {Model of cortical-basal ganglionic processing: encoding the serial order of sensory events},
	volume = {79},
	abstract = {Several lines of evidence suggest that the prefrontal (PF) cortex and basal ganglia are important in cognitive aspects of serial order in behavior. We present a modular neural network model of these areas that encodes the serial order of events into spatial patterns of PF activity. The model is based on the topographically specific circuits linking the PF with the basal ganglia. Each module traces a pathway from the PF, through the basal ganglia and thalamus, and back to the PF. The complete model consists of an array of modules interacting through recurrent corticostriatal projections and collateral inhibition between striatal spiny units. The model's architecture positions spiny units for the classification of cortical contexts and events and provides bistable cortical-thalamic loops for sustaining a representation of these contextual events in working memory activations. The model was tested with a simulated version of a delayed-sequencing task. In single-unit studies, the task begins with the presentation of a sequence of target lights. After a short delay, the monkey must touch the targets in the order in which they were presented. When instantiated with randomly distributed corticostriatal weights, the model produces different patterns of PF activation in response to different target sequences. These patterns represent an unambiguous and spatially distributed encoding of the sequence. Parameter studies of these random networks were used to compare the computational consequences of collateral and feed-forward inhibition within the striatum. In addition, we studied the receptive fields of 20,640 model units and uncovered an interesting set of cue-, rank- and sequence-related responses that qualitatively resemble responses reported in single unit studies of the PF. The majority of units respond to more than one sequence of stimuli. A method for analyzing serial receptive fields is presented and utilized for comparing the model units to single-unit data.},
	number = {6},
	journal = {J. Neurophysiol.},
	author = {Beiser, Dg and Houk, Jc},
	month = jun,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {3168--3188},
}

@article{whittington_inhibition-based_2000,
	title = {Inhibition-based rhythms: experimental and mathematical observations on network dynamics},
	volume = {38},
	abstract = {An increasingly large body of data exists which demonstrates that oscillations of frequency 12-80 Hz are a consequence of, or are inextricably linked to, the behaviour of inhibitory interneurons in the central nervous system. This frequency range covers the EEG bands beta 1 (12-20 Hz), beta 2 (20-30 Hz) and gamma (30-80 Hz). The pharmacological profile of both spontaneous and sensory-evoked EEG potentials reveals a very strong influence on these rhythms by drugs which have direct effects on GABA(A) receptor-mediated synaptic transmission (general anaesthetics, sedative/hypnotics) or indirect effects on inhibitory neuronal function (opiates, ketamine). In addition, a number of experimental models of, in particular, gamma-frequency oscillations, have revealed both common denominators for oscillation generation and function, and subtle differences in network dynamics between the different frequency ranges. Powerful computer and mathematical modelling techniques based around both clinical and experimental observations have recently provided invaluable insight into the behaviour of large networks of interconnected neurons. In particular, the mechanistic profile of oscillations generated as an emergent property of such networks, and the mathematical derivation of this complex phenomenon have much to contribute to our understanding of how and why neurons oscillate. This review will provide the reader with a brief outline of the basic properties of inhibition-based oscillations in the CNS by combining research from laboratory models, large-scale neuronal network simulations, and mathematical analysis.},
	number = {3},
	journal = {Int. J. Psychophysiol.},
	author = {Whittington, Ma and Traub, Rd and Kopell, N and Ermentrout, B and Buhl, Eh},
	month = dec,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {315--336},
}

@article{kopell_gamma_2000,
	title = {Gamma rhythms and beta rhythms have different synchronization properties},
	volume = {97},
	abstract = {Experimental and modeling efforts suggest that rhythms in the CA1 region of the hippocampus that are in the beta range (12-29 Hz) have a different dynamical structure than that of gamma (30-70 Hz). We use a simplified model to show that the different rhythms employ different dynamical mechanisms to synchronize, based on different ionic currents. The beta frequency is able to synchronize over long conduction delays (corresponding to signals traveling a significant distance in the brain) that apparently cannot be tolerated by gamma rhythms. The synchronization properties are consistent with data suggesting that gamma rhythms are used for relatively local computations whereas beta rhythms are used for higher level interactions involving more distant structures.},
	number = {4},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Kopell, N and Ermentrout, Gb and Whittington, Ma and Traub, Rd},
	month = feb,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {1867--1872},
}

@article{wang_gamma_1996,
	title = {Gamma oscillation by synaptic inhibition in a hippocampal interneuronal network model},
	volume = {16},
	abstract = {Fast neuronal oscillations (gamma, 20-80 Hz) have been observed in the neocortex and hippocampus during behavioral arousal. Using computer simulations, we investigated the hypothesis that such rhythmic activity can emerge in a random network of interconnected GABAergic fast-spiking interneurons. Specific conditions for the population synchronization, on properties of single cells and the circuit, were identified. These include the following: (1) that the amplitude of spike afterhyperpolarization be above the GABAA synaptic reversal potential; (2) that the ratio between the synaptic decay time constant and the oscillation period be sufficiently large; (3) that the effects of heterogeneities be modest because of a steep frequency-current relationship of fast-spiking neurons. Furthermore, using a population coherence measure, based on coincident firings of neural pairs, it is demonstrated that large-scale network synchronization requires a critical (minimal) average number of synaptic contacts per cell, which is not sensitive to the network size. By changing the GABAA synaptic maximal conductance, synaptic decay time constant, or the mean external excitatory drive to the network, the neuronal firing frequencies were gradually and monotonically varied. By contrast, the network synchronization was found to be high only within a frequency band coinciding with the gamma (20-80 Hz) range. We conclude that the GABAA synaptic transmission provides a suitable mechanism for synchronized gamma oscillations in a sparsely connected network of fast-spiking interneurons. In turn, the interneuronal network can presumably maintain subthreshold oscillations in principal cell populations and serve to synchronize discharges of spatially distributed neurons.},
	number = {20},
	journal = {J. Neurosci.},
	author = {Wang, Xj and Buzsaki, G},
	month = oct,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {6402--6413},
}

@article{levy_distributed_2001,
	title = {Distributed synchrony in a cell assembly of spiking neurons},
	volume = {14},
	abstract = {We investigate the formation of a Hebbian cell assembly of spiking neurons, using a temporal synaptic learning curve that is based on recent experimental findings. It includes potentiation for short time delays between pre- and post-synaptic neuronal spiking, and depression for spiking events occurring in the reverse order. The coupling between the dynamics of synaptic learning and that of neuronal activation leads to interesting results. One possible mode of activity is distributed synchrony, implying spontaneous division of the Hebbian cell assembly into groups, or subassemblies, of cells that fire in a cyclic manner. The behavior of distributed synchrony is investigated both by simulations and by analytic calculations of the resulting synaptic distributions.},
	number = {6-7},
	journal = {Neural Netw.},
	author = {Levy, N and Horn, D and Meilijson, I and Ruppin, E},
	year = {2001},
	keywords = {merged\_fiete.bib},
	pages = {815--824},
}

@article{clifford_perceptual_2002,
	title = {Perceptual adaptation: motion parallels orientation},
	volume = {6},
	abstract = {Adaptation phenomena provide striking examples of perceptual plasticity and offer valuable insight into the mechanisms of visual coding. Within the context of recent progress in neurobiology and computational modelling, I review evidence from studies employing psychophysical adaptation to investigate orientation and motion processing. These studies reveal marked similarities between the orientation and motion domains, raising the possibility that common computational principles underlie the processing of orientation and motion despite apparently distinct cortical substrates.},
	number = {3},
	journal = {Trends Cogn. Sci.},
	author = {Clifford, Cw},
	month = mar,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {136--143},
}

@article{wainwright_visual_1999,
	title = {Visual adaptation as optimal information transmission},
	volume = {39},
	abstract = {We propose that visual adaptation in orientation, spatial frequency, and motion can be understood from the perspective of optimal information transmission. The essence of the proposal is that neural response properties at the system level should be adjusted to the changing statistics of the input so as to maximize information transmission. We show that this principle accounts for several well-documented psychophysical phenomena, including the tilt aftereffect, change in contrast sensitivity and post-adaptation changes in orientation discrimination. Adaptation can also be considered on a longer time scale, in the context of tailoring response properties to natural scene statistics. From the anisotropic distribution of power in natural scenes, the proposal also predicts differences in the contrast sensitivity function across spatial frequency and orientation, including the oblique effect.},
	number = {23},
	journal = {Vision Res.},
	author = {Wainwright, Mj},
	month = nov,
	year = {1999},
	keywords = {merged\_fiete.bib},
	pages = {3960--3974},
}

@article{pouget_statistically_1998,
	title = {Statistically efficient estimation using population coding},
	volume = {10},
	abstract = {Coarse codes are widely used throughout the brain to encode sensory and motor variables. Methods designed to interpret these codes, such as population vector analysis, are either inefficient (the variance of the estimate is much larger than the smallest possible variance) or biologically implausible, like maximum likelihood. Moreover, these methods attempt to compute a scalar or vector estimate of the encoded variable. Neurons are faced with a similar estimation problem. They must read out the responses of the presynaptic neurons, but, by contrast, they typically encode the variable with a further population code rather than as a scalar. We show how a nonlinear recurrent network can be used to perform estimation in a near-optimal way while keeping the estimate in a coarse code format. This work suggests that lateral connections in the cortex may be involved in cleaning up uncorrelated noise among neurons representing similar variables.},
	number = {2},
	journal = {Neural Comput.},
	author = {Pouget, A and Zhang, K and Deneve, S and Latham, Pe},
	month = feb,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {373--401},
}

@article{tiesinga_synchronous_2000,
	title = {Synchronous clusters in a noisy inhibitory neural network},
	volume = {9},
	abstract = {We study the stability and information encoding capacity of synchronized states in a neuronal network model that represents part of thalamic circuitry. Our model neurons have a Hodgkin-Huxley-type low-threshold calcium channel, display postinhibitory rebound, and are connected via GABAergic inhibitory synapses. We find that there is a threshold in synaptic strength, tau(c), below which there are no stable spiking network states. Above threshold the stable spiking state is a cluster state, where different groups of neurons fire consecutively, and each neuron fires with the same cluster each time. Weak noise destabilizes this state, but stronger noise drives the system into a different, self-organized, stochastically synchronized state. Neuronal firing is still organized in clusters, but individual neurons can hop from cluster to cluster. Noise can actually induce and sustain such a state below the threshold of synaptic strength. We do find a qualitative difference in the firing patterns between small (approximately 10 neurons) and large (approximately 1000 neurons) networks. We determine the information content of the spike trains in terms of two separate contributions: the spike-time jitter around cluster firing times, and the hopping from cluster to cluster. We quantify the information loss due to temporally correlated interspike intervals. Recent experiments on the locust olfactory system and striatal neurons suggest that the nervous system may actually use these two channels to encode separate and unique information.},
	number = {1},
	journal = {J. Comput. Neurosci.},
	author = {Tiesinga, Ph and Jose, Jv},
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {49--65},
}

@article{svirskis_enhancement_2002,
	title = {Enhancement of signal-to-noise ratio and phase locking for small inputs by a low-threshold outward current in auditory neurons},
	volume = {22},
	abstract = {Neurons possess multiple voltage-dependent conductances specific for their function. To investigate how low-threshold outward currents improve the detection of small signals in a noisy background, we recorded from gerbil medial superior olivary (MSO) neurons in vitro. MSO neurons responded phasically, with a single spike to a step current injection. When bathed in dendrotoxin (DTX), most cells switched to tonic firing, suggesting that low-threshold potassium currents (I(KLT)) participated in shaping these phasic responses. Neurons were stimulated with a computer-generated steady barrage of random inputs, mimicking weak synaptic conductance transients (the “noise”), together with a larger but still subthreshold postsynaptic conductance, EPSG (the “signal”). DTX reduced the signal-to-noise ratio (SNR), defined as the ratio of probability to fire in response to the EPSG and the probability to fire spontaneously in response to noise. The reduction was mainly attributable to the increase of spontaneous firing in DTX. The spike-triggered reverse correlation indicated that, for spike generation, the neuron with I(KLT) required faster inward current transients. This narrow temporal integration window contributed to superior phase locking of firing to periodic stimuli before application of DTX. A computer model including Hodgkin-Huxley type conductances for spike generation and for I(KLT) (Rathouz and Trussell, 1998) showed similar response statistics. The dynamic low-threshold outward current increased SNR and the temporal precision of integration of weak subthreshold signals in auditory neurons by suppressing false positives.},
	number = {24},
	journal = {J. Neurosci.},
	author = {Svirskis, G and Kotak, V and Sanes, Dh and Rinzel, J},
	month = dec,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {11019--11025},
}

@article{brunel_persistent_2000,
	title = {Persistent activity and the single-cell frequency-current curve in a cortical network model},
	volume = {11},
	abstract = {Neurophysiological experiments indicate that working memory of an object is maintained by the persistent activity of cells in the prefrontal cortex and infero-temporal cortex of the monkey. This paper considers a cortical network model in which this persistent activity appears due to recurrent synaptic interactions. The conditions under which the magnitude of spontaneous and persistent activity are close to one another (as is found empirically) are investigated using a simplified mean-field description in which firing rates in these states are given by the intersections of a straight line with the f-I curve of a single pyramidal cell. The present analysis relates a network phenomenon - persistent activity in a 'working memory' state - to single-cell data which are accessible to experiment. It predicts that, in networks of the cerebral cortex in which persistent activity phenomena are observed, average synaptic inputs in both spontaneous and persistent activity should bring the cells close to firing threshold. Cells should be slightly sub-threshold in spontaneous activity, and slightly supra-threshold in persistent activity. The results are shown to be robust to the inclusion of inhomogeneities that produce wide distributions of firing rates, in both spontaneous and working memory states.},
	number = {4},
	journal = {Network},
	author = {Brunel, N},
	month = nov,
	year = {2000},
	keywords = {merged\_fiete.bib},
	pages = {261--80.},
}

@article{rao_self-organizing_2003,
	title = {Self-organizing neural systems based on predictive learning},
	volume = {361},
	abstract = {The ability to predict future events based on the past is an important attribute of organisms that engage in adaptive behaviour. One prominent computational method for learning to predict is called temporal-difference (TD) learning. It is so named because it uses the difference between successive predictions to learn to predict correctly. TD learning is well suited to modelling the biological phenomenon of conditioning, wherein an organism learns to predict a reward even though the reward may occur later in time. We review a model for conditioning in bees based on TD learning. The model illustrates how the TD-learning algorithm allows an organism to learn an appropriate sequence of actions leading up to a reward, based solely on reinforcement signals. The second part of the paper describes how TD learning can be used at the cellular level to model the recently discovered phenomenon of spike-timing-dependent plasticity. Using a biophysical model of a neocortical neuron, we demonstrate that the shape of the spike-timing-dependent learning windows found in biology can be interpreted as a form of TD learning occurring at the cellular level. We conclude by showing that such spike-based TD-learning mechanisms can produce direction selectivity in visual-motion-sensitive cells and can endow recurrent neocortical circuits with the powerful ability to predict their inputs at the millisecond time-scale.},
	number = {1807},
	journal = {Philos. Trans. A Math. Phys. Eng. Sci.},
	author = {Rao, Rp and Sejnowski, Tj},
	month = jun,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {1149--75.},
}

@article{meunier_sparsely_1991,
	title = {Sparsely coded associative memories: capacity and dynamical properties},
	volume = {2},
	abstract = {Considers very sparsely coded associative memories of binary neurons, for both Hebbian and covariant learning rules. The authors calculate explicitly their maximal capacity both in terms of patterns, and in terms of information content, taking into account the correlation of local fields, and they investigate its dependence on the degree of sparsity. The sparseness of the coding enhances both the memory capacity and the information capacity, whatever the chosen scheme. The study of the retrieval dynamics shows that, as soon as the number of patterns stored exceeds some critical value, retrieval becomes limited to the states with the same activity as the prototype patterns.},
	journal = {Network: Comput. Neural Syst.},
	author = {Meunier, C and Yanai, H-F and Amari, S},
	month = nov,
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {469--487},
}

@article{drew_model_2003,
	title = {Model of song selectivity and sequence generation in area {HVc} of the songbird},
	volume = {89},
	abstract = {In songbirds, nucleus HVc plays a key role in the generation of the syllable sequences that make up a song. Auditory responses of neurons in HVc are selective for single syllables and for combinations of syllables occurring in temporal sequences corresponding to those in the bird's own song. We present a model of HVc that produces syllable- and temporal-combination-selective responses on the basis of input from recorded bird songs filtered through spectral temporal receptive fields similar to those measured in field L, a primary auditory area. Normalization of the field L outputs, similar to that proposed in models of visual processing, plays an important role in the generation of syllable-selective responses in the model. For temporal-combination-selective responses, N-methyl-d-aspartate (NMDA) conductances provide a memory that allows inhibitory neurons to gate responses to a final syllable in a sequence on the basis of responses to earlier syllables. When the same network that produces temporal-combination-selective responses is excited by a nonspecific timing signal, it generates a similar pattern of output as it does in response to auditory song input. Thus the same model network can perform both sensory and motor functions.},
	number = {5},
	journal = {J. Neurophysiol.},
	author = {Drew, Pj and Abbott, Lf},
	month = may,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {2697--706. Epub 2003 Jan 22.},
}

@article{arnold_learning_1991,
	title = {A learning network model of the neural integrator of the oculomotor system},
	volume = {64},
	abstract = {Certain premotor neurons of the oculomotor system fire at a rate proportional to desired eye velocity. Their output is integrated by a network of neurons to supply an eye position command to the motoneurons of the extraocular muscles. This network, known as the neural integrator, is calibrated during infancy and then maintained through development and trauma with remarkable precision. We have modeled this system with a self-organizing neural network that learns to integrate vestibular velocity commands to generate appropriate eye movements. It learns by using current eye movement on any given trial to calculate the amount of retinal image slip and this is used as the error signal. The synaptic weights are then changed using a straight-forward algorithm that is independent of the network configuration and does not necessitate backwards propagation of information. Minimization of the error in this fashion causes the network to develop multiple positive feedback loops that enable it to integrate a push-pull signal without integrating the background rate on which it rides. The network is also capable of recovering from various lesions and of generating more complicated signals to simulate induced post-saccadic drift and compensation for eye muscle mechanics.},
	number = {6},
	journal = {Biol. Cybern.},
	author = {Arnold, D B and Robinson, D A},
	month = apr,
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {447--454},
}

@article{traub_model_1991,
	title = {A model of a {CA3} hippocampal pyramidal neuron incorporating voltage-clamp data on intrinsic conductances},
	volume = {66},
	abstract = {1. We have developed a 19-compartment cable model of a guinea pig CA3 pyramidal neuron. Each compartment is allowed to contain six active ionic conductances: gNa, gCa, gK(DR) (where DR stands for delayed rectifier), gK(A), gK(AHP), and gK(C). THe conductance gCa is of the high-voltage activated type. The model kinetics for the first five of these conductances incorporate voltage-clamp data obtained from isolated hippocampal pyramidal neurons. The kinetics of gK(C) are based on data from bullfrog sympathetic neurons. The time constant for decay of submembrane calcium derives from optical imaging of Ca signals in Purkinje cell dendrites. 2. To construct the model from available voltage-clamp data, we first reproduced current-clamp records from a model isolated neuron (soma plus proximal dendrites). We next assumed that ionic channel kinetics in the dendrites were the same as in the soma. In accord with dendritic recordings and calcium-imaging data, we also assumed that significant gCa occurs in dendrites. We then attached sections of basilar and apical dendritic cable. By trial and error, we found a distribution (not necessarily unique) of ionic conductance densities that was consistent with current-clamp records from the soma and dendrites of whole neurons and from isolated apical dendrites. 3. The resulting model reproduces the Ca(2+)-dependent spike depolarizing afterpotential (DAP) recorded after a stimulus subthreshold for burst elicitation. 4. The model also reproduces the behavior of CA3 pyramidal neurons injected with increasing somatic depolarizing currents: low-frequency (0.3-1.0 Hz) rhythmic bursting for small currents, with burst frequency increasing with current magnitude; then more irregular bursts followed by afterhyperpolarizations (AHPs) interspersed with brief bursts without AHPs; and finally, rhythmic action potentials without bursts. 5. The model predicts the existence of still another firing pattern during tonic depolarizing dendritic stimulation: brief bursts at less than 1 to approximately 12 Hz, a pattern not observed during somatic stimulation. These bursts correspond to rhythmic dendritic calcium spikes. 6. The model CA3 pyramidal neuron can be made to resemble functionally a CA1 pyramidal neuron by increasing gK(DR) and decreasing dendritic gCa and gK(C). Specifically, after these alterations, tonic depolarization of the soma leads to adapting repetitive firing, whereas stimulation of the distal dendrites leads to bursting. 7. A critical set of parameters concerns the regulation of the pool of intracellular [Ca2+] that interacts with membrane channels (gK(C) and gK(AHP)), particularly in the dendrites.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Traub, Rd and Wong, Rk and Miles, R and Michelson, H},
	month = aug,
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {635--50.},
}

@article{wang_ionic_1993,
	title = {Ionic basis for intrinsic 40 {Hz} neuronal oscillations},
	volume = {5},
	abstract = {We present a biophysical model of a slowly inactivating potassium ion current IKS, based on recent voltage-clamp data from layer V pyramidal neurons in the cat sensorimotor cortex and show that the interplay between a persistent sodium current INaP and IKS is able to produce intrinsic membrane potential oscillations in the 10- to 50-frequency range. A most notable characteristic of such rhythmicity is what may be termed mixed-mode bursting, where clusters of action potentials alternate in time with epochs of small subthreshold oscillations.},
	number = {3},
	journal = {Neuroreport},
	author = {Wang, Xj},
	month = dec,
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {221--4.},
}

@article{widrow_30_1990,
	title = {30 {Years} of {Adaptive} {Neural} {Networks}: {Perceptron}, {Madaline}, and {Backpropogation}},
	volume = {78},
	number = {9},
	journal = {Proc. IEEE},
	author = {Widrow, B and Lehr, M},
	month = sep,
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {1415--1442},
}

@article{sarpeshkar_white_1993,
	title = {White {Noise} in {MOS} {Transistors} and {Resistors}},
	volume = {9},
	abstract = {The theoretical and experimental results for white noise in the low-power subthreshold region of operation of an MOS transistor are discussed. It is shown that the measurements are consistent with the theoretical predictions. Measurements of noise in photoreceptors-circuits containing a photodiode and an MOS transistor-that are consistent with theory are reported. The photoreceptor noise measurements illustrate the intimate connection of the equipartition theorem of statistical mechanics with noise calculations.},
	number = {6},
	journal = {IEEE Circuits Devices Mag.},
	author = {Sarpeshkar, R and Delbruck, T and Mead, C A},
	month = nov,
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {23--29},
}

@inproceedings{werfel_learning_2003,
	title = {Learning curves for stochastic gradient descent in linear feedforward networks},
	booktitle = {{NIPS}},
	author = {Werfel, J K and Xie, X H and Seung, H S},
	year = {2003},
	keywords = {merged\_fiete.bib},
}

@article{dehaene_neural_1987,
	title = {Neural networks that learn temporal sequences by selection},
	volume = {84},
	abstract = {A model for formal neural networks that learn temporal sequences by selection is proposed on the basis of observations on the acquisition of song by birds, on sequence-detecting neurons, and on allosteric receptors. The model relies on hypothetical elementary devices made up of three neurons, the synaptic triads, which yield short-term modification of synaptic efficacy through heterosynaptic interactions, and on a local Hebbian learning rule. The functional units postulated are mutually inhibiting clusters of synergic neurons and bundles of synapses. Networks formalized on this basis display capacities for passive recognition and for production of temporal sequences that may include repetitions. Introduction of the learning rule leads to the differentiation of sequence-detecting neurons and to the stabilization of ongoing temporal sequences. A network architecture composed of three layers of neuronal clusters is shown to exhibit active recognition and learning of time sequences by selection: the network spontaneously produces prerepresentations that are selected according to their resonance with the input percepts. Predictions of the model are discussed.},
	number = {9},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Dehaene, S and Changeux, Jp and Nadal, Jp},
	month = may,
	year = {1987},
	keywords = {merged\_fiete.bib},
	pages = {2727--31.},
}

@article{amit_correlations_1994,
	title = {Correlations of cortical {Hebbian} reverberations: theory versus experiment},
	volume = {14},
	abstract = {Interpreting recent single-unit recordings of delay activities in delayed match-to-sample experiments in anterior ventral temporal (AVT) cortex of monkeys in terms of reverberation dynamics, we present a model neural network of quasi-realistic elements that reproduces the empirical results in great detail. Information about the contiguity of successive stimuli in the training sequence, representing the fact that training is done on a set of uncorrelated stimuli presented in a fixed temporal sequence, is embedded in the synaptic structure. The model reproduces quite accurately the correlations between delay activity distributions corresponding to stimulation with the uncorrelated stimuli used for training. It reproduces also the activity distributions of spike rates on sample cells as a function of the stimulating pattern. It is, in our view, the first time that a computational phenomenon, represented on the neurophysiological level, is reproduced in all its quantitative aspects. The model is then used to make predictions about further features of the physiology of such experiments. Those include further properties of the correlations, features of selective cells as discriminators of stimuli provoking different delay activity distributions, and activity distributions among the neurons in a delay activity produced by a given pattern. The model has predictive implications also for the dependence of the delay activities on different training protocols. Finally, we discuss the perspectives of the interplay between such models and neurophysiology as well as its limitations and possible extensions.},
	number = {11 Pt 1},
	journal = {J. Neurosci.},
	author = {Amit, Dj and Brunel, N and Tsodyks, Mv},
	month = nov,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {6435--45.},
}

@article{amari_learning_1972-1,
	title = {Learning {Patterns} and {Pattern} {Sequences} by {Self}-{Organizing} {Nets} of {Threshold} {Elements}},
	volume = {C-21},
	abstract = {We suggest a mecpurpose, the stability of state transition in an autonomous logical net of threshold elements is studied by the use of characteristics of threshold elements. It is also shown that a self-organizing net forms a representative pattern from a given set of stimulus patterns and fixes it as a stable state. The representative pattern can be recalled from any member of the set. This kind of self-organizing net may be regarded as a model for associative memory, sequential recalling, and concept formation.},
	number = {11},
	journal = {IEEE Trans. Comput.},
	author = {Amari, Shun-Ichi},
	month = nov,
	year = {1972},
	keywords = {merged\_fiete.bib},
	pages = {1197--1206},
}

@article{amari_characteristics_1972,
	title = {Characteristics of {Random} {Nets} of {Analog} {Neuron}-{Like} {Elements}},
	volume = {SMC-2},
	abstract = {The dynamic behavior of randomly connected analog neuron-like elements that process pulse-frequency modulated signals is investigated from the macroscopic point of view. By extracting two statistical parameters, the macroscopic state equations are derived in terms of these parameters under some hypotheses on the stochastics of microscopic states. It is shown that a random net of statistically symmetric structure is monostable or bistable, and the stability criteria are explicitly given. Random nets consisting of many different classes of elements are also analyzed. Special attention is paid to nets of randomly connected excitatory and inhibitory elements. It is shown that a stable oscillation exists in such a net - in contrast with the fact that no stable oscillations exist in a net of statistically symmetric structure even if negative as well as positive synaptic weights are permitted at a time. The results are checked by computer-simulated experiments.},
	number = {5},
	journal = {IEEE Transactions on Systems, Man, \& Cybernetics},
	author = {Amari, Shun-Ichi},
	month = nov,
	year = {1972},
	keywords = {merged\_fiete.bib},
	pages = {643--657},
}

@article{dembo_model-free_1990,
	title = {Model-{Free} {Distributed} {Learning}},
	volume = {1},
	abstract = {Model-free learning for synchronous and asynchronous quasi-static networks is presented. The network weights are continuously perturbed while the time varying performance index is measured and correlated with the perturbation signals; the correlation output determines the changes in the weights. The perturbation may be either via noise sources or orthogonal signals. The invariance to detailed network structure mitigates large variability between supposedly identical networks as well as implementation defects. This local, regular, and completely distributed mechanism requires no central control, and involves only few global signals. Thus is allows for integrated, on-chip learning in large analog and optical networks.},
	number = {1},
	journal = {IEEE Trans. Neural Netw.},
	author = {Dembo, Amir and Kailath, Thomas},
	month = mar,
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {58--70},
}

@article{marr_theory_1970,
	title = {A {Theory} for {Cerebral} {Neocortex}},
	volume = {176},
	abstract = {It is proposed that the learning of many tasks by the cerebrum is based on using a very few fundamental techniques for organizing information. It is argued that this is made possible by the prevalence in the world of a particular kind of redundancy, which is characterized by a 'Fundamental Hypothesis'. This hypothesis is used to found a theory of the basic operations which, it is proposed, are carried out by the cerebral neocortex. They involve the use of past experience to form so-called 'classificatory units' with which to interpret subsequent experience. Such classificatory units are imagined to be created whenever either something occurs frequently in the brain's experience, or enough redundancy appears in the form of clusters of slightly differing inputs. A (non-Bayesian) information theoretic account is given of the diagnosis of an input as an instance of an existing classificatory unit, and of the interpretation as such of an incompletely specified input. Neural models are devised to implement the two operations of diagnosis and interpretation, and it is found that the performance of the second is an automatic consequence of the model's ability to perform the first. The discovery and formation of new classificatory units is discussed within the context of these neural models. It is shown how a climbing fibre input (of the kind described by Cajal) to the correct cell can cause that cell to perform a mountain-climbing operation in an underlying probability space, that will lead it to respond to a class of events for which it is appropriate to code. This is called the 'spatial recognizer effect'. The structure of the cerebral neocortex is reviewed in the light of the model which the theory establishes. It is found that many elements in the cortex have a natural identification with elements in the model. This enables many predictions, with specified degrees of firmness, to be made concerning the connexions and synapses of the following cortical cells and fibres: Martinotti cells; cerebral granule cells; pyramidal cells of layers III, V and II; short axon cells of all layers, especially I, IV and VI; cerebral climbing fibres and those cells of the cortex which give rise to them; cerebral basket cells; fusiform cells of layers VI and VII. It is shown that if rather little information about the classificatory units to be formed has been coded genetically, it may be necessary to use a technique called codon formation to organize structure in a suitable way to represent a new unit. It is shown that under certain conditions, it is necessary to carry out a part of this organization during sleep. A prediction is made about the effect of sleep on learning of a certain kind.},
	number = {1043},
	journal = {Proc. R. Soc. Lond. B Biol. Sci.},
	author = {Marr, D},
	month = nov,
	year = {1970},
	keywords = {merged\_fiete.bib},
	pages = {161--234},
}

@article{marr_simple_1971,
	title = {Simple {Memory}: {A} {Theory} for {Archicortex}},
	volume = {262},
	abstract = {It is proposed that the most important characteristic of archicortex is its ability to perform a simple kind of memorizing task. It is shown that rather general numerical constraints roughly determine the dimensions of memorizing models for the mammalian brain, and from these is derived a general model for archicortex. The addition of further constraints leads to the notion of a simple representation, which is a way of translating a great deal of information into the firing of about 200 out of a population of 10{\textasciicircum}5 cells. It is shown that if about 10{\textasciicircum}5 simple representations are stored in such a population of cells, very little information about a single learnt event is necessary to provoke its recall. A detailed numerical examination is made of a particular example of this kind of memory, and various general conclusions are drawn from the analysis. The insight gained from these models is used to derive theories for various archicortical areas. A functional interpretation is given of the cells and synapses of the area entorhinalis, the presubiculum, the prosubiculum, the cornu ammonis and the fascia dentata. Many predictions are made, a substantial number of which must be true if the theory is correct. A general functional classification of typical archicortical cells is proposed.},
	number = {841},
	journal = {Philos. Trans. R. Soc. Lond. B Biol. Sci.},
	author = {Marr, D},
	month = jul,
	year = {1971},
	keywords = {merged\_fiete.bib},
	pages = {23--81},
}

@article{mcnaughton_hippocampal_1987,
	title = {Hippocampal synaptic enhancement and information storage within a distributed memory system},
	volume = {10},
	abstract = {The hypothesis that the physical substrate of memory in the mammalian brain resides in alterations of synaptic efficacy has been proposed frequently in both neuroscience (1-5) and cognitive science (6-12), and has been widely investigated in behavioural, physiological and theoretical studies. Although this hypothesis remains unproven, considerable evidence suggests that a particular form of synaptic strengthening, induced by electrical stimulation of certain CNS fibre systems, may represent the activation of mechanisms that normally subserve associative memory. This phenomenon is known as long-term potentiation (LTP) or long-term enhancement (LTE)*. It has been most intensively investigated within the hippocampal formation, a brain structure that plays a crucial role in certain forms of associative memory. Physiological investigation has revealed that LTE exhibits most of the properties implicit in Hebb's original suggestion that associative memory results from a synaptic strengthening that is contingent upon the conjunction of activity in pre- and post-synaptic elements. In this article, we outline a simple neuronal model capable of superimposing multiple memory traces within the same matrix of connections, and consider the correspondence between such models and the properties of LTE in the context of the hippocampal circuitry in which it occurs. Certain predictions are derived from this framework concerning the behavioural consequences of experimental manipulation of LTE, and we conclude by describing experimental evidence that confirms these predictions and suggests that LTE is, in fact, fundamentally involved in memory.},
	number = {10},
	journal = {Trends Neurosci.},
	author = {McNaughton, B L and Morris, R G M},
	year = {1987},
	keywords = {merged\_fiete.bib},
	pages = {408--415},
}

@article{treves_computational_1994,
	title = {Computational analysis of the role of the hippocampus in memory},
	volume = {4},
	abstract = {The authors draw together the results of a series of detailed computational studies and show how they are contributing to the development of a theory of hippocampal function. A new part of the theory introduced here is a quantitative analysis of how backprojections from the hippocampus to the neocortex could lead to the recall of recent memories. The theory is then compared with other theories of hippocampal function. First, what is computed by the hippocampus is considered. The hypothesis the authors advocate, on the basis of the effects of damage to the hippocampus and neuronal activity recorded in it, is that it is involved in the formation of new memories by acting as an intermediate-term buffer store for information about episodes, particularly for spatial, but probably also for some nonspatial, information. The authors analyze how the hippocampus could perform this function, by producing a computational theory of how it operates, based on neuroanatomical and neurophysiological information about the different neuronal systems contained within the hippocampus. Key hypotheses are that the CA3 pyramidal cells operate as a single autoassociation network to store new episodic information as it arrives via a number of specialized preprocessing stages from many association areas of the cerebral cortex, and that the dentate granule cell/mossy fiber system is important, particularly during learning, to help to produce a new pattern of firing in the CA3 cells for each episode. The computational analysis shows how many memories could be stored in the hippocampus and how quickly the CA3 autoassociation system would operate during recall. The analysis is then extended to show how the CA3 system could be used to recall a whole episodic memory when only a fragment of it is presented. It is shown how this recall could operate using modified synapses in backprojection pathways from the hippocampus to the cerebral neocortex, resulting in reinstatement of neuronal activity in association areas of the cerebral neocortex similar to that present during the original episode. The recalled information in the cerebral neocortex could then be used by the neocortex in the formation of long-term memories.},
	number = {3},
	journal = {Hippocampus},
	author = {Treves, A and Rolls, Et},
	month = jun,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {374--91.},
}

@article{treves_computational_1992,
	title = {Computational constraints suggest the need for two distinct input systems to the hippocampal {CA3} network},
	volume = {2},
	abstract = {The CA3 network in the hippocampus may operate as an autoassociator, in which declarative memories, known to be dependent on hippocampal processing, could be stored, and subsequently retrieved, using modifiable synaptic efficacies in the CA3 recurrent collateral system. On the basis of this hypothesis, the authors explore the computational relevance of the extrinsic afferents to the CA3 network. A quantitative statistical analysis of the information that may be relayed by such afferent connections reveals the need for two distinct systems of input synapses. The synapses of the first system need to be strong (but not associatively modifiable) in order to force, during learning, the CA3 cells into a pattern of activity relatively independent of any inputs being received from the recurrent collaterals, and which thus reflects sizable amounts of new information. It is proposed that the mossy fiber system performs this function. A second system, with a large number of associatively modifiable synapses on each receiving cell, is needed in order to relay a signal specific enough to initiate the retrieval process. This may be identified, we propose, with the perforant path input to CA3.},
	number = {2},
	journal = {Hippocampus},
	author = {Treves, A and Rolls, E T},
	month = apr,
	year = {1992},
	keywords = {merged\_fiete.bib},
	pages = {189--99.},
}

@article{willshaw_assessment_1990,
	title = {An assessment of {Marr}'s theory of the hippocampus as a temporary memory store},
	volume = {329},
	abstract = {The recent reawakened interest in 'neural' networks begs the question of their relevance to the analysis of real nervous systems. Network models have been criticized for the lack of realism of their individual components, and because the architectures required by some neural-network algorithms do not seem to exist in real nervous systems. In three related papers published in the 1970s, David Marr proposed that the cerebellum, the neocortex and the hippocampus each acts as a memorizing device. These theories were intended to satisfy the biological constraints, but in computational terms they are undetermined. In this paper we reassess Marr's theory of the hippocampus as a temporary memory store. We give a complete computational account of the theory and we show that Marr's computational arguments do not sufficiently constrain his choice of model. We discuss Marr's specific model of temporary memory with reference to the neurophysiology and neuroanatomy of the mammalian hippocampus. Our analysis is supported by simulation studies done on various memory models built according to the principles advocated by Marr.},
	number = {1253},
	journal = {Philos. Trans. R. Soc. Lond. B Biol. Sci.},
	author = {Willshaw, D J and Buckingham, J T},
	month = aug,
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {205--15.},
}

@inproceedings{andes_mriii_1990,
	title = {{MRIII}: {A} {Robust} {Algorithm} for {Training} {Analog} {Neural} {Networks}},
	volume = {1 - Theory Track - Neural and Cognitive Sciences Track},
	abstract = {Like many training algorithms for artificial neural networks, the backpropagation technique assumes complete a priori knowledge about both the network architecture and the transfer characteristics of the computing devices. This is reasonable if the network is to be constructed with floating-point hardware. If, however, the implementation is to be analog, often the assumed knowledge will not be available in any precise form. Thus, there is some need for a method which is analogous to backpropagation, but better suited for analog circuitry. In this paper we introduce Madaline Rule III (MRIII), a new training rule which serves this purpose. Like backpropagation, MRIII trains differentiable neural networks by steepest-descent. Consequently, when applied to simple feed-forward topologies with known characteristics, both algorithms achieve equivalent solutions. MRIII does not need prior knowledge about the network, so it is relatively immune to the effects of neuron-to-neuron variations and unknown or non-ideal component characteristics. Thus the new algorithm performs well when applied to analog neural networks, including networks comprised of unconventional components, and those with unusual or recurrent interconnections.},
	booktitle = {{IJCNN}-90-{WASHDC}: {International} {Joint} {Conference} on {Neural} {Networks}},
	publisher = {Lawrence Erlbaum Associates},
	author = {Andes, D and Widrow, B and Lehr, M and Wan, E},
	year = {1990},
	note = {Backup Publisher: Co-sponsored by the International Neural Network Society and the Institute of Electrical and Electronics Engineers, Inc.},
	keywords = {merged\_fiete.bib},
	pages = {533--536},
}

@article{xie_learning_2004,
	title = {Learning in neural networks by reinforcement of irregular spiking},
	volume = {69},
	abstract = {Artificial neural networks are often trained by using the back propagation algorithm to compute the gradient of an objective function with respect to the synaptic strengths. For a biological neural network, such a gradient computation would be difficult to implement, because of the complex dynamics of intrinsic and synaptic conductances in neurons. Here we show that irregular spiking similar to that observed in biological neurons could be used as the basis for a learning rule that calculates a stochastic approximation to the gradient. The learning rule is derived based on a special class of model networks in which neurons fire spike trains with Poisson statistics. The learning is compatible with forms of synaptic dynamics such as short-term facilitation and depression. By correlating the fluctuations in irregular spiking with a reward signal, the learning rule performs stochastic gradient ascent on the expected reward. It is applied to two examples, learning the XOR computation and learning direction selectivity using depressing synapses. We also show in simulation that the learning rule is applicable to a network of noisy integrate-and-fire neurons.},
	journal = {Phys. Rev. E Stat. Nonlin. Soft Matter Phys.},
	author = {Xie, X and Seung, H S},
	month = apr,
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {041909},
}

@article{reeke_synthetic_1990,
	title = {Synthetic {Neural} {Modeling}: {The} “{Darwin}” {Series} of {Recognition} {Automata}},
	volume = {78},
	abstract = {Synthetic neural modeling is a multilevel theoretical approach to the problem of understanding the neuronal bases of adaptive behavior. It uses simultaneous large-scale computer simulations of the nervous system, the phenotype, and the environment of a particular organism to study events and their interactions at these three levels. The simulations are based on physiological and anatomical data. They incorporate detailed models for synaptic modification, for the organization of cells into neuronal groups and larger assemblies, and for the integrated action of multiple cortical layers and brain regions to generate behavior in the context of a particular environment and the unique history of an organism. Synthetic neural modeling takes into account possible evolutionary origins and modes of development of the nervous system, permitting a wide range of psychophysical and behavioral phenomena to be studied within a common framework. The automata discussed here deal first with certain abstract properties of pattern recognition (Darwin I) and then with categorization and association (Darwin II). The discussion culminates in a description of an automaton with sensory and motor systems and autonomous behavior (Darwin III). The behavior of this automaton is not programmed but results from its encounter with events in its world under constraints of neuronal and synaptic selection. Darwin III exists in an environment of simple two-dimensional shapes moving on a background; its phenotype comprises a sessile “creature” with an eye and a multijointed arm provided with senses of touch and kinesthesia; its nervous system consists of some 50 interconnected networks containing over 50,000 cells and 620,000 synaptic junctions. By interaction with its environment, Darwin III develops sensorimotor coordination, permitting it to track moving objects with its eye, to reach out and touch objects with its arm, to categorize certain objects according to combinations of visual, tactile, and kinesthetic cues, and to respond to objects based on previous categorizations. These elementary behaviors provide a microcosm in which it is possible to analyze critical problems involving the acquisition and maturation of integrated sensory and motor behavior in animals.},
	number = {9},
	journal = {Proc. IEEE},
	author = {Reeke, G N and {Jr.} and Sporns, O and Edelman, G M},
	month = sep,
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {1498--1530},
}

@article{tsodyks_hierarchical_1990,
	title = {Hierarchical associative memory in neural networks with low activity level},
	volume = {4},
	abstract = {A Hopfield-like neural network that can store hierarchically correlated patterns with low level of activity is studied. Three learning rules are proposed which enable to obtain nearly optimal storage capacity. These learning rules have different rate of biological relevancy and the restrictions they put upon the structure of hierarchical tree. By varying the value of the neural threshold, it is possible to climb up and down the hierarchical tree.},
	number = {4},
	journal = {Mod. Phys. Lett. B},
	author = {Tsodyks, M V},
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {259--265},
}

@article{tsodyks_associative_1990,
	title = {Associative memory in neural networks with binary synapses},
	volume = {4},
	abstract = {The simple learning algorithm in the neural network with binary synapses, which take one step for storing one pattern is considered. The resulting model turns out to be palimpsestic, and the number of patterns which can be effectively retrieved is L N{\textasciicircum}1/2.},
	number = {11},
	journal = {Mod. Phys. Lett. B},
	author = {Tsodyks, M V},
	year = {1990},
	keywords = {merged\_fiete.bib},
	pages = {713--716},
}

@article{tsodyks_associative_1989,
	title = {Associative memory in neural networks with the {Hebbian} learning rule},
	volume = {3},
	abstract = {We consider the Hopfield model with the most simple form of the Hebbian learning rule, when only simultaneous activity of pre- and post-synaptic neurons leads to modification of synapse. An extra inhibition proportional to full network activity is needed. Both symmetric nondiluted and asymmetric diluted networks are considered. The model performs well at extremely low level of activity p {\textless} K{\textasciicircum}-1/2, where K is the mean number of synapses per neuron.},
	number = {7},
	journal = {Mod. Phys. Lett. B},
	author = {Tsodyks, M V},
	year = {1989},
	keywords = {merged\_fiete.bib},
	pages = {555--560},
}

@article{tsodyks_associative_1988,
	title = {Associative memory in asymmetric diluted network with low level of activity},
	volume = {7},
	abstract = {We extend the analysis of asymmetric diluted networks to the case of low-activity level. The same learning algorithm which was used for the symmetric model turns out to be successful. The use of “V-variables” (V = 0; 1) leads to significant enhancing of the storage capacity. The overloading phase transition is found to be of the first order, which means good retrieval quality in all associative memory phases. The intensity of time-dependent nonthermal noise can be diminished considerably by the appropriate choice of the neural threshold. Some sort of “universality” of the performance of the networks with low-activity level can be noted.},
	number = {3},
	journal = {Europhys. Lett.},
	author = {Tsodyks, M V},
	month = oct,
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {203--208},
}

@article{tsodyks_enhanced_1988,
	title = {The enhanced storage capacity in neural networks with low activity level},
	volume = {6},
	abstract = {The modified Hopfield model defined in terms of “V-variables” (V = 0; 1), which is appropriate for storage of correlated patterns, is considered. The learning algorithm is proposed to enhance significantly the storage capacity in comparison with previous estimates. At low levels of neural activity, p {\textless}{\textless} 1, we obtain a[subscript: c](p) (p{\textbar}lnp{\textbar}){\textasciicircum}-1 which resembles Gardner's estimate for the maximum storage capacity.},
	number = {2},
	journal = {Europhys. Lett.},
	author = {Tsodyks, M V and Feigelman, M V},
	month = may,
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {101--105},
}

@article{friston_value-dependent_1994,
	title = {Value-dependent selection in the brain: simulation in a synthetic neural model},
	volume = {59},
	abstract = {Many forms of learning depend on the ability of an organism to sense and react to the adaptive value of its behavior. Such value, if reflected in the activity of specific neural structures (neural value systems), can selectively increase the probability of adaptive behaviors by modulating synaptic changes in the circuits relevant to those behaviors. Neuromodulatory systems in the brain are well suited to carry out this process since they respond to evolutionarily important cues (innate value), broadcast their responses to widely distributed areas of the brain through diffuse projections, and release substances that can modulate changes in synaptic strength. The main aim of this paper is to show that, if value-dependent modulation is extended to the inputs of neural value systems themselves, initially neutral cues can acquire value. This process has important implications for the acquisition of behavioral sequences. We have used a synthetic neural model to illustrate value-dependent acquisition of a simple foveation response to a visual stimulus. We then examine the improvement that ensues when the connections to the value system are themselves plastic and thus become able to mediate acquired value. Using a second-order conditioning paradigm, we demonstrate that auditory discrimination can occur in the model in the absence of direct positive reinforcement and even in the presence of slight negative reinforcement. The discriminative responses are accompanied by value-dependent plasticity of receptive fields, as reflected in the selective augmentation of unit responses to valuable sensory cues. We then consider the time-course during learning of the responses of the value system and the transfer of these responses from one sensory modality to another. Finally, we discuss the relation of value-dependent learning to models of reinforcement learning. The results obtained from these simulations can be directly related to various reported experimental findings and provide additional support for the application of selectional principles to the analysis of brain and behavior.},
	number = {2},
	journal = {Neuroscience},
	author = {Friston, K J and Tononi, G and Jr, G N Reeke and Sporns, O and Edelman, G M},
	month = mar,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {229--43.},
}

@article{longuet-higgins_theories_1970,
	title = {Theories of associative recall},
	volume = {3},
	number = {2},
	journal = {Q. Rev. Biophys.},
	author = {Longuet-Higgins, H C and Willshaw, D J and Buneman, O P},
	month = may,
	year = {1970},
	keywords = {merged\_fiete.bib},
	pages = {223--44.},
}

@article{titze_physics_1988,
	title = {The physics of small-amplitude oscillation of the vocal folds},
	volume = {83},
	abstract = {A theory of vocal fold oscillation is developed on the basis of the body-cover hypothesis. The cover is represented by a distributed surface layer that can propagate a mucosal surface wave. Linearization of the surface-wave displacement and velocity, and further small-amplitude approximations, yields closed-form expressions for conditions of oscillation. The theory predicts that the lung pressure required to sustain oscillation, i.e., the oscillation threshold pressure, is reduced by reducing the mucosal wave velocity, by bringing the vocal folds closer together and by reducing the convergence angle in the glottis. The effect of vocal tract acoustic loading is included. It is shown that vocal tract inertance reduces the oscillation threshold pressure, whereas vocal tract resistance increases it. The treatment, which is applicable to falsetto and breathy voice, as well as onset or release of phonation in the absence of vocal fold collision, is harmonized with former treatments based on two-mass models and collapsible tubes.},
	number = {4},
	journal = {J. Acoust. Soc. Am.},
	author = {Titze, I R},
	month = apr,
	year = {1988},
	keywords = {merged\_fiete.bib},
	pages = {1536--52.},
}

@article{dayan_optimising_1991,
	title = {Optimising synaptic learning rules in linear associative memories},
	volume = {65},
	abstract = {Associative matrix memories with real-valued synapses have been studied in many incarnations. We consider how the signal/noise ratio for associations depends on the form of the learning rule, and we show that a covariance rule is optimal. Two other rules, which have been suggested in the neurobiology literature, are asymptotically optimal in the limit of sparse coding. The results appear to contradict a line of reasoning particularly prevalent in the physics community. It turns out that the apparent conflict is due to the adoption of different underlying models. Ironically, they perform identically at their co-incident optima. We give details of the mathematical results, and discuss some other possible derivations and definitions of the signal/noise ratio.},
	number = {4},
	journal = {Biol. Cybern.},
	author = {Dayan, P and Willshaw, D J},
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {253--65.},
}

@article{mcclelland_why_1995,
	title = {Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory},
	volume = {102},
	abstract = {Damage to the hippocampal system disrupts recent memory but leaves remote memory intact. The account presented here suggests that memories are first stored via synaptic changes in the hippocampal system, that these changes support reinstatement of recent memories in the neocortex, that neocortical synapses change a little on each reinstatement, and that remote memory is based on accumulated neocortical changes. Models that learn via changes to connections help explain this organization. These models discover the structure in ensembles of items if learning of each item is gradual and interleaved with learning about other items. This suggests that the neocortex learns slowly to discover the structure in ensembles of experiences. The hippocampal system permits rapid learning of new items without disrupting this structure, and reinstatement of new memories interleaves them with others to integrate them into structured neocortical memory systems.},
	number = {3},
	journal = {Psychol. Rev.},
	author = {McClelland, J L and McNaughton, B L and O'Reilly, R C},
	month = jul,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {419--57.},
}

@article{stollberg_synapse_1995,
	title = {Synapse elimination, the size principle, and {Hebbian} synapses},
	volume = {26},
	abstract = {Synapse elimination at the vertebrate neuromuscular junction reduces a polyinnervated population of muscle fibers to a monoinnervated state. The function of this developmental phenomenon (if any) is unproven. A theoretical analysis of Hebbian (correlation) rules connecting presynaptic and postsynaptic activity and synaptic strength at the neuromuscular junction is presented. The following points are demonstrated: (1) Correlational competition leads to the reduction of polyinnervation to a stable monoinnervated state; (2) the competition gives rise to the size principle over a wide range of the plausible parameter space; (3) over a significant subrange, the competition selectively eliminates topographically incorrect synapses; and (4) in cases in which topographic projection errors overwhelm the system, both error correction and the development of the size principle are disrupted. Correlational competition may explain contradictory experimental results concerning the effects of stimulating or silencing subpopulations of motor neurons. It may also explain an otherwise puzzling instance of a breakdown in the size principle seen in humans undergoing neural regeneration. Taken together, these findings suggest a novel hypothesis for the function of synapse elimination at the neuromuscular junction: the establishment of the size principle.},
	number = {2},
	journal = {J. Neurobiol.},
	author = {Stollberg, J},
	month = feb,
	year = {1995},
	keywords = {merged\_fiete.bib},
	pages = {273--82.},
}

@article{daw_opponent_2002,
	title = {Opponent interactions between serotonin and dopamine},
	volume = {15},
	abstract = {Anatomical and pharmacological evidence suggests that the dorsal raphe serotonin system and the ventral tegmental and substantia nigra dopamine system may act as mutual opponents. In the light of the temporal difference model of the involvement of the dopamine system in reward learning, we consider three aspects of motivational opponency involving dopamine and serotonin. We suggest that a tonic serotonergic signal reports the long-run average reward rate as part of an average-case reinforcement learning model; that a tonic dopaminergic signal reports the long-run average punishment rate in a similar context; and finally speculate that a phasic serotonin signal might report an ongoing prediction error for future punishment.},
	number = {4-6},
	journal = {Neural Netw.},
	author = {Daw, Nd and Kakade, S and Dayan, P},
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {603--16.},
}

@article{fransen_model_1998,
	title = {A model of cortical associative memory based on a horizontal network of connected columns},
	volume = {9},
	abstract = {An attractor network model of cortical associative memory functions has been constructed and simulated. By replacing the single cell as the functional unit by multiple cells in cortical columns connected by long-range fibers, the model is improved in terms of correspondence with cortical connectivity. The connectivity is improved, since the original dense and symmetric connectivity of a standard recurrent network becomes sparse and asymmetric at the cell-to-cell level. Our simulations show that this kind of network, with model neurons of the Hodgkin-Huxley type arranged in columns, can operate as an associative memory in much the same way as previous models having simpler connectivity. The network shows attractor-like behaviour and performs the standard assembly operations despite differences in the dynamics introduced by the more detailed cell model and network structure. Furthermore, the model has become sufficiently detailed to allow evaluation against electrophysiological and anatomical observations. For instance, cell activities comply with experimental findings and reaction times are within biological and psychological ranges. By introducing a scaling model we demonstrate that a network approaching experimentally reported neuron numbers and synaptic distributions also could work like the model studied here.},
	number = {2},
	journal = {Network},
	author = {Fransen, Erik and Lansner, Anders},
	month = may,
	year = {1998},
	keywords = {merged\_fiete.bib},
	pages = {235--264},
}

@article{amari_characteristics_1971,
	title = {Characteristics of {Randomly} {Connected} {Threshold}-{Element} {Networks} and {Network} {Systems}},
	volume = {59},
	abstract = {The characteristics of the networks which are composed of many randomly connected threshold elements are investigated with the intention of understanding some aspects of information processing in nervous systems. In these networks, the statistical properties of connection are sufficient to determine the characteristics. Information is carried by the activity level of a network which designates the rate of exciting elements. Dynamics of the activity level is studied. Two statistical parameters, which are sufficient to determine the characteristics of networks, are extracted and the networks are categorized into three classes by these parameters. One is monostable, having only one stable activity level. Another is monostable or bistable according to the average threshold value of the elements. The third is astable or monostable. The characteristics of these three kinds of networks are analyzed in detail. Various systems can be obtained by connecting random networks, where the average thresholds of component networks can be controlled by other networks. The system performances are given. A stable oscillation of a long period is shown to exist in a system composed of two kinds of elements, i.e., excitatory and inhibitory elements, by randomly connecting them. A model for association of ideas is presented.},
	number = {1},
	journal = {Proc. IEEE},
	author = {Amari, Shun-Ichi},
	month = jan,
	year = {1971},
	keywords = {merged\_fiete.bib},
	pages = {35--47},
}

@article{tovee_information_1993,
	title = {Information encoding and the responses of single neurons in the primate temporal visual cortex},
	volume = {70},
	abstract = {1. The possibility of temporal encoding in the spike trains of single neurons recorded in the temporal lobe visual cortical areas of rhesus macaques was analyzed with the use of principal component and information theory analyses of smoothed spike trains. The neurons analyzed had responses selective for faces. 2. Provided that a correction was applied to earlier methods of principal component analysis used for neuronal spike trains, it was shown that the first principal component provides by a great extent the most information, with the second and third adding only small proportions (on average 18.8 and 8.4\%, respectively). 3. It was shown that the magnitude of the second and higher principal components is even smaller if the spike train analysis is started after the onset of the neuronal response, instead of before the neuronal response has started. This suggests that variations in response latency are at least a part of what is reflected by the second and higher principal components. 4. The first principal component was correlated with the mean firing rate of the neurons. The second and higher principal components reflected at least partly the onset properties of the neuronal responses, such as response latency differences between the stimuli. 5. A considerable proportion of the information available from principal components 1-3 is available in the firing rate of the neuron. 6. Periods of the firing rate of as little as 50 or even 20 ms are sufficient to give a reasonable estimate of the firing rate of the neuron. 7. Information theory analysis showed that in short epochs (e.g., 50 ms) the information available from the firing rate can be as high, on average, as 84.4\% of that available from the firing rate calculated over 400 ms, and 52.0\% of that available from principal components 1-3 in the 400-ms period. It was also found that 44.0\% of the information calculated from the first three principal components is available in the firing rates calculated over epochs as short as 20 ms. 8. More information was available near the start of the neuronal response, and the information available from short epochs became less later in the neuronal response. 9. Taken together, these analyses provide evidence that a short period of firing taken close to the start of the neuronal response provides a reasonable proportion of the total information that would be available if a long period of neuronal firing (e.g., 400 ms) were utilized to extract it, even if temporal encoding were used.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Tovée, M J and Rolls, E T and Treves, A and Bellis, R P},
	month = aug,
	year = {1993},
	keywords = {merged\_fiete.bib},
	pages = {640--654},
}

@article{rolls_processing_1994,
	title = {Processing speed in the cerebral cortex and the neurophysiology of visual masking},
	volume = {257},
	abstract = {In experiments to investigate the duration of the time for which cortical neurons respond when the identification of a visual stimulus is just possible, we presented a test face stimulus for 16 ms, and followed it at different intervals by a masking stimulus (either an N-O pattern or a face) while recording from single neurons in the temporal visual cortex of macaques. When there was no mask the cells responded to the 16 ms of the test stimulus for 200-300 ms, far longer than the presentation time. We suggest that this reflects the operation of a short-term memory system implemented in cortical circuitry. If the mask was a stimulus which did not stimulate the cells (either a non-face pattern or a face which was a non-effective stimulus for that cell), then, as the interval between the onset of the test stimulus and the onset of the mask stimulus (the stimulus onset asynchrony) was reduced, the length of time for which the cells fired in response to the test stimulus was reduced. It is suggested that this is due to the mask stimulating adjacent cells in the cortex which by lateral inhibition reduce the responses of the cells activated by the test stimulus. When the stimulus onset asynchrony was 20 ms, face-selective neurons in the inferior temporal cortex of macaques responded for a period of 20-30 ms before their firing was interrupted by the mask. With the same test-mask stimulus onset asynchrony of 20 ms, humans could just identify which of six faces was shown.(ABSTRACT TRUNCATED AT 250 WORDS)},
	number = {1348},
	journal = {Proc. Biol. Sci.},
	author = {Rolls, E T and Tovee, M J},
	month = jul,
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {9--15},
}

@article{rolls_responses_1994,
	title = {The responses of neurons in the temporal cortex of primates, and face identification and detection},
	volume = {101},
	abstract = {The ability of a human observer to detect the presence of a briefly flashed picture of a face can depend on the picture's spatial configuration, that is on whether its features are rearranged (jumbled) or are in their normal configuration. The face-detection effect (FDE) is found under conditions of backward masking, when the presence of a face can be detected with shorter masking intervals when it is in the normal than when in the rear-ranged configuration. A similar effect is found when the subject is asked to classify the face as rearranged or not - the face-classification effect (FCE). Part of the interest of the FDE and the FCE is that they show how the configuration of a stimulus can be an important factor in the perceptual processing which leads to detection and classification of the stimulus. To analyse these effects we recorded from single neurons in the cortex in the superior temporal sulcus of macaques when they were shown (in a visual fixation task) normal and rearranged faces under backward masking conditions shown in experiments 2 and 3 to produce, with the same apparatus, the FCE, and also to produce comparable effects on the identification of which face was present (called hereafter the face-identification effect), and also of the clarity of the face. We found in experiment 1 that there are some face-selective neurons which respond to faces only, or better, when the features in the faces are in their normal configuration rather than rearranged. We also showed in this experiment that the difference in the response to the normal as compared to the rearranged faces became greater when the masking stimulus was delayed more. Thus, at intermediate delays, there are more neurons active for the normal than for the rearranged face. We therefore propose that the FDE, the FCE, and the face-identification effect arise because the total number of neurons activated by faces in their normal configuration is greater than that activated by rearranged faces, because of the sensitivity of some face-selective neurons to the spatial arrangement of the features. The experiments also show that backward visual masking does produce abrupt termination of the firing of neurons in the temporal cortical visual system, so that the duration of a neuronal response is very short when visual stimuli can just be perceived.},
	number = {3},
	journal = {Exp. Brain Res.},
	author = {Rolls, E T and Tovee, M J and Purcell, D G and Stewart, A L and Azzopardi, P},
	year = {1994},
	keywords = {merged\_fiete.bib},
	pages = {473--484},
}

@inproceedings{trettel_phase_2012,
	title = {Phase precession through intrinsic neural resonance in continuous attractor models of grid cells},
	booktitle = {{CoSyNe} {Abstracts}},
	author = {Trettel, S and Buice, M A and Singh, A and Fiete, I R},
	year = {2012},
	keywords = {merged\_fiete.bib},
}

@article{tsodyks_population_1996,
	title = {Population dynamics and theta rhythm phase precession of hippocampal place cell firing: a spiking neuron model},
	volume = {6},
	abstract = {O'Keefe and Recce ([1993] Hippocampus 68:317-330) have observed that the spatially selective firing of pyramidal cells in the CA1 field of the rat hippocampus tends to advance to earlier phases of the electroencephalogram theta rhythm as a rat passes through the place field of a cell. We present here a neural network model based on integrate- and-fire neurons that accounts for this effect. In this model, place selectivity in the hippocampus is a consequence of synaptic interactions between pyramidal neurons together with weakly selective external input. The phase shift of neuronal spiking arises in the model as result of asymmetric spread of activation through the network, caused by asymmetry in the synaptic interactions. Several experimentally observed properties of the phase shift effect follow naturally from the model, including 1) the observation that the first spikes a cell fires appear near the theta phase corresponding to minimal population activity, 2) the overall advance is less than 360 degrees, and 3) the location of the rat within the place field of the cell is the primary correlate of the firing phase, not the time the rat has been in the field. The model makes several predictions concerning the emergence of place fields during the earliest stages of exploration in a novel environment. It also suggests new experiments that could provide further constraints on a possible explanation of the phase precession effect.},
	number = {3},
	journal = {Hippocampus},
	author = {Tsodyks, M V and Skaggs, W E and Sejnowski, T J and McNaughton, B L},
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {271--280},
}

@article{brown_statistical_1998,
	title = {A statistical paradigm for neural spike train decoding applied to position prediction from ensemble firing patterns of rat hippocampal place cells},
	volume = {18},
	abstract = {The problem of predicting the position of a freely foraging rat based on the ensemble firing patterns of place cells recorded from the CA1 region of its hippocampus is used to develop a two-stage statistical paradigm for neural spike train decoding. In the first, or encoding stage, place cell spiking activity is modeled as an inhomogeneous Poisson process whose instantaneous rate is a function of the animal's position in space and phase of its theta rhythm. The animal's path is modeled as a Gaussian random walk. In the second, or decoding stage, a Bayesian statistical paradigm is used to derive a nonlinear recursive causal filter algorithm for predicting the position of the animal from the place cell ensemble firing patterns. The algebra of the decoding algorithm defines an explicit map of the discrete spike trains into the position prediction. The confidence regions for the position predictions quantify spike train information in terms of the most probable locations of the animal given the ensemble firing pattern. Under our inhomogeneous Poisson model position was a three to five times stronger modulator of the place cell spiking activity than theta phase in an open circular environment. For animal 1 (2) the median decoding error based on 34 (33) place cells recorded during 10 min of foraging was 8.0 (7.7) cm. Our statistical paradigm provides a reliable approach for quantifying the spatial information in the ensemble place cell firing patterns and defines a generally applicable framework for studying information encoding in neural systems.},
	number = {18},
	journal = {J. Neurosci.},
	author = {Brown, E N and Frank, L M and Tang, D and Quirk, M C and Wilson, M A},
	month = sep,
	year = {1998},
	keywords = {merged\_fiete.bib, Non-programmatic},
	pages = {7411--7425},
}

@article{navratilova_experience-dependent_2012,
	title = {Experience-dependent firing rate remapping generates directional selectivity in hippocampal place cells},
	volume = {6},
	abstract = {When rodents engage in irregular foraging in an open-field environment, hippocampal principal cells exhibit place-specific firing that is statistically independent of the direction of traverse through the place field. When the path is restricted to a track, however, in-field rates differ substantially in opposite directions. Frequently, the representations of the track in the two directions are essentially orthogonal. We show that this directionally selective firing is not hard-wired, but develops through experience-dependent plasticity. During the rats' first pass in each direction, place fields were highly directionally symmetric, whereas over subsequent laps, the firing rates in the two directions gradually but substantially diverged. We conclude that, even on a restricted track, place cell firing is initially determined by allocentric position, and only later, the within-field firing rates change in response to differential sensory information or behavioral cues in the two directions. In agreement with previous data, place fields near local cues, such as textures on the track, developed less directionality than place fields on a uniform part of the track, possibly because the local cues reduced the net difference in sensory input at a given point. Directionality also developed in an open environment without physical restriction of the animal's path, when rats learned to run along a specified path. In this case, directionality developed later than on the running track, only after the rats began to run in a stereotyped manner. Although the average population firing rates exhibited little if any change over laps in either direction, the direction-specific firing rates in a given place field were up-or down-regulated with about equal probability and magnitude, which was independent in the two directions, suggesting some form of competitive mechanism (e.g., LTP/LTD) acting coherently on the set of synapses conveying external information to each cell.},
	journal = {Front. Neural Circuits},
	author = {Navratilova, Zaneta and Hoang, Lan T and Schwindel, C Daniela and Tatsuno, Masami and McNaughton, Bruce L},
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {6},
}

@article{tegner_dynamical_2002,
	title = {The dynamical stability of reverberatory neural circuits},
	volume = {87},
	abstract = {The concept of reverberation proposed by Lorente de Nó and Hebb is key to understanding strongly recurrent cortical networks. In particular, synaptic reverberation is now viewed as a likely mechanism for the active maintenance of working memory in the prefrontal cortex. Theoretically, this has spurred a debate as to how such a potentially explosive mechanism can provide stable working-memory function given the synaptic and cellular mechanisms at play in the cerebral cortex. We present here new evidence for the participation of NMDA receptors in the stabilization of persistent delay activity in a biophysical network model of conductance-based neurons. We show that the stability of working-memory function, and the required NMDA/AMPA ratio at recurrent excitatory synapses, depend on physiological properties of neurons and synaptic interactions, such as the time constants of excitation and inhibition, mutual inhibition between interneurons, differential NMDA receptor participation at excitatory projections to pyramidal neurons and interneurons, or the presence of slow intrinsic ion currents in pyramidal neurons. We review other mechanisms proposed to enhance the dynamical stability of synaptically generated attractor states of a reverberatory circuit. This recent work represents a necessary and significant step towards testing attractor network models by cortical electrophysiology.},
	number = {5-6},
	journal = {Biol. Cybern.},
	author = {Tegnér, Jesper and Compte, Albert and Wang, Xiao-Jing},
	month = dec,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {471--481},
}

@article{wong_recurrent_2006,
	title = {A recurrent network mechanism of time integration in perceptual decisions},
	volume = {26},
	abstract = {Recent physiological studies using behaving monkeys revealed that, in a two-alternative forced-choice visual motion discrimination task, reaction time was correlated with ramping of spike activity of lateral intraparietal cortical neurons. The ramping activity appears to reflect temporal accumulation, on a timescale of hundreds of milliseconds, of sensory evidence before a decision is reached. To elucidate the cellular and circuit basis of such integration times, we developed and investigated a simplified two-variable version of a biophysically realistic cortical network model of decision making. In this model, slow time integration can be achieved robustly if excitatory reverberation is primarily mediated by NMDA receptors; our model with only fast AMPA receptors at recurrent synapses produces decision times that are not comparable with experimental observations. Moreover, we found two distinct modes of network behavior, in which decision computation by winner-take-all competition is instantiated with or without attractor states for working memory. Decision process is closely linked to the local dynamics, in the “decision space” of the system, in the vicinity of an unstable saddle steady state that separates the basins of attraction for the two alternative choices. This picture provides a rigorous and quantitative explanation for the dependence of performance and response time on the degree of task difficulty, and the reason for which reaction times are longer in error trials than in correct trials as observed in the monkey experiment. Our reduced two-variable neural model offers a simple yet biophysically plausible framework for studying perceptual decision making in general.},
	number = {4},
	journal = {J. Neurosci.},
	author = {Wong, Kong-Fatt and Wang, Xiao-Jing},
	month = jan,
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {1314--1328},
}

@article{wang_decision_2008,
	title = {Decision making in recurrent neuronal circuits},
	volume = {60},
	abstract = {Decision making has recently emerged as a central theme in neurophysiological studies of cognition, and experimental and computational work has led to the proposal of a cortical circuit mechanism of elemental decision computations. This mechanism depends on slow recurrent synaptic excitation balanced by fast feedback inhibition, which not only instantiates attractor states for forming categorical choices but also long transients for gradually accumulating evidence in favor of or against alternative options. Such a circuit endowed with reward-dependent synaptic plasticity is able to produce adaptive choice behavior. While decision threshold is a core concept for reaction time tasks, it can be dissociated from a general decision rule. Moreover, perceptual decisions and value-based economic choices are described within a unified framework in which probabilistic choices result from irregular neuronal activity as well as iterative interactions of a decision maker with an uncertain environment or other unpredictable decision makers in a social group.},
	number = {2},
	journal = {Neuron},
	author = {Wang, Xiao-Jing},
	month = oct,
	year = {2008},
	keywords = {merged\_fiete.bib},
	pages = {215--234},
}

@article{hughes_absence_2009,
	title = {Absence seizures: a review of recent reports with new concepts},
	volume = {15},
	abstract = {Absence seizures with bilateral spike-wave (SW) complexes at 3Hz are divided into the childhood form, with onset at around 6 years of age, and the juvenile form, with onset usually at 12 years of age. These seizures typically last 9-12s and, at times, are activated by hyperventilation and occasionally by photic stimulation. Generalized tonic-clonic (GTC) seizures may also occur, especially in the juvenile form. There may be cognitive changes, in addition to linguistic and behavioral problems. Possible mechanisms for epileptogenesis may involve GABAergic systems, but especially T-calcium channels. The thalamus, especially the reticular nucleus, plays a major role, as does the frontal cortex, mainly the dorsolateral and orbital frontal areas, to the extent that some investigators have concluded that absence seizures are not truly generalized, but rather have selective cortical networks, mainly ventromesial frontal areas and the somatosensory cortex. The latter network is a departure from the more popular concept of a generalized epilepsy. Between the “centrencephalic” and “corticoreticular” theories, a “unified” theory is presented. Proposed genes include T-calcium channel gene CACNA1H, likely a susceptible gene in the Chinese Han population and a contributory gene in Caucasians. Electroencephalography has revealed an interictal increase in prefrontal activity, essential for the buildup of the ictal SW complexes maximal in that region. Infraslow activity can also be seen during ictal SW complexes. For treatment, counter to common belief, ethosuximide may not increase GTC seizures, as it reduces low-threshold T-calcium currents in thalamic neurons. Valproic acid and lamotrigine are also first-line medications. In addition, zonisamide and levetiracetam can be very helpful in absence epilepsy.},
	number = {4},
	journal = {Epilepsy Behav.},
	author = {Hughes, John R},
	month = aug,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {404--412},
}

@article{crunelli_childhood_2002,
	title = {Childhood absence epilepsy: genes, channels, neurons and networks},
	volume = {3},
	abstract = {Childhood absence epilepsy is an idiopathic, generalized non-convulsive epilepsy with a multifactorial genetic aetiology. Molecular-genetic analyses of affected human families and experimental models, together with neurobiological investigations, have led to important breakthroughs in the identification of candidate genes and loci, and potential pathophysiological mechanisms for this type of epilepsy. Here, we review these results, and compare the human and experimental phenotypes that have been investigated. Continuing efforts and comparisons of this type will help us to elucidate the multigenetic traits and pathophysiology of this form of generalized epilepsy.},
	number = {5},
	journal = {Nat. Rev. Neurosci.},
	author = {Crunelli, Vincenzo and Leresche, Nathalie},
	month = may,
	year = {2002},
	keywords = {merged\_fiete.bib},
	pages = {371--382},
}

@article{butts_tuning_2006,
	title = {Tuning curves, neuronal variability, and sensory coding},
	volume = {4},
	abstract = {Tuning curves are widely used to characterize the responses of sensory neurons to external stimuli, but there is an ongoing debate as to their role in sensory processing. Commonly, it is assumed that a neuron's role is to encode the stimulus at the tuning curve peak, because high firing rates are the neuron's most distinct responses. In contrast, many theoretical and empirical studies have noted that nearby stimuli are most easily discriminated in high-slope regions of the tuning curve. Here, we demonstrate that both intuitions are correct, but that their relative importance depends on the experimental context and the level of variability in the neuronal response. Using three different information-based measures of encoding applied to experimentally measured sensory neurons, we show how the best-encoded stimulus can transition from high-slope to high-firing-rate regions of the tuning curve with increasing noise level. We further show that our results are consistent with recent experimental findings that correlate neuronal sensitivities with perception and behavior. This study illustrates the importance of the noise level in determining the encoding properties of sensory neurons and provides a unified framework for interpreting how the tuning curve and neuronal variability relate to the overall role of the neuron in sensory encoding.},
	number = {4},
	journal = {PLoS Biol.},
	author = {Butts, Daniel A and Goldman, Mark S},
	month = apr,
	year = {2006},
	keywords = {merged\_fiete.bib},
	pages = {e92},
}

@article{ozeki_inhibitory_2009,
	title = {Inhibitory stabilization of the cortical network underlies visual surround suppression},
	volume = {62},
	abstract = {In what regime does the cortical circuit operate? Our intracellular studies of surround suppression in cat primary visual cortex (V1) provide strong evidence on this question. Although suppression has been thought to arise from an increase in lateral inhibition, we find that the inhibition that cells receive is reduced, not increased, by a surround stimulus. Instead, suppression is mediated by a withdrawal of excitation. Thalamic recordings and previous work show that these effects cannot be explained by a withdrawal of thalamic input. We find in theoretical work that this behavior can only arise if V1 operates as an inhibition-stabilized network (ISN), in which excitatory recurrence alone is strong enough to destabilize visual responses but feedback inhibition maintains stability. We confirm two strong tests of this scenario experimentally and show through simulation that observed cell-to-cell variability in surround effects, from facilitation to suppression, can arise naturally from variability in the ISN.},
	number = {4},
	journal = {Neuron},
	author = {Ozeki, Hirofumi and Finn, Ian M and Schaffer, Evan S and Miller, Kenneth D and Ferster, David},
	month = may,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {578--592},
}

@article{litvak_transmission_2003,
	title = {On the transmission of rate code in long feedforward networks with excitatory-inhibitory balance},
	volume = {23},
	abstract = {The capability of feedforward networks composed of multiple layers of integrate-and-fire neurons to transmit rate code was examined. Synaptic connections were made only from one layer to the next, and excitation was balanced by inhibition. When time is discrete and the synaptic potentials rise instantaneously, we show that, for random uncorrelated input to layer one, the mean rate of activity in deep layers is essentially independent of input firing rate. This implies that the input rate cannot be transmitted reliably in such feedforward networks because neurons in a given layer tend to synchronize partially with each other because of shared inputs. As a result of this synchronization, the average firing rate in deep layers will either decay to zero or reach a stable fixed point, depending on model parameters. When time is treated continuously and the synaptic potentials rise instantaneously, these effects develop slowly, and rate transmission over a limited number of layers is possible. However, the correlations among neurons at the same layer hamper reliable assessment of firing rate by averaging over 100 msec (or less). When the synaptic potentials develop gradually, as is the realistic case, transmission of rate code fails. In a network in which inhibition only balances the mean excitation but is not timed precisely with it, neurons in each layer fire together, and this volley successively propagates from layer to layer. We conclude that the transmission of rate code in feedforward networks is highly unlikely.},
	number = {7},
	journal = {J. Neurosci.},
	author = {Litvak, Vladimir and Sompolinsky, Haim and Segev, Idan and Abeles, Moshe},
	month = apr,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {3006--3015},
}

@article{van_vreeswijk_chaos_1996,
	title = {Chaos in neuronal networks with balanced excitatory and inhibitory activity},
	volume = {274},
	abstract = {Neurons in the cortex of behaving animals show temporally irregular spiking patterns. The origin of this irregularity and its implications for neural processing are unknown. The hypothesis that the temporal variability in the firing of a neuron results from an approximate balance between its excitatory and inhibitory inputs was investigated theoretically. Such a balance emerges naturally in large networks of excitatory and inhibitory neuronal populations that are sparsely connected by relatively strong synapses. The resulting state is characterized by strongly chaotic dynamics, even when the external inputs to the network are constant in time. Such a network exhibits a linear response, despite the highly nonlinear dynamics of single neurons, and reacts to changing external stimuli on time scales much smaller than the integration time constant of a single neuron.},
	number = {5293},
	journal = {Science},
	author = {van Vreeswijk, C and Sompolinsky, H},
	month = dec,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {1724--1726},
}

@article{beck_insights_2011,
	title = {Insights from a simple expression for linear fisher information in a recurrently connected population of spiking neurons},
	volume = {23},
	abstract = {A simple expression for a lower bound of Fisher information is derived for a network of recurrently connected spiking neurons that have been driven to a noise-perturbed steady state. We call this lower bound linear Fisher information, as it corresponds to the Fisher information that can be recovered by a locally optimal linear estimator. Unlike recent similar calculations, the approach used here includes the effects of nonlinear gain functions and correlated input noise and yields a surprisingly simple and intuitive expression that offers substantial insight into the sources of information degradation across successive layers of a neural network. Here, this expression is used to (1) compute the optimal (i.e., information-maximizing) firing rate of a neuron, (2) demonstrate why sharpening tuning curves by either thresholding or the action of recurrent connectivity is generally a bad idea, (3) show how a single cortical expansion is sufficient to instantiate a redundant population code that can propagate across multiple cortical layers with minimal information loss, and (4) show that optimal recurrent connectivity strongly depends on the covariance structure of the inputs to the network.},
	number = {6},
	journal = {Neural Comput.},
	author = {Beck, Jeffrey and Bejjanki, Vikranth R and Pouget, Alexandre},
	month = jun,
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {1484--1502},
}

@article{markram_redistribution_1996,
	title = {Redistribution of synaptic efficacy between neocortical pyramidal neurons},
	volume = {382},
	abstract = {Experience-dependent potentiation and depression of synaptic strength has been proposed to subserve learning and memory by changing the gain of signals conveyed between neurons. Here we examine synaptic plasticity between individual neocortical layer-5 pyramidal neurons. We show that an increase in the synaptic response, induced by pairing action-potential activity in pre- and postsynaptic neurons, was only observed when synaptic input occurred at low frequencies. This frequency-dependent increase in synaptic responses arises because of a redistribution of the available synaptic efficacy and not because of an increase in the efficacy. Redistribution of synaptic efficacy could represent a mechanism to change the content, rather than the gain, of signals conveyed between neurons.},
	number = {6594},
	journal = {Nature},
	author = {Markram, H and Tsodyks, M},
	month = aug,
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {807--810},
}

@article{markram_redistribution_1996-1,
	title = {Redistribution of synaptic efficacy: a mechanism to generate infinite synaptic input diversity from a homogeneous population of neurons without changing absolute synaptic efficacies},
	volume = {90},
	abstract = {Changing the reliability of neurotransmitter release results in a change in the efficacy of low frequency synaptic transmission and in the rate of high frequency synaptic depression thus it can not cause an uniform change in strength of synapses and instead results in a change in the dynamics of synaptic transmission referred to as 'redistribution of synaptic efficacy' (RSE). Since the change in synaptic transmission associated with RSE depends on the history of action potential activity it is concluded that RSE serves as a mechanism to generate a potentially infinite diversity of synaptic input.},
	number = {3-4},
	journal = {J. Physiol. Paris},
	author = {Markram, H and Tsodyks, M},
	year = {1996},
	keywords = {merged\_fiete.bib},
	pages = {229--232},
}

@article{series_tuning_2004,
	title = {Tuning curve sharpening for orientation selectivity: coding efficiency and the impact of correlations},
	volume = {7},
	abstract = {Several studies have shown that the information conveyed by bell-shaped tuning curves increases as their width decreases, leading to the notion that sharpening of tuning curves improves population codes. This notion, however, is based on assumptions that the noise distribution is independent among neurons and independent of the tuning curve width. Here we reexamine these assumptions in networks of spiking neurons by using orientation selectivity as an example. We compare two principal classes of model: one in which the tuning curves are sharpened through cortical lateral interactions, and one in which they are not. We report that sharpening through lateral interactions does not improve population codes but, on the contrary, leads to a severe loss of information. In addition, the sharpening models generate complicated codes that rely extensively on pairwise correlations. Our study generates several experimental predictions that can be used to distinguish between these two classes of model.},
	number = {10},
	journal = {Nat. Neurosci.},
	author = {Seriès, Peggy and Latham, Peter E and Pouget, Alexandre},
	month = oct,
	year = {2004},
	keywords = {merged\_fiete.bib},
	pages = {1129--1135},
}

@article{buice_field-theoretic_2007,
	title = {Field-theoretic approach to fluctuation effects in neural networks},
	volume = {75},
	abstract = {A well-defined stochastic theory for neural activity, which permits the calculation of arbitrary statistical moments and equations governing them, is a potentially valuable tool for theoretical neuroscience. We produce such a theory by analyzing the dynamics of neural activity using field theoretic methods for nonequilibrium statistical processes. Assuming that neural network activity is Markovian, we construct the effective spike model, which describes both neural fluctuations and response. This analysis leads to a systematic expansion of corrections to mean field theory, which for the effective spike model is a simple version of the Wilson-Cowan equation. We argue that neural activity governed by this model exhibits a dynamical phase transition which is in the universality class of directed percolation. More general models (which may incorporate refractoriness) can exhibit other universality classes, such as dynamic isotropic percolation. Because of the extremely high connectivity in typical networks, it is expected that higher-order terms in the systematic expansion are small for experimentally accessible measurements, and thus, consistent with measurements in neocortical slice preparations, we expect mean field exponents for the transition. We provide a quantitative criterion for the relative magnitude of each term in the systematic expansion, analogous to the Ginsburg criterion. Experimental identification of dynamic universality classes in vivo is an outstanding and important question for neuroscience.},
	number = {5 Pt 1},
	journal = {Phys. Rev. E Stat. Nonlin. Soft Matter Phys.},
	author = {Buice, Michael A and Cowan, Jack D},
	month = may,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {051919},
}

@article{buice_statistical_2009,
	title = {Statistical mechanics of the neocortex},
	volume = {99},
	abstract = {We analyze neocortical dynamics using field theoretic methods for non-equilibrium statistical processes. Assuming the dynamics is Markovian, we introduce a model that describes both neural fluctuations and responses to stimuli. We show that at low spiking rates, neocortical activity exhibits a dynamical phase transition which is in the universality class of directed percolation (DP). Because of the high density and large spatial extent of neural interactions, there is a “mean field” region in which the effects of fluctuations are negligible. However as the generation and decay of spiking activity becomes balanced, there is a crossover into the critical fluctuation driven DP region, consistent with measurements in neocortical slice preparations. From the perspective of theoretical neuroscience, the principal contribution of this work is the formulation of a theory of neural activity that goes beyond the mean-field approximation and incorporates the effects of fluctuations and correlations in the critical region. This theory shows that the scaling laws found in many measurements of neocortical activity, in anesthetized, normal and epileptic neocortex, are consistent with the existence of DP and related phase transitions at a critical point. It also shows how such properties lead to a model of the origins of both random and rhythmic brain activity.},
	number = {2-3},
	journal = {Prog. Biophys. Mol. Biol.},
	author = {Buice, Michael A and Cowan, Jack D},
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {53--86},
}

@article{buice_systematic_2010,
	title = {Systematic fluctuation expansion for neural network activity equations},
	volume = {22},
	abstract = {Population rate or activity equations are the foundation of a common approach to modeling for neural networks. These equations provide mean field dynamics for the firing rate or activity of neurons within a network given some connectivity. The shortcoming of these equations is that they take into account only the average firing rate, while leaving out higher-order statistics like correlations between firing. A stochastic theory of neural networks that includes statistics at all orders was recently formulated. We describe how this theory yields a systematic extension to population rate equations by introducing equations for correlations and appropriate coupling terms. Each level of the approximation yields closed equations; they depend only on the mean and specific correlations of interest, without an ad hoc criterion for doing so. We show in an example of an all-to-all connected network how our system of generalized activity equations captures phenomena missed by the mean field rate equations alone.},
	number = {2},
	journal = {Neural Comput.},
	author = {Buice, Michael A and Cowan, Jack D and Chow, Carson C},
	month = feb,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {377--426},
}

@article{ringach_dynamics_1997,
	title = {Dynamics of orientation tuning in macaque primary visual cortex},
	volume = {387},
	abstract = {Orientation tuning of neurons is one of the chief emergent characteristics of the primary visual cortex, V1. Neurons of the lateral geniculate nucleus, which comprise the thalamic input to V1, are not orientation-tuned, but the majority of V1 neurons are quite selective. How orientation tuning arises within V1 is still controversial. To study this problem, we measured how the orientation tuning of neurons evolves with time using a new method: reverse correlation in the orientation domain. Orientation tuning develops after a delay of 30-45 milliseconds and persists for 40-85 ms. Neurons in layers 4C alpha or 4C beta, which receive direct input from the thalamus, show a single orientation preference which remains unchanged throughout the response period. In contrast, the preferred orientations of output layer neurons (in layers 2, 3, 4B, 5 or 6) usually change with time, and in many cases the orientation tuning may have more than one peak. This difference in dynamics is accompanied by a change in the sharpness of orientation tuning; cells in the input layers are more broadly tuned than cells in the output layers. Many of these observed properties of output layer neurons cannot be explained by simple feedforward models, whereas they arise naturally in feedback networks. Our results indicate that V1 is more than a bank of static oriented filters; the dynamics of output layer cells appear to be shaped by intracortical feedback.},
	number = {6630},
	journal = {Nature},
	author = {Ringach, D L and Hawken, M J and Shapley, R},
	month = may,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {281--284},
}

@article{carandini_predictions_1997,
	title = {Predictions of a recurrent model of orientation selectivity},
	volume = {37},
	abstract = {Recurrent models of orientation selectivity in the visual cortex postulate that an initially broad tuning given by the pattern of geniculate afferents is substantially sharpened by intracortical feedback. We show that these models can be tested on the basis of their predicted responses to certain visual stimuli, without the need for pharmacological or physiological manipulations. First, we consider a detailed recurrent model proposed by Somers, Nelson and Sur [(1995) Journal of Neuroscience, 15, 5448-5465] and show that it can be simplified to a single equation: a center-surround feedback filter in the orientation domain. Then, we explore the responses of the simplified model to stimuli containing two or more orientations. We find that the model exhibits peculiar responses to stimuli containing two orientations, such as plaids or crosses: if the component orientations differ by less than 45 deg the model cannot distinguish between them; if the orientations differ by more than 45 deg the model overestimates their angle by as much as 30 deg. Moreover, the model cannot signal the presence of three orientations separated by 60 deg (it responds as if there were only two orientations), and the addition of two-dimensional visual noise to an oriented stimulus results in strong spurious responses at the orthogonal orientation. We argue that the effects of attraction and repulsion between orientations and the emergence of responses at off-optimal orientations are common to a wide class of feedback models of orientation selectivity. These models could thus be tested by measuring the visual responses of cortical neurons to stimuli containing multiple orientations.},
	number = {21},
	journal = {Vision Res.},
	author = {Carandini, M and Ringach, D L},
	month = nov,
	year = {1997},
	keywords = {merged\_fiete.bib},
	pages = {3061--3071},
}

@article{aksay_correlated_2003,
	title = {Correlated discharge among cell pairs within the oculomotor horizontal velocity-to-position integrator},
	volume = {23},
	abstract = {In the oculomotor system, temporal integration of velocity commands into position signals may depend on synaptic feedback among neurons of a bilateral brainstem cell assembly known as the “neural integrator.” Both ipsilateral excitatory and contralateral inhibitory projections between eye position-related integrator cells are hypothesized as a substrate for positive feedback supporting integration. Presence of feedback interactions should be evident in cross-correlation functions of neuron pairs. Here, unilateral and bilateral paired recordings were obtained during fixation behavior from neurons in goldfish brainstem area I, a key element of the integrator. During fixations, discharge of most unilateral pairs, composed of cells with eye position sensitivities of the same sign, was positively correlated with lag of 0-10 msec (n = 11 of 14 significant). Typically, a very narrow peak (mean half-width {\textless}4 msec) near zero lag was observed. Discharge of bilateral pairs, composed of cells with position sensitivities of the opposite sign, was either negatively correlated with lag of 0-10 msec (n = 5 of 13 significant) or not correlated. Troughs in negative correlations always had minima between 3 and 5 msec lag. These results are consistent with the feedback hypothesis of temporal integration, highlighting excitation unilaterally and inhibition bilaterally. Absence of visual input did not weaken correlations, but other sources of correlated input extrinsic to area I were not ruled out. Triplet recordings revealed that unilateral pairwise correlations were primarily independent. Correlation between unilateral pairs systematically decreased with increasing eye position, demonstrating that synchrony is not necessary for persistent activity at high firing rates.},
	number = {34},
	journal = {J. Neurosci.},
	author = {Aksay, Emre and Baker, Robert and Seung, H Sebastian and Tank, David W},
	month = nov,
	year = {2003},
	keywords = {merged\_fiete.bib},
	pages = {10852--10858},
}

@article{levine_quasicrystals_1986,
	title = {Quasicrystals. {I}. {Definition} and structure},
	volume = {34},
	number = {2},
	journal = {Phys. Rev. B Condens. Matter},
	author = {Levine, D and Steinhardt, P J},
	year = {1986},
	keywords = {merged\_fiete.bib},
	pages = {596--616},
}

@article{renart_mean-driven_2007,
	title = {Mean-driven and fluctuation-driven persistent activity in recurrent networks},
	volume = {19},
	abstract = {Spike trains from cortical neurons show a high degree of irregularity, with coefficients of variation (CV) of their interspike interval (ISI) distribution close to or higher than one. It has been suggested that this irregularity might be a reflection of a particular dynamical state of the local cortical circuit in which excitation and inhibition balance each other. In this “balanced” state, the mean current to the neurons is below threshold, and firing is driven by current fluctuations, resulting in irregular Poisson-like spike trains. Recent data show that the degree of irregularity in neuronal spike trains recorded during the delay period of working memory experiments is the same for both low-activity states of a few Hz and for elevated, persistent activity states of a few tens of Hz. Since the difference between these persistent activity states cannot be due to external factors coming from sensory inputs, this suggests that the underlying network dynamics might support coexisting balanced states at different firing rates. We use mean field techniques to study the possible existence of multiple balanced steady states in recurrent networks of current-based leaky integrate-and-fire (LIF) neurons. To assess the degree of balance of a steady state, we extend existing mean-field theories so that not only the firing rate, but also the coefficient of variation of the interspike interval distribution of the neurons, are determined self-consistently. Depending on the connectivity parameters of the network, we find bistable solutions of different types. If the local recurrent connectivity is mainly excitatory, the two stable steady states differ mainly in the mean current to the neurons. In this case, the mean drive in the elevated persistent activity state is suprathreshold and typically characterized by low spiking irregularity. If the local recurrent excitatory and inhibitory drives are both large and nearly balanced, or even dominated by inhibition, two stable states coexist, both with subthreshold current drive. In this case, the spiking variability in both the resting state and the mnemonic persistent state is large, but the balance condition implies parameter fine-tuning. Since the degree of required fine-tuning increases with network size and, on the other hand, the size of the fluctuations in the afferent current to the cells increases for small networks, overall we find that fluctuation-driven persistent activity in the very simplified type of models we analyze is not a robust phenomenon. Possible implications of considering more realistic models are discussed.},
	number = {1},
	journal = {Neural Comput.},
	author = {Renart, Alfonso and Moreno-Bote, Rubén and Wang, Xiao-Jing and Parga, Néstor},
	month = jan,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {1--46},
}

@article{ecker_decorrelated_2010,
	title = {Decorrelated neuronal firing in cortical microcircuits},
	volume = {327},
	abstract = {Correlated trial-to-trial variability in the activity of cortical neurons is thought to reflect the functional connectivity of the circuit. Many cortical areas are organized into functional columns, in which neurons are believed to be densely connected and to share common input. Numerous studies report a high degree of correlated variability between nearby cells. We developed chronically implanted multitetrode arrays offering unprecedented recording quality to reexamine this question in the primary visual cortex of awake macaques. We found that even nearby neurons with similar orientation tuning show virtually no correlated variability. Our findings suggest a refinement of current models of cortical microcircuit architecture and function: Either adjacent neurons share only a few percent of their inputs or, alternatively, their activity is actively decorrelated.},
	number = {5965},
	journal = {Science},
	author = {Ecker, Alexander S and Berens, Philipp and Keliris, Georgios A and Bethge, Matthias and Logothetis, Nikos K and Tolias, Andreas S},
	month = jan,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {584--587},
}

@article{renart_asynchronous_2010,
	title = {The asynchronous state in cortical circuits},
	volume = {327},
	abstract = {Correlated spiking is often observed in cortical circuits, but its functional role is controversial. It is believed that correlations are a consequence of shared inputs between nearby neurons and could severely constrain information decoding. Here we show theoretically that recurrent neural networks can generate an asynchronous state characterized by arbitrarily low mean spiking correlations despite substantial amounts of shared input. In this state, spontaneous fluctuations in the activity of excitatory and inhibitory populations accurately track each other, generating negative correlations in synaptic currents which cancel the effect of shared input. Near-zero mean correlations were seen experimentally in recordings from rodent neocortex in vivo. Our results suggest a reexamination of the sources underlying observed correlations and their functional consequences for information processing.},
	number = {5965},
	journal = {Science},
	author = {Renart, Alfonso and de la Rocha, Jaime and Bartho, Peter and Hollender, Liad and Parga, Néstor and Reyes, Alex and Harris, Kenneth D},
	month = jan,
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {587--590},
}

@article{de_la_rocha_correlation_2007,
	title = {Correlation between neural spike trains increases with firing rate},
	volume = {448},
	abstract = {Populations of neurons in the retina, olfactory system, visual and somatosensory thalamus, and several cortical regions show temporal correlation between the discharge times of their action potentials (spike trains). Correlated firing has been linked to stimulus encoding, attention, stimulus discrimination, and motor behaviour. Nevertheless, the mechanisms underlying correlated spiking are poorly understood, and its coding implications are still debated. It is not clear, for instance, whether correlations between the discharges of two neurons are determined solely by the correlation between their afferent currents, or whether they also depend on the mean and variance of the input. We addressed this question by computing the spike train correlation coefficient of unconnected pairs of in vitro cortical neurons receiving correlated inputs. Notably, even when the input correlation remained fixed, the spike train output correlation increased with the firing rate, but was largely independent of spike train variability. With a combination of analytical techniques and numerical simulations using 'integrate-and-fire' neuron models we show that this relationship between output correlation and firing rate is robust to input heterogeneities. Finally, this overlooked relationship is replicated by a standard threshold-linear model, demonstrating the universality of the result. This connection between the rate and correlation of spiking activity links two fundamental features of the neural code.},
	number = {7155},
	journal = {Nature},
	author = {de la Rocha, Jaime and Doiron, Brent and Shea-Brown, Eric and Josić, Kresimir and Reyes, Alex},
	month = aug,
	year = {2007},
	keywords = {merged\_fiete.bib},
	pages = {802--806},
}

@article{josic_stimulus-dependent_2009,
	title = {Stimulus-dependent correlations and population codes},
	volume = {21},
	abstract = {The magnitude of correlations between stimulus-driven responses of pairs of neurons can itself be stimulus dependent. We examine how this dependence affects the information carried by neural populations about the stimuli that drive them. Stimulus-dependent changes in correlations can both carry information directly and modulate the information separately carried by the firing rates and variances. We use Fisher information to quantify these effects and show that, although stimulus-dependent correlations often carry little information directly, their modulatory effects on the overall information can be large. In particular, if the stimulus dependence is such that correlations increase with stimulus-induced firing rates, this can significantly enhance the information of the population when the structure of correlations is determined solely by the stimulus. However, in the presence of additional strong spatial decay of correlations, such stimulus dependence may have a negative impact. Opposite relationships hold when correlations decrease with firing rates.},
	number = {10},
	journal = {Neural Comput.},
	author = {Josić, Kresimir and Shea-Brown, Eric and Doiron, Brent and de la Rocha, Jaime},
	month = oct,
	year = {2009},
	keywords = {merged\_fiete.bib},
	pages = {2774--2804},
}

@article{middleton_neural_2012,
	title = {Neural correlation is stimulus modulated by feedforward inhibitory circuitry},
	volume = {32},
	abstract = {Correlated variability of neural spiking activity has important consequences for signal processing. How incoming sensory signals shape correlations of population responses remains unclear. Cross-correlations between spiking of different neurons may be particularly consequential in sparsely firing neural populations such as those found in layer 2/3 of sensory cortex. In rat whisker barrel cortex, we found that pairs of excitatory layer 2/3 neurons exhibit similarly low levels of spike count correlation during both spontaneous and sensory-evoked states. The spontaneous activity of excitatory-inhibitory neuron pairs is positively correlated, while sensory stimuli actively decorrelate joint responses. Computational modeling shows how threshold nonlinearities and local inhibition form the basis of a general decorrelating mechanism. We show that inhibitory population activity maintains low correlations in excitatory populations, especially during periods of sensory-evoked coactivation. The role of feedforward inhibition has been previously described in the context of trial-averaged phenomena. Our findings reveal a novel role for inhibition to shape correlations of neural variability and thereby prevent excessive correlations in the face of feedforward sensory-evoked activation.},
	number = {2},
	journal = {J. Neurosci.},
	author = {Middleton, Jason W and Omar, Cyrus and Doiron, Brent and Simons, Daniel J},
	month = jan,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {506--518},
}

@article{polk_correlated_2012,
	title = {Correlated neural variability in persistent state networks},
	volume = {109},
	abstract = {Neural activity that persists long after stimulus presentation is a biological correlate of short-term memory. Variability in spiking activity causes persistent states to drift over time, ultimately degrading memory. Models of short-term memory often assume that the input fluctuations to neural populations are independent across cells, a feature that attenuates population-level variability and stabilizes persistent activity. However, this assumption is at odds with experimental recordings from pairs of cortical neurons showing that both the input currents and output spike trains are correlated. It remains unclear how correlated variability affects the stability of persistent activity and the performance of cognitive tasks that it supports. We consider the stochastic long-timescale attractor dynamics of pairs of mutually inhibitory populations of spiking neurons. In these networks, persistent activity was less variable when correlated variability was globally distributed across both populations compared with the case when correlations were locally distributed only within each population. Using a reduced firing rate model with a continuum of persistent states, we show that, when input fluctuations are correlated across both populations, they drive firing rate fluctuations orthogonal to the persistent state attractor, thereby causing minimal stochastic drift. Using these insights, we establish that distributing correlated fluctuations globally as opposed to locally improves network's performance on a two-interval, delayed response discrimination task. Our work shows that the correlation structure of input fluctuations to a network is an important factor when determining long-timescale, persistent population spiking activity.},
	number = {16},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Polk, Amber and Litwin-Kumar, Ashok and Doiron, Brent},
	month = apr,
	year = {2012},
	keywords = {merged\_fiete.bib},
	pages = {6295--6300},
}

@article{da_costa_whose_2010,
	title = {Whose {Cortical} {Column} {Would} that {Be}?},
	volume = {4},
	abstract = {The cortical column has been an invaluable concept to explain the functional organization of the neocortex. While this idea was born out of experiments that cleverly combined electrophysiological recordings with anatomy, no one has 'seen' the anatomy of a column. All we know is that when we record through the cortex of primates, ungulates, and carnivores in a trajectory perpendicular to its surface there is a remarkable constancy in the receptive field properties of the neurons regarding one set of stimulus features. There is no obvious morphological analog for this functional architecture, in fact much of the anatomical data seems to challenge it. Here we describe historically the origins of the concept of the cortical column and the struggles of the pioneers to define the columnar architecture. We suggest that in the concept of a 'canonical circuit' we may find the means to reconcile the structure of neocortex with its functional architecture. The canonical microcircuit respects the known connectivity of the neocortex, and it is flexible enough to change transiently the architecture of its network in order to perform the required computations.},
	journal = {Front. Neuroanat.},
	author = {da Costa, Nuno Maçarico and Martin, Kevan A C},
	year = {2010},
	keywords = {merged\_fiete.bib},
	pages = {16},
}

@article{douglas_functional_1991,
	title = {A functional microcircuit for cat visual cortex},
	volume = {440},
	abstract = {1. We have studied in vivo the intracellular responses of neurones in cat visual cortex to electrical pulse stimulation of the cortical afferents and have developed a microcircuit that simulates much of the experimental data. 2. Inhibition and excitation are not separable events, because individual neurones are embedded in microcircuits that contribute strong population effects. Synchronous electrical activation of the cortex inevitably set in motion a sequence of excitation and inhibition in every neurone we recorded. The temporal form of this response depends on the cortical layer in which the neurone is located. Superficial layer (layers 2+3) pyramidal neurones show a more marked polysynaptic excitatory phase than the pyramids of the deep layers (layers 5+6). 3. Excitatory effects on pyramidal neurones, particularly the superficial layer pyramids, are in general not due to monosynaptic input from thalamus, but polysynaptic input from cortical pyramids. Since the thalamic input is transient it does not provide the major, sustained excitation arriving at any cortical neurone. Instead the intracortical excitatory connections provide the major component of the excitation. 4. The polysynaptic excitatory response would be sustained well after the stimulus, were it not for the suppressive effect of intracortical inhibition induced by the pulse stimulation. 5. Intracellular recording combined with ionophoresis of gamma-aminobutyric acid (GABA) agonists and antagonists showed that intracortical inhibition is mediated by GABAA and GABAB receptors. The GABAA component occurs in the early phase of the impulse response. It is reflected in the strong hyperpolarization that follows the excitatory response and lasts about 50 ms. The GABAB component occurs in the late phase of the response, and is reflected in a sustained hyperpolarization that lasts some 200-300 ms. Both components are seen in all cortical pyramidal neurones. However, the GABAA component appears more powerful in deep layer pyramids than superficial layer pyramids. 6. The microcircuit simulates with good fidelity the above data from experiments in vivo and provides a novel explantation for the apparent lack of significant inhibition during visual stimulation. The basic circuit may be common to all cortical areas studied and thus the microcircuit may be a 'canonical' microcircuit for neocortex.},
	journal = {J. Physiol.},
	author = {Douglas, R J and Martin, K A},
	year = {1991},
	keywords = {merged\_fiete.bib},
	pages = {735--769},
}

@article{feldmeyer_barrel_2012,
	title = {Barrel cortex function},
	abstract = {Neocortex, the neuronal structure at the base of the remarkable cognitive skills of mammals, is a layered sheet of neuronal tissue composed of juxtaposed and interconnected columns. A cortical column is considered the basic module of cortical processing present in all cortical areas. It is believed to contain a characteristic microcircuit composed of a few thousands of neurons. The high degree of cortical segmentation into vertical columns and horizontal layers is a boon for scientific investigation because it eases the systematic dissection and functional analysis of intrinsic as well as extrinsic connections of the column. In this review we will argue that in order to understand neocortical function one needs to combine a microscopic view, elucidating the workings of the local columnar microcircuits, with a macroscopic view, which keeps track of the linkage of distant cortical modules in different behavioral contexts. We will exemplify this strategy using the model system of vibrissal touch in mice and rats. On the macroscopic level vibrissal touch is an important sense for the subterranean rodents and has been honed by evolution to serve an array of distinct behaviors. Importantly, the vibrissae are moved actively to touch - requiring intricate sensorimotor interactions. Vibrissal touch, therefore, offers ample opportunities to relate different behavioral contexts to specific interactions of distant columns. On the microscopic level, the cortical modules in primary somatosensory cortex process touch inputs at highest magnification and discreteness - each whisker is represented by its own so-called barrel column. The cellular composition, intrinsic connectivity and functional aspects of the barrel column have been studied in great detail. Building on the versatility of genetic tools available in rodents, new, highly selective and flexible cellular and molecular tools to monitor and manipulate neuronal activity have been devised. Researchers have started to combine these with advanced and highly precise behavioral methods, on par with the precision known from monkey preparations. Therefore, the vibrissal touch model system is exquisitely positioned to combine the microscopic with the macroscopic view and promises to be instrumental in our understanding of neocortical function.},
	journal = {Prog. Neurobiol.},
	author = {Feldmeyer, Dirk and Brecht, Michael and Helmchen, Fritjof and Petersen, Carl C H and Poulet, James F A and Staiger, Jochen F and Luhmann, Heiko J and Schwarz, Cornelius},
	month = nov,
	year = {2012},
	keywords = {merged\_fiete.bib},
}

@article{rockland_widespread_1982,
	title = {Widespread periodic intrinsic connections in the tree shrew visual cortex},
	volume = {215},
	abstract = {Intrinsic connections within the tree shrew (Tupaia glis) visual cortex (area 17) are organized in periodic stripelike patterns within layers I, II, and III. This anatomical network resembles the regularly organized stripes of 2-deoxyglucose accumulation seen after stimulation of alert animals with uniformly oriented lines. Such connections imply that widespread lateral interactions are superimposed on the retinotopic organization of area 17 and suggest alternative interpretations of cortical columns.},
	number = {4539},
	journal = {Science},
	author = {Rockland, K S and Lund, J S},
	month = mar,
	year = {1982},
	keywords = {merged\_fiete.bib},
	pages = {1532--1534},
}

@article{gilbert_morphology_1979,
	title = {Morphology and intracortical projections of functionally characterised neurones in the cat visual cortex},
	volume = {280},
	abstract = {The neuronal structure and connectivity underlying receptive field organisation of cells in the cat visual cortex have been investigated. Intracellular recordings were made using a micropipette filled with a histochemical marker, which was injected into the cells after their receptive fields had been characterised. This allowed visualisation of the dendritic and axonal arborisations of functionally identified neurones.},
	number = {5718},
	journal = {Nature},
	author = {Gilbert, C D and Wiesel, T N},
	month = jul,
	year = {1979},
	keywords = {merged\_fiete.bib},
	pages = {120--125},
}

@article{chavane_lateral_2011,
	title = {Lateral {Spread} of {Orientation} {Selectivity} in {V1} is {Controlled} by {Intracortical} {Cooperativity}},
	volume = {5},
	abstract = {Neurons in the primary visual cortex receive subliminal information originating from the periphery of their receptive fields (RF) through a variety of cortical connections. In the cat primary visual cortex, long-range horizontal axons have been reported to preferentially bind to distant columns of similar orientation preferences, whereas feedback connections from higher visual areas provide a more diverse functional input. To understand the role of these lateral interactions, it is crucial to characterize their effective functional connectivity and tuning properties. However, the overall functional impact of cortical lateral connections, whatever their anatomical origin, is unknown since it has never been directly characterized. Using direct measurements of postsynaptic integration in cat areas 17 and 18, we performed multi-scale assessments of the functional impact of visually driven lateral networks. Voltage-sensitive dye imaging showed that local oriented stimuli evoke an orientation-selective activity that remains confined to the cortical feedforward imprint of the stimulus. Beyond a distance of one hypercolumn, the lateral spread of cortical activity gradually lost its orientation preference approximated as an exponential with a space constant of about 1 mm. Intracellular recordings showed that this loss of orientation selectivity arises from the diversity of converging synaptic input patterns originating from outside the classical RF. In contrast, when the stimulus size was increased, we observed orientation-selective spread of activation beyond the feedforward imprint. We conclude that stimulus-induced cooperativity enhances the long-range orientation-selective spread.},
	journal = {Front. Syst. Neurosci.},
	author = {Chavane, Frédéric and Sharon, Dahlia and Jancke, Dirk and Marre, Olivier and Frégnac, Yves and Grinvald, Amiram},
	year = {2011},
	keywords = {merged\_fiete.bib},
	pages = {4},
}

@article{tanaka_representation_1996-1,
	title = {Representation of {Visual} {Features} of {Objects} in the {Inferotemporal} {Cortex}},
	volume = {9},
	abstract = {Cells in area TE of the inferotemporal cortex of the monkey brain selectively respond to various moderately complex object features, and those that respond to similar features cluster in a columnar region elongated vertical to the cortical surface. Columns representing related but different features partially overlap, and at least in some cases they comprise a continuous map of a piece of complex feature space. This continuous mapping is likely used for various computations, such as production of the image of the object at different viewing angles, illumination conditions, and articulation poses. Copyright 1996 Elsevier Science Ltd.},
	language = {ENG},
	number = {8},
	journal = {Neural Netw.},
	author = {Tanaka, K},
	year = {1996},
	note = {Place: The Institute of Physical and Chemical Research (RIKEN), Japan},
	keywords = {merged\_fiete.bib},
	pages = {1459--1475},
}

@article{bizzi_does_1994,
	title = {Does the nervous system use equilibrium-point control to guide single and multiple joint movements?},
	journal = {Movement Control, eds: Paul Cordo and Stevan Harnad},
	author = {Bizzi, E and Hogan, N and Mussa-Ivaldi, F A and Giszter, S},
	year = {1994},
	keywords = {Jun 12 import},
	pages = {1--11},
}

@article{kargo_rapid_2000,
	title = {Rapid correction of aimed movements by summation of force-field primitives},
	volume = {20},
	number = {1},
	journal = {J. Neurosci.},
	author = {Kargo, W J and Giszter, S F},
	month = jan,
	year = {2000},
	keywords = {Jun 12 import},
	pages = {409--426},
}

@article{kargo_afferent_2000,
	title = {Afferent roles in hindlimb wipe-reflex trajectories: free-limb kinematics and motor patterns},
	volume = {83},
	number = {3},
	journal = {J. Neurophysiol.},
	author = {Kargo, W J and Giszter, S F},
	month = mar,
	year = {2000},
	keywords = {Jun 12 import},
	pages = {1480--1501},
}

@article{giszter_convergent_1993,
	title = {Convergent {Force} {Fields} {Organized} in the {Frog}'s {Spinal} {Cord}},
	volume = {13},
	number = {2},
	journal = {J. Neurosci.},
	author = {Giszter, Simon F and Mussa-Ivaldi, Fernando A and Bizzi, Emilio},
	month = feb,
	year = {1993},
	keywords = {Jun 12 import},
	pages = {467--491},
}

@article{mussa-ivaldi_linear_1994,
	title = {Linear combinations of primitives in motor control},
	volume = {91},
	number = {16},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Mussa-Ivaldi, F A and Giszter, S F and Bizzi, E},
	month = aug,
	year = {1994},
	keywords = {Jun 12 import},
	pages = {7534--7538},
}

@article{gallagher_evolution_1999,
	title = {Evolution and analysis of dynamical neural networks for agents integrating vision, locomotion and short-term memory},
	abstract = {The use of evolutionary approaches to create dynamical �nervous systems� for autonomous agents is becoming increasingly widespread. In previous work, we have successfully applied this approach to chemotaxis, walking, learning, and such minimally cognitive behavior as visually-guided orientation, object discrimination and pointing. In this paper, we extend this approach to the integration of visually-guided orientation and walking and to an object orientation task that requires short-term memory. In addition, we examine the neural dynamics underlying the operation of some of these evolved agents.},
	journal = {GECCO},
	author = {Gallagher, John C and Beer, Randall D},
	month = jul,
	year = {1999},
	keywords = {Jun 12 import},
	pages = {1273--1280},
}

@article{chiel_evolution_1999,
	title = {Evolution and {Analysis} of {Model} {CPGs} for {Walking} {I}. {Dynamical} {Modules}},
	volume = {7},
	abstract = {Can one develop an abstract description of the dynamics of pattern generators that provides quantitative insight into their operation? We explored this question by examining the dynamics of a model central pattern generator that was created using an evolutionary algorithm. We propose an abstract description based on the concept of a dynamical module, a set of neurons that simultaneously make their transitions from one quasistable state to another while the synaptic inputs that they receive remain essentially constant, thus temporarily reducing the dimensionality of the circuit dynamics. Using the mathematical tools of dynamical systems theory, we describe a method for identifying dynamical modules, and demonstrate that this concept can be used to quantitatively characterize constraints on neural architecture, account for phase durations, and predict the effects of parameter changes. Moreover, this abstract description reveals coordinated parameter changes that leave the overall circuit dynamics essentially unchanged. In a companion paper (Beer et al. submitted), we employ this abstract description to examine the relationship between general principles and individual variability in large populations of evolved model pattern generators.},
	journal = {J. Comput. Neurosci.},
	author = {Chiel, Hillel J and Beer, Randall D and Gallagher, John C},
	year = {1999},
	keywords = {Jun 12 import},
	pages = {99--118},
}

@article{beer_evolution_1999,
	title = {Evolution and {Analysis} of {Model} {CPGs} for {Walking} {II}. {General} {Principles} and {Individual} {Variability}},
	volume = {7},
	abstract = {Are there general principles for pattern generation? We examined this question by analyzing the operation of large populations of evolved model central pattern generators (CPGs) for walking. Three populations of model CPGs were evolved, containing 3, 4, or 5 neurons. We identified six general principles. First, locomotion performance increased with the number of interneurons. Second, the top ten 3-, 4- and 5-neuron CPGs could be decomposed into dynamical modules, an abstract description developed in a companion paper (Chiel et al. submitted). Third, these dynamical modules were multistable: they could be switched between multiple stable output configurations. Fourth, the rhythmic pattern generated by a CPG could be understood as a closed chain of successive destabilizations of one dynamical module by another. A combinatorial analysis enumerated the possible dynamical modular structures. Fifth, one-dimensional modules were frequently observed and, in some cases, could be assigned specific functional roles. Finally, dynamic dynamical modules, in which the modular structure itself changed over one cycle, were frequently observed. The existence of these general principles despite significant variability in both patterns of connectivity and neural parameters was explained by degeneracy in the maps from neural parameters to neural dynamics to behavior to fitness. An analysis of the biomechanical properties of the model body was essential for relating neural activity to behavior. Our studies of evolved model circuits suggest that, in the absence of other constraints, there is no compelling reason to expect neural circuits to be functionally decomposable as the number of interneurons increase. Analyzing idealized model pattern generators may be an effective methodology for gaining insights into the operation of biological pattern generators.},
	journal = {J. Comput. Neurosci.},
	author = {Beer, Randall D and Chiel, Hillel J and Gallagher, John C},
	year = {1999},
	keywords = {Jun 12 import},
	pages = {119--147},
}

@article{gomi_human_1997,
	title = {Human arm stiffness and equilibrium-point trajectory},
	volume = {76},
	abstract = {By using a newly designed high-performancemanipulandum and a new estimation algorithm, wemeasured human multi-joint arm stiffness parametersduring multi-joint point-to-point movements on a hori-zontal plane. This manipulandum allows us to applya suffcient perturbation to subject's arm within a briefperiod during movement. Arm stiffness parameters werereliably estimated using a new algorithm, in which allunknown structural parameters could be estimated inde-pendent of arm posture (i.e., constant values under anyarm posture). Arm sti�ness during transverse movementwas considerably greater than that during correspondingposture, but not during a longitudinal movement. Although the ratios of elbow, shoulder, and double-jointstiffness were varied in time, the orientation of stiffnessellipses during the movement did not change much.Equilibrium-point trajectories that were predicted frommeasured sti�ness parameters and actual trajectorieswere slightly sinusoidally curved in Cartesian space andtheir velocity profiles were quite di�erent from the velo-city profiles of actual hand trajectories. This result con-tradicts the hypothesis that the brain does not take thedynamics into account in movement control dependingon the neuromuscular servo mechanism; rather, it impliesthat the brain needs to acquire some internal models ofcontrolled objects.},
	journal = {Biol. Cybern.},
	author = {Gomi, Hiroaki and Kawato, Mitsuo},
	year = {1997},
	keywords = {Jun 12 import},
	pages = {163--171},
}

@article{kawato_internal_1999,
	title = {Internal models for motor control and trajectory planning},
	volume = {9},
	abstract = {A number of internal model concepts are now widespread in neuroscience and cognitive science. These concepts are supported by behavioral, neurophysiological, and imaging data; furthermore, these models have had their structures and functions revealed by such data. In particular, a specific theory on inverse dynamics model learning is directly supported by unit recordings from cerebellar Purkinje cells. Multiple paired forward inverse models describing how diverse objects and environments can be controlled and learned separately have recently been proposed. The 'minimum variance model' is another major recent advance in the computational theory of motor control. This model integrates two furiously disputed approaches on trajectory planning, strongly suggesting that both kinematic and dynamic internal models are utilized in movement planning and control.},
	number = {6},
	journal = {Curr. Opin. Neurobiol.},
	author = {Kawato, M},
	month = dec,
	year = {1999},
	keywords = {Jun 12 import},
	pages = {718--727},
}

@article{shastri_biologically_1997,
	title = {A biologically consistent model of legged locomotion gaits},
	volume = {76},
	abstract = {Significant advances have occurred over the past two decades in issues related to the mechanical design of legged robots and the coordination and control of legs dur-ing locomotion. The performance of current legged robots, however, remains far below even simplest counterparts in the biological world. Naturally, this has led to a search by researchers for biologically motivated approaches to the de-sign and control of legged robots in order to improve their performance and robustness. In this paper the use of central pattern generators (CPGs) will be examined for the control of locomotion. In doing so, a biologically consistent mathe-matical model that has the ability to emulate arbitrary gaits is developed. A simple algorithm for encoding the character-istic gaits of bipeds, quadrupeds and hexapeds is presented. The paper concludes with a brief description of a locomotion control architecture for actually realizing leg movements that correspond to various gaits.},
	journal = {Biol. Cybern.},
	author = {Shastri, S V},
	year = {1997},
	keywords = {Jun 12 import},
	pages = {429--440},
}

@article{bhushan_computational_1999,
	title = {Computational nature of human adaptive control during learning of reaching movements in force fields},
	volume = {81},
	abstract = {Learning to make reaching movements in force fields was used as a paradigm to explore the system architecture of the biological adaptive controller. We compared the performance of a number of candidate control systems that acted on a model of the neuromuscular system of the human arm and asked how well the dynamics of the candidate system compared with the movement characteristics of 16 subjects. We found that control via a supra-spinal system that utilized an adaptive inverse model resulted in dynamics that were similar to that observed in our subjects, but lacked essential characteristics. These characteristics pointed to a different architecture where descending commands were influenced by an adaptive forward model. However, we found that control via a forward model alone also resulted in dynamics that did not match the behavior of the human arm. We considered a third control architecture where a forward model was used in conjunction with an inverse model and found that the resulting dynamics were remarkably similar to that observed in the experimental data. The essential property of this control architecture was that it predicted a complex pattern of near-discontinuities in hand trajectory in the novel force field. A nearly identical pattern was observed in our subjects, suggesting that generation of descending motor commands was likely through a control system architecture that included both adaptive forward and inverse models. We found that as subjects learned to make reaching movements, adaptation rates for the forward and inverse models could be independently estimated and the resulting changes in performance of subjects from movement to movement could be accurately accounted for. Results suggested that the adaptation of the forward model played a dominant role in the motor learning of subjects. After a period of consolidation, the rates of adaptation in the internal models were signi�cantly larger than those observed before the memory had consolidated. This suggested that consolidation of motor memory coincided with freeing of certain computational resources for subsequent learning.},
	journal = {Biol. Cybern.},
	author = {Bhushan, Nikhil and Shadmehr, Reza},
	year = {1999},
	keywords = {Jun 12 import},
	pages = {39--60},
}

@article{canavier_phase_1997,
	title = {Phase response characteristics of model neurons determine which patterns are expressed in a ring circuit model of gait generation},
	volume = {77},
	abstract = {In order to assess the relative contributions to pattern-generation of the intrinsic properties of individual neurons and of their connectivity, we examined a ring circuit composed of four complex physiologically based oscillators. This circuit produced patterns that correspond to several quadrupedal gaits, including the walk, the bound, and the gallop. An analysis using the phase response curve (PRC) of an uncoupled oscillator accurately predicted all modes exhibited by this circuit and their phasic relationships–with the caveat that in certain parameter ranges, bistability in the individual oscillators added nongait patterns that were not amenable to PRC analysis, but further enriched the pattern-generating repertoire of the circuit. The key insights in the PRC analysis were that in a gait pattern, since all oscillators are entrained at the same frequency, the phase advance or delay caused by the action of each oscillator on its postsynaptic oscillator must be the same, and the sum of the normalized phase differences around the ring must equal to an integer. As suggested by several previous studies, our analysis showed that the capacity to exhibit a large number of patterns is inherent in the ring circuit configuration. In addition, our analysis revealed that the shape of the PRC for the individual oscillators determines which of the theoretically possible modes can be generated using these oscillators as circuit elements. PRCs that have a complex shape enable a circuit to produce a wider variety of patterns, and since complex neurons tend to have complex PRCs, enriching the repertoire of patterns exhibited by a circuit may be the function of some intrinsic neuronal complexity. Our analysis showed that gait transitions, or more generally, pattern transitions, in a ring circuit do not require rewiring the circuit or any changes in the strength of the connections. Instead, transitions can be achieved by using a control parameter, such as stimulus intensity, to sculpt the PRC so that it has the appropriate shape for the desired pattern(s). A transition can then be achieved simply by changing the value of the control parameter so that the first pattern either ceases to exist or loses stability, while a second pattern either comes into existence or gains stability. Our analysis illustrates the predictive value of PRCs in circuit analysis and can be extended to provide a design method for pattern-generating circuits.},
	number = {6},
	journal = {Biol. Cybern.},
	author = {Canavier, C C and Butera, R J and Dror, R O and Baxter, D A and Clark, J W and Byrne, J H},
	month = dec,
	year = {1997},
	keywords = {Jun 12 import},
	pages = {367--380},
}

@article{gandolfo_cortical_2000,
	title = {Cortical correlates of learning in monkeys adapting to a new dynamical environment},
	volume = {97},
	abstract = {In this paper, we describe the neural changes observed in the primary motor cortex of two monkeys while they learned a new motor skill. The monkeys had to adapt their reaching movements to external forces that interfered with the execution of their arm movements. We found a sizable population of cells that changed their tuning properties during exposure to the force field. These cells took on the properties of neurons that are involved in the control of movement. Furthermore, the cells maintained the acquired activity as the monkey readapted to the no-force condition. Recent imaging studies in humans have reported the effects of motor learning in the primary motor cortex. Our results are consistent with the findings of these studies and provide evidence for single-cell plasticity in the primary motor cortex of primates.},
	number = {5},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Gandolfo, F and Li, C and Benda, B J and Schioppa, C P and Bizzi, E},
	month = feb,
	year = {2000},
	keywords = {Jun 12 import},
	pages = {2259--2263},
}

@article{zhang_theory_1999,
	title = {A theory of geometric constraints on neural activity for natural three-dimensional movement},
	volume = {19},
	abstract = {Although the orientation of an arm in space or the static view of an object may be represented by a population of neurons in complex ways, how these variables change with movement often follows simple linear rules, reflecting the underlying geometric constraints in the physical world. A theoretical analysis is presented for how such constraints affect the average firing rates of sensory and motor neurons during natural movements with low degrees of freedom, such as a limb movement and rigid object motion. When applied to nonrigid reaching arm movements, the linear theory accounts for cosine directional tuning with linear speed modulation, predicts a curl-free spatial distribution of preferred directions, and also explains why the instantaneous motion of the hand can be recovered from the neural population activity. For three-dimensional motion of a rigid object, the theory predicts that, to a first approximation, the response of a sensory neuron should have a preferred translational direction and a preferred rotation axis in space, both with cosine tuning functions modulated multiplicatively by speed and angular speed, respectively. Some known tuning properties of motion-sensitive neurons follow as special cases. Acceleration tuning and nonlinear speed modulation are considered in an extension of the linear theory. This general approach provides a principled method to derive mechanism-insensitive neuronal properties by exploiting the inherently low dimensionality of natural movements.},
	number = {8},
	journal = {J. Neurosci.},
	author = {Zhang, K and Sejnowski, T J},
	month = apr,
	year = {1999},
	keywords = {Jun 12 import},
	pages = {3122--3145},
}

@article{georgopoulos_arm_1996,
	title = {Arm movements in monkeys: behavior and neurophysiology},
	volume = {179},
	abstract = {Reaching to objects of interest is very common in the behavioral repertoire of primates. Monkeys possess keen binocular vision and make graceful and accurate arm movements. This review focuses on behavioral and neurophysiological aspects of eye-hand coordination in behaving monkeys, including neural coding mechanisms at the single cell level and in neuronal populations. The results of these studies have converged to a common behavioral-neurophysiological ground and provided a springboard for studies of brain mechanisms underlying motor cognitive function.},
	number = {5},
	journal = {J. Comp. Physiol. A},
	author = {Georgopoulos, A P},
	month = nov,
	year = {1996},
	keywords = {Jun 12 import},
	pages = {603--612},
}

@article{fukai_model_1995,
	title = {A model cortical circuit for the storage of temporal sequences},
	volume = {72},
	abstract = {Despite the fact that temporal information processing is of particular significance in biological memory systems, not much has yet been explored about how these systems manage to store temporal information involved in sequences of stimuli. A neural network model capable of learning and recalling temporal sequences is proposed, based on a neural mechanism in which the sequences are expanded into a series of periodic rectangular oscillations. Thus, the mathematical framework underlying the model, to some extent, is concerned with the Walsh function series. The oscillatory activities generated by the interplay between excitatory and inhibitory neuron pools are transmitted to another neuron pool whose role in learning and retrieval is to modify the rhythms and phases of the rectangular oscillations. Thus, a basic functional neural circuit involves three different neuron pools. The modifiability of rhythms and phases is incorporated into the model with the aim of improving the quality of the retrieval. Numerical simulations were conducted to show the characteristic features of the learning as well as the performance of the model in memory recall.},
	journal = {Biol. Cybern.},
	author = {Fukai, Tomoki},
	year = {1995},
	keywords = {Jun 12 import},
	pages = {321--328},
}

@article{gottlieb_directional_1997,
	title = {Directional control of planar human arm movement},
	volume = {78},
	abstract = {We examined the patterns of joint kinematics and torques in two kinds of sagittal plane reaching movements. One consisted of movements from a fixed initial position with the arm partially outstretched, to different targets, equidistant from the initial position and located according to the hours of a clock. The other series added movements from different initial positions and directions and {\textgreater}40-80 cm distances. Dynamic muscle torque was calculated by inverse dynamic equations with the gravitational components removed. In making movements in almost every direction, the dynamic components of the muscle torques at both the elbow and shoulder were related almost linearly to each other. Both were similarly shaped, biphasic, almost synchronous and symmetrical pulses. These findings are consistent with our previously reported observations, which we termed a linear synergy. The relative scaling of the two joint torques changes continuously and regularly with movement direction. This was confirmed by calculating a vector defined by the dynamic components of the shoulder and elbow torques. The vector rotates smoothly about an ellipse in intrinsic, joint torque space as the direction of hand motion rotates about a circle in extrinsic Cartesian space. This confirms a second implication of linear synergy that the scaling constant between the linearly related joint torques is directionally dependent. Multiple linear regression showed that the torque at each joint scales as a simple linear function of the angular displacement at both joints, in spite of the complex nonlinear dynamics of multijoint movement. The coefficients of this function are independent of the initial arm position and movement distance and are the same for all subjects. This is an unanticipated finding. We discuss these observations in terms of the hypothesis that voluntary, multiple degrees of freedom, rapid reaching movements may use rule-based, feed-forward control of dynamic joint torque. Rule-based control of joint torque with separate dynamic and static controllers is an alternative to models such as those based on the equilibrium point hypotheses that rely on a positionally based controller to produce both dynamic and static torque components. It is also an alternative to feed-forward models that directly solve the problems of inverse dynamics. Our experimental findings are not necessarily incompatible with any of the alternative models, but they describe new, additional findings for which we need to account. The rules are chosen by the nervous system according to features of the kinematic task to couple muscle contraction at the shoulder and elbow in a linear synergy. Speed and load control preserves the relative magnitudes of the dynamic torques while directional control is accomplished by modulating them in a differential manner. This control system operates in parallel with a positional control system that solves the problems of postural stability.},
	number = {6},
	journal = {J. Neurophysiol.},
	author = {Gottlieb, G L and Song, Q and Almeida, G L and Hong, D A and Corcos, D},
	month = dec,
	year = {1997},
	keywords = {Jun 12 import},
	pages = {2985--2998},
}

@article{grillner_bridging_1999,
	title = {Bridging the gap - from ion channels to networks and behaviour},
	volume = {9},
	abstract = {A major challenge for current research in neuroscience is to understand the intrinsic operation of the functional modules of the central nervous system, such as those formed by cortical columns and the neuronal networks controlling motor behaviour. Most vertebrate experimental models used in network analyses involve developing nervous systems, which are in rapid transition with regard to their cellular properties and the expression of different ion channels. Recent advances in our understanding of the cellular and circuit properties of motor networks are making it possible to decipher the mechanisms involved in vertebrate motor pattern generation.},
	number = {6},
	journal = {Curr. Opin. Neurobiol.},
	author = {Grillner, S},
	month = dec,
	year = {1999},
	keywords = {Jun 12 import},
	pages = {663--669},
}

@article{riener_model-based_1999,
	title = {Model-based development of neuroprosthesis for paraplegic patients},
	volume = {354},
	abstract = {In paraplegic patients with upper motor neuron lesions the signal path from the central nervous system to the muscles is interrupted. Functional electrical stimulation applied to the lower motor neurons can replace the lacking signals. A so-called neuroprosthesis may be used to restore motor function in paraplegic patients on the basis of functional electrical stimulation. However, the control of multiple joints is difficult due to the complexity, nonlinearity, and time-variance of the system involved. Furthermore, effects such as muscle fatigue, spasticity, and limited force in the stimulated muscle further complicate the control task. Mathematical models of the human musculoskeletal system can support the development of neuroprosthesis. In this article a detailed overview of the existing work in the literature is given and two examples developed by the author are presented that give an insight into model-based development of neuroprosthesis for paraplegic patients. It is shown that modelling the musculoskeletal system can provide better understanding of muscular force production and movement coordination principles. Models can also be used to design and test stimulation patterns and feedback control strategies. Additionally, model components can be implemented in a controller to improve control performance. Eventually, the use of musculoskeletal models for neuroprosthesis design may help to avoid internal disturbances such as fatigue and optimize muscular force output. Furthermore, better controller quality can be obtained than in previous empirical approaches. In addition, the number of experimental tests to be performed with human subjects can be reduced. It is concluded that mathematical models play an increasing role in the development of reliable closed-loop controlled, lower extremity neuroprostheses.},
	number = {1385},
	journal = {Philos. Trans. R. Soc. Lond. B Biol. Sci.},
	author = {Riener, R},
	month = may,
	year = {1999},
	keywords = {simulation, Jun 12 import, functional electrical stimulation, model, motion control, neuroprosthesis, paraplegic patient},
	pages = {877--894},
}

@article{schweighofer_role_1998,
	title = {Role of the cerebellum in reaching movements in humans. {I}. {Distributed} inverse dynamics control},
	volume = {10},
	abstract = {This study focuses on the role of the motor cortex, the spinal cord and the cerebellum in the dynamics stage of the control of arm movement. Currently, two classes of models have been proposed for the neural control of movements, namely the virtual trajectory control hypothesis and the acquisition of internal models of the motor apparatus hypothesis. In the present study, we expand the virtual trajectory model to whole arm reaching movements. This expanded model accurately reproduced slow movements, but faster reaching movements deviated significantly from the planned trajectories, indicating that for fast movements, this model was not sufficient. These results led us to propose a new distributed functional model consistent with behavioural, anatomical and neurophysiological data, which takes into account arm muscles, spinal cord, motor cortex and cerebellum and is consistent with the view that the central nervous system acquires a distributed inverse dynamics model of the arm. Previous studies indicated that the cerebellum compensates for the interaction forces that arise during reaching movements. We show here how the cerebellum may increase the accuracy of reaching movements by compensating for the interaction torques by learning a portion of an inverse dynamics model that refines a basic inverse model in the motor cortex and spinal cord.},
	number = {1},
	journal = {Eur. J. Neurosci.},
	author = {Schweighofer, N and Arbib, M A and Kawato, M},
	month = jan,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {86--94},
}

@article{schweighofer_role_1998-1,
	title = {Role of the cerebellum in reaching movements in humans. {II}. {A} neural model of the intermediate cerebellum},
	volume = {10},
	abstract = {The cerebellum is essential for the control of multijoint movements; when the cerebellum is lesioned, the performance error is more than the summed errors produced by single joints. In the companion paper (Schweighofer et al., 1998), a functional anatomical model for visually guided arm movement was proposed. The model comprised a basic feedforward/feedback controller with realistic transmission delays and was connected to a two-link, six-muscle, planar arm. In the present study, we examined the role of the cerebellum in reaching movements by embedding a novel, detailed cerebellar neural network in this functional control model. We could derive realistic cerebellar inputs and the role of the cerebellum in learning to control the arm was assessed. This cerebellar network learned the part of the inverse dynamics of the arm not provided by the basic feedforward/feedback controller. Despite realistically low inferior olive firing rates and noisy mossy fibre inputs, the model could reduce the error between intended and planned movements. The responses of the different cell groups were comparable to those of biological cell groups. In particular, the modelled Purkinje cells exhibited directional tuning after learning and the parallel fibres, due to their length, provide Purkinje cells with the input required for this coordination task. The inferior olive responses contained two different components; the earlier response, locked to movement onset, was always present and the later response disappeared after learning. These results support the theory that the cerebellum is involved in motor learning.},
	number = {1},
	journal = {Eur. J. Neurosci.},
	author = {Schweighofer, N and Spoelstra, J and Arbib, M A and Kawato, M},
	month = jan,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {95--105},
}

@article{spoelstra_cerebellar_2000,
	title = {Cerebellar learning of accurate predictive control for fast-reaching movements},
	volume = {82},
	abstract = {Long conduction delays in the nervous system prevent the accurate control of movements by feedback control alone. We present a new, biologically plausible cerebellar model to study how fast arm movements can be executed in spite of these delays. To provide a realistic test-bed of the cerebellar neural model, we embed the cerebellar network in a simulated biological motor system comprising a spinal cord model and a six-muscle two-dimensional arm model. We argue that if the trajectory errors are detected at the spinal cord level, memory traces in the cerebellum can solve the temporal mismatch problem between efferent motor commands and delayed error signals. Moreover, learning is made stable by the inclusion of the cerebello-nucleo-olivary loop in the model. It is shown that the cerebellar network implements a nonlinear predictive regulator by learning part of the inverse dynamics of the plant and spinal circuit. After learning, fast accurate reaching movements can be generated.},
	number = {4},
	journal = {Biol. Cybern.},
	author = {Spoelstra, J and Schweighofer, N and Arbib, M A},
	month = apr,
	year = {2000},
	keywords = {Jun 12 import},
	pages = {321--333},
}

@article{papantoniou_control_1999,
	title = {Control of a robot dinosaur},
	volume = {354},
	abstract = {The Palaiomation Consortium, supported by the European Commission, is building a robot Iguanadon atherfieldensis for museum display that is much more sophisticated than existing animatronic exhibits. The current half-size (2.5m) prototype is fully autonomous, carrying its own computer and batteries. It walks around the room, choosing its own path and avoiding obstacles. A bigger version with a larger repertoire of behaviors is planned. Many design problems have had to be overcome. A real dinosaur would have had hundreds of muscles, and we have had to devise means of achieving life-like movement with a much smaller number of motors; we have limited ourselves to 20, to keep the control problems manageable. Realistic stance requires a narrower trackway and a higher centre of mass than in previous (often spiker-like) legged robots, making it more difficult to maintain stability. Other important differences from previous walking robots are that the forelegs have to be shorted than the hind, and the machinery has had to be designed to fit inside a realistically shaped body shell. Battery life is about one hour, but to achieve this, we have had to design the robot to have very low power consumption. Currently, this limits it to unrealistically slow movements. The control system includes a high-level instructions processor, a gait generator, a motion, a motion-coordination generator, and a kinematic model.},
	number = {1385},
	journal = {Philos. Trans. R. Soc. Lond. B Biol. Sci.},
	author = {Papantoniou, V and Avlakiotis, P and Alexander, R Mcn},
	month = may,
	year = {1999},
	keywords = {Jun 12 import, dinosaur, quadrapedal locomotion, robot, walking},
	pages = {863--868},
}

@incollection{klavins_role_2001,
	title = {The {Role} of {Reflexes} {Versus} {Central} {Pattern} {Generators} in {Dynamical} {Legged} {Locomotion}},
	booktitle = {Neurotechnology for {Biomimetic} {Robots}},
	publisher = {MIT Press},
	author = {Klavins, Eric and Komsuoglu, Haldun and Full, Robert J and Koditschek, Daniel E},
	year = {2001},
	keywords = {Jun 12 import},
}

@article{rizzolatti_premotor_1996,
	title = {Premotor cortex and the recognition of motor actions},
	volume = {3},
	abstract = {In area F5 of the monkey premotor cortex there are neurons that discharge both when the monkey performs an action and when he observes a similar action made by another monkey or by the experimenter. We report here some of the properties of these 'mirror' neurons and we propose that their activity 'represents' the observed action. We posit, then, that this motor representation is at the basis of the understanding of motor events. Finally, on the basis of some recent data showing that, in man, the observation of motor actions activate the posterior part of inferior frontal gyrus, we suggest that the development of the lateral verbal communication system in man derives from a more ancient communication system based on recognition of hand and face gestures.},
	number = {2},
	journal = {Brain Res. Cogn. Brain Res.},
	author = {Rizzolatti, G and Fadiga, L and Gallese, V and Fogassi, L},
	month = mar,
	year = {1996},
	keywords = {Jun 12 import},
	pages = {131--141},
}

@article{karni_acquisition_1996,
	title = {The acquisition of perceptual and motor skills: a memory system in the adult human cortex},
	volume = {5},
	number = {1-2},
	journal = {Brain Res. Cogn. Brain Res.},
	author = {Karni, A},
	month = dec,
	year = {1996},
	keywords = {Memory, Jun 12 import, human, Cortex, Plasticity, Procedural learning},
	pages = {39--48},
}

@article{bizzi_neural_1998,
	title = {Neural basis of motor control and its cognitive implications},
	volume = {2},
	abstract = {It has recently been demonstrated that human subjects and nonhuman primates adapt their arm movements when subjected to complex patterns of disturbing forces. The presence of after-effects following the removal of the disturbing forces indicates that adaptation takes place through the development of an internal model of the disturbing force. The experimental evidence described in this paper has identified some important properties of this internal model: (1) it is limited to a region surrounding that part of the space where the disturbances had been experienced; (2) there is an enhancement of the internal model that depends only on the passage of time; and (3) there is a process of consolidation of the internal model, which takes a minimum of four hours. Anatomically, the substrate of the internal model is distributed: the motor cortex, basal ganglia and cerebellum are interconnected structures that are active to different degress during the acquisition of motor skills. Recent investigation of the spinal cord has suggested the existence of modules that organize the motor output in a discrete set of synergies. The outputs of these modules combine by addition, and might thus form the building blocks for the internal models represented by supraspinal structures.},
	number = {3},
	journal = {Trends Cogn. Sci.},
	author = {Bizzi, Emilio and Mussa-Ivaldi, Ferdinando A},
	month = mar,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {97--102},
}

@article{bizzi_new_2000,
	title = {{NEW} {PERSPECTIVES} {ON} {SPINAL} {MOTOR} {SYSTEMS}},
	volume = {1},
	abstract = {The production and control of complex motor functions are usually attributed to central brain structures such as cortex, basal ganglia and cerebellum. In traditional schemes the spinal cord is assigned a subservient function during the production of movement, playing a predominantly passive role by relaying the commands dictated to it by supraspinal systems. This review challenges this idea by presenting evidence that the spinal motor system is an active participant in several aspects of the production of movement, contributing to functions normally ascribed to `higher� brain regions.},
	journal = {Nat. Rev. Neurosci.},
	author = {Bizzi, Emilio and Tresch, Matthew C and Saltiel, Philippe and d�Avella, Andrea},
	year = {2000},
	keywords = {Jun 12 import},
	pages = {101--108},
}

@article{thach_specific_1996,
	title = {On the specific role of the cerebellum in motor learning and cognition: {Clues} from {PET} activation and lesion studies in man},
	volume = {19},
	abstract = {Brindley proposed that we initially generate movements �consciously,� under higher cerebral control. As the movement is practiced, the cerebellum learns to link within itself the context in which the movement is made to the lower level movement generators. Marr and Albus proposed that the linkage is established by a special input from the inferior olive, which plays upon an input-output element within the cerebellum during the period of the learning. When the linkage is complete, the occurrence of the context (represented by a certain input to the cerebellum) will trigger (through the cerebellum) the appropriate motor response. The �learned� movement is distinguished from the �unlearned� conscious movement by its now being automatic, rapid, and stereotyped. The idea is still controversial, but has been supported by a variety of animal studies and, as reviewed here, is consistent with the results of a number of human PET and ablation studies. I have added to the idea of context-response linkage what I think is another important variable: novel combinations of downstream elements. With regard to the motor system and the muscles, this could explain how varied combinations of muscles may become active in precise time-amplitude specifications so as to produce coordinated movements appropriate to specific contexts. In this target article, I have further extended this idea to the premotor parts of the brain and their role in cognition. These areas receive influences from the cerebellum; they are active both in planning movements that are to be executed and in thinking about movements that are not to be executed. From recent evidence, the cerebellar output extends even to what has been characterized as the ultimate frontal planning area, the �prefrontal� cortex, area 46. The cerebellum thus may be involved in context-response linkage, and response combination even at these higher levels. The implication would be that, through practice, an experiential context would automatically evoke a certain mental action plan. The plan would be in the realm of thought, and could - but need not - lead to execution. The specific cerebeilar contribution would be one of the context linkage and the shaping of the response, through trial and error learning. The prefrontal and premotor areas could still plan without the help of the cerebellum, but not so automatically, rapidly, stereotypically, so precisely linked to context, or so free of error. Nor would their activities improve optimally with mental practice.},
	journal = {Behav. Brain Sci.},
	author = {Thach, W T},
	year = {1996},
	keywords = {planning, timing, cerebellum, Jun 12 import, cognition, mental movement imagery, motor learning, sequence},
	pages = {411--431},
}

@article{li_neuronal_2001,
	title = {Neuronal {Correlates} of {Motor} {Performance} and {Motor} {Learning} in the {Primary} {Motor} {Cortex} of {Monkeys} {Adapting} to an {External} {Force} {Field}},
	volume = {30},
	abstract = {The primary motor cortex (M1) is known to control motor performance. Recent findings have also implicated M1 in motor learning, as neurons in this area show learning�related plasticity. In the present study, we analyzed the neuronal activity recorded in M1 in a force field-adaptation task. Our goal was to investigate the neuronal reorganization across behavioral epochs (before, during and after adaptation). Here we report two main findings. First, memory cells were present in two classes. Class I memory cells changed their activation following adaptation and maintained the new activation after removal of the perturbation. Class II memory cells, whose activation was not changed by the exposure to the force field, changed their activation following re-adaptation to the non-perturbed conditions. With respect to the changes of preferred direction (Pd), these two classes complemented each other after re-adaptation. Second, for the entire neuronal population the shift of Pd matched the shift observed for muscles. These results provide a framework whereby the activity of distinct neuronal sub-populations combines to subserve both functions of motor performance and motor learning.},
	journal = {Neuron},
	author = {Li, Chiang-Shan Ray and Padoa-Schioppa, Camillo and Bizzi, Emilio},
	month = may,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {593--607},
}

@article{harris_signal-dependent_1998,
	title = {Signal-dependent noise determines motor planning},
	volume = {394},
	abstract = {When we make saccadic eye movements or goal-directed arm movements, there is an infinite number of possible trajectories that the eye or arm could take to reach the target. However, humans show highly stereotyped trajectories in which velocity profiles of both the eye and hand are smooth and symmetric for brief movements. Here we present a unifying theory of eye and arm movements based on the single physiological assumption that the neural control signals are corrupted by noise whose variance increases with the size of the control signal. We propose that in the presence of such signal-dependent noise, the shape of a trajectory is selected to minimize the variance of the final eye or arm position. This minimum-variance theory accurately predicts the trajectories of both saccades and arm movements and the speed-accuracy trade-off described by Fitt's law. These profiles are robust to changes in the dynamics of the eye or arm, as found empirically. Moreover, the relation between path curvature and hand velocity during drawing movements reproduces the empirical 'two-thirds power law. This theory provides a simple and powerful unifying perspective for both eye and arm movement control.},
	number = {6695},
	journal = {Nature},
	author = {Harris, C M and Wolpert, D M},
	month = aug,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {780--784},
}

@incollection{jordan_computational_1999,
	title = {Computational {Motor} {Control}},
	abstract = {We discuss some of the computational approaches that have been developed in the area of motor control. We focus on problems relating to motor planning, internal models, state estimation, motor learning and modularity. The aim of the chapter is to demonstrate, both at a conceptual level and through consideration of specific models, how computational approaches shed light on problems in the control of movement.},
	booktitle = {The {Cognitive} {Neurosciences}},
	publisher = {MIT Press},
	author = {Jordan, Michael I and Wolpert, Daniel M},
	editor = {{Gazzaniga}},
	year = {1999},
	keywords = {Jun 12 import},
}

@article{leung_cerebellar_2000,
	title = {Cerebellar {Flocculus} and {Paraflocculus} {Purkinje} {Cell} {Activity} {During} {Circular} {Pursuit} in {Monkey}},
	volume = {83},
	abstract = {Responses from 69 Purkinje cells in the flocculus and paraflocculus of two rhesus monkeys were studied during smooth pursuit of targets moving along circular trajectories and compared with responses during sinusoidal pursuit and fixation. A variety of interesting responses was observed during circular pursuit. Although some neurons fired most strongly in a single preferred direction during clockwise (CW) and counterclockwise (CCW) pursuit, others had directional preferences that changed with rotation direction. Some of these neurons showed similar modulation amplitudes during CW and CCW pursuit, whereas other neurons showed a preference for a particular rotation direction. Response specificity also was observed during sinusoidal pursuit. Some neurons showed responses that were much stronger during centrifugal pursuit, others showed a preference for centripetal pursuit, and still others showed responses during both centripetal and centrifugal motion. Differences in preferred response direction were sometimes observed for centripetal versus centrifugal pursuit. CW/CCW and centrifugal/centripetal preferences were not explained by a breakdown in component additivity. That is, modulations in firing rate during pursuit along a circular trajectory equaled the sum of modulations during horizontal and vertical sinusoidal components as well as for diagonal components. Instead all responses were well fit by a model that expressed the instantaneous firing rate of each neuron as a multilinear function of the two-dimensional position and velocity of the eye. This model generalized well to performance at different sinusoidal frequencies. It did somewhat less well for responses during fixation, suggesting some separation in the neural mechanisms of dynamic and static positioning. The model indicates that position sensitivity accounted for approximately 36\% of the modulation during circular pursuit, and velocity sensitivity accounted for approximately 64\%. When position and velocity sensitivity vectors were aligned, responses were simpler and modulations were similar during CW versus CCW pursuit. In contrast, when these vectors pointed in different directions, response complexity increased. Nonaligned position and velocity influences tended to reinforce during circular pursuit in one direction and to cancel each other during pursuit in the opposite direction. They also tended to produce response differences during centripetal versus centrifugal sinusoidal pursuit. The distinct roles played by position and velocity in shaping Purkinje cell responses are compatible with the control signals required to generate smooth pursuit along circular and other two-dimensional trajectories.},
	number = {1},
	journal = {J. Neurophysiol.},
	author = {Leung, H C and Suh, M and Kettner, R E},
	month = jan,
	year = {2000},
	keywords = {Jun 12 import},
	pages = {13--30},
}

@article{mcmahon_mechanics_1984,
	title = {Mechanics of {Locomotion}},
	volume = {3},
	abstract = {Energetic and mechanical principles of walking and running are reviewed, using information available from force-plate studies. A mathematical model of walking is described that conserves the sum of the kinetic and gravitational potential energies of the body. In running, energy is stored transiently in the elastic deformations of stretched muscles and tendons. Theory and experiments are described using these principles and others to find the range of stiffness values for a running track that both lowers the potential for injuries and increases running speed.},
	number = {2},
	journal = {Int. J. Rob. Res.},
	author = {McMahon, T A},
	year = {1984},
	keywords = {Jun 12 import},
}

@article{grossberg_neural_1997,
	title = {Neural control of interlimb oscillations. {I}. {Human} bimanual coordination},
	volume = {77},
	abstract = {How do humans and other animals accomplish coordinated movements? How are novel combinations of limb joints rapidly assembled into new behavioral units that move together in in-phase or anti-phase movement patterns during complex movement tasks? A neural central pattern generator (CPG) model simulates data from human bimanual coordination tasks. As in the data, anti-phase oscillations at low frequencies switch to in-phase oscillations at high frequencies, in-phase oscillations occur at both low and high frequencies, phase fluctuations occur at the anti-phase in-phase transition, a “seagull effect” of larger errors occurs at intermediate phases, and oscillations slip toward in-phase and anti-phase when driven at intermediate phases. These oscillations and bifurcations are emergent properties of the CPG model in response to volitional inputs. The CPG model is a version of the Ellias-Grossberg oscillator. Its neurons obey Hodgkin-Huxley type equations whose excitatory signals operate on a faster time scale than their inhibitory signals in a recurrent on-center off-surround anatomy. When an equal command or GO signal activates both model channels, the model CPG can generate both in-phase and anti-phase oscillations at different GO amplitudes. Phase transitions from either in-phase to anti-phase oscillations, or from anti-phase to in-phase oscillations, can occur in different parameter ranges, as the GO signal increases.},
	number = {2},
	journal = {Biol. Cybern.},
	author = {Grossberg, S and Pribe, C and Cohen, M A},
	month = aug,
	year = {1997},
	keywords = {Jun 12 import},
	pages = {131--140},
}

@article{pribe_neural_1997,
	title = {Neural control of interlimb oscillations. {II}. {Biped} and quadruped gaits and bifurcations},
	volume = {77},
	abstract = {Behavioral data concerning animal and human gaits and gait transitions are simulated as emergent properties of a central pattern generator (CPG) model. The CPG model is a version of the Ellias-Grossberg oscillator. Its neurons obey Hodgkin-Huxley type equations whose excitatory signals operate on a faster time scale than their inhibitory signals in a recurrent on-center off-surround anatomy. A descending command or GO signal activates the gaits and triggers gait transitions as its amplitude increases. A single model CPG can generate both in-phase and anti-phase oscillations at different GO amplitudes. Phase transitions from either in-phase to anti-phase oscillations or from anti-phase to in-phase oscillations can occur in different parameter ranges, as the GO signal increases. Quadruped vertebrate gaits, including the amble, the walk, all three pairwise gaits (trot, pace, and gallop), and the pronk are simulated using this property. Rapid gait transitions are simulated in the order–walk, trot, pace, and gallop–that occurs in the cat, along with the observed increase in oscillation frequency. Precise control of quadruped gait switching uses GO-dependent modulation of inhibitory interactions, which generates a different functional anatomy at different arousal levels. The primary human gaits (the walk and the run) and elephant gaits (the amble and the walk) are simulated, without modulation, by oscillations with the same phase relationships but different waveform shapes at different GO signal levels, much as the duty cycles of the feet are longer in the walk than in the run. Relevant neural data from spinal cord, globus pallidus, and motor cortex, among other structures, are discussed.},
	number = {2},
	journal = {Biol. Cybern.},
	author = {Pribe, C and Grossberg, S and Cohen, M A},
	month = aug,
	year = {1997},
	keywords = {Jun 12 import},
	pages = {141--152},
}

@article{optican_visually_1985,
	title = {Visually induced adaptive changes in primate saccadic oculomotor control signals},
	volume = {54},
	abstract = {Saccades are the rapid eye movements used to change visual fixation. Normal saccades end abruptly with very little postsaccadic ocular drift, but acute ocular motor deficits can cause the eyes to drift appreciably after a saccade. Previous studies in both patients and monkeys with peripheral ocular motor deficits have demonstrated that the brain can suppress such postsaccadic drifts. Ocular drift might be suppressed in response to visual and/or proprioceptive feedback of position and/or velocity errors. This study attempts to characterize the adaptive mechanism for suppression of postsaccadic drift. The responses of seven rhesus monkeys were studied to postsaccadic retinal slip induced by horizontal exponential movements of a full-field stimulus. After several hours of saccade-related retinal image slip, the eye movements of the monkeys developed a zero-latency, compensatory postsaccadic ocular drift. This ocular drift was still evident in the dark, although smaller (typically 15\% of the amplitude of the antecedent saccade, up to a maximum drift of 8 degrees). Retinal slip alone, without a net displacement of the image, was sufficient to elicit these adaptive changes, and compensation for leftward and rightward saccades was independent. It took several days to complete adaptation, but recovery (in the light) was much quicker. The decay of this adaptation in darkness was very slow; after 3 days the ocular drift was reduced by less than 50\%. The time constants of single exponential curve fits to adaptation time courses of data from five animals were 35 h for acquisition, 4 h for recovery, and at least 40 h for decay in darkness. Descriptions of the central innervation for a saccade are usually simplified to only two components: a pulse and a step. It has been hypothesized that suppression of pathological postsaccadic drift is achieved by adjusting the ratio of the pulse to the step of innervation (19, 26). However, we show that the time constant of the ocular drift is influenced by the time constant of the adapting stimulus, which cannot be explained by the simple pulse-step model of saccadic innervation. A more realistic representation of the saccadic innervation has three components: a pulse, an exponential slide, and a step. Normal saccades were accurately simulated by a fourth-order, linear model of the ocular motor plant driven by such a pulse-slide-step combination. Saccades made after prolonged exposure to optically induced retinal image slip could also be simulated by properly adjusting the slide and step components.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Optican, L M and Miles, F A},
	month = oct,
	year = {1985},
	keywords = {Jun 12 import},
	pages = {940--958},
}

@article{sanner_mathematical_1999,
	title = {A mathematical model of the adaptive control of human arm motions},
	volume = {80},
	abstract = {This paper discusses similarities between models of adaptive motor control suggested by recent experiments with human and animal subjects, and the structure of a new control law derived mathematically from nonlinear stability theory. In both models, the control actions required to track a specified trajectory are adaptively assembled from a large collection of simple computational elements. By adaptively recombining these elements, the controllers develop complex internal models which are used to compensate for the effects of externally imposed forces or changes in the physical properties of the system. On a motor learning task involving planar, multi-joint arm motions, the simulated performance of the mathematical model is shown to be qualitatively similar to observed human performance, suggesting that the model captures some of the interesting features of the dynamics of low-level motor adaptation.},
	number = {5},
	journal = {Biol. Cybern.},
	author = {Sanner, R M and Kosha, M},
	month = may,
	year = {1999},
	keywords = {Jun 12 import},
	pages = {369--382},
}

@article{singer_dynamical_1994,
	title = {Dynamical encoding of cursive handwriting},
	volume = {71},
	abstract = {A model-based approach to on-line cursive handwriting analysis and recognition is presented and evaluated. In this model, on-line handwriting is considered as a modulation of a simple cycloidal pen motion, described by two coupled oscillations with a constant linear drift along the line of the writing. By slow modulations of the amplitudes and phase lags of the two oscillators, a general pen trajectory can be efficiently encoded. These parameters are then quantized into a small number of values without altering the writing intelligibility. A general procedure for the estimation and quantization of these cycloidal motion parameters for arbitrary handwriting is presented. The result is a discrete motor control representation of the continuous pen motion, via the quantized levels of the model parameters. This motor control representation enables successful word spotting and matching of cursive scripts. Our experiments clearly indicate the potential of this dynamic representation for complete cursive handwriting recognition.},
	number = {3},
	journal = {Biol. Cybern.},
	author = {Singer, Y and Tishby, N},
	year = {1994},
	keywords = {Jun 12 import},
	pages = {227--237},
}

@article{gottlieb_organizing_1989,
	title = {Organizing principles for single-joint movements. {I}. {A} speed-insensitive strategy},
	volume = {62},
	abstract = {1. Normal human subjects made discrete elbow flexions and extensions in the horizontal plane from a stationary initial position to visually defined targets at different distances with a constant inertial load or made flexions to a visually defined target with different inertial loads. We measured joint angle, acceleration, and electromyograms (EMGs) from two agonist and two antagonist muscles. 2. Subjects were instructed to move their limbs accurately but quickly to the targets. Movements of greater distances or lesser loads were performed at higher velocities. 3. Peak inertial torque, acceleration and velocity, movement time, and integrated, rectified EMG were all highly correlated with the task variables, distance and inertial load. We show that peak inertial torque can be used as a linking variable that is almost sufficient to explain all correlations between the tasks, the EMG, and movement kinematics. 4. The rate at which subjects initially developed torque to accelerate their movements was invariant over changes in the value of either task variable. The rising phase of the agonist EMG was also independent of the distance or load moved. 5. Two components were distinguished in the antagonist EMG. The first had a relatively constant latency and amplitude. It terminated on the onset of the second and larger component at a latency that was delayed as both distance and load increased. 6. The integrated, rectified antagonist EMG was proportional to inertial load and peak decelerating torque for changes in inertial load. When target distance varied, proportionality between peak decelerating torque and antagonist EMG could be found if correction was made for the effects of muscle length on the torque-EMG relationship. 7. We propose organizing principles for the control of single-joint human movements in which tasks are performed by one of two strategies. These are called speed-insensitive and speed-sensitive strategies. 8. A model is described in which movements made under a speed-insensitive strategy are executed by controlling the duration and the relative timing of amplitude invariant patterns of activation to the spinal motoneuron pools.},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Gottlieb, G L and Corcos, D M and Agarwal, G C},
	month = aug,
	year = {1989},
	keywords = {Jun 12 import},
	pages = {342--357},
}

@article{corcos_organizing_1989,
	title = {Organizing principles for single-joint movements. {II}. {A} speed-sensitive strategy},
	volume = {62},
	abstract = {1. Normal human subjects made discrete flexions of the elbow over a fixed distance in the horizontal plane from a stationary initial position to a visually defined target. We measured joint angle, acceleration, and electromyograms (EMGs) from two agonist and two antagonist muscles. 2. Changes in movement speed were elicited either by explicit instruction to the subject or by adjusting the target width. Instructions always required accurately stopping in the target zone. 3. Peak inertial torques and accelerations, movement times, and integrated EMGs were all highly correlated with speed. We show that inertial torque can be used as a linking variable that is almost sufficient to explain all correlations between the task, the EMG, and movement kinematics. 4. When subjects perform tasks that require control of movement speed, they adjust the rate at which torque is developed by the muscles. This rate is modulated by the way in which the muscles are activated. The rate at which joint torque develops is correlated with the rate at which the agonist EMG rises as well as with integrated EMG. 5. The antagonist EMG shows two components. The latency of the first is 30-50 ms and independent of movement dynamics. The latency of the second component is proportional to movement time. The rate of rise and area of both components scale with torque. 6. We propose organizing principles for the control of single-joint movements in which tasks are performed by one of two strategies. These are called speed-insensitive and speed-sensitive strategies. 7. A model is proposed in which movements made under a speed-sensitive strategy are executed by controlling the intensity of an excitation pulse delivered to the motoneuron pool. The effect is to regulate the rate at which joint torque, and consequently acceleration, increases. 8. Movements of variable distance, speed, accuracy, and load are shown to be controlled by one of two consistent sets of rules for muscle activation. These rules apply to the control of both the agonist and antagonist muscles. Rules of activation lead to distinguishable patterns of EMG and torque development. All observable changes in movement kinematics are explained as deterministic consequences of these effects.},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Corcos, D M and Gottlieb, G L and Agarwal, G C},
	month = aug,
	year = {1989},
	keywords = {Jun 12 import},
	pages = {358--368},
}

@article{gottlieb_organizing_1990,
	title = {Organizing principles for single joint movements. {III}. {Speed}-insensitive strategy as a default},
	volume = {63},
	abstract = {1. Human subjects made discrete elbow flexions in a horizontal plane over different distances, from a stationary initial position to a visually defined stationary target 9 degrees wide. We measured joint angle, acceleration, and electromyograms (EMGs) from two agonist and two antagonist muscles. 2. Subjects made movements over four different distances following one of four different instructions. The first instructed the subject simply to choose a comfortable speed. The other three explicitly emphasized either speed, accuracy, or maintenance of the “same” speed over different distances. These instructions produced a wide range of movement velocities. 3. The initial rises of the acceleration (and therefore of the inertial torque), as well as the initial slope of the agonist EMG, were all invariant over changes in the target distance for any single instruction but were all sensitive to the given instruction. 4. Our results demonstrate that the speed-insensitive strategy is a standard or default pattern for performing movements that may be carried out for different instructions over a wide range of speeds. A uniform intensity of excitation pulse is not a byproduct of moving at maximal speed. Submaximal intensities are associated with submaximal speeds and are a selected feature of the pattern of movement control.},
	number = {3},
	journal = {J. Neurophysiol.},
	author = {Gottlieb, G L and Corcos, D M and Agarwal, G C and Latash, M L},
	month = mar,
	year = {1990},
	keywords = {Jun 12 import},
	pages = {625--636},
}

@article{gribble_origins_1996,
	title = {Origins of the power law relation between movement velocity and curvature: modeling the effects of muscle mechanics and limb dynamics},
	volume = {76},
	abstract = {1. When subjects trace patterns such as ellipses, the instantaneous velocity of movements is related to the instantaneous curvature of the trajectories according to a power law-movements tend to slow down when curvature is high and speed up when curvature is low. It has been proposed that this relationship is centrally planned. 2. The arm's muscle properties and dynamics can significantly affect kinematics. Even under isometric conditions, muscle mechanical properties can affect the development of muscle forces and torques. Without a model that accounts for these effects, it is difficult to distinguish between kinematic patterns that are attributable to central control and patterns that arise because of dynamics and muscle properties and are not represented in the underlying control signals. 3. In this paper we address the nature of the control signals that underlie movements that obey the power law. We use a numerical simulation of arm movement control based on the lambda version of the equilibrium point hypothesis. We demonstrate that simulated elliptical and circular movements, and elliptical force trajectories generated under isometric conditions, obey the power law even though there was no relation between curvature and speed in the modeled control signals. 4. We suggest that limb dynamics and muscle mechanics-specifically, the springlike properties of muscles-can contribute significantly to the emergence of the power law relationship in kinematics. Thus, without a model that accounts for these effects, care must be taken when making inferences about the nature of neural control.},
	number = {5},
	journal = {J. Neurophysiol.},
	author = {Gribble, P L and Ostry, D J},
	month = nov,
	year = {1996},
	keywords = {Jun 12 import},
	pages = {2853--2860},
}

@article{uno_formation_1989,
	title = {Formation and control of optimal trajectory in human multijoint arm movement. {Minimum} torque-change model},
	volume = {61},
	abstract = {In this paper, we study trajectory planning and control in voluntary, human arm movements. When a hand is moved to a target, the central nervous system must select one specific trajectory among an infinite number of possible trajectories that lead to the target position. First, we discuss what criterion is adopted for trajectory determination. Several researchers measured the hand trajectories of skilled movements and found common invariant features. For example, when moving the hand between a pair of targets, subjects tended to generate roughly straight hand paths with bell-shaped speed profiles. On the basis of these observations and dynamic optimization theory, we propose a mathematical model which accounts for formation of hand trajectories. This model is formulated by defining an objective function, a measure of performance for any possible movement: square of the rate of change of torque integrated over the entire movement. That is, the objective function CT is defined as follows: (formula; see text) We overcome this difficult by developing an iterative scheme, with which the optimal trajectory and the associated motor command are simultaneously computed. To evaluate our model, human hand trajectories were experimentally measured under various behavioral situations. These results supported the idea that the human hand trajectory is planned and controlled in accordance with the minimum torque-change criterion.},
	number = {2},
	journal = {Biol. Cybern.},
	author = {Uno, Y and Kawato, M and Suzuki, R},
	year = {1989},
	keywords = {Jun 12 import},
	pages = {89--101},
}

@article{flash_coordination_1985,
	title = {The coordination of arm movements: an experimentally confirmed mathematical model},
	volume = {5},
	abstract = {This paper presents studies of the coordination of voluntary human arm movements. A mathematical model is formulated which is shown to predict both the qualitative features and the quantitative details observed experimentally in planar, multijoint arm movements. Coordination is modeled mathematically by defining an objective function, a measure of performance for any possible movement. The unique trajectory which yields the best performance is determined using dynamic optimization theory. In the work presented here, the objective function is the square of the magnitude of jerk (rate of change of acceleration) of the hand integrated over the entire movement. This is equivalent to assuming that a major goal of motor coordination is the production of the smoothest possible movement of the hand. Experimental observations of human subjects performing voluntary unconstrained movements in a horizontal plane are presented. They confirm the following predictions of the mathematical model: unconstrained point-to-point motions are approximately straight with bell-shaped tangential velocity profiles; curved motions (through an intermediate point or around an obstacle) have portions of low curvature joined by portions of high curvature; at points of high curvature, the tangential velocity is reduced; the durations of the low-curvature portions are approximately equal. The theoretical analysis is based solely on the kinematics of movement independent of the dynamics of the musculoskeletal system and is successful only when formulated in terms of the motion of the hand in extracorporal space. The implications with respect to movement organization are discussed.},
	number = {7},
	journal = {J. Neurosci.},
	author = {Flash, T and Hogan, N},
	month = jul,
	year = {1985},
	keywords = {Jun 12 import},
	pages = {1688--1703},
}

@article{fitts_information_1964,
	title = {Information capacity of discrete motor responses},
	volume = {67},
	abstract = {The effects of response amplitude and terminal accuracy on 2-choice reaction time (RT) and on movement time (MT) were studied. Both the required amplitude (A) of a movement, and the width (W) of the target that S was required to hit, had a large and systematic effect on MT, whereas they had a relatively small effect on RT. Definind an index of movement difficulty as ID = log\_2 2A/W, the correlation between ID and MT was found to be above .99 over the ID rage from 2.6 to 7.6 bits per response. Thus the times for discrete movements follow the same type of law as was found earlier to hold for serial responses. The relative independence of RT and MT is interpreted as pointing to the serial and independent nature of perceptual and motor processes.},
	number = {2},
	journal = {J. Exp. Psychol.},
	author = {Fitts, Paul M and Peterson, James R},
	month = feb,
	year = {1964},
	keywords = {Jun 12 import},
	pages = {103--112},
}

@article{krylow_role_1997,
	title = {Role of intrinsic muscle properties in producing smooth movements},
	volume = {44},
	abstract = {Human upper limb movement trajectories have been shown to be quite smooth, in that time derivatives of end point position (r), including d3r/dt3 (i.e., jerk), appear to be minimized during rapid voluntary reaching tasks. Studies have suggested that these movements are implemented by an optimal neural controller which seeks to minimize a cost function, such as average jerk cost, over the course of these motions. While this hypothetical control strategy is widely supported, there are substantial difficulties associated with implementing such a controller, including ambiguities inherent in transformations from Cartesian to joint coordinates, and the lack of appropriate transducers to provide information about higher derivatives of limb motion to the nervous system. Given these limitations, we evaluate the possibility that smoothing of movement might be induced primarily by the intrinsic mechanical properties of muscle by recording the trajectories of inertially loaded muscle with the excitatory input held constant. These trajectories are compared with those predicted by a minimum-jerk optimization model, and by a Hill-based muscle model. Our results indicate that trajectories produced by inertially loaded muscle alone are smooth (in the minimum-jerk sense), and that muscle properties may suffice to account for much of the observed smoothing of voluntary motion, obviating the need for an optimizing neural strategy.},
	number = {2},
	journal = {IEEE Trans. Biomed. Eng.},
	author = {Krylow, A M and Rymer, W Z},
	month = feb,
	year = {1997},
	keywords = {Jun 12 import},
	pages = {165--176},
}

@article{hasan_model_1983,
	title = {A model of spindle afferent response to muscle stretch},
	volume = {49},
	abstract = {1. A unified model of the properties of stretch responses of mammalian spindle endings is proposed. This model encompasses the disparity between sensitivity of spindle endings to small and to large stretch of the muscle as well as the disparity in their dynamic responsiveness for different amplitudes of stretch. 2. In the model the mechanical properties of intrafusal fibers include a property akin to friction, which is hypothesized on the basis of reported observations on amphibian muscle. Transducer and encoder processes are modeled in the light of recent observations on isolated spindles. The model involves five unknown parameters whose values are selected by reference to certain reported observations on deefferented primary and secondary endings. The model can be used to predict responses to length changes of arbitrary time course. 3. Predicted responses to large ramp-and-hold stretch are quantitatively comparable to observations over a wide range of stretch velocities. The quantities compared include the increment in response during ramp stretch as well as the dynamic index, which is a measure of adaptation at stretch plateau. 4. At a fixed frequency of sinusoidal stretch, the relation between amplitudes of stretch and response is predicted in quantitative agreement with measurements. As the frequency of stretch is decreased, the predicted phase lead decreases and then increases, while the sensitivity decreases monotonically, in accord with observations. 5. In the model the high sensitivity for small stretch is not specific to any particular length of the muscle. When stretch is large, the region of high sensitivity is gradually reestablished at the new length, a phenomenon referred to as resetting. The dynamic response to a large stretch can be seen as arising, for the most part, from the dynamic process of resetting. 6. The influences of static or dynamic fusimotor activation on stretch responses of the primary ending are simulated by modifying the parameter values in the model. The modifications are such that static (dynamic) fusimotor activity speeds up (slows down) the resetting of the high-sensitivity region. The predictions mimic qualitatively the observed fusimotor effects not only on the response to large ramp stretch but also the contrasting effects seen with smaller, sinusoidal stretch.},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Hasan, Z},
	month = apr,
	year = {1983},
	keywords = {Jun 12 import},
	pages = {989--1006},
}

@article{brown_mechanics_1996,
	title = {Mechanics of feline soleus: {II}. {Design} and validation of a mathematical model},
	volume = {17},
	abstract = {We have developed a mathematical model to describe force production in cat soleus during steady-state activation over a range of fascicle lengths and velocities. The model was based primarily upon a three element design by Zajac but also considered the many different features present in other previously described models. We compared quantitatively the usefulness of these features and putative relationships to account for a set of force and length data from cat soleus wholemuscle described in a companion paper. Among the novel features that proved useful were the inclusion of a short-length passive force resisting compression, a new normalisation constant for connective-tissue lengths to replace the potentially troublesome slack length, and a new length dependent term for lengthening velocities in the force-velocity relationship. Each feature of this model was chosen to provide the most accurate description of the data possible without adding unneeded complexity. Previously described functions were compared with novel functions to determine the best description of the experimental data for each of the elements in the model.},
	number = {2},
	journal = {J. Muscle Res. Cell Motil.},
	author = {Brown, I E and Scott, S H and Loeb, G E},
	month = apr,
	year = {1996},
	keywords = {Jun 12 import},
	pages = {221--233},
}

@article{mussa-ivaldi_neural_1985,
	title = {Neural, mechanical, and geometric factors subserving arm posture in humans},
	volume = {5},
	abstract = {When the hand is displaced from an equilibrium posture by an external disturbance, a force is generated to restore the original position. We developed a new experimental method to measure and represent the field of elastic forces associated with posture of the hand in the horizontal plane. While subjects maintained a given posture, small displacements of the hand along different directions were delivered by torque motors. The hand was held in the displaced positions and, at that time, we measured the corresponding restoring forces before the onset of any voluntary reaction. The stiffness in the vicinity of the hand equilibrium position was estimated by analyzing the force and displacement vectors. We chose to represent the stiffness both numerically, as a matrix, and graphically, as an ellipse characterized by three parameters: magnitude (the area), shape (the ratio of axis) and orientation (direction of the major axis). The latter representation captures the main geometrical features of the elastic force field associated with posture. We also evaluated the conservative and nonconservative components of this elastic force field. We found that the former were much larger than the latter and concluded that the behavior of the neuromuscular system of the multiarticular arm is predominantly spring-like. Our data indicated that the shape and orientation of the stiffness were invariant over subjects and over time. We also investigated the ability of our subjects to produce voluntary and adaptive changes in the stiffness. Our findings indicated that, when a disturbance acting along a fixed and predictable direction was imposed, the magnitude of the stiffness was increased but only minor changes in shape and orientation occurred. Taken together, all of these experiments represent a step toward the understanding of the interactions between geometrical and neural factors involved in maintaining hand posture and its interactions with the environment.},
	number = {10},
	journal = {J. Neurosci.},
	author = {Mussa-Ivaldi, F A and Hogan, N and Bizzi, E},
	month = oct,
	year = {1985},
	keywords = {Jun 12 import},
	pages = {2732--2743},
}

@article{bizzi_mechanical_1982,
	title = {Mechanical {Properties} of {Muscles}: {Implications} for {Motor} {Control}},
	volume = {5},
	abstract = {Recent experiments suggest a simple relationship between posture and movement. Posture appears to result from the CNS setting the activity level of agonist and antagonist muscles around the joint, resulting in an equilibrium force, the ratios of which are different for different positions. Control of movement is accomplished by changing the set of opposing length/tension curves. However, the experimental evidence also indicates that during movement there is active control of the trajectory, in addition to control of final position. A simple strategy of choosing a new posture via the length/tension curves and letting a limb move until equilibrium is established is not the control algorithm used by the vertebrate motor system.},
	number = {11},
	journal = {TINS},
	author = {Bizzi, Emilio and Chapple, William and Hogan, Neville},
	month = nov,
	year = {1982},
	keywords = {Jun 12 import},
	pages = {395--398},
}

@article{mcintyre_servo_1993,
	title = {Servo {Hypothesis} for the {Biological} {Control} of {Movement}},
	volume = {25},
	abstract = {An analysis is made of equilibrium-point models for motor control, describing these models in the context of servo control mechanisms. We considered issues of speed and stiffness scaling that are incompatible with current formulations of the equilibrium-point models. A modification of the equilibrium-point models is proposed in which the central nervous system controls velocity as well as positions during the course of fast limb movements. Numerical simulations are presented to verify that such a servo control mechanism could successfully produce fast limb movements, as observed in human subjects.},
	number = {3},
	journal = {J. Mot. Behav.},
	author = {McIntyre, Joseph and Bizzi, Emilio},
	year = {1993},
	keywords = {Jun 12 import, elbow movements, equilibrium-point hypothesis, human arm movements, motor control},
	pages = {193--202},
}

@article{shadmehr_postural_1993,
	title = {Postural force fields of the human arm and their role in generating multijoint movements},
	volume = {13},
	abstract = {When a perturbation displaces the human hand from equilibrium, arm muscles respond by producing restoring forces. When a set of displacements are given at various directions from the same equilibrium position, the resulting restoring forces form a “postural force field.” It is not known whether these postural forces are related to those generated when a reaching movement is executed. However, if a movement is a consequence of a shift of the equilibrium position of the hand toward the target, then, from the postural force field, predictions can be made regarding the nature of the elastic forces acting on the hand during the movement. We have taken the first steps in testing this hypothesis by measuring the postural force field of a subject's arm over relatively large distances, and comparing these forces with the static forces generated at the hand while the subject attempted a reaching movement. Using a robot manipulandum, the hand was displaced at various directions from an equilibrium position. The measured restoring forces were fitted to a nonlinear model to define a postural force field for that equilibrium position. This field was used to predict elastic forces generated when the subject attempted to move the manipulandum from a point on the circumference of a circle to a target at its center–the center corresponded to the equilibrium position at which the postural field was measured. In some of the movement trials, the manipulandum was locked during approximately the first 120 msec of the program for motion and the resulting static “evoked” forces measured. We found that (1) the evoked forces did not point to the target, but were a function of the configuration of the arm and rotated with the shoulder joint, and (2) the magnitude of the evoked forces varied systematically, even though the movements were of the same magnitude. These patterns were remarkably similar to those observed in the postural forces. Our results provide experimental evidence linking maintenance of posture in a multijoint system to that of generating a movement. The evidence is consistent with the hypothesis that the CNS programs a reaching movement by shifting the equilibrium position of the hand toward the target.},
	number = {1},
	journal = {J. Neurosci.},
	author = {Shadmehr, R and Ivaldi, Mussa-Fa and Bizzi, E},
	month = jan,
	year = {1993},
	keywords = {Jun 12 import},
	pages = {45--62},
}

@article{wiesendanger_why_1975,
	title = {Why transcortical reflexes?},
	volume = {2},
	abstract = {Experiments in humans and in monkeys have indicated that load perturbations, occurring during voluntary movements and postural activity, may be automatically compensated for. Overall muscle stiffness opposing load changes is determined by the visco-elastic properties of the muscle, by segmental reflex actions and finally by long-loop reflexes. Under certain circumstances, for instance when the subject or the experimental monkey is “prepared” to counteract perturbations which are unpredictable in time, the long-loop “reflexes” appear to be responsible for most of the corrective muscle tension. Experiments in anaesthetized monkeys revealed that signals from stretch afferents reach neurons of the motor cortex, possibly via a relay in the cortical area 3a. The latencies of these responses to well controlled muscle stretches were in the same range as motor cortical cell discharges recorded in alert monkeys subjected to load perturbations. Furthermore, these responses of cells in the motor cortex also had the appropriate timing to indicate a causal relationship with the long-latency electromyographic responses to load changes referred to above. These experimental results therefore strongly support the hypothesis, first proposed by Phillips (1969), of a transcortical servo-loop adjusting motor cortical output according to the load conditions in which movements are performed. The major advantage of transcortical regulations as opposed to segmental regulations, seems to be a powerful gain control acting at the cortical level; it was repeatedly shown that the long-loop reflexes are strongly modifiable and under voluntary control. It is suggested that an adaptive gain control at the cortical level is a prerequisite to preserve the complex capabilities of the motor cortex as the chief “executive” for skilled, preprogrammed movements. A loss of this adaptive gain control may be, at least partly, the cause of motor disorders such as rigidity in Parkinsonian patients, as reported by Tatton and Lee (1975). It is suggested that further investigations of the control of transcortical reflexes may aid in the understanding of the pathophysiology of motor disabilities.},
	number = {3},
	journal = {Can. J. Neurol. Sci.},
	author = {Wiesendanger, M and Ruegg, D G and Lucier, G E},
	month = aug,
	year = {1975},
	keywords = {Jun 12 import},
	pages = {295--301},
}

@article{flash_control_1987,
	title = {The control of hand equilibrium trajectories in multi-joint arm movements},
	volume = {57},
	abstract = {According to the equilibrium trajectory hypothesis, multi-joint arm movements are achieved by gradually shifting the hand equilibrium positions defined by the neuromuscular activity. The magnitude of the force exerted on the arm, at any time, depends on the difference between the actual and equilibrium hand positions and the stiffness and viscosity about the equilibrium position. The purpose of this paper is to test the validity and implications of this hypothesis in the context of reaching movements. A mathematical description of the behavior of an arm tracking the equilibrium trajectory was developed and implemented in computer simulations. The joint stiffness parameters used in these simulations were derived from experimentally measured static stiffness values. The kinematic features of hand equilibrium trajectories which were derived from measured planar horizontal movements gave rise to the suggestion that the generation of reaching movements involves explicit planning of spatially and temporally invariant hand equilibrium trajectories. This hypothesis was tested by simulating actual arm movements based on hypothetical equilibrium trajectories. The success of the predicted behavior in capturing both the qualitative features and the quantitative kinematic details of the measured movements supports the equilibrium trajectory hypothesis. The control strategy suggested here may allow the motor system to avoid some of the complicated computational problems associated with multi-joint arm movements.},
	number = {4-5},
	journal = {Biol. Cybern.},
	author = {Flash, T},
	year = {1987},
	keywords = {Jun 12 import},
	pages = {257--274},
}

@article{hore_evidence_1986,
	title = {Evidence that a disordered servo-like mechanism contributes to tremor in movements during cerebellar dysfunction},
	volume = {56},
	abstract = {The characteristics of discontinuities and tremor that occurred in elbow flexions during cooling of the lateral cerebellar nuclei were investigated in five Cebus monkeys. Discontinuities in movements appeared as rhythmical oscillations (kinetic tremor) when movements were slow or when movements were made with a constant force that loaded the antagonist. These oscillations had similar properties to cerebellar terminal tremor following movements; e.g., their amplitude and frequency were decreased by addition of mass to the handle and they occurred in the absence of visual feedback. The abnormal initial decrease in velocity that initiated oscillations in flexion movements was associated with abnormally early or large antagonist (triceps) electromyogram (EMG) activity. This abnormal EMG activity did not follow the normal inverse relation between initial velocity and antagonist latency from onset of movement. The initial deflection from the expected trajectory was opposed by a second burst of EMG activity in the agonist (biceps). This second burst was not the continuation of a step of EMG activity because its amplitude was often larger than the amplitude of the first agonist burst. The second agonist burst had the properties of a servo-like response: it occurred when biceps shortening was slowed (but biceps was not stretched), its magnitude was proportional to the magnitude or the deflection in velocity, its latency was 50-80 ms from onset of the abnormal decrease in velocity, and it occurred in the absence of visual feedback. However, this servo-like response was disordered because it did not return the limb accurately to the expected trajectory. The servo-like mechanism was studied further by applying torque pulse perturbations during elbow flexions. When the cerebellar nuclei were cooled, agonist responses to the perturbation were proportional to the size of the velocity deflection, but they were prolonged and onset of antagonist activity was delayed. It is suggested that discontinuities and tremor in movements during cerebellar dysfunction result from the same mechanism: alternation between disordered stretch reflexes and disordered servo-assistance mechanisms, both partly involving transcortical pathways.},
	number = {1},
	journal = {J. Neurophysiol.},
	author = {Hore, J and Flament, D},
	month = jul,
	year = {1986},
	keywords = {Jun 12 import},
	pages = {123--136},
}

@article{gomi_equilibrium-point_1996,
	title = {Equilibrium-point control hypothesis examined by measured arm stiffness during multijoint movement},
	volume = {272},
	abstract = {For the last 20 years, it has been hypothesized that well-coordinated, multijoint movements are executed without complex computation by the brain, with the use of springlike muscle properties and peripheral neural feedback loops. However, it has been technically and conceptually difficult to examine this “equilibrium-point control” hypothesis directly in physiological or behavioral experiments. A high-performance manipulandum was developed and used here to measure human arm stiffness, the magnitude of which during multijoint movement is important for this hypothesis. Here, the equilibrium-point trajectory was estimated from the measured stiffness, the actual trajectory, and the generated torque. Its velocity profile differed from that of the actual trajectory. These results argue against the hypothesis that the brain sends as a motor command only an equilibrium-point trajectory similar to the actual trajectory.},
	number = {5258},
	journal = {Science},
	author = {Gomi, H and {Kawato}},
	month = apr,
	year = {1996},
	keywords = {Jun 12 import},
	pages = {117--120},
}

@article{miall_is_1993,
	title = {Is the {Cerebellum} a {Smith} {Predictor}?},
	volume = {25},
	abstract = {The motor system may use intemal predictive models of the motor apparatus to achieve better control than would be possible by negative feedback. Several theories have proposed that the cerebellum may form these predictive representations, In this article, we review these theories and try to unify them by reference to an engineering control model known as a Smith Pre dictor. We suggest that the cerebellum forms two types of internal model. One model is a forward predictive model of the motor apparatus (e.g. , limb and muscle), providing a rapid prediction of the sensory consequences of each movement. The second model is of the time delays in the control loop (due to receptor and effec-tor delays, axona] conductances, and cognitive processing de-lays). This model delays a copy of the rapid prediction so that it can be compared in temporal register with actual sensory feedback from the movement. The result of this comparison is used both to correct for errors in perf.ormance and as a training signal to learn the first model We discuss evidence that the cerebellum could form both of these models and suggest that the cerebellum may hold at least two separate Smith Predictors. One, in the lateral cerebellum, would predict the movement outcome in visual, ego-centric, or peripersonaJ coordinates. Another, in the intermediate cerebellum, would predict the consequences in motor coordinates. Generalization of the Smith Predictor theory is discussed in ]ight of cerebellar involvement in nonmotor control systems, including autonomic functions and cognition.},
	number = {3},
	journal = {J. Mot. Behav.},
	author = {Miall, R C and Weir, D J and Wolpert, D M and Stein, J F},
	year = {1993},
	keywords = {cerebellum, Jun 12 import, internal models, tracking},
	pages = {203--216},
}

@incollection{hore_cerebellar-dependent_1984,
	title = {A {Cerebellar}-dependent {Efference} {Copy} {Mechanism} for {Generating} {Appropriate} {Muscle} {Responses} to {Limb} {Perturbations}},
	booktitle = {Cerebellar {Functions}},
	publisher = {Springer-Verlag},
	author = {Hore, J and Vilis, T},
	year = {1984},
	keywords = {Jun 12 import},
}

@article{katayama_virtual_1993,
	title = {Virtual trajectory and stiffness ellipse during multijoint arm movement predicted by neural inverse models},
	volume = {69},
	abstract = {We predict the virtual trajectories and stiffness ellipses during multijoint arm movements by computer simulations. A two-link manipulator with four single-joint muscles and two double-joint muscles is used as a model of the human arm. Physical parameters of the model are derived from several experimental data. Among them, special emphasis is put on low values of the dynamic hand stiffness recently measured during single-joint and multijoint movements. The feedback-error-learning scheme to acquire the inverse dynamics model and the inverse statics model is utilized for this prediction. The virtual trajectories are much more complex than the actual trajectories. This indicates that planning the virtual trajectory is as difficult as solving the inverse dynamics problem for medium and fast movements, and simply falsifies the advocated computational advantage of the virtual trajectory control hypothesis. Thus, we conclude that learning inverse models is essential even in the virtual trajectory control framework. Finally, we propose a new computational model to learn the complicated shape of the virtual trajectories by integrating the virtual trajectory control and the feedback-error-learning scheme.},
	number = {5-6},
	journal = {Biol. Cybern.},
	author = {Katayama, M and Kawato, M},
	year = {1993},
	keywords = {Jun 12 import},
	pages = {353--362},
}

@article{feldman_composition_1981,
	title = {The composition of central programs subserving horizontal eye movements in man},
	volume = {42},
	abstract = {A hypothesis is presented which describes, in biomechanical terms, the central programs underlying horizontal eye movements in man. It is suggested that eye movements are produced by means of programmed shifts of the so-called invariant muscle characteristics (static force vs angle phi of gaze). These shifts lead to a change of the equilibrium point resulting from the interaction of agonist and antagonist muscles and, as a consequence, to movement and the attainment of a new position of gaze. A reciprocal or a coactivation command to agonist and antagonist muscles occurs when their characteristics shift with respect to the coordinate phi in the same or opposite directions, respectively. It is proposed that during pursuit and saccadic eye movements a superposition of the both central commands occurs. During a saccade, the reciprocal command develops evenly up to a certain level. The initial and final levels of the reciprocal command dictate the respective position of gaze and therefore the size of the saccade. The coactivation command develops to a maximum level and is slowly switched off when the new position of gaze has been achieved. The magnitude of the coactivation command seems to be not connected with an absolute position of gaze. It provides probably a stability of the movement and, in particular, prevents overshoot and oscillation during the saccade. The same timing of these commands occurs during pursuit movements, but the magnitude of the coactivation command and the rates of the development of the both commands are less in this case and correlate with the velocity of the movement. This hypothesis enables the tension changes in the muscle during saccadic and pursuit movements to be simulated in qualitative accordance with unique experimental data obtained by Collins et al. (1975). The functional significance of superposition of these motor commands and similarity in the efferent organization of eye and limb movements are discussed. Analysis of limb movements in man and animals has allowed one to formulate some concepts concerning the motor control. For instance, it has been suggested and experimentally confirmed that central commands are adequately expressed in terms of shifts of muscle static length - force characteristics and specify an equilibrium point resulting from the interaction of agonist and antagonist muscles (Asatryan and Feldman, 1965; Felman, 1966a, 1974, 1979, 1980a, b; Bizzi et al., 1976; Kelso, 1977; Polit and Bizzi, 1978, 1979; Houk, 1979; Kelso and Holt, 1980). Experimental observation have also shown that two central commands, i.e. reciprocal and unidirectional activation of agonist and antagonist muscles are usually combined by the nervous system in a proper manner depending on the motor task (Feldman, 1979, 1980a, b). The present, theoretical report is designed to show that these concepts are consistent with available experimental data concerning oculomotor control.},
	number = {2},
	journal = {Biol. Cybern.},
	author = {Feldman, A G},
	year = {1981},
	keywords = {Jun 12 import},
	pages = {107--116},
}

@article{taga_model_1998,
	title = {A model of the neuro-musculo-skeletal system for anticipatory adjustment of human locomotion during obstacle avoidance},
	volume = {78},
	abstract = {Theoretical studies on human locomotion have shown that a stable and flexible gait emerges from the dynamic interaction between the rhythmic activity of a neural system composed of a neural rhythm generator (RG) and the rhythmic movement of the musculo-skeletal system. This study further explores the mechanism of the anticipatory control of locomotion based on the emergent properties of a neural system that generates the basic pattern of gait. A model of the neuro-musculo-skeletal system to execute the task of stepping over a visible obstacle with both limbs during walking is described. The RG in the neural system was combined with a system referred to as a discrete movement generator (DM), which receives both the output of the RG and visual information regarding the obstacle and generates discrete signals for modification of the basic gait pattern. A series of computer simulations demonstrated that an obstacle placed at an arbitrary position can be cleared by sequential modifications of gait: (1) modulating the step length when approaching the obstacle and (2) modifying the trajectory of the swing limbs while stepping over it. This result suggests that anticipatory adjustments are produced not by the unidirectional flow of the information from visual signals to motor commands but by the bi-directional circulation of information between the DM and the RG. The validity of this model is discussed in relation to motor cortical activity during anticipatory modifications in cats and the ecological psychology of visuo-motor control in humans.},
	number = {1},
	journal = {Biol. Cybern.},
	author = {Taga, G},
	month = jan,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {9--17},
}

@article{taga_model_1995,
	title = {A model of the neuro-musculo-skeletal system for human locomotion. {I}. {Emergence} of basic gait},
	volume = {73},
	abstract = {The generation of human locomotion was examined by linking computational neuroscience with biomechanics from the perspective of nonlinear dynamical theory. We constructed a model of human locomotion, which includes a musculo-skeletal system with 8 segments and 20 muscles, a neural rhythm generator composed of 7 pairs of neural oscillators, and mechanisms for processing and transporting sensory and motor signals. Using a computer simulation, we found that locomotion emerged as a stable limit cycle that was generated by the global entrainment between the musculo-skeletal system, the neural system, and the environment. Moreover, the walking movements of the model could be compared quantitatively with those of experimental studies in humans.},
	number = {2},
	journal = {Biol. Cybern.},
	author = {Taga, G},
	month = jul,
	year = {1995},
	keywords = {Jun 12 import},
	pages = {97--111},
}

@article{taga_model_1995-1,
	title = {A model of the neuro-musculo-skeletal system for human locomotion. {II} {Real}-time adaptability under various constraints},
	volume = {73},
	abstract = {Adaptive gaits of humans were produced as a result of emergent properties of a model based on the neurophysiology of the central pattern generator and the biomechanics of the human musculoskeletal system. We previously proposed a neuromusculoskeletal model for human locomotion, in which movements emerged as a stable limit cycle that was generated through the global entrainment among the neural system, composed of neural oscillators, the musculoskeletal system, and the environment. In the present study, we investigated the adaptability of this model under various types of environmental and task constraints. Using a computer simulation, it was found that walking movements were robust against mechanical perturbations, loads with a mass, and uneven terrain. Moreover, the speed of walking could be controlled by a single parameter which tonically drove the neural oscillators, and the step cycle could be entrained by a rhythmic input to the neural oscillators.},
	number = {2},
	journal = {Biol. Cybern.},
	author = {Taga, G},
	month = jul,
	year = {1995},
	keywords = {Jun 12 import},
	pages = {113--121},
}

@article{cullen_use_1996,
	title = {The use of system identification techniques in the analysis of oculomotor burst neuron spike train dynamics},
	volume = {3},
	abstract = {The objective of system identification methods is to construct a mathematical model of a dynamical system in order to describe adequately the input-output relationship observed in that system. Over the past several decades, mathematical models have been employed frequently in the oculomotor field, and their use has contributed greatly to our understanding of how information flows through the implicated brain regions. However, the existing analyses of oculomotor neural discharges have not taken advantage of the power of optimization algorithms that have been developed for system identification purposes. In this article, we employ these techniques to specifically investigate the “burst generator” in the brainstem that drives saccadic eye movements. The discharge characteristics of a specific class of neurons, inhibitory burst neurons (IBNs) that project monosynaptically to ocular motoneurons, are examined. The discharges of IBNs are analyzed using different linear and nonlinear equations that express a neuron's firing frequency and history (i.e., the derivative of frequency), in terms of quantities that describe a saccade trajectory, such as eye position, velocity, and acceleration. The variance accounted for by each equation can be compared to choose the optimal model. The methods we present allow optimization across multiple saccade trajectories simultaneously. We are able to investigate objectively how well a specific equation predicts a neuron's discharge pattern as well as whether increasing the complexity of a model is justifiable. In addition, we demonstrate that these techniques can be used both to provide an objective estimate of a neuron's dynamic latency and to test whether a neuron's initial firing rate (expressed as an initial condition) is a function of a quantity describing a saccade trajectory (such as initial eye position).},
	number = {4},
	journal = {J. Comput. Neurosci.},
	author = {Cullen, K E and Rey, C G and Guitton, D and Galiana, H L},
	month = dec,
	year = {1996},
	keywords = {Jun 12 import},
	pages = {347--368},
}

@incollection{goldberg_control_2000,
	edition = {Fourth},
	title = {The {Control} of {Gaze}},
	booktitle = {Principles of {Neural} {Science}},
	publisher = {McGraw-Hill Companies},
	author = {Goldberg, Michael E},
	editor = {Kandel, Eric R and Schwartz, James H and Jessell, Thomas M},
	year = {2000},
	note = {Section: 39},
	keywords = {Jun 12 import},
	pages = {782--800},
}

@article{buono_models_2001,
	title = {Models of central pattern generators for quadruped locomotion. {I}. {Primary} gaits},
	volume = {42},
	abstract = {In this paper we continue the analysis of a network of symmetrically coupled cells modeling central pattern generators for quadruped locomotion proposed by Golubitsky, Stewart, Buono, and Collins. By a cell we mean a system of ordinary differential equations and by a coupled cell system we mean a network of identical cells with coupling terms. We have three main results in this paper. First, we show that the proposed network is the simplest one modeling the common quadruped gaits of walk, trot, and pace. In doing so we prove a general theorem classifying spatio-temporal symmetries of periodic solutions to equivariant systems of differential equations. We also specialize this theorem to coupled cell systems. Second, this paper focuses on primary gaits; that is, gaits that are modeled by output signals from the central pattern generator where each cell emits the same waveform along with exact phase shifts between cells. Our previous work showed that the network is capable of producing six primary gaits. Here, we show that under mild assumptions on the cells and the coupling of the network, primary gaits can be produced from Hopf bifurcation by varying only coupling strengths of the network. Third, we discuss the stability of primary gaits and exhibit these solutions by performing numerical simulations using the dimensionless Morris-Lecar equations for the cell dynamics.},
	number = {4},
	journal = {J. Math. Biol.},
	author = {Buono, Pl and Golubitsky, M},
	month = apr,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {291--326},
}

@article{kawato_trajectory_1990,
	title = {Trajectory {Formation} of {Arm} {Movement} by {Cascade} {Neural} {Network} {Model} {Based} on {Minimum} {Torque}-{Change} {Criterion}},
	volume = {62},
	abstract = {We proposed that the trajectory followed by human subject arms tended to minimize the time integral of the square of the rate of change of torque (Uno et al. 1987). This minimum torque-change model predicted and reproduced human multi-joint movement data quite well (Uno et al. 1989). Here, we propose a neural network model for trajectory formation based on the minimum torque-change criterion. Basic ideas of information representation and algorithm are (i) spatial representation of time, (ii) learning of forward dynamics and kinetics model and (iii) relaxation computation based on the acquired model. The model can resolve ill-posed inverse kinematics and inverse dynamics problems for redundant controlled object as well as ill-posed trajectory formation problems. By computer simulation, we show that the model can produce a multi-joint arm trajectory while avoiding obstacles or passing through via-points.},
	journal = {Biol. Cybern.},
	author = {Kawato, M and Maeda, Y and Uno, Y and Suzuki, R},
	year = {1990},
	keywords = {Jun 12 import},
	pages = {275--288},
}

@article{hirayama_cascade_1993,
	title = {The {Cascade} {Neural} {Network} {Model} and a {Speed}-{Accuracy} {Trade}-{Off} of {Arm} {Movement}},
	volume = {25},
	abstract = {We propose a hybrid neural network model of aimed arm movements that consists of a feedforward controller and a postural controller. The cascade neural network of Kawato, Maeda, Uno, and Suzuki (1990) was employed as a computational implementation of the feedforward controller. This network computes feedforward motor commands based on a minimum torque-change criterion. If the weighting parameter of the smoothness criterion is fixed and the number of relaxation iterations is rather small, the cascade model cannot calculate the exact torque, and the hand does not reach the desired target by using the feedforward control alone. Thus, one observes an error between the final position and the desired target location. By using a fixed weighting parameter value and a limited iteration number to simulate target-directed arm movements, we found that the cascade model generated a planning time-accuracy trade-off, and a quasi-power-law type of speed-accuracy trade-off. The model provides a candidate neural mechanism to explain the stochastic variability of the time course of the feedforward motor command. Our approach also accounts for several invariant features of multijoint arm trajectories, such as roughly straight hand paths and bell-shaped speed profiles.},
	number = {3},
	journal = {J. Mot. Behav.},
	author = {Hirayama, Makato and Kawato, Mitsuo and Jordan, Michael I},
	year = {1993},
	keywords = {Jun 12 import, arm movement, Fitts' law, neural network model},
	pages = {162--174},
}

@article{todorov_direct_2000,
	title = {Direct cortical control of muscle activation in voluntary arm movements: a model},
	volume = {3},
	abstract = {What neural activity in motor cortex represents and how it controls ongoing movement remain unclear. Suggestions that cortex generates low-level muscle control are discredited by correlations with higher-level parameters of hand movement, but no coherent alternative exists. I argue that the view of low-level control is in principle correct, and that seeming contradictions result from overlooking known properties of the motor periphery. Assuming direct motor cortical activation of muscle groups and taking into account the state dependence of muscle-force production and multijoint mechanics, I show that cortical population output must correlate with hand kinematics in quantitative agreement with experimental observations. The model reinterprets the 'neural population vector' to afford unified control of posture, movement and force production.},
	number = {4},
	journal = {Nat. Neurosci.},
	author = {Todorov, E},
	month = apr,
	year = {2000},
	keywords = {Jun 12 import},
	pages = {391--398},
}

@article{nakano_quantitative_1999,
	title = {Quantitative {Examinations} of {Internal} {Representations} for {Arm} {Trajectory} {Planning}: {Minimum} {Commanded} {Torque} {Change} {Model}},
	volume = {81},
	abstract = {Nakano, Eri, Hiroshi Imamizu, Rieko Osu, Yoji Uno, Hiroaki Gomi, Toshinori Yoshioka, and Mitsuo Kawato. Quantitative Examinations of Internal Representations for Arm Trajectory Planning: Minimum Commanded Torque Change Model. J. Neurophysiol. 81: 2140-2155, 1999. Quantitative examinations of internal representations for arm trajectory planning: minimum commanded torque change model. A number of invariant features of multijoint planar reaching movements have been observed in measured hand trajectories. These features include roughly straight hand paths and bell-shaped speed profiles where the trajectory curvatures between transverse and radial movements have been found to be different. For quantitative and statistical investigations, we obtained a large amount of trajectory data within a wide range of the workspace in the horizontal and sagittal planes (400 trajectories for each subject). A pair of movements within the horizontal and sagittal planes was set to be equivalent in the elbow and shoulder flexion/extension. The trajectory curvatures of the corresponding pair in these planes were almost the same. Moreover, these curvatures can be accurately reproduced with a linear regression from the summation of rotations in the elbow and shoulder joints. This means that trajectory curvatures systematically depend on the movement location and direction represented in the intrinsic body coordinates. We then examined the following four candidates as planning spaces and the four corresponding computational models for trajectory planning. The candidates were as follows: the minimum hand jerk model in an extrinsic-kinematic space, the minimum angle jerk model in an intrinsic-kinematic space, the minimum torque change model in an intrinsic-dynamic-mechanical space, and the minimum commanded torque change model in an intrinsic-dynamic-neural space. The minimum commanded torque change model, which is proposed here as a computable version of the minimum motor command change model, reproduced actual trajectories best for curvature, position, velocity, acceleration, and torque. The model's prediction that the longer the duration of the movement the larger the trajectory curvature was also confirmed. Movements passing through via-points in the horizontal plane were also measured, and they converged to those predicted by the minimum commanded torque change model with training. Our results indicated that the brain may plan, and learn to plan, the optimal trajectory in the intrinsic coordinates considering arm and muscle dynamics and using representations for motor commands controlling muscle tensions.},
	number = {5},
	journal = {J. Neurophysiol.},
	author = {Nakano, E and Imamizu, H and Osu, R and Uno, Y and Gomi, H and Yoshioka, T and Kawato, M},
	month = may,
	year = {1999},
	keywords = {Jun 12 import},
	pages = {2140--2155},
}

@article{thoroughman_learning_2000,
	title = {Learning of action through adaptive combination of motor primitives},
	volume = {407},
	abstract = {Understanding how the brain constructs movements remains a fundamental challenge in neuroscience. The brain may control complex movements through flexible combination of motor primitives, where each primitive is an element of computation in the sensorimotor map that transforms desired limb trajectories into motor commands. Theoretical studies have shown that a system's ability to learn action depends on the shape of its primitives. Using a time-series analysis of error patterns, here we show that humans learn the dynamics of reaching movements through a flexible combination of primitives that have gaussian-like tuning functions encoding hand velocity. The wide tuning of the inferred primitives predicts limitations on the brain's ability to represent viscous dynamics. We find close agreement between the predicted limitations and the subjects' adaptation to new force fields. The mathematical properties of the derived primitives resemble the tuning curves of Purkinje cells in the cerebellum. The activity of these cells may encode primitives that underlie the learning of dynamics.},
	number = {6805},
	journal = {Nature},
	author = {Thoroughman, K A and Shadmehr, R},
	month = oct,
	year = {2000},
	keywords = {Jun 12 import},
	pages = {742--747},
}

@article{wolpert_internal_1998,
	title = {Internal models in the cerebellum},
	volume = {2},
	abstract = {This review will focus on the possiblity that the cerebellum contains an internal model or models of the motor apparatus. Inverse internal models can provide the neural command necessary to achieve some desired trajectory. First, we review the necessity of such a model and the evidence, based on the ocular following response, that the inverse models are found within the cerebellar circuitry. Forward internal models predict the consequences of actions and can be used to overcome time delays associated with feedback control. Secondly, we review the evidence that the cerebellum generates predictions using such a forward model. Finally, we review a computational model that includes multiple paired forward and inverse models and show how such an arrangement can be advantageous for motor learning and control.},
	number = {9},
	journal = {Trends Cogn. Sci.},
	author = {{Wolpert} and M., Daniel and {Miall} and \& Kawato, R c and {M.}},
	month = sep,
	year = {1998},
	keywords = {cerebellum, Jun 12 import, internal models},
	pages = {338--347},
}

@article{guenther_speech_1995,
	title = {Speech sound acquisition, coarticulation, and rate effects in a neural network model of speech production},
	volume = {102},
	abstract = {This article describes a neural network model of speech motor skill acquisition and speech production that explains a wide range of data on contextual variability, motor equivalence, coarticulation, and speaking rate effects. Model parameters are learned during a babbling phase. To explain how infants learn phoneme-specific and language-specific limits on acceptable articulatory variability, the learned speech sound targets take the form of multidimensional convex regions in orosensory coordinates. Reduction of target size for better accuracy during slower speech (in the spirit of the speed-accuracy trade-off described by Fitts� law) leads to differential effects for vowels and consonants, as seen in speaking rate experiments that have been previously taken as evidence for separate control processes for the two sound types. An account of antici-patory coarticulation is posited wherein the target for a speech sound is reduced in size based on context to provide a more efficient sequence of articulator movements. This explanation generalizes the well-known look-ahead model of coarticulation to incorporate convex region targets. Computer simulations verify the model�s properties, including linear velocity/distance relationships, motor equivalence, speaking rate effects, and carryover and anticipatory coarticulation.},
	journal = {Psychol. Rev.},
	author = {Guenther, Frank H},
	year = {1995},
	keywords = {Jun 12 import},
	pages = {594--621},
}

@article{grasso_motor_1998,
	title = {Motor patterns for human gait: backward versus forward locomotion},
	volume = {80},
	abstract = {Seven healthy subjects walked forward (FW) and backward (BW) at different freely chosen speeds, while their motion, ground reaction forces, and electromyographic (EMG) activity from lower limb muscles were recorded. We considered the time course of the elevation angles of the thigh, shank, and foot segments in the sagittal plane, the anatomic angles of the hip, knee, and ankle joints, the vertical and longitudinal ground reaction forces, and the rectified EMGs. The elevation angles were the most reproducible variables across trials in each walking direction. After normalizing the time course of each variable over the gait cycle duration, the waveforms of all elevation angles in BW gait were essentially time reversed relative to the corresponding waveforms in FW gait. Moreover, the changes of the thigh, shank, and foot elevation covaried along a plane during the whole gait cycle in both FW and BW directions. Cross-correlation analysis revealed that the phase coupling among these elevation angles is maintained with a simple reversal of the delay on the reversal of walking direction. The extent of FW-BW correspondence also was good for the hip angle, but it was smaller for the knee and ankle angles and for the ground reaction forces. The EMG patterns were drastically different in the two movement directions as was the organization of the muscular synergies measured by cross-correlation analysis. Moreover, at any given speed, the mean EMG activity over the gait cycle was generally higher in BW than in FW gait, suggesting a greater level of energy expenditure in the former task. We argue that conservation of kinematic templates across gait reversal at the expense of a complete reorganization of muscle synergies does not arise from biomechanical constraints but may reflect a behavioral goal achieved by the central networks involved in the control of locomotion.},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Grasso, R and Bianchi, L and Lacquaniti, F},
	month = oct,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {1868--1885},
}

@article{grillner_neural_1995,
	title = {Neural networks that co-ordinate locomotion and body orientation in lamprey},
	volume = {18},
	abstract = {The networks of the brainstem and spinal cord that co-ordinate locomotion and body orientation in lamprey are described. The cycle-to-cycle pattern generation of these networks is produced by interacting glutamatergic and glycinergic neurones, with NMDA receptor-channels playing an important role at lower rates of locomotion. The fine tuning of the networks produced by 5-HT, dopamine and GABA systems involves a modulation of Ca2+-dependent K+ channels, high- and low-threshold voltage-activated Ca2+ channels and presynaptic inhibitory mechanisms. Mathematical modelling has been used to explore the capacity of these biological networks. The vestibular control of the body orientation during swimming is exerted via reticulospinal neurones located in different reticular nuclei. These neurones become activated maximally at different angles of tilt.},
	number = {6},
	journal = {Trends Neurosci.},
	author = {Grillner, S and Deliagina, T and Ekeberg, O and A, Manira El and Hill, Rh and Lansner, A and Orlovsky, Gn and Wallen, P},
	month = jun,
	year = {1995},
	keywords = {Jun 12 import},
	pages = {270--279},
}

@article{bullock_cortical_1998,
	title = {Cortical networks for control of voluntary arm movements under variable force conditions},
	volume = {8},
	abstract = {A neural model of voluntary movement and proprioception is developed that offers an integrated interpretation of the functional roles of diverse cell types in movement-related areas of primate cortex. The model circuit maintains accurate proprioception while controlling voluntary reaches to spatial targets, exertion of force against obstacles, posture maintenance despite perturbations, compliance with an imposed movement, and static and inertial load compensations. Computer simulations show that properties of model elements correspond to the properties of many known cells types in areas 4 and 5. Among these properties are delay period activation, response profiles during movement, kinematic and kinetic sensitivities, and latency of activity onset. In particular, area 4 phasic and tonic cells, respectively, compute velocity and position commands that are capable of activating alpha and gamma motor neurons, thereby shifting the mechanical equilibrium point. Anterior area 5 cells compute the position of the limb using corollary discharges from area 4 and feedback from muscle spindles. Posterior area 5 neurons use the position perception signal and a target position signal to compute a desired movement vector. The cortical loop is closed by a volition-gated projection of this movement vector to the area 4 phasic cells. An auxiliary circuit allows phasic-tonic cells in area 4 to incorporate force command components needed to compensate for static and inertial loads. After reporting simulations of prior experimental results, predictions are made for both motor and parietal cell types under novel experimental protocols.},
	number = {1},
	journal = {Cereb. Cortex},
	author = {Bullock, D and Cisek, P and Grossberg, S},
	year = {1998},
	keywords = {Jun 12 import},
	pages = {48--62},
}

@article{kobayashi_temporal_1998,
	title = {Temporal firing patterns of {Purkinje} cells in the cerebellar ventral paraflocculus during ocular following responses in monkeys {II}. {Complex} spikes},
	volume = {80},
	abstract = {Many theories of cerebellar motor learning propose that complex spikes (CS) provide essential error signals for learning and modulate parallel fiber inputs that generate simple spikes (SS). These theories, however, do not satisfactorily specify what modality is represented by CS or how information is conveyed by the ultra-low CS firing rate (1 Hz). To further examine the function of CS and the relationship between CS and SS in the cerebellum, CS and SS were recorded in the ventral paraflocculus (VPFL) of awake monkeys during ocular following responses (OFR). In addition, a new statistical method using a generalized linear model of firing probability based on a binomial distribution of the spike count was developed for analysis of the ultra-low CS firing rate. The results of the present study showed that the spatial coordinates of CS were aligned with those of SS and the speed-tuning properties of CS and SS were more linear for eye movement than retinal slip velocity, indicating that CS contain a motor component in addition to the sensory component identified in previous studies. The generalized linear model to reproduce firing probability confirmed these results, demonstrating that CS conveyed high-frequency information with its ultra-low firing frequency and conveyed both sensory and motor information. Although the temporal patterns of the CS were similar to those of the SS when the sign was reversed and magnitude was amplified approximately 50 times, the velocity/acceleration coefficient ratio of the eye movement model, an aspect of the CS temporal firing profile, was less than that of the SS, suggesting that CS were more sensory in nature than SS. A cross-correlation analysis of SS that are triggered by CS revealed that short-term modulation, that is, the brief pause in SS caused by CS, does not account for the reciprocal modulation of SS and CS. The results also showed that three major aspects of the CS and SS individual cell firing characteristics were negatively correlated on a cell-to-cell basis: the preferred direction of stimulus motion, the mean percent change in firing rate induced by upward stimulus motion, and patterns of temporal firing probability. These results suggest that CS may contribute to long-term interactions between parallel and climbing fiber inputs, such as long-term depression and/or potentiation.},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Kobayashi, Y and Kawano, K and Takemura, A and Inoue, Y and Kitama, T and Gomi, H and Kawato, M},
	month = aug,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {832--848},
}

@article{gomi_temporal_1998,
	title = {Temporal firing patterns of {Purkinje} cells in the cerebellar ventral paraflocculus during ocular following responses in monkeys {I}. {Simple} spikes},
	volume = {80},
	abstract = {The simple-spike firing frequency of 30 Purkinje cells (P cells) in the ventral paraflocculus (VPFL) of alert monkeys was studied in relation to vertical slow eye movements, termed ocular following response (OFR), induced by large-field visual motions of different velocities and durations. To quantitatively analyze the relationship between eye movement and firing frequency, an inverse dynamics representation of the eye movement was used for reconstructing the temporal waveform of firing. Coefficients of eye-acceleration, velocity, and position, bias, and time lag between firing and eye movement were estimated by least-square error method. In the regression analyses for each stimulus condition, 86\% (146/170) of the well-modulated temporal firing patterns taken from those 30 P cells were reconstructed successfully from eye movement. The model with acceleration, velocity, and position terms, which we used, was shown as the best among several potential models by Cp statistics, consistent with t-test of significance of each term. Reliable coefficients were obtained from 75\% (109/146) of the well-reconstructed firing patterns of 28 cells among 30. The estimated coefficients were larger (statistically significant) for slow stimuli than for fast stimuli, suggesting changes in sensitivities under different conditions. However, firing patterns of each cell under several different conditions were frequently well reconstructed by an inverse dynamics representation with a single set of coefficients (13 cells among 21). This indicates that the relationships between P cell firing and OFR are roughly linear in those stimulus ranges. The estimated coefficients for acceleration and velocity suggested that the VPFL P cells properly encode the dynamic components of the motor command during vertical OFR. As for the positional component, however, these P cells are correlated with eye movement in the opposite direction. In the regression analysis without positional component, remarkable differences between observed and reconstructed firing patterns were noted especially in the initial phase of the movements, indicating that the negative positional component was not negligible during OFR. Thus we conclude that, during OFR, the VPFL P cells cannot provide the necessary final motor command, and other brain regions, downstream neural structures, or other types of P cells must provide lacking position-dependent motor commands. This finding about the negative correlation with the position is in the opposite sign with previous studies obtained from the fixation and the smooth pursuit movement. From these comparisons, how the VPFL contributes to a part of the final motor command or how other brain regions complement the VPFL is suggested to be different for early and late phases of the movements.},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Gomi, H and Shidara, M and Takemura, A and Inoue, Y and Kawano, K and Kawato, M},
	month = aug,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {818--831},
}

@article{shidara_inverse-dynamics_1993,
	title = {Inverse-dynamics model eye movement control by {Purkinje} cells in the cerebellum},
	volume = {365},
	abstract = {Many lines of evidence suggest that the cerebellum is involved in motor control. But what features of these movements are encoded by cerebellar neurons? For slow-tracking eye movements, the activity of Purkinje cells in the ventral paraflocculus of the cerebellum is known to be correlated with eye velocity and acceleration. Here we show that the complex temporal pattern of the firing frequency that occurs during the ocular following response elicited by movements of a large visual scene can be reconstructed by an inverse-dynamics representation, which uses the position, velocity and acceleration of eye movements. Further analysis reveals that the velocity and acceleration components can provide appropriate dynamic drive signals to ocular motor neurons, whereas the position component often has the wrong polarity. We conclude that these Purkinje cells primarily contribute dynamic command signals.},
	number = {6441},
	journal = {Nature},
	author = {Shidara, M and Kawano, K and Gomi, H and Kawato, M},
	month = sep,
	year = {1993},
	keywords = {Jun 12 import},
	pages = {50--52},
}

@inproceedings{schaal_programmable_1998,
	title = {Programmable {Pattern} {Generators}},
	abstract = {This paper explores the idea to create complex human-like arm movements from movement primitives based on nonlinear attractor dynamics. Each degree-of-freedom of an arm is assumed to have two independent abilities to create movement, one through a discrete dynamic system, and one through a rhythmic system. The discrete system creates point-to-point movements based on internal or external target specifications. The rhythmic system can add an additional oscillatory movement relative to the current position of the discrete system. In the present study, we develop appropriate dynamic systems that can realize the above model, motivate the particular choice of the systems from a biological and engineering point of view, and present simulation results of the performance of such movement primitives. Implementation results on a Sarcos Dexterous Arm are discussed.},
	publisher = {International Conference on Computational Intelligence in Neuroscience},
	author = {Schaal, Stefan and Sternad, Dagmar},
	year = {1998},
	keywords = {Jun 12 import},
}

@article{dietz_significance_2000,
	title = {Significance of load receptor input during locomotion: a review},
	volume = {11},
	abstract = {A basic aspect of the neuronal control of quadrupedal locomotion of cat and of bipedal stance and gait of humans concerns the antigravity function of leg extensors. In humans proprioceptive reflexes involved in the maintenance of body equilibrium depend on the presence of contact forces opposing gravity. Extensor load receptors are thought to signal changes of the projection of body's centre of mass with respect to the feet. According to observations in the cat, this afferent input probably arises from Golgi tendon organs and represents a newly discovered function of these receptors in the regulation of stance and gait. From these experiments it can be concluded that during locomotion there is a closing of Ib inhibitory and an opening of Ib extensor facilitatory paths. In humans evidence for a significant contribution of load receptor contribution to the leg muscle activation came from immersion experiments. Compensatory leg muscle activation depends on the actual body weight. Also during gait the strength of leg extensor activation during the stance phase is load dependent. In patients with Parkinson's disease there is a reduced load sensitivity and decreased leg extensor activation, which might contribute to the movement disorder. Recent experiments in paraplegic patients show that the beneficial effects of a locomotor training critically depends on the initial degree of body unloading and reloading during the course of the training period.},
	number = {2},
	journal = {Gait Posture},
	author = {Dietz, V and Duysens, J},
	month = apr,
	year = {2000},
	keywords = {Jun 12 import},
	pages = {102--110},
}

@article{allum_proprioceptive_1998,
	title = {Proprioceptive control of posture: a review of new concepts},
	volume = {8},
	abstract = {The assumption that proprioceptive inputs from the lower legs are used to trigger balance and gait movements is questioned in this review (an outgrowth of discussions initiated during the Neural Control of Movement Satellite meeting held in Cozumel, Mexico, April 1997). Recent findings presented here suggest that trunk or hip inputs may be more important in triggering human balance corrections and that proprioceptive input from the lower legs mainly helps with the final shaping and intermuscular coordination of postural and gait movements. Three major questions were considered. First, what role, if any, do lower-leg proprioceptive inputs play in the triggering of normal balance corrections? If this role is negligible, which alternative proprioceptive inputs then trigger balance corrections? Second, what is the effect of proprioceptive loss on the triggering of postural and gait movements? Third, how does proprioceptive loss affect the output of central pattern generators in providing the final shaping of postural movements? The authors conclude that postural and gait movements are centrally organized at two levels. The first level involves the generation of the basic directional-specific response pattern based primarily on hip or trunk proprioceptive input secondarily on vestibular inputs. This pattern specifies the spatial characteristics of muscle activation, that is which muscles are primarily activated, as well as intermuscular timing, that is, the sequence in which muscles are activated. The second level is involved in the shaping of centrally set activation patterns on the basis of multisensorial afferent input (including proprioceptive input from all body segments and vestibular sensors) in order that movements can adapt to different task conditions. Copyright 1998 Elsevier Science B.V.},
	number = {3},
	journal = {Gait Posture},
	author = {Allum, Jh and Bloem, Br and Carpenter, Mg and Hulliger, M and Algra, Hadders-M},
	month = dec,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {214--242},
}

@article{duysens_neural_1998,
	title = {Neural control of locomotion; {The} central pattern generator from cats to humans},
	volume = {7},
	abstract = {In the last years it has become possible to regain some locomotor activity in patients suffering from an incomplete spinal cord injury (SCI) through intense training on a treadmill. The ideas behind this approach owe much to insights derived from animal studies. Many studies showed that cats with complete spinal cord transection can recover locomotor function. These observations were at the basis of the concept of the central pattern generator (CPG) located at spinal level. The evidence for such a spinal CPG in cats and primates (including man) is reviewed in part 1, with special emphasis on some very recent developments which support the view that there is a human spinal CPG for locomotion. Copyright 1997 Elsevier Science B.V.},
	number = {2},
	journal = {Gait Posture},
	author = {Duysens, J and Crommert, De Van Hw},
	month = mar,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {131--141},
}

@article{crommert_neural_1998,
	title = {Neural control of locomotion: sensory control of the central pattern generator and its relation to treadmill training},
	volume = {7},
	abstract = {Many studies have shown that a special treadmill training is effective in restoring locomotor function in cats with a complete spinal lesion. In the last few years it has become possible to regain some locomotor activity in patients suffering from a spinal cord injury through an intense training on a treadmill, as in cats. The ideas behind this approach owe much to insights derived from studies on spinalized animals. The neural system responsible for the locomotor restoration in both cats and humans is thought to be located at spinal level and is referred to as the central pattern generator. The evidence for such a spinal central pattern generator is reviewed in part 1. An important element in the treadmill training for both spinal injured cats and humans is the provision of adequate locomotor related sensory input, which can possibly activate and/or regulate the spinal locomotor circuitry. This part of the review deals with the afferent control of the central pattern generator. Furthermore, the results of treadmill training for both cats and humans and their relation to sensory input are treated. These insights can possibly contribute to the design of a better treadmill training program for the rehabilitation of gait in spinal cord injured patients. Copyright 1998 Elsevier Science B.V. All rights reserved},
	number = {3},
	journal = {Gait Posture},
	author = {Crommert, De Van Hw and Mulder, T and Duysens, J},
	month = may,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {251--263},
}

@article{novacheck_biomechanics_1998,
	title = {The biomechanics of running},
	volume = {7},
	abstract = {This review article summarizes the current literature regarding the analysis of running gait. It is compared to walking and sprinting. The current state of knowledge is presented as it fits in the context of the history of analysis of movement. The characteristics of the gait cycle and its relationship to potential and kinetic energy interactions are reviewed. The timing of electromyographic activity is provided. Kinematic and kinetic data (including center of pressure measurements, raw force plate data, joint moments, and joint powers) and the impact of changes in velocity on these findings is presented. The status of shoewear literature, alterations in movement strategies, the role of biarticular muscles, and the springlike function of tendons are addressed. This type of information can provide insight into injury mechanisms and training strategies. Copyright 1998 Elsevier Science B.V.},
	number = {1},
	journal = {Gait Posture},
	author = {Novacheck, Tf},
	month = jan,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {77--95},
}

@article{kawato_hierarchical_1987,
	title = {A hierarchical neural-network model for control and learning of voluntary movement},
	volume = {57},
	abstract = {In order to control voluntary movements, the central nervous system (CNS) must solve the following three computational problems at different levels: the determination of a desired trajectory in the visual coordinates, the transformation of its coordinates to the body coordinates and the generation of motor command. Based on physiological knowledge and previous models, we propose a hierarchical neural network model which accounts for the generation of motor command. In our model the association cortex provides the motor cortex with the desired trajectory in the body coordinates, where the motor command is then calculated by means of long-loop sensory feedback. Within the spinocerebellum–magnocellular red nucleus system, an internal neural model of the dynamics of the musculoskeletal system is acquired with practice, because of the heterosynaptic plasticity, while monitoring the motor command and the results of movement. Internal feedback control with this dynamical model updates the motor command by predicting a possible error of movement. Within the cerebrocerebellum–parvocellular red nucleus system, an internal neural model of the inverse-dynamics of the musculo-skeletal system is acquired while monitoring the desired trajectory and the motor command. The inverse-dynamics model substitutes for other brain regions in the complex computation of the motor command. The dynamics and the inverse-dynamics models are realized by a parallel distributed neural network, which comprises many sub-systems computing various nonlinear transformations of input signals and a neuron with heterosynaptic plasticity (that is, changes of synaptic weights are assumed proportional to a product of two kinds of synaptic inputs). Control and learning performance of the model was investigated by computer simulation, in which a robotic manipulator was used as a controlled system, with the following results: (1) Both the dynamics and the inverse-dynamics models were acquired during control of movements. (2) As motor learning proceeded, the inverse-dynamics model gradually took the place of external feedback as the main controller. Concomitantly, overall control performance became much better. (3) Once the neural network model learned to control some movement, it could control quite different and faster movements. (4) The neural network model worked well even when only very limited information about the fundamental dynamical structure of the controlled system was available.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {3},
	journal = {Biol. Cybern.},
	author = {Kawato, M and Furukawa, K and Suzuki, R},
	year = {1987},
	keywords = {Jun 12 import},
	pages = {169--185},
}

@inproceedings{gomi_learning_1990,
	title = {Learning {Control} for a {Closed} {Loop} {System} using {Feedback}-{Error}-{Learning}},
	abstract = {In this paper, we propose new learning schemes using feedback-error-learning for a neural network model applied to adaptive nonlinear feedback control. Using these schemes, the actual response after learning correspond to desired responses. When the desired response in Cartesian space is required, learning impedance control is derived. The convergence properties of the neural networks are provided by averaged equation and Liapunov method. We show also some simulation results of these learning schemes.},
	publisher = {Proceedings of the 29th Conference on Decision and Control},
	author = {Gomi, Hiroaki and Kawato, Mitsuo},
	year = {1990},
	keywords = {Jun 12 import, feedback-error learning},
	pages = {3289--3294},
}

@article{sumbre_control_2001,
	title = {Control of {Octopus} {Arm} {Extension} by a {Peripheral} {Motor} {Program}},
	volume = {293},
	abstract = {For goal-directed arm movements, the nervous system generates a sequence of motor commands that bring the arm toward the target. Control of the octopus arm is especially complex because the arm can be moved in any direction, with a virtually infinite number of degrees of freedom. Here we show that arm extensions can be evoked mechanically or electrically in arms whose connection with the brain has been severed. These extensions show kinematic features that are almost identical to normal behavior, suggesting that the basic motor program for voluntary movement is embedded within the neural circuitry of the arm itself. Such peripheral motor programs represent considerable simplification in the motor control of this highly redundant appendage.},
	number = {5536},
	journal = {Science},
	author = {Sumbre, German and Gutfreund, Yoram and Fiorito, Graziano and Flash, Tamar and Hochner, Binyamin},
	month = sep,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {1845--1848},
}

@article{anderson_static_2001,
	title = {Static and dynamic optimization solutions for gait are practically equivalent},
	volume = {34},
	abstract = {The proposition that dynamic optimization provides better estimates of muscle forces during gait than static optimization is examined by comparing a dynamic solution with two static solutions. A 23-degree-of-freedom musculoskeletal model actuated by 54 Hill-type musculotendon units was used to simulate one cycle of normal gait. The dynamic problem was to find the muscle excitations which minimized metabolic energy per unit distance traveled, and which produced a repeatable gait cycle. In the dynamic problem, activation dynamics was described by a first-order differential equation. The joint moments predicted by the dynamic solution were used as input to the static problems. In each static problem, the problem was to find the muscle activations which minimized the sum of muscle activations squared, and which generated the joint moments input from the dynamic solution. In the first static problem, muscles were treated as ideal force generators; in the second, they were constrained by their force-length-velocity properties; and in both, activation dynamics was neglected. In terms of predicted muscle forces and joint contact forces, the dynamic and static solutions were remarkably similar. Also, activation dynamics and the force-length-velocity properties of muscle had little influence on the static solutions. Thus, for normal gait, if one can accurately solve the inverse dynamics problem and if one seeks only to estimate muscle forces, the use of dynamic optimization rather than static optimization is currently not justified. Scenarios in which the use of dynamic optimization is justified are suggested.},
	number = {2},
	journal = {J. Biomech.},
	author = {Anderson, Frank C and Pandy, Marcus G},
	month = feb,
	year = {2001},
	keywords = {Jun 12 import, Articular contact forces, Dynamic optimization, Gait, Muscle forces, Static optimization},
	pages = {153--161},
}

@article{full_templates_1999,
	title = {Templates and anchors: neuromechanical hypotheses of legged locomotion on land},
	volume = {202},
	abstract = {Locomotion results from complex, high-dimensional, non-linear, dynamically coupled interactions between an organism and its environment. Fortunately, simple models we call templates have been and can be made to resolve the redundancy of multiple legs, joints and muscles by seeking synergies and symmetries. A template is the simplest model (least number of variables and parameters) that exhibits a targeted behavior. For example, diverse species that differ in skeletal type, leg number and posture run in a stable manner like sagittal- and horizontal-plane spring-mass systems. Templates suggest control strategies that can be tested against empirical data. Templates must be grounded in more detailed morphological and physiological models to ask specific questions about multiple legs, the joint torques that actuate them, the recruitment of muscles that produce those torques and the neural networks that activate the ensemble. We term these more elaborate models anchors. They introduce representations of specific biological details whose mechanism of coordination is of interest. Since mechanisms require controls, anchors incorporate specific hypotheses concerning the manner in which unnecessary motion or energy from legs, joints and muscles is removed, leaving behind the behavior of the body in the low-degree-of-freedom template. Locating the origin of control is a challenge because neural and mechanical systems are dynamically coupled and both play a role. The control of slow, variable-frequency locomotion appears to be dominated by the nervous system, whereas during rapid, rhythmic locomotion, the control may reside more within the mechanical system. Anchored templates of many-legged, sprawled-postured animals suggest that passive, dynamic self-stabilization from a feedforward, tuned mechanical system can reject rapid perturbations and simplify control. Future progress would benefit from the creation of a field embracing comparative neuromechanics.},
	number = {23},
	journal = {J. Exp. Biol.},
	author = {Full, R J and Koditschek, D E},
	year = {1999},
	keywords = {Jun 12 import},
	pages = {3325--3332},
}

@article{dickinson_how_2000,
	title = {How {Animals} {Move}: {An} {Integrative} {View}},
	volume = {288},
	abstract = {Recent advances in integrative studies of locomotion have revealed several general principles. Energy storage and exchange mechanisms discovered in walking and running bipeds apply to multilegged locomotion and even to flying and swimming. Nonpropulsive lateral forces can be sizable, but they may benefit stability, maneuverability, or other criteria that become apparent in natural environments. Locomotor control systems combine rapid mechanical preflexes with multimodal sensory feedback and feedforward commands. Muscles have a surprising variety of functions in locomotion, serving as motors, brakes, springs, and struts. Integrative approaches reveal not only how each component within a locomotor system operates but how they function as a collective whole.},
	journal = {Science},
	author = {Dickinson, Michael H and Farley, Claire T and Full, Robert J and Koehl, M A R and Kram, Rodger and Lehman, Steven},
	year = {2000},
	keywords = {Jun 12 import},
	pages = {100--106},
}

@article{lee_determinants_1998,
	title = {Determinants of the center of mass trajectory in human walking and running},
	volume = {201},
	abstract = {Walking is often modeled as an inverted pendulum system in which the center of mass vaults over the rigid stance limb. Running is modeled as a simple spring-mass system in which the center of mass bounces along on the compliant stance limb. In these models, differences in stance-limb behavior lead to nearly opposite patterns of vertical movements of the center of mass in the two gaits. Our goal was to quantify the importance of stance-limb behavior and other factors in determining the trajectory of the center of mass during walking and running. We collected kinematic and force platform data during human walking and running. Virtual stance-limb compression (i.e. reduction in the distance between the point of foot-ground contact and the center of mass during the first half of the stance phase) was only 26\% lower for walking (0.091 m) than for running (0.123 m) at speeds near the gait transition speed. In spite of this relatively small difference, the center of mass moved upwards by 0.031 m during the first half of the stance phase during walking and moved downwards by 0.073 m during the first half of the stance phase during running. The most important reason for this difference was that the stance limb swept through a larger angle during walking (30.4 degrees) than during running (19.2 degrees). We conclude that stance-limb touchdown angle and virtual stance-limb compression both play important roles in determining the trajectory of the center of mass and whether a gait is a walk or a run.},
	number = {21},
	journal = {J. Exp. Biol.},
	author = {Lee, Cr and Farley, Ct},
	year = {1998},
	keywords = {Jun 12 import},
	pages = {2935--2944},
}

@article{berns_computational_1998-1,
	title = {A computational model of how the basal ganglia produce sequences},
	volume = {10},
	abstract = {We propose a systems-level computational model of the basal ganglia based closely on known anatomy and physiology. First, we assume that the thalamic targets, which relay ascending information to cortical action and planning areas, are tonically inhibited by the basal ganglia. Second, we assume that the output stage of the basal ganglia, the internal segment of the globus pallidus (Gpi), selects a single action from several competing actions via lateral interactions. Third, we propose that a form of local working memory exists in the form of reciprocal connections between the external globus pallidus (Gpe) and the subthalamic nucleus (STN). As a test of the model, the system was trained to learn a sequence of states that required the context of previous actions. The striatum, which was assumed to represent a conjunction of cortical states, directly selected the action in the GP during training. The STN-to-GP connection strengths were modified by an associative learning rule and came to encode the sequence after 20 to 40 iterations through the sequence. Subsequently, the system automatically reproduced the sequence when cued to the first action. The behavior of the model was found to be sensitive to the ratio of the striatal-nigral learning rate to the STN-GP learning rate. Additionally, the degree of striatal inhibition of the globus pallidus had a significant influence on both learning and the ability to select an action. Low learning rates, which would be hypothesized to reflect low levels of dopamine, as in Parkinson's disease, led to slow acquisition of contextual information. However, this could be partially offset by modeling a lesion of the globus pallidus that resulted in an increase in the gain of the STN units. The parameter sensitivity of the model is discussed within the framework of existing behavioral and lesion data.},
	journal = {J. Cogn. Neurosci.},
	author = {Berns, G S and Sejnowski, T J},
	year = {1998},
	keywords = {Jun 12 import},
	pages = {108--121},
}

@article{suri_dynamic_1997,
	title = {A dynamic model of motor basal ganglia functions},
	volume = {76},
	abstract = {Fast aiming movements were measured in a choice reaction paradigm in a healthy control group and in Parkinsonian patients. The patients were tested without ('off') and with 3,4-dihydroxyphenylalanine ('on') (L-dopa) medication. The movement trajectories were used to estimate the parameters of a dynamic linear model. The model is based on the functional structure of the basal ganglia-thalamocortical circuit with direct and indirect pathways linking the putamen to the basal ganglia output nuclei (Albin et al. 1989). The output of the circuit is connected to a model for the motor neuron-musculo-skeletal system. The gain kd for the direct pathway and the gain ki for the indirect pathway were estimated. They were found to be significantly decreased for Parkinsonian patients in 'off' compared with the control group. L-dopa therapy in Parkinsonian patients increased the gains of the direct and the indirect pathway almost to normal values which implies that the long-term dopamine level in the striatum was excitatory for the direct and for the indirect pathway. This result is restricted to movements of correct size. For movements of diminished size, which are typical for Parkinsonian patients, the model predicts that the dopamine level in the striatum is excitatory for the direct pathway but inhibitory for the indirect pathway. The simulated values for neuronal activities are in agreement with expected values according to the experimental data. The proposed model of the 'motor' basal ganglia thalamocortical circuit implies that information about biomechanical properties of the musculo-skeletal system is stored in the 'motor' basal ganglia-thalamocortical circuit, and that the basal ganglia are involved in computation of the desired movement amplitude.},
	number = {6},
	journal = {Biol. Cybern.},
	author = {Suri, Re and Albani, C and Glattfelder, Ah},
	month = jun,
	year = {1997},
	keywords = {Jun 12 import},
	pages = {451--458},
}

@article{won_stability_1995,
	title = {Stability properties of human reaching movements},
	volume = {107},
	abstract = {Through an experimental study of the stability properties of the human neuromuscular system while it performs simple point-to-point arm movements, this paper evaluates the concepts of equilibrium and virtual trajectories as a means of executing movement of the arm. Human subjects grasped the instrumented handle of a two-link robot manipulandum and performed specified point-to-point planar arm trajectories. Computer-controlled brakes were used to subtly change the movements by constraining the trajectory along an arc of radius equal to the length of one link of the manipulandum. Target points were arranged to lie along the arc so that the subject could complete the movement even when constrained. These situations were tested: (1) unconstrained throughout the movement, (2) constrained through the entire movement, and (3) initially constrained and then released during movement. Experimental results showed that the constraint evoked significant forces strongly oriented so as to restore the hand to the unconstrained hand path. In addition, when released from the constraint, these forces caused a strong tendency to return the hand to the unconstrained path before the end of the movement was reached. Such strong positional stability properties of the arm reinforce the notion that a moving attractor point dominates the dynamics of the arm during movement. Additionally, bounds on the shape of the virtual trajectory were found which indicate that the equilibrium point remains close to the actual movement produced. These results, showing that a controlled equilibrium point may be used for planning and coordinating multijoint movements, are consistent with an equilibrium point hypothesis.},
	number = {1},
	journal = {Exp. Brain Res.},
	author = {Won, J and Hogan, N},
	year = {1995},
	keywords = {Jun 12 import},
	pages = {125--136},
}

@article{rancourt_stability_2001,
	title = {Stability in force-production tasks},
	volume = {33},
	abstract = {Exerting a force on a mechanical system can induce mechanical instability. To overcome that instability, humans may take advantage of their upper limb mechanical impedance (e.g., hand stiffness). The authors investigated what stiffness is required to maintain static stability and how humans can achieve that stiffness in the context of the task of pushing on a pivoting stick. Results showed that the stiffness required is in the range of measured human upper limb stiffness. To avoid an ill-posed problem, one can better express the requirements for stability as a simple geometrical criterion related to the curvature of the potential energy field at the hand. A planar model of the upper limb revealed that individuals can use both hand rotational and translational stiffness to stabilize a stick. Although hand rotational stiffness does not participate in producing the axial force on the stick, it can significantly contribute to achieving a limb stiffness appropriate for maintaining static stability. Hand rotational stiffness can be important for the design of hand tools, because humans can increase it only by augmenting grip force, a biomechanical factor associated with cumulative trauma injuries of the upper extremities.},
	number = {2},
	journal = {J. Mot. Behav.},
	author = {Rancourt, D and Hogan, N},
	month = jun,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {193--204},
}

@article{hogan_mechanics_1985,
	title = {The mechanics of multi-joint posture and movement control},
	volume = {52},
	abstract = {The dependence of muscle force on muscle length gives rise to a “spring-like” behavior which has been shown to play a role in the execution of single-joint posture and movement. This paper extends this concept and considers the influence of the apparent mechanical behavior of the neural, muscular and skeletal system on the control and coordination of multiple degree of freedom posture and movement. A rigorous definition of “spring-like” behavior is presented. From it a numerically quantifiable, experimental test of spring-like behavior is formulated. It is shown that if the steady-state force-displacement behavior of a limb is not spring-like, this can only be due to the action of inter-muscular feedback, and can not be due to intrinsic muscle properties. The directional character of the spring-like behavior of a multiple degree of freedom system is described. The unique way in which synergistic coactivation of polyarticular muscles may modulate the directional properties of the spring-like behavior of a multiple degree of freedom system is explained. Dynamic aspects of postural behavior are also considered. The concept of mechanical impedance is presented as a rigorous dynamic generalisation of the postural stiffness of the limb. The inertial behavior of the system is characterised by its mobility. As with the stiffness or impedance, in the multiple degree of freedom case it has a directional property. The way in which the apparent kinematic redundancy of the musculo-skeletal system may be used to modify its dynamic behavior is explained. Whereas the inertial behavior of a single limb segment is not modifiable, it is shown that the apparent inertial behavior of a multiple degree of freedom system may be modulated by repositioning the joints. A unified description of the posture and movement of a multi-joint system is presented by defining a “virtual trajectory” of equilibrium positions for the limb which may be specified by the neuro-muscular system. The way in which this approach may lead to a simplification of some the apparent computational difficulties associated with the control of multi-joint motion is discussed.},
	number = {5},
	journal = {Biol. Cybern.},
	author = {Hogan, N},
	year = {1985},
	keywords = {Jun 12 import},
	pages = {315--331},
}

@article{hanneton_does_1997,
	title = {Does the brain use sliding variables for the control of movements},
	volume = {77},
	abstract = {Delays in the transmission of sensory and motor information prevent errors from being instantaneously available to the central nervous system (CNS) and can reduce the stability of a closed-loop control strategy. On the other hand, the use of a pure feedforward control (inverse dynamics) requires a perfect knowledge of the dynamic behavior of the body and of manipulated objects. Sensory feedback is essential both to accommodate unexpected errors and events and to compensate for uncertainties about the dynamics of the body. Experimental observations concerning the control of posture, gaze and limbs have shown that the CNS certainly uses a combination of closed-loop and open-loop control. Feedforward components of movement, such as eye saccades, occur intermittently and present a stereotyped kinematic profile. In visuo-manual tracking tasks, hand movements exhibit velocity peaks that occur intermittently. When a delay or a slow dynamics are inserted in the visuo-manual control loop, intermittent step-and-hold movements appear clearly in the hand trajectory. In this study, we investigated strategies used by human subjects involved in the control of a particular dynamic system. We found strong evidence for substantial nonlinearities in the commands produced. The presence of step-and-hold movements seemed to be the major source of nonlinearities in the control loop. Furthermore, the stereotyped ballistic-like kinematics of these rapid and corrective movements suggests that they were produced in an open-loop way by the CNS. We analyzed the generation of ballistic movements in the light of sliding control theory assuming that they occurred when a sliding variable exceeded a constant threshold. In this framework, a sliding variable is defined as a composite variable (a combination of the instantaneous tracking error and its temporal derivatives) that fulfills a specific stability criterion. Based on this hypothesis and on the assumption of a constant reaction time, the tracking error and its derivatives should be correlated at a particular time lag before movement onset. A peak of correlation was found for a physiologically plausible reaction time, corresponding to a stable composite variable. The direction and amplitude of the ongoing stereotyped movements seemed also be adjusted in order to minimize this variable. These findings suggest that, during visually guided movements, human subjects attempt to minimize such a composite variable and not the instantaneous error. This minimization seems to be obtained by the execution of stereotyped corrective movements.},
	number = {6},
	journal = {Biol. Cybern.},
	author = {Hanneton, S and Berthoz, A and Droulez, J and Slotine, Jj},
	month = dec,
	year = {1997},
	keywords = {Jun 12 import},
	pages = {381--393},
}

@inproceedings{buchanan_locomotion_1991,
	title = {Locomotion in a {Lower} {Vertebrate}: {Studies} of the {Cellular} {Basis} of {Rhythmogenesis} and {Oscillator} {Coupling}},
	abstract = {To test whether the known connectivies of neurons in the lamprey spinal cord are sufficient to account for locomotor rhytbmogenesis, a “connection- ist” neural network simulation was done using identical cells connected ac- cording to experimentally established patterns. It was demonstrated that the network oscillates in a stable manner with the same phase relation- ships among the neurons as observed in the lamprey. The model was then used to explore coupling between identical oscillators. It was concluded that the neurons can have a dual role as rhythm generators and as coordi- nators between oscillators to produce the phase relations observed among segmental oscillators during swimming.},
	publisher = {NIPS},
	author = {Buchanan, James T},
	year = {1991},
	keywords = {Jun 12 import},
	pages = {101--108},
}

@article{wolpert_perspectives_2001,
	title = {Perspectives and problems in motor learning},
	abstract = {is, in general, to improve performance. Whereas some simple species show no motor learning, the need for motor learning arises in species in which the organism s environment, body or task change. Specifically, when such changes are unpredictable, they cannot be pre-specified in a control system, and therefore flexibility in the control process is required. Movement provides the only means we have to interact with both the world and other people. Such interactions can be hard-wired or learned through experience with the environment. Learning allows us to adapt to a changing physical environment as well as to novel conventions developed by society. Here we review motor learning from a computational perspective, exploring the need for motor learning, what is learned and how it is represented, and the mechanisms of learning. We relate these computational issues to empirical studies on motor learning in humans.},
	journal = {TRENDS in Cognitive Sciences Vol. 5 No. 11 November 2001},
	author = {Wolpert, Daniel M and Ghahramani, Zoubin and Flanagan, J Randall},
	year = {2001},
	keywords = {Jun 12 import},
}

@article{anderson_dynamic_2001,
	title = {Dynamic {Optimization} of {Human} {Walking}},
	volume = {123},
	abstract = {A three-dimensional, neuromusculoskeletal model of the body was combined with dynamic optimization theory to simulate normal walking on level ground. The body was modeled as a 23 degree-of-freedom mechanical linkage, actuated by 54 muscles. The dynamic optimization problem was to calculate the muscle excitation histories, muscle forces, and limb motions subject to minimum metabolic energy expenditure per unit distance traveled. Muscle metabolic energy was calculated by summing five terms: the basal or resting heat, activation heat, maintenance heat, shortening heat, and the mechanical work done by all the muscles in the model. The gait cycle was assumed to be symmetric; that is, the muscle excitations for the right and left legs and the initial and terminal states in the model were assumed to be equal. Importantly, a tracking problem was not solved. Rather, only a set of terminal constraints was placed on the states of the model to enforce repeatability of the gait cycle. Quantitative comparisons of the model predictions with patterns of body-segmental displacements, ground-reaction forces, and muscle activations obtained from experiment show that the simulation reproduces the salient features of normal gait. The simulation results suggest that minimum metabolic energy per unit distance traveled is a valid measure of walking performance.},
	number = {5},
	journal = {J. Biomech. Eng.},
	author = {Anderson, Frank C and Pandy, Marcus G},
	month = oct,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {381--390},
}

@article{wang_learning_2001,
	title = {Learning the dynamics of reaching movements results in the modification of arm impedance and long-latency perturbation responses},
	volume = {85},
	abstract = {Some characteristics of arm movements that humans exhibit during learning the dynamics of reaching are consistent with a theoretical framework where training results in motor commands that are gradually modified to predict and compensate for novel forces that may act on the hand. As a first approximation, the motor control system behaves as an adapting controller that learns an internal model of the dynamics of the task. It approximates inverse dynamics and predicts motor commands that are appropriate for a desired limb trajectory. However, we had previously noted that subtle motion characteristics observed during changes in task dynamics challenged this simple model and raised the possibility that adaptation also involved sensory-motor feedback pathways. These pathways reacted to sensory feedback during the course of the movement. Here we hypothesize that adaptation to dynamics might also involve a modification of how the CNS responds to sensory feedback. We tested this through experiments that quantified how the motor system's response to errors during voluntary movements changed as it adapted to dynamics of a force field. We describe a nonlinear approach that approximates the impedance of the arm, i.e., force response as a function of arm displacement trajectory. We observe that after adaptation, the impedance function changes in a way that closely matches and counters the effect of the force field. This is particularly prominent in the long-latency ({\textgreater}100 ms) component of response to perturbations. Therefore, it appears that practice not only modifies the internal model with which the brain generates motor commands that initiate a movement, but also the internal model with which sensory feedback is integrated with the ongoing descending commands in order to respond to error during the movement.},
	number = {6},
	journal = {Biol. Cybern.},
	author = {Wang, Tie and Dordevic, Goran S and Shadmehr, Reza},
	year = {2001},
	keywords = {Jun 12 import},
	pages = {437--448},
}

@article{winter_stiffness_1998,
	title = {Stiffness control of balance in quiet standing},
	volume = {80},
	abstract = {Our goal was to provide some insights into how the CNS controls and maintains an upright standing posture, which is an integral part of activities of daily living. Although researchers have used simple performance measures of maintenance of this posture quite effectively in clinical decision making, the mechanisms and control principles involved have not been clear. We propose a relatively simple control scheme for regulation of upright posture that provides almost instantaneous corrective response and reduces the operating demands on the CNS. The analytic model is derived and experimentally validated. A stiffness model was developed for quiet standing. The model assumes that muscles act as springs to cause the center-of-pressure (COP) to move in phase with the center-of-mass (COM) as the body sways about some desired position. In the sagittal plane this stiffness control exists at the ankle plantarflexors, in the frontal plane by the hip abductors/adductors. On the basis of observations that the COP-COM error signal continuously oscillates, it is evident that the inverted pendulum model is severely underdamped, approaching the undamped condition. The spectrum of this error signal is seen to match that of a tuned mass, spring, damper system, and a curve fit of this “tuned circuit” yields omega n the undamped natural frequency of the system. The effective stiffness of the system, Ke, is then estimated from Ke = I omega n2, and the damping B is estimated from B = BW X I, where BW is the bandwidth of the tuned response (in rad/s), and I is the moment of inertia of the body about the ankle joint. Ten adult subjects were assessed while standing quietly at three stance widths: 50\% hip-to-hip distance, 100 and 150\%. Subjects stood for 2 min in each position with eyes open; the 100\% stance width was repeated with eyes closed. In all trials and in both planes, the COP oscillated virtually in phase (within 6 ms) with COM, which was predicted by a simple 0th order spring model. Sway amplitude decreased as stance width increased, and Ke increased with stance width. A stiffness model would predict sway to vary as Ke-0.5. The experimental results were close to this prediction: sway was proportional to Ke(-0.55). Reactive control of balance was not evident for several reasons. The visual system does not appear to contribute because no significant difference between eyes open and eyes closed results was found at 100\% stance width. Vestibular (otolith) and joint proprioceptive reactive control were discounted because the necessary head accelerations, joint displacements, and velocities were well below reported thresholds. Besides, any reactive control would predict that COP would considerably lag (150-250 ms) behind the COM. Because the average COP was only 4 ms delayed behind the COM, reactive control was not evident; this small delay was accounted for by the damping in the tuned mechanical system.},
	number = {3},
	journal = {J. Neurophysiol.},
	author = {Winter, Da and Patla, Ae and Prince, F and Ishac, M and Perczak, Gielo-K},
	month = sep,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {1211--1221},
}

@article{schoner_dynamic_1988,
	title = {Dynamic pattern generation in behavioral and neural systems},
	volume = {239},
	abstract = {In the search for principles of pattern generation in complex biological systems, an operational approach is presented that embraces both theory and experiment. The central mathematical concepts of self-organization in nonequilibrium systems (including order parameter dynamics, stability, fluctuations, and time scales) are used to show how a large number of empirically observed features of temporal patterns can be mapped onto simple low-dimensional (stochastic, nonlinear) dynamical laws that are derivable from lower levels of description. The theoretical framework provides a language and a strategy, accompanied by new observables, that may afford an understanding of dynamic patterns at several scales of analysis (including behavioral patterns, neural networks, and individual neurons) and the linkage among them.},
	number = {4847},
	journal = {Science},
	author = {Schoner, G and Kelso, Ja},
	month = mar,
	year = {1988},
	keywords = {Jun 12 import},
	pages = {1513--1520},
}

@article{leblond_corticospinal_2001,
	title = {Corticospinal control of locomotor pathways generating extensor activities in the cat},
	volume = {138},
	abstract = {Interneuronal convergence of corticospinal and segmental pathways involved with the generation of extensor activities during locomotion was investigated in decerebrate and partially spinalized cats. L-dihydroxyphenylalanine (L-DOPA) was slowly injected until long-latency, long-lasting discharges could be evoked by the stimulation of contralateral flexor reflex afferents (coFRA) and the group I autogenetic inhibition was reversed to polysynaptic excitation in extensor motoneurons. Under these conditions, we stimulated in alternation the contralateral pyramidal tract (PT), group I afferents from knee and ankle extensor muscles, and both stimuli together. We did the same for the stimulation of PT and of coFRA. Clear polysynaptic EPSPs could be evoked from all three sources in 32 extensor motoneurons. Convergence was inferred from spatial facilitation, which occurred when the amplitude of the EPSPs evoked by the combined stimuli was notably larger than the algebraic sum of the EPSPs evoked by individual stimulation. Spatial facilitation was found between PT and extensor group I inputs in 30/59 tests (51\%) in 20 motoneurons and in all cases (6/6) between PT and coFRA in six motoneurons. When fictive locomotion was induced with further injection of L-DOPA, PT descending volleys from the same stimulating site could reset the stepping rhythm by initiating bursts of activity in all extensors. These results indicate that at least some of the corticospinal fibers project onto interneurons shared by the coFRA and the polysynaptic excitatory group I pathways to extensors. The implications of such convergence patterns on the organization of the extensor “half-center” for locomotion are discussed.},
	number = {2},
	journal = {Exp. Brain Res.},
	author = {Leblond, H and Menard, A and Gossard, Jp},
	month = may,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {173--184},
}

@article{mccrea_spinal_2001,
	title = {Spinal circuitry of sensorimotor control of locomotion},
	volume = {533},
	abstract = {During locomotion many segmental hindlimb reflex pathways serve not only to regulate the excitability of local groups of motoneurones, but also to control the basic operation of the central pattern-generating circuitry responsible for locomotion. This is accomplished through a reorganization of reflexes that includes the suppression of reflex pathways operating at rest and the recruitment during locomotion of previously unrecognized types of spinal interneurones. In addition presynaptic inhibition of transmission from segmental afferents serves to regulate the gain of segmental reflexes and may contribute to the selection of particular reflex pathways during locomotion. The fictive locomotion preparation in adult decerebrate cats has proved to be an important tool in understanding reflex pathway reorganization. Further identification of the spinal interneurones involved in locomotor-dependent reflexes will contribute to our understanding not only of reflex pathway organization but also of the organization of the mammalian central pattern generator.},
	number = {Pt 1},
	journal = {J. Physiol.},
	author = {Mccrea, Da},
	month = may,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {41--50},
}

@incollection{rossignol_neural_1996,
	title = {Neural control of stereotypic limb movements},
	volume = {12. Exercise: Regulation and Integration of Multiple Systems},
	booktitle = {Handbook of {Physiology}},
	publisher = {American Physiological Society},
	author = {Rossignol, Serge},
	editor = {Sheperd, L b Rowell and t, J.},
	year = {1996},
	note = {Section: 5},
	keywords = {Jun 12 import},
	pages = {173--216},
}

@article{wright_application_2001,
	title = {The {Application} of {Ground} {Force} {Explains} the {Energetic} {Cost} of {Running} {Backward} and {Forward}},
	volume = {204},
	abstract = {We compared backward with forward running to test the idea that the application of ground force to support the weight of the body determines the energetic cost of running. We hypothesized that higher metabolic rates during backward versus forward running would be directly related to greater rates of ground force application and the volume of muscle activated to apply support forces to the ground. Four trained males ran backward and forward under steady-state conditions at eight treadmill speeds from 1.75 to 3.50ms-1. Rates of oxygen uptake were measured to determine metabolic rates, and inverse periods of foot�ground contact (1/tc) were measured to estimate rates of ground force application. As expected, at all eight speeds, both metabolic rates and estimated rates of ground force application were greater for backward than for forward running. At the five slowest speeds, the differences in rates of ground force application were directly proportional to the differences in metabolic rates between modes (paired t-test, P{\textless}0.05), but at the three highest speeds, small but significant differences in proportionality were present in this relationship. At one of these three higher speeds (3.0ms-1), additional measurements to estimate muscle volumes were made using a non-invasive force plate/video technique. These measurements indicated that the volume of muscle active per unit of force applied to the ground was 10�3 \% greater when running backward than forward at this speed. The product of rates of ground force application and estimated muscle volumes predicted a difference in metabolic rate that was indistinguishable from the difference we measured (34�6\% versus 35�6 \%; means � S.E.M., N=4). We conclude that metabolic rates during running are determined by rates of ground force application and the volume of muscle activated to apply support forces to the ground.},
	journal = {J. Exp. Biol.},
	author = {Wright, Seth and Weyand, Peter G},
	year = {2001},
	keywords = {locomotion, Jun 12 import, human, contact time, cost coefficient, ground force, metabolic rate, muscle force},
	pages = {1805--1815},
}

@article{guan_impact_2001,
	title = {Impact of {Movement} and {Movement}-{Related} {Feedback} on the {Lamprey} {Central} {Pattern} {Generator} for {Locomotion}},
	volume = {204},
	abstract = {A semi-reduced, minimally restrained lamprey preparation was used to investigate the impact of movement and movement-related feedback during Dglutamate- induced locomotion. The preparation consisted of the trunk alone with the spinal cord exposed to the bathing solution. Two conditions were compared using electromyography or nerve recording: (i) muscle and spinal cord, (ii) spinal cord alone supported by the notochord. Compared with the isolated spinal cord, movement in the presence of muscle consistently and significantly increased the frequency of the motor output and reduced the phase delay among the segments. In moving preparations, coupling among the segments was reduced by two staggered hemisections to permit the strength and direction of intersegmental coupling to be estimated. The estimates revealed that movement increased the total intersegmental coupling strength and increased the proportion of the coupling that was descending over those of the isolated spinal cord. The effects on the phase and frequency of bursting can be explained in the light of the excitation evoked by bending that we have reported previously. Thus, we demonstrate that movement and movement-related feedback that arise from spinally induced motor patterns can alter the form of the movement and the functional coupling strength among the segments of the lamprey spinal cord.},
	journal = {J. Exp. Biol.},
	author = {Guan, Li and Kiemel, Tim and Cohen, Avis H},
	year = {2001},
	keywords = {Jun 12 import, spinal cord, Ichthyomyzon unicuspis, intersegmental coordination, lamprey, movement, oscillator, Petromyzon marinus, sensory feedback},
	pages = {2361--2370},
}

@article{lam_proprioceptive_2001,
	title = {Proprioceptive {Modulation} of {Hip} {Flexor} {Activity} {During} the {Swing} {Phase} of {Locomotion} in {Decerebrate} {Cats}},
	volume = {86},
	abstract = {Proprioceptive modulation of hip flexor activity during the swing phase of locomotion in decerebrate cats. J Neurophysiol 86: 1321�1332, 2001. This study examined the influence of proprioceptive input from hip flexor muscles on the activity in hip flexors during the swing phase of walking in the decerebrate cat. One hindlimb was partially denervated to remove cutaneous input and afferent input from most other hindlimb muscles. Perturbations to hip movement were applied either by 1) manual resistance or assistance to swing or by 2) resistance to hip flexion using a device that blocked hip flexion but allowed leg extension. Electromyographic recordings were made from the iliopsoas (IP), sartorius, and medial gastrocnemius muscles. When the hip was manually assisted into flexion, there was a reduction in hip flexor burst activity. Conversely, when hip flexion was manually resisted or mechanically blocked during swing, the duration and amplitude of hip flexor activity was increased. We also found some specificity in the role of afferents from individual hip flexor muscles in the modulation of flexor burst activity. If the IP muscle was detached from its insertion, little change in the response to blocking flexion was observed. Specific activation of IP afferent fibers by stretching the muscle also did not greatly affect flexor activity. On the other hand, if conduction in the sartorius nerves was blocked, there was a diminished response to blocking hip flexion. The increase in duration of the flexor bursts still occurred, but this increase was consistently lower than that observed when the sartorius nerves were intact. From these results we propose that during swing, feedback from hip flexor muscle afferents, particularly those from the sartorius muscles, enhances flexor activity. In addition, if we delayed the onset of flexor activity in the contralateral hindlimb, blocking hip flexion often resulted in the prolongation of ipsilateral flexor activity for long periods of time, further revealing the reinforcing effects of flexor afferent feedback on flexor activity. This effect was not seen if conduction in the sartorius nerves was blocked. In conclusion, we have found that hip flexor activity during locomotion can be strongly modulated by modifying proprioceptive feedback from the hip flexor muscles.},
	journal = {J. Neurophysiol.},
	author = {Lam, Tania and Pearson, Keir G},
	month = sep,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {1321--1332},
}

@article{mechsner_perceptual_2001,
	title = {Perceptual basis of bimanual coordination},
	volume = {414},
	abstract = {Periodic bimanual movements are often the focus of studies of the basic organizational principles of human actions. In such movements there is a typical spontaneous tendency towards mirror symmetry. Even involuntary slips from asymmetrical movement patterns into symmetry occur, but not vice versa. Traditionally, this phenomenon has been interpreted as a tendency towards co-activation of homologous muscles, probably originating in motoric neuronal structures. Here we provide evidence contrary to this widespread assumption. We show for two prominent experimental models-bimanual finger oscillation and bimanual four-finger tapping-that the symmetry bias is actually towards spatial, perceptual symmetry, without regard to the muscles involved. We suggest that spontaneous coordination phenomena of this kind are purely perceptual in nature. In the case of a bimanual circling model, our findings reveal that highly complex, even 'impossible' movements can easily be performed with only simple visual feedback. A 'motoric' representation of the performed perceptual oscillation patterns is not necessary. Thus there is no need to translate such a 'motoric' into a 'perceptual' representation or vice versa, using 'internal models' (ref. 29). We suggest that voluntary movements are organized by way of a representation of the perceptual goals, whereas the corresponding motor activity, of sometimes high complexity, is spontaneously and flexibly tuned in.},
	number = {6859},
	journal = {Nature},
	author = {Mechsner, F and Kerzel, D and Knoblich, G and Prinz, W},
	month = nov,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {69--73},
}

@article{pearson_neural_2000,
	title = {Neural adaptation in the generation of rhythmic behavior},
	volume = {62},
	abstract = {Motor systems can adapt rapidly to changes in external conditions and to switching of internal goals. They can also adapt slowly in response to training, alterations in the mechanics of the system, and any changes in the system resulting from injury. This article reviews the mechanisms underlying short- and long-term adaptation in rhythmic motor systems. The neuronal networks underlying the generation of rhythmic motor patterns (central pattern generators; CPGs) are extremely flexible. Neuromodulators, central commands, and afferent signals all influence the pattern produced by a CPG by altering the cellular and synaptic properties of individual neurons and the coupling between different populations of neurons. This flexibility allows the generation of a variety of motor patterns appropriate for the mechanical requirements of different forms of a behavior. The matching of motor output to mechanical requirements depends on the capacity of pattern-generating networks to adapt to slow changes in body mechanics and persistent errors in performance. Afferent feedback from body and limb proprioceptors likely plays an important role in driving these long-term adaptive processes.},
	journal = {Annu. Rev. Physiol.},
	author = {Pearson, Kg},
	year = {2000},
	keywords = {Jun 12 import},
	pages = {723--753},
}

@article{burdet_central_2001,
	title = {The central nervous system stabilizes unstable dynamics by learning optimal impedance},
	volume = {414},
	abstract = {To manipulate objects or to use tools we must compensate for any forces arising from interaction with the physical environment. Recent studies indicate that this compensation is achieved by learning an internal model of the dynamics, that is, a neural representation of the relation between motor command and movement. In these studies interaction with the physical environment was stable, but many common tasks are intrinsically unstable. For example, keeping a screwdriver in the slot of a screw is unstable because excessive force parallel to the slot can cause the screwdriver to slip and because misdirected force can cause loss of contact between the screwdriver and the screw. Stability may be dependent on the control of mechanical impedance in the human arm because mechanical impedance can generate forces which resist destabilizing motion. Here we examined arm movements in an unstable dynamic environment created by a robotic interface. Our results show that humans learn to stabilize unstable dynamics using the skilful and energy-efficient strategy of selective control of impedance geometry.},
	number = {6862},
	journal = {Nature},
	author = {Burdet, E and Osu, R and Franklin, Dw and Milner, Te and Kawato, M},
	month = nov,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {446--449},
}

@article{lackner_adaptation_1998,
	title = {Adaptation in a rotating artificial gravity environment},
	volume = {28},
	abstract = {The centripetal force generated by a rotating space vehicle is a potential source of artificial gravity. Minimizing the cost of such a vehicle dictates using the smallest radius and highest rotation rate possible, but head movements made at high rotation rates generate disorienting, nauseogenic cross-coupled semicircular canal stimulation. Early studies suggested 3 or 4 rpm as the highest rate at which humans could adapt to this vestibular stimulus. These studies neglected the concomitant Coriolis force actions on the head/neck system. We assessed non-vestibular Coriolis effects by measuring arm and leg movements made in the center of a rotating room turning at 10 rpm and found that movement endpoints and trajectories are initially deviated; however, subjects readily adapt with 10-20 additional movements, even without seeing their errors. Equilibrium point theories of motor control errantly predict that Coriolis forces will not cause movement endpoint errors so that subjects will not have to adapt their reaching movements during rotation. Adaptation of movement trajectory acquired during Coriolis force perturbations of one arm transfers to the unexposed arm but there is no intermanual transfer of endpoint adaptation indicating that neuromotor representations of movement endpoint and trajectory are separable and can adapt independently, also contradictory to equilibrium point theories. Touching a surface at the end of reaching movements is required for complete endpoint adaptation in darkness but trajectory adapts completely with or without terminal contact. We have also made the first kinematic measurements of unconstrained head movements during rotation, these movements show rapid adaptation to Coriolis force perturbations. Our results point to methods for achieving full compensation for rotation up to 10 rpm. Copyright 1998 Published by Elsevier Science B.V.},
	number = {1-2},
	journal = {Brain Res. Brain Res. Rev.},
	author = {Lackner, Jr and Dizio, P},
	month = nov,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {194--202},
}

@article{lackner_gravitoinertial_1998,
	title = {Gravitoinertial force background level affects adaptation to coriolis force perturbations of reaching movements},
	volume = {80},
	abstract = {We evaluated the combined effects on reaching movements of the transient, movement-dependent Coriolis forces and the static centrifugal forces generated in a rotating environment. Specifically, we assessed the effects of comparable Coriolis force perturbations in different static force backgrounds. Two groups of subjects made reaching movements toward a just-extinguished visual target before rotation began, during 10 rpm counterclockwise rotation, and after rotation ceased. One group was seated on the axis of rotation, the other 2.23 m away. The resultant of gravity and centrifugal force on the hand was 1.0 g for the on-center group during 10 rpm rotation, and 1.031 g for the off-center group because of the 0.25 g centrifugal force present. For both groups, rightward Coriolis forces, approximately 0.2 g peak, were generated during voluntary arm movements. The endpoints and paths of the initial per-rotation movements were deviated rightward for both groups by comparable amounts. Within 10 subsequent reaches, the on-center group regained baseline accuracy and straight-line paths; however, even after 40 movements the off-center group had not resumed baseline endpoint accuracy. Mirror-image aftereffects occurred when rotation stopped. These findings demonstrate that manual control is disrupted by transient Coriolis force perturbations and that adaptation can occur even in the absence of visual feedback. An increase, even a small one, in background force level above normal gravity does not affect the size of the reaching errors induced by Coriolis forces nor does it affect the rate of reacquiring straight reaching paths; however, it does hinder restoration of reaching accuracy.},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Lackner, Jr and Dizio, P},
	month = aug,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {546--553},
}

@article{lackner_rapid_1994,
	title = {Rapid adaptation to {Coriolis} force perturbations of arm trajectory},
	volume = {72},
	abstract = {1. Forward reaching movements made during body rotation generate tangential Coriolis forces that are proportional to the cross product of the angular velocity of rotation and the linear velocity of the arm. Coriolis forces are inertial forces that do not involve mechanical contact. Virtually no constant centrifugal forces will be present in the background when motion of the arm generates transient Coriolis forces if the radius of body rotation is small. 2. We measured the trajectories of arm movements made in darkness to a visual target that was extinguished as movement began. The reaching movements were made prerotation, during rotation at 10 rpm in a fully enclosed rotating room, and postrotation. During testing the subject was seated at the center of the room and pointed radially. Neither visual nor tactile feedback about movement accuracy was present. 3. In experiment 1, subjects reached at a fast or slow rate and their hands made contact with a horizontal surface at the end of the reach. Their initial perrotary movements were highly significantly deviated relative to prerotation in both trajectories and end-points in the direction of the transient Coriolis forces that had been generated during the reaches. Despite the absence of visual and tactile feedback about reaching accuracy, all subjects rapidly regained straight movement trajectories and accurate endpoints. Postrotation, transient errors of opposite sign were present for both trajectories and endpoints. 4. In a second experiment the conditions were identical except that subjects pointed just above the location of the extinguished target so that no surface contact was involved. All subjects showed significant initial perrotation deviations of trajectories and endpoints in the direction of the transient Coriolis forces. With repeated reaches the trajectories, as viewed from above, again became straight, but there was only partial restoration of endpoint accuracy, so that subjects reached in a straight line to the wrong place. Aftereffects of opposite sign were transiently present in the postrotary movements. 5. These observations fail to support current equilibrium point models, both alpha and lambda, of movement control. Such theories would not predict endpoint errors under our experimental conditions, in which the Coriolis force is absent at the beginning and end of a movement. Our results indicate that detailed aspects of movement trajectory are being continuously monitored on the basis of proprioceptive feedback in relation to motor commands. Adaptive compensations can be initiated after one perturbation despite the absence of either visual or tactile feedback about movement trajectory and endpoint error. Moreover, movement trajectory and end-point can be remapped independently.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {1},
	journal = {J. Neurophysiol.},
	author = {Lackner, Jr and Dizio, P},
	month = jul,
	year = {1994},
	keywords = {Jun 12 import},
	pages = {299--313},
}

@article{dizio_motor_1995,
	title = {Motor adaptation to {Coriolis} force perturbations of reaching movements: endpoint but not trajectory adaptation transfers to the nonexposed arm},
	volume = {74},
	abstract = {1. Reaching movements made in a rotating room generate Coriolis forces that are directly proportional to the cross product of the room's angular velocity and the arm's linear velocity. Such Coriolis forces are inertial forces not involving mechanical contact with the arm. 2. We measured the trajectories of arm movements made in darkness to a visual target that was extinguished at the onset of each reach. Prerotation subjects pointed with both the right and left arms in alternating sets of eight movements. During rotation at 10 rpm, the subjects reached only with the right arm. Postrotation, the subjects pointed with the left and right arms, starting with the left, in alternating sets of eight movements. 3. The initial perrotary reaching movements of the right arm were highly deviated both in movement path and endpoint relative to the prerotation reaches of the right arm. With additional movements, subjects rapidly regained straight movement paths and accurate endpoints despite the absence of visual or tactile feedback about reaching accuracy. The initial postrotation reaches of the left arm followed straight paths to the wrong endpoint. The initial postrotation reaches of the right arm had paths with mirror image curvature to the initial perrotation reaches of the right arm but went to the correct endpoint. 4. These observations are inconsistent with current equilibrium point models of movement control. Such theories predict accurate reaches under our experimental conditions. Our observations further show independent implementation of movement and posture, as evidenced by transfer of endpoint adaptation to the nonexposed arm without transfer of path adaptation. Endpoint control may occur at a relatively central stage that represents general constraints such as gravitoinertial force background or egocentric direction relative to both arms, and control of path may occur at a more peripheral stage that represents moments of inertia and muscle dynamics unique to each limb. 5. Endpoint and path adaptation occur despite the absence both of mechanical contact cues about the perturbing force and visual or tactile cues about movement accuracy. These findings point to the importance of muscle spindle signals, monitoring of motor commands, and possibly joint and tendon receptors in a detailed trajectory monitoring process. Muscle spindle primary and secondary afferent signals may differentially influence adaptation of movement shape and endpoint, respectively.},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Dizio, P and Lackner, Jr},
	month = oct,
	year = {1995},
	keywords = {Jun 12 import},
	pages = {1787--1792},
}

@article{fa_motor_2000,
	title = {Motor learning through the combination of primitives},
	volume = {355},
	abstract = {In this paper we discuss a new perspective on how the central nervous system (CNS) represents and solves some of the most fundamental computational problems of motor control. In particular, we consider the task of transforming a planned limb movement into an adequate set of motor commands. To carry out this task the CNS must solve a complex inverse dynamic problem. This problem involves the transformation from a desired motion to the forces that are needed to drive the limb. The inverse dynamic problem is a hard computational challenge because of the need to coordinate multiple limb segments and because of the continuous changes in the mechanical properties of the limbs and of the environment with which they come in contact. A number of studies of motor learning have provided support for the idea that the CNS creates, updates and exploits internal representations of limb dynamics in order to deal with the complexity of inverse dynamics. Here we discuss how such internal representations are likely to be built by combining the modular primitives in the spinal cord as well as other building blocks found in higher brain structures. Experimental studies on spinalized frogs and rats have led to the conclusion that the premotor circuits within the spinal cord are organized into a set of discrete modules. Each module, when activated, induces a specific force field and the simultaneous activation of multiple modules leads to the vectorial combination of the corresponding fields. We regard these force fields as computational primitives that are used by the CNS for generating a rich grammar of motor behaviours.},
	number = {1404},
	journal = {Philos. Trans. R. Soc. Lond. B Biol. Sci.},
	author = {Fa, Mussa-Ivaldi and Bizzi, E},
	month = dec,
	year = {2000},
	keywords = {Jun 12 import},
	pages = {1755--1769},
}

@article{tresch_construction_1999,
	title = {The construction of movement by the spinal cord},
	volume = {2},
	abstract = {We used a computational analysis to identify the basic elements with which the vertebrate spinal cord constructs one complex behavior. This analysis extracted a small set of muscle synergies from the range of muscle activations generated by cutaneous stimulation of the frog hindlimb. The flexible combination of these synergies was able to account for the large number of different motor patterns produced by different animals. These results therefore demonstrate one strategy used by the vertebrate nervous system to produce movement in a computationally simple manner.},
	number = {2},
	journal = {Nat. Neurosci.},
	author = {Tresch, Mc and Saltiel, P and Bizzi, E},
	month = feb,
	year = {1999},
	keywords = {Jun 12 import},
	pages = {162--167},
}

@article{hiebert_contribution_1999,
	title = {Contribution of sensory feedback to the generation of extensor activity during walking in the decerebrate {Cat}},
	volume = {81},
	abstract = {In this investigation we have estimated the afferent contribution to the generation of activity in the knee and ankle extensor muscles during walking in decerebrate cats by loading and unloading extensor muscles, and by unilateral deafferentation of a hind leg. The total contribution of afferent feedback to extensor burst generation was estimated by allowing one hind leg to step into a hole in the treadmill belt on which the animal was walking. In the absence of ground support the level of activity in knee and ankle extensor muscles was reduced to approximately 70\% of normal. Activity in the ankle extensors could be restored during the “foot-in-hole” trials by selectively resisting extension at the ankle. Thus feedback from proprioceptors in the ankle extensor muscles probably makes a large contribution to burst generation in these muscles during weight-bearing steps. Similarly, feedback from proprioceptors in knee extensor appears to contribute substantially to the activation of knee extensor muscles because unloading and loading these muscles, by lifting and dropping the hindquarters, strongly reduced and increased, respectively, the level of activity in the knee extensors. This conclusion was supported by the finding that partial deafferentation of one hind leg by transection of the L4-L6 dorsal roots reduced the level of activity in the knee extensors by approximately 50\%, but did not noticeably influence the activity in ankle extensor muscles. However, extending the deafferentation to include the L7-S2 dorsal roots decreased the ankle extensor activity. We conclude that afferent feedback contributes to more than one-half of the input to knee and ankle extensor motoneurons during the stance phase of walking in decerebrate cats. The continuous contribution of afferent feedback to the generation of extensor activity could function to automatically adjust the intensity of activity to meet external demands.},
	number = {2},
	journal = {J. Neurophysiol.},
	author = {Hiebert, Gw and Pearson, Kg},
	month = feb,
	year = {1999},
	keywords = {Jun 12 import},
	pages = {758--770},
}

@article{kjaerulff_distribution_1996,
	title = {Distribution of networks generating and coordinating locomotor activity in the neonatal rat spinal cord in vitro: a lesion study},
	volume = {16},
	abstract = {The isolated spinal cord of the newborn rat contains networks that are able to create a patterned motor output resembling normal locomotor movements. In this study, we sought to localize the regions of primary importance for rhythm and pattern generation using specific mechanical lesions. We used ventral root recordings to monitor neuronal activity and tested the ability of various isolated parts of the caudal thoraciclumbar cord to generate rhythmic bursting in a combination of 5-HT and NMDA. In addition, pathways mediating left/right and rostrocaudal burst alternation were localized. We found that the isolated ventral third of the spinal cord can generate normally coordinated rhythmic activity, whereas lateral fragments resulting from sagittal sections showed little or no rhythmogenic capability compared with intact control preparations. The ability to generate fast and regular rhythmic activity decreased in the caudal direction, but the rhythm-generating network was found to be distributed over the entire lumbar region and to extend into the caudal thoracic region. The pathways mediating left/ right alternation exist primarily in the ventral commissure. As with the rhythmogenic ability, these pathways were distributed along the lumbar enlargement. Both lateral and ventral funiculi were sufficient to coordinate activity in the rostral and caudal regions. We conclude that the networks organizing locomotor-related activity in the spinal cord of the newborn rat are distributed.},
	number = {18},
	journal = {J. Neurosci.},
	author = {Kjaerulff, O and Kiehn, O},
	month = sep,
	year = {1996},
	keywords = {Jun 12 import},
	pages = {5777--5794},
}

@article{schmitt_mechanical_2000,
	title = {Mechanical models for insect locomotion: dynamics and stability in the horizontal plane {I}. {Theory}},
	volume = {83},
	abstract = {We study the dynamics and stability of legged locomotion in the horizontal plane. Motivated by experimental studies of insects, we develop two- and three-degree-of freedom rigid body models with pairs of 'virtual' elastic legs in intermittent contact with the ground. We focus on conservative compliant-legged models, but we also consider prescribed forces, prescribed leg displacements, and combined strategies. The resulting mechanical systems exhibit periodic gaits whose stability characteristics are due to intermittent foot contact, and are largely determined by geometrical criteria. Most strikingly, we show that mechanics alone can confer asymptotic stability in heading and body orientation. In a companion paper, we apply our results to rapidly running cockroaches.},
	number = {6},
	journal = {Biol. Cybern.},
	author = {Schmitt, J and Holmes, P},
	month = dec,
	year = {2000},
	keywords = {Jun 12 import},
	pages = {501--515},
}

@article{schmitt_mechanical_2000-1,
	title = {Mechanical models for insect locomotion: dynamics and stability in the horizontal plane-{II}. {Application}},
	volume = {83},
	abstract = {We study the dynamics and stability of legged locomotion in the horizontal plane. We discuss the relevance of idealized mechanical models, developed in a companion paper, to recent experiments and simulations on insect running and turning. Applying our results to rapidly running cockroaches, we show that the models' gait and force characteristics match observations reasonably well.},
	number = {6},
	journal = {Biol. Cybern.},
	author = {Schmitt, J and Holmes, P},
	month = dec,
	year = {2000},
	keywords = {Jun 12 import},
	pages = {517--527},
}

@article{schiller_look_2001,
	title = {Look and see: how the brain moves your eyes about},
	volume = {134},
	abstract = {Two major cortical streams are involved in the generation of visually guided saccadic eye movements: the anterior and the posterior. The anterior stream from the frontal and medial eye fields has direct access to brainstem oculomotor centers. The posterior stream from the occipital cortices reaches brainstem oculomotor centers through the superior colliculus. The parietal cortex interconnects with both streams. Our findings suggest that the posterior stream plays an unique role in the execution of rapid, short-latency eye movements called 'express saccades'. Both the anterior and posterior streams play a role in the selection of targets to which saccades are to be generated, but do so in different ways. Areas V1, V2 and LIP contribute to decisions involved in where to look as well as where not to look. In addition, area LIP is involved in decisions about how long to maintain fixation prior to the execution of a saccade. Area V4 does not appear to be directly involved in eye-movement generation. In the anterior stream, the frontal eye fields, and to a lesser extent the medial eye fields, are involved in the correct execution of saccades subsequent to decisions made about where to look and where not to look.},
	journal = {Prog. Brain Res.},
	author = {Schiller, Ph and Tehovnik, Ej},
	year = {2001},
	keywords = {Jun 12 import},
	pages = {127--142},
}

@article{todorov_optimal_2002,
	title = {Optimal feedback control as a theory of motor coordination},
	volume = {5},
	abstract = {A central problem in motor control is understanding how the many biomechanical degrees of freedom are coordinated to achieve a common goal. An especially puzzling aspect of coordination is that behavioral goals are achieved reliably and repeatedly with movements rarely reproducible in their detail. Existing theoretical frameworks emphasize either goal achievement or the richness of motor variability, but fail to reconcile the two. Here we propose an alternative theory based on stochastic optimal feedback control. We show that the optimal strategy in the face of uncertainty is to allow variability in redundant (task-irrelevant) dimensions. This strategy does not enforce a desired trajectory, but uses feedback more intelligently, correcting only those deviations that interfere with task goals. From this framework, task-constrained variability, goal-directed corrections, motor synergies, controlled parameters, simplifying rules and discrete coordination modes emerge naturally. We present experimental results from a range of motor tasks to support this theory.},
	number = {11},
	journal = {Nat. Neurosci.},
	author = {Todorov, Emanuel},
	year = {2002},
	keywords = {Jun 12 import},
	pages = {1226},
}

@book{muybridge_muybridges_1979,
	series = {3 {Vols}},
	title = {Muybridge's {Complete} {Human} and {Animal} {Locomotion}: {All} 781 {Plates} from the 1887 {Animal} {Locomotion}},
	publisher = {Dover Publications, Incorporated},
	author = {Muybridge, Eadweard and Mozley, Anita Ventura},
	month = may,
	year = {1979},
	keywords = {Jun 12 import},
}

@book{orlovsky_neural_1999,
	edition = {1st},
	title = {Neural {Control} of {Locomotion}: {From} {Mullusc} to {Man}},
	publisher = {Oxford University Press},
	author = {Orlovsky, Grigori and Deliagina, T g and Grillner, Sten},
	month = nov,
	year = {1999},
	keywords = {Jun 12 import},
}

@article{muellbacher_early_2002,
	title = {Early consolidation in human primary motor cortex},
	volume = {415},
	abstract = {Behavioural studies indicate that a newly acquired motor skill is rapidly consolidated from an initially unstable state to a more stable state, whereas neuroimaging studies demonstrate that the brain engages new regions for performance of the task as a result of this consolidation. However, it is not known where a new skill is retained and processed before it is firmly consolidated. Some early aspects of motor skill acquisition involve the primary motor cortex (M1), but the nature of that involvement is unclear. We tested the possibility that the human M1 is essential to early motor consolidation. We monitored changes in elementary motor behaviour while subjects practised fast finger movements that rapidly improved in movement acceleration and muscle force generation. Here we show that low-frequency, repetitive transcranial magnetic stimulation of M1 but not other brain areas specifically disrupted the retention of the behavioural improvement, but did not affect basal motor behaviour, task performance, motor learning by subsequent practice, or recall of the newly acquired motor skill. These findings indicate that the human M1 is specifically engaged during the early stage of motor consolidation.},
	number = {6872},
	journal = {Nature},
	author = {Muellbacher, W and Ziemann, U and Wissel, J and Dang, N and Kofler, M and Facchini, S and Boroojerdi, B and Poewe, W and Hallett, M},
	month = feb,
	year = {2002},
	keywords = {Jun 12 import},
	pages = {640--644},
}

@article{cisek_alternative_1999,
	title = {An alternative interpretation of population vector rotation in macaque motor cortex},
	volume = {272},
	abstract = {Neural recordings from the primary motor cortex of monkeys performing movements at an angle to a cue stimulus have yielded two main results: (A) the population vector rotates from the direction of the cue to the direction of movement, and (B) cells with intermediate preferred directions are recruited during the middle of this rotation. These results have been interpreted as the neural correlates of a process of 'mental rotation'. Here we propose that results A and B are also consistent with an alternate hypothesis of 'response substitution', given four well known features of cortical neurophysiology.},
	number = {1},
	journal = {Neurosci. Lett.},
	author = {Cisek, P and Scott, Sh},
	month = sep,
	year = {1999},
	keywords = {Jun 12 import},
	pages = {1--4},
}

@article{miall_cerebellum_2001,
	title = {The cerebellum coordinates eye and hand tracking movements},
	volume = {4},
	abstract = {The cerebellum is thought to help coordinate movement. We tested this using functional magnetic resonance imaging (fMRI) of the human brain during visually guided tracking tasks requiring varying degrees of eye-hand coordination. The cerebellum was more active during independent rather than coordinated eye and hand tracking. However, in three further tasks, we also found parametric increases in cerebellar blood oxygenation signal (BOLD) as eye-hand coordination increased. Thus, the cerebellar BOLD signal has a non-monotonic relationship to tracking performance, with high activity during both coordinated and independent conditions. These data provide the most direct evidence from functional imaging that the cerebellum supports motor coordination. Its activity is consistent with roles in coordinating and learning to coordinate eye and hand movement.},
	number = {6},
	journal = {Nat. Neurosci.},
	author = {Miall, Rc and Reckess, Gz and Imamizu, H},
	month = jun,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {638--644},
}

@article{chapin_real-time_1999,
	title = {Real-time control of a robot arm using simultaneously recorded neurons in the motor cortex},
	volume = {2},
	abstract = {To determine whether simultaneously recorded motor cortex neurons can be used for real-time device control, rats were trained to position a robot arm to obtain water by pressing a lever. Mathematical transformations, including neural networks, converted multineuron signals into 'neuronal population functions' that accurately predicted lever trajectory. Next, these functions were electronically converted into real-time signals for robot arm control. After switching to this 'neurorobotic' mode, 4 of 6 animals (those with {\textgreater} 25 task-related neurons) routinely used these brain-derived signals to position the robot arm and obtain water. With continued training in neurorobotic mode, the animals' lever movement diminished or stopped. These results suggest a possible means for movement restoration in paralysis patients.},
	number = {7},
	journal = {Nat. Neurosci.},
	author = {Chapin, Jk and Moxon, Ka and Markowitz, Rs and Nicolelis, Ma},
	month = jul,
	year = {1999},
	keywords = {Jun 12 import},
	pages = {664--670},
}

@article{d_modeling_2001,
	title = {A modeling study of potential sources of curvature in human reaching movements},
	volume = {33},
	abstract = {The authors of this article suggest that the slight but consistent posture-dependent curvature of the spatial paths in the kinematic transformation between intrinsic and extrinsic coordinates may result in a systematic curvature of movements initially planned as straight-line trajectories toward the target. A kinematic planning model is presented that takes into account the anisotropy of the intrinsic and extrinsic transformation and tends to avoid movements that require excessive joint rotations by introducing slight deviations from a straight-line trajectory. Preliminary simulations showed reasonably good agreement with experimental data, especially considering that the current model is strictly based on kinematics. A quantitative analysis showed that the strategy used in the model achieves a favorable compromise between straight-line movements and angular joint changes: By slightly increasing the spatial length of the movement (i.e., by introducing curvature), an individual can greatly reduce the total amount of joint rotation required to produce the movement.},
	number = {4},
	journal = {J. Mot. Behav.},
	author = {D, Barreca Micci and Guenther, Fh},
	month = dec,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {387--400},
}

@article{georgopoulos_neuronal_1986-1,
	title = {Neuronal population coding of movement direction},
	volume = {233},
	abstract = {Although individual neurons in the arm area of the primate motor cortex are only broadly tuned to a particular direction in three-dimensional space, the animal can very precisely control the movement of its arm. The direction of movement was found to be uniquely predicted by the action of a population of motor cortical neurons. When individual cells were represented as vectors that make weighted contributions along the axis of their preferred direction (according to changes in their activity during the movement under consideration) the resulting vector sum of all cell vectors (population vector) was in a direction congruent with the direction of movement. This population vector can be monitored during various tasks, and similar measures in other neuronal populations could be of heuristic value where there is a neural representation of variables with vectorial attributes.},
	number = {4771},
	journal = {Science},
	author = {Georgopoulos, A P and Schwartz, A B and Kettner, R E},
	month = sep,
	year = {1986},
	keywords = {Jun 12 import},
	pages = {1416--1419},
}

@article{scott_dissociation_2001,
	title = {Dissociation between hand motion and population vectors from neural activity in motor cortex},
	volume = {413},
	abstract = {The population vector hypothesis was introduced almost twenty years ago to illustrate that a population vector constructed from neural activity in primary motor cortex (MI) of non-human primates could predict the direction of hand movement during reaching. Alternative explanations for this population signal have been suggested but could not be tested experimentally owing to movement complexity in the standard reaching model. We re-examined this issue by recording the activity of neurons in contralateral MI of monkeys while they made reaching movements with their right arms oriented in the horizontal plane-where the mechanics of limb motion are measurable and anisotropic. Here we found systematic biases between the population vector and the direction of hand movement. These errors were attributed to a non-uniform distribution of preferred directions of neurons and the non-uniformity covaried with peak joint power at the shoulder and elbow. These observations contradict the population vector hypothesis and show that non-human primates are capable of generating reaching movements to spatial targets even though population vectors based on MI activity do not point in the direction of hand motion.},
	number = {6852},
	journal = {Nature},
	author = {Scott, Sh and Gribble, Pl and Graham, Km and Cabel, Dw},
	month = sep,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {161--165},
}

@article{rioult-pedotti_strengthening_1998,
	title = {Strengthening of horizontal cortical connections following skill learning},
	volume = {1},
	abstract = {Learning a new motor skill requires an alteration in the spatiotemporal pattern of muscle activation. Motor areas of cerebral neocortex are thought to be involved in this type of learning, possibly by functional reorganization of cortical connections. Here we show that skill learning is accompanied by changes in the strength of connections within adult rat primary motor cortex (M1). Rats were trained for three or five days in a skilled reaching task with one forelimb, after which slices of motor cortex were examined to determine the effect of training on the strength of horizontal intracortical connections in layer II/III. The amplitude of field potentials in the forelimb region contralateral to the trained limb was significantly increased relative to the opposite 'untrained' hemisphere. No differences were seen in the hindlimb region. Moreover, the amount of long-term potentiation (LTP) that could be induced in trained M1 was less than in controls, suggesting that the effect of training was at least partly due to LTP-like mechanisms. These data represent the first direct evidence that plasticity of intracortical connections is associated with learning a new motor skill.},
	number = {3},
	journal = {Nat. Neurosci.},
	author = {Rioult-Pedotti, M S and Friedman, D and Hess, G and Donoghue, J P},
	month = jul,
	year = {1998},
	keywords = {Jun 12 import},
	pages = {230--234},
}

@article{rioult-pedotti_learning-induced_2000,
	title = {Learning-induced {LTP} in neocortex},
	volume = {290},
	abstract = {The hypothesis that learning occurs through long-term potentiation (LTP)- and long-term depression (LTD)-like mechanisms is widely held but unproven. This hypothesis makes three assumptions: Synapses are modifiable, they modify with learning, and they strengthen through an LTP-like mechanism. We previously established the ability for synaptic modification and a synaptic strengthening with motor skill learning in horizontal connections of the rat motor cortex (MI). Here we investigated whether learning strengthened these connections through LTP. We demonstrated that synapses in the trained MI were near the ceiling of their modification range, compared with the untrained MI, but the range of synaptic modification was not affected by learning. In the trained MI, LTP was markedly reduced and LTD was enhanced. These results are consistent with the use of LTP to strengthen synapses during learning.},
	number = {5491},
	journal = {Science},
	author = {Rioult-Pedotti, M S and Friedman, D and Donoghue, J P},
	month = oct,
	year = {2000},
	keywords = {Jun 12 import},
	pages = {533--536},
}

@article{flanagan_trajectory_1995,
	title = {Trajectory adaptation to a nonlinear visuomotor transformation: evidence of motion planning in visually perceived space},
	volume = {74},
	abstract = {1. Although reaching movements are characterized by hand paths that tend to follow roughly straight lines in Cartesian space, a fundamental issue is whether this reflects constraints associated with perception or movement production. 2. To address this issue, we examined two-joint planar reaching movements in which we manipulated the mapping between actual and visually perceived motion. In particular, we used a nonlinear transformation such that straight line hand paths in Cartesian space would result in curved paths in perceived space and vice versa. 3. Under these conditions, subjects learned to make straight line paths in perceived space even though the paths of the hand in Cartesian space were markedly curved. In contrast, when the motion was perceived in Cartesian space (i.e., in the absence of a nonlinear distortion), straight line hand paths were observed. 4. These findings suggest that visually guided reaching movements are planned in a perceptual frame of reference. Reaching movements in the horizontal plane are adapted so as to produce straight lines in visually perceived space.},
	number = {5},
	journal = {J. Neurophysiol.},
	author = {Flanagan, Jr and Rao, Ak},
	month = nov,
	year = {1995},
	keywords = {Jun 12 import},
	pages = {2174--2178},
}

@article{vallbo_organization_1993,
	title = {Organization of motor output in slow finger movements in man},
	volume = {469},
	abstract = {1. Slow finger movements were analysed in normal human subjects with regard to kinematics and EMG activity of the long finger muscles. Surface EMG from the finger extensor and flexor muscles on the forearm was recorded along with angular position and angular velocity during voluntary ramp movements at single metacarpophalangeal joints. Angular acceleration was computed from the velocity record. 2. It was found that movements were not smooth but characterized by steps or discontinuities, often recurring at intervals of 100-125 ms, yielding velocity and acceleration profiles dominated by 8-10 Hz cycles. The discontinuities were manifest from the very first trial and thus not dependent on training. Their amplitude and amount varied between subjects but were relatively stable for the individual subject. 3. The 8-10 Hz cycles were seen with voluntary ramp movements of widely varying velocities, higher velocities being associated with larger steps recurring with the same repetition rate as the small steps of slow voluntary ramps. Maximal step amplitude observed was more than one order of magnitude larger than physiological tremor. 4. The individual 8-10 Hz cycle was asymmetrical in that decelerations usually reached higher peaks than the preceding acceleration, suggesting that the antagonist contributed with a braking action. Moreover, in very slow voluntary ramps, the movement cycles were often interspaced by periods of zero velocity, providing a highly non-sinusoidal velocity profile. 5. The EMG of the agonist and the antagonist muscles was modulated in close relation to the accelerations and decelerations respectively of the individual movement cycle. These modulations were present in both extensor and flexor muscles, although they were more consistent and usually more prominent in the former. 6. The findings indicate that a feature of slow finger movements was an 8-10 Hz periodic output to the muscular system, suggesting that slow finger movements are implemented by a series of biphasic force pulses, involving not only the shortening agonist muscle propelling the movement, but the antagonist muscle as well whose activity increased shortly after the agonist and contributed to a sharp deceleration of the individual step of movement. 7. It is proposed, as a hypothesis, that this biphasic motor output may reflect a similar organization of the descending motor command for slow finger movements. Hence, this command would include a series of biphasic pulses, concatenated at a rate of 8-10 per second and a pulse-height regulator capable of setting the size of the pulse and thus the overall speed of the movement.},
	journal = {J. Physiol.},
	author = {Vallbo, Ab and Wessberg, J},
	month = sep,
	year = {1993},
	keywords = {Jun 12 import},
	pages = {673--691},
}

@article{wessberg_real-time_2000,
	title = {Real-time prediction of hand trajectory by ensembles of cortical neurons in primates},
	volume = {408},
	abstract = {Signals derived from the rat motor cortex can be used for controlling one-dimensional movements of a robot arm. It remains unknown, however, whether real-time processing of cortical signals can be employed to reproduce, in a robotic device, the kind of complex arm movements used by primates to reach objects in space. Here we recorded the simultaneous activity of large populations of neurons, distributed in the premotor, primary motor and posterior parietal cortical areas, as non-human primates performed two distinct motor tasks. Accurate real-time predictions of one- and three-dimensional arm movement trajectories were obtained by applying both linear and nonlinear algorithms to cortical neuronal ensemble activity recorded from each animal. In addition, cortically derived signals were successfully used for real-time control of robotic devices, both locally and through the Internet. These results suggest that long-term control of complex prosthetic robot arm movements can be achieved by simple real-time transformations of neuronal population signals derived from multiple cortical areas in primates.},
	number = {6810},
	journal = {Nature},
	author = {Wessberg, J and Stambaugh, Cr and Kralik, Jd and Beck, Pd and Laubach, M and Chapin, Jk and Kim, J and Biggs, Sj and Srinivasan, Ma and Nicolelis, Ma},
	month = nov,
	year = {2000},
	keywords = {Jun 12 import},
	pages = {361--365},
}

@article{nicolelis_actions_2001,
	title = {Actions from thoughts},
	volume = {409 Suppl},
	abstract = {Real-time direct interfaces between the brain and electronic and mechanical devices could one day be used to restore sensory and motor functions lost through injury or disease. Hybrid brain-machine interfaces also have the potential to enhance our perceptual, motor and cognitive capabilities by revolutionizing the way we use computers and interact with remote environments.},
	journal = {Nature},
	author = {Nicolelis, Ma},
	month = jan,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {403--407},
}

@article{serruya_brain-machine_2002,
	title = {Brain-machine interface: {Instant} neural control of a movement signal},
	volume = {416},
	abstract = {The activity of motor cortex (MI) neurons conveys movement intent sufficiently well to be used as a control signal to operate artificial devices, but until now this has called for extensive training or has been confined to a limited movement repertoire. Here we show how activity from a few (7-30) MI neurons can be decoded into a signal that a monkey is able to use immediately to move a computer cursor to any new position in its workspace (14 degrees x 14 degrees visual angle). Our results, which are based on recordings made by an electrode array that is suitable for human use, indicate that neurally based control of movement may eventually be feasible in paralysed humans.},
	number = {6877},
	journal = {Nature},
	author = {Serruya, Md and Hatsopoulos, Ng and Paninski, L and Fellows, Mr and Donoghue, Jp},
	month = mar,
	year = {2002},
	keywords = {Jun 12 import},
	pages = {141--142},
}

@article{sereno_evolution_2000,
	title = {The {Evolution} of {Dinosaurs}},
	volume = {290},
	abstract = {A 290-million-year-old reptilian skeleton from the Lower Permian (Asselian) of Germany provides evidence of abilities for cursorial bipedal locomotion, employing a parasagittal digitigrade posture. The skeleton is of a small bolosaurid, Eudibamus cursoris, gen. et sp. nov., and confirms the widespread distribution of Bolosauridae across Laurasia during this early stage of amniote evolution. E. cursoris is the oldest known representative of Parareptilia, a major clade of reptiles.},
	journal = {Science},
	author = {Sereno, Paul C},
	month = nov,
	year = {2000},
	keywords = {Jun 12 import},
	pages = {969--972},
}

@article{ahn_motor_2002,
	title = {A motor and a brake: two leg extensor muscles acting at the same joint manage energy differently in a running insect},
	volume = {205},
	abstract = {The individual muscles of a multiple muscle group at a given joint are often assumed to function synergistically to share the load during locomotion. We examined two leg extensors of a running cockroach to test the hypothesis that leg muscles within an anatomical muscle group necessarily manage (i.e. produce, store, transmit or absorb) energy similarly during running. Using electromyographic and video motion-analysis techniques, we determined that muscles 177c and 179 are both active during the first half of the stance period during muscle shortening. Using the in vivo strain and stimulation patterns determined during running, we measured muscle power output. Although both muscles were stimulated during the first half of shortening, muscle 177c generated mechanical energy (28 W x kg(-1)) like a motor, while muscle 179 absorbed energy (-19 W x kg(-1)) like a brake. Both muscles exhibited nearly identical intrinsic characteristics including similar twitch kinetics and force-velocity relationships. Differences in the extrinsic factors of activation and relative shortening velocity caused the muscles to operate very differently during running. Presumed redundancy in a multiple muscle group may, therefore, represent diversity in muscle function. Discovering how muscles manage energy during behavior requires the measurement of a large number of dynamically interacting variables.},
	number = {Pt 3},
	journal = {J. Exp. Biol.},
	author = {Ahn, An and Full, Rj},
	month = feb,
	year = {2002},
	keywords = {Jun 12 import},
	pages = {379--389},
}

@article{patla_understanding_2002,
	title = {Understanding the contribution of binocular vision to the control of adaptive locomotion},
	volume = {142},
	abstract = {Although the contribution of binocular vision to reach-to-grasp movements has been extensively studied, it has been largely ignored in locomotion. The aim of these studies was to explore the role of binocular vision during the approach phase and step over the obstacle and the contribution of head movements to acquisition of depth information under monocular vision. Binocular and monocular vision was manipulated in different phases using either an eye patch or liquid crystal glasses. Head movement relative to the trunk was restricted in the first experiment by a modified Ferno Universal Head Immobilizer attached to a rigid board strapped to the participant's back. Whole body kinematics were collected by placing infrared diodes on anatomical landmarks and using an Optotrak imaging system. Several measures related to head and limb movement were analyzed. Three major findings emerged from these studies. First, binocular vision is important for the acquisition of accurate information about the surrounding environment: accuracy but not precision of limb elevation over the obstacle was adversely affected when binocular vision was unavailable. Second, motion parallax due to self-motion provides the most critical depth information and it can be used to partially compensate for the loss of binocular vision. Although head movement is not essential to augment depth information, it is important for reorientation of the visual field to obtain the necessary information about the moving limbs when visual field is suddenly limited under monocular vision. Third, step over the obstacle is pre-planned based on visual information acquired during the approach phase: changes in visual condition during the adaptive step do not influence the limb trajectory. Collectively these three studies provide unique insights into the contribution of binocular vision during adaptive locomotion.},
	number = {4},
	journal = {Exp. Brain Res.},
	author = {Patla, Aftab E and Niechwiej, Ewa and Racco, Vincent and Goodale, Melvyn A},
	year = {2002},
	keywords = {Jun 12 import, Adaptive locomotion - Vision - Monocular - Head movement - Distance perception},
	pages = {551--561},
}

@article{varraine_interaction_2002,
	title = {Interaction between different sensory cues in the control of human gait},
	volume = {142},
	abstract = {This experiment investigates the interaction of different sensory cues in the control of propulsive forces in human gait which in turn allow the body's forward progression to be regulated. The aim of this work was to determine how optic flow and leg-somatosensory feedback interact in this control. We therefore determined whether the responses to sinusoidal perturbations of optic flow were accentuated when leg-somatosensory feedback was modified by varying the support resistance. Subjects walked on a treadmill which was driven by their own locomotor activity (1) with a sinusoidal variation of optic flow velocity, (2) with a sinusoidal variation of support resistance which modified leg-somatosensory information and (3) with both visual and leg-somatosensory modification at different frequencies. The response of the subject was measured as changes in speed and propulsive power. The response to sinusoidal perturbations of optic flow was found to be increased and time delayed when visual perturbations are coupled with support perturbations in comparison with the response observed with visual perturbations only. This result shows the influence of leg-somatosensory feedback on the weighting of optic flow. Inversely, it was also found that the motor response to support perturbation was different when the flow was congruent (i.e., corresponding to the subject's virtual speed) and when it was not. This latter result shows the influence of optic flow on the weighting of leg-somatosensory feedback. The interaction between optic flow and leg-somatosensory feedback argues in favor of a multimodal sensory control of propulsive forces. This multimodal sensory control would be based on all the sensory feedback and all their mutual sensorial interaction. Therefore, the modification of one sensory input modifies not only this input but also the integration of the other inputs.},
	number = {3},
	journal = {Exp. Brain Res.},
	author = {Varraine, Elodie and Bonnard, Mireille and Pailhous, Jean},
	year = {2002},
	keywords = {Jun 12 import, Sensorial integration - Optic flow - Propulsive forces - Human gait},
	pages = {374--384},
}

@article{drew_role_1996,
	title = {Role of the motor cortex in the control of visually triggered gait modifications},
	volume = {74},
	abstract = {One important aspect of locomotor control is the ability of an animal to make anticipatory gait modifications to avoid obstacles, by stepping either around them or over them. This paper reviews some of the evidence that suggests that the motor cortex is one of the principal structures involved in the control of such anticipatory gait modifications in cats, in particular when they are triggered by a visual signal. Evidence for this statement is provided both from experiments in which the motor cortex has been lesioned or inactivated and from studies in which the activity of motor cortical neurones has been recorded during locomotor tasks in which visual information is required to ensure the correct positioning of the paw or an appropriate modification of the limb trajectory. Inactivation of small regions of the motor cortex with the GABA agonist muscimol results in changes in the limb trajectory so that cats hit an obstacle instead of stepping over it as they do normally. A similar disruption of the hindlimb trajectory is seen following lesions of the spinal cord at T13 that interrupt the corticospinal tract. The results from cell recording studies are complementary in that they show that the activity of many identified pyramidal tract neurones increases when the cat is required to modify the forelimb or hindlimb trajectory to step over obstacles. We suggest that the major function of this increased discharge frequency is to regulate the amplitude, duration, and temporal pattern of muscle activity during the gait modification to ensure an appropriate modification of limb trajectory. We further suggest that different groups of pyramidal tract neurones are involved in regulating the activity of groups of synergistic muscles active at different times in the gait modification. For example, some groups of pyramidal tract neurones would be involved in ensuring the appropriate and sequential activation of the muscle groups involved in the initial flexion of the elbow, while others would be active prior to the repositioning of the paw on the support surface. We discuss the possibility that the motor cortical activity seen during locomotion is the sum result of a feedforward signal, which provides visuospatial information about the environment, and feedback activity, which signals, in part, the state of the interneuronal pattern generating networks in the spinal cord. The way in which the resulting descending command may interact with the basic locomotor rhythm to produce the gait modifications is discussed.},
	number = {4},
	journal = {Can. J. Physiol. Pharmacol.},
	author = {Drew, Trevor and Jiang, Wan and Kably, Bouchra and Lavoie, Sylvain},
	month = apr,
	year = {1996},
	keywords = {motor cortex, locomotion, Jun 12 import, vision, supraspinal control, voluntary gait modification},
	pages = {426--442},
}

@article{schmitt_dynamics_2002,
	title = {Dynamics and stability of legged locomotion in the horizontal plane: a test case using insects},
	volume = {86},
	abstract = {Motivated by experimental studies of insects, we propose a model for legged locomotion in the horizontal plane. A three-degree-of freedom, energetically conservative, rigid-body model with a pair of compliant virtual legs in intermittent contact with the ground allows us to study how dynamics depends on parameters such as mass, moment of inertia, leg stiffness, and length. We find periodic gaits, and show that mechanics alone can confer asymptotic stability of relative heading and body angular velocity. We discuss the relevance of our idealized models to experiments and simulations on insect running, showing that their gait and force characteristics match observations reasonably well. We perform parameter studies and suggest that our model is relevant to the understanding of locomotion dynamics across species.},
	number = {5},
	journal = {Biol. Cybern.},
	author = {{Schmitt} and Garcia, M and Razo, R C and Holmes, P and Full, R J},
	year = {2002},
	keywords = {Jun 12 import},
	pages = {343--353},
}

@article{garwicz_common_2002,
	title = {Common principles of sensory encoding in spinal reflex modules and cerebellar climbing fibres},
	volume = {540},
	abstract = {An important step towards understanding the function of olivo-cerebellar climbing fibres must be to clarify what they signal. We suggest that climbing fibres projecting to paravermal cerebellum mediate highly integrated sensorimotor information derived from activity in spinal withdrawal reflex modules acting on single forelimb muscles. To test this hypothesis, cutaneous nociceptive receptive fields of spinal reflex modules were mapped and compared to those of climbing fibres. Quantitative methods were used both for mapping and for comparing receptive fields. The organization of muscle afferent input converging on individual climbing fibres was analysed in the light of results from receptive field comparisons. Individual cutaneous receptive fields in the two systems were readily matched. Matched pairs were highly similar with regard to detailed distributions of sensitivity: correlation coefficient r = 0.85; overlap of receptive field foci 72 \% (average values). The olivary targets of muscle afferents from a given muscle were mainly climbing fibres with cutaneous receptive fields similar to that of the muscle itself, but to a lesser extent also other climbing fibres. In conclusion, paravermal climbing fibres apparently convey information integrating (i) cutaneous input to an individual spinal withdrawal reflex module, (ii) muscle afferent input from the output muscle of that module and (iii) muscle afferent input from muscles that constitute the output of functionally related modules. This suggests that an individual climbing fibre signals cutaneous sensory events reflecting activity of a single muscle conditional upon the functional state of the muscle itself and that of functionally related muscles.},
	number = {Pt 3},
	journal = {J. Physiol.},
	author = {Garwicz, M and Levinsson, A and Schouenborg, J},
	month = may,
	year = {2002},
	keywords = {Jun 12 import},
	pages = {1061--1069},
}

@article{seyfarth_movement_2002,
	title = {A movement criterion for running},
	volume = {35},
	abstract = {The adjustment of the leg during running was addressed using a spring-mass model with a fixed landing angle of attack. The objective was to obtain periodic movement patterns. Spring-like running was monitored by a one-dimensional stride-to-stride mapping of the apex height to identify mechanically stable fixed points.We found that for certain angles of attack, the system becomes self-stabilized if the leg stiffness was properly adjusted and a minimum running speed was exceeded. At a given speed, running techniques fulfilling a stable movement pattern are characterized by an almost constant maximum leg force. With increasing speed, the leg adjustment becomes less critical. The techniques predicted for stable running are in agreement with experimental studies.Mechanically self-stabilized running requires a spring-like leg operation, a minimum running speed and a proper adjustment of leg stiffness and angle of attack. These conditions can be considered as a movement criterion for running.},
	number = {5},
	journal = {J. Biomech.},
	author = {Seyfarth, Andre and Geyer, Hartmut and Günther, Michael and Blickhan, Reinhard},
	month = may,
	year = {2002},
	keywords = {Jun 12 import},
	pages = {649--655},
}

@article{perreault_voluntary_2002,
	title = {Voluntary control of static endpoint stiffness during force regulation tasks},
	volume = {87},
	abstract = {The goals of this study were to determine the degree to which subjects could voluntarily modulate static endpoint stiffness orientation and to quantify the effects of simultaneously generated voluntary endpoint forces on this ability. Static endpoint stiffness, which characterizes the relationship between externally imposed displacements of the hand and the elastic forces generated in response, was estimated in real time during the application of planar, stochastic perturbations of endpoint position. This estimation was accomplished using a real-time parametric identification algorithm on measured force and position data. Subjects were provided with real-time visual feedback of endpoint stiffness, and their ability to modulate the orientation of maximum static stiffness was measured for different endpoint force magnitudes and directions. We found that individuals can voluntarily change stiffness orientation but that the magnitude of these changes is small, the range of available stiffness orientations decreases as endpoint force exertion increases, and endpoint force direction significantly constrains direction and magnitude of the stiffness orientations that can be achieved. Given these findings it appears unlikely that static endpoint stiffness orientation is controlled independently of force by voluntary neural mechanisms during postural tasks.},
	number = {6},
	journal = {J. Neurophysiol.},
	author = {Perreault, Ej and Kirsch, Rf and Crago, Pe},
	month = jun,
	year = {2002},
	keywords = {Jun 12 import},
	pages = {2808--2816},
}

@article{ivanenko_control_2002,
	title = {Control of foot trajectory in human locomotion: role of ground contact forces in simulated reduced gravity},
	volume = {87},
	abstract = {We studied the changes of vertical contact forces, lower limb kinematics, and electromyographic activity (EMG) at different speeds and gravitational loads. To this end healthy subjects were asked to walk on a motorized treadmill while the percentage of body weight unloaded (body weight support, BWS) was modified in steps by means of a well-characterized unloading system. BWS was set at 0, 35, 50, 75, 95, or 100\% of body weight. Walking speed was 0.7, 1.1, 2, 3, or 5 km/h. We found that changing BWS between 0 and 95\% resulted in drastic changes of kinetic parameters but in limited changes of the kinematic coordination. In particular, the peak vertical contact forces decreased proportionally to BWS; at 95\%-BWS they were 20-fold smaller than at 0\% and were applied at the forefoot only. Also, there were considerable changes of the amplitude of EMG activity of all tested lower limb muscles and a complex re-organization of the pattern of activity of thigh muscles. By contrast, the corresponding variation of the parameters that describe shape and variability of the foot path was very limited, always {\textless}30\% of the corresponding values at 0 BWS. Moreover, the planar co-variation of the elevation angles was obeyed at all speed and BWS values. Minimum variance of limb trajectory occurred at 3 km/h. At 100\% BWS, subjects stepped in the air, their feet oscillating back and forth just above but never contacting the treadmill. In this case, step-to-step variability of foot path was much greater than at all other BWS levels but was restored to lower values when minimal surrogate contact forces were provided during the “stance” phase. The results did not depend on the specific instruction given to the subject. Therefore we conclude that minimal contact forces are sufficient for accurate foot trajectory control.},
	number = {6},
	journal = {J. Neurophysiol.},
	author = {Ivanenko, Yp and Grasso, R and Macellari, V and Lacquaniti, F},
	month = jun,
	year = {2002},
	keywords = {Jun 12 import},
	pages = {3070--3089},
}

@article{georgopoulos_relations_1982-1,
	title = {On the relations between the direction of two-dimensional arm movements and cell discharge in primate motor cortex},
	volume = {2},
	abstract = {The activity of single cells in the motor cortex was recorded while monkeys made arm movements in eight directions (at 45 degrees intervals) in a two-dimensional apparatus. These movements started from the same point and were of the same amplitude. The activity of 606 cells related to proximal arm movements was examined in the task; 323 of the 606 cells were active in that task and were studied in detail. The frequency of discharge of 241 of the 323 cells (74.6\%) varied in an orderly fashion with the direction of movement. Discharge was most intense with movements in a preferred direction and was reduced gradually when movements were made in directions farther and farther away from the preferred one. This resulted in a bell-shaped directional tuning curve. These relations were observed for cell discharge during the reaction time, the movement time, and the period that preceded the earliest changes in the electromyographic activity (approximately 80 msec before movement onset). In about 75\% of the 241 directionally tuned cells, the frequency of discharge, D, was a sinusoidal function of the direction of movement, theta: D = b0 + b1 sin theta + b2cos theta, or, in terms of the preferred direction, theta 0: D = b0 + c1cos (theta - theta0), where b0, b1, b2, and c1 are regression coefficients. Preferred directions differed for different cells so that the tuning curves partially overlapped. The orderly variation of cell discharge with the direction of movement and the fact that cells related to only one of the eight directions of movement tested were rarely observed indicate that movements in a particular direction are not subserved by motor cortical cells uniquely related to that movement. It is suggested, instead, that a movement trajectory in a desired direction might be generated by the cooperation of cells with overlapping tuning curves. The nature of this hypothetical population code for movement direction remains to be elucidated.},
	number = {11},
	journal = {J. Neurosci.},
	author = {Georgopoulos, A P and Kalaska, J F and Caminiti, R and Massey, J T},
	month = nov,
	year = {1982},
	keywords = {Jun 12 import},
	pages = {1527--1537},
}

@article{fadiga_motor_1995,
	title = {Motor facilitation during action observation: a magnetic stimulation study},
	volume = {73},
	abstract = {1. We stimulated the motor cortex of normal subjects (transcranial magnetic stimulation) while they 1) observed an experimenter grasping 3D-objects, 2) looked at the same 3D-objects, 3) observed an experimenter tracing geometrical figures in the air with his arm, and 4) detected the dimming of a light. Motor evoked potentials (MEPs) were recorded from hand muscles. 2. We found that MEPs significantly increased during the conditions in which subjects observed movements. The MEP pattern reflected the pattern of muscle activity recorded when the subjects executed the observed actions. 3. We conclude that in humans there is a system matching action observation and execution. This system resembles the one recently described in the monkey.},
	number = {6},
	journal = {J. Neurophysiol.},
	author = {Fadiga, L and Fogassi, L and Pavesi, G and Rizzolatti, G},
	month = jun,
	year = {1995},
	keywords = {Jun 12 import},
	pages = {2608--2611},
}

@article{de_rugy_perception-action_2002,
	title = {Perception-action coupling model for human locomotor pointing},
	volume = {87},
	abstract = {How do humans achieve the precise positioning of the feet during walking, for example, to reach the first step of a stairway? We addressed this question at the visuomotor integration level. Based on the optical specification of the required adaptation, a dynamical system model of the visuomotor control of human locomotor pointing was devised for the positioning of a foot on a visible target on the floor during walking. Visuomotor integration consists of directly linking optical information to a motor command that specifically modulates step length in accordance with the ongoing dynamics of locomotor pattern generation. The adaptation of locomotion emerges from a perception-action coupling type of control based on temporal information rather than on feedforward planning of movements. The proposed model reproduces experimental results obtained for human locomotor pointing.},
	number = {2},
	journal = {Biol. Cybern.},
	author = {de Rugy, A and Taga, G and Montagne, G and Buekers, M J and Laurent, M},
	month = aug,
	year = {2002},
	keywords = {Jun 12 import},
	pages = {141--150},
}

@article{jindrich_many-legged_1999,
	title = {Many-legged maneuverability: dynamics of turning in hexapod},
	volume = {202},
	abstract = {Remarkable similarities in the vertical plane of forward motion exist among diverse legged runners. The effect of differences in posture may be reflected instead in maneuverability occurring in the horizontal plane. The maneuver we selected was turning during rapid running by the cockroach Blaberus discoidalis, a sprawled-postured arthropod. Executing a turn successfully involves at least two requirements. The animal's mean heading (the direction of the mean velocity vector of the center of mass) must be deflected, and the animal's body must rotate to keep the body axis aligned with the heading. We used two-dimensional kinematics to estimate net forces and rotational torques, and a photoelastic technique to estimate single-leg ground-reaction forces during turning. Stride frequencies and duty factors did not differ among legs during turning. The inside legs ended their steps closer to the body than during straight-ahead running, suggesting that they contributed to turning the body. However, the inside legs did not contribute forces or torques to turning the body, but actively pushed against the turn. Legs farther from the center of rotation on the outside of the turn contributed the majority of force and torque impulse which caused the body to turn. The dynamics of turning could not be predicted from kinematic measurements alone. To interpret the single-leg forces observed during turning, we have developed a general model that relates leg force production and leg position to turning performance. The model predicts that all legs could turn the body. Front legs can contribute most effectively to turning by producing forces nearly perpendicular to the heading, whereas middle and hind legs must produce additional force parallel to the heading. The force production necessary to turn required only minor alterations in the force hexapods generate during dynamically stable, straight-ahead locomotion. A consideration of maneuverability in the horizontal plane revealed that a sprawled-postured, hexapodal body design may provide exceptional performance with simplified control.},
	number = {Pt 12},
	journal = {J. Exp. Biol.},
	author = {Jindrich, Dl and Full, Rj},
	month = jun,
	year = {1999},
	keywords = {Jun 12 import},
	pages = {1603--1623},
}

@article{jindrich_dynamic_2002,
	title = {Dynamic stabilization of rapid hexapedal locomotion},
	volume = {205},
	abstract = {To stabilize locomotion, animals must generate forces appropriate to overcome the effects of perturbations and to maintain a desired speed or direction of movement. We studied the stabilizing mechanism employed by rapidly running insects by using a novel apparatus to perturb running cockroaches (Blaberus discoidalis). The apparatus used chemical propellants to accelerate a small projectile, generating reaction force impulses of less than 10 ms duration. The apparatus was mounted onto the thorax of the insect, oriented to propel the projectile laterally and loaded with propellant sufficient to cause a nearly tenfold increase in lateral velocity relative to maxima observed during unperturbed locomotion. Cockroaches were able to recover from these perturbations in 27+/-12 ms (mean +/- S.D., N=9) when running on a high-friction substratum. Lateral velocity began to decrease 13+/-5 ms (mean +/- S.D., N=11) following the start of a perturbation, a time comparable with the fastest reflexes measured in cockroaches. Cockroaches did not require step transitions to recover from lateral perturbations. Instead, they exhibited viscoelastic behavior in the lateral direction, with spring constants similar to those observed during unperturbed locomotion. The rapid onset of recovery from lateral perturbations supports the possibility that, during fast locomotion, intrinsic properties of the musculoskeletal system augment neural stabilization by reflexes.},
	number = {Pt 18},
	journal = {J. Exp. Biol.},
	author = {Jindrich, Dl and Full, Rj},
	month = sep,
	year = {2002},
	keywords = {Jun 12 import},
	pages = {2803--2823},
}

@article{laje_neuromuscular_nodate,
	title = {Neuromuscular control of vocalizations in birdsong: {A} model},
	volume = {65},
	abstract = {We present a dynamical model of the processes involved in birdsong production, relating qualitatively its parameters with biological ones. In this way, we intend to unify the activity patterns of the muscles controlling the vocal organ with the resulting vocalization. With relatively simple paths in the parameter space of our model, we reproduce experimental recordings of the Chingolo sparrow (Zonotrichia capensis).},
	journal = {Phys. Rev. E Stat. Nonlin. Soft Matter Phys.},
	author = {Laje, Rodrigo and Gardner, Timothy J and Mindlin, Gabriel B},
	keywords = {Jun 12 import},
	pages = {051921},
}

@article{gardner_simple_2001,
	title = {Simple {Motor} {Gestures} for {Birdsongs}},
	volume = {87},
	abstract = {We present a model of sound production in a songbird's vocal organ and find that much of the complexity of the song of the canary ( Serinus canaria) can be produced from simple time variations in forcing functions. The starts, stops, and pauses between syllables, as well as variation in pitch and timbre are inherent in the mechanics and can often be expressed through smooth and simple variations in the frequency and relative phase of two driving parameters},
	journal = {Phys. Rev. Lett.},
	author = {Gardner, Tim and Cecchi, G and Magnasco, M and Laje, R and Mindlin, Gabriel B},
	month = nov,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {208101},
}

@article{lacquaniti_motor_1999,
	title = {Motor {Patterns} in {Walking}},
	volume = {14},
	abstract = {Despite the fact that locomotion may differ widely in mammals, common principles of kinematic control are at work. These reflect common mechanical and neural constraints. The former are related to the need to maintain balance and to limit energy expenditure. The latter are related to the organization of the central pattern-generating networks.},
	journal = {News Physiol. Sci.},
	author = {Lacquaniti, F and Grasso, R and Zago, M},
	month = aug,
	year = {1999},
	keywords = {Jun 12 import},
	pages = {168--174},
}

@article{patla_how_2003,
	title = {How far ahead do we look when required to step on specific locations in the travel path during locomotion?},
	volume = {148},
	abstract = {Spatial-temporal gaze behaviour patterns were analysed as normal participants wearing a mobile eye tracker were required to step on 17 footprints, regularly or irregularly spaced over a 10-m distance, placed in their travel path. We examined the characteristics of two types of gaze fixation with respect to the participants' stepping patterns: footprint fixation; and travel fixation when the gaze is stable and travelling at the speed of whole body. The results showed that travel gaze fixation is a dominant gaze behaviour occupying over 50\% of the travel time. It is hypothesised that this gaze behaviour would facilitate acquisition of environmental and self-motion information from the optic flow that is generated during locomotion: this in turn would guide movements of the lower limbs to the appropriate landing targets. When participants did fixate on the landing target they did so on average two steps ahead, about 800-1,000 ms before the limb is placed on the target area. This would allow them sufficient time to successfully modify their gait patterns. None of the gaze behaviours was influenced by the placement (regularly versus irregularly spaced) of the footprints or repeated exposures to the travel path. Rather visual information acquired during each trial was used “de novo” to modulate gait patterns. This study provides a clear temporal link between gaze and stepping pattern and adds to our understanding of how vision is used to regulate locomotion.},
	number = {1},
	journal = {Exp. Brain Res.},
	author = {Patla, Aftab E and Vickers, Joan N},
	month = jan,
	year = {2003},
	keywords = {Jun 12 import, Gaze behaviour - Human locomotion - Feedforward control - Cluttered terrain},
	pages = {133--138},
}

@article{alexander_energetics_2002,
	title = {Energetics and optimization of human walking and running: the 2000 {Raymond} {Pearl} memorial lecture},
	volume = {14},
	abstract = {Humans seem to adjust their walking and running gaits to minimise the metabolic energy cost of locomotion. The walking speed that we tend to prefer is the one that minimises energy cost per unit distance, though faster speeds might seem preferable when time is valuable. At speeds up to 2 m/s, walking requires less energy than running, and we walk. At higher speeds, running is more economical, and we run. At each speed we use the stride length that minimises energy costs. A computer model that predicts metabolic rates for all conceivable gaits of a simple biped helps to understand these and other features of human gait. The energy cost of walking is increased on uphill slopes and also on soft ground. Consequently, zigzag paths should be preferred to straight ones, up hills of more than a critical gradient. Also, it may be more economical to divert a path around a hill than to travel along a straight line. Simple theories of optimum diversions are presented, both for hilly ground and for ground interrupted by marshy patches, on which costs of walking are increased. Energy costs are also increased by heavy loads, though it seems possible in some circumstances to carry moderate loads without measurable extra cost. Copyright 2002 Wiley-Liss, Inc.},
	number = {5},
	journal = {Am. J. Hum. Biol.},
	author = {Alexander, R Mcneill},
	year = {2002},
	keywords = {Jun 12 import},
	pages = {641--8.},
}

@article{jackson_synchrony_2003,
	title = {Synchrony between {Neurons} with {Similar} {Muscle} {Fields} in {Monkey} {Motor} {Cortex}},
	volume = {38},
	abstract = {Synchronous firing of motor cortex cells exhibiting postspike facilitation (PSF) or suppression (PSS) of hand muscle EMG was examined to investigate the relationship between synchrony and output connectivity. Recordings were made in macaque monkeys performing a precision grip task. Synchronization was assessed with cross-correlation histograms of the activity from 144 pairs of simultaneously recorded neurons, while spike-triggered averages of EMG defined the muscle field for each cell. Cell pairs with similar muscle fields showed greater synchronization than pairs with nonoverlapping fields. Furthermore, cells with opposing effects in the same muscles exhibited negative synchronization. We conclude that synchrony in motor cortex engages networks of neurons directly controlling the same muscle set, while inhibitory connections exist between neuronal populations with opposing output effects.},
	journal = {Neuron},
	author = {Jackson, Andrew and Gee, Veronica J and Baker, Stuart N and Lemon, Roger N},
	year = {2003},
	keywords = {Jun 12 import},
	pages = {115--125},
}

@article{patton_relative_2000,
	title = {Relative stability improves with experience in a dynamic standing task},
	volume = {135},
	abstract = {This study tested the hypothesis that subjects improve their relative stability as they learn a dynamic pulling task. Healthy adult subjects practiced making brief horizontal pulls ({\textless}300 ms) on a handle to a range of target forces ranging from 20 to 80\% of their estimated maximum for 5 days. They were instructed to always keep their feet flat and begin and end their motion in an upright posture. In order to do this, subjects had to develop the appropriate body momentum prior to the pull and then recover their balance following the pull. We analyzed relative stability during balance recovery, using two measures: spatial safety margin (minimum distance of the center of pressure, COP, to the edges of the feet) and temporal safety margin (minimum extrapolated time for the COP to reach the edges of the feet). We hypothesized that: (1) spatial and temporal safety margins would be uncorrelated; (2) safety-margin means would increase with practice; and (3) safety-margin standard deviations would decrease with practice. Two experiments were conducted: one where subjects practiced three force targets and positioned their initial COP in a small window, and one where subjects practiced two force targets with no initial COP constraint. Results showed that spatial and temporal safety margins were correlated but shared less than 6\% variance, indicating that they reflected different aspects of control. Safety-margin averages increased with practice and standard deviations decreased with practice, indicating that the stability of balance control in the execution of this task became more robust. We suggest that the nervous system could use safety margins in both feedback and feedforward control of balance.},
	number = {1},
	journal = {Exp. Brain Res.},
	author = {Patton, James L and Lee, Wynne A and Pai, Yi-Chung},
	month = nov,
	year = {2000},
	keywords = {Jun 12 import, human, motor learning, balance control, constraints, posture, robust control},
	pages = {117--126},
}

@article{ivanchenko_developmental_2003,
	title = {A developmental approach {AIDS} motor learning},
	volume = {15},
	abstract = {Bernstein (1967) suggested that people attempting to learn to perform a difficult motor task try to ameliorate the degrees-of-freedom problem through the use of a developmental progression. Early in training, people maintain a subset of their control parameters (e.g., joint positions) at constant settings and attempt to learn to perform the task by varying the values of the remaining parameters. With practice, people refine and improve this early-learned control strategy by also varying those parameters that were initially held constant. We evaluated Bernstein's proposed developmental progression using six neural network systems and found that a network whose training included developmental progressions of both its trajectory and its feedback gains outperformed all other systems. These progressions, however, yielded performance benefits only on motor tasks that were relatively difficult to learn. We conclude that development can indeed aid motor learning.},
	number = {9},
	journal = {Neural Comput.},
	author = {Ivanchenko, V and Jacobs, Ra},
	month = sep,
	year = {2003},
	keywords = {Jun 12 import},
	pages = {2051--65.},
}

@article{heglund_energy-saving_1995,
	title = {Energy-saving gait mechanics with head-supported loads},
	volume = {375},
	abstract = {In many areas of the world that lack a transportation infrastructure, people routinely carry extraordinary loads supported by their heads, for example the Sherpa of the Himalayas and the women of East Africa. It has previously been shown that African women from the Kikuyu and Luo tribes can carry loads substantially more cheaply than army recruits; however, the mechanism for their economy has remained unknown. Here we investigate, using a force platform, the mechanics of carrying head-supported loads by Kikuyu and Luo women. The weight-specific mechanical work, required to maintain the motion of the common centre of mass of the body and load, decreases with load in the African women, whereas it increases in control subjects. The decrease in work by the African women is a result of a greater conservation of mechanical energy resulting from an improved pendulum-like transfer of energy during each step, back and forth between gravitational potential energy and kinetic energy of the centre of mass.},
	number = {6526},
	journal = {Nature},
	author = {Heglund, Nc and Willems, Pa and Penta, M and Cavagna, Ga},
	month = may,
	year = {1995},
	keywords = {Jun 12 import},
	pages = {52--4.},
}

@article{shadmehr_adaptive_1994,
	title = {Adaptive representation of dynamics during learning of a motor task},
	volume = {14},
	abstract = {We investigated how the CNS learns to control movements in different dynamical conditions, and how this learned behavior is represented. In particular, we considered the task of making reaching movements in the presence of externally imposed forces from a mechanical environment. This environment was a force field produced by a robot manipulandum, and the subjects made reaching movements while holding the end-effector of this manipulandum. Since the force field significantly changed the dynamics of the task, subjects' initial movements in the force field were grossly distorted compared to their movements in free space. However, with practice, hand trajectories in the force field converged to a path very similar to that observed in free space. This indicated that for reaching movements, there was a kinematic plan independent of dynamical conditions. The recovery of performance within the changed mechanical environment is motor adaptation. In order to investigate the mechanism underlying this adaptation, we considered the response to the sudden removal of the field after a training phase. The resulting trajectories, named aftereffects, were approximately mirror images of those that were observed when the subjects were initially exposed to the field. This suggested that the motor controller was gradually composing a model of the force field, a model that the nervous system used to predict and compensate for the forces imposed by the environment. In order to explore the structure of the model, we investigated whether adaptation to a force field, as presented in a small region, led to aftereffects in other regions of the workspace. We found that indeed there were aftereffects in workspace regions where no exposure to the field had taken place; that is, there was transfer beyond the boundary of the training data. This observation rules out the hypothesis that the subject's model of the force field was constructed as a narrow association between visited states and experienced forces; that is, adaptation was not via composition of a look-up table. In contrast, subjects modeled the force field by a combination of computational elements whose output was broadly tuned across the motor state space. These elements formed a model that extrapolated to outside the training region in a coordinate system similar to that of the joints and muscles rather than end-point forces. This geometric property suggests that the elements of the adaptive process represent dynamics of a motor task in terms of the intrinsic coordinate system of the sensors and actuators.},
	number = {5 Pt 2},
	journal = {J. Neurosci.},
	author = {Shadmehr, R and Ivaldi, Mussa-Fa},
	month = may,
	year = {1994},
	keywords = {Jun 12 import},
	pages = {3208--24.},
}

@article{donelan_mechanical_2001,
	title = {Mechanical and metabolic determinants of the preferred step width in human walking},
	volume = {268},
	abstract = {We studied the selection of preferred step width in human walking by measuring mechanical and metabolic costs as a function of experimentally manipulated step width (0.00 - 0.45L; fraction of leg length, L). We estimated mechanical costs from individual limb external mechanical work and metabolic costs using open circuit respirometry. For widths greater than the preferred value (0.15 - 0.45L), mechanical and metabolic costs both increased substantially (54\% and 45\%, respectively) and with step width squared (R2 = 0.91 and 0.83, respectively). As predicted by a three-dimensional model of walking mechanics, increases in these costs appear to be a result of the mechanical work required to redirect the center of mass velocity during the transition between single stance phases (stance limb transition cost). For steps narrower than preferred (0.10 - 0.00L), metabolic cost increased by 8\%, likely a result of the added cost of moving the swing leg laterally to avoid the stance leg (lateral limb swing cost). Tradeoffs between stance limb transition and lateral limb swing costs resulted in a minimum metabolic cost at a step width of 0.12L, not significantly different from foot width (0.11L) or preferred step width (0.13L). Humans appear to prefer a step width that minimizes metabolic cost.},
	journal = {Proc. R. Soc. Lond. B Biol. Sci.},
	author = {Donelan, J Maxwell and Kram, Rodger and Kuo, Arthur D},
	year = {2001},
	keywords = {locomotion, Jun 12 import, biomechanics, biped, energetics},
	pages = {1985--1992},
}

@article{hirasaki_highly_2004,
	title = {Do highly trained monkeys walk like humans? {A} kinematic study of bipedal locomotion in bipedally trained {Japanese} macaques},
	volume = {46},
	abstract = {In this study, we examined the kinematics of bipedal walking in macaque monkeys that have been highly trained to stand and walk bipedally, and compared them to the kinematics of bipedal walking in ordinary macaques. The results revealed that the trained macaques walked with longer and less frequent strides than ordinary subjects. In addition, they appear to have used inverted pendulum mechanics during bipedal walking, which resulted in an efficient exchange of potential and kinetic energy. These gait characteristics resulted from the relatively more extended hindlimb joints of the trained macaques. By contrast, the body of the ordinary macaques translated downward during the single-limb stance phase due to more flexed hindlimb joints. This resulted in almost in-phase fluctuations of potential and kinetic energy, which indicated that energy transformation was less efficient in the ordinary macaques. The findings provide two insights into the early stage of the evolution of human bipedalism. First, the finding that training considerably improved bipedal walking a posteriori may explain why the very first bipeds that might not yet have been morphologically adapted to bipedal walking continued to walk bipedally. The evolutionary transition from quadrupedalism to bipedalism might not be as difficult as has been envisioned. In addition, the finding that macaques, which are phylogenetically distant from humans and in which bipedal walking is unlike human walking, could develop humanlike gait characteristics with training, provides strong support for the commonly held but unproven idea that the characteristics of the human gait are advantageous to human bipedalism.},
	number = {6},
	journal = {J. Hum. Evol.},
	author = {Hirasaki, Eishi and Ogihara, Naomichi and Hamada, Yuzuru and Kumakura, Hiroo and Nakatsukasa, Masato},
	month = jun,
	year = {2004},
	keywords = {Jun 12 import, Bipedalism, Energy cost, Hindlimb joints, Inverted pendulum, Macaca fuscata},
	pages = {739--750},
}

@article{borst_spatio-temporal_1988,
	title = {Spatio-{Temporal} {Integration} of {Motion}: {A} simple strategy for safe landing in flies},
	volume = {75},
	journal = {Naturwissenschaften},
	author = {Borst, A and Bahde, S},
	year = {1988},
	keywords = {Jun 12 import},
	pages = {265--267},
}

@article{borst_time_1986,
	title = {Time {Course} of the {Houseflies}' {Landing} {Response}},
	volume = {54},
	abstract = {The landing response of stationary flying houseflies 'Musca domestica' has been recorded on video tape. The leg movements were quantitatively evaluated. It could be demonstrated that: 1) only the first two pairs of legs are invloved in the reaction (Fig. 1). Prothoracic tarsi are lifted beyond the head, mesothoracic tarsi are lowered and moved sidewards (Fig. 2a and b). 2) the movement of the tarsal tips is mainly due to an opening of one single joint per leg, i.e. the femur-tibia joint of the prothoracic leg (Fig. 2c), and the coxa-femur joint of the mesothoracic leg. 3) the landing reaction is a fixed action pattern which does not seem to require further sensory input once it is released (Fig. 4d). 4) the landing responses to a light-off stimulus and to expanding patterns with different angular velocities are indistinguishable (compare Fig. 3a-c with Fig. 2a-c). The only parameter that is obviously dependent on the stimulus conditions, is the latency of the reaction (Fig. 4a-c).},
	journal = {Biol. Cybern.},
	author = {Borst, A},
	year = {1986},
	keywords = {Jun 12 import},
	pages = {379--383},
}

@article{borst_comparison_1987,
	title = {Comparison between the {Movement} {Detection} {Systems} {Underlying} the {Optomotor} and the {Landing} {Response} in the {Housefly}},
	volume = {56},
	abstract = {Flies evaluate movement within their visual field in order to control the course of flight and to elicit landing manoeuvres. Although the motor output of the two types of responses is quite different, both systems can be compared with respect to the underlying movement detection systems. For a quantitative comparison, both responses were measured during tethered flight under identical conditions. The stimulus was a sinusoidal periodic pattern of vertical stripes presented bilaterally in the fronto-lateral eye region of the fly. To release the landing response, the pattern was moved on either side from front to back. The latency of the response depends on the stimulus conditions and was measured by means of an infrared light-beam that was interrupted whenever the fly lifted its forelegs to assume a preprogrammed landing posture (Borst and Bahde 1986). As an optomotor stimulus the pattern moved on one side from front to back and on the other side in the opposite direction. The induced turning tendency was measured by a torque meter (Gotz 1964). The response values which will be compared are the inverse latencies of the landing response and the amplitude of the yaw torque. 1. Optomotor course-control is more sensitive to pattern movement at small spatial wavelengths (10 deg. and 20 deg.) than the landing response (Fig. 1a and b). This suggests that elementary movement detectors (EMDs, Buchner 1976) with large detection base (the distance between interacting visual elements) contriubute more strongly to the landing than to the optomotor system. 2. The optimum contrast frequencies of the different responses obtained at a comparatively high pattern contrast of about 0.6 was found to be between 1 and 10 Hz for the optomotor response, and around 20 Hz for the landing response (Fig. 2a and b). This discrepancy can be explained by the fact that the optomotor response was tested under stationary conditions (several seconds of stimulation) while for the landing response transient response characteristics of the movement detectors have to be taken into account (landing occurs under these conditions within less than 100 ms after onset of the movement stimulus). To test the landing system under more stationary conditions, the pattern contrast had to be reduced to low values. This led to latencies of several seconds. Then the optimum of the landing response is around 4 Hx. This is in the optimum range of the optomotor course-control response. The result suggests the same filter time constants for the movement detectors of both systems. 3. The dependence of both responses on the position and the size of the pattern was examined. The landing response has its optimum sensitivity more ventrally than the optomotor response (Fig. 3a and b). Both response amplitudes increase with the size of the pattern in a similar progression (Fig. 3c and d). In first approximation, the present results are compatible with the assumption of a common set of movement detectors for both the optomotor course-control and the landing system. Movement detectors with different sampling bases and at different positions in the visual field seem to contribute with different gain to both responses. Accordingly, the control systems underlying both behaiors are likely to be independent already at the level of spatial integration of the detector output.},
	journal = {Biol. Cybern.},
	author = {Borst, A and Bahde, S},
	year = {1987},
	keywords = {Jun 12 import},
	pages = {217--224},
}

@incollection{doya_computational_1998,
	title = {A computational model of birdsong learning by auditory experience and auditory feedback},
	booktitle = {Central {Auditory} {Processing} and {Neural} {Modeling}},
	publisher = {Plenum Publishing},
	author = {Doya, K and Sejnowski, T J},
	editor = {Brugge, J and Poon, P},
	year = {1998},
	keywords = {Jun 12 import},
	pages = {77--88},
}

@incollection{doya_novel_1995-1,
	title = {A novel reinforcement model of birdsong vocalization learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 7},
	publisher = {MIT Press},
	author = {Doya, K and Sejnowski, T J},
	editor = {Tesauro, G and Touretzky, D S and Leen, T K},
	year = {1995},
	keywords = {Jun 12 import},
	pages = {101--108},
}

@article{hahnloser_bayesian_2002,
	title = {A bayesian characterization of a feedforward signal pathway in the songbird},
	journal = {Advances in Neural Information Processing Systems, submitted},
	author = {Hahnloser, R H R and Brown, E N and Kozhevnikov, A A and Fee, M S},
	year = {2002},
	keywords = {Jun 12 import},
}

@article{willshaw_non-holographic_1969,
	title = {Non-holographic associative memory},
	volume = {222},
	journal = {Nature},
	author = {Willshaw, D J and Buneman, O P and Longuet-Higgins, H C},
	year = {1969},
	keywords = {Jun 12 import},
	pages = {960--962},
}

@article{herrmann_analysis_1995,
	title = {Analysis of synfire chains},
	volume = {6},
	number = {3},
	journal = {Network: Comput. Neural Syst.},
	author = {Herrmann, M and Hertz, J A and Prugel-Bennett, A},
	month = aug,
	year = {1995},
	keywords = {Jun 12 import},
	pages = {403--414},
}

@article{golomb_willshaw_1990,
	title = {Willshaw model: associative memory with sparse coding and low firing rates},
	volume = {41},
	journal = {Phys. Rev. A},
	author = {Golomb, D and Rubin, N and Sompolinsky, H},
	year = {1990},
	keywords = {Jun 12 import},
	pages = {1843--1854},
}

@article{tsodyks_enhanced_1988-1,
	title = {Enhanced {Storage} {Capacity} in {Neural} {Networks} with {Low} {Level} of {Activity}},
	volume = {6},
	journal = {Europhys. Lett.},
	author = {Tsodyks, M and Feigelman, M},
	year = {1988},
	keywords = {Jun 12 import},
	pages = {101},
}

@article{amari_learning_1972-2,
	title = {Learning pattern and pattern sequences by self-organizing nets of threshold elements},
	journal = {IEEE Trans. Comput.},
	author = {Amari, S-I},
	year = {1972},
	keywords = {Jun 12 import},
	pages = {1197--1206},
}

@article{mooney_synaptic_1992-1,
	title = {Synaptic basis for developmental plasticity in a birdsong nucleus},
	volume = {12},
	journal = {J. Neurosci.},
	author = {Mooney, R},
	year = {1992},
	keywords = {Jun 12 import},
	pages = {2464--2477},
}

@article{nottebohm_central_1976-1,
	title = {Central control of song in the canary, {Serinus} canarius},
	volume = {165},
	journal = {J. Comp. Neurol.},
	author = {Nottebohm, F and Stokes, T M and Leonard, C M},
	year = {1976},
	keywords = {Jun 12 import},
	pages = {457--486},
}

@article{georgopoulos_motor_1992,
	title = {The {Motor} {Cortex} and the {Coding} of {Force}},
	volume = {256},
	number = {5064},
	journal = {Science},
	author = {Georgopoulos, A and Ashe, J and Smyrnis, N and Taira, M},
	month = jun,
	year = {1992},
	keywords = {Jun 12 import},
	pages = {1692--1695},
}

@article{theunissen_spectral-temporal_2000,
	title = {Spectral-temporal receptive fields of nonlinear auditory neurons obtained using natural sounds},
	volume = {20},
	number = {6},
	journal = {J. Neurosci.},
	author = {Theunissen, F E and Sen, K and Doupe, A J},
	month = mar,
	year = {2000},
	keywords = {Jun 12 import},
	pages = {2315--2331},
}

@article{simpson_brain_1990,
	title = {Brain pathways for learned and unlearned vocalizations differ in zebra finches},
	volume = {10},
	number = {5},
	journal = {J. Neurosci.},
	author = {Simpson, H B and Vicario, D S},
	year = {1990},
	keywords = {Jun 12 import},
	pages = {1541--1556},
}

@article{nordeen_long-term_1993,
	title = {Long-term maintenance of song in adult zebra finches is not affected by lesions of a forebrain region involved in song learning},
	volume = {59},
	journal = {Behav. Neural Biol.},
	author = {Nordeen, K and Nordeen, E},
	year = {1993},
	keywords = {Jun 12 import},
	pages = {79--82},
}

@article{williams_simple_1992-1,
	title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
	volume = {8},
	abstract = {This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms, while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms.},
	journal = {Mach. Learn.},
	author = {Williams, R J},
	year = {1992},
	keywords = {Jun 12 import},
	pages = {229--256},
}

@article{zibulevsky_blind_2001,
	title = {Blind {Source} {Separation} by {Sparse} {Decomposition} in a {Signal} {Dictionary}},
	volume = {In press},
	abstract = {The blind source separation problem is to extract the underlying source signals from a set of linear mixtures, where the mixing matrix is unknown. This situation is common, in acoustics, radio, medical signal and image processing, hyperspectral imaging, etc. We suggest a two-stage seperation process. First, a priori selection of a possibly overcomplete signal dictionary (for instance a wavelet frame, or a learned dictionary) in which the sources are assumed to be sparsely representable. Second, unmixing the sources by exploiting their sparse representability. We consider the general case of more sources than mixtures, but also derive a more efficient algorithm in the case of a non-overcomplete and an equal number of sources and mixtures. Experiments with artificial signals and with musical sounds demonstrate significantly better separation than other known techniques.},
	journal = {Neural Comput.},
	author = {Zibulevsky, Michael and Pearlmutter, Barak A},
	year = {2001},
	keywords = {Jun 12 import},
}

@article{kaelbling_reinforcement_1996,
	title = {Reinforcement {Learning}: {A} {Survey}},
	volume = {4},
	abstract = {This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of the current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word “reinforcement”. The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and copying with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.},
	journal = {J. Artif. Intell. Res.},
	author = {Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
	year = {1996},
	keywords = {Jun 12 import},
}

@inproceedings{lee_learning_1999,
	title = {Learning in {Intelligent} {Embedded} {Systems}},
	abstract = {Information processing capabilities of embedded systems presently lack the robustness and rich complexity found in biological systems. Endowing artificial systems with the ability to adapt to changing conditions requires algorithms that can rapidly learn from examples. We demonstrate the application of one such learning algorithm on an inexpensive robot constructed to perform simple sensorimotor tasks. The robot learns to track a particular object by discovering the salient visual and auditory cues unique to that object. The system uses a convolutional neural network to combine color, luminance, motion, and auditory information. The weights of the networks are adjusted using feedback from a teacher to reflect the reliability of the various input channels in the surrounding environment. We also discuss how unsupervised learning can discover features in data without external interaction. An unsupervised algorithm based upon nonnegative matrix factorization is able to automatically learn the different parts of objects. Such a parts-based representation of data is crucial for robust object recognition.},
	publisher = {USENIX Workshop on Embedded Systems},
	author = {Lee, Daniel D and Seung, H Sebastian},
	year = {1999},
	keywords = {Jun 12 import},
}

@article{lee_neural_1998,
	title = {A neural network based head tracking system},
	volume = {10},
	abstract = {We have constructed an inexpensive, video-based, motorized tracking system that learns to track a head. It uses real time graphical user inputs or an auxiliary infrared detector as supervisory signals to train a convolutional neural network. The inputs to the neural network consist of normalized luminance and chrominance images and motion information from frame differences. Subsampled images are also used to provide scale invariance. During the online training phase, the neural network rapidly adjusts the input weights depending upon the reliability of the different channels in the surrounding environment. This quick adaptation allows the system to robustly track a head even when other objects are moving within a cluttered background.},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Lee, D D and Seung, H S},
	year = {1998},
	keywords = {Jun 12 import},
	pages = {605--611},
}

@inproceedings{atkeson_comparison_1997,
	title = {A {Comparison} of {Direct} and {Model}-{Based} {Reinforcement} {Learning}},
	abstract = {This papers compares direct reinforcement learning (no explicit model) and model-based reinforcement learning on a simple task: pendulum swing up. We find that in this task model-based approaches support reinforcement learning from smaller amounts of training data and efficient handling of changing goals.},
	publisher = {International Conference on Robotics and Automation},
	author = {Atkeson, Christopher G and Santamaria, Juan Carlos},
	year = {1997},
	keywords = {Jun 12 import},
}

@article{doya_reinforcement_1999,
	title = {Reinforcement learning in continuous time and space},
	volume = {12},
	abstract = {This paper presents a reinforcement learning framework for continuous- time dynamical systems without a priori discretization of time, state, and action. Based on the Hamilton-Jacobi-Bellman (HJB) equation for infinite- horizon, discounted reward problems, we derive algorithms for estimating value functions and for improving policies with the use of function approx- imators. The process of value function estimation is formulated as the minimization of a continuous-time form of the temporal difference (TD) error. Update methods based on backward Euler approximation and ex- ponential eligibility traces are derived and their correspondences with the conventional residual gradient, TD(0), and TD({\textbackslash}textbackslashlambda) algorithms are shown. For policy improvement, two methods, namely, a continuous actor-critic method and a value-gradient based greedy policy, are formulated. As a special case of the latter, a nonlinear feedback control law using the value gradient and the model of the input gain is derived. The advantage up- dating“, a model-free algorithm derived previously, is also formulated in the HJB based framework. The performance of the proposed algorithms is first tested in a non- linear control task of swinging up a pendulum with limited torque. It is shown in the simulations that 1) the task is accomplished by the continuous actor-critic method in a number of trials several times fewer than by the conventional discrete actor-critic method; 2) among the continuous policy update methods, the value-gradient based policy with a known or learned dynamic model performs several times better than the actor-critic method; and 3) a value function update using exponential eligibility traces is more efficient and stable than that based on Euler approximation. The algorithms are then tested in a higher-dimensional task, i.e., cart-pole swing-up. This task is accomplished in several hundred trials using the value-gradient based policy with a learned dynamic model.},
	journal = {Neural Comput.},
	author = {Doya, Kenji},
	year = {1999},
	keywords = {Jun 12 import},
	pages = {243--269},
}

@article{konda_actor-critic_1999,
	title = {Actor-{Critic} {Algorithms}},
	volume = {12},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Konda, V R and Tsitsiklis, J N},
	year = {1999},
	keywords = {Jun 12 import},
	pages = {1008--1014},
}

@article{sutton_policy_1999,
	title = {Policy {Gradient} {Methods} for {Reinforcement} {Learning} with {Function} {Approximation}},
	abstract = {Function approximation is essential to reinforcement learning, but the standard approach of approximating a value function and determining a policy from it has so far proven theoretically intractable. In this paper we explore an alternative approach in which the policy is explicitly represented by its own function approximator, independent of the value function, and is updated according to the gradient of expected reward with respect to the policy parameters. Williams's REINFORCE method and actor–critic methods are examples of this approach. Our main new result is to show that the gradient can be written in a form suitable for estimation from experience aided by an approximate action-value or advantage function. Using this result, we prove for the first time that a version of policy iteration with arbitrary differentiable function approximation is convergent to a locally optimal policy.},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
	year = {1999},
	keywords = {Jun 12 import},
}

@inproceedings{peshkin_learning_1999,
	title = {Learning {Policies} with {External} {Memory}},
	publisher = {Proceedings of the Sixteenth International Conference on Machine Learning},
	author = {Peshkin, Leonid and Meuleau, Nicolas and Kaelbling, Leslie Pack},
	year = {1999},
	keywords = {Jun 12 import},
}

@inproceedings{baird_gradient_1999,
	title = {Gradient {Descent} for {General} {Reinforcement} {Learning}},
	abstract = {A simple learning rule is derived, the VAPS algorithm, which can be instantiated to generate a wide range of new reinforcement-learning algorithms. These algorithms solve a number of open problems, define several new approaches to reinforcement learning, and unify different approaches to reinforcement learning under a single theory. These algorithms all have guaranteed convergence, and include modifications of several existing algorithms that were known to fail to converge on simple MDPs. These include Q-learning, SARSA, and advantage learning. In addition to these value-based algorithms it also generates pure policy-search reinforcement-learning algorithms, which learn optimal policies without learning a value function. In addition, it allows policy-search and value-based algorithms to be combined, thus unifying two very different approaches to reinforcement learning into a single Value and Policy Search (VAPS) algorithm. And these algorithms converge for POMDPs without requiring a proper belief state. Simulations results are given, and several areas for future research are discussed.},
	publisher = {Advances in Neural Information Processing Systems},
	author = {Baird, Leemon C and Moore, Andrew W},
	year = {1999},
	keywords = {Jun 12 import},
}

@inproceedings{kearns_approximate_1999,
	title = {Approximate planning in large {POMDPs} via reusable trajectories},
	publisher = {Advances in Neural Information Processing Systems},
	author = {Kearns, Michael and Mansour, Y and Ng, A},
	year = {1999},
	keywords = {Jun 12 import},
}

@book{press_numerical_1992,
	edition = {Second},
	title = {Numerical {Recipes} in {C}: {The} {Art} of {Scientific} {Computing}},
	publisher = {Cambridge University Press},
	author = {Press, William H and Teukolsky, Saul A and Vetterling, William T and Flannery, Brian P},
	year = {1992},
	keywords = {Jun 12 import},
}

@inproceedings{meuleau_off-policy_2000,
	title = {Off-{Policy} {Policy} {Search}},
	abstract = {Gradient-based policy search is an alternative to value-function-based methods for reinforcement learning in non-Markovian domains. One apparent drawback of policy search is its requirement that all actions be “on-policy”; that is, that there be no explicit exploration. In this paper, we provide a method using importance sampling to allow any well-behaved directed exploration policy during learning. We show both theoretically and experimentally that using this method can acheive dramatic performance improvements.},
	publisher = {NIPS},
	author = {Meuleau, Nicolas and Peshkin, Leonid and Kaelbling, Leslie P and Kim, Kee-Eung},
	year = {2000},
	keywords = {Jun 12 import},
}

@article{jordan_forward_1992,
	title = {Forward {Models}: {Supervised} {Learning} with a {Distal} {Teacher}},
	volume = {16},
	abstract = {Internal models of the environment have an important role to play in adaptive systems in general and are of particular importance for the supervised learning paradigm. In this paper we demonstrate that certain classical problems associated with the notion of the “teacher” in supervised learning can be solved by judicious use of learned internal models as components of the adaptive system. In particular, we show how supervised learning algorithms can be utilized in cases in which an unknown dynamical system intervenes between actions and desired outcomes. Our approach applies to any supervised learning algorithm that is capable of learning in multi-layer networks.},
	journal = {Cogn. Sci.},
	author = {Jordan, Michael I and Rumelhart, David E},
	year = {1992},
	keywords = {Jun 12 import},
	pages = {307--354},
}

@article{jordan_constrained_1992,
	title = {Constrained {Supervised} {Learning}},
	volume = {36},
	abstract = {When distinct outputs of an adaptive system have equivalent effects on the environment, the problem of finding appropriate actions given desired results is ill-posed. For supervised learning algorithms, the ill-posedness of such “inverse learning problems” implies a certain flexibility - during training, there are in general many possible target vectors corresponding to each input vector. To allow supervised learning algorithms to make use of this flexibility, the current paper considers how to specify targets by sets of constraints, rather than as particular vectors. Two classes of constraints are distinguished - configurational constraints, whish define regions of output space in which an output vector must lie, and temporal constraints, which define relationships between outputs produced at different points in time. Learning algorithms minimize a cost function that contains terms for both kinds of constraints.},
	number = {3},
	journal = {J. Math. Psychol.},
	author = {Jordan, Michael I},
	month = sep,
	year = {1992},
	keywords = {Jun 12 import},
	pages = {396--425},
}

@article{young_hebbian_2001,
	title = {A {Hebbian} {Feedback} {Covariance} {Learning} {Paradigm} for {Self}-{Tuning} {Optimal} {Control}},
	volume = {31},
	abstract = {We propose a novel adaptive optimal control paradigm inspired by Hebbian covariance synaptic adaptation, a preeminent model of learning and memory as well as other malleable functions in the brain. The adaptation is driven by the spontaneous fluctuations in the system input and output, the covariance of which provides useful information about the changes in the system behavior. The control structure represents a novel form of associative reinforcement learning in which the reinforcement signal is implicitly given by the covariance of the input output (I/O) signals. Theoretical foundations for the paradigm are derived using Lyapunov theory and are verified by means of computer simulations. The learning algorithm is applicable to a general class of nonlinear adaptive control prob-lems. This on-line direct adaptive control method benefits from a c omputationally straightforward design, proof of convergence, no need for complete system identification, robustness to noise and uncertainties, and the ability to optimize a general performance criterion in terms of system states and control signals. These attractive properties of Hebbian feedback covariance learning control lend themselves to future investigations into the computa-tional functions of synaptic plasticity in biological neurons.},
	number = {2},
	journal = {IEEE Trans. Syst. Man Cybern. B Cybern.},
	author = {Young, D L and Poon, C-S},
	month = apr,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {173--186},
}

@article{jacobs_adaptive_1991,
	title = {Adaptive mixtures of local experts},
	volume = {3},
	abstract = {We present a new supervised learning procedure for systems composed of many separate networks, each of which learns to handle a subset of the complete set of training cases. The new procedure can be viewed either as a modular version of a multilayer supervised networks, or as an associative version of competitive learning. It therefore provides a new link between these two apparently different approaches. We demonstrate that the learning procedure divides up a vowel discrimination task into appropriate subtasks, each of which can be solved by a very simple expert network.},
	journal = {Neural Comput.},
	author = {Jacobs, R and Jordan, M I and Nowlan, S J and Hinton, G E},
	year = {1991},
	keywords = {Jun 12 import},
	pages = {79--87},
}

@article{cauwenberghs_analog_1996,
	title = {An {Analog} {VLSI} {Recurrent} {Neural} {Network} {Learning} a {Continuous}-{Time} {Trajectory}},
	volume = {7},
	abstract = {Real-time algorithms for gradient descent supervised learning in recurrent dynamical neural networks fail to support scalable VLSI (very large scale integration) implementation, due to their complexity which grows sharply with the network dimension. We present an alternative implementation in analog VLSI, which employs a stochastic perturbative algorithm to observe the gradient of the error index directly on the network in random directions of the parameter space, thereby avoiding the tedious task of deriving the gradient from an explicit model of the network dynamics. The network contains six fully recurrent neurons with continuous-time dynamics, providing 42 free parameters which comprise connection strengths and thresholds. The chip implementing the network includes local provisions supporting both the learning and storage of the parameters, integrated in a scalable architecture which can be readily expanded for applications of learning recurrent dynamical networks requiring larger dimensionality. We describe and characterize the functional elements comprising the implemented recurrent network and integrated learning system, and include experimental results obtained from training the network to produce two outputs following a circular trajectory, representing a quadrature-phase oscillator.},
	number = {2},
	journal = {IEEE Trans. Neural Netw.},
	author = {Cauwenberghs, G},
	month = mar,
	year = {1996},
	keywords = {Jun 12 import},
	pages = {346--361},
}

@article{jabri_weight_1992,
	title = {Weight {Perturbation}: {An} {Optimal} {Architecture} and {Learning} {Technique} for {Analog} {VLSI} {Feedforward} and {Recurrent} {Multilayer} {Networks}},
	volume = {3},
	abstract = {Previous work on analog VLSI implementation of multilayer perceptrons with on-chip learning has mainly targeted the implementation of algorithms such as back-propagation. Although back-propagation is efficient, its implementation in analog VLSI requires excessive computational hardware. In this paper we show that using gradient descent with direct approximation of the gradient instead of back-propagation is more economical for parallel analog implementations. We also show that this technique (which we call “weight perturbation”) is suitable for multilayer recurrent networks as well. A discrete level analog implementation showing the training of an XOR network as an example is also presented.},
	number = {1},
	journal = {IEEE Trans. Neural Netw.},
	author = {Jabri, M and Flower, B},
	month = jan,
	year = {1992},
	keywords = {Jun 12 import},
	pages = {154--157},
}

@inproceedings{hochreiter_learning_2001,
	title = {Learning to {Learn} {Using} {Gradient} {Descent}},
	publisher = {International Conference on Artificial Neural Networks},
	author = {Hochreiter, S and Younger, A S and Conwell, P R},
	year = {2001},
	keywords = {Jun 12 import},
	pages = {87--94},
}

@article{ghahramani_probabilistic_nodate,
	title = {Probabilistic {Models} for {Unsupervised} {Learning}},
	abstract = {Many of the methods used for clustering, dimensionality reduction, source separation, time series modeling, and other classical problems in unsupervised data modeling are closely related to each other. The focus of this tutorial is to present a consistent unified picture of how these methods, which have been developed and rediscovered in several different fields, are variants of each other, and how a single framework can be used to develop learning algorithms for all of them. We will start from a humble Gaussian model, to describe how continuous state models such as factor analysis, principal components analysis (PCA) and independent components analysis (ICA) are related to each other. We will then motivate discrete state mixture models and vector quantization. Mixture models and factor analysis are then extended to model time series data, and result in hidden Markov models (HMMs) and linear-Gaussian dynamical systems (a.k.a. state-space models), respectively. All of these models can be described within the framework of probabilistic graphical models, which we will briefly introduce. In this framework it becomes easy to explore variants and hybrids (such as mixtures of factor analyzers and switching state-space models) which are potentially powerful tools. This framework also makes it clear that the same general probability propagation algorithm can be used to infer the hidden (i.e. latent) variables in all these models, and that the EM algorithm can be used to learn the maximum likelihood (ML) parameters. In the latter part of the tutorial we will focus on approximate inference techniques for models in which probability propagation is intractable, and on variational methods for Bayesian model averaging which can overcome the overfitting and model selection problems in ML learning. Matlab demos will be used to demonstrate some of the models and algorithms.},
	author = {Ghahramani, Zoubin and Roweis, Sam},
	keywords = {Jun 12 import},
}

@article{giles_noisy_2001,
	title = {Noisy {Time} {Series} {Prediction} using a {Recurrent} {Neural} {Network} and {Grammatical} {Inference}},
	abstract = {Financial forecasting is an example of a signal processing problem which is challenging due to small sample sizes, high noise, non-stationarity, and non-linearity. Neural networks have been very successful in a number of signal processing applications. We discuss fundamental limita-tions and inherent difficulties when using neural networks for the processing of high noise, small sample size signals. We introduce a new intelligent signal processing method which addresses the difficulties. The method proposed uses conversion into a symbolic representation with a self-organizing map, and grammatical inference with recurrent neural networks. We apply the method to the prediction of daily foreign exchange rates, addressing difficulties with non-stationarity, overfitting, and unequal a priori class probabilities, and we find significant predictability in com-prehensive experiments covering 5 different foreign exchange rates. The method correctly pre-dicts the direction of change for the next day with an error rate of 47.1\%. The error rate reduces to around 40\% when rejecting examples where the system has low confidence in its prediction. We show that the symbolic representation aids the extraction of symbolic knowledge from the trained recurrent neural networks in the form of deterministic finite state automata. These automata ex-plain the operation of the system and are often relatively simple. Automata rules related to well known behavior such as trend following and mean reversal are extracted.},
	journal = {Machine Learning, Volume 44, Number 1/2, July/August, pp. 161183, 2001.},
	author = {Giles, C Lee},
	year = {2001},
	keywords = {Jun 12 import},
}

@article{connor_recurrent_1994,
	title = {Recurrent neural networks and robust time series prediction},
	journal = {IEEE Trans. Neural Netw.},
	author = {Connor, J t and Martin, R d and Altas, L e},
	year = {1994},
	keywords = {Jun 12 import},
}

@article{molgedey_separation_1994,
	title = {Separation of a mixture of independent signals using time delayed correlations},
	volume = {72},
	abstract = {The problem of separating n linearly superimposed uncorrelated signals and determining their mixing coefficients is reduced to an eigenvalue problem which involves the simultaneous diagonalization of two symmetric matrices whose elements are measureable time delayed correlation functions. The diagonalization matrix can be determined from a cost function whose number of minima is equal to the number of degenerate solutions. Our approach offers the possibility to separate also nonlinear mixtures of signals.},
	journal = {Phys. Rev. Lett.},
	author = {Molgedey, L and Schuster, H G},
	year = {1994},
	keywords = {Jun 12 import},
	pages = {3634--3637},
}

@article{neal_probabilistic_nodate,
	title = {Probabilistic {Inference} using {Markov} {Chain} {Monte} {Carlo} {Methods}},
	abstract = {Probabilistic inference is an attractive approach to uncertain reasoning and empirical learning in artificial intelligence. Computational difficulties arise, however, because probabilistic models with the necessary realism and flexibility lead to complex distributions over high-dimensional spaces. Related problems in other fields have been tackled using Monte Carlo methods based on sampling using Markov chains, providing a rich array of techniques that can be applied to problems in artificial intelligence. The “Metropolis algorithm” has been used to solve difficult problems in statistical physics for over forty years, and, in the last few years, the related method of “Gibbs sampling” has been applied to problems of statistical inference. Concurrently, an alternative method for solving problems in statistical physics by means of dynamical simulation has been developed as well, and has recently been unified with the Metropolis algorithm to produce the “hybrid Monte Carlo” method. In computer science, Markov chain sampling is the basis of the heuristic optimization technique of “simulated annealing”, and has recently been used in randomized algorithms for approximate counting of large sets. In this review, I outline the role of probabilistic inference in artificial intelligence, present the theory of Markov chains, and describe various Markov chain Monte Carlo algorithms, along with a number of supporting techniques. I try to present a comprehensive picture of the range of methods that have been developed, including techniques from the varied literature that have not yet seen wide application in artificial intelligence, but which appear relevant. As illustrative examples, I use the problems of probabilistic inference in expert systems, discovery of latent classes from data, and Bayesian learning for neural networks.},
	journal = {Technical Report CRG-TR-93-1 (September 1993),},
	author = {Neal, Radford M},
	keywords = {Jun 12 import},
}

@article{baxter_infinite-horizon_2001,
	title = {Infinite-{Horizon} {Policy}-{Gradient} {Estimation}},
	volume = {15},
	abstract = {Gradient-based approaches to direct policy search in reinforcement learning have received much recent attention as a means to solve problems of partial observability and to avoid some of the problems associated with policy degradation in value-function methods. In this paper we introduce GPOMDP, a simulation-based algorithm for generating a biased estimate of the gradient of the average reward in Partially Observable Markov Decision Processes POMDPs controlled by parameterized stochastic policies. A similar algorithm was proposed by (Kimura et al. 1995). The algorithm's chief advantages are that it requires storage of only twice the number of policy parameters, uses one free beta (which has a natural interpretation in terms of bias-variance trade-off), and requires no knowledge of the underlying state. We prove convergence of GPOMDP, and show how the correct choice of the parameter beta is related to the mixing time of the controlled POMDP. We briefly describe extensions of GPOMDP to controlled Markov chains, continuous state, observation and control spaces, multiple-agents, higher-order derivatives, and a version for training stochastic policies with internal states. In a companion paper (Baxter et al., this volume) we show how the gradient estimates generated by GPOMDP can be used in both a traditional stochastic gradient algorithm and a conjugate-gradient procedure to find local optima of the average reward.},
	journal = {J. Artif. Intell. Res.},
	author = {Baxter, J and Bartlett, P l},
	year = {2001},
	keywords = {Jun 12 import},
	pages = {319--350},
}

@incollection{smagt_solving_1998,
	series = {Springer {Lecture} {Notes} in {Computer} {Science}},
	title = {Solving the ill-conditioning in neural network learning},
	volume = {1524},
	abstract = {In this paper we investigate the feed-forward learning problem. The well-known ill-conditioning which is present in most feed-forward learning problems is shown to be the result of the structure of the network. Also, the well-known problem that weights between `higher' layers in the network have to settle before `lower' weights can converge is addressed. We present a solution to these problems by modifying the structure of the network through the addition of linear connections which carry shared weights. We call the new network structure the linearly augmented feed-forward network, and it is shown that the universal approximation theorems are still valid. Simulation experiments show the validity of the new method, and demonstrate that the new network is less sensitive to local minima and learns faster than the original network.},
	booktitle = {Neural {Networks}: {Tricks} of the {Trade}},
	author = {Smagt, P Van Der and Hirzinger, G},
	editor = {M�ller, J Orr and {K}},
	year = {1998},
	keywords = {Jun 12 import},
	pages = {193--206},
}

@incollection{bianchini_optimal_1997,
	series = {Neural {Network} {Systems}, {Techniques} and {Applications}},
	title = {Optimal {Learning} in {Artificial} {Neural} {Networks}: {A} {Theoretical} {View}},
	volume = {2},
	abstract = {The effectiveness of connectionist models in emulating intelligent behaviour and solving significant practical problems is strictly related to the capability of the learning algorithms to find optimal or near-optimal solutions and to generalize to new examples. This chapter reviews some theoretical contributions to optimal learning in the attempt to provide a unified view and give the state of the art in the field. The focus of the review is on the problem of local minima in the cost function that is likely to affect more or less any learning algorithm. Starting from this analysis, we briefly review proposals for discovering optimal solutions and suggest conditions for designing architectures tailored to a given task. We focus mainly on batch-mode by investigating conditions that guarantee local minima free error surface for both static and dynamic networks. In the case of feedforward networks, local minima free error surfaces are guaranteed when the patterns are linearly separable or when using networks with as many hidden units as patterns to learn. Analogous results hold for radial basis function networks for which the absence of local minima is gained under the condition of patterns separable by hyperspheres. In the case of dynamic networks, local minima free error surfaces are guaranteed when matching the Decoupling Network Assumptions (DNA). They are essentially related to the decoupling of sequences of different classes on at least one gradient coordinate. Unlike other sufficient conditions, DNA seem more valuable in network design. Basically, for a given classification task, one can look for architectures that are well suited for learning. In the best case, such a search leads to discover networks for which learning takes place with no local minima. When no optimal network is found that guarantees local minima free error surface, one can, in any case, exploit DNA for discovering architectures that are well suited for the task at hand. The theoretical results described for batch-mode can partially be extended, at least for feedforward networks, to the case of pattern-mode learning. This duality, that holds also for non-small learning rates, is quite interesting, since it suggests conceiving new learning algorithms that are not necessarily based on function optimization, but on smart weight updating rules acting similarly to pattern-mode.},
	booktitle = {Optimization {Techniques}},
	publisher = {Academic Press},
	author = {Bianchini, M and Frasconi, P and Gori, M and Maggini, M},
	editor = {Leondes, C T},
	month = oct,
	year = {1997},
	keywords = {Jun 12 import},
	pages = {1--51},
}

@article{barto_associative_1981,
	title = {Associative search network: {A} reinforcement learning associative memory},
	volume = {40},
	journal = {Biol. Cybern.},
	author = {Barto, A G and Sutton, R S and Brouwer, P S},
	year = {1981},
	keywords = {Jun 12 import},
	pages = {201--211},
}

@article{barto_landmark_1981,
	title = {Landmark learning: {An} illustration of associative search},
	volume = {42},
	journal = {Biol. Cybern.},
	author = {Barto, A G and Sutton, R S},
	year = {1981},
	keywords = {Jun 12 import},
	pages = {1--8},
}

@article{barto_neuronlike_1983,
	title = {Neuronlike elements that can solve difficult learning control problems},
	volume = {13},
	journal = {IEEE Trans. Syst. Man Cybern.},
	author = {Barto, A G and Sutton, R S and Anderson, C W},
	year = {1983},
	keywords = {Jun 12 import},
	pages = {835--846},
}

@article{baxter_experiments_nodate,
	title = {Experiments with {Infinite}-{Horizon}, {Policy}-{Gradient} {Estimation}},
	abstract = {In this paper, we present algorithms that perform gradient ascent of the average reward in a par-tially observable Markov decision process (POMDP). These algorithms are based on GPOMDP, an algorithm introduced in a companion paper (Baxter \& Bartlett, 2001), which computes biased estimates of the performance gradient in POMDPs. The algorithms chief advantages are that it uses only one free parameter 2 [0; 1), which has a natural interpretation in terms of bias-variance trade-off, it requires no knowledge of the underlying state, and it can be applied to infinite state, control and observation spaces. We show how the gradient estimates produced by GPOMDP can be used to perform gradient ascent, both with a traditional stochastic-gradient algorithm, and with an algorithm based on conjugate-gradients that utilizes gradient information to bracket maxima in line searches. Experimental results are presented illustrating both the theoretical results of Baxter and Bartlett (2001) on a toy problem, and practical aspects of the algorithms on a number of more realistic problems.},
	journal = {Journal of Artificial Intelligence Research 15 (2001) 351-381 Submitted 9/00; published 11/01},
	author = {Baxter, J and Bartlett, P L and Weaver, L},
	keywords = {Jun 12 import},
}

@article{cucker_mathematical_2002,
	title = {On the mathematical foundations of learning},
	volume = {39},
	number = {1},
	journal = {Bull. Am. Math. Soc.},
	author = {Cucker, Felipe and Smale, Steve},
	year = {2002},
	keywords = {Jun 12 import},
	pages = {1--49},
}

@article{evgeniou_regularization_2000,
	title = {Regularization {Networks} and {Support} {Vector} {Machines}},
	volume = {13},
	abstract = {Regularization Networks and Support Vector Machines are techniques for solving certain problems of learning from examples � in particular, the regression problem of approximating a multivariate function from sparse data. Radial Basis Functions, for example, are a special case of both regularization and Support Vector Machines. We review both formulations in the context of Vapnik�s theory of statistical learning which provides a general foundation for the learning problem, combining functional analysis and statistics. The emphasis is on regression: classification is treated as a special case.},
	number = {1},
	journal = {Adv. Comput. Math.},
	author = {Evgeniou, Theodoros and Pontil, Massimiliano and Poggio, Tomaso},
	year = {2000},
	keywords = {Jun 12 import, Radial Basis Functions, regularization, Reproducing Kernel Hilbert Space, Structural Risk Minimization, Support Vector Machines},
	pages = {1--50},
}

@article{beardsley_sequential_1997,
	title = {Sequential {Updating} of {Projective} and {Affine} {Structure} from {Motion}},
	volume = {23},
	abstract = {A structure from motion algorithm is described which recovers structure and camera position, modulo a projective ambiguity. Camera calibration is not required, and camera parameters such as focal length can be altered freely during motion. The structure is updated sequentially over an image sequence, in contrast to schemes which employ a batch process. A specialisation of the algorithm to recover structure and camera position modulo an affine transformation is described, together with a method to periodically update the affine coordinate frame to prevent drift over time. We describe the constraint used to obtain this specialisation. Structure is recovered from image corners detected and matched automatically and reliably in real image sequences. Results are shown for reference objects and indoor environments, and accuracy of recovered structure is fully evaluated and compared for a number of reconstruction schemes. A specific application of the work is demonstrated�affine structure is used to compute free space maps enabling navigation through unstructured environments and avoidance of obstacles. The path planning involves only affine constructions.},
	number = {3},
	journal = {Int. J. Comput. Vis.},
	author = {Beardsley, P a and Zisserman, A and Murray, D w},
	year = {1997},
	keywords = {Jun 12 import},
	pages = {235--259},
}

@article{lee_learning_1999-1,
	title = {Learning the parts of objects by non-negative matrix factorization},
	volume = {401},
	abstract = {Is perception of the whole based on perception of its parts? There is psychological and physiological evidence for parts-based representations in the brain, and certain computational theories of object recognition rely on such representations. But little is known about how brains or computers might learn the parts of objects. Here we demonstrate an algorithm for non-negative matrix factorization that is able to learn parts of faces and semantic features of text. This is in contrast to other methods, such as principal components analysis and vector quantization, that learn holistic, not parts-based, representations. Non-negative matrix factorization is distinguished from the other methods by its use of non-negativity constraints. These constraints lead to a parts-based representation because they allow only additive, not subtractive, combinations. When non-negative matrix factorization is implemented as a neural network, parts-based representations emerge by virtue of two properties: the firing rates of neurons are never negative and synaptic strengths do not change sign.},
	number = {6755},
	journal = {Nature},
	author = {Lee, Dd and Seung, Hs},
	month = oct,
	year = {1999},
	keywords = {Jun 12 import},
	pages = {788--791},
}

@article{lee_algorithms_2001,
	title = {Algorithms for non-negative matrix factorization},
	volume = {13},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Lee, D d and Seung, H s},
	year = {2001},
	keywords = {Jun 12 import},
	pages = {556--562},
}

@article{boyan_generalization_1995,
	title = {Generalization in {Reinforcement} {Learning}: {Safely} {Approximating} the {Value} {Function}},
	volume = {7},
	abstract = {A straightforward approach to the curse of dimensionality in reinforcement learning and dynamic programming is to replace the lookup table with a generalizing function approximator such as a neural net. Although this has been successful in the domain of backgammon, there is no guarantee of convergence. In this paper, we show that the combination of dynamic programming and function approximation is not robust, and in even very benign cases, may produce an entirely wrong policy. We then introduce Grow-Support, a new algorithm which is safe from divergence yet can still reap the benefits of successful generalization.},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Boyan, Justin A and Moore, Rew W},
	year = {1995},
	keywords = {Jun 12 import},
}

@inproceedings{ng_pegasus_2000,
	title = {{PEGASUS}: {A} policy search method for large {MDPs} and {POMDPs}},
	abstract = {We propose a new approach to the problem of searching a space of policies for a Markov decision process (MDP) or a partially observable Markov decision process (POMDP), given a model. Our approach is based on the following observation: Any (PO)MDP can be transformed into an �equivalent� POMDP in which all state transitions (given the current state and action) are deterministic. This reduces the general problem of policy search to one in which we need only consider POMDPs with deterministic transitions. We give a natural way of estimating the value of all policies in these transformed POMDPs. Policy search is then simply performed by searching for a policy with high estimated value. We also establish conditions under which our value estimates will be good, recovering theoretical results similar to those of Kearns, Mansour and Ng [7], but with �sample complexity� bounds that have only a polynomial rather than exponential dependence on the horizon time. Our method applies to arbitrary POMDPs, including ones with infi- nite state and action spaces. We also present empirical results for our approach on a small discrete problem, and on a complex continuous state/continuous action problem involving learning to ride a bicycle.},
	booktitle = {Uncertainty in {Artificial} {Intelligence}},
	author = {Ng, Andrew Y and Jordan, Michael},
	year = {2000},
	keywords = {Jun 12 import},
}

@inproceedings{ng_policy_2000,
	title = {Policy search via density estimation},
	volume = {12},
	abstract = {We propose a new approach to the problem of searching a space of stochastic controllers for a Markov decision process (MDP) or a partially observable Markov decision process (POMDP). Following several other authors, our approach is based on searching in parameterized families of policies (for example, via gradient descent) to optimize solution quality. However, rather than trying to estimate the values and derivatives of a policy directly, we do so indirectly using estimates for the probability densities that the policy induces on states at the different points in time. This enables our algorithms to exploit the many techniques for efficient and robust approximate density propagation in stochastic systems. We show how our techniques can be applied both to deterministic propagation schemes (where the MDP�s dynamics are given explicitly in compact form,) and to stochastic propagation schemes (where we have access only to a generative model, or simulator, of the MDP).We present empirical results for both of these variants on complex problems.},
	publisher = {NIPS},
	author = {Ng, Andrew Y and Parr, Ronald and Koller, Daphne},
	year = {2000},
	keywords = {Jun 12 import},
}

@inproceedings{kearns_sparse_1999,
	title = {A sparse sampling algorithm for near-optimal planning in large {Markov} decision processes},
	publisher = {Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence (IJCAI)},
	author = {Kearns, Michael and Mansour, Yishay and Ng, Andrew Y},
	year = {1999},
	keywords = {Jun 12 import},
}

@inproceedings{ng_policy_1999,
	title = {Policy invariance under reward transformations: {Theory} and application to reward shaping},
	publisher = {Proceedings of the Sixteenth International Conference on Machine Learning},
	author = {Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
	year = {1999},
	keywords = {Jun 12 import},
}

@article{huang_inference_1994,
	title = {Inference in {Belief} {Networks}: {A} {Procedural} {Guide}},
	volume = {11},
	abstract = {Belief networks are popular tools for encoding uncertainty in expert systems. These networks rely on inference algorithms to compute beliefs in the context of observed evidence. One established method for exact inference on belief networks is the Probability Propagation in Trees of Clusters (PPTC) algorithm, as developed by Lauritzen and Spiegelhalter and refined by Jensen et al. [1, 2, 3] PPTC converts the belief network into a secondary structure, then computes probabilities by manipulating the secondary structure. In this document, we provide a self-contained, procedural guide to understanding and implementing PPTC. We synthesize various optimizations to PPTC that are scattered throughout the literature. We articulate undocumented, “open secrets” that are vital to producing a robust and efficient implementation of PPTC. We hope that this document makes probabilistic inference more accessible and affordable to those without extensive prior exposure.},
	journal = {Int. J. Approx. Reason.},
	author = {Huang, Cecil and Darwiche, Adnan},
	year = {1994},
	keywords = {Jun 12 import, Artificial intelligence, Bayesian network, belief network, causal network, evidence, expert systems, join tree, probabilistic inference, probability propagation, reasoning under uncertainty},
}

@inproceedings{sutton_generalization_1995,
	title = {Generalization in {Reinforcement} {Learning}: {Successful} {Examples} {Using} {Sparse} {Coarse} {Coding}},
	volume = {8},
	abstract = {On large problems, reinforcement learning systems must use parameterized function approximators such as neural networks in order to generalize between similar situations and actions. In these cases there are no strong theoretical results on the accuracy of convergence, and computational results have been mixed. In particular, Boyan and Moore reported at last year's meeting a series of negative results in attempting to apply dynamic programming together with function approximation to simple control problems with continuous state spaces. In this paper, we present positive results for all the control tasks they attempted, and for one that is significantly larger. The most important differences are that we used sparse-coarse-coded function approximators (CMACs) whereas they used mostly global function approximators, and that we learned online whereas they learned offiine. Boyan and Moore and others have suggested that the problems they encountered could be solved by using actual outcomes (“rollouts”), as in classical Monte Carlo methods, and as in the TD({\textbackslash}textbackslashgamma) algorithm when {\textbackslash}textbackslashgamma = 1. However, in our experiments this always resulted in substantially poorer performance. We conclude that reinforcement learning can work robustly in conjunction with function approximators, and that there is little justification at present for avoiding the case of general {\textbackslash}textbackslashgamma.},
	publisher = {NIPS},
	author = {Sutton, R s},
	year = {1995},
	keywords = {Jun 12 import, acrobot},
	pages = {1038--1044},
}

@article{biehl_learning_1995,
	title = {Learning by on-line gradient descent},
	volume = {28},
	journal = {J. Phys. A Math. Gen.},
	author = {Biehl, M and Schwarze, H},
	year = {1995},
	keywords = {Jun 12 import},
	pages = {643--656},
}

@article{lopez_-line_2000,
	title = {On-line learning from a finite training set: {A} solvable model},
	volume = {49},
	number = {3},
	journal = {Europhys. Lett.},
	author = {Lopez, B and Opper, M},
	year = {2000},
	keywords = {Jun 12 import},
	pages = {275--281},
}

@article{wiegerinck_stochastic_1994,
	title = {Stochastic dynamics of learning with momentum in neural networks},
	volume = {27},
	journal = {J. Phys. A Math. Gen.},
	author = {Wiegerinck, W and Komoda, A and Heskes, T},
	year = {1994},
	keywords = {Jun 12 import},
	pages = {4425--4437},
}

@article{leen_optimal_1999,
	title = {Optimal asymptotic learning rate: {Macroscopic} versus microscopic dynamics},
	volume = {59},
	journal = {PRE},
	author = {Leen, Tk and Schottky, B and Saad, D},
	year = {1999},
	keywords = {Jun 12 import},
	pages = {985--991},
}

@inproceedings{bradtke_reinforcement_1994,
	title = {Reinforcement {Learning} {Methods} for {Continuous}-{Time} {Markov} {Decision} {Problems}},
	volume = {07},
	abstract = {Semi-Markov Decision Problems are continuous time generalizations of discrete time Markov Decision Problems. A number of reinforcement learning algorithms have been developed recently for the solution of Markov Decision Problems, based on the ideas of asynchronous dynamic programming and stochastic approximation. Among these are TD({\textbackslash}textbackslashlambda), Q-learning, and Real-time Dynamic Programming. After reviewing semi-Markov Decision Problems and Bellman's optimality equation in that context, we propose algorithms similar to those named above, adapted to the solution of semi-Markov Decision Problems. We demonstrate these algorithms by applying them to the problem of determining the optimal control for a simple queueing system. We conclude with a discussion of circumstances under which these algorithms may be usefully applied.},
	publisher = {NIPS},
	author = {Bradtke, Steven J and Duff, Michael O},
	year = {1994},
	keywords = {Jun 12 import},
	pages = {393},
}

@inproceedings{smart_effective_2002,
	title = {Effective {Reinforcement} {Learning} for {Mobile} {Robots}},
	abstract = {Programming mobile robots can be a long, time-consuming process. Specifying the low-level mapping from sensors to actuators is prone to programmer misconceptions, and debugging such a mapping can be tedious. The idea of having a robot learn how to accomplish a task, rather than being told explicitly is an appealing one. It seems easier and much more intuitive for the programmer to specify what the robot should be doing, and to let it learn the details of how to do it. In this paper, we introduce a framework for reinforcement learning on mobile robots and describe our experiments using it to learn simple tasks.},
	publisher = {International Conference on Robotics and Automation},
	author = {Smart, William D and Kaelbling, Leslie Pack},
	year = {2002},
	keywords = {Jun 12 import, learning from demonstration., machine learning, Mobile robots, reinforcement learning},
}

@article{tsitsiklis_analysis_1997,
	title = {An {Analysis} of {Temporal}-{Difference} {Learning} with {Function} {Approximation}},
	volume = {42},
	abstract = {We discuss the temporal-difference learning algorithm, as applied to approximating cost-to-go function of an infinite-horizon discounted Markov chain. The algorithm we analyze updates parameters of a linear function approximator on-line, during a single endless trajectory of an irreducible aperiodic Markov chain with a finite or infinite state space. We present a proof of convergence (with probability 1), a characterization of the limit of convergence, and a bound on the resulting approximation error. Furthermore, our analysis is based on a new line of reasoning that provides new intuition about the dynamics of temporal-difference learning. In addition to proving new and stronger positive results than those previously available, we identify the significance of on-line updating and potential hazards associated with the use of nonlinear function approximators. First, we prove that divergence may occur when updates are not based on trajectories of the Markov chain. This fact reconciles positive and negative results that have been discussed in the literature, regarding the soundness of temporal-difference learning. Second, we present an example illustrating the possibility of divergence when temporal-difference learning is used in the presence of a nonlinear function approximator.},
	number = {5},
	journal = {IEEE Trans. Automat. Contr.},
	author = {Tsitsiklis, John and Van Roy, Ben},
	month = may,
	year = {1997},
	keywords = {Jun 12 import},
	pages = {674--690},
}

@inproceedings{coulom_feedforward_2002,
	title = {Feedforward {Neural} {Networks} in {Reinforcement} {Learning} {Applied} to {High}-dimensional {Motor} {Control}},
	abstract = {Local linear function approximators are often preferred to feedforward neural networks to estimate value functions in reinforcement learning. Still, motor tasks usually solved by this kind of methods have a low-dimensional state space. This article demonstrates that feedforward neural networks can be applied successfully to high-dimensional problems. The main difficulties of using backpropagation networks in reinforcement learning are reviewed, and a simple method to perform gradient descent efficiently is proposed. It was tested successfully on an original task of learning to swim by a complex simulated articulated robot, with 4 control variables and 12 independent state variables.},
	publisher = {ALT2002},
	author = {Coulom, Remi},
	year = {2002},
	keywords = {Jun 12 import},
}

@inproceedings{precup_off-policy_2001,
	title = {Off-policy temporal-difference learning with function approximation},
	abstract = {We introduce the first algorithm for off-policy temporal-difference learning that is stable with linear function approximation. Off-policy learning is of interest because it forms the basis for popular reinforcement learning methods such as Q-learning, which has been known to diverge with linear function approximation, and because it is critical to the practical utility of multi-scale, multi-goal, learning frameworks such as options, HAMs, and MAXQ. Our new algorithm combines TD(lambda) over state-action pairs with importance sampling ideas from our previous work. We prove that, given training under any epsilon-soft policy, the algorithm converges w.p.1 to a close approximation (as in Tsitsiklis and Van Roy, 1997; Tadic, 2001) to the action-value function for an arbitrary target policy. Variations of the algorithm designed to reduce variance introduce additional bias but are also guaranteed convergent. We also illustrate our method empirically on a small policy evaluation problem, showing reduced variance compared to the most obvious importance sampling algorithm for this problem. Our current results are limited to episodic tasks with episodes of bounded length.},
	publisher = {18th International Conference on Machine Learning},
	author = {Precup, D and Sutton, R s and Dasgupta, S},
	year = {2001},
	keywords = {Jun 12 import},
}

@inproceedings{sutton_dyna_1991,
	title = {Dyna, an integrated architecture for learning, planning and reacting},
	abstract = {Dyna is an AI architecture that integrates learning, planning, and reactive execution. Learning methods are used in Dyna both for compiling planning results and for updating a model of the effects of the agent's actions on the world. Planning is incremental and can use the probabilistic and ofttimes incorrect world models generated by learning processes. Execution is fully reactive in the sense that no planning intervenes between perception and action. Dyna relies on machine learning methods for learning from examples—these are among the basic building blocks making up the architecture—yet is not tied to any particular method. This paper briefly introduces Dyna and discusses its strengths and weaknesses with respect to other architectures.},
	publisher = {AAAI Spring Symposium on Integrated Intelligent Architectures and SIGART Bulletin 2},
	author = {Sutton, Richard S},
	year = {1991},
	keywords = {Jun 12 import},
	pages = {160--163},
}

@inproceedings{baird_residual_1995,
	title = {Residual {Algorithms}: {Reinforcement} {Learning} with {Function} {Approximation}},
	abstract = {A number of reinforcement learning algorithms have been developed that are guaranteed to converge to the optimal solution when used with lookup tables. It is shown, however, that these algorithms can easily become unstable when implemented directly with a general function-approximation system, such as a sigmoidal multilayer perceptron, a radial-basis-function system, a memory-based learning system, or even a linear function-approximation system. A new class of algorithms, residual gradient algorithms, is proposed, which perform gradient descent on the mean squared Bellman residual, guaranteeing convergence. It is shown, however, that they may learn very slowly in some cases. A larger class of algorithms, residual algorithms, is proposed that has the guaranteed convergence of the residual gradient algorithms, yet can retain the fast learning speed of direct algorithms. In fact, both direct and residual gradient algorithms are shown to be special cases of residual algorithms, and it is shown that residual algorithms can combine the advantages of each approach. The direct, residual gradient, and residual forms of value iteration, Q-learning, and advantage learning are all presented. Theoretical analysis is given explaining the properties these algorithms have, and simulation results are given that demonstrate these properties.},
	publisher = {International Conference on Machine Learning (ICML)},
	author = {Baird, Leemon C},
	year = {1995},
	keywords = {Jun 12 import},
}

@inproceedings{sutton_dyna_1991-1,
	title = {Dyna, an integrated architecture for learning, planning and reacting},
	abstract = {Dyna is an AI architecture that integrates learning, planning, and reactive execution. Learning methods are used in Dyna both for compiling planning results and for updating a model of the effects of the agent's actions on the world. Planning is incremental and can use the probabilistic and ofttimes incorrect world models generated by learning processes. Execution is fully reactive in the sense that no planning intervenes between perception and action. Dyna relies on machine learning methods for learning from examples—these are among the basic building blocks making up the architecture—yet is not tied to any particular method. This paper briefly introduces Dyna and discusses its strengths and weaknesses with respect to other architectures.},
	publisher = {AAAI Spring Symposium on Integrated Intelligent Architectures and SIGART Bulletin 2},
	author = {Sutton, Richard S},
	year = {1991},
	keywords = {MachineLearning.bib},
	pages = {160--163},
}

@inproceedings{dayan_improving_1996,
	title = {Improving policies without measuring metrics},
	volume = {8},
	abstract = {Performing policy iteration in dynamic programming should only require knowledge of relative rather than absolute measures of the utility of actions (Werbos, 1991) - what Baird (1993) calls the advantages of actions at states. Nevertheless, most existing methods in dynamic programming (including Baird's) compute some form of absolute utility function. For smooth problems, advantages satisfy two differential consistency conditions (including the requirement that they be free of curl), and we show that enforcing these can lead to appropriate policy improvement solely in terms of advantages.},
	publisher = {NIPS},
	author = {Dayan, Peter and Singh, Satinder P},
	year = {1996},
	keywords = {Jun 12 import},
}

@inproceedings{bagnell_policy_2003,
	title = {Policy search by dynamic programming},
	volume = {16},
	abstract = {We consider the policy search approach to reinforcement learning. We show that if a �baseline distribution� is given (indicating roughly how often we expect a good policy to visit each state), then we can derive a policy search algorithm that terminates in a finite number of steps, and for which we can provide non-trivial performance guarantees. We also demonstrate this algorithm on several grid-world POMDPs, a planar biped walking robot, and a double-pole balancing problem.},
	publisher = {NIPS},
	author = {Bagnell, J Andrew and Kakade, Sham and Ng, Andrew Y and Schneider, Jeff},
	year = {2003},
	keywords = {Jun 12 import},
}

@article{ng_autonomous_2003,
	title = {Autonomous helicopter flight via {Reinforcement} {Learning}},
	volume = {16},
	abstract = {Autonomous helicopter flight represents a challenging control problem, with complex, noisy, dynamics. In this paper, we describe a successful application of reinforcement learning to autonomous helicopter flight. We first fit a stochastic, nonlinear model of the helicopter dynamics. We then use the model to learn to hover in place, and to fly a number of maneuvers taken from an RC helicopter competition.},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Ng, Andrew Y and Kim, H Jin and Jordan, Michael I and Sastry, Shankar},
	year = {2003},
	keywords = {Jun 12 import},
}

@inproceedings{singh_learning_1994,
	title = {Learning without state estimation in partially observable environments},
	volume = {11},
	publisher = {ICML},
	author = {Singh, Satinder P and Jaakkola, Tommi and Jordan, Michael I},
	year = {1994},
	keywords = {Jun 12 import},
}

@inproceedings{kimura_analysis_1998,
	title = {An {Analysis} of {Actor}/{Critic} {Algorithms} using {Eligibility} {Traces}: {Reinforcement} {Learning} with {Imperfect} {Value} {Functions}},
	abstract = {We present an analysis of actor/critic algorithms, in which the actor updates its policy using eligibility traces of the policy parameters. Most of the theoretical results for eligibility traces have been for only critic's value iteration algorithms. This paper investigates what the actor's eligibility trace does. The results show that the algorithm is an extension of Williams' REINFORCE algorithms for infinite horizon reinforcement tasks, and then the critic provides an appropriate reinforcement baseline for the actor. Thanks to the actor's eligibility trace, the actor improves its policy by using a gradient of actual return, not by using a gradient of the estimated return in the critic. It enables the agent to learn a fairly good policy under the condition that the approximated value function in the critic is hopelessly inaccurate for conventional actor/critic algorithms. Also, if an accurate value function is estimated by the critic, the actor's learning is dramatically accelerated in our test cases. The behavior of the algorithm is demonstrated through simulations of a linear quadratic control problem and a pole balancing problem.},
	booktitle = {Proceedings of the {International} {Conference} on {Machine} {Learning} ({ICML})},
	author = {Kimura, Hajime and Kobayashi, Shigenobu},
	year = {1998},
	keywords = {Jun 12 import},
	pages = {278--286},
}

@article{walter_imitation_1950,
	title = {An {Imitation} of {Life}},
	volume = {182},
	abstract = {Concerning the author's instructive genus of mechanical tortoises. Although they possess only two sensory organs and two electronic nerve cells, they exhibit “free will”.},
	number = {5},
	journal = {Sci. Am.},
	author = {Walter, W Grey},
	month = may,
	year = {1950},
	keywords = {Jun 12 import},
	pages = {42--45},
}

@article{walter_machine_1951,
	title = {A {Machine} {That} {Learns}},
	volume = {185},
	abstract = {Concerning Machina docilis, descendant of Machina speculatrix, the small imitation of life that was described in the May, 1950, issue of this magazine.},
	number = {2},
	journal = {Sci. Am.},
	author = {Walter, W Grey},
	month = aug,
	year = {1951},
	keywords = {Jun 12 import},
	pages = {60--63},
}

@inproceedings{vaughan_evolution_2004,
	title = {The evolution of control and adaptation in a {3D} powered passive dynamic walker},
	booktitle = {Proceedings of the {International} {Conference} on the {Simulation} and {Synthesis} of {Living} {Systems} ({ALIFE})},
	publisher = {MIT Press},
	author = {Vaughan, E and Di Paolo, E A and Harvey, I},
	year = {2004},
	keywords = {Jun 12 import},
}

@article{barto_recent_2003,
	title = {Recent {Advances} in {Hiearchical} {Reinforcement} {Learning}},
	volume = {13},
	abstract = {Reinforcement learning is bedeviled by the curse of dimensionality: the number of parameters to be learned grows exponentially with the size of any compact encoding of a state. Recent attempts to combat the curse of dimensionality have turned to principled ways of exploiting temporal abstraction, where decisions are not required at each step, but rather invoke the execution of temporally-extended activities which follow their own policies until termination. This leads naturally to hierarchical control architectures and associated learning algorithms. We review several approaches to temporal abstraction and hierarchical organization that machine learning researchers have recently developed. Common to these approaches is a reliance on the theory of semi-Markov decision processes, which we emphasize in our review. We then discuss extensions of these ideas to concurrent activities, multiagent coordination, and hierarchical memory for addressing partial observability. Concluding remarks address open challenges facing the further development of reinforcement learning in a hierarchical setting.},
	journal = {Discrete Event Systems Journal},
	author = {Barto, Andrew G and Mahadevan, Sridhar},
	year = {2003},
	keywords = {Jun 12 import},
	pages = {41--77},
}

@inproceedings{lecun_gemini_1989,
	title = {{GEMINI}: {Gradient} estimation through matrix inversion after noise injection},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 1 ({NIPS} '88)},
	author = {LeCun, Yann and Galland, Conrad C and Hinton, Geoffrey E},
	editor = {Touretzky, David},
	year = {1989},
	keywords = {Jun 12 import},
	pages = {141--149},
}

@article{barto_pattern-recognizing_1985,
	title = {Pattern-{Recognizing} {Stochastic} {Learning} {Automata}},
	volume = {15},
	abstract = {A class of learning tasks is described that combines aspects of learning automaton tasks and supervised learning pattern-classification tasks. We call these tasks associative reinforcement learning tasks. An algorithm is presented, called the 'associative reward-penalty,' or A(subscript: R-P), algorithm, for which a form of optimal performance is proved. This algorithm simultaneously generalizes a class of stochastic learning automata and a class of supervised learning pattern-classification methods relating to the Robbins-Monro stochastic approximation procedure. The relevance of this hybrid algorithm is discussed with respect to the collective behavior of learning automata and the behavior of networks of pattern-classifying adaptive elements. Simulation results are presented that illustrate the associative reinforcement learning task and the performance of the A(subscript: R-P) algorithm as compared with that of several existing algorithms.},
	number = {3},
	journal = {IEEE Trans. Syst. Man Cybern.},
	author = {Barto, A G and Anandan, P},
	year = {1985},
	keywords = {Jun 12 import},
	pages = {360--375},
}

@inproceedings{barto_gradient_1987,
	title = {Gradient following without back-propagation in layered networks},
	volume = {2},
	abstract = {We describe a method for solving nonlinear supervised learning tasks by multilayer feed-forward networks. It estimates the performance gradient without back-propagating error information by using the 'Associative Reward-Penalty,' or A(subscript: R-P), algorithm that has been the subject of previous papers [2,3,4,5]. We introduce a variant of the A(subscript: R-P) algorithm, called the S-model A(subscript: R-P), for learning with real-valued reinforcement, and we introduce a method, called “batching”, for increasing the learning efficiency of A(subscript: R-P) networks. We describe simulation experiments using the task of learning symmetry axes to compare the variants of the A(subscript: R-P) network method as well as the back-propagation method of Rumelhart, Hinton, and Williams [11].},
	booktitle = {{IEEE} {First} {International} {Conference} on {Neural} {Networks}},
	publisher = {IEEE},
	author = {Barto, Andrew G and Jordan, Michael I},
	editor = {Caudill, M and Butler, C},
	year = {1987},
	note = {Backup Publisher: IEEE},
	keywords = {Jun 12 import},
	pages = {629--636},
}

@article{page_connectionist_2000,
	title = {Connectionist {Modelling} in {Psychology}: {A} {Localist} {Manifesto}},
	volume = {23},
	abstract = {Over the last decade, fully-distributed models have become dominant in connectionist psychological modelling, whereas the virtues of localist models have been underestimated. This target article illustrates some of the benefits of localist modelling. Localist models are characterized by the presence of localist representations rather than the absence of distributed representations. A generalized localist model is proposed that exhibits many of the properties of fully distributed models. It can be applied to a number of problems that are difficult for fully distributed models and its applicability can be extended through comparisons with a number of classic mathematical models of behaviour. There are reasons why localist models have been underused and these are addressed. In particular, many conclusions about connectionist representation, based on neuroscientific observation, are called into question. There are still some problems inherent in the application of fully distributed systems and some inadequacies in proposed solutions to these problems. In the domain of psychological modelling, localist modelling is to be preferred.},
	number = {4},
	journal = {Behav. Brain Sci.},
	author = {Page, Mike},
	year = {2000},
	keywords = {neural networks, Jun 12 import, choice, competition, connectionist modelling, consolidation., distributed, localist, reaction-time},
}

@article{chown_making_1999,
	title = {Making predictions in an uncertain world: {Environmental} structure and cognitive maps},
	volume = {7},
	abstract = {The article examines the relationship between environmental and cognitive structure. One of the key tasks for any agent interacting in the real world is the management of uncertainty; because of this the cognitive structures which interact with real environments, such as would be used in navigation, must effectively cope with the uncertainty inherent in a constantly changing world. Despite this uncertainty, however, real environment usually afford structure that can be effectively exploited by organisms. The article examines environmental characteristics and structures that enable humans to survive and thrive in a wide range of real environments. The relationship between these characteristics and structures, uncertainty, and cognitive structure is explored in the context of PLAN, a proposed model of human cognitive mapping, and R-PLAN, a version of PLAN that has been instantiated on an actual mobile robot. An examination of these models helps to provide insight into environmental characteristics which impact human performance on tasks which require interaction with the world.},
	number = {1},
	journal = {Adapt. Behav.},
	author = {Chown, Eric},
	year = {1999},
	keywords = {Jun 12 import, navigation, associative networks, cognitive maps, gateways},
}

@article{fu_perceptual_2000,
	title = {The {Perceptual} {Generalization} {Capabilities} of the {Cell} {Assembly}},
	abstract = {Perceptual generalization is the capacity to appropriately recognize many different stimulus patterns as the same object despite enormous variability in these patterns. Perceptual generalization is an essential component of the phenomenal information processing abilities of humans that allows us to adapt to our ever-changing world. The development of computer models that can be used to simulate how humans are able to appropriately generalize can aid our understanding of both natural and artificial intelligence. In order to understand how cell assemblies acquire the capacity for perceptual generalization, the formation of cell assemblies via unsupervised perceptual learning was studied. This paper reports results that provide an existence proof of circumstances under which the cell assemblies that formed respond appropriately for two perceptual generalization tasks. The first task involved varying the features that were presented each time an object was presented. The second task was designed to capture the idea that one never sees the front of a three-dimensional object and the back of the object at the same time, yet one is still able to recognize it as the same object. This is possible because views of the side of the object contain features of both the front and the back of the object. The results for the second perceptual generalization task are also applicable to the ability of the cell assembly to categorize based on family resemblance. For economy of storage, subassemblies are expected to be shared between cell assemblies. This paper also reports results on the formation of cell assemblies that share subassemblies, where this sharing does not cause the inappropriate activation of cell assemblies.},
	author = {Fu, Leeann L},
	year = {2000},
	keywords = {Jun 12 import},
}

@article{kaplan_tracing_1991,
	title = {Tracing {Recurrent} {Activity} in {Cognitive} {Elements} ({TRACE}): a {Model} of {Temporal} {Dynamics} in a {Cell} {Assembly}},
	volume = {3},
	abstract = {Hebb's introduction of the cell assembly marks the beginning of modern connectionism, yet its implications remain largely unexplored and its potential unexploited. Lately, however, promising efforts have been made to utilize recurrent connections, suggesting the timeliness of a re-examination of the cell assembly as a key element in a cognitive connectionism. Our approach emphasizes the psychological functions of activity in a cell assembly. This provides an opportunity to explore the dynamic behavior of the cell assembly considered as a continuous system, an important topic that we feel has not been given sufficient attention. A step-by-step analysis leads to an identification of characteristic temporal patterns and of necessary control systems. Each step of this analysis leads to a corresponding building block in a set of emerging equations. A series of experiments is then described that explore the implications of the theoretically derived equations in terms of the time course of activity generated by a simulation under different conditions. Finally, the model is evaluated in terms of whether the various constraints deemed important can be met, whether the resulting simulation is robust, and whether the solution promises sufficient utility and generality.},
	number = {2},
	journal = {Conn. Sci.},
	author = {Kaplan, Stephen and Sonntag, Martin and Chown, Eric},
	year = {1991},
	keywords = {Neural networks, simulation, Jun 12 import, cell assembly, perception, consolidation, connectionism, neural fatigue, peak activation},
	pages = {179--206},
}

@article{kuhl_linguistic_1992,
	title = {Linguistic experience alters phonetic perception in infants by 6 months of age},
	volume = {255},
	abstract = {Linguistic experience affects phonetic perception. However, the critical period during which experience affects perception and the mechanism responsible for these effects are unknown. This study of 6-month-old infants from two countries, the United States and Sweden, shows that exposure to a specific language in the first half year of life alters infants' phonetic perception.},
	journal = {Science},
	author = {Kuhl, Patricia K and Williams, Karen A and Lacerda, Francisco and Stevens, Kenneth N and Lindblom, Bjorn},
	month = jan,
	year = {1992},
	keywords = {Jun 12 import},
	pages = {606--608},
}

@article{chown_prototypes_1995,
	title = {Prototypes, {Location}, and {Associative} {Networks} ({PLAN}): {Towards} a {Unified} {Theory} of {Cognitive} {Mapping}},
	volume = {19},
	journal = {Cogn. Sci.},
	author = {Chown, E and Kaplan, S and Kortenkamp, D},
	year = {1995},
	keywords = {Jun 12 import},
	pages = {1--51},
}

@incollection{nadel_neural_1999,
	title = {Neural {Mechanisms} of {Spatial} {Orientation} and {Wayfinding}: {An} {Overview}},
	booktitle = {Wayfinding {Behavior}: {Cognitive} {Mapping} and {Other} {Spatial} {Processes}},
	publisher = {The Johns Hopkins University Press},
	author = {Nadel, Lynn},
	editor = {Golledge, Reginald G},
	year = {1999},
	note = {Section: 12},
	keywords = {Jun 12 import},
	pages = {313--327},
}

@incollection{berthoz_dissociation_1999,
	title = {Dissociation between {Distance} and {Direction} during {Locomotor} {Navigation}},
	booktitle = {Wayfinding {Behavior}: {Cognitive} {Mapping} and {Other} {Spatial} {Processes}},
	publisher = {The Johns Hopkins University Press},
	author = {Berthoz, Alain and Amorim, Michel-Ange and Glasauer, Stephan and Grasso, Renato and Takei, Yasuiko and Viaud-Delmon, Isabelle},
	editor = {Golledge, Reginald G},
	year = {1999},
	note = {Section: 13},
	keywords = {Jun 12 import},
	pages = {328--348},
}

@incollection{chown_error_1999,
	title = {Error {Tolerance} and {Generalization} in {Cognitive} {Maps}: {Performance} without {Precision}},
	booktitle = {Wayfinding {Behavior}: {Cognitive} {Mapping} and {Other} {Spatial} {Processes}},
	publisher = {The Johns Hopkins University Press},
	author = {Chown, Eric},
	editor = {Golledge, Reginald G},
	year = {1999},
	note = {Section: 14},
	keywords = {Jun 12 import},
	pages = {349--369},
}

@article{herrnstein_relative_1961,
	title = {Relative and {Absolute} {Strength} of {Response} as a {Function} of {Frequency} of {Reinforcement}},
	volume = {4},
	abstract = {A previous paper (Herrnstein, 1958) reported how pigeons behave on a concurrent schedule under which they peck at either of two response-keys. The significant finding of this investigation was that the relative frequency of responding to each of the keys may be controlled within narrow limits by adjustments in an independent variable. In brief, the requirement for reinforcement in this procedure is the emission of a minimum number of pecks to each of the keys. The pigeon receives food when it completes the requirement on both keys. The frequency of responding to each key was a close approximation to the minimum requirement. The present experiment explores the relative frequency of responding further. In the earlier study it was shown that the output of behavior to each of two keys may be controlled by specific requirements of outputs. Now we are investigating output as a function of frequency of reinforcement. The earlier experiment may be considered a study of differential reinforcement; the present one, a study of strength of response. Both experiments are attempts to elucidate the properties of relative frequency of responding as a dependent variable.},
	journal = {J. Exp. Anal. Behav.},
	author = {Herrnstein, R J},
	year = {1961},
	keywords = {Jun 12 import},
	pages = {267--272},
}

@article{herrnstein_melioration_1991,
	title = {Melioration: {A} {Theory} of {Distributed} {Choice}},
	volume = {5},
	abstract = {In modern expositions of the theory of rational choice, the notion of what constitutes an object of choice is kept deliberately vague, so as not to restrict unduly the range of possible problems to which the theory will be applied later on. A recent advanced textbook on consumer behavior (Deaton and Muellbauer, 1980), for example, initially defines the objects of choice as “individual purchases of commodities” (p. 269), but this concrete definition yields quickly to the more abstract notion of a commodity “bundle,” which is rarely obtained through an individual purchase. Implicit in this exchangeability of terms is the supposition that in applying the theory it does not matter whether: A) the “choice” corresponds to an actual decision, made at a specific point in time; or B) the “choice” is an aggregate of many smaller decisions, distributed over a period of time. In this paper, we develop a theory of individual choice called 'melioration,' for which the distinction between choices of type A and type B is critical, and which implies that choices of type B may be reliably and predictably suboptimal, in terms of the person's own preferences. If true, this would imply that preferences as revealed in the marketplace may be a distortion of the true underlying preferences whenever the measured economic variables are aggregates of a stream of smaller decisions; the extent and direction of the distortion is then something that the theory will need to explain.},
	number = {3},
	journal = {J. Econ. Perspect.},
	author = {Herrnstein, R J and Prelec, D},
	year = {1991},
	keywords = {Jun 12 import},
	pages = {137--156},
}

@article{heyman_operant_1979,
	title = {Operant matching is not a logical consequence of maximizing reinforcement rate},
	volume = {7},
	abstract = {The distribution of behavior between concurrently available schedules of reinforcement approximates the distribution of reinforcements between the schedules. This equality, called matching, has been explained as an instance of the principle that organisms maximize reinforcement rate. However, a precise account of the relationship between the distribution of behavior and reinforcement rate on the standard concurrent schedule shows that matching and maximizing are different.},
	number = {2},
	journal = {Anim. Learn. Behav.},
	author = {Heyman, G M and Luce, R D},
	year = {1979},
	keywords = {Jun 12 import},
	pages = {133--140},
}

@article{baum_optimization_1981,
	title = {Optimization and the matching law as accounts of instrumental behavior},
	volume = {36},
	abstract = {The interaction between instrumental behavior and environment can be conveniently described at a molar level as a feedback system. Two different possible theories, the matching law and optimization, differ primarily in the reference criterion they suggest for the system. Both offer accounts of most of the known phenomena of performance on concurrent and single variable-interval and variable-ratio schedules. The matching law appears stronger in describing concurrent performances, whereas optimization appears stronger in describing performance on single schedules.},
	number = {3},
	journal = {J. Exp. Anal. Behav.},
	author = {Baum, W M},
	month = nov,
	year = {1981},
	keywords = {Jun 12 import},
	pages = {387--403},
}

@article{heyman_markov_1979,
	title = {A {Markov} {Model} {Description} of {Changeover} {Probabilities} on {Concurrent} {Variable}-{Interval} {Schedules}},
	volume = {31},
	abstract = {The primary data were peck-by-peck sequential records of four pigeons responding on several different concurrent variable-interval schedules. According to the hypothesis that the subject chooses the alternative with the highest probability of reinforcement at the moment, response-by-response performance in concurrent schedules should show sequential dependencies. However, such dependencies were not found, and it was possible to describe molecular-level performance with simple Markov chain models. The Markov model description implies that the momentary changeover probabilities were proportional to the overall relative reinforcement frequencies, and that changeover probabilities did not change as a function of previous responding. A second finding was that although a change-over-delay procedure was omitted, relative response frequencies closely approximated relative reinforcement frequencies.},
	number = {1},
	journal = {J. Exp. Anal. Behav.},
	author = {Heyman, G M},
	month = jan,
	year = {1979},
	keywords = {Jun 12 import},
	pages = {41--51},
}

@article{heyman_harvard_2002,
	title = {The {Harvard} {Pigeon} {Lab}, 1970-1998: {Graduate} {Students} and {Matching} {Law} {Research}},
	volume = {77},
	number = {3},
	journal = {J. Exp. Anal. Behav.},
	author = {Heyman, G M},
	month = may,
	year = {2002},
	keywords = {Jun 12 import},
	pages = {380--383},
}

@article{heyman_more_1986,
	title = {More on concurrent interval-ratio schedules: a replication and review},
	volume = {46},
	abstract = {It has been suggested that the failure to maximize reinforcement on concurrent variable-interval, variable-ratio schedules may be misleading. Inasmuch as response costs are not directly measured, it is possible that subjects are optimally balancing the benefits of reinforcement against the costs of responding. To evaluate this hypothesis, pigeons were tested in a procedure in which interval and ratio schedules had equal response costs. On a concurrent variable time (VT), variable ratio-time (VRT) schedule, the VT schedule runs throughout the session and the VRT schedule is controlled by responses to a changeover key that switches from one schedule to the other. Reinforcement is presented independent of response. This schedule retains the essential features of concurrent VI VR, but eliminates differential response costs for the two alternatives. It therefore also eliminates at least one significant ambiguity about the reinforcement maximizing performance. Pigeons did not maximize rate of reinforcement on this procedure. Instead, their times spent on the alternative schedules matched the relative rates of reinforcement, even when schedule parameters were such that matching earned the lowest possible overall rate of reinforcement. It was further shown that the observed matching was not a procedural artifact arising from the constraints built into the schedule.},
	number = {3},
	journal = {J. Exp. Anal. Behav.},
	author = {Heyman, G M and Herrnstein, R J},
	month = nov,
	year = {1986},
	keywords = {Jun 12 import},
	pages = {331--351},
}

@article{giurfa_concepts_2001,
	title = {The concepts of 'sameness' and 'difference' in an insect},
	volume = {410},
	abstract = {Insects process and learn information flexibly to adapt to their environment. The honeybee Apis mellifera constitutes a traditional model for studying learning and memory at behavioural, cellular and molecular levels. Earlier studies focused on elementary associative and non-associative forms of learning determined by either olfactory conditioning of the proboscis extension reflex or the learning of visual stimuli in an operant context. However, research has indicated that bees are capable of cognitive performances that were thought to occur only in some vertebrate species. For example, honeybees can interpolate visual information, exhibit associative recall, categorize visual information and learn contextual information. Here we show that honeybees can form 'sameness' and 'difference' concepts. They learn to solve 'delayed matching-to-sample' tasks, in which they are required to respond to a matching stimulus, and 'delayed non-matching-to-sample' tasks, in which they are required to respond to a different stimulus; they can also transfer the learned rules to new stimuli of the same or a different sensory modality. Thus, not only can bees learn specific objects and their physical parameters, but they can also master abstract inter-relationships, such as sameness and difference.},
	number = {6831},
	journal = {Nature},
	author = {Giurfa, M and Zhang, S and Jenett, A and Menzel, R and Srinivasan, Mv},
	month = apr,
	year = {2001},
	keywords = {Jun 12 import},
	pages = {930--3.},
}

@article{huang_effects_1990,
	title = {Effects of ratio reinforcement schedules on choice behavior},
	volume = {117},
	abstract = {Choice behavior under a concurrent VR-FR schedule of reinforcement was investigated in two experiments to test a molar theory of maximization. Hunger-motivated albino rats pressed two bars, one on an FR10 and the other on a VR10 schedule, for a food reward. With the total number of experiences with each bar equated and interalternative switching eliminated during training, the study showed that during the choice test, the animals made significantly more responses to the VR than to the FR alternative, allocating about 75\% of their responses to the VR alternative. The results suggest that, given an equal return of reward in the long run, the animals preferred a variable to a constant alternative in a choice situation. The findings are discussed in terms of a molar theory of maximization and a schedule-appropriate behavior interpretation of choice.},
	number = {1},
	journal = {J. Gen. Psychol.},
	author = {Huang, In and Melvin, Jn},
	month = jan,
	year = {1990},
	keywords = {Jun 12 import},
	pages = {99--106.},
}

@article{loo_learning_1992,
	title = {Learning in honeybees ({Apis} mellifera) as a function of sucrose concentration},
	volume = {106},
	abstract = {Foraging honeybees (Apis mellifera) were trained with 2 successively presented targets differing in color or odor, one of which always contained a 5-microliters drop of 50\% sucrose solution and the other, a 5-microliters drop of 20\% sucrose solution. Latency of response to each target was measured during the training, and at the conclusion, preference was measured in an unrewarded choice test. Analysis of the latencies showed both a prospective effect (faster response to the 50\% target than to the 20\% target) and a nonassociative retrospective effect (faster response after leaving the 20\% target than after leaving the 50\% target) reminiscent of the frustration effect in rats. The results both for prospective latency and for choice can be understood on the simple theory that the attractiveness of a target depends on the strength of its association with sucrose and that the effect of concentration is on asymptotic strength.},
	number = {1},
	journal = {J. Comp. Psychol.},
	author = {Loo, Sk and Bitterman, Me},
	month = mar,
	year = {1992},
	keywords = {Jun 12 import},
	pages = {29--36.},
}

@article{page_connectionist_2000-1,
	title = {Connectionist {Modelling} in {Psychology}: {A} {Localist} {Manifesto}},
	volume = {23},
	abstract = {Over the last decade, fully-distributed models have become dominant in connectionist psychological modelling, whereas the virtues of localist models have been underestimated. This target article illustrates some of the benefits of localist modelling. Localist models are characterized by the presence of localist representations rather than the absence of distributed representations. A generalized localist model is proposed that exhibits many of the properties of fully distributed models. It can be applied to a number of problems that are difficult for fully distributed models and its applicability can be extended through comparisons with a number of classic mathematical models of behaviour. There are reasons why localist models have been underused and these are addressed. In particular, many conclusions about connectionist representation, based on neuroscientific observation, are called into question. There are still some problems inherent in the application of fully distributed systems and some inadequacies in proposed solutions to these problems. In the domain of psychological modelling, localist modelling is to be preferred.},
	number = {4},
	journal = {Behav. Brain Sci.},
	author = {Page, Mike},
	year = {2000},
	keywords = {neural networks, Psychology.bib, choice, competition, connectionist modelling, consolidation., distributed, localist, reaction-time},
}

@article{chown_making_1999-1,
	title = {Making predictions in an uncertain world: {Environmental} structure and cognitive maps},
	volume = {7},
	abstract = {The article examines the relationship between environmental and cognitive structure. One of the key tasks for any agent interacting in the real world is the management of uncertainty; because of this the cognitive structures which interact with real environments, such as would be used in navigation, must effectively cope with the uncertainty inherent in a constantly changing world. Despite this uncertainty, however, real environment usually afford structure that can be effectively exploited by organisms. The article examines environmental characteristics and structures that enable humans to survive and thrive in a wide range of real environments. The relationship between these characteristics and structures, uncertainty, and cognitive structure is explored in the context of PLAN, a proposed model of human cognitive mapping, and R-PLAN, a version of PLAN that has been instantiated on an actual mobile robot. An examination of these models helps to provide insight into environmental characteristics which impact human performance on tasks which require interaction with the world.},
	number = {1},
	journal = {Adapt. Behav.},
	author = {Chown, Eric},
	year = {1999},
	keywords = {Psychology.bib, navigation, associative networks, cognitive maps, gateways},
}

@article{fu_perceptual_2000-1,
	title = {The {Perceptual} {Generalization} {Capabilities} of the {Cell} {Assembly}},
	abstract = {Perceptual generalization is the capacity to appropriately recognize many different stimulus patterns as the same object despite enormous variability in these patterns. Perceptual generalization is an essential component of the phenomenal information processing abilities of humans that allows us to adapt to our ever-changing world. The development of computer models that can be used to simulate how humans are able to appropriately generalize can aid our understanding of both natural and artificial intelligence. In order to understand how cell assemblies acquire the capacity for perceptual generalization, the formation of cell assemblies via unsupervised perceptual learning was studied. This paper reports results that provide an existence proof of circumstances under which the cell assemblies that formed respond appropriately for two perceptual generalization tasks. The first task involved varying the features that were presented each time an object was presented. The second task was designed to capture the idea that one never sees the front of a three-dimensional object and the back of the object at the same time, yet one is still able to recognize it as the same object. This is possible because views of the side of the object contain features of both the front and the back of the object. The results for the second perceptual generalization task are also applicable to the ability of the cell assembly to categorize based on family resemblance. For economy of storage, subassemblies are expected to be shared between cell assemblies. This paper also reports results on the formation of cell assemblies that share subassemblies, where this sharing does not cause the inappropriate activation of cell assemblies.},
	author = {Fu, Leeann L},
	year = {2000},
	keywords = {Psychology.bib},
}

@article{kaplan_tracing_1991-1,
	title = {Tracing {Recurrent} {Activity} in {Cognitive} {Elements} ({TRACE}): a {Model} of {Temporal} {Dynamics} in a {Cell} {Assembly}},
	volume = {3},
	abstract = {Hebb's introduction of the cell assembly marks the beginning of modern connectionism, yet its implications remain largely unexplored and its potential unexploited. Lately, however, promising efforts have been made to utilize recurrent connections, suggesting the timeliness of a re-examination of the cell assembly as a key element in a cognitive connectionism. Our approach emphasizes the psychological functions of activity in a cell assembly. This provides an opportunity to explore the dynamic behavior of the cell assembly considered as a continuous system, an important topic that we feel has not been given sufficient attention. A step-by-step analysis leads to an identification of characteristic temporal patterns and of necessary control systems. Each step of this analysis leads to a corresponding building block in a set of emerging equations. A series of experiments is then described that explore the implications of the theoretically derived equations in terms of the time course of activity generated by a simulation under different conditions. Finally, the model is evaluated in terms of whether the various constraints deemed important can be met, whether the resulting simulation is robust, and whether the solution promises sufficient utility and generality.},
	number = {2},
	journal = {Conn. Sci.},
	author = {Kaplan, Stephen and Sonntag, Martin and Chown, Eric},
	year = {1991},
	keywords = {Neural networks, simulation, Psychology.bib, cell assembly, perception, consolidation, connectionism, neural fatigue, peak activation},
	pages = {179--206},
}

@article{kuhl_linguistic_1992-1,
	title = {Linguistic experience alters phonetic perception in infants by 6 months of age},
	volume = {255},
	abstract = {Linguistic experience affects phonetic perception. However, the critical period during which experience affects perception and the mechanism responsible for these effects are unknown. This study of 6-month-old infants from two countries, the United States and Sweden, shows that exposure to a specific language in the first half year of life alters infants' phonetic perception.},
	journal = {Science},
	author = {Kuhl, Patricia K and Williams, Karen A and Lacerda, Francisco and Stevens, Kenneth N and Lindblom, Bjorn},
	month = jan,
	year = {1992},
	keywords = {Psychology.bib},
	pages = {606--608},
}

@article{chown_prototypes_1995-1,
	title = {Prototypes, {Location}, and {Associative} {Networks} ({PLAN}): {Towards} a {Unified} {Theory} of {Cognitive} {Mapping}},
	volume = {19},
	journal = {Cogn. Sci.},
	author = {Chown, E and Kaplan, S and Kortenkamp, D},
	year = {1995},
	keywords = {Psychology.bib},
	pages = {1--51},
}

@incollection{nadel_neural_1999-1,
	title = {Neural {Mechanisms} of {Spatial} {Orientation} and {Wayfinding}: {An} {Overview}},
	booktitle = {Wayfinding {Behavior}: {Cognitive} {Mapping} and {Other} {Spatial} {Processes}},
	publisher = {The Johns Hopkins University Press},
	author = {Nadel, Lynn},
	editor = {Golledge, Reginald G},
	year = {1999},
	note = {Section: 12},
	keywords = {Psychology.bib},
	pages = {313--327},
}

@incollection{berthoz_dissociation_1999-1,
	title = {Dissociation between {Distance} and {Direction} during {Locomotor} {Navigation}},
	booktitle = {Wayfinding {Behavior}: {Cognitive} {Mapping} and {Other} {Spatial} {Processes}},
	publisher = {The Johns Hopkins University Press},
	author = {Berthoz, Alain and Amorim, Michel-Ange and Glasauer, Stephan and Grasso, Renato and Takei, Yasuiko and Viaud-Delmon, Isabelle},
	editor = {Golledge, Reginald G},
	year = {1999},
	note = {Section: 13},
	keywords = {Psychology.bib},
	pages = {328--348},
}

@incollection{chown_error_1999-1,
	title = {Error {Tolerance} and {Generalization} in {Cognitive} {Maps}: {Performance} without {Precision}},
	booktitle = {Wayfinding {Behavior}: {Cognitive} {Mapping} and {Other} {Spatial} {Processes}},
	publisher = {The Johns Hopkins University Press},
	author = {Chown, Eric},
	editor = {Golledge, Reginald G},
	year = {1999},
	note = {Section: 14},
	keywords = {Psychology.bib},
	pages = {349--369},
}

@article{herrnstein_relative_1961-1,
	title = {Relative and {Absolute} {Strength} of {Response} as a {Function} of {Frequency} of {Reinforcement}},
	volume = {4},
	abstract = {A previous paper (Herrnstein, 1958) reported how pigeons behave on a concurrent schedule under which they peck at either of two response-keys. The significant finding of this investigation was that the relative frequency of responding to each of the keys may be controlled within narrow limits by adjustments in an independent variable. In brief, the requirement for reinforcement in this procedure is the emission of a minimum number of pecks to each of the keys. The pigeon receives food when it completes the requirement on both keys. The frequency of responding to each key was a close approximation to the minimum requirement. The present experiment explores the relative frequency of responding further. In the earlier study it was shown that the output of behavior to each of two keys may be controlled by specific requirements of outputs. Now we are investigating output as a function of frequency of reinforcement. The earlier experiment may be considered a study of differential reinforcement; the present one, a study of strength of response. Both experiments are attempts to elucidate the properties of relative frequency of responding as a dependent variable.},
	journal = {J. Exp. Anal. Behav.},
	author = {Herrnstein, R J},
	year = {1961},
	keywords = {Psychology.bib},
	pages = {267--272},
}

@article{herrnstein_melioration_1991-1,
	title = {Melioration: {A} {Theory} of {Distributed} {Choice}},
	volume = {5},
	abstract = {In modern expositions of the theory of rational choice, the notion of what constitutes an object of choice is kept deliberately vague, so as not to restrict unduly the range of possible problems to which the theory will be applied later on. A recent advanced textbook on consumer behavior (Deaton and Muellbauer, 1980), for example, initially defines the objects of choice as “individual purchases of commodities” (p. 269), but this concrete definition yields quickly to the more abstract notion of a commodity “bundle,” which is rarely obtained through an individual purchase. Implicit in this exchangeability of terms is the supposition that in applying the theory it does not matter whether: A) the “choice” corresponds to an actual decision, made at a specific point in time; or B) the “choice” is an aggregate of many smaller decisions, distributed over a period of time. In this paper, we develop a theory of individual choice called 'melioration,' for which the distinction between choices of type A and type B is critical, and which implies that choices of type B may be reliably and predictably suboptimal, in terms of the person's own preferences. If true, this would imply that preferences as revealed in the marketplace may be a distortion of the true underlying preferences whenever the measured economic variables are aggregates of a stream of smaller decisions; the extent and direction of the distortion is then something that the theory will need to explain.},
	number = {3},
	journal = {J. Econ. Perspect.},
	author = {Herrnstein, R J and Prelec, D},
	year = {1991},
	keywords = {Psychology.bib},
	pages = {137--156},
}

@article{heyman_operant_1979-1,
	title = {Operant matching is not a logical consequence of maximizing reinforcement rate},
	volume = {7},
	abstract = {The distribution of behavior between concurrently available schedules of reinforcement approximates the distribution of reinforcements between the schedules. This equality, called matching, has been explained as an instance of the principle that organisms maximize reinforcement rate. However, a precise account of the relationship between the distribution of behavior and reinforcement rate on the standard concurrent schedule shows that matching and maximizing are different.},
	number = {2},
	journal = {Anim. Learn. Behav.},
	author = {Heyman, G M and Luce, R D},
	year = {1979},
	keywords = {Psychology.bib},
	pages = {133--140},
}

@article{baum_optimization_1981-1,
	title = {Optimization and the matching law as accounts of instrumental behavior},
	volume = {36},
	abstract = {The interaction between instrumental behavior and environment can be conveniently described at a molar level as a feedback system. Two different possible theories, the matching law and optimization, differ primarily in the reference criterion they suggest for the system. Both offer accounts of most of the known phenomena of performance on concurrent and single variable-interval and variable-ratio schedules. The matching law appears stronger in describing concurrent performances, whereas optimization appears stronger in describing performance on single schedules.},
	number = {3},
	journal = {J. Exp. Anal. Behav.},
	author = {Baum, W M},
	month = nov,
	year = {1981},
	keywords = {Psychology.bib},
	pages = {387--403},
}

@article{heyman_markov_1979-1,
	title = {A {Markov} {Model} {Description} of {Changeover} {Probabilities} on {Concurrent} {Variable}-{Interval} {Schedules}},
	volume = {31},
	abstract = {The primary data were peck-by-peck sequential records of four pigeons responding on several different concurrent variable-interval schedules. According to the hypothesis that the subject chooses the alternative with the highest probability of reinforcement at the moment, response-by-response performance in concurrent schedules should show sequential dependencies. However, such dependencies were not found, and it was possible to describe molecular-level performance with simple Markov chain models. The Markov model description implies that the momentary changeover probabilities were proportional to the overall relative reinforcement frequencies, and that changeover probabilities did not change as a function of previous responding. A second finding was that although a change-over-delay procedure was omitted, relative response frequencies closely approximated relative reinforcement frequencies.},
	number = {1},
	journal = {J. Exp. Anal. Behav.},
	author = {Heyman, G M},
	month = jan,
	year = {1979},
	keywords = {Psychology.bib},
	pages = {41--51},
}

@article{heyman_harvard_2002-1,
	title = {The {Harvard} {Pigeon} {Lab}, 1970-1998: {Graduate} {Students} and {Matching} {Law} {Research}},
	volume = {77},
	number = {3},
	journal = {J. Exp. Anal. Behav.},
	author = {Heyman, G M},
	month = may,
	year = {2002},
	keywords = {Psychology.bib},
	pages = {380--383},
}

@article{heyman_more_1986-1,
	title = {More on concurrent interval-ratio schedules: a replication and review},
	volume = {46},
	abstract = {It has been suggested that the failure to maximize reinforcement on concurrent variable-interval, variable-ratio schedules may be misleading. Inasmuch as response costs are not directly measured, it is possible that subjects are optimally balancing the benefits of reinforcement against the costs of responding. To evaluate this hypothesis, pigeons were tested in a procedure in which interval and ratio schedules had equal response costs. On a concurrent variable time (VT), variable ratio-time (VRT) schedule, the VT schedule runs throughout the session and the VRT schedule is controlled by responses to a changeover key that switches from one schedule to the other. Reinforcement is presented independent of response. This schedule retains the essential features of concurrent VI VR, but eliminates differential response costs for the two alternatives. It therefore also eliminates at least one significant ambiguity about the reinforcement maximizing performance. Pigeons did not maximize rate of reinforcement on this procedure. Instead, their times spent on the alternative schedules matched the relative rates of reinforcement, even when schedule parameters were such that matching earned the lowest possible overall rate of reinforcement. It was further shown that the observed matching was not a procedural artifact arising from the constraints built into the schedule.},
	number = {3},
	journal = {J. Exp. Anal. Behav.},
	author = {Heyman, G M and Herrnstein, R J},
	month = nov,
	year = {1986},
	keywords = {Psychology.bib},
	pages = {331--351},
}

@article{giurfa_concepts_2001-1,
	title = {The concepts of 'sameness' and 'difference' in an insect},
	volume = {410},
	abstract = {Insects process and learn information flexibly to adapt to their environment. The honeybee Apis mellifera constitutes a traditional model for studying learning and memory at behavioural, cellular and molecular levels. Earlier studies focused on elementary associative and non-associative forms of learning determined by either olfactory conditioning of the proboscis extension reflex or the learning of visual stimuli in an operant context. However, research has indicated that bees are capable of cognitive performances that were thought to occur only in some vertebrate species. For example, honeybees can interpolate visual information, exhibit associative recall, categorize visual information and learn contextual information. Here we show that honeybees can form 'sameness' and 'difference' concepts. They learn to solve 'delayed matching-to-sample' tasks, in which they are required to respond to a matching stimulus, and 'delayed non-matching-to-sample' tasks, in which they are required to respond to a different stimulus; they can also transfer the learned rules to new stimuli of the same or a different sensory modality. Thus, not only can bees learn specific objects and their physical parameters, but they can also master abstract inter-relationships, such as sameness and difference.},
	number = {6831},
	journal = {Nature},
	author = {Giurfa, M and Zhang, S and Jenett, A and Menzel, R and Srinivasan, Mv},
	month = apr,
	year = {2001},
	keywords = {Psychology.bib},
	pages = {930--3.},
}

@article{loo_learning_1992-1,
	title = {Learning in honeybees ({Apis} mellifera) as a function of sucrose concentration},
	volume = {106},
	abstract = {Foraging honeybees (Apis mellifera) were trained with 2 successively presented targets differing in color or odor, one of which always contained a 5-microliters drop of 50\% sucrose solution and the other, a 5-microliters drop of 20\% sucrose solution. Latency of response to each target was measured during the training, and at the conclusion, preference was measured in an unrewarded choice test. Analysis of the latencies showed both a prospective effect (faster response to the 50\% target than to the 20\% target) and a nonassociative retrospective effect (faster response after leaving the 20\% target than after leaving the 50\% target) reminiscent of the frustration effect in rats. The results both for prospective latency and for choice can be understood on the simple theory that the attractiveness of a target depends on the strength of its association with sucrose and that the effect of concentration is on asymptotic strength.},
	number = {1},
	journal = {J. Comp. Psychol.},
	author = {Loo, Sk and Bitterman, Me},
	month = mar,
	year = {1992},
	keywords = {Psychology.bib},
	pages = {29--36.},
}

@article{huang_effects_1990-1,
	title = {Effects of ratio reinforcement schedules on choice behavior},
	volume = {117},
	abstract = {Choice behavior under a concurrent VR-FR schedule of reinforcement was investigated in two experiments to test a molar theory of maximization. Hunger-motivated albino rats pressed two bars, one on an FR10 and the other on a VR10 schedule, for a food reward. With the total number of experiences with each bar equated and interalternative switching eliminated during training, the study showed that during the choice test, the animals made significantly more responses to the VR than to the FR alternative, allocating about 75\% of their responses to the VR alternative. The results suggest that, given an equal return of reward in the long run, the animals preferred a variable to a constant alternative in a choice situation. The findings are discussed in terms of a molar theory of maximization and a schedule-appropriate behavior interpretation of choice.},
	number = {1},
	journal = {J. Gen. Psychol.},
	author = {Huang, In and Melvin, Jn},
	month = jan,
	year = {1990},
	keywords = {Psychology.bib},
	pages = {99--106.},
}

@incollection{foldiak_sparse_1995,
	title = {Sparse coding in the primate cortex},
	booktitle = {The {Handbook} of {Brain} {Theory} and {Neural} {Networks}},
	publisher = {MIT Press},
	author = {Foldiak, P},
	editor = {Arbib, M A},
	year = {1995},
	keywords = {Jun 12 import},
	pages = {895--898},
}

@article{price_developmental_1979,
	title = {Developmental determinants of structure in zebra finch song},
	volume = {93},
	journal = {J. Comp. Physiol. Psychol.},
	author = {Price, P H},
	year = {1979},
	keywords = {Jun 12 import},
	pages = {268--277},
}

@incollection{doya_computational_1998-1,
	title = {A computational model of birdsong learning by auditory experience and auditory feedback},
	booktitle = {Central {Auditory} {Processing} and {Neural} {Modeling}},
	publisher = {Plenum Publishing},
	author = {Doya, K and Sejnowski, T J},
	editor = {Brugge, J and Poon, P},
	year = {1998},
	keywords = {birdpaper.bib},
	pages = {77--88},
}

@incollection{foldiak_sparse_1995-1,
	title = {Sparse coding in the primate cortex},
	booktitle = {The {Handbook} of {Brain} {Theory} and {Neural} {Networks}},
	publisher = {MIT Press},
	author = {Foldiak, P},
	editor = {Arbib, M A},
	year = {1995},
	keywords = {birdpaper.bib},
	pages = {895--898},
}

@incollection{doya_novel_1995-2,
	title = {A novel reinforcement model of birdsong vocalization learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 7},
	publisher = {MIT Press},
	author = {Doya, K and Sejnowski, T J},
	editor = {Tesauro, G and Touretzky, D S and Leen, T K},
	year = {1995},
	keywords = {birdpaper.bib},
	pages = {101--108},
}

@article{hahnloser_bayesian_2002-1,
	title = {A bayesian characterization of a feedforward signal pathway in the songbird},
	journal = {Advances in Neural Information Processing Systems, submitted},
	author = {Hahnloser, R H R and Brown, E N and Kozhevnikov, A A and Fee, M S},
	year = {2002},
	keywords = {birdpaper.bib},
}

@article{willshaw_non-holographic_1969-1,
	title = {Non-holographic associative memory},
	volume = {222},
	journal = {Nature},
	author = {Willshaw, D J and Buneman, O P and Longuet-Higgins, H C},
	year = {1969},
	keywords = {birdpaper.bib},
	pages = {960--962},
}

@article{herrmann_analysis_1995-1,
	title = {Analysis of synfire chains},
	volume = {6},
	number = {3},
	journal = {Network: Comput. Neural Syst.},
	author = {Herrmann, M and Hertz, J A and Prugel-Bennett, A},
	month = aug,
	year = {1995},
	keywords = {birdpaper.bib},
	pages = {403--414},
}

@article{golomb_willshaw_1990-1,
	title = {Willshaw model: associative memory with sparse coding and low firing rates},
	volume = {41},
	journal = {Phys. Rev. A},
	author = {Golomb, D and Rubin, N and Sompolinsky, H},
	year = {1990},
	keywords = {birdpaper.bib},
	pages = {1843--1854},
}

@article{tsodyks_enhanced_1988-2,
	title = {Enhanced {Storage} {Capacity} in {Neural} {Networks} with {Low} {Level} of {Activity}},
	volume = {6},
	journal = {Europhys. Lett.},
	author = {Tsodyks, M and Feigelman, M},
	year = {1988},
	keywords = {birdpaper.bib},
	pages = {101},
}

@article{amari_learning_1972-3,
	title = {Learning pattern and pattern sequences by self-organizing nets of threshold elements},
	journal = {IEEE Trans. Comput.},
	author = {Amari, S-I},
	year = {1972},
	keywords = {birdpaper.bib},
	pages = {1197--1206},
}

@article{mooney_synaptic_1992-2,
	title = {Synaptic basis for developmental plasticity in a birdsong nucleus},
	volume = {12},
	journal = {J. Neurosci.},
	author = {Mooney, R},
	year = {1992},
	keywords = {birdpaper.bib},
	pages = {2464--2477},
}

@article{price_developmental_1979-1,
	title = {Developmental determinants of structure in zebra finch song},
	volume = {93},
	journal = {J. Comp. Physiol. Psychol.},
	author = {Price, P H},
	year = {1979},
	keywords = {birdpaper.bib},
	pages = {268--277},
}

@article{nottebohm_central_1976-2,
	title = {Central control of song in the canary, {Serinus} canarius},
	volume = {165},
	journal = {J. Comp. Neurol.},
	author = {Nottebohm, F and Stokes, T M and Leonard, C M},
	year = {1976},
	keywords = {birdpaper.bib},
	pages = {457--486},
}

@article{georgopoulos_motor_1992-1,
	title = {The {Motor} {Cortex} and the {Coding} of {Force}},
	volume = {256},
	number = {5064},
	journal = {Science},
	author = {Georgopoulos, A and Ashe, J and Smyrnis, N and Taira, M},
	month = jun,
	year = {1992},
	keywords = {birdpaper.bib},
	pages = {1692--1695},
}

@article{theunissen_spectral-temporal_2000-1,
	title = {Spectral-temporal receptive fields of nonlinear auditory neurons obtained using natural sounds},
	volume = {20},
	number = {6},
	journal = {J. Neurosci.},
	author = {Theunissen, F E and Sen, K and Doupe, A J},
	month = mar,
	year = {2000},
	keywords = {birdpaper.bib},
	pages = {2315--2331},
}

@article{simpson_brain_1990-1,
	title = {Brain pathways for learned and unlearned vocalizations differ in zebra finches},
	volume = {10},
	number = {5},
	journal = {J. Neurosci.},
	author = {Simpson, H B and Vicario, D S},
	year = {1990},
	keywords = {birdpaper.bib},
	pages = {1541--1556},
}

@article{nordeen_long-term_1993-1,
	title = {Long-term maintenance of song in adult zebra finches is not affected by lesions of a forebrain region involved in song learning},
	volume = {59},
	journal = {Behav. Neural Biol.},
	author = {Nordeen, K and Nordeen, E},
	year = {1993},
	keywords = {birdpaper.bib},
	pages = {79--82},
}

@article{zhu_minimax_1997,
	title = {minimax entropy principle and its application to texture modeling},
	journal = {Neural Comput.},
	author = {{Zhu} and {Wu} and {Mumford}},
	year = {1997},
	keywords = {Jun 12 import},
}

@article{williams_simple_1992-2,
	title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
	volume = {8},
	abstract = {This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms, while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms.},
	journal = {Mach. Learn.},
	author = {Williams, R J},
	year = {1992},
	keywords = {MachineLearning.bib},
	pages = {229--256},
}

@article{zibulevsky_blind_2001-1,
	title = {Blind {Source} {Separation} by {Sparse} {Decomposition} in a {Signal} {Dictionary}},
	volume = {In press},
	abstract = {The blind source separation problem is to extract the underlying source signals from a set of linear mixtures, where the mixing matrix is unknown. This situation is common, in acoustics, radio, medical signal and image processing, hyperspectral imaging, etc. We suggest a two-stage seperation process. First, a priori selection of a possibly overcomplete signal dictionary (for instance a wavelet frame, or a learned dictionary) in which the sources are assumed to be sparsely representable. Second, unmixing the sources by exploiting their sparse representability. We consider the general case of more sources than mixtures, but also derive a more efficient algorithm in the case of a non-overcomplete and an equal number of sources and mixtures. Experiments with artificial signals and with musical sounds demonstrate significantly better separation than other known techniques.},
	journal = {Neural Comput.},
	author = {Zibulevsky, Michael and Pearlmutter, Barak A},
	year = {2001},
	keywords = {MachineLearning.bib},
}

@article{kaelbling_reinforcement_1996-1,
	title = {Reinforcement {Learning}: {A} {Survey}},
	volume = {4},
	abstract = {This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of the current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word “reinforcement”. The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and copying with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.},
	journal = {J. Artif. Intell. Res.},
	author = {Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
	year = {1996},
	keywords = {MachineLearning.bib},
}

@inproceedings{lee_learning_1999-2,
	title = {Learning in {Intelligent} {Embedded} {Systems}},
	abstract = {Information processing capabilities of embedded systems presently lack the robustness and rich complexity found in biological systems. Endowing artificial systems with the ability to adapt to changing conditions requires algorithms that can rapidly learn from examples. We demonstrate the application of one such learning algorithm on an inexpensive robot constructed to perform simple sensorimotor tasks. The robot learns to track a particular object by discovering the salient visual and auditory cues unique to that object. The system uses a convolutional neural network to combine color, luminance, motion, and auditory information. The weights of the networks are adjusted using feedback from a teacher to reflect the reliability of the various input channels in the surrounding environment. We also discuss how unsupervised learning can discover features in data without external interaction. An unsupervised algorithm based upon nonnegative matrix factorization is able to automatically learn the different parts of objects. Such a parts-based representation of data is crucial for robust object recognition.},
	publisher = {USENIX Workshop on Embedded Systems},
	author = {Lee, Daniel D and Seung, H Sebastian},
	year = {1999},
	keywords = {MachineLearning.bib},
}

@article{lee_neural_1998-1,
	title = {A neural network based head tracking system},
	volume = {10},
	abstract = {We have constructed an inexpensive, video-based, motorized tracking system that learns to track a head. It uses real time graphical user inputs or an auxiliary infrared detector as supervisory signals to train a convolutional neural network. The inputs to the neural network consist of normalized luminance and chrominance images and motion information from frame differences. Subsampled images are also used to provide scale invariance. During the online training phase, the neural network rapidly adjusts the input weights depending upon the reliability of the different channels in the surrounding environment. This quick adaptation allows the system to robustly track a head even when other objects are moving within a cluttered background.},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Lee, D D and Seung, H S},
	year = {1998},
	keywords = {MachineLearning.bib},
	pages = {605--611},
}

@inproceedings{atkeson_comparison_1997-1,
	title = {A {Comparison} of {Direct} and {Model}-{Based} {Reinforcement} {Learning}},
	abstract = {This papers compares direct reinforcement learning (no explicit model) and model-based reinforcement learning on a simple task: pendulum swing up. We find that in this task model-based approaches support reinforcement learning from smaller amounts of training data and efficient handling of changing goals.},
	publisher = {International Conference on Robotics and Automation},
	author = {Atkeson, Christopher G and Santamaria, Juan Carlos},
	year = {1997},
	keywords = {MachineLearning.bib},
}

@article{doya_reinforcement_1999-1,
	title = {Reinforcement learning in continuous time and space},
	volume = {12},
	abstract = {This paper presents a reinforcement learning framework for continuous- time dynamical systems without a priori discretization of time, state, and action. Based on the Hamilton-Jacobi-Bellman (HJB) equation for infinite- horizon, discounted reward problems, we derive algorithms for estimating value functions and for improving policies with the use of function approx- imators. The process of value function estimation is formulated as the minimization of a continuous-time form of the temporal difference (TD) error. Update methods based on backward Euler approximation and ex- ponential eligibility traces are derived and their correspondences with the conventional residual gradient, TD(0), and TD({\textbackslash}textbackslashlambda) algorithms are shown. For policy improvement, two methods, namely, a continuous actor-critic method and a value-gradient based greedy policy, are formulated. As a special case of the latter, a nonlinear feedback control law using the value gradient and the model of the input gain is derived. The advantage up- dating“, a model-free algorithm derived previously, is also formulated in the HJB based framework. The performance of the proposed algorithms is first tested in a non- linear control task of swinging up a pendulum with limited torque. It is shown in the simulations that 1) the task is accomplished by the continuous actor-critic method in a number of trials several times fewer than by the conventional discrete actor-critic method; 2) among the continuous policy update methods, the value-gradient based policy with a known or learned dynamic model performs several times better than the actor-critic method; and 3) a value function update using exponential eligibility traces is more efficient and stable than that based on Euler approximation. The algorithms are then tested in a higher-dimensional task, i.e., cart-pole swing-up. This task is accomplished in several hundred trials using the value-gradient based policy with a learned dynamic model.},
	journal = {Neural Comput.},
	author = {Doya, Kenji},
	year = {1999},
	keywords = {MachineLearning.bib},
	pages = {243--269},
}

@article{konda_actor-critic_1999-1,
	title = {Actor-{Critic} {Algorithms}},
	volume = {12},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Konda, V R and Tsitsiklis, J N},
	year = {1999},
	keywords = {MachineLearning.bib},
	pages = {1008--1014},
}

@article{sutton_policy_1999-1,
	title = {Policy {Gradient} {Methods} for {Reinforcement} {Learning} with {Function} {Approximation}},
	abstract = {Function approximation is essential to reinforcement learning, but the standard approach of approximating a value function and determining a policy from it has so far proven theoretically intractable. In this paper we explore an alternative approach in which the policy is explicitly represented by its own function approximator, independent of the value function, and is updated according to the gradient of expected reward with respect to the policy parameters. Williams's REINFORCE method and actor–critic methods are examples of this approach. Our main new result is to show that the gradient can be written in a form suitable for estimation from experience aided by an approximate action-value or advantage function. Using this result, we prove for the first time that a version of policy iteration with arbitrary differentiable function approximation is convergent to a locally optimal policy.},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
	year = {1999},
	keywords = {MachineLearning.bib},
}

@inproceedings{peshkin_learning_1999-1,
	title = {Learning {Policies} with {External} {Memory}},
	publisher = {Proceedings of the Sixteenth International Conference on Machine Learning},
	author = {Peshkin, Leonid and Meuleau, Nicolas and Kaelbling, Leslie Pack},
	year = {1999},
	keywords = {MachineLearning.bib},
}

@inproceedings{baird_gradient_1999-1,
	title = {Gradient {Descent} for {General} {Reinforcement} {Learning}},
	abstract = {A simple learning rule is derived, the VAPS algorithm, which can be instantiated to generate a wide range of new reinforcement-learning algorithms. These algorithms solve a number of open problems, define several new approaches to reinforcement learning, and unify different approaches to reinforcement learning under a single theory. These algorithms all have guaranteed convergence, and include modifications of several existing algorithms that were known to fail to converge on simple MDPs. These include Q-learning, SARSA, and advantage learning. In addition to these value-based algorithms it also generates pure policy-search reinforcement-learning algorithms, which learn optimal policies without learning a value function. In addition, it allows policy-search and value-based algorithms to be combined, thus unifying two very different approaches to reinforcement learning into a single Value and Policy Search (VAPS) algorithm. And these algorithms converge for POMDPs without requiring a proper belief state. Simulations results are given, and several areas for future research are discussed.},
	publisher = {Advances in Neural Information Processing Systems},
	author = {Baird, Leemon C and Moore, Andrew W},
	year = {1999},
	keywords = {MachineLearning.bib},
}

@inproceedings{kearns_approximate_1999-1,
	title = {Approximate planning in large {POMDPs} via reusable trajectories},
	publisher = {Advances in Neural Information Processing Systems},
	author = {Kearns, Michael and Mansour, Y and Ng, A},
	year = {1999},
	keywords = {MachineLearning.bib},
}

@book{press_numerical_1992-1,
	edition = {Second},
	title = {Numerical {Recipes} in {C}: {The} {Art} of {Scientific} {Computing}},
	publisher = {Cambridge University Press},
	author = {Press, William H and Teukolsky, Saul A and Vetterling, William T and Flannery, Brian P},
	year = {1992},
	keywords = {MachineLearning.bib},
}

@inproceedings{meuleau_off-policy_2000-1,
	title = {Off-{Policy} {Policy} {Search}},
	abstract = {Gradient-based policy search is an alternative to value-function-based methods for reinforcement learning in non-Markovian domains. One apparent drawback of policy search is its requirement that all actions be “on-policy”; that is, that there be no explicit exploration. In this paper, we provide a method using importance sampling to allow any well-behaved directed exploration policy during learning. We show both theoretically and experimentally that using this method can acheive dramatic performance improvements.},
	publisher = {NIPS},
	author = {Meuleau, Nicolas and Peshkin, Leonid and Kaelbling, Leslie P and Kim, Kee-Eung},
	year = {2000},
	keywords = {MachineLearning.bib},
}

@article{jordan_forward_1992-1,
	title = {Forward {Models}: {Supervised} {Learning} with a {Distal} {Teacher}},
	volume = {16},
	abstract = {Internal models of the environment have an important role to play in adaptive systems in general and are of particular importance for the supervised learning paradigm. In this paper we demonstrate that certain classical problems associated with the notion of the “teacher” in supervised learning can be solved by judicious use of learned internal models as components of the adaptive system. In particular, we show how supervised learning algorithms can be utilized in cases in which an unknown dynamical system intervenes between actions and desired outcomes. Our approach applies to any supervised learning algorithm that is capable of learning in multi-layer networks.},
	journal = {Cogn. Sci.},
	author = {Jordan, Michael I and Rumelhart, David E},
	year = {1992},
	keywords = {MachineLearning.bib},
	pages = {307--354},
}

@article{jordan_constrained_1992-1,
	title = {Constrained {Supervised} {Learning}},
	volume = {36},
	abstract = {When distinct outputs of an adaptive system have equivalent effects on the environment, the problem of finding appropriate actions given desired results is ill-posed. For supervised learning algorithms, the ill-posedness of such “inverse learning problems” implies a certain flexibility - during training, there are in general many possible target vectors corresponding to each input vector. To allow supervised learning algorithms to make use of this flexibility, the current paper considers how to specify targets by sets of constraints, rather than as particular vectors. Two classes of constraints are distinguished - configurational constraints, whish define regions of output space in which an output vector must lie, and temporal constraints, which define relationships between outputs produced at different points in time. Learning algorithms minimize a cost function that contains terms for both kinds of constraints.},
	number = {3},
	journal = {J. Math. Psychol.},
	author = {Jordan, Michael I},
	month = sep,
	year = {1992},
	keywords = {MachineLearning.bib},
	pages = {396--425},
}

@article{young_hebbian_2001-1,
	title = {A {Hebbian} {Feedback} {Covariance} {Learning} {Paradigm} for {Self}-{Tuning} {Optimal} {Control}},
	volume = {31},
	abstract = {We propose a novel adaptive optimal control paradigm inspired by Hebbian covariance synaptic adaptation, a preeminent model of learning and memory as well as other malleable functions in the brain. The adaptation is driven by the spontaneous fluctuations in the system input and output, the covariance of which provides useful information about the changes in the system behavior. The control structure represents a novel form of associative reinforcement learning in which the reinforcement signal is implicitly given by the covariance of the input output (I/O) signals. Theoretical foundations for the paradigm are derived using Lyapunov theory and are verified by means of computer simulations. The learning algorithm is applicable to a general class of nonlinear adaptive control prob-lems. This on-line direct adaptive control method benefits from a c omputationally straightforward design, proof of convergence, no need for complete system identification, robustness to noise and uncertainties, and the ability to optimize a general performance criterion in terms of system states and control signals. These attractive properties of Hebbian feedback covariance learning control lend themselves to future investigations into the computa-tional functions of synaptic plasticity in biological neurons.},
	number = {2},
	journal = {IEEE Trans. Syst. Man Cybern. B Cybern.},
	author = {Young, D L and Poon, C-S},
	month = apr,
	year = {2001},
	keywords = {MachineLearning.bib},
	pages = {173--186},
}

@article{jacobs_adaptive_1991-1,
	title = {Adaptive mixtures of local experts},
	volume = {3},
	abstract = {We present a new supervised learning procedure for systems composed of many separate networks, each of which learns to handle a subset of the complete set of training cases. The new procedure can be viewed either as a modular version of a multilayer supervised networks, or as an associative version of competitive learning. It therefore provides a new link between these two apparently different approaches. We demonstrate that the learning procedure divides up a vowel discrimination task into appropriate subtasks, each of which can be solved by a very simple expert network.},
	journal = {Neural Comput.},
	author = {Jacobs, R and Jordan, M I and Nowlan, S J and Hinton, G E},
	year = {1991},
	keywords = {MachineLearning.bib},
	pages = {79--87},
}

@article{cauwenberghs_analog_1996-1,
	title = {An {Analog} {VLSI} {Recurrent} {Neural} {Network} {Learning} a {Continuous}-{Time} {Trajectory}},
	volume = {7},
	abstract = {Real-time algorithms for gradient descent supervised learning in recurrent dynamical neural networks fail to support scalable VLSI (very large scale integration) implementation, due to their complexity which grows sharply with the network dimension. We present an alternative implementation in analog VLSI, which employs a stochastic perturbative algorithm to observe the gradient of the error index directly on the network in random directions of the parameter space, thereby avoiding the tedious task of deriving the gradient from an explicit model of the network dynamics. The network contains six fully recurrent neurons with continuous-time dynamics, providing 42 free parameters which comprise connection strengths and thresholds. The chip implementing the network includes local provisions supporting both the learning and storage of the parameters, integrated in a scalable architecture which can be readily expanded for applications of learning recurrent dynamical networks requiring larger dimensionality. We describe and characterize the functional elements comprising the implemented recurrent network and integrated learning system, and include experimental results obtained from training the network to produce two outputs following a circular trajectory, representing a quadrature-phase oscillator.},
	number = {2},
	journal = {IEEE Trans. Neural Netw.},
	author = {Cauwenberghs, G},
	month = mar,
	year = {1996},
	keywords = {MachineLearning.bib},
	pages = {346--361},
}

@article{jabri_weight_1992-1,
	title = {Weight {Perturbation}: {An} {Optimal} {Architecture} and {Learning} {Technique} for {Analog} {VLSI} {Feedforward} and {Recurrent} {Multilayer} {Networks}},
	volume = {3},
	abstract = {Previous work on analog VLSI implementation of multilayer perceptrons with on-chip learning has mainly targeted the implementation of algorithms such as back-propagation. Although back-propagation is efficient, its implementation in analog VLSI requires excessive computational hardware. In this paper we show that using gradient descent with direct approximation of the gradient instead of back-propagation is more economical for parallel analog implementations. We also show that this technique (which we call “weight perturbation”) is suitable for multilayer recurrent networks as well. A discrete level analog implementation showing the training of an XOR network as an example is also presented.},
	number = {1},
	journal = {IEEE Trans. Neural Netw.},
	author = {Jabri, M and Flower, B},
	month = jan,
	year = {1992},
	keywords = {MachineLearning.bib},
	pages = {154--157},
}

@inproceedings{hochreiter_learning_2001-1,
	title = {Learning to {Learn} {Using} {Gradient} {Descent}},
	publisher = {International Conference on Artificial Neural Networks},
	author = {Hochreiter, S and Younger, A S and Conwell, P R},
	year = {2001},
	keywords = {MachineLearning.bib},
	pages = {87--94},
}

@article{ghahramani_probabilistic_nodate-1,
	title = {Probabilistic {Models} for {Unsupervised} {Learning}},
	abstract = {Many of the methods used for clustering, dimensionality reduction, source separation, time series modeling, and other classical problems in unsupervised data modeling are closely related to each other. The focus of this tutorial is to present a consistent unified picture of how these methods, which have been developed and rediscovered in several different fields, are variants of each other, and how a single framework can be used to develop learning algorithms for all of them. We will start from a humble Gaussian model, to describe how continuous state models such as factor analysis, principal components analysis (PCA) and independent components analysis (ICA) are related to each other. We will then motivate discrete state mixture models and vector quantization. Mixture models and factor analysis are then extended to model time series data, and result in hidden Markov models (HMMs) and linear-Gaussian dynamical systems (a.k.a. state-space models), respectively. All of these models can be described within the framework of probabilistic graphical models, which we will briefly introduce. In this framework it becomes easy to explore variants and hybrids (such as mixtures of factor analyzers and switching state-space models) which are potentially powerful tools. This framework also makes it clear that the same general probability propagation algorithm can be used to infer the hidden (i.e. latent) variables in all these models, and that the EM algorithm can be used to learn the maximum likelihood (ML) parameters. In the latter part of the tutorial we will focus on approximate inference techniques for models in which probability propagation is intractable, and on variational methods for Bayesian model averaging which can overcome the overfitting and model selection problems in ML learning. Matlab demos will be used to demonstrate some of the models and algorithms.},
	author = {Ghahramani, Zoubin and Roweis, Sam},
	keywords = {MachineLearning.bib},
}

@article{giles_noisy_2001-1,
	title = {Noisy {Time} {Series} {Prediction} using a {Recurrent} {Neural} {Network} and {Grammatical} {Inference}},
	abstract = {Financial forecasting is an example of a signal processing problem which is challenging due to small sample sizes, high noise, non-stationarity, and non-linearity. Neural networks have been very successful in a number of signal processing applications. We discuss fundamental limita-tions and inherent difficulties when using neural networks for the processing of high noise, small sample size signals. We introduce a new intelligent signal processing method which addresses the difficulties. The method proposed uses conversion into a symbolic representation with a self-organizing map, and grammatical inference with recurrent neural networks. We apply the method to the prediction of daily foreign exchange rates, addressing difficulties with non-stationarity, overfitting, and unequal a priori class probabilities, and we find significant predictability in com-prehensive experiments covering 5 different foreign exchange rates. The method correctly pre-dicts the direction of change for the next day with an error rate of 47.1\%. The error rate reduces to around 40\% when rejecting examples where the system has low confidence in its prediction. We show that the symbolic representation aids the extraction of symbolic knowledge from the trained recurrent neural networks in the form of deterministic finite state automata. These automata ex-plain the operation of the system and are often relatively simple. Automata rules related to well known behavior such as trend following and mean reversal are extracted.},
	journal = {Machine Learning, Volume 44, Number 1/2, July/August, pp. 161183, 2001.},
	author = {Giles, C Lee},
	year = {2001},
	keywords = {MachineLearning.bib},
}

@article{connor_recurrent_1994-1,
	title = {Recurrent neural networks and robust time series prediction},
	journal = {IEEE Trans. Neural Netw.},
	author = {Connor, J t and Martin, R d and Altas, L e},
	year = {1994},
	keywords = {MachineLearning.bib},
}

@article{molgedey_separation_1994-1,
	title = {Separation of a mixture of independent signals using time delayed correlations},
	volume = {72},
	abstract = {The problem of separating n linearly superimposed uncorrelated signals and determining their mixing coefficients is reduced to an eigenvalue problem which involves the simultaneous diagonalization of two symmetric matrices whose elements are measureable time delayed correlation functions. The diagonalization matrix can be determined from a cost function whose number of minima is equal to the number of degenerate solutions. Our approach offers the possibility to separate also nonlinear mixtures of signals.},
	journal = {Phys. Rev. Lett.},
	author = {Molgedey, L and Schuster, H G},
	year = {1994},
	keywords = {MachineLearning.bib},
	pages = {3634--3637},
}

@article{zhu_minimax_1997-1,
	title = {minimax entropy principle and its application to texture modeling},
	journal = {Neural Comput.},
	author = {{Zhu} and {Wu} and {Mumford}},
	year = {1997},
	keywords = {MachineLearning.bib},
}

@article{neal_probabilistic_nodate-1,
	title = {Probabilistic {Inference} using {Markov} {Chain} {Monte} {Carlo} {Methods}},
	abstract = {Probabilistic inference is an attractive approach to uncertain reasoning and empirical learning in artificial intelligence. Computational difficulties arise, however, because probabilistic models with the necessary realism and flexibility lead to complex distributions over high-dimensional spaces. Related problems in other fields have been tackled using Monte Carlo methods based on sampling using Markov chains, providing a rich array of techniques that can be applied to problems in artificial intelligence. The “Metropolis algorithm” has been used to solve difficult problems in statistical physics for over forty years, and, in the last few years, the related method of “Gibbs sampling” has been applied to problems of statistical inference. Concurrently, an alternative method for solving problems in statistical physics by means of dynamical simulation has been developed as well, and has recently been unified with the Metropolis algorithm to produce the “hybrid Monte Carlo” method. In computer science, Markov chain sampling is the basis of the heuristic optimization technique of “simulated annealing”, and has recently been used in randomized algorithms for approximate counting of large sets. In this review, I outline the role of probabilistic inference in artificial intelligence, present the theory of Markov chains, and describe various Markov chain Monte Carlo algorithms, along with a number of supporting techniques. I try to present a comprehensive picture of the range of methods that have been developed, including techniques from the varied literature that have not yet seen wide application in artificial intelligence, but which appear relevant. As illustrative examples, I use the problems of probabilistic inference in expert systems, discovery of latent classes from data, and Bayesian learning for neural networks.},
	journal = {Technical Report CRG-TR-93-1 (September 1993),},
	author = {Neal, Radford M},
	keywords = {MachineLearning.bib},
}

@article{baxter_infinite-horizon_2001-1,
	title = {Infinite-{Horizon} {Policy}-{Gradient} {Estimation}},
	volume = {15},
	abstract = {Gradient-based approaches to direct policy search in reinforcement learning have received much recent attention as a means to solve problems of partial observability and to avoid some of the problems associated with policy degradation in value-function methods. In this paper we introduce GPOMDP, a simulation-based algorithm for generating a biased estimate of the gradient of the average reward in Partially Observable Markov Decision Processes POMDPs controlled by parameterized stochastic policies. A similar algorithm was proposed by (Kimura et al. 1995). The algorithm's chief advantages are that it requires storage of only twice the number of policy parameters, uses one free beta (which has a natural interpretation in terms of bias-variance trade-off), and requires no knowledge of the underlying state. We prove convergence of GPOMDP, and show how the correct choice of the parameter beta is related to the mixing time of the controlled POMDP. We briefly describe extensions of GPOMDP to controlled Markov chains, continuous state, observation and control spaces, multiple-agents, higher-order derivatives, and a version for training stochastic policies with internal states. In a companion paper (Baxter et al., this volume) we show how the gradient estimates generated by GPOMDP can be used in both a traditional stochastic gradient algorithm and a conjugate-gradient procedure to find local optima of the average reward.},
	journal = {J. Artif. Intell. Res.},
	author = {Baxter, J and Bartlett, P l},
	year = {2001},
	keywords = {MachineLearning.bib},
	pages = {319--350},
}

@incollection{smagt_solving_1998-1,
	series = {Springer {Lecture} {Notes} in {Computer} {Science}},
	title = {Solving the ill-conditioning in neural network learning},
	volume = {1524},
	abstract = {In this paper we investigate the feed-forward learning problem. The well-known ill-conditioning which is present in most feed-forward learning problems is shown to be the result of the structure of the network. Also, the well-known problem that weights between `higher' layers in the network have to settle before `lower' weights can converge is addressed. We present a solution to these problems by modifying the structure of the network through the addition of linear connections which carry shared weights. We call the new network structure the linearly augmented feed-forward network, and it is shown that the universal approximation theorems are still valid. Simulation experiments show the validity of the new method, and demonstrate that the new network is less sensitive to local minima and learns faster than the original network.},
	booktitle = {Neural {Networks}: {Tricks} of the {Trade}},
	author = {Smagt, P Van Der and Hirzinger, G},
	editor = {M�ller, J Orr and {K}},
	year = {1998},
	keywords = {MachineLearning.bib},
	pages = {193--206},
}

@incollection{bianchini_optimal_1997-1,
	series = {Neural {Network} {Systems}, {Techniques} and {Applications}},
	title = {Optimal {Learning} in {Artificial} {Neural} {Networks}: {A} {Theoretical} {View}},
	volume = {2},
	abstract = {The effectiveness of connectionist models in emulating intelligent behaviour and solving significant practical problems is strictly related to the capability of the learning algorithms to find optimal or near-optimal solutions and to generalize to new examples. This chapter reviews some theoretical contributions to optimal learning in the attempt to provide a unified view and give the state of the art in the field. The focus of the review is on the problem of local minima in the cost function that is likely to affect more or less any learning algorithm. Starting from this analysis, we briefly review proposals for discovering optimal solutions and suggest conditions for designing architectures tailored to a given task. We focus mainly on batch-mode by investigating conditions that guarantee local minima free error surface for both static and dynamic networks. In the case of feedforward networks, local minima free error surfaces are guaranteed when the patterns are linearly separable or when using networks with as many hidden units as patterns to learn. Analogous results hold for radial basis function networks for which the absence of local minima is gained under the condition of patterns separable by hyperspheres. In the case of dynamic networks, local minima free error surfaces are guaranteed when matching the Decoupling Network Assumptions (DNA). They are essentially related to the decoupling of sequences of different classes on at least one gradient coordinate. Unlike other sufficient conditions, DNA seem more valuable in network design. Basically, for a given classification task, one can look for architectures that are well suited for learning. In the best case, such a search leads to discover networks for which learning takes place with no local minima. When no optimal network is found that guarantees local minima free error surface, one can, in any case, exploit DNA for discovering architectures that are well suited for the task at hand. The theoretical results described for batch-mode can partially be extended, at least for feedforward networks, to the case of pattern-mode learning. This duality, that holds also for non-small learning rates, is quite interesting, since it suggests conceiving new learning algorithms that are not necessarily based on function optimization, but on smart weight updating rules acting similarly to pattern-mode.},
	booktitle = {Optimization {Techniques}},
	publisher = {Academic Press},
	author = {Bianchini, M and Frasconi, P and Gori, M and Maggini, M},
	editor = {Leondes, C T},
	month = oct,
	year = {1997},
	keywords = {MachineLearning.bib},
	pages = {1--51},
}

@article{barto_associative_1981-1,
	title = {Associative search network: {A} reinforcement learning associative memory},
	volume = {40},
	journal = {Biol. Cybern.},
	author = {Barto, A G and Sutton, R S and Brouwer, P S},
	year = {1981},
	keywords = {MachineLearning.bib},
	pages = {201--211},
}

@article{barto_landmark_1981-1,
	title = {Landmark learning: {An} illustration of associative search},
	volume = {42},
	journal = {Biol. Cybern.},
	author = {Barto, A G and Sutton, R S},
	year = {1981},
	keywords = {MachineLearning.bib},
	pages = {1--8},
}

@article{aronszajn_theory_1950,
	title = {Theory of {Reproducing} {Kernels}},
	volume = {68},
	number = {3},
	journal = {Trans. Amer. Math. Soc.},
	author = {Aronszajn, N},
	month = may,
	year = {1950},
	keywords = {Jun 12 import},
	pages = {337--404},
}

@article{hansen_stochastic_1993,
	title = {Stochastic dynamics of supervised learning},
	volume = {26},
	journal = {J Physics A},
	author = {Hansen, Lk and Pathria, R and Salamaon, P},
	year = {1993},
	keywords = {Jun 12 import},
	pages = {63},
}

@article{heskes_learning_1991,
	title = {Learning processes in neural networks},
	volume = {44},
	number = {4},
	journal = {Phys. Rev. A},
	author = {Heskes, Tm and Kappen, B},
	month = aug,
	year = {1991},
	keywords = {Jun 12 import},
	pages = {2718--2726},
}

@article{heskes_fokker-planck_1994,
	title = {On {Fokker}-{Planck} approximations of on-line learning processes},
	volume = {27},
	journal = {J. Phys. A Math. Gen.},
	author = {Heskes, Tom},
	year = {1994},
	keywords = {Jun 12 import},
	pages = {5145--5160},
}

@inproceedings{smart_practical_2000,
	title = {Practical {Reinforcement} {Learning} in {Continuous} {Spaces}},
	volume = {16},
	publisher = {International Conference on Machine Learning (ICML)},
	author = {Smart, William D and Kaelbling, Leslie Pack},
	year = {2000},
	keywords = {Jun 12 import},
}

@article{barto_neuronlike_1983-1,
	title = {Neuronlike elements that can solve difficult learning control problems},
	volume = {13},
	journal = {IEEE Trans. Syst. Man Cybern.},
	author = {Barto, A G and Sutton, R S and Anderson, C W},
	year = {1983},
	keywords = {MachineLearning.bib},
	pages = {835--846},
}

@article{baxter_experiments_nodate-1,
	title = {Experiments with {Infinite}-{Horizon}, {Policy}-{Gradient} {Estimation}},
	abstract = {In this paper, we present algorithms that perform gradient ascent of the average reward in a par-tially observable Markov decision process (POMDP). These algorithms are based on GPOMDP, an algorithm introduced in a companion paper (Baxter \& Bartlett, 2001), which computes biased estimates of the performance gradient in POMDPs. The algorithms chief advantages are that it uses only one free parameter 2 [0; 1), which has a natural interpretation in terms of bias-variance trade-off, it requires no knowledge of the underlying state, and it can be applied to infinite state, control and observation spaces. We show how the gradient estimates produced by GPOMDP can be used to perform gradient ascent, both with a traditional stochastic-gradient algorithm, and with an algorithm based on conjugate-gradients that utilizes gradient information to bracket maxima in line searches. Experimental results are presented illustrating both the theoretical results of Baxter and Bartlett (2001) on a toy problem, and practical aspects of the algorithms on a number of more realistic problems.},
	journal = {Journal of Artificial Intelligence Research 15 (2001) 351-381 Submitted 9/00; published 11/01},
	author = {Baxter, J and Bartlett, P L and Weaver, L},
	keywords = {MachineLearning.bib},
}

@article{cucker_mathematical_2002-1,
	title = {On the mathematical foundations of learning},
	volume = {39},
	number = {1},
	journal = {Bull. Am. Math. Soc.},
	author = {Cucker, Felipe and Smale, Steve},
	year = {2002},
	keywords = {MachineLearning.bib},
	pages = {1--49},
}

@article{evgeniou_regularization_2000-1,
	title = {Regularization {Networks} and {Support} {Vector} {Machines}},
	volume = {13},
	abstract = {Regularization Networks and Support Vector Machines are techniques for solving certain problems of learning from examples � in particular, the regression problem of approximating a multivariate function from sparse data. Radial Basis Functions, for example, are a special case of both regularization and Support Vector Machines. We review both formulations in the context of Vapnik�s theory of statistical learning which provides a general foundation for the learning problem, combining functional analysis and statistics. The emphasis is on regression: classification is treated as a special case.},
	number = {1},
	journal = {Adv. Comput. Math.},
	author = {Evgeniou, Theodoros and Pontil, Massimiliano and Poggio, Tomaso},
	year = {2000},
	keywords = {MachineLearning.bib, Radial Basis Functions, regularization, Reproducing Kernel Hilbert Space, Structural Risk Minimization, Support Vector Machines},
	pages = {1--50},
}

@article{beardsley_sequential_1997-1,
	title = {Sequential {Updating} of {Projective} and {Affine} {Structure} from {Motion}},
	volume = {23},
	abstract = {A structure from motion algorithm is described which recovers structure and camera position, modulo a projective ambiguity. Camera calibration is not required, and camera parameters such as focal length can be altered freely during motion. The structure is updated sequentially over an image sequence, in contrast to schemes which employ a batch process. A specialisation of the algorithm to recover structure and camera position modulo an affine transformation is described, together with a method to periodically update the affine coordinate frame to prevent drift over time. We describe the constraint used to obtain this specialisation. Structure is recovered from image corners detected and matched automatically and reliably in real image sequences. Results are shown for reference objects and indoor environments, and accuracy of recovered structure is fully evaluated and compared for a number of reconstruction schemes. A specific application of the work is demonstrated�affine structure is used to compute free space maps enabling navigation through unstructured environments and avoidance of obstacles. The path planning involves only affine constructions.},
	number = {3},
	journal = {Int. J. Comput. Vis.},
	author = {Beardsley, P a and Zisserman, A and Murray, D w},
	year = {1997},
	keywords = {MachineLearning.bib},
	pages = {235--259},
}

@article{aronszajn_theory_1950-1,
	title = {Theory of {Reproducing} {Kernels}},
	volume = {68},
	number = {3},
	journal = {Trans. Amer. Math. Soc.},
	author = {Aronszajn, N},
	month = may,
	year = {1950},
	keywords = {MachineLearning.bib},
	pages = {337--404},
}

@article{lee_learning_1999-3,
	title = {Learning the parts of objects by non-negative matrix factorization},
	volume = {401},
	abstract = {Is perception of the whole based on perception of its parts? There is psychological and physiological evidence for parts-based representations in the brain, and certain computational theories of object recognition rely on such representations. But little is known about how brains or computers might learn the parts of objects. Here we demonstrate an algorithm for non-negative matrix factorization that is able to learn parts of faces and semantic features of text. This is in contrast to other methods, such as principal components analysis and vector quantization, that learn holistic, not parts-based, representations. Non-negative matrix factorization is distinguished from the other methods by its use of non-negativity constraints. These constraints lead to a parts-based representation because they allow only additive, not subtractive, combinations. When non-negative matrix factorization is implemented as a neural network, parts-based representations emerge by virtue of two properties: the firing rates of neurons are never negative and synaptic strengths do not change sign.},
	number = {6755},
	journal = {Nature},
	author = {Lee, Dd and Seung, Hs},
	month = oct,
	year = {1999},
	keywords = {MachineLearning.bib},
	pages = {788--791},
}

@article{lee_algorithms_2001-1,
	title = {Algorithms for non-negative matrix factorization},
	volume = {13},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Lee, D d and Seung, H s},
	year = {2001},
	keywords = {MachineLearning.bib},
	pages = {556--562},
}

@article{boyan_generalization_1995-1,
	title = {Generalization in {Reinforcement} {Learning}: {Safely} {Approximating} the {Value} {Function}},
	volume = {7},
	abstract = {A straightforward approach to the curse of dimensionality in reinforcement learning and dynamic programming is to replace the lookup table with a generalizing function approximator such as a neural net. Although this has been successful in the domain of backgammon, there is no guarantee of convergence. In this paper, we show that the combination of dynamic programming and function approximation is not robust, and in even very benign cases, may produce an entirely wrong policy. We then introduce Grow-Support, a new algorithm which is safe from divergence yet can still reap the benefits of successful generalization.},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Boyan, Justin A and Moore, Rew W},
	year = {1995},
	keywords = {MachineLearning.bib},
}

@inproceedings{ng_pegasus_2000-1,
	title = {{PEGASUS}: {A} policy search method for large {MDPs} and {POMDPs}},
	abstract = {We propose a new approach to the problem of searching a space of policies for a Markov decision process (MDP) or a partially observable Markov decision process (POMDP), given a model. Our approach is based on the following observation: Any (PO)MDP can be transformed into an �equivalent� POMDP in which all state transitions (given the current state and action) are deterministic. This reduces the general problem of policy search to one in which we need only consider POMDPs with deterministic transitions. We give a natural way of estimating the value of all policies in these transformed POMDPs. Policy search is then simply performed by searching for a policy with high estimated value. We also establish conditions under which our value estimates will be good, recovering theoretical results similar to those of Kearns, Mansour and Ng [7], but with �sample complexity� bounds that have only a polynomial rather than exponential dependence on the horizon time. Our method applies to arbitrary POMDPs, including ones with infi- nite state and action spaces. We also present empirical results for our approach on a small discrete problem, and on a complex continuous state/continuous action problem involving learning to ride a bicycle.},
	booktitle = {Uncertainty in {Artificial} {Intelligence}},
	author = {Ng, Andrew Y and Jordan, Michael},
	year = {2000},
	keywords = {MachineLearning.bib},
}

@inproceedings{ng_policy_2000-1,
	title = {Policy search via density estimation},
	volume = {12},
	abstract = {We propose a new approach to the problem of searching a space of stochastic controllers for a Markov decision process (MDP) or a partially observable Markov decision process (POMDP). Following several other authors, our approach is based on searching in parameterized families of policies (for example, via gradient descent) to optimize solution quality. However, rather than trying to estimate the values and derivatives of a policy directly, we do so indirectly using estimates for the probability densities that the policy induces on states at the different points in time. This enables our algorithms to exploit the many techniques for efficient and robust approximate density propagation in stochastic systems. We show how our techniques can be applied both to deterministic propagation schemes (where the MDP�s dynamics are given explicitly in compact form,) and to stochastic propagation schemes (where we have access only to a generative model, or simulator, of the MDP).We present empirical results for both of these variants on complex problems.},
	publisher = {NIPS},
	author = {Ng, Andrew Y and Parr, Ronald and Koller, Daphne},
	year = {2000},
	keywords = {MachineLearning.bib},
}

@inproceedings{kearns_sparse_1999-1,
	title = {A sparse sampling algorithm for near-optimal planning in large {Markov} decision processes},
	publisher = {Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence (IJCAI)},
	author = {Kearns, Michael and Mansour, Yishay and Ng, Andrew Y},
	year = {1999},
	keywords = {MachineLearning.bib},
}

@inproceedings{ng_policy_1999-1,
	title = {Policy invariance under reward transformations: {Theory} and application to reward shaping},
	publisher = {Proceedings of the Sixteenth International Conference on Machine Learning},
	author = {Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
	year = {1999},
	keywords = {MachineLearning.bib},
}

@article{huang_inference_1994-1,
	title = {Inference in {Belief} {Networks}: {A} {Procedural} {Guide}},
	volume = {11},
	abstract = {Belief networks are popular tools for encoding uncertainty in expert systems. These networks rely on inference algorithms to compute beliefs in the context of observed evidence. One established method for exact inference on belief networks is the Probability Propagation in Trees of Clusters (PPTC) algorithm, as developed by Lauritzen and Spiegelhalter and refined by Jensen et al. [1, 2, 3] PPTC converts the belief network into a secondary structure, then computes probabilities by manipulating the secondary structure. In this document, we provide a self-contained, procedural guide to understanding and implementing PPTC. We synthesize various optimizations to PPTC that are scattered throughout the literature. We articulate undocumented, “open secrets” that are vital to producing a robust and efficient implementation of PPTC. We hope that this document makes probabilistic inference more accessible and affordable to those without extensive prior exposure.},
	journal = {Int. J. Approx. Reason.},
	author = {Huang, Cecil and Darwiche, Adnan},
	year = {1994},
	keywords = {MachineLearning.bib, Artificial intelligence, Bayesian network, belief network, causal network, evidence, expert systems, join tree, probabilistic inference, probability propagation, reasoning under uncertainty},
}

@inproceedings{sutton_generalization_1995-1,
	title = {Generalization in {Reinforcement} {Learning}: {Successful} {Examples} {Using} {Sparse} {Coarse} {Coding}},
	volume = {8},
	abstract = {On large problems, reinforcement learning systems must use parameterized function approximators such as neural networks in order to generalize between similar situations and actions. In these cases there are no strong theoretical results on the accuracy of convergence, and computational results have been mixed. In particular, Boyan and Moore reported at last year's meeting a series of negative results in attempting to apply dynamic programming together with function approximation to simple control problems with continuous state spaces. In this paper, we present positive results for all the control tasks they attempted, and for one that is significantly larger. The most important differences are that we used sparse-coarse-coded function approximators (CMACs) whereas they used mostly global function approximators, and that we learned online whereas they learned offiine. Boyan and Moore and others have suggested that the problems they encountered could be solved by using actual outcomes (“rollouts”), as in classical Monte Carlo methods, and as in the TD({\textbackslash}textbackslashgamma) algorithm when {\textbackslash}textbackslashgamma = 1. However, in our experiments this always resulted in substantially poorer performance. We conclude that reinforcement learning can work robustly in conjunction with function approximators, and that there is little justification at present for avoiding the case of general {\textbackslash}textbackslashgamma.},
	publisher = {NIPS},
	author = {Sutton, R s},
	year = {1995},
	keywords = {MachineLearning.bib, acrobot},
	pages = {1038--1044},
}

@article{hansen_stochastic_1993-1,
	title = {Stochastic dynamics of supervised learning},
	volume = {26},
	journal = {J Physics A},
	author = {Hansen, Lk and Pathria, R and Salamaon, P},
	year = {1993},
	keywords = {MachineLearning.bib},
	pages = {63},
}

@article{heskes_learning_1991-1,
	title = {Learning processes in neural networks},
	volume = {44},
	number = {4},
	journal = {Phys. Rev. A},
	author = {Heskes, Tm and Kappen, B},
	month = aug,
	year = {1991},
	keywords = {MachineLearning.bib},
	pages = {2718--2726},
}

@article{biehl_learning_1995-1,
	title = {Learning by on-line gradient descent},
	volume = {28},
	journal = {J. Phys. A Math. Gen.},
	author = {Biehl, M and Schwarze, H},
	year = {1995},
	keywords = {MachineLearning.bib},
	pages = {643--656},
}

@article{lopez_-line_2000-1,
	title = {On-line learning from a finite training set: {A} solvable model},
	volume = {49},
	number = {3},
	journal = {Europhys. Lett.},
	author = {Lopez, B and Opper, M},
	year = {2000},
	keywords = {MachineLearning.bib},
	pages = {275--281},
}

@article{heskes_fokker-planck_1994-1,
	title = {On {Fokker}-{Planck} approximations of on-line learning processes},
	volume = {27},
	journal = {J. Phys. A Math. Gen.},
	author = {Heskes, Tom},
	year = {1994},
	keywords = {MachineLearning.bib},
	pages = {5145--5160},
}

@article{wiegerinck_stochastic_1994-1,
	title = {Stochastic dynamics of learning with momentum in neural networks},
	volume = {27},
	journal = {J. Phys. A Math. Gen.},
	author = {Wiegerinck, W and Komoda, A and Heskes, T},
	year = {1994},
	keywords = {MachineLearning.bib},
	pages = {4425--4437},
}

@article{leen_optimal_1999-1,
	title = {Optimal asymptotic learning rate: {Macroscopic} versus microscopic dynamics},
	volume = {59},
	journal = {PRE},
	author = {Leen, Tk and Schottky, B and Saad, D},
	year = {1999},
	keywords = {MachineLearning.bib},
	pages = {985--991},
}

@inproceedings{bradtke_reinforcement_1994-1,
	title = {Reinforcement {Learning} {Methods} for {Continuous}-{Time} {Markov} {Decision} {Problems}},
	volume = {07},
	abstract = {Semi-Markov Decision Problems are continuous time generalizations of discrete time Markov Decision Problems. A number of reinforcement learning algorithms have been developed recently for the solution of Markov Decision Problems, based on the ideas of asynchronous dynamic programming and stochastic approximation. Among these are TD({\textbackslash}textbackslashlambda), Q-learning, and Real-time Dynamic Programming. After reviewing semi-Markov Decision Problems and Bellman's optimality equation in that context, we propose algorithms similar to those named above, adapted to the solution of semi-Markov Decision Problems. We demonstrate these algorithms by applying them to the problem of determining the optimal control for a simple queueing system. We conclude with a discussion of circumstances under which these algorithms may be usefully applied.},
	publisher = {NIPS},
	author = {Bradtke, Steven J and Duff, Michael O},
	year = {1994},
	keywords = {MachineLearning.bib},
	pages = {393},
}

@inproceedings{smart_practical_2000-1,
	title = {Practical {Reinforcement} {Learning} in {Continuous} {Spaces}},
	volume = {16},
	publisher = {International Conference on Machine Learning (ICML)},
	author = {Smart, William D and Kaelbling, Leslie Pack},
	year = {2000},
	keywords = {MachineLearning.bib},
}

@inproceedings{smart_effective_2002-1,
	title = {Effective {Reinforcement} {Learning} for {Mobile} {Robots}},
	abstract = {Programming mobile robots can be a long, time-consuming process. Specifying the low-level mapping from sensors to actuators is prone to programmer misconceptions, and debugging such a mapping can be tedious. The idea of having a robot learn how to accomplish a task, rather than being told explicitly is an appealing one. It seems easier and much more intuitive for the programmer to specify what the robot should be doing, and to let it learn the details of how to do it. In this paper, we introduce a framework for reinforcement learning on mobile robots and describe our experiments using it to learn simple tasks.},
	publisher = {International Conference on Robotics and Automation},
	author = {Smart, William D and Kaelbling, Leslie Pack},
	year = {2002},
	keywords = {MachineLearning.bib, learning from demonstration., machine learning, Mobile robots, reinforcement learning},
}

@article{tsitsiklis_analysis_1997-1,
	title = {An {Analysis} of {Temporal}-{Difference} {Learning} with {Function} {Approximation}},
	volume = {42},
	abstract = {We discuss the temporal-difference learning algorithm, as applied to approximating cost-to-go function of an infinite-horizon discounted Markov chain. The algorithm we analyze updates parameters of a linear function approximator on-line, during a single endless trajectory of an irreducible aperiodic Markov chain with a finite or infinite state space. We present a proof of convergence (with probability 1), a characterization of the limit of convergence, and a bound on the resulting approximation error. Furthermore, our analysis is based on a new line of reasoning that provides new intuition about the dynamics of temporal-difference learning. In addition to proving new and stronger positive results than those previously available, we identify the significance of on-line updating and potential hazards associated with the use of nonlinear function approximators. First, we prove that divergence may occur when updates are not based on trajectories of the Markov chain. This fact reconciles positive and negative results that have been discussed in the literature, regarding the soundness of temporal-difference learning. Second, we present an example illustrating the possibility of divergence when temporal-difference learning is used in the presence of a nonlinear function approximator.},
	number = {5},
	journal = {IEEE Trans. Automat. Contr.},
	author = {Tsitsiklis, John and Van Roy, Ben},
	month = may,
	year = {1997},
	keywords = {MachineLearning.bib},
	pages = {674--690},
}

@inproceedings{coulom_feedforward_2002-1,
	title = {Feedforward {Neural} {Networks} in {Reinforcement} {Learning} {Applied} to {High}-dimensional {Motor} {Control}},
	abstract = {Local linear function approximators are often preferred to feedforward neural networks to estimate value functions in reinforcement learning. Still, motor tasks usually solved by this kind of methods have a low-dimensional state space. This article demonstrates that feedforward neural networks can be applied successfully to high-dimensional problems. The main difficulties of using backpropagation networks in reinforcement learning are reviewed, and a simple method to perform gradient descent efficiently is proposed. It was tested successfully on an original task of learning to swim by a complex simulated articulated robot, with 4 control variables and 12 independent state variables.},
	publisher = {ALT2002},
	author = {Coulom, Remi},
	year = {2002},
	keywords = {MachineLearning.bib},
}

@inproceedings{precup_off-policy_2001-1,
	title = {Off-policy temporal-difference learning with function approximation},
	abstract = {We introduce the first algorithm for off-policy temporal-difference learning that is stable with linear function approximation. Off-policy learning is of interest because it forms the basis for popular reinforcement learning methods such as Q-learning, which has been known to diverge with linear function approximation, and because it is critical to the practical utility of multi-scale, multi-goal, learning frameworks such as options, HAMs, and MAXQ. Our new algorithm combines TD(lambda) over state-action pairs with importance sampling ideas from our previous work. We prove that, given training under any epsilon-soft policy, the algorithm converges w.p.1 to a close approximation (as in Tsitsiklis and Van Roy, 1997; Tadic, 2001) to the action-value function for an arbitrary target policy. Variations of the algorithm designed to reduce variance introduce additional bias but are also guaranteed convergent. We also illustrate our method empirically on a small policy evaluation problem, showing reduced variance compared to the most obvious importance sampling algorithm for this problem. Our current results are limited to episodic tasks with episodes of bounded length.},
	publisher = {18th International Conference on Machine Learning},
	author = {Precup, D and Sutton, R s and Dasgupta, S},
	year = {2001},
	keywords = {MachineLearning.bib},
}

@techreport{baird_advantage_1993,
	title = {Advantage {Updating}},
	abstract = {A new algorithm for reinforcement learning, advantage updating, is proposed. Advantage updating is a direct learning technique; it does not require a model to be given or learned. It is incremental, requiring only a constant amount of calculation per time step, independent of the number of possible actions, possible outcomes from a given action, or number of states. Analysis and simulation indicate that advantage updating is applicable to reinforcement learning systems working in continuous time (or discrete time with small time steps) for which Q-learning is not applicable. Simulation results are presented indicating that for a simple linear quadratic regulator (LQR) problem with no noise and large time steps, advantage updating learns slightly faster than Q-learning. When there is noise or small time steps, advantage updating learns more quickly than Q-learning by a factor of more than 100,000. Convergence properties and implementation issues are discussed. New convergence results are presented for R-learning and algorithms based upon change in value. It is proved that the learning rule for advantage updating converges to the optimal policy with probability one.},
	institution = {Wright Laboratory, Wright-Patterson Air Force Base},
	author = {Baird, Leemon C},
	year = {1993},
	keywords = {Jun 12 import},
}

@inproceedings{baird_residual_1995-1,
	title = {Residual {Algorithms}: {Reinforcement} {Learning} with {Function} {Approximation}},
	abstract = {A number of reinforcement learning algorithms have been developed that are guaranteed to converge to the optimal solution when used with lookup tables. It is shown, however, that these algorithms can easily become unstable when implemented directly with a general function-approximation system, such as a sigmoidal multilayer perceptron, a radial-basis-function system, a memory-based learning system, or even a linear function-approximation system. A new class of algorithms, residual gradient algorithms, is proposed, which perform gradient descent on the mean squared Bellman residual, guaranteeing convergence. It is shown, however, that they may learn very slowly in some cases. A larger class of algorithms, residual algorithms, is proposed that has the guaranteed convergence of the residual gradient algorithms, yet can retain the fast learning speed of direct algorithms. In fact, both direct and residual gradient algorithms are shown to be special cases of residual algorithms, and it is shown that residual algorithms can combine the advantages of each approach. The direct, residual gradient, and residual forms of value iteration, Q-learning, and advantage learning are all presented. Theoretical analysis is given explaining the properties these algorithms have, and simulation results are given that demonstrate these properties.},
	publisher = {International Conference on Machine Learning (ICML)},
	author = {Baird, Leemon C},
	year = {1995},
	keywords = {MachineLearning.bib},
}

@techreport{baird_advantage_1993-1,
	title = {Advantage {Updating}},
	abstract = {A new algorithm for reinforcement learning, advantage updating, is proposed. Advantage updating is a direct learning technique; it does not require a model to be given or learned. It is incremental, requiring only a constant amount of calculation per time step, independent of the number of possible actions, possible outcomes from a given action, or number of states. Analysis and simulation indicate that advantage updating is applicable to reinforcement learning systems working in continuous time (or discrete time with small time steps) for which Q-learning is not applicable. Simulation results are presented indicating that for a simple linear quadratic regulator (LQR) problem with no noise and large time steps, advantage updating learns slightly faster than Q-learning. When there is noise or small time steps, advantage updating learns more quickly than Q-learning by a factor of more than 100,000. Convergence properties and implementation issues are discussed. New convergence results are presented for R-learning and algorithms based upon change in value. It is proved that the learning rule for advantage updating converges to the optimal policy with probability one.},
	institution = {Wright Laboratory, Wright-Patterson Air Force Base},
	author = {Baird, Leemon C},
	year = {1993},
	keywords = {MachineLearning.bib},
}

@inproceedings{dayan_improving_1996-1,
	title = {Improving policies without measuring metrics},
	volume = {8},
	abstract = {Performing policy iteration in dynamic programming should only require knowledge of relative rather than absolute measures of the utility of actions (Werbos, 1991) - what Baird (1993) calls the advantages of actions at states. Nevertheless, most existing methods in dynamic programming (including Baird's) compute some form of absolute utility function. For smooth problems, advantages satisfy two differential consistency conditions (including the requirement that they be free of curl), and we show that enforcing these can lead to appropriate policy improvement solely in terms of advantages.},
	publisher = {NIPS},
	author = {Dayan, Peter and Singh, Satinder P},
	year = {1996},
	keywords = {MachineLearning.bib},
}

@inproceedings{bagnell_policy_2003-1,
	title = {Policy search by dynamic programming},
	volume = {16},
	abstract = {We consider the policy search approach to reinforcement learning. We show that if a �baseline distribution� is given (indicating roughly how often we expect a good policy to visit each state), then we can derive a policy search algorithm that terminates in a finite number of steps, and for which we can provide non-trivial performance guarantees. We also demonstrate this algorithm on several grid-world POMDPs, a planar biped walking robot, and a double-pole balancing problem.},
	publisher = {NIPS},
	author = {Bagnell, J Andrew and Kakade, Sham and Ng, Andrew Y and Schneider, Jeff},
	year = {2003},
	keywords = {MachineLearning.bib},
}

@article{ng_autonomous_2003-1,
	title = {Autonomous helicopter flight via {Reinforcement} {Learning}},
	volume = {16},
	abstract = {Autonomous helicopter flight represents a challenging control problem, with complex, noisy, dynamics. In this paper, we describe a successful application of reinforcement learning to autonomous helicopter flight. We first fit a stochastic, nonlinear model of the helicopter dynamics. We then use the model to learn to hover in place, and to fly a number of maneuvers taken from an RC helicopter competition.},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Ng, Andrew Y and Kim, H Jin and Jordan, Michael I and Sastry, Shankar},
	year = {2003},
	keywords = {MachineLearning.bib},
}

@inproceedings{singh_learning_1994-1,
	title = {Learning without state estimation in partially observable environments},
	volume = {11},
	publisher = {ICML},
	author = {Singh, Satinder P and Jaakkola, Tommi and Jordan, Michael I},
	year = {1994},
	keywords = {MachineLearning.bib},
}

@inproceedings{kimura_analysis_1998-1,
	title = {An {Analysis} of {Actor}/{Critic} {Algorithms} using {Eligibility} {Traces}: {Reinforcement} {Learning} with {Imperfect} {Value} {Functions}},
	abstract = {We present an analysis of actor/critic algorithms, in which the actor updates its policy using eligibility traces of the policy parameters. Most of the theoretical results for eligibility traces have been for only critic's value iteration algorithms. This paper investigates what the actor's eligibility trace does. The results show that the algorithm is an extension of Williams' REINFORCE algorithms for infinite horizon reinforcement tasks, and then the critic provides an appropriate reinforcement baseline for the actor. Thanks to the actor's eligibility trace, the actor improves its policy by using a gradient of actual return, not by using a gradient of the estimated return in the critic. It enables the agent to learn a fairly good policy under the condition that the approximated value function in the critic is hopelessly inaccurate for conventional actor/critic algorithms. Also, if an accurate value function is estimated by the critic, the actor's learning is dramatically accelerated in our test cases. The behavior of the algorithm is demonstrated through simulations of a linear quadratic control problem and a pole balancing problem.},
	booktitle = {Proceedings of the {International} {Conference} on {Machine} {Learning} ({ICML})},
	author = {Kimura, Hajime and Kobayashi, Shigenobu},
	year = {1998},
	keywords = {MachineLearning.bib},
	pages = {278--286},
}

@article{walter_imitation_1950-1,
	title = {An {Imitation} of {Life}},
	volume = {182},
	abstract = {Concerning the author's instructive genus of mechanical tortoises. Although they possess only two sensory organs and two electronic nerve cells, they exhibit “free will”.},
	number = {5},
	journal = {Sci. Am.},
	author = {Walter, W Grey},
	month = may,
	year = {1950},
	keywords = {MachineLearning.bib},
	pages = {42--45},
}

@article{walter_machine_1951-1,
	title = {A {Machine} {That} {Learns}},
	volume = {185},
	abstract = {Concerning Machina docilis, descendant of Machina speculatrix, the small imitation of life that was described in the May, 1950, issue of this magazine.},
	number = {2},
	journal = {Sci. Am.},
	author = {Walter, W Grey},
	month = aug,
	year = {1951},
	keywords = {MachineLearning.bib},
	pages = {60--63},
}

@inproceedings{vaughan_evolution_2004-1,
	title = {The evolution of control and adaptation in a {3D} powered passive dynamic walker},
	booktitle = {Proceedings of the {International} {Conference} on the {Simulation} and {Synthesis} of {Living} {Systems} ({ALIFE})},
	publisher = {MIT Press},
	author = {Vaughan, E and Di Paolo, E A and Harvey, I},
	year = {2004},
	keywords = {MachineLearning.bib},
}

@article{barto_recent_2003-1,
	title = {Recent {Advances} in {Hiearchical} {Reinforcement} {Learning}},
	volume = {13},
	abstract = {Reinforcement learning is bedeviled by the curse of dimensionality: the number of parameters to be learned grows exponentially with the size of any compact encoding of a state. Recent attempts to combat the curse of dimensionality have turned to principled ways of exploiting temporal abstraction, where decisions are not required at each step, but rather invoke the execution of temporally-extended activities which follow their own policies until termination. This leads naturally to hierarchical control architectures and associated learning algorithms. We review several approaches to temporal abstraction and hierarchical organization that machine learning researchers have recently developed. Common to these approaches is a reliance on the theory of semi-Markov decision processes, which we emphasize in our review. We then discuss extensions of these ideas to concurrent activities, multiagent coordination, and hierarchical memory for addressing partial observability. Concluding remarks address open challenges facing the further development of reinforcement learning in a hierarchical setting.},
	journal = {Discrete Event Systems Journal},
	author = {Barto, Andrew G and Mahadevan, Sridhar},
	year = {2003},
	keywords = {MachineLearning.bib},
	pages = {41--77},
}

@inproceedings{lecun_gemini_1989-1,
	title = {{GEMINI}: {Gradient} estimation through matrix inversion after noise injection},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 1 ({NIPS} '88)},
	author = {LeCun, Yann and Galland, Conrad C and Hinton, Geoffrey E},
	editor = {Touretzky, David},
	year = {1989},
	keywords = {MachineLearning.bib},
	pages = {141--149},
}

@article{barto_pattern-recognizing_1985-1,
	title = {Pattern-{Recognizing} {Stochastic} {Learning} {Automata}},
	volume = {15},
	abstract = {A class of learning tasks is described that combines aspects of learning automaton tasks and supervised learning pattern-classification tasks. We call these tasks associative reinforcement learning tasks. An algorithm is presented, called the 'associative reward-penalty,' or A(subscript: R-P), algorithm, for which a form of optimal performance is proved. This algorithm simultaneously generalizes a class of stochastic learning automata and a class of supervised learning pattern-classification methods relating to the Robbins-Monro stochastic approximation procedure. The relevance of this hybrid algorithm is discussed with respect to the collective behavior of learning automata and the behavior of networks of pattern-classifying adaptive elements. Simulation results are presented that illustrate the associative reinforcement learning task and the performance of the A(subscript: R-P) algorithm as compared with that of several existing algorithms.},
	number = {3},
	journal = {IEEE Trans. Syst. Man Cybern.},
	author = {Barto, A G and Anandan, P},
	year = {1985},
	keywords = {MachineLearning.bib},
	pages = {360--375},
}

@inproceedings{barto_gradient_1987-1,
	title = {Gradient following without back-propagation in layered networks},
	volume = {2},
	abstract = {We describe a method for solving nonlinear supervised learning tasks by multilayer feed-forward networks. It estimates the performance gradient without back-propagating error information by using the 'Associative Reward-Penalty,' or A(subscript: R-P), algorithm that has been the subject of previous papers [2,3,4,5]. We introduce a variant of the A(subscript: R-P) algorithm, called the S-model A(subscript: R-P), for learning with real-valued reinforcement, and we introduce a method, called “batching”, for increasing the learning efficiency of A(subscript: R-P) networks. We describe simulation experiments using the task of learning symmetry axes to compare the variants of the A(subscript: R-P) network method as well as the back-propagation method of Rumelhart, Hinton, and Williams [11].},
	booktitle = {{IEEE} {First} {International} {Conference} on {Neural} {Networks}},
	publisher = {IEEE},
	author = {Barto, Andrew G and Jordan, Michael I},
	editor = {Caudill, M and Butler, C},
	year = {1987},
	note = {Backup Publisher: IEEE},
	keywords = {MachineLearning.bib},
	pages = {629--636},
}

@book{buzsaki_brain_2019,
	title = {The {Brain} from {Inside} {Out}},
	abstract = {Is there a right way to study how the brain works? Following the empiricist's tradition, the most common approach involves the study of neural reactions to stimuli presented by an experimenter. This 'outside-in' method fueled a generation of brain research and now must confront hidden assumptions about causation and concepts that may not hold neatly for systems that act and react. György Buzsáki's The Brain from Inside Out examines why the outside-in framework for understanding brain function has become stagnant and points to new directions for understanding neural function. Building upon the success of 2011's Rhythms of the Brain, Professor Buzsáki presents the brain as a foretelling device that interacts with its environment through action and the examination of action's consequence. Consider that our brains are initially filled with nonsense patterns, all of which are gibberish until grounded by action-based interactions. By matching these nonsense “words” to the outcomes of action, they acquire meaning. Once its circuits are “calibrated” by action and experience, the brain can disengage from its sensors and actuators, and examine “what happens if” scenarios by peeking into its own computation, a process that we refer to as cognition. The Brain from Inside Out explains why our brain is not an information-absorbing coding device, as it is often portrayed, but a venture-seeking explorer constantly controlling the body to test hypotheses. Our brain does not process information: it creates it.},
	language = {en},
	publisher = {Oxford University Press},
	author = {Buzsáki, György},
	month = apr,
	year = {2019},
}

@article{aviel_synfire_2002,
	title = {Synfire chain in a balanced network},
	volume = {44-46},
	abstract = {We investigate the formation of ordered spatiotemporal activations of pools of neurons in synfire chains (SFC) within a balanced network, both by simulations and by analytic tools. Using a suitable matrix of synaptic connections, we show that the results depend on the ratio between the size of an individual pool of neurons (w) and the total excitatory input of a neuron (K). In our simulations of 10,000 neurons, we obtain an asynchronous-irregular firing mode, which does not sustain a traveling pulse-packet of SFC activity. Our analysis shows that the latter may be expected to exist in larger networks in which very small w/K values can be realized.},
	journal = {Neurocomputing},
	author = {Aviel, Y and Pavlov, E and Abeles, M and Horn, D},
	month = jun,
	year = {2002},
	keywords = {Asynchronous irregular state, Balanced network, Common input, Integrate-and-fire neuron, Synfire chain},
	pages = {285--292},
}

@article{abeles_synfire_2009,
	title = {Synfire chains},
	volume = {4},
	number = {7},
	journal = {Scholarpedia J.},
	author = {Abeles, Moshe},
	year = {2009},
	note = {Publisher: Scholarpedia},
	pages = {1441},
}

@misc{marc_synfire_2008,
	title = {Synfire activity without synfire anatomy: {Impact} of nonlinear dendritic summation on the dynamics of recurrent neural circuits},
	author = {Marc, Timme},
	year = {2008},
	note = {Publication Title: Frontiers in Computational Neuroscience
Volume: 2},
}

@article{macvicar_electrotonic_1982,
	title = {Electrotonic coupling between granule cells of rat dentate gyrus: physiological and anatomical evidence},
	volume = {47},
	language = {en},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {MacVicar, B A and Dudek, F E},
	month = apr,
	year = {1982},
	pages = {579--592},
}

@misc{ribak_ultrastructure_2007,
	title = {Ultrastructure and synaptic connectivity of cell types in the adult rat dentate gyrus},
	author = {Ribak, Charles E and Shapiro, Lee A},
	year = {2007},
	note = {Pages: 155–166
Publication Title: The Dentate Gyrus: A Comprehensive Guide to Structure, Function, and Clinical Implications},
}

@article{li_hippocampal_1994,
	title = {The hippocampal {CA3} network: an in vivo intracellular labeling study},
	volume = {339},
	abstract = {The intrahippocampal distribution of axon collaterals of individual CA3 pyramidal cells was investigated in the rat. Pyramidal cells in the CA3 region of the hippocampus were physiologically characterized and filled with biocytin in anesthetized animals. Their axonal trees were reconstructed with the aid of a drawing tube. Single CA3 pyramidal cells arborized most extensively in the CA1 region, covering approximately two-thirds of the longitudinal axis of the hippocampus. The total length of axon collaterals in the CA3 region was less than in CA1 and the axon branches tended to cluster in narrow bands (200-800 microns), usually several hundred microns anterior or posterior to the cell body. The majority of the recurrent collaterals of a given neuron remained in the same subfield (CA3a, b, or c) as the parent cell. CA3a neurons innervated predominantly the basal dendrites, whereas neurons located proximal to the hilus (CA3c) terminated predominantly on the apical dendrites of both CA1 and CA3 cells. Two cells, with horizontal dendrites and numerous thorny excrescences at the CA3c-hilus transitional zone, were also labeled and projected to both CA3 and CA1 regions. All CA3 neurons projected some collaterals to the hilar region. Proximal (CA3c) neurons had numerous collaterals in the hilus proper. One CA3c pyramidal cell in the dorsal hippocampus sent an axon collaterals to the inner third of the molecular layer. CA3c pyramidal cells in the ventral hippocampus had extensive projections to the inner third of the dentate molecular layer, as well as numerous collaterals in the hilus, CA3, and CA1 areas, and several axon collaterals penetrated the subiculum. The total projected axon length of a single neuron ranged from 150 to 300 mm. On the basis of the projected axon length and bouton density (mean interbouton distance: 4.7 microns), we estimate that a single CA3 pyramidal cell can make synapses with 30,000-60,000 neurons in the ipsilateral hippocampus. The concentrated distribution of the axon collaterals (“patches”) indicates that subpopulations of neurons may receive disproportionately denser innervation, whereas innervation in the rest of the target zones is rather sparse. These observations offer new insights into the physiological organization of the CA3 pyramidal cell network.},
	language = {en},
	number = {2},
	journal = {J. Comp. Neurol.},
	author = {Li, X G and Somogyi, P and Ylinen, A and Buzsáki, G},
	month = jan,
	year = {1994},
	pages = {181--208},
}

@article{solodkin_entorhinal_2014,
	title = {Entorhinal cortex},
	author = {Solodkin, A and Van Hoesen, G W and Insausti, R},
	year = {2014},
	note = {Publisher: Elsevier},
}

@misc{zeisel_cell_2015,
	title = {Cell types in the mouse cortex and hippocampus revealed by single-cell {RNA}-seq},
	author = {Zeisel, Amit and Muñoz-Manchado, Ana B and Codeluppi, Simone and Lönnerberg, Peter and La Manno, Gioele and Juréus, Anna and Marques, Sueli and Munguba, Hermany and He, Liqun and Betsholtz, Christer and Rolny, Charlotte and Castelo-Branco, Gonçalo and Hjerling-Leffler, Jens and Linnarsson, Sten},
	year = {2015},
	note = {Issue: 6226
Pages: 1138–1142
Publication Title: Science
Volume: 347},
}

@article{alkadhi_cellular_2019,
	title = {Cellular and {Molecular} {Differences} {Between} {Area} {CA1} and the {Dentate} {Gyrus} of the {Hippocampus}},
	volume = {56},
	abstract = {A distinct feature of the hippocampus of the brain is its unidirectional tri-synaptic pathway originating from the entorhinal cortex and projecting to the dentate gyrus (DG) then to area CA3 and subsequently, area CA1 of the Ammon's horn. Each of these areas of the hippocampus has its own cellular structure and distinctive function. The principal neurons in these areas are granule cells in the DG and pyramidal cells in the Ammon's horn's CA1 and CA3 areas with a vast network of interneurons. This review discusses the fundamental differences between the CA1 and DG areas regarding cell morphology, synaptic plasticity, signaling molecules, ability for neurogenesis, vulnerability to various insults and pathologies, and response to pharmacological agents.},
	language = {en},
	number = {9},
	journal = {Mol. Neurobiol.},
	author = {Alkadhi, Karim A},
	month = sep,
	year = {2019},
	keywords = {Alzheimer' disease, Calbindin, Chronic stress, Functional plasticity, Granule cell, Hypothyroidism, Ischemia, Obesity, OZR, Pyramidal cell, Signaling molecules, Structural plasticity},
	pages = {6566--6580},
}

@article{lu_transforming_2022,
	title = {Transforming representations of movement from body- to world-centric space},
	volume = {601},
	abstract = {When an animal moves through the world, its brain receives a stream of information about the body's translational velocity from motor commands and sensory feedback signals. These incoming signals are referenced to the body, but ultimately, they must be transformed into world-centric coordinates for navigation1,2. Here we show that this computation occurs in the fan-shaped body in the brain of Drosophila melanogaster. We identify two cell types, PFNd and PFNv3-5, that conjunctively encode translational velocity and heading as a fly walks. In these cells, velocity signals are acquired from locomotor brain regions6 and are multiplied with heading signals from the compass system. PFNd neurons prefer forward-ipsilateral movement, whereas PFNv neurons prefer backward-contralateral movement, and perturbing PFNd neurons disrupts idiothetic path integration in walking flies7. Downstream, PFNd and PFNv neurons converge onto hΔB neurons, with a connectivity pattern that pools together heading and translation direction combinations corresponding to the same movement in world-centric space. This network motif effectively performs a rotation of the brain's representation of body-centric translational velocity according to the current heading direction. Consistent with our predictions, we observe that hΔB neurons form a representation of translational velocity in world-centric coordinates. By integrating this representation over time, it should be possible for the brain to form a working memory of the path travelled through the environment8-10.},
	language = {en},
	number = {7891},
	journal = {Nature},
	author = {Lu, Jenny and Behbahani, Amir H and Hamburg, Lydia and Westeinde, Elena A and Dawson, Paul M and Lyu, Cheng and Maimon, Gaby and Dickinson, Michael H and Druckmann, Shaul and Wilson, Rachel I},
	month = jan,
	year = {2022},
	pages = {98--104},
}

@misc{amari_mathematical_nodate,
	title = {Mathematical theories of neural networks},
	author = {Amari, Shun-Ichi},
	note = {Publication Title: Handbook of Neural Computation},
}

@article{turner_reconstruction_2022,
	title = {Reconstruction of neocortex: {Organelles}, compartments, cells, circuits, and activity},
	volume = {185},
	abstract = {We assembled a semi-automated reconstruction of L2/3 mouse primary visual cortex from ∼250 {\textbackslash}times 140 {\textbackslash}times 90 μm3 of electron microscopic images, including pyramidal and non-pyramidal neurons, astrocytes, microglia, oligodendrocytes and precursors, pericytes, vasculature, nuclei, mitochondria, and synapses. Visual responses of a subset of pyramidal cells are included. The data are publicly available, along with tools for programmatic and three-dimensional interactive access. Brief vignettes illustrate the breadth of potential applications relating structure to function in cortical circuits and neuronal cell biology. Mitochondria and synapse organization are characterized as a function of path length from the soma. Pyramidal connectivity motif frequencies are predicted accurately using a configuration model of random graphs. Pyramidal cells receiving more connections from nearby cells exhibit stronger and more reliable visual responses. Sample code shows data access and analysis.},
	language = {en},
	number = {6},
	journal = {Cell},
	author = {Turner, Nicholas L and Macrina, Thomas and Bae, J Alexander and Yang, Runzhe and Wilson, Alyssa M and Schneider-Mizell, Casey and Lee, Kisuk and Lu, Ran and Wu, Jingpeng and Bodor, Agnes L and Bleckert, Adam A and Brittain, Derrick and Froudarakis, Emmanouil and Dorkenwald, Sven and Collman, Forrest and Kemnitz, Nico and Ih, Dodam and Silversmith, William M and Zung, Jonathan and Zlateski, Aleksandar and Tartavull, Ignacio and Yu, Szi-Chieh and Popovych, Sergiy and Mu, Shang and Wong, William and Jordan, Chris S and Castro, Manuel and Buchanan, Joann and Bumbarger, Daniel J and Takeno, Marc and Torres, Russel and Mahalingam, Gayathri and Elabbady, Leila and Li, Yang and Cobos, Erick and Zhou, Pengcheng and Suckow, Shelby and Becker, Lynne and Paninski, Liam and Polleux, Franck and Reimer, Jacob and Tolias, Andreas S and Reid, R Clay and da Costa, Nuno Maçarico and Seung, H Sebastian},
	month = mar,
	year = {2022},
	keywords = {calcium imaging, mouse, cortex, pyramidal cell, 3D reconstruction, electron microscopy, inhibitory cell, mitochondria, synaptic connectivity, visual cortex},
	pages = {1082--1100.e24},
}

@inproceedings{boopathy_how_2022,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {How to {Train} {Your} {Wide} {Neural} {Network} {Without} {Backprop}: {An} {Input}-{Weight} {Alignment} {Perspective}},
	volume = {162},
	abstract = {Recent works have examined theoretical and empirical properties of wide neural networks trained in the Neural Tangent Kernel (NTK) regime. Given that biological neural networks are much wider than their artificial counterparts, we consider NTK regime wide neural networks as a possible model of biological neural networks. Leveraging NTK theory, we show theoretically that gradient descent drives layerwise weight updates that are aligned with their input activity correlations weighted by error, and demonstrate empirically that the result also holds in finite-width wide networks. The alignment result allows us to formulate a family of biologically-motivated, backpropagation-free learning rules that are theoretically equivalent to backpropagation in infinite-width networks. We test these learning rules on benchmark problems in feedforward and recurrent neural networks and demonstrate, in wide networks, comparable performance to backpropagation. The proposed rules are particularly effective in low data regimes, which are common in biological learning settings.},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Boopathy, Akhilan and Fiete, Ila},
	editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
	year = {2022},
	pages = {2178--2205},
}

@article{malpeli_representation_1975,
	title = {The representation of the visual field in the lateral geniculate nucleus of {Macaca} mulatta},
	volume = {161},
	abstract = {Microelectrode recording techniques were used to investigate the projection of the visual field into the lateral geniculate nucleus (LGN) of Macaca mulatta. The data were used to construct charts plotting visual direction, designated in terms of azimuth and elevation, onto sections of the nucleus cut in coronal, sagittal and horizontal Horsley-Clarke planes. The projection of the horizontal meridian divides the LGN along its plane of symmetry into a medial-superior half having negative elevations and a lateral-inferior half having positive elevations. Elevations become more positive or negative with distance from this plane. Azimuths closest to the vertical meridian are located posteriorly, while the most peripheral azimuths are found at the anterior pole. Two families of surfaces representing visual directions of constant azimuth and elevation are described. Visual field zones of increasing eccentricity are represented serially along the posterior-anterior axis of the LGN, with the foveal area restricted to the posterior pole and the monocular crescent projecting to the anterior pole. The mapping is completely continuous across the horizontal meridian. The edges of the stacked cell laminae exposed around the periphery of the LGN form an oval band which receives the projection of the perimeter of the contralateral hemifield. The vertical meridian is represented by the posterior two-thirds of this band, while the periphery of the hemifield projects to the anterior third. The central visual field out to the optic disc is represented by six cell layers, while the rest of the binocular field projects to four layers only (2 parvocellular and 2 magnocellular). The monocular crescent is represented by one parvocellular and one magnocellular layer. Features associated with the projection column of the optic disc are integrated into the transition from six to four layers. Details of the receptive field topography in the vicinity of the optic disc discontinuities indicate that these gaps are produced by intralaminar mechanisms. The magnification factor (mm-3/steradian) increased monotonically from peripheral visual fields to the foveal center, varying over a range of three decades. This range is intermediate between those derived from data reported in the literature for the retina and the striate cortex. The ratio of LGN magnifications at any two angular eccentricities is a power function, with an exponent of 1.34, of the corresponding ratio of retinal ganglion cell densities. Similarly, the ratio of cortical magnifications (mm-2/steradian) at any two eccentricites is a power function, with an exponent of 1.35, of the corresponding ratio of LGN magnifications.},
	language = {en},
	number = {4},
	journal = {J. Comp. Neurol.},
	author = {Malpeli, J G and Baker, F H},
	month = jun,
	year = {1975},
	pages = {569--594},
}

@article{fiete_learning_2004,
	title = {Learning and coding in biological neural networks},
	abstract = {How can large groups of neurons that locally modify their activities learn to collectively perform a desired task? Do studies of learning in small networks tell us anything about …},
	author = {Fiete, I R},
	year = {2004},
	note = {Publisher: search.proquest.com},
}

@article{sreenivasan_grid_2011-1,
	title = {Grid cells generate an analog error-correcting code for singularly precise neural computation},
	volume = {14},
	abstract = {Entorhinal grid cells in mammals fire as a function of animal location, with spatially periodic response patterns. This nonlocal periodic representation of location, a local variable, is unlike other neural codes. There is no theoretical explanation for why such a code should exist. We examined how accurately the grid code with noisy neurons allows an ideal observer to estimate location and found this code to be a previously unknown type of population code with unprecedented robustness to noise. In particular, the representational accuracy attained by grid cells over the coding range was in a qualitatively different class from what is possible with observed sensory and motor population codes. We found that a simple neural network can effectively correct the grid code. To the best of our knowledge, these results are the first demonstration that the brain contains, and may exploit, powerful error-correcting codes for analog variables.},
	language = {en},
	number = {10},
	journal = {Nat. Neurosci.},
	author = {Sreenivasan, Sameet and Fiete, Ila},
	month = sep,
	year = {2011},
	pages = {1330--1337},
}

@article{benna_computational_2016,
	title = {Computational principles of synaptic memory consolidation},
	volume = {19},
	abstract = {Memories are stored and retained through complex, coupled processes operating on multiple timescales. To understand the computational principles behind these intricate networks of interactions, we construct a broad class of synaptic models that efficiently harness biological complexity to preserve numerous memories by protecting them against the adverse effects of overwriting. The memory capacity scales almost linearly with the number of synapses, which is a substantial improvement over the square root scaling of previous models. This was achieved by combining multiple dynamical processes that initially store memories in fast variables and then progressively transfer them to slower variables. Notably, the interactions between fast and slow variables are bidirectional. The proposed models are robust to parameter perturbations and can explain several properties of biological memory, including delayed expression of synaptic modifications, metaplasticity, and spacing effects.},
	language = {en},
	number = {12},
	journal = {Nat. Neurosci.},
	author = {Benna, Marcus K and Fusi, Stefano},
	month = dec,
	year = {2016},
	pages = {1697--1706},
}

@article{chaudhuri_intrinsic_2019-1,
	title = {The intrinsic attractor manifold and population dynamics of a canonical cognitive circuit across waking and sleep},
	volume = {22},
	abstract = {Neural circuits construct distributed representations of key variables-external stimuli or internal constructs of quantities relevant for survival, such as an estimate of one's location in the world-as vectors of population activity. Although population activity vectors may have thousands of entries (dimensions), we consider that they trace out a low-dimensional manifold whose dimension and topology match the represented variable. This manifold perspective enables blind discovery and decoding of the represented variable using only neural population activity (without knowledge of the input, output, behavior or topography). We characterize and directly visualize manifold structure in the mammalian head direction circuit, revealing that the states form a topologically nontrivial one-dimensional ring. The ring exhibits isometry and is invariant across waking and rapid eye movement sleep. This result directly demonstrates that there are continuous attractor dynamics and enables powerful inference about mechanism. Finally, external rather than internal noise limits memory fidelity, and the manifold approach reveals new dynamical trajectories during sleep.},
	language = {en},
	number = {9},
	journal = {Nat. Neurosci.},
	author = {Chaudhuri, Rishidev and Gerçek, Berk and Pandey, Biraj and Peyrache, Adrien and Fiete, Ila},
	month = sep,
	year = {2019},
	pages = {1512--1520},
}

@article{fiete_neural_2007,
	title = {Neural network models of birdsong production, learning, and coding},
	abstract = {Birdsong involves motor sequence generation and goal-directed sensorimotor learning, and is controlled by a discrete set of premotor brain nuclei. These features make it an ideal …},
	author = {Fiete, I R and Seung, H S},
	year = {2007},
	note = {Publisher: academia.edu},
}

@article{kanitscheider_making_2017,
	title = {Making our way through the world: {Towards} a functional understanding of the brain's spatial circuits},
	abstract = {Many animals make return trips from a home base to gather food and supplies, mate, or survive the seasons. In a world of unreliable and ambiguous cues, localizing within familiar …},
	journal = {Current Opinion in Systems Biology},
	author = {Kanitscheider, I and Fiete, I},
	year = {2017},
	note = {Publisher: Elsevier},
}

@article{padilla-coreano_cortical_2022,
	title = {Cortical ensembles orchestrate social competition through hypothalamic outputs},
	volume = {603},
	abstract = {Most social species self-organize into dominance hierarchies1,2, which decreases aggression and conserves energy3,4, but it is not clear how individuals know their social rank. We have only begun to learn how the brain represents social rank5-9 and guides behaviour on the basis of this representation. The medial prefrontal cortex (mPFC) is involved in social dominance in rodents7,8 and humans10,11. Yet, precisely how the mPFC encodes relative social rank and which circuits mediate this computation is not known. We developed a social competition assay in which mice compete for rewards, as well as a computer vision tool (AlphaTracker) to track multiple, unmarked animals. A hidden Markov model combined with generalized linear models was able to decode social competition behaviour from mPFC ensemble activity. Population dynamics in the mPFC predicted social rank and competitive success. Finally, we demonstrate that mPFC cells that project to the lateral hypothalamus promote dominance behaviour during reward competition. Thus, we reveal a cortico-hypothalamic circuit by which the mPFC exerts top-down modulation of social dominance.},
	language = {en},
	number = {7902},
	journal = {Nature},
	author = {Padilla-Coreano, Nancy and Batra, Kanha and Patarino, Makenzie and Chen, Zexin and Rock, Rachel R and Zhang, Ruihan and Hausmann, Sébastien B and Weddington, Javier C and Patel, Reesha and Zhang, Yu E and Fang, Hao-Shu and Mishra, Srishti and LeDuke, Deryn O and Revanna, Jasmin and Li, Hao and Borio, Matilde and Pamintuan, Rachelle and Bal, Aneesh and Keyes, Laurel R and Libster, Avraham and Wichmann, Romy and Mills, Fergil and Taschbach, Felix H and Matthews, Gillian A and Curley, James P and Fiete, Ila R and Lu, Cewu and Tye, Kay M},
	month = mar,
	year = {2022},
	pages = {667--671},
}

@article{clayton_learning_2019,
	title = {Learning birdsong by imitation},
	volume = {366},
	language = {en},
	number = {6461},
	journal = {Science},
	author = {Clayton, David F},
	month = oct,
	year = {2019},
	pages = {33--34},
}

@article{yoo_dynamic_2012-1,
	title = {Dynamic shift-map coding with side information at the decoder},
	abstract = {Shift-map codes have been studied as joint source-channel codes for continuous sources. These codes are useful in delay-limited scenarios and also provide better tolerance to …},
	journal = {2012 50th Annual},
	author = {Yoo, Y and Koyluoglu, O O and Vishwanath, S and {others}},
	year = {2012},
	note = {Publisher: ieeexplore.ieee.org},
}

@article{khona_smooth_2022,
	title = {From smooth cortical gradients to discrete modules: spontaneous and topologically robust emergence of modularity in grid cells},
	abstract = {The grid cell system is a paradigmatic example of the computational advantages of modular representations. Modular responses emerge early in juvenile animals along a strip of cortex …},
	journal = {bioRxiv},
	author = {Khona, M and Chandra, S and Fiete, I R},
	year = {2022},
	note = {Publisher: biorxiv.org},
}

@article{padilla-coreano_cortical-hypothalamic_2020,
	title = {A cortical-hypothalamic circuit decodes social rank and promotes dominance behavior},
	author = {Padilla-Coreano, Nancy and Batra, Kanha and Patarino, Makenzie and Chen, Zexin and Rock, Rachel and Zhang, Ruihan and Hausmann, Sebastien and Weddington, Javier and Patel, Reesha and Zhang, Yu and {Others}},
	year = {2020},
	note = {Publisher: Research Square},
}

@inproceedings{li_neurotensin_2020,
	title = {Neurotensin {Gates} {Valence}-{Specific} {Plasticity} {Underlying} {Associative} {Learning}},
	volume = {45},
	booktitle = {{NEUROPSYCHOPHARMACOLOGY}},
	publisher = {SPRINGERNATURE CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND},
	author = {Li, Hao and Namburi, Praneeth and Olson, Jacob and Borio, Matilde and Lemieux, Mackenzie and Beyeler, Anna and Calhoon, Gwendolyn and Libster, Avi and Jin, Xin and Choudhury, Sourav and {Others}},
	year = {2020},
	pages = {233--234},
}

@article{schartner_motor_2021,
	title = {Motor correlates of cognitive variables in the international brain laboratory task},
	abstract = {In the IBL task, a head-fixed mouse is trained to move a wheel to the left or right, depending on the side of a Gabor patch shown on a screen in front of the animal. The probability of a …},
	journal = {50th Annual Meeting},
	author = {Schartner, M and Langdon, C and Miska, J and {others}},
	year = {2021},
	note = {Publisher: pure.mpg.de},
}

@article{gjorgjieva_editorial_2021,
	title = {Editorial overview: {Theoretical} and computational approaches to decipher brain function from molecules to behavior},
	volume = {70},
	language = {en},
	journal = {Curr. Opin. Neurobiol.},
	author = {Gjorgjieva, Julijana and Fiete, Ila},
	month = oct,
	year = {2021},
	pages = {iii--vii},
}

@inproceedings{li_neuropeptidergic_2021,
	title = {A {Neuropeptidergic} {Mechanism} for {Governing} {Valence} {Assignment}},
	volume = {46},
	booktitle = {{NEUROPSYCHOPHARMACOLOGY}},
	publisher = {SPRINGERNATURE CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND},
	author = {Li, Hao and Namburi, Praneeth and Olson, Jacob and Borio, Matilde and Lemieux, Mackenzie and Beyeler, Anna and Calhoon, Gwendolyn and Hitora-Imamura, Natsuko and Coley, Austin and Libster, Avraham and {Others}},
	year = {2021},
	pages = {212--212},
}

@book{hiesinger_self-assembling_2021,
	title = {The {Self}-{Assembling} {Brain}},
	abstract = {What neurobiology and artificial intelligence tell us about how the brain builds itself How does a neural network become a brain? While neurobiologists investigate how nature accomplishes this feat, computer scientists interested in artificial intelligence strive to achieve this through technology. The Self-Assembling Brain tells the stories of both fields, exploring the historical and modern approaches taken by the scientists pursuing answers to the quandary: What information is necessary to make an intelligent neural network? As Peter Robin Hiesinger argues, “the information problem” underlies both fields, motivating the questions driving forward the frontiers of research. How does genetic information unfold during the years-long process of human brain development—and is there a quicker path to creating human-level artificial intelligence? Is the biological brain just messy hardware, which scientists can improve upon by running learning algorithms on computers? Can AI bypass the evolutionary programming of “grown” networks? Through a series of fictional discussions between researchers across disciplines, complemented by in-depth seminars, Hiesinger explores these tightly linked questions, highlighting the challenges facing scientists, their different disciplinary perspectives and approaches, as well as the common ground shared by those interested in the development of biological brains and AI systems. In the end, Hiesinger contends that the information content of biological and artificial neural networks must unfold in an algorithmic process requiring time and energy. There is no genome and no blueprint that depicts the final product. The self-assembling brain knows no shortcuts. Written for readers interested in advances in neuroscience and artificial intelligence, The Self-Assembling Brain looks at how neural networks grow smarter.},
	language = {en},
	publisher = {Princeton University Press},
	author = {Hiesinger, Peter Robin},
	month = jun,
	year = {2021},
	keywords = {deep learning, memory, self-organization, evolution, connectome, complexity, behavior, information theory, brain development, machine learning, algorithm, algorithmic growth, artificial life, artificial neural network, axon guidance, brain wiring, cellular automaton, cognitive bias, computer intelligence, cybernetics, filopodia, Gary Macus, gene, guidance cue, How to Create a Mind, neural circuit, neurogenetics, Peter Sterling, Principles of Neural Design, Ray Kurzweil, Roger Sperry, Seymour Benzer, Simon Laughlin, Sydney Brenner, synapse, The Birth of the Mind},
}

@inproceedings{a_boopathy_model-agnostic_2022,
	title = {Model-agnostic {Measure} of {Generalization} {Difficulty}},
	booktitle = {In review},
	author = {A. Boopathy, I R Fiete},
	year = {2022},
}

@article{s_neupane_ir_fiete_m_jazayeri_interval_2022,
	title = {Interval timing as mental navigation through a structured space},
	journal = {In preparation},
	author = {{S. Neupane, I.R. Fiete, M. Jazayeri}},
	year = {2022},
}

@book{cicero_oratore_1862,
	title = {De oratore},
	language = {la},
	publisher = {B.G. Teubner},
	author = {Cicero, Marcus Tullius},
	year = {1862},
}

@article{tolman_cognitive_1948,
	title = {Cognitive maps in rats and men},
	volume = {55},
	language = {en},
	number = {4},
	journal = {Psychol. Rev.},
	author = {Tolman, E C},
	month = jul,
	year = {1948},
	keywords = {CONDITIONING THERAPY},
	pages = {189--208},
}

@article{tolman_purpose_1925,
	title = {Purpose and cognition: the determiners of animal learning},
	volume = {32},
	abstract = {Such terms as “goal-seeking (purpose),” “initial exploratory impulses (initial cognitive 'hunches'),” and “final object-adjustments (final cognitions)” may be used advantageously in the study of animal behavior. These terms are more fruitful in the study of animal learning than the purely physiological categories—at least in the present state of psychology. These terms are said to be “behavioristic” and by this is meant that the purposes, cognitions, “hunches,” etc., of a rat, for example, can be stated objectively in terms of the maze or other conditions and in terms of the rat's behavior. The thesis is illustrated by experiments with the white rat and especially by work done at the University of California. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {4},
	journal = {Psychol. Rev.},
	author = {Tolman, E C},
	month = jul,
	year = {1925},
	pages = {285--297},
}

@article{noauthor_akhilan_nodate,
	title = {‪{Akhilan} {Boopathy}‬ - ‪{Google} {Scholar}‬},
	journal = {https://scholar.google.se › citationshttps://scholar.google.se › citations},
}

@article{gobet_chunking_2001,
	title = {Chunking mechanisms in human learning},
	volume = {5},
	abstract = {Pioneering work in the 1940s and 1950s suggested that the concept of 'chunking' might be important in many processes of perception, learning and cognition in humans and animals. We summarize here the major sources of evidence for chunking mechanisms, and consider how such mechanisms have been implemented in computational models of the learning process. We distinguish two forms of chunking: the first deliberate, under strategic control, and goal-oriented; the second automatic, continuous, and linked to perceptual processes. Recent work with discrimination-network computational models of long- and short-term memory (EPAM/CHREST) has produced a diverse range of applications of perceptual chunking. We focus on recent successes in verbal learning, expert memory, language acquisition and learning multiple representations, to illustrate the implementation and use of chunking mechanisms within contemporary models of human learning.},
	language = {en},
	number = {6},
	journal = {Trends Cogn. Sci.},
	author = {Gobet, F and Lane, P C R and Croker, S and Cheng, P C-H and Jones, G and Oliver, I and Pine, J M},
	month = jun,
	year = {2001},
	pages = {236--243},
}

@article{simon_how_1974,
	title = {How {Big} {Is} a {Chunk}?: {By} combining data from several experiments, a basic human memory unit can be identified and measured},
	volume = {183},
	abstract = {I have explored some of the interactions between research on higher mental processes over the past decade or two and laboratory experiments on simpler cognitive processes. I have shown that, by viewing experimentation in a parameter-estimating paradigm instead of a hypothesis-testing paradigm, one can obtain much more information from experiments-information that, combined with contemporary theoretical models of the cognitive processes, has implications for human performance on tasks quite different from those of the original experiments. The work of identifying and measuring the basic parameters of the human information processing system has just begun, but already important information has been gained. The psychological reality of the chunk has been fairly well demonstrated, and the chunk capacity of short-term memory has been shown to be in the range of five to seven. Fixation of information in longterm memory has been shown to take about 5 or 10 seconds per chunk. Some other “magical numbers” have been estimated-for example, visual scanning speeds and times required for simple grammatical transformations-and no doubt others remain to be discovered. But even the two basic constants discussed in this article-short-term memory capacity and rate of fixation in long-term memory-organize, systematize, and explain a wide range of findings, about both simple tasks and more complex cognitive performances that have been reported in the psychological literature over the past 50 years or more.},
	language = {en},
	number = {4124},
	journal = {Science},
	author = {Simon, H A},
	month = feb,
	year = {1974},
	pages = {482--488},
}

@book{scherreik_online_2020,
	title = {Online {Clustering} with {Bayesian} {Nonparametrics}},
	abstract = {Clustering algorithms, such as Gaussian mixture models and K-means, often require the number of clusters to be specified a priori. Bayesian nonparametric (BNP) methods avoid this problem by specifying a prior distribution over the cluster assignments that allows the number of clusters to be inferred from the data. This can be especially useful for online clustering tasks, where data arrives in a continuous stream and the number of clusters may dynamically change over time. Classical BNP priors often overestimate the number of clusters, however, leading researchers to develop new priors with more control over this tendency. To date, BNP algorithms resistant to over-clustering have only been implemented for offline processing, utilizing Markov chain Monte Carlo inference. In this dissertation, we derive a novel algorithm for online BNP clustering using variational inference, with explicit control over the over-clustering phenomenon. Additionally, we propose two methods for tuning a critical hyperparameter mid-stream, based on empirical analysis of the BNP cluster assignment prior and a cost function from Gaussian mixture reduction. We demonstrate the effectiveness of our algorithms on dynamic datasets designed specifically to challenge online BNP clustering algorithms. We also show that our algorithms can be employed for practical applications of radar pulse clustering and neural spike sorting, achieving competitive-and often superior-results when compared to classical BNP methods. Furthermore, we exploit the model-based framework to extend our algorithm and tuning methods from purely Gaussian mixtures to handle data with mixed multivariate Gaussian and categorical type, and demonstrate this new extension on real-world data. Our empirical studies indicate that the developments in this dissertation are a significant contribution to the state of the art in BNP clustering.},
	language = {en},
	publisher = {Wright State University},
	author = {Scherreik, Matthew D},
	year = {2020},
}

@inproceedings{hwang_jaedong_and_hong_zhang-wei_and_chen_eric_r_and_boopathy_akhilan_and_agrawal_pulkit_and_fiete_ila_r_efficient_2022,
	title = {Efficient exploration via fragmentation and recall},
	booktitle = {In review},
	author = {{Hwang, Jaedong and Hong, Zhang-Wei and Chen, Eric R and Boopathy, Akhilan and Agrawal, Pulkit and Fiete, Ila R}},
	year = {2022},
}

@misc{noauthor_ostp_2022-1,
	title = {{OSTP} {Issues} {Guidance} to {Make} {Federally} {Funded} {Research} {Freely} {Available} {Without} {Delay}},
	url = {https://www.whitehouse.gov/ostp/news-updates/2022/08/25/ostp-issues-guidance-to-make-federally-funded-research-freely-available-without-delay/},
	abstract = {Today, the White House Office of Science and Technology Policy (OSTP) updated U.S. policy guidance to make the results of taxpayer-supported research immediately available to the American public at no cost. In a memorandum to federal departments and agencies, Dr. Alondra Nelson, the head of OSTP, delivered guidance for agencies to update their public access…},
	language = {en},
	month = aug,
	year = {2022},
	note = {Publication Title: The White House},
}

@article{barbas_general_2015,
	title = {General cortical and special prefrontal connections: principles from structure to function},
	volume = {38},
	abstract = {How is the vast brain communication system organized? A structural model relates connections to laminar differences between linked areas. The model is based on the principle of systematic structural variation in the cortex, extending from the simplest limbic cortices to eulaminate areas with elaborate lamination. The model accounts for laminar patterns and for the strength and topography of connections between nearby or distant cortices and subcortical structures, exemplified quantitatively for the principal and special prefrontal connections. Widespread connections of limbic areas and focal connections of eulaminate areas yield a broad range of circuit patterns for diverse functions. These diverse pathways innervate excitatory and functionally distinct inhibitory neurons, providing the basis for differential recruitment of areas for flexible behavior. Systematic structural variation likely emerges by timing differences in the development of distinct areas and has important implications for altered connections in diseases of developmental origin.},
	language = {en},
	journal = {Annu. Rev. Neurosci.},
	author = {Barbas, Helen},
	month = jul,
	year = {2015},
	keywords = {schizophrenia, autism, cortical development, emotions, structural model, systematic cortical variation},
	pages = {269--289},
}

@article{butler_remembered_2019,
	title = {Remembered reward locations restructure entorhinal spatial maps},
	volume = {363},
	abstract = {Ethologically relevant navigational strategies often incorporate remembered reward locations. Although neurons in the medial entorhinal cortex provide a maplike representation of the external spatial world, whether this map integrates information regarding learned reward locations remains unknown. We compared entorhinal coding in rats during a free-foraging task and a spatial memory task. Entorhinal spatial maps restructured to incorporate a learned reward location, which in turn improved positional decoding near this location. This finding indicates that different navigational strategies drive the emergence of discrete entorhinal maps of space and points to a role for entorhinal codes in a diverse range of navigational behaviors.},
	language = {en},
	number = {6434},
	journal = {Science},
	author = {Butler, William N and Hardcastle, Kiah and Giocomo, Lisa M},
	month = mar,
	year = {2019},
	pages = {1447--1452},
}

@article{widloski_flexible_2022,
	title = {Flexible rerouting of hippocampal replay sequences around changing barriers in the absence of global place field remapping},
	volume = {110},
	abstract = {Flexibility is a hallmark of memories that depend on the hippocampus. For navigating animals, flexibility is necessitated by environmental changes such as blocked paths and extinguished food sources. To better understand the neural basis of this flexibility, we recorded hippocampal replays in a spatial memory task where barriers as well as goals were moved between sessions to see whether replays could adapt to new spatial and reward contingencies. Strikingly, replays consistently depicted new goal-directed trajectories around each new barrier configuration and largely avoided barrier violations. Barrier-respecting replays were learned rapidly and did not rely on place cell remapping. These data distinguish sharply between place field responses, which were largely stable and remained tied to sensory cues, and replays, which changed flexibly to reflect the learned contingencies in the environment and suggest sequenced activations such as replay to be an important link between the hippocampus and flexible memory.},
	language = {en},
	number = {9},
	journal = {Neuron},
	author = {Widloski, John and Foster, David J},
	month = may,
	year = {2022},
	keywords = {hippocampus, place cells, memory, replay, spatial navigation, attractor dynamics, adaptation, barriers, sequences},
	pages = {1547--1558.e8},
}

@misc{noauthor_ostp_2022-2,
	title = {{OSTP} {Issues} {Guidance} to {Make} {Federally} {Funded} {Research} {Freely} {Available} {Without} {Delay}},
	url = {https://www.whitehouse.gov/ostp/news-updates/2022/08/25/ostp-issues-guidance-to-make-federally-funded-research-freely-available-without-delay/},
	abstract = {Today, the White House Office of Science and Technology Policy (OSTP) updated U.S. policy guidance to make the results of taxpayer-supported research immediately available to the American public at no cost. In a memorandum to federal departments and agencies, Dr. Alondra Nelson, the head of OSTP, delivered guidance for agencies to update their public access…},
	language = {en},
	month = aug,
	year = {2022},
	note = {Publication Title: The White House},
	keywords = {Scientific Publishing},
}

@misc{noauthor_ostp_2022-3,
	title = {{OSTP} {Issues} {Guidance} to {Make} {Federally} {Funded} {Research} {Freely} {Available} {Without} {Delay}},
	url = {https://www.whitehouse.gov/ostp/news-updates/2022/08/25/ostp-issues-guidance-to-make-federally-funded-research-freely-available-without-delay/},
	abstract = {Today, the White House Office of Science and Technology Policy (OSTP) updated U.S. policy guidance to make the results of taxpayer-supported research immediately available to the American public at no cost. In a memorandum to federal departments and agencies, Dr. Alondra Nelson, the head of OSTP, delivered guidance for agencies to update their public access…},
	language = {en},
	month = aug,
	year = {2022},
	note = {Publication Title: The White House},
	keywords = {Scientific Publishing},
}

@article{anderson_more_1972-1,
	title = {More {Is} {Different}},
	volume = {177},
	number = {4047},
	journal = {Science},
	author = {Anderson, P W},
	year = {1972},
	pages = {393--396},
}

@unpublished{stockl_probabilistic_2021,
	title = {Probabilistic skeletons endow brain-like neural networks with innate computing capabilities},
	abstract = {Genetically encoded structure endows neural networks of the brain with innate computational capabilities that enable odor classification and basic motor control right after birth. It is also conjectured that the stereotypical laminar organization of neocortical microcircuits provides basic computing capabilities on which subsequent learning can build. However, it has re-mained unknown how nature achieves this. Insight from artificial neural networks does not help to solve this problem, since their computational ca-pabilities result from learning. We show that genetically encoded control over connection probabilities between different types of neurons suffices for programming substantial computing capabilities into neural networks. This insight also provides a method for enhancing computing and learning ca-pabilities of artificial neural networks and neuromorphic hardware through clever initialization. \#\#\# Competing Interest Statement The authors have declared no competing interest.},
	language = {en},
	author = {Stöckl, Christoph and Lang, Dominik and Maass, Wolfgang},
	month = may,
	year = {2021},
	note = {Publication Title: bioRxiv},
}

@misc{noauthor_publishing-call--action_nodate,
	title = {Publishing-call-to-action},
	url = {https://www.overleaf.com/project/6251de5017bd3fb30d3406ef},
	abstract = {An online LaTeX editor that's easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
	language = {en},
	keywords = {Scientific Publishing},
}

@article{noauthor_figure_2022,
	title = {Figure 4},
	abstract = {Synaptic connections between star pyramidal neurons located in the same barrel. A, Camera lucida reconstruction of a synaptically connected pair of star pyramidal neurons. Red, Dendrites; blue, axons. Gray shading, Barrel structure. Scale bar, 100 μm. Yellow dots indicate putative contacts between axons of presynaptic cell (green soma) and dendrites of postsynaptic cell (red soma) as identified from 100{\textbackslash}times microscopic images. B, Positions of cells whose recordings are shown in C. Star pyramidal neuron (a) forms synaptic contact with another star pyramidal neuron (b) located in the same barrel, but not with another spiny star pyramidal neuron (c) located in the adjacent barrel (not shown in A). C1, Presynaptic APs in cell a (bottom trace, 3 sweeps overlaid) do not evoke a synaptic response in cell c (top sweeps). C2, APs in cell a (bottom, 20 traces overlaid) evoked uEPSPs in cell b (top). C3, Typical AP trains, evoked by 100 pA, 0.5 s depolarizing current pulses in cell a and cell b, show frequency adaptation.},
	language = {en},
	journal = {J. Neurosci.},
	month = oct,
	year = {2022},
	note = {Publisher: Society for Neuroscience},
}

@article{rich_place_2014,
	title = {Place cells. {Large} environments reveal the statistical structure governing hippocampal representations},
	volume = {345},
	abstract = {The rules governing the formation of spatial maps in the hippocampus have not been determined. We investigated the large-scale structure of place field activity by recording hippocampal neurons in rats exploring a previously unencountered 48-meter-long track. Single-cell and population activities were well described by a two-parameter stochastic model. Individual neurons had their own characteristic propensity for forming fields randomly along the track, with some cells expressing many fields and many exhibiting few or none. Because of the particular distribution of propensities across cells, the number of neurons with fields scaled logarithmically with track length over a wide, ethological range. These features constrain hippocampal memory mechanisms, may allow efficient encoding of environments and experiences of vastly different extents and durations, and could reflect general principles of population coding.},
	language = {en},
	number = {6198},
	journal = {Science},
	author = {Rich, P Dylan and Liaw, Hua-Peng and Lee, Albert K},
	month = aug,
	year = {2014},
	pages = {814--817},
}

@article{eliav_multiscale_2021,
	title = {Multiscale representation of very large environments in the hippocampus of flying bats},
	volume = {372},
	abstract = {Hippocampal place cells encode the animal's location. Place cells were traditionally studied in small environments, and nothing is known about large ethologically relevant spatial scales. We wirelessly recorded from hippocampal dorsal CA1 neurons of wild-born bats flying in a long tunnel (200 meters). The size of place fields ranged from 0.6 to 32 meters. Individual place cells exhibited multiple fields and a multiscale representation: Place fields of the same neuron differed up to 20-fold in size. This multiscale coding was observed from the first day of exposure to the environment, and also in laboratory-born bats that never experienced large environments. Theoretical decoding analysis showed that the multiscale code allows representation of very large environments with much higher precision than that of other codes. Together, by increasing the spatial scale, we discovered a neural code that is radically different from classical place codes.},
	language = {en},
	number = {6545},
	journal = {Science},
	author = {Eliav, Tamir and Maimon, Shir R and Aljadeff, Johnatan and Tsodyks, Misha and Ginosar, Gily and Las, Liora and Ulanovsky, Nachum},
	month = may,
	year = {2021},
}

@article{van_vreeswijk_chaos_1996-1,
	title = {Chaos in neuronal networks with balanced excitatory and inhibitory activity},
	volume = {274},
	abstract = {Neurons in the cortex of behaving animals show temporally irregular spiking patterns. The origin of this irregularity and its implications for neural processing are unknown. The hypothesis that the temporal variability in the firing of a neuron results from an approximate balance between its excitatory and inhibitory inputs was investigated theoretically. Such a balance emerges naturally in large networks of excitatory and inhibitory neuronal populations that are sparsely connected by relatively strong synapses. The resulting state is characterized by strongly chaotic dynamics, even when the external inputs to the network are constant in time. Such a network exhibits a linear response, despite the highly nonlinear dynamics of single neurons, and reacts to changing external stimuli on time scales much smaller than the integration time constant of a single neuron.},
	language = {en},
	number = {5293},
	journal = {Science},
	author = {van Vreeswijk, C and Sompolinsky, H},
	month = dec,
	year = {1996},
	pages = {1724--1726},
}

@article{amit_storing_1985-1,
	title = {Storing infinite numbers of patterns in a spin-glass model of neural networks},
	volume = {55},
	language = {en},
	number = {14},
	journal = {Phys. Rev. Lett.},
	author = {Amit, D J and Gutfreund, H and Sompolinsky, H},
	month = sep,
	year = {1985},
	pages = {1530--1533},
}

@article{seung_statistical_1992,
	title = {Statistical mechanics of learning from examples},
	volume = {45},
	language = {en},
	number = {8},
	journal = {Phys. Rev. A},
	author = {Seung, H S and Sompolinsky, H and Tishby, N},
	month = apr,
	year = {1992},
	pages = {6056--6091},
}

@article{hanuschkin_hebbian_2013,
	title = {A {Hebbian} learning rule gives rise to mirror neurons and links them to control theoretic inverse models},
	volume = {7},
	abstract = {Mirror neurons are neurons whose responses to the observation of a motor act resemble responses measured during production of that act. Computationally, mirror neurons have been viewed as evidence for the existence of internal inverse models. Such models, rooted within control theory, map-desired sensory targets onto the motor commands required to generate those targets. To jointly explore both the formation of mirrored responses and their functional contribution to inverse models, we develop a correlation-based theory of interactions between a sensory and a motor area. We show that a simple eligibility-weighted Hebbian learning rule, operating within a sensorimotor loop during motor explorations and stabilized by heterosynaptic competition, naturally gives rise to mirror neurons as well as control theoretic inverse models encoded in the synaptic weights from sensory to motor neurons. Crucially, we find that the correlational structure or stereotypy of the neural code underlying motor explorations determines the nature of the learned inverse model: random motor codes lead to causal inverses that map sensory activity patterns to their motor causes; such inverses are maximally useful, by allowing the imitation of arbitrary sensory target sequences. By contrast, stereotyped motor codes lead to less useful predictive inverses that map sensory activity to future motor actions. Our theory generalizes previous work on inverse models by showing that such models can be learned in a simple Hebbian framework without the need for error signals or backpropagation, and it makes new conceptual connections between the causal nature of inverse models, the statistical structure of motor variability, and the time-lag between sensory and motor responses of mirror neurons. Applied to bird song learning, our theory can account for puzzling aspects of the song system, including necessity of sensorimotor gating and selectivity of auditory responses to bird's own song (BOS) stimuli.},
	language = {en},
	journal = {Front. Neural Circuits},
	author = {Hanuschkin, A and Ganguli, S and Hahnloser, R H R},
	month = jun,
	year = {2013},
	keywords = {inverse problem, linear models, mirror neurons, sensory motor learning, songbird},
	pages = {106},
}

@article{miall_connecting_2003,
	title = {Connecting mirror neurons and forward models},
	volume = {14},
	abstract = {Two recent developments in motor neuroscience are promising the extension of theoretical concepts from motor control towards cognitive processes, including human social interactions and understanding the intentions of others. The first of these is the discovery of what are now called mirror neurons, which code for both observed and executed actions. The second is the concept of internal models, and in particular recent proposals that forward and inverse models operate in paired modules. These two ideas will be briefly introduced, and a recent suggestion linking between the two processes of mirroring and modelling will be described which may underlie our abilities for imitating actions, for cooperation between two actors, and possibly for communication via gesture and language.},
	language = {en},
	number = {17},
	journal = {Neuroreport},
	author = {Miall, R C},
	month = dec,
	year = {2003},
	pages = {2135--2137},
}

@misc{noauthor_brain_2021-1,
	title = {Brain {Initiative} {Cell} {Census} {Network}},
	url = {https://www.nature.com/collections/cicghheddj},
	abstract = {Generating a multimodal cell census and atlas of primary motor cortex through collaborative data collection, tool development and analysis.},
	language = {en},
	month = oct,
	year = {2021},
	note = {Publication Title: Nature},
}

@misc{noauthor_brain_2021-2,
	title = {{BRAIN} {Initiative} {Cell} {Census} {Network}—{Motor} {Cortex}},
	url = {https://www.nature.com/immersive/d42859-021-00067-2/index.html},
	abstract = {Generating a multimodal cell census and atlas of primary motor cortex through collaborative data collection, tool development and analysis.},
	language = {en},
	month = oct,
	year = {2021},
}

@misc{noauthor_brain_2021-3,
	title = {{BRAIN} {Initiative} {Cell} {Census} {Network}—{Motor} {Cortex}},
	url = {https://www.nature.com/immersive/d42859-021-00067-2/index.html},
	abstract = {Generating a multimodal cell census and atlas of primary motor cortex through collaborative data collection, tool development and analysis.},
	language = {en},
	month = oct,
	year = {2021},
}

@article{pettijohn_walking_2016,
	title = {Walking through doorways causes forgetting: {Event} structure or updating disruption?},
	volume = {69},
	abstract = {According to event cognition theory, people segment experience into separate event models. One consequence of this segmentation is that when people transport objects from one location to another, memory is worse than if people move across a large location. In two experiments participants navigated through a virtual environment, and recognition memory was tested in either the presence or the absence of a location shift for objects that were recently interacted with (i.e., just picked up or set down). Of particular concern here is whether this location updating effect is due to (a) differences in retention intervals as a result of the navigation process, (b) a temporary disruption in cognitive processing that may occur as a result of the updating processes, or (c) a need to manage multiple event models, as has been suggested in prior research. Experiment 1 explored whether retention interval is driving this effect by recording travel times from the acquisition of an object and the probe time. The results revealed that travel times were similar, thereby rejecting a retention interval explanation. Experiment 2 explored whether a temporary disruption in processing is producing the effect by introducing a 3-second delay prior to the presentation of a memory probe. The pattern of results was not affected by adding a delay, thereby rejecting a temporary disruption account. These results are interpreted in the context of the event horizon model, which suggests that when there are multiple event models that contain common elements there is interference at retrieval, which compromises performance.},
	language = {en},
	number = {11},
	journal = {Q. J. Exp. Psychol.},
	author = {Pettijohn, Kyle A and Radvansky, Gabriel A},
	month = nov,
	year = {2016},
	keywords = {Event cognition, Event models, Mental models, Spatial updating},
	pages = {2119--2129},
}

@article{barkai_robust_2009,
	title = {Robust generation and decoding of morphogen gradients},
	volume = {1},
	abstract = {Morphogen gradients play a key role in multiple differentiation processes. Both the formation of the gradient and its interpretation by the receiving cells need to occur at high precision to ensure reproducible patterning. This need for quantitative precision is challenged by fluctuations in the environmental conditions and by variations in the genetic makeup of the developing embryos. We discuss mechanisms that buffer morphogen profiles against variations in gene dosage. Self-enhanced morphogen degradation and pre-steady-state decoding provide general means for buffering the morphogen profile against fluctuations in morphogen production rate. A more specific “shuttling” mechanism, which establishes a sharp and robust activation profile of a widely expressed morphogen, and enables the adjustment of morphogen profile with embryo size, is also described. Finally, we consider the transformation of the smooth gradient profile into sharp borders of gene expression in the signal-receiving cells. The integration theory and experiments are increasingly used, providing key insights into the system-level functioning of the developmental system.},
	language = {en},
	number = {5},
	journal = {Cold Spring Harb. Perspect. Biol.},
	author = {Barkai, Naama and Shilo, Ben-Zion},
	month = nov,
	year = {2009},
	pages = {a001990},
}

@article{kennedy_temporal_2014,
	title = {A temporal basis for predicting the sensory consequences of motor commands in an electric fish},
	volume = {17},
	number = {3},
	journal = {Nat. Neurosci.},
	author = {Kennedy, Ann and Wayne, Greg and Kaifosh, Patrick and Alviña, Karina and Abbott, L F and Sawtell, Nathaniel B},
	year = {2014},
	note = {Publisher: Nature Publishing Group US New York},
	pages = {416--422},
}

@article{hoverstad_noise_2011,
	title = {Noise and the evolution of neural network modularity},
	volume = {17},
	abstract = {We study the selective advantage of modularity in artificially evolved networks. Modularity abounds in complex systems in the real world. However, experimental evidence for the selective advantage of network modularity has been elusive unless it has been supported or mandated by the genetic representation. The evolutionary origin of modularity is thus still debated: whether networks are modular because of the process that created them, or the process has evolved to produce modular networks. It is commonly argued that network modularity is beneficial under noisy conditions, but experimental support for this is still very limited. In this article, we evolve nonlinear artificial neural network classifiers for a binary classification task with a modular structure. When noise is added to the edge weights of the networks, modular network topologies evolve, even without representational support.},
	language = {en},
	number = {1},
	journal = {Artif. Life},
	author = {Høverstad, Boye Annfelt},
	year = {2011},
	pages = {33--50},
}

@article{khona_smooth_2021,
	title = {From smooth cortical gradients to discrete modules: {A} biologically plausible mechanism for the self-organization of modularity in grid cells},
	abstract = {… smooth gradients in several biophysical properties, within days of eye opening in juvenile animals. The mechanisms … functionally discrete grid modules can spontaneously self - organize …},
	author = {Khona, M and Chandra, S and Fiete, I R},
	year = {2021},
	note = {Publisher: europepmc.org},
}

@unpublished{schaeffer_no_2022,
	title = {No {Free} {Lunch} from {Deep} {Learning} in {Neuroscience}: {A} {Case} {Study} through {Models} of the {Entorhinal}-{Hippocampal} {Circuit}},
	abstract = {Research in Neuroscience, as in many scientific disciplines, is undergoing a renaissance based on deep learning. Unique to Neuroscience, deep learning models can be used not only as a tool but interpreted as models of the brain. The central claims of recent deep learning-based models of brain circuits are that they make novel predictions about neural phenomena or shed light on the fundamental functions being optimized. We show, through the case-study of grid cells in the entorhinal-hippocampal circuit, that one may get neither. We begin by reviewing the principles of grid cell mechanism and function obtained from first-principles modeling efforts, then rigorously examine the claims of deep learning models of grid cells. Using large-scale hyperparameter sweeps and theory-driven experimentation, we demonstrate that the results of such models may be more strongly driven by particular, non-fundamental, and post-hoc implementation choices than fundamental truths about neural circuits or the loss function(s) they might optimize. We discuss why these models cannot be expected to produce accurate models of the brain without the addition of substantial amounts of inductive bias, an informal No Free Lunch result for Neuroscience. Based on first principles work, we provide hypotheses for what additional loss functions will produce grid cells more robustly. In conclusion, caution and consideration, together with biological knowledge, are warranted in building and interpreting deep learning models in Neuroscience. \#\#\# Competing Interest Statement The authors have declared no competing interest.},
	language = {en},
	author = {Schaeffer, Rylan and Khona, Mikail and Fiete, Ila Rani},
	month = aug,
	year = {2022},
	note = {Publication Title: bioRxiv},
}

@unpublished{khona_smooth_2022-1,
	title = {From smooth cortical gradients to discrete modules: {A} biologically plausible mechanism for the self-organization of modularity in grid cells},
	abstract = {The grid cell system is a paradigmatic example of the computational advantages of modular representations. Modular grid responses emerge along a strip of cortex with smooth gradients in several biophysical properties, within days of eye opening in juvenile animals. The mechanisms underlying this emergence are unknown. We show that multiple spatially and functionally discrete grid modules can spontaneously self-organize from lateral interactions that are continuously graded in scale, when combined with a fixed-scale interaction. We derive a comprehensive analytic theory to reveal that modularization through this mechanism is highly generic and robust. It predicts that each term in the sequence of grid period ratios should be distinct and furnishes values that are invariant to microscopic details about dynamics and connectivity, resulting in the most accurate match to data to date. Altogether, this work reveals novel self-organization mechanisms by which simple local interactions and smooth gradients may interact to produce macroscopic modular organization. \#\#\# Competing Interest Statement The authors have declared no competing interest.},
	language = {en},
	author = {Khona, Mikail and Chandra, Sarthak and Fiete, Ila R},
	month = mar,
	year = {2022},
	note = {Publication Title: bioRxiv},
}

@article{schacter_searching_1996,
	title = {Searching for memory: {The} brain, the mind, and the past},
	volume = {398},
	abstract = {According to Daniel Schacter, . . . the mysteries of memory are finally yielding to . . . scientific breakthroughs. [In this book the author] explains how and why it may change our understanding of everything from false memory to Alzheimer's disease (AD), from recovered memory to amnesia. Drawing on his own work and that of other cognitive, clinical, and neuroscientists, Schacter gives us . . . evidence for the thesis that we possess more than one memory system, which explains why some brain-damaged people cannot remember past events, and others cannot acquire new knowledge or call up old. He also shows us how new breakthroughs in brain imaging are allowing us to see, for the 1st time, the many parts of the brain that must interact to enable us to encode or retrieve a memory. [This book] contains . . . firsthand accounts of patients with . . . amnesias resulting from brain injury or psychological trauma. Schacter also takes us into the hidden world of implicit memories—unconscious influences of the past that, outside our awareness, affect our judgments, preferences, and actions. And he examines the nature and accuracy of emotionally traumatic memories, using the latest advances in cognitive neuroscience to clarify vexing issues in the heated controversy over repressed memories of childhood trauma. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	author = {Schacter, Daniel L},
	year = {1996},
	note = {Place: New York, NY, US
Publisher: Basic Books Searching for memory},
}

@article{raspopovic_modeling_2014,
	title = {Modeling digits. {Digit} patterning is controlled by a {Bmp}-{Sox9}-{Wnt} {Turing} network modulated by morphogen gradients},
	volume = {345},
	abstract = {During limb development, digits emerge from the undifferentiated mesenchymal tissue that constitutes the limb bud. It has been proposed that this process is controlled by a self-organizing Turing mechanism, whereby diffusible molecules interact to produce a periodic pattern of digital and interdigital fates. However, the identities of the molecules remain unknown. By combining experiments and modeling, we reveal evidence that a Turing network implemented by Bmp, Sox9, and Wnt drives digit specification. We develop a realistic two-dimensional simulation of digit patterning and show that this network, when modulated by morphogen gradients, recapitulates the expression patterns of Sox9 in the wild type and in perturbation experiments. Our systems biology approach reveals how a combination of growth, morphogen gradients, and a self-organizing Turing network can achieve robust and reproducible pattern formation.},
	language = {en},
	number = {6196},
	journal = {Science},
	author = {Raspopovic, J and Marcon, L and Russo, L and Sharpe, J},
	month = aug,
	year = {2014},
	pages = {566--570},
}

@article{baum_internal_1988-2,
	title = {Internal representations for associative memory},
	volume = {59},
	abstract = {We describe a class of feed forward neural network models for associative content addressable memory (ACAM) which utilize sparse internal representations for stored data. In addition to the input and output layers, our networks incorporate an intermediate processing layer which serves to label each stored memory and to perform error correction and association. We study two classes of internal label representations: the unary representation and various sparse, distributed representations. Finally, we consider storage of sparse data and sparsification of data. These models are found to have advantages in terms of storage capacity, hardware efficiency, and recall reliability when compared to the Hopfield model, and to possess analogies to both biological neural networks and standard digital computer memories.},
	number = {4},
	journal = {Biol. Cybern.},
	author = {Baum, E B and Moody, J and Wilczek, F},
	month = sep,
	year = {1988},
	pages = {217--228},
}

@article{bittner_behavioral_2017,
	title = {Behavioral time scale synaptic plasticity underlies {CA1} place fields},
	volume = {357},
	abstract = {Learning is primarily mediated by activity-dependent modifications of synaptic strength within neuronal circuits. We discovered that place fields in hippocampal area CA1 are produced by a synaptic potentiation notably different from Hebbian plasticity. Place fields could be produced in vivo in a single trial by potentiation of input that arrived seconds before and after complex spiking. The potentiated synaptic input was not initially coincident with action potentials or depolarization. This rule, named behavioral time scale synaptic plasticity, abruptly modifies inputs that were neither causal nor close in time to postsynaptic activation. In slices, five pairings of subthreshold presynaptic activity and calcium (Ca2+) plateau potentials produced a large potentiation with an asymmetric seconds-long time course. This plasticity efficiently stores entire behavioral sequences within synaptic weights to produce predictive place cell activity.},
	language = {en},
	number = {6355},
	journal = {Science},
	author = {Bittner, Katie C and Milstein, Aaron D and Grienberger, Christine and Romani, Sandro and Magee, Jeffrey C},
	month = sep,
	year = {2017},
	pages = {1033--1036},
}

@article{zhao_rapid_2022,
	title = {Rapid synaptic plasticity contributes to a learned conjunctive code of position and choice-related information in the hippocampus},
	volume = {110},
	abstract = {To successfully perform goal-directed navigation, animals must know where they are and what they are doing-e.g., looking for water, bringing food back to the nest, or escaping from a predator. Hippocampal neurons code for these critical variables conjunctively, but little is known about how this “where/what” code is formed or flexibly routed to other brain regions. To address these questions, we performed intracellular whole-cell recordings in mouse CA1 during a cued, two-choice virtual navigation task. We demonstrate that plateau potentials in CA1 pyramidal neurons rapidly strengthen synaptic inputs carrying conjunctive information about position and choice. Plasticity-induced response fields were modulated by cues only in animals previously trained to collect rewards based on available cues. Thus, we reveal that gradual learning is required for the formation of a conjunctive population code, upstream of CA1, while plateau-potential-induced synaptic plasticity in CA1 enables flexible routing of the code to downstream brain regions.},
	language = {en},
	number = {1},
	journal = {Neuron},
	author = {Zhao, Xinyu and Hsu, Ching-Lung and Spruston, Nelson},
	month = jan,
	year = {2022},
	keywords = {hippocampus, learning, plateau potential, place cell, plasticity, context dependence},
	pages = {96--108.e4},
}

@article{peer_processing_2019,
	title = {Processing of different spatial scales in the human brain},
	volume = {8},
	abstract = {Humans navigate across a range of spatial scales, from rooms to continents, but the brain systems underlying spatial cognition are usually investigated only in small-scale environments. Do the same brain systems represent and process larger spaces? Here we asked subjects to compare distances between real-world items at six different spatial scales (room, building, neighborhood, city, country, continent) under functional MRI. Cortical activity showed a gradual progression from small to large scale processing, along three gradients extending anteriorly from the parahippocampal place area (PPA), retrosplenial complex (RSC) and occipital place area (OPA), and along the hippocampus posterior-anterior axis. Each of the cortical gradients overlapped with the visual system posteriorly and the default-mode network (DMN) anteriorly. These results suggest a progression from concrete to abstract processing with increasing spatial scale, and offer a new organizational framework for the brain's spatial system, that may also apply to conceptual spaces beyond the spatial domain.},
	language = {en},
	journal = {Elife},
	author = {Peer, Michael and Ron, Yorai and Monsa, Rotem and Arzy, Shahar},
	month = sep,
	year = {2019},
	keywords = {human, neuroscience, cortical gradient, default-mode network, OPA, PPA, RSC, spatial scale},
}

@article{siu_development_2018,
	title = {The development of human visual cortex and clinical implications},
	volume = {10},
	abstract = {The primary visual cortex (V1) is the first cortical area that processes visual information. Normal development of V1 depends on binocular vision during the critical period, and age-related losses of vision are linked with neurobiological changes in V1. Animal studies have provided important details about the neurobiological mechanisms in V1 that support normal vision or are changed by visual diseases. There is very little information, however, about those neurobiological mechanisms in human V1. That lack of information has hampered the translation of biologically inspired treatments from preclinical models to effective clinical treatments. We have studied human V1 to characterize the expression of neurobiological mechanisms that regulate visual perception and neuroplasticity. We have identified five stages of development for human V1 that start in infancy and continue across the life span. Here, we describe these stages, compare them with visual and anatomical milestones, and discuss implications for translating treatments for visual disorders that depend on neuroplasticity of V1 function.},
	language = {en},
	journal = {Eye Brain},
	author = {Siu, Caitlin R and Murphy, Kathryn M},
	month = apr,
	year = {2018},
	keywords = {synaptic plasticity, development, amblyopia, GABAergic, glutamatergic, human visual cortex, receptors},
	pages = {25--36},
}

@article{espinosa_development_2012,
	title = {Development and plasticity of the primary visual cortex},
	volume = {75},
	abstract = {Hubel and Wiesel began the modern study of development and plasticity of primary visual cortex (V1), discovering response properties of cortical neurons that distinguished them from their inputs and that were arranged in a functional architecture. Their findings revealed an early innate period of development and a later critical period of dramatic experience-dependent plasticity. Recent studies have used rodents to benefit from biochemistry and genetics. The roles of spontaneous neural activity and molecular signaling in innate, experience-independent development have been clarified, as have the later roles of visual experience. Plasticity produced by monocular visual deprivation (MD) has been dissected into stages governed by distinct signaling mechanisms, some of whose molecular players are known. Many crucial questions remain, but new tools for perturbing cortical cells and measuring plasticity at the level of changes in connections among identified neurons now exist. The future for the study of V1 to illuminate cortical development and plasticity is bright.},
	language = {en},
	number = {2},
	journal = {Neuron},
	author = {Espinosa, J Sebastian and Stryker, Michael P},
	month = jul,
	year = {2012},
	pages = {230--249},
}

@article{burak_fundamental_2012,
	title = {Fundamental limits on persistent activity in networks of noisy neurons},
	volume = {109},
	abstract = {Neural noise limits the fidelity of representations in the brain. This limitation has been extensively analyzed for sensory coding. However, in short-term memory and integrator networks, where noise accumulates and can play an even more prominent role, much less is known about how neural noise interacts with neural and network parameters to determine the accuracy of the computation. Here we analytically derive how the stored memory in continuous attractor networks of probabilistically spiking neurons will degrade over time through diffusion. By combining statistical and dynamical approaches, we establish a fundamental limit on the network's ability to maintain a persistent state: The noise-induced drift of the memory state over time within the network is strictly lower-bounded by the accuracy of estimation of the network's instantaneous memory state by an ideal external observer. This result takes the form of an information-diffusion inequality. We derive some unexpected consequences: Despite the persistence time of short-term memory networks, it does not pay to accumulate spikes for longer than the cellular time-constant to read out their contents. For certain neural transfer functions, the conditions for optimal sensory coding coincide with those for optimal storage, implying that short-term memory may be co-localized with sensory representation.},
	language = {en},
	number = {43},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Burak, Yoram and Fiete, Ila R},
	month = oct,
	year = {2012},
	pages = {17645--17650},
}

@article{bienkowski_integration_2018,
	title = {Integration of gene expression and brain-wide connectivity reveals the multiscale organization of mouse hippocampal networks},
	volume = {21},
	abstract = {Understanding the organization of the hippocampus is fundamental to understanding brain function related to learning, memory, emotions, and diseases such as Alzheimer's disease. Physiological studies in humans and rodents have suggested that there is both structural and functional heterogeneity along the longitudinal axis of the hippocampus. However, the recent discovery of discrete gene expression domains in the mouse hippocampus has provided the opportunity to re-evaluate hippocampal connectivity. To integrate mouse hippocampal gene expression and connectivity, we mapped the distribution of distinct gene expression patterns in mouse hippocampus and subiculum to create the Hippocampus Gene Expression Atlas (HGEA). Notably, previously unknown subiculum gene expression patterns revealed a hidden laminar organization. Guided by the HGEA, we constructed the most detailed hippocampal connectome available using Mouse Connectome Project ( http://www.mouseconnectome.org ) tract tracing data. Our results define the hippocampus' multiscale network organization and elucidate each subnetwork's unique brain-wide connectivity patterns.},
	language = {en},
	number = {11},
	journal = {Nat. Neurosci.},
	author = {Bienkowski, Michael S and Bowman, Ian and Song, Monica Y and Gou, Lin and Ard, Tyler and Cotter, Kaelan and Zhu, Muye and Benavidez, Nora L and Yamashita, Seita and Abu-Jaber, Jaspar and Azam, Sana and Lo, Darrick and Foster, Nicholas N and Hintiryan, Houri and Dong, Hong-Wei},
	month = nov,
	year = {2018},
	pages = {1628--1643},
}

@article{arcaro_hierarchical_2017,
	title = {A hierarchical, retinotopic proto-organization of the primate visual system at birth},
	volume = {6},
	abstract = {The adult primate visual system comprises a series of hierarchically organized areas. Each cortical area contains a topographic map of visual space, with different areas extracting different kinds of information from the retinal input. Here we asked to what extent the newborn visual system resembles the adult organization. We find that hierarchical, topographic organization is present at birth and therefore constitutes a proto-organization for the entire primate visual system. Even within inferior temporal cortex, this proto-organization was already present, prior to the emergence of category selectivity (e.g., faces or scenes). We propose that this topographic organization provides the scaffolding for the subsequent development of visual cortex that commences at the onset of visual experience},
	journal = {Elife},
	author = {Arcaro, Michael J and Livingstone, Margaret S},
	month = jul,
	year = {2017},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {hierarchy, vision, proto-organization, retinotopy, visual development},
	pages = {e26196},
}

@article{baradad_learning_2021,
	title = {Learning to {See} by {Looking} at {Noise}},
	abstract = {Current vision systems are trained on huge datasets, and these datasets come with costs: curation is expensive, they inherit human biases, and there are concerns over privacy and usage rights. To counter these costs, interest has surged in learning from cheaper data sources, such as unlabeled images. In this paper we go a step further and ask if we can do away with real image datasets entirely, instead learning from noise processes. We investigate a suite of image generation models that produce images from simple random processes. These are then used as training data for a visual representation learner with a contrastive loss. We study two types of noise processes, statistical image models and deep generative models under different random initializations. Our findings show that it is important for the noise to capture certain structural properties of real data but that good performance can be achieved even with processes that are far from realistic. We also find that diversity is a key property to learn good representations. Datasets, models, and code are available at https://mbaradad.github.io/learning\_with\_noise.},
	author = {Baradad, Manel and Wulff, Jonas and Wang, Tongzhou and Isola, Phillip and Torralba, Antonio},
	month = jun,
	year = {2021},
	note = {\_eprint: 2106.05963},
}

@article{chaudhuri_associative_2017,
	title = {Associative content-addressable networks with exponentially many robust stable states},
	abstract = {The brain must robustly store a large number of memories, corresponding to the many events encountered over a lifetime. However, the number of memory states in existing …},
	journal = {arXiv preprint arXiv:1704.02019},
	author = {Chaudhuri, R and Fiete, I},
	year = {2017},
	note = {Publisher: arxiv.org},
}

@article{yoo_multi-periodic_2016,
	title = {Multi-periodic neural coding for adaptive information transfer},
	abstract = {Abstract Information processing in the presence of noise has been a key challenge in multiple disciplines including computer science, communications, and neuroscience. Among …},
	journal = {Theor. Comput. Sci.},
	author = {Yoo, Y and Koyluoglu, O O and Vishwanath, S and Fiete, I},
	year = {2016},
	note = {Publisher: Elsevier},
}

@article{fiete_losing_2010-2,
	title = {Losing phase},
	volume = {66},
	abstract = {In this issue of Neuron, Remme and colleagues examine the biophysics of synchronization between oscillating dendrites and soma. Their findings suggest that oscillators will quickly phase-lock when weakly coupled. These findings are at odds with assumptions of an influential model of grid cell response generation and have implications for grid cell response mechanisms.},
	language = {en},
	number = {3},
	journal = {Neuron},
	author = {Fiete, Ila R},
	month = may,
	year = {2010},
	pages = {331--334},
}

@article{chaudhuri_population_2019,
	title = {The population dynamics of a canonical cognitive circuit},
	abstract = {The brain constructs distributed representations of key low-dimensional variables. These variables may be external stimuli or internal constructs of quantities relevant for survival …},
	journal = {bioRxiv},
	author = {Chaudhuri, R and Gerçek, B and Pandey, B and Peyrache, A and Fiete, I},
	year = {2019},
	note = {Publisher: biorxiv.org},
}

@article{harkin_parallel_2022,
	title = {Parallel and {Recurrent} {Cascade} {Models} as a {Unifying} {Force} for {Understanding} {Subcellular} {Computation}},
	volume = {489},
	abstract = {Neurons are very complicated computational devices, incorporating numerous non-linear processes, particularly in their dendrites. Biophysical models capture these processes directly by explicitly modelling physiological variables, such as ion channels, current flow, membrane capacitance, etc. However, another option for capturing the complexities of real neural computation is to use cascade models, which treat individual neurons as a cascade of linear and non-linear operations, akin to a multi-layer artificial neural network. Recent research has shown that cascade models can capture single-cell computation well, but there are still a number of sub-cellular, regenerative dendritic phenomena that they cannot capture, such as the interaction between sodium, calcium, and NMDA spikes in different compartments. Here, we propose that it is possible to capture these additional phenomena using parallel, recurrent cascade models, wherein an individual neuron is modelled as a cascade of parallel linear and non-linear operations that can be connected recurrently, akin to a multi-layer, recurrent, artificial neural network. Given their tractable mathematical structure, we show that neuron models expressed in terms of parallel recurrent cascades can themselves be integrated into multi-layered artificial neural networks and trained to perform complex tasks. We go on to discuss potential implications and uses of these models for artificial intelligence. Overall, we argue that parallel, recurrent cascade models provide an important, unifying tool for capturing single-cell computation and exploring the algorithmic implications of physiological phenomena.},
	language = {en},
	journal = {Neuroscience},
	author = {Harkin, Emerson F and Shen, Peter R and Goel, Anish and Richards, Blake A and Naud, Richard},
	month = may,
	year = {2022},
	keywords = {artificial neural networks, cascade models, dendritic non-linearities, single-cell computation},
	pages = {200--215},
}

@article{leutgeb_progressive_2005,
	title = {Progressive transformation of hippocampal neuronal representations in “morphed” environments},
	volume = {48},
	abstract = {Hippocampal neural codes for different, familiar environments are thought to reflect distinct attractor states, possibly implemented in the recurrent CA3 network. A defining property of an attractor network is its ability to undergo sharp and coherent transitions between pre-established (learned) representations when the inputs to the network are changed. To determine whether hippocampal neuronal ensembles exhibit such discontinuities, we recorded in CA3 and CA1 when a familiar square recording enclosure was morphed in quantifiable steps into a familiar circular enclosure while leaving other inputs constant. We observed a gradual noncoherent progression from the initial to the final network state. In CA3, the transformation was accompanied by significant hysteresis, resulting in more similar end states than when only square and circle were presented. These observations suggest that hippocampal cell assemblies are capable of incremental plastic deformation, with incongruous information being incorporated into pre-existing representations.},
	language = {en},
	number = {2},
	journal = {Neuron},
	author = {Leutgeb, Jill K and Leutgeb, Stefan and Treves, Alessandro and Meyer, Retsina and Barnes, Carol A and McNaughton, Bruce L and Moser, May-Britt and Moser, Edvard I},
	month = oct,
	year = {2005},
	pages = {345--358},
}

@article{yu_uncertainty_2005,
	title = {Uncertainty, neuromodulation, and attention},
	volume = {46},
	abstract = {Uncertainty in various forms plagues our interactions with the environment. In a Bayesian statistical framework, optimal inference and prediction, based on unreliable observations in changing contexts, require the representation and manipulation of different forms of uncertainty. We propose that the neuromodulators acetylcholine and norepinephrine play a major role in the brain's implementation of these uncertainty computations. Acetylcholine signals expected uncertainty, coming from known unreliability of predictive cues within a context. Norepinephrine signals unexpected uncertainty, as when unsignaled context switches produce strongly unexpected observations. These uncertainty signals interact to enable optimal inference and learning in noisy and changeable environments. This formulation is consistent with a wealth of physiological, pharmacological, and behavioral data implicating acetylcholine and norepinephrine in specific aspects of a range of cognitive processes. Moreover, the model suggests a class of attentional cueing tasks that involve both neuromodulators and shows how their interactions may be part-antagonistic, part-synergistic.},
	language = {en},
	number = {4},
	journal = {Neuron},
	author = {Yu, Angela J and Dayan, Peter},
	month = may,
	year = {2005},
	pages = {681--692},
}

@article{fiete_spike-time-dependent_2010-1,
	title = {Spike-time-dependent plasticity and heterosynaptic competition organize networks to produce long scale-free sequences of neural activity},
	volume = {65},
	abstract = {Sequential neural activity patterns are as ubiquitous as the outputs they drive, which include motor gestures and sequential cognitive processes. Neural sequences are long, compared to the activation durations of participating neurons, and sequence coding is sparse. Numerous studies demonstrate that spike-time-dependent plasticity (STDP), the primary known mechanism for temporal order learning in neurons, cannot organize networks to generate long sequences, raising the question of how such networks are formed. We show that heterosynaptic competition within single neurons, when combined with STDP, organizes networks to generate long unary activity sequences even without sequential training inputs. The network produces a diversity of sequences with a power law length distribution and exponent -1, independent of cellular time constants. We show evidence for a similar distribution of sequence lengths in the recorded premotor song activity of songbirds. These results suggest that neural sequences may be shaped by synaptic constraints and network circuitry rather than cellular time constants.},
	language = {en},
	number = {4},
	journal = {Neuron},
	author = {Fiete, Ila R and Senn, Walter and Wang, Claude Z H and Hahnloser, Richard H R},
	month = feb,
	year = {2010},
	pages = {563--576},
}

@article{fiete_what_2008-1,
	title = {What grid cells convey about rat location},
	volume = {28},
	abstract = {We characterize the relationship between the simultaneously recorded quantities of rodent grid cell firing and the position of the rat. The formalization reveals various properties of grid cell activity when considered as a neural code for representing and updating estimates of the rat's location. We show that, although the spatially periodic response of grid cells appears wasteful, the code is fully combinatorial in capacity. The resulting range for unambiguous position representation is vastly greater than the approximately 1-10 m periods of individual lattices, allowing for unique high-resolution position specification over the behavioral foraging ranges of rats, with excess capacity that could be used for error correction. Next, we show that the merits of the grid cell code for position representation extend well beyond capacity and include arithmetic properties that facilitate position updating. We conclude by considering the numerous implications, for downstream readouts and experimental tests, of the properties of the grid cell code.},
	language = {en},
	number = {27},
	journal = {J. Neurosci.},
	author = {Fiete, Ila R and Burak, Yoram and Brookings, Ted},
	month = jul,
	year = {2008},
	pages = {6858--6871},
}

@article{burgalossi_microcircuits_2011,
	title = {Microcircuits of functionally identified neurons in the rat medial entorhinal cortex},
	volume = {70},
	abstract = {VIDEO ABSTRACT: Extracellular recordings have elucidated spatial neural representations without identifying underlying microcircuits. We labeled neurons juxtacellularly in medial entorhinal cortex of freely moving rats with a friction-based, pipette-stabilization system. In a linear maze novel to the animals, spatial firing of superficial layer neurons was reminiscent of grid cell activity. Layer 2 stellate cells showed stronger theta modulation than layer 3 neurons, and both fired during the ascending phase of field potential theta. Deep-layer neurons showed little or no activity. Layer 2 stellate cells resided in hundreds of small patches. At the dorsomedial entorhinal border, we identified larger (putative parasubicular) patches, which contained polarized head-direction selective neurons firing during the descending theta phase. Three axon systems interconnected patches: centrifugal axons from superficial cells to single large patches, centripetal axons from large-patch cells to single small patches, and circumcurrent axons interconnecting large patches. Our microcircuit analysis during behavior reveals modularity of entorhinal processing.},
	language = {en},
	number = {4},
	journal = {Neuron},
	author = {Burgalossi, Andrea and Herfst, Lucas and von Heimendahl, Moritz and Förste, Henning and Haskic, Kurt and Schmidt, Martin and Brecht, Michael},
	month = may,
	year = {2011},
	pages = {773--786},
}

@article{hopfield_neural_1985,
	title = {“{Neural}” computation of decisions in optimization problems},
	volume = {52},
	abstract = {Highly-interconnected networks of nonlinear analog neurons are shown to be extremely effective in computing. The networks can rapidly provide a collectively-computed solution (a digital output) to a problem on the basis of analog input information. The problems to be solved must be formulated in terms of desired optima, often subject to constraints. The general principles involved in constructing networks to solve specific problems are discussed. Results of computer simulations of a network designed to solve a difficult but well-defined optimization problem–the Traveling-Salesman Problem–are presented and used to illustrate the computational power of the networks. Good solutions to this problem are collectively computed within an elapsed time of only a few neural time constants. The effectiveness of the computation involves both the nonlinear analog response of the neurons and the large connectivity among them. Dedicated networks of biological or microelectronic neurons could provide the computational capabilities described for a wide class of problems having combinatorial complexity. The power and speed naturally displayed by such collective networks may contribute to the effectiveness of biological information processing.},
	language = {en},
	number = {3},
	journal = {Biol. Cybern.},
	author = {Hopfield, J J and Tank, D W},
	year = {1985},
	note = {Publisher: Springer Science and Business Media LLC},
	pages = {141--152},
}

@article{scharfman_ca3_2007,
	title = {The {CA3} “backprojection” to the dentate gyrus},
	volume = {163},
	abstract = {The hippocampus is typically described in the context of the trisynaptic circuit, a pathway that relays information from the perforant path to the dentate gyrus, dentate to area CA3, and CA3 to area CA1. Associated with this concept is the assumption that most hippocampal information processing occurs along the trisynaptic circuit. However, the entorhinal cortex may not be the only major extrinsic input to consider, and the trisynaptic circuit may not be the only way information is processed in hippocampus. Area CA3 receives input from a variety of sources, and may be as much of an “entry point” to hippocampus as the dentate gyrus. The axon of CA3 pyramidal cells targets diverse cell types, and has commissural projections, which together make it able to send information to much more of the hippocampus than granule cells. Therefore, CA3 pyramidal cells seem better designed to spread information through hippocampus than the granule cells. From this perspective, CA3 may be a point of entry that receives information which needs to be “broadcasted,” whereas the dentate gyrus may be a point of entry that receives information with more selective needs for hippocampal processing. One aspect of the argument that CA3 pyramidal cells have a widespread projection is based on a part of its axonal arbor that has received relatively little attention, the collaterals that project in the opposite direction to the trisynaptic circuit, “back” to the dentate gyrus. The evidence for this “backprojection” to the dentate gyrus is strong, particularly in area CA3c, the region closest to the dentate gyrus, and in temporal hippocampus. The influence on granule cells is indirect, through hilar mossy cells and GABAergic neurons of the dentate gyrus, and appears to include direct projections in the case of CA3c pyramidal cells of ventral hippocampus. Physiological studies suggest that normally area CA3 does not have a robust excitatory influence on granule cells, but serves instead to inhibit it by activating dentate gyrus GABAergic neurons. Thus, GABAergic inhibition normally controls the backprojection to dentate granule cells, analogous to the way GABAergic inhibition appears to control the perforant path input to granule cells. From this perspective, the dentate gyrus has two robust glutamatergic inputs, entorhinal cortex and CA3, and two “gates,” or inhibitory filters that reduce the efficacy of both inputs, keeping granule cells relatively quiescent. When GABAergic inhibition is reduced experimentally, or under pathological conditions, CA3 pyramidal cells activate granule cells reliably, and do so primarily by disynaptic excitation that is mediated by mossy cells. We suggest that the backprojection has important functions normally that are dynamically regulated by nonprincipal cells of the dentate gyrus. Slightly reduced GABAergic input would lead to increased polysynaptic associative processing between CA3 and the dentate gyrus. Under pathological conditions associated with loss of GABAergic interneurons, the backprojection may support reverberatory excitatory activity between CA3, mossy cells, and granule cells, possibly enhanced by mossy fiber sprouting. In this case, the backprojection could be important to seizure activity originating in hippocampus, and help explain the seizure susceptibility of ventral hippocampus.},
	language = {en},
	journal = {Prog. Brain Res.},
	author = {Scharfman, Helen E},
	year = {2007},
	pages = {627--637},
}

@article{hadjiabadi_higher-order_2020,
	title = {Higher-order hub cells involved in feedforward motifs as critical factors in epileptic network instability},
	journal = {bioRxiv},
	author = {Hadjiabadi, Darian and Lovett-Barron, Matthew and Raikov, Ivan and Sparks, Fraser and Liao, Zhenrui and Baraban, Scott C and Leskovec, Jure and Losonczy, Attila and Deisseroth, Karl and Soltesz, Ivan},
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory},
	pages = {2020--2010},
}

@article{dudok_alternating_2021,
	title = {Alternating sources of perisomatic inhibition during behavior},
	volume = {109},
	abstract = {Interneurons expressing cholecystokinin (CCK) and parvalbumin (PV) constitute two key GABAergic controllers of hippocampal pyramidal cell output. Although the temporally precise and millisecond-scale inhibitory regulation of neuronal ensembles delivered by PV interneurons is well established, the in vivo recruitment patterns of CCK-expressing basket cell (BC) populations has remained unknown. We show in the CA1 of the mouse hippocampus that the activity of CCK BCs inversely scales with both PV and pyramidal cell activity at the behaviorally relevant timescales of seconds. Intervention experiments indicated that the inverse coupling of CCK and PV GABAergic systems arises through a mechanism involving powerful inhibitory control of CCK BCs by PV cells. The tightly coupled complementarity of two key microcircuit regulatory modules demonstrates a novel form of brain-state-specific segregation of inhibition during spontaneous behavior.},
	language = {en},
	number = {6},
	journal = {Neuron},
	author = {Dudok, Barna and Klein, Peter M and Hwaun, Ernie and Lee, Brian R and Yao, Zizhen and Fong, Olivia and Bowler, John C and Terada, Satoshi and Sparks, Fraser T and Szabo, Gergely G and Farrell, Jordan S and Berg, Jim and Daigle, Tanya L and Tasic, Bosiljka and Dimidschstein, Jordane and Fishell, Gord and Losonczy, Attila and Zeng, Hongkui and Soltesz, Ivan},
	month = mar,
	year = {2021},
	keywords = {locomotion, hippocampus, CA1, inhibition, GABA, interneuron, brain state, CB1 receptor, cholecystokinin, parvalbumin, Sncg},
	pages = {997--1012.e9},
}

@article{tukker_microcircuits_2022,
	title = {Microcircuits for spatial coding in the medial entorhinal cortex},
	volume = {102},
	abstract = {The hippocampal formation is critically involved in learning and memory and contains a large proportion of neurons encoding aspects of the organism's spatial surroundings. In the medial entorhinal cortex (MEC), this includes grid cells with their distinctive hexagonal firing fields as well as a host of other functionally defined cell types including head direction cells, speed cells, border cells, and object-vector cells. Such spatial coding emerges from the processing of external inputs by local microcircuits. However, it remains unclear exactly how local microcircuits and their dynamics within the MEC contribute to spatial discharge patterns. In this review we focus on recent investigations of intrinsic MEC connectivity, which have started to describe and quantify both excitatory and inhibitory wiring in the superficial layers of the MEC. Although the picture is far from complete, it appears that these layers contain robust recurrent connectivity that could sustain the attractor dynamics posited to underlie grid pattern formation. These findings pave the way to a deeper understanding of the mechanisms underlying spatial navigation and memory.},
	language = {en},
	number = {2},
	journal = {Physiol. Rev.},
	author = {Tukker, John J and Beed, Prateep and Brecht, Michael and Kempter, Richard and Moser, Edvard I and Schmitz, Dietmar},
	month = apr,
	year = {2022},
	keywords = {entorhinal cortex, grid cells, navigation, connectivity, microcircuits},
	pages = {653--688},
}

@misc{ray_complementary_2017,
	title = {Complementary {Modular} {Microcircuits} of the {Rat} {Medial} {Entorhinal} {Cortex}},
	author = {Ray, Saikat and Burgalossi, Andrea and Brecht, Michael and Naumann, Robert K},
	year = {2017},
	note = {Publication Title: Frontiers in Systems Neuroscience
Volume: 11},
}

@article{schmidt_axonal_2017,
	title = {Axonal synapse sorting in medial entorhinal cortex},
	volume = {549},
	abstract = {Research on neuronal connectivity in the cerebral cortex has focused on the existence and strength of synapses between neurons, and their location on the cell bodies and dendrites of postsynaptic neurons. The synaptic architecture of individual presynaptic axonal trees, however, remains largely unknown. Here we used dense reconstructions from three-dimensional electron microscopy in rats to study the synaptic organization of local presynaptic axons in layer 2 of the medial entorhinal cortex, the site of grid-like spatial representations. We observe path-length-dependent axonal synapse sorting, such that axons of excitatory neurons sequentially target inhibitory neurons followed by excitatory neurons. Connectivity analysis revealed a cellular feedforward inhibition circuit involving wide, myelinated inhibitory axons and dendritic synapse clustering. Simulations show that this high-precision circuit can control the propagation of synchronized activity in the medial entorhinal cortex, which is known for temporally precise discharges.},
	language = {en},
	number = {7673},
	journal = {Nature},
	author = {Schmidt, Helene and Gour, Anjali and Straehle, Jakob and Boergens, Kevin M and Brecht, Michael and Helmstaedter, Moritz},
	month = sep,
	year = {2017},
	pages = {469--475},
}

@misc{schaffer_odor_2018,
	title = {Odor {Perception} on the {Two} {Sides} of the {Brain}: {Consistency} {Despite} {Randomness}},
	author = {Schaffer, Evan S and Stettler, Dan D and Kato, Daniel and Choi, Gloria B and Axel, Richard and Abbott, L F},
	year = {2018},
	note = {Issue: 4
Pages: 736–742.e3
Publication Title: Neuron
Volume: 98},
}

@article{caron_random_2013,
	title = {Random convergence of olfactory inputs in the {Drosophila} mushroom body},
	volume = {497},
	abstract = {The mushroom body in the fruitfly Drosophila melanogaster is an associative brain centre that translates odour representations into learned behavioural responses. Kenyon cells, the intrinsic neurons of the mushroom body, integrate input from olfactory glomeruli to encode odours as sparse distributed patterns of neural activity. We have developed anatomic tracing techniques to identify the glomerular origin of the inputs that converge onto 200 individual Kenyon cells. Here we show that each Kenyon cell integrates input from a different and apparently random combination of glomeruli. The glomerular inputs to individual Kenyon cells show no discernible organization with respect to their odour tuning, anatomic features or developmental origins. Moreover, different classes of Kenyon cells do not seem to preferentially integrate inputs from specific combinations of glomeruli. This organization of glomerular connections to the mushroom body could allow the fly to contextualize novel sensory experiences, a feature consistent with the role of this brain centre in mediating learned olfactory associations and behaviours.},
	language = {en},
	number = {7447},
	journal = {Nature},
	author = {Caron, Sophie J C and Ruta, Vanessa and Abbott, L F and Axel, Richard},
	month = may,
	year = {2013},
	pages = {113--117},
}

@article{wang_gamma_1996-1,
	title = {Gamma oscillation by synaptic inhibition in a hippocampal interneuronal network model},
	volume = {16},
	abstract = {Fast neuronal oscillations (gamma, 20-80 Hz) have been observed in the neocortex and hippocampus during behavioral arousal. Using computer simulations, we investigated the hypothesis that such rhythmic activity can emerge in a random network of interconnected GABAergic fast-spiking interneurons. Specific conditions for the population synchronization, on properties of single cells and the circuit, were identified. These include the following: (1) that the amplitude of spike afterhyperpolarization be above the GABAA synaptic reversal potential; (2) that the ratio between the synaptic decay time constant and the oscillation period be sufficiently large; (3) that the effects of heterogeneities be modest because of a steep frequency-current relationship of fast-spiking neurons. Furthermore, using a population coherence measure, based on coincident firings of neural pairs, it is demonstrated that large-scale network synchronization requires a critical (minimal) average number of synaptic contacts per cell, which is not sensitive to the network size. By changing the GABAA synaptic maximal conductance, synaptic decay time constant, or the mean external excitatory drive to the network, the neuronal firing frequencies were gradually and monotonically varied. By contrast, the network synchronization was found to be high only within a frequency band coinciding with the gamma (20-80 Hz) range. We conclude that the GABAA synaptic transmission provides a suitable mechanism for synchronized gamma oscillations in a sparsely connected network of fast-spiking interneurons. In turn, the interneuronal network can presumably maintain subthreshold oscillations in principal cell populations and serve to synchronize discharges of spatially distributed neurons.},
	language = {en},
	number = {20},
	journal = {J. Neurosci.},
	author = {Wang, X J and Buzsáki, G},
	month = oct,
	year = {1996},
	pages = {6402--6413},
}

@article{csicsvari_mechanisms_2003-1,
	title = {Mechanisms of {Gamma} {Oscillations} in the {Hippocampus} of the {Behaving} {Rat}},
	volume = {37},
	abstract = {AbstractGamma frequency oscillations (30–100 Hz) have been suggested to underlie various cognitive and motor functions. Here, we examine the generation of gamma oscillation currents in the hippocampus, using two-dimensional, 96-site silicon probes. Two gamma generators were identified, one in the dentate gyrus and another in the CA3-CA1 regions. The coupling strength between the two oscillators varied during both theta and nontheta states. Both pyramidal cells and interneurons were phase-locked to gamma waves. Anatomical connectivity, rather than physical distance, determined the coupling strength of the oscillating neurons. CA3 pyramidal neurons discharged CA3 and CA1 interneurons at latencies indicative of monosynaptic connections. Intrahippocampal gamma oscillation emerges in the CA3 recurrent system, which entrains the CA1 region via its interneurons.},
	language = {en},
	number = {2},
	journal = {Neuron},
	author = {Csicsvari, Jozsef and Jamieson, Brian and Wise, Kensall D and Buzsáki, György},
	month = jan,
	year = {2003},
	note = {Publisher: Elsevier},
	pages = {311--322},
}

@article{buzsaki_mechanisms_2012,
	title = {Mechanisms of gamma oscillations},
	volume = {35},
	abstract = {Gamma rhythms are commonly observed in many brain regions during both waking and sleep states, yet their functions and mechanisms remain a matter of debate. Here we review the cellular and synaptic mechanisms underlying gamma oscillations and outline empirical questions and controversial conceptual issues. Our main points are as follows: First, gamma-band rhythmogenesis is inextricably tied to perisomatic inhibition. Second, gamma oscillations are short-lived and typically emerge from the coordinated interaction of excitation and inhibition, which can be detected as local field potentials. Third, gamma rhythm typically concurs with irregular firing of single neurons, and the network frequency of gamma oscillations varies extensively depending on the underlying mechanism. To document gamma oscillations, efforts should be made to distinguish them from mere increases of gamma-band power and/or increased spiking activity. Fourth, the magnitude of gamma oscillation is modulated by slower rhythms. Such cross-frequency coupling may serve to couple active patches of cortical circuits. Because of their ubiquitous nature and strong correlation with the “operational modes” of local circuits, gamma oscillations continue to provide important clues about neuronal population dynamics in health and disease.},
	language = {en},
	journal = {Annu. Rev. Neurosci.},
	author = {Buzsáki, György and Wang, Xiao-Jing},
	month = mar,
	year = {2012},
	pages = {203--225},
}

@article{colgin_gamma_2010,
	title = {Gamma oscillations in the hippocampus},
	volume = {25},
	abstract = {Gamma oscillations are thought to temporally link the activity of distributed cells. We discuss mechanisms of gamma oscillations in the hippocampus and review evidence supporting a functional role for such oscillations in several key hippocampal operations, including cell grouping, dynamic routing, and memory. We propose that memory encoding and retrieval are coordinated by different frequencies of hippocampal gamma oscillations and suggest how transitions between slow and fast gamma may occur.},
	language = {en},
	number = {5},
	journal = {Physiology},
	author = {Colgin, Laura Lee and Moser, Edvard I},
	month = oct,
	year = {2010},
	pages = {319--329},
}

@article{wulff_hippocampal_2009,
	title = {Hippocampal theta rhythm and its coupling with gamma oscillations require fast inhibition onto parvalbumin-positive interneurons},
	volume = {106},
	abstract = {Hippocampal theta (5-10 Hz) and gamma (35-85 Hz) oscillations depend on an inhibitory network of GABAergic interneurons. However, the lack of methods for direct and cell-type-specific interference with inhibition has prevented better insights that help link synaptic and cellular properties with network function. Here, we generated genetically modified mice (PV-Deltagamma(2)) in which synaptic inhibition was ablated in parvalbumin-positive (PV+) interneurons. Hippocampal local field potential and unit recordings in the CA1 area of freely behaving mice revealed that theta rhythm was strongly reduced in these mice. The characteristic coupling of theta and gamma oscillations was strongly altered in PV-Deltagamma(2) mice more than could be accounted for by the reduction in theta rhythm only. Surprisingly, gamma oscillations were not altered. These data indicate that synaptic inhibition onto PV+ interneurons is indispensable for theta- and its coupling to gamma oscillations but not for rhythmic gamma-activity in the hippocampus. Similar alterations in rhythmic activity were obtained in a computational hippocampal network model mimicking the genetic modification, suggesting that intrahippocampal networks might contribute to these effects.},
	language = {en},
	number = {9},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Wulff, Peer and Ponomarenko, Alexey A and Bartos, Marlene and Korotkova, Tatiana M and Fuchs, Elke C and Bähner, Florian and Both, Martin and Tort, Adriano B L and Kopell, Nancy J and Wisden, William and Monyer, Hannah},
	month = mar,
	year = {2009},
	pages = {3561--3566},
}

@article{aviel_embedding_2003,
	title = {On embedding synfire chains in a balanced network},
	volume = {15},
	abstract = {We investigate the formation of synfire waves in a balanced network of integrate-and-fire neurons. The synaptic connectivity of this network embodies synfire chains within a sparse random connectivity. This network can exhibit global oscillations but can also operate in an asynchronous activity mode. We analyze the correlations of two neurons in a pool as convenient indicators for the state of the network. We find, using different models, that these indicators depend on a scaling variable. Beyond a critical point, strong correlations and large network oscillations are obtained. We looked for the conditions under which a synfire wave could be propagated on top of an otherwise asynchronous state of the network. This condition was found to be highly restrictive, requiring a large number of neurons for its implementation in our network. The results are based on analytic derivations and simulations.},
	language = {en},
	number = {6},
	journal = {Neural Comput.},
	author = {Aviel, Y and Mehring, C and Abeles, M and Horn, D},
	month = jun,
	year = {2003},
	pages = {1321--1340},
}

@article{rajan_recurrent_2016,
	title = {Recurrent {Network} {Models} of {Sequence} {Generation} and {Memory}},
	volume = {90},
	abstract = {Sequential activation of neurons is a common feature of network activity during a variety of behaviors, including working memory and decision making. Previous network models for sequences and memory emphasized specialized architectures in which a principled mechanism is pre-wired into their connectivity. Here we demonstrate that, starting from random connectivity and modifying a small fraction of connections, a largely disordered recurrent network can produce sequences and implement working memory efficiently. We use this process, called Partial In-Network Training (PINning), to model and match cellular resolution imaging data from the posterior parietal cortex during a virtual memory-guided two-alternative forced-choice task. Analysis of the connectivity reveals that sequences propagate by the cooperation between recurrent synaptic interactions and external inputs, rather than through feedforward or asymmetric connections. Together our results suggest that neural sequences may emerge through learning from largely unstructured network architectures.},
	language = {en},
	number = {1},
	journal = {Neuron},
	author = {Rajan, Kanaka and Harvey, Christopher D and Tank, David W},
	month = apr,
	year = {2016},
	pages = {128--142},
}

@unpublished{ohara_hippocampal-medial_2022,
	title = {Hippocampal-medial entorhinal circuit is differently organized along the dorsoventral axis in rodents},
	abstract = {The general understanding of hippocampal circuits is that the hippocampus and the entorhinal cortex (EC) are topographically connected through parallel identical circuits along the dorsoventral axis. Our anterograde tracing and in vitro electrophysiology data, however, show a markedly different dorsoventral organization of the hippocampal projection to the medial EC (MEC). Whereas dorsal hippocampal projections are confined to the dorsal MEC and preferentially target layer Vb (LVb) over layer Va (LVa) neurons, the ventral hippocampus innervates the entire dorsoventral extent of MEC. In the ventral MEC, these projections innervate neurons in both LVa and LVb. In contrast, in the dorsal MEC, ventral hippocampal projections target mainly LVa neurons. As LVa neurons project to telencephalic structures, our findings indicate that the ventral hippocampus regulates LVa-mediated entorhinal-neocortical output from both the dorsal and ventral MEC. Overall, the marked dorsoventral differences in hippocampal-entorhinal connectivity impose important constraints on signal flow in hippocampal-neocortical circuits. \#\#\# Competing Interest Statement The authors have declared no competing interest.},
	language = {en},
	author = {Ohara, Shinya and Rannap, Märt and Tsutsui, Ken-Ichiro and Draguhn, Andreas and Egorov, Alexei V and Witter, Menno P},
	month = may,
	year = {2022},
	note = {Publication Title: bioRxiv},
}

@misc{mosheiff_velocity_nodate,
	title = {Velocity coupling of grid cell modules: stable embedding of a low dimensional variable in a high dimensional neural attractor},
	author = {Mosheiff, Noga and Burak, Yoram},
}

@inproceedings{le_gorrec_uncovering_2020,
	title = {Uncovering {Hidden} {Block} {Structure} for {Clustering}},
	abstract = {We present a multistage procedure to cluster directed and undirected weighted graphs by finding the block structure of their adjacency matrices. A central part of the process is to scale the adjacency matrix into a doubly-stochastic form, which permits detection of the whole matrix block structure with minimal spectral information (theoretically a single pair of singular vectors suffices).},
	booktitle = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}},
	publisher = {Springer International Publishing},
	author = {le Gorrec, Luce and Mouysset, Sandrine and Duff, Iain S and Knight, Philip A and Ruiz, Daniel},
	year = {2020},
	pages = {140--155},
}

@misc{yang_overlapping_nodate,
	title = {Overlapping community detection at scale: {A} nonnegative matrix factorization approach},
	url = {http://i.stanford.edu/ crucis/pubs/paper-nmfagm.pdf},
	abstract = {Network communities represent basic structures for understanding the organization of real-world networks. A community (also referred to as a module or a cluster) is typically thought of as a group of nodes with more connections amongst its members than between its members and the remainder of the network. Communities in networks also overlap as nodes belong to multiple clusters at once. Due to the difficulties in evaluating the detected communities and the lack of scalable algorithms, the task of overlapping community detection in large networks largely remains an open problem. In this paper we present BIGCLAM (Cluster Affiliation Model for Big Networks), an overlapping community detection method that scales to large networks of millions of nodes and edges. We build on a novel observation that overlaps between communities are densely connected. This is in sharp contrast with present community detection methods which implicitly assume that overlaps between communities are sparsely connected and thus cannot properly extract overlapping communities in networks. In this paper, we develop a model-based community detection algorithm that can detect densely overlapping, hierarchically nested as well as nonoverlapping communities in massive networks. We evaluate our algorithm on 6 large social, collaboration and information networks with ground-truth community information. Experiments show state of the art performance both in terms of the quality of detected communities as well as in speed and scalability of our algorithm.},
	author = {Yang, Jaewon and Leskovec, Jure},
}

@article{psorakis_overlapping_nodate,
	title = {Overlapping {Community} {Detection} using {Bayesian} {Nonnegative} {Matrix} {Factorization}},
	author = {Psorakis, Ioannis and Roberts, Stephen and Ebden, Mark},
}

@article{traag_louvain_2019,
	title = {From {Louvain} to {Leiden}: guaranteeing well-connected communities},
	volume = {9},
	abstract = {Community detection is often used to understand the structure of large and complex networks. One of the most popular algorithms for uncovering community structure is the so-called Louvain algorithm. We show that this algorithm has a major defect that largely went unnoticed until now: the Louvain algorithm may yield arbitrarily badly connected communities. In the worst case, communities may even be disconnected, especially when running the algorithm iteratively. In our experimental analysis, we observe that up to 25\% of the communities are badly connected and up to 16\% are disconnected. To address this problem, we introduce the Leiden algorithm. We prove that the Leiden algorithm yields communities that are guaranteed to be connected. In addition, we prove that, when the Leiden algorithm is applied iteratively, it converges to a partition in which all subsets of all communities are locally optimally assigned. Furthermore, by relying on a fast local move approach, the Leiden algorithm runs faster than the Louvain algorithm. We demonstrate the performance of the Leiden algorithm for several benchmark and real-world networks. We find that the Leiden algorithm is faster than the Louvain algorithm and uncovers better partitions, in addition to providing explicit guarantees.},
	language = {en},
	number = {1},
	journal = {Sci. Rep.},
	author = {Traag, V A and Waltman, L and van Eck, N J},
	month = mar,
	year = {2019},
	pages = {5233},
}

@article{hunt_novel_2018,
	title = {A novel pyramidal cell type promotes sharp-wave synchronization in the hippocampus},
	volume = {21},
	abstract = {To support cognitive function, the CA3 region of the hippocampus performs computations involving attractor dynamics. Understanding how cellular and ensemble activities of CA3 neurons enable computation is critical for elucidating the neural correlates of cognition. Here we show that CA3 comprises not only classically described pyramid cells with thorny excrescences, but also includes previously unidentified 'athorny' pyramid cells that lack mossy-fiber input. Moreover, the two neuron types have distinct morphological and physiological phenotypes and are differentially modulated by acetylcholine. To understand the contribution of these athorny pyramid neurons to circuit function, we measured cell-type-specific firing patterns during sharp-wave synchronization events in vivo and recapitulated these dynamics with an attractor network model comprising two principal cell types. Our data and simulations reveal a key role for athorny cell bursting in the initiation of sharp waves: transient network attractor states that signify the execution of pattern completion computations vital to cognitive function.},
	language = {en},
	number = {7},
	journal = {Nat. Neurosci.},
	author = {Hunt, David L and Linaro, Daniele and Si, Bailu and Romani, Sandro and Spruston, Nelson},
	month = jul,
	year = {2018},
	pages = {985--995},
}

@article{lee_causal_2016,
	title = {Causal {Evidence} for the {Role} of {Specific} {GABAergic} {Interneuron} {Types} in {Entorhinal} {Recruitment} of {Dentate} {Granule} {Cells}},
	volume = {6},
	abstract = {The dentate gyrus (DG) is the primary gate of the hippocampus and controls information flow from the cortex to the hippocampus proper. To maintain normal function, granule cells (GCs), the principal neurons in the DG, receive fine-tuned inhibition from local-circuit GABAergic inhibitory interneurons (INs). Abnormalities of GABAergic circuits in the DG are associated with several brain disorders, including epilepsy, autism, schizophrenia, and Alzheimer disease. Therefore, understanding the network mechanisms of inhibitory control of GCs is of functional and pathophysiological importance. GABAergic inhibitory INs are heterogeneous, but it is unclear how individual subtypes contribute to GC activity. Using cell-type-specific optogenetic perturbation, we investigated whether and how two major IN populations defined by parvalbumin (PV) and somatostatin (SST) expression, regulate GC input transformations. We showed that PV-expressing (PV+) INs, and not SST-expressing (SST+) INs, primarily suppress GC responses to single cortical stimulation. In addition, these two IN classes differentially regulate GC responses to ϑ and γ frequency inputs from the cortex. Notably, PV+ INs specifically control the onset of the spike series, whereas SST+ INs preferentially regulate the later spikes in the series. Together, PV+ and SST+ GABAergic INs engage differentially in GC input-output transformations in response to various activity patterns.},
	language = {en},
	journal = {Sci. Rep.},
	author = {Lee, Cheng-Ta and Kao, Min-Hua and Hou, Wen-Hsien and Wei, Yu-Ting and Chen, Chin-Lin and Lien, Cheng-Chang},
	month = nov,
	year = {2016},
	pages = {36885},
}

@article{hsu_differential_2016,
	title = {Differential {Recruitment} of {Dentate} {Gyrus} {Interneuron} {Types} by {Commissural} {Versus} {Perforant} {Pathways}},
	volume = {26},
	abstract = {Gamma-aminobutyric acidergic (GABAergic) interneurons (INs) in the dentate gyrus (DG) provide inhibitory control to granule cell (GC) activity and thus gate incoming signals to the hippocampus. However, how various IN subtypes inhibit GCs in response to different excitatory input pathways remains mostly unknown. By using electrophysiology and optogenetics, we investigated neurotransmission of the hilar commissural pathway (COM) and the medial perforant path (MPP) to the DG in acutely prepared mouse slices. We found that the short-term dynamics of excitatory COM-GC and MPP-GC synapses was similar, but that the dynamics of COM- and MPP-mediated inhibition measured in GCs was remarkably different, during theta-frequency stimulation. This resulted in the increased inhibition-excitation (I/E) ratios in single GCs for COM stimulation, but decreased I/E ratios for MPP stimulation. Further analysis of pathway-specific responses in identified INs revealed that basket cell-like INs, total molecular layer- and molecular layer-like cells, received greater excitation and were more reliably recruited by the COM than by the MPP inputs. In contrast, hilar perforant path-associated and hilar commissural-associational pathway-related-like cells were minimally activated by both inputs. These results demonstrate that distinct IN subtypes are preferentially recruited by different inputs to the DG, and reveal their relative contributions in COM-mediated feedforward inhibition.},
	language = {en},
	number = {6},
	journal = {Cereb. Cortex},
	author = {Hsu, Tsan-Ting and Lee, Cheng-Ta and Tai, Ming-Hong and Lien, Cheng-Chang},
	month = jun,
	year = {2016},
	keywords = {inhibition, optogenetics, GABA, granule cell, mossy cell},
	pages = {2715--2727},
}

@article{degro_interneuron_2022,
	title = {Interneuron diversity in the rat dentate gyrus: {An} unbiased in vitro classification},
	volume = {32},
	abstract = {Information processing in cortical circuits, including the hippocampus, relies on the dynamic control of neuronal activity by GABAergic interneurons (INs). INs form a heterogenous population with defined types displaying distinct morphological, molecular, and physiological characteristics. In the major input region of the hippocampus, the dentate gyrus (DG), a number of IN types have been described which provide synaptic inhibition to distinct compartments of excitatory principal cells (PrCs) and other INs. In this study, we perform an unbiased classification of GABAergic INs in the DG by combining in vitro whole-cell patch-clamp recordings, intracellular labeling, morphological analysis, and unsupervised cluster analysis to better define IN type diversity in this region. This analysis reveals that DG INs divide into at least 13 distinct morpho-physiological types which reflect the complexity of the local IN network and serve as a basis for further network analyses.},
	language = {en},
	number = {4},
	journal = {Hippocampus},
	author = {Degro, Claudius E and Bolduan, Felix and Vida, Imre and Booker, Sam A},
	month = apr,
	year = {2022},
	keywords = {inhibition, GABA, interneuron, cluster analysis, dentate gyrus, neuron diversity},
	pages = {310--331},
}

@article{condylis_dense_2022,
	title = {Dense functional and molecular readout of a circuit hub in sensory cortex},
	volume = {375},
	abstract = {Although single-cell transcriptomics of the neocortex has uncovered more than 300 putative cell types, whether this molecular classification predicts distinct functional roles is unclear. We combined two-photon calcium imaging with spatial transcriptomics to functionally and molecularly investigate cortical circuits. We characterized behavior-related responses across major neuronal subclasses in layers 2 or 3 of the primary somatosensory cortex as mice performed a tactile working memory task. We identified an excitatory intratelencephalic cell type, Baz1a, that exhibits high tactile feature selectivity. Baz1a neurons homeostatically maintain stimulus responsiveness during altered experience and show persistent enrichment of subsets of immediately early genes. Functional and anatomical connectivity reveals that Baz1a neurons residing in upper portions of layers 2 or 3 preferentially innervate somatostatin-expressing inhibitory neurons. This motif defines a circuit hub that orchestrates local sensory processing in superficial layers of the neocortex.},
	language = {en},
	number = {6576},
	journal = {Science},
	author = {Condylis, Cameron and Ghanbari, Abed and Manjrekar, Nikita and Bistrong, Karina and Yao, Shenqin and Yao, Zizhen and Nguyen, Thuc Nghi and Zeng, Hongkui and Tasic, Bosiljka and Chen, Jerry L},
	month = jan,
	year = {2022},
	pages = {eabl5981},
}

@article{de_almeida_memory_2007,
	title = {Memory retrieval time and memory capacity of the {CA3} network: role of gamma frequency oscillations},
	volume = {14},
	abstract = {The existence of recurrent synaptic connections in CA3 led to the hypothesis that CA3 is an autoassociative network similar to the Hopfield networks studied by theorists. CA3 undergoes gamma frequency periodic inhibition that prevents a persistent attractor state. This argues against the analogy to Hopfield nets, in which an attractor state can be used for working memory. However, we show that such periodic inhibition allows one cycle of recurrent excitatory activity and that this is sufficient for memory retrieval (within milliseconds). Thus, gamma oscillations are compatible with a long-term autoassociative memory function for CA3. A second goal of our work was to evaluate previous methods for estimating the memory capacity (P) of CA3. We confirm the equation, P = c/a(2), where c is the probability that any two cells are recurrently connected and a is the fraction of cells representing a memory item. In applying this to CA3, we focus on CA3a, the subregion where recurrent connections are most numerous (c = 0.2) and approximate randomness. We estimate that a memory item is represented by approximately 225 of the 70,000 neurons in CA3a (a = 0.003) and that approximately 20,000 memory items can be stored. Our general conclusion is that the physiological and anatomical findings of CA3a are consistent with an autoassociative function. The nature of the information that is associated in CA3a is discussed. We also discuss how the autoassociative properties of CA3 and the heteroassociative properties of dentate synapses (linking sequential memories) form an integrated system for the storage and recall of item sequences. The recall process generates the phase precession in dentate, CA3, and entorhinal cortex.},
	language = {en},
	number = {11},
	journal = {Learn. Mem.},
	author = {de Almeida, Licurgo and Idiart, Marco and Lisman, John E},
	month = nov,
	year = {2007},
	pages = {795--806},
}

@article{de_almeida_single_2012,
	title = {The single place fields of {CA3} cells: a two-stage transformation from grid cells},
	volume = {22},
	abstract = {Granule cells of the dentate gyrus (DG) generally have multiple place fields, whereas CA3 cells, which are second order, have only a single place field. Here, we explore the mechanisms by which the high selectivity of CA3 cells is achieved. Previous work showed that the multiple place fields of DG neurons could be quantitatively accounted for by a model based on the number and strength of grid cell inputs and a competitive network interaction in the DG that is mediated by gamma frequency feedback inhibition. We have now built a model of CA3 based on similar principles. CA3 cells receive input from an average of one active DG cell and from 1,400 cortical grid cells. Based on experimental findings, we have assumed a linear interaction of the two pathways. The results show that simulated CA3 cells generally have a single place field, as observed experimentally. Thus, a two-step process based on simple rules (and that can occur without learning) is able to explain how grid cell inputs to the hippocampus give rise to cells having ultimate spatial selectivity. The CA3 processes that produce a single place depend critically on the competitive network processes and do not require the direct cortical inputs to CA3, which are therefore likely to perform some other unknown function.},
	language = {en},
	number = {2},
	journal = {Hippocampus},
	author = {de Almeida, Licurgo and Idiart, Marco and Lisman, John E},
	month = feb,
	year = {2012},
	pages = {200--208},
}

@article{naumann_conserved_2016,
	title = {Conserved size and periodicity of pyramidal patches in layer 2 of medial/caudal entorhinal cortex},
	volume = {524},
	abstract = {To understand the structural basis of grid cell activity, we compare medial entorhinal cortex architecture in layer 2 across five mammalian species (Etruscan shrews, mice, rats, Egyptian fruit bats, and humans), bridging ∼100 million years of evolutionary diversity. Principal neurons in layer 2 are divided into two distinct cell types, pyramidal and stellate, based on morphology, immunoreactivity, and functional properties. We confirm the existence of patches of calbindin-positive pyramidal cells across these species, arranged periodically according to analyses techniques like spatial autocorrelation, grid scores, and modifiable areal unit analysis. In rodents, which show sustained theta oscillations in entorhinal cortex, cholinergic innervation targeted calbindin patches. In bats and humans, which only show intermittent entorhinal theta activity, cholinergic innervation avoided calbindin patches. The organization of calbindin-negative and calbindin-positive cells showed marked differences in entorhinal subregions of the human brain. Layer 2 of the rodent medial and the human caudal entorhinal cortex were structurally similar in that in both species patches of calbindin-positive pyramidal cells were superimposed on scattered stellate cells. The number of calbindin-positive neurons in a patch increased from ∼80 in Etruscan shrews to ∼800 in humans, only an ∼10-fold over a 20,000-fold difference in brain size. The relatively constant size of calbindin patches differs from cortical modules such as barrels, which scale with brain size. Thus, selective pressure appears to conserve the distribution of stellate and pyramidal cells, periodic arrangement of calbindin patches, and relatively constant neuron number in calbindin patches in medial/caudal entorhinal cortex.},
	language = {en},
	number = {4},
	journal = {J. Comp. Neurol.},
	author = {Naumann, Robert K and Ray, Saikat and Prokop, Stefan and Las, Liora and Heppner, Frank L and Brecht, Michael},
	month = mar,
	year = {2016},
	keywords = {calbindin-positive pyramidal neuron patches, conserved patch size and cell number per patch, grid-like arrangement of patches in layer 2, variable patch number and cholinergic innervation pattern},
	pages = {783--806},
}

@article{turner-evans_angular_2017,
	title = {Angular velocity integration in a fly heading circuit},
	volume = {6},
	abstract = {Many animals maintain an internal representation of their heading as they move through their surroundings. Such a compass representation was recently discovered in a neural population in the Drosophila melanogaster central complex, a brain region implicated in spatial navigation. Here, we use two-photon calcium imaging and electrophysiology in head-fixed walking flies to identify a different neural population that conjunctively encodes heading and angular velocity, and is excited selectively by turns in either the clockwise or counterclockwise direction. We show how these mirror-symmetric turn responses combine with the neurons' connectivity to the compass neurons to create an elegant mechanism for updating the fly's heading representation when the animal turns in darkness. This mechanism, which employs recurrent loops with an angular shift, bears a resemblance to those proposed in theoretical models for rodent head direction cells. Our results provide a striking example of structure matching function for a broadly relevant computation.},
	language = {en},
	journal = {Elife},
	author = {Turner-Evans, Daniel and Wegener, Stephanie and Rouault, Hervé and Franconville, Romain and Wolff, Tanya and Seelig, Johannes D and Druckmann, Shaul and Jayaraman, Vivek},
	month = may,
	year = {2017},
	keywords = {electrophysiology, neural circuits, neuroscience, navigation, D. melanogaster, internal representation, modeling, two-photon calcium imaging},
}

@article{naumann_structural_2018,
	title = {Structural modularity and grid activity in the medial entorhinal cortex},
	volume = {119},
	abstract = {Following the groundbreaking discovery of grid cells, the medial entorhinal cortex (MEC) has become the focus of intense anatomical, physiological, and computational investigations. Whether and how grid activity maps onto cell types and cortical architecture is still an open question. Fundamental similarities in microcircuits, function, and connectivity suggest a homology between rodent MEC and human posteromedial entorhinal cortex. Both are specialized for spatial processing and display similar cellular organization, consisting of layer 2 pyramidal/calbindin cell patches superimposed on scattered stellate neurons. Recent data indicate the existence of a further nonoverlapping modular system (zinc patches) within the superficial MEC layers. Zinc and calbindin patches have been shown to receive largely segregated inputs from the presubiculum and parasubiculum. Grid cells are also clustered in the MEC, and we discuss possible structure-function schemes on how grid activity could map onto cortical patch systems. We hypothesize that in the superficial layers of the MEC, anatomical location can be predictive of function; thus relating functional properties and neuronal morphologies to the cortical modules will be necessary for resolving how grid activity maps onto cortical architecture. Imaging or cell identification approaches in freely moving animals will be required for testing this hypothesis.},
	language = {en},
	number = {6},
	journal = {J. Neurophysiol.},
	author = {Naumann, Robert K and Preston-Ferrer, Patricia and Brecht, Michael and Burgalossi, Andrea},
	month = jun,
	year = {2018},
	note = {Publisher: American Physiological Society},
	pages = {2129--2144},
}

@article{ray_structural_2016,
	title = {Structural development and dorsoventral maturation of the medial entorhinal cortex},
	volume = {5},
	abstract = {We investigated the structural development of superficial-layers of medial entorhinal cortex and parasubiculum in rats. The grid-layout and cholinergic-innervation of calbindin-positive pyramidal-cells in layer-2 emerged around birth while reelin-positive stellate-cells were scattered throughout development. Layer-3 and parasubiculum neurons had a transient calbindin-expression, which declined with age. Early postnatally, layer-2 pyramidal but not stellate-cells co-localized with doublecortin - a marker of immature neurons - suggesting delayed functional-maturation of pyramidal-cells. Three observations indicated a dorsal-to-ventral maturation of entorhinal cortex and parasubiculum: (i) calbindin-expression in layer-3 neurons decreased progressively from dorsal-to-ventral, (ii) doublecortin in layer-2 calbindin-positive-patches disappeared dorsally before ventrally, and (iii) wolframin-expression emerged earlier in dorsal than ventral parasubiculum. The early appearance of calbindin-pyramidal-grid-organization in layer-2 suggests that this pattern is instructed by genetic information rather than experience. Superficial-layer-microcircuits mature earlier in dorsal entorhinal cortex, where small spatial-scales are represented. Maturation of ventral-entorhinal-microcircuits - representing larger spatial-scales - follows later around the onset of exploratory behavior.},
	language = {en},
	journal = {Elife},
	author = {Ray, Saikat and Brecht, Michael},
	month = apr,
	year = {2016},
	keywords = {neuroscience, rat, medial entorhinal cortex, calbindin patches, doublecortin, immature neurons, parasubiculum, pyramidal neurons},
	pages = {e13343},
}

@article{chaudhuri_intrinsic_2019-2,
	title = {The intrinsic attractor manifold and population dynamics of a canonical cognitive circuit across waking and sleep},
	volume = {22},
	abstract = {Neural circuits construct distributed representations of key variables-external stimuli or internal constructs of quantities relevant for survival, such as an estimate of one's location in the world-as vectors of population activity. Although population activity vectors may have thousands of entries (dimensions), we consider that they trace out a low-dimensional manifold whose dimension and topology match the represented variable. This manifold perspective enables blind discovery and decoding of the represented variable using only neural population activity (without knowledge of the input, output, behavior or topography). We characterize and directly visualize manifold structure in the mammalian head direction circuit, revealing that the states form a topologically nontrivial one-dimensional ring. The ring exhibits isometry and is invariant across waking and rapid eye movement sleep. This result directly demonstrates that there are continuous attractor dynamics and enables powerful inference about mechanism. Finally, external rather than internal noise limits memory fidelity, and the manifold approach reveals new dynamical trajectories during sleep.},
	language = {en},
	number = {9},
	journal = {Nat. Neurosci.},
	author = {Chaudhuri, Rishidev and Gerçek, Berk and Pandey, Biraj and Peyrache, Adrien and Fiete, Ila},
	month = sep,
	year = {2019},
	pages = {1512--1520},
}

@article{chaudhuri_intrinsic_2019-3,
	title = {The intrinsic attractor manifold and population dynamics of a canonical cognitive circuit across waking and sleep},
	volume = {22},
	abstract = {Neural circuits construct distributed representations of key variables—external stimuli or internal constructs of quantities relevant for survival, such as an estimate of one's location in the world—as vectors of population activity. Although population activity vectors may have thousands of entries (dimensions), we consider that they trace out a low-dimensional manifold whose dimension and topology match the represented variable. This manifold perspective enables blind discovery and decoding of the represented variable using only neural population activity (without knowledge of the input, output, behavior or topography). We characterize and directly visualize manifold structure in the mammalian head direction circuit, revealing that the states form a topologically nontrivial one-dimensional ring. The ring exhibits isometry and is invariant across waking and rapid eye movement sleep. This result directly demonstrates that there are continuous attractor dynamics and enables powerful inference about mechanism. Finally, external rather than internal noise limits memory fidelity, and the manifold approach reveals new dynamical trajectories during sleep. Neural populations often encode unknown variables. Chaudhuri et al. develop a method to decode unknown variables by finding shapes in neural data. They show that a mammalian brain circuit of thousands of neurons constructs a navigational compass with only a one-dimensional ring of stable activity states.},
	language = {en},
	number = {9},
	journal = {Nat. Neurosci.},
	author = {Chaudhuri, Rishidev and Gerçek, Berk and Pandey, Biraj and Peyrache, Adrien and Fiete, Ila},
	month = aug,
	year = {2019},
	note = {Publisher: Nature Publishing Group},
	pages = {1512--1520},
}

@article{kim_superlinear_2020,
	title = {Superlinear {Precision} and {Memory} in {Simple} {Population} {Codes}},
	abstract = {It is found that the optimal tuning curve width for coding no longer scales as the inverse population size, and the quadratic scaling of precision with system size predicted by Fisher information alone no longer holds, however, superlinearity is still preserved with only a logarithmic slowdown. The brain constructs population codes to represent stimuli through widely distributed patterns of activity across neurons. An important figure of merit of population codes is how much information about the original stimulus can be decoded from them. Fisher information is widely used to quantify coding precision and specify optimal codes, because of its relationship to mean squared error (MSE) under certain assumptions. When neural firing is sparse, however, optimizing Fisher information can result in codes that are highly sub-optimal in terms of MSE. We find that this discrepancy arises from the non-local component of error not accounted for by the Fisher information. Using this insight, we construct optimal population codes by directly minimizing the MSE. We study the scaling properties of MSE with coding parameters, focusing on the tuning curve width. We find that the optimal tuning curve width for coding no longer scales as the inverse population size, and the quadratic scaling of precision with system size predicted by Fisher information alone no longer holds. However, superlinearity is still preserved with only a logarithmic slowdown. We derive analogous results for networks storing the memory of a stimulus through continuous attractor dynamics, and show that similar scaling properties optimize memory and representation.},
	language = {en},
	journal = {https://www.semanticscholar.org › paper › Superlinear-Pr...https://www.semanticscholar.org › paper › Superlinear-Pr...},
	author = {Kim, Jimmy H J and Fiete, I and Schwab, D},
	year = {2020},
}

@article{mckee_locally_2021,
	title = {Locally {Learned} {Synaptic} {Dropout} for {Complete} {Bayesian} {Inference}},
	abstract = {The Bayesian brain hypothesis postulates that the brain accurately operates on statistical distributions according to Bayes' theorem. The random failure of presynaptic vesicles to release neurotransmitters may allow the brain to sample from posterior distributions of network parameters, interpreted as epistemic uncertainty. It has not been shown previously how random failures might allow networks to sample from observed distributions, also known as aleatoric or residual uncertainty. Sampling from both distributions enables probabilistic inference, efficient search, and creative or generative problem solving. We demonstrate that under a population-code based interpretation of neural activity, both types of distribution can be represented and sampled with synaptic failure alone. We first define a biologically constrained neural network and sampling scheme based on synaptic failure and lateral inhibition. Within this framework, we derive drop-out based epistemic uncertainty, then prove an analytic mapping from synaptic efficacy to release probability that allows networks to sample from arbitrary, learned distributions represented by a receiving layer. Second, our result leads to a local learning rule by which synapses adapt their release probabilities. Our result demonstrates complete Bayesian inference, related to the variational learning method of dropout, in a biologically constrained network using only locally-learned synaptic failure rates.},
	author = {McKee, Kevin L and Crandell, Ian C and Chaudhuri, Rishidev and O'Reilly, Randall C},
	month = nov,
	year = {2021},
	note = {\_eprint: 2111.09780},
}

@article{moore_using_2020,
	title = {Using noise to probe recurrent neural network structure and prune synapses},
	abstract = {Many networks in the brain are sparsely connected, and the brain eliminates synapses during development and learning. How could the brain decide which synapses to prune? In …},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Moore, E and Chaudhuri, R},
	year = {2020},
	note = {Publisher: proceedings.neurips.cc},
}

@unpublished{harris_molecular_2023,
	title = {Molecular encoding of stimulus features in a single sensory neuron type enables neuronal and behavioral plasticity},
	abstract = {Neurons modify their transcriptomes in response to an animal's experience. How specific experiences are transduced to modulate gene expression and precisely tune neuronal functions are not fully defined. Here, we describe the molecular profile of a thermosensory neuron pair in C. elegans experiencing different temperature stimuli. We find that distinct salient features of the temperature stimulus including its duration, magnitude of change, and absolute value are encoded in the gene expression program in this single neuron, and identify a novel transmembrane protein and a transcription factor whose specific transcriptional dynamics are essential to drive neuronal, behavioral, and developmental plasticity. Expression changes are driven by broadly expressed activity-dependent transcription factors and corresponding cis -regulatory elements that nevertheless direct neuron- and stimulus-specific gene expression programs. Our results indicate that coupling of defined stimulus characteristics to the gene regulatory logic in individual specialized neuron types can customize neuronal properties to drive precise behavioral adaptation. \#\#\# Competing Interest Statement The authors have declared no competing interest.},
	language = {en},
	author = {Harris, Nathan and Bates, Samuel and Zhuang, Zihao and Bernstein, Matthew and Stonemetz, Jamie and Hill, Tyler and Yu, Yanxun V and Calarco, John A and Sengupta, Piali},
	month = jan,
	year = {2023},
	note = {Publication Title: bioRxiv},
}

@article{witter_architecture_2017,
	title = {Architecture of the {Entorhinal} {Cortex} {A} {Review} of {Entorhinal} {Anatomy} in {Rodents} with {Some} {Comparative} {Notes}},
	volume = {11},
	abstract = {The entorhinal cortex (EC) is the major input and output structure of the hippocampal formation, forming the nodal point in cortico-hippocampal circuits. Different division schemes including two or many more subdivisions have been proposed, but here we will argue that subdividing EC into two components, the lateral EC (LEC) and medial EC (MEC) might suffice to describe the functional architecture of EC. This subdivision then leads to an anatomical interpretation of the different phenotypes of LEC and MEC. First, we will briefly summarize the cytoarchitectonic differences and differences in hippocampal projection patterns on which the subdivision between LEC and MEC traditionally is based and provide a short comparative perspective. Second, we focus on main differences in cortical connectivity, leading to the conclusion that the apparent differences may well correlate with the functional differences. Cortical connectivity of MEC is features interactions with areas such as the presubiculum, parasubiculum, retrosplenial cortex (RSC) and postrhinal cortex, all areas that are considered to belong to the “spatial processing domain” of the cortex. In contrast, LEC is strongly connected with olfactory areas, insular, medial- and orbitofrontal areas and perirhinal cortex. These areas are likely more involved in processing of object information, attention and motivation. Third, we will compare the intrinsic networks involving principal- and inter-neurons in LEC and MEC. Together, these observations suggest that the different phenotypes of both EC subdivisions likely depend on the combination of intrinsic organization and specific sets of inputs. We further suggest a reappraisal of the notion of EC as a layered input-output structure for the hippocampal formation.},
	language = {en},
	journal = {Front. Syst. Neurosci.},
	author = {Witter, Menno P and Doan, Thanh P and Jacobsen, Bente and Nilssen, Eirik S and Ohara, Shinya},
	month = jun,
	year = {2017},
	keywords = {hippocampus, primate, connectivity, parahippocampal region, rodent},
	pages = {46},
}

@article{tang_pyramidal_2014-1,
	title = {Pyramidal and stellate cell specificity of grid and border representations in layer 2 of medial entorhinal cortex},
	volume = {84},
	abstract = {In medial entorhinal cortex, layer 2 principal cells divide into pyramidal neurons (mostly calbindin positive) and dentate gyrus-projecting stellate cells (mostly calbindin negative). We juxtacellularly labeled layer 2 neurons in freely moving animals, but small sample size prevented establishing unequivocal structure-function relationships. We show, however, that spike locking to theta oscillations allows assigning unidentified extracellular recordings to pyramidal and stellate cells with ∼83\% and ∼89\% specificity, respectively. In pooled anatomically identified and theta-locking-assigned recordings, nonspatial discharges dominated, and weakly hexagonal spatial discharges and head-direction selectivity were observed in both cell types. Clear grid discharges were rare and mostly classified as pyramids (19\%, 19/99 putative pyramids versus 3\%, 3/94 putative stellates). Most border cells were classified as stellate (11\%, 10/94 putative stellates versus 1\%, 1/99 putative pyramids). Our data suggest weakly theta-locked stellate border cells provide spatial input to dentate gyrus, whereas strongly theta-locked grid discharges occur mainly in hexagonally arranged pyramidal cell patches and do not feed into dentate gyrus.},
	language = {en},
	number = {6},
	journal = {Neuron},
	author = {Tang, Qiusong and Burgalossi, Andrea and Ebbesen, Christian Laut and Ray, Saikat and Naumann, Robert and Schmidt, Helene and Spicher, Dominik and Brecht, Michael},
	month = dec,
	year = {2014},
	pages = {1191--1197},
}

@article{bates_neuronal_2019,
	title = {Neuronal cell types in the fly: single-cell anatomy meets single-cell genomics},
	volume = {56},
	abstract = {At around 150 000 neurons, the adult Drosophila melanogaster central nervous system is one of the largest species, for which a complete cellular catalogue is imminent. While numerically much simpler than mammalian brains, its complexity is still difficult to parse without grouping neurons into consistent types, which can number 1-1000 cells per hemisphere. We review how neuroanatomical and gene expression data are being used to discover neuronal types at scale. The correlation among multiple co-varying neuronal properties, including lineage, gene expression, morphology, connectivity, response properties and shared behavioral significance is essential to the definition of neuronal cell type. Initial studies comparing morphological and transcriptomic definitions of neuronal type suggest that these are highly consistent, but there is much to do to match these approaches brain-wide. Matched single-cell transcriptomic and morphological data provide an effective reference point to integrate other data types, including connectomics data. This will significantly enhance our ability to make functional predictions from brain wiring diagrams as well facilitating molecular genetic manipulation of neuronal types.},
	language = {en},
	journal = {Curr. Opin. Neurobiol.},
	author = {Bates, Alexander Shakeel and Janssens, Jasper and Jefferis, Gregory Sxe and Aerts, Stein},
	month = jun,
	year = {2019},
	pages = {125--134},
}

@article{ji_differential_2008,
	title = {Differential roles for hippocampal areas {CA1} and {CA3} in the contextual encoding and retrieval of extinguished fear},
	volume = {15},
	abstract = {Recent studies demonstrate that context-specific memory retrieval after extinction requires the hippocampus. However, the contribution of hippocampal subfields to the context-dependent expression of extinction is not known. In the present experiments, we examined the roles of areas CA1 and CA3 of the dorsal hippocampus in the context specificity of extinction. After pairing an auditory conditional stimulus (CS) with an aversive footshock (unconditional stimulus or US), rats received extinction sessions in which the CS was presented without the US. In Experiment 1, pretraining neurotoxic lesions in either CA1 or CA3 eliminated the context dependence of extinguished fear. In Experiment 2, lesions of CA1 or CA3 were made after extinction training. In this case, only CA1 lesions impaired the context dependence of extinction. Collectively, these results reveal that both hippocampal areas CA1 and CA3 contribute to the acquisition of context-dependent extinction, but that only area CA1 is required for contextual memory retrieval.},
	language = {en},
	number = {4},
	journal = {Learn. Mem.},
	author = {Ji, Jinzhao and Maren, Stephen},
	month = apr,
	year = {2008},
	pages = {244--251},
}

@article{smith_molecular_2022,
	title = {A {Molecular} {Landscape} of {Mouse} {Hippocampal} {Neuromodulation}},
	volume = {16},
	abstract = {Adaptive neuronal circuit function requires a continual adjustment of synaptic network parameters known as “neuromodulation.” This process is now understood to be based primarily on the binding of myriad secreted “modulatory” ligands such as dopamine, serotonin and the neuropeptides to G protein-coupled receptors (GPCRs) that, in turn, regulate the function of the ion channels that establish synaptic weights and membrane excitability. Many of the basic molecular mechanisms of neuromodulation are now known, but the organization of neuromodulation at a network level is still an enigma. New single-cell RNA sequencing data and transcriptomic neurotaxonomies now offer bright new lights to shine on this critical “dark matter” of neuroscience. Here we leverage these advances to explore the cell-type-specific expression of genes encoding GPCRs, modulatory ligands, ion channels and intervening signal transduction molecules in mouse hippocampus area CA1, with the goal of revealing broad outlines of this well-studied brain structure's neuromodulatory network architecture.},
	language = {en},
	journal = {Front. Neural Circuits},
	author = {Smith, Stephen J and von Zastrow, Mark},
	month = may,
	year = {2022},
	keywords = {hippocampus, mouse, GPCR (G protein-coupled receptor), ion channel, neuromodulation, single-cell RNA-Seq, transcriptome},
	pages = {836930},
}

@article{takemura_connectome_2017,
	title = {A connectome of a learning and memory center in the adult {Drosophila} brain},
	volume = {6},
	abstract = {Understanding memory formation, storage and retrieval requires knowledge of the underlying neuronal circuits. In Drosophila, the mushroom body (MB) is the major site of associative learning. We reconstructed the morphologies and synaptic connections of all 983 neurons within the three functional units, or compartments, that compose the adult MB's α lobe, using a dataset of isotropic 8 nm voxels collected by focused ion-beam milling scanning electron microscopy. We found that Kenyon cells (KCs), whose sparse activity encodes sensory information, each make multiple en passant synapses to MB output neurons (MBONs) in each compartment. Some MBONs have inputs from all KCs, while others differentially sample sensory modalities. Only 6\% of KC{\textgreater}MBON synapses receive a direct synapse from a dopaminergic neuron (DAN). We identified two unanticipated classes of synapses, KC{\textgreater}DAN and DAN{\textgreater}MBON. DAN activation produces a slow depolarization of the MBON in these DAN{\textgreater}MBON synapses and can weaken memory recall.},
	journal = {Elife},
	author = {Takemura, Shin-Ya and Aso, Yoshinori and Hige, Toshihide and Wong, Allan and Lu, Zhiyuan and Xu, C Shan and Rivlin, Patricia K and Hess, Harald and Zhao, Ting and Parag, Toufiq and Berg, Stuart and Huang, Gary and Katz, William and Olbris, Donald J and Plaza, Stephen and Umayam, Lowell and Aniceto, Roxanne and Chang, Lei-Ann and Lauchie, Shirley and Ogundeyi, Omotara and Ordish, Christopher and Shinomiya, Aya and Sigmund, Christopher and Takemura, Satoko and Tran, Julie and Turner, Glenn C and Rubin, Gerald M and Scheffer, Louis K},
	month = jul,
	year = {2017},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {dopaminergic neuron, EM reconstruction, memory recall, mushroom body},
	pages = {e26975},
}

@article{song_highly_2005,
	title = {Highly nonrandom features of synaptic connectivity in local cortical circuits},
	volume = {3},
	abstract = {How different is local cortical circuitry from a random network? To answer this question, we probed synaptic connections with several hundred simultaneous quadruple whole-cell recordings from layer 5 pyramidal neurons in the rat visual cortex. Analysis of this dataset revealed several nonrandom features in synaptic connectivity. We confirmed previous reports that bidirectional connections are more common than expected in a random network. We found that several highly clustered three-neuron connectivity patterns are overrepresented, suggesting that connections tend to cluster together. We also analyzed synaptic connection strength as defined by the peak excitatory postsynaptic potential amplitude. We found that the distribution of synaptic connection strength differs significantly from the Poisson distribution and can be fitted by a lognormal distribution. Such a distribution has a heavier tail and implies that synaptic weight is concentrated among few synaptic connections. In addition, the strengths of synaptic connections sharing pre- or postsynaptic neurons are correlated, implying that strong connections are even more clustered than the weak ones. Therefore, the local cortical network structure can be viewed as a skeleton of stronger connections in a sea of weaker ones. Such a skeleton is likely to play an important role in network dynamics and should be investigated further.},
	language = {en},
	number = {3},
	journal = {PLoS Biol.},
	author = {Song, Sen and Sjöström, Per Jesper and Reigl, Markus and Nelson, Sacha and Chklovskii, Dmitri B},
	month = mar,
	year = {2005},
	note = {Publisher: Public Library of Science (PLoS)},
	pages = {e68},
}

@article{varshney_structural_2011,
	title = {Structural properties of the {Caenorhabditis} elegans neuronal network},
	volume = {7},
	abstract = {Despite recent interest in reconstructing neuronal networks, complete wiring diagrams on the level of individual synapses remain scarce and the insights into function they can provide remain unclear. Even for Caenorhabditis elegans, whose neuronal network is relatively small and stereotypical from animal to animal, published wiring diagrams are neither accurate nor complete and self-consistent. Using materials from White et al. and new electron micrographs we assemble whole, self-consistent gap junction and chemical synapse networks of hermaphrodite C. elegans. We propose a method to visualize the wiring diagram, which reflects network signal flow. We calculate statistical and topological properties of the network, such as degree distributions, synaptic multiplicities, and small-world properties, that help in understanding network signal propagation. We identify neurons that may play central roles in information processing, and network motifs that could serve as functional modules of the network. We explore propagation of neuronal activity in response to sensory or artificial stimulation using linear systems theory and find several activity patterns that could serve as substrates of previously described behaviors. Finally, we analyze the interaction between the gap junction and the chemical synapse networks. Since several statistical properties of the C. elegans network, such as multiplicity and motif distributions are similar to those found in mammalian neocortex, they likely point to general principles of neuronal networks. The wiring diagram reported here can help in understanding the mechanistic basis of behavior by generating predictions about future experiments involving genetic perturbations, laser ablations, or monitoring propagation of neuronal activity in response to stimulation.},
	language = {en},
	number = {2},
	journal = {PLoS Comput. Biol.},
	author = {Varshney, Lav R and Chen, Beth L and Paniagua, Eric and Hall, David H and Chklovskii, Dmitri B},
	month = feb,
	year = {2011},
	note = {Publisher: Public Library of Science (PLoS)},
	pages = {e1001066},
}

@article{milo_network_2002,
	title = {Network motifs: simple building blocks of complex networks},
	volume = {298},
	abstract = {Complex networks are studied across many fields of science. To uncover their structural design principles, we defined “network motifs,” patterns of interconnections occurring in complex networks at numbers that are significantly higher than those in randomized networks. We found such motifs in networks from biochemistry, neurobiology, ecology, and engineering. The motifs shared by ecological food webs were distinct from the motifs shared by the genetic networks of Escherichia coli and Saccharomyces cerevisiae or from those found in the World Wide Web. Similar motifs were found in networks that perform information processing, even though they describe elements as different as biomolecules within a cell and synaptic connections between neurons in Caenorhabditis elegans. Motifs may thus define universal classes of networks. This approach may uncover the basic building blocks of most networks.},
	language = {en},
	number = {5594},
	journal = {Science},
	author = {Milo, R and Shen-Orr, S and Itzkovitz, S and Kashtan, N and Chklovskii, D and Alon, U},
	month = oct,
	year = {2002},
	pages = {824--827},
}

@article{topolnik_role_2022,
	title = {The role of inhibitory circuits in hippocampal memory processing},
	abstract = {GABAergic inhibitory circuits play an essential role in coordinating various hippocampal functions. Several decades of work dedicated to a thorough characterization of hippocampal inhibitory populations have highlighted how specific types of interneuron can contribute to network activity. Recent studies have used genetically targeted recordings and peturbations of activity during memory-related behaviours to determine how interneurons that inhibit distinct subcellular domains of principal cells or specialize in principal cell disinhibition may sculpt hippocampal memory. These studies highlight unique contributions of distinct interneuron types to the temporal binding of hippocampal ensembles, synaptic plasticity and the acquisition of spatial and contextual information. Here, we review the current state of knowledge around hippocampal inhibition and memory by discussing the multifaceted roles of populations of inhibitory cells at different stages of hippocampal mnemonic processing.},
	language = {en},
	journal = {Nat. Rev. Neurosci.},
	author = {Topolnik, Lisa and Tamboli, Suhel},
	month = may,
	year = {2022},
}

@article{sun_proximodistal_2017,
	title = {Proximodistal {Heterogeneity} of {Hippocampal} {CA3} {Pyramidal} {Neuron} {Intrinsic} {Properties}, {Connectivity}, and {Reactivation} during {Memory} {Recall}},
	volume = {95},
	abstract = {The hippocampal CA3 region is classically viewed as a homogeneous autoassociative network critical for associative memory and pattern completion. However, recent evidence has demonstrated a striking heterogeneity along the transverse, or proximodistal, axis of CA3 in spatial encoding and memory. Here we report the presence of striking proximodistal gradients in intrinsic membrane properties and synaptic connectivity for dorsal CA3. A decreasing gradient of mossy fiber synaptic strength along the proximodistal axis is mirrored by an increasing gradient of direct synaptic excitation from entorhinal cortex. Furthermore, we uncovered a nonuniform pattern of reactivation of fear memory traces, with the most robust reactivation during memory retrieval occurring in mid-CA3 (CA3b), the region showing the strongest net recurrent excitation. Our results suggest that heterogeneity in both intrinsic properties and synaptic connectivity may contribute to the distinct spatial encoding and behavioral role of CA3 subregions along the proximodistal axis.},
	language = {en},
	number = {3},
	journal = {Neuron},
	author = {Sun, Qian and Sotayo, Alaba and Cazzulino, Alejandro S and Snyder, Anna M and Denny, Christine A and Siegelbaum, Steven A},
	month = aug,
	year = {2017},
	keywords = {Hippocampus, CA3, CA2, contextual fear conditioning, input resistance, intrinsic excitability, mossy fiber, pattern completion, perforant path, recurrent collateral},
	pages = {656--672.e3},
}

@article{stanley_continuous_2020,
	title = {Continuous and {Discrete} {Neuron} {Types} of the {Adult} {Murine} {Striatum}},
	volume = {105},
	abstract = {The mammalian striatum is involved in many complex behaviors and yet is composed largely of a single neuron class: the spiny projection neuron (SPN). It is unclear to what extent the functional specialization of the striatum is due to the molecular specialization of SPN subtypes. We sought to define the molecular and anatomical diversity of adult SPNs using single-cell RNA sequencing (scRNA-seq) and quantitative RNA in situ hybridization (ISH). We computationally distinguished discrete versus continuous heterogeneity in scRNA-seq data and found that SPNs in the striatum can be classified into four major discrete types with no implied spatial relationship between them. Within these discrete types, we find continuous heterogeneity encoding spatial gradients of gene expression and defining anatomical location in a combinatorial mechanism. Our results suggest that neuronal circuitry has a substructure at far higher resolution than is typically interrogated, which is defined by the precise identity and location of a neuron.},
	language = {en},
	number = {4},
	journal = {Neuron},
	author = {Stanley, Geoffrey and Gokce, Ozgun and Malenka, Robert C and Südhof, Thomas C and Quake, Stephen R},
	month = feb,
	year = {2020},
	pages = {688--699.e8},
}

@unpublished{zheng_structured_2020,
	title = {Structured sampling of olfactory input by the fly mushroom body},
	abstract = {Associative memory formation and recall in the adult fruit fly Drosophila melanogaster is subserved by the mushroom body (MB). Upon arrival in the MB, sensory information undergoes a profound transformation. Olfactory projection neurons (PNs), the main MB input, exhibit broadly tuned, sustained, and stereotyped responses to odorants; in contrast, their postsynaptic targets in the MB, the Kenyon cells (KCs), are nonstereotyped, narrowly tuned, and only briefly responsive to odorants. Theory and experiment have suggested that this transformation is implemented by random connectivity between KCs and PNs. However, this hypothesis has been challenging to test, given the difficulty of mapping synaptic connections between large numbers of neurons to achieve a unified view of neuronal network structure. Here we used a recent whole-brain electron microscopy (EM) volume of the adult fruit fly to map large numbers of PN- to-KC connections at synaptic resolution. Comparison of the observed connectome to precisely defined null models revealed unexpected network structure, in which a subset of food-responsive PN types converge on individual downstream KCs more frequently than expected. The connectivity bias is consistent with the neurogeometry: axons of the overconvergent PNs tend to arborize near one another in the MB main calyx, making local KC dendrites more likely to receive input from those types. Computational modeling of the observed PN-to-KC network showed that input from the overconvergent PN types is better discriminated than input from other types. These results suggest an `associative fovea' for olfaction, in that the MB is wired to better discriminate more frequently occurring and ethologically relevant combinations of food-related odors. \#\#\# Competing Interest Statement The authors have declared no competing interest.},
	language = {en},
	author = {Zheng, Zhihao and Li, Feng and Fisher, Corey and Ali, Iqbal J and Sharifi, Nadiya and Calle-Schuler, Steven and Hsu, Joseph and Masoodpanah, Najla and Kmecova, Lucia and Kazimiers, Tom and Perlman, Eric and Nichols, Matthew and Li, Peter H and Jain, Viren and Bock, Davi D},
	month = apr,
	year = {2020},
	note = {Publication Title: bioRxiv},
}

@unpublished{zheng_structured_2020-1,
	title = {Structured sampling of olfactory input by the fly mushroom body},
	abstract = {AbstractAssociative memory formation and recall in the adult fruit fly Drosophila melanogaster is subserved by the mushroom body (MB). Upon arrival in the MB, sensory information undergoes a profound transformation. Olfactory projection neurons (PNs), the main MB input, exhibit broadly tuned, sustained, and stereotyped responses to odorants; in contrast, their postsynaptic targets in the MB, the Kenyon cells (KCs), are nonstereotyped, narrowly tuned, and only briefly responsive to odorants. Theory and experiment have suggested that this transformation is implemented by random connectivity between KCs and PNs. However, this hypothesis has been challenging to test, given the difficulty of mapping synaptic connections between large numbers of neurons to achieve a unified view of neuronal network structure. Here we used a recent whole-brain electron microscopy (EM) volume of the adult fruit fly to map large numbers of PN- to-KC connections at synaptic resolution. Comparison of the observed connectome to precisely defined null models revealed unexpected network structure, in which a subset of food-responsive PN types converge on individual downstream KCs more frequently than expected. The connectivity bias is consistent with the neurogeometry: axons of the overconvergent PNs tend to arborize near one another in the MB main calyx, making local KC dendrites more likely to receive input from those types. Computational modeling of the observed PN-to-KC network showed that input from the overconvergent PN types is better discriminated than input from other types. These results suggest an `associative fovea' for olfaction, in that the MB is wired to better discriminate more frequently occurring and ethologically relevant combinations of food-related odors.},
	language = {en},
	author = {Zheng, Zhihao and Li, Feng and Fisher, Corey and Ali, Iqbal J and Sharifi, Nadiya and Calle-Schuler, Steven and Hsu, Joseph and Masoodpanah, Najla and Kmecova, Lucia and Kazimiers, Tom and Perlman, Eric and Nichols, Matthew and Li, Peter H and Jain, Viren and Bock, Davi D},
	month = apr,
	year = {2020},
	note = {Publication Title: bioRxiv
Publisher: bioRxiv},
}

@article{ko_functional_2011,
	title = {Functional specificity of local synaptic connections in neocortical networks},
	volume = {473},
	abstract = {Neuronal connectivity is fundamental to information processing in the brain. Therefore, understanding the mechanisms of sensory processing requires uncovering how connection patterns between neurons relate to their function. On a coarse scale, long-range projections can preferentially link cortical regions with similar responses to sensory stimuli. But on the local scale, where dendrites and axons overlap substantially, the functional specificity of connections remains unknown. Here we determine synaptic connectivity between nearby layer 2/3 pyramidal neurons in vitro, the response properties of which were first characterized in mouse visual cortex in vivo. We found that connection probability was related to the similarity of visually driven neuronal activity. Neurons with the same preference for oriented stimuli connected at twice the rate of neurons with orthogonal orientation preferences. Neurons responding similarly to naturalistic stimuli formed connections at much higher rates than those with uncorrelated responses. Bidirectional synaptic connections were found more frequently between neuronal pairs with strongly correlated visual responses. Our results reveal the degree of functional specificity of local synaptic connections in the visual cortex, and point to the existence of fine-scale subnetworks dedicated to processing related sensory information.},
	language = {en},
	number = {7345},
	journal = {Nature},
	author = {Ko, Ho and Hofer, Sonja B and Pichler, Bruno and Buchanan, Katherine A and Sjöström, P Jesper and Mrsic-Flogel, Thomas D},
	month = may,
	year = {2011},
	pages = {87--91},
}

@article{kirchner_emergence_2021,
	title = {Emergence of local and global synaptic organization on cortical dendrites},
	volume = {12},
	abstract = {Synaptic inputs on cortical dendrites are organized with remarkable subcellular precision at the micron level. This organization emerges during early postnatal development through patterned spontaneous activity and manifests both locally where nearby synapses are significantly correlated, and globally with distance to the soma. We propose a biophysically motivated synaptic plasticity model to dissect the mechanistic origins of this organization during development and elucidate synaptic clustering of different stimulus features in the adult. Our model captures local clustering of orientation in ferret and receptive field overlap in mouse visual cortex based on the receptive field diameter and the cortical magnification of visual space. Including action potential back-propagation explains branch clustering heterogeneity in the ferret and produces a global retinotopy gradient from soma to dendrite in the mouse. Therefore, by combining activity-dependent synaptic competition and species-specific receptive fields, our framework explains different aspects of synaptic organization regarding stimulus features and spatial scales.},
	language = {en},
	number = {1},
	journal = {Nat. Commun.},
	author = {Kirchner, Jan H and Gjorgjieva, Julijana},
	month = jun,
	year = {2021},
	pages = {4005},
}

@article{ferrante_post-inhibitory_2017,
	title = {Post-{Inhibitory} {Rebound} {Spikes} in {Rat} {Medial} {Entorhinal} {Layer} {II}/{III} {Principal} {Cells}: {In} {Vivo}, {In} {Vitro}, and {Computational} {Modeling} {Characterization}},
	volume = {27},
	abstract = {Medial entorhinal cortex Layer-II stellate cells (mEC-LII-SCs) primarily interact via inhibitory interneurons. This suggests the presence of alternative mechanisms other than excitatory synaptic inputs for triggering action potentials (APs) in stellate cells during spatial navigation. Our intracellular recordings show that the hyperpolarization-activated cation current (Ih) allows post-inhibitory-rebound spikes (PIRS) in mEC-LII-SCs. In vivo, strong inhibitory-post-synaptic potentials immediately preceded most APs shortening their delay and enhancing excitability. In vitro experiments showed that inhibition initiated spikes more effectively than excitation and that more dorsal mEC-LII-SCs produced faster and more synchronous spikes. In contrast, PIRS in Layer-II/III pyramidal cells were harder to evoke, voltage-independent, and slower in dorsal mEC. In computational simulations, mEC-LII-SCs morphology and Ih homeostatically regulated the dorso-ventral differences in PIRS timing and most dendrites generated PIRS with a narrow range of stimulus amplitudes. These results suggest inhibitory inputs could mediate the emergence of grid cell firing in a neuronal network.},
	language = {en},
	number = {3},
	journal = {Cereb. Cortex},
	author = {Ferrante, Michele and Shay, Christopher F and Tsuno, Yusuke and William Chapman, G and Hasselmo, Michael E},
	month = mar,
	year = {2017},
	keywords = {entorhinal cortex, inhibition, stellate cells, hyperpolarization-activated cation current (Ih), post-inhibitory spikes},
	pages = {2111--2125},
}

@article{martinez_anatomical_2017,
	title = {Anatomical and {Electrophysiological} {Clustering} of {Superficial} {Medial} {Entorhinal} {Cortex} {Interneurons}},
	volume = {4},
	abstract = {Local GABAergic interneurons regulate the activity of spatially-modulated principal cells in the medial entorhinal cortex (MEC), mediating stellate-to-stellate connectivity and possibly enabling grid formation via recurrent inhibitory circuitry. Despite the important role interneurons seem to play in the MEC cortical circuit, the combination of low cell counts and functional diversity has made systematic electrophysiological studies of these neurons difficult. For these reasons, there remains a paucity of knowledge on the electrophysiological profiles of superficial MEC interneuron populations. Taking advantage of glutamic acid decarboxylase 2 (GAD2)-IRES-tdTomato and PV-tdTomato transgenic mice, we targeted GABAergic interneurons for whole-cell patch-clamp recordings and characterized their passive membrane features, basic input/output properties and action potential (AP) shape. These electrophysiologically characterized cells were then anatomically reconstructed, with emphasis on axonal projections and pial depth. K-means clustering of interneuron anatomical and electrophysiological data optimally classified a population of 106 interneurons into four distinct clusters. The first cluster is comprised of layer 2- and 3-projecting, slow-firing interneurons. The second cluster is comprised largely of PV+ fast-firing interneurons that project mainly to layers 2 and 3. The third cluster contains layer 1- and 2-projecting interneurons, and the fourth cluster is made up of layer 1-projecting horizontal interneurons. These results, among others, will provide greater understanding of the electrophysiological characteristics of MEC interneurons, help guide future in vivo studies, and may aid in uncovering the mechanism of grid field formation.},
	language = {en},
	number = {5},
	journal = {eNeuro},
	author = {Martínez, Joan José and Rahsepar, Bahar and White, John A},
	month = sep,
	year = {2017},
	keywords = {excitability, entorhinal, interneuron, cluster analysis},
}

@misc{marks_stimulus-dependent_2021,
	title = {Stimulus-dependent representational drift in primary visual cortex},
	author = {Marks, Tyler D and Goard, Michael J},
	year = {2021},
	note = {Issue: 1
Publication Title: Nature Communications
Volume: 12},
}

@article{boussard_three-dimensional_2021,
	title = {Three-dimensional spike localization and improved motion correction for {Neuropixels} recordings},
	volume = {34},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Boussard, Julien and Varol, Erdem and Lee, Hyun Dong and Dethe, Nishchal and Paninski, Liam},
	year = {2021},
	pages = {22095--22105},
}

@article{pinto_task-dependent_2019,
	title = {Task-{Dependent} {Changes} in the {Large}-{Scale} {Dynamics} and {Necessity} of {Cortical} {Regions}},
	volume = {104},
	abstract = {Neural activity throughout the cortex is correlated with perceptual decisions, but inactivation studies suggest that only a small number of areas are necessary for these behaviors. Here we show that the number of required cortical areas and their dynamics vary across related tasks with different cognitive computations. In a visually guided virtual T-maze task, bilateral inactivation of only a few dorsal cortical regions impaired performance. In contrast, in tasks requiring evidence accumulation and/or post-stimulus memory, performance was impaired by inactivation of widespread cortical areas with diverse patterns of behavioral deficits across areas and tasks. Wide-field imaging revealed widespread ramps of Ca2+ activity during the accumulation and visually guided tasks. Additionally, during accumulation, different regions had more diverse activity profiles, leading to reduced inter-area correlations. Using a modular recurrent neural network model trained to perform analogous tasks, we argue that differences in computational strategies alone could explain these findings.},
	language = {en},
	number = {4},
	journal = {Neuron},
	author = {Pinto, Lucas and Rajan, Kanaka and DePasquale, Brian and Thiberge, Stephan Y and Tank, David W and Brody, Carlos D},
	month = nov,
	year = {2019},
	keywords = {decision making, virtual reality, optogenetics, cortex, working memory, evidence accumulation, mouse behavior, RNN, widefield Ca(2+) imaging},
	pages = {810--824.e9},
}

@article{scott_fronto-parietal_2017,
	title = {Fronto-parietal {Cortical} {Circuits} {Encode} {Accumulated} {Evidence} with a {Diversity} of {Timescales}},
	volume = {95},
	abstract = {Decision-making in dynamic environments often involves accumulation of evidence, in which new information is used to update beliefs and select future actions. Using in vivo cellular resolution imaging in voluntarily head-restrained rats, we examined the responses of neurons in frontal and parietal cortices during a pulse-based accumulation of evidence task. Neurons exhibited activity that predicted the animal's upcoming choice, previous choice, and graded responses that reflected the strength of the accumulated evidence. The pulsatile nature of the stimuli enabled characterization of the responses of neurons to a single quantum (pulse) of evidence. Across the population, individual neurons displayed extensive heterogeneity in the dynamics of responses to pulses. The diversity of responses was sufficiently rich to form a temporal basis for accumulated evidence estimated from a latent variable model. These results suggest that heterogeneous, often transient sensory responses distributed across the fronto-parietal cortex may support working memory on behavioral timescales. VIDEO ABSTRACT.},
	language = {en},
	number = {2},
	journal = {Neuron},
	author = {Scott, Benjamin B and Constantinople, Christine M and Akrami, Athena and Hanks, Timothy D and Brody, Carlos D and Tank, David W},
	month = jul,
	year = {2017},
	keywords = {decision-making, neocortex, calcium imaging, neural coding, working memory, rodent, accumulation of evidence, drift diffusion model, head restraint, multiphoton fluorescence microscopy},
	pages = {385--398.e5},
}

@article{pinto_task-dependent_2019-1,
	title = {Task-{Dependent} {Changes} in the {Large}-{Scale} {Dynamics} and {Necessity} of {Cortical} {Regions}},
	volume = {104},
	abstract = {Neural activity throughout the cortex is correlated with perceptual decisions, but inactivation studies suggest that only a small number of areas are necessary for these behaviors. Here we show that the number of required cortical areas and their dynamics vary across related tasks with different cognitive computations. In a visually guided virtual T-maze task, bilateral inactivation of only a few dorsal cortical regions impaired performance. In contrast, in tasks requiring evidence accumulation and/or post-stimulus memory, performance was impaired by inactivation of widespread cortical areas with diverse patterns of behavioral deficits across areas and tasks. Wide-field imaging revealed widespread ramps of Ca2+ activity during the accumulation and visually guided tasks. Additionally, during accumulation, different regions had more diverse activity profiles, leading to reduced inter-area correlations. Using a modular recurrent neural network model trained to perform analogous tasks, we argue that differences in computational strategies alone could explain these findings.},
	language = {en},
	number = {4},
	journal = {Neuron},
	author = {Pinto, Lucas and Rajan, Kanaka and DePasquale, Brian and Thiberge, Stephan Y and Tank, David W and Brody, Carlos D},
	month = nov,
	year = {2019},
	keywords = {decision making, virtual reality, optogenetics, cortex, working memory, evidence accumulation, mouse behavior, RNN, widefield Ca(2+) imaging},
	pages = {810--824.e9},
}

@unpublished{schaeffer_no_2022-1,
	title = {No {Free} {Lunch} from {Deep} {Learning} in {Neuroscience}: {A} {Case} {Study} through {Models} of the {Entorhinal}-{Hippocampal} {Circuit}},
	abstract = {Fundamental research in Neuroscience is currently undergoing a renaissance based on deep learning. The central promises of deep learning-based modeling of brain circuits are that the models shed light on evolutionary optimization problems, constraints and solutions, and generate novel predictions regarding neural phenomena. We show, through the case-study of grid cells in the entorhinal-hippocampal circuit, that one often gets neither. We begin by reviewing the principles of grid cell mechanism and function obtained from analytical and first-principles modeling efforts, then consider the claims of deep learning models of grid cells and rigorously examine their results under varied conditions. Using large-scale hyperparameter sweeps and hypothesis-driven experimentation, we demonstrate that the results of such models may reveal more about particular and non-fundamental implementation choices than fundamental truths about neural circuits or the loss function(s) they might optimize. Finally, we discuss why it is that these models of the brain cannot be expected to work without the addition of substantial amounts of inductive bias, an informal No Free Lunch theorem for Neuroscience. In conclusion, caution and consideration, together with biological knowledge, are warranted in building and interpreting deep learning models in Neuroscience.},
	author = {Schaeffer, Rylan and Khona, Mikail and Fiete, Ila R},
	month = jun,
	year = {2022},
}

@article{mccormick_brain_2015,
	title = {Brain state dependent activity in the cortex and thalamus},
	volume = {31},
	abstract = {Cortical and thalamocortical activity is highly state dependent, varying between patterns that are conducive to accurate sensory-motor processing, to states in which the brain is largely off-line and generating internal rhythms irrespective of the outside world. The generation of rhythmic activity occurs through the interaction of stereotyped patterns of connectivity together with intrinsic membrane and synaptic properties. One common theme in the generation of rhythms is the interaction of a positive feedback loop (e.g., recurrent excitation) with negative feedback control (e.g., inhibition, adaptation, or synaptic depression). The operation of these state-dependent activities has wide ranging effects from enhancing or blocking sensory-motor processing to the generation of pathological rhythms associated with psychiatric or neurological disorders.},
	language = {en},
	journal = {Curr. Opin. Neurobiol.},
	author = {McCormick, David A and McGinley, Matthew J and Salkoff, David B},
	month = apr,
	year = {2015},
	pages = {133--140},
}

@article{rigas_thalamocortical_2007,
	title = {Thalamocortical {Up} states: differential effects of intrinsic and extrinsic cortical inputs on persistent activity},
	volume = {27},
	abstract = {During behavioral quiescence, the neocortex generates spontaneous slow oscillations that consist of Up and Down states. Up states are short epochs of persistent activity that resemble the activated neocortex during arousal and cognition. Although Up states are generated within the cortex, the impact of extrinsic (thalamocortical) and intrinsic (intracortical) inputs on the persistent activity is not known. Using thalamocortical slices, we found that the persistent cortical activity during spontaneous Up states effectively drives thalamocortical relay cells through corticothalamic connections. However, thalamic activity can also precede the onset of cortical Up states, which suggests a role of thalamic activity in triggering cortical Up states through thalamocortical connections. In support of this hypothesis, we found that cutting the connections between thalamus and cortex reduced the incidence of spontaneous Up states in the cortex. Consistent with a facilitating role of thalamic activity on Up states, electrical or chemical stimulation of the thalamus triggered cortical Up states very effectively and enhanced those occurring spontaneously. In contrast, stimulation of the cortex triggered Up states only at very low intensities but otherwise had a suppressive effect on Up states. Moreover, cortical stimulation suppressed the facilitating effect of thalamic stimulation on Up states. In conclusion, thalamocortical inputs facilitate and intracortical inputs suppress cortical Up states. Thus, extrinsic and intrinsic cortical inputs differentially regulate persistent activity, which may serve to adjust the processing state of thalamocortical networks during behavior.},
	language = {en},
	number = {16},
	journal = {J. Neurosci.},
	author = {Rigas, Pavlos and Castro-Alamancos, Manuel A},
	month = apr,
	year = {2007},
	pages = {4261--4272},
}

@article{watson_up_2008,
	title = {{UP} states protect ongoing cortical activity from thalamic inputs},
	volume = {3},
	abstract = {Cortical neurons in vitro and in vivo fluctuate spontaneously between two stable membrane potentials: a depolarized UP state and a hyperpolarized DOWN state. UP states temporally correspond with multineuronal firing sequences which may be important for information processing. To examine how thalamic inputs interact with ongoing cortical UP state activity, we used calcium imaging and targeted whole-cell recordings of activated neurons in thalamocortical slices of mouse somatosensory cortex. Whereas thalamic stimulation during DOWN states generated multineuronal, synchronized UP states, identical stimulation during UP states had no effect on the subthreshold membrane dynamics of the vast majority of cells or on ongoing multineuronal temporal patterns. Both thalamocortical and corticocortical PSPs were significantly reduced and neuronal input resistance was significantly decreased during cortical UP states – mechanistically consistent with UP state insensitivity. Our results demonstrate that cortical dynamics during UP states are insensitive to thalamic inputs.},
	language = {en},
	number = {12},
	journal = {PLoS One},
	author = {Watson, Brendon O and MacLean, Jason N and Yuste, Rafael},
	month = dec,
	year = {2008},
	pages = {e3971},
}

@article{banino_vector-based_2018-1,
	title = {Vector-based navigation using grid-like representations in artificial agents},
	volume = {557},
	abstract = {Deep neural networks have achieved impressive successes in fields ranging from object recognition to complex games such as Go1,2. Navigation, however, remains a substantial challenge for artificial agents, with deep neural networks trained by reinforcement learning3-5 failing to rival the proficiency of mammalian spatial behaviour, which is underpinned by grid cells in the entorhinal cortex 6 . Grid cells are thought to provide a multi-scale periodic representation that functions as a metric for coding space7,8 and is critical for integrating self-motion (path integration)6,7,9 and planning direct trajectories to goals (vector-based navigation)7,10,11. Here we set out to leverage the computational functions of grid cells to develop a deep reinforcement learning agent with mammal-like navigational abilities. We first trained a recurrent network to perform path integration, leading to the emergence of representations resembling grid cells, as well as other entorhinal cell types 12 . We then showed that this representation provided an effective basis for an agent to locate goals in challenging, unfamiliar, and changeable environments-optimizing the primary objective of navigation through deep reinforcement learning. The performance of agents endowed with grid-like representations surpassed that of an expert human and comparison agents, with the metric quantities necessary for vector-based navigation derived from grid-like units within the network. Furthermore, grid-like representations enabled agents to conduct shortcut behaviours reminiscent of those performed by mammals. Our findings show that emergent grid-like representations furnish agents with a Euclidean spatial metric and associated vector operations, providing a foundation for proficient navigation. As such, our results support neuroscientific theories that see grid cells as critical for vector-based navigation7,10,11, demonstrating that the latter can be combined with path-based strategies to support navigation in challenging environments.},
	language = {en},
	number = {7705},
	journal = {Nature},
	author = {Banino, Andrea and Barry, Caswell and Uria, Benigno and Blundell, Charles and Lillicrap, Timothy and Mirowski, Piotr and Pritzel, Alexander and Chadwick, Martin J and Degris, Thomas and Modayil, Joseph and Wayne, Greg and Soyer, Hubert and Viola, Fabio and Zhang, Brian and Goroshin, Ross and Rabinowitz, Neil and Pascanu, Razvan and Beattie, Charlie and Petersen, Stig and Sadik, Amir and Gaffney, Stephen and King, Helen and Kavukcuoglu, Koray and Hassabis, Demis and Hadsell, Raia and Kumaran, Dharshan},
	month = may,
	year = {2018},
	pages = {429--433},
}

@inproceedings{schaeffer_efficient_2021,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Efficient online inference for nonparametric mixture models},
	volume = {161},
	abstract = {Natural data are often well-described as belonging to latent clusters. When the number of clusters is unknown, Bayesian nonparametric (BNP) models can provide a flexible and powerful technique to model the data. However, algorithms for inference in nonparametric mixture models fail to meet two critical requirements for practical use: (1) that inference can be performed online, and (2) that inference is efficient in the large time/sample limit. In this work, we propose a novel Bayesian recursion to efficiently infer a posterior distribution over discrete latent variables from a sequence of observations in an online manner, assuming a Chinese Restaurant Process prior on the sequence of latent variables. Our recursive filter, which we call the Recursive Chinese Restaurant Process (R-CRP), has quasilinear average time complexity and logarithmic average space complexity in the total number of observations. We experimentally compare our filtering method against both online and offline inference algorithms including Markov chain Monte Carlo, variational approximations and DP-Means, and demonstrate that our inference algorithm achieves comparable or better performance for a fraction of the runtime.},
	booktitle = {Proceedings of the {Thirty}-{Seventh} {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
	publisher = {PMLR},
	author = {Schaeffer, Rylan and Bordelon, Blake and Khona, Mikail and Pan, Weiwei and Fiete, Ila Rani},
	editor = {de Campos, Cassio and Maathuis, Marloes H},
	year = {2021},
	pages = {2072--2081},
}

@article{white_segregation_1998,
	title = {Segregation of receptive field properties in the lateral geniculate nucleus of a {New}-{World} monkey, the marmoset {Callithrix} jacchus},
	volume = {80},
	abstract = {The lateral geniculate nucleus (LGN) in humans and Old-World monkeys is dominated by the representation of the fovea in the parvocellular (PC) layers, and most PC cells in the foveal representation have red-green cone opponent receptive field properties. It is not known whether these features are both unique to trichromatic primates. Here we measured receptive field properties and the visuotopic organization of cells in the LGN of a New-World monkey, the marmoset Callithrix jacchus. The marmoset displays a polymorphism of cone opsins in the medium-long wavelength (ML) range, which allows the LGN of dichromatic (“red-green color blind”) and trichromatic individuals to be compared. Furthermore, the koniocellular-interlaminar layers are segregated from the main PC layers in marmoset, allowing the functional role of this subdivision of the LGN to be assessed. We show that the representation of the visual field in the LGN is quantitatively similar in dichromatic and trichromatic marmosets and is similar to that reported for macaque; the vast majority of LGN volume is devoted to the central visual field. ON- and OFF-type responses are partially segregated in the PC layers so that responses are more commonly encountered near the external border of each layer. The red-green (ML) opponent cells in trichromatic animals were all located in the PC layers, and their receptive fields were within 16 degrees of the fovea. The koniocellular zone between the PC and magnocellular layers contained cells that receive excitatory input from short wavelength sensitive cones (“blue- cells”) as well as other nonopponent cells. These results suggest that the basic organization of the LGN is common to dichromatic and trichromatic primates and provide further evidence that ML and SWS opponent signals are carried in distinct subdivisions of the retinogeniculocortical pathway.},
	language = {en},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {White, A J and Wilder, H D and Goodchild, A K and Sefton, A J and Martin, P R},
	month = oct,
	year = {1998},
	pages = {2063--2076},
}

@article{adams_precise_2003,
	title = {A precise retinotopic map of primate striate cortex generated from the representation of angioscotomas},
	volume = {23},
	abstract = {Shadows cast by retinal blood vessels are represented in striate cortex of the squirrel monkey. Their pattern was exploited to generate a true retinotopic map of V1. For calibration, retinal landmarks were projected onto a tangent screen to measure their visual field location. Next, the retina was warped onto striate cortex, distorting it as necessary to match each retinal vessel to its cortical representation. Maps from four hemispheres of two normal adult squirrel monkeys were created and used to derive expressions for cortical magnification factor (M). A mean map was produced by averaging the individual maps. To address the controversial issue of whether the ratio of retinal ganglion cell (RGC) density to M is constant at all eccentricities, we stained a retinal whole mount from one of the two monkeys for Nissl substance. A ganglion cell density map was compiled by sampling the concentration of cells at 171 retinal points. Allowance was made for displaced amacrine cells and for the centripetal displacement of RGCs from central photoreceptors. After these corrections the V1 surface area and RGC density were compared at each eccentricity. The cortical representation of the macula was found to be amplified, even beyond the magnification expected from its high density of RGCs. For example, the central 4 degrees of visual field were allotted 27\% of the surface area of V1 but were supplied by only 12\% of RGCs. We conclude that, in monkey striate cortex, more tissue is allocated per ganglion cell for the analysis of information emanating from the macula as compared with the peripheral retina.},
	language = {en},
	number = {9},
	journal = {J. Neurosci.},
	author = {Adams, Daniel L and Horton, Jonathan C},
	month = may,
	year = {2003},
	pages = {3771--3789},
}

@article{cang_development_2005,
	title = {Development of precise maps in visual cortex requires patterned spontaneous activity in the retina},
	volume = {48},
	abstract = {The visual cortex is organized into retinotopic maps that preserve an orderly representation of the visual world, achieved by topographically precise inputs from the lateral geniculate nucleus. We show here that geniculocortical mapping is imprecise when the waves of spontaneous activity in the retina during the first postnatal week are disrupted genetically. This anatomical mapping defect is present by postnatal day 8 and has functional consequences, as revealed by optical imaging and microelectrode recording in adults. Pharmacological disruption of these retinal waves during the first week phenocopies the mapping defect, confirming both the site and the timing of the disruption in neural activity responsible for the defect. Analysis shows that the geniculocortical miswiring is not a trivial or necessary consequence of the retinogeniculate defect. Our findings demonstrate that disrupting early spontaneous activity in the eye alters thalamic connections to the cortex.},
	language = {en},
	number = {5},
	journal = {Neuron},
	author = {Cang, Jianhua and Rentería, René C and Kaneko, Megumi and Liu, Xiaorong and Copenhagen, David R and Stryker, Michael P},
	month = dec,
	year = {2005},
	pages = {797--809},
}

@article{grubb_abnormal_2003,
	title = {Abnormal functional organization in the dorsal lateral geniculate nucleus of mice lacking the beta 2 subunit of the nicotinic acetylcholine receptor},
	volume = {40},
	abstract = {Spontaneous activity patterns in the developing retina appear important for the functional organization of the visual system. We show here that an absence of early retinal waves in mice lacking the beta2 subunit of the nicotinic acetylcholine receptor (nAChR) is associated with both gain and loss of functional organization in the dorsal lateral geniculate nucleus (dLGN). Anatomical studies show normal gross retinotopy in the beta2(-/-) dLGN but suggest reduced topographic precision in the retinogeniculate projection. Physiological recordings reveal normal topography in the dorsoventral visual axis but a lack of fine-scale mapping in the nasotemporal visual plane. In contrast, unlike wild-type mice, on- and off-center cells in the beta2(-/-) dLGN are spatially segregated. The presence of the beta2 subunit of the nAChR in the CNS is therefore important for normal functional organization in the retinogeniculate projection.},
	language = {en},
	number = {6},
	journal = {Neuron},
	author = {Grubb, Matthew S and Rossi, Francesco M and Changeux, Jean Pierre and Thompson, Ian D},
	month = dec,
	year = {2003},
	pages = {1161--1172},
}

@incollection{eglen_retinotopic_2015,
	address = {New York, NY},
	title = {Retinotopic {Development}, {Models} of},
	booktitle = {Encyclopedia of {Computational} {Neuroscience}},
	publisher = {Springer New York},
	author = {Eglen, Stephen J},
	editor = {Jaeger, Dieter and Jung, Ranu},
	year = {2015},
	pages = {2631--2633},
}

@unpublished{roth_kernel_2022,
	title = {Kernel {RNN} {Learning} ({KeRNL})},
	author = {Roth, Christopher and Kanitscheider, Ingmar and Fiete, Ila},
	month = feb,
	year = {2022},
	note = {Publication Title: https://openreview.net › forumhttps://openreview.net › forum},
}

@article{burak_accurate_2009,
	title = {Accurate path integration in continuous attractor network models of grid cells},
	volume = {5},
	abstract = {Grid cells in the rat entorhinal cortex display strikingly regular firing responses to the animal's position in 2-D space and have been hypothesized to form the neural substrate for dead-reckoning. However, errors accumulate rapidly when velocity inputs are integrated in existing models of grid cell activity. To produce grid-cell-like responses, these models would require frequent resets triggered by external sensory cues. Such inadequacies, shared by various models, cast doubt on the dead-reckoning potential of the grid cell system. Here we focus on the question of accurate path integration, specifically in continuous attractor models of grid cell activity. We show, in contrast to previous models, that continuous attractor models can generate regular triangular grid responses, based on inputs that encode only the rat's velocity and heading direction. We consider the role of the network boundary in the integration performance of the network and show that both periodic and aperiodic networks are capable of accurate path integration, despite important differences in their attractor manifolds. We quantify the rate at which errors in the velocity integration accumulate as a function of network size and intrinsic noise within the network. With a plausible range of parameters and the inclusion of spike variability, our model networks can accurately integrate velocity inputs over a maximum of approximately 10-100 meters and approximately 1-10 minutes. These findings form a proof-of-concept that continuous attractor dynamics may underlie velocity integration in the dorsolateral medial entorhinal cortex. The simulations also generate pertinent upper bounds on the accuracy of integration that may be achieved by continuous attractor dynamics in the grid cell network. We suggest experiments to test the continuous attractor model and differentiate it from models in which single cells establish their responses independently of each other.},
	language = {en},
	number = {2},
	journal = {PLoS Comput. Biol.},
	author = {Burak, Yoram and Fiete, Ila R},
	month = feb,
	year = {2009},
	pages = {e1000291},
}

@article{yoon_specific_2013-1,
	title = {Specific evidence of low-dimensional continuous attractor dynamics in grid cells},
	volume = {16},
	abstract = {We examined simultaneously recorded spikes from multiple rat grid cells, to explain mechanisms underlying their activity. Among grid cells with similar spatial periods, the population activity was confined to lie close to a two-dimensional (2D) manifold: grid cells differed only along two dimensions of their responses and otherwise were nearly identical. Relationships between cell pairs were conserved despite extensive deformations of single-neuron responses. Results from novel environments suggest such structure is not inherited from hippocampal or external sensory inputs. Across conditions, cell-cell relationships are better conserved than responses of single cells. Finally, the system is continually subject to perturbations that, were the 2D manifold not attractive, would drive the system to inhabit a different region of state space than observed. These findings have strong implications for theories of grid-cell activity and substantiate the general hypothesis that the brain computes using low-dimensional continuous attractors.},
	language = {en},
	number = {8},
	journal = {Nat. Neurosci.},
	author = {Yoon, Kijung and Buice, Michael A and Barry, Caswell and Hayman, Robin and Burgess, Neil and Fiete, Ila R},
	month = aug,
	year = {2013},
	pages = {1077--1084},
}

@article{fiete_model_2007-1,
	title = {Model of birdsong learning based on gradient estimation by dynamic perturbation of neural conductances},
	volume = {98},
	abstract = {We propose a model of songbird learning that focuses on avian brain areas HVC and RA, involved in song production, and area LMAN, important for generating song variability. Plasticity at HVC –{\textgreater} RA synapses is driven by hypothetical “rules” depending on three signals: activation of HVC –{\textgreater} RA synapses, activation of LMAN –{\textgreater} RA synapses, and reinforcement from an internal critic that compares the bird's own song with a memorized template of an adult tutor's song. Fluctuating glutamatergic input to RA from LMAN generates behavioral variability for trial-and-error learning. The plasticity rules perform gradient-based reinforcement learning in a spiking neural network model of song production. Although the reinforcement signal is delayed, temporally imprecise, and binarized, the model learns in a reasonable amount of time in numerical simulations. Varying the number of neurons in HVC and RA has little effect on learning time. The model makes specific predictions for the induction of bidirectional long-term plasticity at HVC –{\textgreater} RA synapses.},
	language = {en},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Fiete, Ila R and Fee, Michale S and Seung, H Sebastian},
	month = oct,
	year = {2007},
	pages = {2038--2057},
}

@article{murthy_testing_2008-1,
	title = {Testing odor response stereotypy in the {Drosophila} mushroom body},
	volume = {59},
	abstract = {The mushroom body is an insect brain structure required for olfactory learning. Its principal neurons, the Kenyon cells (KCs), form a large cell population. The neuronal populations from which their olfactory input derives (olfactory sensory and projection neurons) can be identified individually by genetic, anatomical, and physiological criteria. We ask whether KCs are similarly identifiable individually, using genetic markers and whole-cell patch-clamp in vivo. We find that across-animal responses are as diverse within the genetically labeled subset as across all KCs in a larger sample. These results combined with those from a simple model, using projection neuron odor responses as inputs, suggest that the precise circuit specification seen at earlier stages of odor processing is likely absent among the mushroom body KCs.},
	language = {en},
	number = {6},
	journal = {Neuron},
	author = {Murthy, Mala and Fiete, Ila and Laurent, Gilles},
	month = sep,
	year = {2008},
	pages = {1009--1023},
}

@article{fiete_gradient_2006-1,
	title = {Gradient learning in spiking neural networks by dynamic perturbation of conductances},
	volume = {97},
	abstract = {We present a method of estimating the gradient of an objective function with respect to the synaptic weights of a spiking neural network. The method works by measuring the fluctuations in the objective function in response to dynamic perturbation of the membrane conductances of the neurons. It is compatible with recurrent networks of conductance-based model neurons with dynamic synapses. The method can be interpreted as a biologically plausible synaptic learning rule, if the dynamic perturbations are generated by a special class of “empiric” synapses driven by random spike trains from an external source.},
	language = {en},
	number = {4},
	journal = {Phys. Rev. Lett.},
	author = {Fiete, Ila R and Seung, H Sebastian},
	month = jul,
	year = {2006},
	pages = {048104},
}

@article{fiete_temporal_2004-1,
	title = {Temporal sparseness of the premotor drive is important for rapid learning in a neural network model of birdsong},
	volume = {92},
	abstract = {Sparse neural codes have been widely observed in cortical sensory and motor areas. A striking example of sparse temporal coding is in the song-related premotor area high vocal center (HVC) of songbirds: The motor neurons innervating avian vocal muscles are driven by premotor nucleus robustus archistriatalis (RA), which is in turn driven by nucleus HVC. Recent experiments reveal that RA-projecting HVC neurons fire just one burst per song motif. However, the function of this remarkable temporal sparseness has remained unclear. Because birdsong is a clear example of a learned complex motor behavior, we explore in a neural network model with the help of numerical and analytical techniques the possible role of sparse premotor neural codes in song-related motor learning. In numerical simulations with nonlinear neurons, as HVC activity is made progressively less sparse, the minimum learning time increases significantly. Heuristically, this slowdown arises from increasing interference in the weight updates for different synapses. If activity in HVC is sparse, synaptic interference is reduced, and is minimized if each synapse from HVC to RA is used only once in the motif, which is the situation observed experimentally. Our numerical results are corroborated by a theoretical analysis of learning in linear networks, for which we derive a relationship between sparse activity, synaptic interference, and learning time. If songbirds acquire their songs under significant pressure to learn quickly, this study predicts that HVC activity, currently measured only in adults, should also be sparse during the sensorimotor phase in the juvenile bird. We discuss the relevance of these results, linking sparse codes and learning speed, to other multilayered sensory and motor systems.},
	language = {en},
	number = {4},
	journal = {J. Neurophysiol.},
	author = {Fiete, Ila R and Hahnloser, Richard H R and Fee, Michale S and Seung, H Sebastian},
	month = oct,
	year = {2004},
	pages = {2274--2282},
}

@article{welinder_grid_2008-2,
	title = {Grid cells: the position code, neural network models of activity, and the problem of learning},
	volume = {18},
	abstract = {We review progress on the modeling and theoretical fronts in the quest to unravel the computational properties of the grid cell code and to explain the mechanisms underlying grid cell dynamics. The goals of the review are to outline a coherent framework for understanding the dynamics of grid cells and their representation of space; to critically present and draw contrasts between recurrent network models of grid cells based on continuous attractor dynamics and independent-neuron models based on temporal interference; and to suggest open questions for experiment and theory.},
	language = {en},
	number = {12},
	journal = {Hippocampus},
	author = {Welinder, Peter E and Burak, Yoram and Fiete, Ila R},
	year = {2008},
	pages = {1283--1300},
}

@article{widloski_model_2014-1,
	title = {A model of grid cell development through spatial exploration and spike time-dependent plasticity},
	volume = {83},
	abstract = {Grid cell responses develop gradually after eye opening, but little is known about the rules that govern this process. We present a biologically plausible model for the formation of a grid cell network. An asymmetric spike time-dependent plasticity rule acts upon an initially unstructured network of spiking neurons that receive inputs encoding animal velocity and location. Neurons develop an organized recurrent architecture based on the similarity of their inputs, interacting through inhibitory interneurons. The mature network can convert velocity inputs into estimates of animal location, showing that spatially periodic responses and the capacity of path integration can arise through synaptic plasticity, acting on inputs that display neither. The model provides numerous predictions about the necessity of spatial exploration for grid cell development, network topography, the maturation of velocity tuning and neural correlations, the abrupt transition to stable patterned responses, and possible mechanisms to set grid period across grid modules.},
	language = {en},
	number = {2},
	journal = {Neuron},
	author = {Widloski, John and Fiete, Ila R},
	month = jul,
	year = {2014},
	pages = {481--495},
}

@article{gu_map-like_2018-1,
	title = {A {Map}-like {Micro}-{Organization} of {Grid} {Cells} in the {Medial} {Entorhinal} {Cortex}},
	volume = {175},
	abstract = {How the topography of neural circuits relates to their function remains unclear. Although topographic maps exist for sensory and motor variables, they are rarely observed for cognitive variables. Using calcium imaging during virtual navigation, we investigated the relationship between the anatomical organization and functional properties of grid cells, which represent a cognitive code for location during navigation. We found a substantial degree of grid cell micro-organization in mouse medial entorhinal cortex: grid cells and modules all clustered anatomically. Within a module, the layout of grid cells was a noisy two-dimensional lattice in which the anatomical distribution of grid cells largely matched their spatial tuning phases. This micro-arrangement of phases demonstrates the existence of a topographical map encoding a cognitive variable in rodents. It contributes to a foundation for evaluating circuit models of the grid cell network and is consistent with continuous attractor models as the mechanism of grid formation.},
	language = {en},
	number = {3},
	journal = {Cell},
	author = {Gu, Yi and Lewallen, Sam and Kinkhabwala, Amina A and Domnisoru, Cristina and Yoon, Kijung and Gauthier, Jeffrey L and Fiete, Ila R and Tank, David W},
	month = oct,
	year = {2018},
	keywords = {grid cell, virtual reality, calcium imaging, grid module, continuous attractor network models, grid phase, medial entorhinal cortex, microprism, pyramidal cell, stellate cell},
	pages = {736--750.e30},
}

@article{trettel_grid_2019-1,
	title = {Grid cell co-activity patterns during sleep reflect spatial overlap of grid fields during active behaviors},
	volume = {22},
	abstract = {Continuous-attractor network models of grid formation posit that recurrent connectivity between grid cells controls their patterns of co-activation. Grid cells from a common module exhibit stable offsets in their periodic spatial tuning curves across environments, and this may reflect recurrent connectivity or correlated sensory inputs. Here we explore whether cell-cell relationships predicted by attractor models persist during sleep states in which spatially informative sensory inputs are absent. We recorded ensembles of grid cells in superficial layers of medial entorhinal cortex during active exploratory behaviors and overnight sleep. Per grid cell pair and collectively, and across waking, rapid eye movement sleep and non-rapid eye movement sleep, we found preserved patterns of spike-time correlations that reflected the spatial tuning offsets between these grid cells during active exploration. The preservation of cell-cell relationships across waking and sleep states was not explained by theta oscillations or activity in hippocampal subregion CA1. These results indicate that recurrent connectivity within the grid cell network drives grid cell activity across behavioral states.},
	language = {en},
	number = {4},
	journal = {Nat. Neurosci.},
	author = {Trettel, Sean G and Trimper, John B and Hwaun, Ernie and Fiete, Ila R and Colgin, Laura Lee},
	month = apr,
	year = {2019},
	pages = {609--617},
}

@article{burak_we_2006,
	title = {Do we understand the emergent dynamics of grid cell activity?},
	volume = {26},
	language = {en},
	number = {37},
	journal = {J. Neurosci.},
	author = {Burak, Yoram and Fiete, Ila},
	month = sep,
	year = {2006},
	pages = {9352--4; discussion 9354},
}

@article{yoon_grid_2016-1,
	title = {Grid {Cell} {Responses} in {1D} {Environments} {Assessed} as {Slices} through a {2D} {Lattice}},
	volume = {89},
	abstract = {Grid cells, defined by their striking periodic spatial responses in open 2D arenas, appear to respond differently on 1D tracks: the multiple response fields are not periodically arranged, peak amplitudes vary across fields, and the mean spacing between fields is larger than in 2D environments. We ask whether such 1D responses are consistent with the system's 2D dynamics. Combining analytical and numerical methods, we show that the 1D responses of grid cells with stable 1D fields are consistent with a linear slice through a 2D triangular lattice. Further, the 1D responses of comodular cells are well described by parallel slices, and the offsets in the starting points of the 1D slices can predict the measured 2D relative spatial phase between the cells. From these results, we conclude that the 2D dynamics of these cells is preserved in 1D, suggesting a common computation during both types of navigation behavior.},
	language = {en},
	number = {5},
	journal = {Neuron},
	author = {Yoon, Kijung and Lewallen, Sam and Kinkhabwala, Amina A and Tank, David W and Fiete, Ila R},
	month = mar,
	year = {2016},
	pages = {1086--1099},
}

@article{kanitscheider_training_2017-1,
	title = {Training recurrent networks to generate hypotheses about how the brain solves hard navigation problems},
	abstract = {Self-localization during navigation with noisy sensors in an ambiguous world is computationally challenging, yet animals and humans excel at it. In robotics,\{\vphantom{\}}{\textbackslash}textbackslashem …},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Kanitscheider, I and Fiete, I},
	year = {2017},
	note = {Publisher: proceedings.neurips.cc},
}

@article{international_brain_laboratory_electronic_address_churchlandcshledu_international_2017-1,
	title = {An {International} {Laboratory} for {Systems} and {Computational} {Neuroscience}},
	volume = {96},
	abstract = {The neural basis of decision-making has been elusive and involves the coordinated activity of multiple brain structures. This NeuroView, by the International Brain Laboratory (IBL), discusses their efforts to develop a standardized mouse decision-making behavior, to make coordinated measurements of neural activity across the mouse brain, and to use theory and analyses to uncover the neural computations that support decision-making.},
	language = {en},
	number = {6},
	journal = {Neuron},
	author = {{International Brain Laboratory. Electronic address: churchland@cshl.edu} and {International Brain Laboratory}},
	month = dec,
	year = {2017},
	pages = {1213--1218},
}

@article{chen_bias_2015-1,
	title = {Bias in {Human} {Path} {Integration} {Is} {Predicted} by {Properties} of {Grid} {Cells}},
	volume = {25},
	abstract = {Accurate wayfinding is essential to the survival of many animal species and requires the ability to maintain spatial orientation during locomotion. One of the ways that humans and other animals stay spatially oriented is through path integration, which operates by integrating self-motion cues over time, providing information about total displacement from a starting point. The neural substrate of path integration in mammals may exist in grid cells, which are found in dorsomedial entorhinal cortex and presubiculum and parasubiculum in rats. Grid cells have also been found in mice, bats, and monkeys, and signatures of grid cell activity have been observed in humans. We demonstrate that distance estimation by humans during path integration is sensitive to geometric deformations of a familiar environment and show that patterns of path integration error are predicted qualitatively by a model in which locations in the environment are represented in the brain as phases of arrays of grid cells with unique periods and decoded by the inverse mapping from phases to locations. The periods of these grid networks are assumed to expand and contract in response to expansions and contractions of a familiar environment. Biases in distance estimation occur when the periods of the encoding and decoding grids differ. Our findings explicate the way in which grid cells could function in human path integration.},
	language = {en},
	number = {13},
	journal = {Curr. Biol.},
	author = {Chen, Xiaoli and He, Qiliang and Kelly, Jonathan W and Fiete, Ila R and McNamara, Timothy P},
	month = jun,
	year = {2015},
	pages = {1771--1776},
}

@article{das_systematic_2020-1,
	title = {Systematic errors in connectivity inferred from activity in strongly recurrent networks},
	volume = {23},
	abstract = {Understanding the mechanisms of neural computation and learning will require knowledge of the underlying circuitry. Because it is difficult to directly measure the wiring diagrams of neural circuits, there has long been an interest in estimating them algorithmically from multicell activity recordings. We show that even sophisticated methods, applied to unlimited data from every cell in the circuit, are biased toward inferring connections between unconnected but highly correlated neurons. This failure to 'explain away' connections occurs when there is a mismatch between the true network dynamics and the model used for inference, which is inevitable when modeling the real world. Thus, causal inference suffers when variables are highly correlated, and activity-based estimates of connectivity should be treated with special caution in strongly connected networks. Finally, performing inference on the activity of circuits pushed far out of equilibrium by a simple low-dimensional suppressive drive might ameliorate inference bias.},
	language = {en},
	number = {10},
	journal = {Nat. Neurosci.},
	author = {Das, Abhranil and Fiete, Ila R},
	month = oct,
	year = {2020},
	pages = {1286--1296},
}

@article{klukas_efficient_2020-1,
	title = {Efficient and flexible representation of higher-dimensional cognitive variables with grid cells},
	volume = {16},
	abstract = {We shed light on the potential of entorhinal grid cells to efficiently encode variables of dimension greater than two, while remaining faithful to empirical data on their low-dimensional structure. Our model constructs representations of high-dimensional inputs through a combination of low-dimensional random projections and “classical” low-dimensional hexagonal grid cell responses. Without reconfiguration of the recurrent circuit, the same system can flexibly encode multiple variables of different dimensions while maximizing the coding range (per dimension) by automatically trading-off dimension with an exponentially large coding range. It achieves high efficiency and flexibility by combining two powerful concepts, modularity and mixed selectivity, in what we call “mixed modular coding”. In contrast to previously proposed schemes, the model does not require the formation of higher-dimensional grid responses, a cell-inefficient and rigid mechanism. The firing fields observed in flying bats or climbing rats can be generated by neurons that combine activity from multiple grid modules, each representing higher-dimensional spaces according to our model. The idea expands our understanding of grid cells, suggesting that they could implement a general circuit that generates on-demand coding and memory states for variables in high-dimensional vector spaces.},
	language = {en},
	number = {4},
	journal = {PLoS Comput. Biol.},
	author = {Klukas, Mirko and Lewis, Marcus and Fiete, Ila},
	month = apr,
	year = {2020},
	pages = {e1007796},
}

@article{stangl_sources_2020-1,
	title = {Sources of path integration error in young and aging humans},
	volume = {11},
	abstract = {Path integration plays a vital role in navigation: it enables the continuous tracking of one's position in space by integrating self-motion cues. Path integration abilities vary widely across individuals, and tend to deteriorate in old age. The specific causes of path integration errors, however, remain poorly characterized. Here, we combine tests of path integration performance in participants of different ages with an analysis based on the Langevin equation for diffusive dynamics, which allows us to decompose errors into distinct causes that can corrupt path integration computations. We show that, across age groups, the dominant error source is unbiased noise that accumulates with travel distance not elapsed time, suggesting that the noise originates in the velocity input rather than within the integrator. Age-related declines are primarily traced to a growth in this noise. These findings shed light on the contributors to path integration error and the mechanisms underlying age-related navigational deficits.},
	language = {en},
	number = {1},
	journal = {Nat. Commun.},
	author = {Stangl, Matthias and Kanitscheider, Ingmar and Riemer, Martin and Fiete, Ila and Wolbers, Thomas},
	month = may,
	year = {2020},
	pages = {2626},
}

@article{koyluoglu_fundamental_2017-1,
	title = {Fundamental bound on the persistence and capacity of short-term memory stored as graded persistent activity},
	volume = {6},
	abstract = {It is widely believed that persistent neural activity underlies short-term memory. Yet, as we show, the degradation of information stored directly in such networks behaves differently from human short-term memory performance. We build a more general framework where memory is viewed as a problem of passing information through noisy channels whose degradation characteristics resemble those of persistent activity networks. If the brain first encoded the information appropriately before passing the information into such networks, the information can be stored substantially more faithfully. Within this framework, we derive a fundamental lower-bound on recall precision, which declines with storage duration and number of stored items. We show that human performance, though inconsistent with models involving direct (uncoded) storage in persistent activity networks, can be well-fit by the theoretical bound. This finding is consistent with the view that if the brain stores information in patterns of persistent activity, it might use codes that minimize the effects of noise, motivating the search for such codes in the brain.},
	language = {en},
	journal = {Elife},
	author = {Koyluoglu, Onur Ozan and Pertzov, Yoni and Manohar, Sanjay and Husain, Masud and Fiete, Ila R},
	month = sep,
	year = {2017},
	keywords = {human, neuroscience, computational biology, systems biology, short term memory, forgetting, information theory},
}

@article{roth_kernel_2018,
	title = {Kernel rnn learning (kernl)},
	abstract = {We describe Kernel RNN Learning (KeRNL), a reduced-rank, temporal eligibility trace- based approximation to backpropagation through time (BPTT) for training recurrent neural …},
	journal = {International Conference on},
	author = {Roth, C and Kanitscheider, I and Fiete, I},
	year = {2018},
	note = {Publisher: openreview.net},
}

@article{burak_triangular_2006,
	title = {Triangular lattice neurons may implement an advanced numeral system to precisely encode rat position over large ranges},
	abstract = {We argue by observation of the neural data that neurons in area dMEC of rats, which fire whenever the rat is on any vertex of a regular triangular lattice that tiles 2-d space, may be …},
	journal = {arXiv preprint q-bio/0606005},
	author = {Burak, Y and Brookings, T and Fiete, I},
	year = {2006},
	note = {Publisher: arxiv.org},
}

@article{chaudhuri_bipartite_2019-1,
	title = {Bipartite expander {Hopfield} networks as self-decoding high-capacity error correcting codes},
	abstract = {Neural network models of memory and error correction famously include the Hopfield network, which can directly store—and error-correct through its dynamics—arbitrary N-bit …},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {Chaudhuri, R and Fiete, I},
	year = {2019},
	note = {Publisher: proceedings.neurips.cc},
}

@article{widloski_how_2014-1,
	title = {How does the brain solve the computational problems of spatial navigation?},
	abstract = {Flexible navigation in the real world involves the ability to maintain an ongoing estimate of one's location in the environment, to use landmarks to help navigate, and to construct …},
	journal = {Space, time and memory in the hippocampal formation},
	author = {Widloski, J and Fiete, I},
	year = {2014},
	note = {Publisher: Springer},
}

@article{fiete_binary_2014-1,
	title = {A binary {Hopfield} network with information rate and applications to grid cell decoding},
	abstract = {A Hopfield network is an auto-associative, distributive model of neural memory storage and retrieval. A form of error-correcting code, the Hopfield network can learn a set of patterns as …},
	journal = {arXiv preprint arXiv:1407.6029},
	author = {Fiete, I and Schwab, D J and Tran, N M},
	year = {2014},
	note = {Publisher: arxiv.org},
}

@article{widloski_inferring_2018-1,
	title = {Inferring circuit mechanisms from sparse neural recording and global perturbation in grid cells},
	volume = {7},
	abstract = {A goal of systems neuroscience is to discover the circuit mechanisms underlying brain function. Despite experimental advances that enable circuit-wide neural recording, the problem remains open in part because solving the 'inverse problem' of inferring circuity and mechanism by merely observing activity is hard. In the grid cell system, we show through modeling that a technique based on global circuit perturbation and examination of a novel theoretical object called the distribution of relative phase shifts (DRPS) could reveal the mechanisms of a cortical circuit at unprecedented detail using extremely sparse neural recordings. We establish feasibility, showing that the method can discriminate between recurrent versus feedforward mechanisms and amongst various recurrent mechanisms using recordings from a handful of cells. The proposed strategy demonstrates that sparse recording coupled with simple perturbation can reveal more about circuit mechanism than can full knowledge of network activity or the synaptic connectivity matrix.},
	language = {en},
	journal = {Elife},
	author = {Widloski, John and Marder, Michael P and Fiete, Ila R},
	month = jul,
	year = {2018},
	keywords = {grid cells, neuroscience, none, attractor dynamics, circuit perturbation, recurrent networks},
}

@article{kanitscheider_emergence_2017-1,
	title = {Emergence of dynamically reconfigurable hippocampal responses by learning to perform probabilistic spatial reasoning},
	abstract = {Navigation in natural environments is computationally difficult: Location errors from motion estimation noise accumulate over time, while landmarks can be spatially extended and often …},
	journal = {bioRxiv},
	author = {Kanitscheider, I and Fiete, I},
	year = {2017},
	note = {Publisher: biorxiv.org},
}

@article{yim_place-cell_2021-1,
	title = {Place-cell capacity and volatility with grid-like inputs},
	volume = {10},
	abstract = {What factors constrain the arrangement of the multiple fields of a place cell? By modeling place cells as perceptrons that act on multiscale periodic grid-cell inputs, we analytically enumerate a place cell's repertoire - how many field arrangements it can realize without external cues while its grid inputs are unique - and derive its capacity - the spatial range over which it can achieve any field arrangement. We show that the repertoire is very large and relatively noise-robust. However, the repertoire is a vanishing fraction of all arrangements, while capacity scales only as the sum of the grid periods so field arrangements are constrained over larger distances. Thus, grid-driven place field arrangements define a large response scaffold that is strongly constrained by its structured inputs. Finally, we show that altering grid-place weights to generate an arbitrary new place field strongly affects existing arrangements, which could explain the volatility of the place code.},
	language = {en},
	journal = {Elife},
	author = {Yim, Man Yi and Sadun, Lorenzo A and Fiete, Ila R and Taillefumier, Thibaud},
	month = may,
	year = {2021},
	keywords = {grid cells, place cells, neuroscience, capacity, computational biology, linear separability, none, perceptron, systems biology, volatility},
}

@article{widloski_cortical_2015,
	title = {Cortical microcircuit determination through global perturbation and sparse sampling in grid cells},
	abstract = {Under modern interrogation, famously well-studied neural circuits such as that for orientation tuning in V1 are steadily giving up their secrets, but quite basic questions about connectivity …},
	journal = {bioRxiv},
	author = {Widloski, J and Fiete, I R},
	year = {2015},
	note = {Publisher: biorxiv.org},
}

@article{das_systematic_2019,
	title = {Systematic errors in connectivity inferred from activity in strongly coupled recurrent circuits},
	abstract = {Understanding the mechanisms of neural computation and learning will require knowledge of the underlying circuitry. Because it is slow, expensive, or often infeasible to directly …},
	journal = {bioRxiv},
	author = {Das, A and Fiete, I R},
	year = {2019},
	note = {Publisher: biorxiv.org},
}

@article{khona_attractor_2021-1,
	title = {Attractor and integrator networks in the brain},
	abstract = {Attractor neural networks are some of the most-studied circuit models of brain function. We discuss the utility of low-dimensional attractors for computation in the brain, provide a …},
	journal = {arXiv preprint arXiv:2112.03978},
	author = {Khona, M and Fiete, I R},
	year = {2021},
	note = {Publisher: arxiv.org},
}

@article{schaeffer_efficient_2021-1,
	title = {Efficient online inference for nonparametric mixture models},
	abstract = {Natural data are often well-described as belonging to latent clusters. When the number of clusters is unknown, Bayesian nonparametric (BNP) models can provide a flexible and …},
	journal = {Uncertain. Artif. Intell.},
	author = {Schaeffer, R and Bordelon, B and Khona, M and {others}},
	year = {2021},
	note = {Publisher: proceedings.mlr.press},
}

@article{kriener_robust_2020-1,
	title = {Robust parallel decision-making in neural circuits with nonlinear inhibition},
	volume = {117},
	abstract = {An elemental computation in the brain is to identify the best in a set of options and report its value. It is required for inference, decision-making, optimization, action selection, consensus, and foraging. Neural computing is considered powerful because of its parallelism; however, it is unclear whether neurons can perform this max-finding operation in a way that improves upon the prohibitively slow optimal serial max-finding computation (which takes [Formula: see text] time for N noisy candidate options) by a factor of N, the benchmark for parallel computation. Biologically plausible architectures for this task are winner-take-all (WTA) networks, where individual neurons inhibit each other so only those with the largest input remain active. We show that conventional WTA networks fail the parallelism benchmark and, worse, in the presence of noise, altogether fail to produce a winner when N is large. We introduce the nWTA network, in which neurons are equipped with a second nonlinearity that prevents weakly active neurons from contributing inhibition. Without parameter fine-tuning or rescaling as N varies, the nWTA network achieves the parallelism benchmark. The network reproduces experimentally observed phenomena like Hick's law without needing an additional readout stage or adaptive N-dependent thresholds. Our work bridges scales by linking cellular nonlinearities to circuit-level decision-making, establishes that distributed computation saturating the parallelism benchmark is possible in networks of noisy, finite-memory neurons, and shows that Hick's law may be a symptom of near-optimal parallel decision-making with noisy input.},
	language = {en},
	number = {41},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Kriener, Birgit and Chaudhuri, Rishidev and Fiete, Ila R},
	month = oct,
	year = {2020},
	keywords = {neural circuits, noisy computation, optimal decision-making, speed–accuracy trade-off},
	pages = {25505--25516},
}

@article{mulders_structured_2021,
	title = {A structured scaffold underlies activity in the hippocampus},
	abstract = {Place cells are believed to organize memory across space and time, inspiring the idea of the cognitive map. Yet unlike the structured activity in the associated grid and head-direction …},
	journal = {bioRxiv},
	author = {Mulders, D and Yim, M Y and Lee, J S and Lee, A K and Taillefumier, T and {others}},
	year = {2021},
	note = {Publisher: biorxiv.org},
}

@article{sanders_efficient_2020-1,
	title = {Efficient {Inference} in {Structured} {Spaces}},
	volume = {183},
	abstract = {Whittington et al. demonstrate how network architectures defined in a spatial context may be useful for inference on different types of relational knowledge. These architectures allow for learning the structure of the environment and then transferring that knowledge to allow prediction of novel transitions.},
	language = {en},
	number = {5},
	journal = {Cell},
	author = {Sanders, Honi and Wilson, Matthew and Klukas, Mirko and Sharma, Sugandha and Fiete, Ila},
	month = nov,
	year = {2020},
	pages = {1147--1148},
}

@article{klukas_efficient_2020-2,
	title = {Efficient and flexible representation of higher-dimensional cognitive variables with grid cells},
	volume = {16},
	abstract = {We shed light on the potential of entorhinal grid cells to efficiently encode variables of dimension greater than two, while remaining faithful to empirical data on their low-dimensional structure. Our model constructs representations of high-dimensional inputs through a combination of low-dimensional random projections and “classical” low-dimensional hexagonal grid cell responses. Without reconfiguration of the recurrent circuit, the same system can flexibly encode multiple variables of different dimensions while maximizing the coding range (per dimension) by automatically trading-off dimension with an exponentially large coding range. It achieves high efficiency and flexibility by combining two powerful concepts, modularity and mixed selectivity, in what we call “mixed modular coding”. In contrast to previously proposed schemes, the model does not require the formation of higher-dimensional grid responses, a cell-inefficient and rigid mechanism. The firing fields observed in flying bats or climbing rats can be generated by neurons that combine activity from multiple grid modules, each representing higher-dimensional spaces according to our model. The idea expands our understanding of grid cells, suggesting that they could implement a general circuit that generates on-demand coding and memory states for variables in high-dimensional vector spaces.},
	language = {en},
	number = {4},
	journal = {PLoS Comput. Biol.},
	author = {Klukas, Mirko and Lewis, Marcus and Fiete, Ila},
	month = apr,
	year = {2020},
	pages = {e1007796},
}

@inproceedings{boopathy_how_2022-1,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {How to {Train} {Your} {Wide} {Neural} {Network} {Without} {Backprop}: {An} {Input}-{Weight} {Alignment} {Perspective}},
	volume = {162},
	abstract = {Recent works have examined theoretical and empirical properties of wide neural networks trained in the Neural Tangent Kernel (NTK) regime. Given that biological neural networks are much wider than their artificial counterparts, we consider NTK regime wide neural networks as a possible model of biological neural networks. Leveraging NTK theory, we show theoretically that gradient descent drives layerwise weight updates that are aligned with their input activity correlations weighted by error, and demonstrate empirically that the result also holds in finite-width wide networks. The alignment result allows us to formulate a family of biologically-motivated, backpropagation-free learning rules that are theoretically equivalent to backpropagation in infinite-width networks. We test these learning rules on benchmark problems in feedforward and recurrent neural networks and demonstrate, in wide networks, comparable performance to backpropagation. The proposed rules are particularly effective in low data regimes, which are common in biological learning settings.},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Boopathy, Akhilan and Fiete, Ila},
	editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
	year = {2022},
	pages = {2178--2205},
}

@inproceedings{sharma_content_2022-1,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Content {Addressable} {Memory} {Without} {Catastrophic} {Forgetting} by {Heteroassociation} with a {Fixed} {Scaffold}},
	volume = {162},
	abstract = {Content-addressable memory (CAM) networks, so-called because stored items can be recalled by partial or corrupted versions of the items, exhibit near-perfect recall of a small number of information-dense patterns below capacity and a 'memory cliff' beyond, such that inserting a single additional pattern results in catastrophic loss of all stored patterns. We propose a novel CAM architecture, Memory Scaffold with Heteroassociation (MESH), that factorizes the problems of internal attractor dynamics and association with external content to generate a CAM continuum without a memory cliff: Small numbers of patterns are stored with complete information recovery matching standard CAMs, while inserting more patterns still results in partial recall of every pattern, with a graceful trade-off between pattern number and pattern richness. Motivated by the architecture of the Entorhinal-Hippocampal memory circuit in the brain, MESH is a tripartite architecture with pairwise interactions that uses a predetermined set of internally stabilized states together with heteroassociation between the internal states and arbitrary external patterns. We show analytically and experimentally that for any number of stored patterns, MESH nearly saturates the total information bound (given by the number of synapses) for CAM networks, outperforming all existing CAM models.},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Sharma, Sugandha and Chandra, Sarthak and Fiete, Ila},
	editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
	year = {2022},
	pages = {19658--19682},
}

@article{khona_spontaneous_2021-1,
	title = {Spontaneous emergence of topologically robust grid cell modules: {A} multiscale instability theory},
	abstract = {Modular structures in the brain play a central role in compositionality and intelligence, however the general mechanisms driving module emergence have remained elusive. Studying entorhinal grid cells as paradigmatic examples of modular architecture and function, we demonstrate the spontaneous emergence of a small number of discrete spatial and functional modules from an interplay between continuously varying lateral interactions generated by smooth cortical gradients. We derive a comprehensive analytic theory of …},
	journal = {bioRxiv},
	author = {Khona, M and Chandra, S and Fiete, I},
	year = {2021},
	note = {Publisher: biorxiv.org},
}

@unpublished{schaeffer_no_2022-2,
	title = {No {Free} {Lunch} from {Deep} {Learning} in {Neuroscience}: {A} {Case} {Study} through {Models} of the {Entorhinal}-{Hippocampal} {Circuit}},
	author = {Schaeffer, Rylan and Khona, Mikail and Fiete, Ila R},
	month = jul,
	year = {2022},
}

@unpublished{international_brain_laboratory_reproducibility_2022,
	title = {Reproducibility of in-vivo electrophysiological measurements in mice},
	abstract = {Understanding whole-brain-scale electrophysiological recordings will rely on the collective work of multiple labs. Because two labs recording from the same brain area often reach different conclusions, it is critical to quantify and control for features that decrease reproducibility. To address these issues, we formed a multi-lab collaboration using a shared, open-source behavioral task and experimental apparatus. We repeatedly inserted Neuropixels multi-electrode probes targeting the same brain locations (including posterior parietal cortex, hippocampus, and thalamus) in mice performing the behavioral task. We gathered data across 9 labs and developed a common histological and data processing pipeline to analyze the resulting large datasets. After applying stringent behavioral, histological, and electrophysiological quality-control criteria, we found that neuronal yield, firing rates, spike amplitudes, and task-modulated neuronal activity were reproducible across laboratories. To quantify variance in neural activity explained by task variables (e.g., stimulus onset time), behavioral variables (timing of licks/paw movements), and other variables (e.g., spatial location in the brain or the lab ID), we developed a multi-task neural network encoding model that extends common, simpler regression approaches by allowing nonlinear interactions between variables. We found that within-lab random effects captured by this model were comparable to between-lab random effects. Taken together, these results demonstrate that across-lab standardization of electrophysiological procedures can lead to reproducible results across labs. Moreover, our protocols to achieve reproducibility, along with our analyses to evaluate it are openly accessible to the scientific community, along with our extensive electrophysiological dataset with corresponding behavior and open-source analysis code. \#\#\# Competing Interest Statement The authors have declared no competing interest.},
	language = {en},
	author = {{International Brain Laboratory} and Banga, Kush and Benson, Julius and Bonacchi, Niccolò and Bruijns, Sebastian A and Campbell, Rob and Chapuis, Gaëlle A and Churchland, Anne K and Felicia Davatolhagh, M and Lee, Hyun Dong and Faulkner, Mayo and Hu, Fei and Hunterberg, Julia and Khanal, Anup and Krasniak, Christopher and Meijer, Guido T and Miska, Nathaniel J and Mohammadi, Zeinab and Noel, Jean-Paul and Paninski, Liam and Pan-Vazquez, Alejandro and Roth, Noam and Schartner, Michael and Socha, Karolina and Steinmetz, Nicholas A and Taheri, Marsa and Urai, Anne E and Wells, Miles and West, Steven J and Whiteway, Matthew R and Winter, Olivier},
	month = may,
	year = {2022},
	note = {Publication Title: bioRxiv},
}

@article{boopathy_gradient-trained_2021,
	title = {Gradient-trained {Weights} in {Wide} {Neural} {Networks} {Align} {Layerwise} to {Error}-scaled {Input} {Correlations}},
	abstract = {Recent works have examined how deep neural networks, which can solve a variety of difficult problems, incorporate the statistics of training data to achieve their success …},
	journal = {arXiv preprint arXiv:2106.08453},
	author = {Boopathy, A and Fiete, I},
	year = {2021},
	note = {Publisher: arxiv.org},
}

@article{fiete_ila_2021,
	title = {Ila {Fiete}},
	volume = {31},
	abstract = {Interview with Ila Fiete, who studies the microscopic cellular and synaptic processes responsible for behaviors of memory and cognition in the brain at Massachusetts Institute of Technology.},
	language = {en},
	number = {24},
	journal = {Curr. Biol.},
	author = {Fiete, Ila},
	month = dec,
	year = {2021},
	pages = {R1552--R1555},
}

@unpublished{voigts_spatial_2022,
	title = {Spatial reasoning via recurrent neural dynamics in mouse retrosplenial cortex},
	abstract = {From visual perception to language, sensory stimuli change their meaning depending on prior experience. Recurrent neural dynamics can interpret stimuli based on externally cued context, but it is unknown whether similar dynamics can compute and employ internal hypotheses to resolve ambiguities. Here, we show that mouse retrosplenial cortex (RSC) can form hypotheses over time and perform spatial reasoning through recurrent dynamics. In our task, mice navigated using ambiguous landmarks that are identified through their mutual spatial relationship, requiring sequential refinement of hypotheses. Neurons in RSC and in artificial neural networks encoded mixtures of hypotheses, location, and sensory information, and were constrained by robust low dimensional dynamics. RSC encoded hypotheses as locations in activity space with divergent trajectories for identical sensory inputs, enabling their correct interpretation. Our results indicate that interactions between internal hypotheses and external sensory data in recurrent circuits can provide a substrate for complex sequential cognitive reasoning. \#\#\# Competing Interest Statement The authors have declared no competing interest.},
	language = {en},
	author = {Voigts, Jakob and Kanitscheider, Ingmar and Miller, Nicholas J and Toloza, Enrique H S and Newman, Jonathan P and Fiete, Ila R and Harnett, Mark T},
	month = apr,
	year = {2022},
	note = {Publication Title: bioRxiv},
}

@article{sharma_efficient_2022,
	title = {Efficient exploration of spatial environments through {Map} {Induction} using adaptable compositional map representations},
	volume = {44},
	abstract = {Author(s): Sharma, Sugandha; Curtis, Aidan; Kryven, Marta; Tenenbaum, Josh; Fiete, Ila {\textbar} Abstract: How do humans find their way in new environments, so quickly and efficiently? Humans reuse old knowledge to build new concepts in many non-spatial domains, such as language and drawing. Could people learn maps by a similar process, that extracts common structure to speed up learning, and generalize across maps? Understanding the computational cognitive mechanisms that support this efficiency can advance the study of the human mind and enable more efficient exploration algorithms. We hypothesize that human map learning relies on inferences over the structure of unobserved spaces, based on spatial priors informed by previous experience. We model this by combining Program Induction with a Hierarchical Bayesian framework that explicitly reasons about uncertainty through strong spatial priors. Using a new behavioral Map Induction Task, we demonstrate that this computational framework explains human exploration behavior better than non-inductive models and outperforms state-of-the-art planning algorithms in a realistic spatial navigation domain.},
	number = {44},
	journal = {Proceedings of the Annual Meeting of the Cognitive Science Society},
	author = {Sharma, Sugandha and Curtis, Aidan and Kryven, Marta and Tenenbaum, Josh and Fiete, Ila},
	year = {2022},
	keywords = {Social and Behavioral Sciences},
}

@article{li_neurotensin_2022,
	title = {Neurotensin orchestrates valence assignment in the amygdala},
	abstract = {The ability to associate temporally segregated information and assign positive or negative valence to environmental cues is paramount for survival. Studies have shown that different projections from the basolateral amygdala (BLA) are potentiated following reward or punishment learning1-7. However, we do not yet understand how valence-specific information is routed to the BLA neurons with the appropriate downstream projections, nor do we understand how to reconcile the sub-second timescales of synaptic plasticity8-11 with the longer timescales separating the predictive cues from their outcomes. Here we demonstrate that neurotensin (NT)-expressing neurons in the paraventricular nucleus of the thalamus (PVT) projecting to the BLA (PVT-BLA:NT) mediate valence assignment by exerting NT concentration-dependent modulation in BLA during associative learning. We found that optogenetic activation of the PVT-BLA:NT projection promotes reward learning, whereas PVT-BLA projection-specific knockout of the NT gene (Nts) augments punishment learning. Using genetically encoded calcium and NT sensors, we further revealed that both calcium dynamics within the PVT-BLA:NT projection and NT concentrations in the BLA are enhanced after reward learning and reduced after punishment learning. Finally, we showed that CRISPR-mediated knockout of the Nts gene in the PVT-BLA pathway blunts BLA neural dynamics and attenuates the preference for active behavioural strategies to reward and punishment predictive cues. In sum, we have identified NT as a neuropeptide that signals valence in the BLA, and showed that NT is a critical neuromodulator that orchestrates positive and negative valence assignment in amygdala neurons by extending valence-specific plasticity to behaviourally relevant timescales.},
	language = {en},
	journal = {Nature},
	author = {Li, Hao and Namburi, Praneeth and Olson, Jacob M and Borio, Matilde and Lemieux, Mackenzie E and Beyeler, Anna and Calhoon, Gwendolyn G and Hitora-Imamura, Natsuko and Coley, Austin A and Libster, Avraham and Bal, Aneesh and Jin, Xin and Wang, Huan and Jia, Caroline and Choudhury, Sourav R and Shi, Xi and Felix-Ortiz, Ada C and de la Fuente, Verónica and Barth, Vanessa P and King, Hunter O and Izadmehr, Ehsan M and Revanna, Jasmin S and Batra, Kanha and Fischer, Kyle B and Keyes, Laurel R and Padilla-Coreano, Nancy and Siciliano, Cody A and McCullough, Kenneth M and Wichmann, Romy and Ressler, Kerry J and Fiete, Ila R and Zhang, Feng and Li, Yulong and Tye, Kay M},
	month = jul,
	year = {2022},
}

@article{sara_locus_2009,
	title = {The locus coeruleus and noradrenergic modulation of cognition},
	volume = {10},
	abstract = {Mood, attention and motivation co-vary with activity in the neuromodulatory systems of the brain to influence behaviour. These psychological states, mediated by neuromodulators, have a profound influence on the cognitive processes of attention, perception and, particularly, our ability to retrieve memories from the past and make new ones. Moreover, many psychiatric and neurodegenerative disorders are related to dysfunction of these neuromodulatory systems. Neurons of the brainstem nucleus locus coeruleus are the sole source of noradrenaline, a neuromodulator that has a key role in all of these forebrain activities. Elucidating the factors that control the activity of these neurons and the effect of noradrenaline in target regions is key to understanding how the brain allocates attention and apprehends the environment to select, store and retrieve information for generating adaptive behaviour.},
	language = {en},
	number = {3},
	journal = {Nat. Rev. Neurosci.},
	author = {Sara, Susan J},
	month = mar,
	year = {2009},
	pages = {211--223},
}

@unpublished{koulakov_encoding_2022,
	title = {Encoding innate ability through a genomic bottleneck},
	abstract = {Animals are born with extensive innate behavioral capabilities, which arise from neural circuits encoded in the genome. However, the information capacity of the genome is orders of magnitude smaller than that needed to specify the connectivity of an arbitrary brain circuit, indicating that the rules encoding circuit formation must fit through a “genomic bottleneck” as they pass from one generation to the next. Here we formulate the problem of innate behavioral capacity in the context of artificial neural networks in terms of lossy compression of the weight matrix. We find that several standard network architectures can be compressed by several orders of magnitude, yielding pre-training performance that can approach that of the fully-trained network. Interestingly, for complex but not for simple test problems, the genomic bottleneck algorithm also captures essential features of the circuit, leading to enhanced transfer learning to novel tasks and datasets. Our results suggest that compressing a neural circuit through the genomic bottleneck serves as a regularizer, enabling evolution to select simple circuits that can be readily adapted to important real-world tasks. The genomic bottleneck also suggests how innate priors can complement conventional approaches to learning in designing algorithms for artificial intelligence. \#\#\# Competing Interest Statement The authors have declared no competing interest.},
	language = {en},
	author = {Koulakov, Alexei and Shuvaev, Sergey and Lachi, Divyansha and Zador, Anthony},
	month = may,
	year = {2022},
	note = {Publication Title: bioRxiv},
}

@article{palacios-filardo_neuromodulation_2019,
	title = {Neuromodulation of hippocampal long-term synaptic plasticity},
	volume = {54},
	abstract = {Multiple neuromodulators including acetylcholine, noradrenaline, dopamine and serotonin are released in response to uncertainty to focus attention on events where the predicted outcome does not match observed reality. In these situations, internal representations need to be updated, a process that requires long-term synaptic plasticity. Through a variety of common and divergent mechanisms, it is recently shown that all these neuromodulators facilitate the induction and/or expression of long-term synaptic plasticity within the hippocampus. Under physiological conditions, this may be critical for suprathreshold induction of plasticity endowing neuromodulators with a gating function and providing a mechanism by which neuromodulators enable the targeted updating of memory with relevant information to improve the accuracy of future predictions.},
	language = {en},
	journal = {Curr. Opin. Neurobiol.},
	author = {Palacios-Filardo, Jon and Mellor, Jack R},
	month = feb,
	year = {2019},
	pages = {37--43},
}

@article{hasselmo_role_2006-1,
	title = {The role of acetylcholine in learning and memory},
	volume = {16},
	abstract = {Pharmacological data clearly indicate that both muscarinic and nicotinic acetylcholine receptors have a role in the encoding of new memories. Localized lesions and antagonist infusions demonstrate the anatomical locus of these cholinergic effects, and computational modeling links the function of cholinergic modulation to specific cellular effects within these regions. Acetylcholine has been shown to increase the strength of afferent input relative to feedback, to contribute to theta rhythm oscillations, activate intrinsic mechanisms for persistent spiking, and increase the modification of synapses. These effects might enhance different types of encoding in different cortical structures. In particular, the effects in entorhinal and perirhinal cortex and hippocampus might be important for encoding new episodic memories.},
	language = {en},
	number = {6},
	journal = {Curr. Opin. Neurobiol.},
	author = {Hasselmo, Michael E},
	month = dec,
	year = {2006},
	pages = {710--715},
}

@article{low_dynamic_2021,
	title = {Dynamic and reversible remapping of network representations in an unchanging environment},
	volume = {109},
	abstract = {Neurons in the medial entorhinal cortex alter their firing properties in response to environmental changes. This flexibility in neural coding is hypothesized to support navigation and memory by dividing sensory experience into unique episodes. However, it is unknown how the entorhinal circuit as a whole transitions between different representations when sensory information is not delineated into discrete contexts. Here we describe rapid and reversible transitions between multiple spatial maps of an unchanging task and environment. These remapping events were synchronized across hundreds of neurons, differentially affected navigational cell types, and correlated with changes in running speed. Despite widespread changes in spatial coding, remapping comprised a translation along a single dimension in population-level activity space, enabling simple decoding strategies. These findings provoke reconsideration of how the medial entorhinal cortex dynamically represents space and suggest a remarkable capacity of cortical circuits to rapidly and substantially reorganize their neural representations.},
	language = {en},
	number = {18},
	journal = {Neuron},
	author = {Low, Isabel I C and Williams, Alex H and Campbell, Malcolm G and Linderman, Scott W and Giocomo, Lisa M},
	month = sep,
	year = {2021},
	keywords = {population coding, medial entorhinal cortex, attractor manifolds, behavioral state, dynamic coding},
	pages = {2967--2980.e11},
}

@article{wang_what_2021,
	title = {What {Have} {We} {Learned} from {OpenReview}?},
	abstract = {Anonymous peer review is used by the great majority of computer science conferences. OpenReview is such a platform that aims to promote openness in peer review process. The paper, (meta) reviews, rebuttals, and final decisions are all released to public. We collect 5,527 submissions and their 16,853 reviews from the OpenReview platform. We also collect these submissions' citation data from Google Scholar and their non-peer-reviewed versions from arXiv.org. By acquiring deep insights into these data, we have several interesting findings that could help understand the effectiveness of the public-accessible double-blind peer review process. Our results can potentially help writing a paper, reviewing it, and deciding on its acceptance.},
	author = {Wang, Gang and Peng, Qi and Zhang, Yanfeng and Zhang, Mingyang},
	month = mar,
	year = {2021},
	note = {\_eprint: 2103.05885},
}

@article{wang_what_2021-1,
	title = {What {Have} {We} {Learned} from {OpenReview}?},
	abstract = {Anonymous peer review is used by the great majority of computer science conferences. OpenReview is such a platform that aims to promote openness in peer review process. The paper, (meta) reviews, rebuttals, and final decisions are all released to public. We collect 5,527 submissions and their 16,853 reviews from the OpenReview platform. We also collect these submissions' citation data from Google Scholar and their non-peer-reviewed versions from arXiv.org. By acquiring deep insights into these data, we have several interesting findings that could help understand the effectiveness of the public-accessible double-blind peer review process. Our results can potentially help writing a paper, reviewing it, and deciding on its acceptance.},
	author = {Wang, Gang and Peng, Qi and Zhang, Yanfeng and Zhang, Mingyang},
	month = mar,
	year = {2021},
	note = {\_eprint: 2103.05885},
}

@article{soergel_open_2013,
	title = {Open {Scholarship} and {Peer} {Review}: a {Time} for {Experimentation} ￼},
	author = {Soergel, David and Saunders, Adam and McCallum, Andrew},
	month = may,
	year = {2013},
}

@article{stockl_probabilistic_2021-1,
	title = {Probabilistic skeletons endow brain-like neural},
	author = {Stöckl, Christoph and Lang, Dominik and Maass, Wolfgang},
	year = {2021},
}

@article{hinton_one-thousand_2004,
	title = {“{One}-thousand one... one-thousand two...”: chronometric counting violates the scalar property in interval timing},
	volume = {11},
	abstract = {Weber's law applied to interval timing is called the scalar property. A hallmark of timing in the seconds-to-minutes range, the scalar property is characterized by proportionality between the standard deviation of a response distribution and the duration being timed. In this temporal reproduction study, we assessed whether the scalar property was upheld when participants chronometrically counted three visually presented durations (8, 16, and 24 sec) as compared with explicitly timing durations without counting. Accuracy for timing and accuracy for counting were similar. However, whereas timing variability showed the scalar property, counting variability did not. Counting variability across intervals was accurately modeled by summing a random variable representing an individual count. A second experiment replicated the first and demonstrated that task differences were not due to presentation order or practice effects. The distinct psychophysical properties of counting and timing behaviors argue for greater attention to participant strategies in timing studies.},
	language = {en},
	number = {1},
	journal = {Psychon. Bull. Rev.},
	author = {Hinton, Sean C and Rao, Stephen M},
	month = feb,
	year = {2004},
	pages = {24--30},
}

@article{getty_counting_1976,
	title = {Counting processes in human timing},
	volume = {20},
	abstract = {A subject reproducing a long duration, t, may time out either a single interval of duration t or a succession of n intervals, each of duration t/n. It is shown that a class of timing models obeying Weber's law predicts the variance of reproductions of t to be a decreasing function of the number of subdivisions, n. In contrast, a second class of proportional variance models, which includes Creelman's pulse counter model (1962), predicts no change in the variance as a function of n. Data are presented from a duration reproduction experiment in which subjects counted silently at a specified rate up to a given number and then responded. Several statistics involving the variance of the reproduced durations are shown to be predicted significantly better by the Weber's law class of models than by the proportional variance class of models.},
	number = {3},
	journal = {Percept. Psychophys.},
	author = {Getty, David J},
	month = may,
	year = {1976},
	pages = {191--197},
}

@article{buzsaki_space_2018,
	title = {Space and {Time}: {The} {Hippocampus} as a {Sequence} {Generator}},
	volume = {22},
	abstract = {Neural computations are often compared to instrument-measured distance or duration, and such relationships are interpreted by a human observer. However, neural circuits do not depend on human-made instruments but perform computations relative to an internally defined rate-of-change. While neuronal correlations with external measures, such as distance or duration, can be observed in spike rates or other measures of neuronal activity, what matters for the brain is how such activity patterns are utilized by downstream neural observers. We suggest that hippocampal operations can be described by the sequential activity of neuronal assemblies and their internally defined rate of change without resorting to the concept of space or time.},
	language = {en},
	number = {10},
	journal = {Trends Cogn. Sci.},
	author = {Buzsáki, György and Tingley, David},
	month = oct,
	year = {2018},
	keywords = {place cells, lateral septum, phase coding, theta oscillation, time cells},
	pages = {853--869},
}

@article{dabaghian_topological_2012,
	title = {A topological paradigm for hippocampal spatial map formation using persistent homology},
	volume = {8},
	abstract = {An animal's ability to navigate through space rests on its ability to create a mental map of its environment. The hippocampus is the brain region centrally responsible for such maps, and it has been assumed to encode geometric information (distances, angles). Given, however, that hippocampal output consists of patterns of spiking across many neurons, and downstream regions must be able to translate those patterns into accurate information about an animal's spatial environment, we hypothesized that 1) the temporal pattern of neuronal firing, particularly co-firing, is key to decoding spatial information, and 2) since co-firing implies spatial overlap of place fields, a map encoded by co-firing will be based on connectivity and adjacency, i.e., it will be a topological map. Here we test this topological hypothesis with a simple model of hippocampal activity, varying three parameters (firing rate, place field size, and number of neurons) in computer simulations of rat trajectories in three topologically and geometrically distinct test environments. Using a computational algorithm based on recently developed tools from Persistent Homology theory in the field of algebraic topology, we find that the patterns of neuronal co-firing can, in fact, convey topological information about the environment in a biologically realistic length of time. Furthermore, our simulations reveal a “learning region” that highlights the interplay between the parameters in combining to produce hippocampal states that are more or less adept at map formation. For example, within the learning region a lower number of neurons firing can be compensated by adjustments in firing rate or place field size, but beyond a certain point map formation begins to fail. We propose that this learning region provides a coherent theoretical lens through which to view conditions that impair spatial learning by altering place cell firing rates or spatial specificity.},
	language = {en},
	number = {8},
	journal = {PLoS Comput. Biol.},
	author = {Dabaghian, Y and Mémoli, F and Frank, L and Carlsson, G},
	month = aug,
	year = {2012},
	pages = {e1002581},
}

@unpublished{klukas_flexible_2019,
	title = {Flexible representation of higher-dimensional cognitive variables with grid cells},
	abstract = {Abstract We shed light on the theoretical capabilities of entorhinal grid cells to encode variables of dimension greater than two. Our model constructs representations of high-dimensional inputs through a combination of low-dimensional random projections and “classical” low-dimensional hexagonal grid cell responses. Without reconfiguration of the recurrent circuit, the same system can flexibly encode multiple variables of different dimensions while maximizing the coding range (per dimension) by automatically trading-off dimension with an exponentially large coding range. In contrast to previously proposed schemes, the model does not require the formation of higher-dimensional grid responses, a cell-inefficient and rigid mechanism. The firing fields observed in flying bats or climbing rats can be generated by neurons that combine activity from multiple grid modules, each representing higher-dimensional spaces according to our model. The idea expands our understanding of grid cells, suggesting that they could implement a general circuit that generates on-demand coding and memory states for variables in high-dimensional vector spaces.},
	language = {en},
	author = {Klukas, Mirko and Lewis, Marcus and Fiete, Ila},
	month = aug,
	year = {2019},
	note = {Publication Title: bioRxiv},
}

@article{gobet_chunks_2015,
	title = {Chunks, {Schemata}, and {Retrieval} {Structures}: {Past} and {Current} {Computational} {Models}},
	volume = {6},
	language = {en},
	journal = {Front. Psychol.},
	author = {Gobet, Fernand and Lane, Peter C R and Lloyd-Kelly, Martyn},
	month = nov,
	year = {2015},
	keywords = {theory, modeling, CHREST, chunk, long-term working-memory, retrieval structure, schema},
	pages = {1785},
}

@article{boopathy_how_2021,
	title = {How to {Train} {Your} {Wide} {Neural} {Network} {Without} {Backprop}: {An} {Input}-{Weight} {Alignment} {Perspective}},
	abstract = {Recent works have examined theoretical and empirical properties of wide neural networks trained in the Neural Tangent Kernel (NTK) regime. Given that biological neural networks are much wider than their artiﬁcial counterparts, we consider NTK regime wide neural networks as a possible model of biological neural networks. Lever-aging NTK theory, we show theoretically that gradient descent drives layerwise weight updates that are aligned with their input activity corre-lations weighted by error, and demonstrate empirically that the result also holds in ﬁnite-width wide networks. The alignment result allows us to formulate a family of biologically-motivated, backpropagation-free learning rules that are theoretically equivalent to backpropagation in inﬁnite-width networks. We test these learning rules on benchmark problems in feedforward and recurrent neural networks and demonstrate, in wide networks, comparable performance to backpropagation. The proposed rules are particularly effective in low data regimes, which are common in biological learning settings.},
	language = {en},
	journal = {ICML},
	author = {Boopathy, Akhilan and Fiete, I},
	year = {2021},
}

@article{simon_problem_nodate,
	title = {Problem solving and rule induction: {A} unified view},
	journal = {Knowledge and cognition},
	author = {{Simon} and {Lea}},
}

@article{feigenbaum_epam-like_1984,
	title = {{EPAM}-like models of recognition and learning},
	volume = {8},
	abstract = {Provides a description of EPAM-III, a computer program for simulating human verbal learning, and a summary of empirical evidence for its validity. Criticisms of the theory by L. W. Barsalou and G. H. Bower (see record 1985-05895-001) derive from their misconception that EPAM-III employed a binary discrimination net. Barsalou and Bower failed to understand how the recursive structure of EPAM-III eliminates the need to duplicate test nodes that are used to recognize subobjects. EPAM is compared with other theories of human discrimination and discrimination learning, including PANDEMONIUM-like systems and data-flow nets. (47 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {4},
	journal = {Cogn. Sci.},
	author = {Feigenbaum, Edward A and Simon, Herbert A},
	month = dec,
	year = {1984},
	pages = {305--336},
}

@inproceedings{charikar_better_2003,
	address = {New York, NY, USA},
	series = {{STOC} '03},
	title = {Better streaming algorithms for clustering problems},
	abstract = {We study clustering problems in the streaming model, where the goal is to cluster a set of points by making one pass (or a few passes) over the data using a small amount of storage space. Our main result is a randomized algorithm for the k–Median problem which produces a constant factor approximation in one pass using storage space O(k poly log n). This is a significant improvement of the previous best algorithm which yielded a 2O(1/ϵ) approximation using O(nϵ) space. Next we give a streaming algorithm for the k–Median problem with an arbitrary distance function. We also study algorithms for clustering problems with outliers in the streaming model. Here, we give bicriterion guarantees, producing constant factor approximations by increasing the allowed fraction of outliers slightly.},
	booktitle = {Proceedings of the thirty-fifth annual {ACM} symposium on {Theory} of computing},
	publisher = {Association for Computing Machinery},
	author = {Charikar, Moses and O'Callaghan, Liadan and Panigrahy, Rina},
	month = jun,
	year = {2003},
	note = {event-place: San Diego, CA, USA},
	keywords = {clustering, k-median, streaming algorithm},
	pages = {30--39},
}

@article{ailon_streaming_nodate,
	title = {Streaming k-means approximation},
	journal = {Adv. Neural Inf. Process. Syst.},
	author = {{Ailon} and {Jaiswal} and {others}},
}

@article{burgess_understanding_2018,
	title = {Understanding disentangling in {\textbackslash}beta {\textbackslash}-{VAE}},
	journal = {arXiv preprint arXiv:1804. 03599},
	author = {Burgess, Christopher P and Higgins, Irina and Pal, Arka and Matthey, Loic and Watters, Nick and Desjardins, Guillaume and Lerchner, Alexander},
	year = {2018},
}

@article{burgess_monet_2019,
	title = {{MONet}: {Unsupervised} {Scene} {Decomposition} and {Representation}},
	abstract = {The ability to decompose scenes in terms of abstract building blocks is crucial for general intelligence. Where those basic building blocks share meaningful properties, interactions and other regularities across scenes, such decompositions can simplify reasoning and facilitate imagination of novel scenarios. In particular, representing perceptual observations in terms of entities should improve data efficiency and transfer performance on a wide range of tasks. Thus we need models capable of discovering useful decompositions of scenes by identifying units with such regularities and representing them in a common format. To address this problem, we have developed the Multi-Object Network (MONet). In this model, a VAE is trained end-to-end together with a recurrent attention network – in a purely unsupervised manner – to provide attention masks around, and reconstructions of, regions of images. We show that this model is capable of learning to decompose and represent challenging 3D scenes into semantically meaningful components, such as objects and background elements.},
	author = {Burgess, Christopher P and Matthey, Loic and Watters, Nicholas and Kabra, Rishabh and Higgins, Irina and Botvinick, Matt and Lerchner, Alexander},
	month = jan,
	year = {2019},
	note = {\_eprint: 1901.11390},
}

@article{logiaco_thalamic_2021,
	title = {Thalamic control of cortical dynamics in a model of flexible motor sequencing},
	volume = {35},
	abstract = {The neural mechanisms that generate an extensible library of motor motifs and flexibly string them into arbitrary sequences are unclear. We developed a model in which inhibitory basal ganglia output neurons project to thalamic units that are themselves bidirectionally connected to a recurrent cortical network. We model the basal ganglia inhibitory patterns as silencing some thalamic neurons while leaving others disinhibited and free to interact with cortex during specific motifs. We show that a small number of disinhibited thalamic neurons can control cortical dynamics to generate specific motor output in a noise-robust way. Additionally, a single “preparatory” thalamocortical network can produce fast cortical dynamics that support rapid transitions between any pair of learned motifs. If the thalamic units associated with each sequence component are segregated, many motor outputs can be learned without interference and then combined in arbitrary orders for the flexible production of long and complex motor sequences.},
	language = {en},
	number = {9},
	journal = {Cell Rep.},
	author = {Logiaco, Laureline and Abbott, L F and Escola, Sean},
	month = jun,
	year = {2021},
	keywords = {recurrent neural networks, control, hierarchical behaviors, low-rank connectivity perturbation, motor cortex, motor sequencing, switching linear dynamics, thalamocortical loops, thalamus},
	pages = {109090},
}

@unpublished{mossing_antagonistic_2021,
	title = {Antagonistic inhibitory subnetworks control cooperation and competition across cortical space},
	abstract = {The cortical microcircuit can dynamically adjust to dramatic changes in the strength, scale, and complexity of its input. In the primary visual cortex (V1), pyramidal cells (PCs) integrate widely across space when signals are weak, but narrowly when signals are strong, a phenomenon known as contrast-dependent surround suppression. Theoretical work has proposed that local interneurons could mediate a shift from cooperation to competition of PCs across cortical space, underlying this computation. We combined calcium imaging and electrophysiology to constrain a stabilized supralinear network model that explains how the four principal cell types in layer 2/3 (L2/3) of mouse V1– somatostatin (SST), parvalbumin (PV), and vasoactive intestinal peptide (VIP) interneurons, and PCs– transform inputs from layer 4 (L4) PCs to encode drifting gratings of varying size and contrast. Using bidirectional optogenetic perturbations, we confirmed key predictions of the model. Our data and modeling showed that recurrent amplification drives a transition from a positive PC{\textbackslash}rightarrowVIP⊣SST⊣PC feedback loop at small size and low contrast to a negative PC{\textbackslash}rightarrowSST⊣PC feedback loop at large size and high contrast to contribute to this flexible computation. This may represent a widespread mechanism for gating competition across cortical space to optimally meet task demands. \#\#\# Competing Interest Statement The authors have declared no competing interest.},
	language = {en},
	author = {Mossing, Daniel P and Veit, Julia and Palmigiano, Agostina and Miller, Kenneth D and Adesnik, Hillel},
	month = dec,
	year = {2021},
	note = {Publication Title: bioRxiv},
}

@article{thompson_mechanism_2009,
	title = {Mechanism of potassium-channel selectivity revealed by {Na}(+) and {Li}(+) binding sites within the {KcsA} pore},
	volume = {16},
	abstract = {Potassium channels allow K(+) ions to diffuse through their pores while preventing smaller Na(+) ions from permeating. Discrimination between these similar, abundant ions enables these proteins to control electrical and chemical activity in all organisms. Selection occurs at the narrow selectivity filter containing structurally identified K(+) binding sites. Selectivity is thought to arise because smaller ions such as Na(+) do not bind to these K(+) sites in a thermodynamically favorable way. Using the model K(+) channel KcsA, we examined how intracellular Na(+) and Li(+) interact with the pore and the permeant ions using electrophysiology, molecular dynamics simulations and X-ray crystallography. Our results suggest that these small cations have a separate binding site within the K(+) selectivity filter. We propose that selective permeation from the intracellular side primarily results from a large energy barrier blocking filter entry for Na(+) and Li(+) in the presence of K(+), not from a difference of binding affinity between ions.},
	language = {en},
	number = {12},
	journal = {Nat. Struct. Mol. Biol.},
	author = {Thompson, Ameer N and Kim, Ilsoo and Panosian, Timothy D and Iverson, Tina M and Allen, Toby W and Nimigean, Crina M},
	month = dec,
	year = {2009},
	pages = {1317--1324},
}

@article{lindsay_how_2018,
	title = {How biological attention mechanisms improve task performance in a large-scale visual system model},
	volume = {7},
	abstract = {How does attentional modulation of neural activity enhance performance? Here we use a deep convolutional neural network as a large-scale model of the visual system to address this question. We model the feature similarity gain model of attention, in which attentional modulation is applied according to neural stimulus tuning. Using a variety of visual tasks, we show that neural modulations of the kind and magnitude observed experimentally lead to performance changes of the kind and magnitude observed experimentally. We find that, at earlier layers, attention applied according to tuning does not successfully propagate through the network, and has a weaker impact on performance than attention applied according to values computed for optimally modulating higher areas. This raises the question of whether biological attention might be applied at least in part to optimize function rather than strictly according to tuning. We suggest a simple experiment to distinguish these alternatives.},
	journal = {Elife},
	author = {Lindsay, Grace W and Miller, Kenneth D},
	month = oct,
	year = {2018},
	note = {Publisher: eLife Sciences Publications, Ltd},
	keywords = {gain modulation, convolutional neural networks, visual attention},
	pages = {e38105},
}

@article{keller_disinhibitory_2020,
	title = {A {Disinhibitory} {Circuit} for {Contextual} {Modulation} in {Primary} {Visual} {Cortex}},
	volume = {108},
	abstract = {Context guides perception by influencing stimulus saliency. Accordingly, in visual cortex, responses to a stimulus are modulated by context, the visual scene surrounding the stimulus. Responses are suppressed when stimulus and surround are similar but not when they differ. The underlying mechanisms remain unclear. Here, we use optical recordings, manipulations, and computational modeling to show that disinhibitory circuits consisting of vasoactive intestinal peptide (VIP)-expressing and somatostatin (SOM)-expressing inhibitory neurons modulate responses in mouse visual cortex depending on similarity between stimulus and surround, primarily by modulating recurrent excitation. When stimulus and surround are similar, VIP neurons are inactive, and activity of SOM neurons leads to suppression of excitatory neurons. However, when stimulus and surround differ, VIP neurons are active, inhibiting SOM neurons, which leads to relief of excitatory neurons from suppression. We have identified a canonical cortical disinhibitory circuit that contributes to contextual modulation and may regulate perceptual saliency.},
	language = {en},
	number = {6},
	journal = {Neuron},
	author = {Keller, Andreas J and Dipoppa, Mario and Roth, Morgane M and Caudill, Matthew S and Ingrosso, Alessandro and Miller, Kenneth D and Scanziani, Massimo},
	month = dec,
	year = {2020},
	keywords = {visual cortex, canonical disinhibitory circuit, computational modeling, contextual modulation, figure-ground segregation, inhibitory neurons, pop-out effects, recurrent neural network, saliency, stabilized supralinear network},
	pages = {1181--1193.e8},
}

@article{wang_theory_2022,
	title = {Theory of the {Multiregional} {Neocortex}: {Large}-{Scale} {Neural} {Dynamics} and {Distributed} {Cognition}},
	volume = {45},
	abstract = {The neocortex is a complex neurobiological system with many interacting regions. How these regions work together to subserve flexible behavior and cognition has become increasingly amenable to rigorous research. Here, I review recent experimental and theoretical work on the modus operandi of a multiregional cortex. These studies revealed several general principles for the neocortical interareal connectivity, low-dimensional macroscopic gradients of biological properties across cortical areas, and a hierarchy of timescales for information processing. Theoretical work suggests testable predictions regarding differential excitation and inhibition along feedforward and feedback pathways in the cortical hierarchy. Furthermore, modeling of distributed working memory and simple decision-making has given rise to a novel mathematical concept, dubbed bifurcation in space, that potentially explains how different cortical areas, with a canonical circuit organization but gradients of biological heterogeneities, are able to subserve their respective (e.g., sensory coding versus executive control) functions in a modularly organized brain.},
	language = {en},
	journal = {Annu. Rev. Neurosci.},
	author = {Wang, Xiao-Jing},
	month = jul,
	year = {2022},
	keywords = {computational modeling, distributed cognition, global brain dynamics, hierarchy of timescales, macroscopic gradients, neocortical connectome},
	pages = {533--560},
}

@article{cohen_separability_2020,
	title = {Separability and geometry of object manifolds in deep neural networks},
	volume = {11},
	abstract = {Stimuli are represented in the brain by the collective population responses of sensory neurons, and an object presented under varying conditions gives rise to a collection of neural population responses called an `object manifold'. Changes in the object representation along a hierarchical sensory system are associated with changes in the geometry of those manifolds, and recent theoretical progress connects this geometry with `classification capacity', a quantitative measure of the ability to support object classification. Deep neural networks trained on object classification tasks are a natural testbed for the applicability of this relation. We show how classification capacity improves along the hierarchies of deep neural networks with different architectures. We demonstrate that changes in the geometry of the associated object manifolds underlie this improved capacity, and shed light on the functional roles different levels in the hierarchy play to achieve it, through orchestrated reduction of manifolds' radius, dimensionality and inter-manifold correlations. Neural activity space or manifold that represents object information changes across the layers of a deep neural network. Here the authors present a theoretical account of the relationship between the geometry of the manifolds and the classification capacity of the neural networks.},
	language = {en},
	number = {1},
	journal = {Nat. Commun.},
	author = {Cohen, Uri and Chung, Sueyeon and Lee, Daniel D and Sompolinsky, Haim},
	month = feb,
	year = {2020},
	note = {Publisher: Nature Publishing Group},
	pages = {1--13},
}

@article{milstein_inhibitory_2015,
	title = {Inhibitory {Gating} of {Input} {Comparison} in the {CA1} {Microcircuit}},
	volume = {87},
	abstract = {Spatial and temporal features of synaptic inputs engage integration mechanisms on multiple scales, including presynaptic release sites, postsynaptic dendrites, and networks of inhibitory interneurons. Here we investigate how these mechanisms cooperate to filter synaptic input in hippocampal area CA1. Dendritic recordings from CA1 pyramidal neurons reveal that proximal inputs from CA3 as well as distal inputs from entorhinal cortex layer III (ECIII) sum sublinearly or linearly at low firing rates due to feedforward inhibition, but sum supralinearly at high firing rates due to synaptic facilitation, producing a high-pass filter. However, during ECIII and CA3 input comparison, supralinear dendritic integration is dynamically balanced by feedforward and feedback inhibition, resulting in suppression of dendritic complex spiking. We find that a particular subpopulation of CA1 interneurons expressing neuropeptide Y (NPY) contributes prominently to this dynamic filter by integrating both ECIII and CA3 input pathways and potently inhibiting CA1 pyramidal neuron dendrites.},
	language = {en},
	number = {6},
	journal = {Neuron},
	author = {Milstein, Aaron D and Bloss, Erik B and Apostolides, Pierre F and Vaidya, Sachin P and Dilly, Geoffrey A and Zemelman, Boris V and Magee, Jeffrey C},
	month = sep,
	year = {2015},
	pages = {1274--1289},
}

@article{palacios-filardo_acetylcholine_2021,
	title = {Acetylcholine prioritises direct synaptic inputs from entorhinal cortex to {CA1} by differential modulation of feedforward inhibitory circuits},
	volume = {12},
	abstract = {Acetylcholine release in the hippocampus plays a central role in the formation of new memory representations. An influential but largely untested theory proposes that memory formation requires acetylcholine to enhance responses in CA1 to new sensory information from entorhinal cortex whilst depressing inputs from previously encoded representations in CA3. Here, we show that excitatory inputs from entorhinal cortex and CA3 are depressed equally by synaptic release of acetylcholine in CA1. However, feedforward inhibition from entorhinal cortex exhibits greater depression than CA3 resulting in a selective enhancement of excitatory-inhibitory balance and CA1 activation by entorhinal inputs. Entorhinal and CA3 pathways engage different feedforward interneuron subpopulations and cholinergic modulation of presynaptic function is mediated differentially by muscarinic M3 and M4 receptors, respectively. Thus, our data support a role and mechanisms for acetylcholine to prioritise novel information inputs to CA1 during memory formation.},
	language = {en},
	number = {1},
	journal = {Nat. Commun.},
	author = {Palacios-Filardo, Jon and Udakis, Matt and Brown, Giles A and Tehan, Benjamin G and Congreve, Miles S and Nathan, Pradeep J and Brown, Alastair J H and Mellor, Jack R},
	month = sep,
	year = {2021},
	pages = {5475},
}

@article{udakis_interneuron-specific_2020,
	title = {Interneuron-specific plasticity at parvalbumin and somatostatin inhibitory synapses onto {CA1} pyramidal neurons shapes hippocampal output},
	volume = {11},
	abstract = {The formation and maintenance of spatial representations within hippocampal cell assemblies is strongly dictated by patterns of inhibition from diverse interneuron populations. Although it is known that inhibitory synaptic strength is malleable, induction of long-term plasticity at distinct inhibitory synapses and its regulation of hippocampal network activity is not well understood. Here, we show that inhibitory synapses from parvalbumin and somatostatin expressing interneurons undergo long-term depression and potentiation respectively (PV-iLTD and SST-iLTP) during physiological activity patterns. Both forms of plasticity rely on T-type calcium channel activation to confer synapse specificity but otherwise employ distinct mechanisms. Since parvalbumin and somatostatin interneurons preferentially target perisomatic and distal dendritic regions respectively of CA1 pyramidal cells, PV-iLTD and SST-iLTP coordinate a reprioritisation of excitatory inputs from entorhinal cortex and CA3. Furthermore, circuit-level modelling reveals that PV-iLTD and SST-iLTP cooperate to stabilise place cells while facilitating representation of multiple unique environments within the hippocampal network.},
	language = {en},
	number = {1},
	journal = {Nat. Commun.},
	author = {Udakis, Matt and Pedrosa, Victor and Chamberlain, Sophie E L and Clopath, Claudia and Mellor, Jack R},
	month = sep,
	year = {2020},
	pages = {4395},
}

@article{desimone_neural_1995,
	title = {Neural mechanisms of selective visual attention},
	volume = {18},
	language = {en},
	journal = {Annu. Rev. Neurosci.},
	author = {Desimone, R and Duncan, J},
	year = {1995},
	pages = {193--222},
}

@article{schuman_neocortical_2021,
	title = {Neocortical {Layer} 1: {An} {Elegant} {Solution} to {Top}-{Down} and {Bottom}-{Up} {Integration}},
	volume = {44},
	abstract = {Many of our daily activities, such as riding a bike to work or reading a book in a noisy cafe, and highly skilled activities, such as a professional playing a tennis match or a violin concerto, depend upon the ability of the brain to quickly make moment-to-moment adjustments to our behavior in response to the results of our actions. Particularly, they depend upon the ability of the neocortex to integrate the information provided by the sensory organs (bottom-up information) with internally generated signals such as expectations or attentional signals (top-down information). This integration occurs in pyramidal cells (PCs) and their long apical dendrite, which branches extensively into a dendritic tuft in layer 1 (L1). The outermost layer of the neocortex, L1 is highly conserved across cortical areas and species. Importantly, L1 is the predominant input layer for top-down information, relayed by a rich, dense mesh of long-range projections that provide signals to the tuft branches of the PCs. Here, we discuss recent progress in our understanding of the composition of L1 and review evidence that L1 processing contributes to functions such as sensory perception, cross-modal integration, controlling states of consciousness, attention, and learning.},
	language = {en},
	journal = {Annu. Rev. Neurosci.},
	author = {Schuman, Benjamin and Dellal, Shlomo and Prönneke, Alvar and Machold, Robert and Rudy, Bernardo},
	month = jul,
	year = {2021},
	keywords = {neocortex, predictive coding, GABAergic interneurons, layer 1, pyramidal cell dendrites, top-down processing},
	pages = {221--252},
}

@article{fiete_ila_2021-1,
	title = {Ila {Fiete}},
	volume = {31},
	abstract = {Interview with Ila Fiete, who studies the microscopic cellular and synaptic processes responsible for behaviors of memory and cognition in the brain at Massachusetts Institute of Technology.},
	language = {en},
	number = {24},
	journal = {Curr. Biol.},
	author = {Fiete, Ila},
	month = dec,
	year = {2021},
	pages = {R1552--R1555},
}

@article{ziv_long-term_2013-1,
	title = {Long-term dynamics of {CA1} hippocampal place codes},
	volume = {16},
	abstract = {Using Ca(2+) imaging in freely behaving mice that repeatedly explored a familiar environment, we tracked thousands of CA1 pyramidal cells' place fields over weeks. Place coding was dynamic, as each day the ensemble representation of this environment involved a unique subset of cells. However, cells in the ∼15-25\% overlap between any two of these subsets retained the same place fields, which sufficed to preserve an accurate spatial representation across weeks.},
	language = {en},
	number = {3},
	journal = {Nat. Neurosci.},
	author = {Ziv, Yaniv and Burns, Laurie D and Cocker, Eric D and Hamel, Elizabeth O and Ghosh, Kunal K and Kitch, Lacey J and El Gamal, Abbas and Schnitzer, Mark J},
	month = mar,
	year = {2013},
	pages = {264--266},
}

@article{harris_hierarchical_2019,
	title = {Hierarchical organization of cortical and thalamic connectivity},
	volume = {575},
	abstract = {The mammalian cortex is a laminar structure containing many areas and cell types that are densely interconnected in complex ways, and for which generalizable principles of organization remain mostly unknown. Here we describe a major expansion of the Allen Mouse Brain Connectivity Atlas resource1, involving around a thousand new tracer experiments in the cortex and its main satellite structure, the thalamus. We used Cre driver lines (mice expressing Cre recombinase) to comprehensively and selectively label brain-wide connections by layer and class of projection neuron. Through observations of axon termination patterns, we have derived a set of generalized anatomical rules to describe corticocortical, thalamocortical and corticothalamic projections. We have built a model to assign connection patterns between areas as either feedforward or feedback, and generated testable predictions of hierarchical positions for individual cortical and thalamic areas and for cortical network modules. Our results show that cell-class-specific connections are organized in a shallow hierarchy within the mouse corticothalamic network.},
	language = {en},
	number = {7781},
	journal = {Nature},
	author = {Harris, Julie A and Mihalas, Stefan and Hirokawa, Karla E and Whitesell, Jennifer D and Choi, Hannah and Bernard, Amy and Bohn, Phillip and Caldejon, Shiella and Casal, Linzy and Cho, Andrew and Feiner, Aaron and Feng, David and Gaudreault, Nathalie and Gerfen, Charles R and Graddis, Nile and Groblewski, Peter A and Henry, Alex M and Ho, Anh and Howard, Robert and Knox, Joseph E and Kuan, Leonard and Kuang, Xiuli and Lecoq, Jerome and Lesnar, Phil and Li, Yaoyao and Luviano, Jennifer and McConoughey, Stephen and Mortrud, Marty T and Naeemi, Maitham and Ng, Lydia and Oh, Seung Wook and Ouellette, Benjamin and Shen, Elise and Sorensen, Staci A and Wakeman, Wayne and Wang, Quanxin and Wang, Yun and Williford, Ali and Phillips, John W and Jones, Allan R and Koch, Christof and Zeng, Hongkui},
	month = nov,
	year = {2019},
	pages = {195--202},
}

@unpublished{pattadkal_primate_2022,
	title = {Primate neocortex performs balanced sensory amplification},
	abstract = {Sensory cortex amplifies relevant features of external stimuli. This sensitivity and selectivity arise through the transformation of inputs by cortical circuitry. We characterize the circuit mechanisms and dynamics of cortical amplification by making large-scale simultaneous measurements of single cells in awake primates and by testing computational models. By comparing network activity in both driven and spontaneous states with models, we identify the circuit as operating in a regime of balanced amplification. Incoming inputs are strongly but transiently amplified by recurrent excitation. Inhibition acts to counterbalance this excitation by rapidly quenching responses, thereby permitting tracking of time-varying stimuli. One-Sentence Summary Sensory cortex uses balanced excitatory and inhibitory circuitry to boost weak signals while maintaining fast sensory dynamics in a changing environment. \#\#\# Competing Interest Statement The authors have declared no competing interest.},
	language = {en},
	author = {Pattadkal, Jagruti J and Zemelman, Boris V and Fiete, Ila and Priebe, Nicholas J},
	month = jun,
	year = {2022},
	note = {Publication Title: bioRxiv},
}

@article{boccara_entorhinal_2019,
	title = {The entorhinal cognitive map is attracted to goals},
	volume = {363},
	abstract = {Recent findings suggest a more complex role of grid cells in the brain than simply coding for space. The grid map in the entorhinal cortex, which is responsible for encoding spatial information, is not as rigid as originally thought and can be distorted by environmental modifications (see the Perspective by Quian Quiroga). Butler et al. compared grid cell coding during a free-foraging task and a spatial memory task in rats. They discovered that entorhinal spatial maps restructure to incorporate the location of a learned reward. Boccara et al. tested the influence of behaviorally relevant information on the cognitive map that emerges from grid cell firing in the rat medial entorhinal cortex. They found that grid cells participate in neural coding of the goal locality, not the whole environment. Science, this issue p. 1447, p. 1443; see also p. 1388 Goal learning in rats leads to a local distortion of grid cell rate maps, suggesting a complex code beyond simply encoding space. Grid cells with their rigid hexagonal firing fields are thought to provide an invariant metric to the hippocampal cognitive map, yet environmental geometrical features have recently been shown to distort the grid structure. Given that the hippocampal role goes beyond space, we tested the influence of nonspatial information on the grid organization. We trained rats to daily learn three new reward locations on a cheeseboard maze while recording from the medial entorhinal cortex and the hippocampal CA1 region. Many grid fields moved toward goal location, leading to long-lasting deformations of the entorhinal map. Therefore, distortions in the grid structure contribute to goal representation during both learning and recall, which demonstrates that grid cells participate in mnemonic coding and do not merely provide a simple metric of space.},
	number = {6434},
	journal = {Science},
	author = {Boccara, Charlotte N and Nardin, Michele and Stella, Federico and O'Neill, Joseph and Csicsvari, Jozsef},
	year = {2019},
	pages = {1443--1447},
}

@unpublished{pattadkal_primate_2022-1,
	title = {Primate neocortex performs balanced sensory amplification},
	abstract = {Sensory cortex amplifies relevant features of external stimuli. This sensitivity and selectivity arise through the transformation of inputs by cortical circuitry. We characterize the circuit mechanisms and dynamics of cortical amplification by making large-scale simultaneous measurements of single cells in awake primates and by testing computational models. By comparing network activity in both driven and spontaneous states with models, we identify the circuit as operating in a regime of balanced amplification. Incoming inputs are strongly but transiently amplified by recurrent excitation. Inhibition acts to counterbalance this excitation by rapidly quenching responses, thereby permitting tracking of time-varying stimuli. One-Sentence Summary Sensory cortex uses balanced excitatory and inhibitory circuitry to boost weak signals while maintaining fast sensory dynamics in a changing environment. \#\#\# Competing Interest Statement The authors have declared no competing interest.},
	language = {en},
	author = {Pattadkal, Jagruti J and Zemelman, Boris V and Fiete, Ila and Priebe, Nicholas J},
	month = jun,
	year = {2022},
	note = {Publication Title: bioRxiv},
}

@article{khona_winning_2022,
	title = {Winning the lottery with neurobiology: faster learning on many cognitive tasks with fixed sparse {RNNs}},
	abstract = {RNNs are often used as models of biological brain circuits and can solve a variety of difficult problems requiring memory, error-correction, or selection {\textbackslash}textbackslashcite\{hopfield1982neural, maass2002real,maass2011liquid\}. However, fully-connected RNNs contrast structurally with their biological counterparts, which are extremely sparse ({\textbackslash}sim 0.1\%). Practical deployment of large RNNs is often limited due to requirements of long training times and large memory requirements. Motivated by brains, where neural connectivity is constrained by distance along cortical sheets and other synaptic wiring costs, we introduce locality masked RNNs (LM-RNNs) that utilize task-agnostic predetermined graphs with sparsity as low as 4\%. We make three contributions: First, we show that LM-RNNs can perform as well as their fully-connected counterparts, without {\textbackslash}textbackslashemph\{a posteriori\} construction of the best sparse subnetwork. Second, we find that LM-RNNs train faster with more data-efficiency in a multitask setting relevant to cognitive systems neuroscience, often achieving better asymptotic performance. Third, we contribute a new cognitive multi-task battery, Mod-Cog, consisting of 132 tasks that expands by {\textbackslash}sim 7-fold the number of tasks and task-complexity of an existing commonly used set of tasks {\textbackslash}textbackslashcite\{yang2019task\}, showing that while LM-RNNs can solve the simple {\textbackslash}textbackslashcite\{yang2019task\} tasks with a small pool of unconnected autapses, the expanded task-set produces richer solutions.},
	author = {Khona, Mikail and Chandra, Sarthak and Ma, Joy J and Fiete, Ila},
	month = jul,
	year = {2022},
	note = {\_eprint: 2207.03523},
}

@inproceedings{schaeffer_streaming_2022,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Streaming {Inference} for {Infinite} {Feature} {Models}},
	volume = {162},
	abstract = {Unsupervised learning from a continuous stream of data is arguably one of the most common and most challenging problems facing intelligent agents. One class of unsupervised models, collectively termed feature models, attempts unsupervised discovery of latent features underlying the data and includes common models such as PCA, ICA, and NMF. However, if the data arrives in a continuous stream, determining the number of features is a significant challenge and the number may grow with time. In this work, we make feature models significantly more applicable to streaming data by imbuing them with the ability to create new features, online, in a probabilistic and principled manner. To achieve this, we derive a novel recursive form of the Indian Buffet Process, which we term the Recursive IBP (R-IBP). We demonstrate that R-IBP can be be used as a prior for feature models to efficiently infer a posterior over an unbounded number of latent features, with quasilinear average time complexity and logarithmic average space complexity. We compare R-IBP to existing offline sampling and variational baselines in two feature models (Linear Gaussian and Factor Analysis) and demonstrate on synthetic and real data that R-IBP achieves comparable or better performance in significantly less time.},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Schaeffer, Rylan and Du, Yilun and Liu, Gabrielle K and Fiete, Ila},
	editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
	year = {2022},
	pages = {19366--19387},
}

@article{schaeffer_streaming_2022-1,
	title = {Streaming {Inference} for {Infinite} {Non}-{Stationary} {Clustering}},
	abstract = {Learning from a continuous stream of non-stationary data in an unsupervised manner is arguably one of the most common and most challenging settings facing intelligent agents. Here, we attack learning under all three conditions (unsupervised, streaming, non-stationary) in the context of clustering, also known as mixture modeling. We introduce a novel clustering algorithm that endows mixture models with the ability to create new clusters online, as demanded by the data, in a probabilistic, time-varying, and principled manner. To achieve this, we first define a novel stochastic process called the Dynamical Chinese Restaurant Process (Dynamical CRP), which is a non-exchangeable distribution over partitions of a set; next, we show that the Dynamical CRP provides a non-stationary prior over cluster assignments and yields an efficient streaming variational inference algorithm. We conclude with experiments showing that the Dynamical CRP can be applied on diverse synthetic and real data with Gaussian and non-Gaussian likelihoods.},
	author = {Schaeffer, Rylan and Liu, Gabrielle Kaili-May and Du, Yilun and Linderman, Scott and Fiete, Ila Rani},
	month = may,
	year = {2022},
	note = {\_eprint: 2205.01212},
}

@misc{ballard_possibility_nodate,
	title = {possibility is to use the {Backpropagation} algorithm},
	url = {https://www.aaai.org/Papers/AAAI/1987/AAAI87-050.pdf},
	abstract = {In the development of large-scale knowledge networks, much recent progress has been inspired by connections to neurobiology. An important component of any “'neural” network is an accompanying learning algorithm. Such an algorithm, to be biologically lausible, !s must work for very large numbers of units. tudies of large-scale systems have so far been restricted to systems without internal units (units with no direct connections to the input or output). Internal units are crucial to such systems as they are the means by which a system can encode high-order regularities (or invariants) that are implicit in its inputs and outputs. Computer simulations of learning using internal units have been restricted to small-scale systems. This paper describes a way of coupling autoassociative learning modules into hierarchies that should greatly improve the performance of learning algorithms in large-scale systems. The idea has been tested experimentally with positive results.},
	author = {Ballard, Dana H},
}

@article{seung_query_1992,
	title = {Query by committee},
	abstract = {We propose an algorithm called query by commitee, in which a committee of students is trained on the same data set. The next query is chosen according to the principle of maximal …},
	journal = {of the fifth annual workshop on …},
	author = {Seung, H S and Opper, M and Sompolinsky, H},
	year = {1992},
	note = {Publisher: dl.acm.org},
}

@article{vorhees_morris_2006,
	title = {Morris water maze: procedures for assessing spatial and related forms of learning and memory},
	volume = {1},
	abstract = {The Morris water maze (MWM) is a test of spatial learning for rodents that relies on distal cues to navigate from start locations around the perimeter of an open swimming arena to locate a submerged escape platform. Spatial learning is assessed across repeated trials and reference memory is determined by preference for the platform area when the platform is absent. Reversal and shift trials enhance the detection of spatial impairments. Trial-dependent, latent and discrimination learning can be assessed using modifications of the basic protocol. Search-to-platform area determines the degree of reliance on spatial versus non-spatial strategies. Cued trials determine whether performance factors that are unrelated to place learning are present. Escape from water is relatively immune from activity or body mass differences, making it ideal for many experimental models. The MWM has proven to be a robust and reliable test that is strongly correlated with hippocampal synaptic plasticity and NMDA receptor function. We present protocols for performing variants of the MWM test, from which results can be obtained from individual animals in as few as 6 days.},
	language = {en},
	number = {2},
	journal = {Nat. Protoc.},
	author = {Vorhees, Charles V and Williams, Michael T},
	year = {2006},
	pages = {848--858},
}

@article{eisen_peer_2022,
	title = {Peer review without gatekeeping},
	volume = {11},
	abstract = {eLife is changing its editorial process to emphasize public reviews and assessments of preprints by eliminating accept/reject decisions after peer review.},
	language = {en},
	journal = {Elife},
	author = {Eisen, Michael B and Akhmanova, Anna and Behrens, Timothy E and Diedrichsen, Jörn and Harper, Diane M and Iordanova, Mihaela D and Weigel, Detlef and Zaidi, Mone},
	month = oct,
	year = {2022},
	keywords = {peer review, preprints, research assessment, research communication, scientific publishing},
}

@unpublished{powell_i_2020,
	title = {I {TRIED} {A} {BUNCH} {OF} {THINGS}: {THE} {DANGERS} {OF} {UNEXPECTED} {OVERFITTING} {IN} {CLASSIFICATION}},
	abstract = {ABSTRACT Machine learning is a powerful set of techniques that has enhanced the abilities of neuroscientists to interpret information collected through EEG, fMRI, and MEG data. With these powerful techniques comes the danger of overfitting of hyper-parameters which can render results invalid, and cause a failure to generalize beyond the data set. We refer to this problem as `over-hyping' and show that it is pernicious despite commonly used precautions. In particular, over-hyping occurs when an analysis is run repeatedly with slightly different analysis parameters and one set of results is selected based on the analysis. When this is done, the resulting method is unlikely to generalize to a new dataset, rendering it a partially, or perhaps even completely spurious result that will not be valid outside of the data used in the original analysis. While it is commonly assumed that cross-validation is an effective protection against such spurious results generated through overfitting or overhyping, this is not actually true. In this article, we show that both one-shot and iterative optimization of an analysis are prone to over-hyping, despite the use of cross-validation. We demonstrate that non-generalizable results can be obtained even on non-informative (i.e. random) data by modifying hyper-parameters in seemingly innocuous ways. We recommend a number of techniques for limiting over-hyping, such as lock-boxes, blind analyses, pre-registrations, and nested cross-validation. These techniques, are common in other fields that use machine learning, including computer science and physics. Adopting similar safeguards is critical for ensuring the robustness of machine-learning techniques in the neurosciences.},
	language = {en},
	author = {Powell, Michael and Hosseini, Mahan and Collins, John and Callahan-Flintoft, Chloe and Jones, William and Bowman, Howard and Wyble, Brad},
	month = feb,
	year = {2020},
	note = {Publication Title: bioRxiv},
}

@article{brembs_deep_2013,
	title = {Deep impact: unintended consequences of journal rank},
	volume = {7},
	abstract = {Most researchers acknowledge an intrinsic hierarchy in the scholarly journals (“journal rank”) that they submit their work to, and adjust not only their submission but also their reading strategies accordingly. On the other hand, much has been written about the negative effects of institutionalizing journal rank as an impact measure. So far, contributions to the debate concerning the limitations of journal rank as a scientific impact assessment tool have either lacked data, or relied on only a few studies. In this review, we present the most recent and pertinent data on the consequences of our current scholarly communication system with respect to various measures of scientific quality (such as utility/citations, methodological soundness, expert ratings or retractions). These data corroborate previous hypotheses: using journal rank as an assessment tool is bad scientific practice. Moreover, the data lead us to argue that any journal rank (not only the currently-favored Impact Factor) would have this negative impact. Therefore, we suggest that abandoning journals altogether, in favor of a library-based scholarly communication system, will ultimately be necessary. This new system will use modern information technology to vastly improve the filter, sort and discovery functions of the current journal system.},
	language = {en},
	journal = {Front. Hum. Neurosci.},
	author = {Brembs, Björn and Button, Katherine and Munafò, Marcus},
	month = jun,
	year = {2013},
	keywords = {Scientific Publishing, impact factor, journal ranking, libraries, library services, open access, publishing, scholarly communication, statistics as topic},
	pages = {291},
}

@article{brembs_prestigious_2018,
	title = {Prestigious {Science} {Journals} {Struggle} to {Reach} {Even} {Average} {Reliability}},
	volume = {12},
	abstract = {In which journal a scientist publishes is considered one of the most crucial factors determining their career. The underlying common assumption is that only the best scientists manage to publish in a highly selective tier of the most prestigious journals. However, data from several lines of evidence suggest that the methodological quality of scientific experiments does not increase with increasing rank of the journal. On the contrary, an accumulating body of evidence suggests the inverse: methodological quality and, consequently, reliability of published research works in several fields may be decreasing with increasing journal rank. The data supporting these conclusions circumvent confounding factors such as increased readership and scrutiny for these journals, focusing instead on quantifiable indicators of methodological soundness in the published literature, relying on, in part, semi-automated data extraction from often thousands of publications at a time. With the accumulating evidence over the last decade grew the realization that the very existence of scholarly journals, due to their inherent hierarchy, constitutes one of the major threats to publicly funded science: hiring, promoting and funding scientists who publish unreliable science eventually erodes public trust in science.},
	language = {en},
	journal = {Front. Hum. Neurosci.},
	author = {Brembs, Björn},
	month = feb,
	year = {2018},
	keywords = {Scientific Publishing, journal ranking, journals, reliability, reproducibility of results, science policy},
	pages = {37},
}

@article{foster_reverse_2006-1,
	title = {Reverse replay of behavioural sequences in hippocampal place cells during the awake state},
	volume = {440},
	abstract = {During sleep, neurons in the rat hippocampus are known to replay sequences of activity that took place when the rat was awake. A new study, in rats running around a track, eating and grooming, shows that replay also occurs repeatedly during the awake state, and that behavioural sequences are replayed in reverse order. Theories of spatial learning have previously suggested that reverse replay might be useful. Replay during the awake state might also explain in part why learning can be more effective if learning sessions are spaced out in time rather than clustered together, why hyperactivity causes learning problems, and why simply being awake and resting can help learning. The hippocampus has long been known to be involved in spatial navigational learning in rodents1,2, and in memory for events in rodents3,4, primates5 and humans6. A unifying property of both navigation and event memory is a requirement for dealing with temporally sequenced information. Reactivation of temporally sequenced memories for previous behavioural experiences has been reported in sleep in rats7,8. Here we report that sequential replay occurs in the rat hippocampus during awake periods immediately after spatial experience. This replay has a unique form, in which recent episodes of spatial experience are replayed in a temporally reversed order. This replay is suggestive of a role in the evaluation of event sequences in the manner of reinforcement learning models. We propose that such replay might constitute a general mechanism of learning and memory.},
	language = {en},
	number = {7084},
	journal = {Nature},
	author = {Foster, David J and Wilson, Matthew A},
	month = feb,
	year = {2006},
	note = {Publisher: Nature Publishing Group},
	pages = {680--683},
}

@article{eliav_multiscale_2021-1,
	title = {Multiscale representation of very large environments in the hippocampus of flying bats},
	volume = {372},
	abstract = {Hippocampal place cells encode the animal's location. Place cells were traditionally studied in small environments, and nothing is known about large ethologically relevant spatial scales. We wirelessly recorded from hippocampal dorsal CA1 neurons of wild-born bats flying in a long tunnel (200 meters). The size of place fields ranged from 0.6 to 32 meters. Individual place cells exhibited multiple fields and a multiscale representation: Place fields of the same neuron differed up to 20-fold in size. This multiscale coding was observed from the first day of exposure to the environment, and also in laboratory-born bats that never experienced large environments. Theoretical decoding analysis showed that the multiscale code allows representation of very large environments with much higher precision than that of other codes. Together, by increasing the spatial scale, we discovered a neural code that is radically different from classical place codes.},
	language = {en},
	number = {6545},
	journal = {Science},
	author = {Eliav, Tamir and Maimon, Shir R and Aljadeff, Johnatan and Tsodyks, Misha and Ginosar, Gily and Las, Liora and Ulanovsky, Nachum},
	month = may,
	year = {2021},
}

@article{ben-yishai_theory_1995-1,
	title = {Theory of orientation tuning in visual cortex},
	volume = {92},
	abstract = {The role of intrinsic cortical connections in processing sensory input and in generating behavioral output is poorly understood. We have examined this issue in the context of the tuning of neuronal responses in cortex to the orientation of a visual stimulus. We analytically study a simple network model that incorporates both orientation-selective input from the lateral geniculate nucleus and orientation-specific cortical interactions. Depending on the model parameters, the network exhibits orientation selectivity that originates from within the cortex, by a symmetry-breaking mechanism. In this case, the width of the orientation tuning can be sharp even if the lateral geniculate nucleus inputs are only weakly anisotropic. By using our model, several experimental consequences of this cortical mechanism of orientation tuning are derived. The tuning width is relatively independent of the contrast and angular anisotropy of the visual stimulus. The transient population response to changing of the stimulus orientation exhibits a slow “virtual rotation.” Neuronal cross-correlations exhibit long time tails, the sign of which depends on the preferred orientations of the cells and the stimulus orientation.},
	language = {en},
	number = {9},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Ben-Yishai, R and Bar-Or, R L and Sompolinsky, H},
	month = apr,
	year = {1995},
	pages = {3844--3848},
}

@article{seung_simple_1993-2,
	title = {Simple models for reading neuronal population codes},
	volume = {90},
	abstract = {In many neural systems, sensory information is distributed throughout a population of neurons. We study simple neural network models for extracting this information. The inputs to the networks are the stochastic responses of a population of sensory neurons tuned to directional stimuli. The performance of each network model in psychophysical tasks is compared with that of the optimal maximum likelihood procedure. As a model of direction estimation in two dimensions, we consider a linear network that computes a population vector. Its performance depends on the width of the population tuning curves and is maximal for width, which increases with the level of background activity. Although for narrowly tuned neurons the performance of the population vector is significantly inferior to that of maximum likelihood estimation, the difference between the two is small when the tuning is broad. For direction discrimination, we consider two models: a perceptron with fully adaptive weights and a network made by adding an adaptive second layer to the population vector network. We calculate the error rates of these networks after exhaustive training to a particular direction. By testing on the full range of possible directions, the extent of transfer of training to novel stimuli can be calculated. It is found that for threshold linear networks the transfer of perceptual learning is nonmonotonic. Although performance deteriorates away from the training stimulus, it peaks again at an intermediate angle. This nonmonotonicity provides an important psychophysical test of these models.},
	language = {en},
	number = {22},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Seung, H S and Sompolinsky, H},
	month = nov,
	year = {1993},
	pages = {10749--10753},
}

@article{sorscher_neural_2022,
	title = {Neural representational geometry underlies few-shot concept learning},
	volume = {119},
	abstract = {Understanding the neural basis of the remarkable human cognitive capacity to learn novel concepts from just one or a few sensory experiences constitutes a fundamental problem. We propose a simple, biologically plausible, mathematically tractable, and computationally powerful neural mechanism for few-shot learning of naturalistic concepts. We posit that the concepts that can be learned from few examples are defined by tightly circumscribed manifolds in the neural firing-rate space of higher-order sensory areas. We further posit that a single plastic downstream readout neuron learns to discriminate new concepts based on few examples using a simple plasticity rule. We demonstrate the computational power of our proposal by showing that it can achieve high few-shot learning accuracy on natural visual concepts using both macaque inferotemporal cortex representations and deep neural network (DNN) models of these representations and can even learn novel visual concepts specified only through linguistic descriptors. Moreover, we develop a mathematical theory of few-shot learning that links neurophysiology to predictions about behavioral outcomes by delineating several fundamental and measurable geometric properties of neural representations that can accurately predict the few-shot learning performance of naturalistic concepts across all our numerical simulations. This theory reveals, for instance, that high-dimensional manifolds enhance the ability to learn new concepts from few examples. Intriguingly, we observe striking mismatches between the geometry of manifolds in the primate visual pathway and in trained DNNs. We discuss testable predictions of our theory for psychophysics and neurophysiological experiments.},
	language = {en},
	number = {43},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Sorscher, Ben and Ganguli, Surya and Sompolinsky, Haim},
	month = oct,
	year = {2022},
	keywords = {population coding, neural networks, few-shot learning, ventral visual stream},
	pages = {e2200800119},
}

@article{jiang_high_2019,
	title = {The high resource impact of reformatting requirements for scientific papers},
	volume = {14},
	abstract = {BACKGROUND: Most research manuscripts are not accepted for publication on first submission. A major part of the resubmission process is reformatting to another journal's specific requirements, a process separate from revising the scientific content. There has been little research to understand the magnitude of the burden imposed by the current resubmission process. METHODS: We analyzed original research article submission requirements from twelve randomly selected journals in each of eight scientific and clinical focus areas from the InCites Journal Citation Reports database. From the 96 journals selected, we randomly identified three recently published manuscripts and sent surveys to those first and/or corresponding authors (288 total) to solicit information on time spent reformatting resubmissions and opinions on the process. FINDINGS: There was significant variation in manuscript submission requirements for journals within the same scientific focus and only 4\% of journals offered a fully format-free initial submission. Of 203 authors responding (71.5\% response rate), only 11.8\% expressed satisfaction with the resubmission process and 91\% desired reforming the current system. Time spent on reformatting delays most publications by at least two weeks and by over three months in about 20\% of manuscripts. The effort to comply with submission requirements has significant global economic burden, estimated at over \$1.1 billion dollars annually when accounting for a research team's time. INTERPRETATION: We demonstrate that there is significant resource utilization associated with resubmitting manuscripts, heretofore not properly quantified. The vast majority of authors are not satisfied with the current process. Addressing these issues by reconciling reformatting requirements among journals or adopting a universal format-free initial submission policy would help resolve a major subject for the scientific research community and provide more efficient dissemination of findings.},
	language = {en},
	number = {10},
	journal = {PLoS One},
	author = {Jiang, Yan and Lerrigo, Robert and Ullah, Anika and Alagappan, Muthu and Asch, Steven M and Goodman, Steven N and Sinha, Sidhartha R},
	month = oct,
	year = {2019},
	keywords = {Scientific Publishing},
	pages = {e0223976},
}

@article{seel_walking_2019,
	title = {Walking through doorways differentially affects recall and familiarity},
	volume = {110},
	abstract = {Previous research has reported that walking through a doorway to a new location makes memory for objects and events experienced in the previous location less accurate. This effect, termed the location updating effect, has been used to suggest that location changes are used to mark boundaries between events in memory: memories for objects encountered within the current event are more available than those from beyond an event boundary. Within a computer-generated memory task, participants navigated through virtual rooms, walking through doorways, and interacting with objects. The accuracy and their subjective experience of their memory for the objects (remember/know and confidence) were assessed. The findings showed that shifts in location decreased accurate responses associated with the subjective experience of remembering but not those associated with the experience of knowing, even when considering only the most confident responses in each condition. These findings demonstrate that a shift in location selectively impacts recollection and so contributes to our understanding of boundaries in event memory.},
	language = {en},
	number = {1},
	journal = {Br. J. Psychol.},
	author = {Seel, Sabrina V and Easton, Alexander and McGregor, Anthony and Buckley, Matthew G and Eacott, Madeline J},
	month = feb,
	year = {2019},
	keywords = {episodic memory, event model, recall, familiarity, location updating effect},
	pages = {173--184},
}

@article{zhang_spatially_2021,
	title = {Spatially resolved cell atlas of the mouse primary motor cortex by {MERFISH}},
	volume = {598},
	abstract = {A mammalian brain is composed of numerous cell types organized in an intricate manner to form functional neural circuits. Single-cell RNA sequencing allows systematic identification of cell types based on their gene expression profiles and has revealed many distinct cell populations in the brain1,2. Single-cell epigenomic profiling3,4 further provides information on gene-regulatory signatures of different cell types. Understanding how different cell types contribute to brain function, however, requires knowledge of their spatial organization and connectivity, which is not preserved in sequencing-based methods that involve cell dissociation. Here we used a single-cell transcriptome-imaging method, multiplexed error-robust fluorescence in situ hybridization (MERFISH)5, to generate a molecularly defined and spatially resolved cell atlas of the mouse primary motor cortex. We profiled approximately 300,000 cells in the mouse primary motor cortex and its adjacent areas, identified 95 neuronal and non-neuronal cell clusters, and revealed a complex spatial map in which not only excitatory but also most inhibitory neuronal clusters adopted laminar organizations. Intratelencephalic neurons formed a largely continuous gradient along the cortical depth axis, in which the gene expression of individual cells correlated with their cortical depths. Furthermore, we integrated MERFISH with retrograde labelling to probe projection targets of neurons of the mouse primary motor cortex and found that their cortical projections formed a complex network in which individual neuronal clusters project to multiple target regions and individual target regions receive inputs from multiple neuronal clusters.},
	language = {en},
	number = {7879},
	journal = {Nature},
	author = {Zhang, Meng and Eichhorn, Stephen W and Zingg, Brian and Yao, Zizhen and Cotter, Kaelan and Zeng, Hongkui and Dong, Hongwei and Zhuang, Xiaowei},
	month = oct,
	year = {2021},
	pages = {137--143},
}

@article{heys_functional_2014,
	title = {The functional micro-organization of grid cells revealed by cellular-resolution imaging},
	volume = {84},
	abstract = {Establishing how grid cells are anatomically arranged, on a microscopic scale, in relation to their firing patterns in the environment would facilitate a greater microcircuit-level understanding of the brain's representation of space. However, all previous grid cell recordings used electrode techniques that provide limited descriptions of fine-scale organization. We therefore developed a technique for cellular-resolution functional imaging of medial entorhinal cortex (MEC) neurons in mice navigating a virtual linear track, enabling a new experimental approach to study MEC. Using these methods, we show that grid cells are physically clustered in MEC compared to nongrid cells. Additionally, we demonstrate that grid cells are functionally micro-organized: the similarity between the environment firing locations of grid cell pairs varies as a function of the distance between them according to a “Mexican hat”-shaped profile. This suggests that, on average, nearby grid cells have more similar spatial firing phases than those further apart.},
	language = {en},
	number = {5},
	journal = {Neuron},
	author = {Heys, James G and Rangarajan, Krsna V and Dombeck, Daniel A},
	month = dec,
	year = {2014},
	pages = {1079--1090},
}

@article{chen_modularity_2021,
	title = {Modularity and robustness of frontal cortical networks},
	volume = {184},
	abstract = {Neural activity underlying short-term memory is maintained by interconnected networks of brain regions. It remains unknown how brain regions interact to maintain persistent activity while exhibiting robustness to corrupt information in parts of the network. We simultaneously measured activity in large neuronal populations across mouse frontal hemispheres to probe interactions between brain regions. Activity across hemispheres was coordinated to maintain coherent short-term memory. Across mice, we uncovered individual variability in the organization of frontal cortical networks. A modular organization was required for the robustness of persistent activity to perturbations: each hemisphere retained persistent activity during perturbations of the other hemisphere, thus preventing local perturbations from spreading. A dynamic gating mechanism allowed hemispheres to coordinate coherent information while gating out corrupt information. Our results show that robust short-term memory is mediated by redundant modular representations across brain regions. Redundant modular representations naturally emerge in neural network models that learned robust dynamics.},
	language = {en},
	number = {14},
	journal = {Cell},
	author = {Chen, Guang and Kang, Byungwoo and Lindsey, Jack and Druckmann, Shaul and Li, Nuo},
	month = jul,
	year = {2021},
	keywords = {recurrent neural networks, decision-making, fontal cortex, modular organization, multi-regional, network models, neural circuits, neural dynamics, persistent activity, Short-term memory},
	pages = {3717--3730.e24},
}

@article{chu_slowed_2021,
	title = {Slowed canonical progress in large fields of science},
	volume = {118},
	abstract = {In many academic fields, the number of papers published each year has increased significantly over time. Policy measures aim to increase the quantity of scientists, research funding, and scientific output, which is measured by the number of papers produced. These quantitative metrics determine the career trajectories of scholars and evaluations of academic departments, institutions, and nations. Whether and how these increases in the numbers of scientists and papers translate into advances in knowledge is unclear, however. Here, we first lay out a theoretical argument for why too many papers published each year in a field can lead to stagnation rather than advance. The deluge of new papers may deprive reviewers and readers the cognitive slack required to fully recognize and understand novel ideas. Competition among many new ideas may prevent the gradual accumulation of focused attention on a promising new idea. Then, we show data supporting the predictions of this theory. When the number of papers published per year in a scientific field grows large, citations flow disproportionately to already well-cited papers; the list of most-cited papers ossifies; new papers are unlikely to ever become highly cited, and when they do, it is not through a gradual, cumulative process of attention gathering; and newly published papers become unlikely to disrupt existing work. These findings suggest that the progress of large scientific fields may be slowed, trapped in existing canon. Policy measures shifting how scientific work is produced, disseminated, consumed, and rewarded may be called for to push fields into new, more fertile areas of study.},
	language = {en},
	number = {41},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Chu, Johan S G and Evans, James A},
	month = oct,
	year = {2021},
	keywords = {Scientific Publishing, science policy, durable dominance, entrepreneurial futility, science of science, scientific progress},
}

@article{bird_hippocampus_2008,
	title = {The hippocampus and memory: insights from spatial processing},
	volume = {9},
	abstract = {The hippocampus appears to be crucial for long-term episodic memory, yet its precise role remains elusive. Electrophysiological studies in rodents offer a useful starting point for developing models of hippocampal processing in the spatial domain. Here we review one such model that points to an essential role for the hippocampus in the construction of mental images. We explain how this neural-level mechanistic account addresses some of the current controversies in the field, such as the role of the hippocampus in imagery and short-term memory, and discuss its broader implications for the neural bases of episodic memory.},
	language = {en},
	number = {3},
	journal = {Nat. Rev. Neurosci.},
	author = {Bird, Chris M and Burgess, Neil},
	month = mar,
	year = {2008},
	pages = {182--194},
}

@article{international_brain_laboratory_standardized_2021,
	title = {Standardized and reproducible measurement of decision-making in mice},
	volume = {10},
	abstract = {Progress in science requires standardized assays whose results can be readily shared, compared, and reproduced across laboratories. Reproducibility, however, has been a concern in neuroscience, particularly for measurements of mouse behavior. Here, we show that a standardized task to probe decision-making in mice produces reproducible results across multiple laboratories. We adopted a task for head-fixed mice that assays perceptual and value-based decision making, and we standardized training protocol and experimental hardware, software, and procedures. We trained 140 mice across seven laboratories in three countries, and we collected 5 million mouse choices into a publicly available database. Learning speed was variable across mice and laboratories, but once training was complete there were no significant differences in behavior across laboratories. Mice in different laboratories adopted similar reliance on visual stimuli, on past successes and failures, and on estimates of stimulus prior probability to guide their choices. These results reveal that a complex mouse behavior can be reproduced across multiple laboratories. They establish a standard for reproducible rodent behavior, and provide an unprecedented dataset and open-access tools to study decision-making in mice. More generally, they indicate a path toward achieving reproducibility in neuroscience through collaborative open-science approaches.},
	language = {en},
	journal = {Elife},
	author = {{International Brain Laboratory} and Aguillon-Rodriguez, Valeria and Angelaki, Dora and Bayer, Hannah and Bonacchi, Niccolo and Carandini, Matteo and Cazettes, Fanny and Chapuis, Gaelle and Churchland, Anne K and Dan, Yang and Dewitt, Eric and Faulkner, Mayo and Forrest, Hamish and Haetzel, Laura and Häusser, Michael and Hofer, Sonja B and Hu, Fei and Khanal, Anup and Krasniak, Christopher and Laranjeira, Ines and Mainen, Zachary F and Meijer, Guido and Miska, Nathaniel J and Mrsic-Flogel, Thomas D and Murakami, Masayoshi and Noel, Jean-Paul and Pan-Vazquez, Alejandro and Rossant, Cyrille and Sanders, Joshua and Socha, Karolina and Terry, Rebecca and Urai, Anne E and Vergara, Hernando and Wells, Miles and Wilson, Christian J and Witten, Ilana B and Wool, Lauren E and Zador, Anthony M},
	month = may,
	year = {2021},
	keywords = {decision making, neuroscience, mouse, behavior, reproducibility},
}

@unpublished{pachitariu_kilosort_2016,
	title = {Kilosort: realtime spike-sorting for extracellular electrophysiology with hundreds of channels},
	abstract = {Advances in silicon probe technology mean that in vivo electrophysiological recordings from hundreds of channels will soon become commonplace. To interpret these recordings we need fast, scalable and accurate methods for spike sorting, whose output requires minimal time for manual curation. Here we introduce Kilosort, a spike sorting framework that meets these criteria, and show that it allows rapid and accurate sorting of large-scale in vivo data. Kilosort models the recorded voltage as a sum of template waveforms triggered on the spike times, allowing overlapping spikes to be identified and resolved. Rapid processing is achieved thanks to a novel low-dimensional approximation for the spatiotemporal distribution of each template, and to batch-based optimization on GPUs. A novel post-clustering merging step based on the continuity of the templates substantially reduces the requirement for subsequent manual curation operations. We compare Kilosort to an established algorithm on data obtained from 384-channel electrodes, and show superior performance, at much reduced processing times. Data from 384-channel electrode arrays can be processed in approximately realtime. Kilosort is an important step towards fully automated spike sorting of multichannel electrode recordings, and is freely available ([github.com/cortex-lab/Kilosort][1]). [1]: http://github.com/cortex-lab/Kilosort},
	language = {en},
	author = {Pachitariu, Marius and Steinmetz, Nicholas and Kadir, Shabnam and Carandini, Matteo and Harris, Kenneth D},
	month = jun,
	year = {2016},
	note = {Publication Title: bioRxiv},
}

@article{chapuis_spike_2022,
	title = {Spike sorting pipeline for the {International} {Brain} {Laboratory}},
	volume = {10},
	journal = {Channels},
	author = {Chapuis, Mayo Faulkner and Harris, Kenneth D and Huntenburg, Julia M and Hurwitz, Cole and Lee, Hyun Dong and Paninski, Liam and Rossant, Cyrille and Roth, Noam and Steinmetz, Nicholas A and Windolf, Charlie and {Others}},
	year = {2022},
	pages = {6},
}

@article{whiteway_partitioning_2021,
	title = {Partitioning variability in animal behavioral videos using semi-supervised variational autoencoders},
	volume = {17},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	abstract = {Recent neuroscience studies demonstrate that a deeper understanding of brain function requires a deeper understanding of behavior. Detailed behavioral measurements are now often collected using video cameras, resulting in an increased need for computer vision algorithms that extract useful information from video data. Here we introduce a new video analysis tool that combines the output of supervised pose estimation algorithms (e.g. DeepLabCut) with unsupervised dimensionality reduction methods to produce interpretable, low-dimensional representations of behavioral videos that extract more information than pose estimates alone. We demonstrate this tool by extracting interpretable behavioral features from videos of three different head-fixed mouse preparations, as well as a freely moving mouse in an open field arena, and show how these interpretable features can facilitate downstream behavioral and neural analyses. We also show how the behavioral features produced by our model improve the precision and interpretation of these downstream analyses compared to using the outputs of either fully supervised or fully unsupervised methods alone.},
	language = {en},
	number = {9},
	journal = {PLoS Comput. Biol.},
	author = {Whiteway, Matthew R and Biderman, Dan and Friedman, Yoni and Dipoppa, Mario and Buchanan, E Kelly and Wu, Anqi and Zhou, John and Bonacchi, Niccolò and Miska, Nathaniel J and Noel, Jean-Paul and Rodriguez, Erica and Schartner, Michael and Socha, Karolina and Urai, Anne E and Salzman, C Daniel and {International Brain Laboratory} and Cunningham, John P and Paninski, Liam},
	month = sep,
	year = {2021},
	note = {Publisher: Public Library of Science (PLoS)},
	pages = {e1009439},
}

@unpublished{wu_deep_2020,
	title = {Deep {Graph} {Pose}: a semi-supervised deep graphical model for improved animal pose tracking},
	abstract = {AbstractNoninvasive behavioral tracking of animals is crucial for many scientific investigations. Recent transfer learning approaches for behavioral tracking have considerably advanced the state of the art. Typically these methods treat each video frame and each object to be tracked independently. In this work, we improve on these methods (particularly in the regime of few training labels) by leveraging the rich spatiotemporal structures pervasive in behavioral video — specifically, the spatial statistics imposed by physical constraints (e.g., paw to elbow distance), and the temporal statistics imposed by smoothness from frame to frame. We propose a probabilistic graphical model built on top of deep neural networks, Deep Graph Pose (DGP), to leverage these useful spatial and temporal constraints, and develop an efficient structured variational approach to perform inference in this model. The resulting semi-supervised model exploits both labeled and unlabeled frames to achieve significantly more accurate and robust tracking while requiring users to label fewer training frames. In turn, these tracking improvements enhance performance on downstream applications, including robust unsupervised segmentation of behavioral “syllables,” and estimation of interpretable “disentangled” low-dimensional representations of the full behavioral video. Open source code is available athttps://github.com/paninski-lab/deepgraphpose.},
	author = {Wu, Anqi and Buchanan, E Kelly and Whiteway, Matthew R and Schartner, Michael and Meijer, Guido and Noel, Jean-Paul and Rodriguez, Erica and Everett, Claire and Norovich, Amy and Schaffer, Evan and Mishra, Neeli and Salzman, C Daniel and Angelaki, Dora and Bendesky, Andrés and Cunningham, John and Paninski, Liam and {The International Brain Laboratory}},
	month = aug,
	year = {2020},
	note = {Publication Title: bioRxiv
Publisher: bioRxiv},
}

@article{ashwood_mice_2022,
	title = {Mice alternate between discrete strategies during perceptual decision-making},
	volume = {25},
	abstract = {Classical models of perceptual decision-making assume that subjects use a single, consistent strategy to form decisions, or that decision-making strategies evolve slowly over time. Here we present new analyses suggesting that this common view is incorrect. We analyzed data from mouse and human decision-making experiments and found that choice behavior relies on an interplay among multiple interleaved strategies. These strategies, characterized by states in a hidden Markov model, persist for tens to hundreds of trials before switching, and often switch multiple times within a session. The identified decision-making strategies were highly consistent across mice and comprised a single 'engaged' state, in which decisions relied heavily on the sensory stimulus, and several biased states in which errors frequently occurred. These results provide a powerful alternate explanation for 'lapses' often observed in rodent behavioral experiments, and suggest that standard measures of performance mask the presence of major changes in strategy across trials.},
	language = {en},
	number = {2},
	journal = {Nat. Neurosci.},
	author = {Ashwood, Zoe C and Roy, Nicholas A and Stone, Iris R and {International Brain Laboratory} and Urai, Anne E and Churchland, Anne K and Pouget, Alexandre and Pillow, Jonathan W},
	month = feb,
	year = {2022},
	pages = {201--212},
}

@unpublished{klukas_fragmented_2021-1,
	title = {Fragmented {Spatial} {Maps}: {State} {Abstraction} and {Efficient} {Planning} from {Surprisal}},
	abstract = {When animals explore spatial environments, their representations often fragment into multiple maps. What determines these map fragmentations, and can we predict where they will occur with simple principles? We pose the problem of fragmentation of an environment as one of (online) spatial clustering. Taking inspiration from the notion of a contiguous region in robotics, we develop a theory in which fragmentation decisions are driven by surprisal. When this criterion is implemented with boundary, grid, and place cells in various environments, it produces map fragmentations from the first exploration of each space. Augmented with a long-term spatial memory and a rule similar to the distance-dependent Chinese Restaurant Process for selecting among relevant memories, the theory predicts the reuse of map fragments in environments with repeating substructures. Our model provides a simple rule for generating spatial state abstractions and predicts map fragmentations observed in electrophysiological recordings. It further predicts that there should be “fragmentation decision” or “fracture” cells, which in multicompartment environments could be called “doorway” cells. Finally, we show that the resulting abstractions can lead to large (orders of magnitude) improvements in the ability to plan and navigate through complex environments. \#\#\# Competing Interest Statement The authors have declared no competing interest.},
	language = {en},
	author = {Klukas, Mirko and Sharma, Sugandha and Du, Yilun and Lozano-Perez, Tomas and Kaelbling, Leslie and Fiete, Ila},
	month = nov,
	year = {2021},
	note = {Publication Title: bioRxiv},
}

@article{noauthor_30f0641c041f03d94e95a76b9d8bd58f-paperpdf_nodate,
	title = {30f0641c041f03d94e95a76b9d8bd58f-{Paper}.pdf},
}

@article{calaim_geometry_2022,
	title = {The geometry of robustness in spiking neural networks},
	volume = {11},
	abstract = {Neural systems are remarkably robust against various perturbations, a phenomenon that still requires a clear explanation. Here, we graphically illustrate how neural networks can become robust. We study spiking networks that generate low-dimensional representations, and we show that the neurons' subthreshold voltages are confined to a convex region in a lower-dimensional voltage subspace, which we call a 'bounding box'. Any changes in network parameters (such as number of neurons, dimensionality of inputs, firing thresholds, synaptic weights, or transmission delays) can all be understood as deformations of this bounding box. Using these insights, we show that functionality is preserved as long as perturbations do not destroy the integrity of the bounding box. We suggest that the principles underlying robustness in these networks - low-dimensional representations, heterogeneity of tuning, and precise negative feedback - may be key to understanding the robustness of neural systems at the circuit level.},
	language = {en},
	journal = {Elife},
	author = {Calaim, Nuno and Dehmelt, Florian A and Gonçalves, Pedro J and Machens, Christian K},
	month = may,
	year = {2022},
	keywords = {neuroscience, computational biology, none, systems biology, neural coding, robustness, spiking neural networks},
}

@article{deitch_representational_2021,
	title = {Representational drift in the mouse visual cortex},
	volume = {31},
	abstract = {Recent studies have shown that neuronal representations gradually change over time despite no changes in the stimulus, environment, or behavior. However, such representational drift has been assumed to be a property of high-level brain structures, whereas earlier circuits, such as sensory cortices, have been assumed to stably encode information over time. Here, we analyzed large-scale optical and electrophysiological recordings from six visual cortical areas in behaving mice that were repeatedly presented with the same natural movies. Contrary to the prevailing notion, we found representational drift over timescales spanning minutes to days across multiple visual areas, cortical layers, and cell types. Notably, neural-code stability did not reflect the hierarchy of information flow across areas. Although individual neurons showed time-dependent changes in their coding properties, the structure of the relationships between population activity patterns remained stable and stereotypic. Such population-level organization may underlie stable visual perception despite continuous changes in neuronal responses.},
	language = {en},
	number = {19},
	journal = {Curr. Biol.},
	author = {Deitch, Daniel and Rubin, Alon and Ziv, Yaniv},
	month = oct,
	year = {2021},
	keywords = {calcium imaging, visual cortex, manifold, neuropixels, representational drift, tuning curve},
	pages = {4327--4339.e6},
}

@misc{driscoll_dynamic_2017,
	title = {Dynamic {Reorganization} of {Neuronal} {Activity} {Patterns} in {Parietal} {Cortex}},
	author = {Driscoll, Laura N and Pettit, Noah L and Minderer, Matthias and Chettih, Selmaan N and Harvey, Christopher D},
	year = {2017},
	note = {Issue: 5
Pages: 986–999.e16
Publication Title: Cell
Volume: 170},
}

@article{duncan_adaptive_2001,
	title = {An adaptive coding model of neural function in prefrontal cortex},
	volume = {2},
	language = {en},
	number = {11},
	journal = {Nat. Rev. Neurosci.},
	author = {Duncan, J},
	month = nov,
	year = {2001},
	pages = {820--829},
}

@article{jensen_long-term_2022,
	title = {Long-term stability of single neuron activity in the motor system},
	volume = {25},
	abstract = {How an established behavior is retained and consistently produced by a nervous system in constant flux remains a mystery. One possible solution to ensure long-term stability in motor output is to fix the activity patterns of single neurons in the relevant circuits. Alternatively, activity in single cells could drift over time provided that the population dynamics are constrained to produce the same behavior. To arbitrate between these possibilities, we recorded single-unit activity in motor cortex and striatum continuously for several weeks as rats performed stereotyped motor behaviors-both learned and innate. We found long-term stability in single neuron activity patterns across both brain regions. A small amount of drift in neural activity, observed over weeks of recording, could be explained by concomitant changes in task-irrelevant aspects of the behavior. These results suggest that long-term stable behaviors are generated by single neuron activity patterns that are themselves highly stable.},
	language = {en},
	number = {12},
	journal = {Nat. Neurosci.},
	author = {Jensen, Kristopher T and Kadmon Harpaz, Naama and Dhawale, Ashesh K and Wolff, Steffen B E and Ölveczky, Bence P},
	month = dec,
	year = {2022},
	pages = {1664--1674},
}

@article{schoonover_representational_2021,
	title = {Representational drift in primary olfactory cortex},
	volume = {594},
	abstract = {Perceptual constancy requires the brain to maintain a stable representation of sensory input. In the olfactory system, activity in primary olfactory cortex (piriform cortex) is thought to determine odour identity1-5. Here we present the results of electrophysiological recordings of single units maintained over weeks to examine the stability of odour-evoked responses in mouse piriform cortex. Although activity in piriform cortex could be used to discriminate between odorants at any moment in time, odour-evoked responses drifted over periods of days to weeks. The performance of a linear classifier trained on the first recording day approached chance levels after 32 days. Fear conditioning did not stabilize odour-evoked responses. Daily exposure to the same odorant slowed the rate of drift, but when exposure was halted the rate increased again. This demonstration of continuous drift poses the question of the role of piriform cortex in odour perception. This instability might reflect the unstructured connectivity of piriform cortex6-12, and may be a property of other unstructured cortices.},
	language = {en},
	number = {7864},
	journal = {Nature},
	author = {Schoonover, Carl E and Ohashi, Sarah N and Axel, Richard and Fink, Andrew J P},
	month = jun,
	year = {2021},
	pages = {541--546},
}

@misc{voitov_cortical_2022,
	title = {Cortical feedback loops bind distributed representations of working memory},
	author = {Voitov, Ivan and Mrsic-Flogel, Thomas D},
	year = {2022},
	note = {Issue: 7922
Pages: 381–389
Publication Title: Nature
Volume: 608},
}

@article{gjorgjieva_triplet_2011,
	title = {A triplet spike-timing-dependent plasticity model generalizes the {Bienenstock}-{Cooper}-{Munro} rule to higher-order spatiotemporal correlations},
	volume = {108},
	abstract = {Synaptic strength depresses for low and potentiates for high activation of the postsynaptic neuron. This feature is a key property of the Bienenstock-Cooper-Munro (BCM) synaptic learning rule, which has been shown to maximize the selectivity of the postsynaptic neuron, and thereby offers a possible explanation for experience-dependent cortical plasticity such as orientation selectivity. However, the BCM framework is rate-based and a significant amount of recent work has shown that synaptic plasticity also depends on the precise timing of presynaptic and postsynaptic spikes. Here we consider a triplet model of spike-timing-dependent plasticity (STDP) that depends on the interactions of three precisely timed spikes. Triplet STDP has been shown to describe plasticity experiments that the classical STDP rule, based on pairs of spikes, has failed to capture. In the case of rate-based patterns, we show a tight correspondence between the triplet STDP rule and the BCM rule. We analytically demonstrate the selectivity property of the triplet STDP rule for orthogonal inputs and perform numerical simulations for nonorthogonal inputs. Moreover, in contrast to BCM, we show that triplet STDP can also induce selectivity for input patterns consisting of higher-order spatiotemporal correlations, which exist in natural stimuli and have been measured in the brain. We show that this sensitivity to higher-order correlations can be used to develop direction and speed selectivity.},
	language = {en},
	number = {48},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Gjorgjieva, Julijana and Clopath, Claudia and Audet, Juliette and Pfister, Jean-Pascal},
	month = nov,
	year = {2011},
	pages = {19383--19388},
}

@article{pechuk_reprogramming_2022,
	title = {Reprogramming the topology of the nociceptive circuit in {C}. elegans reshapes sexual behavior},
	volume = {32},
	abstract = {The effect of the detailed connectivity of a neural circuit on its function and the resulting behavior of the organism is a key question in many neural systems. Here, we study the circuit for nociception in C. elegans, which is composed of the same neurons in the two sexes that are wired differently. We show that the nociceptive sensory neurons respond similarly in the two sexes, yet the animals display sexually dimorphic behaviors to the same aversive stimuli. To uncover the role of the downstream network topology in shaping behavior, we learn and simulate network models that replicate the observed dimorphic behaviors and use them to predict simple network rewirings that would switch behavior between the sexes. We then show experimentally that these subtle synaptic rewirings indeed flip behavior. Interestingly, when presented with aversive cues, rewired males were compromised in finding mating partners, suggesting that network topologies that enable efficient avoidance of noxious cues have a reproductive “cost.” Our results present a deconstruction of the design of a neural circuit that controls sexual behavior and how to reprogram it.},
	language = {en},
	number = {20},
	journal = {Curr. Biol.},
	author = {Pechuk, Vladyslava and Goldman, Gal and Salzberg, Yehuda and Chaubey, Aditi H and Bola, R Aaron and Hoffman, Jonathon R and Endreson, Morgan L and Miller, Renee M and Reger, Noah J and Portman, Douglas S and Ferkey, Denise M and Schneidman, Elad and Oren-Suissa, Meital},
	month = oct,
	year = {2022},
	keywords = {calcium imaging, optogenetics, C. elegans, computational modeling, artificial synapses, behavioral analysis, network parameters, network topology, neurobiology, neuronal circuits, nociception, sensory processing, sexually dimorphic behaviors, transsynaptic labeling},
	pages = {4372--4385.e7},
}

@article{nummenmaa_bodily_2014,
	title = {Bodily maps of emotions},
	volume = {111},
	abstract = {Emotions are often felt in the body, and somatosensory feedback has been proposed to trigger conscious emotional experiences. Here we reveal maps of bodily sensations associated with different emotions using a unique topographical self-report method. In five experiments, participants (n = 701) were shown two silhouettes of bodies alongside emotional words, stories, movies, or facial expressions. They were asked to color the bodily regions whose activity they felt increasing or decreasing while viewing each stimulus. Different emotions were consistently associated with statistically separable bodily sensation maps across experiments. These maps were concordant across West European and East Asian samples. Statistical classifiers distinguished emotion-specific activation maps accurately, confirming independence of topographies across emotions. We propose that emotions are represented in the somatosensory system as culturally universal categorical somatotopic maps. Perception of these emotion-triggered bodily changes may play a key role in generating consciously felt emotions.},
	language = {en},
	number = {2},
	journal = {Proc. Natl. Acad. Sci. U. S. A.},
	author = {Nummenmaa, Lauri and Glerean, Enrico and Hari, Riitta and Hietanen, Jari K},
	month = jan,
	year = {2014},
	keywords = {embodiment, feelings, somatosensation},
	pages = {646--651},
}

@article{green_positional_2015,
	title = {Positional information and reaction-diffusion: two big ideas in developmental biology combine},
	volume = {142},
	abstract = {One of the most fundamental questions in biology is that of biological pattern: how do the structures and shapes of organisms arise? Undoubtedly, the two most influential ideas in this area are those of Alan Turing's 'reaction-diffusion' and Lewis Wolpert's 'positional information'. Much has been written about these two concepts but some confusion still remains, in particular about the relationship between them. Here, we address this relationship and propose a scheme of three distinct ways in which these two ideas work together to shape biological form.},
	language = {en},
	number = {7},
	journal = {Development},
	author = {Green, Jeremy B A and Sharpe, James},
	month = apr,
	year = {2015},
	keywords = {Biological pattern, Developmental biology, History of ideas, Reaction-diffusion},
	pages = {1203--1211},
}

@article{yim_where_2019,
	title = {Where can a place cell put its fields? let {Us} count the ways},
	abstract = {A hippocampal place cell exhibits multiple firing fields within and across environments. What factors determine the configuration of these fields, and could they be set down in arbitrary …},
	journal = {BioRxiv},
	author = {Yim, M Y and Sadun, L A and Fiete, I R and Taillefumier, T},
	year = {2019},
	note = {Publisher: biorxiv.org},
}

@article{duan_see_2022,
	title = {See and {Copy}: {Generation} of complex compositional movements from modular and geometric {RNN} representations},
	abstract = {A hallmark of biological intelligence and control is combinatorial generalization: animals are able to learn various things, then piece them together in new combinations to produce appropriate outputs for new tasks. Inspired by the ability of primates to readily imitate seen movement sequences, we present a model of motor control using a realistic model of arm dynamics, tasked with imitating a guide that makes arbitrary two-segment drawings. We hypothesize that modular organization is one of the keys to such flexible and generalizable control. We construct a modular control model consisting of separate encoding and motor RNNs and a scheduler, which we train end-to-end on the task. We show that the modular structure allows the model to generalize not only to unseen two-segment trajectories, but to new drawings consisting of many more segments than it was trained on, and also allows for rapid adaptation to perturbations. Finally, our model recapitulates experimental observations of the preparatory and execution-related processes unfolding during motor control, providing a normative explanation for functional segregation of preparatory and execution-related activity within the motor cortex.},
	author = {Duan, Sunny and Khona, Mikail and Bertagnoli, Adrian and Chandra, Sarthak and Fiete, Ila},
	month = oct,
	year = {2022},
	note = {\_eprint: 2210.02521},
}

@unpublished{neupane_vector_2022,
	title = {Vector production via mental navigation in the entorhinal cortex},
	abstract = {A cognitive map is a suitably structured representation that enables an agent to perform novel computations using prior experience, for instance planning a new route in a familiar space[1][1],[2][2]. Recent work in mammals has found direct evidence for such structured representations in the presence of exogenous sensory inputs in both spatial[3][3],[4][4] and non-spatial domains[5][5]–[15][6]. Here, we test a foundational postulate of the original cognitive map theory[1][1],[16][7] that cognitive maps are recruited endogenously during mental navigation without external input. We recorded from the entorhinal cortex of monkeys in a mental navigation task that required animals to use a joystick to produce one-dimensional vectors between pairs of visual landmarks without sensory feedback about the intermediate landmarks. Animals' ability to perform the task and generalize to new pairs indicated that they relied on a structured representation of the landmarks. Task-modulated neurons exhibited periodicity and ramping that matched the temporal structure of the landmarks. Neuron pairs with high periodicity scores had invariant cross-correlation structure, a signature of grid cell continuous attractor states[17][8]– [19][9]. A basic continuous attractor network model of path integration[20][10] augmented with a Hebbian learning mechanism provided an explanation of how the system endogenously recalls landmarks. The model also made an unexpected prediction that endogenous landmarks transiently slow down path integration, reset the dynamics, and thereby, reduce variability. Remarkably, this prediction was borne out of a reanalysis of behavior. Together, our findings connect the structured activity patterns in the entorhinal cortex to the endogenous recruitment of a cognitive map during mental navigation. \#\#\# Competing Interest Statement The authors have declared no competing interest. [1]: \#ref-1 [2]: \#ref-2 [3]: \#ref-3 [4]: \#ref-4 [5]: \#ref-5 [6]: \#ref-15 [7]: \#ref-16 [8]: \#ref-17 [9]: \#ref-19 [10]: \#ref-20},
	language = {en},
	author = {Neupane, Sujaya and Fiete, Ila and Jazayeri, Mehrdad},
	month = dec,
	year = {2022},
	note = {Publication Title: bioRxiv},
}

@article{van_wingerden_theta-band_2010,
	title = {Theta-band phase locking of orbitofrontal neurons during reward expectancy},
	volume = {30},
	abstract = {The expectancy of a rewarding outcome following actions and cues is coded by a network of brain structures including the orbitofrontal cortex. Thus far, predicted reward was considered to be coded by time-averaged spike rates of neurons. However, besides firing rate, the precise timing of action potentials in relation to ongoing oscillations in local field potentials is thought to be of importance for effective communication between brain areas. We performed multineuron and field potential recordings in orbitofrontal cortex of rats performing olfactory discrimination learning to study the temporal structure of coding predictive of outcome. After associative learning, field potentials were marked by theta oscillations, both in advance and during delivery of reward. Orbitofrontal neurons, especially those coding information about upcoming reward with their firing rate, phase locked to these oscillations in anticipation of reward. When established associations were reversed, phase locking collapsed in the anticipatory task phase, but returned when reward became predictable again after relearning. Behaviorally, the outcome anticipation phase was marked by licking responses, but the frequency of lick responses was dissociated from the strength of theta-band phase locking. The strength of theta-band phase locking by orbitofrontal neurons robustly follows the dynamics of associative learning as measured by behavior and correlates with the rat's current outcome expectancy. Theta-band phase locking may facilitate communication of outcome-related information between reward-related brain areas and offers a novel mechanism for coding value signals during reinforcement learning.},
	language = {en},
	number = {20},
	journal = {J. Neurosci.},
	author = {van Wingerden, Marijn and Vinck, Martin and Lankelma, Jan and Pennartz, Cyriel M A},
	month = may,
	year = {2010},
	pages = {7078--7087},
}

@article{latuske_hippocampal_2017,
	title = {Hippocampal {Remapping} and {Its} {Entorhinal} {Origin}},
	volume = {11},
	abstract = {The activity of hippocampal cell ensembles is an accurate predictor of the position of an animal in its surrounding space. One key property of hippocampal cell ensembles is their ability to change in response to alterations in the surrounding environment, a phenomenon called remapping. In this review article, we present evidence for the distinct types of hippocampal remapping. The progressive divergence over time of cell ensembles active in different environments and the transition dynamics between pre-established maps are discussed. Finally, we review recent work demonstrating that hippocampal remapping can be triggered by neurons located in the entorhinal cortex.},
	language = {en},
	journal = {Front. Behav. Neurosci.},
	author = {Latuske, Patrick and Kornienko, Olga and Kohler, Laura and Allen, Kevin},
	year = {2017},
	keywords = {entorhinal cortex, hippocampus, place cells, memory, grid cell, navigation, remapping},
	pages = {253},
}

@article{umulis_mechanisms_2013,
	title = {Mechanisms of scaling in pattern formation},
	volume = {140},
	abstract = {Many organisms and their constituent tissues and organs vary substantially in size but differ little in morphology; they appear to be scaled versions of a common template or pattern. Such scaling involves adjusting the intrinsic scale of spatial patterns of gene expression that are set up during development to the size of the system. Identifying the mechanisms that regulate scaling of patterns at the tissue, organ and organism level during development is a longstanding challenge in biology, but recent molecular-level data and mathematical modeling have shed light on scaling mechanisms in several systems, including Drosophila and Xenopus. Here, we investigate the underlying principles needed for understanding the mechanisms that can produce scale invariance in spatial pattern formation and discuss examples of systems that scale during development.},
	language = {en},
	number = {24},
	journal = {Development},
	author = {Umulis, David M and Othmer, Hans G},
	month = dec,
	year = {2013},
	keywords = {Turing, Bone morphogenetic proteins, Mathematical modeling, Morphogen, Pattern formation, Scale invariance},
	pages = {4830--4843},
}

@article{hopfield_computing_1986,
	title = {Computing with neural circuits: a model},
	volume = {233},
	abstract = {A new conceptual framework and a minimization principle together provide an understanding of computation in model neural circuits. The circuits consist of nonlinear graded-response model neurons organized into networks with effectively symmetric synaptic connections. The neurons represent an approximation to biological neurons in which a simplified set of important computational properties is retained. Complex circuits solving problems similar to those essential in biology can be analyzed and understood without the need to follow the circuit dynamics in detail. Implementation of the model with electronic devices will provide a class of electronic circuits of novel form and function.},
	language = {en},
	number = {4764},
	journal = {Science},
	author = {Hopfield, J J and Tank, D W},
	month = aug,
	year = {1986},
	pages = {625--633},
}

@article{gattass_visuotopic_1988,
	title = {Visuotopic organization and extent of {V3} and {V4} of the macaque},
	volume = {8},
	abstract = {The representation of the visual field in areas V3 and V4 of the macaque was mapped with multiunit electrodes. Twelve Macaca fascicularis were studied in repeated recording sessions while immobilized and anesthetized. V3 is a narrow strip (4-5 mm wide) of myeloarchitectonically distinct cortex located immediately anterior to V2. It contains a systematic representation of the central 35-40 degrees of the contralateral visual field; the representation of the upper quadrant is located ventrally in the hemisphere and that of the lower quadrant, dorsally. There is a small gap between the dorsal (V3d) and ventral (V3v) portions of V3. The representation of the horizontal meridian is adjacent to that in V2 and forms the posterior border of both V3d and V3v. Most or all of the anterior border of V3d consists of the representation of the lower vertical meridian. The entire anterior border of V3v consists of the representation of the upper vertical meridian. V4 is a strip of myeloarchitectonically distinct cortex 5-8 mm wide, immediately anterior to V3. It contains a coarse, but systematic, representation of approximately the central 35-40 degrees of the contralateral visual field. The representation of the upper visual field is located ventrally in the hemisphere. Most of the representation of the lower visual field is located dorsally. The posterior border of V4 corresponds to the representation of the vertical meridian, and the representation of the horizontal meridian is located at or near its anterior border. In both V3 and V4, the representation of the central visual field is magnified relative to that of the periphery. In both areas, the size of receptive fields increases with increasing eccentricity; however, at a given eccentricity, the receptive fields of V4 are larger than those of V3.},
	language = {en},
	number = {6},
	journal = {J. Neurosci.},
	author = {Gattass, R and Sousa, A P and Gross, C G},
	month = jun,
	year = {1988},
	pages = {1831--1845},
}
