\begin{thebibliography}{10}

\bibitem{lecun2022path}
Yann LeCun.
\newblock A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27.
\newblock {\em Open Review}, 62, 2022.

\bibitem{assran2023ijepa}
Mahmoud Assran, Quentin Duval, Ishan Misra, Piotr Bojanowski, Pascal Vincent, Michael Rabbat, Yann LeCun, and Nicolas Ballas.
\newblock Self-supervised learning from images with a joint-embedding predictive architecture.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 15619--15629, 2023.

\bibitem{bardes2024revisiting}
Adrien Bardes, Quentin Garrido, Jean Ponce, Xinlei Chen, Michael Rabbat, Yann LeCun, Mahmoud Assran, and Nicolas Ballas.
\newblock Revisiting feature prediction for learning visual representations from video.
\newblock {\em arXiv preprint arXiv:2404.08471}, 2024.

\bibitem{chen2021simsiam}
Xinlei Chen and Kaiming He.
\newblock Exploring simple siamese representation learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 15750--15758, 2021.

\bibitem{tian2021Understanding}
Yuandong Tian, Xinlei Chen, and Surya Ganguli.
\newblock Understanding self-supervised learning dynamics without contrastive pairs.
\newblock In {\em Proceedings of the 38th International Conference on Machine Learning (ICML)}, pages 10268--10278. PMLR, 2021.

\bibitem{bardes2022vicreg}
Adrien Bardes, Jean Ponce, and Yann LeCun.
\newblock {VICR}eg: Variance-invariance-covariance regularization for self-supervised learning.
\newblock In {\em Proceedings of International Conference on Learning Representations (ICLR)}, 2022.

\bibitem{tian2020what}
Yonglong Tian, Chen Sun, Ben Poole, Dilip Krishnan, Cordelia Schmid, and Phillip Isola.
\newblock What makes for good views for contrastive learning?
\newblock In {\em Proceedings of Advances in Neural Information Processing Systems (NeurIPS)}, pages 6827--6839, 2020.

\bibitem{tian2020contrastive}
Yonglong Tian, Dilip Krishnan, and Phillip Isola.
\newblock Contrastive multiview coding.
\newblock In {\em Proceedings of European Conference on Computer Vision (ECCV)}, 2020.

\bibitem{misra2020self}
Ishan Misra and Laurens van~der Maaten.
\newblock Self-supervised learning of pretext-invariant representations.
\newblock In {\em IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2020.

\bibitem{bao2021beit}
Hangbo Bao, Li~Dong, and Furu Wei.
\newblock Beit: {BERT} pre-training of image transformers.
\newblock {\em arXiv preprint arXiv:2106.08254}, 2021.

\bibitem{atito2021sit}
Sara Atito, Muhammad Awais, and Josef Kittler.
\newblock Sit: Self-supervised vision transformer.
\newblock {\em arXiv preprint arXiv:2104.03602}, 2021.

\bibitem{he2021masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'{a}}r, and Ross~B. Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock {\em arXiv preprint arXiv:2111.06377}, 2021.

\bibitem{wei2022masked}
Chen Wei, Haoqi Fan, Saining Xie, Chao-Yuan Wu, Alan Yuille, and Christoph Feichtenhofer.
\newblock Masked feature prediction for self-supervised visual pre-training.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 14668--14678, June 2022.

\bibitem{xie2022SimMIM}
Zhenda Xie, Zheng Zhang, Yue Cao, Yutong Lin, Jianmin Bao, Zhuliang Yao, Qi~Dai, and Han Hu.
\newblock Simmim: A simple framework for masked image modeling.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 9653--9663, June 2022.

\bibitem{wu2022objectwise}
Jiantao Wu and Shentong Mo.
\newblock Object-wise masked autoencoders for fast pre-training.
\newblock {\em arXiv preprint arXiv:2205.14338}, 2022.

\bibitem{wu2023masked}
Jiantao Wu, Shentong Mo, Muhammad Awais, Sara Atito, Zhenhua Feng, and Josef Kittler.
\newblock Masked momentum contrastive learning for zero-shot semantic understanding.
\newblock {\em arXiv preprint arXiv:2308.11448}, 2023.

\bibitem{wu2023accuracy}
Jiantao Wu, Shentong Mo, Sara Atito, Josef Kittler, Zhenhua Feng, and Muhammad Awais.
\newblock Beyond accuracy: Statistical measures and benchmark for evaluation of representation from self-supervised learning.
\newblock {\em arXiv preprint arXiv:2312.01118}, 2023.

\bibitem{wu2024dailymae}
Jiantao Wu, Shentong Mo, Sara Atito, Zhenhua Feng, Josef Kittler, and Muhammad Awais.
\newblock Dailymae: Towards pretraining masked autoencoders in one day.
\newblock {\em arXiv preprint arXiv:2404.00509}, 2024.

\bibitem{chen2022context}
Xiaokang Chen, Mingyu Ding, Xiaodi Wang, Ying Xin, Shentong Mo, Yunhao Wang, Shumin Han, Ping Luo, Gang Zeng, and Jingdong Wang.
\newblock Context autoencoder for self-supervised representation learning.
\newblock {\em arXiv preprint arXiv:2202.03026}, 2022.

\bibitem{li2021mst}
Zhaowen Li, Zhiyang Chen, Fan Yang, Wei Li, Yousong Zhu, Chaoyang Zhao, Rui Deng, Liwei Wu, Rui Zhao, Ming Tang, and Jinqiao Wang.
\newblock {MST}: Masked self-supervised transformer for visual representation.
\newblock In {\em Proceedings of Advances in Neural Information Processing Systems (NeurIPS)}, 2021.

\bibitem{shi2022adversarial}
Yuge Shi, N~Siddharth, Philip~HS Torr, and Adam~R Kosiorek.
\newblock Adversarial masking for self-supervised learning.
\newblock In {\em Proceedings of International Conference on Machine Learning (ICML)}, 2022.

\bibitem{wei2022mvp}
Longhui Wei, Lingxi Xie, Wengang Zhou, Houqiang Li, and Qi~Tian.
\newblock {MVP:} multimodality-guided visual pre-training.
\newblock In {\em Proceedings of the European Conference on Computer Vision (ECCV)}, pages 337--353, 2022.

\bibitem{li2022semmae}
Gang Li, Heliang Zheng, Daqing Liu, Chaoyue Wang, Bing Su, and Changwen Zheng.
\newblock Sem{MAE}: Semantic-guided masking for learning masked autoencoders.
\newblock In {\em Proceedings of Advances in Neural Information Processing Systems (NeurIPS)}, 2022.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever.
\newblock Learning transferable visual models from natural language supervision.
\newblock {\em arXiv preprint arXiv:2103.00020}, 2021.

\bibitem{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual representations.
\newblock In {\em Proceedings of International Conference on Machine Learning (ICML)}, 2020.

\bibitem{chen2020big}
Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey Hinton.
\newblock Big self-supervised models are strong semi-supervised learners.
\newblock In {\em Proceedings of Advances in Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem{grill2020bootstrap}
Jean-Bastien Grill, Florian Strub, Florent Altch\'{e}, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila~Pires, Zhaohan Guo, Mohammad Gheshlaghi~Azar, Bilal Piot, koray kavukcuoglu, Remi Munos, and Michal Valko.
\newblock Bootstrap your own latent - a new approach to self-supervised learning.
\newblock In {\em Proceedings of Advances in Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem{he2019moco}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In {\em Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 9729--9738, 2020.

\bibitem{chen2020mocov2}
Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He.
\newblock Improved baselines with momentum contrastive learning.
\newblock {\em arXiv preprint arXiv:2003.04297}, 2020.

\bibitem{khosla2020sup}
Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce~Liu, and Dilip Krishnan.
\newblock Supervised contrastive learning.
\newblock In {\em Proceedings of Advances in Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem{cao2020parametric}
Yue Cao, Zhenda Xie, Bin Liu, Yutong Lin, Zheng Zhang, and Han Hu.
\newblock Parametric instance classification for unsupervised visual feature learning.
\newblock In {\em Proceedings of Advances in Neural Information Processing Systems (NeurIPS)}, pages 15614--15624, 2020.

\bibitem{hu2021adco}
Hu~Qianjiang, Wang Xiao, Hu~Wei, and Qi~Guo-Jun.
\newblock {AdCo:} adversarial contrast for efficient learning of unsupervised representations from self-trained negative adversaries.
\newblock In {\em Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 1074--1083, 2021.

\bibitem{mo2023exploring}
Shentong Mo, Zhun Sun, and Chao Li.
\newblock Exploring data augmentations on self-/semi-/fully- supervised pre-trained models.
\newblock {\em arXiv preprint arXiv:2310.18850}, 2023.

\bibitem{mo2023representation}
Shentong Mo, Zhun Sun, and Chao Li.
\newblock Representation disentanglement in generative models with contrastive learning.
\newblock {\em 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, pages 1531--1540, 2023.

\bibitem{caron2020unsupervised}
Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, and Armand Joulin.
\newblock Unsupervised learning of visual features by contrasting cluster assignments.
\newblock In {\em Proceedings of Advances in Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem{li2021prototypical}
Junnan Li, Pan Zhou, Caiming Xiong, and Steven Hoi.
\newblock Prototypical contrastive learning of unsupervised representations.
\newblock In {\em Proceedings of International Conference on Learning Representations (ICLR)}, 2021.

\bibitem{wang2021cld}
Xudong Wang, Ziwei Liu, and Stella~X Yu.
\newblock {CLD:} unsupervised feature learning by cross-level instance-group discrimination.
\newblock In {\em IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2021.

\bibitem{mo2021spcl}
Shentong Mo, Zhun Sun, and Chao Li.
\newblock Siamese prototypical contrastive learning.
\newblock In {\em BMVC}, 2021.

\bibitem{mo2022pauc}
Shentong Mo, Zhun Sun, and Chao Li.
\newblock Rethinking prototypical contrastive learning through alignment, uniformity and correlation.
\newblock In {\em Proceedings of British Machine Vision Conference (BMVC)}, 2022.

\bibitem{mo2023mcvt}
Shentong Mo, Zhun Sun, and Chao Li.
\newblock Multi-level contrastive learning for self-supervised vision transformers.
\newblock In {\em 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, pages 2777--2786, 2023.

\bibitem{mo2024dmtjepa}
Shentong Mo and Sukmin Yun.
\newblock Dmt-jepa: Discriminative masked targets for joint-embedding predictive architecture.
\newblock {\em arXiv preprint arXiv: 2405.17995}, 2024.

\bibitem{chen2023bag}
Yubei Chen, Adrien Bardes, ZENGYI LI, and Yann LeCun.
\newblock Bag of image patch embedding behind the success of self-supervised learning.
\newblock {\em Transactions on Machine Learning Research}, 2023.

\bibitem{halvagal2023implicit}
Manu~Srinath Halvagal, Axel Laborieux, and Friedemann Zenke.
\newblock Implicit variance regularization in non-contrastive {SSL}.
\newblock In {\em Proceedings of Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS)}, 2023.

\bibitem{jacot2018neural}
Arthur Jacot, Franck Gabriel, and Clément Hongler.
\newblock Neural tangent kernel: Convergence and generalization in neural networks.
\newblock In {\em Proceedings of Advances in Neural Information Processing Systems}, 2018.

\bibitem{lee2019wide}
Jaehoon Lee, Lechao Xiao, Samuel~S Schoenholz, Yasaman Bahri, Roman Novak, Jascha Sohl-Dickstein, and Jeffrey Pennington.
\newblock Wide neural networks of any depth evolve as linear models under gradient descent.
\newblock In {\em Proceedings of Advances in Neural Information Processing Systems (NeurIPS)}, 2019.

\bibitem{imagenet_cvpr09}
Jia Deng, Wei Dong, Richard Socher, Li-Jia. Li, Kai Li, and Li~Fei-Fei.
\newblock {ImageNet: A Large-Scale Hierarchical Image Database}.
\newblock In {\em Proceedings of IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 248--255, 2009.

\bibitem{lin2014coco}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, and C.~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em Proceedings of the European Conference on Computer Vision (ECCV)}, pages 740--755, 2014.

\bibitem{zhou2017scene}
Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio Torralba.
\newblock Scene parsing through ade20k dataset.
\newblock In {\em IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 5122--5130, 2017.

\bibitem{Zhou2018SemanticUO}
Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio Torralba.
\newblock Semantic understanding of scenes through the ade20k dataset.
\newblock {\em International Journal of Computer Vision (IJCV)}, 127:302--321, 2018.

\bibitem{chen2021mocov3}
Xinlei Chen, Saining Xie, and Kaiming He.
\newblock An empirical study of training self-supervised vision transformers.
\newblock In {\em Proceedings of the International Conference on Computer Vision (ICCV)}, 2021.

\bibitem{caron2021emerging}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\'e J\'egou, Julien Mairal, Piotr Bojanowski, and Armand Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In {\em Proceedings of the International Conference on Computer Vision (ICCV)}, 2021.

\bibitem{he2017mask}
Kaiming He, Georgia Gkioxari, Piotr Doll\'{a}r, and Ross Girshick.
\newblock Mask r-cnn.
\newblock In {\em IEEE/CVF International Conference on Computer Vision (ICCV)}, pages 2980--2988, 2017.

\bibitem{dosovitskiy2021an}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In {\em Proceedings of International Conference on Learning Representations}, 2021.

\bibitem{xiao2018unified}
Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, and Jian Sun.
\newblock Unified perceptual parsing for scene understanding.
\newblock In {\em Proceedings of European Conference on Computer Vision (ECCV)}, pages 432--448, 2018.

\bibitem{johnson2016clevr}
Justin Johnson, Bharath Hariharan, Laurens van~der Maaten, Li~Fei-Fei, C.~Lawrence Zitnick, and Ross Girshick.
\newblock Clevr: A diagnostic dataset for compositional language and elementary visual reasoning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 2901--2910, 2016.

\bibitem{zhou2021ibot}
Jinghao Zhou, Chen Wei, Huiyu Wang, Wei Shen, Cihang Xie, Alan Yuille, and Tao Kong.
\newblock ibot: Image bert pre-training with online tokenizer.
\newblock {\em International Conference on Learning Representations (ICLR)}, 2022.

\bibitem{baevski2022data2vec}
Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, and Michael Auli.
\newblock data2vec: A general framework for self-supervised learning in speech, vision and language.
\newblock {\em arXiv preprint arXiv:2202.03555}, 2022.

\bibitem{loshchilov2019adamw}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock In {\em Proceedings of International Conference on Learning Representations (ICLR)}, 2019.

\bibitem{loshchilov2017sgdr}
Ilya Loshchilov and Frank Hutter.
\newblock {SGDR}: Stochastic gradient descent with warm restarts.
\newblock In {\em Proceedings of International Conference on Learning Representations (ICLR)}, 2017.

\bibitem{ponttuset2017davis}
Jordi Pont-Tuset, Federico Perazzi, Sergi Caelles, Pablo Arbeláez, Alex Sorkine-Hornung, and Luc~Van Gool.
\newblock The 2017 davis challenge on video object segmentation.
\newblock {\em arXiv preprint arXiv:1704.00675}, 2017.

\end{thebibliography}
