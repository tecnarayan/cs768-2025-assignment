\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andrews et~al.(2002)Andrews, Tsochantaridis, and
  Hofmann]{andrews2002support}
Andrews, S., Tsochantaridis, I., and Hofmann, T.
\newblock Support vector machines for multiple-instance learning.
\newblock In \emph{NeurIPS}, pp.\  577--584, 2002.

\bibitem[Bao et~al.(2018{\natexlab{a}})Bao, Niu, and
  Sugiyama]{bao2017classification}
Bao, H., Niu, G., and Sugiyama, M.
\newblock Classification from pairwise similarity and unlabeled data.
\newblock In \emph{ICML}, pp.\  452--461, 2018{\natexlab{a}}.

\bibitem[Bao et~al.(2018{\natexlab{b}})Bao, Sakai, Sato, and
  Sugiyama]{bao2018convex}
Bao, H., Sakai, T., Sato, I., and Sugiyama, M.
\newblock Convex formulation of multiple instance learning from positive and
  unlabeled bags.
\newblock \emph{Neural Networks}, 105:\penalty0 132--141, 2018{\natexlab{b}}.

\bibitem[Bao et~al.(2022)Bao, Shimada, Xu, Sato, and Sugiyama]{bao2022pairwise}
Bao, H., Shimada, T., Xu, L., Sato, I., and Sugiyama, M.
\newblock Pairwise supervision can provably elicit a decision boundary.
\newblock In \emph{AISTATS}, 2022.

\bibitem[Basu et~al.(2004)Basu, Bilenko, and Mooney]{basu2004probabilistic}
Basu, S., Bilenko, M., and Mooney, R.~J.
\newblock A probabilistic framework for semi-supervised clustering.
\newblock In \emph{KDD}, pp.\  59--68, 2004.

\bibitem[Bilenko et~al.(2004)Bilenko, Basu, and Mooney]{bilenko2004integrating}
Bilenko, M., Basu, S., and Mooney, R.~J.
\newblock Integrating constraints and metric learning in semi-supervised
  clustering.
\newblock In \emph{ICML}, pp.\ ~11, 2004.

\bibitem[Bock(2007)]{bock2007clustering}
Bock, H.-H.
\newblock Clustering methods: a history of k-means algorithms.
\newblock \emph{Selected Contributions in Data Analysis and Classification},
  pp.\  161--172, 2007.

\bibitem[Cao et~al.(2021)Cao, Feng, Xu, An, Niu, and Sugiyama]{cao2021learning}
Cao, Y., Feng, L., Xu, Y., An, B., Niu, G., and Sugiyama, M.
\newblock Learning from similarity-confidence data.
\newblock In \emph{ICML}, pp.\  1272--1282, 2021.

\bibitem[Carbonneau et~al.(2018)Carbonneau, Cheplygina, Granger, and
  Gagnon]{carbonneau2018multiple}
Carbonneau, M.-A., Cheplygina, V., Granger, E., and Gagnon, G.
\newblock Multiple instance learning: A survey of problem characteristics and
  applications.
\newblock \emph{Pattern Recognition}, 77:\penalty0 329--353, 2018.

\bibitem[Chu \& Ghahramani(2005)Chu and Ghahramani]{chu2005preference}
Chu, W. and Ghahramani, Z.
\newblock Preference learning with gaussian processes.
\newblock In \emph{ICML}, pp.\  137--144, 2005.

\bibitem[Clanuwat et~al.(2018)Clanuwat, Bober-Irizar, Kitamoto, Lamb, Yamamoto,
  and Ha]{KMINST}
Clanuwat, T., Bober-Irizar, M., Kitamoto, A., Lamb, A., Yamamoto, K., and Ha,
  D.
\newblock Deep learning for classical japanese literature.
\newblock \emph{arXiv preprint arXiv:1812.01718}, 2018.

\bibitem[Cui et~al.(2020)Cui, Charoenphakdee, Sato, and
  Sugiyama]{cui2020classification}
Cui, Z., Charoenphakdee, N., Sato, I., and Sugiyama, M.
\newblock Classification from triplet comparison data.
\newblock \emph{Neural Computation}, 32\penalty0 (3):\penalty0 659--681, 2020.

\bibitem[Dietterich et~al.(1997)Dietterich, Lathrop, and
  Lozano-P{\'e}rez]{dietterich1997solving}
Dietterich, T.~G., Lathrop, R.~H., and Lozano-P{\'e}rez, T.
\newblock Solving the multiple instance problem with axis-parallel rectangles.
\newblock \emph{Artificial Intelligence}, 89\penalty0 (1-2):\penalty0 31--71,
  1997.

\bibitem[Dua \& Graff(2017)Dua and Graff]{Dua2019UCI}
Dua, D. and Graff, C.
\newblock {UCI} machine learning repository, 2017.
\newblock URL \url{http://archive.ics.uci.edu/ml}.

\bibitem[Dulac-Arnold et~al.(2019)Dulac-Arnold, Zeghidour, Cuturi, Beyer, and
  Vert]{ROT}
Dulac-Arnold, G., Zeghidour, N., Cuturi, M., Beyer, L., and Vert, J.-P.
\newblock Deep multi-class learning from label proportions.
\newblock \emph{arXiv preprint arXiv:1905.12909}, 2019.

\bibitem[Feng et~al.(2020)Feng, Lv, Han, Xu, Niu, Geng, An, and
  Sugiyama]{feng2020provably}
Feng, L., Lv, J., Han, B., Xu, M., Niu, G., Geng, X., An, B., and Sugiyama, M.
\newblock Provably consistent partial-label learning.
\newblock In \emph{NeurIPS}, volume~33, pp.\  10948--10960, 2020.

\bibitem[Feng et~al.(2021)Feng, Shu, Lu, Han, Xu, Niu, An, and
  Sugiyama]{feng2021pointwise}
Feng, L., Shu, S., Lu, N., Han, B., Xu, M., Niu, G., An, B., and Sugiyama, M.
\newblock Pointwise binary classification with pairwise confidence comparisons.
\newblock In \emph{ICML}, pp.\  3252--3262, 2021.

\bibitem[Flaxman et~al.(2015)Flaxman, Wang, and Smola]{flaxman2015supported}
Flaxman, S.~R., Wang, Y.-X., and Smola, A.~J.
\newblock Who supported obama in 2012? ecological inference through
  distribution regression.
\newblock In \emph{KDD}, pp.\  289--298, 2015.

\bibitem[F{\"u}rnkranz \& H{\"u}llermeier(2003)F{\"u}rnkranz and
  H{\"u}llermeier]{furnkranz2003pairwise}
F{\"u}rnkranz, J. and H{\"u}llermeier, E.
\newblock Pairwise preference learning and ranking.
\newblock In \emph{ECMLP-KDD}, pp.\  145--156, 2003.

\bibitem[G{\"a}rtner et~al.(2002)G{\"a}rtner, Flach, Kowalczyk, and
  Smola]{gartner2002multi}
G{\"a}rtner, T., Flach, P.~A., Kowalczyk, A., and Smola, A.~J.
\newblock Multi-instance kernels.
\newblock In \emph{ICML}, pp.\ ~7, 2002.

\bibitem[Hadsell et~al.(2006)Hadsell, Chopra, and LeCun]{contrastive}
Hadsell, R., Chopra, S., and LeCun, Y.
\newblock Dimensionality reduction by learning an invariant mapping.
\newblock In \emph{CVPR}, pp.\  1735--1742, 2006.

\bibitem[Hsu et~al.(2018)Hsu, Lv, Schlosser, Odom, and Kira]{hsu2019multi}
Hsu, Y.-C., Lv, Z., Schlosser, J., Odom, P., and Kira, Z.
\newblock Multi-class classification without multi-class labels.
\newblock In \emph{ICLR}, 2018.

\bibitem[Huang et~al.(2017)Huang, Liu, Van Der~Maaten, and Weinberger]{Dense}
Huang, G., Liu, Z., Van Der~Maaten, L., and Weinberger, K.~Q.
\newblock Densely connected convolutional networks.
\newblock In \emph{CVPR}, pp.\  4700--4708, 2017.

\bibitem[Ilse et~al.(2018)Ilse, Tomczak, and Welling]{ilse2018attention}
Ilse, M., Tomczak, J., and Welling, M.
\newblock Attention-based deep multiple instance learning.
\newblock In \emph{ICML}, pp.\  2127--2136. PMLR, 2018.

\bibitem[Ishida et~al.(2018)Ishida, Niu, and Sugiyama]{ishida2018binary}
Ishida, T., Niu, G., and Sugiyama, M.
\newblock Binary classification from positive-confidence data.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Jordan \& Mitchell(2015)Jordan and Mitchell]{jordan2015machine}
Jordan, M.~I. and Mitchell, T.~M.
\newblock Machine learning: Trends, perspectives, and prospects.
\newblock \emph{Science}, 349\penalty0 (6245):\penalty0 255--260, 2015.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: {A} method for stochastic optimization.
\newblock In \emph{ICLR}, 2015.

\bibitem[Koch et~al.(2015)Koch, Zemel, Salakhutdinov, et~al.]{siamese}
Koch, G., Zemel, R., Salakhutdinov, R., et~al.
\newblock Siamese neural networks for one-shot image recognition.
\newblock In \emph{ICML}, 2015.

\bibitem[Kotsiantis et~al.(2006)Kotsiantis, Zaharakis, and
  Pintelas]{kotsiantis2006machine}
Kotsiantis, S.~B., Zaharakis, I.~D., and Pintelas, P.~E.
\newblock Machine learning: a review of classification and combining
  techniques.
\newblock \emph{Artificial Intelligence Review}, 26\penalty0 (3):\penalty0
  159--190, 2006.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton, et~al.]{CIFAR10}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Kuhn(1955)]{kuhn1955hungarian}
Kuhn, H.~W.
\newblock The hungarian method for the assignment problem.
\newblock \emph{Naval Research Logistics Quarterly}, 2\penalty0 (1-2):\penalty0
  83--97, 1955.

\bibitem[Kumar \& Kummamuru(2008)Kumar and Kummamuru]{kumar2008semisupervised}
Kumar, N. and Kummamuru, K.
\newblock Semisupervised clustering with metric learning using relative
  comparisons.
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering},
  20\penalty0 (4):\penalty0 496--503, 2008.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and Haffner]{MNIST}
LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Maron \& Lozano-P{\'e}rez(1997)Maron and
  Lozano-P{\'e}rez]{maron1997framework}
Maron, O. and Lozano-P{\'e}rez, T.
\newblock A framework for multiple-instance learning.
\newblock In \emph{NeurIPS}, volume~10, 1997.

\bibitem[Mojsilovic \& Ukkonen(2019)Mojsilovic and
  Ukkonen]{mojsilovic2019relative}
Mojsilovic, S. and Ukkonen, A.
\newblock Relative distance comparisons with confidence judgements.
\newblock In \emph{ICDM}, pp.\  459--467. SIAM, 2019.

\bibitem[Moon(1996)]{EM_algorithm}
Moon, T.
\newblock The expectation-maximization algorithm.
\newblock \emph{IEEE Signal Processing Magazine}, 13\penalty0 (6):\penalty0
  47--60, 1996.
\newblock \doi{10.1109/79.543975}.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and Ng]{SVHN}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock 2011.

\bibitem[Nishii(1989)]{nishii1989maximum}
Nishii, R.
\newblock Maximum likelihood principle and model selection when the true model
  is unspecified.
\newblock In \emph{Multivariate Statistics and Probability}, pp.\  392--403.
  Elsevier, 1989.

\bibitem[Quadrianto et~al.(2008)Quadrianto, Smola, Caetano, and
  Le]{quadrianto2008estimating}
Quadrianto, N., Smola, A.~J., Caetano, T.~S., and Le, Q.~V.
\newblock Estimating labels from label proportions.
\newblock In \emph{ICML}, pp.\  776--783, 2008.

\bibitem[Schroff et~al.(2015)Schroff, Kalenichenko, and Philbin]{tripletloss}
Schroff, F., Kalenichenko, D., and Philbin, J.
\newblock Facenet: A unified embedding for face recognition and clustering.
\newblock In \emph{CVPR}, June 2015.

\bibitem[Schuessler(1999)]{schuessler1999ecological}
Schuessler, A.~A.
\newblock Ecological inference.
\newblock \emph{Proceedings of the National Academy of Sciences}, 96\penalty0
  (19):\penalty0 10578--10581, 1999.

\bibitem[Schultz \& Joachims(2003)Schultz and Joachims]{schultz2003learning}
Schultz, M. and Joachims, T.
\newblock Learning a distance metric from relative comparisons.
\newblock In \emph{NeurIPS}, volume~16, 2003.

\bibitem[Scott \& Zhang(2020)Scott and Zhang]{scott2020learning}
Scott, C. and Zhang, J.
\newblock Learning from label proportions: A mutual contamination framework.
\newblock In \emph{NeurIPS}, pp.\  22256--22267, 2020.

\bibitem[Sohn(2016)]{sohn2016improved}
Sohn, K.
\newblock Improved deep metric learning with multi-class n-pair loss objective.
\newblock In \emph{NeurIPS}, volume~29, 2016.

\bibitem[Sugiyama et~al.(2022)Sugiyama, Bao, Ishida, Lu, and
  Sakai]{sugiyama2022machine}
Sugiyama, M., Bao, H., Ishida, T., Lu, N., and Sakai, T.
\newblock \emph{Machine learning from weak supervision: An empirical risk
  minimization approach}.
\newblock MIT Press, 2022.

\bibitem[Vapnik(1999)]{vapnik1999overview}
Vapnik, V.~N.
\newblock An overview of statistical learning theory.
\newblock \emph{IEEE Transactions on Neural Networks}, 10\penalty0
  (5):\penalty0 988--999, 1999.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{FASHION}
Xiao, H., Rasul, K., and Vollgraf, R.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock \emph{arXiv preprint arXiv:1708.07747}, 2017.

\bibitem[Yu et~al.(2013)Yu, Liu, Kumar, Tony, and Chang]{yu2013proptosvm}
Yu, F., Liu, D., Kumar, S., Tony, J., and Chang, S.-F.
\newblock $\backslash$proptosvm for learning with label proportions.
\newblock In \emph{ICML}, pp.\  504--512. PMLR, 2013.

\bibitem[Yu et~al.(2014)Yu, Choromanski, Kumar, Jebara, and Chang]{yu2014llp}
Yu, F.~X., Choromanski, K., Kumar, S., Jebara, T., and Chang, S.-F.
\newblock On learning from label proportions.
\newblock \emph{arXiv preprint arXiv:1402.5902}, 2014.

\bibitem[Zhang \& Goldman(2001)Zhang and Goldman]{zhang2001dd}
Zhang, Q. and Goldman, S.
\newblock Em-dd: An improved multiple-instance learning technique.
\newblock In \emph{NeurIPS}, volume~14, 2001.

\bibitem[Zhang et~al.(2020)Zhang, Charoenphakdee, Wu, and
  Sugiyama]{zhang2020learning}
Zhang, Y., Charoenphakdee, N., Wu, Z., and Sugiyama, M.
\newblock Learning from aggregate observations.
\newblock In \emph{NeurIPS}, volume~33, pp.\  7993--8005, 2020.

\bibitem[Zhou(2018)]{zhou2018brief}
Zhou, Z.-H.
\newblock A brief introduction to weakly supervised learning.
\newblock \emph{National Science Review}, 5\penalty0 (1):\penalty0 44--53,
  2018.

\end{thebibliography}
