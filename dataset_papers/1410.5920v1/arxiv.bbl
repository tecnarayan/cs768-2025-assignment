\begin{thebibliography}{22}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Balcan et~al.(2009)Balcan, Beygelzimer, and Langford]{BalcanBeLa09}
M.~F. Balcan, A.~Beygelzimer, and J.~Langford.
\newblock Agnostic active learning.
\newblock \emph{Journal of Computer and System Sciences}, 75\penalty0
  (1):\penalty0 78--89, 2009.

\bibitem[Burbidge et~al.(2007)Burbidge, Rowland, and King]{BurbidgeRoKi07}
R.~Burbidge, J.~J. Rowland, and R.~D. King.
\newblock Active learning for regression based on query by committee.
\newblock In \emph{Intelligent Data Engineering and Automated Learning-IDEAL
  2007}, pages 209--218. Springer, 2007.

\bibitem[Cai et~al.(2013)Cai, Zhang, and Zhou]{CaiZhZh13}
W.~Cai, Y.~Zhang, and J.~Zhou.
\newblock Maximizing expected model change for active learning in regression.
\newblock In \emph{Data Mining (ICDM), 2013 IEEE 13th International Conference
  on}, pages 51--60. IEEE, 2013.

\bibitem[Carpentier and Munos(2012)]{CarpentierMu12}
A.~Carpentier and R.~Munos.
\newblock Minimax number of strata for online stratified sampling given noisy
  samples.
\newblock In N.~H. Bshouty, G.~Stoltz, N.~Vayatis, and T.~Zeugmann, editors,
  \emph{Algorithmic Learning Theory}, volume 7568 of \emph{Lecture Notes in
  Computer Science}, pages 229--244. Springer Berlin Heidelberg, 2012.

\bibitem[Casella and Strawderman(1981)]{CasellaSt81}
G.~Casella and W.~E. Strawderman.
\newblock Estimating a bounded normal mean.
\newblock \emph{The Annals of Statistics}, 9\penalty0 (4):\penalty0 870--878,
  1981.

\bibitem[Cohn et~al.(1994)Cohn, Atlas, and Ladner]{CohnAtLa94}
D.~Cohn, L.~Atlas, and R.~Ladner.
\newblock Improving generalization with active learning.
\newblock \emph{Machine Learning}, 15:\penalty0 201--221, 1994.

\bibitem[Cohn et~al.(1996)Cohn, Ghahramani, and Jordan]{CohnGhJo96}
D.~A. Cohn, Z.~Ghahramani, and M.~I. Jordan.
\newblock Active learning with statistical models.
\newblock \emph{Journal of Artificial Intelligence Research}, 4:\penalty0
  129--145, 1996.

\bibitem[Dasgupta et~al.(2008)Dasgupta, Hsu, and Monteleoni]{DasguptaHsMo08}
S.~Dasgupta, D.~Hsu, and C.~Monteleoni.
\newblock A general agnostic active learning algorithm.
\newblock In J.~Platt, D.~Koller, Y.~Singer, and S.~Roweis, editors,
  \emph{Advances in Neural Information Processing Systems 20}, pages 353--360.
  MIT Press, 2008.

\bibitem[Efromovich(2007)]{Efromovich07}
S.~Efromovich.
\newblock Sequential design and estimation in heteroscedastic nonparametric
  regression.
\newblock \emph{Sequential Analysis}, 26\penalty0 (1):\penalty0 3--25, 2007.

\bibitem[Ganti and Gray(2012)]{Ganti12}
R.~Ganti and A.~G. Gray.
\newblock Upal: Unbiased pool based active learning.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 422--431, 2012.

\bibitem[Glasserman(2004)]{Glasserman04}
P.~Glasserman.
\newblock \emph{Monte Carlo methods in financial engineering}, volume~53.
\newblock Springer, 2004.

\bibitem[Gy{\"o}rfi et~al.(2002)Gy{\"o}rfi, Kohler, Krzyzak, and
  Walk]{Gyorfi02}
L.~Gy{\"o}rfi, M.~Kohler, A.~Krzyzak, and H.~Walk.
\newblock \emph{A distribution-free theory of nonparametric regression}.
\newblock Springer, 2002.

\bibitem[Hsu and Sabato(2014)]{HsuSabato14}
D.~Hsu and S.~Sabato.
\newblock Heavy-tailed regression with a generalized median-of-means.
\newblock In \emph{Proceedings of the 31st International Conference on Machine
  Learning}, volume~32, pages 37--45. JMLR Workshop and Conference Proceedings,
  2014.

\bibitem[Hsu et~al.(2012)Hsu, Kakade, and Zhang]{HsuKaZh12}
D.~Hsu, S.~M. Kakade, and T.~Zhang.
\newblock Random design analysis of ridge regression.
\newblock In \emph{Twenty-Fifth Conference on Learning Theory}, 2012.

\bibitem[Kanamori(2002)]{Kanamori02}
T.~Kanamori.
\newblock Statistical asymptotic theory of active learning.
\newblock \emph{Annals of the Institute of Statistical Mathematics},
  54\penalty0 (3):\penalty0 459--475, 2002.

\bibitem[Kanamori and Shimodaira(2003)]{KanamoriSh03}
T.~Kanamori and H.~Shimodaira.
\newblock Active learning algorithm using the maximum weighted log-likelihood
  estimator.
\newblock \emph{Journal of Statistical Planning and Inference}, 116\penalty0
  (1):\penalty0 149--162, 2003.

\bibitem[Needell et~al.(2013)Needell, Srebro, and Ward]{NeedellSrWa13}
D.~Needell, N.~Srebro, and R.~Ward.
\newblock Stochastic gradient descent and the randomized kaczmarz algorithm.
\newblock \emph{arXiv preprint arXiv:1310.5715}, 2013.

\bibitem[Sugiyama(2006)]{Sugiyama06}
M.~Sugiyama.
\newblock Active learning in approximately linear regression based on
  conditional expectation of generalization error.
\newblock \emph{The Journal of Machine Learning Research}, 7:\penalty0
  141--166, 2006.

\bibitem[Sugiyama and Nakajima(2009)]{Sugiyama09}
M.~Sugiyama and S.~Nakajima.
\newblock Pool-based active learning in approximate linear regression.
\newblock \emph{Machine Learning}, 75\penalty0 (3):\penalty0 249--274, 2009.

\bibitem[Von~Neumann(1951)]{vonNeumann51}
J.~Von~Neumann.
\newblock Various techniques used in connection with random digits.
\newblock \emph{Applied Math Series}, 12\penalty0 (36-38):\penalty0 1, 1951.

\bibitem[Wiens(1998)]{Wiens98}
D.~P. Wiens.
\newblock Minimax robust designs and weights for approximately specified
  regression models with heteroscedastic errors.
\newblock \emph{Journal of the American Statistical Association}, 93\penalty0
  (444):\penalty0 1440--1450, 1998.

\bibitem[Wiens(2000)]{Wiens00}
D.~P. Wiens.
\newblock Robust weights and designs for biased regression models: Least
  squares and generalized m-estimation.
\newblock \emph{Journal of Statistical Planning and Inference}, 83\penalty0
  (2):\penalty0 395--412, 2000.

\end{thebibliography}
