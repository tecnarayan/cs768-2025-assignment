\begin{thebibliography}{10}

\bibitem{disneypixarcartoonb}
Disney pixar cartoon type b - v1.0.
\newblock \url{https://civitai.com/models/75650/disney-pixar-cartoon-type-b},
  2023.

\bibitem{realisticvisionv60b1}
Realistic vision v6.0 b1.
\newblock \url{https://civitai.com/models/4201/realistic-vision-v60-b1}, 2023.

\bibitem{toonyou2023}
Toonyou - beta 6.
\newblock \url{https://civitai.com/models/30240/toonyou}, 2023.

\bibitem{ansel2024pytorch}
Jason Ansel, Edward Yang, Horace He, Natalia Gimelshein, Animesh Jain, Michael
  Voznesensky, Bin Bao, Peter Bell, David Berard, Evgeni Burovski, et~al.
\newblock Pytorch 2: Faster machine learning through dynamic python bytecode
  transformation and graph compilation.
\newblock In {\em Proceedings of the 29th ACM International Conference on
  Architectural Support for Programming Languages and Operating Systems, Volume
  2}, pages 929--947, 2024.

\bibitem{bain2021frozen}
Max Bain, Arsha Nagrani, G{\"u}l Varol, and Andrew Zisserman.
\newblock Frozen in time: A joint video and image encoder for end-to-end
  retrieval.
\newblock In {\em Int. Conf. Comput. Vis.}, pages 1728--1738, 2021.

\bibitem{balaji2019conditional}
Yogesh Balaji, Martin~Renqiang Min, Bing Bai, Rama Chellappa, and Hans~Peter
  Graf.
\newblock Conditional gan with discriminative filter generation for
  text-to-video synthesis.
\newblock In {\em IJCAI}, volume~1, page~2, 2019.

\bibitem{bao2022analytic}
Fan Bao, Chongxuan Li, Jun Zhu, and Bo~Zhang.
\newblock Analytic-dpm: an analytic estimate of the optimal reverse variance in
  diffusion probabilistic models.
\newblock {\em arXiv preprint arXiv:2201.06503}, 2022.

\bibitem{betker2023improving}
James Betker, Gabriel Goh, Li~Jing, Tim Brooks, Jianfeng Wang, Linjie Li, Long
  Ouyang, Juntang Zhuang, Joyce Lee, Yufei Guo, et~al.
\newblock Improving image generation with better captions.
\newblock {\em Computer Science. https://cdn. openai. com/papers/dall-e-3.
  pdf}, 2(3):8, 2023.

\bibitem{blattmann2023align}
Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, Seung~Wook Kim,
  Sanja Fidler, and Karsten Kreis.
\newblock Align your latents: High-resolution video synthesis with latent
  diffusion models.
\newblock In {\em IEEE Conf. Comput. Vis. Pattern Recog.}, pages 22563--22575,
  2023.

\bibitem{caron2021emerging}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv{\'e} J{\'e}gou, Julien Mairal,
  Piotr Bojanowski, and Armand Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In {\em Int. Conf. Comput. Vis.}, pages 9650--9660, 2021.

\bibitem{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock pages 1597--1607. PMLR, 2020.

\bibitem{chen2020improved}
Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He.
\newblock Improved baselines with momentum contrastive learning.
\newblock {\em arXiv preprint arXiv:2003.04297}, 2020.

\bibitem{dai2023emu}
Xiaoliang Dai, Ji~Hou, Chih-Yao Ma, Sam Tsai, Jialiang Wang, Rui Wang, Peizhao
  Zhang, Simon Vandenhende, Xiaofang Wang, Abhimanyu Dubey, et~al.
\newblock Emu: Enhancing image generation models using photogenic needles in a
  haystack.
\newblock {\em arXiv preprint arXiv:2309.15807}, 2023.

\bibitem{darcet2023vitneedreg}
Timothée Darcet, Maxime Oquab, Julien Mairal, and Piotr Bojanowski.
\newblock Vision transformers need registers, 2023.

\bibitem{fang2024structural}
Gongfan Fang, Xinyin Ma, and Xinchao Wang.
\newblock Structural pruning for diffusion models.
\newblock {\em Adv. Neural Inform. Process. Syst.}, 36, 2024.

\bibitem{ge2023preserve}
Songwei Ge, Seungjun Nah, Guilin Liu, Tyler Poon, Andrew Tao, Bryan Catanzaro,
  David Jacobs, Jia-Bin Huang, Ming-Yu Liu, and Yogesh Balaji.
\newblock Preserve your own correlation: A noise prior for video diffusion
  models.
\newblock In {\em Int. Conf. Comput. Vis.}, pages 22930--22941, 2023.

\bibitem{grill2020bootstrap}
Jean-Bastien Grill, Florian Strub, Florent Altch{\'e}, Corentin Tallec, Pierre
  Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila~Pires, Zhaohan
  Guo, Mohammad Gheshlaghi~Azar, et~al.
\newblock Bootstrap your own latent-a new approach to self-supervised learning.
\newblock {\em Adv. Neural Inform. Process. Syst.}, 33:21271--21284, 2020.

\bibitem{gulrajani2017improved}
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron~C
  Courville.
\newblock Improved training of wasserstein gans.
\newblock {\em Adv. Neural Inform. Process. Syst.}, 30, 2017.

\bibitem{guo2023animatediff}
Yuwei Guo, Ceyuan Yang, Anyi Rao, Yaohui Wang, Yu~Qiao, Dahua Lin, and Bo~Dai.
\newblock Animatediff: Animate your personalized text-to-image diffusion models
  without specific tuning.
\newblock {\em arXiv preprint arXiv:2307.04725}, 2023.

\bibitem{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock {\em Adv. Neural Inform. Process. Syst.}, 30, 2017.

\bibitem{ho2022imagen}
Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey
  Gritsenko, Diederik~P Kingma, Ben Poole, Mohammad Norouzi, David~J Fleet,
  et~al.
\newblock Imagen video: High definition video generation with diffusion models.
\newblock {\em arXiv preprint arXiv:2210.02303}, 2022.

\bibitem{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock {\em Adv. Neural Inform. Process. Syst.}, 33:6840--6851, 2020.

\bibitem{ho2022classifier}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock {\em arXiv preprint arXiv:2207.12598}, 2022.

\bibitem{ho2022video}
Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi,
  and David~J Fleet.
\newblock Video diffusion models.
\newblock {\em Adv. Neural Inform. Process. Syst.}, 35:8633--8646, 2022.

\bibitem{hu2021lora}
Edward~J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
  Wang, Lu~Wang, and Weizhu Chen.
\newblock Lora: Low-rank adaptation of large language models.
\newblock {\em arXiv preprint arXiv:2106.09685}, 2021.

\bibitem{huang2022flowformer}
Zhaoyang Huang, Xiaoyu Shi, Chao Zhang, Qiang Wang, Ka~Chun Cheung, Hongwei
  Qin, Jifeng Dai, and Hongsheng Li.
\newblock Flowformer: A transformer architecture for optical flow.
\newblock In {\em Eur. Conf. Comput. Vis.}, pages 668--685. Springer, 2022.

\bibitem{isola2017image}
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei~A Efros.
\newblock Image-to-image translation with conditional adversarial networks.
\newblock In {\em IEEE Conf. Comput. Vis. Pattern Recog.}, pages 1125--1134,
  2017.

\bibitem{karras2022elucidating}
Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine.
\newblock Elucidating the design space of diffusion-based generative models.
\newblock {\em Adv. Neural Inform. Process. Syst.}, 35:26565--26577, 2022.

\bibitem{khachatryan2023text2video}
Levon Khachatryan, Andranik Movsisyan, Vahram Tadevosyan, Roberto Henschel,
  Zhangyang Wang, Shant Navasardyan, and Humphrey Shi.
\newblock Text2video-zero: Text-to-image diffusion models are zero-shot video
  generators.
\newblock In {\em Int. Conf. Comput. Vis.}, pages 15954--15964, 2023.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{kohler2024imagine}
Jonas Kohler, Albert Pumarola, Edgar Sch{\"o}nfeld, Artsiom Sanakoyeu, Roshan
  Sumbaly, Peter Vajda, and Ali Thabet.
\newblock Imagine flash: Accelerating emu diffusion models with backward
  distillation.
\newblock {\em arXiv preprint arXiv:2405.05224}, 2024.

\bibitem{li2024snapfusion}
Yanyu Li, Huan Wang, Qing Jin, Ju~Hu, Pavlo Chemerys, Yun Fu, Yanzhi Wang,
  Sergey Tulyakov, and Jian Ren.
\newblock Snapfusion: Text-to-image diffusion model on mobile devices within
  two seconds.
\newblock {\em Adv. Neural Inform. Process. Syst.}, 36, 2024.

\bibitem{lin2024common}
Shanchuan Lin, Bingchen Liu, Jiashi Li, and Xiao Yang.
\newblock Common diffusion noise schedules and sample steps are flawed.
\newblock In {\em IEEE Winter Conf. Appl. Comput. Vis.}, pages 5404--5411,
  2024.

\bibitem{lin2024sdxl}
Shanchuan Lin, Anran Wang, and Xiao Yang.
\newblock Sdxl-lightning: Progressive adversarial diffusion distillation.
\newblock {\em arXiv preprint arXiv:2402.13929}, 2024.

\bibitem{lin2024animatediff}
Shanchuan Lin and Xiao Yang.
\newblock Animatediff-lightning: Cross-model diffusion distillation.
\newblock {\em arXiv preprint arXiv:2403.12706}, 2024.

\bibitem{liu2022pseudo}
Luping Liu, Yi~Ren, Zhijie Lin, and Zhou Zhao.
\newblock Pseudo numerical methods for diffusion models on manifolds.
\newblock {\em arXiv preprint arXiv:2202.09778}, 2022.

\bibitem{lu2022dpm}
Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu.
\newblock Dpm-solver: A fast ode solver for diffusion probabilistic model
  sampling in around 10 steps.
\newblock {\em Adv. Neural Inform. Process. Syst.}, 35:5775--5787, 2022.

\bibitem{luo2023latent}
Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and Hang Zhao.
\newblock Latent consistency models: Synthesizing high-resolution images with
  few-step inference.
\newblock {\em arXiv preprint arXiv:2310.04378}, 2023.

\bibitem{ma2023deepcache}
Xinyin Ma, Gongfan Fang, and Xinchao Wang.
\newblock Deepcache: Accelerating diffusion models for free.
\newblock {\em arXiv preprint arXiv:2312.00858}, 2023.

\bibitem{peft}
Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, Sayak Paul,
  and Benjamin Bossan.
\newblock Peft: State-of-the-art parameter-efficient fine-tuning methods.
\newblock \url{https://github.com/huggingface/peft}, 2022.

\bibitem{meng2023distillation}
Chenlin Meng, Robin Rombach, Ruiqi Gao, Diederik Kingma, Stefano Ermon,
  Jonathan Ho, and Tim Salimans.
\newblock On distillation of guided diffusion models.
\newblock In {\em IEEE Conf. Comput. Vis. Pattern Recog.}, pages 14297--14306,
  2023.

\bibitem{nichol2021improved}
Alexander~Quinn Nichol and Prafulla Dhariwal.
\newblock Improved denoising diffusion probabilistic models.
\newblock pages 8162--8171. PMLR, 2021.

\bibitem{oquab2023dinov2}
Maxime Oquab, Timothée Darcet, Theo Moutakanni, Huy~V. Vo, Marc Szafraniec,
  Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin
  El-Nouby, Russell Howes, Po-Yao Huang, Hu~Xu, Vasu Sharma, Shang-Wen Li,
  Wojciech Galuba, Mike Rabbat, Mido Assran, Nicolas Ballas, Gabriel Synnaeve,
  Ishan Misra, Herve Jegou, Julien Mairal, Patrick Labatut, Armand Joulin, and
  Piotr Bojanowski.
\newblock Dinov2: Learning robust visual features without supervision, 2023.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock pages 8748--8763. PMLR, 2021.

\bibitem{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em IEEE Conf. Comput. Vis. Pattern Recog.}, pages 10684--10695,
  2022.

\bibitem{salimans2022progressive}
Tim Salimans and Jonathan Ho.
\newblock Progressive distillation for fast sampling of diffusion models.
\newblock {\em arXiv preprint arXiv:2202.00512}, 2022.

\bibitem{sauer2023stylegan}
Axel Sauer, Tero Karras, Samuli Laine, Andreas Geiger, and Timo Aila.
\newblock Stylegan-t: Unlocking the power of gans for fast large-scale
  text-to-image synthesis.
\newblock pages 30105--30118. PMLR, 2023.

\bibitem{sauer2023adversarial}
Axel Sauer, Dominik Lorenz, Andreas Blattmann, and Robin Rombach.
\newblock Adversarial diffusion distillation.
\newblock {\em arXiv preprint arXiv:2311.17042}, 2023.

\bibitem{schuhmann2022laion}
Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross
  Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell
  Wortsman, et~al.
\newblock Laion-5b: An open large-scale dataset for training next generation
  image-text models.
\newblock {\em Adv. Neural Inform. Process. Syst.}, 35:25278--25294, 2022.

\bibitem{shi2023videoflow}
Xiaoyu Shi, Zhaoyang Huang, Weikang Bian, Dasong Li, Manyuan Zhang, Ka~Chun
  Cheung, Simon See, Hongwei Qin, Jifeng Dai, and Hongsheng Li.
\newblock Videoflow: Exploiting temporal cues for multi-frame optical flow
  estimation.
\newblock In {\em Int. Conf. Comput. Vis.}, pages 12469--12480, 2023.

\bibitem{shi2023flowformer++}
Xiaoyu Shi, Zhaoyang Huang, Dasong Li, Manyuan Zhang, Ka~Chun Cheung, Simon
  See, Hongwei Qin, Jifeng Dai, and Hongsheng Li.
\newblock Flowformer++: Masked cost volume autoencoding for pretraining optical
  flow estimation.
\newblock In {\em IEEE Conf. Comput. Vis. Pattern Recog.}, pages 1599--1610,
  2023.

\bibitem{simonyan2014two}
Karen Simonyan and Andrew Zisserman.
\newblock Two-stream convolutional networks for action recognition in videos.
\newblock {\em Adv. Neural Inform. Process. Syst.}, 27, 2014.

\bibitem{skorokhodov2022stylegan}
Ivan Skorokhodov, Sergey Tulyakov, and Mohamed Elhoseiny.
\newblock Stylegan-v: A continuous video generator with the price, image
  quality and perks of stylegan2.
\newblock In {\em IEEE Conf. Comput. Vis. Pattern Recog.}, pages 3626--3636,
  2022.

\bibitem{song2020denoising}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock {\em arXiv preprint arXiv:2010.02502}, 2020.

\bibitem{song2023consistency}
Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever.
\newblock Consistency models.
\newblock {\em arXiv preprint arXiv:2303.01469}, 2023.

\bibitem{song2020score}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano
  Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock {\em arXiv preprint arXiv:2011.13456}, 2020.

\bibitem{soomro2012ucf101}
Khurram Soomro, Amir~Roshan Zamir, and Mubarak Shah.
\newblock Ucf101: A dataset of 101 human actions classes from videos in the
  wild.
\newblock {\em arXiv preprint arXiv:1212.0402}, 2012.

\bibitem{tulyakov2018mocogan}
Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, and Jan Kautz.
\newblock Mocogan: Decomposing motion and content for video generation.
\newblock In {\em IEEE Conf. Comput. Vis. Pattern Recog.}, pages 1526--1535,
  2018.

\bibitem{unterthiner2018towards}
Thomas Unterthiner, Sjoerd Van~Steenkiste, Karol Kurach, Raphael Marinier,
  Marcin Michalski, and Sylvain Gelly.
\newblock Towards accurate generative models of video: A new metric \&
  challenges.
\newblock {\em arXiv preprint arXiv:1812.01717}, 2018.

\bibitem{von-platen-etal-2022-diffusers}
Patrick von Platen, Suraj Patil, Anton Lozhkov, Pedro Cuenca, Nathan Lambert,
  Kashif Rasul, Mishig Davaadorj, Dhruv Nair, Sayak Paul, William Berman, Yiyi
  Xu, Steven Liu, and Thomas Wolf.
\newblock Diffusers: State-of-the-art diffusion models.
\newblock \url{https://github.com/huggingface/diffusers}, 2022.

\bibitem{wang2024animatelcm}
Fu-Yun Wang, Zhaoyang Huang, Xiaoyu Shi, Weikang Bian, Guanglu Song, Yu~Liu,
  and Hongsheng Li.
\newblock Animatelcm: Accelerating the animation of personalized diffusion
  models and adapters with decoupled consistency learning.
\newblock {\em arXiv preprint arXiv:2402.00769}, 2024.

\bibitem{wang2023modelscope}
Jiuniu Wang, Hangjie Yuan, Dayou Chen, Yingya Zhang, Xiang Wang, and Shiwei
  Zhang.
\newblock Modelscope text-to-video technical report.
\newblock {\em arXiv preprint arXiv:2308.06571}, 2023.

\bibitem{wang2017untrimmednets}
Limin Wang, Yuanjun Xiong, Dahua Lin, and Luc Van~Gool.
\newblock Untrimmednets for weakly supervised action recognition and detection.
\newblock In {\em IEEE Conf. Comput. Vis. Pattern Recog.}, pages 4325--4334,
  2017.

\bibitem{wang2016temporal}
Limin Wang, Yuanjun Xiong, Zhe Wang, Yu~Qiao, Dahua Lin, Xiaoou Tang, and Luc
  Van~Gool.
\newblock Temporal segment networks: Towards good practices for deep action
  recognition.
\newblock In {\em Eur. Conf. Comput. Vis.}, pages 20--36. Springer, 2016.

\bibitem{Wang_2024_CVPR}
Tan Wang, Linjie Li, Kevin Lin, Yuanhao Zhai, Chung-Ching Lin, Zhengyuan Yang,
  Hanwang Zhang, Zicheng Liu, and Lijuan Wang.
\newblock Disco: Disentangled control for realistic human dance generation.
\newblock In {\em IEEE Conf. Comput. Vis. Pattern Recog.}, pages 9326--9336,
  2024.

\bibitem{wang2024videocomposer}
Xiang Wang, Hangjie Yuan, Shiwei Zhang, Dayou Chen, Jiuniu Wang, Yingya Zhang,
  Yujun Shen, Deli Zhao, and Jingren Zhou.
\newblock Videocomposer: Compositional video synthesis with motion
  controllability.
\newblock {\em Adv. Neural Inform. Process. Syst.}, 36, 2024.

\bibitem{wang2023videolcm}
Xiang Wang, Shiwei Zhang, Han Zhang, Yu~Liu, Yingya Zhang, Changxin Gao, and
  Nong Sang.
\newblock Videolcm: Video latent consistency model.
\newblock {\em arXiv preprint arXiv:2312.09109}, 2023.

\bibitem{wang2020g3an}
Yaohui Wang, Piotr Bilinski, Francois Bremond, and Antitza Dantcheva.
\newblock G3an: Disentangling appearance and motion for video generation.
\newblock In {\em IEEE Conf. Comput. Vis. Pattern Recog.}, pages 5264--5273,
  2020.

\bibitem{wu2023tune}
Jay~Zhangjie Wu, Yixiao Ge, Xintao Wang, Stan~Weixian Lei, Yuchao Gu, Yufei
  Shi, Wynne Hsu, Ying Shan, Xiaohu Qie, and Mike~Zheng Shou.
\newblock Tune-a-video: One-shot tuning of image diffusion models for
  text-to-video generation.
\newblock In {\em Int. Conf. Comput. Vis.}, pages 7623--7633, 2023.

\bibitem{wu2023freeinit}
Tianxing Wu, Chenyang Si, Yuming Jiang, Ziqi Huang, and Ziwei Liu.
\newblock Freeinit: Bridging initialization gap in video diffusion models.
\newblock {\em arXiv preprint arXiv:2312.07537}, 2023.

\bibitem{xu2016msr}
Jun Xu, Tao Mei, Ting Yao, and Yong Rui.
\newblock Msr-vtt: A large video description dataset for bridging video and
  language.
\newblock In {\em IEEE Conf. Comput. Vis. Pattern Recog.}, pages 5288--5296,
  2016.

\bibitem{xu2023ufogen}
Yanwu Xu, Yang Zhao, Zhisheng Xiao, and Tingbo Hou.
\newblock Ufogen: You forward once large scale text-to-image generation via
  diffusion gans.
\newblock {\em arXiv preprint arXiv:2311.09257}, 2023.

\bibitem{yuan2023instructvideo}
Hangjie Yuan, Shiwei Zhang, Xiang Wang, Yujie Wei, Tao Feng, Yining Pan, Yingya
  Zhang, Ziwei Liu, Samuel Albanie, and Dong Ni.
\newblock Instructvideo: Instructing video diffusion models with human
  feedback.
\newblock {\em arXiv preprint arXiv:2312.12490}, 2023.

\bibitem{zhai2024idol}
Yuanhao Zhai, Kevin Lin, Linjie Li, Chung-Ching Lin, Jianfeng Wang, Zhengyuan
  Yang, David Doermann, Junsong Yuan, Zicheng Liu, and Lijuan Wang.
\newblock Idol: Unified dual-modal latent diffusion for human-centric joint
  video-depth generation.
\newblock In {\em Eur. Conf. Comput. Vis.}, 2024.

\bibitem{zhang2023adding}
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock In {\em Int. Conf. Comput. Vis.}, pages 3836--3847, 2023.

\bibitem{zhang2022fast}
Qinsheng Zhang and Yongxin Chen.
\newblock Fast sampling of diffusion models with exponential integrator.
\newblock {\em arXiv preprint arXiv:2204.13902}, 2022.

\bibitem{zhao2018recognize}
Yue Zhao, Yuanjun Xiong, and Dahua Lin.
\newblock Recognize actions by disentangling components of dynamics.
\newblock In {\em IEEE Conf. Comput. Vis. Pattern Recog.}, pages 6566--6575,
  2018.

\bibitem{zhu2017unpaired}
Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei~A Efros.
\newblock Unpaired image-to-image translation using cycle-consistent
  adversarial networks.
\newblock In {\em Int. Conf. Comput. Vis.}, pages 2223--2232, 2017.

\end{thebibliography}
