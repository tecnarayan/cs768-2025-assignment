@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems},
year = {2019},
}

@article{luo2018towards,
  title={Towards understanding regularization in batch normalization},
  author={Luo, Ping and Wang, Xinjiang and Shao, Wenqi and Peng, Zhanglin},
  journal={International Conference on Learning Representations},
  year={2019}
}


@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  year={2017},
}


@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  year={2017}
}


@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  year={2016}
}


@article{srivastava2015training,
  title={Training very deep networks},
  author={Srivastava, Rupesh Kumar and Greff, Klaus and Schmidhuber, J{\"u}rgen},
  journal={Advances in Neural Information Processing Systems},
  year={2015}
}


@article{garriga2018deep,
  title={Deep convolutional networks as shallow gaussian processes},
  author={Garriga-Alonso, Adria and Rasmussen, Carl Edward and Aitchison, Laurence},
  journal={International Conference on Learning Representations},
  year={2019}
}


@inproceedings{rahimi2007random,
  title={Random Features for Large-Scale Kernel Machines.},
  author={Rahimi, Ali and Recht, Benjamin and others},
  booktitle={Advances in Neural Information Processing Systems},
  year={2007},
}


@ARTICLE{moore94ojaflow, 
author={Wei-Yong Yan and U. Helmke and J. B. Moore}, 
journal={IEEE Transactions on Neural Networks}, 
title={Global analysis of Oja's flow for neural networks}, 
year={1994}
}

@inproceedings{jain2016streaming,
  title={Streaming PCA: Matching matrix Bernstein and near-optimal finite sample guarantees for Oja’s algorithm},
  author={Jain, Prateek and Jin, Chi and Kakade, Sham M and Netrapalli, Praneeth and Sidford, Aaron},
  booktitle={Conference on Learning Theory},
  year={2016}
}

@book{villani2009optimal,
  title={Optimal transport: old and new},
  author={Villani, C{\'e}dric},
  year={2009},
  publisher={Springer}
}

@inproceedings{garber2016faster,
  title={Faster Eigenvector Computation via Shift-and-Invert Preconditioning.},
  author={Garber, Dan and Hazan, Elad and Jin, Chi and Kakade, Sham M and Musco, Cameron and Netrapalli, Praneeth and Sidford, Aaron},
  booktitle={ICML},
  year={2016}
}

@article{golub1973some,
  title={Some modified matrix eigenvalue problems},
  author={Golub, Gene H},
  journal={Siam Review},
  year={1973},
 }

@article{cheng2014bounds,
  title={The bounds of the eigenvalues for rank-one modification of Hermitian matrix},
  author={Cheng, Guanghui and Song, Zhida and Yang, Jianfeng and Si, Jia},
  journal={Numerical Linear Algebra with Applications},
  year={2014},
  publisher={Wiley Online Library}
}

@article{bunch1978rank,
  title={Rank-one modification of the symmetric eigenproblem},
  author={Bunch, James R and Nielsen, Christopher P and Sorensen, Danny C},
  journal={Numerische Mathematik},
  year={1978},
  publisher={Springer}
}

@inproceedings{jain2018accelerating,
  title={Accelerating Stochastic Gradient Descent for Least Squares Regression},
  author={Jain, Prateek and Kakade, Sham M and Kidambi, Rahul and Netrapalli, Praneeth and Sidford, Aaron},
  booktitle={Conference On Learning Theory},
  year={2018}
}

@article{stewart1990matrix,
  title={Matrix perturbation theory},
  author={Stewart, Gilbert W},
  year={1990},
  publisher={Citeseer}
}

@article{davis1970rotation,
  title={The rotation of eigenvectors by a perturbation. III},
  author={Davis, Chandler and Kahan, William Morton},
  journal={SIAM Journal on Numerical Analysis},
  year={1970},
  publisher={SIAM}
}


@book{bougerol2012products,
  title={Products of random matrices with applications to Schr{\"o}dinger operators},
  author={Bougerol, Philippe and others},
  year={2012},
  publisher={Springer Science \& Business Media}
}
@book{durrett2010probability,
  title={Probability: theory and examples},
  author={Durrett, Rick},
  year={2010},
  publisher={Cambridge university press}
}

%%%% tensor decompositon references 
@article{anandkumar2014tensor,
  title={Tensor decompositions for learning latent variable models},
  author={Anandkumar, Animashree and Ge, Rong and Hsu, Daniel and Kakade, Sham M and Telgarsky, Matus},
  journal={The Journal of Machine Learning Research},
  year={2014},

}
@ARTICLE{Hyvarinen97fastica, 
author={A. {Hyvärinen} and E. {Oja}}, 
journal={Neural Computation}, 
title={A Fast Fixed-Point Algorithm for Independent Component Analysis}, 
year={1997}, 
}
@inproceedings{ge2015escaping,
  title={Escaping from saddle points—online stochastic gradient for tensor decomposition},
  author={Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
  booktitle={Conference on Learning Theory},
  year={2015}
}
@inproceedings{jain2018accelerating,
  title={Accelerating stochastic gradient descent for least squares regression},
  author={Jain, Prateek and Kakade, Sham M and Kidambi, Rahul and Netrapalli, Praneeth and Sidford, Aaron},
  booktitle={Conference On Learning Theory},
  year={2018}
}


%%%%%%%%%%%%%%%% Tensor decomposition reviewing  %%%%%
@article{haastad1990tensor,
  title={Tensor rank is NP-complete},
  author={H{\aa}stad, Johan},
  journal={Journal of Algorithms},
  year={1990},
  publisher={Elsevier}
}



@article{hillar2013most,
  title={Most tensor problems are NP-hard},
  author={Hillar, Christopher J and Lim, Lek-Heng},
  journal={Journal of the ACM (JACM)},
  year={2013},
  publisher={ACM}
}

@article{leurgans1993decomposition,
  title={A decomposition for three-way arrays},
  author={Leurgans, SE and Ross, RT and Abel, RB},
  journal={SIAM Journal on Matrix Analysis and Applications},
  year={1993},
  publisher={SIAM}
}


@inproceedings{frieze1996learning,
  title={Learning linear transformations},
  author={Frieze, Alan and Jerrum, Mark and Kannan, Ravi},
  booktitle={Proceedings of 37th Conference on Foundations of Computer Science},
  year={1996},
  organization={IEEE}
}
@article{hyvarinen1999fast,
  title={Fast and robust fixed-point algorithms for independent component analysis},
  author={Hyvarinen, Aapo},
  journal={IEEE transactions on Neural Networks},
  year={1999},
  publisher={IEEE}
}

@inproceedings{bhaskara2014smoothed,
  title={Smoothed analysis of tensor decompositions},
  author={Bhaskara, Aditya and Charikar, Moses and Moitra, Ankur and Vijayaraghavan, Aravindan},
  booktitle={Proceedings of the forty-sixth annual ACM symposium on Theory of computing},
  year={2014},
}
@inproceedings{simchowitz2018tight,
  title={Tight query complexity lower bounds for PCA via finite sample deformed wigner law},
  author={Simchowitz, Max and El Alaoui, Ahmed and Recht, Benjamin},
  booktitle={Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing},
  year={2018},
  organization={ACM}
}


@inproceedings{fang2018spider,
  title={Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator},
  author={Fang, Cong and Li, Chris Junchi and Lin, Zhouchen and Zhang, Tong},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018}
}

@article{hyvarinen1996simple,
  title={Simple neuron models for independent component analysis},
  author={Hyv{\"a}rinen, Aapo and Oja, Erkki},
  journal={International Journal of Neural Systems},
  year={1996},
  publisher={World Scientific}
}

@book{kushner2003stochastic,
  title={Stochastic approximation and recursive algorithms and applications},
  author={Kushner, Harold and Yin, G George},
  year={2003},
  publisher={Springer Science \& Business Media}
}
@incollection{moulines2011,
title = {Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Machine Learning},
author = {Moulines, Eric and Francis R. Bach},
booktitle = {Advances in Neural Information Processing Systems 24},
editor = {J. Shawe-Taylor and R. S. Zemel and P. L. Bartlett and F. Pereira and K. Q. Weinberger},
year = {2011},
publisher = {Curran Associates, Inc.},
}
@inproceedings{wang2016online,
  title={Online and differentially-private tensor decomposition},
  author={Wang, Yining and Anandkumar, Anima},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@article{tichavsky2006performance,
  title={Performance analysis of the FastICA algorithm and Crame/spl acute/r-rao bounds for linear independent component analysis},
  author={Tichavsky, Petr and Koldovsky, Zbynek and Oja, Erkki},
  journal={IEEE transactions on Signal Processing},
  volume={54},
  number={4},
  pages={1189--1203},
  year={2006},
  publisher={IEEE}
}
@article{oja2006fastica,
  title={The FastICA algorithm revisited: Convergence analysis},
  author={Oja, Erkki and Yuan, Zhijian},
  journal={IEEE Transactions on Neural Networks},
  volume={17},
  number={6},
  pages={1370--1381},
  year={2006},
  publisher={IEEE}
}

@article{de2001independent,
  title={Independent component analysis and (simultaneous) third-order tensor diagonalization},
  author={De Lathauwer, Lieven and De Moor, Bart and Vandewalle, Joos},
  journal={IEEE Transactions on Signal Processing},
  volume={49},
  number={10},
  pages={2262--2271},
  year={2001},
  publisher={IEEE}
}
@article{harshman1970foundations,
  title={Foundations of the PARAFAC procedure: Models and conditions for an" explanatory" multimodal factor analysis},
  author={Harshman, Richard A and others},
  year={1970},
  publisher={University of California at Los Angeles Los Angeles, CA}
}
@article{koldovsky2006efficient,
  title={Efficient variant of algorithm FastICA for independent component analysis attaining the Cram{\'e}r-Rao lower bound},
  author={Koldovsky, Zbynek and Tichavsky, Petr and Oja, Erkki},
  journal={IEEE Transactions on neural networks},
  volume={17},
  number={5},
  pages={1265--1277},
  year={2006},
  publisher={IEEE}
}
@inproceedings{malouche1996extended,
  title={Extended anti-Hebbian adaptation for unsupervised source extraction},
  author={Malouche, Zied and Macchi, Odile},
  booktitle={1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings},
  volume={3},
  pages={1664--1667},
  year={1996},
  organization={IEEE}
}

@inproceedings{cardoso1989source,
  title={Source separation using higher order moments},
  author={Cardoso, J-F},
  booktitle={International Conference on Acoustics, Speech, and Signal Processing,},
  pages={2109--2112},
  year={1989},
  organization={IEEE}
}
@inproceedings{souloumiac1991comparaisons,
  title = {Comparisons of Source Separation Methods},
  author = {Souloumiac, Anthony and Cardoso, Jean-Francois},
  booktitle = {13th Symposium on Signal and Image Processing, FRA, 1991},
  year = {1991},
  organization = {GRETSI, Study Group on Signal and Image Processing}
}
@inproceedings{cardoso1993efficient,
  title={An efficient technique for the blind separation of complex sources},
  author={Cardoso, Jean-Francois and Souloumiac, Antoine},
  booktitle={[1993 Proceedings] IEEE Signal Processing Workshop on Higher-Order Statistics},
  pages={275--279},
  year={1993},
  organization={IEEE}
}
@article{delfosse1995adaptive,
  title={Adaptive blind separation of independent sources: a deflation approach},
  author={Delfosse, Nathalie and Loubaton, Philippe},
  journal={Signal processing},
  volume={45},
  number={1},
  pages={59--83},
  year={1995},
  publisher={Elsevier}
}

@book{hyvarinen2004independent,
  title={Independent component analysis},
  author={Hyv{\"a}rinen, Aapo and Karhunen, Juha and Oja, Erkki},
  volume={46},
  year={2004},
  publisher={John Wiley \& Sons}
}

@article{laurent2000,
author = "Laurent, B. and Massart, P.",
doi = "10.1214/aos/1015957395",
fjournal = "The Annals of Statistics",
journal = "Ann. Statist.",
month = "10",
number = "5",
pages = "1302--1338",
publisher = "The Institute of Mathematical Statistics",
title = "Adaptive estimation of a quadratic functional by model 			 selection",
url = "https://doi.org/10.1214/aos/1015957395",
volume = "28",
year = "2000"
}

@article{renyi1953theory,
  title={On the theory of order statistics},
  author={R{\'e}nyi, Alfr{\'e}d},
  journal={Acta Mathematica Hungarica},
  volume={4},
  number={3-4},
  pages={191--231},
  year={1953},
  publisher={Akad{\'e}miai Kiad{\'o}, co-published with Springer Science+ Business Media BV~…}
}
@article{sukhatme1937tests,
  title={TESTS OF SIGNIFICANCE FOR SAMPLES OF THE x2-POPULATION WITH TWO DEGREES OF FREEDOM},
  author={Sukhatme, Pandurang V},
  journal={Annals of Eugenics},
  volume={8},
  number={1},
  pages={52--56},
  year={1937},
  publisher={Wiley Online Library}
}
@book{arnold1992first,
  title={A first course in order statistics},
  author={Arnold, Barry C and Balakrishnan, Narayanaswamy and Nagaraja, Haikady Navada},
  volume={54},
  year={1992},
  publisher={Siam}
}


@inproceedings{huang2015deterministic,
  title={Deterministic independent component analysis},
  author={Huang, Ruitong and Gyorgy, Andras and Szepesv{\'a}ri, Csaba},
  booktitle={International Conference on Machine Learning},
  pages={2521--2530},
  year={2015}
}

@inproceedings{vempala2015max,
  title={Max vs min: Tensor decomposition and ICA with nearly linear sample complexity},
  author={Vempala, Santosh S and Xiao, Ying},
  booktitle={Conference on Learning Theory},
  pages={1710--1723},
  year={2015}
}
@inproceedings{hsu2013learning,
  title={Learning mixtures of spherical gaussians: moment methods and spectral decompositions},
  author={Hsu, Daniel and Kakade, Sham M},
  booktitle={Proceedings of the 4th conference on Innovations in Theoretical Computer Science},
  pages={11--20},
  year={2013},
  organization={ACM}
}

@inproceedings{hopkins2016fast,
  title={Fast spectral algorithms from sum-of-squares proofs: tensor decomposition and planted sparse vectors},
  author={Hopkins, Samuel B and Schramm, Tselil and Shi, Jonathan and Steurer, David},
  booktitle={Proceedings of the forty-eighth annual ACM symposium on Theory of Computing},
  pages={178--191},
  year={2016},
  organization={ACM}
}
@inproceedings{montanari2014statistical,
  title={A statistical model for tensor PCA},
  author={Richard, Emile and Montanari, Andrea},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2897--2905},
  year={2014}
}
@article{auffinger2013random,
  title={Random matrices and complexity of spin glasses},
  author={Auffinger, Antonio and Arous, G{\'e}rard Ben and {\v{C}}ern{\`y}, Ji{\v{r}}{\'\i}},
  journal={Communications on Pure and Applied Mathematics},
  volume={66},
  number={2},
  pages={165--201},
  year={2013},
  publisher={Wiley Online Library}
}
@inproceedings{ge2017optimization,
  title={On the optimization landscape of tensor decompositions},
  author={Ge, Rong and Ma, Tengyu},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3653--3663},
  year={2017}
}


@article{durmus2017nonasymptotic,
  title={Nonasymptotic convergence analysis for the unadjusted Langevin algorithm},
  author={Durmus, Alain and Moulines, Eric and others},
  journal={The Annals of Applied Probability},
  volume={27},
  number={3},
  pages={1551--1587},
  year={2017},
  publisher={Institute of Mathematical Statistics}
}
@misc{eberle2015markov,
  title={Markov processes},
  author={Eberle, Andreas},
  year={2015},
  publisher={March}
}

@article{sawa1972finite,
  title={Finite-sample properties of the k-class estimators},
  author={Sawa, Takamitsu},
  journal={Econometrica: Journal of the Econometric Society},
  pages={653--680},
  year={1972},
  publisher={JSTOR}
}
@article{gurland1953distribution,
  title={Distribution of quadratic forms and ratios of quadratic forms},
  author={Gurland, John},
  journal={The Annals of Mathematical Statistics},
  pages={416--427},
  year={1953},
  publisher={JSTOR}
}
@article{van1992density,
  title={Density of the quotient of non-negative quadratic forms in normal variables with application to the F-statistic},
  author={Van der Genugten, BB},
  journal={Statistics and Computing},
  year={1992},
  publisher={Springer}
}
@article{mourtada2019exact,
  title={Exact minimax risk for linear least squares, and the lower tail of sample covariance matrices},
  author={Mourtada, Jaouad},
  journal={arXiv preprint arXiv:1912.10754},
  year={2019}
}
@article{lugannani1984distribution,
  title={Distribution of the ratio of quadratic forms in normal variables—Numerical methods},
  author={Lugannani, R and Rice, SO},
  journal={SIAM journal on scientific and statistical computing},
  volume={5},
  number={2},
  pages={476--488},
  year={1984},
  publisher={SIAM}
}

@book{cauchy1825memorie,
  title={Memorie sur les integrales definies, prises entre des limites imaginaires},
  author={Cauchy, Augustin-Louis},
  year={1825},
  publisher={De Bure fr{\`e}res}
}

@inproceedings{yang2018a,
title={A Mean Field Theory of Batch Normalization},
author={Greg Yang and Jeffrey Pennington and Vinay Rao and Jascha Sohl-Dickstein and Samuel S. Schoenholz},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=SyMDXnCcF7},
}
@article{hazan2015steps,
  title={Steps toward deep kernel methods from infinite neural networks},
  author={Hazan, Tamir and Jaakkola, Tommi},
  journal={arXiv preprint arXiv:1508.05133},
  year={2015}
}


@article{lee2017deep,
  title={Deep neural networks as gaussian processes},
  author={Lee, Jaehoon and Bahri, Yasaman and Novak, Roman and Schoenholz, Samuel S and Pennington, Jeffrey and Sohl-Dickstein, Jascha},
  journal={International Conference on Learning Representations},
  year={2019}
}

@article{matthews2018gaussian,
  title={Gaussian process behaviour in wide deep neural networks},
  author={Matthews, Alexander G de G and Rowland, Mark and Hron, Jiri and Turner, Richard E and Ghahramani, Zoubin},
  journal={arXiv preprint arXiv:1804.11271},
  year={2018}
}
@article{pennington2017nonlinear,
  title={Nonlinear random matrix theory for deep learning},
  author={Pennington, Jeffrey and Worah, Pratik},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{de2018random,
  title={Random deep neural networks are biased towards simple functions},
  author={De Palma, Giacomo and Kiani, Bobak Toussi and Lloyd, Seth},
  journal={Advances in Neural Information Processing Systems},
  year={2019}
}
@article{hanin2019products,
  title={Products of many large random matrices and gradients in deep neural networks},
  author={Hanin, Boris and Nica, Mihai},
  journal={Communications in Mathematical Physics},
  pages={1--36},
  year={2019},
  publisher={Springer}
}
@article{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  journal={Advances in Neural Information Processing Systems},
  year={2018}
}
@article{mei2019generalization,
  title={The generalization error of random features regression: Precise asymptotics and double descent curve},
  author={Mei, Song and Montanari, Andrea},
  journal={arXiv preprint arXiv:1908.05355},
  year={2019}
}
@inproceedings{pennington2018emergence,
  title={The emergence of spectral universality in deep networks},
  author={Pennington, Jeffrey and Schoenholz, Samuel and Ganguli, Surya},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2018},
 }
@book{neal2012bayesian,
  title={Bayesian learning for neural networks},
  author={Neal, Radford M},
  year={1996},
  publisher={Springer Science \& Business Media}
}

@article{daneshmand2020batch,
  title={Batch Normalization Provably Avoids Rank Collapse for Randomly Initialised Deep Networks},
  author={Daneshmand, Hadi and Kohler, Jonas and Bach, Francis and Hofmann, Thomas and Lucchi, Aurelien},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={ICML},
  year={2015},
}

@article{saxe2013exact,
  title={Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
  author={Saxe, Andrew M and McClelland, James L and Ganguli, Surya},
  journal={International Conference on Learning Representations},
  year={2014}
}
@article{bietti2019inductive,
  title={On the inductive bias of neural tangent kernels},
  author={Bietti, Alberto and Mairal, Julien},
  journal={Advances in Neural Information Processing Systems},
  year={2019}
}

@article{bartlett2019gradient,
  title={Gradient descent with identity initialization efficiently learns positive-definite linear transformations by deep residual networks},
  author={Bartlett, Peter L. and Helmbold, David P. and Long, Philip M.},
  journal={Neural computation},
  year={2019},
  publisher={MIT Press}
}

@article{arora2018convergence,
  title={A convergence analysis of gradient descent for deep linear neural networks},
  author={Arora, Sanjeev and Cohen, Nadav and Golowich, Noah and Hu, Wei},
  journal={International Conference on Learning Representations},
  year={2019}
}


@inproceedings{huang2014kernel,
  title={Kernel methods match deep neural networks on timit},
  author={Huang, Po-Sen and Avron, Haim and Sainath, Tara N and Sindhwani, Vikas and Ramabhadran, Bhuvana},
  booktitle={ICASSP},
  year={2014},
}
@article{klambauer2017self,
  title={Self-normalizing neural networks},
  author={Klambauer, G{\"u}nter and Unterthiner, Thomas and Mayr, Andreas and Hochreiter, Sepp},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{daniely2016toward,
  title={Toward deeper understanding of neural networks: The power of initialization and a dual view on expressivity},
  author={Daniely, Amit and Frostig, Roy and Singer, Yoram},
  journal={Advances in Neural Information Processing Systems},
  year={2016}
}
@article{williams1998computation,
  title={Computation with infinite neural networks},
  author={Williams, Christopher KI},
  journal={Neural Computation},
  year={1998},
  publisher={MIT Press}
}
@article{ramachandran2017searching,
  title={Searching for activation functions},
  author={Ramachandran, Prajit and Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.05941},
  year={2017}
}
@article{rasmussen2010gaussian,
  title={Gaussian processes for machine learning (GPML) toolbox},
  author={Rasmussen, Carl Edward and Nickisch, Hannes},
  journal={The Journal of Machine Learning Research},
  year={2010}
}

@article{bjorck2018understanding,
  title={Understanding batch normalization},
  author={Bjorck, Johan and Gomes, Carla and Selman, Bart and Weinberger, Kilian Q},
  journal={Advances in Neural Information Processing Systems},
  year={2018}
}
@article{schoenholz2016deep,
  title={Deep information propagation},
  author={Schoenholz, Samuel S and Gilmer, Justin and Ganguli, Surya and Sohl-Dickstein, Jascha},
  journal={International Conference on Learning Representations},
  year={2017}
}
@article{frankle2020training,
  title={Training batchnorm and only batchnorm: On the expressive power of random features in CNNs},
  author={Frankle, Jonathan and Schwab, David J and Morcos, Ari S},
  journal={arXiv preprint arXiv:2003.00152},
  year={2020}
}
@inproceedings{balduzzi2017shattered,
  title={The shattered gradients problem: If resnets are the answer, then what is the question?},
  author={Balduzzi, David and Frean, Marcus and Leary, Lennox and Lewis, JP and Ma, Kurt Wan-Duo and McWilliams, Brian},
  booktitle={ICML},
  year={2017},
 }

@book{khasminskii2011stochastic,
  title={Stochastic stability of differential equations},
  author={Khasminskii, Rafail},
  volume={66},
  year={2011},
  publisher={Springer Science \& Business Media}
}

@techreport{kushner1967stochastic,
  title={Stochastic stability and control},
  author={Kushner, Harold J},
  publisher={Elsevier Academic Press},
  year={1967}
}

@article{chen2018neural,
  title={Neural ordinary differential equations},
  author={Chen, Ricky TQ and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
  journal={Advances in Neural Information Processing Systems},
  year={2018}
}

@article{panaretos2019statistical,
  title={Statistical aspects of Wasserstein distances},
  author={Panaretos, Victor M and Zemel, Yoav},
  journal={Annual review of statistics and its application},
  year={2019},
  publisher={Annual Reviews}
}

@book{kemeny1976markov,
  title={Markov chains},
  author={Kemeny, John G and Snell, J Laurie},
  year={1976},
  publisher={Springer-Verlag, New York}
}

@misc{johnson2014nlopt,
  title={The NLopt nonlinear-optimization package},
  author={Johnson, Steven G},
  year={2014}
}
@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2010},
 }
@article{eberle2009markov,
  title={Markov processes},
  author={Eberle, Andreas},
  journal={Lecture Notes at University of Bonn},
  year={2009}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The Journal of Machine Learning Research},
  year={2014}
  }


@inproceedings{paszke2019pytorch,
  title={PyTorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}


@article{arora2018theoretical,
  title={Theoretical analysis of auto rate-tuning by batch normalization},
  author={Arora, Sanjeev and Li, Zhiyuan and Lyu, Kaifeng},
  journal={International Conference on Learning Representations},
  year={2019}
}


@article{yang2019mean,
  title={A mean field theory of batch normalization},
  author={Yang, Greg and Pennington, Jeffrey and Rao, Vinay and Sohl-Dickstein, Jascha and Schoenholz, Samuel S.},
  journal={International Conference on Learning Representations},
  year={2019}
}

@article{santurkar2018does,
  title={How Does Batch Normalization Help Optimization?(No, It Is Not About Internal Covariate Shift)},
  author={Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
  journal={Advances in Neural Information Processing Systems},
  year={2018}
}

@article{kohler2018exponential,
  title={Exponential convergence rates for Batch Normalization: The power of length-direction decoupling in non-convex optimization},
  author={Kohler, Jonas and Daneshmand, Hadi and Lucchi, Aurelien and Zhou, Ming and Neymeyr, Klaus and Hofmann, Thomas},
  journal={arXiv preprint arXiv:1805.10694},
  year={2018}
}

@inproceedings{karakida2019normalization,
  title={The normalization method for alleviating pathological sharpness in wide neural networks},
  author={Karakida, Ryo and Akaho, Shotaro and Amari, Shun-ichi},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}
@article{yao2019pyhessian,
  title={Py{H}essian: Neural Networks Through the Lens of the {H}essian},
  author={Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael},
  journal={arXiv preprint arXiv:1912.07145},
  year={2019}
}

@article{bahri2020statistical,
  title={Statistical mechanics of deep learning},
  author={Bahri, Yasaman and Kadmon, Jonathan and Pennington, Jeffrey and Schoenholz, Sam S and Sohl-Dickstein, Jascha and Ganguli, Surya},
  journal={Annual Review of Condensed Matter Physics},
  year={2020},
  publisher={Annual Reviews}
}

@InProceedings{express17, title = {On the Expressive Power of Deep Neural Networks}, author = {Maithra Raghu and Ben Poole and Jon Kleinberg and Surya Ganguli and Jascha Sohl-Dickstein}, booktitle = {ICML}, year = {2017}  }

@article{louart2018random,
  title={A random matrix approach to neural networks},
  author={Louart, Cosme and Liao, Zhenyu and Couillet, Romain and others},
  journal={The Annals of Applied Probability},
  year={2018},
  publisher={Institute of Mathematical Statistics}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Technical Report TR-2009, University of Toronto, Toronto.}
}