\begin{thebibliography}{62}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ackley and Littman(1991)]{ackley1991}
D.~Ackley and M.~Littman.
\newblock Interactions between learning and evolution.
\newblock \emph{Artificial life II}, 10:\penalty0 487--509, 1991.

\bibitem[Ahn and Ramakrishna(2003)]{ahn2003}
C.~W. Ahn and R.~S. Ramakrishna.
\newblock Elitism-based compact genetic algorithms.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 7\penalty0
  (4):\penalty0 367--385, 2003.

\bibitem[Andrychowicz et~al.(2017)Andrychowicz, Wolski, Ray, Schneider, Fong,
  Welinder, McGrew, Tobin, Abbeel, and Zaremba]{andrychowicz2017}
M.~Andrychowicz, F.~Wolski, A.~Ray, J.~Schneider, R.~Fong, P.~Welinder,
  B.~McGrew, J.~Tobin, O.~P. Abbeel, and W.~Zaremba.
\newblock Hindsight experience replay.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5048--5058, 2017.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016}
J.~L. Ba, J.~R. Kiros, and G.~E. Hinton.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Bellemare et~al.(2016)Bellemare, Srinivasan, Ostrovski, Schaul,
  Saxton, and Munos]{bellemare2016}
M.~Bellemare, S.~Srinivasan, G.~Ostrovski, T.~Schaul, D.~Saxton, and R.~Munos.
\newblock Unifying count-based exploration and intrinsic motivation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1471--1479, 2016.

\bibitem[Bhatnagar et~al.(2009)Bhatnagar, Precup, Silver, Sutton, Maei, and
  Szepesv{\'a}ri]{bhatnagar2009}
S.~Bhatnagar, D.~Precup, D.~Silver, R.~S. Sutton, H.~R. Maei, and
  C.~Szepesv{\'a}ri.
\newblock Convergent temporal-difference learning with arbitrary smooth
  function approximation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1204--1212, 2009.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Zaremba]{brockman2016}
G.~Brockman, V.~Cheung, L.~Pettersson, J.~Schneider, J.~Schulman, J.~Tang, and
  W.~Zaremba.
\newblock Openai gym.
\newblock \emph{arXiv preprint arXiv:1606.01540}, 2016.

\bibitem[Clevert et~al.(2015)Clevert, Unterthiner, and Hochreiter]{clevert2015}
D.-A. Clevert, T.~Unterthiner, and S.~Hochreiter.
\newblock Fast and accurate deep network learning by exponential linear units
  (elus).
\newblock \emph{arXiv preprint arXiv:1511.07289}, 2015.

\bibitem[Colas et~al.(2018)Colas, Sigaud, and Oudeyer]{colas2018}
C.~Colas, O.~Sigaud, and P.-Y. Oudeyer.
\newblock Gep-pg: Decoupling exploration and exploitation in deep reinforcement
  learning algorithms.
\newblock \emph{arXiv preprint arXiv:1802.05054}, 2018.

\bibitem[Conti et~al.(2017)Conti, Madhavan, Such, Lehman, Stanley, and
  Clune]{conti2017}
E.~Conti, V.~Madhavan, F.~P. Such, J.~Lehman, K.~O. Stanley, and J.~Clune.
\newblock Improving exploration in evolution strategies for deep reinforcement
  learning via a population of novelty-seeking agents.
\newblock \emph{arXiv preprint arXiv:1712.06560}, 2017.

\bibitem[Cully et~al.(2015)Cully, Clune, Tarapore, and Mouret]{cully2015}
A.~Cully, J.~Clune, D.~Tarapore, and J.-B. Mouret.
\newblock Robots that can adapt like animals.
\newblock \emph{Nature}, 521\penalty0 (7553):\penalty0 503, 2015.

\bibitem[De~Asis et~al.(2017)De~Asis, Hernandez-Garcia, Holland, and
  Sutton]{de2017}
K.~De~Asis, J.~F. Hernandez-Garcia, G.~Z. Holland, and R.~S. Sutton.
\newblock Multi-step reinforcement learning: A unifying algorithm.
\newblock \emph{arXiv preprint arXiv:1703.01327}, 2017.

\bibitem[Dhariwal et~al.(2017)Dhariwal, Hesse, Klimov, Nichol, Plappert,
  Radford, Schulman, Sidor, and Wu]{baselines}
P.~Dhariwal, C.~Hesse, O.~Klimov, A.~Nichol, M.~Plappert, A.~Radford,
  J.~Schulman, S.~Sidor, and Y.~Wu.
\newblock Openai baselines.
\newblock \url{https://github.com/openai/baselines}, 2017.

\bibitem[Drugan(2018)]{drugan2018}
M.~M. Drugan.
\newblock Reinforcement learning versus evolutionary computation: A survey on
  hybrid algorithms.
\newblock \emph{Swarm and Evolutionary Computation}, 2018.

\bibitem[Duan et~al.(2016)Duan, Chen, Houthooft, Schulman, and
  Abbeel]{duan2016}
Y.~Duan, X.~Chen, R.~Houthooft, J.~Schulman, and P.~Abbeel.
\newblock Benchmarking deep reinforcement learning for continuous control.
\newblock In \emph{International Conference on Machine Learning}, pages
  1329--1338, 2016.

\bibitem[Espeholt et~al.(2018)Espeholt, Soyer, Munos, Simonyan, Mnih, Ward,
  Doron, Firoiu, Harley, Dunning, et~al.]{espeholt2018}
L.~Espeholt, H.~Soyer, R.~Munos, K.~Simonyan, V.~Mnih, T.~Ward, Y.~Doron,
  V.~Firoiu, T.~Harley, I.~Dunning, et~al.
\newblock Impala: Scalable distributed deep-rl with importance weighted
  actor-learner architectures.
\newblock \emph{arXiv preprint arXiv:1802.01561}, 2018.

\bibitem[Eysenbach et~al.(2018)Eysenbach, Gupta, Ibarz, and
  Levine]{eysenbach2018}
B.~Eysenbach, A.~Gupta, J.~Ibarz, and S.~Levine.
\newblock Diversity is all you need: Learning skills without a reward function.
\newblock \emph{arXiv preprint arXiv:1802.06070}, 2018.

\bibitem[Fernando et~al.(2016)Fernando, Banarse, Reynolds, Besse, Pfau,
  Jaderberg, Lanctot, and Wierstra]{fernando2016}
C.~Fernando, D.~Banarse, M.~Reynolds, F.~Besse, D.~Pfau, M.~Jaderberg,
  M.~Lanctot, and D.~Wierstra.
\newblock Convolution by evolution: Differentiable pattern producing networks.
\newblock In \emph{Proceedings of the Genetic and Evolutionary Computation
  Conference 2016}, pages 109--116. ACM, 2016.

\bibitem[Fernando et~al.(2017)Fernando, Banarse, Blundell, Zwols, Ha, Rusu,
  Pritzel, and Wierstra]{fernando2017}
C.~Fernando, D.~Banarse, C.~Blundell, Y.~Zwols, D.~Ha, A.~A. Rusu, A.~Pritzel,
  and D.~Wierstra.
\newblock Pathnet: Evolution channels gradient descent in super neural
  networks.
\newblock \emph{arXiv preprint arXiv:1701.08734}, 2017.

\bibitem[Floreano et~al.(2008)Floreano, D{\"u}rr, and Mattiussi]{floreano2008}
D.~Floreano, P.~D{\"u}rr, and C.~Mattiussi.
\newblock Neuroevolution: from architectures to learning.
\newblock \emph{Evolutionary Intelligence}, 1\penalty0 (1):\penalty0 47--62,
  2008.

\bibitem[Fogel(2006)]{fogel2006}
D.~B. Fogel.
\newblock \emph{Evolutionary computation: toward a new philosophy of machine
  intelligence}, volume~1.
\newblock John Wiley \& Sons, 2006.

\bibitem[Fortunato et~al.(2017)Fortunato, Azar, Piot, Menick, Osband, Graves,
  Mnih, Munos, Hassabis, Pietquin, et~al.]{fortunato2017}
M.~Fortunato, M.~G. Azar, B.~Piot, J.~Menick, I.~Osband, A.~Graves, V.~Mnih,
  R.~Munos, D.~Hassabis, O.~Pietquin, et~al.
\newblock Noisy networks for exploration.
\newblock \emph{arXiv preprint arXiv:1706.10295}, 2017.

\bibitem[Fujimoto et~al.(2018)Fujimoto, van Hoof, and Meger]{fujimoto2018}
S.~Fujimoto, H.~van Hoof, and D.~Meger.
\newblock Addressing function approximation error in actor-critic methods.
\newblock \emph{arXiv preprint arXiv:1802.09477}, 2018.

\bibitem[Gangwani and Peng(2017)]{gangwani2017}
T.~Gangwani and J.~Peng.
\newblock Genetic policy optimization.
\newblock \emph{arXiv preprint arXiv:1711.01012}, 2017.

\bibitem[Gu et~al.(2017)Gu, Lillicrap, Turner, Ghahramani, Sch{\"o}lkopf, and
  Levine]{gu2017}
S.~Gu, T.~Lillicrap, R.~E. Turner, Z.~Ghahramani, B.~Sch{\"o}lkopf, and
  S.~Levine.
\newblock Interpolated policy gradient: Merging on-policy and off-policy
  gradient estimation for deep reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3849--3858, 2017.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Abbeel, and Levine]{haarnoja2018}
T.~Haarnoja, A.~Zhou, P.~Abbeel, and S.~Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock \emph{arXiv preprint arXiv:1801.01290}, 2018.

\bibitem[Henderson et~al.(2017)Henderson, Islam, Bachman, Pineau, Precup, and
  Meger]{henderson2017}
P.~Henderson, R.~Islam, P.~Bachman, J.~Pineau, D.~Precup, and D.~Meger.
\newblock Deep reinforcement learning that matters.
\newblock \emph{arXiv preprint arXiv:1709.06560}, 2017.

\bibitem[Houthooft et~al.(2016)Houthooft, Chen, Duan, Schulman, De~Turck, and
  Abbeel]{houthooft2016}
R.~Houthooft, X.~Chen, Y.~Duan, J.~Schulman, F.~De~Turck, and P.~Abbeel.
\newblock Vime: Variational information maximizing exploration.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1109--1117, 2016.

\bibitem[Islam et~al.(2017)Islam, Henderson, Gomrokchi, and Precup]{islam2017}
R.~Islam, P.~Henderson, M.~Gomrokchi, and D.~Precup.
\newblock Reproducibility of benchmarked deep reinforcement learning tasks for
  continuous control.
\newblock \emph{arXiv preprint arXiv:1708.04133}, 2017.

\bibitem[Jaderberg et~al.(2017)Jaderberg, Dalibard, Osindero, Czarnecki,
  Donahue, Razavi, Vinyals, Green, Dunning, Simonyan, et~al.]{jaderberg2017}
M.~Jaderberg, V.~Dalibard, S.~Osindero, W.~M. Czarnecki, J.~Donahue, A.~Razavi,
  O.~Vinyals, T.~Green, I.~Dunning, K.~Simonyan, et~al.
\newblock Population based training of neural networks.
\newblock \emph{arXiv preprint arXiv:1711.09846}, 2017.

\bibitem[Kingma and Ba(2014)]{kingma2014}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Lehman and Stanley(2008)]{lehman2008}
J.~Lehman and K.~O. Stanley.
\newblock Exploiting open-endedness to solve problems through the search for
  novelty.
\newblock In \emph{ALIFE}, pages 329--336, 2008.

\bibitem[Lillicrap et~al.(2015)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{lillicrap2015}
T.~P. Lillicrap, J.~J. Hunt, A.~Pritzel, N.~Heess, T.~Erez, Y.~Tassa,
  D.~Silver, and D.~Wierstra.
\newblock Continuous control with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1509.02971}, 2015.

\bibitem[Liu et~al.(2017)Liu, Simonyan, Vinyals, Fernando, and
  Kavukcuoglu]{liu2017}
H.~Liu, K.~Simonyan, O.~Vinyals, C.~Fernando, and K.~Kavukcuoglu.
\newblock Hierarchical representations for efficient architecture search.
\newblock \emph{arXiv preprint arXiv:1711.00436}, 2017.

\bibitem[L{\"u}ders et~al.(2017)L{\"u}ders, Schl{\"a}ger, Korach, and
  Risi]{luders2017}
B.~L{\"u}ders, M.~Schl{\"a}ger, A.~Korach, and S.~Risi.
\newblock Continual and one-shot learning through neural networks with dynamic
  external memory.
\newblock In \emph{European Conference on the Applications of Evolutionary
  Computation}, pages 886--901. Springer, 2017.

\bibitem[Mahmood et~al.(2017)Mahmood, Yu, and Sutton]{mahmood2017}
A.~R. Mahmood, H.~Yu, and R.~S. Sutton.
\newblock Multi-step off-policy learning without importance sampling ratios.
\newblock \emph{arXiv preprint arXiv:1702.03006}, 2017.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~A. Rusu, J.~Veness, M.~G. Bellemare,
  A.~Graves, M.~Riedmiller, A.~K. Fidjeland, G.~Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529, 2015.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley,
  Silver, and Kavukcuoglu]{mnih2016}
V.~Mnih, A.~P. Badia, M.~Mirza, A.~Graves, T.~Lillicrap, T.~Harley, D.~Silver,
  and K.~Kavukcuoglu.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  1928--1937, 2016.

\bibitem[Munos(2016)]{munos2016}
R.~Munos.
\newblock Q ($\lambda$) with off-policy corrections.
\newblock In \emph{Algorithmic Learning Theory: 27th International Conference,
  ALT 2016, Bari, Italy, October 19-21, 2016, Proceedings}, volume 9925, page
  305. Springer, 2016.

\bibitem[Ostrovski et~al.(2017)Ostrovski, Bellemare, Oord, and
  Munos]{ostrovski2017}
G.~Ostrovski, M.~G. Bellemare, A.~v.~d. Oord, and R.~Munos.
\newblock Count-based exploration with neural density models.
\newblock \emph{arXiv preprint arXiv:1703.01310}, 2017.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{paszke2017}
A.~Paszke, S.~Gross, S.~Chintala, G.~Chanan, E.~Yang, Z.~DeVito, Z.~Lin,
  A.~Desmaison, L.~Antiga, and A.~Lerer.
\newblock Automatic differentiation in pytorch.
\newblock 2017.

\bibitem[Pathak et~al.(2017)Pathak, Agrawal, Efros, and Darrell]{pathak2017}
D.~Pathak, P.~Agrawal, A.~A. Efros, and T.~Darrell.
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock In \emph{International Conference on Machine Learning (ICML)}, volume
  2017, 2017.

\bibitem[Plappert et~al.(2017)Plappert, Houthooft, Dhariwal, Sidor, Chen, Chen,
  Asfour, Abbeel, and Andrychowicz]{plappert2017}
M.~Plappert, R.~Houthooft, P.~Dhariwal, S.~Sidor, R.~Y. Chen, X.~Chen,
  T.~Asfour, P.~Abbeel, and M.~Andrychowicz.
\newblock Parameter space noise for exploration.
\newblock \emph{arXiv preprint arXiv:1706.01905}, 2017.

\bibitem[Pugh et~al.(2016)Pugh, Soros, and Stanley]{pugh2016}
J.~K. Pugh, L.~B. Soros, and K.~O. Stanley.
\newblock Quality diversity: A new frontier for evolutionary computation.
\newblock \emph{Frontiers in Robotics and AI}, 3:\penalty0 40, 2016.

\bibitem[Risi and Togelius(2017)]{risi2017}
S.~Risi and J.~Togelius.
\newblock Neuroevolution in games: State of the art and open challenges.
\newblock \emph{IEEE Transactions on Computational Intelligence and AI in
  Games}, 9\penalty0 (1):\penalty0 25--41, 2017.

\bibitem[Salimans et~al.(2017)Salimans, Ho, Chen, and Sutskever]{salimans2017}
T.~Salimans, J.~Ho, X.~Chen, and I.~Sutskever.
\newblock Evolution strategies as a scalable alternative to reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1703.03864}, 2017.

\bibitem[Schulman et~al.(2015{\natexlab{a}})Schulman, Levine, Abbeel, Jordan,
  and Moritz]{schulman2015b}
J.~Schulman, S.~Levine, P.~Abbeel, M.~Jordan, and P.~Moritz.
\newblock Trust region policy optimization.
\newblock In \emph{International Conference on Machine Learning}, pages
  1889--1897, 2015{\natexlab{a}}.

\bibitem[Schulman et~al.(2015{\natexlab{b}})Schulman, Moritz, Levine, Jordan,
  and Abbeel]{schulman2015a}
J.~Schulman, P.~Moritz, S.~Levine, M.~Jordan, and P.~Abbeel.
\newblock High-dimensional continuous control using generalized advantage
  estimation.
\newblock \emph{arXiv preprint arXiv:1506.02438}, 2015{\natexlab{b}}.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017}
J.~Schulman, F.~Wolski, P.~Dhariwal, A.~Radford, and O.~Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Sherstan et~al.(2018)Sherstan, Bennett, Young, Ashley, White, White,
  and Sutton]{sherstan2018}
C.~Sherstan, B.~Bennett, K.~Young, D.~R. Ashley, A.~White, M.~White, and R.~S.
  Sutton.
\newblock Directly estimating the variance of the
  $\{$$\backslash$lambda$\}$-return using temporal-difference methods.
\newblock \emph{arXiv preprint arXiv:1801.08287}, 2018.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, Van
  Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot,
  et~al.]{silver2016}
D.~Silver, A.~Huang, C.~J. Maddison, A.~Guez, L.~Sifre, G.~Van Den~Driessche,
  J.~Schrittwieser, I.~Antonoglou, V.~Panneershelvam, M.~Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock \emph{nature}, 529\penalty0 (7587):\penalty0 484--489, 2016.

\bibitem[Spears et~al.(1993)Spears, De~Jong, B{\"a}ck, Fogel, and
  De~Garis]{spears1993}
W.~M. Spears, K.~A. De~Jong, T.~B{\"a}ck, D.~B. Fogel, and H.~De~Garis.
\newblock An overview of evolutionary computation.
\newblock In \emph{European Conference on Machine Learning}, pages 442--459.
  Springer, 1993.

\bibitem[Stafylopatis and Blekas(1998)]{stafylopatis1998}
A.~Stafylopatis and K.~Blekas.
\newblock Autonomous vehicle navigation using evolutionary reinforcement
  learning.
\newblock \emph{European Journal of Operational Research}, 108\penalty0
  (2):\penalty0 306--318, 1998.

\bibitem[Stanley and Miikkulainen(2002)]{stanley2002}
K.~O. Stanley and R.~Miikkulainen.
\newblock Evolving neural networks through augmenting topologies.
\newblock \emph{Evolutionary computation}, 10\penalty0 (2):\penalty0 99--127,
  2002.

\bibitem[Such et~al.(2017)Such, Madhavan, Conti, Lehman, Stanley, and
  Clune]{such2017}
F.~P. Such, V.~Madhavan, E.~Conti, J.~Lehman, K.~O. Stanley, and J.~Clune.
\newblock Deep neuroevolution: Genetic algorithms are a competitive alternative
  for training deep neural networks for reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1712.06567}, 2017.

\bibitem[Sutton and Barto(1998)]{sutton1998}
R.~S. Sutton and A.~G. Barto.
\newblock \emph{Reinforcement learning: An introduction}, volume~1.
\newblock MIT press Cambridge, 1998.

\bibitem[Tang et~al.(2017)Tang, Houthooft, Foote, Stooke, Chen, Duan, Schulman,
  DeTurck, and Abbeel]{tang2017}
H.~Tang, R.~Houthooft, D.~Foote, A.~Stooke, O.~X. Chen, Y.~Duan, J.~Schulman,
  F.~DeTurck, and P.~Abbeel.
\newblock \# exploration: A study of count-based exploration for deep
  reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2750--2759, 2017.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{todorov2012}
E.~Todorov, T.~Erez, and Y.~Tassa.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ
  International Conference on}, pages 5026--5033. IEEE, 2012.

\bibitem[Turney et~al.(1996)Turney, Whitley, and Anderson]{turney1996}
P.~Turney, D.~Whitley, and R.~W. Anderson.
\newblock Evolution, learning, and instinct: 100 years of the baldwin effect.
\newblock \emph{Evolutionary Computation}, 4\penalty0 (3):\penalty0 iv--viii,
  1996.

\bibitem[Uhlenbeck and Ornstein(1930)]{uhlenbeck1930}
G.~E. Uhlenbeck and L.~S. Ornstein.
\newblock On the theory of the brownian motion.
\newblock \emph{Physical review}, 36\penalty0 (5):\penalty0 823, 1930.

\bibitem[Wang et~al.(2016)Wang, Bapst, Heess, Mnih, Munos, Kavukcuoglu, and
  de~Freitas]{wang2016}
Z.~Wang, V.~Bapst, N.~Heess, V.~Mnih, R.~Munos, K.~Kavukcuoglu, and
  N.~de~Freitas.
\newblock Sample efficient actor-critic with experience replay.
\newblock \emph{arXiv preprint arXiv:1611.01224}, 2016.

\bibitem[Whiteson and Stone(2006)]{whiteson2006}
S.~Whiteson and P.~Stone.
\newblock Evolutionary function approximation for reinforcement learning.
\newblock \emph{Journal of Machine Learning Research}, 7\penalty0
  (May):\penalty0 877--917, 2006.

\end{thebibliography}
