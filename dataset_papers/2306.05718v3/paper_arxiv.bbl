\begin{thebibliography}{48}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Chen et~al.(2021)Chen, Li, Zheng, Huang, Ding, and Yu]{DBGL}
Chaoqi Chen, Jiongcheng Li, Zebiao Zheng, Yue Huang, Xinghao Ding, and Yizhou
  Yu.
\newblock Dual bipartite graph learning: A general approach for domain adaptive
  object detection.
\newblock In \emph{ICCV}, pages 2703--2712, 2021.

\bibitem[Chen et~al.(2023)Chen, Li, Zhou, Han, Huang, Ding, and Yu]{FGRR}
Chaoqi Chen, Jiongcheng Li, Hong-Yu Zhou, Xiaoguang Han, Yue Huang, Xinghao
  Ding, and Yizhou Yu.
\newblock Relation matters: foreground-aware graph-based relational reasoning
  for domain adaptive object detection.
\newblock \emph{TPAMI}, 45\penalty0 (03):\penalty0 3677--3694, 2023.

\bibitem[Chen et~al.(2018)Chen, Li, Sakaridis, Dai, and Van~Gool]{DA-Faster}
Yuhua Chen, Wen Li, Christos Sakaridis, Dengxin Dai, and Luc Van~Gool.
\newblock Domain adaptive faster r-cnn for object detection in the wild.
\newblock In \emph{CVPR}, pages 3339--3348, 2018.

\bibitem[Cordts et~al.(2016)Cordts, Omran, Ramos, Rehfeld, Enzweiler, Benenson,
  Franke, Roth, and Schiele]{Cityscapes}
Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler,
  Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele.
\newblock The cityscapes dataset for semantic urban scene understanding.
\newblock In \emph{CVPR}, 2016.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{ViT}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In \emph{ICLR}, 2021.

\bibitem[Du et~al.(2022)Du, Wei, Zhang, Shi, Gao, and Li]{DetPro}
Yu~Du, Fangyun Wei, Zihe Zhang, Miaojing Shi, Yue Gao, and Guoqi Li.
\newblock Learning to prompt for open-vocabulary object detection with
  vision-language model.
\newblock In \emph{CVPR}, pages 14084--14093, 2022.

\bibitem[Everingham et~al.(2015)Everingham, Eslami, Van~Gool, Williams, Winn,
  and Zisserman]{pascal}
Mark Everingham, SM~Ali Eslami, Luc Van~Gool, Christopher~KI Williams, John
  Winn, and Andrew Zisserman.
\newblock The pascal visual object classes challenge: A retrospective.
\newblock \emph{IJCV}, 111:\penalty0 98--136, 2015.

\bibitem[Fahes et~al.(2022)Fahes, Vu, Bursuc, P{\'e}rez, and de~Charette]{poda}
Mohammad Fahes, Tuan-Hung Vu, Andrei Bursuc, Patrick P{\'e}rez, and Raoul
  de~Charette.
\newblock P $\{$$\backslash$O$\}$ da: Prompt-driven zero-shot domain
  adaptation.
\newblock \emph{arXiv preprint arXiv:2212.03241}, 2022.

\bibitem[Ganin et~al.(2016)Ganin, Ustinova, Ajakan, Germain, Larochelle,
  Laviolette, Marchand, and Lempitsky]{DANN}
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
  Larochelle, Fran{\c{c}}ois Laviolette, Mario Marchand, and Victor Lempitsky.
\newblock Domain-adversarial training of neural networks.
\newblock \emph{JMLR}, 17\penalty0 (1):\penalty0 2096--2030, 2016.

\bibitem[Geiger et~al.(2012)Geiger, Lenz, and Urtasun]{KITTI}
Andreas Geiger, Philip Lenz, and Raquel Urtasun.
\newblock Are we ready for autonomous driving? the kitti vision benchmark
  suite.
\newblock In \emph{CVPR}, 2012.

\bibitem[Gu et~al.(2022)Gu, Lin, Kuo, and Cui]{ViLD}
Xiuye Gu, Tsung-Yi Lin, Weicheng Kuo, and Yin Cui.
\newblock Open-vocabulary object detection via vision and language knowledge
  distillation.
\newblock In \emph{ICLR}, 2022.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{Resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{CVPR}, pages 770--778, 2016.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and
  Girshick]{linearprob}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross
  Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{CVPR}, pages 16000--16009, 2022.

\bibitem[Huang et~al.(2022)Huang, Guan, Xiao, Lu, and Shao]{Category-contrast}
Jiaxing Huang, Dayan Guan, Aoran Xiao, Shijian Lu, and Ling Shao.
\newblock Category contrast for unsupervised domain adaptation in visual tasks.
\newblock In \emph{CVPR}, pages 1203--1214, 2022.

\bibitem[Inoue et~al.(2018)Inoue, Furuta, Yamasaki, and Aizawa]{clipart}
Naoto Inoue, Ryosuke Furuta, Toshihiko Yamasaki, and Kiyoharu Aizawa.
\newblock Cross-domain weakly-supervised object detection through progressive
  domain adaptation.
\newblock In \emph{CVPR}, pages 5001--5009, 2018.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and
  Duerig]{ALIGN}
Chao Jia, Yinfei Yang, Ye~Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le,
  Yun-Hsuan Sung, Zhen Li, and Tom Duerig.
\newblock Scaling up visual and vision-language representation learning with
  noisy text supervision.
\newblock In \emph{ICML}, pages 4904--4916. PMLR, 2021.

\bibitem[Jiao et~al.(2022)Jiao, Yao, and Xu]{DICN}
Yifan Jiao, Hantao Yao, and Changsheng Xu.
\newblock Dual instance-consistent network for cross-domain object detection.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2022.

\bibitem[Johnson-Roberson et~al.(2017)Johnson-Roberson, Barto, Mehta, Sridhar,
  Rosaen, and Vasudevan]{SIM10K}
Matthew Johnson-Roberson, Charles Barto, Rounak Mehta, Sharath~Nittur Sridhar,
  Karl Rosaen, and Ram Vasudevan.
\newblock Driving in the matrix: Can virtual worlds replace human-generated
  annotations for real world tasks?
\newblock In \emph{ICRA 2017}, pages 746--753. IEEE, 2017.

\bibitem[Li et~al.(2020)Li, Du, Zhang, Wen, Luo, Wu, and Zhu]{SAP}
Congcong Li, Dawei Du, Libo Zhang, Longyin Wen, Tiejian Luo, Yanjun Wu, and
  Pengfei Zhu.
\newblock Spatial attention pyramid network for unsupervised domain adaptation.
\newblock In \emph{ECCV}, pages 481--497. Springer, 2020.

\bibitem[Li et~al.(2022{\natexlab{a}})Li, Zhang, Zhang, Yang, Li, Zhong, Wang,
  Yuan, Zhang, Hwang, et~al.]{GLIP}
Liunian~Harold Li, Pengchuan Zhang, Haotian Zhang, Jianwei Yang, Chunyuan Li,
  Yiwu Zhong, Lijuan Wang, Lu~Yuan, Lei Zhang, Jenq-Neng Hwang, et~al.
\newblock Grounded language-image pre-training.
\newblock In \emph{CVPR}, pages 10965--10975, 2022{\natexlab{a}}.

\bibitem[Li et~al.(2022{\natexlab{b}})Li, Liu, Yao, and Yuan]{SCAN}
Wuyang Li, Xinyu Liu, Xiwen Yao, and Yixuan Yuan.
\newblock Scan: Cross domain object detection with semantic conditioned
  adaptation.
\newblock In \emph{AAAI}, volume~6, page~7, 2022{\natexlab{b}}.

\bibitem[Li et~al.(2022{\natexlab{c}})Li, Liu, and Yuan]{SIGMA}
Wuyang Li, Xinyu Liu, and Yixuan Yuan.
\newblock Sigma: Semantic-complete graph matching for domain adaptive object
  detection.
\newblock In \emph{CVPR}, pages 5291--5300, 2022{\natexlab{c}}.

\bibitem[Li et~al.(2023)Li, Liu, and Yuan]{sigma++}
Wuyang Li, Xinyu Liu, and Yixuan Yuan.
\newblock Sigma++: Improved semantic-complete graph matching for domain
  adaptive object detection.
\newblock \emph{TPAMI}, 45\penalty0 (07):\penalty0 9022--9040, 2023.

\bibitem[Li et~al.(2022{\natexlab{d}})Li, Dai, Ma, Liu, Chen, Wu, He, Kitani,
  and Vajda]{AT}
Yu-Jhe Li, Xiaoliang Dai, Chih-Yao Ma, Yen-Cheng Liu, Kan Chen, Bichen Wu,
  Zijian He, Kris Kitani, and Peter Vajda.
\newblock Cross-domain adaptive teacher for object detection.
\newblock In \emph{CVPR}, pages 7581--7590, 2022{\natexlab{d}}.

\bibitem[Lin et~al.(2017)Lin, Doll{\'a}r, Girshick, He, Hariharan, and
  Belongie]{FPN}
Tsung-Yi Lin, Piotr Doll{\'a}r, Ross Girshick, Kaiming He, Bharath Hariharan,
  and Serge Belongie.
\newblock Feature pyramid networks for object detection.
\newblock In \emph{CVPR}, pages 2117--2125, 2017.

\bibitem[Long et~al.(2015)Long, Cao, Wang, and Jordan]{DAN}
Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan.
\newblock Learning transferable features with deep adaptation networks.
\newblock In \emph{ICML}, pages 97--105. PMLR, 2015.

\bibitem[Long et~al.(2016)Long, Zhu, Wang, and Jordan]{RTN}
Mingsheng Long, Han Zhu, Jianmin Wang, and Michael~I Jordan.
\newblock Unsupervised domain adaptation with residual transfer networks.
\newblock \emph{NeurIPS}, 29, 2016.

\bibitem[Long et~al.(2017)Long, Zhu, Wang, and Jordan]{JAN}
Mingsheng Long, Han Zhu, Jianmin Wang, and Michael~I Jordan.
\newblock Deep transfer learning with joint adaptation networks.
\newblock In \emph{ICML}, pages 2208--2217. PMLR, 2017.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{CLIP}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{ICML}, pages 8748--8763. PMLR, 2021.

\bibitem[Redmon et~al.(2016)Redmon, Divvala, Girshick, and Farhadi]{YOLO}
Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi.
\newblock You only look once: Unified, real-time object detection.
\newblock In \emph{CVPR}, pages 779--788, 2016.

\bibitem[Ren et~al.(2015)Ren, He, Girshick, and Sun]{FasterRCNN}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock \emph{NeurIPS}, 28, 2015.

\bibitem[Sakaridis et~al.(2018)Sakaridis, Dai, and Van~Gool]{FoggyCityscapes}
Christos Sakaridis, Dengxin Dai, and Luc Van~Gool.
\newblock Semantic foggy scene understanding with synthetic data.
\newblock \emph{IJCV}, 126\penalty0 (9):\penalty0 973--992, Sep 2018.

\bibitem[Shao et~al.(2018)Shao, Lan, and Yuen]{FCP}
Rui Shao, Xiangyuan Lan, and Pong~C Yuen.
\newblock Feature constrained by pixel: Hierarchical adversarial deep domain
  adaptation.
\newblock In \emph{ACMMM}, pages 220--228, 2018.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{Transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{NeurIPS}, 30, 2017.

\bibitem[Vidit et~al.(2023)Vidit, Engilberge, and Salzmann]{ClipTheGap}
Vidit Vidit, Martin Engilberge, and Mathieu Salzmann.
\newblock Clip the gap: A single domain generalization approach for object
  detection.
\newblock \emph{arXiv preprint arXiv:2301.05499}, 2023.

\bibitem[Vs et~al.(2021)Vs, Gupta, Oza, Sindagi, and Patel]{MEGA-CDA}
Vibashan Vs, Vikram Gupta, Poojan Oza, Vishwanath~A Sindagi, and Vishal~M
  Patel.
\newblock Mega-cda: Memory guided attention for category-aware unsupervised
  domain adaptive object detection.
\newblock In \emph{CVPR}, pages 4516--4526, 2021.

\bibitem[Wang et~al.(2021)Wang, Zhang, Zhang, Li, Xia, Zhang, and Liu]{DSS}
Yu~Wang, Rui Zhang, Shuo Zhang, Miao Li, Yangyang Xia, XiShan Zhang, and ShaoLi
  Liu.
\newblock Domain-specific suppression for adaptive object detection.
\newblock In \emph{CVPR}, pages 9603--9612, 2021.

\bibitem[Wu et~al.(2021)Wu, Liu, Han, Zhu, and Yang]{VD}
Aming Wu, Rui Liu, Yahong Han, Linchao Zhu, and Yi~Yang.
\newblock Vector-decomposed disentanglement for domain-invariant object
  detection.
\newblock In \emph{ICCV}, pages 9342--9351, 2021.

\bibitem[Xu et~al.(2020)Xu, Wang, Ni, Tian, and Zhang]{GPA}
Minghao Xu, Hang Wang, Bingbing Ni, Qi~Tian, and Wenjun Zhang.
\newblock Cross-domain detection via graph-induced prototype alignment.
\newblock In \emph{CVPR}, pages 12355--12364, 2020.

\bibitem[Yan et~al.(2017)Yan, Ding, Li, Wang, Xu, and Zuo]{WMMD}
Hongliang Yan, Yukang Ding, Peihua Li, Qilong Wang, Yong Xu, and Wangmeng Zuo.
\newblock Mind the class weight bias: Weighted maximum mean discrepancy for
  unsupervised domain adaptation.
\newblock In \emph{CVPR}, pages 2272--2281, 2017.

\bibitem[Yao et~al.(2023)Yao, Zhang, and Xu]{KgCoOp}
Hantao Yao, Rui Zhang, and Changsheng Xu.
\newblock Visual-language prompt tuning with knowledge-guided context
  optimization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 6757--6767, 2023.

\bibitem[Zhang et~al.(2015)Zhang, Yu, Chang, and Wang]{DTN}
Xu~Zhang, Felix~Xinnan Yu, Shih-Fu Chang, and Shengjin Wang.
\newblock Deep transfer network: Unsupervised domain adaptation.
\newblock \emph{arXiv preprint arXiv:1503.00591}, 2015.

\bibitem[Zhang et~al.(2021)Zhang, Wang, and Mao]{RPN}
Yixin Zhang, Zilei Wang, and Yushi Mao.
\newblock Rpn prototype alignment for domain adaptive object detector.
\newblock In \emph{CVPR}, pages 12425--12434, 2021.

\bibitem[Zhao and Wang(2022)]{TIA}
Liang Zhao and Limin Wang.
\newblock Task-specific inconsistency alignment for domain adaptive object
  detection.
\newblock In \emph{CVPR}, pages 14217--14226, 2022.

\bibitem[Zhong et~al.(2022)Zhong, Yang, Zhang, Li, Codella, Li, Zhou, Dai,
  Yuan, Li, et~al.]{Regionclip}
Yiwu Zhong, Jianwei Yang, Pengchuan Zhang, Chunyuan Li, Noel Codella,
  Liunian~Harold Li, Luowei Zhou, Xiyang Dai, Lu~Yuan, Yin Li, et~al.
\newblock Regionclip: Region-based language-image pretraining.
\newblock In \emph{CVPR}, pages 16793--16803, 2022.

\bibitem[Zhou et~al.(2022{\natexlab{a}})Zhou, Yang, Loy, and Liu]{CoCoOp}
Kaiyang Zhou, Jingkang Yang, Chen~Change Loy, and Ziwei Liu.
\newblock Conditional prompt learning for vision-language models.
\newblock In \emph{CVPR}, pages 16816--16825, 2022{\natexlab{a}}.

\bibitem[Zhou et~al.(2022{\natexlab{b}})Zhou, Yang, Loy, and Liu]{CoOp}
Kaiyang Zhou, Jingkang Yang, Chen~Change Loy, and Ziwei Liu.
\newblock Learning to prompt for vision-language models.
\newblock \emph{IJCV}, 130\penalty0 (9):\penalty0 2337--2348,
  2022{\natexlab{b}}.

\bibitem[Zhou et~al.(2023)Zhou, Gu, Pang, Feng, Cheng, Lu, Shi, and Ma]{SAD}
Qianyu Zhou, Qiqi Gu, Jiangmiao Pang, Zhengyang Feng, Guangliang Cheng, Xuequan
  Lu, Jianping Shi, and Lizhuang Ma.
\newblock Self-adversarial disentangling for specific domain adaptation.
\newblock \emph{TPAMI}, 45\penalty0 (7):\penalty0 8954--8968, 2023.

\end{thebibliography}
