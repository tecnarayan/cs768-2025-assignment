\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{bach2015pixel}
S.~Bach, A.~Binder, G.~Montavon, F.~Klauschen, K.-R. M{\"u}ller, and W.~Samek.
\newblock On pixel-wise explanations for non-linear classifier decisions by
  layer-wise relevance propagation.
\newblock {\em PloS one}, 10(7), 2015.

\bibitem{bagaria2018adaptive}
V.~Bagaria, G.~M. Kamath, and D.~N. Tse.
\newblock Adaptive monte-carlo optimization.
\newblock {\em arXiv preprint arXiv:1805.08321}, 2018.

\bibitem{bau2017network}
D.~Bau, B.~Zhou, A.~Khosla, A.~Oliva, and A.~Torralba.
\newblock Network dissection: Quantifying interpretability of deep visual
  representations.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 6541--6549, 2017.

\bibitem{binder2016layer}
A.~Binder, G.~Montavon, S.~Lapuschkin, K.-R. M{\"u}ller, and W.~Samek.
\newblock Layer-wise relevance propagation for neural networks with local
  renormalization layers.
\newblock In {\em International Conference on Artificial Neural Networks},
  pages 63--71. Springer, 2016.

\bibitem{buolamwini2018ppb}
J.~Buolamwini and T.~Gebru.
\newblock Gender shades: Intersectional accuracy disparities in commercial
  gender classification.
\newblock In {\em Conference on Fairness, Accountability and Transparency},
  pages 77--91, 2018.

\bibitem{castro2009polynomial}
J.~Castro, D.~G{\'o}mez, and J.~Tejada.
\newblock Polynomial calculation of the shapley value based on sampling.
\newblock {\em Computers \& Operations Research}, 36(5):1726--1730, 2009.

\bibitem{13ref}
J.~Chen, L.~Song, M.~J. Wainwright, and M.~I. Jordan.
\newblock L-shapley and c-shapley: Efficient model interpretation for
  structured data.
\newblock {\em arXiv preprint arXiv:1808.02610}, 2018.

\bibitem{datta2016shap2}
A.~Datta, S.~Sen, and Y.~Zick.
\newblock Algorithmic transparency via quantitative input influence: Theory and
  experiments with learning systems.
\newblock In {\em Security and Privacy (SP), 2016 IEEE Symposium on}, pages
  598--617. IEEE, 2016.

\bibitem{11ref}
K.~Dhamdhere, M.~Sundararajan, and Q.~Yan.
\newblock How important is a neuron?
\newblock {\em arXiv preprint arXiv:1805.12233}, 2018.

\bibitem{frankle2018lottery}
J.~Frankle and M.~Carbin.
\newblock The lottery ticket hypothesis: Finding sparse, trainable neural
  networks.
\newblock {\em arXiv preprint arXiv:1803.03635}, 2018.

\bibitem{ghorbani2019interpretation}
A.~Ghorbani, A.~Abid, and J.~Zou.
\newblock Interpretation of neural networks is fragile.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 3681--3688, 2019.

\bibitem{ghorbani2019towards}
A.~Ghorbani, J.~Wexler, J.~Y. Zou, and B.~Kim.
\newblock Towards automatic concept-based explanations.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  9273--9282, 2019.

\bibitem{ghorbani2019data}
A.~Ghorbani and J.~Zou.
\newblock Data shapley: Equitable valuation of data for machine learning.
\newblock In {\em International Conference on Machine Learning}, pages
  2242--2251, 2019.

\bibitem{goodfellow2014explaining}
I.~J. Goodfellow, J.~Shlens, and C.~Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em arXiv preprint arXiv:1412.6572}, 2014.

\bibitem{hammer1992approximations}
P.~L. Hammer and R.~Holzman.
\newblock Approximations of pseudo-boolean functions; applications to game
  theory.
\newblock {\em Zeitschrift f{\"u}r Operations Research}, 36(1):3--21, 1992.

\bibitem{iandola2016squeezenet}
F.~N. Iandola, S.~Han, M.~W. Moskewicz, K.~Ashraf, W.~J. Dally, and K.~Keutzer.
\newblock Squeezenet: Alexnet-level accuracy with 50x fewer parameters and< 0.5
  mb model size.
\newblock {\em arXiv preprint arXiv:1602.07360}, 2016.

\bibitem{jamieson2016non}
K.~Jamieson and A.~Talwalkar.
\newblock Non-stochastic best arm identification and hyperparameter
  optimization.
\newblock In {\em Artificial Intelligence and Statistics}, pages 240--248,
  2016.

\bibitem{14ref}
R.~Jia, D.~Dao, B.~Wang, F.~A. Hubis, N.~Hynes, N.~M. Gurel, B.~Li, C.~Zhang,
  D.~Song, and C.~Spanos.
\newblock Towards efficient data valuation based on the shapley value.
\newblock {\em arXiv preprint arXiv:1902.10275}, 2019.

\bibitem{kim2017interpretability}
B.~Kim, M.~Wattenberg, J.~Gilmer, C.~Cai, J.~Wexler, F.~Viegas, and R.~Sayres.
\newblock Interpretability beyond feature attribution: Quantitative testing
  with concept activation vectors (tcav).
\newblock {\em arXiv preprint arXiv:1711.11279}, 2017.

\bibitem{kim2019multiaccuracy}
M.~P. Kim, A.~Ghorbani, and J.~Zou.
\newblock Multiaccuracy: Black-box post-processing for fairness in
  classification.
\newblock In {\em Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics,
  and Society}, pages 247--254, 2019.

\bibitem{1ref}
I.~Kononenko et~al.
\newblock An efficient explanation of individual classifications using game
  theory.
\newblock {\em Journal of Machine Learning Research}, 11(Jan):1--18, 2010.

\bibitem{adversarial}
A.~Kurakin, I.~Goodfellow, and S.~Bengio.
\newblock Adversarial machine learning at scale.
\newblock {\em arXiv preprint arXiv:1611.01236}, 2016.

\bibitem{12ref}
K.~Leino, S.~Sen, A.~Datta, M.~Fredrikson, and L.~Li.
\newblock Influence-directed explanations for deep convolutional networks.
\newblock In {\em 2018 IEEE International Test Conference (ITC)}, pages 1--8.
  IEEE, 2018.

\bibitem{li2017hyperband}
L.~Li, K.~Jamieson, G.~DeSalvo, A.~Rostamizadeh, and A.~Talwalkar.
\newblock Hyperband: A novel bandit-based approach to hyperparameter
  optimization.
\newblock {\em The Journal of Machine Learning Research}, 18(1):6765--6816,
  2017.

\bibitem{liu2018large}
Z.~Liu, P.~Luo, X.~Wang, and X.~Tang.
\newblock Large-scale celebfaces attributes (celeba) dataset.
\newblock {\em Retrieved August}, 15:2018, 2018.

\bibitem{3ref}
S.~M. Lundberg, G.~Erion, H.~Chen, A.~DeGrave, J.~M. Prutkin, B.~Nair, R.~Katz,
  J.~Himmelfarb, N.~Bansal, and S.-I. Lee.
\newblock From local explanations to global understanding with explainable ai
  for trees.
\newblock {\em Nature machine intelligence}, 2(1):2522--5839, 2020.

\bibitem{2ref}
S.~M. Lundberg and S.-I. Lee.
\newblock A unified approach to interpreting model predictions.
\newblock In {\em Advances in neural information processing systems}, pages
  4765--4774, 2017.

\bibitem{madry2017towards}
A.~Madry, A.~Makelov, L.~Schmidt, D.~Tsipras, and A.~Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock {\em arXiv preprint arXiv:1706.06083}, 2017.

\bibitem{maleki2013bounding}
S.~Maleki, L.~Tran-Thanh, G.~Hines, T.~Rahwan, and A.~Rogers.
\newblock Bounding the estimation error of sampling-based shapley value
  approximation.
\newblock {\em arXiv preprint arXiv:1306.4265}, 2013.

\bibitem{mann196large}
I.~Mann and L.~S. Shapley.
\newblock Values of large games. 6: Evaluating the electoral college exactly.
\newblock Technical report, RAND CORP SANTA MONICA CA, 1962.

\bibitem{5ref}
M.~Mase, A.~B. Owen, and B.~Seiler.
\newblock Explaining black box decisions by shapley cohort refinement.
\newblock {\em arXiv preprint arXiv:1911.00467}, 2019.

\bibitem{bernstein2}
A.~Maurer and M.~Pontil.
\newblock Empirical bernstein bounds and sample variance penalization.
\newblock {\em arXiv preprint arXiv:0907.3740}, 2009.

\bibitem{bernstein1}
V.~Mnih, C.~Szepesv{\'a}ri, and J.-Y. Audibert.
\newblock Empirical bernstein stopping.
\newblock In {\em Proceedings of the 25th international conference on Machine
  learning}, pages 672--679, 2008.

\bibitem{montavon2017explaining}
G.~Montavon, S.~Lapuschkin, A.~Binder, W.~Samek, and K.-R. M{\"u}ller.
\newblock Explaining nonlinear classification decisions with deep taylor
  decomposition.
\newblock {\em Pattern Recognition}, 65:211--222, 2017.

\bibitem{olah2017feature}
C.~Olah, A.~Mordvintsev, and L.~Schubert.
\newblock Feature visualization.
\newblock {\em Distill}, 2017.
\newblock https://distill.pub/2017/feature-visualization.

\bibitem{russakovsky2015imagenet}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang,
  A.~Karpathy, A.~Khosla, M.~Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock {\em International Journal of Computer Vision}, 115(3):211--252,
  2015.

\bibitem{shapley1953value}
L.~S. Shapley.
\newblock A value for n-person games.
\newblock {\em Contributions to the Theory of Games}, 2(28):307--317, 1953.

\bibitem{shapley1988shapley}
L.~S. Shapley, A.~E. Roth, et~al.
\newblock {\em The Shapley value: essays in honor of Lloyd S. Shapley}.
\newblock Cambridge University Press, 1988.

\bibitem{shrikumar2017learning}
A.~Shrikumar, P.~Greenside, and A.~Kundaje.
\newblock Learning important features through propagating activation
  differences.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 3145--3153. JMLR. org, 2017.

\bibitem{simonyan2014very}
K.~Simonyan and A.~Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{stier2018analysing}
J.~Stier, G.~Gianini, M.~Granitzer, and K.~Ziegler.
\newblock Analysing neural network topologies: a game theoretic approach.
\newblock {\em Procedia Computer Science}, 126:234--243, 2018.

\bibitem{9ref}
M.~Sundararajan, A.~Taly, and Q.~Yan.
\newblock Axiomatic attribution for deep networks.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 3319--3328. JMLR. org, 2017.

\bibitem{szegedy2017inception_resnet}
C.~Szegedy, S.~Ioffe, V.~Vanhoucke, and A.~A. Alemi.
\newblock Inception-v4, inception-resnet and the impact of residual connections
  on learning.
\newblock In {\em AAAI}, volume~4, page~12, 2017.

\bibitem{szegedy2016inception}
C.~Szegedy, V.~Vanhoucke, S.~Ioffe, J.~Shlens, and Z.~Wojna.
\newblock Rethinking the inception architecture for computer vision.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2818--2826, 2016.

\bibitem{tramer2017ensemble}
F.~Tram{\`e}r, A.~Kurakin, N.~Papernot, I.~Goodfellow, D.~Boneh, and
  P.~McDaniel.
\newblock Ensemble adversarial training: Attacks and defenses.
\newblock {\em arXiv preprint arXiv:1705.07204}, 2017.

\bibitem{zhang2019adaptive}
M.~J. Zhang, J.~Zou, and D.~Tse.
\newblock Adaptive monte carlo multiple testing via multi-armed bandits.
\newblock {\em arXiv preprint arXiv:1902.00197}, 2019.

\end{thebibliography}
