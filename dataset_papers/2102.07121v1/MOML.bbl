\begin{thebibliography}{61}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Beck \& Teboulle(2009)Beck and Teboulle]{bt09}
Beck, A. and Teboulle, M.
\newblock A fast iterative shrinkage-thresholding algorithm for linear inverse
  problems.
\newblock \emph{SIAM Journal on Imaging Sciences}, 2\penalty0 (1):\penalty0
  183--202, 2009.

\bibitem[Cai et~al.(2020)Cai, Gan, Wang, Zhang, and Han]{cai2019once}
Cai, H., Gan, C., Wang, T., Zhang, Z., and Han, S.
\newblock Once-for-all: Train one network and specialize it for efficient
  deployment.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Caruana(1997)]{caruana97}
Caruana, R.
\newblock Multitask learning.
\newblock \emph{Machine Learning}, 28\penalty0 (1):\penalty0 41--75, 1997.

\bibitem[Chen et~al.(2019)Chen, Ghadirzadeh, Bj{\"o}rkman, and
  Jensfelt]{chen2019meta}
Chen, X., Ghadirzadeh, A., Bj{\"o}rkman, M., and Jensfelt, P.
\newblock Meta-learning for multi-objective reinforcement learning.
\newblock In \emph{2019 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pp.\  977--983. IEEE, 2019.

\bibitem[Deb \& Sinha(2009)Deb and Sinha]{deb2009solving}
Deb, K. and Sinha, A.
\newblock Solving bilevel multi-objective optimization problems using
  evolutionary algorithms.
\newblock In \emph{International conference on evolutionary multi-criterion
  optimization}, pp.\  110--124. Springer, 2009.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pp.\  248--255. IEEE, 2009.

\bibitem[D\'{e}sid\'{e}ri(2012)]{desideri12}
D\'{e}sid\'{e}ri, J.-A.
\newblock Multiple-gradient descent algorithm ({MGDA}) for multiobjective
  optimization.
\newblock \emph{Comptes Rendus Mathematique}, 350\penalty0 (5):\penalty0
  313--318, 2012.

\bibitem[Domke(2012)]{domke2012generic}
Domke, J.
\newblock Generic methods for optimization-based modeling.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  318--326.
  PMLR, 2012.

\bibitem[Eichfelder(2020)]{eichfelder2020twenty}
Eichfelder, G.
\newblock Twenty years of continuous multiobjective optimization.
\newblock 2020.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
Finn, C., Abbeel, P., and Levine, S.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1126--1135. PMLR, 2017.

\bibitem[Franceschi et~al.(2018)Franceschi, Frasconi, Salzo, Grazzi, and
  Pontil]{franceschi2018bilevel}
Franceschi, L., Frasconi, P., Salzo, S., Grazzi, R., and Pontil, M.
\newblock Bilevel programming for hyperparameter optimization and
  meta-learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1568--1577. PMLR, 2018.

\bibitem[Giagkiozis et~al.(2015)Giagkiozis, Purshouse, and
  Fleming]{giagkiozis2015overview}
Giagkiozis, I., Purshouse, R.~C., and Fleming, P.~J.
\newblock An overview of population-based algorithms for multi-objective
  optimisation.
\newblock \emph{International Journal of Systems Science}, 46\penalty0
  (9):\penalty0 1572--1599, 2015.

\bibitem[Gretton et~al.(2012)Gretton, Sejdinovic, Strathmann, Balakrishnan,
  Pontil, Fukumizu, and Sriperumbudur]{gretton2012optimal}
Gretton, A., Sejdinovic, D., Strathmann, H., Balakrishnan, S., Pontil, M.,
  Fukumizu, K., and Sriperumbudur, B.~K.
\newblock Optimal kernel choice for large-scale two-sample tests.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1205--1213. Citeseer, 2012.

\bibitem[Guo et~al.(2020)Guo, Zhu, Zhao, Cao, Lei, and Li]{guo2020learning}
Guo, J., Zhu, X., Zhao, C., Cao, D., Lei, Z., and Li, S.~Z.
\newblock Learning meta face recognition in unseen domains.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  6163--6172, 2020.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Hilliard et~al.(2018)Hilliard, Phillips, Howland, Yankov, Corley, and
  Hodas]{hilliard2018few}
Hilliard, N., Phillips, L., Howland, S., Yankov, A., Corley, C.~D., and Hodas,
  N.~O.
\newblock Few-shot learning with metric-agnostic conditional embeddings.
\newblock \emph{arXiv preprint arXiv:1802.04376}, 2018.

\bibitem[Hospedales et~al.(2020)Hospedales, Antoniou, Micaelli, and
  Storkey]{hospedales2020meta}
Hospedales, T., Antoniou, A., Micaelli, P., and Storkey, A.
\newblock Meta-learning in neural networks: A survey.
\newblock \emph{arXiv preprint arXiv:2004.05439}, 2020.

\bibitem[Huisman et~al.(2020)Huisman, van Rijn, and Plaat]{huisman2020survey}
Huisman, M., van Rijn, J.~N., and Plaat, A.
\newblock A survey of deep meta-learning.
\newblock \emph{arXiv preprint arXiv:2010.03522}, 2020.

\bibitem[Jin \& Sendhoff(2008)Jin and Sendhoff]{jin2008pareto}
Jin, Y. and Sendhoff, B.
\newblock Pareto-based multiobjective machine learning: An overview and case
  studies.
\newblock \emph{IEEE Transactions on Systems, Man, and Cybernetics, Part C
  (Applications and Reviews)}, 38\penalty0 (3):\penalty0 397--415, 2008.

\bibitem[Johnson et~al.(2016)Johnson, Alahi, and
  Fei-Fei]{johnson2016perceptual}
Johnson, J., Alahi, A., and Fei-Fei, L.
\newblock Perceptual losses for real-time style transfer and super-resolution.
\newblock In \emph{European conference on computer vision}, pp.\  694--711.
  Springer, 2016.

\bibitem[Kendall et~al.(2018)Kendall, Gal, and Cipolla]{kgc18}
Kendall, A., Gal, Y., and Cipolla, R.
\newblock Multi-task learning using uncertainty to weigh losses for scene
  geometry and semantics.
\newblock In \emph{Proceedings of {IEEE} Conference on Computer Vision and
  Pattern Recognition}, pp.\  7482--7491, 2018.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: {A} method for stochastic optimization.
\newblock In \emph{3rd International Conference on Learning Representations,
  {ICLR}}, 2015.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Kuhn \& Tucker(2014)Kuhn and Tucker]{kuhn2014nonlinear}
Kuhn, H.~W. and Tucker, A.~W.
\newblock Nonlinear programming.
\newblock In \emph{Traces and emergence of nonlinear programming}, pp.\
  247--258. Springer, 2014.

\bibitem[Kurakin et~al.(2017)Kurakin, Goodfellow, and Bengio]{pgd17}
Kurakin, A., Goodfellow, I.~J., and Bengio, S.
\newblock Adversarial examples in the physical world.
\newblock In \emph{5th International Conference on Learning Representations,
  {ICLR}}, 2017.

\bibitem[Li et~al.(2018)Li, Yang, Song, and Hospedales]{li2018learning}
Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T.
\newblock Learning to generalize: Meta-learning for domain generalization.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32, 2018.

\bibitem[Li \& Malik(2016)Li and Malik]{li2016learning}
Li, K. and Malik, J.
\newblock Learning to optimize.
\newblock \emph{arXiv preprint arXiv:1606.01885}, 2016.

\bibitem[Liu et~al.(2019{\natexlab{a}})Liu, Simonyan, and Yang]{lsy19}
Liu, H., Simonyan, K., and Yang, Y.
\newblock {DARTS:} differentiable architecture search.
\newblock In \emph{Proceedings of the 7th International Conference on Learning
  Representations}, 2019{\natexlab{a}}.

\bibitem[Liu et~al.(2019{\natexlab{b}})Liu, Johns, and Davison]{ljd19}
Liu, S., Johns, E., and Davison, A.~J.
\newblock End-to-end multi-task learning with attention.
\newblock In \emph{Proceedings of {IEEE} Conference on Computer Vision and
  Pattern Recognition}, pp.\  1871--1880, 2019{\natexlab{b}}.

\bibitem[Long et~al.(2017)Long, Zhu, Wang, and Jordan]{long2017deep}
Long, M., Zhu, H., Wang, J., and Jordan, M.~I.
\newblock Deep transfer learning with joint adaptation networks.
\newblock In \emph{International conference on machine learning}, pp.\
  2208--2217. PMLR, 2017.

\bibitem[Lu et~al.(2020)Lu, Deb, Goodman, Banzhaf, and
  Boddeti]{lu2020nsganetv2}
Lu, Z., Deb, K., Goodman, E., Banzhaf, W., and Boddeti, V.~N.
\newblock {NSGANetv2}: Evolutionary multi-objective surrogate-assisted neural
  architecture search.
\newblock In \emph{European Conference on Computer Vision}, pp.\  35--51.
  Springer, 2020.

\bibitem[Lucchetti(2006)]{lucchetti2006convexity}
Lucchetti, R.
\newblock \emph{Convexity and well-posed problems}.
\newblock Springer Science \& Business Media, 2006.

\bibitem[Lucchetti \& Miglierina(2004)Lucchetti and
  Miglierina]{lucchetti2004stability}
Lucchetti, R. and Miglierina, E.
\newblock Stability for convex vector optimization problems.
\newblock \emph{Optimization}, 53\penalty0 (5-6):\penalty0 517--528, 2004.

\bibitem[Mahapatra \& Rajan(2020)Mahapatra and Rajan]{mahapatra2020multi}
Mahapatra, D. and Rajan, V.
\newblock Multi-task learning with user preferences: Gradient descent with
  controlled ascent in pareto optimization.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  6597--6607. PMLR, 2020.

\bibitem[Nichol et~al.(2018)Nichol, Achiam, and Schulman]{nichol2018first}
Nichol, A., Achiam, J., and Schulman, J.
\newblock On first-order meta-learning algorithms.
\newblock \emph{arXiv preprint arXiv:1803.02999}, 2018.

\bibitem[Pedregosa(2016)]{pedregosa2016hyperparameter}
Pedregosa, F.
\newblock Hyperparameter optimization with approximate gradient.
\newblock In \emph{International conference on machine learning}, pp.\
  737--746. PMLR, 2016.

\bibitem[Pouyanfar et~al.(2018)Pouyanfar, Sadiq, Yan, Tian, Tao, Reyes, Shyu,
  Chen, and Iyengar]{pouyanfar2018survey}
Pouyanfar, S., Sadiq, S., Yan, Y., Tian, H., Tao, Y., Reyes, M.~P., Shyu,
  M.-L., Chen, S.-C., and Iyengar, S.
\newblock A survey on deep learning: Algorithms, techniques, and applications.
\newblock \emph{ACM Computing Surveys (CSUR)}, 51\penalty0 (5):\penalty0 1--36,
  2018.

\bibitem[Rajeswaran et~al.(2019)Rajeswaran, Finn, Kakade, and
  Levine]{rajeswaran2019meta}
Rajeswaran, A., Finn, C., Kakade, S.~M., and Levine, S.
\newblock Meta-learning with implicit gradients.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pp.\
  113--124, 2019.

\bibitem[Ravi \& Larochelle(2017)Ravi and Larochelle]{ravi2016optimization}
Ravi, S. and Larochelle, H.
\newblock Optimization as a model for few-shot learning.
\newblock In \emph{5th International Conference on Learning Representations,
  {ICLR}}, 2017.

\bibitem[Ruuska \& Miettinen(2012)Ruuska and Miettinen]{ruuska2012constructing}
Ruuska, S. and Miettinen, K.
\newblock Constructing evolutionary algorithms for bilevel multiobjective
  optimization.
\newblock In \emph{2012 IEEE Congress on Evolutionary Computation}, pp.\  1--7.
  IEEE, 2012.

\bibitem[Saenko et~al.(2010)Saenko, Kulis, Fritz, and
  Darrell]{saenko2010adapting}
Saenko, K., Kulis, B., Fritz, M., and Darrell, T.
\newblock Adapting visual category models to new domains.
\newblock In \emph{European conference on computer vision}, pp.\  213--226.
  Springer, 2010.

\bibitem[Saito et~al.(2019)Saito, Kim, Sclaroff, Darrell, and
  Saenko]{saito2019semi}
Saito, K., Kim, D., Sclaroff, S., Darrell, T., and Saenko, K.
\newblock Semi-supervised domain adaptation via minimax entropy.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  8050--8058, 2019.

\bibitem[Sener \& Koltun(2018)Sener and Koltun]{sk18}
Sener, O. and Koltun, V.
\newblock Multi-task learning as multi-objective optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 31}, pp.\
  525--536, 2018.

\bibitem[Shaban et~al.(2019)Shaban, Cheng, Hatch, and
  Boots]{shaban2019truncated}
Shaban, A., Cheng, C.-A., Hatch, N., and Boots, B.
\newblock Truncated back-propagation for bilevel optimization.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pp.\  1723--1732. PMLR, 2019.

\bibitem[Sinha(2011)]{sinha2011bilevel}
Sinha, A.
\newblock Bilevel multi-objective optimization problem solving using
  progressively interactive emo.
\newblock In \emph{International Conference on Evolutionary Multi-Criterion
  Optimization}, pp.\  269--284. Springer, 2011.

\bibitem[Snell et~al.(2017)Snell, Swersky, and Zemel]{snell2017prototypical}
Snell, J., Swersky, K., and Zemel, R.~S.
\newblock Prototypical networks for few-shot learning.
\newblock In \emph{Advances in Neural Information Processing Systems 30}, pp.\
  4077--4087, 2017.

\bibitem[Sung et~al.(2018)Sung, Yang, Zhang, Xiang, Torr, and
  Hospedales]{sung2018learning}
Sung, F., Yang, Y., Zhang, L., Xiang, T., Torr, P.~H., and Hospedales, T.~M.
\newblock Learning to compare: Relation network for few-shot learning.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  1199--1208, 2018.

\bibitem[Tan et~al.(2019)Tan, Chen, Pang, Vasudevan, Sandler, Howard, and
  Le]{tcpvshl19}
Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le,
  Q.~V.
\newblock {MnasNet}: Platform-aware neural architecture search for mobile.
\newblock In \emph{Proceedings of {IEEE} Conference on Computer Vision and
  Pattern Recognition}, pp.\  2820--2828, 2019.

\bibitem[Tanabe et~al.(2019)Tanabe, Fukuda, and Yamashita]{tanabe2019proximal}
Tanabe, H., Fukuda, E.~H., and Yamashita, N.
\newblock Proximal gradient methods for multiobjective optimization and their
  applications.
\newblock \emph{Computational Optimization and Applications}, 72\penalty0
  (2):\penalty0 339--361, 2019.

\bibitem[Tzeng et~al.(2014)Tzeng, Hoffman, Zhang, Saenko, and
  Darrell]{tzeng2014deep}
Tzeng, E., Hoffman, J., Zhang, N., Saenko, K., and Darrell, T.
\newblock Deep domain confusion: Maximizing for domain invariance.
\newblock \emph{arXiv preprint arXiv:1412.3474}, 2014.

\bibitem[Venkateswara et~al.(2017)Venkateswara, Eusebio, Chakraborty, and
  Panchanathan]{venkateswara2017deep}
Venkateswara, H., Eusebio, J., Chakraborty, S., and Panchanathan, S.
\newblock Deep hashing network for unsupervised domain adaptation.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  5018--5027, 2017.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Kavukcuoglu, and
  Wierstra]{vinyals2016matching}
Vinyals, O., Blundell, C., Lillicrap, T., Kavukcuoglu, K., and Wierstra, D.
\newblock Matching networks for one shot learning.
\newblock In \emph{Advances in Neural Information Processing Systems 29}, pp.\
  3630--3638, 2016.

\bibitem[Wah et~al.(2011)Wah, Branson, Welinder, Perona, and
  Belongie]{wah2011caltech}
Wah, C., Branson, S., Welinder, P., Perona, P., and Belongie, S.
\newblock The caltech-ucsd birds-200-2011 dataset.
\newblock 2011.

\bibitem[Wang et~al.(2020)Wang, Yao, Kwok, and Ni]{wang2020generalizing}
Wang, Y., Yao, Q., Kwok, J.~T., and Ni, L.~M.
\newblock Generalizing from a few examples: A survey on few-shot learning.
\newblock \emph{ACM Computing Surveys (CSUR)}, 53\penalty0 (3):\penalty0 1--34,
  2020.

\bibitem[Wu et~al.(2019)Wu, Dai, Zhang, Wang, Sun, Wu, Tian, Vajda, Jia, and
  Keutzer]{wu2019fbnet}
Wu, B., Dai, X., Zhang, P., Wang, Y., Sun, F., Wu, Y., Tian, Y., Vajda, P.,
  Jia, Y., and Keutzer, K.
\newblock Fbnet: Hardware-aware efficient convnet design via differentiable
  neural architecture search.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  10734--10742, 2019.

\bibitem[Xu et~al.(2018)Xu, van Hasselt, and Silver]{xu2018meta}
Xu, Z., van Hasselt, H., and Silver, D.
\newblock Meta-gradient reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems 31}, pp.\
  2402--2413, 2018.

\bibitem[Yang et~al.(2020)Yang, Zhang, Dai, and Pan]{yzdp20}
Yang, Q., Zhang, Y., Dai, W., and Pan, S.~J.
\newblock \emph{Transfer Learning}.
\newblock Cambridge University Press, 2020.

\bibitem[Yao et~al.(2015)Yao, Pan, Ngo, Li, and Mei]{yao2015semi}
Yao, T., Pan, Y., Ngo, C.-W., Li, H., and Mei, T.
\newblock Semi-supervised domain adaptation with subspace learning for visual
  recognition.
\newblock In \emph{Proceedings of the IEEE conference on Computer Vision and
  Pattern Recognition}, pp.\  2142--2150, 2015.

\bibitem[Zhang \& Yang(2017)Zhang and Yang]{zy17b}
Zhang, Y. and Yang, Q.
\newblock A survey on multi-task learning.
\newblock \emph{arXiv preprint}, arXiv:1707.08114, 2017.

\bibitem[Zhou et~al.(2011)Zhou, Qu, Li, Zhao, Suganthan, and
  Zhang]{zhou2011multiobjective}
Zhou, A., Qu, B.-Y., Li, H., Zhao, S.-Z., Suganthan, P.~N., and Zhang, Q.
\newblock Multiobjective evolutionary algorithms: A survey of the state of the
  art.
\newblock \emph{Swarm and Evolutionary Computation}, 1\penalty0 (1):\penalty0
  32--49, 2011.

\bibitem[Zhu et~al.(2020)Zhu, Zhuang, Wang, Ke, Chen, Bian, Xiong, and
  He]{zhu2020deep}
Zhu, Y., Zhuang, F., Wang, J., Ke, G., Chen, J., Bian, J., Xiong, H., and He,
  Q.
\newblock Deep subdomain adaptation network for image classification.
\newblock \emph{IEEE transactions on neural networks and learning systems},
  2020.

\end{thebibliography}
