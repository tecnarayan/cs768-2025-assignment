@article{bigot2018characterization,
  title={Characterization of barycenters in the Wasserstein space by averaging optimal transport maps},
  author={Bigot, J{\'e}r{\'e}mie and Klein, Thierry},
  journal={ESAIM: Probability and Statistics},
  volume={22},
  pages={35--57},
  year={2018},
  publisher={EDP Sciences}
}
@article{Fujimoto:2018_TD3,
  author    = {Scott Fujimoto and
               Herke van Hoof and
               David Meger},
  title     = {Addressing Function Approximation Error in Actor-Critic Methods},
  year      = {2018},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  journal = {ICML}
}



@article{Arbel:2019b,
	author = {Arbel, Michael and Gretton, Arthur and Li, Wuchen and Mont{\'u}far, Guido},
	date-added = {2021-10-25 14:22:13 +0200},
	date-modified = {2021-10-25 14:22:14 +0200},
	journal = {arXiv preprint arXiv:1910.09652},
	title = {Kernelized wasserstein natural gradient},
	year = {2019}}



@INPROCEEDINGS{filippi,
  author={S. {Filippi} and O. {Cappé} and A. {Garivier}},
  booktitle={2010 48th Annual Allerton Conference on Communication, Control, and Computing (Allerton)}, 
  title={Optimism in reinforcement learning and Kullback-Leibler divergence}, 
  year={2010},
  pages={115-122}}


@inproceedings{agarwal2017corralling,
  title={Corralling a band of bandit algorithms},
  author={Agarwal, Alekh and Luo, Haipeng and Neyshabur, Behnam and Schapire, Robert E},
  booktitle={Conference on Learning Theory},
  pages={12--38},
  year={2017},
  organization={PMLR}
}

@article{pacchiano2020regret,
  title={Regret Bound Balancing and Elimination for Model Selection in Bandits and RL},
  author={Pacchiano, Aldo and Dann, Christoph and Gentile, Claudio and Bartlett, Peter},
  journal={arXiv preprint arXiv:2012.13045},
  year={2020}
}

@article{pacchiano2020model,
  title={Model selection in contextual stochastic bandit problems},
  author={Pacchiano, Aldo and Phan, My and Abbasi-Yadkori, Yasin and Rao, Anup and Zimmert, Julian and Lattimore, Tor and Szepesvari, Csaba},
  journal={arXiv preprint arXiv:2003.01704},
  year={2020}
}

@inproceedings{ddpg,
  author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
  title={Continuous control with deep reinforcement learning.},
  year={2016},
  booktitle={ICLR},

}

@incollection{agent57,
  author    = {Adri{\`{a}} Puigdom{\`{e}}nech Badia and
               Bilal Piot and
               Steven Kapturowski and
               Pablo Sprechmann and
               Alex Vitvitskyi and
               Daniel Guo and
               Charles Blundell},
  title     = {Agent57: Outperforming the Atari Human Benchmark},
  year      = {2020},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  publisher={ICML}
}


@incollection{learnedPG,
      title={Discovering Reinforcement Learning Algorithms}, 
      author={Junhyuk Oh and Matteo Hessel and Wojciech M. Czarnecki and Zhongwen Xu and Hado van Hasselt and Satinder Singh and David Silver},
      year={2020},
      booktitle = {Advances in Neural Information Processing Systems 33},
      publisher={NeurIPS}
}


@article{PBT,
  author    = {Max Jaderberg and
               Valentin Dalibard and
               Simon Osindero and
               Wojciech M. Czarnecki and
               Jeff Donahue and
               Ali Razavi and
               Oriol Vinyals and
               Tim Green and
               Iain Dunning and
               Karen Simonyan and
               Chrisantha Fernando and
               Koray Kavukcuoglu},
  title     = {Population Based Training of Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1711.09846},
  year      = {2017},
}


@inproceedings{
evolving_algos,
title={Evolving Reinforcement Learning Algorithms},
author={John D Co-Reyes and Yingjie Miao and Daiyi Peng and Quoc V Le and Sergey Levine and Honglak Lee and Aleksandra Faust},
booktitle={International Conference on Learning Representations},
year={2021},
}

@incollection{parkerholder2020effective,
  author    = {Jack Parker{-}Holder and
               Aldo Pacchiano and
               Krzysztof Choromanski and
               Stephen Roberts},
  title     = {Effective Diversity in Population-Based Reinforcement Learning},
  year      = {2020},
  booktitle = {Advances in Neural Information Processing Systems 34},
  publisher = {NeurIPS}
}




@incollection{adaptive_mc_td,
  author    = {Hugo Penedones and
               Carlos Riquelme and
               Damien Vincent and
               Hartmut Maennel and
               Timothy A. Mann and
               Andr{\'{e}} Barreto and
               Sylvain Gelly and
               Gergely Neu},
  title     = {Adaptive Temporal-Difference Learning for Policy Evaluation with Per-State
               Uncertainty Estimates},
 booktitle = {Advances in Neural Information Processing Systems},
  year      = {2019},
  publisher = {NeurIPS}
}

@article{schaul2019adapting,
  author    = {Tom Schaul and
               Diana Borsa and
               David Ding and
               David Szepesvari and
               Georg Ostrovski and
               Will Dabney and
               Simon Osindero},
  title     = {Adapting Behaviour for Learning Progress},
  journal   = {CoRR},
  volume    = {abs/1912.06910},
  year      = {2019},
  archivePrefix = {arXiv},
}

@InProceedings{dpg, 
title = {Deterministic Policy Gradient Algorithms}, 
author = {David Silver and Guy Lever and Nicolas Heess and Thomas Degris and Daan Wierstra and Martin Riedmiller}, 
booktitle = {Proceedings of the 31st International Conference on Machine Learning}, pages = {387--395}, 
year = {2014}}

@article{narl,
      title={On Optimism in Model-Based Reinforcement Learning}, 
      author={Aldo Pacchiano and Philip Ball and Jack Parker-Holder and Krzysztof Choromanski and Stephen Roberts},
      year={2020},
      journal={CoRR}
}

@article{tossou,
  author    = {Aristide C. Y. Tossou and
               Debabrota Basu and
               Christos Dimitrakakis},
  title     = {Near-optimal Optimistic Reinforcement Learning using Empirical Bernstein
               Inequalities},
  journal   = {CoRR},
  volume    = {abs/1905.12425},
  year      = {2019}
}

@article{bartlett_1,
  author    = {Peter L. Bartlett and
               Ambuj Tewari},
  title     = {{REGAL:} {A} Regularization based Algorithm for Reinforcement Learning
               in Weakly Communicating {MDP}s},
  journal   = {CoRR},
  volume    = {abs/1205.2661},
  year      = {2012}
}

@inproceedings{yang2020reinforcement,
  title={Reinforcement learning in feature space: Matrix bandit, kernels, and regret bound},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={10746--10756},
  year={2020},
  organization={PMLR}
}

@inproceedings{jin2018,
  title={Is {Q}-Learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  booktitle={Advances in Neural Information Processing},
  editor = {S. Vishwanathan and H. Wallach and
        S. Larochelle and K. Grauman and N. Cesa-Bianchi},
  volume={31},
  publisher={Curran Associates},
  year={2018}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}

@inproceedings{osband,
  author    = {Mohammad Gheshlaghi Azar and
               Ian Osband and
               R{\'{e}}mi Munos},
  title     = {Minimax Regret Bounds for Reinforcement Learning},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning,
               {ICML}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {70},
  pages     = {263--272},
  year      = {2017},
}

@inproceedings{fruit,
  author    = {Ronan Fruit and
               Matteo Pirotta and
               Alessandro Lazaric and
               Ronald Ortner},
  title     = {Efficient Bias-Span-Constrained Exploration-Exploitation in Reinforcement
               Learning},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning,
               {ICML}},
  volume    = {80},
  pages     = {1573--1581},
  year      = {2018}
}

@inproceedings{
Rashid2020Optimistic,
title={Optimistic Exploration even with a Pessimistic Initialisation},
author={Tabish Rashid and Bei Peng and Wendelin Boehmer and Shimon Whiteson},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{kocsis,
  author    = {Levente Kocsis and
               Csaba Szepesv{\'{a}}ri},

  title     = {Bandit Based {M}onte-{C}arlo Planning},
  booktitle = {Machine Learning: {ECML} 2006, 17th European Conference on Machine
               Learning, Berlin, Germany, September 18-22, 2006, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {4212},
  pages     = {282--293},
  publisher = {Springer},
  year      = {2006},

}

@article{ucrl2,
author = {Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
title = {Near-Optimal Regret Bounds for Reinforcement Learning},
year = {2010},
issue_date = {March 2010},
publisher = {JMLR.org},
volume = {11},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = aug,
pages = {1563–1600},
numpages = {38}
}


@inproceedings{audibert,
  author    = {Jean{-}Yves Audibert and
               R{\'{e}}mi Munos and
               Csaba Szepesv{\'{a}}ri},
  title     = {Tuning Bandit Algorithms in Stochastic Environments},
  booktitle = {Algorithmic Learning Theory, 18th International Conference, {ALT}
               2007, Sendai, Japan, October 1-4, 2007, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {4754},
  pages     = {150--165},
  publisher = {Springer},
  year      = {2007},

}


@incollection{Ciosek:2019_OAC,
      title={Better Exploration with Optimistic Actor-Critic}, 
      author={Kamil Ciosek and Quan Vuong and Robert Loftin and Katja Hofmann},
      year={2019},
 booktitle = {Advances in Neural Information Processing Systems},
 publisher = {NeurIPS}
}

@inproceedings{bootstrapped_dqn,
 author = {Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {4026--4034},
 title = {Deep Exploration via Bootstrapped DQN},
 volume = {29},
 year = {2016}
}



@article{Haarnoja:2018_SAC,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
}

@INPROCEEDINGS{Thrun:93_approx,
    author = {Sebastian Thrun and Anton Schwartz},
    title = {Issues in Using Function Approximation for Reinforcement Learning},
    booktitle = {In Proceedings of the Fourth Connectionist Models Summer School},
    year = {1993},
    publisher = {Erlbaum}
}

@inproceedings{Todorov:12_mujoco,
  added-at = {2018-11-14T00:00:00.000+0100},
  author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle = {IROS},
  keywords = {dblp},
  pages = {5026-5033},
  publisher = {IEEE},
  title = {MuJoCo: A physics engine for model-based control.},
  year = 2012
}


@inproceedings{
Barth-Maron:18_D4PG,
title={Distributional Policy Gradients},
author={Gabriel Barth-Maron and Matthew W. Hoffman and David Budden and Will Dabney and Dan Horgan and Dhruva TB and Alistair Muldal and Nicolas Heess and Timothy Lillicrap},
booktitle={International Conference on Learning Representations},
year={2018},
}


@incollection{Dabney:17_qrdqn,
  author    = {Will Dabney and
               Mark Rowland and
               Marc G. Bellemare and
               R{\'{e}}mi Munos},
  title     = {Distributional Reinforcement Learning with Quantile Regression},
  booktitle   = {AAAI},
  year      = {2018},
  publisher = {AAAI}
}

@inproceedings{Bellemare:17_distRL,
author = {Bellemare, Marc G. and Dabney, Will and Munos, R\'{e}mi},
title = {A Distributional Perspective on Reinforcement Learning},
year = {2017},
publisher = {JMLR.org},
booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
pages = {449–458},
numpages = {10},
}


@article{Dabney:20_dopamine,
	Author = {Dabney, Will and Kurth-Nelson, Zeb and Uchida, Naoshige and Starkweather, Clara Kwon and Hassabis, Demis and Munos, R{\'e}mi and Botvinick, Matthew},
	Da = {2020/01/01},
	Id = {Dabney2020},
	Journal = {Nature},
	Number = {7792},
	Pages = {671--675},
	Title = {A distributional code for value in dopamine-based reinforcement learning},
	Ty = {JOUR},
	Volume = {577},
	Year = {2020}}
	
@misc{Rowland:19_erdqn,
      title={Statistics and Samples in Distributional Reinforcement Learning}, 
      author={Mark Rowland and Robert Dadashi and Saurabh Kumar and Rémi Munos and Marc G. Bellemare and Will Dabney},
      year={2019},
      eprint={1902.08102},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}


@InProceedings{Ball:20_RP1, 
title = {Ready Policy One: World Building Through Active Learning}, 
author = {Ball, Philip and Parker-Holder, Jack and Pacchiano, Aldo and Choromanski, Krzysztof and Roberts, Stephen}, 
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
pages = {591--601}, 
year = {2020}, 
volume = {119}, 
month = {13--18 Jul}, 
}

@InProceedings{Pacchiano:2020_BGRL, 
title = {Learning to Score Behaviors for Guided Policy Optimization}, 
author = {Pacchiano, Aldo and Parker-Holder, Jack and Tang, Yunhao and Choromanski, Krzysztof and Choromanska, Anna and Jordan, Michael}, 
booktitle = {Proceedings of the 37th International Conference on Machine Learning}, pages = {7445--7454}, 
year = {2020}, 
volume = {119}, 
month = {13--18 Jul}, 
}


@incollection{Moskovitz:2020_WNG,
      title={Efficient Wasserstein Natural Gradients for Reinforcement Learning}, 
      author={Ted Moskovitz and Michael Arbel and Ferenc Huszar and Arthur Gretton},
      year={2021},
      booktitle={International Conference on Learning Representations},
      publisher = {ICLR}
}

@article{Watkins:92_Q,
  added-at = {2020-01-01T20:16:30.000+0100},
  author = {Watkins, Christopher J. C. H. and Dayan, Peter},
  journal = {Machine Learning},
  pages = {279--292},
  timestamp = {2020-01-01T20:16:30.000+0100},
  title = {Q-learning},
  volume = 8,
  year = {1992}
}

@inproceedings{Hasselt:2010_doubleQ,
 author = {Hasselt, Hado},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Lafferty and C. Williams and J. Shawe-Taylor and R. Zemel and A. Culotta},
 pages = {2613--2621},
 title = {Double Q-learning},
 volume = {23},
 year = {2010}
}

@book{Sutton:98_rl,
  added-at = {2019-07-13T10:11:53.000+0200},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  edition = {Second},
  publisher = {The MIT Press},
  timestamp = {2019-07-13T10:11:53.000+0200},
  title = {Reinforcement Learning: An Introduction},
  year = {2018 }
}

@article{Brafmen:03_optimism,
author = {Brafman, Ronen I. and Tennenholtz, Moshe},
title = {R-Max - a General Polynomial Time Algorithm for near-Optimal Reinforcement Learning},
year = {2003},
issue_date = {3/1/2003},
publisher = {JMLR.org},
volume = {3},
number = {null},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = mar,
pages = {213–231},
numpages = {19},
}

@article{Brockman:16_gym,
  author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  title = {OpenAI Gym},
  journal={CoRR},
  year = {2016}
}


@article{Silver:2016_go,
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  issn = {0028-0836},
  journal = {Nature},
  keywords = {01614 paper ai google learn algorithm},
  number = 7587,
  pages = {484--489},
  timestamp = {2018-04-16T12:03:12.000+0200},
  title = {Mastering the Game of {Go} with Deep Neural Networks and Tree Search},
  username = {flint63},
  volume = 529,
  year = 2016
}

@article{Mnih:2015_dqn,
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  issn = {00280836},
  journal = {Nature},
  month = feb,
  number = 7540,
  pages = {529--533},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  title = {Human-level control through deep reinforcement learning},
  volume = 518,
  year = 2015
}


@article{Huber:1964_qrloss,
  author = {Huber, Peter J.},
  issn = {0003-4851},
  journal = {Annals of Mathematical Statistics},
  keywords = {mathematics},
  number = 1,
  pages = {73--101},
  timestamp = {2012-09-01T13:08:56.000+0200},
  title = {Robust estimation of a location parameter},
  volume = 35,
  year = 1964
}


@book{Cesa-Bianchi:2006_bandit,
  author = {Cesa-Bianchi, Nicolo and Lugosi, Gabor},
  pages = {I-XII, 1-394},
  publisher = {Cambridge University Press},
  timestamp = {2019-07-30T11:47:45.000+0200},
  title = {Prediction, learning, and games.},
  year = 2006
}


@misc{Ball:21_offcon,
      title={OffCon$^3$: What is state of the art anyway?}, 
      author={Philip J. Ball and Stephen J. Roberts},
      year={2021},
      eprint={2101.11331},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{Bellemare:2012_arcade,
  author    = {Marc G. Bellemare and
               Yavar Naddaf and
               Joel Veness and
               Michael Bowling},
  title     = {The Arcade Learning Environment: An Evaluation Platform for General
               Agents},
  journal   = {CoRR},
  volume    = {abs/1207.4708},
  year      = {2012},
  url       = {http://arxiv.org/abs/1207.4708},
  archivePrefix = {arXiv},
  eprint    = {1207.4708},
  timestamp = {Mon, 13 Aug 2018 16:46:44 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1207-4708.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{Dabney:18_iqn, title = {Implicit Quantile Networks for Distributional Reinforcement Learning}, author = {Dabney, Will and Ostrovski, Georg and Silver, David and Munos, Remi}, booktitle = {Proceedings of the 35th International Conference on Machine Learning}, pages = {1096--1105}, year = {2018}, editor = {Jennifer Dy and Andreas Krause}, volume = {80}, series = {Proceedings of Machine Learning Research}, address = {Stockholmsmässan, Stockholm Sweden}, month = {10--15 Jul}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v80/dabney18a/dabney18a.pdf}, url = {http://proceedings.mlr.press/v80/dabney18a.html} }


@article{Lin:92_buffer,
author = {Lin, Long-Ji},
title = {Self-Improving Reactive Agents Based on Reinforcement Learning, Planning and Teaching},
year = {1992},
issue_date = {May 1992},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {3–4},
issn = {0885-6125},
url = {https://doi.org/10.1007/BF00992699},
doi = {10.1007/BF00992699},
journal = {Mach. Learn.},
month = may,
pages = {293–321},
numpages = {29}
}


@misc{Tassa:20_dmc,
      title={DeepMind Control Suite}, 
      author={Yuval Tassa and Yotam Doron and Alistair Muldal and Tom Erez and Yazhe Li and Diego de Las Casas and David Budden and Abbas Abdolmaleki and Josh Merel and Andrew Lefrancq and Timothy Lillicrap and Martin Riedmiller},
      year={2018},
      eprint={1801.00690},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}


@inproceedings{Laskin:20_rad,
 author = {Laskin, Misha and Lee, Kimin and Stooke, Adam and Pinto, Lerrel and Abbeel, Pieter and Srinivas, Aravind},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {19884--19895},
 publisher = {Curran Associates, Inc.},
 title = {Reinforcement Learning with Augmented Data},
 url = {https://proceedings.neurips.cc/paper/2020/file/e615c82aba461681ade82da2da38004a-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{Laskin:20_curl,
  title={CURL: Contrastive Unsupervised Representations for Reinforcement Learning},
  author={Laskin, Michael and Srinivas, Aravind and Abbeel, Pieter},
  note={arXiv:2004.04136},
  journal={Proceedings of the 37th International Conference on Machine 
  Learning, Vienna, Austria, PMLR 119},
  year={2020}
}


@inproceedings{Yarats:21_drq,
title={Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels},
author={Denis Yarats and Ilya Kostrikov and Rob Fergus},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=GY6-6sTvGaf}
}

@inproceedings{Lee:20_pisac,
 author = {Lee, Kuang-Huei and Fischer, Ian and Liu, Anthony and Guo, Yijie and Lee, Honglak and Canny, John and Guadarrama, Sergio},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {11890--11901},
 publisher = {Curran Associates, Inc.},
 title = {Predictive Information Accelerates Learning in RL},
 url = {https://proceedings.neurips.cc/paper/2020/file/89b9e0a6f6d1505fe13dea0f18a2dcfa-Paper.pdf},
 volume = {33},
 year = {2020}
}

@InProceedings{Hafner:19_planet, title = {Learning Latent Dynamics for Planning from Pixels}, author = {Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James}, booktitle = {Proceedings of the 36th International Conference on Machine Learning}, pages = {2555--2565}, year = {2019}, editor = {Kamalika Chaudhuri and Ruslan Salakhutdinov}, volume = {97}, series = {Proceedings of Machine Learning Research}, month = {09--15 Jun}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v97/hafner19a/hafner19a.pdf}, url = { http://proceedings.mlr.press/v97/hafner19a.html } }


@inproceedings{Hafner:20_dreamer,
title={Dream to Control: Learning Behaviors by Latent Imagination},
author={Danijar Hafner and Timothy Lillicrap and Jimmy Ba and Mohammad Norouzi},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=S1lOTC4tDS}
}

@misc{Lee:20_slac,
title={Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model},
author={Alex X. Lee and Anusha Nagabandi and Pieter Abbeel and Sergey Levine},
year={2020},
url={https://openreview.net/forum?id=HJxDugSFDB}
}

@misc{Yarats:20_sacae,
      title={Improving Sample Efficiency in Model-Free Reinforcement Learning from Images}, 
      author={Denis Yarats and Amy Zhang and Ilya Kostrikov and Brandon Amos and Joelle Pineau and Rob Fergus},
      year={2020},
      eprint={1910.01741},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{Zhang:2019_quota, title={QUOTA: The Quantile Option Architecture for Reinforcement Learning}, volume={33}, url={https://ojs.aaai.org/index.php/AAAI/article/view/4527}, DOI={10.1609/aaai.v33i01.33015797}, number={01}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Zhang, Shangtong and Yao, Hengshuai}, year={2019}, pages={5797-5804} }

@misc{Ma:2019_bs,
      title={A Scheme for Dynamic Risk-Sensitive Sequential Decision Making}, 
      author={Shuai Ma and Jia Yuan Yu and Ahmet Satir},
      year={2019},
      eprint={1907.04269},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}


@inproceedings{Kirsch:2020_lilbitch,
title={Improving Generalization in Meta Reinforcement Learning using Learned Objectives},
author={Louis Kirsch and Sjoerd van Steenkiste and Juergen Schmidhuber},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=S1evHerYPr}
}


