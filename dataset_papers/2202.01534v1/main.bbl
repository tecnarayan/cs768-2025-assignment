\providecommand{\noopsort}[1]{}\providecommand{\noopsort}[1]{}\providecommand{\noopsort}[1]{}\providecommand{\noopsort}[1]{}
\begin{thebibliography}{56}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Acid \& De~Campos(1996)Acid and De~Campos]{Acid1996Algorithm}
Acid, S. and De~Campos, L.~M.
\newblock An algorithm for finding minimum d-separating sets in belief
  networks.
\newblock In \emph{Proceedings of the Twelfth International Conference on
  Uncertainty in Artificial Intelligence}, UAI'96, 1996.

\bibitem[Arjovsky(2021)]{arjovsky2021out}
Arjovsky, M.
\newblock Out of distribution generalization in machine learning.
\newblock \emph{arXiv preprint arXiv:2103.02667}, 2021.

\bibitem[Arjovsky et~al.(2019)Arjovsky, Bottou, Gulrajani, and
  Lopez-Paz]{arjovsky2019invariant}
Arjovsky, M., Bottou, L., Gulrajani, I., and Lopez-Paz, D.
\newblock Invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:1907.02893}, 2019.

\bibitem[Becker et~al.(2003)Becker, Zilberstein, Lesser, and
  Goldman]{Becker03AAMAS}
Becker, R., Zilberstein, S., Lesser, V., and Goldman, C.~V.
\newblock Transition-independent decentralized {M}arkov decision processes.
\newblock In \emph{Proc.\ of the International Conference on Autonomous Agents
  and Multiagent Systems}, pp.\  41--48, 2003.

\bibitem[{Bellemare} et~al.(2013){Bellemare}, {Naddaf}, {Veness}, and
  {Bowling}]{bellemare13arcade}
{Bellemare}, M.~G., {Naddaf}, Y., {Veness}, J., and {Bowling}, M.
\newblock The {Arcade Learning Environment}: An evaluation platform for general
  agents.
\newblock \emph{Journal of Artificial Intelligence Research}, 47:\penalty0
  253--279, jun 2013.

\bibitem[Bellemare et~al.(2020)Bellemare, Candido, Castro, Gong, Machado,
  Moitra, Ponda, and Wang]{bellemare2020autonomous}
Bellemare, M.~G., Candido, S., Castro, P.~S., Gong, J., Machado, M.~C., Moitra,
  S., Ponda, S.~S., and Wang, Z.
\newblock Autonomous navigation of stratospheric balloons using reinforcement
  learning.
\newblock \emph{Nature}, 588\penalty0 (7836):\penalty0 77--82, 2020.

\bibitem[Bishop(2006)]{Bishop06book}
Bishop, C.~M.
\newblock \emph{Pattern Recognition and Machine Learning}.
\newblock Springer, 2006.

\bibitem[Botvinick et~al.(2019)Botvinick, Ritter, Wang, Kurth-Nelson, Blundell,
  and Hassabis]{botvinick2019reinforcement}
Botvinick, M., Ritter, S., Wang, J.~X., Kurth-Nelson, Z., Blundell, C., and
  Hassabis, D.
\newblock Reinforcement learning, fast and slow.
\newblock \emph{Trends in cognitive sciences}, 23\penalty0 (5):\penalty0
  408--422, 2019.

\bibitem[Boutilier et~al.(1996)Boutilier, Friedman, Goldszmidt, and
  Koller]{Boutilier96UAI}
Boutilier, C., Friedman, N., Goldszmidt, M., and Koller, D.
\newblock Context-specific independence in bayesian networks.
\newblock In \emph{Proceedings of the Twelfth Conference on Uncertainty in
  Artificial Intelligence}, pp.\  115--123, 1996.

\bibitem[Boutilier et~al.(1999)Boutilier, Dean, and
  Hanks]{boutilier1999decision}
Boutilier, C., Dean, T., and Hanks, S.
\newblock {Decision-theoretic planning: Structural assumptions and
  computational leverage}.
\newblock \emph{Journal of Artificial Intelligence Research}, 11:\penalty0
  1--94, 1999.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Zaremba]{openaigym}
Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang,
  J., and Zaremba, W.
\newblock Openai gym, 2016.

\bibitem[Chitnis \& Lozano-P\'erez(2020)Chitnis and
  Lozano-P\'erez]{chitnis2020exogenous}
Chitnis, R. and Lozano-P\'erez, T.
\newblock Learning compact models for planning with exogenous processes.
\newblock In \emph{Proceedings of the Conference on Robot Learning}, 2020.

\bibitem[Cho et~al.(2014)Cho, {van Merrienboer}, Gulcehre, Bougares, Schwenk,
  and Bengio]{Cho2014Learning}
Cho, K., {van Merrienboer}, B., Gulcehre, C., Bougares, F., Schwenk, H., and
  Bengio, Y.
\newblock Learning phrase representations using rnn encoder-decoder for
  statistical machine translation.
\newblock In \emph{Conference on Empirical Methods in Natural Language
  Processing (EMNLP 2014)}, 2014.

\bibitem[Claes et~al.(2017)Claes, Oliehoek, Baier, Tuyls,
  et~al.]{claes2017decentralised}
Claes, D., Oliehoek, F., Baier, H., Tuyls, K., et~al.
\newblock Decentralised online planning for multi-robot warehouse
  commissioning.
\newblock In \emph{Proceedings of the 16th international conference on
  autonomous agents and multiagent systems}, pp.\  492--500, 2017.

\bibitem[Congeduti et~al.(2021)Congeduti, Mey, and Oliehoek]{Congeduti21AAMAS}
Congeduti, E., Mey, A., and Oliehoek, F.~A.
\newblock Loss bounds for approximate influence-based abstraction.
\newblock In \emph{AAMAS21}, May 2021.

\bibitem[Dulac-Arnold et~al.(2019)Dulac-Arnold, Mankowitz, and
  Hester]{dulac2019challenges}
Dulac-Arnold, G., Mankowitz, D., and Hester, T.
\newblock Challenges of real-world reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1904.12901}, 2019.

\bibitem[Ganesh et~al.(2019)Ganesh, Vadori, Xu, Zheng, Reddy, and
  Veloso]{Ganesh2019ReinforcementLF}
Ganesh, S., Vadori, N., Xu, M., Zheng, H., Reddy, P., and Veloso, M.~M.
\newblock Reinforcement learning for market making in a multi-agent dealer
  market.
\newblock \emph{ArXiv}, abs/1911.05892, 2019.

\bibitem[Geirhos et~al.(2020)Geirhos, Jacobsen, Michaelis, Zemel, Brendel,
  Bethge, and Wichmann]{geirhos2020shortcut}
Geirhos, R., Jacobsen, J.-H., Michaelis, C., Zemel, R., Brendel, W., Bethge,
  M., and Wichmann, F.~A.
\newblock Shortcut learning in deep neural networks.
\newblock \emph{Nature Machine Intelligence}, 2\penalty0 (11):\penalty0
  665--673, 2020.

\bibitem[Gupta et~al.(2021)Gupta, Badr, Negahban, and Qiu]{gupta2021energy}
Gupta, A., Badr, Y., Negahban, A., and Qiu, R.~G.
\newblock Energy-efficient heating control for smart buildings with deep
  reinforcement learning.
\newblock \emph{Journal of Building Engineering}, 34:\penalty0 101739, 2021.

\bibitem[Ha \& Schmidhuber(2018)Ha and Schmidhuber]{NEURIPS2018_2de5d166}
Ha, D. and Schmidhuber, J.
\newblock Recurrent world models facilitate policy evolution.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~31, pp.\  2450--2462. Curran
  Associates, Inc., 2018.

\bibitem[Hausknecht \& Stone(2015)Hausknecht and Stone]{hausknecht2015deep}
Hausknecht, M. and Stone, P.
\newblock Deep recurrent {Q-learning} for partially observable {MDPs}.
\newblock In \emph{Proceedings of the Twenty-Ninth AAAI Conference on
  Artificial Intelligence}, 2015.

\bibitem[He et~al.(2020)He, Suau, and Oliehoek]{NEURIPS2020_2e6d9c60}
He, J., Suau, M., and Oliehoek, F.
\newblock Influence-augmented online planning for complex environments.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.~F., and Lin,
  H. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~33, pp.\  4392--4402. Curran Associates, Inc., 2020.

\bibitem[Hochreiter \& Schmidhuber(1997)Hochreiter and
  Schmidhuber]{hochreiter1997long}
Hochreiter, S. and Schmidhuber, J.
\newblock Long short-term memory.
\newblock \emph{Neural computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Kaelbling et~al.(1996)Kaelbling, Littman, and Moore]{Kaelbling96JAIR}
Kaelbling, L.~P., Littman, M., and Moore, A.
\newblock Reinforcement learning: A survey.
\newblock \emph{Journal of AI Research}, 4:\penalty0 237--285, 1996.

\bibitem[Kakade(2003)]{kakade2003sample}
Kakade, S.~M.
\newblock \emph{On the sample complexity of reinforcement learning}.
\newblock PhD thesis, UCL (University College London), 2003.

\bibitem[Krueger et~al.(2021)Krueger, Caballero, Jacobsen, Zhang, Binas, Zhang,
  Priol, and Courville]{krueger2021ood}
Krueger, D., Caballero, E., Jacobsen, J.-H., Zhang, A., Binas, J., Zhang, D.,
  Priol, R.~L., and Courville, A.
\newblock Out-of-distribution generalization via risk extrapolation (rex).
\newblock In \emph{Proceedings of the 38th International Conference on Machine
  Learning}, 2021.

\bibitem[Kumar et~al.(2011)Kumar, Zilberstein, and Toussaint]{Kumar11IJCAI}
Kumar, A., Zilberstein, S., and Toussaint, M.
\newblock Scalable multiagent planning using probabilistic inference.
\newblock In \emph{Proc.\ of the International Joint Conference on Artificial
  Intelligence}, pp.\  2140--2146, 2011.

\bibitem[Lazaric(2012)]{lazaric2012transfer}
Lazaric, A.
\newblock Transfer in reinforcement learning: a framework and a survey.
\newblock In \emph{Reinforcement Learning}, pp.\  143--173. Springer, 2012.

\bibitem[Littman(1994)]{Littman94memoryless}
Littman, M.~L.
\newblock Memoryless policies: Theoretical limitations and practical results.
\newblock In \emph{Proc. of the Third International Conference on Simulation of
  Adaptive Behavior : From Animals to Animats 3}, pp.\  238--245, 1994.

\bibitem[Lopez et~al.(2018)Lopez, Behrisch, Bieker-Walz, Erdmann,
  Fl{\"o}tter{\"o}d, Hilbrich, L{\"u}cken, Rummel, Wagner, and
  Wie{\ss}ner]{SUMO2018}
Lopez, P.~A., Behrisch, M., Bieker-Walz, L., Erdmann, J., Fl{\"o}tter{\"o}d,
  Y.-P., Hilbrich, R., L{\"u}cken, L., Rummel, J., Wagner, P., and Wie{\ss}ner,
  E.
\newblock Microscopic traffic simulation using sumo.
\newblock In \emph{The 21st IEEE International Conference on Intelligent
  Transportation Systems}. IEEE, 2018.
\newblock URL \url{https://elib.dlr.de/124092/}.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{Mnih15Nature}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529, 2015.

\bibitem[Moerland et~al.(2020)Moerland, Broekens, and
  Jonker]{moerland2020model}
Moerland, T.~M., Broekens, J., and Jonker, C.~M.
\newblock Model-based reinforcement learning: A survey.
\newblock \emph{arXiv preprint arXiv:2006.16712}, 2020.

\bibitem[Nair et~al.(2005)Nair, Varakantham, Tambe, and Yokoo]{Nair05AAAI}
Nair, R., Varakantham, P., Tambe, M., and Yokoo, M.
\newblock Networked distributed {POMDP}s: A synthesis of distributed constraint
  optimization and {POMDP}s.
\newblock In \emph{Proc.\ of the National Conference on Artificial
  Intelligence}, pp.\  133--139, 2005.

\bibitem[\noopsort{Pol}van~der Pol \& Oliehoek(2016)\noopsort{Pol}van~der Pol
  and Oliehoek]{VanDerPol16NIPSWS}
\noopsort{Pol}van~der Pol, E. and Oliehoek, F.~A.
\newblock Coordinated deep reinforcement learners for traffic light control.
\newblock Submitted to NIPS'16 Workshop on Learning, Inference and Control of
  Multi-Agent Systems, 2016.

\bibitem[Oh et~al.(2016)Oh, Chockalingam, Singh, and Lee]{Oh16ICML}
Oh, J., Chockalingam, V., Singh, S., and Lee, H.
\newblock Control of memory, active perception, and action in minecraft.
\newblock In \emph{Proc.\ of the 33rd International Conference on Machine
  learning}, ICML'16, pp.\  2790--2799. JMLR.org, 2016.

\bibitem[Oliehoek et~al.(2021)Oliehoek, Witwicki, and
  Kaelbling]{oliehoek2021sufficient}
Oliehoek, F., Witwicki, S., and Kaelbling, L.
\newblock A sufficient statistic for influence in structured multiagent
  environments.
\newblock \emph{Journal of Artificial Intelligence Research}, 70:\penalty0
  789--870, 2021.

\bibitem[Pearl(1988)]{pearl88}
Pearl, J.
\newblock \emph{Probabilistic Reasoning In Intelligent Systems: Networks of
  Plausible Inference}.
\newblock Morgan Kaufmann, 1988.

\bibitem[Pearl(2000)]{Pearl2000Causality}
Pearl, J.
\newblock \emph{Causality: Models, Reasoning, and Inference}.
\newblock Cambridge University Press, 2000.

\bibitem[Peters et~al.(2016)Peters, B{\"u}hlmann, and
  Meinshausen]{peters2016causal}
Peters, J., B{\"u}hlmann, P., and Meinshausen, N.
\newblock Causal inference by using invariant prediction: identification and
  confidence intervals.
\newblock \emph{Journal of the Royal Statistical Society. Series B (Statistical
  Methodology)}, pp.\  947--1012, 2016.

\bibitem[Quionero-Candela et~al.(2009)Quionero-Candela, Sugiyama, Schwaighofer,
  and Lawrence]{quionero2009dataset}
Quionero-Candela, J., Sugiyama, M., Schwaighofer, A., and Lawrence, N.~D.
\newblock \emph{Dataset shift in machine learning}.
\newblock The MIT Press, 2009.

\bibitem[Schaul et~al.(2016)Schaul, Quan, Antonoglou, and
  Silver]{DBLP:journals/corr/SchaulQAS15}
Schaul, T., Quan, J., Antonoglou, I., and Silver, D.
\newblock Prioritized experience replay.
\newblock In \emph{4th International Conference on Learning Representations,
  {ICLR} 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track
  Proceedings}, 2016.

\bibitem[Schmidhuber(1991)]{Schmidhuber91NIPS}
Schmidhuber, J.
\newblock Reinforcement learning in {M}arkovian and non-{M}arkovian
  environments.
\newblock In Lippman, D.~S., Moody, J.~E., and Touretzky, D.~S. (eds.),
  \emph{Advances in Neural Information Processing Systems 3 (NIPS 3)}, pp.\
  500--506. Morgan Kaufmann, 1991.

\bibitem[Schrittwieser et~al.(2020)Schrittwieser, Antonoglou, Hubert, Simonyan,
  Sifre, Schmitt, Guez, Lockhart, Hassabis, Graepel,
  et~al.]{schrittwieser2020mastering}
Schrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L.,
  Schmitt, S., Guez, A., Lockhart, E., Hassabis, D., Graepel, T., et~al.
\newblock Mastering atari, go, chess and shogi by planning with a learned
  model.
\newblock \emph{Nature}, 588\penalty0 (7839):\penalty0 604--609, 2020.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017proximal}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Singh et~al.(1994)Singh, Jaakkola, and Jordan]{Singh94ICML}
Singh, S.~P., Jaakkola, T., and Jordan, M.~I.
\newblock Learning without state-estimation in partially observable {M}arkovian
  decision processes.
\newblock In \emph{Proc.\ of the International Conference on Machine Learning},
  pp.\  284--292. Morgan Kaufmann, 1994.

\bibitem[Suau et~al.(2021)Suau, Agapitos, Lynch, Farrell, Zhou, and
  Milenovic]{suau2021offline}
Suau, M., Agapitos, A., Lynch, D., Farrell, D., Zhou, M., and Milenovic, A.
\newblock Offline contextual bandits for wireless network optimization.
\newblock \emph{arXiv preprint arXiv:2111.08587}, 2021.

\bibitem[Sutton(1990)]{Sutton90integratedarchitectures}
Sutton, R.~S.
\newblock Integrated architectures for learning, planning, and reacting based
  on approximating dynamic programming.
\newblock In \emph{In Proceedings of the Seventh International Conference on
  Machine Learning}, pp.\  216--224. Morgan Kaufmann, 1990.

\bibitem[Sutton \& Barto(1998)Sutton and Barto]{SuttonBarto98}
Sutton, R.~S. and Barto, A.~G.
\newblock \emph{Reinforcement Learning: An Introduction}.
\newblock {The MIT Press}, 1998.

\bibitem[Tian et~al.(1998)Tian, Paz, and Pearl]{tian1998finding}
Tian, J., Paz, A., and Pearl, J.
\newblock \emph{Finding minimal d-separators}.
\newblock 1998.

\bibitem[van Hasselt et~al.(2019)van Hasselt, Hessel, and
  Aslanides]{NEURIPS2019_1b742ae2}
van Hasselt, H.~P., Hessel, M., and Aslanides, J.
\newblock When to use parametric models in reinforcement learning?
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A., d\textquotesingle
  Alch\'{e}-Buc, F., Fox, E., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.

\bibitem[Varakantham et~al.(2007)Varakantham, Marecki, Yabu, Tambe, and
  Yokoo]{Varakantham07AAMAS}
Varakantham, P., Marecki, J., Yabu, Y., Tambe, M., and Yokoo, M.
\newblock Letting loose a {SPIDER} on a network of {POMDPs}: Generating quality
  guaranteed policies.
\newblock In \emph{Proc.\ of the International Conference on Autonomous Agents
  and Multiagent Systems}, 2007.

\bibitem[Vinyals et~al.(2019)Vinyals, Babuschkin, Czarnecki, Mathieu, Dudzik,
  Chung, Choi, Powell, Ewalds, Georgiev, et~al.]{vinyals2019grandmaster}
Vinyals, O., Babuschkin, I., Czarnecki, W.~M., Mathieu, M., Dudzik, A., Chung,
  J., Choi, D.~H., Powell, R., Ewalds, T., Georgiev, P., et~al.
\newblock Grandmaster level in starcraft ii using multi-agent reinforcement
  learning.
\newblock \emph{Nature}, 575\penalty0 (7782):\penalty0 350--354, 2019.

\bibitem[Wang et~al.(2021)Wang, Xu, Gu, Song, and Green]{wang2021multi}
Wang, J., Xu, W., Gu, Y., Song, W., and Green, T.
\newblock Multi-agent reinforcement learning for active voltage control on
  power distribution networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Williams \& Peng(1990)Williams and Peng]{williams1990efficient}
Williams, R.~J. and Peng, J.
\newblock An efficient gradient-based algorithm for on-line training of
  recurrent network trajectories.
\newblock \emph{Neural computation}, 2\penalty0 (4):\penalty0 490--501, 1990.

\bibitem[Witwicki \& Durfee(2011)Witwicki and Durfee]{Witwicki11AAMAS}
Witwicki, S.~J. and Durfee, E.~H.
\newblock Towards a unifying characterization for quantifying weak coupling in
  {Dec-POMDPs}.
\newblock In \emph{Proceedings of the Tenth International Conference on
  Autonomous Agents and Multiagent Systems}, pp.\  29--36, Taipei, Taiwan,
  2011.

\bibitem[Wu et~al.(2017)Wu, Kreidieh, Parvate, Vinitsky, and Bayen]{wu2017flow}
Wu, C., Kreidieh, A., Parvate, K., Vinitsky, E., and Bayen, A.~M.
\newblock Flow: A modular learning framework for autonomy in traffic.
\newblock \emph{arXiv preprint arXiv:1710.05465}, 2017.

\end{thebibliography}
