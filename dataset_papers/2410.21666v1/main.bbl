\begin{thebibliography}{45}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Courtade and Wesel(2011)]{courtade2011multiterminal}
Thomas~A Courtade and Richard~D Wesel.
\newblock Multiterminal source coding with an entropy-based distortion measure.
\newblock In \emph{2011 IEEE International Symposium on Information Theory Proceedings}, pages 2040--2044. IEEE, 2011.

\bibitem[Courtade and Weissman(2013)]{courtade2013multiterminal}
Thomas~A Courtade and Tsachy Weissman.
\newblock Multiterminal source coding under logarithmic loss.
\newblock \emph{IEEE Transactions on Information Theory}, 60\penalty0 (1):\penalty0 740--761, 2013.

\bibitem[Shkel and Verd{\'u}(2017)]{shkel2017single}
Yanina~Y Shkel and Sergio Verd{\'u}.
\newblock A single-shot approach to lossy source coding under logarithmic loss.
\newblock \emph{IEEE Transactions on Information Theory}, 64\penalty0 (1):\penalty0 129--147, 2017.

\bibitem[Vidyasagar(2012)]{vidyasagar2012metric}
Mathukumalli Vidyasagar.
\newblock A metric between probability distributions on finite sets of different cardinalities and applications to order reduction.
\newblock \emph{IEEE Transactions on Automatic Control}, 57\penalty0 (10):\penalty0 2464--2477, 2012.

\bibitem[Painsky et~al.(2013)Painsky, Rosset, and Feder]{painsky2013memoryless}
Amichai Painsky, Saharon Rosset, and Meir Feder.
\newblock Memoryless representation of markov processes.
\newblock In \emph{2013 IEEE International Symposium on Information Theory}, pages 2294--298. IEEE, 2013.

\bibitem[Kova{\v{c}}evi{\'c} et~al.(2015)Kova{\v{c}}evi{\'c}, Stanojevi{\'c}, and {\v{S}}enk]{kovavcevic2015entropy}
Mladen Kova{\v{c}}evi{\'c}, Ivan Stanojevi{\'c}, and Vojin {\v{S}}enk.
\newblock On the entropy of couplings.
\newblock \emph{Information and Computation}, 242:\penalty0 369--382, 2015.

\bibitem[Cicalese et~al.(2017)Cicalese, Gargano, and Vaccaro]{cicalese2017find}
Ferdinando Cicalese, Luisa Gargano, and Ugo Vaccaro.
\newblock How to find a joint probability distribution of minimum entropy (almost) given the marginals.
\newblock In \emph{2017 IEEE International Symposium on Information Theory (ISIT)}, pages 2173--2177. IEEE, 2017.

\bibitem[Fr{\'e}chet(1951)]{frechet1951tableaux}
Maurice Fr{\'e}chet.
\newblock Sur les tableaux de corr{\'e}lation dont les marges sont donn{\'e}es.
\newblock \emph{Ann. Univ. Lyon, 3\^{} e serie, Sciences, Sect. A}, 14:\penalty0 53--77, 1951.

\bibitem[Den~Hollander(2012)]{den2012probability}
Frank Den~Hollander.
\newblock Probability theory: The coupling method.
\newblock \emph{Lecture notes available online (http://websites. math. leidenuniv. nl/probability/lecturenotes/CouplingLectures. pdf)}, 2012.

\bibitem[Lin et~al.(2014)Lin, Dou, Kuriki, and Huang]{lin2014recent}
Gwo~Dong Lin, Xiaoling Dou, Satoshi Kuriki, and Jin-Sheng Huang.
\newblock Recent developments on the construction of bivariate distributions with fixed marginals.
\newblock \emph{Journal of Statistical Distributions and Applications}, 1:\penalty0 1--23, 2014.

\bibitem[Benes and Step{\'a}n(2012)]{benes2012distributions}
Viktor Benes and Josef Step{\'a}n.
\newblock \emph{Distributions with given marginals and moment problems}.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Yu and Tan(2018)]{yu2018asymptotic}
Lei Yu and Vincent~YF Tan.
\newblock Asymptotic coupling and its applications in information theory.
\newblock \emph{IEEE Transactions on Information Theory}, 65\penalty0 (3):\penalty0 1321--1344, 2018.

\bibitem[Villani et~al.(2009)]{villani2009optimal}
C{\'e}dric Villani et~al.
\newblock \emph{Optimal transport: old and new}, volume 338.
\newblock Springer, 2009.

\bibitem[Kocaoglu et~al.(2017)Kocaoglu, Dimakis, Vishwanath, and Hassibi]{kocaoglu2017entropic}
Murat Kocaoglu, Alexandros Dimakis, Sriram Vishwanath, and Babak Hassibi.
\newblock Entropic causal inference.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~31, 2017.

\bibitem[Compton(2022)]{compton2022tighter}
Spencer Compton.
\newblock A tighter approximation guarantee for greedy minimum entropy coupling.
\newblock In \emph{2022 IEEE International Symposium on Information Theory (ISIT)}, pages 168--173. IEEE, 2022.

\bibitem[Compton et~al.(2023)Compton, Katz, Qi, Greenewald, and Kocaoglu]{compton2023minimum}
Spencer Compton, Dmitriy Katz, Benjamin Qi, Kristjan Greenewald, and Murat Kocaoglu.
\newblock Minimum-entropy coupling approximation guarantees beyond the majorization barrier.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 10445--10469. PMLR, 2023.

\bibitem[Marshall et~al.(1979)Marshall, Olkin, and Arnold]{marshall1979inequalities}
Albert~W Marshall, Ingram Olkin, and Barry~C Arnold.
\newblock Inequalities: theory of majorization and its applications.
\newblock 1979.

\bibitem[Cicalese et~al.(2019)Cicalese, Gargano, and Vaccaro]{cicalese2019minimum}
Ferdinando Cicalese, Luisa Gargano, and Ugo Vaccaro.
\newblock Minimum-entropy couplings and their applications.
\newblock \emph{IEEE Transactions on Information Theory}, 65\penalty0 (6):\penalty0 3436--3451, 2019.

\bibitem[Li(2021)]{li2021efficient}
Cheuk~Ting Li.
\newblock Efficient approximate minimum entropy coupling of multiple probability distributions.
\newblock \emph{IEEE Transactions on Information Theory}, 67\penalty0 (8):\penalty0 5259--5268, 2021.

\bibitem[Compton et~al.(2020)Compton, Kocaoglu, Greenewald, and Katz]{compton2020entropic}
Spencer Compton, Murat Kocaoglu, Kristjan Greenewald, and Dmitriy Katz.
\newblock Entropic causal inference: Identifiability and finite sample results.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 14772--14782, 2020.

\bibitem[Javidian et~al.(2021)Javidian, Aggarwal, Bao, and Jacob]{javidian2021quantum}
Mohammad~Ali Javidian, Vaneet Aggarwal, Fanglin Bao, and Zubin Jacob.
\newblock Quantum entropic causal inference.
\newblock In \emph{Quantum Information and Measurement}, pages F2C--3. Optica Publishing Group, 2021.

\bibitem[Sokota et~al.(2022)Sokota, De~Witt, Igl, Zintgraf, Torr, Strohmeier, Kolter, Whiteson, and Foerster]{sokota2022communicating}
Samuel Sokota, Christian A~Schroeder De~Witt, Maximilian Igl, Luisa~M Zintgraf, Philip Torr, Martin Strohmeier, Zico Kolter, Shimon Whiteson, and Jakob Foerster.
\newblock Communicating via markov decision processes.
\newblock In \emph{International Conference on Machine Learning}, pages 20314--20328. PMLR, 2022.

\bibitem[de~Witt et~al.(2022)de~Witt, Sokota, Kolter, Foerster, and Strohmeier]{de2022perfectly}
Christian~Schroeder de~Witt, Samuel Sokota, J~Zico Kolter, Jakob Foerster, and Martin Strohmeier.
\newblock Perfectly secure steganography using minimum entropy coupling.
\newblock \emph{arXiv preprint arXiv:2210.14889}, 2022.

\bibitem[Blau and Michaeli(2019)]{pmlr-v97-blau19a}
Yochai Blau and Tomer Michaeli.
\newblock Rethinking lossy compression: The rate-distortion-perception tradeoff.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, \emph{Proceedings of the 36th International Conference on Machine Learning}, volume~97 of \emph{Proceedings of Machine Learning Research}, pages 675--685. PMLR, 09--15 Jun 2019.
\newblock URL \url{https://proceedings.mlr.press/v97/blau19a.html}.

\bibitem[Liu et~al.(2022)Liu, Zhang, Chen, and Khisti]{liu2021lossy}
Huan Liu, George Zhang, Jun Chen, and Ashish~J Khisti.
\newblock Lossy compression with distribution shift as entropy constrained optimal transport.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[De~Bruijn(1981)]{de1981asymptotic}
Nicolaas~Govert De~Bruijn.
\newblock \emph{Asymptotic methods in analysis}, volume~4.
\newblock Courier Corporation, 1981.

\bibitem[Skyrms(2010)]{skyrms2010signals}
Brian Skyrms.
\newblock \emph{Signals: Evolution, learning, and information}.
\newblock OUP Oxford, 2010.

\bibitem[Cover(1999)]{cover1999elements}
Thomas~M Cover.
\newblock \emph{Elements of information theory}.
\newblock John Wiley \& Sons, 1999.

\bibitem[Kirchenbauer et~al.(2023)Kirchenbauer, Geiping, Wen, Katz, Miers, and Goldstein]{kirchenbauer2023watermark}
John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein.
\newblock A watermark for large language models.
\newblock In \emph{International Conference on Machine Learning}, pages 17061--17084. PMLR, 2023.

\bibitem[Isola et~al.(2016)Isola, Zhu, Zhou, and Efros]{isola2016image}
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei~A Efros.
\newblock Image-to-image translation with conditional adversarial networks. arxiv e-prints.
\newblock \emph{arXiv preprint arXiv:1611.07004}, 1611, 2016.

\bibitem[Zhu et~al.(2017)Zhu, Park, Isola, and Efros]{zhu2017unpaired}
Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei~A Efros.
\newblock Unpaired image-to-image translation using cycle-consistent adversarial networks.
\newblock In \emph{Proceedings of the IEEE international conference on computer vision}, pages 2223--2232, 2017.

\bibitem[Hoffman et~al.(2018)Hoffman, Tzeng, Park, Zhu, Isola, Saenko, Efros, and Darrell]{hoffman2018cycada}
Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu, Phillip Isola, Kate Saenko, Alexei Efros, and Trevor Darrell.
\newblock Cycada: Cycle-consistent adversarial domain adaptation.
\newblock In \emph{International conference on machine learning}, pages 1989--1998. Pmlr, 2018.

\bibitem[Kang et~al.(2019)Kang, Tripathi, and Nguyen]{kang2019toward}
Byeongkeun Kang, Subarna Tripathi, and Truong~Q Nguyen.
\newblock Toward joint image generation and compression using generative adversarial networks.
\newblock \emph{arXiv preprint arXiv:1901.07838}, 2019.

\bibitem[Tschannen et~al.(2019)Tschannen, Djolonga, Rubenstein, Gelly, and Lucic]{tschannen2019mutual}
Michael Tschannen, Josip Djolonga, Paul~K Rubenstein, Sylvain Gelly, and Mario Lucic.
\newblock On mutual information maximization for representation learning.
\newblock \emph{arXiv preprint arXiv:1907.13625}, 2019.

\bibitem[Hjelm et~al.(2018)Hjelm, Fedorov, Lavoie-Marchildon, Grewal, Bachman, Trischler, and Bengio]{hjelm2018learning}
R~Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam Trischler, and Yoshua Bengio.
\newblock Learning deep representations by mutual information estimation and maximization.
\newblock \emph{arXiv preprint arXiv:1808.06670}, 2018.

\bibitem[Mangasarian(1996)]{Mangasarian1996}
O.~L. Mangasarian.
\newblock \emph{Machine Learning via Polyhedral Concave Minimization}, pages 175--188.
\newblock Physica-Verlag HD, Heidelberg, 1996.
\newblock ISBN 978-3-642-99789-1.
\newblock \doi{10.1007/978-3-642-99789-1_13}.
\newblock URL \url{https://doi.org/10.1007/978-3-642-99789-1_13}.

\bibitem[Goemans()]{goemans}
Michel~X Goemans.
\newblock Spectral graph theory and numerical linear algebra.
\newblock URL \url{http://www.cs.cmu.edu/afs/cs/user/glmiller/public/Scientific-Computing/F-11/RelatedWork/Goemans-LP-notes.pdf}.

\bibitem[Palacios-Gomez et~al.(1982)Palacios-Gomez, Lasdon, and Engquist]{palacios1982nonlinear}
F~Palacios-Gomez, L~Lasdon, and M~Engquist.
\newblock Nonlinear optimization by successive linear programming.
\newblock \emph{Management science}, 28\penalty0 (10):\penalty0 1106--1120, 1982.

\bibitem[Ziebart et~al.(2008)Ziebart, Maas, Bagnell, Dey, et~al.]{ziebart2008maximum}
Brian~D Ziebart, Andrew~L Maas, J~Andrew Bagnell, Anind~K Dey, et~al.
\newblock Maximum entropy inverse reinforcement learning.
\newblock In \emph{Aaai}, volume~8, pages 1433--1438. Chicago, IL, USA, 2008.

\bibitem[Sutton and Barto(2018)]{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Hanselman(2023)]{hanselman_grid_world_rl_2023}
Kevin Hanselman.
\newblock grid-world-rl.
\newblock \url{https://github.com/kevin-hanselman/grid-world-rl}, 2023.

\bibitem[Barber and Agakov(2004)]{barber2004algorithm}
David Barber and Felix Agakov.
\newblock The im algorithm: a variational approach to information maximization.
\newblock \emph{Advances in neural information processing systems}, 16\penalty0 (320):\penalty0 201, 2004.

\bibitem[Chen et~al.(2016)Chen, Duan, Houthooft, Schulman, Sutskever, and Abbeel]{chen2016infogan}
Xi~Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel.
\newblock Infogan: Interpretable representation learning by information maximizing generative adversarial nets.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[LeCun et~al.(2010)LeCun, Cortes, and Burges]{mnist}
Yann LeCun, Corinna Cortes, and CJ~Burges.
\newblock Mnist handwritten digit database.
\newblock \emph{ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist}, 2, 2010.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, Ng, et~al.]{svhn}
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Baolin Wu, Andrew~Y Ng, et~al.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock In \emph{NIPS workshop on deep learning and unsupervised feature learning}, volume 2011, page~4. Granada, 2011.

\end{thebibliography}
