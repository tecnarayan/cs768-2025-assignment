\begin{thebibliography}{59}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2014)Agarwal, Hsu, Kale, Langford, Li, and
  Schapire]{agarwal2014taming}
Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, and Robert
  Schapire.
\newblock Taming the monster: A fast and simple algorithm for contextual
  bandits.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Arora et~al.(2017)Arora, Ge, Liang, Ma, and
  Zhang]{arora2017generalization}
Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi~Zhang.
\newblock Generalization and equilibrium in generative adversarial nets (gans).
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Arora et~al.(2019)Arora, Khandeparkar, Khodak, Plevrakis, and
  Saunshi]{arora2019theoretical}
Sanjeev Arora, Hrishikesh Khandeparkar, Mikhail Khodak, Orestis Plevrakis, and
  Nikunj Saunshi.
\newblock A theoretical analysis of contrastive unsupervised representation
  learning.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Barreto et~al.(2011)Barreto, Precup, and
  Pineau]{barreto2011reinforcement}
Andre Barreto, Doina Precup, and Joelle Pineau.
\newblock Reinforcement learning using kernel-based stochastic factorization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2011.

\bibitem[Barreto and Fragoso(2011)]{barreto2011computing}
Andr{\'e}~MS Barreto and Marcelo~D Fragoso.
\newblock Computing the stationary distribution of a finite markov chain
  through stochastic factorization.
\newblock \emph{SIAM Journal on Matrix Analysis and Applications}, 2011.

\bibitem[Baxter(2000)]{baxter2000model}
Jonathan Baxter.
\newblock A model of inductive bias learning.
\newblock \emph{Journal of artificial intelligence research}, 2000.

\bibitem[Bengio et~al.(2013)Bengio, Courville, and
  Vincent]{bengio2013representation}
Yoshua Bengio, Aaron Courville, and Pascal Vincent.
\newblock Representation learning: A review and new perspectives.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2013.

\bibitem[Cai et~al.(2019)Cai, Yang, Jin, and Wang]{cai2019provably}
Qi~Cai, Zhuoran Yang, Chi Jin, and Zhaoran Wang.
\newblock Provably efficient exploration in policy optimization.
\newblock \emph{arXiv:1912.05830}, 2019.

\bibitem[Chen and Jiang(2019)]{chen2019information}
Jinglin Chen and Nan Jiang.
\newblock Information-theoretic considerations in batch reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Cohen and Rothblum(1993)]{cohen1993nonnegative}
Joel~E Cohen and Uriel~G Rothblum.
\newblock Nonnegative ranks, decompositions, and factorizations of nonnegative
  matices.
\newblock \emph{Linear Algebra and its Applications}, 1993.

\bibitem[Dani et~al.(2008)Dani, Hayes, and Kakade]{dani2008stochastic}
Varsha Dani, Thomas~P Hayes, and Sham~M Kakade.
\newblock Stochastic linear optimization under bandit feedback.
\newblock In \emph{Conference on Learning Theory}, 2008.

\bibitem[Devroye and Lugosi(2012)]{devroye2012combinatorial}
Luc Devroye and G{\'a}bor Lugosi.
\newblock \emph{Combinatorial methods in density estimation}.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Dong et~al.(2019)Dong, Peng, Wang, and Zhou]{dong2019sqrt}
Kefan Dong, Jian Peng, Yining Wang, and Yuan Zhou.
\newblock $\sqrt{n}$-regret for learning in {M}arkov decision processes with
  function approximation and low {B}ellman rank.
\newblock \emph{arXiv:1909.02506}, 2019.

\bibitem[Du et~al.(2019{\natexlab{a}})Du, Kakade, Wang, and Yang]{du2019good}
Simon~S Du, Sham~M Kakade, Ruosong Wang, and Lin~F Yang.
\newblock Is a good representation sufficient for sample efficient
  reinforcement learning?
\newblock In \emph{International Conference on Learning Representations},
  2019{\natexlab{a}}.

\bibitem[Du et~al.(2019{\natexlab{b}})Du, Krishnamurthy, Jiang, Agarwal,
  Dud{\'\i}k, and Langford]{du2019provably}
Simon~S Du, Akshay Krishnamurthy, Nan Jiang, Alekh Agarwal, Miroslav
  Dud{\'\i}k, and John Langford.
\newblock Provably efficient {RL} with rich observations via latent state
  decoding.
\newblock In \emph{International Conference on Machine Learning},
  2019{\natexlab{b}}.

\bibitem[Du et~al.(2019{\natexlab{c}})Du, Luo, Wang, and Zhang]{du2019dsec}
Simon~S Du, Yuping Luo, Ruosong Wang, and Hanrui Zhang.
\newblock Provably efficient {Q}-learning with function approximation via
  distribution shift error checking oracle.
\newblock In \emph{Advances in Neural Information Processing Systems},
  2019{\natexlab{c}}.

\bibitem[Du et~al.(2020)Du, Lee, Mahajan, and Wang]{du2020agnostic}
Simon~S Du, Jason~D Lee, Gaurav Mahajan, and Ruosong Wang.
\newblock Agnostic {Q}-learning with function approximation in deterministic
  systems: Tight bounds on approximation error and sample complexity.
\newblock \emph{arXiv:2002.07125}, 2020.

\bibitem[Duan et~al.(2020)Duan, Wang, Wen, and Yuan]{duan2020adaptive}
Yaqi Duan, Mengdi Wang, Zaiwen Wen, and Yaxiang Yuan.
\newblock Adaptive low-nonnegative-rank approximation for state aggregation of
  {M}arkov chains.
\newblock \emph{SIAM Journal on Matrix Analysis and Applications}, 2020.

\bibitem[Edmonds(1965)]{edmonds1965maximum}
Jack Edmonds.
\newblock Maximum matching and a polyhedron with 0,1-vertices.
\newblock \emph{Journal of Research of the National Bureau of Standards--B},
  1965.

\bibitem[Feng et~al.(2020)Feng, Wang, Yin, Du, and Yang]{feng2020provably}
Fei Feng, Ruosong Wang, Wotao Yin, Simon~S Du, and Lin~F Yang.
\newblock Provably efficient exploration for rl with unsupervised learning.
\newblock \emph{arXiv:2003.06898}, 2020.

\bibitem[Figurnov et~al.(2018)Figurnov, Mohamed, and
  Mnih]{figurnov2018implicit}
Mikhail Figurnov, Shakir Mohamed, and Andriy Mnih.
\newblock Implicit reparameterization gradients.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Fiorini et~al.(2013)Fiorini, Kaibel, Pashkovich, and
  Theis]{fiorini2013combinatorial}
Samuel Fiorini, Volker Kaibel, Kanstantsin Pashkovich, and Dirk~Oliver Theis.
\newblock Combinatorial bounds on nonnegative rank and extended formulations.
\newblock \emph{Discrete Mathematics}, 2013.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, 2014.

\bibitem[Hazan et~al.(2019)Hazan, Kakade, Singh, and
  Van~Soest]{hazan2018provably}
Elad Hazan, Sham~M Kakade, Karan Singh, and Abby Van~Soest.
\newblock Provably efficient maximum entropy exploration.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Jang et~al.(2017)Jang, Gu, and Poole]{jang2017categorical}
Eric Jang, Shixiang Gu, and Ben Poole.
\newblock Categorical reparametrization with gumbel-softmax.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Jiang et~al.(2015)Jiang, Kulesza, and Singh]{jiang2015abstraction}
Nan Jiang, Alex Kulesza, and Satinder Singh.
\newblock Abstraction selection in model-based reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2015.

\bibitem[Jiang et~al.(2017)Jiang, Krishnamurthy, Agarwal, Langford, and
  Schapire]{jiang2017contextual}
Nan Jiang, Akshay Krishnamurthy, Alekh Agarwal, John Langford, and Robert~E
  Schapire.
\newblock Contextual decision processes with low {B}ellman rank are
  {PAC}-learnable.
\newblock In \emph{International Conference on Machine Learning}. JMLR. org,
  2017.

\bibitem[Jin et~al.(2019)Jin, Yang, Wang, and Jordan]{jin2019provably}
Chi Jin, Zhuoran Yang, Zhaoran Wang, and Michael~I Jordan.
\newblock Provably efficient reinforcement learning with linear function
  approximation.
\newblock \emph{arXiv:1907.05388}, 2019.

\bibitem[Jin et~al.(2020)Jin, Krishnamurthy, Simchowitz, and Yu]{jin2020reward}
Chi Jin, Akshay Krishnamurthy, Max Simchowitz, and Tiancheng Yu.
\newblock Reward-free exploration for reinforcement learning.
\newblock \emph{arXiv:2002.02794}, 2020.

\bibitem[Lattimore and Szepesvari(2019)]{lattimore2019learning}
Tor Lattimore and Csaba Szepesvari.
\newblock Learning with good feature representations in bandits and in rl with
  a generative model.
\newblock \emph{arXiv:1911.07676}, 2019.

\bibitem[Lattimore et~al.(2013)Lattimore, Hutter, Sunehag,
  et~al.]{lattimore2013sample}
Tor Lattimore, Marcus Hutter, Peter Sunehag, et~al.
\newblock The sample-complexity of general reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}. Journal of
  Machine Learning Research, 2013.

\bibitem[Littman and Sutton(2002)]{littman2002predictive}
Michael~L Littman and Richard~S Sutton.
\newblock Predictive representations of state.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2002.

\bibitem[Maurer et~al.(2016)Maurer, Pontil, and
  Romera-Paredes]{maurer2016benefit}
Andreas Maurer, Massimiliano Pontil, and Bernardino Romera-Paredes.
\newblock The benefit of multitask representation learning.
\newblock \emph{The Journal of Machine Learning Research}, 2016.

\bibitem[Misra et~al.(2019)Misra, Henaff, Krishnamurthy, and
  Langford]{misra2019kinematic}
Dipendra Misra, Mikael Henaff, Akshay Krishnamurthy, and John Langford.
\newblock Kinematic state abstraction and provably efficient rich-observation
  reinforcement learning.
\newblock \emph{arXiv:1911.05815}, 2019.

\bibitem[Modi et~al.(2020)Modi, Jiang, Tewari, and Singh]{modi2019sample}
Aditya Modi, Nan Jiang, Ambuj Tewari, and Satinder Singh.
\newblock Sample complexity of reinforcement learning using linearly combined
  model ensembles.
\newblock In \emph{Conference on Artificial Intelligence and Statistics}, 2020.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv:1807.03748}, 2018.

\bibitem[Ortner et~al.(2014)Ortner, Maillard, and Ryabko]{ortner2014selecting}
Ronald Ortner, Odalric-Ambrym Maillard, and Daniil Ryabko.
\newblock Selecting near-optimal approximate state representations in
  reinforcement learning.
\newblock In \emph{International Conference on Algorithmic Learning Theory}.
  Springer, 2014.

\bibitem[Osband and Van~Roy(2014)]{osband2014model}
Ian Osband and Benjamin Van~Roy.
\newblock Model-based reinforcement learning and the eluder dimension.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2014.

\bibitem[Pathak et~al.(2017)Pathak, Agrawal, Efros, and
  Darrell]{pathak2017curiosity}
Deepak Pathak, Pulkit Agrawal, Alexei~A Efros, and Trevor Darrell.
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition
  Workshops}, 2017.

\bibitem[Rendle et~al.(2010)Rendle, Freudenthaler, and
  Schmidt-Thieme]{rendle2010factorizing}
Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme.
\newblock Factorizing personalized {M}arkov chains for next-basket
  recommendation.
\newblock In \emph{International Conference on World Wide Web}, 2010.

\bibitem[Rothvo{\ss}(2017)]{rothvoss2017matching}
Thomas Rothvo{\ss}.
\newblock The matching polytope has exponential extension complexity.
\newblock \emph{Journal of the ACM}, 2017.

\bibitem[Russo and Van~Roy(2013)]{russo2013eluder}
Daniel Russo and Benjamin Van~Roy.
\newblock Eluder dimension and the sample complexity of optimistic exploration.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2013.

\bibitem[Singh et~al.(2004)Singh, James, and Rudary]{singh2004predictive}
Satinder Singh, Michael~R James, and Matthew~R Rudary.
\newblock Predictive state representations: a new theory for modeling dynamical
  systems.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, 2004.

\bibitem[Srinivas et~al.(2020)Srinivas, Laskin, and Abbeel]{srinivas2020curl}
Aravind Srinivas, Michael Laskin, and Pieter Abbeel.
\newblock Curl: Contrastive unsupervised representations for reinforcement
  learning.
\newblock \emph{arXiv:2004.04136}, 2020.

\bibitem[Sun et~al.(2019)Sun, Jiang, Krishnamurthy, Agarwal, and
  Langford]{sun2018model}
Wen Sun, Nan Jiang, Akshay Krishnamurthy, Alekh Agarwal, and John Langford.
\newblock Model-based {RL} in contextual decision processes: {PAC} bounds and
  exponential improvements over model-free approaches.
\newblock In \emph{Conference on Learning Theory}, 2019.

\bibitem[Tang et~al.(2017)Tang, Houthooft, Foote, Stooke, Chen, Duan, Schulman,
  DeTurck, and Abbeel]{tang2017exploration}
Haoran Tang, Rein Houthooft, Davis Foote, Adam Stooke, Xi~Chen, Yan Duan, John
  Schulman, Filip DeTurck, and Pieter Abbeel.
\newblock \#{E}xploration: A study of count-based exploration for deep
  reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Thon and Jaeger(2015)]{thon2015links}
Michael Thon and Herbert Jaeger.
\newblock Links between multiplicity automata, observable operator models and
  predictive state representations: a unified learning framework.
\newblock \emph{The Journal of Machine Learning Research}, 2015.

\bibitem[Tosh et~al.(2020)Tosh, Krishnamurthy, and Hsu]{tosh2020contrastive}
Christopher Tosh, Akshay Krishnamurthy, and Daniel Hsu.
\newblock Contrastive estimation reveals topic posterior information to linear
  models.
\newblock \emph{arXiv:2003.02234}, 2020.

\bibitem[Tsybakov(2008)]{tsybakov2008introduction}
Alexandre~B Tsybakov.
\newblock \emph{Introduction to nonparametric estimation}.
\newblock Springer Science \& Business Media, 2008.

\bibitem[Van~de Geer(2000)]{geer2000empirical}
Sara Van~de Geer.
\newblock \emph{Empirical Processes in M-estimation}.
\newblock Cambridge University Press, 2000.

\bibitem[Van~Roy and Dong(2019)]{van2019comments}
Benjamin Van~Roy and Shi Dong.
\newblock Comments on the {D}u-{K}akade-{W}ang-{Y}ang lower bounds.
\newblock \emph{arXiv:1911.07910}, 2019.

\bibitem[Wang et~al.(2019)Wang, Wang, Du, and Krishnamurthy]{wang2019optimism}
Yining Wang, Ruosong Wang, Simon~S Du, and Akshay Krishnamurthy.
\newblock Optimism in reinforcement learning with generalized linear function
  approximation.
\newblock \emph{arXiv:1912.04136}, 2019.

\bibitem[Welling and Teh(2011)]{welling2011bayesian}
Max Welling and Yee~W Teh.
\newblock Bayesian learning via stochastic gradient {L}angevin dynamics.
\newblock In \emph{International Conference on Machine Learning}, 2011.

\bibitem[Wen and Van~Roy(2013)]{wen2013efficient}
Zheng Wen and Benjamin Van~Roy.
\newblock Efficient exploration and value function generalization in
  deterministic systems.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2013.

\bibitem[Yang and Wang(2019{\natexlab{a}})]{yang2019sample}
Lin Yang and Mengdi Wang.
\newblock Sample-optimal parametric {Q}-learning using linearly additive
  features.
\newblock In \emph{International Conference on Machine Learning},
  2019{\natexlab{a}}.

\bibitem[Yang and Wang(2019{\natexlab{b}})]{yang2019reinforcement}
Lin~F Yang and Mengdi Wang.
\newblock Reinforcement leaning in feature space: Matrix bandit, kernels, and
  regret bound.
\newblock \emph{arXiv:1905.10389}, 2019{\natexlab{b}}.

\bibitem[Yannakakis(1991)]{yannakakis1991expressing}
Mihalis Yannakakis.
\newblock Expressing combinatorial optimization problems by linear programs.
\newblock \emph{Journal of Computer and System Sciences}, 1991.

\bibitem[Yao et~al.(2014)Yao, Szepesv{\'a}ri, Pires, and Zhang]{yao2014pseudo}
Hengshuai Yao, Csaba Szepesv{\'a}ri, Bernardo~Avila Pires, and Xinhua Zhang.
\newblock Pseudo-mdps and factored linear action models.
\newblock In \emph{IEEE Symposium on Adaptive Dynamic Programming and
  Reinforcement Learning}, 2014.

\bibitem[Zhang(2006)]{zhang2006from}
Tong Zhang.
\newblock From $\epsilon$-entropy to {KL}-entropy: Analysis of minimum
  information complexity density estimation.
\newblock \emph{The Annals of Statistics}, 2006.

\end{thebibliography}
