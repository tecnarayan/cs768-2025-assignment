
@misc{1972Education,
  title = {Education {{Amendments}} of 1972},
  year = {1972},
  month = jun,
  number = {92-318}
}

@book{1995Carson,
  title = {Carson {{V}}. {{Bethlehem Steel Corporation}}},
  year = {1995},
  publisher = {{United States Court of Appeals for the Seventh Circuit}},
  googlebooks = {NX1vvgAACAAJ},
  language = {en}
}

@inproceedings{abadi2016TensorFlow,
  title = {{{TensorFlow}}: {{A}} System for Large-Scale Machine Learning},
  shorttitle = {{{TensorFlow}}},
  booktitle = {12th {{USENIX Symposium}} on {{Operating Systems Design}} and {{Implementation}} ({{OSDI}} 16)},
  author = {Abadi, Martin and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  year = {2016},
  pages = {265--283},
  file = {/Users/yuekai/Documents/zotero/Abadi et al (2016) - TensorFlow.pdf}
}

@article{abbasi2019Fairness,
  title = {Fairness in Representation: Quantifying Stereotyping as a Representational Harm},
  shorttitle = {Fairness in Representation},
  author = {Abbasi, Mohsen and Friedler, Sorelle A. and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  year = {2019},
  month = jan,
  abstract = {While harms of allocation have been increasingly studied as part of the subfield of algorithmic fairness, harms of representation have received considerably less attention. In this paper, we formalize two notions of stereotyping and show how they manifest in later allocative harms within the machine learning pipeline. We also propose mitigation strategies and demonstrate their effectiveness on synthetic datasets.},
  archivePrefix = {arXiv},
  eprint = {1901.09565},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Abbasi et al (2019) - Fairness in representation.pdf},
  journal = {arXiv:1901.09565 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{abbe2017Community,
  title = {Community Detection and Stochastic Block Models: Recent Developments},
  shorttitle = {Community Detection and Stochastic Block Models},
  author = {Abbe, Emmanuel},
  year = {2017},
  month = mar,
  abstract = {The stochastic block model (SBM) is a random graph model with planted clusters. It is widely employed as a canonical model to study clustering and community detection, and provides generally a fertile ground to study the statistical and computational tradeoffs that arise in network and data sciences. This note surveys the recent developments that establish the fundamental limits for community detection in the SBM, both with respect to information-theoretic and computational thresholds, and for various recovery requirements such as exact, partial and weak recovery (a.k.a., detection). The main results discussed are the phase transitions for exact recovery at the Chernoff-Hellinger threshold, the phase transition for weak recovery at the Kesten-Stigum threshold, the optimal distortion-SNR tradeoff for partial recovery, the learning of the SBM parameters and the gap between information-theoretic and computational thresholds. The note also covers some of the algorithms developed in the quest of achieving the limits, in particular two-round algorithms via graph-splitting, semi-definite programming, linearized belief propagation, classical and nonbacktracking spectral methods. A few open problems are also discussed.},
  archivePrefix = {arXiv},
  eprint = {1703.10146},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Abbe (2017) - Community detection and stochastic block models.pdf},
  journal = {arXiv:1703.10146 [cs, math, stat]},
  keywords = {Computer Science - Computational Complexity,Computer Science - Information Theory,Computer Science - Social and Information Networks,Mathematics - Probability,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{abbe2017Communitya,
  title = {Community {{Detection}} on {{Euclidean Random Graphs}}},
  author = {Abbe, Emmanuel and Baccelli, Francois and Sankararaman, Abishek},
  year = {2017},
  month = jun,
  abstract = {We study the problem of community detection (CD) on Euclidean random geometric graphs where each vertex has two latent variables: a binary community label and a \$\textbackslash mathbb\{R\}\^d\$ valued location label which forms the support of a Poisson point process of intensity \$\textbackslash lambda\$. A random graph is then drawn with edge probabilities dependent on both the community and location labels. In contrast to the stochastic block model (SBM) that has no location labels, the resulting random graph contains many more short loops due to the geometric embedding. We consider the recovery of the community labels, partial and exact, using the random graph and the location labels. We establish phase transitions for both sparse and logarithmic degree regimes, and provide bounds on the location of the thresholds, conjectured to be tight in the case of exact recovery. We also show that the threshold of the distinguishability problem, i.e., the testing between our model and the null model without community labels exhibits no phase-transition and in particular, does not match the weak recovery threshold (in contrast to the SBM).},
  archivePrefix = {arXiv},
  eprint = {1706.09942},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Abbe et al (2017) - Community Detection on Euclidean Random Graphs.pdf},
  journal = {arXiv:1706.09942 [cs, math]},
  keywords = {Computer Science - Information Theory,Computer Science - Social and Information Networks,Mathematics - Probability},
  primaryClass = {cs, math}
}

@article{abbe2017Entrywise,
  title = {Entrywise {{Eigenvector Analysis}} of {{Random Matrices}} with {{Low Expected Rank}}},
  author = {Abbe, Emmanuel and Fan, Jianqing and Wang, Kaizheng and Zhong, Yiqiao},
  year = {2017},
  month = sep,
  abstract = {Recovering low-rank structures via eigenvector perturbation analysis is a common problem in statistical machine learning, such as in factor analysis, community detection, ranking, matrix completion, among others. While a large variety of results provide tight bounds on the average errors between empirical and population statistics of eigenvectors, fewer results are tight for entrywise analyses, which are critical for a number of problems such as community detection and ranking. This paper investigates the entrywise perturbation analysis for a large class of random matrices whose expectations are low-rank, including community detection, synchronization (\$\textbackslash mathbb\{Z\}\_2\$-spiked Wigner model) and matrix completion models. Denoting by \$\textbackslash\{u\_k\textbackslash\}\$, respectively \$\textbackslash\{u\_k\^*\textbackslash\}\$, the eigenvectors of a random matrix \$A\$, respectively \$\textbackslash mathbb\{E\} A\$, the paper characterizes cases for which \$\$u\_k \textbackslash approx \textbackslash frac\{A u\_k\^*\}\{\textbackslash lambda\_k\^*\}\$\$ serves as a first-order approximation under the \$\textbackslash ell\_\textbackslash infty\$ norm. The fact that the approximation is both tight and linear in the random matrix \$A\$ allows for sharp comparisons of \$u\_k\$ and \$u\_k\^*\$. In particular, it allows to compare the signs of \$u\_k\$ and \$u\_k\^*\$ even when \$\textbackslash | u\_k - u\_k\^*\textbackslash |\_\{\textbackslash infty\}\$ is large, which in turn allows to settle the conjecture in Abbe et al. (2016) that the spectral algorithm achieves exact recovery in the stochastic block model without any trimming or cleaning steps. The results are further extended to the perturbation of eigenspaces, providing new bounds for \$\textbackslash ell\_\textbackslash infty\$-type errors in noisy matrix completion.},
  archivePrefix = {arXiv},
  eprint = {1709.09565},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Abbe et al (2017) - Entrywise Eigenvector Analysis of Random Matrices with Low Expected Rank.pdf},
  journal = {arXiv:1709.09565 [math, stat]},
  keywords = {Mathematics - Probability,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{abebe2020Roles,
  title = {Roles for {{Computing}} in {{Social Change}}},
  author = {Abebe, Rediet and Barocas, Solon and Kleinberg, Jon and Levy, Karen and Raghavan, Manish and Robinson, David G.},
  year = {2020},
  month = jan,
  doi = {10.1145/3351095.3372871},
  abstract = {A recent normative turn in computer science has brought concerns about fairness, bias, and accountability to the core of the field. Yet recent scholarship has warned that much of this technical work treats problematic features of the status quo as fixed, and fails to address deeper patterns of injustice and inequality. While acknowledging these critiques, we posit that computational research has valuable roles to play in addressing social problems --- roles whose value can be recognized even from a perspective that aspires toward fundamental social change. In this paper, we articulate four such roles, through an analysis that considers the opportunities as well as the significant risks inherent in such work. Computing research can serve as a diagnostic, helping us to understand and measure social problems with precision and clarity. As a formalizer, computing shapes how social problems are explicitly defined --- changing how those problems, and possible responses to them, are understood. Computing serves as rebuttal when it illuminates the boundaries of what is possible through technical means. And computing acts as synecdoche when it makes long-standing social problems newly salient in the public eye. We offer these paths forward as modalities that leverage the particular strengths of computational work in the service of social change, without overclaiming computing's capacity to solve social problems on its own.},
  archivePrefix = {arXiv},
  eprint = {1912.04883},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Abebe et al (2020) - Roles for Computing in Social Change.pdf},
  journal = {arXiv:1912.04883 [cs]},
  keywords = {Computer Science - Computers and Society},
  primaryClass = {cs}
}

@article{abernethy2020Adaptive,
  title = {Adaptive {{Sampling}} to {{Reduce Disparate Performance}}},
  author = {Abernethy, Jacob and Awasthi, Pranjal and Kleindessner, Matth{\"a}us and Morgenstern, Jamie and Zhang, Jie},
  year = {2020},
  month = jun,
  abstract = {Existing methods for reducing disparate performance of a classifier across different demographic groups assume that one has access to a large data set, thereby focusing on the algorithmic aspect of optimizing overall performance subject to additional constraints. However, poor data collection and imbalanced data sets can severely affect the quality of these methods. In this work, we consider a setting where data collection and optimization are performed simultaneously. In such a scenario, a natural strategy to mitigate the performance difference of the classifier is to provide additional training data drawn from the demographic groups that are worse off. In this paper, we propose to consistently follow this strategy throughout the whole training process and to guide the resulting classifier towards equal performance on the different groups by adaptively sampling each data point from the group that is currently disadvantaged. We provide a rigorous theoretical analysis of our approach in a simplified one-dimensional setting and an extensive experimental evaluation on numerous real-world data sets, including a case study on the data collected during the Flint water crisis.},
  archivePrefix = {arXiv},
  eprint = {2006.06879},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Abernethy et al (2020) - Adaptive Sampling to Reduce Disparate Performance.pdf;/Users/yuekai/Zotero/storage/L3GPGI6K/2006.html},
  journal = {arXiv:2006.06879 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@book{absil2008Optimization,
  title = {Optimization Algorithms on Matrix Manifolds},
  author = {Absil, P.-A. and Mahony, R. and Sepulchre, R.},
  year = {2008},
  publisher = {{Princeton University Press}},
  address = {{Princeton, N.J. ; Woodstock}},
  annotation = {OCLC: ocn174129993},
  file = {/Users/yuekai/Documents/zotero/Absil et al (2008) - Optimization algorithms on matrix manifolds.pdf},
  isbn = {978-0-691-13298-3},
  language = {en},
  lccn = {QA402.5 .A27 2008}
}

@incollection{absil2013Extrinsic,
  title = {An {{Extrinsic Look}} at the {{Riemannian Hessian}}},
  booktitle = {Geometric {{Science}} of {{Information}}},
  author = {Absil, P. -A. and Mahony, Robert and Trumpf, Jochen},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Nielsen, Frank and Barbaresco, Fr{\'e}d{\'e}ric},
  year = {2013},
  volume = {8085},
  pages = {361--368},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-40020-9_39},
  abstract = {Let f be a real-valued function on a Riemannian submanifold of a Euclidean space, and let f\textasciimacron{} be a local extension of f . We show that the Riemannian Hessian of f can be conveniently obtained from the Euclidean gradient and Hessian of f\textasciimacron{} by means of two manifoldspecific objects: the orthogonal projector onto the tangent space and the Weingarten map. Expressions for the Weingarten map are provided on various specific submanifolds.},
  file = {/Users/yuekai/Documents/zotero/Absil et al (2013) - An Extrinsic Look at the Riemannian Hessian.pdf},
  isbn = {978-3-642-40019-3 978-3-642-40020-9},
  language = {en}
}

@article{adamczak2005Logarithmic,
  title = {Logarithmic {{Sobolev Inequalities}} and {{Concentration}} of {{Measure}} for {{Convex Functions}} and {{Polynomial Chaoses}}},
  author = {Adamczak, Radoslaw},
  year = {2005},
  month = may,
  abstract = {We prove logarithmic Sobolev inequalities and concentration results for convex functions and a class of product random vectors. The results are used to derive tail and moment inequalities for chaos variables (in spirit of Talagrand and Arcones, Gine). We also show that the same proof may be used for chaoses generated by log-concave random variables, recovering results by Lochowski and present an application to exponential integrability of Rademacher chaos.},
  archivePrefix = {arXiv},
  eprint = {math/0505175},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Adamczak (2005) - Logarithmic Sobolev Inequalities and Concentration of Measure for Convex.pdf},
  journal = {arXiv:math/0505175},
  keywords = {Mathematics - Probability}
}

@article{adamczak2014note,
  title = {A Note on the {{Hanson}}-{{Wright}} Inequality for Random Vectors with Dependencies},
  author = {Adamczak, Rados{\l}aw},
  year = {2014},
  month = sep,
  abstract = {We prove that quadratic forms in isotropic random vectors \$X\$ in \$\textbackslash mathbb\{R\}\^n\$, possessing the convex concentration property with constant \$K\$, satisfy the Hanson-Wright inequality with constant \$CK\$, where \$C\$ is an absolute constant, thus eliminating the logarithmic (in the dimension) factors in a recent estimate by Vu and Wang. We also show that the concentration inequality for all Lipschitz functions implies a uniform version of the Hanson-Wright inequality for suprema of quadratic forms (in the spirit of the inequalities by Borell, Arcones-Gin\textbackslash 'e and Ledoux-Talagrand). Previous results of this type relied on stronger isoperimetric properties of \$X\$ and in some cases provided an upper bound on the deviations rather than a concentration inequality. In the last part of the paper we show that the uniform version of the Hanson-Wright inequality for Gaussian vectors can be used to recover a recent concentration inequality for empirical estimators of the covariance operator of \$B\$-valued Gaussian variables due to Koltchinskii and Lounici.},
  archivePrefix = {arXiv},
  eprint = {1409.8457},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Adamczak (2014) - A note on the Hanson-Wright inequality for random vectors with dependencies.pdf},
  journal = {arXiv:1409.8457 [math]},
  keywords = {Mathematics - Probability},
  primaryClass = {math}
}

@article{adams2007Bayesian,
  title = {Bayesian {{Online Changepoint Detection}}},
  author = {Adams, Ryan Prescott and MacKay, David J. C.},
  year = {2007},
  month = oct,
  abstract = {Changepoints are abrupt variations in the generative parameters of a data sequence. Online detection of changepoints is useful in modelling and prediction of time series in application areas such as finance, biometrics, and robotics. While frequentist methods have yielded online filtering and prediction techniques, most Bayesian papers have focused on the retrospective segmentation problem. Here we examine the case where the model parameters before and after the changepoint are independent and we derive an online algorithm for exact inference of the most recent changepoint. We compute the probability distribution of the length of the current ``run,'' or time since the last changepoint, using a simple message-passing algorithm. Our implementation is highly modular so that the algorithm may be applied to a variety of types of data. We illustrate this modularity by demonstrating the algorithm on three different real-world data sets.},
  archivePrefix = {arXiv},
  eprint = {0710.3742},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Adams, MacKay (2007) - Bayesian Online Changepoint Detection.pdf},
  journal = {arXiv:0710.3742 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{addario-berry2010combinatorial,
  title = {On Combinatorial Testing Problems},
  author = {{Addario-Berry}, Louigi and Broutin, Nicolas and Devroye, Luc and Lugosi, G{\'a}bor},
  year = {2010},
  month = oct,
  volume = {38},
  pages = {3063--3092},
  issn = {0090-5364},
  doi = {10.1214/10-AOS817},
  abstract = {We study a class of hypothesis testing problems in which, upon observing the realization of an \$n\$-dimensional Gaussian vector, one has to decide whether the vector was drawn from a standard normal distribution or, alternatively, whether there is a subset of the components belonging to a certain given class of sets whose elements have been ``contaminated,'' that is, have a mean different from zero. We establish some general conditions under which testing is possible and others under which testing is hopeless with a small risk. The combinatorial and geometric structure of the class of sets is shown to play a crucial role. The bounds are illustrated on various examples.},
  archivePrefix = {arXiv},
  eprint = {0908.3437},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Addario-Berry et al (2010) - On combinatorial testing problems.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Combinatorics,Mathematics - Statistics Theory},
  language = {en},
  number = {5}
}

@article{adebayo2016Iterative,
  title = {Iterative {{Orthogonal Feature Projection}} for {{Diagnosing Bias}} in {{Black}}-{{Box Models}}},
  author = {Adebayo, Julius and Kagal, Lalana},
  year = {2016},
  month = nov,
  abstract = {Predictive models are increasingly deployed for the purpose of determining access to services such as credit, insurance, and employment. Despite potential gains in productivity and efficiency, several potential problems have yet to be addressed, particularly the potential for unintentional discrimination. We present an iterative procedure, based on orthogonal projection of input attributes, for enabling interpretability of black-box predictive models. Through our iterative procedure, one can quantify the relative dependence of a black-box model on its input attributes.The relative significance of the inputs to a predictive model can then be used to assess the fairness (or discriminatory extent) of such a model.},
  archivePrefix = {arXiv},
  eprint = {1611.04967},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Adebayo, Kagal (2016) - Iterative Orthogonal Feature Projection for Diagnosing Bias in Black-Box Models.pdf},
  journal = {arXiv:1611.04967 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{adebayo2018Sanity,
  title = {Sanity {{Checks}} for {{Saliency Maps}}},
  author = {Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
  year = {2018},
  month = oct,
  abstract = {Saliency methods have emerged as a popular tool to highlight features in an input deemed relevant for the prediction of a learned model. Several saliency methods have been proposed, often guided by visual appeal on image data. In this work, we propose an actionable methodology to evaluate what kinds of explanations a given method can and cannot provide. We find that reliance, solely, on visual assessment can be misleading. Through extensive experiments we show that some existing saliency methods are independent both of the model and of the data generating process. Consequently, methods that fail the proposed tests are inadequate for tasks that are sensitive to either data or model, such as, finding outliers in the data, explaining the relationship between inputs and outputs that the model learned, and debugging the model. We interpret our findings through an analogy with edge detection in images, a technique that requires neither training data nor model. Theory in the case of a linear model and a single-layer convolutional neural network supports our experimental findings.},
  archivePrefix = {arXiv},
  eprint = {1810.03292},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Adebayo et al (2018) - Sanity Checks for Saliency Maps.pdf},
  journal = {arXiv:1810.03292 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@book{adler2007Random,
  title = {Random Fields and Geometry},
  author = {Adler, Robert J. and Taylor, Jonathan E.},
  year = {2007},
  publisher = {{Springer}},
  address = {{New York}},
  isbn = {978-0-387-48112-8 978-0-387-48116-6},
  language = {en},
  lccn = {QA274.45 .A345 2007},
  number = {115},
  series = {Springer Monographs in Mathematics}
}

@article{adler2016Auditing,
  title = {Auditing {{Black}}-Box {{Models}} for {{Indirect Influence}}},
  author = {Adler, Philip and Falk, Casey and Friedler, Sorelle A. and Rybeck, Gabriel and Scheidegger, Carlos and Smith, Brandon and Venkatasubramanian, Suresh},
  year = {2016},
  month = feb,
  abstract = {Data-trained predictive models see widespread use, but for the most part they are used as black boxes which output a prediction or score. It is therefore hard to acquire a deeper understanding of model behavior, and in particular how different features influence the model prediction. This is important when interpreting the behavior of complex models, or asserting that certain problematic attributes (like race or gender) are not unduly influencing decisions. In this paper, we present a technique for auditing black-box models, which lets us study the extent to which existing models take advantage of particular features in the dataset, without knowing how the models work. Our work focuses on the problem of indirect influence: how some features might indirectly influence outcomes via other, related features. As a result, we can find attribute influences even in cases where, upon further direct examination of the model, the attribute is not referred to by the model at all. Our approach does not require the black-box model to be retrained. This is important if (for example) the model is only accessible via an API, and contrasts our work with other methods that investigate feature influence like feature selection. We present experimental evidence for the effectiveness of our procedure using a variety of publicly available datasets and models. We also validate our procedure using techniques from interpretable learning and feature selection, as well as against other black-box auditing procedures.},
  archivePrefix = {arXiv},
  eprint = {1602.07043},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Adler et al (2016) - Auditing Black-box Models for Indirect Influence.pdf},
  journal = {arXiv:1602.07043 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{agarwal2018Reductions,
  title = {A {{Reductions Approach}} to {{Fair Classification}}},
  author = {Agarwal, Alekh and Beygelzimer, Alina and Dud{\'i}k, Miroslav and Langford, John and Wallach, Hanna},
  year = {2018},
  month = jul,
  abstract = {We present a systematic approach for achieving fairness in a binary classification setting. While we focus on two well-known quantitative definitions of fairness, our approach encompasses many other previously studied definitions as special cases. The key idea is to reduce fair classification to a sequence of cost-sensitive classification problems, whose solutions yield a randomized classifier with the lowest (empirical) error subject to the desired constraints. We introduce two reductions that work for any representation of the cost-sensitive classifier and compare favorably to prior baselines on a variety of data sets, while overcoming several of their disadvantages.},
  archivePrefix = {arXiv},
  eprint = {1803.02453},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Agarwal et al (2018) - A Reductions Approach to Fair Classification.pdf},
  journal = {arXiv:1803.02453 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@inproceedings{agarwal2019Estimating,
  title = {Estimating {{Position Bias}} without {{Intrusive Interventions}}},
  booktitle = {Proceedings of the {{Twelfth ACM International Conference}} on {{Web Search}} and {{Data Mining}}},
  author = {Agarwal, Aman and Zaitsev, Ivan and Wang, Xuanhui and Li, Cheng and Najork, Marc and Joachims, Thorsten},
  year = {2019},
  month = jan,
  pages = {474--482},
  publisher = {{Association for Computing Machinery}},
  address = {{Melbourne VIC, Australia}},
  doi = {10.1145/3289600.3291017},
  abstract = {Presentation bias is one of the key challenges when learning from implicit feedback in search engines, as it confounds the relevance signal. While it was recently shown how counterfactual learning-to-rank (LTR) approaches \textbackslash citeJoachims/etal/17a can provably overcome presentation bias when observation propensities are known, it remains to show how to effectively estimate these propensities. In this paper, we propose the first method for producing consistent propensity estimates without manual relevance judgments, disruptive interventions, or restrictive relevance modeling assumptions. First, we show how to harvest a specific type of intervention data from historic feedback logs of multiple different ranking functions, and show that this data is sufficient for consistent propensity estimation in the position-based model. Second, we propose a new extremum estimator that makes effective use of this data. In an empirical evaluation, we find that the new estimator provides superior propensity estimates in two real-world systems -- Arxiv Full-text Search and Google Drive Search. Beyond these two points, we find that the method is robust to a wide range of settings in simulation studies.},
  file = {/Users/yuekai/Documents/zotero/Agarwal et al (2019) - Estimating Position Bias without Intrusive Interventions.pdf},
  isbn = {978-1-4503-5940-5},
  series = {{{WSDM}} '19}
}

@article{agarwal2019Fair,
  title = {Fair {{Regression}}: {{Quantitative Definitions}} and {{Reduction}}-Based {{Algorithms}}},
  shorttitle = {Fair {{Regression}}},
  author = {Agarwal, Alekh and Dud{\'i}k, Miroslav and Wu, Zhiwei Steven},
  year = {2019},
  month = may,
  abstract = {In this paper, we study the prediction of a real-valued target, such as a risk score or recidivism rate, while guaranteeing a quantitative notion of fairness with respect to a protected attribute such as gender or race. We call this class of problems \textbackslash emph\{fair regression\}. We propose general schemes for fair regression under two notions of fairness: (1) statistical parity, which asks that the prediction be statistically independent of the protected attribute, and (2) bounded group loss, which asks that the prediction error restricted to any protected group remain below some pre-determined level. While we only study these two notions of fairness, our schemes are applicable to arbitrary Lipschitz-continuous losses, and so they encompass least-squares regression, logistic regression, quantile regression, and many other tasks. Our schemes only require access to standard risk minimization algorithms (such as standard classification or least-squares regression) while providing theoretical guarantees on the optimality and fairness of the obtained solutions. In addition to analyzing theoretical properties of our schemes, we empirically demonstrate their ability to uncover fairness--accuracy frontiers on several standard datasets.},
  archivePrefix = {arXiv},
  eprint = {1905.12843},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Agarwal et al (2019) - Fair Regression.pdf},
  journal = {arXiv:1905.12843 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{agarwal2019Optimality,
  title = {Optimality and {{Approximation}} with {{Policy Gradient Methods}} in {{Markov Decision Processes}}},
  author = {Agarwal, Alekh and Kakade, Sham M. and Lee, Jason D. and Mahajan, Gaurav},
  year = {2019},
  month = aug,
  abstract = {Policy gradient methods are among the most effective methods in challenging reinforcement learning problems with large state and/or action spaces. However, little is known about even their most basic theoretical convergence properties, including: if and how fast they converge to a globally optimal solution (say with a sufficiently rich policy class); how they cope with approximation error due to using a restricted class of parametric policies; or their finite sample behavior. Such characterizations are important not only to compare these methods to their approximate value function counterparts (where such issues are relatively well understood, at least in the worst case) but also to help with more principled approaches to algorithm design. This work provides provable characterizations of computational, approximation, and sample size issues with regards to policy gradient methods in the context of discounted Markov Decision Processes (MDPs). We focus on both: 1) "tabular" policy parameterizations, where the optimal policy is contained in the class and where we show global convergence to the optimal policy, and 2) restricted policy classes, which may not contain the optimal policy and where we provide agnostic learning results. One insight of this work is in formalizing the importance how a favorable initial state distribution provides a means to circumvent worst-case exploration issues. Overall, these results place policy gradient methods under a solid theoretical footing, analogous to the global convergence guarantees of iterative value function based algorithms.},
  archivePrefix = {arXiv},
  eprint = {1908.00261},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Agarwal et al (2019) - Optimality and Approximation with Policy Gradient Methods in Markov Decision.pdf},
  journal = {arXiv:1908.00261 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{agterberg2019Vertex,
  title = {Vertex {{Nomination}}, {{Consistent Estimation}}, and {{Adversarial Modification}}},
  author = {Agterberg, Joshua and Park, Youngser and Larson, Jonathan and White, Christopher and Priebe, Carey E. and Lyzinski, Vince},
  year = {2019},
  month = may,
  abstract = {Given a pair of graphs \$G\_1\$ and \$G\_2\$ and a vertex set of interest in \$G\_1\$, the vertex nomination problem seeks to find the corresponding vertices of interest in \$G\_2\$ (if they exist) and produce a rank list of the vertices in \$G\_2\$, with the corresponding vertices of interest in \$G\_2\$ concentrating, ideally, at the top of the rank list. In this paper we study the effect of an adversarial contamination model on the performance of a spectral graph embedding-based vertex nomination scheme. In both real and simulated examples, we demonstrate that this vertex nomination scheme performs effectively in the uncontaminated setting; adversarial network contamination adversely impacts the performance of our VN scheme; and network regularization successfully mitigates the impact of the contamination. In addition to furthering the theoretic basis of consistency in vertex nomination, the adversarial noise model posited herein is grounded in theoretical developments that allow us to frame the role of an adversary in terms of maximal vertex nomination consistency classes.},
  archivePrefix = {arXiv},
  eprint = {1905.01776},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Agterberg et al (2019) - Vertex Nomination, Consistent Estimation, and Adversarial Modification.pdf},
  journal = {arXiv:1905.01776 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Computation,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{agueh2011Barycenters,
  title = {Barycenters in the {{Wasserstein Space}}},
  author = {Agueh, Martial and Carlier, Guillaume},
  year = {2011},
  month = jan,
  volume = {43},
  pages = {904--924},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1410},
  doi = {10.1137/100805741},
  abstract = {In this paper, we introduce a notion of barycenter in the Wasserstein space which generalizes McCann's interpolation to the case of more than two measures. We provide existence, uniqueness, characterizations, and regularity of the barycenter and relate it to the multimarginal optimal transport problem considered by Gangbo and \'Swi\k{e}ch in [Comm. Pure Appl. Math., 51 (1998), pp. 23\textendash 45]. We also consider some examples and, in particular, rigorously solve the Gaussian case. We finally discuss convexity of functionals in the Wasserstein space.},
  file = {/Users/yuekai/Documents/zotero/Agueh, Carlier (2011) - Barycenters in the Wasserstein Space.pdf},
  journal = {SIAM Journal on Mathematical Analysis},
  number = {2}
}

@article{aguirregabiria2010Dynamic,
  title = {Dynamic Discrete Choice Structural Models: {{A}} Survey},
  shorttitle = {Dynamic Discrete Choice Structural Models},
  author = {Aguirregabiria, Victor and Mira, Pedro},
  year = {2010},
  month = may,
  volume = {156},
  pages = {38--67},
  issn = {03044076},
  doi = {10.1016/j.jeconom.2009.09.007},
  abstract = {This paper reviews methods for the estimation of dynamic discrete choice structural models and discusses related econometric issues. We consider single-agent models, competitive equilibrium models and dynamic games. The methods are illustrated with descriptions of empirical studies which have applied these techniques to problems in different areas of economics. Programming codes for some of the estimation methods are available in a companion web page.},
  file = {/Users/yuekai/Documents/zotero/Aguirregabiria, Mira (2010) - Dynamic discrete choice structural models.pdf},
  journal = {Journal of Econometrics},
  language = {en},
  number = {1}
}

@article{ahuja2020Invariant,
  title = {Invariant {{Risk Minimization Games}}},
  author = {Ahuja, Kartik and Shanmugam, Karthikeyan and Varshney, Kush and Dhurandhar, Amit},
  year = {2020},
  month = feb,
  abstract = {The standard risk minimization paradigm of machine learning is brittle when operating in environments whose test distributions are different from the training distribution due to spurious correlations. Training on data from many environments and finding invariant predictors reduces the effect of spurious features by concentrating models on features that have a causal relationship with the outcome. In this work, we pose such invariant risk minimization as finding the Nash equilibrium of an ensemble game among several environments. By doing so, we develop a simple training algorithm that uses best response dynamics and, in our experiments, yields similar or better empirical accuracy with much lower variance than the challenging bi-level optimization problem of Arjovsky et.al. (2019). One key theoretical contribution is showing that the set of Nash equilibria for the proposed game are equivalent to the set of invariant predictors for any finite number of environments, even with nonlinear classifiers and transformations. As a result, our method also retains the generalization guarantees to a large set of environments shown in Arjovsky et.al. (2019). The proposed algorithm adds to the collection of successful game-theoretic machine learning algorithms such as generative adversarial networks.},
  archivePrefix = {arXiv},
  eprint = {2002.04692},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ahuja et al (2020) - Invariant Risk Minimization Games.pdf},
  journal = {arXiv:2002.04692 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{aivodji2019Fairwashing,
  title = {Fairwashing: The Risk of Rationalization},
  shorttitle = {Fairwashing},
  author = {A{\"i}vodji, Ulrich and Arai, Hiromi and Fortineau, Olivier and Gambs, S{\'e}bastien and Hara, Satoshi and Tapp, Alain},
  year = {2019},
  month = may,
  abstract = {Black-box explanation is the problem of explaining how a machine learning model -- whose internal logic is hidden to the auditor and generally complex -- produces its outcomes. Current approaches for solving this problem include model explanation, outcome explanation as well as model inspection. While these techniques can be beneficial by providing interpretability, they can be used in a negative manner to perform fairwashing, which we define as promoting the false perception that a machine learning model respects some ethical values. In particular, we demonstrate that it is possible to systematically rationalize decisions taken by an unfair black-box model using the model explanation as well as the outcome explanation approaches with a given fairness metric. Our solution, LaundryML, is based on a regularized rule list enumeration algorithm whose objective is to search for fair rule lists approximating an unfair black-box model. We empirically evaluate our rationalization technique on black-box models trained on real-world datasets and show that one can obtain rule lists with high fidelity to the black-box model while being considerably less unfair at the same time.},
  archivePrefix = {arXiv},
  eprint = {1901.09749},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Aïvodji et al (2019) - Fairwashing.pdf},
  journal = {arXiv:1901.09749 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{alexandari2020EM,
  title = {{{EM}} with {{Bias}}-{{Corrected Calibration}} Is {{Hard}}-{{To}}-{{Beat}} at {{Label Shift Adaptation}}},
  author = {Alexandari, Amr and Kundaje, Anshul and Shrikumar, Avanti},
  year = {2020},
  month = jan,
  abstract = {Label shift refers to the phenomenon where the prior class probability p(y) changes between the training and test distributions, while the conditional probability p(x|y) stays fixed. Label shift arises in settings like medical diagnosis, where a classifier trained to predict disease given symptoms must be adapted to scenarios where the baseline prevalence of the disease is different. Given estimates of p(y|x) from a predictive model, Saerens et al. (2002) proposed an efficient EM algorithm to correct for label shift that does not require model retraining. A limiting assumption of this algorithm is that p(y|x) is calibrated, which is not true of modern neural networks. Recently, Black Box Shift Learning (BBSL) (Lipton et al., 2018) and Regularized Learning under Label Shifts (RLLS) (Azizzadenesheli et al., 2019) have emerged as state-of-the-art techniques to cope with label shift when a classifier does not output calibrated probabilities. However, both BBSL and RLLS require model retraining with importance weights, which poses challenges in practice (Byrd and Lipton, 2019), and neither has been benchmarked against EM. Here we show that by combining EM with a type of calibration we call bias-corrected calibration, we outperform both BBSL and RLLS across diverse datasets and distribution shifts. We further show that the EM objective is concave and bounded, and introduce a theoretically principled strategy for estimating source-domain priors that improves robustness to poor calibration. This work demonstrates that EM with appropriate calibration is a formidable and efficient baseline that future work in label shift adaptation should be compared against. Colab notebooks reproducing experiments are available at (anonymized link): https://github.com/blindauth/labelshiftexperiments},
  archivePrefix = {arXiv},
  eprint = {1901.06852},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Alexandari et al (2020) - EM with Bias-Corrected Calibration is Hard-To-Beat at Label Shift Adaptation.pdf},
  journal = {arXiv:1901.06852 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{ali2018ContinuousTime,
  title = {A {{Continuous}}-{{Time View}} of {{Early Stopping}} for {{Least Squares}}},
  author = {Ali, Alnur and Kolter, J. Zico and Tibshirani, Ryan J.},
  year = {2018},
  month = oct,
  abstract = {We study the statistical properties of the iterates generated by gradient descent, applied to the fundamental problem of least squares regression. We take a continuous-time view, i.e., consider infinitesimal step sizes in gradient descent, in which case the iterates form a trajectory called gradient flow. Our primary focus is to compare the risk of gradient flow to that of ridge regression. Under the calibration \$t=1/\textbackslash lambda\$---where \$t\$ is the time parameter in gradient flow, and \$\textbackslash lambda\$ the tuning parameter in ridge regression---we prove that the risk of gradient flow is no less than 1.69 times that of ridge, along the entire path (for all \$t \textbackslash geq 0\$). This holds in finite samples with very weak assumptions on the data model (in particular, with no assumptions on the features \$X\$). We prove that the same relative risk bound holds for prediction risk, in an average sense over the underlying signal \$\textbackslash beta\_0\$. Finally, we examine limiting risk expressions (under standard Marchenko-Pastur asymptotics), and give supporting numerical experiments.},
  archivePrefix = {arXiv},
  eprint = {1810.10082},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ali et al (2018) - A Continuous-Time View of Early Stopping for Least Squares.pdf},
  journal = {arXiv:1810.10082 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{ali2019Discrimination,
  title = {Discrimination through Optimization: {{How Facebook}}'s Ad Delivery Can Lead to Skewed Outcomes},
  shorttitle = {Discrimination through Optimization},
  author = {Ali, Muhammad and Sapiezynski, Piotr and Bogen, Miranda and Korolova, Aleksandra and Mislove, Alan and Rieke, Aaron},
  year = {2019},
  month = apr,
  abstract = {The enormous financial success of online advertising platforms is partially due to the precise targeting features they offer. Although researchers and journalists have found many ways that advertisers can target---or exclude---particular groups of users seeing their ads, comparatively little attention has been paid to the implications of the platform's ad delivery process, comprised of the platform's choices about who should see an ad. It has been hypothesized that this process can "skew" ad delivery in ways that the advertisers do not intend, making some users less likely than others to see particular ads based on their demographic characteristics. In this paper, we demonstrate that such skewed delivery occurs on Facebook, due to market and financial optimization effects as well as the platform's own predictions about the "relevance" of ads to different groups of users. We find that both the advertiser's budget and the content of the ad each significantly contribute to the skew of Facebook's ad delivery. Critically, we observe significant skew in delivery along gender and racial lines for "real" ads for employment and housing opportunities despite neutral targeting parameters. Our results demonstrate previously unknown mechanisms that can lead to potentially discriminatory ad delivery, even when advertisers set their targeting parameters to be highly inclusive. This underscores the need for policymakers and platforms to carefully consider the role of the ad delivery optimization run by ad platforms themselves---and not just the targeting choices of advertisers---in preventing discrimination in digital advertising.},
  archivePrefix = {arXiv},
  eprint = {1904.02095},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ali et al (2019) - Discrimination through optimization.pdf},
  journal = {arXiv:1904.02095 [cs]},
  keywords = {Computer Science - Computers and Society},
  primaryClass = {cs}
}

@article{aliverti2018Removing,
  title = {Removing the Influence of a Group Variable in High-Dimensional Predictive Modelling},
  author = {Aliverti, Emanuele and Lum, Kristian and Johndrow, James E. and Dunson, David B.},
  year = {2018},
  month = oct,
  abstract = {Predictive modelling relies on the assumption that observations used for
training are representative of the data that will be encountered in future
samples. In a variety of applications, this assumption is severely violated,
since observational training data are often collected under sampling processes
which are systematically biased with respect to group membership. Without
explicit adjustment, machine learning algorithms can produce predictions that
have poor generalization error with performance that varies widely by group. We
propose a method to pre-process the training data, producing an adjusted
dataset that is independent of the group variable with minimum information
loss. We develop a conceptually simple approach for creating such a set of
features in high dimensional settings based on a constrained form of principal
components analysis. The resulting dataset can then be used in any predictive
algorithm with the guarantee that predictions will be independent of the group
variable. We develop a scalable algorithm for implementing the method, along
with theory support in the form of independence guarantees and optimality. The
method is illustrated on some simulation examples and applied to two real
examples: removing machine-specific correlations from brain scan data, and
removing race and ethnicity information from a dataset used to predict
recidivism.},
  file = {/Users/yuekai/Documents/zotero/Aliverti et al (2018) - Removing the influence of a group variable in high-dimensional predictive.pdf},
  language = {en}
}

@article{allen-zhu2018Convergence,
  title = {A {{Convergence Theory}} for {{Deep Learning}} via {{Over}}-{{Parameterization}}},
  author = {{Allen-Zhu}, Zeyuan and Li, Yuanzhi and Song, Zhao},
  year = {2018},
  month = nov,
  abstract = {Deep neural networks (DNNs) have demonstrated dominating performance in many fields; since AlexNet, networks used in practice are going wider and deeper. On the theoretical side, a long line of works has been focusing on training neural networks with one hidden layer. The theory of multi-layer networks remains largely unsettled. In this work, we prove why stochastic gradient descent (SGD) can find \$\textbackslash textit\{global minima\}\$ on the training objective of DNNs in \$\textbackslash textit\{polynomial time\}\$. We only make two assumptions: the inputs are non-degenerate and the network is over-parameterized. The latter means the network width is sufficiently large: \$\textbackslash textit\{polynomial\}\$ in \$L\$, the number of layers and in \$n\$, the number of samples. Our key technique is to derive that, in a sufficiently large neighborhood of the random initialization, the optimization landscape is almost-convex and semi-smooth even with ReLU activations. This implies an equivalence between over-parameterized neural networks and neural tangent kernel (NTK) in the finite (and polynomial) width setting. As concrete examples, starting from randomly initialized weights, we prove that SGD can attain 100\% training accuracy in classification tasks, or minimize regression loss in linear convergence speed, with running time polynomial in \$n,L\$. Our theory applies to the widely-used but non-smooth ReLU activation, and to any smooth and possibly non-convex loss functions. In terms of network architectures, our theory at least applies to fully-connected neural networks, convolutional neural networks (CNN), and residual neural networks (ResNet).},
  archivePrefix = {arXiv},
  eprint = {1811.03962},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Allen-Zhu et al (2018) - A Convergence Theory for Deep Learning via Over-Parameterization.pdf},
  journal = {arXiv:1811.03962 [cs, math, stat]},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{allen2016three,
  title = {The `Three Black Teenagers' Search Shows It Is Society, Not {{Google}}, That Is Racist | {{Antoine Allen}}},
  author = {Allen, Antoine},
  year = {2016},
  month = jun,
  issn = {0261-3077},
  abstract = {Twitter outrage over image search results of black and white teens is misdirected. We must address the prejudice that feeds such negative portrayals},
  chapter = {Opinion},
  journal = {The Guardian},
  language = {en-GB}
}

@article{alvarez-melis2019Optimal,
  title = {Towards {{Optimal Transport}} with {{Global Invariances}}},
  author = {{Alvarez-Melis}, David and Jegelka, Stefanie and Jaakkola, Tommi S.},
  year = {2019},
  month = feb,
  abstract = {Many problems in machine learning involve calculating correspondences between sets of objects, such as point clouds or images. Discrete optimal transport provides a natural and successful approach to such tasks whenever the two sets of objects can be represented in the same space, or at least distances between them can be directly evaluated. Unfortunately neither requirement is likely to hold when object representations are learned from data. Indeed, automatically derived representations such as word embeddings are typically fixed only up to some global transformations, for example, reflection or rotation. As a result, pairwise distances across two such instances are ill-defined without specifying their relative transformation. In this work, we propose a general framework for optimal transport in the presence of latent global transformations. We cast the problem as a joint optimization over transport couplings and transformations chosen from a flexible class of invariances, propose algorithms to solve it, and show promising results in various tasks, including a popular unsupervised word translation benchmark.},
  archivePrefix = {arXiv},
  eprint = {1806.09277},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Alvarez-Melis et al (2019) - Towards Optimal Transport with Global Invariances.pdf},
  journal = {arXiv:1806.09277 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{alvarez-melis2020Unsupervised,
  title = {Unsupervised {{Hierarchy Matching}} with {{Optimal Transport}} over {{Hyperbolic Spaces}}},
  author = {{Alvarez-Melis}, David and Mroueh, Youssef and Jaakkola, Tommi S.},
  year = {2020},
  month = may,
  abstract = {This paper focuses on the problem of unsupervised alignment of hierarchical data such as ontologies or lexical databases. This is a problem that appears across areas, from natural language processing to bioinformatics, and is typically solved by appeal to outside knowledge bases and label-textual similarity. In contrast, we approach the problem from a purely geometric perspective: given only a vector-space representation of the items in the two hierarchies, we seek to infer correspondences across them. Our work derives from and interweaves hyperbolic-space representations for hierarchical data, on one hand, and unsupervised word-alignment methods, on the other. We first provide a set of negative results showing how and why Euclidean methods fail in this hyperbolic setting. We then propose a novel approach based on optimal transport over hyperbolic spaces, and show that it outperforms standard embedding alignment techniques in various experiments on cross-lingual WordNet alignment and ontology matching tasks.},
  archivePrefix = {arXiv},
  eprint = {1911.02536},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Alvarez-Melis et al (2020) - Unsupervised Hierarchy Matching with Optimal Transport over Hyperbolic Spaces.pdf},
  journal = {arXiv:1911.02536 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{amari2019Information,
  title = {Information {{Geometry}} for {{Regularized Optimal Transport}} and {{Barycenters}} of {{Patterns}}},
  author = {Amari, Shun-ichi and Karakida, Ryo and Oizumi, Masafumi and Cuturi, Marco},
  year = {2019},
  month = may,
  volume = {31},
  pages = {827--848},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco_a_01178},
  abstract = {We propose a new divergence on the manifold of probability distributions, building on the entropic regularization of optimal transportation problems. As Cuturi ( 2013 ) showed, regularizing the optimal transport problem with an entropic term is known to bring several computational benefits. However, because of that regularization, the resulting approximation of the optimal transport cost does not define a proper distance or divergence between probability distributions. We recently tried to introduce a family of divergences connecting the Wasserstein distance and the Kullback-Leibler divergence from an information geometry point of view (see Amari, Karakida, \& Oizumi, 2018 ). However, that proposal was not able to retain key intuitive aspects of the Wasserstein geometry, such as translation invariance, which plays a key role when used in the more general problem of computing optimal transport barycenters. The divergence we propose in this work is able to retain such properties and admits an intuitive interpretation.},
  file = {/Users/yuekai/Documents/zotero/Amari et al (2019) - Information Geometry for Regularized Optimal Transport and Barycenters of.pdf},
  journal = {Neural Computation},
  language = {en},
  number = {5}
}

@book{ambrosio2005Gradient,
  title = {Gradient Flows: In Metric Spaces and in the Space of Probability Measures},
  shorttitle = {Gradient Flows},
  author = {Ambrosio, Luigi and Gigli, Nicola and Savar{\'e}, Giuseppe},
  year = {2005},
  publisher = {{Birkh\"auser}},
  address = {{Boston}},
  file = {/Users/yuekai/Documents/zotero/Ambrosio et al (2005) - Gradient flows.pdf},
  isbn = {978-3-7643-2428-5},
  keywords = {Differential equations; Parabolic,Evolution equations; Nonlinear,Measure theory,Metric spaces,Monotone operators},
  language = {en},
  lccn = {QA312 .A58 2005},
  series = {Lectures in Mathematics {{ETH Z\"urich}}}
}

@inbook{ambrosio2013User,
  title = {A {{User}}'s {{Guide}} to {{Optimal Transport}}},
  booktitle = {Modelling and {{Optimisation}} of {{Flows}} on {{Networks}}},
  author = {Ambrosio, Luigi and Gigli, Nicola},
  year = {2013},
  volume = {2062},
  pages = {1--155},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-32160-3_1},
  abstract = {This text is an expanded version of the lectures given by the first author in the 2009 CIME summer school of Cetraro. It provides a quick and reasonably account of the classical theory of optimal mass transportation and of its more recent developments, including the metric theory of gradient flows, geometric and functional inequalities related to optimal transportation, the first and second order differential calculus in the Wasserstein space and the synthetic theory of metric measure spaces with Ricci curvature bounded from below.},
  collaborator = {Ambrosio, Luigi and Bressan, Alberto and Helbing, Dirk and Klar, Axel and Zuazua, Enrique},
  file = {/Users/yuekai/Documents/zotero/Ambrosio, Gigli (2013) - A User’s Guide to Optimal Transport.pdf},
  isbn = {978-3-642-32159-7 978-3-642-32160-3},
  language = {en}
}

@article{amini2013Pseudolikelihood,
  title = {Pseudo-Likelihood Methods for Community Detection in Large Sparse Networks},
  author = {Amini, Arash A. and Chen, Aiyou and Bickel, Peter J. and Levina, Elizaveta},
  year = {2013},
  month = aug,
  volume = {41},
  pages = {2097--2122},
  issn = {0090-5364},
  doi = {10.1214/13-AOS1138},
  abstract = {Many algorithms have been proposed for fitting network models with communities, but most of them do not scale well to large networks, and often fail on sparse networks. Here we propose a new fast pseudo-likelihood method for fitting the stochastic block model for networks, as well as a variant that allows for an arbitrary degree distribution by conditioning on degrees. We show that the algorithms perform well under a range of settings, including on very sparse networks, and illustrate on the example of a network of political blogs. We also propose spectral clustering with perturbations, a method of independent interest, which works well on sparse networks where regular spectral clustering fails, and use it to provide an initial value for pseudo-likelihood. We prove that pseudo-likelihood provides consistent estimates of the communities under a mild condition on the starting value, for the case of a block model with two communities.},
  archivePrefix = {arXiv},
  eprint = {1207.2340},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Amini et al (2013) - Pseudo-likelihood methods for community detection in large sparse networks.pdf},
  journal = {The Annals of Statistics},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Mathematics - Statistics Theory,Physics - Physics and Society,Statistics - Machine Learning},
  number = {4}
}

@article{amit2017MetaLearning,
  title = {Meta-{{Learning}} by {{Adjusting Priors Based}} on {{Extended PAC}}-{{Bayes Theory}}},
  author = {Amit, Ron and Meir, Ron},
  year = {2017},
  month = nov,
  abstract = {In meta-learning an agent extracts knowledge from observed tasks, aiming to facilitate learning of novel future tasks. Under the assumption that future tasks are 'related' to previous tasks, the accumulated knowledge should be learned in a way which captures the common structure across learned tasks, while allowing the learner sufficient flexibility to adapt to novel aspects of new tasks. We present a framework for meta-learning that is based on generalization error bounds, allowing us to extend various PAC-Bayes bounds to meta-learning. Learning takes place through the construction of a distribution over hypotheses based on the observed tasks, and its utilization for learning a new task. Thus, prior knowledge is incorporated through setting an experience-dependent prior for novel tasks. We develop a gradient-based algorithm which minimizes an objective function derived from the bounds and demonstrate its effectiveness numerically with deep neural networks. In addition to establishing the improved performance available through meta-learning, we demonstrate the intuitive way by which prior information is manifested at different levels of the network.},
  archivePrefix = {arXiv},
  eprint = {1711.01244},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Amit, Meir (2017) - Meta-Learning by Adjusting Priors Based on Extended PAC-Bayes Theory.pdf},
  journal = {arXiv:1711.01244 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{amodei2016Concrete,
  title = {Concrete {{Problems}} in {{AI Safety}}},
  author = {Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  year = {2016},
  month = jun,
  abstract = {Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function ("avoiding side effects" and "avoiding reward hacking"), an objective function that is too expensive to evaluate frequently ("scalable supervision"), or undesirable behavior during the learning process ("safe exploration" and "distributional shift"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.},
  archivePrefix = {arXiv},
  eprint = {1606.06565},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Amodei et al (2016) - Concrete Problems in AI Safety.pdf},
  journal = {arXiv:1606.06565 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@inproceedings{anderson1956Statistical,
  title = {Statistical {{Inference}} in {{Factor Analysis}}},
  booktitle = {Proceedings of the {{Third Berkeley Symposium}} on {{Mathematical Statistics}} and {{Probability}}, {{Volume}} 5: {{Contributions}} to {{Econometrics}}, {{Industrial Research}}, and {{Psychometry}}},
  author = {Anderson, T. W. and Rubin, Herman},
  year = {1956},
  publisher = {{The Regents of the University of California}},
  abstract = {Project Euclid - mathematics and statistics online},
  file = {/Users/yuekai/Documents/zotero/Anderson, Rubin (1956) - Statistical Inference in Factor Analysis.pdf},
  language = {EN}
}

@article{anderson1963Asymptotic,
  title = {Asymptotic {{Theory}} for {{Principal Component Analysis}}},
  author = {Anderson, T. W.},
  year = {1963},
  month = mar,
  volume = {34},
  pages = {122--148},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177704248},
  abstract = {Project Euclid - mathematics and statistics online},
  file = {/Users/yuekai/Documents/zotero/Anderson (1963) - Asymptotic Theory for Principal Component Analysis.pdf},
  journal = {The Annals of Mathematical Statistics},
  language = {EN},
  mrnumber = {MR145620},
  number = {1},
  zmnumber = {0202.49504}
}

@article{andoni2008NearOptimal,
  title = {Near-{{Optimal Hashing Algorithms}} for {{Approximate Nearest Neighbor}} in {{High Dimensions}}},
  author = {Andoni, Alexandr and Indyk, Piotr},
  year = {2008},
  month = jan,
  volume = {51},
  pages = {10},
  abstract = {We present an algorithm for the c-approximate nearest neighbor problem in a d-dimensional Euclidean space, achieving query time of O(dn1/c2+o(1)) and space O(dn + n1+1/c2+o(1)). This almost matches the lower bound for hashing-based algorithm recently obtained in [27]. We also obtain a space-efficient version of the algorithm, which uses dn + n logO(1) n space, with a query time of dnO(1/c2). Finally, we discuss practical variants of the algorithms that utilize fast bounded-distance decoders for the Leech Lattice.},
  file = {/Users/yuekai/Documents/zotero/Andoni, Indyk (2008) - Near-Optimal Hashing Algorithms for Approximate Nearest Neighbor in High.pdf},
  journal = {Communications of the ACM},
  language = {en},
  number = {1}
}

@article{andresen2013Critical,
  title = {Critical Dimension in Profile Semiparametric Estimation},
  author = {Andresen, Andreas and Spokoiny, Vladimir},
  year = {2013},
  month = mar,
  abstract = {This paper revisits the classical inference results for profile quasi maximum likelihood estimators (profile MLE) in the semiparametric estimation problem. We mainly focus on two prominent theorems: the Wilks phenomenon and Fisher expansion for the profile MLE are stated in a new fashion allowing finite samples and model misspecification. The method of study is also essentially different from the usual analysis of the semiparametric problem based on the notion of the hardest parametric submodel. Instead we derive finite sample deviation bounds for the linear approximation error for the gradient of the loglikelihood. This novel approach particularly allows to address the important issue of the effective target and nuisance dimension. The obtained nonasymptotic results are surprisingly sharp and yield the classical asymptotic statements including the asymptotic normality and efficiency of the profile MLE. The general results are specified to the important special cases of an i.i.d. sample and the analysis is exemplified with a single index model.},
  archivePrefix = {arXiv},
  eprint = {1303.4640},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Andresen, Spokoiny (2013) - Critical dimension in profile semiparametric estimation.pdf},
  journal = {arXiv:1303.4640 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{andresen2014note,
  title = {A Note on Critical Dimensions in Profile Semiparametric Estimation},
  author = {Andresen, Andreas},
  year = {2014},
  month = oct,
  abstract = {This paper complements the results of Andresen et. al "Critical dimension in profile semiparametric estimation" (2014) on profile estimators in semiparametric models. We present two examples. One that illustrates that the smoothness constraint on the expected value of the contrast functional used to define the profile M-estimator is necessary for the bound derived for the critical ratio of dimension to sample size. A second one to show that in the case that the target dimension is proportional to the full dimension the critical ratio for the Fisher type result stays the same while for the Wilks phenomenon it is multiplied with the square root of the full dimension, just as in the upper bound in Andresen et. al (2014).},
  archivePrefix = {arXiv},
  eprint = {1410.4709},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Andresen (2014) - A note on critical dimensions in profile semiparametric estimation.pdf},
  journal = {arXiv:1410.4709 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{andresen2016Convergence,
  title = {Convergence of an {{Alternating Maximization Procedure}}},
  author = {Andresen, Andreas and Spokoiny, Vladimir},
  year = {2016},
  month = apr,
  volume = {17},
  pages = {53},
  abstract = {We derive two convergence results for a sequential alternating maximization procedure to approximate the maximizer of random functionals such as the realized log likelihood in MLE estimation. We manage to show that the sequence attains the same deviation properties as shown for the profile M-estimator by Andresen and Spokoiny (2013), that means a finite sample Wilks and Fisher theorem. Further under slightly stronger smoothness constraints on the random functional we can show nearly linear convergence to the global maximizer if the starting point for the procedure is well chosen.},
  file = {/Users/yuekai/Documents/zotero/Andresen, Spokoiny (2016) - Convergence of an Alternating Maximization Procedure.pdf},
  journal = {Journal of Machine Learning Research},
  language = {en}
}

@article{andrews2000Inconsistency,
  title = {Inconsistency of the {{Bootstrap When}} a {{Parameter}} Is on the {{Boundary}} of the {{Parameter Space}}},
  author = {Andrews, Donald W. K.},
  year = {2000},
  volume = {68},
  pages = {399--405},
  issn = {0012-9682},
  journal = {Econometrica},
  number = {2}
}

@article{andrieu2003Introduction,
  title = {An {{Introduction}} to {{MCMC}} for {{Machine Learning}}},
  author = {Andrieu, Christophe and {de Freitas}, Nando and Doucet, Arnaud and Jordan, Michael I.},
  year = {2003},
  month = jan,
  volume = {50},
  pages = {5--43},
  issn = {1573-0565},
  doi = {10.1023/A:1020281327116},
  abstract = {This purpose of this introductory paper is threefold. First, it introduces the Monte Carlo method with emphasis on probabilistic machine learning. Second, it reviews the main building blocks of modern Markov chain Monte Carlo simulation, thereby providing and introduction to the remaining papers of this special issue. Lastly, it discusses new interesting research horizons.},
  file = {/Users/yuekai/Documents/zotero/Andrieu et al (2003) - An Introduction to MCMC for Machine Learning.pdf},
  journal = {Machine Learning},
  language = {en},
  number = {1}
}

@article{andriushchenko2019Provably,
  title = {Provably {{Robust Boosted Decision Stumps}} and {{Trees}} against {{Adversarial Attacks}}},
  author = {Andriushchenko, Maksym and Hein, Matthias},
  year = {2019},
  month = jun,
  abstract = {The problem of adversarial samples has been studied extensively for neural networks. However, for boosting, in particular boosted decision trees and decision stumps there are almost no results, even though boosted decision trees, as e.g. XGBoost, are quite popular due to their interpretability and good prediction performance. We show in this paper that for boosted decision stumps the exact min-max optimal robust loss and test error for an \$l\_\textbackslash infty\$-attack can be computed in \$O(n\textbackslash,T\textbackslash log T)\$, where \$T\$ is the number of decision stumps and \$n\$ the number of data points, as well as an optimal update of the ensemble in \$O(n\^2\textbackslash,T\textbackslash log T)\$. While not exact, we show how to optimize an upper bound on the robust loss for boosted trees. Up to our knowledge, these are the first algorithms directly optimizing provable robustness guarantees in the area of boosting. We make the code of all our experiments publicly available at https://github.com/max-andr/provably-robust-boosting},
  archivePrefix = {arXiv},
  eprint = {1906.03526},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Andriushchenko, Hein (2019) - Provably Robust Boosted Decision Stumps and Trees against Adversarial Attacks.pdf},
  journal = {arXiv:1906.03526 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{andrychowicz2016Learning,
  title = {Learning to Learn by Gradient Descent by Gradient Descent},
  author = {Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and Hoffman, Matthew W. and Pfau, David and Schaul, Tom and Shillingford, Brendan and {de Freitas}, Nando},
  year = {2016},
  month = nov,
  abstract = {The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art.},
  archivePrefix = {arXiv},
  eprint = {1606.04474},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Andrychowicz et al (2016) - Learning to learn by gradient descent by gradient descent.pdf},
  journal = {arXiv:1606.04474 [cs]},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  primaryClass = {cs}
}

@misc{angwin2015Tiger,
  title = {The {{Tiger Mom Tax}}: {{Asians Are Nearly Twice}} as {{Likely}} to {{Get}} a {{Higher Price}} from {{Princeton Review}}},
  shorttitle = {The {{Tiger Mom Tax}}},
  author = {Angwin, Julia and Larson, Jeff},
  year = {2015},
  month = sep,
  copyright = {Copyright \textcopyright 2019 ProPublica.},
  howpublished = {https://www.propublica.org/article/asians-nearly-twice-as-likely-to-get-higher-price-from-princeton-review},
  journal = {ProPublica},
  language = {en},
  type = {Text/Html}
}

@misc{angwin2016Facebook,
  title = {Facebook {{Lets Advertisers Exclude Users}} by {{Race}}},
  author = {Angwin, Julia and Parris Jr, Terry},
  year = {2016},
  month = oct,
  abstract = {Facebook's system allows advertisers to exclude black, Hispanic, and other ``ethnic affinities'' from seeing ads.},
  copyright = {Copyright \textcopyright 2019 ProPublica.},
  howpublished = {https://www.propublica.org/article/facebook-lets-advertisers-exclude-users-by-race},
  journal = {ProPublica},
  language = {en}
}

@misc{angwin2016Machine,
  title = {Machine {{Bias}}},
  author = {Angwin, Julia and Larson, Jeff and Mattu, Surya and Kirchner, Lauren},
  year = {2016},
  month = may,
  abstract = {There's software used across the country to predict future criminals. And it's biased against blacks.},
  copyright = {Copyright \textcopyright 2019 ProPublica.},
  howpublished = {www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing},
  journal = {ProPublica},
  language = {en},
  type = {Text/Html}
}

@misc{angwin2017Facebook,
  title = {Facebook ({{Still}}) {{Letting Housing Advertisers Exclude Users}} by {{Race}}},
  author = {Angwin, Julia and Tobin, Ariana and Varner, Madeleine},
  year = {2017},
  month = nov,
  abstract = {After ProPublica revealed last year that Facebook advertisers could target housing ads to whites only, the company announced it had built a system to spot and reject discriminatory ads. We retested and found major omissions.},
  copyright = {Copyright \textcopyright 2019 ProPublica.},
  howpublished = {https://www.propublica.org/article/facebook-advertising-discrimination-housing-race-sex-national-origin},
  journal = {ProPublica},
  language = {en}
}

@misc{angwin2017Minority,
  title = {Minority {{Neighborhoods Pay Higher Car Insurance Premiums Than White Areas With}} the {{Same Risk}}},
  author = {Angwin, Julia and Larson, Jeff and Kirchner, Lauren and Mattu, Surya},
  year = {2017},
  month = apr,
  abstract = {Our analysis of premiums and payouts in California, Illinois, Texas and Missouri shows that some major insurers charge minority neighborhoods as much as 30 percent more than other areas with similar accident costs.},
  copyright = {Copyright \textcopyright 2019 ProPublica.},
  howpublished = {https://www.propublica.org/article/minority-neighborhoods-higher-car-insurance-premiums-white-areas-same-risk},
  journal = {ProPublica},
  language = {en},
  type = {Text/Html}
}

@article{ansari2002Heterogeneous,
  title = {Heterogeneous Factor Analysis Models: {{A}} Bayesian Approach},
  shorttitle = {Heterogeneous Factor Analysis Models},
  author = {Ansari, Asim and Jedidi, Kamel and Dube, Laurette},
  year = {2002},
  month = mar,
  volume = {67},
  pages = {49--77},
  issn = {1860-0980},
  doi = {10.1007/BF02294709},
  abstract = {Multilevel factor analysis models are widely used in the social sciences to account for heterogeneity in mean structures. In this paper we extend previous work on multilevel models to account for general forms of heterogeneity in confirmatory factor analysis models. We specify various models of mean and covariance heterogeneity in confirmatory factor analysis and develop Markov Chain Monte Carlo (MCMC) procedures to perform Bayesian inference, model checking, and model comparison.We test our methodology using synthetic data and data from a consumption emotion study. The results from synthetic data show that our Bayesian model perform well in recovering the true parameters and selecting the appropriate model. More importantly, the results clearly illustrate the consequences of ignoring heterogeneity. Specifically, we find that ignoring heterogeneity can lead to sign reversals of the factor covariances, inflation of factor variances and underappreciation of uncertainty in parameter estimates. The results from the emotion study show that subjects vary both in means and covariances. Thus traditional psychometric methods cannot fully capture the heterogeneity in our data.},
  file = {/Users/yuekai/Documents/zotero/Ansari et al (2002) - Heterogeneous factor analysis models.pdf},
  journal = {Psychometrika},
  language = {en},
  number = {1}
}

@article{antoniou2018How,
  title = {How to Train Your {{MAML}}},
  author = {Antoniou, Antreas and Edwards, Harrison and Storkey, Amos},
  year = {2018},
  month = oct,
  abstract = {The field of few-shot learning has recently seen substantial advancements. Most of these advancements came from casting few-shot learning as a meta-learning problem. Model Agnostic Meta Learning or MAML is currently one of the best approaches for few-shot learning via meta-learning. MAML is simple, elegant and very powerful, however, it has a variety of issues, such as being very sensitive to neural network architectures, often leading to instability during training, requiring arduous hyperparameter searches to stabilize training and achieve high generalization and being very computationally expensive at both training and inference times. In this paper, we propose various modifications to MAML that not only stabilize the system, but also substantially improve the generalization performance, convergence speed and computational overhead of MAML, which we call MAML++.},
  archivePrefix = {arXiv},
  eprint = {1810.09502},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Antoniou et al (2018) - How to train your MAML.pdf},
  journal = {arXiv:1810.09502 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{aragam2018Identifiability,
  title = {Identifiability of {{Nonparametric Mixture Models}} and {{Bayes Optimal Clustering}}},
  author = {Aragam, Bryon and Dan, Chen and Ravikumar, Pradeep and Xing, Eric P.},
  year = {2018},
  month = feb,
  abstract = {Motivated by problems in data clustering, we establish general conditions under which families of nonparametric mixture models are identifiable, by introducing a novel framework involving clustering overfitted \textbackslash emph\{parametric\} (i.e. misspecified) mixture models. These identifiability conditions generalize existing conditions in the literature, and are flexible enough to include for example mixtures of Gaussian mixtures. In contrast to the recent literature on estimating nonparametric mixtures, we allow for general nonparametric mixture components, and instead impose regularity assumptions on the underlying mixing measure. As our primary application, we apply these results to partition-based clustering, generalizing the notion of a Bayes optimal partition from classical parametric model-based clustering to nonparametric settings. Furthermore, this framework is constructive so that it yields a practical algorithm for learning identified mixtures, which is illustrated through several examples on real data. The key conceptual device in the analysis is the convex, metric geometry of probability measures on metric spaces and its connection to the Wasserstein convergence of mixing measures. The result is a flexible framework for nonparametric clustering with formal consistency guarantees.},
  archivePrefix = {arXiv},
  eprint = {1802.04397},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Aragam et al (2018) - Identifiability of Nonparametric Mixture Models and Bayes Optimal Clustering.pdf},
  journal = {arXiv:1802.04397 [cs, math, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{aravkin2013Variational,
  title = {Variational Properties of Value Functions},
  author = {Aravkin, Aleksandr Y. and Burke, James V. and Friedlander, Michael P.},
  year = {2013},
  month = jan,
  volume = {23},
  pages = {1689--1717},
  issn = {1052-6234, 1095-7189},
  doi = {10.1137/120899157},
  abstract = {Regularization plays a key role in a variety of optimization formulations of inverse problems. A recurring theme in regularization approaches is the selection of regularization parameters, and their effect on the solution and on the optimal value of the optimization problem. The sensitivity of the value function to the regularization parameter can be linked directly to the Lagrange multipliers. This paper characterizes the variational properties of the value functions for a broad class of convex formulations, which are not all covered by standard Lagrange multiplier theory. An inverse function theorem is given that links the value functions of different regularization formulations (not necessarily convex). These results have implications for the selection of regularization parameters, and the development of specialized algorithms. Numerical examples illustrate the theoretical results.},
  archivePrefix = {arXiv},
  eprint = {1211.3724},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Aravkin et al (2013) - Variational properties of value functions.pdf},
  journal = {SIAM Journal on Optimization},
  keywords = {Mathematics - Optimization and Control},
  number = {3}
}

@article{arcidiacono2003dynamic,
  title = {The Dynamic Implications of Search Discrimination},
  author = {Arcidiacono, Peter},
  year = {2003},
  month = aug,
  volume = {87},
  pages = {1681--1706},
  issn = {00472727},
  doi = {10.1016/S0047-2727(01)00204-3},
  abstract = {Blacks have both lower employment rates and lower earnings than whites. Further, the earnings gap increases as workers age. This paper focuses on explaining differences in black/white earnings profiles and how government interventions work in a dynamic environment. Three contributions are made. First, multiple equilibria may exist solely because of a coordination failure by firms. Even without taste discrimination, blacks may play no role in their poor labor market outcomes. Second, search discrimination leads to economic discrimination against the non-discriminated group (reverse discrimination). Finally, in response to a quota program, whites may find it optimal to subsidize black investment.},
  file = {/Users/yuekai/Documents/zotero/Arcidiacono (2003) - The dynamic implications of search discrimination.pdf},
  journal = {Journal of Public Economics},
  language = {en},
  number = {7-8}
}

@article{argelaguet2018Multi,
  title = {Multi-{{Omics Factor Analysis}}\textemdash a Framework for Unsupervised Integration of Multi-omics Data Sets},
  author = {Argelaguet, Ricard and Velten, Britta and Arnol, Damien and Dietrich, Sascha and Zenz, Thorsten and Marioni, John C. and Buettner, Florian and Huber, Wolfgang and Stegle, Oliver},
  year = {2018},
  month = jun,
  volume = {14},
  pages = {e8124},
  issn = {1744-4292, 1744-4292},
  doi = {10.15252/msb.20178124},
  abstract = {Multi-omics studies promise the improved characterization of biological processes across molecular layers. However, methods for the unsupervised integration of the resulting heterogeneous data sets are lacking. We present Multi-Omics Factor Analysis (MOFA), a computational method for discovering the principal sources of variation in multi-omics data sets. MOFA infers a set of (hidden) factors that capture biological and technical sources of variability. It disentangles axes of heterogeneity that are shared across multiple modalities and those specific to individual data modalities. The learnt factors enable a variety of downstream analyses, including identification of sample subgroups, data imputation and the detection of outlier samples. We applied MOFA to a cohort of 200 patient samples of chronic lymphocytic leukaemia, profiled for somatic mutations, RNA expression, DNA methylation and ex vivo drug responses. MOFA identified major dimensions of disease heterogeneity, including immunoglobulin heavy-chain variable region status, trisomy of chromosome 12 and previously underappreciated drivers, such as response to oxidative stress. In a second application, we used MOFA to analyse single-cell multi-omics data, identifying coordinated transcriptional and epigenetic changes along cell differentiation.
Synopsis

{$<$}img class="highwire-embed" alt="Embedded Image" src="http://msb.embopress.org/sites/default/files/highwire/msb/14/6/e8124/embed/graphic-1.gif"/{$>$}

Multi-Omics Factor Analysis (MOFA) is a computational framework for unsupervised discovery of the principal axes of biological and technical variation when multiple omics assays are applied to the same samples. MOFA is a broadly applicable approach for multi-omics data integration.

The inferred latent factors represent the underlying principal axes of heterogeneity across the samples. Factors can be shared by multiple data modalities or can be data-type specific.The model flexibly handles missing values and different data types.In an application to Chronic Lymphocytic Leukaemia, MOFA discovers a low dimensional space spanned by known clinical markers and underappreciated axes of variation such as oxidative stress.In an application to multi-omics profiles from single-cells, MOFA recovers differentiation trajectories and identifies coordinated variation between the transcriptome and the epigenome.},
  copyright = {\textcopyright{} 2018 The Authors. Published under the terms of the CC BY 4.0 license. This is an open access article under the terms of the Creative Commons Attribution 4.0 License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited.},
  file = {/Users/yuekai/Documents/zotero/Argelaguet et al (2018) - Multi‐Omics Factor Analysis—a framework for unsupervised integration of.pdf},
  journal = {Molecular Systems Biology},
  language = {en},
  number = {6},
  pmid = {29925568}
}

@article{arias-castro2016Distributionfree,
  title = {Distribution-Free {{Multiple Testing}}},
  author = {{Arias-Castro}, Ery and Chen, Shiyun},
  year = {2016},
  month = apr,
  abstract = {We study a stylized multiple testing problem where the test statistics are independent and assumed to have the same distribution under their respective null hypotheses. We first show that, in the normal means model where the test statistics are normal Z-scores, the well-known method of (Benjamini and Hochberg, 1995) is optimal in some asymptotic sense. We then show that this is also the case of a recent distribution-free method proposed by Foygel-Barber and Cand\textbackslash `es (2015). The method is distribution-free in the sense that it is agnostic to the null distribution - it only requires that the null distribution be symmetric. We extend these optimality results to other location models with a base distribution having fast-decaying tails.},
  archivePrefix = {arXiv},
  eprint = {1604.07520},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Arias-Castro, Chen (2016) - Distribution-free Multiple Testing.pdf},
  journal = {arXiv:1604.07520 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{arjovsky2017Wasserstein,
  title = {Wasserstein {{GAN}}},
  author = {Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  year = {2017},
  month = jan,
  abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.},
  archivePrefix = {arXiv},
  eprint = {1701.07875},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Arjovsky et al (2017) - Wasserstein GAN.pdf},
  journal = {arXiv:1701.07875 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{arjovsky2019Invariant,
  title = {Invariant {{Risk Minimization}}},
  author = {Arjovsky, Martin and Bottou, L{\'e}on and Gulrajani, Ishaan and {Lopez-Paz}, David},
  year = {2019},
  month = sep,
  abstract = {We introduce Invariant Risk Minimization (IRM), a learning paradigm to estimate invariant correlations across multiple training distributions. To achieve this goal, IRM learns a data representation such that the optimal classifier, on top of that data representation, matches for all training distributions. Through theory and experiments, we show how the invariances learned by IRM relate to the causal structures governing the data and enable out-of-distribution generalization.},
  archivePrefix = {arXiv},
  eprint = {1907.02893},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Arjovsky et al (2019) - Invariant Risk Minimization.pdf},
  journal = {arXiv:1907.02893 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{arora2019Exact,
  title = {On {{Exact Computation}} with an {{Infinitely Wide Neural Net}}},
  author = {Arora, Sanjeev and Du, Simon S. and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Ruslan and Wang, Ruosong},
  year = {2019},
  month = apr,
  abstract = {How well does a classic deep net architecture like AlexNet or VGG19 classify on a standard dataset such as CIFAR-10 when its "width" --- namely, number of channels in convolutional layers, and number of nodes in fully-connected internal layers --- is allowed to increase to infinity? Such questions have come to the forefront in the quest to theoretically understand deep learning and its mysteries about optimization and generalization. They also connect deep learning to notions such as Gaussian processes and kernels. A recent paper [Jacot et al., 2018] introduced the Neural Tangent Kernel (NTK) which captures the behavior of fully-connected deep nets in the infinite width limit trained by gradient descent; this object was implicit in some other recent papers. A subsequent paper [Lee et al., 2019] gave heuristic Monte Carlo methods to estimate the NTK and its extension, Convolutional Neural Tangent Kernel (CNTK) and used this to try to understand the limiting behavior on datasets like CIFAR-10. The current paper gives the first efficient exact algorithm (based upon dynamic programming) for computing CNTK as well as an efficient GPU implementation of this algorithm. This results in a significant new benchmark for performance of a pure kernel-based method on CIFAR-10, being 10\% higher than the methods reported in [Novak et al., 2019], and only 5\% lower than the performance of the corresponding finite deep net architecture (once batch normalization etc. are turned off). We give the first non-asymptotic proof showing that a fully-trained sufficiently wide net is indeed equivalent to the kernel regression predictor using NTK. Our experiments also demonstrate that earlier Monte Carlo approximation can degrade the performance significantly, thus highlighting the power of our exact kernel computation, which we have applied even to the full CIFAR-10 dataset and 20-layer nets.},
  archivePrefix = {arXiv},
  eprint = {1904.11955},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Arora et al (2019) - On Exact Computation with an Infinitely Wide Neural Net.pdf},
  journal = {arXiv:1904.11955 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{arroyo-relion2017Network,
  title = {Network Classification with Applications to Brain Connectomics},
  author = {{Arroyo-Reli{\'o}n}, Jes{\'u}s D. and Kessler, Daniel and Levina, Elizaveta and Taylor, Stephan F.},
  year = {2017},
  month = jan,
  abstract = {While statistical analysis of a single network has received a lot of attention in recent years, with a focus on social networks, analysis of a sample of networks presents its own challenges which require a different set of analytic tools. Here we study the problem of classification of networks with labeled nodes, motivated by applications in neuroimaging. Brain networks are constructed from imaging data to represent functional connectivity between regions of the brain, and previous work has shown the potential of such networks to distinguish between various brain disorders, giving rise to a network classification problem. Existing approaches tend to either treat all edge weights as a long vector, ignoring the network structure, or focus on graph topology as represented by summary measures while ignoring the edge weights. Our goal is to design a classification method that uses both the individual edge information and the network structure of the data in a computationally efficient way, and that can produce a parsimonious and interpretable representation of differences in brain connectivity patterns between classes. We propose a graph classification method that uses edge weights as predictors but incorporates the network nature of the data via penalties that promote sparsity in the number of nodes, in addition to the usual sparsity penalties that encourage selection of edges. We implement the method via efficient convex optimization and provide a detailed analysis of data from two fMRI studies of schizophrenia.},
  archivePrefix = {arXiv},
  eprint = {1701.08140},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Arroyo-Relión et al (2017) - Network classification with applications to brain connectomics.pdf},
  journal = {arXiv:1701.08140 [stat]},
  keywords = {Statistics - Machine Learning,Statistics - Methodology},
  language = {en},
  primaryClass = {stat}
}

@article{ashtiani2017Nearoptimal,
  title = {Near-Optimal {{Sample Complexity Bounds}} for {{Robust Learning}} of {{Gaussians Mixtures}} via {{Compression Schemes}}},
  author = {Ashtiani, Hassan and {Ben-David}, Shai and Harvey, Nick and Liaw, Christopher and Mehrabian, Abbas and Plan, Yaniv},
  year = {2017},
  month = oct,
  abstract = {We prove that \$\textbackslash tilde\{\textbackslash Theta\}(k d\^2 / \textbackslash varepsilon\^2)\$ samples are necessary and sufficient for learning a mixture of \$k\$ Gaussians in \$\textbackslash mathbb\{R\}\^d\$, up to error \$\textbackslash varepsilon\$ in total variation distance. This improves both the known upper bounds and lower bounds for this problem. For mixtures of axis-aligned Gaussians, we show that \$\textbackslash tilde\{O\}(k d / \textbackslash varepsilon\^2)\$ samples suffice, matching a known lower bound. Moreover, these results hold in the agnostic-learning/robust-estimation setting as well, where the target distribution is only approximately a mixture of Gaussians. The upper bound is shown using a novel technique for distribution learning based on a notion of `compression.' Any class of distributions that allows such a compression scheme can also be learned with few samples. Moreover, if a class of distributions has such a compression scheme, then so do the classes of products and mixtures of those distributions. The core of our main result is showing that the class of Gaussians in \$\textbackslash mathbb\{R\}\^d\$ admits a small-sized compression scheme.},
  archivePrefix = {arXiv},
  eprint = {1710.05209},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ashtiani et al (2017) - Near-optimal Sample Complexity Bounds for Robust Learning of Gaussians Mixtures.pdf},
  journal = {arXiv:1710.05209 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory},
  primaryClass = {cs, math, stat}
}

@article{asi2018Stochastic,
  title = {Stochastic ({{Approximate}}) {{Proximal Point Methods}}: {{Convergence}}, {{Optimality}}, and {{Adaptivity}}},
  shorttitle = {Stochastic ({{Approximate}}) {{Proximal Point Methods}}},
  author = {Asi, Hilal and Duchi, John C.},
  year = {2018},
  month = oct,
  abstract = {We develop model-based methods for solving stochastic convex optimization problems, introducing the approximate-proximal point, or \textbackslash aProx, family, which includes stochastic subgradient, proximal point, and bundle methods. When the modeling approaches we propose are appropriately accurate, the methods enjoy stronger convergence and robustness guarantees than classical approaches, even though the model-based methods typically add little to no computational overhead over stochastic subgradient methods. For example, we show that improved models converge with probability 1 and enjoy optimal asymptotic normality results under weak assumptions; these methods are also adaptive to a natural class of what we term easy optimization problems, achieving linear convergence under appropriate strong growth conditions on the objective. Our substantial experimental investigation shows the advantages of more accurate modeling over standard subgradient methods across many smooth and non-smooth optimization problems.},
  archivePrefix = {arXiv},
  eprint = {1810.05633},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Asi, Duchi (2018) - Stochastic (Approximate) Proximal Point Methods.pdf},
  journal = {arXiv:1810.05633 [math, stat]},
  keywords = {Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {math, stat}
}

@article{asiaee2018High,
  title = {High {{Dimensional Data Enrichment}}: {{Interpretable}}, {{Fast}}, and {{Data}}-{{Efficient}}},
  shorttitle = {High {{Dimensional Data Enrichment}}},
  author = {Asiaee, Amir and Oymak, Samet and Coombes, Kevin R. and Banerjee, Arindam},
  year = {2018},
  month = jun,
  abstract = {High dimensional structured data enriched model describes groups of observations by shared and per-group individual parameters, each with its own structure such as sparsity or group sparsity. In this paper, we consider the general form of data enrichment where data comes in a fixed but arbitrary number of groups G. Any convex function, e.g., norms, can characterize the structure of both shared and individual parameters. We propose an estimator for high dimensional data enriched model and provide conditions under which it consistently estimates both shared and individual parameters. We also delineate sample complexity of the estimator and present high probability non-asymptotic bound on estimation error of all parameters. Interestingly the sample complexity of our estimator translates to conditions on both per-group sample sizes and the total number of samples. We propose an iterative estimation algorithm with linear convergence rate and supplement our theoretical analysis with synthetic and real experimental results. Particularly, we show the predictive power of data-enriched model along with its interpretable results in anticancer drug sensitivity analysis.},
  archivePrefix = {arXiv},
  eprint = {1806.04047},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Asiaee et al (2018) - High Dimensional Data Enrichment.pdf},
  journal = {arXiv:1806.04047 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{ateniese2013Hacking,
  title = {Hacking {{Smart Machines}} with {{Smarter Ones}}: {{How}} to {{Extract Meaningful Data}} from {{Machine Learning Classifiers}}},
  shorttitle = {Hacking {{Smart Machines}} with {{Smarter Ones}}},
  author = {Ateniese, Giuseppe and Felici, Giovanni and Mancini, Luigi V. and Spognardi, Angelo and Villani, Antonio and Vitali, Domenico},
  year = {2013},
  month = jun,
  abstract = {Machine Learning (ML) algorithms are used to train computers to perform a variety of complex tasks and improve with experience. Computers learn how to recognize patterns, make unintended decisions, or react to a dynamic environment. Certain trained machines may be more effective than others because they are based on more suitable ML algorithms or because they were trained through superior training sets. Although ML algorithms are known and publicly released, training sets may not be reasonably ascertainable and, indeed, may be guarded as trade secrets. While much research has been performed about the privacy of the elements of training sets, in this paper we focus our attention on ML classifiers and on the statistical information that can be unconsciously or maliciously revealed from them. We show that it is possible to infer unexpected but useful information from ML classifiers. In particular, we build a novel meta-classifier and train it to hack other classifiers, obtaining meaningful information about their training sets. This kind of information leakage can be exploited, for example, by a vendor to build more effective classifiers or to simply acquire trade secrets from a competitor's apparatus, potentially violating its intellectual property rights.},
  archivePrefix = {arXiv},
  eprint = {1306.4447},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ateniese et al (2013) - Hacking Smart Machines with Smarter Ones.pdf},
  journal = {arXiv:1306.4447 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{athalye2018Obfuscated,
  title = {Obfuscated {{Gradients Give}} a {{False Sense}} of {{Security}}: {{Circumventing Defenses}} to {{Adversarial Examples}}},
  shorttitle = {Obfuscated {{Gradients Give}} a {{False Sense}} of {{Security}}},
  author = {Athalye, Anish and Carlini, Nicholas and Wagner, David},
  year = {2018},
  month = feb,
  abstract = {We identify obfuscated gradients, a kind of gradient masking, as a phenomenon that leads to a false sense of security in defenses against adversarial examples. While defenses that cause obfuscated gradients appear to defeat iterative optimization-based attacks, we find defenses relying on this effect can be circumvented. We describe characteristic behaviors of defenses exhibiting the effect, and for each of the three types of obfuscated gradients we discover, we develop attack techniques to overcome it. In a case study, examining non-certified white-box-secure defenses at ICLR 2018, we find obfuscated gradients are a common occurrence, with 7 of 9 defenses relying on obfuscated gradients. Our new attacks successfully circumvent 6 completely, and 1 partially, in the original threat model each paper considers.},
  archivePrefix = {arXiv},
  eprint = {1802.00420},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Athalye et al (2018) - Obfuscated Gradients Give a False Sense of Security.pdf},
  journal = {arXiv:1802.00420 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{athey2016Generalized,
  title = {Generalized {{Random Forests}}},
  author = {Athey, Susan and Tibshirani, Julie and Wager, Stefan},
  year = {2016},
  month = oct,
  abstract = {We propose generalized random forests, a method for non-parametric statistical estimation based on random forests (Breiman, 2001) that can be used to fit any quantity of interest identified as the solution to a set of local moment equations. Following the literature on local maximum likelihood estimation, our method considers a weighted set of nearby training examples; however, instead of using classical kernel weighting functions that are prone to a strong curse of dimensionality, we use an adaptive weighting function derived from a forest designed to express heterogeneity in the specified quantity of interest. We propose a flexible, computationally efficient algorithm for growing generalized random forests, develop a large sample theory for our method showing that our estimates are consistent and asymptotically Gaussian, and provide an estimator for their asymptotic variance that enables valid confidence intervals. We use our approach to develop new methods for three statistical tasks: non-parametric quantile regression, conditional average partial effect estimation, and heterogeneous treatment effect estimation via instrumental variables. A software implementation, grf for R and C++, is available from CRAN.},
  archivePrefix = {arXiv},
  eprint = {1610.01271},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Athey et al (2016) - Generalized Random Forests.pdf},
  journal = {arXiv:1610.01271 [econ, stat]},
  keywords = {Economics - Econometrics,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {econ, stat}
}

@article{athey2019Using,
  title = {Using {{Wasserstein Generative Adversarial Networks}} for the {{Design}} of {{Monte Carlo Simulations}}},
  author = {Athey, Susan and Imbens, Guido and Metzger, Jonas and Munro, Evan},
  year = {2019},
  month = sep,
  abstract = {Researchers often use artificial data to assess the performance of new econometric methods. In many cases the data generating processes used in these Monte Carlo studies do not resemble real data sets and instead reflect many arbitrary decisions made by the researchers. As a result potential users of the methods are rarely persuaded by these simulations that the new methods are as attractive as the simulations make them out to be. We discuss the use of Wasserstein Generative Adversarial Networks (WGANs) as a method for systematically generating artificial data that mimic closely any given real data set without the researcher having many degrees of freedom. We apply the methods to compare in three different settings twelve different estimators for average treatment effects under unconfoundedness. We conclude in this example that (i) there is not one estimator that outperforms the others in all three settings, and (ii) that systematic simulation studies can be helpful for selecting among competing methods.},
  archivePrefix = {arXiv},
  eprint = {1909.02210},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Athey et al (2019) - Using Wasserstein Generative Adversarial Networks for the Design of Monte Carlo.pdf},
  journal = {arXiv:1909.02210 [econ, stat]},
  keywords = {Economics - Econometrics,Statistics - Methodology},
  primaryClass = {econ, stat}
}

@article{athiwaratkun2018There,
  title = {There {{Are Many Consistent Explanations}} of {{Unlabeled Data}}: {{Why You Should Average}}},
  shorttitle = {There {{Are Many Consistent Explanations}} of {{Unlabeled Data}}},
  author = {Athiwaratkun, Ben and Finzi, Marc and Izmailov, Pavel and Wilson, Andrew Gordon},
  year = {2018},
  month = jun,
  abstract = {Presently the most successful approaches to semi-supervised learning are based on consistency regularization, whereby a model is trained to be robust to small perturbations of its inputs and parameters. To understand consistency regularization, we conceptually explore how loss geometry interacts with training procedures. The consistency loss dramatically improves generalization performance over supervised-only training; however, we show that SGD struggles to converge on the consistency loss and continues to make large steps that lead to changes in predictions on the test data. Motivated by these observations, we propose to train consistency-based methods with Stochastic Weight Averaging (SWA), a recent approach which averages weights along the trajectory of SGD with a modified learning rate schedule. We also propose fast-SWA, which further accelerates convergence by averaging multiple points within each cycle of a cyclical learning rate schedule. With weight averaging, we achieve the best known semi-supervised results on CIFAR-10 and CIFAR-100, over many different quantities of labeled training data. For example, we achieve 5.0\% error on CIFAR-10 with only 4000 labels, compared to the previous best result in the literature of 6.3\%.},
  archivePrefix = {arXiv},
  eprint = {1806.05594},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Athiwaratkun et al (2018) - There Are Many Consistent Explanations of Unlabeled Data.pdf},
  journal = {arXiv:1806.05594 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{athreya2017Statistical,
  title = {Statistical Inference on Random Dot Product Graphs: A Survey},
  shorttitle = {Statistical Inference on Random Dot Product Graphs},
  author = {Athreya, Avanti and Fishkind, Donniell E. and Levin, Keith and Lyzinski, Vince and Park, Youngser and Qin, Yichen and Sussman, Daniel L. and Tang, Minh and Vogelstein, Joshua T. and Priebe, Carey E.},
  year = {2017},
  month = sep,
  abstract = {The random dot product graph (RDPG) is an independent-edge random graph that is analytically tractable and, simultaneously, either encompasses or can successfully approximate a wide range of random graphs, from relatively simple stochastic block models to complex latent position graphs. In this survey paper, we describe a comprehensive paradigm for statistical inference on random dot product graphs, a paradigm centered on spectral embeddings of adjacency and Laplacian matrices. We examine the analogues, in graph inference, of several canonical tenets of classical Euclidean inference: in particular, we summarize a body of existing results on the consistency and asymptotic normality of the adjacency and Laplacian spectral embeddings, and the role these spectral embeddings can play in the construction of single- and multi-sample hypothesis tests for graph data. We investigate several real-world applications, including community detection and classification in large social networks and the determination of functional and biologically relevant network properties from an exploratory data analysis of the Drosophila connectome. We outline requisite background and current open problems in spectral graph inference.},
  archivePrefix = {arXiv},
  eprint = {1709.05454},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Athreya et al (2017) - Statistical inference on random dot product graphs.pdf},
  journal = {arXiv:1709.05454 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{audibert2007Fast,
  title = {Fast Learning Rates for Plug-in Classifiers},
  author = {Audibert, Jean-Yves and Tsybakov, Alexandre B.},
  year = {2007},
  month = apr,
  volume = {35},
  pages = {608--633},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/009053606000001217},
  abstract = {It has been recently shown that, under the margin (or low noise) assumption, there exist classifiers attaining fast rates of convergence of the excess Bayes risk, that is, rates faster than n-1/2. The work on this subject has suggested the following two conjectures: (i) the best achievable fast rate is of the order n-1, and (ii) the plug-in classifiers generally converge more slowly than the classifiers based on empirical risk minimization. We show that both conjectures are not correct. In particular, we construct plug-in classifiers that can achieve not only fast, but also super-fast rates, that is, rates faster than n-1. We establish minimax lower bounds showing that the obtained rates cannot be improved.},
  file = {/Users/yuekai/Documents/zotero/Audibert, Tsybakov (2007) - Fast learning rates for plug-in classifiers.pdf;/Users/yuekai/Zotero/storage/YJENL9V8/1183667286.html},
  journal = {Annals of Statistics},
  keywords = {Classification,excess risk,fast rates of convergence,minimax lower bounds,plug-in classifiers,statistical learning},
  language = {EN},
  mrnumber = {MR2336861},
  number = {2},
  zmnumber = {1118.62041}
}

@article{auer2003Using,
  title = {Using {{Confidence Bounds}} for {{Exploitation}}-Exploration {{Trade}}-Offs},
  author = {Auer, Peter},
  year = {2003},
  month = mar,
  volume = {3},
  pages = {397--422},
  issn = {1532-4435},
  abstract = {We show how a standard tool from statistics --- namely confidence bounds --- can be used to elegantly deal with situations which exhibit an exploitation-exploration trade-off. Our technique for designing and analyzing algorithms for such situations is general and can be applied when an algorithm has to make exploitation-versus-exploration decisions based on uncertain information provided by a random process. We apply our technique to two models with such an exploitation-exploration trade-off. For the adversarial bandit problem with shifting our new algorithm suffers only O((ST)1/2) regret with high probability over T trials with S shifts. Such a regret bound was previously known only in expectation. The second model we consider is associative reinforcement learning with linear value functions. For this model our technique improves the regret from O(T3/4) to O(T1/2).},
  file = {/Users/yuekai/Documents/zotero/Auer (2003) - Using Confidence Bounds for Exploitation-exploration Trade-offs.pdf},
  journal = {J. Mach. Learn. Res.}
}

@article{avella-medina2019Privacypreserving,
  title = {Privacy-Preserving Parametric Inference: A Case for Robust Statistics},
  shorttitle = {Privacy-Preserving Parametric Inference},
  author = {{Avella-Medina}, Marco},
  year = {2019},
  month = nov,
  abstract = {Differential privacy is a cryptographically-motivated approach to privacy
that has become a very active field of research over the last decade in
theoretical computer science and machine learning. In this paradigm one assumes
there is a trusted curator who holds the data of individuals in a database and
the goal of privacy is to simultaneously protect individual data while allowing
the release of global characteristics of the database. In this setting we
introduce a general framework for parametric inference with differential
privacy guarantees. We first obtain differentially private estimators based on
bounded influence M-estimators by leveraging their gross-error sensitivity in
the calibration of a noise term added to them in order to ensure privacy. We
then show how a similar construction can also be applied to construct
differentially private test statistics analogous to the Wald, score and
likelihood ratio tests. We provide statistical guarantees for all our proposals
via an asymptotic analysis. An interesting consequence of our results is to
further clarify the connection between differential privacy and robust
statistics. In particular, we demonstrate that differential privacy is a weaker
stability requirement than infinitesimal robustness, and show that robust
M-estimators can be easily randomized in order to guarantee both differential
privacy and robustness towards the presence of contaminated data. We illustrate
our results both on simulated and real data.},
  file = {/Users/yuekai/Documents/zotero/Avella-Medina (2019) - Privacy-preserving parametric inference.pdf},
  language = {en}
}

@article{aydore2018Local,
  title = {A {{Local Regret}} in {{Nonconvex Online Learning}}},
  author = {Aydore, Sergul and Dicker, Lee and Foster, Dean},
  year = {2018},
  month = nov,
  abstract = {We consider an online learning process to forecast a sequence of outcomes for nonconvex models. A typical measure to evaluate online learning algorithms is regret but such standard definition of regret is intractable for nonconvex models even in offline settings. Hence, gradient based definition of regrets are common for both offline and online nonconvex problems. Recently, a notion of local gradient based regret was introduced. Inspired by the concept of calibration and a local gradient based regret, we introduce another definition of regret and we discuss why our definition is more interpretable for forecasting problems. We also provide bound analysis for our regret under certain assumptions.},
  archivePrefix = {arXiv},
  eprint = {1811.05095},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Aydore et al (2018) - A Local Regret in Nonconvex Online Learning.pdf},
  journal = {arXiv:1811.05095 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{azadkia2019simple,
  title = {A Simple Measure of Conditional Dependence},
  author = {Azadkia, Mona and Chatterjee, Sourav},
  year = {2019},
  month = oct,
  abstract = {We propose a coefficient of conditional dependence between two random variables \$Y\$ and \$Z\$ given a set of other variables \$X\_1,\textbackslash ldots,X\_p\$, based on an i.i.d. sample. The coefficient has a long list of desirable properties, the most important of which is that under absolutely no distributional assumptions, it converges to a limit in \$[0,1]\$, where the limit is \$0\$ if and only if \$Y\$ and \$Z\$ are conditionally independent given \$X\_1,\textbackslash ldots,X\_p\$, and is \$1\$ if and only if \$Y\$ is equal to a measurable function of \$Z\$ given \$X\_1,\textbackslash ldots,X\_p\$. Using this statistic, we devise a new variable selection algorithm, called Feature Ordering by Conditional Independence (FOCI), which is model-free, has no tuning parameters, and is provably consistent under sparsity assumptions. A number of applications to synthetic and real datasets are worked out.},
  archivePrefix = {arXiv},
  eprint = {1910.12327},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Azadkia, Chatterjee (2019) - A simple measure of conditional dependence.pdf},
  journal = {arXiv:1910.12327 [cs, math, stat]},
  keywords = {Computer Science - Information Theory,Mathematics - Probability,Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {cs, math, stat}
}

@article{azizzadenesheli2019Regularized,
  title = {Regularized {{Learning}} for {{Domain Adaptation}} under {{Label Shifts}}},
  author = {Azizzadenesheli, Kamyar and Liu, Anqi and Yang, Fanny and Anandkumar, Animashree},
  year = {2019},
  month = mar,
  abstract = {We propose Regularized Learning under Label shifts (RLLS), a principled and a practical domain-adaptation algorithm to correct for shifts in the label distribution between a source and a target domain. We first estimate importance weights using labeled source data and unlabeled target data, and then train a classifier on the weighted source samples. We derive a generalization bound for the classifier on the target domain which is independent of the (ambient) data dimensions, and instead only depends on the complexity of the function class. To the best of our knowledge, this is the first generalization bound for the label-shift problem where the labels in the target domain are not available. Based on this bound, we propose a regularized estimator for the small-sample regime which accounts for the uncertainty in the estimated weights. Experiments on the CIFAR-10 and MNIST datasets show that RLLS improves classification accuracy, especially in the low sample and large-shift regimes, compared to previous methods.},
  archivePrefix = {arXiv},
  eprint = {1903.09734},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Azizzadenesheli et al (2019) - Regularized Learning for Domain Adaptation under Label Shifts.pdf},
  journal = {arXiv:1903.09734 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{bach2016Breaking,
  title = {Breaking the {{Curse}} of {{Dimensionality}} with {{Convex Neural Networks}}},
  author = {Bach, Francis},
  year = {2016},
  month = oct,
  abstract = {We consider neural networks with a single hidden layer and non-decreasing homogeneous activa-tion functions like the rectified linear units. By letting the number of hidden units grow unbounded and using classical non-Euclidean regularization tools on the output weights, we provide a detailed theoretical analysis of their generalization performance, with a study of both the approximation and the estimation errors. We show in particular that they are adaptive to unknown underlying linear structures, such as the dependence on the projection of the input variables onto a low-dimensional subspace. Moreover, when using sparsity-inducing norms on the input weights, we show that high-dimensional non-linear variable selection may be achieved, without any strong assumption regarding the data and with a total number of variables potentially exponential in the number of ob-servations. In addition, we provide a simple geometric interpretation to the non-convex problem of addition of a new unit, which is the core potentially hard computational element in the framework of learning from continuously many basis functions. We provide simple conditions for convex relaxations to achieve the same generalization error bounds, even when constant-factor approxi-mations cannot be found (e.g., because it is NP-hard such as for the zero-homogeneous activation function). We were not able to find strong enough convex relaxations and leave open the existence or non-existence of polynomial-time algorithms.},
  archivePrefix = {arXiv},
  eprint = {1412.8690},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bach (2016) - Breaking the Curse of Dimensionality with Convex Neural Networks.pdf},
  journal = {arXiv:1412.8690 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Mathematics - Statistics Theory},
  primaryClass = {cs, math, stat}
}

@article{bache2013UCI,
  title = {{{UCI}} Machine Learning Repository},
  author = {Bache, K. and Lichman, M.},
  year = {2013},
  institution = {{University of California, Irvine, School of Information and Computer Sciences}},
  added-at = {2013-06-05T17:17:45.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/223ca94e325d0c8f933f08e479f2126a0/haeussner},
  description = {Sample Datasets for testing and evaluating e.g. machine learning algortihms such as Bayes Networks},
  interhash = {030e0b9dee25223d6311d687aa3b15e1},
  intrahash = {23ca94e325d0c8f933f08e479f2126a0},
  timestamp = {2013-06-05T17:17:45.000+0200}
}

@article{bagdasaryan2019Differential,
  title = {Differential {{Privacy Has Disparate Impact}} on {{Model Accuracy}}},
  author = {Bagdasaryan, Eugene and Shmatikov, Vitaly},
  year = {2019},
  month = may,
  abstract = {Differential privacy (DP) is a popular mechanism for training machine learning models with bounded leakage about the presence of specific points in the training data. The cost of differential privacy is a reduction in the model's accuracy. We demonstrate that this cost is not borne equally: accuracy of DP models drops much more for the underrepresented classes and subgroups. For example, a DP gender classification model exhibits much lower accuracy for black faces than for white faces. Critically, this gap is bigger in the DP model than in the non-DP model, i.e., if the original model is unfair, the unfairness becomes worse once DP is applied. We demonstrate this effect for a variety of tasks and models, including sentiment analysis of text and image classification. We then explain why DP training mechanisms such as gradient clipping and noise addition have disproportionate effect on the underrepresented and more complex subgroups, resulting in a disparate reduction of model accuracy.},
  archivePrefix = {arXiv},
  eprint = {1905.12101},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bagdasaryan, Shmatikov (2019) - Differential Privacy Has Disparate Impact on Model Accuracy.pdf},
  journal = {arXiv:1905.12101 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{baharlouei2019Renyi,
  title = {R\'enyi {{Fair Inference}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Baharlouei, Sina and Nouiehed, Maher and Beirami, Ahmad and Razaviyayn, Meisam},
  year = {2019},
  month = sep,
  abstract = {Machine learning algorithms have been increasingly deployed in critical automated decision-making systems that directly affect human lives. When these algorithms are solely trained to minimize the...},
  file = {/Users/yuekai/Documents/zotero/Baharlouei et al (2019) - Rényi Fair Inference2.pdf}
}

@article{bai2012Statistical,
  title = {Statistical Analysis of Factor Models of High Dimension},
  author = {Bai, Jushan and Li, Kunpeng},
  year = {2012},
  month = feb,
  volume = {40},
  pages = {436--465},
  issn = {0090-5364},
  doi = {10.1214/11-AOS966},
  abstract = {This paper considers the maximum likelihood estimation of factor models of high dimension, where the number of variables (N) is comparable with or even greater than the number of observations (T). An inferential theory is developed. We establish not only consistency but also the rate of convergence and the limiting distributions. Five different sets of identification conditions are considered. We show that the distributions of the MLE estimators depend on the identification restrictions. Unlike the principal components approach, the maximum likelihood estimator explicitly allows heteroskedasticities, which are jointly estimated with other parameters. Efficiency of MLE relative to the principal components method is also considered.},
  archivePrefix = {arXiv},
  eprint = {1205.6617},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bai, Li (2012) - Statistical analysis of factor models of high dimension.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory},
  language = {en},
  number = {1}
}

@article{bai2019Approximability,
  ids = {bai2018Approximability},
  title = {Approximability of {{Discriminators Implies Diversity}} in {{GANs}}},
  author = {Bai, Yu and Ma, Tengyu and Risteski, Andrej},
  year = {2019},
  month = jul,
  abstract = {While Generative Adversarial Networks (GANs) have empirically produced impressive results on learning complex real-world distributions, recent works have shown that they suffer from lack of diversity or mode collapse. The theoretical work of Arora et al. suggests a dilemma about GANs' statistical properties: powerful discriminators cause overfitting, whereas weak discriminators cannot detect mode collapse. By contrast, we show in this paper that GANs can in principle learn distributions in Wasserstein distance (or KL-divergence in many cases) with polynomial sample complexity, if the discriminator class has strong distinguishing power against the particular generator class (instead of against all possible generators). For various generator classes such as mixture of Gaussians, exponential families, and invertible and injective neural networks generators, we design corresponding discriminators (which are often neural nets of specific architectures) such that the Integral Probability Metric (IPM) induced by the discriminators can provably approximate the Wasserstein distance and/or KL-divergence. This implies that if the training is successful, then the learned distribution is close to the true distribution in Wasserstein distance or KL divergence, and thus cannot drop modes. Our preliminary experiments show that on synthetic datasets the test IPM is well correlated with KL divergence or the Wasserstein distance, indicating that the lack of diversity in GANs may be caused by the sub-optimality in optimization instead of statistical inefficiency.},
  archivePrefix = {arXiv},
  eprint = {1806.10586},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bai et al (2018) - Approximability of Discriminators Implies Diversity in GANs.pdf;/Users/yuekai/Documents/zotero/Bai et al (2019) - Approximability of Discriminators Implies Diversity in GANs.pdf},
  journal = {arXiv:1806.10586 [cs, stat]},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{baker1973Joint,
  title = {Joint {{Measures}} and {{Cross}}-{{Covariance Operators}}},
  author = {Baker, Charles R.},
  year = {1973},
  volume = {186},
  pages = {273--289},
  issn = {0002-9947},
  doi = {10.2307/1996566},
  abstract = {[Let \$H\_1 (\textbackslash operatorname\{resp.\}, H\_2)\$ be a real and separable Hilbert space with Borel {$\sigma$}-field {$\Gamma$}1 (\{operatornameresp., {$\Gamma$}2), and let (H1 \texttimes{} H2, {$\Gamma$}1 \texttimes{} {$\Gamma$}2) be the product measurable space generated by the measurable rectangles. This paper develops relations between probability measures on (H1 \texttimes{} H2, {$\Gamma$}1 \texttimes{} {$\Gamma$}2) i.e., joint measures, and the projections of such measures on (H1, {$\Gamma$}1) and (H2, {$\Gamma$}2). In particular, the class of all joint Gaussian measures having two specified Gaussian measures as projections is characterized, and conditions are obtained for two joint Gaussian measures to be mutually absolutely continuous. The cross-covariance operator of a joint measure plays a major role in these results and these operators are characterized.]\vphantom\}},
  file = {/Users/yuekai/Documents/zotero/Baker (1973) - Joint Measures and Cross-Covariance Operators.pdf},
  journal = {Transactions of the American Mathematical Society}
}

@article{baker2019Feature,
  title = {Feature {{Selection}} for {{Data Integration}} with {{Mixed Multi}}-View {{Data}}},
  author = {Baker, Yulia and Tang, Tiffany M. and Allen, Genevera I.},
  year = {2019},
  month = mar,
  abstract = {Data integration methods that analyze multiple sources of data simultaneously can often provide more holistic insights than can separate inquiries of each data source. Motivated by the advantages of data integration in the era of "big data", we investigate feature selection for high-dimensional multi-view data with mixed data types (e.g. continuous, binary, count-valued). This heterogeneity of multi-view data poses numerous challenges for existing feature selection methods. However, after critically examining these issues through empirical and theoretically-guided lenses, we develop a practical solution, the Block Randomized Adaptive Iterative Lasso (B-RAIL), which combines the strengths of the randomized Lasso, adaptive weighting schemes, and stability selection. B-RAIL serves as a versatile data integration method for sparse regression and graph selection, and we demonstrate the effectiveness of B-RAIL through extensive simulations and a case study to infer the ovarian cancer gene regulatory network. In this case study, B-RAIL successfully identifies well-known biomarkers associated with ovarian cancer and hints at novel candidates for future ovarian cancer research.},
  archivePrefix = {arXiv},
  eprint = {1903.11232},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Baker et al (2019) - Feature Selection for Data Integration with Mixed Multi-view Data.pdf},
  journal = {arXiv:1903.11232 [stat]},
  keywords = {Statistics - Applications,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {stat}
}

@article{baker2019Workshop,
  title = {Workshop Report on Basic Research Needs for Scientific Machine Learning: {{Core}} Technologies for Artificial Intelligence},
  author = {Baker, Nathan and Alexander, Frank and Bremer, Timo and Hagberg, Aric and Kevrekidis, Yannis and Najm, Habib and Parashar, Manish and Patra, Abani and Sethian, James and Wild, Stefan and Willcox, Karen and Lee, Steven},
  year = {2019},
  month = feb,
  doi = {10.2172/1478744},
  abstractnote = {Scientific Machine Learning (SciML) and Artificial Intelligence (AI) will have broad use and transformative effects across the Department of Energy. Accordingly, the January 2018 Basic Research Needs workshop identified six Priority Research Directions (PRDs). The first three PRDs describe foundational research themes that correspond to the need for domain-awareness (PRD \#1), interpretability (PRD \#2), and robustness (PRD \#3). The other three PRDs describe capability research themes and correspond to the three major use cases for massive scientific data analysis (PRD \#4), machine learning-enhanced modeling and simulation (PRD \#5), and intelligent automation and decision-support for complex systems (PRD \#6). The Priority Research Directions provide a sound basis for a coherent, long-term research and development strategy in SciML and AI. Over the last decade, DOE investments in applied mathematics have laid the groundwork for the type of basic research that will underpin key advances in the six PRDs. Such advances will build on the work from leading researchers in optimization, linear algebra, high-performance solvers and algorithms, multiscale modeling and simulation, complex systems research, uncertainty quantification, and the new basic research areas that will emerge from the pursuit of transformative technologies.},
  file = {/Users/yuekai/Documents/zotero/Baker et al (2019) - Workshop report on basic research needs for scientific machine learning.pdf},
  place = {United States}
}

@article{bakker2019Fairness,
  title = {On {{Fairness}} in {{Budget}}-{{Constrained Decision Making}}},
  author = {Bakker, Michiel A and {Noriega-Campero}, Alejandro and Tu, Duy Patrick and Sattigeri, Prasanna and Varshney, Kush R},
  year = {2019},
  pages = {8},
  abstract = {The machine learning community and society at large have become increasingly concerned with discrimination and bias in data-driven decision making systems. This has led to a dramatic increase in academic and popular interest in algorithmic fairness. In this work, we focus on fairness in budget-constrained decision making, where the goal is to acquire information (features) one-by-one for each individual to achieve maximum classification performance in a cost-effective way. We provide a framework for choosing a set of stopping criteria that ensures that a probabilistic classifier achieves a single error parity (e.g. equal opportunity) and calibration. Our framework scales efficiently to multiple protected attributes and is not susceptible to intra-group unfairness. Finally, using one synthetic and two public datasets, we confirm the effectiveness of our framework and investigate its limitations.},
  file = {/Users/yuekai/Documents/zotero/Bakker et al (2019) - On Fairness in Budget-Constrained Decision Making.pdf},
  language = {en}
}

@article{balabdaoui2016Least,
  title = {Least Squares Estimation in the Monotone Single Index Model},
  author = {Balabdaoui, F. and Durot, C. and Jankowski, H.},
  year = {2016},
  month = oct,
  abstract = {We study the monotone single index model where a real response variable \$Y \$ is linked to a \$d\$-dimensional covariate \$X\$ through the relationship \$E[Y | X] = \textbackslash Psi\_0(\textbackslash alpha\^T\_0 X)\$ almost surely. Both the ridge function, \$\textbackslash Psi\_0\$, and the index parameter, \$\textbackslash alpha\_0\$, are unknown and the ridge function is assumed to be monotone on its interval of support. Under some regularity conditions, without imposing a particular distribution on the regression error, we show the \$n\^\{-1/3\}\$ rate of convergence in the \$\textbackslash ell\_2\$-norm for the least squares estimator of the bundled function \$\textbackslash psi\_0(\{\textbackslash alpha\}\^T\_0 \textbackslash cdot),\$ and also that of the ridge function and the index separately. Furthermore, we show that the least squares estimator is nearly parametrically rate-adaptive to piecewise constant ridge functions.},
  archivePrefix = {arXiv},
  eprint = {1610.06026},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Balabdaoui et al (2016) - Least squares estimation in the monotone single index model.pdf},
  journal = {arXiv:1610.06026 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{balabdaoui2019Score,
  title = {Score Estimation in the Monotone Single Index Model},
  author = {Balabdaoui, Fadoua and Groeneboom, Piet and Hendrickx, Kim},
  year = {2019},
  month = jun,
  volume = {46},
  pages = {517--544},
  issn = {0303-6898, 1467-9469},
  doi = {10.1111/sjos.12361},
  abstract = {We consider estimation in the single index model where the link function is monotone. For this model a profile least squares estimator has been proposed to estimate the unknown link function and index. Although it is natural to propose this procedure, it is still unknown whether it produces index estimates which converge at the parametric rate. We show that this holds if we solve a score equation corresponding to this least squares problem. Using a Lagrangian formulation, we show how one can solve this score equation without any reparametrization. This makes it easy to solve the score equations in high dimensions. We also compare our method with the Effective Dimension Reduction (EDR) and the Penalized Least Squares Estimator (PLSE) methods, both available on CRAN as R packages, and compare with link-free methods, where the covariates are ellipticallly symmetric.},
  archivePrefix = {arXiv},
  eprint = {1712.05593},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Balabdaoui et al (2019) - Score estimation in the monotone single index model.pdf},
  journal = {Scandinavian Journal of Statistics},
  keywords = {Mathematics - Statistics Theory},
  number = {2}
}

@article{balakrishnan2014Statistical,
  title = {Statistical Guarantees for the {{EM}} Algorithm: {{From}} Population to Sample-Based Analysis},
  shorttitle = {Statistical Guarantees for the {{EM}} Algorithm},
  author = {Balakrishnan, Sivaraman and Wainwright, Martin J. and Yu, Bin},
  year = {2014},
  month = aug,
  abstract = {We develop a general framework for proving rigorous guarantees on the performance of the EM algorithm and a variant known as gradient EM. Our analysis is divided into two parts: a treatment of these algorithms at the population level (in the limit of infinite data), followed by results that apply to updates based on a finite set of samples. First, we characterize the domain of attraction of any global maximizer of the population likelihood. This characterization is based on a novel view of the EM updates as a perturbed form of likelihood ascent, or in parallel, of the gradient EM updates as a perturbed form of standard gradient ascent. Leveraging this characterization, we then provide non-asymptotic guarantees on the EM and gradient EM algorithms when applied to a finite set of samples. We develop consequences of our general theory for three canonical examples of incomplete-data problems: mixture of Gaussians, mixture of regressions, and linear regression with covariates missing completely at random. In each case, our theory guarantees that with a suitable initialization, a relatively small number of EM (or gradient EM) steps will yield (with high probability) an estimate that is within statistical error of the MLE. We provide simulations to confirm this theoretically predicted behavior.},
  archivePrefix = {arXiv},
  eprint = {1408.2156},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Balakrishnan et al (2014) - Statistical guarantees for the EM algorithm.pdf},
  journal = {arXiv:1408.2156 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{balashankar2019What,
  title = {What Is {{Fair}}? {{Exploring Pareto}}-{{Efficiency}} for {{Fairness Constrained Classifiers}}},
  shorttitle = {What Is {{Fair}}?},
  author = {Balashankar, Ananth and Lees, Alyssa and Welty, Chris and Subramanian, Lakshminarayanan},
  year = {2019},
  month = oct,
  abstract = {The potential for learned models to amplify existing societal biases has been broadly recognized. Fairness-aware classifier constraints, which apply equality metrics of performance across subgroups defined on sensitive attributes such as race and gender, seek to rectify inequity but can yield non-uniform degradation in performance for skewed datasets. In certain domains, imbalanced degradation of performance can yield another form of unintentional bias. In the spirit of constructing fairness-aware algorithms as societal imperative, we explore an alternative: Pareto-Efficient Fairness (PEF). Theoretically, we prove that PEF identifies the operating point on the Pareto curve of subgroup performances closest to the fairness hyperplane, maximizing multiple subgroup accuracy. Empirically we demonstrate that PEF outperforms by achieving Pareto levels in accuracy for all subgroups compared to strict fairness constraints in several UCI datasets.},
  archivePrefix = {arXiv},
  eprint = {1910.14120},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Balashankar et al (2019) - What is Fair.pdf},
  journal = {arXiv:1910.14120 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{balcan2006Agnostic,
  title = {Agnostic Active Learning},
  booktitle = {Proceedings of the 23rd International Conference on {{Machine}} Learning},
  author = {Balcan, Maria-Florina and Beygelzimer, Alina and Langford, John},
  year = {2006},
  month = jun,
  pages = {65--72},
  publisher = {{Association for Computing Machinery}},
  address = {{Pittsburgh, Pennsylvania, USA}},
  doi = {10.1145/1143844.1143853},
  abstract = {We state and analyze the first active learning algorithm which works in the presence of arbitrary forms of noise. The algorithm, A2 (for Agnostic Active), relies only upon the assumption that the samples are drawn i.i.d. from a fixed distribution. We show that A2 achieves an exponential improvement (i.e., requires only O (ln 1/{$\epsilon$}) samples to find an {$\epsilon$}-optimal classifier) over the usual sample complexity of supervised learning, for several settings considered before in the realizable case. These include learning threshold classifiers and learning homogeneous linear separators with respect to an input distribution which is uniform over the unit sphere.},
  file = {/Users/yuekai/Documents/zotero/Balcan et al (2006) - Agnostic active learning.pdf},
  isbn = {978-1-59593-383-6},
  series = {{{ICML}} '06}
}

@article{baldin2018Optimal,
  title = {Optimal Link Prediction with Matrix Logistic Regression},
  author = {Baldin, Nicolai and Berthet, Quentin},
  year = {2018},
  month = mar,
  abstract = {We consider the problem of link prediction, based on partial observation of a large network, and on side information associated to its vertices. The generative model is formulated as a matrix logistic regression. The performance of the model is analysed in a highdimensional regime under a structural assumption. The minimax rate for the Frobenius-norm risk is established and a combinatorial estimator based on the penalised maximum likelihood approach is shown to achieve it. Furthermore, it is shown that this rate cannot be attained by any (randomised) algorithm computable in polynomial time under a computational complexity assumption.},
  archivePrefix = {arXiv},
  eprint = {1803.07054},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Baldin, Berthet (2018) - Optimal link prediction with matrix logistic regression.pdf},
  journal = {arXiv:1803.07054 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning},
  language = {en},
  primaryClass = {math, stat}
}

@article{balghiti2019Generalization,
  title = {Generalization {{Bounds}} in the {{Predict}}-Then-{{Optimize Framework}}},
  author = {Balghiti, Othman El and Elmachtoub, Adam N. and Grigas, Paul and Tewari, Ambuj},
  year = {2019},
  month = may,
  abstract = {The predict-then-optimize framework is fundamental in many practical settings: predict the unknown parameters of an optimization problem, and then solve the problem using the predicted values of the parameters. A natural loss function in this environment is to consider the cost of the decisions induced by the predicted parameters, in contrast to the prediction error of the parameters. This loss function was recently introduced in Elmachtoub and Grigas (2017), which called it the Smart Predict-then-Optimize (SPO) loss. Since the SPO loss is nonconvex and noncontinuous, standard results for deriving generalization bounds do not apply. In this work, we provide an assortment of generalization bounds for the SPO loss function. In particular, we derive bounds based on the Natarajan dimension that, in the case of a polyhedral feasible region, scale at most logarithmically in the number of extreme points, but, in the case of a general convex set, have poor dependence on the dimension. By exploiting the structure of the SPO loss function and an additional strong convexity assumption on the feasible region, we can dramatically improve the dependence on the dimension via an analysis and corresponding bounds that are akin to the margin guarantees in classification problems.},
  archivePrefix = {arXiv},
  eprint = {1905.11488},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Balghiti et al (2019) - Generalization Bounds in the Predict-then-Optimize Framework.pdf},
  journal = {arXiv:1905.11488 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{balkanski2018Importance,
  title = {The {{Importance}} of {{Communities}} for {{Learning}} to {{Influence}}},
  author = {Balkanski, Eric and Immorlica, Nicole and Singer, Yaron},
  year = {2018},
  month = jan,
  abstract = {We consider the canonical problem of influence maximization in social networks. Since the seminal work of Kempe, Kleinberg, and Tardos, there have been two largely disjoint efforts on this problem. The first studies the problem associated with learning the parameters of the generative influence model. The second focuses on the algorithmic challenge of identifying a set of influencers, assuming the parameters of the generative model are known. Recent results on learning and optimization imply that in general, if the generative model is not known but rather learned from training data, no algorithm can yield a constant factor approximation guarantee using polynomially-many samples, drawn from any distribution. In this paper, we design a simple heuristic that overcomes this negative result in practice by leveraging the strong community structure of social networks. Although in general the approximation guarantee of our algorithm is necessarily unbounded, we show that this algorithm performs well experimentally. To justify its performance, we prove our algorithm obtains a constant factor approximation guarantee on graphs generated through the stochastic block model, traditionally used to model networks with community structure.},
  archivePrefix = {arXiv},
  eprint = {1801.07355},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Balkanski et al (2018) - The Importance of Communities for Learning to Influence.pdf},
  journal = {arXiv:1801.07355 [cs]},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Social and Information Networks},
  primaryClass = {cs}
}

@article{ballu2020Stochastic,
  title = {Stochastic {{Optimization}} for {{Regularized Wasserstein Estimators}}},
  author = {Ballu, Marin and Berthet, Quentin and Bach, Francis},
  year = {2020},
  month = feb,
  abstract = {Optimal transport is a foundational problem in optimization, that allows to compare probability distributions while taking into account geometric aspects. Its optimal objective value, the Wasserstein distance, provides an important loss between distributions that has been used in many applications throughout machine learning and statistics. Recent algorithmic progress on this problem and its regularized versions have made these tools increasingly popular. However, existing techniques require solving an optimization problem to obtain a single gradient of the loss, thus slowing down first-order methods to minimize the sum of losses, that require many such gradient computations. In this work, we introduce an algorithm to solve a regularized version of this problem of Wasserstein estimators, with a time per step which is sublinear in the natural dimensions of the problem. We introduce a dual formulation, and optimize it with stochastic gradient steps that can be computed directly from samples, without solving additional optimization problems at each step. Doing so, the estimation and computation tasks are performed jointly. We show that this algorithm can be extended to other tasks, including estimation of Wasserstein barycenters. We provide theoretical guarantees and illustrate the performance of our algorithm with experiments on synthetic data.},
  archivePrefix = {arXiv},
  eprint = {2002.08695},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ballu et al (2020) - Stochastic Optimization for Regularized Wasserstein Estimators.pdf},
  journal = {arXiv:2002.08695 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{bandeira2016Sharp,
  title = {Sharp Nonasymptotic Bounds on the Norm of Random Matrices with Independent Entries},
  author = {Bandeira, Afonso S. and {van Handel}, Ramon},
  year = {2016},
  month = jul,
  volume = {44},
  pages = {2479--2506},
  issn = {0091-1798},
  doi = {10.1214/15-AOP1025},
  abstract = {We obtain nonasymptotic bounds on the spectral norm of random matrices with independent entries that improve significantly on earlier results. If \$X\$ is the \$n\textbackslash times n\$ symmetric matrix with \$X\_\{ij\}\textbackslash sim N(0,b\_\{ij\}\^2)\$, we show that \textbackslash [\textbackslash mathbf\{E\}\textbackslash Vert X\textbackslash Vert \textbackslash lesssim\textbackslash max\_i\textbackslash sqrt\{\textbackslash sum\_jb\_\{ij\}\^2\}+\textbackslash max \_\{ij\}\textbackslash vert b\_\{ij\}\textbackslash vert \textbackslash sqrt\{\textbackslash log n\}.\textbackslash ] This bound is optimal in the sense that a matching lower bound holds under mild assumptions, and the constants are sufficiently sharp that we can often capture the precise edge of the spectrum. Analogous results are obtained for rectangular matrices and for more general sub-Gaussian or heavy-tailed distributions of the entries, and we derive tail bounds in addition to bounds on the expected norm. The proofs are based on a combination of the moment method and geometric functional analysis techniques. As an application, we show that our bounds immediately yield the correct phase transition behavior of the spectral edge of random band matrices and of sparse Wigner matrices. We also recover a result of Seginer on the norm of Rademacher matrices.},
  archivePrefix = {arXiv},
  eprint = {1408.6185},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bandeira, van Handel (2016) - Sharp nonasymptotic bounds on the norm of random matrices with independent.pdf},
  journal = {The Annals of Probability},
  keywords = {Mathematics - Functional Analysis,Mathematics - Probability},
  number = {4}
}

@article{banerjee2007Likelihood,
  title = {Likelihood Based Inference for Monotone Response Models},
  author = {Banerjee, Moulinath},
  year = {2007},
  month = jul,
  volume = {35},
  pages = {931--956},
  issn = {0090-5364},
  doi = {10.1214/009053606000001578},
  abstract = {The behavior of maximum likelihood estimates (MLEs) and the likelihood ratio statistic in a family of problems involving pointwise nonparametric estimation of a monotone function is studied. This class of problems differs radically from the usual parametric or semiparametric situations in that the MLE of the monotone function at a point converges to the truth at rate \$n\^\{1/3\}\$ (slower than the usual \$\textbackslash sqrt\{n\}\$ rate) with a non-Gaussian limit distribution. A framework for likelihood based estimation of monotone functions is developed and limit theorems describing the behavior of the MLEs and the likelihood ratio statistic are established. In particular, the likelihood ratio statistic is found to be asymptotically pivotal with a limit distribution that is no longer \$\textbackslash chi\^2\$ but can be explicitly characterized in terms of a functional of Brownian motion. Applications of the main results are presented and potential extensions discussed.},
  archivePrefix = {arXiv},
  eprint = {0708.2177},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Banerjee (2007) - Likelihood based inference for monotone response models.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory},
  language = {en},
  number = {3}
}

@article{banerjee2008Model,
  title = {Model {{Selection Through Sparse Maximum Likelihood Estimation}} for {{Multivariate Gaussian}} or {{Binary Data}}},
  author = {Banerjee, Onureena and Ghaoui, Laurent El},
  year = {2008},
  month = jun,
  pages = {35},
  abstract = {We consider the problem of estimating the parameters of a Gaussian or binary distribution in such a way that the resulting undirected graphical model is sparse. Our approach is to solve a maximum likelihood problem with an added {$\mathscr{l}$}1-norm penalty term. The problem as formulated is convex but the memory requirements and complexity of existing interior point methods are prohibitive for problems with more than tens of nodes. We present two new algorithms for solving problems with at least a thousand nodes in the Gaussian case. Our first algorithm uses block coordinate descent, and can be interpreted as recursive {$\mathscr{l}$}1-norm penalized regression. Our second algorithm, based on Nesterov's first order method, yields a complexity estimate with a better dependence on problem size than existing interior point methods. Using a log determinant relaxation of the log partition function (Wainwright and Jordan [2006]), we show that these same algorithms can be used to solve an approximate sparse maximum likelihood problem for the binary case. We test our algorithms on synthetic data, as well as on gene expression and senate voting records data.},
  file = {/Users/yuekai/Documents/zotero/Banerjee, Ghaoui (2008) - Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate.pdf},
  language = {en}
}

@article{bao2017TracyWidom,
  title = {Tracy-{{Widom}} Limit for {{Kendall}}'s Tau},
  author = {Bao, Zhigang},
  year = {2017},
  month = dec,
  abstract = {In this paper, we study a high-dimensional random matrix model from nonparametric statistics called Kendall rank correlation matrix, which is a natural multivariate extension of Kendall rank correlation coefficient. We establish the Tracy-Widom law for its largest eigenvalue. It is the first Tracy-Widom law obtained for a nonparametric random matrix model, and is also the first Tracy-Widom law for a high-dimensional U-statistics.},
  archivePrefix = {arXiv},
  eprint = {1712.00892},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bao (2017) - Tracy-Widom limit for Kendall's tau.pdf},
  journal = {arXiv:1712.00892 [math, stat]},
  keywords = {Mathematics - Probability,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{bao2018Singular,
  title = {Singular Vector and Singular Subspace Distribution for the Matrix Denoising Model},
  author = {Bao, Zhigang and Ding, Xiucai and Wang, Ke},
  year = {2018},
  month = sep,
  abstract = {In this paper, we study the matrix denosing model \$Y=S+X\$, where \$S\$ is a low-rank deterministic signal matrix and \$X\$ is a random noise matrix, and both are \$M\textbackslash times n\$. In the scenario that \$M\$ and \$n\$ are comparably large and the signals are supercritical, we study the fluctuation of the outlier singular vectors of \$Y\$. More specifically, we derive the limiting distribution of angles between the principal singular vectors of \$Y\$ and their deterministic counterparts, the singular vectors of \$S\$. Further, we also derive the distribution of the distance between the subspace spanned by the principal singular vectors of \$Y\$ and that spanned by the singular vectors of \$S\$. It turns out that the limiting distributions depend on the structure of the singular vectors of \$S\$ and the distribution of \$X\$, and thus they are non-universal.},
  archivePrefix = {arXiv},
  eprint = {1809.10476},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bao et al (2018) - Singular vector and singular subspace distribution for the matrix denoising.pdf},
  journal = {arXiv:1809.10476 [math, stat]},
  keywords = {Mathematics - Probability,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@book{bar-shalom1990Multitargetmultisensor,
  title = {Multitarget-Multisensor Tracking. [{{Vol}}. 1] {{Advanced}} Applications},
  author = {{Bar-Shalom}, Yaakov},
  year = {1990},
  publisher = {{Artech House}},
  address = {{Norwood, Mass.; Boston}},
  annotation = {OCLC: 256498643},
  isbn = {978-0-89006-377-4},
  language = {English}
}

@article{barber2019Conformal,
  title = {Conformal {{Prediction Under Covariate Shift}}},
  author = {Barber, Rina Foygel and Candes, Emmanuel J. and Ramdas, Aaditya and Tibshirani, Ryan J.},
  year = {2019},
  month = apr,
  abstract = {We extend conformal prediction methodology beyond the case of exchangeable data. In particular, we show that a weighted version of conformal prediction can be used to compute distribution-free prediction intervals for problems in which the test and training covariate distributions differ, but the likelihood ratio between these two distributions is known---or, in practice, can be estimated accurately with access to a large set of unlabeled data (test covariate points). Our weighted extension of conformal prediction also applies more generally, to settings in which the data satisfies a certain weighted notion of exchangeability. We discuss other potential applications of our new conformal methodology, including latent variable and missing data problems.},
  archivePrefix = {arXiv},
  eprint = {1904.06019},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Barber et al (2019) - Conformal Prediction Under Covariate Shift.pdf},
  journal = {arXiv:1904.06019 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{barber2019limits,
  title = {The Limits of Distribution-Free Conditional Predictive Inference},
  author = {Barber, Rina Foygel and Cand{\`e}s, Emmanuel J. and Ramdas, Aaditya and Tibshirani, Ryan J.},
  year = {2019},
  month = mar,
  abstract = {We consider the problem of distribution-free predictive inference, with the goal of producing predictive coverage guarantees that hold conditionally rather than marginally. Existing methods such as conformal prediction offer marginal coverage guarantees, where predictive coverage holds on average over all possible test points, but this is not sufficient for many practical applications where we would like to know that our predictions are valid for a given individual, not merely on average over a population. On the other hand, exact conditional inference guarantees are known to be impossible without imposing assumptions on the underlying distribution. In this work we aim to explore the space in between these two, and examine what types of relaxations of the conditional coverage property would alleviate some of the practical concerns with marginal coverage guarantees while still being possible to achieve in a distribution-free setting.},
  archivePrefix = {arXiv},
  eprint = {1903.04684},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Barber et al (2019) - The limits of distribution-free conditional predictive inference.pdf},
  journal = {arXiv:1903.04684 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{bareinboim2016Causal,
  title = {Causal Inference and the Data-Fusion Problem},
  author = {Bareinboim, Elias and Pearl, Judea},
  year = {2016},
  month = jul,
  volume = {113},
  pages = {7345--7352},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1510507113},
  abstract = {We review concepts, principles, and tools that unify current approaches to causal analysis and attend to new challenges presented by big data. In particular, we address the problem of data fusion\textemdash piecing together multiple datasets collected under heterogeneous conditions (i.e., different populations, regimes, and sampling methods) to obtain valid answers to queries of interest. The availability of multiple heterogeneous datasets presents new opportunities to big data analysts, because the knowledge that can be acquired from combined data would not be possible from any individual source alone. However, the biases that emerge in heterogeneous environments require new analytical tools. Some of these biases, including confounding, sampling selection, and cross-population biases, have been addressed in isolation, largely in restricted parametric models. We here present a general, nonparametric framework for handling these biases and, ultimately, a theoretical solution to the problem of data fusion in causal inference tasks.},
  file = {/Users/yuekai/Documents/zotero/Bareinboim, Pearl (2016) - Causal inference and the data-fusion problem.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {27},
  pmid = {27382148}
}

@article{barocas2016Big,
  title = {Big {{Data}}'s {{Disparate Impact}}},
  author = {Barocas, Solon and Selbst, Andrew D.},
  year = {2016},
  issn = {1556-5068},
  doi = {10.2139/ssrn.2477899},
  file = {/Users/yuekai/Documents/zotero/Barocas, Selbst (2016) - Big Data's Disparate Impact.pdf},
  journal = {SSRN Electronic Journal},
  language = {en}
}

@article{barrett2009Genomewide,
  title = {Genome-Wide Association Study and Meta-Analysis Find That over 40 Loci Affect Risk of Type 1 Diabetes},
  author = {Barrett, Jeffrey C. and Clayton, David G. and Concannon, Patrick and Akolkar, Beena and Cooper, Jason D. and Erlich, Henry A. and Julier, C{\'e}cile and Morahan, Grant and Nerup, J{\o}rn and Nierras, Concepcion and Plagnol, Vincent and Pociot, Flemming and Schuilenburg, Helen and Smyth, Deborah J. and Stevens, Helen and Todd, John A. and Walker, Neil M. and Rich, Stephen S.},
  year = {2009},
  month = jun,
  volume = {41},
  pages = {703--707},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1718},
  doi = {10.1038/ng.381},
  abstract = {Patrick Concannon and colleagues present a type 1 diabetes genome-wide association study and meta-analysis in 7,514 cases and 9,045 reference samples, reporting 22 newly identified loci.},
  copyright = {2009 Nature Publishing Group},
  file = {/Users/yuekai/Documents/zotero/Barrett et al (2009) - Genome-wide association study and meta-analysis find that over 40 loci affect.pdf;/Users/yuekai/Zotero/storage/AGBQ49WX/ng.html},
  journal = {Nature Genetics},
  language = {en},
  number = {6}
}

@misc{barry-jester2015Should,
  title = {Should {{Prison Sentences Be Based On Crimes That Haven}}'t {{Been Committed Yet}}?},
  author = {{Barry-Jester}, Anna Maria and Casselman, Ben and Goldstein, Dana},
  year = {2015},
  month = aug,
  abstract = {The new science of sentencing.},
  journal = {FiveThirtyEight},
  language = {en-US}
}

@article{bartlett2005Local,
  title = {Local {{Rademacher}} Complexities},
  author = {Bartlett, Peter L. and Bousquet, Olivier and Mendelson, Shahar},
  year = {2005},
  month = aug,
  volume = {33},
  pages = {1497--1537},
  issn = {0090-5364},
  doi = {10.1214/009053605000000282},
  abstract = {We propose new bounds on the error of learning algorithms in terms of a data-dependent notion of complexity. The estimates we establish give optimal rates and are based on a local and empirical version of Rademacher averages, in the sense that the Rademacher averages are computed from the data, on a subset of functions with small empirical error. We present some applications to classification and prediction with convex function classes, and with kernel classes in particular.},
  archivePrefix = {arXiv},
  eprint = {math/0508275},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bartlett et al (2005) - Local Rademacher complexities.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory},
  number = {4}
}

@article{bartlett2017Spectrallynormalized,
  title = {Spectrally-Normalized Margin Bounds for Neural Networks},
  author = {Bartlett, Peter and Foster, Dylan J. and Telgarsky, Matus},
  year = {2017},
  month = jun,
  abstract = {This paper presents a margin-based multiclass generalization bound for neural networks that scales with their margin-normalized "spectral complexity": their Lipschitz constant, meaning the product of the spectral norms of the weight matrices, times a certain correction factor. This bound is empirically investigated for a standard AlexNet network trained with SGD on the mnist and cifar10 datasets, with both original and random labels; the bound, the Lipschitz constants, and the excess risks are all in direct correlation, suggesting both that SGD selects predictors whose complexity scales with the difficulty of the learning task, and secondly that the presented bound is sensitive to this complexity.},
  archivePrefix = {arXiv},
  eprint = {1706.08498},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bartlett et al (2017) - Spectrally-normalized margin bounds for neural networks.pdf},
  journal = {arXiv:1706.08498 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{bartlett2019Benign,
  title = {Benign {{Overfitting}} in {{Linear Regression}}},
  author = {Bartlett, Peter L. and Long, Philip M. and Lugosi, G{\'a}bor and Tsigler, Alexander},
  year = {2019},
  month = jun,
  abstract = {The phenomenon of benign overfitting is one of the key mysteries uncovered by deep learning methodology: deep neural networks seem to predict well, even with a perfect fit to noisy training data. Motivated by this phenomenon, we consider when a perfect fit to training data in linear regression is compatible with accurate prediction. We give a characterization of gaussian linear regression problems for which the minimum norm interpolating prediction rule has near-optimal prediction accuracy. The characterization is in terms of two notions of the effective rank of the data covariance. It shows that overparameterization is essential for benign overfitting in this setting: the number of directions in parameter space that are unimportant for prediction must significantly exceed the sample size.},
  archivePrefix = {arXiv},
  eprint = {1906.11300},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bartlett et al (2019) - Benign Overfitting in Linear Regression.pdf},
  journal = {arXiv:1906.11300 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{bassily2019Private,
  title = {Private {{Stochastic Convex Optimization}} with {{Optimal Rates}}},
  author = {Bassily, Raef and Feldman, Vitaly and Talwar, Kunal and Thakurta, Abhradeep},
  year = {2019},
  month = aug,
  abstract = {We study differentially private (DP) algorithms for stochastic convex optimization (SCO). In this problem the goal is to approximately minimize the population loss given i.i.d. samples from a distribution over convex and Lipschitz loss functions. A long line of existing work on private convex optimization focuses on the empirical loss and derives asymptotically tight bounds on the excess empirical loss. However a significant gap exists in the known bounds for the population loss. We show that, up to logarithmic factors, the optimal excess population loss for DP algorithms is equal to the larger of the optimal non-private excess population loss, and the optimal excess empirical loss of DP algorithms. This implies that, contrary to intuition based on private ERM, private SCO has asymptotically the same rate of \$1/\textbackslash sqrt\{n\}\$ as non-private SCO in the parameter regime most common in practice. The best previous result in this setting gives rate of \$1/n\^\{1/4\}\$. Our approach builds on existing differentially private algorithms and relies on the analysis of algorithmic stability to ensure generalization.},
  archivePrefix = {arXiv},
  eprint = {1908.09970},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bassily et al (2019) - Private Stochastic Convex Optimization with Optimal Rates.pdf},
  journal = {arXiv:1908.09970 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{bastani2015Online,
  title = {Online {{Decision}}-{{Making}} with {{High}}-{{Dimensional Covariates}}},
  author = {Bastani, Hamsa and Bayati, Mohsen},
  year = {2015},
  issn = {1556-5068},
  doi = {10.2139/ssrn.2661896},
  file = {/Users/yuekai/Documents/zotero/Bastani, Bayati (2015) - Online Decision-Making with High-Dimensional Covariates.pdf},
  journal = {SSRN Electronic Journal},
  language = {en}
}

@article{bastani2017Mostly,
  title = {Mostly {{Exploration}}-{{Free Algorithms}} for {{Contextual Bandits}}},
  author = {Bastani, Hamsa and Bayati, Mohsen and Khosravi, Khashayar},
  year = {2017},
  month = apr,
  abstract = {The contextual bandit literature has traditionally focused on algorithms that address the exploration-exploitation tradeoff. In particular, greedy algorithms that exploit current estimates without any exploration may be sub-optimal in general. However, exploration-free greedy algorithms are desirable in practical settings where exploration may be costly or unethical (e.g., clinical trials). Surprisingly, we find that a simple greedy algorithm can be rate-optimal (achieves asymptotically optimal regret) if there is sufficient randomness in the observed contexts (covariates). We prove that this is always the case for a two-armed bandit under a general class of context distributions that satisfy a condition we term \$\textbackslash textit\{covariate diversity\}\$. Furthermore, even absent this condition, we show that a greedy algorithm can be rate optimal with positive probability. Thus, standard bandit algorithms may unnecessarily explore. Motivated by these results, we introduce Greedy-First, a new algorithm that uses only observed contexts and rewards to determine whether to follow a greedy algorithm or to explore. We prove that this algorithm is rate-optimal without any additional assumptions on the context distribution or the number of arms. Extensive simulations demonstrate that Greedy-First successfully reduces exploration and outperforms existing (exploration-based) contextual bandit algorithms such as Thompson sampling or upper confidence bound (UCB).},
  archivePrefix = {arXiv},
  eprint = {1704.09011},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bastani et al (2017) - Mostly Exploration-Free Algorithms for Contextual Bandits.pdf},
  journal = {arXiv:1704.09011 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{battey2015Distributed,
  title = {Distributed {{Estimation}} and {{Inference}} with {{Statistical Guarantees}}},
  author = {Battey, Heather and Fan, Jianqing and Liu, Han and Lu, Junwei and Zhu, Ziwei},
  year = {2015},
  month = sep,
  abstract = {This paper studies hypothesis testing and parameter estimation in the context of the divide and conquer algorithm. In a unified likelihood based framework, we propose new test statistics and point estimators obtained by aggregating various statistics from \$k\$ subsamples of size \$n/k\$, where \$n\$ is the sample size. In both low dimensional and high dimensional settings, we address the important question of how to choose \$k\$ as \$n\$ grows large, providing a theoretical upper bound on \$k\$ such that the information loss due to the divide and conquer algorithm is negligible. In other words, the resulting estimators have the same inferential efficiencies and estimation rates as a practically infeasible oracle with access to the full sample. Thorough numerical results are provided to back up the theory.},
  archivePrefix = {arXiv},
  eprint = {1509.05457},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Battey et al (2015) - Distributed Estimation and Inference with Statistical Guarantees.pdf},
  journal = {arXiv:1509.05457 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@inproceedings{beatson2019Efficient,
  title = {Efficient Optimization of Loops and Limits with Randomized Telescoping Sums},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Beatson, Alex and Adams, Ryan P.},
  year = {2019},
  month = may,
  pages = {534--543},
  publisher = {{PMLR}},
  issn = {2640-3498},
  abstract = {We consider optimization problems in which the objective requires an inner loop with many steps or is the limit of a sequence of increasingly costly approximations. Meta-learning, training recurren...},
  file = {/Users/yuekai/Documents/zotero/Beatson, Adams (2019) - Efficient optimization of loops and limits with randomized telescoping sums.pdf;/Users/yuekai/Zotero/storage/BRXFEZAJ/beatson19a.html},
  language = {en}
}

@article{becker2011Templates,
  title = {Templates for Convex Cone Problems with Applications to Sparse Signal Recovery},
  author = {Becker, Stephen R. and Cand{\`e}s, Emmanuel J. and Grant, Michael C.},
  year = {2011},
  month = jul,
  volume = {3},
  pages = {165},
  issn = {1867-2957},
  doi = {10.1007/s12532-011-0029-5},
  abstract = {This paper develops a general framework for solving a variety of convex cone problems that frequently arise in signal processing, machine learning, statistics, and other fields. The approach works as follows: first, determine a conic formulation of the problem; second, determine its dual; third, apply smoothing; and fourth, solve using an optimal first-order method. A merit of this approach is its flexibility: for example, all compressed sensing problems can be solved via this approach. These include models with objective functionals such as the total-variation norm, ||Wx||1 where W is arbitrary, or a combination thereof. In addition, the paper introduces a number of technical contributions such as a novel continuation scheme and a novel approach for controlling the step size, and applies results showing that the smooth and unsmoothed problems are sometimes formally equivalent. Combined with our framework, these lead to novel, stable and computationally efficient algorithms. For instance, our general implementation is competitive with state-of-the-art methods for solving intensively studied problems such as the LASSO. Further, numerical experiments show that one can solve the Dantzig selector problem, for which no efficient large-scale solvers exist, in a few hundred iterations. Finally, the paper is accompanied with a software release. This software is not a single, monolithic solver; rather, it is a suite of programs and routines designed to serve as building blocks for constructing complete algorithms.},
  file = {/Users/yuekai/Documents/zotero/Becker et al (2011) - Templates for convex cone problems with applications to sparse signal recovery.pdf},
  journal = {Mathematical Programming Computation},
  language = {en},
  number = {3}
}

@article{belabbas2009Spectral,
  title = {Spectral Methods in Machine Learning and New Strategies for Very Large Datasets},
  author = {Belabbas, Mohamed-Ali and Wolfe, Patrick J.},
  year = {2009},
  month = jan,
  volume = {106},
  pages = {369--374},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0810600105},
  abstract = {Spectral methods are of fundamental importance in statistics and machine learning, because they underlie algorithms from classical principal components analysis to more recent approaches that exploit manifold structure. In most cases, the core technical problem can be reduced to computing a low-rank approximation to a positive-definite kernel. For the growing number of applications dealing with very large or high-dimensional datasets, however, the optimal approximation afforded by an exact spectral decomposition is too costly, because its complexity scales as the cube of either the number of training examples or their dimensionality. Motivated by such applications, we present here 2 new algorithms for the approximation of positive-semidefinite kernels, together with error bounds that improve on results in the literature. We approach this problem by seeking to determine, in an efficient manner, the most informative subset of our data relative to the kernel approximation task at hand. This leads to two new strategies based on the Nystr\"om method that are directly applicable to massive datasets. The first of these\textemdash based on sampling\textemdash leads to a randomized algorithm whereupon the kernel induces a probability distribution on its set of partitions, whereas the latter approach\textemdash based on sorting\textemdash provides for the selection of a partition in a deterministic way. We detail their numerical implementation and provide simulation results for a variety of representative problems in statistical data analysis, each of which demonstrates the improved performance of our approach relative to existing methods.},
  copyright = {\textcopyright{} 2009 by The National Academy of Sciences of the USA},
  file = {/Users/yuekai/Documents/zotero/Belabbas Wolfe (2009) - Spectral methods in machine learning and new strategies for very large datasets.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {2},
  pmid = {19129490}
}

@article{belkin2003Laplacian,
  title = {Laplacian {{Eigenmaps}} for {{Dimensionality Reduction}} and {{Data Representation}}},
  author = {Belkin, Mikhail and Niyogi, Partha},
  year = {2003},
  month = jun,
  volume = {15},
  pages = {1373--1396},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/089976603321780317},
  file = {/Users/yuekai/Documents/zotero/Belkin Niyogi (2003) - Laplacian Eigenmaps for Dimensionality Reduction and Data Representation.pdf},
  journal = {Neural Computation},
  language = {en},
  number = {6}
}

@article{belkin2018Approximation,
  title = {Approximation Beats Concentration? {{An}} Approximation View on Inference with Smooth Radial Kernels},
  shorttitle = {Approximation Beats Concentration?},
  author = {Belkin, Mikhail},
  year = {2018},
  month = jan,
  abstract = {Positive definite kernels and their associated Reproducing Kernel Hilbert Spaces provide a mathematically compelling and practically competitive framework for learning from data. In this paper we take the approximation theory point of view to explore various aspects of smooth kernels related to their inferential properties. We analyze eigenvalue decay of kernels operators and matrices, properties of eigenfunctions/eigenvectors and "Fourier" coefficients of functions in the kernel space restricted to a discrete set of data points. We also investigate the fitting capacity of kernels, giving explicit bounds on the fat shattering dimension of the balls in Reproducing Kernel Hilbert spaces. Interestingly, the same properties that make kernels very effective approximators for functions in their "native" kernel space, also limit their capacity to represent arbitrary functions. We discuss various implications, including those for gradient descent type methods. It is important to note that most of our bounds are measure independent. Moreover, at least in moderate dimension, the bounds for eigenvalues are much tighter than the bounds which can be obtained from the usual matrix concentration results. For example, we see that the eigenvalues of kernel matrices show nearly exponential decay with constants depending only on the kernel and the domain. We call this "approximation beats concentration" phenomenon as even when the data are sampled from a probability distribution, some of their aspects are better understood in terms of approximation theory.},
  archivePrefix = {arXiv},
  eprint = {1801.03437},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Belkin (2018) - Approximation beats concentration.pdf},
  journal = {arXiv:1801.03437 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{belkin2018Does,
  title = {Does Data Interpolation Contradict Statistical Optimality?},
  author = {Belkin, Mikhail and Rakhlin, Alexander and Tsybakov, Alexandre B.},
  year = {2018},
  month = jun,
  abstract = {We show that learning methods interpolating the training data can achieve optimal rates for the problems of nonparametric regression and prediction with square loss.},
  archivePrefix = {arXiv},
  eprint = {1806.09471},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Belkin et al (2018) - Does data interpolation contradict statistical optimality.pdf},
  journal = {arXiv:1806.09471 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{belkin2018Overfitting,
  title = {Overfitting or Perfect Fitting? {{Risk}} Bounds for Classification and Regression Rules That Interpolate},
  shorttitle = {Overfitting or Perfect Fitting?},
  author = {Belkin, Mikhail and Hsu, Daniel and Mitra, Partha},
  year = {2018},
  month = jun,
  abstract = {Many modern machine learning models are trained to achieve zero or near-zero training error in order to obtain near-optimal (but non-zero) test error. This phenomenon of strong generalization performance for "overfitted" / interpolated classifiers appears to be ubiquitous in high-dimensional data, having been observed in deep networks, kernel machines, boosting and random forests. Their performance is consistently robust even when the data contain large amounts of label noise. Very little theory is available to explain these observations. The vast majority of theoretical analyses of generalization allows for interpolation only when there is little or no label noise. This paper takes a step toward a theoretical foundation for interpolated classifiers by analyzing local interpolating schemes, including geometric simplicial interpolation algorithm and singularly weighted \$k\$-nearest neighbor schemes. Consistency or near-consistency is proved for these schemes in classification and regression problems. Moreover, the nearest neighbor schemes exhibit optimal rates under some standard statistical assumptions. Finally, this paper suggests a way to explain the phenomenon of adversarial examples, which are seemingly ubiquitous in modern machine learning, and also discusses some connections to kernel machines and random forests in the interpolated regime.},
  archivePrefix = {arXiv},
  eprint = {1806.05161},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Belkin et al (2018) - Overfitting or perfect fitting.pdf},
  journal = {arXiv:1806.05161 [cond-mat, stat]},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Statistical Mechanics,Statistics - Machine Learning},
  primaryClass = {cond-mat, stat}
}

@article{belkin2018Reconciling,
  title = {Reconciling Modern Machine Learning Practice and the Bias-Variance Trade-Off},
  author = {Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
  year = {2018},
  month = dec,
  abstract = {Breakthroughs in machine learning are rapidly changing science and society, yet our fundamental understanding of this technology has lagged far behind. Indeed, one of the central tenets of the field, the bias-variance trade-off, appears to be at odds with the observed behavior of methods used in the modern machine learning practice. The bias-variance trade-off implies that a model should balance under-fitting and over-fitting: rich enough to express underlying structure in data, simple enough to avoid fitting spurious patterns. However, in the modern practice, very rich models such as neural networks are trained to exactly fit (i.e., interpolate) the data. Classically, such models would be considered over-fit, and yet they often obtain high accuracy on test data. This apparent contradiction has raised questions about the mathematical foundations of machine learning and their relevance to practitioners. In this paper, we reconcile the classical understanding and the modern practice within a unified performance curve. This "double descent" curve subsumes the textbook U-shaped bias-variance trade-off curve by showing how increasing model capacity beyond the point of interpolation results in improved performance. We provide evidence for the existence and ubiquity of double descent for a wide spectrum of models and datasets, and we posit a mechanism for its emergence. This connection between the performance and the structure of machine learning models delineates the limits of classical analyses, and has implications for both the theory and practice of machine learning.},
  archivePrefix = {arXiv},
  eprint = {1812.11118},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Belkin et al (2018) - Reconciling modern machine learning practice and the bias-variance trade-off.pdf},
  journal = {arXiv:1812.11118 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{belkin2018understand,
  title = {To Understand Deep Learning We Need to Understand Kernel Learning},
  author = {Belkin, Mikhail and Ma, Siyuan and Mandal, Soumik},
  year = {2018},
  month = feb,
  abstract = {Generalization performance of classifiers in deep learning has recently become a subject of intense study. Deep models, typically over-parametrized, tend to fit the training data exactly. Despite this "overfitting", they perform well on test data, a phenomenon not yet fully understood. The first point of our paper is that strong performance of overfitted classifiers is not a unique feature of deep learning. Using six real-world and two synthetic datasets, we establish experimentally that kernel machines trained to have zero classification or near zero regression error perform very well on test data, even when the labels are corrupted with a high level of noise. We proceed to give a lower bound on the norm of zero loss solutions for smooth kernels, showing that they increase nearly exponentially with data size. We point out that this is difficult to reconcile with the existing generalization bounds. Moreover, none of the bounds produce non-trivial results for interpolating solutions. Second, we show experimentally that (non-smooth) Laplacian kernels easily fit random labels, a finding that parallels results for ReLU neural networks. In contrast, fitting noisy data requires many more epochs for smooth Gaussian kernels. Similar performance of overfitted Laplacian and Gaussian classifiers on test, suggests that generalization is tied to the properties of the kernel function rather than the optimization process. Certain key phenomena of deep learning are manifested similarly in kernel methods in the modern "overfitted" regime. The combination of the experimental and theoretical results presented in this paper indicates a need for new theoretical ideas for understanding properties of classical kernel methods. We argue that progress on understanding deep learning will be difficult until more tractable "shallow" kernel methods are better understood.},
  archivePrefix = {arXiv},
  eprint = {1802.01396},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Belkin et al (2018) - To understand deep learning we need to understand kernel learning.pdf},
  journal = {arXiv:1802.01396 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{belkin2019Two,
  title = {Two Models of Double Descent for Weak Features},
  author = {Belkin, Mikhail and Hsu, Daniel and Xu, Ji},
  year = {2019},
  month = mar,
  abstract = {The "double descent" risk curve was recently proposed to qualitatively describe the out-of-sample prediction accuracy of variably-parameterized machine learning models. This article provides a precise mathematical analysis for the shape of this curve in two simple data models with the least squares/least norm predictor. Specifically, it is shown that the risk peaks when the number of features \$p\$ is close to the sample size \$n\$, but also that the risk decreases towards its minimum as \$p\$ increases beyond \$n\$. This behavior is contrasted with that of "prescient" models that select features in an a priori optimal order.},
  archivePrefix = {arXiv},
  eprint = {1903.07571},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Belkin et al (2019) - Two models of double descent for weak features.pdf},
  journal = {arXiv:1903.07571 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{bellamy2018AI,
  title = {{{AI Fairness}} 360: {{An Extensible Toolkit}} for {{Detecting}}, {{Understanding}}, and {{Mitigating Unwanted Algorithmic Bias}}},
  shorttitle = {{{AI Fairness}} 360},
  author = {Bellamy, Rachel K. E. and Dey, Kuntal and Hind, Michael and Hoffman, Samuel C. and Houde, Stephanie and Kannan, Kalapriya and Lohia, Pranay and Martino, Jacquelyn and Mehta, Sameep and Mojsilovic, Aleksandra and Nagar, Seema and Ramamurthy, Karthikeyan Natesan and Richards, John and Saha, Diptikalyan and Sattigeri, Prasanna and Singh, Moninder and Varshney, Kush R. and Zhang, Yunfeng},
  year = {2018},
  month = oct,
  abstract = {Fairness is an increasingly important concern as machine learning models are used to support decision making in high-stakes applications such as mortgage lending, hiring, and prison sentencing. This paper introduces a new open source Python toolkit for algorithmic fairness, AI Fairness 360 (AIF360), released under an Apache v2.0 license \{https://github.com/ibm/aif360). The main objectives of this toolkit are to help facilitate the transition of fairness research algorithms to use in an industrial setting and to provide a common framework for fairness researchers to share and evaluate algorithms. The package includes a comprehensive set of fairness metrics for datasets and models, explanations for these metrics, and algorithms to mitigate bias in datasets and models. It also includes an interactive Web experience (https://aif360.mybluemix.net) that provides a gentle introduction to the concepts and capabilities for line-of-business users, as well as extensive documentation, usage guidance, and industry-specific tutorials to enable data scientists and practitioners to incorporate the most appropriate tool for their problem into their work products. The architecture of the package has been engineered to conform to a standard paradigm used in data science, thereby further improving usability for practitioners. Such architectural design and abstractions enable researchers and developers to extend the toolkit with their new algorithms and improvements, and to use it for performance benchmarking. A built-in testing infrastructure maintains code quality.\vphantom\}},
  archivePrefix = {arXiv},
  eprint = {1810.01943},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bellamy et al (2018) - AI Fairness 360.pdf},
  journal = {arXiv:1810.01943 [cs]},
  keywords = {Computer Science - Artificial Intelligence},
  primaryClass = {cs}
}

@article{bellec2019First,
  title = {First Order Expansion of Convex Regularized Estimators},
  author = {Bellec, Pierre C. and Kuchibhotla, Arun K.},
  year = {2019},
  month = oct,
  abstract = {We consider first order expansions of convex penalized estimators in high-dimensional regression problems with random designs. Our setting includes linear regression and logistic regression as special cases. For a given penalty function \$h\$ and the corresponding penalized estimator \$\textbackslash hat\textbackslash beta\$, we construct a quantity \$\textbackslash eta\$, the first order expansion of \$\textbackslash hat\textbackslash beta\$, such that the distance between \$\textbackslash hat\textbackslash beta\$ and \$\textbackslash eta\$ is an order of magnitude smaller than the estimation error \$\textbackslash |\textbackslash hat\{\textbackslash beta\} - \textbackslash beta\^*\textbackslash |\$. In this sense, the first order expansion \$\textbackslash eta\$ can be thought of as a generalization of influence functions from the mathematical statistics literature to regularized estimators in high-dimensions. Such first order expansion implies that the risk of \$\textbackslash hat\{\textbackslash beta\}\$ is asymptotically the same as the risk of \$\textbackslash eta\$ which leads to a precise characterization of the MSE of \$\textbackslash hat\textbackslash beta\$; this characterization takes a particularly simple form for isotropic design. Such first order expansion also leads to inference results based on \$\textbackslash hat\{\textbackslash beta\}\$. We provide sufficient conditions for the existence of such first order expansion for three regularizers: the Lasso in its constrained form, the lasso in its penalized form, and the Group-Lasso. The results apply to general loss functions under some conditions and those conditions are satisfied for the squared loss in linear regression and for the logistic loss in the logistic model.},
  archivePrefix = {arXiv},
  eprint = {1910.05480},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bellec, Kuchibhotla (2019) - First order expansion of convex regularized estimators.pdf},
  journal = {arXiv:1910.05480 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {math, stat}
}

@article{bellet2013Survey,
  title = {A {{Survey}} on {{Metric Learning}} for {{Feature Vectors}} and {{Structured Data}}},
  author = {Bellet, Aur{\'e}lien and Habrard, Amaury and Sebban, Marc},
  year = {2013},
  month = jun,
  abstract = {The need for appropriate ways to measure the distance or similarity between data is ubiquitous in machine learning, pattern recognition and data mining, but handcrafting such good metrics for specific problems is generally difficult. This has led to the emergence of metric learning, which aims at automatically learning a metric from data and has attracted a lot of interest in machine learning and related fields for the past ten years. This survey paper proposes a systematic review of the metric learning literature, highlighting the pros and cons of each approach. We pay particular attention to Mahalanobis distance metric learning, a well-studied and successful framework, but additionally present a wide range of methods that have recently emerged as powerful alternatives, including nonlinear metric learning, similarity learning and local metric learning. Recent trends and extensions, such as semi-supervised metric learning, metric learning for histogram data and the derivation of generalization guarantees, are also covered. Finally, this survey addresses metric learning for structured data, in particular edit distance learning, and attempts to give an overview of the remaining challenges in metric learning for the years to come.},
  archivePrefix = {arXiv},
  eprint = {1306.6709},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bellet et al (2013) - A Survey on Metric Learning for Feature Vectors and Structured Data.pdf},
  journal = {arXiv:1306.6709 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{belloni2018HighDimensional,
  title = {High-{{Dimensional Econometrics}} and {{Regularized GMM}}},
  author = {Belloni, Alexandre and Chernozhukov, Victor and Chetverikov, Denis and Hansen, Christian and Kato, Kengo},
  year = {2018},
  month = jun,
  abstract = {This chapter presents key concepts and theoretical results for analyzing estimation and inference in high-dimensional models. High-dimensional models are characterized by having a number of unknown parameters that is not vanishingly small relative to the sample size. We first present results in a framework where estimators of parameters of interest may be represented directly as approximate means. Within this context, we review fundamental results including high-dimensional central limit theorems, bootstrap approximation of high-dimensional limit distributions, and moderate deviation theory. We also review key concepts underlying inference when many parameters are of interest such as multiple testing with family-wise error rate or false discovery rate control. We then turn to a general high-dimensional minimum distance framework with a special focus on generalized method of moments problems where we present results for estimation and inference about model parameters. The presented results cover a wide array of econometric applications, and we discuss several leading special cases including high-dimensional linear regression and linear instrumental variables models to illustrate the general results.},
  archivePrefix = {arXiv},
  eprint = {1806.01888},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Belloni et al (2018) - High-Dimensional Econometrics and Regularized GMM.pdf},
  journal = {arXiv:1806.01888 [econ, math, stat]},
  keywords = {Economics - Econometrics,Mathematics - Statistics Theory},
  primaryClass = {econ, math, stat}
}

@article{ben-david2010theory,
  title = {A Theory of Learning from Different Domains},
  author = {{Ben-David}, Shai and Blitzer, John and Crammer, Koby and Kulesza, Alex and Pereira, Fernando and Vaughan, Jennifer Wortman},
  year = {2010},
  month = may,
  volume = {79},
  pages = {151--175},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/s10994-009-5152-4},
  file = {/Users/yuekai/Documents/zotero/Ben-David et al (2010) - A theory of learning from different domains.pdf},
  journal = {Machine Learning},
  language = {en},
  number = {1-2}
}

@book{ben-tal2009Robust,
  title = {Robust Optimization},
  author = {{Ben-Tal}, A. and El Ghaoui, Laurent and Nemirovski{\u \i}, A. S.},
  year = {2009},
  publisher = {{Princeton University Press}},
  address = {{Princeton}},
  abstract = {Robust optimization is a fairly new approach to optimization problems affected by uncertainty, but it has already proved so useful in real applications that it is difficult to tackle such problems today without considering this powerful methodology. The authors are the principal developers of robust optimization},
  annotation = {OCLC: ocn318672208},
  file = {/Users/yuekai/Documents/zotero/Ben-Tal et al (2009) - Robust optimization.pdf},
  isbn = {978-0-691-14368-2},
  language = {en},
  lccn = {QA402.5 .B445 2009},
  series = {Princeton Series in Applied Mathematics}
}

@article{ben-tal2012Robust,
  title = {Robust {{Solutions}} of {{Optimization Problems Affected}} by {{Uncertain Probabilities}}},
  author = {{Ben-Tal}, Aharon and {den Hertog}, Dick and De Waegenaere, Anja and Melenberg, Bertrand and Rennen, Gijs},
  year = {2012},
  month = nov,
  volume = {59},
  pages = {341--357},
  issn = {0025-1909},
  doi = {10.1287/mnsc.1120.1641},
  abstract = {In this paper we focus on robust linear optimization problems with uncertainty regions defined by {$\phi$}-divergences (for example, chi-squared, Hellinger, Kullback\textendash Leibler). We show how uncertainty regions based on {$\phi$}-divergences arise in a natural way as confidence sets if the uncertain parameters contain elements of a probability vector. Such problems frequently occur in, for example, optimization problems in inventory control or finance that involve terms containing moments of random variables, expected utility, etc. We show that the robust counterpart of a linear optimization problem with {$\phi$}-divergence uncertainty is tractable for most of the choices of {$\phi$} typically considered in the literature. We extend the results to problems that are nonlinear in the optimization variables. Several applications, including an asset pricing example and a numerical multi-item newsvendor example, illustrate the relevance of the proposed approach.This paper was accepted by G\'erard P. Cachon, optimization.},
  file = {/Users/yuekai/Documents/zotero/Ben-Tal et al (2012) - Robust Solutions of Optimization Problems Affected by Uncertain Probabilities.pdf},
  journal = {Management Science},
  number = {2}
}

@article{benamou2014Iterative,
  title = {Iterative {{Bregman Projections}} for {{Regularized Transportation Problems}}},
  author = {Benamou, Jean-David and Carlier, Guillaume and Cuturi, Marco and Nenna, Luca and Peyr{\'e}, Gabriel},
  year = {2014},
  month = dec,
  abstract = {This article details a general numerical framework to approximate so-lutions to linear programs related to optimal transport. The general idea is to introduce an entropic regularization of the initial linear program. This regularized problem corresponds to a Kullback-Leibler Bregman di-vergence projection of a vector (representing some initial joint distribu-tion) on the polytope of constraints. We show that for many problems related to optimal transport, the set of linear constraints can be split in an intersection of a few simple constraints, for which the projections can be computed in closed form. This allows us to make use of iterative Bregman projections (when there are only equality constraints) or more generally Bregman-Dykstra iterations (when inequality constraints are in-volved). We illustrate the usefulness of this approach to several variational problems related to optimal transport: barycenters for the optimal trans-port metric, tomographic reconstruction, multi-marginal optimal trans-port and in particular its application to Brenier's relaxed solutions of in-compressible Euler equations, partial un-balanced optimal transport and optimal transport with capacity constraints.},
  archivePrefix = {arXiv},
  eprint = {1412.5154},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Benamou et al (2014) - Iterative Bregman Projections for Regularized Transportation Problems.pdf;/Users/yuekai/Zotero/storage/NBQ8WAVA/1412.html},
  journal = {arXiv:1412.5154 [math]},
  keywords = {Mathematics - Analysis of PDEs,Mathematics - Numerical Analysis},
  primaryClass = {math}
}

@article{benaych-georges2017Largest,
  title = {Largest Eigenvalues of Sparse Inhomogeneous {{Erd}}\textbackslash{{H}}\{o\}s-{{R}}\textbackslash 'enyi Graphs},
  author = {{Benaych-Georges}, Florent and Bordenave, Charles and Knowles, Antti},
  year = {2017},
  month = apr,
  abstract = {We consider inhomogeneous Erd\textbackslash H\{o\}s-R\textbackslash 'enyi graphs. We suppose that the maximal mean degree \$d\$ satisfies \$d \textbackslash ll \textbackslash log n\$. We characterize the asymptotic behavior of the \$n\^\{1 - o(1)\}\$ largest eigenvalues of the adjacency matrix and its centred version. We prove that these extreme eigenvalues are governed at first order by the largest degrees and, for the adjacency matrix, by the nonzero eigenvalues of the expectation matrix. Our results show that the extreme eigenvalues exhibit a novel behaviour which in particular rules out their convergence to a nondegenerate point process. Together with the companion paper [3], where we analyse the extreme eigenvalues in the complementary regime \$d \textbackslash gg \textbackslash log n\$, this establishes a crossover in the behaviour of the extreme eigenvalues around \$d \textbackslash sim \textbackslash log n\$. Our proof relies on a new tail estimate for the Poisson approximation of an inhomogeneous sum of independent Bernoulli random variables, as well as on an estimate on the operator norm of a pruned graph due to Le, Levina, and Vershynin.},
  archivePrefix = {arXiv},
  eprint = {1704.02953},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Benaych-Georges et al (2017) - Largest eigenvalues of sparse inhomogeneous Erd-H o s-R-'enyi graphs.pdf},
  journal = {arXiv:1704.02953 [math]},
  keywords = {Mathematics - Probability},
  primaryClass = {math}
}

@article{benaych-georges2018Eigenvectors,
  title = {Eigenvectors of a Matrix under Random Perturbation},
  author = {{Benaych-Georges}, Florent and Enriquez, Nathana{\"e}l and Micha{\"i}l, Alk{\'e}os},
  year = {2018},
  month = jan,
  abstract = {In this text, based on elementary computations, we provide a perturbative expansion of the coordinates of the eigenvectors of a Hermitian matrix with large size perturbed by a random matrix with small operator norm whose entries in the eigenvector basis of the first one are independent, centered, with a variance profile. This is done through a perturbative expansion of spectral measures associated to the state defined by a given vector.},
  archivePrefix = {arXiv},
  eprint = {1801.10512},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Benaych-Georges et al (2018) - Eigenvectors of a matrix under random perturbation.pdf},
  journal = {arXiv:1801.10512 [math]},
  keywords = {Mathematics - Probability},
  primaryClass = {math}
}

@inproceedings{bengio2003Outofsample,
  title = {Out-of-Sample {{Extensions}} for {{LLE}}, {{Isomap}}, {{MDS}}, {{Eigenmaps}}, and {{Spectral Clustering}}},
  booktitle = {Proceedings of the 16th {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Bengio, Yoshua and Paiement, Jean-Fran{\c c}ois and Vincent, Pascal and Delalleau, Olivier and Roux, Nicolas Le and Ouimet, Marie},
  year = {2003},
  pages = {177--184},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA, USA}},
  abstract = {Several unsupervised learning algorithms based on an eigendecomposition provide either an embedding or a clustering only for given training points, with no straightforward extension for out-of-sample examples short of recomputing eigenvectors. This paper provides a unified framework for extending Local Linear Embedding (LLE), Isomap, Laplacian Eigenmaps, Multi-Dimensional Scaling (for dimensionality reduction) as well as for Spectral Clustering. This framework is based on seeing these algorithms as learning eigenfunctions of a data-dependent kernel. Numerical experiments show that the generalizations performed have a level of error comparable to the variability of the embedding algorithms due to the choice of training data.},
  series = {{{NIPS}}'03}
}

@book{benhabib2011Handbook,
  title = {Handbook of Social Economics},
  editor = {Benhabib, Jess and Jackson, Matthew and Bisin, Alberto},
  year = {2011},
  volume = {1A},
  publisher = {{North-Holland}},
  address = {{Amsterdam}},
  file = {/Users/yuekai/Documents/zotero/Benhabib et al (2011) - Handbook of social economics.pdf},
  isbn = {978-0-444-53187-2},
  language = {en},
  series = {Handbooks in Economics}
}

@article{benson2018Link,
  title = {Link {{Prediction}} in {{Networks}} with {{Core}}-{{Fringe Data}}},
  author = {Benson, Austin R. and Kleinberg, Jon},
  year = {2018},
  month = nov,
  doi = {10.1145/3308558.3313626},
  abstract = {Data collection often involves the partial measurement of a larger system. A common example arises in collecting network data: we often obtain network datasets by recording all of the interactions among a small set of core nodes, so that we end up with a measurement of the network consisting of these core nodes along with a potentially much larger set of fringe nodes that have links to the core. Given the ubiquity of this process for assembling network data, it is crucial to understand the role of such a `core-fringe' structure. Here we study how the inclusion of fringe nodes affects the standard task of network link prediction. One might initially think the inclusion of any additional data is useful, and hence that it should be beneficial to include all fringe nodes that are available. However, we find that this is not true; in fact, there is substantial variability in the value of the fringe nodes for prediction. Once an algorithm is selected, in some datasets, including any additional data from the fringe can actually hurt prediction performance; in other datasets, including some amount of fringe information is useful before prediction performance saturates or even declines; and in further cases, including the entire fringe leads to the best performance. While such variety might seem surprising, we show that these behaviors are exhibited by simple random graph models.},
  archivePrefix = {arXiv},
  eprint = {1811.11540},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Benson, Kleinberg (2018) - Link Prediction in Networks with Core-Fringe Data.pdf},
  journal = {arXiv:1811.11540 [physics, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Physics - Physics and Society,Statistics - Machine Learning},
  primaryClass = {physics, stat}
}

@techreport{berg2018Reduced,
  title = {Reduced Signal for Polygenic Adaptation of Height in {{UK Biobank}}},
  author = {Berg, Jeremy J and Harpak, Arbel and {Sinnott-Armstrong}, Nicholas and Joergensen, Anja Moltke and Mostafavi, Hakhamanesh and Field, Yair and Boyle, Evan A and Zhang, Xinjun and Racimo, Fernando and Pritchard, Jonathan K and Coop, Graham},
  year = {2018},
  month = jun,
  institution = {{Evolutionary Biology}},
  doi = {10.1101/354951},
  abstract = {Several recent papers have reported strong signals of selection on European polygenic height scores. These analyses used height effect estimates from the GIANT consortium and replication studies. Here, we describe a new analysis based on the the UK Biobank (UKB), a large, independent dataset. We find that the signals of selection using UKB effect-size estimates for height are strongly attenuated or absent. We also provide evidence that previous analyses were confounded by population stratification Therefore, the conclusion of strong polygenic adaptation now lacks support. Moreover, these discrepancies highlight (1) that methods for correcting for population stratification in GWAS may not always be sufficient for polygenic trait analyses, and (2) that claims of differences in polygenic scores between populations should be treated with caution until these issues are better understood.},
  file = {/Users/yuekai/Documents/zotero/Berg et al (2018) - Reduced signal for polygenic adaptation of height in UK Biobank.pdf},
  language = {en},
  type = {Preprint}
}

@article{bergmann2019Fenchel,
  title = {Fenchel {{Duality Theory}} and {{A Primal}}-{{Dual Algorithm}} on {{Riemannian Manifolds}}},
  author = {Bergmann, Ronny and Herzog, Roland and Tenbrinck, Daniel and {Vidal-N{\'u}{\~n}ez}, Jos{\'e}},
  year = {2019},
  month = sep,
  abstract = {This paper introduces a new duality theory that generalizes the classical Fenchel conjugation to functions defined on Riemannian manifolds. We investigate its properties, e.g.,\textasciitilde the Fenchel--Young inequality and the characterization of the convex subdifferential using the analogue of the Fenchel--Moreau Theorem. These properties of the Fenchel conjugate are employed to derive a Riemannian primal-dual optimization algorithm, and to prove its convergence for the case of Hadamard manifolds under appropriate assumptions. Numerical results illustrate the performance of the algorithm, which competes with the recently derived Douglas--Rachford algorithm on manifolds of nonpositive curvature. Furthermore we show numerically that our novel algorithm even converges on manifolds of positive curvature.},
  archivePrefix = {arXiv},
  eprint = {1908.02022},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bergmann et al (2019) - Fenchel Duality Theory and A Primal-Dual Algorithm on Riemannian Manifolds.pdf},
  journal = {arXiv:1908.02022 [cs, math]},
  keywords = {Mathematics - Numerical Analysis,Mathematics - Optimization and Control},
  primaryClass = {cs, math}
}

@article{berk2013Valid,
  title = {Valid Post-Selection Inference},
  author = {Berk, Richard and Brown, Lawrence and Buja, Andreas and Zhang, Kai and Zhao, Linda},
  year = {2013},
  month = apr,
  volume = {41},
  pages = {802--837},
  issn = {0090-5364},
  doi = {10.1214/12-AOS1077},
  abstract = {It is common practice in statistical data analysis to perform data-driven variable selection and derive statistical inference from the resulting model. Such inference enjoys none of the guarantees that classical statistical theory provides for tests and confidence intervals when the model has been chosen a priori. We propose to produce valid ``post-selection inference'' by reducing the problem to one of simultaneous inference and hence suitably widening conventional confidence and retention intervals. Simultaneity is required for all linear functions that arise as coefficient estimates in all submodels. By purchasing ``simultaneity insurance'' for all possible submodels, the resulting post-selection inference is rendered universally valid under all possible model selection procedures. This inference is therefore generally conservative for particular selection procedures, but it is always less conservative than full Scheffe protection. Importantly it does not depend on the truth of the selected submodel, and hence it produces valid inference even in wrong models. We describe the structure of the simultaneous inference problem and give some asymptotic results.},
  archivePrefix = {arXiv},
  eprint = {1306.1059},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Berk et al (2013) - Valid post-selection inference.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory},
  number = {2}
}

@article{berk2017Fairness,
  title = {Fairness in {{Criminal Justice Risk Assessments}}: {{The State}} of the {{Art}}},
  shorttitle = {Fairness in {{Criminal Justice Risk Assessments}}},
  author = {Berk, Richard and Heidari, Hoda and Jabbari, Shahin and Kearns, Michael and Roth, Aaron},
  year = {2017},
  month = mar,
  abstract = {Objectives: Discussions of fairness in criminal justice risk assessments typically lack conceptual precision. Rhetoric too often substitutes for careful analysis. In this paper, we seek to clarify the tradeoffs between different kinds of fairness and between fairness and accuracy. Methods: We draw on the existing literatures in criminology, computer science and statistics to provide an integrated examination of fairness and accuracy in criminal justice risk assessments. We also provide an empirical illustration using data from arraignments. Results: We show that there are at least six kinds of fairness, some of which are incompatible with one another and with accuracy. Conclusions: Except in trivial cases, it is impossible to maximize accuracy and fairness at the same time, and impossible simultaneously to satisfy all kinds of fairness. In practice, a major complication is different base rates across different legally protected groups. There is a need to consider challenging tradeoffs.},
  archivePrefix = {arXiv},
  eprint = {1703.09207},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Berk et al (2017) - Fairness in Criminal Justice Risk Assessments.pdf},
  journal = {arXiv:1703.09207 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{berthet2017Fast,
  title = {Fast {{Rates}} for {{Bandit Optimization}} with {{Upper}}-{{Confidence Frank}}-{{Wolfe}}},
  author = {Berthet, Quentin and Perchet, Vianney},
  year = {2017},
  month = feb,
  abstract = {We consider the problem of bandit optimization, inspired by stochastic optimization and online learning problems with bandit feedback. In this problem, the objective is to minimize a global loss function of all the actions, not necessarily a cumulative loss. This framework allows us to study a very general class of problems, with applications in statistics, machine learning, and other fields. To solve this problem, we analyze the Upper-Confidence Frank-Wolfe algorithm, inspired by techniques for bandits and convex optimization. We give theoretical guarantees for the performance of this algorithm over various classes of functions, and discuss the optimality of these results.},
  archivePrefix = {arXiv},
  eprint = {1702.06917},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Berthet, Perchet (2017) - Fast Rates for Bandit Optimization with Upper-Confidence Frank-Wolfe.pdf},
  journal = {arXiv:1702.06917 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{berti1997GlivenkoCantelli,
  title = {A {{Glivenko}}-{{Cantelli}} Theorem for Exchangeable Random Variables},
  author = {Berti, Patrizia and Rigo, Pietro},
  year = {1997},
  month = apr,
  volume = {32},
  pages = {385--391},
  issn = {01677152},
  doi = {10.1016/S0167-7152(96)00098-3},
  abstract = {For an exchangeable sequence of random variables, almost surely, the difference between the empirical and the predictive distribution functions converges to zero uniformly.},
  file = {/Users/yuekai/Documents/zotero/Berti, Rigo (1997) - A Glivenko-Cantelli theorem for exchangeable random variables.pdf},
  journal = {Statistics \& Probability Letters},
  language = {en},
  number = {4}
}

@inproceedings{bertinetto2018Metalearning,
  title = {Meta-Learning with Differentiable Closed-Form Solvers},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Bertinetto, Luca and Henriques, Joao F. and Torr, Philip and Vedaldi, Andrea},
  year = {2018},
  month = sep,
  abstract = {Adapting deep networks to new concepts from a few examples is challenging, due to the high computational requirements of standard fine-tuning procedures.
  Most work on few-shot learning has thus...},
  file = {/Users/yuekai/Documents/zotero/Bertinetto et al (2018) - Meta-learning with differentiable closed-form solvers.pdf;/Users/yuekai/Zotero/storage/N8XWAVGW/forum.html}
}

@article{bertrand2004Are,
  title = {Are {{Emily}} and {{Greg More Employable Than Lakisha}} and {{Jamal}}? {{A Field Experiment}} on {{Labor Market Discrimination}}},
  shorttitle = {Are {{Emily}} and {{Greg More Employable Than Lakisha}} and {{Jamal}}?},
  author = {Bertrand, Marianne and Mullainathan, Sendhil},
  year = {2004},
  month = sep,
  volume = {94},
  pages = {991--1013},
  issn = {0002-8282},
  doi = {10.1257/0002828042002561},
  abstract = {We study race in the labor market by sending fictitious resumes to help-wanted ads in Boston and Chicago newspapers. To manipulate perceived race, resumes are randomly assigned African-American- or White-sounding names. White names receive 50 percent more callbacks for interviews. Callbacks are also more responsive to resume quality for White names than for African-American ones. The racial gap is uniform across occupation, industry, and employer size. We also find little evidence that employers are inferring social class from the names. Differential treatment by race still appears to still be prominent in the U. S. labor market.},
  file = {/Users/yuekai/Documents/zotero/Bertrand, Mullainathan (2004) - Are Emily and Greg More Employable Than Lakisha and Jamal.pdf},
  journal = {American Economic Review},
  language = {en},
  number = {4}
}

@techreport{bertrand2016Field,
  title = {Field {{Experiments}} on {{Discrimination}}},
  author = {Bertrand, Marianne and Duflo, Esther},
  year = {2016},
  month = feb,
  pages = {w22014},
  address = {{Cambridge, MA}},
  institution = {{National Bureau of Economic Research}},
  doi = {10.3386/w22014},
  abstract = {This article reviews the existing field experimentation literature on the prevalence of discrimination, the consequences of such discrimination, and possible approaches to undermine it. We highlight key gaps in the literature and ripe opportunities for future field work. Section 1 reviews the various experimental methods that have been employed to measure the prevalence of discrimination, most notably audit and correspondence studies; it also describes several other measurement tools commonly used in lab-based work that deserve greater consideration in field research. Section 2 provides an overview of the literature on the costs of being stereotyped or discriminated against, with a focus on self-expectancy effects and self-fulfilling prophecies; section 2 also discusses the thin field-based literature on the consequences of limited diversity in organizations and groups. The final section of the paper, Section 3, reviews the evidence for policies and interventions aimed at weakening discrimination, covering role model and intergroup contact effects, as well as socio-cognitive and technological de-biasing strategies.},
  file = {/Users/yuekai/Documents/zotero/Bertrand, Duflo (2016) - Field Experiments on Discrimination.pdf},
  language = {en},
  number = {w22014}
}

@article{bertsimas2011Price,
  title = {The {{Price}} of {{Fairness}}},
  author = {Bertsimas, Dimitris and Farias, Vivek F. and Trichakis, Nikolaos},
  year = {2011},
  month = feb,
  volume = {59},
  pages = {17--31},
  issn = {0030-364X, 1526-5463},
  doi = {10.1287/opre.1100.0865},
  file = {/Users/yuekai/Documents/zotero/Bertsimas et al (2011) - The Price of Fairness.pdf},
  journal = {Operations Research},
  language = {en},
  number = {1}
}

@article{bertsimas2013DataDriven,
  title = {Data-{{Driven Robust Optimization}}},
  author = {Bertsimas, Dimitris and Gupta, Vishal and Kallus, Nathan},
  year = {2013},
  month = dec,
  abstract = {The last decade witnessed an explosion in the availability of data for operations research applications. Motivated by this growing availability, we propose a novel schema for utilizing data to design uncertainty sets for robust optimization using statistical hypothesis tests. The approach is flexible and widely applicable, and robust optimization problems built from our new sets are computationally tractable, both theoretically and practically. Furthermore, optimal solutions to these problems enjoy a strong, finite-sample probabilistic guarantee. \textbackslash edit\{We describe concrete procedures for choosing an appropriate set for a given application and applying our approach to multiple uncertain constraints. Computational evidence in portfolio management and queuing confirm that our data-driven sets significantly outperform traditional robust optimization techniques whenever data is available.\vphantom\}},
  archivePrefix = {arXiv},
  eprint = {1401.0212},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bertsimas et al (2013) - Data-Driven Robust Optimization.pdf},
  journal = {arXiv:1401.0212 [math]},
  keywords = {Mathematics - Optimization and Control},
  primaryClass = {math}
}

@article{bertsimas2015Datadriven,
  title = {Data-Driven Estimation in Equilibrium Using Inverse Optimization},
  author = {Bertsimas, Dimitris and Gupta, Vishal and Paschalidis, Ioannis Ch.},
  year = {2015},
  month = nov,
  volume = {153},
  pages = {595--633},
  issn = {0025-5610, 1436-4646},
  doi = {10.1007/s10107-014-0819-4},
  abstract = {Equilibrium modeling is common in a variety of fields such as game theory and transportation science. The inputs for these models, however, are often difficult to estimate, while their outputs, i.e., the equilibria they are meant to describe, are often directly observable. By combining ideas from inverse optimization with the theory of variational inequalities, we develop an efficient, data-driven technique for estimating the parameters of these models from observed equilibria. We use this technique to estimate the utility functions of players in a game from their observed actions and to estimate the congestion function on a road network from traffic count data. A distinguishing feature of our approach is that it supports both parametric and nonparametric estimation by leveraging ideas from statistical learning (kernel methods and regularization operators). In computational experiments involving Nash and Wardrop equilibria in a nonparametric setting, we find that a) we effectively estimate the unknown demand or congestion function, respectively, and b) our proposed regularization technique substantially improves the out-of-sample performance of our estimators.},
  file = {/Users/yuekai/Documents/zotero/Bertsimas et al (2015) - Data-driven estimation in equilibrium using inverse optimization.pdf},
  journal = {Mathematical Programming},
  language = {en},
  number = {2}
}

@article{bertsimas2016Robust,
  title = {Robust {{Sample Average Approximation}}},
  author = {Bertsimas, Dimitris and Gupta, Vishal and Kallus, Nathan},
  year = {2016},
  month = nov,
  abstract = {Sample average approximation (SAA) is a widely popular approach to data-driven decision-making under uncertainty. Under mild assumptions, SAA is both tractable and enjoys strong asymptotic performance guarantees. Similar guarantees, however, do not typically hold in finite samples. In this paper, we propose a modification of SAA, which we term Robust SAA, which retains SAA's tractability and asymptotic properties and, additionally, enjoys strong finite-sample performance guarantees. The key to our method is linking SAA, distributionally robust optimization, and hypothesis testing of goodness-of-fit. Beyond Robust SAA, this connection provides a unified perspective enabling us to characterize the finite sample and asymptotic guarantees of various other data-driven procedures that are based upon distributionally robust optimization. This analysis provides insight into the practical performance of these various methods in real applications. We present examples from inventory management and portfolio allocation, and demonstrate numerically that our approach outperforms other data-driven approaches in these applications.},
  archivePrefix = {arXiv},
  eprint = {1408.4445},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bertsimas et al (2016) - Robust Sample Average Approximation.pdf},
  journal = {arXiv:1408.4445 [math]},
  keywords = {Mathematics - Optimization and Control},
  primaryClass = {math}
}

@article{besserve2017Group,
  title = {Group Invariance Principles for Causal Generative Models},
  author = {Besserve, Michel and Shajarisales, Naji and Sch{\"o}lkopf, Bernhard and Janzing, Dominik},
  year = {2017},
  month = may,
  abstract = {The postulate of independence of cause and mechanism (ICM) has recently led to several new causal discovery algorithms. The interpretation of independence and the way it is utilized, however, varies across these methods. Our aim in this paper is to propose a group theoretic framework for ICM to unify and generalize these approaches. In our setting, the cause-mechanism relationship is assessed by comparing it against a null hypothesis through the application of random generic group transformations. We show that the group theoretic view provides a very general tool to study the structure of data generating mechanisms with direct applications to machine learning.},
  archivePrefix = {arXiv},
  eprint = {1705.02212},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Besserve et al (2017) - Group invariance principles for causal generative models.pdf},
  journal = {arXiv:1705.02212 [cs, math, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{besserve2020theory,
  title = {A Theory of Independent Mechanisms for Extrapolation in Generative Models},
  author = {Besserve, Michel and Sun, R{\'e}my and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
  year = {2020},
  month = mar,
  abstract = {Deep generative models reproduce complex empirical data but cannot extrapolate to novel environments. An intuitive idea to promote extrapolation capabilities is to enforce the architecture to have the modular structure of a causal graphical model, where one can intervene on each module independently of the others in the graph. We develop a framework to formalize this intuition, using the principle of Independent Causal Mechanisms, and show how over-parameterization of generative neural networks can hinder extrapolation capabilities. Our experiments on the generation of human faces shows successive layers of a generator architecture implement independent mechanisms to some extent, allowing meaningful extrapolations. Finally, we illustrate that independence of mechanisms may be enforced during training to improve extrapolation.},
  archivePrefix = {arXiv},
  eprint = {2004.00184},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Besserve et al (2020) - A theory of independent mechanisms for extrapolation in generative models.pdf},
  journal = {arXiv:2004.00184 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{betancourt2014Geometric,
  title = {The {{Geometric Foundations}} of {{Hamiltonian Monte Carlo}}},
  author = {Betancourt, M. J. and Byrne, Simon and Livingstone, Samuel and Girolami, Mark},
  year = {2014},
  month = oct,
  abstract = {Although Hamiltonian Monte Carlo has proven an empirical success, the lack of a rigorous theoretical understanding of the algorithm has in many ways impeded both principled developments of the method and use of the algorithm in practice. In this paper we develop the formal foundations of the algorithm through the construction of measures on smooth manifolds, and demonstrate how the theory naturally identifies efficient implementations and motivates promising generalizations.},
  archivePrefix = {arXiv},
  eprint = {1410.5110},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Betancourt et al (2014) - The Geometric Foundations of Hamiltonian Monte Carlo.pdf},
  journal = {arXiv:1410.5110 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{betancourt2017Convergence,
  title = {The {{Convergence}} of {{Markov}} Chain {{Monte Carlo Methods}}: {{From}} the {{Metropolis}} Method to {{Hamiltonian Monte Carlo}}},
  shorttitle = {The {{Convergence}} of {{Markov}} Chain {{Monte Carlo Methods}}},
  author = {Betancourt, Michael},
  year = {2017},
  month = jun,
  abstract = {From its inception in the 1950s to the modern frontiers of applied statistics, Markov chain Monte Carlo has been one of the most ubiquitous and successful methods in statistical computing. In that time its development has been fueled by increasingly difficult problems and novel techniques from physics. In this article I will review the history of Markov chain Monte Carlo from its inception with the Metropolis method to today's state-of-the-art in Hamiltonian Monte Carlo. Along the way I will focus on the evolving interplay between the statistical and physical perspectives of the method.},
  archivePrefix = {arXiv},
  eprint = {1706.01520},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Betancourt (2017) - The Convergence of Markov chain Monte Carlo Methods.pdf},
  journal = {arXiv:1706.01520 [physics, stat]},
  keywords = {Physics - History and Philosophy of Physics,Statistics - Methodology},
  primaryClass = {physics, stat}
}

@article{betancourt2018Symplectic,
  title = {On {{Symplectic Optimization}}},
  author = {Betancourt, Michael and Jordan, Michael I. and Wilson, Ashia C.},
  year = {2018},
  month = feb,
  abstract = {Accelerated gradient methods have had significant impact in machine learning
-- in particular the theoretical side of machine learning -- due to their
ability to achieve oracle lower bounds. But their heuristic construction has
hindered their full integration into the practical machine-learning algorithmic
toolbox, and has limited their scope. In this paper we build on recent work
which casts acceleration as a phenomenon best explained in continuous time, and
we augment that picture by providing a systematic methodology for converting
continuous-time dynamics into discrete-time algorithms while retaining oracle
rates. Our framework is based on ideas from Hamiltonian dynamical systems and
symplectic integration. These ideas have had major impact in many areas in
applied mathematics, but have not yet been seen to have a relationship with
optimization.},
  file = {/Users/yuekai/Documents/zotero/Betancourt et al (2018) - On Symplectic Optimization.pdf},
  language = {en}
}

@article{beutel2017Data,
  title = {Data {{Decisions}} and {{Theoretical Implications}} When {{Adversarially Learning Fair Representations}}},
  author = {Beutel, Alex and Chen, Jilin and Zhao, Zhe and Chi, Ed H.},
  year = {2017},
  month = jun,
  abstract = {How can we learn a classifier that is "fair" for a protected or sensitive group, when we do not know if the input to the classifier belongs to the protected group? How can we train such a classifier when data on the protected group is difficult to attain? In many settings, finding out the sensitive input attribute can be prohibitively expensive even during model training, and sometimes impossible during model serving. For example, in recommender systems, if we want to predict if a user will click on a given recommendation, we often do not know many attributes of the user, e.g., race or age, and many attributes of the content are hard to determine, e.g., the language or topic. Thus, it is not feasible to use a different classifier calibrated based on knowledge of the sensitive attribute. Here, we use an adversarial training procedure to remove information about the sensitive attribute from the latent representation learned by a neural network. In particular, we study how the choice of data for the adversarial training effects the resulting fairness properties. We find two interesting results: a small amount of data is needed to train these adversarial models, and the data distribution empirically drives the adversary's notion of fairness.},
  archivePrefix = {arXiv},
  eprint = {1707.00075},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Beutel et al (2017) - Data Decisions and Theoretical Implications when Adversarially Learning Fair.pdf},
  journal = {arXiv:1707.00075 [cs]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{beutel2019Fairness,
  title = {Fairness in {{Recommendation Ranking}} through {{Pairwise Comparisons}}},
  author = {Beutel, Alex and Chen, Jilin and Doshi, Tulsee and Qian, Hai and Wei, Li and Wu, Yi and Heldt, Lukasz and Zhao, Zhe and Hong, Lichan and Chi, Ed H. and Goodrow, Cristos},
  year = {2019},
  month = mar,
  abstract = {Recommender systems are one of the most pervasive applications of machine learning in industry, with many services using them to match users to products or information. As such it is important to ask: what are the possible fairness risks, how can we quantify them, and how should we address them? In this paper we offer a set of novel metrics for evaluating algorithmic fairness concerns in recommender systems. In particular we show how measuring fairness based on pairwise comparisons from randomized experiments provides a tractable means to reason about fairness in rankings from recommender systems. Building on this metric, we offer a new regularizer to encourage improving this metric during model training and thus improve fairness in the resulting rankings. We apply this pairwise regularization to a large-scale, production recommender system and show that we are able to significantly improve the system's pairwise fairness.},
  archivePrefix = {arXiv},
  eprint = {1903.00780},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Beutel et al (2019) - Fairness in Recommendation Ranking through Pairwise Comparisons.pdf},
  journal = {arXiv:1903.00780 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Information Retrieval,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{beutel2019Putting,
  title = {Putting {{Fairness Principles}} into {{Practice}}: {{Challenges}}, {{Metrics}}, and {{Improvements}}},
  shorttitle = {Putting {{Fairness Principles}} into {{Practice}}},
  author = {Beutel, Alex and Chen, Jilin and Doshi, Tulsee and Qian, Hai and Woodruff, Allison and Luu, Christine and Kreitmann, Pierre and Bischof, Jonathan and Chi, Ed H.},
  year = {2019},
  month = jan,
  abstract = {As more researchers have become aware of and passionate about algorithmic fairness, there has been an explosion in papers laying out new metrics, suggesting algorithms to address issues, and calling attention to issues in existing applications of machine learning. This research has greatly expanded our understanding of the concerns and challenges in deploying machine learning, but there has been much less work in seeing how the rubber meets the road. In this paper we provide a case-study on the application of fairness in machine learning research to a production classification system, and offer new insights in how to measure and address algorithmic fairness issues. We discuss open questions in implementing equality of opportunity and describe our fairness metric, conditional equality, that takes into account distributional differences. Further, we provide a new approach to improve on the fairness metric during model training and demonstrate its efficacy in improving performance for a real-world product},
  archivePrefix = {arXiv},
  eprint = {1901.04562},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Beutel et al (2019) - Putting Fairness Principles into Practice.pdf},
  journal = {arXiv:1901.04562 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{bhagoji2019Lower,
  title = {Lower {{Bounds}} on {{Adversarial Robustness}} from {{Optimal Transport}}},
  author = {Bhagoji, Arjun Nitin and Cullina, Daniel and Mittal, Prateek},
  year = {2019},
  month = oct,
  abstract = {While progress has been made in understanding the robustness of machine learning classifiers to test-time adversaries (evasion attacks), fundamental questions remain unresolved. In this paper, we use optimal transport to characterize the minimum possible loss in an adversarial classification scenario. In this setting, an adversary receives a random labeled example from one of two classes, perturbs the example subject to a neighborhood constraint, and presents the modified example to the classifier. We define an appropriate cost function such that the minimum transportation cost between the distributions of the two classes determines the minimum \$0-1\$ loss for any classifier. When the classifier comes from a restricted hypothesis class, the optimal transportation cost provides a lower bound. We apply our framework to the case of Gaussian data with norm-bounded adversaries and explicitly show matching bounds for the classification and transport problems as well as the optimality of linear classifiers. We also characterize the sample complexity of learning in this setting, deriving and extending previously known results as a special case. Finally, we use our framework to study the gap between the optimal classification performance possible and that currently achieved by state-of-the-art robustly trained neural networks for datasets of interest, namely, MNIST, Fashion MNIST and CIFAR-10.},
  archivePrefix = {arXiv},
  eprint = {1909.12272},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bhagoji et al (2019) - Lower Bounds on Adversarial Robustness from Optimal Transport.pdf},
  journal = {arXiv:1909.12272 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{bhatia2019Bayesian,
  title = {Bayesian {{Robustness}}: {{A Nonasymptotic Viewpoint}}},
  shorttitle = {Bayesian {{Robustness}}},
  author = {Bhatia, Kush and Ma, Yi-An and Dragan, Anca D. and Bartlett, Peter L. and Jordan, Michael I.},
  year = {2019},
  month = jul,
  abstract = {We study the problem of robustly estimating the posterior distribution for the setting where observed data can be contaminated with potentially adversarial outliers. We propose Rob-ULA, a robust variant of the Unadjusted Langevin Algorithm (ULA), and provide a finite-sample analysis of its sampling distribution. In particular, we show that after \$T= \textbackslash tilde\{\textbackslash mathcal\{O\}\}(d/\textbackslash varepsilon\_\{\textbackslash textsf\{acc\}\})\$ iterations, we can sample from \$p\_T\$ such that \$\textbackslash text\{dist\}(p\_T, p\^*) \textbackslash leq \textbackslash varepsilon\_\{\textbackslash textsf\{acc\}\} + \textbackslash tilde\{\textbackslash mathcal\{O\}\}(\textbackslash epsilon)\$, where \$\textbackslash epsilon\$ is the fraction of corruptions. We corroborate our theoretical analysis with experiments on both synthetic and real-world data sets for mean estimation, regression and binary classification.},
  archivePrefix = {arXiv},
  eprint = {1907.11826},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bhatia et al (2019) - Bayesian Robustness.pdf},
  journal = {arXiv:1907.11826 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{bhattacharjee2018Change,
  title = {Change {{Point Estimation}} in a {{Dynamic Stochastic Block Model}}},
  author = {Bhattacharjee, Monika and Banerjee, Moulinath and Michailidis, George},
  year = {2018},
  month = dec,
  abstract = {We consider the problem of estimating the location of a single change point in a dynamic stochastic block model. We propose two methods of estimating the change point, together with the model parameters. The first employs a least squares criterion function and takes into consideration the full structure of the stochastic block model and is evaluated at each point in time. Hence, as an intermediate step, it requires estimating the community structure based on a clustering algorithm at every time point. The second method comprises of the following two steps: in the first one, a least squares function is used and evaluated at each time point, but ignores the community structures and just considers a random graph generating mechanism exhibiting a change point. Once the change point is identified, in the second step, all network data before and after it are used together with a clustering algorithm to obtain the corresponding community structures and subsequently estimate the generating stochastic block model parameters. A comparison between these two methods is illustrated. Further, for both methods under their respective identifiability and certain additional regularity conditions, we establish rates of convergence and derive the asymptotic distributions of the change point estimators. The results are illustrated on synthetic data.},
  archivePrefix = {arXiv},
  eprint = {1812.03090},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bhattacharjee et al (2018) - Change Point Estimation in a Dynamic Stochastic Block Model.pdf},
  journal = {arXiv:1812.03090 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {math, stat}
}

@article{bhowmick2018Protection,
  title = {Protection {{Against Reconstruction}} and {{Its Applications}} in {{Private Federated Learning}}},
  author = {Bhowmick, Abhishek and Duchi, John and Freudiger, Julien and Kapoor, Gaurav and Rogers, Ryan},
  year = {2018},
  month = dec,
  abstract = {Federated learning has become an exciting direction for both research and practical training of models with user data. Although data remains decentralized in federated learning, it is common to assume that the model updates are sent in the clear from the devices to the server. Differential privacy has been proposed as a way to ensure the model remains private, but this does not address the issue that model updates can be seen on the server, and lead to leakage of user data. Local differential privacy is one of the strongest forms of privacy protection so that each individual's data is privatized. However, local differential privacy, as it is traditionally used, may prove to be too stringent of a privacy condition in many high dimensional problems, such as in distributed model fitting. We propose a new paradigm for local differential privacy by providing protections against certain adversaries. Specifically, we ensure that adversaries with limited prior information cannot reconstruct, with high probability, the original data within some prescribed tolerance. This interpretation allows us to consider larger privacy parameters. We then design (optimal) DP mechanisms in this large privacy parameter regime. In this work, we combine local privacy protections along with central differential privacy to present a practical approach to do model training privately. Further, we show that these privacy restrictions maintain utility in image classification and language models that is comparable to federated learning without these privacy restrictions.},
  archivePrefix = {arXiv},
  eprint = {1812.00984},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bhowmick et al (2018) - Protection Against Reconstruction and Its Applications in Private Federated.pdf},
  journal = {arXiv:1812.00984 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{bickel1975Sex,
  title = {Sex {{Bias}} in {{Graduate Admissions}}: {{Data}} from {{Berkeley}}},
  shorttitle = {Sex {{Bias}} in {{Graduate Admissions}}},
  author = {Bickel, P. J. and Hammel, E. A. and O'Connell, J. W.},
  year = {1975},
  month = feb,
  volume = {187},
  pages = {398--404},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.187.4175.398},
  abstract = {Examination of aggregate data on graduate admissions to the University of California, Berkeley, for fall 1973 shows a clear but misleading pattern of bias against female applicants. Examination of the disaggregated data reveals few decision-making units that show statistically significant departures from expected frequencies of female admissions, and about as many units appear to favor women as to favor men. If the data are properly pooled, taking into account the autonomy of departmental decision making, thus correcting for the tendency of women to apply to graduate departments that are more difficult for applicants of either sex to enter, there is a small but statistically significant bias in favor of women. The graduate departments that are easier to enter tend to be those that require more mathematics in the undergraduate preparatory curriculum. The bias in the aggregated data stems not from any pattern of discrimination on the part of admissions committees, which seem quite fair on the whole, but apparently from prior screening at earlier levels of the educational system. Women are shunted by their socialization and education toward fields of graduate study that are generally more crowded, less productive of completed degrees, and less well funded, and that frequently offer poorer professional employment prospects.},
  copyright = {1975 by the American Association for the Advancement of Science},
  file = {/Users/yuekai/Documents/zotero/Bickel et al (1975) - Sex Bias in Graduate Admissions.pdf},
  journal = {Science},
  language = {en},
  number = {4175},
  pmid = {17835295}
}

@article{bickel1981Minimax,
  title = {Minimax {{Estimation}} of the {{Mean}} of a {{Normal Distribution}} When the {{Parameter Space}} Is {{Restricted}}},
  author = {Bickel, P. J.},
  year = {1981},
  month = nov,
  volume = {9},
  pages = {1301--1309},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/aos/1176345646},
  abstract = {If XXX is a N(\texttheta,1)N(\texttheta,1)N(\textbackslash theta, 1) random variable, let {$\rho$}(m){$\rho$}(m)\textbackslash rho (m) be the minimax risk for estimation with quadratic loss subject to |\texttheta |{$\leq$}m|\texttheta |{$\leq$}m|\textbackslash theta| \textbackslash leq m. Then {$\rho$}(m)=1-{$\pi$}2/m2+o(m-2){$\rho$}(m)=1-{$\pi$}2/m2+o(m-2)\textbackslash rho (m) = 1 - \textbackslash pi\^2/m\^2 + o(m\^\{-2\}). We exhibit estimates which are asymptotically minimax to this order as well as approximations to the least favorable prior distributions. The approximate least favorable distributions (correct to order m-2m-2m\^\{-2\}) have density m-1cos2({$\pi$}2ms),|s|{$\leq$}mm-1cos2⁡({$\pi$}2ms),|s|{$\leq$}mm\^\{-1\} \textbackslash cos\^2 \textbackslash big(\textbackslash frac\{\textbackslash pi\}\{2m\} s\textbackslash big), |s| \textbackslash leq m rather than the naively expected uniform density on [-m,m][-m,m]\textbackslash lbrack -m, m \textbackslash rbrack. We also show how our results extend to estimation of a vector mean and give some explicit solutions.},
  file = {/Users/yuekai/Documents/zotero/Bickel (1981) - Minimax Estimation of the Mean of a Normal Distribution when the Parameter.pdf},
  journal = {The Annals of Statistics},
  language = {EN},
  mrnumber = {MR630112},
  number = {6},
  zmnumber = {0484.62013}
}

@book{bickel1998Efficient,
  title = {Efficient and {{Adaptive Estimation}} for {{Semiparametric Models}}},
  author = {Bickel, Peter J. and Klaassen, Chris A. J. and Ritov, Ya'acov and Wellner, Jon A.},
  year = {1998},
  publisher = {{Springer-Verlag}},
  address = {{New York}},
  abstract = {This book is about estimation in situations where we believe we have enough knowledge to model some features of the data parametrically, but are unwilling to assume anything for other features. Such models have arisen in a wide variety of contexts in recent years, particularly in economics, epidemiology, and astronomy. The complicated structure of these models typically requires us to consider nonlinear estimation procedures which often can only be implemented algorithmically. The theory of these procedures is necessarily based on asymptotic approximations.},
  file = {/Users/yuekai/Documents/zotero/Bickel et al (1998) - Efficient and Adaptive Estimation for Semiparametric Models.pdf},
  isbn = {978-0-387-98473-5},
  language = {en}
}

@article{bickel2011method,
  title = {The Method of Moments and Degree Distributions for Network Models},
  author = {Bickel, Peter J. and Chen, Aiyou and Levina, Elizaveta},
  year = {2011},
  month = oct,
  volume = {39},
  pages = {2280--2301},
  issn = {0090-5364},
  doi = {10.1214/11-AOS904},
  abstract = {Probability models on graphs are becoming increasingly important in many applications, but statistical tools for fitting such models are not yet well developed. Here we propose a general method of moments approach that can be used to fit a large class of probability models through empirical counts of certain patterns in a graph. We establish some general asymptotic properties of empirical graph moments and prove consistency of the estimates as the graph size grows for all ranges of the average degree including \$\textbackslash Omega(1)\$. Additional results are obtained for the important special case of degree distributions.},
  archivePrefix = {arXiv},
  eprint = {1202.5101},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bickel et al (2011) - The method of moments and degree distributions for network models.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory},
  number = {5}
}

@incollection{bickel2012Resampling,
  title = {Resampling {{Fewer Than}} n {{Observations}}: {{Gains}}, {{Losses}}, and {{Remedies}} for {{Losses}}},
  shorttitle = {Resampling {{Fewer Than}} n {{Observations}}},
  booktitle = {Selected {{Works}} of {{Willem}} van {{Zwet}}},
  author = {Bickel, P. J. and G{\"o}tze, F. and {van Zwet}, W. R.},
  editor = {{van de Geer}, Sara and Wegkamp, Marten},
  year = {2012},
  pages = {267--297},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4614-1314-1_17},
  abstract = {We discuss a number of resampling schemes in which m = o(n) observations are resampled. We review nonparametric bootstrap failure and give results old and new on how the m out of n with replacement and without replacement bootstraps work. We extend work of Bickel and Yahav (1988) to show that m out of n bootstraps can be made second order correct, if the usual nonparametric bootstrap is correct and study how these extrapolation techniques work when the nonparametric bootstrap does not.},
  file = {/Users/yuekai/Documents/zotero/Bickel et al (2012) - Resampling Fewer Than n Observations.pdf},
  isbn = {978-1-4614-1313-4 978-1-4614-1314-1},
  language = {en}
}

@inproceedings{biega2018Equity,
  title = {Equity of {{Attention}}: {{Amortizing Individual Fairness}} in {{Rankings}}},
  shorttitle = {Equity of {{Attention}}},
  booktitle = {The 41st {{International ACM SIGIR Conference}} on {{Research}} \& {{Development}} in {{Information Retrieval}}},
  author = {Biega, Asia J. and Gummadi, Krishna P. and Weikum, Gerhard},
  year = {2018},
  month = jun,
  pages = {405--414},
  publisher = {{Association for Computing Machinery}},
  address = {{Ann Arbor, MI, USA}},
  doi = {10.1145/3209978.3210063},
  abstract = {Rankings of people and items are at the heart of selection-making, match-making, and recommender systems, ranging from employment sites to sharing economy platforms. As ranking positions influence the amount of attention the ranked subjects receive, biases in rankings can lead to unfair distribution of opportunities and resources such as jobs or income. This paper proposes new measures and mechanisms to quantify and mitigate unfairness from a bias inherent to all rankings, namely, the position bias which leads to disproportionately less attention being paid to low-ranked subjects. Our approach differs from recent fair ranking approaches in two important ways. First, existing works measure unfairness at the level of subject groups while our measures capture unfairness at the level of individual subjects, and as such subsume group unfairness. Second, as no single ranking can achieve individual attention fairness, we propose a novel mechanism that achieves amortized fairness, where attention accumulated across a series of rankings is proportional to accumulated relevance. We formulate the challenge of achieving amortized individual fairness subject to constraints on ranking quality as an online optimization problem and show that it can be solved as an integer linear program. Our experimental evaluation reveals that unfair attention distribution in rankings can be substantial, and demonstrates that our method can improve individual fairness while retaining high ranking quality.},
  file = {/Users/yuekai/Documents/zotero/Biega et al (2018) - Equity of Attention.pdf},
  isbn = {978-1-4503-5657-2},
  series = {{{SIGIR}} '18}
}

@article{bien2016Nonconvex,
  title = {Non-Convex {{Global Minimization}} and {{False Discovery Rate Control}} for the {{TREX}}},
  author = {Bien, Jacob and Gaynanova, Irina and Lederer, Johannes and M{\"u}ller, Christian},
  year = {2016},
  month = apr,
  abstract = {The TREX is a recently introduced method for performing sparse high-dimensional regression. Despite its statistical promise as an alternative to the lasso, square-root lasso, and scaled lasso, the TREX is computationally challenging in that it requires solving a non-convex optimization problem. This paper shows a remarkable result: despite the non-convexity of the TREX problem, there exists a polynomial-time algorithm that is guaranteed to find the global minimum. This result adds the TREX to a very short list of non-convex optimization problems that can be globally optimized (principal components analysis being a famous example). After deriving and developing this new approach, we demonstrate that (i) the ability of the preexisting TREX heuristic to reach the global minimum is strongly dependent on the difficulty of the underlying statistical problem, (ii) the new polynomial-time algorithm for TREX permits a novel variable ranking and selection scheme, (iii) this scheme can be incorporated into a rule that controls the false discovery rate (FDR) of included features in the model. To achieve this last aim, we provide an extension of the results of Barber \& Candes (2015) to establish that the knockoff filter framework can be applied to the TREX. This investigation thus provides both a rare case study of a heuristic for non-convex optimization and a novel way of exploiting non-convexity for statistical inference.},
  archivePrefix = {arXiv},
  eprint = {1604.06815},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bien et al (2016) - Non-convex Global Minimization and False Discovery Rate Control for the TREX.pdf},
  journal = {arXiv:1604.06815 [cs, stat]},
  keywords = {Computer Science - Other Computer Science,Statistics - Computation,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {cs, stat}
}

@article{biggio2013Evasion,
  title = {Evasion {{Attacks}} against {{Machine Learning}} at {{Test Time}}},
  author = {Biggio, Battista and Corona, Igino and Maiorca, Davide and Nelson, Blaine and Srndic, Nedim and Laskov, Pavel and Giacinto, Giorgio and Roli, Fabio},
  year = {2013},
  volume = {7908},
  pages = {387--402},
  doi = {10.1007/978-3-642-40994-3_25},
  abstract = {In security-sensitive applications, the success of machine learning depends on a thorough vetting of their resistance to adversarial data. In one pertinent, well-motivated attack scenario, an adversary may attempt to evade a deployed system at test time by carefully manipulating attack samples. In this work, we present a simple but effective gradient-based approach that can be exploited to systematically assess the security of several, widely-used classification algorithms against evasion attacks. Following a recently proposed framework for security evaluation, we simulate attack scenarios that exhibit different risk levels for the classifier by increasing the attacker's knowledge of the system and her ability to manipulate attack samples. This gives the classifier designer a better picture of the classifier performance under evasion attacks, and allows him to perform a more informed model selection (or parameter setting). We evaluate our approach on the relevant security task of malware detection in PDF files, and show that such systems can be easily evaded. We also sketch some countermeasures suggested by our analysis.},
  archivePrefix = {arXiv},
  eprint = {1708.06131},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Biggio et al (2013) - Evasion Attacks against Machine Learning at Test Time.pdf},
  journal = {arXiv:1708.06131 [cs]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{biondo2018Talent,
  title = {Talent vs {{Luck}}: The Role of Randomness in Success and Failure},
  shorttitle = {Talent vs {{Luck}}},
  author = {Biondo, A. Pluchino A. E. and Rapisarda, A.},
  year = {2018},
  month = may,
  volume = {21},
  pages = {1850014},
  issn = {0219-5259, 1793-6802},
  doi = {10.1142/S0219525918500145},
  abstract = {The largely dominant meritocratic paradigm of highly competitive Western cultures is rooted on the belief that success is due mainly, if not exclusively, to personal qualities such as talent, intelligence, skills, efforts or risk taking. Sometimes, we are willing to admit that a certain degree of luck could also play a role in achieving significant material success. But, as a matter of fact, it is rather common to underestimate the importance of external forces in individual successful stories. It is very well known that intelligence or talent exhibit a Gaussian distribution among the population, whereas the distribution of wealth - considered a proxy of success - follows typically a power law (Pareto law). Such a discrepancy between a Normal distribution of inputs, with a typical scale, and the scale invariant distribution of outputs, suggests that some hidden ingredient is at work behind the scenes. In this paper, with the help of a very simple agent-based model, we suggest that such an ingredient is just randomness. In particular, we show that, if it is true that some degree of talent is necessary to be successful in life, almost never the most talented people reach the highest peaks of success, being overtaken by mediocre but sensibly luckier individuals. As to our knowledge, this counterintuitive result - although implicitly suggested between the lines in a vast literature - is quantified here for the first time. It sheds new light on the effectiveness of assessing merit on the basis of the reached level of success and underlines the risks of distributing excessive honors or resources to people who, at the end of the day, could have been simply luckier than others. With the help of this model, several policy hypotheses are also addressed and compared to show the most efficient strategies for public funding of research in order to improve meritocracy, diversity and innovation.},
  archivePrefix = {arXiv},
  eprint = {1802.07068},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Biondo, Rapisarda (2018) - Talent vs Luck.pdf},
  journal = {Advances in Complex Systems},
  keywords = {Physics - Physics and Society},
  number = {03n04}
}

@article{blanchard2013Classification,
  title = {Classification with {{Asymmetric Label Noise}}: {{Consistency}} and {{Maximal Denoising}}},
  shorttitle = {Classification with {{Asymmetric Label Noise}}},
  author = {Blanchard, Gilles and Flaska, Marek and Handy, Gregory and Pozzi, Sara and Scott, Clayton},
  year = {2013},
  month = mar,
  abstract = {In many real-world classification problems, the labels of training examples are randomly corrupted. Most previous theoretical work on classification with label noise assumes that the two classes are separable, that the label noise is independent of the true class label, or that the noise proportions for each class are known. In this work, we give conditions that are necessary and sufficient for the true class-conditional distributions to be identifiable. These conditions are weaker than those analyzed previously, and allow for the classes to be nonseparable and the noise levels to be asymmetric and unknown. The conditions essentially state that a majority of the observed labels are correct and that the true class-conditional distributions are "mutually irreducible," a concept we introduce that limits the similarity of the two distributions. For any label noise problem, there is a unique pair of true class-conditional distributions satisfying the proposed conditions, and we argue that this pair corresponds in a certain sense to maximal denoising of the observed distributions. Our results are facilitated by a connection to "mixture proportion estimation," which is the problem of estimating the maximal proportion of one distribution that is present in another. We establish a novel rate of convergence result for mixture proportion estimation, and apply this to obtain consistency of a discrimination rule based on surrogate loss minimization. Experimental results on benchmark data and a nuclear particle classification problem demonstrate the efficacy of our approach.},
  archivePrefix = {arXiv},
  eprint = {1303.1208},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Blanchard et al (2013) - Classification with Asymmetric Label Noise.pdf},
  journal = {arXiv:1303.1208 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{blanchard2017Domain,
  title = {Domain {{Generalization}} by {{Marginal Transfer Learning}}},
  author = {Blanchard, Gilles and Deshmukh, Aniket Anand and Dogan, Urun and Lee, Gyemin and Scott, Clayton},
  year = {2017},
  month = nov,
  abstract = {Domain generalization is the problem of assigning class labels to an unlabeled test data set, given several labeled training data sets drawn from similar distributions. This problem arises in several applications where data distributions fluctuate because of biological, technical, or other sources of variation. We develop a distribution-free, kernel-based approach that predicts a classifier from the marginal distribution of features, by leveraging the trends present in related classification tasks. This approach involves identifying an appropriate reproducing kernel Hilbert space and optimizing a regularized empirical risk over the space. We present generalization error analysis, describe universal kernels, and establish universal consistency of the proposed methodology. Experimental results on synthetic data and three real data applications demonstrate the superiority of the method with respect to a pooling strategy.},
  archivePrefix = {arXiv},
  eprint = {1711.07910},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Blanchard et al (2017) - Domain Generalization by Marginal Transfer Learning.pdf},
  journal = {arXiv:1711.07910 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{blanchard2017Post,
  title = {Post Hoc Inference via Joint Family-Wise Error Rate Control},
  author = {Blanchard, Gilles and Neuvial, Pierre and Roquain, Etienne},
  year = {2017},
  month = mar,
  abstract = {We introduce a general methodology for post hoc inference in a large-scale multiple testing framework. The approach is called "user-agnostic" in the sense that the statistical guarantee on the number of correct rejections holds for any set of candidate items selected by the user (after having seen the data). This task is investigated by defining a suitable criterion, named the joint-family-wise-error rate (JER for short). We propose several procedures for controlling the JER, with a special focus on incorporating dependencies while adapting to the unknown quantity of signal (via a step-down approach). We show that our proposed setting incorporates as particular cases a version of the higher criticism as well as the closed testing based approach of Goeman and Solari (2011). Our theoretical statements are supported by numerical experiments.},
  archivePrefix = {arXiv},
  eprint = {1703.02307},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Blanchard et al (2017) - Post hoc inference via joint family-wise error rate control.pdf},
  journal = {arXiv:1703.02307 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{blanchet2016Quantifying,
  title = {Quantifying {{Distributional Model Risk}} via {{Optimal Transport}}},
  author = {Blanchet, Jose and Murthy, Karthyek R. A.},
  year = {2016},
  month = apr,
  abstract = {This paper deals with the problem of quantifying the impact of model misspecification when computing general expected values of interest. The methodology that we propose is applicable in great generality, in particular, we provide examples involving path dependent expectations of stochastic processes. Our approach consists in computing bounds for the expectation of interest regardless of the probability measure used, as long as the measure lies within a prescribed tolerance measured in terms of a flexible class of distances from a suitable baseline model. These distances, based on optimal transportation between probability measures, include Wasserstein's distances as particular cases. The proposed methodology is well-suited for risk analysis, as we demonstrate with a number of applications. We also discuss how to estimate the tolerance region non-parametrically using Skorokhod-type embeddings in some of these applications.},
  archivePrefix = {arXiv},
  eprint = {1604.01446},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Blanchet, Murthy (2016) - Quantifying Distributional Model Risk via Optimal Transport.pdf},
  journal = {arXiv:1604.01446 [math, stat]},
  keywords = {Mathematics - Probability,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{blanchet2016Robust,
  title = {Robust {{Wasserstein Profile Inference}} and {{Applications}} to {{Machine Learning}}},
  author = {Blanchet, Jose and Kang, Yang and Murthy, Karthyek},
  year = {2016},
  month = oct,
  abstract = {We show that several machine learning estimators, including square-root LASSO (Least Absolute Shrinkage and Selection) and regularized logistic regression can be represented as solutions to distributionally robust optimization (DRO) problems. The associated uncertainty regions are based on suitably defined Wasserstein distances. Hence, our representations allow us to view regularization as a result of introducing an artificial adversary that perturbs the empirical distribution to account for out-of-sample effects in loss estimation. In addition, we introduce RWPI (Robust Wasserstein Profile Inference), a novel inference methodology which extends the use of methods inspired by Empirical Likelihood to the setting of optimal transport costs (of which Wasserstein distances are a particular case). We use RWPI to show how to optimally select the size of uncertainty regions, and as a consequence, we are able to choose regularization parameters for these machine learning estimators without the use of cross validation. Numerical experiments are also given to validate our theoretical findings.},
  archivePrefix = {arXiv},
  eprint = {1610.05627},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Blanchet et al (2016) - Robust Wasserstein Profile Inference and Applications to Machine Learning.pdf},
  journal = {arXiv:1610.05627 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{blanchet2017Datadriven,
  title = {Data-Driven {{Optimal Cost Selection}} for {{Distributionally Robust Optimization}}},
  author = {Blanchet, Jose and Kang, Yang and Zhang, Fan and Murthy, Karthyek},
  year = {2017},
  month = may,
  abstract = {Recently, (Blanchet, Kang, and Murhy 2016, and Blanchet, and Kang 2017) showed that several machine learning algorithms, such as square-root Lasso, Support Vector Machines, and regularized logistic regression, among many others, can be represented exactly as distributionally robust optimization (DRO) problems. The distributional uncertainty is defined as a neighborhood centered at the empirical distribution. We propose a methodology which learns such neighborhood in a natural data-driven way. We show rigorously that our framework encompasses adaptive regularization as a particular case. Moreover, we demonstrate empirically that our proposed methodology is able to improve upon a wide range of popular machine learning estimators.},
  archivePrefix = {arXiv},
  eprint = {1705.07152},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Blanchet et al (2017) - Data-driven Optimal Cost Selection for Distributionally Robust Optimization.pdf},
  journal = {arXiv:1705.07152 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{blanchet2017Doubly,
  title = {Doubly {{Robust Data}}-{{Driven Distributionally Robust Optimization}}},
  author = {Blanchet, Jose and Kang, Yang and Zhang, Fan and He, Fei and Hu, Zhangyi},
  year = {2017},
  month = may,
  abstract = {Data-driven Distributionally Robust Optimization (DD-DRO) via optimal transport has been shown to encompass a wide range of popular machine learning algorithms. The distributional uncertainty size is often shown to correspond to the regularization parameter. The type of regularization (e.g. the norm used to regularize) corresponds to the shape of the distributional uncertainty. We propose a data-driven robust optimization methodology to inform the transportation cost underlying the definition of the distributional uncertainty. We show empirically that this additional layer of robustification, which produces a method we called doubly robust data-driven distributionally robust optimization (DD-R-DRO), allows to enhance the generalization properties of regularized estimators while reducing testing error relative to state-of-the-art classifiers in a wide range of data sets.},
  archivePrefix = {arXiv},
  eprint = {1705.07168},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Blanchet et al (2017) - Doubly Robust Data-Driven Distributionally Robust Optimization.pdf},
  journal = {arXiv:1705.07168 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{blanchet2018Optimal,
  title = {Towards {{Optimal Running Times}} for {{Optimal Transport}}},
  author = {Blanchet, Jose and Jambulapati, Arun and Kent, Carson and Sidford, Aaron},
  year = {2018},
  month = oct,
  abstract = {In this work, we provide faster algorithms for approximating the optimal
transport distance, e.g. earth mover's distance, between two discrete
probability distributions \${$\mu$}, {$\nu\backslash$}in {$\Delta\sphat$}n\$. Given a cost function \$C :
[n] \textbackslash times [n] \textbackslash to \textbackslash mathbb\{R\}\_\{\textbackslash geq 0\}\$ where \$C(i,j) \textbackslash leq 1\$ quantifies the
penalty of transporting a unit of mass from \$i\$ to \$j\$, we show how to compute
a coupling \$X\$ between \$r\$ and \$c\$ in time \$\textbackslash widetilde\{O\}\textbackslash left(n\^2 /{$\epsilon$}
\textbackslash right)\$ whose expected transportation cost is within an additive \${$\epsilon\$$} of
optimal. This improves upon the previously best known running time for this
problem of \$\textbackslash widetilde\{O\}\textbackslash left(\textbackslash text\{min\}\textbackslash left\textbackslash\{ n\^\{9/4\}/{$\epsilon$},
n\^2/{$\epsilon\sphat$}2 \textbackslash right\textbackslash\}\textbackslash right)\$.
  We achieve our results by providing reductions from optimal transport to
canonical optimization problems for which recent algorithmic efforts have
provided nearly-linear time algorithms. Leveraging nearly linear time
algorithms for solving packing linear programs and for solving the matrix
balancing problem, we obtain two separate proofs of our stated running time.
Further, one of our algorithms is easily parallelized and can be implemented
with depth \$\textbackslash widetilde\{O\}(1/{$\epsilon$})\$.
  Moreover, we show that further algorithmic improvements to our result would
be surprising in the sense that any improvement would yield an \$o(n\^\{2.5\})\$
algorithm for \textbackslash textit\{maximum cardinality bipartite matching\}, for which
currently the only known algorithms for achieving such a result are based on
fast-matrix multiplication.},
  file = {/Users/yuekai/Documents/zotero/Blanchet et al (2018) - Towards Optimal Running Times for Optimal Transport.pdf},
  language = {en}
}

@article{blanchet2018Optimala,
  title = {Optimal {{Transport Based Distributionally Robust Optimization}}: {{Structural Properties}} and {{Iterative Schemes}}},
  shorttitle = {Optimal {{Transport Based Distributionally Robust Optimization}}},
  author = {Blanchet, Jose and Murthy, Karthyek and Zhang, Fan},
  year = {2018},
  month = oct,
  abstract = {We consider optimal transport based distributionally robust optimization (DRO) problems with locally strongly convex transport cost functions and affine decision rules. Under conventional convexity assumptions on the underlying loss function, we obtain structural results about the value function, the optimal policy, and the worst-case optimal transport adversarial model. These results expose a rich structure embedded in the DRO problem (e.g., strong convexity even if the non-DRO problem was not strongly convex, a suitable scaling of the Lagrangian for the DRO constraint, etc. which are crucial for the design of efficient algorithms). As a consequence of these results, one can develop optimization procedures which have the same sample and iteration complexity as a natural non-DRO benchmark algorithm such as stochastic gradient descent; and sometimes even better complexity. Our analysis provides insights into the fine structure and convexity properties of the DRO value function, the optimal policy, and the worst-case optimal transport adversarial model.},
  archivePrefix = {arXiv},
  eprint = {1810.02403},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Blanchet et al (2018) - Optimal Transport Based Distributionally Robust Optimization.pdf},
  journal = {arXiv:1810.02403 [math]},
  keywords = {Mathematics - Optimization and Control},
  primaryClass = {math}
}

@article{blanchet2019Confidence,
  title = {Confidence {{Regions}} in {{Wasserstein Distributionally Robust Estimation}}},
  author = {Blanchet, Jose and Murthy, Karthyek and Si, Nian},
  year = {2019},
  month = jun,
  abstract = {Wasserstein distributionally robust optimization (DRO) estimators are obtained as solutions of min-max problems in which the statistician selects a parameter minimizing the worst-case loss among all probability models within a certain distance (in a Wasserstein sense) from the underlying empirical measure. While motivated by the need to identify model parameters (or) decision choices that are robust to model uncertainties and misspecification, the Wasserstein DRO estimators recover a wide range of regularized estimators, including square-root LASSO and support vector machines, among others, as particular cases. This paper studies the asymptotic normality of underlying DRO estimators as well as the properties of an optimal (in a suitable sense) confidence region induced by the Wasserstein DRO formulation.},
  archivePrefix = {arXiv},
  eprint = {1906.01614},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Blanchet et al (2019) - Confidence Regions in Wasserstein Distributionally Robust Estimation.pdf},
  journal = {arXiv:1906.01614 [math, stat]},
  keywords = {Mathematics - Optimization and Control,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {math, stat}
}

@article{blanchet2019Distributionally,
  title = {A {{Distributionally Robust Boosting Algorithm}}},
  author = {Blanchet, Jose and Kang, Yang and Zhang, Fan and Hu, Zhangyi},
  year = {2019},
  month = may,
  abstract = {Distributionally Robust Optimization (DRO) has been shown to provide a flexible framework for decision making under uncertainty and statistical estimation. For example, recent works in DRO have shown that popular statistical estimators can be interpreted as the solutions of suitable formulated data-driven DRO problems. In turn, this connection is used to optimally select tuning parameters in terms of a principled approach informed by robustness considerations. This paper contributes to this growing literature, connecting DRO and statistics, by showing how boosting algorithms can be studied via DRO. We propose a boosting type algorithm, named DRO-Boosting, as a procedure to solve our DRO formulation. Our DRO-Boosting algorithm recovers Adaptive Boosting (AdaBoost) in particular, thus showing that AdaBoost is effectively solving a DRO problem. We apply our algorithm to a financial dataset on credit card default payment prediction. We find that our approach compares favorably to alternative boosting methods which are widely used in practice.},
  archivePrefix = {arXiv},
  eprint = {1905.07845},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Blanchet et al (2019) - A Distributionally Robust Boosting Algorithm.pdf},
  journal = {arXiv:1905.07845 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{bloem-reddy2019Probabilistic,
  title = {Probabilistic Symmetry and Invariant Neural Networks},
  author = {{Bloem-Reddy}, Benjamin and Teh, Yee Whye},
  year = {2019},
  month = jan,
  abstract = {In an effort to improve the performance of deep neural networks in data-scarce, non-i.i.d., or unsupervised settings, much recent research has been devoted to encoding invariance under symmetry transformations into neural network architectures. We treat the neural network input and output as random variables, and consider group invariance from the perspective of probabilistic symmetry. Drawing on tools from probability and statistics, we establish a link between functional and probabilistic symmetry, and obtain generative functional representations of joint and conditional probability distributions that are invariant or equivariant under the action of a compact group. Those representations completely characterize the structure of neural networks that can be used to model such distributions and yield a general program for constructing invariant stochastic or deterministic neural networks. We develop the details of the general program for exchangeable sequences and arrays, recovering a number of recent examples as special cases.},
  archivePrefix = {arXiv},
  eprint = {1901.06082},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bloem-Reddy, Teh (2019) - Probabilistic symmetry and invariant neural networks.pdf},
  journal = {arXiv:1901.06082 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@techreport{blomberg2010Validation,
  title = {Validation of the {{COMPAS Risk Assessment Classification Instrument}}},
  author = {Blomberg, Thomas and Bales, William and Mann, Karen and Meldrum, Ryan and Nedelec, Joe},
  year = {2010},
  month = sep,
  address = {{Tallahassee, Florida}},
  institution = {{Florida State University}},
  file = {/Users/yuekai/Documents/zotero/Blomberg et al (2010) - Validation of the COMPAS Risk Assessment Classification Instrument.pdf}
}

@article{blondel2019Learning,
  title = {Learning with {{Fenchel}}-{{Young Losses}}},
  author = {Blondel, Mathieu and Martins, Andr{\'e} F. T. and Niculae, Vlad},
  year = {2019},
  month = jan,
  abstract = {Over the past decades, numerous loss functions have been been proposed for a variety of supervised learning tasks, including regression, classification, ranking, and more generally structured prediction. Understanding the core principles and theoretical properties underpinning these losses is key to choose the right loss for the right problem, as well as to create new losses which combine their strengths. In this paper, we introduce Fenchel-Young losses, a generic way to construct a convex loss function for a regularized prediction function. We provide an in-depth study of their properties in a very broad setting, covering all the aforementioned supervised learning tasks, and revealing new connections between sparsity, generalized entropies, and separation margins. We show that Fenchel-Young losses unify many well-known loss functions and allow to create useful new ones easily. Finally, we derive efficient predictive and training algorithms, making Fenchel-Young losses appealing both in theory and practice.},
  archivePrefix = {arXiv},
  eprint = {1901.02324},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Blondel et al (2019) - Learning with Fenchel-Young Losses.pdf},
  journal = {arXiv:1901.02324 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@incollection{blum2007Learning,
  title = {Learning, {{Regret Minimization}}, and {{Equilibria}}},
  booktitle = {Algorithmic {{Game Theory}}},
  author = {Blum, Avrim and Mansour, Yishay},
  editor = {Nisan, Noam and Roughgarden, Tim and Tardos, Eva and Vazirani, Vijay V.},
  year = {2007},
  pages = {79--102},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9780511800481.006},
  abstract = {Many situations involve repeatedly making decisions in an uncertain environment: for instance, deciding what route to drive to work each day, or repeated play of a game against an opponent with an unknown strategy. In this chapter we describe learning algorithms with strong guarantees for settings of this type, along with connections to game-theoretic equilibria when all players in a system are simultaneously adapting in such a manner.},
  file = {/Users/yuekai/Documents/zotero/Blum, Mansour (2007) - Learning, Regret Minimization, and Equilibria.pdf},
  isbn = {978-0-511-80048-1},
  language = {en}
}

@article{blum2017Separating,
  title = {Separating {{Populations}} with {{Wide Data}}: {{A Spectral Analysis}}},
  author = {Blum, Avrim and {Coja-Oghlan}, Amin and Frieze, Alan and Zhou, Shuheng},
  year = {2017},
  month = dec,
  pages = {13},
  abstract = {In this paper, we consider the problem of partitioning a small data sample drawn from a mixture of k product distributions. We are interested in the case that individual features are of low average quality {$\gamma$}, and we want to use as few of them as possible to correctly partition the sample. We analyze a spectral technique that is able to approximately optimize the total data size\textemdash the product of number of data points n and the number of features K\textemdash needed to correctly perform this partitioning as a function of 1/{$\gamma$} for K {$>$} n. Our goal is motivated by an application in clustering individuals according to their population of origin using markers, when the divergence between any two of the populations is small.},
  file = {/Users/yuekai/Documents/zotero/Blum et al (2017) - Separating Populations with Wide Data.pdf},
  language = {en}
}

@article{blum2018preserving,
  title = {On Preserving Non-Discrimination When Combining Expert Advice},
  author = {Blum, Avrim and Gunasekar, Suriya and Lykouris, Thodoris and Srebro, Nathan},
  year = {2018},
  month = oct,
  abstract = {We study the interplay between sequential decision making and avoiding discrimination against protected groups, when examples arrive online and do not follow distributional assumptions. We consider the most basic extension of classical online learning: "Given a class of predictors that are individually non-discriminatory with respect to a particular metric, how can we combine them to perform as well as the best predictor, while preserving non-discrimination?" Surprisingly we show that this task is unachievable for the prevalent notion of "equalized odds" that requires equal false negative rates and equal false positive rates across groups. On the positive side, for another notion of non-discrimination, "equalized error rates", we show that running separate instances of the classical multiplicative weights algorithm for each group achieves this guarantee. Interestingly, even for this notion, we show that algorithms with stronger performance guarantees than multiplicative weights cannot preserve non-discrimination.},
  archivePrefix = {arXiv},
  eprint = {1810.11829},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Blum et al (2018) - On preserving non-discrimination when combining expert advice.pdf},
  journal = {arXiv:1810.11829 [cs, stat]},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{blum2019Recovering,
  title = {Recovering from {{Biased Data}}: {{Can Fairness Constraints Improve Accuracy}}?},
  shorttitle = {Recovering from {{Biased Data}}},
  author = {Blum, Avrim and Stangl, Kevin},
  year = {2019},
  month = dec,
  abstract = {Multiple fairness constraints have been proposed in the literature, motivated by a range of concerns about how demographic groups might be treated unfairly by machine learning classifiers. In this work we consider a different motivation; learning from biased training data. We posit several ways in which training data may be biased, including having a more noisy or negatively biased labeling process on members of a disadvantaged group, or a decreased prevalence of positive or negative examples from the disadvantaged group, or both. Given such biased training data, Empirical Risk Minimization (ERM) may produce a classifier that not only is biased but also has suboptimal accuracy on the true data distribution. We examine the ability of fairness-constrained ERM to correct this problem. In particular, we find that the Equal Opportunity fairness constraint (Hardt, Price, and Srebro 2016) combined with ERM will provably recover the Bayes Optimal Classifier under a range of bias models. We also consider other recovery methods including reweighting the training data, Equalized Odds, and Demographic Parity. These theoretical results provide additional motivation for considering fairness interventions even if an actor cares primarily about accuracy.},
  archivePrefix = {arXiv},
  eprint = {1912.01094},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Blum, Stangl (2019) - Recovering from Biased Data.pdf},
  journal = {arXiv:1912.01094 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{bogen2020Awareness,
  title = {Awareness in Practice: Tensions in Access to Sensitive Attribute Data for Antidiscrimination},
  shorttitle = {Awareness in Practice},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Bogen, Miranda and Rieke, Aaron and Ahmed, Shazeda},
  year = {2020},
  month = jan,
  pages = {492--500},
  publisher = {{Association for Computing Machinery}},
  address = {{Barcelona, Spain}},
  doi = {10.1145/3351095.3372877},
  abstract = {Organizations cannot address demographic disparities that they cannot see. Recent research on machine learning and fairness has emphasized that awareness of sensitive attributes, such as race and sex, is critical to the development of interventions. However, on the ground, the existence of these data cannot be taken for granted. This paper uses the domains of employment, credit, and healthcare in the United States to surface conditions that have shaped the availability of sensitive attribute data. For each domain, we describe how and when private companies collect or infer sensitive attribute data for antidiscrimination purposes. An inconsistent story emerges: Some companies are required by law to collect sensitive attribute data, while others are prohibited from doing so. Still others, in the absence of legal mandates, have determined that collection and imputation of these data are appropriate to address disparities. This story has important implications for fairness research and its future applications. If companies that mediate access to life opportunities are unable or hesitant to collect or infer sensitive attribute data, then proposed techniques to detect and mitigate bias in machine learning models might never be implemented outside the lab. We conclude that today's legal requirements and corporate practices, while highly inconsistent across domains, offer lessons for how to approach the collection and inference of sensitive data in appropriate circumstances. We urge stakeholders, including machine learning practitioners, to actively help chart a path forward that takes both policy goals and technical needs into account.},
  file = {/Users/yuekai/Documents/zotero/Bogen et al (2020) - Awareness in practice.pdf},
  isbn = {978-1-4503-6936-7},
  series = {{{FAT}}* '20}
}

@article{bolukbasi2016Man,
  title = {Man Is to {{Computer Programmer}} as {{Woman}} Is to {{Homemaker}}? {{Debiasing Word Embeddings}}},
  shorttitle = {Man Is to {{Computer Programmer}} as {{Woman}} Is to {{Homemaker}}?},
  author = {Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James and Saligrama, Venkatesh and Kalai, Adam},
  year = {2016},
  month = jul,
  abstract = {The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is first shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender definition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between between the words receptionist and female, while maintaining desired associations such as between the words queen and female. We define metrics to quantify both direct and indirect gender biases in embeddings, and develop algorithms to "debias" the embedding. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias.},
  archivePrefix = {arXiv},
  eprint = {1607.06520},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bolukbasi et al (2016) - Man is to Computer Programmer as Woman is to Homemaker.pdf},
  journal = {arXiv:1607.06520 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@techreport{bonawitz2017Practical,
  title = {Practical {{Secure Aggregation}} for {{Privacy Preserving Machine Learning}}},
  author = {Bonawitz, Keith and Ivanov, Vladimir and Kreuter, Ben and Marcedone, Antonio and McMahan, H. Brendan and Patel, Sarvar and Ramage, Daniel and Segal, Aaron and Seth, Karn},
  year = {2017},
  abstract = {We design a novel, communication-efficient, failure-robust protocol for secure aggregation of high-dimensional data. Our protocol allows a server to compute the sum of large, user-held data vectors from mobile devices in a secure manner (i.e. without learning each user's individual contribution), and can be used, for example, in a federated learning setting, to aggregate user-provided model updates for a deep neural network. We prove the security of our protocol in the honest-but-curious and malicious settings, and show that security is maintained even if an arbitrarily chosen subset of users drop out at any time. We evaluate the efficiency of our protocol and show, by complexity analysis and a concrete implementation, that its runtime and communication overhead remain low even on large data sets and client pools. For 16-bit input values, our protocol offers \$1.73\textbackslash times\$ communication expansion for \$2\^\{10\}\$ users and \$2\^\{20\}\$-dimensional vectors, and \$1.98\textbackslash times\$ expansion for \$2\^\{14\}\$ users and \$2\^\{24\}\$-dimensional vectors over sending data in the clear.},
  file = {/Users/yuekai/Documents/zotero/Bonawitz et al (2017) - Practical Secure Aggregation for Privacy Preserving Machine Learning.pdf},
  keywords = {cryptographic protocols},
  number = {281}
}

@book{bonnans2000Perturbation,
  title = {Perturbation Analysis of Optimization Problems},
  author = {Bonnans, Joseph Fr{\'e}d{\'e}ric and Shapiro, Alexander},
  year = {2000},
  publisher = {{Springer}},
  address = {{New York, NY}},
  annotation = {OCLC: 247674137},
  file = {/Users/yuekai/Documents/zotero/Bonnans, Shapiro (2000) - Perturbation analysis of optimization problems.pdf},
  isbn = {978-1-4612-7129-1 978-0-387-98705-7},
  language = {en},
  series = {Springer Series in Operations Research}
}

@book{bonnans2019Convex,
  title = {Convex and {{Stochastic Optimization}}},
  author = {Bonnans, J. Fr{\'e}d{\'e}ric},
  year = {2019},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-14977-2},
  file = {/Users/yuekai/Documents/zotero/Bonnans (2019) - Convex and Stochastic Optimization.pdf},
  isbn = {978-3-030-14976-5 978-3-030-14977-2},
  language = {en},
  series = {Universitext}
}

@article{borgs2018Identifiability,
  title = {Identifiability for Graphexes and the Weak Kernel Metric},
  author = {Borgs, Christian and Chayes, Jennifer T. and Cohn, Henry and Lov{\'a}sz, L{\'a}szl{\'o} Mikl{\'o}s},
  year = {2018},
  month = apr,
  abstract = {In two recent papers by Veitch and Roy and by Borgs, Chayes, Cohn, and Holden, a new class of sparse random graph processes based on the concept of graphexes over {$\sigma$}-finite measure spaces has been introduced. In this paper, we introduce a metric for graphexes that generalizes the cut metric for the graphons of the dense theory of graph convergence. We show that a sequence of graphexes converges in this metric if and only if the sequence of graph processes generated by the graphexes converges in distribution. In the course of the proof, we establish a regularity lemma and determine which sets of graphexes are precompact under our metric. Finally, we establish an identifiability theorem, characterizing when two graphexes are equivalent in the sense that they lead to the same process of random graphs.},
  archivePrefix = {arXiv},
  eprint = {1804.03277},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Borgs et al (2018) - Identifiability for graphexes and the weak kernel metric.pdf},
  journal = {arXiv:1804.03277 [math]},
  keywords = {Mathematics - Combinatorics,Mathematics - Probability},
  language = {en},
  primaryClass = {math}
}

@article{borkan2019Nuanced,
  title = {Nuanced {{Metrics}} for {{Measuring Unintended Bias}} with {{Real Data}} for {{Text Classification}}},
  author = {Borkan, Daniel and Dixon, Lucas and Sorensen, Jeffrey and Thain, Nithum and Vasserman, Lucy},
  year = {2019},
  month = mar,
  abstract = {Unintended bias in Machine Learning can manifest as systemic differences in performance for different demographic groups, potentially compounding existing challenges to fairness in society at large. In this paper, we introduce a suite of threshold-agnostic metrics that provide a nuanced view of this unintended bias, by considering the various ways that a classifier's score distribution can vary across designated groups. We also introduce a large new test set of online comments with crowd-sourced annotations for identity references. We use this to show how our metrics can be used to find new and potentially subtle unintended bias in existing public models.},
  archivePrefix = {arXiv},
  eprint = {1903.04561},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Borkan et al (2019) - Nuanced Metrics for Measuring Unintended Bias with Real Data for Text.pdf},
  journal = {arXiv:1903.04561 [cs, stat]},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{bottou2012Counterfactual,
  title = {Counterfactual {{Reasoning}} and {{Learning Systems}}},
  author = {Bottou, L{\'e}on and Peters, Jonas and {Qui{\~n}onero-Candela}, Joaquin and Charles, Denis X. and Chickering, D. Max and Portugaly, Elon and Ray, Dipankar and Simard, Patrice and Snelson, Ed},
  year = {2012},
  month = sep,
  abstract = {This work shows how to leverage causal inference to understand the behavior
of complex learning systems interacting with their environment and predict the
consequences of changes to the system. Such predictions allow both humans and
algorithms to select changes that improve both the short-term and long-term
performance of such systems. This work is illustrated by experiments carried
out on the ad placement system associated with the Bing search engine.},
  file = {/Users/yuekai/Documents/zotero/Bottou et al (2012) - Counterfactual Reasoning and Learning Systems.pdf},
  language = {en}
}

@article{bottou2018Optimization,
  title = {Optimization {{Methods}} for {{Large}}-{{Scale Machine Learning}}},
  author = {Bottou, L{\'e}on and Curtis, Frank E. and Nocedal, Jorge},
  year = {2018},
  month = feb,
  abstract = {This paper provides a review and commentary on the past, present, and future of numerical optimization algorithms in the context of machine learning applications. Through case studies on text classification and the training of deep neural networks, we discuss how optimization problems arise in machine learning and what makes them challenging. A major theme of our study is that large-scale machine learning represents a distinctive setting in which the stochastic gradient (SG) method has traditionally played a central role while conventional gradient-based nonlinear optimization techniques typically falter. Based on this viewpoint, we present a comprehensive theory of a straightforward, yet versatile SG algorithm, discuss its practical behavior, and highlight opportunities for designing algorithms with improved performance. This leads to a discussion about the next generation of optimization methods for large-scale machine learning, including an investigation of two main streams of research on techniques that diminish noise in the stochastic directions and methods that make use of second-order derivative approximations.},
  archivePrefix = {arXiv},
  eprint = {1606.04838},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bottou et al (2018) - Optimization Methods for Large-Scale Machine Learning.pdf},
  journal = {arXiv:1606.04838 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{bousquet2019Fast,
  title = {Fast Classification Rates without Standard Margin Assumptions},
  author = {Bousquet, Olivier and Zhivotovskiy, Nikita},
  year = {2019},
  month = oct,
  abstract = {We consider the classical problem of learning rates for classes with finite VC dimension. It is well known that fast learning rates are achievable by the empirical risk minimization algorithm (ERM) if one of the low noise/margin assumptions such as Tsybakov's and Massart's condition is satisfied. In this paper, we consider an alternative way of obtaining fast learning rates in classification if none of these conditions are met. We first consider Chow's reject option model and show that by lowering the impact of a small fraction of hard instances, fast learning rate is achievable in an agnostic model by a specific learning algorithm. Similar results were only known under special versions of margin assumptions. We also show that the learning algorithm achieving these rates is adaptive to standard margin assumptions and always satisfies the risk bounds achieved by ERM. Based on our results on Chow's model, we then analyze a particular family of VC classes, namely classes with finite combinatorial diameter. Using their special structure, we show that there is an improper learning algorithm that provides fast rates of convergence even in the (poorly understood) situations where ERM is suboptimal. This provides the first setup in which an improper learning algorithm may significantly improve the learning rates for non-convex losses. Finally, we discuss some implications of our techniques to the analysis of ERM.},
  archivePrefix = {arXiv},
  eprint = {1910.12756},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bousquet, Zhivotovskiy (2019) - Fast classification rates without standard margin assumptions.pdf},
  journal = {arXiv:1910.12756 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{bower2018Debiasing,
  title = {Debiasing Representations by Removing Unwanted Variation Due to Protected Attributes},
  author = {Bower, Amanda and Niss, Laura and Sun, Yuekai and Vargo, Alexander},
  year = {2018},
  month = jul,
  abstract = {We propose a regression-based approach to removing implicit biases in representations. On tasks where the protected attribute is observed, the method is statistically more efficient than known approaches. Further, we show that this approach leads to debiased representations that satisfy a first order approximation of conditional parity. Finally, we demonstrate the efficacy of the proposed approach by reducing racial bias in recidivism risk scores.},
  archivePrefix = {arXiv},
  eprint = {1807.00461},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bower et al (2018) - Debiasing representations by removing unwanted variation due to protected.pdf},
  journal = {arXiv:1807.00461 [cs]},
  keywords = {Computer Science - Computers and Society},
  primaryClass = {cs}
}

@book{boyd2004Convex,
  title = {Convex Optimization},
  author = {Boyd, Stephen P. and Vandenberghe, Lieven},
  year = {2004},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, UK ; New York}},
  file = {/Users/yuekai/Documents/zotero/Boyd, Vandenberghe (2004) - Convex optimization.pdf},
  isbn = {978-0-521-83378-3},
  language = {en},
  lccn = {QA402.5 .B69 2004}
}

@article{boyd2010Distributed,
  title = {Distributed {{Optimization}} and {{Statistical Learning}} via the {{Alternating Direction Method}} of {{Multipliers}}},
  author = {Boyd, Stephen},
  year = {2010},
  volume = {3},
  pages = {1--122},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000016},
  file = {/Users/yuekai/Documents/zotero/Boyd (2010) - Distributed Optimization and Statistical Learning via the Alternating Direction.pdf},
  journal = {Foundations and Trends\textregistered{} in Machine Learning},
  language = {en},
  number = {1}
}

@article{braverman2019gradient,
  title = {The Gradient Complexity of Linear Regression},
  author = {Braverman, Mark and Hazan, Elad and Simchowitz, Max and Woodworth, Blake},
  year = {2019},
  month = nov,
  abstract = {We investigate the computational complexity of several basic linear algebra primitives, including largest eigenvector computation and linear regression, in the computational model that allows access to the data via a matrix-vector product oracle. We show that for polynomial accuracy, \$\textbackslash Theta(d)\$ calls to the oracle are necessary and sufficient even for a randomized algorithm. Our lower bound is based on a reduction to estimating the least eigenvalue of a random Wishart matrix. This simple distribution enables a concise proof, leveraging a few key properties of the random Wishart ensemble.},
  archivePrefix = {arXiv},
  eprint = {1911.02212},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Braverman et al (2019) - The gradient complexity of linear regression.pdf},
  journal = {arXiv:1911.02212 [cs, math, stat]},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{breiman1985Estimating,
  title = {Estimating {{Optimal Transformations}} for {{Multiple Regression}} and {{Correlation}}},
  author = {Breiman, Leo and Friedman, Jerome H.},
  year = {1985},
  month = sep,
  volume = {80},
  pages = {580--598},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.1985.10478157},
  file = {/Users/yuekai/Documents/zotero/Breiman, Friedman (1985) - Estimating Optimal Transformations for Multiple Regression and Correlation.pdf},
  journal = {Journal of the American Statistical Association},
  language = {en},
  number = {391}
}

@article{brock2018Large,
  title = {Large {{Scale GAN Training}} for {{High Fidelity Natural Image Synthesis}}},
  author = {Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
  year = {2018},
  month = sep,
  abstract = {Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple "truncation trick," allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.5 and Frechet Inception Distance (FID) of 7.4, improving over the previous best IS of 52.52 and FID of 18.6.},
  archivePrefix = {arXiv},
  eprint = {1809.11096},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Brock et al (2018) - Large Scale GAN Training for High Fidelity Natural Image Synthesis.pdf},
  journal = {arXiv:1809.11096 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{bronstein2017Geometric,
  title = {Geometric Deep Learning: Going beyond {{Euclidean}} Data},
  shorttitle = {Geometric Deep Learning},
  author = {Bronstein, Michael M. and Bruna, Joan and LeCun, Yann and Szlam, Arthur and Vandergheynst, Pierre},
  year = {2017},
  month = jul,
  volume = {34},
  pages = {18--42},
  issn = {1053-5888},
  doi = {10.1109/MSP.2017.2693418},
  abstract = {Many scientific fields study data with an underlying structure that is a non-Euclidean space. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions), and are natural targets for machine learning techniques. In particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural language processing, and audio analysis. However, these tools have been most successful on data with an underlying Euclidean or grid-like structure, and in cases where the invariances of these structures are built into networks used to model them. Geometric deep learning is an umbrella term for emerging techniques attempting to generalize (structured) deep neural models to non-Euclidean domains such as graphs and manifolds. The purpose of this paper is to overview different examples of geometric deep learning problems and present available solutions, key difficulties, applications, and future research directions in this nascent field.},
  archivePrefix = {arXiv},
  eprint = {1611.08097},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bronstein et al (2017) - Geometric deep learning.pdf},
  journal = {IEEE Signal Processing Magazine},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  number = {4}
}

@article{brown2009Nonparametric,
  title = {Nonparametric Empirical {{Bayes}} and Compound Decision Approaches to Estimation of a High-Dimensional Vector of Normal Means},
  author = {Brown, Lawrence D. and Greenshtein, Eitan},
  year = {2009},
  month = aug,
  volume = {37},
  pages = {1685--1704},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/08-AOS630},
  abstract = {We consider the classical problem of estimating a vector {$\mu$}=({$\mu$}1, \ldots, {$\mu$}n) based on independent observations Yi{$\sim$}N({$\mu$}i, 1), i=1, \ldots, n. Suppose {$\mu$}i, i=1, \ldots, n are independent realizations from a completely unknown G. We suggest an easily computed estimator {$\mu\hat$}, such that the ratio of its risk E({$\mu\hat-\mu$})2 with that of the Bayes procedure approaches 1. A related compound decision result is also obtained. Our asymptotics is of a triangular array; that is, we allow the distribution G to depend on n. Thus, our theoretical asymptotic results are also meaningful in situations where the vector {$\mu$} is sparse and the proportion of zero coordinates approaches 1. We demonstrate the performance of our estimator in simulations, emphasizing sparse setups. In ``moderately-sparse'' situations, our procedure performs very well compared to known procedures tailored for sparse setups. It also adapts well to nonsparse situations.},
  file = {/Users/yuekai/Documents/zotero/Brown, Greenshtein (2009) - Nonparametric empirical Bayes and compound decision approaches to estimation of.pdf},
  journal = {The Annals of Statistics},
  language = {EN},
  mrnumber = {MR2533468},
  number = {4},
  zmnumber = {1166.62005}
}

@article{brown2020Language,
  title = {Language {{Models}} Are {{Few}}-{{Shot Learners}}},
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and {Herbert-Voss}, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  year = {2020},
  month = jun,
  abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
  archivePrefix = {arXiv},
  eprint = {2005.14165},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Brown et al (2020) - Language Models are Few-Shot Learners.pdf},
  journal = {arXiv:2005.14165 [cs]},
  keywords = {Computer Science - Computation and Language},
  primaryClass = {cs}
}

@article{bruck1977weak,
  title = {On the Weak Convergence of an Ergodic Iteration for the Solution of Variational Inequalities for Monotone Operators in {{Hilbert}} Space},
  author = {Bruck, Ronald E},
  year = {1977},
  month = nov,
  volume = {61},
  pages = {159--164},
  issn = {0022247X},
  doi = {10.1016/0022-247X(77)90152-4},
  file = {/Users/yuekai/Documents/zotero/Bruck (1977) - On the weak convergence of an ergodic iteration for the solution of variational.pdf},
  journal = {Journal of Mathematical Analysis and Applications},
  language = {en},
  number = {1}
}

@article{brunel2018Methods,
  title = {Methods for {{Estimation}} of {{Convex Sets}}},
  author = {Brunel, Victor-Emmanuel},
  year = {2018},
  month = nov,
  volume = {33},
  pages = {615--632},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/18-STS669},
  abstract = {In the framework of shape constrained estimation, we review methods and works done in convex set estimation. These methods mostly build on stochastic and convex geometry, empirical process theory, functional analysis, linear programming, extreme value theory, etc. The statistical problems that we review include density support estimation, estimation of the level sets of densities or depth functions, nonparametric regression, etc. We focus on the estimation of convex sets under the Nikodym and Hausdorff metrics, which require different techniques and, quite surprisingly, lead to very different results, in particular in density support estimation. Finally, we discuss computational issues in high dimensions.},
  file = {/Users/yuekai/Documents/zotero/Brunel (2018) - Methods for Estimation of Convex Sets.pdf},
  journal = {Statistical Science},
  language = {EN},
  mrnumber = {MR3881211},
  number = {4},
  zmnumber = {07032832}
}

@article{brunton2020Machine,
  title = {Machine {{Learning}} for {{Fluid Mechanics}}},
  author = {Brunton, Steven and Noack, Bernd and Koumoutsakos, Petros},
  year = {2020},
  month = jan,
  volume = {52},
  pages = {477--508},
  issn = {0066-4189, 1545-4479},
  doi = {10.1146/annurev-fluid-010719-060214},
  abstract = {The field of fluid mechanics is rapidly advancing, driven by unprecedented volumes of data from field measurements, experiments and large-scale simulations at multiple spatiotemporal scales. Machine learning offers a wealth of techniques to extract information from data that could be translated into knowledge about the underlying fluid mechanics. Moreover, machine learning algorithms can augment domain knowledge and automate tasks related to flow control and optimization. This article presents an overview of past history, current developments, and emerging opportunities of machine learning for fluid mechanics. It outlines fundamental machine learning methodologies and discusses their uses for understanding, modeling, optimizing, and controlling fluid flows. The strengths and limitations of these methods are addressed from the perspective of scientific inquiry that considers data as an inherent part of modeling, experimentation, and simulation. Machine learning provides a powerful information processing framework that can enrich, and possibly even transform, current lines of fluid mechanics research and industrial applications.},
  archivePrefix = {arXiv},
  eprint = {1905.11075},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Brunton et al (2020) - Machine Learning for Fluid Mechanics.pdf},
  journal = {Annual Review of Fluid Mechanics},
  keywords = {Computer Science - Machine Learning,Physics - Fluid Dynamics,Statistics - Machine Learning},
  number = {1}
}

@article{bu2019Deep,
  title = {Deep {{Learning}} with {{Gaussian Differential Privacy}}},
  author = {Bu, Zhiqi and Dong, Jinshuo and Long, Qi and Su, Weijie J.},
  year = {2019},
  month = dec,
  abstract = {Deep learning models are often trained on datasets that contain sensitive information such as individuals' shopping transactions, personal contacts, and medical records. An increasingly important line of work therefore has sought to train neural networks subject to privacy constraints that are specified by differential privacy or its divergence-based relaxations. These privacy definitions, however, have weaknesses in handling certain important primitives (composition and subsampling), thereby giving loose or complicated privacy analyses of training neural networks. In this paper, we consider a recently proposed privacy definition termed f-differential privacy [17] for a refined privacy analysis of training neural networks. Leveraging the appealing properties of f-differential privacy in handling composition and subsampling, this paper derives analytically tractable expressions for the privacy guarantees of both stochastic gradient descent and Adam used in training deep neural networks, without the need of developing sophisticated techniques as [3] did. Our results demonstrate that the f-differential privacy framework allows for a new privacy analysis that improves on the prior analysis [3], which in turn suggests tuning certain parameters of neural networks for a better prediction accuracy without violating the privacy budget. These theoretically derived improvements are confirmed by our experiments in a range of tasks in image classification, text classification, and recommender systems.},
  archivePrefix = {arXiv},
  eprint = {1911.11607},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bu et al (2019) - Deep Learning with Gaussian Differential Privacy.pdf},
  journal = {arXiv:1911.11607 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{bubeck2014Convex,
  title = {Convex {{Optimization}}: {{Algorithms}} and {{Complexity}}},
  shorttitle = {Convex {{Optimization}}},
  author = {Bubeck, S{\'e}bastien},
  year = {2014},
  month = may,
  abstract = {This monograph presents the main complexity theorems in convex optimization and their corresponding algorithms. Starting from the fundamental theory of black-box optimization, the material progresses towards recent advances in structural optimization and stochastic optimization. Our presentation of black-box optimization, strongly influenced by Nesterov's seminal book and Nemirovski's lecture notes, includes the analysis of cutting plane methods, as well as (accelerated) gradient descent schemes. We also pay special attention to non-Euclidean settings (relevant algorithms include Frank-Wolfe, mirror descent, and dual averaging) and discuss their relevance in machine learning. We provide a gentle introduction to structural optimization with FISTA (to optimize a sum of a smooth and a simple non-smooth term), saddle-point mirror prox (Nemirovski's alternative to Nesterov's smoothing), and a concise description of interior point methods. In stochastic optimization we discuss stochastic gradient descent, mini-batches, random coordinate descent, and sublinear algorithms. We also briefly touch upon convex relaxation of combinatorial problems and the use of randomness to round solutions, as well as random walks based methods.},
  archivePrefix = {arXiv},
  eprint = {1405.4980},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bubeck (2014) - Convex Optimization.pdf},
  journal = {arXiv:1405.4980 [cs, math, stat]},
  keywords = {Computer Science - Computational Complexity,Computer Science - Machine Learning,Computer Science - Numerical Analysis,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{bubeck2018Adversarial,
  title = {Adversarial Examples from Computational Constraints},
  author = {Bubeck, S{\'e}bastien and Price, Eric and Razenshteyn, Ilya},
  year = {2018},
  month = may,
  abstract = {Why are classifiers in high dimension vulnerable to "adversarial" perturbations? We show that it is likely not due to information theoretic limitations, but rather it could be due to computational constraints. First we prove that, for a broad set of classification tasks, the mere existence of a robust classifier implies that it can be found by a possibly exponential-time algorithm with relatively few training examples. Then we give a particular classification task where learning a robust classifier is computationally intractable. More precisely we construct a binary classification task in high dimensional space which is (i) information theoretically easy to learn robustly for large perturbations, (ii) efficiently learnable (non-robustly) by a simple linear separator, (iii) yet is not efficiently robustly learnable, even for small perturbations, by any algorithm in the statistical query (SQ) model. This example gives an exponential separation between classical learning and robust learning in the statistical query model. It suggests that adversarial examples may be an unavoidable byproduct of computational limitations of learning algorithms.},
  archivePrefix = {arXiv},
  eprint = {1805.10204},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bubeck et al (2018) - Adversarial examples from computational constraints.pdf},
  journal = {arXiv:1805.10204 [cs, stat]},
  keywords = {Computer Science - Computational Complexity,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{buesing2018Woulda,
  title = {Woulda, {{Coulda}}, {{Shoulda}}: {{Counterfactually}}-{{Guided Policy Search}}},
  shorttitle = {Woulda, {{Coulda}}, {{Shoulda}}},
  author = {Buesing, Lars and Weber, Theophane and Zwols, Yori and Racaniere, Sebastien and Guez, Arthur and Lespiau, Jean-Baptiste and Heess, Nicolas},
  year = {2018},
  month = nov,
  abstract = {Learning policies on data synthesized by models can in principle quench the thirst of reinforcement learning algorithms for large amounts of real experience, which is often costly to acquire. However, simulating plausible experience de novo is a hard problem for many complex environments, often resulting in biases for model-based policy evaluation and search. Instead of de novo synthesis of data, here we assume logged, real experience and model alternative outcomes of this experience under counterfactual actions, actions that were not actually taken. Based on this, we propose the Counterfactually-Guided Policy Search (CF-GPS) algorithm for learning policies in POMDPs from off-policy experience. It leverages structural causal models for counterfactual evaluation of arbitrary policies on individual off-policy episodes. CF-GPS can improve on vanilla model-based RL algorithms by making use of available logged data to de-bias model predictions. In contrast to off-policy algorithms based on Importance Sampling which re-weight data, CF-GPS leverages a model to explicitly consider alternative outcomes, allowing the algorithm to make better use of experience data. We find empirically that these advantages translate into improved policy evaluation and search results on a non-trivial grid-world task. Finally, we show that CF-GPS generalizes the previously proposed Guided Policy Search and that reparameterization-based algorithms such Stochastic Value Gradient can be interpreted as counterfactual methods.},
  archivePrefix = {arXiv},
  eprint = {1811.06272},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Buesing et al (2018) - Woulda, Coulda, Shoulda.pdf},
  journal = {arXiv:1811.06272 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{buhlmann2018Invariance,
  title = {Invariance, {{Causality}} and {{Robustness}}},
  author = {B{\"u}hlmann, Peter},
  year = {2018},
  month = dec,
  abstract = {We discuss recent work for causal inference and predictive robustness in a unifying way. The key idea relies on a notion of probabilistic invariance or stability: it opens up new insights for formulating causality as a certain risk minimization problem with a corresponding notion of robustness. The invariance itself can be estimated from general heterogeneous or perturbation data which frequently occur with nowadays data collection. The novel methodology is potentially useful in many applications, offering more robustness and better `causal-oriented' interpretation than machine learning or estimation in standard regression or classification frameworks.},
  archivePrefix = {arXiv},
  eprint = {1812.08233},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bühlmann (2018) - Invariance, Causality and Robustness.pdf},
  journal = {arXiv:1812.08233 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{bui2018Partitioned,
  title = {Partitioned {{Variational Inference}}: {{A}} Unified Framework Encompassing Federated and Continual Learning},
  shorttitle = {Partitioned {{Variational Inference}}},
  author = {Bui, Thang D. and Nguyen, Cuong V. and Swaroop, Siddharth and Turner, Richard E.},
  year = {2018},
  month = nov,
  abstract = {Variational inference (VI) has become the method of choice for fitting many modern probabilistic models. However, practitioners are faced with a fragmented literature that offers a bewildering array of algorithmic options. First, the variational family. Second, the granularity of the updates e.g. whether the updates are local to each data point and employ message passing or global. Third, the method of optimization (bespoke or blackbox, closed-form or stochastic updates, etc.). This paper presents a new framework, termed Partitioned Variational Inference (PVI), that explicitly acknowledges these algorithmic dimensions of VI, unifies disparate literature, and provides guidance on usage. Crucially, the proposed PVI framework allows us to identify new ways of performing VI that are ideally suited to challenging learning scenarios including federated learning (where distributed computing is leveraged to process non-centralized data) and continual learning (where new data and tasks arrive over time and must be accommodated quickly). We showcase these new capabilities by developing communication-efficient federated training of Bayesian neural networks and continual learning for Gaussian process models with private pseudo-points. The new methods significantly outperform the state-of-the-art, whilst being almost as straightforward to implement as standard VI.},
  archivePrefix = {arXiv},
  eprint = {1811.11206},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Bui et al (2018) - Partitioned Variational Inference.pdf},
  journal = {arXiv:1811.11206 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{buja2019Models,
  title = {Models as {{Approximations I}}: {{Consequences Illustrated}} with {{Linear Regression}}},
  shorttitle = {Models as {{Approximations I}}},
  author = {Buja, Andreas and Brown, Lawrence and Berk, Richard and George, Edward and Pitkin, Emil and Traskin, Mikhail and Zhang, Kai and Zhao, Linda},
  year = {2019},
  month = nov,
  volume = {34},
  pages = {523--544},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/18-STS693},
  abstract = {In the early 1980s, Halbert White inaugurated a ``model-robust'' form of statistical inference based on the ``sandwich estimator'' of standard error. This estimator is known to be ``heteroskedasticity-consistent,'' but it is less well known to be ``nonlinearity-consistent'' as well. Nonlinearity, however, raises fundamental issues because in its presence regressors are not ancillary, hence cannot be treated as fixed. The consequences are deep: (1) population slopes need to be reinterpreted as statistical functionals obtained from OLS fits to largely arbitrary joint x-yx-y\{x\textbackslash textrm\{-\}y\} distributions; (2) the meaning of slope parameters needs to be rethought; (3) the regressor distribution affects the slope parameters; (4) randomness of the regressors becomes a source of sampling variability in slope estimates of order 1/N--{$\surd$}1/N1/\textbackslash sqrt\{N\}; (5) inference needs to be based on model-robust standard errors, including sandwich estimators or the x-yx-y\{x\textbackslash textrm\{-\}y\} bootstrap. In theory, model-robust and model-trusting standard errors can deviate by arbitrary magnitudes either way. In practice, significant deviations between them can be detected with a diagnostic test.},
  file = {/Users/yuekai/Documents/zotero/Buja et al (2019) - Models as Approximations I.pdf;/Users/yuekai/Zotero/storage/JNSBCZTU/1578474016.html},
  journal = {Statistical Science},
  keywords = {Ancillarity of regressors,bootstrap,econometrics,misspecification,sandwich estimator},
  language = {EN},
  mrnumber = {MR4048582},
  number = {4}
}

@article{buja2019Modelsa,
  title = {Models as {{Approximations II}}: {{A Model}}-{{Free Theory}} of {{Parametric Regression}}},
  shorttitle = {Models as {{Approximations II}}},
  author = {Buja, Andreas and Brown, Lawrence and Kuchibhotla, Arun Kumar and Berk, Richard and George, Edward and Zhao, Linda},
  year = {2019},
  month = nov,
  volume = {34},
  pages = {545--565},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/18-STS694},
  abstract = {We develop a model-free theory of general types of parametric regression for i.i.d. observations. The theory replaces the parameters of parametric models with statistical functionals, to be called ``regression functionals,'' defined on large nonparametric classes of joint x-yx-y\{x\textbackslash textrm\{-\}y\} distributions, without assuming a correct model. Parametric models are reduced to heuristics to suggest plausible objective functions. An example of a regression functional is the vector of slopes of linear equations fitted by OLS to largely arbitrary x-yx-y\{x\textbackslash textrm\{-\}y\} distributions, without assuming a linear model (see Part I). More generally, regression functionals can be defined by minimizing objective functions, solving estimating equations, or with ad hoc constructions. In this framework, it is possible to achieve the following: (1) define a notion of ``well-specification'' for regression functionals that replaces the notion of correct specification of models, (2) propose a well-specification diagnostic for regression functionals based on reweighting distributions and data, (3) decompose sampling variability of regression functionals into two sources, one due to the conditional response distribution and another due to the regressor distribution interacting with misspecification, both of order N-1/2N-1/2N\^\{-1/2\}, (4) exhibit plug-in/sandwich estimators of standard error as limit cases of x-yx-y\{x\textbackslash textrm\{-\}y\} bootstrap estimators, and (5) provide theoretical heuristics to indicate that x-yx-y\{x\textbackslash textrm\{-\}y\} bootstrap standard errors may generally be preferred over sandwich estimators.},
  file = {/Users/yuekai/Documents/zotero/Buja et al (2019) - Models as Approximations II.pdf;/Users/yuekai/Zotero/storage/GCJRNCJJ/1578474017.html},
  journal = {Statistical Science},
  keywords = {Ancillarity of regressors,bagging,bootstrap,econometrics,misspecification,sandwich estimator},
  language = {EN},
  mrnumber = {MR4048583},
  number = {4}
}

@inproceedings{buolamwini2018Gender,
  title = {Gender {{Shades}}: {{Intersectional Accuracy Disparities}} in {{Commercial Gender Classification}}},
  booktitle = {Proceedings of {{Machine Learning Research}}},
  author = {Buolamwini, Joy and Gebru, Timnit},
  year = {2018},
  volume = {87},
  pages = {77--91},
  abstract = {Recent studies demonstrate that machine learning algorithms can discriminate based on classes like race and gender. In this work, we present an approach to evaluate bias present in automated facial analysis algorithms and datasets with respect to phenotypic subgroups. Using the dermatologist approved Fitzpatrick Skin Type classification system, we characterize the gender and skin type distribution of two facial analysis benchmarks, IJB-A and Adience. We find that these datasets are overwhelmingly composed of lighter-skinned subjects (79.6\% for IJB-A and 86.2\% for Adience) and introduce a new facial analysis dataset which is balanced by gender and skin type. We evaluate 3 commercial gender classification systems using our dataset and show that darker-skinned females are the most misclassified group (with error rates of up to 34.7\%). The maximum error rate for lighter-skinned males is 0.8\%. The substantial disparities in the accuracy of classifying darker females, lighter females, darker males, and lighter males in gender classification systems require urgent attention if commercial companies are to build genuinely fair, transparent and accountable facial analysis algorithms.},
  file = {/Users/yuekai/Documents/zotero/Buolamwini, Gebru (2018) - Gender Shades.pdf},
  language = {en}
}

@book{burgisser2013Condition,
  title = {Condition: The Geometry of Numerical Algorithms},
  shorttitle = {Condition},
  author = {Burgisser, Peter},
  year = {2013},
  edition = {1st edition},
  publisher = {{Springer}},
  address = {{New York}},
  file = {/Users/yuekai/Documents/zotero/Burgisser (2013) - Condition.pdf},
  isbn = {978-3-642-38895-8},
  language = {en},
  number = {349},
  series = {Grundlehren Der Mathematischen Wissenschaften}
}

@article{burt2019Rates,
  title = {Rates of {{Convergence}} for {{Sparse Variational Gaussian Process Regression}}},
  author = {Burt, David R. and Rasmussen, Carl E. and {van der Wilk}, Mark},
  year = {2019},
  month = mar,
  abstract = {Excellent variational approximations to Gaussian process posteriors have been developed which avoid the \$\textbackslash mathcal\{O\}\textbackslash left(N\^3\textbackslash right)\$ scaling with dataset size \$N\$. They reduce the computational cost to \$\textbackslash mathcal\{O\}\textbackslash left(NM\^2\textbackslash right)\$, with \$M\textbackslash ll N\$ being the number of inducing variables, which summarise the process. While the computational cost seems to be linear in \$N\$, the true complexity of the algorithm depends on how \$M\$ must increase to ensure a certain quality of approximation. We address this by characterising the behavior of an upper bound on the KL divergence to the posterior. We show that with high probability the KL divergence can be made arbitrarily small by growing \$M\$ more slowly than \$N\$. A particular case of interest is that for regression with normally distributed inputs in D-dimensions with the popular Squared Exponential kernel, \$M=\textbackslash mathcal\{O\}(\textbackslash log\^D N)\$ is sufficient. Our results show that as datasets grow, Gaussian process posteriors can truly be approximated cheaply, and provide a concrete rule for how to increase \$M\$ in continual learning scenarios.},
  archivePrefix = {arXiv},
  eprint = {1903.03571},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Burt et al (2019) - Rates of Convergence for Sparse Variational Gaussian Process Regression.pdf},
  journal = {arXiv:1903.03571 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{bussell2019Applying,
  title = {Applying Optimal Control Theory to Complex Epidemiological Models to Inform Real-World Disease Management},
  author = {Bussell, E. H. and Dangerfield, C. E. and Gilligan, C. A. and Cunniffe, N. J.},
  year = {2019},
  month = jul,
  volume = {374},
  pages = {20180284},
  publisher = {{Royal Society}},
  doi = {10.1098/rstb.2018.0284},
  abstract = {Mathematical models provide a rational basis to inform how, where and when to control disease. Assuming an accurate spatially explicit simulation model can be fitted to spread data, it is straightforward to use it to test the performance of a range of management strategies. However, the typical complexity of simulation models and the vast set of possible controls mean that only a small subset of all possible strategies can ever be tested. An alternative approach\textemdash optimal control theory\textemdash allows the best control to be identified unambiguously. However, the complexity of the underpinning mathematics means that disease models used to identify this optimum must be very simple. We highlight two frameworks for bridging the gap between detailed epidemic simulations and optimal control theory: open-loop and model predictive control. Both these frameworks approximate a simulation model with a simpler model more amenable to mathematical analysis. Using an illustrative example model, we show the benefits of using feedback control, in which the approximation and control are updated as the epidemic progresses. Our work illustrates a new methodology to allow the insights of optimal control theory to inform practical disease management strategies, with the potential for application to diseases of humans, animals and plants.This article is part of the theme issue `Modelling infectious disease outbreaks in humans, animals and plants: epidemic forecasting and control'. This theme issue is linked with the earlier issue `Modelling infectious disease outbreaks in humans, animals and plants: approaches and important themes'.},
  file = {/Users/yuekai/Documents/zotero/Bussell et al (2019) - Applying optimal control theory to complex epidemiological models to inform.pdf},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  number = {1776}
}

@article{cai2015Structured,
  title = {Structured {{Matrix Completion}} with {{Applications}} to {{Genomic Data Integration}}},
  author = {Cai, Tianxi and Cai, T. Tony and Zhang, Anru},
  year = {2015},
  month = apr,
  abstract = {Matrix completion has attracted significant recent attention in many fields including statistics, applied mathematics and electrical engineering. Current literature on matrix completion focuses primarily on independent sampling models under which the individual observed entries are sampled independently. Motivated by applications in genomic data integration, we propose a new framework of structured matrix completion (SMC) to treat structured missingness by design. Specifically, our proposed method aims at efficient matrix recovery when a subset of the rows and columns of an approximately low-rank matrix are observed. We provide theoretical justification for the proposed SMC method and derive lower bound for the estimation errors, which together establish the optimal rate of recovery over certain classes of approximately low-rank matrices. Simulation studies show that the method performs well in finite sample under a variety of configurations. The method is applied to integrate several ovarian cancer genomic studies with different extent of genomic measurements, which enables us to construct more accurate prediction rules for ovarian cancer survival.},
  archivePrefix = {arXiv},
  eprint = {1504.01823},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cai et al (2015) - Structured Matrix Completion with Applications to Genomic Data Integration.pdf},
  journal = {arXiv:1504.01823 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{cai2019Differential,
  title = {Differential {{Markov}} Random Field Analysis with an Application to Detecting Differential Microbial Community Networks},
  author = {Cai, T T and Li, H and Ma, J and Xia, Y},
  year = {2019},
  month = apr,
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/asz012},
  file = {/Users/yuekai/Documents/zotero/Cai et al (2019) - Differential Markov random field analysis with an application to detecting.pdf},
  journal = {Biometrika},
  language = {en}
}

@article{cai2019Individualized,
  title = {Individualized {{Group Learning}}},
  author = {Cai, Chencheng and Chen, Rong and Xie, Min-ge},
  year = {2019},
  month = jun,
  abstract = {Many massive data are assembled through collections of information of a large number of individuals in a population. The analysis of such data, especially in the aspect of individualized inferences and solutions, has the potential to create significant value for practical applications. Traditionally, inference for an individual in the data set is either solely relying on the information of the individual or from summarizing the information about the whole population. However, with the availability of big data, we have the opportunity, as well as a unique challenge, to make a more effective individualized inference that takes into consideration of both the population information and the individual discrepancy. To deal with the possible heterogeneity within the population while providing effective and credible inferences for individuals in a data set, this article develops a new approach called the individualized group learning (iGroup). The iGroup approach uses local nonparametric techniques to generate an individualized group by pooling other entities in the population which share similar characteristics with the target individual, even when individual estimates are biased due to limited number of observations. Three general cases of iGroup are discussed, and their asymptotic performances are investigated. Both theoretical results and empirical simulations reveal that, by applying iGroup, the performance of statistical inference on the individual level are ensured and can be substantially improved from inference based on either solely individual information or entire population information. The method has a broad range of applications. Two examples in financial statistics and maritime anomaly detection are presented.},
  archivePrefix = {arXiv},
  eprint = {1906.05533},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cai et al (2019) - Individualized Group Learning.pdf},
  journal = {arXiv:1906.05533 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{cai2019Neural,
  title = {Neural {{Temporal}}-{{Difference Learning Converges}} to {{Global Optima}}},
  author = {Cai, Qi and Yang, Zhuoran and Lee, Jason D. and Wang, Zhaoran},
  year = {2019},
  month = may,
  abstract = {Temporal-difference learning (TD), coupled with neural networks, is among the most fundamental building blocks of deep reinforcement learning. However, due to the nonlinearity in value function approximation, such a coupling leads to nonconvexity and even divergence in optimization. As a result, the global convergence of neural TD remains unclear. In this paper, we prove for the first time that neural TD converges at a sublinear rate to the global optimum of the mean-squared projected Bellman error for policy evaluation. In particular, we show how such global convergence is enabled by the overparametrization of neural networks, which also plays a vital role in the empirical success of neural TD. Beyond policy evaluation, we establish the global convergence of neural (soft) Q-learning, which is further connected to that of policy gradient algorithms.},
  archivePrefix = {arXiv},
  eprint = {1905.10027},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cai et al (2019) - Neural Temporal-Difference Learning Converges to Global Optima.pdf},
  journal = {arXiv:1905.10027 [cs, math, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{cai2019Privacy,
  title = {Privacy {{Preserving Integrative Regression Analysis}} of {{High}}-Dimensional {{Heterogeneous Data}}},
  author = {Cai, Tianxi and Liu, Molei and Xia, Yin},
  year = {2019},
  month = feb,
  abstract = {Meta-analyzing multiple studies, enabling more precise estimation and investigation of generalizability, is important for evidence based decision making. Integrative analysis of multiple heterogeneous studies is, however, highly challenging in the high dimensional setting. The challenge is even more pronounced when the individual level data cannot be shared across studies due to privacy concerns. Under ultra high dimensional sparse regression models, we propose in this paper a novel integrative estimation procedure by aggregating and debiasing local estimators (ADeLE), which allows us to base solely on the derived data to perform estimation with general loss functions. The ADeLE procedure accommodates between study heterogeneity in both the covariate distribution and model parameters, and attains consistent variable selection. Furthermore, the prediction and estimation errors incurred by aggregating derived data is negligible compared to the statistical minimax rate. In addition, the ADeLE estimator is shown to be asymptotically equivalent in prediction and estimation to the ideal estimator obtained by sharing all data. The finite-sample performance of the ADeLE procedure is studied via extensive simulations. We further illustrate the utility of the ADeLE procedure to derive phenotyping algorithms for coronary artery disease using electronic health records data from multiple disease cohorts.},
  archivePrefix = {arXiv},
  eprint = {1902.06115},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cai et al (2019) - Privacy Preserving Integrative Regression Analysis of High-dimensional.pdf},
  journal = {arXiv:1902.06115 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{cai2019Transfer,
  title = {Transfer {{Learning}} for {{Nonparametric Classification}}: {{Minimax Rate}} and {{Adaptive Classifier}}},
  shorttitle = {Transfer {{Learning}} for {{Nonparametric Classification}}},
  author = {Cai, T. Tony and Wei, Hongji},
  year = {2019},
  month = jun,
  abstract = {Human learners have the natural ability to use knowledge gained in one setting for learning in a different but related setting. This ability to transfer knowledge from one task to another is essential for effective learning. In this paper, we study transfer learning in the context of nonparametric classification based on observations from different distributions under the posterior drift model, which is a general framework and arises in many practical problems. We first establish the minimax rate of convergence and construct a rate-optimal two-sample weighted \$K\$-NN classifier. The results characterize precisely the contribution of the observations from the source distribution to the classification task under the target distribution. A data-driven adaptive classifier is then proposed and is shown to simultaneously attain within a logarithmic factor of the optimal rate over a large collection of parameter spaces. Simulation studies and real data applications are carried out where the numerical results further illustrate the theoretical analysis. Extensions to the case of multiple source distributions are also considered.},
  archivePrefix = {arXiv},
  eprint = {1906.02903},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cai, Wei (2019) - Transfer Learning for Nonparametric Classification.pdf},
  journal = {arXiv:1906.02903 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {cs, math, stat}
}

@article{cai2020Distributed,
  title = {Distributed {{Gaussian Mean Estimation}} under {{Communication Constraints}}: {{Optimal Rates}} and {{Communication}}-{{Efficient Algorithms}}},
  shorttitle = {Distributed {{Gaussian Mean Estimation}} under {{Communication Constraints}}},
  author = {Cai, T. Tony and Wei, Hongji},
  year = {2020},
  month = jan,
  abstract = {We study distributed estimation of a Gaussian mean under communication constraints in a decision theoretical framework. Minimax rates of convergence, which characterize the tradeoff between the communication costs and statistical accuracy, are established in both the univariate and multivariate settings. Communication-efficient and statistically optimal procedures are developed. In the univariate case, the optimal rate depends only on the total communication budget, so long as each local machine has at least one bit. However, in the multivariate case, the minimax rate depends on the specific allocations of the communication budgets among the local machines. Although optimal estimation of a Gaussian mean is relatively simple in the conventional setting, it is quite involved under the communication constraints, both in terms of the optimal procedure design and lower bound argument. The techniques developed in this paper can be of independent interest. An essential step is the decomposition of the minimax estimation problem into two stages, localization and refinement. This critical decomposition provides a framework for both the lower bound analysis and optimal procedure design.},
  archivePrefix = {arXiv},
  eprint = {2001.08877},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cai, Wei (2020) - Distributed Gaussian Mean Estimation under Communication Constraints.pdf},
  journal = {arXiv:2001.08877 [cs, math, stat]},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Information Theory,Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{calafiore2006Distributionally,
  title = {On {{Distributionally Robust Chance}}-{{Constrained Linear Programs}}},
  author = {Calafiore, G. C. and Ghaoui, L. El},
  year = {2006},
  month = jul,
  volume = {130},
  pages = {1--22},
  issn = {1573-2878},
  doi = {10.1007/s10957-006-9084-x},
  abstract = {In this paper, we discuss linear programs in which the data that specify the constraints are subject to random uncertainty. A usual approach in this setting is to enforce the constraints up to a given level of probability. We show that, for a wide class of probability distributions (namely, radial distributions) on the data, the probability constraints can be converted explicitly into convex second-order cone constraints; hence, the probability-constrained linear program can be solved exactly with great efficiency. Next, we analyze the situation where the probability distribution of the data is not completely specified, but is only known to belong to a given class of distributions. In this case, we provide explicit convex conditions that guarantee the satisfaction of the probability constraints for any possible distribution belonging to the given class.},
  file = {/Users/yuekai/Documents/zotero/Calafiore, Ghaoui (2006) - On Distributionally Robust Chance-Constrained Linear Programs.pdf},
  journal = {Journal of Optimization Theory and Applications},
  language = {en},
  number = {1}
}

@article{caldermuffy2018Computational,
  title = {Computational Modelling for Decision-Making: Where, Why, What, Who and How},
  shorttitle = {Computational Modelling for Decision-Making},
  author = {{Calder Muffy} and {Craig Claire} and {Culley Dave} and {de Cani Richard} and {Donnelly Christl A.} and {Douglas Rowan} and {Edmonds Bruce} and {Gascoigne Jonathon} and {Gilbert Nigel} and {Hargrove Caroline} and {Hinds Derwen} and {Lane David C.} and {Mitchell Dervilla} and {Pavey Giles} and {Robertson David} and {Rosewell Bridget} and {Sherwin Spencer} and {Walport Mark} and {Wilson Alan}},
  year = {2018},
  month = jun,
  volume = {5},
  pages = {172096},
  doi = {10.1098/rsos.172096},
  abstract = {In order to deal with an increasingly complex world, we need ever more sophisticated computational models that can help us make decisions wisely and understand the potential consequences of choices. But creating a model requires far more than just raw data and technical skills: it requires a close collaboration between model commissioners, developers, users and reviewers. Good modelling requires its users and commissioners to understand more about the whole process, including the different kinds of purpose a model can have and the different technical bases. This paper offers a guide to the process of commissioning, developing and deploying models across a wide range of domains from public policy to science and engineering. It provides two checklists to help potential modellers, commissioners and users ensure they have considered the most significant factors that will determine success. We conclude there is a need to reinforce modelling as a discipline, so that misconstruction is less likely; to increase understanding of modelling in all domains, so that the misuse of models is reduced; and to bring commissioners closer to modelling, so that the results are more useful.},
  file = {/Users/yuekai/Documents/zotero/Calder Muffy et al (2018) - Computational modelling for decision-making.pdf},
  journal = {Royal Society Open Science},
  number = {6}
}

@inproceedings{calders2009Building,
  title = {Building {{Classifiers}} with {{Independency Constraints}}},
  booktitle = {2009 {{IEEE International Conference}} on {{Data Mining Workshops}}},
  author = {Calders, T. and Kamiran, F. and Pechenizkiy, M.},
  year = {2009},
  month = dec,
  pages = {13--18},
  doi = {10.1109/ICDMW.2009.83},
  abstract = {In this paper we study the problem of classifier learning where the input data contains unjustified dependencies between some data attributes and the class label. Such cases arise for example when the training data is collected from different sources with different labeling criteria or when the data is generated by a biased decision process. When a classifier is trained directly on such data, these undesirable dependencies will carry over to the classifier's predictions. In order to tackle this problem, we study the classification with independency constraints problem: find an accurate model for which the predictions are independent from a given binary attribute. We propose two solutions for this problem and present an empirical validation.},
  file = {/Users/yuekai/Zotero/storage/2N2UGCML/5360534.html}
}

@article{caliskan2017Semantics,
  title = {Semantics Derived Automatically from Language Corpora Contain Human-like Biases},
  author = {Caliskan, Aylin and Bryson, Joanna J. and Narayanan, Arvind},
  year = {2017},
  month = apr,
  volume = {356},
  pages = {183--186},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aal4230},
  file = {/Users/yuekai/Documents/zotero/Caliskan et al (2017) - Semantics derived automatically from language corpora contain human-like biases.pdf},
  journal = {Science},
  language = {en},
  number = {6334}
}

@article{calver2017Numerical,
  title = {Numerical Methods for Computing Sensitivities for {{ODEs}} and {{DDEs}}},
  author = {Calver, Jonathan and Enright, Wayne},
  year = {2017},
  month = apr,
  volume = {74},
  pages = {1101--1117},
  issn = {1572-9265},
  doi = {10.1007/s11075-016-0188-6},
  abstract = {We investigate the performance of the adjoint approach and the variational approach for computing the sensitivities of the least squares objective function commonly used when fitting models to observations. We note that the discrete nature of the objective function makes the cost of the adjoint approach for computing the sensitivities dependent on the number of observations. In the case of ordinary differential equations (ODEs), this dependence is due to having to interrupt the computation at each observation point during numerical solution of the adjoint equations. Each observation introduces a jump discontinuity in the solution of the adjoint differential equations. These discontinuities are propagated in the case of delay differential equations (DDEs), making the performance of the adjoint approach even more sensitive to the number of observations for DDEs. We quantify this cost and suggest ways to make the adjoint approach scale better with the number of observations. In numerical experiments, we compare the adjoint approach with the variational approach for computing the sensitivities.},
  file = {/Users/yuekai/Documents/zotero/Calver, Enright (2017) - Numerical methods for computing sensitivities for ODEs and DDEs.pdf},
  journal = {Numerical Algorithms},
  language = {en},
  number = {4}
}

@article{campbell2013Dynamic,
  title = {Dynamic {{Clustering}} via {{Asymptotics}} of the {{Dependent Dirichlet Process Mixture}}},
  author = {Campbell, Trevor and Liu, Miao and Kulis, Brian and How, Jonathan P. and Carin, Lawrence},
  year = {2013},
  month = may,
  abstract = {This paper presents a novel algorithm, based upon the dependent Dirichlet process mixture model (DDPMM), for clustering batch-sequential data containing an unknown number of evolving clusters. The algorithm is derived via a low-variance asymptotic analysis of the Gibbs sampling algorithm for the DDPMM, and provides a hard clustering with convergence guarantees similar to those of the k-means algorithm. Empirical results from a synthetic test with moving Gaussian clusters and a test with real ADS-B aircraft trajectory data demonstrate that the algorithm requires orders of magnitude less computational time than contemporary probabilistic and hard clustering algorithms, while providing higher accuracy on the examined datasets.},
  archivePrefix = {arXiv},
  eprint = {1305.6659},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Campbell et al (2013) - Dynamic Clustering via Asymptotics of the Dependent Dirichlet Process Mixture.pdf},
  journal = {arXiv:1305.6659 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{candes2008Exact,
  title = {Exact {{Matrix Completion}} via {{Convex Optimization}}},
  author = {Candes, Emmanuel J. and Recht, Benjamin},
  year = {2008},
  month = may,
  abstract = {We consider a problem of considerable practical interest: the recovery of a data matrix from a sampling of its entries. Suppose that we observe m entries selected uniformly at random from a matrix M. Can we complete the matrix and recover the entries that we have not seen? We show that one can perfectly recover most low-rank matrices from what appears to be an incomplete set of entries. We prove that if the number m of sampled entries obeys m {$>$}= C n\^\{1.2\} r log n for some positive numerical constant C, then with very high probability, most n by n matrices of rank r can be perfectly recovered by solving a simple convex optimization program. This program finds the matrix with minimum nuclear norm that fits the data. The condition above assumes that the rank is not too large. However, if one replaces the 1.2 exponent with 1.25, then the result holds for all values of the rank. Similar results hold for arbitrary rectangular matrices as well. Our results are connected with the recent literature on compressed sensing, and show that objects other than signals and images can be perfectly reconstructed from very limited information.},
  archivePrefix = {arXiv},
  eprint = {0805.4471},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Candes, Recht (2008) - Exact Matrix Completion via Convex Optimization.pdf},
  journal = {arXiv:0805.4471 [cs, math]},
  keywords = {Computer Science - Information Theory},
  primaryClass = {cs, math}
}

@article{canzoneri2007Euler,
  title = {Euler Equations and Money Market Interest Rates: {{A}} Challenge for Monetary Policy Models},
  shorttitle = {Euler Equations and Money Market Interest Rates},
  author = {Canzoneri, Matthew B. and Cumby, Robert E. and Diba, Behzad T.},
  year = {2007},
  month = oct,
  volume = {54},
  pages = {1863--1881},
  issn = {03043932},
  doi = {10.1016/j.jmoneco.2006.09.001},
  abstract = {Standard macroeconomic models equate the money market rate targeted by the central bank with the interest rate implied by a consumption Euler equation. We use U.S. data to calculate the interest rates implied by Euler equations derived from a number of specifications of household preferences. Correlations between these Euler equation rates and the Federal Funds rate are generally negative. Regression results and impulse response functions imply that the spreads between the Euler equation rates and the Federal Funds rate are systematically linked to the stance of monetary policy. Our findings pose a fundamental challenge for models that equate the two.},
  file = {/Users/yuekai/Documents/zotero/Canzoneri et al (2007) - Euler equations and money market interest rates.pdf},
  journal = {Journal of Monetary Economics},
  language = {en},
  number = {7}
}

@article{cao2003Adjoint,
  title = {Adjoint {{Sensitivity Analysis}} for {{Differential}}-{{Algebraic Equations}}: {{The Adjoint DAE System}} and {{Its Numerical Solution}}},
  shorttitle = {Adjoint {{Sensitivity Analysis}} for {{Differential}}-{{Algebraic Equations}}},
  author = {Cao, Yang and Li, Shengtai and Petzold, Linda and Serban, Radu},
  year = {2003},
  month = jan,
  volume = {24},
  pages = {1076--1089},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/S1064827501380630},
  abstract = {An adjoint sensitivity method is presented for parameter-dependent differentialalgebraic equation systems (DAEs). The adjoint system is derived, along with conditions for its consistent initialization, for DAEs of index up to two (Hessenberg). For stable linear DAEs, stability of the adjoint system (for semi-explicit DAEs) or of an augmented adjoint system (for fully implicit DAEs) is shown. In addition, it is shown for these systems that numerical stability is maintained for the adjoint system or for the augmented adjoint system.},
  file = {/Users/yuekai/Documents/zotero/Cao et al (2003) - Adjoint Sensitivity Analysis for Differential-Algebraic Equations.pdf},
  journal = {SIAM Journal on Scientific Computing},
  language = {en},
  number = {3}
}

@article{cao2019Generalization,
  title = {Generalization {{Bounds}} of {{Stochastic Gradient Descent}} for {{Wide}} and {{Deep Neural Networks}}},
  author = {Cao, Yuan and Gu, Quanquan},
  year = {2019},
  month = may,
  abstract = {We study the training and generalization of deep neural networks (DNNs) in the over-parameterized regime, where the network width (i.e., number of hidden nodes per layer) is much larger than the number of training data points. We show that, the expected \$0\$-\$1\$ loss of a wide enough ReLU network trained with stochastic gradient descent (SGD) and random initialization can be bounded by the training loss of a random feature model induced by the network gradient at initialization, which we call a neural tangent random feature (NTRF) model. For data distributions that can be classified by NTRF model with sufficiently small error, our result yields a generalization error bound in the order of \$\textbackslash tilde\{\textbackslash mathcal\{O\}\}(n\^\{-1/2\})\$ that is independent of the network width. Our result is more general and sharper than many existing generalization error bounds for over-parameterized neural networks. In addition, we establish a strong connection between our generalization error bound and the neural tangent kernel (NTK) proposed in recent work.},
  archivePrefix = {arXiv},
  eprint = {1905.13210},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cao, Gu (2019) - Generalization Bounds of Stochastic Gradient Descent for Wide and Deep Neural.pdf},
  journal = {arXiv:1905.13210 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{cape2017twotoinfinity,
  title = {The Two-to-Infinity Norm and Singular Subspace Geometry with Applications to High-Dimensional Statistics},
  author = {Cape, Joshua and Tang, Minh and Priebe, Carey E.},
  year = {2017},
  month = may,
  abstract = {The singular value matrix decomposition plays a ubiquitous role throughout statistics and related fields. Myriad applications including clustering, classification, and dimensionality reduction involve studying and exploiting the geometric structure of singular values and singular vectors. This paper provides a novel collection of technical and theoretical tools for studying the geometry of singular subspaces using the two-to-infinity norm. Motivated by preliminary deterministic Procrustes analysis, we consider a general matrix perturbation setting in which we derive a new Procrustean matrix decomposition. Together with flexible machinery developed for the two-to-infinity norm, this allows us to conduct a refined analysis of the induced perturbation geometry with respect to the underlying singular vectors even in the presence of singular value multiplicity. Our analysis yields singular vector entrywise perturbation bounds for a range of popular matrix noise models, each of which has a meaningful associated statistical inference task. In addition, we demonstrate how the two-to-infinity norm is the preferred norm in certain statistical settings. Specific applications discussed in this paper include covariance estimation, singular subspace recovery, and multiple graph inference. Both our Procrustean matrix decomposition and the technical machinery developed for the two-to-infinity norm may be of independent interest.},
  archivePrefix = {arXiv},
  eprint = {1705.10735},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cape et al (2017) - The two-to-infinity norm and singular subspace geometry with applications to.pdf},
  journal = {arXiv:1705.10735 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{cape2018Signalplusnoise,
  title = {Signal-plus-Noise Matrix Models: Eigenvector Deviations and Fluctuations},
  shorttitle = {Signal-plus-Noise Matrix Models},
  author = {Cape, Joshua and Tang, Minh and Priebe, Carey E.},
  year = {2018},
  month = feb,
  abstract = {Estimating eigenvectors and low-dimensional subspaces is of central importance for numerous problems in statistics, computer science, and applied mathematics. This paper characterizes the behavior of perturbed eigenvectors for a range of signal-plus-noise matrix models encountered in both statistical and random matrix theoretic settings. We prove both first-order approximation results (i.e. sharp deviations) as well as second-order distributional limit theory (i.e. fluctuations). The concise methodology considered in this paper synthesizes tools rooted in two core concepts, namely (i) deterministic decompositions of matrix perturbations and (ii) probabilistic matrix concentration phenomena. We illustrate our theoretical results via simulation examples involving stochastic block model random graphs.},
  archivePrefix = {arXiv},
  eprint = {1802.00381},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cape et al (2018) - Signal-plus-noise matrix models.pdf},
  journal = {arXiv:1802.00381 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{carcamo2018Strong,
  title = {Strong Duality and {{KKT}} Conditions in Nonconvex Optimization with a Single Equality Constraint and Geometric Constraint},
  author = {C{\'a}rcamo, Gabriel and {Flores-Baz{\'a}n}, Fabi{\'a}n},
  year = {2018},
  month = mar,
  volume = {168},
  pages = {369--400},
  issn = {1436-4646},
  doi = {10.1007/s10107-016-1078-3},
  abstract = {Some topological and geometric characterizations of strong duality for a non convex optimization problem under a single equality and geometric constraints are established. In particular, a hidden convexity of the conic hull of joint-range of the pair of functions associated to the original problem, is obtained. Applications to derive (a characterization of the validity of) KKT conditions without standard constraints qualification, are also discussed. It goes beyond the exact penalization technique. Several examples showing our results provide much more information than those appearing elsewhere, are given. Finally, the standard quadratic problem involving a non necessarily polyhedral cone is analyzed in detail.},
  file = {/Users/yuekai/Documents/zotero/Cárcamo, Flores-Bazán (2018) - Strong duality and KKT conditions in nonconvex optimization with a single.pdf},
  journal = {Mathematical Programming},
  language = {en},
  number = {1}
}

@article{carleo2017Solving,
  title = {Solving the Quantum Many-Body Problem with Artificial Neural Networks},
  author = {Carleo, Giuseppe and Troyer, Matthias},
  year = {2017},
  month = feb,
  volume = {355},
  pages = {602--606},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aag2302},
  abstract = {Machine learning and quantum physics
Elucidating the behavior of quantum interacting systems of many particles remains one of the biggest challenges in physics. Traditional numerical methods often work well, but some of the most interesting problems leave them stumped. Carleo and Troyer harnessed the power of machine learning to develop a variational approach to the quantum many-body problem (see the Perspective by Hush). The method performed at least as well as state-of-the-art approaches, setting a benchmark for a prototypical two-dimensional problem. With further development, it may well prove a valuable piece in the quantum toolbox.
Science, this issue p. 602; see also p. 580
The challenge posed by the many-body problem in quantum physics originates from the difficulty of describing the nontrivial correlations encoded in the exponential complexity of the many-body wave function. Here we demonstrate that systematic machine learning of the wave function can reduce this complexity to a tractable computational form for some notable cases of physical interest. We introduce a variational representation of quantum states based on artificial neural networks with a variable number of hidden neurons. A reinforcement-learning scheme we demonstrate is capable of both finding the ground state and describing the unitary time evolution of complex interacting quantum systems. Our approach achieves high accuracy in describing prototypical interacting spins models in one and two dimensions.
A machine-learning approach sets a computational benchmark for a prototypical two-dimensional problem.
A machine-learning approach sets a computational benchmark for a prototypical two-dimensional problem.},
  chapter = {Research Articles},
  copyright = {Copyright \textcopyright{} 2017, American Association for the Advancement of Science},
  file = {/Users/yuekai/Documents/zotero/Carleo, Troyer (2017) - Solving the quantum many-body problem with artificial neural networks.pdf},
  journal = {Science},
  language = {en},
  number = {6325},
  pmid = {28183973}
}

@article{carlier2010Matching,
  title = {Matching for Teams},
  author = {Carlier, G. and Ekeland, I.},
  year = {2010},
  month = feb,
  volume = {42},
  pages = {397--418},
  issn = {1432-0479},
  doi = {10.1007/s00199-008-0415-z},
  abstract = {We are given a list of tasks Z and a population divided into several groups Xjof equal size. Performing one task z requires constituting a team with exactly one member xjfrom every group. There is a cost (or reward) for participation: if type xjchooses task z, he receives pj(z); utilities are quasi-linear. One seeks an equilibrium price, that is, a price system that distributes all the agents into distinct teams. We prove existence of equilibria and fully characterize them as solutions to some convex optimization problems. The main mathematical tools are convex duality and mass transportation theory. Uniqueness and purity of equilibria are discussed. We will also give an alternative linear-programming formulation as in the recent work of Chiappori et al. (Econ Theory, to appear).},
  file = {/Users/yuekai/Documents/zotero/Carlier, Ekeland (2010) - Matching for teams.pdf},
  journal = {Economic Theory},
  language = {en},
  number = {2}
}

@article{carlier2014Vector,
  title = {Vector {{Quantile Regression}}: {{An Optimal Transport Approach}}},
  shorttitle = {Vector {{Quantile Regression}}},
  author = {Carlier, Guillaume and Chernozhukov, Victor and Galichon, Alfred},
  year = {2014},
  month = jun,
  abstract = {We propose a notion of conditional vector quantile function and a vector quantile regression. A \textbackslash emph\{conditional vector quantile function\} (CVQF) of a random vector \$Y\$, taking values in \$\textbackslash mathbb\{R\}\^d\$ given covariates \$Z=z\$, taking values in \$\textbackslash mathbb\{R\}\% \^k\$, is a map \$u \textbackslash longmapsto Q\_\{Y\textbackslash mid Z\}(u,z)\$, which is monotone, in the sense of being a gradient of a convex function, and such that given that vector \$U\$ follows a reference non-atomic distribution \$F\_U\$, for instance uniform distribution on a unit cube in \$\textbackslash mathbb\{R\}\^d\$, the random vector \$Q\_\{Y\textbackslash mid Z\}(U,z)\$ has the distribution of \$Y\$ conditional on \$Z=z\$. Moreover, we have a strong representation, \$Y = Q\_\{Y\textbackslash mid Z\}(U,Z)\$ almost surely, for some version of \$U\$. The \textbackslash emph\{vector quantile regression\} (VQR) is a linear model for CVQF of \$Y\$ given \$Z\$. Under correct specification, the notion produces strong representation, \$Y=\textbackslash beta \textbackslash left(U\textbackslash right) \^\textbackslash top f(Z)\$, for \$f(Z)\$ denoting a known set of transformations of \$Z\$, where \$u \textbackslash longmapsto \textbackslash beta(u)\^\textbackslash top f(Z)\$ is a monotone map, the gradient of a convex function, and the quantile regression coefficients \$u \textbackslash longmapsto \textbackslash beta(u)\$ have the interpretations analogous to that of the standard scalar quantile regression. As \$f(Z)\$ becomes a richer class of transformations of \$Z\$, the model becomes nonparametric, as in series modelling. A key property of VQR is the embedding of the classical Monge-Kantorovich's optimal transportation problem at its core as a special case. In the classical case, where \$Y\$ is scalar, VQR reduces to a version of the classical QR, and CVQF reduces to the scalar conditional quantile function. An application to multiple Engel curve estimation is considered.},
  archivePrefix = {arXiv},
  eprint = {1406.4643},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Carlier et al (2014) - Vector Quantile Regression.pdf},
  journal = {arXiv:1406.4643 [stat]},
  keywords = {Statistics - Methodology},
  language = {en},
  primaryClass = {stat}
}

@article{carlini2016Evaluating,
  title = {Towards {{Evaluating}} the {{Robustness}} of {{Neural Networks}}},
  author = {Carlini, Nicholas and Wagner, David},
  year = {2016},
  month = aug,
  abstract = {Neural networks provide state-of-the-art results for most machine learning tasks. Unfortunately, neural networks are vulnerable to adversarial examples: given an input \$x\$ and any target classification \$t\$, it is possible to find a new input \$x'\$ that is similar to \$x\$ but classified as \$t\$. This makes it difficult to apply neural networks in security-critical areas. Defensive distillation is a recently proposed approach that can take an arbitrary neural network, and increase its robustness, reducing the success rate of current attacks' ability to find adversarial examples from \$95\textbackslash\%\$ to \$0.5\textbackslash\%\$. In this paper, we demonstrate that defensive distillation does not significantly increase the robustness of neural networks by introducing three new attack algorithms that are successful on both distilled and undistilled neural networks with \$100\textbackslash\%\$ probability. Our attacks are tailored to three distance metrics used previously in the literature, and when compared to previous adversarial example generation algorithms, our attacks are often much more effective (and never worse). Furthermore, we propose using high-confidence adversarial examples in a simple transferability test we show can also be used to break defensive distillation. We hope our attacks will be used as a benchmark in future defense attempts to create neural networks that resist adversarial examples.},
  archivePrefix = {arXiv},
  eprint = {1608.04644},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Carlini, Wagner (2016) - Towards Evaluating the Robustness of Neural Networks.pdf},
  journal = {arXiv:1608.04644 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Cryptography and Security},
  primaryClass = {cs}
}

@article{carlini2019Evaluating,
  title = {On {{Evaluating Adversarial Robustness}}},
  author = {Carlini, Nicholas and Athalye, Anish and Papernot, Nicolas and Brendel, Wieland and Rauber, Jonas and Tsipras, Dimitris and Goodfellow, Ian and Madry, Aleksander and Kurakin, Alexey},
  year = {2019},
  month = feb,
  abstract = {Correctly evaluating defenses against adversarial examples has proven to be extremely difficult. Despite the significant amount of recent work attempting to design defenses that withstand adaptive attacks, few have succeeded; most papers that propose defenses are quickly shown to be incorrect. We believe a large contributing factor is the difficulty of performing security evaluations. In this paper, we discuss the methodological foundations, review commonly accepted best practices, and suggest new methods for evaluating defenses to adversarial examples. We hope that both researchers developing defenses as well as readers and reviewers who wish to understand the completeness of an evaluation consider our advice in order to avoid common pitfalls.},
  archivePrefix = {arXiv},
  eprint = {1902.06705},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Carlini et al (2019) - On Evaluating Adversarial Robustness.pdf},
  journal = {arXiv:1902.06705 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{carmon2019Unlabeled,
  title = {Unlabeled {{Data Improves Adversarial Robustness}}},
  author = {Carmon, Yair and Raghunathan, Aditi and Schmidt, Ludwig and Liang, Percy and Duchi, John C.},
  year = {2019},
  month = may,
  abstract = {We demonstrate, theoretically and empirically, that adversarial robustness can significantly benefit from semisupervised learning. Theoretically, we revisit the simple Gaussian model of Schmidt et al. that shows a sample complexity gap between standard and robust classification. We prove that this gap does not pertain to labels: a simple semisupervised learning procedure (self-training) achieves robust accuracy using the same number of labels required for standard accuracy. Empirically, we augment CIFAR-10 with 500K unlabeled images sourced from 80 Million Tiny Images and use robust self-training to outperform state-of-the-art robust accuracies by over 5 points in (i) \$\textbackslash ell\_\textbackslash infty\$ robustness against several strong attacks via adversarial training and (ii) certified \$\textbackslash ell\_2\$ and \$\textbackslash ell\_\textbackslash infty\$ robustness via randomized smoothing. On SVHN, adding the dataset's own extra training set with the labels removed provides gains of 4 to 10 points, within 1 point of the gain from using the extra labels as well.},
  archivePrefix = {arXiv},
  eprint = {1905.13736},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Carmon et al (2019) - Unlabeled Data Improves Adversarial Robustness.pdf},
  journal = {arXiv:1905.13736 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{caron2014Sparse,
  title = {Sparse Graphs Using Exchangeable Random Measures},
  author = {Caron, Fran{\c c}ois and Fox, Emily B.},
  year = {2014},
  month = jan,
  file = {/Users/yuekai/Documents/zotero/Caron, Fox (2014) - Sparse graphs using exchangeable random measures.pdf},
  language = {en}
}

@article{castillo2019Fairness,
  title = {Fairness and {{Transparency}} in {{Ranking}}},
  author = {Castillo, Carlos},
  year = {2019},
  month = jan,
  volume = {52},
  pages = {64--71},
  issn = {0163-5840},
  doi = {10.1145/3308774.3308783},
  abstract = {Ranking in Information Retrieval (IR) has been traditionally evaluated from the perspective of the relevance of search engine results to people searching for information, i.e., the extent to which the system provides "the right information, to the right people, in the right way, at the right time." However, people in current IR systems are not only the ones issuing search queries, but increasingly they are also the ones being searched. This raises several new problems in IR that have been addressed in recent research, particularly with respect to fairness/non-discrimination, accountability, and transparency. This is a summary of some these initial developments.},
  file = {/Users/yuekai/Documents/zotero/Castillo (2019) - Fairness and Transparency in Ranking.pdf},
  journal = {ACM SIGIR Forum},
  number = {2}
}

@article{castroFaster,
  title = {Faster {{Rates}} in {{Regression Via Active Learning}}},
  author = {Castro, Rui and Willett, Rebecca and Nowak, Robert},
  pages = {46},
  abstract = {In this paper we address the theoretical capabilities of active sampling for estimating functions in noise. Specifically, the problem we consider is that of estimating a function from noisy point-wise samples, that is, the measurements which are collected at various points over the domain of the function. In the classical (passive) setting the sampling locations are chosen a priori, meaning that the choice of the sample locations precedes the gathering of the function observations. In the active sampling setting, on the other hand, the sample locations are chosen in an online fashion: the decision of where to sample next depends on all the observations made up to that point, in the spirit of the twenty questions game (as opposed to passive sampling where all the questions need to be asked before any answers are given). This extra degree of flexibility leads to improved signal reconstruction in comparison to the performance of classical (passive) methods. We present results characterizing the fundamental limits of active learning for various nonparametric function classes, as well as practical algorithms capable of exploiting the extra flexibility of the active setting and provably improving on classical techniques. In particular, significantly faster rates of convergence are achievable in cases involving functions whose complexity (in a the Kolmogorov sense) is highly concentrated in small regions of space (e.g., piecewise constant functions). Our active learning theory and methods show promise in a number of applications, including field estimation using wireless sensor networks and fault line detection.},
  file = {/Users/yuekai/Zotero/storage/38F4Q6FF/Castro et al. - Faster Rates in Regression Via Active Learning.pdf},
  language = {en}
}

@article{caticha2011Entropic,
  title = {Entropic {{Inference}}},
  author = {Caticha, Ariel},
  year = {2011},
  pages = {20--29},
  doi = {10.1063/1.3573619},
  abstract = {In this tutorial we review the essential arguments behing entropic inference. We focus on the epistemological notion of information and its relation to the Bayesian beliefs of rational agents. The problem of updating from a prior to a posterior probability distribution is tackled through an eliminative induction process that singles out the logarithmic relative entropy as the unique tool for inference. The resulting method of Maximum relative Entropy (ME), includes as special cases both MaxEnt and Bayes' rule, and therefore unifies the two themes of these workshops -- the Maximum Entropy and the Bayesian methods -- into a single general inference scheme.},
  archivePrefix = {arXiv},
  eprint = {1011.0723},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Caticha (2011) - Entropic Inference.pdf},
  journal = {arXiv:1011.0723 [cond-mat, physics:physics, stat]},
  keywords = {Condensed Matter - Statistical Mechanics,Physics - Data Analysis; Statistics and Probability,Statistics - Methodology},
  primaryClass = {cond-mat, physics:physics, stat}
}

@article{cattaneo2017BootstrapBased,
  title = {Bootstrap-{{Based Inference}} for {{Cube Root Asymptotics}}},
  author = {Cattaneo, Matias D. and Jansson, Michael and Nagasawa, Kenichi},
  year = {2017},
  month = apr,
  abstract = {This paper proposes a consistent bootstrap-based distributional approximation for cube root consistent and related estimators exhibiting a Chernoff (1964)-type limiting distribution. For estimators of this kind, the standard nonparametric bootstrap is inconsistent. Our method restores consistency of the nonparametric bootstrap by altering the shape of the criterion function defining the estimator whose distribution we seek to approximate. This modification leads to a generic and easy-to-implement resampling method for inference that is conceptually distinct from other available distributional approximations. We illustrate the applicability of our core idea with six canonical examples in statistics, machine learning, econometrics, and biostatistics. Simulation evidence is also provided.},
  archivePrefix = {arXiv},
  eprint = {1704.08066},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cattaneo et al (2017) - Bootstrap-Based Inference for Cube Root Asymptotics.pdf},
  journal = {arXiv:1704.08066 [econ, math, stat]},
  keywords = {Economics - Econometrics,Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {econ, math, stat}
}

@article{cayley1882Monge,
  title = {On {{Monge}}'s ``{{M\'emoire}} Sur La {{Th\'eorie}} Des {{D\'eblais}} et Des {{Remblais}}.''},
  author = {Cayley},
  year = {1882},
  volume = {s1-14},
  pages = {139--143},
  issn = {1460-244X},
  doi = {10.1112/plms/s1-14.1.139},
  annotation = {\_eprint: https://londmathsoc.onlinelibrary.wiley.com/doi/pdf/10.1112/plms/s1-14.1.139},
  copyright = {\textcopyright{} 1882 London Mathematical Society},
  file = {/Users/yuekai/Zotero/storage/L2VL54CI/s1-14.1.html},
  journal = {Proceedings of the London Mathematical Society},
  language = {en},
  number = {1}
}

@article{celis2014Buyitnow,
  title = {Buy-It-Now or {{Take}}-a-Chance: {{Price Discrimination}} through {{Randomized Auctions}}},
  author = {Celis, L Elisa and Lewis, Gregory and Mobious, Markus and Nazerzadeh, Hamid},
  year = {2014},
  month = oct,
  volume = {60},
  pages = {36},
  file = {/Users/yuekai/Documents/zotero/Celis et al (2014) - Buy-it-now or Take-a-chance.pdf},
  journal = {Management Science},
  language = {en},
  number = {12}
}

@article{celis2018Algorithmic,
  title = {An {{Algorithmic Framework}} to {{Control Bias}} in {{Bandit}}-Based {{Personalization}}},
  author = {Celis, L. Elisa and Kapoor, Sayash and Salehi, Farnood and Vishnoi, Nisheeth K.},
  year = {2018},
  month = feb,
  abstract = {Personalization is pervasive in the online space as it leads to higher efficiency and revenue by allowing the most relevant content to be served to each user. However, recent studies suggest that personalization methods can propagate societal or systemic biases and polarize opinions; this has led to calls for regulatory mechanisms and algorithms to combat bias and inequality. Algorithmically, bandit optimization has enjoyed great success in learning user preferences and personalizing content or feeds accordingly. We propose an algorithmic framework that allows for the possibility to control bias or discrimination in such bandit-based personalization. Our model allows for the specification of general fairness constraints on the sensitive types of the content that can be displayed to a user. The challenge, however, is to come up with a scalable and low regret algorithm for the constrained optimization problem that arises. Our main technical contribution is a provably fast and low-regret algorithm for the fairness-constrained bandit optimization problem. Our proofs crucially leverage the special structure of our problem. Experiments on synthetic and real-world data sets show that our algorithmic framework can control bias with only a minor loss to revenue.},
  archivePrefix = {arXiv},
  eprint = {1802.08674},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Celis et al (2018) - An Algorithmic Framework to Control Bias in Bandit-based Personalization.pdf},
  journal = {arXiv:1802.08674 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{celis2018Classification,
  title = {Classification with {{Fairness Constraints}}: {{A Meta}}-{{Algorithm}} with {{Provable Guarantees}}},
  shorttitle = {Classification with {{Fairness Constraints}}},
  author = {Celis, L. Elisa and Huang, Lingxiao and Keswani, Vijay and Vishnoi, Nisheeth K.},
  year = {2018},
  month = jun,
  abstract = {Developing classification algorithms that are fair with respect to sensitive attributes of the data has become an important problem due to the growing deployment of classification algorithms in various social contexts. Several recent works have focused on fairness with respect to a specific metric, modeled the corresponding fair classification problem as a constrained optimization problem, and developed tailored algorithms to solve them. Despite this, there still remain important metrics for which we do not have fair classifiers and many of the aforementioned algorithms do not come with theoretical guarantees; perhaps because the resulting optimization problem is non-convex. The main contribution of this paper is a new meta-algorithm for classification that takes as input a large class of fairness constraints, with respect to multiple non-disjoint sensitive attributes, and which comes with provable guarantees. This is achieved by first developing a meta-algorithm for a large family of classification problems with convex constraints, and then showing that classification problems with general types of fairness constraints can be reduced to those in this family. We present empirical results that show that our algorithm can achieve near-perfect fairness with respect to various fairness metrics, and that the loss in accuracy due to the imposed fairness constraints is often small. Overall, this work unifies several prior works on fair classification, presents a practical algorithm with theoretical guarantees, and can handle fairness metrics that were previously not possible.},
  archivePrefix = {arXiv},
  eprint = {1806.06055},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Celis et al (2018) - Classification with Fairness Constraints.pdf},
  journal = {arXiv:1806.06055 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{celis2019Controlling,
  title = {Toward {{Controlling Discrimination}} in {{Online Ad Auctions}}},
  author = {Celis, L. Elisa and Mehrotra, Anay and Vishnoi, Nisheeth K.},
  year = {2019},
  month = jan,
  abstract = {Online advertising platforms are thriving due to the customizable audiences they offer advertisers. However, recent studies show that advertisements can be discriminatory with respect to the gender or race of the audience that sees the ad, and may inadvertently cross ethical and/or legal boundaries. To prevent this, we propose a constrained ad auction framework that maximizes the platform's revenue conditioned on ensuring that the audience seeing an advertiser's ad is distributed appropriately across sensitive types such as gender or race. Building upon Myerson's classic work, we first present an optimal auction mechanism for a large class of fairness constraints. Finding the parameters of this optimal auction, however, turns out to be a non-convex problem. We show that this non-convex problem can be reformulated as a more structured non-convex problem with no saddle points or local-maxima; this allows us to develop a gradient-descent-based algorithm to solve it. Our empirical results on the A1 Yahoo! dataset demonstrate that our algorithm can obtain uniform coverage across different user types for each advertiser at a minor loss to the revenue of the platform, and a small change to the size of the audience each advertiser reaches.},
  archivePrefix = {arXiv},
  eprint = {1901.10450},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Celis et al (2019) - Toward Controlling Discrimination in Online Ad Auctions.pdf},
  journal = {arXiv:1901.10450 [cs]},
  keywords = {Computer Science - Computer Science and Game Theory,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{celis2019Fair,
  title = {Fair {{Distributions}} from {{Biased Samples}}: {{A Maximum Entropy Optimization Framework}}},
  shorttitle = {Fair {{Distributions}} from {{Biased Samples}}},
  author = {Celis, L. Elisa and Keswani, Vijay and Yildiz, Ozan and Vishnoi, Nisheeth K.},
  year = {2019},
  month = jun,
  abstract = {One reason for the emergence of bias in AI systems is biased data -- datasets that may not be true representations of the underlying distributions -- and may over or under-represent groups with respect to protected attributes such as gender or race. We consider the problem of correcting such biases and learning distributions that are "fair", with respect to measures such as proportional representation and statistical parity, from the given samples. Our approach is based on a novel formulation of the problem of learning a fair distribution as a maximum entropy optimization problem with a given expectation vector and a prior distribution. Technically, our main contributions are: (1) a new second-order method to compute the (dual of the) maximum entropy distribution over an exponentially-sized discrete domain that turns out to be faster than previous methods, and (2) methods to construct prior distributions and expectation vectors that provably guarantee that the learned distributions satisfy a wide class of fairness criteria. Our results also come with quantitative bounds on the total variation distance between the empirical distribution obtained from the samples and the learned fair distribution. Our experimental results include testing our approach on the COMPAS dataset and showing that the fair distributions not only improve disparate impact values but when used to train classifiers only incur a small loss of accuracy.},
  archivePrefix = {arXiv},
  eprint = {1906.02164},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Celis et al (2019) - Fair Distributions from Biased Samples.pdf},
  journal = {arXiv:1906.02164 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{celis2020Interventions,
  title = {Interventions for {{Ranking}} in the {{Presence}} of {{Implicit Bias}}},
  author = {Celis, L. Elisa and Mehrotra, Anay and Vishnoi, Nisheeth K.},
  year = {2020},
  month = jan,
  abstract = {Implicit bias is the unconscious attribution of particular qualities (or lack
thereof) to a member from a particular social group (e.g., defined by gender or
race). Studies on implicit bias have shown that these unconscious stereotypes
can have adverse outcomes in various social contexts, such as job screening,
teaching, or policing. Recently, (Kleinberg and Raghavan, 2018) considered a
mathematical model for implicit bias and showed the effectiveness of the Rooney
Rule as a constraint to improve the utility of the outcome for certain cases of
the subset selection problem. Here we study the problem of designing
interventions for the generalization of subset selection -- ranking -- that
requires to output an ordered set and is a central primitive in various social
and computational contexts. We present a family of simple and interpretable
constraints and show that they can optimally mitigate implicit bias for a
generalization of the model studied in (Kleinberg and Raghavan, 2018).
Subsequently, we prove that under natural distributional assumptions on the
utilities of items, simple, Rooney Rule-like, constraints can also surprisingly
recover almost all the utility lost due to implicit biases. Finally, we augment
our theoretical results with empirical findings on real-world distributions
from the IIT-JEE (2009) dataset and the Semantic Scholar Research corpus.},
  file = {/Users/yuekai/Documents/zotero/Celis et al (2020) - Interventions for Ranking in the Presence of Implicit Bias.pdf},
  language = {en}
}

@article{cetin2006Distributed,
  title = {Distributed Fusion in Sensor Networks},
  author = {Cetin, M. and Chen, Lei and Fisher, J.W. and Ihler, A.T. and Moses, R.L. and Wainwright, M.J. and Willsky, A.S.},
  year = {2006},
  month = jul,
  volume = {23},
  pages = {42--55},
  issn = {1053-5888},
  doi = {10.1109/MSP.2006.1657816},
  file = {/Users/yuekai/Documents/zotero/Cetin et al (2006) - Distributed fusion in sensor networks.pdf},
  journal = {IEEE Signal Processing Magazine},
  language = {en},
  number = {4}
}

@article{cevid2019Spectral,
  title = {Spectral {{Deconfounding}} via {{Perturbed Sparse Linear Models}}},
  author = {{\'C}evid, Domagoj and B{\"u}hlmann, Peter and Meinshausen, Nicolai},
  year = {2019},
  month = jul,
  abstract = {Standard high-dimensional regression methods assume that the underlying coefficient vector is sparse. This might not be true in some cases, in particular in presence of hidden, confounding variables. Such hidden confounding can be represented as a high-dimensional linear model where the sparse coefficient vector is perturbed. For this model, we develop and investigate a class of methods that are based on running the Lasso on preprocessed data. The preprocessing step consists of applying certain spectral transformations that change the singular values of the design matrix. We show that, under some assumptions, one can achieve the optimal \$\textbackslash ell\_1\$-error rate for estimating the underlying sparse coefficient vector. Our theory also covers the Lava estimator (Chernozhukov et al. [2017]) for a special model class. The performance of the method is illustrated on simulated data and a genomic dataset.},
  archivePrefix = {arXiv},
  eprint = {1811.05352},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ćevid et al (2019) - Spectral Deconfounding via Perturbed Sparse Linear Models.pdf},
  journal = {arXiv:1811.05352 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{chaganty2013Spectral,
  title = {Spectral {{Experts}} for {{Estimating Mixtures}} of {{Linear Regressions}}},
  author = {Chaganty, Arun Tejasvi and Liang, Percy},
  year = {2013},
  month = jun,
  abstract = {Discriminative latent-variable models are typically learned using EM or gradient-based optimization, which suffer from local optima. In this paper, we develop a new computationally efficient and provably consistent estimator for a mixture of linear regressions, a simple instance of a discriminative latent-variable model. Our approach relies on a low-rank linear regression to recover a symmetric tensor, which can be factorized into the parameters using a tensor power method. We prove rates of convergence for our estimator and provide an empirical evaluation illustrating its strengths relative to local optimization (EM).},
  archivePrefix = {arXiv},
  eprint = {1306.3729},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chaganty, Liang (2013) - Spectral Experts for Estimating Mixtures of Linear Regressions.pdf},
  journal = {arXiv:1306.3729 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@book{chakraborty2013Statistical,
  title = {Statistical {{Methods}} for {{Dynamic Treatment Regimes}}},
  author = {Chakraborty, Bibhas and Moodie, Erica E.M.},
  year = {2013},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4614-7428-9},
  file = {/Users/yuekai/Documents/zotero/Chakraborty, Moodie (2013) - Statistical Methods for Dynamic Treatment Regimes.pdf},
  isbn = {978-1-4614-7427-2 978-1-4614-7428-9},
  language = {en},
  series = {Statistics for {{Biology}} and {{Health}}}
}

@article{chakraborty2017Who,
  title = {Who {{Makes Trends}}? {{Understanding Demographic Biases}} in {{Crowdsourced Recommendations}}},
  shorttitle = {Who {{Makes Trends}}?},
  author = {Chakraborty, Abhijnan and Messias, Johnnatan and Benevenuto, Fabricio and Ghosh, Saptarshi and Ganguly, Niloy and Gummadi, Krishna P.},
  year = {2017},
  month = apr,
  abstract = {Users of social media sites like Facebook and Twitter rely on crowdsourced content recommendation systems (e.g., Trending Topics) to retrieve important and useful information. Contents selected for recommendation indirectly give the initial users who promoted (by liking or posting) the content an opportunity to propagate their messages to a wider audience. Hence, it is important to understand the demographics of people who make a content worthy of recommendation, and explore whether they are representative of the media site's overall population. In this work, using extensive data collected from Twitter, we make the first attempt to quantify and explore the demographic biases in the crowdsourced recommendations. Our analysis, focusing on the selection of trending topics, finds that a large fraction of trends are promoted by crowds whose demographics are significantly different from the overall Twitter population. More worryingly, we find that certain demographic groups are systematically under-represented among the promoters of the trending topics. To make the demographic biases in Twitter trends more transparent, we developed and deployed a Web-based service 'Who-Makes-Trends' at twitter-app.mpi-sws.org/who-makes-trends.},
  archivePrefix = {arXiv},
  eprint = {1704.00139},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chakraborty et al (2017) - Who Makes Trends.pdf},
  journal = {arXiv:1704.00139 [physics]},
  keywords = {Computer Science - Social and Information Networks,Physics - Physics and Society},
  primaryClass = {physics}
}

@article{chandrasekaran2010Latent,
  title = {Latent Variable Graphical Model Selection via Convex Optimization},
  author = {Chandrasekaran, Venkat and Parrilo, Pablo A. and Willsky, Alan S.},
  year = {2010},
  month = aug,
  doi = {10.1214/11-AOS949},
  file = {/Users/yuekai/Documents/zotero/Chandrasekaran et al (2010) - Latent variable graphical model selection via convex optimization.pdf},
  language = {en}
}

@article{chandrasekaran2012Convex,
  title = {The {{Convex Geometry}} of {{Linear Inverse Problems}}},
  author = {Chandrasekaran, Venkat and Recht, Benjamin and Parrilo, Pablo A. and Willsky, Alan S.},
  year = {2012},
  month = dec,
  volume = {12},
  pages = {805--849},
  issn = {1615-3383},
  doi = {10.1007/s10208-012-9135-7},
  abstract = {In applications throughout science and engineering one is often faced with the challenge of solving an ill-posed inverse problem, where the number of available measurements is smaller than the dimension of the model to be estimated. However in many practical situations of interest, models are constrained structurally so that they only have a few degrees of freedom relative to their ambient dimension. This paper provides a general framework to convert notions of simplicity into convex penalty functions, resulting in convex optimization solutions to linear, underdetermined inverse problems. The class of simple models considered includes those formed as the sum of a few atoms from some (possibly infinite) elementary atomic set; examples include well-studied cases from many technical fields such as sparse vectors (signal processing, statistics) and low-rank matrices (control, statistics), as well as several others including sums of a few permutation matrices (ranked elections, multiobject tracking), low-rank tensors (computer vision, neuroscience), orthogonal matrices (machine learning), and atomic measures (system identification). The convex programming formulation is based on minimizing the norm induced by the convex hull of the atomic set; this norm is referred to as the atomic norm. The facial structure of the atomic norm ball carries a number of favorable properties that are useful for recovering simple models, and an analysis of the underlying convex geometry provides sharp estimates of the number of generic measurements required for exact and robust recovery of models from partial information. These estimates are based on computing the Gaussian widths of tangent cones to the atomic norm ball. When the atomic set has algebraic structure the resulting optimization problems can be solved or approximated via semidefinite programming. The quality of these approximations affects the number of measurements required for recovery, and this tradeoff is characterized via some examples. Thus this work extends the catalog of simple models (beyond sparse vectors and low-rank matrices) that can be recovered from limited linear information via tractable convex programming.},
  file = {/Users/yuekai/Documents/zotero/Chandrasekaran et al (2012) - The Convex Geometry of Linear Inverse Problems.pdf},
  journal = {Foundations of Computational Mathematics},
  language = {en},
  number = {6}
}

@article{chang1997Conditioning,
  title = {Conditioning as Disintegration},
  author = {Chang, J. T. and Pollard, D.},
  year = {1997},
  volume = {51},
  pages = {287--317},
  issn = {1467-9574},
  doi = {10.1111/1467-9574.00056},
  abstract = {Conditional probability distributions seem to have a bad reputation when it comes to rigorous treatment of conditioning. Technical arguments are published as manipulations of Radon\textendash Nikodym derivatives, although we all secretly perform heuristic calculations using elementary definitions of conditional probabilities. In print, measurability and averaging properties substitute for intuitive ideas about random variables behaving like constants given particular conditioning information. One way to engage in rigorous, guilt-free manipulation of conditional distributions is to treat them as disintegrating measures\textemdash families of probability measures concentrating on the level sets of a conditioning statistic. In this paper we present a little theory and a range of examples\textemdash from EM algorithms and the Neyman factorization, through Bayes theory and marginalization paradoxes\textemdash to suggest that disintegrations have both intuitive appeal and the rigor needed for many problems in mathematical statistics.},
  copyright = {VVS 1997},
  file = {/Users/yuekai/Documents/zotero/Chang, Pollard (1997) - Conditioning as disintegration.pdf},
  journal = {Statistica Neerlandica},
  language = {en},
  number = {3}
}

@article{chang2020Invariant,
  title = {Invariant {{Rationalization}}},
  author = {Chang, Shiyu and Zhang, Yang and Yu, Mo and Jaakkola, Tommi S.},
  year = {2020},
  month = mar,
  abstract = {Selective rationalization improves neural network interpretability by identifying a small subset of input features -- the rationale -- that best explains or supports the prediction. A typical rationalization criterion, i.e. maximum mutual information (MMI), finds the rationale that maximizes the prediction performance based only on the rationale. However, MMI can be problematic because it picks up spurious correlations between the input features and the output. Instead, we introduce a game-theoretic invariant rationalization criterion where the rationales are constrained to enable the same predictor to be optimal across different environments. We show both theoretically and empirically that the proposed rationales can rule out spurious correlations, generalize better to different test scenarios, and align better with human judgments. Our data and code are available.},
  archivePrefix = {arXiv},
  eprint = {2003.09772},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chang et al (2020) - Invariant Rationalization.pdf},
  journal = {arXiv:2003.09772 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{chapelle2011Yahoo,
  title = {Yahoo! {{Learning}} to {{Rank Challenge Overview}}},
  booktitle = {Proceedings of the {{Learning}} to {{Rank Challenge}}},
  author = {Chapelle, Olivier and Chang, Yi},
  year = {2011},
  month = jan,
  pages = {1--24},
  issn = {1938-7228},
  abstract = {Learning to rank for information retrieval has gained a lot of interest in the recent years but there is a lack for large real-world datasets to benchmark algorithms. That led us to publicly releas...},
  chapter = {Machine Learning},
  file = {/Users/yuekai/Documents/zotero/Chapelle, Chang (2011) - Yahoo.pdf},
  language = {en}
}

@article{charles2018Geometric,
  title = {A {{Geometric Perspective}} on the {{Transferability}} of {{Adversarial Directions}}},
  author = {Charles, Zachary and Rosenberg, Harrison and Papailiopoulos, Dimitris},
  year = {2018},
  month = nov,
  abstract = {State-of-the-art machine learning models frequently misclassify inputs that have been perturbed in an adversarial manner. Adversarial perturbations generated for a given input and a specific classifier often seem to be effective on other inputs and even different classifiers. In other words, adversarial perturbations seem to transfer between different inputs, models, and even different neural network architectures. In this work, we show that in the context of linear classifiers and two-layer ReLU networks, there provably exist directions that give rise to adversarial perturbations for many classifiers and data points simultaneously. We show that these "transferable adversarial directions" are guaranteed to exist for linear separators of a given set, and will exist with high probability for linear classifiers trained on independent sets drawn from the same distribution. We extend our results to large classes of two-layer ReLU networks. We further show that adversarial directions for ReLU networks transfer to linear classifiers while the reverse need not hold, suggesting that adversarial perturbations for more complex models are more likely to transfer to other classifiers. We validate our findings empirically, even for deeper ReLU networks.},
  archivePrefix = {arXiv},
  eprint = {1811.03531},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Charles et al (2018) - A Geometric Perspective on the Transferability of Adversarial Directions.pdf},
  journal = {arXiv:1811.03531 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{chatterjee2008new,
  title = {A New Method of Normal Approximation},
  author = {Chatterjee, Sourav},
  year = {2008},
  month = jul,
  volume = {36},
  pages = {1584--1610},
  issn = {0091-1798, 2168-894X},
  doi = {10.1214/07-AOP370},
  abstract = {We introduce a new version of Stein's method that reduces a large class of normal approximation problems to variance bounding exercises, thus making a connection between central limit theorems and concentration of measure. Unlike Skorokhod embeddings, the object whose variance must be bounded has an explicit formula that makes it possible to carry out the program more easily. As an application, we derive a general CLT for functions that are obtained as combinations of many local contributions, where the definition of ``local'' itself depends on the data. Several examples are given, including the solution to a nearest-neighbor CLT problem posed by P. Bickel.},
  file = {/Users/yuekai/Documents/zotero/Chatterjee (2008) - A new method of normal approximation.pdf},
  journal = {The Annals of Probability},
  language = {EN},
  mrnumber = {MR2435859},
  number = {4},
  zmnumber = {1159.62009}
}

@article{chatterjee2019new,
  title = {A New Coefficient of Correlation},
  author = {Chatterjee, Sourav},
  year = {2019},
  month = sep,
  abstract = {Is it possible to define a coefficient of correlation which is (a) as simple as the classical coefficients like Pearson's correlation or Spearman's correlation, and yet (b) consistently estimates some simple and interpretable measure of the degree of dependence between the variables, which is 0 if and only if the variables are independent and 1 if and only if one is a measurable function of the other, and (c) has a simple asymptotic theory under the hypothesis of independence, like the classical coefficients? This article answers this question in the affirmative, by producing such a coefficient. No assumptions are needed on the distributions of the variables. There are several coefficients in the literature that converge to 0 if and only if the variables are independent, but none that satisfy any of the other properties mentioned above.},
  archivePrefix = {arXiv},
  eprint = {1909.10140},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chatterjee (2019) - A new coefficient of correlation.pdf},
  journal = {arXiv:1909.10140 [math, stat]},
  keywords = {Mathematics - Probability,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{chaudhari2017Stochastic,
  title = {Stochastic Gradient Descent Performs Variational Inference, Converges to Limit Cycles for Deep Networks},
  author = {Chaudhari, Pratik and Soatto, Stefano},
  year = {2017},
  month = oct,
  abstract = {Stochastic gradient descent (SGD) is widely believed to perform implicit regularization when used to train deep neural networks, but the precise manner in which this occurs has thus far been elusive. We prove that SGD minimizes an average potential over the posterior distribution of weights along with an entropic regularization term. This potential is however not the original loss function in general. So SGD does perform variational inference, but for a different loss than the one used to compute the gradients. Even more surprisingly, SGD does not even converge in the classical sense: we show that the most likely trajectories of SGD for deep networks do not behave like Brownian motion around critical points. Instead, they resemble closed loops with deterministic components. We prove that such "out-of-equilibrium" behavior is a consequence of highly non-isotropic gradient noise in SGD; the covariance matrix of mini-batch gradients for deep networks has a rank as small as 1\% of its dimension. We provide extensive empirical validation of these claims, proven in the appendix.},
  archivePrefix = {arXiv},
  eprint = {1710.11029},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chaudhari, Soatto (2017) - Stochastic gradient descent performs variational inference, converges to limit.pdf},
  journal = {arXiv:1710.11029 [cond-mat, stat]},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Statistical Mechanics,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cond-mat, stat}
}

@article{chaudhry2019Tiny,
  title = {On {{Tiny Episodic Memories}} in {{Continual Learning}}},
  author = {Chaudhry, Arslan and Rohrbach, Marcus and Elhoseiny, Mohamed and Ajanthan, Thalaiyasingam and Dokania, Puneet K. and Torr, Philip H. S. and Ranzato, Marc'Aurelio},
  year = {2019},
  month = feb,
  abstract = {In continual learning (CL), an agent learns from a stream of tasks leveraging prior experience to transfer knowledge to future tasks. It is an ideal framework to decrease the amount of supervision in the existing learning algorithms. But for a successful knowledge transfer, the learner needs to remember how to perform previous tasks. One way to endow the learner the ability to perform tasks seen in the past is to store a small memory, dubbed episodic memory, that stores few examples from previous tasks and then to replay these examples when training for future tasks. In this work, we empirically analyze the effectiveness of a very small episodic memory in a CL setup where each training example is only seen once. Surprisingly, across four rather different supervised learning benchmarks adapted to CL, a very simple baseline, that jointly trains on both examples from the current task as well as examples stored in the episodic memory, significantly outperforms specifically designed CL approaches with and without episodic memory. Interestingly, we find that repetitive training on even tiny memories of past tasks does not harm generalization, on the contrary, it improves it, with gains between 7\textbackslash\% and 17\textbackslash\% when the memory is populated with a single example per class.},
  archivePrefix = {arXiv},
  eprint = {1902.10486},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chaudhry et al (2019) - On Tiny Episodic Memories in Continual Learning.pdf},
  journal = {arXiv:1902.10486 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{chavdarova2019Reducing,
  title = {Reducing {{Noise}} in {{GAN Training}} with {{Variance Reduced Extragradient}}},
  author = {Chavdarova, Tatjana and Gidel, Gauthier and Fleuret, Fran{\c c}ois and {Lacoste-Julien}, Simon},
  year = {2019},
  month = apr,
  abstract = {We study the effect of the stochastic gradient noise on the training of generative adversarial networks (GANs) and show that it can prevent the convergence of standard game optimization methods, while the batch version converges. We address this issue with a novel stochastic variance-reduced extragradient (SVRE) optimization algorithm that improves upon the best convergence rates proposed in the literature. We observe empirically that SVRE performs similarly to a batch method on MNIST while being computationally cheaper, and that SVRE yields more stable GAN training on standard datasets.},
  archivePrefix = {arXiv},
  eprint = {1904.08598},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chavdarova et al (2019) - Reducing Noise in GAN Training with Variance Reduced Extragradient.pdf},
  journal = {arXiv:1904.08598 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@book{chen2005Stein,
  title = {Stein's Method for Normal Approximation},
  author = {Chen, Louis H Y and Shao, Qi-Man},
  year = {2005},
  month = apr,
  doi = {10.1142/5792},
  file = {/Users/yuekai/Documents/zotero/Chen, Shao (2005) - Stein’s method for normal approximation.pdf},
  isbn = {978-981-256-280-7 978-981-256-768-0},
  language = {en},
  series = {Lecture {{Notes Series}}, {{IMS}}, {{NUS}}}
}

@article{chen2007Robust,
  title = {A {{Robust Optimization Perspective}} on {{Stochastic Programming}}},
  author = {Chen, Xin and Sim, Melvyn and Sun, Peng},
  year = {2007},
  volume = {55},
  pages = {1058--1071},
  doi = {10.1287/opre.1070.0441},
  abstract = {In this paper, we introduce an approach for constructing uncertainty sets for robust optimization using new deviation measures for random variables termed the forward and backward deviations. These deviation measures capture distributional asymmetry and lead to better approximations of chance constraints. Using a linear decision rule, we also propose a tractable approximation approach for solving a class of multistage chance-constrained stochastic linear optimization problems. An attractive feature of the framework is that we convert the original model into a second-order cone program, which is computationally tractable both in theory and in practice. We demonstrate the framework through an application of a project management problem with uncertain activity completion time.},
  file = {/Users/yuekai/Documents/zotero/Chen et al (2007) - A Robust Optimization Perspective on Stochastic Programming.pdf},
  journal = {Operations Research}
}

@article{chen2013Data,
  title = {Data Enriched Linear Regression},
  author = {Chen, Aiyou and Owen, Art B. and Shi, Minghui},
  year = {2013},
  month = apr,
  abstract = {We present a linear regression method for predictions on a small data set making use of a second possibly biased data set that may be much larger. Our method fits linear regressions to the two data sets while penalizing the difference between predictions made by those two models. The resulting algorithm is a shrinkage method similar to those used in small area estimation. We find a Stein-type finding for Gaussian responses: when the model has 5 or more coefficients and 10 or more error degrees of freedom, it becomes inadmissible to use only the small data set, no matter how large the bias is. We also present both plug-in and AICc-based methods to tune our penalty parameter. Most of our results use an \$L\_2\$ penalty, but we obtain formulas for \$L\_1\$ penalized estimates when the model is specialized to the location setting. Ordinary Stein shrinkage provides an inadmissibility result for only 3 or more coefficients, but we find that our shrinkage method typically produces much lower squared errors in as few as 5 or 10 dimensions when the bias is small and essentially equivalent squared errors when the bias is large.},
  archivePrefix = {arXiv},
  eprint = {1304.1837},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chen et al (2013) - Data enriched linear regression.pdf},
  journal = {arXiv:1304.1837 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@inproceedings{chen2013Pairwise,
  title = {Pairwise {{Ranking Aggregation}} in a {{Crowdsourced Setting}}},
  booktitle = {Proceedings of the {{Sixth ACM International Conference}} on {{Web Search}} and {{Data Mining}}},
  author = {Chen, Xi and Bennett, Paul N. and {Collins-Thompson}, Kevyn and Horvitz, Eric},
  year = {2013},
  pages = {193--202},
  publisher = {{ACM}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2433396.2433420},
  abstract = {Inferring rankings over elements of a set of objects, such as documents or images, is a key learning problem for such important applications as Web search and recommender systems. Crowdsourcing services provide an inexpensive and efficient means to acquire preferences over objects via labeling by sets of annotators. We propose a new model to predict a gold-standard ranking that hinges on combining pairwise comparisons via crowdsourcing. In contrast to traditional ranking aggregation methods, the approach learns about and folds into consideration the quality of contributions of each annotator. In addition, we minimize the cost of assessment by introducing a generalization of the traditional active learning scenario to jointly select the annotator and pair to assess while taking into account the annotator quality, the uncertainty over ordering of the pair, and the current model uncertainty. We formalize this as an active learning strategy that incorporates an exploration-exploitation tradeoff and implement it using an efficient online Bayesian updating scheme. Using simulated and real-world data, we demonstrate that the active learning strategy achieves significant reductions in labeling cost while maintaining accuracy.},
  isbn = {978-1-4503-1869-3},
  series = {{{WSDM}} '13}
}

@article{chen2014Generalised,
  title = {Generalised Additive and Index Models with Shape Constraints},
  author = {Chen, Yining and Samworth, Richard J.},
  year = {2014},
  month = apr,
  abstract = {We study generalised additive models, with shape restrictions (e.g. monotonicity, convexity, concavity) imposed on each component of the additive prediction function. We show that this framework facilitates a nonparametric estimator of each additive component, obtained by maximising the likelihood. The procedure is free of tuning parameters and under mild conditions is proved to be uniformly consistent on compact intervals. More generally, our methodology can be applied to generalised additive index models. Here again, the procedure can be justified on theoretical grounds and, like the original algorithm, possesses highly competitive finite-sample performance. Practical utility is illustrated through the use of these methods in the analysis of two real datasets. Our algorithms are publicly available in the \textbackslash texttt\{R\} package \textbackslash textbf\{scar\}, short for \textbackslash textbf\{s\}hape-\textbackslash textbf\{c\}onstrained \textbackslash textbf\{a\}dditive \textbackslash textbf\{r\}egression.},
  archivePrefix = {arXiv},
  eprint = {1404.2957},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chen, Samworth (2014) - Generalised additive and index models with shape constraints.pdf},
  journal = {arXiv:1404.2957 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{chen2016direct,
  title = {The Direct Extension of {{ADMM}} for Multi-Block Convex Minimization Problems Is Not Necessarily Convergent},
  author = {Chen, Caihua and He, Bingsheng and Ye, Yinyu and Yuan, Xiaoming},
  year = {2016},
  month = jan,
  volume = {155},
  pages = {57--79},
  issn = {0025-5610, 1436-4646},
  doi = {10.1007/s10107-014-0826-5},
  abstract = {The alternating direction method of multipliers (ADMM) is now widely used in many fields, and its convergence was proved when two blocks of variables are alternatively updated. It is strongly desirable and practically valuable to extend the ADMM directly to the case of a multi-block convex minimization problem where its objective function is the sum of more than two separable convex functions. However, the convergence of this extension has been missing for a long time \textemdash neither an affirmative convergence proof nor an example showing its non-convergence is known in the literature. In this paper we give a negative answer to this long-standing open question: The direct extension of ADMM is not necessarily convergent. We present a sufficient condition to ensure the convergence of the direct extension of ADMM, and give an example to show its divergence.},
  file = {/Users/yuekai/Documents/zotero/Chen et al (2016) - The direct extension of ADMM for multi-block convex minimization problems is.pdf},
  journal = {Mathematical Programming},
  language = {en},
  number = {1-2}
}

@article{chen2016XGBoost,
  title = {{{XGBoost}}: {{A Scalable Tree Boosting System}}},
  shorttitle = {{{XGBoost}}},
  author = {Chen, Tianqi and Guestrin, Carlos},
  year = {2016},
  pages = {785--794},
  doi = {10.1145/2939672.2939785},
  abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
  archivePrefix = {arXiv},
  eprint = {1603.02754},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chen, Guestrin (2016) - XGBoost.pdf},
  journal = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '16},
  keywords = {Computer Science - Machine Learning}
}

@article{chen2017Multivariate,
  title = {The {{Multivariate Hawkes Process}} in {{High Dimensions}}: {{Beyond Mutual Excitation}}},
  shorttitle = {The {{Multivariate Hawkes Process}} in {{High Dimensions}}},
  author = {Chen, Shizhe and Shojaie, Ali and {Shea-Brown}, Eric and Witten, Daniela},
  year = {2017},
  month = jul,
  abstract = {The Hawkes process is a class of point processes whose future depends on their own history. Previous theoretical work on the Hawkes process is limited to a special case in which a past event can only increase the occurrence of future events, and the link function is linear. However, in neuronal networks and other real-world applications, inhibitory relationships may be present, and the link function may be non-linear. In this paper, we develop a new approach for investigating the properties of the Hawkes process without the restriction to mutual excitation or linear link functions. To this end, we employ a thinning process representation and a coupling construction to bound the dependence coefficient of the Hawkes process. Using recent developments on weakly dependent sequences, we establish a concentration inequality for second-order statistics of the Hawkes process. We apply this concentration inequality to cross-covariance analysis in the high-dimensional regime, and we verify the theoretical claims with simulation studies.},
  archivePrefix = {arXiv},
  eprint = {1707.04928},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chen et al (2017) - The Multivariate Hawkes Process in High Dimensions.pdf},
  journal = {arXiv:1707.04928 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{chen2018Asymmetry,
  title = {Asymmetry {{Helps}}: {{Eigenvalue}} and {{Eigenvector Analyses}} of {{Asymmetrically Perturbed Low}}-{{Rank Matrices}}},
  shorttitle = {Asymmetry {{Helps}}},
  author = {Chen, Yuxin and Cheng, Chen and Fan, Jianqing},
  year = {2018},
  month = nov,
  abstract = {This paper is concerned with a curious phenomenon in spectral estimation. Suppose we are interested in a rank-1 and symmetric matrix \$\textbackslash boldsymbol\{M\}\^\{\textbackslash star\}\textbackslash in \textbackslash mathbb\{R\}\^\{n\textbackslash times n\}\$, yet only a randomly perturbed version \$\textbackslash boldsymbol\{M\}\$ is observed. The perturbation/noise matrix \$\textbackslash boldsymbol\{M\}-\textbackslash boldsymbol\{M\}\^\{\textbackslash star\}\$ is composed of independent and zero-mean entries and is not symmetric. This might arise, for example, when we have two independent samples for each entry of \$\textbackslash boldsymbol\{M\}\^\{\textbackslash star\}\$ and arrange them into an \$\textbackslash mathit\{asymmetric\}\$ data matrix \$\textbackslash boldsymbol\{M\}\$. The aim is to estimate the leading eigenvalue and eigenvector of \$\textbackslash boldsymbol\{M\}\^\{\textbackslash star\}\$. Somewhat unexpectedly, our findings reveal that the leading eigenvalue of the data matrix \$\textbackslash boldsymbol\{M\}\$ can be \$\textbackslash sqrt\{n\}\$ times more accurate than its leading singular value in eigenvalue estimation. Further, the perturbation of any linear form of the leading eigenvector of \$\textbackslash boldsymbol\{M\}\$ (e.g. entrywise eigenvector perturbation) is provably well-controlled. We further provide partial theory for the more general rank-\$r\$ case; this allows us to accommodate the case when \$\textbackslash boldsymbol\{M\}\^\{\textbackslash star\}\$ is rank-1 but asymmetric, by considering eigen-decomposition of the associated rank-2 dilation matrix. The takeaway message is this: arranging the data samples in an asymmetric manner and performing eigen-decomposition (as opposed to SVD) could sometimes be quite beneficial.},
  archivePrefix = {arXiv},
  eprint = {1811.12804},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chen et al (2018) - Asymmetry Helps.pdf},
  journal = {arXiv:1811.12804 [cs, eess, math, stat]},
  keywords = {Computer Science - Information Theory,Electrical Engineering and Systems Science - Signal Processing,Mathematics - Numerical Analysis,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, eess, math, stat}
}

@article{chen2018Firstorder,
  title = {First-Order {{Newton}}-Type {{Estimator}} for {{Distributed Estimation}} and {{Inference}}},
  author = {Chen, Xi and Liu, Weidong and Zhang, Yichen},
  year = {2018},
  month = nov,
  abstract = {This paper studies distributed estimation and inference for a general statistical problem with a convex loss that could be non-differentiable. For the purpose of efficient computation, we restrict ourselves to stochastic first-order optimization, which enjoys low per-iteration complexity. To motivate the proposed method, we first investigate the theoretical properties of a straightforward Divide-and-Conquer Stochastic Gradient Descent (DC-SGD) approach. Our theory shows that there is a restriction on the number of machines and this restriction becomes more stringent when the dimension p is large. To overcome this limitation, this paper proposes a new multi-round distributed estimation procedure that approximates the Newton step only using stochastic subgradient. The key component in our method is the proposal of a computationally efficient estimator of {$\Sigma-$}1w, where {$\Sigma$} is the population Hessian matrix and w is any given vector. Instead of estimating {$\Sigma$} (or {$\Sigma-$}1) that usually requires the second-order differentiability of the loss, the proposed First-Order Newton-type Estimator (FONE) directly estimates the vector of interest {$\Sigma-$}1w as a whole and is applicable to non-differentiable losses. Our estimator also facilitates the inference for the empirical risk minimizer. It turns out that the key term in the limiting covariance has the form of {$\Sigma-$}1w, which can be estimated by FONE.},
  archivePrefix = {arXiv},
  eprint = {1811.11368},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chen et al (2018) - First-order Newton-type Estimator for Distributed Estimation and Inference.pdf},
  journal = {arXiv:1811.11368 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  language = {en},
  primaryClass = {cs, stat}
}

@inproceedings{chen2018Investigating,
  title = {Investigating the {{Impact}} of {{Gender}} on {{Rank}} in {{Resume Search Engines}}},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Chen, Le and Ma, Ruijun and Hann{\'a}k, Anik{\'o} and Wilson, Christo},
  year = {2018},
  month = apr,
  pages = {1--14},
  publisher = {{Association for Computing Machinery}},
  address = {{Montreal QC, Canada}},
  doi = {10.1145/3173574.3174225},
  abstract = {In this work we investigate gender-based inequalities in the context of resume search engines, which are tools that allow recruiters to proactively search for candidates based on keywords and filters. If these ranking algorithms take demographic features into account (directly or indirectly), they may produce rankings that disadvantage some candidates. We collect search results from Indeed, Monster, and CareerBuilder based on 35 job titles in 20 U. S. cities, resulting in data on 855K job candidates. Using statistical tests, we examine whether these search engines produce rankings that exhibit two types of indirect discrimination: individual and group unfairness. Furthermore, we use controlled experiments to show that these websites do not use inferred gender of candidates as explicit features in their ranking algorithms.},
  file = {/Users/yuekai/Documents/zotero/Chen et al (2018) - Investigating the Impact of Gender on Rank in Resume Search Engines.pdf},
  isbn = {978-1-4503-5620-6},
  series = {{{CHI}} '18}
}

@article{chen2018Learning,
  title = {Learning to {{Explain}}: {{An Information}}-{{Theoretic Perspective}} on {{Model Interpretation}}},
  shorttitle = {Learning to {{Explain}}},
  author = {Chen, Jianbo and Song, Le and Wainwright, Martin J. and Jordan, Michael I.},
  year = {2018},
  month = jun,
  abstract = {We introduce instancewise feature selection as a methodology for model interpretation. Our method is based on learning a function to extract a subset of features that are most informative for each given example. This feature selector is trained to maximize the mutual information between selected features and the response variable, where the conditional distribution of the response variable given the input is the model to be explained. We develop an efficient variational approximation to the mutual information, and show the effectiveness of our method on a variety of synthetic and real data sets using both quantitative metrics and human evaluation.},
  archivePrefix = {arXiv},
  eprint = {1802.07814},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chen et al (2018) - Learning to Explain.pdf},
  journal = {arXiv:1802.07814 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{chen2018Neural,
  title = {Neural {{Ordinary Differential Equations}}},
  author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
  year = {2018},
  month = jun,
  abstract = {We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.},
  archivePrefix = {arXiv},
  eprint = {1806.07366},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chen et al (2018) - Neural Ordinary Differential Equations.pdf},
  journal = {arXiv:1806.07366 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{chen2018Quantile,
  title = {Quantile {{Regression Under Memory Constraint}}},
  author = {Chen, Xi and Liu, Weidong and Zhang, Yichen},
  year = {2018},
  month = oct,
  abstract = {This paper studies the inference problem in quantile regression (QR) for a large sample size \$n\$ but under a limited memory constraint, where the memory can only store a small batch of data of size \$m\$. A natural method is the na\textbackslash "ive divide-and-conquer approach, which splits data into batches of size \$m\$, computes the local QR estimator for each batch, and then aggregates the estimators via averaging. However, this method only works when \$n=o(m\^2)\$ and is computationally expensive. This paper proposes a computationally efficient method, which only requires an initial QR estimator on a small batch of data and then successively refines the estimator via multiple rounds of aggregations. Theoretically, as long as \$n\$ grows polynomially in \$m\$, we establish the asymptotic normality for the obtained estimator and show that our estimator with only a few rounds of aggregations achieves the same efficiency as the QR estimator computed on all the data. Moreover, our result allows the case that the dimensionality \$p\$ goes to infinity. The proposed method can also be applied to address the QR problem under distributed computing environment (e.g., in a large-scale sensor network) or for real-time streaming data.},
  archivePrefix = {arXiv},
  eprint = {1810.08264},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chen et al (2018) - Quantile Regression Under Memory Constraint.pdf},
  journal = {arXiv:1810.08264 [econ, stat]},
  keywords = {Economics - Econometrics,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {econ, stat}
}

@article{chen2018Stability,
  title = {Stability and {{Convergence Trade}}-off of {{Iterative Optimization Algorithms}}},
  author = {Chen, Yuansi and Jin, Chi and Yu, Bin},
  year = {2018},
  month = apr,
  abstract = {The overall performance or expected excess risk of an iterative machine learning algorithm can be decomposed into training error and generalization error. While the former is controlled by its convergence analysis, the latter can be tightly handled by algorithmic stability. The machine learning community has a rich history investigating convergence and stability separately. However, the question about the trade-off between these two quantities remains open. In this paper, we show that for any iterative algorithm at any iteration, the overall performance is lower bounded by the minimax statistical error over an appropriately chosen loss function class. This implies an important trade-off between convergence and stability of the algorithm -- a faster converging algorithm has to be less stable, and vice versa. As a direct consequence of this fundamental tradeoff, new convergence lower bounds can be derived for classes of algorithms constrained with different stability bounds. In particular, when the loss function is convex (or strongly convex) and smooth, we discuss the stability upper bounds of gradient descent (GD) and stochastic gradient descent and their variants with decreasing step sizes. For Nesterov's accelerated gradient descent (NAG) and heavy ball method (HB), we provide stability upper bounds for the quadratic loss function. Applying existing stability upper bounds for the gradient methods in our trade-off framework, we obtain lower bounds matching the well-established convergence upper bounds up to constants for these algorithms and conjecture similar lower bounds for NAG and HB. Finally, we numerically demonstrate the tightness of our stability bounds in terms of exponents in the rate and also illustrate via a simulated logistic regression problem that our stability bounds reflect the generalization errors better than the simple uniform convergence bounds for GD and NAG.},
  archivePrefix = {arXiv},
  eprint = {1804.01619},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chen et al (2018) - Stability and Convergence Trade-off of Iterative Optimization Algorithms.pdf},
  journal = {arXiv:1804.01619 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{chen2018Why,
  title = {Why {{Is My Classifier Discriminatory}}?},
  author = {Chen, Irene and Johansson, Fredrik D. and Sontag, David},
  year = {2018},
  month = may,
  abstract = {Recent attempts to achieve fairness in predictive models focus on the balance between fairness and accuracy. In sensitive applications such as healthcare or criminal justice, this trade-off is often undesirable as any increase in prediction error could have devastating consequences. In this work, we argue that the fairness of predictions should be evaluated in context of the data, and that unfairness induced by inadequate samples sizes or unmeasured predictive variables should be addressed through data collection, rather than by constraining the model. We decompose cost-based metrics of discrimination into bias, variance, and noise, and propose actions aimed at estimating and reducing each term. Finally, we perform case-studies on prediction of income, mortality, and review ratings, confirming the value of this analysis. We find that data collection is often a means to reduce discrimination without sacrificing accuracy.},
  archivePrefix = {arXiv},
  eprint = {1805.12002},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chen et al (2018) - Why Is My Classifier Discriminatory.pdf},
  journal = {arXiv:1805.12002 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{chen2019Fairness,
  title = {Fairness {{Under Unawareness}}: {{Assessing Disparity When Protected Class Is Unobserved}}},
  shorttitle = {Fairness {{Under Unawareness}}},
  author = {Chen, Jiahao and Kallus, Nathan and Mao, Xiaojie and Svacha, Geoffry and Udell, Madeleine},
  year = {2019},
  pages = {339--348},
  doi = {10.1145/3287560.3287594},
  abstract = {Assessing the fairness of a decision making system with respect to a protected class, such as gender or race, is challenging when class membership labels are unavailable. Probabilistic models for predicting the protected class based on observable proxies, such as surname and geolocation for race, are sometimes used to impute these missing labels for compliance assessments. Empirically, these methods are observed to exaggerate disparities, but the reason why is unknown. In this paper, we decompose the biases in estimating outcome disparity via threshold-based imputation into multiple interpretable bias sources, allowing us to explain when over- or underestimation occurs. We also propose an alternative weighted estimator that uses soft classification, and show that its bias arises simply from the conditional covariance of the outcome with the true class membership. Finally, we illustrate our results with numerical simulations and a public dataset of mortgage applications, using geolocation as a proxy for race. We confirm that the bias of threshold-based imputation is generally upward, but its magnitude varies strongly with the threshold chosen. Our new weighted estimator tends to have a negative bias that is much simpler to analyze and reason about.},
  archivePrefix = {arXiv},
  eprint = {1811.11154},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chen et al (2019) - Fairness Under Unawareness.pdf},
  journal = {Proceedings of the Conference on Fairness, Accountability, and Transparency  - FAT* '19},
  keywords = {Statistics - Applications,Statistics - Machine Learning}
}

@article{chen2019Inference,
  title = {Inference and {{Uncertainty Quantification}} for {{Noisy Matrix Completion}}},
  author = {Chen, Yuxin and Fan, Jianqing and Ma, Cong and Yan, Yuling},
  year = {2019},
  month = nov,
  volume = {116},
  pages = {22931--22937},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1910053116},
  abstract = {Noisy matrix completion aims at estimating a low-rank matrix given only partial and corrupted entries. Despite substantial progress in designing efficient estimation algorithms, it remains largely unclear how to assess the uncertainty of the obtained estimates and how to perform statistical inference on the unknown matrix (e.g.\textasciitilde constructing a valid and short confidence interval for an unseen entry). This paper takes a step towards inference and uncertainty quantification for noisy matrix completion. We develop a simple procedure to compensate for the bias of the widely used convex and nonconvex estimators. The resulting de-biased estimators admit nearly precise non-asymptotic distributional characterizations, which in turn enable optimal construction of confidence intervals\textbackslash,/\textbackslash,regions for, say, the missing entries and the low-rank factors. Our inferential procedures do not rely on sample splitting, thus avoiding unnecessary loss of data efficiency. As a byproduct, we obtain a sharp characterization of the estimation accuracy of our de-biased estimators, which, to the best of our knowledge, are the first tractable algorithms that provably achieve full statistical efficiency (including the preconstant). The analysis herein is built upon the intimate link between convex and nonconvex optimization --- an appealing feature recently discovered by \textbackslash cite\{chen2019noisy\}.},
  archivePrefix = {arXiv},
  eprint = {1906.04159},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chen et al (2019) - Inference and Uncertainty Quantification for Noisy Matrix Completion.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {Computer Science - Information Theory,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Signal Processing,Mathematics - Optimization and Control,Mathematics - Statistics Theory,Statistics - Machine Learning},
  number = {46}
}

@article{chen2019Robust,
  title = {Robust {{Decision Trees Against Adversarial Examples}}},
  author = {Chen, Hongge and Zhang, Huan and Boning, Duane and Hsieh, Cho-Jui},
  year = {2019},
  month = feb,
  abstract = {Although adversarial examples and model robustness have been extensively studied in the context of linear models and neural networks, research on this issue in tree-based models and how to make tree-based models robust against adversarial examples is still limited. In this paper, we show that tree based models are also vulnerable to adversarial examples and develop a novel algorithm to learn robust trees. At its core, our method aims to optimize the performance under the worst-case perturbation of input features, which leads to a max-min saddle point problem. Incorporating this saddle point objective into the decision tree building procedure is non-trivial due to the discrete nature of trees --- a naive approach to finding the best split according to this saddle point objective will take exponential time. To make our approach practical and scalable, we propose efficient tree building algorithms by approximating the inner minimizer in this saddle point problem, and present efficient implementations for classical information gain based trees as well as state-of-the-art tree boosting models such as XGBoost. Experimental results on real world datasets demonstrate that the proposed algorithms can substantially improve the robustness of tree-based models against adversarial examples.},
  archivePrefix = {arXiv},
  eprint = {1902.10660},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chen et al (2019) - Robust Decision Trees Against Adversarial Examples.pdf},
  journal = {arXiv:1902.10660 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{chen2019Robustness,
  title = {Robustness {{Verification}} of {{Tree}}-Based {{Models}}},
  author = {Chen, Hongge and Zhang, Huan and Si, Si and Li, Yang and Boning, Duane and Hsieh, Cho-Jui},
  year = {2019},
  month = jun,
  abstract = {We study the robustness verification problem for tree-based models, including decision trees, random forests (RFs) and gradient boosted decision trees (GBDTs). Formal robustness verification of decision tree ensembles involves finding the exact minimal adversarial perturbation or a guaranteed lower bound of it. Existing approaches find the minimal adversarial perturbation by a mixed integer linear programming (MILP) problem, which takes exponential time so is impractical for large ensembles. Although this verification problem is NP-complete in general, we give a more precise complexity characterization. We show that there is a simple linear time algorithm for verifying a single tree, and for tree ensembles, the verification problem can be cast as a max-clique problem on a multi-partite graph with bounded boxicity. For low dimensional problems when boxicity can be viewed as constant, this reformulation leads to a polynomial time algorithm. For general problems, by exploiting the boxicity of the graph, we develop an efficient multi-level verification algorithm that can give tight lower bounds on the robustness of decision tree ensembles, while allowing iterative improvement and any-time termination. OnRF/GBDT models trained on 10 datasets, our algorithm is hundreds of times faster than the previous approach that requires solving MILPs, and is able to give tight robustness verification bounds on large GBDTs with hundreds of deep trees.},
  archivePrefix = {arXiv},
  eprint = {1906.03849},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chen et al (2019) - Robustness Verification of Tree-based Models.pdf},
  journal = {arXiv:1906.03849 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{cheng2010How,
  title = {How {{Many Iterations}} Are {{Sufficient}} for {{Semiparametric Estimation}}?},
  author = {Cheng, Guang},
  year = {2010},
  month = sep,
  abstract = {A common practice in obtaining a semiparametric efficient estimate is through iteratively maximizing the (penalized) log-likelihood w.r.t. its Euclidean parameter and functional nuisance parameter via Newton-Raphson algorithm. The purpose of this paper is to provide a formula in calculating the minimal number of iterations \$k\^\textbackslash ast\$ needed to produce an efficient estimate \$\textbackslash hat\textbackslash theta\_n\^\{(k\^\textbackslash ast)\}\$ from a theoretical point of view. We discover that (a) \$k\^\textbackslash ast\$ depends on the convergence rates of the initial estimate and nuisance estimate; (b) more than \$k\^\textbackslash ast\$ iterations, i.e., \$k\$, will only improve the higher order asymptotic efficiency of \$\textbackslash hat\textbackslash theta\_n\^\{(k)\}\$; (c) \$k\^\textbackslash ast\$ iterations are also sufficient for recovering the estimation sparsity in high dimensional data. These general conclusions hold, in particular, when the nuisance parameter is not estimable at root-n rate, and apply to semiparametric models estimated under various regularizations, e.g., kernel or penalized estimation. This paper provides a first general theoretical justification for the "one-/two-step iteration" phenomena observed in the literature, and may be useful in reducing the bootstrap computational cost for the semiparametric models.},
  archivePrefix = {arXiv},
  eprint = {1009.2111},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cheng (2010) - How Many Iterations are Sufficient for Semiparametric Estimation.pdf},
  journal = {arXiv:1009.2111 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{cheng2015Identification,
  title = {Identification of Homogeneous and Heterogeneous Variables in Pooled Cohort Studies: {{Identification}} of {{Heterogeneity}} in {{Pooled Studies}}},
  shorttitle = {Identification of Homogeneous and Heterogeneous Variables in Pooled Cohort Studies},
  author = {Cheng, Xin and Lu, Wenbin and Liu, Mengling},
  year = {2015},
  month = jun,
  volume = {71},
  pages = {397--403},
  issn = {0006341X},
  doi = {10.1111/biom.12285},
  abstract = {Pooled analyses integrate data from multiple studies and achieve a larger sample size for enhanced statistical power. When heterogeneity exists in variables' effects on the outcome across studies, the simple pooling strategy fails to present a fair and complete picture of the effects of heterogeneous variables. Thus, it is important to investigate the homogeneous and heterogeneous structure of variables in pooled studies. In this paper, we consider the pooled cohort studies with time-to-event outcomes and propose a penalized Cox partial likelihood approach with adaptively weighted composite penalties on variables' homogeneous and heterogeneous effects. We show that our method can characterize the variables as having heterogeneous, homogeneous, or null effects, and estimate non-zero effects. The results are readily extended to high-dimensional applications where the number of parameters is larger than the sample size. The proposed selection and estimation procedure can be implemented using the iterative shooting algorithm. We conduct extensive numerical studies to evaluate the performance of our proposed method and demonstrate it using a pooled analysis of gene expression in patients with ovarian cancer.},
  file = {/Users/yuekai/Documents/zotero/Cheng et al (2015) - Identification of homogeneous and heterogeneous variables in pooled cohort.pdf},
  journal = {Biometrics},
  language = {en},
  number = {2}
}

@article{cheng2018QueryEfficient,
  title = {Query-{{Efficient Hard}}-Label {{Black}}-Box {{Attack}}:{{An Optimization}}-Based {{Approach}}},
  shorttitle = {Query-{{Efficient Hard}}-Label {{Black}}-Box {{Attack}}},
  author = {Cheng, Minhao and Le, Thong and Chen, Pin-Yu and Yi, Jinfeng and Zhang, Huan and Hsieh, Cho-Jui},
  year = {2018},
  month = jul,
  abstract = {We study the problem of attacking a machine learning model in the hard-label black-box setting, where no model information is revealed except that the attacker can make queries to probe the corresponding hard-label decisions. This is a very challenging problem since the direct extension of state-of-the-art white-box attacks (e.g., CW or PGD) to the hard-label black-box setting will require minimizing a non-continuous step function, which is combinatorial and cannot be solved by a gradient-based optimizer. The only current approach is based on random walk on the boundary, which requires lots of queries and lacks convergence guarantees. We propose a novel way to formulate the hard-label black-box attack as a real-valued optimization problem which is usually continuous and can be solved by any zeroth order optimization algorithm. For example, using the Randomized Gradient-Free method, we are able to bound the number of iterations needed for our algorithm to achieve stationary points. We demonstrate that our proposed method outperforms the previous random walk approach to attacking convolutional neural networks on MNIST, CIFAR, and ImageNet datasets. More interestingly, we show that the proposed algorithm can also be used to attack other discrete and non-continuous machine learning models, such as Gradient Boosting Decision Trees (GBDT).},
  archivePrefix = {arXiv},
  eprint = {1807.04457},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cheng et al (2018) - Query-Efficient Hard-label Black-box Attack.pdf},
  journal = {arXiv:1807.04457 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{cherapanamjeri2019Fast,
  title = {Fast {{Mean Estimation}} with {{Sub}}-{{Gaussian Rates}}},
  author = {Cherapanamjeri, Yeshwanth and Flammarion, Nicolas and Bartlett, Peter L.},
  year = {2019},
  month = feb,
  abstract = {We propose an estimator for the mean of a random vector in Rd that can be computed in time O(n4 + n2d) for n i.i.d. samples and that has error bounds matching the sub-Gaussian case. The only assumptions we make about the data distribution are that it has finite mean and covariance; in particular, we make no assumptions about higher-order moments. Like the polynomial time estimator introduced by [Hop18], which is based on the sum-of-squares hierarchy, our estimator achieves optimal statistical efficiency in this challenging setting, but it has a significantly faster runtime and a simpler analysis.},
  archivePrefix = {arXiv},
  eprint = {1902.01998},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cherapanamjeri et al (2019) - Fast Mean Estimation with Sub-Gaussian Rates.pdf},
  journal = {arXiv:1902.01998 [cs, math, stat]},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, math, stat}
}

@article{chernozhukov2015MongeKantorovich,
  title = {Monge-{{Kantorovich Depth}}, {{Quantiles}}, {{Ranks}}, and {{Signs}}},
  author = {Chernozhukov, Victor and Galichon, Alfred and Hallin, Marc and Henry, Marc},
  year = {2015},
  month = sep,
  abstract = {We propose new concepts of statistical depth, multivariate quantiles, ranks and signs, based on canonical transportation maps between a distribution of interest on \$R\^d\$ and a reference distribution on the \$d\$-dimensional unit ball. The new depth concept, called Monge-Kantorovich depth, specializes to halfspace depth in the case of spherical distributions, but, for more general distributions, differs from the latter in the ability for its contours to account for non convex features of the distribution of interest. We propose empirical counterparts to the population versions of those Monge-Kantorovich depth contours, quantiles, ranks and signs, and show their consistency by establishing a uniform convergence property for empirical transport maps, which is of independent interest.},
  archivePrefix = {arXiv},
  eprint = {1412.8434},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chernozhukov et al (2015) - Monge-Kantorovich Depth, Quantiles, Ranks, and Signs.pdf},
  journal = {arXiv:1412.8434 [econ, math, stat]},
  keywords = {Economics - Econometrics,Mathematics - Statistics Theory},
  primaryClass = {econ, math, stat}
}

@article{chi2018Nonconvex,
  title = {Nonconvex {{Optimization Meets Low}}-{{Rank Matrix Factorization}}: {{An Overview}}},
  shorttitle = {Nonconvex {{Optimization Meets Low}}-{{Rank Matrix Factorization}}},
  author = {Chi, Yuejie and Lu, Yue M. and Chen, Yuxin},
  year = {2018},
  month = sep,
  abstract = {Substantial progress has been made recently on developing provably accurate
and efficient algorithms for low-rank matrix factorization via nonconvex
optimization. While conventional wisdom often takes a dim view of nonconvex
optimization algorithms due to their susceptibility to spurious local minima,
simple iterative methods such as gradient descent have been remarkably
successful in practice. The theoretical footings, however, had been largely
lacking until recently.
  In this tutorial-style overview, we highlight the important role of
statistical models in enabling efficient nonconvex optimization with
performance guarantees. We review two contrasting approaches: (1) two-stage
algorithms, which consist of a tailored initialization step followed by
successive refinement; and (2) global landscape analysis and
initialization-free algorithms. Several canonical matrix factorization problems
are discussed, including but not limited to matrix sensing, phase retrieval,
matrix completion, blind deconvolution, robust principal component analysis,
phase synchronization, and joint alignment. Special care is taken to illustrate
the key technical insights underlying their analyses. This article serves as a
testament that the integrated thinking of optimization and statistics leads to
fruitful research findings.},
  file = {/Users/yuekai/Documents/zotero/Chi et al (2018) - Nonconvex Optimization Meets Low-Rank Matrix Factorization.pdf},
  language = {en}
}

@article{chi2020Asymptotic,
  title = {Asymptotic {{Properties}} of {{High}}-{{Dimensional Random Forests}}},
  author = {Chi, Chien-Ming and Vossler, Patrick and Fan, Yingying and Lv, Jinchi},
  year = {2020},
  month = apr,
  abstract = {As a flexible nonparametric learning tool, random forest has been widely applied to various real applications with appealing empirical performance, even in the presence of high-dimensional feature space. Unveiling the underlying mechanisms has led to some important recent theoretical results on consistency under the classical setting of fixed dimensionality or for some modified version of the random forest algorithm. Yet the consistency rates of the original version of the random forest algorithm in a general high-dimensional nonparametric regression setting remain largely unexplored. In this paper, we fill such a gap and build a high-dimensional consistency theory for random forest. Our new theoretical results show that random forest can indeed adapt to high dimensions and also provide some insights into the role of sparsity from the perspective of feature relevance.},
  archivePrefix = {arXiv},
  eprint = {2004.13953},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chi et al (2020) - Asymptotic Properties of High-Dimensional Random Forests.pdf},
  journal = {arXiv:2004.13953 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{chiappa2019PathSpecific,
  title = {Path-{{Specific Counterfactual Fairness}}},
  author = {Chiappa, Silvia},
  year = {2019},
  month = jul,
  volume = {33},
  pages = {7801--7808},
  issn = {2374-3468},
  doi = {10.1609/aaai.v33i01.33017801},
  abstract = {We consider the problem of learning fair decision systems from data in which a sensitive attribute might affect the decision along both fair and unfair pathways. We introduce a counterfactual approach to disregard effects along unfair pathways that does not incur in the same loss of individual-specific information as previous approaches. Our method corrects observations adversely affected by the sensitive attribute, and uses these to form a decision. We leverage recent developments in deep learning and approximate inference to develop a VAE-type method that is widely applicable to complex nonlinear models.},
  copyright = {Copyright (c) 2019 Association for the Advancement of Artificial Intelligence},
  file = {/Users/yuekai/Documents/zotero/Chiappa (2019) - Path-Specific Counterfactual Fairness.pdf},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  language = {en},
  number = {01}
}

@inproceedings{chiappa2020General,
  title = {A {{General Approach}} to {{Fairness}} with {{Optimal Transport}}},
  booktitle = {Thirty-{{Fourth AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Chiappa, Silvia and Jiang, Ray and Stepleton, Tom and Pacchiano, Aldo and Jiang, Heinrich and Aslanides, John},
  year = {2020},
  pages = {8},
  abstract = {We propose a general approach to fairness based on transporting distributions corresponding to different sensitive attributes to a common distribution. We use optimal transport theory to derive target distributions and methods that allow us to achieve fairness with minimal changes to the unfair model. Our approach is applicable to both classification and regression problems, can enforce different notions of fairness, and enable us to achieve a Pareto-optimal trade-off between accuracy and fairness. We demonstrate that it outperforms previous approaches in several benchmark fairness datasets.},
  file = {/Users/yuekai/Documents/zotero/Chiappa et al (2020) - A General Approach to Fairness with Optimal Transport.pdf},
  language = {en}
}

@article{chiappori2010Hedonic,
  title = {Hedonic Price Equilibria, Stable Matching, and Optimal Transport: Equivalence, Topology, and Uniqueness},
  shorttitle = {Hedonic Price Equilibria, Stable Matching, and Optimal Transport},
  author = {Chiappori, Pierre-Andr{\'e} and McCann, Robert J. and Nesheim, Lars P.},
  year = {2010},
  month = feb,
  volume = {42},
  pages = {317--354},
  issn = {1432-0479},
  doi = {10.1007/s00199-009-0455-z},
  abstract = {Hedonic pricing with quasi-linear preferences is shown to be equivalent to stable matching with transferable utilities and a participation constraint, and to an optimal transportation (Monge\textendash Kantorovich) linear programming problem. Optimal assignments in the latter correspond to stable matchings, and to hedonic equilibria. These assignments are shown to exist in great generality; their marginal indirect payoffs with respect to agent type are shown to be unique whenever direct payoffs vary smoothly with type. Under a generalized Spence-Mirrlees condition (also known as a twist condition) the assignments are shown to be unique and to be pure, meaning the matching is one-to-one outside a negligible set. For smooth problems set on compact, connected type spaces such as the circle, there is a topological obstruction to purity, but we give a weaker condition still guaranteeing uniqueness of the stable match.},
  file = {/Users/yuekai/Documents/zotero/Chiappori et al (2010) - Hedonic price equilibria, stable matching, and optimal transport.pdf},
  journal = {Economic Theory},
  language = {en},
  number = {2}
}

@article{chiquet2017Structured,
  title = {Structured Regularization for Conditional {{Gaussian}} Graphical Models},
  author = {Chiquet, Julien and {Mary-Huard}, Tristan and Robin, St{\'e}phane},
  year = {2017},
  month = may,
  volume = {27},
  pages = {789--804},
  issn = {1573-1375},
  doi = {10.1007/s11222-016-9654-1},
  abstract = {Conditional Gaussian graphical models are a reparametrization of the multivariate linear regression model which explicitly exhibits (i) the partial covariances between the predictors and the responses, and (ii) the partial covariances between the responses themselves. Such models are particularly suitable for interpretability since partial covariances describe direct relationships between variables. In this framework, we propose a regularization scheme to enhance the learning strategy of the model by driving the selection of the relevant input features by prior structural information. It comes with an efficient alternating optimization procedure which is guaranteed to converge to the global minimum. On top of showing competitive performance on artificial and real datasets, our method demonstrates capabilities for fine interpretation, as illustrated on three high-dimensional datasets from spectroscopy, genetics, and genomics.},
  file = {/Users/yuekai/Documents/zotero/Chiquet et al (2017) - Structured regularization for conditional Gaussian graphical models.pdf},
  journal = {Statistics and Computing},
  language = {en},
  number = {3}
}

@incollection{chizat2018Globala,
  title = {On the {{Global Convergence}} of {{Gradient Descent}} for {{Over}}-Parameterized {{Models}} Using {{Optimal Transport}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 31},
  author = {Chizat, L{\'e}na{\"i}c and Bach, Francis},
  editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and {Cesa-Bianchi}, N. and Garnett, R.},
  year = {2018},
  pages = {3036--3046},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/yuekai/Documents/zotero/Chizat, Bach (2018) - On the Global Convergence of Gradient Descent for Over-parameterized Models.pdf;/Users/yuekai/Zotero/storage/SI2ET9TQ/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-.html}
}

@article{chizat2018Note,
  title = {A {{Note}} on {{Lazy Training}} in {{Supervised Differentiable Programming}}},
  author = {Chizat, L{\'e}na{\"i}c and Bach, Francis},
  year = {2018},
  month = dec,
  pages = {18},
  abstract = {In a series of recent theoretical work, it has been shown that strongly over-parameterized neural networks trained with gradient-based methods could converge linearly to zero training loss, with their parameters hardly varying. In this note, our goal is to exhibit the simple structure that is behind these results. In a simplified setting, we prove that ``lazy training'' essentially solves a kernel regression. We also show that this behavior is not so much due to over-parameterization than to a choice of scaling, often implicit, that allows to linearize the model around its initialization. These theoretical results complemented with simple numerical experiments make it seem unlikely that ``lazy training'' is behind the many successes of neural networks in high dimensional tasks.},
  file = {/Users/yuekai/Documents/zotero/Chizat, Bach (2018) - A Note on Lazy Training in Supervised Diﬀerentiable Programming.pdf},
  language = {en}
}

@article{chizat2019Lazy,
  title = {On {{Lazy Training}} in {{Differentiable Programming}}},
  author = {Chizat, Lenaic and Oyallon, Edouard and Bach, Francis},
  year = {2019},
  month = jun,
  abstract = {In a series of recent theoretical works, it was shown that strongly over-parameterized neural networks trained with gradient-based methods could converge exponentially fast to zero training loss, with their parameters hardly varying. In this work, we show that this "lazy training" phenomenon is not specific to over-parameterized neural networks, and is due to a choice of scaling, often implicit, that makes the model behave as its linearization around the initialization, thus yielding a model equivalent to learning with positive-definite kernels. Through a theoretical analysis, we exhibit various situations where this phenomenon arises in non-convex optimization and we provide bounds on the distance between the lazy and linearized optimization paths. Our numerical experiments bring a critical note, as we observe that the performance of commonly used non-linear deep convolutional neural networks in computer vision degrades when trained in the lazy regime. This makes it unlikely that "lazy training" is behind the many successes of neural networks in difficult high dimensional tasks.},
  archivePrefix = {arXiv},
  eprint = {1812.07956},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chizat et al (2019) - On Lazy Training in Differentiable Programming.pdf},
  journal = {arXiv:1812.07956 [cs, math]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control},
  primaryClass = {cs, math}
}

@article{chizat2019Sparse,
  title = {Sparse {{Optimization}} on {{Measures}} with {{Over}}-Parameterized {{Gradient Descent}}},
  author = {Chizat, Lenaic},
  year = {2019},
  month = jul,
  abstract = {Minimizing a convex function of a measure with a sparsity-inducing penalty is
a typical problem arising, e.g., in sparse spikes deconvolution or two-layer
neural networks training. We show that this problem can be solved by
discretizing the measure and running non-convex gradient descent on the
positions and weights of the particles. For measures on a \$d\$-dimensional
manifold and under some non-degeneracy assumptions, this leads to a global
optimization algorithm with a complexity scaling as \$\textbackslash log(1/{$\epsilon$})\$ in the
desired accuracy \${$\epsilon\$$}, instead of \${$\epsilon\sphat\lbrace$}-d\vphantom\{\}\$ for convex methods. The
key theoretical tools are a local convergence analysis in Wasserstein space and
an analysis of a perturbed mirror descent in the space of measures. Our bounds
involve quantities that are exponential in \$d\$ which is unavoidable under our
assumptions.},
  file = {/Users/yuekai/Documents/zotero/Chizat (2019) - Sparse Optimization on Measures with Over-parameterized Gradient Descent.pdf;/Users/yuekai/Zotero/storage/XYS58RCC/1907.html},
  language = {en}
}

@article{chizat2020Implicit,
  title = {Implicit {{Bias}} of {{Gradient Descent}} for {{Wide Two}}-Layer {{Neural Networks Trained}} with the {{Logistic Loss}}},
  author = {Chizat, Lenaic and Bach, Francis},
  year = {2020},
  month = mar,
  abstract = {Neural networks trained to minimize the logistic (a.k.a. cross-entropy) loss with gradient-based methods are observed to perform well in many supervised classification tasks. Towards understanding this phenomenon, we analyze the training and generalization behavior of infinitely wide two-layer neural networks with homogeneous activations. We show that the limits of the gradient flow on exponentially tailed losses can be fully characterized as a max-margin classifier in a certain non-Hilbertian space of functions. In presence of hidden low-dimensional structures, the resulting margin is independent of the ambiant dimension, which leads to strong generalization bounds. In contrast, training only the output layer implicitly solves a kernel support vector machine, which a priori does not enjoy such an adaptivity. Our analysis of training is non-quantitative in terms of running time but we prove computational guarantees in simplified settings by showing equivalences with online mirror descent. Finally, numerical experiments suggest that our analysis describes well the practical behavior of two-layer neural networks with ReLU activation and confirm the statistical benefits of this implicit bias.},
  archivePrefix = {arXiv},
  eprint = {2002.04486},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chizat, Bach (2020) - Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks Trained.pdf},
  journal = {arXiv:2002.04486 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{choe2020Empirical,
  title = {An {{Empirical Study}} of {{Invariant Risk Minimization}}},
  author = {Choe, Yo Joong and Ham, Jiyeon and Park, Kyubyong},
  year = {2020},
  month = apr,
  abstract = {Invariant risk minimization (IRM; Arjovsky et al., 2019) is a recently proposed framework designed for learning predictors that are invariant to spurious correlations across different training environments. Because IRM does not assume that the test data is identically distributed as the training data, it can allow models to learn invariances that generalize well on unseen and out-of-distribution (OOD) samples. Yet, despite this theoretical justification, IRM has not been extensively tested across various settings. In an attempt to gain a better understanding of IRM, we empirically investigate several research questions using IRMv1, which is the first practical algorithm proposed in (Arjovsky et al., 2019) to approximately solve IRM. By extending the ColoredMNIST experiment from (Arjovsky et al., 2019) in multiple ways, we find that IRMv1 (i) performs better as the spurious correlation varies more widely between training environments, (ii) learns an approximately invariant predictor when the underlying relationship is approximately invariant, and (iii) can be extended to multiple environments, multiple outcomes, and different modalities (i.e., text). We hope that this work will shed light on the characteristics of IRM and help with applying IRM to real-world OOD generalization tasks.},
  archivePrefix = {arXiv},
  eprint = {2004.05007},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Choe et al (2020) - An Empirical Study of Invariant Risk Minimization.pdf},
  journal = {arXiv:2004.05007 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{chouldechova2017Fair,
  title = {Fair Prediction with Disparate Impact: {{A}} Study of Bias in Recidivism Prediction Instruments},
  shorttitle = {Fair Prediction with Disparate Impact},
  author = {Chouldechova, Alexandra},
  year = {2017},
  month = feb,
  abstract = {Recidivism prediction instruments (RPI's) provide decision makers with an assessment of the likelihood that a criminal defendant will reoffend at a future point in time. While such instruments are gaining increasing popularity across the country, their use is attracting tremendous controversy. Much of the controversy concerns potential discriminatory bias in the risk assessments that are produced. This paper discusses several fairness criteria that have recently been applied to assess the fairness of recidivism prediction instruments. We demonstrate that the criteria cannot all be simultaneously satisfied when recidivism prevalence differs across groups. We then show how disparate impact can arise when a recidivism prediction instrument fails to satisfy the criterion of error rate balance.},
  archivePrefix = {arXiv},
  eprint = {1703.00056},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chouldechova (2017) - Fair prediction with disparate impact.pdf},
  journal = {arXiv:1703.00056 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Statistics - Applications,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{chouldechova2018Frontiers,
  title = {The {{Frontiers}} of {{Fairness}} in {{Machine Learning}}},
  author = {Chouldechova, Alexandra and Roth, Aaron},
  year = {2018},
  month = oct,
  abstract = {The last few years have seen an explosion of academic and popular interest in algorithmic fairness. Despite this interest and the volume and velocity of work that has been produced recently, the fundamental science of fairness in machine learning is still in a nascent state. In March 2018, we convened a group of experts as part of a CCC visioning workshop to assess the state of the field, and distill the most promising research directions going forward. This report summarizes the findings of that workshop. Along the way, it surveys recent theoretical work in the field and points towards promising directions for research.},
  archivePrefix = {arXiv},
  eprint = {1810.08810},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chouldechova, Roth (2018) - The Frontiers of Fairness in Machine Learning.pdf},
  journal = {arXiv:1810.08810 [cs, stat]},
  keywords = {Computer Science - Computer Science and Game Theory,Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{christiano2017Deep,
  title = {Deep Reinforcement Learning from Human Preferences},
  author = {Christiano, Paul and Leike, Jan and Brown, Tom B. and Martic, Miljan and Legg, Shane and Amodei, Dario},
  year = {2017},
  month = jun,
  abstract = {For sophisticated reinforcement learning (RL) systems to interact usefully with real-world environments, we need to communicate complex goals to these systems. In this work, we explore goals defined in terms of (non-expert) human preferences between pairs of trajectory segments. We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on less than one percent of our agent's interactions with the environment. This reduces the cost of human oversight far enough that it can be practically applied to state-of-the-art RL systems. To demonstrate the flexibility of our approach, we show that we can successfully train complex novel behaviors with about an hour of human time. These behaviors and environments are considerably more complex than any that have been previously learned from human feedback.},
  archivePrefix = {arXiv},
  eprint = {1706.03741},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Christiano et al (2017) - Deep reinforcement learning from human preferences.pdf},
  journal = {arXiv:1706.03741 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{chu2011Contextual,
  title = {Contextual {{Bandits}} with {{Linear Payoff Functions}}},
  booktitle = {Proceedings of the 14th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}} ({{AISTATS}})},
  author = {Chu, Wei and Li, Lihong and Reyzin, Lev and Schapire, Robert E},
  year = {2011},
  pages = {7},
  address = {{Fort Lauderdale, FL, USA}},
  abstract = {In this paper we study the contextual bandit problem (also known as the multi-armed bandit problem with expert advice) for linear payoff functions. For T rounds, K actions, and d dimensional feature vectors, we prove an O T d ln3(KT ln(T )/{$\delta$}) regret bound that holds with probability 1 - {$\delta$} for the simplest known (both conceptually and computationally) efficient upper confidence bound algorithm for this pro{$\surd$}blem. We also prove a lower bound of {$\Omega$}( T d) for this setting, matching the upper bound up to logarithmic factors.},
  file = {/Users/yuekai/Documents/zotero/Chu et al (2011) - Contextual Bandits with Linear Payoﬀ Functions.pdf},
  language = {en}
}

@article{chu2019Probability,
  title = {Probability {{Functional Descent}}: {{A Unifying Perspective}} on {{GANs}}, {{Variational Inference}}, and {{Reinforcement Learning}}},
  shorttitle = {Probability {{Functional Descent}}},
  author = {Chu, Casey and Blanchet, Jose and Glynn, Peter},
  year = {2019},
  month = may,
  abstract = {This paper provides a unifying view of a wide range of problems of interest in machine learning by framing them as the minimization of functionals defined on the space of probability measures. In particular, we show that generative adversarial networks, variational inference, and actor-critic methods in reinforcement learning can all be seen through the lens of our framework. We then discuss a generic optimization algorithm for our formulation, called probability functional descent (PFD), and show how this algorithm recovers existing methods developed independently in the settings mentioned earlier.},
  archivePrefix = {arXiv},
  eprint = {1901.10691},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chu et al (2019) - Probability Functional Descent.pdf},
  journal = {arXiv:1901.10691 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{chzhen2020Leveraging,
  title = {Leveraging {{Labeled}} and {{Unlabeled Data}} for {{Consistent Fair Binary Classification}}},
  author = {Chzhen, Evgenii and Denis, Christophe and Hebiri, Mohamed and Oneto, Luca and Pontil, Massimiliano},
  year = {2020},
  month = feb,
  abstract = {We study the problem of fair binary classification using the notion of Equal Opportunity. It requires the true positive rate to distribute equally across the sensitive groups. Within this setting we show that the fair optimal classifier is obtained by recalibrating the Bayes classifier by a group-dependent threshold. We provide a constructive expression for the threshold. This result motivates us to devise a plug-in classification procedure based on both unlabeled and labeled datasets. While the latter is used to learn the output conditional probability, the former is used for calibration. The overall procedure can be computed in polynomial time and it is shown to be statistically consistent both in terms of the classification error and fairness measure. Finally, we present numerical experiments which indicate that our method is often superior or competitive with the state-of-the-art methods on benchmark datasets.},
  archivePrefix = {arXiv},
  eprint = {1906.05082},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Chzhen et al (2020) - Leveraging Labeled and Unlabeled Data for Consistent Fair Binary Classification.pdf},
  journal = {arXiv:1906.05082 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {math, stat}
}

@article{cisse2017Parseval,
  title = {Parseval {{Networks}}: {{Improving Robustness}} to {{Adversarial Examples}}},
  shorttitle = {Parseval {{Networks}}},
  author = {Cisse, Moustapha and Bojanowski, Piotr and Grave, Edouard and Dauphin, Yann and Usunier, Nicolas},
  year = {2017},
  month = apr,
  abstract = {We introduce Parseval networks, a form of deep neural networks in which the Lipschitz constant of linear, convolutional and aggregation layers is constrained to be smaller than 1. Parseval networks are empirically and theoretically motivated by an analysis of the robustness of the predictions made by deep neural networks when their input is subject to an adversarial perturbation. The most important feature of Parseval networks is to maintain weight matrices of linear and convolutional layers to be (approximately) Parseval tight frames, which are extensions of orthogonal matrices to non-square matrices. We describe how these constraints can be maintained efficiently during SGD. We show that Parseval networks match the state-of-the-art in terms of accuracy on CIFAR-10/100 and Street View House Numbers (SVHN) while being more robust than their vanilla counterpart against adversarial examples. Incidentally, Parseval networks also tend to train faster and make a better usage of the full capacity of the networks.},
  archivePrefix = {arXiv},
  eprint = {1704.08847},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cisse et al (2017) - Parseval Networks.pdf},
  journal = {arXiv:1704.08847 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@techreport{citron2014Scored,
  title = {The {{Scored Society}}: {{Due Process}} for {{Automated Predictions}}},
  shorttitle = {The {{Scored Society}}},
  author = {Citron, Danielle Keats and Pasquale, Frank A.},
  year = {2014},
  address = {{Rochester, NY}},
  institution = {{Social Science Research Network}},
  abstract = {Big Data is increasingly mined to rank and rate individuals. Predictive algorithms assess whether we are good credit risks, desirable employees, reliable tenants, valuable customers \textemdash{} or deadbeats, shirkers, menaces, and ``wastes of time.'' Crucial opportunities are on the line, including the ability to obtain loans, work, housing, and insurance. Though automated scoring is pervasive and consequential, it is also opaque and lacking oversight.  In one area where regulation does prevail \textemdash{} credit \textemdash{} the law focuses on credit history, not the derivation of scores from data.},
  keywords = {artificial intelligence,Big Data,predictions},
  language = {en},
  number = {ID 2376209},
  type = {{{SSRN Scholarly Paper}}}
}

@article{clarkson2012Low,
  title = {Low {{Rank Approximation}} and {{Regression}} in {{Input Sparsity Time}}},
  author = {Clarkson, Kenneth L. and Woodruff, David P.},
  year = {2012},
  month = jul,
  abstract = {We design a new distribution over \$\textbackslash poly(r \textbackslash eps\^\{-1\}) \textbackslash times n\$ matrices \$S\$ so that for any fixed \$n \textbackslash times d\$ matrix \$A\$ of rank \$r\$, with probability at least 9/10, \$\textbackslash norm\{SAx\}\_2 = (1 \textbackslash pm \textbackslash eps)\textbackslash norm\{Ax\}\_2\$ simultaneously for all \$x \textbackslash in \textbackslash mathbb\{R\}\^d\$. Such a matrix \$S\$ is called a \textbackslash emph\{subspace embedding\}. Furthermore, \$SA\$ can be computed in \$\textbackslash nnz(A) + \textbackslash poly(d \textbackslash eps\^\{-1\})\$ time, where \$\textbackslash nnz(A)\$ is the number of non-zero entries of \$A\$. This improves over all previous subspace embeddings, which required at least \$\textbackslash Omega(nd \textbackslash log d)\$ time to achieve this property. We call our matrices \$S\$ \textbackslash emph\{sparse embedding matrices\}. Using our sparse embedding matrices, we obtain the fastest known algorithms for \$(1+\textbackslash eps)\$-approximation for overconstrained least-squares regression, low-rank approximation, approximating all leverage scores, and \$\textbackslash ell\_p\$-regression. The leading order term in the time complexity of our algorithms is \$O(\textbackslash nnz(A))\$ or \$O(\textbackslash nnz(A)\textbackslash log n)\$. We optimize the low-order \$\textbackslash poly(d/\textbackslash eps)\$ terms in our running times (or for rank-\$k\$ approximation, the \$n*\textbackslash poly(k/eps)\$ term), and show various tradeoffs. For instance, we also use our methods to design new preconditioners that improve the dependence on \$\textbackslash eps\$ in least squares regression to \$\textbackslash log 1/\textbackslash eps\$. Finally, we provide preliminary experimental results which suggest that our algorithms are competitive in practice.},
  archivePrefix = {arXiv},
  eprint = {1207.6365},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Clarkson, Woodruff (2012) - Low Rank Approximation and Regression in Input Sparsity Time.pdf},
  journal = {arXiv:1207.6365 [cs]},
  keywords = {Computer Science - Data Structures and Algorithms},
  primaryClass = {cs}
}

@article{clason2020Introduction,
  title = {Introduction to {{Nonsmooth Analysis}} and {{Optimization}}},
  author = {Clason, Christian and Valkonen, Tuomo},
  year = {2020},
  month = aug,
  abstract = {These notes aim to give an introduction to generalized derivative concepts useful in deriving necessary optimality conditions and numerical algorithms for infinite-dimensional nondifferentiable optimization problems that arise in inverse problems, imaging, and PDE-constrained optimization. They cover convex subdifferentials, Fenchel duality, monotone operators and resolvents, Moreau--Yosida regularization as well as Clarke and (briefly) limiting subdifferentials. Both first-order (proximal point and splitting) methods and second-order (semismooth Newton) methods are treated. In addition, differentiation of set-valued mapping is discussed and used for deriving second-order optimality condition. The required background from functional analysis and calculus of variations is also briefly summarized.},
  archivePrefix = {arXiv},
  eprint = {2001.00216},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Clason, Valkonen (2020) - Introduction to Nonsmooth Analysis and Optimization.pdf;/Users/yuekai/Zotero/storage/RYEGL2NR/2001.html},
  journal = {arXiv:2001.00216 [math]},
  keywords = {Mathematics - Optimization and Control},
  primaryClass = {math}
}

@article{coate1993Will,
  title = {Will {{Affirmative}}-{{Action Policies Eliminate Negative Stereotypes}}?},
  author = {Coate, Stephen and Loury, Glenn C.},
  year = {1993},
  volume = {83},
  pages = {1220--1240},
  issn = {0002-8282},
  abstract = {A key question concerning affirmative action is whether the labor-market gains it brings to minorities can continue without it becoming a permanent fixture in the labor market. We argue that this depends on how the policy affects employers' beliefs about the productivity of minority workers. We study the joint determination of employer beliefs and worker productivity in a model of statistical discrimination in job assignments. We prove that, even when identifiable groups are equally endowed ex ante, affirmative action can bring about a situation in which employers (correctly) perceive the groups to be unequally productive, ex post.},
  file = {/Users/yuekai/Documents/zotero/Coate Loury (1993) - Will Affirmative-Action Policies Eliminate Negative Stereotypes.pdf},
  journal = {The American Economic Review},
  number = {5}
}

@inproceedings{cohen2016Featurebased,
  title = {Feature-Based {{Dynamic Pricing}}},
  booktitle = {Proceedings of the 2016 {{ACM Conference}} on {{Economics}} and {{Computation}}},
  author = {Cohen, Maxime and Lobel, Ilan and Leme, Renato Paes},
  year = {2016},
  file = {/Users/yuekai/Documents/zotero/Cohen et al (2016) - Feature-based Dynamic Pricing.pdf}
}

@article{cohn1994Improving,
  title = {Improving {{Generalization}} with {{Active Learning}}},
  author = {Cohn, David and Atlas, Les and Ladner, Richard},
  year = {1994},
  month = may,
  volume = {15},
  pages = {201--221},
  issn = {0885-6125},
  doi = {10.1023/A:1022673506211},
  abstract = {Active learning differs from ``learning from examples'' in that the learning algorithm assumes at least some control over what part of the input domain it receives information about. In some situations, active learning is provably more powerful than learning from examples alone, giving better generalization for a fixed number of training examples. In this article, we consider the problem of learning a binary concept in the absence of noise. We describe a formalism for active concept learning called selective sampling and show how it may be approximately implemented by a neural network. In selective sampling, a learner receives distribution information from the environment and queries an oracle on parts of the domain it considers ``useful.'' We test our implementation, called an SG-network, on three domains and observe significant improvement in generalization.},
  file = {/Users/yuekai/Documents/zotero/Cohn et al (1994) - Improving Generalization with Active Learning.pdf},
  journal = {Machine Language},
  keywords = {active learning,generalization,neural networks,queries,version space},
  number = {2}
}

@article{coifman2005Geometric,
  title = {Geometric Diffusions as a Tool for Harmonic Analysis and Structure Definition of Data: {{Diffusion}} Maps},
  shorttitle = {Geometric Diffusions as a Tool for Harmonic Analysis and Structure Definition of Data},
  author = {Coifman, R. R. and Lafon, S. and Lee, A. B. and Maggioni, M. and Nadler, B. and Warner, F. and Zucker, S. W.},
  year = {2005},
  month = may,
  volume = {102},
  pages = {7426--7431},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0500334102},
  abstract = {We provide a framework for structural multiscale geometric organization of graphs and subsets of {$<$}img class="highwire-embed tex" alt="Math" src="https://www.pnas.org/sites/default/files/highwire/pnas/102/21/7426/embed/tex-math-1.gif"/{$>$}. We use diffusion semigroups to generate multiscale geometries in order to organize and represent complex structures. We show that appropriately selected eigenfunctions or scaling functions of Markov matrices, which describe local transitions, lead to macroscopic descriptions at different scales. The process of iterating or diffusing the Markov matrix is seen as a generalization of some aspects of the Newtonian paradigm, in which local infinitesimal transitions of a system lead to global macroscopic descriptions by integration. We provide a unified view of ideas from data analysis, machine learning, and numerical analysis.},
  copyright = {Copyright \textcopyright{} 2005, The National Academy of Sciences},
  file = {/Users/yuekai/Documents/zotero/Coifman et al (2005) - Geometric diffusions as a tool for harmonic analysis and structure definition.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {21},
  pmid = {15899970}
}

@article{coker2018Theory,
  title = {A {{Theory}} of {{Statistical Inference}} for {{Ensuring}} the {{Robustness}} of {{Scientific Results}}},
  author = {Coker, Beau and Rudin, Cynthia and King, Gary},
  year = {2018},
  month = apr,
  abstract = {Inference is the process of using facts we know to learn about facts we do not know. A theory of inference gives assumptions necessary to get from the former to the latter, along with a definition for and summary of the resulting uncertainty. Any one theory of inference is neither right nor wrong, but merely an axiom that may or may not be useful. Each of the many diverse theories of inference can be valuable for certain applications. However, no existing theory of inference addresses the tendency to choose, from the range of plausible data analysis specifications consistent with prior evidence, those that inadvertently favor one's own hypotheses. Since the biases from these choices are a growing concern across scientific fields, and in a sense the reason the scientific community was invented in the first place, we introduce a new theory of inference designed to address this critical problem. We derive "hacking intervals," which are the range of a summary statistic one may obtain given a class of possible endogenous manipulations of the data. Hacking intervals require no appeal to hypothetical data sets drawn from imaginary superpopulations. A scientific result with a small hacking interval is more robust to researcher manipulation than one with a larger interval, and is often easier to interpret than a classical confidence interval. Some versions of hacking intervals turn out to be equivalent to classical confidence intervals, which means they may also provide a more intuitive and potentially more useful interpretation of classical confidence intervals},
  archivePrefix = {arXiv},
  eprint = {1804.08646},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Coker et al (2018) - A Theory of Statistical Inference for Ensuring the Robustness of Scientific.pdf},
  journal = {arXiv:1804.08646 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{collaboration2015Estimating,
  title = {Estimating the Reproducibility of Psychological Science},
  author = {Collaboration, Open Science},
  year = {2015},
  month = aug,
  volume = {349},
  pages = {aac4716},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aac4716},
  abstract = {Empirically analyzing empirical evidence
One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.
Science, this issue 10.1126/science.aac4716
Structured Abstract
INTRODUCTIONReproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.
RATIONALEThere is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.
RESULTSWe conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (Mr = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (Mr = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P {$<$} .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.
CONCLUSIONNo single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that ``we already know this'' belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know. {$<$}img class="fragment-image" aria-describedby="F1-caption" src="http://science.sciencemag.org/content/sci/349/6251/aac4716/F1.medium.gif"/{$>$} Download high-res image Open in new tab Download Powerpoint Original study effect size versus replication effect size (correlation coefficients).Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.
Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.
A large-scale assessment suggests that experimental reproducibility in psychology leaves a lot to be desired.
A large-scale assessment suggests that experimental reproducibility in psychology leaves a lot to be desired.},
  copyright = {Copyright \textcopyright{} 2015, American Association for the Advancement of Science},
  file = {/Users/yuekai/Documents/zotero/Collaboration (2015) - Estimating the reproducibility of psychological science.pdf},
  journal = {Science},
  language = {en},
  number = {6251},
  pmid = {26315443}
}

@article{combes2020Domain,
  title = {Domain {{Adaptation}} with {{Conditional Distribution Matching}} and {{Generalized Label Shift}}},
  author = {des Combes, Remi Tachet and Zhao, Han and Wang, Yu-Xiang and Gordon, Geoff},
  year = {2020},
  month = mar,
  abstract = {Adversarial learning has demonstrated good performance in the unsupervised domain adaptation setting, by learning domain-invariant representations that perform well on the source domain. However, recent work has underlined limitations of existing methods in the presence of mismatched label distributions between the source and target domains. In this paper, we extend a recent upper-bound on the performance of adversarial domain adaptation to multi-class classification and more general discriminators. We then propose generalized label shift (GLS) as a way to improve robustness against mismatched label distributions. GLS states that, conditioned on the label, there exists a representation of the input that is invariant between the source and target domains. Under GLS, we provide theoretical guarantees on the transfer performance of any classifier. We also devise necessary and sufficient conditions for GLS to hold. The conditions are based on the estimation of the relative class weights between domains and on an appropriate reweighting of samples. Guided by our theoretical insights, we modify three widely used algorithms, JAN, DANN and CDAN and evaluate their performance on standard domain adaptation tasks where our method outperforms the base versions. We also demonstrate significant gains on artificially created tasks with large divergences between their source and target label distributions.},
  archivePrefix = {arXiv},
  eprint = {2003.04475},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Combes et al (2020) - Domain Adaptation with Conditional Distribution Matching and Generalized Label.pdf},
  journal = {arXiv:2003.04475 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{cook2016Lower,
  title = {Lower Bounds for the Smallest Singular Value of Structured Random Matrices},
  author = {Cook, Nicholas A.},
  year = {2016},
  month = aug,
  abstract = {We obtain lower tail estimates for the smallest singular value of random matrices with independent but non-identically distributed entries. Specifically, we consider \$n\textbackslash times n\$ matrices with complex entries of the form \textbackslash [ M = A\textbackslash circ X + B = (a\_\{ij\}\textbackslash xi\_\{ij\} + b\_\{ij\}) \textbackslash ] where \$X=(\textbackslash xi\_\{ij\})\$ has iid centered entries of unit variance and \$A\$ and \$B\$ are fixed matrices. In our main result we obtain polynomial bounds on the smallest singular value of \$M\$ for the case that \$A\$ has bounded (possibly zero) entries, and \$B= Z\textbackslash sqrt\{n\}\$ where \$Z\$ is a diagonal matrix with entries bounded away from zero. As a byproduct of our methods we can also handle general perturbations \$B\$ under additional hypotheses on \$A\$, which translate to connectivity hypotheses on an associated graph. In particular, we extend a result of Rudelson and Zeitouni for Gaussian matrices to allow for general entry distributions satisfying some moment hypotheses. Our proofs make use of tools which (to our knowledge) were previously unexploited in random matrix theory, in particular Szemer\textbackslash 'edi's Regularity Lemma, and a version of the Restricted Invertibility Theorem due to Spielman and Srivastava.},
  archivePrefix = {arXiv},
  eprint = {1608.07347},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cook (2016) - Lower bounds for the smallest singular value of structured random matrices.pdf},
  journal = {arXiv:1608.07347 [math]},
  keywords = {Mathematics - Probability},
  primaryClass = {math}
}

@article{corbett-davies2017Algorithmic,
  title = {Algorithmic Decision Making and the Cost of Fairness},
  author = {{Corbett-Davies}, Sam and Pierson, Emma and Feller, Avi and Goel, Sharad and Huq, Aziz},
  year = {2017},
  month = jan,
  doi = {10.1145/3097983.309809},
  abstract = {Algorithms are now regularly used to decide whether defendants awaiting trial are too dangerous to be released back into the community. In some cases, black defendants are substantially more likely than white defendants to be incorrectly classified as high risk. To mitigate such disparities, several techniques recently have been proposed to achieve algorithmic fairness. Here we reformulate algorithmic fairness as constrained optimization: the objective is to maximize public safety while satisfying formal fairness constraints designed to reduce racial disparities. We show that for several past definitions of fairness, the optimal algorithms that result require detaining defendants above race-specific risk thresholds. We further show that the optimal unconstrained algorithm requires applying a single, uniform threshold to all defendants. The unconstrained algorithm thus maximizes public safety while also satisfying one important understanding of equality: that all individuals are held to the same standard, irrespective of race. Because the optimal constrained and unconstrained algorithms generally differ, there is tension between improving public safety and satisfying prevailing notions of algorithmic fairness. By examining data from Broward County, Florida, we show that this trade-off can be large in practice. We focus on algorithms for pretrial release decisions, but the principles we discuss apply to other domains, and also to human decision makers carrying out structured decision rules.},
  archivePrefix = {arXiv},
  eprint = {1701.08230},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Corbett-Davies et al (2017) - Algorithmic decision making and the cost of fairness.pdf},
  journal = {arXiv:1701.08230 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Statistics - Applications},
  primaryClass = {cs, stat}
}

@article{corbett-davies2018Measure,
  title = {The {{Measure}} and {{Mismeasure}} of {{Fairness}}: {{A Critical Review}} of {{Fair Machine Learning}}},
  shorttitle = {The {{Measure}} and {{Mismeasure}} of {{Fairness}}},
  author = {{Corbett-Davies}, Sam and Goel, Sharad},
  year = {2018},
  month = jul,
  abstract = {The nascent field of fair machine learning aims to ensure that decisions guided by algorithms are equitable. Over the last several years, three formal definitions of fairness have gained prominence: (1) anti-classification, meaning that protected attributes---like race, gender, and their proxies---are not explicitly used to make decisions; (2) classification parity, meaning that common measures of predictive performance (e.g., false positive and false negative rates) are equal across groups defined by the protected attributes; and (3) calibration, meaning that conditional on risk estimates, outcomes are independent of protected attributes. Here we show that all three of these fairness definitions suffer from significant statistical limitations. Requiring anti-classification or classification parity can, perversely, harm the very groups they were designed to protect; and calibration, though generally desirable, provides little guarantee that decisions are equitable. In contrast to these formal fairness criteria, we argue that it is often preferable to treat similarly risky people similarly, based on the most statistically accurate estimates of risk that one can produce. Such a strategy, while not universally applicable, often aligns well with policy objectives; notably, this strategy will typically violate both anti-classification and classification parity. In practice, it requires significant effort to construct suitable risk estimates. One must carefully define and measure the targets of prediction to avoid retrenching biases in the data. But, importantly, one cannot generally address these difficulties by requiring that algorithms satisfy popular mathematical formalizations of fairness. By highlighting these challenges in the foundation of fair machine learning, we hope to help researchers and practitioners productively advance the area.},
  archivePrefix = {arXiv},
  eprint = {1808.00023},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Corbett-Davies, Goel (2018) - The Measure and Mismeasure of Fairness.pdf},
  journal = {arXiv:1808.00023 [cs]},
  keywords = {Computer Science - Computers and Society},
  primaryClass = {cs}
}

@article{cotter2019Optimization,
  title = {Optimization with {{Non}}-{{Differentiable Constraints}} with {{Applications}} to {{Fairness}}, {{Recall}}, {{Churn}}, and {{Other Goals}}},
  author = {Cotter, Andrew and Jiang, Heinrich and Gupta, Maya and Wang, Serena and Narayan, Taman and You, Seungil and Sridharan, Karthik},
  year = {2019},
  volume = {20},
  pages = {1--59},
  issn = {1533-7928},
  file = {/Users/yuekai/Documents/zotero/Cotter et al (2019) - Optimization with Non-Differentiable Constraints with Applications to Fairness,.pdf},
  journal = {Journal of Machine Learning Research},
  number = {172}
}

@article{courty2015Optimal,
  title = {Optimal {{Transport}} for {{Domain Adaptation}}},
  author = {Courty, Nicolas and Flamary, R{\'e}mi and Tuia, Devis and Rakotomamonjy, Alain},
  year = {2015},
  month = jul,
  abstract = {Domain adaptation from one data space (or domain) to another is one of the most challenging tasks of modern data analytics. If the adaptation is done correctly, models built on a specific data space become more robust when confronted to data depicting the same semantic concepts (the classes), but observed by another observation system with its own specificities. Among the many strategies proposed to adapt a domain to another, finding a common representation has shown excellent properties: by finding a common representation for both domains, a single classifier can be effective in both and use labelled samples from the source domain to predict the unlabelled samples of the target domain. In this paper, we propose a regularized unsupervised optimal transportation model to perform the alignment of the representations in the source and target domains. We learn a transportation plan matching both PDFs, which constrains labelled samples in the source domain to remain close during transport. This way, we exploit at the same time the few labeled information in the source and the unlabelled distributions observed in both domains. Experiments in toy and challenging real visual adaptation examples show the interest of the method, that consistently outperforms state of the art approaches.},
  archivePrefix = {arXiv},
  eprint = {1507.00504},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Courty et al (2015) - Optimal Transport for Domain Adaptation.pdf},
  journal = {arXiv:1507.00504 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{cowgill2019Economics,
  title = {Economics, {{Fairness}} and {{Algorithmic Bias}}},
  author = {Cowgill, Bo and Tucker, Catherine E.},
  year = {2019},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3361280},
  abstract = {We develop an economic perspective on algorithmic fairness. Algorithmic bias and fairness issues are appearing in an increasing variety of economic research literatures. Our perspective draws from obvious connections to the economics of discrimination, crime, personnel and technological innovation; as well as less obvious connections to environmental economics, product safety regulation, behavioral economics and economics of information. We survey the small but growing literature in economics that directly examines this topic theoretically and empirically. Algorithms are not only growing in social impact, but also have attractive measurement properties that ease challenges for research economists. We conclude by discussing economic policy implications and future research directions.},
  file = {/Users/yuekai/Documents/zotero/Cowgill, Tucker (2019) - Economics, Fairness and Algorithmic Bias.pdf},
  journal = {SSRN Electronic Journal},
  language = {en}
}

@article{cox2018Almost,
  title = {Almost {{Sure Uniqueness}} of a {{Global Minimum Without Convexity}}},
  author = {Cox, Gregory},
  year = {2018},
  month = mar,
  abstract = {This paper establishes the argmin of a random objective function to be unique almost surely. This paper first formulates a general result that proves almost sure uniqueness without convexity of the objective function. The general result is then applied to a variety of applications in statistics. Four applications are discussed, including uniqueness of M-estimators, both classical likelihood and penalized likelihood estimators, and two applications of the argmin theorem, threshold regression and weak identification.},
  archivePrefix = {arXiv},
  eprint = {1803.02415},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cox (2018) - Almost Sure Uniqueness of a Global Minimum Without Convexity.pdf},
  journal = {arXiv:1803.02415 [econ, math, stat]},
  keywords = {Economics - Econometrics,Mathematics - Statistics Theory},
  primaryClass = {econ, math, stat}
}

@article{craig2016exponential,
  title = {The Exponential Formula for the Wasserstein Metric},
  author = {Craig, Katy},
  year = {2016},
  month = jan,
  volume = {22},
  pages = {169--187},
  issn = {1292-8119, 1262-3377},
  doi = {10.1051/cocv/2014069},
  abstract = {Many evolutionary partial differential equations may be rewritten as the gradient flow of an energy functional, a perspective which provides useful estimates on the behavior of solutions. The notion of gradient flow requires both the specification of an energy functional and a metric with respect to which the gradient is taken. In recent years, there has been significant interest in gradient flow on the space of probability measures endowed with the Wasserstein metric. The notion of gradient in this setting in purely formal and rigorous analysis of the gradient flow problem typically considers a time discretization of the problem known as the ``discrete gradient flow''. In this dissertation, we adapt Crandall and Liggett's Banach space method to give a new proof of the exponential formula, quantifying the rate at which solutions to the discrete gradient flow converge to solutions of the gradient flow. In the process, we prove an Euler-Lagrange equation characterizing the discrete gradient flow by using a new class of metrics\textemdash transport metrics\textemdash that have stronger convexity properties than the Wasserstein metric. We then apply these results to give simple proofs of properties of the gradient flow, including the contracting semigroup property and the energy dissipation inequality.},
  file = {/Users/yuekai/Documents/zotero/Craig (2016) - The exponential formula for the wasserstein metric.pdf},
  journal = {ESAIM: Control, Optimisation and Calculus of Variations},
  language = {en},
  number = {1}
}

@techreport{craig2017Complementary,
  title = {Complementary {{Bias}}: {{A Model}} of {{Two}}-{{Sided Statistical Discrimination}}},
  shorttitle = {Complementary {{Bias}}},
  author = {Craig, Ashley and Fryer, Roland},
  year = {2017},
  month = sep,
  pages = {w23811},
  address = {{Cambridge, MA}},
  institution = {{National Bureau of Economic Research}},
  doi = {10.3386/w23811},
  abstract = {We introduce a model of two-sided statistical discrimination in which worker and firm beliefs are complementary. Firms try to infer whether workers have made investments required for them to be productive, and simultaneously, workers try to deduce whether firms have made investments necessary for them to thrive. When multiple equilibria exist, group differences are sustained by both sides of the interaction \textendash{} workers and firms. Strategic complementarity between the two sides complicates both empirical analysis designed to detect discrimination and policy meant to alleviate it. Affirmative action is much less effective than in traditional statistical discrimination models. More generally, we demonstrate the futility of policies that are designed to correct gender and racial disparities but do not address both sides of the coordination problem. We propose a two-sided version of ``investment insurance'' \textendash{} a highly effective and potentially cheap policy in which the government (after observing a noisy version of the employer's signal) offers to hire any worker who it believes to be qualified and whom the employers do not offer a job. The paper concludes by proposing a way to identify statistical discrimination by employers when beliefs are complements.},
  file = {/Users/yuekai/Documents/zotero/Craig, Fryer (2017) - Complementary Bias.pdf},
  language = {en},
  number = {w23811}
}

@article{crane2016Edge,
  title = {Edge Exchangeable Models for Network Data},
  author = {Crane, Harry and Dempsey, Walter},
  year = {2016},
  month = mar,
  file = {/Users/yuekai/Documents/zotero/Crane, Dempsey (2016) - Edge exchangeable models for network data.pdf},
  language = {en}
}

@article{creager2019Causal,
  title = {Causal {{Modeling}} for {{Fairness}} in {{Dynamical Systems}}},
  author = {Creager, Elliot and Madras, David and Pitassi, Toniann and Zemel, Richard},
  year = {2019},
  month = sep,
  abstract = {In this work, we present causal directed acyclic graphs (DAGs) as a unifying
framework for the recent literature on fairness in dynamical systems. We
advocate for the use of causal DAGs as a tool in both designing equitable
policies and estimating their impacts. By visualizing models of dynamic
unfairness graphically, we expose implicit causal assumptions which can then be
more easily interpreted and scrutinized by domain experts. We demonstrate that
this method of reinterpretation can be used to critique the robustness of an
existing model/policy, or uncover new policy evaluation questions. Causal
models also enable a rich set of options for evaluating a new candidate policy
without incurring the risk of implementing the policy in the real world. We
close the paper with causal analyses of several models from the recent
literature, and provide an in-depth case study to demonstrate the utility of
causal DAGs for modeling fairness in dynamical systems.},
  file = {/Users/yuekai/Documents/zotero/Creager et al (2019) - Causal Modeling for Fairness in Dynamical Systems.pdf},
  language = {en}
}

@article{creager2019Flexibly,
  title = {Flexibly {{Fair Representation Learning}} by {{Disentanglement}}},
  author = {Creager, Elliot and Madras, David and Jacobsen, J{\"o}rn-Henrik and Weis, Marissa A. and Swersky, Kevin and Pitassi, Toniann and Zemel, Richard},
  year = {2019},
  month = jun,
  abstract = {We consider the problem of learning representations that achieve group and subgroup fairness with respect to multiple sensitive attributes. Taking inspiration from the disentangled representation learning literature, we propose an algorithm for learning compact representations of datasets that are useful for reconstruction and prediction, but are also \textbackslash emph\{flexibly fair\}, meaning they can be easily modified at test time to achieve subgroup demographic parity with respect to multiple sensitive attributes and their conjunctions. We show empirically that the resulting encoder---which does not require the sensitive attributes for inference---enables the adaptation of a single representation to a variety of fair classification tasks with new target labels and subgroup definitions.},
  archivePrefix = {arXiv},
  eprint = {1906.02589},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Creager et al (2019) - Flexibly Fair Representation Learning by Disentanglement.pdf},
  journal = {arXiv:1906.02589 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@incollection{cuturi2013Sinkhorn,
  title = {Sinkhorn {{Distances}}: {{Lightspeed Computation}} of {{Optimal Transport}}},
  shorttitle = {Sinkhorn {{Distances}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 26},
  author = {Cuturi, Marco},
  editor = {Burges, C. J. C. and Bottou, L. and Welling, M. and Ghahramani, Z. and Weinberger, K. Q.},
  year = {2013},
  pages = {2292--2300},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/yuekai/Documents/zotero/Cuturi (2013) - Sinkhorn Distances.pdf}
}

@article{cuturi2018Semidual,
  title = {Semi-Dual {{Regularized Optimal Transport}}},
  author = {Cuturi, Marco and Peyr{\'e}, Gabriel},
  year = {2018},
  month = jan,
  volume = {60},
  pages = {941--965},
  issn = {0036-1445, 1095-7200},
  doi = {10.1137/18M1208654},
  abstract = {Variational problems that involve Wasserstein distances and more generally optimal transport (OT) theory are playing an increasingly important role in data sciences. Such problems can be used to form an examplar measure out of various probability measures, as in the Wasserstein barycenter problem, or to carry out parametric inference and density fitting, where the loss is measured in terms of an optimal transport cost to the measure of observations. Despite being conceptually simple, such problems are computationally challenging because they involve minimizing over quantities (Wasserstein distances) that are themselves hard to compute. Entropic regularization has recently emerged as an efficient tool to approximate the solution of such variational Wasserstein problems. In this paper, we give a thorough duality tour of these regularization techniques. In particular, we show how important concepts from classical OT such as c-transforms and semi-discrete approaches translate into similar ideas in a regularized setting. These dual formulations lead to smooth variational problems, which can be solved using smooth, differentiable and convex optimization problems that are simpler to implement and numerically more stable that their un-regularized counterparts. We illustrate the versatility of this approach by applying it to the computation of Wasserstein barycenters and gradient flows of spatial regularization functionals.},
  archivePrefix = {arXiv},
  eprint = {1811.05527},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Cuturi, Peyré (2018) - Semi-dual Regularized Optimal Transport.pdf},
  journal = {SIAM Review},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  number = {4}
}

@incollection{cuturi2019Differentiable,
  title = {Differentiable {{Ranking}} and {{Sorting}} Using {{Optimal Transport}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 32},
  author = {Cuturi, Marco and Teboul, Olivier and Vert, Jean-Philippe},
  editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and d{\textbackslash}textquotesingle {Alch{\'e}-Buc}, F. and Fox, E. and Garnett, R.},
  year = {2019},
  pages = {6861--6871},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/yuekai/Documents/zotero/Cuturi et al (2019) - Differentiable Ranking and Sorting using Optimal Transport.pdf;/Users/yuekai/Zotero/storage/FRKMJV8L/8910-differentiable-ranking-and-sorting-using-optimal-transport.html}
}

@phdthesis{dahl2012CONVEX,
  title = {{{CONVEX DUALITY AND MATHEMATICAL FINANCE}}},
  author = {Dahl, Kristina Rognlien},
  year = {2012},
  month = may,
  abstract = {The theme of this thesis is duality methods in mathematical  nance. This is a hot topic in the  eld of mathematical  nance, and there is currently a lot of research activity regarding this subject. However, since it is a fairly new  eld of study, a lot of the material available is technical and di cult to read. This thesis aims to connect the duality methods used in mathematical  nance to the general theory of duality methods in optimization and convexity, and hence clarify the subject. This requires the use of stochastic, real and functional analysis, as well as measure and integration theory.},
  file = {/Users/yuekai/Documents/zotero/Dahl (2012) - CONVEX DUALITY AND MATHEMATICAL FINANCE.pdf},
  language = {en},
  school = {University of Oslo}
}

@article{dai2012Deviation,
  title = {Deviation Optimal Learning Using Greedy {{Q}}-Aggregation},
  author = {Dai, Dong and Rigollet, Philippe and Zhang, Tong},
  year = {2012},
  month = jun,
  volume = {40},
  pages = {1878--1905},
  issn = {0090-5364},
  doi = {10.1214/12-AOS1025},
  abstract = {Given a finite family of functions, the goal of model selection aggregation is to construct a procedure that mimics the function from this family that is the closest to an unknown regression function. More precisely, we consider a general regression model with fixed design and measure the distance between functions by the mean squared error at the design points. While procedures based on exponential weights are known to solve the problem of model selection aggregation in expectation, they are, surprisingly, sub-optimal in deviation. We propose a new formulation called Q-aggregation that addresses this limitation; namely, its solution leads to sharp oracle inequalities that are optimal in a minimax sense. Moreover, based on the new formulation, we design greedy Q-aggregation procedures that produce sparse aggregation models achieving the optimal rate. The convergence and performance of these greedy procedures are illustrated and compared with other standard methods on simulated examples.},
  archivePrefix = {arXiv},
  eprint = {1203.2507},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Dai et al (2012) - Deviation optimal learning using greedy Q-aggregation.pdf},
  journal = {The Annals of Statistics},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  number = {3}
}

@book{daley2003introduction,
  title = {An Introduction to the Theory of Point Processes},
  author = {Daley, Daryl J. and {Vere-Jones}, D.},
  year = {2003},
  edition = {2nd ed},
  publisher = {{Springer}},
  address = {{New York}},
  file = {/Users/yuekai/Documents/zotero/Daley, Vere-Jones (2003) - An introduction to the theory of point processes.pdf},
  isbn = {978-0-387-95541-4 978-0-387-21337-8 978-0-387-49835-5},
  language = {en},
  lccn = {QA274.42 .D35 2003}
}

@article{dallanese2019Optimization,
  title = {Optimization and {{Learning}} with {{Information Streams}}: {{Time}}-Varying {{Algorithms}} and {{Applications}}},
  shorttitle = {Optimization and {{Learning}} with {{Information Streams}}},
  author = {Dall'Anese, Emiliano and Simonetto, Andrea and Becker, Stephen and Madden, Liam},
  year = {2019},
  month = oct,
  abstract = {There is a growing cross-disciplinary effort in the broad domain of optimization and learning with streams of data, applied to settings where traditional batch optimization techniques cannot produce solutions at time scales that match the inter-arrival times of the data points due to computational and/or communication bottlenecks. Special types of online algorithms can handle this situation, and this article focuses on such time-varying optimization algorithms, with emphasis on Machine Leaning and Signal Processing, as well as data-driven control. Approaches for the design of time-varying first-order methods are discussed, with emphasis on algorithms that can handle errors in the gradient, as may arise when the gradient is estimated. Insights on performance metrics and accompanying claims are provided, along with evidence of cases where algorithms that are provably convergent in batch optimization perform poorly in an online regime. The role of distributed computation is discussed. Illustrative numerical examples for a number of applications of broad interest are provided to convey key ideas.},
  archivePrefix = {arXiv},
  eprint = {1910.08123},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Dall'Anese et al (2019) - Optimization and Learning with Information Streams.pdf},
  journal = {arXiv:1910.08123 [cs, eess, math]},
  keywords = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Signal Processing,Mathematics - Optimization and Control},
  primaryClass = {cs, eess, math}
}

@article{damle2017Geometric,
  title = {A {{Geometric Approach}} to {{Archetypal Analysis}} and {{Nonnegative Matrix Factorization}}},
  author = {Damle, Anil and Sun, Yuekai},
  year = {2017},
  month = jul,
  volume = {59},
  pages = {361--370},
  issn = {0040-1706, 1537-2723},
  doi = {10.1080/00401706.2016.1247017},
  abstract = {Archetypal analysis and nonnegative matrix factorization (NMF) are staples in a statistician's toolbox for dimension reduction and exploratory data analysis. We describe a geometric approach to both NMF and archetypal analysis by interpreting both problems as finding extreme points of the data cloud. We also develop and analyze an efficient approach to finding extreme points in high dimensions. For modern massive datasets that are too large to fit on a single machine and must be stored in a distributed setting, our approach makes only a small number of passes over the data. In fact, it is possible to obtain the NMF or perform archetypal analysis with just two passes over the data.},
  file = {/Users/yuekai/Documents/zotero/Damle, Sun (2017) - A Geometric Approach to Archetypal Analysis and Nonnegative Matrix Factorization.pdf},
  journal = {Technometrics},
  language = {en},
  number = {3}
}

@article{damle2019Uniform,
  title = {Uniform Bounds for Invariant Subspace Perturbations},
  author = {Damle, Anil and Sun, Yuekai},
  year = {2019},
  month = may,
  abstract = {For a fixed matrix A and perturbation E we develop purely deterministic bounds on how invariant subspaces of A and A+E can differ when measured by a suitable "row-wise" metric rather than via traditional norms such as two or Frobenius. Understanding perturbations of invariant subspaces with respect to such metrics is becoming increasingly important across a wide variety of applications and therefore necessitates new theoretical developments. Under minimal assumptions we develop new bounds on subspace perturbations under the two-to-infinity matrix norm and show in what settings these row-wise differences in the invariant subspaces can be significantly smaller than the two or Frobenius norm differences. We also demonstrate that the constitutive pieces of our bounds are necessary absent additional assumptions and therefore our results provide a natural starting point for further analysis of specific problems.},
  archivePrefix = {arXiv},
  eprint = {1905.07865},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Damle, Sun (2019) - Uniform bounds for invariant subspace perturbations.pdf},
  journal = {arXiv:1905.07865 [math, stat]},
  keywords = {Mathematics - Numerical Analysis,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{dan2018Sample,
  title = {Sample {{Complexity}} of {{Nonparametric Semi}}-{{Supervised Learning}}},
  author = {Dan, Chen and Leqi, Liu and Aragam, Bryon and Ravikumar, Pradeep and Xing, Eric P.},
  year = {2018},
  month = sep,
  abstract = {We study the sample complexity of semi-supervised learning (SSL) and introduce new assumptions based on the mismatch between a mixture model learned from unlabeled data and the true mixture model induced by the (unknown) class conditional distributions. Under these assumptions, we establish an \$\textbackslash Omega(K\textbackslash log K)\$ labeled sample complexity bound without imposing parametric assumptions, where \$K\$ is the number of classes. Our results suggest that even in nonparametric settings it is possible to learn a near-optimal classifier using only a few labeled samples. Unlike previous theoretical work which focuses on binary classification, we consider general multiclass classification (\$K{$>$}2\$), which requires solving a difficult permutation learning problem. This permutation defines a classifier whose classification error is controlled by the Wasserstein distance between mixing measures, and we provide finite-sample results characterizing the behaviour of the excess risk of this classifier. Finally, we describe three algorithms for computing these estimators based on a connection to bipartite graph matching, and perform experiments to illustrate the superiority of the MLE over the majority vote estimator.},
  archivePrefix = {arXiv},
  eprint = {1809.03073},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Dan et al (2018) - Sample Complexity of Nonparametric Semi-Supervised Learning.pdf},
  journal = {arXiv:1809.03073 [cs, math, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{dan2020Sharp,
  title = {Sharp {{Statistical Guarantees}} for {{Adversarially Robust Gaussian Classification}}},
  author = {Dan, Chen and Wei, Yuting and Ravikumar, Pradeep},
  year = {2020},
  month = jun,
  abstract = {Adversarial robustness has become a fundamental requirement in modern machine learning applications. Yet, there has been surprisingly little statistical understanding so far. In this paper, we provide the first result of the optimal minimax guarantees for the excess risk for adversarially robust classification, under Gaussian mixture model proposed by \textbackslash cite\{schmidt2018adversarially\}. The results are stated in terms of the Adversarial Signal-to-Noise Ratio (AdvSNR), which generalizes a similar notion for standard linear classification to the adversarial setting. For the Gaussian mixtures with AdvSNR value of \$r\$, we establish an excess risk lower bound of order \$\textbackslash Theta(e\^\{-(\textbackslash frac\{1\}\{8\}+o(1)) r\^2\} \textbackslash frac\{d\}\{n\})\$ and design a computationally efficient estimator that achieves this optimal rate. Our results built upon minimal set of assumptions while cover a wide spectrum of adversarial perturbations including \$\textbackslash ell\_p\$ balls for any \$p \textbackslash ge 1\$.},
  archivePrefix = {arXiv},
  eprint = {2006.16384},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Dan et al (2020) - Sharp Statistical Guarantees for Adversarially Robust Gaussian Classification.pdf},
  journal = {arXiv:2006.16384 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{danaher2011joint,
  title = {The Joint Graphical Lasso for Inverse Covariance Estimation across Multiple Classes},
  author = {Danaher, Patrick and Wang, Pei and Witten, Daniela M.},
  year = {2011},
  month = nov,
  abstract = {We consider the problem of estimating multiple related but distinct graphical models on the basis of a high-dimensional data set with observations that belong to distinct classes. A motivating example occurs in the analysis of gene expression data for tissue samples with and without cancer. In this case, we might wish to estimate a gene expression network for the normal tissue and a gene expression network for the tumor tissue. We expect the two gene expression networks to be similar but not identical to each other, and so more accurate estimation of these two networks may be possible using a joint approach. We propose the joint graphical lasso for this purpose. Rather than estimating a graphical model for each class separately, or a single graphical model across all classes, we borrow strength across the classes in order to estimate multiple graphical models that share certain characteristics, such as the locations or weights of nonzero edges. Our approach is based upon maximizing a penalized log likelihood. We employ fused lasso or group lasso penalties, and implement a very fast computational approach that solves the joint graphical lasso problem. In a simulation study we demonstrate that our proposed approach leads to more accurate estimation of networks and covariance structure than competing approaches. We further illustrate our proposal on a publicly-available lung cancer gene expression data set.},
  archivePrefix = {arXiv},
  eprint = {1111.0324},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Danaher et al (2011) - The joint graphical lasso for inverse covariance estimation across multiple.pdf},
  journal = {arXiv:1111.0324 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{dasgupta2007Probabilistic,
  title = {A {{Probabilistic Analysis}} of {{EM}} for {{Mixtures}} of {{Separated}}, {{Spherical Gaussians}}},
  author = {Dasgupta, Sanjoy and Schulman, Leonard},
  year = {2007},
  volume = {8},
  pages = {203--226},
  issn = {ISSN 1533-7928},
  file = {/Users/yuekai/Documents/zotero/Dasgupta, Schulman (2007) - A Probabilistic Analysis of EM for Mixtures of Separated, Spherical Gaussians.pdf},
  journal = {Journal of Machine Learning Research},
  number = {Feb}
}

@incollection{dasgupta2008general,
  title = {A General Agnostic Active Learning Algorithm},
  booktitle = {Advances in {{Neural Information Processing Systems}} 20},
  author = {Dasgupta, Sanjoy and Hsu, Daniel J and Monteleoni, Claire},
  editor = {Platt, J. C. and Koller, D. and Singer, Y. and Roweis, S. T.},
  year = {2008},
  pages = {353--360},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/yuekai/Documents/zotero/Dasgupta et al (2008) - A general agnostic active learning algorithm.pdf}
}

@article{dasgupta2017Learning,
  title = {Learning from Partial Correction},
  author = {Dasgupta, Sanjoy and Luby, Michael},
  year = {2017},
  month = may,
  abstract = {We introduce a new model of interactive learning in which an expert examines the predictions of a learner and partially fixes them if they are wrong. Although this kind of feedback is not i.i.d., we show statistical generalization bounds on the quality of the learned model.},
  archivePrefix = {arXiv},
  eprint = {1705.08076},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Dasgupta, Luby (2017) - Learning from partial correction.pdf},
  journal = {arXiv:1705.08076 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{dastin2018Amazon,
  title = {Amazon Scraps Secret {{AI}} Recruiting Tool That Showed Bias against Women},
  author = {Dastin, Jeffrey},
  year = {2018},
  month = oct,
  abstract = {Amazon.com Inc's machine-learning specialists uncovered a big problem: thei...},
  journal = {Reuters},
  language = {en}
}

@article{daudin1980Partial,
  title = {Partial Association Measures and an Application to Qualitative Regression},
  author = {Daudin, J. J.},
  year = {1980},
  month = jan,
  volume = {67},
  pages = {581--590},
  issn = {0006-3444},
  doi = {10.1093/biomet/67.3.581},
  abstract = {Abstract.   We define partial \cyrchar\cyrf{} 2 and additive partial \cyrchar\cyrf{} 2 measures of association between two random variables and we characterize conditional independence by},
  file = {/Users/yuekai/Documents/zotero/Daudin (1980) - Partial association measures and an application to qualitative regression.pdf},
  journal = {Biometrika},
  language = {en},
  number = {3}
}

@article{davarnia2017estimation,
  title = {From Estimation to Optimization via Shrinkage},
  author = {Davarnia, Danial and Cornu{\'e}jols, G{\'e}rard},
  year = {2017},
  month = nov,
  volume = {45},
  pages = {642--646},
  issn = {01676377},
  doi = {10.1016/j.orl.2017.10.005},
  abstract = {We study a class of quadratic stochastic programs where the distribution of random variables has unknown parameters. A traditional approach is to estimate the parameters using a maximum likelihood estimator (MLE) and to use this as input in the optimization problem. For the unconstrained case, we show that an estimator that shrinks the MLE towards an arbitrary vector yields a uniformly better risk than the MLE. In contrast, when there are constraints, we show that the MLE is admissible.},
  file = {/Users/yuekai/Documents/zotero/Davarnia, Cornuéjols (2017) - From estimation to optimization via shrinkage.pdf},
  journal = {Operations Research Letters},
  language = {en},
  number = {6}
}

@article{davis1970Rotation,
  title = {The {{Rotation}} of {{Eigenvectors}} by a {{Perturbation}}. {{III}}},
  author = {Davis, C. and Kahan, W.},
  year = {1970},
  month = mar,
  volume = {7},
  pages = {1--46},
  issn = {0036-1429},
  doi = {10.1137/0707001},
  abstract = {When a Hermitian linear operator is slightly perturbed, by how much can its invariant subspaces change? Given some approximations to a cluster of neighboring eigenvalues and to the corresponding eigenvectors of a real symmetric matrix, and given an estimate for the gap that separates the cluster from all other eigenvalues, how much can the subspace spanned by the eigenvectors differ from the subspace spanned by our approximations? These questions are closely related; both are investigated here. The difference between the two subspaces is characterized in terms of certain angles through which one subspace must be rotated in order most directly to reach the other. These angles unify the treatment of natural geometric, operator-theoretic and error-analytic questions concerning those subspaces. Sharp bounds upon trigonometric functions of these angles are obtained from the gap and from bounds upon either the perturbation (1st question) or a computable residual (2nd question). An example is included.},
  file = {/Users/yuekai/Documents/zotero/Davis, Kahan (1970) - The Rotation of Eigenvectors by a Perturbation.pdf},
  journal = {SIAM Journal on Numerical Analysis},
  number = {1}
}

@article{davis2018Stochastic,
  title = {Stochastic Subgradient Method Converges on Tame Functions},
  author = {Davis, Damek and Drusvyatskiy, Dmitriy and Kakade, Sham and Lee, Jason D.},
  year = {2018},
  month = apr,
  abstract = {This work considers the question: what convergence guarantees does the stochastic subgradient method have in the absence of smoothness and convexity? We prove that the stochastic subgradient method, on any semialgebraic locally Lipschitz function, produces limit points that are all first-order stationary. More generally, our result applies to any function with a Whitney stratifiable graph. In particular, this work endows the stochastic subgradient method, and its proximal extension, with rigorous convergence guarantees for a wide class of problems arising in data science---including all popular deep learning architectures.},
  archivePrefix = {arXiv},
  eprint = {1804.07795},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Davis et al (2018) - Stochastic subgradient method converges on tame functions.pdf},
  journal = {arXiv:1804.07795 [cs, math]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control},
  primaryClass = {cs, math}
}

@article{de-arteaga2019Bias,
  title = {Bias in {{Bios}}: {{A Case Study}} of {{Semantic Representation Bias}} in a {{High}}-{{Stakes Setting}}},
  shorttitle = {Bias in {{Bios}}},
  author = {{De-Arteaga}, Maria and Romanov, Alexey and Wallach, Hanna and Chayes, Jennifer and Borgs, Christian and Chouldechova, Alexandra and Geyik, Sahin and Kenthapadi, Krishnaram and Kalai, Adam Tauman},
  year = {2019},
  pages = {120--128},
  doi = {10.1145/3287560.3287572},
  abstract = {We present a large-scale study of gender bias in occupation classification, a task where the use of machine learning may lead to negative outcomes on peoples' lives. We analyze the potential allocation harms that can result from semantic representation bias. To do so, we study the impact on occupation classification of including explicit gender indicators---such as first names and pronouns---in different semantic representations of online biographies. Additionally, we quantify the bias that remains when these indicators are "scrubbed," and describe proxy behavior that occurs in the absence of explicit gender indicators. As we demonstrate, differences in true positive rates between genders are correlated with existing gender imbalances in occupations, which may compound these imbalances.},
  archivePrefix = {arXiv},
  eprint = {1901.09451},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/De-Arteaga et al (2019) - Bias in Bios.pdf},
  journal = {Proceedings of the Conference on Fairness, Accountability, and Transparency  - FAT* '19},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{deb2019Multivariate,
  title = {Multivariate {{Rank}}-Based {{Distribution}}-Free {{Nonparametric Testing}} Using {{Measure Transportation}}},
  author = {Deb, Nabarun and Sen, Bodhisattva},
  year = {2019},
  month = sep,
  abstract = {In this paper, we propose a general framework for distribution-free nonparametric testing in multi-dimensions, based on a notion of multivariate ranks defined using the theory of measure transportation. Unlike other existing proposals in the literature, these multivariate ranks share a number of useful properties with the usual one-dimensional ranks; most importantly, these ranks are distribution-free. This crucial observation allows us to design nonparametric tests that are exactly distribution-free under the null hypothesis. We demonstrate the applicability of this approach by constructing exact distribution-free tests for two classical nonparametric problems: (i) testing for mutual independence between random vectors, and (ii) testing for the equality of multivariate distributions. In particular, we propose (multivariate) rank versions of distance covariance (Sz\textbackslash 'ekely et al., 2007) and energy statistic (Sz\textbackslash 'ekely and Rizzo, 2013) for testing scenarios (i) and (ii) respectively. In both these problems, we derive the asymptotic null distribution of the proposed test statistics. We further show that our tests are consistent against all fixed alternatives. Moreover, the proposed tests are tuning-free, computationally feasible and are well-defined under minimal assumptions on the underlying distributions (e.g., they do not need any moment assumptions). We also demonstrate the efficacy of these procedures via extensive simulations. In the process of analyzing the theoretical properties of our procedures, we end up proving some new results in the theory of measure transportation and in the limit theory of permutation statistics using Stein's method for exchangeable pairs, which may be of independent interest.},
  archivePrefix = {arXiv},
  eprint = {1909.08733},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Deb, Sen (2019) - Multivariate Rank-based Distribution-free Nonparametric Testing using Measure.pdf},
  journal = {arXiv:1909.08733 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{decoste2002Training,
  title = {Training {{Invariant Support Vector Machines}}},
  author = {Decoste, Dennis and Sch{\"o}lkopf, Bernhard},
  year = {2002},
  month = jan,
  volume = {46},
  pages = {161--190},
  issn = {1573-0565},
  doi = {10.1023/A:1012454411458},
  abstract = {Practical experience has shown that in order to obtain the best possible performance, prior knowledge about invariances of a classification problem at hand ought to be incorporated into the training procedure. We describe and review all known methods for doing so in support vector machines, provide experimental results, and discuss their respective merits. One of the significant new results reported in this work is our recent achievement of the lowest reported test error on the well-known MNIST digit recognition benchmark task, with SVM training times that are also significantly faster than previous SVM methods.},
  file = {/Users/yuekai/Documents/zotero/Decoste, Schölkopf (2002) - Training Invariant Support Vector Machines.pdf},
  journal = {Machine Learning},
  language = {en},
  number = {1}
}

@article{delage2010Distributionally,
  title = {Distributionally {{Robust Optimization Under Moment Uncertainty}} with {{Application}} to {{Data}}-{{Driven Problems}}},
  author = {Delage, Erick and Ye, Yinyu},
  year = {2010},
  volume = {58},
  pages = {595--612},
  doi = {10.1287/opre.1090.0741},
  abstract = {Stochastic programming can effectively describe many deci sion making problems in uncertain environments. Unfortunately, such programs are often computationally demanding to solve. In addition, their solution can be misleading when there is ambiguity in the choice of a distribution for the ran dom parameters. In this paper, we propose a model that describes uncertainty in both the distribution form (discr ete, Gaussian, exponential, etc.) and moments (mean and cov ariance matrix). We demonstrate that for a wide range of cost fun ctio s the associated distributionally robust (or min-max ) stochastic program can be solved efficiently. Furthermore, by deriving a new confidence region for the mean and the covariance matrix of a random vector, we provide probabilis tic arguments for using our model in problems that rely heavily on historical data. These arguments are confirmed in a pra ctical example of portfolio selection, where our framework leads to better performing policies on the ``true'' distribut on underlying the daily returns of financial assets.},
  file = {/Users/yuekai/Documents/zotero/Delage, Ye (2010) - Distributionally Robust Optimization Under Moment Uncertainty with Application.pdf},
  journal = {Operations Research}
}

@article{delange2019Continual,
  title = {Continual Learning: {{A}} Comparative Study on How to Defy Forgetting in Classification Tasks},
  shorttitle = {Continual Learning},
  author = {De Lange, Matthias and Aljundi, Rahaf and Masana, Marc and Parisot, Sarah and Jia, Xu and Leonardis, Ales and Slabaugh, Gregory and Tuytelaars, Tinne},
  year = {2019},
  month = sep,
  abstract = {Artificial neural networks thrive in solving the classification problem for a particular rigid task, where the network resembles a static entity of knowledge, acquired through generalized learning behaviour from a distinct training phase. However, endeavours to extend this knowledge without targeting the original task usually result in a catastrophic forgetting of this task. Continual learning shifts this paradigm towards a network that can continually accumulate knowledge over different tasks without the need for retraining from scratch, with methods in particular aiming to alleviate forgetting. We focus on task-incremental classification, where tasks arrive in a batch-like fashion, and are delineated by clear boundaries. Our main contributions concern 1) a taxonomy and extensive overview of the state-of-the-art, 2) a novel framework to continually determine stability-plasticity trade-off of the continual learner, 3) a comprehensive experimental comparison of 10 state-of-the-art continual learning methods and 4 baselines. We empirically scrutinize which method performs best, both on balanced Tiny Imagenet and a large-scale unbalanced iNaturalist datasets. We study the influence of model capacity, weight decay and dropout regularization, and the order in which the tasks are presented, and qualitatively compare methods in terms of required memory, computation time and storage.},
  archivePrefix = {arXiv},
  eprint = {1909.08383},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/De Lange et al (2019) - Continual learning.pdf},
  journal = {arXiv:1909.08383 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{delbarrio2018Central,
  title = {Central {{Limit Theorem}} for Empirical Transportation Cost in General Dimension},
  author = {Del Barrio, Eustasio and Loubes, Jean-Michel},
  year = {2018},
  month = mar,
  abstract = {We consider the problem of optimal transportation with quadratic cost between a empirical measure and a general target probability on R d , with d \$\textbackslash ge\$ 1. We provide new results on the uniqueness and stability of the associated optimal transportation potentials , namely, the minimizers in the dual formulation of the optimal transportation problem. As a consequence, we show that a CLT holds for the empirical transportation cost under mild moment and smoothness requirements. The limiting distributions are Gaussian and admit a simple description in terms of the optimal transportation potentials.},
  archivePrefix = {arXiv},
  eprint = {1705.01299},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Del Barrio, Loubes (2018) - Central Limit Theorem for empirical transportation cost in general dimension.pdf},
  journal = {arXiv:1705.01299 [math, stat]},
  keywords = {Mathematics - Probability,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{delbarrio2018Obtaining,
  title = {Obtaining Fairness Using Optimal Transport Theory},
  author = {{del Barrio}, Eustasio and Gamboa, Fabrice and Gordaliza, Paula and Loubes, Jean-Michel},
  year = {2018},
  month = jun,
  abstract = {Statistical algorithms are usually helping in making decisions in many aspects of our lives. But, how do we know if these algorithms are biased and commit unfair discrimination of a particular group of people, typically a minority? \textbackslash textit\{Fairness\} is generally studied in a probabilistic framework where it is assumed that there exists a protected variable, whose use as an input of the algorithm may imply discrimination. There are different definitions of Fairness in the literature. In this paper we focus on two of them which are called Disparate Impact (DI) and Balanced Error Rate (BER). Both are based on the outcome of the algorithm across the different groups determined by the protected variable. The relationship between these two notions is also studied. The goals of this paper are to detect when a binary classification rule lacks fairness and to try to fight against the potential discrimination attributable to it. This can be done by modifying either the classifiers or the data itself. Our work falls into the second category and modifies the input data using optimal transport theory.},
  archivePrefix = {arXiv},
  eprint = {1806.03195},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/del Barrio et al (2018) - Obtaining fairness using optimal transport theory.pdf},
  journal = {arXiv:1806.03195 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{delyon1999Convergence,
  title = {Convergence of a Stochastic Approximation Version of the {{EM}} Algorithm},
  author = {Delyon, Bernard and Lavielle, Marc and Moulines, Eric},
  year = {1999},
  month = mar,
  volume = {27},
  pages = {94--128},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/aos/1018031103},
  abstract = {The expectation-maximization (EM) algorithm is a powerful computational technique for locating maxima of functions. It is widely used in statistics for maximum likelihood or maximum a posteriori estimation in incomplete data models. In certain situations, however, this method is not applicable because the expectation step cannot be performed in closed form. To deal with these problems, a novel method is introduced, the stochastic approximation EM (SAEM), which replaces the expectation step of the EM algorithm by one iteration of a stochastic approximation procedure. The convergence of the SAEM algorithm is established under conditions that are applicable to many practical situations. Moreover, it is proved that, under mild additional conditions, the attractive stationary points of the SAEM algorithm correspond to the local maxima of the function presented to support our findings.},
  file = {/Users/yuekai/Documents/zotero/Delyon et al (1999) - Convergence of a stochastic approximation version of the EM algorithm.pdf},
  journal = {The Annals of Statistics},
  language = {en},
  mrnumber = {MR1701103},
  number = {1},
  zmnumber = {0932.62094}
}

@article{demidenko2001Computational,
  title = {Computational Aspects of Probit Model},
  author = {Demidenko, Eugene},
  year = {2001},
  pages = {15},
  abstract = {Sometimes the maximum likelihood estimation procedure for the probit model fails. There may be two reasons: the maximum likelihood estimate (MLE) just does not exist or computer overflow error occurs during the computation of the cumulative distribution function (cdf ). For example, the approximation explosive effect due to an inaccurate computation of the cdf for a large value of the argument occurs in a popular statistical package S-plus. The goal of the paper is to provide remedies for these two abnormalities. First, despite the availability of a criterion for the MLE existence, expressed in terms of a separation plane in the covariate space, there are no constructive criteria to verify whether such a separation exists. We develop constructive criteria for the MLE existence that are valid also for other link functions. Second, to avoid the overflow problem we suggest approximate formulae for the log-likelihood function and its derivatives in the case of possible large value of the argument. Standard algorithms of the log-likelihood maximization like Newton-Raphson or Fisher Scoring are very sensitive to large values of the linear predictor, particularly outliers. Five algorithms are compared by the time to converge and reliability via statistical simulations. The corrected algorithms, based on the approximate formulae are more reliable and almost as fast as the standard ones.},
  file = {/Users/yuekai/Documents/zotero/Demidenko (2001) - Computational aspects of probit model.pdf},
  language = {en},
  number = {6}
}

@article{demirer2019SemiParametric,
  title = {Semi-{{Parametric Efficient Policy Learning}} with {{Continuous Actions}}},
  author = {Demirer, Mert and Syrgkanis, Vasilis and Lewis, Greg and Chernozhukov, Victor},
  year = {2019},
  month = may,
  abstract = {We consider off-policy evaluation and optimization with continuous action spaces. We focus on observational data where the data collection policy is unknown and needs to be estimated. We take a semi-parametric approach where the value function takes a known parametric form in the treatment, but we are agnostic on how it depends on the observed contexts. We propose a doubly robust off-policy estimate for this setting and show that off-policy optimization based on this estimate is robust to estimation errors of the policy function or the regression model. Our results also apply if the model does not satisfy our semi-parametric form, but rather we measure regret in terms of the best projection of the true value function to this functional space. Our work extends prior approaches of policy optimization from observational data that only considered discrete actions. We provide an experimental evaluation of our method in a synthetic data example motivated by optimal personalized pricing and costly resource allocation.},
  archivePrefix = {arXiv},
  eprint = {1905.10116},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Demirer et al (2019) - Semi-Parametric Efficient Policy Learning with Continuous Actions.pdf},
  journal = {arXiv:1905.10116 [cs, econ, math, stat]},
  keywords = {Computer Science - Machine Learning,Economics - Econometrics,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, econ, math, stat}
}

@article{deng2020Strong,
  title = {Strong {{Consistency}}, {{Graph Laplacians}}, and the {{Stochastic Block Model}}},
  author = {Deng, Shaofeng and Ling, Shuyang and Strohmer, Thomas},
  year = {2020},
  month = apr,
  abstract = {Spectral clustering has become one of the most popular algorithms in data clustering and community detection. We study the performance of classical two-step spectral clustering via the graph Laplacian to learn the stochastic block model. Our aim is to answer the following question: when is spectral clustering via the graph Laplacian able to achieve strong consistency, i.e., the exact recovery of the underlying hidden communities? Our work provides an entrywise analysis (an \$\textbackslash ell\_\{\textbackslash infty\}\$-norm perturbation bound) of the Fielder eigenvector of both the unnormalized and the normalized Laplacian associated with the adjacency matrix sampled from the stochastic block model. We prove that spectral clustering is able to achieve exact recovery of the planted community structure under conditions that match the information-theoretic limits.},
  archivePrefix = {arXiv},
  eprint = {2004.09780},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Deng et al (2020) - Strong Consistency, Graph Laplacians, and the Stochastic Block Model.pdf},
  journal = {arXiv:2004.09780 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{denton2019Detecting,
  title = {Detecting {{Bias}} with {{Generative Counterfactual Face Attribute Augmentation}}},
  author = {Denton, Emily and Hutchinson, Ben and Mitchell, Margaret and Gebru, Timnit},
  year = {2019},
  month = jun,
  abstract = {We introduce a simple framework for identifying biases of a smiling attribute classifier. Our method poses counterfactual questions of the form: how would the prediction change if this face characteristic had been different? We leverage recent advances in generative adversarial networks to build a realistic generative model of face images that affords controlled manipulation of specific image characteristics. We introduce a set of metrics that measure the effect of manipulating a specific property of an image on the output of a trained classifier. Empirically, we identify several different factors of variation that affect the predictions of a smiling classifier trained on CelebA.},
  archivePrefix = {arXiv},
  eprint = {1906.06439},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Denton et al (2019) - Detecting Bias with Generative Counterfactual Face Attribute Augmentation.pdf},
  journal = {arXiv:1906.06439 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{deshpande2013Linear,
  title = {Linear {{Bandits}} in {{High Dimension}} and {{Recommendation Systems}}},
  author = {Deshpande, Yash and Montanari, Andrea},
  year = {2013},
  month = jan,
  abstract = {A large number of online services provide automated recommendations to help users to navigate through a large collection of items. New items (products, videos, songs, advertisements) are suggested on the basis of the user's past history and --when available-- her demographic profile. Recommendations have to satisfy the dual goal of helping the user to explore the space of available items, while allowing the system to probe the user's preferences. We model this trade-off using linearly parametrized multi-armed bandits, propose a policy and prove upper and lower bounds on the cumulative "reward" that coincide up to constants in the data poor (high-dimensional) regime. Prior work on linear bandits has focused on the data rich (low-dimensional) regime and used cumulative "risk" as the figure of merit. For this data rich regime, we provide a simple modification for our policy that achieves near-optimal risk performance under more restrictive assumptions on the geometry of the problem. We test (a variation of) the scheme used for establishing achievability on the Netflix and MovieLens datasets and obtain good agreement with the qualitative predictions of the theory we develop.},
  archivePrefix = {arXiv},
  eprint = {1301.1722},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Deshpande, Montanari (2013) - Linear Bandits in High Dimension and Recommendation Systems.pdf},
  journal = {arXiv:1301.1722 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{devlin2018BERT,
  title = {{{BERT}}: {{Pre}}-Training of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2018},
  month = oct,
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  archivePrefix = {arXiv},
  eprint = {1810.04805},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Devlin et al (2018) - BERT.pdf},
  journal = {arXiv:1810.04805 [cs]},
  keywords = {Computer Science - Computation and Language},
  primaryClass = {cs}
}

@book{devroye1996probabilistic,
  title = {A Probabilistic Theory of Pattern Recognition},
  author = {Devroye, Luc and Gy{\"o}rfi, L{\'a}szl{\'o} and Lugosi, G{\'a}bor},
  year = {1996},
  publisher = {{Springer}},
  address = {{New York}},
  file = {/Users/yuekai/Documents/zotero/Devroye et al (1996) - A probabilistic theory of pattern recognition.pdf},
  isbn = {978-0-387-94618-4},
  language = {en},
  lccn = {Q327 .D5 1996}
}

@article{dezeure2017Highdimensional,
  title = {High-Dimensional Simultaneous Inference with the Bootstrap},
  author = {Dezeure, Ruben and B{\"u}hlmann, Peter and Zhang, Cun-Hui},
  year = {2017},
  month = dec,
  volume = {26},
  pages = {685--719},
  issn = {1133-0686, 1863-8260},
  doi = {10.1007/s11749-017-0554-2},
  file = {/Users/yuekai/Documents/zotero/Dezeure et al (2017) - High-dimensional simultaneous inference with the bootstrap.pdf},
  journal = {TEST},
  language = {en},
  number = {4}
}

@article{diakonikolas2018Approximate,
  title = {The {{Approximate Duality Gap Technique}}: {{A Unified Theory}} of {{First}}-{{Order Methods}}},
  shorttitle = {The {{Approximate Duality Gap Technique}}},
  author = {Diakonikolas, Jelena and Orecchia, Lorenzo},
  year = {2018},
  month = dec,
  abstract = {We present a general technique for the analysis of first-order methods. The technique relies on the construction of a duality gap for an appropriate approximation of the objective function, where the function approximation improves as the algorithm converges. We show that in continuous time enforcement of an invariant that this approximate duality gap decreases at a certain rate exactly recovers a wide range of first-order continuous-time methods. We characterize the discretization errors incurred by different discretization methods, and show how iteration-complexity-optimal methods for various classes of problems cancel out the discretization error. The techniques are illustrated on various classes of problems -- including convex minimization for Lipschitz-continuous objectives, smooth convex minimization, composite minimization, smooth and strongly convex minimization, solving variational inequalities with monotone operators, and convex-concave saddle-point optimization -- and naturally extend to other settings.},
  archivePrefix = {arXiv},
  eprint = {1712.02485},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Diakonikolas, Orecchia (2018) - The Approximate Duality Gap Technique.pdf},
  journal = {arXiv:1712.02485 [cs, math]},
  keywords = {Computer Science - Data Structures and Algorithms,Mathematics - Optimization and Control},
  primaryClass = {cs, math}
}

@article{dianat2019Statistical,
  title = {Statistical {{Discrimination}} and {{Affirmative Action}} in the {{Lab}}},
  author = {Dianat, Ahrash and Echenique, Federico and Yariv, Leeat},
  year = {2019},
  month = may,
  pages = {42},
  abstract = {We present results from laboratory experiments studying statistical discrimination and affirmative action. We induce statistical discrimination in simple labor-market interactions between firms and workers. We then introduce affirmative-action policies that vary in the size and duration of a subsidy that firms receive for hiring discriminatedagainst workers. These different affirmative-action policies have nearly the same effect, and practically eliminate discriminatory hiring practices. However, once lifted, few positive effects remain and discrimination reverts to its initial levels. One exception is lengthy affirmative-action policies, which exhibit somewhat longer-lived effects. Stickiness of beliefs, which we elicit, helps explain the observed outcomes.},
  file = {/Users/yuekai/Documents/zotero/Dianat et al (2019) - Statistical Discrimination and Aﬃrmative Action in the Lab.pdf},
  language = {en}
}

@article{dicker2016Ridge,
  title = {Ridge Regression and Asymptotic Minimax Estimation over Spheres of Growing Dimension},
  author = {Dicker, Lee H.},
  year = {2016},
  month = feb,
  volume = {22},
  pages = {1--37},
  publisher = {{Bernoulli Society for Mathematical Statistics and Probability}},
  issn = {1350-7265},
  doi = {10.3150/14-BEJ609},
  abstract = {We study asymptotic minimax problems for estimating a ddd-dimensional regression parameter over spheres of growing dimension (d\textrightarrow{$\infty$}d\textrightarrow{$\infty$}d\textbackslash to\textbackslash infty). Assuming that the data follows a linear model with Gaussian predictors and errors, we show that ridge regression is asymptotically minimax and derive new closed form expressions for its asymptotic risk under squared-error loss. The asymptotic risk of ridge regression is closely related to the Stieltjes transform of the Mar\v{c}enko\textendash Pastur distribution and the spectral distribution of the predictors from the linear model. Adaptive ridge estimators are also proposed (which adapt to the unknown radius of the sphere) and connections with equivariant estimation are highlighted. Our results are mostly relevant for asymptotic settings where the number of observations, nnn, is proportional to the number of predictors, that is, d/n\textrightarrow{$\rho\in$}(0,{$\infty$})d/n\textrightarrow{$\rho\in$}(0,{$\infty$})d/n\textbackslash to\textbackslash rho\textbackslash in(0,\textbackslash infty).},
  file = {/Users/yuekai/Documents/zotero/Dicker (2016) - Ridge regression and asymptotic minimax estimation over spheres of growing.pdf;/Users/yuekai/Zotero/storage/TFGVRWWE/1443620842.html},
  journal = {Bernoulli},
  keywords = {adaptive estimation,equivariance,Marčenko–Pastur distribution,random matrix theory},
  language = {EN},
  mrnumber = {MR3449775},
  number = {1},
  zmnumber = {06543262}
}

@inproceedings{dixon2018Measuring,
  title = {Measuring and {{Mitigating Unintended Bias}} in {{Text Classification}}},
  booktitle = {Proceedings of the 2018 {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}  - {{AIES}} '18},
  author = {Dixon, Lucas and Li, John and Sorensen, Jeffrey and Thain, Nithum and Vasserman, Lucy},
  year = {2018},
  pages = {67--73},
  publisher = {{ACM Press}},
  address = {{New Orleans, LA, USA}},
  doi = {10.1145/3278721.3278729},
  abstract = {We introduce and illustrate a new approach to measuring and mitigating unintended bias in machine learning models. Our definition of unintended bias is parameterized by a test set and a subset of input features. We illustrate how this can be used to evaluate text classifiers using a synthetic test set and a public corpus of comments annotated for toxicity from Wikipedia Talk pages. We also demonstrate how imbalances in training data can lead to unintended bias in the resulting models, and therefore potentially unfair applications. We use a set of common demographic identity terms as the subset of input features on which we measure bias. This technique permits analysis in the common scenario where demographic information on authors and readers is unavailable, so that bias mitigation must focus on the content of the text itself. The mitigation method we introduce is an unsupervised approach based on balancing the training dataset. We demonstrate that this approach reduces the unintended bias without compromising overall model quality.},
  file = {/Users/yuekai/Documents/zotero/Dixon et al (2018) - Measuring and Mitigating Unintended Bias in Text Classification.pdf},
  isbn = {978-1-4503-6012-8},
  language = {en}
}

@article{dobriban2015HighDimensional,
  title = {High-{{Dimensional Asymptotics}} of {{Prediction}}: {{Ridge Regression}} and {{Classification}}},
  shorttitle = {High-{{Dimensional Asymptotics}} of {{Prediction}}},
  author = {Dobriban, Edgar and Wager, Stefan},
  year = {2015},
  month = nov,
  abstract = {We provide a unified analysis of the predictive risk of ridge regression and regularized discriminant analysis in a dense random effects model. We work in a high-dimensional asymptotic regime where \$p, n \textbackslash to \textbackslash infty\$ and \$p/n \textbackslash to \textbackslash gamma \textbackslash in (0, \textbackslash, \textbackslash infty)\$, and allow for arbitrary covariance among the features. For both methods, we provide an explicit and efficiently computable expression for the limiting predictive risk, which depends only on the spectrum of the feature-covariance matrix, the signal strength, and the aspect ratio \$\textbackslash gamma\$. Especially in the case of regularized discriminant analysis, we find that predictive accuracy has a nuanced dependence on the eigenvalue distribution of the covariance matrix, suggesting that analyses based on the operator norm of the covariance matrix may not be sharp. Our results also uncover several qualitative insights about both methods: for example, with ridge regression, there is an exact inverse relation between the limiting predictive risk and the limiting estimation risk given a fixed signal strength. Our analysis builds on recent advances in random matrix theory.},
  archivePrefix = {arXiv},
  eprint = {1507.03003},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Dobriban, Wager (2015) - High-Dimensional Asymptotics of Prediction.pdf;/Users/yuekai/Zotero/storage/VXEYENJD/1507.html},
  journal = {arXiv:1507.03003 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {math, stat}
}

@article{dobriban2018New,
  title = {A {{New Theory}} for {{Sketching}} in {{Linear Regression}}},
  author = {Dobriban, Edgar and Liu, Sifan},
  year = {2018},
  month = oct,
  abstract = {Large datasets create opportunities as well as analytic challenges. A recent development is to use random projection or sketching methods for dimension reduction in statistics and machine learning. In this work, we study the statistical performance of sketching algorithms for linear regression. Suppose we randomly project the data matrix and the outcome using a random sketching matrix reducing the sample size, and do linear regression on the resulting data. How much do we lose compared to the original linear regression? The existing theory does not give a precise enough answer, and this has been a bottleneck for using random projections in practice. In this paper, we introduce a new mathematical approach to the problem, relying on very recent results from asymptotic random matrix theory and free probability theory. This is a perfect fit, as the sketching matrices are random in practice. We allow the dimension and sample sizes to have an arbitrary ratio. We study the most popular sketching methods in a unified framework, including random projection methods (Gaussian and iid projections, uniform orthogonal projections, subsampled randomized Hadamard transforms), as well as sampling methods (including uniform, leverage-based, and greedy sampling). We find precise and simple expressions for the accuracy loss of these methods. These go beyond classical Johnson-Lindenstrauss type results, because they are exact, instead of being bounds up to constants. Our theoretical formulas are surprisingly accurate in extensive simulations and on two empirical datasets.},
  archivePrefix = {arXiv},
  eprint = {1810.06089},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Dobriban Liu (2018) - A New Theory for Sketching in Linear Regression.pdf},
  journal = {arXiv:1810.06089 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Numerical Analysis,Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {cs, math, stat}
}

@article{dobriban2020WONDER,
  title = {{{WONDER}}: {{Weighted}} One-Shot Distributed Ridge Regression in High Dimensions},
  shorttitle = {{{WONDER}}},
  author = {Dobriban, Edgar and Sheng, Yue},
  year = {2020},
  month = feb,
  abstract = {In many areas, practitioners need to analyze large datasets that challenge conventional single-machine computing. To scale up data analysis, distributed and parallel computing approaches are increasingly needed. Here we study a fundamental and highly important problem in this area: How to do ridge regression in a distributed computing environment? Ridge regression is an extremely popular method for supervised learning, and has several optimality properties, thus it is important to study. We study one-shot methods that construct weighted combinations of ridge regression estimators computed on each machine. By analyzing the mean squared error in a high dimensional random-effects model where each predictor has a small effect, we discover several new phenomena. 1. Infinite-worker limit: The distributed estimator works well for very large numbers of machines, a phenomenon we call "infinite-worker limit". 2. Optimal weights: The optimal weights for combining local estimators sum to more than unity, due to the downward bias of ridge. Thus, all averaging methods are suboptimal. We also propose a new Weighted ONe-shot DistributEd Ridge regression (WONDER) algorithm. We test WONDER in simulation studies and using the Million Song Dataset as an example. There it can save at least 100x in computation time, while nearly preserving test accuracy.},
  archivePrefix = {arXiv},
  eprint = {1903.09321},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Dobriban, Sheng (2020) - WONDER.pdf;/Users/yuekai/Zotero/storage/MY7UW3MQ/1903.html},
  journal = {arXiv:1903.09321 [cs, math, stat]},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Computation},
  primaryClass = {cs, math, stat}
}

@article{domingos2012fewa,
  title = {A Few Useful Things to Know about Machine Learning},
  author = {Domingos, Pedro},
  year = {2012},
  month = oct,
  volume = {55},
  pages = {78},
  issn = {00010782},
  doi = {10.1145/2347736.2347755},
  file = {/Users/yuekai/Documents/zotero/Domingos (2012) - A few useful things to know about machine learning.pdf},
  journal = {Communications of the ACM},
  language = {en},
  number = {10}
}

@article{dondelinger2016Highdimensional,
  title = {High-Dimensional Regression over Disease Subgroups},
  author = {Dondelinger, Frank and Mukherjee, Sach and Initiative, The Alzheimer's Disease Neuroimaging},
  year = {2016},
  month = nov,
  abstract = {We consider high-dimensional regression over subgroups of observations. Our work is motivated by biomedical problems, where disease subtypes, for example, may differ with respect to underlying regression models, but sample sizes at the subgroup-level may be limited. We focus on the case in which subgroup-specific models may be expected to be similar but not necessarily identical. Our approach is to treat subgroups as related problem instances and jointly estimate subgroup-specific regression coefficients. This is done in a penalized framework, combining an \$\textbackslash ell\_1\$ term with an additional term that penalizes differences between subgroup-specific coefficients. This gives solutions that are globally sparse but that allow information-sharing between the subgroups. We present algorithms for estimation and empirical results on simulated data and using Alzheimer's disease, amyotrophic lateral sclerosis and cancer datasets. These examples demonstrate the gains our approach can offer in terms of prediction and the ability to estimate subgroup-specific sparsity patterns.},
  archivePrefix = {arXiv},
  eprint = {1611.00953},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Dondelinger et al (2016) - High-dimensional regression over disease subgroups.pdf},
  journal = {arXiv:1611.00953 [stat]},
  keywords = {Statistics - Applications,Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{dong2019Gaussian,
  title = {Gaussian {{Differential Privacy}}},
  author = {Dong, Jinshuo and Roth, Aaron and Su, Weijie J.},
  year = {2019},
  month = may,
  abstract = {Differential privacy has seen remarkable success as a rigorous and practical formalization of data privacy in the past decade. This privacy definition and its divergence based relaxations, however, have several acknowledged weaknesses, either in handling composition of private algorithms or in analyzing important primitives like privacy amplification by subsampling. Inspired by the hypothesis testing formulation of privacy, this paper proposes a new relaxation, which we term `\$f\$-differential privacy' (\$f\$-DP). This notion of privacy has a number of appealing properties and, in particular, avoids difficulties associated with divergence based relaxations. First, \$f\$-DP preserves the hypothesis testing interpretation. In addition, \$f\$-DP allows for lossless reasoning about composition in an algebraic fashion. Moreover, we provide a powerful technique to import existing results proven for original DP to \$f\$-DP and, as an application, obtain a simple subsampling theorem for \$f\$-DP. In addition to the above findings, we introduce a canonical single-parameter family of privacy notions within the \$f\$-DP class that is referred to as `Gaussian differential privacy' (GDP), defined based on testing two shifted Gaussians. GDP is focal among the \$f\$-DP class because of a central limit theorem we prove. More precisely, the privacy guarantees of \textbackslash emph\{any\} hypothesis testing based definition of privacy (including original DP) converges to GDP in the limit under composition. The CLT also yields a computationally inexpensive tool for analyzing the exact composition of private algorithms. Taken together, this collection of attractive properties render \$f\$-DP a mathematically coherent, analytically tractable, and versatile framework for private data analysis. Finally, we demonstrate the use of the tools we develop by giving an improved privacy analysis of noisy stochastic gradient descent.},
  archivePrefix = {arXiv},
  eprint = {1905.02383},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Dong et al (2019) - Gaussian Differential Privacy.pdf},
  journal = {arXiv:1905.02383 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{dong2019Network,
  title = {Network {{Density}} of {{States}}},
  author = {Dong, Kun and Benson, Austin R. and Bindel, David},
  year = {2019},
  pages = {1152--1161},
  doi = {10.1145/3292500.3330891},
  abstract = {Spectral analysis connects graph structure to the eigenvalues and eigenvectors of associated matrices. Much of spectral graph theory descends directly from spectral geometry, the study of differentiable manifolds through the spectra of associated differential operators. But the translation from spectral geometry to spectral graph theory has largely focused on results involving only a few extreme eigenvalues and their associated eigenvalues. Unlike in geometry, the study of graphs through the overall distribution of eigenvalues - the spectral density - is largely limited to simple random graph models. The interior of the spectrum of real-world graphs remains largely unexplored, difficult to compute and to interpret. In this paper, we delve into the heart of spectral densities of real-world graphs. We borrow tools developed in condensed matter physics, and add novel adaptations to handle the spectral signatures of common graph motifs. The resulting methods are highly efficient, as we illustrate by computing spectral densities for graphs with over a billion edges on a single compute node. Beyond providing visually compelling fingerprints of graphs, we show how the estimation of spectral densities facilitates the computation of many common centrality measures, and use spectral densities to estimate meaningful information about graph structure that cannot be inferred from the extremal eigenpairs alone.},
  archivePrefix = {arXiv},
  eprint = {1905.09758},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Dong et al (2019) - Network Density of States.pdf},
  journal = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining  - KDD '19},
  keywords = {Computer Science - Social and Information Networks,Mathematics - Numerical Analysis}
}

@article{donoho2003Hessian,
  title = {Hessian Eigenmaps: {{Locally}} Linear Embedding Techniques for High-Dimensional Data},
  shorttitle = {Hessian Eigenmaps},
  author = {Donoho, David L. and Grimes, Carrie},
  year = {2003},
  month = may,
  volume = {100},
  pages = {5591--5596},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1031596100},
  abstract = {We describe a method for recovering the underlying parametrization of scattered data (mi) lying on a manifold M embedded in high-dimensional Euclidean space. The method, Hessian-based locally linear embedding, derives from a conceptual framework of local isometry in which the manifold M, viewed as a Riemannian submanifold of the ambient Euclidean space {$\mathbb{R}$}n, is locally isometric to an open, connected subset {$\Theta$} of Euclidean space {$\mathbb{R}$}d. Because {$\Theta$} does not have to be convex, this framework is able to handle a significantly wider class of situations than the original ISOMAP algorithm. The theoretical framework revolves around a quadratic form {$\mathscr{H}$}(f) = {$\int$}M {$\parallel$}Hf(m){$\parallel<$}img class="highwire-embed tex" alt="Math" src="https://www.pnas.org/sites/default/files/highwire/pnas/100/10/5591/embed/tex-math-1.gif"/{$>$}dm defined on functions f : M {$\mapsto$} {$\mathbb{R}$}. Here Hf denotes the Hessian of f, and {$\mathscr{H}$}(f) averages the Frobenius norm of the Hessian over M. To define the Hessian, we use orthogonal coordinates on the tangent planes of M. The key observation is that, if M truly is locally isometric to an open, connected subset of {$\mathbb{R}$}d, then {$\mathscr{H}$}(f) has a (d + 1)-dimensional null space consisting of the constant functions and a d-dimensional space of functions spanned by the original isometric coordinates. Hence, the isometric coordinates can be recovered up to a linear isometry. Our method may be viewed as a modification of locally linear embedding and our theoretical framework as a modification of the Laplacian eigenmaps framework, where we substitute a quadratic form based on the Hessian in place of one based on the Laplacian.},
  copyright = {Copyright \textcopyright{} 2003, The National Academy of Sciences},
  file = {/Users/yuekai/Documents/zotero/Donoho Grimes (2003) - Hessian eigenmaps.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {10},
  pmid = {16576753}
}

@article{dressel2018accuracy,
  title = {The Accuracy, Fairness, and Limits of Predicting Recidivism},
  author = {Dressel, Julia and Farid, Hany},
  year = {2018},
  month = jan,
  volume = {4},
  pages = {eaao5580},
  issn = {2375-2548},
  doi = {10.1126/sciadv.aao5580},
  abstract = {Algorithms for predicting recidivism are commonly used to assess a criminal defendant's likelihood of committing a crime. These predictions are used in pretrial, parole, and sentencing decisions. Proponents of these systems argue that big data and advanced machine learning make these analyses more accurate and less biased than humans. We show, however, that the widely used commercial risk assessment software COMPAS is no more accurate or fair than predictions made by people with little or no criminal justice expertise. In addition, despite COMPAS's collection of 137 features, the same accuracy can be achieved with a simple linear classifier with only two features.
Should we trust computers to make life-altering decisions in the criminal justice system?
Should we trust computers to make life-altering decisions in the criminal justice system?},
  copyright = {Copyright \textcopyright{} 2018 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution NonCommercial License 4.0 (CC BY-NC).. This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial license, which permits use, distribution, and reproduction in any medium, so long as the resultant use is not for commercial advantage and provided the original work is properly cited.},
  file = {/Users/yuekai/Documents/zotero/Dressel, Farid (2018) - The accuracy, fairness, and limits of predicting recidivism.pdf},
  journal = {Science Advances},
  language = {en},
  number = {1}
}

@article{drineas2016Workshop,
  title = {Workshop on ``{{Theoretical Foundations}} of {{Data Science}} ({{TFoDS}})''},
  author = {Drineas, P and Huo, X},
  year = {2016},
  month = apr,
  pages = {20},
  file = {/Users/yuekai/Documents/zotero/Drineas, Huo () - Workshop on “Theoretical Foundations of Data Science (TFoDS)”.pdf},
  language = {en}
}

@article{du1999Centroidal,
  title = {Centroidal {{Voronoi Tessellations}}: {{Applications}} and {{Algorithms}}},
  shorttitle = {Centroidal {{Voronoi Tessellations}}},
  author = {Du, Q. and Faber, V. and Gunzburger, M.},
  year = {1999},
  month = jan,
  volume = {41},
  pages = {637--676},
  issn = {0036-1445},
  doi = {10.1137/S0036144599352836},
  abstract = {A centroidal Voronoi tessellation is a Voronoi tessellation whose generating points are the centroids (centers of mass) of the corresponding Voronoi regions. We give some applications of such tessellations to problems in image compression, quadrature, finite difference methods, distribution of resources, cellular biology, statistics, and the territorial behavior of animals. We discuss methodsfor computing these tessellations, provide some analyses concerning both the tessellations and the methods for their determination, and, finally, present the results of some numerical experiments.},
  file = {/Users/yuekai/Documents/zotero/Du et al (1999) - Centroidal Voronoi Tessellations.pdf},
  journal = {SIAM Review},
  number = {4}
}

@article{du2018Gradient,
  title = {Gradient {{Descent Finds Global Minima}} of {{Deep Neural Networks}}},
  author = {Du, Simon S. and Lee, Jason D. and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
  year = {2018},
  month = nov,
  abstract = {Gradient descent finds a global minimum in training deep neural networks despite the objective function being non-convex. The current paper proves gradient descent achieves zero training loss in polynomial time for a deep over-parameterized neural network with residual connections (ResNet). Our analysis relies on the particular structure of the Gram matrix induced by the neural network architecture. This structure allows us to show the Gram matrix is stable throughout the training process and this stability implies the global optimality of the gradient descent algorithm. We further extend our analysis to deep residual convolutional neural networks and obtain a similar convergence result.},
  archivePrefix = {arXiv},
  eprint = {1811.03804},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Du et al (2018) - Gradient Descent Finds Global Minima of Deep Neural Networks.pdf},
  journal = {arXiv:1811.03804 [cs, math, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{du2019Good,
  title = {Is a {{Good Representation Sufficient}} for {{Sample Efficient Reinforcement Learning}}?},
  author = {Du, Simon S. and Kakade, Sham M. and Wang, Ruosong and Yang, Lin F.},
  year = {2019},
  month = oct,
  abstract = {Modern deep learning methods provide an effective means to learn good representations. However, is a good representation itself sufficient for efficient reinforcement learning? This question is largely unexplored, and the extant body of literature mainly focuses on conditions which permit efficient reinforcement learning with little understanding of what are necessary conditions for efficient reinforcement learning. This work provides strong negative results for reinforcement learning methods with function approximation for which a good representation (feature extractor) is known to the agent, focusing on natural representational conditions relevant to value-based learning and policy-based learning. For value-based learning, we show that even if the agent has a highly accurate linear representation, the agent still needs to sample exponentially many trajectories in order to find a near-optimal policy. For policy-based learning, we show even if the agent's linear representation is capable of perfectly representing the optimal policy, the agent still needs to sample exponentially many trajectories in order to find a near-optimal policy. These lower bounds highlight the fact that having a good (value-based or policy-based) representation in and of itself is insufficient for efficient reinforcement learning. In particular, these results provide new insights into why the existing provably efficient reinforcement learning methods rely on further assumptions, which are often model-based in nature. Additionally, our lower bounds imply exponential separations in the sample complexity between 1) valuebased learning with perfect representation and value-based learning with a good-but-not-perfect representation, 2) value-based learning and policy-based learning, 3) policy-based learning and supervised learning and 4) reinforcement learning and imitation learning.},
  archivePrefix = {arXiv},
  eprint = {1910.03016},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Du et al (2019) - Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning.pdf},
  journal = {arXiv:1910.03016 [cs, math, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, math, stat}
}

@article{du2020FewShot,
  title = {Few-{{Shot Learning}} via {{Learning}} the {{Representation}}, {{Provably}}},
  author = {Du, Simon S. and Hu, Wei and Kakade, Sham M. and Lee, Jason D. and Lei, Qi},
  year = {2020},
  month = feb,
  abstract = {This paper studies few-shot learning via representation learning, where one uses \$T\$ source tasks with \$n\_1\$ data per task to learn a representation in order to reduce the sample complexity of a target task for which there is only \$n\_2 (\textbackslash ll n\_1)\$ data. Specifically, we focus on the setting where there exists a good \textbackslash emph\{common representation\} between source and target, and our goal is to understand how much of a sample size reduction is possible. First, we study the setting where this common representation is low-dimensional and provide a fast rate of \$O\textbackslash left(\textbackslash frac\{\textbackslash mathcal\{C\}\textbackslash left(\textbackslash Phi\textbackslash right)\}\{n\_1T\} + \textbackslash frac\{k\}\{n\_2\}\textbackslash right)\$; here, \$\textbackslash Phi\$ is the representation function class, \$\textbackslash mathcal\{C\}\textbackslash left(\textbackslash Phi\textbackslash right)\$ is its complexity measure, and \$k\$ is the dimension of the representation. When specialized to linear representation functions, this rate becomes \$O\textbackslash left(\textbackslash frac\{dk\}\{n\_1T\} + \textbackslash frac\{k\}\{n\_2\}\textbackslash right)\$ where \$d (\textbackslash gg k)\$ is the ambient input dimension, which is a substantial improvement over the rate without using representation learning, i.e. over the rate of \$O\textbackslash left(\textbackslash frac\{d\}\{n\_2\}\textbackslash right)\$. Second, we consider the setting where the common representation may be high-dimensional but is capacity-constrained (say in norm); here, we again demonstrate the advantage of representation learning in both high-dimensional linear regression and neural network learning. Our results demonstrate representation learning can fully utilize all \$n\_1T\$ samples from source tasks.},
  archivePrefix = {arXiv},
  eprint = {2002.09434},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Du et al (2020) - Few-Shot Learning via Learning the Representation, Provably.pdf;/Users/yuekai/Zotero/storage/GHWNDWI3/2002.html},
  journal = {arXiv:2002.09434 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{duan2019Heterogeneityaware,
  title = {Heterogeneity-Aware and Communication-Efficient Distributed Statistical Inference},
  author = {Duan, Rui and Ning, Yang and Chen, Yong},
  year = {2019},
  month = dec,
  abstract = {In multicenter research, individual-level data are often protected against sharing across sites. To overcome the barrier of data sharing, many distributed algorithms, which only require sharing aggregated information, have been developed. The existing distributed algorithms usually assume the data are homogeneously distributed across sites. This assumption ignores the important fact that the data collected at different sites may come from various sub-populations and environments, which can lead to heterogeneity in the distribution of the data. Ignoring the heterogeneity may lead to erroneous statistical inference. In this paper, we propose distributed algorithms which account for the heterogeneous distributions by allowing site-specific nuisance parameters. The proposed methods extend the surrogate likelihood approach to the heterogeneous setting by applying a novel density ratio tilting method to the efficient score function. The proposed algorithms maintain same communication cost as the existing communication-efficient algorithms. We establish the non-asymptotic risk bound of the proposed distributed estimator and its limiting distribution in the two-index asymptotic setting. In addition, we show that the asymptotic variance of the estimator attains the Cram\textbackslash 'er-Rao lower bound. Finally, the simulation study shows the proposed algorithms reach higher estimation accuracy compared to several existing methods.},
  archivePrefix = {arXiv},
  eprint = {1912.09623},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Duan et al (2019) - Heterogeneity-aware and communication-efficient distributed statistical.pdf},
  journal = {arXiv:1912.09623 [cs, math, stat]},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing,Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {cs, math, stat}
}

@inproceedings{dubois2013Stochastic,
  title = {Stochastic Blockmodeling of Relational Event Dynamics},
  booktitle = {Artificial {{Intelligence}} and {{Statistics}}},
  author = {DuBois, Christopher and Butts, Carter and Smyth, Padhraic},
  year = {2013},
  month = apr,
  pages = {238--246},
  abstract = {Several approaches have recently been proposed for modeling of continuous-time network data via dyadic event rates conditioned on the observed history of events and nodal or dyadic covariates. In m...},
  file = {/Users/yuekai/Documents/zotero/DuBois et al (2013) - Stochastic blockmodeling of relational event dynamics.pdf},
  language = {en}
}

@article{duchi2015Asynchronous,
  title = {Asynchronous Stochastic Convex Optimization},
  author = {Duchi, John C. and Chaturapruek, Sorathan and R{\'e}, Christopher},
  year = {2015},
  month = aug,
  abstract = {We show that asymptotically, completely asynchronous stochastic gradient procedures achieve optimal (even to constant factors) convergence rates for the solution of convex optimization problems under nearly the same conditions required for asymptotic optimality of standard stochastic gradient procedures. Roughly, the noise inherent to the stochastic approximation scheme dominates any noise from asynchrony. We also give empirical evidence demonstrating the strong performance of asynchronous, parallel stochastic optimization schemes, demonstrating that the robustness inherent to stochastic approximation problems allows substantially faster parallel and asynchronous solution methods.},
  archivePrefix = {arXiv},
  eprint = {1508.00882},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Duchi et al (2015) - Asynchronous stochastic convex optimization.pdf},
  journal = {arXiv:1508.00882 [math, stat]},
  keywords = {Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {math, stat}
}

@article{duchi2016Statistics,
  title = {Statistics of {{Robust Optimization}}: {{A Generalized Empirical Likelihood Approach}}},
  shorttitle = {Statistics of {{Robust Optimization}}},
  author = {Duchi, John and Glynn, Peter and Namkoong, Hongseok},
  year = {2016},
  month = oct,
  abstract = {We study statistical inference and distributionally robust solution methods for stochastic optimization problems, focusing on confidence intervals for optimal values and solutions that achieve exact coverage asymptotically. We develop a generalized empirical likelihood framework---based on distributional uncertainty sets constructed from nonparametric \$f\$-divergence balls---for Hadamard differentiable functionals, and in particular, stochastic optimization problems. As consequences of this theory, we provide a principled method for choosing the size of distributional uncertainty regions to provide one- and two-sided confidence intervals that achieve exact coverage. We also give an asymptotic expansion for our distributionally robust formulation, showing how robustification regularizes problems by their variance. Finally, we show that optimizers of the distributionally robust formulations we study enjoy (essentially) the same consistency properties as those in classical sample average approximations. Our general approach applies to quickly mixing stationary sequences, including geometrically ergodic Harris recurrent Markov chains.},
  archivePrefix = {arXiv},
  eprint = {1610.03425},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Duchi et al (2016) - Statistics of Robust Optimization.pdf},
  journal = {arXiv:1610.03425 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{duchi2016Variancebased,
  title = {Variance-Based Regularization with Convex Objectives},
  author = {Duchi, John and Namkoong, Hongseok},
  year = {2016},
  month = oct,
  abstract = {We develop an approach to risk minimization and stochastic optimization that
provides a convex surrogate for variance, allowing near-optimal and
computationally efficient trading between approximation and estimation error.
Our approach builds off of techniques for distributionally robust optimization
and Owen's empirical likelihood, and we provide a number of finite-sample and
asymptotic results characterizing the theoretical performance of the estimator.
In particular, we show that our procedure comes with certificates of
optimality, achieving (in some scenarios) faster rates of convergence than
empirical risk minimization by virtue of automatically balancing bias and
variance. We give corroborating empirical evidence showing that in practice,
the estimator indeed trades between variance and absolute performance on a
training sample, improving out-of-sample (test) performance over standard
empirical risk minimization for a number of classification problems.},
  file = {/Users/yuekai/Documents/zotero/Duchi, Namkoong (2016) - Variance-based regularization with convex objectives.pdf},
  language = {en}
}

@article{duchi2018Learning,
  title = {Learning {{Models}} with {{Uniform Performance}} via {{Distributionally Robust Optimization}}},
  author = {Duchi, John and Namkoong, Hongseok},
  year = {2018},
  month = oct,
  abstract = {A common goal in statistics and machine learning is to learn models that can perform well against distributional shifts, such as latent heterogeneous subpopulations, unknown covariate shifts, or unmodeled temporal effects. We develop and analyze a distributionally robust stochastic optimization (DRO) framework that learns a model that provides good performance against perturbations to the data-generating distribution. We give a convex optimization formulation for the problem, providing several convergence guarantees. We prove finite-sample minimax upper and lower bounds, showing that distributinoal robustness sometimes comes at a cost in convergence rates. We give limit theorems for the learned parameters, where we fully specify the limiting distribution so that confidence intervals can be computed. On real tasks including generalizing to unknown subpopulations, fine-grained recognition, and providing good tail performance, the distributionally robust approach often exhibits improved performance.},
  archivePrefix = {arXiv},
  eprint = {1810.08750},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Duchi, Namkoong (2018) - Learning Models with Uniform Performance via Distributionally Robust.pdf},
  journal = {arXiv:1810.08750 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{duchi2018Right,
  title = {The {{Right Complexity Measure}} in {{Locally Private Estimation}}: {{It}} Is Not the {{Fisher Information}}},
  shorttitle = {The {{Right Complexity Measure}} in {{Locally Private Estimation}}},
  author = {Duchi, John C. and Ruan, Feng},
  year = {2018},
  month = jun,
  abstract = {We identify fundamental tradeoffs between statistical utility and privacy under local models of privacy in which data is kept private even from the statistician, providing instance-specific bounds for private estimation and learning problems by developing the \textbackslash emph\{local minimax risk\}. In contrast to approaches based on worst-case (minimax) error, which are conservative, this allows us to evaluate the difficulty of individual problem instances and delineate the possibilities for adaptation in private estimation and inference. Our main results show that the local modulus of continuity of the estimand with respect to the variation distance---as opposed to the Hellinger distance central to classical statistics---characterizes rates of convergence under locally private estimation for many notions of privacy, including differential privacy and its relaxations. As consequences of these results, we identify an alternative to the Fisher information for private estimation, giving a more nuanced understanding of the challenges of adaptivity and optimality, and provide new minimax bounds for high-dimensional estimation showing that even interactive locally private procedures suffer poor performance under weak notions of privacy.},
  archivePrefix = {arXiv},
  eprint = {1806.05756},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Duchi, Ruan (2018) - The Right Complexity Measure in Locally Private Estimation.pdf},
  journal = {arXiv:1806.05756 [cs, math, stat]},
  keywords = {Computer Science - Information Theory,Mathematics - Statistics Theory},
  primaryClass = {cs, math, stat}
}

@article{duchi2019Distributionally,
  title = {Distributionally {{Robust Losses Against Mixture Covariate Shifts}}},
  author = {Duchi, John C and Hashimoto, Tatsunori and Namkoong, Hongseok},
  year = {2019},
  abstract = {Modern large-scale datasets are often collected over heterogeneous subpopulations, such as multiple demographic groups or multiple text corpora. Minimizing average loss over such datasets fails to guarantee uniformly low losses across all subpopulations. We propose a convex procedure that controls the worst-case performance over all subpopulations of a certain size. Our procedure comes with finite-sample optimality guarantees on the worst off subpopulation, and converges at the standard nonparametric rate. Empirically, we observe on lexical similarity and recidivism prediction tasks that our worst-case procedure learns models that do well against unseen subpopulations.},
  file = {/Users/yuekai/Documents/zotero/Duchi et al (2019) - Distributionally Robust Losses Against Mixture Covariate Shifts.pdf},
  journal = {preprint},
  language = {en}
}

@article{duchi2020Distributionally,
  title = {Distributionally {{Robust Losses}} for {{Latent Covariate Mixtures}}},
  author = {Duchi, John and Hashimoto, Tatsunori and Namkoong, Hongseok},
  year = {2020},
  month = jul,
  abstract = {While modern large-scale datasets often consist of heterogeneous subpopulations---for example, multiple demographic groups or multiple text corpora---the standard practice of minimizing average loss fails to guarantee uniformly low losses across all subpopulations. We propose a convex procedure that controls the worst-case performance over all subpopulations of a given size. Our procedure comes with finite-sample (nonparametric) convergence guarantees on the worst-off subpopulation. Empirically, we observe on lexical similarity, wine quality, and recidivism prediction tasks that our worst-case procedure learns models that do well against unseen subpopulations.},
  archivePrefix = {arXiv},
  eprint = {2007.13982},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Duchi et al (2020) - Distributionally Robust Losses for Latent Covariate Mixtures.pdf;/Users/yuekai/Zotero/storage/IWMXVPME/2007.html},
  journal = {arXiv:2007.13982 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{dumbgen1993nondifferentiable,
  title = {On Nondifferentiable Functions and the Bootstrap},
  author = {Dumbgen, Lutz},
  year = {1993},
  volume = {95},
  pages = {125--140},
  abstract = {We investigate a class of statistical problems, where usual bootstrap methods fail, and discuss two alternative solutions. In particular, a stochastic procedure for constructing confidence sets is proposed. Special applications are the eigenvalues of a eovariance matrix and minimum distance functionals.},
  file = {/Users/yuekai/Documents/zotero/Dumbgen (1993) - On nondifferentiable functions and the bootstrap.pdf},
  journal = {Probability Theory and Related Fields},
  language = {en}
}

@article{duncan2019Analysis,
  title = {Analysis of Polygenic Risk Score Usage and Performance in Diverse Human Populations},
  author = {Duncan, L. and Shen, H. and Gelaye, B. and Meijsen, J. and Ressler, K. and Feldman, M. and Peterson, R. and Domingue, B.},
  year = {2019},
  month = jul,
  volume = {10},
  pages = {3328},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-11112-0},
  abstract = {A historical tendency to use European ancestry samples hinders medical genetics research, including the use of polygenic scores, which are individual-level metrics of genetic risk. We analyze the first decade of polygenic scoring studies (2008\textendash 2017, inclusive), and find that 67\% of studies included exclusively European ancestry participants and another 19\% included only East Asian ancestry participants. Only 3.8\% of studies were among cohorts of African, Hispanic, or Indigenous peoples. We find that predictive performance of European ancestry-derived polygenic scores is lower in non-European ancestry samples (e.g. African ancestry samples: t\,=\,-5.97, df\,=\,24, p\,=\,3.7\,\texttimes\,10-6), and we demonstrate the effects of methodological choices in polygenic score distributions for worldwide populations. These findings highlight the need for improved treatment of linkage disequilibrium and variant frequencies when applying polygenic scoring to cohorts of non-European ancestry, and bolster the rationale for large-scale GWAS in diverse human populations.},
  copyright = {2019 The Author(s)},
  file = {/Users/yuekai/Documents/zotero/Duncan et al (2019) - Analysis of polygenic risk score usage and performance in diverse human.pdf;/Users/yuekai/Zotero/storage/ZMIJK69C/s41467-019-11112-0.html},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@book{dunford1958Linear,
  title = {Linear {{Operators}}},
  author = {Dunford, Nelson and Schwartz, Jacob T. and Bade, William G. and Bartle, Robert G.},
  year = {1958},
  publisher = {{Interscience Publishers}},
  file = {/Users/yuekai/Documents/zotero/Dunford et al (1958) - Linear Operators.pdf},
  language = {en}
}

@article{dutta2019InformationTheoretic,
  title = {An {{Information}}-{{Theoretic Perspective}} on the {{Relationship Between Fairness}} and {{Accuracy}}},
  author = {Dutta, Sanghamitra and Wei, Dennis and Yueksel, Hazar and Chen, Pin-Yu and Liu, Sijia and Varshney, Kush R.},
  year = {2019},
  month = oct,
  abstract = {Our goal is to understand the so-called trade-off between fairness and accuracy. In this work, using a tool from information theory called Chernoff information, we derive fundamental limits on this relationship that explain why the accuracy on a given dataset often decreases as fairness increases. Novel to this work, we examine the problem of fair classification through the lens of a mismatched hypothesis testing problem, i.e., where we are trying to find a classifier that distinguishes between two "ideal" distributions but instead we are given two mismatched distributions that are biased. Based on this perspective, we contend that measuring accuracy with respect to the given (possibly biased) dataset is a problematic measure of performance. Instead one should also consider accuracy with respect to an ideal dataset that is unbiased. We formulate an optimization to find such ideal distributions and show that the optimization is feasible. Lastly, when the Chernoff information for one group is strictly less than another in the given dataset, we derive the information-theoretic criterion under which collection of more features can actually improve the Chernoff information and achieve fairness without compromising accuracy on the available data.},
  archivePrefix = {arXiv},
  eprint = {1910.07870},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Dutta et al (2019) - An Information-Theoretic Perspective on the Relationship Between Fairness and.pdf},
  journal = {arXiv:1910.07870 [cs, math, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Information Theory,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{dwivedi2019Challenges,
  title = {Challenges with {{EM}} in Application to Weakly Identifiable Mixture Models},
  author = {Dwivedi, Raaz and Ho, Nhat and Khamaru, Koulik and Wainwright, Martin J. and Jordan, Michael I. and Yu, Bin},
  year = {2019},
  month = feb,
  abstract = {We study a class of weakly identifiable location-scale mixture models for which the maximum likelihood estimates based on \$n\$ i.i.d. samples are known to have lower accuracy than the classical \$n\^\{- \textbackslash frac\{1\}\{2\}\}\$ error. We investigate whether the Expectation-Maximization (EM) algorithm also converges slowly for these models. We first demonstrate via simulation studies a broad range of over-specified mixture models for which the EM algorithm converges very slowly, both in one and higher dimensions. We provide a complete analytical characterization of this behavior for fitting data generated from a multivariate standard normal distribution using two-component Gaussian mixture with varying location and scale parameters. Our results reveal distinct regimes in the convergence behavior of EM as a function of the dimension \$d\$. In the multivariate setting (\$d \textbackslash geq 2\$), when the covariance matrix is constrained to a multiple of the identity matrix, the EM algorithm converges in order \$(n/d)\^\{\textbackslash frac\{1\}\{2\}\}\$ steps and returns estimates that are at a Euclidean distance of order \$\{(n/d)\^\{-\textbackslash frac\{1\}\{4\}\}\}\$ and \$\{ (n d)\^\{- \textbackslash frac\{1\}\{2\}\}\}\$ from the true location and scale parameter respectively. On the other hand, in the univariate setting (\$d = 1\$), the EM algorithm converges in order \$n\^\{\textbackslash frac\{3\}\{4\} \}\$ steps and returns estimates that are at a Euclidean distance of order \$\{ n\^\{- \textbackslash frac\{1\}\{8\}\}\}\$ and \$\{ n\^\{-\textbackslash frac\{1\} \{4\}\}\}\$ from the true location and scale parameter respectively. Establishing the slow rates in the univariate setting requires a novel localization argument with two stages, with each stage involving an epoch-based argument applied to a different surrogate EM operator at the population level. We also show multivariate (\$d \textbackslash geq 2\$) examples, involving more general covariance matrices, that exhibit the same slow rates as the univariate case.},
  archivePrefix = {arXiv},
  eprint = {1902.00194},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Dwivedi et al (2019) - Challenges with EM in application to weakly identifiable mixture models.pdf},
  journal = {arXiv:1902.00194 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{dwork2011Fairness,
  title = {Fairness {{Through Awareness}}},
  author = {Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Rich},
  year = {2011},
  month = apr,
  abstract = {We study fairness in classification, where individuals are classified, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classifier (the university). The main conceptual contribution of this paper is a framework for fair classification comprising (1) a (hypothetical) task-specific metric for determining the degree to which individuals are similar with respect to the classification task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of "fair affirmative action," which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classification are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of differential privacy may be applied to fairness.},
  archivePrefix = {arXiv},
  eprint = {1104.3913},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Dwork et al (2011) - Fairness Through Awareness.pdf},
  journal = {arXiv:1104.3913 [cs]},
  keywords = {Computer Science - Computational Complexity,Computer Science - Computers and Society},
  primaryClass = {cs}
}

@article{dwork2020Individual,
  title = {Individual {{Fairness}} in {{Pipelines}}},
  author = {Dwork, Cynthia and Ilvento, Christina and Jagadeesan, Meena},
  year = {2020},
  month = apr,
  abstract = {It is well understood that a system built from individually fair components may not itself be individually fair. In this work, we investigate individual fairness under pipeline composition. Pipelines differ from ordinary sequential or repeated composition in that individuals may drop out at any stage, and classification in subsequent stages may depend on the remaining "cohort" of individuals. As an example, a company might hire a team for a new project and at a later point promote the highest performer on the team. Unlike other repeated classification settings, where the degree of unfairness degrades gracefully over multiple fair steps, the degree of unfairness in pipelines can be arbitrary, even in a pipeline with just two stages. Guided by a panoply of real-world examples, we provide a rigorous framework for evaluating different types of fairness guarantees for pipelines. We show that na\textbackslash "\{i\}ve auditing is unable to uncover systematic unfairness and that, in order to ensure fairness, some form of dependence must exist between the design of algorithms at different stages in the pipeline. Finally, we provide constructions that permit flexibility at later stages, meaning that there is no need to lock in the entire pipeline at the time that the early stage is constructed.},
  archivePrefix = {arXiv},
  eprint = {2004.05167},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Dwork et al (2020) - Individual Fairness in Pipelines.pdf},
  journal = {arXiv:2004.05167 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{edelman1998Geometry,
  title = {The {{Geometry}} of {{Algorithms}} with {{Orthogonality Constraints}}},
  author = {Edelman, Alan and Arias, Tom{\'a}s A. and Smith, Steven T.},
  year = {1998},
  month = jan,
  volume = {20},
  pages = {303--353},
  issn = {0895-4798, 1095-7162},
  doi = {10.1137/S0895479895290954},
  abstract = {In this paper we develop new Newton and conjugate gradient algorithms on the Grassmann and Stiefel manifolds. These manifolds represent the constraints that arise in such areas as the symmetric eigenvalue problem, nonlinear eigenvalue problems, electronic structures computations, and signal processing. In addition to the new algorithms, we show how the geometrical framework gives penetrating new insights allowing us to create, understand, and compare algorithms. The theory proposed here provides a taxonomy for numerical linear algebra algorithms that provide a top level mathematical view of previously unrelated algorithms. It is our hope that developers of new algorithms and perturbation theories will benefit from the theory, methods, and examples in this paper.},
  file = {/Users/yuekai/Documents/zotero/Edelman et al (1998) - The Geometry of Algorithms with Orthogonality Constraints.pdf},
  journal = {SIAM Journal on Matrix Analysis and Applications},
  language = {en},
  number = {2}
}

@article{edwards2015Censoring,
  title = {Censoring {{Representations}} with an {{Adversary}}},
  author = {Edwards, Harrison and Storkey, Amos},
  year = {2015},
  month = nov,
  abstract = {In practice, there are often explicit constraints on what representations or decisions are acceptable in an application of machine learning. For example it may be a legal requirement that a decision must not favour a particular group. Alternatively it can be that that representation of data must not have identifying information. We address these two related issues by learning flexible representations that minimize the capability of an adversarial critic. This adversary is trying to predict the relevant sensitive variable from the representation, and so minimizing the performance of the adversary ensures there is little or no information in the representation about the sensitive variable. We demonstrate this adversarial approach on two problems: making decisions free from discrimination and removing private information from images. We formulate the adversarial model as a minimax problem, and optimize that minimax objective using a stochastic gradient alternate min-max optimizer. We demonstrate the ability to provide discriminant free representations for standard test problems, and compare with previous state of the art methods for fairness, showing statistically significant improvement across most cases. The flexibility of this method is shown via a novel problem: removing annotations from images, from unaligned training examples of annotated and unannotated images, and with no a priori knowledge of the form of annotation provided to the model.},
  archivePrefix = {arXiv},
  eprint = {1511.05897},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Edwards, Storkey (2015) - Censoring Representations with an Adversary.pdf},
  journal = {arXiv:1511.05897 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{efron2007Size,
  title = {Size, Power and False Discovery Rates},
  author = {Efron, Bradley},
  year = {2007},
  month = aug,
  volume = {35},
  pages = {1351--1377},
  issn = {0090-5364},
  doi = {10.1214/009053606000001460},
  abstract = {Modern scientific technology has provided a new class of large-scale simultaneous inference problems, with thousands of hypothesis tests to consider at the same time. Microarrays epitomize this type of technology, but similar situations arise in proteomics, spectroscopy, imaging, and social science surveys. This paper uses false discovery rate methods to carry out both size and power calculations on large-scale problems. A simple empirical Bayes approach allows the false discovery rate (fdr) analysis to proceed with a minimum of frequentist or Bayesian modeling assumptions. Closed-form accuracy formulas are derived for estimated false discovery rates, and used to compare different methodologies: local or tail-area fdr's, theoretical, permutation, or empirical null hypothesis estimates. Two microarray data sets as well as simulations are used to evaluate the methodology, the power diagnostics showing why nonnull cases might easily fail to appear on a list of ``significant'' discoveries.},
  archivePrefix = {arXiv},
  eprint = {0710.2245},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Efron (2007) - Size, power and false discovery rates.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory},
  number = {4}
}

@article{efron2011Tweedie,
  title = {Tweedie's {{Formula}} and {{Selection Bias}}},
  author = {Efron, Bradley},
  year = {2011},
  month = dec,
  volume = {106},
  pages = {1602--1614},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1198/jasa.2011.tm11181},
  abstract = {We suppose that the statistician observes some large number of estimates zi, each with its own unobserved expectation parameter {$\mu$}i. The largest few of the zi's are likely to substantially overestimate their corresponding {$\mu$}i's, this being an example of selection bias, or regression to the mean. Tweedie's formula, first reported by Robbins in 1956, offers a simple empirical Bayes approach for correcting selection bias. This article investigates its merits and limitations. In addition to the methodology, Tweedie's formula raises more general questions concerning empirical Bayes theory, discussed here as ``relevance'' and ``empirical Bayes information.'' There is a close connection between applications of the formula and James\textendash Stein estimation.},
  annotation = {\_eprint: https://doi.org/10.1198/jasa.2011.tm11181},
  file = {/Users/yuekai/Documents/zotero/Efron (2011) - Tweedie’s Formula and Selection Bias.pdf;/Users/yuekai/Zotero/storage/GBKSXRRK/jasa.2011.html},
  journal = {Journal of the American Statistical Association},
  keywords = {Bayesian relevance,Empirical Bayes information,False discovery rates,James–Stein,Regret,Winner’s curse},
  number = {496}
}

@article{efron2014Two,
  title = {Two {{Modeling Strategies}} for {{Empirical Bayes Estimation}}},
  author = {Efron, Bradley},
  year = {2014},
  month = may,
  volume = {29},
  pages = {285--301},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/13-STS455},
  abstract = {Empirical Bayes methods use the data from parallel experiments, for instance, observations Xk{$\sim$}({$\Theta$}k,1)Xk{$\sim$}N({$\Theta$}k,1)X\_\{k\}\textbackslash sim\textbackslash mathcal\{N\}(\textbackslash Theta\_\{k\},1) for k=1,2,\ldots,Nk=1,2,\ldots,Nk=1,2,\textbackslash ldots,N, to estimate the conditional distributions {$\Theta$}k|Xk{$\Theta$}k|Xk\textbackslash Theta\_\{k\}|X\_\{k\}. There are two main estimation strategies: modeling on the \texttheta\texttheta\textbackslash theta space, called ``ggg-modeling'' here, and modeling on the xxx space, called ``fff-modeling.'' The two approaches are described and compared. A series of computational formulas are developed to assess their frequentist accuracy. Several examples, both contrived and genuine, show the strengths and limitations of the two strategies.},
  file = {/Users/yuekai/Documents/zotero/Efron (2014) - Two Modeling Strategies for Empirical Bayes Estimation.pdf;/Users/yuekai/Zotero/storage/SJHSBBD7/1408368582.html},
  journal = {Statistical Science},
  keywords = {$f$-modeling,$g$-modeling,Bayes rule in terms of $f$,prior exponential families},
  language = {EN},
  mrnumber = {MR3264543},
  number = {2},
  zmnumber = {1332.62031}
}

@article{efron2019Bayes,
  title = {Bayes, {{Oracle Bayes}} and {{Empirical Bayes}}},
  author = {Efron, Bradley},
  year = {2019},
  month = may,
  volume = {34},
  pages = {177--201},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/18-STS674},
  abstract = {This article concerns the Bayes and frequentist aspects of empirical Bayes inference. Some of the ideas explored go back to Robbins in the 1950s, while others are current. Several examples are discussed, real and artificial, illustrating the two faces of empirical Bayes methodology: ``oracle Bayes'' shows empirical Bayes in its most frequentist mode, while ``finite Bayes inference'' is a fundamentally Bayesian application. In either case, modern theory and computation allow us to present a sharp finite-sample picture of what is at stake in an empirical Bayes analysis.},
  file = {/Users/yuekai/Documents/zotero/Efron (2019) - Bayes, Oracle Bayes and Empirical Bayes.pdf},
  journal = {Statistical Science},
  language = {EN},
  mrnumber = {MR3983318},
  number = {2},
  zmnumber = {1420.62023}
}

@article{einav2014Economics,
  title = {Economics in the Age of Big Data},
  author = {Einav, Liran and Levin, Jonathan},
  year = {2014},
  month = nov,
  volume = {346},
  pages = {1243089},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1243089},
  abstract = {Structured Abstract
Background Economic science has evolved over several decades toward greater emphasis on empirical work. The data revolution of the past decade is likely to have a further and profound effect on economic research. Increasingly, economists make use of newly available large-scale administrative data or private sector data that often are obtained through collaborations with private firms, giving rise to new opportunities and challenges.
{$<$}img class="highwire-embed" alt="Embedded Image" src="http://science.sciencemag.org/sites/default/files/highwire/sci/346/6210/1243089/embed/inline-graphic-1.gif"/{$>$}The rising use of non\textendash publicly available data in economic research. Here we show the percentage of papers published in the American Economic Review (AER) that obtained an exemption from the AER's data availability policy, as a share of all papers published by the AER that relied on any form of data (excluding simulations and laboratory experiments). Notes and comments, as well as AER Papers and Proceedings issues, are not included in the analysis. We obtained a record of exemptions directly from the AER administrative staff and coded each exemption manually to reflect public sector versus private data. Our check of nonexempt papers suggests that the AER records may possibly understate the percentage of papers that actually obtained exemptions. The asterisk indicates that data run from when the AER started collecting these data (December 2005 issue) to the September 2014 issue. To make full use of the data, we define year 2006 to cover October 2005 through September 2006, year 2007 to cover October 2006 through September 2007, and so on.
Advances These new data are affecting economic research along several dimensions. Many fields have shifted from a reliance on relatively small-sample government surveys to administrative data with universal or near-universal population coverage. This shift is transformative, as it allows researchers to rigorously examine variation in wages, health, productivity, education, and other measures across different subpopulations; construct consistent long-run statistical indices; generate new quasi-experimental research designs; and track diverse outcomes from natural and controlled experiments. Perhaps even more notable is the expansion of private sector data on economic activity. These data, sometimes available from public sources but other times obtained through data-sharing agreements with private firms, can help to create more granular and real-time measurement of aggregate economic statistics. The data also offer researchers a look inside the ``black box'' of firms and markets by providing meaningful statistics on economic behavior such as search and information gathering, communication, decision-making, and microlevel transactions. Collaborations with data-oriented firms also create new opportunities to conduct and evaluate randomized experiments. Economic theory plays an important role in the analysis of large data sets with complex structure. It can be difficult to organize and study this type of data (or even to decide which variables to construct) without a simplifying conceptual framework, which is where economic models become useful. Better data also allow for sharper tests of existing models and tests of theories that had previously been difficult to assess.
Outlook The advent of big data is already allowing for better measurement of economic effects and outcomes and is enabling novel research designs across a range of topics. Over time, these data are likely to affect the types of questions economists pose, by allowing for more focus on population variation and the analysis of a broader range of economic activities and interactions. We also expect economists to increasingly adopt the large-data statistical methods that have been developed in neighboring fields and that often may complement traditional econometric techniques. These data opportunities also raise some important challenges. Perhaps the primary one is developing methods for researchers to access and explore data in ways that respect privacy and confidentiality concerns. This is a major issue in working with both government administrative data and private sector firms. Other challenges include developing the appropriate data management and programming capabilities, as well as designing creative and scalable approaches to summarize, describe, and analyze large-scale and relatively unstructured data sets. These challenges notwithstanding, the next few decades are likely to be a very exciting time for economic research.
The quality and quantity of data on economic activity are expanding rapidly. Empirical research increasingly relies on newly available large-scale administrative data or private sector data that often is obtained through collaboration with private firms. Here we highlight some challenges in accessing and using these new data. We also discuss how new data sets may change the statistical methods used by economists and the types of questions posed in empirical research.},
  copyright = {Copyright \textcopyright{} 2014, American Association for the Advancement of Science},
  file = {/Users/yuekai/Documents/zotero/Einav, Levin (2014) - Economics in the age of big data.pdf},
  journal = {Science},
  language = {en},
  number = {6210},
  pmid = {25378629}
}

@inproceedings{ekstrand2019Fairness,
  title = {Fairness and {{Discrimination}} in {{Retrieval}} and {{Recommendation}}},
  booktitle = {Proceedings of the 42nd {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Ekstrand, Michael D. and Burke, Robin and Diaz, Fernando},
  year = {2019},
  month = jul,
  pages = {1403--1404},
  publisher = {{Association for Computing Machinery}},
  address = {{Paris, France}},
  doi = {10.1145/3331184.3331380},
  abstract = {Fairness and related concerns have become of increasing importance in a variety of AI and machine learning contexts. They are also highly relevant to information retrieval and related problems such as recommendation, as evidenced by the growing literature in SIGIR, FAT*, RecSys, and special sessions such as the FATREC workshop and the Fairness track at TREC 2019; however, translating algorithmic fairness constructs from classification, scoring, and even many ranking settings into information retrieval and recommendation scenarios is not a straightforward task. This tutorial will help to orient IR researchers to algorithmic fairness, understand how concepts do and do not translate from other settings, and provide an introduction to the growing literature on this topic.},
  file = {/Users/yuekai/Documents/zotero/Ekstrand et al (2019) - Fairness and Discrimination in Retrieval and Recommendation.pdf},
  isbn = {978-1-4503-6172-9},
  series = {{{SIGIR}}'19}
}

@article{eldridge2017Unperturbed,
  title = {Unperturbed: Spectral Analysis beyond {{Davis}}-{{Kahan}}},
  shorttitle = {Unperturbed},
  author = {Eldridge, Justin and Belkin, Mikhail and Wang, Yusu},
  year = {2017},
  month = jun,
  abstract = {Classical matrix perturbation results, such as Weyl's theorem for eigenvalues and the Davis-Kahan theorem for eigenvectors, are general purpose. These classical bounds are tight in the worst case, but in many settings sub-optimal in the typical case. In this paper, we present perturbation bounds which consider the nature of the perturbation and its interaction with the unperturbed structure in order to obtain significant improvements over the classical theory in many scenarios, such as when the perturbation is random. We demonstrate the utility of these new results by analyzing perturbations in the stochastic blockmodel where we derive much tighter bounds than provided by the classical theory. We use our new perturbation theory to show that a very simple and natural clustering algorithm -- whose analysis was difficult using the classical tools -- nevertheless recovers the communities of the blockmodel exactly even in very sparse graphs.},
  archivePrefix = {arXiv},
  eprint = {1706.06516},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Eldridge et al (2017) - Unperturbed.pdf},
  journal = {arXiv:1706.06516 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{elzayn2018Fair,
  title = {Fair {{Algorithms}} for {{Learning}} in {{Allocation Problems}}},
  author = {Elzayn, Hadi and Jabbari, Shahin and Jung, Christopher and Kearns, Michael and Neel, Seth and Roth, Aaron and Schutzman, Zachary},
  year = {2018},
  month = aug,
  abstract = {Settings such as lending and policing can be modeled by a centralized agent allocating a resource (loans or police officers) amongst several groups, in order to maximize some objective (loans given that are repaid or criminals that are apprehended). Often in such problems fairness is also a concern. A natural notion of fairness, based on general principles of equality of opportunity, asks that conditional on an individual being a candidate for the resource, the probability of actually receiving it is approximately independent of the individual's group. In lending this means that equally creditworthy individuals in different racial groups have roughly equal chances of receiving a loan. In policing it means that two individuals committing the same crime in different districts would have roughly equal chances of being arrested. We formalize this fairness notion for allocation problems and investigate its algorithmic consequences. Our main technical results include an efficient learning algorithm that converges to an optimal fair allocation even when the frequency of candidates (creditworthy individuals or criminals) in each group is unknown. The algorithm operates in a censored feedback model in which only the number of candidates who received the resource in a given allocation can be observed, rather than the true number of candidates. This models the fact that we do not learn the creditworthiness of individuals we do not give loans to nor learn about crimes committed if the police presence in a district is low. As an application of our framework, we consider the predictive policing problem. The learning algorithm is trained on arrest data gathered from its own deployments on previous days, resulting in a potential feedback loop that our algorithm provably overcomes. We empirically investigate the performance of our algorithm on the Philadelphia Crime Incidents dataset.},
  archivePrefix = {arXiv},
  eprint = {1808.10549},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Elzayn et al (2018) - Fair Algorithms for Learning in Allocation Problems.pdf},
  journal = {arXiv:1808.10549 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{engstrom2019Learning,
  title = {Learning {{Perceptually}}-{{Aligned Representations}} via {{Adversarial Robustness}}},
  author = {Engstrom, Logan and Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Tran, Brandon and Madry, Aleksander},
  year = {2019},
  month = jun,
  abstract = {Many applications of machine learning require models that are human-aligned, i.e., that make decisions based on human-meaningful information about the input. We identify the pervasive brittleness of deep networks' learned representations as a fundamental barrier to attaining this goal. We then re-cast robust optimization as a tool for enforcing human priors on the features learned by deep neural networks. The resulting robust feature representations turn out to be significantly more aligned with human perception. We leverage these representations to perform input interpolation, feature manipulation, and sensitivity mapping, without any post-processing or human intervention after model training. Our code and models for reproducing these results is available at https://git.io/robust-reps.},
  archivePrefix = {arXiv},
  eprint = {1906.00945},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Engstrom et al (2019) - Learning Perceptually-Aligned Representations via Adversarial Robustness.pdf},
  journal = {arXiv:1906.00945 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{esfahani2015Datadriven,
  title = {Data-Driven {{Distributionally Robust Optimization Using}} the {{Wasserstein Metric}}: {{Performance Guarantees}} and {{Tractable Reformulations}}},
  shorttitle = {Data-Driven {{Distributionally Robust Optimization Using}} the {{Wasserstein Metric}}},
  author = {Esfahani, Peyman Mohajerin and Kuhn, Daniel},
  year = {2015},
  month = may,
  abstract = {We consider stochastic programs where the distribution of the uncertain
parameters is only observable through a finite training dataset. Using the
Wasserstein metric, we construct a ball in the space of (multivariate and
non-discrete) probability distributions centered at the uniform distribution on
the training samples, and we seek decisions that perform best in view of the
worst-case distribution within this Wasserstein ball. The state-of-the-art
methods for solving the resulting distributionally robust optimization problems
rely on global optimization techniques, which quickly become computationally
excruciating. In this paper we demonstrate that, under mild assumptions, the
distributionally robust optimization problems over Wasserstein balls can in
fact be reformulated as finite convex programs---in many interesting cases even
as tractable linear programs. Leveraging recent measure concentration results,
we also show that their solutions enjoy powerful finite-sample performance
guarantees. Our theoretical results are exemplified in mean-risk portfolio
optimization as well as uncertainty quantification.},
  file = {/Users/yuekai/Documents/zotero/Esfahani, Kuhn (2015) - Data-driven Distributionally Robust Optimization Using the Wasserstein Metric.pdf},
  language = {en}
}

@article{evans1983Introduction,
  title = {An {{Introduction}} to {{Mathematical Optimal Control Theory Version}} 0.2},
  author = {Evans, Lawrence C},
  year = {1983},
  pages = {126},
  file = {/Users/yuekai/Documents/zotero/Evans (1983) - An Introduction to Mathematical Optimal Control Theory Version 0.pdf},
  language = {en}
}

@article{evans2019Statistically,
  title = {Statistically {{Valid Inferences}} from {{Privacy Protected Data}}},
  author = {Evans, Georgina and King, Gary and Schwenzfeier, Margaret and Thakurta, Abhradeep},
  year = {2019},
  month = nov,
  pages = {33},
  abstract = {Unprecedented quantities of data that could help social scientists understand and ameliorate the challenges of human society are presently locked away inside companies, governments, and other organizations, in part because of worries about privacy violations. We address this problem with a general-purpose data access and analysis system with mathematical guarantees of privacy for individuals who may be represented in the data, statistical guarantees for researchers seeking insights from it, and protection for society from some fallacious scientific conclusions. We build on the standard of ``differential privacy'' but, unlike most such approaches, we also correct for the serious statistical biases induced by privacy-preserving procedures, provide a proper accounting for statistical uncertainty, and impose minimal constraints on the choice of data analytic methods and types of quantities estimated. Our algorithm is easy to implement, simple to use, and computationally efficient; we also offer open source software to illustrate all our methods.},
  file = {/Users/yuekai/Documents/zotero/Evans et al (2019) - Statistically Valid Inferences from Privacy Protected Data.pdf},
  language = {en}
}

@book{facchinei2003Finitedimensional,
  title = {Finite-Dimensional Variational Inequalities and Complementarity Problems {{II}}},
  author = {Facchinei, Francisco and Pang, Jong-Shi},
  year = {2003},
  publisher = {{Springer}},
  address = {{New York}},
  file = {/Users/yuekai/Documents/zotero/Facchinei, Pang (2003) - Finite-dimensional variational inequalities and complementarity problems I.pdf},
  isbn = {978-0-387-95580-3 978-0-387-95581-0},
  language = {en},
  lccn = {QA316 .P36 2003},
  series = {Springer Series in Operations Research}
}

@book{facchinei2003Finitedimensionala,
  title = {Finite-Dimensional Variational Inequalities and Complementarity Problems {{I}}},
  author = {Facchinei, Francisco and Pang, Jong-Shi},
  year = {2003},
  publisher = {{Springer}},
  address = {{New York}},
  file = {/Users/yuekai/Documents/zotero/Facchinei, Pang (2003) - Finite-dimensional variational inequalities and complementarity problems II.pdf},
  isbn = {978-0-387-95580-3 978-0-387-95581-0},
  language = {en},
  lccn = {QA316 .P36 2003},
  series = {Springer Series in Operations Research}
}

@article{fallah2020Personalized,
  title = {Personalized {{Federated Learning}}: {{A Meta}}-{{Learning Approach}}},
  shorttitle = {Personalized {{Federated Learning}}},
  author = {Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman},
  year = {2020},
  month = feb,
  abstract = {The goal of federated learning is to design algorithms in which several agents communicate with a central node, in a privacy-protecting manner, to minimize the average of their loss functions. In this approach, each node not only shares the required computational budget but also has access to a larger data set, which improves the quality of the resulting model. However, this method only develops a common output for all the agents, and therefore, does not adapt the model to each user data. This is an important missing feature especially given the heterogeneity of the underlying data distribution for various agents. In this paper, we study a personalized variant of the federated learning in which our goal is to find a shared initial model in a distributed manner that can be slightly updated by either a current or a new user by performing one or a few steps of gradient descent with respect to its own loss function. This approach keeps all the benefits of the federated learning architecture while leading to a more personalized model for each user. We show this problem can be studied within the Model-Agnostic Meta-Learning (MAML) framework. Inspired by this connection, we propose a personalized variant of the well-known Federated Averaging algorithm and evaluate its performance in terms of gradient norm for non-convex loss functions. Further, we characterize how this performance is affected by the closeness of underlying distributions of user data, measured in terms of distribution distances such as Total Variation and 1-Wasserstein metric.},
  archivePrefix = {arXiv},
  eprint = {2002.07948},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fallah et al (2020) - Personalized Federated Learning.pdf},
  journal = {arXiv:2002.07948 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{fama1975ShortTerm,
  title = {Short-{{Term Interest Rates}} as {{Predictors}} of {{Inflation}}},
  author = {Fama, Eugene F.},
  year = {1975},
  volume = {65},
  pages = {269--282},
  issn = {0002-8282},
  journal = {The American Economic Review},
  number = {3}
}

@article{fan1955Metric,
  title = {Some {{Metric Inequalities}} in the {{Space}} of {{Matrices}}},
  author = {Fan, Ky and Hoffman, A. J.},
  year = {1955},
  volume = {6},
  pages = {111--116},
  issn = {0002-9939},
  doi = {10.2307/2032662},
  journal = {Proceedings of the American Mathematical Society},
  number = {1}
}

@article{fan2011Large,
  title = {Large {{Covariance Estimation}} by {{Thresholding Principal Orthogonal Complements}}},
  author = {Fan, Jianqing and Liao, Yuan and Mincheva, Martina},
  year = {2011},
  month = dec,
  abstract = {This paper deals with the estimation of a high-dimensional covariance with a conditional sparsity structure and fast-diverging eigenvalues. By assuming sparse error covariance matrix in an approximate factor model, we allow for the presence of some cross-sectional correlation even after taking out common but unobservable factors. We introduce the Principal Orthogonal complEment Thresholding (POET) method to explore such an approximate factor structure with sparsity. The POET estimator includes the sample covariance matrix, the factor-based covariance matrix (Fan, Fan, and Lv, 2008), the thresholding estimator (Bickel and Levina, 2008) and the adaptive thresholding estimator (Cai and Liu, 2011) as specific examples. We provide mathematical insights when the factor analysis is approximately the same as the principal component analysis for high-dimensional data. The rates of convergence of the sparse residual covariance matrix and the conditional sparse covariance matrix are studied under various norms. It is shown that the impact of estimating the unknown factors vanishes as the dimensionality increases. The uniform rates of convergence for the unobserved factors and their factor loadings are derived. The asymptotic results are also verified by extensive simulation studies. Finally, a real data application on portfolio allocation is presented.},
  archivePrefix = {arXiv},
  eprint = {1201.0175},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fan et al (2011) - Large Covariance Estimation by Thresholding Principal Orthogonal Complements.pdf},
  journal = {arXiv:1201.0175 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{fan2012Variable,
  title = {Variable Selection in Linear Mixed Effects Models},
  author = {Fan, Yingying and Li, Runze},
  year = {2012},
  month = aug,
  volume = {40},
  pages = {2043--2068},
  issn = {0090-5364},
  doi = {10.1214/12-AOS1028},
  abstract = {This paper is concerned with the selection and estimation of fixed and random effects in linear mixed effects models. We propose a class of nonconcave penalized profile likelihood methods for selecting and estimating important fixed effects. To overcome the difficulty of unknown covariance matrix of random effects, we propose to use a proxy matrix in the penalized profile likelihood. We establish conditions on the choice of the proxy matrix and show that the proposed procedure enjoys the model selection consistency where the number of fixed effects is allowed to grow exponentially with the sample size. We further propose a group variable selection strategy to simultaneously select and estimate important random effects, where the unknown covariance matrix of random effects is replaced with a proxy matrix. We prove that, with the proxy matrix appropriately chosen, the proposed procedure can identify all true random effects with asymptotic probability one, where the dimension of random effects vector is allowed to increase exponentially with the sample size. Monte Carlo simulation studies are conducted to examine the finite-sample performance of the proposed procedures. We further illustrate the proposed procedures via a real data example.},
  archivePrefix = {arXiv},
  eprint = {1211.0457},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fan, Li (2012) - Variable selection in linear mixed effects models.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory},
  number = {4}
}

@article{fan2014Projected,
  title = {Projected Principal Component Analysis in Factor Models},
  author = {Fan, Jianqing and Liao, Yuan and Wang, Weichen},
  year = {2014},
  month = jun,
  doi = {10.1214/15-AOS1364},
  file = {/Users/yuekai/Documents/zotero/Fan et al (2014) - Projected principal component analysis in factor models.pdf},
  language = {en}
}

@article{fan2015Asymptotics,
  title = {Asymptotics of {{Empirical Eigen}}-Structure for {{Ultra}}-High {{Dimensional Spiked Covariance Model}}},
  author = {Fan, Jianqing and Wang, Weichen},
  year = {2015},
  month = feb,
  abstract = {We derive the asymptotic distributions of the spiked eigenvalues and
eigenvectors under a generalized and unified asymptotic regime, which takes
into account the spike magnitude of leading eigenvalues, sample size, and
dimensionality. This new regime allows high dimensionality and diverging
eigenvalue spikes and provides new insights into the roles the leading
eigenvalues, sample size, and dimensionality play in principal component
analysis. The results are proven by a technical device, which swaps the role of
rows and columns and converts the high-dimensional problems into
low-dimensional ones. Our results are a natural extension of those in Paul
(2007) to more general setting with new insights and solve the rates of
convergence problems in Shen et al. (2013). They also reveal the biases of the
estimation of leading eigenvalues and eigenvectors by using principal component
analysis, and lead to a new covariance estimator for the approximate factor
model, called shrinkage principal orthogonal complement thresholding (S-POET),
that corrects the biases. Our results are successfully applied to outstanding
problems in estimation of risks of large portfolios and false discovery
proportions for dependent test statistics and are illustrated by simulation
studies.},
  file = {/Users/yuekai/Documents/zotero/Fan, Wang (2015) - Asymptotics of Empirical Eigen-structure for Ultra-high Dimensional Spiked.pdf},
  language = {en}
}

@article{fan2016Heterogeneity,
  title = {Heterogeneity {{Adjustment}} with {{Applications}} to {{Graphical Model Inference}}},
  author = {Fan, Jianqing and Liu, Han and Wang, Weichen and Zhu, Ziwei},
  year = {2016},
  month = feb,
  abstract = {Heterogeneity is an unwanted variation when analyzing aggregated datasets from multiple sources. Though different methods have been proposed for heterogeneity adjustment, no systematic theory exists to justify these methods. In this work, we propose a generic framework named ALPHA (short for Adaptive Low-rank Principal Heterogeneity Adjustment) to model, estimate, and adjust heterogeneity from the original data. Once the heterogeneity is adjusted, we are able to remove the biases of batch effects and to enhance the inferential power by aggregating the homogeneous residuals from multiple sources. Under a pervasive assumption that the latent heterogeneity factors simultaneously affect a large fraction of observed variables, we provide a rigorous theory to justify the proposed framework. Our framework also allows the incorporation of informative covariates and appeals to the "Bless of Dimensionality". As an illustrative application of this generic framework, we consider a problem of estimating high-dimensional precision matrix for graphical model inference based on multiple datasets. We also provide thorough numerical studies on both synthetic datasets and a brain imaging dataset to demonstrate the efficacy of the developed theory and methods.},
  archivePrefix = {arXiv},
  eprint = {1602.05455},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fan et al (2016) - Heterogeneity Adjustment with Applications to Graphical Model Inference.pdf},
  journal = {arXiv:1602.05455 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{fan2017Distributed,
  title = {Distributed {{Estimation}} of {{Principal Eigenspaces}}},
  author = {Fan, Jianqing and Wang, Dong and Wang, Kaizheng and Zhu, Ziwei},
  year = {2017},
  month = feb,
  abstract = {Principal component analysis (PCA) is fundamental to statistical machine learning. It extracts latent principal factors that contribute to the most variation of the data. When data are stored across multiple machines, however, communication cost can prohibit the computation of PCA in a central location and distributed algorithms for PCA are thus needed. This paper proposes and studies a distributed PCA algorithm: each node machine computes the top \$K\$ eigenvectors and transmits them to the central server; the central server then aggregates the information from all the node machines and conducts a PCA based on the aggregated information. We investigate the bias and variance for the resulting distributed estimator of the top \$K\$ eigenvectors. In particular, we show that for distributions with symmetric innovation, the empirical top eigenspaces are unbiased and hence the distributed PCA is "unbiased". We derive the rate of convergence for distributed PCA estimators, which depends explicitly on the effective rank of covariance, eigen-gap, and the number of machines. We show that when the number of machines is not unreasonably large, the distributed PCA performs as well as the whole sample PCA, even without full access of whole data. The theoretical results are verified by an extensive simulation study. We also extend our analysis to the heterogeneous case where the population covariance matrices are different across local machines but share similar top eigen-structures.},
  archivePrefix = {arXiv},
  eprint = {1702.06488},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fan et al (2017) - Distributed Estimation of Principal Eigenspaces.pdf},
  journal = {arXiv:1702.06488 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Computation},
  primaryClass = {math, stat}
}

@article{fan2017Partial,
  title = {Partial {{Consistency}} with {{Sparse Incidental Parameters}}},
  author = {Fan, Jianqing and Tang, Runlong and Shi, Xiaofeng},
  year = {2017},
  month = aug,
  abstract = {Penalized estimation principle is fundamental to high-dimensional problems. In the literature, it has been extensively and successfully applied to various models with only structural parameters. As a contrast, in this paper, we apply this penalization principle to a linear regression model with a finite-dimensional vector of structural parameters and a high-dimensional vector of sparse incidental parameters. For the estimators of the structural parameters, we derive their consistency and asymptotic normality, which reveals an oracle property. However, the penalized estimators for the incidental parameters possess only partial selection consistency but not consistency. This is an interesting partial consistency phenomenon: the structural parameters are consistently estimated while the incidental ones cannot. For the structural parameters, also considered is an alternative two-step penalized estimator, which has fewer possible asymptotic distributions and thus is more suitable for statistical inferences. We further extend the methods and results to the case where the dimension of the structural parameter vector diverges with but slower than the sample size. A data-driven approach for selecting a penalty regularization parameter is provided. The finite-sample performance of the penalized estimators for the structural parameters is evaluated by simulations and a real data set is analyzed.},
  archivePrefix = {arXiv},
  eprint = {1210.6950},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fan et al (2017) - Partial Consistency with Sparse Incidental Parameters.pdf},
  journal = {arXiv:1210.6950 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{fan2018Robust,
  title = {Robust High Dimensional Factor Models with Applications to Statistical Machine Learning},
  author = {Fan, Jianqing and Wang, Kaizheng and Zhong, Yiqiao and Zhu, Ziwei},
  year = {2018},
  month = aug,
  abstract = {Factor models are a class of powerful statistical models that have been widely used to deal with dependent measurements that arise frequently from various applications from genomics and neuroscience to economics and finance. As data are collected at an ever-growing scale, statistical machine learning faces some new challenges: high dimensionality, strong dependence among observed variables, heavy-tailed variables and heterogeneity. High-dimensional robust factor analysis serves as a powerful toolkit to conquer these challenges. This paper gives a selective overview on recent advance on high-dimensional factor models and their applications to statistics including Factor-Adjusted Robust Model selection (FarmSelect) and Factor-Adjusted Robust Multiple testing (FarmTest). We show that classical methods, especially principal component analysis (PCA), can be tailored to many new problems and provide powerful tools for statistical estimation and inference. We highlight PCA and its connections to matrix perturbation theory, robust statistics, random projection, false discovery rate, etc., and illustrate through several applications how insights from these fields yield solutions to modern challenges. We also present far-reaching connections between factor models and popular statistical learning problems, including network analysis and low-rank matrix recovery.},
  archivePrefix = {arXiv},
  eprint = {1808.03889},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fan et al (2018) - Robust high dimensional factor models with applications to statistical machine.pdf},
  journal = {arXiv:1808.03889 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{fan2019Asymptotic,
  title = {Asymptotic {{Theory}} of {{Eigenvectors}} for {{Large Random Matrices}}},
  author = {Fan, Jianqing and Fan, Yingying and Han, Xiao and Lv, Jinchi},
  year = {2019},
  month = feb,
  abstract = {Characterizing the exact asymptotic distributions of high-dimensional eigenvectors for large structured random matrices poses important challenges yet can provide useful insights into a range of applications. To this end, in this paper we introduce a general framework of asymptotic theory of eigenvectors (ATE) for large structured symmetric random matrices with heterogeneous variances, and establish the asymptotic properties of the spiked eigenvectors and eigenvalues for the scenario of the generalized Wigner matrix noise, where the mean matrix is assumed to have the low-rank structure. Under some mild regularity conditions, we provide the asymptotic expansions for the spiked eigenvalues and show that they are asymptotically normal after some normalization. For the spiked eigenvectors, we establish novel asymptotic expansions for the general linear combination and further show that it is asymptotically normal after some normalization, where the weight vector can be arbitrary. We also provide a more general asymptotic theory for the spiked eigenvectors using the bilinear form. Simulation studies verify the validity of our new theoretical results. Our family of models encompasses many popularly used ones such as the stochastic block models with or without overlapping communities for network analysis and the topic models for text analysis, and our general theory can be exploited for statistical inference in these large-scale applications.},
  archivePrefix = {arXiv},
  eprint = {1902.06846},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fan et al (2019) - Asymptotic Theory of Eigenvectors for Large Random Matrices.pdf},
  journal = {arXiv:1902.06846 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{fan2019CommunicationEfficient,
  title = {Communication-{{Efficient Accurate Statistical Estimation}}},
  author = {Fan, Jianqing and Guo, Yongyi and Wang, Kaizheng},
  year = {2019},
  month = jun,
  abstract = {When the data are stored in a distributed manner, direct application of traditional statistical inference procedures is often prohibitive due to communication cost and privacy concerns. This paper develops and investigates two Communication-Efficient Accurate Statistical Estimators (CEASE), implemented through iterative algorithms for distributed optimization. In each iteration, node machines carry out computation in parallel and communicate with the central processor, which then broadcasts aggregated information to node machines for new updates. The algorithms adapt to the similarity among loss functions on node machines, and converge rapidly when each node machine has large enough sample size. Moreover, they do not require good initialization and enjoy linear converge guarantees under general conditions. The contraction rate of optimization errors is presented explicitly, with dependence on the local sample size unveiled. In addition, the improved statistical accuracy per iteration is derived. By regarding the proposed method as a multi-step statistical estimator, we show that statistical efficiency can be achieved in finite steps in typical statistical applications. In addition, we give the conditions under which the one-step CEASE estimator is statistically efficient. Extensive numerical experiments on both synthetic and real data validate the theoretical results and demonstrate the superior performance of our algorithms.},
  archivePrefix = {arXiv},
  eprint = {1906.04870},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fan et al (2019) - Communication-Efficient Accurate Statistical Estimation.pdf},
  journal = {arXiv:1906.04870 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Computation,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{fan2019Eigenvalue,
  title = {Eigenvalue Distributions of Variance Components Estimators in High-Dimensional Random Effects Models},
  author = {Fan, Zhou and Johnstone, Iain M.},
  year = {2019},
  month = oct,
  volume = {47},
  pages = {2855--2886},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/18-AOS1767},
  abstract = {We study the spectra of MANOVA estimators for variance component covariance matrices in multivariate random effects models. When the dimensionality of the observations is large and comparable to the number of realizations of each random effect, we show that the empirical spectra of such estimators are well approximated by deterministic laws. The Stieltjes transforms of these laws are characterized by systems of fixed-point equations, which are numerically solvable by a simple iterative procedure. Our proof uses operator-valued free probability theory, and we establish a general asymptotic freeness result for families of rectangular orthogonally invariant random matrices, which is of independent interest. Our work is motivated in part by the estimation of components of covariance between multiple phenotypic traits in quantitative genetics, and we specialize our results to common experimental designs that arise in this application.},
  file = {/Users/yuekai/Documents/zotero/Fan, Johnstone (2019) - Eigenvalue distributions of variance components estimators in high-dimensional.pdf;/Users/yuekai/Zotero/storage/6FZAWZWN/1564797866.html},
  journal = {Annals of Statistics},
  keywords = {covariance estimation,deterministic equivalents,free probability,Random matrix theory},
  language = {EN},
  mrnumber = {MR3988775},
  number = {5},
  zmnumber = {07114931}
}

@article{fan2019Precision,
  title = {Precision {{Matrix Estimation}} with {{Noisy}} and {{Missing Data}}},
  author = {Fan, Roger and Jang, Byoungwook and Sun, Yuekai and Zhou, Shuheng},
  year = {2019},
  month = apr,
  abstract = {Estimating conditional dependence graphs and precision matrices are some of the most common problems in modern statistics and machine learning. When data are fully observed, penalized maximum likelihood-type estimators have become standard tools for estimating graphical models under sparsity conditions. Extensions of these methods to more complex settings where data are contaminated with additive or multiplicative noise have been developed in recent years. In these settings, however, the relative performance of different methods is not well understood and algorithmic gaps still exist. In particular, in high-dimensional settings these methods require using non-positive semidefinite matrices as inputs, presenting novel optimization challenges. We develop an alternating direction method of multipliers (ADMM) algorithm for these problems, providing a feasible algorithm to estimate precision matrices with indefinite input and potentially nonconvex penalties. We compare this method with existing alternative solutions and empirically characterize the tradeoffs between them. Finally, we use this method to explore the networks among US senators estimated from voting records data.},
  archivePrefix = {arXiv},
  eprint = {1904.03548},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fan et al (2019) - Precision Matrix Estimation with Noisy and Missing Data.pdf},
  journal = {arXiv:1904.03548 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {cs, stat}
}

@article{fan2019Selective,
  title = {A {{Selective Overview}} of {{Deep Learning}}},
  author = {Fan, Jianqing and Ma, Cong and Zhong, Yiqiao},
  year = {2019},
  month = apr,
  abstract = {Deep learning has arguably achieved tremendous success in recent years. In simple words, deep learning uses the composition of many nonlinear functions to model the complex dependency between input features and labels. While neural networks have a long history, recent advances have greatly improved their performance in computer vision, natural language processing, etc. From the statistical and scientific perspective, it is natural to ask: What is deep learning? What are the new characteristics of deep learning, compared with classical methods? What are the theoretical foundations of deep learning? To answer these questions, we introduce common neural network models (e.g., convolutional neural nets, recurrent neural nets, generative adversarial nets) and training techniques (e.g., stochastic gradient descent, dropout, batch normalization) from a statistical point of view. Along the way, we highlight new characteristics of deep learning (including depth and over-parametrization) and explain their practical and theoretical benefits. We also sample recent results on theories of deep learning, many of which are only suggestive. While a complete understanding of deep learning remains elusive, we hope that our perspectives and discussions serve as a stimulus for new statistical research.},
  archivePrefix = {arXiv},
  eprint = {1904.05526},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fan et al (2019) - A Selective Overview of Deep Learning.pdf},
  journal = {arXiv:1904.05526 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  language = {en},
  primaryClass = {cs, math, stat}
}

@article{fan2019SIMPLE,
  title = {{{SIMPLE}}: {{Statistical Inference}} on {{Membership Profiles}} in {{Large Networks}}},
  shorttitle = {{{SIMPLE}}},
  author = {Fan, Jianqing and Fan, Yingying and Han, Xiao and Lv, Jinchi},
  year = {2019},
  month = oct,
  abstract = {Network data is prevalent in many contemporary big data applications in which a common interest is to unveil important latent links between different pairs of nodes. Yet a simple fundamental question of how to precisely quantify the statistical uncertainty associated with the identification of latent links still remains largely unexplored. In this paper, we propose the method of statistical inference on membership profiles in large networks (SIMPLE) in the setting of degree-corrected mixed membership model, where the null hypothesis assumes that the pair of nodes share the same profile of community memberships. In the simpler case of no degree heterogeneity, the model reduces to the mixed membership model for which an alternative more robust test is also proposed. Both tests are of the Hotelling-type statistics based on the rows of empirical eigenvectors or their ratios, whose asymptotic covariance matrices are very challenging to derive and estimate. Nevertheless, their analytical expressions are unveiled and the unknown covariance matrices are consistently estimated. Under some mild regularity conditions, we establish the exact limiting distributions of the two forms of SIMPLE test statistics under the null hypothesis and contiguous alternative hypothesis. They are the chi-square distributions and the noncentral chi-square distributions, respectively, with degrees of freedom depending on whether the degrees are corrected or not. We also address the important issue of estimating the unknown number of communities and establish the asymptotic properties of the associated test statistics. The advantages and practical utility of our new procedures in terms of both size and power are demonstrated through several simulation examples and real network applications.},
  archivePrefix = {arXiv},
  eprint = {1910.01734},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fan et al (2019) - SIMPLE.pdf},
  journal = {arXiv:1910.01734 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{fang2014Inference,
  title = {Inference on {{Directionally Differentiable Functions}}},
  author = {Fang, Zheng and Santos, Andres},
  year = {2014},
  month = apr,
  abstract = {This paper studies an asymptotic framework for conducting inference on parameters of the form \$\textbackslash phi(\textbackslash theta\_0)\$, where \$\textbackslash phi\$ is a known directionally differentiable function and \$\textbackslash theta\_0\$ is estimated by \$\textbackslash hat \textbackslash theta\_n\$. In these settings, the asymptotic distribution of the plug-in estimator \$\textbackslash phi(\textbackslash hat \textbackslash theta\_n)\$ can be readily derived employing existing extensions to the Delta method. We show, however, that the "standard" bootstrap is only consistent under overly stringent conditions -- in particular we establish that differentiability of \$\textbackslash phi\$ is a necessary and sufficient condition for bootstrap consistency whenever the limiting distribution of \$\textbackslash hat \textbackslash theta\_n\$ is Gaussian. An alternative resampling scheme is proposed which remains consistent when the bootstrap fails, and is shown to provide local size control under restrictions on the directional derivative of \$\textbackslash phi\$. We illustrate the utility of our results by developing a test of whether a Hilbert space valued parameter belongs to a convex set -- a setting that includes moment inequality problems and certain tests of shape restrictions as special cases.},
  archivePrefix = {arXiv},
  eprint = {1404.3763},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fang, Santos (2014) - Inference on Directionally Differentiable Functions.pdf},
  journal = {arXiv:1404.3763 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@inproceedings{fang2019Intervention,
  title = {Intervention {{Harvesting}} for {{Context}}-{{Dependent Examination}}-{{Bias Estimation}}},
  booktitle = {Proceedings of the 42nd {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Fang, Zhichong and Agarwal, Aman and Joachims, Thorsten},
  year = {2019},
  month = jul,
  pages = {825--834},
  publisher = {{Association for Computing Machinery}},
  address = {{Paris, France}},
  doi = {10.1145/3331184.3331238},
  abstract = {Accurate estimates of examination bias are crucial for unbiased learning-to-rank from implicit feedback in search engines and recommender systems, since they enable the use of Inverse Propensity Score (IPS) weighting techniques to address selection biases and missing data. Unfortunately, existing examination-bias estimators are limited to the Position-Based Model (PBM), where the examination bias may only depend on the rank of the document. To overcome this limitation, we propose a Contextual Position-Based Model (CPBM) where the examination bias may also depend on a context vector describing the query and the user. Furthermore, we propose an effective estimator for the CPBM based on intervention harvesting. A key feature of the estimator is that it does not require disruptive interventions but merely exploits natural variation resulting from the use of multiple historic ranking functions. Real-world experiments on the ArXiv search engine and semi-synthetic experiments on the Yahoo Learning-To-Rank dataset demonstrate the superior effectiveness and robustness of the new approach.},
  file = {/Users/yuekai/Documents/zotero/Fang et al (2019) - Intervention Harvesting for Context-Dependent Examination-Bias Estimation.pdf},
  isbn = {978-1-4503-6172-9},
  series = {{{SIGIR}}'19}
}

@article{farajtabar2016COEVOLVE,
  title = {{{COEVOLVE}}: {{A Joint Point Process Model}} for {{Information Diffusion}} and {{Network Co}}-Evolution},
  shorttitle = {{{COEVOLVE}}},
  author = {Farajtabar, Mehrdad and Wang, Yichen and Rodriguez, Manuel Gomez and Li, Shuang and Zha, Hongyuan and Song, Le},
  year = {2016},
  month = apr,
  abstract = {Information diffusion in online social networks is affected by the underlying network topology, but it also has the power to change it. Online users are constantly creating new links when exposed to new information sources, and in turn these links are alternating the way information spreads. However, these two highly intertwined stochastic processes, information diffusion and network evolution, have been predominantly studied separately, ignoring their co-evolutionary dynamics. We propose a temporal point process model, COEVOLVE, for such joint dynamics, allowing the intensity of one process to be modulated by that of the other. This model allows us to efficiently simulate interleaved diffusion and network events, and generate traces obeying common diffusion and network patterns observed in real-world networks. Furthermore, we also develop a convex optimization framework to learn the parameters of the model from historical diffusion and network evolution traces. We experimented with both synthetic data and data gathered from Twitter, and show that our model provides a good fit to the data as well as more accurate predictions than alternatives.},
  archivePrefix = {arXiv},
  eprint = {1507.02293},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Farajtabar et al (2016) - COEVOLVE.pdf},
  journal = {arXiv:1507.02293 [physics, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Physics - Physics and Society,Statistics - Machine Learning},
  primaryClass = {physics, stat}
}

@article{farquhar2018Robust,
  title = {Towards {{Robust Evaluations}} of {{Continual Learning}}},
  author = {Farquhar, Sebastian and Gal, Yarin},
  year = {2018},
  month = may,
  abstract = {Experiments used in current continual learning research do not faithfully assess fundamental challenges of learning continually. Instead of assessing performance on challenging and representative experiment designs, recent research has focused on increased dataset difficulty, while still using flawed experiment set-ups. We examine standard evaluations and show why these evaluations make some continual learning approaches look better than they are. We introduce desiderata for continual learning evaluations and explain why their absence creates misleading comparisons. Based on our desiderata we then propose new experiment designs which we demonstrate with various continual learning approaches and datasets. Our analysis calls for a reprioritization of research effort by the community.},
  archivePrefix = {arXiv},
  eprint = {1805.09733},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Farquhar, Gal (2018) - Towards Robust Evaluations of Continual Learning.pdf},
  journal = {arXiv:1805.09733 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{farrell2018Deep,
  title = {Deep {{Neural Networks}} for {{Estimation}} and {{Inference}}: {{Application}} to {{Causal Effects}} and {{Other Semiparametric Estimands}}},
  shorttitle = {Deep {{Neural Networks}} for {{Estimation}} and {{Inference}}},
  author = {Farrell, Max H. and Liang, Tengyuan and Misra, Sanjog},
  year = {2018},
  month = sep,
  abstract = {We study deep neural networks and their use in semiparametric inference. We prove valid inference after first-step estimation with deep learning, a result new to the literature. We provide new rates of convergence for deep feedforward neural nets and, because our rates are sufficiently fast (in some cases minimax optimal), obtain valid semiparametric inference. Our estimation rates and semiparametric inference results handle the current standard architecture: fully connected feedforward neural networks (multi-layer perceptrons), with the now-common rectified linear unit activation function and a depth explicitly diverging with the sample size. We discuss other architectures as well, including fixed-width, very deep networks. We establish nonasymptotic bounds for these deep nets for nonparametric regression, covering the standard least squares and logistic losses in particular. We then apply our theory to develop semiparametric inference, focusing on treatment effects, expected welfare, and decomposition effects for concreteness. Inference in many other semiparametric contexts can be readily obtained. We demonstrate the effectiveness of deep learning with a Monte Carlo analysis and an empirical application to direct mail marketing.},
  archivePrefix = {arXiv},
  eprint = {1809.09953},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Farrell et al (2018) - Deep Neural Networks for Estimation and Inference.pdf},
  journal = {arXiv:1809.09953 [cs, econ, math, stat]},
  keywords = {Computer Science - Machine Learning,Economics - Econometrics,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, econ, math, stat}
}

@article{faury2019Distributionally,
  title = {Distributionally {{Robust Counterfactual Risk Minimization}}},
  author = {Faury, Louis and Tanielian, Ugo and Vasile, Flavian and Smirnova, Elena and Dohmatob, Elvis},
  year = {2019},
  month = jun,
  abstract = {This manuscript introduces the idea of using Distributionally Robust Optimization (DRO) for the Counterfactual Risk Minimization (CRM) problem. Tapping into a rich existing literature, we show that DRO is a principled tool for counterfactual decision making. We also show that well-established solutions to the CRM problem like sample variance penalization schemes are special instances of a more general DRO problem. In this unifying framework, a variety of distributionally robust counterfactual risk estimators can be constructed using various probability distances and divergences as uncertainty measures. We propose the use of Kullback-Leibler divergence as an alternative way to model uncertainty in CRM and derive a new robust counterfactual objective. In our experiments, we show that this approach outperforms the state-of-the-art on four benchmark datasets, validating the relevance of using other uncertainty measures in practical applications.},
  archivePrefix = {arXiv},
  eprint = {1906.06211},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Faury et al (2019) - Distributionally Robust Counterfactual Risk Minimization.pdf},
  journal = {arXiv:1906.06211 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{fawzi2015Analysis,
  title = {Analysis of Classifiers' Robustness to Adversarial Perturbations},
  author = {Fawzi, Alhussein and Fawzi, Omar and Frossard, Pascal},
  year = {2015},
  month = feb,
  abstract = {The goal of this paper is to analyze an intriguing phenomenon recently discovered in deep networks, namely their instability to adversarial perturbations (Szegedy et. al., 2014). We provide a theoretical framework for analyzing the robustness of classifiers to adversarial perturbations, and show fundamental upper bounds on the robustness of classifiers. Specifically, we establish a general upper bound on the robustness of classifiers to adversarial perturbations, and then illustrate the obtained upper bound on the families of linear and quadratic classifiers. In both cases, our upper bound depends on a distinguishability measure that captures the notion of difficulty of the classification task. Our results for both classes imply that in tasks involving small distinguishability, no classifier in the considered set will be robust to adversarial perturbations, even if a good accuracy is achieved. Our theoretical framework moreover suggests that the phenomenon of adversarial instability is due to the low flexibility of classifiers, compared to the difficulty of the classification task (captured by the distinguishability). Moreover, we show the existence of a clear distinction between the robustness of a classifier to random noise and its robustness to adversarial perturbations. Specifically, the former is shown to be larger than the latter by a factor that is proportional to \textbackslash sqrt\{d\} (with d being the signal dimension) for linear classifiers. This result gives a theoretical explanation for the discrepancy between the two robustness properties in high dimensional problems, which was empirically observed in the context of neural networks. To the best of our knowledge, our results provide the first theoretical work that addresses the phenomenon of adversarial instability recently observed for deep networks. Our analysis is complemented by experimental results on controlled and real-world data.},
  archivePrefix = {arXiv},
  eprint = {1502.02590},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fawzi et al (2015) - Analysis of classifiers' robustness to adversarial perturbations.pdf},
  journal = {arXiv:1502.02590 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{fawzi2018Adversarial,
  title = {Adversarial Vulnerability for Any Classifier},
  author = {Fawzi, Alhussein and Fawzi, Hamza and Fawzi, Omar},
  year = {2018},
  month = feb,
  abstract = {Despite achieving impressive performance, state-of-the-art classifiers remain highly vulnerable to small, imperceptible, adversarial perturbations. This vulnerability has proven empirically to be very intricate to address. In this paper, we study the phenomenon of adversarial perturbations under the assumption that the data is generated with a smooth generative model. We derive fundamental upper bounds on the robustness to perturbations of any classification function, and prove the existence of adversarial perturbations that transfer well across different classifiers with small risk. Our analysis of the robustness also provides insights onto key properties of generative models, such as their smoothness and dimensionality of latent space. We conclude with numerical experimental results showing that our bounds provide informative baselines to the maximal achievable robustness on several datasets.},
  archivePrefix = {arXiv},
  eprint = {1802.08686},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fawzi et al (2018) - Adversarial vulnerability for any classifier.pdf},
  journal = {arXiv:1802.08686 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{fei2015Temporal,
  title = {Temporal {{Models}} for {{Predicting Student Dropout}} in {{Massive Open Online Courses}}},
  booktitle = {Proceedings of the 2015 {{IEEE International Conference}} on {{Data Mining Workshop}} ({{ICDMW}})},
  author = {Fei, Mi and Yeung, Dit-Yan},
  year = {2015},
  month = nov,
  pages = {256--263},
  publisher = {{IEEE Computer Society}},
  address = {{USA}},
  doi = {10.1109/ICDMW.2015.174},
  abstract = {Over the past few years, the rapid emergence of massive open online courses (MOOCs) has sparked a great deal of research interest in MOOC data analytics. Dropout prediction, or identifying students at risk of dropping out of a course, is an important problem to study due to the high attrition rate commonly found on many MOOC platforms. The methods proposed recently for dropout prediction apply relatively simple machine learning methods like support vector machines and logistic regression, using features that reflect such student activities as lecture video watching and forum activities on a MOOC platform during the study period of a course. Since the features are captured continuously for each student over a period of time, dropout prediction is essentially a time series prediction problem. By regarding dropout prediction as a sequence classification problem, we propose some temporal models for solving it. In particular, based on extensive experiments conducted on two MOOCs offered on Coursera and edX, a recurrent neural network (RNN) model with long short-term memory (LSTM) cells beats the baseline methods as well as our other proposed methods by a large margin.},
  isbn = {978-1-4673-8493-3},
  series = {{{ICDMW}} '15}
}

@article{feldman2014Certifying,
  title = {Certifying and Removing Disparate Impact},
  author = {Feldman, Michael and Friedler, Sorelle and Moeller, John and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  year = {2014},
  month = dec,
  abstract = {What does it mean for an algorithm to be biased? In U.S. law, unintentional bias is encoded via disparate impact, which occurs when a selection process has widely different outcomes for different groups, even as it appears to be neutral. This legal determination hinges on a definition of a protected class (ethnicity, gender, religious practice) and an explicit description of the process. When the process is implemented using computers, determining disparate impact (and hence bias) is harder. It might not be possible to disclose the process. In addition, even if the process is open, it might be hard to elucidate in a legal setting how the algorithm makes its decisions. Instead of requiring access to the algorithm, we propose making inferences based on the data the algorithm uses. We make four contributions to this problem. First, we link the legal notion of disparate impact to a measure of classification accuracy that while known, has received relatively little attention. Second, we propose a test for disparate impact based on analyzing the information leakage of the protected class from the other data attributes. Third, we describe methods by which data might be made unbiased. Finally, we present empirical evidence supporting the effectiveness of our test for disparate impact and our approach for both masking bias and preserving relevant information in the data. Interestingly, our approach resembles some actual selection practices that have recently received legal scrutiny.},
  archivePrefix = {arXiv},
  eprint = {1412.3756},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Feldman et al (2014) - Certifying and removing disparate impact.pdf},
  journal = {arXiv:1412.3756 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{feltner2015High,
  title = {High {{Price}} of {{Mandatory Auto Insurance}} in {{Predominantly African American Communities}}},
  author = {Feltner, Tom and Heller, Douglas},
  year = {2015},
  month = nov,
  pages = {16},
  file = {/Users/yuekai/Documents/zotero/Feltner, Heller (2015) - High Price of Mandatory Auto Insurance in Predominantly African American.pdf},
  language = {en}
}

@article{finn2017ModelAgnostic,
  title = {Model-{{Agnostic Meta}}-{{Learning}} for {{Fast Adaptation}} of {{Deep Networks}}},
  author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  year = {2017},
  month = mar,
  abstract = {We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.},
  archivePrefix = {arXiv},
  eprint = {1703.03400},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Finn et al (2017) - Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.pdf},
  journal = {arXiv:1703.03400 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  primaryClass = {cs}
}

@article{finn2019Online,
  title = {Online {{Meta}}-{{Learning}}},
  author = {Finn, Chelsea and Rajeswaran, Aravind and Kakade, Sham and Levine, Sergey},
  year = {2019},
  month = feb,
  abstract = {A central capability of intelligent systems is the ability to continuously build upon previous experiences to speed up and enhance learning of new tasks. Two distinct research paradigms have studied this question. Meta-learning views this problem as learning a prior over model parameters that is amenable for fast adaptation on a new task, but typically assumes the set of tasks are available together as a batch. In contrast, online (regret based) learning considers a sequential setting in which problems are revealed one after the other, but conventionally train only a single model without any task-specific adaptation. This work introduces an online meta-learning setting, which merges ideas from both the aforementioned paradigms to better capture the spirit and practice of continual lifelong learning. We propose the follow the meta leader algorithm which extends the MAML algorithm to this setting. Theoretically, this work provides an \$\textbackslash mathcal\{O\}(\textbackslash log T)\$ regret guarantee with only one additional higher order smoothness assumption in comparison to the standard online setting. Our experimental evaluation on three different large-scale tasks suggest that the proposed algorithm significantly outperforms alternatives based on traditional online learning approaches.},
  archivePrefix = {arXiv},
  eprint = {1902.08438},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Finn et al (2019) - Online Meta-Learning.pdf},
  journal = {arXiv:1902.08438 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{finn2019Probabilistic,
  title = {Probabilistic {{Model}}-{{Agnostic Meta}}-{{Learning}}},
  author = {Finn, Chelsea and Xu, Kelvin and Levine, Sergey},
  year = {2019},
  month = oct,
  abstract = {Meta-learning for few-shot learning entails acquiring a prior over previous tasks and experiences, such that new tasks be learned from small amounts of data. However, a critical challenge in few-shot learning is task ambiguity: even when a powerful prior can be meta-learned from a large number of prior tasks, a small dataset for a new task can simply be too ambiguous to acquire a single model (e.g., a classifier) for that task that is accurate. In this paper, we propose a probabilistic meta-learning algorithm that can sample models for a new task from a model distribution. Our approach extends model-agnostic meta-learning, which adapts to new tasks via gradient descent, to incorporate a parameter distribution that is trained via a variational lower bound. At meta-test time, our algorithm adapts via a simple procedure that injects noise into gradient descent, and at meta-training time, the model is trained such that this stochastic adaptation procedure produces samples from the approximate model posterior. Our experimental results show that our method can sample plausible classifiers and regressors in ambiguous few-shot learning problems. We also show how reasoning about ambiguity can also be used for downstream active learning problems.},
  archivePrefix = {arXiv},
  eprint = {1806.02817},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Finn et al (2019) - Probabilistic Model-Agnostic Meta-Learning.pdf},
  journal = {arXiv:1806.02817 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{fithian2014Local,
  title = {Local Case-Control Sampling: {{Efficient}} Subsampling in Imbalanced Data Sets},
  shorttitle = {Local Case-Control Sampling},
  author = {Fithian, William and Hastie, Trevor},
  year = {2014},
  month = oct,
  volume = {42},
  pages = {1693--1724},
  issn = {0090-5364},
  doi = {10.1214/14-AOS1220},
  abstract = {For classification problems with significant class imbalance, subsampling can reduce computational costs at the price of inflated variance in estimating model parameters. We propose a method for subsampling efficiently for logistic regression by adjusting the class balance locally in feature space via an accept-reject scheme. Our method generalizes standard case-control sampling, using a pilot estimate to preferentially select examples whose responses are conditionally rare given their features. The biased subsampling is corrected by a post-hoc analytic adjustment to the parameters. The method is simple and requires one parallelizable scan over the full data set. Standard case-control sampling is inconsistent under model misspecification for the population risk-minimizing coefficients \$\textbackslash theta\^*\$. By contrast, our estimator is consistent for \$\textbackslash theta\^*\$ provided that the pilot estimate is. Moreover, under correct specification and with a consistent, independent pilot estimate, our estimator has exactly twice the asymptotic variance of the full-sample MLE - even if the selected subsample comprises a miniscule fraction of the full data set, as happens when the original data are severely imbalanced. The factor of two improves to \$1+\textbackslash frac\{1\}\{c\}\$ if we multiply the baseline acceptance probabilities by \$c{$>$}1\$ (and weight points with acceptance probability greater than 1), taking roughly \$\textbackslash frac\{1+c\}\{2\}\$ times as many data points into the subsample. Experiments on simulated and real data show that our method can substantially outperform standard case-control subsampling.},
  archivePrefix = {arXiv},
  eprint = {1306.3706},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fithian, Hastie (2014) - Local case-control sampling.pdf},
  journal = {The Annals of Statistics},
  keywords = {Statistics - Computation,Statistics - Machine Learning},
  number = {5}
}

@article{fithian2017Optimal,
  title = {Optimal {{Inference After Model Selection}}},
  author = {Fithian, William and Sun, Dennis and Taylor, Jonathan},
  year = {2017},
  month = apr,
  abstract = {To perform inference after model selection, we propose controlling the selective type I error; i.e., the error rate of a test given that it was performed. By doing so, we recover long-run frequency properties among selected hypotheses analogous to those that apply in the classical (non-adaptive) context. Our proposal is closely related to data splitting and has a similar intuitive justification, but is more powerful. Exploiting the classical theory of Lehmann and Scheff\textbackslash 'e (1955), we derive most powerful unbiased selective tests and confidence intervals for inference in exponential family models after arbitrary selection procedures. For linear regression, we derive new selective z-tests that generalize recent proposals for inference after model selection and improve on their power, and new selective t-tests that do not require knowledge of the error variance.},
  archivePrefix = {arXiv},
  eprint = {1410.2597},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fithian et al (2017) - Optimal Inference After Model Selection.pdf},
  journal = {arXiv:1410.2597 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{flennerhag2019MetaLearning,
  title = {Meta-{{Learning}} with {{Warped Gradient Descent}}},
  author = {Flennerhag, Sebastian and Rusu, Andrei A. and Pascanu, Razvan and Yin, Hujun and Hadsell, Raia},
  year = {2019},
  month = aug,
  abstract = {A versatile and effective approach to meta-learning is to infer a gradient-based up-date rule directly from data that promotes rapid learning of new tasks from the same distribution. Current methods rely on backpropagating through the learning process, limiting their scope to few-shot learning. In this work, we introduce Warped Gradient Descent (WarpGrad), a family of modular optimisers that can scale to arbitrary adaptation processes. WarpGrad methods meta-learn to warp task loss surfaces across the joint task-parameter distribution to facilitate gradient descent, which is achieved by a reparametrisation of neural networks that interleaves warp layers in the architecture. These layers are shared across task learners and fixed during adaptation; they represent a projection of task parameters into a meta-learned space that is conducive to task adaptation and standard backpropagation induces a form of gradient preconditioning. WarpGrad methods are computationally efficient and easy to implement as they rely on parameter sharing and backpropagation. They are readily combined with other meta-learners and can scale both in terms of model size and length of adaptation trajectories as meta-learning warp parameters do not require differentiation through task adaptation processes. We show empirically that WarpGrad optimisers meta-learn a warped space where gradient descent is well behaved, with faster convergence and better performance in a variety of settings, including few-shot, standard supervised, continual, and reinforcement learning.},
  archivePrefix = {arXiv},
  eprint = {1909.00025},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Flennerhag et al (2019) - Meta-Learning with Warped Gradient Descent.pdf},
  journal = {arXiv:1909.00025 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{flores-bazan2012complete,
  title = {A Complete Characterization of Strong Duality in Nonconvex Optimization with a Single Constraint},
  author = {{Flores-Baz{\'a}n}, Fabi{\'a}n and {Flores-Baz{\'a}n}, Fernando and Vera, Cristi{\'a}n},
  year = {2012},
  month = jun,
  volume = {53},
  pages = {185--201},
  issn = {1573-2916},
  doi = {10.1007/s10898-011-9673-6},
  abstract = {We first establish sufficient conditions ensuring strong duality for cone constrained nonconvex optimization problems under a generalized Slater-type condition. Such conditions allow us to cover situations where recent results cannot be applied. Afterwards, we provide a new complete characterization of strong duality for a problem with a single constraint: showing, in particular, that strong duality still holds without the standard Slater condition. This yields Lagrange multipliers characterizations of global optimality in case of (not necessarily convex) quadratic homogeneous functions after applying a generalized joint-range convexity result. Furthermore, a result which reduces a constrained minimization problem into one with a single constraint under generalized convexity assumptions, is also presented.},
  file = {/Users/yuekai/Documents/zotero/Flores-Bazán et al (2012) - A complete characterization of strong duality in nonconvex optimization with a.pdf},
  journal = {Journal of Global Optimization},
  language = {en},
  number = {2}
}

@article{flores-bazan2017Primal,
  title = {Primal or Dual Strong-Duality in Nonconvex Optimization and a Class of Quasiconvex Problems Having Zero Duality Gap},
  author = {{Flores-Baz{\'a}n}, Fabi{\'a}n and Echegaray, William and {Flores-Baz{\'a}n}, Fernando and Oca{\~n}a, Eladio},
  year = {2017},
  month = dec,
  volume = {69},
  pages = {823--845},
  issn = {1573-2916},
  doi = {10.1007/s10898-017-0542-9},
  abstract = {Primal or dual strong-duality (or min-sup, inf-max duality) in nonconvex optimization is revisited in view of recent literature on the subject, establishing, in particular, new characterizations for the second case. This gives rise to a new class of quasiconvex problems having zero duality gap or closedness of images of vector mappings associated to those problems. Such conditions are described for the classes of linear fractional functions and that of quadratic ones. In addition, some applications to nonconvex quadratic optimization problems under a single inequality or equality constraint, are presented, providing new results for the fulfillment of zero duality gap or dual strong-duality.},
  file = {/Users/yuekai/Documents/zotero/Flores-Bazán et al (2017) - Primal or dual strong-duality in nonconvex optimization and a class of.pdf},
  journal = {Journal of Global Optimization},
  language = {en},
  number = {4}
}

@article{fogliato2020Fairness,
  title = {Fairness {{Evaluation}} in {{Presence}} of {{Biased Noisy Labels}}},
  author = {Fogliato, Riccardo and G'Sell, Max and Chouldechova, Alexandra},
  year = {2020},
  month = mar,
  abstract = {Risk assessment tools are widely used around the country to inform decision making within the criminal justice system. Recently, considerable attention has been devoted to the question of whether such tools may suffer from racial bias. In this type of assessment, a fundamental issue is that the training and evaluation of the model is based on a variable (arrest) that may represent a noisy version of an unobserved outcome of more central interest (offense). We propose a sensitivity analysis framework for assessing how assumptions on the noise across groups affect the predictive bias properties of the risk assessment model as a predictor of reoffense. Our experimental results on two real world criminal justice data sets demonstrate how even small biases in the observed labels may call into question the conclusions of an analysis based on the noisy outcome.},
  archivePrefix = {arXiv},
  eprint = {2003.13808},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Fogliato et al (2020) - Fairness Evaluation in Presence of Biased Noisy Labels.pdf},
  journal = {arXiv:2003.13808 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Statistics - Methodology},
  primaryClass = {cs, stat}
}

@article{foster2019Orthogonal,
  title = {Orthogonal {{Statistical Learning}}},
  author = {Foster, Dylan J. and Syrgkanis, Vasilis},
  year = {2019},
  month = jan,
  abstract = {We provide excess risk guarantees for statistical learning in a setting where the population risk with respect to which we evaluate the target model depends on an unknown model that must be to be estimated from data (a "nuisance model"). We analyze a two-stage sample splitting meta-algorithm that takes as input two arbitrary estimation algorithms: one for the target model and one for the nuisance model. We show that if the population risk satisfies a condition called Neyman orthogonality, the impact of the nuisance estimation error on the excess risk bound achieved by the meta-algorithm is of second order. Our theorem is agnostic to the particular algorithms used for the target and nuisance and only makes an assumption on their individual performance. This enables the use of a plethora of existing results from statistical learning and machine learning literature to give new guarantees for learning with a nuisance component. Moreover, by focusing on excess risk rather than parameter estimation, we can give guarantees under weaker assumptions than in previous works and accommodate the case where the target parameter belongs to a complex nonparametric class. We characterize conditions on the metric entropy such that oracle rates---rates of the same order as if we knew the nuisance model---are achieved. We also analyze the rates achieved by specific estimation algorithms such as variance-penalized empirical risk minimization, neural network estimation and sparse high-dimensional linear model estimation. We highlight the applicability of our results in four settings of central importance in the literature: 1) heterogeneous treatment effect estimation, 2) offline policy optimization, 3) domain adaptation, and 4) learning with missing data.},
  archivePrefix = {arXiv},
  eprint = {1901.09036},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Foster, Syrgkanis (2019) - Orthogonal Statistical Learning.pdf},
  journal = {arXiv:1901.09036 [cs, econ, math, stat]},
  keywords = {Computer Science - Machine Learning,Economics - Econometrics,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, econ, math, stat}
}

@article{frankle2018Lottery,
  title = {The {{Lottery Ticket Hypothesis}}: {{Finding Sparse}}, {{Trainable Neural Networks}}},
  shorttitle = {The {{Lottery Ticket Hypothesis}}},
  author = {Frankle, Jonathan and Carbin, Michael},
  year = {2018},
  month = mar,
  abstract = {Neural network pruning techniques can reduce the parameter counts of trained networks by over 90\%, decreasing storage requirements and improving computational performance of inference without compromising accuracy. However, contemporary experience is that the sparse architectures produced by pruning are difficult to train from the start, which would similarly improve training performance. We find that a standard pruning technique naturally uncovers subnetworks whose initializations made them capable of training effectively. Based on these results, we articulate the "lottery ticket hypothesis:" dense, randomly-initialized, feed-forward networks contain subnetworks ("winning tickets") that - when trained in isolation - reach test accuracy comparable to the original network in a similar number of iterations. The winning tickets we find have won the initialization lottery: their connections have initial weights that make training particularly effective. We present an algorithm to identify winning tickets and a series of experiments that support the lottery ticket hypothesis and the importance of these fortuitous initializations. We consistently find winning tickets that are less than 10-20\% of the size of several fully-connected and convolutional feed-forward architectures for MNIST and CIFAR10. Above this size, the winning tickets that we find learn faster than the original network and reach higher test accuracy.},
  archivePrefix = {arXiv},
  eprint = {1803.03635},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Frankle, Carbin (2018) - The Lottery Ticket Hypothesis.pdf},
  journal = {arXiv:1803.03635 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  primaryClass = {cs}
}

@article{frankle2020Early,
  title = {The {{Early Phase}} of {{Neural Network Training}}},
  author = {Frankle, Jonathan and Schwab, David J. and Morcos, Ari S.},
  year = {2020},
  month = feb,
  abstract = {Recent studies have shown that many important aspects of neural network learning take place within the very earliest iterations or epochs of training. For example, sparse, trainable sub-networks emerge (Frankle et al., 2019), gradient descent moves into a small subspace (Gur-Ari et al., 2018), and the network undergoes a critical period (Achille et al., 2019). Here we examine the changes that deep neural networks undergo during this early phase of training. We perform extensive measurements of the network state during these early iterations of training and leverage the framework of Frankle et al. (2019) to quantitatively probe the weight distribution and its reliance on various aspects of the dataset. We find that, within this framework, deep networks are not robust to reinitializing with random weights while maintaining signs, and that weight distributions are highly non-independent even after only a few hundred iterations. Despite this behavior, pre-training with blurred inputs or an auxiliary self-supervised task can approximate the changes in supervised networks, suggesting that these changes are not inherently label-dependent, though labels significantly accelerate this process. Together, these results help to elucidate the network changes occurring during this pivotal initial period of learning.},
  archivePrefix = {arXiv},
  eprint = {2002.10365},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Frankle et al (2020) - The Early Phase of Neural Network Training.pdf},
  journal = {arXiv:2002.10365 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{friedler2016im,
  title = {On the (Im)Possibility of Fairness},
  author = {Friedler, Sorelle A. and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  year = {2016},
  month = sep,
  abstract = {What does it mean for an algorithm to be fair? Different papers use different notions of algorithmic fairness, and although these appear internally consistent, they also seem mutually incompatible. We present a mathematical setting in which the distinctions in previous papers can be made formal. In addition to characterizing the spaces of inputs (the "observed" space) and outputs (the "decision" space), we introduce the notion of a construct space: a space that captures unobservable, but meaningful variables for the prediction. We show that in order to prove desirable properties of the entire decision-making process, different mechanisms for fairness require different assumptions about the nature of the mapping from construct space to decision space. The results in this paper imply that future treatments of algorithmic fairness should more explicitly state assumptions about the relationship between constructs and observations.},
  archivePrefix = {arXiv},
  eprint = {1609.07236},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Friedler et al (2016) - On the (im)possibility of fairness.pdf},
  journal = {arXiv:1609.07236 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{friedler2018comparative,
  title = {A Comparative Study of Fairness-Enhancing Interventions in Machine Learning},
  author = {Friedler, Sorelle A. and Scheidegger, Carlos and Venkatasubramanian, Suresh and Choudhary, Sonam and Hamilton, Evan P. and Roth, Derek},
  year = {2018},
  month = feb,
  abstract = {Computers are increasingly used to make decisions that have significant impact in people's lives. Often, these predictions can affect different population subgroups disproportionately. As a result, the issue of fairness has received much recent interest, and a number of fairness-enhanced classifiers and predictors have appeared in the literature. This paper seeks to study the following questions: how do these different techniques fundamentally compare to one another, and what accounts for the differences? Specifically, we seek to bring attention to many under-appreciated aspects of such fairness-enhancing interventions. Concretely, we present the results of an open benchmark we have developed that lets us compare a number of different algorithms under a variety of fairness measures, and a large number of existing datasets. We find that although different algorithms tend to prefer specific formulations of fairness preservations, many of these measures strongly correlate with one another. In addition, we find that fairness-preserving algorithms tend to be sensitive to fluctuations in dataset composition (simulated in our benchmark by varying training-test splits), indicating that fairness interventions might be more brittle than previously thought.},
  archivePrefix = {arXiv},
  eprint = {1802.04422},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Friedler et al (2018) - A comparative study of fairness-enhancing interventions in machine learning.pdf},
  journal = {arXiv:1802.04422 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{friedman2001Greedy,
  title = {Greedy Function Approximation: {{A}} Gradient Boosting Machine.},
  shorttitle = {Greedy Function Approximation},
  author = {Friedman, Jerome H.},
  year = {2001},
  volume = {29},
  pages = {1189--1232},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/aos/1013203451},
  abstract = {Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent ``boosting'' paradigm is developed for additive expansions based on any fitting criterion.Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such ``TreeBoost'' models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed.},
  file = {/Users/yuekai/Documents/zotero/Friedman (2001) - Greedy function approximation.pdf},
  journal = {The Annals of Statistics},
  language = {en},
  mrnumber = {MR1873328},
  number = {5},
  zmnumber = {1043.62034}
}

@article{friedman2008Sparse,
  title = {Sparse Inverse Covariance Estimation with the Graphical Lasso},
  author = {Friedman, J. and Hastie, T. and Tibshirani, R.},
  year = {2008},
  month = jul,
  volume = {9},
  pages = {432--441},
  issn = {1465-4644, 1468-4357},
  doi = {10.1093/biostatistics/kxm045},
  abstract = {We consider the problem of estimating sparse graphs by a lasso penalty applied to the inverse covariance matrix. Using a coordinate descent procedure for the lasso, we develop a simple algorithm\textemdash{} the Graphical Lasso\textemdash{} that is remarkably fast: it solves a 1000 node problem ({$\sim$} 500, 000 parameters) in at most a minute, and is 30 to 4000 times faster than competing methods. It also provides a conceptual link between the exact problem and the approximation suggested by Meinshausen \& Bu\textasciidieresis hlmann (2006). We illustrate the method on some cell-signaling data from proteomics.},
  file = {/Users/yuekai/Documents/zotero/Friedman et al (2008) - Sparse inverse covariance estimation with the graphical lasso.pdf},
  journal = {Biostatistics},
  language = {en},
  number = {3}
}

@article{frogner2019Incorporating,
  title = {Incorporating {{Unlabeled Data}} into {{Distributionally Robust Learning}}},
  author = {Frogner, Charlie and Claici, Sebastian and Chien, Edward and Solomon, Justin},
  year = {2019},
  month = dec,
  abstract = {We study a robust alternative to empirical risk minimization called distributionally robust learning (DRL), in which one learns to perform against an adversary who can choose the data distribution from a specified set of distributions. We illustrate a problem with current DRL formulations, which rely on an overly broad definition of allowed distributions for the adversary, leading to learned classifiers that are unable to predict with any confidence. We propose a solution that incorporates unlabeled data into the DRL problem to further constrain the adversary. We show that this new formulation is tractable for stochastic gradient-based optimization and yields a computable guarantee on the future performance of the learned classifier, analogous to -- but tighter than -- guarantees from conventional DRL. We examine the performance of this new formulation on 14 real datasets and find that it often yields effective classifiers with nontrivial performance guarantees in situations where conventional DRL produces neither. Inspired by these results, we extend our DRL formulation to active learning with a novel, distributionally-robust version of the standard model-change heuristic. Our active learning algorithm often achieves superior learning performance to the original heuristic on real datasets.},
  archivePrefix = {arXiv},
  eprint = {1912.07729},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Frogner et al (2019) - Incorporating Unlabeled Data into Distributionally Robust Learning.pdf},
  journal = {arXiv:1912.07729 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{frogner2019Learning,
  title = {Learning {{Embeddings}} into {{Entropic Wasserstein Spaces}}},
  author = {Frogner, Charlie and Mirzazadeh, Farzaneh and Solomon, Justin},
  year = {2019},
  month = may,
  abstract = {Euclidean embeddings of data are fundamentally limited in their ability to capture latent semantic structures, which need not conform to Euclidean spatial assumptions. Here we consider an alternative, which embeds data as discrete probability distributions in a Wasserstein space, endowed with an optimal transport metric. Wasserstein spaces are much larger and more flexible than Euclidean spaces, in that they can successfully embed a wider variety of metric structures. We exploit this flexibility by learning an embedding that captures semantic information in the Wasserstein distance between embedded distributions. We examine empirically the representational capacity of our learned Wasserstein embeddings, showing that they can embed a wide variety of metric structures with smaller distortion than an equivalent Euclidean embedding. We also investigate an application to word embedding, demonstrating a unique advantage of Wasserstein embeddings: We can visualize the high-dimensional embedding directly, since it is a probability distribution on a low-dimensional space. This obviates the need for dimensionality reduction techniques like t-SNE for visualization.},
  archivePrefix = {arXiv},
  eprint = {1905.03329},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Frogner et al (2019) - Learning Embeddings into Entropic Wasserstein Spaces.pdf},
  journal = {arXiv:1905.03329 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{frome2007Learning,
  title = {Learning {{Globally}}-{{Consistent Local Distance Functions}} for {{Shape}}-{{Based Image Retrieval}} and {{Classification}}},
  booktitle = {2007 {{IEEE}} 11th {{International Conference}} on {{Computer Vision}}},
  author = {Frome, A. and Singer, Y. and Sha, F. and Malik, J.},
  year = {2007},
  month = oct,
  pages = {1--8},
  doi = {10.1109/ICCV.2007.4408839},
  abstract = {We address the problem of visual category recognition by learning an image-to-image distance function that attempts to satisfy the following property: the distance between images from the same category should be less than the distance between images from different categories. We use patch-based feature vectors common in object recognition work as a basis for our image-to-image distance functions. Our large-margin formulation for learning the distance functions is similar to formulations used in the machine learning literature on distance metric learning, however we differ in that we learn local distance functions-a different parameterized function for every image of our training set-whereas typically a single global distance function is learned. This was a novel approach first introduced in Frome, Singer, \& Malik, NIPS 2006. In that work we learned the local distance functions independently, and the outputs of these functions could not be compared at test time without the use of additional heuristics or training. Here we introduce a different approach that has the advantage that it learns distance functions that are globally consistent in that they can be directly compared for purposes of retrieval and classification. The output of the learning algorithm are weights assigned to the image features, which is intuitively appealing in the computer vision setting: some features are more salient than others, and which are more salient depends on the category, or image, being considered. We train and test using the Caltech 101 object recognition benchmark.},
  file = {/Users/yuekai/Documents/zotero/Frome et al (2007) - Learning Globally-Consistent Local Distance Functions for Shape-Based Image.pdf;/Users/yuekai/Zotero/storage/DNSHFZZZ/4408839.html}
}

@article{frosst2019Analyzing,
  title = {Analyzing and {{Improving Representations}} with the {{Soft Nearest Neighbor Loss}}},
  author = {Frosst, Nicholas and Papernot, Nicolas and Hinton, Geoffrey},
  year = {2019},
  month = feb,
  abstract = {We explore and expand the \$\textbackslash textit\{Soft Nearest Neighbor Loss\}\$ to measure the \$\textbackslash textit\{entanglement\}\$ of class manifolds in representation space: i.e., how close pairs of points from the same class are relative to pairs of points from different classes. We demonstrate several use cases of the loss. As an analytical tool, it provides insights into the evolution of class similarity structures during learning. Surprisingly, we find that \$\textbackslash textit\{maximizing\}\$ the entanglement of representations of different classes in the hidden layers is beneficial for discrimination in the final layer, possibly because it encourages representations to identify class-independent similarity structures. Maximizing the soft nearest neighbor loss in the hidden layers leads not only to improved generalization but also to better-calibrated estimates of uncertainty on outlier data. Data that is not from the training distribution can be recognized by observing that in the hidden layers, it has fewer than the normal number of neighbors from the predicted class.},
  archivePrefix = {arXiv},
  eprint = {1902.01889},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Frosst et al (2019) - Analyzing and Improving Representations with the Soft Nearest Neighbor Loss.pdf},
  journal = {arXiv:1902.01889 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{fryer2007Economic,
  title = {An {{Economic Analysis}} of {{Color}}-{{Blind Affirmative Action}}},
  author = {Fryer, R. G. and Loury, G. C. and Yuret, T.},
  year = {2007},
  month = nov,
  volume = {24},
  pages = {319--355},
  issn = {8756-6222, 1465-7341},
  doi = {10.1093/jleo/ewm053},
  file = {/Users/yuekai/Documents/zotero/Fryer et al (2007) - An Economic Analysis of Color-Blind Affirmative Action.pdf},
  journal = {Journal of Law, Economics, and Organization},
  language = {en},
  number = {2}
}

@article{fu2000Asymptotics,
  title = {Asymptotics for Lasso-Type Estimators},
  author = {Fu, Wenjiang and Knight, Keith},
  year = {2000},
  month = oct,
  volume = {28},
  pages = {1356--1378},
  issn = {0090-5364},
  doi = {10.1214/aos/1015957397},
  file = {/Users/yuekai/Documents/zotero/Fu, Knight (2000) - Asymptotics for lasso-type estimators.pdf},
  journal = {The Annals of Statistics},
  language = {en},
  number = {5}
}

@inproceedings{fu2019ActorCritic,
  title = {Actor-{{Critic Provably Finds Nash Equilibria}} of {{Linear}}-{{Quadratic Mean}}-{{Field Games}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Fu, Zuyue and Yang, Zhuoran and Chen, Yongxin and Wang, Zhaoran},
  year = {2019},
  month = sep,
  abstract = {We study discrete-time mean-field Markov games with infinite numbers of agents where each agent aims to minimize its ergodic cost. We consider the setting where the agents have identical linear...},
  file = {/Users/yuekai/Documents/zotero/Fu et al (2019) - Actor-Critic Provably Finds Nash Equilibria of Linear-Quadratic Mean-Field Games.pdf}
}

@article{fukumizu2004Dimensionality,
  title = {Dimensionality {{Reduction}} for {{Supervised Learning}} with {{Reproducing Kernel Hilbert Spaces}}},
  author = {Fukumizu, Kenji and Bach, Francis R. and Jordan, Michael I.},
  year = {2004},
  volume = {5},
  pages = {73--99},
  issn = {ISSN 1533-7928},
  file = {/Users/yuekai/Documents/zotero/Fukumizu et al (2004) - Dimensionality Reduction for Supervised Learning with Reproducing Kernel.pdf},
  journal = {Journal of Machine Learning Research},
  number = {Jan}
}

@article{fukumizu2007Kernel,
  title = {Kernel {{Measures}} of {{Conditional Dependence}}},
  author = {Fukumizu, Kenji and Gretton, Arthur and Sun, Xiaohai and Scholkopf, Bernhard},
  year = {2007},
  month = dec,
  pages = {13},
  abstract = {We propose a new measure of conditional dependence of random variables, based on normalized cross-covariance operators on reproducing kernel Hilbert spaces. Unlike previous kernel dependence measures, the proposed criterion does not depend on the choice of kernel in the limit of infinite data, for a wide class of kernels. At the same time, it has a straightforward empirical estimate with good convergence behaviour. We discuss the theoretical properties of the measure, and demonstrate its application in experiments.},
  file = {/Users/yuekai/Documents/zotero/Fukumizu et al (2007) - Kernel Measures of Conditional Dependence.pdf},
  language = {en}
}

@article{fukumizu2013Kernel,
  title = {Kernel {{Bayes}}' {{Rule}}: {{Bayesian Inference}} with {{Positive Definite Kernels}}},
  shorttitle = {Kernel {{Bayes}}' {{Rule}}},
  author = {Fukumizu, Kenji and Song, Le and Gretton, Arthur},
  year = {2013},
  month = dec,
  volume = {14},
  pages = {3753--3783},
  issn = {1532-4435},
  abstract = {A kernel method for realizing Bayes' rule is proposed, based on representations of probabilities in reproducing kernel Hilbert spaces. Probabilities are uniquely characterized by the mean of the canonical map to the RKHS. The prior and conditional probabilities are expressed in terms of RKHS functions of an empirical sample: no explicit parametric model is needed for these quantities. The posterior is likewise an RKHS mean of a weighted sample. The estimator for the expectation of a function of the posterior is derived, and rates of consistency are shown. Some representative applications of the kernel Bayes' rule are presented, including Bayesian computation without likelihood and filtering with a nonparametric state-space model.},
  file = {/Users/yuekai/Documents/zotero/Fukumizu et al (2013) - Kernel Bayes' Rule.pdf},
  journal = {J. Mach. Learn. Res.},
  number = {1}
}

@article{gagnon-bartsch2012Using,
  title = {Using Control Genes to Correct for Unwanted Variation in Microarray Data},
  author = {{Gagnon-Bartsch}, Johann A. and Speed, Terence P.},
  year = {2012},
  month = jul,
  volume = {13},
  pages = {539--552},
  issn = {1468-4357},
  doi = {10.1093/biostatistics/kxr034},
  abstract = {Microarray expression studies suffer from the problem of batch effects and other unwanted variation. Many methods have been proposed to adjust microarray data to mitigate the problems of unwanted variation. Several of these methods rely on factor analysis to infer the unwanted variation from the data. A central problem with this approach is the difficulty in discerning the unwanted variation from the biological variation that is of interest to the researcher. We present a new method, intended for use in differential expression studies, that attempts to overcome this problem by restricting the factor analysis to negative control genes. Negative control genes are genes known a priori not to be differentially expressed with respect to the biological factor of interest. Variation in the expression levels of these genes can therefore be assumed to be unwanted variation. We name this method "Remove Unwanted Variation, 2-step" (RUV-2). We discuss various techniques for assessing the performance of an adjustment method and compare the performance of RUV-2 with that of other commonly used adjustment methods such as Combat and Surrogate Variable Analysis (SVA). We present several example studies, each concerning genes differentially expressed with respect to gender in the brain and find that RUV-2 performs as well or better than other methods. Finally, we discuss the possibility of adapting RUV-2 for use in studies not concerned with differential expression and conclude that there may be promise but substantial challenges remain.},
  file = {/Users/yuekai/Documents/zotero/Gagnon-Bartsch, Speed (2012) - Using control genes to correct for unwanted variation in microarray data.pdf},
  journal = {Biostatistics (Oxford, England)},
  language = {eng},
  number = {3},
  pmcid = {PMC3577104},
  pmid = {22101192}
}

@techreport{gagnon-bartsch2013Removing,
  title = {Removing {{Unwanted Variation}} from {{High Dimensional Data}} with {{Negative Controls}}},
  author = {{Gagnon-Bartsch}, Johann A and Jacob, Laurent and Speed, Terence P},
  year = {2013},
  month = dec,
  pages = {112},
  abstract = {High dimensional data suffer from unwanted variation, such as the batch effects common in microarray data. Unwanted variation complicates the analysis of high dimensional data, leading to high rates of false discoveries, high rates of missed discoveries, or both. In many cases the factors causing the unwanted variation are unknown and must be inferred from the data. In such cases, negative controls may be used to identify the unwanted variation and separate it from the wanted variation. We present a new method, RUV-4, to adjust for unwanted variation in high dimensional data with negative controls. RUV-4 may be used when the goal of the analysis is to determine which of the features are truly associated with a given factor of interest. One nice property of RUV-4 is that it is relatively insensitive to the number of unwanted factors included in the model; this makes estimating the number of factors less critical. We also present a novel method for estimating the features' variances that may be used even when a large number of unwanted factors are included in the model and the design matrix is full rank. We name this the ``inverse method for estimating variances.'' By combining RUV-4 with the inverse method, it is no longer necessary to estimate the number of unwanted factors at all. Using both real and simulated data we compare the performance of RUV-4 with that of other adjustment methods such as SVA, LEAPP, ICE, and RUV-2. We find that RUV-4 and its variants perform as well or better than other methods.},
  file = {/Users/yuekai/Documents/zotero/Gagnon-Bartsch et al (2013) - Removing Unwanted Variation from High Dimensional Data with Negative Controls.pdf},
  language = {en},
  number = {820}
}

@article{galhotra2020Fair,
  title = {Fair {{Data Integration}}},
  author = {Galhotra, Sainyam and Shanmugam, Karthikeyan and Sattigeri, Prasanna and Varshney, Kush R.},
  year = {2020},
  month = jun,
  abstract = {The use of machine learning (ML) in high-stakes societal decisions has encouraged the consideration of fairness throughout the ML lifecycle. Although data integration is one of the primary steps to generate high quality training data, most of the fairness literature ignores this stage. In this work, we consider fairness in the integration component of data management, aiming to identify features that improve prediction without adding any bias to the dataset. We work under the causal interventional fairness paradigm. Without requiring the underlying structural causal model a priori, we propose an approach to identify a sub-collection of features that ensure the fairness of the dataset by performing conditional independence tests between different subsets of features. We use group testing to improve the complexity of the approach. We theoretically prove the correctness of the proposed algorithm to identify features that ensure interventional fairness and show that sub-linear conditional independence tests are sufficient to identify these variables. A detailed empirical evaluation is performed on real-world datasets to demonstrate the efficacy and efficiency of our technique.},
  archivePrefix = {arXiv},
  eprint = {2006.06053},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Galhotra et al (2020) - Fair Data Integration.pdf},
  journal = {arXiv:2006.06053 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Databases,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{gao2010Doubt,
  title = {On the {{Doubt}} about {{Margin Explanation}} of {{Boosting}}},
  author = {Gao, Wei and Zhou, Zhi-Hua},
  year = {2010},
  month = sep,
  abstract = {Margin theory provides one of the most popular explanations to the success of \textbackslash texttt\{AdaBoost\}, where the central point lies in the recognition that \textbackslash textit\{margin\} is the key for characterizing the performance of \textbackslash texttt\{AdaBoost\}. This theory has been very influential, e.g., it has been used to argue that \textbackslash texttt\{AdaBoost\} usually does not overfit since it tends to enlarge the margin even after the training error reaches zero. Previously the \textbackslash textit\{minimum margin bound\} was established for \textbackslash texttt\{AdaBoost\}, however, \textbackslash cite\{Breiman1999\} pointed out that maximizing the minimum margin does not necessarily lead to a better generalization. Later, \textbackslash cite\{Reyzin:Schapire2006\} emphasized that the margin distribution rather than minimum margin is crucial to the performance of \textbackslash texttt\{AdaBoost\}. In this paper, we first present the \textbackslash textit\{\$k\$th margin bound\} and further study on its relationship to previous work such as the minimum margin bound and Emargin bound. Then, we improve the previous empirical Bernstein bounds \textbackslash citep\{Maurer:Pontil2009,Audibert:Munos:Szepesvari2009\}, and based on such findings, we defend the margin-based explanation against Breiman's doubts by proving a new generalization error bound that considers exactly the same factors as \textbackslash cite\{Schapire:Freund:Bartlett:Lee1998\} but is sharper than \textbackslash cite\{Breiman1999\}'s minimum margin bound. By incorporating factors such as average margin and variance, we present a generalization error bound that is heavily related to the whole margin distribution. We also provide margin distribution bounds for generalization error of voting classifiers in finite VC-dimension space.},
  archivePrefix = {arXiv},
  eprint = {1009.3613},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gao, Zhou (2010) - On the Doubt about Margin Explanation of Boosting.pdf},
  journal = {arXiv:1009.3613 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{gao2015Rateoptimal,
  title = {Rate-Optimal Graphon Estimation},
  author = {Gao, Chao and Lu, Yu and Zhou, Harrison H.},
  year = {2015},
  month = dec,
  volume = {43},
  pages = {2624--2652},
  issn = {0090-5364},
  doi = {10.1214/15-AOS1354},
  abstract = {Network analysis is becoming one of the most active research areas in statistics. Significant advances have been made recently on developing theories, methodologies and algorithms for analyzing networks. However, there has been little fundamental study on optimal estimation. In this paper, we establish optimal rate of convergence for graphon estimation. For the stochastic block model with \$k\$ clusters, we show that the optimal rate under the mean squared error is \$n\^\{-1\}\textbackslash log k+k\^2/n\^2\$. The minimax upper bound improves the existing results in literature through a technique of solving a quadratic equation. When \$k\textbackslash leq\textbackslash sqrt\{n\textbackslash log n\}\$, as the number of the cluster \$k\$ grows, the minimax rate grows slowly with only a logarithmic order \$n\^\{-1\}\textbackslash log k\$. A key step to establish the lower bound is to construct a novel subset of the parameter space and then apply Fano's lemma, from which we see a clear distinction of the nonparametric graphon estimation problem from classical nonparametric regression, due to the lack of identifiability of the order of nodes in exchangeable random graph models. As an immediate application, we consider nonparametric graphon estimation in a H\textbackslash "\{o\}lder class with smoothness \$\textbackslash alpha\$. When the smoothness \$\textbackslash alpha\textbackslash geq1\$, the optimal rate of convergence is \$n\^\{-1\}\textbackslash log n\$, independent of \$\textbackslash alpha\$, while for \$\textbackslash alpha\textbackslash in(0,1)\$, the rate is \$n\^\{-2\textbackslash alpha/(\textbackslash alpha+1)\}\$, which is, to our surprise, identical to the classical nonparametric rate.},
  archivePrefix = {arXiv},
  eprint = {1410.5837},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gao et al (2015) - Rate-optimal graphon estimation.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory},
  number = {6}
}

@article{gao2017Robust,
  title = {Robust {{Regression}} via {{Mutivariate Regression Depth}}},
  author = {Gao, Chao},
  year = {2017},
  month = feb,
  abstract = {This paper studies robust regression in the settings of Huber's \$\textbackslash epsilon\$-contamination models. We consider estimators that are maximizers of multivariate regression depth functions. These estimators are shown to achieve minimax rates in the settings of \$\textbackslash epsilon\$-contamination models for various regression problems including nonparametric regression, sparse linear regression, reduced rank regression, etc. We also discuss a general notion of depth function for linear operators that has potential applications in robust functional linear regression.},
  archivePrefix = {arXiv},
  eprint = {1702.04656},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gao (2017) - Robust Regression via Mutivariate Regression Depth.pdf},
  journal = {arXiv:1702.04656 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {math, stat}
}

@article{gao2017Wasserstein,
  title = {Wasserstein {{Distributional Robustness}} and {{Regularization}} in {{Statistical Learning}}},
  author = {Gao, Rui and Chen, Xi and Kleywegt, Anton J.},
  year = {2017},
  month = dec,
  abstract = {A central question in statistical learning is to design algorithms that not only perform well on training data, but also generalize to new and unseen data. In this paper, we tackle this question by formulating a distributionally robust stochastic optimization (DRSO) problem, which seeks a solution that minimizes the worst-case expected loss over a family of distributions that are close to the empirical distribution in Wasserstein distances. We establish a connection between such Wasserstein DRSO and regularization. More precisely, we identify a broad class of loss functions, for which the Wasserstein DRSO is asymptotically equivalent to a regularization problem with a gradient-norm penalty. Such relation provides new interpretations for problems involving regularization, including a great number of statistical learning problems and discrete choice models (e.g. multinomial logit). The connection suggests a principled way to regularize high-dimensional, non-convex problems. This is demonstrated through the training of Wasserstein generative adversarial networks in deep learning.},
  archivePrefix = {arXiv},
  eprint = {1712.06050},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gao et al (2017) - Wasserstein Distributional Robustness and Regularization in Statistical Learning.pdf},
  journal = {arXiv:1712.06050 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{gao2018ADMM,
  title = {{{ADMM}} for {{Multiaffine Constrained Optimization}}},
  author = {Gao, Wenbo and Goldfarb, Donald and Curtis, Frank E.},
  year = {2018},
  month = feb,
  abstract = {We propose an expansion of the scope of the alternating direction method of multipliers (ADMM). Specifically, we show that ADMM, when employed to solve problems with multiaffine constraints that satisfy certain easily verifiable assumptions, converges to the set of constrained stationary points if the penalty parameter in the augmented Lagrangian is sufficiently large. When the Kurdyka-Lojasiewicz (K-L) property holds, this is strengthened to convergence to a single constrained stationary point. Our analysis applies under assumptions that we have endeavored to make as weak as possible. It applies to problems that involve nonconvex and/or nonsmooth objective terms, in addition to the multiaffine constraints that can involve multiple (three or more) blocks of variables. To illustrate the applicability of our results, we describe examples including nonnegative matrix factorization, sparse learning, risk parity portfolio selection, nonconvex formulations of convex problems, and neural network training. In each case, our ADMM approach encounters only subproblems that have closed-form solutions.},
  archivePrefix = {arXiv},
  eprint = {1802.09592},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gao et al (2018) - ADMM for Multiaffine Constrained Optimization.pdf},
  journal = {arXiv:1802.09592 [math]},
  keywords = {Mathematics - Optimization and Control},
  primaryClass = {math}
}

@article{gao2018Fundamental,
  title = {Fundamental {{Limits}} of {{Exact Support Recovery}} in {{High Dimensions}}},
  author = {Gao, Zheng and Stoev, Stilian},
  year = {2018},
  month = nov,
  abstract = {We study the support recovery problem for a high-dimensional signal observed with additive noise. With suitable parametrization of the signal sparsity and magnitude of its non-zero components, we characterize a phase-transition phenomenon akin to the signal detection problem studied by Ingster in 1998. Specifically, if the signal magnitude is above the so-called strong classification boundary, we show that several classes of well-known procedures achieve asymptotically perfect support recovery as the dimension goes to infinity. This is so, for a very broad class of error distributions with light, rapidly varying tails which may have arbitrary dependence. Conversely, if the signal is below the boundary, then for a very broad class of error dependence structures, no thresholding estimators (including ones with data-dependent thresholds) can achieve perfect support recovery. The proofs of these results exploit a certain concentration of maxima phenomenon known as relative stability. We provide a complete characterization of the relative stability phenomenon for Gaussian triangular arrays in terms their correlation structure. The proof uses classic Sudakov-Fernique and Slepian lemma arguments along with a curious application of Ramsey's coloring theorem. We note that our study of the strong classification boundary is in a finer, point-wise, rather than minimax, sense. We also establish the Bayes optimality and sub-optimality of thresholding procedures. Consequently, we obtain a minimax-type characterization of the strong classification boundary for errors with log-concave densities.},
  archivePrefix = {arXiv},
  eprint = {1811.05124},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gao, Stoev (2018) - Fundamental Limits of Exact Support Recovery in High Dimensions.pdf},
  journal = {arXiv:1811.05124 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{gao2018Minimax,
  title = {Minimax {{Rates}} in {{Network Analysis}}: {{Graphon Estimation}}, {{Community Detection}} and {{Hypothesis Testing}}},
  shorttitle = {Minimax {{Rates}} in {{Network Analysis}}},
  author = {Gao, Chao and Ma, Zongming},
  year = {2018},
  month = nov,
  abstract = {This paper surveys some recent developments in fundamental limits and optimal algorithms for network analysis. We focus on minimax optimal rates in three fundamental problems of network analysis: graphon estimation, community detection, and hypothesis testing. For each problem, we review state-of-the-art results in the literature followed by general principles behind the optimal procedures that lead to minimax estimation and testing. This allows us to connect problems in network analysis to other statistical inference problems from a general perspective.},
  archivePrefix = {arXiv},
  eprint = {1811.06055},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gao, Ma (2018) - Minimax Rates in Network Analysis.pdf},
  journal = {arXiv:1811.06055 [cs, math, stat]},
  keywords = {Computer Science - Social and Information Networks,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{gao2018Robust,
  title = {Robust {{Estimation}} and {{Generative Adversarial Nets}}},
  author = {Gao, Chao and Liu, Jiyi and Yao, Yuan and Zhu, Weizhi},
  year = {2018},
  month = oct,
  abstract = {Robust estimation under Huber's \$\textbackslash epsilon\$-contamination model has become an important topic in statistics and theoretical computer science. Statistically optimal procedures such as Tukey's median and other estimators based on depth functions are impractical because of their computational intractability. In this paper, we establish an intriguing connection between \$f\$-GANs and various depth functions through the lens of \$f\$-Learning. Similar to the derivation of \$f\$-GANs, we show that these depth functions that lead to statistically optimal robust estimators can all be viewed as variational lower bounds of the total variation distance in the framework of \$f\$-Learning. This connection opens the door of computing robust estimators using tools developed for training GANs. In particular, we show in both theory and experiments that some appropriate structures of discriminator networks with hidden layers in GANs lead to statistically optimal robust location estimators for both Gaussian distribution and general elliptical distributions where first moment may not exist.},
  archivePrefix = {arXiv},
  eprint = {1810.02030},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gao et al (2018) - Robust Estimation and Generative Adversarial Nets.pdf},
  journal = {arXiv:1810.02030 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Computation,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {cs, math, stat}
}

@inproceedings{gao2018ROBUST,
  title = {{{ROBUST ESTIMATION VIA GENERATIVE ADVERSARIAL NETWORKS}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Gao, Chao and Liu, Jiyi and Yao, Yuan and Zhu, Weizhi},
  year = {2018},
  month = sep,
  abstract = {Robust estimation under Huber's \$\textbackslash epsilon\$-contamination model has become an important topic in statistics and theoretical computer science. Rate-optimal procedures such as Tukey's median and other...},
  file = {/Users/yuekai/Documents/zotero/Gao et al (2018) - ROBUST ESTIMATION VIA GENERATIVE ADVERSARIAL NETWORKS.pdf;/Users/yuekai/Zotero/storage/JS4N9XJH/forum.html}
}

@article{gao2018Robusta,
  title = {Robust {{Hypothesis Testing Using Wasserstein Uncertainty Sets}}},
  author = {Gao, Rui and Xie, Liyan and Xie, Yao and Xu, Huan},
  year = {2018},
  month = may,
  abstract = {We develop a novel computationally efficient and general framework for robust hypothesis testing. The new framework features a new way to construct uncertainty sets under the null and the alternative distributions, which are sets centered around the empirical distribution defined via Wasserstein metric, thus our approach is data-driven and free of distributional assumptions. We develop a convex safe approximation of the minimax formulation and show that such approximation renders a nearly-optimal detector among the family of all possible tests. By exploiting the structure of the least favorable distribution, we also develop a tractable reformulation of such approximation, with complexity independent of the dimension of observation space and can be nearly sample-size-independent in general. Real-data example using human activity data demonstrated the excellent performance of the new robust detector.},
  archivePrefix = {arXiv},
  eprint = {1805.10611},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gao et al (2018) - Robust Hypothesis Testing Using Wasserstein Uncertainty Sets.pdf},
  journal = {arXiv:1805.10611 [cs, math, stat]},
  keywords = {Computer Science - Information Theory,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{gao2019Convergence,
  title = {Convergence of {{Adversarial Training}} in {{Overparametrized Networks}}},
  author = {Gao, Ruiqi and Cai, Tianle and Li, Haochuan and Wang, Liwei and Hsieh, Cho-Jui and Lee, Jason D.},
  year = {2019},
  month = jun,
  abstract = {Neural networks are vulnerable to adversarial examples, i.e. inputs that are imperceptibly perturbed from natural data and yet incorrectly classified by the network. Adversarial training, a heuristic form of robust optimization that alternates between minimization and maximization steps, has proven to be among the most successful methods to train networks that are robust against a pre-defined family of perturbations. This paper provides a partial answer to the success of adversarial training. When the inner maximization problem can be solved to optimality, we prove that adversarial training finds a network of small robust train loss. When the maximization problem is solved by a heuristic algorithm, we prove that adversarial training finds a network of small robust surrogate train loss. The analysis technique leverages recent work on the analysis of neural networks via Neural Tangent Kernel (NTK), combined with online-learning when the maximization is solved by a heuristic, and the expressiveness of the NTK kernel in the \$\textbackslash ell\_\textbackslash infty\$-norm.},
  archivePrefix = {arXiv},
  eprint = {1906.07916},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gao et al (2019) - Convergence of Adversarial Training in Overparametrized Networks.pdf},
  journal = {arXiv:1906.07916 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{gardner2018Evaluating,
  title = {Evaluating {{Predictive Models}} of {{Student Success}}: {{Closing}} the {{Methodological Gap}}},
  shorttitle = {Evaluating {{Predictive Models}} of {{Student Success}}},
  author = {Gardner, Josh and Brooks, Christopher},
  year = {2018/00/00},
  volume = {5},
  pages = {105--125},
  publisher = {{Society for Learning Analytics Research}},
  issn = {1929-7750},
  abstract = {Model evaluation -- the process of making inferences about the performance of predictive models -- is a critical component of predictive modelling research in learning analytics. We survey the state of the practice with respect to model evaluation in learning analytics, which overwhelmingly uses only na\"ive methods for model evaluation or statistical tests that are not appropriate for predictive model evaluation. We conduct a critical comparison of both null hypothesis significance testing (NHST) and a preferred Bayesian method for model evaluation. Finally, we apply three methods -- the na\"ive average commonly used in learning analytics, NHST, and Bayesian -- to a predictive modelling experiment on a large set of MOOC data. We compare 96 different predictive models, including different feature sets, statistical modelling algorithms, and tuning hyperparameters for each, using this case study to demonstrate the different experimental conclusions these evaluation techniques provide.},
  file = {/Users/yuekai/Documents/zotero/Gardner, Brooks (2018) - Evaluating Predictive Models of Student Success.pdf},
  journal = {Journal of Learning Analytics},
  keywords = {Academic Achievement,Bayesian Statistics,Case Studies,Comparative Analysis,Computation,Data Analysis,Evaluation,Evaluation Methods,Hypothesis Testing,Mathematics,Models,Online Courses,Prediction},
  language = {en},
  number = {2}
}

@inproceedings{gardner2018Replicating,
  title = {Replicating {{MOOC}} Predictive Models at Scale},
  booktitle = {Proceedings of the {{Fifth Annual ACM Conference}} on {{Learning}} at {{Scale}}},
  author = {Gardner, Josh and Brooks, Christopher and Andres, Juan Miguel and Baker, Ryan},
  year = {2018},
  month = jun,
  pages = {1--10},
  publisher = {{Association for Computing Machinery}},
  address = {{London, United Kingdom}},
  doi = {10.1145/3231644.3231656},
  abstract = {We present a case study in predictive model replication for student dropout in Massive Open Online Courses (MOOCs) using a large and diverse dataset (133 sessions of 28 unique courses offered by two institutions). This experiment was run on the MOOC Replication Framework (MORF), which makes it feasible to fully replicate complex machine learned models, from raw data to model evaluation. We provide an overview of the MORF platform architecture and functionality, and demonstrate its use through a case study. In this replication of [41], we contextualize and evaluate the results of the previous work using statistical tests and a more effective model evaluation scheme. We find that only some of the original findings replicate across this larger and more diverse sample of MOOCs, with others replicating significantly in the opposite direction. Our analysis also reveals results which are highly relevant to the prediction task which were not reported in the original experiment. This work demonstrates the importance of replication of predictive modeling research in MOOCs using large and diverse datasets, illuminates the challenges of doing so, and describes our freely available, open-source software framework to overcome barriers to replication.},
  file = {/Users/yuekai/Documents/zotero/Gardner et al (2018) - Replicating MOOC predictive models at scale.pdf},
  isbn = {978-1-4503-5886-6},
  series = {L@{{S}} '18}
}

@inproceedings{gardner2019Evaluating,
  title = {Evaluating the {{Fairness}} of {{Predictive Student Models Through Slicing Analysis}}},
  booktitle = {Proceedings of the 9th {{International Conference}} on {{Learning Analytics}} \& {{Knowledge}}},
  author = {Gardner, Josh and Brooks, Christopher and Baker, Ryan},
  year = {2019},
  month = mar,
  pages = {225--234},
  publisher = {{Association for Computing Machinery}},
  address = {{Tempe, AZ, USA}},
  doi = {10.1145/3303772.3303791},
  abstract = {Predictive modeling has been a core area of learning analytics research over the past decade, with such models currently deployed in a variety of educational contexts from MOOCs to K-12. However, analyses of the differential effectiveness of these models across demographic, identity, or other groups has been scarce. In this paper, we present a method for evaluating unfairness in predictive student models. We define this in terms of differential accuracy between subgroups, and measure it using a new metric we term the Absolute Between-ROC Area (ABROCA). We demonstrate the proposed method through a gender-based "slicing analysis" using five different models replicated from other works and a dataset of 44 unique MOOCs and over four million learners. Our results demonstrate (1) significant differences in model fairness according to (a) statistical algorithm and (b) feature set used; (2) that the gender imbalance ratio, curricular area, and specific course used for a model all display significant association with the value of the ABROCA statistic; and (3) that there is not evidence of a strict tradeoff between performance and fairness. This work provides a framework for quantifying and understanding how predictive models might inadvertently privilege, or disparately impact, different student subgroups. Furthermore, our results suggest that learning analytics researchers and practitioners can use slicing analysis to improve model fairness without necessarily sacrificing performance.1},
  file = {/Users/yuekai/Documents/zotero/Gardner et al (2019) - Evaluating the Fairness of Predictive Student Models Through Slicing Analysis.pdf},
  isbn = {978-1-4503-6256-6},
  keywords = {Fairness,machine learning,MOOCs},
  series = {{{LAK19}}}
}

@article{garg2018Counterfactual,
  title = {Counterfactual {{Fairness}} in {{Text Classification}} through {{Robustness}}},
  author = {Garg, Sahaj and Perot, Vincent and Limtiaco, Nicole and Taly, Ankur and Chi, Ed H. and Beutel, Alex},
  year = {2018},
  month = sep,
  abstract = {In this paper, we study counterfactual fairness in text classification, which asks the question: How would the prediction change if the sensitive attribute referenced in the example were different? Toxicity classifiers demonstrate a counterfactual fairness issue by predicting that "Some people are gay" is toxic while "Some people are straight" is nontoxic. We offer a metric, counterfactual token fairness (CTF), for measuring this particular form of fairness in text classifiers, and describe its relationship with group fairness. Further, we offer three approaches, blindness, counterfactual augmentation, and counterfactual logit pairing (CLP), for optimizing counterfactual token fairness during training, bridging the robustness and fairness literature. Empirically, we find that blindness and CLP address counterfactual token fairness. The methods do not harm classifier performance, and have varying tradeoffs with group fairness. These approaches, both for measurement and optimization, provide a new path forward for addressing fairness concerns in text classification.},
  archivePrefix = {arXiv},
  eprint = {1809.10610},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Garg et al (2018) - Counterfactual Fairness in Text Classification through Robustness.pdf},
  journal = {arXiv:1809.10610 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{garg2019Solving,
  title = {Solving Graph Compression via Optimal Transport},
  author = {Garg, Vikas K. and Jaakkola, Tommi},
  year = {2019},
  month = may,
  abstract = {We propose a new approach to graph compression by appeal to optimal transport. The transport problem is seeded with prior information about node importance, attributes, and edges in the graph. The transport formulation can be setup for either directed or undirected graphs, and its dual characterization is cast in terms of distributions over the nodes. The compression pertains to the support of node distributions and makes the problem challenging to solve directly. To this end, we introduce Boolean relaxations and specify conditions under which these relaxations are exact. The relaxations admit algorithms with provably fast convergence. Moreover, we provide an exact \$O(d \textbackslash log d)\$ algorithm for the subproblem of projecting a \$d\$-dimensional vector to transformed simplex constraints. Our method outperforms state-of-the-art compression methods on graph classification.},
  archivePrefix = {arXiv},
  eprint = {1905.12158},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Garg, Jaakkola (2019) - Solving graph compression via optimal transport.pdf},
  journal = {arXiv:1905.12158 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{garg2019Tracking,
  title = {Tracking and {{Improving Information}} in the {{Service}} of {{Fairness}}},
  author = {Garg, Sumegha and Kim, Michael P. and Reingold, Omer},
  year = {2019},
  month = apr,
  abstract = {As algorithmic prediction systems have become widespread, fears that these systems may inadvertently discriminate against members of underrepresented populations have grown. With the goal of understanding fundamental principles that underpin the growing number of approaches to mitigating algorithmic discrimination, we investigate the role of information in fair prediction. A common strategy for decision-making uses a predictor to assign individuals a risk score; then, individuals are selected or rejected on the basis of this score. In this work, we formalize a framework for measuring the information content of predictors. Central to this framework is the notion of a refinement; intuitively, a refinement of a predictor \$z\$ increases the overall informativeness of the predictions without losing the information already contained in \$z\$. We show that increasing information content through refinements improves the downstream selection rules across a wide range of fairness measures (e.g. true positive rates, false positive rates, selection rates). In turn, refinements provide a simple but effective tool for reducing disparity in treatment and impact without sacrificing the utility of the predictions. Our results suggest that in many applications, the perceived "cost of fairness" results from an information disparity across populations, and thus, may be avoided with improved information.},
  archivePrefix = {arXiv},
  eprint = {1904.09942},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Garg et al (2019) - Tracking and Improving Information in the Service of Fairness.pdf},
  journal = {arXiv:1904.09942 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{garg2020Unified,
  title = {A {{Unified View}} of {{Label Shift Estimation}}},
  author = {Garg, Saurabh and Wu, Yifan and Balakrishnan, Sivaraman and Lipton, Zachary C.},
  year = {2020},
  month = mar,
  abstract = {Label shift describes the setting where although the label distribution might change between the source and target domains, the class-conditional probabilities (of data given a label) do not. There are two dominant approaches for estimating the label marginal. BBSE, a moment-matching approach based on confusion matrices, is provably consistent and provides interpretable error bounds. However, a maximum likelihood estimation approach, which we call MLLS, dominates empirically. In this paper, we present a unified view of the two methods and the first theoretical characterization of the likelihood-based estimator. Our contributions include (i) conditions for consistency of MLLS, which include calibration of the classifier and a confusion matrix invertibility condition that BBSE also requires; (ii) a unified view of the methods, casting the confusion matrix as roughly equivalent to MLLS for a particular choice of calibration method; and (iii) a decomposition of MLLS's finite-sample error into terms reflecting the impacts of miscalibration and estimation error. Our analysis attributes BBSE's statistical inefficiency to a loss of information due to coarse calibration. We support our findings with experiments on both synthetic data and the MNIST and CIFAR10 image recognition datasets.},
  archivePrefix = {arXiv},
  eprint = {2003.07554},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Garg et al (2020) - A Unified View of Label Shift Estimation.pdf},
  journal = {arXiv:2003.07554 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{ge2016Matrix,
  title = {Matrix {{Completion}} Has {{No Spurious Local Minimum}}},
  author = {Ge, Rong and Lee, Jason D. and Ma, Tengyu},
  year = {2016},
  month = may,
  abstract = {Matrix completion is a basic machine learning problem that has wide applications, especially in collaborative filtering and recommender systems. Simple non-convex optimization algorithms are popular and effective in practice. Despite recent progress in proving various non-convex algorithms converge from a good initial point, it remains unclear why random or arbitrary initialization suffices in practice. We prove that the commonly used non-convex objective function for \textbackslash textit\{positive semidefinite\} matrix completion has no spurious local minima --- all local minima must also be global. Therefore, many popular optimization algorithms such as (stochastic) gradient descent can provably solve positive semidefinite matrix completion with \textbackslash textit\{arbitrary\} initialization in polynomial time. The result can be generalized to the setting when the observed entries contain noise. We believe that our main proof strategy can be useful for understanding geometric properties of other statistical problems involving partial or noisy observations.},
  archivePrefix = {arXiv},
  eprint = {1605.07272},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ge et al (2016) - Matrix Completion has No Spurious Local Minimum.pdf},
  journal = {arXiv:1605.07272 [cs, stat]},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{ge2017No,
  title = {No {{Spurious Local Minima}} in {{Nonconvex Low Rank Problems}}: {{A Unified Geometric Analysis}}},
  shorttitle = {No {{Spurious Local Minima}} in {{Nonconvex Low Rank Problems}}},
  author = {Ge, Rong and Jin, Chi and Zheng, Yi},
  year = {2017},
  month = apr,
  abstract = {In this paper we develop a new framework that captures the common landscape underlying the common non-convex low-rank matrix problems including matrix sensing, matrix completion and robust PCA. In particular, we show for all above problems (including asymmetric cases): 1) all local minima are also globally optimal; 2) no high-order saddle points exists. These results explain why simple algorithms such as stochastic gradient descent have global converge, and efficiently optimize these non-convex objective functions in practice. Our framework connects and simplifies the existing analyses on optimization landscapes for matrix sensing and symmetric matrix completion. The framework naturally leads to new results for asymmetric matrix completion and robust PCA.},
  archivePrefix = {arXiv},
  eprint = {1704.00708},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ge et al (2017) - No Spurious Local Minima in Nonconvex Low Rank Problems.pdf},
  journal = {arXiv:1704.00708 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{geiger2020Garbage,
  title = {Garbage {{In}}, {{Garbage Out}}? {{Do Machine Learning Application Papers}} in {{Social Computing Report Where Human}}-{{Labeled Training Data Comes From}}?},
  author = {Geiger, R Stuart and Yu, Kevin and Yang, Yanlai and Dai, Mindy and Qiu, Jie and Tang, Rebekah and Huang, Jenny},
  year = {2020},
  pages = {12},
  abstract = {Many machine learning projects for new application areas involve teams of humans who label data for a particular purpose, from hiring crowdworkers to the paper's authors labeling the data themselves. Such a task is quite similar to (or a form of) structured content analysis, which is a longstanding methodology in the social sciences and humanities, with many established best practices. In this paper, we investigate to what extent a sample of machine learning application papers in social computing \textemdash{} specifically papers from ArXiv and traditional publications performing an ML classification task on Twitter data \textemdash{} give specific details about whether such best practices were followed. Our team conducted multiple rounds of structured content analysis of each paper, making determinations such as: Does the paper report who the labelers were, what their qualifications were, whether they independently labeled the same items, whether inter-rater reliability metrics were disclosed, what level of training and/or instructions were given to labelers, whether compensation for crowdworkers is disclosed, and if the training data is publicly available. We find a wide divergence in whether such practices were followed and documented. Much of machine learning research and education focuses on what is done once a ``gold standard'' of training data is available, but we discuss issues around the equally-important aspect of whether such data is reliable in the first place.},
  file = {/Users/yuekai/Documents/zotero/Geiger et al (2020) - Garbage In, Garbage Out.pdf},
  language = {en}
}

@book{gelman2013Bayesian,
  title = {Bayesian {{Data Analysis}}},
  author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
  year = {2013},
  month = nov,
  edition = {Third},
  publisher = {{Chapman \& Hall/CRC}},
  file = {/Users/yuekai/Documents/zotero/Gelman et al (2013) - Bayesian Data Analysis.pdf},
  language = {en},
  number = {106},
  series = {Texts in {{Statistical Science}}}
}

@phdthesis{genevay2019EntropyRegularized,
  title = {Entropy-{{Regularized Optimal Transport}} for {{Machine Learning}}},
  author = {Genevay, Aude},
  year = {2019},
  month = mar,
  abstract = {This thesis proposes theoretical and numerical contributions to use Entropy-regularized Optimal Transport (EOT) for machine learning. We introduce Sinkhorn Divergences (SD), a class of discrepancies between probability measures based on EOT which interpolates between two other well-known discrepancies: Optimal Transport (OT) and Maximum Mean Discrepancies (MMD). We develop an efficient numerical method to use SD for density fitting tasks, showing that a suitable choice of regularization can improve performance over existing methods. We derive a sample complexity theorem for SD which proves that choosing a large enough regularization parameter allows to break the curse of dimensionality from OT, and recover asymptotic rates similar to MMD. We propose and analyze stochastic optimization solvers for EOT, which yield online methods that can cope with arbitrary measures and are well suited to large scale problems, contrarily to existing discrete batch solvers.},
  file = {/Users/yuekai/Documents/zotero/Genevay (2019) - Entropy-Regularized Optimal Transport for Machine Learning.pdf},
  school = {Ecole Normale Sup\'erieure}
}

@article{genevay2019Sample,
  title = {Sample {{Complexity}} of {{Sinkhorn}} Divergences},
  author = {Genevay, Aude and Chizat, L{\'e}naic and Bach, Francis and Cuturi, Marco and Peyr{\'e}, Gabriel},
  year = {2019},
  month = feb,
  abstract = {Optimal transport (OT) and maximum mean discrepancies (MMD) are now routinely used in machine learning to compare probability measures. We focus in this paper on \textbackslash emph\{Sinkhorn divergences\} (SDs), a regularized variant of OT distances which can interpolate, depending on the regularization strength \$\textbackslash varepsilon\$, between OT (\$\textbackslash varepsilon=0\$) and MMD (\$\textbackslash varepsilon=\textbackslash infty\$). Although the tradeoff induced by that regularization is now well understood computationally (OT, SDs and MMD require respectively \$O(n\^3\textbackslash log n)\$, \$O(n\^2)\$ and \$n\^2\$ operations given a sample size \$n\$), much less is known in terms of their \textbackslash emph\{sample complexity\}, namely the gap between these quantities, when evaluated using finite samples \textbackslash emph\{vs.\} their respective densities. Indeed, while the sample complexity of OT and MMD stand at two extremes, \$1/n\^\{1/d\}\$ for OT in dimension \$d\$ and \$1/\textbackslash sqrt\{n\}\$ for MMD, that for SDs has only been studied empirically. In this paper, we \textbackslash emph\{(i)\} derive a bound on the approximation error made with SDs when approximating OT as a function of the regularizer \$\textbackslash varepsilon\$, \textbackslash emph\{(ii)\} prove that the optimizers of regularized OT are bounded in a Sobolev (RKHS) ball independent of the two measures and \textbackslash emph\{(iii)\} provide the first sample complexity bound for SDs, obtained,by reformulating SDs as a maximization problem in a RKHS. We thus obtain a scaling in \$1/\textbackslash sqrt\{n\}\$ (as in MMD), with a constant that depends however on \$\textbackslash varepsilon\$, making the bridge between OT and MMD complete.},
  archivePrefix = {arXiv},
  eprint = {1810.02733},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Genevay et al (2019) - Sample Complexity of Sinkhorn divergences.pdf},
  journal = {arXiv:1810.02733 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{genovese2004stochastic,
  title = {A Stochastic Process Approach to False Discovery Control},
  author = {Genovese, Christopher and Wasserman, Larry},
  year = {2004},
  month = jun,
  volume = {32},
  pages = {1035--1061},
  issn = {0090-5364},
  doi = {10.1214/009053604000000283},
  abstract = {This paper extends the theory of false discovery rates (FDR) pioneered by Benjamini and Hochberg [J. Roy. Statist. Soc. Ser. B 57 (1995) 289-300]. We develop a framework in which the False Discovery Proportion (FDP)--the number of false rejections divided by the number of rejections--is treated as a stochastic process. After obtaining the limiting distribution of the process, we demonstrate the validity of a class of procedures for controlling the False Discovery Rate (the expected FDP). We construct a confidence envelope for the whole FDP process. From these envelopes we derive confidence thresholds, for controlling the quantiles of the distribution of the FDP as well as controlling the number of false discoveries. We also investigate methods for estimating the p-value distribution.},
  archivePrefix = {arXiv},
  eprint = {math/0406519},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Genovese, Wasserman (2004) - A stochastic process approach to false discovery control.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory},
  number = {3}
}

@article{gerard2017Unifying,
  title = {Unifying and {{Generalizing Methods}} for {{Removing Unwanted Variation Based}} on {{Negative Controls}}},
  author = {Gerard, David and Stephens, Matthew},
  year = {2017},
  month = may,
  abstract = {Unwanted variation, including hidden confounding, is a well-known problem in many fields, particularly large-scale gene expression studies. Recent proposals to use control genes --- genes assumed to be unassociated with the covariates of interest --- have led to new methods to deal with this problem. Going by the moniker Removing Unwanted Variation (RUV), there are many versions --- RUV1, RUV2, RUV4, RUVinv, RUVrinv, RUVfun. In this paper, we introduce a general framework, RUV*, that both unites and generalizes these approaches. This unifying framework helps clarify connections between existing methods. In particular we provide conditions under which RUV2 and RUV4 are equivalent. The RUV* framework also preserves an advantage of RUV approaches --- their modularity --- which facilitates the development of novel methods based on existing matrix imputation algorithms. We illustrate this by implementing RUVB, a version of RUV* based on Bayesian factor analysis. In realistic simulations based on real data we found that RUVB is competitive with existing methods in terms of both power and calibration, although we also highlight the challenges of providing consistently reliable calibration among data sets.},
  archivePrefix = {arXiv},
  eprint = {1705.08393},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gerard, Stephens (2017) - Unifying and Generalizing Methods for Removing Unwanted Variation Based on.pdf},
  journal = {arXiv:1705.08393 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{germain2016PACBayesian,
  title = {{{PAC}}-{{Bayesian Theorems}} for {{Domain Adaptation}} with {{Specialization}} to {{Linear Classifiers}}},
  author = {Germain, Pascal and Habrard, Amaury and Laviolette, Fran{\c c}ois and Morvant, Emilie},
  year = {2016},
  month = aug,
  abstract = {In this paper, we provide two main contributions in PAC-Bayesian theory for domain adaptation where the objective is to learn, from a source distribution, a well-performing majority vote on a different target distribution. On the one hand, we propose an improvement of the previous approach proposed by Germain et al. (2013), that relies on a novel distribution pseudodistance based on a disagreement averaging, allowing us to derive a new tighter PAC-Bayesian domain adaptation bound for the stochastic Gibbs classifier. We specialize it to linear classifiers, and design a learning algorithm which shows interesting results on a synthetic problem and on a popular sentiment annotation task. On the other hand, we generalize these results to multisource domain adaptation allowing us to take into account different source domains. This study opens the door to tackle domain adaptation tasks by making use of all the PAC-Bayesian tools.},
  archivePrefix = {arXiv},
  eprint = {1503.06944},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Germain et al (2016) - PAC-Bayesian Theorems for Domain Adaptation with Specialization to Linear.pdf},
  journal = {arXiv:1503.06944 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{ghadimi2013Stochastic,
  title = {Stochastic {{First}}- and {{Zeroth}}-Order {{Methods}} for {{Nonconvex Stochastic Programming}}},
  author = {Ghadimi, Saeed and Lan, Guanghui},
  year = {2013},
  month = sep,
  abstract = {In this paper, we introduce a new stochastic approximation (SA) type algorithm, namely the randomized stochastic gradient (RSG) method, for solving an important class of nonlinear (possibly nonconvex) stochastic programming (SP) problems. We establish the complexity of this method for computing an approximate stationary point of a nonlinear programming problem. We also show that this method possesses a nearly optimal rate of convergence if the problem is convex. We discuss a variant of the algorithm which consists of applying a post-optimization phase to evaluate a short list of solutions generated by several independent runs of the RSG method, and show that such modification allows to improve significantly the large-deviation properties of the algorithm. These methods are then specialized for solving a class of simulation-based optimization problems in which only stochastic zeroth-order information is available.},
  archivePrefix = {arXiv},
  eprint = {1309.5549},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ghadimi, Lan (2013) - Stochastic First- and Zeroth-order Methods for Nonconvex Stochastic Programming.pdf},
  journal = {arXiv:1309.5549 [cs, math, stat]},
  keywords = {Computer Science - Computational Complexity,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{ghili2018Eliminating,
  title = {Eliminating {{Latent Discrimination}}: {{Train Then Mask}}},
  shorttitle = {Eliminating {{Latent Discrimination}}},
  author = {Ghili, Soheil and Kazemi, Ehsan and Karbasi, Amin},
  year = {2018},
  month = nov,
  abstract = {How can we control for latent discrimination in predictive models? How can we provably remove it? Such questions are at the heart of algorithmic fairness and its impacts on society. In this paper, we define a new operational fairness criteria, inspired by the well-understood notion of omitted variable-bias in statistics and econometrics. Our notion of fairness effectively controls for sensitive features and provides diagnostics for deviations from fair decision making. We then establish analytical and algorithmic results about the existence of a fair classifier in the context of supervised learning. Our results readily imply a simple, but rather counter-intuitive, strategy for eliminating latent discrimination. In order to prevent other features proxying for sensitive features, we need to include sensitive features in the training phase, but exclude them in the test/evaluation phase while controlling for their effects. We evaluate the performance of our algorithm on several real-world datasets and show how fairness for these datasets can be improved with a very small loss in accuracy.},
  archivePrefix = {arXiv},
  eprint = {1811.04973},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ghili et al (2018) - Eliminating Latent Discrimination.pdf},
  journal = {arXiv:1811.04973 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{ghosal2019Multivariate,
  title = {Multivariate {{Ranks}} and {{Quantiles}} Using {{Optimal Transportation}} and {{Applications}} to {{Goodness}}-of-Fit {{Testing}}},
  author = {Ghosal, Promit and Sen, Bodhisattva},
  year = {2019},
  month = may,
  abstract = {In this paper we study multivariate ranks and quantiles, defined using the theory of optimal transportation, and build on the work of Chernozhukov et al. (2017) and del Barrio et al. (2018). We study the characterization, computation and properties of the multivariate rank and quantile functions and their empirical counterparts. We derive the uniform consistency of these empirical estimates to their population versions, under certain assumptions. In fact, we prove a Glivenko-Cantelli type theorem that shows the asymptotic stability of the empirical rank map in any direction. We provide easily verifiable sufficient conditions that guarantee the existence of a continuous and invertible population quantile map --- a crucial assumption for our main consistency result. We provide a framework to derive the local uniform rate of convergence of the estimated quantile and ranks functions and explicitly illustrate the technique in a special case. Further, we propose multivariate (nonparametric) goodness-of-fit tests --- a two-sample test and a test for mutual independence --- based on our notion of quantiles and ranks. Asymptotic consistency of these tests are also shown. Additionally, we derive many properties of (sub)-gradients of convex functions and their Legendre-Fenchel duals that may be of independent interest.},
  archivePrefix = {arXiv},
  eprint = {1905.05340},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ghosal, Sen (2019) - Multivariate Ranks and Quantiles using Optimal Transportation and Applications.pdf},
  journal = {arXiv:1905.05340 [math, stat]},
  keywords = {Mathematics - Probability,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{ghosh2019Landmark,
  title = {Landmark {{Ordinal Embedding}}},
  author = {Ghosh, Nikhil and Chen, Yuxin and Yue, Yisong},
  year = {2019},
  month = oct,
  abstract = {In this paper, we aim to learn a low-dimensional Euclidean representation from a set of constraints of the form "item j is closer to item i than item k". Existing approaches for this "ordinal embedding" problem require expensive optimization procedures, which cannot scale to handle increasingly larger datasets. To address this issue, we propose a landmark-based strategy, which we call Landmark Ordinal Embedding (LOE). Our approach trades off statistical efficiency for computational efficiency by exploiting the low-dimensionality of the latent embedding. We derive bounds establishing the statistical consistency of LOE under the popular Bradley-Terry-Luce noise model. Through a rigorous analysis of the computational complexity, we show that LOE is significantly more efficient than conventional ordinal embedding approaches as the number of items grows. We validate these characterizations empirically on both synthetic and real datasets. We also present a practical approach that achieves the "best of both worlds", by using LOE to warm-start existing methods that are more statistically efficient but computationally expensive.},
  archivePrefix = {arXiv},
  eprint = {1910.12379},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ghosh et al (2019) - Landmark Ordinal Embedding.pdf},
  journal = {arXiv:1910.12379 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{gidel2018Variational,
  title = {A {{Variational Inequality Perspective}} on {{Generative Adversarial Networks}}},
  author = {Gidel, Gauthier and Berard, Hugo and Vignoud, Ga{\"e}tan and Vincent, Pascal and {Lacoste-Julien}, Simon},
  year = {2018},
  month = feb,
  abstract = {Generative adversarial networks (GANs) form a generative modeling approach known for producing appealing samples, but they are notably difficult to train. One common way to tackle this issue has been to propose new formulations of the GAN objective. Yet, surprisingly few studies have looked at optimization methods designed for this adversarial training. In this work, we cast GAN optimization problems in the general variational inequality framework. Tapping into the mathematical programming literature, we counter some common misconceptions about the difficulties of saddle point optimization and propose to extend techniques designed for variational inequalities to the training of GANs. We apply averaging, extrapolation and a computationally cheaper variant that we call extrapolation from the past to the stochastic gradient method (SGD) and Adam.},
  archivePrefix = {arXiv},
  eprint = {1802.10551},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gidel et al (2018) - A Variational Inequality Perspective on Generative Adversarial Networks.pdf},
  journal = {arXiv:1802.10551 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{gillen2018Online,
  title = {Online {{Learning}} with an {{Unknown Fairness Metric}}},
  author = {Gillen, Stephen and Jung, Christopher and Kearns, Michael and Roth, Aaron},
  year = {2018},
  month = feb,
  abstract = {We consider the problem of online learning in the linear contextual bandits setting, but in which there are also strong individual fairness constraints governed by an unknown similarity metric. These constraints demand that we select similar actions or individuals with approximately equal probability (arXiv:1104.3913), which may be at odds with optimizing reward, thus modeling settings where profit and social policy are in tension. We assume we learn about an unknown Mahalanobis similarity metric from only weak feedback that identifies fairness violations, but does not quantify their extent. This is intended to represent the interventions of a regulator who "knows unfairness when he sees it" but nevertheless cannot enunciate a quantitative fairness metric over individuals. Our main result is an algorithm in the adversarial context setting that has a number of fairness violations that depends only logarithmically on \$T\$, while obtaining an optimal \$O(\textbackslash sqrt\{T\})\$ regret bound to the best fair policy.},
  archivePrefix = {arXiv},
  eprint = {1802.06936},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gillen et al (2018) - Online Learning with an Unknown Fairness Metric.pdf},
  journal = {arXiv:1802.06936 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{gillis2014Fast,
  title = {Fast and {{Robust Recursive Algorithms}} for {{Separable Nonnegative Matrix Factorization}}},
  author = {Gillis, Nicolas and Vavasis, Stephen A.},
  year = {2014},
  month = apr,
  volume = {36},
  pages = {698--714},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2013.226},
  abstract = {In this paper, we study the nonnegative matrix factorization problem under the separability assumption (that is, there exists a cone spanned by a small subset of the columns of the input nonnegative data matrix containing all columns), which is equivalent to the hyperspectral unmixing problem under the linear mixing model and the pure-pixel assumption. We present a family of fast recursive algorithms, and prove they are robust under any small perturbations of the input data matrix. This family generalizes several existing hyperspectral unmixing algorithms and hence provides for the first time a theoretical justification of their better practical performance.},
  archivePrefix = {arXiv},
  eprint = {1208.1237},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gillis, Vavasis (2014) - Fast and Robust Recursive Algorithms for Separable Nonnegative Matrix.pdf},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  number = {4}
}

@article{gilmer2018Adversarial,
  title = {Adversarial {{Spheres}}},
  author = {Gilmer, Justin and Metz, Luke and Faghri, Fartash and Schoenholz, Samuel S. and Raghu, Maithra and Wattenberg, Martin and Goodfellow, Ian},
  year = {2018},
  month = jan,
  abstract = {State of the art computer vision models have been shown to be vulnerable to small adversarial perturbations of the input. In other words, most images in the data distribution are both correctly classified by the model and are very close to a visually similar misclassified image. Despite substantial research interest, the cause of the phenomenon is still poorly understood and remains unsolved. We hypothesize that this counter intuitive behavior is a naturally occurring result of the high dimensional geometry of the data manifold. As a first step towards exploring this hypothesis, we study a simple synthetic dataset of classifying between two concentric high dimensional spheres. For this dataset we show a fundamental tradeoff between the amount of test error and the average distance to nearest error. In particular, we prove that any model which misclassifies a small constant fraction of a sphere will be vulnerable to adversarial perturbations of size \$O(1/\textbackslash sqrt\{d\})\$. Surprisingly, when we train several different architectures on this dataset, all of their error sets naturally approach this theoretical bound. As a result of the theory, the vulnerability of neural networks to small adversarial perturbations is a logical consequence of the amount of test error observed. We hope that our theoretical analysis of this very simple case will point the way forward to explore how the geometry of complex real-world data sets leads to adversarial examples.},
  archivePrefix = {arXiv},
  eprint = {1801.02774},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gilmer et al (2018) - Adversarial Spheres.pdf},
  journal = {arXiv:1801.02774 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryClass = {cs}
}

@article{gilmer2018Motivating,
  title = {Motivating the {{Rules}} of the {{Game}} for {{Adversarial Example Research}}},
  author = {Gilmer, Justin and Adams, Ryan P. and Goodfellow, Ian and Andersen, David and Dahl, George E.},
  year = {2018},
  month = jul,
  abstract = {Advances in machine learning have led to broad deployment of systems with impressive performance on important problems. Nonetheless, these systems can be induced to make errors on data that are surprisingly similar to examples the learned system handles correctly. The existence of these errors raises a variety of questions about out-of-sample generalization and whether bad actors might use such examples to abuse deployed systems. As a result of these security concerns, there has been a flurry of recent papers proposing algorithms to defend against such malicious perturbations of correctly handled examples. It is unclear how such misclassifications represent a different kind of security problem than other errors, or even other attacker-produced examples that have no specific relationship to an uncorrupted input. In this paper, we argue that adversarial example defense papers have, to date, mostly considered abstract, toy games that do not relate to any specific security concern. Furthermore, defense papers have not yet precisely described all the abilities and limitations of attackers that would be relevant in practical security. Towards this end, we establish a taxonomy of motivations, constraints, and abilities for more plausible adversaries. Finally, we provide a series of recommendations outlining a path forward for future work to more clearly articulate the threat model and perform more meaningful evaluation.},
  archivePrefix = {arXiv},
  eprint = {1807.06732},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gilmer et al (2018) - Motivating the Rules of the Game for Adversarial Example Research.pdf},
  journal = {arXiv:1807.06732 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{gilpin2018Explaining,
  title = {Explaining {{Explanations}}: {{An Overview}} of {{Interpretability}} of {{Machine Learning}}},
  shorttitle = {Explaining {{Explanations}}},
  author = {Gilpin, Leilani H. and Bau, David and Yuan, Ben Z. and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
  year = {2018},
  month = may,
  abstract = {There has recently been a surge of work in explanatory artificial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we provide our definition of explainability and show how it can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufficient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artificial intelligence.},
  archivePrefix = {arXiv},
  eprint = {1806.00069},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gilpin et al (2018) - Explaining Explanations.pdf},
  journal = {arXiv:1806.00069 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{gimenez2019Improving,
  title = {Improving the {{Stability}} of the {{Knockoff Procedure}}: {{Multiple Simultaneous Knockoffs}} and {{Entropy Maximization}}},
  shorttitle = {Improving the {{Stability}} of the {{Knockoff Procedure}}},
  author = {Gimenez, Jaime Roquero and Zou, James},
  year = {2019},
  month = may,
  abstract = {The Model-X knockoff procedure has recently emerged as a powerful approach for feature selection with statistical guarantees. The advantage of knockoff is that if we have a good model of the features X, then we can identify salient features without knowing anything about how the outcome Y depends on X. An important drawback of knockoffs is its instability: running the procedure twice can result in very different selected features, potentially leading to different conclusions. Addressing this instability is critical for obtaining reproducible and robust results. Here we present a generalization of the knockoff procedure that we call simultaneous multi-knockoffs. We show that multi-knockoff guarantees false discovery rate (FDR) control, and is substantially more stable and powerful compared to the standard (single) knockoff. Moreover we propose a new algorithm based on entropy maximization for generating Gaussian multi-knockoffs. We validate the improved stability and power of multi-knockoffs in systematic experiments. We also illustrate how multi-knockoffs can improve the accuracy of detecting genetic mutations that are causally linked to phenotypes.},
  archivePrefix = {arXiv},
  eprint = {1810.11378},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gimenez, Zou (2019) - Improving the Stability of the Knockoff Procedure.pdf},
  journal = {arXiv:1810.11378 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@book{gine2016Mathematical,
  title = {Mathematical {{Foundations}} of {{Infinite}}-{{Dimensional Statistical Models}}},
  author = {Gine, Evarist and Nickl, Richard},
  year = {2016},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9781107337862},
  file = {/Users/yuekai/Documents/zotero/Gine, Nickl (2016) - Mathematical Foundations of Infinite-Dimensional Statistical Models.pdf},
  isbn = {978-1-107-33786-2},
  language = {en}
}

@article{goh2010Distributionally,
  title = {Distributionally {{Robust Optimization}} and {{Its Tractable Approximations}}},
  author = {Goh, Joel and Sim, Melvyn},
  year = {2010},
  month = aug,
  volume = {58},
  pages = {902--917},
  issn = {0030-364X, 1526-5463},
  doi = {10.1287/opre.1090.0795},
  abstract = {In this paper, we focus on a linear optimization problem with uncertainties, having expectations in the objective and in the set of constraints. We present a modular framework to obtain an approximate solution to the problem that is distributionally robust, and more flexible than the standard technique of using linear rules. Our framework begins by firstly affinely-extending the set of primitive uncertainties to generate new linear decision rules of larger dimensions, and are therefore more flexible. Next, we develop new piecewise-linear decision rules which allow a more flexible re-formulation of the original problem. The reformulated problem will generally contain terms with expectations on the positive parts of the recourse variables. Finally, we convert the uncertain linear program into a deterministic convex program by constructing distributionally robust bounds on these expectations. These bounds are constructed by first using different pieces of information on the distribution of the underlying uncertainties to develop separate bounds, and next integrating them into a combined bound that is better than each of the individual bounds.},
  file = {/Users/yuekai/Documents/zotero/Goh, Sim (2010) - Distributionally Robust Optimization and Its Tractable Approximations.pdf},
  journal = {Operations Research},
  language = {en},
  number = {4-part-1}
}

@article{goldblum2020Unraveling,
  title = {Unraveling {{Meta}}-{{Learning}}: {{Understanding Feature Representations}} for {{Few}}-{{Shot Tasks}}},
  shorttitle = {Unraveling {{Meta}}-{{Learning}}},
  author = {Goldblum, Micah and Reich, Steven and Fowl, Liam and Ni, Renkun and Cherepanova, Valeriia and Goldstein, Tom},
  year = {2020},
  month = jul,
  abstract = {Meta-learning algorithms produce feature extractors which achieve state-of-the-art performance on few-shot classification. While the literature is rich with meta-learning methods, little is known about why the resulting feature extractors perform so well. We develop a better understanding of the underlying mechanics of meta-learning and the difference between models trained using meta-learning and models which are trained classically. In doing so, we introduce and verify several hypotheses for why meta-learned models perform better. Furthermore, we develop a regularizer which boosts the performance of standard training routines for few-shot classification. In many cases, our routine outperforms meta-learning while simultaneously running an order of magnitude faster.},
  archivePrefix = {arXiv},
  eprint = {2002.06753},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Goldblum et al (2020) - Unraveling Meta-Learning.pdf;/Users/yuekai/Zotero/storage/GMVRNASZ/2002.html},
  journal = {arXiv:2002.06753 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{goldfeld2020GaussianSmooth,
  title = {Gaussian-{{Smooth Optimal Transport}}: {{Metric Structure}} and {{Statistical Efficiency}}},
  shorttitle = {Gaussian-{{Smooth Optimal Transport}}},
  author = {Goldfeld, Ziv and Greenewald, Kristjan},
  year = {2020},
  month = jan,
  abstract = {Optimal transport (OT), and in particular the Wasserstein distance, has seen a surge of interest and applications in machine learning. However, empirical approximation under Wasserstein distances suffers from a severe curse of dimensionality, rendering them impractical in high dimensions. As a result, entropically regularized OT has become a popular workaround. However, while it enjoys fast algorithms and better statistical properties, it looses the metric structure that Wasserstein distances enjoy. This work proposes a novel Gaussian-smoothed OT (GOT) framework, that achieves the best of both worlds: preserving the 1-Wasserstein metric structure while alleviating the empirical approximation curse of dimensionality. Furthermore, as the Gaussian-smoothing parameter shrinks to zero, GOT \$\textbackslash Gamma\$-converges towards classic OT (with convergence of optimizers), thus serving as a natural extension. An empirical study that supports the theoretical results is provided, promoting Gaussian-smoothed OT as a powerful alternative to entropic OT.},
  archivePrefix = {arXiv},
  eprint = {2001.09206},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Goldfeld, Greenewald (2020) - Gaussian-Smooth Optimal Transport.pdf},
  journal = {arXiv:2001.09206 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{goldfeld2020Limit,
  title = {Limit {{Distribution Theory}} for {{Smooth Wasserstein Distance}} with {{Applications}} to {{Generative Modeling}}},
  author = {Goldfeld, Ziv and Kato, Kengo},
  year = {2020},
  month = feb,
  abstract = {The 1-Wasserstein distance (\$\textbackslash mathsf\{W\}\_1\$) is a popular proximity measure between probability distributions. Its metric structure, robustness to support mismatch, and rich geometric structure fueled its wide adoption for machine learning tasks. Such tasks inherently rely on approximating distributions from data. This surfaces a central issue -- empirical approximation under Wasserstein distances suffers from the curse of dimensionality, converging at rate \$n\^\{-1/d\}\$ where \$n\$ is the sample size and \$d\$ is the data dimension; this rate drastically deteriorates in high dimensions. To circumvent this impasse, we adopt the framework of Gaussian smoothed Wasserstein distance \$\textbackslash mathsf\{W\}\_1\^\{(\textbackslash sigma)\}\$, where both probability measures are convolved with an isotropic Gaussian distribution of parameter \$\textbackslash sigma {$>$} 0\$. In remarkable contrast to classic \$\textbackslash mathsf\{W\}\_1\$, the empirical convergence rate under \$\textbackslash mathsf\{W\}\_1\^\{(\textbackslash sigma)\}\$ is \$n\^\{-1/2\}\$ in all dimensions. Inspired by this fact, the present paper conducts an in-depth study of the statistical properties of the smooth Wasserstein distance. We derive the limit distribution of \$\textbackslash sqrt\{n\}\textbackslash mathsf\{W\}\_1\^\{(\textbackslash sigma)\}(P\_n,P)\$ for all \$d\$, where \$P\_n\$ is the empirical measure of \$n\$ independent observations from \$P\$. In arbitrary dimension, the limit is characterized as the supremum of a tight Gaussian process indexed by 1-Lipschitz functions convolved with a Gaussian density. Building on this result we derive concentration inequalities, bootstrap consistency, and explore generative modeling with \$\textbackslash mathsf\{W\}\_1\^\{(\textbackslash sigma)\}\$ under the minimum distance estimation framework. For the latter, we derive measurability, almost sure convergence, and limit distributions for optimal generative models and their corresponding smooth Wasserstein error. These results promote the smooth Wasserstein distance as a powerful tool for statistical inference in high dimensions.},
  archivePrefix = {arXiv},
  eprint = {2002.01012},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Goldfeld, Kato (2020) - Limit Distribution Theory for Smooth Wasserstein Distance with Applications to.pdf},
  journal = {arXiv:2002.01012 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@book{golub1996Matrix,
  title = {Matrix {{Computations}}},
  author = {Golub, Gene H. and Loan, Charles F. Van},
  year = {1996},
  month = oct,
  edition = {3rd edition},
  publisher = {{Johns Hopkins University Press}},
  address = {{Baltimore}},
  abstract = {Revised and updated, the third edition of Golub and Van Loan's classic text in computer science provides essential information about the mathematical background and algorithmic skills required for the production of numerical software. This new edition includes thoroughly revised chapters on matrix multiplication problems and parallel matrix computations, expanded treatment of CS decomposition, an updated overview of floating point arithmetic, a more accurate rendition of the modified Gram-Schmidt process, and new material devoted to GMRES, QMR, and other methods designed to handle the sparse unsymmetric linear system problem.},
  file = {/Users/yuekai/Documents/zotero/Golub, Loan (1996) - Matrix Computations.pdf},
  isbn = {978-0-8018-5414-9},
  language = {English}
}

@article{gomez-rodriguez2012Inferring,
  title = {Inferring {{Networks}} of {{Diffusion}} and {{Influence}}},
  author = {{Gomez-Rodriguez}, Manuel and Leskovec, Jure and Krause, Andreas},
  year = {2012},
  month = feb,
  volume = {5},
  pages = {1--37},
  issn = {15564681},
  doi = {10.1145/2086737.2086741},
  file = {/Users/yuekai/Documents/zotero/Gomez-Rodriguez et al (2012) - Inferring Networks of Diffusion and Influence.pdf},
  journal = {ACM Transactions on Knowledge Discovery from Data},
  language = {en},
  number = {4}
}

@article{gonen2019Lipstick,
  title = {Lipstick on a {{Pig}}: {{Debiasing Methods Cover}} up {{Systematic Gender Biases}} in {{Word Embeddings But}} Do Not {{Remove Them}}},
  shorttitle = {Lipstick on a {{Pig}}},
  author = {Gonen, Hila and Goldberg, Yoav},
  year = {2019},
  month = mar,
  abstract = {Word embeddings are widely used in NLP for a vast range of tasks. It was shown that word embeddings derived from text corpora reflect gender biases in society. This phenomenon is pervasive and consistent across different word embedding models, causing serious concern. Several recent works tackle this problem, and propose methods for significantly reducing this gender bias in word embeddings, demonstrating convincing results. However, we argue that this removal is superficial. While the bias is indeed substantially reduced according to the provided bias definition, the actual effect is mostly hiding the bias, not removing it. The gender bias information is still reflected in the distances between "gender-neutralized" words in the debiased embeddings, and can be recovered from them. We present a series of experiments to support this claim, for two debiasing methods. We conclude that existing bias removal techniques are insufficient, and should not be trusted for providing gender-neutral modeling.},
  archivePrefix = {arXiv},
  eprint = {1903.03862},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gonen, Goldberg (2019) - Lipstick on a Pig.pdf},
  journal = {arXiv:1903.03862 [cs]},
  keywords = {Computer Science - Computation and Language},
  primaryClass = {cs}
}

@inproceedings{gong2016Domain,
  title = {Domain {{Adaptation}} with {{Conditional Transferable Components}}},
  booktitle = {Proceedings of {{Machine Learning Research}}},
  author = {Gong, Mingming and Zhang, Kun and Liu, Tongliang and Tao, Dacheng and Glymour, Clark and Scholkopf, Bernhard},
  year = {2016},
  month = jun,
  volume = {48},
  pages = {17},
  address = {{New York, New York, USA}},
  abstract = {Domain adaptation arises in supervised learning when the training (source domain) and test (target domain) data have different distributions. Let X and Y denote the features and target, respectively, previous work on domain adaptation mainly considers the covariate shift situation where the distribution of the features P (X) changes across domains while the conditional distribution P (Y |X) stays the same. To reduce domain discrepancy, recent methods try to find invariant components T (X) that have similar P (T (X)) on different domains by explicitly minimizing a distribution discrepancy measure. However, it is not clear if P (Y |T (X)) in different domains is also similar when P (Y |X) changes. Furthermore, transferable components do not necessarily have to be invariant. If the change in some components is identifiable, we can make use of such components for prediction in the target domain. In this paper, we focus on the case where P (X|Y ) and P (Y ) both change in a causal system in which Y is the cause for X. Under appropriate assumptions, we aim to extract conditional transferable components whose conditional distribution P (T (X)|Y ) is invariant after proper location-scale (LS) transformations, and identify how P (Y ) changes between domains simultaneously. We provide theoretical analysis and empirical evaluation on both synthetic and real-world data to show the effectiveness of our method.},
  file = {/Users/yuekai/Documents/zotero/Gong et al (2016) - Domain Adaptation with Conditional Transferable Components.pdf},
  language = {en}
}

@article{goodfellow2014Explaining,
  title = {Explaining and {{Harnessing Adversarial Examples}}},
  author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
  year = {2014},
  month = dec,
  abstract = {Several machine learning models, including neural networks, consistently
misclassify adversarial examples---inputs formed by applying small but
intentionally worst-case perturbations to examples from the dataset, such that
the perturbed input results in the model outputting an incorrect answer with
high confidence. Early attempts at explaining this phenomenon focused on
nonlinearity and overfitting. We argue instead that the primary cause of neural
networks' vulnerability to adversarial perturbation is their linear nature.
This explanation is supported by new quantitative results while giving the
first explanation of the most intriguing fact about them: their generalization
across architectures and training sets. Moreover, this view yields a simple and
fast method of generating adversarial examples. Using this approach to provide
examples for adversarial training, we reduce the test set error of a maxout
network on the MNIST dataset.},
  file = {/Users/yuekai/Documents/zotero/Goodfellow et al (2014) - Explaining and Harnessing Adversarial Examples.pdf},
  language = {en}
}

@article{goodman2016What,
  title = {What Does Research Reproducibility Mean?},
  author = {Goodman, Steven N. and Fanelli, Daniele and Ioannidis, John P. A.},
  year = {2016},
  month = jun,
  volume = {8},
  pages = {341ps12-341ps12},
  issn = {1946-6234, 1946-6242},
  doi = {10.1126/scitranslmed.aaf5027},
  abstract = {The language and conceptual framework of ``research reproducibility'' are nonstandard and unsettled across the sciences. In this Perspective, we review an array of explicit and implicit definitions of reproducibility and related terminology, and discuss how to avoid potential misunderstandings when these terms are used as a surrogate for ``truth.''
The language and conceptual framework of ``research reproducibility'' are nonstandard and unsettled across the sciences.
The language and conceptual framework of ``research reproducibility'' are nonstandard and unsettled across the sciences.},
  copyright = {Copyright \textcopyright{} 2016, American Association for the Advancement of Science},
  file = {/Users/yuekai/Documents/zotero/Goodman et al (2016) - What does research reproducibility mean.pdf},
  journal = {Science Translational Medicine},
  language = {en},
  number = {341},
  pmid = {27252173}
}

@article{gotze1999Asymptotic,
  title = {Asymptotic {{Distribution}} of {{Quadratic Forms}}},
  author = {G{\"o}tze, F. and Tikhomirov, A. N.},
  year = {1999},
  month = apr,
  volume = {27},
  pages = {1072--1098},
  issn = {0091-1798, 2168-894X},
  doi = {10.1214/aop/1022677395},
  abstract = {We consider quadratic forms Q\_n = \textbackslash sum\_\{1 \textbackslash le j \textbackslash neq k \textbackslash le n\} a\_\{jk\}X\_j X\_k, where XjXjX\_j are i.i.d. random variables with finite third moment. We obtain optimal bounds for the Kolmogorov distance between the distribution of QnQnQ\_n and the distribution of the same quadratic forms with XjXjX\_j replaced by corresponding Gaussian random variables. These bounds are applied to Toeplitz and random matrices as well as to nonstationary AR(1) processes.},
  file = {/Users/yuekai/Documents/zotero/Götze, Tikhomirov (1999) - Asymptotic Distribution of Quadratic Forms.pdf},
  journal = {The Annals of Probability},
  language = {EN},
  mrnumber = {MR1699003},
  number = {2},
  zmnumber = {0941.60049}
}

@article{grant2018Recasting,
  title = {Recasting {{Gradient}}-{{Based Meta}}-{{Learning}} as {{Hierarchical Bayes}}},
  author = {Grant, Erin and Finn, Chelsea and Levine, Sergey and Darrell, Trevor and Griffiths, Thomas},
  year = {2018},
  month = jan,
  abstract = {Meta-learning allows an intelligent agent to leverage prior learning episodes as a basis for quickly improving performance on a novel task. Bayesian hierarchical modeling provides a theoretical framework for formalizing meta-learning as inference for a set of parameters that are shared across tasks. Here, we reformulate the model-agnostic meta-learning algorithm (MAML) of Finn et al. (2017) as a method for probabilistic inference in a hierarchical Bayesian model. In contrast to prior methods for meta-learning via hierarchical Bayes, MAML is naturally applicable to complex function approximators through its use of a scalable gradient descent procedure for posterior inference. Furthermore, the identification of MAML as hierarchical Bayes provides a way to understand the algorithm's operation as a meta-learning procedure, as well as an opportunity to make use of computational strategies for efficient inference. We use this opportunity to propose an improvement to the MAML algorithm that makes use of techniques from approximate inference and curvature estimation.},
  archivePrefix = {arXiv},
  eprint = {1801.08930},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Grant et al (2018) - Recasting Gradient-Based Meta-Learning as Hierarchical Bayes.pdf},
  journal = {arXiv:1801.08930 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{grari2019Fair,
  title = {Fair {{Adversarial Gradient Tree Boosting}}},
  author = {Grari, Vincent and Ruf, Boris and Lamprier, Sylvain and Detyniecki, Marcin},
  year = {2019},
  month = nov,
  abstract = {Fair classification has become an important topic in machine learning research. While most bias mitigation strategies focus on neural networks, we noticed a lack of work on fair classifiers based on decision trees even though they have proven very efficient. In an up-to-date comparison of state-of-the-art classification algorithms in tabular data, tree boosting outperforms deep learning. For this reason, we have developed a novel approach of adversarial gradient tree boosting. The objective of the algorithm is to predict the output \$Y\$ with gradient tree boosting while minimizing the ability of an adversarial neural network to predict the sensitive attribute \$S\$. The approach incorporates at each iteration the gradient of the neural network directly in the gradient tree boosting. We empirically assess our approach on 4 popular data sets and compare against state-of-the-art algorithms. The results show that our algorithm achieves a higher accuracy while obtaining the same level of fairness, as measured using a set of different common fairness definitions.},
  archivePrefix = {arXiv},
  eprint = {1911.05369},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Grari et al (2019) - Fair Adversarial Gradient Tree Boosting.pdf},
  journal = {arXiv:1911.05369 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{grari2019FairnessAware,
  title = {Fairness-{{Aware Neural R}}\textbackslash 'eyni {{Minimization}} for {{Continuous Features}}},
  author = {Grari, Vincent and Ruf, Boris and Lamprier, Sylvain and Detyniecki, Marcin},
  year = {2019},
  month = nov,
  abstract = {The past few years have seen a dramatic rise of academic and societal interest in fair machine learning. While plenty of fair algorithms have been proposed recently to tackle this challenge for discrete variables, only a few ideas exist for continuous ones. The objective in this paper is to ensure some independence level between the outputs of regression models and any given continuous sensitive variables. For this purpose, we use the Hirschfeld-Gebelein-R\textbackslash 'enyi (HGR) maximal correlation coefficient as a fairness metric. We propose two approaches to minimize the HGR coefficient. First, by reducing an upper bound of the HGR with a neural network estimation of the \$\textbackslash chi\^\{2\}\$ divergence. Second, by minimizing the HGR directly with an adversarial neural network architecture. The idea is to predict the output Y while minimizing the ability of an adversarial neural network to find the estimated transformations which are required to predict the HGR coefficient. We empirically assess and compare our approaches and demonstrate significant improvements on previously presented work in the field.},
  archivePrefix = {arXiv},
  eprint = {1911.04929},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Grari et al (2019) - Fairness-Aware Neural R-'eyni Minimization for Continuous Features.pdf},
  journal = {arXiv:1911.04929 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{grathwohl2018FFJORD,
  title = {{{FFJORD}}: {{Free}}-Form {{Continuous Dynamics}} for {{Scalable Reversible Generative Models}}},
  shorttitle = {{{FFJORD}}},
  author = {Grathwohl, Will and Chen, Ricky T. Q. and Bettencourt, Jesse and Sutskever, Ilya and Duvenaud, David},
  year = {2018},
  month = oct,
  abstract = {A promising class of generative models maps points from a simple distribution to a complex distribution through an invertible neural network. Likelihood-based training of these models requires restricting their architectures to allow cheap computation of Jacobian determinants. Alternatively, the Jacobian trace can be used if the transformation is specified by an ordinary differential equation. In this paper, we use Hutchinson's trace estimator to give a scalable unbiased estimate of the log-density. The result is a continuous-time invertible generative model with unbiased density estimation and one-pass sampling, while allowing unrestricted neural network architectures. We demonstrate our approach on high-dimensional density estimation, image generation, and variational inference, achieving the state-of-the-art among exact likelihood methods with efficient sampling.},
  archivePrefix = {arXiv},
  eprint = {1810.01367},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Grathwohl et al (2018) - FFJORD.pdf},
  journal = {arXiv:1810.01367 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{grathwohl2019Your,
  title = {Your Classifier Is Secretly an Energy Based Model and You Should Treat It like One},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Grathwohl, Will and Wang, Kuan-Chieh and Jacobsen, Joern-Henrik and Duvenaud, David and Norouzi, Mohammad and Swersky, Kevin},
  year = {2019},
  month = sep,
  abstract = {We propose to reinterpret a standard discriminative classifier of p(y|x) as an energy based model for the joint distribution p(x, y). In this setting, the standard class probabilities can be easily...},
  file = {/Users/yuekai/Documents/zotero/Grathwohl et al (2019) - Your classifier is secretly an energy based model and you should treat it like.pdf}
}

@article{greenwald1998Measuring,
  title = {Measuring {{Individual Differences}} in {{Implicit Cognition}}: {{The Implicit Association Test}}},
  author = {Greenwald, Anthony G and McGhee, Debbie E and Schwartz, Jordan L K},
  year = {1998},
  volume = {74},
  pages = {17},
  file = {/Users/yuekai/Documents/zotero/Greenwald et al (1998) - Measuring Individual Differences in Implicit Cognition.pdf},
  journal = {Journal of Personality and Soclal Psychology},
  language = {en},
  number = {6}
}

@incollection{gretton2005Measuring,
  title = {Measuring {{Statistical Dependence}} with {{Hilbert}}-{{Schmidt Norms}}},
  booktitle = {Algorithmic {{Learning Theory}}},
  author = {Gretton, Arthur and Bousquet, Olivier and Smola, Alex and Sch{\"o}lkopf, Bernhard},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Jain, Sanjay and Simon, Hans Ulrich and Tomita, Etsuji},
  year = {2005},
  volume = {3734},
  pages = {63--77},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/11564089_7},
  abstract = {We propose an independence criterion based on the eigenspectrum of covariance operators in reproducing kernel Hilbert spaces (RKHSs), consisting of an empirical estimate of the Hilbert-Schmidt norm of the cross-covariance operator (we term this a Hilbert-Schmidt Independence Criterion, or HSIC). This approach has several advantages, compared with previous kernel-based independence criteria. First, the empirical estimate is simpler than any other kernel dependence test, and requires no user-defined regularisation. Second, there is a clearly defined population quantity which the empirical estimate approaches in the large sample limit, with exponential convergence guaranteed between the two: this ensures that independence tests based on HSIC do not suffer from slow learning rates. Finally, we show in the context of independent component analysis (ICA) that the performance of HSIC is competitive with that of previously published kernel-based criteria, and of other recently published ICA methods.},
  file = {/Users/yuekai/Documents/zotero/Gretton et al (2005) - Measuring Statistical Dependence with Hilbert-Schmidt Norms.pdf},
  isbn = {978-3-540-29242-5 978-3-540-31696-1},
  language = {en}
}

@inproceedings{grgic-hlaca2018Human,
  title = {Human {{Perceptions}} of {{Fairness}} in {{Algorithmic Decision Making}}: {{A Case Study}} of {{Criminal Risk Prediction}}},
  shorttitle = {Human {{Perceptions}} of {{Fairness}} in {{Algorithmic Decision Making}}},
  booktitle = {Proceedings of the 2018 {{World Wide Web Conference}}},
  author = {{Grgic-Hlaca}, Nina and Redmiles, Elissa M. and Gummadi, Krishna P. and Weller, Adrian},
  year = {2018},
  month = apr,
  pages = {903--912},
  publisher = {{International World Wide Web Conferences Steering Committee}},
  address = {{Lyon, France}},
  doi = {10.1145/3178876.3186138},
  abstract = {As algorithms are increasingly used to make important decisions that affect human lives, ranging from social benefit assignment to predicting risk of criminal recidivism, concerns have been raised about the fairness of algorithmic decision making. Most prior works on algorithmic fairness normatively prescribe how fair decisions ought to be made. In contrast, here, we descriptively survey users for how they perceive and reason about fairness in algorithmic decision making. A key contribution of this work is the framework we propose to understand why people perceive certain features as fair or unfair to be used in algorithms. Our framework identifies eight properties of features, such as relevance, volitionality and reliability, as latent considerations that inform people\guillemotright s moral judgments about the fairness of feature use in decision-making algorithms. We validate our framework through a series of scenario-based surveys with 576 people. We find that, based on a person\guillemotright s assessment of the eight latent properties of a feature in our exemplar scenario, we can accurately ({$>$} 85\%) predict if the person will judge the use of the feature as fair. Our findings have important implications. At a high-level, we show that people\guillemotright s unfairness concerns are multi-dimensional and argue that future studies need to address unfairness concerns beyond discrimination. At a low-level, we find considerable disagreements in people\guillemotright s fairness judgments. We identify root causes of the disagreements, and note possible pathways to resolve them.},
  isbn = {978-1-4503-5639-8},
  series = {{{WWW}} '18}
}

@book{groeneboom1992Information,
  title = {Information {{Bounds}} and {{Nonparametric Maximum Likelihood Estimation}}},
  author = {Groeneboom, Piet and Wellner, Jon A.},
  year = {1992},
  publisher = {{Birkh\"auser Basel}},
  address = {{Basel}},
  doi = {10.1007/978-3-0348-8621-5},
  file = {/Users/yuekai/Documents/zotero/Groeneboom, Wellner (1992) - Information Bounds and Nonparametric Maximum Likelihood Estimation.pdf},
  isbn = {978-3-7643-2794-1 978-3-0348-8621-5},
  language = {en}
}

@article{groeneboom2016Current,
  title = {Current Status Linear Regression},
  author = {Groeneboom, Piet and Hendrickx, Kim},
  year = {2016},
  month = jan,
  abstract = {We construct \$\textbackslash sqrt\{n\}\$-consistent and asymptotically normal estimates for the finite dimensional regression parameter in the current status linear regression model, which do not require any smoothing device and are based on maximum likelihood estimates (MLEs) of the infinite dimensional parameter. We also construct estimates, again only based on these MLEs, which are arbitrarily close to efficient estimates, if the generalized Fisher information is finite. This type of efficiency is also derived under minimal conditions for estimates based on smooth non-monotone plug-in estimates of the distribution function. Algorithms for computing the estimates and for selecting the bandwidth of the smooth estimates with a bootstrap method are provided. The connection with results in the econometric literature is also pointed out.},
  archivePrefix = {arXiv},
  eprint = {1601.00202},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Groeneboom, Hendrickx (2016) - Current status linear regression.pdf},
  journal = {arXiv:1601.00202 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{groeneboom2018Lagrange,
  title = {The {{Lagrange}} Approach in the Monotone Single Index Model},
  author = {Groeneboom, Piet},
  year = {2018},
  month = dec,
  abstract = {The finite-dimensional parameters of the monotone single index model are often estimated by minimization of a least squares criterion and reparametrization to deal with the non-unicity. We avoid the reparametrization by using a Lagrange-type method and replace the minimization over the finite-dimensional parameter alpha by a `crossing of zero' criterion at the derivative level. In particular, we consider a simple score estimator (SSE), an efficient score estimator (ESE), and a penalized least squares estimator (PLSE) for which we can apply this method. The SSE and ESE were discussed in Balabdaoui, Groeneboom and Hendrickx (2018\vphantom\{\}, but the proofs still used reparametrization. Another version of the PLSE was discussed in Kuchibhotla and Patra (2017), where also reparametrization was used. The estimators are compared with the profile least squares estimator (LSE), Han's maximum rank estimator (MRE), the effective dimension reduction estimator (EDR) and a linear least squares estimator, which can be used if the covariates have an elliptically symmetric distribution. We also investigate the effects of random starting values in the search algorithms.},
  archivePrefix = {arXiv},
  eprint = {1812.01380},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Groeneboom (2018) - The Lagrange approach in the monotone single index model.pdf},
  journal = {arXiv:1812.01380 [stat]},
  keywords = {Statistics - Computation},
  primaryClass = {stat}
}

@article{groeneboom2019Estimation,
  title = {Estimation in Monotone Single-index Models},
  author = {Groeneboom, Piet and Hendrickx, Kim},
  year = {2019},
  month = feb,
  volume = {73},
  pages = {78--99},
  issn = {0039-0402, 1467-9574},
  doi = {10.1111/stan.12138},
  file = {/Users/yuekai/Documents/zotero/Groeneboom, Hendrickx (2019) - Estimation in monotone single‐index models.pdf},
  journal = {Statistica Neerlandica},
  language = {en},
  number = {1}
}

@article{gross2016Data,
  title = {Data {{Shared Lasso}}: {{A}} Novel Tool to Discover Uplift},
  shorttitle = {Data {{Shared Lasso}}},
  author = {Gross, Samuel M. and Tibshirani, Robert},
  year = {2016},
  month = sep,
  volume = {101},
  pages = {226--235},
  issn = {01679473},
  doi = {10.1016/j.csda.2016.02.015},
  abstract = {A model is presented for the supervised learning problem where the observations come from a fixed number of pre-specified groups, and the regression coefficients may vary sparsely between groups. The model spans the continuum between individual models for each group and one model for all groups. The resulting algorithm is designed with a high dimensional framework in mind. The approach is applied to a sentiment analysis dataset to show its efficacy and interpretability. One particularly useful application is for finding sub-populations in a randomized trial for which an intervention (treatment) is beneficial, often called the uplift problem. Some new concepts are introduced that are useful for uplift analysis. The value is demonstrated in an application to a real world credit card promotion dataset. In this example, although sending the promotion has a very small average effect, by targeting a particular subgroup with the promotion one can obtain a 15\% increase in the proportion of people who purchase the new credit card.},
  file = {/Users/yuekai/Documents/zotero/Gross, Tibshirani (2016) - Data Shared Lasso.pdf},
  journal = {Computational Statistics \& Data Analysis},
  language = {en}
}

@article{guan2019Prediction,
  title = {Prediction and Outlier Detection in Classification Problems},
  author = {Guan, Leying and Tibshirani, Rob},
  year = {2019},
  month = may,
  abstract = {We consider the multi-class classification problem when the training data and the out-of-sample test data may have different distributions and propose a method called BCOPS (balanced and conformal optimized prediction sets). BCOPS constructs a prediction set \$C(x)\$ as a subset of class labels, possibly empty. It tries to optimize the out-of-sample performance, aiming to include the correct class as often as possible, but also detecting outliers \$x\$, for which the method returns no prediction (corresponding to \$C(x)\$ equal to the empty set). The proposed method combines supervised-learning algorithms with the method of conformal prediction to minimize a misclassification loss averaged over the out-of-sample distribution. The constructed prediction sets have a finite-sample coverage guarantee without distributional assumptions. We also propose a method to estimate the outlier detection rate of a given method. We prove asymptotic consistency and optimality of our proposals under suitable assumptions and illustrate our methods on real data examples.},
  archivePrefix = {arXiv},
  eprint = {1905.04396},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Guan, Tibshirani (2019) - Prediction and outlier detection in classification problems.pdf},
  journal = {arXiv:1905.04396 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Applications,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{guha2018Model,
  title = {Model {{Aggregation}} via {{Good}}-{{Enough Model Spaces}}},
  author = {Guha, Neel and Smith, Virginia},
  year = {2018},
  month = may,
  abstract = {In many applications, the training data for a machine learning task is partitioned across multiple nodes, and aggregating this data may be infeasible due to communication, privacy, or storage constraints. Existing distributed optimization methods for learning global models in these settings typically aggregate local updates from each node in an iterative fashion. However, these approaches require many rounds of communication between nodes, and assume that updates can be synchronously shared across a connected network. In this work, we present Good-Enough Model Spaces (GEMS), a novel framework for learning a global model by carefully intersecting the sets of "good-enough" models across each node. Our approach utilizes minimal communication and does not require sharing of data between nodes. We present methods for learning both convex models and neural networks within this framework and discuss how small samples of held-out data can be used for post-learning fine-tuning. In experiments on image and medical datasets, our approach on average improves upon other baseline aggregation techniques such as ensembling or model averaging by as much as 15 points (accuracy).},
  archivePrefix = {arXiv},
  eprint = {1805.07782},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Guha, Smith (2018) - Model Aggregation via Good-Enough Model Spaces.pdf},
  journal = {arXiv:1805.07782 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{gulrajani2017Improved,
  title = {Improved {{Training}} of {{Wasserstein GANs}}},
  author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron},
  year = {2017},
  month = mar,
  abstract = {Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.},
  archivePrefix = {arXiv},
  eprint = {1704.00028},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gulrajani et al (2017) - Improved Training of Wasserstein GANs.pdf},
  journal = {arXiv:1704.00028 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{gumedze2011Parameter,
  title = {Parameter Estimation and Inference in the Linear Mixed Model},
  author = {Gumedze, F. N. and Dunne, T. T.},
  year = {2011},
  month = oct,
  volume = {435},
  pages = {1920--1944},
  issn = {0024-3795},
  doi = {10.1016/j.laa.2011.04.015},
  abstract = {The paper reviews the linear mixed model with a focus on parameter estimation and inference. Parameter estimation for the different components of the model are reviewed, with an emphasis on variance parameter estimation. Inferential procedures for the fixed effects, random effects or a combination of both fixed and random effects are also discussed.},
  file = {/Users/yuekai/Documents/zotero/Gumedze, Dunne (2011) - Parameter estimation and inference in the linear mixed model.pdf;/Users/yuekai/Zotero/storage/CRTWNVHX/S002437951100320X.html},
  journal = {Linear Algebra and its Applications},
  keywords = {Average information algorithm,Information matrix,Likelihood ratio test,Linear mixed model,REML,Score test,Wald test},
  language = {en},
  number = {8}
}

@article{gunawardena2003Chemical,
  title = {Chemical Reaction Network Theory for In-Silico Biologists},
  author = {Gunawardena, Jeremy},
  year = {2003},
  month = jun,
  pages = {26},
  file = {/Users/yuekai/Documents/zotero/Gunawardena (2003) - Chemical reaction network theory for in-silico biologists.pdf},
  language = {en}
}

@article{guntuboyina2017Adaptive,
  title = {Adaptive {{Risk Bounds}} in {{Univariate Total Variation Denoising}} and {{Trend Filtering}}},
  author = {Guntuboyina, Adityanand and Lieu, Donovan and Chatterjee, Sabyasachi and Sen, Bodhisattva},
  year = {2017},
  month = feb,
  abstract = {We study trend filtering, a relatively recent method for univariate nonparametric regression. For a given integer r {$\geq$} 1, the rth order trend filtering estimator is defined as the minimizer of the sum of squared errors when we constrain (or penalize) the sum of the absolute rth order discrete derivatives of the fitted function at the design points. For r = 1, the estimator reduces to total variation regularization which has received much attention in the statistics and image processing literature. In this paper, we study the performance of the trend filtering estimator for every r {$\geq$} 1, both in the constrained and penalized forms. Our main results show that in the strong sparsity setting when the underlying function is a (discrete) spline with few ``knots'', the risk (under the global squared error loss) of the trend filtering estimator (with an appropriate choice of the tuning parameter) achieves the parametric n-1-rate, up to a logarithmic (multiplicative) factor. Our results therefore provide support for the use of trend filtering, for every r {$\geq$} 1, in the strong sparsity setting.},
  archivePrefix = {arXiv},
  eprint = {1702.05113},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Guntuboyina et al (2017) - Adaptive Risk Bounds in Univariate Total Variation Denoising and Trend Filtering.pdf},
  journal = {arXiv:1702.05113 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  language = {en},
  primaryClass = {math, stat}
}

@article{guo2001Nonsymmetric,
  title = {Nonsymmetric {{Algebraic Riccati Equations}} and {{Wiener}}--{{Hopf Factorization}} for {{M}}-{{Matrices}}},
  author = {Guo, Chun-Hua.},
  year = {2001},
  month = jan,
  volume = {23},
  pages = {225--242},
  issn = {0895-4798},
  doi = {10.1137/S0895479800375680},
  abstract = {We consider the nonsymmetric algebraic Riccati equation for which the four coefficient matrices form an M-matrix. Nonsymmetricalgebraic Riccati equations of this type appear in applied probability and transport theory. The minimal nonnegative solution of these equations can be found by Newton's method and basic fixed-point iterations. The study of these equations is also closely related to the so-called Wiener--Hopf factorization for M-matrices. We explain how the minimal nonnegative solution can be found by the Schur method and compare the Schur method with Newton's method and some basic fixed-point iterations. The development in this paper parallels that for symmetric algebraic Riccati equations arising in linear quadratic control.},
  file = {/Users/yuekai/Documents/zotero/Guo (2001) - Nonsymmetric Algebraic Riccati Equations and Wiener--Hopf Factorization for.pdf},
  journal = {SIAM Journal on Matrix Analysis and Applications},
  number = {1}
}

@article{guo2011Joint,
  title = {Joint Estimation of Multiple Graphical Models},
  author = {Guo, J. and Levina, E. and Michailidis, G. and Zhu, J.},
  year = {2011},
  month = mar,
  volume = {98},
  pages = {1--15},
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/asq060},
  abstract = {Gaussian graphical models explore dependence relationships between random variables, through the estimation of the corresponding inverse covariance matrices. In this paper we develop an estimator for such models appropriate for data from several graphical models that share the same variables and some of the dependence structure. In this setting, estimating a single graphical model would mask the underlying heterogeneity, while estimating separate models for each category does not take advantage of the common structure. We propose a method that jointly estimates the graphical models corresponding to the different categories present in the data, aiming to preserve the common structure, while allowing for differences between the categories. This is achieved through a hierarchical penalty that targets the removal of common zeros in the inverse covariance matrices across categories. We establish the asymptotic consistency and sparsity of the proposed estimator in the high-dimensional case, and illustrate its performance on a number of simulated networks. An application to learning semantic connections between terms from webpages collected from computer science departments is included.},
  file = {/Users/yuekai/Documents/zotero/Guo et al (2011) - Joint estimation of multiple graphical models.pdf},
  journal = {Biometrika},
  language = {en},
  number = {1}
}

@article{gupta2020DataPooling,
  title = {Data-{{Pooling}} in {{Stochastic Optimization}}},
  author = {Gupta, Vishal and Kallus, Nathan},
  year = {2020},
  month = apr,
  abstract = {Managing large-scale systems often involves simultaneously solving thousands of unrelated stochastic optimization problems, each with limited data. Intuition suggests one can decouple these unrelated problems and solve them separately without loss of generality. We propose a novel data-pooling algorithm called Shrunken-SAA that disproves this intuition. In particular, we prove that combining data across problems can outperform decoupling, even when there is no a priori structure linking the problems and data are drawn independently. Our approach does not require strong distributional assumptions and applies to constrained, possibly non-convex, non-smooth optimization problems such as vehicle-routing, economic lot-sizing or facility location. We compare and contrast our results to a similar phenomenon in statistics (Stein's Phenomenon), highlighting unique features that arise in the optimization setting that are not present in estimation. We further prove that as the number of problems grows large, Shrunken-SAA learns if pooling can improve upon decoupling and the optimal amount to pool, even if the average amount of data per problem is fixed and bounded. Importantly, we highlight a simple intuition based on stability that highlights when and why data-pooling offers a benefit, elucidating this perhaps surprising phenomenon. This intuition further suggests that data-pooling offers the most benefits when there are many problems, each of which has a small amount of relevant data. Finally, we demonstrate the practical benefits of data-pooling using real data from a chain of retail drug stores in the context of inventory management.},
  archivePrefix = {arXiv},
  eprint = {1906.00255},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Gupta, Kallus (2020) - Data-Pooling in Stochastic Optimization.pdf},
  journal = {arXiv:1906.00255 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Mathematics - Statistics Theory},
  primaryClass = {cs, math, stat}
}

@article{gymrek2013Identifying,
  title = {Identifying {{Personal Genomes}} by {{Surname Inference}}},
  author = {Gymrek, Melissa and McGuire, Amy L. and Golan, David and Halperin, Eran and Erlich, Yaniv},
  year = {2013},
  month = jan,
  volume = {339},
  pages = {321--324},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1229566},
  abstract = {Sharing sequencing data sets without identifiers has become a common practice in genomics. Here, we report that surnames can be recovered from personal genomes by profiling short tandem repeats on the Y chromosome (Y-STRs) and querying recreational genetic genealogy databases. We show that a combination of a surname with other types of metadata, such as age and state, can be used to triangulate the identity of the target. A key feature of this technique is that it entirely relies on free, publicly accessible Internet resources. We quantitatively analyze the probability of identification for U.S. males. We further demonstrate the feasibility of this technique by tracing back with high probability the identities of multiple participants in public sequencing projects.
Anonymity of male personal genome data sets can be compromised by means of publicly available data. [Also see News story and Policy Forum by Rodriguez et al.]
Anonymity of male personal genome data sets can be compromised by means of publicly available data. [Also see News story and Policy Forum by Rodriguez et al.]},
  copyright = {Copyright \textcopyright{} 2013, American Association for the Advancement of Science},
  file = {/Users/yuekai/Documents/zotero/Gymrek et al (2013) - Identifying Personal Genomes by Surname Inference.pdf},
  journal = {Science},
  language = {en},
  number = {6117},
  pmid = {23329047}
}

@article{haavelmo1943Statistical,
  title = {The {{Statistical Implications}} of a {{System}} of {{Simultaneous Equations}}},
  author = {Haavelmo, Trygve},
  year = {1943},
  volume = {11},
  pages = {1--12},
  issn = {0012-9682},
  doi = {10.2307/1905714},
  journal = {Econometrica},
  number = {1}
}

@book{hall1980Martingale,
  title = {Martingale {{Limit Theory}} and Its {{Application}}},
  author = {Hall, Peter and Heyde, Christopher},
  year = {1980},
  publisher = {{Elsevier}},
  doi = {10.1016/C2013-0-10818-5},
  file = {/Users/yuekai/Documents/zotero/Hall, Heyde (1980) - Martingale Limit Theory and its Application.pdf},
  isbn = {978-0-12-319350-6},
  language = {en}
}

@book{hampel2005Robust,
  title = {Robust Statistics: The Approach Based on Influence Functions},
  shorttitle = {Robust Statistics},
  editor = {Hampel, Frank R.},
  year = {2005},
  edition = {Digital print},
  publisher = {{Wiley}},
  address = {{New York}},
  annotation = {OCLC: 255133771},
  file = {/Users/yuekai/Documents/zotero/Hampel (2005) - Robust statistics.pdf},
  isbn = {978-0-471-73577-9},
  language = {en},
  series = {Wiley Series in Probability and Mathematical Statistics}
}

@article{hamrick2016Metacontrol,
  title = {Metacontrol for {{Adaptive Imagination}}-{{Based Optimization}}},
  author = {Hamrick, Jessica B. and Ballard, Andrew J. and Pascanu, Razvan and Vinyals, Oriol and Heess, Nicolas and Battaglia, Peter W.},
  year = {2016},
  month = nov,
  abstract = {Many machine learning systems are built to solve the hardest examples of a particular task, which often makes them large and expensive to run---especially with respect to the easier examples, which...},
  file = {/Users/yuekai/Documents/zotero/Hamrick et al (2016) - Metacontrol for Adaptive Imagination-Based Optimization.pdf}
}

@article{han2019Universal,
  title = {Universal {{Rank Inference}} via {{Residual Subsampling}} with {{Application}} to {{Large Networks}}},
  author = {Han, Xiao and Yang, Qing and Fan, Yingying},
  year = {2019},
  month = dec,
  abstract = {Determining the precise rank is an important problem in many large-scale applications with matrix data exploiting low-rank plus noise models. In this paper, we suggest a universal approach to rank inference via residual subsampling (RIRS) for testing and estimating rank in a wide family of models, including many popularly used network models such as the degree corrected mixed membership model as a special case. Our procedure constructs a test statistic via subsampling entries of the residual matrix after extracting the spiked components. The test statistic converges in distribution to the standard normal under the null hypothesis, and diverges to infinity with asymptotic probability one under the alternative hypothesis. The effectiveness of RIRS procedure is justified theoretically, utilizing the asymptotic expansions of eigenvectors and eigenvalues for large random matrices recently developed in Fan et al. (2019a) and Fan et al. (2019b). The advantages of the newly suggested procedure are demonstrated through several simulation and real data examples.},
  archivePrefix = {arXiv},
  eprint = {1912.11583},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Han et al (2019) - Universal Rank Inference via Residual Subsampling with Application to Large.pdf},
  journal = {arXiv:1912.11583 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{hanna2019Critical,
  title = {Towards a {{Critical Race Methodology}} in {{Algorithmic Fairness}}},
  author = {Hanna, Alex and Denton, Emily and Smart, Andrew and {Smith-Loud}, Jamila},
  year = {2019},
  month = dec,
  doi = {10.1145/3351095.3372826},
  abstract = {We examine the way race and racial categories are adopted in algorithmic fairness frameworks. Current methodologies fail to adequately account for the socially constructed nature of race, instead adopting a conceptualization of race as a fixed attribute. Treating race as an attribute, rather than a structural, institutional, and relational phenomenon, can serve to minimize the structural aspects of algorithmic unfairness. In this work, we focus on the history of racial categories and turn to critical race theory and sociological work on race and ethnicity to ground conceptualizations of race for fairness research, drawing on lessons from public health, biomedical research, and social survey research. We argue that algorithmic fairness researchers need to take into account the multidimensionality of race, take seriously the processes of conceptualizing and operationalizing race, focus on social processes which produce racial inequality, and consider perspectives of those most affected by sociotechnical systems.},
  archivePrefix = {arXiv},
  eprint = {1912.03593},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hanna et al (2019) - Towards a Critical Race Methodology in Algorithmic Fairness.pdf},
  journal = {arXiv:1912.03593 [cs]},
  keywords = {Computer Science - Computers and Society},
  primaryClass = {cs}
}

@incollection{hanneke2019Value,
  title = {On the {{Value}} of {{Target Data}} in {{Transfer Learning}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 32},
  author = {Hanneke, Steve and Kpotufe, Samory},
  editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and d{\textbackslash}textquotesingle {Alch{\'e}-Buc}, F. and Fox, E. and Garnett, R.},
  year = {2019},
  pages = {9871--9881},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/yuekai/Documents/zotero/Hanneke, Kpotufe (2019) - On the Value of Target Data in Transfer Learning.pdf}
}

@article{hanzely2020Federated,
  title = {Federated {{Learning}} of a {{Mixture}} of {{Global}} and {{Local Models}}},
  author = {Hanzely, Filip and Richt{\'a}rik, Peter},
  year = {2020},
  month = feb,
  abstract = {We propose a new optimization formulation for training federated learning models. The standard formulation has the form of an empirical risk minimization problem constructed to find a single global model trained from the private data stored across all participating devices. In contrast, our formulation seeks an explicit trade-off between this traditional global model and the local models, which can be learned by each device from its own private data without any communication. Further, we develop several efficient variants of SGD (with and without partial participation and with and without variance reduction) for solving the new formulation and prove communication complexity guarantees. Notably, our methods are similar but not identical to federated averaging / local SGD, thus shedding some light on the essence of the elusive method. In particular, our methods do not perform full averaging steps and instead merely take steps towards averaging. We argue for the benefits of this new paradigm for federated learning.},
  archivePrefix = {arXiv},
  eprint = {2002.05516},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hanzely, Richtárik (2020) - Federated Learning of a Mixture of Global and Local Models.pdf},
  journal = {arXiv:2002.05516 [cs, math, stat]},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{hao2016Simultaneous,
  title = {Simultaneous {{Clustering}} and {{Estimation}} of {{Heterogeneous Graphical Models}}},
  author = {Hao, Botao and Sun, Will Wei and Liu, Yufeng and Cheng, Guang},
  year = {2016},
  month = nov,
  abstract = {We consider joint estimation of multiple graphical models arising from heterogeneous and high-dimensional observations. Unlike most previous approaches which assume that the cluster structure is given in advance, an appealing feature of our method is to learn cluster structure while estimating heterogeneous graphical models. This is achieved via a high dimensional version of Expectation Conditional Maximization (ECM) algorithm (Meng and Rubin, 1993). A joint graphical lasso penalty is imposed on the conditional maximization step to extract both homogeneity and heterogeneity components across all clusters. Our algorithm is computationally efficient due to fast sparse learning routines and can be implemented without unsupervised learning knowledge. The superior performance of our method is demonstrated by extensive experiments and its application to a Glioblastoma cancer dataset reveals some new insights in understanding the Glioblastoma cancer. In theory, a non-asymptotic error bound is established for the output directly from our high dimensional ECM algorithm, and it consists of two quantities: statistical error (statistical accuracy) and optimization error (computational complexity). Such a result gives a theoretical guideline in terminating our ECM iterations.},
  archivePrefix = {arXiv},
  eprint = {1611.09391},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hao et al (2016) - Simultaneous Clustering and Estimation of Heterogeneous Graphical Models.pdf},
  journal = {arXiv:1611.09391 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {math, stat}
}

@article{hardt2016Equality,
  title = {Equality of {{Opportunity}} in {{Supervised Learning}}},
  author = {Hardt, Moritz and Price, Eric and Srebro, Nathan},
  year = {2016},
  month = oct,
  abstract = {We propose a criterion for discrimination against a specified sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our definition. Our framework also improves incentives by shifting the cost of poor classification from disadvantaged groups to the decision maker, who can respond by improving the classification accuracy. In line with other studies, our notion is oblivious: it depends only on the joint statistics of the predictor, the target and the protected attribute, but not on interpretation of individualfeatures. We study the inherent limits of defining and identifying biases based on such oblivious measures, outlining what can and cannot be inferred from different oblivious tests. We illustrate our notion using a case study of FICO credit scores.},
  archivePrefix = {arXiv},
  eprint = {1610.02413},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hardt et al (2016) - Equality of Opportunity in Supervised Learning.pdf},
  journal = {arXiv:1610.02413 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{hare2007ProxRegularity,
  title = {Prox-{{Regularity}} and {{Stability}} of the {{Proximal Mapping}}},
  author = {Hare, W L and Poliquin, R A},
  year = {2007},
  volume = {14},
  pages = {18},
  file = {/Users/yuekai/Documents/zotero/Hare, Poliquin (2007) - Prox-Regularity and Stability of the Proximal Mapping.pdf},
  journal = {Journal of Convex Analysis},
  language = {en},
  number = {3}
}

@article{harrison2020Empirical,
  title = {An {{Empirical Study}} on the {{Perceived Fairness}} of {{Realistic}}, {{Imperfect Machine Learning Models}}},
  author = {Harrison, Galen and Hanson, Julia and Jacinto, Christine and Ramirez, Julio and Ur, Blase},
  year = {2020},
  pages = {11},
  abstract = {There are many competing definitions of what statistical properties make a machine learning model fair. Unfortunately, research has shown that some key properties are mutually exclusive. Realistic models are thus necessarily imperfect, choosing one side of a tradeoff or the other. To gauge perceptions of the fairness of such realistic, imperfect models, we conducted a between-subjects experiment with 502 Mechanical Turk workers. Each participant compared two models for deciding whether to grant bail to criminal defendants. The first model equalized one potentially desirable model property, with the other property varying across racial groups. The second model did the opposite. We tested pairwise trade-offs between the following four properties: accuracy; false positive rate; outcomes; and the consideration of race. We also varied which racial group the model disadvantaged. We observed a preference among participants for equalizing the false positive rate between groups over equalizing accuracy. Nonetheless, no preferences were overwhelming, and both sides of each trade-off we tested were strongly preferred by a non-trivial fraction of participants. We observed nuanced distinctions between participants considering a model ``unbiased'' and considering it ``fair.'' Furthermore, even when a model within a trade-off pair was seen as fair and unbiased by a majority of participants, we did not observe consensus that a machine learning model was preferable to a human judge. Our results highlight challenges for building machine learning models that are perceived as fair and broadly acceptable in realistic situations.},
  file = {/Users/yuekai/Documents/zotero/Harrison et al (2020) - An Empirical Study on the Perceived Fairness of Realistic, Imperfect Machine.pdf},
  language = {en}
}

@article{hashimoto2018Fairness,
  title = {Fairness {{Without Demographics}} in {{Repeated Loss Minimization}}},
  author = {Hashimoto, Tatsunori B. and Srivastava, Megha and Namkoong, Hongseok and Liang, Percy},
  year = {2018},
  month = jun,
  abstract = {Machine learning models (e.g., speech recognizers) are usually trained to minimize average loss, which results in representation disparity---minority groups (e.g., non-native speakers) contribute less to the training objective and thus tend to suffer higher loss. Worse, as model accuracy affects user retention, a minority group can shrink over time. In this paper, we first show that the status quo of empirical risk minimization (ERM) amplifies representation disparity over time, which can even make initially fair models unfair. To mitigate this, we develop an approach based on distributionally robust optimization (DRO), which minimizes the worst case risk over all distributions close to the empirical distribution. We prove that this approach controls the risk of the minority group at each time step, in the spirit of Rawlsian distributive justice, while remaining oblivious to the identity of the groups. We demonstrate that DRO prevents disparity amplification on examples where ERM fails, and show improvements in minority group user satisfaction in a real-world text autocomplete task.},
  archivePrefix = {arXiv},
  eprint = {1806.08010},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hashimoto et al (2018) - Fairness Without Demographics in Repeated Loss Minimization.pdf},
  journal = {arXiv:1806.08010 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{hastie2015Matrix,
  title = {Matrix {{Completion}} and {{Low}}-{{Rank SVD}} via {{Fast Alternating Least Squares}}},
  author = {Hastie, Trevor and Mazumder, Rahul and Lee, Jason D. and Zadeh, Reza},
  year = {2015},
  volume = {16},
  pages = {3367--3402},
  issn = {1533-7928},
  file = {/Users/yuekai/Documents/zotero/Hastie et al (2015) - Matrix Completion and Low-Rank SVD via Fast Alternating Least Squares.pdf},
  journal = {Journal of Machine Learning Research},
  number = {104}
}

@article{hastie2019Surprises,
  title = {Surprises in {{High}}-{{Dimensional Ridgeless Least Squares Interpolation}}},
  author = {Hastie, Trevor and Montanari, Andrea and Rosset, Saharon and Tibshirani, Ryan J.},
  year = {2019},
  month = nov,
  abstract = {Interpolators---estimators that achieve zero training error---have attracted growing attention in machine learning, mainly because state-of-the art neural networks appear to be models of this type. In this paper, we study minimum \$\textbackslash ell\_2\$ norm ("ridgeless") interpolation in high-dimensional least squares regression. We consider two different models for the feature distribution: a linear model, where the feature vectors \$x\_i \textbackslash in \textbackslash mathbb\{R\}\^p\$ are obtained by applying a linear transform to a vector of i.i.d. entries, \$x\_i = \textbackslash Sigma\^\{1/2\} z\_i\$ (with \$z\_i \textbackslash in \textbackslash mathbb\{R\}\^p\$); and a nonlinear model, where the feature vectors are obtained by passing the input through a random one-layer neural network, \$x\_i = \textbackslash varphi(W z\_i)\$ (with \$z\_i \textbackslash in \textbackslash mathbb\{R\}\^d\$, \$W \textbackslash in \textbackslash mathbb\{R\}\^\{p \textbackslash times d\}\$ a matrix of i.i.d. entries, and \$\textbackslash varphi\$ an activation function acting componentwise on \$W z\_i\$). We recover---in a precise quantitative way---several phenomena that have been observed in large-scale neural networks and kernel machines, including the "double descent" behavior of the prediction risk, and the potential benefits of overparametrization.},
  archivePrefix = {arXiv},
  eprint = {1903.08560},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hastie et al (2019) - Surprises in High-Dimensional Ridgeless Least Squares Interpolation.pdf},
  journal = {arXiv:1903.08560 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@book{hayashi2000Econometrics,
  title = {Econometrics},
  author = {Hayashi, Fumio},
  year = {2000},
  publisher = {{Princeton University Press}},
  file = {/Users/yuekai/Documents/zotero/Hayashi (2000) - Econometrics.djvu}
}

@article{hayou2019Training,
  title = {Training {{Dynamics}} of {{Deep Networks}} Using {{Stochastic Gradient Descent}} via {{Neural Tangent Kernel}}},
  author = {Hayou, Soufiane and Doucet, Arnaud and Rousseau, Judith},
  year = {2019},
  month = may,
  abstract = {Stochastic Gradient Descent (SGD) is widely used to train deep neural networks. However, few theoretical results on the training dynamics of SGD are available. Recent work by Jacot et al. (2018) has showed that training a neural network of any kind with a full batch gradient descent in parameter space is equivalent to kernel gradient descent in function space with respect to the Neural Tangent Kernel (NTK). Lee et al. (2019) built on this result to show that the output of a neural network trained using full batch gradient descent can be approximated by a linear model for wide neural networks. We show here how these results can be extended to SGD. In this case, the resulting training dynamics is given by a stochastic differential equation dependent on the NTK which becomes a simple mean-reverting process for the squared loss. When the network depth is also large, we provide a comprehensive analysis on the impact of the initialization and the activation function on the NTK, and thus on the corresponding training dynamics under SGD. We provide experiments illustrating our theoretical results.},
  archivePrefix = {arXiv},
  eprint = {1905.13654},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hayou et al (2019) - Training Dynamics of Deep Networks using Stochastic Gradient Descent via Neural.pdf},
  journal = {arXiv:1905.13654 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{hazan2016Introduction,
  title = {Introduction to {{Online Convex Optimization}}},
  author = {Hazan, Elad},
  year = {2016},
  month = aug,
  volume = {2},
  pages = {157--325},
  publisher = {{Now Publishers, Inc.}},
  issn = {2167-3888, 2167-3918},
  doi = {10.1561/2400000013},
  abstract = {Introduction to Online Convex Optimization},
  file = {/Users/yuekai/Documents/zotero/Hazan (2016) - Introduction to Online Convex Optimization.pdf},
  journal = {Foundations and Trends\textregistered{} in Optimization},
  language = {English},
  number = {3-4}
}

@article{hazan2018Provably,
  title = {Provably {{Efficient Maximum Entropy Exploration}}},
  author = {Hazan, Elad and Kakade, Sham M. and Singh, Karan and Van Soest, Abby},
  year = {2018},
  month = dec,
  abstract = {Suppose an agent is in a (possibly unknown) Markov Decision Process in the absence of a reward signal, what might we hope that an agent can efficiently learn to do? This work studies a broad class of objectives that are defined solely as functions of the state-visitation frequencies that are induced by how the agent behaves. For example, one natural, intrinsically defined, objective problem is for the agent to learn a policy which induces a distribution over state space that is as uniform as possible, which can be measured in an entropic sense. We provide an efficient algorithm to optimize such such intrinsically defined objectives, when given access to a black box planning oracle (which is robust to function approximation). Furthermore, when restricted to the tabular setting where we have sample based access to the MDP, our proposed algorithm is provably efficient, both in terms of its sample and computational complexities. Key to our algorithmic methodology is utilizing the conditional gradient method (a.k.a. the Frank-Wolfe algorithm) which utilizes an approximate MDP solver.},
  archivePrefix = {arXiv},
  eprint = {1812.02690},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hazan et al (2018) - Provably Efficient Maximum Entropy Exploration.pdf},
  journal = {arXiv:1812.02690 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{he2016Deep,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  booktitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2016},
  month = jun,
  pages = {770--778},
  publisher = {{IEEE}},
  address = {{Las Vegas, NV, USA}},
  doi = {10.1109/CVPR.2016.90},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers\textemdash 8\texttimes{} deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.},
  file = {/Users/yuekai/Documents/zotero/He et al (2016) - Deep Residual Learning for Image Recognition.pdf},
  isbn = {978-1-4673-8851-1},
  language = {en}
}

@article{he2016Sparse,
  title = {Sparse Meta-Analysis with High-Dimensional Data},
  author = {He, Qianchuan and Zhang, Hao Helen and Avery, Christy L. and Lin, D. Y.},
  year = {2016},
  month = apr,
  volume = {17},
  pages = {205--220},
  issn = {1465-4644, 1468-4357},
  doi = {10.1093/biostatistics/kxv038},
  abstract = {Meta-analysis plays an important role in summarizing and synthesizing scientific evidence derived from multiple studies. With high-dimensional data, the incorporation of variable selection into meta-analysis improves model interpretation and prediction. Existing variable selection methods require direct access to raw data, which may not be available in practical situations. We propose a new approach, sparse metaanalysis (SMA), in which variable selection for meta-analysis is based solely on summary statistics and the effect sizes of each covariate are allowed to vary among studies. We show that the SMA enjoys the oracle property if the estimated covariance matrix of the parameter estimators from each study is available. We also show that our approach achieves selection consistency and estimation consistency even when summary statistics include only the variance estimators or no variance/covariance information at all. Simulation studies and applications to high-throughput genomics studies demonstrate the usefulness of our approach.},
  file = {/Users/yuekai/Documents/zotero/He et al (2016) - Sparse meta-analysis with high-dimensional data.pdf},
  journal = {Biostatistics},
  language = {en},
  number = {2}
}

@article{he2019Local,
  title = {The {{Local Elasticity}} of {{Neural Networks}}},
  author = {He, Hangfeng and Su, Weijie J.},
  year = {2019},
  month = oct,
  abstract = {This paper presents a phenomenon in neural networks that we refer to as \textbackslash textit\{local elasticity\}. Roughly speaking, a classifier is said to be locally elastic if its prediction at a feature vector \$\textbackslash bx'\$ is \textbackslash textit\{not\} significantly perturbed, after the classifier is updated via stochastic gradient descent at a (labeled) feature vector \$\textbackslash bx\$ that is \textbackslash textit\{dissimilar\} to \$\textbackslash bx'\$ in a certain sense. This phenomenon is shown to persist for neural networks with nonlinear activation functions through extensive simulations on real-life and synthetic datasets, whereas this is not observed in linear classifiers. In addition, we offer a geometric interpretation of local elasticity using the neural tangent kernel \textbackslash citep\{jacot2018neural\}. Building on top of local elasticity, we obtain pairwise similarity measures between feature vectors, which can be used for clustering in conjunction with \$K\$-means. The effectiveness of the clustering algorithm on the MNIST and CIFAR-10 datasets in turn corroborates the hypothesis of local elasticity of neural networks on real-life data. Finally, we discuss some implications of local elasticity to shed light on several intriguing aspects of deep neural networks.},
  archivePrefix = {arXiv},
  eprint = {1910.06943},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/He, Su (2019) - The Local Elasticity of Neural Networks.pdf},
  journal = {arXiv:1910.06943 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{hebert-johnson2017Calibration,
  title = {Calibration for the ({{Computationally}}-{{Identifiable}}) {{Masses}}},
  author = {{H{\'e}bert-Johnson}, {\'U}rsula and Kim, Michael P. and Reingold, Omer and Rothblum, Guy N.},
  year = {2017},
  month = nov,
  abstract = {As algorithms increasingly inform and influence decisions made about individuals, it becomes increasingly important to address concerns that these algorithms might be discriminatory. The output of an algorithm can be discriminatory for many reasons, most notably: (1) the data used to train the algorithm might be biased (in various ways) to favor certain populations over others; (2) the analysis of this training data might inadvertently or maliciously introduce biases that are not borne out in the data. This work focuses on the latter concern. We develop and study multicalbration -- a new measure of algorithmic fairness that aims to mitigate concerns about discrimination that is introduced in the process of learning a predictor from data. Multicalibration guarantees accurate (calibrated) predictions for every subpopulation that can be identified within a specified class of computations. We think of the class as being quite rich; in particular, it can contain many overlapping subgroups of a protected group. We show that in many settings this strong notion of protection from discrimination is both attainable and aligned with the goal of obtaining accurate predictions. Along the way, we present new algorithms for learning a multicalibrated predictor, study the computational complexity of this task, and draw new connections to computational learning models such as agnostic learning.},
  archivePrefix = {arXiv},
  eprint = {1711.08513},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hébert-Johnson et al (2017) - Calibration for the (Computationally-Identifiable) Masses.pdf},
  journal = {arXiv:1711.08513 [cs, stat]},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{heidari2019Longterm,
  title = {On the {{Long}}-Term {{Impact}} of {{Algorithmic Decision Policies}}: {{Effort Unfairness}} and {{Feature Segregation}} through {{Social Learning}}},
  shorttitle = {On the {{Long}}-Term {{Impact}} of {{Algorithmic Decision Policies}}},
  author = {Heidari, Hoda and Nanda, Vedant and Gummadi, Krishna P.},
  year = {2019},
  month = mar,
  abstract = {Most existing notions of algorithmic fairness are one-shot: they ensure some form of allocative equality at the time of decision making, but do not account for the adverse impact of the algorithmic decisions today on the long-term welfare and prosperity of certain segments of the population. We take a broader perspective on algorithmic fairness. We propose an effort-based measure of fairness and present a data-driven framework for characterizing the long-term impact of algorithmic policies on reshaping the underlying population. Motivated by the psychological literature on \textbackslash emph\{social learning\} and the economic literature on equality of opportunity, we propose a micro-scale model of how individuals may respond to decision-making algorithms. We employ existing measures of segregation from sociology and economics to quantify the resulting macro-scale population-level change. Importantly, we observe that different models may shift the group-conditional distribution of qualifications in different directions. Our findings raise a number of important questions regarding the formalization of fairness for decision-making models.},
  archivePrefix = {arXiv},
  eprint = {1903.01209},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Heidari et al (2019) - On the Long-term Impact of Algorithmic Decision Policies.pdf},
  journal = {arXiv:1903.01209 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society},
  primaryClass = {cs}
}

@article{heikkila2017Differentially,
  title = {Differentially {{Private Bayesian Learning}} on {{Distributed Data}}},
  author = {Heikkil{\"a}, Mikko and Lagerspetz, Eemil and Kaski, Samuel and Shimizu, Kana and Tarkoma, Sasu and Honkela, Antti},
  year = {2017},
  month = mar,
  abstract = {Many applications of machine learning, for example in health care, would benefit from methods that can guarantee privacy of data subjects. Differential privacy (DP) has become established as a standard for protecting learning results. The standard DP algorithms require a single trusted party to have access to the entire data, which is a clear weakness. We consider DP Bayesian learning in a distributed setting, where each party only holds a single sample or a few samples of the data. We propose a learning strategy based on a secure multi-party sum function for aggregating summaries from data holders and the Gaussian mechanism for DP. Our method builds on an asymptotically optimal and practically efficient DP Bayesian inference with rapidly diminishing extra cost.},
  archivePrefix = {arXiv},
  eprint = {1703.01106},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Heikkilä et al (2017) - Differentially Private Bayesian Learning on Distributed Data.pdf},
  journal = {arXiv:1703.01106 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{heinze-deml2017Conditional,
  title = {Conditional {{Variance Penalties}} and {{Domain Shift Robustness}}},
  author = {{Heinze-Deml}, Christina and Meinshausen, Nicolai},
  year = {2017},
  month = oct,
  abstract = {When training a deep neural network for image classification, one can broadly distinguish between two types of latent features of images that will drive the classification. We can divide latent features into (i) "core" or "conditionally invariant" features \$X\^\textbackslash text\{core\}\$ whose distribution \$X\^\textbackslash text\{core\}\textbackslash vert Y\$, conditional on the class \$Y\$, does not change substantially across domains and (ii) "style" features \$X\^\{\textbackslash text\{style\}\}\$ whose distribution \$X\^\{\textbackslash text\{style\}\} \textbackslash vert Y\$ can change substantially across domains. Examples for style features include position, rotation, image quality or brightness but also more complex ones like hair color, image quality or posture for images of persons. Our goal is to minimize a loss that is robust under changes in the distribution of these style features. In contrast to previous work, we assume that the domain itself is not observed and hence a latent variable. We do assume that we can sometimes observe a typically discrete identifier or "\$\textbackslash mathrm\{ID\}\$ variable". In some applications we know, for example, that two images show the same person, and \$\textbackslash mathrm\{ID\}\$ then refers to the identity of the person. The proposed method requires only a small fraction of images to have \$\textbackslash mathrm\{ID\}\$ information. We group observations if they share the same class and identifier \$(Y,\textbackslash mathrm\{ID\})=(y,\textbackslash mathrm\{id\})\$ and penalize the conditional variance of the prediction or the loss if we condition on \$(Y,\textbackslash mathrm\{ID\})\$. Using a causal framework, this conditional variance regularization (CoRe) is shown to protect asymptotically against shifts in the distribution of the style variables. Empirically, we show that the CoRe penalty improves predictive accuracy substantially in settings where domain changes occur in terms of image quality, brightness and color while we also look at more complex changes such as changes in movement and posture.},
  archivePrefix = {arXiv},
  eprint = {1710.11469},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Heinze-Deml, Meinshausen (2017) - Conditional Variance Penalties and Domain Shift Robustness.pdf},
  journal = {arXiv:1710.11469 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{heller2019Optimal,
  title = {Optimal {{FDR}} Control in the Two-Group Model},
  author = {Heller, Ruth and Rosset, Saharon},
  year = {2019},
  month = feb,
  abstract = {The highly influential two group model in testing a large number of statistical hypothesis assumes that the test statistics come from a mixture of a high probability null distribution and a low probability alternative. Optimal control of the marginal false discovery rate (mFDR), in the sense that it provides maximal power (expected true discoveries) subject to mFDR control, is achieved by thresholding the local false discovery rate (locFDR) with a fixed threshold. In this paper we address the challenge of controlling the popular false discovery rate (FDR) rather than mFDR in the two group model. Since FDR is less conservative, this results in more rejections. We derive the optimal multiple testing (OMT) policy for this task, which turns out to be thresholding the locFDR with a threshold that is a function of the entire set of statistics. We show how to evaluate this threshold in time that is linear in the number of hypotheses, leading to an efficient algorithm for finding this policy. Thus, we can easily derive and apply the optimal procedure for problems with thousands of hypotheses. We show that for K=5000 hypotheses there can be significant power gain in OMT with FDR versus mFDR control.},
  archivePrefix = {arXiv},
  eprint = {1902.00892},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Heller, Rosset (2019) - Optimal FDR control in the two-group model.pdf},
  journal = {arXiv:1902.00892 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{hendrycks2019AugMix,
  title = {{{AugMix}}: {{A Simple Data Processing Method}} to {{Improve Robustness}} and {{Uncertainty}}},
  shorttitle = {{{AugMix}}},
  author = {Hendrycks, Dan and Mu, Norman and Cubuk, Ekin D. and Zoph, Barret and Gilmer, Justin and Lakshminarayanan, Balaji},
  year = {2019},
  month = dec,
  abstract = {Modern deep neural networks can achieve high accuracy when the training distribution and test distribution are identically distributed, but this assumption is frequently violated in practice. When the train and test distributions are mismatched, accuracy can plummet. Currently there are few techniques that improve robustness to unforeseen data shifts encountered during deployment. In this work, we propose a technique to improve the robustness and uncertainty estimates of image classifiers. We propose AugMix, a data processing technique that is simple to implement, adds limited computational overhead, and helps models withstand unforeseen corruptions. AugMix significantly improves robustness and uncertainty measures on challenging image classification benchmarks, closing the gap between previous methods and the best possible performance in some cases by more than half.},
  archivePrefix = {arXiv},
  eprint = {1912.02781},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hendrycks et al (2019) - AugMix.pdf},
  journal = {arXiv:1912.02781 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{hendrycks2019Natural,
  title = {Natural {{Adversarial Examples}}},
  author = {Hendrycks, Dan and Zhao, Kevin and Basart, Steven and Steinhardt, Jacob and Song, Dawn},
  year = {2019},
  month = jul,
  abstract = {We introduce natural adversarial examples -- real-world, unmodified, and naturally occurring examples that cause classifier accuracy to significantly degrade. We curate 7,500 natural adversarial examples and release them in an ImageNet classifier test set that we call ImageNet-A. This dataset serves as a new way to measure classifier robustness. Like l\_p adversarial examples, ImageNet-A examples successfully transfer to unseen or black-box classifiers. For example, on ImageNet-A a DenseNet-121 obtains around 2\% accuracy, an accuracy drop of approximately 90\%. Recovering this accuracy is not simple because ImageNet-A examples exploit deep flaws in current classifiers including their over-reliance on color, texture, and background cues. We observe that popular training techniques for improving robustness have little effect, but we show that some architectural changes can enhance robustness to natural adversarial examples. Future research is required to enable robust generalization to this hard ImageNet test set.},
  archivePrefix = {arXiv},
  eprint = {1907.07174},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hendrycks et al (2019) - Natural Adversarial Examples.pdf},
  journal = {arXiv:1907.07174 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{hendrycks2020Many,
  title = {The {{Many Faces}} of {{Robustness}}: {{A Critical Analysis}} of {{Out}}-of-{{Distribution Generalization}}},
  shorttitle = {The {{Many Faces}} of {{Robustness}}},
  author = {Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and Song, Dawn and Steinhardt, Jacob and Gilmer, Justin},
  year = {2020},
  month = jun,
  abstract = {We introduce three new robustness benchmarks consisting of naturally occurring distribution changes in image style, geographic location, camera operation, and more. Using our benchmarks, we take stock of previously proposed hypotheses for out-of-distribution robustness and put them to the test. We find that using larger models and synthetic data augmentation can improve robustness on real-world distribution shifts, contrary to claims in prior work. Motivated by this, we introduce a new data augmentation method which advances the state-of-the-art and outperforms models pretrained with 1000x more labeled data. We find that some methods consistently help with distribution shifts in texture and local image statistics, but these methods do not help with some other distribution shifts like geographic changes. We conclude that future research must study multiple distribution shifts simultaneously.},
  archivePrefix = {arXiv},
  eprint = {2006.16241},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hendrycks et al (2020) - The Many Faces of Robustness.pdf},
  journal = {arXiv:2006.16241 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@book{hernan2020Causal,
  title = {Causal {{Inference}}: {{What If}}},
  author = {Hern{\'a}n, Miguel A and Robins, James M},
  year = {2020},
  publisher = {{Chapman \& Hall/CRC}},
  address = {{Boca Raton}},
  file = {/Users/yuekai/Documents/zotero/Hernán, Robins (2020) - Causal Inference.pdf},
  language = {en}
}

@article{hey2020Machine,
  title = {Machine Learning and Big Scientific Data},
  author = {Hey, Tony and Butler, Keith and Jackson, Sam and Thiyagalingam, Jeyarajan},
  year = {2020},
  month = mar,
  volume = {378},
  pages = {20190054},
  doi = {10.1098/rsta.2019.0054},
  abstract = {This paper reviews some of the challenges posed by the huge growth of experimental data generated by the new generation of large-scale experiments at UK national facilities at the Rutherford Appleton Laboratory (RAL) site at Harwell near Oxford. Such `Big Scientific Data' comes from the Diamond Light Source and Electron Microscopy Facilities, the ISIS Neutron and Muon Facility and the UK's Central Laser Facility. Increasingly, scientists are now required to use advanced machine learning and other AI technologies both to automate parts of the data pipeline and to help find new scientific discoveries in the analysis of their data. For commercially important applications, such as object recognition, natural language processing and automatic translation, deep learning has made dramatic breakthroughs. Google's DeepMind has now used the deep learning technology to develop their AlphaFold tool to make predictions for protein folding. Remarkably, it has been able to achieve some spectacular results for this specific scientific problem. Can deep learning be similarly transformative for other scientific problems? After a brief review of some initial applications of machine learning at the RAL, we focus on challenges and opportunities for AI in advancing materials science. Finally, we discuss the importance of developing some realistic machine learning benchmarks using Big Scientific Data coming from several different scientific domains. We conclude with some initial examples of our `scientific machine learning' benchmark suite and of the research challenges these benchmarks will enable.This article is part of a discussion meeting issue `Numerical algorithms for high-performance computational science'.},
  file = {/Users/yuekai/Documents/zotero/Hey et al (2020) - Machine learning and big scientific data.pdf},
  journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  number = {2166}
}

@article{hiai2007Monotonicity,
  title = {Monotonicity for Entrywise Functions of Matrices},
  author = {Hiai, Fumio},
  year = {2007},
  month = sep,
  abstract = {We characterize real functions \$f\$ on an interval \$(-\textbackslash alpha,\textbackslash alpha)\$ for which the entrywise matrix function \$[a\_\{ij\}] \textbackslash mapsto [f(a\_\{ij\})]\$ is positive, monotone and convex, respectively, in the positive semidefiniteness order. Fractional power functions are exemplified and related weak majorizations are shown.},
  archivePrefix = {arXiv},
  eprint = {0709.1235},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hiai (2007) - Monotonicity for entrywise functions of matrices.pdf},
  journal = {arXiv:0709.1235 [math]},
  keywords = {Mathematics - Functional Analysis},
  primaryClass = {math}
}

@article{higham2001Algorithmic,
  title = {An {{Algorithmic Introduction}} to {{Numerical Simulation}} of {{Stochastic Differential Equations}}},
  author = {Higham, Desmond J.},
  year = {2001},
  month = jan,
  volume = {43},
  pages = {525--546},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1445},
  doi = {10.1137/S0036144500378302},
  abstract = {A practical and accessible introduction to numerical methods for stochastic differential equations is given. The reader is assumed to be familiar with Euler's method for deterministic differential equations and to have at least an intuitive feel for the concept of a random variable; however, no knowledge of advanced probability theory or stochastic processes is assumed. The article is built around \$10\$ MATLAB programs, and the topics covered include stochastic integration, the Euler--Maruyama method, Milstein's method, strong and weak convergence, linear stability, and the stochastic chain rule.},
  file = {/Users/yuekai/Documents/zotero/Higham (2001) - An Algorithmic Introduction to Numerical Simulation of Stochastic Differential.pdf},
  journal = {SIAM Review},
  number = {3}
}

@article{ho2007Matching,
  title = {Matching as {{Nonparametric Preprocessing}} for {{Reducing Model Dependence}} in {{Parametric Causal Inference}}},
  author = {Ho, Daniel E. and Imai, Kosuke and King, Gary and Stuart, Elizabeth A.},
  year = {2007/ed},
  volume = {15},
  pages = {199--236},
  issn = {1047-1987, 1476-4989},
  doi = {10.1093/pan/mpl013},
  abstract = {Although published works rarely include causal estimates from more than a few model specifications, authors usually choose the presented estimates from numerous trial runs readers never see. Given the often large variation in estimates across choices of control variables, functional forms, and other modeling assumptions, how can researchers ensure that the few estimates presented are accurate or representative? How do readers know that publications are not merely demonstrations that it is possible to find a specification that fits the author's favorite hypothesis? And how do we evaluate or even define statistical properties like unbiasedness or mean squared error when no unique model or estimator even exists? Matching methods, which offer the promise of causal inference with fewer assumptions, constitute one possible way forward, but crucial results in this fast-growing methodological literature are often grossly misinterpreted. We explain how to avoid these misinterpretations and propose a unified approach that makes it possible for researchers to preprocess data with matching (such as with the easy-to-use software we offer) and then to apply the best parametric techniques they would have used anyway. This procedure makes parametric models produce more accurate and considerably less model-dependent causal inferences.},
  file = {/Users/yuekai/Documents/zotero/Ho et al (2007) - Matching as Nonparametric Preprocessing for Reducing Model Dependence in.pdf},
  journal = {Political Analysis},
  language = {en},
  number = {3}
}

@article{holland1983Stochastic,
  title = {Stochastic Blockmodels: {{First}} Steps},
  shorttitle = {Stochastic Blockmodels},
  author = {Holland, Paul W. and Laskey, Kathryn Blackmond and Leinhardt, Samuel},
  year = {1983},
  month = jun,
  volume = {5},
  pages = {109--137},
  issn = {03788733},
  doi = {10.1016/0378-8733(83)90021-7},
  file = {/Users/yuekai/Documents/zotero/Holland et al (1983) - Stochastic blockmodels.pdf},
  journal = {Social Networks},
  language = {en},
  number = {2}
}

@article{holstein2018Improving,
  title = {Improving Fairness in Machine Learning Systems: {{What}} Do Industry Practitioners Need?},
  shorttitle = {Improving Fairness in Machine Learning Systems},
  author = {Holstein, Kenneth and Vaughan, Jennifer Wortman and Daum{\'e} III, Hal and Dud{\'i}k, Miro and Wallach, Hanna},
  year = {2018},
  month = dec,
  doi = {10.1145/3290605.3300830},
  abstract = {The potential for machine learning (ML) systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. A surge of recent work has focused on the development of algorithmic tools to assess and mitigate such unfairness. If these tools are to have a positive impact on industry practice, however, it is crucial that their design be informed by an understanding of real-world needs. Through 35 semi-structured interviews and an anonymous survey of 267 ML practitioners, we conduct the first systematic investigation of commercial product teams' challenges and needs for support in developing fairer ML systems. We identify areas of alignment and disconnect between the challenges faced by industry practitioners and solutions proposed in the fair ML research literature. Based on these findings, we highlight directions for future ML and HCI research that will better address industry practitioners' needs.},
  archivePrefix = {arXiv},
  eprint = {1812.05239},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Holstein et al (2018) - Improving fairness in machine learning systems.pdf},
  journal = {arXiv:1812.05239 [cs]},
  keywords = {Computer Science - Computers and Society,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning,Computer Science - Software Engineering},
  primaryClass = {cs}
}

@article{hong2016Convergence,
  title = {Convergence {{Analysis}} of {{Alternating Direction Method}} of {{Multipliers}} for a {{Family}} of {{Nonconvex Problems}}},
  author = {Hong, Mingyi and Luo, Zhi-Quan and Razaviyayn, Meisam},
  year = {2016},
  month = jan,
  volume = {26},
  pages = {337--364},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1052-6234},
  doi = {10.1137/140990309},
  abstract = {The alternating direction method of multipliers (ADMM) is widely used to solve large-scale linearly constrained optimization problems, convex or nonconvex, in many engineering fields. However there is a general lack of theoretical understanding of the algorithm when the objective function is nonconvex. In this paper we analyze the convergence of the ADMM for solving certain nonconvex consensus and sharing problems. We show that the classical ADMM converges to the set of stationary solutions, provided that the penalty parameter in the augmented Lagrangian is chosen to be sufficiently large. For the sharing problems, we show that the ADMM is convergent regardless of the number of variable blocks. Our analysis does not impose any assumptions on the iterates generated by the algorithm and is broadly applicable to many ADMM variants involving proximal update rules and various flexible block selection rules.},
  file = {/Users/yuekai/Documents/zotero/Hong et al (2016) - Convergence Analysis of Alternating Direction Method of Multipliers for a.pdf},
  journal = {SIAM Journal on Optimization},
  number = {1}
}

@article{hong2016Numerical,
  title = {The {{Numerical Delta Method}} and {{Bootstrap}}},
  author = {Hong, Han and Li, Jessie},
  year = {2016},
  month = oct,
  pages = {83},
  abstract = {This paper studies inference on nondifferentiable functions using methods based on numerical differentiation. First we show that for an appropriately chosen sequence of step sizes, numerical derivative based delta methods provide consistent inference for functions of parameters that are directionally differentiable. Examples of directionally differentiable functions arise in a variety of economic applications such as moment inequalities models and threshold regression models. Second, we propose a numerical bootstrap method that provides asymptotically valid inference even for parameters that are not known to be directionally differentiable. The numerical bootstrap can consistently estimate the limiting distribution in many cases where the conventional bootstrap is known to fail and where subsampling has been the most commonly used inference approach. Applications include constrained and unconstrained M-estimators converging at both regular and nonstandard rates, misspecified simulated GMM models with nondifferentiable moments, LASSO, and 1-norm Support Vector Machine regression.},
  file = {/Users/yuekai/Documents/zotero/Hong, Li (2016) - The Numerical Delta Method and Bootstrap.pdf},
  language = {en}
}

@article{hopkins2018Mean,
  title = {Mean {{Estimation}} with {{Sub}}-{{Gaussian Rates}} in {{Polynomial Time}}},
  author = {Hopkins, Samuel B.},
  year = {2018},
  month = sep,
  abstract = {We study polynomial time algorithms for estimating the mean of a heavy-tailed multivariate random vector. We assume only that the random vector \$X\$ has finite mean and covariance. In this setting, the radius of confidence intervals achieved by the empirical mean are large compared to the case that \$X\$ is Gaussian or sub-Gaussian. We offer the first polynomial time algorithm to estimate the mean with sub-Gaussian-size confidence intervals under such mild assumptions. Our algorithm is based on a new semidefinite programming relaxation of a high-dimensional median. Previous estimators which assumed only existence of finitely-many moments of \$X\$ either sacrifice sub-Gaussian performance or are only known to be computable via brute-force search procedures requiring time exponential in the dimension.},
  archivePrefix = {arXiv},
  eprint = {1809.07425},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hopkins (2018) - Mean Estimation with Sub-Gaussian Rates in Polynomial Time.pdf},
  journal = {arXiv:1809.07425 [cs, math, stat]},
  keywords = {Computer Science - Data Structures and Algorithms,Mathematics - Statistics Theory},
  primaryClass = {cs, math, stat}
}

@article{horowitz1992Smoothed,
  title = {A {{Smoothed Maximum Score Estimator}} for the {{Binary Response Model}}},
  author = {Horowitz, Joel L.},
  year = {1992},
  volume = {60},
  pages = {505--531},
  abstract = {This paper describes a semiparametric estimator for binary response models in which there may be arbitrary heteroskedasticity of unknown form. The estimator is obtained by maximizing a smoothed version of the objective function of C. Manski's maximum score estimator. The smoothing procedure is similar to that used in kernel nonparametric density estimation. The resulting estimator's rate of convergence in probability is the fastest possible under the assumptions that are made. The centered, normalized estimator is asymptotically normally distributed. Methods are given for consistently estimating the parameters of the limiting distribution and for selecting the bandwidth required by the smoothing procedure. Copyright 1992 by The Econometric Society.},
  journal = {Econometrica},
  language = {en},
  number = {3}
}

@article{horowitz2019NonAsymptotic,
  title = {Non-{{Asymptotic Inference}} in a {{Class}} of {{Optimization Problems}}},
  author = {Horowitz, Joel and Lee, Sokbae},
  year = {2019},
  month = may,
  abstract = {This paper describes a method for carrying out non-asymptotic inference on partially identified parameters that are solutions to a class of optimization problems. The optimization problems arise in applications in which grouped data are used for estimation of a model's structural parameters. The parameters are characterized by restrictions that involve the population means of observed random variables in addition to the structural parameters of interest. Inference consists of finding confidence intervals for the structural parameters. Our method is non-asymptotic in the sense that it provides a finite-sample bound on the difference between the true and nominal probabilities with which a confidence interval contains the true but unknown value of a parameter. We contrast our method with an alternative non-asymptotic method based on the median-of-means estimator of Minsker (2015). The results of Monte Carlo experiments and an empirical example illustrate the usefulness of our method.},
  archivePrefix = {arXiv},
  eprint = {1905.06491},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Horowitz, Lee (2019) - Non-Asymptotic Inference in a Class of Optimization Problems.pdf},
  journal = {arXiv:1905.06491 [econ, stat]},
  keywords = {Economics - Econometrics,Statistics - Methodology},
  primaryClass = {econ, stat}
}

@article{hsu2012Learning,
  title = {Learning Mixtures of Spherical {{Gaussians}}: Moment Methods and Spectral Decompositions},
  shorttitle = {Learning Mixtures of Spherical {{Gaussians}}},
  author = {Hsu, Daniel and Kakade, Sham M.},
  year = {2012},
  month = oct,
  abstract = {This work provides a computationally efficient and statistically consistent moment-based estimator for mixtures of spherical Gaussians. Under the condition that component means are in general position, a simple spectral decomposition technique yields consistent parameter estimates from low-order observable moments, without additional minimum separation assumptions needed by previous computationally efficient estimation procedures. Thus computational and information-theoretic barriers to efficient estimation in mixture models are precluded when the mixture components have means in general position and spherical covariances. Some connections are made to estimation problems related to independent component analysis.},
  archivePrefix = {arXiv},
  eprint = {1206.5766},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hsu, Kakade (2012) - Learning mixtures of spherical Gaussians.pdf},
  journal = {arXiv:1206.5766 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{hsu2019Multiclass,
  title = {Multi-Class {{Classification}} without {{Multi}}-Class {{Labels}}},
  author = {Hsu, Yen-Chang and Lv, Zhaoyang and Schlosser, Joel and Odom, Phillip and Kira, Zsolt},
  year = {2019},
  month = jan,
  abstract = {This work presents a new strategy for multi-class classification that requires no class-specific labels, but instead leverages pairwise similarity between examples, which is a weaker form of annotation. The proposed method, meta classification learning, optimizes a binary classifier for pairwise similarity prediction and through this process learns a multi-class classifier as a submodule. We formulate this approach, present a probabilistic graphical model for it, and derive a surprisingly simple loss function that can be used to learn neural network-based models. We then demonstrate that this same framework generalizes to the supervised, unsupervised cross-task, and semi-supervised settings. Our method is evaluated against state of the art in all three learning paradigms and shows a superior or comparable accuracy, providing evidence that learning multi-class classification without multi-class labels is a viable learning option.},
  archivePrefix = {arXiv},
  eprint = {1901.00544},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hsu et al (2019) - Multi-class Classification without Multi-class Labels.pdf},
  journal = {arXiv:1901.00544 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{hu2004Mining,
  title = {Mining and {{Summarizing Customer Reviews}}},
  booktitle = {Proceedings of the Tenth {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining},
  author = {Hu, Minqing and Liu, Bing},
  year = {2004},
  month = aug,
  pages = {10},
  address = {{Seattle, WA}},
  abstract = {Merchants selling products on the Web often ask their customers to review the products that they have purchased and the associated services. As e-commerce is becoming more and more popular, the number of customer reviews that a product receives grows rapidly. For a popular product, the number of reviews can be in hundreds or even thousands. This makes it difficult for a potential customer to read them to make an informed decision on whether to purchase the product. It also makes it difficult for the manufacturer of the product to keep track and to manage customer opinions. For the manufacturer, there are additional difficulties because many merchant sites may sell the same product and the manufacturer normally produces many kinds of products. In this research, we aim to mine and to summarize all the customer reviews of a product. This summarization task is different from traditional text summarization because we only mine the features of the product on which the customers have expressed their opinions and whether the opinions are positive or negative. We do not summarize the reviews by selecting a subset or rewrite some of the original sentences from the reviews to capture the main points as in the classic text summarization. Our task is performed in three steps: (1) mining product features that have been commented on by customers; (2) identifying opinion sentences in each review and deciding whether each opinion sentence is positive or negative; (3) summarizing the results. This paper proposes several novel techniques to perform these tasks. Our experimental results using reviews of a number of products sold online demonstrate the effectiveness of the techniques.},
  file = {/Users/yuekai/Documents/zotero/Hu, Liu (2004) - Mining and Summarizing Customer Reviews.pdf},
  language = {en}
}

@inproceedings{hu2019Empirical,
  title = {Empirical {{Bayes Transductive Meta}}-{{Learning}} with {{Synthetic Gradients}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Hu, Shell Xu and Moreno, Pablo and Xiao, Yang and Shen, Xi and Obozinski, Guillaume and Lawrence, Neil and Damianou, Andreas},
  year = {2019},
  month = sep,
  abstract = {We propose a meta-learning approach that learns from multiple tasks in a transductive setting, by leveraging unlabeled information in the query set to learn a more powerful meta-model. To develop...},
  file = {/Users/yuekai/Documents/zotero/Hu et al (2019) - Empirical Bayes Transductive Meta-Learning with Synthetic Gradients.pdf}
}

@article{hu2019Fair,
  title = {Fair {{Classification}} and {{Social Welfare}}},
  author = {Hu, Lily and Chen, Yiling},
  year = {2019},
  month = apr,
  abstract = {Now that machine learning algorithms lie at the center of many resource allocation pipelines, computer scientists have been unwittingly cast as partial social planners. Given this state of affairs, important questions follow. What is the relationship between fairness as defined by computer scientists and notions of social welfare? In this paper, we present a welfare-based analysis of classification and fairness regimes. We translate a loss minimization program into a social welfare maximization problem with a set of implied welfare weights on individuals and groups--weights that can be analyzed from a distribution justice lens. In the converse direction, we ask what the space of possible labelings is for a given dataset and hypothesis class. We provide an algorithm that answers this question with respect to linear hyperplanes in \$\textbackslash mathbb\{R\}\^d\$ that runs in \$O(n\^dd)\$. Our main findings on the relationship between fairness criteria and welfare center on sensitivity analyses of fairness-constrained empirical risk minimization programs. We characterize the ranges of \$\textbackslash Delta \textbackslash epsilon\$ perturbations to a fairness parameter \$\textbackslash epsilon\$ that yield better, worse, and neutral outcomes in utility for individuals and by extension, groups. We show that applying more strict fairness criteria that are codified as parity constraints, can worsen welfare outcomes for both groups. More generally, always preferring "more fair" classifiers does not abide by the Pareto Principle---a fundamental axiom of social choice theory and welfare economics. Recent work in machine learning has rallied around these notions of fairness as critical to ensuring that algorithmic systems do not have disparate negative impact on disadvantaged social groups. By showing that these constraints often fail to translate into improved outcomes for these groups, we cast doubt on their effectiveness as a means to ensure justice.},
  archivePrefix = {arXiv},
  eprint = {1905.00147},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hu, Chen (2019) - Fair Classification and Social Welfare.pdf},
  journal = {arXiv:1905.00147 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{hu2019Learning,
  title = {Learning {{Data Manipulation}} for {{Augmentation}} and {{Weighting}}},
  author = {Hu, Zhiting and Tan, Bowen and Salakhutdinov, Ruslan and Mitchell, Tom and Xing, Eric P.},
  year = {2019},
  month = oct,
  abstract = {Manipulating data, such as weighting data examples or augmenting with new instances, has been increasingly used to improve model training. Previous work has studied various rule- or learning-based approaches designed for specific types of data manipulation. In this work, we propose a new method that supports learning different manipulation schemes with the same gradient-based algorithm. Our approach builds upon a recent connection of supervised learning and reinforcement learning (RL), and adapts an off-the-shelf reward learning algorithm from RL for joint data manipulation learning and model training. Different parameterization of the "data reward" function instantiates different manipulation schemes. We showcase data augmentation that learns a text transformation network, and data weighting that dynamically adapts the data sample importance. Experiments show the resulting algorithms significantly improve the image and text classification performance in low data regime and class-imbalance problems.},
  archivePrefix = {arXiv},
  eprint = {1910.12795},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hu et al (2019) - Learning Data Manipulation for Augmentation and Weighting.pdf},
  journal = {arXiv:1910.12795 [cs, stat]},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{huang1996Efficient,
  title = {Efficient Estimation for the Proportional Hazards Model with Interval Censoring},
  author = {Huang, Jian},
  year = {1996},
  month = apr,
  volume = {24},
  pages = {540--568},
  doi = {10.1214/aos/1032894452},
  file = {/Users/yuekai/Documents/zotero/Huang (1996) - Efficient estimation for the proportional hazards model with interval censoring.pdf},
  journal = {The Annals of Statistics},
  language = {en},
  number = {2}
}

@article{huang2016AnchorFree,
  title = {Anchor-{{Free Correlated Topic Modeling}}: {{Identifiability}} and {{Algorithm}}},
  shorttitle = {Anchor-{{Free Correlated Topic Modeling}}},
  author = {Huang, Kejun and Fu, Xiao and Sidiropoulos, Nicholas D.},
  year = {2016},
  month = nov,
  abstract = {In topic modeling, many algorithms that guarantee identifiability of the topics have been developed under the premise that there exist anchor words -- i.e., words that only appear (with positive probability) in one topic. Follow-up work has resorted to three or higher-order statistics of the data corpus to relax the anchor word assumption. Reliable estimates of higher-order statistics are hard to obtain, however, and the identification of topics under those models hinges on uncorrelatedness of the topics, which can be unrealistic. This paper revisits topic modeling based on second-order moments, and proposes an anchor-free topic mining framework. The proposed approach guarantees the identification of the topics under a much milder condition compared to the anchor-word assumption, thereby exhibiting much better robustness in practice. The associated algorithm only involves one eigen-decomposition and a few small linear programs. This makes it easy to implement and scale up to very large problem instances. Experiments using the TDT2 and Reuters-21578 corpus demonstrate that the proposed anchor-free approach exhibits very favorable performance (measured using coherence, similarity count, and clustering accuracy metrics) compared to the prior art.},
  archivePrefix = {arXiv},
  eprint = {1611.05010},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Huang et al (2016) - Anchor-Free Correlated Topic Modeling.pdf},
  journal = {arXiv:1611.05010 [cs, stat]},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{huber1964Robust,
  title = {Robust {{Estimation}} of a {{Location Parameter}}},
  author = {Huber, Peter J.},
  year = {1964},
  month = mar,
  volume = {35},
  pages = {73--101},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177703732},
  abstract = {This paper contains a new approach toward a theory of robust estimation; it treats in detail the asymptotic theory of estimating a location parameter for contaminated normal distributions, and exhibits estimators--intermediaries between sample mean and sample median--that are asymptotically most robust (in a sense to be specified) among all translation invariant estimators. For the general background, see Tukey (1960) (p. 448 ff.) Let x1,{$\cdots$},xnx\_1, \textbackslash cdots, x\_n be independent random variables with common distribution function F(t-{$\xi$})F(t - \textbackslash xi). The problem is to estimate the location parameter {$\xi\backslash$}xi, but with the complication that the prototype distribution F(t)F(t) is only approximately known. I shall primarily be concerned with the model of indeterminacy F=(1-{$\epsilon$}){$\Phi$}+{$\epsilon$}HF = (1 - \textbackslash epsilon)\textbackslash Phi + \textbackslash epsilon H, where 0{$\leqq\epsilon<$}10 \textbackslash leqq \textbackslash epsilon {$<$} 1 is a known number, {$\Phi$}(t)=(2{$\pi$})-12{$\int$}t-{$\infty$}exp(-12s2)ds\textbackslash Phi(t) = (2\textbackslash pi)\^\{-\textbackslash frac\{1\}\{2\}\} \textbackslash int\^t\_\{-\textbackslash infty\} \textbackslash exp(-\textbackslash frac\{1\}\{2\}s\^2) ds is the standard normal cumulative and HH is an unknown contaminating distribution. This model arises for instance if the observations are assumed to be normal with variance 1, but a fraction {$\epsilon\backslash$}epsilon of them is affected by gross errors. Later on, I shall also consider other models of indeterminacy, e.g., supt|F(t)-{$\Phi$}(t)|{$\leqq\epsilon\backslash$}sup\_t |F(t) - \textbackslash Phi(t)| \textbackslash leqq \textbackslash epsilon. Some inconvenience is caused by the fact that location and scale parameters are not uniquely determined: in general, for fixed {$\epsilon\backslash$}epsilon, there will be several values of {$\xi\backslash$}xi and {$\sigma\backslash$}sigma such that supt|F(t)-{$\Phi$}((t-{$\xi$})/{$\sigma$})|{$\leqq\epsilon\backslash$}sup\_t|F(t) - \textbackslash Phi((t - \textbackslash xi)/\textbackslash sigma)| \textbackslash leqq \textbackslash epsilon, and similarly for the contaminated case. Although this inherent and unavoidable indeterminacy is small if {$\epsilon\backslash$}epsilon is small and is rather irrelevant for practical purposes, it poses awkward problems for the theory, especially for optimality questions. To remove this difficulty, one may either (i) restrict attention to symmetric distributions, and estimate the location of the center of symmetry (this works for {$\xi\backslash$}xi but not for {$\sigma\backslash$}sigma); or (ii) one may define the parameter to be estimated in terms of the estimator itself, namely by its asymptotic value for sample size n\textrightarrow{$\infty$}n \textbackslash rightarrow \textbackslash infty; or (iii) one may define the parameters by arbitrarily chosen functionals of the distribution (e.g., by the expectation, or the median of FF). All three possibilities have unsatisfactory aspects, and I shall usually choose the variant which is mathematically most convenient. It is interesting to look back to the very origin of the theory of estimation, namely to Gauss and his theory of least squares. Gauss was fully aware that his main reason for assuming an underlying normal distribution and a quadratic loss function was mathematical, i.e., computational, convenience. In later times, this was often forgotten, partly because of the central limit theorem. However, if one wants to be honest, the central limit theorem can at most explain why many distributions occurring in practice are approximately normal. The stress is on the word "approximately." This raises a question which could have been asked already by Gauss, but which was, as far as I know, only raised a few years ago (notably by Tukey): What happens if the true distribution deviates slightly from the assumed normal one? As is now well known, the sample mean then may have a catastrophically bad performance: seemingly quite mild deviations may already explode its variance. Tukey and others proposed several more robust substitutes--trimmed means, Winsorized means, etc.--and explored their performance for a few typical violations of normality. A general theory of robust estimation is still lacking; it is hoped that the present paper will furnish the first few steps toward such a theory. At the core of the method of least squares lies the idea to minimize the sum of the squared "errors," that is, to adjust the unknown parameters such that the sum of the squares of the differences between observed and computed values is minimized. In the simplest case, with which we are concerned here, namely the estimation of a location parameter, one has to minimize the expression {$\sum$}i(xi-T)2\textbackslash sum\_i (x\_i - T)\^2; this is of course achieved by the sample mean T={$\sum$}ixi/nT = \textbackslash sum\_i x\_i/n. I should like to emphasize that no loss function is involved here; I am only describing how the least squares estimator is defined, and neither the underlying family of distributions nor the true value of the parameter to be estimated enters so far. It is quite natural to ask whether one can obtain more robustness by minimizing another function of the errors than the sum of their squares. We shall therefore concentrate our attention to estimators that can be defined by a minimum principle of the form (for a location parameter): T=Tn(x1,{$\cdots$},xn)minimizes{$\sum$}i{$\rho$}(xi-T),T = T\_n(x\_1, \textbackslash cdots, x\_n) minimizes \textbackslash sum\_i \textbackslash rho(x\_i - T), where{$\rho$}isanon-constantfunction.\textbackslash begin\{equation*\} \textbackslash tag\{M\} where \textbackslash rho is a non-constant function. \textbackslash end\{equation*\} Of course, this definition generalizes at once to more general least squares type problems, where several parameters have to be determined. This class of estimators contains in particular (i) the sample mean ({$\rho$}(t)=t2)(\textbackslash rho(t) = t\^2), (ii) the sample median ({$\rho$}(t)=|t|)(\textbackslash rho(t) = |t|), and more generally, (iii) all maximum likelihood estimators ({$\rho$}(t)=-logf(t)(\textbackslash rho(t) = -\textbackslash log f(t), where ff is the assumed density of the untranslated distribution). These (MM)-estimators, as I shall call them for short, have rather pleasant asymptotic properties; sufficient conditions for asymptotic normality and an explicit expression for their asymptotic variance will be given. How should one judge the robustness of an estimator Tn(x)=Tn(x1,{$\cdots$},xn)T\_n(x) = T\_n(x\_1, \textbackslash cdots, x\_n)? Since ill effects from contamination are mainly felt for large sample sizes, it seems that one should primarily optimize large sample robustness properties. Therefore, a convenient measure of robustness for asymptotically normal estimators seems to be the supremum of the asymptotic variance (n\textrightarrow{$\infty$})(n \textbackslash rightarrow \textbackslash infty) when FF ranges over some suitable set of underlying distributions, in particular over the set of all F=(1-{$\epsilon$}){$\Phi$}+{$\epsilon$}HF = (1 - \textbackslash epsilon)\textbackslash Phi + \textbackslash epsilon H for fixed {$\epsilon\backslash$}epsilon and symmetric HH. On second thought, it turns out that the asymptotic variance is not only easier to handle, but that even for moderate values of nn it is a better measure of performance than the actual variance, because (i) the actual variance of an estimator depends very much on the behavior of the tails of HH, and the supremum of the actual variance is infinite for any estimator whose value is always contained in the convex hull of the observations. (ii) If an estimator is asymptotically normal, then the important central part of its distribution and confidence intervals for moderate confidence levels can better be approximated in terms of the asymptotic variance than in terms of the actual variance. If we adopt this measure of robustness, and if we restrict attention to (MM)-estimators, then it will be shown that the most robust estimator is uniquely determined and corresponds to the following {$\rho$}:{$\rho$}(t)=12t2\textbackslash rho:\textbackslash rho(t) = \textbackslash frac\{1\}\{2\}t\^2 for |t|},
  file = {/Users/yuekai/Documents/zotero/Huber (1964) - Robust Estimation of a Location Parameter.pdf},
  journal = {The Annals of Mathematical Statistics},
  language = {EN},
  mrnumber = {MR161415},
  number = {1},
  zmnumber = {0136.39805}
}

@book{huber2009Robust,
  title = {Robust Statistics},
  author = {Huber, Peter J. and Ronchetti, Elvezio},
  year = {2009},
  edition = {2nd ed},
  publisher = {{Wiley}},
  address = {{Hoboken, N.J}},
  annotation = {OCLC: ocn236325889},
  file = {/Users/yuekai/Documents/zotero/Huber, Ronchetti (2009) - Robust statistics.pdf},
  isbn = {978-0-470-12990-6},
  language = {en},
  lccn = {QA276 .H785 2009},
  series = {Wiley Series in Probability and Statistics}
}

@article{hung2019Statistical,
  title = {Statistical {{Methods}} for {{Replicability Assessment}}},
  author = {Hung, Kenneth and Fithian, William},
  year = {2019},
  month = mar,
  abstract = {Large-scale replication studies like the Reproducibility Project: Psychology (RP:P) provide invaluable systematic data on scientific replicability, but most analyses and interpretations of the data fail to agree on the definition of "replicability" and disentangle the inexorable consequences of known selection bias from competing explanations. We discuss three concrete definitions of replicability based on (1) whether published findings about the signs of effects are mostly correct, (2) how effective replication studies are in reproducing whatever true effect size was present in the original experiment, and (3) whether true effect sizes tend to diminish in replication. We apply techniques from multiple testing and post-selection inference to develop new methods that answer these questions while explicitly accounting for selection bias. Re-analyzing the RP:P data, we estimate that 22 out of 68 (32\%) original directional claims were false (upper confidence bound 47\%); by comparison, we estimate that among claims significant at the stricter significance threshold 0.005, only 2.2 out of 33 (7\%) were directionally false (upper confidence bound 18\%). In addition, we compute selection-adjusted confidence intervals for the difference in effect size between original and replication studies and, after adjusting for multiplicity, identify five (11\%) which exclude zero (exact replication). We estimate that the effect size declined by at least 20\% in the replication study relative to the original study in 16 of the 46 (35\%) study pairs (lower confidence bound 11\%). Our methods make no distributional assumptions about the true effect sizes.},
  archivePrefix = {arXiv},
  eprint = {1903.08747},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Hung, Fithian (2019) - Statistical Methods for Replicability Assessment.pdf},
  journal = {arXiv:1903.08747 [stat]},
  keywords = {Statistics - Applications,Statistics - Methodology},
  primaryClass = {stat}
}

@book{hunter2001Applied,
  title = {Applied {{Analysis}}},
  author = {Hunter, John K. and Nachtergaele, Bruno},
  year = {2001},
  publisher = {{World Scientific}},
  abstract = {This book provides an introduction to those parts of analysis that are most useful in applications for graduate students. The material is selected for use in applied problems, and is presented clearly and simply but without sacrificing mathematical rigor.The text is accessible to students from a wide variety of backgrounds, including undergraduate students entering applied mathematics from non-mathematical fields and graduate students in the sciences and engineering who want to learn analysis. A basic background in calculus, linear algebra and ordinary differential equations, as well as some familiarity with functions and sets, should be sufficient.},
  file = {/Users/yuekai/Documents/zotero/Hunter, Nachtergaele (2001) - Applied Analysis.pdf},
  googlebooks = {oOYQVeHmNk4C},
  isbn = {978-981-02-4191-9},
  language = {en}
}

@article{hyttinen2012Learning,
  title = {Learning {{Linear Cyclic Causal Models}} with {{Latent Variables}}},
  author = {Hyttinen, Antti and Eberhardt, Frederick and Hoyer, Patrik O.},
  year = {2012},
  volume = {13},
  pages = {3387--3439},
  issn = {ISSN 1533-7928},
  file = {/Users/yuekai/Documents/zotero/Hyttinen et al (2012) - Learning Linear Cyclic Causal Models with Latent Variables.pdf},
  journal = {Journal of Machine Learning Research},
  number = {Nov}
}

@inproceedings{ibrahim2018Imbalanced,
  title = {Imbalanced {{Toxic Comments Classification Using Data Augmentation}} and {{Deep Learning}}},
  booktitle = {2018 17th {{IEEE International Conference}} on {{Machine Learning}} and {{Applications}} ({{ICMLA}})},
  author = {Ibrahim, Mai and Torki, Marwan and {El-Makky}, Nagwa},
  year = {2018},
  month = dec,
  pages = {875--878},
  issn = {null},
  doi = {10.1109/ICMLA.2018.00141},
  abstract = {Recently cyber-bullying and online harassment have become two of the most serious issues in many public online communities. In this paper, we use data from Wikipedia talk page edits to train multi-label classifier that detects different types of toxicity in online user-generated content. We present different data augmentation techniques to overcome the data imbalance problem in the Wikipedia dataset. The proposed solution is an ensemble of three models: convolutional neural network (CNN), bidirectional long short-term memory (LSTM) and bidirectional gated recurrent units (GRU). We divide the classification problem into two steps, first we determine whether or not the input is toxic then we find the types of toxicity present in the toxic content. The evaluation results show that the proposed ensemble approach provides the highest accuracy among all considered algorithms. It achieves 0.828 F1-score for toxic/non-toxic classification and 0.872 for toxicity types prediction.},
  file = {/Users/yuekai/Documents/zotero/Ibrahim et al (2018) - Imbalanced Toxic Comments Classification Using Data Augmentation and Deep.pdf;/Users/yuekai/Zotero/storage/R74CDK7Q/8614166.html}
}

@article{ichimura1993Semiparametric,
  title = {Semiparametric Least Squares ({{SLS}}) and Weighted {{SLS}} Estimation of Single-Index Models},
  author = {Ichimura, Hidehiko},
  year = {1993},
  month = jul,
  volume = {58},
  pages = {71--120},
  issn = {03044076},
  doi = {10.1016/0304-4076(93)90114-K},
  file = {/Users/yuekai/Documents/zotero/Ichimura (1993) - Semiparametric least squares (SLS) and weighted SLS estimation of single-index2.pdf},
  journal = {Journal of Econometrics},
  language = {en},
  number = {1-2}
}

@article{ilvento2019Metric,
  title = {Metric {{Learning}} for {{Individual Fairness}}},
  author = {Ilvento, Christina},
  year = {2019},
  month = jun,
  abstract = {There has been much discussion recently about how fairness should be measured or enforced in classification. Individual Fairness [Dwork, Hardt, Pitassi, Reingold, Zemel, 2012], which requires that similar individuals be treated similarly, is a highly appealing definition as it gives strong guarantees on treatment of individuals. Unfortunately, the need for a task-specific similarity metric has prevented its use in practice. In this work, we propose a solution to the problem of approximating a metric for Individual Fairness based on human judgments. Our model assumes that we have access to a human fairness arbiter, who can answer a limited set of queries concerning similarity of individuals for a particular task, is free of explicit biases and possesses sufficient domain knowledge to evaluate similarity. Our contributions include definitions for metric approximation relevant for Individual Fairness, constructions for approximations from a limited number of realistic queries to the arbiter on a sample of individuals, and learning procedures to construct hypotheses for metric approximations which generalize to unseen samples under certain assumptions of learnability of distance threshold functions.},
  archivePrefix = {arXiv},
  eprint = {1906.00250},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ilvento (2019) - Metric Learning for Individual Fairness.pdf},
  journal = {arXiv:1906.00250 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{ilyas2018Blackbox,
  title = {Black-Box {{Adversarial Attacks}} with {{Limited Queries}} and {{Information}}},
  author = {Ilyas, Andrew and Engstrom, Logan and Athalye, Anish and Lin, Jessy},
  year = {2018},
  month = apr,
  abstract = {Current neural network-based classifiers are susceptible to adversarial examples even in the black-box setting, where the attacker only has query access to the model. In practice, the threat model for real-world systems is often more restrictive than the typical black-box model where the adversary can observe the full output of the network on arbitrarily many chosen inputs. We define three realistic threat models that more accurately characterize many real-world classifiers: the query-limited setting, the partial-information setting, and the label-only setting. We develop new attacks that fool classifiers under these more restrictive threat models, where previous methods would be impractical or ineffective. We demonstrate that our methods are effective against an ImageNet classifier under our proposed threat models. We also demonstrate a targeted black-box attack against a commercial classifier, overcoming the challenges of limited query access, partial information, and other practical issues to break the Google Cloud Vision API.},
  archivePrefix = {arXiv},
  eprint = {1804.08598},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ilyas et al (2018) - Black-box Adversarial Attacks with Limited Queries and Information.pdf},
  journal = {arXiv:1804.08598 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Cryptography and Security,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{ilyas2019Adversarial,
  title = {Adversarial {{Examples Are Not Bugs}}, {{They Are Features}}},
  author = {Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
  year = {2019},
  month = may,
  abstract = {Adversarial examples have attracted significant attention in machine learning, but the reasons for their existence and pervasiveness remain unclear. We demonstrate that adversarial examples can be directly attributed to the presence of non-robust features: features derived from patterns in the data distribution that are highly predictive, yet brittle and incomprehensible to humans. After capturing these features within a theoretical framework, we establish their widespread existence in standard datasets. Finally, we present a simple setting where we can rigorously tie the phenomena we observe in practice to a misalignment between the (human-specified) notion of robustness and the inherent geometry of the data.},
  archivePrefix = {arXiv},
  eprint = {1905.02175},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ilyas et al (2019) - Adversarial Examples Are Not Bugs, They Are Features.pdf},
  journal = {arXiv:1905.02175 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{imbens2019Potential,
  title = {Potential {{Outcome}} and {{Directed Acyclic Graph Approaches}} to {{Causality}}: {{Relevance}} for {{Empirical Practice}} in {{Economics}}},
  shorttitle = {Potential {{Outcome}} and {{Directed Acyclic Graph Approaches}} to {{Causality}}},
  author = {Imbens, Guido W.},
  year = {2019},
  month = jul,
  abstract = {In this essay I discuss potential outcome and graphical approaches to causality, and their relevance for empirical work in economics. I review some of the work on directed acyclic graphs, including the recent "The Book of Why," by Pearl and MacKenzie. I also discuss the potential outcome framework developed by Rubin and coauthors, building on work by Neyman. I then discuss the relative merits of these approaches for empirical work in economics, focusing on the questions each answer well, and why much of the the work in economics is closer in spirit to the potential outcome framework.},
  archivePrefix = {arXiv},
  eprint = {1907.07271},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Imbens (2019) - Potential Outcome and Directed Acyclic Graph Approaches to Causality.pdf},
  journal = {arXiv:1907.07271 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@incollection{ishida2018Binary,
  title = {Binary {{Classification}} from {{Positive}}-{{Confidence Data}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 31},
  author = {Ishida, Takashi and Niu, Gang and Sugiyama, Masashi},
  editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and {Cesa-Bianchi}, N. and Garnett, R.},
  year = {2018},
  pages = {5917--5928},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/yuekai/Documents/zotero/Ishida et al (2018) - Binary Classification from Positive-Confidence Data.pdf}
}

@inproceedings{iyer2014Maximum,
  title = {Maximum {{Mean Discrepancy}} for {{Class Ratio Estimation}}: {{Convergence Bounds}} and {{Kernel Selection}}},
  shorttitle = {Maximum {{Mean Discrepancy}} for {{Class Ratio Estimation}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Iyer, Arun and Nath, Saketha and Sarawagi, Sunita},
  year = {2014},
  month = jan,
  pages = {530--538},
  issn = {1938-7228},
  abstract = {In recent times, many real world applications have emerged that require estimates of class ratios in an unlabeled instance collection as opposed to labels of individual instances in the collection....},
  chapter = {Machine Learning},
  file = {/Users/yuekai/Documents/zotero/Iyer et al (2014) - Maximum Mean Discrepancy for Class Ratio Estimation.pdf;/Users/yuekai/Zotero/storage/3JL2EJM3/iyer14.html},
  language = {en}
}

@inproceedings{iyyer2015Deep,
  title = {Deep {{Unordered Composition Rivals Syntactic Methods}} for {{Text Classification}}},
  booktitle = {Proceedings of the 53rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 7th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 1: {{Long Papers}})},
  author = {Iyyer, Mohit and Manjunatha, Varun and {Boyd-Graber}, Jordan and Daum{\'e} III, Hal},
  year = {2015},
  pages = {1681--1691},
  publisher = {{Association for Computational Linguistics}},
  address = {{Beijing, China}},
  doi = {10.3115/v1/P15-1162},
  abstract = {Many existing deep learning models for natural language processing tasks focus on learning the compositionality of their inputs, which requires many expensive computations. We present a simple deep neural network that competes with and, in some cases, outperforms such models on sentiment analysis and factoid question answering tasks while taking only a fraction of the training time. While our model is syntactically-ignorant, we show significant improvements over previous bag-of-words models by deepening our network and applying a novel variant of dropout. Moreover, our model performs better than syntactic models on datasets with high syntactic variance. We show that our model makes similar errors to syntactically-aware models, indicating that for the tasks we consider, nonlinearly transforming the input is more important than tailoring a network to incorporate word order and syntax.},
  file = {/Users/yuekai/Documents/zotero/Iyyer et al (2015) - Deep Unordered Composition Rivals Syntactic Methods for Text Classification.pdf},
  language = {en}
}

@article{izbicki2016Nonparametric,
  title = {Nonparametric {{Conditional Density Estimation}} in a {{High}}-{{Dimensional Regression Setting}}},
  author = {Izbicki, Rafael and Lee, Ann B.},
  year = {2016},
  month = oct,
  volume = {25},
  pages = {1297--1316},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.2015.1094393},
  file = {/Users/yuekai/Documents/zotero/Izbicki, Lee (2016) - Nonparametric Conditional Density Estimation in a High-Dimensional Regression.pdf},
  journal = {Journal of Computational and Graphical Statistics},
  language = {en},
  number = {4}
}

@article{izmailov2018Averaging,
  title = {Averaging {{Weights Leads}} to {{Wider Optima}} and {{Better Generalization}}},
  author = {Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
  year = {2018},
  month = mar,
  abstract = {Deep neural networks are typically trained by optimizing a loss function with an SGD variant, in conjunction with a decaying learning rate, until convergence. We show that simple averaging of multiple points along the trajectory of SGD, with a cyclical or constant learning rate, leads to better generalization than conventional training. We also show that this Stochastic Weight Averaging (SWA) procedure finds much flatter solutions than SGD, and approximates the recent Fast Geometric Ensembling (FGE) approach with a single model. Using SWA we achieve notable improvement in test accuracy over conventional SGD training on a range of state-of-the-art residual networks, PyramidNets, DenseNets, and Shake-Shake networks on CIFAR-10, CIFAR-100, and ImageNet. In short, SWA is extremely easy to implement, improves generalization, and has almost no computational overhead.},
  archivePrefix = {arXiv},
  eprint = {1803.05407},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Izmailov et al (2018) - Averaging Weights Leads to Wider Optima and Better Generalization.pdf},
  journal = {arXiv:1803.05407 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{jabbari2016Fairness,
  title = {Fairness in {{Reinforcement Learning}}},
  author = {Jabbari, Shahin and Joseph, Matthew and Kearns, Michael and Morgenstern, Jamie and Roth, Aaron},
  year = {2016},
  month = nov,
  abstract = {We initiate the study of fairness in reinforcement learning, where the actions of a learning algorithm may affect its environment and future rewards. Our fairness constraint requires that an algorithm never prefers one action over another if the long-term (discounted) reward of choosing the latter action is higher. Our first result is negative: despite the fact that fairness is consistent with the optimal policy, any learning algorithm satisfying fairness must take time exponential in the number of states to achieve non-trivial approximation to the optimal policy. We then provide a provably fair polynomial time algorithm under an approximate notion of fairness, thus establishing an exponential gap between exact and approximate fairness},
  archivePrefix = {arXiv},
  eprint = {1611.03071},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jabbari et al (2016) - Fairness in Reinforcement Learning.pdf},
  journal = {arXiv:1611.03071 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{jacobs2019Measurement,
  title = {Measurement and {{Fairness}}},
  author = {Jacobs, Abigail Z. and Wallach, Hanna},
  year = {2019},
  month = dec,
  abstract = {We introduce the language of measurement modeling from the quantitative social sciences as a framework for understanding fairness in computational systems. Computational systems often involve unobservable theoretical constructs, such as "creditworthiness," "teacher quality," or "risk to society," that cannot be measured directly and must instead be inferred from observable properties thought to be related to them---i.e., operationalized via a measurement model. This process introduces the potential for mismatch between the theoretical understanding of the construct purported to be measured and its operationalization. Indeed, we argue that many of the harms discussed in the literature on fairness in computational systems are direct results of such mismatches. Further complicating these discussions is the fact that fairness itself is an unobservable theoretical construct. Moreover, it is an essentially contested construct---i.e., it has many different theoretical understandings depending on the context. We argue that this contestedness underlies recent debates about fairness definitions: disagreements that appear to be about contradictory operationalizations are, in fact, disagreements about different theoretical understandings of the construct itself. By introducing the language of measurement modeling, we provide the computer science community with a process for making explicit and testing assumptions about unobservable theoretical constructs, thereby making it easier to identify, characterize, and even mitigate fairness-related harms.},
  archivePrefix = {arXiv},
  eprint = {1912.05511},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jacobs, Wallach (2019) - Measurement and Fairness.pdf},
  journal = {arXiv:1912.05511 [cs]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{jacot2018Neural,
  title = {Neural {{Tangent Kernel}}: {{Convergence}} and {{Generalization}} in {{Neural Networks}}},
  shorttitle = {Neural {{Tangent Kernel}}},
  author = {Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  year = {2018},
  month = jun,
  abstract = {At initialization, artificial neural networks (ANNs) are equivalent to Gaussian processes in the infinite-width limit, thus connecting them to kernel methods. We prove that the evolution of an ANN during training can also be described by a kernel: during gradient descent on the parameters of an ANN, the network function \$f\_\textbackslash theta\$ (which maps input vectors to output vectors) follows the kernel gradient of the functional cost (which is convex, in contrast to the parameter cost) w.r.t. a new kernel: the Neural Tangent Kernel (NTK). This kernel is central to describe the generalization features of ANNs. While the NTK is random at initialization and varies during training, in the infinite-width limit it converges to an explicit limiting kernel and it stays constant during training. This makes it possible to study the training of ANNs in function space instead of parameter space. Convergence of the training can then be related to the positive-definiteness of the limiting NTK. We prove the positive-definiteness of the limiting NTK when the data is supported on the sphere and the non-linearity is non-polynomial. We then focus on the setting of least-squares regression and show that in the infinite-width limit, the network function \$f\_\textbackslash theta\$ follows a linear differential equation during training. The convergence is fastest along the largest kernel principal components of the input data with respect to the NTK, hence suggesting a theoretical motivation for early stopping. Finally we study the NTK numerically, observe its behavior for wide networks, and compare it to the infinite-width limit.},
  archivePrefix = {arXiv},
  eprint = {1806.07572},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jacot et al (2018) - Neural Tangent Kernel.pdf},
  journal = {arXiv:1806.07572 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Mathematics - Probability,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{jagielski2018Differentially,
  title = {Differentially {{Private Fair Learning}}},
  author = {Jagielski, Matthew and Kearns, Michael and Mao, Jieming and Oprea, Alina and Roth, Aaron and {Sharifi-Malvajerdi}, Saeed and Ullman, Jonathan},
  year = {2018},
  month = dec,
  abstract = {We design two learning algorithms that simultaneously promise differential privacy and equalized odds, a 'fairness' condition that corresponds to equalizing false positive and negative rates across protected groups. Our first algorithm is a simple private implementation of the post-processing approach of [Hardt et al. 2016]. This algorithm has the merit of being exceedingly simple, but must be able to use protected group membership explicitly at test time, which can be viewed as 'disparate treatment'. The second algorithm is a differentially private version of the algorithm of [Agarwal et al. 2018], an oracle-efficient algorithm that can be used to find the optimal fair classifier, given access to a subroutine that can solve the original (not necessarily fair) learning problem. This algorithm need not have access to protected group membership at test time. We identify new tradeoffs between fairness, accuracy, and privacy that emerge only when requiring all three properties, and show that these tradeoffs can be milder if group membership may be used at test time.},
  archivePrefix = {arXiv},
  eprint = {1812.02696},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jagielski et al (2018) - Differentially Private Fair Learning.pdf},
  journal = {arXiv:1812.02696 [cs, stat]},
  keywords = {Computer Science - Computer Science and Game Theory,Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{jahanian2019steerability,
  title = {On the "Steerability" of Generative Adversarial Networks},
  author = {Jahanian, Ali and Chai, Lucy and Isola, Phillip},
  year = {2019},
  month = oct,
  abstract = {An open secret in contemporary machine learning is that many models work beautifully on standard benchmarks but fail to generalize outside the lab. This has been attributed to biased training data, which provide poor coverage over real world events. Generative models are no exception, but recent advances in generative adversarial networks (GANs) suggest otherwise - these models can now synthesize strikingly realistic and diverse images. Is generative modeling of photos a solved problem? We show that although current GANs can fit standard datasets very well, they still fall short of being comprehensive models of the visual manifold. In particular, we study their ability to fit simple transformations such as camera movements and color changes. We find that the models reflect the biases of the datasets on which they are trained (e.g., centered objects), but that they also exhibit some capacity for generalization: by "steering" in latent space, we can shift the distribution while still creating realistic images. We hypothesize that the degree of distributional shift is related to the breadth of the training data distribution. Thus, we conduct experiments to quantify the limits of GAN transformations and introduce techniques to mitigate the problem. Code is released on our project page: https://ali-design.github.io/gan\_steerability/},
  archivePrefix = {arXiv},
  eprint = {1907.07171},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jahanian et al (2019) - On the steerability of generative adversarial networks.pdf},
  journal = {arXiv:1907.07171 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@incollection{jain2016Estimating,
  title = {Estimating the Class Prior and Posterior from Noisy Positives and Unlabeled Data},
  booktitle = {Advances in {{Neural Information Processing Systems}} 29},
  author = {Jain, Shantanu and White, Martha and Radivojac, Predrag},
  editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
  year = {2016},
  pages = {2693--2701},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/yuekai/Documents/zotero/Jain et al (2016) - Estimating the class prior and posterior from noisy positives and unlabeled data.pdf;/Users/yuekai/Zotero/storage/BU9QFQB7/6168-estimating-the-class-prior-and-posterior-from-noisy-positives-and-unlabeled-data.html}
}

@article{jain2016Finite,
  title = {Finite {{Sample Prediction}} and {{Recovery Bounds}} for {{Ordinal Embedding}}},
  author = {Jain, Lalit and Jamieson, Kevin and Nowak, Robert},
  year = {2016},
  month = jun,
  abstract = {The goal of ordinal embedding is to represent items as points in a low-dimensional Euclidean space given a set of constraints in the form of distance comparisons like "item \$i\$ is closer to item \$j\$ than item \$k\$". Ordinal constraints like this often come from human judgments. To account for errors and variation in judgments, we consider the noisy situation in which the given constraints are independently corrupted by reversing the correct constraint with some probability. This paper makes several new contributions to this problem. First, we derive prediction error bounds for ordinal embedding with noise by exploiting the fact that the rank of a distance matrix of points in \$\textbackslash mathbb\{R\}\^d\$ is at most \$d+2\$. These bounds characterize how well a learned embedding predicts new comparative judgments. Second, we investigate the special case of a known noise model and study the Maximum Likelihood estimator. Third, knowledge of the noise model enables us to relate prediction errors to embedding accuracy. This relationship is highly non-trivial since we show that the linear map corresponding to distance comparisons is non-invertible, but there exists a nonlinear map that is invertible. Fourth, two new algorithms for ordinal embedding are proposed and evaluated in experiments.},
  archivePrefix = {arXiv},
  eprint = {1606.07081},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jain et al (2016) - Finite Sample Prediction and Recovery Bounds for Ordinal Embedding2.pdf},
  journal = {arXiv:1606.07081 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{jalal2017Robust,
  title = {The {{Robust Manifold Defense}}: {{Adversarial Training}} Using {{Generative Models}}},
  shorttitle = {The {{Robust Manifold Defense}}},
  author = {Jalal, Ajil and Ilyas, Andrew and Daskalakis, Constantinos and Dimakis, Alexandros G.},
  year = {2017},
  month = dec,
  abstract = {We propose a new type of attack for finding adversarial examples for image classifiers. Our method exploits spanners, i.e. deep neural networks whose input space is low-dimensional and whose output range approximates the set of images of interest. Spanners may be generators of GANs or decoders of VAEs. The key idea in our attack is to search over latent code pairs to find ones that generate nearby images with different classifier outputs. We argue that our attack is stronger than searching over perturbations of real images. Moreover, we show that our stronger attack can be used to reduce the accuracy of Defense-GAN to 3\textbackslash\%, resolving an open problem from the well-known paper by Athalye et al. We combine our attack with normal adversarial training to obtain the most robust known MNIST classifier, significantly improving the state of the art against PGD attacks. Our formulation involves solving a min-max problem, where the min player sets the parameters of the classifier and the max player is running our attack, and is thus searching for adversarial examples in the \{\textbackslash em low-dimensional\} input space of the spanner. All code and models are available at \textbackslash url\{https://github.com/ajiljalal/manifold-defense.git\}},
  archivePrefix = {arXiv},
  eprint = {1712.09196},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jalal et al (2017) - The Robust Manifold Defense.pdf},
  journal = {arXiv:1712.09196 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{jamieson2011Lowdimensional,
  title = {Low-Dimensional Embedding Using Adaptively Selected Ordinal Data},
  booktitle = {2011 49th {{Annual Allerton Conference}} on {{Communication}}, {{Control}}, and {{Computing}} ({{Allerton}})},
  author = {Jamieson, K. G. and Nowak, R. D.},
  year = {2011},
  month = sep,
  pages = {1077--1084},
  doi = {10.1109/Allerton.2011.6120287},
  abstract = {Low-dimensional embedding based on non-metric data (e.g., non-metric multidimensional scaling) is a problem that arises in many applications, especially those involving human subjects. This paper investigates the problem of learning an embedding of n objects into d-dimensional Euclidean space that is consistent with pairwise comparisons of the type "object a is closer to object b than c." While there are O(n3) such comparisons, experimental studies suggest that relatively few are necessary to uniquely determine the embedding up to the constraints imposed by all possible pairwise comparisons (i.e., the problem is typically over-constrained). This paper is concerned with quantifying the minimum number of pairwise comparisons necessary to uniquely determine an embedding up to all possible comparisons. The comparison constraints stipulate that, with respect to each object, the other objects are ranked relative to their proximity. We prove that at least {$\Omega$}(dnlogn) pairwise comparisons are needed to determine the embedding of all n objects. The lower bounds cannot be achieved by using randomly chosen pairwise comparisons. We propose an algorithm that exploits the low-dimensional geometry in order to accurately embed objects based on relatively small number of sequentially selected pairwise comparisons and demonstrate its performance with experiments.},
  file = {/Users/yuekai/Documents/zotero/Jamieson, Nowak (2011) - Low-dimensional embedding using adaptively selected ordinal data.pdf;/Users/yuekai/Zotero/storage/QXSZRG38/6120287.html}
}

@article{jankova2016Semiparametric,
  title = {Semi-Parametric Efficiency Bounds for High-Dimensional Models},
  author = {Jankova, Jana and {van de Geer}, Sara},
  year = {2016},
  month = jan,
  abstract = {Asymptotic lower bounds for estimation play a fundamental role in assessing the quality of statistical procedures. In this paper we propose a framework for obtaining semi-parametric efficiency bounds for sparse high-dimensional models, where the dimension of the parameter is larger than the sample size. We adopt a semi-parametric point of view: we concentrate on one dimensional functions of a high-dimensional parameter. We follow two different approaches to reach the lower bounds: asymptotic Cram\textbackslash 'er-Rao bounds and Le Cam's type of analysis. Both these approaches allow us to define a class of asymptotically unbiased or "regular" estimators for which a lower bound is derived. Consequently, we show that certain estimators obtained by de-sparsifying (or de-biasing) an \$\textbackslash ell\_1\$-penalized M-estimator are asymptotically unbiased and achieve the lower bound on the variance: thus in this sense they are asymptotically efficient. The paper discusses in detail the linear regression model and the Gaussian graphical model.},
  archivePrefix = {arXiv},
  eprint = {1601.00815},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jankova, van de Geer (2016) - Semi-parametric efficiency bounds for high-dimensional models.pdf},
  journal = {arXiv:1601.00815 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{jankova2018Debiased,
  title = {De-Biased Sparse {{PCA}}: {{Inference}} and Testing for Eigenstructure of Large Covariance Matrices},
  shorttitle = {De-Biased Sparse {{PCA}}},
  author = {Jankov{\'a}, Jana and {van de Geer}, Sara},
  year = {2018},
  month = jan,
  abstract = {Sparse principal component analysis (sPCA) has become one of the most widely used techniques for dimensionality reduction in high-dimensional datasets. The main challenge underlying sPCA is to estimate the first vector of loadings of the population covariance matrix, provided that only a certain number of loadings are non-zero. In this paper, we propose confidence intervals for individual loadings and for the largest eigenvalue of the population covariance matrix. Given an independent sample \$X\^i \textbackslash in\textbackslash mathbb R\^p, i = 1,...,n,\$ generated from an unknown distribution with an unknown covariance matrix \$\textbackslash Sigma\_0\$, our aim is to estimate the first vector of loadings and the largest eigenvalue of \$\textbackslash Sigma\_0\$ in a setting where \$p\textbackslash gg n\$. Next to the high-dimensionality, another challenge lies in the inherent non-convexity of the problem. We base our methodology on a Lasso-penalized M-estimator which, despite non-convexity, may be solved by a polynomial-time algorithm such as coordinate or gradient descent. We show that our estimator achieves the minimax optimal rates in \$\textbackslash ell\_1\$ and \$\textbackslash ell\_2\$-norm. We identify the bias in the Lasso-based estimator and propose a de-biased sparse PCA estimator for the vector of loadings and for the largest eigenvalue of the covariance matrix \$\textbackslash Sigma\_0\$. Our main results provide theoretical guarantees for asymptotic normality of the de-biased estimator. The major conditions we impose are sparsity in the first eigenvector of small order \$\textbackslash sqrt\{n\}/\textbackslash log p\$ and sparsity of the same order in the columns of the inverse Hessian matrix of the population risk.},
  archivePrefix = {arXiv},
  eprint = {1801.10567},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Janková, van de Geer (2018) - De-biased sparse PCA.pdf},
  journal = {arXiv:1801.10567 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{janzing2010Causal,
  title = {Causal {{Inference Using}} the {{Algorithmic Markov Condition}}},
  author = {Janzing, Dominik and Scholkopf, Bernhard},
  year = {2010},
  month = oct,
  volume = {56},
  pages = {5168--5194},
  issn = {0018-9448, 1557-9654},
  doi = {10.1109/TIT.2010.2060095},
  abstract = {Inferring the causal structure that links n observables is usually based upon detecting statistical dependences and choosing simple graphs that make the joint measure Markovian. Here we argue why causal inference is also possible when the sample size is one.},
  file = {/Users/yuekai/Documents/zotero/Janzing, Scholkopf (2010) - Causal Inference Using the Algorithmic Markov Condition.pdf},
  journal = {IEEE Transactions on Information Theory},
  language = {en},
  number = {10}
}

@incollection{janzing2019Causal,
  title = {Causal {{Regularization}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 32},
  author = {Janzing, Dominik},
  editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and d{\textbackslash}textquotesingle {Alch{\'e}-Buc}, F. and Fox, E. and Garnett, R.},
  year = {2019},
  pages = {12683--12693},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/yuekai/Documents/zotero/Janzing (2019) - Causal Regularization.pdf}
}

@article{javanmard2013Nearly,
  title = {Nearly {{Optimal Sample Size}} in {{Hypothesis Testing}} for {{High}}-{{Dimensional Regression}}},
  author = {Javanmard, Adel and Montanari, Andrea},
  year = {2013},
  month = nov,
  abstract = {We consider the problem of fitting the parameters of a high-dimensional linear regression model. In the regime where the number of parameters \$p\$ is comparable to or exceeds the sample size \$n\$, a successful approach uses an \$\textbackslash ell\_1\$-penalized least squares estimator, known as Lasso. Unfortunately, unlike for linear estimators (e.g., ordinary least squares), no well-established method exists to compute confidence intervals or p-values on the basis of the Lasso estimator. Very recently, a line of work \textbackslash cite\{javanmard2013hypothesis, confidenceJM, GBR-hypothesis\} has addressed this problem by constructing a debiased version of the Lasso estimator. In this paper, we study this approach for random design model, under the assumption that a good estimator exists for the precision matrix of the design. Our analysis improves over the state of the art in that it establishes nearly optimal \textbackslash emph\{average\} testing power if the sample size \$n\$ asymptotically dominates \$s\_0 (\textbackslash log p)\^2\$, with \$s\_0\$ being the sparsity level (number of non-zero coefficients). Earlier work obtains provable guarantees only for much larger sample size, namely it requires \$n\$ to asymptotically dominate \$(s\_0 \textbackslash log p)\^2\$. In particular, for random designs with a sparse precision matrix we show that an estimator thereof having the required properties can be computed efficiently. Finally, we evaluate this approach on synthetic data and compare it with earlier proposals.},
  archivePrefix = {arXiv},
  eprint = {1311.0274},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Javanmard, Montanari (2013) - Nearly Optimal Sample Size in Hypothesis Testing for High-Dimensional Regression.pdf},
  journal = {arXiv:1311.0274 [cs, math, stat]},
  keywords = {Computer Science - Information Theory,Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {cs, math, stat}
}

@article{javanmard2015Debiasing,
  title = {De-Biasing the {{Lasso}}: {{Optimal Sample Size}} for {{Gaussian Designs}}},
  shorttitle = {De-Biasing the {{Lasso}}},
  author = {Javanmard, Adel and Montanari, Andrea},
  year = {2015},
  month = aug,
  abstract = {Performing statistical inference in high-dimension is an outstanding challenge. A major source of difficulty is the absence of precise information on the distribution of high-dimensional estimators. Here, we consider linear regression in the high-dimensional regime \$p\textbackslash gg n\$. In this context, we would like to perform inference on a high-dimensional parameters vector \$\textbackslash theta\^*\textbackslash in\{\textbackslash mathbb R\}\^p\$. Important progress has been achieved in computing confidence intervals for single coordinates \$\textbackslash theta\^*\_i\$. A key role in these new methods is played by a certain debiased estimator \$\textbackslash hat\{\textbackslash theta\}\^\{\textbackslash rm d\}\$ that is constructed from the Lasso. Earlier work establishes that, under suitable assumptions on the design matrix, the coordinates of \$\textbackslash hat\{\textbackslash theta\}\^\{\textbackslash rm d\}\$ are asymptotically Gaussian provided \$\textbackslash theta\^*\$ is \$s\_0\$-sparse with \$s\_0 = o(\textbackslash sqrt\{n\}/\textbackslash log p )\$. The condition \$s\_0 = o(\textbackslash sqrt\{n\}/ \textbackslash log p )\$ is stronger than the one for consistent estimation, namely \$s\_0 = o(n/ \textbackslash log p)\$. We study Gaussian designs with known or unknown population covariance. When the covariance is known, we prove that the debiased estimator is asymptotically Gaussian under the nearly optimal condition \$s\_0 = o(n/ (\textbackslash log p)\^2)\$. Note that earlier work was limited to \$s\_0 = o(\textbackslash sqrt\{n\}/\textbackslash log p)\$ even for perfectly known covariance. The same conclusion holds if the population covariance is unknown but can be estimated sufficiently well, e.g. under the same sparsity conditions on the inverse covariance as assumed by earlier work. For intermediate regimes, we describe the trade-off between sparsity in the coefficients and in the inverse covariance of the design. We further discuss several applications of our results to high-dimensional inference. In particular, we propose a new estimator that is minimax optimal up to a factor \$1+o\_n(1)\$ for i.i.d. Gaussian designs.},
  archivePrefix = {arXiv},
  eprint = {1508.02757},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Javanmard, Montanari (2015) - De-biasing the Lasso.pdf},
  journal = {arXiv:1508.02757 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {math, stat}
}

@article{javanmard2016Dynamic,
  title = {Dynamic {{Pricing}} in {{High}}-Dimensions},
  author = {Javanmard, Adel and Nazerzadeh, Hamid},
  year = {2016},
  month = sep,
  abstract = {We study the pricing problem faced by a firm that sells a large number of products, described via a wide range of features, to customers that arrive over time. Customers independently make purchasing decisions according to a general choice model that includes products features and customers' characteristics, encoded as \$d\$-dimensional numerical vectors, as well as the price offered. The parameters of the choice model are a priori unknown to the firm, but can be learned as the (binary-valued) sales data accrues over time. The firm's objective is to minimize the regret, i.e., the expected revenue loss against a clairvoyant policy that knows the parameters of the choice model in advance, and always offers the revenue-maximizing price. This setting is motivated in part by the prevalence of online marketplaces that allow for real-time pricing. We assume a structured choice model, parameters of which depend on \$s\_0\$ out of the \$d\$ product features. We propose a dynamic policy, called Regularized Maximum Likelihood Pricing (RMLP) that leverages the (sparsity) structure of the high-dimensional model and obtains a logarithmic regret in \$T\$. More specifically, the regret of our algorithm is of \$O(s\_0 \textbackslash log d \textbackslash cdot \textbackslash log T)\$. Furthermore, we show that no policy can obtain regret better than \$O(s\_0 (\textbackslash log d + \textbackslash log T))\$.},
  archivePrefix = {arXiv},
  eprint = {1609.07574},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Javanmard, Nazerzadeh (2016) - Dynamic Pricing in High-dimensions.pdf},
  journal = {arXiv:1609.07574 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{javanmard2017Perishability,
  title = {Perishability of {{Data}}: {{Dynamic Pricing}} under {{Varying}}-{{Coefficient Models}}},
  shorttitle = {Perishability of {{Data}}},
  author = {Javanmard, Adel},
  year = {2017},
  month = jan,
  abstract = {We consider a firm that sells a large number of products to its customers in an online fashion. Each product is described by a high dimensional feature vector, and the market value of a product is assumed to be linear in the values of its features. Parameters of the valuation model are unknown and can change over time. The firm sequentially observes a product's features and can use the historical sales data (binary sale/no sale feedbacks) to set the price of current product, with the objective of maximizing the collected revenue. We measure the performance of a dynamic pricing policy via regret, which is the expected revenue loss compared to a clairvoyant that knows the sequence of model parameters in advance. We propose a pricing policy based on projected stochastic gradient descent (PSGD) and characterize its regret in terms of time \$T\$, features dimension \$d\$, and the temporal variability in the model parameters, \$\textbackslash delta\_t\$. We consider two settings. In the first one, feature vectors are chosen antagonistically by nature and we prove that the regret of PSGD pricing policy is of order \$O(\textbackslash sqrt\{T\} + \textbackslash sum\_\{t=1\}\^T \textbackslash sqrt\{t\}\textbackslash delta\_t)\$. In the second setting (referred to as stochastic features model), the feature vectors are drawn independently from an unknown distribution. We show that in this case, the regret of PSGD pricing policy is of order \$O(d\^2 \textbackslash log T + \textbackslash sum\_\{t=1\}\^T t\textbackslash delta\_t/d)\$.},
  archivePrefix = {arXiv},
  eprint = {1701.03537},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Javanmard (2017) - Perishability of Data.pdf},
  journal = {arXiv:1701.03537 [cs, stat]},
  keywords = {Computer Science - Computer Science and Game Theory,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{javanmard2018False,
  title = {False {{Discovery Rate Control}} via {{Debiased Lasso}}},
  author = {Javanmard, Adel and Javadi, Hamid},
  year = {2018},
  month = mar,
  file = {/Users/yuekai/Documents/zotero/Javanmard, Javadi (2018) - False Discovery Rate Control via Debiased Lasso.pdf},
  language = {en}
}

@article{javanmard2019MultiProduct,
  title = {Multi-{{Product Dynamic Pricing}} in {{High}}-{{Dimensions}} with {{Heterogenous Price Sensitivity}}},
  author = {Javanmard, Adel and Nazerzadeh, Hamid and Shao, Simeng},
  year = {2019},
  month = jan,
  abstract = {We consider the problem of multi-product dynamic pricing in a contextual
setting for a seller of differentiated products. In this environment, the
customers arrive over time and products are described by high-dimensional
feature vectors. Each customer chooses a product according to the widely used
Multinomial Logit (MNL) choice model and her utility depends on the product
features as well as the prices offered. Our model allows for heterogenous price
sensitivities for products. The seller a-priori does not know the parameters of
the choice model but can learn them through interactions with the customers.
The seller's goal is to design a pricing policy that maximizes her cumulative
revenue. This model is motivated by online marketplaces such as Airbnb platform
and online advertising. We measure the performance of a pricing policy in terms
of regret, which is the expected revenue loss with respect to a clairvoyant
policy that knows the parameters of the choice model in advance and always sets
the revenue-maximizing prices. We propose a pricing policy, named M3P, that
achieves a \$T\$-period regret of \$O(\textbackslash sqrt\{\textbackslash log(dT) T\})\$ under heterogenous price
sensitivity for products with features dimension of \$d\$. We also prove that no
policy can achieve worst-case \$T\$-regret better than \${$\Omega$}(\textbackslash sqrt\{T\})\$.},
  file = {/Users/yuekai/Documents/zotero/Javanmard et al (2019) - Multi-Product Dynamic Pricing in High-Dimensions with Heterogenous Price.pdf},
  language = {en}
}

@article{javanmard2020Precise,
  title = {Precise {{Tradeoffs}} in {{Adversarial Training}} for {{Linear Regression}}},
  author = {Javanmard, Adel and Soltanolkotabi, Mahdi and Hassani, Hamed},
  year = {2020},
  month = feb,
  abstract = {Despite breakthrough performance, modern learning models are known to be highly vulnerable to small adversarial perturbations in their inputs. While a wide variety of recent \textbackslash emph\{adversarial training\} methods have been effective at improving robustness to perturbed inputs (robust accuracy), often this benefit is accompanied by a decrease in accuracy on benign inputs (standard accuracy), leading to a tradeoff between often competing objectives. Complicating matters further, recent empirical evidence suggest that a variety of other factors (size and quality of training data, model size, etc.) affect this tradeoff in somewhat surprising ways. In this paper we provide a precise and comprehensive understanding of the role of adversarial training in the context of linear regression with Gaussian features. In particular, we characterize the fundamental tradeoff between the accuracies achievable by any algorithm regardless of computational power or size of the training data. Furthermore, we precisely characterize the standard/robust accuracy and the corresponding tradeoff achieved by a contemporary mini-max adversarial training approach in a high-dimensional regime where the number of data points and the parameters of the model grow in proportion to each other. Our theory for adversarial training algorithms also facilitates the rigorous study of how a variety of factors (size and quality of training data, model overparametrization etc.) affect the tradeoff between these two competing accuracies.},
  archivePrefix = {arXiv},
  eprint = {2002.10477},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Javanmard et al (2020) - Precise Tradeoffs in Adversarial Training for Linear Regression.pdf},
  journal = {arXiv:2002.10477 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{jensen2016Field,
  title = {Field Observations of the Developing Legal Recreational Cannabis Economy in {{Washington State}}},
  author = {Jensen, Eric L. and Roussell, Aaron},
  year = {2016},
  month = jul,
  volume = {33},
  pages = {96--101},
  issn = {0955-3959},
  doi = {10.1016/j.drugpo.2016.02.023},
  abstract = {Background
Washington State legalized the sale of recreational cannabis in 2012. This paper describes the unfolding of the market regulatory regime in an eastern portion of the state, including field descriptions to illustrate the setting.
Methods
We made observations and conducted interviews of the local supply chain comprising a producer/processor, analytic facility, and retail establishments as well as querying the state director of the regulatory board.
Results
Interviews and observations of facilities suggest an overwhelming concern for black market diversion drives state regulatory efforts. The ongoing dialogue between market actors and the state has resulted in a more equitable distribution of profits at different stages in the process. State safety regulations have thus far been shifted to independent laboratories. Banks and insurance companies have slowly begun making inroads into the industry, despite federal prohibition.
Conclusion
The law was conceived as a social justice remedy, but the bulk of the legal and regulatory activity surrounds cannabis marketplace management. This has been characterized by concerns for black market diversion, producer/processor profits, and a hands-off approach to safety regulation. Minor cannabis violations as a pathway to criminal justice system involvement have been reduced substantially but disproportionate enforcement upon racial/ethnic minorities continues.},
  file = {/Users/yuekai/Documents/zotero/Jensen, Roussell (2016) - Field observations of the developing legal recreational cannabis economy in.pdf},
  journal = {International Journal of Drug Policy}
}

@article{ji2018Risk,
  title = {Risk and Parameter Convergence of Logistic Regression},
  author = {Ji, Ziwei and Telgarsky, Matus},
  year = {2018},
  month = mar,
  abstract = {Gradient descent, when applied to the task of logistic regression, outputs iterates which are biased to follow a unique ray defined by the data. The direction of this ray is the maximum margin predictor of a maximal linearly separable subset of the data; the gradient descent iterates converge to this ray in direction at the rate \$\textbackslash mathcal\{O\}(\textbackslash ln\textbackslash ln t / \textbackslash ln t)\$. The ray does not pass through the origin in general, and its offset is the bounded global optimum of the risk over the remaining data; gradient descent recovers this offset at a rate \$\textbackslash mathcal\{O\}((\textbackslash ln t)\^2 / \textbackslash sqrt\{t\})\$.},
  archivePrefix = {arXiv},
  eprint = {1803.07300},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ji, Telgarsky (2018) - Risk and parameter convergence of logistic regression.pdf},
  journal = {arXiv:1803.07300 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{jia2019Neural,
  title = {Neural {{Jump Stochastic Differential Equations}}},
  author = {Jia, Junteng and Benson, Austin R.},
  year = {2019},
  month = may,
  abstract = {Many time series can be effectively modeled with a combination of continuous flows along with random jumps sparked by discrete events. However, we usually do not have the equation of motion describing the flows, or how they are affected by jumps. To this end, we introduce Neural Jump Stochastic Differential Equations that provide a data-driven approach to learn continuous and discrete dynamic behavior, i.e., hybrid systems that both flow and jump. Our approach extends the framework of Neural Ordinary Differential Equations with a stochastic process term that models discrete events. We then model temporal point processes with a piecewise-continuous latent trajectory, where stochastic events cause an abrupt change in the latent variables. We demonstrate the predictive capabilities of our model on a range of synthetic and real-world marked point process datasets, including classical point processes such as Hawkes processes, medical records, awards on Stack Overflow, and earthquake monitoring.},
  archivePrefix = {arXiv},
  eprint = {1905.10403},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jia, Benson (2019) - Neural Jump Stochastic Differential Equations.pdf},
  journal = {arXiv:1905.10403 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{jiang1996REML,
  title = {{{REML}} Estimation: Asymptotic Behavior and Related Topics},
  shorttitle = {{{REML}} Estimation},
  author = {Jiang, Jiming},
  year = {1996},
  month = feb,
  volume = {24},
  pages = {255--286},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/aos/1033066209},
  abstract = {The restricted maximum likelihood (REML) estimates of dispersion parameters (variance components) in a general (non-normal) mixed model are defined as solutions of the REML equations. In this paper, we show the REML estimates are consistent if the model is asymptotically identifiable and infinitely informative under the (location) invariant class, and are asymptotically normal (A.N.) if in addition the model is asymptotically nondegenerate. The result does not require normality or boundedness of the rank p of design matrix of fixed effects. Moreover, we give a necessary and sufficient condition for asymptotic normality of Gaussian maximum likelihood estimates (MLE) in non-normal cases. As an application, we show for all unconfounded balanced mixed models of the analysis of variance the REML (ANOVA) estimates are consistent; and are also A.N. provided the models are nondegenerate; the MLE are consistent (A.N.) if and only if certain constraints on p are satisfied.},
  file = {/Users/yuekai/Documents/zotero/Jiang (1996) - REML estimation.pdf},
  journal = {The Annals of Statistics},
  language = {en},
  mrnumber = {MR1389890},
  number = {1},
  zmnumber = {0853.62022}
}

@article{jiang2019Fantastic,
  title = {Fantastic {{Generalization Measures}} and {{Where}} to {{Find Them}}},
  author = {Jiang, Yiding and Neyshabur, Behnam and Mobahi, Hossein and Krishnan, Dilip and Bengio, Samy},
  year = {2019},
  month = dec,
  abstract = {Generalization of deep networks has been of great interest in recent years, resulting in a number of theoretically and empirically motivated complexity measures. However, most papers proposing such measures study only a small set of models, leaving open the question of whether the conclusion drawn from those experiments would remain valid in other settings. We present the first large scale study of generalization in deep networks. We investigate more then 40 complexity measures taken from both theoretical bounds and empirical studies. We train over 10,000 convolutional networks by systematically varying commonly used hyperparameters. Hoping to uncover potentially causal relationships between each measure and generalization, we analyze carefully controlled experiments and show surprising failures of some measures as well as promising measures for further research.},
  archivePrefix = {arXiv},
  eprint = {1912.02178},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jiang et al (2019) - Fantastic Generalization Measures and Where to Find Them.pdf},
  journal = {arXiv:1912.02178 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{jiang2019Identifying,
  title = {Identifying and {{Correcting Label Bias}} in {{Machine Learning}}},
  author = {Jiang, Heinrich and Nachum, Ofir},
  year = {2019},
  month = jan,
  abstract = {Datasets often contain biases which unfairly disadvantage certain groups, and classifiers trained on such datasets can inherit these biases. In this paper, we provide a mathematical formulation of how this bias can arise. We do so by assuming the existence of underlying, unknown, and unbiased labels which are overwritten by an agent who intends to provide accurate labels but may have biases against certain groups. Despite the fact that we only observe the biased labels, we are able to show that the bias may nevertheless be corrected by re-weighting the data points without changing the labels. We show, with theoretical guarantees, that training on the re-weighted dataset corresponds to training on the unobserved but unbiased labels, thus leading to an unbiased machine learning classifier. Our procedure is fast and robust and can be used with virtually any learning algorithm. We evaluate on a number of standard machine learning fairness datasets and a variety of fairness notions, finding that our method outperforms standard approaches in achieving fair classification.},
  archivePrefix = {arXiv},
  eprint = {1901.04966},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jiang, Nachum (2019) - Identifying and Correcting Label Bias in Machine Learning.pdf},
  journal = {arXiv:1901.04966 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{jiang2019Improving,
  title = {Improving {{Federated Learning Personalization}} via {{Model Agnostic Meta Learning}}},
  author = {Jiang, Yihan and Kone{\v c}n{\'y}, Jakub and Rush, Keith and Kannan, Sreeram},
  year = {2019},
  month = sep,
  abstract = {Federated Learning (FL) refers to learning a high quality global model based on decentralized data storage, without ever copying the raw data. A natural scenario arises with data created on mobile phones by the activity of their users. Given the typical data heterogeneity in such situations, it is natural to ask how can the global model be personalized for every such device, individually. In this work, we point out that the setting of Model Agnostic Meta Learning (MAML), where one optimizes for a fast, gradient-based, few-shot adaptation to a heterogeneous distribution of tasks, has a number of similarities with the objective of personalization for FL. We present FL as a natural source of practical applications for MAML algorithms, and make the following observations. 1) The popular FL algorithm, Federated Averaging, can be interpreted as a meta learning algorithm. 2) Careful fine-tuning can yield a global model with higher accuracy, which is at the same time easier to personalize. However, solely optimizing for the global model accuracy yields a weaker personalization result. 3) A model trained using a standard datacenter optimization method is much harder to personalize, compared to one trained using Federated Averaging, supporting the first claim. These results raise new questions for FL, MAML, and broader ML research.},
  archivePrefix = {arXiv},
  eprint = {1909.12488},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jiang et al (2019) - Improving Federated Learning Personalization via Model Agnostic Meta Learning.pdf},
  journal = {arXiv:1909.12488 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{jiang2019Wasserstein,
  title = {Wasserstein {{Fair Classification}}},
  author = {Jiang, Ray and Pacchiano, Aldo and Stepleton, Tom and Jiang, Heinrich and Chiappa, Silvia},
  year = {2019},
  month = jul,
  abstract = {We propose an approach to fair classification that enforces independence between the classifier outputs and sensitive information by minimizing Wasserstein-1 distances. The approach has desirable theoretical properties and is robust to specific choices of the threshold used to obtain class predictions from model outputs. We introduce different methods that enable hiding sensitive information at test time or have a simple and fast implementation. We show empirical performance against different fairness baselines on several benchmark fairness datasets.},
  archivePrefix = {arXiv},
  eprint = {1907.12059},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jiang et al (2019) - Wasserstein Fair Classification.pdf},
  journal = {arXiv:1907.12059 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{jitkrittum2017LinearTime,
  title = {A {{Linear}}-{{Time Kernel Goodness}}-of-{{Fit Test}}},
  author = {Jitkrittum, Wittawat and Xu, Wenkai and Szabo, Zoltan and Fukumizu, Kenji and Gretton, Arthur},
  year = {2017},
  month = may,
  abstract = {We propose a novel adaptive test of goodness-of-fit, with computational cost linear in the number of samples. We learn the test features that best indicate the differences between observed samples and a reference model, by minimizing the false negative rate. These features are constructed via Stein's method, meaning that it is not necessary to compute the normalising constant of the model. We analyse the asymptotic Bahadur efficiency of the new test, and prove that under a mean-shift alternative, our test always has greater relative efficiency than a previous linear-time kernel test, regardless of the choice of parameters for that test. In experiments, the performance of our method exceeds that of the earlier linear-time test, and matches or exceeds the power of a quadratic-time kernel test. In high dimensions and where model structure may be exploited, our goodness of fit test performs far better than a quadratic-time two-sample test based on the Maximum Mean Discrepancy, with samples drawn from the model.},
  archivePrefix = {arXiv},
  eprint = {1705.07673},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jitkrittum et al (2017) - A Linear-Time Kernel Goodness-of-Fit Test.pdf},
  journal = {arXiv:1705.07673 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{jitkrittum2020Testing,
  title = {Testing {{Goodness}} of {{Fit}} of {{Conditional Density Models}} with {{Kernels}}},
  author = {Jitkrittum, Wittawat and Kanagawa, Heishiro and Sch{\"o}lkopf, Bernhard},
  year = {2020},
  month = feb,
  abstract = {We propose two nonparametric statistical tests of goodness of fit for conditional distributions: given a conditional probability density function \$p(y|x)\$ and a joint sample, decide whether the sample is drawn from \$p(y|x)r\_x(x)\$ for some density \$r\_x\$. Our tests, formulated with a Stein operator, can be applied to any differentiable conditional density model, and require no knowledge of the normalizing constant. We show that 1) our tests are consistent against any fixed alternative conditional model; 2) the statistics can be estimated easily, requiring no density estimation as an intermediate step; and 3) our second test offers an interpretable test result providing insight on where the conditional model does not fit well in the domain of the covariate. We demonstrate the interpretability of our test on a task of modeling the distribution of New York City's taxi drop-off location given a pick-up point. To our knowledge, our work is the first to propose such conditional goodness-of-fit tests that simultaneously have all these desirable properties.},
  archivePrefix = {arXiv},
  eprint = {2002.10271},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jitkrittum et al (2020) - Testing Goodness of Fit of Conditional Density Models with Kernels.pdf},
  journal = {arXiv:2002.10271 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@inproceedings{joachims2017Unbiased,
  title = {Unbiased {{Learning}}-to-{{Rank}} with {{Biased Feedback}}},
  booktitle = {Proceedings of the {{Tenth ACM International Conference}} on {{Web Search}} and {{Data Mining}}},
  author = {Joachims, Thorsten and Swaminathan, Adith and Schnabel, Tobias},
  year = {2017},
  month = feb,
  pages = {781--789},
  publisher = {{Association for Computing Machinery}},
  address = {{Cambridge, United Kingdom}},
  doi = {10.1145/3018661.3018699},
  abstract = {Implicit feedback (e.g., clicks, dwell times, etc.) is an abundant source of data in human-interactive systems. While implicit feedback has many advantages (e.g., it is inexpensive to collect, user centric, and timely), its inherent biases are a key obstacle to its effective use. For example, position bias in search rankings strongly influences how many clicks a result receives, so that directly using click data as a training signal in Learning-to-Rank (LTR) methods yields sub-optimal results. To overcome this bias problem, we present a counterfactual inference framework that provides the theoretical basis for unbiased LTR via Empirical Risk Minimization despite biased data. Using this framework, we derive a Propensity-Weighted Ranking SVM for discriminative learning from implicit feedback, where click models take the role of the propensity estimator. In contrast to most conventional approaches to de-biasing the data using click models, this allows training of ranking functions even in settings where queries do not repeat. Beyond the theoretical support, we show empirically that the proposed learning method is highly effective in dealing with biases, that it is robust to noise and propensity model misspecification, and that it scales efficiently. We also demonstrate the real-world applicability of our approach on an operational search engine, where it substantially improves retrieval performance.},
  file = {/Users/yuekai/Documents/zotero/Joachims et al (2017) - Unbiased Learning-to-Rank with Biased Feedback.pdf},
  isbn = {978-1-4503-4675-7},
  series = {{{WSDM}} '17}
}

@article{johansson2018Learning,
  title = {Learning {{Weighted Representations}} for {{Generalization Across Designs}}},
  author = {Johansson, Fredrik D. and Kallus, Nathan and Shalit, Uri and Sontag, David},
  year = {2018},
  month = feb,
  abstract = {Predictive models that generalize well under distributional shift are often desirable and sometimes crucial to building robust and reliable machine learning applications. We focus on distributional shift that arises in causal inference from observational data and in unsupervised domain adaptation. We pose both of these problems as prediction under a shift in design. Popular methods for overcoming distributional shift make unrealistic assumptions such as having a well-specified model or knowing the policy that gave rise to the observed data. Other methods are hindered by their need for a pre-specified metric for comparing observations, or by poor asymptotic properties. We devise a bound on the generalization error under design shift, incorporating both representation learning and sample re-weighting. Based on the bound, we propose an algorithmic framework that does not require any of the above assumptions and which is asymptotically consistent. We empirically study the new framework using two synthetic datasets, and demonstrate its effectiveness compared to previous methods.},
  archivePrefix = {arXiv},
  eprint = {1802.08598},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Johansson et al (2018) - Learning Weighted Representations for Generalization Across Designs.pdf},
  journal = {arXiv:1802.08598 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{johndrow2017algorithm,
  title = {An Algorithm for Removing Sensitive Information: Application to Race-Independent Recidivism Prediction},
  shorttitle = {An Algorithm for Removing Sensitive Information},
  author = {Johndrow, James E. and Lum, Kristian},
  year = {2017},
  month = mar,
  abstract = {Predictive modeling is increasingly being employed to assist human decision-makers. One purported advantage of replacing or augmenting human judgment with computer models in high stakes settings-- such as sentencing, hiring, policing, college admissions, and parole decisions-- is the perceived "neutrality" of computers. It is argued that because computer models do not hold personal prejudice, the predictions they produce will be equally free from prejudice. There is growing recognition that employing algorithms does not remove the potential for bias, and can even amplify it if the training data were generated by a process that is itself biased. In this paper, we provide a probabilistic notion of algorithmic bias. We propose a method to eliminate bias from predictive models by removing all information regarding protected variables from the data to which the models will ultimately be trained. Unlike previous work in this area, our framework is general enough to accommodate data on any measurement scale. Motivated by models currently in use in the criminal justice system that inform decisions on pre-trial release and parole, we apply our proposed method to a dataset on the criminal histories of individuals at the time of sentencing to produce "race-neutral" predictions of re-arrest. In the process, we demonstrate that a common approach to creating "race-neutral" models-- omitting race as a covariate-- still results in racially disparate predictions. We then demonstrate that the application of our proposed method to these data removes racial disparities from predictions with minimal impact on predictive accuracy.},
  archivePrefix = {arXiv},
  eprint = {1703.04957},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Johndrow, Lum (2017) - An algorithm for removing sensitive information.pdf},
  journal = {arXiv:1703.04957 [stat]},
  keywords = {Statistics - Applications},
  primaryClass = {stat}
}

@book{johnstone2017Gaussian,
  title = {Gaussian Estimation: {{Sequence}} and Wavelet Models},
  author = {Johnstone, Iain M},
  year = {2017},
  month = sep,
  file = {/Users/yuekai/Documents/zotero/Johnstone (2017) - Gaussian estimation.pdf},
  language = {en}
}

@article{jordan1998Variational,
  title = {The {{Variational Formulation}} of the {{Fokker}}--{{Planck Equation}}},
  author = {Jordan, Richard and Kinderlehrer, David and Otto, Felix},
  year = {1998},
  month = jan,
  volume = {29},
  pages = {1--17},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1410},
  doi = {10.1137/S0036141096303359},
  abstract = {The Fokker--Planck equation, or forward Kolmogorov equation, describes the evolution of the probability density for a stochastic process associated with an Ito stochastic differential equation. It pertains to a wide variety of time-dependent systems in which randomness plays a role. In this paper, we are concerned with Fokker--Planck equations for which the drift term is given by the gradient of a potential. For a broad class of potentials, we construct a time discrete, iterative variational scheme whose solutions converge to the solution of the Fokker--Planck equation. The major novelty of this iterative scheme is that the time-step is governed by the Wasserstein metric on probability measures. This formulation enables us to reveal an appealing, and previously unexplored, relationship between the Fokker--Planck equation and the associated free energy functional. Namely, we demonstrate that the dynamics may be regarded as a gradient flux, or a steepest descent, for the free energy with respect to the Wasserstein metric.},
  file = {/Users/yuekai/Documents/zotero/Jordan et al (1998) - The Variational Formulation of the Fokker--Planck Equation.pdf},
  journal = {SIAM Journal on Mathematical Analysis},
  number = {1}
}

@article{jordan2016CommunicationEfficient,
  title = {Communication-{{Efficient Distributed Statistical Inference}}},
  author = {Jordan, Michael I. and Lee, Jason D. and Yang, Yun},
  year = {2016},
  month = may,
  abstract = {We present a Communication-efficient Surrogate Likelihood (CSL) framework for solving distributed statistical inference problems. CSL provides a communication-efficient surrogate to the global likelihood that can be used for low-dimensional estimation, high-dimensional regularized estimation and Bayesian inference. For low-dimensional estimation, CSL provably improves upon naive averaging schemes and facilitates the construction of confidence intervals. For high-dimensional regularized estimation, CSL leads to a minimax-optimal estimator with controlled communication cost. For Bayesian inference, CSL can be used to form a communication-efficient quasi-posterior distribution that converges to the true posterior. This quasi-posterior procedure significantly improves the computational efficiency of MCMC algorithms even in a non-distributed setting. We present both theoretical analysis and experiments to explore the properties of the CSL approximation.},
  archivePrefix = {arXiv},
  eprint = {1605.07689},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jordan et al (2016) - Communication-Efficient Distributed Statistical Inference.pdf},
  journal = {arXiv:1605.07689 [cs, math, stat]},
  keywords = {Computer Science - Information Theory,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {cs, math, stat}
}

@article{joseph2013Impact,
  title = {Impact of Regularization on {{Spectral Clustering}}},
  author = {Joseph, Antony and Yu, Bin},
  year = {2013},
  month = dec,
  abstract = {The performance of spectral clustering can be considerably improved via regularization, as demonstrated empirically in Amini et. al (2012). Here, we provide an attempt at quantifying this improvement through theoretical analysis. Under the stochastic block model (SBM), and its extensions, previous results on spectral clustering relied on the minimum degree of the graph being sufficiently large for its good performance. By examining the scenario where the regularization parameter \$\textbackslash tau\$ is large we show that the minimum degree assumption can potentially be removed. As a special case, for an SBM with two blocks, the results require the maximum degree to be large (grow faster than \$\textbackslash log n\$) as opposed to the minimum degree. More importantly, we show the usefulness of regularization in situations where not all nodes belong to well-defined clusters. Our results rely on a `bias-variance'-like trade-off that arises from understanding the concentration of the sample Laplacian and the eigen gap as a function of the regularization parameter. As a byproduct of our bounds, we propose a data-driven technique \textbackslash textit\{DKest\} (standing for estimated Davis-Kahan bounds) for choosing the regularization parameter. This technique is shown to work well through simulations and on a real data set.},
  archivePrefix = {arXiv},
  eprint = {1312.1733},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Joseph, Yu (2013) - Impact of regularization on Spectral Clustering.pdf},
  journal = {arXiv:1312.1733 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{joseph2016Fair,
  title = {Fair {{Algorithms}} for {{Infinite}} and {{Contextual Bandits}}},
  author = {Joseph, Matthew and Kearns, Michael and Morgenstern, Jamie and Neel, Seth and Roth, Aaron},
  year = {2016},
  month = oct,
  abstract = {We study fairness in linear bandit problems. Starting from the notion of meritocratic fairness introduced in Joseph et al. [2016], we carry out a more refined analysis of a more general problem, achieving better performance guarantees with fewer modelling assumptions on the number and structure of available choices as well as the number selected. We also analyze the previously-unstudied question of fairness in infinite linear bandit problems, obtaining instance-dependent regret upper bounds as well as lower bounds demonstrating that this instance-dependence is necessary. The result is a framework for meritocratic fairness in an online linear setting that is substantially more powerful, general, and realistic than the current state of the art.},
  archivePrefix = {arXiv},
  eprint = {1610.09559},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Joseph et al (2016) - Fair Algorithms for Infinite and Contextual Bandits.pdf},
  journal = {arXiv:1610.09559 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{joseph2016Fairness,
  title = {Fairness in {{Learning}}: {{Classic}} and {{Contextual Bandits}}},
  shorttitle = {Fairness in {{Learning}}},
  author = {Joseph, Matthew and Kearns, Michael and Morgenstern, Jamie and Roth, Aaron},
  year = {2016},
  month = may,
  abstract = {We introduce the study of fairness in multi-armed bandit problems. Our fairness definition can be interpreted as demanding that given a pool of applicants (say, for college admission or mortgages), a worse applicant is never favored over a better one, despite a learning algorithm's uncertainty over the true payoffs. We prove results of two types. First, in the important special case of the classic stochastic bandits problem (i.e., in which there are no contexts), we provide a provably fair algorithm based on "chained" confidence intervals, and provide a cumulative regret bound with a cubic dependence on the number of arms. We further show that any fair algorithm must have such a dependence. When combined with regret bounds for standard non-fair algorithms such as UCB, this proves a strong separation between fair and unfair learning, which extends to the general contextual case. In the general contextual case, we prove a tight connection between fairness and the KWIK (Knows What It Knows) learning model: a KWIK algorithm for a class of functions can be transformed into a provably fair contextual bandit algorithm, and conversely any fair contextual bandit algorithm can be transformed into a KWIK learning algorithm. This tight connection allows us to provide a provably fair algorithm for the linear contextual bandit problem with a polynomial dependence on the dimension, and to show (for a different class of functions) a worst-case exponential gap in regret between fair and non-fair learning algorithms},
  archivePrefix = {arXiv},
  eprint = {1605.07139},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Joseph et al (2016) - Fairness in Learning.pdf},
  journal = {arXiv:1605.07139 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{juditsky2007Stochastic,
  title = {Stochastic {{Approximation Approach}} to {{Stochastic Programming}}},
  author = {Juditsky, Anatoli and Lan, Guanghui and Nemirovski, Arkadi and Shapiro, Alexander},
  year = {2007},
  month = sep,
  pages = {35},
  abstract = {In this paper we consider optimization problems where the objective function is given in a form of the expectation. A basic difficulty of solving such stochastic optimization problems is that the involved multidimensional integrals (expectations) cannot be computed with high accuracy. The aim of this paper is to compare two computational approaches based on Monte Carlo sampling techniques, namely, the Stochastic Approximation (SA) and the Sample Average Approximation (SAA) methods. Both approaches, the SA and SAA methods, have a long history. Current opinion is that the SAA method can efficiently use a specific (say linear) structure of the considered problem, while the SA approach is a crude subgradient method which often performs poorly in practice. We intend to demonstrate that a properly modified SA approach can be competitive and even significantly outperform the SAA method for a certain class of convex stochastic problems. We extend the analysis to the case of convex-concave stochastic saddle point problems, and present (in our opinion highly encouraging) results of numerical experiments.},
  file = {/Users/yuekai/Documents/zotero/Juditsky et al (2007) - Stochastic Approximation Approach to Stochastic Programming.pdf},
  language = {en}
}

@article{juditsky2008Solving,
  title = {Solving Variational Inequalities with {{Stochastic Mirror}}-{{Prox}} Algorithm},
  author = {Juditsky, Anatoli and Nemirovskii, Arkadii S. and Tauvel, Claire},
  year = {2008},
  month = sep,
  abstract = {In this paper we consider iterative methods for stochastic variational inequalities (s.v.i.) with monotone operators. Our basic assumption is that the operator possesses both smooth and nonsmooth components. Further, only noisy observations of the problem data are available. We develop a novel Stochastic Mirror-Prox (SMP) algorithm for solving s.v.i. and show that with the convenient stepsize strategy it attains the optimal rates of convergence with respect to the problem parameters. We apply the SMP algorithm to Stochastic composite minimization and describe particular applications to Stochastic Semidefinite Feasability problem and Eigenvalue minimization.},
  archivePrefix = {arXiv},
  eprint = {0809.0815},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Juditsky et al (2008) - Solving variational inequalities with Stochastic Mirror-Prox algorithm.pdf},
  journal = {arXiv:0809.0815 [math, stat]},
  keywords = {Mathematics - Optimization and Control,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{jung2019Eliciting,
  title = {Eliciting and {{Enforcing Subjective Individual Fairness}}},
  author = {Jung, Christopher and Kearns, Michael and Neel, Seth and Roth, Aaron and Stapleton, Logan and Wu, Zhiwei Steven},
  year = {2019},
  month = may,
  abstract = {We revisit the notion of individual fairness first proposed by Dwork et al. [2012], which asks that "similar individuals should be treated similarly". A primary difficulty with this definition is that it assumes a completely specified fairness metric for the task at hand. In contrast, we consider a framework for fairness elicitation, in which fairness is indirectly specified only via a sample of pairs of individuals who should be treated (approximately) equally on the task. We make no assumption that these pairs are consistent with any metric. We provide a provably convergent oracle-efficient algorithm for minimizing error subject to the fairness constraints, and prove generalization theorems for both accuracy and fairness. Since the constrained pairs could be elicited either from a panel of judges, or from particular individuals, our framework provides a means for algorithmically enforcing subjective notions of fairness. We report on preliminary findings of a behavioral study of subjective fairness using human-subject fairness constraints elicited on the COMPAS criminal recidivism dataset.},
  archivePrefix = {arXiv},
  eprint = {1905.10660},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Jung et al (2019) - Eliciting and Enforcing Subjective Individual Fairness.pdf},
  journal = {arXiv:1905.10660 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{kaariainen2006Active,
  title = {Active Learning in the Non-Realizable Case},
  booktitle = {{{NIPS Workshop}} on {{Foundations}} of {{Active Learning}}},
  author = {K{\"a}{\"a}ri{\"a}inen, Matti},
  year = {2006},
  abstract = {Abstract. Most of the existing active learning algorithms are based on the realizability assumption: The learner's hypothesis class is assumed to contain a target function that perfectly classifies all training and test examples. This assumption can hardly ever be justified in practice. In this paper, we study how relaxing the realizability assumption affects the sample complexity of active learning. First, we extend existing results on query learning to show that any active learning algorithm for the realizable case can be transformed to tolerate random bounded rate class noise. Thus, bounded rate class noise adds little extra complications to active learning, and in particular exponential label complexity savings over passive learning are still possible. However, it is questionable whether this noise model is any more realistic in practice than assuming no noise at all. Our second result shows that if we move to the truly non-realizable model of statistical learning theory, then the label complexity of active learning has the same dependence {$\Omega$}(1/\k{o} 2) on the accuracy parameter \k{o} as the passive learning label complexity. More specifically, we show that under the assumption that the best classifier in the learner's hypothesis class has generalization error at most {$\beta>$} 0, the label complexity of active learning is {$\Omega$}({$\beta$} 2 /\k{o} 2 log(1/{$\delta$})), where the accuracy parameter \k{o} measures how close to optimal within the hypothesis class the active learner has to get and {$\delta$} is the confidence parameter. The implication of this lower bound is that exponential savings should not be expected in realistic models of active learning, and thus the label complexity goals in active learning should be refined. 1},
  file = {/Users/yuekai/Documents/zotero/Kääriäinen (2006) - Active learning in the non-realizable case.pdf}
}

@article{kairouz2019Advances,
  title = {Advances and {{Open Problems}} in {{Federated Learning}}},
  author = {Kairouz, Peter and McMahan, H. Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Keith and Charles, Zachary and Cormode, Graham and Cummings, Rachel and D'Oliveira, Rafael G. L. and Rouayheb, Salim El and Evans, David and Gardner, Josh and Garrett, Zachary and Gasc{\'o}n, Adri{\`a} and Ghazi, Badih and Gibbons, Phillip B. and Gruteser, Marco and Harchaoui, Zaid and He, Chaoyang and He, Lie and Huo, Zhouyuan and Hutchinson, Ben and Hsu, Justin and Jaggi, Martin and Javidi, Tara and Joshi, Gauri and Khodak, Mikhail and Kone{\v c}n{\'y}, Jakub and Korolova, Aleksandra and Koushanfar, Farinaz and Koyejo, Sanmi and Lepoint, Tancr{\`e}de and Liu, Yang and Mittal, Prateek and Mohri, Mehryar and Nock, Richard and {\"O}zg{\"u}r, Ayfer and Pagh, Rasmus and Raykova, Mariana and Qi, Hang and Ramage, Daniel and Raskar, Ramesh and Song, Dawn and Song, Weikang and Stich, Sebastian U. and Sun, Ziteng and Suresh, Ananda Theertha and Tram{\`e}r, Florian and Vepakomma, Praneeth and Wang, Jianyu and Xiong, Li and Xu, Zheng and Yang, Qiang and Yu, Felix X. and Yu, Han and Zhao, Sen},
  year = {2019},
  month = dec,
  abstract = {Federated learning (FL) is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized. FL embodies the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches. Motivated by the explosive growth in FL research, this paper discusses recent advances and presents an extensive collection of open problems and challenges.},
  archivePrefix = {arXiv},
  eprint = {1912.04977},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kairouz et al (2019) - Advances and Open Problems in Federated Learning.pdf},
  journal = {arXiv:1912.04977 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{kakade2011Efficient,
  title = {Efficient {{Learning}} of {{Generalized Linear}} and {{Single Index Models}} with {{Isotonic Regression}}},
  author = {Kakade, Sham and Kalai, Adam Tauman and Kanade, Varun and Shamir, Ohad},
  year = {2011},
  month = apr,
  abstract = {Generalized Linear Models (GLMs) and Single Index Models (SIMs) provide powerful generalizations of linear regression, where the target variable is assumed to be a (possibly unknown) 1-dimensional function of a linear predictor. In general, these problems entail non-convex estimation procedures, and, in practice, iterative local search heuristics are often used. Kalai and Sastry (2009) recently provided the first provably efficient method for learning SIMs and GLMs, under the assumptions that the data are in fact generated under a GLM and under certain monotonicity and Lipschitz constraints. However, to obtain provable performance, the method requires a fresh sample every iteration. In this paper, we provide algorithms for learning GLMs and SIMs, which are both computationally and statistically efficient. We also provide an empirical study, demonstrating their feasibility in practice.},
  archivePrefix = {arXiv},
  eprint = {1104.2018},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kakade et al (2011) - Efficient Learning of Generalized Linear and Single Index Models with Isotonic.pdf},
  journal = {arXiv:1104.2018 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{kallus2018DeepMatch,
  title = {{{DeepMatch}}: {{Balancing Deep Covariate Representations}} for {{Causal Inference Using Adversarial Training}}},
  shorttitle = {{{DeepMatch}}},
  author = {Kallus, Nathan},
  year = {2018},
  month = feb,
  abstract = {We study optimal covariate balance for causal inferences from observational data when rich covariates and complex relationships necessitate flexible modeling with neural networks. Standard approaches such as propensity weighting and matching/balancing fail in such settings due to miscalibrated propensity nets and inappropriate covariate representations, respectively. We propose a new method based on adversarial training of a weighting and a discriminator network that effectively addresses this methodological gap. This is demonstrated through new theoretical characterizations of the method as well as empirical results using both fully connected architectures to learn complex relationships and convolutional architectures to handle image confounders, showing how this new method can enable strong causal analyses in these challenging settings.},
  archivePrefix = {arXiv},
  eprint = {1802.05664},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kallus (2018) - DeepMatch.pdf},
  journal = {arXiv:1802.05664 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{kallus2018Residual,
  title = {Residual {{Unfairness}} in {{Fair Machine Learning}} from {{Prejudiced Data}}},
  author = {Kallus, Nathan and Zhou, Angela},
  year = {2018},
  month = jun,
  abstract = {Recent work in fairness in machine learning has proposed adjusting for fairness by equalizing accuracy metrics across groups and has also studied how datasets affected by historical prejudices may lead to unfair decision policies. We connect these lines of work and study the residual unfairness that arises when a fairness-adjusted predictor is not actually fair on the target population due to systematic censoring of training data by existing biased policies. This scenario is particularly common in the same applications where fairness is a concern. We characterize theoretically the impact of such censoring on standard fairness metrics for binary classifiers and provide criteria for when residual unfairness may or may not appear. We prove that, under certain conditions, fairness-adjusted classifiers will in fact induce residual unfairness that perpetuates the same injustices, against the same groups, that biased the data to begin with, thus showing that even state-of-the-art fair machine learning can have a "bias in, bias out" property. When certain benchmark data is available, we show how sample reweighting can estimate and adjust fairness metrics while accounting for censoring. We use this to study the case of Stop, Question, and Frisk (SQF) and demonstrate that attempting to adjust for fairness perpetuates the same injustices that the policy is infamous for.},
  archivePrefix = {arXiv},
  eprint = {1806.02887},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kallus, Zhou (2018) - Residual Unfairness in Fair Machine Learning from Prejudiced Data.pdf},
  journal = {arXiv:1806.02887 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{kallus2019Assessing,
  title = {Assessing {{Algorithmic Fairness}} with {{Unobserved Protected Class Using Data Combination}}},
  author = {Kallus, Nathan and Mao, Xiaojie and Zhou, Angela},
  year = {2019},
  month = jun,
  abstract = {The increasing impact of algorithmic decisions on people's lives compels us to scrutinize their fairness and, in particular, the disparate impacts that ostensibly-color-blind algorithms can have on different groups. Examples include credit decisioning, hiring, advertising, criminal justice, personalized medicine, and targeted policymaking, where in some cases legislative or regulatory frameworks for fairness exist and define specific protected classes. In this paper we study a fundamental challenge to assessing disparate impacts in practice: protected class membership is often not observed in the data. This is particularly a problem in lending and healthcare. We consider the use of an auxiliary dataset, such as the US census, that includes class labels but not decisions or outcomes. We show that a variety of common disparity measures are generally unidentifiable aside for some unrealistic cases, providing a new perspective on the documented biases of popular proxy-based methods. We provide exact characterizations of the sharpest-possible partial identification set of disparities either under no assumptions or when we incorporate mild smoothness constraints. We further provide optimization-based algorithms for computing and visualizing these sets, which enables reliable and robust assessments -- an important tool when disparity assessment can have far-reaching policy implications. We demonstrate this in two case studies with real data: mortgage lending and personalized medicine dosing.},
  archivePrefix = {arXiv},
  eprint = {1906.00285},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kallus et al (2019) - Assessing Algorithmic Fairness with Unobserved Protected Class Using Data.pdf},
  journal = {arXiv:1906.00285 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{kaltenbacher2018Parameter,
  title = {Parameter Estimation in {{SDEs}} via the {{Fokker}}\textendash{{Planck}} Equation: {{Likelihood}} Function and Adjoint Based Gradient Computation},
  shorttitle = {Parameter Estimation in {{SDEs}} via the {{Fokker}}\textendash{{Planck}} Equation},
  author = {Kaltenbacher, Barbara and Pedretscher, Barbara},
  year = {2018},
  month = sep,
  volume = {465},
  pages = {872--884},
  issn = {0022-247X},
  doi = {10.1016/j.jmaa.2018.05.048},
  abstract = {In this paper we consider the problem of identifying parameters in stochastic differential equations. For this purpose, we transform the originally stochastic and nonlinear state equation to a deterministic linear partial differential equation for the transition probability density. We provide an appropriate likelihood cost function for parameter fitting, and derive an adjoint based approach for the computation of its gradient.},
  file = {/Users/yuekai/Documents/zotero/Kaltenbacher, Pedretscher (2018) - Parameter estimation in SDEs via the Fokker–Planck equation.pdf},
  journal = {Journal of Mathematical Analysis and Applications},
  language = {en},
  number = {2}
}

@incollection{kandasamy2018Neural,
  title = {Neural {{Architecture Search}} with {{Bayesian Optimisation}} and {{Optimal Transport}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 31},
  author = {Kandasamy, Kirthevasan and Neiswanger, Willie and Schneider, Jeff and Poczos, Barnabas and Xing, Eric P},
  editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and {Cesa-Bianchi}, N. and Garnett, R.},
  year = {2018},
  pages = {2016--2025},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/yuekai/Documents/zotero/Kandasamy et al (2018) - Neural Architecture Search with Bayesian Optimisation and Optimal Transport.pdf;/Users/yuekai/Zotero/storage/JUQ9N8SC/7472-neural-architecture-search-with-bayesian-optimisation-and-optimal-transport.html}
}

@article{kang2019Transfer,
  title = {Transfer of {{Adversarial Robustness Between Perturbation Types}}},
  author = {Kang, Daniel and Sun, Yi and Brown, Tom and Hendrycks, Dan and Steinhardt, Jacob},
  year = {2019},
  month = may,
  abstract = {We study the transfer of adversarial robustness of deep neural networks between different perturbation types. While most work on adversarial examples has focused on \$L\_\textbackslash infty\$ and \$L\_2\$-bounded perturbations, these do not capture all types of perturbations available to an adversary. The present work evaluates 32 attacks of 5 different types against models adversarially trained on a 100-class subset of ImageNet. Our empirical results suggest that evaluating on a wide range of perturbation sizes is necessary to understand whether adversarial robustness transfers between perturbation types. We further demonstrate that robustness against one perturbation type may not always imply and may sometimes hurt robustness against other perturbation types. In light of these results, we recommend evaluation of adversarial defenses take place on a diverse range of perturbation types and sizes.},
  archivePrefix = {arXiv},
  eprint = {1905.01034},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kang et al (2019) - Transfer of Adversarial Robustness Between Perturbation Types.pdf},
  journal = {arXiv:1905.01034 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{kannan2018Adversarial,
  title = {Adversarial {{Logit Pairing}}},
  author = {Kannan, Harini and Kurakin, Alexey and Goodfellow, Ian},
  year = {2018},
  month = mar,
  abstract = {In this paper, we develop improved techniques for defending against adversarial examples at scale. First, we implement the state of the art version of adversarial training at unprecedented scale on ImageNet and investigate whether it remains effective in this setting - an important open scientific question (Athalye et al., 2018). Next, we introduce enhanced defenses using a technique we call logit pairing, a method that encourages logits for pairs of examples to be similar. When applied to clean examples and their adversarial counterparts, logit pairing improves accuracy on adversarial examples over vanilla adversarial training; we also find that logit pairing on clean examples only is competitive with adversarial training in terms of accuracy on two datasets. Finally, we show that adversarial logit pairing achieves the state of the art defense on ImageNet against PGD white box attacks, with an accuracy improvement from 1.5\% to 27.9\%. Adversarial logit pairing also successfully damages the current state of the art defense against black box attacks on ImageNet (Tramer et al., 2018), dropping its accuracy from 66.6\% to 47.1\%. With this new accuracy drop, adversarial logit pairing ties with Tramer et al.(2018) for the state of the art on black box attacks on ImageNet.},
  archivePrefix = {arXiv},
  eprint = {1803.06373},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kannan et al (2018) - Adversarial Logit Pairing.pdf},
  journal = {arXiv:1803.06373 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{kantchelian2015Evasion,
  title = {Evasion and {{Hardening}} of {{Tree Ensemble Classifiers}}},
  author = {Kantchelian, Alex and Tygar, J. D. and Joseph, Anthony D.},
  year = {2015},
  month = sep,
  abstract = {Classifier evasion consists in finding for a given instance \$x\$ the nearest instance \$x'\$ such that the classifier predictions of \$x\$ and \$x'\$ are different. We present two novel algorithms for systematically computing evasions for tree ensembles such as boosted trees and random forests. Our first algorithm uses a Mixed Integer Linear Program solver and finds the optimal evading instance under an expressive set of constraints. Our second algorithm trades off optimality for speed by using symbolic prediction, a novel algorithm for fast finite differences on tree ensembles. On a digit recognition task, we demonstrate that both gradient boosted trees and random forests are extremely susceptible to evasions. Finally, we harden a boosted tree model without loss of predictive accuracy by augmenting the training set of each boosting round with evading instances, a technique we call adversarial boosting.},
  archivePrefix = {arXiv},
  eprint = {1509.07892},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kantchelian et al (2015) - Evasion and Hardening of Tree Ensemble Classifiers.pdf},
  journal = {arXiv:1509.07892 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@book{kantorovich1982Functional,
  title = {Functional {{Analysis}}},
  author = {Kantorovich, L. V. and Akilov, G. P.},
  year = {1982},
  edition = {Second},
  publisher = {{Pergamon}},
  abstract = {Functional Analysis, Second Edition is an exposition of the theory of topological vector spaces, partially ordered spaces, and the development of the theory of integral operators and their representations on ideal spaces of measurable functions. Although this edition has deviated substantially from the first edition, it has still retained the overall plan, selection, and arrangement of the topics. The text is primarily devoted to the applications of functional analysis to applied analysis. However, these concepts have been extended and modernized. Some topics of functional analysis connected with applications to mathematical economics and control theory are also included in this edition. The applications of functional analysis are both wide and far-reaching as these are common language for all areas of mathematics involving the concept of continuity. Those who are in the field of mathematics, mechanics, and theoretical physics will find this book a valuable resource.},
  file = {/Users/yuekai/Documents/zotero/Kantorovich, Akilov (1982) - Functional Analysis.pdf},
  isbn = {978-1-4831-3825-1},
  language = {en}
}

@article{kantorovich2006Translocation,
  title = {On the {{Translocation}} of {{Masses}}},
  author = {Kantorovich, L. V.},
  year = {2006},
  month = mar,
  volume = {133},
  pages = {1381--1382},
  issn = {1573-8795},
  doi = {10.1007/s10958-006-0049-2},
  file = {/Users/yuekai/Documents/zotero/Kantorovich (2006) - On the Translocation of Masses.pdf},
  journal = {Journal of Mathematical Sciences},
  language = {en},
  number = {4}
}

@article{karimi2020Algorithmic,
  title = {Algorithmic {{Recourse}}: From {{Counterfactual Explanations}} to {{Interventions}}},
  shorttitle = {Algorithmic {{Recourse}}},
  author = {Karimi, Amir-Hossein and Sch{\"o}lkopf, Bernhard and Valera, Isabel},
  year = {2020},
  month = feb,
  abstract = {As machine learning is increasingly used to inform consequential decision-making (e.g., pre-trial bail and loan approval), it becomes important to explain how the system arrived at its decision, and also suggest actions to achieve a favorable decision. Counterfactual explanations -- "how the world would have (had) to be different for a desirable outcome to occur" -- aim to satisfy these criteria. Existing works have primarily focused on designing algorithms to obtain counterfactual explanations for a wide range of settings. However, one of the main objectives of "explanations as a means to help a data-subject act rather than merely understand" has been overlooked. In layman's terms, counterfactual explanations inform an individual where they need to get to, but not how to get there. In this work, we rely on causal reasoning to caution against the use of counterfactual explanations as a recommendable set of actions for recourse. Instead, we propose a shift of paradigm from recourse via nearest counterfactual explanations to recourse through minimal interventions, moving the focus from explanations to recommendations. Finally, we provide the reader with an extensive discussion on how to realistically achieve recourse beyond structural interventions.},
  archivePrefix = {arXiv},
  eprint = {2002.06278},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Karimi et al (2020) - Algorithmic Recourse.pdf},
  journal = {arXiv:2002.06278 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{karkkainen2019FairFace,
  title = {{{FairFace}}: {{Face Attribute Dataset}} for {{Balanced Race}}, {{Gender}}, and {{Age}}},
  shorttitle = {{{FairFace}}},
  author = {K{\"a}rkk{\"a}inen, Kimmo and Joo, Jungseock},
  year = {2019},
  month = aug,
  abstract = {Existing public face datasets are strongly biased toward Caucasian faces, and other races (e.g., Latino) are significantly underrepresented. This can lead to inconsistent model accuracy, limit the applicability of face analytic systems to non-White race groups, and adversely affect research findings based on such skewed data. To mitigate the race bias in these datasets, we construct a novel face image dataset, containing 108,501 images, with an emphasis of balanced race composition in the dataset. We define 7 race groups: White, Black, Indian, East Asian, Southeast Asian, Middle East, and Latino. Images were collected from the YFCC-100M Flickr dataset and labeled with race, gender, and age groups. Evaluations were performed on existing face attribute datasets as well as novel image datasets to measure generalization performance. We find that the model trained from our dataset is substantially more accurate on novel datasets and the accuracy is consistent between race and gender groups.},
  archivePrefix = {arXiv},
  eprint = {1908.04913},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kärkkäinen, Joo (2019) - FairFace.pdf},
  journal = {arXiv:1908.04913 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{karow2014Perturbation,
  title = {On a {{Perturbation Bound}} for {{Invariant Subspaces}} of {{Matrices}}},
  author = {Karow, M. and Kressner, D.},
  year = {2014},
  month = jan,
  volume = {35},
  pages = {599--618},
  issn = {0895-4798},
  doi = {10.1137/130912372},
  abstract = {Given a nonsymmetric matrix \$A\$, we investigate the effect of perturbations on an invariant subspace of \$A\$. The result derived in this paper differs from Stewart's classical result and sometimes yields tighter bounds. Moreover, we provide norm estimates for the remainder terms in well-known perturbation expansions for invariant subspaces, eigenvectors, and eigenvalues.},
  file = {/Users/yuekai/Documents/zotero/Karow, Kressner (2014) - On a Perturbation Bound for Invariant Subspaces of Matrices.pdf},
  journal = {SIAM Journal on Matrix Analysis and Applications},
  number = {2}
}

@inproceedings{katenka2006Local,
  title = {Local {{Vote Decision Fusion}} for {{Target Detection}}},
  booktitle = {In {{Wireless Sensor Networks}},'' in {{Joint Research Conf}}. on {{Statistics}} in {{Quality Industry}} and {{Tech}}},
  author = {Katenka, Natallia and Levina, Elizaveta and Michailidis, George},
  year = {2006},
  abstract = {This study examines the problem of target detection by a wireless sensor network. Sensors acquire measurements emitted from the target that are corrupted by noise and initially make individual decisions about the presence/absence of the target. We propose the Local Vote Decision Fusion algorithm, in which sensors first correct their decisions using decisions of neighboring sensors, and then make a collective decision as a network. An explicit formula that approximates the system's decision threshold for a given false alarm rate is derived using limit theorems for random fields, which provides a theoretical performance guarantee for the algorithm. We examine both distance- and nearest neighbor-based versions of the local vote algorithm for grid and random sensor deployments and show that, for a fixed system false alarm, the local vote correction achieves significantly higher target detection rate than decision fusion based on uncorrected decisions. The local vote decision fusion framework is extended to the sequential case, where information becomes available over time.},
  file = {/Users/yuekai/Documents/zotero/Katenka et al (2006) - Local Vote Decision Fusion for Target Detection.pdf}
}

@article{katenka2013Tracking,
  title = {Tracking {{Multiple Targets Using Binary Decisions From Wireless Sensor Networks}}},
  author = {Katenka, Natallia and Levina, Elizaveta and Michailidis, George},
  year = {2013},
  month = jun,
  volume = {108},
  pages = {398--410},
  issn = {0162-1459},
  doi = {10.1080/01621459.2013.770284},
  abstract = {This article introduces a framework for tracking multiple targets over time using binary decisions collected by a wireless sensor network, and applies the methodology to two case studies\textemdash an experiment involving tracking people and a dataset adapted from a project tracking zebras in Kenya. The tracking approach is based on a penalized maximum likelihood framework, and allows for sensor failures, targets appearing and disappearing over time, and complex intersecting target trajectories. We show that binary decisions about the presence/absence of a target in a sensor's neighborhood, corrected locally by a method known as local vote decision fusion, provide the most robust performance in noisy environments and give good tracking results in applications.},
  file = {/Users/yuekai/Documents/zotero/Katenka et al (2013) - Tracking Multiple Targets Using Binary Decisions From Wireless Sensor Networks.pdf},
  journal = {Journal of the American Statistical Association},
  number = {502}
}

@article{kato2009Asymptotics,
  title = {Asymptotics for Argmin Processes: {{Convexity}} Arguments},
  shorttitle = {Asymptotics for Argmin Processes},
  author = {Kato, Kengo},
  year = {2009},
  month = sep,
  volume = {100},
  pages = {1816--1829},
  issn = {0047259X},
  doi = {10.1016/j.jmva.2009.02.008},
  abstract = {The convexity arguments developed by Pollard [D. Pollard, Asymptotics for least absolute deviation regression estimators, Econometric Theory 7 (1991) 186\textendash 199], Hjort and Pollard [N.L. Hjort, D. Pollard, Asymptotics for minimizers of convex processes, 1993 (unpublished manuscript)], and Geyer [C.J. Geyer, On the asymptotics of convex stochastic optimization, 1996 (unpublished manuscript)] are now basic tools for investigating the asymptotic behavior of M-estimators with non-differentiable convex objective functions. This paper extends the scope of convexity arguments to the case where estimators are obtained as stochastic processes. Our convexity arguments provide a simple proof for the asymptotic distribution of regression quantile processes. In addition to quantile regression, we apply our technique to LAD (least absolute deviation) inference for threshold regression.},
  file = {/Users/yuekai/Documents/zotero/Kato (2009) - Asymptotics for argmin processes.pdf},
  journal = {Journal of Multivariate Analysis},
  language = {en},
  number = {8}
}

@article{katsevich2018simultaneous,
  title = {Towards "Simultaneous Selective Inference": Post-Hoc Bounds on the False Discovery Proportion},
  shorttitle = {Towards "Simultaneous Selective Inference"},
  author = {Katsevich, Eugene and Ramdas, Aaditya},
  year = {2018},
  month = mar,
  abstract = {The false discovery rate (FDR) is a popular error criterion for multiple testing, but it has been criticized for lacking flexibility. A target FDR level \$q\$ must be set in advance, and the resulting rejection set cannot be contracted or expanded without invalidating FDR control. In exploratory settings, it is desirable to allow the experimenter more freedom to choose a rejection set, while still preserving some Type-I error guarantees. In this paper, we show that the entire path of rejection sets considered by a variety of existing FDR procedures (like BH, knockoffs, and many others) can be endowed with simultaneous high-probability bounds on FDP. The path can be defined based on either the p-values themselves, side information, or a combination of the two. FDR procedures maintain an estimate of FDP for each rejection set on the path, stopping when this estimate exceeds \$q\$. We show that inflating this FDP estimate by a small, explicit, multiplicative constant bounds the FDP with high probability across the entire path. These results allow the scientist to \$\textbackslash textit\{spot\}\$ one or more suitable rejection sets (Select Post hoc On the algorithm's Trajectory) as they wish, for example by picking a data-dependent size or error level, after examining the FDP bounds for the whole path, and still get a valid high probability FDP bound on the chosen set. Bounding the FDP simultaneously for a selected path of rejection sets (simultaneous selective inference) can be a fruitful middle ground between fully simultaneous inference (guarantees for all possible rejection sets), and fully selective inference (guarantees only for one rejection set).},
  archivePrefix = {arXiv},
  eprint = {1803.06790},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Katsevich, Ramdas (2018) - Towards simultaneous selective inference.pdf},
  journal = {arXiv:1803.06790 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{kawaguchi2019Gradient,
  title = {Gradient {{Descent Finds Global Minima}} for {{Generalizable Deep Neural Networks}} of {{Practical Sizes}}},
  author = {Kawaguchi, Kenji and Huang, Jiaoyang},
  year = {2019},
  month = aug,
  abstract = {In this paper, we theoretically prove that gradient descent can find a global minimum for nonlinear deep neural networks of sizes commonly encountered in practice. The theory developed in this paper requires only the number of trainable parameters to increase linearly as the number of training samples increases. This allows the size of the deep neural networks to be several orders of magnitude smaller than that required by the previous theories. Moreover, we prove that the linear increase of the size of the network is the optimal rate and that it cannot be improved, except by a logarithmic factor. Furthermore, deep neural networks with the trainability guarantee are shown to generalize well to unseen test samples with a natural dataset but not a random dataset.},
  archivePrefix = {arXiv},
  eprint = {1908.02419},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kawaguchi, Huang (2019) - Gradient Descent Finds Global Minima for Generalizable Deep Neural Networks of.pdf},
  journal = {arXiv:1908.02419 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{kearns2017Preventing,
  title = {Preventing {{Fairness Gerrymandering}}: {{Auditing}} and {{Learning}} for {{Subgroup Fairness}}},
  shorttitle = {Preventing {{Fairness Gerrymandering}}},
  author = {Kearns, Michael and Neel, Seth and Roth, Aaron and Wu, Zhiwei Steven},
  year = {2017},
  month = nov,
  abstract = {The most prevalent notions of fairness in machine learning are statistical definitions: they fix a small collection of pre-defined groups, and then ask for parity of some statistic of the classifier across these groups. Constraints of this form are susceptible to intentional or inadvertent "fairness gerrymandering", in which a classifier appears to be fair on each individual group, but badly violates the fairness constraint on one or more structured subgroups defined over the protected attributes. We propose instead to demand statistical notions of fairness across exponentially (or infinitely) many subgroups, defined by a structured class of functions over the protected attributes. This interpolates between statistical definitions of fairness and recently proposed individual notions of fairness, but raises several computational challenges. It is no longer clear how to audit a fixed classifier to see if it satisfies such a strong definition of fairness. We prove that the computational problem of auditing subgroup fairness for both equality of false positive rates and statistical parity is equivalent to the problem of weak agnostic learning, which means it is computationally hard in the worst case, even for simple structured subclasses. We then derive two algorithms that provably converge to the best fair classifier, given access to oracles which can solve the agnostic learning problem. The algorithms are based on a formulation of subgroup fairness as a two-player zero-sum game between a Learner and an Auditor. Our first algorithm provably converges in a polynomial number of steps. Our second algorithm enjoys only provably asymptotic convergence, but has the merit of simplicity and faster per-step computation. We implement the simpler algorithm using linear regression as a heuristic oracle, and show that we can effectively both audit and learn fair classifiers on real datasets.},
  archivePrefix = {arXiv},
  eprint = {1711.05144},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kearns et al (2017) - Preventing Fairness Gerrymandering.pdf},
  journal = {arXiv:1711.05144 [cs]},
  keywords = {Computer Science - Computer Science and Game Theory,Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{kearns2019Average,
  title = {Average {{Individual Fairness}}: {{Algorithms}}, {{Generalization}} and {{Experiments}}},
  shorttitle = {Average {{Individual Fairness}}},
  author = {Kearns, Michael and Roth, Aaron and {Sharifi-Malvajerdi}, Saeed},
  year = {2019},
  month = may,
  abstract = {We propose a new family of fairness definitions for classification problems that combine some of the best properties of both statistical and individual notions of fairness. We posit not only a distribution over individuals, but also a distribution over (or collection of) classification tasks. We then ask that standard statistics (such as error or false positive/negative rates) be (approximately) equalized across individuals, where the rate is defined as an expectation over the classification tasks. Because we are no longer averaging over coarse groups (such as race or gender), this is a semantically meaningful individual-level constraint. Given a sample of individuals and classification problems, we design an oracle-efficient algorithm (i.e. one that is given access to any standard, fairness-free learning heuristic) for the fair empirical risk minimization task. We also show that given sufficiently many samples, the ERM solution generalizes in two directions: both to new individuals, and to new classification tasks, drawn from their corresponding distributions. Finally we implement our algorithm and empirically verify its effectiveness.},
  archivePrefix = {arXiv},
  eprint = {1905.10607},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kearns et al (2019) - Average Individual Fairness.pdf},
  journal = {arXiv:1905.10607 [cs, stat]},
  keywords = {Computer Science - Computer Science and Game Theory,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{kemp2006Learning,
  title = {Learning {{Systems}} of {{Concepts}} with an {{Infinite Relational Model}}},
  booktitle = {Proceedings of the 21st National Conference on {{Artificial}} Intelligence},
  author = {Kemp, Charles and Tenenbaum, Joshua B and Griffiths, Thomas L and Yamada, Takeshi and Ueda, Naonori},
  year = {2006},
  month = jul,
  pages = {8},
  address = {{Boston, MA}},
  abstract = {Relationships between concepts account for a large proportion of semantic knowledge. We present a nonparametric Bayesian model that discovers systems of related concepts. Given data involving several sets of entities, our model discovers the kinds of entities in each set and the relations between kinds that are possible or likely. We apply our approach to four problems: clustering objects and features, learning ontologies, discovering kinship systems, and discovering structure in political data.},
  file = {/Users/yuekai/Documents/zotero/Kemp et al (2006) - Learning Systems of Concepts with an Inﬁnite Relational Model.pdf},
  language = {en}
}

@article{khajehnejad2019Optimal,
  title = {Optimal {{Decision Making Under Strategic Behavior}}},
  author = {Khajehnejad, Moein and Tabibian, Behzad and Sch{\"o}lkopf, Bernhard and Singla, Adish and {Gomez-Rodriguez}, Manuel},
  year = {2019},
  month = may,
  abstract = {We are witnessing an increasing use of data-driven predictive models to inform decisions. As decisions have implications for individuals and society, there is increasing pressure on decision makers to be transparent about their decision policies, models, and the features they use. At the same time, individuals may use knowledge, gained by transparency, to invest effort strategically in order to maximize their chances of receiving a beneficial decision. In this paper, our goal is to find decision policies that are optimal in terms of utility in such a strategic setting. To this end, we first use the theory of optimal transport to characterize how strategic investment of effort by individuals leads to a change in the feature distribution at a population level. Then, we show that, in contrast with the non-strategic setting, optimal decision policies are stochastic, and we cannot expect to find them in polynomial time. Finally, we derive an efficient greedy algorithm that is guaranteed to find locally optimal decision policies in polynomial time. Experiments on synthetic and real lending data illustrate our theoretical findings and show that the decision policies found by our greedy algorithm achieve higher utility than deterministic threshold rules, which are optimal policies in a non-strategic setting.},
  archivePrefix = {arXiv},
  eprint = {1905.09239},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Khajehnejad et al (2019) - Optimal Decision Making Under Strategic Behavior.pdf},
  journal = {arXiv:1905.09239 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{khaled2019First,
  title = {First {{Analysis}} of {{Local GD}} on {{Heterogeneous Data}}},
  author = {Khaled, Ahmed and Mishchenko, Konstantin and Richt{\'a}rik, Peter},
  year = {2019},
  month = sep,
  abstract = {We provide the first convergence analysis of local gradient descent for minimizing the average of smooth and convex but otherwise arbitrary functions. Problems of this form and local gradient descent as a solution method are of importance in federated learning, where each function is based on private data stored by a user on a mobile device, and the data of different users can be arbitrarily heterogeneous. We show that in a low accuracy regime, the method has the same communication complexity as gradient descent.},
  archivePrefix = {arXiv},
  eprint = {1909.04715},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Khaled et al (2019) - First Analysis of Local GD on Heterogeneous Data.pdf},
  journal = {arXiv:1909.04715 [cs, math, stat]},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning,Mathematics - Numerical Analysis,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{khani2019Maximum,
  title = {Maximum {{Weighted Loss Discrepancy}}},
  author = {Khani, Fereshte and Raghunathan, Aditi and Liang, Percy},
  year = {2019},
  month = jun,
  abstract = {Though machine learning algorithms excel at minimizing the average loss over a population, this might lead to large discrepancies between the losses across groups within the population. To capture this inequality, we introduce and study a notion we call maximum weighted loss discrepancy (MWLD), the maximum (weighted) difference between the loss of a group and the loss of the population. We relate MWLD to group fairness notions and robustness to demographic shifts. We then show MWLD satisfies the following three properties: 1) It is statistically impossible to estimate MWLD when all groups have equal weights. 2) For a particular family of weighting functions, we can estimate MWLD efficiently. 3) MWLD is related to loss variance, a quantity that arises in generalization bounds. We estimate MWLD with different weighting functions on four common datasets from the fairness literature. We finally show that loss variance regularization can halve the loss variance of a classifier and hence reduce MWLD without suffering a significant drop in accuracy.},
  archivePrefix = {arXiv},
  eprint = {1906.03518},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Khani et al (2019) - Maximum Weighted Loss Discrepancy.pdf},
  journal = {arXiv:1906.03518 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{khani2019Noise,
  title = {Noise {{Induces Loss Discrepancy Across Groups}} for {{Linear Regression}}},
  author = {Khani, Fereshte and Liang, Percy},
  year = {2019},
  month = nov,
  abstract = {We study the effect of feature noise (measurement error) on the discrepancy between losses across two groups (e.g., men and women) in the context of linear regression. Our main finding is that adding even the same amount of noise on all individuals impacts groups differently. We characterize several forms of loss discrepancy in terms of the amount of noise and difference between moments of the two groups, for estimators that either do or do not use group membership information. We then study how long it takes for an estimator to adapt to a shift in the population that makes the groups have the same mean. We finally validate our results on three real-world datasets.},
  archivePrefix = {arXiv},
  eprint = {1911.09876},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Khani, Liang (2019) - Noise Induces Loss Discrepancy Across Groups for Linear Regression.pdf},
  journal = {arXiv:1911.09876 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{khim2018Adversarial,
  title = {Adversarial {{Risk Bounds}} via {{Function Transformation}}},
  author = {Khim, Justin and Loh, Po-Ling},
  year = {2018},
  month = oct,
  abstract = {We derive bounds for a notion of adversarial risk, designed to characterize the robustness of linear and neural network classifiers to adversarial perturbations. Specifically, we introduce a new class of function transformations with the property that the risk of the transformed functions upper-bounds the adversarial risk of the original functions. This reduces the problem of deriving bounds on the adversarial risk to the problem of deriving risk bounds using standard learning-theoretic techniques. We then derive bounds on the Rademacher complexities of the transformed function classes, obtaining error rates on the same order as the generalization error of the original function classes. We also discuss extensions of our theory to multiclass classification and regression. Finally, we provide two algorithms for optimizing the adversarial risk bounds in the linear case, and discuss connections to regularization and distributional robustness.},
  archivePrefix = {arXiv},
  eprint = {1810.09519},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Khim, Loh (2018) - Adversarial Risk Bounds via Function Transformation.pdf},
  journal = {arXiv:1810.09519 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{khodak2019Adaptive,
  title = {Adaptive {{Gradient}}-{{Based Meta}}-{{Learning Methods}}},
  author = {Khodak, Mikhail and Balcan, Maria-Florina and Talwalkar, Ameet},
  year = {2019},
  month = dec,
  abstract = {We build a theoretical framework for designing and understanding practical meta-learning methods that integrates sophisticated formalizations of task-similarity with the extensive literature on online convex optimization and sequential prediction algorithms. Our approach enables the task-similarity to be learned adaptively, provides sharper transfer-risk bounds in the setting of statistical learning-to-learn, and leads to straightforward derivations of average-case regret bounds for efficient algorithms in settings where the task-environment changes dynamically or the tasks share a certain geometric structure. We use our theory to modify several popular meta-learning algorithms and improve their meta-test-time performance on standard problems in few-shot learning and federated learning.},
  archivePrefix = {arXiv},
  eprint = {1906.02717},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Khodak et al (2019) - Adaptive Gradient-Based Meta-Learning Methods.pdf},
  journal = {arXiv:1906.02717 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{khodak2019Provable,
  title = {Provable {{Guarantees}} for {{Gradient}}-{{Based Meta}}-{{Learning}}},
  author = {Khodak, Mikhail and Balcan, Maria-Florina and Talwalkar, Ameet},
  year = {2019},
  month = feb,
  abstract = {We study the problem of meta-learning through the lens of online convex optimization, developing a meta-algorithm bridging the gap between popular gradient-based meta-learning and classical regularization-based multi-task transfer methods. Our method is the first to simultaneously satisfy good sample efficiency guarantees in the convex setting, with generalization bounds that improve with task-similarity, while also being computationally scalable to modern deep learning architectures and the many-task setting. Despite its simplicity, the algorithm matches, up to a constant factor, a lower bound on the performance of any such parameter-transfer method under natural task similarity assumptions. We use experiments in both convex and deep learning settings to verify and demonstrate the applicability of our theory.},
  archivePrefix = {arXiv},
  eprint = {1902.10644},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Khodak et al (2019) - Provable Guarantees for Gradient-Based Meta-Learning.pdf},
  journal = {arXiv:1902.10644 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{khrulkov2017Art,
  title = {Art of Singular Vectors and Universal Adversarial Perturbations},
  author = {Khrulkov, Valentin and Oseledets, Ivan},
  year = {2017},
  month = sep,
  abstract = {Vulnerability of Deep Neural Networks (DNNs) to adversarial attacks has been attracting a lot of attention in recent studies. It has been shown that for many state of the art DNNs performing image classification there exist universal adversarial perturbations --- image-agnostic perturbations mere addition of which to natural images with high probability leads to their misclassification. In this work we propose a new algorithm for constructing such universal perturbations. Our approach is based on computing the so-called \$(p, q)\$-singular vectors of the Jacobian matrices of hidden layers of a network. Resulting perturbations present interesting visual patterns, and by using only 64 images we were able to construct universal perturbations with more than 60 \textbackslash\% fooling rate on the dataset consisting of 50000 images. We also investigate a correlation between the maximal singular value of the Jacobian matrix and the fooling rate of the corresponding singular vector, and show that the constructed perturbations generalize across networks.},
  archivePrefix = {arXiv},
  eprint = {1709.03582},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Khrulkov, Oseledets (2017) - Art of singular vectors and universal adversarial perturbations.pdf},
  journal = {arXiv:1709.03582 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{kiefer1956Consistency,
  title = {Consistency of the {{Maximum Likelihood Estimator}} in the {{Presence}} of {{Infinitely Many Incidental Parameters}}},
  author = {Kiefer, J. and Wolfowitz, J.},
  year = {1956},
  month = dec,
  volume = {27},
  pages = {887--906},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177728066},
  abstract = {It is shown that, under usual regularity conditions, the maximum likelihood estimator of a structural parameter is strongly consistent, when the (infinitely many) incidental parameters are independently distributed chance variables with a common unknown distribution function. The latter is also consistently estimated although it is not assumed to belong to a parametric class. Application is made to several problems, in particular to the problem of estimating a straight line with both variables subject to error, which thus after all has a maximum likelihood solution.},
  file = {/Users/yuekai/Documents/zotero/Kiefer, Wolfowitz (1956) - Consistency of the Maximum Likelihood Estimator in the Presence of Infinitely.pdf},
  journal = {Annals of Mathematical Statistics},
  language = {EN},
  mrnumber = {MR86464},
  number = {4},
  zmnumber = {0073.14701}
}

@article{kilbertus2017Avoiding,
  title = {Avoiding {{Discrimination}} through {{Causal Reasoning}}},
  author = {Kilbertus, Niki and {Rojas-Carulla}, Mateo and Parascandolo, Giambattista and Hardt, Moritz and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
  year = {2017},
  month = jun,
  abstract = {Recent work on fairness in machine learning has focused on various statistical discrimination criteria and how they trade off. Most of these criteria are observational: They depend only on the joint distribution of predictor, protected attribute, features, and outcome. While convenient to work with, observational criteria have severe inherent limitations that prevent them from resolving matters of fairness conclusively. Going beyond observational criteria, we frame the problem of discrimination based on protected attributes in the language of causal reasoning. This viewpoint shifts attention from "What is the right fairness criterion?" to "What do we want to assume about the causal data generating process?" Through the lens of causality, we make several contributions. First, we crisply articulate why and when observational criteria fail, thus formalizing what was before a matter of opinion. Second, our approach exposes previously ignored subtleties and why they are fundamental to the problem. Finally, we put forward natural causal non-discrimination criteria and develop algorithms that satisfy them.},
  archivePrefix = {arXiv},
  eprint = {1706.02744},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kilbertus et al (2017) - Avoiding Discrimination through Causal Reasoning.pdf},
  journal = {arXiv:1706.02744 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{kilbertus2018Generalization,
  title = {Generalization in Anti-Causal Learning},
  author = {Kilbertus, Niki and Parascandolo, Giambattista and Sch{\"o}lkopf, Bernhard},
  year = {2018},
  month = dec,
  abstract = {The ability to learn and act in novel situations is still a prerogative of animate intelligence, as current machine learning methods mostly fail when moving beyond the standard i.i.d. setting. What is the reason for this discrepancy? Most machine learning tasks are anti-causal, i.e., we infer causes (labels) from effects (observations). Typically, in supervised learning we build systems that try to directly invert causal mechanisms. Instead, in this paper we argue that strong generalization capabilities crucially hinge on searching and validating meaningful hypotheses, requiring access to a causal model. In such a framework, we want to find a cause that leads to the observed effect. Anti-causal models are used to drive this search, but a causal model is required for validation. We investigate the fundamental differences between causal and anti-causal tasks, discuss implications for topics ranging from adversarial attacks to disentangling factors of variation, and provide extensive evidence from the literature to substantiate our view. We advocate for incorporating causal models in supervised learning to shift the paradigm from inference only, to search and validation.},
  archivePrefix = {arXiv},
  eprint = {1812.00524},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kilbertus et al (2018) - Generalization in anti-causal learning.pdf},
  journal = {arXiv:1812.00524 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{kilbertus2019Fair,
  title = {Fair {{Decisions Despite Imperfect Predictions}}},
  author = {Kilbertus, Niki and {Gomez-Rodriguez}, Manuel and Sch{\"o}lkopf, Bernhard and Muandet, Krikamol and Valera, Isabel},
  year = {2019},
  month = feb,
  abstract = {Consequential decisions are increasingly informed by sophisticated data-driven predictive models. For accurate predictive models, deterministic threshold rules have been shown to be optimal in terms of utility, even under a variety of fairness constraints. However, consistently learning accurate predictive models requires access to ground truth labels. Unfortunately, in practice, labels only exist conditional on certain decisions, which may have been made using a potentially imperfect decision policy. As a result, learned deterministic threshold rules are often suboptimal. Can we do better if we learn to decide rather than to predict? We first show that, if decisions are taken by a faulty deterministic policy, the observed labels are insufficient to improve it. Then, we describe how to avoid this undesirable behavior by directly learning stochastic decision policies that maximize utility under fairness constraints. Experiments on synthetic and real-world data illustrate the favorable properties of learning to decide in terms of utility and fairness.},
  archivePrefix = {arXiv},
  eprint = {1902.02979},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kilbertus et al (2019) - Fair Decisions Despite Imperfect Predictions.pdf},
  journal = {arXiv:1902.02979 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@incollection{killian2017Robust,
  title = {Robust and {{Efficient Transfer Learning}} with {{Hidden Parameter Markov Decision Processes}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 30},
  author = {Killian, Taylor W and Daulton, Samuel and Konidaris, George and {Doshi-Velez}, Finale},
  editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  year = {2017},
  pages = {6250--6261},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/yuekai/Documents/zotero/Killian et al (2017) - Robust and Efficient Transfer Learning with Hidden Parameter Markov Decision.pdf}
}

@article{kim1990Cube,
  title = {Cube {{Root Asymptotics}}},
  author = {Kim, Jeankyung and Pollard, David},
  year = {1990},
  month = mar,
  volume = {18},
  pages = {191--219},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/aos/1176347498},
  abstract = {We establish a new functional central limit theorem for empirical processes indexed by classes of functions. In a neighborhood of a fixed parameter point, an n-1/3n-1/3n\^\{-1/3\} rescaling of the parameter is compensated for by an n2/3n2/3n\^\{2/3\} rescaling of the empirical measure, resulting in a limiting Gaussian process. By means of a modified continuous mapping theorem for the location of the maximizing value, we deduce limit theorems for several statistics defined by maximization or constrained minimization of a process derived from the empirical measure. These statistics include the short, Rousseeuw's least median of squares estimator, Manski's maximum score estimator, and the maximum likelihood estimator for a monotone density. The limit theory depends on a simple new sufficient condition for a Gaussian process to achieve its maximum almost surely at a unique point.},
  file = {/Users/yuekai/Documents/zotero/Kim, Pollard (1990) - Cube Root Asymptotics.pdf},
  journal = {The Annals of Statistics},
  language = {EN},
  mrnumber = {MR1041391},
  number = {1},
  zmnumber = {0703.62063}
}

@article{kim2011Modeling,
  title = {Modeling {{Social Networks}} with {{Node Attributes}} Using the {{Multiplicative Attribute Graph Model}}},
  author = {Kim, Myunghwan and Leskovec, Jure},
  year = {2011},
  month = jun,
  abstract = {Networks arising from social, technological and natural domains exhibit rich connectivity patterns and nodes in such networks are often labeled with attributes or features. We address the question of modeling the structure of networks where nodes have attribute information. We present a Multiplicative Attribute Graph (MAG) model that considers nodes with categorical attributes and models the probability of an edge as the product of individual attribute link formation affinities. We develop a scalable variational expectation maximization parameter estimation method. Experiments show that MAG model reliably captures network connectivity as well as provides insights into how different attributes shape the network structure.},
  archivePrefix = {arXiv},
  eprint = {1106.5053},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kim, Leskovec (2011) - Modeling Social Networks with Node Attributes using the Multiplicative.pdf},
  journal = {arXiv:1106.5053 [physics]},
  keywords = {Computer Science - Social and Information Networks,Physics - Physics and Society},
  primaryClass = {physics}
}

@article{kim2017Review,
  title = {A {{Review}} of {{Dynamic Network Models}} with {{Latent Variables}}},
  author = {Kim, Bomin and Lee, Kevin and Xue, Lingzhou and Niu, Xiaoyue},
  year = {2017},
  month = nov,
  abstract = {We present a selective review of statistical modeling of dynamic networks. We focus on models with latent variables, specifically, the latent space models and the latent class models (or stochastic blockmodels), which investigate both the observed features and the unobserved structure of networks. We begin with an overview of the static models, and then we introduce the dynamic extensions. For each dynamic model, we also discuss its applications that have been studied in the literature, with the data source listed in Appendix. Based on the review, we summarize a list of open problems and challenges in dynamic network modeling with latent variables.},
  archivePrefix = {arXiv},
  eprint = {1711.10421},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kim et al (2017) - A Review of Dynamic Network Models with Latent Variables.pdf},
  journal = {arXiv:1711.10421 [stat]},
  keywords = {Statistics - Methodology,Statistics - Other Statistics},
  primaryClass = {stat}
}

@article{kim2017Wasserstein,
  title = {Wasserstein Barycenters over {{Riemannian}} Manifolds},
  author = {Kim, Young-Heon and Pass, Brendan},
  year = {2017},
  month = feb,
  volume = {307},
  pages = {640--683},
  issn = {0001-8708},
  doi = {10.1016/j.aim.2016.11.026},
  abstract = {We study barycenters in the space of probability measures on a Riemannian manifold, equipped with the Wasserstein metric. Under reasonable assumptions, we establish absolute continuity of the barycenter of general measures {$\Omega\in$}P(P(M)) on Wasserstein space, extending on one hand, results in the Euclidean case (for barycenters between finitely many measures) of Agueh and Carlier [1] to the Riemannian setting, and on the other hand, results in the Riemannian case of Cordero-Erausquin, McCann, Schmuckenschl\"ager [12] for barycenters between two measures to the multi-marginal setting. Our work also extends these results to the case where {$\Omega$} is not finitely supported. As applications, we prove versions of Jensen's inequality on Wasserstein space and a generalized Brunn\textendash Minkowski inequality for a random measurable set on a Riemannian manifold.},
  file = {/Users/yuekai/Documents/zotero/Kim, Pass (2017) - Wasserstein barycenters over Riemannian manifolds.pdf},
  journal = {Advances in Mathematics},
  language = {en}
}

@article{kim2018Bayesian,
  title = {Bayesian {{Model}}-{{Agnostic Meta}}-{{Learning}}},
  author = {Kim, Taesup and Yoon, Jaesik and Dia, Ousmane and Kim, Sungwoong and Bengio, Yoshua and Ahn, Sungjin},
  year = {2018},
  month = jun,
  abstract = {Learning to infer Bayesian posterior from a few-shot dataset is an important step towards robust meta-learning due to the model uncertainty inherent in the problem. In this paper, we propose a novel Bayesian model-agnostic meta-learning method. The proposed method combines scalable gradient-based meta-learning with nonparametric variational inference in a principled probabilistic framework. During fast adaptation, the method is capable of learning complex uncertainty structure beyond a point estimate or a simple Gaussian approximation. In addition, a robust Bayesian meta-update mechanism with a new meta-loss prevents overfitting during meta-update. Remaining an efficient gradient-based meta-learner, the method is also model-agnostic and simple to implement. Experiment results show the accuracy and robustness of the proposed method in various tasks: sinusoidal regression, image classification, active learning, and reinforcement learning.},
  archivePrefix = {arXiv},
  eprint = {1806.03836},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kim et al (2018) - Bayesian Model-Agnostic Meta-Learning.pdf},
  journal = {arXiv:1806.03836 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{kim2018Fairness,
  title = {Fairness {{Through Computationally}}-{{Bounded Awareness}}},
  author = {Kim, Michael P. and Reingold, Omer and Rothblum, Guy N.},
  year = {2018},
  month = mar,
  abstract = {We study the problem of fair classification within the versatile framework of Dwork et al. [ITCS '12], which assumes the existence of a metric that measures similarity between pairs of individuals. Unlike earlier work, we do not assume that the entire metric is known to the learning algorithm; instead, the learner can query this arbitrary metric a bounded number of times. We propose a new notion of fairness called metric multifairness and show how to achieve this notion in our setting. Metric multifairness is parameterized by a similarity metric \$d\$ on pairs of individuals to classify and a rich collection \$\{\textbackslash cal C\}\$ of (possibly overlapping) "comparison sets" over pairs of individuals. At a high level, metric multifairness guarantees that similar subpopulations are treated similarly, as long as these subpopulations are identified within the class \$\{\textbackslash cal C\}\$.},
  archivePrefix = {arXiv},
  eprint = {1803.03239},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kim et al (2018) - Fairness Through Computationally-Bounded Awareness.pdf},
  journal = {arXiv:1803.03239 [cs]},
  keywords = {Computer Science - Computational Complexity,Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@inproceedings{kim2018Interpretability,
  title = {Interpretability {{Beyond Feature Attribution}}: {{Quantitative Testing}} with {{Concept Activation Vectors}} ({{TCAV}})},
  shorttitle = {Interpretability {{Beyond Feature Attribution}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and Sayres, Rory},
  year = {2018},
  month = jul,
  pages = {2668--2677},
  abstract = {The interpretation of deep learning models is a challenge due to their size, complexity, and often opaque internal state. In addition, many systems, such as image classifiers, operate on low-level ...},
  file = {/Users/yuekai/Documents/zotero/Kim et al (2018) - Interpretability Beyond Feature Attribution.pdf},
  language = {en}
}

@article{kim2018Multiaccuracy,
  title = {Multiaccuracy: {{Black}}-{{Box Post}}-{{Processing}} for {{Fairness}} in {{Classification}}},
  shorttitle = {Multiaccuracy},
  author = {Kim, Michael P. and Ghorbani, Amirata and Zou, James},
  year = {2018},
  month = may,
  abstract = {Prediction systems are successfully deployed in applications ranging from disease diagnosis, to predicting credit worthiness, to image recognition. Even when the overall accuracy is high, these systems may exhibit systematic biases that harm specific subpopulations; such biases may arise inadvertently due to underrepresentation in the data used to train a machine-learning model, or as the result of intentional malicious discrimination. We develop a rigorous framework of *multiaccuracy* auditing and post-processing to ensure accurate predictions across *identifiable subgroups*. Our algorithm, MULTIACCURACY-BOOST, works in any setting where we have black-box access to a predictor and a relatively small set of labeled data for auditing; importantly, this black-box framework allows for improved fairness and accountability of predictions, even when the predictor is minimally transparent. We prove that MULTIACCURACY-BOOST converges efficiently and show that if the initial model is accurate on an identifiable subgroup, then the post-processed model will be also. We experimentally demonstrate the effectiveness of the approach to improve the accuracy among minority subgroups in diverse applications (image classification, finance, population health). Interestingly, MULTIACCURACY-BOOST can improve subpopulation accuracy (e.g. for "black women") even when the sensitive features (e.g. "race", "gender") are not given to the algorithm explicitly.},
  archivePrefix = {arXiv},
  eprint = {1805.12317},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kim et al (2018) - Multiaccuracy.pdf},
  journal = {arXiv:1805.12317 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{kim2019Learning,
  title = {Learning {{Not}} to {{Learn}}: {{Training Deep Neural Networks}} with {{Biased Data}}},
  shorttitle = {Learning {{Not}} to {{Learn}}},
  author = {Kim, Byungju and Kim, Hyunwoo and Kim, Kyungsu and Kim, Sungjin and Kim, Junmo},
  year = {2019},
  month = apr,
  abstract = {We propose a novel regularization algorithm to train deep neural networks, in which data at training time is severely biased. Since a neural network efficiently learns data distribution, a network is likely to learn the bias information to categorize input data. It leads to poor performance at test time, if the bias is, in fact, irrelevant to the categorization. In this paper, we formulate a regularization loss based on mutual information between feature embedding and bias. Based on the idea of minimizing this mutual information, we propose an iterative algorithm to unlearn the bias information. We employ an additional network to predict the bias distribution and train the network adversarially against the feature embedding network. At the end of learning, the bias prediction network is not able to predict the bias not because it is poorly trained, but because the feature embedding network successfully unlearns the bias information. We also demonstrate quantitative and qualitative experimental results which show that our algorithm effectively removes the bias information from feature embedding.},
  archivePrefix = {arXiv},
  eprint = {1812.10352},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kim et al (2019) - Learning Not to Learn.pdf},
  journal = {arXiv:1812.10352 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryClass = {cs}
}

@article{kim2019PreferenceInformed,
  title = {Preference-{{Informed Fairness}}},
  author = {Kim, Michael P. and Korolova, Aleksandra and Rothblum, Guy N. and Yona, Gal},
  year = {2019},
  month = apr,
  abstract = {As algorithms are increasingly used to make important decisions pertaining to individuals, algorithmic discrimination is becoming a prominent concern. The seminal work of Dwork et al. [ITCS 2012] introduced the notion of individual fairness (IF): given a task-specific similarity metric, every pair of similar individuals should receive similar outcomes. In this work, we study fairness when individuals have diverse preferences over the possible outcomes. We show that in such settings, individual fairness can be too restrictive: requiring individual fairness can lead to less-preferred outcomes for the very individuals that IF aims to protect (e.g. a protected minority group). We introduce and study a new notion of preference-informed individual fairness (PIIF), a relaxation of individual fairness that allows for outcomes that deviate from IF, provided the deviations are in line with individuals' preferences. We show that PIIF can allow for solutions that are considerably more beneficial to individuals than the best IF solution. We further show how to efficiently optimize any convex objective over the outcomes subject to PIIF, for a rich class of individual preferences. Motivated by fairness concerns in targeted advertising, we apply this new fairness notion to the multiple-task setting introduced by Dwork and Ilvento [ITCS 2019]. We show that, in this setting too, PIIF can allow for considerably more beneficial solutions, and we extend our efficient optimization algorithm to this setting.},
  archivePrefix = {arXiv},
  eprint = {1904.01793},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kim et al (2019) - Preference-Informed Fairness.pdf},
  journal = {arXiv:1904.01793 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{kim2020FACT,
  title = {{{FACT}}: {{A Diagnostic}} for {{Group Fairness Trade}}-Offs},
  shorttitle = {{{FACT}}},
  author = {Kim, Joon Sik and Chen, Jiahao and Talwalkar, Ameet},
  year = {2020},
  month = jul,
  abstract = {Group fairness, a class of fairness notions that measure how different groups of individuals are treated differently according to their protected attributes, has been shown to conflict with one another, often with a necessary cost in loss of model's predictive performance. We propose a general diagnostic that enables systematic characterization of these trade-offs in group fairness. We observe that the majority of group fairness notions can be expressed via the fairness-confusion tensor, which is the confusion matrix split according to the protected attribute values. We frame several optimization problems that directly optimize both accuracy and fairness objectives over the elements of this tensor, which yield a general perspective for understanding multiple trade-offs including group fairness incompatibilities. It also suggests an alternate post-processing method for designing fair classifiers. On synthetic and real datasets, we demonstrate the use cases of our diagnostic, particularly on understanding the trade-off landscape between accuracy and fairness.},
  archivePrefix = {arXiv},
  eprint = {2004.03424},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kim et al (2020) - FACT.pdf},
  journal = {arXiv:2004.03424 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{king2019Why,
  title = {Why {{Propensity Scores Should Not Be Used}} for {{Matching}}},
  author = {King, Gary and Nielsen, Richard},
  year = {2019},
  month = oct,
  volume = {27},
  pages = {435--454},
  issn = {1047-1987, 1476-4989},
  doi = {10.1017/pan.2019.11},
  abstract = {We show that propensity score matching (PSM), an enormously popular method of preprocessing data for causal inference, often accomplishes the opposite of its intended goal \textemdash{} thus increasing imbalance, inefficiency, model dependence, and bias. The weakness of PSM comes from its attempts to approximate a completely randomized experiment, rather than, as with other matching methods, a more efficient fully blocked randomized experiment. PSM is thus uniquely blind to the often large portion of imbalance that can be eliminated by approximating full blocking with other matching methods. Moreover, in data balanced enough to approximate complete randomization, either to begin with or after pruning some observations, PSM approximates random matching which, we show, increases imbalance even relative to the original data. Although these results suggest researchers replace PSM with one of the other available matching methods, propensity scores have other productive uses.},
  file = {/Users/yuekai/Documents/zotero/King, Nielsen (2019) - Why Propensity Scores Should Not Be Used for Matching.pdf},
  journal = {Political Analysis},
  language = {en},
  number = {4}
}

@article{kipf2016SemiSupervised,
  title = {Semi-{{Supervised Classification}} with {{Graph Convolutional Networks}}},
  author = {Kipf, Thomas N. and Welling, Max},
  year = {2016},
  month = sep,
  abstract = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.},
  archivePrefix = {arXiv},
  eprint = {1609.02907},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kipf, Welling (2016) - Semi-Supervised Classification with Graph Convolutional Networks.pdf},
  journal = {arXiv:1609.02907 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{kiraly2014Learning,
  title = {Learning with {{Algebraic Invariances}}, and the {{Invariant Kernel Trick}}},
  author = {Kir{\'a}ly, Franz J. and Ziehe, Andreas and M{\"u}ller, Klaus-Robert},
  year = {2014},
  month = nov,
  abstract = {When solving data analysis problems it is important to integrate prior knowledge and/or structural invariances. This paper contributes by a novel framework for incorporating algebraic invariance structure into kernels. In particular, we show that algebraic properties such as sign symmetries in data, phase independence, scaling etc. can be included easily by essentially performing the kernel trick twice. We demonstrate the usefulness of our theory in simulations on selected applications such as sign-invariant spectral clustering and underdetermined ICA.},
  archivePrefix = {arXiv},
  eprint = {1411.7817},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Király et al (2014) - Learning with Algebraic Invariances, and the Invariant Kernel Trick.pdf},
  journal = {arXiv:1411.7817 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@book{kiss2017Mathematics,
  title = {Mathematics of {{Epidemics}} on {{Networks}}: {{From Exact}} to {{Approximate Models}}},
  shorttitle = {Mathematics of {{Epidemics}} on {{Networks}}},
  author = {Kiss, Istv{\'a}n Z. and Miller, Joel C. and Simon, P{\'e}ter L.},
  year = {2017},
  volume = {46},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-50806-1},
  file = {/Users/yuekai/Documents/zotero/Kiss et al (2017) - Mathematics of Epidemics on Networks.pdf},
  isbn = {978-3-319-50804-7 978-3-319-50806-1},
  language = {en},
  series = {Interdisciplinary {{Applied Mathematics}}}
}

@article{klatt2018Empirical,
  title = {Empirical {{Regularized Optimal Transport}}: {{Statistical Theory}} and {{Applications}}},
  shorttitle = {Empirical {{Regularized Optimal Transport}}},
  author = {Klatt, Marcel and Tameling, Carla and Munk, Axel},
  year = {2018},
  month = oct,
  abstract = {We derive limit distributions for certain empirical regularized optimal transport distances between probability distributions supported on a finite metric space and show consistency of the (naive) bootstrap. In particular, we prove that the empirical regularized transport plan itself asymptotically follows a Gaussian law. The theory includes the Boltzmann-Shannon entropy regularization and hence a limit law for the widely applied Sinkhorn divergence. Our approach is based on an application of the implicit function theorem to necessary and sufficient optimality conditions for the regularized transport problem. The asymptotic results are investigated in Monte Carlo simulations. We further discuss computational and statistical applications, e.g. confidence bands for colocalization analysis of protein interaction networks based on regularized optimal transport.},
  archivePrefix = {arXiv},
  eprint = {1810.09880},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Klatt et al (2018) - Empirical Regularized Optimal Transport.pdf},
  journal = {arXiv:1810.09880 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{kleijn2012BernsteinVonMises,
  title = {The {{Bernstein}}-{{Von}}-{{Mises}} Theorem under Misspecification},
  author = {Kleijn, B. J. K. and van der Vaart, A. W.},
  year = {2012},
  volume = {6},
  pages = {354--381},
  issn = {1935-7524},
  doi = {10.1214/12-EJS675},
  abstract = {We prove that the posterior distribution of a parameter in misspecified LAN parametric models can be approximated by a random normal distribution. We derive from this that Bayesian credible sets are not valid confidence sets if the model is misspecified. We obtain the result under conditions that are comparable to those in the well-specified situation: uniform testability against fixed alternatives and sufficient prior mass in neighbourhoods of the point of convergence. The rate of convergence is considered in detail, with special attention for the existence and construction of suitable test sequences. We also give a lemma to exclude testable model subsets which implies a misspecified version of Schwartz' consistency theorem, establishing weak convergence of the posterior to a measure degenerate at the point at minimal Kullback-Leibler divergence with respect to the true distribution.},
  file = {/Users/yuekai/Documents/zotero/Kleijn Vaart (2012) - The Bernstein-Von-Mises theorem under misspecification.pdf},
  journal = {Electronic Journal of Statistics},
  language = {EN},
  mrnumber = {MR2988412},
  zmnumber = {1274.62203}
}

@article{kleinberg2016Inherent,
  title = {Inherent {{Trade}}-{{Offs}} in the {{Fair Determination}} of {{Risk Scores}}},
  author = {Kleinberg, Jon and Mullainathan, Sendhil and Raghavan, Manish},
  year = {2016},
  month = sep,
  abstract = {Recent discussion in the public sphere about algorithmic classification has involved tension between competing notions of what it means for a probabilistic classification to be fair to different groups. We formalize three fairness conditions that lie at the heart of these debates, and we prove that except in highly constrained special cases, there is no method that can satisfy these three conditions simultaneously. Moreover, even satisfying all three conditions approximately requires that the data lie in an approximate version of one of the constrained special cases identified by our theorem. These results suggest some of the ways in which key notions of fairness are incompatible with each other, and hence provide a framework for thinking about the trade-offs between them.},
  archivePrefix = {arXiv},
  eprint = {1609.05807},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kleinberg et al (2016) - Inherent Trade-Offs in the Fair Determination of Risk Scores.pdf},
  journal = {arXiv:1609.05807 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{kleinberg2018Algorithmic,
  title = {Algorithmic {{Fairness}}},
  author = {Kleinberg, Jon and Ludwig, Jens and Mullainathan, Sendhil and Rambachan, Ashesh},
  year = {2018},
  volume = {108},
  pages = {22--27},
  issn = {2574-0768},
  doi = {10.1257/pandp.20181018},
  file = {/Users/yuekai/Documents/zotero/Kleinberg et al (2018) - Algorithmic Fairness.pdf},
  journal = {AEA Papers and Proceedings},
  language = {en}
}

@article{kleinberg2018Discrimination,
  title = {Discrimination in the {{Age}} of {{Algorithms}}},
  author = {Kleinberg, Jon and Ludwig, Jens and Mullainathan, Sendhil and Sunstein, Cass R.},
  year = {2018},
  month = dec,
  volume = {10},
  pages = {113--174},
  publisher = {{Oxford Academic}},
  issn = {2161-7201},
  doi = {10.1093/jla/laz001},
  abstract = {Abstract.  The law forbids discrimination. But the ambiguity of human decision-making often makes it hard for the legal system to know whether anyone has discri},
  file = {/Users/yuekai/Documents/zotero/Kleinberg et al (2018) - Discrimination in the Age of Algorithms.pdf},
  journal = {Journal of Legal Analysis},
  language = {en}
}

@article{kleinberg2018How,
  title = {How {{Do Classifiers Induce Agents To Invest Effort Strategically}}?},
  author = {Kleinberg, Jon and Raghavan, Manish},
  year = {2018},
  month = jul,
  abstract = {Algorithms are often used to produce decision-making rules that classify or evaluate individuals. When these individuals have incentives to be classified a certain way, they may behave strategically to influence their outcomes. We develop a model for how strategic agents can invest effort in order to change the outcomes they receive, and we give a tight characterization of when such agents can be incentivized to invest specified forms of effort into improving their outcomes as opposed to "gaming" the classifier. We show that whenever any "reasonable" mechanism can do so, a simple linear mechanism suffices.},
  archivePrefix = {arXiv},
  eprint = {1807.05307},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kleinberg, Raghavan (2018) - How Do Classifiers Induce Agents To Invest Effort Strategically.pdf},
  journal = {arXiv:1807.05307 [cs, stat]},
  keywords = {Computer Science - Computer Science and Game Theory,Computer Science - Computers and Society,Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{kleinberg2018Human,
  title = {Human {{Decisions}} and {{Machine Predictions}}},
  author = {Kleinberg, Jon and Lakkaraju, Himabindu and Leskovec, Jure and Ludwig, Jens and Mullainathan, Sendhil},
  year = {2018},
  month = feb,
  volume = {133},
  pages = {237--293},
  publisher = {{Oxford Academic}},
  issn = {0033-5533},
  doi = {10.1093/qje/qjx032},
  abstract = {Abstract.  Can machine learning improve human decision making? Bail decisions provide a good test case. Millions of times each year, judges make jail-or-release},
  file = {/Users/yuekai/Documents/zotero/Kleinberg et al (2018) - Human Decisions and Machine Predictions.pdf},
  journal = {The Quarterly Journal of Economics},
  language = {en},
  number = {1}
}

@article{kleinberg2018Selection,
  title = {Selection {{Problems}} in the {{Presence}} of {{Implicit Bias}}},
  author = {Kleinberg, Jon and Raghavan, Manish},
  year = {2018},
  month = jan,
  abstract = {Over the past two decades, the notion of implicit bias has come to serve as
an important component in our understanding of discrimination in activities
such as hiring, promotion, and school admissions. Research on implicit bias
posits that when people evaluate others -- for example, in a hiring context --
their unconscious biases about membership in particular groups can have an
effect on their decision-making, even when they have no deliberate intention to
discriminate against members of these groups. A growing body of experimental
work has pointed to the effect that implicit bias can have in producing adverse
outcomes.
  Here we propose a theoretical model for studying the effects of implicit bias
on selection decisions, and a way of analyzing possible procedural remedies for
implicit bias within this model. A canonical situation represented by our model
is a hiring setting: a recruiting committee is trying to choose a set of
finalists to interview among the applicants for a job, evaluating these
applicants based on their future potential, but their estimates of potential
are skewed by implicit bias against members of one group. In this model, we
show that measures such as the Rooney Rule, a requirement that at least one of
the finalists be chosen from the affected group, can not only improve the
representation of this affected group, but also lead to higher payoffs in
absolute terms for the organization performing the recruiting. However,
identifying the conditions under which such measures can lead to improved
payoffs involves subtle trade-offs between the extent of the bias and the
underlying distribution of applicant characteristics, leading to novel
theoretical questions about order statistics in the presence of probabilistic
side information.},
  file = {/Users/yuekai/Documents/zotero/Kleinberg, Raghavan (2018) - Selection Problems in the Presence of Implicit Bias.pdf},
  language = {en}
}

@article{klopp2015Oracle,
  title = {Oracle Inequalities for Network Models and Sparse Graphon Estimation},
  author = {Klopp, Olga and Tsybakov, Alexandre B. and Verzelen, Nicolas},
  year = {2015},
  month = jul,
  abstract = {Inhomogeneous random graph models encompass many network models such as stochastic block models and latent position models. We consider the problem of statistical estimation of the matrix of connection probabilities based on the observations of the adjacency matrix of the network. Taking the stochastic block model as an approximation, we construct estimators of network connection probabilities -- the ordinary block constant least squares estimator, and its restricted version. We show that they satisfy oracle inequalities with respect to the block constant oracle. As a consequence, we derive optimal rates of estimation of the probability matrix. Our results cover the important setting of sparse networks. Another consequence consists in establishing upper bounds on the minimax risks for graphon estimation in the \$L\textbackslash\_2\$ norm when the probability matrix is sampled according to a graphon model. These bounds include an additional term accounting for the "agnostic" error induced by the variability of the latent unobserved variables of the graphon model. In this setting, the optimal rates are influenced not only by the bias and variance components as in usual nonparametric problems but also include the third component, which is the agnostic error. The results shed light on the differences between estimation under the empirical loss (the probability matrix estimation) and under the integrated loss (the graphon estimation).},
  archivePrefix = {arXiv},
  eprint = {1507.04118},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Klopp et al (2015) - Oracle inequalities for network models and sparse graphon estimation.pdf},
  journal = {arXiv:1507.04118 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@inproceedings{kocaoglu2018CausalGAN,
  title = {{{CausalGAN}}: {{Learning Causal Implicit Generative Models}} with {{Adversarial Training}}},
  shorttitle = {{{CausalGAN}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Kocaoglu, Murat and Snyder, Christopher and Dimakis, Alexandros G. and Vishwanath, Sriram},
  year = {2018},
  month = feb,
  abstract = {We introduce causal implicit generative models (CiGMs): models that allow sampling from not only the true observational but also the true interventional distributions. We show that adversarial...},
  file = {/Users/yuekai/Documents/zotero/Kocaoglu et al (2018) - CausalGAN.pdf}
}

@article{koenecke2020Racial,
  title = {Racial Disparities in Automated Speech Recognition},
  author = {Koenecke, Allison and Nam, Andrew and Lake, Emily and Nudell, Joe and Quartey, Minnie and Mengesha, Zion and Toups, Connor and Rickford, John R. and Jurafsky, Dan and Goel, Sharad},
  year = {2020},
  month = apr,
  volume = {117},
  pages = {7684--7689},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1915768117},
  abstract = {Automated speech recognition (ASR) systems, which use sophisticated machine-learning algorithms to convert spoken language to text, have become increasingly widespread, powering popular virtual assistants, facilitating automated closed captioning, and enabling digital dictation platforms for health care. Over the last several years, the quality of these systems has dramatically improved, due both to advances in deep learning and to the collection of large-scale datasets used to train the systems. There is concern, however, that these tools do not work equally well for all subgroups of the population. Here, we examine the ability of five state-of-the-art ASR systems\textemdash developed by Amazon, Apple, Google, IBM, and Microsoft\textemdash to transcribe structured interviews conducted with 42 white speakers and 73 black speakers. In total, this corpus spans five US cities and consists of 19.8 h of audio matched on the age and gender of the speaker. We found that all five ASR systems exhibited substantial racial disparities, with an average word error rate (WER) of 0.35 for black speakers compared with 0.19 for white speakers. We trace these disparities to the underlying acoustic models used by the ASR systems as the race gap was equally large on a subset of identical phrases spoken by black and white individuals in our corpus. We conclude by proposing strategies\textemdash such as using more diverse training datasets that include African American Vernacular English\textemdash to reduce these performance differences and ensure speech recognition technology is inclusive.},
  chapter = {Social Sciences},
  copyright = {Copyright \textcopyright{} 2020 the Author(s). Published by PNAS.. https://creativecommons.org/licenses/by-nc-nd/4.0/This open access article is distributed under Creative Commons Attribution-NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND).},
  file = {/Users/yuekai/Documents/zotero/Koenecke et al (2020) - Racial disparities in automated speech recognition.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {fair machine learning,natural language processing,speech-to-text},
  language = {en},
  number = {14},
  pmid = {32205437}
}

@article{koenker2014Convex,
  title = {Convex {{Optimization}}, {{Shape Constraints}}, {{Compound Decisions}}, and {{Empirical Bayes Rules}}},
  author = {Koenker, Roger and Mizera, Ivan},
  year = {2014},
  month = apr,
  volume = {109},
  pages = {674--685},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.2013.869224},
  abstract = {Estimation of mixture densities for the classical Gaussian compound decision problem and their associated (empirical) Bayes rules is considered from two new perspectives. The first, motivated by Brown and Greenshtein, introduces a nonparametric maximum likelihood estimator of the mixture density subject to a monotonicity constraint on the resulting Bayes rule. The second, motivated by Jiang and Zhang, proposes a new approach to computing the Kiefer\textendash Wolfowitz nonparametric maximum likelihood estimator for mixtures. In contrast to prior methods for these problems, our new approaches are cast as convex optimization problems that can be efficiently solved by modern interior point methods. In particular, we show that the reformulation of the Kiefer\textendash Wolfowitz estimator as a convex optimization problem reduces the computational effort by several orders of magnitude for typical problems, by comparison to prior EM-algorithm based methods, and thus greatly expands the practical applicability of the resulting methods. Our new procedures are compared with several existing empirical Bayes methods in simulations employing the well-established design of Johnstone and Silverman. Some further comparisons are made based on prediction of baseball batting averages. A Bernoulli mixture application is briefly considered in the penultimate section.},
  annotation = {\_eprint: https://doi.org/10.1080/01621459.2013.869224},
  file = {/Users/yuekai/Documents/zotero/Koenker, Mizera (2014) - Convex Optimization, Shape Constraints, Compound Decisions, and Empirical Bayes.pdf;/Users/yuekai/Zotero/storage/MVUYM863/01621459.2013.html},
  journal = {Journal of the American Statistical Association},
  keywords = {Empirical Bayes,Kiefer-Wolfowitz maximum likelihood estimator,Mixture models},
  number = {506}
}

@article{koh2017Understanding,
  title = {Understanding {{Black}}-Box {{Predictions}} via {{Influence Functions}}},
  author = {Koh, Pang Wei and Liang, Percy},
  year = {2017},
  month = mar,
  abstract = {How can we explain the predictions of a black-box model? In this paper, we use influence functions -- a classic technique from robust statistics -- to trace a model's prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks.},
  archivePrefix = {arXiv},
  eprint = {1703.04730},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Koh, Liang (2017) - Understanding Black-box Predictions via Influence Functions.pdf},
  journal = {arXiv:1703.04730 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{koh2018Stronger,
  title = {Stronger {{Data Poisoning Attacks Break Data Sanitization Defenses}}},
  author = {Koh, Pang Wei and Steinhardt, Jacob and Liang, Percy},
  year = {2018},
  month = nov,
  abstract = {Machine learning models trained on data from the outside world can be corrupted by data poisoning attacks that inject malicious points into the models' training sets. A common defense against these attacks is data sanitization: first filter out anomalous training points before training the model. Can data poisoning attacks break data sanitization defenses? In this paper, we develop three new attacks that can all bypass a broad range of data sanitization defenses, including commonly-used anomaly detectors based on nearest neighbors, training loss, and singular-value decomposition. For example, our attacks successfully increase the test error on the Enron spam detection dataset from 3\% to 24\% and on the IMDB sentiment classification dataset from 12\% to 29\% by adding just 3\% poisoned data. In contrast, many existing attacks from the literature do not explicitly consider defenses, and we show that those attacks are ineffective in the presence of the defenses we consider. Our attacks are based on two ideas: (i) we coordinate our attacks to place poisoned points near one another, which fools some anomaly detectors, and (ii) we formulate each attack as a constrained optimization problem, with constraints designed to ensure that the poisoned points evade detection. While this optimization involves solving an expensive bilevel problem, we explore and develop three efficient approximations to this problem based on influence functions; minimax duality; and the Karush-Kuhn-Tucker (KKT) conditions. Our results underscore the urgent need to develop more sophisticated and robust defenses against data poisoning attacks.},
  archivePrefix = {arXiv},
  eprint = {1811.00741},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Koh et al (2018) - Stronger Data Poisoning Attacks Break Data Sanitization Defenses.pdf},
  journal = {arXiv:1811.00741 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{koh2019Accuracy,
  title = {On the {{Accuracy}} of {{Influence Functions}} for {{Measuring Group Effects}}},
  author = {Koh, Pang Wei and Ang, Kai-Siang and Teo, Hubert H. K. and Liang, Percy},
  year = {2019},
  month = may,
  abstract = {Influence functions estimate the effect of removing particular training points on a model without needing to retrain it. They are based on a first-order approximation that is accurate for small changes in the model, and so are commonly used for studying the effect of individual points in large datasets. However, we often want to study the effects of large groups of training points, e.g., to diagnose batch effect or apportion credit between different data sources. Removing such large groups can result in significant changes to the model. Are influence functions still accurate in this setting? In this paper, we find that across many different types of groups and in a range of real-world datasets, the influence of a group correlates surprisingly well with its actual effect, even if the absolute and relative error can be large. Our theoretical analysis shows that such correlation arises under certain settings but need not hold in general, indicating that real-world datasets have particular properties that keep the influence approximation well-behaved.},
  archivePrefix = {arXiv},
  eprint = {1905.13289},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Koh et al (2019) - On the Accuracy of Influence Functions for Measuring Group Effects.pdf},
  journal = {arXiv:1905.13289 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{kohavi1996Scaling,
  title = {Scaling {{Up}} the {{Accuracy}} of {{Naive}}-{{Bayes Classifiers}}: A {{Decision}}-{{Tree Hybrid}}},
  booktitle = {{{PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING}}},
  author = {Kohavi, Ron},
  year = {1996},
  pages = {6},
  abstract = {Naive-Bayes induction algorithms were previously shown to be surprisingly accurate on many classi cation tasks even when the conditional independence assumption on which they are based is violated. However, most studies were done on small databases. We show that in some larger databases, the accuracy of Naive-Bayes does not scale up as well as decision trees. We then propose a new algorithm, NBTree, which induces a hybrid of decision-tree classi ers and NaiveBayes classi ers: the decision-tree nodes contain univariate splits as regular decision-trees, but the leaves contain Naive-Bayesian classi ers. The approach retains the interpretability of Naive-Bayes and decision trees, while resulting in classi ers that frequently outperform both constituents, especially in the larger databases tested.},
  file = {/Users/yuekai/Documents/zotero/Kohavi (1996) - Scaling Up the Accuracy of Naive-Bayes Classifiers.pdf},
  language = {en}
}

@article{komolafe2017Statistical,
  title = {Statistical {{Evaluation}} of {{Spectral Methods}} for {{Anomaly Detection}} in {{Networks}}},
  author = {Komolafe, Tomilayo and Quevedo, A. Valeria and Sengupta, Srijan and Woodall, William H.},
  year = {2017},
  month = nov,
  abstract = {Monitoring of networks for anomaly detection has attracted a lot of attention in recent years especially with the rise of connected devices and social networks. This is of importance as anomaly detection could span a wide range of application, from detecting terrorist cells in counter-terrorism efforts to phishing attacks in social network circles. For this reason, numerous techniques for anomaly detection have been introduced. However, application of these techniques to more complex network models is hindered by various challenges such as the size of the network being investigated, how much apriori information is needed, the size of the anomalous graph, among others. A recent technique introduced by Miller et al, which relies on a spectral framework for anomaly detection, has the potential to address many of these challenges. In their discussion of the spectral framework, three algorithms were proposed that relied on the eigenvalues and eigenvectors of the residual matrix of a binary network. The authors demonstrated the ability to detect anomalous subgraphs that were less than 1\% of the network size. However, to date, there is little work that has been done to evaluate the statistical performance of these algorithms. This study investigates the statistical properties of the spectral methods, specifically the Chi-square and L1 norm algorithm proposed by Miller. We will analyze the performance of the algorithm using simulated networks and also extend the method's application to count networks. Finally we will make some methodological improvements and recommendations to both algorithms.},
  archivePrefix = {arXiv},
  eprint = {1711.01378},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Komolafe et al (2017) - Statistical Evaluation of Spectral Methods for Anomaly Detection in Networks.pdf},
  journal = {arXiv:1711.01378 [stat]},
  keywords = {Statistics - Applications},
  primaryClass = {stat}
}

@article{korotin2020Wasserstein2,
  title = {Wasserstein-2 {{Generative Networks}}},
  author = {Korotin, Alexander and Egiazarian, Vage and Asadulaev, Arip and Burnaev, Evgeny},
  year = {2020},
  month = feb,
  abstract = {Generative Adversarial Networks training is not easy due to the minimax nature of the optimization objective. In this paper, we propose a novel end-to-end algorithm for training generative models which uses a non-minimax objective simplifying model training. The proposed algorithm uses the approximation of Wasserstein-2 distance by Input Convex Neural Networks. From the theoretical side, we estimate the properties of the generative mapping fitted by the algorithm. From the practical side, we conduct computational experiments which confirm the efficiency of our algorithm in various applied problems: image-to-image color transfer, latent space optimal transport, image-to-image style transfer, and domain adaptation.},
  archivePrefix = {arXiv},
  eprint = {1909.13082},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Korotin et al (2020) - Wasserstein-2 Generative Networks.pdf},
  journal = {arXiv:1909.13082 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{korpelevich1976extragradient,
  title = {The Extragradient Method for Finding Saddle Points and Other Problems},
  author = {Korpelevich, G. M.},
  year = {1976},
  volume = {12},
  pages = {747--756},
  journal = {Ekonomika i Matematicheskie Metody}
}

@article{kosmidis2010generic,
  title = {A Generic Algorithm for Reducing Bias in Parametric Estimation},
  author = {Kosmidis, Ioannis and Firth, David},
  year = {2010},
  volume = {4},
  pages = {1097--1112},
  issn = {1935-7524},
  doi = {10.1214/10-EJS579},
  abstract = {A general iterative algorithm is developed for the computation of reduced-bias parameter estimates in regular statistical models through adjustments to the score function. The algorithm unifies and provides appealing new interpretation for iterative methods that have been published previously for some specific model classes. The new algorithm can usefully be viewed as a series of iterative bias corrections, thus facilitating the adjusted score approach to bias reduction in any model for which the first-order bias of the maximum likelihood estimator has already been derived. The method is tested by application to a logit-linear multiple regression model with beta-distributed responses; the results confirm the effectiveness of the new algorithm, and also reveal some important errors in the existing literature on beta regression.},
  file = {/Users/yuekai/Documents/zotero/Kosmidis, Firth (2010) - A generic algorithm for reducing bias in parametric estimation.pdf},
  journal = {Electronic Journal of Statistics},
  language = {EN},
  mrnumber = {MR2735881},
  zmnumber = {1329.62103}
}

@article{kosmidis2014Bias,
  title = {Bias in Parametric Estimation: Reduction and Useful Side-Effects: {{Bias}} in Parametric Estimation},
  shorttitle = {Bias in Parametric Estimation},
  author = {Kosmidis, Ioannis},
  year = {2014},
  month = may,
  volume = {6},
  pages = {185--196},
  issn = {19395108},
  doi = {10.1002/wics.1296},
  file = {/Users/yuekai/Documents/zotero/Kosmidis (2014) - Bias in parametric estimation.pdf},
  journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
  language = {en},
  number = {3}
}

@article{kouw2018introduction,
  title = {An Introduction to Domain Adaptation and Transfer Learning},
  author = {Kouw, Wouter M. and Loog, Marco},
  year = {2018},
  month = dec,
  abstract = {In machine learning, if the training data is an unbiased sample of an underlying distribution, then the learned classification function will make accurate predictions for new samples. However, if the training data is not an unbiased sample, then there will be differences between how the training data is distributed and how the test data is distributed. Standard classifiers cannot cope with changes in data distributions between training and test phases, and will not perform well. Domain adaptation and transfer learning are sub-fields within machine learning that are concerned with accounting for these types of changes. Here, we present an introduction to these fields, guided by the question: when and how can a classifier generalize from a source to a target domain? We will start with a brief introduction into risk minimization, and how transfer learning and domain adaptation expand upon this framework. Following that, we discuss three special cases of data set shift, namely prior, covariate and concept shift. For more complex domain shifts, there are a wide variety of approaches. These are categorized into: importance-weighting, subspace mapping, domain-invariant spaces, feature augmentation, minimax estimators and robust algorithms. A number of points will arise, which we will discuss in the last section. We conclude with the remark that many open questions will have to be addressed before transfer learners and domain-adaptive classifiers become practical.},
  archivePrefix = {arXiv},
  eprint = {1812.11806},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kouw, Loog (2018) - An introduction to domain adaptation and transfer learning.pdf},
  journal = {arXiv:1812.11806 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{kpotufe2017Lipschitz,
  title = {Lipschitz {{Density}}-{{Ratios}}, {{Structured Data}}, and {{Data}}-Driven {{Tuning}}},
  booktitle = {Proceedings of the 20th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Kpotufe, Samory},
  year = {2017},
  pages = {14},
  address = {{Fort Lauderdale, Florida}},
  abstract = {Density-ratio estimation (i.e. estimating f = fQ/fP for two unknown distributions Q and P ) has proved useful in many Machine Learning tasks, e.g., risk-calibration in transfer-learning, two-sample tests, and also useful in common techniques such importance sampling and bias correction. While there are many important analyses of this estimation problem, the present paper derives convergence rates in other practical settings that are less understood, namely, extensions of traditional Lipschitz smoothness conditions, and common high-dimensional settings with structured data (e.g. manifold data, sparse data). Various interesting facts, which hold in earlier settings, are shown to extend to these settings. Namely, (1) optimal rates depend only on the smoothness of the ratio f , and not on the densities fQ, fP , supporting the belief that plugging in estimates for fQ, fP is suboptimal; (2) optimal rates depend only on the intrinsic dimension of data, i.e. this problem \textendash{} unlike density estimation \textendash{} escapes the curse of dimension.},
  file = {/Users/yuekai/Documents/zotero/Kpotufe (2017) - Lipschitz Density-Ratios, Structured Data, and Data-driven Tuning.pdf},
  language = {en}
}

@article{kpotufe2018Marginal,
  title = {Marginal {{Singularity}}, and the {{Benefits}} of {{Labels}} in {{Covariate}}-{{Shift}}},
  author = {Kpotufe, Samory and Martinet, Guillaume},
  year = {2018},
  month = mar,
  abstract = {We present new minimax results that concisely capture the relative benefits of source and target labeled data, under covariate-shift. Namely, we show that the benefits of target labels are controlled by a transfer-exponent \$\textbackslash gamma\$ that encodes how singular Q is locally w.r.t. P, and interestingly allows situations where transfer did not seem possible under previous insights. In fact, our new minimax analysis - in terms of \$\textbackslash gamma\$ - reveals a continuum of regimes ranging from situations where target labels have little benefit, to regimes where target labels dramatically improve classification. We then show that a recently proposed semi-supervised procedure can be extended to adapt to unknown \$\textbackslash gamma\$, and therefore requests labels only when beneficial, while achieving minimax transfer rates.},
  archivePrefix = {arXiv},
  eprint = {1803.01833},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kpotufe, Martinet (2018) - Marginal Singularity, and the Benefits of Labels in Covariate-Shift.pdf},
  journal = {arXiv:1803.01833 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{krishnamurthy2018Semiparametric,
  title = {Semiparametric {{Contextual Bandits}}},
  author = {Krishnamurthy, Akshay and Wu, Zhiwei Steven and Syrgkanis, Vasilis},
  year = {2018},
  month = mar,
  abstract = {This paper studies semiparametric contextual bandits, a generalization of the linear stochastic bandit problem where the reward for an action is modeled as a linear function of known action features confounded by an non-linear action-independent term. We design new algorithms that achieve \$\textbackslash tilde\{O\}(d\textbackslash sqrt\{T\})\$ regret over \$T\$ rounds, when the linear function is \$d\$-dimensional, which matches the best known bounds for the simpler unconfounded case and improves on a recent result of Greenewald et al. (2017). Via an empirical evaluation, we show that our algorithms outperform prior approaches when there are non-linear confounding effects on the rewards. Technically, our algorithms use a new reward estimator inspired by doubly-robust approaches and our proofs require new concentration inequalities for self-normalized martingales.},
  archivePrefix = {arXiv},
  eprint = {1803.04204},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Krishnamurthy et al (2018) - Semiparametric Contextual Bandits.pdf},
  journal = {arXiv:1803.04204 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{krivelevich2001largest,
  title = {{{THe}} Largest Eigenvalue of Sparse Random Graphs},
  author = {Krivelevich, Michael and Sudakov, Benny},
  year = {2001},
  month = jun,
  abstract = {We prove that for all values of the edge probability p(n) the largest eigenvalue of a random graph G(n,p) satisfies almost surely: \textbackslash lambda\_1(G)=(1+o(1))max\{\textbackslash sqrt\{\textbackslash Delta\},np\}, where \textbackslash Delta is a maximal degree of G, and the o(1) term tends to zero as max\{\textbackslash sqrt\{\textbackslash Delta\},np\} tends to infinity.},
  archivePrefix = {arXiv},
  eprint = {math/0106066},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Krivelevich, Sudakov (2001) - THe largest eigenvalue of sparse random graphs.pdf},
  journal = {arXiv:math/0106066},
  keywords = {Mathematics - Combinatorics,Mathematics - Probability}
}

@article{kuang2020Ivy,
  title = {Ivy: {{Instrumental Variable Synthesis}} for {{Causal Inference}}},
  shorttitle = {Ivy},
  author = {Kuang, Zhaobin and Sala, Frederic and Sohoni, Nimit and Wu, Sen and {C{\'o}rdova-Palomera}, Aldo and Dunnmon, Jared and Priest, James and R{\'e}, Christopher},
  year = {2020},
  month = apr,
  abstract = {A popular way to estimate the causal effect of a variable x on y from observational data is to use an instrumental variable (IV): a third variable z that affects y only through x. The more strongly z is associated with x, the more reliable the estimate is, but such strong IVs are difficult to find. Instead, practitioners combine more commonly available IV candidates---which are not necessarily strong, or even valid, IVs---into a single "summary" that is plugged into causal effect estimators in place of an IV. In genetic epidemiology, such approaches are known as allele scores. Allele scores require strong assumptions---independence and validity of all IV candidates---for the resulting estimate to be reliable. To relax these assumptions, we propose Ivy, a new method to combine IV candidates that can handle correlated and invalid IV candidates in a robust manner. Theoretically, we characterize this robustness, its limits, and its impact on the resulting causal estimates. Empirically, Ivy can correctly identify the directionality of known relationships and is robust against false discovery (median effect size {$<$}= 0.025) on three real-world datasets with no causal effects, while allele scores return more biased estimates (median effect size {$>$}= 0.118).},
  archivePrefix = {arXiv},
  eprint = {2004.05316},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kuang et al (2020) - Ivy.pdf},
  journal = {arXiv:2004.05316 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{kubat1998Machine,
  title = {Machine {{Learning}} for the {{Detection}} of {{Oil Spills}} in {{Satellite Radar Images}}},
  author = {Kubat, Miroslav and Holte, Robert C. and Matwin, Stan},
  year = {1998},
  month = feb,
  volume = {30},
  pages = {195--215},
  issn = {1573-0565},
  doi = {10.1023/A:1007452223027},
  abstract = {During a project examining the use of machine learning techniques for oil spill detection, we encountered several essential questions that we believe deserve the attention of the research community. We use our particular case study to illustrate such issues as problem formulation, selection of evaluation measures, and data preparation. We relate these issues to properties of the oil spill application, such as its imbalanced class distribution, that are shown to be common to many applications. Our solutions to these issues are implemented in the Canadian Environmental Hazards Detection System (CEHDS), which is about to undergo field testing.},
  file = {/Users/yuekai/Documents/zotero/Kubat et al (1998) - Machine Learning for the Detection of Oil Spills in Satellite Radar Images.pdf},
  journal = {Machine Learning},
  language = {en},
  number = {2}
}

@article{kulis2013Metric,
  title = {Metric {{Learning}}: {{A Survey}}},
  shorttitle = {Metric {{Learning}}},
  author = {Kulis, Brian},
  year = {2013},
  volume = {5},
  pages = {287--364},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000019},
  abstract = {The metric learning problem is concerned with learning a distance function tuned to a particular task, and has been shown to be useful when used in conjunction with nearest-neighbor methods and other techniques that rely on distances or similarities. This survey presents an overview of existing research in metric learning, including recent progress on scaling to high-dimensional feature spaces and to data sets with an extremely large number of data points. A goal of the survey is to present as unified as possible a framework under which existing research on metric learning can be cast. The first part of the survey focuses on linear metric learning approaches, mainly concentrating on the class of Mahalanobis distance learning methods. We then discuss nonlinear metric learning approaches, focusing on the connections between the nonlinear and linear approaches. Finally, we discuss extensions of metric learning, as well as applications to a variety of problems in computer vision, text analysis, program analysis, and multimedia.},
  file = {/Users/yuekai/Documents/zotero/Kulis (2013) - Metric Learning.pdf},
  journal = {Foundations and Trends\textregistered{} in Machine Learning},
  language = {en},
  number = {4}
}

@inproceedings{kumar2010Generalized,
  title = {Generalized Distances between Rankings},
  booktitle = {Proceedings of the 19th International Conference on {{World}} Wide Web},
  author = {Kumar, Ravi and Vassilvitskii, Sergei},
  year = {2010},
  month = apr,
  pages = {571--580},
  publisher = {{Association for Computing Machinery}},
  address = {{Raleigh, North Carolina, USA}},
  doi = {10.1145/1772690.1772749},
  abstract = {Spearman's footrule and Kendall's tau are two well established distances between rankings. They, however, fail to take into account concepts crucial to evaluating a result set in information retrieval: element relevance and positional information. That is, changing the rank of a highly-relevant document should result in a higher penalty than changing the rank of an irrelevant document; a similar logic holds for the top versus the bottom of the result ordering. In this work, we extend both of these metrics to those with position and element weights, and show that a variant of the Diaconis-Graham inequality still holds - the generalized two measures remain within a constant factor of each other for all permutations. We continue by extending the element weights into a distance metric between elements. For example, in search evaluation, swapping the order of two nearly duplicate results should result in little penalty, even if these two are highly relevant and appear at the top of the list. We extend the distance measures to this more general case and show that they remain within a constant factor of each other. We conclude by conducting simple experiments on web search data with the proposed measures. Our experiments show that the weighted generalizations are more robust and consistent with each other than their unweighted counter-parts.},
  file = {/Users/yuekai/Documents/zotero/Kumar, Vassilvitskii (2010) - Generalized distances between rankings.pdf},
  isbn = {978-1-60558-799-8},
  series = {{{WWW}} '10}
}

@article{kumar2017Semisupervised,
  title = {Semi-Supervised {{Learning}} with {{GANs}}: {{Manifold Invariance}} with {{Improved Inference}}},
  shorttitle = {Semi-Supervised {{Learning}} with {{GANs}}},
  author = {Kumar, Abhishek and Sattigeri, Prasanna and Fletcher, P. Thomas},
  year = {2017},
  month = may,
  abstract = {Semi-supervised learning methods using Generative Adversarial Networks (GANs) have shown promising empirical success recently. Most of these methods use a shared discriminator/classifier which discriminates real examples from fake while also predicting the class label. Motivated by the ability of the GANs generator to capture the data manifold well, we propose to estimate the tangent space to the data manifold using GANs and employ it to inject invariances into the classifier. In the process, we propose enhancements over existing methods for learning the inverse mapping (i.e., the encoder) which greatly improves in terms of semantic similarity of the reconstructed sample with the input sample. We observe considerable empirical gains in semi-supervised learning over baselines, particularly in the cases when the number of labeled examples is low. We also provide insights into how fake examples influence the semi-supervised learning procedure.},
  archivePrefix = {arXiv},
  eprint = {1705.08850},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kumar et al (2017) - Semi-supervised Learning with GANs.pdf},
  journal = {arXiv:1705.08850 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{kurakin2016Adversarial,
  title = {Adversarial {{Machine Learning}} at {{Scale}}},
  author = {Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  year = {2016},
  month = nov,
  abstract = {Adversarial examples are malicious inputs designed to fool machine learning
models. They often transfer from one model to another, allowing attackers to
mount black box attacks without knowledge of the target model's parameters.
Adversarial training is the process of explicitly training a model on
adversarial examples, in order to make it more robust to attack or to reduce
its test error on clean inputs. So far, adversarial training has primarily been
applied to small problems. In this research, we apply adversarial training to
ImageNet. Our contributions include: (1) recommendations for how to succesfully
scale adversarial training to large models and datasets, (2) the observation
that adversarial training confers robustness to single-step attack methods, (3)
the finding that multi-step attack methods are somewhat less transferable than
single-step attack methods, so single-step attacks are the best for mounting
black-box attacks, and (4) resolution of a "label leaking" effect that causes
adversarially trained models to perform better on adversarial examples than on
clean examples, because the adversarial example construction process uses the
true label and the model can learn to exploit regularities in the construction
process.},
  file = {/Users/yuekai/Documents/zotero/Kurakin et al (2016) - Adversarial Machine Learning at Scale.pdf},
  language = {en}
}

@article{kurakin2016Adversariala,
  title = {Adversarial Examples in the Physical World},
  author = {Kurakin, Alexey and Goodfellow, Ian J. and Bengio, Samy},
  year = {2016},
  month = nov,
  abstract = {Most existing machine learning classifiers are highly vulnerable to adversarial examples.
  An adversarial example is a sample of input data which has been modified
  very slightly in a way that is...},
  file = {/Users/yuekai/Documents/zotero/Kurakin et al (2016) - Adversarial examples in the physical world.pdf}
}

@inproceedings{kusner2015Word,
  title = {From {{Word Embeddings To Document Distances}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Kusner, Matt and Sun, Yu and Kolkin, Nicholas and Weinberger, Kilian},
  year = {2015},
  month = jun,
  pages = {957--966},
  issn = {1938-7228},
  abstract = {We present the Word Mover's Distance (WMD), a novel distance function between text documents. Our work is based on recent results in word embeddings that learn semantically meaningful representatio...},
  chapter = {Machine Learning},
  file = {/Users/yuekai/Documents/zotero/Kusner et al (2015) - From Word Embeddings To Document Distances.pdf},
  language = {en}
}

@article{kusner2018Counterfactual,
  title = {Counterfactual {{Fairness}}},
  author = {Kusner, Matt J. and Loftus, Joshua R. and Russell, Chris and Silva, Ricardo},
  year = {2018},
  month = mar,
  abstract = {Machine learning can impact people with legal or ethical consequences when it is used to automate decisions in areas such as insurance, lending, hiring, and predictive policing. In many of these scenarios, previous decisions have been made that are unfairly biased against certain subpopulations, for example those of a particular race, gender, or sexual orientation. Since this past data may be biased, machine learning predictors must account for this to avoid perpetuating or creating discriminatory practices. In this paper, we develop a framework for modeling fairness using tools from causal inference. Our definition of counterfactual fairness captures the intuition that a decision is fair towards an individual if it is the same in (a) the actual world and (b) a counterfactual world where the individual belonged to a different demographic group. We demonstrate our framework on a real-world problem of fair prediction of success in law school.},
  archivePrefix = {arXiv},
  eprint = {1703.06856},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Kusner et al (2018) - Counterfactual Fairness.pdf},
  journal = {arXiv:1703.06856 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{kusner2019Making,
  title = {Making {{Decisions}} That {{Reduce Discriminatory Impacts}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Kusner, Matt and Russell, Chris and Loftus, Joshua and Silva, Ricardo},
  year = {2019},
  month = may,
  pages = {3591--3600},
  abstract = {As machine learning algorithms move into real-world settings, it is crucial to ensure they are aligned with societal values. There has been much work on one aspect of this, namely the discriminator...},
  file = {/Users/yuekai/Documents/zotero/Kusner et al (2019) - Making Decisions that Reduce Discriminatory Impacts.pdf},
  language = {en}
}

@article{kusner2020long,
  title = {The Long Road to Fairer Algorithms},
  author = {Kusner, Matt J. and Loftus, Joshua R.},
  year = {2020},
  month = feb,
  volume = {578},
  pages = {34--36},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/d41586-020-00274-3},
  file = {/Users/yuekai/Documents/zotero/Kusner, Loftus (2020) - The long road to fairer algorithms.pdf},
  journal = {Nature},
  language = {en},
  number = {7793}
}

@book{lablee2015Spectral,
  title = {Spectral {{Theory}} in {{Riemannian Geometry}}},
  author = {Labl{\'e}e, Olivier},
  year = {2015},
  month = feb,
  doi = {10.4171/151},
  file = {/Users/yuekai/Documents/zotero/Lablée (2015) - Spectral Theory in Riemannian Geometry.pdf},
  isbn = {978-3-03719-151-4}
}

@article{lahoti2019iFair,
  title = {{{iFair}}: {{Learning Individually Fair Data Representations}} for {{Algorithmic Decision Making}}},
  shorttitle = {{{iFair}}},
  author = {Lahoti, Preethi and Gummadi, Krishna P. and Weikum, Gerhard},
  year = {2019},
  month = feb,
  abstract = {People are rated and ranked, towards algorithmic decision making in an increasing number of applications, typically based on machine learning. Research on how to incorporate fairness into such tasks has prevalently pursued the paradigm of group fairness: giving adequate success rates to specifically protected groups. In contrast, the alternative paradigm of individual fairness has received relatively little attention, and this paper advances this less explored direction. The paper introduces a method for probabilistically mapping user records into a low-rank representation that reconciles individual fairness and the utility of classifiers and rankings in downstream applications. Our notion of individual fairness requires that users who are similar in all task-relevant attributes such as job qualification, and disregarding all potentially discriminating attributes such as gender, should have similar outcomes. We demonstrate the versatility of our method by applying it to classification and learning-to-rank tasks on a variety of real-world datasets. Our experiments show substantial improvements over the best prior work for this setting.},
  archivePrefix = {arXiv},
  eprint = {1806.01059},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lahoti et al (2019) - iFair.pdf},
  journal = {arXiv:1806.01059 [cs, stat]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{lahoti2019Operationalizing,
  title = {Operationalizing Individual Fairness with Pairwise Fair Representations},
  author = {Lahoti, Preethi and Gummadi, Krishna P. and Weikum, Gerhard},
  year = {2019},
  month = dec,
  volume = {13},
  pages = {506--518},
  issn = {2150-8097},
  doi = {10.14778/3372716.3372723},
  abstract = {We revisit the notion of individual fairness proposed by Dwork et al. A central challenge in operationalizing their approach is the difficulty in eliciting a human specification of a similarity metric. In this paper, we propose an operationalization of individual fairness that does not rely on a human specification of a distance metric. Instead, we propose novel approaches to elicit and leverage side-information on equally deserving individuals to counter subordination between social groups. We model this knowledge as a fairness graph, and learn a unified Pairwise Fair Representation (PFR) of the data that captures both data-driven similarity between individuals and the pairwise side-information in fairness graph. We elicit fairness judgments from a variety of sources, including human judgments for two real-world datasets on recidivism prediction (COMPAS) and violent neighborhood prediction (Crime \& Communities). Our experiments show that the PFR model for operationalizing individual fairness is practically viable.},
  file = {/Users/yuekai/Documents/zotero/Lahoti et al (2019) - Operationalizing individual fairness with pairwise fair representations.pdf},
  journal = {Proceedings of the VLDB Endowment},
  language = {en},
  number = {4}
}

@inproceedings{lam2015Quantifying,
  title = {Quantifying Uncertainty in Sample Average Approximation},
  booktitle = {2015 {{Winter Simulation Conference}} ({{WSC}})},
  author = {Lam, H. and Zhou, Enlu},
  year = {2015},
  month = dec,
  pages = {3846--3857},
  doi = {10.1109/WSC.2015.7408541},
  abstract = {We consider stochastic optimization problems in which the input probability distribution is not fully known, and can only be observed through data. Common procedures handle such problems by optimizing an empirical counterpart, namely via using an empirical distribution of the input. The optimal solutions obtained through such procedures are hence subject to uncertainty of the data. In this paper, we explore techniques to quantify this uncertainty that have potentially good finite-sample performance. We consider three approaches: the empirical likelihood method, nonparametric Bayesian approach, and the bootstrap approach. They are designed to approximate the confidence intervals or posterior distributions of the optimal values or the optimality gaps. We present computational procedures for each of the approaches and discuss their relative benefits. A numerical example on conditional value-at-risk is used to demonstrate these methods.},
  file = {/Users/yuekai/Documents/zotero/Lam, Enlu Zhou (2015) - Quantifying uncertainty in sample average approximation.pdf;/Users/yuekai/Zotero/storage/QYT56ZRR/7408541.html}
}

@inproceedings{lam2016Advanced,
  title = {Advanced Tutorial: Input Uncertainty and Robust Analysis in Stochastic Simulation},
  shorttitle = {Advanced Tutorial},
  booktitle = {Proceedings of the 2016 {{Winter Simulation Conference}}},
  author = {Lam, Henry},
  year = {2016},
  month = dec,
  pages = {178--192},
  publisher = {{IEEE Press}},
  address = {{Arlington, Virginia}},
  abstract = {Input uncertainty refers to errors caused by a lack of complete knowledge about the probability distributions used to generate input variates in stochastic simulation. The quantification of input uncertainty is one of the central topics of interest and has been studied over the years among the simulation community. This tutorial overviews some methodological developments in two parts. The first part discusses major established statistical methods, while the second part discusses some recent results from a robust-optimization-based viewpoint and their comparisons to the established methods.},
  file = {/Users/yuekai/Documents/zotero/Lam (2016) - Advanced tutorial.pdf},
  isbn = {978-1-5090-4484-9},
  series = {{{WSC}} '16}
}

@article{lancaster2000incidental,
  title = {The Incidental Parameter Problem since 1948},
  author = {Lancaster, Tony},
  year = {2000},
  month = apr,
  volume = {95},
  pages = {391--413},
  issn = {03044076},
  doi = {10.1016/S0304-4076(99)00044-5},
  abstract = {This paper was written to mark the 50th anniversary of Neyman and Scott's Econometrica paper de"ning the incidental parameter problem. It surveys the history both of the paper and of the problem in the statistics and econometrics literature. 2000 Elsevier Science S.A. All rights reserved.},
  file = {/Users/yuekai/Documents/zotero/Lancaster (2000) - The incidental parameter problem since 1948.pdf},
  journal = {Journal of Econometrics},
  language = {en},
  number = {2}
}

@book{lange2013Optimization,
  title = {Optimization},
  author = {Lange, Kenneth},
  year = {2013},
  edition = {Second},
  publisher = {{Springer-Verlag}},
  address = {{New York}},
  abstract = {Finite-dimensional optimization problems occur throughout the mathematical sciences. The majority of these problems cannot be solved analytically. This introduction to optimization attempts to strike a balance between presentation of mathematical theory and development of numerical algorithms. Building on students' skills in calculus and linear algebra, the text provides a rigorous exposition without undue abstraction. Its stress on statistical applications will be especially appealing to graduate students of statistics and biostatistics. The intended audience also includes students in applied mathematics, computational biology, computer science, economics, and physics who want to see rigorous mathematics combined with real applications.In this second edition the emphasis remains on finite-dimensional optimization. New material has been added on the MM algorithm, block descent and ascent, and the calculus of variations. Convex calculus is now treated in much greater depth. Advanced topics such as the Fenchel conjugate, subdifferentials, duality, feasibility, alternating projections, projected gradient methods, exact penalty methods, and Bregman iteration will equip students with the essentials for understanding modern data mining techniques in high dimensions.},
  file = {/Users/yuekai/Documents/zotero/Lange (2013) - Optimization.pdf},
  isbn = {978-1-4614-5837-1},
  language = {en},
  series = {Springer {{Texts}} in {{Statistics}}}
}

@misc{larson2017How,
  title = {How {{We Examined Racial Discrimination}} in {{Auto Insurance}}\ldots},
  author = {Larson, Jeff and Angwin, Julia},
  year = {2017},
  month = apr,
  abstract = {ProPublica is an independent, non-profit newsroom that produces investigative journalism in the public interest.},
  copyright = {Copyright \textcopyright 2019 ProPublica.},
  howpublished = {https://www.propublica.org/article/minority-neighborhoods-higher-car-insurance-premiums-methodology},
  journal = {ProPublica},
  language = {en},
  type = {Text/Html}
}

@book{lattimore2019Bandit,
  title = {Bandit {{Algorithms}}},
  author = {Lattimore, Szepesvari},
  year = {2019},
  month = apr,
  publisher = {{Cambridge University Press}},
  file = {/Users/yuekai/Documents/zotero/Lattimore (2019) - Bandit Algorithms.pdf},
  language = {en}
}

@article{lazar2020Resolution,
  title = {A {{Resolution}} in {{Algorithmic Fairness}}: {{Calibrated Scores}} for {{Fair Classifications}}},
  shorttitle = {A {{Resolution}} in {{Algorithmic Fairness}}},
  author = {Lazar, Claire and Vijaykumar, Suhas},
  year = {2020},
  month = feb,
  abstract = {Calibration and equal error rates are fundamental conditions for algorithmic fairness that have been shown to conflict with each other, suggesting that they cannot be satisfied simultaneously. This paper shows that the two are in fact compatible and presents a method for reconciling them. In particular, we derive necessary and sufficient conditions for the existence of calibrated scores that yield classifications achieving equal error rates. We then present an algorithm that searches for the most informative score subject to both calibration and minimal error rate disparity. Applied empirically to credit lending, our algorithm provides a solution that is more fair and profitable than a common alternative that omits sensitive features.},
  archivePrefix = {arXiv},
  eprint = {2002.07676},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lazar, Vijaykumar (2020) - A Resolution in Algorithmic Fairness.pdf},
  journal = {arXiv:2002.07676 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{le2015Concentration,
  title = {Concentration and Regularization of Random Graphs},
  author = {Le, Can M. and Levina, Elizaveta and Vershynin, Roman},
  year = {2015},
  month = jun,
  abstract = {This paper studies how close random graphs are typically to their expectations. We interpret this question through the concentration of the adjacency and Laplacian matrices in the spectral norm. We study inhomogeneous Erd\textbackslash "os-R\textbackslash 'enyi random graphs on \$n\$ vertices, where edges form independently and possibly with different probabilities \$p\_\{ij\}\$. Sparse random graphs whose expected degrees are \$o(\textbackslash log n)\$ fail to concentrate; the obstruction is caused by vertices with abnormally high and low degrees. We show that concentration can be restored if we regularize the degrees of such vertices, and one can do this in various ways. As an example, let us reweight or remove enough edges to make all degrees bounded above by \$O(d)\$ where \$d=\textbackslash max np\_\{ij\}\$. Then we show that the resulting adjacency matrix \$A'\$ concentrates with the optimal rate: \$\textbackslash |A' - \textbackslash mathbb\{E\} A\textbackslash | = O(\textbackslash sqrt\{d\})\$. Similarly, if we make all degrees bounded below by \$d\$ by adding weight \$d/n\$ to all edges, then the resulting Laplacian concentrates with the optimal rate: \$\textbackslash |L(A') - L(\textbackslash mathbb\{E\} A')\textbackslash | = O(1/\textbackslash sqrt\{d\})\$. Our approach is based on Grothendieck-Pietsch factorization, using which we construct a new decomposition of random graphs. We illustrate the concentration results with an application to the community detection problem in the analysis of networks.},
  archivePrefix = {arXiv},
  eprint = {1506.00669},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Le et al (2015) - Concentration and regularization of random graphs.pdf},
  journal = {arXiv:1506.00669 [cs, math, stat]},
  keywords = {Computer Science - Social and Information Networks,Mathematics - Probability,Mathematics - Statistics Theory},
  primaryClass = {cs, math, stat}
}

@article{le2017Estimating,
  title = {Estimating a Network from Multiple Noisy Realizations},
  author = {Le, Can M. and Levina, Elizaveta},
  year = {2017},
  month = oct,
  abstract = {Complex interactions between entities are often represented as edges in a network. In practice, the network is often constructed from noisy measurements and inevitably contains some errors. In this paper we consider the problem of estimating a network from multiple noisy observations where edges of the original network are recorded with both false positives and false negatives. This problem is motivated by neuroimaging applications where brain networks of a group of patients with a particular brain condition could be viewed as noisy versions of an unobserved true network corresponding to the disease. The key to optimally leveraging these multiple observations is to take advantage of network structure, and here we focus on the case where the true network contains communities. Communities are common in real networks in general and in particular are believed to be presented in brain networks. Under a community structure assumption on the truth, we derive an efficient method to estimate the noise levels and the original network, with theoretical guarantees on the convergence of our estimates. We show on synthetic networks that the performance of our method is close to an oracle method using the true parameter values, and apply our method to fMRI brain data, demonstrating that it constructs stable and plausible estimates of the population network.},
  archivePrefix = {arXiv},
  eprint = {1710.04765},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Le, Levina (2017) - Estimating a network from multiple noisy realizations.pdf},
  journal = {arXiv:1710.04765 [cs, math, stat]},
  keywords = {Computer Science - Social and Information Networks,Mathematics - Statistics Theory},
  language = {en},
  primaryClass = {cs, math, stat}
}

@article{le2018Concentration,
  title = {Concentration of Random Graphs and Application to Community Detection},
  author = {Le, Can M. and Levina, Elizaveta and Vershynin, Roman},
  year = {2018},
  month = jan,
  abstract = {Random matrix theory has played an important role in recent work on statistical network analysis. In this paper, we review recent results on regimes of concentration of random graphs around their expectation, showing that dense graphs concentrate and sparse graphs concentrate after regularization. We also review relevant network models that may be of interest to probabilists considering directions for new random matrix theory developments, and random matrix theory tools that may be of interest to statisticians looking to prove properties of network algorithms. Applications of concentration results to the problem of community detection in networks are discussed in detail.},
  archivePrefix = {arXiv},
  eprint = {1801.08724},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Le et al (2018) - Concentration of random graphs and application to community detection.pdf},
  journal = {arXiv:1801.08724 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  language = {en},
  primaryClass = {math, stat}
}

@article{le2018Theoretical,
  title = {Theoretical {{Perspective}} of {{Deep Domain Adaptation}}},
  author = {Le, Trung and Nguyen, Khanh and Ho, Nhat and Bui, Hung and Phung, Dinh},
  year = {2018},
  month = nov,
  abstract = {Deep domain adaptation has been applied successfully in many applications of machine learning. Comparing with its shallow rivals, deep domain adaptation approach has generally resulted in higher predictive performance and better at modeling rich structural data (e.g., image and sequential data). The underlying idea is to bridge the gap between the source and target domains in a joint feature space so that a supervised classifier trained on labeled source data can be nicely transferred to the target domain. While this idea is appealing and intuitive, its theoretical underpinnings are woefully incomplete. Our goal in this paper is to develop a rigorous framework to study and explain why such a gap in the intermediate joint space can be formulated and minimized. More specifically, we first study the loss incurred during the transfer learning from the source to the target domain. This lays a foundation for our next contribution in rigorously explaining why closing the gap between the two domains in the joint feature space can directly minimize the loss incurred during transfer classification learning between two domains. We provide concrete theoretical results to quantify such gaps and corresponding transfer learning reduction in classification errors.},
  archivePrefix = {arXiv},
  eprint = {1811.06199},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Le et al (2018) - Theoretical Perspective of Deep Domain Adaptation.pdf},
  journal = {arXiv:1811.06199 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@book{lecam2000Asymptotics,
  title = {Asymptotics in Statistics: Some Basic Concepts},
  shorttitle = {Asymptotics in Statistics},
  author = {Le Cam, Lucien M. and Yang, Grace Lo},
  year = {2000},
  edition = {2. ed},
  publisher = {{Springer}},
  address = {{New York, NY}},
  annotation = {OCLC: 247645191},
  file = {/Users/yuekai/Documents/zotero/Le Cam Yang (2000) - Asymptotics in statistics.pdf},
  isbn = {978-1-4612-7030-0 978-0-387-95036-5},
  language = {en},
  series = {Springer Series in Statistics}
}

@article{lecerf2016Short,
  title = {A {{Short Survey}} on {{Kantorovich}}: {{Like Theorems}} for {{Newton}}'s {{Method}}},
  shorttitle = {A {{Short Survey}} on {{Kantorovich}}},
  author = {Lecerf, Gr{\'e}goire and Saad{\'e}, Joelle},
  year = {2016},
  month = apr,
  volume = {50},
  pages = {1--11},
  issn = {1932-2240},
  doi = {10.1145/2930964.2930965},
  abstract = {We survey influential quantitative results on the convergence of the Newton iterator towards simple roots of continuously differentiable maps defined over Banach spaces. We present a general statement of Kantorovich's theorem, with a concise proof from scratch, dedicated to wide audience. From it, we quickly recover known results, and gather historical notes together with pointers to recent articles.},
  file = {/Users/yuekai/Documents/zotero/Lecerf, Saadé (2016) - A Short Survey on Kantorovich.pdf},
  journal = {ACM Commun. Comput. Algebra},
  number = {1}
}

@article{lecun1998Gradientbased,
  title = {Gradient-Based Learning Applied to Document Recognition},
  author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  year = {1998},
  month = nov,
  volume = {86},
  pages = {2278--2324},
  issn = {1558-2256},
  doi = {10.1109/5.726791},
  abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
  file = {/Users/yuekai/Documents/zotero/Lecun et al (1998) - Gradient-based learning applied to document recognition.pdf;/Users/yuekai/Zotero/storage/P7ANB2GS/726791.html},
  journal = {Proceedings of the IEEE},
  number = {11}
}

@article{lecuyer2018Certified,
  title = {Certified {{Robustness}} to {{Adversarial Examples}} with {{Differential Privacy}}},
  author = {Lecuyer, Mathias and Atlidakis, Vaggelis and Geambasu, Roxana and Hsu, Daniel and Jana, Suman},
  year = {2018},
  month = feb,
  abstract = {Adversarial examples that fool machine learning models, particularly deep neural networks, have been a topic of intense research interest, with attacks and defenses being developed in a tight back-and-forth. Most past defenses are best effort and have been shown to be vulnerable to sophisticated attacks. Recently a set of certified defenses have been introduced, which provide guarantees of robustness to norm-bounded attacks, but they either do not scale to large datasets or are limited in the types of models they can support. This paper presents the first certified defense that both scales to large networks and datasets (such as Google's Inception network for ImageNet) and applies broadly to arbitrary model types. Our defense, called PixelDP, is based on a novel connection between robustness against adversarial examples and differential privacy, a cryptographically-inspired formalism, that provides a rigorous, generic, and flexible foundation for defense.},
  archivePrefix = {arXiv},
  eprint = {1802.03471},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lecuyer et al (2018) - Certified Robustness to Adversarial Examples with Differential Privacy.pdf},
  journal = {arXiv:1802.03471 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@book{ledoux2011Probability,
  title = {Probability in {{Banach}} Spaces: Isoperimetry and Processes},
  shorttitle = {Probability in {{Banach}} Spaces},
  author = {Ledoux, Michel and Talagrand, Michel},
  year = {2011},
  publisher = {{Springer}},
  address = {{Berlin ; London}},
  annotation = {OCLC: ocn751525992},
  file = {/Users/yuekai/Documents/zotero/Ledoux, Talagrand (2011) - Probability in Banach spaces.pdf},
  isbn = {978-3-642-20211-7 978-3-642-20212-4},
  language = {en},
  lccn = {QA273 .L373 2011},
  series = {Classics in Mathematics}
}

@article{lee1999Learning,
  title = {Learning the Parts of Objects by Non-Negative Matrix Factorization},
  author = {Lee, Daniel D. and Seung, H. Sebastian},
  year = {1999},
  month = oct,
  volume = {401},
  pages = {788--791},
  issn = {1476-4687},
  doi = {10.1038/44565},
  abstract = {Is perception of the whole based on perception of its parts? There is psychological1 and physiological2,3 evidence for parts-based representations in the brain, and certain computational theories of object recognition rely on such representations4,5. But little is known about how brains or computers might learn the parts of objects. Here we demonstrate an algorithm for non-negative matrix factorization that is able to learn parts of faces and semantic features of text. This is in contrast to other methods, such as principal components analysis and vector quantization, that learn holistic, not parts-based, representations. Non-negative matrix factorization is distinguished from the other methods by its use of non-negativity constraints. These constraints lead to a parts-based representation because they allow only additive, not subtractive, combinations. When non-negative matrix factorization is implemented as a neural network, parts-based representations emerge by virtue of two properties: the firing rates of neurons are never negative and synaptic strengths do not change sign.},
  copyright = {1999 Nature Publishing Group},
  file = {/Users/yuekai/Documents/zotero/Lee, Seung (1999) - Learning the parts of objects by non-negative matrix factorization.pdf},
  journal = {Nature},
  language = {en},
  number = {6755}
}

@article{lee2014Multiway,
  title = {Multi-Way Spectral Partitioning and Higher-Order {{Cheeger}} Inequalities},
  author = {Lee, James R. and Gharan, Shayan Oveis and Trevisan, Luca},
  year = {2014},
  month = nov,
  abstract = {A basic fact in spectral graph theory is that the number of connected components in an undirected graph is equal to the multiplicity of the eigenvalue zero in the Laplacian matrix of the graph. In particular, the graph is disconnected if and only if there are at least two eigenvalues equal to zero. Cheeger's inequality and its variants provide an approximate version of the latter fact; they state that a graph has a sparse cut if and only if there are at least two eigenvalues that are close to zero. It has been conjectured that an analogous characterization holds for higher multiplicities, i.e., there are \$k\$ eigenvalues close to zero if and only if the vertex set can be partitioned into \$k\$ subsets, each defining a sparse cut. We resolve this conjecture. Our result provides a theoretical justification for clustering algorithms that use the bottom \$k\$ eigenvectors to embed the vertices into \$\textbackslash mathbb R\^k\$, and then apply geometric considerations to the embedding. We also show that these techniques yield a nearly optimal tradeoff between the expansion of sets of size \$\textbackslash approx n/k\$, and the \$k\$th smallest eigenvalue of the normalized Laplacian matrix, denoted \$\textbackslash lambda\_k\$. In particular, we show that in every graph there is a set of size at most \$2n/k\$ which has expansion at most \$O(\textbackslash sqrt\{\textbackslash lambda\_k \textbackslash log k\})\$. This bound is tight, up to constant factors, for the "noisy hypercube" graphs.},
  archivePrefix = {arXiv},
  eprint = {1111.1055},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lee et al (2014) - Multi-way spectral partitioning and higher-order Cheeger inequalities.pdf},
  journal = {arXiv:1111.1055 [cs, math]},
  keywords = {Computer Science - Data Structures and Algorithms,Mathematics - Metric Geometry,Mathematics - Spectral Theory},
  primaryClass = {cs, math}
}

@article{lee2014Proximal,
  title = {Proximal {{Newton}}-{{Type Methods}} for {{Minimizing Composite Functions}}},
  author = {Lee, Jason D. and Sun, Yuekai. and Saunders, Michael A.},
  year = {2014},
  month = jan,
  volume = {24},
  pages = {1420--1443},
  issn = {1052-6234},
  doi = {10.1137/130921428},
  abstract = {We generalize Newton-type methods for minimizing smooth functions to handle a sum of two convex functions: a smooth function and a nonsmooth function with a simple proximal mapping. We show that the resulting proximal Newton-type methods inherit the desirable convergence behavior of Newton-type methods for minimizing smooth functions, even when search directions are computed inexactly. Many popular methods tailored to problems arising in bioinformatics, signal processing, and statistical learning are special cases of proximal Newton-type methods, and our analysis yields new convergence results for some of these methods.},
  file = {/Users/yuekai/Documents/zotero/Lee et al (2014) - Proximal Newton-Type Methods for Minimizing Composite Functions.pdf},
  journal = {SIAM Journal on Optimization},
  number = {3}
}

@article{lee2015Distributed,
  title = {Distributed {{Stochastic Variance Reduced Gradient Methods}} and {{A Lower Bound}} for {{Communication Complexity}}},
  author = {Lee, Jason D. and Lin, Qihang and Ma, Tengyu and Yang, Tianbao},
  year = {2015},
  month = jul,
  abstract = {We study distributed optimization algorithms for minimizing the average of convex functions. The applications include empirical risk minimization problems in statistical machine learning where the datasets are large and have to be stored on different machines. We design a distributed stochastic variance reduced gradient algorithm that, under certain conditions on the condition number, simultaneously achieves the optimal parallel runtime, amount of communication and rounds of communication among all distributed first-order methods up to constant factors. Our method and its accelerated extension also outperform existing distributed algorithms in terms of the rounds of communication as long as the condition number is not too large compared to the size of data in each machine. We also prove a lower bound for the number of rounds of communication for a broad class of distributed first-order methods including the proposed algorithms in this paper. We show that our accelerated distributed stochastic variance reduced gradient algorithm achieves this lower bound so that it uses the fewest rounds of communication among all distributed first-order algorithms.},
  archivePrefix = {arXiv},
  eprint = {1507.07595},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lee et al (2015) - Distributed Stochastic Variance Reduced Gradient Methods and A Lower Bound for.pdf},
  journal = {arXiv:1507.07595 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{lee2015model,
  title = {On Model Selection Consistency of Regularized {{M}}-Estimators},
  author = {Lee, Jason D. and Sun, Yuekai and Taylor, Jonathan E.},
  year = {2015},
  volume = {9},
  pages = {608--642},
  issn = {1935-7524},
  doi = {10.1214/15-EJS1013},
  abstract = {Regularized M-estimators are used in diverse areas of science and engineering to fit high-dimensional models with some low-dimensional structure. Usually the low-dimensional structure is encoded by the presence of the (unknown) parameters in some low-dimensional model subspace. In such settings, it is desirable for estimates of the model parameters to be model selection consistent: the estimates also fall in the model subspace. We develop a general framework for establishing consistency and model selection consistency of regularized M-estimators and show how it applies to some special cases of interest in statistical learning. Our analysis identifies two key properties of regularized M-estimators, referred to as geometric decomposability and irrepresentability, that ensure the estimators are consistent and model selection consistent.},
  file = {/Users/yuekai/Documents/zotero/Lee et al (2015) - On model selection consistency of regularized M-estimators.pdf},
  journal = {Electronic Journal of Statistics},
  language = {EN},
  mrnumber = {MR3331852},
  number = {1},
  zmnumber = {1309.62044}
}

@article{lee2016Exact,
  title = {Exact Post-Selection Inference, with Application to the Lasso},
  author = {Lee, Jason D. and Sun, Dennis L. and Sun, Yuekai and Taylor, Jonathan E.},
  year = {2016},
  month = jun,
  volume = {44},
  pages = {907--927},
  issn = {0090-5364},
  doi = {10.1214/15-AOS1371},
  abstract = {We develop a general approach to valid inference after model selection. At the core of our framework is a result that characterizes the distribution of a post-selection estimator conditioned on the selection event. We specialize the approach to model selection by the lasso to form valid confidence intervals for the selected coefficients and test whether all relevant variables have been included in the model.},
  archivePrefix = {arXiv},
  eprint = {1311.6238},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lee et al (2016) - Exact post-selection inference, with application to the lasso.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  number = {3}
}

@article{lee2016Gradient,
  title = {Gradient {{Descent Converges}} to {{Minimizers}}},
  author = {Lee, Jason D. and Simchowitz, Max and Jordan, Michael I. and Recht, Benjamin},
  year = {2016},
  month = feb,
  abstract = {We show that gradient descent converges to a local minimizer, almost surely with random initialization. This is proved by applying the Stable Manifold Theorem from dynamical systems theory.},
  archivePrefix = {arXiv},
  eprint = {1602.04915},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lee et al (2016) - Gradient Descent Converges to Minimizers.pdf},
  journal = {arXiv:1602.04915 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{lee2017Communicationefficient,
  title = {Communication-Efficient Sparse Regression: A One-Shot Approach},
  shorttitle = {Communication-Efficient Sparse Regression},
  author = {Lee, Jason D. and Sun, Yuekai and Liu, Qiang and Taylor, Jonathan E.},
  year = {2017},
  month = jan,
  volume = {18},
  abstract = {We devise a one-shot approach to distributed sparse regression in the high-dimensional setting. The key idea is to average "debiased" or "desparsified" lasso estimators. We show the approach converges at the same rate as the lasso as long as the dataset is not split across too many machines. We also extend the approach to generalized linear models.},
  archivePrefix = {arXiv},
  eprint = {1503.04337},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lee et al (2017) - Communication-efficient sparse regression.pdf},
  journal = {Journal of Machine Learning Research},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{lee2017Firstorder,
  title = {First-Order {{Methods Almost Always Avoid Saddle Points}}},
  author = {Lee, Jason D. and Panageas, Ioannis and Piliouras, Georgios and Simchowitz, Max and Jordan, Michael I. and Recht, Benjamin},
  year = {2017},
  month = oct,
  abstract = {We establish that first-order methods avoid saddle points for almost all initializations. Our results apply to a wide variety of first-order methods, including gradient descent, block coordinate descent, mirror descent and variants thereof. The connecting thread is that such algorithms can be studied from a dynamical systems perspective in which appropriate instantiations of the Stable Manifold Theorem allow for a global stability analysis. Thus, neither access to second-order derivative information nor randomness beyond initialization is necessary to provably avoid saddle points.},
  archivePrefix = {arXiv},
  eprint = {1710.07406},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lee et al (2017) - First-order Methods Almost Always Avoid Saddle Points.pdf},
  journal = {arXiv:1710.07406 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{lee2017Minimax,
  title = {Minimax {{Statistical Learning}} with {{Wasserstein Distances}}},
  author = {Lee, Jaeho and Raginsky, Maxim},
  year = {2017},
  month = may,
  abstract = {As opposed to standard empirical risk minimization (ERM), distributionally robust optimization aims to minimize the worst-case risk over a larger ambiguity set containing the original empirical distribution of the training data. In this work, we describe a minimax framework for statistical learning with ambiguity sets given by balls in Wasserstein space. In particular, we prove generalization bounds that involve the covering number properties of the original ERM problem. As an illustrative example, we provide generalization guarantees for transport-based domain adaptation problems where the Wasserstein distance between the source and target domain distributions can be reliably estimated from unlabeled samples.},
  archivePrefix = {arXiv},
  eprint = {1705.07815},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lee, Raginsky (2017) - Minimax Statistical Learning with Wasserstein Distances.pdf},
  journal = {arXiv:1705.07815 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{lee2017Overcoming,
  title = {Overcoming {{Catastrophic Forgetting}} by {{Incremental Moment Matching}}},
  author = {Lee, Sang-Woo and Kim, Jin-Hwa and Jun, Jaehyun and Ha, Jung-Woo and Zhang, Byoung-Tak},
  year = {2017},
  month = mar,
  abstract = {Catastrophic forgetting is a problem of neural networks that loses the information of the first task after training the second task. Here, we propose a method, i.e. incremental moment matching (IMM), to resolve this problem. IMM incrementally matches the moment of the posterior distribution of the neural network which is trained on the first and the second task, respectively. To make the search space of posterior parameter smooth, the IMM procedure is complemented by various transfer learning techniques including weight transfer, L2-norm of the old and the new parameter, and a variant of dropout with the old parameter. We analyze our approach on a variety of datasets including the MNIST, CIFAR-10, Caltech-UCSD-Birds, and Lifelog datasets. The experimental results show that IMM achieves state-of-the-art performance by balancing the information between an old and a new network.},
  archivePrefix = {arXiv},
  eprint = {1703.08475},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lee et al (2017) - Overcoming Catastrophic Forgetting by Incremental Moment Matching.pdf},
  journal = {arXiv:1703.08475 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{lee2018Bayesian,
  title = {A {{Bayesian}} Model for Sparse Graphs with Flexible Degree Distribution and Overlapping Community Structure},
  author = {Lee, Juho and James, Lancelot F. and Choi, Seungjin and Caron, Fran{\c c}ois},
  year = {2018},
  month = oct,
  abstract = {We consider a non-projective class of inhomogeneous random graph models with interpretable parameters and a number of interesting asymptotic properties. Using the results of Bollob\textbackslash 'as et al. [2007], we show that i) the class of models is sparse and ii) depending on the choice of the parameters, the model is either scale-free, with power-law exponent greater than 2, or with an asymptotic degree distribution which is power-law with exponential cut-off. We propose an extension of the model that can accommodate an overlapping community structure. Scalable posterior inference can be performed due to the specific choice of the link probability. We present experiments on five different real-world networks with up to 100,000 nodes and edges, showing that the model can provide a good fit to the degree distribution and recovers well the latent community structure.},
  archivePrefix = {arXiv},
  eprint = {1810.01778},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lee et al (2018) - A Bayesian model for sparse graphs with flexible degree distribution and.pdf},
  journal = {arXiv:1810.01778 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{lee2018FactorDriven,
  title = {Factor-{{Driven Two}}-{{Regime Regression}}},
  author = {Lee, Sokbae and Liao, Yuan and Seo, Myung Hwan and Shin, Youngki},
  year = {2018},
  month = oct,
  abstract = {We propose a novel two-regime regression model where the switching between the regimes is driven by a vector of possibly unobservable factors. When the factors are latent, we estimate them by the principal component analysis of a panel data set. We show that the optimization problem can be reformulated as mixed integer optimization and present two alternative computational algorithms. We derive the asymptotic distributions of the resulting estimators under the scheme that the threshold effect shrinks to zero. In particular, we establish a phase transition that describes the effect of first stage factor estimation as the cross-sectional dimension of panel data increases relative to the time-series dimension. Moreover, we develop a consistent factor selection procedure with a penalty term on the number of factors and present bootstrap methods for carrying out inference and testing linearity with the aid of efficient computational algorithms. Finally, we illustrate our methods via numerical studies.},
  archivePrefix = {arXiv},
  eprint = {1810.11109},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lee et al (2018) - Factor-Driven Two-Regime Regression.pdf},
  journal = {arXiv:1810.11109 [econ]},
  keywords = {Economics - Econometrics},
  primaryClass = {econ}
}

@article{lee2019Efficient,
  title = {Efficient {{Exploration}} via {{State Marginal Matching}}},
  author = {Lee, Lisa and Eysenbach, Benjamin and Parisotto, Emilio and Xing, Eric and Levine, Sergey and Salakhutdinov, Ruslan},
  year = {2019},
  month = jun,
  abstract = {To solve tasks with sparse rewards, reinforcement learning algorithms must be equipped with suitable exploration techniques. However, it is unclear what underlying objective is being optimized by existing exploration algorithms, or how they can be altered to incorporate prior knowledge about the task. Most importantly, it is difficult to use exploration experience from one task to acquire exploration strategies for another task. We address these shortcomings by learning a single exploration policy that can quickly solve a suite of downstream tasks in a multi-task setting, amortizing the cost of learning to explore. We recast exploration as a problem of State Marginal Matching (SMM): we learn a mixture of policies for which the state marginal distribution matches a given target state distribution, which can incorporate prior knowledge about the task. Without any prior knowledge, the SMM objective reduces to maximizing the marginal state entropy. We optimize the objective by reducing it to a two-player, zero-sum game, where we iteratively fit a state density model and then update the policy to visit states with low density under this model. While many previous algorithms for exploration employ a similar procedure, they omit a crucial historical averaging step, without which the iterative procedure does not converge to a Nash equilibria. To parallelize exploration, we extend our algorithm to use mixtures of policies, wherein we discover connections between SMM and previously-proposed skill learning methods based on mutual information. On complex navigation and manipulation tasks, we demonstrate that our algorithm explores faster and adapts more quickly to new tasks.},
  archivePrefix = {arXiv},
  eprint = {1906.05274},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lee et al (2019) - Efficient Exploration via State Marginal Matching.pdf},
  journal = {arXiv:1906.05274 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{lee2019Learning,
  title = {Learning to {{Balance}}: {{Bayesian Meta}}-{{Learning}} for {{Imbalanced}} and {{Out}}-of-Distribution {{Tasks}}},
  shorttitle = {Learning to {{Balance}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Lee, Hae Beom and Lee, Hayeon and Na, Donghyun and Kim, Saehoon and Park, Minseop and Yang, Eunho and Hwang, Sung Ju},
  year = {2019},
  month = sep,
  abstract = {While tasks could come with varying the number of instances and classes in realistic settings, the existing meta-learning approaches for few-shot classification assume that number of instances per...},
  file = {/Users/yuekai/Documents/zotero/Lee et al (2019) - Learning to Balance.pdf}
}

@article{lee2019Wide,
  title = {Wide {{Neural Networks}} of {{Any Depth Evolve}} as {{Linear Models Under Gradient Descent}}},
  author = {Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel S. and Bahri, Yasaman and Novak, Roman and {Sohl-Dickstein}, Jascha and Pennington, Jeffrey},
  year = {2019},
  month = feb,
  abstract = {A longstanding goal in deep learning research has been to precisely characterize training and generalization. However, the often complex loss landscapes of neural networks have made a theory of learning dynamics elusive. In this work, we show that for wide neural networks the learning dynamics simplify considerably and that, in the infinite width limit, they are governed by a linear model obtained from the first-order Taylor expansion of the network around its initial parameters. Furthermore, mirroring the correspondence between wide Bayesian neural networks and Gaussian processes, gradient-based training of wide neural networks with a squared loss produces test set predictions drawn from a Gaussian process with a particular compositional kernel. While these theoretical results are only exact in the infinite width limit, we nevertheless find excellent empirical agreement between the predictions of the original network and those of the linearized version even for finite practically-sized networks. This agreement is robust across different architectures, optimization methods, and loss functions.},
  archivePrefix = {arXiv},
  eprint = {1902.06720},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lee et al (2019) - Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent.pdf},
  journal = {arXiv:1902.06720 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{lee2020Parallel,
  title = {Parallel {{Unbalanced Optimal Transport Regularization}} for {{Large Scale Imaging Problems}}},
  author = {Lee, John and Bertrand, Nicholas P. and Rozell, Christopher J.},
  year = {2020},
  month = may,
  abstract = {The modeling of phenomenological structure is a crucial aspect in inverse imaging problems. One emerging modeling tool in computational imaging is the optimal transport framework. Its ability to model geometric displacements across an image's support gives it attractive qualities similar to those of optical flow methods which are effective at capturing visual motion, but are restricted to operate in significantly smaller state-spaces. Despite this advantage, two major drawbacks make it unsuitable for general deployment: (i) it suffers from exorbitant computational costs due to a quadratic optimization-variable complexity, and (ii) it has a mass-balancing assumption that limits applications with natural images. We tackle these issues simultaneously by proposing a novel formulation for an unbalanced optimal transport regularizer that has linear optimization-variable complexity. In addition, we present a general parallelizable proximal method for this regularizer, and demonstrate superior empirical performance on novel dynamical tracking applications in synthetic and real video.},
  archivePrefix = {arXiv},
  eprint = {1909.00149},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lee et al (2020) - Parallel Unbalanced Optimal Transport Regularization for Large Scale Imaging.pdf;/Users/yuekai/Zotero/storage/R4GMHK7G/1909.html},
  journal = {arXiv:1909.00149 [eess]},
  keywords = {Electrical Engineering and Systems Science - Image and Video Processing,Electrical Engineering and Systems Science - Signal Processing},
  primaryClass = {eess}
}

@article{lee2020Predicting,
  title = {Predicting {{What You Already Know Helps}}: {{Provable Self}}-{{Supervised Learning}}},
  shorttitle = {Predicting {{What You Already Know Helps}}},
  author = {Lee, Jason D. and Lei, Qi and Saunshi, Nikunj and Zhuo, Jiacheng},
  year = {2020},
  month = aug,
  abstract = {Self-supervised representation learning solves auxiliary prediction tasks (known as pretext tasks), that do not require labeled data, to learn semantic representations. These pretext tasks are created solely using the input features, such as predicting a missing image patch, recovering the color channels of an image from context, or predicting missing words, yet predicting this \$known\textbackslash{} \$information helps in learning representations effective for downstream prediction tasks. This paper posits a mechanism based on conditional independence to formalize how solving certain pretext tasks can learn representations that provably decreases the sample complexity of downstream supervised tasks. Formally, we quantify how approximate independence between the components of the pretext task (conditional on the label and latent variables) allows us to learn representations that can solve the downstream task with drastically reduced sample complexity by just training a linear layer on top of the learned representation.},
  archivePrefix = {arXiv},
  eprint = {2008.01064},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lee et al (2020) - Predicting What You Already Know Helps.pdf;/Users/yuekai/Zotero/storage/MS4TQM5W/2008.html},
  journal = {arXiv:2008.01064 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{leek2007Capturing,
  title = {Capturing {{Heterogeneity}} in {{Gene Expression Studies}} by {{Surrogate Variable Analysis}}},
  author = {Leek, Jeffrey T. and Storey, John D.},
  year = {2007},
  month = sep,
  volume = {3},
  pages = {e161},
  issn = {1553-7404},
  doi = {10.1371/journal.pgen.0030161},
  abstract = {It has unambiguously been shown that genetic, environmental, demographic, and technical factors may have substantial effects on gene expression levels. In addition to the measured variable(s) of interest, there will tend to be sources of signal due to factors that are unknown, unmeasured, or too complicated to capture through simple models. We show that failing to incorporate these sources of heterogeneity into an analysis can have widespread and detrimental effects on the study. Not only can this reduce power or induce unwanted dependence across genes, but it can also introduce sources of spurious signal to many genes. This phenomenon is true even for well-designed, randomized studies. We introduce ``surrogate variable analysis'' (SVA) to overcome the problems caused by heterogeneity in expression studies. SVA can be applied in conjunction with standard analysis techniques to accurately capture the relationship between expression and any modeled variables of interest. We apply SVA to disease class, time course, and genetics of gene expression studies. We show that SVA increases the biological accuracy and reproducibility of analyses in genome-wide expression studies.},
  file = {/Users/yuekai/Documents/zotero/Leek, Storey (2007) - Capturing Heterogeneity in Gene Expression Studies by Surrogate Variable.pdf},
  journal = {PLOS Genetics},
  language = {en},
  number = {9}
}

@article{leek2008general,
  title = {A General Framework for Multiple Testing Dependence},
  author = {Leek, Jeffrey T. and Storey, John D.},
  year = {2008},
  month = dec,
  volume = {105},
  pages = {18718--18723},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0808709105},
  abstract = {We develop a general framework for performing large-scale significance testing in the presence of arbitrarily strong dependence. We derive a low-dimensional set of random vectors, called a dependence kernel, that fully captures the dependence structure in an observed high-dimensional dataset. This result shows a surprising reversal of the ``curse of dimensionality'' in the high-dimensional hypothesis testing setting. We show theoretically that conditioning on a dependence kernel is sufficient to render statistical tests independent regardless of the level of dependence in the observed data. This framework for multiple testing dependence has implications in a variety of common multiple testing problems, such as in gene expression studies, brain imaging, and spatial epidemiology.},
  copyright = {\textcopyright{} 2008 by the National Academy of Sciences of the USA.  Freely available online through the PNAS open access option.},
  file = {/Users/yuekai/Documents/zotero/Leek, Storey (2008) - A general framework for multiple testing dependence.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {48},
  pmid = {19033188}
}

@article{leek2010Tackling,
  title = {Tackling the Widespread and Critical Impact of Batch Effects in High-Throughput Data},
  author = {Leek, Jeffrey T. and Scharpf, Robert B. and Bravo, H{\'e}ctor Corrada and Simcha, David and Langmead, Benjamin and Johnson, W. Evan and Geman, Donald and Baggerly, Keith and Irizarry, Rafael A.},
  year = {2010},
  month = oct,
  volume = {11},
  pages = {733--739},
  issn = {1471-0064},
  doi = {10.1038/nrg2825},
  abstract = {High-throughput technologies are widely used, for example to assay genetic variants, gene and protein expression, and epigenetic modifications. One often overlooked complication with such studies is batch effects, which occur because measurements are affected by laboratory conditions, reagent lots and personnel differences. This becomes a major problem when batch effects are correlated with an outcome of interest and lead to incorrect conclusions. Using both published studies and our own analyses, we argue that batch effects (as well as other technical and biological artefacts) are widespread and critical to address. We review experimental and computational approaches for doing so.},
  copyright = {2010 Nature Publishing Group},
  file = {/Users/yuekai/Documents/zotero/Leek et al (2010) - Tackling the widespread and critical impact of batch effects in high-throughput.pdf},
  journal = {Nature Reviews Genetics},
  language = {en},
  number = {10}
}

@incollection{lei2011Differentially,
  title = {Differentially {{Private M}}-{{Estimators}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 24},
  author = {Lei, Jing},
  editor = {{Shawe-Taylor}, J. and Zemel, R. S. and Bartlett, P. L. and Pereira, F. and Weinberger, K. Q.},
  year = {2011},
  pages = {361--369},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/yuekai/Documents/zotero/Lei (2011) - Differentially Private M-Estimators.pdf}
}

@article{lei2016AdaPT,
  title = {{{AdaPT}}: {{An}} Interactive Procedure for Multiple Testing with Side Information},
  shorttitle = {{{AdaPT}}},
  author = {Lei, Lihua and Fithian, William},
  year = {2016},
  month = sep,
  abstract = {We consider the problem of multiple hypothesis testing with generic side information: for each hypothesis \$H\_i\$ we observe both a p-value \$p\_i\$ and some predictor \$x\_i\$ encoding contextual information about the hypothesis. For large-scale problems, adaptively focusing power on the more promising hypotheses (those more likely to yield discoveries) can lead to much more powerful multiple testing procedures. We propose a general iterative framework for this problem, called the Adaptive p-value Thresholding (AdaPT) procedure, which adaptively estimates a Bayes-optimal p-value rejection threshold and controls the false discovery rate (FDR) in finite samples. At each iteration of the procedure, the analyst proposes a rejection threshold and observes partially censored p-values, estimates the false discovery proportion (FDP) below the threshold, and either stops to reject or proposes another threshold, until the estimated FDP is below \$\textbackslash alpha\$. Our procedure is adaptive in an unusually strong sense, permitting the analyst to use any statistical or machine learning method she chooses to estimate the optimal threshold, and to switch between different models at each iteration as information accrues. We demonstrate the favorable performance of AdaPT by comparing it to state-of-the-art methods in five real applications and two simulation studies.},
  archivePrefix = {arXiv},
  eprint = {1609.06035},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lei, Fithian (2016) - AdaPT.pdf},
  journal = {arXiv:1609.06035 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{lei2016DistributionFree,
  title = {Distribution-{{Free Predictive Inference For Regression}}},
  author = {Lei, Jing and G'Sell, Max and Rinaldo, Alessandro and Tibshirani, Ryan J. and Wasserman, Larry},
  year = {2016},
  month = apr,
  abstract = {We develop a general framework for distribution-free predictive inference in regression, using conformal inference. The proposed methodology allows for the construction of a prediction band for the response variable using any estimator of the regression function. The resulting prediction band preserves the consistency properties of the original estimator under standard assumptions, while guaranteeing finite-sample marginal coverage even when these assumptions do not hold. We analyze and compare, both empirically and theoretically, the two major variants of our conformal framework: full conformal inference and split conformal inference, along with a related jackknife method. These methods offer different tradeoffs between statistical accuracy (length of resulting prediction intervals) and computational efficiency. As extensions, we develop a method for constructing valid in-sample prediction intervals called \{\textbackslash it rank-one-out\} conformal inference, which has essentially the same computational efficiency as split conformal inference. We also describe an extension of our procedures for producing prediction bands with locally varying length, in order to adapt to heteroskedascity in the data. Finally, we propose a model-free notion of variable importance, called \{\textbackslash it leave-one-covariate-out\} or LOCO inference. Accompanying this paper is an R package \{\textbackslash tt conformalInference\} that implements all of the proposals we have introduced. In the spirit of reproducibility, all of our empirical results can also be easily (re)generated using this package.},
  archivePrefix = {arXiv},
  eprint = {1604.04173},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lei et al (2016) - Distribution-Free Predictive Inference For Regression.pdf},
  journal = {arXiv:1604.04173 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{lei2017ActorCritic,
  title = {An {{Actor}}-{{Critic Contextual Bandit Algorithm}} for {{Personalized Mobile Health Interventions}}},
  author = {Lei, Huitian and Tewari, Ambuj and Murphy, Susan A.},
  year = {2017},
  month = jun,
  abstract = {Increasing technological sophistication and widespread use of smartphones and wearable devices provide opportunities for innovative and highly personalized health interventions. A Just-In-Time Adaptive Intervention (JITAI) uses real-time data collection and communication capabilities of modern mobile devices to deliver interventions in real-time that are adapted to the in-the-moment needs of the user. The lack of methodological guidance in constructing data-based JITAIs remains a hurdle in advancing JITAI research despite the increasing popularity of JITAIs among clinical scientists. In this article, we make a first attempt to bridge this methodological gap by formulating the task of tailoring interventions in real-time as a contextual bandit problem. Interpretability requirements in the domain of mobile health lead us to formulate the problem differently from existing formulations intended for web applications such as ad or news article placement. Under the assumption of linear reward function, we choose the reward function (the "critic") parameterization separately from a lower dimensional parameterization of stochastic policies (the "actor"). We provide an online actor-critic algorithm that guides the construction and refinement of a JITAI. Asymptotic properties of the actor-critic algorithm are developed and backed up by numerical experiments. Additional numerical experiments are conducted to test the robustness of the algorithm when idealized assumptions used in the analysis of contextual bandit algorithm are breached.},
  archivePrefix = {arXiv},
  eprint = {1706.09090},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lei et al (2017) - An Actor-Critic Contextual Bandit Algorithm for Personalized Mobile Health.pdf},
  journal = {arXiv:1706.09090 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{lei2018Convergence,
  title = {Convergence and {{Concentration}} of {{Empirical Measures}} under {{Wasserstein Distance}} in {{Unbounded Functional Spaces}}},
  author = {Lei, Jing},
  year = {2018},
  month = apr,
  abstract = {We provide upper bounds of the expected Wasserstein distance between a probability measure and its empirical version, generalizing recent results for finite dimensional Euclidean spaces and bounded functional spaces. Such a generalization can cover Euclidean spaces with large dimensionality, with the optimal dependence on the dimensionality. Our method also covers the important case of Gaussian processes in separable Hilbert spaces, with rate-optimal upper bounds for functional data distributions whose coordinates decay geometrically or polynomially. Moreover, our bounds of the expected value can be combined with mean-concentration results to yield improved exponential tail probability bounds for the Wasserstein error of empirical measures under a Bernstein-type tail condition.},
  archivePrefix = {arXiv},
  eprint = {1804.10556},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lei (2018) - Convergence and Concentration of Empirical Measures under Wasserstein Distance.pdf},
  journal = {arXiv:1804.10556 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {math, stat}
}

@article{lei2018Network,
  title = {Network {{Representation Using Graph Root Distributions}}},
  author = {Lei, Jing},
  year = {2018},
  month = feb,
  abstract = {Exchangeable random graphs serve as an important probabilistic framework for the statistical analysis of network data. At the core of this framework is the parameterization of graph sampling distributions, where existing methods suffer from non-trivial identifiability issues. In this work we develop a new parameterization for general exchangeable random graphs, where the nodes are independent random vectors in a linear space equipped with an indefinite inner product, and the edge probability between two nodes equals the inner product of the corresponding node vectors. Therefore, the distribution of exchangeable random graphs can be represented by a node sampling distribution on this linear space, which we call the "graph root distribution". We study existence and uniqueness of such representations, the topological relationship between the graph root distribution and the exchangeable random graph sampling distribution, and the statistical estimation of graph root distributions.},
  archivePrefix = {arXiv},
  eprint = {1802.09684},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lei (2018) - Network Representation Using Graph Root Distributions.pdf},
  journal = {arXiv:1802.09684 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{lei2019Inverting,
  title = {Inverting {{Deep Generative}} Models, {{One}} Layer at a Time},
  author = {Lei, Qi and Jalal, Ajil and Dhillon, Inderjit S. and Dimakis, Alexandros G.},
  year = {2019},
  month = jun,
  abstract = {We study the problem of inverting a deep generative model with ReLU activations. Inversion corresponds to finding a latent code vector that explains observed measurements as much as possible. In most prior works this is performed by attempting to solve a non-convex optimization problem involving the generator. In this paper we obtain several novel theoretical results for the inversion problem. We show that for the realizable case, single layer inversion can be performed exactly in polynomial time, by solving a linear program. Further, we show that for multiple layers, inversion is NP-hard and the pre-image set can be non-convex. For generative models of arbitrary depth, we show that exact recovery is possible in polynomial time with high probability, if the layers are expanding and the weights are randomly selected. Very recent work analyzed the same problem for gradient descent inversion. Their analysis requires significantly higher expansion (logarithmic in the latent dimension) while our proposed algorithm can provably reconstruct even with constant factor expansion. We also provide provable error bounds for different norms for reconstructing noisy observations. Our empirical validation demonstrates that we obtain better reconstructions when the latent dimension is large.},
  archivePrefix = {arXiv},
  eprint = {1906.07437},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lei et al (2019) - Inverting Deep Generative models, One layer at a time.pdf},
  journal = {arXiv:1906.07437 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{lei2019Unified,
  title = {Unified \$\textbackslash ell\_\{2\textbackslash rightarrow\textbackslash infty\}\$ {{Eigenspace Perturbation Theory}} for {{Symmetric Random Matrices}}},
  author = {Lei, Lihua},
  year = {2019},
  month = sep,
  abstract = {Modern applications in statistics, computer science and network science have seen tremendous values of finer matrix spectral perturbation theory. In this paper, we derive a generic \$\textbackslash ell\_\{2\textbackslash rightarrow\textbackslash infty\}\$ eigenspace perturbation bound for symmetric random matrices, with independent or dependent entries and fairly flexible entry distributions. In particular, we apply our generic bound to binary random matrices with independent entries or with certain dependency structures, including the unnormalized Laplacian of inhomogenous random graphs and \$m\$-dependent matrices. Through a detailed comparison, we found that for binary random matrices with independent entries, our \$\textbackslash ell\_\{2\textbackslash rightarrow\textbackslash infty\}\$ bound is tighter than all existing bounds that we are aware of, while our condition is weaker than most of them with only one exception in a special regime. We employ our perturbation bounds in three problems and improve the state of the art: concentration of the spectral norm of sparse random graphs, exact recovery of communities in stochastic block models and partial consistency of divisive hierarchical clustering. Finally we discuss the extensions of our theory to random matrices with more complex dependency structures and non-binary entries, asymmetric rectangular matrices and induced perturbation theory in other metrics.},
  archivePrefix = {arXiv},
  eprint = {1909.04798},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lei (2019) - Unified $-ell_ 2-rightarrow-infty $ Eigenspace Perturbation Theory for.pdf},
  journal = {arXiv:1909.04798 [math, stat]},
  keywords = {Mathematics - Probability,Mathematics - Spectral Theory,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{lei2020SGD,
  title = {{{SGD Learns One}}-{{Layer Networks}} in {{WGANs}}},
  author = {Lei, Qi and Lee, Jason D. and Dimakis, Alexandros G. and Daskalakis, Constantinos},
  year = {2020},
  month = jul,
  abstract = {Generative adversarial networks (GANs) are a widely used framework for learning generative models. Wasserstein GANs (WGANs), one of the most successful variants of GANs, require solving a minmax optimization problem to global optimality, but are in practice successfully trained using stochastic gradient descent-ascent. In this paper, we show that, when the generator is a one-layer network, stochastic gradient descent-ascent converges to a global solution with polynomial time and sample complexity.},
  archivePrefix = {arXiv},
  eprint = {1910.07030},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lei et al (2020) - SGD Learns One-Layer Networks in WGANs.pdf},
  journal = {arXiv:1910.07030 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{lelarge2015Reconstruction,
  title = {Reconstruction in the {{Labeled Stochastic Block Model}}},
  author = {Lelarge, Marc and Massouli{\'e}, Laurent and Xu, Jiaming},
  year = {2015},
  month = feb,
  abstract = {The labeled stochastic block model is a random graph model representing networks with community structure and interactions of multiple types. In its simplest form, it consists of two communities of approximately equal size, and the edges are drawn and labeled at random with probability depending on whether their two endpoints belong to the same community or not. It has been conjectured in \textbackslash cite\{Heimlicher12\} that correlated reconstruction (i.e.\textbackslash{} identification of a partition correlated with the true partition into the underlying communities) would be feasible if and only if a model parameter exceeds a threshold. We prove one half of this conjecture, i.e., reconstruction is impossible when below the threshold. In the positive direction, we introduce a weighted graph to exploit the label information. With a suitable choice of weight function, we show that when above the threshold by a specific constant, reconstruction is achieved by (1) minimum bisection, (2) a semidefinite relaxation of minimum bisection, and (3) a spectral method combined with removal of edges incident to vertices of high degree. Furthermore, we show that hypothesis testing between the labeled stochastic block model and the labeled Erd\textbackslash H\{o\}s-R\textbackslash 'enyi random graph model exhibits a phase transition at the conjectured reconstruction threshold.},
  archivePrefix = {arXiv},
  eprint = {1502.03365},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lelarge et al (2015) - Reconstruction in the Labeled Stochastic Block Model.pdf},
  journal = {arXiv:1502.03365 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{lemhadri2019neural,
  title = {A Neural Network with Feature Sparsity},
  author = {Lemhadri, Ismael and Ruan, Feng and Tibshirani, Robert},
  year = {2019},
  month = jul,
  abstract = {We propose a neural network model, with a separate linear (residual) term, that explicitly bounds the input layer weights for a feature by the linear weight for that feature. The model can be seen as a modification of so-called residual neural networks to produce a path of models that are feature-sparse, that is, use only a subset of the features. This is analogous to the solution path from the usual Lasso (\$\textbackslash ell\_1\$-regularized) linear regression. We call the proposed procedure \{\textbackslash tt LassoNet\} and develop a projected proximal gradient algorithm for its optimization. This approach can sometimes give as low or lower test error than a standard neural network, and its feature selection provides more interpretable solutions. We illustrate the method using both simulated and real data examples, and show that it is often able to achieve competitive performance with a much smaller number of input feature},
  archivePrefix = {arXiv},
  eprint = {1907.12207},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lemhadri et al (2019) - A neural network with feature sparsity.pdf},
  journal = {arXiv:1907.12207 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{lenzen2012Distributed,
  title = {Distributed Algorithms for Sensor Networks},
  author = {Lenzen, Christoph and Wattenhofer, Roger},
  year = {2012},
  month = jan,
  volume = {370},
  pages = {11--26},
  issn = {1364-503X, 1471-2962},
  doi = {10.1098/rsta.2011.0212},
  abstract = {Distributed algorithms are an established tool for designing protocols for sensor networks. In this paper, we discuss the relation between distributed computing theory and sensor network applications. We also present a few basic and illustrative distributed algorithms.},
  copyright = {This journal is \textcopyright{} 2011 The Royal Society},
  file = {/Users/yuekai/Documents/zotero/Lenzen, Wattenhofer (2012) - Distributed algorithms for sensor networks.pdf},
  journal = {Phil. Trans. R. Soc. A},
  language = {en},
  number = {1958},
  pmid = {22124079}
}

@article{leskovec2008Kronecker,
  title = {Kronecker {{Graphs}}: {{An Approach}} to {{Modeling Networks}}},
  shorttitle = {Kronecker {{Graphs}}},
  author = {Leskovec, Jure and Chakrabarti, Deepayan and Kleinberg, Jon and Faloutsos, Christos and Ghahramani, Zoubin},
  year = {2008},
  month = dec,
  abstract = {How can we model networks with a mathematically tractable model that allows for rigorous analysis of network properties? Networks exhibit a long list of surprising properties: heavy tails for the degree distribution; small diameters; and densification and shrinking diameters over time. Most present network models either fail to match several of the above properties, are complicated to analyze mathematically, or both. In this paper we propose a generative model for networks that is both mathematically tractable and can generate networks that have the above mentioned properties. Our main idea is to use the Kronecker product to generate graphs that we refer to as "Kronecker graphs". First, we prove that Kronecker graphs naturally obey common network properties. We also provide empirical evidence showing that Kronecker graphs can effectively model the structure of real networks. We then present KronFit, a fast and scalable algorithm for fitting the Kronecker graph generation model to large real networks. A naive approach to fitting would take super- exponential time. In contrast, KronFit takes linear time, by exploiting the structure of Kronecker matrix multiplication and by using statistical simulation techniques. Experiments on large real and synthetic networks show that KronFit finds accurate parameters that indeed very well mimic the properties of target networks. Once fitted, the model parameters can be used to gain insights about the network structure, and the resulting synthetic graphs can be used for null- models, anonymization, extrapolations, and graph summarization.},
  archivePrefix = {arXiv},
  eprint = {0812.4905},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Leskovec et al (2008) - Kronecker Graphs.pdf},
  journal = {arXiv:0812.4905 [physics, stat]},
  keywords = {Computer Science - Data Structures and Algorithms,Physics - Data Analysis; Statistics and Probability,Physics - Physics and Society,Statistics - Machine Learning},
  primaryClass = {physics, stat}
}

@article{leslie2020Tackling,
  title = {Tackling {{COVID}}-19 through {{Responsible AI Innovation}}: {{Five Steps}} in the {{Right Direction}}},
  shorttitle = {Tackling {{COVID}}-19 through {{Responsible AI Innovation}}},
  author = {Leslie, David},
  year = {2020},
  month = jun,
  abstract = {Innovations in data science and artificial intelligence (AI) have a central role to play in supporting global efforts to combat Covid-19. The versatility of AI technologies is enabling scientists and technologists to address an impressively broad range of biomedical, epidemiological, and socio-economic challenges. This wide-reaching scientific capacity is, however, also raising a diverse array of ethical challenges. The need for researchers to act quickly and globally in tackling Coronavirus demands unprecedented practices of open research and responsible data sharing at a time when innovation ecosystems are hobbled by proprietary protectionism and a lack of public trust. Moreover, societally impactful interventions like digital contact tracing are raising fears of ``surveillance creep'' and are challenging widely-held commitments to privacy, autonomy, and civil liberties. Pre-pandemic concerns that data-driven innovations may function to reinforce entrenched dynamics of social inequality are likewise now only more intensified given the life-and-death consequences of biased and discriminatory public health outcomes. The following offers five steps toward responsible research and innovation that need to be taken to address these concerns. It presents a practice-based path to responsible AI design and discovery centered on open, accountable, equitable, and democratically governed processes and products. When taken from the start, these steps will not only enhance the capacity of innovators to tackle Covid-19 responsibly, they will help to set the data science and AI community down a path that is both better prepared to cope with future pandemics and better equipped to support a more humane, rational, and just society of tomorrow.},
  file = {/Users/yuekai/Documents/zotero/Leslie (2020) - Tackling COVID-19 through Responsible AI Innovation.pdf},
  journal = {Harvard Data Science Review},
  language = {en}
}

@article{leung2006Information,
  title = {Information {{Theory}} and {{Mixing Least}}-{{Squares Regressions}}},
  author = {Leung, G. and Barron, A.R.},
  year = {2006},
  month = aug,
  volume = {52},
  pages = {3396--3410},
  issn = {0018-9448, 1557-9654},
  doi = {10.1109/TIT.2006.878172},
  abstract = {For Gaussian regression, we develop and analyze methods for combining estimators from various models. For squared-error loss, an unbiased estimator of the risk of the mixture of general estimators is developed. Special attention is given to the case that the component estimators are least-squares projections into arbitrary linear subspaces, such as those spanned by subsets of explanatory variables in a given design. We relate the unbiased estimate of the risk of the mixture estimator to estimates of the risks achieved by the components. This results in simple and accurate bounds on the risk and its estimate, in the form of sharp and exact oracle inequalities. That is, without advance knowledge of which model is best, the resulting performance is comparable to or perhaps even superior to what is achieved by the best of the individual models. Furthermore, in the case that the unknown parameter has a sparse representation, our mixture estimator adapts to the underlying sparsity. Simulations show that the performance of these mixture estimators is better than that of a related model-selection estimator which picks a model with the highest weight. Also, the connection between our mixtures with Bayes procedures is discussed},
  file = {/Users/yuekai/Documents/zotero/Leung, Barron (2006) - Information Theory and Mixing Least-Squares Regressions.pdf;/Users/yuekai/Zotero/storage/LD3QXA5V/1661826.html},
  journal = {IEEE Transactions on Information Theory},
  number = {8}
}

@article{levy2000Stability,
  title = {Stability of {{Locally Optimal Solutions}}},
  author = {Levy, A. B. and Poliquin, R. A. and Rockafellar, R. T.},
  year = {2000},
  month = jan,
  volume = {10},
  pages = {580--604},
  issn = {1052-6234},
  doi = {10.1137/S1052623498348274},
  abstract = {Necessary and sufficient conditions are obtained for the Lipschitzian stability of local solutions to finite-dimensional parameterized optimization problems in a very general setting. Properties of prox-regularity of the essential objective function and positive definiteness of its coderivative Hessian are the keys to these results. A previous characterization of tilt stability arises as a special case.},
  file = {/Users/yuekai/Documents/zotero/Levy et al (2000) - Stability of Locally Optimal Solutions.pdf},
  journal = {SIAM Journal on Optimization},
  number = {2}
}

@article{levy2019Necessary,
  title = {Necessary and {{Sufficient Geometries}} for {{Gradient Methods}}},
  author = {Levy, Daniel and Duchi, John C.},
  year = {2019},
  month = sep,
  abstract = {We study the impact of the constraint set and gradient geometry on the
convergence of online and stochastic methods for convex optimization, providing
a characterization of the geometries for which stochastic gradient and adaptive
gradient methods are (minimax) optimal. In particular, we show that when the
constraint set is quadratically convex, diagonally pre-conditioned stochastic
gradient methods are minimax optimal. We further provide a converse that shows
that when the constraints are not quadratically convex---for example, any
\$\textbackslash ell\_p\$-ball for \$p {$<$} 2\$---the methods are far from optimal. Based on this, we
can provide concrete recommendations for when one should use adaptive, mirror
or stochastic gradient methods.},
  file = {/Users/yuekai/Documents/zotero/Levy, Duchi (2019) - Necessary and Sufficient Geometries for Gradient Methods.pdf},
  language = {en}
}

@article{lewis2005Nonsmooth,
  title = {Nonsmooth {{Analysis}} of {{Singular Values}}. {{Part I}}: {{Theory}}},
  shorttitle = {Nonsmooth {{Analysis}} of {{Singular Values}}. {{Part I}}},
  author = {Lewis, Adrian S. and Sendov, Hristo S.},
  year = {2005},
  month = sep,
  volume = {13},
  pages = {213--241},
  issn = {0927-6947, 1572-932X},
  doi = {10.1007/s11228-004-7197-7},
  abstract = {The singular values of a rectangular matrix are nonsmooth functions of its entries. In this work we study the nonsmooth analysis of functions of singular values. In particular we give simple formulae for the regular subdifferential, the limiting subdifferential, and the horizon subdifferential, of such functions. Along the way to the main result we give several applications and in particular derive von Neumann's trace inequality for singular values.},
  file = {/Users/yuekai/Documents/zotero/Lewis, Sendov (2005) - Nonsmooth Analysis of Singular Values.pdf},
  journal = {Set-Valued Analysis},
  language = {en},
  number = {3}
}

@article{lewis2005Nonsmootha,
  title = {Nonsmooth {{Analysis}} of {{Singular Values}}. {{Part II}}: {{Applications}}},
  shorttitle = {Nonsmooth {{Analysis}} of {{Singular Values}}. {{Part II}}},
  author = {Lewis, Adrian S. and Sendov, Hristo S.},
  year = {2005},
  month = sep,
  volume = {13},
  pages = {243--264},
  issn = {0927-6947, 1572-932X},
  doi = {10.1007/s11228-004-7198-6},
  abstract = {In this work we continue the nonsmooth analysis of absolutely symmetric functions of the singular values of a real rectangular matrix. Absolutely symmetric functions are invariant under permutations and sign changes of its arguments. We extend previous work on subgradients to analogous formulae for the proximal subdifferential and Clarke subdifferential when the function is either locally Lipschitz or just lower semicontinuous. We illustrate the results by calculating the various subdifferentials of individual singular values. Another application gives a nonsmooth proof of Lidskii's theorem for weak majorization.},
  file = {/Users/yuekai/Documents/zotero/Lewis, Sendov (2005) - Nonsmooth Analysis of Singular Values.pdf},
  journal = {Set-Valued Analysis},
  language = {en},
  number = {3}
}

@article{li2015Uncovering,
  title = {Uncovering the {{Small Community Structure}} in {{Large Networks}}: {{A Local Spectral Approach}}},
  shorttitle = {Uncovering the {{Small Community Structure}} in {{Large Networks}}},
  author = {Li, Yixuan and He, Kun and Bindel, David and Hopcroft, John},
  year = {2015},
  month = sep,
  abstract = {Large graphs arise in a number of contexts and understanding their structure and extracting information from them is an important research area. Early algorithms on mining communities have focused on the global structure, and often run in time functional to the size of the entire graph. Nowadays, as we often explore networks with billions of vertices and find communities of size hundreds, it is crucial to shift our attention from macroscopic structure to microscopic structure when dealing with large networks. A growing body of work has been adopting local expansion methods in order to identify the community from a few exemplary seed members. In this paper, we propose a novel approach for finding overlapping communities called LEMON (Local Expansion via Minimum One Norm). Different from PageRank-like diffusion methods, LEMON finds the community by seeking a sparse vector in the span of the local spectra such that the seeds are in its support. We show that LEMON can achieve the highest detection accuracy among state-of-the-art proposals. The running time depends on the size of the community rather than that of the entire graph. The algorithm is easy to implement, and is highly parallelizable. Moreover, given that networks are not all similar in nature, a comprehensive analysis on how the local expansion approach is suited for uncovering communities in different networks is still lacking. We thoroughly evaluate our approach using both synthetic and real-world datasets across different domains, and analyze the empirical variations when applying our method to inherently different networks in practice. In addition, the heuristics on how the quality and quantity of the seed set would affect the performance are provided.},
  archivePrefix = {arXiv},
  eprint = {1509.07715},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Li et al (2015) - Uncovering the Small Community Structure in Large Networks.pdf},
  journal = {arXiv:1509.07715 [physics]},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Social and Information Networks,Physics - Physics and Society},
  primaryClass = {physics}
}

@article{li2016Network,
  title = {Network Cross-Validation by Edge Sampling},
  author = {Li, Tianxi and Levina, Elizaveta and Zhu, Ji},
  year = {2016},
  month = dec,
  abstract = {While many statistical models and methods are now available for network analysis, resampling network data remains a challenging problem. Cross-validation is a useful general tool for model selection and parameter tuning, but is not directly applicable to networks since splitting network nodes into groups requires deleting edges and destroys some of the network structure. Here we propose a new network resampling strategy based on splitting node pairs rather than nodes applicable to crossvalidation for a wide range of network model selection tasks. We provide a theoretical justification for our method in a general setting and examples of how our method can be used in specific network model selection and parameter tuning tasks. Numerical results on simulated networks and on a citation network of statisticians show that this cross-validation approach works well for model selection.},
  archivePrefix = {arXiv},
  eprint = {1612.04717},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Li et al (2016) - Network cross-validation by edge sampling.pdf},
  journal = {arXiv:1612.04717 [stat]},
  keywords = {Statistics - Machine Learning,Statistics - Methodology},
  language = {en},
  primaryClass = {stat}
}

@article{li2017Limitations,
  title = {On the {{Limitations}} of {{First}}-{{Order Approximation}} in {{GAN Dynamics}}},
  author = {Li, Jerry and Madry, Aleksander and Peebles, John and Schmidt, Ludwig},
  year = {2017},
  month = jun,
  abstract = {While Generative Adversarial Networks (GANs) have demonstrated promising performance on multiple vision tasks, their learning dynamics are not yet well understood, both in theory and in practice. To address this issue, we study GAN dynamics in a simple yet rich parametric model that exhibits several of the common problematic convergence behaviors such as vanishing gradients, mode collapse, and diverging or oscillatory behavior. In spite of the non-convex nature of our model, we are able to perform a rigorous theoretical analysis of its convergence behavior. Our analysis reveals an interesting dichotomy: a GAN with an optimal discriminator provably converges, while first order approximations of the discriminator steps lead to unstable GAN dynamics and mode collapse. Our result suggests that using first order discriminator steps (the de-facto standard in most existing GAN setups) might be one of the factors that makes GAN training challenging in practice.},
  archivePrefix = {arXiv},
  eprint = {1706.09884},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Li et al (2017) - On the Limitations of First-Order Approximation in GAN Dynamics.pdf},
  journal = {arXiv:1706.09884 [cs]},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{li2018Hierarchical,
  title = {Hierarchical Community Detection by Recursive Partitioning},
  author = {Li, Tianxi and Lei, Lihua and Bhattacharyya, Sharmodeep and Sarkar, Purnamrita and Bickel, Peter J. and Levina, Elizaveta},
  year = {2018},
  month = oct,
  abstract = {The problem of community detection in networks is usually formulated as finding a single partition of the network into some ``correct'' number of communities. We argue that it is more interpretable and in some regimes more accurate to construct a hierarchical tree of communities instead. This can be done with a simple top-down recursive partitioning algorithm, starting with a single community and separating the nodes into two communities by spectral clustering repeatedly, until a stopping rule suggests there are no further communities. This class of algorithms is model-free, computationally efficient, and requires no tuning other than selecting a stopping rule. We show that there are regimes where this approach outperforms K-way spectral clustering, and propose a natural framework for analyzing the algorithm's theoretical performance, the binary tree stochastic block model. Under this model, we prove that the algorithm correctly recovers the entire community tree under relatively mild assumptions. We also apply the algorithm to a dataset of statistics papers to construct a hierarchical tree of statistical research communities.},
  archivePrefix = {arXiv},
  eprint = {1810.01509},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Li et al (2018) - Hierarchical community detection by recursive partitioning.pdf},
  journal = {arXiv:1810.01509 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  language = {en},
  primaryClass = {math, stat}
}

@article{li2018Maximum,
  title = {Maximum {{Principle Based Algorithms}} for {{Deep Learning}}},
  author = {Li, Qianxiao and Chen, Long and Tai, Cheng and E, Weinan},
  year = {2018},
  volume = {18},
  pages = {1--29},
  issn = {1533-7928},
  file = {/Users/yuekai/Documents/zotero/Li et al (2018) - Maximum Principle Based Algorithms for Deep Learning.pdf},
  journal = {Journal of Machine Learning Research},
  number = {165}
}

@article{li2018Multithreshold,
  title = {Multi-Threshold {{Change Plane Model}}: {{Estimation Theory}} and {{Applications}} in {{Subgroup Identification}}},
  shorttitle = {Multi-Threshold {{Change Plane Model}}},
  author = {Li, Jialiang and Li, Yaguang and Jin, Baisuo},
  year = {2018},
  month = aug,
  abstract = {We propose a multi-threshold change plane regression model which naturally partitions the observed subjects into subgroups with different covariate effects. The underlying grouping variable is a linear function of covariates and thus multiple thresholds form parallel change planes in the covariate space. We contribute a novel 2-stage approach to estimate the number of subgroups, the location of thresholds and all other regression parameters. In the first stage we adopt a group selection principle to consistently identify the number of subgroups, while in the second stage change point locations and model parameter estimates are refined by a penalized induced smoothing technique. Our procedure allows sparse solutions for relatively moderate- or high-dimensional covariates. We further establish the asymptotic properties of our proposed estimators under appropriate technical conditions. We evaluate the performance of the proposed methods by simulation studies and provide illustration using two medical data. Our proposal for subgroup identification may lead to an immediate application in personalized medicine.},
  archivePrefix = {arXiv},
  eprint = {1808.00647},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Li et al (2018) - Multi-threshold Change Plane Model.pdf},
  journal = {arXiv:1808.00647 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@inproceedings{li2019Differentially,
  title = {Differentially {{Private Meta}}-{{Learning}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Li, Jeffrey and Khodak, Mikhail and Caldas, Sebastian and Talwalkar, Ameet},
  year = {2019},
  month = sep,
  abstract = {Parameter-transfer is a well-known and versatile approach for meta-learning, with applications including few-shot learning, federated learning, with personalization, and reinforcement learning....},
  file = {/Users/yuekai/Documents/zotero/Li et al (2019) - Differentially Private Meta-Learning.pdf}
}

@inproceedings{li2019Fair,
  title = {Fair {{Resource Allocation}} in {{Federated Learning}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Li, Tian and Sanjabi, Maziar and Beirami, Ahmad and Smith, Virginia},
  year = {2019},
  month = sep,
  abstract = {Federated learning involves training statistical models in massive, heterogeneous networks. Naively minimizing an aggregate loss function in such a network may disproportionately advantage or...},
  file = {/Users/yuekai/Documents/zotero/Li et al (2019) - Fair Resource Allocation in Federated Learning.pdf}
}

@article{li2019Learn,
  title = {Learn to {{Grow}}: {{A Continual Structure Learning Framework}} for {{Overcoming Catastrophic Forgetting}}},
  shorttitle = {Learn to {{Grow}}},
  author = {Li, Xilai and Zhou, Yingbo and Wu, Tianfu and Socher, Richard and Xiong, Caiming},
  year = {2019},
  month = mar,
  abstract = {Addressing catastrophic forgetting is one of the key challenges in continual learning where machine learning systems are trained with sequential or streaming tasks. Despite recent remarkable progress in state-of-the-art deep learning, deep neural networks (DNNs) are still plagued with the catastrophic forgetting problem. This paper presents a conceptually simple yet general and effective framework for handling catastrophic forgetting in continual learning with DNNs. The proposed method consists of two components: a neural structure optimization component and a parameter learning and/or fine-tuning component. By separating the explicit neural structure learning and the parameter estimation, not only is the proposed method capable of evolving neural structures in an intuitively meaningful way, but also shows strong capabilities of alleviating catastrophic forgetting in experiments. Furthermore, the proposed method outperforms all other baselines on the permuted MNIST dataset, the split CIFAR100 dataset and the Visual Domain Decathlon dataset in continual learning setting.},
  archivePrefix = {arXiv},
  eprint = {1904.00310},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Li et al (2019) - Learn to Grow.pdf},
  journal = {arXiv:1904.00310 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{li2019Network,
  title = {Network Cross-Validation by Edge Sampling},
  author = {Li, Tianxi and Levina, Elizaveta and Zhu, Ji},
  year = {2019},
  month = mar,
  abstract = {While many statistical models and methods are now available for network analysis, resampling network data remains a challenging problem. Cross-validation is a useful general tool for model selection and parameter tuning, but is not directly applicable to networks since splitting network nodes into groups requires deleting edges and destroys some of the network structure. Here we propose a new network resampling strategy based on splitting node pairs rather than nodes applicable to cross-validation for a wide range of network model selection tasks. We provide a theoretical justification for our method in a general setting and examples of how our method can be used in specific network model selection and parameter tuning tasks. Numerical results on simulated networks and on a citation network of statisticians show that this cross-validation approach works well for model selection.},
  archivePrefix = {arXiv},
  eprint = {1612.04717},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Li et al (2019) - Network cross-validation by edge sampling.pdf},
  journal = {arXiv:1612.04717 [stat]},
  keywords = {Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {stat}
}

@article{li2019Online,
  title = {Online {{Learning}} to {{Rank}} with {{Features}}},
  author = {Li, Shuai and Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year = {2019},
  month = may,
  abstract = {We introduce a new model for online ranking in which the click probability factors into an examination and attractiveness function and the attractiveness function is a linear function of a feature vector and an unknown parameter. Only relatively mild assumptions are made on the examination function. A novel algorithm for this setup is analysed, showing that the dependence on the number of items is replaced by a dependence on the dimension, allowing the new algorithm to handle a large number of items. When reduced to the orthogonal case, the regret of the algorithm improves on the state-of-the-art.},
  archivePrefix = {arXiv},
  eprint = {1810.02567},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Li et al (2019) - Online Learning to Rank with Features.pdf},
  journal = {arXiv:1810.02567 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{li2020Getting,
  title = {Getting Too Personal(Ized): {{The}} Importance of Feature Choice in Online Adaptive Algorithms},
  booktitle = {Educational {{Data Mining}}},
  author = {Li, ZhaoBin and Yee, Luna and Sauerberg, Nathaniel},
  year = {2020},
  month = jul,
  pages = {12},
  abstract = {Digital educational technologies offer the potential to customize students' experiences and learn what works for which students, enhancing the technology as more students interact with it. We consider whether and when attempting to discover how to personalize has a cost, such as if the adaptation to personal information can delay the adoption of policies that benefit all students. We explore these issues in the context of using multi-armed bandit (MAB) algorithms to learn a policy for what version of an educational technology to present to each student, varying the relation between student characteristics and outcomes and also whether the algorithm is aware of these characteristics. Through simulations, we demonstrate that the inclusion of student characteristics for personalization can be beneficial when those characteristics are needed to learn the optimal action. In other scenarios, this inclusion decreases performance and increases variation in student experiences. Moreover, including unneeded student characteristics can systematically disadvantage students with less common values for these characteristics. Our simulations do however suggest that realtime personalization will be helpful in particular real-world scenarios, and we illustrate this through case studies using existing experimental results in ASSISTments [23]. Overall, our simulations show that adaptive personalization in educational technologies can be a double-edged sword: real-time adaptation improves student experiences in some contexts, but the slower adaptation and increased variability mean that a more personalized model is not always beneficial.},
  file = {/Users/yuekai/Documents/zotero/Li et al (2020) - Getting too personal(ized).pdf},
  language = {en}
}

@article{li2020Scalable,
  title = {Scalable {{Gradients}} for {{Stochastic Differential Equations}}},
  author = {Li, Xuechen and Wong, Ting-Kam Leonard and Chen, Ricky T. Q. and Duvenaud, David},
  year = {2020},
  month = feb,
  abstract = {The adjoint sensitivity method scalably computes gradients of solutions to ordinary differential equations. We generalize this method to stochastic differential equations, allowing time-efficient and constant-memory computation of gradients with high-order adaptive solvers. Specifically, we derive a stochastic differential equation whose solution is the gradient, a memory-efficient algorithm for caching noise, and conditions under which numerical solutions converge. In addition, we combine our method with gradient-based stochastic variational inference for latent stochastic differential equations. We use our method to fit stochastic dynamics defined by neural networks, achieving competitive performance on a 50-dimensional motion capture dataset.},
  archivePrefix = {arXiv},
  eprint = {2001.01328},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Li et al (2020) - Scalable Gradients for Stochastic Differential Equations.pdf},
  journal = {arXiv:2001.01328 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Numerical Analysis,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{liang2020Precise,
  title = {A {{Precise High}}-{{Dimensional Asymptotic Theory}} for {{Boosting}} and {{Minimum}}-{{L1}}-{{Norm Interpolated Classifiers}}},
  author = {Liang, Tengyuan and Sur, Pragya},
  year = {2020},
  month = jul,
  abstract = {This paper establishes a precise high-dimensional asymptotic theory for boosting on separable data, taking statistical and computational perspectives. We consider the setting where the number of features (weak learners) \$p\$ scales with the sample size \$n\$, in an over-parametrized regime. Under a broad class of statistical models, we provide an exact analysis of the generalization error of boosting, when the algorithm interpolates the training data and maximizes the empirical \$\textbackslash ell\_1\$-margin. The relation between the boosting test error and the optimal Bayes error is pinned down explicitly. In turn, these precise characterizations resolve several open questions raised in \textbackslash cite\{breiman1999prediction, schapire1998boosting\} surrounding boosting. On the computational front, we provide a sharp analysis of the stopping time when boosting approximately maximizes the empirical \$\textbackslash ell\_1\$ margin. Furthermore, we discover that the larger the overparametrization ratio \$p/n\$, the smaller the proportion of active features (with zero initialization), and the faster the optimization reaches interpolation. At the heart of our theory lies an in-depth study of the maximum \$\textbackslash ell\_1\$-margin, which can be accurately described by a new system of non-linear equations; we analyze this margin and the properties of this system, using Gaussian comparison techniques and a novel uniform deviation argument. Variants of AdaBoost corresponding to general \$\textbackslash ell\_q\$ geometry, for \$q {$>$} 1\$, are also presented, together with an exact analysis of the high-dimensional generalization and optimization behavior of a class of these algorithms.},
  archivePrefix = {arXiv},
  eprint = {2002.01586},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Liang, Sur (2020) - A Precise High-Dimensional Asymptotic Theory for Boosting and Minimum-L1-Norm.pdf;/Users/yuekai/Zotero/storage/DZDLM2QD/2002.html},
  journal = {arXiv:2002.01586 [cs, math, stat]},
  keywords = {Computer Science - Information Theory,Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{liao2015Methods,
  title = {Methods to {{Develop}} an {{Electronic Medical Record Phenotype Algorithm}} to {{Compare}} the {{Risk}} of {{Coronary Artery Disease}} across 3 {{Chronic Disease Cohorts}}},
  author = {Liao, Katherine P. and Ananthakrishnan, Ashwin N. and Kumar, Vishesh and Xia, Zongqi and Cagan, Andrew and Gainer, Vivian S. and Goryachev, Sergey and Chen, Pei and Savova, Guergana K. and Agniel, Denis and Churchill, Susanne and Lee, Jaeyoung and Murphy, Shawn N. and Plenge, Robert M. and Szolovits, Peter and Kohane, Isaac and Shaw, Stanley Y. and Karlson, Elizabeth W. and Cai, Tianxi},
  year = {2015},
  month = aug,
  volume = {10},
  pages = {e0136651},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0136651},
  abstract = {Background Typically, algorithms to classify phenotypes using electronic medical record (EMR) data were developed to perform well in a specific patient population. There is increasing interest in analyses which can allow study of a specific outcome across different diseases. Such a study in the EMR would require an algorithm that can be applied across different patient populations. Our objectives were: (1) to develop an algorithm that would enable the study of coronary artery disease (CAD) across diverse patient populations; (2) to study the impact of adding narrative data extracted using natural language processing (NLP) in the algorithm. Additionally, we demonstrate how to implement CAD algorithm to compare risk across 3 chronic diseases in a preliminary study. Methods and Results We studied 3 established EMR based patient cohorts: diabetes mellitus (DM, n = 65,099), inflammatory bowel disease (IBD, n = 10,974), and rheumatoid arthritis (RA, n = 4,453) from two large academic centers. We developed a CAD algorithm using NLP in addition to structured data (e.g. ICD9 codes) in the RA cohort and validated it in the DM and IBD cohorts. The CAD algorithm using NLP in addition to structured data achieved specificity {$>$}95\% with a positive predictive value (PPV) 90\% in the training (RA) and validation sets (IBD and DM). The addition of NLP data improved the sensitivity for all cohorts, classifying an additional 17\% of CAD subjects in IBD and 10\% in DM while maintaining PPV of 90\%. The algorithm classified 16,488 DM (26.1\%), 457 IBD (4.2\%), and 245 RA (5.0\%) with CAD. In a cross-sectional analysis, CAD risk was 63\% lower in RA and 68\% lower in IBD compared to DM (p{$<$}0.0001) after adjusting for traditional cardiovascular risk factors. Conclusions We developed and validated a CAD algorithm that performed well across diverse patient populations. The addition of NLP into the CAD algorithm improved the sensitivity of the algorithm, particularly in cohorts where the prevalence of CAD was low. Preliminary data suggest that CAD risk was significantly lower in RA and IBD compared to DM.},
  file = {/Users/yuekai/Documents/zotero/Liao et al (2015) - Methods to Develop an Electronic Medical Record Phenotype Algorithm to Compare.pdf},
  journal = {PLOS ONE},
  language = {en},
  number = {8}
}

@article{liao2019LanczosNet,
  title = {{{LanczosNet}}: {{Multi}}-{{Scale Deep Graph Convolutional Networks}}},
  shorttitle = {{{LanczosNet}}},
  author = {Liao, Renjie and Zhao, Zhizhen and Urtasun, Raquel and Zemel, Richard S.},
  year = {2019},
  month = jan,
  abstract = {We propose the Lanczos network (LanczosNet), which uses the Lanczos algorithm to construct low rank approximations of the graph Laplacian for graph convolution. Relying on the tridiagonal decomposition of the Lanczos algorithm, we not only efficiently exploit multi-scale information via fast approximated computation of matrix power but also design learnable spectral filters. Being fully differentiable, LanczosNet facilitates both graph kernel learning as well as learning node embeddings. We show the connection between our LanczosNet and graph based manifold learning methods, especially the diffusion maps. We benchmark our model against several recent deep graph networks on citation networks and QM8 quantum chemistry dataset. Experimental results show that our model achieves the state-of-the-art performance in most tasks.},
  archivePrefix = {arXiv},
  eprint = {1901.01484},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Liao et al (2019) - LanczosNet.pdf},
  journal = {arXiv:1901.01484 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{lin2006Efficient,
  title = {Efficient In-Network Moving Object Tracking in Wireless Sensor Networks},
  author = {Lin, Chih-Yu and Peng, Wen-Chih and Tseng, Yu-Chee},
  year = {2006},
  month = aug,
  volume = {5},
  pages = {1044--1056},
  issn = {1536-1233},
  doi = {10.1109/TMC.2006.115},
  abstract = {The rapid progress of wireless communication and embedded microsensing MEMS technologies has made wireless sensor networks possible. In light of storage in sensors, a sensor network can be considered as a distributed database, in which one can conduct in-network data processing. An important issue of wireless sensor networks is object tracking, which typically involves two basic operations: update and query. This issue has been intensively studied in other areas, such as cellular networks. However, the in-network processing characteristic of sensor networks has posed new challenges to this issue. In this paper, we develop several tree structures for in-network object tracking which take the physical topology of the sensor network into consideration. The optimization process has two stages. The first stage tries to reduce the location update cost based on a deviation-avoidance principle and a highest-weight-first principle. The second stage further adjusts the tree obtained in the first stage to reduce the query cost. The way we model this problem allows us to analytically formulate the cost of object tracking given the update and query rates of objects. Extensive simulations are conducted, which show a significant improvement over existing solutions},
  file = {/Users/yuekai/Documents/zotero/Lin et al (2006) - Efficient in-network moving object tracking in wireless sensor networks.pdf;/Users/yuekai/Zotero/storage/ZW38C5LX/1644749.html},
  journal = {IEEE Transactions on Mobile Computing},
  number = {8}
}

@article{lin2019Defensive,
  title = {Defensive {{Quantization}}: {{When Efficiency Meets Robustness}}},
  shorttitle = {Defensive {{Quantization}}},
  author = {Lin, Ji and Gan, Chuang and Han, Song},
  year = {2019},
  month = apr,
  abstract = {Neural network quantization is becoming an industry standard to efficiently deploy deep learning models on hardware platforms, such as CPU, GPU, TPU, and FPGAs. However, we observe that the conventional quantization approaches are vulnerable to adversarial attacks. This paper aims to raise people's awareness about the security of the quantized models, and we designed a novel quantization methodology to jointly optimize the efficiency and robustness of deep learning models. We first conduct an empirical study to show that vanilla quantization suffers more from adversarial attacks. We observe that the inferior robustness comes from the error amplification effect, where the quantization operation further enlarges the distance caused by amplified noise. Then we propose a novel Defensive Quantization (DQ) method by controlling the Lipschitz constant of the network during quantization, such that the magnitude of the adversarial noise remains non-expansive during inference. Extensive experiments on CIFAR-10 and SVHN datasets demonstrate that our new quantization method can defend neural networks against adversarial examples, and even achieves superior robustness than their full-precision counterparts while maintaining the same hardware efficiency as vanilla quantization approaches. As a by-product, DQ can also improve the accuracy of quantized models without adversarial attack.},
  archivePrefix = {arXiv},
  eprint = {1904.08444},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lin et al (2019) - Defensive Quantization.pdf},
  journal = {arXiv:1904.08444 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{lin2020NearOptimal,
  title = {Near-{{Optimal Algorithms}} for {{Minimax Optimization}}},
  author = {Lin, Tianyi and Jin, Chi and Jordan, Michael I.},
  year = {2020},
  month = feb,
  abstract = {This paper resolves a longstanding open question pertaining to the design of near-optimal first-order algorithms for smooth and strongly-convex-strongly-concave minimax problems. Current state-of-the-art first-order algorithms find an approximate Nash equilibrium using \$\textbackslash tilde\{O\}(\textbackslash kappa\_\{\textbackslash mathbf x\}+\textbackslash kappa\_\{\textbackslash mathbf y\})\$ or \$\textbackslash tilde\{O\}(\textbackslash min\textbackslash\{\textbackslash kappa\_\{\textbackslash mathbf x\}\textbackslash sqrt\{\textbackslash kappa\_\{\textbackslash mathbf y\}\}, \textbackslash sqrt\{\textbackslash kappa\_\{\textbackslash mathbf x\}\}\textbackslash kappa\_\{\textbackslash mathbf y\}\textbackslash\})\$ gradient evaluations, where \$\textbackslash kappa\_\{\textbackslash mathbf x\}\$ and \$\textbackslash kappa\_\{\textbackslash mathbf y\}\$ are the condition numbers for the strong-convexity and strong-concavity assumptions. A gap remains between these results and the best existing lower bound \$\textbackslash tilde\{\textbackslash Omega\}(\textbackslash sqrt\{\textbackslash kappa\_\{\textbackslash mathbf x\}\textbackslash kappa\_\{\textbackslash mathbf y\}\})\$. This paper presents the first algorithm with \$\textbackslash tilde\{O\}(\textbackslash sqrt\{\textbackslash kappa\_\{\textbackslash mathbf x\}\textbackslash kappa\_\{\textbackslash mathbf y\}\})\$ gradient complexity, matching the lower bound up to logarithmic factors. Our new algorithm is designed based on an accelerated proximal point method and an accelerated solver for minimax proximal steps. It can be easily extended to the settings of strongly-convex-concave, convex-concave, nonconvex-strongly-concave, and nonconvex-concave functions. This paper also presents algorithms that match or outperform all existing methods in these settings in terms of gradient complexity, up to logarithmic factors.},
  archivePrefix = {arXiv},
  eprint = {2002.02417},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lin et al (2020) - Near-Optimal Algorithms for Minimax Optimization.pdf},
  journal = {arXiv:2002.02417 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{lin2020Projection,
  title = {On {{Projection Robust Optimal Transport}}: {{Sample Complexity}} and {{Model Misspecification}}},
  shorttitle = {On {{Projection Robust Optimal Transport}}},
  author = {Lin, Tianyi and Zheng, Zeyu and Chen, Elynn Y. and Cuturi, Marco and Jordan, Michael I.},
  year = {2020},
  month = jun,
  abstract = {Optimal transport (OT) distances are increasingly used as loss functions for statistical inference, notably in the learning of generative models or supervised learning. Yet, the behavior of minimum Wasserstein estimators is poorly understood, notably in high-dimensional regimes or under model misspecification. In this work we adopt the viewpoint of projection robust (PR) OT, which seeks to maximize the OT cost between two measures by choosing a \$k\$-dimensional subspace onto which they can be projected. Our first contribution is to establish several fundamental statistical properties of PR Wasserstein distances, complementing and improving previous literature that has been restricted to one-dimensional and well-specified cases. Next, we propose the integral PR Wasserstein (IPRW) distance as an alternative to the PRW distance, by averaging rather than optimizing on subspaces. Our complexity bounds can help explain why both PRW and IPRW distances outperform Wasserstein distances empirically in high-dimensional inference tasks. Finally, we consider parametric inference using the PRW distance. We provide an asymptotic guarantee of two types of minimum PRW estimators and formulate a central limit theorem for max-sliced Wasserstein estimator under model misspecification. To enable our analysis on PRW with projection dimension larger than one, we devise a novel combination of variational analysis and statistical theory.},
  archivePrefix = {arXiv},
  eprint = {2006.12301},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lin et al (2020) - On Projection Robust Optimal Transport.pdf},
  journal = {arXiv:2006.12301 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{lin2020Projectiona,
  title = {Projection {{Robust Wasserstein Distance}} and {{Riemannian Optimization}}},
  author = {Lin, Tianyi and Fan, Chenyou and Ho, Nhat and Cuturi, Marco and Jordan, Michael I.},
  year = {2020},
  month = jun,
  abstract = {Projection robust Wasserstein (PRW) distance, or Wasserstein projection pursuit (WPP), is a robust variant of the Wasserstein distance. Recent work suggests that this quantity is more robust than the standard Wasserstein distance, in particular when comparing probability measures in high-dimensions. However, it is ruled out for practical application because the optimization model is essentially non-convex and non-smooth which makes the computation intractable. Our contribution in this paper is to revisit the original motivation behind WPP/PRW, but take the hard route of showing that, despite its non-convexity and lack of nonsmoothness, and even despite some hardness results proved by\textasciitilde\textbackslash citet\{Niles-2019-Estimation\} in a minimax sense, the original formulation for PRW/WPP \textbackslash textit\{can\} be efficiently computed in practice using Riemannian optimization, yielding in relevant cases better behavior than its convex relaxation. More specifically, we provide three simple algorithms with solid theoretical guarantee on their complexity bound (one in the appendix), and demonstrate their effectiveness and efficiency by conducing extensive experiments on synthetic and real data. This paper provides a first step into a computational theory of the PRW distance and provides the links between optimal transport and Riemannian optimization.},
  archivePrefix = {arXiv},
  eprint = {2006.07458},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lin et al (2020) - Projection Robust Wasserstein Distance and Riemannian Optimization.pdf},
  journal = {arXiv:2006.07458 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@book{lindemann1983Employment,
  title = {Employment {{Discrimination Law}}},
  author = {Lindemann, Barbara and Grossman, Paul and Weirich, C Geoffrey},
  year = {1983}
}

@article{linderman2014Discovering,
  title = {Discovering {{Latent Network Structure}} in {{Point Process Data}}},
  author = {Linderman, Scott W. and Adams, Ryan P.},
  year = {2014},
  month = feb,
  abstract = {Networks play a central role in modern data analysis, enabling us to reason about systems by studying the relationships between their parts. Most often in network analysis, the edges are given. However, in many systems it is difficult or impossible to measure the network directly. Examples of latent networks include economic interactions linking financial instruments and patterns of reciprocity in gang violence. In these cases, we are limited to noisy observations of events associated with each node. To enable analysis of these implicit networks, we develop a probabilistic model that combines mutually-exciting point processes with random graph models. We show how the Poisson superposition principle enables an elegant auxiliary variable formulation and a fully-Bayesian, parallel inference algorithm. We evaluate this new model empirically on several datasets.},
  archivePrefix = {arXiv},
  eprint = {1402.0914},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Linderman, Adams (2014) - Discovering Latent Network Structure in Point Process Data.pdf},
  journal = {arXiv:1402.0914 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{lindley1972Bayes,
  title = {Bayes {{Estimates}} for the {{Linear Model}}},
  author = {Lindley, D. V. and Smith, A. F. M.},
  year = {1972},
  month = sep,
  volume = {34},
  pages = {1--18},
  issn = {00359246},
  doi = {10.1111/j.2517-6161.1972.tb00885.x},
  abstract = {The usual linear statistical model is reanalyzed using Bayesian methods and the concept of exchangeability. The general method is illustrated by applications to two-factor experimental designs and multiple regression.},
  file = {/Users/yuekai/Documents/zotero/Lindley, Smith (1972) - Bayes Estimates for the Linear Model.pdf},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  language = {en},
  number = {1}
}

@article{ling2016Machine,
  title = {Machine Learning Strategies for Systems with Invariance Properties},
  author = {Ling, Julia and Jones, Reese and Templeton, Jeremy},
  year = {2016},
  month = aug,
  volume = {318},
  pages = {22--35},
  issn = {00219991},
  doi = {10.1016/j.jcp.2016.05.003},
  abstract = {In many scientific fields, empirical models are employed to facilitate computational simulations of engineering systems. For example, in fluid mechanics, empirical Reynolds stress closures enable computationally-efficient Reynolds Averaged Navier Stokes simulations. Likewise, in solid mechanics, constitutive relations between the stress and strain in a material are required in deformation analysis. Traditional methods for developing and tuning empirical models usually combine physical intuition with simple regression techniques on limited data sets. The rise of high performance computing has led to a growing availability of high fidelity simulation data. These data open up the possibility of using machine learning algorithms, such as random forests or neural networks, to develop more accurate and general empirical models. A key question when using datadriven algorithms to develop these empirical models is how domain knowledge should be incorporated into the machine learning process. This paper will specifically address physical systems that possess symmetry or invariance properties. Two different methods for teaching a machine learning model an invariance property are compared. In the first method, a basis of invariant inputs is constructed, and the machine learning model is trained upon this basis, thereby embedding the invariance into the model. In the second method, the algorithm is trained on multiple transformations of the raw input data until the model learns invariance to that transformation. Results are discussed for two case studies: one in turbulence modeling and one in crystal elasticity. It is shown that in both cases embedding the invariance property into the input features yields higher performance at significantly reduced computational training costs.},
  file = {/Users/yuekai/Documents/zotero/Ling et al (2016) - Machine learning strategies for systems with invariance properties2.pdf},
  journal = {Journal of Computational Physics},
  language = {en}
}

@article{ling2016Reynolds,
  title = {Reynolds Averaged Turbulence Modelling Using Deep Neural Networks with Embedded Invariance},
  author = {Ling, Julia and Kurzawski, Andrew and Templeton, Jeremy},
  year = {2016},
  month = nov,
  volume = {807},
  pages = {155--166},
  publisher = {{Cambridge University Press}},
  issn = {0022-1120, 1469-7645},
  doi = {10.1017/jfm.2016.615},
  abstract = {There exists significant demand for improved Reynolds-averaged Navier\textendash Stokes (RANS) turbulence models that are informed by and can represent a richer set of turbulence physics. This paper presents a method of using deep neural networks to learn a model for the Reynolds stress anisotropy tensor from high-fidelity simulation data. A novel neural network architecture is proposed which uses a multiplicative layer with an invariant tensor basis to embed Galilean invariance into the predicted anisotropy tensor. It is demonstrated that this neural network architecture provides improved prediction accuracy compared with a generic neural network architecture that does not embed this invariance property. The Reynolds stress anisotropy predictions of this invariant neural network are propagated through to the velocity field for two test cases. For both test cases, significant improvement versus baseline RANS linear eddy viscosity and nonlinear eddy viscosity models is demonstrated.},
  file = {/Users/yuekai/Documents/zotero/Ling et al (2016) - Reynolds averaged turbulence modelling using deep neural networks with embedded.pdf},
  journal = {Journal of Fluid Mechanics},
  language = {en}
}

@article{lipton2018Detecting,
  title = {Detecting and {{Correcting}} for {{Label Shift}} with {{Black Box Predictors}}},
  author = {Lipton, Zachary C. and Wang, Yu-Xiang and Smola, Alex},
  year = {2018},
  month = jul,
  abstract = {Faced with distribution shift between training and test set, we wish to detect and quantify the shift, and to correct our classifiers without test set labels. Motivated by medical diagnosis, where diseases (targets) cause symptoms (observations), we focus on label shift, where the label marginal \$p(y)\$ changes but the conditional \$p(x| y)\$ does not. We propose Black Box Shift Estimation (BBSE) to estimate the test distribution \$p(y)\$. BBSE exploits arbitrary black box predictors to reduce dimensionality prior to shift correction. While better predictors give tighter estimates, BBSE works even when predictors are biased, inaccurate, or uncalibrated, so long as their confusion matrices are invertible. We prove BBSE's consistency, bound its error, and introduce a statistical test that uses BBSE to detect shift. We also leverage BBSE to correct classifiers. Experiments demonstrate accurate estimates and improved prediction, even on high-dimensional datasets of natural images.},
  archivePrefix = {arXiv},
  eprint = {1802.03916},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lipton et al (2018) - Detecting and Correcting for Label Shift with Black Box Predictors.pdf},
  journal = {arXiv:1802.03916 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{lipton2018Troubling,
  title = {Troubling {{Trends}} in {{Machine Learning Scholarship}}},
  author = {Lipton, Zachary C. and Steinhardt, Jacob},
  year = {2018},
  month = jul,
  abstract = {Collectively, machine learning (ML) researchers are engaged in the creation and dissemination of knowledge about data-driven algorithms. In a given paper, researchers might aspire to any subset of the following goals, among others: to theoretically characterize what is learnable, to obtain understanding through empirically rigorous experiments, or to build a working system that has high predictive accuracy. While determining which knowledge warrants inquiry may be subjective, once the topic is fixed, papers are most valuable to the community when they act in service of the reader, creating foundational knowledge and communicating as clearly as possible. Recent progress in machine learning comes despite frequent departures from these ideals. In this paper, we focus on the following four patterns that appear to us to be trending in ML scholarship: (i) failure to distinguish between explanation and speculation; (ii) failure to identify the sources of empirical gains, e.g., emphasizing unnecessary modifications to neural architectures when gains actually stem from hyper-parameter tuning; (iii) mathiness: the use of mathematics that obfuscates or impresses rather than clarifies, e.g., by confusing technical and non-technical concepts; and (iv) misuse of language, e.g., by choosing terms of art with colloquial connotations or by overloading established technical terms. While the causes behind these patterns are uncertain, possibilities include the rapid expansion of the community, the consequent thinness of the reviewer pool, and the often-misaligned incentives between scholarship and short-term measures of success (e.g., bibliometrics, attention, and entrepreneurial opportunity). While each pattern offers a corresponding remedy (don't do it), we also discuss some speculative suggestions for how the community might combat these trends.},
  archivePrefix = {arXiv},
  eprint = {1807.03341},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lipton, Steinhardt (2018) - Troubling Trends in Machine Learning Scholarship.pdf},
  journal = {arXiv:1807.03341 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{lipton2019Does,
  title = {Does Mitigating {{ML}}'s Impact Disparity Require Treatment Disparity?},
  author = {Lipton, Zachary C. and Chouldechova, Alexandra and McAuley, Julian},
  year = {2019},
  month = jan,
  abstract = {Following related work in law and policy, two notions of disparity have come to shape the study of fairness in algorithmic decision-making. Algorithms exhibit treatment disparity if they formally treat members of protected subgroups differently; algorithms exhibit impact disparity when outcomes differ across subgroups, even if the correlation arises unintentionally. Naturally, we can achieve impact parity through purposeful treatment disparity. In one thread of technical work, papers aim to reconcile the two forms of parity proposing disparate learning processes (DLPs). Here, the learning algorithm can see group membership during training but produce a classifier that is group-blind at test time. In this paper, we show theoretically that: (i) When other features correlate to group membership, DLPs will (indirectly) implement treatment disparity, undermining the policy desiderata they are designed to address; (ii) When group membership is partly revealed by other features, DLPs induce within-class discrimination; and (iii) In general, DLPs provide a suboptimal trade-off between accuracy and impact parity. Based on our technical analysis, we argue that transparent treatment disparity is preferable to occluded methods for achieving impact parity. Experimental results on several real-world datasets highlight the practical consequences of applying DLPs vs. per-group thresholds.},
  archivePrefix = {arXiv},
  eprint = {1711.07076},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lipton et al (2019) - Does mitigating ML's impact disparity require treatment disparity.pdf},
  journal = {arXiv:1711.07076 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{litvak2018smallest,
  title = {The Smallest Singular Value of a Shifted \$d\$-Regular Random Square Matrix},
  author = {Litvak, Alexander and Lytova, Anna and Tikhomirov, Konstantin and {Tomczak-Jaegermann}, Nicole and Youssef, Pierre},
  year = {2018},
  month = jun,
  issn = {0178-8051, 1432-2064},
  doi = {10.1007/s00440-018-0852-y},
  abstract = {We derive a lower bound on the smallest singular value of a random \$d\$-regular matrix, that is, the adjacency matrix of a random \$d\$-regular directed graph. More precisely, let \$C\_1},
  archivePrefix = {arXiv},
  eprint = {1707.02635},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Litvak et al (2018) - The smallest singular value of a shifted $d$-regular random square matrix.pdf},
  journal = {Probability Theory and Related Fields},
  keywords = {Mathematics - Combinatorics,Mathematics - Probability}
}

@inproceedings{liu2016Kernelized,
  title = {A {{Kernelized Stein Discrepancy}} for {{Goodness}}-of-Fit {{Tests}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Liu, Qiang and Lee, Jason and Jordan, Michael},
  year = {2016},
  month = jun,
  pages = {276--284},
  abstract = {We derive a new discrepancy statistic for measuring differences between two probability distributions based on combining Stein's identity and the reproducing kernel Hilbert space theory. We apply o...},
  file = {/Users/yuekai/Documents/zotero/Liu et al (2016) - A Kernelized Stein Discrepancy for Goodness-of-fit Tests.pdf},
  language = {en}
}

@article{liu2017Calibrated,
  title = {Calibrated {{Fairness}} in {{Bandits}}},
  author = {Liu, Yang and Radanovic, Goran and Dimitrakakis, Christos and Mandal, Debmalya and Parkes, David C.},
  year = {2017},
  month = jul,
  abstract = {We study fairness within the stochastic, \textbackslash emph\{multi-armed bandit\} (MAB) decision making framework. We adapt the fairness framework of "treating similar individuals similarly" to this setting. Here, an `individual' corresponds to an arm and two arms are `similar' if they have a similar quality distribution. First, we adopt a \{\textbackslash em smoothness constraint\} that if two arms have a similar quality distribution then the probability of selecting each arm should be similar. In addition, we define the \{\textbackslash em fairness regret\}, which corresponds to the degree to which an algorithm is not calibrated, where perfect calibration requires that the probability of selecting an arm is equal to the probability with which the arm has the best quality realization. We show that a variation on Thompson sampling satisfies smooth fairness for total variation distance, and give an \$\textbackslash tilde\{O\}((kT)\^\{2/3\})\$ bound on fairness regret. This complements prior work, which protects an on-average better arm from being less favored. We also explain how to extend our algorithm to the dueling bandit setting.},
  archivePrefix = {arXiv},
  eprint = {1707.01875},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Liu et al (2017) - Calibrated Fairness in Bandits.pdf},
  journal = {arXiv:1707.01875 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{liu2017Learning,
  title = {Learning {{Sparse Structural Changes}} in {{High}}-Dimensional {{Markov Networks}}: {{A Review}} on {{Methodologies}} and {{Theories}}},
  shorttitle = {Learning {{Sparse Structural Changes}} in {{High}}-Dimensional {{Markov Networks}}},
  author = {Liu, Song and Fukumizu, Kenji and Suzuki, Taiji},
  year = {2017},
  month = jan,
  abstract = {Recent years have seen an increasing popularity of learning the sparse \textbackslash emph\{changes\} in Markov Networks. Changes in the structure of Markov Networks reflect alternations of interactions between random variables under different regimes and provide insights into the underlying system. While each individual network structure can be complicated and difficult to learn, the overall change from one network to another can be simple. This intuition gave birth to an approach that \textbackslash emph\{directly\} learns the sparse changes without modelling and learning the individual (possibly dense) networks. In this paper, we review such a direct learning method with some latest developments along this line of research.},
  archivePrefix = {arXiv},
  eprint = {1701.01582},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Liu et al (2017) - Learning Sparse Structural Changes in High-dimensional Markov Networks.pdf},
  journal = {arXiv:1701.01582 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{liu2017Stein,
  title = {Stein {{Variational Gradient Descent}} as {{Gradient Flow}}},
  author = {Liu, Qiang},
  year = {2017},
  month = nov,
  abstract = {Stein variational gradient descent (SVGD) is a deterministic sampling algorithm that iteratively transports a set of particles to approximate given distributions, based on an efficient gradient-based update that guarantees to optimally decrease the KL divergence within a function space. This paper develops the first theoretical analysis on SVGD, discussing its weak convergence properties and showing that its asymptotic behavior is captured by a gradient flow of the KL divergence functional under a new metric structure induced by Stein operator. We also provide a number of results on Stein operator and Stein's identity using the notion of weak derivative, including a new proof of the distinguishability of Stein discrepancy under weak conditions.},
  archivePrefix = {arXiv},
  eprint = {1704.07520},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Liu (2017) - Stein Variational Gradient Descent as Gradient Flow.pdf},
  journal = {arXiv:1704.07520 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{liu2018Causal,
  title = {Causal {{Inference}} on {{Multidimensional Data Using Free Probability Theory}}},
  author = {Liu, F. and Chan, L.},
  year = {2018},
  month = jul,
  volume = {29},
  pages = {3188--3198},
  issn = {2162-237X},
  doi = {10.1109/TNNLS.2017.2716539},
  abstract = {In this paper, we deal with the problem of inferring causal relations for multidimensional data. Based on the postulate that the distribution of the cause and the conditional distribution of the effect given cause are generated independently, we show that the covariance matrix of the mean embedding of the cause in reproducing kernel Hilbert space (RKHS) is free independent with the covariance matrix of the conditional embedding of the effect given cause. This, called freeness condition, induces a cause-effect asymmetry that a designed measurement is 0 in the causal direction but smaller than 0 in the anticausal direction, and it uncovers the causal direction. One important novel aspect of this paper is that we interpret the independence as a freeness condition between covariance matrices of RKHS distribution embeddings, and it has a wide applicability. We show that our freeness condition-based inference method succeeds in scenarios like additive noise cases, where other methods fail, by theoretical analysis and experimental results.},
  file = {/Users/yuekai/Documents/zotero/Liu, Chan (2018) - Causal Inference on Multidimensional Data Using Free Probability Theory.pdf;/Users/yuekai/Zotero/storage/KY5LADG9/7983426.html},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  number = {7}
}

@article{liu2018Delayed,
  title = {Delayed {{Impact}} of {{Fair Machine Learning}}},
  author = {Liu, Lydia T. and Dean, Sarah and Rolf, Esther and Simchowitz, Max and Hardt, Moritz},
  year = {2018},
  month = mar,
  abstract = {Fairness in machine learning has predominantly been studied in static classification settings without concern for how decisions change the underlying population over time. Conventional wisdom suggests that fairness criteria promote the long-term well-being of those groups they aim to protect. We study how static fairness criteria interact with temporal indicators of well-being, such as long-term improvement, stagnation, and decline in a variable of interest. We demonstrate that even in a one-step feedback model, common fairness criteria in general do not promote improvement over time, and may in fact cause harm in cases where an unconstrained objective would not. We completely characterize the delayed impact of three standard criteria, contrasting the regimes in which these exhibit qualitatively different behavior. In addition, we find that a natural form of measurement error broadens the regime in which fairness criteria perform favorably. Our results highlight the importance of measurement and temporal modeling in the evaluation of fairness criteria, suggesting a range of new challenges and trade-offs.},
  archivePrefix = {arXiv},
  eprint = {1803.04383},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Liu et al (2018) - Delayed Impact of Fair Machine Learning.pdf},
  journal = {arXiv:1803.04383 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{liu2019Competing,
  title = {Competing {{Bandits}} in {{Matching Markets}}},
  author = {Liu, Lydia T. and Mania, Horia and Jordan, Michael I.},
  year = {2019},
  month = jun,
  abstract = {Stable matching, a classical model for two-sided markets, has long been studied with little consideration for how each side's preferences are learned. With the advent of massive online markets powered by data-driven matching platforms, it has become necessary to better understand the interplay between learning and market objectives. We propose a statistical learning model in which one side of the market does not have a priori knowledge about its preferences for the other side and is required to learn these from stochastic rewards. Our model extends the standard multi-armed bandits framework to multiple players, with the added feature that arms have preferences over players. We study both centralized and decentralized approaches to this problem and show surprising exploration-exploitation trade-offs compared to the single player multi-armed bandits setting.},
  archivePrefix = {arXiv},
  eprint = {1906.05363},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Liu et al (2019) - Competing Bandits in Matching Markets.pdf},
  journal = {arXiv:1906.05363 [cs, stat]},
  keywords = {Computer Science - Computer Science and Game Theory,Computer Science - Machine Learning,Computer Science - Multiagent Systems,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{liu2019Neural,
  title = {Neural {{SDE}}: {{Stabilizing Neural ODE Networks}} with {{Stochastic Noise}}},
  shorttitle = {Neural {{SDE}}},
  author = {Liu, Xuanqing and Xiao, Tesi and Si, Si and Cao, Qin and Kumar, Sanjiv and Hsieh, Cho-Jui},
  year = {2019},
  month = jun,
  abstract = {Neural Ordinary Differential Equation (Neural ODE) has been proposed as a continuous approximation to the ResNet architecture. Some commonly used regularization mechanisms in discrete neural networks (e.g. dropout, Gaussian noise) are missing in current Neural ODE networks. In this paper, we propose a new continuous neural network framework called Neural Stochastic Differential Equation (Neural SDE) network, which naturally incorporates various commonly used regularization mechanisms based on random noise injection. Our framework can model various types of noise injection frequently used in discrete networks for regularization purpose, such as dropout and additive/multiplicative noise in each block. We provide theoretical analysis explaining the improved robustness of Neural SDE models against input perturbations/adversarial attacks. Furthermore, we demonstrate that the Neural SDE network can achieve better generalization than the Neural ODE and is more resistant to adversarial and non-adversarial input perturbations.},
  archivePrefix = {arXiv},
  eprint = {1906.02355},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Liu et al (2019) - Neural SDE.pdf},
  journal = {arXiv:1906.02355 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{liu2019Robust,
  title = {Robust {{Regression}} for {{Safe Exploration}} in {{Control}}},
  author = {Liu, Anqi and Shi, Guanya and Chung, Soon-Jo and Anandkumar, Anima and Yue, Yisong},
  year = {2019},
  month = jun,
  abstract = {We study the problem of safe learning and exploration in sequential control problems. The goal is to safely collect data samples from an operating environment to learn an optimal controller. A central challenge in this setting is how to quantify uncertainty in order to choose provably-safe actions that allow us to collect useful data and reduce uncertainty, thereby achieving both improved safety and optimality. To address this challenge, we present a deep robust regression model that is trained to directly predict the uncertainty bounds for safe exploration. We then show how to integrate our robust regression approach with model-based control methods by learning a dynamic model with robustness bounds. We derive generalization bounds under domain shifts for learning and connect them with safety and stability bounds in control. We demonstrate empirically that our robust regression approach can outperform conventional Gaussian process (GP) based safe exploration in settings where it is difficult to specify a good GP prior.},
  archivePrefix = {arXiv},
  eprint = {1906.05819},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Liu et al (2019) - Robust Regression for Safe Exploration in Control.pdf},
  journal = {arXiv:1906.05819 [cs, eess, stat]},
  keywords = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Systems and Control,Statistics - Machine Learning},
  primaryClass = {cs, eess, stat}
}

@article{liu2019Stein,
  title = {Stein {{Variational Gradient Descent}}: {{A General Purpose Bayesian Inference Algorithm}}},
  shorttitle = {Stein {{Variational Gradient Descent}}},
  author = {Liu, Qiang and Wang, Dilin},
  year = {2019},
  month = sep,
  abstract = {We propose a general purpose variational inference algorithm that forms a natural counterpart of gradient descent for optimization. Our method iteratively transports a set of particles to match the target distribution, by applying a form of functional gradient descent that minimizes the KL divergence. Empirical studies are performed on various real world models and datasets, on which our method is competitive with existing state-of-the-art methods. The derivation of our method is based on a new theoretical result that connects the derivative of KL divergence under smooth transforms with Stein's identity and a recently proposed kernelized Stein discrepancy, which is of independent interest.},
  archivePrefix = {arXiv},
  eprint = {1608.04471},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Liu, Wang (2019) - Stein Variational Gradient Descent.pdf},
  journal = {arXiv:1608.04471 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{liu2019Triply,
  title = {Triply {{Robust Off}}-{{Policy Evaluation}}},
  author = {Liu, Anqi and Liu, Hao and Anandkumar, Anima and Yue, Yisong},
  year = {2019},
  month = nov,
  abstract = {We propose a robust regression approach to off-policy evaluation (OPE) for contextual bandits. We frame OPE as a covariate-shift problem and leverage modern robust regression tools. Ours is a general approach that can be used to augment any existing OPE method that utilizes the direct method. When augmenting doubly robust methods, we call the resulting method Triply Robust. We prove upper bounds on the resulting bias and variance, as well as derive novel minimax bounds based on robust minimax analysis for covariate shift. Our robust regression method is compatible with deep learning, and is thus applicable to complex OPE settings that require powerful function approximators. Finally, we demonstrate superior empirical performance across the standard OPE benchmarks, especially in the case where the logging policy is unknown and must be estimated from data.},
  archivePrefix = {arXiv},
  eprint = {1911.05811},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Liu et al (2019) - Triply Robust Off-Policy Evaluation.pdf},
  journal = {arXiv:1911.05811 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{liu2019Understanding,
  title = {Understanding and {{Accelerating Particle}}-{{Based Variational Inference}}},
  author = {Liu, Chang and Zhuo, Jingwei and Cheng, Pengyu and Zhang, Ruiyi and Zhu, Jun and Carin, Lawrence},
  year = {2019},
  month = jul,
  abstract = {Particle-based variational inference methods (ParVIs) have gained attention in the Bayesian inference literature, for their capacity to yield flexible and accurate approximations. We explore ParVIs from the perspective of Wasserstein gradient flows, and make both theoretical and practical contributions. We unify various finite-particle approximations that existing ParVIs use, and recognize that the approximation is essentially a compulsory smoothing treatment, in either of two equivalent forms. This novel understanding reveals the assumptions and relations of existing ParVIs, and also inspires new ParVIs. We propose an acceleration framework and a principled bandwidth-selection method for general ParVIs; these are based on the developed theory and leverage the geometry of the Wasserstein space. Experimental results show the improved convergence by the acceleration framework and enhanced sample accuracy by the bandwidth-selection method.},
  archivePrefix = {arXiv},
  eprint = {1807.01750},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Liu et al (2019) - Understanding and Accelerating Particle-Based Variational Inference.pdf},
  journal = {arXiv:1807.01750 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{liu2019Understandinga,
  title = {Understanding {{MCMC Dynamics}} as {{Flows}} on the {{Wasserstein Space}}},
  author = {Liu, Chang and Zhuo, Jingwei and Zhu, Jun},
  year = {2019},
  month = jul,
  abstract = {It is known that the Langevin dynamics used in MCMC is the gradient flow of the KL divergence on the Wasserstein space, which helps convergence analysis and inspires recent particle-based variational inference methods (ParVIs). But no more MCMC dynamics is understood in this way. In this work, by developing novel concepts, we propose a theoretical framework that recognizes a general MCMC dynamics as the fiber-gradient Hamiltonian flow on the Wasserstein space of a fiber-Riemannian Poisson manifold. The "conservation + convergence" structure of the flow gives a clear picture on the behavior of general MCMC dynamics. The framework also enables ParVI simulation of MCMC dynamics, which enriches the ParVI family with more efficient dynamics, and also adapts ParVI advantages to MCMCs. We develop two ParVI methods for a particular MCMC dynamics and demonstrate the benefits in experiments.},
  archivePrefix = {arXiv},
  eprint = {1902.00282},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Liu et al (2019) - Understanding MCMC Dynamics as Flows on the Wasserstein Space.pdf},
  journal = {arXiv:1902.00282 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{liu2020Fast,
  title = {Fast and {{Powerful Conditional Randomization Testing}} via {{Distillation}}},
  author = {Liu, Molei and Katsevich, Eugene and Janson, Lucas and Ramdas, Aaditya},
  year = {2020},
  month = jul,
  abstract = {We consider the problem of conditional independence testing, where given a response \$Y\$ and covariates \$(X,Z)\$, we test the null hypothesis that \$Y \textbackslash perp X \textbackslash mid Z\$. The conditional randomization test (CRT) was recently proposed as a way to use distributional information about \$X\textbackslash mid Z\$ to exactly (non-asymptotically) control Type-I error using \$any\$ test statistic in \$any\$ dimensionality without assuming anything about \$Y\textbackslash mid (X,Z)\$. This flexibility in principle allows one to derive powerful test statistics from complex state-of-the-art machine learning algorithms while maintaining statistical validity. Yet the direct use of such advanced test statistics in the CRT is prohibitively computationally expensive, especially with multiple testing, due to the CRT's requirement to recompute the test statistic many times on resampled data. We propose the \$distilled\textasciitilde CRT\$, a novel approach to using state-of-the-art machine learning algorithms in the CRT while drastically reducing the number of times those algorithms need to be run, thereby taking advantage of their power and the CRT's statistical guarantees without suffering the usual computational expense. In addition to distillation, we propose a number of other tricks like screening and recycling computations to further speed up the CRT without sacrificing its high power and exact validity. Indeed, we show in simulations that all our proposals combined lead to a test that has similar power to the CRT but requires orders of magnitude less computation, making it a practical tool even for large data sets. We demonstrate these benefits on a breast cancer dataset by identifying biomarkers related to cancer stage.},
  archivePrefix = {arXiv},
  eprint = {2006.03980},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Liu et al (2020) - Fast and Powerful Conditional Randomization Testing via Distillation.pdf;/Users/yuekai/Zotero/storage/2DMDNFXN/2006.html},
  journal = {arXiv:2006.03980 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{livni2014Computational,
  title = {On the {{Computational Efficiency}} of {{Training Neural Networks}}},
  author = {Livni, Roi and {Shalev-Shwartz}, Shai and Shamir, Ohad},
  year = {2014},
  month = oct,
  abstract = {It is well-known that neural networks are computationally hard to train. On the other hand, in practice, modern day neural networks are trained efficiently using SGD and a variety of tricks that include different activation functions (e.g. ReLU), over-specification (i.e., train networks which are larger than needed), and regularization. In this paper we revisit the computational complexity of training neural networks from a modern perspective. We provide both positive and negative results, some of them yield new provably efficient and practical algorithms for training certain types of neural networks.},
  archivePrefix = {arXiv},
  eprint = {1410.1141},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Livni et al (2014) - On the Computational Efficiency of Training Neural Networks.pdf},
  journal = {arXiv:1410.1141 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{loftus2018Causal,
  title = {Causal {{Reasoning}} for {{Algorithmic Fairness}}},
  author = {Loftus, Joshua R. and Russell, Chris and Kusner, Matt J. and Silva, Ricardo},
  year = {2018},
  month = may,
  abstract = {In this work, we argue for the importance of causal reasoning in creating fair algorithms for decision making. We give a review of existing approaches to fairness, describe work in causality necessary for the understanding of causal approaches, argue why causality is necessary for any approach that wishes to be fair, and give a detailed analysis of the many recent approaches to causality-based fairness.},
  archivePrefix = {arXiv},
  eprint = {1805.05859},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Loftus et al (2018) - Causal Reasoning for Algorithmic Fairness.pdf},
  journal = {arXiv:1805.05859 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society},
  primaryClass = {cs}
}

@article{loh2018Scale,
  title = {Scale Calibration for High-Dimensional Robust Regression},
  author = {Loh, Po-Ling},
  year = {2018},
  month = nov,
  abstract = {We present a new method for high-dimensional linear regression when a scale parameter of the additive errors is unknown. The proposed estimator is based on a penalized Huber \$M\$-estimator, for which theoretical results on estimation error have recently been proposed in high-dimensional statistics literature. However, the variance of the error term in the linear model is intricately connected to the optimal parameter used to define the shape of the Huber loss. Our main idea is to use an adaptive technique, based on Lepski's method, to overcome the difficulties in solving a joint nonconvex optimization problem with respect to the location and scale parameters.},
  archivePrefix = {arXiv},
  eprint = {1811.02096},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Loh (2018) - Scale calibration for high-dimensional robust regression.pdf},
  journal = {arXiv:1811.02096 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{long2018PDENet,
  title = {{{PDE}}-{{Net}} 2.0: {{Learning PDEs}} from {{Data}} with {{A Numeric}}-{{Symbolic Hybrid Deep Network}}},
  shorttitle = {{{PDE}}-{{Net}} 2.0},
  author = {Long, Zichao and Lu, Yiping and Dong, Bin},
  year = {2018},
  month = nov,
  abstract = {Partial differential equations (PDEs) are commonly derived based on empirical observations. However, recent advances of technology enable us to collect and store massive amount of data, which offers new opportunities for data-driven discovery of PDEs. In this paper, we propose a new deep neural network, called PDE-Net 2.0, to discover (time-dependent) PDEs from observed dynamic data with minor prior knowledge on the underlying mechanism that drives the dynamics. The design of PDE-Net 2.0 is based on our earlier work \textbackslash cite\{Long2018PDE\} where the original version of PDE-Net was proposed. PDE-Net 2.0 is a combination of numerical approximation of differential operators by convolutions and a symbolic multi-layer neural network for model recovery. Comparing with existing approaches, PDE-Net 2.0 has the most flexibility and expressive power by learning both differential operators and the nonlinear response function of the underlying PDE model. Numerical experiments show that the PDE-Net 2.0 has the potential to uncover the hidden PDE of the observed dynamics, and predict the dynamical behavior for a relatively long time, even in a noisy environment.},
  archivePrefix = {arXiv},
  eprint = {1812.04426},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Long et al (2018) - PDE-Net 2.pdf},
  journal = {arXiv:1812.04426 [physics, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Numerical Analysis,Physics - Computational Physics,Statistics - Machine Learning},
  primaryClass = {physics, stat}
}

@article{lopes2018Error,
  title = {Error {{Estimation}} for {{Randomized Least}}-{{Squares Algorithms}} via the {{Bootstrap}}},
  author = {Lopes, Miles E. and Wang, Shusen and Mahoney, Michael W.},
  year = {2018},
  month = mar,
  abstract = {Over the course of the past decade, a variety of randomized algorithms have been proposed for computing approximate least-squares (LS) solutions in large-scale settings. A longstanding practical issue is that, for any given input, the user rarely knows the actual error of an approximate solution (relative to the exact solution). Likewise, it is difficult for the user to know precisely how much computation is needed to achieve the desired error tolerance. Consequently, the user often appeals to worst-case error bounds that tend to offer only qualitative guidance. As a more practical alternative, we propose a bootstrap method to compute a posteriori error estimates for randomized LS algorithms. These estimates permit the user to numerically assess the error of a given solution, and to predict how much work is needed to improve a "preliminary" solution. In addition, we provide theoretical consistency results for the method, which are the first such results in this context (to the best of our knowledge). From a practical standpoint, the method also has considerable flexibility, insofar as it can be applied to several popular sketching algorithms, as well as a variety of error metrics. Moreover, the extra step of error estimation does not add much cost to an underlying sketching algorithm. Finally, we demonstrate the effectiveness of the method with empirical results.},
  archivePrefix = {arXiv},
  eprint = {1803.08021},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lopes et al (2018) - Error Estimation for Randomized Least-Squares Algorithms via the Bootstrap.pdf},
  journal = {arXiv:1803.08021 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{lotz2018Concentration,
  title = {Concentration of the {{Intrinsic Volumes}} of a {{Convex Body}}},
  author = {Lotz, Martin and McCoy, Michael B. and Nourdin, Ivan and Peccati, Giovanni and Tropp, Joel A.},
  year = {2018},
  month = oct,
  abstract = {The intrinsic volumes are measures of the content of a convex body. This paper uses probabilistic and information-theoretic methods to study the sequence of intrinsic volumes of a convex body. The main result states that the intrinsic volume sequence concentrates sharply around a specific index, called the central intrinsic volume. Furthermore, among all convex bodies whose central intrinsic volume is fixed, an appropriately scaled cube has the intrinsic volume sequence with maximum entropy.},
  archivePrefix = {arXiv},
  eprint = {1810.12412},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lotz et al (2018) - Concentration of the Intrinsic Volumes of a Convex Body.pdf},
  journal = {arXiv:1810.12412 [cs, math]},
  keywords = {Computer Science - Information Theory,Mathematics - Metric Geometry,Mathematics - Probability},
  primaryClass = {cs, math}
}

@article{lu2019Intelligent,
  title = {Intelligent Sampling for Multiple Change-Points in Exceedingly Long Time Series with Rate Guarantees},
  author = {Lu, Zhiyuan and Banerjee, Moulinath and Michailidis, George},
  year = {2019},
  month = feb,
  abstract = {Change point estimation in its offline version is traditionally performed by optimizing over the data set of interest, by considering each data point as the true location parameter and computing a data fit criterion. Subsequently, the data point that minimizes the criterion is declared as the change point estimate. For estimating multiple change points, the procedures are analogous in spirit, but significantly more involved in execution. Since change-points are local discontinuities, only data points close to the actual change point provide useful information for estimation, while data points far away are superfluous, to the point where using only a few points close to the true parameter is just as precise as using the full data set. Leveraging this "locality principle", we introduce a two-stage procedure for the problem at hand, which in the 1st stage uses a sparse subsample to obtain pilot estimates of the underlying change points, and in the 2nd stage refines these estimates by sampling densely in appropriately defined neighborhoods around them. We establish that this method achieves the same rate of convergence and even virtually the same asymptotic distribution as the analysis of the full data, while reducing computational complexity to O(N\^0.5) time (N being the length of data set), as opposed to at least O(N) time for all current procedures, making it promising for the analysis on exceedingly long data sets with adequately spaced out change points. The main results are established under a signal plus noise model with independent and identically distributed error terms, but extensions to dependent data settings, as well as multiple stage ({$>$}2) procedures are also provided. The performance of our procedure -- which is coined "intelligent sampling" -- is illustrated on both synthetic and real Internet data streams.},
  archivePrefix = {arXiv},
  eprint = {1710.07420},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lu et al (2019) - Intelligent sampling for multiple change-points in exceedingly long time series.pdf},
  journal = {arXiv:1710.07420 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{lu2019Statistical,
  title = {Statistical Inference for Piecewise Normal Distributions and Stochastic Variational Inequalities},
  author = {Lu, Shu and Liu, Hongsheng},
  year = {2019},
  month = jul,
  abstract = {In this paper we first provide a method to compute confidence intervals for the center of a piecewise normal distribution given a sample from this distribution, under certain assumptions. We then extend this method to an asymptotic setting, and apply this method to compute confidence intervals for the true solution of a stochastic variational inequality based on a solution to a sample average approximation problem. The confidence intervals are computed with simple formulas. Performance of the proposed method is tested with numerical experiments.},
  archivePrefix = {arXiv},
  eprint = {1907.05353},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Lu, Liu (2019) - Statistical inference for piecewise normal distributions and stochastic.pdf},
  journal = {arXiv:1907.05353 [math, stat]},
  keywords = {Mathematics - Optimization and Control,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{lubke2005Investigating,
  title = {Investigating Population Heterogeneity with Factor Mixture Models.},
  author = {Lubke, Gitta H. and Muth{\'e}n, Bengt},
  year = {2005},
  month = mar,
  volume = {10},
  pages = {21--39},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/1082-989X.10.1.21},
  file = {/Users/yuekai/Documents/zotero/Lubke, Muthén (2005) - Investigating population heterogeneity with factor mixture models.pdf},
  journal = {Psychological Methods},
  language = {en},
  number = {1}
}

@book{luenberger1968OPTIMIZATION,
  title = {{{OPTIMIZATION BY VECTOR SPACE METHODS}}},
  author = {Luenberger, David},
  year = {1968},
  publisher = {{John Wiley \& Sons}},
  file = {/Users/yuekai/Documents/zotero/Luenberger (1968) - OPTIMIZATION BY VECTOR SPACE METHODS.pdf}
}

@article{luise2018Differential,
  title = {Differential {{Properties}} of {{Sinkhorn Approximation}} for {{Learning}} with {{Wasserstein Distance}}},
  author = {Luise, Giulia and Rudi, Alessandro and Pontil, Massimiliano and Ciliberto, Carlo},
  year = {2018},
  month = may,
  abstract = {Applications of optimal transport have recently gained remarkable attention thanks to the computational advantages of entropic regularization. However, in most situations the Sinkhorn approximation of the Wasserstein distance is replaced by a regularized version that is less accurate but easy to differentiate. In this work we characterize the differential properties of the original Sinkhorn distance, proving that it enjoys the same smoothness as its regularized version and we explicitly provide an efficient algorithm to compute its gradient. We show that this result benefits both theory and applications: on one hand, high order smoothness confers statistical guarantees to learning with Wasserstein approximations. On the other hand, the gradient formula allows us to efficiently solve learning and optimization problems in practice. Promising preliminary experiments complement our analysis.},
  archivePrefix = {arXiv},
  eprint = {1805.11897},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Luise et al (2018) - Differential Properties of Sinkhorn Approximation for Learning with Wasserstein.pdf},
  journal = {arXiv:1805.11897 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{luo2017Efficient,
  title = {Efficient {{Contextual Bandits}} in {{Non}}-Stationary {{Worlds}}},
  author = {Luo, Haipeng and Wei, Chen-Yu and Agarwal, Alekh and Langford, John},
  year = {2017},
  month = aug,
  abstract = {Most contextual bandit algorithms minimize regret against the best fixed policy, a questionable benchmark for non-stationary environments that are ubiquitous in applications. In this work, we develop several efficient contextual bandit algorithms for non-stationary environments by equipping existing methods for i.i.d. problems with sophisticated statistical tests so as to dynamically adapt to a change in distribution. We analyze various standard notions of regret suited to non-stationary environments for these algorithms, including interval regret, switching regret, and dynamic regret. When competing with the best policy at each time, one of our algorithms achieves regret \$\textbackslash mathcal\{O\}(\textbackslash sqrt\{ST\})\$ if there are \$T\$ rounds with \$S\$ stationary periods, or more generally \$\textbackslash mathcal\{O\}(\textbackslash Delta\^\{1/3\}T\^\{2/3\})\$ where \$\textbackslash Delta\$ is some non-stationarity measure. These results almost match the optimal guarantees achieved by an inefficient baseline that is a variant of the classic Exp4 algorithm. The dynamic regret result is also the first one for efficient and fully adversarial contextual bandit. Furthermore, while the results above require tuning a parameter based on the unknown quantity \$S\$ or \$\textbackslash Delta\$, we also develop a parameter free algorithm achieving regret \$\textbackslash min\textbackslash\{S\^\{1/4\}T\^\{3/4\}, \textbackslash Delta\^\{1/5\}T\^\{4/5\}\textbackslash\}\$. This improves and generalizes the best existing result \$\textbackslash Delta\^\{0.18\}T\^\{0.82\}\$ by Karnin and Anava (2016) which only holds for the two-armed bandit problem.},
  archivePrefix = {arXiv},
  eprint = {1708.01799},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Luo et al (2017) - Efficient Contextual Bandits in Non-stationary Worlds.pdf},
  journal = {arXiv:1708.01799 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{ma2016Joint,
  title = {Joint {{Structural Estimation}} of {{Multiple Graphical Models}}},
  author = {Ma, Jing and Michailidis, George},
  year = {2016},
  month = jan,
  volume = {17},
  pages = {5777--5824},
  issn = {1532-4435},
  abstract = {Gaussian graphical models capture dependence relationships between random variables through the pattern of nonzero elements in the corresponding inverse covariance matrices. To date, there has been a large body of literature on both computational methods and analytical results on the estimation of a single graphical model. However, in many application domains, one has to estimate several related graphical models, a problem that has also received attention in the literature. The available approaches usually assume that all graphical models are globally related. On the other hand, in many settings different relationships between subsets of the node sets exist between different graphical models. We develop methodology that jointly estimates multiple Gaussian graphical models, assuming that there exists prior information on how they are structurally related. For many applications, such information is available from external data sources. The proposed method consists of first applying neighborhood selection with a group lasso penalty to obtain edge sets of the graphs, and a maximum likelihood refit for estimating the nonzero entries in the inverse covariance matrices. We establish consistency of the proposed method for sparse high-dimensional Gaussian graphical models and examine its performance using simulation experiments. Applications to a climate data set and a breast cancer data set are also discussed.},
  file = {/Users/yuekai/Documents/zotero/Ma, Michailidis (2016) - Joint Structural Estimation of Multiple Graphical Models.pdf},
  journal = {J. Mach. Learn. Res.},
  number = {1}
}

@article{ma2017Diving,
  title = {Diving into the Shallows: A Computational Perspective on Large-Scale Shallow Learning},
  shorttitle = {Diving into the Shallows},
  author = {Ma, Siyuan and Belkin, Mikhail},
  year = {2017},
  month = mar,
  abstract = {In this paper we first identify a basic limitation in gradient descent-based optimization methods when used in conjunctions with smooth kernels. An analysis based on the spectral properties of the kernel demonstrates that only a vanishingly small portion of the function space is reachable after a polynomial number of gradient descent iterations. This lack of approximating power drastically limits gradient descent for a fixed computational budget leading to serious over-regularization/underfitting. The issue is purely algorithmic, persisting even in the limit of infinite data. To address this shortcoming in practice, we introduce EigenPro iteration, based on a preconditioning scheme using a small number of approximately computed eigenvectors. It can also be viewed as learning a new kernel optimized for gradient descent. It turns out that injecting this small (computationally inexpensive and SGD-compatible) amount of approximate second-order information leads to major improvements in convergence. For large data, this translates into significant performance boost over the standard kernel methods. In particular, we are able to consistently match or improve the state-of-the-art results recently reported in the literature with a small fraction of their computational budget. Finally, we feel that these results show a need for a broader computational perspective on modern large-scale learning to complement more traditional statistical and convergence analyses. In particular, many phenomena of large-scale high-dimensional inference are best understood in terms of optimization on infinite dimensional Hilbert spaces, where standard algorithms can sometimes have properties at odds with finite-dimensional intuition. A systematic analysis concentrating on the approximation power of such algorithms within a budget of computation may lead to progress both in theory and practice.},
  archivePrefix = {arXiv},
  eprint = {1703.10622},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ma, Belkin (2017) - Diving into the shallows.pdf},
  journal = {arXiv:1703.10622 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{ma2017Exploration,
  title = {Exploration of {{Large Networks}} with {{Covariates}} via {{Fast}} and {{Universal Latent Space Model Fitting}}},
  author = {Ma, Zhuang and Ma, Zongming},
  year = {2017},
  month = may,
  abstract = {Latent space models are effective tools for statistical modeling and exploration of network data. These models can effectively model real world network characteristics such as degree heterogeneity, transitivity, homophily, etc. Due to their close connection to generalized linear models, it is also natural to incorporate covariate information in them. The current paper presents two universal fitting algorithms for networks with edge covariates: one based on nuclear norm penalization and the other based on projected gradient descent. Both algorithms are motivated by maximizing likelihood for a special class of inner-product models while working simultaneously for a wide range of different latent space models, such as distance models, which allow latent vectors to affect edge formation in flexible ways. These fitting methods, especially the one based on projected gradient descent, are fast and scalable to large networks. We obtain their rates of convergence for both inner-product models and beyond. The effectiveness of the modeling approach and fitting algorithms is demonstrated on five real world network datasets for different statistical tasks, including community detection with and without edge covariates, and network assisted learning.},
  archivePrefix = {arXiv},
  eprint = {1705.02372},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ma, Ma (2017) - Exploration of Large Networks with Covariates via Fast and Universal Latent.pdf},
  journal = {arXiv:1705.02372 [cs, stat]},
  keywords = {Computer Science - Social and Information Networks,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {cs, stat}
}

@article{ma2018Sampling,
  title = {Sampling {{Can Be Faster Than Optimization}}},
  author = {Ma, Yi-An and Chen, Yuansi and Jin, Chi and Flammarion, Nicolas and Jordan, Michael I.},
  year = {2018},
  month = nov,
  abstract = {Optimization algorithms and Monte Carlo sampling algorithms have provided the computational foundations for the rapid growth in applications of statistical machine learning in recent years. There is, however, limited theoretical understanding of the relationships between these two kinds of methodology, and limited understanding of relative strengths and weaknesses. Moreover, existing results have been obtained primarily in the setting of convex functions (for optimization) and log-concave functions (for sampling). In this setting, where local properties determine global properties, optimization algorithms are unsurprisingly more efficient computationally than sampling algorithms. We instead examine a class of nonconvex objective functions that arise in mixture modeling and multi-stable systems. In this nonconvex setting, we find that the computational complexity of sampling algorithms scales linearly with the model dimension while that of optimization algorithms scales exponentially.},
  archivePrefix = {arXiv},
  eprint = {1811.08413},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ma et al (2018) - Sampling Can Be Faster Than Optimization.pdf},
  journal = {arXiv:1811.08413 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{ma2019Implicit,
  title = {Implicit {{Regularization}} in {{Nonconvex Statistical Estimation}}: {{Gradient Descent Converges Linearly}} for {{Phase Retrieval}}, {{Matrix Completion}}, and {{Blind Deconvolution}}},
  shorttitle = {Implicit {{Regularization}} in {{Nonconvex Statistical Estimation}}},
  author = {Ma, Cong and Wang, Kaizheng and Chi, Yuejie and Chen, Yuxin},
  year = {2019},
  month = jul,
  abstract = {Recent years have seen a flurry of activities in designing provably efficient nonconvex procedures for solving statistical estimation problems. Due to the highly nonconvex nature of the empirical loss, state-of-the-art procedures often require proper regularization (e.g. trimming, regularized cost, projection) in order to guarantee fast convergence. For vanilla procedures such as gradient descent, however, prior theory either recommends highly conservative learning rates to avoid overshooting, or completely lacks performance guarantees. This paper uncovers a striking phenomenon in nonconvex optimization: even in the absence of explicit regularization, gradient descent enforces proper regularization implicitly under various statistical models. In fact, gradient descent follows a trajectory staying within a basin that enjoys nice geometry, consisting of points incoherent with the sampling mechanism. This "implicit regularization" feature allows gradient descent to proceed in a far more aggressive fashion without overshooting, which in turn results in substantial computational savings. Focusing on three fundamental statistical estimation problems, i.e. phase retrieval, low-rank matrix completion, and blind deconvolution, we establish that gradient descent achieves near-optimal statistical and computational guarantees without explicit regularization. In particular, by marrying statistical modeling with generic optimization theory, we develop a general recipe for analyzing the trajectories of iterative algorithms via a leave-one-out perturbation argument. As a byproduct, for noisy matrix completion, we demonstrate that gradient descent achieves near-optimal error control --- measured entrywise and by the spectral norm --- which might be of independent interest.},
  archivePrefix = {arXiv},
  eprint = {1711.10467},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ma et al (2019) - Implicit Regularization in Nonconvex Statistical Estimation.pdf},
  journal = {arXiv:1711.10467 [cs, math, stat]},
  keywords = {Computer Science - Information Theory,Computer Science - Machine Learning,Mathematics - Optimization and Control,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@inproceedings{maaten2012Stochastic,
  title = {Stochastic Triplet Embedding},
  booktitle = {2012 {{IEEE International Workshop}} on {{Machine Learning}} for {{Signal Processing}}},
  author = {van der Maaten, L. and Weinberger, K.},
  year = {2012},
  month = sep,
  pages = {1--6},
  doi = {10.1109/MLSP.2012.6349720},
  abstract = {This paper considers the problem of learning an embedding of data based on similarity triplets of the form ``A is more similar to B than to C''. This learning setting is of relevance to scenarios in which we wish to model human judgements on the similarity of objects. We argue that in order to obtain a truthful embedding of the underlying data, it is insufficient for the embedding to satisfy the constraints encoded by the similarity triplets. In particular, we introduce a new technique called t-Distributed Stochastic Triplet Embedding (t-STE) that collapses similar points and repels dissimilar points in the embedding - even when all triplet constraints are satisfied. Our experimental evaluation on three data sets shows that as a result, t-STE is much better than existing techniques at revealing the underlying data structure.},
  file = {/Users/yuekai/Documents/zotero/Maaten, Weinberger (2012) - Stochastic triplet embedding.pdf;/Users/yuekai/Zotero/storage/XGR55WGZ/6349720.html}
}

@inproceedings{madaan2018Analyze,
  title = {Analyze, {{Detect}} and {{Remove Gender Stereotyping}} from {{Bollywood Movies}}},
  booktitle = {Conference on {{Fairness}}, {{Accountability}} and {{Transparency}}},
  author = {Madaan, Nishtha and Mehta, Sameep and Agrawaal, Taneea and Malhotra, Vrinda and Aggarwal, Aditi and Gupta, Yatin and Saxena, Mayank},
  year = {2018},
  month = jan,
  pages = {92--105},
  abstract = {The presence of gender stereotypes in many aspects of society is a well-known phenomenon. In this paper, we focus on studying such stereotypes and bias in Hindi movie industry (\textbackslash it Bollywood) and p...},
  file = {/Users/yuekai/Documents/zotero/Madaan et al (2018) - Analyze, Detect and Remove Gender Stereotyping from Bollywood Movies.pdf},
  language = {en}
}

@article{madras2018Learning,
  title = {Learning {{Adversarially Fair}} and {{Transferable Representations}}},
  author = {Madras, David and Creager, Elliot and Pitassi, Toniann and Zemel, Richard},
  year = {2018},
  month = feb,
  abstract = {In this paper, we advocate for representation learning as the key to mitigating unfair prediction outcomes downstream. Motivated by a scenario where learned representations are used by third parties with unknown objectives, we propose and explore adversarial representation learning as a natural method of ensuring those parties act fairly. We connect group fairness (demographic parity, equalized odds, and equal opportunity) to different adversarial objectives. Through worst-case theoretical guarantees and experimental validation, we show that the choice of this objective is crucial to fair prediction. Furthermore, we present the first in-depth experimental demonstration of fair transfer learning and demonstrate empirically that our learned representations admit fair predictions on new tasks while maintaining utility, an essential goal of fair representation learning.},
  archivePrefix = {arXiv},
  eprint = {1802.06309},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Madras et al (2018) - Learning Adversarially Fair and Transferable Representations.pdf},
  journal = {arXiv:1802.06309 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{madry2017Deep,
  title = {Towards {{Deep Learning Models Resistant}} to {{Adversarial Attacks}}},
  author = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  year = {2017},
  month = jun,
  abstract = {Recent work has demonstrated that neural networks are vulnerable to adversarial examples, i.e., inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models.},
  archivePrefix = {arXiv},
  eprint = {1706.06083},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Madry et al (2017) - Towards Deep Learning Models Resistant to Adversarial Attacks.pdf},
  journal = {arXiv:1706.06083 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{magliacane2018Domain,
  title = {Domain {{Adaptation}} by {{Using Causal Inference}} to {{Predict Invariant Conditional Distributions}}},
  author = {Magliacane, Sara and {van Ommen}, Thijs and Claassen, Tom and Bongers, Stephan and Versteeg, Philip and Mooij, Joris M.},
  year = {2018},
  month = oct,
  abstract = {An important goal common to domain adaptation and causal inference is to make accurate predictions when the distributions for the source (or training) domain(s) and target (or test) domain(s) differ. In many cases, these different distributions can be modeled as different contexts of a single underlying system, in which each distribution corresponds to a different perturbation of the system, or in causal terms, an intervention. We focus on a class of such causal domain adaptation problems, where data for one or more source domains are given, and the task is to predict the distribution of a certain target variable from measurements of other variables in one or more target domains. We propose an approach for solving these problems that exploits causal inference and does not rely on prior knowledge of the causal graph, the type of interventions or the intervention targets. We demonstrate our approach by evaluating a possible implementation on simulated and real world data.},
  archivePrefix = {arXiv},
  eprint = {1707.06422},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Magliacane et al (2018) - Domain Adaptation by Using Causal Inference to Predict Invariant Conditional.pdf},
  journal = {arXiv:1707.06422 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{mahadevan2002Dynamic,
  title = {Dynamic {{Flux Balance Analysis}} of {{Diauxic Growth}} in {{Escherichia}} Coli},
  author = {Mahadevan, Radhakrishnan and Edwards, Jeremy S. and Doyle, Francis J.},
  year = {2002},
  month = sep,
  volume = {83},
  pages = {1331--1340},
  issn = {00063495},
  doi = {10.1016/S0006-3495(02)73903-9},
  abstract = {Flux Balance Analysis (FBA) has been used in the past to analyze microbial metabolic networks. Typically, FBA is used to study the metabolic flux at a particular steady state of the system. However, there are many situations where the reprogramming of the metabolic network is important. Therefore, the dynamics of these metabolic networks have to be studied. In this paper, we have extended FBA to account for dynamics and present two different formulations for dynamic FBA. These two approaches were used in the analysis of diauxic growth in Escherichia coli. Dynamic FBA was used to simulate the batch growth of E. coli on glucose, and the predictions were found to qualitatively match experimental data. The dynamic FBA formalism was also used to study the sensitivity to the objective function. It was found that an instantaneous objective function resulted in better predictions than a terminal-type objective function. The constraints that govern the growth at different phases in the batch culture were also identified. Therefore, dynamic FBA provides a framework for analyzing the transience of metabolism due to metabolic reprogramming and for obtaining insights for the design of metabolic networks.},
  file = {/Users/yuekai/Documents/zotero/Mahadevan et al (2002) - Dynamic Flux Balance Analysis of Diauxic Growth in Escherichia coli.pdf},
  journal = {Biophysical Journal},
  language = {en},
  number = {3}
}

@article{mahadevan2014Proximal,
  title = {Proximal {{Reinforcement Learning}}: {{A New Theory}} of {{Sequential Decision Making}} in {{Primal}}-{{Dual Spaces}}},
  shorttitle = {Proximal {{Reinforcement Learning}}},
  author = {Mahadevan, Sridhar and Liu, Bo and Thomas, Philip and Dabney, Will and Giguere, Steve and Jacek, Nicholas and Gemp, Ian and Liu, Ji},
  year = {2014},
  month = may,
  abstract = {In this paper, we set forth a new vision of reinforcement learning developed by us over the past few years, one that yields mathematically rigorous solutions to longstanding important questions that have remained unresolved: (i) how to design reliable, convergent, and robust reinforcement learning algorithms (ii) how to guarantee that reinforcement learning satisfies pre-specified "safety" guarantees, and remains in a stable region of the parameter space (iii) how to design "off-policy" temporal difference learning algorithms in a reliable and stable manner, and finally (iv) how to integrate the study of reinforcement learning into the rich theory of stochastic optimization. In this paper, we provide detailed answers to all these questions using the powerful framework of proximal operators. The key idea that emerges is the use of primal dual spaces connected through the use of a Legendre transform. This allows temporal difference updates to occur in dual spaces, allowing a variety of important technical advantages. The Legendre transform elegantly generalizes past algorithms for solving reinforcement learning problems, such as natural gradient methods, which we show relate closely to the previously unconnected framework of mirror descent methods. Equally importantly, proximal operator theory enables the systematic development of operator splitting methods that show how to safely and reliably decompose complex products of gradients that occur in recent variants of gradient-based temporal difference learning. This key technical innovation makes it possible to finally design "true" stochastic gradient methods for reinforcement learning. Finally, Legendre transforms enable a variety of other benefits, including modeling sparsity and domain geometry. Our work builds extensively on recent work on the convergence of saddle-point algorithms, and on the theory of monotone operators.},
  archivePrefix = {arXiv},
  eprint = {1405.6757},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mahadevan et al (2014) - Proximal Reinforcement Learning.pdf},
  journal = {arXiv:1405.6757 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{maity2019CommunicationEfficient,
  title = {Communication-{{Efficient Integrative Regression}} in {{High}}-{{Dimensions}}},
  author = {Maity, Subha and Sun, Yuekai and Banerjee, Moulinath},
  year = {2019},
  month = dec,
  abstract = {We consider the task of meta-analysis in high-dimensional settings in which the data sources we wish to integrate are similar but non-identical. To borrow strength across such heterogeneous data sources, we introduce a global parameter that addresses several identification issues. We also propose a one-shot estimator of the global parameter that preserves the anonymity of the data sources and converges at a rate that depends on the size of the combined dataset. Finally, we demonstrate the benefits of our approach on a large-scale drug treatment dataset involving several different cancer cell lines.},
  archivePrefix = {arXiv},
  eprint = {1912.11928},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Maity et al (2019) - Communication-Efficient Integrative Regression in High-Dimensions.pdf},
  journal = {arXiv:1912.11928 [stat]},
  keywords = {Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {stat}
}

@article{maity2020Transfer,
  title = {Transfer {{Learning}} for {{Target Shift}}: {{Minimax Rate}} and {{Classifier}}},
  shorttitle = {Transfer {{Learning}} for {{Target Shift}}: {{Minimax Rate}} and {{Classifier}}},
  author = {Maity, Subha and Banerjee, Moulinath and Sun, Yuekai},
  year = {2020},
  month = mar,
  abstract = {Humans have an inherent ability to transfer knowledge across tasks. This ability to transfer knowledge across task is necessary for effective learning, and is considered as the next driver of artificial intelligence to be commercially successful.	In this project, we study the problem of transfer learning in the context of non-parametric classification under the target shift model. We show that the difficulty of the target shift problem is determined primarily by the smoothness of the ratio of the densities of the class conditional distributions. This is not surprising because this ratio also determines the difficulty of classification in IID (non-transfer learning) settings. In other words, as long as we correctly approach the task, the target shift aspect does not contribute to its difficulty. Formally, we establish a minimax rate of convergence for the excess risk and propose a classifier that achieves the minimax rate. The approach taken by the rate-optimal classifier suggests the correct way of approaching the target shift task.},
  archivePrefix = {arXiv},
  eprint = {1903.10063},
  eprinttype = {arxiv},
  journal = {submitted to Annals of Statistics},
  keywords = {Mathematics - Statistics Theory}
}

@article{mak2016Support,
  title = {Support Points},
  author = {Mak, Simon and Joseph, V. Roshan},
  year = {2016},
  month = sep,
  abstract = {This paper introduces a new way to compact a continuous probability distribution \$F\$ into a set of representative points called support points. These points are obtained by minimizing the energy distance, a statistical potential measure initially proposed by Sz\textbackslash 'ekely and Rizzo (2004) for testing goodness-of-fit. The energy distance has two appealing features. First, its distance-based structure allows us to exploit the duality between powers of the Euclidean distance and its Fourier transform for theoretical analysis. Using this duality, we show that support points converge in distribution to \$F\$, and enjoy an improved error rate to Monte Carlo for integrating a large class of functions. Second, the minimization of the energy distance can be formulated as a difference-of-convex program, which we manipulate using two algorithms to efficiently generate representative point sets. In simulation studies, support points provide improved integration performance to both Monte Carlo and a specific Quasi-Monte Carlo method. Two important applications of support points are then highlighted: (a) as a way to quantify the propagation of uncertainty in expensive simulations, and (b) as a method to optimally compact Markov chain Monte Carlo (MCMC) samples in Bayesian computation.},
  archivePrefix = {arXiv},
  eprint = {1609.01811},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mak, Joseph (2016) - Support points.pdf;/Users/yuekai/Documents/zotero/Mak, Joseph (2016) - Support points.pdf},
  journal = {arXiv:1609.01811 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{makkuva2020Optimal,
  title = {Optimal Transport Mapping via Input Convex Neural Networks},
  author = {Makkuva, Ashok Vardhan and Taghvaei, Amirhossein and Oh, Sewoong and Lee, Jason D.},
  year = {2020},
  month = jun,
  abstract = {In this paper, we present a novel and principled approach to learn the optimal transport between two distributions, from samples. Guided by the optimal transport theory, we learn the optimal Kantorovich potential which induces the optimal transport map. This involves learning two convex functions, by solving a novel minimax optimization. Building upon recent advances in the field of input convex neural networks, we propose a new framework where the gradient of one convex function represents the optimal transport mapping. Numerical experiments confirm that we learn the optimal transport mapping. This approach ensures that the transport mapping we find is optimal independent of how we initialize the neural networks. Further, target distributions from a discontinuous support can be easily captured, as gradient of a convex function naturally models a \{\textbackslash em discontinuous\} transport mapping.},
  archivePrefix = {arXiv},
  eprint = {1908.10962},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Makkuva et al (2020) - Optimal transport mapping via input convex neural networks.pdf},
  journal = {arXiv:1908.10962 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{malinsky2019Potential,
  title = {A {{Potential Outcomes Calculus}} for {{Identifying Conditional Path}}-{{Specific Effects}}},
  author = {Malinsky, Daniel and Shpitser, Ilya and Richardson, Thomas},
  year = {2019},
  month = mar,
  abstract = {The do-calculus is a well-known deductive system for deriving connections between interventional and observed distributions, and has been proven complete for a number of important identifiability problems in causal inference. Nevertheless, as it is currently defined, the do-calculus is inapplicable to causal problems that involve complex nested counterfactuals which cannot be expressed in terms of the "do" operator. Such problems include analyses of path-specific effects and dynamic treatment regimes. In this paper we present the potential outcome calculus (po-calculus), a natural generalization of do-calculus for arbitrary potential outcomes. We thereby provide a bridge between identification approaches which have their origins in artificial intelligence and statistics, respectively. We use po-calculus to give a complete identification algorithm for conditional path-specific effects with applications to problems in mediation analysis and algorithmic fairness.},
  archivePrefix = {arXiv},
  eprint = {1903.03662},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Malinsky et al (2019) - A Potential Outcomes Calculus for Identifying Conditional Path-Specific Effects.pdf},
  journal = {arXiv:1903.03662 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{malod-dognin2018Precision,
  title = {Precision Medicine \rule{1em}{1pt} {{A}} Promising, yet Challenging Road Lies Ahead},
  author = {{Malod-Dognin}, No{\"e}l and Petschnigg, Julia and Pr{\v z}ulj, Nata{\v s}a},
  year = {2018},
  month = feb,
  volume = {7},
  pages = {1--7},
  issn = {24523100},
  doi = {10.1016/j.coisb.2017.10.003},
  abstract = {Precision medicine proposes to individualize the practice of medicine based on patients' genetic backgrounds, their biomarker characteristics and other omics datasets. After outlining the key challenges in precision medicine, namely patient stratification, biomarker discovery and drug repurposing, we survey recent developments in high-throughput technologies and big biological datasets that shape the future of precision medicine. Furthermore, we provide an overview of recent data-integrative approaches that have been successfully used in precision medicine for mining medical knowledge from big-biological data, and we highlight modeling and computing issues that such integrative approaches will face due to the ever-growing nature of big-biological data. Finally, we raise attention to the challenges in translational medicine when moving from research findings to approved medical practices.},
  file = {/Users/yuekai/Documents/zotero/Malod-Dognin et al (2018) - Precision medicine ― A promising, yet challenging road lies ahead.pdf},
  journal = {Current Opinion in Systems Biology},
  language = {en}
}

@article{manski1988Identification,
  title = {Identification of {{Binary Response Models}}},
  author = {Manski, Charles F.},
  year = {1988},
  volume = {83},
  pages = {729--738},
  issn = {0162-1459},
  doi = {10.2307/2289298},
  abstract = {This article studies identification of the threshold-crossing model of binary response. Most research on binary response has considered specific estimators and tests. The study of identification exposes the foundations of binary response analysis by making explicit the assumptions needed to justify different methods. It also clarifies the connections between reduced-form and structural analyses of binary response data. Assume that the binary outcome z is determined by an observable random vector x and by an unobservable scalar u through a model z = 1[ x{$\beta$} + u {$\geq$} 0]. Also assume that F\textsubscript{u{$\mid$} x}, the probability distribution of u conditional on x, is continuous and strictly increasing. Given these maintained assumptions, we investigate the identifiability of {$\beta$} given the following restrictions on the distributions (F\textsubscript{u{$\mid$} x}, x {$\in$} X): mean independence, quantile independence, index sufficiency, statistical independence, and statistical independence with the distribution known. We find that mean independence has no identifying power. On the other hand, quantile independence implies that {$\beta$} is identified up to scale, provided that the distribution of x has sufficiently rich support. Index sufficiency can identify the slope components of {$\beta$} up to scale and sign, again provided that the distribution of x has a rich support. Statistical independence subsumes both quantile independence and index sufficiency and so implies all of the positive findings previously reported. If u is statistically independent of x with the distribution known, identification requires only that the distribution of x have full rank.},
  journal = {Journal of the American Statistical Association},
  number = {403}
}

@article{manski1989Estimation,
  title = {Estimation of Best Predictors of Binary Response},
  author = {Manski, Charles F. and Thompson, T.Scott},
  year = {1989},
  month = jan,
  volume = {40},
  pages = {97--123},
  issn = {03044076},
  doi = {10.1016/0304-4076(89)90032-8},
  file = {/Users/yuekai/Documents/zotero/Manski, Thompson (1989) - Estimation of best predictors of binary response.pdf},
  journal = {Journal of Econometrics},
  language = {en},
  number = {1}
}

@article{mansour2009Domain,
  title = {Domain {{Adaptation}}: {{Learning Bounds}} and {{Algorithms}}},
  shorttitle = {Domain {{Adaptation}}},
  author = {Mansour, Yishay and Mohri, Mehryar and Rostamizadeh, Afshin},
  year = {2009},
  month = feb,
  abstract = {This paper addresses the general problem of domain adaptation which arises in a variety of applications where the distribution of the labeled sample available somewhat differs from that of the test data. Building on previous work by Ben-David et al. (2007), we introduce a novel distance between distributions, discrepancy distance, that is tailored to adaptation problems with arbitrary loss functions. We give Rademacher complexity bounds for estimating the discrepancy distance from finite samples for different loss functions. Using this distance, we derive novel generalization bounds for domain adaptation for a wide family of loss functions. We also present a series of novel adaptation bounds for large classes of regularization-based algorithms, including support vector machines and kernel ridge regression based on the empirical discrepancy. This motivates our analysis of the problem of minimizing the empirical discrepancy for various loss functions for which we also give novel algorithms. We report the results of preliminary experiments that demonstrate the benefits of our discrepancy minimization algorithms for domain adaptation.},
  archivePrefix = {arXiv},
  eprint = {0902.3430},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mansour et al (2009) - Domain Adaptation.pdf},
  journal = {arXiv:0902.3430 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{mansour2020Three,
  title = {Three {{Approaches}} for {{Personalization}} with {{Applications}} to {{Federated Learning}}},
  author = {Mansour, Yishay and Mohri, Mehryar and Ro, Jae and Suresh, Ananda Theertha},
  year = {2020},
  month = feb,
  abstract = {The standard objective in machine learning is to train a single model for all users. However, in many learning scenarios, such as cloud computing and federated learning, it is possible to learn one personalized model per user. In this work, we present a systematic learning-theoretic study of personalization. We propose and analyze three approaches: user clustering, data interpolation, and model interpolation. For all three approaches, we provide learning-theoretic guarantees and efficient algorithms for which we also demonstrate the performance empirically. All of our algorithms are model agnostic and work for any hypothesis class.},
  archivePrefix = {arXiv},
  eprint = {2002.10619},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mansour et al (2020) - Three Approaches for Personalization with Applications to Federated Learning.pdf},
  journal = {arXiv:2002.10619 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{manzini2019Black,
  title = {Black Is to {{Criminal}} as {{Caucasian}} Is to {{Police}}:{{Detecting}} and {{Removing Multiclass Bias}} in {{Word Embeddings}}},
  shorttitle = {Black Is to {{Criminal}} as {{Caucasian}} Is to {{Police}}},
  author = {Manzini, Thomas and Lim, Yao Chong and Tsvetkov, Yulia and Black, Alan W.},
  year = {2019},
  month = apr,
  abstract = {Online texts -- across genres, registers, domains, and styles -- are riddled with human stereotypes, expressed in overt or subtle ways. Word embeddings, trained on these texts, perpetuate and amplify these stereotypes, and propagate biases to machine learning models that use word embeddings as features. In this work, we propose a method to debias word embeddings in multiclass settings such as race and religion, extending the work of (Bolukbasi et al., 2016) from the binary setting, such as binary gender. Next, we propose a novel methodology for the evaluation of multiclass debiasing. We demonstrate that our multiclass debiasing is robust and maintains the efficacy in standard NLP tasks.},
  archivePrefix = {arXiv},
  eprint = {1904.04047},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Manzini et al (2019) - Black is to Criminal as Caucasian is to Police.pdf},
  journal = {arXiv:1904.04047 [cs, stat]},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{marda2020Data,
  title = {Data in {{New Delhi}}'s Predictive Policing System},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Marda, Vidushi and Narayan, Shivangi},
  year = {2020},
  month = jan,
  pages = {317--324},
  publisher = {{ACM}},
  address = {{Barcelona Spain}},
  doi = {10.1145/3351095.3372865},
  abstract = {In 2015, Delhi Police announced plans for predictive policing. The Crime Mapping, Analytics and Predictive System (CMAPS) would be implemented in India's capital, for live spatial hotspot mapping of crime, criminal behavior patterns and suspect analysis. Four years later, there is little known about the effect of CMAPS due to the lack of public accountability mechanisms and large exceptions for law enforcement under India's Right to Information Act. Through an ethnographic study of Delhi Police's data collection practices, and analysing the institutional and legal reality within which CMAPS will function, this paper presents one of the first accounts of smart policing in India. Through our findings and discussion we show what kinds of biases are present within Delhi Police's data collection practices currently and how they translate and transfer into initiatives like CMAPS. We further discuss what the biases in CMAPS can teach us about future public sector deployment of socio-technical systems in India and other global South geographies. We also offer methodological considerations for studying AI deployments in non-western contexts. We conclude with a set of recommendations for civil society and social justice actors to consider when engaging with opaque systems implemented in the public sector.},
  file = {/Users/yuekai/Documents/zotero/Marda, Narayan (2020) - Data in New Delhi's predictive policing system.pdf},
  isbn = {978-1-4503-6936-7},
  language = {en}
}

@article{martinez2019Fairness,
  title = {Fairness {{With Minimal Harm}}: {{A Pareto}}-{{Optimal Approach For Healthcare}}},
  shorttitle = {Fairness {{With Minimal Harm}}},
  author = {Martinez, Natalia and Bertran, Martin and Sapiro, Guillermo},
  year = {2019},
  month = nov,
  abstract = {Common fairness definitions in machine learning focus on balancing notions of disparity and utility. In this work, we study fairness in the context of risk disparity among sub-populations. We are interested in learning models that minimize performance discrepancies across sensitive groups without causing unnecessary harm. This is relevant to high-stakes domains such as healthcare, where non-maleficence is a core principle. We formalize this objective using Pareto frontiers, and provide analysis, based on recent works in fairness, to exemplify scenarios were perfect fairness might not be feasible without doing unnecessary harm. We present a methodology for training neural networks that achieve our goal by dynamically re-balancing subgroups risks. We argue that even in domains where fairness at cost is required, finding a non-unnecessary-harm fairness model is the optimal initial step. We demonstrate this methodology on real case-studies of predicting ICU patient mortality, and classifying skin lesions from dermatoscopic images.},
  archivePrefix = {arXiv},
  eprint = {1911.06935},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Martinez et al (2019) - Fairness With Minimal Harm.pdf},
  journal = {arXiv:1911.06935 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{marx2019Disentangling,
  title = {Disentangling {{Influence}}: {{Using Disentangled Representations}} to {{Audit Model Predictions}}},
  shorttitle = {Disentangling {{Influence}}},
  author = {Marx, Charles T. and Phillips, Richard Lanas and Friedler, Sorelle A. and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  year = {2019},
  month = jun,
  abstract = {Motivated by the need to audit complex and black box models, there has been extensive research on quantifying how data features influence model predictions. Feature influence can be direct (a direct influence on model outcomes) and indirect (model outcomes are influenced via proxy features). Feature influence can also be expressed in aggregate over the training or test data or locally with respect to a single point. Current research has typically focused on one of each of these dimensions. In this paper, we develop disentangled influence audits, a procedure to audit the indirect influence of features. Specifically, we show that disentangled representations provide a mechanism to identify proxy features in the dataset, while allowing an explicit computation of feature influence on either individual outcomes or aggregate-level outcomes. We show through both theory and experiments that disentangled influence audits can both detect proxy features and show, for each individual or in aggregate, which of these proxy features affects the classifier being audited the most. In this respect, our method is more powerful than existing methods for ascertaining feature influence.},
  archivePrefix = {arXiv},
  eprint = {1906.08652},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Marx et al (2019) - Disentangling Influence.pdf},
  journal = {arXiv:1906.08652 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{mary2019FairnessAware,
  title = {Fairness-{{Aware Learning}} for {{Continuous Attributes}} and {{Treatments}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Mary, Jeremie and Calauz{\`e}nes, Cl{\'e}ment and Karoui, Noureddine El},
  year = {2019},
  month = may,
  pages = {4382--4391},
  abstract = {We address the problem of algorithmic fairness: ensuring that the outcome of a classifier is not biased towards certain values of sensitive variables such as age, race or gender. As common fairness...},
  file = {/Users/yuekai/Documents/zotero/Mary et al (2019) - Fairness-Aware Learning for Continuous Attributes and Treatments.pdf},
  language = {en}
}

@incollection{mason2000Boosting,
  title = {Boosting {{Algorithms}} as {{Gradient Descent}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 12},
  author = {Mason, Llew and Baxter, Jonathan and Bartlett, Peter L. and Frean, Marcus R.},
  editor = {Solla, S. A. and Leen, T. K. and M{\"u}ller, K.},
  year = {2000},
  pages = {512--518},
  publisher = {{MIT Press}},
  file = {/Users/yuekai/Documents/zotero/Mason et al (2000) - Boosting Algorithms as Gradient Descent.pdf}
}

@article{maurer2016Benefit,
  title = {The {{Benefit}} of {{Multitask Representation Learning}}},
  author = {Maurer, Andreas and Pontil, Massimiliano and {Romera-Paredes}, Bernardino},
  year = {2016},
  volume = {17},
  pages = {1--32},
  issn = {1533-7928},
  file = {/Users/yuekai/Documents/zotero/Maurer et al (2016) - The Benefit of Multitask Representation Learning.pdf},
  journal = {Journal of Machine Learning Research},
  number = {81}
}

@article{maurer2016benefit,
  title = {The Benefit of Multitask Representation Learning},
  author = {Maurer, Andreas and Pontil, Massimiliano and {Romera-Paredes}, Bernardino},
  year = {2016},
  month = jan,
  volume = {17},
  pages = {2853--2884},
  issn = {1532-4435},
  abstract = {We discuss a general method to learn data representations from multiple tasks. We provide a justification for this method in both settings of multitask learning and learning-to-learn. The method is illustrated in detail in the special case of linear feature learning. Conditions on the theoretical advantage offered by multitask representation learning over independent task learning are established. In particular, focusing on the important example of half-space learning, we derive the regime in which multitask representation learning is beneficial over independent task learning, as a function of the sample size, the number of tasks and the intrinsic data dimensionality. Other potential applications of our results include multitask feature learning in reproducing kernel Hilbert spaces and multilayer, deep networks.},
  file = {/Users/yuekai/Documents/zotero/Maurer et al (2016) - The benefit of multitask representation learning2.pdf},
  journal = {The Journal of Machine Learning Research},
  keywords = {learning-to-learn,multitask learning,representation learning,statistical learning theory,transfer learning},
  number = {1}
}

@article{may2019Measuring,
  title = {On {{Measuring Social Biases}} in {{Sentence Encoders}}},
  author = {May, Chandler and Wang, Alex and Bordia, Shikha and Bowman, Samuel R. and Rudinger, Rachel},
  year = {2019},
  month = mar,
  abstract = {The Word Embedding Association Test shows that GloVe and word2vec word embeddings exhibit human-like implicit biases based on gender, race, and other social constructs (Caliskan et al., 2017). Meanwhile, research on learning reusable text representations has begun to explore sentence-level texts, with some sentence encoders seeing enthusiastic adoption. Accordingly, we extend the Word Embedding Association Test to measure bias in sentence encoders. We then test several sentence encoders, including state-of-the-art methods such as ELMo and BERT, for the social biases studied in prior work and two important biases that are difficult or impossible to test at the word level. We observe mixed results including suspicious patterns of sensitivity that suggest the test's assumptions may not hold in general. We conclude by proposing directions for future work on measuring bias in sentence encoders.},
  archivePrefix = {arXiv},
  eprint = {1903.10561},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/May et al (2019) - On Measuring Social Biases in Sentence Encoders.pdf},
  journal = {arXiv:1903.10561 [cs]},
  keywords = {Computer Science - Computation and Language,Computer Science - Computers and Society},
  primaryClass = {cs}
}

@phdthesis{mccoy2013geometric,
  title = {A Geometric Analysis of Convex Demixing},
  author = {McCoy, Michael Brian},
  year = {2013},
  abstract = {{$<$}p{$>$}Demixing is the task of identifying multiple signals given only their sum and prior information about their structures.  Examples of demixing problems include (i) separating a signal that is sparse with respect to one basis from a signal that is sparse with respect to a second basis; (ii) decomposing an observed matrix into low-rank and sparse components; and (iii) identifying a binary codeword with impulsive corruptions.  This thesis describes and analyzes a convex optimization framework for solving an array of demixing problems.{$<$}/p{$>$}
  
{$<$}p{$>$}Our framework includes a random orientation model for the constituent signals that ensures the structures are incoherent.  This work introduces a summary parameter, the statistical dimension, that reflects the intrinsic complexity of a signal.  The main result indicates that the difficulty of demixing under this random model depends only on the total complexity of the constituent signals involved: demixing succeeds with high probability when the sum of the complexities is less than the ambient dimension; otherwise, it fails with high probability.{$<$}/p{$>$}

{$<$}p{$>$}The fact that a phase transition between success and failure occurs in demixing is a consequence of a new inequality in conic integral geometry. Roughly speaking, this inequality asserts that a convex cone behaves like a subspace whose dimension is equal to the statistical dimension of the cone. When combined with a geometric optimality condition for demixing, this inequality provides precise quantitative information about the phase transition, including the location and width of the transition region.{$<$}/p{$>$}},
  file = {/Users/yuekai/Documents/zotero/McCoy (2013) - A geometric analysis of convex demixing.pdf},
  school = {California Institute of Technology},
  type = {Phd}
}

@article{mcduff2019Characterizing,
  title = {Characterizing {{Bias}} in {{Classifiers}} Using {{Generative Models}}},
  author = {McDuff, Daniel and Ma, Shuang and Song, Yale and Kapoor, Ashish},
  year = {2019},
  month = may,
  abstract = {Models that are learned from real-world data are often biased because the data used to train them is biased. This can propagate systemic human biases that exist and ultimately lead to inequitable treatment of people, especially minorities. To characterize bias in learned classifiers, existing approaches rely on human oracles labeling real-world examples to identify the "blind spots" of the classifiers; these are ultimately limited due to the human labor required and the finite nature of existing image examples. We propose a simulation-based approach for interrogating classifiers using generative adversarial models in a systematic manner. We incorporate a progressive conditional generative model for synthesizing photo-realistic facial images and Bayesian Optimization for an efficient interrogation of independent facial image classification systems. We show how this approach can be used to efficiently characterize racial and gender biases in commercial systems.},
  archivePrefix = {arXiv},
  eprint = {1906.11891},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/McDuff et al (2019) - Characterizing Bias in Classifiers using Generative Models.pdf},
  journal = {arXiv:1906.11891 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryClass = {cs}
}

@article{mcmahan2016CommunicationEfficient,
  title = {Communication-{{Efficient Learning}} of {{Deep Networks}} from {{Decentralized Data}}},
  author = {McMahan, H. Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Ag{\"u}era},
  year = {2016},
  month = feb,
  abstract = {Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches. We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning. We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10-100x as compared to synchronized stochastic gradient descent.},
  archivePrefix = {arXiv},
  eprint = {1602.05629},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/McMahan et al (2016) - Communication-Efficient Learning of Deep Networks from Decentralized Data.pdf},
  journal = {arXiv:1602.05629 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{mehrabi2020Statistical,
  title = {Statistical {{Equity}}: {{A Fairness Classification Objective}}},
  shorttitle = {Statistical {{Equity}}},
  author = {Mehrabi, Ninareh and Huang, Yuzhong and Morstatter, Fred},
  year = {2020},
  month = may,
  abstract = {Machine learning systems have been shown to propagate the societal errors of the past. In light of this, a wealth of research focuses on designing solutions that are "fair." Even with this abundance of work, there is no singular definition of fairness, mainly because fairness is subjective and context dependent. We propose a new fairness definition, motivated by the principle of equity, that considers existing biases in the data and attempts to make equitable decisions that account for these previous historical biases. We formalize our definition of fairness, and motivate it with its appropriate contexts. Next, we operationalize it for equitable classification. We perform multiple automatic and human evaluations to show the effectiveness of our definition and demonstrate its utility for aspects of fairness, such as the feedback loop.},
  archivePrefix = {arXiv},
  eprint = {2005.07293},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mehrabi et al (2020) - Statistical Equity.pdf},
  journal = {arXiv:2005.07293 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{mei2017Neural,
  title = {The {{Neural Hawkes Process}}: {{A Neurally Self}}-{{Modulating Multivariate Point Process}}},
  shorttitle = {The {{Neural Hawkes Process}}},
  author = {Mei, Hongyuan and Eisner, Jason},
  year = {2017},
  month = nov,
  abstract = {Many events occur in the world. Some event types are stochastically excited or inhibited---in the sense of having their probabilities elevated or decreased---by patterns in the sequence of previous events. Discovering such patterns can help us predict which type of event will happen next and when. We model streams of discrete events in continuous time, by constructing a neurally self-modulating multivariate point process in which the intensities of multiple event types evolve according to a novel continuous-time LSTM. This generative model allows past events to influence the future in complex and realistic ways, by conditioning future event intensities on the hidden state of a recurrent neural network that has consumed the stream of past events. Our model has desirable qualitative properties. It achieves competitive likelihood and predictive accuracy on real and synthetic datasets, including under missing-data conditions.},
  archivePrefix = {arXiv},
  eprint = {1612.09328},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mei, Eisner (2017) - The Neural Hawkes Process.pdf},
  journal = {arXiv:1612.09328 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{mei2018Mean,
  title = {A {{Mean Field View}} of the {{Landscape}} of {{Two}}-{{Layers Neural Networks}}},
  author = {Mei, Song and Montanari, Andrea and Nguyen, Phan-Minh},
  year = {2018},
  month = aug,
  abstract = {Multi-layer neural networks are among the most powerful models in machine learning, yet the fundamental reasons for this success defy mathematical understanding. Learning a neural network requires to optimize a non-convex high-dimensional objective (risk function), a problem which is usually attacked using stochastic gradient descent (SGD). Does SGD converge to a global optimum of the risk or only to a local optimum? In the first case, does this happen because local minima are absent, or because SGD somehow avoids them? In the second, why do local minima reached by SGD have good generalization properties? In this paper we consider a simple case, namely two-layers neural networks, and prove that -in a suitable scaling limit- SGD dynamics is captured by a certain non-linear partial differential equation (PDE) that we call distributional dynamics (DD). We then consider several specific examples, and show how DD can be used to prove convergence of SGD to networks with nearly ideal generalization error. This description allows to 'average-out' some of the complexities of the landscape of neural networks, and can be used to prove a general convergence result for noisy SGD.},
  archivePrefix = {arXiv},
  eprint = {1804.06561},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mei et al (2018) - A Mean Field View of the Landscape of Two-Layers Neural Networks.pdf},
  journal = {arXiv:1804.06561 [cond-mat, stat]},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Statistical Mechanics,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cond-mat, stat}
}

@article{mei2019generalization,
  title = {The Generalization Error of Random Features Regression: {{Precise}} Asymptotics and Double Descent Curve},
  shorttitle = {The Generalization Error of Random Features Regression},
  author = {Mei, Song and Montanari, Andrea},
  year = {2019},
  month = aug,
  abstract = {Deep learning methods operate in regimes that defy the traditional statistical mindset. The neural network architectures often contain more parameters than training samples, and are so rich that they can interpolate the observed labels, even if the latter are replaced by pure noise. Despite their huge complexity, the same architectures achieve small generalization error on real data. This phenomenon has been rationalized in terms of a so-called `double descent' curve. As the model complexity increases, the generalization error follows the usual U-shaped curve at the beginning, first decreasing and then peaking around the interpolation threshold (when the model achieves vanishing training error). However, it descends again as model complexity exceeds this threshold. The global minimum of the generalization error is found in this overparametrized regime, often when the number of parameters is much larger than the number of samples. Far from being a peculiar property of deep neural networks, elements of this behavior have been demonstrated in much simpler settings, including linear regression with random covariates. In this paper we consider the problem of learning an unknown function over the \$d\$-dimensional sphere \$\textbackslash mathbb S\^\{d-1\}\$, from \$n\$ i.i.d. samples \$(\textbackslash boldsymbol x\_i, y\_i) \textbackslash in \textbackslash mathbb S\^\{d-1\} \textbackslash times \textbackslash mathbb R\$, \$i \textbackslash le n\$. We perform ridge regression on \$N\$ random features of the form \$\textbackslash sigma(\textbackslash boldsymbol w\_a\^\{\textbackslash mathsf T\}\textbackslash boldsymbol x)\$, \$a \textbackslash le N\$. This can be equivalently described as a two-layers neural network with random first-layer weights. We compute the precise asymptotics of the generalization error, in the limit \$N, n, d \textbackslash to \textbackslash infty\$ with \$N/d\$ and \$n/d\$ fixed. This provides the first analytically tractable model that captures all the features of the double descent phenomenon.},
  archivePrefix = {arXiv},
  eprint = {1908.05355},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mei, Montanari (2019) - The generalization error of random features regression.pdf},
  journal = {arXiv:1908.05355 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {math, stat}
}

@inproceedings{menon2018cost,
  title = {The Cost of Fairness in Binary Classification},
  booktitle = {Conference on {{Fairness}}, {{Accountability}} and {{Transparency}}},
  author = {Menon, Aditya Krishna and Williamson, Robert C.},
  year = {2018},
  month = jan,
  pages = {107--118},
  issn = {1938-7228},
  abstract = {Binary classifiers are often required to possess fairness in the sense of not overly discriminating with respect to a feature deemed sensitive e.g. race. We study the inherent tradeoffs in learning...},
  chapter = {Machine Learning},
  file = {/Users/yuekai/Documents/zotero/Menon, Williamson (2018) - The cost of fairness in binary classification.pdf},
  language = {en}
}

@article{mertikopoulos2018Optimistic,
  title = {Optimistic Mirror Descent in Saddle-Point Problems: {{Going}} the Extra (Gradient) Mile},
  shorttitle = {Optimistic Mirror Descent in Saddle-Point Problems},
  author = {Mertikopoulos, Panayotis and Lecouat, Bruno and Zenati, Houssam and Foo, Chuan-Sheng and Chandrasekhar, Vijay and Piliouras, Georgios},
  year = {2018},
  month = jul,
  abstract = {Owing to their connection with generative adversarial networks (GANs), saddle-point problems have recently attracted considerable interest in machine learning and beyond. By necessity, most theoretical guarantees revolve around convex-concave (or even linear) problems; however, making theoretical inroads towards efficient GAN training depends crucially on moving beyond this classic framework. To make piecemeal progress along these lines, we analyze the behavior of mirror descent (MD) in a class of non-monotone problems whose solutions coincide with those of a naturally associated variational inequality - a property which we call coherence. We first show that ordinary, "vanilla" MD converges under a strict version of this condition, but not otherwise; in particular, it may fail to converge even in bilinear models with a unique solution. We then show that this deficiency is mitigated by optimism: by taking an "extra-gradient" step, optimistic mirror descent (OMD) converges in all coherent problems. Our analysis generalizes and extends the results of Daskalakis et al. (2018) for optimistic gradient descent (OGD) in bilinear problems, and makes concrete headway for establishing convergence beyond convex-concave games. We also provide stochastic analogues of these results, and we validate our analysis by numerical experiments in a wide array of GAN models (including Gaussian mixture models, as well as the CelebA and CIFAR-10 datasets).},
  archivePrefix = {arXiv},
  eprint = {1807.02629},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mertikopoulos et al (2018) - Optimistic mirror descent in saddle-point problems.pdf},
  journal = {arXiv:1807.02629 [cs, math, stat]},
  keywords = {Computer Science - Computer Science and Game Theory,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{metz2020Algorithm,
  title = {An {{Algorithm That Grants Freedom}}, or {{Takes It Away}}},
  author = {Metz, Cade and Satariano, Adam},
  year = {2020},
  month = feb,
  issn = {0362-4331},
  abstract = {Across the United States and Europe, software is making probation decisions and predicting whether teens will commit crime. Opponents want more human oversight.},
  chapter = {Technology},
  journal = {The New York Times},
  language = {en-US}
}

@article{metzen2017Detecting,
  title = {On {{Detecting Adversarial Perturbations}}},
  author = {Metzen, Jan Hendrik and Genewein, Tim and Fischer, Volker and Bischoff, Bastian},
  year = {2017},
  month = feb,
  abstract = {Machine learning and deep learning in particular has advanced tremendously on perceptual tasks in recent years. However, it remains vulnerable against adversarial perturbations of the input that have been crafted specifically to fool the system while being quasi-imperceptible to a human. In this work, we propose to augment deep neural networks with a small "detector" subnetwork which is trained on the binary classification task of distinguishing genuine data from data containing adversarial perturbations. Our method is orthogonal to prior work on addressing adversarial perturbations, which has mostly focused on making the classification network itself more robust. We show empirically that adversarial perturbations can be detected surprisingly well even though they are quasi-imperceptible to humans. Moreover, while the detectors have been trained to detect only a specific adversary, they generalize to similar and weaker adversaries. In addition, we propose an adversarial attack that fools both the classifier and the detector and a novel training procedure for the detector that counteracts this attack.},
  archivePrefix = {arXiv},
  eprint = {1702.04267},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Metzen et al (2017) - On Detecting Adversarial Perturbations.pdf},
  journal = {arXiv:1702.04267 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{middlebrook1992Methods,
  title = {Methods of Design-Oriented Analysis: {{The}} Quadratic Equation Revisited},
  booktitle = {Proc. {{IEEE Frontiers}} in {{Education}}, {{Twenty}}-{{Second Annual Conference}}},
  author = {Middlebrook, Robert},
  year = {1992},
  month = nov,
  address = {{Vanderbilt University}},
  file = {/Users/yuekai/Documents/zotero/Middlebrook (1992) - Methods of design-oriented analysis.pdf}
}

@incollection{mikolov2013Distributed,
  title = {Distributed {{Representations}} of {{Words}} and {{Phrases}} and Their {{Compositionality}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 26},
  author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  editor = {Burges, C. J. C. and Bottou, L. and Welling, M. and Ghahramani, Z. and Weinberger, K. Q.},
  year = {2013},
  pages = {3111--3119},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/yuekai/Documents/zotero/Mikolov et al (2013) - Distributed Representations of Words and Phrases and their Compositionality.pdf}
}

@article{minsker2014Active,
  title = {Active {{Clinical Trials}} for {{Personalized Medicine}}},
  author = {Minsker, Stanislav and Zhao, Ying-Qi and Cheng, Guang},
  year = {2014},
  month = apr,
  abstract = {Individualized treatment rules (ITRs) tailor treatments according to individual patient characteristics. They can significantly improve patient care and are thus becoming increasingly popular. The data collected during randomized clinical trials are often used to estimate the optimal ITRs. However, these trials are generally expensive to run, and, moreover, they are not designed to efficiently estimate ITRs. In this paper, we propose a cost-effective estimation method from an active learning perspective. In particular, our method recruits only the "most informative" patients (in terms of learning the optimal ITRs) from an ongoing clinical trial. Simulation studies and real-data examples show that our active clinical trial method significantly improves on competing methods. We derive risk bounds and show that they support these observed empirical advantages.},
  archivePrefix = {arXiv},
  eprint = {1404.2971},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Minsker et al (2014) - Active Clinical Trials for Personalized Medicine.pdf},
  journal = {arXiv:1404.2971 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{mirza2014Conditional,
  title = {Conditional {{Generative Adversarial Nets}}},
  author = {Mirza, Mehdi and Osindero, Simon},
  year = {2014},
  month = nov,
  abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.},
  archivePrefix = {arXiv},
  eprint = {1411.1784},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mirza, Osindero (2014) - Conditional Generative Adversarial Nets.pdf},
  journal = {arXiv:1411.1784 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{mishchenko2019Revisiting,
  title = {Revisiting {{Stochastic Extragradient}}},
  author = {Mishchenko, Konstantin and Kovalev, Dmitry and Shulgin, Egor and Richt{\'a}rik, Peter and Malitsky, Yura},
  year = {2019},
  month = may,
  abstract = {We consider a new extension of the extragradient method that is motivated by approximating implicit updates. Since in a recent work\textasciitilde\textbackslash cite\{chavdarova2019reducing\} it was shown that the existing stochastic extragradient algorithm (called mirror-prox) of\textasciitilde\textbackslash cite\{juditsky2011solving\} diverges on a simple bilinear problem, we prove guarantees for solving variational inequality that are more general than in\textasciitilde\textbackslash cite\{juditsky2011solving\}. Furthermore, we illustrate numerically that the proposed variant converges faster than many other methods on the example of\textasciitilde\textbackslash cite\{chavdarova2019reducing\}. We also discuss how extragradient can be applied to training Generative Adversarial Networks (GANs). Our experiments on GANs demonstrate that the introduced approach may make the training faster in terms of data passes, while its higher iteration complexity makes the advantage smaller. To further accelerate method's convergence on problems such as bilinear minimax, we combine the extragradient step with negative momentum\textasciitilde\textbackslash cite\{gidel2018negative\} and discuss the optimal momentum value.},
  archivePrefix = {arXiv},
  eprint = {1905.11373},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mishchenko et al (2019) - Revisiting Stochastic Extragradient.pdf},
  journal = {arXiv:1905.11373 [cs, math]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control},
  primaryClass = {cs, math}
}

@techreport{mishkin1991Fisher,
  title = {Is the {{Fisher Effect}} for {{Real}}? {{A Reexamination}} of the {{Relationship Between Inflation}} and {{Interest Rates}}},
  shorttitle = {Is the {{Fisher Effect}} for {{Real}}?},
  author = {Mishkin, Frederic S},
  year = {1991},
  month = feb,
  institution = {{National Bureau of Economic Research}},
  doi = {10.3386/w3632},
  abstract = {The basic puzzle about the so-called Fisher effect, in which movements in short-term interest rates primarily reflect fluctuations in expected inflation, is why a strong Fisher effect occurs only for certain periods but not for others. This paper resolves this puzzle by reexamining the relationship between inflation and interest rates with modern time-series techniques. Recognition that the level of inflation and interest rates may contain stochastic trends suggests that the apparent ability of short-term interest rates to forecast inflation in the postwar United States is spurious. Additional evidence does not support the presence of a short-run Fisher effect but does support the existence of a long-run Fisher effect in which inflation and interest rates trend together in the long run when they exhibit trends. The evidence here can explain why the Fisher effect appears to be strong only for particular sample periods, but not for others. The conclusion that there is a long-run Fisher effect implies that when inflation and interest rates exhibit trends, these two series will trend together and thus there will be a strong correlation between inflation and interest rates. On the other hand, the nonexistence of a short-run Fisher effect implies that when either inflation and interest rates do not display trends, there is no long-run Fisher effect to produce a strong correlation between interest rates and inflation. The analysis in this paper resolves an important puzzle about when the Fisher effect appears in the data.},
  file = {/Users/yuekai/Documents/zotero/Mishkin (1991) - Is the Fisher Effect for Real.pdf},
  number = {3632},
  type = {Working {{Paper}}}
}

@article{mitchell2019PredictionBased,
  title = {Prediction-{{Based Decisions}} and {{Fairness}}: {{A Catalogue}} of {{Choices}}, {{Assumptions}}, and {{Definitions}}},
  shorttitle = {Prediction-{{Based Decisions}} and {{Fairness}}},
  author = {Mitchell, Shira and Potash, Eric and Barocas, Solon and D'Amour, Alexander and Lum, Kristian},
  year = {2019},
  month = jul,
  abstract = {A recent flurry of research activity has attempted to quantitatively define "fairness" for decisions based on statistical and machine learning (ML) predictions. The rapid growth of this new field has led to wildly inconsistent terminology and notation, presenting a serious challenge for cataloguing and comparing definitions. This paper attempts to bring much-needed order. First, we explicate the various choices and assumptions made---often implicitly---to justify the use of prediction-based decisions. Next, we show how such choices and assumptions can raise concerns about fairness and we present a notationally consistent catalogue of fairness definitions from the ML literature. In doing so, we offer a concise reference for thinking through the choices, assumptions, and fairness considerations of prediction-based decision systems.},
  archivePrefix = {arXiv},
  eprint = {1811.07867},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mitchell et al (2019) - Prediction-Based Decisions and Fairness.pdf},
  journal = {arXiv:1811.07867 [stat]},
  keywords = {Statistics - Applications},
  primaryClass = {stat}
}

@article{miyato2015Distributional,
  title = {Distributional {{Smoothing}} with {{Virtual Adversarial Training}}},
  author = {Miyato, Takeru and Maeda, Shin-ichi and Koyama, Masanori and Nakae, Ken and Ishii, Shin},
  year = {2015},
  month = jul,
  abstract = {We propose local distributional smoothness (LDS), a new notion of smoothness for statistical model that can be used as a regularization term to promote the smoothness of the model distribution. We named the LDS based regularization as virtual adversarial training (VAT). The LDS of a model at an input datapoint is defined as the KL-divergence based robustness of the model distribution against local perturbation around the datapoint. VAT resembles adversarial training, but distinguishes itself in that it determines the adversarial direction from the model distribution alone without using the label information, making it applicable to semi-supervised learning. The computational cost for VAT is relatively low. For neural network, the approximated gradient of the LDS can be computed with no more than three pairs of forward and back propagations. When we applied our technique to supervised and semi-supervised learning for the MNIST dataset, it outperformed all the training methods other than the current state of the art method, which is based on a highly advanced generative model. We also applied our method to SVHN and NORB, and confirmed our method's superior performance over the current state of the art semi-supervised method applied to these datasets.},
  archivePrefix = {arXiv},
  eprint = {1507.00677},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Miyato et al (2015) - Distributional Smoothing with Virtual Adversarial Training.pdf},
  journal = {arXiv:1507.00677 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{mizera1994CONSISTENT,
  title = {{{ON CONSISTENT M}}-{{ESTIMATORS}}: {{TUNING CONSTANTS}}, {{UNIMODALITY AND BREAKDOWN}}},
  author = {Mizera, Ivan},
  year = {1994},
  volume = {30},
  pages = {13},
  file = {/Users/yuekai/Documents/zotero/Mizera (1994) - ON CONSISTENT M-ESTIMATORS.pdf},
  journal = {Kybernetika},
  language = {en}
}

@article{mnih2015Humanlevel,
  title = {Human-Level Control through Deep Reinforcement Learning},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  year = {2015},
  month = feb,
  volume = {518},
  pages = {529--533},
  issn = {1476-4687},
  doi = {10.1038/nature14236},
  abstract = {An artificial agent is developed that learns to play\&nbsp;a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a\&nbsp;performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action.},
  copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  journal = {Nature},
  language = {en},
  number = {7540}
}

@article{mohajerinesfahani2018Datadriven,
  title = {Data-Driven Distributionally Robust Optimization Using the {{Wasserstein}} Metric: Performance Guarantees and Tractable Reformulations},
  shorttitle = {Data-Driven Distributionally Robust Optimization Using the {{Wasserstein}} Metric},
  author = {Mohajerin Esfahani, Peyman and Kuhn, Daniel},
  year = {2018},
  month = sep,
  volume = {171},
  pages = {115--166},
  issn = {0025-5610, 1436-4646},
  doi = {10.1007/s10107-017-1172-1},
  abstract = {We consider stochastic programs where the distribution of the uncertain parameters is only observable through a finite training dataset. Using the Wasserstein metric, we construct a ball in the space of (multivariate and non-discrete) probability distributions centered at the uniform distribution on the training samples, and we seek decisions that perform best in view of the worst-case distribution within this Wasserstein ball. The state-of-the-art methods for solving the resulting distributionally robust optimization problems rely on global optimization techniques, which quickly become computationally excruciating. In this paper we demonstrate that, under mild assumptions, the distributionally robust optimization problems over Wasserstein balls can in fact be reformulated as finite convex programs\textemdash in many interesting cases even as tractable linear programs. Leveraging recent measure concentration results, we also show that their solutions enjoy powerful finite-sample performance guarantees. Our theoretical results are exemplified in mean-risk portfolio optimization as well as uncertainty quantification.},
  file = {/Users/yuekai/Documents/zotero/Mohajerin Esfahani, Kuhn (2018) - Data-driven distributionally robust optimization using the Wasserstein metric.pdf},
  journal = {Mathematical Programming},
  language = {en},
  number = {1-2}
}

@article{mohan2013NodeBased,
  title = {Node-{{Based Learning}} of {{Multiple Gaussian Graphical Models}}},
  author = {Mohan, Karthik and London, Palma and Fazel, Maryam and Witten, Daniela and Lee, Su-In},
  year = {2013},
  month = mar,
  abstract = {We consider the problem of estimating high-dimensional Gaussian graphical models corresponding to a single set of variables under several distinct conditions. This problem is motivated by the task of recovering transcriptional regulatory networks on the basis of gene expression data \{containing heterogeneous samples, such as different disease states, multiple species, or different developmental stages\}. We assume that most aspects of the conditional dependence networks are shared, but that there are some structured differences between them. Rather than assuming that similarities and differences between networks are driven by individual edges, we take a node-based approach, which in many cases provides a more intuitive interpretation of the network differences. We consider estimation under two distinct assumptions: (1) differences between the K networks are due to individual nodes that are perturbed across conditions, or (2) similarities among the K networks are due to the presence of common hub nodes that are shared across all K networks. Using a row-column overlap norm penalty function, we formulate two convex optimization problems that correspond to these two assumptions. We solve these problems using an alternating direction method of multipliers algorithm, and we derive a set of necessary and sufficient conditions that allows us to decompose the problem into independent subproblems so that our algorithm can be scaled to high-dimensional settings. Our proposal is illustrated on synthetic data, a webpage data set, and a brain cancer gene expression data set.},
  archivePrefix = {arXiv},
  eprint = {1303.5145},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mohan et al (2013) - Node-Based Learning of Multiple Gaussian Graphical Models.pdf},
  journal = {arXiv:1303.5145 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{mohri2019Agnostic,
  title = {Agnostic {{Federated Learning}}},
  author = {Mohri, Mehryar and Sivek, Gary and Suresh, Ananda Theertha},
  year = {2019},
  month = jan,
  abstract = {A key learning scenario in large-scale applications is that of federated learning, where a centralized model is trained based on data originating from a large number of clients. We argue that, with the existing training and inference, federated models can be biased towards different clients. Instead, we propose a new framework of agnostic federated learning, where the centralized model is optimized for any target distribution formed by a mixture of the client distributions. We further show that this framework naturally yields a notion of fairness. We present data-dependent Rademacher complexity guarantees for learning with this objective, which guide the definition of an algorithm for agnostic federated learning. We also give a fast stochastic optimization algorithm for solving the corresponding optimization problem, for which we prove convergence bounds, assuming a convex loss function and hypothesis set. We further empirically demonstrate the benefits of our approach in several datasets. Beyond federated learning, our framework and algorithm can be of interest to other learning scenarios such as cloud computing, domain adaptation, drifting, and other contexts where the training and test distributions do not coincide.},
  archivePrefix = {arXiv},
  eprint = {1902.00146},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mohri et al (2019) - Agnostic Federated Learning.pdf},
  journal = {arXiv:1902.00146 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{mokhtari2019Unified,
  title = {A {{Unified Analysis}} of {{Extra}}-Gradient and {{Optimistic Gradient Methods}} for {{Saddle Point Problems}}: {{Proximal Point Approach}}},
  shorttitle = {A {{Unified Analysis}} of {{Extra}}-Gradient and {{Optimistic Gradient Methods}} for {{Saddle Point Problems}}},
  author = {Mokhtari, Aryan and Ozdaglar, Asuman and Pattathil, Sarath},
  year = {2019},
  month = jan,
  abstract = {In this paper we consider solving saddle point problems using two variants of Gradient Descent-Ascent algorithms, Extra-gradient (EG) and Optimistic Gradient Descent Ascent (OGDA) methods. We show that both of these algorithms admit a unified analysis as approximations of the classical proximal point method for solving saddle point problems. This viewpoint enables us to develop a new framework for analyzing EG and OGDA for bilinear and strongly convex-strongly concave settings. Moreover, we use the proximal point approximation interpretation to generalize the results for OGDA for a wide range of parameters.},
  archivePrefix = {arXiv},
  eprint = {1901.08511},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mokhtari et al (2019) - A Unified Analysis of Extra-gradient and Optimistic Gradient Methods for Saddle.pdf},
  journal = {arXiv:1901.08511 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@book{monge1781Memoire,
  title = {{M\'emoire sur la th\'eorie des d\'eblais et des remblais}},
  author = {Monge, Gaspard},
  year = {1781},
  publisher = {{De l'Imprimerie Royale}},
  googlebooks = {IG7CGwAACAAJ},
  language = {fr}
}

@article{moosavi-dezfooli2015DeepFool,
  title = {{{DeepFool}}: A Simple and Accurate Method to Fool Deep Neural Networks},
  shorttitle = {{{DeepFool}}},
  author = {{Moosavi-Dezfooli}, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
  year = {2015},
  month = nov,
  abstract = {State-of-the-art deep neural networks have achieved impressive results on many image classification tasks. However, these same architectures have been shown to be unstable to small, well sought, perturbations of the images. Despite the importance of this phenomenon, no effective methods have been proposed to accurately compute the robustness of state-of-the-art deep classifiers to such perturbations on large-scale datasets. In this paper, we fill this gap and propose the DeepFool algorithm to efficiently compute perturbations that fool deep networks, and thus reliably quantify the robustness of these classifiers. Extensive experimental results show that our approach outperforms recent methods in the task of computing adversarial perturbations and making classifiers more robust.},
  archivePrefix = {arXiv},
  eprint = {1511.04599},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Moosavi-Dezfooli et al (2015) - DeepFool.pdf},
  journal = {arXiv:1511.04599 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{moro2003Affirmative,
  title = {Affirmative Action in a Competitive Economy},
  author = {Moro, Andrea and Norman, Peter},
  year = {2003},
  month = mar,
  volume = {87},
  pages = {567--594},
  issn = {00472727},
  doi = {10.1016/S0047-2727(01)00121-9},
  abstract = {We consider a model of endogenous human capital formation with competitively determined wages. Discrimination is sustainable in equilibrium in the presence of two distinguishable, but ex ante identical groups of workers. An affirmative action policy consisting of a quota may `fail' in the sense that there still may be equilibria where groups are treated differently. However, the incentives to invest for agents in the discriminated group are improved by affirmative action if the initial equilibrium is the most discriminatory equilibrium in the model without the policy. The welfare effects are ambiguous. It is possible that the policy makes the intended beneficiaries worse off: even if the starting point is the most discriminatory equilibrium the expected payoff may decrease for all agents in the target group.},
  file = {/Users/yuekai/Documents/zotero/Moro, Norman (2003) - Affirmative action in a competitive economy.pdf},
  journal = {Journal of Public Economics},
  language = {en},
  number = {3-4}
}

@article{moro2004general,
  title = {A General Equilibrium Model of Statistical Discrimination},
  author = {Moro, Andrea and Norman, Peter},
  year = {2004},
  month = jan,
  volume = {114},
  pages = {1--30},
  issn = {00220531},
  doi = {10.1016/S0022-0531(03)00165-0},
  abstract = {We study a general equilibrium model with endogenous human capital formation in which ex ante identical groups may be treated asymmetrically in equilibrium. The interaction between an informational externality and general equilibrium effects creates incentives for groups to specialize. Discrimination may arise even if the corresponding model with a single group has a unique equilibrium. The dominant group gains from discrimination, rationalizing why a majority may be reluctant to eliminate discrimination. The model is also consistent with ``reverse discrimination'' as a remedy against discrimination since it may be necessary to decrease the welfare of the dominant group to achieve parity.},
  file = {/Users/yuekai/Documents/zotero/Moro, Norman (2004) - A general equilibrium model of statistical discrimination.pdf},
  journal = {Journal of Economic Theory},
  language = {en},
  number = {1}
}

@article{morris1983Parametric,
  title = {Parametric {{Empirical Bayes Inference}}: {{Theory}} and {{Applications}}},
  shorttitle = {Parametric {{Empirical Bayes Inference}}},
  author = {Morris, Carl N.},
  year = {1983},
  month = mar,
  volume = {78},
  pages = {47--55},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.1983.10477920},
  file = {/Users/yuekai/Documents/zotero/Morris (1983) - Parametric Empirical Bayes Inference.pdf},
  journal = {Journal of the American Statistical Association},
  language = {en},
  number = {381}
}

@article{moslehian2005Survey,
  title = {A {{Survey}} on the {{Complemented Subspace Problem}}},
  author = {Moslehian, Mohammad Sal},
  year = {2005},
  month = jan,
  abstract = {The complemented subspace problem asks, in general, which closed subspaces \$M\$ of a Banach space \$X\$ are complemented; i.e. there exists a closed subspace \$N\$ of \$X\$ such that \$X=M\textbackslash oplus N\$? This problem is in the heart of the theory of Banach spaces and plays a key role in the development of the Banach space theory. Our aim is to investigate some results on complemented subspaces, to give a history of the subject, and to present some open problems.},
  archivePrefix = {arXiv},
  eprint = {math/0501048},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Moslehian (2005) - A Survey on the Complemented Subspace Problem.pdf},
  journal = {arXiv:math/0501048},
  keywords = {Mathematics - Functional Analysis}
}

@article{mossel2017Opinion,
  title = {Opinion {{Exchange Dynamics}}},
  author = {Mossel, Elchanan and Tamuz, Omer},
  year = {2017},
  volume = {14},
  pages = {155--204},
  issn = {1549-5787},
  doi = {10.1214/14-PS230},
  abstract = {We survey a range of models of opinion exchange. From the introduction: "The exchange of opinions between individuals is a fundamental social interaction... Moreover, many models in this field are an excellent playground for mathematicians, especially those working in probability, algorithms and combinatorics. The goal of this survey is to introduce such models to mathematicians, and especially to those working in discrete mathematics, information theory, optimization, probability and statistics."},
  archivePrefix = {arXiv},
  eprint = {1401.4770},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mossel, Tamuz (2017) - Opinion Exchange Dynamics.pdf},
  journal = {Probability Surveys},
  keywords = {Computer Science - Computer Science and Game Theory,Mathematics - Probability},
  number = {0}
}

@article{moutafis2017Overview,
  title = {An {{Overview}} and {{Empirical Comparison}} of {{Distance Metric Learning Methods}}},
  author = {Moutafis, P. and Leng, M. and Kakadiaris, I. A.},
  year = {2017},
  month = mar,
  volume = {47},
  pages = {612--625},
  issn = {2168-2267},
  doi = {10.1109/TCYB.2016.2521767},
  abstract = {In this paper, we first offer an overview of advances in the field of distance metric learning. Then, we empirically compare selected methods using a common experimental protocol. The number of distance metric learning algorithms proposed keeps growing due to their effectiveness and wide application. However, existing surveys are either outdated or they focus only on a few methods. As a result, there is an increasing need to summarize the obtained knowledge in a concise, yet informative manner. Moreover, existing surveys do not conduct comprehensive experimental comparisons. On the other hand, individual distance metric learning papers compare the performance of the proposed approach with only a few related methods and under different settings. This highlights the need for an experimental evaluation using a common and challenging protocol. To this end, we conduct face verification experiments, as this task poses significant challenges due to varying conditions during data acquisition. In addition, face verification is a natural application for distance metric learning because the encountered challenge is to define a distance function that: 1) accurately expresses the notion of similarity for verification; 2) is robust to noisy data; 3) generalizes well to unseen subjects; and 4) scales well with the dimensionality and number of training samples. In particular, we utilize well-tested features to assess the performance of selected methods following the experimental protocol of the state-of-the-art database labeled faces in the wild. A summary of the results is presented along with a discussion of the insights obtained and lessons learned by employing the corresponding algorithms.},
  file = {/Users/yuekai/Documents/zotero/Moutafis et al (2017) - An Overview and Empirical Comparison of Distance Metric Learning Methods.pdf;/Users/yuekai/Zotero/storage/V5A96MSF/7407637.html},
  journal = {IEEE Transactions on Cybernetics},
  number = {3}
}

@article{mouzannar2018Fair,
  title = {From {{Fair Decision Making}} to {{Social Equality}}},
  author = {Mouzannar, Hussein and Ohannessian, Mesrob I. and Srebro, Nathan},
  year = {2018},
  month = dec,
  abstract = {The study of fairness in intelligent decision systems has mostly ignored long-term influence on the underlying population. Yet fairness considerations (e.g. affirmative action) have often the implicit goal of achieving balance among groups within the population. The most basic notion of balance is eventual equality between the qualifications of the groups. How can we incorporate influence dynamics in decision making? How well do dynamics-oblivious fairness policies fare in terms of reaching equality? In this paper, we propose a simple yet revealing model that encompasses (1) a selection process where an institution chooses from multiple groups according to their qualifications so as to maximize an institutional utility and (2) dynamics that govern the evolution of the groups' qualifications according to the imposed policies. We focus on demographic parity as the formalism of affirmative action. We then give conditions under which an unconstrained policy reaches equality on its own. In this case, surprisingly, imposing demographic parity may break equality. When it doesn't, one would expect the additional constraint to reduce utility, however, we show that utility may in fact increase. In more realistic scenarios, unconstrained policies do not lead to equality. In such cases, we show that although imposing demographic parity may remedy it, there is a danger that groups settle at a worse set of qualifications. As a silver lining, we also identify when the constraint not only leads to equality, but also improves all groups. This gives quantifiable insight into both sides of the mismatch hypothesis. These cases and trade-offs are instrumental in determining when and how imposing demographic parity can be beneficial in selection processes, both for the institution and for society on the long run.},
  archivePrefix = {arXiv},
  eprint = {1812.02952},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mouzannar et al (2018) - From Fair Decision Making to Social Equality.pdf},
  journal = {arXiv:1812.02952 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{mozannar2020Fair,
  title = {Fair {{Learning}} with {{Private Demographic Data}}},
  author = {Mozannar, Hussein and Ohannessian, Mesrob I. and Srebro, Nathan},
  year = {2020},
  month = feb,
  abstract = {Sensitive attributes such as race are rarely available to learners in real world settings as their collection is often restricted by laws and regulations. We give a scheme that allows individuals to release their sensitive information privately while still allowing any downstream entity to learn non-discriminatory predictors. We show how to adapt non-discriminatory learners to work with privatized protected attributes giving theoretical guarantees on performance. Finally, we highlight how the methodology could apply to learning fair predictors in settings where protected attributes are only available for a subset of the data.},
  archivePrefix = {arXiv},
  eprint = {2002.11651},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mozannar et al (2020) - Fair Learning with Private Demographic Data.pdf},
  journal = {arXiv:2002.11651 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{mroueh2019Sobolev,
  title = {Sobolev {{Independence Criterion}}},
  author = {Mroueh, Youssef and Sercu, Tom and Rigotti, Mattia and Padhi, Inkit and Santos, Cicero Dos},
  year = {2019},
  month = oct,
  abstract = {We propose the Sobolev Independence Criterion (SIC), an interpretable dependency measure between a high dimensional random variable X and a response variable Y . SIC decomposes to the sum of feature importance scores and hence can be used for nonlinear feature selection. SIC can be seen as a gradient regularized Integral Probability Metric (IPM) between the joint distribution of the two random variables and the product of their marginals. We use sparsity inducing gradient penalties to promote input sparsity of the critic of the IPM. In the kernel version we show that SIC can be cast as a convex optimization problem by introducing auxiliary variables that play an important role in feature selection as they are normalized feature importance scores. We then present a neural version of SIC where the critic is parameterized as a homogeneous neural network, improving its representation power as well as its interpretability. We conduct experiments validating SIC for feature selection in synthetic and real-world experiments. We show that SIC enables reliable and interpretable discoveries, when used in conjunction with the holdout randomization test and knockoffs to control the False Discovery Rate. Code is available at http://github.com/ibm/sic.},
  archivePrefix = {arXiv},
  eprint = {1910.14212},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mroueh et al (2019) - Sobolev Independence Criterion.pdf},
  journal = {arXiv:1910.14212 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{muandet2013Domain,
  title = {Domain {{Generalization}} via {{Invariant Feature Representation}}},
  author = {Muandet, Krikamol and Balduzzi, David and Sch{\"o}lkopf, Bernhard},
  year = {2013},
  month = jan,
  abstract = {This paper investigates domain generalization: How to take knowledge acquired
from an arbitrary number of related domains and apply it to previously unseen
domains? We propose Domain-Invariant Component Analysis (DICA), a kernel-based
optimization algorithm that learns an invariant transformation by minimizing
the dissimilarity across domains, whilst preserving the functional relationship
between input and output variables. A learning-theoretic analysis shows that
reducing dissimilarity improves the expected generalization ability of
classifiers on new domains, motivating the proposed algorithm. Experimental
results on synthetic and real-world datasets demonstrate that DICA successfully
learns invariant features and improves classifier performance in practice.},
  file = {/Users/yuekai/Documents/zotero/Muandet et al (2013) - Domain Generalization via Invariant Feature Representation.pdf},
  language = {en}
}

@article{mukherjee2013Theory,
  title = {A {{Theory}} of {{Multiclass Boosting}}},
  author = {Mukherjee, Indraneel and Schapire, Robert E},
  year = {2013},
  month = feb,
  volume = {14},
  pages = {61},
  abstract = {Boosting combines weak classifiers to form highly accurate predictors. Although the case of binary classification is well understood, in the multiclass setting, the ``correct'' requirements on the weak classifier, or the notion of the most efficient boosting algorithms are missing. In this paper, we create a broad and general framework, within which we make precise and identify the optimal requirements on the weak-classifier, as well as design the most effective, in a certain sense, boosting algorithms that assume such requirements.},
  file = {/Users/yuekai/Documents/zotero/Mukherjee, Schapire (2013) - A Theory of Multiclass Boosting.pdf},
  journal = {Journal of Machine Learning Research},
  language = {en}
}

@article{mukherjee2019NonStandard,
  title = {Non-{{Standard Asymptotics}} in {{High Dimensions}}: {{Manski}}'s {{Maximum Score Estimator Revisited}}},
  shorttitle = {Non-{{Standard Asymptotics}} in {{High Dimensions}}},
  author = {Mukherjee, Debarghya and Banerjee, Moulinath and Ritov, Ya'acov},
  year = {2019},
  month = apr,
  abstract = {Manski's celebrated maximum score estimator for the binary choice model has been the focus of much investigation in both the econometrics and statistics literatures, but its behavior under growing dimension scenarios still largely remains unknown. This paper seeks to address that gap. Two different cases are considered: \$p\$ grows with \$n\$ but at a slow rate, i.e. \$p/n \textbackslash rightarrow 0\$; and \$p \textbackslash gg n\$ (fast growth). By relating Manski's score estimation to empirical risk minimization in a classification problem, we show that under a \textbackslash emph\{soft margin condition\} involving a smoothness parameter \$\textbackslash alpha {$>$} 0\$, the rate of the score estimator in the slow regime is essentially \$\textbackslash left((p/n)\textbackslash log n\textbackslash right)\^\{\textbackslash frac\{\textbackslash alpha\}\{\textbackslash alpha + 2\}\}\$, while, in the fast regime, the \$l\_0\$ penalized score estimator essentially attains the rate \$((s\_0 \textbackslash log\{p\} \textbackslash log\{n\})/n)\^\{\textbackslash frac\{\textbackslash alpha\}\{\textbackslash alpha + 2\}\}\$, where \$s\_0\$ is the sparsity of the true regression parameter. For the most interesting regime, \$\textbackslash alpha = 1\$, the rates of Manski's estimator are therefore \$\textbackslash left((p/n)\textbackslash log n\textbackslash right)\^\{1/3\}\$ and \$((s\_0 \textbackslash log\{p\} \textbackslash log\{n\})/n)\^\{1/3\}\$ in the slow and fast growth scenarios respectively, which can be viewed as high-dimensional analogues of cube-root asymptotics: indeed, this work is possibly the first study of a non-regular statistical problem in a high-dimensional framework. We also establish upper and lower bounds for the minimax \$L\_2\$ error in the Manski's model that differ by a logarithmic factor, and construct a minimax-optimal estimator in the setting \$\textbackslash alpha=1\$. Finally, we provide computational recipes for the maximum score estimator in growing dimensions that show promising results.},
  archivePrefix = {arXiv},
  eprint = {1903.10063},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Mukherjee et al (2019) - Non-Standard Asymptotics in High Dimensions.pdf},
  journal = {arXiv:1903.10063 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@inproceedings{mukherjee2020Two,
  title = {Two Simple Ways to Learn Individual Fairness Metrics from Data},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Mukherjee, Debarghya and Yurochkin, Mikhail and Banerjee, Moulinath and Sun, Yuekai},
  year = {2020},
  month = jul,
  issn = {1938-7228},
  chapter = {Machine Learning},
  language = {en}
}

@article{murdoch2019Definitions,
  title = {Definitions, Methods, and Applications in Interpretable Machine Learning},
  author = {Murdoch, W. James and Singh, Chandan and Kumbier, Karl and {Abbasi-Asl}, Reza and Yu, Bin},
  year = {2019},
  month = oct,
  volume = {116},
  pages = {22071--22080},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1900654116},
  abstract = {Machine-learning models have demonstrated great success in learning complex patterns that enable them to make predictions about unobserved data. In addition to using models for prediction, the ability to interpret what a model has learned is receiving an increasing amount of attention. However, this increased focus has led to considerable confusion about the notion of interpretability. In particular, it is unclear how the wide array of proposed interpretation methods are related and what common concepts can be used to evaluate them. We aim to address these concerns by defining interpretability in the context of machine learning and introducing the predictive, descriptive, relevant (PDR) framework for discussing interpretations. The PDR framework provides 3 overarching desiderata for evaluation: predictive accuracy, descriptive accuracy, and relevancy, with relevancy judged relative to a human audience. Moreover, to help manage the deluge of interpretation methods, we introduce a categorization of existing techniques into model-based and post hoc categories, with subgroups including sparsity, modularity, and simulatability. To demonstrate how practitioners can use the PDR framework to evaluate and understand interpretations, we provide numerous real-world examples. These examples highlight the often underappreciated role played by human audiences in discussions of interpretability. Finally, based on our framework, we discuss limitations of existing methods and directions for future work. We hope that this work will provide a common vocabulary that will make it easier for both practitioners and researchers to discuss and choose from the full range of interpretation methods.},
  chapter = {Physical Sciences},
  copyright = {\textcopyright{} 2019 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
  file = {/Users/yuekai/Documents/zotero/Murdoch et al (2019) - Definitions, methods, and applications in interpretable machine learning.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {explainability,interpretability,machine learning,relevancy},
  language = {en},
  number = {44},
  pmid = {31619572}
}

@article{murphy2003Optimal,
  title = {Optimal Dynamic Treatment Regimes},
  author = {Murphy, S. A.},
  year = {2003},
  month = may,
  volume = {65},
  pages = {331--355},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/1467-9868.00389},
  abstract = {A dynamic treatment regime is a list of decision rules, one per time interval, for how the level of treatment will be tailored through time to an individual's changing status. The goal of this paper is to use experimental or observational data to estimate decision regimes that result in a maximal mean response. To explicate our objective and to state the assumptions, we use the potential outcomes model. The method proposed makes smooth parametric assumptions only on quantities that are directly relevant to the goal of estimating the optimal rules. We illustrate the methodology proposed via a small simulation.},
  file = {/Users/yuekai/Documents/zotero/Murphy (2003) - Optimal dynamic treatment regimes.pdf},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  language = {en},
  number = {2}
}

@article{myerson1981Optimal,
  title = {Optimal {{Auction Design}}},
  author = {Myerson, Roger B.},
  year = {1981},
  month = feb,
  volume = {6},
  pages = {58--73},
  issn = {0364-765X},
  doi = {10.1287/moor.6.1.58},
  abstract = {This paper considers the problem faced by a seller who has a single object to sell to one of several possible buyers, when the seller has imperfect information about how much the buyers might be willing to pay for the object. The seller's problem is to design an auction game which has a Nash equilibrium giving him the highest possible expected utility. Optimal auctions are derived in this paper for a wide class of auction design problems.},
  journal = {Math. Oper. Res.},
  number = {1}
}

@article{nabi2017Fair,
  title = {Fair {{Inference On Outcomes}}},
  author = {Nabi, Razieh and Shpitser, Ilya},
  year = {2017},
  month = may,
  abstract = {In this paper, we consider the problem of fair statistical inference involving outcome variables. Examples include classification and regression problems, and estimating treatment effects in randomized trials or observational data. The issue of fairness arises in such problems where some covariates or treatments are "sensitive," in the sense of having potential of creating discrimination. In this paper, we argue that the presence of discrimination can be formalized in a sensible way as the presence of an effect of a sensitive covariate on the outcome along certain causal pathways, a view which generalizes (Pearl, 2009). A fair outcome model can then be learned by solving a constrained optimization problem. We discuss a number of complications that arise in classical statistical inference due to this view and provide workarounds based on recent work in causal and semi-parametric inference.},
  archivePrefix = {arXiv},
  eprint = {1705.10378},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Nabi, Shpitser (2017) - Fair Inference On Outcomes.pdf},
  journal = {arXiv:1705.10378 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{nabi2018Learning,
  title = {Learning {{Optimal Fair Policies}}},
  author = {Nabi, Razieh and Malinsky, Daniel and Shpitser, Ilya},
  year = {2018},
  month = sep,
  abstract = {Systematic discriminatory biases present in our society influence the way data is collected and stored, the way variables are defined, and the way scientific findings are put into practice as policy. Automated decision procedures and learning algorithms applied to such data may serve to perpetuate existing injustice or unfairness in our society. In this paper, we consider how to make optimal but fair decisions, which "break the cycle of injustice" by correcting for the unfair dependence of both decisions and outcomes on sensitive features (e.g., variables that correspond to gender, race, disability, or other protected attributes). We use methods from causal inference and constrained optimization to learn optimal policies in a way that addresses multiple potential biases which afflict data analysis in sensitive contexts, extending the approach of (Nabi and Shpitser 2018). Our proposal comes equipped with the theoretical guarantee that the chosen fair policy will induce a joint distribution for new instances that satisfies given fairness constraints. We illustrate our approach with both synthetic data and real criminal justice data.},
  archivePrefix = {arXiv},
  eprint = {1809.02244},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Nabi et al (2018) - Learning Optimal Fair Policies.pdf},
  journal = {arXiv:1809.02244 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{nachum2019AlgaeDICE,
  title = {{{AlgaeDICE}}: {{Policy Gradient}} from {{Arbitrary Experience}}},
  shorttitle = {{{AlgaeDICE}}},
  author = {Nachum, Ofir and Dai, Bo and Kostrikov, Ilya and Chow, Yinlam and Li, Lihong and Schuurmans, Dale},
  year = {2019},
  month = dec,
  abstract = {In many real-world applications of reinforcement learning (RL), interactions with the environment are limited due to cost or feasibility. This presents a challenge to traditional RL algorithms since the max-return objective involves an expectation over on-policy samples. We introduce a new formulation of max-return optimization that allows the problem to be re-expressed by an expectation over an arbitrary behavior-agnostic and off-policy data distribution. We first derive this result by considering a regularized version of the dual max-return objective before extending our findings to unregularized objectives through the use of a Lagrangian formulation of the linear programming characterization of Q-values. We show that, if auxiliary dual variables of the objective are optimized, then the gradient of the off-policy objective is exactly the on-policy policy gradient, without any use of importance weighting. In addition to revealing the appealing theoretical properties of this approach, we also show that it delivers good practical performance.},
  archivePrefix = {arXiv},
  eprint = {1912.02074},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Nachum et al (2019) - AlgaeDICE.pdf},
  journal = {arXiv:1912.02074 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{nachum2020Reinforcement,
  title = {Reinforcement {{Learning}} via {{Fenchel}}-{{Rockafellar Duality}}},
  author = {Nachum, Ofir and Dai, Bo},
  year = {2020},
  month = jan,
  abstract = {We review basic concepts of convex duality, focusing on the very general and supremely useful Fenchel-Rockafellar duality. We summarize how this duality may be applied to a variety of reinforcement learning (RL) settings, including policy evaluation or optimization, online or offline learning, and discounted or undiscounted rewards. The derivations yield a number of intriguing results, including the ability to perform policy evaluation and on-policy policy gradient with behavior-agnostic offline data and methods to learn a policy via max-likelihood optimization. Although many of these results have appeared previously in various forms, we provide a unified treatment and perspective on these results, which we hope will enable researchers to better use and apply the tools of convex duality to make further progress in RL.},
  archivePrefix = {arXiv},
  eprint = {2001.01866},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Nachum, Dai (2020) - Reinforcement Learning via Fenchel-Rockafellar Duality.pdf},
  journal = {arXiv:2001.01866 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{namkoong2016Stochastic,
  title = {Stochastic {{Gradient Methods}} for {{Distributionally Robust Optimization}} with {{F}}-Divergences},
  booktitle = {Proceedings of the 30th {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Namkoong, Hongseok and Duchi, John C.},
  year = {2016},
  pages = {2216--2224},
  publisher = {{Curran Associates Inc.}},
  address = {{USA}},
  abstract = {We develop efficient solution methods for a robust empirical risk minimization problem designed to give calibrated confidence intervals on performance and provide optimal tradeoffs between bias and variance. Our methods apply to distributionally robust optimization problems proposed by Ben-Tal et al., which put more weight on observations inducing high loss via a worst-case approach over a non-parametric uncertainty set on the underlying data distribution. Our algorithm solves the resulting minimax problems with nearly the same computational cost of stochastic gradient descent through the use of several carefully designed data structures. For a sample of size n, the per-iteration cost of our method scales as O(log n), which allows us to give optimality certificates that distributionally robust optimization provides at little extra cost compared to empirical risk minimization and stochastic gradient methods.},
  file = {/Users/yuekai/Documents/zotero/Namkoong, Duchi (2016) - Stochastic Gradient Methods for Distributionally Robust Optimization with.pdf},
  isbn = {978-1-5108-3881-9},
  series = {{{NIPS}}'16}
}

@article{nandi2018Adapting,
  title = {Adapting {{BH}} to {{One}}- and {{Two}}-{{Way Classified Structures}} of {{Hypotheses}}},
  author = {Nandi, Shinjini and Sarkar, Sanat K.},
  year = {2018},
  month = dec,
  abstract = {Multiple testing literature contains ample research on controlling false
discoveries for hypotheses classified according to one criterion, which we
refer to as one-way classified hypotheses. Although simultaneous classification
of hypotheses according to two different criteria, resulting in two-way
classified hypotheses, do often occur in scientific studies, no such research
has taken place yet, as far as we know, under this structure. This article
produces procedures, both in their oracle and data-adaptive forms, for
controlling the overall false discovery rate (FDR) across all hypotheses
effectively capturing the underlying one- or two-way classification structure.
They have been obtained by using results associated with weighted
Benjamini-Hochberg (BH) procedure in their more general forms providing
guidance on how to adapt the original BH procedure to the underlying one- or
two-way classification structure through an appropriate choice of the weights.
The FDR is maintained non-asymptotically by our proposed procedures in their
oracle forms under positive regression dependence on subset of null \$p\$-values
(PRDS) and in their data-adaptive forms under independence of the \$p\$-values.
Possible control of FDR for our data-adaptive procedures in certain scenarios
involving dependent \$p\$-values have been investigated through simulations. The
fact that our suggested procedures can be superior to contemporary practices
has been demonstrated through their applications in simulated scenarios and to
real-life data sets. While the procedures proposed here for two-way classified
hypotheses are new, the data-adaptive procedure obtained for one-way classified
hypotheses is alternative to and often more powerful than those proposed in Hu
et al. (2010).},
  file = {/Users/yuekai/Documents/zotero/Nandi, Sarkar (2018) - Adapting BH to One- and Two-Way Classified Structures of Hypotheses.pdf},
  language = {en}
}

@article{narayanan2006How,
  title = {How {{To Break Anonymity}} of the {{Netflix Prize Dataset}}},
  author = {Narayanan, Arvind and Shmatikov, Vitaly},
  year = {2006},
  month = oct,
  abstract = {We present a new class of statistical de-anonymization attacks against high-dimensional micro-data, such as individual preferences, recommendations, transaction records and so on. Our techniques are robust to perturbation in the data and tolerate some mistakes in the adversary's background knowledge. We apply our de-anonymization methodology to the Netflix Prize dataset, which contains anonymous movie ratings of 500,000 subscribers of Netflix, the world's largest online movie rental service. We demonstrate that an adversary who knows only a little bit about an individual subscriber can easily identify this subscriber's record in the dataset. Using the Internet Movie Database as the source of background knowledge, we successfully identified the Netflix records of known users, uncovering their apparent political preferences and other potentially sensitive information.},
  archivePrefix = {arXiv},
  eprint = {cs/0610105},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Narayanan, Shmatikov (2006) - How To Break Anonymity of the Netflix Prize Dataset.pdf},
  journal = {arXiv:cs/0610105},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Databases}
}

@article{nasr2019Bidding,
  title = {Bidding {{Strategies}} with {{Gender Nondiscrimination}}: {{Constraints}} for {{Online Ad Auctions}}},
  shorttitle = {Bidding {{Strategies}} with {{Gender Nondiscrimination}}},
  author = {Nasr, Milad and Tschantz, Michael},
  year = {2019},
  month = sep,
  abstract = {Interactions between bids to show ads online can lead to an advertiser's ad being shown to more men than women even when the advertiser does not target towards men. We design bidding strategies that advertisers can use to avoid such emergent discrimination without having to modify the auction mechanism. We mathematically analyze the strategies to determine the additional cost to the advertiser for avoiding discrimination, proving our strategies to be optimal in some settings. We use simulations to understand other settings.},
  archivePrefix = {arXiv},
  eprint = {1909.02156},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Nasr, Tschantz (2019) - Bidding Strategies with Gender Nondiscrimination.pdf;/Users/yuekai/Zotero/storage/EZK5X5UM/1909.html},
  journal = {arXiv:1909.02156 [cs]},
  keywords = {Computer Science - Computer Science and Game Theory},
  primaryClass = {cs}
}

@article{nedic2009Subgradient,
  title = {Subgradient {{Methods}} for {{Saddle}}-{{Point Problems}}},
  author = {Nedi{\'c}, A. and Ozdaglar, A.},
  year = {2009},
  month = jul,
  volume = {142},
  pages = {205--228},
  issn = {1573-2878},
  doi = {10.1007/s10957-009-9522-7},
  abstract = {We study subgradient methods for computing the saddle points of a convex-concave function. Our motivation comes from networking applications where dual and primal-dual subgradient methods have attracted much attention in the design of decentralized network protocols. We first present a subgradient algorithm for generating approximate saddle points and provide per-iteration convergence rate estimates on the constructed solutions. We then focus on Lagrangian duality, where we consider a convex primal optimization problem and its Lagrangian dual problem, and generate approximate primal-dual optimal solutions as approximate saddle points of the Lagrangian function. We present a variation of our subgradient method under the Slater constraint qualification and provide stronger estimates on the convergence rate of the generated primal sequences. In particular, we provide bounds on the amount of feasibility violation and on the primal objective function values at the approximate solutions. Our algorithm is particularly well-suited for problems where the subgradient of the dual function cannot be evaluated easily (equivalently, the minimum of the Lagrangian function at a dual solution cannot be computed efficiently), thus impeding the use of dual subgradient methods.},
  file = {/Users/yuekai/Documents/zotero/Nedić, Ozdaglar (2009) - Subgradient Methods for Saddle-Point Problems.pdf},
  journal = {Journal of Optimization Theory and Applications},
  language = {en},
  number = {1}
}

@article{nemirovski2009Robust,
  title = {Robust {{Stochastic Approximation Approach}} to {{Stochastic Programming}}},
  author = {Nemirovski, A. and Juditsky, A. and Lan, G. and Shapiro, A.},
  year = {2009},
  month = jan,
  volume = {19},
  pages = {1574--1609},
  issn = {1052-6234, 1095-7189},
  doi = {10.1137/070704277},
  abstract = {In this paper we consider optimization problems where the objective function is given in a form of the expectation. A basic difficulty of solving such stochastic optimization problems is that the involved multidimensional integrals (expectations) cannot be computed with high accuracy. The aim of this paper is to compare two computational approaches based on Monte Carlo sampling techniques, namely, the stochastic approximation (SA) and the sample average approximation (SAA) methods. Both approaches, the SA and SAA methods, have a long history. Current opinion is that the SAA method can efficiently use a specific (say, linear) structure of the considered problem, while the SA approach is a crude subgradient method, which often performs poorly in practice. We intend to demonstrate that a properly modified SA approach can be competitive and even significantly outperform the SAA method for a certain class of convex stochastic problems. We extend the analysis to the case of convex-concave stochastic saddle point problems and present (in our opinion highly encouraging) results of numerical experiments.},
  file = {/Users/yuekai/Documents/zotero/Nemirovski et al (2009) - Robust Stochastic Approximation Approach to Stochastic Programming.pdf},
  journal = {SIAM Journal on Optimization},
  language = {en},
  number = {4}
}

@article{nesterov2007Dual,
  title = {Dual Extrapolation and Its Applications to Solving Variational Inequalities and Related Problems},
  author = {Nesterov, Yurii},
  year = {2007},
  month = jan,
  volume = {109},
  pages = {319--344},
  issn = {0025-5610, 1436-4646},
  doi = {10.1007/s10107-006-0034-z},
  file = {/Users/yuekai/Documents/zotero/Nesterov (2007) - Dual extrapolation and its applications to solving variational inequalities and.pdf},
  journal = {Mathematical Programming},
  language = {en},
  number = {2-3}
}

@article{netrapalli2012Finding,
  title = {Finding the {{Graph}} of {{Epidemic Cascades}}},
  author = {Netrapalli, Praneeth and Sanghavi, Sujay},
  year = {2012},
  month = feb,
  abstract = {We consider the problem of finding the graph on which an epidemic cascade spreads, given only the times when each node gets infected. While this is a problem of importance in several contexts -- offline and online social networks, e-commerce, epidemiology, vulnerabilities in infrastructure networks -- there has been very little work, analytical or empirical, on finding the graph. Clearly, it is impossible to do so from just one cascade; our interest is in learning the graph from a small number of cascades. For the classic and popular "independent cascade" SIR epidemics, we analytically establish the number of cascades required by both the global maximum-likelihood (ML) estimator, and a natural greedy algorithm. Both results are based on a key observation: the global graph learning problem decouples into \$n\$ local problems -- one for each node. For a node of degree \$d\$, we show that its neighborhood can be reliably found once it has been infected \$O(d\^2 \textbackslash log n)\$ times (for ML on general graphs) or \$O(d\textbackslash log n)\$ times (for greedy on trees). We also provide a corresponding information-theoretic lower bound of \$\textbackslash Omega(d\textbackslash log n)\$; thus our bounds are essentially tight. Furthermore, if we are given side-information in the form of a super-graph of the actual graph (as is often the case), then the number of cascade samples required -- in all cases -- becomes independent of the network size \$n\$. Finally, we show that for a very general SIR epidemic cascade model, the Markov graph of infection times is obtained via the moralization of the network graph.},
  archivePrefix = {arXiv},
  eprint = {1202.1779},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Netrapalli, Sanghavi (2012) - Finding the Graph of Epidemic Cascades.pdf},
  journal = {arXiv:1202.1779 [physics, stat]},
  keywords = {Computer Science - Social and Information Networks,Physics - Physics and Society,Statistics - Machine Learning},
  primaryClass = {physics, stat}
}

@inproceedings{ng2001Spectral,
  title = {On {{Spectral Clustering}}: {{Analysis}} and an Algorithm},
  shorttitle = {On {{Spectral Clustering}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Ng, Andrew Y. and Jordan, Michael I. and Weiss, Yair},
  year = {2001},
  pages = {849--856},
  publisher = {{MIT Press}},
  abstract = {Despite many empirical successes of spectral clustering methods -- algorithms that cluster points using eigenvectors of matrices derived  from the distances between the points -- there are several unresolved  issues. First, there is a wide variety of algorithms that  use the eigenvectors in slightly different ways. Second, many of  these algorithms have no proof that they will actually compute a  reasonable clustering. In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab. Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected  to do well. We also show surprisingly good experimental results on  a number of challenging clustering problems.},
  file = {/Users/yuekai/Documents/zotero/Ng et al (2001) - On Spectral Clustering.pdf}
}

@article{nguyen2010Estimating,
  title = {Estimating {{Divergence Functionals}} and the {{Likelihood Ratio}} by {{Convex Risk Minimization}}},
  author = {Nguyen, XuanLong and Wainwright, Martin J. and Jordan, Michael I.},
  year = {2010},
  month = nov,
  volume = {56},
  pages = {5847--5861},
  issn = {0018-9448, 1557-9654},
  doi = {10.1109/TIT.2010.2068870},
  abstract = {We develop and analyze -estimation methods for divergence functionals and the likelihood ratios of two probability distributions. Our method is based on a nonasymptotic variational characterization of -divergences, which allows the problem of estimating divergences to be tackled via convex empirical risk optimization. The resulting estimators are simple to implement, requiring only the solution of standard convex programs. We present an analysis of consistency and convergence for these estimators. Given conditions only on the ratios of densities, we show that our estimators can achieve optimal minimax rates for the likelihood ratio and the divergence functionals in certain regimes. We derive an efficient optimization algorithm for computing our estimates, and illustrate their convergence behavior and practical viability by simulations.},
  file = {/Users/yuekai/Documents/zotero/Nguyen et al (2010) - Estimating Divergence Functionals and the Likelihood Ratio by Convex Risk.pdf},
  journal = {IEEE Transactions on Information Theory},
  language = {en},
  number = {11}
}

@article{nguyen2014Deep,
  title = {Deep {{Neural Networks}} Are {{Easily Fooled}}: {{High Confidence Predictions}} for {{Unrecognizable Images}}},
  shorttitle = {Deep {{Neural Networks}} Are {{Easily Fooled}}},
  author = {Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
  year = {2014},
  month = dec,
  abstract = {Deep neural networks (DNNs) have recently been achieving state-of-the-art performance on a variety of pattern-recognition tasks, most notably visual classification problems. Given that DNNs are now able to classify objects in images with near-human-level performance, questions naturally arise as to what differences remain between computer and human vision. A recent study revealed that changing an image (e.g. of a lion) in a way imperceptible to humans can cause a DNN to label the image as something else entirely (e.g. mislabeling a lion a library). Here we show a related result: it is easy to produce images that are completely unrecognizable to humans, but that state-of-the-art DNNs believe to be recognizable objects with 99.99\% confidence (e.g. labeling with certainty that white noise static is a lion). Specifically, we take convolutional neural networks trained to perform well on either the ImageNet or MNIST datasets and then find images with evolutionary algorithms or gradient ascent that DNNs label with high confidence as belonging to each dataset class. It is possible to produce images totally unrecognizable to human eyes that DNNs believe with near certainty are familiar objects, which we call "fooling images" (more generally, fooling examples). Our results shed light on interesting differences between human vision and current DNNs, and raise questions about the generality of DNN computer vision.},
  archivePrefix = {arXiv},
  eprint = {1412.1897},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Nguyen et al (2014) - Deep Neural Networks are Easily Fooled.pdf},
  journal = {arXiv:1412.1897 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Neural and Evolutionary Computing},
  primaryClass = {cs}
}

@article{nichol2018FirstOrder,
  title = {On {{First}}-{{Order Meta}}-{{Learning Algorithms}}},
  author = {Nichol, Alex and Achiam, Joshua and Schulman, John},
  year = {2018},
  month = oct,
  abstract = {This paper considers meta-learning problems, where there is a distribution of tasks, and we would like to obtain an agent that performs well (i.e., learns quickly) when presented with a previously unseen task sampled from this distribution. We analyze a family of algorithms for learning a parameter initialization that can be fine-tuned quickly on a new task, using only first-order derivatives for the meta-learning updates. This family includes and generalizes first-order MAML, an approximation to MAML obtained by ignoring second-order derivatives. It also includes Reptile, a new algorithm that we introduce here, which works by repeatedly sampling a task, training on it, and moving the initialization towards the trained weights on that task. We expand on the results from Finn et al. showing that first-order meta-learning algorithms perform well on some well-established benchmarks for few-shot classification, and we provide theoretical analysis aimed at understanding why these algorithms work.},
  archivePrefix = {arXiv},
  eprint = {1803.02999},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Nichol et al (2018) - On First-Order Meta-Learning Algorithms.pdf},
  journal = {arXiv:1803.02999 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{niles-weed2019Estimation,
  title = {Estimation of {{Wasserstein}} Distances in the {{Spiked Transport Model}}},
  author = {{Niles-Weed}, Jonathan and Rigollet, Philippe},
  year = {2019},
  month = sep,
  abstract = {We propose a new statistical model, the spiked transport model, which formalizes the assumption that two probability distributions differ only on a low-dimensional subspace. We study the minimax rate of estimation for the Wasserstein distance under this model and show that this low-dimensional structure can be exploited to avoid the curse of dimensionality. As a byproduct of our minimax analysis, we establish a lower bound showing that, in the absence of such structure, the plug-in estimator is nearly rate-optimal for estimating the Wasserstein distance in high dimension. We also give evidence for a statistical-computational gap and conjecture that any computationally efficient estimator is bound to suffer from the curse of dimensionality.},
  archivePrefix = {arXiv},
  eprint = {1909.07513},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Niles-Weed, Rigollet (2019) - Estimation of Wasserstein distances in the Spiked Transport Model.pdf},
  journal = {arXiv:1909.07513 [math, stat]},
  keywords = {62F99; 62H99,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@inproceedings{nissim2007Smooth,
  title = {Smooth Sensitivity and Sampling in Private Data Analysis},
  booktitle = {Proceedings of the Thirty-Ninth Annual {{ACM}} Symposium on {{Theory}} of Computing},
  author = {Nissim, Kobbi and Raskhodnikova, Sofya and Smith, Adam},
  year = {2007},
  month = jun,
  pages = {75--84},
  publisher = {{Association for Computing Machinery}},
  address = {{San Diego, California, USA}},
  doi = {10.1145/1250790.1250803},
  abstract = {We introduce a new, generic framework for private data analysis.The goal of private data analysis is to release aggregate information about a data set while protecting the privacy of the individuals whose information the data set contains.Our framework allows one to release functions f of the data withinstance-based additive noise. That is, the noise magnitude is determined not only by the function we want to release, but also bythe database itself. One of the challenges is to ensure that the noise magnitude does not leak information about the database. To address that, we calibrate the noise magnitude to the smoothsensitivity of f on the database x --- a measure of variabilityof f in the neighborhood of the instance x. The new frameworkgreatly expands the applicability of output perturbation, a technique for protecting individuals' privacy by adding a smallamount of random noise to the released statistics. To our knowledge, this is the first formal analysis of the effect of instance-basednoise in the context of data privacy. Our framework raises many interesting algorithmic questions. Namely,to apply the framework one must compute or approximate the smoothsensitivity of f on x. We show how to do this efficiently for several different functions, including the median and the cost ofthe minimum spanning tree. We also give a generic procedure based on sampling that allows one to release f(x) accurately on manydatabases x. This procedure is applicable even when no efficient algorithm for approximating smooth sensitivity of f is known orwhen f is given as a black box. We illustrate the procedure by applying it to k-SED (k-means) clustering and learning mixtures of Gaussians.},
  file = {/Users/yuekai/Documents/zotero/Nissim et al (2007) - Smooth sensitivity and sampling in private data analysis.pdf},
  isbn = {978-1-59593-631-8},
  series = {{{STOC}} '07}
}

@article{nitanda2018Functional,
  title = {Functional {{Gradient Boosting}} Based on {{Residual Network Perception}}},
  author = {Nitanda, Atsushi and Suzuki, Taiji},
  year = {2018},
  month = feb,
  abstract = {Residual Networks (ResNets) have become state-of-the-art models in deep learning and several theoretical studies have been devoted to understanding why ResNet works so well. One attractive viewpoint on ResNet is that it is optimizing the risk in a functional space by combining an ensemble of effective features. In this paper, we adopt this viewpoint to construct a new gradient boosting method, which is known to be very powerful in data analysis. To do so, we formalize the gradient boosting perspective of ResNet mathematically using the notion of functional gradients and propose a new method called ResFGB for classification tasks by leveraging ResNet perception. Two types of generalization guarantees are provided from the optimization perspective: one is the margin bound and the other is the expected risk bound by the sample-splitting technique. Experimental results show superior performance of the proposed method over state-of-the-art methods such as LightGBM.},
  archivePrefix = {arXiv},
  eprint = {1802.09031},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Nitanda, Suzuki (2018) - Functional Gradient Boosting based on Residual Network Perception.pdf},
  journal = {arXiv:1802.09031 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@book{nocedal2006Numerical,
  title = {Numerical Optimization},
  author = {Nocedal, Jorge and Wright, Stephen J.},
  year = {2006},
  edition = {2nd ed},
  publisher = {{Springer}},
  address = {{New York}},
  annotation = {OCLC: ocm68629100},
  file = {/Users/yuekai/Documents/zotero/Nocedal, Wright (2006) - Numerical optimization.pdf},
  isbn = {978-0-387-30303-1},
  language = {en},
  lccn = {QA402.5 .N62 2006},
  series = {Springer Series in Operations Research}
}

@inproceedings{noriega-campero2019Active,
  title = {Active {{Fairness}} in {{Algorithmic Decision Making}}},
  booktitle = {Proceedings of the 2019 {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  author = {{Noriega-Campero}, Alejandro and Bakker, Michiel A. and {Garcia-Bulle}, Bernardo and Pentland, Alex 'Sandy'},
  year = {2019},
  month = jan,
  pages = {77--83},
  publisher = {{Association for Computing Machinery}},
  address = {{Honolulu, HI, USA}},
  doi = {10.1145/3306618.3314277},
  abstract = {Society increasingly relies on machine learning models for automated decision making. Yet, efficiency gains from automation have come paired with concern for algorithmic discrimination that can systematize inequality. Recent work has proposed optimal post-processing methods that randomize classification decisions for a fraction of individuals, in order to achieve fairness measures related to parity in errors and calibration. These methods, however, have raised concern due to the information inefficiency, intra-group unfairness, and Pareto sub-optimality they entail. The present work proposes an alternativeactive framework for fair classification, where, in deployment, a decision-maker adaptively acquires information according to the needs of different groups or individuals, towards balancing disparities in classification performance. We propose two such methods, where information collection is adapted to group- and individual-level needs respectively. We show on real-world datasets that these can achieve: 1) calibration and single error parity (e.g.,equal opportunity ); and 2) parity in both false positive and false negative rates (i.e.,equal odds ). Moreover, we show that by leveraging their additional degree of freedom,active approaches can substantially outperform randomization-based classifiers previously considered optimal, while avoiding limitations such as intra-group unfairness.},
  file = {/Users/yuekai/Documents/zotero/Noriega-Campero et al (2019) - Active Fairness in Algorithmic Decision Making.pdf},
  isbn = {978-1-4503-6324-2},
  keywords = {active feature acquisition,adaptive inquiry,algorithmic fairness},
  series = {{{AIES}} '19}
}

@article{noriega-campero2020Algorithmic,
  title = {Algorithmic {{Targeting}} of {{Social Policies}}: {{Fairness}}, {{Accuracy}}, and {{Distributed Governance}}},
  author = {{Noriega-Campero}, Alejandro and {Garcia-Bulle}, Bernardo and Cantu, Luis Fernando and Bakker, Michiel A and Tejerina, Luis and Pentland, Alex},
  year = {2020},
  pages = {11},
  abstract = {Targeted social policies are the main strategy for poverty alleviation across the developing world. These include targeted cash transfers (CTs), as well as targeted subsidies in health, education, housing, energy, childcare, and others. Due to the scale, diversity, and widespread relevance of targeted social policies like CTs, the algorithmic rules that decide who is eligible to benefit from them\textemdash and who is not\textemdash are among the most important algorithms operating in the world today. Here we report on a year-long engagement towards improving social targeting systems in a couple of developing countries. We demonstrate that a shift towards the use of AI methods in poverty-based targeting can substantially increase accuracy, extending the coverage of the poor by nearly a million people in two countries, without increasing expenditure. However, we also show that, absent explicit parity constraints, both status quo and AI-based systems induce disparities across population subgroups. Moreover, based on qualitative interviews with local social institutions, we find a lack of consensus on normative standards for prioritization and fairness criteria. Hence, we close by proposing a decision-support platform for distributed governance, which enables a diversity of institutions to customize the use of AI-based insights into their targeting decisions.},
  file = {/Users/yuekai/Documents/zotero/Noriega-Campero et al (2020) - Algorithmic Targeting of Social Policies.pdf},
  language = {en}
}

@inproceedings{novak2019Neural,
  title = {Neural {{Tangents}}: {{Fast}} and {{Easy Infinite Neural Networks}} in {{Python}}},
  shorttitle = {Neural {{Tangents}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Novak, Roman and Xiao, Lechao and Hron, Jiri and Lee, Jaehoon and Alemi, Alexander A. and {Sohl-Dickstein}, Jascha and Schoenholz, Samuel S.},
  year = {2019},
  month = sep,
  abstract = {Neural Tangents is a library designed to enable research into infinite-width neural networks. It provides a high-level API for specifying complex and hierarchical neural network architectures....},
  file = {/Users/yuekai/Documents/zotero/Novak et al (2019) - Neural Tangents.pdf}
}

@inproceedings{nowozin2016fGAN,
  title = {F-{{GAN}}: {{Training}} Generative Neural Samplers Using Variational Divergence Minimization},
  shorttitle = {F-{{GAN}}},
  booktitle = {Proceedings of the 30th {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota},
  year = {2016},
  month = dec,
  pages = {271--279},
  publisher = {{Curran Associates Inc.}},
  address = {{Red Hook, NY, USA}},
  abstract = {Generative neural samplers are probabilistic models that implement sampling using feedforward neural networks: they take a random input vector and produce a sample from a probability distribution defined by the network weights. These models are expressive and allow efficient computation of samples and derivatives, but cannot be used for computing likelihoods or for marginalization. The generative-adversarial training method allows to train such models through the use of an auxiliary discriminative neural network. We show that the generative-adversarial approach is a special case of an existing more general variational divergence estimation approach. We show that any f-divergence can be used for training generative neural samplers. We discuss the benefits of various choices of divergence functions on training complexity and the quality of the obtained generative models.},
  file = {/Users/yuekai/Documents/zotero/Nowozin et al (2016) - if-i-GAN.pdf},
  isbn = {978-1-5108-3881-9},
  series = {{{NIPS}}'16}
}

@article{obermeyer2019Dissecting,
  title = {Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations},
  author = {Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and Mullainathan, Sendhil},
  year = {2019},
  month = oct,
  volume = {366},
  pages = {447--453},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aax2342},
  abstract = {Racial bias in health algorithms
The U.S. health care system uses commercial algorithms to guide health decisions. Obermeyer et al. find evidence of racial bias in one widely used algorithm, such that Black patients assigned the same level of risk by the algorithm are sicker than White patients (see the Perspective by Benjamin). The authors estimated that this racial bias reduces the number of Black patients identified for extra care by more than half. Bias occurs because the algorithm uses health costs as a proxy for health needs. Less money is spent on Black patients who have the same level of need, and the algorithm thus falsely concludes that Black patients are healthier than equally sick White patients. Reformulating the algorithm so that it no longer uses costs as a proxy for needs eliminates the racial bias in predicting who needs extra care.
Science, this issue p. 447; see also p. 421
Health systems rely on commercial prediction algorithms to identify and help patients with complex health needs. We show that a widely used algorithm, typical of this industry-wide approach and affecting millions of patients, exhibits significant racial bias: At a given risk score, Black patients are considerably sicker than White patients, as evidenced by signs of uncontrolled illnesses. Remedying this disparity would increase the percentage of Black patients receiving additional help from 17.7 to 46.5\%. The bias arises because the algorithm predicts health care costs rather than illness, but unequal access to care means that we spend less money caring for Black patients than for White patients. Thus, despite health care cost appearing to be an effective proxy for health by some measures of predictive accuracy, large racial biases arise. We suggest that the choice of convenient, seemingly effective proxies for ground truth can be an important source of algorithmic bias in many contexts.
A health algorithm that uses health costs as a proxy for health needs leads to racial bias against Black patients.
A health algorithm that uses health costs as a proxy for health needs leads to racial bias against Black patients.},
  copyright = {Copyright \textcopyright{} 2019 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. http://www.sciencemag.org/about/science-licenses-journal-article-reuseThis is an article distributed under the terms of the Science Journals Default License.},
  file = {/Users/yuekai/Documents/zotero/Obermeyer et al (2019) - Dissecting racial bias in an algorithm used to manage the health of populations.pdf},
  journal = {Science},
  language = {en},
  number = {6464},
  pmid = {31649194}
}

@article{oberst2019Counterfactual,
  title = {Counterfactual {{Off}}-{{Policy Evaluation}} with {{Gumbel}}-{{Max Structural Causal Models}}},
  author = {Oberst, Michael and Sontag, David},
  year = {2019},
  month = may,
  abstract = {We introduce an off-policy evaluation procedure for highlighting episodes where applying a reinforcement learned (RL) policy is likely to have produced a substantially different outcome than the observed policy. In particular, we introduce a class of structural causal models (SCMs) for generating counterfactual trajectories in finite partially observable Markov Decision Processes (POMDPs). We see this as a useful procedure for off-policy "debugging" in high-risk settings (e.g., healthcare); by decomposing the expected difference in reward between the RL and observed policy into specific episodes, we can identify episodes where the counterfactual difference in reward is most dramatic. This in turn can be used to facilitate review of specific episodes by domain experts. We demonstrate the utility of this procedure with a synthetic environment of sepsis management.},
  archivePrefix = {arXiv},
  eprint = {1905.05824},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Oberst, Sontag (2019) - Counterfactual Off-Policy Evaluation with Gumbel-Max Structural Causal Models.pdf},
  journal = {arXiv:1905.05824 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{oconnor2014PrimalDual,
  title = {Primal-{{Dual Decomposition}} by {{Operator Splitting}} and {{Applications}} to {{Image Deblurring}}},
  author = {O'Connor, Daniel and Vandenberghe, Lieven},
  year = {2014},
  month = jan,
  volume = {7},
  pages = {1724--1754},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/13094671X},
  abstract = {We present primal-dual decomposition algorithms for convex optimization problems with cost functions \$f(x)+g(Ax)\$, where \$f\$ and \$g\$ have inexpensive proximal operators and \$A\$ can be decomposed as a sum of two structured matrices. The methods are based on the Douglas--Rachford splitting algorithm applied to various splittings of the primal-dual optimality conditions. We discuss applications to image deblurring problems with nonquadratic data fidelity terms, different types of convex regularization, and simple convex constraints. In these applications, the primal-dual splitting approach allows us to handle general boundary conditions for the blurring operator. Numerical results indicate that the primal-dual splitting methods compare favorably with the alternating direction method of multipliers, the Douglas--Rachford algorithm applied to a reformulated primal problem, and the Chambolle--Pock primal-dual algorithm.},
  file = {/Users/yuekai/Documents/zotero/O'Connor, Vandenberghe (2014) - Primal-Dual Decomposition by Operator Splitting and Applications to Image.pdf},
  journal = {SIAM Journal on Imaging Sciences},
  number = {3}
}

@article{oglic2018Large,
  title = {Large {{Scale Learning}} with {{Kre}}\textbackslash u\{\textbackslash i\}n {{Kernels}}},
  author = {Oglic, Dino and G{\"a}rtner, Thomas},
  year = {2018},
  month = sep,
  abstract = {We extend the Nystr\textbackslash "om method for low-rank approximation of positive definite Mercer kernels to approximation of indefinite kernel matrices. Our result is the first derivation of the approach that does not require the positive definiteness of the kernel function. Building on this result, we then devise highly scalable methods for learning in reproducing kernel Kre\textbackslash u\{\textbackslash i\}n spaces. The main motivation for our work comes from problems with structured representations (e.g., graphs, strings, time-series), where it is relatively easy to devise a pairwise (dis)similarity function based on intuition/knowledge of a domain expert. Such pairwise functions are typically not positive definite and it is often well beyond the expertise of practitioners to verify this condition. The proposed large scale approaches for learning in reproducing kernel Kre\textbackslash u\{\textbackslash i\}n spaces provide principled and theoretically well-founded means to tackle this class of problems. The effectiveness of the approaches is evaluated empirically using kernels defined on structured and vectorial data representations.},
  archivePrefix = {arXiv},
  eprint = {1809.02157},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Oglic, Gärtner (2018) - Large Scale Learning with Kre-u -i n Kernels.pdf},
  journal = {arXiv:1809.02157 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{oglic2018Learning,
  title = {Learning in {{Reproducing Kernel Kre{\u \i}n Spaces}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Oglic, Dino and Gaertner, Thomas},
  year = {2018},
  month = jul,
  pages = {3859--3867},
  abstract = {We formulate a novel regularized risk minimization problem for learning in reproducing kernel Kre\{{\u \i}\}n spaces and show that the strong representer theorem applies to it. As a result of the latter, ...},
  file = {/Users/yuekai/Documents/zotero/Oglic, Gaertner (2018) - Learning in Reproducing Kernel Kreı̆n Spaces.pdf},
  language = {en}
}

@article{olkhovskaya2018Online,
  title = {Online {{Influence Maximization}} with {{Local Observations}}},
  author = {Olkhovskaya, Julia and Neu, Gergely and Lugosi, G{\'a}bor},
  year = {2018},
  month = may,
  abstract = {We consider an online influence maximization problem in which a decision maker selects a node among a large number of possibilities and places a piece of information at the node. The node transmits the information to some others that are in the same connected component in a random graph. The goal of the decision maker is to reach as many nodes as possible, with the added complication that feedback is only available about the degree of the selected node. Our main result shows that such local observations can be sufficient for maximizing global influence in two broadly studied families of random graph models: stochastic block models and Chung--Lu models. With this insight, we propose a bandit algorithm that aims at maximizing local (and thus global) influence, and provide its theoretical analysis in both the subcritical and supercritical regimes of both considered models. Notably, our performance guarantees show no explicit dependence on the total number of nodes in the network, making our approach well-suited for large-scale applications.},
  archivePrefix = {arXiv},
  eprint = {1805.11022},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Olkhovskaya et al (2018) - Online Influence Maximization with Local Observations.pdf},
  journal = {arXiv:1805.11022 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{ollier2015Regression,
  title = {Regression Modeling on Stratified Data with the Lasso},
  author = {Ollier, Edouard and Viallon, Vivian},
  year = {2015},
  month = aug,
  abstract = {We consider the estimation of regression models on strata defined using a categorical covariate, in order to identify interactions between this categorical covariate and the other predictors. A basic approach requires the choice of a reference stratum. We show that the performance of a penalized version of this approach depends on this arbitrary choice. We propose a refined approach that bypasses this arbitrary choice, at almost no additional computational cost. Regarding model selection consistency, our proposal mimics the strategy based on an optimal and covariate-specific choice for the reference stratum. Results from an empirical study confirm that our proposal generally outperforms the basic approach in the identification and description of the interactions. An illustration on gene expression data is provided.},
  archivePrefix = {arXiv},
  eprint = {1508.05476},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ollier, Viallon (2015) - Regression modeling on stratified data with the lasso.pdf},
  journal = {arXiv:1508.05476 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{onatski2012Asymptotics,
  title = {Asymptotics of the Principal Components Estimator of Large Factor Models with Weakly Influential Factors},
  author = {Onatski, Alexei},
  year = {2012},
  month = jun,
  volume = {168},
  pages = {244--258},
  issn = {0304-4076},
  doi = {10.1016/j.jeconom.2012.01.034},
  abstract = {This paper introduces a drifting-parameter asymptotic framework to derive accurate approximations to the finite sample distribution of the principal components (PC) estimator in situations when the factors' explanatory power does not strongly dominate the explanatory power of the cross-sectionally and temporally correlated idiosyncratic terms. Under our asymptotics, the PC estimator is inconsistent. We find explicit formulae for the amount of the inconsistency, and propose an estimator of the number of factors for which the PC estimator works reasonably well. For the special case when the idiosyncratic terms are cross-sectionally but not temporally correlated (or vice versa), we show that the coefficients in the OLS regressions of the PC estimates of factors (loadings) on the true factors (true loadings) are asymptotically normal, and find explicit formulae for the corresponding asymptotic covariance matrix. We explain how to estimate the parameters of the derived asymptotic distributions. Our Monte Carlo analysis suggests that our asymptotic formulae and estimators work well even for relatively small n and T. We apply our theoretical results to test a hypothesis about the factor content of the US stock return data.},
  file = {/Users/yuekai/Documents/zotero/Onatski (2012) - Asymptotics of the principal components estimator of large factor models with.pdf},
  journal = {Journal of Econometrics},
  number = {2}
}

@inproceedings{ong2004Learning,
  title = {Learning with Non-Positive Kernels},
  booktitle = {Twenty-First International Conference on {{Machine}} Learning  - {{ICML}} '04},
  author = {Ong, Cheng Soon and Mary, Xavier and Canu, St{\'e}phane and Smola, Alexander J.},
  year = {2004},
  pages = {81},
  publisher = {{ACM Press}},
  address = {{Banff, Alberta, Canada}},
  doi = {10.1145/1015330.1015443},
  abstract = {In this paper we show that many kernel methods can be adapted to deal with indefinite kernels, that is, kernels which are not positive semidefinite. They do not satisfy Mercer's condition and they induce associated functional spaces called Reproducing Kernel Kre\textasciibreve\i n Spaces (RKKS), a generalization of Reproducing Kernel Hilbert Spaces (RKHS).},
  file = {/Users/yuekai/Documents/zotero/Ong et al (2004) - Learning with non-positive kernels.pdf},
  language = {en}
}

@article{orbanz2015Bayesian,
  title = {Bayesian {{Models}} of {{Graphs}}, {{Arrays}} and {{Other Exchangeable Random Structures}}},
  author = {Orbanz, Peter and Roy, Daniel M.},
  year = {2015},
  month = feb,
  volume = {37},
  pages = {437--461},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2014.2334607},
  abstract = {The natural habitat of most Bayesian ever large? There are answers to these questions, and most methods is data represented by exchangeable sequences of them can be deduced from a single result, known as the of observations, for which de Finetti's theorem provides Aldous-Hoover theorem [3, 34], which gives a precise charthe theoretical foundation. Dirichlet process clustering, acterization of the conditional independence structure of Gaussian process regression, and many other parametric random graphs and arrays if they satisfy an exchangeabiland nonparametric Bayesian models fall within the remit ity property. Hoff [31] was the first to invoke this result in of this framework; many problems arising in modern data the machine learning literature.},
  file = {/Users/yuekai/Documents/zotero/Orbanz, Roy (2015) - Bayesian Models of Graphs, Arrays and Other Exchangeable Random Structures.pdf},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  language = {en},
  number = {2}
}

@article{orourke2013Random,
  title = {Random Perturbation of Low Rank Matrices: {{Improving}} Classical Bounds},
  shorttitle = {Random Perturbation of Low Rank Matrices},
  author = {O'Rourke, Sean and Vu, Van and Wang, Ke},
  year = {2013},
  month = nov,
  abstract = {Matrix perturbation inequalities, such as Weyl's theorem (concerning the singular values) and the Davis-Kahan theorem (concerning the singular vectors), play essential roles in quantitative science; in particular, these bounds have found application in data analysis as well as related areas of engineering and computer science. In many situations, the perturbation is assumed to be random, and the original matrix has certain structural properties (such as having low rank). We show that, in this scenario, classical perturbation results, such as Weyl and Davis-Kahan, can be improved significantly. We believe many of our new bounds are close to optimal and also discuss some applications.},
  archivePrefix = {arXiv},
  eprint = {1311.2657},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/O'Rourke et al (2013) - Random perturbation of low rank matrices.pdf},
  journal = {arXiv:1311.2657 [math, stat]},
  keywords = {Mathematics - Combinatorics,Mathematics - Numerical Analysis,Mathematics - Probability,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{orvieto2020Continuoustime,
  title = {Continuous-Time {{Models}} for {{Stochastic Optimization Algorithms}}},
  author = {Orvieto, Antonio and Lucchi, Aurelien},
  year = {2020},
  month = mar,
  abstract = {We propose new continuous-time formulations for first-order stochastic optimization algorithms such as mini-batch gradient descent and variance-reduced methods. We exploit these continuous-time models, together with simple Lyapunov analysis as well as tools from stochastic calculus, in order to derive convergence bounds for various types of non-convex functions. Guided by such analysis, we show that the same Lyapunov arguments hold in discrete-time, leading to matching rates. In addition, we use these models and Ito calculus to infer novel insights on the dynamics of SGD, proving that a decreasing learning rate acts as time warping or, equivalently, as landscape stretching.},
  archivePrefix = {arXiv},
  eprint = {1810.02565},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Orvieto, Lucchi (2020) - Continuous-time Models for Stochastic Optimization Algorithms.pdf},
  journal = {arXiv:1810.02565 [cs, math]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control},
  primaryClass = {cs, math}
}

@article{padakandla2019Reinforcement,
  title = {Reinforcement {{Learning}} in {{Non}}-{{Stationary Environments}}},
  author = {Padakandla, Sindhu and J, Prabuchandran K. and Bhatnagar, Shalabh},
  year = {2019},
  month = may,
  abstract = {Reinforcement learning (RL) methods learn optimal decisions in the presence of a stationary environment. However, the stationary assumption on the environment is very restrictive. In many real world problems like traffic signal control, robotic applications, one often encounters situations with non-stationary environments and in these scenarios, RL methods yield sub-optimal decisions. In this paper, we thus consider the problem of developing RL methods that obtain optimal decisions in a non-stationary environment. The goal of this problem is to maximize the long-term discounted reward achieved when the underlying model of the environment changes over time. To achieve this, we first adapt a change point algorithm to detect change in the statistics of the environment and then develop an RL algorithm that maximizes the long-run reward accrued. We illustrate that our change point method detects change in the model of the environment effectively and thus facilitates the RL algorithm in maximizing the long-run reward. We further validate the effectiveness of the proposed solution on non-stationary random Markov decision processes, a sensor energy management problem and a traffic signal control problem.},
  archivePrefix = {arXiv},
  eprint = {1905.03970},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Padakandla et al (2019) - Reinforcement Learning in Non-Stationary Environments.pdf},
  journal = {arXiv:1905.03970 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{pananjady2019Value,
  title = {Value Function Estimation in {{Markov}} Reward Processes: {{Instance}}-Dependent \$\textbackslash ell\_\textbackslash infty\$-Bounds for Policy Evaluation},
  shorttitle = {Value Function Estimation in {{Markov}} Reward Processes},
  author = {Pananjady, Ashwin and Wainwright, Martin J.},
  year = {2019},
  month = sep,
  abstract = {Markov reward processes (MRPs) are used to model stochastic phenomena arising in operations research, control engineering, robotics, artificial intelligence, as well as communication and transportation networks. In many of these cases, such as in the policy evaluation problem encountered in reinforcement learning, the goal is to estimate the long-term value function of such a process without access to the underlying population transition and reward functions. Working with samples generated under the synchronous model, we study the problem of estimating the value function of an infinite-horizon, discounted MRP in the \$\textbackslash ell\_\textbackslash infty\$-norm. We analyze both the standard plug-in approach to this problem and a more robust variant, and establish non-asymptotic bounds that depend on the (unknown) problem instance, as well as data-dependent bounds that can be evaluated based on the observed data. We show that these approaches are minimax-optimal up to constant factors over natural sub-classes of MRPs. Our analysis makes use of a leave-one-out decoupling argument tailored to the policy evaluation problem, one which may be of independent interest.},
  archivePrefix = {arXiv},
  eprint = {1909.08749},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Pananjady, Wainwright (2019) - Value function estimation in Markov reward processes.pdf},
  journal = {arXiv:1909.08749 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Mathematics - Probability,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{pang2019Improving,
  title = {Improving {{Adversarial Robustness}} via {{Promoting Ensemble Diversity}}},
  author = {Pang, Tianyu and Xu, Kun and Du, Chao and Chen, Ning and Zhu, Jun},
  year = {2019},
  month = jan,
  abstract = {Though deep neural networks have achieved significant progress on various tasks, often enhanced by model ensemble, existing high-performance models can be vulnerable to adversarial attacks. Many efforts have been devoted to enhancing the robustness of individual networks and then constructing a straightforward ensemble, e.g., by directly averaging the outputs, which ignores the interaction among networks. This paper presents a new method that explores the interaction among individual networks to improve robustness for ensemble models. Technically, we define a new notion of ensemble diversity in the adversarial setting as the diversity among non-maximal predictions of individual members, and present an adaptive diversity promoting (ADP) regularizer to encourage the diversity, which leads to globally better robustness for the ensemble by making adversarial examples difficult to transfer among individual members. Our method is computationally efficient and compatible with the defense methods acting on individual networks. Empirical results on various datasets verify that our method can improve adversarial robustness while maintaining state-of-the-art accuracy on normal examples.},
  archivePrefix = {arXiv},
  eprint = {1901.08846},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Pang et al (2019) - Improving Adversarial Robustness via Promoting Ensemble Diversity.pdf},
  journal = {arXiv:1901.08846 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{panigrahi2016Pliable,
  title = {Pliable {{Methods}} for {{Post}}-{{Selection Inference Under Convex Constraints}}},
  author = {Panigrahi, Snigdha and Taylor, Jonathan and Weinstein, Asaf},
  year = {2016},
  month = may,
  abstract = {Inference after model selection has been an active research topic in the past few years, with numerous works offering different approaches to addressing the problems associated with the reuse of data. In particular, major progress has been made recently on large and useful classes of problems by harnessing general theory of hypothesis testing in exponential families, but these methods have their limitations. Perhaps most immediate is the gap between theory and practice: implementing the exact theoretical prescription in realistic situations---for example, when new data arrives and inference needs to be adjusted accordingly---may turn out to be a prohibitive task. In this paper we develop methods for carrying out inference conditional on selection, which are more flexible in the sense that they naturally accommodate different models for the data, instead of requiring a case-by-case treatment. Our methods come at the price of offering only approximate inference, but we provide both theory and simulation examples to show that our specific approximation has competitive performance.},
  archivePrefix = {arXiv},
  eprint = {1605.08824},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Panigrahi et al (2016) - Pliable Methods for Post-Selection Inference Under Convex Constraints.pdf},
  journal = {arXiv:1605.08824 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{panigrahi2018Carving,
  title = {Carving Model-Free Inference},
  author = {Panigrahi, Snigdha},
  year = {2018},
  month = nov,
  abstract = {Many scientific studies are modeled as hierarchical procedures where the starting point of data-analysis is based on pilot samples that are employed to determine parameters of interest. With the availability of more data, the scientist is tasked with conducting a meta-analysis based on the augmented data-sets, that combines explorations from the pilot stage with a confirmatory study in the second stage. Casting these two-staged procedures into a conditional framework, inference is based on a carved likelihood. Such a likelihood is obtained in Fithian et al. (2014) by conditioning the law of the augmented data upon the selection carried out on the first stage data. Though the concept of carving is more general, the theory for valid inference in this previous work is strongly tied to parametric models for the data, an example being the ubiquitous Gaussian model. Our focus in the current paper is to take a step towards model-free inference while integrating explorations with fresh samples in a data-efficient manner. Towards this goal, we provide results that validate carved inference in an asymptotic regime for a broad class of parameters.},
  archivePrefix = {arXiv},
  eprint = {1811.03142},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Panigrahi (2018) - Carving model-free inference.pdf},
  journal = {arXiv:1811.03142 [math, stat]},
  keywords = {Mathematics - Probability,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{papernot2015Limitations,
  title = {The {{Limitations}} of {{Deep Learning}} in {{Adversarial Settings}}},
  author = {Papernot, Nicolas and McDaniel, Patrick and Jha, Somesh and Fredrikson, Matt and Celik, Z. Berkay and Swami, Ananthram},
  year = {2015},
  month = nov,
  abstract = {Deep learning takes advantage of large datasets and computationally efficient
training algorithms to outperform other approaches at various machine learning
tasks. However, imperfections in the training phase of deep neural networks
make them vulnerable to adversarial samples: inputs crafted by adversaries with
the intent of causing deep neural networks to misclassify. In this work, we
formalize the space of adversaries against deep neural networks (DNNs) and
introduce a novel class of algorithms to craft adversarial samples based on a
precise understanding of the mapping between inputs and outputs of DNNs. In an
application to computer vision, we show that our algorithms can reliably
produce samples correctly classified by human subjects but misclassified in
specific targets by a DNN with a 97\% adversarial success rate while only
modifying on average 4.02\% of the input features per sample. We then evaluate
the vulnerability of different sample classes to adversarial perturbations by
defining a hardness measure. Finally, we describe preliminary work outlining
defenses against adversarial samples by defining a predictive measure of
distance between a benign input and a target classification.},
  file = {/Users/yuekai/Documents/zotero/Papernot et al (2015) - The Limitations of Deep Learning in Adversarial Settings.pdf},
  language = {en}
}

@article{papernot2016Practical,
  title = {Practical {{Black}}-{{Box Attacks}} against {{Machine Learning}}},
  author = {Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z. Berkay and Swami, Ananthram},
  year = {2016},
  month = feb,
  abstract = {Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers. Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the first practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge. Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs. Our attack strategy consists in training a local model to substitute for the target DNN, using inputs synthetically generated by an adversary and labeled by the target DNN. We use the local substitute to craft adversarial examples, and find that they are misclassified by the targeted DNN. To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API. We find that their DNN misclassifies 84.24\% of the adversarial examples crafted with our substitute. We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes. They yield adversarial examples misclassified by Amazon and Google at rates of 96.19\% and 88.94\%. We also find that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder.},
  archivePrefix = {arXiv},
  eprint = {1602.02697},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Papernot et al (2016) - Practical Black-Box Attacks against Machine Learning.pdf},
  journal = {arXiv:1602.02697 [cs]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{papernot2016Science,
  title = {Towards the {{Science}} of {{Security}} and {{Privacy}} in {{Machine Learning}}},
  author = {Papernot, Nicolas and McDaniel, Patrick and Sinha, Arunesh and Wellman, Michael},
  year = {2016},
  month = nov,
  abstract = {Advances in machine learning (ML) in recent years have enabled a dizzying array of applications such as data analytics, autonomous systems, and security diagnostics. ML is now pervasive---new systems and models are being deployed in every domain imaginable, leading to rapid and widespread deployment of software based inference and decision making. There is growing recognition that ML exposes new vulnerabilities in software systems, yet the technical community's understanding of the nature and extent of these vulnerabilities remains limited. We systematize recent findings on ML security and privacy, focusing on attacks identified on these systems and defenses crafted to date. We articulate a comprehensive threat model for ML, and categorize attacks and defenses within an adversarial framework. Key insights resulting from works both in the ML and security communities are identified and the effectiveness of approaches are related to structural elements of ML algorithms and the data used to train them. We conclude by formally exploring the opposing relationship between model accuracy and resilience to adversarial manipulation. Through these explorations, we show that there are (possibly unavoidable) tensions between model complexity, accuracy, and resilience that must be calibrated for the environments in which they will be used.},
  archivePrefix = {arXiv},
  eprint = {1611.03814},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Papernot et al (2016) - Towards the Science of Security and Privacy in Machine Learning2.pdf},
  journal = {arXiv:1611.03814 [cs]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{papernot2016Transferability,
  title = {Transferability in {{Machine Learning}}: From {{Phenomena}} to {{Black}}-{{Box Attacks}} Using {{Adversarial Samples}}},
  shorttitle = {Transferability in {{Machine Learning}}},
  author = {Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian},
  year = {2016},
  month = may,
  abstract = {Many machine learning models are vulnerable to adversarial examples: inputs that are specially crafted to cause a machine learning model to produce an incorrect output. Adversarial examples that affect one model often affect another model, even if the two models have different architectures or were trained on different training sets, so long as both models were trained to perform the same task. An attacker may therefore train their own substitute model, craft adversarial examples against the substitute, and transfer them to a victim model, with very little information about the victim. Recent work has further developed a technique that uses the victim model as an oracle to label a synthetic training set for the substitute, so the attacker need not even collect a training set to mount the attack. We extend these recent techniques using reservoir sampling to greatly enhance the efficiency of the training procedure for the substitute model. We introduce new transferability attacks between previously unexplored (substitute, victim) pairs of machine learning model classes, most notably SVMs and decision trees. We demonstrate our attacks on two commercial machine learning classification systems from Amazon (96.19\% misclassification rate) and Google (88.94\%) using only 800 queries of the victim model, thereby showing that existing machine learning approaches are in general vulnerable to systematic black-box attacks regardless of their structure.},
  archivePrefix = {arXiv},
  eprint = {1605.07277},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Papernot et al (2016) - Transferability in Machine Learning.pdf},
  journal = {arXiv:1605.07277 [cs]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{papernot2018Deep,
  title = {Deep K-{{Nearest Neighbors}}: {{Towards Confident}}, {{Interpretable}} and {{Robust Deep Learning}}},
  shorttitle = {Deep K-{{Nearest Neighbors}}},
  author = {Papernot, Nicolas and McDaniel, Patrick},
  year = {2018},
  month = mar,
  abstract = {Deep neural networks (DNNs) enable innovative applications of machine learning like image recognition, machine translation, or malware detection. However, deep learning is often criticized for its lack of robustness in adversarial settings (e.g., vulnerability to adversarial inputs) and general inability to rationalize its predictions. In this work, we exploit the structure of deep learning to enable new learning-based inference and decision strategies that achieve desirable properties such as robustness and interpretability. We take a first step in this direction and introduce the Deep k-Nearest Neighbors (DkNN). This hybrid classifier combines the k-nearest neighbors algorithm with representations of the data learned by each layer of the DNN: a test input is compared to its neighboring training points according to the distance that separates them in the representations. We show the labels of these neighboring points afford confidence estimates for inputs outside the model's training manifold, including on malicious inputs like adversarial examples--and therein provides protections against inputs that are outside the models understanding. This is because the nearest neighbors can be used to estimate the nonconformity of, i.e., the lack of support for, a prediction in the training data. The neighbors also constitute human-interpretable explanations of predictions. We evaluate the DkNN algorithm on several datasets, and show the confidence estimates accurately identify inputs outside the model, and that the explanations provided by nearest neighbors are intuitive and useful in understanding model failures.},
  archivePrefix = {arXiv},
  eprint = {1803.04765},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Papernot, McDaniel (2018) - Deep k-Nearest Neighbors.pdf},
  journal = {arXiv:1803.04765 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{parikh2014Proximal,
  title = {Proximal {{Algorithms}}},
  author = {Parikh, Neal},
  year = {2014},
  volume = {1},
  pages = {127--239},
  issn = {2167-3888, 2167-3918},
  doi = {10.1561/2400000003},
  file = {/Users/yuekai/Documents/zotero/Parikh (2014) - Proximal Algorithms.pdf},
  journal = {Foundations and Trends\textregistered{} in Optimization},
  language = {en},
  number = {3}
}

@article{parisi2014Ranking,
  title = {Ranking and Combining Multiple Predictors without Labeled Data},
  author = {Parisi, Fabio and Strino, Francesco and Nadler, Boaz and Kluger, Yuval},
  year = {2014},
  month = jan,
  volume = {111},
  pages = {1253--1258},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1219097111},
  abstract = {In a broad range of classification and decision making problems, one is given the advice or predictions of several classifiers, of unknown reliability, over multiple questions or queries. This scenario is different from the standard supervised setting, where each classifier accuracy can be assessed using available labeled data, and raises two questions: given only the predictions of several classifiers over a large set of unlabeled test data, is it possible to a) reliably rank them; and b) construct a meta-classifier more accurate than most classifiers in the ensemble? Here we present a novel spectral approach to address these questions. First, assuming conditional independence between classifiers, we show that the off-diagonal entries of their covariance matrix correspond to a rank-one matrix. Moreover, the classifiers can be ranked using the leading eigenvector of this covariance matrix, as its entries are proportional to their balanced accuracies. Second, via a linear approximation to the maximum likelihood estimator, we derive the Spectral Meta-Learner (SML), a novel ensemble classifier whose weights are equal to this eigenvector entries. On both simulated and real data, SML typically achieves a higher accuracy than most classifiers in the ensemble and can provide a better starting point than majority voting, for estimating the maximum likelihood solution. Furthermore, SML is robust to the presence of small malicious groups of classifiers designed to veer the ensemble prediction away from the (unknown) ground truth.},
  archivePrefix = {arXiv},
  eprint = {1303.3257},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Parisi et al (2014) - Ranking and combining multiple predictors without labeled data.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  number = {4}
}

@article{parno2018Transport,
  title = {Transport Map Accelerated {{Markov}} Chain {{Monte Carlo}}},
  author = {Parno, Matthew and Marzouk, Youssef},
  year = {2018},
  month = jan,
  volume = {6},
  pages = {645--682},
  issn = {2166-2525},
  doi = {10.1137/17M1134640},
  abstract = {We introduce a new framework for efficient sampling from complex probability distributions, using a combination of optimal transport maps and the Metropolis-Hastings rule. The core idea is to use continuous transportation to transform typical Metropolis proposal mechanisms (e.g., random walks, Langevin methods) into non-Gaussian proposal distributions that can more effectively explore the target density. Our approach adaptively constructs a lower triangular transport map-an approximation of the Knothe-Rosenblatt rearrangement-using information from previous MCMC states, via the solution of an optimization problem. This optimization problem is convex regardless of the form of the target distribution. It is solved efficiently using a Newton method that requires no gradient information from the target probability distribution; the target distribution is instead represented via samples. Sequential updates enable efficient and parallelizable adaptation of the map even for large numbers of samples. We show that this approach uses inexact or truncated maps to produce an adaptive MCMC algorithm that is ergodic for the exact target distribution. Numerical demonstrations on a range of parameter inference problems show order-of-magnitude speedups over standard MCMC techniques, measured by the number of effectively independent samples produced per target density evaluation and per unit of wallclock time.},
  archivePrefix = {arXiv},
  eprint = {1412.5492},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Parno, Marzouk (2018) - Transport map accelerated Markov chain Monte Carlo.pdf},
  journal = {SIAM/ASA Journal on Uncertainty Quantification},
  keywords = {65C05; 28D05; 65C40,Statistics - Computation},
  number = {2}
}

@article{pass2013Optimal,
  title = {Optimal Transportation with Infinitely Many Marginals},
  author = {Pass, Brendan},
  year = {2013},
  month = feb,
  volume = {264},
  pages = {947--963},
  issn = {0022-1236},
  doi = {10.1016/j.jfa.2012.12.002},
  abstract = {We formulate and study an optimal transportation problem with infinitely many marginals; this is a natural extension of the multi-marginal problem studied by Gangbo and \'Swi\c{e}ch (1998) [15]. We prove results on the existence, uniqueness and characterization of the optimizer, which are natural extensions of the results in Gangbo and \'Swi\c{e}ch (1998) [15]. The proof relies on a relationship between this problem and the problem of finding barycenters in the Wasserstein space, a connection first observed for finitely many marginals by Agueh and Carlier (2011) [1].},
  file = {/Users/yuekai/Documents/zotero/Pass (2013) - Optimal transportation with infinitely many marginals.pdf},
  journal = {Journal of Functional Analysis},
  language = {en},
  number = {4}
}

@phdthesis{patel2018Use,
  title = {Use of the {{LASSO}} in Single and Multi-Cohort Genome-Wide Association Studies},
  author = {Patel, Virag},
  year = {2018},
  month = aug,
  abstract = {Over the past decade, there has been an ever growing interest in genome-wide association studies (GWAS). The role of GWAS is to discover associations between genetic variants; commonly Single Nucleotide Polymorphisms (SNPs) and complex diseases. Due to the ever increasing number of SNPs in GWAS, the commonly used association analyses tend to be univariate models rather than multivariate models. These methods are therefore unable to account for the correlation between SNPs; known as Linkage Disequilibrium (LD). 
Penalised regression methods have been suggested as an alternative method in GWAS, specifically the Least Absolute Shrinkage and Selection Operator (LASSO). This method has the ability to both shrink regression coefficients and perform variable selection. In this thesis, the use of the LASSO in both single and multi-cohort GWAS is examined. In the context of the single cohort, the LASSO is applied to the GRAPHIC study in an attempt to discover novel associations with Low-density Lipoprotein. This thesis will also address some of the problems with the LASSO such the tuning parameter selection method that should be used for SNP selection and the need for pruning to reduce the dimensionality of the data in order to fit LASSO models. The literature suggests that a pruning or pre-screening method is required to fit LASSO models in GWAS due to the high computational burden of fitting such a model, yet there is little work to address how the dataset should be pruned. A SNP pruning package in R called prune is developed and is utilised in a simulation study to determine which pruning method should be used. The role of the LASSO in multi-cohort studies is also considered specifically in integrative analyses. A new penalised regression method, the Integrative LASSO, is proposed and developed which uses a combination of LASSO, ridge regression and fused LASSO penalties and tested against some of the current methods in the literature in a simulation study.},
  file = {/Users/yuekai/Documents/zotero/Patel (2018) - Use of the LASSO in single and multi-cohort genome-wide association studies.pdf},
  language = {en},
  school = {Department of Cardiovascular Sciences},
  type = {Thesis}
}

@article{patil2018Training,
  title = {Training Replicable Predictors in Multiple Studies},
  author = {Patil, Prasad and Parmigiani, Giovanni},
  year = {2018},
  month = mar,
  volume = {115},
  pages = {2578--2583},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1708283115},
  abstract = {This article considers replicability of the performance of predictors across studies. We suggest a general approach to investigating this issue, based on ensembles of prediction models trained on different studies. We quantify how the common practice of training on a single study accounts in part for the observed challenges in replicability of prediction performance. We also investigate whether ensembles of predictors trained on multiple studies can be combined, using unique criteria, to design robust ensemble learners trained upfront to incorporate replicability into different contexts and populations.},
  file = {/Users/yuekai/Documents/zotero/Patil, Parmigiani (2018) - Training replicable predictors in multiple studies.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {11}
}

@article{patra2012Estimation,
  title = {Estimation of a {{Two}}-Component {{Mixture Model}} with {{Applications}} to {{Multiple Testing}}},
  author = {Patra, Rohit Kumar and Sen, Bodhisattva},
  year = {2012},
  month = apr,
  abstract = {We consider a two-component mixture model with one known component. We develop methods for estimating the mixing proportion and the unknown distribution nonparametrically, given i.i.d.\textasciitilde data from the mixture model, using ideas from shape restricted function estimation. We establish the consistency of our estimators. We find the rate of convergence and asymptotic limit of the estimator for the mixing proportion. Completely automated distribution-free honest finite sample lower confidence bounds are developed for the mixing proportion. Connection to the problem of multiple testing is discussed. The identifiability of the model, and the estimation of the density of the unknown distribution are also addressed. We compare the proposed estimators, which are easily implementable, with some of the existing procedures through simulation studies and analyse two data sets, one arising from an application in astronomy and the other from a microarray experiment.},
  archivePrefix = {arXiv},
  eprint = {1204.5488},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Patra, Sen (2012) - Estimation of a Two-component Mixture Model with Applications to Multiple.pdf},
  journal = {arXiv:1204.5488 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@book{pearl2009Causality,
  title = {Causality: {{Models}}, {{Reasoning}} and {{Inference}}},
  shorttitle = {Causality},
  author = {Pearl, Judea},
  year = {2009},
  edition = {Second},
  publisher = {{Cambridge University Press}},
  address = {{New York, NY, USA}},
  abstract = {Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studying the relationships between causal connections and statistical associations. The book will open the way for including causal analysis in the standard curricula of statistics, artificial intelligence, business, epidemiology, social sciences, and economics. Students in these fields will find natural models, simple inferential procedures, and precise mathematical definitions of causal concepts that traditional texts have evaded or made unduly complicated. The first edition of Causality has led to a paradigmatic change in the way that causality is treated in statistics, philosophy, computer science, social science, and economics. Cited in more than 3,000 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research. Causality will be of interests to students and professionals in a wide variety of fields. Anyone who wishes to elucidate meaningful relationships from data, predict effects of actions and policies, assess explanations of reported events, or form theories of causal understanding and causal speech will find this book stimulating and invaluable.},
  isbn = {978-0-521-89560-6}
}

@book{pearl2016Causal,
  title = {Causal {{Inference}} in {{Statistics}}: {{A Primer}}},
  shorttitle = {Causal {{Inference}} in {{Statistics}}},
  author = {Pearl, Judea and Glymour, Madelyn and Jewell, Nicholas P.},
  year = {2016},
  month = feb,
  publisher = {{John Wiley \& Sons}},
  abstract = {Many of the concepts and terminology surrounding modern causal inference can be quite intimidating to the novice. Judea Pearl presents a book ideal for beginners in statistics, providing a comprehensive introduction to the field of causality. Examples from classical statistics are presented throughout to demonstrate the need for causality in resolving decision-making dilemmas posed by data. Causal methods are also compared to traditional statistical methods, whilst questions are provided at the end of each section to aid student learning.},
  googlebooks = {IqCECwAAQBAJ},
  isbn = {978-1-119-18685-4},
  language = {en}
}

@article{pensky2016Dynamic,
  title = {Dynamic Network Models and Graphon Estimation},
  author = {Pensky, Marianna},
  year = {2016},
  month = jul,
  abstract = {In the present paper we consider a dynamic stochastic network model. The objective is estimation of the tensor of connection probabilities \$\textbackslash Lambda\$ when it is generated by a Dynamic Stochastic Block Model (DSBM) or a dynamic graphon. In particular, in the context of the DSBM, we derive a penalized least squares estimator \$\textbackslash widehat\{\textbackslash Lambda\}\$ of \$\textbackslash Lambda\$ and show that \$\textbackslash widehat\{\textbackslash Lambda\}\$ satisfies an oracle inequality and also attains minimax lower bounds for the risk. We extend those results to estimation of \$\textbackslash Lambda\$ when it is generated by a dynamic graphon function. The estimators constructed in the paper are adaptive to the unknown number of blocks in the context of the DSBM or to the smoothness of the graphon function. The technique relies on the vectorization of the model and leads to much simpler mathematical arguments than the ones used previously in the stationary set up. In addition, all results in the paper are non-asymptotic and allow a variety of extensions.},
  archivePrefix = {arXiv},
  eprint = {1607.00673},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Pensky (2016) - Dynamic network models and graphon estimation.pdf},
  journal = {arXiv:1607.00673 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{peters2015Causal,
  title = {Causal Inference Using Invariant Prediction: Identification and Confidence Intervals},
  shorttitle = {Causal Inference Using Invariant Prediction},
  author = {Peters, Jonas and B{\"u}hlmann, Peter and Meinshausen, Nicolai},
  year = {2015},
  month = nov,
  abstract = {What is the difference of a prediction that is made with a causal model and a non-causal model? Suppose we intervene on the predictor variables or change the whole environment. The predictions from a causal model will in general work as well under interventions as for observational data. In contrast, predictions from a non-causal model can potentially be very wrong if we actively intervene on variables. Here, we propose to exploit this invariance of a prediction under a causal model for causal inference: given different experimental settings (for example various interventions) we collect all models that do show invariance in their predictive accuracy across settings and interventions. The causal model will be a member of this set of models with high probability. This approach yields valid confidence intervals for the causal relationships in quite general scenarios. We examine the example of structural equation models in more detail and provide sufficient assumptions under which the set of causal predictors becomes identifiable. We further investigate robustness properties of our approach under model misspecification and discuss possible extensions. The empirical properties are studied for various data sets, including large-scale gene perturbation experiments.},
  archivePrefix = {arXiv},
  eprint = {1501.01332},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Peters et al (2015) - Causal inference using invariant prediction.pdf;/Users/yuekai/Zotero/storage/8JQZBCRX/1501.html},
  journal = {arXiv:1501.01332 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{peters2016Causal,
  title = {Causal Inference by Using Invariant Prediction: Identification and Confidence Intervals},
  shorttitle = {Causal Inference by Using Invariant Prediction},
  author = {Peters, Jonas and B{\"u}hlmann, Peter and Meinshausen, Nicolai},
  year = {2016},
  month = nov,
  volume = {78},
  pages = {947--1012},
  issn = {13697412},
  doi = {10.1111/rssb.12167},
  abstract = {What is the difference between a prediction that is made with a causal model and that with a non-causal model? Suppose that we intervene on the predictor variables or change the whole environment. The predictions from a causal model will in general work as well under interventions as for observational data. In contrast, predictions from a non-causal model can potentially be very wrong if we actively intervene on variables. Here, we propose to exploit this invariance of a prediction under a causal model for causal inference: given different experimental settings (e.g. various interventions) we collect all models that do show invariance in their predictive accuracy across settings and interventions. The causal model will be a member of this set of models with high probability. This approach yields valid confidence intervals for the causal relationships in quite general scenarios. We examine the example of structural equation models in more detail and provide sufficient assumptions under which the set of causal predictors becomes identifiable. We further investigate robustness properties of our approach under model misspecification and discuss possible extensions. The empirical properties are studied for various data sets, including large-scale gene perturbation experiments.},
  file = {/Users/yuekai/Documents/zotero/Peters et al (2016) - Causal inference by using invariant prediction.pdf},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  language = {en},
  number = {5}
}

@book{peters2017Elements,
  title = {Elements of {{Causal Inference}}: {{Foundations}} and {{Learning Algorithms}}},
  shorttitle = {Elements of {{Causal Inference}}},
  author = {Peters, Jonas and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
  year = {2017},
  month = nov,
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachuestts}},
  abstract = {A concise and self-contained introduction to causal inference, increasingly important in data science and machine learning.The mathematization of causality is a relatively recent development, and has become increasingly important in data science and machine learning. This book offers a self-contained and concise introduction to causal models and how to learn them from data.After explaining the need for causal models and discussing some of the principles underlying causal inference, the book teaches readers how to use causal models: how to compute intervention distributions, how to infer causal models from observational and interventional data, and how causal ideas could be exploited for classical machine learning problems. All of these topics are discussed first in terms of two variables and then in the more general multivariate case. The bivariate case turns out to be a particularly hard problem for causal learning because there are no conditional independences as used by classical methods for solving multivariate cases. The authors consider analyzing statistical asymmetries between cause and effect to be highly instructive, and they report on their decade of intensive research into this problem. The book is accessible to readers with a background in machine learning or statistics, and can be used in graduate courses or as a reference for researchers. The text includes code snippets that can be copied and pasted, exercises, and an appendix with a summary of the most important technical concepts.},
  file = {/Users/yuekai/Documents/zotero/Peters et al (2017) - Elements of Causal Inference.pdf},
  isbn = {978-0-262-03731-0},
  language = {English}
}

@article{petzold2006Sensitivity,
  title = {Sensitivity Analysis of Differential-Algebraic Equations and Partial Differential Equations},
  author = {Petzold, Linda and Li, Shengtai and Cao, Yang and Serban, Radu},
  year = {2006},
  month = sep,
  volume = {30},
  pages = {1553--1559},
  issn = {0098-1354},
  doi = {10.1016/j.compchemeng.2006.05.015},
  abstract = {Sensitivity analysis generates essential information for model development, design optimization, parameter estimation, optimal control, model reduction and experimental design. In this paper we describe the forward and adjoint methods for sensitivity analysis, and outline some of our recent work on theory, algorithms and software for sensitivity analysis of differential-algebraic equation (DAE) and time-dependent partial differential equation (PDE) systems.},
  file = {/Users/yuekai/Documents/zotero/Petzold et al (2006) - Sensitivity analysis of differential-algebraic equations and partial.pdf},
  journal = {Computers \& Chemical Engineering},
  language = {en},
  number = {10},
  series = {Papers Form {{Chemical Process Control VII}}}
}

@article{peyre2018Computational,
  title = {Computational {{Optimal Transport}}},
  author = {Peyr{\'e}, Gabriel and Cuturi, Marco},
  year = {2018},
  month = mar,
  abstract = {Optimal transport (OT) theory can be informally described using the words of the French mathematician Gaspard Monge (1746-1818): A worker with a shovel in hand has to move a large pile of sand lying on a construction site. The goal of the worker is to erect with all that sand a target pile with a prescribed shape (for example, that of a giant sand castle). Naturally, the worker wishes to minimize her total effort, quantified for instance as the total distance or time spent carrying shovelfuls of sand. Mathematicians interested in OT cast that problem as that of comparing two probability distributions, two different piles of sand of the same volume. They consider all of the many possible ways to morph, transport or reshape the first pile into the second, and associate a "global" cost to every such transport, using the "local" consideration of how much it costs to move a grain of sand from one place to another. Recent years have witnessed the spread of OT in several fields, thanks to the emergence of approximate solvers that can scale to sizes and dimensions that are relevant to data sciences. Thanks to this newfound scalability, OT is being increasingly used to unlock various problems in imaging sciences (such as color or texture processing), computer vision and graphics (for shape manipulation) or machine learning (for regression, classification and density fitting). This short book reviews OT with a bias toward numerical methods and their applications in data sciences, and sheds lights on the theoretical properties of OT that make it particularly useful for some of these applications.},
  archivePrefix = {arXiv},
  eprint = {1803.00567},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Peyré, Cuturi (2018) - Computational Optimal Transport.pdf},
  journal = {arXiv:1803.00567 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{pfender2004Kissing,
  title = {Kissing {{Numbers}}, {{Sphere Packings}}, and {{Some Unexpected Proofs}}},
  author = {Pfender, Florian and Ziegler, G{\"u}nter M},
  year = {2004},
  pages = {11},
  file = {/Users/yuekai/Documents/zotero/Pfender, Ziegler (2004) - Kissing Numbers, Sphere Packings, and Some Unexpected Proofs.pdf},
  language = {en}
}

@article{pfister2019Stabilizing,
  title = {Stabilizing {{Variable Selection}} and {{Regression}}},
  author = {Pfister, Niklas and Williams, Evan G. and Peters, Jonas and Aebersold, Ruedi and B{\"u}hlmann, Peter},
  year = {2019},
  month = nov,
  abstract = {We consider regression in which one predicts a response \$Y\$ with a set of predictors \$X\$ across different experiments or environments. This is a common setup in many data-driven scientific fields and we argue that statistical inference can benefit from an analysis that takes into account the distributional changes across environments. In particular, it is useful to distinguish between stable and unstable predictors, i.e., predictors which have a fixed or a changing functional dependence on the response, respectively. We introduce stabilized regression which explicitly enforces stability and thus improves generalization performance to previously unseen environments. Our work is motivated by an application in systems biology. Using multiomic data, we demonstrate how hypothesis generation about gene function can benefit from stabilized regression. We believe that a similar line of arguments for exploiting heterogeneity in data can be powerful for many other applications as well. We draw a theoretical connection between multi-environment regression and causal models, which allows to graphically characterize stable versus unstable functional dependence on the response. Formally, we introduce the notion of a stable blanket which is a subset of the predictors that lies between the direct causal predictors and the Markov blanket. We prove that this set is optimal in the sense that a regression based on these predictors minimizes the mean squared prediction error given that the resulting regression generalizes to unseen new environments.},
  archivePrefix = {arXiv},
  eprint = {1911.01850},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Pfister et al (2019) - Stabilizing Variable Selection and Regression.pdf},
  journal = {arXiv:1911.01850 [stat]},
  keywords = {Statistics - Applications,Statistics - Methodology},
  primaryClass = {stat}
}

@article{pierson2017Fast,
  title = {Fast {{Threshold Tests}} for {{Detecting Discrimination}}},
  author = {Pierson, Emma and {Corbett-Davies}, Sam and Goel, Sharad},
  year = {2017},
  month = feb,
  abstract = {Threshold tests have recently been proposed as a useful method for detecting bias in lending, hiring, and policing decisions. For example, in the case of credit extensions, these tests aim to estimate the bar for granting loans to white and minority applicants, with a higher inferred threshold for minorities indicative of discrimination. This technique, however, requires fitting a complex Bayesian latent variable model for which inference is often computationally challenging. Here we develop a method for fitting threshold tests that is two orders of magnitude faster than the existing approach, reducing computation from hours to minutes. To achieve these performance gains, we introduce and analyze a flexible family of probability distributions on the interval [0, 1] -- which we call discriminant distributions -- that is computationally efficient to work with. We demonstrate our technique by analyzing 2.7 million police stops of pedestrians in New York City.},
  archivePrefix = {arXiv},
  eprint = {1702.08536},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Pierson et al (2017) - Fast Threshold Tests for Detecting Discrimination.pdf},
  journal = {arXiv:1702.08536 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{pilanci2014Iterative,
  title = {Iterative {{Hessian}} Sketch: {{Fast}} and Accurate Solution Approximation for Constrained Least-Squares},
  shorttitle = {Iterative {{Hessian}} Sketch},
  author = {Pilanci, Mert and Wainwright, Martin J.},
  year = {2014},
  month = nov,
  abstract = {We study randomized sketching methods for approximately solving least-squares problem with a general convex constraint. The quality of a least-squares approximation can be assessed in different ways: either in terms of the value of the quadratic objective function (cost approximation), or in terms of some distance measure between the approximate minimizer and the true minimizer (solution approximation). Focusing on the latter criterion, our first main result provides a general lower bound on any randomized method that sketches both the data matrix and vector in a least-squares problem; as a surprising consequence, the most widely used least-squares sketch is sub-optimal for solution approximation. We then present a new method known as the iterative Hessian sketch, and show that it can be used to obtain approximations to the original least-squares problem using a projection dimension proportional to the statistical complexity of the least-squares minimizer, and a logarithmic number of iterations. We illustrate our general theory with simulations for both unconstrained and constrained versions of least-squares, including \$\textbackslash ell\_1\$-regularization and nuclear norm constraints. We also numerically demonstrate the practicality of our approach in a real face expression classification experiment.},
  archivePrefix = {arXiv},
  eprint = {1411.0347},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Pilanci, Wainwright (2014) - Iterative Hessian sketch.pdf},
  journal = {arXiv:1411.0347 [cs, math, stat]},
  keywords = {Computer Science - Information Theory,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{piquero2008Assessing,
  title = {Assessing the {{Race}}\textendash{{Crime}} and {{Ethnicity}}\textendash{{Crime Relationship}} in a {{Sample}} of {{Serious Adolescent Delinquents}}},
  author = {Piquero, Alex R. and Brame, Robert W.},
  year = {2008},
  month = jul,
  volume = {54},
  pages = {390--422},
  issn = {0011-1287},
  doi = {10.1177/0011128707307219},
  abstract = {Official record studies consistently show that Blacks exhibit higher levels of involvement in criminal offending than Whites do. Although self-report studies suggest somewhat lower levels of Black overrepresentation in criminal offending activity (especially with less serious forms of crime), there appears to be considerable evidence that Blacks are disproportionately involved in serious crime. Yet most of this evidence is based on data from broad cross-sections of the general population. To date, there is little evidence on which to base inferences about the relationship between race and criminal involvement within serious offender populations. In this article, the authors use both official record and self-report data on samples of serious adolescent offenders in Philadelphia and Phoenix to reach a better understanding of the relationship between race and criminal activity. The analysis suggests that consistent race differences of the kind normally seen in the criminological literature are not evident in our sample of serious offenders.},
  file = {/Users/yuekai/Documents/zotero/Piquero, Brame (2008) - Assessing the Race–Crime and Ethnicity–Crime Relationship in a Sample of.pdf},
  journal = {Crime and delinquency},
  number = {3},
  pmcid = {PMC2782848},
  pmid = {19946564}
}

@inproceedings{pleiss2017fairness,
  title = {On Fairness and Calibration},
  booktitle = {Proceedings of the 31st {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Pleiss, Geoff and Raghavan, Manish and Wu, Felix and Kleinberg, Jon and Weinberger, Kilian Q.},
  year = {2017},
  month = dec,
  pages = {5684--5693},
  publisher = {{Curran Associates Inc.}},
  address = {{Long Beach, California, USA}},
  abstract = {The machine learning community has become increasingly concerned with the potential for bias and discrimination in predictive models. This has motivated a growing line of work on what it means for a classification procedure to be "fair." In this paper, we investigate the tension between minimizing error disparity across different population groups while maintaining calibrated probability estimates. We show that calibration is compatible only with a single error constraint (i.e. equal false-negatives rates across groups), and show that any algorithm that satisfies this relaxation is no better than randomizing a percentage of predictions for an existing classifier. These unsettling findings, which extend and generalize existing results, are empirically confirmed on several datasets.},
  file = {/Users/yuekai/Documents/zotero/Pleiss et al (2017) - On fairness and calibration.pdf},
  isbn = {978-1-5108-6096-4},
  series = {{{NIPS}}'17}
}

@article{plessis2012SemiSupervised,
  title = {Semi-{{Supervised Learning}} of {{Class Balance}} under {{Class}}-{{Prior Change}} by {{Distribution Matching}}},
  author = {Plessis, Marthinus Du and Sugiyama, Masashi},
  year = {2012},
  month = jun,
  abstract = {In real-world classification problems, the class balance in the training dataset does not necessarily reflect that of the test dataset, which can cause significant estimation bias. If the class ratio of the test dataset is known, instance re-weighting or resampling allows systematical bias correction. However, learning the class ratio of the test dataset is challenging when no labeled data is available from the test domain. In this paper, we propose to estimate the class ratio in the test dataset by matching probability distributions of training and test input data. We demonstrate the utility of the proposed approach through experiments.},
  archivePrefix = {arXiv},
  eprint = {1206.4677},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Plessis, Sugiyama (2012) - Semi-Supervised Learning of Class Balance under Class-Prior Change by.pdf;/Users/yuekai/Zotero/storage/3R6VECPI/1206.html},
  journal = {arXiv:1206.4677 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@book{politis2013Subsampling,
  title = {Subsampling},
  author = {Politis, Dimitris N},
  year = {2013},
  publisher = {{Springer}},
  address = {{Place of publication not identified}},
  annotation = {OCLC: 968636509},
  file = {/Users/yuekai/Documents/zotero/Politis (2013) - Subsampling.pdf},
  isbn = {978-1-4612-1554-7},
  language = {en}
}

@article{powell1989Semiparametric,
  title = {Semiparametric {{Estimation}} of {{Index Coefficients}}},
  author = {Powell, James L. and Stock, James H. and Stoker, Thomas M.},
  year = {1989},
  month = nov,
  volume = {57},
  pages = {1403},
  issn = {00129682},
  doi = {10.2307/1913713},
  abstract = {This papergives a solutionto the problemof estimatingcoefficientsof index models, throughthe estimationof the density-weightedaveragederivativeof a generalregression function.We showhow a normalizedversionof the density-weightedaveragederivatives can be estimatedby certainlinearinstrumentavlariablescoefficientsB. othof the estimators are computationallysimple,root-N-consistenatnd asymptoticallynormal;theirstatistical propertiesdo not relyon functionalformassumptionson the regressionfunctionor the distributionof the data. The estimatorsb, ased on sampleanaloguesof the product moment representationof the averagederivative,are constructedusing nonparametric kernelestimatorsof thedensityof theregressorsA. symptoticnormalityis establishedusing extensionsof classicalU-statistictheoremsa, ndasymptoticbiasis reducedthroughuseof a higher-orderkernel.Consistentestimatorsof the asymptoticvariance-covariancmeatrices of the estimatorsare given,and a limitedMonte Carlosimulationis used to study the practicalperformanceof theprocedures.},
  file = {/Users/yuekai/Documents/zotero/Powell et al (1989) - Semiparametric Estimation of Index Coefficients.pdf},
  journal = {Econometrica},
  language = {en},
  number = {6}
}

@article{prabhat2012TECA,
  title = {{{TECA}}: {{A Parallel Toolkit}} for {{Extreme Climate Analysis}}},
  shorttitle = {{{TECA}}},
  author = {{Prabhat} and R{\"u}bel, Oliver and Byna, Surendra and Wu, Kesheng and Li, Fuyu and Wehner, Michael and Bethel, Wes},
  year = {2012},
  month = jan,
  volume = {9},
  pages = {866--876},
  issn = {1877-0509},
  doi = {10.1016/j.procs.2012.04.093},
  abstract = {We present TECA, a parallel toolkit for detecting extreme events in large climate datasets. Modern climate datasets expose parallelism across a number of dimensions: spatial locations, timesteps and ensemble members. We design TECA to exploit these modes of parallelism and demonstrate a prototype implementation for detecting and tracking three classes of extreme events: tropical cyclones, extra-tropical cyclones and atmospheric rivers. We process a modern TB-sized CAM5 simulation dataset with TECA, and demonstrate good runtime performance for the three case studies.},
  file = {/Users/yuekai/Documents/zotero/Prabhat et al (2012) - TECA.pdf},
  journal = {Procedia Computer Science},
  language = {en},
  series = {Proceedings of the {{International Conference}} on {{Computational Science}}, {{ICCS}} 2012}
}

@article{press2009Bandita,
  title = {Bandit Solutions Provide Unified Ethical Models for Randomized Clinical Trials and Comparative Effectiveness Research},
  author = {Press, William H.},
  year = {2009},
  month = dec,
  volume = {106},
  pages = {22387--22392},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0912378106},
  file = {/Users/yuekai/Documents/zotero/Press (2009) - Bandit solutions provide unified ethical models for randomized clinical trials.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {52}
}

@article{prost2019Debiasing,
  title = {Debiasing {{Embeddings}} for {{Reduced Gender Bias}} in {{Text Classification}}},
  author = {Prost, Flavien and Thain, Nithum and Bolukbasi, Tolga},
  year = {2019},
  month = aug,
  abstract = {(Bolukbasi et al., 2016) demonstrated that pretrained word embeddings can inherit gender bias from the data they were trained on. We investigate how this bias affects downstream classification tasks, using the case study of occupation classification (De-Arteaga et al.,2019). We show that traditional techniques for debiasing embeddings can actually worsen the bias of the downstream classifier by providing a less noisy channel for communicating gender information. With a relatively minor adjustment, however, we show how these same techniques can be used to simultaneously reduce bias and maintain high classification accuracy.},
  archivePrefix = {arXiv},
  eprint = {1908.02810},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Prost et al (2019) - Debiasing Embeddings for Reduced Gender Bias in Text Classification.pdf},
  journal = {arXiv:1908.02810 [cs, stat]},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{pujol2020Fair,
  ids = {kuppam2019Fair},
  title = {Fair {{Decision Making Using Privacy}}-{{Protected Data}}},
  author = {Pujol, David and McKenna, Ryan and Kuppam, Satya and Hay, Michael and Machanavajjhala, Ashwin and Miklau, Gerome},
  year = {2020},
  pages = {11},
  abstract = {Data collected about individuals is regularly used to make decisions that impact those same individuals. We consider settings where sensitive personal data is used to decide who will receive resources or benefits. While it is well known that there is a tradeoff between protecting privacy and the accuracy of decisions, we initiate a first-of-its-kind study into the impact of formally private mechanisms (based on differential privacy) on fair and equitable decision-making. We empirically investigate novel tradeoffs on two real-world decisions made using U.S. Census data (allocation of federal funds and assignment of voting rights benefits) as well as a classic apportionment problem.},
  archivePrefix = {arXiv},
  eprint = {1905.12744},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Pujol et al (2020) - Fair Decision Making Using Privacy-Protected Data.pdf},
  keywords = {Computer Science - Databases},
  language = {en}
}

@misc{puri2018Mitigating,
  title = {Mitigating {{Bias}} in {{Artificial Intelligence}} ({{AI}}) {{Models}} -- {{IBM Research}}},
  author = {Puri, Ruchi},
  year = {2018},
  month = feb,
  abstract = {IBM is committed to delivering AI services that are unbiased, explainable, value aligned, and transparent, including Watson Visual recognition service.},
  copyright = {\textcopyright{} Copyright IBM Corp. 2019},
  howpublished = {www.ibm.com/blogs/research/2018/02/mitigating-bias-ai-models/},
  journal = {IBM Research Blog},
  language = {en-US}
}

@book{puterman2005Markov,
  title = {Markov Decision Processes: Discrete Stochastic Dynamic Programming},
  shorttitle = {Markov Decision Processes},
  author = {Puterman, Martin L.},
  year = {2005},
  publisher = {{Wiley-Interscience}},
  address = {{Hoboken, NJ}},
  annotation = {OCLC: 254152847},
  file = {/Users/yuekai/Documents/zotero/Puterman (2005) - Markov decision processes.pdf},
  isbn = {978-0-471-72782-8},
  language = {en},
  series = {Wiley Series in Probability and Statistics}
}

@article{qian2019Global,
  title = {Global {{Convergence}} of {{Least Squares EM}} for {{Demixing Two Log}}-{{Concave Densities}}},
  author = {Qian, Wei and Zhang, Yuqian and Chen, Yudong},
  year = {2019},
  month = jun,
  abstract = {This work studies the location estimation problem for a mixture of two rotation invariant log-concave densities. We demonstrate that Least Squares EM, a variant of the EM algorithm, converges to the true location parameter from a randomly initialized point. We establish the explicit convergence rates and sample complexity bounds, revealing their dependence on the signal-to-noise ratio and the tail property of the log-concave distribution. Moreover, we show that this global convergence property is robust under model mis-specification. Our analysis generalizes previous techniques for proving the convergence results for Gaussian mixtures. In particular, we make use of an angle-decreasing property for establishing global convergence of Least Squares EM beyond Gaussian settings, as \$\textbackslash ell\_2\$ distance contraction no longer holds globally for general log-concave mixtures.},
  archivePrefix = {arXiv},
  eprint = {1906.06776},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Qian et al (2019) - Global Convergence of Least Squares EM for Demixing Two Log-Concave Densities.pdf},
  journal = {arXiv:1906.06776 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{qin2019Imperceptible,
  title = {Imperceptible, {{Robust}}, and {{Targeted Adversarial Examples}} for {{Automatic Speech Recognition}}},
  author = {Qin, Yao and Carlini, Nicholas and Goodfellow, Ian and Cottrell, Garrison and Raffel, Colin},
  year = {2019},
  month = mar,
  abstract = {Adversarial examples are inputs to machine learning models designed by an adversary to cause an incorrect output. So far, adversarial examples have been studied most extensively in the image domain. In this domain, adversarial examples can be constructed by imperceptibly modifying images to cause misclassification, and are practical in the physical world. In contrast, current targeted adversarial examples applied to speech recognition systems have neither of these properties: humans can easily identify the adversarial perturbations, and they are not effective when played over-the-air. This paper makes advances on both of these fronts. First, we develop effectively imperceptible audio adversarial examples (verified through a human study) by leveraging the psychoacoustic principle of auditory masking, while retaining 100\% targeted success rate on arbitrary full-sentence targets. Next, we make progress towards physical-world over-the-air audio adversarial examples by constructing perturbations which remain effective even after applying realistic simulated environmental distortions.},
  archivePrefix = {arXiv},
  eprint = {1903.10346},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Qin et al (2019) - Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech.pdf},
  journal = {arXiv:1903.10346 [cs, eess, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing,Statistics - Machine Learning},
  primaryClass = {cs, eess, stat}
}

@article{qu2004Assessing,
  title = {Assessing Robustness of Generalised Estimating Equations and Quadratic Inference Functions},
  author = {Qu, A.},
  year = {2004},
  month = jun,
  volume = {91},
  pages = {447--459},
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/91.2.447},
  abstract = {In the presence of data contamination or outliers, some empirical studies have indicated that the two methods of generalised estimating equations and quadratic inference functions appear to have rather different robustness behaviour. This paper presents a theoretical investigation from the perspective of the influence function to identify the causes for the difference. We show that quadratic inference functions lead to bounded influence functions and the corresponding M-estimator has a redescending property, but the generalised estimating equation approach does not. We also illustrate that, unlike generalised estimating equations, quadratic inference functions can still provide consistent estimators even if part of the data is contaminated. We conclude that the quadratic inference function is a preferable method to the generalised estimating equation as far as robustness is concerned. This conclusion is supported by simulations and real-data examples.},
  file = {/Users/yuekai/Documents/zotero/Qu (2004) - Assessing robustness of generalised estimating equations and quadratic.pdf},
  journal = {Biometrika},
  language = {en},
  number = {2}
}

@article{quillian2017Metaanalysis,
  title = {Meta-Analysis of Field Experiments Shows No Change in Racial Discrimination in Hiring over Time},
  author = {Quillian, Lincoln and Pager, Devah and Hexel, Ole and Midtb{\o}en, Arnfinn H.},
  year = {2017},
  month = oct,
  volume = {114},
  pages = {10870--10875},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1706255114},
  abstract = {This study investigates change over time in the level of hiring discrimination in US labor markets. We perform a meta-analysis of every available field experiment of hiring discrimination against African Americans or Latinos (n = 28). Together, these studies represent 55,842 applications submitted for 26,326 positions. We focus on trends since 1989 (n = 24 studies), when field experiments became more common and improved methodologically. Since 1989, whites receive on average 36\% more callbacks than African Americans, and 24\% more callbacks than Latinos. We observe no change in the level of hiring discrimination against African Americans over the past 25 years, although we find modest evidence of a decline in discrimination against Latinos. Accounting for applicant education, applicant gender, study method, occupational groups, and local labor market conditions does little to alter this result. Contrary to claims of declining discrimination in American society, our estimates suggest that levels of discrimination remain largely unchanged, at least at the point of hire.},
  copyright = {\textcopyright{}  . Freely available online through the PNAS open access option.},
  file = {/Users/yuekai/Documents/zotero/Quillian et al (2017) - Meta-analysis of field experiments shows no change in racial discrimination in.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {41},
  pmid = {28900012}
}

@article{quio2008Constraint,
  title = {Constraint Qualifications for Nonlinear Programming},
  author = {Quio, Rodrigo G Eusta and Karas, Elizabeth W and Ribeiro, Ademir A},
  year = {2008},
  month = nov,
  pages = {12},
  abstract = {This paper deals with optimality conditions to solve nonlinear programming problems. The classical Karush-Kuhn-Tucker (KKT) optimality conditions are demonstrated through a cone approach, using the well known Farkas' Lemma. These conditions are valid at a minimizer of a nonlinear programming problem if a constraint qualification is satisfied. First we prove the KKT theorem supposing the equality between the polar of the tangent cone and the polar of the first order feasible variations cone. Although this condition is the weakest assumption, it is extremely difficult to be verified. Therefore, other constraints qualifications, which are easier to be verified, are studied, as: Slater's, linear independence of gradients, Mangasarian-Fromovitz's and quasiregularity. The relations among them are discussed.},
  file = {/Users/yuekai/Documents/zotero/Quio et al (2008) - CONSTRAINT QUALIFICATIONS FOR NONLINEAR PROGRAMMING.pdf},
  language = {en}
}

@inproceedings{rabin2012Wasserstein,
  title = {Wasserstein {{Barycenter}} and {{Its Application}} to {{Texture Mixing}}},
  booktitle = {Scale {{Space}} and {{Variational Methods}} in {{Computer Vision}}},
  author = {Rabin, Julien and Peyr{\'e}, Gabriel and Delon, Julie and Bernot, Marc},
  editor = {Bruckstein, Alfred M. and {ter Haar Romeny}, Bart M. and Bronstein, Alexander M. and Bronstein, Michael M.},
  year = {2012},
  pages = {435--446},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-24785-9_37},
  abstract = {This paper proposes a new definition of the averaging of discrete probability distributions as a barycenter over the Monge-Kantorovich optimal transport space. To overcome the time complexity involved by the numerical solving of such problem, the original Wasserstein metric is replaced by a sliced approximation over 1D distributions. This enables us to introduce a new fast gradient descent algorithm to compute Wasserstein barycenters of point clouds.This new notion of barycenter of probabilities is likely to find applications in computer vision where one wants to average features defined as distributions. We show an application to texture synthesis and mixing, where a texture is characterized by the distribution of the response to a multi-scale oriented filter bank. This leads to a simple way to navigate over a convex domain of color textures.},
  file = {/Users/yuekai/Documents/zotero/Rabin et al (2012) - Wasserstein Barycenter and Its Application to Texture Mixing.pdf},
  isbn = {978-3-642-24785-9},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@article{rabinovich2020Optimal,
  title = {Optimal {{Rates}} and {{Tradeoffs}} in {{Multiple Testing}}},
  author = {Rabinovich, Maxim and Ramdas, Aaditya and Jordan, Michael I. and Wainwright, Martin J.},
  year = {2020},
  issn = {10170405},
  doi = {10.5705/ss.202017.0468},
  abstract = {Multiple hypothesis testing is a central topic in statistics, but despite abundant work on the false discovery rate (FDR) and the corresponding Type-II error concept known as the false non-discovery rate (FNR), a fine-grained understanding of the fundamental limits of multiple testing has not been developed. Our main contribution is to derive a precise non-asymptotic tradeoff between FNR and FDR for a variant of the generalized Gaussian sequence model. Our analysis is flexible enough to permit analyses of settings where the problem parameters vary with the number of hypotheses n, including various sparse and dense regimes (with o(n) and O(n) signals). Moreover, we prove that the Benjamini-Hochberg algorithm as well as the BarberCand`es algorithm are both rate-optimal up to constants across these regimes.},
  file = {/Users/yuekai/Documents/zotero/Rabinovich et al (2020) - Optimal Rates and Tradeoffs in Multiple Testing.pdf},
  journal = {Statistica Sinica},
  language = {en}
}

@article{racah2017ExtremeWeather,
  title = {{{ExtremeWeather}}: {{A}} Large-Scale Climate Dataset for Semi-Supervised Detection, Localization, and Understanding of Extreme Weather Events},
  shorttitle = {{{ExtremeWeather}}},
  author = {Racah, Evan and Beckham, Christopher and Maharaj, Tegan and Kahou, Samira Ebrahimi and Prabhat and Pal, Christopher},
  year = {2017},
  month = nov,
  abstract = {Then detection and identification of extreme weather events in large-scale climate simulations is an important problem for risk management, informing governmental policy decisions and advancing our basic understanding of the climate system. Recent work has shown that fully supervised convolutional neural networks (CNNs) can yield acceptable accuracy for classifying well-known types of extreme weather events when large amounts of labeled data are available. However, many different types of spatially localized climate patterns are of interest including hurricanes, extra-tropical cyclones, weather fronts, and blocking events among others. Existing labeled data for these patterns can be incomplete in various ways, such as covering only certain years or geographic areas and having false negatives. This type of climate data therefore poses a number of interesting machine learning challenges. We present a multichannel spatiotemporal CNN architecture for semi-supervised bounding box prediction and exploratory data analysis. We demonstrate that our approach is able to leverage temporal information and unlabeled data to improve the localization of extreme weather events. Further, we explore the representations learned by our model in order to better understand this important data. We present a dataset, ExtremeWeather, to encourage machine learning research in this area and to help facilitate further work in understanding and mitigating the effects of climate change. The dataset is available at extremeweatherdataset.github.io and the code is available at https://github.com/eracah/hur-detect.},
  archivePrefix = {arXiv},
  eprint = {1612.02095},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Racah et al (2017) - ExtremeWeather.pdf},
  journal = {arXiv:1612.02095 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{radchenko2008Mixedrates,
  title = {Mixed-Rates Asymptotics},
  author = {Radchenko, Peter},
  year = {2008},
  month = feb,
  volume = {36},
  pages = {287--309},
  issn = {0090-5364},
  doi = {10.1214/009053607000000668},
  abstract = {A general method is presented for deriving the limiting behavior of estimators that are defined as the values of parameters optimizing an empirical criterion function. The asymptotic behavior of such estimators is typically deduced from uniform limit theorems for rescaled and reparametrized criterion functions. The new method can handle cases where the standard approach does not yield the complete limiting behavior of the estimator. The asymptotic analysis depends on a decomposition of criterion functions into sums of components with different rescalings. The method is explained by examples from Lasso-type estimation, \$k\$-means clustering, Shorth estimation and partial linear models.},
  archivePrefix = {arXiv},
  eprint = {0803.1942},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Radchenko (2008) - Mixed-rates asymptotics.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory},
  number = {1}
}

@article{radford2015Unsupervised,
  title = {Unsupervised {{Representation Learning}} with {{Deep Convolutional Generative Adversarial Networks}}},
  author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
  year = {2015},
  month = nov,
  abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
  archivePrefix = {arXiv},
  eprint = {1511.06434},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Radford et al (2015) - Unsupervised Representation Learning with Deep Convolutional Generative.pdf},
  journal = {arXiv:1511.06434 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{raghavan2018Externalities,
  title = {The {{Externalities}} of {{Exploration}} and {{How Data Diversity Helps Exploitation}}},
  author = {Raghavan, Manish and Slivkins, Aleksandrs and Vaughan, Jennifer Wortman and Wu, Zhiwei Steven},
  year = {2018},
  month = jun,
  abstract = {Online learning algorithms, widely used to power search and content optimization on the web, must balance exploration and exploitation, potentially sacrificing the experience of current users for information that will lead to better decisions in the future. Recently, concerns have been raised about whether the process of exploration could be viewed as unfair, placing too much burden on certain individuals or groups. Motivated by these concerns, we initiate the study of the externalities of exploration - the undesirable side effects that the presence of one party may impose on another - under the linear contextual bandits model. We introduce the notion of a group externality, measuring the extent to which the presence of one population of users impacts the rewards of another. We show that this impact can in some cases be negative, and that, in a certain sense, no algorithm can avoid it. We then study externalities at the individual level, interpreting the act of exploration as an externality imposed on the current user of a system by future users. This drives us to ask under what conditions inherent diversity in the data makes explicit exploration unnecessary. We build on a recent line of work on the smoothed analysis of the greedy algorithm that always chooses the action that currently looks optimal, improving on prior results to show that a greedy approach almost matches the best possible Bayesian regret rate of any other algorithm on the same problem instance whenever the diversity conditions hold, and that this regret is at most \$\textbackslash tilde\{O\}(T\^\{1/3\})\$. Returning to group-level effects, we show that under the same conditions, negative group externalities essentially vanish under the greedy algorithm. Together, our results uncover a sharp contrast between the high externalities that exist in the worst case, and the ability to remove all externalities if the data is sufficiently diverse.},
  archivePrefix = {arXiv},
  eprint = {1806.00543},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Raghavan et al (2018) - The Externalities of Exploration and How Data Diversity Helps Exploitation.pdf},
  journal = {arXiv:1806.00543 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{raghavan2019Mitigating,
  title = {Mitigating {{Bias}} in {{Algorithmic Employment Screening}}: {{Evaluating Claims}} and {{Practices}}},
  shorttitle = {Mitigating {{Bias}} in {{Algorithmic Employment Screening}}},
  author = {Raghavan, Manish and Barocas, Solon and Kleinberg, Jon and Levy, Karen},
  year = {2019},
  month = jun,
  abstract = {There has been rapidly growing interest in the use of algorithms for employment assessment, especially as a means to address or mitigate bias in hiring. Yet, to date, little is known about how these methods are being used in practice. How are algorithmic assessments built, validated, and examined for bias? In this work, we document and assess the claims and practices of companies offering algorithms for employment assessment, using a methodology that can be applied to evaluate similar applications and issues of bias in other domains. In particular, we identify vendors of algorithmic pre-employment assessments (i.e., algorithms to screen candidates), document what they have disclosed about their development and validation procedures, and evaluate their techniques for detecting and mitigating bias. We find that companies' formulation of "bias" varies, as do their approaches to dealing with it. We also discuss the various choices vendors make regarding data collection and prediction targets, in light of the risks and trade-offs that these choices pose. We consider the implications of these choices and we raise a number of technical and legal considerations.},
  archivePrefix = {arXiv},
  eprint = {1906.09208},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Raghavan et al (2019) - Mitigating Bias in Algorithmic Employment Screening.pdf},
  journal = {arXiv:1906.09208 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{raghu2019Rapid,
  title = {Rapid {{Learning}} or {{Feature Reuse}}? {{Towards Understanding}} the {{Effectiveness}} of {{MAML}}},
  shorttitle = {Rapid {{Learning}} or {{Feature Reuse}}?},
  author = {Raghu, Aniruddh and Raghu, Maithra and Bengio, Samy and Vinyals, Oriol},
  year = {2019},
  month = sep,
  abstract = {An important research direction in machine learning has centered around developing meta-learning algorithms to tackle few-shot learning. An especially successful algorithm has been Model Agnostic Meta-Learning (MAML), a method that consists of two optimization loops, with the outer loop finding a meta-initialization, from which the inner loop can efficiently learn new tasks. Despite MAML's popularity, a fundamental open question remains -- is the effectiveness of MAML due to the meta-initialization being primed for rapid learning (large, efficient changes in the representations) or due to feature reuse, with the meta initialization already containing high quality features? We investigate this question, via ablation studies and analysis of the latent representations, finding that feature reuse is the dominant factor. This leads to the ANIL (Almost No Inner Loop) algorithm, a simplification of MAML where we remove the inner loop for all but the (task-specific) head of a MAML-trained network. ANIL matches MAML's performance on benchmark few-shot image classification and RL and offers computational improvements over MAML. We further study the precise contributions of the head and body of the network, showing that performance on the test tasks is entirely determined by the quality of the learned features, and we can remove even the head of the network (the NIL algorithm). We conclude with a discussion of the rapid learning vs feature reuse question for meta-learning algorithms more broadly.},
  archivePrefix = {arXiv},
  eprint = {1909.09157},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Raghu et al (2019) - Rapid Learning or Feature Reuse.pdf},
  journal = {arXiv:1909.09157 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{raghunathan2018Certified,
  title = {Certified {{Defenses}} against {{Adversarial Examples}}},
  author = {Raghunathan, Aditi and Steinhardt, Jacob and Liang, Percy},
  year = {2018},
  month = jan,
  abstract = {While neural networks have achieved high accuracy on standard image classification benchmarks, their accuracy drops to nearly zero in the presence of small adversarial perturbations to test inputs. Defenses based on regularization and adversarial training have been proposed, but often followed by new, stronger attacks that defeat these defenses. Can we somehow end this arms race? In this work, we study this problem for neural networks with one hidden layer. We first propose a method based on a semidefinite relaxation that outputs a certificate that for a given network and test input, no attack can force the error to exceed a certain value. Second, as this certificate is differentiable, we jointly optimize it with the network parameters, providing an adaptive regularizer that encourages robustness against all attacks. On MNIST, our approach produces a network and a certificate that no attack that perturbs each pixel by at most \textbackslash epsilon = 0.1 can cause more than 35\% test error.},
  archivePrefix = {arXiv},
  eprint = {1801.09344},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Raghunathan et al (2018) - Certified Defenses against Adversarial Examples.pdf},
  journal = {arXiv:1801.09344 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{raghunathan2020Understanding,
  title = {Understanding and {{Mitigating}} the {{Tradeoff Between Robustness}} and {{Accuracy}}},
  author = {Raghunathan, Aditi and Xie, Sang Michael and Yang, Fanny and Duchi, John and Liang, Percy},
  year = {2020},
  month = feb,
  abstract = {Adversarial training augments the training set with perturbations to improve the robust error (over worst-case perturbations), but it often leads to an increase in the standard error (on unperturbed test inputs). Previous explanations for this tradeoff rely on the assumption that no predictor in the hypothesis class has low standard and robust error. In this work, we precisely characterize the effect of augmentation on the standard error in linear regression when the optimal linear predictor has zero standard and robust error. In particular, we show that the standard error could increase even when the augmented perturbations have noiseless observations from the optimal linear predictor. We then prove that the recently proposed robust self-training (RST) estimator improves robust error without sacrificing standard error for noiseless linear regression. Empirically, for neural networks, we find that RST with different adversarial training methods improves both standard and robust error for random and adversarial rotations and adversarial \$\textbackslash ell\_\textbackslash infty\$ perturbations in CIFAR-10.},
  archivePrefix = {arXiv},
  eprint = {2002.10716},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Raghunathan et al (2020) - Understanding and Mitigating the Tradeoff Between Robustness and Accuracy.pdf},
  journal = {arXiv:2002.10716 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{rahimian2019Distributionally,
  title = {Distributionally {{Robust Optimization}}: {{A Review}}},
  shorttitle = {Distributionally {{Robust Optimization}}},
  author = {Rahimian, Hamed and Mehrotra, Sanjay},
  year = {2019},
  month = aug,
  abstract = {The concepts of risk-aversion, chance-constrained optimization, and robust optimization have developed significantly over the last decade. Statistical learning community has also witnessed a rapid theoretical and applied growth by relying on these concepts. A modeling framework, called distributionally robust optimization (DRO), has recently received significant attention in both the operations research and statistical learning communities. This paper surveys main concepts and contributions to DRO, and its relationships with robust optimization, risk-aversion, chance-constrained optimization, and function regularization.},
  archivePrefix = {arXiv},
  eprint = {1908.05659},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rahimian, Mehrotra (2019) - Distributionally Robust Optimization.pdf},
  journal = {arXiv:1908.05659 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{raj2020Causal,
  title = {Causal {{Feature Selection}} via {{Orthogonal Search}}},
  author = {Raj, Anant and Bauer, Stefan and Soleymani, Ashkan and Besserve, Michel and Sch{\"o}lkopf, Bernhard},
  year = {2020},
  month = jul,
  abstract = {The problem of inferring the direct causal parents of a response variable among a large set of explanatory variables is of high practical importance in many disciplines. Recent work in the field of causal discovery exploits invariance properties of models across different experimental conditions for detecting direct causal links. However, these approaches generally do not scale well with the number of explanatory variables, are difficult to extend to nonlinear relationships, and require data across different experiments. Inspired by \{\textbackslash em Debiased\} machine learning methods, we study a one-vs.-the-rest feature selection approach to discover the direct causal parent of the response. We propose an algorithm that works for purely observational data, while also offering theoretical guarantees, including the case of partially nonlinear relationships. Requiring only one estimation for each variable, we can apply our approach even to large graphs, demonstrating significant improvements compared to established approaches.},
  archivePrefix = {arXiv},
  eprint = {2007.02938},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Raj et al (2020) - Causal Feature Selection via Orthogonal Search.pdf},
  journal = {arXiv:2007.02938 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{rajeswaran2019MetaLearning,
  title = {Meta-{{Learning}} with {{Implicit Gradients}}},
  author = {Rajeswaran, Aravind and Finn, Chelsea and Kakade, Sham and Levine, Sergey},
  year = {2019},
  month = sep,
  abstract = {A core capability of intelligent systems is the ability to quickly learn new tasks by drawing on prior experience. Gradient (or optimization) based meta-learning has recently emerged as an effective approach for few-shot learning. In this formulation, meta-parameters are learned in the outer loop, while task-specific models are learned in the inner-loop, by using only a small amount of data from the current task. A key challenge in scaling these approaches is the need to differentiate through the inner loop learning process, which can impose considerable computational and memory burdens. By drawing upon implicit differentiation, we develop the implicit MAML algorithm, which depends only on the solution to the inner level optimization and not the path taken by the inner loop optimizer. This effectively decouples the meta-gradient computation from the choice of inner loop optimizer. As a result, our approach is agnostic to the choice of inner loop optimizer and can gracefully handle many gradient steps without vanishing gradients or memory constraints. Theoretically, we prove that implicit MAML can compute accurate meta-gradients with a memory footprint that is, up to small constant factors, no more than that which is required to compute a single inner loop gradient and at no overall increase in the total computational cost. Experimentally, we show that these benefits of implicit MAML translate into empirical gains on few-shot image recognition benchmarks.},
  archivePrefix = {arXiv},
  eprint = {1909.04630},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rajeswaran et al (2019) - Meta-Learning with Implicit Gradients.pdf},
  journal = {arXiv:1909.04630 [cs, math, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{raji2020Closing,
  title = {Closing the {{AI Accountability Gap}}: {{Defining}} an {{End}}-to-{{End Framework}} for {{Internal Algorithmic Auditing}}},
  shorttitle = {Closing the {{AI Accountability Gap}}},
  author = {Raji, Inioluwa Deborah and Smart, Andrew and White, Rebecca N. and Mitchell, Margaret and Gebru, Timnit and Hutchinson, Ben and {Smith-Loud}, Jamila and Theron, Daniel and Barnes, Parker},
  year = {2020},
  month = jan,
  abstract = {Rising concern for the societal implications of artificial intelligence systems has inspired a wave of academic and journalistic literature in which deployed systems are audited for harm by investigators from outside the organizations deploying the algorithms. However, it remains challenging for practitioners to identify the harmful repercussions of their own systems prior to deployment, and, once deployed, emergent issues can become difficult or impossible to trace back to their source. In this paper, we introduce a framework for algorithmic auditing that supports artificial intelligence system development end-to-end, to be applied throughout the internal organization development lifecycle. Each stage of the audit yields a set of documents that together form an overall audit report, drawing on an organization's values or principles to assess the fit of decisions made throughout the process. The proposed auditing framework is intended to contribute to closing the accountability gap in the development and deployment of large-scale artificial intelligence systems by embedding a robust process to ensure audit integrity.},
  archivePrefix = {arXiv},
  eprint = {2001.00973},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Raji et al (2020) - Closing the AI Accountability Gap.pdf},
  journal = {arXiv:2001.00973 [cs]},
  keywords = {Computer Science - Computers and Society},
  primaryClass = {cs}
}

@article{rajpurkar2017CheXNet,
  title = {{{CheXNet}}: {{Radiologist}}-{{Level Pneumonia Detection}} on {{Chest X}}-{{Rays}} with {{Deep Learning}}},
  shorttitle = {{{CheXNet}}},
  author = {Rajpurkar, Pranav and Irvin, Jeremy and Zhu, Kaylie and Yang, Brandon and Mehta, Hershel and Duan, Tony and Ding, Daisy and Bagul, Aarti and Langlotz, Curtis and Shpanskaya, Katie and Lungren, Matthew P. and Ng, Andrew Y.},
  year = {2017},
  month = dec,
  abstract = {We develop an algorithm that can detect pneumonia from chest X-rays at a level exceeding practicing radiologists. Our algorithm, CheXNet, is a 121-layer convolutional neural network trained on ChestX-ray14, currently the largest publicly available chest X-ray dataset, containing over 100,000 frontal-view X-ray images with 14 diseases. Four practicing academic radiologists annotate a test set, on which we compare the performance of CheXNet to that of radiologists. We find that CheXNet exceeds average radiologist performance on the F1 metric. We extend CheXNet to detect all 14 diseases in ChestX-ray14 and achieve state of the art results on all 14 diseases.},
  archivePrefix = {arXiv},
  eprint = {1711.05225},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rajpurkar et al (2017) - CheXNet.pdf},
  journal = {arXiv:1711.05225 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{rajput2019Does,
  title = {Does {{Data Augmentation Lead}} to {{Positive Margin}}?},
  author = {Rajput, Shashank and Feng, Zhili and Charles, Zachary and Loh, Po-Ling and Papailiopoulos, Dimitris},
  year = {2019},
  month = may,
  abstract = {Data augmentation (DA) is commonly used during model training, as it significantly improves test error and model robustness. DA artificially expands the training set by applying random noise, rotations, crops, or even adversarial perturbations to the input data. Although DA is widely used, its capacity to provably improve robustness is not fully understood. In this work, we analyze the robustness that DA begets by quantifying the margin that DA enforces on empirical risk minimizers. We first focus on linear separators, and then a class of nonlinear models whose labeling is constant within small convex hulls of data points. We present lower bounds on the number of augmented data points required for non-zero margin, and show that commonly used DA techniques may only introduce significant margin after adding exponentially many points to the data set.},
  archivePrefix = {arXiv},
  eprint = {1905.03177},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rajput et al (2019) - Does Data Augmentation Lead to Positive Margin.pdf},
  journal = {arXiv:1905.03177 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{ramdas2017unified,
  title = {A Unified Treatment of Multiple Testing with Prior Knowledge Using the P-Filter},
  author = {Ramdas, Aaditya and Barber, Rina Foygel and Wainwright, Martin J. and Jordan, Michael I.},
  year = {2017},
  month = mar,
  abstract = {There is a significant literature on methods for incorporating knowledge into multiple testing procedures so as to improve their power and precision. Some common forms of prior knowledge include (a) beliefs about which hypotheses are null, modeled by non-uniform prior weights; (b) differing importances of hypotheses, modeled by differing penalties for false discoveries; (c) multiple arbitrary partitions of the hypotheses into (possibly overlapping) groups; and (d) knowledge of independence, positive or arbitrary dependence between hypotheses or groups, suggesting the use of more aggressive or conservative procedures. We present a unified algorithmic framework called p-filter for global null testing and false discovery rate (FDR) control that allows the scientist to incorporate all four types of prior knowledge (a)-(d) simultaneously, recovering a variety of known algorithms as special cases.},
  archivePrefix = {arXiv},
  eprint = {1703.06222},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ramdas et al (2017) - A unified treatment of multiple testing with prior knowledge using the p-filter.pdf},
  journal = {arXiv:1703.06222 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{rao2017Discordancy,
  title = {Discordancy {{Partitioning}} for {{Validating Potentially Inconsistent Pharmacogenomic Studies}}},
  author = {Rao, J. Sunil and Liu, Hongmei},
  year = {2017},
  month = dec,
  volume = {7},
  issn = {2045-2322},
  doi = {10.1038/s41598-017-15590-4},
  file = {/Users/yuekai/Documents/zotero/Rao, Liu (2017) - Discordancy Partitioning for Validating Potentially Inconsistent.pdf},
  journal = {Scientific Reports},
  language = {en},
  number = {1}
}

@article{raskutti2014Information,
  title = {The {{Information Geometry}} of {{Mirror Descent}}},
  author = {Raskutti, Garvesh and Mukherjee, Sayan},
  year = {2014},
  month = apr,
  abstract = {Information geometry applies concepts in differential geometry to probability and statistics and is especially useful for parameter estimation in exponential families where parameters are known to lie on a Riemannian manifold. Connections between the geometric properties of the induced manifold and statistical properties of the estimation problem are well-established. However developing first-order methods that scale to larger problems has been less of a focus in the information geometry community. The best known algorithm that incorporates manifold structure is the second-order natural gradient descent algorithm introduced by Amari. On the other hand, stochastic approximation methods have led to the development of first-order methods for optimizing noisy objective functions. A recent generalization of the Robbins-Monro algorithm known as mirror descent, developed by Nemirovski and Yudin is a first order method that induces non-Euclidean geometries. However current analysis of mirror descent does not precisely characterize the induced non-Euclidean geometry nor does it consider performance in terms of statistical relative efficiency. In this paper, we prove that mirror descent induced by Bregman divergences is equivalent to the natural gradient descent algorithm on the dual Riemannian manifold. Using this equivalence, it follows that (1) mirror descent is the steepest descent direction along the Riemannian manifold of the exponential family; (2) mirror descent with log-likelihood loss applied to parameter estimation in exponential families asymptotically achieves the classical Cram\textbackslash 'er-Rao lower bound and (3) natural gradient descent for manifolds corresponding to exponential families can be implemented as a first-order method through mirror descent.},
  archivePrefix = {arXiv},
  eprint = {1310.7780},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Raskutti, Mukherjee (2014) - The Information Geometry of Mirror Descent.pdf},
  journal = {arXiv:1310.7780 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{ratkovic2019Rehabilitating,
  title = {Rehabilitating the {{Regression}}: {{Honest}} and {{Valid Causal Inference}} through {{Machine Learning}}},
  author = {Ratkovic, Marc},
  year = {2019},
  month = jul,
  pages = {62},
  abstract = {The linear regression suffers from several well-known flaws. First, specification choices by the researcher can affect inference. Second, the regression is primarily a correlative tool and generally does not estimate an average causal effect. We introduce a method that overcomes both shortcomings. First, the method combines a machine learning approach to control for background covariates with a regression to estimate the coefficient on the treatment variable of theoretical interest. Second, the method models the treatment variable as well as the outcome, allowing for the recovery of a causal effect. The method applies regardless of whether the treatment variable is a binary, continuous, or count variable. We prove that the method's estimate is consistent for the average causal effect and that its standard errors are asymptotically valid and semiparametrically efficient. A simulation study and application to real-world datasets illustrates the method's utility.},
  file = {/Users/yuekai/Documents/zotero/Ratkovic (2019) - Rehabilitating the Regression.pdf},
  language = {en}
}

@article{ravikumar2010Highdimensional,
  title = {High-Dimensional {{Ising}} Model Selection Using \$\{\textbackslash ell\_1\}\$-Regularized Logistic Regression},
  author = {Ravikumar, Pradeep and Wainwright, Martin J. and Lafferty, John D.},
  year = {2010},
  month = jun,
  volume = {38},
  pages = {1287--1319},
  issn = {0090-5364},
  doi = {10.1214/09-AOS691},
  abstract = {We consider the problem of estimating the graph associated with a binary Ising Markov random field. We describe a method based on \$\textbackslash ell\_1\$-regularized logistic regression, in which the neighborhood of any given node is estimated by performing logistic regression subject to an \$\textbackslash ell\_1\$-constraint. The method is analyzed under high-dimensional scaling in which both the number of nodes \$p\$ and maximum neighborhood size \$d\$ are allowed to grow as a function of the number of observations \$n\$. Our main results provide sufficient conditions on the triple \$(n,p,d)\$ and the model parameters for the method to succeed in consistently estimating the neighborhood of every node in the graph simultaneously. With coherence conditions imposed on the population Fisher information matrix, we prove that consistent neighborhood selection can be obtained for sample sizes \$n=\textbackslash Omega(d\^3\textbackslash log p)\$ with exponentially decaying error. When these same conditions are imposed directly on the sample matrices, we show that a reduced sample size of \$n=\textbackslash Omega(d\^2\textbackslash log p)\$ suffices for the method to estimate neighborhoods consistently. Although this paper focuses on the binary graphical models, we indicate how a generalization of the method of the paper would apply to general discrete Markov random fields.},
  archivePrefix = {arXiv},
  eprint = {1010.0311},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ravikumar et al (2010) - High-dimensional Ising model selection using $ -ell_1 $-regularized logistic.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory},
  number = {3}
}

@article{recht2018Tour,
  title = {A {{Tour}} of {{Reinforcement Learning}}: {{The View}} from {{Continuous Control}}},
  shorttitle = {A {{Tour}} of {{Reinforcement Learning}}},
  author = {Recht, Benjamin},
  year = {2018},
  month = jun,
  abstract = {This manuscript surveys reinforcement learning from the perspective of optimization and control with a focus on continuous control applications. It surveys the general formulation, terminology, and typical experimental implementations of reinforcement learning and reviews competing solution paradigms. In order to compare the relative merits of various techniques, this survey presents a case study of the Linear Quadratic Regulator (LQR) with unknown dynamics, perhaps the simplest and best-studied problem in optimal control. The manuscript describes how merging techniques from learning theory and control can provide non-asymptotic characterizations of LQR performance and shows that these characterizations tend to match experimental behavior. In turn, when revisiting more complex applications, many of the observed phenomena in LQR persist. In particular, theory and experiment demonstrate the role and importance of models and the cost of generality in reinforcement learning algorithms. This survey concludes with a discussion of some of the challenges in designing learning systems that safely and reliably interact with complex and uncertain environments and how tools from reinforcement learning and control might be combined to approach these challenges.},
  archivePrefix = {arXiv},
  eprint = {1806.09460},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Recht (2018) - A Tour of Reinforcement Learning.pdf},
  journal = {arXiv:1806.09460 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@inproceedings{redko2019Optimal,
  title = {Optimal {{Transport}} for {{Multi}}-Source {{Domain Adaptation}} under {{Target Shift}}},
  booktitle = {The 22nd {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Redko, Ievgen and Courty, Nicolas and Flamary, R{\'e}mi and Tuia, Devis},
  year = {2019},
  month = apr,
  pages = {849--858},
  abstract = {In this paper, we tackle the problem of reducing discrepancies between multiple domains, i.e. multi-source domain adaptation, and consider it under the target shift assumption: in all domains we ai...},
  file = {/Users/yuekai/Documents/zotero/Redko et al (2019) - Optimal Transport for Multi-source Domain Adaptation under Target Shift.pdf},
  language = {en}
}

@article{regenwetter2011Transitivity,
  title = {Transitivity of {{Preferences}}},
  author = {Regenwetter, Michel and Dana, Jason and {Davis-Stober}, Clintin P},
  year = {2011},
  volume = {118},
  pages = {15},
  abstract = {Transitivity of preferences is a fundamental principle shared by most major contemporary rational, prescriptive, and descriptive models of decision making. To have transitive preferences, a person, group, or society that prefers choice option x to y and y to z must prefer x to z. Any claim of empirical violations of transitivity by individual decision makers requires evidence beyond a reasonable doubt. We discuss why unambiguous evidence is currently lacking and how to clarify the issue. In counterpoint to Tversky's (1969) seminal ``Intransitivity of Preferences,'' we reconsider his data as well as those from more than 20 other studies of intransitive human or animal decision makers. We challenge the standard operationalizations of transitive preferences and discuss pervasive methodological problems in the collection, modeling, and analysis of relevant empirical data. For example, violations of weak stochastic transitivity do not imply violations of transitivity of preference. Building on past multidisciplinary work, we use parsimonious mixture models, where the space of permissible preference states is the family of (transitive) strict linear orders. We show that the data from many of the available studies designed to elicit intransitive choice are consistent with transitive preferences.},
  file = {/Users/yuekai/Documents/zotero/Regenwetter et al (2011) - Transitivity of Preferences.pdf},
  journal = {Psychological Review},
  language = {en},
  number = {1}
}

@article{rieger2008Sampling,
  title = {Sampling Inequalities for Infinitely Smooth Functions, with Applications to Interpolation and Machine Learning},
  author = {Rieger, Christian and Zwicknagl, Barbara},
  year = {2008},
  month = jul,
  volume = {32},
  pages = {103},
  issn = {1572-9044},
  doi = {10.1007/s10444-008-9089-0},
  abstract = {Sampling inequalities give a precise formulation of the fact that a differentiable function cannot attain large values if its derivatives are bounded and if it is small on a sufficiently dense discrete set. Sampling inequalities can be applied to the difference of a function and its reconstruction in order to obtain (sometimes optimal) convergence orders for very general possibly regularized recovery processes. So far, there are only sampling inequalities for finitely smooth functions, which lead to algebraic convergence orders. In this paper, the case of infinitely smooth functions is investigated, in order to derive error estimates with exponential convergence orders.},
  file = {/Users/yuekai/Documents/zotero/Rieger, Zwicknagl (2008) - Sampling inequalities for infinitely smooth functions, with applications to.pdf},
  journal = {Advances in Computational Mathematics},
  language = {en},
  number = {1}
}

@article{rigollet2009Optimal,
  title = {Optimal Rates for Plug-in Estimators of Density Level Sets},
  author = {Rigollet, Philippe and Vert, R{\'e}gis},
  year = {2009},
  month = nov,
  volume = {15},
  pages = {1154--1178},
  issn = {1350-7265},
  doi = {10.3150/09-BEJ184},
  abstract = {In the context of density level set estimation, we study the convergence of general plug-in methods under two main assumptions on the density for a given level \$\textbackslash lambda\$. More precisely, it is assumed that the density (i) is smooth in a neighborhood of \$\textbackslash lambda\$ and (ii) has \$\textbackslash gamma\$-exponent at level \$\textbackslash lambda\$. Condition (i) ensures that the density can be estimated at a standard nonparametric rate and condition (ii) is similar to Tsybakov's margin assumption which is stated for the classification framework. Under these assumptions, we derive optimal rates of convergence for plug-in estimators. Explicit convergence rates are given for plug-in estimators based on kernel density estimators when the underlying measure is the Lebesgue measure. Lower bounds proving optimality of the rates in a minimax sense when the density is H\textbackslash "older smooth are also provided.},
  archivePrefix = {arXiv},
  eprint = {math/0611473},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rigollet, Vert (2009) - Optimal rates for plug-in estimators of density level sets.pdf;/Users/yuekai/Zotero/storage/DJ4DQW7N/0611473.html},
  journal = {Bernoulli},
  keywords = {Mathematics - Statistics Theory},
  number = {4}
}

@article{rigollet2012Sparse,
  title = {Sparse {{Estimation}} by {{Exponential Weighting}}},
  author = {Rigollet, Philippe and Tsybakov, Alexandre B.},
  year = {2012},
  month = nov,
  volume = {27},
  pages = {558--575},
  issn = {0883-4237},
  doi = {10.1214/12-STS393},
  abstract = {Consider a regression model with fixed design and Gaussian noise where the regression function can potentially be well approximated by a function that admits a sparse representation in a given dictionary. This paper resorts to exponential weights to exploit this underlying sparsity by implementing the principle of sparsity pattern aggregation. This model selection take on sparse estimation allows us to derive sparsity oracle inequalities in several popular frameworks, including ordinary sparsity, fused sparsity and group sparsity. One striking aspect of these theoretical results is that they hold under no condition in the dictionary. Moreover, we describe an efficient implementation of the sparsity pattern aggregation principle that compares favorably to state-of-the-art procedures on some basic numerical examples.},
  archivePrefix = {arXiv},
  eprint = {1108.5116},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rigollet, Tsybakov (2012) - Sparse Estimation by Exponential Weighting.pdf},
  journal = {Statistical Science},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  number = {4}
}

@article{rigollet2018Entropic,
  title = {Entropic Optimal Transport Is Maximum-Likelihood Deconvolution},
  author = {Rigollet, Philippe and Weed, Jonathan},
  year = {2018},
  month = sep,
  abstract = {We give a statistical interpretation of entropic optimal transport by showing that performing maximum-likelihood estimation for Gaussian deconvolution corresponds to calculating a projection with respect to the entropic optimal transport distance. This structural result gives theoretical support for the wide adoption of these tools in the machine learning community.},
  archivePrefix = {arXiv},
  eprint = {1809.05572},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rigollet, Weed (2018) - Entropic optimal transport is maximum-likelihood deconvolution.pdf},
  journal = {arXiv:1809.05572 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{ritov2014Bayesian,
  title = {The {{Bayesian Analysis}} of {{Complex}}, {{High}}-{{Dimensional Models}}: {{Can It Be CODA}}?},
  shorttitle = {The {{Bayesian Analysis}} of {{Complex}}, {{High}}-{{Dimensional Models}}},
  author = {Ritov, Y. and Bickel, P. J. and Gamst, A. C. and Kleijn, B. J. K.},
  year = {2014},
  month = nov,
  volume = {29},
  pages = {619--639},
  issn = {0883-4237},
  doi = {10.1214/14-STS483},
  abstract = {We consider the Bayesian analysis of a few complex, highdimensional models and show that intuitive priors, which are not tailored to the fine details of the model and the estimated parameters, produce estimators which perform poorly in situations in which good, simple frequentist estimators exist. The models we consider are: stratified sampling, the partial linear model, linear and quadratic functionals of white noise and estimation with stopping times. We present a strong vipseotresstnieocrneiooorffisDa {$\surd$}ouonnbi-f'cosorcnmosnilsystie{$\surd$}sntentn-fccooyrnvtsahilseutoeernsetmofeswtthhiemicpahatrodaremmeenotsneursrtiernsatsteuhsbatsthettahsteotfhBpearyeioxesrprobability 1. We also demonstrate that it is, at least, in principle, possible to construct Bayes priors giving both global and local minimax rates, using a suitable combination of loss functions. We argue that there is no contradiction in these apparently conflicting findings.},
  archivePrefix = {arXiv},
  eprint = {1203.5471},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ritov et al (2014) - The Bayesian Analysis of Complex, High-Dimensional Models.pdf},
  journal = {Statistical Science},
  keywords = {Mathematics - Statistics Theory},
  language = {en},
  number = {4}
}

@article{ritov2017conditional,
  title = {On Conditional Parity as a Notion of Non-Discrimination in Machine Learning},
  author = {Ritov, Ya'acov and Sun, Yuekai and Zhao, Ruofei},
  year = {2017},
  month = jun,
  abstract = {We identify conditional parity as a general notion of non-discrimination in machine learning. In fact, several recently proposed notions of non-discrimination, including a few counterfactual notions, are instances of conditional parity. We show that conditional parity is amenable to statistical analysis by studying randomization as a general mechanism for achieving conditional parity and a kernel-based test of conditional parity.},
  archivePrefix = {arXiv},
  eprint = {1706.08519},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ritov et al (2017) - On conditional parity as a notion of non-discrimination in machine learning.pdf},
  journal = {arXiv:1706.08519 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{rizoiu2017Tutorial,
  title = {A {{Tutorial}} on {{Hawkes Processes}} for {{Events}} in {{Social Media}}},
  author = {Rizoiu, Marian-Andrei and Lee, Young and Mishra, Swapnil and Xie, Lexing},
  year = {2017},
  month = oct,
  abstract = {This chapter provides an accessible introduction for point processes, and especially Hawkes processes, for modeling discrete, inter-dependent events over continuous time. We start by reviewing the definitions and the key concepts in point processes. We then introduce the Hawkes process, its event intensity function, as well as schemes for event simulation and parameter estimation. We also describe a practical example drawn from social media data - we show how to model retweet cascades using a Hawkes self-exciting process. We presents a design of the memory kernel, and results on estimating parameters and predicting popularity. The code and sample event data are available as an online appendix},
  archivePrefix = {arXiv},
  eprint = {1708.06401},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rizoiu et al (2017) - A Tutorial on Hawkes Processes for Events in Social Media.pdf},
  journal = {arXiv:1708.06401 [cs, stat]},
  keywords = {Computer Science - Social and Information Networks,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{robins1997Curse,
  title = {Toward a {{Curse}} of {{Dimensionality Appropriate}} (Coda) {{Asymptotic Theory}} for {{Semi}}-{{Parametric Models}}},
  author = {Robins, James M. and Ritov, Ya'acov},
  year = {1997},
  volume = {16},
  pages = {285--319},
  issn = {1097-0258},
  doi = {10.1002/(SICI)1097-0258(19970215)16:3<285::AID-SIM535>3.0.CO;2-\#},
  abstract = {We argue, that due to the curse of dimensionality, there are major difficulties with any pure or smoothed likelihood-based method of inference in designed studies with randomly missing data when missingness depends on a high-dimensional vector of variables. We study in detail a semi-parametric superpopulation version of continuously stratified random sampling. We show that all estimators of the population mean that are uniformly consistent or that achieve an algebraic rate of convergence, no matter how slow, require the use of the selection (randomization) probabilities. We argue that, in contrast to likelihood methods which ignore these probabilities, inverse selection probability weighted estimators continue to perform well achieving uniform n1/2-rates of convergence. We propose a curse of dimensionality appropriate (CODA) asymptotic theory for inference in non- and semi-parametric models in an attempt to formalize our arguments. We discuss whether our results constitute a fatal blow to the likelihood principle and study the attitude toward these that a committed subjective Bayesian would adopt. Finally, we apply our CODA theory to analyse the effect of the `curse of dimensionality' in several interesting semi-parametric models, including a model for a two-armed randomized trial with randomization probabilities depending on a vector of continuous pre-treatment covariates X. We provide substantive settings under which a subjective Bayesian would ignore the randomization probabilities in analysing the trial data. We then show that any statistician who ignores the randomization probabilities is unable to construct nominal 95 per cent confidence intervals for the true treatment effect that have both: (i) an expected length which goes to zero with increasing sample size; and (ii) a guaranteed expected actual coverage rate of at least 95 per cent over the ensemble of trials analysed by the statistician during his or her lifetime. However, we derive a new interval estimator, depending on the Randomization probabilities, that satisfies (i) and (ii). \textcopyright{} 1997 by John Wiley \& Sons, Ltd.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291097-0258\%2819970215\%2916\%3A3\%3C285\%3A\%3AAID-SIM535\%3E3.0.CO\%3B2-\%23},
  copyright = {Copyright \textcopyright{} 1997 John Wiley \& Sons, Ltd.},
  file = {/Users/yuekai/Documents/zotero/Robins, Ritov (1997) - Toward a Curse of Dimensionality Appropriate (coda) Asymptotic Theory for.pdf},
  journal = {Statistics in Medicine},
  language = {en},
  number = {3}
}

@book{rockafellar1974Conjugate,
  title = {Conjugate {{Duality}} and {{Optimization}}},
  author = {Rockafellar, R Tyrrell},
  year = {1974},
  file = {/Users/yuekai/Documents/zotero/Rockafellar (1974) - Conjugate Duality and Optimization.pdf},
  language = {en},
  series = {{{CBMS}}-{{NSF Regional Conference Series}} in {{Applied Mathematics}}}
}

@article{rockafellar1993Lagrange,
  title = {Lagrange {{Multipliers}} and {{Optimality}}},
  author = {Rockafellar, R Tyrell},
  year = {1993},
  month = jun,
  volume = {35},
  pages = {56},
  abstract = {Lagrange multipliers used to be viewed as auxiliary variables introduced in a problem of constrained minimization in order to write first-order optimality conditions formally as a system of equations. Modern applications, with their emphasis on numerical methods and more complicated side conditions than equations, have demanded deeper understanding of the concept and how it fits into a larger theoretical picture. A major line of research has been the nonsmooth geometry of one-sided tangent and normal vectors to the set of points satisfying the given constraints. Another has been the game-theoretic role of multiplier vectors as solutions to a dual problem. Interpretations as generalized derivatives of the optimal value with respect to problem parameters have also been explored. Lagrange multipliers are now being seen as arising from a general rule for the subdifferentiation of a nonsmooth objective function which allows black-and-white constraints to be replaced by penalty expressions. This paper traces such themes in the current theory of Lagrange multipliers, providing along the way a free-standing exposition of basic nonsmooth analysis as motivated by and applied to this subject.},
  file = {/Users/yuekai/Documents/zotero/Rockafellar (1993) - Lagrange Multipliers and Optimality.pdf},
  journal = {SIAM Review},
  language = {en},
  number = {2}
}

@book{rockafellar2004Variational,
  title = {Variational Analysis},
  author = {Rockafellar, R. Tyrrell and Wets, Roger J.-B.},
  year = {2004},
  edition = {Corr. 2nd print},
  publisher = {{Springer}},
  address = {{Berlin}},
  file = {/Users/yuekai/Documents/zotero/Rockafellar, Wets (2004) - Variational analysis.pdf},
  isbn = {978-3-540-62772-2},
  language = {en},
  lccn = {QA315 .R63 2004},
  number = {317},
  series = {Grundlehren Der Mathematischen {{Wissenschaften}}}
}

@article{rohde2019Geometrizing,
  title = {Geometrizing Rates of Convergence under Local Differential Privacy Constraints},
  author = {Rohde, Angelika and Steinberger, Lukas},
  year = {2019},
  month = may,
  abstract = {We study the problem of estimating a functional \$\textbackslash theta(\textbackslash mathbb P)\$ of an unknown probability distribution \$\textbackslash mathbb P \textbackslash in\textbackslash mathcal P\$ in which the original iid sample \$X\_1,\textbackslash dots, X\_n\$ is kept private even from the statistician via an \$\textbackslash alpha\$-local differential privacy constraint. Let \$\textbackslash omega\_\{TV\}\$ denote the modulus of continuity of the functional \$\textbackslash theta\$ over \$\textbackslash mathcal P\$, with respect to total variation distance. For a large class of loss functions \$l\$ and a fixed privacy level \$\textbackslash alpha\$, we prove that the privatized minimax risk is equivalent to \$l(\textbackslash omega\_\{TV\}(n\^\{-1/2\}))\$ to within constants, under regularity conditions that are satisfied, in particular, if \$\textbackslash theta\$ is linear and \$\textbackslash mathcal P\$ is convex. Our results complement the theory developed by Donoho and Liu (1991) with the nowadays highly relevant case of privatized data. Somewhat surprisingly, the difficulty of the estimation problem in the private case is characterized by \$\textbackslash omega\_\{TV\}\$, whereas, it is characterized by the Hellinger modulus of continuity if the original data \$X\_1,\textbackslash dots, X\_n\$ are available. We also find that for locally private estimation of linear functionals over a convex model a simple sample mean estimator, based on independently and binary privatized observations, always achieves the minimax rate. We further provide a general recipe for choosing the functional parameter in the optimal binary privatization mechanisms and illustrate the general theory in numerous examples. Our theory allows to quantify the price to be paid for local differential privacy in a large class of estimation problems. This price appears to be highly problem specific.},
  archivePrefix = {arXiv},
  eprint = {1805.01422},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rohde, Steinberger (2019) - Geometrizing rates of convergence under local differential privacy constraints.pdf},
  journal = {arXiv:1805.01422 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{rohe2020Vintage,
  title = {Vintage {{Factor Analysis}} with {{Varimax Performs Statistical Inference}}},
  author = {Rohe, Karl and Zeng, Muzhe},
  year = {2020},
  month = apr,
  abstract = {Psychologists developed Multiple Factor Analysis to decompose multivariate data into a small number of interpretable factors without any a priori knowledge about those factors. In this form of factor analysis, the Varimax "factor rotation" is a key step to make the factors interpretable. Charles Spearman and many others objected to factor rotations because the factors seem to be rotationally invariant. These objections are still reported in all contemporary multivariate statistics textbooks. This is an engima because this vintage form of factor analysis has survived and is widely popular because, empirically, the factor rotation often makes the factors easier to interpret. We argue that the rotation makes the factors easier to interpret because, in fact, the Varimax factor rotation performs statistical inference. We show that Principal Components Analysis (PCA) with the Varimax rotation provides a unified spectral estimation strategy for a broad class of modern factor models, including the Stochastic Blockmodel and a natural variation of Latent Dirichlet Allocation (i.e., "topic modeling"). In addition, we show that Thurstone's widely employed sparsity diagnostics implicitly assess a key "leptokurtic" condition that makes the rotation statistically identifiable in these models. Taken together, this shows that the know-how of Vintage Factor Analysis performs statistical inference, reversing nearly a century of statistical thinking on the topic. With a sparse eigensolver, PCA with Varimax is both fast and stable. Combined with Thurstone's straightforward diagnostics, this vintage approach is suitable for a wide array of modern applications.},
  archivePrefix = {arXiv},
  eprint = {2004.05387},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rohe, Zeng (2020) - Vintage Factor Analysis with Varimax Performs Statistical Inference.pdf;/Users/yuekai/Zotero/storage/4UN4VEGC/2004.html},
  journal = {arXiv:2004.05387 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{rojas-carulla2018Invariant,
  title = {Invariant {{Models}} for {{Causal Transfer Learning}}},
  author = {{Rojas-Carulla}, Mateo and Sch{\"o}lkopf, Bernhard and Turner, Richard and Peters, Jonas},
  year = {2018},
  month = sep,
  abstract = {Methods of transfer learning try to combine knowledge from several related tasks (or domains) to improve performance on a test task. Inspired by causal methodology, we relax the usual covariate shift assumption and assume that it holds true for a subset of predictor variables: the conditional distribution of the target variable given this subset of predictors is invariant over all tasks. We show how this assumption can be motivated from ideas in the field of causality. We focus on the problem of Domain Generalization, in which no examples from the test task are observed. We prove that in an adversarial setting using this subset for prediction is optimal in Domain Generalization; we further provide examples, in which the tasks are sufficiently diverse and the estimator therefore outperforms pooling the data, even on average. If examples from the test task are available, we also provide a method to transfer knowledge from the training tasks and exploit all available features for prediction. However, we provide no guarantees for this method. We introduce a practical method which allows for automatic inference of the above subset and provide corresponding code. We present results on synthetic data sets and a gene deletion data set.},
  archivePrefix = {arXiv},
  eprint = {1507.05333},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rojas-Carulla et al (2018) - Invariant Models for Causal Transfer Learning.pdf},
  journal = {arXiv:1507.05333 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{rolnick2018Experience,
  title = {Experience {{Replay}} for {{Continual Learning}}},
  author = {Rolnick, David and Ahuja, Arun and Schwarz, Jonathan and Lillicrap, Timothy P. and Wayne, Greg},
  year = {2018},
  month = nov,
  abstract = {Continual learning is the problem of learning new tasks or knowledge while protecting old knowledge and ideally generalizing from old experience to learn new tasks faster. Neural networks trained by stochastic gradient descent often degrade on old tasks when trained successively on new tasks with different data distributions. This phenomenon, referred to as catastrophic forgetting, is considered a major hurdle to learning with non-stationary data or sequences of new tasks, and prevents networks from continually accumulating knowledge and skills. We examine this issue in the context of reinforcement learning, in a setting where an agent is exposed to tasks in a sequence. Unlike most other work, we do not provide an explicit indication to the model of task boundaries, which is the most general circumstance for a learning agent exposed to continuous experience. While various methods to counteract catastrophic forgetting have recently been proposed, we explore a straightforward, general, and seemingly overlooked solution - that of using experience replay buffers for all past events - with a mixture of on- and off-policy learning, leveraging behavioral cloning. We show that this strategy can still learn new tasks quickly yet can substantially reduce catastrophic forgetting in both Atari and DMLab domains, even matching the performance of methods that require task identities. When buffer storage is constrained, we confirm that a simple mechanism for randomly discarding data allows a limited size buffer to perform almost as well as an unbounded one.},
  archivePrefix = {arXiv},
  eprint = {1811.11682},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rolnick et al (2018) - Experience Replay for Continual Learning.pdf},
  journal = {arXiv:1811.11682 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{romano2018Deep,
  title = {Deep {{Knockoffs}}},
  author = {Romano, Yaniv and Sesia, Matteo and Cand{\`e}s, Emmanuel J.},
  year = {2018},
  month = nov,
  abstract = {This paper introduces a machine for sampling approximate model-X knockoffs for arbitrary and unspecified data distributions using deep generative models. The main idea is to iteratively refine a knockoff sampling mechanism until a criterion measuring the validity of the produced knockoffs is optimized; this criterion is inspired by the popular maximum mean discrepancy in machine learning and can be thought of as measuring the distance to pairwise exchangeability between original and knockoff features. By building upon the existing model-X framework, we thus obtain a flexible and model-free statistical tool to perform controlled variable selection. Extensive numerical experiments and quantitative tests confirm the generality, effectiveness, and power of our deep knockoff machines. Finally, we apply this new method to a real study of mutations linked to changes in drug resistance in the human immunodeficiency virus.},
  archivePrefix = {arXiv},
  eprint = {1811.06687},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Romano et al (2018) - Deep Knockoffs.pdf},
  journal = {arXiv:1811.06687 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Applications,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{romanov2019What,
  title = {What's in a {{Name}}? {{Reducing Bias}} in {{Bios}} without {{Access}} to {{Protected Attributes}}},
  shorttitle = {What's in a {{Name}}?},
  author = {Romanov, Alexey and {De-Arteaga}, Maria and Wallach, Hanna and Chayes, Jennifer and Borgs, Christian and Chouldechova, Alexandra and Geyik, Sahin and Kenthapadi, Krishnaram and Rumshisky, Anna and Kalai, Adam Tauman},
  year = {2019},
  month = apr,
  abstract = {There is a growing body of work that proposes methods for mitigating bias in machine learning systems. These methods typically rely on access to protected attributes such as race, gender, or age. However, this raises two significant challenges: (1) protected attributes may not be available or it may not be legal to use them, and (2) it is often desirable to simultaneously consider multiple protected attributes, as well as their intersections. In the context of mitigating bias in occupation classification, we propose a method for discouraging correlation between the predicted probability of an individual's true occupation and a word embedding of their name. This method leverages the societal biases that are encoded in word embeddings, eliminating the need for access to protected attributes. Crucially, it only requires access to individuals' names at training time and not at deployment time. We evaluate two variations of our proposed method using a large-scale dataset of online biographies. We find that both variations simultaneously reduce race and gender biases, with almost no reduction in the classifier's overall true positive rate.},
  archivePrefix = {arXiv},
  eprint = {1904.05233},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Romanov et al (2019) - What's in a Name.pdf},
  journal = {arXiv:1904.05233 [cs, stat]},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{romisch2006Delta,
  title = {Delta {{Method}}, {{Infinite Dimensional}}},
  author = {R{\"o}misch, Werner},
  year = {2006},
  pages = {13},
  abstract = {The infinite-dimensional delta method including higher order and set-valued variants is presented. The relevant underlying material on weak convergence, Hadamard directional derivatives and on hyperspaces of closed sets is discussed. Some examples of Hadamard directional differentiable functions and of the delta method, including Mestimation, are given.},
  file = {/Users/yuekai/Documents/zotero/Römisch (2006) - Delta Method, Inﬁnite Dimensional.pdf},
  language = {en}
}

@article{rosasco2010Learning,
  title = {On {{Learning}} with {{Integral Operators}}},
  author = {Rosasco, Lorenzo and Belkin, Mikhail and Vito, Ernesto De},
  year = {2010},
  volume = {11},
  pages = {905--934},
  issn = {ISSN 1533-7928},
  file = {/Users/yuekai/Documents/zotero/Rosasco et al (2010) - On Learning with Integral Operators.pdf},
  journal = {Journal of Machine Learning Research},
  number = {Feb}
}

@article{ross2017Improving,
  title = {Improving the {{Adversarial Robustness}} and {{Interpretability}} of {{Deep Neural Networks}} by {{Regularizing}} Their {{Input Gradients}}},
  author = {Ross, Andrew Slavin and {Doshi-Velez}, Finale},
  year = {2017},
  month = nov,
  abstract = {Deep neural networks have proven remarkably effective at solving many classification problems, but have been criticized recently for two major weaknesses: the reasons behind their predictions are uninterpretable, and the predictions themselves can often be fooled by small adversarial perturbations. These problems pose major obstacles for the adoption of neural networks in domains that require security or transparency. In this work, we evaluate the effectiveness of defenses that differentiably penalize the degree to which small changes in inputs can alter model predictions. Across multiple attacks, architectures, defenses, and datasets, we find that neural networks trained with this input gradient regularization exhibit robustness to transferred adversarial examples generated to fool all of the other models. We also find that adversarial examples generated to fool gradient-regularized models fool all other models equally well, and actually lead to more "legitimate," interpretable misclassifications as rated by people (which we confirm in a human subject experiment). Finally, we demonstrate that regularizing input gradients makes them more naturally interpretable as rationales for model predictions. We conclude by discussing this relationship between interpretability and robustness in deep neural networks.},
  archivePrefix = {arXiv},
  eprint = {1711.09404},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ross, Doshi-Velez (2017) - Improving the Adversarial Robustness and Interpretability of Deep Neural.pdf},
  journal = {arXiv:1711.09404 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{ross2017Right,
  title = {Right for the {{Right Reasons}}: {{Training Differentiable Models}} by {{Constraining}} Their {{Explanations}}},
  shorttitle = {Right for the {{Right Reasons}}},
  author = {Ross, Andrew Slavin and Hughes, Michael C. and {Doshi-Velez}, Finale},
  year = {2017},
  month = mar,
  abstract = {Neural networks are among the most accurate supervised learning methods in use today. However, their opacity makes them difficult to trust in critical applications, especially if conditions in training may differ from those in test. Recent work on explanations for black-box models has produced tools (e.g. LIME) to show the implicit rules behind predictions. These tools can help us identify when models are right for the wrong reasons. However, these methods do not scale to explaining entire datasets and cannot correct the problems they reveal. We introduce a method for efficiently explaining and regularizing differentiable models by examining and selectively penalizing their input gradients. We apply these penalties both based on expert annotation and in an unsupervised fashion that produces multiple classifiers with qualitatively different decision boundaries. On multiple datasets, we show our approach generates faithful explanations and models that generalize much better when conditions differ between training and test.},
  archivePrefix = {arXiv},
  eprint = {1703.03717},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ross et al (2017) - Right for the Right Reasons.pdf},
  journal = {arXiv:1703.03717 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{roth2018Adversarially,
  title = {Adversarially {{Robust Training}} through {{Structured Gradient Regularization}}},
  author = {Roth, Kevin and Lucchi, Aurelien and Nowozin, Sebastian and Hofmann, Thomas},
  year = {2018},
  month = may,
  abstract = {We propose a novel data-dependent structured gradient regularizer to increase the robustness of neural networks vis-a-vis adversarial perturbations. Our regularizer can be derived as a controlled approximation from first principles, leveraging the fundamental link between training with noise and regularization. It adds very little computational overhead during learning and is simple to implement generically in standard deep learning frameworks. Our experiments provide strong evidence that structured gradient regularization can act as an effective first line of defense against attacks based on low-level signal corruption.},
  archivePrefix = {arXiv},
  eprint = {1805.08736},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Roth et al (2018) - Adversarially Robust Training through Structured Gradient Regularization.pdf},
  journal = {arXiv:1805.08736 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{rothblum2018Probably,
  title = {Probably {{Approximately Metric}}-{{Fair Learning}}},
  author = {Rothblum, Guy N. and Yona, Gal},
  year = {2018},
  month = mar,
  abstract = {The seminal work of Dwork \{\textbackslash em et al.\} [ITCS 2012] introduced a metric-based notion of individual fairness. Given a task-specific similarity metric, their notion required that every pair of similar individuals should be treated similarly. In the context of machine learning, however, individual fairness does not generalize from a training set to the underlying population. We show that this can lead to computational intractability even for simple fair-learning tasks. With this motivation in mind, we introduce and study a relaxed notion of \{\textbackslash em approximate metric-fairness\}: for a random pair of individuals sampled from the population, with all but a small probability of error, if they are similar then they should be treated similarly. We formalize the goal of achieving approximate metric-fairness simultaneously with best-possible accuracy as Probably Approximately Correct and Fair (PACF) Learning. We show that approximate metric-fairness \{\textbackslash em does\} generalize, and leverage these generalization guarantees to construct polynomial-time PACF learning algorithms for the classes of linear and logistic predictors.},
  archivePrefix = {arXiv},
  eprint = {1803.03242},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rothblum, Yona (2018) - Probably Approximately Metric-Fair Learning.pdf},
  journal = {arXiv:1803.03242 [cs]},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{rothenhausler2015backShift,
  title = {{{backShift}}: {{Learning}} Causal Cyclic Graphs from Unknown Shift Interventions},
  shorttitle = {{{backShift}}},
  author = {Rothenh{\"a}usler, Dominik and Heinze, Christina and Peters, Jonas and Meinshausen, Nicolai},
  year = {2015},
  month = jun,
  abstract = {We propose a simple method to learn linear causal cyclic models in the presence of latent variables. The method relies on equilibrium data of the model recorded under a specific kind of interventions ("shift interventions"). The location and strength of these interventions do not have to be known and can be estimated from the data. Our method, called backShift, only uses second moments of the data and performs simple joint matrix diagonalization, applied to differences between covariance matrices. We give a sufficient and necessary condition for identifiability of the system, which is fulfilled almost surely under some quite general assumptions if and only if there are at least three distinct experimental settings, one of which can be pure observational data. We demonstrate the performance on some simulated data and applications in flow cytometry and financial time series. The code is made available as R-package backShift.},
  archivePrefix = {arXiv},
  eprint = {1506.02494},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rothenhäusler et al (2015) - backShift.pdf},
  journal = {arXiv:1506.02494 [stat]},
  keywords = {Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {stat}
}

@article{rothenhausler2018Anchor,
  title = {Anchor Regression: Heterogeneous Data Meets Causality},
  shorttitle = {Anchor Regression},
  author = {Rothenh{\"a}usler, Dominik and Meinshausen, Nicolai and B{\"u}hlmann, Peter and Peters, Jonas},
  year = {2018},
  month = jan,
  abstract = {Estimating causal parameters from observational data is notoriously difficult. Popular approaches such as regression adjustment or the instrumental variables approach only work under relatively strong assumptions and are prone to mistakes. Furthermore, causal parameters can exhibit conservative predictive performance which can limit their usefulness in practice. Causal parameters can be written as the solution to a minimax risk problem, where the maximum is taken over a range of interventional (or perturbed) distributions. This motivates anchor regression, a method that makes use of exogeneous variables to solve a relaxation of the "causal" minimax problem. The procedure naturally provides an interpolation between the solution to ordinary least squares and two-stage least squares, but also has predictive guarantees if the instrumental variables assumptions are violated. We derive guarantees of the proposed procedure for predictive performance under perturbations for the population case and for high-dimensional data. An additional characterization of the procedure is given in terms of quantiles: If the data follow a Gaussian distribution, the method minimizes quantiles of the conditional mean squared error. If anchor regression and least squares provide the same answer ("anchor stability"), the relationship between targets and predictors is unconfounded and the coefficients have a causal interpretation. Furthermore, we show under which conditions anchor regression satisfies replicability among different experiments. Anchor regression is shown empirically to improve replicability and protect against distributional shifts},
  archivePrefix = {arXiv},
  eprint = {1801.06229},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rothenhäusler et al (2018) - Anchor regression.pdf},
  journal = {arXiv:1801.06229 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{rothenhausler2018Causal,
  title = {Causal {{Dantzig}}: Fast Inference in Linear Structural Equation Models with Hidden Variables under Additive Interventions},
  shorttitle = {Causal {{Dantzig}}},
  author = {Rothenh{\"a}usler, Dominik and B{\"u}hlmann, Peter and Meinshausen, Nicolai},
  year = {2018},
  month = jun,
  abstract = {Causal inference is known to be very challenging when only observational data are available. Randomized experiments are often costly and impractical and in instrumental variable regression the number of instruments has to exceed the number of causal predictors. It was recently shown in Peters et al. [2016] that causal inference for the full model is possible when data from distinct observational environments are available, exploiting that the conditional distribution of a response variable is invariant under the correct causal model. Two shortcomings of such an approach are the high computational effort for large-scale data and the assumed absence of hidden confounders. Here we show that these two shortcomings can be addressed if one is willing to make a more restrictive assumption on the type of interventions that generate different environments. Thereby, we look at a different notion of invariance, namely inner-product invariance. By avoiding a computationally cumbersome reverse-engineering approach such as in Peters et al. [2016], it allows for large-scale causal inference in linear structural equation models. We discuss identifiability conditions for the causal parameter and derive asymptotic confidence intervals in the low-dimensional setting. In the case of non-identifiability we show that the solution set of causal Dantzig has predictive guarantees under certain interventions. We derive finite-sample bounds in the high-dimensional setting and investigate its performance on simulated datasets.},
  archivePrefix = {arXiv},
  eprint = {1706.06159},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rothenhäusler et al (2018) - Causal Dantzig.pdf},
  journal = {arXiv:1706.06159 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{rothenhausler2019Incremental,
  title = {Incremental Causal Effects},
  author = {Rothenh{\"a}usler, Dominik and Yu, Bin},
  year = {2019},
  month = oct,
  abstract = {The ignorability assumption and the overlap condition are key assumptions in causal inference. They are commonly made, but often violated in observational studies. In this paper, we investigate a local version of the ignorability assumption for continuous treatments, where potential outcomes are independent of the treatment assignment only in a neighborhood of the current treatment assignment. Similarly, we introduce a local version of the overlap condition, where the positivity assumption only holds in a neighborhood of observations. Under these local assumptions and a smoothness condition, we show that the effect of shifting a continuous treatment variable by a small amount across the whole population (termed average partial effect or incremental causal effect) is still identifiable, and that the incremental causal effect can be estimated via the average derivative. Moreover, we prove that in certain regression settings, estimating the incremental effect is easier than estimating the average treatment effect in terms of asymptotic variance. In addition, we show that estimation of incremental causal effects is often more robust than estimating average treatment effects if the ignorability assumption is slightly violated. For high-dimensional settings, we develop a simple feature transformation that allows for doubly-robust estimation and doubly-robust inference of incremental causal effects. Finally, we compare the behaviour of estimators of the incremental treatment effect and average treatment effect in experiments including data-inspired simulations.},
  archivePrefix = {arXiv},
  eprint = {1907.13258},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rothenhäusler, Yu (2019) - Incremental causal effects.pdf},
  journal = {arXiv:1907.13258 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{roughgarden2016Price,
  title = {The {{Price}} of {{Anarchy}} in {{Auctions}}},
  author = {Roughgarden, Tim and Syrgkanis, Vasilis and Tardos, Eva},
  year = {2016},
  month = jul,
  abstract = {This survey outlines a general and modular theory for proving approximation guarantees for equilibria of auctions in complex settings. This theory complements traditional economic techniques, which generally focus on exact and optimal solutions and are accordingly limited to relatively stylized settings. We highlight three user-friendly analytical tools: smoothness-type inequalities, which immediately yield approximation guarantees for many auction formats of interest in the special case of complete information and deterministic strategies; extension theorems, which extend such guarantees to randomized strategies, no-regret learning outcomes, and incomplete-information settings; and composition theorems, which extend such guarantees from simpler to more complex auctions. Combining these tools yields tight worst-case approximation guarantees for the equilibria of many widely-used auction formats.},
  archivePrefix = {arXiv},
  eprint = {1607.07684},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Roughgarden et al (2016) - The Price of Anarchy in Auctions.pdf},
  journal = {arXiv:1607.07684 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Science and Game Theory,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@book{roughgarden2016Twenty,
  title = {Twenty {{Lectures}} on {{Algorithmic Game Theory}}},
  author = {Roughgarden, Tim},
  year = {2016},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9781316779309},
  file = {/Users/yuekai/Documents/zotero/Roughgarden (2016) - Twenty Lectures on Algorithmic Game Theory.pdf},
  isbn = {978-1-316-77930-9},
  language = {en}
}

@article{rudelson2017Errorsinvariables,
  title = {Errors-in-Variables Models with Dependent Measurements},
  author = {Rudelson, Mark and Zhou, Shuheng},
  year = {2017},
  volume = {11},
  pages = {1699--1797},
  issn = {1935-7524},
  doi = {10.1214/17-EJS1234},
  abstract = {Suppose that we observe y{$\in$}Rny{$\in$}Rny\textbackslash in\textbackslash mathbb\{R\}\^\{n\} and X{$\in$}Rn\texttimes mX{$\in$}Rn\texttimes mX\textbackslash in\textbackslash mathbb\{R\}\^\{n\textbackslash times m\} in the following errors-in-variables model: yX==X0{$\beta{_\ast}$}+{$\epsilon$}X0+Wy=X0{$\beta{_\ast}$}+{$\epsilon$}X=X0+W\textbackslash begin\{eqnarray*\}y\&=\&X\_\{0\}\textbackslash beta\^\{*\}+\textbackslash epsilon\textbackslash\textbackslash X\&=\&X\_\{0\}+W\textbackslash end\{eqnarray*\} where X0X0X\_\{0\} is an n\texttimes mn\texttimes mn\textbackslash times m design matrix with independent subgaussian row vectors, {$\epsilon\in$}Rn{$\epsilon\in$}Rn\textbackslash epsilon\textbackslash in\textbackslash mathbb\{R\}\^\{n\} is a noise vector and WWW is a mean zero n\texttimes mn\texttimes mn\textbackslash times m random noise matrix with independent subgaussian column vectors, independent of X0X0X\_\{0\} and {$\epsilon\epsilon\backslash$}epsilon. This model is significantly different from those analyzed in the literature in the sense that we allow the measurement error for each covariate to be a dependent vector across its nnn observations. Such error structures appear in the science literature when modeling the trial-to-trial fluctuations in response strength shared across a set of neurons. Under sparsity and restrictive eigenvalue type of conditions, we show that one is able to recover a sparse vector {$\beta{_\ast}\in$}Rm{$\beta{_\ast}\in$}Rm\textbackslash beta\^\{*\}\textbackslash in\textbackslash mathbb\{R\}\^\{m\} from the model given a single observation matrix XXX and the response vector yyy. We establish consistency in estimating {$\beta{_\ast}\beta{_\ast}\backslash$}beta\^\{*\} and obtain the rates of convergence in the {$\mathscr{l}$}q{$\mathscr{l}$}q\textbackslash ell\_\{q\} norm, where q=1,2q=1,2q=1,2 for the Lasso-type estimator, and for q{$\in$}[1,2]q{$\in$}[1,2]q\textbackslash in [1,2] for a Dantzig-type Conic programming estimator. We show error bounds which approach that of the regular Lasso and the Dantzig selector in case the errors in WWW are tending to 0. We analyze the convergence rates of the gradient descent methods for solving the nonconvex programs and show that the composite gradient descent algorithm is guaranteed to converge at a geometric rate to a neighborhood of the global minimizers: the size of the neighborhood is bounded by the statistical error in the {$\mathscr{l}$}2{$\mathscr{l}$}2\textbackslash ell\_\{2\} norm. Our analysis reveals interesting connections between computational and statistical efficiency and the concentration of measure phenomenon in random matrix theory. We provide simulation evidence illuminating the theoretical predictions.},
  file = {/Users/yuekai/Documents/zotero/Rudelson, Zhou (2017) - Errors-in-variables models with dependent measurements.pdf},
  journal = {Electronic Journal of Statistics},
  language = {EN},
  mrnumber = {MR3639561},
  number = {1},
  zmnumber = {1364.62179}
}

@article{rudi2015Less,
  title = {Less Is {{More}}: {{Nystr}}\textbackslash "om {{Computational Regularization}}},
  shorttitle = {Less Is {{More}}},
  author = {Rudi, Alessandro and Camoriano, Raffaello and Rosasco, Lorenzo},
  year = {2015},
  month = jul,
  abstract = {We study Nystro\textasciidieresis m type subsampling approaches to large scale kernel methods, and prove learning bounds in the statistical learning setting, where random sampling and high probability estimates are considered. In particular, we prove that these approaches can achieve optimal learning bounds, provided the subsampling level is suitably chosen. These results suggest a simple incremental variant of Nystro\textasciidieresis m Kernel Regularized Least Squares, where the subsampling level implements a form of computational regularization, in the sense that it controls at the same time regularization and computations. Extensive experimental analysis shows that the considered approach achieves state of the art performances on benchmark large scale datasets.},
  archivePrefix = {arXiv},
  eprint = {1507.04717},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rudi et al (2015) - Less is More.pdf},
  journal = {arXiv:1507.04717 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{rudin2018age,
  title = {The Age of Secrecy and Unfairness in Recidivism Prediction},
  author = {Rudin, Cynthia and Wang, Caroline and Coker, Beau},
  year = {2018},
  month = nov,
  abstract = {In our current society, secret algorithms make important decisions about individuals. There has been substantial discussion about whether these algorithms are unfair to groups of individuals. While noble, this pursuit is complex and ultimately stagnating because there is no clear definition of fairness and competing definitions are largely incompatible. We argue that the focus on the question of fairness is misplaced, as these algorithms fail to meet a more important and yet readily obtainable goal: transparency. As a result, creators of secret algorithms can provide incomplete or misleading descriptions about how their models work, and various other kinds of errors can easily go unnoticed. By partially reverse engineering the COMPAS algorithm -- a recidivism-risk scoring algorithm used throughout the criminal justice system -- we show that it does not seem to depend linearly on the defendant's age, despite statements to the contrary by the algorithm's creator. Furthermore, by subtracting from COMPAS its (hypothesized) nonlinear age component, we show that COMPAS does not necessarily depend on race, contradicting ProPublica's analysis, which assumed linearity in age. In other words, faulty assumptions about a proprietary algorithm lead to faulty conclusions that go unchecked without careful reverse engineering. Were the algorithm transparent in the first place, this would likely not have occurred. The most important result in this work is that we find that there are many defendants with low risk score but long criminal histories, suggesting that data inconsistencies occur frequently in criminal justice databases. We argue that transparency satisfies a different notion of procedural fairness by providing both the defendants and the public with the opportunity to scrutinize the methodology and calculations behind risk scores for recidivism.},
  archivePrefix = {arXiv},
  eprint = {1811.00731},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rudin et al (2018) - The age of secrecy and unfairness in recidivism prediction.pdf},
  journal = {arXiv:1811.00731 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Statistics - Applications},
  primaryClass = {cs, stat}
}

@article{rudin2019Stop,
  title = {Stop {{Explaining Black Box Machine Learning Models}} for {{High Stakes Decisions}} and {{Use Interpretable Models Instead}}},
  author = {Rudin, Cynthia},
  year = {2019},
  month = sep,
  abstract = {Black box machine learning models are currently being used for high stakes decision-making throughout society, causing problems throughout healthcare, criminal justice, and in other domains. People have hoped that creating methods for explaining these black box models will alleviate some of these problems, but trying to \textbackslash textit\{explain\} black box models, rather than creating models that are \textbackslash textit\{interpretable\} in the first place, is likely to perpetuate bad practices and can potentially cause catastrophic harm to society. There is a way forward -- it is to design models that are inherently interpretable. This manuscript clarifies the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identifies challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare, and computer vision.},
  archivePrefix = {arXiv},
  eprint = {1811.10154},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Rudin (2019) - Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and.pdf},
  journal = {arXiv:1811.10154 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@incollection{russell2017When,
  title = {When {{Worlds Collide}}: {{Integrating Different Counterfactual Assumptions}} in {{Fairness}}},
  shorttitle = {When {{Worlds Collide}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 30},
  author = {Russell, Chris and Kusner, Matt J and Loftus, Joshua and Silva, Ricardo},
  editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  year = {2017},
  pages = {6414--6423},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/yuekai/Documents/zotero/Russell et al (2017) - When Worlds Collide.pdf}
}

@article{russo2016InformationTheoretic,
  title = {An {{Information}}-{{Theoretic Analysis}} of {{Thompson Sampling}}},
  author = {Russo, Daniel},
  year = {2016},
  month = apr,
  volume = {17},
  pages = {30},
  abstract = {We provide an information-theoretic analysis of Thompson sampling that applies across a broad range of online optimization problems in which a decision-maker must learn from partial feedback. This analysis inherits the simplicity and elegance of information theory and leads to regret bounds that scale with the entropy of the optimal-action distribution. This strengthens preexisting results and yields new insight into how information improves performance.},
  file = {/Users/yuekai/Documents/zotero/Russo (2016) - An Information-Theoretic Analysis of Thompson Sampling.pdf},
  journal = {Journal of Machine Learning Research},
  language = {en}
}

@article{russo2019WorstCase,
  title = {Worst-{{Case Regret Bounds}} for {{Exploration}} via {{Randomized Value Functions}}},
  author = {Russo, Daniel},
  year = {2019},
  month = aug,
  abstract = {This paper studies a recent proposal to use randomized value functions to drive exploration in reinforcement learning. These randomized value functions are generated by injecting random noise into the training data, making the approach compatible with many popular methods for estimating parameterized value functions. By providing a worst-case regret bound for tabular finite-horizon Markov decision processes, we show that planning with respect to these randomized value functions can induce provably efficient exploration.},
  archivePrefix = {arXiv},
  eprint = {1906.02870},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Russo (2019) - Worst-Case Regret Bounds for Exploration via Randomized Value Functions.pdf},
  journal = {arXiv:1906.02870 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Systems and Control,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@incollection{rust1994Structural,
  title = {Structural Estimation of Markov Decision Processes},
  booktitle = {Handbook of {{Econometrics}}},
  author = {Rust, John},
  year = {1994},
  volume = {4},
  pages = {3081--3143},
  publisher = {{Elsevier}},
  doi = {10.1016/S1573-4412(05)80020-0},
  file = {/Users/yuekai/Documents/zotero/Rust (1994) - Structural estimation of markov decision processes.pdf},
  isbn = {978-0-444-88766-5},
  language = {en}
}

@article{rust2019Has,
  title = {Has {{Dynamic Programming Improved Decision Making}}?},
  author = {Rust, John},
  year = {2019},
  volume = {11},
  pages = {833--858},
  doi = {10.1146/annurev-economics-080218-025721},
  abstract = {Dynamic programming (DP) is a powerful tool for solving a wide class of sequential decision-making problems under uncertainty. In principle, it enables us to compute optimal decision rules that specify the best possible decision in any situation. This article reviews developments in DP and contrasts its revolutionary impact on economics, operations research, engineering, and artificial intelligence with the comparative paucity of its real-world applications to improve the decision making of individuals and firms. The fuzziness of many real-world decision problems and the difficulty in mathematically modeling them are key obstacles to a wider application of DP in real-world settings. Nevertheless, I discuss several success stories, and I conclude that DP offers substantial promise for improving decision making if we let go of the empirically untenable assumption of unbounded rationality and confront the challenging decision problems faced every day by individuals and firms.},
  file = {/Users/yuekai/Documents/zotero/Rust (2019) - Has Dynamic Programming Improved Decision Making.pdf},
  journal = {Annual Review of Economics},
  number = {1}
}

@article{ryser1960MATRICES,
  title = {{{MATRICES OF ZEROS AND ONES}}},
  author = {Ryser, H J},
  year = {1960},
  volume = {66},
  pages = {442--464},
  file = {/Users/yuekai/Documents/zotero/Ryser (1960) - MATRICES OF ZEROS AND ONES.pdf},
  journal = {Bulletin of the American Mathematical Society},
  language = {en},
  number = {6}
}

@article{ryu2015Extensions,
  title = {Extensions of {{Gauss Quadrature Via Linear Programming}}},
  author = {Ryu, Ernest K. and Boyd, Stephen P.},
  year = {2015},
  month = aug,
  volume = {15},
  pages = {953--971},
  issn = {1615-3383},
  doi = {10.1007/s10208-014-9197-9},
  abstract = {Gauss quadrature is a well-known method for estimating the integral of a continuous function with respect to a given measure as a weighted sum of the function evaluated at a set of node points. Gauss quadrature is traditionally developed using orthogonal polynomials. We show that Gauss quadrature can also be obtained as the solution to an infinite-dimensional linear program (LP): minimize the \$\$n\$\$nth moment among all nonnegative measures that match the \$\$0\$\$0through \$\$n-1\$\$n-1moments of the given measure. While this infinite-dimensional LP provides no computational advantage in the traditional setting of integration on the real line, it can be used to construct Gauss-like quadratures in more general settings, including arbitrary domains in multiple dimensions.},
  file = {/Users/yuekai/Documents/zotero/Ryu, Boyd (2015) - Extensions of Gauss Quadrature Via Linear Programming.pdf},
  journal = {Foundations of Computational Mathematics},
  language = {en},
  number = {4}
}

@article{ryu2016PRIMER,
  title = {A {{PRIMER ON MONOTONE OPERATOR METHODS}}},
  author = {Ryu, Ernest K and Boyd, Stephen},
  year = {2016},
  pages = {41},
  abstract = {This tutorial paper presents the basic notation and results of monotone operators and operator splitting methods, with a focus on convex optimization. A very wide variety of algorithms, ranging from classical to recently developed, can be derived in a uniform way. The approach is to pose the original problem to be solved as one of finding a zero of an appropriate monotone operator; this problem in turn is then posed as one of finding a fixed point of a related operator, which is done using the fixed point iteration. A few basic convergence results then tell us conditions under which the method converges, and, in some cases, how fast. This approach can be traced back to the 1960s and 1970s, and is still an active area of research. This primer is a self-contained gentle introduction to the topic.},
  file = {/Users/yuekai/Documents/zotero/Ryu, Boyd (2016) - A PRIMER ON MONOTONE OPERATOR METHODS.pdf},
  journal = {APPL. COMPUT. MATH.},
  language = {en}
}

@article{ryu2018Vector,
  title = {Vector and {{Matrix Optimal Mass Transport}}: {{Theory}}, {{Algorithm}}, and {{Applications}}},
  shorttitle = {Vector and {{Matrix Optimal Mass Transport}}},
  author = {Ryu, Ernest K. and Chen, Yongxin and Li, Wuchen and Osher, Stanley},
  year = {2018},
  month = jan,
  volume = {40},
  pages = {A3675-A3698},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/17M1163396},
  abstract = {In many applications such as color image processing, data has more than one piece of information associated with each spatial coordinate, and in such cases the classical optimal mass transport (OMT) must be generalized to handle vector-valued or matrix-valued densities. In this paper, we discuss the vector and matrix optimal mass transport and present three contributions. We first present a rigorous mathematical formulation for these setups and provide analytical results including existence of solutions and strong duality. Next, we present a simple, scalable, and parallelizable method to solve the vector and matrix-OMT problems. Finally, we implement the proposed methods on a CUDA GPU and present experiments and applications.},
  file = {/Users/yuekai/Documents/zotero/Ryu et al (2018) - Vector and Matrix Optimal Mass Transport.pdf},
  journal = {SIAM Journal on Scientific Computing},
  language = {en},
  number = {5}
}

@article{ryu2019ODE,
  title = {{{ODE Analysis}} of {{Stochastic Gradient Methods}} with {{Optimism}} and {{Anchoring}} for {{Minimax Problems}} and {{GANs}}},
  author = {Ryu, Ernest K. and Yuan, Kun and Yin, Wotao},
  year = {2019},
  month = may,
  abstract = {Despite remarkable empirical success, the training dynamics of generative adversarial networks (GAN), which involves solving a minimax game using stochastic gradients, is still poorly understood. In this work, we analyze last-iterate convergence of simultaneous gradient descent (simGD) and its variants under the assumption of convex-concavity, guided by a continuous-time analysis with differential equations. First, we show that simGD, as is, converges with stochastic sub-gradients under strict convexity in the primal variable. Second, we generalize optimistic simGD to accommodate an optimism rate separate from the learning rate and show its convergence with full gradients. Finally, we present anchored simGD, a new method, and show convergence with stochastic subgradients.},
  archivePrefix = {arXiv},
  eprint = {1905.10899},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ryu et al (2019) - ODE Analysis of Stochastic Gradient Methods with Optimism and Anchoring for.pdf},
  journal = {arXiv:1905.10899 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{ryu2019Scaled,
  title = {Scaled {{Relative Graph}}: {{Nonexpansive}} Operators via {{2D Euclidean Geometry}}},
  shorttitle = {Scaled {{Relative Graph}}},
  author = {Ryu, Ernest K. and Hannah, Robert and Yin, Wotao},
  year = {2019},
  month = feb,
  abstract = {Many iterative methods in applied mathematics can be thought of as fixed-point iterations, and such algorithms are usually analyzed analytically, with inequalities. In this paper, we present a geometric approach to analyzing contractive and nonexpansive fixed point iterations with a new tool called the scaled relative graph (SRG). The SRG provides a rigorous correspondence between nonlinear operators and subsets of the 2D plane. Under this framework, a geometric argument in the 2D plane becomes a rigorous proof of contractiveness of the corresponding operator.},
  archivePrefix = {arXiv},
  eprint = {1902.09788},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ryu et al (2019) - Scaled Relative Graph.pdf},
  journal = {arXiv:1902.09788 [math]},
  keywords = {Mathematics - Optimization and Control},
  primaryClass = {math}
}

@article{sagawa2019Distributionally,
  title = {Distributionally {{Robust Neural Networks}} for {{Group Shifts}}: {{On}} the {{Importance}} of {{Regularization}} for {{Worst}}-{{Case Generalization}}},
  shorttitle = {Distributionally {{Robust Neural Networks}} for {{Group Shifts}}},
  author = {Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B. and Liang, Percy},
  year = {2019},
  month = nov,
  abstract = {Overparameterized neural networks can be highly accurate on average on an i.i.d. test set yet consistently fail on atypical groups of the data (e.g., by learning spurious correlations that hold on average but not in such groups). Distributionally robust optimization (DRO) allows us to learn models that instead minimize the worst-case training loss over a set of pre-defined groups. However, we find that naively applying group DRO to overparameterized neural networks fails: these models can perfectly fit the training data, and any model with vanishing average training loss also already has vanishing worst-case training loss. Instead, their poor worst-case performance arises from poor generalization on some groups. By coupling group DRO models with increased regularization---stronger-than-typical \$\textbackslash ell\_2\$ regularization or early stopping---we achieve substantially higher worst-group accuracies, with 10-40 percentage point improvements on a natural language inference task and two image tasks, while maintaining high average accuracies. Our results suggest that regularization is critical for worst-group generalization in the overparameterized regime, even if it is not needed for average generalization. Finally, we introduce and give convergence guarantees for a stochastic optimizer for the group DRO setting, underpinning the empirical study above.},
  archivePrefix = {arXiv},
  eprint = {1911.08731},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Sagawa et al (2019) - Distributionally Robust Neural Networks for Group Shifts.pdf},
  journal = {arXiv:1911.08731 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{saha2020nonparametric,
  title = {On the Nonparametric Maximum Likelihood Estimator for {{Gaussian}} Location Mixture Densities with Application to {{Gaussian}} Denoising},
  author = {Saha, Sujayam and Guntuboyina, Adityanand},
  year = {2020},
  month = apr,
  volume = {48},
  pages = {738--762},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/19-AOS1817},
  abstract = {We study the nonparametric maximum likelihood estimator (NPMLE) for estimating Gaussian location mixture densities in ddd-dimensions from independent observations. Unlike usual likelihood-based methods for fitting mixtures, NPMLEs are based on convex optimization. We prove finite sample results on the Hellinger accuracy of every NPMLE. Our results imply, in particular, that every NPMLE achieves near parametric risk (up to logarithmic multiplicative factors) when the true density is a discrete Gaussian mixture without any prior information on the number of mixture components. NPMLEs can naturally be used to yield empirical Bayes estimates of the oracle Bayes estimator in the Gaussian denoising problem. We prove bounds for the accuracy of the empirical Bayes estimate as an approximation to the oracle Bayes estimator. Here our results imply that the empirical Bayes estimator performs at nearly the optimal level (up to logarithmic factors) for denoising in clustering situations without any prior knowledge of the number of clusters.},
  file = {/Users/yuekai/Documents/zotero/Saha, Guntuboyina (2020) - On the nonparametric maximum likelihood estimator for Gaussian location mixture.pdf;/Users/yuekai/Zotero/storage/J8I96JTX/1590480032.html},
  journal = {Annals of Statistics},
  keywords = {adaptive estimation,convex clustering,convex optimization,Density estimation,Gaussian mixture model,Hellinger distance,metric entropy,model selection,rate of convergence},
  language = {EN},
  mrnumber = {MR4102674},
  number = {2}
}

@article{salman2019Convex,
  title = {A {{Convex Relaxation Barrier}} to {{Tight Robustness Verification}} of {{Neural Networks}}},
  author = {Salman, Hadi and Yang, Greg and Zhang, Huan and Hsieh, Cho-Jui and Zhang, Pengchuan},
  year = {2019},
  month = feb,
  abstract = {Verification of neural networks enables us to gauge their robustness against adversarial attacks. Verification algorithms fall into two categories: exact verifiers that run in exponential time and relaxed verifiers that are efficient but incomplete. In this paper, we unify all existing LP-relaxed verifiers, to the best of our knowledge, under a general convex relaxation framework. This framework works for neural networks with diverse architectures and nonlinearities and covers both primal and dual views of robustness verification. We further prove strong duality between the primal and dual problems under very mild conditions. Next, we perform large-scale experiments, amounting to more than 22 CPU-years, to obtain exact solution to the convex-relaxed problem that is optimal within our framework for ReLU networks. We find the exact solution does not significantly improve upon the gap between PGD and existing relaxed verifiers for various networks trained normally or robustly on MNIST and CIFAR datasets. Our results suggest there is an inherent barrier to tight verification for the large class of methods captured by our framework. We discuss possible causes of this barrier and potential future directions for bypassing it.},
  archivePrefix = {arXiv},
  eprint = {1902.08722},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Salman et al (2019) - A Convex Relaxation Barrier to Tight Robustness Verification of Neural Networks.pdf},
  journal = {arXiv:1902.08722 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{samadi2018Price,
  title = {The {{Price}} of {{Fair PCA}}: {{One Extra Dimension}}},
  shorttitle = {The {{Price}} of {{Fair PCA}}},
  author = {Samadi, Samira and Tantipongpipat, Uthaipon and Morgenstern, Jamie and Singh, Mohit and Vempala, Santosh},
  year = {2018},
  month = oct,
  abstract = {We investigate whether the standard dimensionality reduction technique of PCA inadvertently produces data representations with different fidelity for two different populations. We show on several real-world data sets, PCA has higher reconstruction error on population A than on B (for example, women versus men or lower- versus higher-educated individuals). This can happen even when the data set has a similar number of samples from A and B. This motivates our study of dimensionality reduction techniques which maintain similar fidelity for A and B. We define the notion of Fair PCA and give a polynomial-time algorithm for finding a low dimensional representation of the data which is nearly-optimal with respect to this measure. Finally, we show on real-world data sets that our algorithm can be used to efficiently generate a fair low dimensional representation of the data.},
  archivePrefix = {arXiv},
  eprint = {1811.00103},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Samadi et al (2018) - The Price of Fair PCA.pdf},
  journal = {arXiv:1811.00103 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{samworth2017Recent,
  title = {Recent Progress in Log-Concave Density Estimation},
  author = {Samworth, Richard J.},
  year = {2017},
  month = sep,
  abstract = {In recent years, log-concave density estimation via maximum likelihood estimation has emerged as a fascinating alternative to traditional nonparametric smoothing techniques, such as kernel density estimation, which require the choice of one or more bandwidths. The purpose of this article is to describe some of the properties of the class of log-concave densities on \$\textbackslash mathbb\{R\}\^d\$ which make it so attractive from a statistical perspective, and to outline the latest methodological, theoretical and computational advances in the area.},
  archivePrefix = {arXiv},
  eprint = {1709.03154},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Samworth (2017) - Recent progress in log-concave density estimation.pdf},
  journal = {arXiv:1709.03154 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology,Statistics - Other Statistics},
  primaryClass = {math, stat}
}

@article{sanderson2014Class,
  title = {Class {{Proportion Estimation}} with {{Application}} to {{Multiclass Anomaly Rejection}}},
  author = {Sanderson, Tyler and Scott, Clayton},
  year = {2014},
  month = feb,
  abstract = {This work addresses two classification problems that fall under the heading of domain adaptation, wherein the distributions of training and testing examples differ. The first problem studied is that of class proportion estimation, which is the problem of estimating the class proportions in an unlabeled testing data set given labeled examples of each class. Compared to previous work on this problem, our approach has the novel feature that it does not require labeled training data from one of the classes. This property allows us to address the second domain adaptation problem, namely, multiclass anomaly rejection. Here, the goal is to design a classifier that has the option of assigning a "reject" label, indicating that the instance did not arise from a class present in the training data. We establish consistent learning strategies for both of these domain adaptation problems, which to our knowledge are the first of their kind. We also implement the class proportion estimation technique and demonstrate its performance on several benchmark data sets.},
  archivePrefix = {arXiv},
  eprint = {1306.5056},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Sanderson, Scott (2014) - Class Proportion Estimation with Application to Multiclass Anomaly Rejection.pdf;/Users/yuekai/Zotero/storage/7TLI9WKZ/1306.html},
  journal = {arXiv:1306.5056 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@book{santambrogio2015Optimal,
  title = {Optimal {{Transport}} for {{Applied Mathematicians}}},
  author = {Santambrogio, Filippo},
  year = {2015},
  volume = {87},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-20828-2},
  file = {/Users/yuekai/Documents/zotero/Santambrogio (2015) - Optimal Transport for Applied Mathematicians.pdf},
  isbn = {978-3-319-20827-5 978-3-319-20828-2},
  language = {en},
  series = {Progress in {{Nonlinear Differential Equations}} and {{Their Applications}}}
}

@article{santambrogio2016Euclidean,
  title = {\{ \vphantom\}{{Euclidean}}, {{Metric}}, and {{Wasserstein}} \vphantom\{\} {{Gradient Flows}}: An Overview},
  shorttitle = {\{ \vphantom\}{{Euclidean}}, {{Metric}}, and {{Wasserstein}} \vphantom\{\} {{Gradient Flows}}},
  author = {Santambrogio, Filippo},
  year = {2016},
  month = sep,
  abstract = {This is an expository paper on the theory of gradient flows, and in particular of those PDEs which can be interpreted as gradient flows for the Wasserstein metric on the space of probability measures (a distance induced by optimal transport). The starting point is the Euclidean theory, and then its generalization to metric spaces, according to the work of Ambrosio, Gigli and Savar\{\textbackslash 'e\}. Then comes an independent exposition of the Wasserstein theory, with a short introduction to the optimal transport tools that are needed and to the notion of geodesic convexity, followed by a precise desciption of the Jordan-Kinderleher-Otto scheme, with proof of convergence in the easiest case: the linear Fokker-Planck equation. A discussion of other gradient flows PDEs and of numerical methods based on these ideas is also provided. The paper ends with a new, theoretical, development, due to Ambrosio, Gigli, Savar\{\textbackslash 'e\}, Kuwada and Ohta: the study of the heat flow in metric measure spaces.},
  archivePrefix = {arXiv},
  eprint = {1609.03890},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Santambrogio (2016) - Euclidean, Metric, and Wasserstein Gradient Flows.pdf},
  journal = {arXiv:1609.03890 [math]},
  keywords = {Mathematics - Analysis of PDEs,Mathematics - Dynamical Systems},
  primaryClass = {math}
}

@article{santurkar2017ClassificationBased,
  title = {A {{Classification}}-{{Based Study}} of {{Covariate Shift}} in {{GAN Distributions}}},
  author = {Santurkar, Shibani and Schmidt, Ludwig and M{\k{a}}dry, Aleksander},
  year = {2017},
  month = nov,
  abstract = {A basic, and still largely unanswered, question in the context of Generative Adversarial Networks (GANs) is whether they are truly able to capture all the fundamental characteristics of the distributions they are trained on. In particular, evaluating the diversity of GAN distributions is challenging and existing methods provide only a partial understanding of this issue. In this paper, we develop quantitative and scalable tools for assessing the diversity of GAN distributions. Specifically, we take a classification-based perspective and view loss of diversity as a form of covariate shift introduced by GANs. We examine two specific forms of such shift: mode collapse and boundary distortion. In contrast to prior work, our methods need only minimal human supervision and can be readily applied to state-of-the-art GANs on large, canonical datasets. Examining popular GANs using our tools indicates that these GANs have significant problems in reproducing the more distributional properties of their training dataset.},
  archivePrefix = {arXiv},
  eprint = {1711.00970},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Santurkar et al (2017) - A Classification-Based Study of Covariate Shift in GAN Distributions.pdf},
  journal = {arXiv:1711.00970 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{santurkar2018How,
  title = {How {{Does Batch Normalization Help Optimization}}?},
  author = {Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
  year = {2018},
  month = may,
  abstract = {Batch Normalization (BatchNorm) is a widely adopted technique that enables faster and more stable training of deep neural networks (DNNs). Despite its pervasiveness, the exact reasons for BatchNorm's effectiveness are still poorly understood. The popular belief is that this effectiveness stems from controlling the change of the layers' input distributions during training to reduce the so-called "internal covariate shift". In this work, we demonstrate that such distributional stability of layer inputs has little to do with the success of BatchNorm. Instead, we uncover a more fundamental impact of BatchNorm on the training process: it makes the optimization landscape significantly smoother. This smoothness induces a more predictive and stable behavior of the gradients, allowing for faster training.},
  archivePrefix = {arXiv},
  eprint = {1805.11604},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Santurkar et al (2018) - How Does Batch Normalization Help Optimization.pdf},
  journal = {arXiv:1805.11604 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{sap2019Risk,
  title = {The {{Risk}} of {{Racial Bias}} in {{Hate Speech Detection}}},
  booktitle = {Proceedings of the 57th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Sap, Maarten and Card, Dallas and Gabriel, Saadia and Choi, Yejin and Smith, Noah A},
  year = {2019},
  pages = {11},
  address = {{Florence, Italy}},
  abstract = {We investigate how annotators' insensitivity to differences in dialect can lead to racial bias in automatic hate speech detection models, potentially amplifying harm against minority populations. We first uncover unexpected correlations between surface markers of African American English (AAE) and ratings of toxicity in several widely-used hate speech datasets. Then, we show that models trained on these corpora acquire and propagate these biases, such that AAE tweets and tweets by self-identified African Americans are up to two times more likely to be labelled as offensive compared to others. Finally, we propose dialect and race priming as ways to reduce the racial bias in annotation, showing that when annotators are made explicitly aware of an AAE tweet's dialect they are significantly less likely to label the tweet as offensive.},
  file = {/Users/yuekai/Documents/zotero/Sap et al (2019) - The Risk of Racial Bias in Hate Speech Detection.pdf},
  language = {en}
}

@article{sattigeri2018Fairness,
  title = {Fairness {{GAN}}},
  author = {Sattigeri, Prasanna and Hoffman, Samuel C. and Chenthamarakshan, Vijil and Varshney, Kush R.},
  year = {2018},
  month = may,
  abstract = {In this paper, we introduce the Fairness GAN, an approach for generating a dataset that is plausibly similar to a given multimedia dataset, but is more fair with respect to protected attributes in allocative decision making. We propose a novel auxiliary classifier GAN that strives for demographic parity or equality of opportunity and show empirical results on several datasets, including the CelebFaces Attributes (CelebA) dataset, the Quick, Draw!\textbackslash{} dataset, and a dataset of soccer player images and the offenses they were called for. The proposed formulation is well-suited to absorbing unlabeled data; we leverage this to augment the soccer dataset with the much larger CelebA dataset. The methodology tends to improve demographic parity and equality of opportunity while generating plausible images.},
  archivePrefix = {arXiv},
  eprint = {1805.09910},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Sattigeri et al (2018) - Fairness GAN.pdf},
  journal = {arXiv:1805.09910 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{saunders2018Trial,
  title = {Trial without {{Error}}: {{Towards Safe Reinforcement Learning}} via {{Human Intervention}}},
  author = {Saunders, William and Sastry, Girish and Stuhlm{\"u}ller, Andreas and Evans, Owain},
  year = {2018},
  pages = {3},
  abstract = {During training, model-free reinforcement learning (RL) systems can explore actions that lead to harmful or costly consequences. Having a human ``in the loop'' and ready to intervene at all times can prevent these mistakes, but is prohibitively expensive for current algorithms. We explore how human oversight can be combined with a supervised learning system to prevent catastrophic events during training. We demonstrate this scheme on Atari games, with a Deep RL agent being overseen by a human for four hours. When the class of catastrophes is simple, we are able to prevent all catastrophes without affecting the agent's learning (whereas an RL baseline fails due to catastrophic forgetting).},
  file = {/Users/yuekai/Documents/zotero/Saunders et al (2018) - Trial without Error.pdf},
  language = {en}
}

@book{schapire2012Boosting,
  title = {Boosting: {{Foundations}} and {{Algorithms}}},
  shorttitle = {Boosting},
  author = {Schapire, Robert E. and Freund, Yoav},
  year = {2012},
  publisher = {{MIT Press}},
  abstract = {An accessible introduction and essential reference for an approach to machine learning that creates highly accurate prediction rules by combining many weak and inaccurate ones. Boosting is an approach to machine learning based on the idea of creating a highly accurate predictor by combining many weak and inaccurate "rules of thumb." A remarkably rich theory has evolved around boosting, with connections to a range of topics, including statistics, game theory, convex optimization, and information geometry. Boosting algorithms have also enjoyed practical success in such fields as biology, vision, and speech processing. At various times in its history, boosting has been perceived as mysterious, controversial, even paradoxical. This book, written by the inventors of the method, brings together, organizes, simplifies, and substantially extends two decades of research on boosting, presenting both theory and applications in a way that is accessible to readers from diverse backgrounds while also providing an authoritative reference for advanced researchers. With its introductory treatment of all material and its inclusion of exercises in every chapter, the book is appropriate for course use as well. The book begins with a general introduction to machine learning algorithms and their analysis; then explores the core theory of boosting, especially its ability to generalize; examines some of the myriad other theoretical viewpoints that help to explain and understand boosting; provides practical extensions of boosting for more complex learning problems; and finally presents a number of advanced theoretical topics. Numerous applications and practical illustrations are offered throughout.},
  file = {/Users/yuekai/Documents/zotero/Schapire, Freund (2012) - Boosting.pdf},
  googlebooks = {blSReLACtToC},
  isbn = {978-0-262-01718-3},
  language = {en}
}

@article{schiebinger2015geometry,
  title = {The Geometry of Kernelized Spectral Clustering},
  author = {Schiebinger, Geoffrey and Wainwright, Martin J. and Yu, Bin},
  year = {2015},
  month = apr,
  volume = {43},
  pages = {819--846},
  issn = {0090-5364},
  doi = {10.1214/14-AOS1283},
  abstract = {Clustering of data sets is a standard problem in many areas of science and engineering. The method of spectral clustering is based on embedding the data set using a kernel function, and using the top eigenvectors of the normalized Laplacian to recover the connected components. We study the performance of spectral clustering in recovering the latent labels of i.i.d. samples from a finite mixture of nonparametric distributions. The difficulty of this label recovery problem depends on the overlap between mixture components and how easily a mixture component is divided into two nonoverlapping components. When the overlap is small compared to the indivisibility of the mixture components, the principal eigenspace of the population-level normalized Laplacian operator is approximately spanned by the square-root kernelized component densities. In the finite sample setting, and under the same assumption, embedded samples from different components are approximately orthogonal with high probability when the sample size is large. As a corollary we control the fraction of samples mislabeled by spectral clustering under finite mixtures with nonparametric components.},
  archivePrefix = {arXiv},
  eprint = {1404.7552},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Schiebinger et al (2015) - The geometry of kernelized spectral clustering.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning},
  number = {2}
}

@article{schmidt2018Adversarially,
  title = {Adversarially {{Robust Generalization Requires More Data}}},
  author = {Schmidt, Ludwig and Santurkar, Shibani and Tsipras, Dimitris and Talwar, Kunal and M{\k{a}}dry, Aleksander},
  year = {2018},
  month = apr,
  abstract = {Machine learning models are often susceptible to adversarial perturbations of their inputs. Even small perturbations can cause state-of-the-art classifiers with high "standard" accuracy to produce an incorrect prediction with high confidence. To better understand this phenomenon, we study adversarially robust learning from the viewpoint of generalization. We show that already in a simple natural data model, the sample complexity of robust learning can be significantly larger than that of "standard" learning. This gap is information theoretic and holds irrespective of the training algorithm or the model family. We complement our theoretical results with experiments on popular image classification datasets and show that a similar gap exists here as well. We postulate that the difficulty of training robust classifiers stems, at least partially, from this inherently larger sample complexity.},
  archivePrefix = {arXiv},
  eprint = {1804.11285},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Schmidt et al (2018) - Adversarially Robust Generalization Requires More Data.pdf},
  journal = {arXiv:1804.11285 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{scholkopf1996Incorporating,
  title = {Incorporating Invariances in Support Vector Learning Machines},
  booktitle = {Artificial {{Neural Networks}} \textemdash{} {{ICANN}} 96},
  author = {Sch{\"o}lkopf, Bernhard and Burges, Chris and Vapnik, Vladimir},
  editor = {{von der Malsburg}, Christoph and {von Seelen}, Werner and Vorbr{\"u}ggen, Jan C. and Sendhoff, Bernhard},
  year = {1996},
  pages = {47--52},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-61510-5_12},
  abstract = {Developed only recently, support vector learning machines achieve high generalization ability by minimizing a bound on the expected test error; however, so far there existed no way of adding knowledge about invariances of a classification problem at hand. We present a method of incorporating prior knowledge about transformation invariances by applying transformations to support vectors, the training examples most critical for determining the classification boundary.},
  file = {/Users/yuekai/Documents/zotero/Schölkopf et al (1996) - Incorporating invariances in support vector learning machines.pdf},
  isbn = {978-3-540-68684-2},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@article{scholkopf2019Causality,
  title = {Causality for {{Machine Learning}}},
  author = {Sch{\"o}lkopf, Bernhard},
  year = {2019},
  month = dec,
  abstract = {Graphical causal inference as pioneered by Judea Pearl arose from research on artificial intelligence (AI), and for a long time had little connection to the field of machine learning. This article discusses where links have been and should be established, introducing key concepts along the way. It argues that the hard open problems of machine learning and AI are intrinsically related to causality, and explains how the field is beginning to understand them.},
  archivePrefix = {arXiv},
  eprint = {1911.10500},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Schölkopf (2019) - Causality for Machine Learning2.pdf},
  journal = {arXiv:1911.10500 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@phdthesis{schulman2016Optimizing,
  title = {Optimizing {{Expectations}}: {{From Deep Reinforcement Learning}} to {{Stochastic Computation Graphs}}},
  author = {Schulman, John},
  year = {2016},
  file = {/Users/yuekai/Documents/zotero/Schulman (2016) - Optimizing Expectations.pdf},
  school = {UC Berkeley}
}

@article{schultheiss2020Multicarving,
  title = {Multicarving for High-Dimensional Post-Selection Inference},
  author = {Schultheiss, Christoph and Renaux, Claude and B{\"u}hlmann, Peter},
  year = {2020},
  month = jun,
  abstract = {We consider post-selection inference for high-dimensional (generalized) linear models. Data carving (Fithian et al., 2014) is a promising technique to perform this task. However, it suffers from the instability of the model selector and hence may lead to poor replicability, especially in high-dimensional settings. We propose the multicarve method inspired by multisplitting, to improve upon stability and replicability. Furthermore, we extend existing concepts to group inference and illustrate the applicability of the methodology also for generalized linear models.},
  archivePrefix = {arXiv},
  eprint = {2006.04613},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Schultheiss et al (2020) - Multicarving for high-dimensional post-selection inference.pdf},
  journal = {arXiv:2006.04613 [stat]},
  keywords = {62J07 (Primary) 62F03 (Secondary),Statistics - Methodology},
  primaryClass = {stat}
}

@article{schumann2019Transfer,
  title = {Transfer of {{Machine Learning Fairness}} across {{Domains}}},
  author = {Schumann, Candice and Wang, Xuezhi and Beutel, Alex and Chen, Jilin and Qian, Hai and Chi, Ed H.},
  year = {2019},
  month = jun,
  abstract = {If our models are used in new or unexpected cases, do we know if they will make fair predictions? Previously, researchers developed ways to debias a model for a single problem domain. However, this is often not how models are trained and used in practice. For example, labels and demographics (sensitive attributes) are often hard to observe, resulting in auxiliary or synthetic data to be used for training, and proxies of the sensitive attribute to be used for evaluation of fairness. A model trained for one setting may be picked up and used in many others, particularly as is common with pre-training and cloud APIs. Despite the pervasiveness of these complexities, remarkably little work in the fairness literature has theoretically examined these issues. We frame all of these settings as domain adaptation problems: how can we use what we have learned in a source domain to debias in a new target domain, without directly debiasing on the target domain as if it is a completely new problem? We offer new theoretical guarantees of improving fairness across domains, and offer a modeling approach to transfer to data-sparse target domains. We give empirical results validating the theory and showing that these modeling approaches can improve fairness metrics with less data.},
  archivePrefix = {arXiv},
  eprint = {1906.09688},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Schumann et al (2019) - Transfer of Machine Learning Fairness across Domains.pdf},
  journal = {arXiv:1906.09688 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{scott2018Generalized,
  title = {A {{Generalized Neyman}}-{{Pearson Criterion}} for {{Optimal Domain Adaptation}}},
  author = {Scott, Clayton},
  year = {2018},
  month = oct,
  abstract = {In the problem of domain adaptation for binary classification, the learner is presented with labeled examples from a source domain, and must correctly classify unlabeled examples from a target domain, which may differ from the source. Previous work on this problem has assumed that the performance measure of interest is the expected value of some loss function. We introduce a new Neyman-Pearson-like criterion and argue that, for this optimality criterion, stronger domain adaptation results are possible than what has previously been established. In particular, we study a class of domain adaptation problems that generalizes both the covariate shift assumption and a model for feature-dependent label noise, and establish optimal classification on the target domain despite not having access to labelled data from this domain.},
  archivePrefix = {arXiv},
  eprint = {1810.01545},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Scott (2018) - A Generalized Neyman-Pearson Criterion for Optimal Domain Adaptation.pdf},
  journal = {arXiv:1810.01545 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{seck20191norm,
  title = {L 1-Norm Double Backpropagation Adversarial Defense},
  author = {Seck, Isma{\"i}la and Loosli, Ga{\"e}lle and Canu, Stephane},
  year = {2019},
  month = mar,
  abstract = {Adversarial examples are a challenging open problem for deep neural networks. We propose in this paper to add a penalization term that forces the decision function to be at in some regions of the input space, such that it becomes, at least locally, less sensitive to attacks. Our proposition is theoretically motivated and shows on a first set of carefully conducted experiments that it behaves as expected when used alone, and seems promising when coupled with adversarial training.},
  archivePrefix = {arXiv},
  eprint = {1903.01715},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Seck et al (2019) - L 1-norm double backpropagation adversarial defense.pdf},
  journal = {arXiv:1903.01715 [cs]},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  primaryClass = {cs}
}

@article{seguy2018LargeScale,
  title = {Large-{{Scale Optimal Transport}} and {{Mapping Estimation}}},
  author = {Seguy, Vivien and Damodaran, Bharath Bhushan and Flamary, R{\'e}mi and Courty, Nicolas and Rolet, Antoine and Blondel, Mathieu},
  year = {2018},
  month = feb,
  abstract = {This paper presents a novel two-step approach for the fundamental problem of learning an optimal map from one distribution to another. First, we learn an optimal transport (OT) plan, which can be thought as a one-to-many map between the two distributions. To that end, we propose a stochastic dual approach of regularized OT, and show empirically that it scales better than a recent related approach when the amount of samples is very large. Second, we estimate a \textbackslash textit\{Monge map\} as a deep neural network learned by approximating the barycentric projection of the previously-obtained OT plan. This parameterization allows generalization of the mapping outside the support of the input measure. We prove two theoretical stability results of regularized OT which show that our estimations converge to the OT plan and Monge map between the underlying continuous measures. We showcase our proposed approach on two applications: domain adaptation and generative modeling.},
  archivePrefix = {arXiv},
  eprint = {1711.02283},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Seguy et al (2018) - Large-Scale Optimal Transport and Mapping Estimation.pdf},
  journal = {arXiv:1711.02283 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{semenova2018Machine,
  title = {Machine {{Learning}} for {{Dynamic Discrete Choice}}},
  author = {Semenova, Vira},
  year = {2018},
  month = aug,
  abstract = {Dynamic discrete choice models often discretize the state vector and restrict its dimension in order to achieve valid inference. I propose a novel two-stage estimator for the set-identified structural parameter that incorporates a high-dimensional state space into the dynamic model of imperfect competition. In the first stage, I estimate the state variable's law of motion and the equilibrium policy function using machine learning tools. In the second stage, I plug the first-stage estimates into a moment inequality and solve for the structural parameter. The moment function is presented as the sum of two components, where the first one expresses the equilibrium assumption and the second one is a bias correction term that makes the sum insensitive (i.e., orthogonal) to first-stage bias. The proposed estimator uniformly converges at the root-N rate and I use it to construct confidence regions. The results developed here can be used to incorporate high-dimensional state space into classic dynamic discrete choice models, for example, those considered in Rust (1987), Bajari et al. (2007), and Scott (2013).},
  archivePrefix = {arXiv},
  eprint = {1808.02569},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Semenova (2018) - Machine Learning for Dynamic Discrete Choice.pdf},
  journal = {arXiv:1808.02569 [econ]},
  keywords = {Economics - Econometrics},
  primaryClass = {econ}
}

@article{shafahi2019Adversarial,
  title = {Adversarial {{Training}} for {{Free}}!},
  author = {Shafahi, Ali and Najibi, Mahyar and Ghiasi, Amin and Xu, Zheng and Dickerson, John and Studer, Christoph and Davis, Larry S. and Taylor, Gavin and Goldstein, Tom},
  year = {2019},
  month = apr,
  abstract = {Adversarial training, in which a network is trained on adversarial examples, is one of the few defenses against adversarial attacks that withstands strong attacks. Unfortunately, the high cost of generating strong adversarial examples makes standard adversarial training impractical on large-scale problems like ImageNet. We present an algorithm that eliminates the overhead cost of generating adversarial examples by recycling the gradient information computed when updating model parameters. Our "free" adversarial training algorithm achieves state-of-the-art robustness on CIFAR-10 and CIFAR-100 datasets at negligible additional cost compared to natural training, and can be 7 to 30 times faster than other strong adversarial training methods. Using a single workstation with 4 P100 GPUs and 2 days of runtime, we can train a robust model for the large-scale ImageNet classification task that maintains 40\% accuracy against PGD attacks.},
  archivePrefix = {arXiv},
  eprint = {1904.12843},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Shafahi et al (2019) - Adversarial Training for Free.pdf},
  journal = {arXiv:1904.12843 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{shafieezadeh-abadeh2015Distributionally,
  title = {Distributionally {{Robust Logistic Regression}}},
  author = {{Shafieezadeh-Abadeh}, Soroosh and Esfahani, Peyman Mohajerin and Kuhn, Daniel},
  year = {2015},
  month = sep,
  abstract = {This paper proposes a distributionally robust approach to logistic
regression. We use the Wasserstein distance to construct a ball in the space of
probability distributions centered at the uniform distribution on the training
samples. If the radius of this ball is chosen judiciously, we can guarantee
that it contains the unknown data-generating distribution with high confidence.
We then formulate a distributionally robust logistic regression model that
minimizes a worst-case expected logloss function, where the worst case is taken
over all distributions in the Wasserstein ball. We prove that this optimization
problem admits a tractable reformulation and encapsulates the classical as well
as the popular regularized logistic regression problems as special cases. We
further propose a distributionally robust approach based on Wasserstein balls
to compute upper and lower confidence bounds on the misclassification
probability of the resulting classifier. These bounds are given by the optimal
values of two highly tractable linear programs. We validate our theoretical
out-of-sample guarantees through simulated and empirical experiments.},
  file = {/Users/yuekai/Documents/zotero/Shafieezadeh-Abadeh et al (2015) - Distributionally Robust Logistic Regression.pdf},
  language = {en}
}

@article{shah2015Stochastically,
  title = {Stochastically {{Transitive Models}} for {{Pairwise Comparisons}}: {{Statistical}} and {{Computational Issues}}},
  shorttitle = {Stochastically {{Transitive Models}} for {{Pairwise Comparisons}}},
  author = {Shah, Nihar B. and Balakrishnan, Sivaraman and Guntuboyina, Adityanand and Wainwright, Martin J.},
  year = {2015},
  month = oct,
  abstract = {There are various parametric models for analyzing pairwise comparison data, including the Bradley-Terry-Luce (BTL) and Thurstone models, but their reliance on strong parametric assumptions is limiting. In this work, we study a flexible model for pairwise comparisons, under which the probabilities of outcomes are required only to satisfy a natural form of stochastic transitivity. This class includes parametric models including the BTL and Thurstone models as special cases, but is considerably more general. We provide various examples of models in this broader stochastically transitive class for which classical parametric models provide poor fits. Despite this greater flexibility, we show that the matrix of probabilities can be estimated at the same rate as in standard parametric models. On the other hand, unlike in the BTL and Thurstone models, computing the minimax-optimal estimator in the stochastically transitive model is non-trivial, and we explore various computationally tractable alternatives. We show that a simple singular value thresholding algorithm is statistically consistent but does not achieve the minimax rate. We then propose and study algorithms that achieve the minimax rate over interesting sub-classes of the full stochastically transitive class. We complement our theoretical results with thorough numerical simulations.},
  archivePrefix = {arXiv},
  eprint = {1510.05610},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Shah et al (2015) - Stochastically Transitive Models for Pairwise Comparisons.pdf},
  journal = {arXiv:1510.05610 [cs, math, stat]},
  keywords = {Computer Science - Information Theory,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{shah2018Hardness,
  title = {The {{Hardness}} of {{Conditional Independence Testing}} and the {{Generalised Covariance Measure}}},
  author = {Shah, Rajen D. and Peters, Jonas},
  year = {2018},
  month = apr,
  abstract = {It is a common saying that testing for conditional independence, i.e., testing whether X is independent of Y, given Z, is a hard statistical problem if Z is a continuous random variable. In this paper, we prove that conditional independence is indeed a particularly difficult hypothesis to test for. Statistical tests are required to have a size that is smaller than a predefined significance level, and different tests usually have power against a different class of alternatives. We prove that a valid test for conditional independence does not have power against any alternative. Given the non-existence of a uniformly valid conditional independence test, we argue that tests must be designed so their suitability for a particular problem setting may be judged easily. To address this need, we propose in the case where X and Y are univariate to nonlinearly regress X on Z, and Y on Z and then compute a test statistic based on the sample covariance between the residuals, which we call the generalised covariance measure (GCM). We prove that validity of this form of test relies almost entirely on the weak requirement that the regression procedures are able to estimate the conditional means X given Z, and Y given Z, at a slow rate. We extend the methodology to handle settings where X and Y may be multivariate or even high-dimensional. While our general procedure can be tailored to the setting at hand by combining it with any regression technique, we develop the theoretical guarantees for kernel ridge regression. A simulation study shows that the test based on GCM is competitive with state of the art conditional independence tests. Code will be available as an R package.},
  archivePrefix = {arXiv},
  eprint = {1804.07203},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Shah, Peters (2018) - The Hardness of Conditional Independence Testing and the Generalised Covariance.pdf},
  journal = {arXiv:1804.07203 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{shah2018Mixture,
  title = {Mixture {{Learning}} from {{Partial Observations}} and {{Its Application}} to {{Ranking}}},
  author = {Shah, Devavrat and Song, Dogyoon},
  year = {2018},
  month = dec,
  abstract = {Despite recent advances in rank aggregation and mixture learning, there has been a limited amount of success for learning a mixture model for ranking data. Motivated by the problem of learning a mixture of ranking models from pair-wise comparisons, we consider mixture learning from partial observations. The generic approaches for mixture learning do not generalize to this setting. Matrix estimation, however, provides a way to recover a structured underlying matrix from its partial, noisy observations. We utilize matrix estimation as a pre-processing step to extend the mixture learning problem to allow for partial observations. Instantiating our matrix estimation subroutine with singular value thresholding, we provide a bound on the estimation error with respect to \$\textbackslash |\textbackslash cdot\textbackslash |\_\{2,\textbackslash infty\}\$-norm. In particular, we show that if \$p\$ (the fraction of observed entries) scales as \$\textbackslash tilde\{\textbackslash Omega\}((\textbackslash frac\{r\}\{d\})\^\{\textbackslash frac\{1\}\{3\}\})\$, then the normalized \$\textbackslash |\textbackslash cdot\textbackslash |\_\{2,\textbackslash infty\}\$ error vanishes to \$0\$ as long as the underlying \$N \textbackslash times d\$ (\$N\textbackslash geq d\$) matrix is rank \$r\$; this holds true even if the noise is correlated across columns. As an application, we argue if \$\textbackslash Gamma p=\textbackslash tilde\{\textbackslash Omega\}(\textbackslash sqrt\{r\})\$, then the mixture components can be correctly identified with \$N=poly(d)\$ samples; \$\textbackslash Gamma\$ is the minimum gap between the mixture means. Further, we argue a large class of popular ranking models (e.g., Mallow, Multinomial Logit (MNL) Model) satisfy the sub-gaussian property when viewed through a pairwise embedding lens. Hence, our method provides a sufficient condition for efficiently recovering the mixture components for an important class of models. For example, mixtures of \$r\$ components can be clustered correctly using \$\textbackslash tilde\{O\}(rn\^4)\$ pair-wise comparisons when the components are well-separated and distributed as per either a Mallows, MNL, or any Random Utility Model over \$n\$ items.},
  archivePrefix = {arXiv},
  eprint = {1812.11917},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Shah, Song (2018) - Mixture Learning from Partial Observations and Its Application to Ranking.pdf},
  journal = {arXiv:1812.11917 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{shah2019Doubleestimationfriendly,
  title = {Double-Estimation-Friendly Inference for High-Dimensional Misspecified Models},
  author = {Shah, Rajen D. and B{\"u}hlmann, Peter},
  year = {2019},
  month = sep,
  abstract = {All models may be wrong---but that is not necessarily a problem for inference. Consider the standard \$t\$-test for the significance of a variable \$X\$ for predicting response \$Y\$ whilst controlling for \$p\$ other covariates \$Z\$ in a random design linear model. This yields correct asymptotic type\textasciitilde I error control for the null hypothesis that \$X\$ is conditionally independent of \$Y\$ given \$Z\$ under an \textbackslash emph\{arbitrary\} regression model of \$Y\$ on \$(X, Z)\$, provided that a linear regression model for \$X\$ on \$Z\$ holds. An analogous robustness to misspecification, which we term the "double-estimation-friendly" (DEF) property, also holds for Wald tests in generalised linear models, with some small modifications. In this expository paper we explore this phenomenon, and propose methodology for high-dimensional regression settings that respects the DEF property. We advocate specifying (sparse) generalised linear regression models for both \$Y\$ and the covariate of interest \$X\$; our framework gives valid inference for the conditional independence null if either of these hold. In the special case where both specifications are linear, our proposal amounts to a small modification of the popular debiased Lasso test. We also investigate constructing confidence intervals for the regression coefficient of \$X\$ via inverting our tests; these have coverage guarantees even in partially linear models where the contribution of \$Z\$ to \$Y\$ can be arbitrary. Numerical experiments demonstrate the effectiveness of the methodology.},
  archivePrefix = {arXiv},
  eprint = {1909.10828},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Shah, Bühlmann (2019) - Double-estimation-friendly inference for high-dimensional misspecified models.pdf},
  journal = {arXiv:1909.10828 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{shaikh2017EndToEnd,
  title = {An {{End}}-{{To}}-{{End Machine Learning Pipeline That Ensures Fairness Policies}}},
  author = {Shaikh, Samiulla and Vishwakarma, Harit and Mehta, Sameep and Varshney, Kush R. and Ramamurthy, Karthikeyan Natesan and Wei, Dennis},
  year = {2017},
  month = oct,
  abstract = {In consequential real-world applications, machine learning (ML) based systems are expected to provide fair and non-discriminatory decisions on candidates from groups defined by protected attributes such as gender and race. These expectations are set via policies or regulations governing data usage and decision criteria (sometimes explicitly calling out decisions by automated systems). Often, the data creator, the feature engineer, the author of the algorithm and the user of the results are different entities, making the task of ensuring fairness in an end-to-end ML pipeline challenging. Manually understanding the policies and ensuring fairness in opaque ML systems is time-consuming and error-prone, thus necessitating an end-to-end system that can: 1) understand policies written in natural language, 2) alert users to policy violations during data usage, and 3) log each activity performed using the data in an immutable storage so that policy compliance or violation can be proven later. We propose such a system to ensure that data owners and users are always in compliance with fairness policies.},
  archivePrefix = {arXiv},
  eprint = {1710.06876},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Shaikh et al (2017) - An End-To-End Machine Learning Pipeline That Ensures Fairness Policies.pdf},
  journal = {arXiv:1710.06876 [cs]},
  keywords = {Computer Science - Computers and Society},
  primaryClass = {cs}
}

@article{shalit2017Estimating,
  title = {Estimating Individual Treatment Effect: Generalization Bounds and Algorithms},
  shorttitle = {Estimating Individual Treatment Effect},
  author = {Shalit, Uri and Johansson, Fredrik D. and Sontag, David},
  year = {2017},
  month = may,
  abstract = {There is intense interest in applying machine learning to problems of causal inference in fields such as healthcare, economics and education. In particular, individual-level causal inference has important applications such as precision medicine. We give a new theoretical analysis and family of algorithms for predicting individual treatment effect (ITE) from observational data, under the assumption known as strong ignorability. The algorithms learn a "balanced" representation such that the induced treated and control distributions look similar. We give a novel, simple and intuitive generalization-error bound showing that the expected ITE estimation error of a representation is bounded by a sum of the standard generalization-error of that representation and the distance between the treated and control distributions induced by the representation. We use Integral Probability Metrics to measure distances between distributions, deriving explicit bounds for the Wasserstein and Maximum Mean Discrepancy (MMD) distances. Experiments on real and simulated data show the new algorithms match or outperform the state-of-the-art.},
  archivePrefix = {arXiv},
  eprint = {1606.03976},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Shalit et al (2017) - Estimating individual treatment effect.pdf},
  journal = {arXiv:1606.03976 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{shalizi2013Consistency,
  title = {Consistency under Sampling of Exponential Random Graph Models},
  author = {Shalizi, Cosma Rohilla and Rinaldo, Alessandro},
  year = {2013},
  month = apr,
  volume = {41},
  pages = {508--535},
  issn = {0090-5364},
  doi = {10.1214/12-AOS1044},
  abstract = {The growing availability of network data and of scientific interest in distributed systems has led to the rapid development of statistical models of network structure. Typically, however, these are models for the entire network, while the data consists only of a sampled sub-network. Parameters for the whole network, which is what is of interest, are estimated by applying the model to the sub-network. This assumes that the model is consistent under sampling, or, in terms of the theory of stochastic processes, that it defines a projective family. Focusing on the popular class of exponential random graph models (ERGMs), we show that this apparently trivial condition is in fact violated by many popular and scientifically appealing models, and that satisfying it drastically limits ERGM's expressive power. These results are actually special cases of more general results about exponential families of dependent random variables, which we also prove. Using such results, we offer easily checked conditions for the consistency of maximum likelihood estimation in ERGMs, and discuss some possible constructive responses.},
  archivePrefix = {arXiv},
  eprint = {1111.3054},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Shalizi, Rinaldo (2013) - Consistency under sampling of exponential random graph models.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory},
  number = {2}
}

@article{shalizi2016Estimating,
  title = {Estimating {{Causal Peer Influence}} in {{Homophilous Social Networks}} by {{Inferring Latent Locations}}},
  author = {Shalizi, Cosma Rohilla and McFowland III, Edward},
  year = {2016},
  month = jul,
  abstract = {Social influence cannot be identified from purely observational data on social networks, because such influence is generically confounded with latent homophily, i.e., with a node's network partners being informative about the node's attributes and therefore its behavior. We show that \{\textbackslash em if\} the network grows according to either a community (stochastic block) model, or a continuous latent space model, then latent homophilous attributes can be consistently estimated from the global pattern of social ties. Moreover, these estimates are informative enough that controlling for them allows for unbiased and consistent estimation of social-influence effects in additive models. For community models, we also provide bounds on the finite-sample bias. These are the first results on the consistent estimation of social-influence effects in the presence of latent homophily, and we discuss the prospects for generalizing them.},
  archivePrefix = {arXiv},
  eprint = {1607.06565},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Shalizi, McFowland III (2016) - Estimating Causal Peer Influence in Homophilous Social Networks by Inferring.pdf},
  journal = {arXiv:1607.06565 [physics, stat]},
  keywords = {Computer Science - Social and Information Networks,Physics - Physics and Society,Statistics - Methodology},
  primaryClass = {physics, stat}
}

@article{shalizi2017Consistency,
  title = {Consistency of {{Maximum Likelihood}} for {{Continuous}}-{{Space Network Models}}},
  author = {Shalizi, Cosma Rohilla and Asta, Dena},
  year = {2017},
  month = nov,
  file = {/Users/yuekai/Documents/zotero/Shalizi, Asta (2017) - Consistency of Maximum Likelihood for Continuous-Space Network Models.pdf},
  language = {en}
}

@article{shallue2018Measuring,
  title = {Measuring the {{Effects}} of {{Data Parallelism}} on {{Neural Network Training}}},
  author = {Shallue, Christopher J. and Lee, Jaehoon and Antognini, Joseph and {Sohl-Dickstein}, Jascha and Frostig, Roy and Dahl, George E.},
  year = {2018},
  month = nov,
  abstract = {Recent hardware developments have dramatically increased the scale of data parallelism available for neural network training. Among the simplest ways to harness next-generation hardware is to increase the batch size in standard mini-batch neural network training algorithms. In this work, we aim to experimentally characterize the effects of increasing the batch size on training time, as measured by the number of steps necessary to reach a goal out-of-sample error. We study how this relationship varies with the training algorithm, model, and data set, and find extremely large variation between workloads. Along the way, we show that disagreements in the literature on how batch size affects model quality can largely be explained by differences in metaparameter tuning and compute budgets at different batch sizes. We find no evidence that larger batch sizes degrade out-of-sample performance. Finally, we discuss the implications of our results on efforts to train neural networks much faster in the future. Our experimental data is publicly available as a database of 71,638,836 loss measurements taken over the course of training for 168,160 individual models across 35 workloads.},
  archivePrefix = {arXiv},
  eprint = {1811.03600},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Shallue et al (2018) - Measuring the Effects of Data Parallelism on Neural Network Training.pdf},
  journal = {arXiv:1811.03600 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{shanahan2018Machine,
  title = {Machine Learning Action Parameters in Lattice Quantum Chromodynamics},
  author = {Shanahan, Phiala and Trewartha, Daneil and Detmold, William},
  year = {2018},
  month = may,
  volume = {97},
  publisher = {{American Physical Society (APS)}},
  issn = {2470-0010},
  doi = {10.1103/PhysRevD.97.094506},
  abstract = {The U.S. Department of Energy's Office of Scientific and Technical Information},
  file = {/Users/yuekai/Documents/zotero/Shanahan et al (2018) - Machine learning action parameters in lattice quantum chromodynamics.pdf},
  journal = {Physical Review D},
  language = {English},
  number = {JLAB-THY-18-2627; DOE/OR/23177-4325; arXiv:1801.05784; MIT-CTP/4980}
}

@article{shao1994Bootstrap,
  title = {Bootstrap {{Sample Size}} in {{Nonregular Cases}}},
  author = {Shao, Jun},
  year = {1994},
  volume = {122},
  pages = {1251--1262},
  issn = {0002-9939},
  doi = {10.2307/2161196},
  abstract = {We study the bootstrap estimator fo the sampling distribution of a given statistic in some nonregular cases where the given statistic is nonsmooth or not-so-smooth. It is found that the ordinary bootstrap, based on a bootstrap sample of the same size as the original data set, produces an inconsistent bootstrap estimator. On the other hand, when we draw a bootstrap sample of a smaller size with the ratio of the size of the bootstrap sample over the size of the original data set tending to zero, the resulting bootstrap estimator is consistent. Examples of these nonregular cases are given, including the cases of functions of means with null first-order derivatives, differentiable statistical functionals with null influence function, nondifferentiable functions of means, and estimators based on some test results.},
  file = {/Users/yuekai/Documents/zotero/Shao (1994) - Bootstrap Sample Size in Nonregular Cases.pdf},
  journal = {Proceedings of the American Mathematical Society},
  number = {4}
}

@book{shapiro2009Lectures,
  title = {Lectures on {{Stochastic Programming}}: {{Modeling}} and {{Theory}}},
  shorttitle = {Lectures on {{Stochastic Programming}}},
  author = {Shapiro, Alexander and Dentcheva, Darinka and Ruszczy{\'n}ski, Andrzej},
  year = {2009},
  month = jan,
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9780898718751},
  file = {/Users/yuekai/Documents/zotero/Shapiro et al (2009) - Lectures on Stochastic Programming.pdf},
  isbn = {978-0-89871-687-0 978-0-89871-875-1},
  language = {en}
}

@article{sharchilev2018Finding,
  title = {Finding {{Influential Training Samples}} for {{Gradient Boosted Decision Trees}}},
  author = {Sharchilev, Boris and Ustinovsky, Yury and Serdyukov, Pavel and {de Rijke}, Maarten},
  year = {2018},
  month = feb,
  abstract = {We address the problem of finding influential training samples for a particular case of tree ensemble-based models, e.g., Random Forest (RF) or Gradient Boosted Decision Trees (GBDT). A natural way of formalizing this problem is studying how the model's predictions change upon leave-one-out retraining, leaving out each individual training sample. Recent work has shown that, for parametric models, this analysis can be conducted in a computationally efficient way. We propose several ways of extending this framework to non-parametric GBDT ensembles under the assumption that tree structures remain fixed. Furthermore, we introduce a general scheme of obtaining further approximations to our method that balance the trade-off between performance and computational complexity. We evaluate our approaches on various experimental setups and use-case scenarios and demonstrate both the quality of our approach to finding influential training samples in comparison to the baselines and its computational efficiency.},
  archivePrefix = {arXiv},
  eprint = {1802.06640},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Sharchilev et al (2018) - Finding Influential Training Samples for Gradient Boosted Decision Trees.pdf},
  journal = {arXiv:1802.06640 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{shen2019Interpreting,
  title = {Interpreting the {{Latent Space}} of {{GANs}} for {{Semantic Face Editing}}},
  author = {Shen, Yujun and Gu, Jinjin and Tang, Xiaoou and Zhou, Bolei},
  year = {2019},
  month = nov,
  abstract = {Despite the recent advance of Generative Adversarial Networks (GANs) in high-fidelity image synthesis, there lacks enough understanding on how GANs are able to map the latent code sampled from a random distribution to a photo-realistic image. Previous work assumes the latent space learned by GANs follows a distributed representation but observes the vector arithmetic phenomenon. In this work, we propose a novel framework, called InterFaceGAN, for semantic face editing by interpreting the latent semantics learned by GANs. In this framework, we conduct a detailed study on how different semantics are encoded in the latent space of GANs for face synthesis. We find that the latent code of well-trained generative models actually learns a disentangled representation after linear transformations. We explore the disentanglement between various semantics and manage to decouple some entangled semantics with subspace projection, leading to more precise control of facial attributes. Besides manipulating gender, age, expression, and the presence of eyeglasses, we can even vary the face pose as well as fix the artifacts accidentally generated by GAN models. The proposed method is further applied to achieve real image manipulation when combined with GAN inversion methods or some encoder-involved models. Extensive results suggest that learning to synthesize faces spontaneously brings a disentangled and controllable facial attribute representation.},
  archivePrefix = {arXiv},
  eprint = {1907.10786},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Shen et al (2019) - Interpreting the Latent Space of GANs for Semantic Face Editing.pdf},
  journal = {arXiv:1907.10786 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryClass = {cs}
}

@article{shevlyakov2008Redescending,
  title = {Redescending {{M}} -Estimators},
  author = {Shevlyakov, Georgy and Morgenthaler, Stephan and Shurygin, Alexander},
  year = {2008},
  month = oct,
  volume = {138},
  pages = {16},
  abstract = {In finite sample studies redescending M -estimators outperform bounded M -estimators (see for example, Andrews et al., 1972). Even though redescenders arise naturally out of the maximum likelihood approach if one uses very heavy-tailed models, the commonly used redescenders have been derived from purely heuristic considerations. Using a recent approach proposed by Shurygin, we studied the optimality of redescending M -estimators. We show that redescending M -estimator can be designed by applying a global minimax criterion to locally robust estimators, namely maximizing the minimum variance sensitivity of an estimator over a given class of densities. As a particular result, we proved that Smith's estimator, which is a compromise between Huber's skipped mean and Tukey's biweight, provides the guaranteed level of an estimator's variance sensitivity over the class of distribution densities with a bounded variance.},
  file = {/Users/yuekai/Documents/zotero/Shevlyakov et al (2008) - Redescending M -estimators.pdf},
  journal = {Journal of Statistical Planning and Inference},
  language = {en},
  number = {10}
}

@article{shi2009Data,
  title = {Data Spectroscopy: {{Eigenspaces}} of Convolution Operators and Clustering},
  shorttitle = {Data Spectroscopy},
  author = {Shi, Tao and Belkin, Mikhail and Yu, Bin},
  year = {2009},
  month = dec,
  volume = {37},
  pages = {3960--3984},
  issn = {0090-5364},
  doi = {10.1214/09-AOS700},
  abstract = {This paper focuses on obtaining clustering information about a distribution from its i.i.d. samples. We develop theoretical results to understand and use clustering information contained in the eigenvectors of data adjacency matrices based on a radial kernel function with a sufficiently fast tail decay. In particular, we provide population analyses to gain insights into which eigenvectors should be used and when the clustering information for the distribution can be recovered from the sample. We learn that a fixed number of top eigenvectors might at the same time contain redundant clustering information and miss relevant clustering information. We use this insight to design the data spectroscopic clustering (DaSpec) algorithm that utilizes properly selected eigenvectors to determine the number of clusters automatically and to group the data accordingly. Our findings extend the intuitions underlying existing spectral techniques such as spectral clustering and Kernel Principal Components Analysis, and provide new understanding into their usability and modes of failure. Simulation studies and experiments on real-world data are conducted to show the potential of our algorithm. In particular, DaSpec is found to handle unbalanced groups and recover clusters of different shapes better than the competing methods.},
  archivePrefix = {arXiv},
  eprint = {0807.3719},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Shi et al (2009) - Data spectroscopy.pdf},
  journal = {The Annals of Statistics},
  keywords = {Statistics - Machine Learning,Statistics - Methodology},
  number = {6B}
}

@article{shi2019Determining,
  title = {Determining the {{Number}} of {{Latent Factors}} in {{Statistical Multi}}-{{Relational Learning}}},
  author = {Shi, Chengchun and Lu, Wenbin and Song, Rui},
  year = {2019},
  month = feb,
  volume = {20},
  pages = {38},
  abstract = {Statistical relational learning is primarily concerned with learning and inferring relationships between entities in large-scale knowledge graphs. Nickel et al. (2011) proposed a RESCAL tensor factorization model for statistical relational learning, which achieves better or at least comparable results on common benchmark data sets when compared to other state-of-the-art methods. Given a positive integer s, RESCAL computes an s-dimensional latent vector for each entity. The latent factors can be further used for solving relational learning tasks, such as collective classification, collective entity resolution and link-based clustering.},
  file = {/Users/yuekai/Documents/zotero/Shi et al (2019) - Determining the Number of Latent Factors in Statistical Multi-Relational.pdf},
  journal = {Journal of Machine Learning Research},
  language = {en}
}

@article{shi2020Learning,
  title = {On {{Learning Rates}} and {{Schr}}\textbackslash "odinger {{Operators}}},
  author = {Shi, Bin and Su, Weijie J. and Jordan, Michael I.},
  year = {2020},
  month = apr,
  abstract = {The learning rate is perhaps the single most important parameter in the training of neural networks and, more broadly, in stochastic (nonconvex) optimization. Accordingly, there are numerous effective, but poorly understood, techniques for tuning the learning rate, including learning rate decay, which starts with a large initial learning rate that is gradually decreased. In this paper, we present a general theoretical analysis of the effect of the learning rate in stochastic gradient descent (SGD). Our analysis is based on the use of a learning-rate-dependent stochastic differential equation (lr-dependent SDE) that serves as a surrogate for SGD. For a broad class of objective functions, we establish a linear rate of convergence for this continuous-time formulation of SGD, highlighting the fundamental importance of the learning rate in SGD, and contrasting to gradient descent and stochastic gradient Langevin dynamics. Moreover, we obtain an explicit expression for the optimal linear rate by analyzing the spectrum of the Witten-Laplacian, a special case of the Schr\textbackslash "odinger operator associated with the lr-dependent SDE. Strikingly, this expression clearly reveals the dependence of the linear convergence rate on the learning rate -- the linear rate decreases rapidly to zero as the learning rate tends to zero for a broad class of nonconvex functions, whereas it stays constant for strongly convex functions. Based on this sharp distinction between nonconvex and convex problems, we provide a mathematical interpretation of the benefits of using learning rate decay for nonconvex optimization.},
  archivePrefix = {arXiv},
  eprint = {2004.06977},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Shi et al (2020) - On Learning Rates and Schr-odinger Operators.pdf},
  journal = {arXiv:2004.06977 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Analysis of PDEs,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{shneiderman2016Opinion,
  title = {Opinion: {{The}} Dangers of Faulty, Biased, or Malicious Algorithms Requires Independent Oversight},
  shorttitle = {Opinion},
  author = {Shneiderman, Ben},
  year = {2016},
  month = nov,
  volume = {113},
  pages = {13538--13540},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1618211113},
  abstract = {The recent crash of a driverless car sends a clear warning about how algorithms can be deadly (1). Similarly, there are clear dangers in vital national services, such as communications, financial trading, healthcare, and transportation. These services depend on sophisticated algorithms, some relying on unpredictable artificial intelligence techniques, such as deep learning, that are increasingly embedded in complex software systems (2{$\Downarrow$}\textendash 4). As search algorithms, high-speed trading, medical devices, and autonomous aircraft become more widely implemented, stronger checks become necessary to prevent failures (5, 6).

Proper independent oversight and investigation of flawed algorithms can help anticipate and improve quality, hence avoiding failures that lead to disaster. Image courtesy of Shutterstock/joloei.

What might help are traditional forms of independent oversight that use knowledgeable people who have powerful tools to anticipate, monitor, and retrospectively review operations of vital national services. The three forms of independent oversight that have been used in the past by industry and governments\textemdash planning oversight, continuous monitoring by knowledgeable review boards using advanced software, and a retrospective analysis of disasters\textemdash provide guidance for responsible technology leaders and concerned policy makers (7). Considering all three forms of oversight could lead to policies that prevent inadequate designs, biased outcomes, or criminal actions.

There is a long history of analyses of how poor design, unintentional bias, and malicious interventions can cause algorithms to trigger huge financial losses, promote unfair decisions, violate laws, and even cause deaths (8). Helen Nissenbaum, a scholar who focuses on the impact of technology on culture and society, identified the sources of bugs and biases in software, complaining about the ``systematic erosion \ldots{} 

[{$\carriagereturn$}][1]1Email: ben\{at\}cs.umd.edu.

 [1]: \#xref-corresp-1-1},
  chapter = {Opinion},
  file = {/Users/yuekai/Documents/zotero/Shneiderman (2016) - Opinion.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {48},
  pmid = {27911762}
}

@inproceedings{shokri2017Membership,
  title = {Membership {{Inference Attacks Against Machine Learning Models}}},
  booktitle = {2017 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})},
  author = {Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  year = {2017},
  month = may,
  pages = {3--18},
  publisher = {{IEEE}},
  address = {{San Jose, CA, USA}},
  doi = {10.1109/SP.2017.41},
  abstract = {We quantitatively investigate how machine learning models leak information about the individual data records on which they were trained. We focus on the basic membership inference attack: given a data record and black-box access to a model, determine if the record was in the model's training dataset. To perform membership inference against a target model, we make adversarial use of machine learning and train our own inference model to recognize differences in the target model's predictions on the inputs that it trained on versus the inputs that it did not train on.},
  file = {/Users/yuekai/Documents/zotero/Shokri et al (2017) - Membership Inference Attacks Against Machine Learning Models.pdf},
  isbn = {978-1-5090-5533-3},
  language = {en}
}

@article{shu2018Amortized,
  title = {Amortized {{Inference Regularization}}},
  author = {Shu, Rui and Bui, Hung H. and Zhao, Shengjia and Kochenderfer, Mykel J. and Ermon, Stefano},
  year = {2018},
  month = may,
  abstract = {The variational autoencoder (VAE) is a popular model for density estimation and representation learning. Canonically, the variational principle suggests to prefer an expressive inference model so that the variational approximation is accurate. However, it is often overlooked that an overly-expressive inference model can be detrimental to the test set performance of both the amortized posterior approximator and, more importantly, the generative density estimator. In this paper, we leverage the fact that VAEs rely on amortized inference and propose techniques for amortized inference regularization (AIR) that control the smoothness of the inference model. We demonstrate that, by applying AIR, it is possible to improve VAE generalization on both inference and generative performance. Our paper challenges the belief that amortized inference is simply a mechanism for approximating maximum likelihood training and illustrates that regularization of the amortization family provides a new direction for understanding and improving generalization in VAEs.},
  archivePrefix = {arXiv},
  eprint = {1805.08913},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Shu et al (2018) - Amortized Inference Regularization.pdf},
  journal = {arXiv:1805.08913 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{siegel2019Accelerated,
  title = {Accelerated {{First}}-{{Order Methods}}: {{Differential Equations}} and {{Lyapunov Functions}}},
  shorttitle = {Accelerated {{First}}-{{Order Methods}}},
  author = {Siegel, Jonathan W.},
  year = {2019},
  month = may,
  abstract = {We develop a theory of accelerated first-order optimization from the viewpoint of differential equations and Lyapunov functions. Building upon the work of previous authors, we consider differential equations which model the behavior of accelerated gradient descent. Our main contribution is to provide a general framework for discretizating the differential equations to produce accelerated methods. An important novelty in our approach is the treatment of stochastic discretizations, which introduce randomness at each iteration. This leads to a unified derivation of a wide variety of methods, which include accelerated gradient descent, FISTA, and accelerated coordinate descent as special cases.},
  archivePrefix = {arXiv},
  eprint = {1903.05671},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Siegel (2019) - Accelerated First-Order Methods.pdf},
  journal = {arXiv:1903.05671 [math]},
  keywords = {Mathematics - Optimization and Control},
  primaryClass = {math}
}

@article{silin2020Hypothesis,
  title = {Hypothesis Testing for Eigenspaces of Covariance Matrix},
  author = {Silin, Igor and Fan, Jianqing},
  year = {2020},
  month = feb,
  abstract = {Eigenspaces of covariance matrices play an important role in statistical machine learning, arising in variety of modern algorithms. Quantitatively, it is convenient to describe the eigenspaces in terms of spectral projectors. This work focuses on hypothesis testing for the spectral projectors, both in one- and two-sample scenario. We present new tests, based on a specific matrix norm developed in order to utilize the structure of the spectral projectors. A new resampling technique of independent interest is introduced and analyzed: it serves as an alternative to the well-known multiplier bootstrap, significantly reducing computational complexity of bootstrap-based methods. We provide theoretical guarantees for the type-I error of our procedures, which remarkably improve the previously obtained results in the field. Moreover, we analyze power of our tests. Numerical experiments illustrate good performance of the proposed methods compared to previously developed ones.},
  archivePrefix = {arXiv},
  eprint = {2002.09810},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Silin, Fan (2020) - Hypothesis testing for eigenspaces of covariance matrix.pdf},
  journal = {arXiv:2002.09810 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{simoiu2016Problem,
  title = {The {{Problem}} of {{Infra}}-Marginality in {{Outcome Tests}} for {{Discrimination}}},
  author = {Simoiu, Camelia and {Corbett-Davies}, Sam and Goel, Sharad},
  year = {2016},
  month = jul,
  abstract = {Outcome tests are a popular method for detecting bias in lending, hiring, and policing decisions. These tests operate by comparing the success rate of decisions across groups. For example, if loans made to minority applicants are observed to be repaid more often than loans made to whites, it suggests that only exceptionally qualified minorities are granted loans, indicating discrimination. Outcome tests, however, are known to suffer from the problem of infra-marginality: even absent discrimination, the repayment rates for minority and white loan recipients might differ if the two groups have different risk distributions. Thus, at least in theory, outcome tests can fail to accurately detect discrimination. We develop a new statistical test of discrimination---the threshold test---that mitigates the problem of infra-marginality by jointly estimating decision thresholds and risk distributions via a hierarchical Bayesian latent variable model. Applying our test to a dataset of 4.5 million police stops in North Carolina, we find that the problem of infra-marginality is more than a theoretical possibility, and can cause the outcome test to yield misleading results in practice.},
  archivePrefix = {arXiv},
  eprint = {1607.05376},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Simoiu et al (2016) - The Problem of Infra-marginality in Outcome Tests for Discrimination.pdf},
  journal = {arXiv:1607.05376 [stat]},
  keywords = {Statistics - Applications},
  primaryClass = {stat}
}

@article{simon-gabriel2018Adversarial,
  title = {Adversarial {{Vulnerability}} of {{Neural Networks Increases With Input Dimension}}},
  author = {{Simon-Gabriel}, Carl-Johann and Ollivier, Yann and Bottou, L{\'e}on and Sch{\"o}lkopf, Bernhard and {Lopez-Paz}, David},
  year = {2018},
  month = feb,
  abstract = {Over the past four years, neural networks have been proven vulnerable to adversarial images: targeted but imperceptible image perturbations lead to drastically different predictions. We show that adversarial vulnerability increases with the gradients of the training objective when viewed as a function of the inputs. For most current network architectures, we prove that the 1-norm of these gradients grows as the square root of the input size. These nets therefore become increasingly vulnerable with growing image size. Our proofs rely on the network's weight distribution at initialization, but extensive experiments confirm that our conclusions still hold after training.},
  archivePrefix = {arXiv},
  eprint = {1802.01421},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Simon-Gabriel et al (2018) - Adversarial Vulnerability of Neural Networks Increases With Input Dimension.pdf},
  journal = {arXiv:1802.01421 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{simon-gabriel2018Kernel,
  title = {Kernel {{Distribution Embeddings}}: {{Universal Kernels}}, {{Characteristic Kernels}} and {{Kernel Metrics}} on {{Distributions}}},
  author = {{Simon-Gabriel}, Carl-Johann and Scholkopf, Bernhard},
  year = {2018},
  pages = {29},
  abstract = {Kernel mean embeddings have become a popular tool in machine learning. They map probability measures to functions in a reproducing kernel Hilbert space. The distance between two mapped measures defines a semi-distance over the probability measures known as the maximum mean discrepancy (MMD). Its properties depend on the underlying kernel and have been linked to three fundamental concepts of the kernel literature: universal, characteristic and strictly positive definite kernels.},
  file = {/Users/yuekai/Documents/zotero/Simon-Gabriel, Scholkopf (2018) - Kernel Distribution Embeddings.pdf},
  language = {en}
}

@article{simonite2019Best,
  title = {The {{Best Algorithms Still Struggle}} to {{Recognize Black Faces}}},
  author = {Simonite, Tom},
  year = {2019},
  month = jul,
  issn = {1059-1028},
  abstract = {US government tests find even top-performing facial recognition systems misidentify black people at rates 5 to 10 times higher than they do white people.},
  journal = {Wired},
  keywords = {algorithms,artificial intelligence,facial recognition,law enforcement,web},
  language = {en}
}

@article{singh2018Fairness,
  title = {Fairness of {{Exposure}} in {{Rankings}}},
  author = {Singh, Ashudeep and Joachims, Thorsten},
  year = {2018},
  pages = {2219--2228},
  doi = {10.1145/3219819.3220088},
  abstract = {Rankings are ubiquitous in the online world today. As we have transitioned from finding books in libraries to ranking products, jobs, job applicants, opinions and potential romantic partners, there is a substantial precedent that ranking systems have a responsibility not only to their users but also to the items being ranked. To address these often conflicting responsibilities, we propose a conceptual and computational framework that allows the formulation of fairness constraints on rankings in terms of exposure allocation. As part of this framework, we develop efficient algorithms for finding rankings that maximize the utility for the user while provably satisfying a specifiable notion of fairness. Since fairness goals can be application specific, we show how a broad range of fairness constraints can be implemented using our framework, including forms of demographic parity, disparate treatment, and disparate impact constraints. We illustrate the effect of these constraints by providing empirical results on two ranking problems.},
  archivePrefix = {arXiv},
  eprint = {1802.07281},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Singh, Joachims (2018) - Fairness of Exposure in Rankings.pdf},
  journal = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining  - KDD '18},
  keywords = {Computer Science - Computers and Society,Computer Science - Information Retrieval}
}

@article{singh2019Fair,
  title = {Fair {{Predictors}} under {{Distribution Shift}}},
  author = {Singh, Harvineet and Singh, Rina and Mhasawade, Vishwali and Chunara, Rumi},
  year = {2019},
  month = nov,
  abstract = {Recent work on fair machine learning adds to a growing set of algorithmic safeguards required for deployment in high societal impact areas. A fundamental concern with model deployment is to guarantee stable performance under changes in data distribution. Extensive work in domain adaptation addresses this concern, albeit with the notion of stability limited to that of predictive performance. We provide conditions under which a stable model both in terms of prediction and fairness performance can be trained. Building on the problem setup of causal domain adaptation, we select a subset of features for training predictors with fairness constraints such that risk with respect to an unseen target data distribution is minimized. Advantages of the approach are demonstrated on synthetic datasets and on the task of diagnosing acute kidney injury in a real-world dataset under an instance of measurement policy shift and selection bias.},
  archivePrefix = {arXiv},
  eprint = {1911.00677},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Singh et al (2019) - Fair Predictors under Distribution Shift.pdf},
  journal = {arXiv:1911.00677 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{singh2019Kernel,
  title = {Kernel {{Instrumental Variable Regression}}},
  author = {Singh, Rahul and Sahani, Maneesh and Gretton, Arthur},
  year = {2019},
  month = dec,
  abstract = {Instrumental variable (IV) regression is a strategy for learning causal relationships in observational data. If measurements of input X and output Y are confounded, the causal relationship can nonetheless be identified if an instrumental variable Z is available that influences X directly, but is conditionally independent of Y given X and the unmeasured confounder. The classic two-stage least squares algorithm (2SLS) simplifies the estimation problem by modeling all relationships as linear functions. We propose kernel instrumental variable regression (KIV), a nonparametric generalization of 2SLS, modeling relations among X, Y, and Z as nonlinear functions in reproducing kernel Hilbert spaces (RKHSs). We prove the consistency of KIV under mild assumptions, and derive conditions under which convergence occurs at the minimax optimal rate for unconfounded, single-stage RKHS regression. In doing so, we obtain an efficient ratio between training sample sizes used in the algorithm's first and second stages. In experiments, KIV outperforms state of the art alternatives for nonparametric IV regression.},
  archivePrefix = {arXiv},
  eprint = {1906.00232},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Singh et al (2019) - Kernel Instrumental Variable Regression.pdf},
  journal = {arXiv:1906.00232 [cs, econ, math, stat]},
  keywords = {Computer Science - Machine Learning,Economics - Econometrics,Mathematics - Functional Analysis,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, econ, math, stat}
}

@article{singh2019Model,
  title = {Model {{Fusion}} via {{Optimal Transport}}},
  author = {Singh, Sidak Pal and Jaggi, Martin},
  year = {2019},
  month = dec,
  abstract = {Combining different models is a widely used paradigm in machine learning applications. While the most common approach is to form an ensemble of models and average their individual predictions, this approach is often rendered infeasible by given resource constraints in terms of memory and computation, which grow linearly with the number of models. We present a layer-wise model fusion procedure for neural networks that utilizes optimal transport to (soft-) align neurons across the models before averaging their associated parameters. We discuss two main algorithms for fusing neural networks in this "one-shot" manner, without requiring any retraining. Finally, we illustrate on CIFAR10 and MNIST how this significantly outperforms vanilla averaging on convolutional networks, such as VGG11 and multi-layer perceptrons, and for transfer tasks even surpasses the performance of both original models.},
  archivePrefix = {arXiv},
  eprint = {1910.05653},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Singh, Jaggi (2019) - Model Fusion via Optimal Transport.pdf},
  journal = {arXiv:1910.05653 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{singh2019Policy,
  title = {Policy {{Learning}} for {{Fairness}} in {{Ranking}}},
  author = {Singh, Ashudeep and Joachims, Thorsten},
  year = {2019},
  month = feb,
  abstract = {Conventional Learning-to-Rank (LTR) methods optimize the utility of the rankings to the users, but they are oblivious to their impact on the ranked items. However, there has been a growing understanding that the latter is important to consider for a wide range of ranking applications (e.g. online marketplaces, job placement, admissions). To address this need, we propose a general LTR framework that can optimize a wide range of utility metrics (e.g. NDCG) while satisfying fairness of exposure constraints with respect to the items. This framework expands the class of learnable ranking functions to stochastic ranking policies, which provides a language for rigorously expressing fairness specifications. Furthermore, we provide a new LTR algorithm called Fair-PG-Rank for directly searching the space of fair ranking policies via a policy-gradient approach. Beyond the theoretical evidence in deriving the framework and the algorithm, we provide empirical results on simulated and real-world datasets verifying the effectiveness of the approach in individual and group-fairness settings.},
  archivePrefix = {arXiv},
  eprint = {1902.04056},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Singh, Joachims (2019) - Policy Learning for Fairness in Ranking.pdf},
  journal = {arXiv:1902.04056 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Information Retrieval,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{sinha2017Certifying,
  title = {Certifying {{Some Distributional Robustness}} with {{Principled Adversarial Training}}},
  author = {Sinha, Aman and Namkoong, Hongseok and Duchi, John},
  year = {2017},
  month = oct,
  abstract = {Neural networks are vulnerable to adversarial examples and researchers have proposed many heuristic attack and defense mechanisms. We address this problem through the principled lens of distributionally robust optimization, which guarantees performance under adversarial input perturbations. By considering a Lagrangian penalty formulation of perturbing the underlying data distribution in a Wasserstein ball, we provide a training procedure that augments model parameter updates with worst-case perturbations of training data. For smooth losses, our procedure provably achieves moderate levels of robustness with little computational or statistical cost relative to empirical risk minimization. Furthermore, our statistical guarantees allow us to efficiently certify robustness for the population loss. For imperceptible perturbations, our method matches or outperforms heuristic approaches.},
  archivePrefix = {arXiv},
  eprint = {1710.10571},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Sinha et al (2017) - Certifying Some Distributional Robustness with Principled Adversarial Training.pdf},
  journal = {arXiv:1710.10571 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{slack2020Fairnessa,
  title = {Fairness {{Warnings}} and {{Fair}}-{{MAML}}: {{Learning Fairly}} with {{Minimal Data}}},
  author = {Slack, Dylan and Friedler, Sorelle A and Givental, Emile},
  year = {2020},
  pages = {10},
  abstract = {Motivated by concerns surrounding the fairness effects of sharing and transferring fair machine learning tools, we propose two algorithms: Fairness Warnings and Fair-MAML. The first is a modelagnostic algorithm that provides interpretable boundary conditions for when a fairly trained model may not behave fairly on similar but slightly different tasks within a given domain. The second is a fair meta-learning approach to train models that can be quickly fine-tuned to specific tasks from only a few number of sample instances while balancing fairness and accuracy. We demonstrate experimentally the individual utility of each model using relevant baselines and provide the first experiment to our knowledge of K-shot fairness, i.e. training a fair model on a new task with only K data points. Then, we illustrate the usefulness of both algorithms as a combined method for training models from a few data points on new tasks while using Fairness Warnings as interpretable boundary conditions under which the newly trained model may not be fair.},
  file = {/Users/yuekai/Documents/zotero/Slack et al (2020) - Fairness Warnings and Fair-MAML.pdf},
  language = {en}
}

@article{smirnova2019Distributionally,
  title = {Distributionally {{Robust Reinforcement Learning}}},
  author = {Smirnova, Elena and Dohmatob, Elvis and Mary, J{\'e}r{\'e}mie},
  year = {2019},
  month = feb,
  abstract = {Real-world applications require RL algorithms to act safely. During learning process, it is likely that the agent executes sub-optimal actions that may lead to unsafe/poor states of the system. Exploration is particularly brittle in high-dimensional state/action space due to increased number of low-performing actions. In this work, we consider risk-averse exploration in approximate RL setting. To ensure safety during learning, we propose the distributionally robust policy iteration scheme that provides lower bound guarantee on state-values. Our approach induces a dynamic level of risk to prevent poor decisions and yet preserves the convergence to the optimal policy. Our formulation results in a efficient algorithm that accounts for a simple re-weighting of policy actions in the standard policy iteration scheme. We extend our approach to continuous state/action space and present a practical algorithm, distributionally robust soft actor-critic, that implements a different exploration strategy: it acts conservatively at short-term and it explores optimistically in a long-run. We provide promising experimental results on continuous control tasks.},
  archivePrefix = {arXiv},
  eprint = {1902.08708},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Smirnova et al (2019) - Distributionally Robust Reinforcement Learning.pdf},
  journal = {arXiv:1902.08708 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{smith2014Optimization,
  title = {Optimization {{Techniques}} on {{Riemannian Manifolds}}},
  author = {Smith, Steven Thomas},
  year = {2014},
  month = jul,
  abstract = {The techniques and analysis presented in this paper provide new methods to solve optimization problems posed on Riemannian manifolds. A new point of view is offered for the solution of constrained optimization problems. Some classical optimization techniques on Euclidean space are generalized to Riemannian manifolds. Several algorithms are presented and their convergence properties are analyzed employing the Riemannian structure of the manifold. Specifically, two apparently new algorithms, which can be thought of as Newton's method and the conjugate gradient method on Riemannian manifolds, are presented and shown to possess, respectively, quadratic and superlinear convergence. Examples of each method on certain Riemannian manifolds are given with the results of numerical experiments. Rayleigh's quotient defined on the sphere is one example. It is shown that Newton's method applied to this function converges cubically, and that the Rayleigh quotient iteration is an efficient approximation of Newton's method. The Riemannian version of the conjugate gradient method applied to this function gives a new algorithm for finding the eigenvectors corresponding to the extreme eigenvalues of a symmetric matrix. Another example arises from extremizing the function \$\textbackslash mathop\{\textbackslash rm tr\} \{\textbackslash Theta\}\^\{\textbackslash scriptscriptstyle\textbackslash rm T\}Q\{\textbackslash Theta\}N\$ on the special orthogonal group. In a similar example, it is shown that Newton's method applied to the sum of the squares of the off-diagonal entries of a symmetric matrix converges cubically.},
  archivePrefix = {arXiv},
  eprint = {1407.5965},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Smith (2014) - Optimization Techniques on Riemannian Manifolds.pdf},
  journal = {arXiv:1407.5965 [cs, math]},
  keywords = {Computer Science - Computational Geometry,Computer Science - Numerical Analysis,Mathematics - Differential Geometry,Mathematics - Dynamical Systems,Mathematics - Optimization and Control},
  primaryClass = {cs, math}
}

@article{sommerfeld2016Inference,
  title = {Inference for {{Empirical Wasserstein Distances}} on {{Finite Spaces}}},
  author = {Sommerfeld, Max and Munk, Axel},
  year = {2016},
  month = oct,
  abstract = {The Wasserstein distance is an attractive tool for data analysis but statistical inference is hindered by the lack of distributional limits. To overcome this obstacle, for probability measures supported on finitely many points, we derive the asymptotic distribution of empirical Wasserstein distances as the optimal value of a linear program with random objective function. This facilitates statistical inference (e.g. confidence intervals for sample based Wasserstein distances) in large generality. Our proof is based on directional Hadamard differentiability. Failure of the classical bootstrap and alternatives are discussed. The utility of the distributional results is illustrated on two data sets.},
  archivePrefix = {arXiv},
  eprint = {1610.03287},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Sommerfeld, Munk (2016) - Inference for Empirical Wasserstein Distances on Finite Spaces.pdf},
  journal = {arXiv:1610.03287 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{song2016Pufferfish,
  title = {Pufferfish {{Privacy Mechanisms}} for {{Correlated Data}}},
  author = {Song, Shuang and Wang, Yizhen and Chaudhuri, Kamalika},
  year = {2016},
  month = mar,
  abstract = {Many modern databases include personal and sensitive correlated data, such as private information on users connected together in a social network, and measurements of physical activity of single subjects across time. However, differential privacy, the current gold standard in data privacy, does not adequately address privacy issues in this kind of data. This work looks at a recent generalization of differential privacy, called Pufferfish, that can be used to address privacy in correlated data. The main challenge in applying Pufferfish is a lack of suitable mechanisms. We provide the first mechanism -- the Wasserstein Mechanism -- which applies to any general Pufferfish framework. Since this mechanism may be computationally inefficient, we provide an additional mechanism that applies to some practical cases such as physical activity measurements across time, and is computationally efficient. Our experimental evaluations indicate that this mechanism provides privacy and utility for synthetic as well as real data in two separate domains.},
  archivePrefix = {arXiv},
  eprint = {1603.03977},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Song et al (2016) - Pufferfish Privacy Mechanisms for Correlated Data.pdf},
  journal = {arXiv:1603.03977 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{song2018Improving,
  title = {Improving the {{Generalization}} of {{Adversarial Training}} with {{Domain Adaptation}}},
  author = {Song, Chuanbiao and He, Kun and Wang, Liwei and Hopcroft, John E.},
  year = {2018},
  month = oct,
  abstract = {By injecting adversarial examples into training data, adversarial training is promising for improving the robustness of deep learning models. However, most existing adversarial training approaches are based on a specific type of adversarial attack. It may not provide sufficiently representative samples from the adversarial domain, leading to a weak generalization ability on adversarial examples from other attacks. Moreover, during the adversarial training, adversarial perturbations on inputs are usually crafted by fast single-step adversaries so as to scale to large datasets. This work is mainly focused on the adversarial training yet efficient FGSM adversary. In this scenario, it is difficult to train a model with great generalization due to the lack of representative adversarial samples, aka the samples are unable to accurately reflect the adversarial domain. To alleviate this problem, we propose a novel Adversarial Training with Domain Adaptation (ATDA) method. Our intuition is to regard the adversarial training on FGSM adversary as a domain adaption task with limited number of target domain samples. The main idea is to learn a representation that is semantically meaningful and domain invariant on the clean domain as well as the adversarial domain. Empirical evaluations on Fashion-MNIST, SVHN, CIFAR-10 and CIFAR-100 demonstrate that ATDA can greatly improve the generalization of adversarial training and the smoothness of the learned models, and outperforms state-of-the-art methods on standard benchmark datasets. To show the transfer ability of our method, we also extend ATDA to the adversarial training on iterative attacks such as PGD-Adversial Training (PAT) and the defense performance is improved considerably.},
  archivePrefix = {arXiv},
  eprint = {1810.00740},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Song et al (2018) - Improving the Generalization of Adversarial Training with Domain Adaptation.pdf},
  journal = {arXiv:1810.00740 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{song2019Generative,
  title = {Generative {{Modeling}} by {{Estimating Gradients}} of the {{Data Distribution}}},
  author = {Song, Yang and Ermon, Stefano},
  year = {2019},
  month = jul,
  abstract = {We introduce a new generative model where samples are produced via Langevin dynamics using gradients of the data distribution estimated with score matching. Because gradients might be ill-defined when the data resides on low-dimensional manifolds, we perturb the data with different levels of Gaussian noise and jointly estimate the corresponding scores, i.e., the vector fields of gradients of the perturbed data distribution for all noise levels. For sampling, we propose an annealed Langevin dynamics where we use gradients corresponding to gradually decreasing noise levels as the sampling process gets closer to the data manifold. Our framework allows flexible model architectures, requires no sampling during training or the use of adversarial methods, and provides a learning objective that can be used for principled model comparisons. Our models produce samples comparable to GANs on MNIST, CelebA and CIFAR-10 datasets, achieving a new state-of-the-art inception score of 8.91 on CIFAR-10. Additionally, we demonstrate that our models learn effective representations via image inpainting experiments.},
  archivePrefix = {arXiv},
  eprint = {1907.05600},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Song, Ermon (2019) - Generative Modeling by Estimating Gradients of the Data Distribution.pdf},
  journal = {arXiv:1907.05600 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{song2019Surfing,
  title = {Surfing: {{Iterative}} Optimization over Incrementally Trained Deep Networks},
  shorttitle = {Surfing},
  author = {Song, Ganlin and Fan, Zhou and Lafferty, John},
  year = {2019},
  month = jul,
  abstract = {We investigate a sequential optimization procedure to minimize the empirical risk functional \$f\_\{\textbackslash hat\textbackslash theta\}(x) = \textbackslash frac\{1\}\{2\}\textbackslash |G\_\{\textbackslash hat\textbackslash theta\}(x) - y\textbackslash |\^2\$ for certain families of deep networks \$G\_\{\textbackslash theta\}(x)\$. The approach is to optimize a sequence of objective functions that use network parameters obtained during different stages of the training process. When initialized with random parameters \$\textbackslash theta\_0\$, we show that the objective \$f\_\{\textbackslash theta\_0\}(x)\$ is "nice'' and easy to optimize with gradient descent. As learning is carried out, we obtain a sequence of generative networks \$x \textbackslash mapsto G\_\{\textbackslash theta\_t\}(x)\$ and associated risk functions \$f\_\{\textbackslash theta\_t\}(x)\$, where \$t\$ indicates a stage of stochastic gradient descent during training. Since the parameters of the network do not change by very much in each step, the surface evolves slowly and can be incrementally optimized. The algorithm is formalized and analyzed for a family of expansive networks. We call the procedure \{\textbackslash it surfing\} since it rides along the peak of the evolving (negative) empirical risk function, starting from a smooth surface at the beginning of learning and ending with a wavy nonconvex surface after learning is complete. Experiments show how surfing can be used to find the global optimum and for compressed sensing even when direct gradient descent on the final learned network fails.},
  archivePrefix = {arXiv},
  eprint = {1907.08653},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Song et al (2019) - Surfing.pdf},
  journal = {arXiv:1907.08653 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{speicher2018Potential,
  title = {Potential for {{Discrimination}} in {{Online Targeted Advertising}}},
  booktitle = {Conference on {{Fairness}}, {{Accountability}} and {{Transparency}}},
  author = {Speicher, Till and Ali, Muhammad and Venkatadri, Giridhari and Ribeiro, Filipe Nunes and Arvanitakis, George and Benevenuto, Fabr{\'i}cio and Gummadi, Krishna P. and Loiseau, Patrick and Mislove, Alan},
  year = {2018},
  month = jan,
  pages = {5--19},
  issn = {1938-7228},
  abstract = {Recently, online targeted advertising platforms like Facebook have been criticized for allowing advertisers to discriminate against users belonging to sensitive groups, i.e., to exclude users belon...},
  chapter = {Machine Learning},
  file = {/Users/yuekai/Documents/zotero/Speicher et al (2018) - Potential for Discrimination in Online Targeted Advertising.pdf},
  language = {en}
}

@article{spielman2002Smoothed,
  title = {Smoothed Analysis of Algorithms},
  author = {Spielman, Daniel A. and Teng, Shang-Hua},
  year = {2002},
  month = nov,
  abstract = {Spielman and Teng introduced the smoothed analysis of algorithms to provide a framework in which one could explain the success in practice of algorithms and heuristics that could not be understood through the traditional worst-case and average-case analyses. In this talk, we survey some of the smoothed analyses that have been performed.},
  archivePrefix = {arXiv},
  eprint = {math/0212413},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Spielman, Teng (2002) - Smoothed analysis of algorithms.pdf},
  journal = {arXiv:math/0212413},
  keywords = {Mathematics - Optimization and Control}
}

@article{spokoiny2012Parametric,
  title = {Parametric Estimation. {{Finite}} Sample Theory},
  author = {Spokoiny, Vladimir},
  year = {2012},
  month = dec,
  volume = {40},
  pages = {2877--2909},
  issn = {0090-5364},
  doi = {10.1214/12-AOS1054},
  abstract = {The paper aims at reconsidering the famous Le Cam LAN theory. The main features of the approach which make it different from the classical one are as follows: (1) the study is nonasymptotic, that is, the sample size is fixed and does not tend to infinity; (2) the parametric assumption is possibly misspecified and the underlying data distribution can lie beyond the given parametric family. These two features enable to bridge the gap between parametric and nonparametric theory and to build a unified framework for statistical estimation. The main results include large deviation bounds for the (quasi) maximum likelihood and the local quadratic bracketing of the log-likelihood process. The latter yields a number of important corollaries for statistical inference: concentration, confidence and risk bounds, expansion of the maximum likelihood estimate, etc. All these corollaries are stated in a nonclassical way admitting a model misspecification and finite samples. However, the classical asymptotic results including the efficiency bounds can be easily derived as corollaries of the obtained nonasymptotic statements. At the same time, the new bracketing device works well in the situations with large or growing parameter dimension in which the classical parametric theory fails. The general results are illustrated for the i.i.d. setup as well as for generalized linear and median estimation. The results apply for any dimension of the parameter space and provide a quantitative lower bound on the sample size yielding the root-n accuracy.},
  archivePrefix = {arXiv},
  eprint = {1111.3029},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Spokoiny (2012) - Parametric estimation.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory},
  number = {6}
}

@article{spokoiny2013Bernstein,
  title = {Bernstein - von {{Mises Theorem}} for Growing Parameter Dimension},
  author = {Spokoiny, Vladimir},
  year = {2013},
  month = feb,
  abstract = {This paper revisits the prominent Fisher, Wilks, and Bernstein -- von Mises (BvM) results from different viewpoints. Particular issues to address are: nonasymptotic framework with just one finite sample, possible model misspecification, and a large parameter dimension. In particular, in the case of an i.i.d. sample, the mentioned results can be stated for any smooth parametric family provided that the dimension \textbackslash (p \textbackslash ) of the parameter space satisfies the condition "\textbackslash (p\^\{2\}/n \textbackslash ) is small" for the Fisher expansion, while the Wilks and the BvM results require "\textbackslash (p\^\{3\}/n \textbackslash ) is small".},
  archivePrefix = {arXiv},
  eprint = {1302.3430},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Spokoiny (2013) - Bernstein - von Mises Theorem for growing parameter dimension.pdf},
  journal = {arXiv:1302.3430 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{srivastava2018Scalable,
  title = {Scalable {{Bayes}} via {{Barycenter}} in {{Wasserstein Space}}},
  author = {Srivastava, Sanvesh and Li, Cheng and Dunson, David B.},
  year = {2018},
  month = jun,
  abstract = {Divide-and-conquer based methods for Bayesian inference provide a general approach for tractable posterior inference when the sample size is large. These methods divide the data into smaller subsets, sample from the posterior distribution of parameters in parallel on all the subsets, and combine posterior samples from all the subsets to approximate the full data posterior distribution. The smaller size of any subset compared to the full data implies that posterior sampling on any subset is computationally more efficient than sampling from the true posterior distribution. Since the combination step takes negligible time relative to sampling, posterior computations can be scaled to massive data by dividing the full data into a sufficiently large number of data subsets. One such approach relies on the geometry of posterior distributions estimated across different subsets and combines them through their barycenter in a Wasserstein space of probability measures. We provide theoretical guarantees on the accuracy of approximation that are valid in many applications. We show that the geometric method approximates the full data posterior distribution better than its competitors across diverse simulations and reproduces known results when applied to a movie ratings database.},
  archivePrefix = {arXiv},
  eprint = {1508.05880},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Srivastava et al (2018) - Scalable Bayes via Barycenter in Wasserstein Space.pdf},
  journal = {arXiv:1508.05880 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{staib2017Distributionally,
  title = {Distributionally {{Robust Deep Learning}} as a {{Generalization}} of {{Adversarial Training}}},
  author = {Staib, Matthew and Jegelka, Stefanie},
  year = {2017},
  month = dec,
  pages = {9},
  abstract = {Machine learning models are vulnerable to adversarial attacks at test time: a correctly classified test example can be slightly perturbed to cause a misclassification. Training models that are robust to these attacks, and theoretical understanding of such defenses are active research areas. Adversarial Training (AT) via robust optimization is a promising approach, where the model is trained against an adversary acting on the training set, but it is less clear how to reason about perturbations on the unseen test set. Distributionally Robust Optimization (DRO) with Wasserstein distance is an interesting theoretical tool for understanding robustness and generalization, but it has been limited algorithmically to simple models. We link DRO and AT both theoretically and algorithmically: AT is a special case of DRO, and in general DRO yields a stronger adversary. We also give an algorithm for DRO for neural networks that is no more expensive than AT.},
  file = {/Users/yuekai/Documents/zotero/Staib, Jegelka (2017) - Distributionally Robust Deep Learning as a Generalization of Adversarial.pdf},
  language = {en}
}

@article{steel2010Web,
  title = {On the {{Web}}'s {{Cutting Edge}}, {{Anonymity}} in {{Name Only}}},
  author = {Steel, Emily and Angwin, Julia},
  year = {2010},
  month = aug,
  issn = {0099-9660},
  abstract = {Websites are learning to decide if you're a good customer or not, before you tell them a single thing about yourself. What They Know is a Wall Street Journal report on digital privacy.},
  chapter = {Tech},
  journal = {Wall Street Journal},
  language = {en-US}
}

@article{steinhardt2018ROBUST,
  title = {{{ROBUST LEARNING}}: {{INFORMATION THEORY AND ALGORITHMS}}},
  author = {Steinhardt, Jacob},
  year = {2018},
  pages = {88},
  file = {/Users/yuekai/Documents/zotero/Steinhardt (2018) - ROBUST LEARNING.pdf},
  language = {en}
}

@book{steinwart2008Support,
  title = {Support Vector Machines},
  author = {Steinwart, Ingo and Christmann, Andreas},
  year = {2008},
  edition = {1st ed},
  publisher = {{Springer}},
  address = {{New York}},
  file = {/Users/yuekai/Documents/zotero/Steinwart, Christmann (2008) - Support vector machines.pdf},
  isbn = {978-0-387-77241-7 978-0-387-77242-4},
  language = {en},
  lccn = {Q325.5 .S74 2008},
  series = {Information Science and Statistics}
}

@article{stevens2020See,
  title = {See How Experts Use Disease Modeling to Predict Coronavirus Cases after States Reopen},
  shorttitle = {Disease Modelers Are Wary of Reopening the Country. {{Here}}'s How They Arrive at Their Verdict.},
  author = {Stevens, Harry and Muyskens, John},
  year = {2020},
  month = may,
  journal = {Washington Post},
  language = {en}
}

@article{stewart1971Error,
  title = {Error {{Bounds}} for {{Approximate Invariant Subspaces}} of {{Closed Linear Operators}}},
  author = {Stewart, G.},
  year = {1971},
  month = dec,
  volume = {8},
  pages = {796--808},
  issn = {0036-1429},
  doi = {10.1137/0708073},
  abstract = {Let A be a closed linear operator on a separable Hilbert space \$\textbackslash mathcal\{H\}\$ whose domain is dense in \$\textbackslash mathcal\{H\}\$ Let \$\textbackslash mathcal\{X\}\$ be a subspace of \$\textbackslash mathcal\{H\}\$ contained in the domain of A and let \$\textbackslash mathcal\{Y\}\$ be its orthogonal complement. Let B and C be the compressions of A to \$\textbackslash mathcal\{Z\}\$ and \$\textbackslash mathcal\{Y\}\$ respectively, let \$G = Y\^ *  AX\$, where X and Y are the injections of \$\textbackslash mathcal\{X\}\$ and \$\textbackslash mathcal\{Y\}\$ into \$\textbackslash mathcal\{H\}\$. It is shown that if B and C have disjoint spectra and \$\textbackslash | G \textbackslash |\$ is sufficiently small, then there is an invariant subspace \$\textbackslash mathcal\{X\}'\$ of A near \$\textbackslash mathcal\{X\}\$. Bounds for the distance between \$\textbackslash mathcal\{X\}'\$ and \$\textbackslash mathcal\{X\}\$ are given, and the spectrum of A is related to the spectra of B and C. In the development a measure of the separation of the spectra of B and C which is insensitive to small perturbations in B and C is introduced and analyzed.},
  file = {/Users/yuekai/Documents/zotero/Stewart (1971) - Error Bounds for Approximate Invariant Subspaces of Closed Linear Operators.pdf},
  journal = {SIAM Journal on Numerical Analysis},
  number = {4}
}

@article{stewart1973Error,
  title = {Error and {{Perturbation Bounds}} for {{Subspaces Associated}} with {{Certain Eigenvalue Problems}}},
  author = {Stewart, G. W.},
  year = {1973},
  volume = {15},
  pages = {727--764},
  issn = {0036-1445},
  abstract = {[This paper describes a technique for obtaining error bounds for certain characteristic subspaces associated with the algebraic eigenvalue problem, the generalized eigenvalue problem, and the singular value decomposition. The method also gives perturbation bounds for isolated eigenvalues and useful information about clusters of eigenvalues. The bounds are obtained from an iterative process for generating the subspaces in question, and one or more steps of the iteration can be used to construct perturbation estimates whose error can be bounded.]},
  file = {/Users/yuekai/Documents/zotero/Stewart (1973) - Error and Perturbation Bounds for Subspaces Associated with Certain Eigenvalue.pdf},
  journal = {SIAM Review},
  number = {4}
}

@article{stewart1979note,
  title = {A Note on the Perturbation of Singular Values},
  author = {Stewart, G.W.},
  year = {1979},
  month = dec,
  volume = {28},
  pages = {213--216},
  issn = {00243795},
  doi = {10.1016/0024-3795(79)90134-4},
  abstract = {In tbis note a variant of the classical perturbation theorem for singular values is given. Tbe bounds explain why perturbations will tend to increase rather than decrease singular values of the same order of magnitude as the perturbation.},
  file = {/Users/yuekai/Documents/zotero/Stewart (1979) - A note on the perturbation of singular values.pdf},
  journal = {Linear Algebra and its Applications},
  language = {en}
}

@article{stewart1984second,
  title = {A Second Order Perturbation Expansion for Small Singular Values},
  author = {Stewart, G.W.},
  year = {1984},
  month = jan,
  volume = {56},
  pages = {231--235},
  issn = {00243795},
  doi = {10.1016/0024-3795(84)90128-9},
  abstract = {An expansionfor the square of the smallest singularvalue of a matrix is presented. The expansion includes second order terms in the perturbation and therefore remains accurate when the smallest singular value is zero.},
  file = {/Users/yuekai/Documents/zotero/Stewart (1984) - A second order perturbation expansion for small singular values.pdf},
  journal = {Linear Algebra and its Applications},
  language = {en}
}

@book{stewart1990Matrix,
  title = {Matrix {{Perturbation Theory}}},
  author = {Stewart, Gilbert W. and Sun, Ji-guang},
  year = {1990},
  publisher = {{Academic Press}},
  abstract = {This book is a comprehensive survey of matrix perturbation theory, a topic of interest to numerical analysts, statisticians, physical scientists, and engineers. In particular, the authors cover perturbation theory of linear systems and least square problems, the eignevalue problem, and the generalized eignevalue problem as wellas a complete treatment of vector and matrix norms, including the theory of unitary invariant norms.},
  googlebooks = {l78PAQAAMAAJ},
  isbn = {978-0-12-670230-9},
  language = {en}
}

@techreport{stewart1990Perturbation,
  title = {Perturbation {{Theory}} for the {{Singular Value Decomposition}}},
  author = {Stewart, G W},
  year = {1990},
  month = sep,
  pages = {15},
  address = {{College Park, MD}},
  institution = {{University of Maryland}},
  abstract = {The singular value decomposition has a number of applications in digital signal processing. However, the the decomposition must be computed from a matrix consisting of both signal and noise. It is therefore important to be able to assess the e ects of the noise on the singular values and singular vectors | a problem in classical perturbation theory. In this paper we survey the perturbation theory of the singular value decomposition.},
  file = {/Users/yuekai/Documents/zotero/Stewart (1990) - Perturbation Theory for the Singular Value Decomposition.pdf},
  language = {en},
  number = {CS-TR 2539}
}

@article{stewart1990Stochastic,
  title = {Stochastic {{Perturbation Theory}}},
  author = {Stewart, G. W.},
  year = {1990},
  volume = {32},
  pages = {579--610},
  issn = {0036-1445},
  abstract = {[In this paper classical matrix perturbation theory is approached from a probabilistic point of view. The perturbed quantity is approximated by a first-order perturbation expansion, in which the perturbation is assumed to be random. This permits the computation of statistics estimating the variation in the perturbed quantity. Up to the higher-order terms that are ignored in the expansion, these statistics tend to be more realistic than perturbation bounds obtained in terms of norms. The technique is applied to a number of problems in matrix perturbation theory, including least squares and the eigenvalue problem.]},
  file = {/Users/yuekai/Documents/zotero/Stewart (1990) - Stochastic Perturbation Theory.pdf},
  journal = {SIAM Review},
  number = {4}
}

@article{stinis2019Enforcing,
  title = {Enforcing Constraints for Interpolation and Extrapolation in {{Generative Adversarial Networks}}},
  author = {Stinis, Panos and Hagge, Tobias and Tartakovsky, Alexandre M. and Yeung, Enoch},
  year = {2019},
  month = nov,
  volume = {397},
  pages = {108844},
  issn = {00219991},
  doi = {10.1016/j.jcp.2019.07.042},
  abstract = {We suggest ways to enforce given constraints in the output of a Generative Adversarial Network (GAN) generator both for interpolation and extrapolation (prediction). For the case of dynamical systems, given a time series, we wish to train GAN generators that can be used to predict trajectories starting from a given initial condition. In this setting, the constraints can be in algebraic and/or differential form. Even though we are predominantly interested in the case of extrapolation, we will see that the tasks of interpolation and extrapolation are related. However, they need to be treated differently. For the case of interpolation, the incorporation of constraints is built into the training of the GAN. The incorporation of the constraints respects the primary game-theoretic setup of a GAN so it can be combined with existing algorithms. However, it can exacerbate the problem of instability during training that is well-known for GANs. We suggest adding small noise to the constraints as a simple remedy that has performed well in our numerical experiments. The case of extrapolation (prediction) is more involved. During training, the GAN generator learns to interpolate a noisy version of the data and we enforce the constraints. This approach has connections with model reduction that we can utilize to improve the efficiency and accuracy of the training. Depending on the form of the constraints, we may enforce them also during prediction through a projection step. We provide examples of linear and nonlinear systems of differential equations to illustrate the various constructions.},
  archivePrefix = {arXiv},
  eprint = {1803.08182},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Stinis et al (2019) - Enforcing constraints for interpolation and extrapolation in Generative.pdf},
  journal = {Journal of Computational Physics},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{su2015Differential,
  title = {A {{Differential Equation}} for {{Modeling Nesterov}}'s {{Accelerated Gradient Method}}: {{Theory}} and {{Insights}}},
  shorttitle = {A {{Differential Equation}} for {{Modeling Nesterov}}'s {{Accelerated Gradient Method}}},
  author = {Su, Weijie and Boyd, Stephen and Candes, Emmanuel J.},
  year = {2015},
  month = oct,
  abstract = {We derive a second-order ordinary differential equation (ODE) which is the limit of Nesterov's accelerated gradient method. This ODE exhibits approximate equivalence to Nesterov's scheme and thus can serve as a tool for analysis. We show that the continuous time ODE allows for a better understanding of Nesterov's scheme. As a byproduct, we obtain a family of schemes with similar convergence rates. The ODE interpretation also suggests restarting Nesterov's scheme leading to an algorithm, which can be rigorously proven to converge at a linear rate whenever the objective is strongly convex.},
  archivePrefix = {arXiv},
  eprint = {1503.01243},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Su et al (2015) - A Differential Equation for Modeling Nesterov's Accelerated Gradient Method.pdf},
  journal = {arXiv:1503.01243 [math, stat]},
  keywords = {Mathematics - Classical Analysis and ODEs,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {math, stat}
}

@article{su2019One,
  title = {One Pixel Attack for Fooling Deep Neural Networks},
  author = {Su, Jiawei and Vargas, Danilo Vasconcellos and Kouichi, Sakurai},
  year = {2019},
  month = oct,
  volume = {23},
  pages = {828--841},
  issn = {1089-778X, 1089-778X, 1941-0026},
  doi = {10.1109/TEVC.2019.2890858},
  abstract = {Recent research has revealed that the output of Deep Neural Networks (DNN) can be easily altered by adding relatively small perturbations to the input vector. In this paper, we analyze an attack in an extremely limited scenario where only one pixel can be modified. For that we propose a novel method for generating one-pixel adversarial perturbations based on differential evolution (DE). It requires less adversarial information (a black-box attack) and can fool more types of networks due to the inherent features of DE. The results show that 67.97\% of the natural images in Kaggle CIFAR-10 test dataset and 16.04\% of the ImageNet (ILSVRC 2012) test images can be perturbed to at least one target class by modifying just one pixel with 74.03\% and 22.91\% confidence on average. We also show the same vulnerability on the original CIFAR-10 dataset. Thus, the proposed attack explores a different take on adversarial machine learning in an extreme limited scenario, showing that current DNNs are also vulnerable to such low dimension attacks. Besides, we also illustrate an important application of DE (or broadly speaking, evolutionary computation) in the domain of adversarial machine learning: creating tools that can effectively generate low-cost adversarial attacks against neural networks for evaluating robustness.},
  archivePrefix = {arXiv},
  eprint = {1710.08864},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Su et al (2019) - One pixel attack for fooling deep neural networks.pdf},
  journal = {IEEE Transactions on Evolutionary Computation},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  number = {5}
}

@article{suarez2018Tutorial,
  title = {A {{Tutorial}} on {{Distance Metric Learning}}: {{Mathematical Foundations}}, {{Algorithms}} and {{Software}}},
  shorttitle = {A {{Tutorial}} on {{Distance Metric Learning}}},
  author = {Su{\'a}rez, Juan Luis and Garc{\'i}a, Salvador and Herrera, Francisco},
  year = {2018},
  month = dec,
  abstract = {This paper describes the discipline of distance metric learning, a branch of machine learning that aims to learn distances from the data. Distance metric learning can be useful to improve similarity learning algorithms, and also has applications in dimensionality reduction. We describe the distance metric learning problem and analyze its main mathematical foundations. We discuss some of the most popular distance metric learning techniques used in classification, showing their goals and the required information to understand and use them. Furthermore, we present a Python package that collects a set of 17 distance metric learning techniques explained in this paper, with some experiments to evaluate the performance of the different algorithms. Finally, we discuss several possibilities of future work in this topic.},
  archivePrefix = {arXiv},
  eprint = {1812.05944},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Suárez et al (2018) - A Tutorial on Distance Metric Learning.pdf},
  journal = {arXiv:1812.05944 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{subbaswamy2019Preventing,
  title = {Preventing {{Failures Due}} to {{Dataset Shift}}: {{Learning Predictive Models That Transport}}},
  shorttitle = {Preventing {{Failures Due}} to {{Dataset Shift}}},
  author = {Subbaswamy, Adarsh and Schulam, Peter and Saria, Suchi},
  year = {2019},
  month = feb,
  abstract = {Classical supervised learning produces unreliable models when training and target distributions differ, with most existing solutions requiring samples from the target domain. We propose a proactive approach which learns a relationship in the training domain that will generalize to the target domain by incorporating prior knowledge of aspects of the data generating process that are expected to differ as expressed in a causal selection diagram. Specifically, we remove variables generated by unstable mechanisms from the joint factorization to yield the Surgery Estimator---an interventional distribution that is invariant to the differences across environments. We prove that the surgery estimator finds stable relationships in strictly more scenarios than previous approaches which only consider conditional relationships, and demonstrate this in simulated experiments. We also evaluate on real world data for which the true causal diagram is unknown, performing competitively against entirely data-driven approaches.},
  archivePrefix = {arXiv},
  eprint = {1812.04597},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Subbaswamy et al (2019) - Preventing Failures Due to Dataset Shift.pdf},
  journal = {arXiv:1812.04597 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{sudderth2002Nonparametric,
  title = {Nonparametric {{Belief Propagation}}},
  author = {Sudderth, Erik B and Ihler, Alexander T and Freeman, William T and Willsky, Alan S},
  year = {2002},
  month = oct,
  pages = {10},
  abstract = {In applications of graphical models arising in fields such as computer vision, the hidden variables of interest are most naturally specified by continuous, non\textendash Gaussian distributions. However, due to the limitations of existing inference algorithms, it is often necessary to form coarse, discrete approximations to such models. In this paper, we develop a nonparametric belief propagation (NBP) algorithm, which uses stochastic methods to propagate kernel\textendash based approximations to the true continuous messages. Each NBP message update is based on an efficient sampling procedure which can accomodate an extremely broad class of potential functions, allowing easy adaptation to new application areas. We validate our method using comparisons to continuous BP for Gaussian networks, and an application to the stereo vision problem.},
  file = {/Users/yuekai/Documents/zotero/Sudderth et al (2002) - Nonparametric Belief Propagation.pdf},
  language = {en}
}

@article{suggala2018Revisiting,
  title = {Revisiting {{Adversarial Risk}}},
  author = {Suggala, Arun Sai and Prasad, Adarsh and Nagarajan, Vaishnavh and Ravikumar, Pradeep},
  year = {2018},
  month = jun,
  abstract = {Recent works on adversarial perturbations show that there is an inherent trade-off between standard test accuracy and adversarial accuracy. Specifically, they show that no classifier can simultaneously be robust to adversarial perturbations and achieve high standard test accuracy. However, this is contrary to the standard notion that on tasks such as image classification, humans are robust classifiers with low error rate. In this work, we show that the main reason behind this confusion is the inexact definition of adversarial perturbation that is used in the literature. To fix this issue, we propose a slight, yet important modification to the existing definition of adversarial perturbation. Based on the modified definition, we show that there is no trade-off between adversarial and standard accuracies; there exist classifiers that are robust and achieve high standard accuracy. We further study several properties of this new definition of adversarial risk and its relation to the existing definition.},
  archivePrefix = {arXiv},
  eprint = {1806.02924},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Suggala et al (2018) - Revisiting Adversarial Risk.pdf},
  journal = {arXiv:1806.02924 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{sugiyama2008Direct,
  title = {Direct Importance Estimation for Covariate Shift Adaptation},
  author = {Sugiyama, Masashi and Suzuki, Taiji and Nakajima, Shinichi and Kashima, Hisashi and {von B{\"u}nau}, Paul and Kawanabe, Motoaki},
  year = {2008},
  month = dec,
  volume = {60},
  pages = {699--746},
  issn = {0020-3157, 1572-9052},
  doi = {10.1007/s10463-008-0197-x},
  file = {/Users/yuekai/Documents/zotero/Sugiyama et al (2008) - Direct importance estimation for covariate shift adaptation.pdf},
  journal = {Annals of the Institute of Statistical Mathematics},
  language = {en},
  number = {4}
}

@book{suli2003Introduction,
  title = {An {{Introduction}} to {{Numerical Analysis}}},
  author = {S{\"u}li, Endre and Mayers, David F.},
  year = {2003},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9780511801181},
  abstract = {Numerical analysis provides the theoretical foundation for the numerical algorithms we rely on to solve a multitude of computational problems in science. Based on a successful course at Oxford University, this book covers a wide range of such problems ranging from the approximation of functions and integrals to the approximate solution of algebraic, transcendental, differential and integral equations. Throughout the book, particular attention is paid to the essential qualities of a numerical algorithm - stability, accuracy, reliability and efficiency. The authors go further than simply providing recipes for solving computational problems. They carefully analyse the reasons why methods might fail to give accurate answers, or why one method might return an answer in seconds while another would take billions of years. This book is ideal as a text for students in the second year of a university mathematics course. It combines practicality regarding applications with consistently high standards of rigour.},
  file = {/Users/yuekai/Documents/zotero/Süli, Mayers (2003) - An Introduction to Numerical Analysis.pdf},
  isbn = {978-0-521-00794-8}
}

@article{sun1997SEMIPARAMETRIC,
  title = {{{SEMI}}-{{PARAMETRIC ESTIMATES UNDER BIASED SAMPLING}}},
  author = {Sun, Jiayang and Woodroofe, Michael},
  year = {1997},
  volume = {7},
  pages = {31},
  abstract = {In observational studies subjects may self select, thereby creating a biased sample. Such problems arise frequently, for example, in astronomical, biomedical, animal, and oil studies, survey sampling and econometrics. For a typical subject, let Y denote the value of interest and suppose that Y has an unknown density function f . Further, let w(y) denote the probability that the subject includes itself in the study given Y = y. Then the conditional density of Y given that it is observed is f {${_\ast}$}(y) = w(y)f (y)/{$\kappa$}, where {$\kappa$} is a normalizing constant. The problem of estimating w and f from a biased sample X1, . . . , Xn independently from f {${_\ast}$} is considered when f is known to belong to a parametric family, say f = f\texttheta, where \texttheta{} is a vector of unknown parameters, and w is assumed to be non-decreasing. An algorithm for computing the maximum likelihood estimator of (w, \texttheta ) is developed, and consistency is established. Simulations are used to show that our method is feasible with moderate sample size, and applications to animal and oil data are given.},
  file = {/Users/yuekai/Documents/zotero/Sun, Woodroofe (1997) - SEMI-PARAMETRIC ESTIMATES UNDER BIASED SAMPLING.pdf},
  journal = {Statistica Sinica},
  language = {en}
}

@article{sun2012Multiple,
  title = {Multiple Hypothesis Testing Adjusted for Latent Variables, with an Application to the {{AGEMAP}} Gene Expression Data},
  author = {Sun, Yunting and Zhang, Nancy R. and Owen, Art B.},
  year = {2012},
  month = dec,
  volume = {6},
  pages = {1664--1688},
  issn = {1932-6157},
  doi = {10.1214/12-AOAS561},
  abstract = {In high throughput settings we inspect a great many candidate variables (e.g., genes) searching for associations with a primary variable (e.g., a phenotype). High throughput hypothesis testing can be made difficult by the presence of systemic effects and other latent variables. It is well known that those variables alter the level of tests and induce correlations between tests. They also change the relative ordering of significance levels among hypotheses. Poor rankings lead to wasteful and ineffective follow-up studies. The problem becomes acute for latent variables that are correlated with the primary variable. We propose a two-stage analysis to counter the effects of latent variables on the ranking of hypotheses. Our method, called LEAPP, statistically isolates the latent variables from the primary one. In simulations, it gives better ordering of hypotheses than competing methods such as SVA and EIGENSTRAT. For an illustration, we turn to data from the AGEMAP study relating gene expression to age for 16 tissues in the mouse. LEAPP generates rankings with greater consistency across tissues than the rankings attained by the other methods.},
  archivePrefix = {arXiv},
  eprint = {1301.2420},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Sun et al (2012) - Multiple hypothesis testing adjusted for latent variables, with an application.pdf},
  journal = {The Annals of Applied Statistics},
  keywords = {Statistics - Applications},
  number = {4}
}

@inproceedings{sun2014Learning,
  title = {Learning {{Mixtures}} of {{Linear Classifiers}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Sun, Yuekai and Ioannidis, Stratis and Montanari, Andrea},
  year = {2014},
  month = jan,
  pages = {721--729},
  abstract = {We consider a discriminative learning (regression) problem, whereby the regression function is a convex combination of k linear classifiers. Existing approaches are based on the EM algorithm, or si...},
  file = {/Users/yuekai/Documents/zotero/Sun et al (2014) - Learning Mixtures of Linear Classifiers.pdf},
  language = {en}
}

@article{sun2019Are,
  title = {Are We There yet? {{Manifold}} Identification of Gradient-Related Proximal Methods},
  author = {Sun, Yifan and Jeong, Halyun and Nutini, Julie and Schmidt, Mark},
  year = {2019},
  month = mar,
  pages = {28},
  abstract = {In machine learning, models that generalize better often generate outputs that lie on a low-dimensional manifold. Recently, several works have separately shown finite-time manifold identification by some proximal methods. In this work we provide a unified view by giving a simple condition under which any proximal method using a constant step size can achieve finite-iteration manifold detection. For several key methods (FISTA, DRS, ADMM, SVRG, SAGA, and RDA) we give an iteration bound, characterized in terms of their variable convergence rate and a problem-dependent constant that indicates problem degeneracy. For popular models, this constant is related to certain data assumptions, which gives intuition as to when lower active set complexity may be expected in practice.},
  file = {/Users/yuekai/Documents/zotero/Sun et al (2019) - Are we there yet.pdf},
  language = {en}
}

@article{sun2019Mitigating,
  title = {Mitigating {{Gender Bias}} in {{Natural Language Processing}}: {{Literature Review}}},
  shorttitle = {Mitigating {{Gender Bias}} in {{Natural Language Processing}}},
  author = {Sun, Tony and Gaut, Andrew and Tang, Shirlyn and Huang, Yuxin and ElSherief, Mai and Zhao, Jieyu and Mirza, Diba and Belding, Elizabeth and Chang, Kai-Wei and Wang, William Yang},
  year = {2019},
  month = jun,
  abstract = {As Natural Language Processing (NLP) and Machine Learning (ML) tools rise in popularity, it becomes increasingly vital to recognize the role they play in shaping societal biases and stereotypes. Although NLP models have shown success in modeling various applications, they propagate and may even amplify gender bias found in text corpora. While the study of bias in artificial intelligence is not new, methods to mitigate gender bias in NLP are relatively nascent. In this paper, we review contemporary studies on recognizing and mitigating gender bias in NLP. We discuss gender bias based on four forms of representation bias and analyze methods recognizing gender bias. Furthermore, we discuss the advantages and drawbacks of existing gender debiasing methods. Finally, we discuss future studies for recognizing and mitigating gender bias in NLP.},
  archivePrefix = {arXiv},
  eprint = {1906.08976},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Sun et al (2019) - Mitigating Gender Bias in Natural Language Processing.pdf},
  journal = {arXiv:1906.08976 [cs]},
  keywords = {Computer Science - Computation and Language},
  primaryClass = {cs}
}

@article{sun2019Optimization,
  title = {Optimization for Deep Learning: Theory and Algorithms},
  shorttitle = {Optimization for Deep Learning},
  author = {Sun, Ruoyu},
  year = {2019},
  month = dec,
  abstract = {When and why can a neural network be successfully trained? This article provides an overview of optimization algorithms and theory for training neural networks. First, we discuss the issue of gradient explosion/vanishing and the more general issue of undesirable spectrum, and then discuss practical solutions including careful initialization and normalization methods. Second, we review generic optimization methods used in training neural networks, such as SGD, adaptive gradient methods and distributed methods, and theoretical results for these algorithms. Third, we review existing research on the global issues of neural network training, including results on bad local minima, mode connectivity, lottery ticket hypothesis and infinite-width analysis.},
  archivePrefix = {arXiv},
  eprint = {1912.08957},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Sun (2019) - Optimization for deep learning.pdf},
  journal = {arXiv:1912.08957 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{sun2019Querying,
  title = {Querying a {{Matrix}} through {{Matrix}}-{{Vector Products}}},
  author = {Sun, Xiaoming and Woodruff, David P. and Yang, Guang and Zhang, Jialin},
  year = {2019},
  month = nov,
  abstract = {We consider algorithms with access to an unknown matrix \$M\textbackslash in\textbackslash mathbb\{F\}\^\{n \textbackslash times d\}\$ via matrix-vector products, namely, the algorithm chooses vectors \$\textbackslash mathbf\{v\}\^1, \textbackslash ldots, \textbackslash mathbf\{v\}\^q\$, and observes \$M\textbackslash mathbf\{v\}\^1,\textbackslash ldots, M\textbackslash mathbf\{v\}\^q\$. Here the \$\textbackslash mathbf\{v\}\^i\$ can be randomized as well as chosen adaptively as a function of \$ M\textbackslash mathbf\{v\}\^1,\textbackslash ldots,M\textbackslash mathbf\{v\}\^\{i-1\}\$. Motivated by applications of sketching in distributed computation, linear algebra, and streaming models, as well as connections to areas such as communication complexity and property testing, we initiate the study of the number \$q\$ of queries needed to solve various fundamental problems. We study problems in three broad categories, including linear algebra, statistics problems, and graph problems. For example, we consider the number of queries required to approximate the rank, trace, maximum eigenvalue, and norms of a matrix \$M\$; to compute the AND/OR/Parity of each column or row of \$M\$, to decide whether there are identical columns or rows in \$M\$ or whether \$M\$ is symmetric, diagonal, or unitary; or to compute whether a graph defined by \$M\$ is connected or triangle-free. We also show separations for algorithms that are allowed to obtain matrix-vector products only by querying vectors on the right, versus algorithms that can query vectors on both the left and the right. We also show separations depending on the underlying field the matrix-vector product occurs in. For graph problems, we show separations depending on the form of the matrix (bipartite adjacency versus signed edge-vertex incidence matrix) to represent the graph. Surprisingly, this fundamental model does not appear to have been studied on its own, and we believe a thorough investigation of problems in this model would be beneficial to a number of different application areas.},
  archivePrefix = {arXiv},
  eprint = {1906.05736},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Sun et al (2019) - Querying a Matrix through Matrix-Vector Products.pdf},
  journal = {arXiv:1906.05736 [cs]},
  keywords = {Computer Science - Computational Complexity,Computer Science - Data Structures and Algorithms},
  primaryClass = {cs}
}

@article{sur2017Likelihood,
  title = {The {{Likelihood Ratio Test}} in {{High}}-{{Dimensional Logistic Regression Is Asymptotically}} a {{Rescaled Chi}}-{{Square}}},
  author = {Sur, Pragya and Chen, Yuxin and Cand{\`e}s, Emmanuel J.},
  year = {2017},
  month = jun,
  abstract = {Logistic regression is used thousands of times a day to fit data, predict future outcomes, and assess the statistical significance of explanatory variables. When used for the purpose of statistical inference, logistic models produce p-values for the regression coefficients by using an approximation to the distribution of the likelihood-ratio test. Indeed, Wilks' theorem asserts that whenever we have a fixed number \$p\$ of variables, twice the log-likelihood ratio (LLR) \$2\textbackslash Lambda\$ is distributed as a \$\textbackslash chi\^2\_k\$ variable in the limit of large sample sizes \$n\$; here, \$k\$ is the number of variables being tested. In this paper, we prove that when \$p\$ is not negligible compared to \$n\$, Wilks' theorem does not hold and that the chi-square approximation is grossly incorrect; in fact, this approximation produces p-values that are far too small (under the null hypothesis). Assume that \$n\$ and \$p\$ grow large in such a way that \$p/n\textbackslash rightarrow\textbackslash kappa\$ for some constant \$\textbackslash kappa {$<$} 1/2\$. We prove that for a class of logistic models, the LLR converges to a rescaled chi-square, namely, \$2\textbackslash Lambda\textasciitilde\textbackslash stackrel\{\textbackslash mathrm\{d\}\}\{\textbackslash rightarrow\}\textasciitilde\textbackslash alpha(\textbackslash kappa)\textbackslash chi\_k\^2\$, where the scaling factor \$\textbackslash alpha(\textbackslash kappa)\$ is greater than one as soon as the dimensionality ratio \$\textbackslash kappa\$ is positive. Hence, the LLR is larger than classically assumed. For instance, when \$\textbackslash kappa=0.3\$, \$\textbackslash alpha(\textbackslash kappa)\textbackslash approx1.5\$. In general, we show how to compute the scaling factor by solving a nonlinear system of two equations with two unknowns. Our mathematical arguments are involved and use techniques from approximate message passing theory, non-asymptotic random matrix theory and convex geometry. We also complement our mathematical study by showing that the new limiting distribution is accurate for finite sample sizes. Finally, all the results from this paper extend to some other regression models such as the probit regression model.},
  archivePrefix = {arXiv},
  eprint = {1706.01191},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Sur et al (2017) - The Likelihood Ratio Test in High-Dimensional Logistic Regression Is.pdf},
  journal = {arXiv:1706.01191 [cs, math, stat]},
  keywords = {Computer Science - Information Theory,Mathematics - Probability,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{sur2018modern,
  title = {A Modern Maximum-Likelihood Theory for High-Dimensional Logistic Regression},
  author = {Sur, Pragya and Candes, Emmanuel J.},
  year = {2018},
  month = mar,
  abstract = {Every student in statistics or data science learns early on that when the sample size n largely exceeds the number p of variables, fitting a logistic model produces estimates that are approximately unbiased. Every student also learns that there are formulas to predict the variability of these estimates which are used for the purpose of statistical inference; for instance, to produce p-values for testing the significance of regression coefficients. Although these formulas come from large sample asymptotics, we are often told that we are on reasonably safe grounds when n is large in such a way that n {$\geq$} 5p or n {$\geq$} 10p. This paper shows that this is far from the case, and consequently, inferences routinely produced by common software packages are often unreliable.},
  archivePrefix = {arXiv},
  eprint = {1803.06964},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Sur, Candes (2018) - A modern maximum-likelihood theory for high-dimensional logistic regression.pdf},
  journal = {arXiv:1803.06964 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  language = {en},
  primaryClass = {math, stat}
}

@article{suresh2017Distributed,
  title = {Distributed {{Mean Estimation}} with {{Limited Communication}}},
  author = {Suresh, Ananda Theertha and Yu, Felix X. and Kumar, Sanjiv and McMahan, H. Brendan},
  year = {2017},
  month = sep,
  abstract = {Motivated by the need for distributed learning and optimization algorithms with low communication cost, we study communication efficient algorithms for distributed mean estimation. Unlike previous works, we make no probabilistic assumptions on the data. We first show that for \$d\$ dimensional data with \$n\$ clients, a naive stochastic binary rounding approach yields a mean squared error (MSE) of \$\textbackslash Theta(d/n)\$ and uses a constant number of bits per dimension per client. We then extend this naive algorithm in two ways: we show that applying a structured random rotation before quantization reduces the error to \$\textbackslash mathcal\{O\}((\textbackslash log d)/n)\$ and a better coding strategy further reduces the error to \$\textbackslash mathcal\{O\}(1/n)\$ and uses a constant number of bits per dimension per client. We also show that the latter coding strategy is optimal up to a constant in the minimax sense i.e., it achieves the best MSE for a given communication cost. We finally demonstrate the practicality of our algorithms by applying them to distributed Lloyd's algorithm for k-means and power iteration for PCA.},
  archivePrefix = {arXiv},
  eprint = {1611.00429},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Suresh et al (2017) - Distributed Mean Estimation with Limited Communication.pdf},
  journal = {arXiv:1611.00429 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{susnjara2015Accelerated,
  title = {Accelerated Filtering on Graphs Using {{Lanczos}} Method},
  author = {Susnjara, Ana and Perraudin, Nathanael and Kressner, Daniel and Vandergheynst, Pierre},
  year = {2015},
  month = sep,
  abstract = {Signal-processing on graphs has developed into a very active field of research during the last decade. In particular, the number of applications using frames constructed from graphs, like wavelets on graphs, has substantially increased. To attain scalability for large graphs, fast graph-signal filtering techniques are needed. In this contribution, we propose an accelerated algorithm based on the Lanczos method that adapts to the Laplacian spectrum without explicitly computing it. The result is an accurate, robust, scalable and efficient algorithm. Compared to existing methods based on Chebyshev polynomials, our solution achieves higher accuracy without increasing the overall complexity significantly. Furthermore, it is particularly well suited for graphs with large spectral gaps.},
  archivePrefix = {arXiv},
  eprint = {1509.04537},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Susnjara et al (2015) - Accelerated filtering on graphs using Lanczos method.pdf},
  journal = {arXiv:1509.04537 [math]},
  keywords = {Mathematics - Numerical Analysis},
  primaryClass = {math}
}

@book{sutton2018Reinforcement,
  title = {Reinforcement Learning: An Introduction},
  shorttitle = {Reinforcement Learning},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  year = {2018},
  edition = {Second edition},
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachusetts}},
  abstract = {"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms."--},
  file = {/Users/yuekai/Documents/zotero/Sutton, Barto (2018) - Reinforcement learning.pdf},
  isbn = {978-0-262-03924-6},
  language = {en},
  lccn = {Q325.6 .R45 2018},
  series = {Adaptive Computation and Machine Learning Series}
}

@inproceedings{swaminathan2015Counterfactual,
  title = {Counterfactual {{Risk Minimization}}: {{Learning}} from {{Logged Bandit Feedback}}},
  booktitle = {Proceedings of the 32nd {{International Conference}} on {{Machine Learning}}},
  author = {Swaminathan, Adith and Joachims, Thorsten},
  year = {2015},
  pages = {10},
  address = {{Lille, France}},
  abstract = {We develop a learning principle and an efficient algorithm for batch learning from logged bandit feedback. This learning setting is ubiquitous in online systems (e.g., ad placement, web search, recommendation), where an algorithm makes a prediction (e.g., ad ranking) for a given input (e.g., query) and observes bandit feedback (e.g., user clicks on presented ads). We first address the counterfactual nature of the learning problem through propensity scoring. Next, we prove generalization error bounds that account for the variance of the propensity-weighted empirical risk estimator. These constructive bounds give rise to the Counterfactual Risk Minimization (CRM) principle. We show how CRM can be used to derive a new learning method \textendash{} called Policy Optimizer for Exponential Models (POEM) \textendash{} for learning stochastic linear rules for structured output prediction. We present a decomposition of the POEM objective that enables efficient stochastic gradient optimization. POEM is evaluated on several multi-label classification problems showing substantially improved robustness and generalization performance compared to the state-of-the-art.},
  file = {/Users/yuekai/Documents/zotero/Swaminathan, Joachims (2015) - Counterfactual Risk Minimization.pdf},
  language = {en}
}

@article{sweeney1997Weaving,
  title = {Weaving {{Technology}} and {{Policy Together}} to {{Maintain Confidentiality}}},
  author = {Sweeney, Latanya},
  year = {1997},
  month = jun,
  volume = {25},
  pages = {98--110},
  issn = {1073-1105},
  doi = {10.1111/j.1748-720X.1997.tb01885.x},
  file = {/Users/yuekai/Documents/zotero/Sweeney (1997) - Weaving Technology and Policy Together to Maintain Confidentiality.pdf},
  journal = {The Journal of Law, Medicine \& Ethics},
  language = {en},
  number = {2-3}
}

@article{syrgkanis2019Machine,
  title = {Machine {{Learning Estimation}} of {{Heterogeneous Treatment Effects}} with {{Instruments}}},
  author = {Syrgkanis, Vasilis and Lei, Victor and Oprescu, Miruna and Hei, Maggie and Battocchi, Keith and Lewis, Greg},
  year = {2019},
  month = may,
  abstract = {We consider the estimation of heterogeneous treatment effects with arbitrary machine learning methods in the presence of unobserved confounders with the aid of a valid instrument. Such settings arise in A/B tests with an intent-to-treat structure, where the experimenter randomizes over which user will receive a recommendation to take an action, and we are interested in the effect of the downstream action. We develop a statistical learning approach to the estimation of heterogeneous effects, reducing the problem to the minimization of an appropriate loss function that depends on a set of auxiliary models (each corresponding to a separate prediction task). The reduction enables the use of all recent algorithmic advances (e.g. neural nets, forests). We show that the estimated effect model is robust to estimation errors in the auxiliary models, by showing that the loss satisfies a Neyman orthogonality criterion. Our approach can be used to estimate projections of the true effect model on simpler hypothesis spaces. When these spaces are parametric, then the parameter estimates are asymptotically normal, which enables construction of confidence sets. We applied our method to estimate the effect of membership on downstream webpage engagement on TripAdvisor, using as an instrument an intent-to-treat A/B test among 4 million TripAdvisor users, where some users received an easier membership sign-up process. We also validate our method on synthetic data and on public datasets for the effects of schooling on income.},
  archivePrefix = {arXiv},
  eprint = {1905.10176},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Syrgkanis et al (2019) - Machine Learning Estimation of Heterogeneous Treatment Effects with Instruments.pdf},
  journal = {arXiv:1905.10176 [cs, econ, stat]},
  keywords = {Computer Science - Machine Learning,Economics - Econometrics,Statistics - Applications,Statistics - Machine Learning},
  primaryClass = {cs, econ, stat}
}

@article{szegedy2013Intriguing,
  title = {Intriguing Properties of Neural Networks},
  author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  year = {2013},
  month = dec,
  abstract = {Deep neural networks are highly expressive models that have recently achieved
state of the art performance on speech and visual recognition tasks. While
their expressiveness is the reason they succeed, it also causes them to learn
uninterpretable solutions that could have counter-intuitive properties. In this
paper we report two such properties.
  First, we find that there is no distinction between individual high level
units and random linear combinations of high level units, according to various
methods of unit analysis. It suggests that it is the space, rather than the
individual units, that contains of the semantic information in the high layers
of neural networks.
  Second, we find that deep neural networks learn input-output mappings that
are fairly discontinuous to a significant extend. We can cause the network to
misclassify an image by applying a certain imperceptible perturbation, which is
found by maximizing the network's prediction error. In addition, the specific
nature of these perturbations is not a random artifact of learning: the same
perturbation can cause a different network, that was trained on a different
subset of the dataset, to misclassify the same input.},
  file = {/Users/yuekai/Documents/zotero/Szegedy et al (2013) - Intriguing properties of neural networks.pdf},
  language = {en}
}

@article{tabak2020Conditional,
  title = {Conditional Density Estimation and Simulation through Optimal Transport},
  author = {Tabak, Esteban G. and Trigila, Giulio and Zhao, Wenjun},
  year = {2020},
  month = apr,
  volume = {109},
  pages = {665--688},
  issn = {1573-0565},
  doi = {10.1007/s10994-019-05866-3},
  abstract = {A methodology to estimate from samples the probability density of a random variable x conditional to the values of a set of covariates \$\$\textbackslash\{z\_\{l\}\textbackslash\}\$\$\{zl\} is proposed. The methodology relies on a data-driven formulation of the Wasserstein barycenter, posed as a minimax problem in terms of the conditional map carrying each sample point to the barycenter and a potential characterizing the inverse of this map. This minimax problem is solved through the alternation of a flow developing the map in time and the maximization of the potential through an alternate projection procedure. The dependence on the covariates \$\$\textbackslash\{z\_\{l\}\textbackslash\}\$\$\{zl\} is formulated in terms of convex combinations, so that it can be applied to variables of nearly any type, including real, categorical and distributional. The methodology is illustrated through numerical examples on synthetic and real data. The real-world example chosen is meteorological, forecasting the temperature distribution at a given location as a function of time, and estimating the joint distribution at a location of the highest and lowest daily temperatures as a function of the date.},
  file = {/Users/yuekai/Documents/zotero/Tabak et al (2020) - Conditional density estimation and simulation through optimal transport.pdf},
  journal = {Machine Learning},
  language = {en},
  number = {4}
}

@article{tabibian2019Consequential,
  title = {Consequential {{Ranking Algorithms}} and {{Long}}-Term {{Welfare}}},
  author = {Tabibian, Behzad and G{\'o}mez, Vicen{\c c} and De, Abir and Sch{\"o}lkopf, Bernhard and Rodriguez, Manuel Gomez},
  year = {2019},
  month = may,
  abstract = {Ranking models are typically designed to provide rankings that optimize some measure of immediate utility to the users. As a result, they have been unable to anticipate an increasing number of undesirable long-term consequences of their proposed rankings, from fueling the spread of misinformation and increasing polarization to degrading social discourse. Can we design ranking models that understand the consequences of their proposed rankings and, more importantly, are able to avoid the undesirable ones? In this paper, we first introduce a joint representation of rankings and user dynamics using Markov decision processes. Then, we show that this representation greatly simplifies the construction of consequential ranking models that trade off the immediate utility and the long-term welfare. In particular, we can obtain optimal consequential rankings just by applying weighted sampling on the rankings provided by models that maximize measures of immediate utility. However, in practice, such a strategy may be inefficient and impractical, specially in high dimensional scenarios. To overcome this, we introduce an efficient gradient-based algorithm to learn parameterized consequential ranking models that effectively approximate optimal ones. We showcase our methodology using synthetic and real data gathered from Reddit and show that ranking models derived using our methodology provide ranks that may mitigate the spread of misinformation and improve the civility of online discussions.},
  archivePrefix = {arXiv},
  eprint = {1905.05305},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Tabibian et al (2019) - Consequential Ranking Algorithms and Long-term Welfare.pdf},
  journal = {arXiv:1905.05305 [cs, stat]},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{taghvaei20192Wasserstein,
  title = {2-{{Wasserstein Approximation}} via {{Restricted Convex Potentials}} with {{Application}} to {{Improved Training}} for {{GANs}}},
  author = {Taghvaei, Amirhossein and Jalali, Amin},
  year = {2019},
  month = feb,
  abstract = {We provide a framework to approximate the 2-Wasserstein distance and the optimal transport map, amenable to efficient training as well as statistical and geometric analysis. With the quadratic cost and considering the Kantorovich dual form of the optimal transportation problem, the Brenier theorem states that the optimal potential function is convex and the optimal transport map is the gradient of the optimal potential function. Using this geometric structure, we restrict the optimization problem to different parametrized classes of convex functions and pay special attention to the class of input-convex neural networks. We analyze the statistical generalization and the discriminative power of the resulting approximate metric, and we prove a restricted moment-matching property for the approximate optimal map. Finally, we discuss a numerical algorithm to solve the restricted optimization problem and provide numerical experiments to illustrate and compare the proposed approach with the established regularization-based approaches. We further discuss practical implications of our proposal in a modular and interpretable design for GANs which connects the generator training with discriminator computations to allow for learning an overall composite generator.},
  archivePrefix = {arXiv},
  eprint = {1902.07197},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Taghvaei, Jalali (2019) - 2-Wasserstein Approximation via Restricted Convex Potentials with Application.pdf},
  journal = {arXiv:1902.07197 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{takada2018HMLasso,
  title = {{{HMLasso}}: {{Lasso}} for {{High Dimensional}} and {{Highly Missing Data}}},
  shorttitle = {{{HMLasso}}},
  author = {Takada, Masaaki and Fujisawa, Hironori and Nishikawa, Takeichiro},
  year = {2018},
  month = nov,
  abstract = {Sparse regression such as Lasso has achieved great success in dealing with high dimensional data for several decades. However, there are few methods applicable to missing data, which often occurs in high dimensional data. Recently, CoCoLasso was proposed to deal with high dimensional missing data, but it still suffers from highly missing data. In this paper, we propose a novel Lasso-type regression technique for Highly Missing data, called `HMLasso'. We use the mean imputed covariance matrix, which is notorious in general due to its estimation bias for missing data. However, we effectively incorporate it into Lasso, by using a useful connection with the pairwise covariance matrix. The resulting optimization problem can be seen as a weighted modification of CoCoLasso with the missing ratios, and is quite effective for highly missing data. To the best of our knowledge, this is the first method that can efficiently deal with both high dimensional and highly missing data. We show that the proposed method is beneficial with regards to non-asymptotic properties of the covariance matrix. Numerical experiments show that the proposed method is highly advantageous in terms of estimation error and generalization error.},
  archivePrefix = {arXiv},
  eprint = {1811.00255},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Takada et al (2018) - HMLasso.pdf},
  journal = {arXiv:1811.00255 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{tamuz2011Adaptively,
  title = {Adaptively {{Learning}} the {{Crowd Kernel}}},
  author = {Tamuz, Omer and Liu, Ce and Belongie, Serge and Shamir, Ohad and Kalai, Adam Tauman},
  year = {2011},
  month = may,
  abstract = {We introduce an algorithm that, given n objects, learns a similarity matrix over all n\^2 pairs, from crowdsourced data alone. The algorithm samples responses to adaptively chosen triplet-based relative-similarity queries. Each query has the form "is object 'a' more similar to 'b' or to 'c'?" and is chosen to be maximally informative given the preceding responses. The output is an embedding of the objects into Euclidean space (like MDS); we refer to this as the "crowd kernel." SVMs reveal that the crowd kernel captures prominent and subtle features across a number of domains, such as "is striped" among neckties and "vowel vs. consonant" among letters.},
  archivePrefix = {arXiv},
  eprint = {1105.1033},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Tamuz et al (2011) - Adaptively Learning the Crowd Kernel.pdf},
  journal = {arXiv:1105.1033 [cs]},
  keywords = {Computer Science - Machine Learning},
  primaryClass = {cs}
}

@inproceedings{tan2018DistillandCompare,
  title = {Distill-and-{{Compare}}: {{Auditing Black}}-{{Box Models Using Transparent Model Distillation}}},
  shorttitle = {Distill-and-{{Compare}}},
  booktitle = {Proceedings of the 2018 {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  author = {Tan, Sarah and Caruana, Rich and Hooker, Giles and Lou, Yin},
  year = {2018},
  month = dec,
  pages = {303--310},
  publisher = {{Association for Computing Machinery}},
  address = {{New Orleans, LA, USA}},
  doi = {10.1145/3278721.3278725},
  abstract = {Black-box risk scoring models permeate our lives, yet are typically proprietary or opaque. We propose Distill-and-Compare, an approach to audit such models without probing the black-box model API or pre-defining features to audit. To gain insight into black-box models, we treat them as teachers, training transparent student models to mimic the risk scores assigned by the black-box models. We compare the mimic model trained with distillation to a second, un-distilled transparent model trained on ground truth outcomes, and use differences between the two models to gain insight into the black-box model. We demonstrate the approach on four data sets: COMPAS, Stop-and-Frisk, Chicago Police, and Lending Club. We also propose a statistical test to determine if a data set is missing key features used to train the black-box model. Our test finds that the ProPublica data is likely missing key feature(s) used in COMPAS.},
  file = {/Users/yuekai/Documents/zotero/Tan et al (2018) - Distill-and-Compare.pdf},
  isbn = {978-1-4503-6012-8},
  keywords = {black-box models,distillation,fairness,interpretability},
  series = {{{AIES}} '18}
}

@article{tang2018Integrated,
  title = {Integrated {{Principal Components Analysis}}},
  author = {Tang, Tiffany M. and Allen, Genevera I.},
  year = {2018},
  month = oct,
  abstract = {Data integration, or the strategic analysis of multiple sources of data simultaneously, can often lead to discoveries that may be hidden in individualistic analyses of a single data source. We develop a new statistical data integration method named Integrated Principal Components Analysis (iPCA), which is a model-based generalization of PCA and serves as a practical tool to find and visualize common patterns that occur in multiple datasets. The key idea driving iPCA is the matrix-variate normal model, whose Kronecker product covariance structure captures both individual patterns within each dataset and joint patterns shared by multiple datasets. Building upon this model, we develop several penalized (sparse and non-sparse) covariance estimators for iPCA and study their theoretical properties. We show that our sparse iPCA estimator consistently estimates the underlying joint subspace, and using geodesic convexity, we prove that our non-sparse iPCA estimator converges to the global solution of a non-convex problem. We also demonstrate the practical advantages of iPCA through simulations and a case study application to integrative genomics for Alzheimer's Disease. In particular, we show that the joint patterns extracted via iPCA are highly predictive of a patient's cognition and Alzheimer's diagnosis.},
  archivePrefix = {arXiv},
  eprint = {1810.00832},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Tang, Allen (2018) - Integrated Principal Components Analysis.pdf},
  journal = {arXiv:1810.00832 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{taskesen2020Distributionally,
  title = {A {{Distributionally Robust Approach}} to {{Fair Classification}}},
  author = {Taskesen, Bahar and Nguyen, Viet Anh and Kuhn, Daniel and Blanchet, Jose},
  year = {2020},
  month = jul,
  abstract = {We propose a distributionally robust logistic regression model with an unfairness penalty that prevents discrimination with respect to sensitive attributes such as gender or ethnicity. This model is equivalent to a tractable convex optimization problem if a Wasserstein ball centered at the empirical distribution on the training data is used to model distributional uncertainty and if a new convex unfairness measure is used to incentivize equalized opportunities. We demonstrate that the resulting classifier improves fairness at a marginal loss of predictive accuracy on both synthetic and real datasets. We also derive linear programming-based confidence bounds on the level of unfairness of any pre-trained classifier by leveraging techniques from optimal uncertainty quantification over Wasserstein balls.},
  archivePrefix = {arXiv},
  eprint = {2007.09530},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Taskesen et al (2020) - A Distributionally Robust Approach to Fair Classification.pdf},
  journal = {arXiv:2007.09530 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{tenenbaum2000Global,
  title = {A {{Global Geometric Framework}} for {{Nonlinear Dimensionality Reduction}}},
  author = {Tenenbaum, J. B.},
  year = {2000},
  month = dec,
  volume = {290},
  pages = {2319--2323},
  issn = {00368075, 10959203},
  doi = {10.1126/science.290.5500.2319},
  file = {/Users/yuekai/Documents/zotero/Tenenbaum (2000) - A Global Geometric Framework for Nonlinear Dimensionality Reduction.pdf},
  journal = {Science},
  language = {en},
  number = {5500}
}

@incollection{tewari2017Ads,
  title = {From {{Ads}} to {{Interventions}}: {{Contextual Bandits}} in {{Mobile Health}}},
  shorttitle = {From {{Ads}} to {{Interventions}}},
  booktitle = {Mobile {{Health}}},
  author = {Tewari, Ambuj and Murphy, Susan A.},
  editor = {Rehg, James M. and Murphy, Susan A. and Kumar, Santosh},
  year = {2017},
  pages = {495--517},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-51394-2_25},
  abstract = {The first paper on contextual bandits was written by Michael Woodroofe in 1979 (Journal of the American Statistical Association, 74(368), 799\textendash 806, 1979) but the term ``contextual bandits'' was invented only recently in 2008 by Langford and Zhang (Advances in neural information processing systems, pages 817\textendash 824, 2008). Woodroofe's motivating application was clinical trials whereas modern interest in this problem was driven to a great extent by problems on the internet, such as online ad and online news article placement. We have now come full circle because contextual bandits provide a natural framework for sequential decision making in mobile health. We will survey the contextual bandits literature with a focus on modifications needed to adapt existing approaches to the mobile health setting. We discuss specific challenges in this direction such as: good initialization of the learning algorithm, finding interpretable policies, assessing usefulness of tailoring variables, computational considerations, robustness to failure of assumptions, and dealing with variables that are costly to acquire and missing.},
  file = {/Users/yuekai/Documents/zotero/Tewari, Murphy (2017) - From Ads to Interventions.pdf},
  isbn = {978-3-319-51393-5 978-3-319-51394-2},
  language = {en}
}

@article{thorpe2018Introduction,
  title = {Introduction to {{Optimal Transport}}},
  author = {Thorpe, Matthew},
  year = {2018},
  month = mar,
  pages = {56},
  file = {/Users/yuekai/Documents/zotero/Thorpe (2018) - Introduction to Optimal Transport.pdf},
  language = {en}
}

@article{thys2019Fooling,
  title = {Fooling Automated Surveillance Cameras: Adversarial Patches to Attack Person Detection},
  shorttitle = {Fooling Automated Surveillance Cameras},
  author = {Thys, Simen and Van Ranst, Wiebe and Goedem{\'e}, Toon},
  year = {2019},
  month = apr,
  abstract = {Adversarial attacks on machine learning models have seen increasing interest in the past years. By making only subtle changes to the input of a convolutional neural network, the output of the network can be swayed to output a completely different result. The first attacks did this by changing pixel values of an input image slightly to fool a classifier to output the wrong class. Other approaches have tried to learn "patches" that can be applied to an object to fool detectors and classifiers. Some of these approaches have also shown that these attacks are feasible in the real-world, i.e. by modifying an object and filming it with a video camera. However, all of these approaches target classes that contain almost no intra-class variety (e.g. stop signs). The known structure of the object is then used to generate an adversarial patch on top of it. In this paper, we present an approach to generate adversarial patches to targets with lots of intra-class variety, namely persons. The goal is to generate a patch that is able successfully hide a person from a person detector. An attack that could for instance be used maliciously to circumvent surveillance systems, intruders can sneak around undetected by holding a small cardboard plate in front of their body aimed towards the surveillance camera. From our results we can see that our system is able significantly lower the accuracy of a person detector. Our approach also functions well in real-life scenarios where the patch is filmed by a camera. To the best of our knowledge we are the first to attempt this kind of attack on targets with a high level of intra-class variety like persons.},
  archivePrefix = {arXiv},
  eprint = {1904.08653},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Thys et al (2019) - Fooling automated surveillance cameras.pdf},
  journal = {arXiv:1904.08653 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryClass = {cs}
}

@article{tian2015Selective,
  title = {Selective Inference with a Randomized Response},
  author = {Tian, Xiaoying and Taylor, Jonathan E.},
  year = {2015},
  month = jul,
  abstract = {Inspired by sample splitting and the reusable holdout introduced in the field of differential privacy, we consider selective inference with a randomized response. We discuss two major advantages of using a randomized response for model selection. First, the selectively valid tests are more powerful after randomized selection. Second, it allows consistent estimation and weak convergence of selective inference procedures. Under independent sampling, we prove a selective (or privatized) central limit theorem that transfers procedures valid under asymptotic normality without selection to their corresponding selective counterparts. This allows selective inference in nonparametric settings. Finally, we propose a framework of inference after combining multiple randomized selection procedures. We focus on the classical asymptotic setting, leaving the interesting high-dimensional asymptotic questions for future work.},
  archivePrefix = {arXiv},
  eprint = {1507.06739},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Tian, Taylor (2015) - Selective inference with a randomized response.pdf},
  journal = {arXiv:1507.06739 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{tibshirani2014General,
  title = {A {{General Framework}} for {{Fast Stagewise Algorithms}}},
  author = {Tibshirani, Ryan J.},
  year = {2014},
  month = aug,
  abstract = {Forward stagewise regression follows a very simple strategy for constructing a sequence of sparse regression estimates: it starts with all coefficients equal to zero, and iteratively updates the coefficient (by a small amount \$\textbackslash epsilon\$) of the variable that achieves the maximal absolute inner product with the current residual. This procedure has an interesting connection to the lasso: under some conditions, it is known that the sequence of forward stagewise estimates exactly coincides with the lasso path, as the step size \$\textbackslash epsilon\$ goes to zero. Furthermore, essentially the same equivalence holds outside of least squares regression, with the minimization of a differentiable convex loss function subject to an \$\textbackslash ell\_1\$ norm constraint (the stagewise algorithm now updates the coefficient corresponding to the maximal absolute component of the gradient). Even when they do not match their \$\textbackslash ell\_1\$-constrained analogues, stagewise estimates provide a useful approximation, and are computationally appealing. Their success in sparse modeling motivates the question: can a simple, effective strategy like forward stagewise be applied more broadly in other regularization settings, beyond the \$\textbackslash ell\_1\$ norm and sparsity? The current paper is an attempt to do just this. We present a general framework for stagewise estimation, which yields fast algorithms for problems such as group-structured learning, matrix completion, image denoising, and more.},
  archivePrefix = {arXiv},
  eprint = {1408.5801},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Tibshirani (2014) - A General Framework for Fast Stagewise Algorithms.pdf},
  journal = {arXiv:1408.5801 [stat]},
  keywords = {Statistics - Computation,Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{ting2020Manifold,
  title = {Manifold {{Learning}} via {{Manifold Deflation}}},
  author = {Ting, Daniel and Jordan, Michael I.},
  year = {2020},
  month = jul,
  abstract = {Nonlinear dimensionality reduction methods provide a valuable means to visualize and interpret high-dimensional data. However, many popular methods can fail dramatically, even on simple two-dimensional manifolds, due to problems such as vulnerability to noise, repeated eigendirections, holes in convex bodies, and boundary bias. We derive an embedding method for Riemannian manifolds that iteratively uses single-coordinate estimates to eliminate dimensions from an underlying differential operator, thus "deflating" it. These differential operators have been shown to characterize any local, spectral dimensionality reduction method. The key to our method is a novel, incremental tangent space estimator that incorporates global structure as coordinates are added. We prove its consistency when the coordinates converge to true coordinates. Empirically, we show our algorithm recovers novel and interesting embeddings on real-world and synthetic datasets.},
  archivePrefix = {arXiv},
  eprint = {2007.03315},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ting, Jordan (2020) - Manifold Learning via Manifold Deflation.pdf},
  journal = {arXiv:2007.03315 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Differential Geometry,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@misc{tobin2019HUD,
  title = {{{HUD Sues Facebook Over Housing Discrimination}} and {{Says}} the {{Company}}'s {{Algorithms Have Made}} the {{Problem Worse}}},
  author = {Tobin, Ariana},
  year = {2019},
  month = mar,
  abstract = {The charge comes a week after Facebook made major changes to its advertising platform, and two years after our reporting raised the issue.},
  copyright = {Copyright \textcopyright 2019 ProPublica.},
  howpublished = {https://www.propublica.org/article/hud-sues-facebook-housing-discrimination-advertising-algorithms},
  journal = {ProPublica},
  language = {en},
  type = {Text/Html}
}

@misc{tobin2019New,
  title = {New {{York Is Investigating Whether Facebook Lets Advertisers Discriminate}}},
  author = {Tobin, Ariana},
  year = {2019},
  month = jul,
  abstract = {The state's Department of Financial Services will look into allegations, first exposed by ProPublica, that advertisers can exclude users by race, gender, age and other characteristics that are protected under federal law.},
  copyright = {Copyright \textcopyright 2019 ProPublica.},
  howpublished = {https://www.propublica.org/article/new-york-is-investigating-whether-facebook-lets-advertisers-discriminate},
  journal = {ProPublica},
  language = {en}
}

@inproceedings{torralba2011Unbiased,
  title = {Unbiased Look at Dataset Bias},
  booktitle = {{{CVPR}} 2011},
  author = {Torralba, Antonio and Efros, Alexei A.},
  year = {2011},
  month = jun,
  pages = {1521--1528},
  publisher = {{IEEE}},
  address = {{Colorado Springs, CO, USA}},
  doi = {10.1109/CVPR.2011.5995347},
  abstract = {Datasets are an integral part of contemporary object recognition research. They have been the chief reason for the considerable progress in the field, not just as source of large amounts of training data, but also as means of measuring and comparing performance of competing algorithms. At the same time, datasets have often been blamed for narrowing the focus of object recognition research, reducing it to a single benchmark performance number. Indeed, some datasets, that started out as data capture efforts aimed at representing the visual world, have become closed worlds unto themselves (e.g. the Corel world, the Caltech101 world, the PASCAL VOC world). With the focus on beating the latest benchmark numbers on the latest dataset, have we perhaps lost sight of the original purpose? The goal of this paper is to take stock of the current state of recognition datasets. We present a comparison study using a set of popular datasets, evaluated based on a number of criteria including: relative data bias, cross-dataset generalization, effects of closed-world assumption, and sample value. The experimental results, some rather surprising, suggest directions that can improve dataset collection as well as algorithm evaluation protocols. But more broadly, the hope is to stimulate discussion in the community regarding this very important, but largely neglected issue.},
  file = {/Users/yuekai/Documents/zotero/Torralba, Efros (2011) - Unbiased look at dataset bias.pdf},
  isbn = {978-1-4577-0394-2},
  language = {en}
}

@article{tramer2017Ensemble,
  title = {Ensemble {{Adversarial Training}}: {{Attacks}} and {{Defenses}}},
  shorttitle = {Ensemble {{Adversarial Training}}},
  author = {Tram{\`e}r, Florian and Kurakin, Alexey and Papernot, Nicolas and Goodfellow, Ian and Boneh, Dan and McDaniel, Patrick},
  year = {2017},
  month = may,
  abstract = {Adversarial examples are perturbed inputs designed to fool machine learning
models. Adversarial training injects such examples into training data to
increase robustness. To scale this technique to large datasets, perturbations
are crafted using fast single-step methods that maximize a linear approximation
of the model's loss. We show that this form of adversarial training converges
to a degenerate global minimum, wherein small curvature artifacts near the data
points obfuscate a linear approximation of the loss. The model thus learns to
generate weak perturbations, rather than defend against strong ones. As a
result, we find that adversarial training remains vulnerable to black-box
attacks, where we transfer perturbations computed on undefended models, as well
as to a powerful novel single-step attack that escapes the non-smooth vicinity
of the input data via a small random step. We further introduce Ensemble
Adversarial Training, a technique that augments training data with
perturbations transferred from other models. On ImageNet, Ensemble Adversarial
Training yields models with strong robustness to black-box attacks. In
particular, our most robust model won the first round of the NIPS 2017
competition on Defenses against Adversarial Attacks.},
  file = {/Users/yuekai/Documents/zotero/Tramèr et al (2017) - Ensemble Adversarial Training.pdf},
  language = {en}
}

@article{tramer2017Space,
  title = {The {{Space}} of {{Transferable Adversarial Examples}}},
  author = {Tram{\`e}r, Florian and Papernot, Nicolas and Goodfellow, Ian and Boneh, Dan and McDaniel, Patrick},
  year = {2017},
  month = apr,
  abstract = {Adversarial examples are maliciously perturbed inputs designed to mislead machine learning (ML) models at test-time. They often transfer: the same adversarial example fools more than one model. In this work, we propose novel methods for estimating the previously unknown dimensionality of the space of adversarial inputs. We find that adversarial examples span a contiguous subspace of large (\textasciitilde 25) dimensionality. Adversarial subspaces with higher dimensionality are more likely to intersect. We find that for two different models, a significant fraction of their subspaces is shared, thus enabling transferability. In the first quantitative analysis of the similarity of different models' decision boundaries, we show that these boundaries are actually close in arbitrary directions, whether adversarial or benign. We conclude by formally studying the limits of transferability. We derive (1) sufficient conditions on the data distribution that imply transferability for simple model classes and (2) examples of scenarios in which transfer does not occur. These findings indicate that it may be possible to design defenses against transfer-based attacks, even for models that are vulnerable to direct attacks.},
  archivePrefix = {arXiv},
  eprint = {1704.03453},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Tramèr et al (2017) - The Space of Transferable Adversarial Examples.pdf},
  journal = {arXiv:1704.03453 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{trefethen1999Computation,
  title = {Computation of Pseudospectra},
  author = {Trefethen, Lloyd N.},
  year = {1999},
  month = jan,
  volume = {8},
  pages = {247--295},
  issn = {0962-4929, 1474-0508},
  doi = {10.1017/S0962492900002932},
  abstract = {There is more to the computation of pseudospectra than the obvious algorithm of computing singular value decompositions on a grid and sending the results to a contour plotter. Other methods may be hundreds of times faster. The state of the art is reviewed, with emphasis on methods for dense matrices, and a Matlab code is given.},
  file = {/Users/yuekai/Documents/zotero/Trefethen (1999) - Computation of pseudospectra.pdf},
  journal = {Acta Numerica},
  language = {en}
}

@article{triantafillou2019MetaDataset,
  title = {Meta-{{Dataset}}: {{A Dataset}} of {{Datasets}} for {{Learning}} to {{Learn}} from {{Few Examples}}},
  shorttitle = {Meta-{{Dataset}}},
  author = {Triantafillou, Eleni and Zhu, Tyler and Dumoulin, Vincent and Lamblin, Pascal and Xu, Kelvin and Goroshin, Ross and Gelada, Carles and Swersky, Kevin and Manzagol, Pierre-Antoine and Larochelle, Hugo},
  year = {2019},
  month = mar,
  abstract = {Few-shot classification refers to learning a classifier for new classes given only a few examples. While a plethora of models have emerged to tackle this recently, we find the current procedure and datasets that are used to systematically assess progress in this setting lacking. To address this, we propose Meta-Dataset: a new benchmark for training and evaluating few-shot classifiers that is large-scale, consists of multiple datasets, and presents more natural and realistic tasks. The aim is to measure the ability of state-of-the-art models to leverage diverse sources of data to achieve higher generalization, and to evaluate that generalization ability in a more challenging setting. We additionally measure robustness of current methods to variations in the number of available examples and the number of classes. Finally our extensive empirical evaluation leads us to identify weaknesses in Prototypical Networks and MAML, two popular few-shot classification methods, and to propose a new method, Proto-MAML, which achieves improved performance on our benchmark.},
  archivePrefix = {arXiv},
  eprint = {1903.03096},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Triantafillou et al (2019) - Meta-Dataset.pdf},
  journal = {arXiv:1903.03096 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{tripuraneni2020Provable,
  title = {Provable {{Meta}}-{{Learning}} of {{Linear Representations}}},
  author = {Tripuraneni, Nilesh and Jin, Chi and Jordan, Michael I.},
  year = {2020},
  month = feb,
  abstract = {Meta-learning, or learning-to-learn, seeks to design algorithms that can utilize previous experience to rapidly learn new skills or adapt to new environments. Representation learning---a key tool for performing meta-learning---learns a data representation that can transfer knowledge across multiple tasks, which is essential in regimes where data is scarce. Despite a recent surge of interest in the practice of meta-learning, the theoretical underpinnings of meta-learning algorithms are lacking, especially in the context of learning transferable representations. In this paper, we focus on the problem of multi-task linear regression---in which multiple linear regression models share a common, low-dimensional linear representation. Here, we provide provably fast, sample-efficient algorithms to address the dual challenges of (1) learning a common set of features from multiple, related tasks, and (2) transferring this knowledge to new, unseen tasks. Both are central to the general problem of meta-learning. Finally, we complement these results by providing information-theoretic lower bounds on the sample complexity of learning these linear features, showing that our algorithms are optimal up to logarithmic factors.},
  archivePrefix = {arXiv},
  eprint = {2002.11684},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Tripuraneni et al (2020) - Provable Meta-Learning of Linear Representations.pdf},
  journal = {arXiv:2002.11684 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{tripuraneni2020Theory,
  title = {On the {{Theory}} of {{Transfer Learning}}: {{The Importance}} of {{Task Diversity}}},
  shorttitle = {On the {{Theory}} of {{Transfer Learning}}},
  author = {Tripuraneni, Nilesh and Jordan, Michael I. and Jin, Chi},
  year = {2020},
  month = jun,
  abstract = {We provide new statistical guarantees for transfer learning via representation learning--when transfer is achieved by learning a feature representation shared across different tasks. This enables learning on new tasks using far less data than is required to learn them in isolation. Formally, we consider \$t+1\$ tasks parameterized by functions of the form \$f\_j \textbackslash circ h\$ in a general function class \$\textbackslash mathcal\{F\} \textbackslash circ \textbackslash mathcal\{H\}\$, where each \$f\_j\$ is a task-specific function in \$\textbackslash mathcal\{F\}\$ and \$h\$ is the shared representation in \$\textbackslash mathcal\{H\}\$. Letting \$C(\textbackslash cdot)\$ denote the complexity measure of the function class, we show that for diverse training tasks (1) the sample complexity needed to learn the shared representation across the first \$t\$ training tasks scales as \$C(\textbackslash mathcal\{H\}) + t C(\textbackslash mathcal\{F\})\$, despite no explicit access to a signal from the feature representation and (2) with an accurate estimate of the representation, the sample complexity needed to learn a new task scales only with \$C(\textbackslash mathcal\{F\})\$. Our results depend upon a new general notion of task diversity--applicable to models with general tasks, features, and losses--as well as a novel chain rule for Gaussian complexities. Finally, we exhibit the utility of our general framework in several models of importance in the literature.},
  archivePrefix = {arXiv},
  eprint = {2006.11650},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Tripuraneni et al (2020) - On the Theory of Transfer Learning.pdf},
  journal = {arXiv:2006.11650 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{trosset2019Approximate,
  title = {Approximate {{Information Tests}} on {{Statistical Submanifolds}}},
  author = {Trosset, Michael W. and Priebe, Carey E.},
  year = {2019},
  month = mar,
  abstract = {Parametric inference posits a statistical model that is a specified family of probability distributions. Restricted inference, e.g., restricted likelihood ratio testing, attempts to exploit the structure of a statistical submodel that is a subset of the specified family. We consider the problem of testing a simple hypothesis against alternatives from such a submodel. In the case of an unknown submodel, it is not clear how to realize the benefits of restricted inference. To do so, we first construct information tests that are locally asymptotically equivalent to likelihood ratio tests. Information tests are conceptually appealing but (in general) computationally intractable. However, unlike restricted likelihood ratio tests, restricted information tests can be approximated even when the statistical submodel is unknown. We construct approximate information tests using manifold learning procedures to extract information from samples of an unknown (or intractable) submodel, thereby providing a roadmap for computational solutions to a class of previously impenetrable problems in statistical inference. Examples illustrate the efficacy of the proposed methodology.},
  archivePrefix = {arXiv},
  eprint = {1903.08656},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Trosset, Priebe (2019) - Approximate Information Tests on Statistical Submanifolds.pdf},
  journal = {arXiv:1903.08656 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{tsipras2018Robustness,
  title = {Robustness {{May Be}} at {{Odds}} with {{Accuracy}}},
  author = {Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
  year = {2018},
  month = may,
  abstract = {We show that there exists an inherent tension between the goal of adversarial robustness and that of standard generalization. Specifically, training robust models may not only be more resource-consuming, but also lead to a reduction of standard accuracy. We demonstrate that this trade-off between the standard accuracy of a model and its robustness to adversarial perturbations provably exists even in a fairly simple and natural setting. These findings also corroborate a similar phenomenon observed in practice. Further, we argue that this phenomenon is a consequence of robust classifiers learning fundamentally different feature representations than standard classifiers. These differences, in particular, seem to result in unexpected benefits: the representations learned by robust models tend to align better with salient data characteristics and human perception.},
  archivePrefix = {arXiv},
  eprint = {1805.12152},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Tsipras et al (2018) - Robustness May Be at Odds with Accuracy.pdf},
  journal = {arXiv:1805.12152 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@book{tsybakov2009Introduction,
  title = {Introduction to {{Nonparametric Estimation}}},
  author = {Tsybakov, Alexandre B.},
  year = {2009},
  publisher = {{Springer}},
  address = {{New York ; London}},
  annotation = {OCLC: ocn300399286},
  file = {/Users/yuekai/Documents/zotero/Tsybakov (2009) - Introduction to nonparametric estimation.pdf},
  isbn = {978-0-387-79051-0 978-0-387-79052-7},
  language = {en},
  lccn = {QA278.8 .T79 2009},
  series = {Springer Series in Statistics}
}

@article{uppal2019Nonparametric,
  title = {Nonparametric {{Density Estimation}} under {{Besov IPM Losses}}},
  author = {Uppal, Ananya and Singh, Shashank and P{\'o}czos, Barnab{\'a}s},
  year = {2019},
  month = may,
  abstract = {We study the problem of estimating a nonparametric probability density under a large family of losses called Besov IPMs, which include, for example, \$\textbackslash mathcal\{L\}\^p\$ distances, total variation distance, and generalizations of both Wasserstein and Kolmogorov-Smirnov distances. For a wide variety of settings, we provide both lower and upper bounds, identifying precisely how the choice of loss function and assumptions on the data interact to determine the minimax optimal convergence rate. We also show that linear distribution estimates, such as the empirical distribution or kernel density estimator, often fail to converge at the optimal rate. Our bounds generalize, unify, or improve several recent and classical results. Moreover, IPMs can be used to formalize a statistical model of generative adversarial networks (GANs). Thus, we show how our results imply bounds on the statistical error of a GAN, showing, for example, that GANs can strictly outperform the best linear estimator.},
  archivePrefix = {arXiv},
  eprint = {1902.03511},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Uppal et al (2019) - Nonparametric Density Estimation under Besov IPM Losses.pdf},
  journal = {arXiv:1902.03511 [cs, math, stat]},
  keywords = {Computer Science - Information Theory,Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{useeoc1979Uniform,
  title = {Uniform Guidelines on Employee Selection Procedures},
  author = {US EEOC},
  year = {1979},
  month = mar,
  volume = {44},
  file = {/Users/yuekai/Zotero/storage/P9UGPRJU/questions-and-answers-clarify-and-provide-common-interpretation-uniform-guidelines.html},
  journal = {Federal Register},
  number = {43}
}

@article{usman2020LogLikelihood,
  title = {Log-{{Likelihood Ratio Minimizing Flows}}: {{Towards Robust}} and {{Quantifiable Neural Distribution Alignment}}},
  shorttitle = {Log-{{Likelihood Ratio Minimizing Flows}}},
  author = {Usman, Ben and Dufour, Nick and Sud, Avneesh and Saenko, Kate},
  year = {2020},
  month = mar,
  abstract = {Unsupervised distribution alignment has many applications in deep learning, including domain adaptation and unsupervised image-to-image translation. Most prior work on unsupervised distribution alignment relies either on minimizing simple non-parametric statistical distances such as maximum mean discrepancy, or on adversarial alignment. However, the former fails to capture the structure of complex real-world distributions, while the latter is difficult to train and does not provide any universal convergence guarantees or automatic quantitative validation procedures. In this paper we propose a new distribution alignment method based on a log-likelihood ratio statistic and normalizing flows. We show that, under certain assumptions, this combination yields a deep neural likelihood-based minimization objective that attains a known lower bound upon convergence. We experimentally verify that minimizing the resulting objective results in domain alignment that preserves the local structure of input domains.},
  archivePrefix = {arXiv},
  eprint = {2003.12170},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Usman et al (2020) - Log-Likelihood Ratio Minimizing Flows.pdf},
  journal = {arXiv:2003.12170 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{ustun2019Actionable,
  title = {Actionable {{Recourse}} in {{Linear Classification}}},
  booktitle = {Proceedings of the {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}  - {{FAT}}* '19},
  author = {Ustun, Berk and Spangher, Alexander and Liu, Yang},
  year = {2019},
  pages = {10--19},
  publisher = {{ACM Press}},
  address = {{Atlanta, GA, USA}},
  doi = {10.1145/3287560.3287566},
  abstract = {Classi\dbend cation models are often used to make decisions that a\dbend ect humans: whether to approve a loan application, extend a job o\dbend er, or provide insurance. In such applications, individuals should have the ability to change the decision of the model. When a person is denied a loan by a credit scoring model, for example, they should be able to change the input variables of the model in a way that will guarantee approval. Otherwise, this person will be denied the loan so long as the model is deployed, and \textendash{} more importantly \textendash will lack agency over a decision that a\dbend ects their livelihood.},
  file = {/Users/yuekai/Documents/zotero/Ustun et al (2019) - Actionable Recourse in Linear Classification.pdf},
  isbn = {978-1-4503-6125-5},
  language = {en}
}

@book{vaart2000Weak,
  title = {Weak Convergence and Empirical Processes: With Applications to Statistics},
  shorttitle = {Weak Convergence and Empirical Processes},
  author = {van der Vaart, A. W. and Wellner, Jon A},
  year = {2000},
  publisher = {{Springer}},
  address = {{New York}},
  annotation = {OCLC: 45749647},
  file = {/Users/yuekai/Documents/zotero/Vaart, Wellner (2000) - Weak convergence and empirical processes.pdf},
  isbn = {978-0-387-94640-5 978-1-4757-2547-6},
  language = {en}
}

@article{vandegeer2014asymptotically,
  title = {On Asymptotically Optimal Confidence Regions and Tests for High-Dimensional Models},
  author = {{van de Geer}, Sara and B{\"u}hlmann, Peter and Ritov, Ya'acov and Dezeure, Ruben},
  year = {2014},
  month = jun,
  volume = {42},
  pages = {1166--1202},
  issn = {0090-5364},
  doi = {10.1214/14-AOS1221},
  abstract = {We propose a general method for constructing confidence intervals and statistical tests for single or low-dimensional components of a large parameter vector in a high-dimensional model. It can be easily adjusted for multiplicity taking dependence among tests into account. For linear models, our method is essentially the same as in Zhang and Zhang [J. R. Stat. Soc. Ser. B Stat. Methodol. 76 (2014) 217-242]: we analyze its asymptotic properties and establish its asymptotic optimality in terms of semiparametric efficiency. Our method naturally extends to generalized linear models with convex loss functions. We develop the corresponding theory which includes a careful analysis for Gaussian, sub-Gaussian and bounded correlated designs.},
  archivePrefix = {arXiv},
  eprint = {1303.0518},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/van de Geer et al (2014) - On asymptotically optimal confidence regions and tests for high-dimensional.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory},
  number = {3}
}

@article{vandenberg2008Probing,
  title = {Probing the {{Pareto Frontier}} for {{Basis Pursuit Solutions}}},
  author = {{van den Berg}, Ewout and Friedlander, Michael P.},
  year = {2008},
  month = nov,
  volume = {31},
  pages = {890--912},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/080714488},
  abstract = {The basis pursuit problem seeks a minimum one-norm solution of an underdetermined least-squares problem. Basis pursuit denoise (BPDN) fits the least-squares problem only approximately, and a single parameter determines a curve that traces the optimal trade-off between the least-squares fit and the one-norm of the solution. We prove that this curve is convex and continuously differentiable over all points of interest, and show that it gives an explicit relationship to two other optimization problems closely related to BPDN. We describe a root-finding algorithm for finding arbitrary points on this curve; the algorithm is suitable for problems that are large scale and for those that are in the complex domain. At each iteration, a spectral gradient-projection method approximately minimizes a least-squares problem with an explicit one-norm constraint. Only matrix-vector operations are required. The primal-dual solution of this problem gives function and derivative information needed for the root-finding method. Numerical experiments on a comprehensive set of test problems demonstrate that the method scales well to large problems.},
  file = {/Users/yuekai/Documents/zotero/van den Berg, Friedlander (2008) - Probing the Pareto Frontier for Basis Pursuit Solutions.pdf;/Users/yuekai/Zotero/storage/74WWZU6J/080714488.html},
  journal = {SIAM Journal on Scientific Computing},
  number = {2}
}

@article{vandermeulen2016Operator,
  title = {An {{Operator Theoretic Approach}} to {{Nonparametric Mixture Models}}},
  author = {Vandermeulen, Robert A. and Scott, Clayton D.},
  year = {2016},
  month = jun,
  abstract = {When estimating finite mixture models, it is common to make assumptions on
the mixture components, such as parametric assumptions. In this work, we make
no distributional assumptions on the mixture components and instead assume that
observations from the mixture model are grouped, such that observations in the
same group are known to be drawn from the same mixture component. We precisely
characterize the number of observations \$n\$ per group needed for the mixture
model to be identifiable, as a function of the number \$m\$ of mixture
components. In addition to our assumption-free analysis, we also study the
settings where the mixture components are either linearly independent or
jointly irreducible. Furthermore, our analysis considers two kinds of
identifiability -- where the mixture model is the simplest one explaining the
data, and where it is the only one. As an application of these results, we
precisely characterize identifiability of multinomial mixture models. Our
analysis relies on an operator-theoretic framework that associates mixture
models in the grouped-sample setting with certain infinite-dimensional tensors.
Based on this framework, we introduce general spectral algorithms for
recovering the mixture components and illustrate their use on a synthetic data
set.},
  file = {/Users/yuekai/Documents/zotero/Vandermeulen, Scott (2016) - An Operator Theoretic Approach to Nonparametric Mixture Models.pdf},
  language = {en}
}

@book{vandervaart1998Asymptotic,
  title = {Asymptotic {{Statistics}}},
  author = {{van der Vaart}, Aad W.},
  year = {1998},
  month = oct,
  publisher = {{Cambridge University Press}},
  doi = {10.1017/CBO9780511802256},
  language = {en}
}

@article{vandervaart2014Higher,
  title = {Higher {{Order Tangent Spaces}} and {{Influence Functions}}},
  author = {{van der Vaart}, Aad},
  year = {2014},
  month = nov,
  volume = {29},
  pages = {679--686},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/14-STS478},
  abstract = {We review higher order tangent spaces and influence functions and their use to construct minimax efficient estimators for parameters in high-dimensional semiparametric models.},
  file = {/Users/yuekai/Documents/zotero/van der Vaart (2014) - Higher Order Tangent Spaces and Influence Functions.pdf},
  journal = {Statistical Science},
  keywords = {minimax rate of convergence,Semiparametric model,U-statistic},
  language = {EN},
  mrnumber = {MR3300365},
  number = {4},
  zmnumber = {1331.62111}
}

@article{vanderweele2014Causal,
  title = {On the {{Causal Interpretation}} of {{Race}} in {{Regressions Adjusting}} for {{Confounding}} and {{Mediating Variables}}},
  author = {VanderWeele, Tyler J. and Robinson, Whitney R.},
  year = {2014},
  month = jul,
  volume = {25},
  pages = {473},
  issn = {1044-3983},
  doi = {10.1097/EDE.0000000000000105},
  abstract = {We consider several possible interpretations of the ``effect of race'' when regressions are run with race as an exposure variable, controlling also for various confounding and mediating variables. When adjustment is made for socioeconomic status early in a person's life, we discuss under what contexts the regression coefficients for race can be interpreted as corresponding to the extent to which a racial inequality would remain if various socioeconomic distributions early in life across racial groups could be equalized. When adjustment is also made for adult socioeconomic status, we note how the overall racial inequality can be decomposed into the portion that would be eliminated by equalizing adult socioeconomic status across racial groups and the portion of the inequality that would remain even if adult socioeconomic status across racial groups were equalized. We also discuss a stronger interpretation of the effect of race (stronger in terms of assumptions) involving the joint effects of race-associated physical phenotype (eg, skin color), parental physical phenotype, genetic background, and cultural context when such variables are thought to be hypothetically manipulable and if adequate control for confounding were possible. We discuss some of the challenges with such an interpretation. Further discussion is given as to how the use of selected populations in examining racial disparities can additionally complicate the interpretation of the effects.},
  file = {/Users/yuekai/Documents/zotero/VanderWeele, Robinson (2014) - On the Causal Interpretation of Race in Regressions Adjusting for Confounding.pdf},
  journal = {Epidemiology},
  language = {en-US},
  number = {4}
}

@article{vandeven2019Three,
  title = {Three Scenarios for Continual Learning},
  author = {{van de Ven}, Gido M. and Tolias, Andreas S.},
  year = {2019},
  month = apr,
  abstract = {Standard artificial neural networks suffer from the well-known issue of catastrophic forgetting, making continual or lifelong learning difficult for machine learning. In recent years, numerous methods have been proposed for continual learning, but due to differences in evaluation protocols it is difficult to directly compare their performance. To enable more structured comparisons, we describe three continual learning scenarios based on whether at test time task identity is provided and--in case it is not--whether it must be inferred. Any sequence of well-defined tasks can be performed according to each scenario. Using the split and permuted MNIST task protocols, for each scenario we carry out an extensive comparison of recently proposed continual learning methods. We demonstrate substantial differences between the three scenarios in terms of difficulty and in terms of how efficient different methods are. In particular, when task identity must be inferred (i.e., class incremental learning), we find that regularization-based approaches (e.g., elastic weight consolidation) fail and that replaying representations of previous experiences seems required for solving this scenario.},
  archivePrefix = {arXiv},
  eprint = {1904.07734},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/van de Ven, Tolias (2019) - Three scenarios for continual learning.pdf},
  journal = {arXiv:1904.07734 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@techreport{vanhandel2016Probability,
  title = {Probability in {{High Dimension}}:},
  shorttitle = {Probability in {{High Dimension}}},
  author = {{van Handel}, Ramon},
  year = {2016},
  month = dec,
  address = {{Princeton, NJ}},
  institution = {{Princeton University}},
  doi = {10.21236/ADA623999},
  file = {/Users/yuekai/Documents/zotero/van Handel (2016) - Probability in High Dimension.pdf},
  language = {en}
}

@article{vanwieringen2020Lecture,
  title = {Lecture Notes on Ridge Regression},
  author = {{van Wieringen}, Wessel N.},
  year = {2020},
  month = aug,
  abstract = {The linear regression model cannot be fitted to high-dimensional data, as the high-dimensionality brings about empirical non-identifiability. Penalized regression overcomes this non-identifiability by augmentation of the loss function by a penalty (i.e. a function of regression coefficients). The ridge penalty is the sum of squared regression coefficients, giving rise to ridge regression. Here many aspect of ridge regression are reviewed e.g. moments, mean squared error, its equivalence to constrained estimation, and its relation to Bayesian regression. Finally, its behaviour and use are illustrated in simulation and on omics data. Subsequently, ridge regression is generalized to allow for a more general penalty. The ridge penalization framework is then translated to logistic regression and its properties are shown to carry over. To contrast ridge penalized estimation, the final chapter introduces its lasso counterpart.},
  archivePrefix = {arXiv},
  eprint = {1509.09169},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/van Wieringen (2020) - Lecture notes on ridge regression.pdf;/Users/yuekai/Zotero/storage/TL26NYZS/1509.html},
  journal = {arXiv:1509.09169 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{varma1994Stoichiometric,
  title = {Stoichiometric Flux Balance Models Quantitatively Predict Growth and Metabolic By-Product Secretion in Wild-Type {{Escherichia}} Coli {{W3110}}.},
  author = {Varma, A and Palsson, B O},
  year = {1994},
  month = oct,
  volume = {60},
  pages = {3724--3731},
  issn = {0099-2240},
  abstract = {Flux balance models of metabolism use stoichiometry of metabolic pathways, metabolic demands of growth, and optimality principles to predict metabolic flux distribution and cellular growth under specified environmental conditions. These models have provided a mechanistic interpretation of systemic metabolic physiology, and they are also useful as a quantitative tool for metabolic pathway design. Quantitative predictions of cell growth and metabolic by-product secretion that are experimentally testable can be obtained from these models. In the present report, we used independent measurements to determine the model parameters for the wild-type Escherichia coli strain W3110. We experimentally determined the maximum oxygen utilization rate (15 mmol of O2 per g [dry weight] per h), the maximum aerobic glucose utilization rate (10.5 mmol of Glc per g [dry weight] per h), the maximum anaerobic glucose utilization rate (18.5 mmol of Glc per g [dry weight] per h), the non-growth-associated maintenance requirements (7.6 mmol of ATP per g [dry weight] per h), and the growth-associated maintenance requirements (13 mmol of ATP per g of biomass). The flux balance model specified by these parameters was found to quantitatively predict glucose and oxygen uptake rates as well as acetate secretion rates observed in chemostat experiments. We have formulated a predictive algorithm in order to apply the flux balance model to describe unsteady-state growth and by-product secretion in aerobic batch, fed-batch, and anaerobic batch cultures. In aerobic experiments we observed acetate secretion, accumulation in the culture medium, and reutilization from the culture medium. In fed-batch cultures acetate is cometabolized with glucose during the later part of the culture period.(ABSTRACT TRUNCATED AT 250 WORDS)},
  file = {/Users/yuekai/Documents/zotero/Varma, Palsson (1994) - Stoichiometric flux balance models quantitatively predict growth and metabolic.pdf},
  journal = {Applied and Environmental Microbiology},
  number = {10},
  pmcid = {PMC201879},
  pmid = {7986045}
}

@article{vaswani2019Painless,
  title = {Painless {{Stochastic Gradient}}: {{Interpolation}}, {{Line}}-{{Search}}, and {{Convergence Rates}}},
  shorttitle = {Painless {{Stochastic Gradient}}},
  author = {Vaswani, Sharan and Mishkin, Aaron and Laradji, Issam and Schmidt, Mark and Gidel, Gauthier and {Lacoste-Julien}, Simon},
  year = {2019},
  month = may,
  abstract = {Recent works have shown that stochastic gradient descent (SGD) achieves the fast convergence rates of full-batch gradient descent for over-parameterized models satisfying certain interpolation conditions. However, the step-size used in these works depends on unknown quantities, and SGD's practical performance heavily relies on the choice of the step-size. We propose to use line-search methods to automatically set the step-size when training models that can interpolate the data. We prove that SGD with the classic Armijo line-search attains the fast convergence rates of full-batch gradient descent in convex and strongly-convex settings. We also show that under additional assumptions, SGD with a modified line-search can attain a fast rate of convergence for non-convex functions. Furthermore, we show that a stochastic extra-gradient method with a Lipschitz line-search attains a fast convergence rate for an important class of non-convex functions and saddle-point problems satisfying interpolation. We then give heuristics to use larger step-sizes and acceleration with our line-search techniques. We compare the proposed algorithms against numerous optimization methods for standard classification tasks using both kernel methods and deep networks. The proposed methods are robust and result in competitive performance across all models and datasets. Moreover, for the deep network models, SGD with our line-search results in both faster convergence and better generalization.},
  archivePrefix = {arXiv},
  eprint = {1905.09997},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Vaswani et al (2019) - Painless Stochastic Gradient.pdf},
  journal = {arXiv:1905.09997 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{vaughan2018Making,
  title = {Making {{Better Use}} of the {{Crowd}}: {{How Crowdsourcing Can Advance Machine Learning Research}}},
  shorttitle = {Making {{Better Use}} of the {{Crowd}}},
  author = {Vaughan, Jennifer Wortman},
  year = {2018},
  volume = {18},
  pages = {1--46},
  issn = {1533-7928},
  file = {/Users/yuekai/Documents/zotero/Vaughan (2018) - Making Better Use of the Crowd.pdf},
  journal = {Journal of Machine Learning Research},
  number = {193}
}

@inproceedings{veale2018Fairness,
  title = {Fairness and {{Accountability Design Needs}} for {{Algorithmic Support}} in {{High}}-{{Stakes Public Sector Decision}}-{{Making}}},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Veale, Michael and Van Kleek, Max and Binns, Reuben},
  year = {2018},
  month = apr,
  pages = {1--14},
  publisher = {{Association for Computing Machinery}},
  address = {{Montreal QC, Canada}},
  doi = {10.1145/3173574.3174014},
  abstract = {Calls for heightened consideration of fairness and accountability in algorithmically-informed public decisions-like taxation, justice, and child protection-are now commonplace. How might designers support such human values? We interviewed 27 public sector machine learning practitioners across 5 OECD countries regarding challenges understanding and imbuing public values into their work. The results suggest a disconnect between organisational and institutional realities, constraints and needs, and those addressed by current research into usable, transparent and 'discrimination-aware' machine learning-absences likely to undermine practical initiatives unless addressed. We see design opportunities in this disconnect, such as in supporting the tracking of concept drift in secondary data sources, and in building usable transparency tools to identify risks and incorporate domain knowledge, aimed both at managers and at the 'street-level bureaucrats' on the frontlines of public service. We conclude by outlining ethical challenges and future directions for collaboration in these high-stakes applications.},
  file = {/Users/yuekai/Documents/zotero/Veale et al (2018) - Fairness and Accountability Design Needs for Algorithmic Support in High-Stakes.pdf},
  isbn = {978-1-4503-5620-6},
  keywords = {algorithmic accountability,algorithmic bias,decision-support,predictive policing,public administration},
  series = {{{CHI}} '18}
}

@article{veitch2016Sampling,
  title = {Sampling and {{Estimation}} for ({{Sparse}}) {{Exchangeable Graphs}}},
  author = {Veitch, Victor and Roy, Daniel M.},
  year = {2016},
  month = nov,
  abstract = {Sparse exchangeable graphs on R+, and the associated graphex framework for sparse graphs, generalize exchangeable graphs on N, and the associated graphon framework for dense graphs. We develop the graphex framework as a tool for statistical network analysis by identifying the sampling scheme that is naturally associated with the models of the framework, and by introducing a general consistent estimator for the parameter (the graphex) underlying these models. The sampling scheme is a modification of independent vertex sampling that throws away vertices that are isolated in the sampled subgraph. The estimator is a dilation of the empirical graphon estimator, which is known to be a consistent estimator for dense exchangeable graphs; both can be understood as graph analogues to the empirical distribution in the i.i.d. sequence setting. Our results may be viewed as a generalization of consistent estimation via the empirical graphon from the dense graph regime to also include sparse graphs.},
  archivePrefix = {arXiv},
  eprint = {1611.00843},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Veitch, Roy (2016) - Sampling and Estimation for (Sparse) Exchangeable Graphs.pdf},
  journal = {arXiv:1611.00843 [cs, math, stat]},
  keywords = {Computer Science - Social and Information Networks,Mathematics - Combinatorics,Mathematics - Statistics Theory},
  language = {en},
  primaryClass = {cs, math, stat}
}

@article{vershynin2011Introduction,
  title = {Introduction to the Non-Asymptotic Analysis of Random Matrices},
  author = {Vershynin, Roman},
  year = {2011},
  month = nov,
  abstract = {This is a tutorial on some basic non-asymptotic methods and concepts in random matrix theory. The reader will learn several tools for the analysis of the extreme singular values of random matrices with independent rows or columns. Many of these methods sprung off from the development of geometric functional analysis since the 1970's. They have applications in several fields, most notably in theoretical computer science, statistics and signal processing. A few basic applications are covered in this text, particularly for the problem of estimating covariance matrices in statistics and for validating probabilistic constructions of measurement matrices in compressed sensing. These notes are written particularly for graduate students and beginning researchers in different areas, including functional analysts, probabilists, theoretical statisticians, electrical engineers, and theoretical computer scientists.},
  archivePrefix = {arXiv},
  eprint = {1011.3027},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Vershynin (2011) - Introduction to the non-asymptotic analysis of random matrices.pdf},
  journal = {arXiv:1011.3027 [cs, math]},
  keywords = {Mathematics - Functional Analysis,Mathematics - Numerical Analysis,Mathematics - Probability},
  primaryClass = {cs, math}
}

@book{vershynin2018HighDimensional,
  title = {High-{{Dimensional Probability}}},
  author = {Vershynin, Roman},
  year = {2018},
  month = sep,
  publisher = {{Cambridge University Press}},
  file = {/Users/yuekai/Documents/zotero/Vershynin (2018) - High-Dimensional Probability.pdf},
  language = {en}
}

@article{vigdor2019Apple,
  title = {Apple {{Card Investigated After Gender Discrimination Complaints}}},
  author = {Vigdor, Neil},
  year = {2019},
  month = nov,
  issn = {0362-4331},
  abstract = {A prominent software developer said on Twitter that the credit card was ``sexist'' against women applying for credit.},
  chapter = {Business},
  journal = {The New York Times},
  language = {en-US}
}

@book{villani2009Optimal,
  title = {Optimal Transport: Old and New},
  shorttitle = {Optimal Transport},
  author = {Villani, C{\'e}dric},
  year = {2009},
  publisher = {{Springer}},
  address = {{Berlin}},
  annotation = {OCLC: ocn244421231},
  file = {/Users/yuekai/Documents/zotero/Villani (2009) - Optimal transport.pdf},
  isbn = {978-3-540-71049-3},
  language = {en},
  lccn = {QA402.5 .V538 2009},
  number = {338},
  series = {Grundlehren Der Mathematischen {{Wissenschaften}}}
}

@article{vinyals2016Matching,
  title = {Matching {{Networks}} for {{One Shot Learning}}},
  author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Kavukcuoglu, Koray and Wierstra, Daan},
  year = {2016},
  month = jun,
  abstract = {Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6\% to 93.2\% and from 88.0\% to 93.8\% on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank.},
  archivePrefix = {arXiv},
  eprint = {1606.04080},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Vinyals et al (2016) - Matching Networks for One Shot Learning.pdf},
  journal = {arXiv:1606.04080 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{vonluxburg2008Consistency,
  title = {Consistency of Spectral Clustering},
  author = {{von Luxburg}, Ulrike and Belkin, Mikhail and Bousquet, Olivier},
  year = {2008},
  month = apr,
  volume = {36},
  pages = {555--586},
  issn = {0090-5364},
  doi = {10.1214/009053607000000640},
  abstract = {Consistency is a key property of all statistical procedures analyzing randomly sampled data. Surprisingly, despite decades of work, little is known about consistency of most clustering algorithms. In this paper we investigate consistency of the popular family of spectral clustering algorithms, which clusters the data with the help of eigenvectors of graph Laplacian matrices. We develop new methods to establish that, for increasing sample size, those eigenvectors converge to the eigenvectors of certain limit operators. As a result, we can prove that one of the two major classes of spectral clustering (normalized clustering) converges under very general conditions, while the other (unnormalized clustering) is only consistent under strong additional assumptions, which are not always satisfied in real data. We conclude that our analysis provides strong evidence for the superiority of normalized spectral clustering.},
  archivePrefix = {arXiv},
  eprint = {0804.0678},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/von Luxburg et al (2008) - Consistency of spectral clustering.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory},
  number = {2}
}

@article{wachter2018Counterfactual,
  title = {Counterfactual {{Explanations}} without {{Opening}} the {{Black Box}}: {{Automated Decisions}} and the {{GDPR}}},
  shorttitle = {Counterfactual {{Explanations}} without {{Opening}} the {{Black Box}}},
  author = {Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
  year = {2018},
  month = mar,
  abstract = {There has been much discussion of the right to explanation in the EU General Data Protection Regulation, and its existence, merits, and disadvantages. Implementing a right to explanation that opens the black box of algorithmic decision-making faces major legal and technical barriers. Explaining the functionality of complex algorithmic decision-making systems and their rationale in specific cases is a technically challenging problem. Some explanations may offer little meaningful information to data subjects, raising questions around their value. Explanations of automated decisions need not hinge on the general public understanding how algorithmic systems function. Even though such interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the black box. Looking at explanations as a means to help a data subject act rather than merely understand, one could gauge the scope and content of explanations according to the specific goal or action they are intended to support. From the perspective of individuals affected by automated decision-making, we propose three aims for explanations: (1) to inform and help the individual understand why a particular decision was reached, (2) to provide grounds to contest the decision if the outcome is undesired, and (3) to understand what would need to change in order to receive a desired result in the future, based on the current decision-making model. We assess how each of these goals finds support in the GDPR. We suggest data controllers should offer a particular type of explanation, unconditional counterfactual explanations, to support these three aims. These counterfactual explanations describe the smallest change to the world that can be made to obtain a desirable outcome, or to arrive at the closest possible world, without needing to explain the internal logic of the system.},
  archivePrefix = {arXiv},
  eprint = {1711.00399},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wachter et al (2018) - Counterfactual Explanations without Opening the Black Box.pdf},
  journal = {arXiv:1711.00399 [cs]},
  keywords = {Computer Science - Artificial Intelligence},
  primaryClass = {cs}
}

@article{wager2014Asymptotic,
  title = {Asymptotic {{Theory}} for {{Random Forests}}},
  author = {Wager, Stefan},
  year = {2014},
  month = may,
  abstract = {Random forests have proven to be reliable predictive algorithms in many application areas. Not much is known, however, about the statistical properties of random forests. Several authors have established conditions under which their predictions are consistent, but these results do not provide practical estimates of random forest errors. In this paper, we analyze a random forest model based on subsampling, and show that random forest predictions are asymptotically normal provided that the subsample size s scales as s(n)/n = o(log(n)\^\{-d\}), where n is the number of training examples and d is the number of features. Moreover, we show that the asymptotic variance can consistently be estimated using an infinitesimal jackknife for bagged ensembles recently proposed by Efron (2014). In other words, our results let us both characterize and estimate the error-distribution of random forest predictions, thus taking a step towards making random forests tools for statistical inference instead of just black-box predictive algorithms.},
  archivePrefix = {arXiv},
  eprint = {1405.0352},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wager (2014) - Asymptotic Theory for Random Forests.pdf},
  journal = {arXiv:1405.0352 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {math, stat}
}

@article{wager2015Estimation,
  title = {Estimation and {{Inference}} of {{Heterogeneous Treatment Effects}} Using {{Random Forests}}},
  author = {Wager, Stefan and Athey, Susan},
  year = {2015},
  month = oct,
  abstract = {Many scientific and engineering challenges -- ranging from personalized medicine to customized marketing recommendations -- require an understanding of treatment effect heterogeneity. In this paper, we develop a non-parametric causal forest for estimating heterogeneous treatment effects that extends Breiman's widely used random forest algorithm. In the potential outcomes framework with unconfoundedness, we show that causal forests are pointwise consistent for the true treatment effect, and have an asymptotically Gaussian and centered sampling distribution. We also discuss a practical method for constructing asymptotic confidence intervals for the true treatment effect that are centered at the causal forest estimates. Our theoretical results rely on a generic Gaussian theory for a large family of random forest algorithms. To our knowledge, this is the first set of results that allows any type of random forest, including classification and regression forests, to be used for provably valid statistical inference. In experiments, we find causal forests to be substantially more powerful than classical methods based on nearest-neighbor matching, especially in the presence of irrelevant covariates.},
  archivePrefix = {arXiv},
  eprint = {1510.04342},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wager, Athey (2015) - Estimation and Inference of Heterogeneous Treatment Effects using Random Forests.pdf},
  journal = {arXiv:1510.04342 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {math, stat}
}

@inproceedings{wagstaff2001Constrained,
  title = {Constrained {{K}}-Means {{Clustering}} with {{Background Knowledge}}},
  booktitle = {Proceedings of the {{Eighteenth International Conference}} on {{Machine Learning}}},
  author = {Wagstaff, Kiri and Cardie, Claire and Rogers, Seth and Schr{\"o}dl, Stefan},
  year = {2001},
  month = jun,
  pages = {577--584},
  publisher = {{Morgan Kaufmann Publishers Inc.}},
  address = {{San Francisco, CA, USA}},
  isbn = {978-1-55860-778-1},
  series = {{{ICML}} '01}
}

@book{wainwright2019HighDimensional,
  title = {High-{{Dimensional Statistics}}: {{A Non}}-{{Asymptotic Viewpoint}}},
  shorttitle = {High-{{Dimensional Statistics}}},
  author = {Wainwright, Martin J.},
  year = {2019},
  month = feb,
  edition = {First},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/9781108627771},
  file = {/Users/yuekai/Documents/zotero/Wainwright (2019) - High-Dimensional Statistics.pdf},
  isbn = {978-1-108-62777-1 978-1-108-49802-9},
  language = {en}
}

@article{wainwright2019Stochastic,
  title = {Stochastic Approximation with Cone-Contractive Operators: {{Sharp}} \$\textbackslash ell\_\textbackslash infty\$-Bounds for \${{Q}}\$-Learning},
  shorttitle = {Stochastic Approximation with Cone-Contractive Operators},
  author = {Wainwright, Martin J.},
  year = {2019},
  month = may,
  abstract = {Motivated by the study of \$Q\$-learning algorithms in reinforcement learning, we study a class of stochastic approximation procedures based on operators that satisfy monotonicity and quasi-contractivity conditions with respect to an underlying cone. We prove a general sandwich relation on the iterate error at each time, and use it to derive non-asymptotic bounds on the error in terms of a cone-induced gauge norm. These results are derived within a deterministic framework, requiring no assumptions on the noise. We illustrate these general bounds in application to synchronous \$Q\$-learning for discounted Markov decision processes with discrete state-action spaces, in particular by deriving non-asymptotic bounds on the \$\textbackslash ell\_\textbackslash infty\$-norm for a range of stepsizes. These results are the sharpest known to date, and we show via simulation that the dependence of our bounds cannot be improved in a worst-case sense. These results show that relative to a model-based \$Q\$-iteration, the \$\textbackslash ell\_\textbackslash infty\$-based sample complexity of \$Q\$-learning is suboptimal in terms of the discount factor \$\textbackslash gamma\$.},
  archivePrefix = {arXiv},
  eprint = {1905.06265},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wainwright (2019) - Stochastic approximation with cone-contractive operators.pdf},
  journal = {arXiv:1905.06265 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@incollection{wang2012Supervised,
  title = {Supervised {{Earth Mover}}'s {{Distance Learning}} and {{Its Computer Vision Applications}}},
  booktitle = {Computer {{Vision}} \textendash{} {{ECCV}} 2012},
  author = {Wang, Fan and Guibas, Leonidas J.},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Fitzgibbon, Andrew and Lazebnik, Svetlana and Perona, Pietro and Sato, Yoichi and Schmid, Cordelia},
  year = {2012},
  volume = {7572},
  pages = {442--455},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-33718-5_32},
  abstract = {The Earth Mover's Distance (EMD) is an intuitive and natural distance metric for comparing two histograms or probability distributions. It provides a distance value as well as a flow-network indicating how the probability mass is optimally transported between the bins. In traditional EMD, the ground distance between the bins is pre-defined. Instead, we propose to jointly optimize the ground distance matrix and the EMD flow-network based on a partial ordering of histogram distances in an optimization framework. Our method is further extended to accept information from general labeled pairs. The trained ground distance better reflects the cross-bin relationships, hence produces more accurate EMD values and flow-networks. Two computer vision applications are used to demonstrate the effectiveness of the algorithm: first, we apply the optimized EMD value to face verification, and achieve state-of-theart performance on the PubFig and the LFW data sets; second, the learned EMD flow-network is used to analyze face attribute changes, obtaining consistent paths that demonstrate intuitive transitions on certain facial attributes.},
  file = {/Users/yuekai/Documents/zotero/Wang, Guibas (2012) - Supervised Earth Mover’s Distance Learning and Its Computer Vision Applications.pdf},
  isbn = {978-3-642-33717-8 978-3-642-33718-5},
  language = {en}
}

@article{wang2014Falling,
  title = {The {{Falling Factorial Basis}} and {{Its Statistical Applications}}},
  author = {Wang, Yu-Xiang and Smola, Alex and Tibshirani, Ryan J.},
  year = {2014},
  month = may,
  abstract = {We study a novel spline-like basis, which we name the "falling factorial basis", bearing many similarities to the classic truncated power basis. The advantage of the falling factorial basis is that it enables rapid, linear-time computations in basis matrix multiplication and basis matrix inversion. The falling factorial functions are not actually splines, but are close enough to splines that they provably retain some of the favorable properties of the latter functions. We examine their application in two problems: trend filtering over arbitrary input points, and a higher-order variant of the two-sample Kolmogorov-Smirnov test.},
  archivePrefix = {arXiv},
  eprint = {1405.0558},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wang et al (2014) - The Falling Factorial Basis and Its Statistical Applications.pdf},
  journal = {arXiv:1405.0558 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{wang2015Confounder,
  title = {Confounder {{Adjustment}} in {{Multiple Hypothesis Testing}}},
  author = {Wang, Jingshu and Zhao, Qingyuan and Hastie, Trevor and Owen, Art B.},
  year = {2015},
  month = aug,
  abstract = {We consider large-scale studies in which thousands of significance tests are performed simultaneously. In some of these studies, the multiple testing procedure can be severely biased by latent confounding factors such as batch effects and unmeasured covariates that correlate with both primary variable(s) of interest (e.g. treatment variable, phenotype) and the outcome. Over the past decade, many statistical methods have been proposed to adjust for the confounders in hypothesis testing. We unify these methods in the same framework, generalize them to include multiple primary variables and multiple nuisance variables, and analyze their statistical properties. In particular, we provide theoretical guarantees for RUV-4 and LEAPP, which correspond to two different identification conditions in the framework: the first requires a set of "negative controls" that are known a priori to follow the null distribution; the second requires the true non-nulls to be sparse. Two different estimators which are based on RUV-4 and LEAPP are then applied to these two scenarios. We show that if the confounding factors are strong, the resulting estimators can be asymptotically as powerful as the oracle estimator which observes the latent confounding factors. For hypothesis testing, we show the asymptotic z-tests based on the estimators can control the type I error. Numerical experiments show that the false discovery rate is also controlled by the Benjamini-Hochberg procedure when the sample size is reasonably large.},
  archivePrefix = {arXiv},
  eprint = {1508.04178},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wang et al (2015) - Confounder Adjustment in Multiple Hypothesis Testing.pdf},
  journal = {arXiv:1508.04178 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{wang2015Sharp,
  title = {Sharp {{Computational}}-{{Statistical Phase Transitions}} via {{Oracle Computational Model}}},
  author = {Wang, Zhaoran and Gu, Quanquan and Liu, Han},
  year = {2015},
  month = dec,
  abstract = {We study the fundamental tradeoffs between computational tractability and statistical accuracy for a general family of hypothesis testing problems with combinatorial structures. Based upon an oracle model of computation, which captures the interactions between algorithms and data, we establish a general lower bound that explicitly connects the minimum testing risk under computational budget constraints with the intrinsic probabilistic and combinatorial structures of statistical problems. This lower bound mirrors the classical statistical lower bound by Le Cam (1986) and allows us to quantify the optimal statistical performance achievable given limited computational budgets in a systematic fashion. Under this unified framework, we sharply characterize the statistical-computational phase transition for two testing problems, namely, normal mean detection and sparse principal component detection. For normal mean detection, we consider two combinatorial structures, namely, sparse set and perfect matching. For these problems we identify significant gaps between the optimal statistical accuracy that is achievable under computational tractability constraints and the classical statistical lower bounds. Compared with existing works on computational lower bounds for statistical problems, which consider general polynomial-time algorithms on Turing machines, and rely on computational hardness hypotheses on problems like planted clique detection, we focus on the oracle computational model, which covers a broad range of popular algorithms, and do not rely on unproven hypotheses. Moreover, our result provides an intuitive and concrete interpretation for the intrinsic computational intractability of high-dimensional statistical problems. One byproduct of our result is a lower bound for a strict generalization of the matrix permanent problem, which is of independent interest.},
  archivePrefix = {arXiv},
  eprint = {1512.08861},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wang et al (2015) - Sharp Computational-Statistical Phase Transitions via Oracle Computational Model.pdf},
  journal = {arXiv:1512.08861 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@phdthesis{wang2016Factor,
  title = {Factor {{Analysis}} for {{High}}-Dimensional Data},
  author = {Wang, Jingshu},
  year = {2016},
  month = jul,
  file = {/Users/yuekai/Documents/zotero/Wang (2016) - FACTOR ANALYSIS FOR HIGH-DIMENSIONAL DATA.pdf},
  language = {en},
  school = {Stanford University}
}

@article{wang2016optimal,
  title = {An Optimal Learning Method for Developing Personalized Treatment Regimes},
  author = {Wang, Yingfei and Powell, Warren},
  year = {2016},
  month = jul,
  abstract = {A treatment regime is a function that maps individual patient information to a recommended treatment, hence explicitly incorporating the heterogeneity in need for treatment across individuals. Patient responses are dichotomous and can be predicted through an unknown relationship that depends on the patient information and the selected treatment. The goal is to find the treatments that lead to the best patient responses on average. Each experiment is expensive, forcing us to learn the most from each experiment. We adopt a Bayesian approach both to incorporate possible prior information and to update our treatment regime continuously as information accrues, with the potential to allow smaller yet more informative trials and for patients to receive better treatment. By formulating the problem as contextual bandits, we introduce a knowledge gradient policy to guide the treatment assignment by maximizing the expected value of information, for which an approximation method is used to overcome computational challenges. We provide a detailed study on how to make sequential medical decisions under uncertainty to reduce health care costs on a real world knee replacement dataset. We use clustering and LASSO to deal with the intrinsic sparsity in health datasets. We show experimentally that even though the problem is sparse, through careful selection of physicians (versus picking them at random), we can significantly improve the success rates.},
  archivePrefix = {arXiv},
  eprint = {1607.01462},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wang, Powell (2016) - An optimal learning method for developing personalized treatment regimes.pdf},
  journal = {arXiv:1607.01462 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{wang2017Comparison,
  title = {A {{Comparison Study}} of {{Machine Learning Based Algorithms}} for {{Fatigue Crack Growth Calculation}}},
  author = {Wang, Hongxun and Zhang, Weifang and Sun, Fuqiang and Zhang, Wei},
  year = {2017},
  month = may,
  volume = {10},
  pages = {543},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/ma10050543},
  abstract = {The relationships between the fatigue crack growth rate      (  d a / d N  )       and stress intensity factor range      (  {$\Delta$} K  )      are not always linear even in the Paris region. The stress ratio effects on fatigue crack growth rate are diverse in different materials. However, most existing fatigue crack growth models cannot handle these nonlinearities appropriately. The machine learning method provides a flexible approach to the modeling of fatigue crack growth because of its excellent nonlinear approximation and multivariable learning ability. In this paper, a fatigue crack growth calculation method is proposed based on three different machine learning algorithms (MLAs): extreme learning machine (ELM), radial basis function network (RBFN) and genetic algorithms optimized back propagation network (GABP). The MLA based method is validated using testing data of different materials. The three MLAs are compared with each other as well as the classical two-parameter model (     K *      approach). The results show that the predictions of MLAs are superior to those of      K *      approach in accuracy and effectiveness, and the ELM based algorithms show overall the best agreement with the experimental data out of the three MLAs, for its global optimization and extrapolation ability.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {/Users/yuekai/Documents/zotero/Wang et al (2017) - A Comparison Study of Machine Learning Based Algorithms for Fatigue Crack.pdf},
  journal = {Materials},
  language = {en},
  number = {5}
}

@article{wang2017Fast,
  title = {Fast and {{Scalable Learning}} of {{Sparse Changes}} in {{High}}-{{Dimensional Gaussian Graphical Model Structure}}},
  author = {Wang, Beilun and Sekhon, Arshdeep and Qi, Yanjun},
  year = {2017},
  month = oct,
  abstract = {We focus on the problem of estimating the change in the dependency structures of two p-dimensional Gaussian Graphical models (GGMs). Previous studies for sparse change estimation in GGMs involve expensive and difficult non-smooth optimization. We propose a novel method, DIFFEE for estimating DIFFerential networks via an Elementary Estimator under a high-dimensional situation. DIFFEE is solved through a faster and closed form solution that enables it to work in large-scale settings. We conduct a rigorous statistical analysis showing that surprisingly DIFFEE achieves the same asymptotic convergence rates as the state-of-the-art estimators that are much more difficult to compute. Our experimental results on multiple synthetic datasets and one real-world data about brain connectivity show strong performance improvements over baselines, as well as significant computational benefits.},
  archivePrefix = {arXiv},
  eprint = {1710.11223},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wang et al (2017) - Fast and Scalable Learning of Sparse Changes in High-Dimensional Gaussian.pdf},
  journal = {arXiv:1710.11223 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, stat}
}

@article{wang2017Stochastic,
  title = {Stochastic {{Zeroth}}-Order {{Optimization}} in {{High Dimensions}}},
  author = {Wang, Yining and Du, Simon and Balakrishnan, Sivaraman and Singh, Aarti},
  year = {2017},
  month = oct,
  abstract = {We consider the problem of optimizing a high-dimensional convex function using stochastic zeroth-order queries. Under sparsity assumptions on the gradients or function values, we present two algorithms: a successive component/feature selection algorithm and a noisy mirror descent algorithm using Lasso gradient estimates, and show that both algorithms have convergence rates that de- pend only logarithmically on the ambient dimension of the problem. Empirical results confirm our theoretical findings and show that the algorithms we design outperform classical zeroth-order optimization methods in the high-dimensional setting.},
  archivePrefix = {arXiv},
  eprint = {1710.10551},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wang et al (2017) - Stochastic Zeroth-order Optimization in High Dimensions.pdf},
  journal = {arXiv:1710.10551 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{wang2018Blessings,
  title = {The {{Blessings}} of {{Multiple Causes}}},
  author = {Wang, Yixin and Blei, David M.},
  year = {2018},
  month = may,
  abstract = {Causal inference from observational data often assumes "ignorability," that all confounders are observed. This assumption is standard yet untestable. However, many scientific studies involve multiple causes, different variables whose effects are simultaneously of interest. We propose the deconfounder, an algorithm that combines unsupervised machine learning and predictive model checking to perform causal inference in multiple-cause settings. The deconfounder infers a latent variable as a substitute for unobserved confounders and then uses that substitute to perform causal inference. We develop theory for the deconfounder, and show that it requires weaker assumptions than classical causal inference. We analyze its performance in three types of studies: semi-simulated data around smoking and lung cancer, semi-simulated data around genome-wide association studies, and a real dataset about actors and movie revenue. The deconfounder provides a checkable approach to estimating closer-to-truth causal effects.},
  archivePrefix = {arXiv},
  eprint = {1805.06826},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wang, Blei (2018) - The Blessings of Multiple Causes.pdf},
  journal = {arXiv:1805.06826 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {cs, stat}
}

@article{wang2018Fast,
  title = {A {{Fast}} and {{Scalable Joint Estimator}} for {{Integrating Additional Knowledge}} in {{Learning Multiple Related Sparse Gaussian Graphical Models}}},
  author = {Wang, Beilun and Sekhon, Arshdeep and Qi, Yanjun},
  year = {2018},
  month = jun,
  abstract = {We consider the problem of including additional knowledge in estimating sparse Gaussian graphical models (sGGMs) from aggregated samples, arising often in bioinformatics and neuroimaging applications. Previous joint sGGM estimators either fail to use existing knowledge or cannot scale-up to many tasks (large \$K\$) under a high-dimensional (large \$p\$) situation. In this paper, we propose a novel \textbackslash underline\{J\}oint \textbackslash underline\{E\}lementary \textbackslash underline\{E\}stimator incorporating additional \textbackslash underline\{K\}nowledge (JEEK) to infer multiple related sparse Gaussian Graphical models from large-scale heterogeneous data. Using domain knowledge as weights, we design a novel hybrid norm as the minimization objective to enforce the superposition of two weighted sparsity constraints, one on the shared interactions and the other on the task-specific structural patterns. This enables JEEK to elegantly consider various forms of existing knowledge based on the domain at hand and avoid the need to design knowledge-specific optimization. JEEK is solved through a fast and entry-wise parallelizable solution that largely improves the computational efficiency of the state-of-the-art \$O(p\^5K\^4)\$ to \$O(p\^2K\^4)\$. We conduct a rigorous statistical analysis showing that JEEK achieves the same convergence rate \$O(\textbackslash log(Kp)/n\_\{tot\})\$ as the state-of-the-art estimators that are much harder to compute. Empirically, on multiple synthetic datasets and two real-world data, JEEK outperforms the speed of the state-of-arts significantly while achieving the same level of prediction accuracy. Available as R tool "jeek"},
  archivePrefix = {arXiv},
  eprint = {1806.00548},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wang et al (2018) - A Fast and Scalable Joint Estimator for Integrating Additional Knowledge in.pdf},
  journal = {arXiv:1806.00548 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{wang2018Optimal,
  title = {Optimal {{Change Point Detection}} and {{Localization}} in {{Sparse Dynamic Networks}}},
  author = {Wang, Daren and Yu, Yi and Rinaldo, Alessandro},
  year = {2018},
  month = sep,
  abstract = {We study the problem of change point detection and localization in dynamic networks. We assume that we observe a sequence of independent adjacency matrices of given size, each corresponding to one realization from an unknown inhomogeneous Bernoulli model. The underlying distribution of the adjacency matrices may change over a subset of the time points, called change points. Our task is to recover with high accuracy the unknown number and positions of the change points. Our generic model setting allows for all the model parameters to change with the total number of time points, including the network size, the minimal spacing between consecutive change points, the magnitude of the smallest change and the degree of sparsity of the networks. We first identify an impossible region in the space of the model parameters such that no change point estimator is provably consistent if the data are generated according to parameters falling in that region. We propose a computationally simple novel algorithm for network change point localization, called Network Binary Segmentation, which relies on weighted averages of the adjacency matrices. We show that Network Binary Segmentation is consistent over a range of the model parameters that nearly cover the complement of the impossibility region, thus demonstrating the existence of a phase transition for the problem at hand. Next, we devise a more sophisticated algorithm based on singular value thresholding, called Local Refinement, that delivers more accurate estimates of the change point locations. We show that, under appropriate conditions, Local Refinement guarantees a minimax optimal rate for network change point localization while remaining computationally feasible.},
  archivePrefix = {arXiv},
  eprint = {1809.09602},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wang et al (2018) - Optimal Change Point Detection and Localization in Sparse Dynamic Networks.pdf},
  journal = {arXiv:1809.09602 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{wang2018Variational,
  title = {Variational {{Inference}} with {{Tail}}-Adaptive f-{{Divergence}}},
  author = {Wang, Dilin and Liu, Hao and Liu, Qiang},
  year = {2018},
  month = oct,
  abstract = {Variational inference with \{\textbackslash alpha\}-divergences has been widely used in modern probabilistic machine learning. Compared to Kullback-Leibler (KL) divergence, a major advantage of using \{\textbackslash alpha\}-divergences (with positive \{\textbackslash alpha\} values) is their mass-covering property. However, estimating and optimizing \{\textbackslash alpha\}-divergences require to use importance sampling, which could have extremely large or infinite variances due to heavy tails of importance weights. In this paper, we propose a new class of tail-adaptive f-divergences that adaptively change the convex function f with the tail of the importance weights, in a way that theoretically guarantees finite moments, while simultaneously achieving mass-covering properties. We test our methods on Bayesian neural networks, as well as deep reinforcement learning in which our method is applied to improve a recent soft actor-critic (SAC) algorithm. Our results show that our approach yields significant advantages compared with existing methods based on classical KL and \{\textbackslash alpha\}-divergences.},
  archivePrefix = {arXiv},
  eprint = {1810.11943},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wang et al (2018) - Variational Inference with Tail-adaptive f-Divergence.pdf},
  journal = {arXiv:1810.11943 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{wang2019Empirical,
  title = {An {{Empirical Study}} on {{Learning Fairness Metrics}} for {{COMPAS Data}} with {{Human Supervision}}},
  author = {Wang, Hanchen and {Grgic-Hlaca}, Nina and Lahoti, Preethi and Gummadi, Krishna P. and Weller, Adrian},
  year = {2019},
  month = oct,
  abstract = {The notion of individual fairness requires that similar people receive similar treatment. However, this is hard to achieve in practice since it is difficult to specify the appropriate similarity metric. In this work, we attempt to learn such similarity metric from human annotated data. We gather a new dataset of human judgments on a criminal recidivism prediction (COMPAS) task. By assuming the human supervision obeys the principle of individual fairness, we leverage prior work on metric learning, evaluate the performance of several metric learning methods on our dataset, and show that the learned metrics outperform the Euclidean and Precision metric under various criteria. We do not provide a way to directly learn a similarity metric satisfying the individual fairness, but to provide an empirical study on how to derive the similarity metric from human supervisors, then future work can use this as a tool to understand human supervision.},
  archivePrefix = {arXiv},
  eprint = {1910.10255},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wang et al (2019) - An Empirical Study on Learning Fairness Metrics for COMPAS Data with Human.pdf},
  journal = {arXiv:1910.10255 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@inproceedings{wang2019Federated,
  title = {Federated {{Learning}} with {{Matched Averaging}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Wang, Hongyi and Yurochkin, Mikhail and Sun, Yuekai and Papailiopoulos, Dimitris and Khazaeni, Yasaman},
  year = {2019},
  month = sep,
  abstract = {Federated learning allows edge devices to collaboratively learn a shared model while keeping the training data on device, decoupling the ability to do model training from the need to store the data...},
  file = {/Users/yuekai/Documents/zotero/Wang et al (2019) - Federated Learning with Matched Averaging.pdf}
}

@article{wang2019Multiple,
  title = {Multiple {{Causes}}: {{A Causal Graphical View}}},
  shorttitle = {Multiple {{Causes}}},
  author = {Wang, Yixin and Blei, David M.},
  year = {2019},
  month = may,
  abstract = {Unobserved confounding is a major hurdle for causal inference from observational data. Confounders---the variables that affect both the causes and the outcome---induce spurious non-causal correlations between the two. Wang \& Blei (2018) lower this hurdle with "the blessings of multiple causes," where the correlation structure of multiple causes provides indirect evidence for unobserved confounding. They leverage these blessings with an algorithm, called the deconfounder, that uses probabilistic factor models to correct for the confounders. In this paper, we take a causal graphical view of the deconfounder. In a graph that encodes shared confounding, we show how the multiplicity of causes can help identify intervention distributions. We then justify the deconfounder, showing that it makes valid inferences of the intervention. Finally, we expand the class of graphs, and its theory, to those that include other confounders and selection variables. Our results expand the theory in Wang \& Blei (2018), justify the deconfounder for causal graphs, and extend the settings where it can be used.},
  archivePrefix = {arXiv},
  eprint = {1905.12793},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wang, Blei (2019) - Multiple Causes.pdf},
  journal = {arXiv:1905.12793 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {cs, stat}
}

@article{wang2019Repairing,
  title = {Repairing without {{Retraining}}: {{Avoiding Disparate Impact}} with {{Counterfactual Distributions}}},
  shorttitle = {Repairing without {{Retraining}}},
  author = {Wang, Hao and Ustun, Berk and Calmon, Flavio P.},
  year = {2019},
  month = jan,
  abstract = {When the performance of a machine learning model varies over groups defined by sensitive attributes (e.g., gender or ethnicity), the performance disparity can be expressed in terms of the probability distributions of the input and output variables over each group. In this paper, we exploit this fact to reduce the disparate impact of a fixed classification model over a population of interest. Given a black-box classifier, we aim to eliminate the performance gap by perturbing the distribution of input variables for the disadvantaged group. We refer to the perturbed distribution as a counterfactual distribution, and characterize its properties for common fairness criteria. We introduce a descent algorithm to learn a counterfactual distribution from data. We then discuss how the estimated distribution can be used to build a data preprocessor that can reduce disparate impact without training a new model. We validate our approach through experiments on real-world datasets, showing that it can repair different forms of disparity without a significant drop in accuracy.},
  archivePrefix = {arXiv},
  eprint = {1901.10501},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wang et al (2019) - Repairing without Retraining.pdf},
  journal = {arXiv:1901.10501 [cs, math, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Information Theory,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{wang2019WassersteinFisherRao,
  title = {Wasserstein-{{Fisher}}-{{Rao Document Distance}}},
  author = {Wang, Zihao and Zhou, Datong and Zhang, Yong and Wu, Hao and Bao, Chenglong},
  year = {2019},
  month = jul,
  abstract = {As a fundamental problem of natural language processing, it is important to measure the distance between different documents. Among the existing methods, the Word Mover's Distance (WMD) has shown remarkable success in document semantic matching for its clear physical insight as a parameter-free model. However, WMD is essentially based on the classical Wasserstein metric, thus it often fails to robustly represent the semantic similarity between texts of different lengths. In this paper, we apply the newly developed Wasserstein-Fisher-Rao (WFR) metric from unbalanced optimal transport theory to measure the distance between different documents. The proposed WFR document distance maintains the great interpretability and simplicity as WMD. We demonstrate that the WFR document distance has significant advantages when comparing the texts of different lengths. In addition, an accelerated Sinkhorn based algorithm with GPU implementation has been developed for the fast computation of WFR distances. The KNN classification results on eight datasets have shown its clear improvement over WMD.},
  archivePrefix = {arXiv},
  eprint = {1904.10294},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wang et al (2019) - Wasserstein-Fisher-Rao Document Distance.pdf},
  journal = {arXiv:1904.10294 [cs, stat]},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{wang2020Fairness,
  title = {On the {{Fairness}} of {{Randomized Trials}} for {{Recommendation}} with {{Heterogeneous Demographics}} and {{Beyond}}},
  author = {Wang, Zifeng and Chen, Xi and Wen, Rui and Huang, Shao-Lun},
  year = {2020},
  month = feb,
  abstract = {Observed events in recommendation are consequence of the decisions made by a policy, thus they are usually selectively labeled, namely the data are Missing Not At Random (MNAR), which often causes large bias to the estimate of true outcomes risk. A general approach to correct MNAR bias is performing small Randomized Controlled Trials (RCTs), where an additional uniform policy is employed to randomly assign items to each user. In this work, we concentrate on the fairness of RCTs under both homogeneous and heterogeneous demographics, especially analyzing the bias for the least favorable group on the latter setting. Considering RCTs' limitations, we propose a novel Counterfactual Robust Risk Minimization (CRRM) framework, which is totally free of expensive RCTs, and derive its theoretical generalization error bound. At last, empirical experiments are performed on synthetic tasks and real-world data sets, substantiating our method's superiority both in fairness and generalization.},
  archivePrefix = {arXiv},
  eprint = {2001.09328},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wang et al (2020) - On the Fairness of Randomized Trials for Recommendation with Heterogeneous.pdf},
  journal = {arXiv:2001.09328 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{wasserman2014Stein,
  title = {Stein's {{Method}} and {{The Bootstrap}} in {{Low}} and {{High Dimensions}}: {{A Tutorial}}},
  author = {Wasserman, Larry},
  year = {2014},
  month = feb,
  pages = {46},
  file = {/Users/yuekai/Documents/zotero/Wasserman (2014) - Stein’s Method and The Bootstrap in Low and High Dimensions.pdf},
  language = {en}
}

@article{wasserman2019Universal,
  title = {Universal {{Inference Using}} the {{Split Likelihood Ratio Test}}},
  author = {Wasserman, Larry and Ramdas, Aaditya and Balakrishnan, Sivaraman},
  year = {2019},
  month = dec,
  abstract = {We propose a general method for constructing hypothesis tests and confidence sets that have finite sample guarantees without regularity conditions. We refer to such procedures as ``universal.'' The method is very simple and is based on a modified version of the usual likelihood ratio statistic, that we call ``the split likelihood ratio test'' (split LRT). The method is especially appealing for irregular statistical models. Canonical examples include mixture models and models that arise in shape-constrained inference. \%mixture models and shape-constrained models are just two examples. Constructing tests and confidence sets for such models is notoriously difficult. Typical inference methods, like the likelihood ratio test, are not useful in these cases because they have intractable limiting distributions. In contrast, the method we suggest works for any parametric model and also for some nonparametric models. The split LRT can also be used with profile likelihoods to deal with nuisance parameters, and it can also be run sequentially to yield anytime-valid \$p\$-values and confidence sequences.},
  archivePrefix = {arXiv},
  eprint = {1912.11436},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wasserman et al (2019) - Universal Inference Using the Split Likelihood Ratio Test.pdf},
  journal = {arXiv:1912.11436 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{webber2000SelfOrganization,
  title = {Self-{{Organization}} of {{Symmetry Networks}}: {{Transformation Invariance}} from the {{Spontaneous Symmetry}}-{{Breaking Mechanism}}},
  shorttitle = {Self-{{Organization}} of {{Symmetry Networks}}},
  author = {Webber, Chris J. S.},
  year = {2000},
  month = mar,
  volume = {12},
  pages = {565--596},
  publisher = {{MIT Press}},
  issn = {0899-7667},
  doi = {10.1162/089976600300015718},
  abstract = {Symmetry networks use permutation symmetries among synaptic weights to achieve transformation-invariant response. This article proposes a generic mechanism by which such symmetries can develop during unsupervised adaptation: it is shown analytically that spontaneous symmetry breaking can result in the discovery of unknown invariances of the data's probability distribution. It is proposed that a role of sparse coding is to facilitate the discovery of statistical invariances by this mechanism. It is demonstrated that the statistical dependences that exist between simple-cell-like threshold feature detectors, when exposed to temporally uncorrelated natural image data, can drive the development of complex-cell-like invariances, via single-cell Hebbian adaptation. A single learning rule can generate both simple-cell-like and complex-cell-like receptive fields.},
  file = {/Users/yuekai/Documents/zotero/Webber (2000) - Self-Organization of Symmetry Networks.pdf},
  journal = {Neural Computation},
  number = {3}
}

@misc{weber2016Optimization,
  title = {Optimization and {{Control}}},
  author = {Weber, Richard},
  year = {2016},
  file = {/Users/yuekai/Documents/zotero/Weber (2016) - Optimization and Control.pdf}
}

@article{wei2017Early,
  title = {Early Stopping for Kernel Boosting Algorithms: {{A}} General Analysis with Localized Complexities},
  shorttitle = {Early Stopping for Kernel Boosting Algorithms},
  author = {Wei, Yuting and Yang, Fanny and Wainwright, Martin J.},
  year = {2017},
  month = jul,
  abstract = {Early stopping of iterative algorithms is a widely-used form of regularization in statistics, commonly used in conjunction with boosting and related gradient-type algorithms. Although consistency results have been established in some settings, such estimators are less well-understood than their analogues based on penalized regularization. In this paper, for a relatively broad class of loss functions and boosting algorithms (including L2-boost, LogitBoost and AdaBoost, among others), we exhibit a direct connection between the performance of a stopped iterate and the localized Gaussian complexity of the associated function class. This connection allows us to show that local fixed point analysis of Gaussian or Rademacher complexities, now standard in the analysis of penalized estimators, can be used to derive optimal stopping rules. We derive such stopping rules in detail for various kernel classes, and illustrate the correspondence of our theory with practice for Sobolev kernel classes.},
  archivePrefix = {arXiv},
  eprint = {1707.01543},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wei et al (2017) - Early stopping for kernel boosting algorithms.pdf},
  journal = {arXiv:1707.01543 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{wei2018Regularization,
  title = {Regularization {{Matters}}: {{Generalization}} and {{Optimization}} of {{Neural Nets}} v.s. Their {{Induced Kernel}}},
  shorttitle = {Regularization {{Matters}}},
  author = {Wei, Colin and Lee, Jason D. and Liu, Qiang and Ma, Tengyu},
  year = {2018},
  month = oct,
  abstract = {Recent works have shown that on sufficiently over-parametrized neural nets, gradient descent with relatively large initialization optimizes a prediction function in the RKHS of the Neural Tangent Kernel (NTK). This analysis leads to global convergence results but does not work when there is a standard l2 regularizer, which is useful to have in practice. We show that sample efficiency can indeed depend on the presence of the regularizer: we construct a simple distribution in d dimensions which the optimal regularized neural net learns with O(d) samples but the NTK requires \textbackslash Omega(d\^2) samples to learn. To prove this, we establish two analysis tools: i) for multi-layer feedforward ReLU nets, we show that the global minimizer of a weakly-regularized cross-entropy loss is the max normalized margin solution among all neural nets, which generalizes well; ii) we develop a new technique for proving lower bounds for kernel methods, which relies on showing that the kernel cannot focus on informative features. Motivated by our generalization results, we study whether the regularized global optimum is attainable. We prove that for infinite-width two-layer nets, noisy gradient descent optimizes the regularized neural net loss to a global minimum in polynomial iterations.},
  archivePrefix = {arXiv},
  eprint = {1810.05369},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wei et al (2018) - Regularization Matters.pdf},
  journal = {arXiv:1810.05369 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{wei2019Optimized,
  title = {Optimized {{Score Transformation}} for {{Fair Classification}}},
  author = {Wei, Dennis and Ramamurthy, Karthikeyan Natesan and Calmon, Flavio du Pin},
  year = {2019},
  month = dec,
  abstract = {This paper considers fair probabilistic classification where the outputs of primary interest are predicted probabilities, commonly referred to as scores. We formulate the problem of transforming scores to satisfy fairness constraints that are linear in conditional means of scores while minimizing the loss in utility. The formulation can be applied either to post-process classifier outputs or to pre-process training data, thus allowing maximum freedom in selecting a classification algorithm. We derive a closed-form expression for the optimal transformed scores and a convex optimization problem for the transformation parameters. In the population limit, the transformed score function is the fairness-constrained minimizer of cross-entropy with respect to the optimal unconstrained scores. In the finite sample setting, we propose to approach this solution using a combination of standard probabilistic classifiers and ADMM. The transformation parameters obtained from the finite-sample procedure are shown to be asymptotically optimal. Comprehensive experiments comparing to 10 existing methods show that the proposed FairScoreTransformer has advantages for score-based metrics such as Brier score and AUC while remaining competitive for binary label-based metrics such as accuracy.},
  archivePrefix = {arXiv},
  eprint = {1906.00066},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wei et al (2019) - Optimized Score Transformation for Fair Classification.pdf},
  journal = {arXiv:1906.00066 [cs, math, stat]},
  keywords = {Computer Science - Information Theory,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{weichwald2020Distributional,
  title = {Distributional Robustness as a Guiding Principle for Causality in Cognitive Neuroscience},
  author = {Weichwald, Sebastian and Peters, Jonas},
  year = {2020},
  month = feb,
  abstract = {While probabilistic models describe the dependence structure between observed variables, causal models go one step further: they predict how cognitive functions are affected by external interventions that perturb neuronal activity. Inferring causal relationships from data is an ambitious task that is particularly challenging in cognitive neuroscience. Here, we discuss two difficulties in more detail: the scarcity of interventional data and the challenge of finding the right variables. We argue for distributional robustness as a guiding principle to tackle these problems. Modelling a target variable using the correct set of causal variables yields a model that generalises across environments or subjects (if these environments leave the causal mechanisms intact). Conversely, if a candidate model does not generalise, then either it includes non-causes of the target variable or the underlying variables are wrongly defined. In this sense, generalisability may serve as a guiding principle when defining relevant variables and can be used to partially compensate for the lack of interventional data.},
  archivePrefix = {arXiv},
  eprint = {2002.06060},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Weichwald, Peters (2020) - Distributional robustness as a guiding principle for causality in cognitive.pdf},
  journal = {arXiv:2002.06060 [q-bio, stat]},
  keywords = {Quantitative Biology - Neurons and Cognition,Statistics - Applications,Statistics - Methodology},
  primaryClass = {q-bio, stat}
}

@article{wen2016Online,
  title = {Online {{Influence Maximization}} under {{Independent Cascade Model}} with {{Semi}}-{{Bandit Feedback}}},
  author = {Wen, Zheng and Kveton, Branislav and Valko, Michal and Vaswani, Sharan},
  year = {2016},
  month = may,
  abstract = {We study the online influence maximization problem in social networks under the independent cascade model. Specifically, we aim to learn the set of "best influencers" in a social network online while repeatedly interacting with it. We address the challenges of (i) combinatorial action space, since the number of feasible influencer sets grows exponentially with the maximum number of influencers, and (ii) limited feedback, since only the influenced portion of the network is observed. Under a stochastic semi-bandit feedback, we propose and analyze IMLinUCB, a computationally efficient UCB-based algorithm. Our bounds on the cumulative regret are polynomial in all quantities of interest, achieve near-optimal dependence on the number of interactions and reflect the topology of the network and the activation probabilities of its edges, thereby giving insights on the problem complexity. To the best of our knowledge, these are the first such results. Our experiments show that in several representative graph topologies, the regret of IMLinUCB scales as suggested by our upper bounds. IMLinUCB permits linear generalization and thus is both statistically and computationally suitable for large-scale problems. Our experiments also show that IMLinUCB with linear generalization can lead to low regret in real-world online influence maximization.},
  archivePrefix = {arXiv},
  eprint = {1605.06593},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wen et al (2016) - Online Influence Maximization under Independent Cascade Model with Semi-Bandit.pdf},
  journal = {arXiv:1605.06593 [cs, math, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{weng2018EVALUATING,
  title = {{{EVALUATING THE ROBUSTNESS OF NEURAL NET}}- {{WORKS}}: {{AN EXTREME VALUE THEORY APPROACH}}},
  author = {Weng, Tsui-Wei and Zhang, Huan and Chen, Pin-Yu and Yi, Jinfeng and Su, Dong and Gao, Yupeng and Hsieh, Cho-Jui and Daniel, Luca},
  year = {2018},
  pages = {18},
  abstract = {The robustness of neural networks to adversarial examples has received great attention due to security implications. Despite various attack approaches to crafting visually imperceptible adversarial examples, little has been developed towards a comprehensive measure of robustness. In this paper, we provide a theoretical justification for converting robustness analysis into a local Lipschitz constant estimation problem, and propose to use the Extreme Value Theory for efficient evaluation. Our analysis yields a novel robustness metric called CLEVER, which is short for Cross Lipschitz Extreme Value for nEtwork Robustness. The proposed CLEVER score is attack-agnostic and computationally feasible for large neural networks. Experimental results on various networks, including ResNet, Inceptionv3 and MobileNet, show that (i) CLEVER is aligned with the robustness indication measured by the 2 and {$\infty$} norms of adversarial examples from powerful attacks, and (ii) defended networks using defensive distillation or bounded ReLU indeed achieve better CLEVER scores. To the best of our knowledge, CLEVER is the first attack-independent robustness metric that can be applied to any neural network classifier.},
  file = {/Users/yuekai/Documents/zotero/Weng et al (2018) - EVALUATING THE ROBUSTNESS OF NEURAL NET- WORKS.pdf},
  language = {en}
}

@article{weng2018Evaluating,
  title = {Evaluating the {{Robustness}} of {{Neural Networks}}: {{An Extreme Value Theory Approach}}},
  shorttitle = {Evaluating the {{Robustness}} of {{Neural Networks}}},
  author = {Weng, Tsui-Wei and Zhang, Huan and Chen, Pin-Yu and Yi, Jinfeng and Su, Dong and Gao, Yupeng and Hsieh, Cho-Jui and Daniel, Luca},
  year = {2018},
  month = jan,
  abstract = {The robustness of neural networks to adversarial examples has received great attention due to security implications. Despite various attack approaches to crafting visually imperceptible adversarial examples, little has been developed towards a comprehensive measure of robustness. In this paper, we provide a theoretical justification for converting robustness analysis into a local Lipschitz constant estimation problem, and propose to use the Extreme Value Theory for efficient evaluation. Our analysis yields a novel robustness metric called CLEVER, which is short for Cross Lipschitz Extreme Value for nEtwork Robustness. The proposed CLEVER score is attack-agnostic and computationally feasible for large neural networks. Experimental results on various networks, including ResNet, Inception-v3 and MobileNet, show that (i) CLEVER is aligned with the robustness indication measured by the \$\textbackslash ell\_2\$ and \$\textbackslash ell\_\textbackslash infty\$ norms of adversarial examples from powerful attacks, and (ii) defended networks using defensive distillation or bounded ReLU indeed achieve better CLEVER scores. To the best of our knowledge, CLEVER is the first attack-independent robustness metric that can be applied to any neural network classifier.},
  archivePrefix = {arXiv},
  eprint = {1801.10578},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Weng et al (2018) - Evaluating the Robustness of Neural Networks.pdf},
  journal = {arXiv:1801.10578 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{wexler2017Life,
  title = {Life, {{Liberty}}, and {{Trade Secrets}}: {{Intellectual Property}} in the {{Criminal Justice System}}},
  shorttitle = {Life, {{Liberty}}, and {{Trade Secrets}}},
  author = {Wexler, Rebecca},
  year = {2017},
  issn = {1556-5068},
  doi = {10.2139/ssrn.2920883},
  abstract = {The criminal justice system is becoming automated. At every stage, from policing to evidence to parole, machine learning and other computer systems guide outcomes. Widespread debates over the pros and cons of these technologies have overlooked a crucial issue: ownership. Developers often claim that details about how their tools work are trade secrets and refuse to disclose that information to criminal defendants or their attorneys. The introduction of intellectual property claims into the criminal justice system raises undertheorized tensions between life, liberty, and property interests.},
  file = {/Users/yuekai/Documents/zotero/Wexler (2017) - Life, Liberty, and Trade Secrets.pdf},
  journal = {SSRN Electronic Journal},
  language = {en}
}

@article{wibisono2018Sampling,
  title = {Sampling as Optimization in the Space of Measures: {{The Langevin}} Dynamics as a Composite Optimization Problem},
  shorttitle = {Sampling as Optimization in the Space of Measures},
  author = {Wibisono, Andre},
  year = {2018},
  month = feb,
  abstract = {We study sampling as optimization in the space of measures. We focus on gradient flow-based optimization with the Langevin dynamics as a case study. We investigate the source of the bias of the unadjusted Langevin algorithm (ULA) in discrete time, and consider how to remove or reduce the bias. We point out the difficulty is that the heat flow is exactly solvable, but neither its forward nor backward method is implementable in general, except for Gaussian data. We propose the symmetrized Langevin algorithm (SLA), which should have a smaller bias than ULA, at the price of implementing a proximal gradient step in space. We show SLA is in fact consistent for Gaussian target measure, whereas ULA is not. We also illustrate various algorithms explicitly for Gaussian target measure, including gradient descent, proximal gradient, and Forward-Backward, and show they are all consistent.},
  archivePrefix = {arXiv},
  eprint = {1802.08089},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wibisono (2018) - Sampling as optimization in the space of measures.pdf},
  journal = {arXiv:1802.08089 [cs, math, stat]},
  keywords = {Computer Science - Information Theory,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{wilber2014CostEffective,
  title = {Cost-{{Effective HITs}} for {{Relative Similarity Comparisons}}},
  author = {Wilber, Michael J. and Kwak, Iljung S. and Belongie, Serge J.},
  year = {2014},
  month = apr,
  abstract = {Similarity comparisons of the form "Is object a more similar to b than to c?" are useful for computer vision and machine learning applications. Unfortunately, an embedding of \$n\$ points is specified by \$n\^3\$ triplets, making collecting every triplet an expensive task. In noticing this difficulty, other researchers have investigated more intelligent triplet sampling techniques, but they do not study their effectiveness or their potential drawbacks. Although it is important to reduce the number of collected triplets, it is also important to understand how best to display a triplet collection task to a user. In this work we explore an alternative display for collecting triplets and analyze the monetary cost and speed of the display. We propose best practices for creating cost effective human intelligence tasks for collecting triplets. We show that rather than changing the sampling algorithm, simple changes to the crowdsourcing UI can lead to much higher quality embeddings. We also provide a dataset as well as the labels collected from crowd workers.},
  archivePrefix = {arXiv},
  eprint = {1404.3291},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wilber et al (2014) - Cost-Effective HITs for Relative Similarity Comparisons.pdf},
  journal = {arXiv:1404.3291 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{wolfe2013Nonparametric,
  title = {Nonparametric Graphon Estimation},
  author = {Wolfe, Patrick J. and Olhede, Sofia C.},
  year = {2013},
  month = sep,
  abstract = {We propose a nonparametric framework for the analysis of networks, based on a natural limit object termed a graphon. We prove consistency of graphon estimation under general conditions, giving rates which include the important practical setting of sparse networks. Our results cover dense and sparse stochastic blockmodels with a growing number of classes, under model misspecification. We use profile likelihood methods, and connect our results to approximation theory, nonparametric function estimation, and the theory of graph limits.},
  archivePrefix = {arXiv},
  eprint = {1309.5936},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wolfe, Olhede (2013) - Nonparametric graphon estimation.pdf},
  journal = {arXiv:1309.5936 [math, stat]},
  keywords = {Mathematics - Combinatorics,Mathematics - Probability,Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{wong2017Provable,
  title = {Provable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope},
  author = {Wong, Eric and Kolter, J. Zico},
  year = {2017},
  month = nov,
  abstract = {We propose a method to learn deep ReLU-based classifiers that are provably robust against norm-bounded adversarial perturbations on the training data. For previously unseen examples, the approach is guaranteed to detect all adversarial examples, though it may flag some non-adversarial examples as well. The basic idea is to consider a convex outer approximation of the set of activations reachable through a norm-bounded perturbation, and we develop a robust optimization procedure that minimizes the worst case loss over this outer region (via a linear program). Crucially, we show that the dual problem to this linear program can be represented itself as a deep network similar to the backpropagation network, leading to very efficient optimization approaches that produce guaranteed bounds on the robust loss. The end result is that by executing a few more forward and backward passes through a slightly modified version of the original network (though possibly with much larger batch sizes), we can learn a classifier that is provably robust to any norm-bounded adversarial attack. We illustrate the approach on a number of tasks to train classifiers with robust adversarial guarantees (e.g. for MNIST, we produce a convolutional classifier that provably has less than 5.8\% test error for any adversarial attack with bounded \$\textbackslash ell\_\textbackslash infty\$ norm less than \$\textbackslash epsilon = 0.1\$), and code for all experiments in the paper is available at https://github.com/locuslab/convex\_adversarial.},
  archivePrefix = {arXiv},
  eprint = {1711.00851},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wong, Kolter (2017) - Provable defenses against adversarial examples via the convex outer adversarial.pdf},
  journal = {arXiv:1711.00851 [cs, math]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Mathematics - Optimization and Control},
  primaryClass = {cs, math}
}

@article{wong2018Scaling,
  title = {Scaling Provable Adversarial Defenses},
  author = {Wong, Eric and Schmidt, Frank R. and Metzen, Jan Hendrik and Kolter, J. Zico},
  year = {2018},
  month = may,
  abstract = {Recent work has developed methods for learning deep network classifiers that are provably robust to norm-bounded adversarial perturbation; however, these methods are currently only possible for relatively small feedforward networks. In this paper, in an effort to scale these approaches to substantially larger models, we extend previous work in three main directions. First, we present a technique for extending these training procedures to much more general networks, with skip connections (such as ResNets) and general nonlinearities; the approach is fully modular, and can be implemented automatically (analogous to automatic differentiation). Second, in the specific case of \$\textbackslash ell\_\textbackslash infty\$ adversarial perturbations and networks with ReLU nonlinearities, we adopt a nonlinear random projection for training, which scales linearly in the number of hidden units (previous approaches scaled quadratically). Third, we show how to further improve robust error through cascade models. On both MNIST and CIFAR data sets, we train classifiers that improve substantially on the state of the art in provable robust adversarial error bounds: from 5.8\% to 3.1\% on MNIST (with \$\textbackslash ell\_\textbackslash infty\$ perturbations of \$\textbackslash epsilon=0.1\$), and from 80\% to 36.4\% on CIFAR (with \$\textbackslash ell\_\textbackslash infty\$ perturbations of \$\textbackslash epsilon=2/255\$). Code for all experiments in the paper is available at https://github.com/locuslab/convex\_adversarial/.},
  archivePrefix = {arXiv},
  eprint = {1805.12514},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wong et al (2018) - Scaling provable adversarial defenses.pdf},
  journal = {arXiv:1805.12514 [cs, math, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{wood1999BINOMIAL,
  title = {{{BINOMIAL MIXTURES}}: {{GEOMETRIC ESTIMATION OF THE MIXING DISTRIBUTION}}},
  author = {Wood, G R},
  year = {1999},
  volume = {27},
  pages = {16},
  file = {/Users/yuekai/Documents/zotero/Wood (1999) - BINOMIAL MIXTURES.pdf},
  journal = {The Annals of Statistics},
  language = {en},
  number = {5}
}

@article{woodroofe1993penalized,
  title = {A Penalized Maximum Likelihood Estimate of f(0+) When f Is Non-Increasing},
  author = {Woodroofe, Michael and Sun, Jiayang},
  year = {1993},
  volume = {3},
  pages = {501--515},
  issn = {1017-0405},
  abstract = {The problem of estimating the value at 0+ of a non-increasing density f (on (0, {$\infty$})) is considered. It is shown, by example, that the problem is interesting, and it is noted that the nonparametric maximum likelihood estimator is inconsistent. A penalized maximum likelihood estimator is derived as an alternative, and its properties studied through simulations and asymptotic analysis. In particular, the penalized maximum likelihood estimator is shown to be consistent.},
  file = {/Users/yuekai/Documents/zotero/Woodroofe, Sun (1993) - A PENALIZED MAXIMUM LIKELIHOOD ESTIMATE OF f(0+) WHEN f IS NON-INCREASING.pdf},
  journal = {Statistica Sinica},
  number = {2}
}

@article{woodworth2019Kernel,
  title = {Kernel and {{Rich Regimes}} in {{Overparametrized Models}}},
  author = {Woodworth, Blake and Gunasekar, Suriya and Savarese, Pedro and Moroshko, Edward and Golan, Itay and Lee, Jason and Soudry, Daniel and Srebro, Nathan},
  year = {2019},
  month = sep,
  abstract = {A recent line of work studies overparametrized neural networks in the "kernel regime," i.e. when the network behaves during training as a kernelized linear predictor, and thus training with gradient descent has the effect of finding the minimum RKHS norm solution. This stands in contrast to other studies which demonstrate how gradient descent on overparametrized multilayer networks can induce rich implicit biases that are not RKHS norms. Building on an observation by Chizat and Bach, we show how the scale of the initialization controls the transition between the "kernel" (aka lazy) and "rich" (aka active) regimes and affects generalization properties in multilayer homogeneous models. We provide a complete and detailed analysis for a simple two-layer model that already exhibits an interesting and meaningful transition between the kernel and rich regimes, and we demonstrate the transition for more complex matrix factorization models and multilayer non-linear networks.},
  archivePrefix = {arXiv},
  eprint = {1906.05827},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Woodworth et al (2019) - Kernel and Rich Regimes in Overparametrized Models2.pdf},
  journal = {arXiv:1906.05827 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{woody2018Optimal,
  title = {Optimal Post-Selection Inference for Sparse Signals: A Nonparametric Empirical-{{Bayes}} Approach},
  shorttitle = {Optimal Post-Selection Inference for Sparse Signals},
  author = {Woody, Spencer and Scott, James G.},
  year = {2018},
  month = oct,
  abstract = {A large body of recent Bayesian work has focused on the question of how to find sparse signals. Much less work, however, has been done on the natural follow-up question: how to make valid inferences for the magnitude of those signals once they've been found. Ordinary Bayesian credible intervals are not necessarily appropriate for this task: in many circumstances, they suffer from selection bias, owing to the fact that the target of inference is chosen adaptively. There are many purely frequentist proposals for addressing this problem. But these typically require sacrificing the benefits of shrinkage or `borrowing strength' inherent to Bayesian modeling, resulting in confidence intervals that are needlessly wide. On the flip side, there are also Bayesian proposals for addressing this problem, most notably that of Yekutieli (2012), who constructs selection-adjusted posterior distributions. The resulting credible intervals, however, have poor frequentist performance: for nearly all values of the underlying parameter, they fail to exhibit the correct nominal coverage. Thus there is an unmet need for approaches to inference that correctly adjust for selection, and incorporate the benefits of shrinkage while maintaining exact frequentist coverage. We address this gap by proposing a nonparametric empirical-Bayes approach for constructing optimal selection-adjusted confidence sets. The method produces confidence sets that are as short as possible, while both adjusting for selection and maintaining exact frequentist coverage uniformly across the whole parameter space. Across a series of examples, the method outperforms existing frequentist techniques for post-selection inference, producing confidence sets that are notably shorter but with the same coverage guarantee.},
  archivePrefix = {arXiv},
  eprint = {1810.11042},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Woody, Scott (2018) - Optimal post-selection inference for sparse signals.pdf},
  journal = {arXiv:1810.11042 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{wu2009Genomewide,
  title = {Genome-Wide Association Analysis by Lasso Penalized Logistic Regression},
  author = {Wu, Tong Tong and Chen, Yi Fang and Hastie, Trevor and Sobel, Eric and Lange, Kenneth},
  year = {2009},
  month = mar,
  volume = {25},
  pages = {714--721},
  issn = {1460-2059, 1367-4803},
  doi = {10.1093/bioinformatics/btp041},
  abstract = {Motivation: In ordinary regression, imposition of a lasso penalty makes continuous model selection straightforward. Lasso penalized regression is particularly advantageous when the number of predictors far exceeds the number of observations.},
  file = {/Users/yuekai/Documents/zotero/Wu et al (2009) - Genome-wide association analysis by lasso penalized logistic regression.pdf},
  journal = {Bioinformatics},
  language = {en},
  number = {6}
}

@article{wu2016Convergence,
  title = {On the {{Convergence}} of the {{EM Algorithm}}: {{A Data}}-{{Adaptive Analysis}}},
  shorttitle = {On the {{Convergence}} of the {{EM Algorithm}}},
  author = {Wu, Chong and Yang, Can and Zhao, Hongyu and Zhu, Ji},
  year = {2016},
  month = nov,
  abstract = {The Expectation-Maximization (EM) algorithm is an iterative method to maximize the log-likelihood function for parameter estimation. Previous works on the convergence analysis of the EM algorithm have established results on the asymptotic (population level) convergence rate of the algorithm. In this paper, we give a data-adaptive analysis of the sample level local convergence rate of the EM algorithm. In particular, we show that the local convergence rate of the EM algorithm is a random variable \$\textbackslash overline\{K\}\_\{n\}\$ derived from the data generating distribution, which adaptively yields the convergence rate of the EM algorithm on each finite sample data set from the same population distribution. We then give a non-asymptotic concentration bound of \$\textbackslash overline\{K\}\_\{n\}\$ on the population level optimal convergence rate \$\textbackslash overline\{\textbackslash kappa\}\$ of the EM algorithm, which implies that \$\textbackslash overline\{K\}\_\{n\}\textbackslash to\textbackslash overline\{\textbackslash kappa\}\$ in probability as the sample size \$n\textbackslash to\textbackslash infty\$. Our theory identifies the effect of sample size on the convergence behavior of sample EM sequence, and explains a surprising phenomenon in applications of the EM algorithm, i.e. the finite sample version of the algorithm sometimes converges faster even than the population version. We apply our theory to the EM algorithm on three canonical models and obtain specific forms of the adaptive convergence theorem for each model.},
  archivePrefix = {arXiv},
  eprint = {1611.00519},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wu et al (2016) - On the Convergence of the EM Algorithm.pdf},
  journal = {arXiv:1611.00519 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{wu2017Reinforcing,
  title = {Reinforcing {{Adversarial Robustness}} Using {{Model Confidence Induced}} by {{Adversarial Training}}},
  author = {Wu, Xi and Jang, Uyeong and Chen, Jiefeng and Chen, Lingjiao and Jha, Somesh},
  year = {2017},
  month = nov,
  abstract = {In this paper we study leveraging confidence information induced by adversarial training to reinforce adversarial robustness of a given adversarially trained model. A natural measure of confidence is \$\textbackslash |F(\{\textbackslash bf x\})\textbackslash |\_\textbackslash infty\$ (i.e. how confident \$F\$ is about its prediction?). We start by analyzing an adversarial training formulation proposed by Madry et al.. We demonstrate that, under a variety of instantiations, an only somewhat good solution to their objective induces confidence to be a discriminator, which can distinguish between right and wrong model predictions in a neighborhood of a point sampled from the underlying distribution. Based on this, we propose Highly Confident Near Neighbor (\$\{\textbackslash tt HCNN\}\$), a framework that combines confidence information and nearest neighbor search, to reinforce adversarial robustness of a base model. We give algorithms in this framework and perform a detailed empirical study. We report encouraging experimental results that support our analysis, and also discuss problems we observed with existing adversarial training.},
  archivePrefix = {arXiv},
  eprint = {1711.08001},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wu et al (2017) - Reinforcing Adversarial Robustness using Model Confidence Induced by.pdf},
  journal = {arXiv:1711.08001 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{wu2020Minimax,
  title = {On {{Minimax Optimality}} of {{GANs}} for {{Robust Mean Estimation}}},
  booktitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Wu, Kaiwen and Ding, Gavin Weiguang and Huang, Ruitong and Yu, Yaoliang},
  year = {2020},
  month = jun,
  pages = {4541--4551},
  issn = {2640-3498},
  abstract = {Generative adversarial networks (GANs) have become one of the most popular generative modeling techniques in machine learning. In this work, we study the statistical and robust properties of GANs f...},
  chapter = {Machine Learning},
  file = {/Users/yuekai/Documents/zotero/Wu et al (2020) - On Minimax Optimality of GANs for Robust Mean Estimation.pdf;/Users/yuekai/Zotero/storage/YUIZLAPC/wu20d.html},
  language = {en}
}

@article{wu2020Representation,
  title = {Representation {{Bayesian Risk Decompositions}} and {{Multi}}-{{Source Domain Adaptation}}},
  author = {Wu, Xi and Guo, Yang and Chen, Jiefeng and Liang, Yingyu and Jha, Somesh and Chalasani, Prasad},
  year = {2020},
  month = apr,
  abstract = {We consider representation learning (with hypothesis class \$\textbackslash mathcal\{H\} = \textbackslash mathcal\{F\}\textbackslash circ\textbackslash mathcal\{G\}\$) where training and test distributions can be different. Recent studies provide hints and failure examples for domain invariant representation learning, a common approach to this problem, but are inadequate for fully understanding the phenomena. In this paper, we provide new decompositions of risk which provide finer-grained explanations and clarify potential generalization issues. For Single-Source Domain Adaptation, we give an exact risk decomposition, an equality, where target risk is the sum of three factors: (1) source risk, (2) representation conditional label divergence, and (3) representation covariate shift. We derive a similar decomposition for the Multi-Source case. These decompositions reveal factors (2) and (3) as the precise reasons for failing to generalize. For example, we demonstrate that domain adversarial neural networks (DANN) attempt to regularize for (3) but miss (2), while a recent technique Invariant Risk Minimization (IRM) attempts to account for (2) but may suffer from not considering (3). We also verify these observations experimentally.},
  archivePrefix = {arXiv},
  eprint = {2004.10390},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wu et al (2020) - Representation Bayesian Risk Decompositions and Multi-Source Domain Adaptation.pdf},
  journal = {arXiv:2004.10390 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{wu2020Steepest,
  title = {Steepest {{Descent Neural Architecture Optimization}}: {{Escaping Local Optimum}} with {{Signed Neural Splitting}}},
  shorttitle = {Steepest {{Descent Neural Architecture Optimization}}},
  author = {Wu, Lemeng and Ye, Mao and Lei, Qi and Lee, Jason D. and Liu, Qiang},
  year = {2020},
  month = aug,
  abstract = {Developing efficient and principled neural architecture optimization methods is a critical challenge of modern deep learning. Recently, Liu et al.[19] proposed a splitting steepest descent (S2D) method that jointly optimizes the neural parameters and architectures based on progressively growing network structures by splitting neurons into multiple copies in a steepest descent fashion. However, S2D suffers from a local optimality issue when all the neurons become "splitting stable", a concept akin to local stability in parametric optimization. In this work, we develop a significant and surprising extension of the splitting descent framework that addresses the local optimality issue. The idea is to observe that the original S2D is unnecessarily restricted to splitting neurons into positive weighted copies. By simply allowing both positive and negative weights during splitting, we can eliminate the appearance of splitting stability in S2D and hence escape the local optima to obtain better performance. By incorporating signed splittings, we significantly extend the optimization power of splitting steepest descent both theoretically and empirically. We verify our method on various challenging benchmarks such as CIFAR-100, ImageNet and ModelNet40, on which we outperform S2D and other advanced methods on learning accurate and energy-efficient neural networks.},
  archivePrefix = {arXiv},
  eprint = {2003.10392},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wu et al (2020) - Steepest Descent Neural Architecture Optimization.pdf;/Users/yuekai/Zotero/storage/IWXRHWQC/2003.html},
  journal = {arXiv:2003.10392 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{wyner2015Explaining,
  title = {Explaining the {{Success}} of {{AdaBoost}} and {{Random Forests}} as {{Interpolating Classifiers}}},
  author = {Wyner, Abraham J. and Olson, Matthew and Bleich, Justin and Mease, David},
  year = {2015},
  month = apr,
  abstract = {There is a large literature explaining why AdaBoost is a successful classifier. The literature on AdaBoost focuses on classifier margins and boosting's interpretation as the optimization of an exponential likelihood function. These existing explanations, however, have been pointed out to be incomplete. A random forest is another popular ensemble method for which there is substantially less explanation in the literature. We introduce a novel perspective on AdaBoost and random forests that proposes that the two algorithms work for similar reasons. While both classifiers achieve similar predictive accuracy, random forests cannot be conceived as a direct optimization procedure. Rather, random forests is a self-averaging, interpolating algorithm which creates what we denote as a "spikey-smooth" classifier, and we view AdaBoost in the same light. We conjecture that both AdaBoost and random forests succeed because of this mechanism. We provide a number of examples and some theoretical justification to support this explanation. In the process, we question the conventional wisdom that suggests that boosting algorithms for classification require regularization or early stopping and should be limited to low complexity classes of learners, such as decision stumps. We conclude that boosting should be used like random forests: with large decision trees and without direct regularization or early stopping.},
  archivePrefix = {arXiv},
  eprint = {1504.07676},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Wyner et al (2015) - Explaining the Success of AdaBoost and Random Forests as Interpolating.pdf},
  journal = {arXiv:1504.07676 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {cs, stat}
}

@article{xiao2019Privacypreserving,
  title = {On {{Privacy}}-Preserving {{Decentralized Optimization}} through {{Alternating Direction Method}} of {{Multipliers}}},
  author = {Xiao, Hanshen and Yu, Ye and Devadas, Srini},
  year = {2019},
  month = feb,
  abstract = {Privacy concerns with sensitive data in machine learning are receiving increasing attention. In this paper, we study privacy-preserving distributed learning under the framework of Alternating Direction Method of Multipliers (ADMM). While secure distributed learning has been previously exploited in cryptographic or non-cryptographic (noise perturbation) approaches, it comes at a cost of either prohibitive computation overhead or a heavy loss of accuracy. Moreover, convergence in noise perturbation is hardly explored in existing privacy-preserving ADMM schemes. In this work, we propose two modified private ADMM schemes in the scenario of peer-to-peer semi-honest agents: First, for bounded colluding agents, we show that with merely linear secret sharing, information-theoretically private distributed optimization can be achieved. Second, using the notion of differential privacy, we propose first-order approximation based ADMM schemes with random parameters. We prove that the proposed private ADMM schemes can be implemented with a linear convergence rate and with a sharpened privacy loss bound in relation to prior work. Finally, we provide experimental results to support the theory.},
  archivePrefix = {arXiv},
  eprint = {1902.06101},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Xiao et al (2019) - On Privacy-preserving Decentralized Optimization through Alternating Direction.pdf},
  journal = {arXiv:1902.06101 [cs, math]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Mathematics - Optimization and Control},
  primaryClass = {cs, math}
}

@article{xie2018OffPolicy,
  title = {Off-{{Policy Evaluation}} and {{Learning}} from {{Logged Bandit Feedback}}: {{Error Reduction}} via {{Surrogate Policy}}},
  shorttitle = {Off-{{Policy Evaluation}} and {{Learning}} from {{Logged Bandit Feedback}}},
  author = {Xie, Yuan and Liu, Boyi and Liu, Qiang and Wang, Zhaoran and Zhou, Yuan and Peng, Jian},
  year = {2018},
  month = aug,
  abstract = {When learning from a batch of logged bandit feedback, the discrepancy between the policy to be learned and the off-policy training data imposes statistical and computational challenges. Unlike classical supervised learning and online learning settings, in batch contextual bandit learning, one only has access to a collection of logged feedback from the actions taken by a historical policy, and expect to learn a policy that takes good actions in possibly unseen contexts. Such a batch learning setting is ubiquitous in online and interactive systems, such as ad platforms and recommendation systems. Existing approaches based on inverse propensity weights, such as Inverse Propensity Scoring (IPS) and Policy Optimizer for Exponential Models (POEM), enjoy unbiasedness but often suffer from large mean squared error. In this work, we introduce a new approach named Maximum Likelihood Inverse Propensity Scoring (MLIPS) for batch learning from logged bandit feedback. Instead of using the given historical policy as the proposal in inverse propensity weights, we estimate a maximum likelihood surrogate policy based on the logged action-context pairs, and then use this surrogate policy as the proposal. We prove that MLIPS is asymptotically unbiased, and moreover, has a smaller nonasymptotic mean squared error than IPS. Such an error reduction phenomenon is somewhat surprising as the estimated surrogate policy is less accurate than the given historical policy. Results on multi-label classification problems and a large- scale ad placement dataset demonstrate the empirical effectiveness of MLIPS. Furthermore, the proposed surrogate policy technique is complementary to existing error reduction techniques, and when combined, is able to consistently boost the performance of several widely used approaches.},
  archivePrefix = {arXiv},
  eprint = {1808.00232},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Xie et al (2018) - Off-Policy Evaluation and Learning from Logged Bandit Feedback.pdf},
  journal = {arXiv:1808.00232 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{xie2019Scalable,
  title = {On {{Scalable}} and {{Efficient Computation}} of {{Large Scale Optimal Transport}}},
  author = {Xie, Yujia and Chen, Minshuo and Jiang, Haoming and Zhao, Tuo and Zha, Hongyuan},
  year = {2019},
  month = apr,
  abstract = {Optimal Transport (OT) naturally arises in many machine learning applications, yet the heavy computational burden limits its wide-spread uses. To address the scalability issue, we propose an implicit generative learning-based framework called SPOT (Scalable Push-forward of Optimal Transport). Specifically, we approximate the optimal transport plan by a pushforward of a reference distribution, and cast the optimal transport problem into a minimax problem. We then can solve OT problems efficiently using primal dual stochastic gradient-type algorithms. We also show that we can recover the density of the optimal transport plan using neural ordinary differential equations. Numerical experiments on both synthetic and real datasets illustrate that SPOT is robust and has favorable convergence behavior. SPOT also allows us to efficiently sample from the optimal transport plan, which benefits downstream applications such as domain adaptation.},
  archivePrefix = {arXiv},
  eprint = {1905.00158},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Xie et al (2019) - On Scalable and Efficient Computation of Large Scale Optimal Transport.pdf},
  journal = {arXiv:1905.00158 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{xu1997Lower,
  title = {Lower Bound Estimation for the Separation of Two Matrices},
  author = {Xu, Shu-Fang},
  year = {1997},
  month = sep,
  volume = {262},
  pages = {67--82},
  issn = {0024-3795},
  doi = {10.1016/S0024-3795(97)80023-7},
  abstract = {We give some lower bounds on the separations sep1(A, B), sep{$\infty$}(A, B), and sepF(A, B). The bounds show that the separation of two matrices A and B is closely related to the separation between the spectral sets of A and B, the structure of the Jordan canonical forms of A and B, and the departures from normality of A and B.},
  file = {/Users/yuekai/Documents/zotero/Xu (1997) - Lower bound estimation for the separation of two matrices.pdf},
  journal = {Linear Algebra and its Applications}
}

@article{xu2008Robustness,
  title = {Robustness and {{Regularization}} of {{Support Vector Machines}}},
  author = {Xu, Huan and Caramanis, Constantine and Mannor, Shie},
  year = {2008},
  month = mar,
  abstract = {We consider regularized support vector machines (SVMs) and show that they are
precisely equivalent to a new robust optimization formulation. We show that
this equivalence of robust optimization and regularization has implications for
both algorithms, and analysis. In terms of algorithms, the equivalence suggests
more general SVM-like algorithms for classification that explicitly build in
protection to noise, and at the same time control overfitting. On the analysis
front, the equivalence of robustness and regularization, provides a robust
optimization interpretation for the success of regularized SVMs. We use the
this new robustness interpretation of SVMs to give a new proof of consistency
of (kernelized) SVMs, thus establishing robustness as the reason regularized
SVMs generalize well.},
  file = {/Users/yuekai/Documents/zotero/Xu et al (2008) - Robustness and Regularization of Support Vector Machines.pdf},
  language = {en}
}

@article{xu2012Distributional,
  title = {A {{Distributional Interpretation}} of {{Robust Optimization}}},
  author = {Xu, Huan and Caramanis, Constantine and Mannor, Shie},
  year = {2012},
  month = jan,
  volume = {37},
  pages = {95--110},
  issn = {0364-765X},
  doi = {10.1287/moor.1110.0531},
  abstract = {Motivated by data-driven decision making and sampling problems, we investigate probabilistic interpretations of robust optimization (RO). We establish a connection between RO and distributionally robust stochastic programming (DRSP), showing that the solution to any RO problem is also a solution to a DRSP problem. Specifically, we consider the case where multiple uncertain parameters belong to the same fixed dimensional space and find the set of distributions of the equivalent DRSP problem. The equivalence we derive enables us to construct RO formulations for sampled problems (as in stochastic programming and machine learning) that are statistically consistent, even when the original sampled problem is not. In the process, this provides a systematic approach for tuning the uncertainty set. The equivalence further provides a probabilistic explanation for the common shrinkage heuristic, where the uncertainty set used in an RO problem is a shrunken version of the original uncertainty set.},
  file = {/Users/yuekai/Documents/zotero/Xu et al (2012) - A Distributional Interpretation of Robust Optimization.pdf},
  journal = {Mathematics of Operations Research},
  number = {1}
}

@article{xu2017Rates,
  title = {Rates of {{Convergence}} of {{Spectral Methods}} for {{Graphon Estimation}}},
  author = {Xu, Jiaming},
  year = {2017},
  month = sep,
  abstract = {This paper studies the problem of estimating the grahpon model - the underlying generating mechanism of a network. Graphon estimation arises in many applications such as predicting missing links in networks and learning user preferences in recommender systems. The graphon model deals with a random graph of \$n\$ vertices such that each pair of two vertices \$i\$ and \$j\$ are connected independently with probability \$\textbackslash rho \textbackslash times f(x\_i,x\_j)\$, where \$x\_i\$ is the unknown \$d\$-dimensional label of vertex \$i\$, \$f\$ is an unknown symmetric function, and \$\textbackslash rho\$ is a scaling parameter characterizing the graph sparsity. Recent studies have identified the minimax error rate of estimating the graphon from a single realization of the random graph. However, there exists a wide gap between the known error rates of computationally efficient estimation procedures and the minimax optimal error rate. Here we analyze a spectral method, namely universal singular value thresholding (USVT) algorithm, in the relatively sparse regime with the average vertex degree \$n\textbackslash rho=\textbackslash Omega(\textbackslash log n)\$. When \$f\$ belongs to H\textbackslash "\{o\}lder or Sobolev space with smoothness index \$\textbackslash alpha\$, we show the error rate of USVT is at most \$(n\textbackslash rho)\^\{ -2 \textbackslash alpha / (2\textbackslash alpha+d)\}\$, approaching the minimax optimal error rate \$\textbackslash log (n\textbackslash rho)/(n\textbackslash rho)\$ for \$d=1\$ as \$\textbackslash alpha\$ increases. Furthermore, when \$f\$ is analytic, we show the error rate of USVT is at most \$\textbackslash log\^d (n\textbackslash rho)/(n\textbackslash rho)\$. In the special case of stochastic block model with \$k\$ blocks, the error rate of USVT is at most \$k/(n\textbackslash rho)\$, which is larger than the minimax optimal error rate by at most a multiplicative factor \$k/\textbackslash log k\$. This coincides with the computational gap observed for community detection. A key step of our analysis is to derive the eigenvalue decaying rate of the edge probability matrix using piecewise polynomial approximations of the graphon function \$f\$.},
  archivePrefix = {arXiv},
  eprint = {1709.03183},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Xu (2017) - Rates of Convergence of Spectral Methods for Graphon Estimation.pdf},
  journal = {arXiv:1709.03183 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@inproceedings{xu2019Achieving,
  title = {Achieving {{Causal Fairness}} through {{Generative Adversarial Networks}}},
  booktitle = {Proceedings of the {{Twenty}}-{{Eighth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Xu, Depeng and Wu, Yongkai and Yuan, Shuhan and Zhang, Lu and Wu, Xintao},
  year = {2019},
  month = aug,
  pages = {1452--1458},
  publisher = {{International Joint Conferences on Artificial Intelligence Organization}},
  address = {{Macao, China}},
  doi = {10.24963/ijcai.2019/201},
  abstract = {Achieving fairness in learning models is currently an imperative task in machine learning. Meanwhile, recent research showed that fairness should be studied from the causal perspective, and proposed a number of fairness criteria based on Pearl's causal modeling framework. In this paper, we investigate the problem of building causal fairnessaware generative adversarial networks (CFGAN), which can learn a close distribution from a given dataset, while also ensuring various causal fairness criteria based on a given causal graph. CFGAN adopts two generators, whose structures are purposefully designed to reflect the structures of causal graph and interventional graph. Therefore, the two generators can respectively simulate the underlying causal model that generates the real data, as well as the causal model after the intervention. On the other hand, two discriminators are used for producing a close-to-real distribution, as well as for achieving various fairness criteria based on causal quantities simulated by generators. Experiments on a real-world dataset show that CFGAN can generate high quality fair data.},
  file = {/Users/yuekai/Documents/zotero/Xu et al (2019) - Achieving Causal Fairness through Generative Adversarial Networks.pdf},
  isbn = {978-0-9992411-4-1},
  language = {en}
}

@inproceedings{xue2020Amortized,
  title = {Amortized {{Finite Element Analysis}} for {{Fast PDE}}-{{Constrained Optimization}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Xue, Tianju and Beatson, Alex and Adriaenssens, Sigrid and Adams, Ryan P},
  year = {2020},
  month = jul,
  pages = {10},
  abstract = {Optimizing the parameters of partial differential equations (PDEs), i.e., PDE-constrained optimization (PDE-CO), allows us to model natural systems from observations or perform rational design of structures with complicated mechanical, thermal, or electromagnetic properties. However, PDE-CO is often computationally prohibitive due to the need to solve the PDE\textemdash typically via finite element analysis (FEA)\textemdash at each step of the optimization procedure. In this paper we propose amortized finite element analysis (AmorFEA), in which a neural network learns to produce accurate PDE solutions, while preserving many of the advantages of traditional finite element methods. This network is trained to directly minimize the potential energy from which the PDE and finite element method are derived, avoiding the need to generate costly supervised training data by solving PDEs with traditional FEA. As FEA is a variational procedure, AmorFEA is a direct analogue to popular amortized inference approaches in latent variable models, with the finite element basis acting as the variational family. AmorFEA can perform PDE-CO without the need to repeatedly solve the associated PDE, accelerating optimization when compared to a traditional workflow using FEA and the adjoint method.},
  file = {/Users/yuekai/Documents/zotero/Xue et al (2020) - Amortized Finite Element Analysis for Fast PDE-Constrained Optimization.pdf},
  language = {en}
}

@inproceedings{xue2020Auditing,
  title = {Auditing {{ML Models}} for {{Individual Bias}} and {{Unfairness}}},
  booktitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Xue, Songkai and Yurochkin, Mikhail and Sun, Yuekai},
  year = {2020},
  month = jun,
  pages = {4552--4562},
  issn = {1938-7228},
  abstract = {We consider the task of auditing ML models for individual bias/unfairness. We formalize the task in an optimization problem and develop a suite of inferential tools for the optimal value. Our tools...},
  chapter = {Machine Learning},
  file = {/Users/yuekai/Documents/zotero/Xue et al (2020) - Auditing ML Models for Individual Bias and Unfairness.pdf},
  language = {en}
}

@article{yadav2019Fair,
  title = {Fair {{Learning}}-to-{{Rank}} from {{Implicit Feedback}}},
  author = {Yadav, Himank and Du, Zhengxiao and Joachims, Thorsten},
  year = {2019},
  month = nov,
  abstract = {Addressing unfairness in rankings has become an increasingly important problem due to the growing influence of rankings in critical decision making, yet existing learning-to-rank algorithms suffer from multiple drawbacks when learning fair ranking policies from implicit feedback. Some algorithms suffer from extrinsic reasons of unfairness due to inherent selection biases in implicit feedback leading to rich-get-richer dynamics. While those that address the biased nature of implicit feedback suffer from intrinsic reasons of unfairness due to the lack of explicit control over the allocation of exposure based on merit (i.e, relevance). In both cases, the learned ranking policy can be unfair and lead to suboptimal results. To this end, we propose a novel learning-to-rank framework, FULTR, that is the first to address both intrinsic and extrinsic reasons of unfairness when learning ranking policies from logged implicit feedback. Considering the needs of various applications, we define a class of amortized fairness of exposure constraints with respect to items based on their merit, and propose corresponding counterfactual estimators of disparity (aka unfairness) and utility that are also robust to click noise. Furthermore, we provide an efficient algorithm that optimizes both utility and fairness via a policy-gradient approach. To show that our proposed algorithm learns accurate and fair ranking policies from biased and noisy feedback, we provide empirical results beyond the theoretical justification of the framework.},
  archivePrefix = {arXiv},
  eprint = {1911.08054},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yadav et al (2019) - Fair Learning-to-Rank from Implicit Feedback.pdf},
  journal = {arXiv:1911.08054 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Information Retrieval,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{yadlowsky2018Bounds,
  title = {Bounds on the Conditional and Average Treatment Effect in the Presence of Unobserved Confounders},
  author = {Yadlowsky, Steve and Namkoong, Hongseok and Basu, Sanjay and Duchi, John and Tian, Lu},
  year = {2018},
  month = aug,
  abstract = {The causal effect of an intervention can not be consistently estimated when the treatment assignment is influenced by unknown confounding factors. However, we can still study the causal effect when the dependence of treatment assignment on unobserved confounding factors is bounded by performing a sensitivity analysis. In such a case, the treatment effect is partially identifiable in that the bound of the treatment effect is still estimable based on the observed data. Here, we propose a sensitivity analysis approach to bound the conditional average treatment effect over observed covariates under bounded selection on unobservables. Additionally, we propose a semi-parametric method to estimate bounds on the average treatment effect and derive confidence intervals for these bounds. Combining the confidence intervals of the lower and upper bound gives a confidence region that includes the average treatment effect when the bounded selection on unobservables holds. This method scales to settings where the dimension of observed covariates is too high to apply a traditional sensitivity analysis based on covariate matching. Finally, we provide evidence from simulations and real data to illustrate the accuracy of the confidence intervals and value of our approach in practical finite sample regimes.},
  archivePrefix = {arXiv},
  eprint = {1808.09521},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yadlowsky et al (2018) - Bounds on the conditional and average treatment effect in the presence of.pdf},
  journal = {arXiv:1808.09521 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{yaghini2019Disparate,
  title = {Disparate {{Vulnerability}}: On the {{Unfairness}} of {{Privacy Attacks Against Machine Learning}}},
  shorttitle = {Disparate {{Vulnerability}}},
  author = {Yaghini, Mohammad and Kulynych, Bogdan and Troncoso, Carmela},
  year = {2019},
  month = jun,
  abstract = {A membership inference attack (MIA) against a machine learning model enables an attacker to determine whether a given data record was part of the model's training dataset or not. Such attacks have been shown to be practical both in centralized and federated settings, and pose a threat in many privacy-sensitive domains such as medicine or law enforcement. In the literature, the effectiveness of these attacks is invariably reported using metrics computed across the whole population. In this paper, we take a closer look at the attack's performance across different subgroups present in the data distributions. We introduce a framework that enables us to efficiently analyze the vulnerability of machine learning models to MIA. We discover that even if the accuracy of MIA looks no better than random guessing over the whole population, subgroups are subject to disparate vulnerability, i.e., certain subgroups can be significantly more vulnerable than others. We provide a theoretical definition for MIA vulnerability which we validate empirically both on synthetic and real data.},
  archivePrefix = {arXiv},
  eprint = {1906.00389},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yaghini et al (2019) - Disparate Vulnerability.pdf},
  journal = {arXiv:1906.00389 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{yang1991Monte,
  title = {A {{Monte Carlo Method}} for {{Sensitivity Analysis}} and {{Parametric Optimization}} of {{Nonlinear Stochastic Systems}}},
  author = {Yang, Jichuan and Kushner, Harold J.},
  year = {1991},
  month = sep,
  volume = {29},
  pages = {1216--1249},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0363-0129},
  doi = {10.1137/0329064},
  abstract = {For high-dimensional or nonlinear problems there are serious limitations on the power of available computational methods for the optimization or parametric optimization of stochastic systems. The paper develops an effective Monte Carlo method for obtaining good estimators of systems sensitivities with respect to system parameters under quite general conditions on the systems and cost functions. The value of the method is borne out by numerical experiments, and the computational requirements are favorable with respect to competing methods when the dimension is high or the nonlinearities ``severe.'' The method is a type of ``derivative of likelihood ratio'' method. Jump-diffusion, functional diffusion, and reflected diffusion models of broad types are covered by the basic technique (e.g., the type of limit model that arises in the analysis of queueing systems under heavy traffic, where the boundary reflection conditions are discontinuous). For a wide class of problems, the cost function or dynamics need not be smooth in the state variables; for example, where the cost is the probability of an event or ``sign'' functions appear in the dynamics. Under appropriate conditions, it is shown that the cost functions are differentiable with respect to the parameters. Since the basic diffusion (or other) model cannot be simulated exactly, two types of readily simulatable approximations are discussed in detail, and estimators of the derivatives of the cost functions for these approximations are obtained and analyzed. It is shown that these estimators and their expectations converge to those for the original problem. Thus, a robustness result for the sensitivity estimators, namely that the derivatives of the cost functions (and their estimators) for the simulatable approximations converge to those for the approximated process is proven. Such results are essential, in any case, if a simulation-based method is to be used with confidence.},
  file = {/Users/yuekai/Documents/zotero/Yang, Kushner (1991) - A Monte Carlo Method for Sensitivity Analysis and Parametric Optimization of.pdf},
  journal = {SIAM Journal on Control and Optimization},
  number = {5}
}

@article{yang2015Randomized,
  title = {Randomized Sketches for Kernels: {{Fast}} and Optimal Non-Parametric Regression},
  shorttitle = {Randomized Sketches for Kernels},
  author = {Yang, Yun and Pilanci, Mert and Wainwright, Martin J.},
  year = {2015},
  month = jan,
  abstract = {Kernel ridge regression (KRR) is a standard method for performing non-parametric regression over reproducing kernel Hilbert spaces. Given \$n\$ samples, the time and space complexity of computing the KRR estimate scale as \$\textbackslash mathcal\{O\}(n\^3)\$ and \$\textbackslash mathcal\{O\}(n\^2)\$ respectively, and so is prohibitive in many cases. We propose approximations of KRR based on \$m\$-dimensional randomized sketches of the kernel matrix, and study how small the projection dimension \$m\$ can be chosen while still preserving minimax optimality of the approximate KRR estimate. For various classes of randomized sketches, including those based on Gaussian and randomized Hadamard matrices, we prove that it suffices to choose the sketch dimension \$m\$ proportional to the statistical dimension (modulo logarithmic factors). Thus, we obtain fast and minimax optimal approximations to the KRR estimate for non-parametric regression.},
  archivePrefix = {arXiv},
  eprint = {1501.06195},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yang et al (2015) - Randomized sketches for kernels.pdf},
  journal = {arXiv:1501.06195 [cs, stat]},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@incollection{yang2016Featuredistributed,
  title = {Feature-Distributed Sparse Regression: A Screen-and-Clean Approach},
  shorttitle = {Feature-Distributed Sparse Regression},
  booktitle = {Advances in {{Neural Information Processing Systems}} 29},
  author = {Yang, Jiyan and Mahoney, Michael W and Saunders, Michael and Sun, Yuekai},
  editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
  year = {2016},
  pages = {2712--2720},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/yuekai/Documents/zotero/Yang et al (2016) - Feature-distributed sparse regression.pdf}
}

@article{yang2017Stein,
  title = {On {{Stein}}'s {{Identity}} and {{Near}}-{{Optimal Estimation}} in {{High}}-Dimensional {{Index Models}}},
  author = {Yang, Zhuoran and Balasubramanian, Krishnakumar and Liu, Han},
  year = {2017},
  month = sep,
  abstract = {We consider estimating the parametric components of semi-parametric multiple index models in a high-dimensional and non-Gaussian setting. Such models form a rich class of non-linear models with applications to signal processing, machine learning and statistics. Our estimators leverage the score function based first and second-order Stein's identities and do not require the covariates to satisfy Gaussian or elliptical symmetry assumptions common in the literature. Moreover, to handle score functions and responses that are heavy-tailed, our estimators are constructed via carefully thresholding their empirical counterparts. We show that our estimator achieves near-optimal statistical rate of convergence in several settings. We supplement our theoretical results via simulation experiments that confirm the theory.},
  archivePrefix = {arXiv},
  eprint = {1709.08795},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yang et al (2017) - On Stein's Identity and Near-Optimal Estimation in High-dimensional Index Models.pdf},
  journal = {arXiv:1709.08795 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{yang2018Estimating,
  title = {Estimating {{Time}}-{{Varying Graphical Models}}},
  author = {Yang, Jilei and Peng, Jie},
  year = {2018},
  month = apr,
  abstract = {In this paper, we study time-varying graphical models based on data measured over a temporal grid. Such models are motivated by the needs to describe and understand evolving interacting relationships among a set of random variables in many real applications, for instance the study of how stocks interact with each other and how such interactions change over time. We propose a new model, LOcal Group Graphical Lasso Estimation (loggle), under the assumption that the graph topology changes gradually over time. Specifically, loggle uses a novel local group-lasso type penalty to efficiently incorporate information from neighboring time points and to impose structural smoothness of the graphs. We implement an ADMM based algorithm to fit the loggle model. This algorithm utilizes blockwise fast computation and pseudo-likelihood approximation to improve computational efficiency. An R package loggle has also been developed. We evaluate the performance of loggle by simulation experiments. We also apply loggle to S\&P 500 stock price data and demonstrate that loggle is able to reveal the interacting relationships among stocks and among industrial sectors in a time period that covers the recent global financial crisis.},
  archivePrefix = {arXiv},
  eprint = {1804.03811},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yang, Peng (2018) - Estimating Time-Varying Graphical Models.pdf},
  journal = {arXiv:1804.03811 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{yang2019Adversarial,
  title = {Adversarial {{Examples}} for {{Non}}-{{Parametric Methods}}: {{Attacks}}, {{Defenses}} and {{Large Sample Limits}}},
  shorttitle = {Adversarial {{Examples}} for {{Non}}-{{Parametric Methods}}},
  author = {Yang, Yao-Yuan and Rashtchian, Cyrus and Wang, Yizhen and Chaudhuri, Kamalika},
  year = {2019},
  month = jun,
  abstract = {Adversarial examples have received a great deal of recent attention because of their potential to uncover security flaws in machine learning systems. However, most prior work on adversarial examples has been on parametric classifiers, for which generic attack and defense methods are known; non-parametric methods have been only considered on an ad-hoc or classifier-specific basis. In this work, we take a holistic look at adversarial examples for non-parametric methods. We first provide a general region-based attack that applies to a wide range of classifiers, including nearest neighbors, decision trees, and random forests. Motivated by the close connection between non-parametric methods and the Bayes Optimal classifier, we next exhibit a robust analogue to the Bayes Optimal, and we use it to motivate a novel and generic defense that we call adversarial pruning. We empirically show that the region-based attack and adversarial pruning defense are either better than or competitive with existing attacks and defenses for non-parametric methods, while being considerably more generally applicable.},
  archivePrefix = {arXiv},
  eprint = {1906.03310},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yang et al (2019) - Adversarial Examples for Non-Parametric Methods.pdf},
  journal = {arXiv:1906.03310 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{yang2019Conditional,
  title = {Conditional {{Density Estimation}}, {{Latent Variable Discovery}} and {{Optimal Transport}}},
  author = {Yang, Hongkang and Tabak, Esteban G},
  year = {2019},
  month = oct,
  pages = {39},
  abstract = {A framework is proposed that addresses both conditional density estimation and latent variable discovery. The objective function maximizes explanation of variability in the data, achieved through the optimal transport barycenter generalized to a collection of conditional distributions indexed by a covariate \textendash either given or latent\textendash{} in any suitable space. Theoretical results establish the existence of barycenters, a minimax formulation of optimal transport maps, and a general characterization of variability via the optimal transport cost. This framework leads to a family of non-parametric neural network-based algorithms, the BaryNet, with a supervised version that estimates conditional distributions and an unsupervised version that assigns latent variables. The efficacy of BaryNets is demonstrated by tests on both artificial and real-world data sets. A parallel drawn between autoencoders and the barycenter framework leads to the Barycentric autoencoder algorithm (BAE).},
  file = {/Users/yuekai/Documents/zotero/Yang, Tabak (2019) - Conditional Density Estimation, Latent Variable Discovery and Optimal Transport.pdf},
  language = {en}
}

@article{yang2019DynamicME,
  title = {{{DynamicME}}: Dynamic Simulation and Refinement of Integrated Models of Metabolism and Protein Expression},
  shorttitle = {{{DynamicME}}},
  author = {Yang, Laurence and Ebrahim, Ali and Lloyd, Colton J. and Saunders, Michael A. and Palsson, Bernhard O.},
  year = {2019},
  month = dec,
  volume = {13},
  pages = {2},
  issn = {1752-0509},
  doi = {10.1186/s12918-018-0675-6},
  abstract = {Background: Genome-scale models of metabolism and macromolecular expression (ME models) enable systems-level computation of proteome allocation coupled to metabolic phenotype.
Results: We develop DynamicME, an algorithm enabling time-course simulation of cell metabolism and protein expression. DynamicME correctly predicted the substrate utilization hierarchy on a mixed carbon substrate medium. We also found good agreement between predicted and measured time-course expression profiles. ME models involve considerably more parameters than metabolic models (M models). We thus generate an ensemble of models (each model having its rate constants perturbed), and then analyze the models by identifying archetypal time-course metabolite concentration profiles. Furthermore, we use a metaheuristic optimization method to calibrate ME model parameters using time-course measurements such as from a (fed-) batch culture. Finally, we show that constraints on protein concentration dynamics (``inertia'') alter the metabolic response to environmental fluctuations, including increased substrate-level phosphorylation and lowered oxidative phosphorylation.
Conclusions: Overall, DynamicME provides a novel method for understanding proteome allocation and metabolism under complex and transient environments, and to utilize time-course cell culture data for model-based interpretation or model refinement.},
  file = {/Users/yuekai/Documents/zotero/Yang et al (2019) - DynamicME.pdf},
  journal = {BMC Systems Biology},
  language = {en},
  number = {1}
}

@article{yang2019Fairer,
  title = {Towards {{Fairer Datasets}}: {{Filtering}} and {{Balancing}} the {{Distribution}} of the {{People Subtree}} in the {{ImageNet Hierarchy}}},
  shorttitle = {Towards {{Fairer Datasets}}},
  author = {Yang, Kaiyu and Qinami, Klint and {Fei-Fei}, Li and Deng, Jia and Russakovsky, Olga},
  year = {2019},
  month = dec,
  doi = {10.1145/3351095.3375709},
  abstract = {Computer vision technology is being used by many but remains representative of only a few. People have reported misbehavior of computer vision models, including offensive prediction results and lower performance for underrepresented groups. Current computer vision models are typically developed using datasets consisting of manually annotated images or videos; the data and label distributions in these datasets are critical to the models' behavior. In this paper, we examine ImageNet, a large-scale ontology of images that has spurred the development of many modern computer vision methods. We consider three key factors within the "person" subtree of ImageNet that may lead to problematic behavior in downstream computer vision technology: (1) the stagnant concept vocabulary of WordNet, (2) the attempt at exhaustive illustration of all categories with images, and (3) the inequality of representation in the images within concepts. We seek to illuminate the root causes of these concerns and take the first steps to mitigate them constructively.},
  archivePrefix = {arXiv},
  eprint = {1912.07726},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yang et al (2019) - Towards Fairer Datasets.pdf},
  journal = {arXiv:1912.07726 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryClass = {cs}
}

@article{yang2019Invarianceinducing,
  title = {Invariance-Inducing Regularization Using Worst-Case Transformations Suffices to Boost Accuracy and Spatial Robustness},
  author = {Yang, Fanny and Wang, Zuowen and {Heinze-Deml}, Christina},
  year = {2019},
  month = jun,
  abstract = {This work provides theoretical and empirical evidence that invariance-inducing regularizers can increase predictive accuracy for worst-case spatial transformations (spatial robustness). Evaluated on these adversarially transformed examples, we demonstrate that adding regularization on top of standard or adversarial training reduces the relative error by 20\% for CIFAR10 without increasing the computational cost. This outperforms handcrafted networks that were explicitly designed to be spatial-equivariant. Furthermore, we observe for SVHN, known to have inherent variance in orientation, that robust training also improves standard accuracy on the test set. We prove that this no-trade-off phenomenon holds for adversarial examples from transformation groups in the infinite data limit.},
  archivePrefix = {arXiv},
  eprint = {1906.11235},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yang et al (2019) - Invariance-inducing regularization using worst-case transformations suffices to.pdf},
  journal = {arXiv:1906.11235 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{yang2019SWALP,
  title = {{{SWALP}} : {{Stochastic Weight Averaging}} in {{Low}}-{{Precision Training}}},
  shorttitle = {{{SWALP}}},
  author = {Yang, Guandao and Zhang, Tianyi and Kirichenko, Polina and Bai, Junwen and Wilson, Andrew Gordon and De Sa, Christopher},
  year = {2019},
  month = apr,
  abstract = {Low precision operations can provide scalability, memory savings, portability, and energy efficiency. This paper proposes SWALP, an approach to low precision training that averages low-precision SGD iterates with a modified learning rate schedule. SWALP is easy to implement and can match the performance of full-precision SGD even with all numbers quantized down to 8 bits, including the gradient accumulators. Additionally, we show that SWALP converges arbitrarily close to the optimal solution for quadratic objectives, and to a noise ball asymptotically smaller than low precision SGD in strongly convex settings.},
  archivePrefix = {arXiv},
  eprint = {1904.11943},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yang et al (2019) - SWALP.pdf},
  journal = {arXiv:1904.11943 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@incollection{yao2018Representation,
  title = {Representation {{Learning}} for {{Treatment Effect Estimation}} from {{Observational Data}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 31},
  author = {Yao, Liuyi and Li, Sheng and Li, Yaliang and Huai, Mengdi and Gao, Jing and Zhang, Aidong},
  editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and {Cesa-Bianchi}, N. and Garnett, R.},
  year = {2018},
  pages = {2633--2643},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/yuekai/Documents/zotero/Yao et al (2018) - Representation Learning for Treatment Effect Estimation from Observational Data.pdf}
}

@article{yao2020Survey,
  title = {A {{Survey}} on {{Causal Inference}}},
  author = {Yao, Liuyi and Chu, Zhixuan and Li, Sheng and Li, Yaliang and Gao, Jing and Zhang, Aidong},
  year = {2020},
  month = feb,
  abstract = {Causal inference is a critical research topic across many domains, such as statistics, computer science, education, public policy and economics, for decades. Nowadays, estimating causal effect from observational data has become an appealing research direction owing to the large amount of available data and low budget requirement, compared with randomized controlled trials. Embraced with the rapidly developed machine learning area, various causal effect estimation methods for observational data have sprung up. In this survey, we provide a comprehensive review of causal inference methods under the potential outcome framework, one of the well known causal inference framework. The methods are divided into two categories depending on whether they require all three assumptions of the potential outcome framework or not. For each category, both the traditional statistical methods and the recent machine learning enhanced methods are discussed and compared. The plausible applications of these methods are also presented, including the applications in advertising, recommendation, medicine and so on. Moreover, the commonly used benchmark datasets as well as the open-source codes are also summarized, which facilitate researchers and practitioners to explore, evaluate and apply the causal inference methods.},
  archivePrefix = {arXiv},
  eprint = {2002.02770},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yao et al (2020) - A Survey on Causal Inference.pdf},
  journal = {arXiv:2002.02770 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {cs, stat}
}

@article{ye2019Learning,
  title = {Learning {{Classifier Synthesis}} for {{Generalized Few}}-{{Shot Learning}}},
  author = {Ye, Han-Jia and Hu, Hexiang and Zhan, De-Chuan and Sha, Fei},
  year = {2019},
  month = jun,
  abstract = {Visual recognition in real-world requires handling long-tailed and even open-ended data. It is a practical utility of a visual system to reliably recognizing the populated "head" visual concepts and meanwhile to learn about "tail" categories of few instances. Class-balanced many-shot learning and few-shot learning tackle one side of this challenging problem, via either learning strong classifiers for populated categories or few-shot classifiers for the tail classes. In this paper, we investigate the problem of generalized few-shot learning, where recognition on the head and the tail are performed jointly. We propose a neural dictionary-based ClAssifier SynThesis LEarning (CASTLE) approach to synthesizes the calibrated "tail" classifiers in addition to the multi-class "head" classifiers, and simultaneously recognizes the head and tail visual categories in a global discerning framework. CASTLE has demonstrated superior performances across different learning scenarios, i.e., many-shot learning, few-shot learning, and generalized few-shot learning, on two standard benchmark datasets --- MiniImageNet and TieredImageNet.},
  archivePrefix = {arXiv},
  eprint = {1906.02944},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Ye et al (2019) - Learning Classifier Synthesis for Generalized Few-Shot Learning.pdf},
  journal = {arXiv:1906.02944 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{ye2020Stein,
  title = {Stein {{Self}}-{{Repulsive Dynamics}}: {{Benefits From Past Samples}}},
  shorttitle = {Stein {{Self}}-{{Repulsive Dynamics}}},
  author = {Ye, Mao and Ren, Tongzheng and Liu, Qiang},
  year = {2020},
  month = feb,
  abstract = {We propose a new Stein self-repulsive dynamics for obtaining diversified
samples from intractable un-normalized distributions. Our idea is to introduce
Stein variational gradient as a repulsive force to push the samples of Langevin
dynamics away from the past trajectories. This simple idea allows us to
significantly decrease the auto-correlation in Langevin dynamics and hence
increase the effective sample size. Importantly, as we establish in our
theoretical analysis, the asymptotic stationary distribution remains correct
even with the addition of the repulsive force, thanks to the special properties
of the Stein variational gradient. We perform extensive empirical studies of
our new algorithm, showing that our method yields much higher sample efficiency
and better uncertainty estimation than vanilla Langevin dynamics.},
  file = {/Users/yuekai/Documents/zotero/Ye et al (2020) - Stein Self-Repulsive Dynamics.pdf},
  language = {en}
}

@article{yen2010Treebased,
  title = {Tree-Based Object Tracking without Mobility Statistics in Wireless Sensor Networks},
  author = {Yen, Li-Hsing and Wu, Bang Ye and Yang, Chia-Cheng},
  year = {2010},
  month = jul,
  volume = {16},
  pages = {1263--1276},
  issn = {1022-0038, 1572-8196},
  doi = {10.1007/s11276-009-0201-2},
  abstract = {Object tracking in wireless sensor networks is to track mobile objects by scattered sensors. These sensors are typically organized into a tree to deliver report messages upon detecting object's move. Existing tree construction algorithms all require a mobility profile that characterizes the movement statistics of the target object. Mobility profiles are generally obtained based on historical running traces. The contribution of this work is twofold. We first show that the problem of finding an optimal message report tree that requires the least amount of report messages is NP-hard. We then propose analytic estimates of mobility profiles based on Markov-chain model. This profiling replaces an otherwise experimental process that generates and analyzes running traces. Simulation results show that the analytic profiling works well and can replace costly statistical profiling without noticeable performance degradation.},
  file = {/Users/yuekai/Documents/zotero/Yen et al (2010) - Tree-based object tracking without mobility statistics in wireless sensor.pdf},
  journal = {Wireless Networks},
  language = {en},
  number = {5}
}

@article{yeo2020Computational,
  title = {A {{Computational Model}} for {{Estimating}} the {{Progression}} of {{COVID}}-19 {{Cases}} in the {{US West}} and {{East Coasts}}},
  author = {Yeo, Yao Yu and Yeo, Yao-Rui and Yeo, Wan-Jin},
  year = {2020},
  month = mar,
  pages = {2020.03.24.20043026},
  publisher = {{Cold Spring Harbor Laboratory Press}},
  doi = {10.1101/2020.03.24.20043026},
  abstract = {{$<$}p{$>$}The ongoing coronavirus disease 2019 (COVID-19) pandemic is of global concern and has recently emerged in the US. In this paper, we construct a stochastic variant of the SEIR model to make a quasi-worst-case scenario prediction of the COVID-19 outbreak in the US West and East Coasts. The model is then fitted to current data and implemented using Runge-Kutta methods. Our computation results predict that the number of new cases would peak around mid-April and begin to abate by July, and that the number of cases of COVID-19 might be significantly mitigated by having greater numbers of functional testing kits available for screening. The model also showed how small changes in variables can make large differences in outcomes and highlights the importance of healthcare preparedness during pandemics.{$<$}/p{$>$}},
  copyright = {\textcopyright{} 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  file = {/Users/yuekai/Documents/zotero/Yeo et al (2020) - A Computational Model for Estimating the Progression of COVID-19 Cases in the.pdf},
  journal = {medRxiv},
  language = {en}
}

@article{yeom2018Hunting,
  title = {Hunting for {{Discriminatory Proxies}} in {{Linear Regression Models}}},
  author = {Yeom, Samuel and Datta, Anupam and Fredrikson, Matt},
  year = {2018},
  month = oct,
  abstract = {A machine learning model may exhibit discrimination when used to make decisions involving people. One potential cause for such outcomes is that the model uses a statistical proxy for a protected demographic attribute. In this paper we formulate a definition of proxy use for the setting of linear regression and present algorithms for detecting proxies. Our definition follows recent work on proxies in classification models, and characterizes a model's constituent behavior that: 1) correlates closely with a protected random variable, and 2) is causally influential in the overall behavior of the model. We show that proxies in linear regression models can be efficiently identified by solving a second-order cone program, and further extend this result to account for situations where the use of a certain input variable is justified as a `business necessity'. Finally, we present empirical results on two law enforcement datasets that exhibit varying degrees of racial disparity in prediction outcomes, demonstrating that proxies shed useful light on the causes of discriminatory behavior in models.},
  archivePrefix = {arXiv},
  eprint = {1810.07155},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yeom et al (2018) - Hunting for Discriminatory Proxies in Linear Regression Models.pdf},
  journal = {arXiv:1810.07155 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{yeom2019Discriminative,
  title = {Discriminative but {{Not Discriminatory}}: {{A Comparison}} of {{Fairness Definitions}} under {{Different Worldviews}}},
  shorttitle = {Discriminative but {{Not Discriminatory}}},
  author = {Yeom, Samuel and Tschantz, Michael Carl},
  year = {2019},
  month = sep,
  abstract = {We mathematically compare three competing definitions of group-level nondiscrimination: demographic parity, equalized odds, and calibration. Using the theoretical framework of Friedler et al., we study the properties of each definition under various worldviews, which are assumptions about how, if at all, the observed data is biased. We argue that different worldviews call for different definitions of fairness, and we specify the worldviews that, when combined with the desire to avoid a criterion for discrimination that we call disparity amplification, motivate demographic parity and equalized odds. In addition, we show that calibration is insufficient for avoiding disparity amplification because it allows an arbitrarily large inter-group disparity. Finally, we define a worldview that is more realistic than the previously considered ones, and we introduce a new notion of fairness that corresponds to this worldview.},
  archivePrefix = {arXiv},
  eprint = {1808.08619},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yeom, Tschantz (2019) - Discriminative but Not Discriminatory.pdf},
  journal = {arXiv:1808.08619 [cs, stat]},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{yin2018ByzantineRobust,
  title = {Byzantine-{{Robust Distributed Learning}}: {{Towards Optimal Statistical Rates}}},
  shorttitle = {Byzantine-{{Robust Distributed Learning}}},
  author = {Yin, Dong and Chen, Yudong and Ramchandran, Kannan and Bartlett, Peter},
  year = {2018},
  month = mar,
  abstract = {In large-scale distributed learning, security issues have become increasingly important. Particularly in a decentralized environment, some computing units may behave abnormally, or even exhibit Byzantine failures---arbitrary and potentially adversarial behavior. In this paper, we develop distributed learning algorithms that are provably robust against such failures, with a focus on achieving optimal statistical performance. A main result of this work is a sharp analysis of two robust distributed gradient descent algorithms based on median and trimmed mean operations, respectively. We prove statistical error rates for three kinds of population loss functions: strongly convex, non-strongly convex, and smooth non-convex. In particular, these algorithms are shown to achieve order-optimal statistical error rates for strongly convex losses. To achieve better communication efficiency, we further propose a median-based distributed algorithm that is provably robust, and uses only one communication round. For strongly convex quadratic loss, we show that this algorithm achieves the same optimal error rate as the robust distributed gradient descent algorithms.},
  archivePrefix = {arXiv},
  eprint = {1803.01498},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yin et al (2018) - Byzantine-Robust Distributed Learning.pdf},
  journal = {arXiv:1803.01498 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{yin2018Rademacher,
  title = {Rademacher {{Complexity}} for {{Adversarially Robust Generalization}}},
  author = {Yin, Dong and Ramchandran, Kannan and Bartlett, Peter},
  year = {2018},
  month = oct,
  abstract = {Many machine learning models are vulnerable to adversarial attacks. It has been observed that adding adversarial perturbations that are imperceptible to humans can make machine learning models produce wrong predictions with high confidence. Although there has been a lot of recent effort dedicated to learning models that are adversarially robust, this remains an open problem. In particular, it has been empirically observed that although using adversarial training can effectively reduce the adversarial classification error on the training dataset, the learned model cannot generalize well to the test data. Moreover, we lack a theoretical understanding of the generalization property of machine learning models in the adversarial setting. In this paper, we study the adversarially robust generalization problem through the lens of Rademacher complexity. We focus on \$\textbackslash ell\_\textbackslash infty\$ adversarial attacks and study both linear classifiers and feedforward neural networks. For binary linear classifiers, we prove tight bounds for the adversarial Rademacher complexity, and show that in the adversarial setting, the Rademacher complexity is never smaller than that in the natural setting, and it has an unavoidable dimension dependence, unless the weight vector has bounded \$\textbackslash ell\_1\$ norm. The results also extend to multi-class linear classifiers. For (nonlinear) neural networks, we show that the dimension dependence also exists in the Rademacher complexity of the \$\textbackslash ell\_\textbackslash infty\$ adversarial loss function class. We further consider a surrogate adversarial loss and prove margin bounds for this setting. Our results indicate that having \$\textbackslash ell\_1\$ norm constraints on the weight matrices might be a potential way to improve generalization in the adversarial setting.},
  archivePrefix = {arXiv},
  eprint = {1810.11914},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yin et al (2018) - Rademacher Complexity for Adversarially Robust Generalization.pdf},
  journal = {arXiv:1810.11914 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{yin2019Fourier,
  title = {A {{Fourier Perspective}} on {{Model Robustness}} in {{Computer Vision}}},
  author = {Yin, Dong and Lopes, Raphael Gontijo and Shlens, Jonathon and Cubuk, Ekin D. and Gilmer, Justin},
  year = {2019},
  month = oct,
  abstract = {Achieving robustness to distributional shift is a longstanding and challenging goal of computer vision. Data augmentation is a commonly used approach for improving robustness, however robustness gains are typically not uniform across corruption types. Indeed increasing performance in the presence of random noise is often met with reduced performance on other corruptions such as contrast change. Understanding when and why these sorts of trade-offs occur is a crucial step towards mitigating them. Towards this end, we investigate recently observed trade-offs caused by Gaussian data augmentation and adversarial training. We find that both methods improve robustness to corruptions that are concentrated in the high frequency domain while reducing robustness to corruptions that are concentrated in the low frequency domain. This suggests that one way to mitigate these trade-offs via data augmentation is to use a more diverse set of augmentations. Towards this end we observe that AutoAugment, a recently proposed data augmentation policy optimized for clean accuracy, achieves state-of-the-art robustness on the CIFAR-10-C benchmark.},
  archivePrefix = {arXiv},
  eprint = {1906.08988},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yin et al (2019) - A Fourier Perspective on Model Robustness in Computer Vision.pdf},
  journal = {arXiv:1906.08988 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{yoo2016KAKUTANI,
  title = {{{KAKUTANI}}'{{S FIXED POINT THEOREM AND THE MINIMAX THEOREM IN GAME THEORY}}},
  author = {Yoo, Younggeun},
  year = {2016},
  month = jul,
  pages = {9},
  abstract = {The minimax theorem is one of the most important results in game theory. It was first introduced by John von Neumann in the paper Zur Theorie Der Gesellschaftsspiele. Later, John Forbes Nash Jr. provided an alternative proof of the minimax theorem using Brouwer's fixed point theorem. We describe in detail Kakutani's proof of the minimax theorem using Kakutani's fixed point theorem, and discuss applications of Kakutani's fixed point theorem to economics and the theory of zero-sum games.},
  file = {/Users/yuekai/Documents/zotero/Yoo (2016) - KAKUTANI’S FIXED POINT THEOREM AND THE MINIMAX THEOREM IN GAME THEORY.pdf},
  language = {en}
}

@article{yu2014useful,
  title = {A Useful Variant of the {{Davis}}--{{Kahan}} Theorem for Statisticians},
  author = {Yu, Yi and Wang, Tengyao and Samworth, Richard J.},
  year = {2014},
  month = may,
  abstract = {The Davis--Kahan theorem is used in the analysis of many statistical procedures to bound the distance between subspaces spanned by population eigenvectors and their sample versions. It relies on an eigenvalue separation condition between certain relevant population and sample eigenvalues. We present a variant of this result that depends only on a population eigenvalue separation condition, making it more natural and convenient for direct application in statistical contexts, and improving the bounds in some cases. We also provide an extension to situations where the matrices under study may be asymmetric or even non-square, and where interest is in the distance between subspaces spanned by corresponding singular vectors.},
  archivePrefix = {arXiv},
  eprint = {1405.0680},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yu et al (2014) - A useful variant of the Davis--Kahan theorem for statisticians.pdf},
  journal = {arXiv:1405.0680 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@article{yu2019Convergent,
  title = {Convergent {{Policy Optimization}} for {{Safe Reinforcement Learning}}},
  author = {Yu, Ming and Yang, Zhuoran and Kolar, Mladen and Wang, Zhaoran},
  year = {2019},
  month = oct,
  abstract = {We study the safe reinforcement learning problem with nonlinear function approximation, where policy optimization is formulated as a constrained optimization problem with both the objective and the constraint being nonconvex functions. For such a problem, we construct a sequence of surrogate convex constrained optimization problems by replacing the nonconvex functions locally with convex quadratic functions obtained from policy gradient estimators. We prove that the solutions to these surrogate problems converge to a stationary point of the original nonconvex problem. Furthermore, to extend our theoretical results, we apply our algorithm to examples of optimal control and multi-agent reinforcement learning with safety constraints.},
  archivePrefix = {arXiv},
  eprint = {1910.12156},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yu et al (2019) - Convergent Policy Optimization for Safe Reinforcement Learning.pdf},
  journal = {arXiv:1910.12156 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{yu2019Reinforcement,
  title = {Reinforcement {{Learning}} in {{Healthcare}}: {{A Survey}}},
  shorttitle = {Reinforcement {{Learning}} in {{Healthcare}}},
  author = {Yu, Chao and Liu, Jiming and Nemati, Shamim},
  year = {2019},
  month = aug,
  abstract = {As a subfield of machine learning, reinforcement learning (RL) aims at empowering one's capabilities in behavioural decision making by using interaction experience with the world and an evaluative feedback. Unlike traditional supervised learning methods that usually rely on one-shot, exhaustive and supervised reward signals, RL tackles with sequential decision making problems with sampled, evaluative and delayed feedback simultaneously. Such distinctive features make RL technique a suitable candidate for developing powerful solutions in a variety of healthcare domains, where diagnosing decisions or treatment regimes are usually characterized by a prolonged and sequential procedure. This survey will discuss the broad applications of RL techniques in healthcare domains, in order to provide the research community with systematic understanding of theoretical foundations, enabling methods and techniques, existing challenges, and new insights of this emerging paradigm. By first briefly examining theoretical foundations and key techniques in RL research from efficient and representational directions, we then provide an overview of RL applications in a variety of healthcare domains, ranging from dynamic treatment regimes in chronic diseases and critical care, automated medical diagnosis from both unstructured and structured clinical data, as well as many other control or scheduling domains that have infiltrated many aspects of a healthcare system. Finally, we summarize the challenges and open issues in current research, and point out some potential solutions and directions for future research.},
  archivePrefix = {arXiv},
  eprint = {1908.08796},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yu et al (2019) - Reinforcement Learning in Healthcare.pdf},
  journal = {arXiv:1908.08796 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  language = {en},
  primaryClass = {cs}
}

@article{yuan2007Model,
  title = {Model Selection and Estimation in the {{Gaussian}} Graphical Model},
  author = {Yuan, M. and Lin, Y.},
  year = {2007},
  month = feb,
  volume = {94},
  pages = {19--35},
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/asm018},
  abstract = {We propose penalized likelihood methods for estimating the concentration matrix in the Gaussian graphical model. The methods lead to a sparse and shrinkage estimator of the concentration matrix that is positive definite, and thus conduct model selection and estimation simultaneously. The implementation of the methods is nontrivial because of the positive definite constraint on the concentration matrix, but we show that the computation can be done effectively by taking advantage of the efficient maxdet algorithm developed in convex optimization. We propose a BIC-type criterion for the selection of the tuning parameter in the penalized likelihood methods. The connection between our methods and existing methods is illustrated. Simulations and real examples demonstrate the competitive performance of the new methods.},
  file = {/Users/yuekai/Documents/zotero/Yuan, Lin (2007) - Model selection and estimation in the Gaussian graphical model.pdf},
  journal = {Biometrika},
  language = {en},
  number = {1}
}

@article{yuan2014Partial,
  title = {Partial {{Gaussian Graphical Model Estimation}}},
  author = {Yuan, Xiao-Tong and Zhang, Tong},
  year = {2014},
  month = mar,
  volume = {60},
  pages = {1673--1687},
  issn = {1557-9654},
  doi = {10.1109/TIT.2013.2296784},
  abstract = {This paper studies the partial estimation of Gaussian graphical models from high-dimensional empirical observations. We derive a convex formulation for this problem using {$\mathscr{l}$}1-regularized maximum-likelihood estimation, which can be solved via a smoothing approximation algorithm. Statistical estimation performance can be established for our method. The proposed approach has competitive empirical performance compared with existing methods, as demonstrated by various experiments on synthetic and real data sets.},
  file = {/Users/yuekai/Documents/zotero/Yuan, Zhang (2014) - Partial Gaussian Graphical Model Estimation.pdf;/Users/yuekai/Zotero/storage/UV9K3S23/6698361.html},
  journal = {IEEE Transactions on Information Theory},
  keywords = {conditional random fields,convex optimization,convex optimization formulation,convex programming,Covariance matrices,Gaussian graphical models,Gaussian processes,graph theory,Graphical models,high-dimensional empirical observations,ℓ1-regularized maximum-likelihood estimation,maximum likelihood estimation,Maximum likelihood estimation,multivariate regression,Multivariate regression,partial Gaussian graphical model estimation,real data sets,smoothing approximation algorithm,Sparse matrices,sparse recovery,statistical analysis,statistical estimation performance,synthetic data sets,Vectors},
  number = {3}
}

@article{yuan2017Adversarial,
  title = {Adversarial {{Examples}}: {{Attacks}} and {{Defenses}} for {{Deep Learning}}},
  shorttitle = {Adversarial {{Examples}}},
  author = {Yuan, Xiaoyong and He, Pan and Zhu, Qile and Li, Xiaolin},
  year = {2017},
  month = dec,
  abstract = {With rapid progress and significant successes in a wide spectrum of applications, deep learning is being applied in many safety-critical environments. However, deep neural networks have been recently found vulnerable to well-designed input samples, called adversarial examples. Adversarial examples are imperceptible to human but can easily fool deep neural networks in the testing/deploying stage. The vulnerability to adversarial examples becomes one of the major risks for applying deep neural networks in safety-critical environments. Therefore, attacks and defenses on adversarial examples draw great attention. In this paper, we review recent findings on adversarial examples for deep neural networks, summarize the methods for generating adversarial examples, and propose a taxonomy of these methods. Under the taxonomy, applications for adversarial examples are investigated. We further elaborate on countermeasures for adversarial examples and explore the challenges and the potential solutions.},
  archivePrefix = {arXiv},
  eprint = {1712.07107},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yuan et al (2017) - Adversarial Examples.pdf},
  journal = {arXiv:1712.07107 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{yurochkin2016Geometric,
  title = {Geometric {{Dirichlet Means}} Algorithm for Topic Inference},
  author = {Yurochkin, Mikhail and Nguyen, XuanLong},
  year = {2016},
  month = oct,
  abstract = {We propose a geometric algorithm for topic learning and inference that is built on the convex geometry of topics arising from the Latent Dirichlet Allocation (LDA) model and its nonparametric extensions. To this end we study the optimization of a geometric loss function, which is a surrogate to the LDA's likelihood. Our method involves a fast optimization based weighted clustering procedure augmented with geometric corrections, which overcomes the computational and statistical inefficiencies encountered by other techniques based on Gibbs sampling and variational inference, while achieving the accuracy comparable to that of a Gibbs sampler. The topic estimates produced by our method are shown to be statistically consistent under some conditions. The algorithm is evaluated with extensive experiments on simulated and real data.},
  archivePrefix = {arXiv},
  eprint = {1610.09034},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yurochkin, Nguyen (2016) - Geometric Dirichlet Means algorithm for topic inference.pdf},
  journal = {arXiv:1610.09034 [stat]},
  keywords = {Statistics - Machine Learning},
  primaryClass = {stat}
}

@article{yurochkin2019Bayesian,
  title = {Bayesian {{Nonparametric Federated Learning}} of {{Neural Networks}}},
  author = {Yurochkin, Mikhail and Agarwal, Mayank and Ghosh, Soumya and Greenewald, Kristjan and Hoang, Trong Nghia and Khazaeni, Yasaman},
  year = {2019},
  month = may,
  abstract = {In federated learning problems, data is scattered across different servers and exchanging or pooling it is often impractical or prohibited. We develop a Bayesian nonparametric framework for federated learning with neural networks. Each data server is assumed to provide local neural network weights, which are modeled through our framework. We then develop an inference approach that allows us to synthesize a more expressive global network without additional supervision, data pooling and with as few as a single communication round. We then demonstrate the efficacy of our approach on federated learning problems simulated from two popular image classification datasets.},
  archivePrefix = {arXiv},
  eprint = {1905.12022},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yurochkin et al (2019) - Bayesian Nonparametric Federated Learning of Neural Networks.pdf},
  journal = {arXiv:1905.12022 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{yurochkin2019Dirichlet,
  title = {Dirichlet {{Simplex Nest}} and {{Geometric Inference}}},
  author = {Yurochkin, Mikhail and Guha, Aritra and Sun, Yuekai and Nguyen, XuanLong},
  year = {2019},
  month = may,
  abstract = {We propose Dirichlet Simplex Nest, a class of probabilistic models suitable for a variety of data types, and develop fast and provably accurate inference algorithms by accounting for the model's convex geometry and low dimensional simplicial structure. By exploiting the connection to Voronoi tessellation and properties of Dirichlet distribution, the proposed inference algorithm is shown to achieve consistency and strong error bound guarantees on a range of model settings and data distributions. The effectiveness of our model and the learning algorithm is demonstrated by simulations and by analyses of text and financial data.},
  archivePrefix = {arXiv},
  eprint = {1905.11009},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yurochkin et al (2019) - Dirichlet Simplex Nest and Geometric Inference.pdf},
  journal = {arXiv:1905.11009 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{yurochkin2019Hierarchical,
  title = {Hierarchical {{Optimal Transport}} for {{Document Representation}}},
  author = {Yurochkin, Mikhail and Claici, Sebastian and Chien, Edward and Mirzazadeh, Farzaneh and Solomon, Justin},
  year = {2019},
  month = jun,
  abstract = {The ability to measure similarity between documents enables intelligent summarization and analysis of large corpora. Past distances between documents suffer from either an inability to incorporate semantic similarities between words or from scalability issues. As an alternative, we introduce hierarchical optimal transport as a meta-distance between documents, where documents are modeled as distributions over topics, which themselves are modeled as distributions over words. We then solve an optimal transport problem on the smaller topic space to compute a similarity score. We give conditions on the topics under which this construction defines a distance, and we relate it to the word mover's distance. We evaluate our technique for \$k\$-NN classification and show better interpretability and scalability with comparable performance to current methods at a fraction of the cost.},
  archivePrefix = {arXiv},
  eprint = {1906.10827},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yurochkin et al (2019) - Hierarchical Optimal Transport for Document Representation.pdf},
  journal = {arXiv:1906.10827 [cs, stat]},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@misc{yurochkin2019Sensitive,
  title = {Sensitive {{Subspace Robustness}} ({{SenSR}})},
  author = {Yurochkin, Mikhail and Bower, Amanda and Sun, Yuekai},
  year = {2019},
  month = jun,
  howpublished = {github.com/IBM/sensitive-subspace-robustness},
  journal = {IBM/sensitive-subspace-robustness}
}

@article{yurochkin2020SenSeI,
  title = {{{SenSeI}}: {{Sensitive Set Invariance}} for {{Enforcing Individual Fairness}}},
  shorttitle = {{{SenSeI}}},
  author = {Yurochkin, Mikhail and Sun, Yuekai},
  year = {2020},
  month = jun,
  abstract = {In this paper, we cast fair machine learning as invariant machine learning. We first formulate a version of individual fairness that enforces invariance on certain sensitive sets. We then design a transport-based regularizer that enforces this version of individual fairness and develop an algorithm to minimize the regularizer efficiently. Our theoretical results guarantee the proposed approach trains certifiably fair ML models. Finally, in the experimental studies we demonstrate improved fairness metrics in comparison to several recent fair training procedures on three ML tasks that are susceptible to algorithmic bias.},
  archivePrefix = {arXiv},
  eprint = {2006.14168},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Yurochkin, Sun (2020) - SenSeI.pdf},
  journal = {arXiv:2006.14168 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{yurochkin2020Training,
  title = {Training Individually Fair {{ML}} Models with Sensitive Subspace Robustness},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Yurochkin, Mikhail and Bower, Amanda and Sun, Yuekai},
  year = {2020},
  address = {{Addis Ababa, Ethiopia}},
  abstract = {We propose an approach to training machine learning models that are fair in the sense that their performance is invariant under certain perturbations to the features. For example, the performance...},
  file = {/Users/yuekai/Documents/zotero/Yurochkin et al (2019) - Training individually fair ML models with sensitive subspace robustness.pdf}
}

@article{zafar2015Fairness,
  title = {Fairness {{Constraints}}: {{Mechanisms}} for {{Fair Classification}}},
  shorttitle = {Fairness {{Constraints}}},
  author = {Zafar, Muhammad Bilal and Valera, Isabel and Rodriguez, Manuel Gomez and Gummadi, Krishna P.},
  year = {2015},
  month = jul,
  abstract = {Algorithmic decision making systems are ubiquitous across a wide variety of online as well as offline services. These systems rely on complex learning methods and vast amounts of data to optimize the service functionality, satisfaction of the end user and profitability. However, there is a growing concern that these automated decisions can lead, even in the absence of intent, to a lack of fairness, i.e., their outcomes can disproportionately hurt (or, benefit) particular groups of people sharing one or more sensitive attributes (e.g., race, sex). In this paper, we introduce a flexible mechanism to design fair classifiers by leveraging a novel intuitive measure of decision boundary (un)fairness. We instantiate this mechanism with two well-known classifiers, logistic regression and support vector machines, and show on real-world data that our mechanism allows for a fine-grained control on the degree of fairness, often at a small cost in terms of accuracy.},
  archivePrefix = {arXiv},
  eprint = {1507.05259},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zafar et al (2015) - Fairness Constraints.pdf},
  journal = {arXiv:1507.05259 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{zafar2017Fairness,
  title = {Fairness {{Beyond Disparate Treatment}} \& {{Disparate Impact}}: {{Learning Classification}} without {{Disparate Mistreatment}}},
  shorttitle = {Fairness {{Beyond Disparate Treatment}} \&amp; {{Disparate Impact}}},
  booktitle = {Proceedings of the 26th {{International Conference}} on {{World Wide Web}}},
  author = {Zafar, Muhammad Bilal and Valera, Isabel and Gomez Rodriguez, Manuel and Gummadi, Krishna P.},
  year = {2017},
  month = apr,
  pages = {1171--1180},
  publisher = {{International World Wide Web Conferences Steering Committee}},
  address = {{Perth, Australia}},
  doi = {10.1145/3038912.3052660},
  abstract = {Automated data-driven decision making systems are increasingly being used to assist, or even replace humans in many settings. These systems function by learning from historical decisions, often taken by humans. In order to maximize the utility of these systems (or, classifiers), their training involves minimizing the errors (or, misclassifications) over the given historical data. However, it is quite possible that the optimally trained classifier makes decisions for people belonging to different social groups with different misclassification rates (e.g., misclassification rates for females are higher than for males), thereby placing these groups at an unfair disadvantage. To account for and avoid such unfairness, in this paper, we introduce a new notion of unfairness, disparate mistreatment, which is defined in terms of misclassification rates. We then propose intuitive measures of disparate mistreatment for decision boundary-based classifiers, which can be easily incorporated into their formulation as convex-concave constraints. Experiments on synthetic as well as real world datasets show that our methodology is effective at avoiding disparate mistreatment, often at a small cost in terms of accuracy.},
  file = {/Users/yuekai/Documents/zotero/Zafar et al (2017) - Fairness Beyond Disparate Treatment & Disparate Impact.pdf},
  isbn = {978-1-4503-4913-0},
  keywords = {algorithmic decision making,discrimination in decision making,fair classification,fair decision making,machine learning and law},
  series = {{{WWW}} '17}
}

@article{zafar2019Fairness,
  title = {Fairness {{Constraints}}: {{A Flexible Approach}} for {{Fair Classification}}},
  shorttitle = {Fairness {{Constraints}}},
  author = {Zafar, Muhammad Bilal and Valera, Isabel and {Gomez-Rodriguez}, Manuel and Gummadi, Krishna P.},
  year = {2019},
  volume = {20},
  pages = {1--42},
  issn = {1533-7928},
  file = {/Users/yuekai/Documents/zotero/Zafar et al (2019) - Fairness Constraints.pdf},
  journal = {Journal of Machine Learning Research},
  number = {75}
}

@article{zaheer2017Deep,
  title = {Deep {{Sets}}},
  author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan and Smola, Alexander},
  year = {2017},
  month = mar,
  abstract = {We study the problem of designing models for machine learning tasks defined on \textbackslash emph\{sets\}. In contrast to traditional approach of operating on fixed dimensional vectors, we consider objective functions defined on sets that are invariant to permutations. Such problems are widespread, ranging from estimation of population statistics \textbackslash cite\{poczos13aistats\}, to anomaly detection in piezometer data of embankment dams \textbackslash cite\{Jung15Exploration\}, to cosmology \textbackslash cite\{Ntampaka16Dynamical,Ravanbakhsh16ICML1\}. Our main theorem characterizes the permutation invariant functions and provides a family of functions to which any permutation invariant objective function must belong. This family of functions has a special structure which enables us to design a deep network architecture that can operate on sets and which can be deployed on a variety of scenarios including both unsupervised and supervised learning tasks. We also derive the necessary and sufficient conditions for permutation equivariance in deep models. We demonstrate the applicability of our method on population statistic estimation, point cloud classification, set expansion, and outlier detection.},
  archivePrefix = {arXiv},
  eprint = {1703.06114},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zaheer et al (2017) - Deep Sets.pdf},
  journal = {arXiv:1703.06114 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{zajkowski2018Bounds,
  title = {Bounds on Tail Probabilities for Quadratic Forms in Dependent Sub-Gaussian Random Variables},
  author = {Zajkowski, Krzysztof},
  year = {2018},
  month = sep,
  abstract = {We show bounds on tail probabilities for quadratic forms in sub-gaussian not necessarily independent random variables. Our main tool will be estimates of the Luxemburg norms of such forms. This will allow us to formulate the above-mentioned bounds. As an example we give estimates of tail probabilities for quadratic forms in bounded martingale increments.},
  archivePrefix = {arXiv},
  eprint = {1809.08569},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zajkowski (2018) - Bounds on tail probabilities for quadratic forms in dependent sub-gaussian.pdf},
  journal = {arXiv:1809.08569 [math]},
  keywords = {Mathematics - Probability},
  primaryClass = {math}
}

@inproceedings{zehlike2020Reducing,
  title = {Reducing {{Disparate Exposure}} in {{Ranking}}: {{A Learning To Rank Approach}}},
  shorttitle = {Reducing {{Disparate Exposure}} in {{Ranking}}},
  booktitle = {Proceedings of {{The Web Conference}} 2020},
  author = {Zehlike, Meike and Castillo, Carlos},
  year = {2020},
  month = apr,
  pages = {2849--2855},
  publisher = {{Association for Computing Machinery}},
  address = {{Taipei, Taiwan}},
  doi = {10.1145/3366424.3380048},
  abstract = {Ranked search results have become the main mechanism by which we find content, products, places, and people online. Thus their ordering contributes not only to the satisfaction of the searcher, but also to career and business opportunities, educational placement, and even social success of those being ranked. Researchers have become increasingly concerned with systematic biases in data-driven ranking models, and various post-processing methods have been proposed to mitigate discrimination and inequality of opportunity. This approach, however, has the disadvantage that it still allows an unfair ranking model to be trained. In this paper we explore a new in-processing approach: DELTR, a learning-to-rank framework that addresses potential issues of discrimination and unequal opportunity in rankings at training time. We measure these problems in terms of discrepancies in the average group exposure and design a ranker that optimizes search results in terms of relevance and in terms of reducing such discrepancies. We perform an extensive experimental study showing that being ``colorblind'' can be among the best or the worst choices from the perspective of relevance and exposure, depending on how much and which kind of bias is present in the training set. We show that our in-processing method performs better in terms of relevance and exposure than a pre-processing and a post-processing method across all tested scenarios.},
  file = {/Users/yuekai/Documents/zotero/Zehlike, Castillo (2020) - Reducing Disparate Exposure in Ranking.pdf},
  isbn = {978-1-4503-7023-3},
  keywords = {Algorithmic Fairness,Disparate Impact,Ranking},
  series = {{{WWW}} '20}
}

@inproceedings{zemel2013Learning,
  title = {Learning {{Fair Representations}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Zemel, Rich and Wu, Yu and Swersky, Kevin and Pitassi, Toni and Dwork, Cynthia},
  year = {2013},
  month = feb,
  pages = {325--333},
  abstract = {We propose a learning algorithm for fair classification that achieves both group fairness (the proportion of members in a protected group receiving positive classification is identical to the propo...},
  file = {/Users/yuekai/Documents/zotero/Zemel et al (2013) - Learning Fair Representations.pdf},
  language = {en}
}

@article{zeng2017Interpretable,
  title = {Interpretable {{Classification Models}} for {{Recidivism Prediction}}},
  author = {Zeng, Jiaming and Ustun, Berk and Rudin, Cynthia},
  year = {2017},
  month = jun,
  volume = {180},
  pages = {689--722},
  issn = {09641998},
  doi = {10.1111/rssa.12227},
  abstract = {We investigate a long-debated question, which is how to create predictive models of recidivism that are sufficiently accurate, transparent, and interpretable to use for decision-making. This question is complicated as these models are used to support different decisions, from sentencing, to determining release on probation, to allocating preventative social services. Each use case might have an objective other than classification accuracy, such as a desired true positive rate (TPR) or false positive rate (FPR). Each (TPR, FPR) pair is a point on the receiver operator characteristic (ROC) curve. We use popular machine learning methods to create models along the full ROC curve on a wide range of recidivism prediction problems. We show that many methods (SVM, Ridge Regression) produce equally accurate models along the full ROC curve. However, methods that designed for interpretability (CART, C5.0) cannot be tuned to produce models that are accurate and/or interpretable. To handle this shortcoming, we use a new method known as SLIM (Supersparse Linear Integer Models) to produce accurate, transparent, and interpretable models along the full ROC curve. These models can be used for decision-making for many different use cases, since they are just as accurate as the most powerful black-box machine learning models, but completely transparent, and highly interpretable.},
  archivePrefix = {arXiv},
  eprint = {1503.07810},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zeng et al (2017) - Interpretable Classification Models for Recidivism Prediction.pdf},
  journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  keywords = {Statistics - Applications,Statistics - Machine Learning},
  number = {3}
}

@article{zhang1997EMPIRICAL,
  title = {{{EMPIRICAL BAYES AND COMPOUND ESTIMATION OF NORMAL MEANS}}},
  author = {Zhang, Cun-Hui},
  year = {1997},
  volume = {7},
  pages = {13},
  abstract = {This article concerns the canonical empirical Bayes problem of estimating normal means under squared-error loss. General empirical estimators are derived which are asymptotically minimax and optimal. Uniform convergence and the speed of convergence are considered. The general empirical Bayes estimators are compared with the shrinkage estimators of Stein (1956) and James and Stein (1961). Estimation of the mixture density and its derivatives are also discussed.},
  file = {/Users/yuekai/Documents/zotero/Zhang (1997) - EMPIRICAL BAYES AND COMPOUND ESTIMATION OF NORMAL MEANS.pdf},
  language = {en}
}

@article{zhang2003Compound,
  title = {Compound Decision Theory and Empirical {{Bayes}} Methods: Invited Paper},
  shorttitle = {Compound Decision Theory and Empirical {{Bayes}} Methods},
  author = {Zhang, Cun-Hui},
  year = {2003},
  month = apr,
  volume = {31},
  pages = {379--390},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/aos/1051027872},
  abstract = {Project Euclid - mathematics and statistics online},
  file = {/Users/yuekai/Documents/zotero/Zhang (2003) - Compound decision theory and empirical Bayes methods.pdf},
  journal = {The Annals of Statistics},
  language = {en},
  mrnumber = {MR1983534},
  number = {2}
}

@article{zhang2005Boosting,
  title = {Boosting with Early Stopping: {{Convergence}} and Consistency},
  shorttitle = {Boosting with Early Stopping},
  author = {Zhang, Tong and Yu, Bin},
  year = {2005},
  month = aug,
  volume = {33},
  pages = {1538--1579},
  issn = {0090-5364},
  doi = {10.1214/009053605000000255},
  abstract = {Boosting is one of the most significant advances in machine learning for classification and regression. In its original and computationally flexible version, boosting seeks to minimize empirically a loss function in a greedy fashion. The resulting estimator takes an additive function form and is built iteratively by applying a base estimator (or learner) to updated samples depending on the previous iterations. An unusual regularization technique, early stopping, is employed based on CV or a test set. This paper studies numerical convergence, consistency and statistical rates of convergence of boosting with early stopping, when it is carried out over the linear span of a family of basis functions. For general loss functions, we prove the convergence of boosting's greedy optimization to the infinimum of the loss function over the linear span. Using the numerical convergence result, we find early-stopping strategies under which boosting is shown to be consistent based on i.i.d. samples, and we obtain bounds on the rates of convergence for boosting estimators. Simulation studies are also presented to illustrate the relevance of our theoretical results for providing insights to practical aspects of boosting. As a side product, these results also reveal the importance of restricting the greedy search step-sizes, as known in practice through the work of Friedman and others. Moreover, our results lead to a rigorous proof that for a linearly separable problem, AdaBoost with \textbackslash epsilon\textbackslash to0 step-size becomes an L\^1-margin maximizer when left to run to convergence.},
  archivePrefix = {arXiv},
  eprint = {math/0508276},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhang, Yu (2005) - Boosting with early stopping.pdf},
  journal = {The Annals of Statistics},
  keywords = {Mathematics - Statistics Theory},
  number = {4}
}

@inproceedings{zhang2010Learning,
  title = {Learning {{Multiple Tasks}} with a {{Sparse Matrix}}-Normal {{Penalty}}},
  booktitle = {Proceedings of the 23rd {{International Conference}} on {{Neural Information Processing Systems}} - {{Volume}} 2},
  author = {Zhang, Yi and Schneider, Jeff},
  year = {2010},
  pages = {2550--2558},
  publisher = {{Curran Associates Inc.}},
  address = {{USA}},
  abstract = {In this paper, we propose a matrix-variate normal penalty with sparse inverse co-variances to couple multiple tasks. Learning multiple (parametric) models can be viewed as estimating a matrix of parameters, where rows and columns of the matrix correspond to tasks and features, respectively. Following the matrix-variate normal density, we design a penalty that decomposes the full covariance of matrix elements into the Kronecker product of row covariance and column covariance, which characterizes both task relatedness and feature representation. Several recently proposed methods are variants of the special cases of this formulation. To address the overfitting issue and select meaningful task and feature structures, we include sparse covariance selection into our matrix-normal regularization via {$\mathscr{l}$}1 penalties on task and feature inverse covariances. We empirically study the proposed method and compare with related models in two real-world problems: detecting landmines in multiple fields and recognizing faces between different subjects. Experimental results show that the proposed framework provides an effective and flexible way to model various different structures of multiple tasks.},
  file = {/Users/yuekai/Documents/zotero/Zhang, Schneider (2010) - Learning Multiple Tasks with a Sparse Matrix-normal Penalty.pdf},
  series = {{{NIPS}}'10}
}

@article{zhang2012Kernelbased,
  title = {Kernel-Based {{Conditional Independence Test}} and {{Application}} in {{Causal Discovery}}},
  author = {Zhang, Kun and Peters, Jonas and Janzing, Dominik and Schoelkopf, Bernhard},
  year = {2012},
  month = feb,
  abstract = {Conditional independence testing is an important problem, especially in Bayesian network learning and causal discovery. Due to the curse of dimensionality, testing for conditional independence of continuous variables is particularly challenging. We propose a Kernel-based Conditional Independence test (KCI-test), by constructing an appropriate test statistic and deriving its asymptotic distribution under the null hypothesis of conditional independence. The proposed method is computationally efficient and easy to implement. Experimental results show that it outperforms other methods, especially when the conditioning set is large or the sample size is not very large, in which case other methods encounter difficulties.},
  archivePrefix = {arXiv},
  eprint = {1202.3775},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhang et al (2012) - Kernel-based Conditional Independence Test and Application in Causal Discovery.pdf},
  journal = {arXiv:1202.3775 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{zhang2012Learning,
  title = {Learning {{Structural Changes}} of {{Gaussian Graphical Models}} in {{Controlled Experiments}}},
  author = {Zhang, Bai and Wang, Yue},
  year = {2012},
  month = mar,
  abstract = {Graphical models are widely used in scienti fic and engineering research to represent conditional independence structures between random variables. In many controlled experiments, environmental changes or external stimuli can often alter the conditional dependence between the random variables, and potentially produce significant structural changes in the corresponding graphical models. Therefore, it is of great importance to be able to detect such structural changes from data, so as to gain novel insights into where and how the structural changes take place and help the system adapt to the new environment. Here we report an effective learning strategy to extract structural changes in Gaussian graphical model using l1-regularization based convex optimization. We discuss the properties of the problem formulation and introduce an efficient implementation by the block coordinate descent algorithm. We demonstrate the principle of the approach on a numerical simulation experiment, and we then apply the algorithm to the modeling of gene regulatory networks under different conditions and obtain promising yet biologically plausible results.},
  archivePrefix = {arXiv},
  eprint = {1203.3532},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhang, Wang (2012) - Learning Structural Changes of Gaussian Graphical Models in Controlled.pdf},
  journal = {arXiv:1203.3532 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{zhang2017Causal,
  title = {A {{Causal Framework}} for {{Discovering}} and {{Removing Direct}} and {{Indirect Discrimination}}},
  booktitle = {Proceedings of the {{Twenty}}-{{Sixth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Zhang, Lu and Wu, Yongkai and Wu, Xintao},
  year = {2017},
  month = aug,
  pages = {3929--3935},
  publisher = {{International Joint Conferences on Artificial Intelligence Organization}},
  address = {{Melbourne, Australia}},
  doi = {10.24963/ijcai.2017/549},
  abstract = {In this paper, we investigate the problem of discovering both direct and indirect discrimination from the historical data, and removing the discriminatory effects before the data is used for predictive analysis (e.g., building classifiers). The main drawback of existing methods is that they cannot distinguish the part of influence that is really caused by discrimination from all correlated influences. In our approach, we make use of the causal network to capture the causal structure of the data. Then we model direct and indirect discrimination as the path-specific effects, which accurately identify the two types of discrimination as the causal effects transmitted along different paths in the network. Based on that, we propose an effective algorithm for discovering direct and indirect discrimination, as well as an algorithm for precisely removing both types of discrimination while retaining good data utility. Experiments using the real dataset show the effectiveness of our approaches.},
  file = {/Users/yuekai/Documents/zotero/Zhang et al (2017) - A Causal Framework for Discovering and Removing Direct and Indirect.pdf},
  isbn = {978-0-9992411-0-3},
  language = {en}
}

@article{zhang2017Networkbased,
  title = {Network-Based Machine Learning and Graph Theory Algorithms for Precision Oncology},
  author = {Zhang, Wei and Chien, Jeremy and Yong, Jeongsik and Kuang, Rui},
  year = {2017},
  month = aug,
  volume = {1},
  pages = {1--15},
  publisher = {{Nature Publishing Group}},
  issn = {2397-768X},
  doi = {10.1038/s41698-017-0029-7},
  abstract = {Network-based analytics plays an increasingly important role in precision oncology. Growing evidence in recent studies suggests that cancer can be better understood through mutated or dysregulated pathways or networks rather than individual mutations and that the efficacy of repositioned drugs can be inferred from disease modules in molecular networks. This article reviews network-based machine learning and graph theory algorithms for integrative analysis of personal genomic data and biomedical knowledge bases to identify tumor-specific molecular mechanisms, candidate targets and repositioned drugs for personalized treatment. The review focuses on the algorithmic design and mathematical formulation of these methods to facilitate applications and implementations of network-based analysis in the practice of precision oncology. We review the methods applied in three scenarios to integrate genomic data and network models in different analysis pipelines, and we examine three categories of network-based approaches for repositioning drugs in drug\textendash disease\textendash gene networks. In addition, we perform a comprehensive subnetwork/pathway analysis of mutations in 31 cancer genome projects in the Cancer Genome Atlas and present a detailed case study on ovarian cancer. Finally, we discuss interesting observations, potential pitfalls and future directions in network-based precision oncology.},
  copyright = {2017 The Author(s)},
  file = {/Users/yuekai/Documents/zotero/Zhang et al (2017) - Network-based machine learning and graph theory algorithms for precision.pdf},
  journal = {npj Precision Oncology},
  language = {en},
  number = {1}
}

@incollection{zhang2018Endtoend,
  title = {End-to-End {{Symmetry Preserving Inter}}-Atomic {{Potential Energy Model}} for {{Finite}} and {{Extended Systems}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 31},
  author = {Zhang, Linfeng and Han, Jiequn and Wang, Han and Saidi, Wissam and Car, Roberto and E, Weinan},
  editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and {Cesa-Bianchi}, N. and Garnett, R.},
  year = {2018},
  pages = {4436--4446},
  publisher = {{Curran Associates, Inc.}},
  file = {/Users/yuekai/Documents/zotero/Zhang et al (2018) - End-to-end Symmetry Preserving Inter-atomic Potential Energy Model for Finite.pdf}
}

@article{zhang2018Joint,
  title = {Joint Association and Classification Analysis of Multi-View Data},
  author = {Zhang, Yunfeng and Gaynanova, Irina},
  year = {2018},
  month = nov,
  abstract = {Multi-view data, that is matched sets of measurements on the same subjects, have become increasingly common with technological advances in genomics and other fields. Often, the subjects are separated into known classes, and it is of interest to find associations between the views that are related to the class membership. Existing classification methods can either be applied to each view separately, or to the concatenated matrix of all views without taking into account between-views associations. On the other hand, existing association methods can not directly incorporate class information. In this work we propose a framework for Joint Association and Classification Analysis of multi-view data (JACA). We support the methodology with theoretical guarantees for estimation consistency in high-dimensional settings, and numerical comparisons with existing methods. In addition to joint learning framework, a distinct advantage of our approach is its ability to use partial information: it can be applied both in the settings with missing class labels, and in the settings with missing subsets of views. We apply JACA to colorectal cancer data from The Cancer Genome Atlas project, and quantify the association between RNAseq and miRNA views with respect to consensus molecular subtypes of colorectal cancer.},
  archivePrefix = {arXiv},
  eprint = {1811.08511},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhang, Gaynanova (2018) - Joint association and classification analysis of multi-view data.pdf},
  journal = {arXiv:1811.08511 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{zhang2018Mitigating,
  title = {Mitigating {{Unwanted Biases}} with {{Adversarial Learning}}},
  author = {Zhang, Brian Hu and Lemoine, Blake and Mitchell, Margaret},
  year = {2018},
  month = jan,
  abstract = {Machine learning is a tool for building models that accurately represent input training data. When undesired biases concerning demographic groups are in the training data, well-trained models will reflect those biases. We present a framework for mitigating such biases by including a variable for the group of interest and simultaneously learning a predictor and an adversary. The input to the network X, here text or census data, produces a prediction Y, such as an analogy completion or income bracket, while the adversary tries to model a protected variable Z, here gender or zip code. The objective is to maximize the predictor's ability to predict Y while minimizing the adversary's ability to predict Z. Applied to analogy completion, this method results in accurate predictions that exhibit less evidence of stereotyping Z. When applied to a classification task using the UCI Adult (Census) Dataset, it results in a predictive model that does not lose much accuracy while achieving very close to equality of odds (Hardt, et al., 2016). The method is flexible and applicable to multiple definitions of fairness as well as a wide range of gradient-based learning models, including both regression and classification tasks.},
  archivePrefix = {arXiv},
  eprint = {1801.07593},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhang et al (2018) - Mitigating Unwanted Biases with Adversarial Learning.pdf},
  journal = {arXiv:1801.07593 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{zhang2018Policy,
  title = {Policy {{Optimization}} as {{Wasserstein Gradient Flows}}},
  author = {Zhang, Ruiyi and Chen, Changyou and Li, Chunyuan and Carin, Lawrence},
  year = {2018},
  month = aug,
  abstract = {Policy optimization is a core component of reinforcement learning (RL), and most existing RL methods directly optimize parameters of a policy based on maximizing the expected total reward, or its surrogate. Though often achieving encouraging empirical success, its underlying mathematical principle on \{\textbackslash em policy-distribution\} optimization is unclear. We place policy optimization into the space of probability measures, and interpret it as Wasserstein gradient flows. On the probability-measure space, under specified circumstances, policy optimization becomes a convex problem in terms of distribution optimization. To make optimization feasible, we develop efficient algorithms by numerically solving the corresponding discrete gradient flows. Our technique is applicable to several RL settings, and is related to many state-of-the-art policy-optimization algorithms. Empirical results verify the effectiveness of our framework, often obtaining better performance compared to related algorithms.},
  archivePrefix = {arXiv},
  eprint = {1808.03030},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhang et al (2018) - Policy Optimization as Wasserstein Gradient Flows.pdf},
  journal = {arXiv:1808.03030 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{zhang2018Stackelberg,
  title = {Stackelberg {{GAN}}: {{Towards Provable Minimax Equilibrium}} via {{Multi}}-{{Generator Architectures}}},
  shorttitle = {Stackelberg {{GAN}}},
  author = {Zhang, Hongyang and Xu, Susu and Jiao, Jiantao and Xie, Pengtao and Salakhutdinov, Ruslan and Xing, Eric P.},
  year = {2018},
  month = nov,
  abstract = {We study the problem of alleviating the instability issue in the GAN training procedure via new architecture design. The discrepancy between the minimax and maximin objective values could serve as a proxy for the difficulties that the alternating gradient descent encounters in the optimization of GANs. In this work, we give new results on the benefits of multi-generator architecture of GANs. We show that the minimax gap shrinks to \$\textbackslash epsilon\$ as the number of generators increases with rate \$\textbackslash widetilde\{O\}(1/\textbackslash epsilon)\$. This improves over the best-known result of \$\textbackslash widetilde\{O\}(1/\textbackslash epsilon\^2)\$. At the core of our techniques is a novel application of Shapley-Folkman lemma to the generic minimax problem, where in the literature the technique was only known to work when the objective function is restricted to the Lagrangian function of a constraint optimization problem. Our proposed Stackelberg GAN performs well experimentally in both synthetic and real-world datasets, improving Fr\textbackslash 'echet Inception Distance by \$14.61\textbackslash\%\$ over the previous multi-generator GANs on the benchmark datasets.},
  archivePrefix = {arXiv},
  eprint = {1811.08010},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhang et al (2018) - Stackelberg GAN.pdf},
  journal = {arXiv:1811.08010 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{zhang2019Bridging,
  title = {Bridging {{Theory}} and {{Algorithm}} for {{Domain Adaptation}}},
  author = {Zhang, Yuchen and Liu, Tianle and Long, Mingsheng and Jordan, Michael I.},
  year = {2019},
  month = apr,
  abstract = {This paper addresses the problem of unsupervised domain adaption from theoretical and algorithmic perspectives. Existing domain adaptation theories naturally imply minimax optimization algorithms, which connect well with the adversarial-learning based domain adaptation methods. However, several disconnections still form the gap between theory and algorithm. We extend previous theories (Ben-David et al., 2010; Mansour et al., 2009c) to multiclass classification in domain adaptation, where classifiers based on scoring functions and margin loss are standard algorithmic choices. We introduce a novel measurement, margin disparity discrepancy, that is tailored both to distribution comparison with asymmetric margin loss, and to minimax optimization for easier training. Using this discrepancy, we derive new generalization bounds in terms of Rademacher complexity. Our theory can be seamlessly transformed into an adversarial learning algorithm for domain adaptation, successfully bridging the gap between theory and algorithm. A series of empirical studies show that our algorithm achieves the state-of-the-art accuracies on challenging domain adaptation tasks.},
  archivePrefix = {arXiv},
  eprint = {1904.05801},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhang et al (2019) - Bridging Theory and Algorithm for Domain Adaptation.pdf},
  journal = {arXiv:1904.05801 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@inproceedings{zhang2019Cyclical,
  title = {Cyclical {{Stochastic Gradient MCMC}} for {{Bayesian Deep Learning}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Zhang, Ruqi and Li, Chunyuan and Zhang, Jianyi and Chen, Changyou and Wilson, Andrew Gordon},
  year = {2019},
  month = sep,
  abstract = {The posteriors over neural network weights are high dimensional and multimodal. Each mode typically characterizes a meaningfully different representation of the data. We develop Cyclical Stochastic...},
  file = {/Users/yuekai/Documents/zotero/Zhang et al (2019) - Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning.pdf}
}

@article{zhang2019Long,
  title = {Long Term Impact of Fair Machine Learning in Sequential Decision Making: Representation Disparity and Group Retention},
  shorttitle = {Long Term Impact of Fair Machine Learning in Sequential Decision Making},
  author = {Zhang, Xueru and Khalili, Mohammad Mahdi and Tekin, Cem and Liu, Mingyan},
  year = {2019},
  month = may,
  abstract = {Machine learning models trained on data from multiple demographic groups can inherit representation disparity (Hashimoto et al., 2018) that may exist in the data: the group contributing less to the training process may suffer higher loss in model accuracy; this in turn can degrade population retention in these groups over time in terms of their contribution to the training process of future models, which then exacerbates representation disparity in the long run. In this study, we seek to understand the interplay between the model accuracy and the underlying group representation and how they evolve in a sequential decision setting over an infinite horizon, and how the use of fair machine learning plays a role in this process. Using a simple user dynamics (arrival and departure) model, we characterize the long-term property of using machine learning models under a set of fairness criteria imposed on each stage of the decision process, including the commonly used statistical parity and equal opportunity fairness. We show that under this particular arrival/departure model, both these criteria cause the representation disparity to worsen over time, resulting in groups diminishing entirely from the sample pool, while the criterion of equalized loss fares much better. Our results serve to highlight the fact that fairness cannot be defined outside the larger feedback loop where past actions taken by users (who are either subject to the decisions made by the algorithm or whose data are used to train the algorithm or both) will determine future observations and decisions.},
  archivePrefix = {arXiv},
  eprint = {1905.00569},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhang et al (2019) - Long term impact of fair machine learning in sequential decision making.pdf},
  journal = {arXiv:1905.00569 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{zhang2019Theoretically,
  title = {Theoretically {{Principled Trade}}-off between {{Robustness}} and {{Accuracy}}},
  author = {Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric P. and Ghaoui, Laurent El and Jordan, Michael I.},
  year = {2019},
  month = jun,
  abstract = {We identify a trade-off between robustness and accuracy that serves as a guiding principle in the design of defenses against adversarial examples. Although this problem has been widely studied empirically, much remains unknown concerning the theory underlying this trade-off. In this work, we decompose the prediction error for adversarial examples (robust error) as the sum of the natural (classification) error and boundary error, and provide a differentiable upper bound using the theory of classification-calibrated loss, which is shown to be the tightest possible upper bound uniform over all probability distributions and measurable predictors. Inspired by our theoretical analysis, we also design a new defense method, TRADES, to trade adversarial robustness off against accuracy. Our proposed algorithm performs well experimentally in real-world datasets. The methodology is the foundation of our entry to the NeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of \textasciitilde 2,000 submissions, surpassing the runner-up approach by \$11.41\textbackslash\%\$ in terms of mean \$\textbackslash ell\_2\$ perturbation distance.},
  archivePrefix = {arXiv},
  eprint = {1901.08573},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhang et al (2019) - Theoretically Principled Trade-off between Robustness and Accuracy.pdf},
  journal = {arXiv:1901.08573 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{zhang2019Who,
  title = {Who {{Started It}}? {{Identifying Root Sources}} in {{Textual Conversation Threads}}},
  shorttitle = {Who {{Started It}}?},
  author = {Zhang, Wei and Bu, Fan and {Owens-Oas}, Derek and Heller, Katherine and Zhu, Xiaojin},
  year = {2019},
  month = sep,
  abstract = {In textual conversation threads, as found on many popular social media platforms, each particular user text comment either originates a new thread of discussion, or replies to a previous comment. An individual who makes an original comment ---termed as the "root source''---is a topic initiator or even an information source, and identifying such individuals is of particular interest. The reply structure of comments is not always available (e.g. in the proliferation of a news event), and thus identifying root sources is a nontrivial task. In this paper, we develop a generative model based on marked multivariate Hawkes processes, and introduce a novel concept, "root source probability", to quantify the uncertainty in attributing possible root sources to each comment. A dynamic-programming-based algorithm is then derived to efficiently compute root source probabilities. Experiments on synthetic and real-world data show that our method identifies root sources that match ground truth and human intuition.},
  archivePrefix = {arXiv},
  eprint = {1809.03648},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhang et al (2019) - Who Started It.pdf},
  journal = {arXiv:1809.03648 [cs]},
  keywords = {Computer Science - Social and Information Networks},
  primaryClass = {cs}
}

@article{zhang2020Localized,
  title = {On {{Localized Discrepancy}} for {{Domain Adaptation}}},
  author = {Zhang, Yuchen and Long, Mingsheng and Wang, Jianmin and Jordan, Michael I.},
  year = {2020},
  month = aug,
  abstract = {We propose the discrepancy-based generalization theories for unsupervised domain adaptation. Previous theories introduced distribution discrepancies defined as the supremum over complete hypothesis space. The hypothesis space may contain hypotheses that lead to unnecessary overestimation of the risk bound. This paper studies the localized discrepancies defined on the hypothesis space after localization. First, we show that these discrepancies have desirable properties. They could be significantly smaller than the pervious discrepancies. Their values will be different if we exchange the two domains, thus can reveal asymmetric transfer difficulties. Next, we derive improved generalization bounds with these discrepancies. We show that the discrepancies could influence the rate of the sample complexity. Finally, we further extend the localized discrepancies for achieving super transfer and derive generalization bounds that could be even more sample-efficient on source domain.},
  archivePrefix = {arXiv},
  eprint = {2008.06242},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhang et al (2020) - On Localized Discrepancy for Domain Adaptation.pdf;/Users/yuekai/Zotero/storage/VQMG9JHU/2008.html},
  journal = {arXiv:2008.06242 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{zhao2017Propensityscore,
  title = {Propensity-Score Based Methods for Causal Inference in Observational Studies with Non-Binary Treatments},
  author = {Zhao, Shandong and {van Dyk}, David A and Imai, Kosuke},
  year = {2017},
  month = jan,
  pages = {21},
  abstract = {Propensity score methods are a part of the standard toolkit for applied researchers who wish to ascertain causal effects from observational data. While they were originally developed for binary treatments, several researchers have proposed generalizations of the propensity score methodology for non-binary treatment regimes. Such extensions have widened the applicability of propensity score methods and are indeed becoming increasingly popular themselves. In this article, we closely examine two methods that generalize propensity scores in this direction, namely, the propensity function (pf), and the generalized propensity score (gps), along with two extensions of the gps that aim to improve its robustness. We compare the assumptions, theoretical properties, and empirical performance of these methods. On a theoretical level, the gps and its extensions are advantageous in that they are designed to estimate the full dose response function rather than the average treatment effect that is estimated with the pf. We compare gps with a new pf method, both of which estimate the dose response function. We illustrate our findings and proposals through simulation studies, including one based on an empirical study about the effect of smoking on healthcare costs. While our proposed pf-based estimator preforms well, we generally advise caution in that all available methods can be biased by model misspecification and extrapolation.},
  file = {/Users/yuekai/Documents/zotero/Zhao et al (2017) - Propensity-score based methods for causal inference in observational studies.pdf},
  language = {en}
}

@article{zhao2018Learning,
  title = {Learning {{Gender}}-{{Neutral Word Embeddings}}},
  author = {Zhao, Jieyu and Zhou, Yichao and Li, Zeyu and Wang, Wei and Chang, Kai-Wei},
  year = {2018},
  month = aug,
  abstract = {Word embedding models have become a fundamental component in a wide range of Natural Language Processing (NLP) applications. However, embeddings trained on human-generated corpora have been demonstrated to inherit strong gender stereotypes that reflect social constructs. To address this concern, in this paper, we propose a novel training procedure for learning gender-neutral word embeddings. Our approach aims to preserve gender information in certain dimensions of word vectors while compelling other dimensions to be free of gender influence. Based on the proposed method, we generate a Gender-Neutral variant of GloVe (GN-GloVe). Quantitative and qualitative experiments demonstrate that GN-GloVe successfully isolates gender information without sacrificing the functionality of the embedding model.},
  archivePrefix = {arXiv},
  eprint = {1809.01496},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhao et al (2018) - Learning Gender-Neutral Word Embeddings.pdf},
  journal = {arXiv:1809.01496 [cs, stat]},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{zhao2018Powerful,
  title = {Powerful Genome-Wide Design and Robust Statistical Inference in Two-Sample Summary-Data {{Mendelian}} Randomization},
  author = {Zhao, Qingyuan and Chen, Yang and Wang, Jingshu and Small, Dylan S.},
  year = {2018},
  month = apr,
  abstract = {Two-sample summary-data Mendelian randomization (MR) has become a popular research design to estimate the causal effect of risk exposures. With the sample size of GWAS continuing to increase, it is now possible to utilize genetic instruments that are only weakly associated with the exposure. To maximize the statistical power of MR, we propose a genome-wide design where more than a thousand genetic instruments are used. For the statistical analysis, we use an empirical partially Bayes approach where instruments are weighted according to their strength, thus weak instruments bring less variation to the estimator. The estimator is highly efficient with many weak genetic instruments and is robust to balanced and/or sparse pleiotropy. We apply our method to estimate the causal effect of body mass index (BMI) and major blood lipids on cardiovascular disease outcomes and obtain substantially shorter confidence intervals. Some new and statistically significant findings are: the estimated causal odds ratio of BMI on ischemic stroke is 1.19 (95\% CI: 1.07--1.32, p-value {$<$} 0.001); the estimated causal odds ratio of high-density lipoprotein cholesterol (HDL-C) on coronary artery disease (CAD) is 0.78 (95\% CI 0.73--0.84, p-value {$<$} 0.001). However, the estimated effect of HDL-C becomes substantially smaller and statistically non-significant when we only use the strong instruments. By employing a genome-wide design and robust statistical methods, the statistical power of MR studies can be greatly improved. Our empirical results suggest that, even though the relationship between HDL-C and CAD appears to be highly heterogeneous, it may be too soon to completely dismiss the HDL hypothesis.},
  archivePrefix = {arXiv},
  eprint = {1804.07371},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhao et al (2018) - Powerful genome-wide design and robust statistical inference in two-sample.pdf},
  journal = {arXiv:1804.07371 [stat]},
  keywords = {Statistics - Applications},
  primaryClass = {stat}
}

@article{zhao2018Statistical,
  title = {Statistical {{Convergence}} of the {{EM Algorithm}} on {{Gaussian Mixture Models}}},
  author = {Zhao, Ruofei and Li, Yuanzhi and Sun, Yuekai},
  year = {2018},
  month = oct,
  abstract = {We study the convergence behavior of the Expectation Maximization (EM) algorithm on Gaussian mixture models with an arbitrary number of mixture components and mixing weights. We show that as long as the means of the components are separated by at least \$\textbackslash Omega(\textbackslash sqrt\{\textbackslash min\textbackslash\{M,d\textbackslash\}\})\$, where \$M\$ is the number of components and \$d\$ is the dimension, the EM algorithm converges locally to the global optimum of the log-likelihood. Further, we show that the convergence rate is linear and characterize the size of the basin of attraction to the global optimum.},
  archivePrefix = {arXiv},
  eprint = {1810.04090},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhao et al (2018) - Statistical Convergence of the EM Algorithm on Gaussian Mixture Models.pdf},
  journal = {arXiv:1810.04090 [math, stat]},
  keywords = {Mathematics - Statistics Theory},
  primaryClass = {math, stat}
}

@inproceedings{zhao2019Conditional,
  title = {Conditional {{Learning}} of {{Fair Representations}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Zhao, Han and Coston, Amanda and Adel, Tameem and Gordon, Geoffrey J.},
  year = {2019},
  month = sep,
  abstract = {We propose a novel algorithm for learning fair representations that can simultaneously mitigate two notions of disparity among different demographic subgroups. Two key components underpinning the...},
  file = {/Users/yuekai/Documents/zotero/Zhao et al (2019) - Conditional Learning of Fair Representations.pdf}
}

@article{zhao2020Inherent,
  title = {Inherent {{Tradeoffs}} in {{Learning Fair Representations}}},
  author = {Zhao, Han and Gordon, Geoffrey J.},
  year = {2020},
  month = jun,
  abstract = {With the prevalence of machine learning in high-stakes applications, especially the ones regulated by anti-discrimination laws or societal norms, it is crucial to ensure that the predictive models do not propagate any existing bias or discrimination. Due to the ability of deep neural nets to learn rich representations, recent advances in algorithmic fairness have focused on learning fair representations with adversarial techniques to reduce bias in data while preserving utility simultaneously. In this paper, through the lens of information theory, we provide the first result that quantitatively characterizes the tradeoff between demographic parity and the joint utility across different population groups. Specifically, when the base rates differ between groups, we show that any method aiming to learn fair representations admits an information-theoretic lower bound on the joint error across these groups. To complement our negative results, we also prove that if the optimal decision functions across different groups are close, then learning fair representations leads to an alternative notion of fairness, known as the accuracy parity, which states that the error rates are close between groups. Finally, our theoretical findings are also confirmed empirically on real-world datasets.},
  archivePrefix = {arXiv},
  eprint = {1906.08386},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhao, Gordon (2020) - Inherent Tradeoffs in Learning Fair Representations.pdf},
  journal = {arXiv:1906.08386 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{zheng2018Distributionally,
  title = {Distributionally {{Adversarial Attack}}},
  author = {Zheng, Tianhang and Chen, Changyou and Ren, Kui},
  year = {2018},
  month = aug,
  abstract = {Recent work on adversarial attack has shown that Projected Gradient Descent (PGD) Adversary is a universal first-order adversary, and the classifier adversarially trained by PGD is robust against a wide range of first-order attacks. It is worth noting that the original objective of an attack/defense model relies on a data distribution \$p(\textbackslash mathbf\{x\})\$, typically in the form of risk maximization/minimization, e.g., \$\textbackslash max/\textbackslash min\textbackslash mathbb\{E\}\_\{p(\textbackslash mathbf(x))\}\textbackslash mathcal\{L\}(\textbackslash mathbf\{x\})\$ with \$p(\textbackslash mathbf\{x\})\$ some unknown data distribution and \$\textbackslash mathcal\{L\}(\textbackslash cdot)\$ a loss function. However, since PGD generates attack samples independently for each data sample based on \$\textbackslash mathcal\{L\}(\textbackslash cdot)\$, the procedure does not necessarily lead to good generalization in terms of risk optimization. In this paper, we achieve the goal by proposing distributionally adversarial attack (DAA), a framework to solve an optimal \{\textbackslash em adversarial-data distribution\}, a perturbed distribution that satisfies the \$L\_\textbackslash infty\$ constraint but deviates from the original data distribution to increase the generalization risk maximally. Algorithmically, DAA performs optimization on the space of potential data distributions, which introduces direct dependency between all data points when generating adversarial samples. DAA is evaluated by attacking state-of-the-art defense models, including the adversarially-trained models provided by \{\textbackslash em MIT MadryLab\}. Notably, DAA ranks \{\textbackslash em the first place\} on MadryLab's white-box leaderboards, reducing the accuracy of their secret MNIST model to \$88.79\textbackslash\%\$ (with \$l\_\textbackslash infty\$ perturbations of \$\textbackslash epsilon = 0.3\$) and the accuracy of their secret CIFAR model to \$44.71\textbackslash\%\$ (with \$l\_\textbackslash infty\$ perturbations of \$\textbackslash epsilon = 8.0\$). Code for the experiments is released on \textbackslash url\{https://github.com/tianzheng4/Distributionally-Adversarial-Attack\}.},
  archivePrefix = {arXiv},
  eprint = {1808.05537},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zheng et al (2018) - Distributionally Adversarial Attack.pdf},
  journal = {arXiv:1808.05537 [cs, stat]},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{zhou2016Interpreting,
  title = {Interpreting {{Models}} via {{Single Tree Approximation}}},
  author = {Zhou, Yichen and Hooker, Giles},
  year = {2016},
  month = oct,
  abstract = {We propose a procedure to build a decision tree which approximates the performance of complex machine learning models. This single approximation tree can be used to interpret and simplify the predicting pattern of random forests (RFs) and other models. The use of a tree structure is particularly relevant in medical questionnaires where it enables an adaptive shortening of the questionnaire, reducing response burden. We study the asymptotic behavior of splits and introduce an improved splitting method designed to stabilize tree structure. Empirical studies on both simulation and real data sets illustrate that our method can simultaneously achieve high approximation power and stability.},
  archivePrefix = {arXiv},
  eprint = {1610.09036},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhou, Hooker (2016) - Interpreting Models via Single Tree Approximation.pdf},
  journal = {arXiv:1610.09036 [stat]},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}

@article{zhou2018Offline,
  title = {Offline {{Multi}}-{{Action Policy Learning}}: {{Generalization}} and {{Optimization}}},
  shorttitle = {Offline {{Multi}}-{{Action Policy Learning}}},
  author = {Zhou, Zhengyuan and Athey, Susan and Wager, Stefan},
  year = {2018},
  month = oct,
  abstract = {In many settings, a decision-maker wishes to learn a rule, or policy, that maps from observable characteristics of an individual to an action. Examples include selecting offers, prices, advertisements, or emails to send to consumers, as well as the problem of determining which medication to prescribe to a patient. While there is a growing body of literature devoted to this problem, most existing results are focused on the case where data comes from a randomized experiment, and further, there are only two possible actions, such as giving a drug to a patient or not. In this paper, we study the offline multi-action policy learning problem with observational data and where the policy may need to respect budget constraints or belong to a restricted policy class such as decision trees. We build on the theory of efficient semi-parametric inference in order to propose and implement a policy learning algorithm that achieves asymptotically minimax-optimal regret. To the best of our knowledge, this is the first result of this type in the multi-action setup, and it provides a substantial performance improvement over the existing learning algorithms. We then consider additional computational challenges that arise in implementing our method for the case where the policy is restricted to take the form of a decision tree. We propose two different approaches, one using a mixed integer program formulation and the other using a tree-search based algorithm.},
  archivePrefix = {arXiv},
  eprint = {1810.04778},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhou et al (2018) - Offline Multi-Action Policy Learning.pdf},
  journal = {arXiv:1810.04778 [cs, econ, stat]},
  keywords = {Computer Science - Machine Learning,Economics - Econometrics,Statistics - Machine Learning},
  primaryClass = {cs, econ, stat}
}

@article{zhou2020Modelb,
  title = {Model {{Linkage Selection}} for {{Cooperative Learning}}},
  author = {Zhou, Jiaying and Ding, Jie and Tan, Kean Ming and Tarokh, Vahid},
  year = {2020},
  month = may,
  abstract = {Rapid developments in data collecting devices and computation platforms produce an emerging number of learners and data modalities in many scientific domains. We consider the setting in which each learner holds a pair of parametric statistical model and a specific data source, with the goal of integrating information across a set of learners to enhance the prediction accuracy of a specific learner. One natural way to integrate information is to build a joint model across a set of learners that shares common parameters of interest. However, the parameter sharing patterns across a set of learners are not known a priori. Misspecifying the parameter sharing patterns and the parametric statistical model for each learner yields a biased estimator and degrades the prediction accuracy of the joint model. In this paper, we propose a novel framework for integrating information across a set of learners that is robust against model misspecification and misspecified parameter sharing patterns. The main crux is to sequentially incorporates additional learners that can enhance the prediction accuracy of an existing joint model based on a user-specified parameter sharing patterns across a set of learners, starting from a model with one learner. Theoretically, we show that the proposed method can data-adaptively select the correct parameter sharing patterns based on a user-specified parameter sharing patterns, and thus enhances the prediction accuracy of a learner. Extensive numerical studies are performed to evaluate the performance of the proposed method.},
  archivePrefix = {arXiv},
  eprint = {2005.07342},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhou et al (2020) - Model Linkage Selection for Cooperative Learning.pdf},
  journal = {arXiv:2005.07342 [stat]},
  keywords = {Statistics - Machine Learning,Statistics - Methodology},
  primaryClass = {stat}
}

@article{zhu2014Structural,
  title = {Structural {{Pursuit Over Multiple Undirected Graphs}}},
  author = {Zhu, Yunzhang and Shen, Xiaotong and Pan, Wei},
  year = {2014},
  month = oct,
  volume = {109},
  pages = {1683--1696},
  issn = {0162-1459},
  doi = {10.1080/01621459.2014.921182},
  abstract = {Gaussian graphical models are useful to analyze and visualize conditional dependence relationships between interacting units. Motivated from network analysis under different experimental conditions, such as gene networks for disparate cancer subtypes, we model structural changes over multiple networks with possible heterogeneities. In particular, we estimate multiple precision matrices describing dependencies among interacting units through maximum penalized likelihood. Of particular interest are homogeneous groups of similar entries across and zero-entries of these matrices, referred to as clustering and sparseness structures, respectively. A nonconvex method is proposed to seek a sparse representation for each matrix and identify clusters of the entries across the matrices. Computationally, we develop an efficient method on the basis of difference convex programming, the augmented Lagrangian method and the blockwise coordinate descent method, which is scalable to hundreds of graphs of thousands nodes through a simple necessary and sufficient partition rule, which divides nodes into smaller disjoint subproblems excluding zero-coefficients nodes for arbitrary graphs with convex relaxation. Theoretically, a finite-sample error bound is derived for the proposed method to reconstruct the clustering and sparseness structures. This leads to consistent reconstruction of these two structures simultaneously, permitting the number of unknown parameters to be exponential in the sample size, and yielding the optimal performance of the oracle estimator as if the true structures were given a priori. Simulation studies suggest that the method enjoys the benefit of pursuing these two disparate kinds of structures, and compares favorably against its convex counterpart in the accuracy of structure pursuit and parameter estimation.},
  file = {/Users/yuekai/Documents/zotero/Zhu et al (2014) - Structural Pursuit Over Multiple Undirected Graphs.pdf},
  journal = {Journal of the American Statistical Association},
  number = {508}
}

@article{zhu2017Taming,
  title = {Taming the Heavy-Tailed Features by Shrinkage and Clipping},
  author = {Zhu, Ziwei},
  year = {2017},
  month = oct,
  abstract = {In this paper, we consider the generalized linear models (GLM) with heavy-tailed features and corruptions. Besides clipping the response, we propose to shrink the feature vector by its \$\textbackslash ell\_4\$-norm under the low dimensional regime and clip each entry of the feature vector in the high-dimensional regime. Under bounded fourth moment assumptions, we show that the MLE based on shrunk or clipped data enjoys nearly the minimax optimal rate with exponential deviation bound. Simulations demonstrate significant improvement in statistical performance by feature shrinkage and clipping in linear regression with heavy-tailed noise and logistic regression with noisy labels. We also apply shrinkage to deep features of MNIST images and find that classifiers trained by shrunk deep features are fairly robust to noisy labels: it achieves \$0.9\textbackslash\%\$ testing error in the presence of \$40\textbackslash\%\$ mislabeled data.},
  archivePrefix = {arXiv},
  eprint = {1710.09020},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhu (2017) - Taming the heavy-tailed features by shrinkage and clipping.pdf},
  journal = {arXiv:1710.09020 [math, stat]},
  keywords = {Mathematics - Statistics Theory,Statistics - Methodology},
  primaryClass = {math, stat}
}

@article{zhu2018Multiple,
  title = {Multiple {{Matrix Gaussian Graphs Estimation}}},
  author = {Zhu, Yunzhang and Li, Lexin},
  year = {2018},
  month = jun,
  volume = {80},
  pages = {50},
  abstract = {Matrix-valued data, where the sampling unit is a matrix consisting of rows and columns of measurements, are emerging in numerous scientific and business applications. Matrix Gaussian graphical model is a useful tool to characterize the conditional dependence structure of rows and columns. In this article, we employ nonconvex penalization to tackle the estimation of multiple graphs from matrixvalued data under a matrix normal distribution. We propose a highly e cient nonconvex optimization algorithm that can scale up for graphs with hundreds of nodes. We establish the asymptotic properties of the estimator, which requires less stringent conditions and has a sharper probability error bound than existing results. We demonstrate the e cacy of our proposed method through both simulations and real functional magnetic resonance imaging analyses.},
  file = {/Users/yuekai/Documents/zotero/Zhu, Li (2018) - Multiple Matrix Gaussian Graphs Estimation.pdf},
  journal = {Journal of the Royal Statistical Society: Series B},
  language = {en},
  number = {5}
}

@article{zhu2019Efficient,
  title = {Efficient {{Inference}} and {{Exploration}} for {{Reinforcement Learning}}},
  author = {Zhu, Y. I. and Dong, Jing and Lam, Henry},
  year = {2019},
  month = nov,
  abstract = {Despite an ever growing literature on reinforcement learning algorithms and applications, much less is known about their statistical inference. In this paper, we investigate the large sample behaviors of the Q-value estimates with closed-form characterizations of the asymptotic variances. This allows us to efficiently construct confidence regions for Q-value and optimal value functions, and to develop policies to minimize their estimation errors. This also leads to a policy exploration strategy that relies on estimating the relative discrepancies among the Q estimates. Numerical experiments show superior performances of our exploration strategy than other benchmark approaches.},
  archivePrefix = {arXiv},
  eprint = {1910.05471},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhu et al (2019) - Efficient Inference and Exploration for Reinforcement Learning.pdf},
  journal = {arXiv:1910.05471 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{zhu2019Generalized,
  title = {Generalized {{Resilience}} and {{Robust Statistics}}},
  author = {Zhu, Banghua and Jiao, Jiantao and Steinhardt, Jacob},
  year = {2019},
  month = sep,
  abstract = {Robust statistics traditionally focuses on outliers, or perturbations in total variation distance. However, a dataset could be corrupted in many other ways, such as systematic measurement errors and missing covariates. We generalize the robust statistics approach to consider perturbations under any Wasserstein distance, and show that robust estimation is possible whenever a distribution's population statistics are robust under a certain family of friendly perturbations. This generalizes a property called resilience previously employed in the special case of mean estimation with outliers. We justify the generalized resilience property by showing that it holds under moment or hypercontractive conditions. Even in the total variation case, these subsume conditions in the literature for mean estimation, regression, and covariance estimation; the resulting analysis simplifies and sometimes improves these known results in both population limit and finite-sample rate. Our robust estimators are based on minimum distance (MD) functionals (Donoho and Liu, 1988), which project onto a set of distributions under a discrepancy related to the perturbation. We present two approaches for designing MD estimators with good finite-sample rates: weakening the discrepancy and expanding the set of distributions. We also present connections to Gao et al. (2019)'s recent analysis of generative adversarial networks for robust estimation.},
  archivePrefix = {arXiv},
  eprint = {1909.08755},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zhu et al (2019) - Generalized Resilience and Robust Statistics.pdf},
  journal = {arXiv:1909.08755 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}

@article{zliobaite2015relation,
  title = {On the Relation between Accuracy and Fairness in Binary Classification},
  author = {Zliobaite, Indre},
  year = {2015},
  month = may,
  abstract = {Our study revisits the problem of accuracy-fairness tradeoff in binary classification. We argue that comparison of non-discriminatory classifiers needs to account for different rates of positive predictions, otherwise conclusions about performance may be misleading, because accuracy and discrimination of naive baselines on the same dataset vary with different rates of positive predictions. We provide methodological recommendations for sound comparison of non-discriminatory classifiers, and present a brief theoretical and empirical analysis of tradeoffs between accuracy and non-discrimination.},
  archivePrefix = {arXiv},
  eprint = {1505.05723},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zliobaite (2015) - On the relation between accuracy and fairness in binary classification.pdf},
  journal = {arXiv:1505.05723 [cs]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  primaryClass = {cs}
}

@article{zou2015Crowdsourcing,
  title = {Crowdsourcing {{Feature Discovery}} via {{Adaptively Chosen Comparisons}}},
  author = {Zou, James Y. and Chaudhuri, Kamalika and Kalai, Adam Tauman},
  year = {2015},
  month = mar,
  abstract = {We introduce an unsupervised approach to efficiently discover the underlying features in a data set via crowdsourcing. Our queries ask crowd members to articulate a feature common to two out of three displayed examples. In addition we also ask the crowd to provide binary labels to the remaining examples based on the discovered features. The triples are chosen adaptively based on the labels of the previously discovered features on the data set. In two natural models of features, hierarchical and independent, we show that a simple adaptive algorithm, using "two-out-of-three" similarity queries, recovers all features with less labor than any nonadaptive algorithm. Experimental results validate the theoretical findings.},
  archivePrefix = {arXiv},
  eprint = {1504.00064},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zou et al (2015) - Crowdsourcing Feature Discovery via Adaptively Chosen Comparisons.pdf},
  journal = {arXiv:1504.00064 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{zou2019Reinforcement,
  title = {Reinforcement {{Learning}} to {{Optimize Long}}-Term {{User Engagement}} in {{Recommender Systems}}},
  author = {Zou, Lixin and Xia, Long and Ding, Zhuoye and Song, Jiaxing and Liu, Weidong and Yin, Dawei},
  year = {2019},
  month = jul,
  abstract = {Recommender systems play a crucial role in our daily lives. Feed streaming mechanism has been widely used in the recommender system, especially on the mobile Apps. The feed streaming setting provides users the interactive manner of recommendation in never-ending feeds. In such an interactive manner, a good recommender system should pay more attention to user stickiness, which is far beyond classical instant metrics, and typically measured by \{\textbackslash bf long-term user engagement\}. Directly optimizing the long-term user engagement is a non-trivial problem, as the learning target is usually not available for conventional supervised learning methods. Though reinforcement learning\textasciitilde (RL) naturally fits the problem of maximizing the long term rewards, applying RL to optimize long-term user engagement is still facing challenges: user behaviors are versatile and difficult to model, which typically consists of both instant feedback\textasciitilde (e.g. clicks, ordering) and delayed feedback\textasciitilde (e.g. dwell time, revisit); in addition, performing effective off-policy learning is still immature, especially when combining bootstrapping and function approximation. To address these issues, in this work, we introduce a reinforcement learning framework --- FeedRec to optimize the long-term user engagement. FeedRec includes two components: 1)\textasciitilde a Q-Network which designed in hierarchical LSTM takes charge of modeling complex user behaviors, and 2)\textasciitilde an S-Network, which simulates the environment, assists the Q-Network and voids the instability of convergence in policy learning. Extensive experiments on synthetic data and a real-world large scale data show that FeedRec effectively optimizes the long-term user engagement and outperforms state-of-the-arts.},
  archivePrefix = {arXiv},
  eprint = {1902.05570},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zou et al (2019) - Reinforcement Learning to Optimize Long-term User Engagement in Recommender.pdf},
  journal = {arXiv:1902.05570 [cs]},
  keywords = {Computer Science - Information Retrieval},
  primaryClass = {cs}
}

@article{zrnic2019Natural,
  title = {Natural {{Analysts}} in {{Adaptive Data Analysis}}},
  author = {Zrnic, Tijana and Hardt, Moritz},
  year = {2019},
  month = jan,
  abstract = {Adaptive data analysis is frequently criticized for its pessimistic generalization guarantees. The source of these pessimistic bounds is a model that permits arbitrary, possibly adversarial analysts that optimally use information to bias results. While being a central issue in the field, still lacking are notions of natural analysts that allow for more optimistic bounds faithful to the reality that typical analysts aren't adversarial. In this work, we propose notions of natural analysts that smoothly interpolate between the optimal non-adaptive bounds and the best-known adaptive generalization bounds. To accomplish this, we model the analyst's knowledge as evolving according to the rules of an unknown dynamical system that takes in revealed information and outputs new statistical queries to the data. This allows us to restrict the analyst through different natural control-theoretic notions. One such notion corresponds to a recency bias, formalizing an inability to arbitrarily use distant information. Another complementary notion formalizes an anchoring bias, a tendency to weight initial information more strongly. Both notions come with quantitative parameters that smoothly interpolate between the non-adaptive case and the fully adaptive case, allowing for a rich spectrum of intermediate analysts that are neither non-adaptive nor adversarial. Natural not only from a cognitive perspective, we show that our notions also capture standard optimization methods, like gradient descent in various settings. This gives a new interpretation to the fact that gradient descent tends to overfit much less than its adaptive nature might suggest.},
  archivePrefix = {arXiv},
  eprint = {1901.11143},
  eprinttype = {arxiv},
  file = {/Users/yuekai/Documents/zotero/Zrnic, Hardt (2019) - Natural Analysts in Adaptive Data Analysis.pdf},
  journal = {arXiv:1901.11143 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  primaryClass = {cs, math, stat}
}


