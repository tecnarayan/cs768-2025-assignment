@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{devlin2018bert,
    title={{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
    booktitle={Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
    year={2019},
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{wei2022emergent,
  title={Emergent Abilities of Large Language Models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={Transactions on Machine Learning Research},
  year={2022}
}

@inproceedings{biderman2023pythia,
  title={Pythia: A suite for analyzing large language models across training and scaling},
  author={Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin Gregory and Bradley, Herbie and Oâ€™Brien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, USVSN Sai and Raff, Edward and others},
  booktitle={International Conference on Machine Learning},
  pages={2397--2430},
  year={2023},
  organization={PMLR}
}

@inproceedings{carlini2022quantifying,
  author       = {Nicholas Carlini and
                  Daphne Ippolito and
                  Matthew Jagielski and
                  Katherine Lee and
                  Florian Tram{\`{e}}r and
                  Chiyuan Zhang},
  title        = {Quantifying Memorization Across Neural Language Models},
  booktitle    = {International Conference on Learning Representations},
  year         = {2023},
}

@article{orhan2023recognition,
  title={Recognition, recall, and retention of few-shot memories in large language models},
  author={Orhan, A Emin},
  journal={arXiv preprint arXiv:2303.17557},
  year={2023}
}

@incollection{mccloskey1989catastrophic,
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  booktitle={Psychology of Learning and Motivation},
  volume={24},
  pages={109--165},
  year={1989},
  publisher={Elsevier}
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the National Academy of Sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Academy of Sciences}
}

@inproceedings{zenke2017continual,
  title={Continual learning through synaptic intelligence},
  author={Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
  booktitle={International Conference on Machine Learning},
  pages={3987--3995},
  year={2017},
  organization={PMLR}
}

@inproceedings{aljundi2018memory,
  title={Memory aware synapses: Learning what (not) to forget},
  author={Aljundi, Rahaf and Babiloni, Francesca and Elhoseiny, Mohamed and Rohrbach, Marcus and Tuytelaars, Tinne},
  booktitle={Proceedings of the European Conference on Computer Vision},
  pages={139--154},
  year={2018}
}

@inproceedings{rebuffi2017icarl,
  title={{iCaRL}: Incremental classifier and representation learning},
  author={Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={2001--2010},
  year={2017}
}

@article{rolnick2019experience,
  title={Experience replay for continual learning},
  author={Rolnick, David and Ahuja, Arun and Schwarz, Jonathan and Lillicrap, Timothy and Wayne, Gregory},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{chaudhry2019tiny,
  title={On tiny episodic memories in continual learning},
  author={Chaudhry, Arslan and Rohrbach, Marcus and Elhoseiny, Mohamed and Ajanthan, Thalaiyasingam and Dokania, Puneet K and Torr, Philip HS and Ranzato, Marc'Aurelio},
  journal={arXiv preprint arXiv:1902.10486},
  year={2019}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@inproceedings{madaan2023heterogeneous,
  title={Heterogeneous Continual Learning},
  author={Madaan, Divyam and Yin, Hongxu and Byeon, Wonmin and Kautz, Jan and Molchanov, Pavlo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15985--15995},
  year={2023}
}

@article{buzzega2020dark,
  title={Dark experience for general continual learning: a strong, simple baseline},
  author={Buzzega, Pietro and Boschini, Matteo and Porrello, Angelo and Abati, Davide and Calderara, Simone},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15920--15930},
  year={2020}
}

@article{li2017learning,
  title={Learning without forgetting},
  author={Li, Zhizhong and Hoiem, Derek},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={40},
  number={12},
  pages={2935--2947},
  year={2017},
  publisher={IEEE}
}

@inproceedings{yoon2017lifelong,
  author       = {Jaehong Yoon and
                  Eunho Yang and
                  Jeongtae Lee and
                  Sung Ju Hwang},
  title        = {Lifelong Learning with Dynamically Expandable Networks},
  booktitle    = {International Conference on Learning Representations},
  year         = {2018},
}

@inproceedings{serra2018overcoming,
  title={Overcoming catastrophic forgetting with hard attention to the task},
  author={Serra, Joan and Suris, Didac and Miron, Marius and Karatzoglou, Alexandros},
  booktitle={International Conference on Machine Learning},
  pages={4548--4557},
  year={2018},
  organization={PMLR}
}

@inproceedings{gurbuz2022nispa,
  title={{NISPA}: Neuro-Inspired Stability-Plasticity Adaptation for Continual Learning in Sparse Networks},
  author={Gurbuz, Mustafa B and Dovrolis, Constantine},
  booktitle={International Conference on Machine Learning},
  pages={8157--8174},
  year={2022},
  organization={PMLR}
}

@inproceedings{kang2022forget,
  title={Forget-free continual learning with winning subnetworks},
  author={Kang, Haeyong and Mina, Rusty John Lloyd and Madjid, Sultan Rizky Hikmawan and Yoon, Jaehong and Hasegawa-Johnson, Mark and Hwang, Sung Ju and Yoo, Chang D},
  booktitle={International Conference on Machine Learning},
  pages={10734--10750},
  year={2022},
  organization={PMLR}
}

@inproceedings{davidson2020sequential,
  title={Sequential mastery of multiple visual tasks: Networks naturally learn to learn and forget to forget},
  author={Davidson, Guy and Mozer, Michael C},
  booktitle={Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition},
  pages={9282--9293},
  year={2020}
}

@inproceedings{janson2022simple,
  title={A Simple Baseline that Questions the Use of Pretrained-Models in Continual Learning},
  author={Janson, Paul and Zhang, Wenxuan and Aljundi, Rahaf and Elhoseiny, Mohamed},
  booktitle={NeurIPS 2022 Workshop on Distribution Shifts: Connecting Methods and Applications},
  year={2022}
}

@inproceedings{lee2023pre,
  title={Do pre-trained models benefit equally in continual learning?},
  author={Lee, Kuan-Ying and Zhong, Yuanyi and Wang, Yu-Xiong},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={6485--6493},
  year={2023}
}

@inproceedings{fini2022self,
  title={Self-supervised models are continual learners},
  author={Fini, Enrico and Da Costa, Victor G Turrisi and Alameda-Pineda, Xavier and Ricci, Elisa and Alahari, Karteek and Mairal, Julien},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9621--9630},
  year={2022}
}

@inproceedings{scialom2022fine,
  title={Fine-tuned language models are continual learners},
  author={Scialom, Thomas and Chakrabarty, Tuhin and Muresan, Smaranda},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={6107--6122},
  year={2022}
}

@inproceedings{ke2022continual,
  title={Continual Pre-training of Language Models},
  author={Ke, Zixuan and Shao, Yijia and Lin, Haowei and Konishi, Tatsuya and Kim, Gyuhak and Liu, Bing},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{mayo2023multitask,
  title={Multitask Learning Via Interleaving: A Neural Network Investigation},
  author={Mayo, David and Scott, Tyler and Ren, Mengye and Elsayed, Gamaleldin and Hermann, Katherine and Jones, Matt and Mozer, Michael},
  editor={M. Goldwater and F. K. Anggoro and B. K. Hayes and D. C. Ong},
  booktitle={Proceedings of the 45th Annual Conference of the Cognitive Science Society},
  volume=45,
  year={2023}
}

@inproceedings{wortsman2022model,
  title={Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and others},
  booktitle={International Conference on Machine Learning},
  pages={23965--23998},
  year={2022},
  organization={PMLR}
}

@article{ilharco2022patching,
  title={Patching open-vocabulary models by interpolating weights},
  author={Ilharco, Gabriel and Wortsman, Mitchell and Gadre, Samir Yitzhak and Song, Shuran and Hajishirzi, Hannaneh and Kornblith, Simon and Farhadi, Ali and Schmidt, Ludwig},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={29262--29277},
  year={2022}
}

@article{matena2022merging,
  title={Merging models with fisher-weighted averaging},
  author={Matena, Michael S and Raffel, Colin A},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17703--17716},
  year={2022}
}

@article{neyshabur2020being,
  title={What is being transferred in transfer learning?},
  author={Neyshabur, Behnam and Sedghi, Hanie and Zhang, Chiyuan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={512--523},
  year={2020}
}

@inproceedings{ganguli2022predictability,
  title={Predictability and surprise in large generative models},
  author={Ganguli, Deep and Hernandez, Danny and Lovitt, Liane and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and Dassarma, Nova and Drain, Dawn and Elhage, Nelson and others},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={1747--1764},
  year={2022}
}

@article{srivastava2023beyond,
  title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={Transactions on Machine Learning Research},
  year={2023}
}

@inproceedings{jaidka2018diachronic,
  title={Diachronic degradation of language models: Insights from social media},
  author={Jaidka, Kokil and Chhaya, Niyati and Ungar, Lyle},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages={195--200},
  year={2018}
}

@article{lazaridou2021mind,
  title={Mind the gap: Assessing temporal generalization in neural language models},
  author={Lazaridou, Angeliki and Kuncoro, Adhi and Gribovskaya, Elena and Agrawal, Devang and Liska, Adam and Terzi, Tayfun and Gimenez, Mai and de Masson d'Autume, Cyprien and Kocisky, Tomas and Ruder, Sebastian and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={29348--29363},
  year={2021}
}

@misc{openai2023gpt4,
      title={{GPT}-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{touvron2023llama,
  title={{LLaMA}: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{van2020brain,
  title={Brain-inspired replay for continual learning with artificial neural networks},
  author={Van de Ven, Gido M and Siegelmann, Hava T and Tolias, Andreas S},
  journal={Nature Communications},
  volume={11},
  number={1},
  pages={4069},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@book{chen2018lifelong,
  title={Lifelong Machine Learning},
  author={Chen, Zhiyuan and Liu, Bing},
  volume={1},
  year={2018},
  publisher={Springer}
}

@article{xu2022stochastic,
  title={Stochastic Gradient Descent without Full Data Shuffle},
  author={Xu, Lijie and Qiu, Shuang and Yuan, Binhang and Jiang, Jiawei and Renggli, Cedric and Gan, Shaoduo and Kara, Kaan and Li, Guoliang and Liu, Ji and Wu, Wentao and others},
  journal={arXiv preprint arXiv:2206.05830},
  year={2022}
}

@article{ahn2020sgd,
  title={{SGD} with shuffling: {O}ptimal rates without component convexity and large epoch requirements},
  author={Ahn, Kwangjun and Yun, Chulhee and Sra, Suvrit},
  journal={{Advances in Neural Information Processing Systems}},
  volume={33},
  pages={17526--17535},
  year={2020}
}

@article{gao2020pile,
  title={The {P}ile: An 800{GB} dataset of diverse text for language modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  journal={arXiv preprint arXiv:2101.00027},
  year={2020}
}

@article{biderman2022datasheet,
  title={Datasheet for the {P}ile},
  author={Biderman, Stella and Bicheno, Kieran and Gao, Leo},
  journal={arXiv preprint arXiv:2201.07311},
  year={2022}
}

@inproceedings{nallapati2016abstractive,
  title={Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond},
  author={Nallapati, Ramesh and Zhou, Bowen and dos Santos, Cicero and Gul{\c{c}}ehre, {\c{C}}a{\u{g}}lar and Xiang, Bing},
  booktitle={Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning},
  pages={280--290},
  year={2016}
}

@inproceedings{chen2020generative,
  title={Generative pretraining from pixels},
  author={Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeffrey and Jun, Heewoo and Luan, David and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={1691--1703},
  year={2020},
  organization={PMLR}
}

@article{luo2023empirical,
  title={An empirical study of catastrophic forgetting in large language models during continual fine-tuning},
  author={Luo, Yun and Yang, Zhen and Meng, Fandong and Li, Yafu and Zhou, Jie and Zhang, Yue},
  journal={arXiv preprint arXiv:2308.08747},
  year={2023}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  journal={University of Toronto}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on Computer Vision and Pattern Recognition},
  pages={248--255},
  year={2009},
  organization={IEEE}
}

@inproceedings{kingma2014adam,
  author       = {Diederik P. Kingma and Jimmy Ba},
  title        = {Adam: {A} Method for Stochastic Optimization},
  booktitle    = {International Conference on Learning Representations},
  year         = {2015},
}

@article{hoffmann2022training,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}

@article{xue2023repeat,
  title={To repeat or not to repeat: Insights from scaling llm under token-crisis},
  author={Xue, Fuzhao and Fu, Yao and Zhou, Wangchunshu and Zheng, Zangwei and You, Yang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{chowdhery2023palm,
  title={{PaLM}: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@inproceedings{jones2023learning,
  author       = {Matt Jones and
                  Tyler R. Scott and
                  Mengye Ren and
                  Gamaleldin Fathy Elsayed and
                  Katherine L. Hermann and
                  David Mayo and
                  Michael Curtis Mozer},
  title        = {Learning in temporally structured environments},
  booktitle    = {International Conference on Learning Representations},
  year         = {2023}
}

@article{gurbuzbalaban2019convergence,
  title={Convergence rate of incremental gradient and incremental Newton methods},
  author={Gurbuzbalaban, M and Ozdaglar, Asu and Parrilo, Pablo A},
  journal={SIAM Journal on Optimization},
  volume={29},
  number={4},
  pages={2542--2565},
  year={2019},
  publisher={SIAM}
}

@article{mishchenko2020random,
  title={Random reshuffling: Simple analysis with vast improvements},
  author={Mishchenko, Konstantin and Khaled, Ahmed and Richt{\'a}rik, Peter},
  journal={{Advances in Neural Information Processing Systems}},
  volume={33},
  pages={17309--17320},
  year={2020}
}

@inproceedings{safran2020good,
  title={How good is {SGD} with random shuffling?},
  author={Safran, Itay and Shamir, Ohad},
  booktitle={Conference on Learning Theory},
  pages={3250--3284},
  year={2020},
  organization={PMLR}
}

@inproceedings{dosovitskiy2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{hannan1957approximation,
  title={Approximation to {B}ayes risk in repeated play},
  author={Hannan, James},
  journal={Contributions to the Theory of Games},
  volume={3},
  pages={97--139},
  year={1957}
}

@inproceedings{finn2019online,
  title={Online meta-learning},
  author={Finn, Chelsea and Rajeswaran, Aravind and Kakade, Sham and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1920--1930},
  year={2019},
  organization={PMLR}
}

@article{denevi2019online,
  title={Online-within-online meta-learning},
  author={Denevi, Giulia and Stamos, Dimitris and Ciliberto, Carlo and Pontil, Massimiliano},
  journal={{Advances in Neural Information Processing Systems}},
  volume={32},
  year={2019}
}

@inproceedings{ren2020wandering,
  author       = {Mengye Ren and
                  Michael Louis Iuzzolino and
                  Michael Curtis Mozer and
                  Richard S. Zemel},
  title        = {Wandering within a world: Online contextualized few-shot learning},
  booktitle    = {International Conference on Learning Representations},
  year         = {2021},
}

@inproceedings{denevi2019learning,
  title={Learning-to-learn stochastic gradient descent with biased regularization},
  author={Denevi, Giulia and Ciliberto, Carlo and Grazzi, Riccardo and Pontil, Massimiliano},
  booktitle={International Conference on Machine Learning},
  pages={1566--1575},
  year={2019},
  organization={PMLR}
}

@article{javed2019meta,
  title={Meta-learning representations for continual learning},
  author={Javed, Khurram and White, Martha},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{wang2021wanderlust,
  title={Wanderlust: Online continual object detection in the real world},
  author={Wang, Jianren and Wang, Xin and Shang-Guan, Yue and Gupta, Abhinav},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10829--10838},
  year={2021}
}

@inproceedings{fini2020online,
  title={Online continual learning under extreme memory constraints},
  author={Fini, Enrico and Lathuiliere, St{\'e}phane and Sangineto, Enver and Nabi, Moin and Ricci, Elisa},
  booktitle={Proceedings of the European Conference on Computer Vision},
  pages={720--735},
  year={2020},
  organization={Springer}
}

@article{biehl1995learning,
  title={Learning by on-line gradient descent},
  author={Biehl, Michael and Schwarze, Holm},
  journal={Journal of Physics A: Mathematical and general},
  volume={28},
  number={3},
  pages={643},
  year={1995},
  publisher={IOP Publishing}
}

@book{cesa2006prediction,
  title={Prediction, learning, and games},
  author={Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  year={2006},
  publisher={Cambridge University Press}
}

@inproceedings{zinkevich2003online,
  title={Online convex programming and generalized infinitesimal gradient ascent},
  author={Zinkevich, Martin},
  booktitle={International Conference on Machine Learning},
  pages={928--936},
  year={2003}
}

@article{shalev2012online,
  title={Online learning and online convex optimization},
  author={Shalev-Shwartz, Shai and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={4},
  number={2},
  pages={107--194},
  year={2012},
  publisher={Now Publishers, Inc.}
}

@inproceedings{simonyan2014very,
  author       = {Karen Simonyan and Andrew Zisserman},
  title        = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  booktitle    = {International Conference on Learning Representations},
  year         = {2015},
}

@article{srivastava2022beyond,
  title={Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={arXiv preprint arXiv:2206.04615},
  year={2022}
}

@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{merity2017pointer,
  author       = {Stephen Merity and
                  Caiming Xiong and
                  James Bradbury and
                  Richard Socher},
  title        = {Pointer Sentinel Mixture Models},
  booktitle    = {5th International Conference on Learning Representations, Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  year         = {2017},
}

@book{rockafellar2009variational,
  title={Variational analysis},
  author={Rockafellar, R Tyrrell and Wets, Roger J-B},
  volume={317},
  year={2009},
  publisher={Springer Science \& Business Media}
}

@inproceedings{cai2021online,
  title={Online continual learning with natural distribution shifts: An empirical study with visual data},
  author={Cai, Zhipeng and Sener, Ozan and Koltun, Vladlen},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={8281--8290},
  year={2021}
}

@inproceedings{madotto2021continual,
    title = "Continual Learning in Task-Oriented Dialogue Systems",
    author = "Madotto, Andrea  and
      Lin, Zhaojiang  and
      Zhou, Zhenpeng  and
      Moon, Seungwhan  and
      Crook, Paul  and
      Liu, Bing  and
      Yu, Zhou  and
      Cho, Eunjoon  and
      Fung, Pascale  and
      Wang, Zhiguang",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.590",
    doi = "10.18653/v1/2021.emnlp-main.590",
    pages = "7452--7467",
}

@inproceedings{qin2022LFPT5,
  author       = {Chengwei Qin and
                  Shafiq R. Joty},
  title        = {{LFPT5:} {A} Unified Framework for Lifelong Few-shot Language Learning
                  Based on Prompt Tuning of {T5}},
  booktitle    = {International Conference on Learning Representations},
  publisher    = {OpenReview.net},
  year         = {2022},
  url          = {https://openreview.net/forum?id=HCRVf71PMF},
  timestamp    = {Thu, 22 Sep 2022 17:53:15 +0200},
}

@inproceedings{razdaibiedina2023progressive,
  author       = {Anastasia Razdaibiedina and
                  Yuning Mao and
                  Rui Hou and
                  Madian Khabsa and
                  Mike Lewis and
                  Amjad Almahairi},
  title        = {Progressive Prompts: Continual Learning for Language Models},
  booktitle    = {International Conference on Learning Representations},
  publisher    = {OpenReview.net},
  year         = {2023},
  url          = {https://openreview.net/forum?id=UJTgQBc91\_},
  timestamp    = {Wed, 24 Jul 2024 16:50:34 +0200},
}
