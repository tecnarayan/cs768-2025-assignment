\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andrychowicz et~al.(2020)Andrychowicz, Baker, Chociej, Józefowicz,
  McGrew, Pachocki, Petron, Plappert, Powell, Ray, Schneider, Sidor, Tobin,
  Welinder, Weng, and Zaremba]{dexmanip}
Andrychowicz, M., Baker, B., Chociej, M., Józefowicz, R., McGrew, B.,
  Pachocki, J., Petron, A., Plappert, M., Powell, G., Ray, A., Schneider, J.,
  Sidor, S., Tobin, J., Welinder, P., Weng, L., and Zaremba, W.
\newblock Learning dexterous in-hand manipulation.
\newblock \emph{The International Journal of Robotics Research}, 39\penalty0
  (1), 2020.

\bibitem[Babaeizadeh et~al.(2017)Babaeizadeh, Frosio, Tyree, Clemons, and
  Kautz]{ga3c}
Babaeizadeh, M., Frosio, I., Tyree, S., Clemons, J., and Kautz, J.
\newblock Reinforcement learning through asynchronous advantage actor-critic on
  a {GPU}.
\newblock In \emph{ICLR}, 2017.

\bibitem[Baker et~al.(2020)Baker, Kanitscheider, Markov, Wu, Powell, McGrew,
  and Mordatch]{hide-n-seek}
Baker, B., Kanitscheider, I., Markov, T., Wu, Y., Powell, G., McGrew, B., and
  Mordatch, I.
\newblock Emergent tool use from multi-agent autocurricula.
\newblock In \emph{ICLR}, 2020.

\bibitem[Bansal et~al.(2018)Bansal, Pachocki, Sidor, Sutskever, and
  Mordatch]{self-play}
Bansal, T., Pachocki, J., Sidor, S., Sutskever, I., and Mordatch, I.
\newblock Emergent complexity via multi-agent competition.
\newblock In \emph{ICLR}, 2018.

\bibitem[Beattie et~al.(2016)Beattie, Leibo, Teplyashin, Ward, Wainwright,
  K{\"{u}}ttler, Lefrancq, Green, Vald{\'{e}}s, Sadik, Schrittwieser, Anderson,
  York, Cant, Cain, Bolton, Gaffney, King, Hassabis, Legg, and Petersen]{dmlab}
Beattie, C., Leibo, J.~Z., Teplyashin, D., Ward, T., Wainwright, M.,
  K{\"{u}}ttler, H., Lefrancq, A., Green, S., Vald{\'{e}}s, V., Sadik, A.,
  Schrittwieser, J., Anderson, K., York, S., Cant, M., Cain, A., Bolton, A.,
  Gaffney, S., King, H., Hassabis, D., Legg, S., and Petersen, S.
\newblock {DeepMind} {Lab}.
\newblock \emph{CoRR}, abs/1612.03801, 2016.

\bibitem[Beeching et~al.(2019)Beeching, Wolf, Dibangoye, and
  Simonin]{doom_supercomputer}
Beeching, E., Wolf, C., Dibangoye, J., and Simonin, O.
\newblock Deep reinforcement learning on a budget: {3D} control and reasoning
  without a supercomputer.
\newblock \emph{CoRR}, abs/1904.01806, 2019.

\bibitem[Bellemare et~al.(2013)Bellemare, Naddaf, Veness, and Bowling]{ale}
Bellemare, M.~G., Naddaf, Y., Veness, J., and Bowling, M.
\newblock The arcade learning environment: An evaluation platform for general
  agents.
\newblock In \emph{IJCAI}, 2013.

\bibitem[Berner et~al.(2019)Berner, Brockman, Chan, Cheung, Debiak, Dennison,
  Farhi, Fischer, Hashme, Hesse, J{\'{o}}zefowicz, Gray, Olsson, Pachocki,
  Petrov, de~Oliveira~Pinto, Raiman, Salimans, Schlatter, Schneider, Sidor,
  Sutskever, Tang, Wolski, and Zhang]{openai2019dota}
Berner, C., Brockman, G., Chan, B., Cheung, V., Debiak, P., Dennison, C.,
  Farhi, D., Fischer, Q., Hashme, S., Hesse, C., J{\'{o}}zefowicz, R., Gray,
  S., Olsson, C., Pachocki, J., Petrov, M., de~Oliveira~Pinto, H.~P., Raiman,
  J., Salimans, T., Schlatter, J., Schneider, J., Sidor, S., Sutskever, I.,
  Tang, J., Wolski, F., and Zhang, S.
\newblock Dota 2 with large scale deep reinforcement learning.
\newblock \emph{CoRR}, abs/1912.06680, 2019.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Zaremba]{gym}
Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang,
  J., and Zaremba, W.
\newblock {OpenAI} {Gym}.
\newblock \emph{CoRR}, abs/1606.01540, 2016.

\bibitem[Dhariwal et~al.(2017)Dhariwal, Hesse, Klimov, Nichol, Plappert,
  Radford, Schulman, Sidor, Wu, and Zhokhov]{baselines}
Dhariwal, P., Hesse, C., Klimov, O., Nichol, A., Plappert, M., Radford, A.,
  Schulman, J., Sidor, S., Wu, Y., and Zhokhov, P.
\newblock {OpenAI} baselines.
\newblock \url{https://github.com/openai/baselines}, 2017.

\bibitem[Dosovitskiy \& Koltun(2017)Dosovitskiy and Koltun]{dfp}
Dosovitskiy, A. and Koltun, V.
\newblock Learning to act by predicting the future.
\newblock In \emph{ICLR}, 2017.

\bibitem[Espeholt et~al.(2018)Espeholt, Soyer, Munos, Simonyan, Mnih, Ward,
  Doron, Firoiu, Harley, Dunning, Legg, and Kavukcuoglu]{impala}
Espeholt, L., Soyer, H., Munos, R., Simonyan, K., Mnih, V., Ward, T., Doron,
  Y., Firoiu, V., Harley, T., Dunning, I., Legg, S., and Kavukcuoglu, K.
\newblock {IMPALA}: Scalable distributed deep-rl with importance weighted
  actor-learner architectures.
\newblock In \emph{ICML}, 2018.

\bibitem[Espeholt et~al.(2019)Espeholt, Marinier, Stanczyk, Wang, and
  Michalski]{seedrl}
Espeholt, L., Marinier, R., Stanczyk, P., Wang, K., and Michalski, M.
\newblock {SEED} {RL}: Scalable and efficient deep-rl with accelerated central
  inference.
\newblock \emph{CoRR}, abs/1910.06591, 2019.

\bibitem[Harutyunyan et~al.(2016)Harutyunyan, Bellemare, Stepleton, and
  Munos]{retrace}
Harutyunyan, A., Bellemare, M.~G., Stepleton, T., and Munos, R.
\newblock Q({\(\lambda\)}) with off-policy corrections.
\newblock In \emph{Algorithmic Learning Theory, {ALT}}, 2016.

\bibitem[Horgan et~al.(2018)Horgan, Quan, Budden, Barth{-}Maron, Hessel, van
  Hasselt, and Silver]{apex}
Horgan, D., Quan, J., Budden, D., Barth{-}Maron, G., Hessel, M., van Hasselt,
  H., and Silver, D.
\newblock Distributed prioritized experience replay.
\newblock In \emph{ICLR}, 2018.

\bibitem[Hwangbo et~al.(2019)Hwangbo, Lee, Dosovitskiy, Bellicoso, Tsounis,
  Koltun, and Hutter]{hwangbo2019learning}
Hwangbo, J., Lee, J., Dosovitskiy, A., Bellicoso, D., Tsounis, V., Koltun, V.,
  and Hutter, M.
\newblock Learning agile and dynamic motor skills for legged robots.
\newblock \emph{Science Robotics}, 4\penalty0 (26), 2019.

\bibitem[Jaderberg et~al.(2019)Jaderberg, Czarnecki, Dunning, Marris, Lever,
  Casta{\~n}eda, Beattie, Rabinowitz, Morcos, Ruderman, Sonnerat, Green,
  Deason, Leibo, Silver, Hassabis, Kavukcuoglu, and Graepel]{dmquakescience}
Jaderberg, M., Czarnecki, W.~M., Dunning, I., Marris, L., Lever, G.,
  Casta{\~n}eda, A.~G., Beattie, C., Rabinowitz, N.~C., Morcos, A.~S.,
  Ruderman, A., Sonnerat, N., Green, T., Deason, L., Leibo, J.~Z., Silver, D.,
  Hassabis, D., Kavukcuoglu, K., and Graepel, T.
\newblock Human-level performance in {3D} multiplayer games with
  population-based reinforcement learning.
\newblock \emph{Science}, 364\penalty0 (6443), 2019.

\bibitem[Kapturowski et~al.(2019)Kapturowski, Ostrovski, Quan, Munos, and
  Dabney]{r2d2}
Kapturowski, S., Ostrovski, G., Quan, J., Munos, R., and Dabney, W.
\newblock Recurrent experience replay in distributed reinforcement learning.
\newblock In \emph{ICLR}, 2019.

\bibitem[Kempka et~al.(2016)Kempka, Wydmuch, Runc, Toczek, and
  Jaskowski]{vizdoom}
Kempka, M., Wydmuch, M., Runc, G., Toczek, J., and Jaskowski, W.
\newblock Vizdoom: {A} {Doom}-based {AI} research platform for visual
  reinforcement learning.
\newblock In \emph{{IEEE} Conference on Computational Intelligence and Games},
  2016.

\bibitem[K{\"{u}}ttler et~al.(2019)K{\"{u}}ttler, Nardelli, Lavril, Selvatici,
  Sivakumar, Rockt{\"{a}}schel, and Grefenstette]{torchbeast}
K{\"{u}}ttler, H., Nardelli, N., Lavril, T., Selvatici, M., Sivakumar, V.,
  Rockt{\"{a}}schel, T., and Grefenstette, E.
\newblock {TorchBeast}: {A} {PyTorch} platform for distributed {RL}.
\newblock \emph{CoRR}, abs/1910.03552, 2019.

\bibitem[Li \& Schuurmans(2011)Li and Schuurmans]{mapreducerl}
Li, Y. and Schuurmans, D.
\newblock {MapReduce} for parallel reinforcement learning.
\newblock In \emph{European Workshop on Reinforcement Learning}, 2011.

\bibitem[Liang et~al.(2018)Liang, Liaw, Nishihara, Moritz, Fox, Goldberg,
  Gonzalez, Jordan, and Stoica]{rllib}
Liang, E., Liaw, R., Nishihara, R., Moritz, P., Fox, R., Goldberg, K.,
  Gonzalez, J., Jordan, M.~I., and Stoica, I.
\newblock {RLlib}: Abstractions for distributed reinforcement learning.
\newblock In \emph{ICML}, 2018.

\bibitem[McCandlish et~al.(2018)McCandlish, Kaplan, Amodei,
  et~al.]{large_batch_openai_sam_mccandlish2018}
McCandlish, S., Kaplan, J., Amodei, D., et~al.
\newblock An empirical model of large-batch training.
\newblock \emph{CoRR}, abs/1812.06162, 2018.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley,
  Silver, and Kavukcuoglu]{a3c}
Mnih, V., Badia, A.~P., Mirza, M., Graves, A., Lillicrap, T.~P., Harley, T.,
  Silver, D., and Kavukcuoglu, K.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In \emph{ICML}, 2016.

\bibitem[Molchanov et~al.(2019)Molchanov, Chen, H{\"{o}}nig, Preiss, Ayanian,
  and Sukhatme]{amdrone}
Molchanov, A., Chen, T., H{\"{o}}nig, W., Preiss, J.~A., Ayanian, N., and
  Sukhatme, G.~S.
\newblock Sim-to-(multi)-real: Transfer of low-level robust control policies to
  multiple quadrotors.
\newblock In \emph{IROS}, 2019.

\bibitem[Moritz et~al.(2018)Moritz, Nishihara, Wang, Tumanov, Liaw, Liang,
  Elibol, Yang, Paul, Jordan, and Stoica]{ray}
Moritz, P., Nishihara, R., Wang, S., Tumanov, A., Liaw, R., Liang, E., Elibol,
  M., Yang, Z., Paul, W., Jordan, M.~I., and Stoica, I.
\newblock Ray: {A} distributed framework for emerging {AI} applications.
\newblock In \emph{{USENIX} Symposium on Operating Systems Design and
  Implementation}, 2018.

\bibitem[M{\"{u}}ller et~al.(2018)M{\"{u}}ller, Dosovitskiy, Ghanem, and
  Koltun]{rccar_sim2real}
M{\"{u}}ller, M., Dosovitskiy, A., Ghanem, B., and Koltun, V.
\newblock Driving policy transfer via modularity and abstraction.
\newblock In \emph{Conference on Robot Learning (CoRL)}, 2018.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, K{\"{o}}pf, Yang, DeVito,
  Raison, Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., K{\"{o}}pf, A., Yang,
  E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang,
  L., Bai, J., and Chintala, S.
\newblock {PyTorch}: An imperative style, high-performance deep learning
  library.
\newblock In \emph{Neural Information Processing Systems}, 2019.

\bibitem[Recht et~al.(2011)Recht, R{\'{e}}, Wright, and Niu]{hogwild}
Recht, B., R{\'{e}}, C., Wright, S.~J., and Niu, F.
\newblock Hogwild: {A} lock-free approach to parallelizing stochastic gradient
  descent.
\newblock In \emph{Neural Information Processing Systems}, 2011.

\bibitem[Schmitt et~al.(2019)Schmitt, Hessel, and Simonyan]{laser}
Schmitt, S., Hessel, M., and Simonyan, K.
\newblock Off-policy actor-critic with shared experience replay.
\newblock \emph{CoRR}, abs/1909.11583, 2019.

\bibitem[Schulman et~al.(2015)Schulman, Levine, Abbeel, Jordan, and
  Moritz]{trpo}
Schulman, J., Levine, S., Abbeel, P., Jordan, M.~I., and Moritz, P.
\newblock Trust region policy optimization.
\newblock In \emph{ICML}, 2015.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{ppo}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.
\newblock Proximal policy optimization algorithms.
\newblock \emph{CoRR}, abs/1707.06347, 2017.

\bibitem[Stooke \& Abbeel(2019)Stooke and Abbeel]{rlpyt}
Stooke, A. and Abbeel, P.
\newblock rlpyt: {A} research code base for deep reinforcement learning in
  {PyTorch}.
\newblock \emph{CoRR}, abs/1909.01500, 2019.

\bibitem[Vinyals et~al.(2019)Vinyals, Babuschkin, Czarnecki, Mathieu, Dudzik,
  Chung, Choi, Powell, Ewalds, Georgiev, et~al.]{dmstarcraft2}
Vinyals, O., Babuschkin, I., Czarnecki, W.~M., Mathieu, M., Dudzik, A., Chung,
  J., Choi, D.~H., Powell, R., Ewalds, T., Georgiev, P., et~al.
\newblock Grandmaster level in {StarCraft II} using multi-agent reinforcement
  learning.
\newblock \emph{Nature}, 575\penalty0 (7782), 2019.

\bibitem[Wijmans et~al.(2020)Wijmans, Kadian, Morcos, Lee, Essa, Parikh, Savva,
  and Batra]{ddppo}
Wijmans, E., Kadian, A., Morcos, A., Lee, S., Essa, I., Parikh, D., Savva, M.,
  and Batra, D.
\newblock {DD-PPO}: {L}earning near-perfect {PointGoal} navigators from 2.5
  billion frames.
\newblock In \emph{ICLR}, 2020.

\bibitem[Wydmuch et~al.(2019)Wydmuch, Kempka, and Jaskowski]{doom_competitions}
Wydmuch, M., Kempka, M., and Jaskowski, W.
\newblock Vizdoom competitions: Playing {Doom} from pixels.
\newblock \emph{{IEEE} Transactions on Games}, 11\penalty0 (3), 2019.

\bibitem[Zhou et~al.(2019)Zhou, Kr{\"{a}}henb{\"{u}}hl, and
  Koltun]{cv_matter_for_action}
Zhou, B., Kr{\"{a}}henb{\"{u}}hl, P., and Koltun, V.
\newblock Does computer vision matter for action?
\newblock \emph{Science Robotics}, 4\penalty0 (30), 2019.

\end{thebibliography}
