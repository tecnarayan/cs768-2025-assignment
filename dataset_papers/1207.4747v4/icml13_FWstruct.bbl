\begin{thebibliography}{31}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bach et~al.(2012)Bach, Lacoste-Julien, and Obozinski]{bach12herding}
Bach, F., Lacoste-Julien, S., and Obozinski, G.
\newblock On the equivalence between herding and conditional gradient
  algorithms.
\newblock In \emph{ICML}, 2012.

\bibitem[Balamurugan et~al.(2011)Balamurugan, Shevade, Sundararajan, and
  Keerthi]{balamurugan11SDM}
Balamurugan, P., Shevade, S., Sundararajan, S., and Keerthi, S.
\newblock A sequential dual method for structural {SVM}s.
\newblock In \emph{SDM}, 2011.

\bibitem[Caetano et~al.(2009)Caetano, McAuley, Cheng, Le, and
  Smola]{Caetano:09graphMatching}
Caetano, T.S., McAuley, J.J., Cheng, Li, Le, Q.V., and Smola, A.J.
\newblock Learning graph matching.
\newblock \emph{IEEE PAMI}, 31\penalty0 (6):\penalty0 1048--1058, 2009.

\bibitem[Clarkson(2010)]{Clarkson:2010hv}
Clarkson, K.
\newblock {Coresets, sparse greedy approximation, and the Frank-Wolfe
  algorithm}.
\newblock \emph{ACM Transactions on Algorithms}, 6\penalty0 (4):\penalty0
  1--30, 2010.

\bibitem[Collins et~al.(2008)Collins, Globerson, Koo, Carreras, and
  Bartlett]{Collins2008}
Collins, M., Globerson, A., Koo, T., Carreras, X., and Bartlett, P.~L.
\newblock Exponentiated gradient algorithms for conditional random fields and
  max-margin {M}arkov networks.
\newblock \emph{JMLR}, 9:\penalty0 1775--1822, 2008.

\bibitem[Dunn \& Harshbarger(1978)Dunn and Harshbarger]{Dunn:1978di}
Dunn, J.C. and Harshbarger, S.
\newblock {Conditional gradient algorithms with open loop step size rules}.
\newblock \emph{Journal of Mathematical Analysis and Applications}, 62\penalty0
  (2):\penalty0 432--444, 1978.

\bibitem[Finley \& Joachims(2008)Finley and Joachims]{finley08svmstruct-app}
Finley, T. and Joachims, T.
\newblock Training structural {SVM}s when exact inference is intractable.
\newblock In \emph{ICML}, 2008.

\bibitem[Frank \& Wolfe(1956)Frank and Wolfe]{Frank:1956vp}
Frank, M. and Wolfe, P.
\newblock {An algorithm for quadratic programming}.
\newblock \emph{Naval Research Logistics Quarterly}, 3:\penalty0 95--110, 1956.

\bibitem[G{\"a}rtner \& Jaggi(2009)G{\"a}rtner and Jaggi]{GartnerJaggi:2009}
G{\"a}rtner, B. and Jaggi, M.
\newblock Coresets for polytope distance.
\newblock \emph{ACM Symposium on Computational Geometry}, 2009.

\bibitem[Hsieh et~al.(2008)Hsieh, Chang, Lin, Keerthi, and
  Sundararajan]{Hsieh:2008bd}
Hsieh, C., Chang, K., Lin, C., Keerthi, S., and Sundararajan, S.
\newblock {A dual coordinate descent method for large-scale linear SVM}.
\newblock In \emph{ICML}, pp.\  408--415, 2008.

\bibitem[Jaggi(2011)]{Jaggi:2011ux}
Jaggi, M.
\newblock \emph{Sparse convex optimization methods for machine learning}.
\newblock PhD thesis, ETH Z{\"u}rich, 2011.

\bibitem[Jaggi(2013)]{Jaggi:2013wg}
Jaggi, M.
\newblock Revisiting {F}rank-{W}olfe: Projection-free sparse convex
  optimization.
\newblock In \emph{ICML}, 2013.

\bibitem[Joachims et~al.(2009)Joachims, Finley, and Yu]{Joachims:2009ex}
Joachims, T., Finley, T., and Yu, C.
\newblock Cutting-plane training of structural {SVMs}.
\newblock \emph{Machine Learn.}, 77\penalty0 (1):\penalty0 27--59, 2009.

\bibitem[{Lacoste-Julien} et~al.(2012){Lacoste-Julien}, {Schmidt}, and
  {Bach}]{LacosteJulien:2012uo}
{Lacoste-Julien}, S., {Schmidt}, M., and {Bach}, F.
\newblock {A simpler approach to obtaining an {O(1/t)} convergence rate for the
  projected stochastic subgradient method}.
\newblock Technical Report 1212.2002v2 [cs.LG], arXiv, December 2012.

\bibitem[Mangasarian(1995)]{Mangasarian:1995wa}
Mangasarian, O.L.
\newblock Machine learning via polyhedral concave minimization.
\newblock Technical Report 95-20, University of Wisconsin, 1995.

\bibitem[Nesterov(2012)]{Nesterov:2012fa}
Nesterov, Yurii.
\newblock Efficiency of coordinate descent methods on huge-scale optimization
  problems.
\newblock \emph{SIAM Journal on Optimization}, 22\penalty0 (2):\penalty0
  341--362, 2012.

\bibitem[Ouyang \& Gray(2010)Ouyang and Gray]{Ouyang:2010vc}
Ouyang, H. and Gray, A.
\newblock Fast stochastic {F}rank-{W}olfe algorithms for nonlinear {SVMs}.
\newblock \emph{SDM}, 2010.

\bibitem[Rakhlin et~al.(2012)Rakhlin, Shamir, and Sridharan]{Rakhlin2012}
Rakhlin, A., Shamir, O., and Sridharan, K.
\newblock Making gradient descent optimal for strongly convex stochastic
  optimization.
\newblock In \emph{ICML}, 2012.

\bibitem[Ratliff et~al.(2007)Ratliff, Bagnell, and
  Zinkevich]{Ratliff:2007subgradient}
Ratliff, N., Bagnell, J.~A., and Zinkevich, M.
\newblock ({O}nline) subgradient methods for structured prediction.
\newblock In \emph{AISTATS}, 2007.

\bibitem[Rousu et~al.(2006)Rousu, Saunders, Szedmak, and
  Shawe-Taylor]{Rousu:2006vv}
Rousu, J., Saunders, C., Szedmak, S., and Shawe-Taylor, J.
\newblock Kernel-based learning of hierarchical multilabel classification
  models.
\newblock \emph{JMLR}, 2006.

\bibitem[Sang \& Buchholz(2000)Sang and Buchholz]{Sang2000}
Sang, E.F.T.K. and Buchholz, S.
\newblock Introduction to the {CoNLL-2000} shared task: {C}hunking, 2000.

\bibitem[Shalev-Shwartz \& Zhang(2012)Shalev-Shwartz and
  Zhang]{ShalevShwartz:2012tn}
Shalev-Shwartz, S. and Zhang, T.
\newblock Proximal stochastic dual coordinate ascent.
\newblock Technical Report 1211.2717v1 [stat.ML], arXiv, November 2012.

\bibitem[Shalev-Shwartz et~al.(2010{\natexlab{a}})Shalev-Shwartz, Singer,
  Srebro, and Cotter]{ShalevShwartz:2010cg}
Shalev-Shwartz, S., Singer, Y., Srebro, N., and Cotter, A.
\newblock Pegasos: primal estimated sub-gradient solver for {SVM}.
\newblock \emph{Mathematical Programming}, 127\penalty0 (1),
  2010{\natexlab{a}}.

\bibitem[Shalev-Shwartz et~al.(2010{\natexlab{b}})Shalev-Shwartz, Srebro, and
  Zhang]{ShalevShwartz:2010wq}
Shalev-Shwartz, S., Srebro, N., and Zhang, T.
\newblock Trading accuracy for sparsity in optimization problems with sparsity
  constraints.
\newblock \emph{SIAM Journal on Optimization}, 20:\penalty0 2807â€“--2832,
  2010{\natexlab{b}}.

\bibitem[Shamir \& Zhang(2013)Shamir and Zhang]{Shamir:2013vw}
Shamir, O. and Zhang, T.
\newblock Stochastic gradient descent for non-smooth optimization: Convergence
  results and optimal averaging schemes.
\newblock In \emph{ICML}, 2013.

\bibitem[Taskar(2004)]{taskar04thesis}
Taskar, B.
\newblock \emph{Learning structured prediction models: A large margin
  approach}.
\newblock PhD thesis, Stanford, 2004.

\bibitem[Taskar et~al.(2003)Taskar, Guestrin, and Koller]{Taskar2003}
Taskar, B., Guestrin, C., and Koller, D.
\newblock Max-margin {M}arkov networks.
\newblock In \emph{NIPS}, 2003.

\bibitem[Taskar et~al.(2006)Taskar, Lacoste-Julien, and Jordan]{Taskar06extrag}
Taskar, B., Lacoste-Julien, S., and Jordan, M.~I.
\newblock Structured prediction, dual extragradient and {B}regman projections.
\newblock \emph{JMLR}, 7:\penalty0 1627--1653, 2006.

\bibitem[Teo et~al.(2010)Teo, Vishwanathan, Smola, and Le]{Teo:2010bundle}
Teo, C.H., Vishwanathan, S.V.N., Smola, A.J., and Le, Q.V.
\newblock Bundle methods for regularized risk minimization.
\newblock \emph{JMLR}, 11:\penalty0 311--365, 2010.

\bibitem[Tsochantaridis et~al.(2005)Tsochantaridis, Joachims, Hofmann, and
  Altun]{Tsochantaridis2005}
Tsochantaridis, I., Joachims, T., Hofmann, T., and Altun, Y.
\newblock Large margin methods for structured and interdependent output
  variables.
\newblock \emph{JMLR}, 6:\penalty0 1453--1484, 2005.

\bibitem[Zhang et~al.(2011)Zhang, Saha, and Vishwanathan]{Zhang:2011:ATM3net}
Zhang, X., Saha, A., and Vishwanathan, S. V.~N.
\newblock Accelerated training of max-margin {M}arkov networks with kernels.
\newblock In \emph{ALT}, pp.\  292--307. Springer, 2011.

\end{thebibliography}
