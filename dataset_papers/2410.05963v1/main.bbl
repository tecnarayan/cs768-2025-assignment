\begin{thebibliography}{10}

\bibitem{attentionflow}
Samira Abnar and Willem~H. Zuidema.
\newblock Quantifying attention flow in transformers.
\newblock In Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel~R. Tetreault, editors, {\em {Annual Meeting of the Association for Computational Linguistics (ACL)}}, 2020.

\bibitem{achiam2023gpt}
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et~al.
\newblock Gpt-4 technical report.
\newblock {\em arXiv preprint arXiv:2303.08774}, 2023.

\bibitem{gpt3}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et~al.
\newblock Language models are few-shot learners.
\newblock {\em {Neural Information Processing Systems (NeurIPS)}}, 2020.

\bibitem{cai2018cascadercnn}
Zhaowei Cai and Nuno Vasconcelos.
\newblock Cascade r-cnn: Delving into high quality object detection.
\newblock In {\em {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}}, 2018.

\bibitem{caron2021dino}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv{\'e} J{\'e}gou, Julien Mairal, Piotr Bojanowski, and Armand Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In {\em {IEEE International Conference on Computer Vision (ICCV)}}, 2021.

\bibitem{chen2023open}
Xi~Chen, Shuang Li, Ser-Nam Lim, Antonio Torralba, and Hengshuang Zhao.
\newblock Open-vocabulary panoptic segmentation with embedding modulation.
\newblock In {\em {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}}, 2023.

\bibitem{cheng2024yoloworld}
Tianheng Cheng, Lin Song, Yixiao Ge, Wenyu Liu, Xinggang Wang, and Ying Shan.
\newblock Yolo-world: Real-time open-vocabulary object detection.
\newblock {\em arXiv preprint arXiv:2401.17270}, 2024.

\bibitem{chiang2023vicuna}
Wei-Lin Chiang, Zhuohan Li, Zi~Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph~E Gonzalez, et~al.
\newblock Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality.
\newblock {\em See https://vicuna. lmsys. org (accessed 14 April 2023)}, 2023.

\bibitem{dave2021fixedap}
Achal Dave, Piotr Doll{\'a}r, Deva Ramanan, Alexander Kirillov, and Ross Girshick.
\newblock Evaluating large-vocabulary object detectors: The devil is in the details.
\newblock {\em arXiv preprint arXiv:2102.01066}, 2021.

\bibitem{dosovitskiy2020vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In {\em ICLR}, 2020.

\bibitem{GLM}
Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang.
\newblock {GLM:} general language model pretraining with autoregressive blank infilling.
\newblock In {\em {Annual Meeting of the Association for Computational Linguistics (ACL)}}, 2022.

\bibitem{gao2023llamaadapterv2}
Peng Gao, Jiaming Han, Renrui Zhang, Ziyi Lin, Shijie Geng, Aojun Zhou, Wei Zhang, Pan Lu, Conghui He, Xiangyu Yue, et~al.
\newblock Llama-adapter v2: Parameter-efficient visual instruction model.
\newblock {\em arXiv preprint arXiv:2304.15010}, 2023.

\bibitem{girshick2015fastrcnn}
Ross Girshick.
\newblock Fast r-cnn.
\newblock In {\em {IEEE International Conference on Computer Vision (ICCV)}}, 2015.

\bibitem{gupta2019lvis}
Agrim Gupta, Piotr Dollar, and Ross Girshick.
\newblock Lvis: A dataset for large vocabulary instance segmentation.
\newblock In {\em {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}}, 2019.

\bibitem{gupta2022owdetr}
Akshita Gupta, Sanath Narayan, KJ~Joseph, Salman Khan, Fahad~Shahbaz Khan, and Mubarak Shah.
\newblock Ow-detr: Open-world detection transformer.
\newblock In {\em {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}}, 2022.

\bibitem{he2017maskrcnn}
Kaiming He, Georgia Gkioxari, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Mask r-cnn.
\newblock In {\em {IEEE International Conference on Computer Vision (ICCV)}}, 2017.

\bibitem{hong2023cogagent}
Wenyi Hong, Weihan Wang, Qingsong Lv, Jiazheng Xu, Wenmeng Yu, Junhui Ji, Yan Wang, Zihan Wang, Yuxiao Dong, Ming Ding, et~al.
\newblock Cogagent: A visual language model for gui agents.
\newblock {\em arXiv preprint arXiv:2312.08914}, 2023.

\bibitem{huang2023tag2text}
Xinyu Huang, Youcai Zhang, Jinyu Ma, Weiwei Tian, Rui Feng, Yuejie Zhang, Yaqian Li, Yandong Guo, and Lei Zhang.
\newblock Tag2text: Guiding vision-language model via image tagging.
\newblock {\em arXiv preprint arXiv:2303.05657}, 2023.

\bibitem{joseph2021ore}
KJ~Joseph, Salman Khan, Fahad~Shahbaz Khan, and Vineeth~N Balasubramanian.
\newblock Towards open world object detection.
\newblock In {\em {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}}, 2021.

\bibitem{kirillov2023sam}
Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander~C Berg, Wan-Yen Lo, et~al.
\newblock Segment anything.
\newblock In {\em {IEEE International Conference on Computer Vision (ICCV)}}, 2023.

\bibitem{krishna2017vg}
Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David~A Shamma, et~al.
\newblock Visual genome: Connecting language and vision using crowdsourced dense image annotations.
\newblock {\em {International Journal on Computer Vision (IJCV)}}, 2017.

\bibitem{li2023maskdino}
Feng Li, Hao Zhang, Huaizhe Xu, Shilong Liu, Lei Zhang, Lionel~M Ni, and Heung-Yeung Shum.
\newblock Mask dino: Towards a unified transformer-based framework for object detection and segmentation.
\newblock In {\em {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}}, 2023.

\bibitem{li2023blip}
Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi.
\newblock Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models.
\newblock In {\em {International Conference on Machine Learning (ICML)}}, 2023.

\bibitem{li2022coda}
Kaican Li, Kai Chen, Haoyu Wang, Lanqing Hong, Chaoqiang Ye, Jianhua Han, Yukuai Chen, Wei Zhang, Chunjing Xu, Dit-Yan Yeung, et~al.
\newblock Coda: A real-world road corner case dataset for object detection in autonomous driving.
\newblock In {\em {European Conference on Computer Vision (ECCV)}}, 2022.

\bibitem{glip}
Liunian~Harold Li, Pengchuan Zhang, Haotian Zhang, Jianwei Yang, Chunyuan Li, Yiwu Zhong, Lijuan Wang, Lu~Yuan, Lei Zhang, Jenq-Neng Hwang, et~al.
\newblock Grounded language-image pre-training.
\newblock In {\em {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}}, 2022.

\bibitem{lin2024generateu}
Chuang Lin, Yi~Jiang, Lizhen Qu, Zehuan Yuan, and Jianfei Cai.
\newblock Generative region-language pretraining for open-ended object detection.
\newblock {\em arXiv preprint arXiv:2403.10191}, 2024.

\bibitem{retinanet}
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll{\'a}r.
\newblock Focal loss for dense object detection.
\newblock In {\em {IEEE International Conference on Computer Vision (ICCV)}}, 2017.

\bibitem{lin2023sphinx}
Ziyi Lin, Chris Liu, Renrui Zhang, Peng Gao, Longtian Qiu, Han Xiao, Han Qiu, Chen Lin, Wenqi Shao, Keqin Chen, et~al.
\newblock Sphinx: The joint mixing of weights, tasks, and visual embeddings for multi-modal large language models.
\newblock {\em arXiv preprint arXiv:2311.07575}, 2023.

\bibitem{liu2024llava}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee.
\newblock Visual instruction tuning.
\newblock {\em {Neural Information Processing Systems (NeurIPS)}}, 2023.

\bibitem{liu2023groundingdino}
Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao Zhang, Jie Yang, Chunyuan Li, Jianwei Yang, Hang Su, Jun Zhu, et~al.
\newblock Grounding dino: Marrying dino with grounded pre-training for open-set object detection.
\newblock {\em arXiv preprint arXiv:2303.05499}, 2023.

\bibitem{liu2021swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted windows.
\newblock In {\em ICCV}, 2021.

\bibitem{owlv2}
Matthias Minderer, Alexey Gritsenko, and Neil Houlsby.
\newblock Scaling open-vocabulary object detection.
\newblock {\em {Neural Information Processing Systems (NeurIPS)}}, 2023.

\bibitem{peng2023instructiongrit}
Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao.
\newblock Instruction tuning with gpt-4.
\newblock {\em arXiv preprint arXiv:2304.03277}, 2023.

\bibitem{DeFRCN}
Peter Pinggera, Sebastian Ramos, Stefan Gehrig, Uwe Franke, Carsten Rother, and Rudolf Mester.
\newblock Lost and found: detecting small road hazards for self-driving vehicles.
\newblock In {\em International Conference on Intelligent Robots and Systems (IROS)}, 2016.

\bibitem{clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In {\em {International Conference on Machine Learning (ICML)}}, 2021.

\bibitem{ren2015fasterrcnn}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster r-cnn: Towards real-time object detection with region proposal networks.
\newblock {\em {Neural Information Processing Systems (NeurIPS)}}, 2015.

\bibitem{scheirer2012openset}
Walter~J Scheirer, Anderson de~Rezende~Rocha, Archana Sapkota, and Terrance~E Boult.
\newblock Toward open set recognition.
\newblock {\em {IEEE Transactions on Pattern Recognition and Machine Intelligence (PAMI)}}, 2012.

\bibitem{sun2021sparsercnn}
Peize Sun, Rufeng Zhang, Yi~Jiang, Tao Kong, Chenfeng Xu, Wei Zhan, Masayoshi Tomizuka, Lei Li, Zehuan Yuan, Changhu Wang, et~al.
\newblock Sparse r-cnn: End-to-end object detection with learnable proposals.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 14454--14463, 2021.

\bibitem{sun2023eva}
Quan Sun, Yuxin Fang, Ledell Wu, Xinlong Wang, and Yue Cao.
\newblock Eva-clip: Improved training techniques for clip at scale.
\newblock {\em arXiv preprint arXiv:2303.15389}, 2023.

\bibitem{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock {\em arXiv preprint arXiv:2302.13971}, 2023.

\bibitem{wang2023cogvlm}
Weihan Wang, Qingsong Lv, Wenmeng Yu, Wenyi Hong, Ji~Qi, Yan Wang, Junhui Ji, Zhuoyi Yang, Lei Zhao, Xixuan Song, et~al.
\newblock Cogvlm: Visual expert for pretrained language models.
\newblock {\em arXiv preprint arXiv:2311.03079}, 2023.

\bibitem{FSDet}
Xin Wang, Thomas~E. Huang, Joseph Gonzalez, Trevor Darrell, and Fisher Yu.
\newblock Frustratingly simple few-shot object detection.
\newblock In {\em {International Conference on Machine Learning (ICML)}}, 2020.

\bibitem{wang2023detecting}
Zhenyu Wang, Yali Li, Xi~Chen, Ser-Nam Lim, Antonio Torralba, Hengshuang Zhao, and Shengjin Wang.
\newblock Detecting everything in the open world: Towards universal object detection.
\newblock In {\em {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}}, 2023.

\bibitem{wen2023gpt4v}
Licheng Wen, Xuemeng Yang, Daocheng Fu, Xiaofeng Wang, Pinlong Cai, Xin Li, Tao Ma, Yingxuan Li, Linran Xu, Dengke Shang, et~al.
\newblock On the road with gpt-4v (ision): Early explorations of visual-language model on autonomous driving.
\newblock {\em arXiv preprint arXiv:2311.05332}, 2023.

\bibitem{wu2023exploring}
Jiannan Wu, Yi~Jiang, Bin Yan, Huchuan Lu, Zehuan Yuan, and Ping Luo.
\newblock Exploring transformers for open-world instance segmentation.
\newblock In {\em {IEEE International Conference on Computer Vision (ICCV)}}, 2023.

\bibitem{xiong2023efficientsam}
Yunyang Xiong, Bala Varadarajan, Lemeng Wu, Xiaoyu Xiang, Fanyi Xiao, Chenchen Zhu, Xiaoliang Dai, Dilin Wang, Fei Sun, Forrest Iandola, et~al.
\newblock Efficientsam: Leveraged masked image pretraining for efficient segment anything.
\newblock {\em arXiv preprint arXiv:2312.00863}, 2023.

\bibitem{yao2022detclip}
Lewei Yao, Jianhua Han, Youpeng Wen, Xiaodan Liang, Dan Xu, Wei Zhang, Zhenguo Li, Chunjing Xu, and Hang Xu.
\newblock Detclip: Dictionary-enriched visual-concept paralleled pre-training for open-world detection.
\newblock {\em {Neural Information Processing Systems (NeurIPS)}}, 2022.

\bibitem{yao2024detclipv3}
Lewei Yao, Renjie Pi, Jianhua Han, Xiaodan Liang, Hang Xu, Wei Zhang, Zhenguo Li, and Dan Xu.
\newblock Detclipv3: Towards versatile generative open-vocabulary object detection.
\newblock {\em arXiv preprint arXiv:2404.09216}, 2024.

\bibitem{yuan2024Open-Vocabulary-SAM}
Haobo Yuan, Xiangtai Li, Chong Zhou, Yining Li, Kai Chen, and Chen~Change Loy.
\newblock Open-vocabulary sam: Segment and recognize twenty-thousand classes interactively.
\newblock {\em arXiv preprint arXiv:2401.02955}, 2024.

\bibitem{mobile_sam}
Chaoning Zhang, Dongshen Han, Yu~Qiao, Jung~Uk Kim, Sung-Ho Bae, Seungkyu Lee, and Choong~Seon Hong.
\newblock Faster segment anything: Towards lightweight sam for mobile applications.
\newblock {\em arXiv preprint arXiv:2306.14289}, 2023.

\bibitem{zhang2023llavaground}
Hao Zhang, Hongyang Li, Feng Li, Tianhe Ren, Xueyan Zou, Shilong Liu, Shijia Huang, Jianfeng Gao, Lei Zhang, Chunyuan Li, et~al.
\newblock Llava-grounding: Grounded visual chat with large multimodal models.
\newblock {\em arXiv preprint arXiv:2312.02949}, 2023.

\bibitem{zhang2022glipv2}
Haotian Zhang, Pengchuan Zhang, Xiaowei Hu, Yen-Chun Chen, Liunian Li, Xiyang Dai, Lijuan Wang, Lu~Yuan, Jenq-Neng Hwang, and Jianfeng Gao.
\newblock Glipv2: Unifying localization and vision-language understanding.
\newblock {\em {Neural Information Processing Systems (NeurIPS)}}, 2022.

\bibitem{zhang2023llamaadapter}
Renrui Zhang, Jiaming Han, Chris Liu, Peng Gao, Aojun Zhou, Xiangfei Hu, Shilin Yan, Pan Lu, Hongsheng Li, and Yu~Qiao.
\newblock Llama-adapter: Efficient fine-tuning of language models with zero-init attention.
\newblock {\em arXiv preprint arXiv:2303.16199}, 2023.

\bibitem{zhang2023persam}
Renrui Zhang, Zhengkai Jiang, Ziyu Guo, Shilin Yan, Junting Pan, Xianzheng Ma, Hao Dong, Peng Gao, and Hongsheng Li.
\newblock Personalize segment anything model with one shot.
\newblock {\em arXiv preprint arXiv:2305.03048}, 2023.

\bibitem{zhu2023minigpt}
Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny.
\newblock Minigpt-4: Enhancing vision-language understanding with advanced large language models.
\newblock {\em arXiv preprint arXiv:2304.10592}, 2023.

\bibitem{zhu2020deformable}
Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai.
\newblock Deformable {DETR:} deformable transformers for end-to-end object detection.
\newblock In {\em {International Conference on Learning Representations (ICLR)}}, 2021.

\bibitem{zhu2024llavaphi}
Yichen Zhu, Minjie Zhu, Ning Liu, Zhicai Ou, Xiaofeng Mou, and Jian Tang.
\newblock Llava-phi: Efficient multi-modal assistant with small language model.
\newblock {\em arXiv preprint arXiv:2401.02330}, 2024.

\end{thebibliography}
