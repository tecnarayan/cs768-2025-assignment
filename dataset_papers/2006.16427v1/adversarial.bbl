\begin{thebibliography}{10}

\bibitem{AdvPerturbations}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock 'intriguing properties of neural networks'.
\newblock {\em International Conference on Learning Representations}, 2014.

\bibitem{BrainScore}
Martin Schrimpf, Jonas Kubilius, Ha~Hong, Najib~J. Majaj, Rishi Rajalingham,
  Elias~B. Issa, Kohitij Kar, Pouya Bashivan, Jonathan Prescott-Roy, Kailyn
  Schmidt, Daniel L.~K. Yamins, and James~J. DiCarlo.
\newblock Brain-score: Which artificial neural network for object recognition
  is most brain-like?
\newblock {\em bioRxiv preprint}, 2018.

\bibitem{NeuralPopulationControl}
Pouya Bashivan, Kohitij Kar, and James~J. DiCarlo.
\newblock Neural population control via deep image synthesis.
\newblock {\em Science}, 364, 2019.

\bibitem{GoalDrivenModelsForCortex}
Daniel L~K Yamins and James~J DiCarlo.
\newblock Using goal-driven deep learning models to understand sensory cortex.
\newblock {\em Nature Neuroscience}, 2016.

\bibitem{alex2017eigendistortions}
Alexander Berardino, Johannes Ballé, Valero Laparra, and Eero~P. Simoncelli.
\newblock Eigen-distortions of hierarchical representations, 2017.

\bibitem{AdvTurtle}
Anish Athalye, Logan Engstrom, Andrew Ilyas, and Kevin Kwok.
\newblock Synthesizing robust adversarial examples.
\newblock {\em International Conference on Machine Learning}, 2018.

\bibitem{DefensiveDistillation}
Nicolas Papernot, Patrick McDaniel, Xi~Wu, Somesh Jha, and Ananthram Swami.
\newblock Distillation as a defense to adversarial perturbations against deep
  neural networks.
\newblock {\em IEEE Symposium on Security and Privacy}, 2016.

\bibitem{FeatureSqueezing}
Weilin Xu, David Evans, and Yanjun Qi.
\newblock Feature squeezing: Detecting adversarial examples in deep neural
  networks.
\newblock {\em Network and Distributed Systems Security Symposium}, 2018.

\bibitem{DefensiveRandomization}
Cihang Xie, Jianyu Wang, Zhishuai Zhang, Zhou Ren, and Alan Yuille.
\newblock Mitigating adversarial effects through randomization.
\newblock {\em International Conference on Learning Representations}, 2018.

\bibitem{MadryAdvTrain}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock {\em International Conference on Learning Representations}, 2018.

\bibitem{GradientObfuscation}
Anish Athalye, Nicholas Carlini, and David Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock {\em International Conference on Machine Learning}, 2018.

\bibitem{EvalGuidelines}
Nicholas Carlini, Anish Athalye, Nicolas Papernot, Wieland Brendel, Jonas
  Rauber, Dimitris Tsipras, Ian Goodfellow, Aleksander Madry, and Alexey
  Kurakin.
\newblock On evaluating adversarial robustness.
\newblock {\em arXiv preprint}, 2019.

\bibitem{DeepMindAdvRisk}
Jonathan Uesato, Brendan O’Donoghue, Aaron van~den Oord, and Pushmeet Kohli.
\newblock Adversarial risk and the dangers of evaluating against weak attacks.
\newblock {\em International Conference on Machine Learning}, 2018.

\bibitem{CWPGD}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock {\em arXiv preprint}, 2018.

\bibitem{BayesianDefense}
Lukas Schott, Jonas Rauber, Matthias Bethge, and Wieland Brendel.
\newblock Towards the first adversarially robust neural network model on mnist.
\newblock {\em International Conference on Learning Representations}, 2019.

\bibitem{BypassFeatureSqueeze}
Warren He, James Wei, Xinyun Chen, Nicholas Carlini, and Dawn Song.
\newblock Adversarial example defenses: Ensembles of weak defenses are not
  strong.
\newblock {\em arXiv preprint}, 2017.

\bibitem{RobustVSAcc}
Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and
  Aleksander Madry.
\newblock 'robustness may be at odds with accuracy'.
\newblock {\em International Conference on Learning Representations}, 2019.

\bibitem{blindspotattack}
Huan Zhang, Hongge Chen, Zhao Song, Duane Boning, Inderjit~S. Dhillon, and
  Cho-Jui Hsieh.
\newblock 'the limitations of adversarial training and the blind-spot attack'.
\newblock {\em International Conference on Learning Representations}, 2019.

\bibitem{AdvFeatures}
Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon
  Tran, and Aleksander Madry.
\newblock Adversarial examples are not bugs, they are features.
\newblock {\em Advances in Neural Information Processing Systems}, 2019.

\bibitem{RobustFeatureManipulate}
Shibani Santurkar, Andrew Ilyas, Dimitris Tsipras, Logan Engstrom, Brandon
  Tran, and Aleksander Madry.
\newblock Image synthesis with a single (robust) classifier.
\newblock {\em Advances in Neural Information Processing Systems}, pages
  1260--1271, 2019.

\bibitem{RobustFeatureRepresentations}
Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Brandon
  Tran, and Aleksander Madry.
\newblock Adversarial robustness as a prior for learned representations.
\newblock {\em arXiv preprint}, 2019.

\bibitem{AdvHumans}
Gamaleldin~F. Elsayed, Shreya Shankar, Brian Cheung, Nicolas Papernot, Alex
  Kurakin, Ian Goodfellow, and Jascha Sohl-Dickstein.
\newblock Adversarial examples that fool both computer vision and time-limited
  humans.
\newblock {\em Advances in Neural Information Processing Systems}, 2018.

\bibitem{Freeman2011}
J.~Freeman and Eero Simoncelli.
\newblock Metamers of the ventral stream.
\newblock {\em Nature Neuroscience}, 14:1195–1201, 2011.

\bibitem{Gattass1981}
R~Gattass, C~G Gross, and J~H Sandell.
\newblock Visual topography of v2 in the macaque.
\newblock {\em The Journal of Comparative Neurology}, 1981.

\bibitem{Gattass1988}
R~Gattass, AP~Sousa, and CG~Gross.
\newblock Visuotopic organization and extent of v3 and v4 of the macaque.
\newblock {\em Journal of Neuroscience}, 1988.

\bibitem{ECNN_MTHEORY}
Tomaso Poggio, Jim Mutch, and Leyla Isik.
\newblock Computational role of eccentricity dependent cortical magnification.
\newblock {\em CBMM Memo}, 2014.

\bibitem{ECNN_SCALE}
Francis~X. Chen, Gemma Roig, Leyla Isik, Xavier Boix, and Tomaso Poggio.
\newblock Eccentricity dependent deep neural networks: Modeling invariance in
  human vision.
\newblock {\em Association for the Advancement of Artificial Intelligence},
  2017.

\bibitem{ECNN_CROWDING}
Anna Volokitin, Gemma Roig, and Tomaso Poggio.
\newblock Do deep neural networks suffer from crowding?
\newblock {\em Advances in Neural Information Processing Systems}, 2017.

\bibitem{yena}
Yena Han, Gemma Roig, Gad Geiger, and Tomaso Poggio.
\newblock Scale and translation-invariance for novel objects in human vision.
\newblock {\em Scientific Reports}, 10, 12 2020.

\bibitem{CIFAR}
A~Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock {\em Technical Report}, 2009.

\bibitem{IMAGENET_dataset}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang,
  A.~Karpathy, A.~Khosla, Bernstein M., A.C. Berg, and Fei-Fei L.
\newblock Large scale visual recognition challenge.
\newblock {\em ImageNet, arXiv:1409.0575}, 2014.

\bibitem{Marretal1980}
E.~Hildreth D.~Marr, T.~Poggio.
\newblock Smallest channel in early human vision.
\newblock {\em Journal of the Optical Society of America}, 1980.

\bibitem{EXTREMELYDEEP_MS_2015}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock {\em Conference on Computer Vision and Pattern Recognition}, 2016.

\bibitem{foolbox}
Jonas Rauber, Wieland Brendel, and Matthias Bethge.
\newblock Foolbox: A python toolbox to benchmark the robustness of machine
  learning models.
\newblock {\em arXiv preprint arXiv:1707.04131}, 2017.

\bibitem{PGD}
Alexey Kurakin, Ian~J. Goodfellow, and Samy Bengio.
\newblock Adversarial examples in the physical world.
\newblock {\em International Conference on Learning Representations}, 2017.

\bibitem{MinimalExamples}
Nicholas Carlini, Guy Katz, Clark Barrett, and David~L. Dill.
\newblock Provably minimally-distorted adversarial examples.
\newblock {\em arXiv preprint}, 2018.

\bibitem{adv_perceptual}
Zhengyu Zhao, Zhuoran Liu, and Martha Larson.
\newblock Towards large yet imperceptible adversarial image perturbations with
  perceptual color distance.
\newblock {\em arXiv preprint}, 2019.

\bibitem{AdvTrainDenoiseFB}
Cihang Xie, Yuxin Wu, Laurens van~der Maaten, Alan Yuille, and Kaiming He.
\newblock Feature denoising for improving adversarial robustness.
\newblock {\em Conference on Computer Vision and Pattern Recognition}, 2019.

\bibitem{AvgFilter}
Xin Li and Fuxin Li.
\newblock Adversarial examples detection in deep networks with convolutional
  filter statistics.
\newblock {\em International Conference on Computer Vision}, 2017.

\bibitem{BoundaryAttack}
Wieland Brendel, Jonas Rauber, and Matthias Bethge.
\newblock Decision-based adversarial attacks: Reliable attacks against
  black-box machine learning models.
\newblock {\em International Conference on Learning Representations}, 2018.

\end{thebibliography}
