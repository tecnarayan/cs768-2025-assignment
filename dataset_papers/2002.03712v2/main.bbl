\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alsing et~al.(2019)Alsing, Charnock, Feeney, and
  Wandelt]{alsing-2019-fast}
Alsing, J., Charnock, T., Feeney, S., and Wandelt, B.
\newblock Fast likelihood-free cosmology with neural density estimators and
  active learning.
\newblock \emph{Monthly Notices of the Royal Astronomical Society},
  488\penalty0 (3):\penalty0 4440--4458, 2019.

\bibitem[Beaumont(2010)]{beaumont-2010-abc_evo_eco}
Beaumont, M.~A.
\newblock Approximate {B}ayesian computation in evolution and ecology.
\newblock \emph{Annual Review of Ecology, Evolution, and Systematics},
  41\penalty0 (1):\penalty0 379--406, 2010.

\bibitem[Beaumont(2019)]{beaumont-2019-abcreview}
Beaumont, M.~A.
\newblock Approximate {B}ayesian computation.
\newblock \emph{Annual Review of Statistics and Its Application}, 6\penalty0
  (1):\penalty0 379--403, 2019.

\bibitem[Beaumont et~al.(2009)Beaumont, Cornuet, Marin, and
  Robert]{beaumont-2009-smc_abc}
Beaumont, M.~A., Cornuet, J.-M., Marin, J.-M., and Robert, C.~P.
\newblock Adaptive approximate {B}ayesian computation.
\newblock \emph{Biometrika}, 96\penalty0 (4):\penalty0 983--990, 2009.

\bibitem[Belghazi et~al.(2018)Belghazi, Baratin, Rajeshwar, Ozair, Bengio,
  Courville, and Hjelm]{belghazi-2018-mine}
Belghazi, M.~I., Baratin, A., Rajeshwar, S., Ozair, S., Bengio, Y., Courville,
  A., and Hjelm, D.
\newblock Mutual information neural estimation.
\newblock \emph{International Conference on Machine Learning}, 2018.

\bibitem[Bishop(1994)]{bishop-1994-mdn}
Bishop, C.~M.
\newblock Mixture density networks.
\newblock Technical Report NCRG/94/004, Aston University, 1994.

\bibitem[Brehmer et~al.(2018{\natexlab{a}})Brehmer, Cranmer, Louppe, and
  Pavez]{brehmer-2018-constraining}
Brehmer, J., Cranmer, K., Louppe, G., and Pavez, J.
\newblock Constraining effective field theories with machine learning.
\newblock \emph{Physical {R}eview {L}etters}, 121\penalty0 (11):\penalty0
  111801, 2018{\natexlab{a}}.

\bibitem[Brehmer et~al.(2018{\natexlab{b}})Brehmer, Louppe, Pavez, and
  Cranmer]{brehmer-2018-mining}
Brehmer, J., Louppe, G., Pavez, J., and Cranmer, K.
\newblock Mining gold from implicit models to improve likelihood-free
  inference.
\newblock \emph{arXiv preprint arXiv:1805.12244}, 2018{\natexlab{b}}.

\bibitem[Cranmer et~al.(2016)Cranmer, Pavez, and Louppe]{cranmer-2016-carl}
Cranmer, K., Pavez, J., and Louppe, G.
\newblock Approximating likelihood ratios with calibrated discriminative
  classifiers.
\newblock \emph{arXiv preprint arXiv:1506.02169}, 2016.

\bibitem[Cranmer et~al.(2019)Cranmer, Brehmer, and
  Louppe]{cranmer-2019-frontier}
Cranmer, K., Brehmer, J., and Louppe, G.
\newblock The frontier of simulation-based inference.
\newblock \emph{arXiv preprint arXiv:1911.01429}, 2019.

\bibitem[Dalmasso et~al.(2019)Dalmasso, Lee, Izbicki, Pospisil, and
  Lin]{dalmasso-2019-validation}
Dalmasso, N., Lee, A.~B., Izbicki, R., Pospisil, T., and Lin, C.-A.
\newblock Validation of approximate likelihood and emulator models for
  computationally intensive simulations.
\newblock \emph{arXiv preprint arXiv:1905.11505}, 2019.

\bibitem[Durkan et~al.(2019)Durkan, Bekasov, Murray, and
  Papamakarios]{durkan-2019-cubic}
Durkan, C., Bekasov, A., Murray, I., and Papamakarios, G.
\newblock Cubic-spline flows.
\newblock \emph{Workshop on Invertible Neural Networks and Normalizing flows at
  the International Conference on Machine Learning}, 2019.

\bibitem[Fan et~al.(2013)Fan, Nott, and Sisson]{fan-2013-abc}
Fan, Y., Nott, D.~J., and Sisson, S.~A.
\newblock Approximate {B}ayesian computation via regression density estimation.
\newblock \emph{Stat}, 2\penalty0 (1):\penalty0 34--48, 2013.

\bibitem[Fasiolo et~al.(2018)Fasiolo, Wood, Hartig, and
  Bravington]{fasiolo-2018-saddlepoint}
Fasiolo, M., Wood, S.~N., Hartig, F., and Bravington, M.~V.
\newblock An extended empirical saddlepoint approximation for intractable
  likelihoods.
\newblock \emph{Electronic Journal of Statistics}, 12\penalty0 (1):\penalty0
  1544--1578, 2018.

\bibitem[Germain et~al.(2015)Germain, Gregor, Murray, and
  Larochelle]{germain-2015-made}
Germain, M., Gregor, K., Murray, I., and Larochelle, H.
\newblock {MADE}: Masked autoencoder for distribution estimation.
\newblock \emph{International Conference on Machine Learning}, 2015.

\bibitem[Gon{\c{c}}alves et~al.(2019)Gon{\c{c}}alves, Lueckmann, Deistler,
  Nonnenmacher, {\"O}cal, Bassetto, Chintaluri, Podlaski, Haddad, Vogels,
  Greenberg, and Macke]{gonccalves-2019-training}
Gon{\c{c}}alves, P.~J., Lueckmann, J.-M., Deistler, M., Nonnenmacher, M.,
  {\"O}cal, K., Bassetto, G., Chintaluri, C., Podlaski, W.~F., Haddad, S.~A.,
  Vogels, T.~P., Greenberg, D.~S., and Macke, J.~H.
\newblock Training deep neural density estimators to identify mechanistic
  models of neural dynamics.
\newblock \emph{bioRxiv}, pp.\  838383, 2019.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow-2014-gans}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock \emph{Advances in Neural Information Processing Systems}, 2014.

\bibitem[Gordon et~al.(2014)Gordon, Henzinger, Nori, and
  Rajamani]{gordon-2014-probprog}
Gordon, A.~D., Henzinger, T.~A., Nori, A.~V., and Rajamani, S.~K.
\newblock Probabilistic programming.
\newblock \emph{Proceedings of the on Future of Software Engineering}, pp.\
  167--181, 2014.

\bibitem[Greenberg et~al.(2019)Greenberg, Nonnenmacher, and
  Macke]{greenberg-2019-apt}
Greenberg, D.~S., Nonnenmacher, M., and Macke, J.~H.
\newblock Automatic posterior transformation for likelihood-free inference.
\newblock \emph{International Conference on Machine Learning}, 2019.

\bibitem[Gutmann \& Hyv{\"a}rinen(2010)Gutmann and
  Hyv{\"a}rinen]{gutmann-2010-nce}
Gutmann, M. and Hyv{\"a}rinen, A.
\newblock Noise-contrastive estimation: {A} new estimation principle for
  unnormalized statistical models.
\newblock \emph{International Conference on Artificial Intelligence and
  Statistics}, 2010.

\bibitem[Gutmann \& Corander(2016)Gutmann and Corander]{gutmann-2016-bolfi}
Gutmann, M.~U. and Corander, J.
\newblock {B}ayesian optimization for likelihood-free inference of
  simulator-based statistical models.
\newblock \emph{Journal of Machine Learning Research}, 17\penalty0
  (125):\penalty0 1--47, 2016.

\bibitem[Gutmann et~al.(2018)Gutmann, Dutta, Kaski, and
  Corander]{gutmann-2018-classification}
Gutmann, M.~U., Dutta, R., Kaski, S., and Corander, J.
\newblock Likelihood-free inference via classification.
\newblock \emph{Statistics and Computing}, 28\penalty0 (2):\penalty0 411--425,
  2018.

\bibitem[Hastie et~al.(2001)Hastie, Tibshirani, and
  Friedman]{hastie-2001-elements}
Hastie, T., Tibshirani, R., and Friedman, J.
\newblock \emph{The Elements of Statistical Learning}.
\newblock Springer Series in Statistics. Springer New York, 2001.

\bibitem[He et~al.(2019)He, Fan, Wu, Xie, and
  Girshick]{he-2019-momentum-contrast}
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock \emph{arXiv preprint arXiv:1911.05722}, 2019.

\bibitem[H{\'e}naff et~al.(2019)H{\'e}naff, Razavi, Doersch, Eslami, and
  van~den Oord]{henaff-2019-cpc-extended}
H{\'e}naff, O.~J., Razavi, A., Doersch, C., Eslami, S., and van~den Oord, A.
\newblock Data-efficient image recognition with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1905.09272}, 2019.

\bibitem[Hermans et~al.(2020)Hermans, Begy, and Louppe]{hermans-2019-sre}
Hermans, J., Begy, V., and Louppe, G.
\newblock Likelihood-free {MCMC} with amortized approximate ratio estimators.
\newblock \emph{International Conference on Machine Learning}, 2020.

\bibitem[Izbicki et~al.(2014)Izbicki, Lee, and
  Schafer]{izbicki-2014-density-ratio}
Izbicki, R., Lee, A.~B., and Schafer, C.
\newblock High-dimensional density ratio estimation with extensions to
  approximate likelihood computation.
\newblock \emph{International Conference on Artificial Intelligence and
  Statistics}, 2014.

\bibitem[J\"arvenp\"a\"a et~al.(2018)J\"arvenp\"a\"a, Gutmann, Vehtari, and
  Marttinen]{jarvenpaa-2018-efficient}
J\"arvenp\"a\"a, M., Gutmann, M., Vehtari, A., and Marttinen, P.
\newblock Efficient acquisition rules for model-based approximate {B}ayesian
  computation.
\newblock \emph{Bayesian Analysis}, 2018.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{kingma-2014-adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{International Conference on Learning Representations}, 2015.

\bibitem[Lintusaari et~al.(2016)Lintusaari, Gutmann, Dutta, Kaski, and
  Corander]{lintusaari-2016-abcreview}
Lintusaari, J., Gutmann, M.~U., Dutta, R., Kaski, S., and Corander, J.
\newblock Fundamentals and recent developments in approximate {B}ayesian
  computation.
\newblock \emph{Systematic Biology}, 66\penalty0 (1):\penalty0 e66--e82, 2016.

\bibitem[Lueckmann et~al.(2017)Lueckmann, Goncalves, Bassetto, {\"O}cal,
  Nonnenmacher, and Macke]{lueckmann-2017-snpe-b}
Lueckmann, J.-M., Goncalves, P.~J., Bassetto, G., {\"O}cal, K., Nonnenmacher,
  M., and Macke, J.~H.
\newblock Flexible statistical inference for mechanistic models of neural
  dynamics.
\newblock \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Lueckmann et~al.(2019)Lueckmann, Bassetto, Karaletsos, and
  Macke]{lueckmann-2018-emulator-networks}
Lueckmann, J.-M., Bassetto, G., Karaletsos, T., and Macke, J.~H.
\newblock Likelihood-free inference with emulator networks.
\newblock \emph{Symposium on Advances in Approximate Bayesian Inference}, 2019.

\bibitem[Meeds \& Welling(2014)Meeds and Welling]{meeds-2014-gps}
Meeds, E. and Welling, M.
\newblock {GPS}-{ABC}: {G}aussian process surrogate approximate {B}ayesian
  computation.
\newblock \emph{Conference on Uncertainty in Artificial Intelligence}, 2014.

\bibitem[Mohamed \& Lakshminarayanan(2016)Mohamed and
  Lakshminarayanan]{mohamed-2016-learning-in-implicit-generative-models}
Mohamed, S. and Lakshminarayanan, B.
\newblock Learning in implicit generative models.
\newblock \emph{arXiv preprint arXiv:1610.03483}, 2016.

\bibitem[Neal(2003)]{neal-2003-slice}
Neal, R.~M.
\newblock Slice sampling.
\newblock \emph{Annals of Statistics}, pp.\  705--741, 2003.

\bibitem[Nowozin et~al.(2016)Nowozin, Cseke, and Tomioka]{nowozin-2016-fgan}
Nowozin, S., Cseke, B., and Tomioka, R.
\newblock f-{GAN}: Training generative neural samplers using variational
  divergence minimization.
\newblock \emph{Advances in {N}eural {I}nformation {P}rocessing {S}ystems},
  2016.

\bibitem[Papamakarios(2019)]{papamakarios-2019-phd}
Papamakarios, G.
\newblock \emph{Neural density estimation and likelihood-free inference}.
\newblock PhD thesis, School of Informatics, University of Edinburgh, 2019.

\bibitem[Papamakarios \& Murray(2016)Papamakarios and
  Murray]{papamakarios-2016-snpe-a}
Papamakarios, G. and Murray, I.
\newblock Fast $\varepsilon$-free inference of simulation models with
  {B}ayesian conditional density estimation.
\newblock \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Papamakarios et~al.(2017)Papamakarios, Pavlakou, and
  Murray]{papamakarios-2017-maf}
Papamakarios, G., Pavlakou, T., and Murray, I.
\newblock Masked autoregressive flow for density estimation.
\newblock \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Papamakarios et~al.(2019{\natexlab{a}})Papamakarios, Nalisnick,
  Rezende, Mohamed, and Lakshminarayanan]{papamakarios-2019-flows-review}
Papamakarios, G., Nalisnick, E., Rezende, D.~J., Mohamed, S., and
  Lakshminarayanan, B.
\newblock Normalizing flows for probabilistic modeling and inference.
\newblock \emph{arXiv preprint arXiv:1912.02762}, 2019{\natexlab{a}}.

\bibitem[Papamakarios et~al.(2019{\natexlab{b}})Papamakarios, Sterratt, and
  Murray]{papamakarios-2018-snl}
Papamakarios, G., Sterratt, D.~C., and Murray, I.
\newblock Sequential neural likelihood: {F}ast likelihood-free inference with
  autoregressive flows.
\newblock \emph{International Conference on Artificial Intelligence and
  Statistics}, 2019{\natexlab{b}}.

\bibitem[Pham et~al.(2014)Pham, Nott, and Chaudhuri]{pham-2014-abcmcmc}
Pham, K.~C., Nott, D.~J., and Chaudhuri, S.
\newblock A note on approximating {ABC-MCMC} using flexible classifiers.
\newblock \emph{Stat}, 3\penalty0 (1):\penalty0 218--227, 2014.

\bibitem[Poole et~al.(2019)Poole, Ozair, van~den Oord, Alemi, and
  Tucker]{poole-2019-variational-bounds}
Poole, B., Ozair, S., van~den Oord, A., Alemi, A.~A., and Tucker, G.
\newblock On variational bounds of mutual information.
\newblock \emph{International Conference on Machine Learning}, 2019.

\bibitem[Price et~al.(2018)Price, Drovandi, Lee, and
  Nott]{price-2018-bayesian_sl}
Price, L.~F., Drovandi, C.~C., Lee, A., and Nott, D.~J.
\newblock {B}ayesian synthetic likelihood.
\newblock \emph{Journal of Computational and Graphical Statistics}, 27\penalty0
  (1):\penalty0 1--11, 2018.

\bibitem[Sisson et~al.(2007)Sisson, Fan, and Tanaka]{sisson-2007-smc_abc}
Sisson, S.~A., Fan, Y., and Tanaka, M.~M.
\newblock Sequential {M}onte {C}arlo without likelihoods.
\newblock \emph{Proceedings of the National Academy of Sciences}, 104\penalty0
  (6):\penalty0 1760--1765, 2007.

\bibitem[Sisson et~al.(2018)Sisson, Fan, and Beaumont]{sisson-2018-handbook}
Sisson, S.~A., Fan, Y., and Beaumont, M.
\newblock \emph{Handbook of approximate Bayesian computation}.
\newblock Chapman and Hall/CRC, 2018.

\bibitem[Stoye et~al.(2018)Stoye, Brehmer, Louppe, Pavez, and
  Cranmer]{stoye-2018-cross-entropy}
Stoye, M., Brehmer, J., Louppe, G., Pavez, J., and Cranmer, K.
\newblock Likelihood-free inference with an improved cross-entropy estimator.
\newblock \emph{arXiv preprint arXiv:1808.00973}, 2018.

\bibitem[Sugiyama et~al.(2012)Sugiyama, Suzuki, and
  Kanamori]{sugiyama-2012-density-ratio}
Sugiyama, M., Suzuki, T., and Kanamori, T.
\newblock \emph{Density ratio estimation in machine learning}.
\newblock Cambridge University Press, 2012.
\newblock ISBN 0521190177.

\bibitem[Thomas et~al.(2016)Thomas, Dutta, Corander, Kaski, and
  Gutmann]{thomas-2016-lfire}
Thomas, O., Dutta, R., Corander, J., Kaski, S., and Gutmann, M.~U.
\newblock Likelihood-free inference by ratio estimation.
\newblock \emph{arXiv preprint arXiv:1611.10242}, 2016.

\bibitem[Toni et~al.(2009)Toni, Welch, Strelkowa, Ipsen, and
  Stumpf]{toni-2009-smc_abc}
Toni, T., Welch, D., Strelkowa, N., Ipsen, A., and Stumpf, M. P.~H.
\newblock Approximate {B}ayesian computation scheme for parameter inference and
  model selection in dynamical systems.
\newblock \emph{Journal of The Royal Society Interface}, 6\penalty0
  (31):\penalty0 187--202, 2009.

\bibitem[Tran et~al.(2017)Tran, Ranganath, and Blei]{tran-2017-hierarchical}
Tran, D., Ranganath, R., and Blei, D.
\newblock Hierarchical implicit models and likelihood-free variational
  inference.
\newblock \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Uria et~al.(2016)Uria, C{{\^o}}t{{\'e}}, Gregor, Murray, and
  Larochelle]{uria-2016-nade}
Uria, B., C{{\^o}}t{{\'e}}, M.-A., Gregor, K., Murray, I., and Larochelle, H.
\newblock Neural autoregressive distribution estimation.
\newblock \emph{Journal of Machine Learning Research}, 17\penalty0
  (205):\penalty0 1--37, 2016.

\bibitem[van~den Oord et~al.(2018)van~den Oord, Li, and Vinyals]{oord-2018-cpc}
van~den Oord, A., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Wood(2010)]{wood-2010-sl}
Wood, S.~N.
\newblock Statistical inference for noisy nonlinear ecological dynamic systems.
\newblock \emph{Nature}, 466\penalty0 (7310):\penalty0 1102--1104, 2010.

\end{thebibliography}
