\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andriushchenko et~al.(2020)Andriushchenko, Croce, Flammarion, and Hein]{square}
Andriushchenko, M., Croce, F., Flammarion, N., and Hein, M.
\newblock Square attack: {A} query-efficient black-box adversarial attack via random search.
\newblock In \emph{ECCV}, 2020.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and Wagner]{AthalyeC018}
Athalye, A., Carlini, N., and Wagner, D.~A.
\newblock Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples.
\newblock In \emph{ICML}, 2018.

\bibitem[Avriel(2003)]{KKT}
Avriel, M.
\newblock \emph{Nonlinear Programming: Analysis and Methods}.
\newblock Courier Corporation, 2003.
\newblock ISBN 0486432270.

\bibitem[Brendel \& Bethge(2019)Brendel and Bethge]{DBLP:conf/iclr/BrendelB19}
Brendel, W. and Bethge, M.
\newblock Approximating {CNNs} with bag-of-local-features models works surprisingly well on imagenet.
\newblock In \emph{ICLR}, 2019.

\bibitem[Cai et~al.(2018)Cai, Liu, and Song]{CAT}
Cai, Q., Liu, C., and Song, D.
\newblock Curriculum adversarial training.
\newblock In \emph{IJCAI}, 2018.

\bibitem[Chefer et~al.(2022)Chefer, Schwartz, and Wolf]{DBLP:conf/nips/CheferSW22}
Chefer, H., Schwartz, I., and Wolf, L.
\newblock Optimizing relevance maps of vision transformers improves robustness.
\newblock In \emph{NeurIPS}, 2022.

\bibitem[Croce \& Hein(2020{\natexlab{a}})Croce and Hein]{AA}
Croce, F. and Hein, M.
\newblock Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks.
\newblock In \emph{ICML}, 2020{\natexlab{a}}.

\bibitem[Croce \& Hein(2020{\natexlab{b}})Croce and Hein]{FAB}
Croce, F. and Hein, M.
\newblock Minimally distorted adversarial examples with a fast adaptive boundary attack.
\newblock In \emph{ICML}, 2020{\natexlab{b}}.

\bibitem[Croce et~al.(2020)Croce, Andriushchenko, Sehwag, Debenedetti, Flammarion, Chiang, Mittal, and Hein]{croce2020robustbench}
Croce, F., Andriushchenko, M., Sehwag, V., Debenedetti, E., Flammarion, N., Chiang, M., Mittal, P., and Hein, M.
\newblock Robustbench: a standardized adversarial robustness benchmark.
\newblock \emph{arXiv preprint arXiv:2010.09670}, 2020.

\bibitem[Dagan et~al.(2019)Dagan, Daskalakis, Dikkala, and Jayanti]{Dagan2019learning}
Dagan, Y., Daskalakis, C., Dikkala, N., and Jayanti, S.
\newblock Learning from weakly dependent data under dobrushin's condition.
\newblock In \emph{COLT}, 2019.

\bibitem[Ding et~al.(2020)Ding, Sharma, Lui, and Huang]{DingSLH20}
Ding, G.~W., Sharma, Y., Lui, K. Y.~C., and Huang, R.
\newblock {MMA} training: Direct input space margin maximization through adversarial training.
\newblock In \emph{ICLR}, 2020.

\bibitem[Dong et~al.(2020)Dong, Han, Chen, Liu, Bian, Ma, Li, Wang, Zhang, and Yu]{DongHCLBMLWZY20}
Dong, X., Han, J., Chen, D., Liu, J., Bian, H., Ma, Z., Li, H., Wang, X., Zhang, W., and Yu, N.
\newblock Robust superpixel-guided attentional adversarial attack.
\newblock In \emph{CVPR}, 2020.

\bibitem[Fu et~al.(2020)Fu, Hu, Dong, Guo, Gao, and Li]{XGradCAM}
Fu, R., Hu, Q., Dong, X., Guo, Y., Gao, Y., and Li, B.
\newblock Axiom-based grad-cam: Towards accurate visualization and explanation of {CNNs}.
\newblock In \emph{BMVC}, 2020.

\bibitem[Gao et~al.(2021)Gao, Liu, Zhang, Han, Liu, Niu, and Sugiyama]{DBLP:conf/icml/GaoLZ0L0S21}
Gao, R., Liu, F., Zhang, J., Han, B., Liu, T., Niu, G., and Sugiyama, M.
\newblock Maximum mean discrepancy test is aware of adversarial attacks.
\newblock In \emph{ICML}, 2021.

\bibitem[Gao et~al.(2022)Gao, Wang, Zhou, Liu, Xie, Niu, Han, and Cheng]{MMA}
Gao, R., Wang, J., Zhou, K., Liu, F., Xie, B., Niu, G., Han, B., and Cheng, J.
\newblock Fast and reliable evaluation of adversarial robustness with minimum-margin attack.
\newblock In \emph{ICML}, 2022.

\bibitem[Geirhos et~al.(2019)Geirhos, Rubisch, Michaelis, Bethge, Wichmann, and Brendel]{geirhos2022imagenettrained}
Geirhos, R., Rubisch, P., Michaelis, C., Bethge, M., Wichmann, F.~A., and Brendel, W.
\newblock Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness.
\newblock In \emph{ICLR}, 2019.

\bibitem[Geirhos et~al.(2020)Geirhos, Jacobsen, Michaelis, Zemel, Brendel, Bethge, and Wichmann]{DBLP:journals/natmi/GeirhosJMZBBW20}
Geirhos, R., Jacobsen, J., Michaelis, C., Zemel, R.~S., Brendel, W., Bethge, M., and Wichmann, F.~A.
\newblock Shortcut learning in deep neural networks.
\newblock \emph{Nat. Mach. Intell.}, 2\penalty0 (11):\penalty0 665--673, 2020.
\newblock \doi{10.1038/S42256-020-00257-Z}.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and Szegedy]{goodfellow2015explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{ICLR}, 2015.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2015deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{CVPR}, 2016.

\bibitem[Hendrycks \& Dietterich(2019)Hendrycks and Dietterich]{DBLP:conf/iclr/HendrycksD19}
Hendrycks, D. and Dietterich, T.~G.
\newblock Benchmarking neural network robustness to common corruptions and perturbations.
\newblock In \emph{ICLR}, 2019.

\bibitem[Hermann \& Lampinen(2020)Hermann and Lampinen]{DBLP:conf/nips/HermannL20}
Hermann, K.~L. and Lampinen, A.~K.
\newblock What shapes feature representations? exploring datasets, architectures, and training.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Jiang et~al.(2021)Jiang, Zhang, Hou, Cheng, and Wei]{LayerCAM}
Jiang, P., Zhang, C., Hou, Q., Cheng, M., and Wei, Y.
\newblock Layercam: Exploring hierarchical class activation maps for localization.
\newblock \emph{{IEEE} Trans. Image Process.}, 30:\penalty0 5875--5888, 2021.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Nair, and Hinton]{cifar}
Krizhevsky, A., Nair, V., and Hinton, G.
\newblock Cifar-10 (canadian institute for advanced research).
\newblock 2009.
\newblock URL \url{http://www.cs.toronto.edu/~kriz/cifar.html}.

\bibitem[Kumar et~al.(2020)Kumar, Vishnu, Mitra, and Mohan]{ae_stop_sign}
Kumar, K.~N., Vishnu, C., Mitra, R., and Mohan, C.~K.
\newblock Black-box adversarial attacks in autonomous vehicle technology.
\newblock In \emph{AIPR}, 2020.

\bibitem[Ma et~al.(2018)Ma, Li, Wang, Erfani, Wijewickrema, Schoenebeck, Song, Houle, and Bailey]{ma2018characterizing}
Ma, X., Li, B., Wang, Y., Erfani, S.~M., Wijewickrema, S. N.~R., Schoenebeck, G., Song, D., Houle, M.~E., and Bailey, J.
\newblock Characterizing adversarial subspaces using local intrinsic dimensionality.
\newblock In \emph{ICLR}, 2018.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and Vladu]{Madry2018}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{ICLR}, 2018.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and Ng]{SVHN}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock In \emph{NIPS Workshop on Deep Learning and Unsupervised Feature Learning}, 2011.

\bibitem[Nie et~al.(2022)Nie, Guo, Huang, Xiao, Vahdat, and Anandkumar]{nie2022diffusion}
Nie, W., Guo, B., Huang, Y., Xiao, C., Vahdat, A., and Anandkumar, A.
\newblock Diffusion models for adversarial purification.
\newblock In \emph{ICML}, 2022.

\bibitem[Rade \& Moosavi{-}Dezfooli(2022)Rade and Moosavi{-}Dezfooli]{DBLP:conf/iclr/RadeM22}
Rade, R. and Moosavi{-}Dezfooli, S.
\newblock Reducing excessive margin to achieve a better accuracy vs. robustness trade-off.
\newblock In \emph{ICLR}, 2022.

\bibitem[Ribeiro et~al.(2016)Ribeiro, Singh, and Guestrin]{Ribeiro0G16}
Ribeiro, M.~T., Singh, S., and Guestrin, C.
\newblock "why should {I} trust you?": Explaining the predictions of any classifier.
\newblock In \emph{ACM SIGKDD}, 2016.

\bibitem[Rice et~al.(2020)Rice, Wong, and Kolter]{RiceWK20}
Rice, L., Wong, E., and Kolter, J.~Z.
\newblock Overfitting in adversarially robust deep learning.
\newblock In \emph{ICML}, 2020.

\bibitem[Ross \& Doshi{-}Velez(2018)Ross and Doshi{-}Velez]{DBLP:conf/aaai/RossD18}
Ross, A.~S. and Doshi{-}Velez, F.
\newblock Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients.
\newblock In \emph{AAAI}, 2018.

\bibitem[Selvaraju et~al.(2017)Selvaraju, Cogswell, Das, Vedantam, Parikh, and Batra]{GradCAM}
Selvaraju, R.~R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., and Batra, D.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based localization.
\newblock In \emph{ICCV}, 2017.

\bibitem[Shi et~al.(2021)Shi, Holtz, and Mishne]{DBLP:conf/iclr/ShiHM21}
Shi, C., Holtz, C., and Mishne, G.
\newblock Online adversarial purification based on self-supervised learning.
\newblock In \emph{ICLR}, 2021.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan, Goodfellow, and Fergus]{adversarial_example}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.~J., and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock In \emph{ICLR}, 2014.

\bibitem[Wang et~al.(2021)Wang, Liu, Han, Liu, Gong, Niu, Zhou, and Sugiyama]{DBLP:conf/nips/WangLHLGNZS21}
Wang, Q., Liu, F., Han, B., Liu, T., Gong, C., Niu, G., Zhou, M., and Sugiyama, M.
\newblock Probabilistic margins for instance reweighting in adversarial training.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Wang et~al.(2019)Wang, Ma, Bailey, Yi, Zhou, and Gu]{DAT}
Wang, Y., Ma, X., Bailey, J., Yi, J., Zhou, B., and Gu, Q.
\newblock On the convergence and robustness of adversarial training.
\newblock In \emph{ICML}, 2019.

\bibitem[Wang et~al.(2020)Wang, Zou, Yi, Bailey, Ma, and Gu]{MART}
Wang, Y., Zou, D., Yi, J., Bailey, J., Ma, X., and Gu, Q.
\newblock Improving adversarial robustness requires revisiting misclassified examples.
\newblock In \emph{ICLR}, 2020.

\bibitem[Wu(2017)]{TinyImagenet}
Wu, J.
\newblock Tiny imagenet challenge.
\newblock 2017.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:212697711}.

\bibitem[Wu et~al.(2023)Wu, Sang, Xu, Zhang, and Yu]{WuSX0Y23}
Wu, S., Sang, J., Xu, K., Zhang, J., and Yu, J.
\newblock Attention, please! adversarial defense via activation rectification and preservation.
\newblock \emph{{ACM} Trans. Multim. Comput. Commun. Appl.}, 2023.

\bibitem[Xu et~al.(2018)Xu, Evans, and Qi]{Xu_2018}
Xu, W., Evans, D., and Qi, Y.
\newblock Feature squeezing: Detecting adversarial examples in deep neural networks.
\newblock In \emph{NDSS}, 2018.

\bibitem[Yoon et~al.(2021)Yoon, Hwang, and Lee]{yoon2021adversarial}
Yoon, J., Hwang, S.~J., and Lee, J.
\newblock Adversarial purification with score-based generative models.
\newblock In \emph{ICML}, 2021.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and Komodakis]{wideresnet}
Zagoruyko, S. and Komodakis, N.
\newblock Wide residual networks.
\newblock In \emph{BMVC}, 2016.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, Ghaoui, and Jordan]{TRADES}
Zhang, H., Yu, Y., Jiao, J., Xing, E.~P., Ghaoui, L.~E., and Jordan, M.~I.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{ICML}, 2019.

\bibitem[Zhang et~al.(2021)Zhang, Zhu, Niu, Han, Sugiyama, and Kankanhalli]{ZhangZ00SK21}
Zhang, J., Zhu, J., Niu, G., Han, B., Sugiyama, M., and Kankanhalli, M.~S.
\newblock Geometry-aware instance-reweighted adversarial training.
\newblock In \emph{ICLR}, 2021.

\bibitem[Zhang et~al.(2023)Zhang, Liu, Yang, Yang, Li, Han, and Tan]{DBLP:conf/icml/ZhangLYYL0T23}
Zhang, S., Liu, F., Yang, J., Yang, Y., Li, C., Han, B., and Tan, M.
\newblock Detecting adversarial data by probing multiple perturbations using expected perturbation score.
\newblock In \emph{ICML}, 2023.

\bibitem[Zhou et~al.(2016)Zhou, Khosla, Lapedriza, Oliva, and Torralba]{CAM}
Zhou, B., Khosla, A., Lapedriza, {\`{A}}., Oliva, A., and Torralba, A.
\newblock Learning deep features for discriminative localization.
\newblock In \emph{CVPR}, 2016.

\bibitem[Zhou et~al.(2021)Zhou, Wang, Peng, Gao, Wang, Yu, and Liu]{Zhou0P0WYL21}
Zhou, D., Wang, N., Peng, C., Gao, X., Wang, X., Yu, J., and Liu, T.
\newblock Removing adversarial noise in class activation feature space.
\newblock In \emph{ICCV}, 2021.

\bibitem[Zhou et~al.(2022)Zhou, Wang, Han, and Liu]{DBLP:conf/icml/ZhouWHL22}
Zhou, D., Wang, N., Han, B., and Liu, T.
\newblock Modeling adversarial noise for adversarial training.
\newblock In \emph{ICML}, 2022.

\bibitem[Zhou et~al.(2023)Zhou, Wang, Yang, Gao, and Liu]{Zhou0Y0L23}
Zhou, D., Wang, N., Yang, H., Gao, X., and Liu, T.
\newblock Phase-aware adversarial defense for improving adversarial robustness.
\newblock In \emph{ICML}, 2023.

\end{thebibliography}
