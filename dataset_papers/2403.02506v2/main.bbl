\begin{thebibliography}{72}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2016)Abadi, Chu, Goodfellow, McMahan, Mironov, Talwar, and Zhang]{abadi2016deep}
Abadi, M., Chu, A., Goodfellow, I., McMahan, H.~B., Mironov, I., Talwar, K., and Zhang, L.
\newblock Deep learning with differential privacy.
\newblock In \emph{Proceedings of the 2016 ACM SIGSAC conference on computer and communications security}, pp.\  308--318, 2016.

\bibitem[Abbas et~al.(2023)Abbas, Tirumala, Simig, Ganguli, and Morcos]{abbas2023semdedup}
Abbas, A., Tirumala, K., Simig, D., Ganguli, S., and Morcos, A.~S.
\newblock Semdedup: Data-efficient learning at web-scale through semantic deduplication.
\newblock \emph{arXiv preprint arXiv:2303.09540}, 2023.

\bibitem[Assran et~al.(2022)Assran, Caron, Misra, Bojanowski, Bordes, Vincent, Joulin, Rabbat, and Ballas]{assran2022masked}
Assran, M., Caron, M., Misra, I., Bojanowski, P., Bordes, F., Vincent, P., Joulin, A., Rabbat, M., and Ballas, N.
\newblock Masked siamese networks for label-efficient learning.
\newblock In \emph{European Conference on Computer Vision}, pp.\  456--473. Springer, 2022.

\bibitem[Balle et~al.(2020)Balle, Barthe, Gaboardi, Hsu, and Sato]{balle2020hypothesis}
Balle, B., Barthe, G., Gaboardi, M., Hsu, J., and Sato, T.
\newblock Hypothesis testing interpretations and {R}{\'e}nyi differential privacy.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pp.\  2496--2506. PMLR, 2020.

\bibitem[Balle et~al.(2022)Balle, Cherubin, and Hayes]{balle2022reconstructing}
Balle, B., Cherubin, G., and Hayes, J.
\newblock Reconstructing training data with informed adversaries.
\newblock In \emph{2022 IEEE Symposium on Security and Privacy (SP)}, pp.\  1138--1156. IEEE, 2022.

\bibitem[Baradad et~al.(2022)Baradad, Chen, Wulff, Wang, Feris, Torralba, and Isola]{baradad2022procedural}
Baradad, M., Chen, R., Wulff, J., Wang, T., Feris, R., Torralba, A., and Isola, P.
\newblock Procedural image programs for representation learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 6450--6462, 2022.

\bibitem[Basu et~al.(2023)Basu, Sanjabi, Massiceti, Hu, and Feizi]{basu2023augmenting}
Basu, S., Sanjabi, M., Massiceti, D., Hu, S.~X., and Feizi, S.
\newblock Augmenting clip with improved visio-linguistic reasoning.
\newblock \emph{arXiv preprint arXiv:2307.09233}, 2023.

\bibitem[Berrada et~al.(2023)Berrada, De, Shen, Hayes, Stanforth, Stutz, Kohli, Smith, and Balle]{berrada2023unlocking}
Berrada, L., De, S., Shen, J.~H., Hayes, J., Stanforth, R., Stutz, D., Kohli, P., Smith, S.~L., and Balle, B.
\newblock Unlocking accuracy and fairness in differentially private image classification.
\newblock \emph{arXiv preprint arXiv:2308.10888}, 2023.

\bibitem[Bommasani et~al.(2021)Bommasani, Hudson, Adeli, Altman, Arora, von Arx, Bernstein, Bohg, Bosselut, Brunskill, et~al.]{bommasani2021opportunities}
Bommasani, R., Hudson, D.~A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M.~S., Bohg, J., Bosselut, A., Brunskill, E., et~al.
\newblock On the opportunities and risks of foundation models.
\newblock \emph{arXiv preprint arXiv:2108.07258}, 2021.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{arXiv preprint arXiv:2005.14165}, 2020.

\bibitem[Bu et~al.(2023)Bu, Wang, Zha, and Karypis]{bu2023differentially}
Bu, Z., Wang, Y.-X., Zha, S., and Karypis, G.
\newblock Differentially private optimization on large model at small cost.
\newblock In \emph{International Conference on Machine Learning}, pp.\  3192--3218. PMLR, 2023.

\bibitem[Bun \& Steinke(2016)Bun and Steinke]{bun2016concentrated}
Bun, M. and Steinke, T.
\newblock Concentrated differential privacy: Simplifications, extensions, and lower bounds.
\newblock In \emph{Theory of Cryptography Conference}, pp.\  635--658. Springer, 2016.

\bibitem[Carlini et~al.(2021)Carlini, Chien, Nasr, Song, Terzis, and Tramer]{carlini2021membership}
Carlini, N., Chien, S., Nasr, M., Song, S., Terzis, A., and Tramer, F.
\newblock Membership inference attacks from first principles.
\newblock \emph{arXiv preprint arXiv:2112.03570}, 2021.

\bibitem[Changpinyo et~al.(2021)Changpinyo, Sharma, Ding, and Soricut]{changpinyo2021conceptual}
Changpinyo, S., Sharma, P., Ding, N., and Soricut, R.
\newblock Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  3558--3568, 2021.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{simclr}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.~E.
\newblock A simple framework for contrastive learning of visual representations.
\newblock \emph{CoRR}, abs/2002.05709, 2020.
\newblock URL \url{https://arxiv.org/abs/2002.05709}.

\bibitem[De et~al.(2022)De, Berrada, Hayes, Smith, and Balle]{DeepMindUnlocking}
De, S., Berrada, L., Hayes, J., Smith, S.~L., and Balle, B.
\newblock Unlocking high-accuracy differentially private image classification through scale, 2022.
\newblock URL \url{https://arxiv.org/abs/2204.13650}.

\bibitem[Deng et~al.(2009{\natexlab{a}})Deng, Dong, Socher, Li, Li, and Fei-Fei]{Imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE Conference on Computer Vision and Pattern Recognition}, pp.\  248--255, 2009{\natexlab{a}}.
\newblock \doi{10.1109/CVPR.2009.5206848}.

\bibitem[Deng et~al.(2009{\natexlab{b}})Deng, Dong, Socher, Li, Li, and Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern recognition}, pp.\  248--255. Ieee, 2009{\natexlab{b}}.

\bibitem[Desai \& Johnson(2021)Desai and Johnson]{desai2021virtex}
Desai, K. and Johnson, J.
\newblock Virtex: Learning visual representations from textual annotations.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  11162--11173, 2021.

\bibitem[Dwork \& Rothblum(2016)Dwork and Rothblum]{dwork2016concentrated}
Dwork, C. and Rothblum, G.~N.
\newblock Concentrated differential privacy.
\newblock \emph{arXiv preprint arXiv:1603.01887}, 2016.

\bibitem[Dwork et~al.(2006)Dwork, McSherry, Nissim, and Smith]{dwork2006calibrating}
Dwork, C., McSherry, F., Nissim, K., and Smith, A.
\newblock Calibrating noise to sensitivity in private data analysis.
\newblock In \emph{Proceedings of the Third Conference on Theory of Cryptography}, pp.\  265â€“284, 2006.

\bibitem[Gadre et~al.(2023)Gadre, Ilharco, Fang, Hayase, Smyrnis, Nguyen, Marten, Wortsman, Ghosh, Zhang, et~al.]{gadre2023datacomp}
Gadre, S.~Y., Ilharco, G., Fang, A., Hayase, J., Smyrnis, G., Nguyen, T., Marten, R., Wortsman, M., Ghosh, D., Zhang, J., et~al.
\newblock Datacomp: In search of the next generation of multimodal datasets.
\newblock \emph{arXiv preprint arXiv:2304.14108}, 2023.

\bibitem[Gopi et~al.(2021)Gopi, Lee, and Wutschitz]{gopi2021numerical}
Gopi, S., Lee, Y.~T., and Wutschitz, L.
\newblock Numerical composition of differential privacy.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 11631--11642, 2021.

\bibitem[Guo et~al.(2022)Guo, Karrer, Chaudhuri, and van~der Maaten]{guo2022bounding}
Guo, C., Karrer, B., Chaudhuri, K., and van~der Maaten, L.
\newblock Bounding training data reconstruction in private (deep) learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\  8056--8071. PMLR, 2022.

\bibitem[Guo et~al.(2023)Guo, Sablayrolles, and Sanjabi]{guo2023analyzing}
Guo, C., Sablayrolles, A., and Sanjabi, M.
\newblock Analyzing privacy leakage in machine learning via multiple hypothesis testing: A lesson from fano.
\newblock In \emph{International Conference on Machine Learning}, pp.\  11998--12011. PMLR, 2023.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and Girshick]{he2022masked}
He, K., Chen, X., Xie, S., Li, Y., Doll{\'a}r, P., and Girshick, R.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  16000--16009, 2022.

\bibitem[Jayaraman \& Evans(2019)Jayaraman and Evans]{jayaraman2019evaluating}
Jayaraman, B. and Evans, D.
\newblock Evaluating differentially private machine learning in practice.
\newblock In \emph{28th USENIX Security Symposium (USENIX Security 19)}, pp.\  1895--1912, 2019.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton, et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and Hinton]{krizhevsky2012imagenet}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock \emph{Advances in neural information processing systems}, 25, 2012.

\bibitem[Kurakin et~al.(2022)Kurakin, Song, Chien, Geambasu, Terzis, and Thakurta]{kurakin2022toward}
Kurakin, A., Song, S., Chien, S., Geambasu, R., Terzis, A., and Thakurta, A.
\newblock Toward training at imagenet scale with differential privacy.
\newblock \emph{arXiv preprint arXiv:2201.12328}, 2022.

\bibitem[Lee \& Kifer(2020)Lee and Kifer]{lee2020scaling}
Lee, J. and Kifer, D.
\newblock Scaling up differentially private deep learning with fast per-example gradient clipping.
\newblock \emph{arXiv preprint arXiv:2009.03106}, 2020.

\bibitem[Li et~al.(2022{\natexlab{a}})Li, Li, Xiong, and Hoi]{li2022blip}
Li, J., Li, D., Xiong, C., and Hoi, S.
\newblock Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation.
\newblock In \emph{International Conference on Machine Learning}, pp.\  12888--12900. PMLR, 2022{\natexlab{a}}.

\bibitem[Li et~al.(2021)Li, TramÃ¨r, Liang, and Hashimoto]{li2021large}
Li, X., TramÃ¨r, F., Liang, P., and Hashimoto, T.
\newblock Large language models can be strong differentially private learners, 2021.

\bibitem[Li et~al.(2022{\natexlab{b}})Li, Liu, Hashimoto, Inan, Kulkarni, Lee, and Guha~Thakurta]{li2022does}
Li, X., Liu, D., Hashimoto, T.~B., Inan, H.~A., Kulkarni, J., Lee, Y.-T., and Guha~Thakurta, A.
\newblock When does differentially private learning not suffer in high dimensions?
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 28616--28630, 2022{\natexlab{b}}.

\bibitem[Li et~al.(2023)Li, Fan, Hu, Feichtenhofer, and He]{li2023scaling}
Li, Y., Fan, H., Hu, R., Feichtenhofer, C., and He, K.
\newblock Scaling language-image pre-training via masking.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  23390--23400, 2023.

\bibitem[Lin et~al.(2015)Lin, Maire, Belongie, Bourdev, Girshick, Hays, Perona, Ramanan, Zitnick, and DollÃ¡r]{lin2015microsoft}
Lin, T.-Y., Maire, M., Belongie, S., Bourdev, L., Girshick, R., Hays, J., Perona, P., Ramanan, D., Zitnick, C.~L., and DollÃ¡r, P.
\newblock Microsoft coco: Common objects in context, 2015.

\bibitem[Liu \& Talwar(2019)Liu and Talwar]{liu2019private}
Liu, J. and Talwar, K.
\newblock Private selection from private candidates.
\newblock In \emph{Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing (STOC)}, pp.\  298--309, 2019.

\bibitem[Loshchilov \& Hutter(2018)Loshchilov and Hutter]{loshchilov2018decoupled}
Loshchilov, I. and Hutter, F.
\newblock Decoupled weight decay regularization.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Mairal(2019)]{mairal2019cyanure}
Mairal, J.
\newblock Cyanure: An open-source toolbox for empirical risk minimization for python, c++, and soon more.
\newblock \emph{arXiv preprint arXiv:1912.08165}, 2019.

\bibitem[McMahan et~al.(2017)McMahan, Ramage, Talwar, and Zhang]{mcmahan2017learning}
McMahan, H.~B., Ramage, D., Talwar, K., and Zhang, L.
\newblock Learning differentially private recurrent language models.
\newblock \emph{arXiv preprint arXiv:1710.06963}, 2017.

\bibitem[Mironov(2017)]{mironov2017renyi}
Mironov, I.
\newblock R{\'e}nyi differential privacy.
\newblock In \emph{2017 IEEE 30th Computer Security Foundations Symposium (CSF)}, pp.\  263--275. IEEE, 2017.

\bibitem[Mironov et~al.(2019)Mironov, Talwar, and Zhang]{mironov2019r}
Mironov, I., Talwar, K., and Zhang, L.
\newblock R\'{e}nyi differential privacy of the {S}ampled {G}aussian {M}echanism.
\newblock \emph{arXiv preprint arXiv:1908.10530}, 2019.

\bibitem[Mu et~al.(2022)Mu, Kirillov, Wagner, and Xie]{mu2022slip}
Mu, N., Kirillov, A., Wagner, D., and Xie, S.
\newblock Slip: Self-supervision meets language-image pre-training.
\newblock In \emph{European Conference on Computer Vision}, pp.\  529--544. Springer, 2022.

\bibitem[Plummer et~al.(2016)Plummer, Wang, Cervantes, Caicedo, Hockenmaier, and Lazebnik]{plummer2016flickr30k}
Plummer, B.~A., Wang, L., Cervantes, C.~M., Caicedo, J.~C., Hockenmaier, J., and Lazebnik, S.
\newblock Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models, 2016.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International conference on machine learning}, pp.\  8748--8763. PMLR, 2021.

\bibitem[R{\'e}nyi(1961)]{renyi1961measures}
R{\'e}nyi, A.
\newblock On measures of entropy and information.
\newblock In \emph{Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Contributions to the Theory of Statistics}, volume~4, pp.\  547--562. University of California Press, 1961.

\bibitem[Russakovsky et~al.(2014)Russakovsky, Deng, Su, Krause, Satheesh, Ma, Huang, Karpathy, Khosla, Bernstein, Berg, and Fei-Fei]{Imagenet2}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.~C., and Fei-Fei, L.
\newblock Imagenet large scale visual recognition challenge, 2014.
\newblock URL \url{https://arxiv.org/abs/1409.0575}.

\bibitem[Sander et~al.(2023)Sander, Stock, and Sablayrolles]{sander2023tan}
Sander, T., Stock, P., and Sablayrolles, A.
\newblock Tan without a burn: Scaling laws of dp-sgd.
\newblock In \emph{International Conference on Machine Learning}, pp.\  29937--29949. PMLR, 2023.

\bibitem[Sander et~al.(2024)Sander, Sylvestre, and Durmus]{sander2024implicit}
Sander, T., Sylvestre, M., and Durmus, A.
\newblock Implicit bias in noisy-sgd: With applications to differentially private training.
\newblock \emph{arXiv preprint arXiv:2402.08344}, 2024.

\bibitem[Sariyildiz et~al.(2020)Sariyildiz, Perez, and Larlus]{sariyildiz2020learning}
Sariyildiz, M.~B., Perez, J., and Larlus, D.
\newblock Learning visual representations with caption annotations.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part VIII 16}, pp.\  153--170. Springer, 2020.

\bibitem[Schuhmann et~al.(2021)Schuhmann, Vencu, Beaumont, Kaczmarczyk, Mullis, Katta, Coombes, Jitsev, and Komatsuzaki]{schuhmann2021laion}
Schuhmann, C., Vencu, R., Beaumont, R., Kaczmarczyk, R., Mullis, C., Katta, A., Coombes, T., Jitsev, J., and Komatsuzaki, A.
\newblock Laion-400m: Open dataset of clip-filtered 400 million image-text pairs.
\newblock \emph{arXiv preprint arXiv:2111.02114}, 2021.

\bibitem[Schuhmann et~al.(2022)Schuhmann, Beaumont, Vencu, Gordon, Wightman, Cherti, Coombes, Katta, Mullis, Wortsman, Schramowski, Kundurthy, Crowson, Schmidt, Kaczmarczyk, and Jitsev]{Schuhmann2022LAION5BAO}
Schuhmann, C., Beaumont, R., Vencu, R., Gordon, C., Wightman, R., Cherti, M., Coombes, T., Katta, A., Mullis, C., Wortsman, M., Schramowski, P., Kundurthy, S., Crowson, K., Schmidt, L., Kaczmarczyk, R., and Jitsev, J.
\newblock Laion-5b: An open large-scale dataset for training next generation image-text models.
\newblock \emph{ArXiv}, abs/2210.08402, 2022.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:252917726}.

\bibitem[Shokri et~al.(2017)Shokri, Stronati, Song, and Shmatikov]{shokri2017membership}
Shokri, R., Stronati, M., Song, C., and Shmatikov, V.
\newblock Membership inference attacks against machine learning models.
\newblock In \emph{2017 IEEE Symposium on Security and Privacy (S\&P)}, pp.\  3--18, 2017.

\bibitem[Song et~al.(2013)Song, Chaudhuri, and Sarwate]{song2013stochastic}
Song, S., Chaudhuri, K., and Sarwate, A.~D.
\newblock Stochastic gradient descent with differentially private updates.
\newblock In \emph{IEEE Global Conference on Signal and Information Processing (GlobalSIP)}, pp.\  245--248, 2013.

\bibitem[Tang et~al.(2024)Tang, Panda, Sehwag, and Mittal]{tang2024differentially}
Tang, X., Panda, A., Sehwag, V., and Mittal, P.
\newblock Differentially private image classification by learning priors from random processes.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Tejankar et~al.(2021)Tejankar, Sanjabi, Wu, Xie, Khabsa, Pirsiavash, and Firooz]{tejankar2021fistful}
Tejankar, A., Sanjabi, M., Wu, B., Xie, S., Khabsa, M., Pirsiavash, H., and Firooz, H.
\newblock A fistful of words: Learning transferable visual models from bag-of-words supervision.
\newblock \emph{arXiv preprint arXiv:2112.13884}, 2021.

\bibitem[Touvron et~al.(2022)Touvron, Cord, and J{\'e}gou]{touvron2022deit}
Touvron, H., Cord, M., and J{\'e}gou, H.
\newblock Deit iii: Revenge of the vit.
\newblock In \emph{European Conference on Computer Vision}, pp.\  516--533. Springer, 2022.

\bibitem[Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux, Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{touvron2023llama}
Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozi{\`e}re, B., Goyal, N., Hambro, E., Azhar, F., et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem[Tramer \& Boneh(2020)Tramer and Boneh]{tramer2020differentially}
Tramer, F. and Boneh, D.
\newblock Differentially private learning needs better features (or much more data).
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Tschannen et~al.(2023)Tschannen, Kumar, Steiner, Zhai, Houlsby, and Beyer]{tschannen2023image}
Tschannen, M., Kumar, M., Steiner, A., Zhai, X., Houlsby, N., and Beyer, L.
\newblock Image captioners are scalable vision learners too.
\newblock \emph{arXiv preprint arXiv:2306.07915}, 2023.

\bibitem[Van~Horn et~al.(2021)Van~Horn, Cole, Beery, Wilber, Belongie, and Mac~Aodha]{van2021benchmarking}
Van~Horn, G., Cole, E., Beery, S., Wilber, K., Belongie, S., and Mac~Aodha, O.
\newblock Benchmarking representation learning for natural world image collections.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  12884--12893, 2021.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N., Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Vedantam et~al.(2015)Vedantam, Zitnick, and Parikh]{vedantam2015cider}
Vedantam, R., Zitnick, C.~L., and Parikh, D.
\newblock Cider: Consensus-based image description evaluation, 2015.

\bibitem[Wang et~al.(2019)Wang, Balle, and Kasiviswanathan]{wang2019subsampled}
Wang, Y.-X., Balle, B., and Kasiviswanathan, S.~P.
\newblock Subsampled r{\'e}nyi differential privacy and analytical moments accountant.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence and Statistics}, pp.\  1226--1235. PMLR, 2019.

\bibitem[Yang et~al.(2021)Yang, Yau, Fei{-}Fei, Deng, and Russakovsky]{yang2021obfuscation}
Yang, K., Yau, J., Fei{-}Fei, L., Deng, J., and Russakovsky, O.
\newblock A study of face obfuscation in imagenet.
\newblock \emph{CoRR}, abs/2103.06191, 2021.
\newblock URL \url{https://arxiv.org/abs/2103.06191}.

\bibitem[You et~al.(2017)You, Gitman, and Ginsburg]{LARS}
You, Y., Gitman, I., and Ginsburg, B.
\newblock Scaling {SGD} batch size to 32k for imagenet training.
\newblock \emph{CoRR}, abs/1708.03888, 2017.
\newblock URL \url{http://arxiv.org/abs/1708.03888}.

\bibitem[Yousefpour et~al.(2021)Yousefpour, Shilov, Sablayrolles, Testuggine, Prasad, Malek, Nguyen, Ghosh, Bharadwaj, Zhao, Cormode, and Mironov]{yousefpour2021opacus}
Yousefpour, A., Shilov, I., Sablayrolles, A., Testuggine, D., Prasad, K., Malek, M., Nguyen, J., Ghosh, S., Bharadwaj, A., Zhao, J., Cormode, G., and Mironov, I.
\newblock Opacus: User-friendly differential privacy library in {PyTorch}, 2021.

\bibitem[Yu et~al.(2022)Yu, Wang, Vasudevan, Yeung, Seyedhosseini, and Wu]{yu2022coca}
Yu, J., Wang, Z., Vasudevan, V., Yeung, L., Seyedhosseini, M., and Wu, Y.
\newblock Coca: Contrastive captioners are image-text foundation models.
\newblock \emph{arXiv preprint arXiv:2205.01917}, 2022.

\bibitem[Yu et~al.(2023)Yu, Sanjabi, Ma, Chaudhuri, and Guo]{yu2023vip}
Yu, Y., Sanjabi, M., Ma, Y., Chaudhuri, K., and Guo, C.
\newblock Vip: A differentially private foundation model for computer vision.
\newblock \emph{arXiv preprint arXiv:2306.08842}, 2023.

\bibitem[Yuksekgonul et~al.(2022)Yuksekgonul, Bianchi, Kalluri, Jurafsky, and Zou]{yuksekgonul2022and}
Yuksekgonul, M., Bianchi, F., Kalluri, P., Jurafsky, D., and Zou, J.
\newblock When and why vision-language models behave like bags-of-words, and what to do about it?
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2022.

\bibitem[Zhou et~al.(2014)Zhou, Lapedriza, Xiao, Torralba, and Oliva]{zhou2014learning}
Zhou, B., Lapedriza, A., Xiao, J., Torralba, A., and Oliva, A.
\newblock Learning deep features for scene recognition using places database.
\newblock \emph{Advances in neural information processing systems}, 27, 2014.

\end{thebibliography}
