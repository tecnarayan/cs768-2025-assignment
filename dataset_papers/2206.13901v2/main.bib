
@article{hayes_practical_2022,
  title = {A Practical Guide to Multi-Objective Reinforcement Learning and Planning},
  author = {Hayes, Conor F. and R{\u a}dulescu, Roxana and Bargiacchi, Eugenio and K{\"a}llstr{\"o}m, Johan and Macfarlane, Matthew and Reymond, Mathieu and Verstraeten, Timothy and Zintgraf, Luisa M. and Dazeley, Richard and Heintz, Fredrik and Howley, Enda and Irissappane, Athirai A. and Mannion, Patrick and Now{\'e}, Ann and Ramos, Gabriel and Restelli, Marcello and Vamplew, Peter and Roijers, Diederik M.},
  year = {2022},
  month = apr,
  journal = {Autonomous Agents and Multi-Agent Systems},
  volume = {36},
  number = {1},
  pages = {26},
}


@inproceedings{Koller-Parr,
  author    = {Daphne Koller and Ronald Parr},
  title     = {Computing factored value functions for policies in structured {MDP}s},
  booktitle = {International Joint Conference on Artificial Intelligence ({IJCAI})},
  year      = {1999},
  }

@inproceedings{HybridRA,
  title={Hybrid Reward Architecture for Reinforcement Learning},
  author={H. V. Seijen and Mehdi Fatemi and Joshua Romoff and Romain Laroche and Tavian Barnes and Jeffrey Tsang},
  booktitle={Conference on Neural Information Processing Systems ({NeurIPS})},
  year={2017}
}

@inproceedings{Lagoudakis-Parr,
	author    = {Michail G. Lagoudakis and Ronald Parr},
	title     = {Learning in Zero-Sum Team Markov Games Using Factored Value Functions},
	booktitle = {Conference on Neural Information Processing Systems ({NeurIPS})},
	year      = {2002}
}

@inproceedings{Yang-Narasimhan,
	author    = {Runzhe Yang and Xingyuan Sun and Karthik Narasimhan},
	title     = {A Generalized Algorithm for Multi-Objective Reinforcement Learning and Policy Adaptation},
	booktitle = {Conference on Neural Information Processing Systems ({NeurIPS})},
	year      = {2019}
}

@inproceedings{Russell2003QDecompositionFR,
  title={Q-Decomposition for Reinforcement Learning Agents},
  author={Stuart J. Russell and A. Zimdars},
  booktitle={International Conference on Machine Learning ({ICML})},
  year={2003}
}

@inproceedings{Juozapaitis2019ExplainableRL,
  title={Explainable Reinforcement Learning via Reward Decomposition},
  author={Zoe Juozapaitis and Anurag Koul and Alan Fern and M. Erwig and Finale Doshi-Velez},
  booktitle = {{IJCAI/ECAI} Workshop on Explainable Artificial Intelligence},
  year={2019}
}

@inproceedings{Schaul2015UniversalVF,
	title={Universal Value Function Approximators},
	author={Tom Schaul and Dan Horgan and K. Gregor and D. Silver},
	booktitle={International Conference on Machine Learning {ICML}},
	year={2015}
}

@article{Mankowitz2018UnicornCL,
	title={Unicorn: Continual Learning with a Universal, Off-policy Agent},
	author={Daniel J. Mankowitz and Augustin Z{\'i}dek and Andr{\'e} Barreto and Dan Horgan and Matteo Hessel and John Quan and Junhyuk Oh and H. V. Hasselt and D. Silver and Tom Schaul},
	journal={arXiv},
	year={2018},
	volume={1802.08294}
}

@inproceedings{Barreto2019TheOK,
	title={The {Option Keyboard}: Combining Skills in Reinforcement Learning},
	author={Andr{\'e} Barreto and Diana Borsa and Shaobo Hou and Gheorghe Comanici and Eser Ayg{\"u}n and P. Hamel and Daniel Toyama and Jonathan Hunt and Shibl Mourad and D. Silver and Doina Precup},
	booktitle = {Conference on Neural Information Processing Systems ({NeurIPS})},
	year={2019}
}

@article{Grimm2019DisentangledCH,
	title={Disentangled Cumulants Help {Successor Representations} Transfer to New Tasks},
	author={Christopher Grimm and I. Higgins and Andr{\'e} Barreto and Denis Teplyashin and Markus Wulfmeier and Tim Hertweck and R. Hadsell and Satinder Singh},
	journal={arXiv},
	year={2019},
	volume={1911.10866}
}

@article{Borsa2019UniversalSF,
	title={Universal {Successor Features} Approximators},
	author={Diana Borsa and Andr{\'e} Barreto and John Quan and Daniel J. Mankowitz and R. Munos and H. V. Hasselt and D. Silver and Tom Schaul},
	journal={arXiv},
	year={2019},
	volume={1812.07626}
}

@article{Barreto2018TransferID,
	title={Transfer in Deep Reinforcement Learning Using {Successor Features} and {Generalised Policy Improvement}},
	author={Andr{\'e} Barreto and Diana Borsa and John Quan and Tom Schaul and D. Silver and Matteo Hessel and Daniel J. Mankowitz and Augustin Z{\'i}dek and R. Munos},
	journal={arXiv},
	year={2018},
	volume={1901.10964}
}

@inproceedings{Agarwal2021DeepRL,
	title={Deep Reinforcement Learning at the Edge of the Statistical Precipice},
	author={Rishabh Agarwal and Max Schwarzer and Pablo Samuel Castro and Aaron Courville and Marc G. Bellemare},
	booktitle = {Conference on Neural Information Processing Systems ({NeurIPS})},
	year={2021}
}

@inproceedings{Zhan2020LearningCP,
	title={Learning Calibratable Policies using Programmatic Style-Consistency},
	author={Eric Zhan and Albert Tseng and Yisong Yue and Adith Swaminathan and M. Hausknecht},
	booktitle={International Conference on Machine Learning ({ICML})},
	year={2020}
}

@inproceedings{Asis2018MultistepRL,
	title={Multi-step Reinforcement Learning: A Unifying Algorithm},
	author={Kristopher De Asis and J. Hernandez-Garcia and G. Holland and R. Sutton},
	booktitle={{AAAI} conference on artificial intelligence},
	year={2018}
}

@article{YUAN2019107,
	title = {A novel multi-step Q-learning method to improve data efficiency for deep reinforcement learning},
	journal = {Knowledge-Based Systems},
	volume = {175},
	pages = {107-117},
	year = {2019},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705119301431},
	author = {Yinlong Yuan and Zhu Liang Yu and Zhenghui Gu and Yao Yeboah and Wu Wei and Xiaoyan Deng and Jingcong Li and Yuanqing Li}}
}

@article{Roijers,
	author    = {Diederik M. Roijers and Peter Vamplew and Shimon Whiteson and Richard Dazeley},
	title     = {A Survey of Multi-Objective Sequential Decision-Making},
	journal   = {Journal of Artificial Intelligence Research},
	volume    = {48},
	pages     = {67--113},
	year      = {2013}
}

@article{Grimm2019LearningIR,
	title={Learning Independently-Obtainable Reward Functions},
	author={Christopher Grimm and Satinder Singh},
	journal={arXiv},
	year={2019},
	volume={1901.08649}
}

@article{Schaul-Borsa,
	title     = {Return-based Scaling: Yet Another Normalisation Trick for Deep {RL}},
	author    = {Tom Schaul and Georg Ostrovski and Iurii Kemaev and Diana Borsa},
	journal = {arXiv},
	year      = {2021},
	volume={2105.05347}
}

@inproceedings{White2014Surprise,
	title={Surprise and Curiosity for Big Data Robotics},
	author={Adam White and Joseph Modayil and Richard S. Sutton},
	booktitle={{AAAI} Workshop on Sequential Decision Making with Big Data},
	year={2014}
}

@inproceedings{Sherstan2018Variance,
	title={Comparing Direct and Indirect Temporal-Difference Methods for Estimating the Variance of the Return},
	author={Craig Sherstan and D. R. Ashley and Brendan Bennett and Kenny Young and Adam White and Martha White and Richard S. Sutton},
	booktitle={Conference on Uncertainty in Artificial Intelligence ({UAI})},
	year={2018}
}

@article{Gould2016Differentiation,
    title = {On Differentiating Parameterized Argmin and Argmax Problems with Application to Bi-level Optimization},
    author = {Stephen Gould and Basura Fernando and Anoop Cherian and Peter Anderson and Rodrigo {Santa Cruz} and Edison Guo},
    journal = {arXiv},
    year = {2016},
    volume = {1607.05447}
}


@article{Sherstan2019Gamma-Nets,
	title     = {Gamma-Nets: Generalizing Value Estimation over Timescale},
	author    = {Craig Sherstan and Shibhansh Dohare and James MacGlashan and Johannes G{\"{u}}nther and Patrick M. Pilarski},
	journal = {arXiv},
	year      = {2021},
	volume={1911.07794}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning ({ICML})},
  year={2018},
}

@article{sac,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv},
  year={2018},
  volume={1812.05905}
}

@inproceedings{cagrad,
  title={Conflict-Averse Gradient Descent for Multi-task Learning},
  author={Liu, Bo and Liu, Xingchao and Jin, Xiaojie and Stone, Peter and Liu, Qiang},
  booktitle = {Conference on Neural Information Processing Systems ({NeurIPS})},
  year={2021}
}

@inproceedings{hasselt2010double,
  title={{Double Q-learning}},
  author={Hasselt, Hado},
  booktitle = {Conference on Neural Information Processing Systems ({NeurIPS})},
  year={2010}
}

@inproceedings{ren2021estimation,
  title={On the Estimation Bias in Double {Q}-Learning},
  author={Ren, Zhizhou and Zhu, Guangxiang and Hu, Hao and Han, Beining and Chen, Jianglun and Zhang, Chongjie},
  booktitle = {Conference on Neural Information Processing Systems ({NeurIPS})},
  year={2021}
}

@inproceedings{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and {van Hoof}, Herke and Meger, David},
  booktitle={International conference on machine learning ({ICML})},
  year={2018}
}

@article{reverb,
  title={Reverb: A framework for experience replay},
  author={Cassirer, Albin and Barth-Maron, Gabriel and Brevdo, Eugene and Ramos, Sabela and Boyd, Toby and Sottiaux, Thibault and Kroiss, Manuel},
  journal={arXiv},
  volume={2102.04736},
  year={2021}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy Lei},
  journal={arXiv},
  volume={1412.6980},
  year={2014}
}

@article{brockman2016openai,
  title={{OpenAI Gym}},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv}, 
  volume={1606.01540},
  year={2016}
}


@article{heuillet2021explainability,
  title={Explainability in deep reinforcement learning},
  author={Heuillet, Alexandre and Couthouis, Fabien and D{\'\i}az-Rodr{\'\i}guez, Natalia},
  journal={Knowledge-Based Systems},
  volume={214},
  pages={106685},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{sutton2011horde,
  title={Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction},
  author={Sutton, Richard S and Modayil, Joseph and Delp, Michael and Degris, Thomas and Pilarski, Patrick M and White, Adam and Precup, Doina},
  booktitle={Conference on Autonomous Agents and Multiagent Systems ({AAMAS})},
  year={2011}
}

@article{knox2021reward,
journal = {arXiv},
volume = {2104.13906},
author = {Knox, W. Bradley and Allievi, Alessandro and Banzhaf, Holger and Schmitt, Felix and Stone, Peter},
title = {{Reward (Mis)design for Autonomous Driving}},
year = {2021}
}

@inproceedings{barreto2017successor,
  title={{Successor Features} for transfer in reinforcement learning},
  author={Barreto, Andr{\'e} and Dabney, Will and Munos, R{\'e}mi and Hunt, Jonathan J and Schaul, Tom and van Hasselt, Hado and Silver, David},
  booktitle = {Conference on Neural Information Processing Systems ({NeurIPS})},
  year={2017}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Peterson, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis, and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@book{lin1992reinforcement,
  title={Reinforcement learning for robots using neural networks},
  author={Lin, Long{-}Ji},
  year={1992},
  publisher={Carnegie Mellon University}
}

@article{dayan1993improving,
  title={Improving generalization for temporal difference learning: The {Successor Representation}},
  author={Dayan, Peter},
  journal={Neural Computation},
  volume={5},
  number={4},
  pages={613--624},
  year={1993},
  publisher={MIT Press}
}

@article{wurman2022GT,
  title={Outracing champion {Gran Turismo} drivers with deep reinforcement learning},
  author={Wurman, Peter R. and Barrett, Samuel and Kawamoto, Kenta and MacGlashan, James and Subramanian, Kaushik and Walsh, Thomas J. and Capobianco, Roberto and Devlic, Alisa and Eckert, Franziska and Fuchs, Florian and Gilpin, Leilani and Khandelwal, Piyush and Kompella, Varun and Lin, HaoChih and MacAlpine, Patrick and Oller, Declan and Seno, Takuma and Sherstan, Craig and Thomure, Michael D. and Aghabozorgi, Houmehr and Barrett, Leon and Douglas, Rory and Whitehead, Dion and Dürr, Peter and Stone, Peter and Spranger, Michael and Kitano, Hiroaki},
  journal={Nature},
  volume={602},
  pages={223--228},
  year={2022},
}

@inproceedings{Edwards2016,
author = {Edwards, Ann L. and Hebert, Jacqueline S. and Pilarski, Patrick M.},
booktitle = {{IEEE} International Conference on Biomedical Robotics and Biomechatronics ({BioRob})},
title = {Machine learning and unlearning to autonomously switch between the functions of a myoelectric arm},
year = {2016}
}

@article{Pilarski2022,
author = {Pilarski, Patrick M. and Butcher, Andrew and Davoodi, Elnaz and Johanson, Michael Bradley and Brenneis, Dylan J. A. and Parker, Adam S. R. and Acker, Leslie and Botvinick, Matthew M. and Modayil, Joseph and White, Adam},
journal = {arXiv},
volume={2203.09498},
title = {The Frost Hollow Experiments: Pavlovian Signalling as a Path to Coordination and Communication Between Agents},
year = {2022}
}

@inproceedings{Parker2019,
author = {Parker, Adam S.R. and Edwards, Ann L. and Pilarski, Patrick M.},
booktitle = {{IEEE} International Conference on Rehabilitation Robotics ({ICORR})},
title = {Exploring the Impact of Machine-Learned Predictions on Feedback from an Artificial Limb},
year = {2019}
}

@article{Pilarski2019,
author = {Pilarski, Patrick M. and Butcher, Andrew and Johanson, Michael and Botvinick, Matthew M. and Bolt, Andrew and Parker, Adam S. R.},
journal = {arXiv},
volume= {1905.02691},
title = {Learned human-agent decision-making, communication and joint action in a virtual reality environment},
year = {2019}
}

@inproceedings{Dabney2017,
author = {Dabney, Will and Rowland, Mark and Bellemare, Marc G. and Munos, R{\'{e}}mi},
booktitle = {{AAAI} Conference on Artificial Intelligence},
title = {Distributional Reinforcement Learning with Quantile Regression},
year = {2018}
}

@article{mills2020finding,
  title={Finding the ground state of spin Hamiltonians with reinforcement learning},
  author={Mills, Kyle and Ronagh, Pooya and Tamblyn, Isaac},
  journal={Nature Machine Intelligence},
  volume={2},
  pages={509--517},
  year={2020},
}


@article{silver2017mastering,
  title={Mastering the game of {G}o without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
  journal={Nature},
  volume={550},
  pages={354--359},
  year={2017},
}

@article{tunyasuvunakool2021highly,
  title={Highly accurate protein structure prediction for the human proteome},
  author={Tunyasuvunakool, Kathryn and Adler, Jonas and Wu, Zachary and Green, Tim and Zielinski, Michal and {\v{Z}}{\'\i}dek, Augustin and Bridgland, Alex and Cowie, Andrew and Meyer, Clemens and Laydon, Agata and others},
  journal={Nature},
  volume={596},
  pages={590--596},
  year={2021},
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}

@article{unreal,
  title={Reinforcement learning with unsupervised auxiliary tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv},
  volume={1611.05397},
  year={2016}
}

@article{learning_to_navigate,
  title={Learning to navigate in complex environments},
  author={Mirowski, Piotr and Pascanu, Razvan and Viola, Fabio and Soyer, Hubert and Ballard, Andrew J and Banino, Andrea and Denil, Misha and Goroshin, Ross and Sifre, Laurent and Kavukcuoglu, Koray and Kumaran, Dharshan and Hadsell, Raia},
  journal={arXiv},
  volume={1611.03673},
  year={2016}
}

@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{\k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and Rafal Józefowicz and Scott Gray and Catherine Olsson and
Jakub Pachocki and Michael Petrov and Henrique Pondé de Oliveira Pinto and Jonathan Raiman and
Tim Salimans and Jeremy Schlatter and Jonas Schneider and Szymon Sidor and Ilya Sutskever and Jie Tang and Filip Wolski and Susan Zhang},
  journal={arXiv},
  volume={1912.06680},
  year={2019}
}

@article{ibarz2021how,
  author = {Julian Ibarz and Jie Tan and Chelsea Finn and Mrinal Kalakrishnan and Peter Pastor and Sergey Levine},
  title ={How to train your robot with deep reinforcement learning: lessons we have learned},
  journal = {The International Journal of Robotics Research},
  volume = {40},
  number = {4-5},
  pages = {698-721},
  year = {2021},
}

@article{fuchs2021super,
  title={Super-human performance in {Gran Turismo Sport} using deep reinforcement learning},
  author={Fuchs, Florian and Song, Yunlong and Kaufmann, Elia and Scaramuzza, Davide and D{\"u}rr, Peter},
  journal={{IEEE} Robotics and Automation Letters},
  volume={6},
  number={3},
  pages={4257--4264},
  year={2021},
}

@inproceedings{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  booktitle = {Conference on Neural Information Processing Systems ({NeurIPS})},
  year={2020}
}

@article{vinyals2019grandmaster,
  title={Grandmaster level in {StarCraft II} using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Junhyuk Oh and Dan Horgan and Manuel Kroiss and Ivo Danihelka and Aja Huang and Laurent Sifre and Trevor Cai and John P. Agapiou and Max Jaderberg and Alexander S. Vezhnevets and Rémi Leblond and Tobias Pohlen and Valentin Dalibard and David Budden and Yury Sulsky and James Molloy and Tom L. Paine and Caglar Gulcehre and Ziyu Wang and Tobias Pfaff and Yuhuai Wu and Roman Ring and Dani Yogatama and Dario Wünsch and Katrina McKinney and Oliver Smith and Tom Schaul and Timothy Lillicrap and Koray Kavukcuoglu and Demis Hassabis and Chris Apps and David Silver},
  journal={Nature},
  volume={575},
  pages={350--354},
  year={2019},
}


@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle = {Conference on Neural Information Processing Systems ({NeurIPS})},
  year={2016}
}


@article{abdolmaleki2018relative,
  title={Relative entropy regularized policy iteration},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Degrave, Jonas and Bohez, Steven and Tassa, Yuval and Belov, Dan and Heess, Nicolas and Riedmiller, Martin},
  journal={arXiv},
  volume={1812.02256},
  year={2018}
}

@inproceedings{Lillicrap2016continuous,
  author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
  title={Continuous control with deep reinforcement learning.},
  year={2016},
  booktitle={International Conference on Learning Representations (ICLR)}
}

@article{2020SciPy-NMeth,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272}
}

@article{laroche2017multi,
  title={Multi-advisor reinforcement learning},
  author={Laroche, Romain and Fatemi, Mehdi and Romoff, Joshua and van Seijen, Harm},
  journal={arXiv preprint arXiv:1704.00756},
  year={2017}
}

@article{fatemi2022orchestrated,
  title={Orchestrated Value Mapping for Reinforcement Learning},
  author={Fatemi, Mehdi and Tavakoli, Arash},
  journal={arXiv preprint arXiv:2203.07171},
  year={2022}
}