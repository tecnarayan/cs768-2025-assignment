\begin{thebibliography}{38}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amodei et~al.(2016)Amodei, Ananthanarayanan, Anubhai, Bai, Battenberg,
  Case, Casper, Catanzaro, Chen, Chrzanowski, Coates, Diamos, Elsen, Engel,
  Fan, Fougner, Hannun, Jun, Han, LeGresley, Li, Lin, Narang, Ng, Ozair,
  Prenger, Qian, Raiman, Satheesh, Seetapun, Sengupta, Wang, Wang, Wang, Xiao,
  Xie, Yogatama, Zhan, and Zhu]{amodei2016deepspeech2}
Amodei, D., Ananthanarayanan, S., Anubhai, R., Bai, J., Battenberg, E., Case,
  C., Casper, J., Catanzaro, B., Chen, J., Chrzanowski, M., Coates, A., Diamos,
  G., Elsen, E., Engel, J., Fan, L., Fougner, C., Hannun, A.~Y., Jun, B., Han,
  T., LeGresley, P., Li, X., Lin, L., Narang, S., Ng, A.~Y., Ozair, S.,
  Prenger, R., Qian, S., Raiman, J., Satheesh, S., Seetapun, D., Sengupta, S.,
  Wang, C., Wang, Y., Wang, Z., Xiao, B., Xie, Y., Yogatama, D., Zhan, J., and
  Zhu, Z.
\newblock Deep speech 2 : End-to-end speech recognition in english and
  mandarin.
\newblock In \emph{Proceedings of the 33nd International Conference on Machine
  Learning, {ICML} 2016, New York City, NY, USA, June 19-24, 2016}, pp.\
  173--182, 2016.

\bibitem[Athalye \& Carlini(2018)Athalye and Carlini]{athalye2018cvpr}
Athalye, A. and Carlini, N.
\newblock On the robustness of the {CVPR} 2018 white-box adversarial example
  defenses.
\newblock \emph{CoRR}, abs/1804.03286, 2018.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and
  Wagner]{athalye2018obfuscated}
Athalye, A., Carlini, N., and Wagner, D.~A.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock \emph{CoRR}, abs/1802.00420, 2018.

\bibitem[Behzadan \& Munir(2017)Behzadan and Munir]{behzadan2017vulnerability}
Behzadan, V. and Munir, A.
\newblock Vulnerability of deep reinforcement learning to policy induction
  attacks.
\newblock \emph{CoRR}, abs/1701.04143, 2017.

\bibitem[Brendel et~al.(2017)Brendel, Rauber, and Bethge]{brendel2017decision}
Brendel, W., Rauber, J., and Bethge, M.
\newblock Decision-based adversarial attacks: Reliable attacks against
  black-box machine learning models.
\newblock \emph{CoRR}, abs/1712.04248, 2017.

\bibitem[Carlini \& Wagner(2017{\natexlab{a}})Carlini and
  Wagner]{carlini2017bypass}
Carlini, N. and Wagner, D.~A.
\newblock Adversarial examples are not easily detected: Bypassing ten detection
  methods.
\newblock \emph{CoRR}, abs/1705.07263, 2017{\natexlab{a}}.

\bibitem[Carlini \& Wagner(2017{\natexlab{b}})Carlini and
  Wagner]{carlini2017towards}
Carlini, N. and Wagner, D.~A.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{IEEE Symposium on Security and Privacy}, pp.\  39--57,
  2017{\natexlab{b}}.

\bibitem[Carlini \& Wagner(2018)Carlini and Wagner]{carlini2018audio}
Carlini, N. and Wagner, D.~A.
\newblock Audio adversarial examples: Targeted attacks on speech-to-text.
\newblock \emph{CoRR}, abs/1801.01944, 2018.

\bibitem[Chen et~al.(2017)Chen, Zhang, Sharma, Yi, and Hsieh]{chen2017zoo}
Chen, P., Zhang, H., Sharma, Y., Yi, J., and Hsieh, C.
\newblock {ZOO:} zeroth order optimization based black-box attacks to deep
  neural networks without training substitute models.
\newblock In \emph{Proceedings of the 10th {ACM} Workshop on Artificial
  Intelligence and Security, AISec@CCS 2017, Dallas, TX, USA, November 3,
  2017}, pp.\  15--26, 2017.
\newblock \doi{10.1145/3128572.3140448}.

\bibitem[Cheng et~al.(2018)Cheng, Le, Chen, Yi, Zhang, and
  Hsieh]{cheng2018query}
Cheng, M., Le, T., Chen, P., Yi, J., Zhang, H., and Hsieh, C.
\newblock Query-efficient hard-label black-box attack: An optimization-based
  approach.
\newblock \emph{CoRR}, abs/1807.04457, 2018.

\bibitem[Cisse et~al.(2017{\natexlab{a}})Cisse, Adi, Neverova, and
  Keshet]{cisse2017houdini}
Cisse, M., Adi, Y., Neverova, N., and Keshet, J.
\newblock Houdini: Fooling deep structured prediction models.
\newblock \emph{CoRR}, abs/1707.05373, 2017{\natexlab{a}}.

\bibitem[Cisse et~al.(2017{\natexlab{b}})Cisse, Bojanowski, Grave, Dauphin, and
  Usunier]{cisse2017parseval}
Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., and Usunier, N.
\newblock Parseval networks: Improving robustness to adversarial examples.
\newblock \emph{CoRR}, abs/1704.08847, 2017{\natexlab{b}}.

\bibitem[Dziugaite et~al.(2016)Dziugaite, Ghahramani, and
  Roy]{dziugaite2016study}
Dziugaite, G.~K., Ghahramani, Z., and Roy, D.
\newblock A study of the effect of {JPG} compression on adversarial images.
\newblock \emph{CoRR}, abs/1608.00853, 2016.

\bibitem[Fawzi et~al.(2018)Fawzi, Fawzi, and Fawzi]{fawzi2018adversarial}
Fawzi, A., Fawzi, H., and Fawzi, O.
\newblock Adversarial vulnerability for any classifier.
\newblock In \emph{Advances in Neural Information Processing Systems 31: Annual
  Conference on Neural Information Processing Systems 2018, NeurIPS 2018, 3-8
  December 2018, Montr{\'{e}}al, Canada.}, pp.\  1186--1195, 2018.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2015explaining}
Goodfellow, I., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{Proc. ICLR}, 2015.

\bibitem[Guo et~al.(2017)Guo, Rana, Ciss{\'{e}}, and van~der
  Maaten]{guo2017countering}
Guo, C., Rana, M., Ciss{\'{e}}, M., and van~der Maaten, L.
\newblock Countering adversarial images using input transformations.
\newblock \emph{CoRR}, abs/1711.00117, 2017.

\bibitem[Guo et~al.(2018)Guo, Frank, and Weinberger]{guo2018low}
Guo, C., Frank, J.~S., and Weinberger, K.~Q.
\newblock Low frequency adversarial perturbations.
\newblock \emph{CoRR}, abs/1809.08758, 2018.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016residual}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proc. CVPR}, pp.\  770--778, 2016.

\bibitem[Huang et~al.(2017{\natexlab{a}})Huang, Liu, Weinberger, and van~der
  Maaten]{huang2016densely}
Huang, G., Liu, Z., Weinberger, K., and van~der Maaten, L.
\newblock Densely connected convolutional networks.
\newblock In \emph{Proc. CVPR}, pp.\  2261--2269, 2017{\natexlab{a}}.

\bibitem[Huang et~al.(2017{\natexlab{b}})Huang, Papernot, Goodfellow, Duan, and
  Abbeel]{huang2017adversarial}
Huang, S., Papernot, N., Goodfellow, I., Duan, Y., and Abbeel, P.
\newblock Adversarial attacks on neural network policies.
\newblock \emph{CoRR}, abs/1702.02284, 2017{\natexlab{b}}.

\bibitem[Ilyas et~al.(2018{\natexlab{a}})Ilyas, Engstrom, Athalye, and
  Lin]{ilyas2018blackbox}
Ilyas, A., Engstrom, L., Athalye, A., and Lin, J.
\newblock Black-box adversarial attacks with limited queries and information.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning, {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July 10-15,
  2018}, pp.\  2142--2151, 2018{\natexlab{a}}.

\bibitem[Ilyas et~al.(2018{\natexlab{b}})Ilyas, Engstrom, and
  Madry]{ilyas2018prior}
Ilyas, A., Engstrom, L., and Madry, A.
\newblock Prior convictions: Black-box adversarial attacks with bandits and
  priors.
\newblock \emph{CoRR}, abs/1807.07978, 2018{\natexlab{b}}.

\bibitem[Kurakin et~al.(2016)Kurakin, Goodfellow, and
  Bengio]{kurakin2016adversarial}
Kurakin, A., Goodfellow, I., and Bengio, S.
\newblock Adversarial machine learning at scale.
\newblock \emph{CoRR}, abs/1611.01236, 2016.

\bibitem[Li \& Li(2017)Li and Li]{li2017adversarial}
Li, X. and Li, F.
\newblock Adversarial examples detection in deep networks with convolutional
  filter statistics.
\newblock In \emph{{IEEE} International Conference on Computer Vision, {ICCV}
  2017, Venice, Italy, October 22-29, 2017}, pp.\  5775--5783, 2017.
\newblock \doi{10.1109/ICCV.2017.615}.

\bibitem[Lu et~al.(2017)Lu, Issaranon, and Forsyth]{lu2017safetynet}
Lu, J., Issaranon, T., and Forsyth, D.~A.
\newblock Safetynet: Detecting and rejecting adversarial examples robustly.
\newblock In \emph{{IEEE} International Conference on Computer Vision, {ICCV}
  2017, Venice, Italy, October 22-29, 2017}, pp.\  446--454, 2017.
\newblock \doi{10.1109/ICCV.2017.56}.

\bibitem[Madry et~al.(2017)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock \emph{CoRR}, abs/1706.06083, 2017.

\bibitem[Meng \& Chen(2017)Meng and Chen]{meng2017magnet}
Meng, D. and Chen, H.
\newblock Magnet: {A} two-pronged defense against adversarial examples.
\newblock In \emph{Proceedings of the 2017 {ACM} {SIGSAC} Conference on
  Computer and Communications Security, {CCS} 2017, Dallas, TX, USA, October 30
  - November 03, 2017}, pp.\  135--147, 2017.
\newblock \doi{10.1145/3133956.3134057}.

\bibitem[Metzen et~al.(2017)Metzen, Genewein, Fischer, and
  Bischoff]{metzen2017detecting}
Metzen, J.~H., Genewein, T., Fischer, V., and Bischoff, B.
\newblock On detecting adversarial perturbations.
\newblock \emph{CoRR}, abs/1702.04267, 2017.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik,
  Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis]{mnih2015human}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M.~A., Fidjeland, A., Ostrovski, G., Petersen,
  S., Beattie, C., Sadik, A., Antonoglou, I., King, H., Kumaran, D., Wierstra,
  D., Legg, S., and Hassabis, D.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529--533, 2015.
\newblock \doi{10.1038/nature14236}.

\bibitem[Moosavi{-}Dezfooli et~al.(2016)Moosavi{-}Dezfooli, Fawzi, and
  Frossard]{dezfooli2016deepfool}
Moosavi{-}Dezfooli, S., Fawzi, A., and Frossard, P.
\newblock Deepfool: {A} simple and accurate method to fool deep neural
  networks.
\newblock In \emph{Proc. CVPR}, pp.\  2574--2582, 2016.

\bibitem[Moosavi-Dezfooli et~al.(2017)Moosavi-Dezfooli, Fawzi, Fawzi, and
  Frossard]{moosavi2017universal}
Moosavi-Dezfooli, S.-M., Fawzi, A., Fawzi, O., and Frossard, P.
\newblock Universal adversarial perturbations.
\newblock In \emph{Proc. CVPR}, pp.\  86--94, 2017.

\bibitem[Shafahi et~al.(2018)Shafahi, Huang, Studer, Feizi, and
  Goldstein]{shafahi2018inevitable}
Shafahi, A., Huang, W.~R., Studer, C., Feizi, S., and Goldstein, T.
\newblock Are adversarial examples inevitable?
\newblock \emph{CoRR}, abs/1809.02104, 2018.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock In \emph{In Proc. ICLR}, 2014.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{szegedy2016rethinking}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Proc. CVPR}, pp.\  2818--2826, 2016.

\bibitem[Tram{\`{e}}r et~al.(2017)Tram{\`{e}}r, Kurakin, Papernot, Boneh, and
  McDaniel]{tramer2017ensemble}
Tram{\`{e}}r, F., Kurakin, A., Papernot, N., Boneh, D., and McDaniel, P.~D.
\newblock Ensemble adversarial training: Attacks and defenses.
\newblock \emph{CoRR}, abs/1705.07204, 2017.

\bibitem[Tu et~al.(2018)Tu, Ting, Chen, Liu, Zhang, Yi, Hsieh, and
  Cheng]{tu2018autozoom}
Tu, C., Ting, P., Chen, P., Liu, S., Zhang, H., Yi, J., Hsieh, C., and Cheng,
  S.
\newblock Autozoom: Autoencoder-based zeroth order optimization method for
  attacking black-box neural networks.
\newblock \emph{CoRR}, abs/1805.11770, 2018.

\bibitem[Xie et~al.(2017)Xie, Wang, Zhang, Zhou, Xie, and
  Yuille]{xie2017adversarial}
Xie, C., Wang, J., Zhang, Z., Zhou, Y., Xie, L., and Yuille, A.~L.
\newblock Adversarial examples for semantic segmentation and object detection.
\newblock In \emph{{ICCV}}, pp.\  1378--1387. {IEEE} Computer Society, 2017.

\bibitem[Xu et~al.(2017)Xu, Evans, and Qi]{xu2017feature}
Xu, W., Evans, D., and Qi, Y.
\newblock Feature squeezing: Detecting adversarial examples in deep neural
  networks.
\newblock \emph{CoRR}, abs/1704.01155, 2017.

\end{thebibliography}
