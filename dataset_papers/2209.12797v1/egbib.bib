@inproceedings{wang2021adaptive,
  title={Adaptive focus for efficient video recognition},
  author={Wang, Yulin and Chen, Zhaoxi and Jiang, Haojun and Song, Shiji and Han, Yizeng and Huang, Gao},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={16249--16258},
  year={2021}
}

@article{wu2019liteeval,
  title={Liteeval: A coarse-to-fine framework for resource efficient video recognition},
  author={Wu, Zuxuan and Xiong, Caiming and Jiang, Yu-Gang and Davis, Larry S},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{korbar2019scsampler,
  title={Scsampler: Sampling salient clips from video for efficient action recognition},
  author={Korbar, Bruno and Tran, Du and Torresani, Lorenzo},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6232--6242},
  year={2019}
}

@inproceedings{meng2020ar,
  title={Ar-net: Adaptive frame resolution for efficient action recognition},
  author={Meng, Yue and Lin, Chung-Ching and Panda, Rameswar and Sattigeri, Prasanna and Karlinsky, Leonid and Oliva, Aude and Saenko, Kate and Feris, Rogerio},
  booktitle={European Conference on Computer Vision},
  pages={86--104},
  year={2020},
  organization={Springer}
}

@inproceedings{wu2019adaframe,
  title={Adaframe: Adaptive frame selection for fast video recognition},
  author={Wu, Zuxuan and Xiong, Caiming and Ma, Chih-Yao and Socher, Richard and Davis, Larry S},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1278--1287},
  year={2019}
}

@article{meng2021adafuse,
  title={Adafuse: Adaptive temporal fusion network for efficient action recognition},
  author={Meng, Yue and Panda, Rameswar and Lin, Chung-Ching and Sattigeri, Prasanna and Karlinsky, Leonid and Saenko, Kate and Oliva, Aude and Feris, Rogerio},
  journal={arXiv preprint arXiv:2102.05775},
  year={2021}
}

@inproceedings{kim2021efficient,
  title={Efficient Action Recognition via Dynamic Knowledge Propagation},
  author={Kim, Hanul and Jain, Mihir and Lee, Jun-Tae and Yun, Sungrack and Porikli, Fatih},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={13719--13728},
  year={2021}
}

@inproceedings{ghodrati2021frameexit,
  title={Frameexit: Conditional early exiting for efficient video recognition},
  author={Ghodrati, Amir and Bejnordi, Babak Ehteshami and Habibian, Amirhossein},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15608--15618},
  year={2021}
}

@inproceedings{sun2021dynamic,
  title={Dynamic network quantization for efficient video inference},
  author={Sun, Ximeng and Panda, Rameswar and Chen, Chun-Fu Richard and Oliva, Aude and Feris, Rogerio and Saenko, Kate},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7375--7385},
  year={2021}
}

@article{wang2021adafocus,
  title={AdaFocus V2: End-to-End Training of Spatial Dynamic Networks for Video Recognition},
  author={Wang, Yulin and Yue, Yang and Lin, Yuanze and Jiang, Haojun and Lai, Zihang and Kulikov, Victor and Orlov, Nikita and Shi, Humphrey and Huang, Gao},
  journal={arXiv preprint arXiv:2112.14238},
  year={2021}
}

@article{lin2022ocsampler,
  title={OCSampler: Compressing Videos to One Clip with Single-step Sampling},
  author={Lin, Jintao and Duan, Haodong and Chen, Kai and Lin, Dahua and Wang, Limin},
  journal={arXiv preprint arXiv:2201.04388},
  year={2022}
}

@inproceedings{gao2020listen,
  title={Listen to look: Action recognition by previewing audio},
  author={Gao, Ruohan and Oh, Tae-Hyun and Grauman, Kristen and Torresani, Lorenzo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10457--10467},
  year={2020}
}

@inproceedings{wu2019multi,
  title={Multi-agent reinforcement learning based frame sampling for effective untrimmed video recognition},
  author={Wu, Wenhao and He, Dongliang and Tan, Xiao and Chen, Shifeng and Wen, Shilei},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6222--6231},
  year={2019}
}

@inproceedings{wang2016temporal,
  title={Temporal segment networks: Towards good practices for deep action recognition},
  author={Wang, Limin and Xiong, Yuanjun and Wang, Zhe and Qiao, Yu and Lin, Dahua and Tang, Xiaoou and Gool, Luc Van},
  booktitle={European conference on computer vision},
  pages={20--36},
  year={2016},
  organization={Springer}
}

@inproceedings{zhou2018temporal,
  title={Temporal relational reasoning in videos},
  author={Zhou, Bolei and Andonian, Alex and Oliva, Aude and Torralba, Antonio},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={803--818},
  year={2018}
}

@inproceedings{liu2021tam,
  title={Tam: Temporal adaptive module for video recognition},
  author={Liu, Zhaoyang and Wang, Limin and Wu, Wayne and Qian, Chen and Lu, Tong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={13708--13718},
  year={2021}
}

@inproceedings{li2020tea,
  title={Tea: Temporal excitation and aggregation for action recognition},
  author={Li, Yan and Ji, Bin and Shi, Xintian and Zhang, Jianguo and Kang, Bin and Wang, Limin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={909--918},
  year={2020}
}

@inproceedings{lin2019tsm,
  title={Tsm: Temporal shift module for efficient video understanding},
  author={Lin, Ji and Gan, Chuang and Han, Song},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7083--7093},
  year={2019}
}

@inproceedings{komodakis2017paying,
  title={Paying more attention to attention: improving the performance of convolutional neural networks via attention transfer},
  author={Komodakis, Nikos and Zagoruyko, Sergey},
  booktitle={ICLR},
  year={2017}
}

@article{ba2014deep,
  title={Do deep nets really need to be deep?},
  author={Ba, Jimmy and Caruana, Rich},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff and others},
  journal={arXiv preprint arXiv:1503.02531},
  volume={2},
  number={7},
  year={2015}
}

@inproceedings{garcia2018modality,
  title={Modality distillation with multiple stream networks for action recognition},
  author={Garcia, Nuno C and Morerio, Pietro and Murino, Vittorio},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={103--118},
  year={2018}
}

@inproceedings{purwanto2019extreme,
  title={Extreme low resolution action recognition with spatial-temporal multi-head self-attention and knowledge distillation},
  author={Purwanto, Didik and Renanda Adhi Pramono, Rizard and Chen, Yie-Tarng and Fang, Wen-Hsien},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops},
  pages={0--0},
  year={2019}
}

@inproceedings{stroud2020d3d,
  title={D3d: Distilled 3d networks for video action recognition},
  author={Stroud, Jonathan and Ross, David and Sun, Chen and Deng, Jia and Sukthankar, Rahul},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={625--634},
  year={2020}
}

@inproceedings{neimark2021video,
  title={Video transformer network},
  author={Neimark, Daniel and Bar, Omri and Zohar, Maya and Asselmann, Dotan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3163--3172},
  year={2021}
}

@article{bertasius2021space,
  title={Is space-time attention all you need for video understanding},
  author={Bertasius, Gedas and Wang, Heng and Torresani, Lorenzo},
  journal={arXiv preprint arXiv:2102.05095},
  volume={2},
  number={3},
  pages={4},
  year={2021}
}

@article{patrick2021keeping,
  title={Keeping your eye on the ball: Trajectory attention in video transformers},
  author={Patrick, Mandela and Campbell, Dylan and Asano, Yuki and Misra, Ishan and Metze, Florian and Feichtenhofer, Christoph and Vedaldi, Andrea and Henriques, Jo{\~a}o F},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{liu2021video,
  title={Video swin transformer},
  author={Liu, Ze and Ning, Jia and Cao, Yue and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Hu, Han},
  journal={arXiv preprint arXiv:2106.13230},
  year={2021}
}

@inproceedings{tran2015learning,
  title={Learning spatiotemporal features with 3d convolutional networks},
  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4489--4497},
  year={2015}
}

@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6299--6308},
  year={2017}
}

@inproceedings{feichtenhofer2020x3d,
  title={X3d: Expanding architectures for efficient video recognition},
  author={Feichtenhofer, Christoph},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={203--213},
  year={2020}
}

@inproceedings{donahue2015long,
  title={Long-term recurrent convolutional networks for visual recognition and description},
  author={Donahue, Jeffrey and Anne Hendricks, Lisa and Guadarrama, Sergio and Rohrbach, Marcus and Venugopalan, Subhashini and Saenko, Kate and Darrell, Trevor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2625--2634},
  year={2015}
}

@article{li2018videolstm,
  title={Videolstm convolves, attends and flows for action recognition},
  author={Li, Zhenyang and Gavrilyuk, Kirill and Gavves, Efstratios and Jain, Mihir and Snoek, Cees GM},
  journal={Computer Vision and Image Understanding},
  volume={166},
  pages={41--50},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{liu2020teinet,
  title={Teinet: Towards an efficient architecture for video recognition},
  author={Liu, Zhaoyang and Luo, Donghao and Wang, Yabiao and Wang, Limin and Tai, Ying and Wang, Chengjie and Li, Jilin and Huang, Feiyue and Lu, Tong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={07},
  pages={11669--11676},
  year={2020}
}

@inproceedings{tran2019video,
  title={Video classification with channel-separated convolutional networks},
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Feiszli, Matt},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5552--5561},
  year={2019}
}

@inproceedings{tran2018closer,
  title={A closer look at spatiotemporal convolutions for action recognition},
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Ray, Jamie and LeCun, Yann and Paluri, Manohar},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={6450--6459},
  year={2018}
}

@inproceedings{xie2018rethinking,
  title={Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs in video classification},
  author={Xie, Saining and Sun, Chen and Huang, Jonathan and Tu, Zhuowen and Murphy, Kevin},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={305--321},
  year={2018}
}

@inproceedings{zolfaghari2018eco,
  title={Eco: Efficient convolutional network for online video understanding},
  author={Zolfaghari, Mohammadreza and Singh, Kamaljeet and Brox, Thomas},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={695--712},
  year={2018}
}

@inproceedings{kondratyuk2021movinets,
  title={Movinets: Mobile video networks for efficient video recognition},
  author={Kondratyuk, Dan and Yuan, Liangzhe and Li, Yandong and Zhang, Li and Tan, Mingxing and Brown, Matthew and Gong, Boqing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16020--16030},
  year={2021}
}

@article{fan2019more,
  title={More is less: Learning efficient video representations by big-little network and depthwise temporal aggregation},
  author={Fan, Quanfu and Chen, Chun-Fu Richard and Kuehne, Hilde and Pistoia, Marco and Cox, David},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{fan2018watching,
  title={Watching a small portion could be as good as watching all: Towards efficient video classification},
  author={Fan, Hehe and Xu, Zhongwen and Zhu, Linchao and Yan, Chenggang and Ge, Jianjun and Yang, Yi},
  booktitle={IJCAI International Joint Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{wu2020dynamic,
  title={Dynamic inference: A new approach toward efficient video action recognition},
  author={Wu, Wenhao and He, Dongliang and Tan, Xiao and Chen, Shifeng and Yang, Yi and Wen, Shilei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={676--677},
  year={2020}
}

@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@inproceedings{caba2015activitynet,
  title={Activitynet: A large-scale video benchmark for human activity understanding},
  author={Caba Heilbron, Fabian and Escorcia, Victor and Ghanem, Bernard and Carlos Niebles, Juan},
  booktitle={Proceedings of the ieee conference on computer vision and pattern recognition},
  pages={961--970},
  year={2015}
}

@article{kay2017kinetics,
  title={The kinetics human action video dataset},
  author={Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and others},
  journal={arXiv preprint arXiv:1705.06950},
  year={2017}
}

@article{jiang2017exploiting,
  title={Exploiting feature and class relationships in video categorization with regularized deep neural networks},
  author={Jiang, Yu-Gang and Wu, Zuxuan and Wang, Jun and Xue, Xiangyang and Chang, Shih-Fu},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={2},
  pages={352--364},
  year={2017},
  publisher={IEEE}
}

@inproceedings{goyal2017something,
  title={The" something something" video database for learning and evaluating visual common sense},
  author={Goyal, Raghav and Ebrahimi Kahou, Samira and Michalski, Vincent and Materzynska, Joanna and Westphal, Susanne and Kim, Heuna and Haenel, Valentin and Fruend, Ingo and Yianilos, Peter and Mueller-Freitag, Moritz and others},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5842--5850},
  year={2017}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{feichtenhofer2019slowfast,
  title={Slowfast networks for video recognition},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6202--6211},
  year={2019}
}

@misc{2020mmaction2,
    title={OpenMMLab's Next Generation Video Understanding Toolbox and Benchmark},
    author={MMAction2 Contributors},
    howpublished = {\url{https://github.com/open-mmlab/mmaction2}},
    year={2020}
}

@inproceedings{heo2019comprehensive,
  title={A comprehensive overhaul of feature distillation},
  author={Heo, Byeongho and Kim, Jeesoo and Yun, Sangdoo and Park, Hyojin and Kwak, Nojun and Choi, Jin Young},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1921--1930},
  year={2019}
}

@article{kim2018paraphrasing,
  title={Paraphrasing complex network: Network compression via factor transfer},
  author={Kim, Jangho and Park, SeongUk and Kwak, Nojun},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{romero2014fitnets,
  title={Fitnets: Hints for thin deep nets},
  author={Romero, Adriana and Ballas, Nicolas and Kahou, Samira Ebrahimi and Chassang, Antoine and Gatta, Carlo and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.6550},
  year={2014}
}