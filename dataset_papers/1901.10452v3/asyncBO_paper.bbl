\begin{thebibliography}{26}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Azimi et~al.(2010)Azimi, Fern, and Fern]{azimi2010batch}
Azimi, J., Fern, A., and Fern, X.~Z.
\newblock Batch {B}ayesian optimization via simulation matching.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  109--117, 2010.

\bibitem[Blaas et~al.(2019)Blaas, Manzano, Limon, and Calliess]{blaas19kinky}
Blaas, A., Manzano, J.~M., Limon, D., and Calliess, J.
\newblock Localised kinky inference.
\newblock In \emph{Proceedings of the European Control Conference}, 2019.

\bibitem[Brochu et~al.(2010)Brochu, Cora, and De~Freitas]{brochu2010tutorial}
Brochu, E., Cora, V.~M., and De~Freitas, N.
\newblock A tutorial on {B}ayesian optimization of expensive cost functions,
  with application to active user modeling and hierarchical reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1012.2599}, 2010.

\bibitem[Chen et~al.(2018)Chen, Huang, Wang, Antonoglou, Schrittwieser, Silver,
  and de~Freitas]{chen2018bayesian}
Chen, Y., Huang, A., Wang, Z., Antonoglou, I., Schrittwieser, J., Silver, D.,
  and de~Freitas, N.
\newblock {B}ayesian optimization in {AlphaGo}.
\newblock \emph{arXiv preprint arXiv:1812.06855}, 2018.

\bibitem[Contal et~al.(2013)Contal, Buffoni, Robicquet, and
  Vayatis]{contal2013parallel}
Contal, E., Buffoni, D., Robicquet, A., and Vayatis, N.
\newblock Parallel {G}aussian process optimization with {U}pper {C}onfidence
  {B}ound and {P}ure {E}xploration.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pp.\  225--240. Springer, 2013.

\bibitem[Desautels et~al.(2014)Desautels, Krause, and
  Burdick]{desautels2014parallelizing}
Desautels, T., Krause, A., and Burdick, J.~W.
\newblock Parallelizing exploration-exploitation tradeoffs in {G}aussian
  process bandit optimization.
\newblock \emph{The Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 3873--3923, 2014.

\bibitem[Ginsbourger et~al.(2008)Ginsbourger, Le~Riche, and
  Carraro]{ginsbourger2008multi}
Ginsbourger, D., Le~Riche, R., and Carraro, L.
\newblock A multi-points criterion for deterministic parallel global
  optimization based on {G}aussian processes.
\newblock 2008.

\bibitem[Ginsbourger et~al.(2010)Ginsbourger, Le~Riche, and
  Carraro]{ginsbourger2010kriging}
Ginsbourger, D., Le~Riche, R., and Carraro, L.
\newblock Kriging is well-suited to parallelize optimization.
\newblock In \emph{Computational intelligence in expensive optimization
  problems}, pp.\  131--162. Springer, 2010.

\bibitem[Ginsbourger et~al.(2011)Ginsbourger, Janusevskis, and
  Le~Riche]{ginsbourger2011dealing}
Ginsbourger, D., Janusevskis, J., and Le~Riche, R.
\newblock Dealing with asynchronicity in parallel {G}aussian process based
  global optimization.
\newblock In \emph{4th International Conference of the ERCIM WG on computing \&
  statistics (ERCIM'11)}, 2011.

\bibitem[Gonz{\'a}lez et~al.(2016)Gonz{\'a}lez, Dai, Hennig, and
  Lawrence]{gonzalez2016batch}
Gonz{\'a}lez, J., Dai, Z., Hennig, P., and Lawrence, N.
\newblock Batch {B}ayesian optimization via local penalization.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  648--657,
  2016.

\bibitem[Hennig \& Schuler(2012)Hennig and Schuler]{hennig2012entropy}
Hennig, P. and Schuler, C.~J.
\newblock Entropy search for information-efficient global optimization.
\newblock \emph{Journal of Machine Learning Research}, 13\penalty0
  (Jun):\penalty0 1809--1837, 2012.

\bibitem[Hern{\'a}ndez-Lobato et~al.(2014)Hern{\'a}ndez-Lobato, Hoffman, and
  Ghahramani]{hernandez2014predictive}
Hern{\'a}ndez-Lobato, J.~M., Hoffman, M.~W., and Ghahramani, Z.
\newblock Predictive entropy search for efficient global optimization of
  black-box functions.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  918--926, 2014.

\bibitem[Hern{\'a}ndez-Lobato et~al.(2017)Hern{\'a}ndez-Lobato, Requeima,
  Pyzer-Knapp, and Aspuru-Guzik]{hernandez2017parallel}
Hern{\'a}ndez-Lobato, J.~M., Requeima, J., Pyzer-Knapp, E.~O., and
  Aspuru-Guzik, A.
\newblock Parallel and distributed {T}hompson sampling for large-scale
  accelerated exploration of chemical space.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2017.

\bibitem[Jalali et~al.(2013)Jalali, Azimi, Fern, and
  Zhang]{jalali2013lipschitz}
Jalali, A., Azimi, J., Fern, X., and Zhang, R.
\newblock A {L}ipschitz exploration-exploitation scheme for {B}ayesian
  optimization.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pp.\  210--224. Springer, 2013.

\bibitem[Jones et~al.(1998)Jones, Schonlau, and Welch]{jones1998efficient}
Jones, D.~R., Schonlau, M., and Welch, W.~J.
\newblock Efficient global optimization of expensive black-box functions.
\newblock \emph{Journal of Global optimization}, 13\penalty0 (4):\penalty0
  455--492, 1998.

\bibitem[Kandasamy et~al.(2018)Kandasamy, Krishnamurthy, Schneider, and
  P{\'o}czos]{kandasamy2018parallelised}
Kandasamy, K., Krishnamurthy, A., Schneider, J., and P{\'o}czos, B.
\newblock Parallelised {B}ayesian optimisation via {T}hompson sampling.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  133--142, 2018.

\bibitem[Kathuria et~al.(2016)Kathuria, Deshpande, and
  Kohli]{kathuria2016batched}
Kathuria, T., Deshpande, A., and Kohli, P.
\newblock Batched {G}aussian process bandit optimization via determinantal
  point processes.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  4206--4214, 2016.

\bibitem[Krizhevsky(2009)]{krizhevsky2009learning}
Krizhevsky, A.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, Citeseer, 2009.

\bibitem[Kushner(1964)]{kushner1964new}
Kushner, H.~J.
\newblock A new method of locating the maximum point of an arbitrary multipeak
  curve in the presence of noise.
\newblock \emph{Journal of Basic Engineering}, 86\penalty0 (1):\penalty0
  97--106, 1964.

\bibitem[Rasmussen \& Williams(2006)Rasmussen and
  Williams]{rasmussen2006gaussian}
Rasmussen, C.~E. and Williams, C.~K.
\newblock \emph{{G}aussian processes for machine learning}, volume~1.
\newblock MIT press Cambridge, 2006.

\bibitem[Ru et~al.(2018)Ru, McLeod, Granziol, and Osborne]{ru2017fast}
Ru, B., McLeod, M., Granziol, D., and Osborne, M.~A.
\newblock Fast information-theoretic {B}ayesian optimisation.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2018.

\bibitem[Shah \& Ghahramani(2015)Shah and Ghahramani]{shah2015parallel}
Shah, A. and Ghahramani, Z.
\newblock Parallel predictive entropy search for batch global optimization of
  expensive objective functions.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3330--3338, 2015.

\bibitem[Srinivas et~al.(2010)Srinivas, Krause, Kakade, and
  Seeger]{srinivas2009gaussian}
Srinivas, N., Krause, A., Kakade, S.~M., and Seeger, M.
\newblock {G}aussian process optimization in the bandit setting: No regret and
  experimental design.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2010.

\bibitem[Wang et~al.(2016)Wang, Clark, Liu, and Frazier]{wang2016parallel}
Wang, J., Clark, S.~C., Liu, E., and Frazier, P.~I.
\newblock Parallel {B}ayesian global optimization of expensive functions.
\newblock \emph{arXiv preprint arXiv:1602.05149}, 2016.

\bibitem[Wang \& Jegelka(2017)Wang and Jegelka]{wang2017maxvalue}
Wang, Z. and Jegelka, S.
\newblock Max-value entropy search for efficient {B}ayesian optimization.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2017.

\bibitem[Wu \& Frazier(2016)Wu and Frazier]{wu2016parallel}
Wu, J. and Frazier, P.
\newblock The parallel knowledge gradient method for batch {B}ayesian
  optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3126--3134, 2016.

\end{thebibliography}
