\begin{thebibliography}{35}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amaldi \& Kann(1998)Amaldi and Kann]{amaldi_approximability_1998}
Amaldi, E. and Kann, V.
\newblock On the {A}pproximability of {M}inimizing {N}onzero {V}ariables or {U}nsatisfied {R}elations in {L}inear {S}ystems.
\newblock \emph{Theoretical Computer Science}, 209:\penalty0 237--260, 1998.

\bibitem[Anguita et~al.(2013)Anguita, Ghio, Oneto, Parra, and Reyes-Ortiz]{smartphone-har}
Anguita, D., Ghio, A., Oneto, L., Parra, X., and Reyes-Ortiz, J.~L.
\newblock A {Public} {Domain} {Dataset} for {Human} {Activity} {Recognition} using {Smartphones}.
\newblock In \emph{The European Symposium on Artificial Neural Networks}, 2013.

\bibitem[Bakker et~al.(2020)Bakker, {van Hoof}, and Welling]{bakkerExperimentalDesignMRI2020a}
Bakker, T., {van Hoof}, H., and Welling, M.
\newblock Experimental {Design} for {MRI} by {Greedy} {Policy} {Search}.
\newblock In \emph{Advances in {{Neural Information Processing Systems}}}, 2020.

\bibitem[Balın et~al.(2019)Balın, Abid, and Zou]{balin_concrete_2019}
Balın, M.~F., Abid, A., and Zou, J.
\newblock Concrete {Autoencoders}: {Differentiable} {Feature} {Selection} and {Reconstruction}.
\newblock In \emph{{International} {Conference} on {Machine} {Learning}}, 2019.

\bibitem[Barber \& Cand{\`e}s(2015)Barber and Cand{\`e}s]{barberControllingFalseDiscovery2015}
Barber, R.~F. and Cand{\`e}s, E.~J.
\newblock Controlling the {False} {Discovery} {Rate} via {Knockoffs}.
\newblock \emph{The Annals of Statistics}, 43, 2015.

\bibitem[Cai et~al.(2018)Cai, Luo, Wang, and Yang]{cai2018feature}
Cai, J., Luo, J., Wang, S., and Yang, S.
\newblock Feature {S}election in {M}achine {L}earning: {A} {N}ew {P}erspective.
\newblock \emph{Neurocomputing}, 300:\penalty0 70--79, 2018.

\bibitem[Carvalho et~al.(2009)Carvalho, Polson, and Scott]{carvalhoHandlingSparsityHorseshoe2009}
Carvalho, C.~M., Polson, N.~G., and Scott, J.~G.
\newblock Handling {{Sparsity}} via the {{Horseshoe}}.
\newblock In \emph{{International Conference} on {Artificial Intelligence} and {Statistics}}, 2009.

\bibitem[Chen et~al.(2018)Chen, Song, Wainwright, and Jordan]{chenLearningExplainInformationTheoretic2018}
Chen, J., Song, L., Wainwright, M., and Jordan, M.
\newblock Learning to {{Explain}}: {{An Information-Theoretic Perspective}} on {{Model Interpretation}}.
\newblock In \emph{{{International Conference}} on {{Machine Learning}}}, 2018.

\bibitem[Cherepanova et~al.(2023)Cherepanova, Levin, Somepalli, Geiping, Bruss, Wilson, Goldstein, and Goldblum]{cherepanovaPerformanceDrivenBenchmarkFeature2023}
Cherepanova, V., Levin, R., Somepalli, G., Geiping, J., Bruss, C.~B., Wilson, A.~G., Goldstein, T., and Goldblum, M.
\newblock A {{Performance-Driven Benchmark}} for {{Feature Selection}} in {{Tabular Deep Learning}}.
\newblock In \emph{Advances in {{Neural Information Processing Systems}}}, 2023.

\bibitem[Cui \& Wang(2016)Cui and Wang]{CUI2016505}
Cui, C. and Wang, D.
\newblock High {Dimensional} {Data} {Regression} {Using} {Lasso} {Model} and {Neural} {Networks} with {Random} {Weights}.
\newblock \emph{Information Sciences}, 372:\penalty0 505--517, 2016.

\bibitem[Englesson \& Azizpour(2021)Englesson and Azizpour]{englesson2021generalized}
Englesson, E. and Azizpour, H.
\newblock Generalized {Jensen-Shannon} {Divergence} {Loss} for {Learning} with {Noisy} {Labels}.
\newblock \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Fanty \& Cole(1990)Fanty and Cole]{isolet}
Fanty, M. and Cole, R.
\newblock Spoken {L}etter {R}ecognition.
\newblock In \emph{Advances in Neural Information Processing Systems}, 1990.

\bibitem[Gumbel(1954)]{gumbelMaximaMeanLargest1954}
Gumbel, E.~J.
\newblock The {{Maxima}} of the {{Mean Largest Value}} and of the {{Range}}.
\newblock \emph{The Annals of Mathematical Statistics}, 25:\penalty0 76--84, 1954.

\bibitem[Guyon \& Elisseeff(2003)Guyon and Elisseeff]{feature_selection_survey}
Guyon, I. and Elisseeff, A.
\newblock An {Introduction} to {Variable} and {Feature} {Selection}.
\newblock \emph{Journal of Machine Learning Research}, 3:\penalty0 1157–1182, 2003.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Mu, Cubuk, Zoph, Gilmer, and Lakshminarayanan]{hendrycks2019augmix}
Hendrycks, D., Mu, N., Cubuk, E.~D., Zoph, B., Gilmer, J., and Lakshminarayanan, B.
\newblock {AugMix}: {A} {Simple} {Data} {Processing} {Method} to {Improve} {Robustness} and {Uncertainty}.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Higuera et~al.(2015)Higuera, Gardiner, and Cios]{mice-protein-original-paper}
Higuera, C., Gardiner, K.~J., and Cios, K.~J.
\newblock {Self-Organizing} {Feature} {Maps} {Identify} {Proteins} {Critical} to {Learning} in a {Mouse} {Model} of {Down} {Syndrome}.
\newblock \emph{PLoS ONE}, 10, 2015.

\bibitem[Huijben et~al.(2019)Huijben, Veeling, and van Sloun]{huijbenDeepProbabilisticSubsampling2019}
Huijben, I. A.~M., Veeling, B.~S., and van Sloun, R. J.~G.
\newblock Deep probabilistic subsampling for task-adaptive compressed sensing.
\newblock In \emph{International {{Conference}} on {{Learning Representations}}}, 2019.

\bibitem[Indelman \& Hazan(2021)Indelman and Hazan]{indelmanLearningRandomlyPerturbed2021}
Indelman, H.~C. and Hazan, T.
\newblock Learning {Randomly} {Perturbed} {Structured} {Predictors} for {Direct} {Loss} {Minimization}.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Jang et~al.(2017)Jang, Gu, and Poole]{jang_gumbel_softmax_2017}
Jang, E., Gu, S., and Poole, B.
\newblock Categorical {Reparameterization} with {Gumbel}-{Softmax}.
\newblock In \emph{International {Conference} on {Learning} {Representations}}, 2017.

\bibitem[Kviman et~al.(2022)Kviman, Melin, Koptagel, Elvira, and Lagergren]{pmlr-v151-kviman22a}
Kviman, O., Melin, H., Koptagel, H., Elvira, V., and Lagergren, J.
\newblock Multiple {I}mportance {S}ampling {ELBO} and {D}eep {E}nsembles of {V}ariational {A}pproximations.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, 2022.

\bibitem[Kviman et~al.(2023)Kviman, Mol\'{e}n, Hotti, Kurt, Elvira, and Lagergren]{pmlr-v202-kviman23a}
Kviman, O., Mol\'{e}n, R., Hotti, A., Kurt, S., Elvira, V., and Lagergren, J.
\newblock Cooperation in the {Latent} {Space}: {The} {Benefits} of {Adding} {Mixture} {Components} in {Variational} {Autoencoders}.
\newblock In \emph{International Conference on Machine Learning}, 2023.

\bibitem[LeCun et~al.(1998)LeCun, Cortes, and Burges]{mnist}
LeCun, Y., Cortes, C., and Burges, C.
\newblock The {MNIST} {D}atabase of {H}andwritten {D}igits.
\newblock 1998.

\bibitem[Lemhadri et~al.(2021)Lemhadri, Ruan, and Tibshirani]{lemhadri_lassonet_2021}
Lemhadri, I., Ruan, F., and Tibshirani, R.
\newblock {LassoNet}: {Neural} {Networks} with {Feature} {Sparsity}.
\newblock In \emph{{International} {Conference} on {Artificial} {Intelligence} and {Statistics}}, 2021.

\bibitem[Li et~al.(2017)Li, Cheng, Wang, Morstatter, Trevino, Tang, and Liu]{li_feature_2017}
Li, J., Cheng, K., Wang, S., Morstatter, F., Trevino, R.~P., Tang, J., and Liu, H.
\newblock Feature {Selection}: {A} {Data} {Perspective}.
\newblock \emph{ACM Computing Surveys}, 50:\penalty0 94:1--94:45, 2017.

\bibitem[Louizos et~al.(2018)Louizos, Welling, and Kingma]{louizosLearningSparseNeural2018a}
Louizos, C., Welling, M., and Kingma, D.~P.
\newblock Learning {{Sparse Neural Networks}} through \${{L}}\_0\$ {{Regularization}}.
\newblock In \emph{International {{Conference}} on {{Learning Representations}}}, 2018.

\bibitem[Maddison et~al.(2017)Maddison, Mnih, and Teh]{maddison_concrete_2017}
Maddison, C.~J., Mnih, A., and Teh, Y.~W.
\newblock The {Concrete} {Distribution}: {A} {Continuous} {Relaxation} of {Discrete} {Random} {Variables}.
\newblock In \emph{International {Conference} on {Learning} {Representations}}, 2017.

\bibitem[Nene et~al.(1996)Nene, Nayar, Murase, et~al.]{coil20}
Nene, S.~A., Nayar, S.~K., Murase, H., et~al.
\newblock Columbia {Object} {Image} {Library} {(COIL-20)}.
\newblock \emph{Technical Report CUCS-005-96}, 1996.

\bibitem[Ro{\v c}kov{\'a} \& George(2018)Ro{\v c}kov{\'a} and George]{rockovaSpikeandSlabLASSO2018}
Ro{\v c}kov{\'a}, V. and George, E.~I.
\newblock The {{Spike-and-Slab LASSO}}.
\newblock \emph{Journal of the American Statistical Association}, 113:\penalty0 431--444, 2018.

\bibitem[Romano et~al.(2020)Romano, Sesia, and Cand{\`e}s]{romanoDeepKnockoffs2020}
Romano, Y., Sesia, M., and Cand{\`e}s, E.
\newblock Deep {{Knockoffs}}.
\newblock \emph{Journal of the American Statistical Association}, 115:\penalty0 1861--1872, 2020.

\bibitem[Sokar et~al.(2022)Sokar, Atashgahi, Pechenizkiy, and Mocanu]{sokar_where_2022}
Sokar, G., Atashgahi, Z., Pechenizkiy, M., and Mocanu, D.~C.
\newblock Where to {Pay} {Attention} in {Sparse} {Training} for {Feature} {Selection}?
\newblock \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Strypsteen \& Bertrand(2021)Strypsteen and Bertrand]{strypsteen2021endtoend}
Strypsteen, T. and Bertrand, A.
\newblock {End-to-End} {Learnable} {EEG} {Channel} {Selection} for {Deep} {Neural} {Networks} with {Gumbel-Softmax}.
\newblock \emph{Journal of Neural Engineering}, 18, 2021.

\bibitem[Tibshirani(1996)]{tibshiraniRegressionShrinkageSelection1996}
Tibshirani, R.
\newblock Regression {{Shrinkage}} and {{Selection Via}} the {{Lasso}}.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Methodological)}, 58:\penalty0 267--288, 1996.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{fashion-mnist}
Xiao, H., Rasul, K., and Vollgraf, R.
\newblock {Fashion-MNIST}: a {Novel} {Image} {Dataset} for {Benchmarking} {Machine} {Learning} {Algorithms}.
\newblock \emph{arXiv preprint arXiv:1708.07747}, 2017.

\bibitem[Yamada et~al.(2020)Yamada, Lindenbaum, Negahban, and Kluger]{yamada_feature_2020}
Yamada, Y., Lindenbaum, O., Negahban, S., and Kluger, Y.
\newblock Feature {Selection} using {Stochastic} {Gates}.
\newblock In \emph{{International} {Conference} on {Machine} {Learning}}, 2020.

\bibitem[Yoon et~al.(2018)Yoon, Jordon, and van~der Schaar]{yoonINVASEInstancewiseVariable2018}
Yoon, J., Jordon, J., and van~der Schaar, M.
\newblock {{INVASE}}: {{Instance-wise Variable Selection}} using {{Neural Networks}}.
\newblock In \emph{International {{Conference}} on {{Learning Representations}}}, 2018.

\end{thebibliography}
