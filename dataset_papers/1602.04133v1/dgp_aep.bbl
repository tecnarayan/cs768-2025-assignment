\begin{thebibliography}{34}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Barber \& Schottky(1998)Barber and Schottky]{barber-schottky-98b}
Barber, D. and Schottky, B.
\newblock Radial basis functions: a {B}ayesian treatment.
\newblock In \emph{Advances in Neural Information Processing Systems 10}, 1998.

\bibitem[Dai et~al.(2015)Dai, Damianou, Gonz{\'a}lez, and
  Lawrence]{dai2015variational}
Dai, Zhenwen, Damianou, Andreas, Gonz{\'a}lez, Javier, and Lawrence, Neil.
\newblock Variational auto-encoded deep {Gaussian} processes.
\newblock \emph{arXiv preprint arXiv:1511.06455}, 2015.

\bibitem[Damianou(2015)]{andreasthesis}
Damianou, Andreas.
\newblock \emph{Deep {Gaussian} processes and variational propagation of
  uncertainty}.
\newblock PhD thesis, University of Sheffield, 2015.

\bibitem[Damianou \& Lawrence(2013)Damianou and
  Lawrence]{damianou-lawrence:2013a}
Damianou, Andreas~C and Lawrence, Neil~D.
\newblock Deep {G}aussian processes.
\newblock In \emph{16th International Conference on Artificial Intelligence and
  Statistics}, pp.\  207--215, 2013.

\bibitem[Deisenroth \& Mohamed(2012)Deisenroth and Mohamed]{deisenroth2012ep}
Deisenroth, Marc and Mohamed, Shakir.
\newblock Expectation propagation in {G}aussian process dynamical systems.
\newblock In \emph{Advances in Neural Information Processing Systems 25}, pp.\
  2609--2617, 2012.

\bibitem[Dem{\v{s}}ar(2006)]{demvsar2006statistical}
Dem{\v{s}}ar, Janez.
\newblock Statistical comparisons of classifiers over multiple data sets.
\newblock \emph{The Journal of Machine Learning Research}, 7:\penalty0 1--30,
  2006.

\bibitem[Duvenaud et~al.(2014)Duvenaud, Rippel, Adams, and
  Ghahramani]{DuvRipAdaGha14}
Duvenaud, David, Rippel, Oren, Adams, Ryan~P., and Ghahramani, Zoubin.
\newblock Avoiding pathologies in very deep networks.
\newblock In \emph{17th International Conference on Artificial Intelligence and
  Statistics}, 2014.

\bibitem[Gal \& Ghahramani(2015)Gal and Ghahramani]{yarin+zoubin:2015}
Gal, Yarin and Ghahramani, Zoubin.
\newblock Dropout as a {B}ayesian approximation: Representing model uncertainty
  in deep learning.
\newblock \emph{arXiv preprint arXiv:1506.02142}, 2015.

\bibitem[Girard et~al.(2003)Girard, Rasmussen, Qui{\~n}onero-Candela, and
  Murray-Smith]{GirRasQuiMur03}
Girard, Agathe, Rasmussen, Carl~Edward, Qui{\~n}onero-Candela, Joaquin, and
  Murray-Smith, Roderick.
\newblock Gaussian process priors with uncertain inputs --- application to
  multiple-step ahead time series forecasting.
\newblock In \emph{Advances in Neural Information Processing Systems 15}, pp.\
  529--536, 2003.

\bibitem[Graves(2011)]{graves2011practical}
Graves, Alex.
\newblock Practical variational inference for neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems 25}, pp.\
  2348--2356, 2011.

\bibitem[Hachmann et~al.(2011)Hachmann, Olivares-Amaya, Atahan-Evrenk,
  Amador-Bedolla, S{\'a}nchez-Carrera, Gold-Parker, Vogt, Brockway, and
  Aspuru-Guzik]{hachmann2011harvard}
Hachmann, Johannes, Olivares-Amaya, Roberto, Atahan-Evrenk, Sule,
  Amador-Bedolla, Carlos, S{\'a}nchez-Carrera, Roel~S, Gold-Parker, Aryeh,
  Vogt, Leslie, Brockway, Anna~M, and Aspuru-Guzik, Al{\'a}n.
\newblock The {H}arvard clean energy project: large-scale computational
  screening and design of organic photovoltaics on the world community grid.
\newblock \emph{The Journal of Physical Chemistry Letters}, 2\penalty0
  (17):\penalty0 2241--2251, 2011.

\bibitem[Hensman \& Lawrence(2014)Hensman and Lawrence]{hensman+lawrence:2014}
Hensman, James and Lawrence, Neil~D.
\newblock Nested variational compression in deep {G}aussian processes.
\newblock \emph{arXiv preprint arXiv:1412.1370}, 2014.

\bibitem[Hern{\'a}ndez-Lobato \& Adams(2015)Hern{\'a}ndez-Lobato and
  Adams]{hernandez+adams:2015}
Hern{\'a}ndez-Lobato, Jos{\'e}~Miguel and Adams, Ryan~P.
\newblock Probabilistic backpropagation for scalable learning of {B}ayesian
  neural networks.
\newblock In \emph{32nd International Conference on Machine Learning}, 2015.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{kingma+ba:2015}
Kingma, D.~P. and Ba, J.
\newblock Adam: a method for stochastic optimization.
\newblock In \emph{3rd International Conference on Learning Representations},
  2015.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{kingma+welling:2014}
Kingma, Diederik~P. and Welling, Max.
\newblock Stochastic gradient {VB} and the variational auto-encoder.
\newblock In \emph{The International Conference on Learning Representations},
  2014.

\bibitem[Lawrence \& Moore(2007)Lawrence and Moore]{lawrence+moore:2007}
Lawrence, Neil~D. and Moore, Andrew~J.
\newblock Hierarchical {G}aussian process latent variable models.
\newblock In \emph{24th International Conference on Machine Learning}, ICML
  '07, pp.\  481--488, New York, NY, USA, 2007.

\bibitem[L{\'a}zaro-Gredilla(2012)]{lazaro2012bayesian}
L{\'a}zaro-Gredilla, Miguel.
\newblock Bayesian warped {G}aussian processes.
\newblock In \emph{Advances in Neural Information Processing Systems 25}, pp.\
  1619--1627, 2012.

\bibitem[Li et~al.(2015)Li, Hern{\'{a}}ndez-Lobato, and Turner]{li+etal:2015}
Li, Yingzhen, Hern{\'{a}}ndez-Lobato, Jos{\'{e}}~Miguel, and Turner, Richard~E.
\newblock Stochastic expectation propagation.
\newblock In \emph{Advances in Neural Information Processing Systems 29}, 2015.

\bibitem[Minka(2001)]{minka2001ep}
Minka, Thomas~P.
\newblock \emph{A family of algorithms for approximate {B}ayesian inference}.
\newblock PhD thesis, Massachusetts Institute of Technology, 2001.

\bibitem[Neal(1993)]{neal1993bayesian}
Neal, Radford~M.
\newblock Bayesian learning via stochastic dynamics.
\newblock In \emph{Advances in Neural Information Processing Systems 6}, pp.\
  475--482, 1993.

\bibitem[Neal(1995)]{neal1995bayesian}
Neal, Radford~M.
\newblock \emph{Bayesian learning for neural networks}.
\newblock PhD thesis, University of Toronto, 1995.

\bibitem[Pyzer-Knapp et~al.(2015)Pyzer-Knapp, Li, and
  Aspuru-Guzik]{pyzer2015learning}
Pyzer-Knapp, Edward~O, Li, Kewei, and Aspuru-Guzik, Alan.
\newblock Learning from the {H}arvard clean energy project: The use of neural
  networks to accelerate materials discovery.
\newblock \emph{Advanced Functional Materials}, 25\penalty0 (41):\penalty0
  6495--6502, 2015.

\bibitem[Qui{\~n}onero-Candela \& Rasmussen(2005)Qui{\~n}onero-Candela and
  Rasmussen]{quinonero+rasmussen:2005}
Qui{\~n}onero-Candela, Joaquin and Rasmussen, Carl~Edward.
\newblock A unifying view of sparse approximate {G}aussian process regression.
\newblock \emph{The Journal of Machine Learning Research}, 6:\penalty0
  1939--1959, 2005.

\bibitem[Rasmussen \& Williams(2005)Rasmussen and Williams]{rasmussen2005gpml}
Rasmussen, Carl~Edward and Williams, Christopher K.~I.
\newblock \emph{{G}aussian Processes for Machine Learning (Adaptive Computation
  and Machine Learning)}.
\newblock The MIT Press, 2005.

\bibitem[Seeger(2007)]{seeger2005ep}
Seeger, Matthias.
\newblock Expectation propagation for exponential families.
\newblock Technical report, Department of EECS, University of California at
  Berkeley, 2007.

\bibitem[Snelson \& Ghahramani(2006)Snelson and
  Ghahramani]{snelson+ghahramani:2006}
Snelson, Edward and Ghahramani, Zoubin.
\newblock Sparse {G}aussian processes using pseudo-inputs.
\newblock In \emph{Advances in Neural Information Processing Systems 19}, pp.\
  1257--1264, 2006.

\bibitem[Snelson et~al.(2004)Snelson, Rasmussen, and Ghahramani]{SneRasGha04}
Snelson, Edward, Rasmussen, Carl~Edward, and Ghahramani, Zoubin.
\newblock Warped {G}aussian processes.
\newblock In \emph{Advances in Neural Information Processing Systems 17}, pp.\
  337--344, Cambridge, MA, USA, 2004.

\bibitem[Sutton \& Barto(1998)Sutton and Barto]{Sutton:1998}
Sutton, Richard~S. and Barto, Andrew~G.
\newblock \emph{Introduction to Reinforcement Learning}.
\newblock MIT Press, Cambridge, MA, USA, 1st edition, 1998.
\newblock ISBN 0262193981.

\bibitem[Titsias(2009)]{titsias2009variational}
Titsias, Michalis~K.
\newblock Variational learning of inducing variables in sparse {G}aussian
  processes.
\newblock In \emph{12th International Conference on Artificial Intelligence and
  Statistics}, pp.\  567--574, 2009.

\bibitem[Titsias \& Lawrence(2010)Titsias and Lawrence]{titsias2010bayesian}
Titsias, Michalis~K and Lawrence, Neil~D.
\newblock Bayesian {G}aussian process latent variable model.
\newblock In \emph{13th International Conference on Artificial Intelligence and
  Statistics}, pp.\  844--851, 2010.

\bibitem[Turner \& Sahani(2011)Turner and Sahani]{turner-and-sahani:2011a}
Turner, R.~E. and Sahani, M.
\newblock Two problems with variational expectation maximisation for
  time-series models.
\newblock In Barber, D., Cemgil, T., and Chiappa, S. (eds.), \emph{Bayesian
  Time series models}, chapter~5, pp.\  109--130. Cambridge University Press,
  2011.

\bibitem[Vanhatalo \& Vehtari(2006)Vanhatalo and Vehtari]{vanhatalo2006mcmc}
Vanhatalo, Jarno and Vehtari, Aki.
\newblock {MCMC} methods for {MLP}-network and {G}aussian process and stuff--a
  documentation for {M}atlab toolbox {MCMCstuff}.
\newblock 2006.
\newblock Laboratory of computational engineering, Helsinki university of
  technology.

\bibitem[Welling \& Teh(2011)Welling and Teh]{welling2011bayesian}
Welling, Max and Teh, Yee~W.
\newblock Bayesian learning via stochastic gradient {L}angevin dynamics.
\newblock In \emph{28th International Conference on Machine Learning}, pp.\
  681--688, 2011.

\bibitem[Wilson \& Adams(2013)Wilson and Adams]{wilson+adams:2013}
Wilson, Andrew and Adams, Ryan.
\newblock Gaussian process kernels for pattern discovery and extrapolation.
\newblock In \emph{30th International Conference on Machine Learning}, pp.\
  1067--1075, 2013.

\end{thebibliography}
