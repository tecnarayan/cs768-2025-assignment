\begin{thebibliography}{65}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achiam et~al.(2023)Achiam, Adler, Agarwal, Ahmad, Akkaya, Aleman,
  Almeida, Altenschmidt, Altman, Anadkat, et~al.]{gpt4}
J.~Achiam, S.~Adler, S.~Agarwal, L.~Ahmad, I.~Akkaya, F.~L. Aleman, D.~Almeida,
  J.~Altenschmidt, S.~Altman, S.~Anadkat, et~al.
\newblock Gpt-4 technical report.
\newblock \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem[Agostinelli et~al.(2023)Agostinelli, Denk, Borsos, Engel, Verzetti,
  Caillon, Huang, Jansen, Roberts, Tagliasacchi, Sharifi, Zeghidour, and
  Frank]{musiclm}
A.~Agostinelli, T.~I. Denk, Z.~Borsos, J.~Engel, M.~Verzetti, A.~Caillon,
  Q.~Huang, A.~Jansen, A.~Roberts, M.~Tagliasacchi, M.~Sharifi, N.~Zeghidour,
  and C.~Frank.
\newblock Musiclm: Generating music from text, 2023.

\bibitem[Bai et~al.(2022)Bai, Jones, Ndousse, Askell, Chen, DasSarma, Drain,
  Fort, Ganguli, Henighan, et~al.]{bai2022training}
Y.~Bai, A.~Jones, K.~Ndousse, A.~Askell, A.~Chen, N.~DasSarma, D.~Drain,
  S.~Fort, D.~Ganguli, T.~Henighan, et~al.
\newblock Training a helpful and harmless assistant with reinforcement learning
  from human feedback.
\newblock \emph{arXiv preprint arXiv:2204.05862}, 2022.

\bibitem[Borsos et~al.(2023{\natexlab{a}})Borsos, Marinier, Vincent,
  Kharitonov, Pietquin, Sharifi, Roblek, Teboul, Grangier, Tagliasacchi,
  et~al.]{audiolm}
Z.~Borsos, R.~Marinier, D.~Vincent, E.~Kharitonov, O.~Pietquin, M.~Sharifi,
  D.~Roblek, O.~Teboul, D.~Grangier, M.~Tagliasacchi, et~al.
\newblock Audiolm: a language modeling approach to audio generation.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 2023{\natexlab{a}}.

\bibitem[Borsos et~al.(2023{\natexlab{b}})Borsos, Sharifi, Vincent, Kharitonov,
  Zeghidour, and Tagliasacchi]{soundstorm}
Z.~Borsos, M.~Sharifi, D.~Vincent, E.~Kharitonov, N.~Zeghidour, and
  M.~Tagliasacchi.
\newblock Soundstorm: Efficient parallel audio generation, 2023{\natexlab{b}}.

\bibitem[Bradley and Terry(1952)]{bradley1952rank}
R.~A. Bradley and M.~E. Terry.
\newblock Rank analysis of incomplete block designs: I. the method of paired
  comparisons.
\newblock \emph{Biometrika}, 39, 1952.

\bibitem[Christiano et~al.(2017)Christiano, Leike, Brown, Martic, Legg, and
  Amodei]{christiano2017deep}
P.~F. Christiano, J.~Leike, T.~Brown, M.~Martic, S.~Legg, and D.~Amodei.
\newblock Deep reinforcement learning from human preferences.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Chung et~al.(2021)Chung, Zhang, Han, Chiu, Qin, Pang, and
  Wu]{wav2vec-bert}
Y.~Chung, Y.~Zhang, W.~Han, C.~Chiu, J.~Qin, R.~Pang, and Y.~Wu.
\newblock W2v-bert: Combining contrastive learning and masked language modeling
  for self-supervised speech pre-training.
\newblock \emph{arXiv:2108.06209}, 2021.

\bibitem[Copet et~al.(2023)Copet, Kreuk, Gat, Remez, Kant, Synnaeve, Adi, and
  Défossez]{musicgen}
J.~Copet, F.~Kreuk, I.~Gat, T.~Remez, D.~Kant, G.~Synnaeve, Y.~Adi, and
  A.~Défossez.
\newblock Simple and controllable music generation, 2023.

\bibitem[Coste et~al.(2023)Coste, Anwar, Kirk, and Krueger]{coste2023reward}
T.~Coste, U.~Anwar, R.~Kirk, and D.~Krueger.
\newblock Reward model ensembles help mitigate overoptimization.
\newblock \emph{arXiv preprint}, 2023.

\bibitem[D{\'{e}}fossez et~al.(2018)D{\'{e}}fossez, Zeghidour, Usunier, Bottou,
  and Bach]{sing}
A.~D{\'{e}}fossez, N.~Zeghidour, N.~Usunier, L.~Bottou, and F.~R. Bach.
\newblock {SING:} symbol-to-instrument neural generator.
\newblock In S.~Bengio, H.~M. Wallach, H.~Larochelle, K.~Grauman,
  N.~Cesa{-}Bianchi, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems 31: Annual Conference on Neural Information
  Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montr{\'{e}}al,
  Canada}, pages 9055--9065, 2018.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2018/hash/56dc0997d871e9177069bb472574eb29-Abstract.html}.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova]{devlin-etal-2019-bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In J.~Burstein, C.~Doran, and T.~Solorio, editors, \emph{Proceedings
  of the 2019 Conference of the North {A}merican Chapter of the Association for
  Computational Linguistics: Human Language Technologies, Volume 1 (Long and
  Short Papers)}, pages 4171--4186, Minneapolis, Minnesota, June 2019.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N19-1423}.
\newblock URL \url{https://aclanthology.org/N19-1423}.

\bibitem[Dhariwal et~al.(2020)Dhariwal, Jun, Payne, Kim, Radford, and
  Sutskever]{jukebox}
P.~Dhariwal, H.~Jun, C.~Payne, J.~W. Kim, A.~Radford, and I.~Sutskever.
\newblock Jukebox: A generative model for music.
\newblock \emph{arXiv:2005.00341}, 2020.

\bibitem[Défossez et~al.(2022)Défossez, Copet, Synnaeve, and
  Adi]{defossez2022highfi}
A.~Défossez, J.~Copet, G.~Synnaeve, and Y.~Adi.
\newblock High fidelity neural audio compression.
\newblock \emph{arXiv:2210.13438}, 2022.

\bibitem[Elizalde et~al.(2022)Elizalde, Deshmukh, Ismail, and
  Wang]{elizalde2022clap}
B.~Elizalde, S.~Deshmukh, M.~A. Ismail, and H.~Wang.
\newblock Clap: Learning audio concepts from natural language supervision,
  2022.

\bibitem[Engel et~al.(2017)Engel, Resnick, Roberts, Dieleman, Norouzi, Eck, and
  Simonyan]{nsynth}
J.~H. Engel, C.~Resnick, A.~Roberts, S.~Dieleman, M.~Norouzi, D.~Eck, and
  K.~Simonyan.
\newblock Neural audio synthesis of musical notes with wavenet autoencoders.
\newblock In D.~Precup and Y.~W. Teh, editors, \emph{Proceedings of the 34th
  International Conference on Machine Learning, {ICML} 2017, Sydney, NSW,
  Australia, 6-11 August 2017}, volume~70 of \emph{Proceedings of Machine
  Learning Research}, pages 1068--1077. {PMLR}, 2017.
\newblock URL \url{http://proceedings.mlr.press/v70/engel17a.html}.

\bibitem[Engel et~al.(2020)Engel, Hantrakul, Gu, and Roberts]{engel2020ddsp}
J.~H. Engel, L.~Hantrakul, C.~Gu, and A.~Roberts.
\newblock {DDSP:} differentiable digital signal processing.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020.

\bibitem[Forsgren and Martiros(2022)]{riffusion}
S.~Forsgren and H.~Martiros.
\newblock {Riffusion - Stable diffusion for real-time music generation}, 2022.
\newblock URL \url{https://riffusion.com/about}.

\bibitem[Garcia et~al.(2023)Garcia, Seetharaman, Kumar, and Pardo]{vampnet}
H.~F. Garcia, P.~Seetharaman, R.~Kumar, and B.~Pardo.
\newblock Vampnet: Music generation via masked acoustic token modeling, 2023.

\bibitem[Gauldin(1988)]{gauldin1988practical}
R.~Gauldin.
\newblock \emph{A practical approach to eighteenth-century counterpoint}.
\newblock Prentice-Hall, 1988.

\bibitem[Gemini~Team(2023)]{gemini2023}
G.~Gemini~Team.
\newblock Gemini: A family of highly capable multimodal models.
\newblock 2023.

\bibitem[Guimaraes et~al.(2017)Guimaraes, Sanchez-Lengeling, Outeiral, Farias,
  and Aspuru-Guzik]{guimaraes2017objective}
G.~L. Guimaraes, B.~Sanchez-Lengeling, C.~Outeiral, P.~L.~C. Farias, and
  A.~Aspuru-Guzik.
\newblock Objective-reinforced generative adversarial networks (organ) for
  sequence generation models.
\newblock \emph{arXiv preprint arXiv:1705.10843}, 2017.

\bibitem[Hawthorne et~al.(2022)Hawthorne, Jaegle, Cangea, Borgeaud, Nash,
  Malinowski, Dieleman, Vinyals, Botvinick, Simon, Sheahan, Zeghidour, Alayrac,
  Carreira, and Engel]{perceiverAR}
C.~Hawthorne, A.~Jaegle, C.~Cangea, S.~Borgeaud, C.~Nash, M.~Malinowski,
  S.~Dieleman, O.~Vinyals, M.~M. Botvinick, I.~Simon, H.~Sheahan, N.~Zeghidour,
  J.~Alayrac, J.~Carreira, and J.~H. Engel.
\newblock General-purpose, long-context autoregressive modeling with perceiver
  {AR}.
\newblock In K.~Chaudhuri, S.~Jegelka, L.~Song, C.~Szepesv{\'{a}}ri, G.~Niu,
  and S.~Sabato, editors, \emph{International Conference on Machine Learning
  (ICML)}, 2022.

\bibitem[Huang et~al.(2022)Huang, Jansen, Lee, Ganti, Li, and Ellis]{mulan}
Q.~Huang, A.~Jansen, J.~Lee, R.~Ganti, J.~Y. Li, and D.~P.~W. Ellis.
\newblock Mulan: A joint embedding of music audio and natural language.
\newblock In \emph{International Society for Music Information Retrieval
  Conference (ISMIR)}, 2022.

\bibitem[Huang et~al.(2023)Huang, Park, Wang, Denk, Ly, Chen, Zhang, Zhang, Yu,
  Frank, et~al.]{Noise2music}
Q.~Huang, D.~S. Park, T.~Wang, T.~I. Denk, A.~Ly, N.~Chen, Z.~Zhang, Z.~Zhang,
  J.~Yu, C.~Frank, et~al.
\newblock Noise2music: Text-conditioned music generation with diffusion models.
\newblock \emph{arXiv preprint arXiv:2302.03917}, 2023.

\bibitem[Jaques et~al.(2017)Jaques, Gu, Bahdanau, Hern{\'a}ndez-Lobato, Turner,
  and Eck]{jaques2017sequence}
N.~Jaques, S.~Gu, D.~Bahdanau, J.~M. Hern{\'a}ndez-Lobato, R.~E. Turner, and
  D.~Eck.
\newblock Sequence tutor: Conservative fine-tuning of sequence generation
  models with kl-control.
\newblock In \emph{International Conference on Machine Learning}, pages
  1645--1654. PMLR, 2017.

\bibitem[Jaques et~al.(2019)Jaques, Ghandeharioun, Shen, Ferguson, Lapedriza,
  Jones, Gu, and Picard]{jaquesrlhf}
N.~Jaques, A.~Ghandeharioun, J.~H. Shen, C.~Ferguson, A.~Lapedriza, N.~Jones,
  S.~Gu, and R.~Picard.
\newblock Way off-policy batch deep reinforcement learning of implicit human
  preferences in dialog.
\newblock \emph{arXiv preprint arXiv:1907.00456}, 2019.

\bibitem[Jiang et~al.(2020)Jiang, Jin, Duan, and Zhang]{rlduet}
N.~Jiang, S.~Jin, Z.~Duan, and C.~Zhang.
\newblock Rl-duet: Online music accompaniment generation using deep
  reinforcement learning.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, volume~34, pages 710--718, 2020.

\bibitem[Karbasi et~al.(2021)Karbasi, Haug, Kvalsund, Krzyzaniak, and
  T{\o}rresen]{squiggles}
S.~M. Karbasi, H.~S. Haug, M.-K. Kvalsund, M.~J. Krzyzaniak, and
  J.~T{\o}rresen.
\newblock A generative model for creating musical rhythms with deep
  reinforcement learning.
\newblock 2nd Conference on AI Music Creativity, 2021.

\bibitem[Kharitonov et~al.(2023)Kharitonov, Vincent, Borsos, Marinier, Girgin,
  Pietquin, Sharifi, Tagliasacchi, and Zeghidour]{spear}
E.~Kharitonov, D.~Vincent, Z.~Borsos, R.~Marinier, S.~Girgin, O.~Pietquin,
  M.~Sharifi, M.~Tagliasacchi, and N.~Zeghidour.
\newblock Speak, read and prompt: High-fidelity text-to-speech with minimal
  supervision.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  11:\penalty0 1703--1718, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:256627687}.

\bibitem[Kilgour et~al.(2019)Kilgour, Zuluaga, Roblek, and Sharifi]{fad}
K.~Kilgour, M.~Zuluaga, D.~Roblek, and M.~Sharifi.
\newblock Fr{\'e}chet audio distance: A reference-free metric for evaluating
  music enhancement algorithms.
\newblock In \emph{INTERSPEECH}, 2019.

\bibitem[Kotecha(2018)]{kotecha2018bach2bach}
N.~Kotecha.
\newblock Bach2bach: generating music using a deep reinforcement learning
  approach.
\newblock \emph{arXiv preprint arXiv:1812.01060}, 2018.

\bibitem[Kreuk et~al.(2022)Kreuk, Synnaeve, Polyak, Singer, Défossez, Copet,
  Parikh, Taigman, and Adi]{audiogen}
F.~Kreuk, G.~Synnaeve, A.~Polyak, U.~Singer, A.~Défossez, J.~Copet, D.~Parikh,
  Y.~Taigman, and Y.~Adi.
\newblock Audiogen: Textually guided audio generation, 2022.

\bibitem[Latif et~al.(2023)Latif, Cuay{\'a}huitl, Pervez, Shamshad, Ali, and
  Cambria]{latif2023survey}
S.~Latif, H.~Cuay{\'a}huitl, F.~Pervez, F.~Shamshad, H.~S. Ali, and E.~Cambria.
\newblock A survey on deep reinforcement learning for audio-based applications.
\newblock \emph{Artificial Intelligence Review}, 56\penalty0 (3):\penalty0
  2193--2240, 2023.

\bibitem[Lee et~al.(2022)Lee, Kim, Kim, Cho, and Han]{rq-transformer}
D.~Lee, C.~Kim, S.~Kim, M.~Cho, and W.-S. Han.
\newblock Autoregressive image generation using residual quantization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 11523--11532, 2022.

\bibitem[Lee et~al.(2023)Lee, Liu, Ryu, Watkins, Du, Boutilier, Abbeel,
  Ghavamzadeh, and Gu]{imagerlhf}
K.~Lee, H.~Liu, M.~Ryu, O.~Watkins, Y.~Du, C.~Boutilier, P.~Abbeel,
  M.~Ghavamzadeh, and S.~S. Gu.
\newblock Aligning text-to-image models using human feedback.
\newblock \emph{arXiv preprint arXiv:2302.12192}, 2023.

\bibitem[Lewkowicz(2001)]{conceptvalidity}
D.~J. Lewkowicz.
\newblock The concept of ecological validity: What are its limitations and is
  it bad to be invalid?
\newblock \emph{Infancy}, 2\penalty0 (4):\penalty0 437--450, 2001.

\bibitem[Liu et~al.(2023)Liu, Chen, Yuan, Mei, Liu, Mandic, Wang, and
  Plumbley]{audioldm}
H.~Liu, Z.~Chen, Y.~Yuan, X.~Mei, X.~Liu, D.~P. Mandic, W.~Wang, and M.~D.
  Plumbley.
\newblock Audioldm: Text-to-audio generation with latent diffusion models.
\newblock In A.~Krause, E.~Brunskill, K.~Cho, B.~Engelhardt, S.~Sabato, and
  J.~Scarlett, editors, \emph{International Conference on Machine Learning,
  {ICML} 2023, 23-29 July 2023, Honolulu, Hawaii, {USA}}, volume 202 of
  \emph{Proceedings of Machine Learning Research}, pages 21450--21474. {PMLR},
  2023.
\newblock URL \url{https://proceedings.mlr.press/v202/liu23f.html}.

\bibitem[OpenAI(2023)]{openai2023gpt4}
OpenAI.
\newblock Gpt-4 technical report.
\newblock 2023.

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin,
  Zhang, Agarwal, Slama, Ray, et~al.]{ouyang2022training}
L.~Ouyang, J.~Wu, X.~Jiang, D.~Almeida, C.~Wainwright, P.~Mishkin, C.~Zhang,
  S.~Agarwal, K.~Slama, A.~Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 27730--27744, 2022.

\bibitem[Parker et~al.(2024)Parker, Spijkervet, Kosta, Yesiler, Kuznetsov,
  Wang, Avent, Chen, and Le]{parker2024stemgen}
J.~D. Parker, J.~Spijkervet, K.~Kosta, F.~Yesiler, B.~Kuznetsov, J.-C. Wang,
  M.~Avent, J.~Chen, and D.~Le.
\newblock Stemgen: A music generation model that listens, 2024.

\bibitem[Rafailov et~al.(2023)Rafailov, Sharma, Mitchell, Ermon, Manning, and
  Finn]{dpo}
R.~Rafailov, A.~Sharma, E.~Mitchell, S.~Ermon, C.~D. Manning, and C.~Finn.
\newblock Direct preference optimization: Your language model is secretly a
  reward model.
\newblock \emph{arXiv preprint arXiv:2305.18290}, 2023.

\bibitem[Ramé et~al.(2024)Ramé, Vieillard, Hussenot, Dadashi, Cideron,
  Bachem, and Ferret]{rame2024warm}
A.~Ramé, N.~Vieillard, L.~Hussenot, R.~Dadashi, G.~Cideron, O.~Bachem, and
  J.~Ferret.
\newblock Warm: On the benefits of weight averaged reward models, 2024.

\bibitem[Ranzato et~al.(2016)Ranzato, Chopra, Auli, and
  Zaremba]{ranzato_sequence_level}
M.~Ranzato, S.~Chopra, M.~Auli, and W.~Zaremba.
\newblock Sequence level training with recurrent neural networks.
\newblock In Y.~Bengio and Y.~LeCun, editors, \emph{4th International
  Conference on Learning Representations, {ICLR} 2016, San Juan, Puerto Rico,
  May 2-4, 2016, Conference Track Proceedings}, 2016.
\newblock URL \url{http://arxiv.org/abs/1511.06732}.

\bibitem[Rey and Neuh{\"{a}}user(2011)]{DBLP:reference/stat/ReyN11}
D.~Rey and M.~Neuh{\"{a}}user.
\newblock Wilcoxon-signed-rank test.
\newblock In M.~Lovric, editor, \emph{International Encyclopedia of Statistical
  Science}, pages 1658--1659. Springer, 2011.
\newblock \doi{10.1007/978-3-642-04898-2\_616}.
\newblock URL \url{https://doi.org/10.1007/978-3-642-04898-2\_616}.

\bibitem[Roit et~al.(2023)Roit, Ferret, Shani, Aharoni, Cideron, Dadashi,
  Geist, Girgin, Hussenot, Keller, Momchev, Garea, Stanczyk, Vieillard, Bachem,
  Elidan, Hassidim, Pietquin, and Szpektor]{ferret_summarization}
P.~Roit, J.~Ferret, L.~Shani, R.~Aharoni, G.~Cideron, R.~Dadashi, M.~Geist,
  S.~Girgin, L.~Hussenot, O.~Keller, N.~Momchev, S.~R. Garea, P.~Stanczyk,
  N.~Vieillard, O.~Bachem, G.~Elidan, A.~Hassidim, O.~Pietquin, and
  I.~Szpektor.
\newblock Factually consistent summarization via reinforcement learning with
  textual entailment feedback.
\newblock In A.~Rogers, J.~L. Boyd{-}Graber, and N.~Okazaki, editors,
  \emph{Proceedings of the 61st Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers), {ACL} 2023, Toronto,
  Canada, July 9-14, 2023}, pages 6252--6272. Association for Computational
  Linguistics, 2023.
\newblock \doi{10.18653/V1/2023.ACL-LONG.344}.
\newblock URL \url{https://doi.org/10.18653/v1/2023.acl-long.344}.

\bibitem[Schneider et~al.(2023)Schneider, Kamal, Jin, and
  Schölkopf]{schneider2023mousai}
F.~Schneider, O.~Kamal, Z.~Jin, and B.~Schölkopf.
\newblock Mo\^usai: Text-to-music generation with long-context latent
  diffusion, 2023.

\bibitem[Stiennon et~al.(2020)Stiennon, Ouyang, Wu, Ziegler, Lowe, Voss,
  Radford, Amodei, and Christiano]{stiennon2020learning}
N.~Stiennon, L.~Ouyang, J.~Wu, D.~Ziegler, R.~Lowe, C.~Voss, A.~Radford,
  D.~Amodei, and P.~F. Christiano.
\newblock Learning to summarize with human feedback.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 3008--3021, 2020.

\bibitem[Sutton and Barto(2018)]{sutton2018reinforcement}
R.~S. Sutton and A.~G. Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Team et~al.(2023)Team, Anil, Borgeaud, Wu, Alayrac, Yu, Soricut,
  Schalkwyk, Dai, Hauth, et~al.]{team2023gemini}
G.~Team, R.~Anil, S.~Borgeaud, Y.~Wu, J.-B. Alayrac, J.~Yu, R.~Soricut,
  J.~Schalkwyk, A.~M. Dai, A.~Hauth, et~al.
\newblock Gemini: a family of highly capable multimodal models.
\newblock \emph{arXiv preprint arXiv:2312.11805}, 2023.

\bibitem[Tervaniemi(2023)]{musicvalidity}
M.~Tervaniemi.
\newblock The neuroscience of music--towards ecological validity.
\newblock \emph{Trends in Neurosciences}, 2023.

\bibitem[Thomas and Kellogg(1989)]{ecologicalgap}
J.~C. Thomas and W.~A. Kellogg.
\newblock Minimizing ecological gaps in interface design.
\newblock \emph{IEEE Software}, 6\penalty0 (1):\penalty0 78--86, 1989.

\bibitem[Thoppilan et~al.(2022)Thoppilan, De~Freitas, Hall, Shazeer,
  Kulshreshtha, Cheng, Jin, Bos, Baker, Du, et~al.]{thoppilan2022lamda}
R.~Thoppilan, D.~De~Freitas, J.~Hall, N.~Shazeer, A.~Kulshreshtha, H.-T. Cheng,
  A.~Jin, T.~Bos, L.~Baker, Y.~Du, et~al.
\newblock Lamda: Language models for dialog applications.
\newblock \emph{arXiv preprint arXiv:2201.08239}, 2022.

\bibitem[Trehub et~al.(2015)Trehub, Becker, and Morley]{crosscultural}
S.~E. Trehub, J.~Becker, and I.~Morley.
\newblock Cross-cultural perspectives on music and musicality.
\newblock \emph{Philosophical Transactions of the Royal Society B: Biological
  Sciences}, 370\penalty0 (1664):\penalty0 20140096, 2015.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  {\L}.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems (NeurIPS)},
  2017.

\bibitem[Wallace et~al.(2023)Wallace, Dang, Rafailov, Zhou, Lou, Purushwalkam,
  Ermon, Xiong, Joty, and Naik]{wallace2023diffusion}
B.~Wallace, M.~Dang, R.~Rafailov, L.~Zhou, A.~Lou, S.~Purushwalkam, S.~Ermon,
  C.~Xiong, S.~Joty, and N.~Naik.
\newblock Diffusion model alignment using direct preference optimization.
\newblock \emph{arXiv preprint arXiv:2311.12908}, 2023.

\bibitem[Wang et~al.(2023)Wang, Chen, Wu, Zhang, Zhou, Liu, Chen, Liu, Wang,
  Li, He, Zhao, and Wei]{vall-e}
C.~Wang, S.~Chen, Y.~Wu, Z.~Zhang, L.~Zhou, S.~Liu, Z.~Chen, Y.~Liu, H.~Wang,
  J.~Li, L.~He, S.~Zhao, and F.~Wei.
\newblock Neural codec language models are zero-shot text to speech
  synthesizers.
\newblock \emph{CoRR}, abs/2301.02111, 2023.
\newblock \doi{10.48550/ARXIV.2301.02111}.
\newblock URL \url{https://doi.org/10.48550/arXiv.2301.02111}.

\bibitem[Williams(1992)]{pg}
R.~J. Williams.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 229--256, 1992.

\bibitem[Wu and Hu(2018)]{summarization_rl}
Y.~Wu and B.~Hu.
\newblock Learning to extract coherent summary via deep reinforcement learning.
\newblock In S.~A. McIlraith and K.~Q. Weinberger, editors, \emph{Proceedings
  of the Thirty-Second {AAAI} Conference on Artificial Intelligence, (AAAI-18),
  the 30th innovative Applications of Artificial Intelligence (IAAI-18), and
  the 8th {AAAI} Symposium on Educational Advances in Artificial Intelligence
  (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018}, pages
  5602--5609. {AAAI} Press, 2018.
\newblock \doi{10.1609/AAAI.V32I1.11987}.
\newblock URL \url{https://doi.org/10.1609/aaai.v32i1.11987}.

\bibitem[Wu et~al.(2016)Wu, Schuster, Chen, Le, Norouzi, Macherey, Krikun, Cao,
  Gao, Macherey, Klingner, Shah, Johnson, Liu, Kaiser, Gouws, Kato, Kudo,
  Kazawa, Stevens, Kurian, Patil, Wang, Young, Smith, Riesa, Rudnick, Vinyals,
  Corrado, Hughes, and Dean]{google_translate}
Y.~Wu, M.~Schuster, Z.~Chen, Q.~V. Le, M.~Norouzi, W.~Macherey, M.~Krikun,
  Y.~Cao, Q.~Gao, K.~Macherey, J.~Klingner, A.~Shah, M.~Johnson, X.~Liu,
  L.~Kaiser, S.~Gouws, Y.~Kato, T.~Kudo, H.~Kazawa, K.~Stevens, G.~Kurian,
  N.~Patil, W.~Wang, C.~Young, J.~Smith, J.~Riesa, A.~Rudnick, O.~Vinyals,
  G.~Corrado, M.~Hughes, and J.~Dean.
\newblock Google's neural machine translation system: Bridging the gap between
  human and machine translation.
\newblock \emph{CoRR}, abs/1609.08144, 2016.
\newblock URL \url{http://arxiv.org/abs/1609.08144}.

\bibitem[Yang et~al.(2022)Yang, Yu, Wang, Wang, Weng, Zou, and
  Yu]{yang2022diffsound}
D.~Yang, J.~Yu, H.~Wang, W.~Wang, C.~Weng, Y.~Zou, and D.~Yu.
\newblock Diffsound: Discrete diffusion model for text-to-sound generation.
\newblock \emph{arXiv:2207.09983}, 2022.

\bibitem[Yang et~al.(2023)Yang, Tian, Tan, Huang, Liu, Chang, Shi, Zhao, Bian,
  Wu, Zhao, Watanabe, and Meng]{yang2023uniaudio}
D.~Yang, J.~Tian, X.~Tan, R.~Huang, S.~Liu, X.~Chang, J.~Shi, S.~Zhao, J.~Bian,
  X.~Wu, Z.~Zhao, S.~Watanabe, and H.~Meng.
\newblock Uniaudio: An audio foundation model toward universal audio
  generation, 2023.

\bibitem[Yu et~al.(2023)Yu, Simig, Flaherty, Aghajanyan, Zettlemoyer, and
  Lewis]{yu2023megabyte}
L.~Yu, D.~Simig, C.~Flaherty, A.~Aghajanyan, L.~Zettlemoyer, and M.~Lewis.
\newblock Megabyte: Predicting million-byte sequences with multiscale
  transformers.
\newblock \emph{arXiv preprint arXiv:2305.07185}, 2023.

\bibitem[Zeghidour et~al.(2022)Zeghidour, Luebs, Omran, Skoglund, and
  Tagliasacchi]{soundstream}
N.~Zeghidour, A.~Luebs, A.~Omran, J.~Skoglund, and M.~Tagliasacchi.
\newblock Soundstream: An end-to-end neural audio codec.
\newblock \emph{{IEEE} {ACM} Trans. Audio Speech Lang. Process.}, 30, 2022.

\bibitem[Ziegler et~al.(2019)Ziegler, Stiennon, Wu, Brown, Radford, Amodei,
  Christiano, and Irving]{ziegler2019fine}
D.~M. Ziegler, N.~Stiennon, J.~Wu, T.~B. Brown, A.~Radford, D.~Amodei,
  P.~Christiano, and G.~Irving.
\newblock Fine-tuning language models from human preferences.
\newblock \emph{arXiv preprint arXiv:1909.08593}, 2019.

\end{thebibliography}
