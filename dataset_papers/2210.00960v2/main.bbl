\begin{thebibliography}{}

\bibitem[Allen-Zhu et~al., 2019]{allen2019convergence}
Allen-Zhu, Z., Li, Y., and Song, Z. (2019).
\newblock A convergence theory for deep learning via over-parameterization.
\newblock In {\em International Conference on Machine Learning}, pages
  242--252. PMLR.

\bibitem[Athalye et~al., 2018]{athalye2018obfuscated}
Athalye, A., Carlini, N., and Wagner, D. (2018).
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock {\em arXiv preprint arXiv:1802.00420}.

\bibitem[Attias et~al., 2021]{attias2021improved}
Attias, I., Kontorovich, A., and Mansour, Y. (2021).
\newblock Improved generalization bounds for adversarially robust learning.

\bibitem[Awasthi et~al., 2020]{awasthi2020adversarial}
Awasthi, P., Frank, N., and Mohri, M. (2020).
\newblock Adversarial learning guarantees for linear hypotheses and neural
  networks.
\newblock In {\em International Conference on Machine Learning}, pages
  431--441. PMLR.

\bibitem[Bartlett and Mendelson, 2002]{bartlett2002rademacher}
Bartlett, P.~L. and Mendelson, S. (2002).
\newblock Rademacher and gaussian complexities: Risk bounds and structural
  results.
\newblock {\em Journal of Machine Learning Research}, 3(Nov):463--482.

\bibitem[Bassily et~al., 2020]{bassily2020stability}
Bassily, R., Feldman, V., Guzm{\'a}n, C., and Talwar, K. (2020).
\newblock Stability of stochastic gradient descent on nonsmooth convex losses.
\newblock {\em arXiv preprint arXiv:2006.06914}.

\bibitem[Bousquet and Elisseeff, 2002]{bousquet2002stability}
Bousquet, O. and Elisseeff, A. (2002).
\newblock Stability and generalization.
\newblock {\em The Journal of Machine Learning Research}, 2:499--526.

\bibitem[Carlini and Wagner, 2017]{carlini2017towards}
Carlini, N. and Wagner, D. (2017).
\newblock Towards evaluating the robustness of neural networks.
\newblock In {\em 2017 ieee symposium on security and privacy (sp)}, pages
  39--57. IEEE.

\bibitem[Carmon et~al., 2019]{carmon2019unlabeled}
Carmon, Y., Raghunathan, A., Schmidt, L., Duchi, J.~C., and Liang, P.~S.
  (2019).
\newblock Unlabeled data improves adversarial robustness.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  11190--11201.

\bibitem[Chen et~al., 2017]{chen2017zoo}
Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., and Hsieh, C.-J. (2017).
\newblock Zoo: Zeroth order optimization based black-box attacks to deep neural
  networks without training substitute models.
\newblock In {\em Proceedings of the 10th ACM Workshop on Artificial
  Intelligence and Security}, pages 15--26.

\bibitem[Chen et~al., 2018]{chen2018stability}
Chen, Y., Jin, C., and Yu, B. (2018).
\newblock Stability and convergence trade-off of iterative optimization
  algorithms.
\newblock {\em arXiv preprint arXiv:1804.01619}.

\bibitem[Dan et~al., 2020]{dan2020sharp}
Dan, C., Wei, Y., and Ravikumar, P. (2020).
\newblock Sharp statistical guaratees for adversarially robust gaussian
  classification.
\newblock In {\em International Conference on Machine Learning}, pages
  2345--2355. PMLR.

\bibitem[Deng et~al., 2009]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L. (2009).
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee.

\bibitem[Du et~al., 2019]{du2019gradient}
Du, S., Lee, J., Li, H., Wang, L., and Zhai, X. (2019).
\newblock Gradient descent finds global minima of deep neural networks.
\newblock In {\em International Conference on Machine Learning}, pages
  1675--1685. PMLR.

\bibitem[Fan et~al., 2020]{fan2020sparse}
Fan, Y., Wu, B., Li, T., Zhang, Y., Li, M., Li, Z., and Yang, Y. (2020).
\newblock Sparse adversarial attack via perturbation factorization.
\newblock In {\em European conference on computer vision}, pages 35--50.
  Springer.

\bibitem[Farnia and Ozdaglar, 2021]{farnia2021train}
Farnia, F. and Ozdaglar, A. (2021).
\newblock Train simultaneously, generalize better: Stability of gradient-based
  minimax learners.
\newblock In {\em International Conference on Machine Learning}, pages
  3174--3185. PMLR.

\bibitem[Feldman and Vondrak, 2018]{feldman2018generalization}
Feldman, V. and Vondrak, J. (2018).
\newblock Generalization bounds for uniformly stable algorithms.
\newblock {\em arXiv preprint arXiv:1812.09859}.

\bibitem[Feldman and Vondrak, 2019]{feldman2019high}
Feldman, V. and Vondrak, J. (2019).
\newblock High probability generalization bounds for uniformly stable
  algorithms with nearly optimal rate.
\newblock In {\em Conference on Learning Theory}, pages 1270--1279. PMLR.

\bibitem[Goodfellow et~al., 2014]{goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C. (2014).
\newblock Explaining and harnessing adversarial examples.
\newblock {\em arXiv preprint arXiv:1412.6572}.

\bibitem[Gowal et~al., 2020]{gowal2020uncovering}
Gowal, S., Qin, C., Uesato, J., Mann, T., and Kohli, P. (2020).
\newblock Uncovering the limits of adversarial training against norm-bounded
  adversarial examples.
\newblock {\em arXiv preprint arXiv:2010.03593}.

\bibitem[Hardt et~al., 2016]{hardt2016train}
Hardt, M., Recht, B., and Singer, Y. (2016).
\newblock Train faster, generalize better: Stability of stochastic gradient
  descent.
\newblock In {\em International Conference on Machine Learning}, pages
  1225--1234. PMLR.

\bibitem[He et~al., 2016]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J. (2016).
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778.

\bibitem[Hochreiter and Schmidhuber, 1997]{hochreiter1997long}
Hochreiter, S. and Schmidhuber, J. (1997).
\newblock Long short-term memory.
\newblock {\em Neural computation}, 9(8):1735--1780.

\bibitem[Huang et~al., 2022]{huang2022fast}
Huang, Z., Fan, Y., Liu, C., Zhang, W., Zhang, Y., Salzmann, M., S{\"u}sstrunk,
  S., and Wang, J. (2022).
\newblock Fast adversarial training with adaptive step size.
\newblock {\em arXiv preprint arXiv:2206.02417}.

\bibitem[Hwang et~al., 2021]{hwang2021adversarial}
Hwang, J.-W., Lee, Y., Oh, S., and Bae, Y. (2021).
\newblock Adversarial training with stochastic weight average.
\newblock In {\em 2021 IEEE International Conference on Image Processing
  (ICIP)}, pages 814--818. IEEE.

\bibitem[Izmailov et~al., 2018]{izmailov2018averaging}
Izmailov, P., Podoprikhin, D., Garipov, T., Vetrov, D., and Wilson, A.~G.
  (2018).
\newblock Averaging weights leads to wider optima and better generalization.
\newblock {\em arXiv preprint arXiv:1803.05407}.

\bibitem[Javanmard et~al., 2020]{javanmard2020precise}
Javanmard, A., Soltanolkotabi, M., and Hassani, H. (2020).
\newblock Precise tradeoffs in adversarial training for linear regression.
\newblock In {\em Conference on Learning Theory}, pages 2034--2078. PMLR.

\bibitem[Khim and Loh, 2018]{khim2018adversarial}
Khim, J. and Loh, P.-L. (2018).
\newblock Adversarial risk bounds via function transformation.
\newblock {\em arXiv preprint arXiv:1810.09519}.

\bibitem[Krizhevsky et~al., 2009]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al. (2009).
\newblock Learning multiple layers of features from tiny images.

\bibitem[Krizhevsky et~al., 2012]{krizhevsky2012imagenet}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E. (2012).
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em Advances in neural information processing systems}, pages
  1097--1105.

\bibitem[Li et~al., 2022]{li2022semi}
Li, Y., Wu, B., Feng, Y., Fan, Y., Jiang, Y., Li, Z., and Xia, S.-T. (2022).
\newblock Semi-supervised robust training with generalized perturbed
  neighborhood.
\newblock {\em Pattern Recognition}, 124:108472.

\bibitem[Liu et~al., 2020]{liu2020loss}
Liu, C., Salzmann, M., Lin, T., Tomioka, R., and S{\"u}sstrunk, S. (2020).
\newblock On the loss landscape of adversarial training: Identifying challenges
  and how to overcome them.
\newblock {\em arXiv preprint arXiv:2006.08403}.

\bibitem[Madry et~al., 2017]{madry2017towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A. (2017).
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock {\em arXiv preprint arXiv:1706.06083}.

\bibitem[Montasser et~al., 2019]{montasser2019vc}
Montasser, O., Hanneke, S., and Srebro, N. (2019).
\newblock Vc classes are adversarially robustly learnable, but only improperly.
\newblock In {\em Conference on Learning Theory}, pages 2512--2530. PMLR.

\bibitem[Nemirovski et~al., 2009]{nemirovski2009robust}
Nemirovski, A., Juditsky, A., Lan, G., and Shapiro, A. (2009).
\newblock Robust stochastic approximation approach to stochastic programming.
\newblock {\em SIAM Journal on optimization}, 19(4):1574--1609.

\bibitem[Netzer et~al., 2011]{netzer2011reading}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y. (2011).
\newblock Reading digits in natural images with unsupervised feature learning.

\bibitem[Ozdaglar et~al., 2022]{ozdaglar2022good}
Ozdaglar, A., Pattathil, S., Zhang, J., and Zhang, K. (2022).
\newblock What is a good metric to study generalization of minimax learners?
\newblock {\em arXiv preprint arXiv:2206.04502}.

\bibitem[Qin et~al., 2022]{qin2022boosting}
Qin, Z., Fan, Y., Liu, Y., Zhang, Y., Wang, J., and Wu, B. (2022).
\newblock Boosting the transferability of adversarial attacks with reverse
  adversarial perturbation.

\bibitem[Qin et~al., 2021]{qin2021random}
Qin, Z., Fan, Y., Zha, H., and Wu, B. (2021).
\newblock Random noise defense against query-based black-box attacks.
\newblock {\em Advances in Neural Information Processing Systems},
  34:7650--7663.

\bibitem[Raghunathan et~al., 2019]{raghunathan2019adversarial}
Raghunathan, A., Xie, S.~M., Yang, F., Duchi, J.~C., and Liang, P. (2019).
\newblock Adversarial training can hurt generalization.
\newblock {\em arXiv preprint arXiv:1906.06032}.

\bibitem[Rebuffi et~al., 2021]{rebuffi2021fixing}
Rebuffi, S.-A., Gowal, S., Calian, D.~A., Stimberg, F., Wiles, O., and Mann, T.
  (2021).
\newblock Fixing data augmentation to improve adversarial robustness.
\newblock {\em arXiv preprint arXiv:2103.01946}.

\bibitem[Rice et~al., 2020]{rice2020overfitting}
Rice, L., Wong, E., and Kolter, Z. (2020).
\newblock Overfitting in adversarially robust deep learning.
\newblock In {\em International Conference on Machine Learning}, pages
  8093--8104. PMLR.

\bibitem[Rogers and Wagner, 1978]{rogers1978finite}
Rogers, W.~H. and Wagner, T.~J. (1978).
\newblock A finite sample distribution-free performance bound for local
  discrimination rules.
\newblock {\em The Annals of Statistics}, pages 506--514.

\bibitem[Schmidt et~al., 2018]{schmidt2018adversarially}
Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., and Madry, A. (2018).
\newblock Adversarially robust generalization requires more data.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  5014--5026.

\bibitem[Sinha et~al., 2017]{sinha2017certifiable}
Sinha, A., Namkoong, H., and Duchi, J. (2017).
\newblock Certifiable distributional robustness with principled adversarial
  training.
\newblock {\em arXiv preprint arXiv:1710.10571}, 2.

\bibitem[Szegedy et~al., 2013]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R. (2013).
\newblock Intriguing properties of neural networks.
\newblock {\em arXiv preprint arXiv:1312.6199}.

\bibitem[Taheri et~al., 2020]{taheri2020asymptotic}
Taheri, H., Pedarsani, R., and Thrampoulidis, C. (2020).
\newblock Asymptotic behavior of adversarial training in binary classification.
\newblock {\em arXiv preprint arXiv:2010.13275}.

\bibitem[Tramer et~al., 2020]{tramer2020adaptive}
Tramer, F., Carlini, N., Brendel, W., and Madry, A. (2020).
\newblock On adaptive attacks to adversarial example defenses.
\newblock {\em arXiv preprint arXiv:2002.08347}.

\bibitem[Vapnik and Chervonenkis, 2015]{vapnik2015uniform}
Vapnik, V.~N. and Chervonenkis, A.~Y. (2015).
\newblock On the uniform convergence of relative frequencies of events to their
  probabilities.
\newblock In {\em Measures of complexity}, pages 11--30. Springer.

\bibitem[Wang et~al., 2019]{wang2019convergence}
Wang, Y., Ma, X., Bailey, J., Yi, J., Zhou, B., and Gu, Q. (2019).
\newblock On the convergence and robustness of adversarial training.
\newblock In {\em ICML}, volume~1, page~2.

\bibitem[Wong et~al., 2020]{wong2020fast}
Wong, E., Rice, L., and Kolter, J.~Z. (2020).
\newblock Fast is better than free: Revisiting adversarial training.
\newblock {\em arXiv preprint arXiv:2001.03994}.

\bibitem[Wu et~al., 2020]{wu2020adversarial}
Wu, D., Xia, S.-T., and Wang, Y. (2020).
\newblock Adversarial weight perturbation helps robust generalization.
\newblock {\em arXiv preprint arXiv:2004.05884}.

\bibitem[Xiao et~al., 2022a]{xiao2022adversarial}
Xiao, J., Fan, Y., Sun, R., and Luo, Z.-Q. (2022a).
\newblock Adversarial rademacher complexity of deep neural networks.

\bibitem[Xiao et~al., 2022b]{xiao2022adaptive}
Xiao, J., Qin, Z., Fan, Y., Wu, B., Wang, J., and Luo, Z.-Q. (2022b).
\newblock Adaptive smoothness-weighted adversarial training for multiple
  perturbations with its stability analysis.
\newblock {\em arXiv preprint arXiv:2210.00557}.

\bibitem[Xiao et~al., 2022c]{xiao2022understanding}
Xiao, J., Yang, L., Fan, Y., Wang, J., and Luo, Z.-Q. (2022c).
\newblock Understanding adversarial robustness against on-manifold adversarial
  examples.
\newblock {\em arXiv preprint arXiv:2210.00430}.

\bibitem[Xing et~al., 2021a]{xing2021on}
Xing, Y., Song, Q., and Cheng, G. (2021a).
\newblock On the algorithmic stability of adversarial training.
\newblock In {\em Thirty-Fifth Conference on Neural Information Processing
  Systems}.

\bibitem[Xing et~al., 2021b]{xing2021generalization}
Xing, Y., Song, Q., and Cheng, G. (2021b).
\newblock On the generalization properties of adversarial training.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 505--513. PMLR.

\bibitem[Xing et~al., 2021c]{xing2021adversarially}
Xing, Y., Zhang, R., and Cheng, G. (2021c).
\newblock Adversarially robust estimate and risk analysis in linear regression.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 514--522. PMLR.

\bibitem[Yin et~al., 2019]{yin2019rademacher}
Yin, D., Kannan, R., and Bartlett, P. (2019).
\newblock Rademacher complexity for adversarially robust generalization.
\newblock In {\em International Conference on Machine Learning}, pages
  7085--7094. PMLR.

\bibitem[Zhai et~al., 2019]{zhai2019adversarially}
Zhai, R., Cai, T., He, D., Dan, C., He, K., Hopcroft, J., and Wang, L. (2019).
\newblock Adversarially robust generalization just requires more unlabeled
  data.
\newblock {\em arXiv preprint arXiv:1906.00555}.

\bibitem[Zhang et~al., 2021]{zhang2021understanding}
Zhang, C., Bengio, S., Hardt, M., Recht, B., and Vinyals, O. (2021).
\newblock Understanding deep learning (still) requires rethinking
  generalization.
\newblock {\em Communications of the ACM}, 64(3):107--115.

\bibitem[Zhang et~al., 2020]{zhang2020single}
Zhang, J., Xiao, P., Sun, R., and Luo, Z. (2020).
\newblock A single-loop smoothed gradient descent-ascent algorithm for
  nonconvex-concave min-max problems.
\newblock {\em Advances in Neural Information Processing Systems},
  33:7377--7389.

\end{thebibliography}
