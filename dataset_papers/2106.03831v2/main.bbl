\begin{thebibliography}{10}

\bibitem{jo2017measuring}
Jo, J., Y.~Bengio.
\newblock Measuring the tendency of cnns to learn surface statistical
  regularities, 2017.

\bibitem{Beery_2018_ECCV}
Beery, S., G.~Van~Horn, P.~Perona.
\newblock Recognition in terra incognita.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}. 2018.

\bibitem{poliak-etal-2018-hypothesis}
Poliak, A., J.~Naradowsky, A.~Haldar, et~al.
\newblock Hypothesis only baselines in natural language inference.
\newblock In \emph{Proceedings of the Seventh Joint Conference on Lexical and
  Computational Semantics}, pages 180--191. Association for Computational
  Linguistics, New Orleans, Louisiana, 2018.

\bibitem{objectHallucination}
Rohrbach, A., L.~A. Hendricks, K.~Burns, et~al.
\newblock Object hallucination in image captioning.
\newblock In \emph{Empirical Methods in Natural Language Processing (EMNLP)}.
  2018.

\bibitem{geirhos2019imagenettrained}
Geirhos, R., P.~Rubisch, C.~Michaelis, et~al.
\newblock Imagenet-trained cnns are biased towards texture; increasing shape
  bias improves accuracy and robustness, 2019.

\bibitem{ijcai2020-124}
Zhang, Y., H.~Tan, M.~Bansal.
\newblock Diagnosing the environment bias in vision-and-language navigation.
\newblock In C.~Bessiere, ed., \emph{Proceedings of the Twenty-Ninth
  International Joint Conference on Artificial Intelligence, {IJCAI} 2020},
  pages 890--897. ijcai.org, 2020.

\bibitem{kaushik-lipton-2018-much}
Kaushik, D., Z.~C. Lipton.
\newblock How much reading does reading comprehension require? a critical
  investigation of popular benchmarks.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pages 5010--5015. Association for Computational
  Linguistics, Brussels, Belgium, 2018.

\bibitem{quinonero2009dataset}
Qui{\~n}onero-Candela, J., M.~Sugiyama, N.~D. Lawrence, et~al.
\newblock \emph{Dataset shift in machine learning}.
\newblock Mit Press, 2009.

\bibitem{szegedy2014intriguing}
Szegedy, C., W.~Zaremba, I.~Sutskever, et~al.
\newblock Intriguing properties of neural networks, 2014.

\bibitem{Ovadia2019CanYT}
Ovadia, Y., E.~Fertig, J.~Ren, et~al.
\newblock Can you trust your model's uncertainty? evaluating predictive
  uncertainty under dataset shift.
\newblock In \emph{NeurIPS}. 2019.

\bibitem{pmlr-v119-filos20a}
Filos, A., P.~Tigkas, R.~Mcallister, et~al.
\newblock Can autonomous vehicles identify, recover from, and adapt to
  distribution shifts?
\newblock In H.~D. III, A.~Singh, eds., \emph{Proceedings of the 37th
  International Conference on Machine Learning}, vol. 119 of \emph{Proceedings
  of Machine Learning Research}, pages 3145--3153. PMLR, 2020.

\bibitem{arjovsky2020invariant}
Arjovsky, M., L.~Bottou, I.~Gulrajani, et~al.
\newblock Invariant risk minimization, 2020.

\bibitem{Peters2015CausalIU}
Peters, J., P.~Buhlmann, N.~Meinshausen.
\newblock Causal inference using invariant prediction: identification and
  confidence intervals.
\newblock \emph{arXiv: Methodology}, 2015.

\bibitem{chang2020invariant}
Chang, S., Y.~Zhang, M.~Yu, et~al.
\newblock Invariant rationalization.
\newblock In \emph{International Conference on Machine Learning}, pages
  1448--1458. PMLR, 2020.

\bibitem{kaushik2020learning}
Kaushik, D., E.~Hovy, Z.~C. Lipton.
\newblock Learning the difference that makes a difference with counterfactually
  augmented data.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2020.

\bibitem{lu2018gender}
Lu, K., P.~Mardziel, F.~Wu, et~al.
\newblock Gender bias in neural natural language processing.
\newblock \emph{arXiv preprint arXiv:1807.11714}, 2018.

\bibitem{zmigrod-etal-2019-counterfactual}
Zmigrod, R., S.~J. Mielke, H.~Wallach, et~al.
\newblock Counterfactual data augmentation for mitigating gender stereotypes in
  languages with rich morphology.
\newblock In \emph{Association for Computational Linguistics (ACL)}. 2019.

\bibitem{maudslay2019s}
Maudslay, R.~H., H.~Gonen, R.~Cotterell, et~al.
\newblock It's all in the name: Mitigating gender bias with name-based
  counterfactual data substitution.
\newblock \emph{arXiv preprint arXiv:1909.00871}, 2019.

\bibitem{pitis2020counterfactual}
Pitis, S., E.~Creager, A.~Garg.
\newblock Counterfactual data augmentation using locally factored dynamics.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem{greenland1999causal}
Greenland, S., J.~Pearl, J.~M. Robins.
\newblock Causal diagrams for epidemiologic research.
\newblock \emph{Epidemiology}, pages 37--48, 1999.

\bibitem{shpitser16identification}
Shpitser, I., J.~Pearl.
\newblock Identification of conditional interventional distributions.
\newblock In \emph{Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence}, UAI'06, page 437–444. AUAI Press, Arlington,
  Virginia, USA, 2006.

\bibitem{shalit2017estimating}
Shalit, U., F.~D. Johansson, D.~Sontag.
\newblock Estimating individual treatment effect: generalization bounds and
  algorithms.
\newblock In \emph{International Conference on Machine Learning}, pages
  3076--3085. PMLR, 2017.

\bibitem{bowman2015large}
Bowman, S.~R., G.~Angeli, C.~Potts, et~al.
\newblock A large annotated corpus for learning natural language inference.
\newblock \emph{arXiv preprint arXiv:1508.05326}, 2015.

\bibitem{N18-1101}
Williams, A., N.~Nangia, S.~Bowman.
\newblock A broad-coverage challenge corpus for sentence understanding through
  inference.
\newblock In \emph{Proceedings of the 2018 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}, pages 1112--1122. Association for
  Computational Linguistics, 2018.

\bibitem{paws2019naacl}
Zhang, Y., J.~Baldridge, L.~He.
\newblock {PAWS: Paraphrase Adversaries from Word Scrambling}.
\newblock In \emph{Proc. of NAACL}. 2019.

\bibitem{lan2018toolkit}
Lan, W., W.~Xu.
\newblock Neural network models for paraphrase identification, semantic textual
  similarity, natural language inference, and question answering.
\newblock In \emph{Proceedings of COLING 2018}. 2018.

\bibitem{suhr-etal-2017-corpus}
Suhr, A., M.~Lewis, J.~Yeh, et~al.
\newblock A corpus of natural language for visual reasoning.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association
  for Computational Linguistics (Volume 2: Short Papers)}, pages 217--223.
  Association for Computational Linguistics, Vancouver, Canada, 2017.

\bibitem{gatys2016neural}
Gatys, L., A.~Ecker, M.~Bethge.
\newblock A neural algorithm of artistic style.
\newblock \emph{Journal of Vision}, 16(12):326--326, 2016.

\bibitem{madaan2020politeness}
Madaan, A., A.~Setlur, T.~Parekh, et~al.
\newblock Politeness transfer: A tag and generate approach.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 1869--1881. 2020.

\bibitem{mirza2014conditional}
Mirza, M., S.~Osindero.
\newblock Conditional generative adversarial nets.
\newblock \emph{arXiv preprint arXiv:1411.1784}, 2014.

\bibitem{DBLP:conf/icml/HuYLSX17}
Hu, Z., Z.~Yang, X.~Liang, et~al.
\newblock Toward controlled generation of text.
\newblock In \emph{ICML}, pages 1587--1596. 2017.

\bibitem{khalifa2021a}
Khalifa, M., H.~Elsahar, M.~Dymetman.
\newblock A distributional approach to controlled text generation.
\newblock In \emph{International Conference on Learning Representations}. 2021.

\bibitem{chen2021human}
Chen, L., Z.~Jiang, J.~Xiao, et~al.
\newblock Human-like controllable image captioning with verb-specific semantic
  roles.
\newblock \emph{arXiv preprint arXiv:2103.12204}, 2021.

\bibitem{deng2020length}
Deng, C., N.~Ding, M.~Tan, et~al.
\newblock Length-controllable image captioning.
\newblock \emph{arXiv preprint arXiv:2007.09580}, 2020.

\bibitem{you2016image}
You, Q., H.~Jin, Z.~Wang, et~al.
\newblock Image captioning with semantic attention.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 4651--4659. 2016.

\bibitem{peters2016}
Peters, J., P.~Bühlmann, N.~Meinshausen.
\newblock Causal inference by using invariant prediction: identification and
  confidence intervals.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 78(5):947--1012, 2016.

\bibitem{ghassami2017learning}
Ghassami, A., S.~Salehkaleybar, N.~Kiyavash, et~al.
\newblock Learning causal structures using regression invariance.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}. 2017.

\bibitem{srivastava2020robustness}
Srivastava, M., T.~Hashimoto, P.~Liang.
\newblock Robustness to spurious correlations via human annotations.
\newblock \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem{kaushik2021learning}
Kaushik, D., A.~Setlur, E.~Hovy, et~al.
\newblock Explaining the efficacy of counterfactually augmented data.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2021.

\bibitem{teney2020learning}
Teney, D., E.~Abbasnedjad, A.~v.~d. Hengel.
\newblock Learning what makes a difference from counterfactual examples and
  gradient supervision.
\newblock \emph{arXiv preprint arXiv:2004.09034}, 2020.

\bibitem{liang-etal-2020-learning}
Liang, Z., W.~Jiang, H.~Hu, et~al.
\newblock Learning to contrast the counterfactual samples for robust visual
  question answering.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 3285--3292. Association for
  Computational Linguistics, Online, 2020.

\bibitem{hassanpour2019learning}
Hassanpour, N., R.~Greiner.
\newblock Learning disentangled representations for counterfactual regression.
\newblock In \emph{International Conference on Learning Representations}. 2019.

\bibitem{pryzant2020causal}
Pryzant, R., D.~Card, D.~Jurafsky, et~al.
\newblock Causal effects of linguistic properties.
\newblock \emph{arXiv preprint arXiv:2010.12919}, 2020.

\bibitem{pearl2009causality}
Pearl, J.
\newblock \emph{Causality}.
\newblock Cambridge university press, 2009.

\bibitem{NIPS2017_b2eeb736}
Li, S., Y.~Fu.
\newblock Matching on balanced nonlinear representations for treatment effects
  estimation.
\newblock In I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, R.~Garnett, eds., \emph{Advances in Neural Information
  Processing Systems}, vol.~30. Curran Associates, Inc., 2017.

\bibitem{johansson2016learning}
Johansson, F., U.~Shalit, D.~Sontag.
\newblock Learning representations for counterfactual inference.
\newblock In \emph{International conference on machine learning}, pages
  3020--3029. PMLR, 2016.

\bibitem{alaa2017bayesian}
Alaa, A.~M., M.~van~der Schaar.
\newblock Bayesian inference of individualized treatment effects using
  multi-task gaussian processes.
\newblock In \emph{Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, pages 3427--3435. 2017.

\bibitem{yoon2018ganite}
Yoon, J., J.~Jordon, M.~Van Der~Schaar.
\newblock Ganite: Estimation of individualized treatment effects using
  generative adversarial nets.
\newblock In \emph{International Conference on Learning Representations}. 2018.

\bibitem{NEURIPS2018_a50abba8}
Yao, L., S.~Li, Y.~Li, et~al.
\newblock Representation learning for treatment effect estimation from
  observational data.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  R.~Garnett, eds., \emph{Advances in Neural Information Processing Systems},
  vol.~31. Curran Associates, Inc., 2018.

\bibitem{pmlr-v37-rezende15}
Rezende, D., S.~Mohamed.
\newblock Variational inference with normalizing flows.
\newblock In F.~Bach, D.~Blei, eds., \emph{Proceedings of the 32nd
  International Conference on Machine Learning}, vol.~37 of \emph{Proceedings
  of Machine Learning Research}, pages 1530--1538. PMLR, Lille, France, 2015.

\bibitem{tran2019discrete}
Tran, D., K.~Vafa, K.~Agrawal, et~al.
\newblock Discrete flows: Invertible generative models of discrete data.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:14719--14728, 2019.

\bibitem{muller1997integral}
M{\"u}ller, A.
\newblock Integral probability metrics and their generating classes of
  functions.
\newblock \emph{Advances in Applied Probability}, pages 429--443, 1997.

\bibitem{villani2008optimal}
Villani, C.
\newblock \emph{Optimal transport: old and new}, vol. 338.
\newblock Springer Science \& Business Media, 2008.

\bibitem{sriperumbudur2012empirical}
Sriperumbudur, B.~K., K.~Fukumizu, A.~Gretton, et~al.
\newblock On the empirical estimation of integral probability metrics.
\newblock \emph{Electronic Journal of Statistics}, 6:1550--1599, 2012.

\bibitem{cuturi2014fast}
Cuturi, M., A.~Doucet.
\newblock Fast computation of wasserstein barycenters.
\newblock In \emph{International conference on machine learning}, pages
  685--693. PMLR, 2014.

\bibitem{jang2016categorical}
Jang, E., S.~Gu, B.~Poole.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock \emph{arXiv preprint arXiv:1611.01144}, 2016.

\bibitem{vaswani2017attention}
Vaswani, A., N.~Shazeer, N.~Parmar, et~al.
\newblock Attention is all you need.
\newblock \emph{arXiv preprint arXiv:1706.03762}, 2017.

\bibitem{devlin2018bert}
Devlin, J., M.-W. Chang, K.~Lee, et~al.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{tan2019lxmert}
Tan, H., M.~Bansal.
\newblock Lxmert: Learning cross-modality encoder representations from
  transformers.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pages 5103--5114. 2019.

\bibitem{liu2019roberta}
Liu, Y., M.~Ott, N.~Goyal, et~al.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{arXiv preprint arXiv:1907.11692}, 2019.

\bibitem{williams2017broad}
Williams, A., N.~Nangia, S.~R. Bowman.
\newblock A broad-coverage challenge corpus for sentence understanding through
  inference.
\newblock \emph{arXiv preprint arXiv:1704.05426}, 2017.

\bibitem{nie-etal-2020-adversarial}
Nie, Y., A.~Williams, E.~Dinan, et~al.
\newblock Adversarial {NLI}: A new benchmark for natural language
  understanding.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}. Association for Computational Linguistics,
  2020.

\bibitem{lewis-etal-2020-bart}
Lewis, M., Y.~Liu, N.~Goyal, et~al.
\newblock {BART}: Denoising sequence-to-sequence pre-training for natural
  language generation, translation, and comprehension.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 7871--7880. Association for
  Computational Linguistics, Online, 2020.

\bibitem{wolf-etal-2020-transformers}
Wolf, T., L.~Debut, V.~Sanh, et~al.
\newblock Transformers: State-of-the-art natural language processing.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing: System Demonstrations}, pages 38--45.
  Association for Computational Linguistics, Online, 2020.

\bibitem{rohrbach2018object}
Rohrbach, A., L.~A. Hendricks, K.~Burns, et~al.
\newblock Object hallucination in image captioning.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pages 4035--4045. 2018.

\bibitem{chen2015microsoft}
Chen, X., H.~Fang, T.-Y. Lin, et~al.
\newblock Microsoft coco captions: Data collection and evaluation server.
\newblock \emph{arXiv preprint arXiv:1504.00325}, 2015.

\bibitem{karpathy2015deep}
Karpathy, A., L.~Fei-Fei.
\newblock Deep visual-semantic alignments for generating image descriptions.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 3128--3137. 2015.

\bibitem{luo2018discriminability}
Luo, R., B.~Price, S.~Cohen, et~al.
\newblock Discriminability objective for training descriptive captions.
\newblock \emph{arXiv preprint arXiv:1803.04376}, 2018.

\bibitem{papineni2002bleu}
Papineni, K., S.~Roukos, T.~Ward, et~al.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock In \emph{Proceedings of the 40th annual meeting of the Association
  for Computational Linguistics}, pages 311--318. 2002.

\bibitem{banerjee2005meteor}
Banerjee, S., A.~Lavie.
\newblock Meteor: An automatic metric for mt evaluation with improved
  correlation with human judgments.
\newblock In \emph{Proceedings of the acl workshop on intrinsic and extrinsic
  evaluation measures for machine translation and/or summarization}, pages
  65--72. 2005.

\bibitem{vedantam2015cider}
Vedantam, R., C.~Lawrence~Zitnick, D.~Parikh.
\newblock Cider: Consensus-based image description evaluation.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 4566--4575. 2015.

\bibitem{anderson2016spice}
Anderson, P., B.~Fernando, M.~Johnson, et~al.
\newblock Spice: Semantic propositional image caption evaluation.
\newblock In \emph{European conference on computer vision}, pages 382--398.
  Springer, 2016.

\bibitem{kingma2013auto}
Kingma, D.~P., M.~Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem{williams1992simple}
Williams, R.~J.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock \emph{Machine learning}, 8(3-4):229--256, 1992.

\end{thebibliography}
