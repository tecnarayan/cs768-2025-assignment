\begin{thebibliography}{11}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bierkens et~al.(2019)Bierkens, Fearnhead, and Roberts]{Bierkens2019}
J.~Bierkens, P.~Fearnhead, and G.~Roberts.
\newblock {The zig-zag process and super-efficient sampling for Bayesian
  analysis of big data}.
\newblock \emph{The Annals of Statistics}, 47\penalty0 (3):\penalty0
  1288--1320, 2019.

\bibitem[Bierkens et~al.(2020)Bierkens, Grazzi, Kamatani, and
  Roberts]{bierkens2020boomerang}
J.~Bierkens, S.~Grazzi, K.~Kamatani, and G.~Roberts.
\newblock The boomerang sampler.
\newblock In \emph{International Conference on Machine Learning}, pages
  908--918. PMLR, 2020.

\bibitem[Bierkens et~al.(2021)Bierkens, Grazzi, van~der Meulen, and
  Schauer]{bierkens2021sticky}
J.~Bierkens, S.~Grazzi, F.~van~der Meulen, and M.~Schauer.
\newblock Sticky {PDMP} samplers for sparse and local inference problems.
\newblock \emph{arXiv.2103.08478}, 2021.

\bibitem[Bouchard-C{\^{o}}t{\'{e}} et~al.(2018)Bouchard-C{\^{o}}t{\'{e}},
  Vollmer, and Doucet]{Bouchard-Cote2018}
A.~Bouchard-C{\^{o}}t{\'{e}}, S.~J. Vollmer, and A.~Doucet.
\newblock {The bouncy particle sampler: A nonreversible rejection-free Markov
  chain Monte Carlo method}.
\newblock \emph{Journal of the American Statistical Association}, 113\penalty0
  (522):\penalty0 855--867, 2018.

\bibitem[Chevallier et~al.(2020)Chevallier, Fearnhead, and
  Sutton]{chevallier2020reversible}
A.~Chevallier, P.~Fearnhead, and M.~Sutton.
\newblock Reversible jump {PDMP} samplers for variable selection.
\newblock \emph{arXiv:2010.11771}, 2020.

\bibitem[Chevallier et~al.(2021)Chevallier, Power, Wang, and
  Fearnhead]{chevallier2021pdmp}
A.~Chevallier, S.~Power, A.~Q. Wang, and P.~Fearnhead.
\newblock {PDMP Monte Carlo methods for piecewise-smooth densities}.
\newblock \emph{arXiv:2111.05859}, 2021.

\bibitem[Gelman and Meng(1998)]{Gelman1998}
A.~Gelman and X.-L. Meng.
\newblock Simulating normalizing constants: From importance sampling to bridge
  sampling to path sampling.
\newblock \emph{Statistical science: a review journal of the Institute of
  Mathematical Statistics}, 13\penalty0 (2):\penalty0 163--185, 1998.

\bibitem[Graham and Storkey(2017)]{Graham2017}
M.~M. Graham and A.~J. Storkey.
\newblock Continuously tempered {H}amiltonian {M}onte {C}arlo.
\newblock In \emph{Proceedings of the Thirty-Third Conference on Uncertainty in
  Artificial Intelligence (UAI)}, 2017.

\bibitem[Nemeth et~al.(2019)Nemeth, Lindsten, Filippone, and
  Hensman]{Nemeth2019}
C.~Nemeth, F.~Lindsten, M.~Filippone, and J.~Hensman.
\newblock Pseudo-extended {M}arkov chain {M}onte {C}arlo.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Pagani et~al.(2020)Pagani, Chevallier, Power, House, and
  Cotter]{cotter2020nuzz}
F.~Pagani, A.~Chevallier, S.~Power, T.~House, and S.~Cotter.
\newblock {NuZZ: numerical Zig-Zag sampling for general models}, 2020.
\newblock \url{https://arxiv.org/abs/2003.03636}.

\bibitem[Sutton and Fearnhead(2021)]{sutton2021concave}
M.~Sutton and P.~Fearnhead.
\newblock {Concave-Convex PDMP-based sampling}.
\newblock \emph{arXiv:2112.12897}, 2021.

\end{thebibliography}
