\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Angwin et~al.(2016)Angwin, Larson, Mattu, and
  Kirchner]{angwin-propublica-risk-scores}
J.~Angwin, J.~Larson, S.~Mattu, and L.~Kirchner.
\newblock Machine bias: There's software used across the country to predict
  future criminals. {And} it's biased against blacks.
\newblock \emph{ProPublica}, 2016.
\newblock
  https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.

\bibitem[Barocas and Selbst(2016)]{barocas2016big}
S.~Barocas and A.~D. Selbst.
\newblock Big data's disparate impact.
\newblock \emph{California Law Review}, 104, 2016.

\bibitem[Berk(2016)]{berk2016primer}
R.~Berk.
\newblock A primer on fairness in criminal justice risk assessments.
\newblock \emph{Criminology}, 41\penalty0 (6):\penalty0 6--9, 2016.

\bibitem[Berk et~al.(2017)Berk, Heidari, Jabbari, Kearns, and
  Roth]{berk2017fairness}
R.~Berk, H.~Heidari, S.~Jabbari, M.~Kearns, and A.~Roth.
\newblock Fairness in criminal justice risk assessments: The state of the art.
\newblock \emph{arXiv preprint arXiv:1703.09207}, 2017.

\bibitem[Bolukbasi et~al.(2016)Bolukbasi, Chang, Zou, Saligrama, and
  Kalai]{bolukbasi2016man}
T.~Bolukbasi, K.-W. Chang, J.~Y. Zou, V.~Saligrama, and A.~T. Kalai.
\newblock Man is to computer programmer as woman is to homemaker? debiasing
  word embeddings.
\newblock In \emph{NIPS}, pages 4349--4357, 2016.

\bibitem[Calders and Verwer(2012)]{calders2010three}
T.~Calders and S.~Verwer.
\newblock Three naive bayes approaches for discrimination-free classification.
\newblock \emph{KDD}, 2012.

\bibitem[Calders et~al.(2009)Calders, Kamiran, and
  Pechenizkiy]{calders2009building}
T.~Calders, F.~Kamiran, and M.~Pechenizkiy.
\newblock Building classifiers with independency constraints.
\newblock In \emph{ICDM Workshops}, 2009.

\bibitem[Chouldechova(2017)]{chouldechova2017fair}
A.~Chouldechova.
\newblock Fair prediction with disparate impact: A study of bias in recidivism
  prediction instruments.
\newblock \emph{arXiv preprint arXiv:1703.00056}, 2017.

\bibitem[Corbett-Davies et~al.(2017)Corbett-Davies, Pierson, Feller, Goel, and
  Huq]{corbett2017algorithmic}
S.~Corbett-Davies, E.~Pierson, A.~Feller, S.~Goel, and A.~Huq.
\newblock Algorithmic decision making and the cost of fairness.
\newblock In \emph{KDD}, pages 797--806, 2017.

\bibitem[Crowson et~al.(2016)Crowson, Atkinson, and
  Therneau]{crowson-calibration-risk-scores}
C.~S. Crowson, E.~J. Atkinson, and T.~M. Therneau.
\newblock Assessing calibration of prognostic risk scores.
\newblock \emph{Statistical Methods in Medical Research}, 25\penalty0
  (4):\penalty0 1692--1706, 2016.

\bibitem[Dawid(1982)]{dawid1982well}
A.~P. Dawid.
\newblock The well-calibrated bayesian.
\newblock \emph{Journal of the American Statistical Association}, 77\penalty0
  (379):\penalty0 605--610, 1982.

\bibitem[Dieterich et~al.(2016)Dieterich, Mendoza, and
  Brennan]{dieterich-northpointe-fairness}
W.~Dieterich, C.~Mendoza, and T.~Brennan.
\newblock {COMPAS} risk scales: Demonstrating accuracy equity and predictive
  parity.
\newblock Technical report, Northpointe, July 2016.
\newblock http://www.northpointeinc.com/northpointe-analysis.

\bibitem[Dwork et~al.(2012)Dwork, Hardt, Pitassi, Reingold, and
  Zemel]{dwork2012fairness}
C.~Dwork, M.~Hardt, T.~Pitassi, O.~Reingold, and R.~Zemel.
\newblock Fairness through awareness.
\newblock In \emph{Innovations in Theoretical Computer Science}, 2012.

\bibitem[Edwards and Storkey(2016)]{edwards2015censoring}
H.~Edwards and A.~Storkey.
\newblock Censoring representations with an adversary.
\newblock In \emph{ICLR}, 2016.

\bibitem[Feldman et~al.(2015)Feldman, Friedler, Moeller, Scheidegger, and
  Venkatasubramanian]{feldman2015certifying}
M.~Feldman, S.~A. Friedler, J.~Moeller, C.~Scheidegger, and
  S.~Venkatasubramanian.
\newblock Certifying and removing disparate impact.
\newblock In \emph{KDD}, pages 259--268, 2015.

\bibitem[Flores et~al.(2016)Flores, Lowenkamp, and
  Bechtel]{flores-re-propublica-fair}
A.~Flores, C.~Lowenkamp, and K.~Bechtel.
\newblock False positives, false negatives, and false analyses: {A} rejoinder
  to ``machine bias: There’s software used across the country to predict
  future criminals. and it’s biased against blacks.''.
\newblock Technical report, Crime \& Justice Institute, September 2016.
\newblock
  http://www.crj.org/cji/entry/false-positives-false-negatives-and-false-analyses-a-rejoinder.

\bibitem[Goh et~al.(2016)Goh, Cotter, Gupta, and
  Friedlander]{goh2016satisfying}
G.~Goh, A.~Cotter, M.~Gupta, and M.~P. Friedlander.
\newblock Satisfying real-world goals with dataset constraints.
\newblock In \emph{NIPS}, pages 2415--2423. 2016.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
C.~Guo, G.~Pleiss, Y.~Sun, and K.~Q. Weinberger.
\newblock On calibration of modern neural networks.
\newblock In \emph{ICML}, 2017.

\bibitem[Hardt et~al.(2016)Hardt, Price, and Nathan]{hardt2016equality}
M.~Hardt, E.~Price, and S.~Nathan.
\newblock Equality of opportunity in supervised learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Johndrow and Lum(2017)]{johndrow2017algorithm}
J.~E. Johndrow and K.~Lum.
\newblock An algorithm for removing sensitive information: application to
  race-independent recidivism prediction.
\newblock \emph{arXiv preprint arXiv:1703.04957}, 2017.

\bibitem[Joseph et~al.(2016)Joseph, Kearns, Morgenstern, and
  Roth]{joseph2016fairness}
M.~Joseph, M.~Kearns, J.~H. Morgenstern, and A.~Roth.
\newblock Fairness in learning: Classic and contextual bandits.
\newblock In \emph{NIPS}, 2016.

\bibitem[Kamiran and Calders(2009)]{kamiran2009classifying}
F.~Kamiran and T.~Calders.
\newblock Classifying without discriminating.
\newblock In \emph{International Conference on Computer Control and
  Communication}, 2009.

\bibitem[Kamishima et~al.(2011)Kamishima, Akaho, and
  Sakuma]{kamishima2011fairness}
T.~Kamishima, S.~Akaho, and J.~Sakuma.
\newblock Fairness-aware learning through regularization approach.
\newblock In \emph{ICDM Workshops}, 2011.

\bibitem[Kearns et~al.(2017)Kearns, Roth, and Wu]{kearns2017meritocratic}
M.~Kearns, A.~Roth, and Z.~S. Wu.
\newblock Meritocratic fairness for cross-population selection.
\newblock In \emph{International Conference on Machine Learning}, pages
  1828--1836, 2017.

\bibitem[Kilbertus et~al.(2017)Kilbertus, Rojas-Carulla, Parascandolo, Hardt,
  Janzing, and Sch{\"o}lkopf]{kilbertus2017avoiding}
N.~Kilbertus, M.~Rojas-Carulla, G.~Parascandolo, M.~Hardt, D.~Janzing, and
  B.~Sch{\"o}lkopf.
\newblock Avoiding discrimination through causal reasoning.
\newblock In \emph{NIPS}, 2017.

\bibitem[Kleinberg et~al.(2017)Kleinberg, Mullainathan, and
  Raghavan]{kleinberg2016inherent}
J.~Kleinberg, S.~Mullainathan, and M.~Raghavan.
\newblock Inherent trade-offs in the fair determination of risk scores.
\newblock In \emph{Innovations in Theoretical Computer Science}. ACM, 2017.

\bibitem[Kusner et~al.(2017)Kusner, Loftus, Russell, and
  Silva]{kusner2017counterfactual}
M.~J. Kusner, J.~R. Loftus, C.~Russell, and R.~Silva.
\newblock Counterfactual fairness.
\newblock \emph{arXiv preprint arXiv:1703.06856}, 2017.

\bibitem[Lichman(2013)]{Lichman:2013}
M.~Lichman.
\newblock {UCI} machine learning repository, 2013.
\newblock URL \url{http://archive.ics.uci.edu/ml}.

\bibitem[Louizos et~al.(2016)Louizos, Swersky, Li, Welling, and
  Zemel]{louizos2015variational}
C.~Louizos, K.~Swersky, Y.~Li, M.~Welling, and R.~Zemel.
\newblock The variational fair auto encoder.
\newblock In \emph{ICLR}, 2016.

\bibitem[Niculescu-Mizil and Caruana(2005)]{niculescu2005predicting}
A.~Niculescu-Mizil and R.~Caruana.
\newblock Predicting good probabilities with supervised learning.
\newblock In \emph{ICML}, 2005.

\bibitem[Platt(1999)]{platt1999probabilistic}
J.~Platt.
\newblock Probabilistic outputs for support vector machines and comparisons to
  regularized likelihood methods.
\newblock \emph{Advances in Large Margin Classifiers}, 10\penalty0
  (3):\penalty0 61--74, 1999.

\bibitem[Romei and Ruggieri(2014)]{romei2014multidisciplinary}
A.~Romei and S.~Ruggieri.
\newblock A multidisciplinary survey on discrimination analysis.
\newblock \emph{The Knowledge Engineering Review}, 29\penalty0 (05):\penalty0
  582--638, 2014.

\bibitem[White-House(2016)]{whitehouse-big-data}
White-House.
\newblock Big data: A report on algorithmic systems, opportunity, and civil
  rights.
\newblock Technical report, May 2016.

\bibitem[Woodworth et~al.(2017)Woodworth, Gunasekar, Ohannessian, and
  Srebro]{woodworth2017learning}
B.~Woodworth, S.~Gunasekar, M.~I. Ohannessian, and N.~Srebro.
\newblock Learning non-discriminatory predictors.
\newblock In \emph{Proceedings of the 2017 Conference on Learning Theory},
  volume~65, pages 1920--1953, Amsterdam, Netherlands, 07--10 Jul 2017. PMLR.

\bibitem[Zadrozny and Elkan(2001)]{zadrozny2001obtaining}
B.~Zadrozny and C.~Elkan.
\newblock Obtaining calibrated probability estimates from decision trees and
  naive bayesian classifiers.
\newblock In \emph{ICML}, pages 609--616, 2001.

\bibitem[Zafar et~al.(2015)Zafar, Valera, Rodriguez, and
  Gummadi]{zafar2015learning}
M.~B. Zafar, I.~Valera, M.~G. Rodriguez, and K.~P. Gummadi.
\newblock Learning fair classifiers.
\newblock \emph{arXiv preprint arXiv:1507.05259}, 2015.

\bibitem[Zafar et~al.(2017)Zafar, Valera, Rodriguez, and
  Gummadi]{zafar2017fairness}
M.~B. Zafar, I.~Valera, M.~G. Rodriguez, and K.~P. Gummadi.
\newblock Fairness beyond disparate treatment \& disparate impact: Learning
  classification without disparate mistreatment.
\newblock In \emph{World Wide Web Conference}, 2017.

\bibitem[Zemel et~al.(2013)Zemel, Wu, Swersky, Pitassi, and
  Dwork]{zemel2013learning}
R.~S. Zemel, Y.~Wu, K.~Swersky, T.~Pitassi, and C.~Dwork.
\newblock Learning fair representations.
\newblock In \emph{ICML}, 2013.

\bibitem[Zliobaite(2015)]{zliobaite2015relation}
I.~Zliobaite.
\newblock On the relation between accuracy and fairness in binary
  classification.
\newblock In \emph{ICML Workshop on Fairness, Accountability, and Transparency
  in Machine Learning}, 2015.

\end{thebibliography}
