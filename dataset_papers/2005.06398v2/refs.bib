@inproceedings{razin2020implicit,
	title={Implicit Regularization in Deep Learning May Not Be Explainable by Norms},
	author={Razin, Noam and Cohen, Nadav},
	booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
	year={2020}
}

@article{anandkumar2014tensor,
	title={Tensor decompositions for learning latent variable models},
	author={Anandkumar, Animashree and Ge, Rong and Hsu, Daniel and Kakade, Sham M and Telgarsky, Matus},
	journal={Journal of Machine Learning Research},
	volume={15},
	pages={2773--2832},
	year={2014},
	publisher={Journal of Machine Learning Research}
}

@article{acar2011scalable,
	title={Scalable tensor factorizations for incomplete data},
	author={Acar, Evrim and Dunlavy, Daniel M and Kolda, Tamara G and M{\o}rup, Morten},
	journal={Chemometrics and Intelligent Laboratory Systems},
	volume={106},
	number={1},
	pages={41--56},
	year={2011},
	publisher={Elsevier}
}

@inproceedings{jain2014provable,
	title={Provable tensor factorization with missing data},
	author={Jain, Prateek and Oh, Sewoong},
	booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
	pages={1431--1439},
	year={2014}
}

@article{narita2012tensor,
	title={Tensor factorization using auxiliary information},
	author={Narita, Atsuhiro and Hayashi, Kohei and Tomioka, Ryota and Kashima, Hisashi},
	journal={Data Mining and Knowledge Discovery},
	volume={25},
	number={2},
	pages={298--324},
	year={2012},
	publisher={Springer}
}

@article{karlsson2016parallel,
	title={Parallel algorithms for tensor completion in the CP format},
	author={Karlsson, Lars and Kressner, Daniel and Uschmajew, Andr{\'e}},
	journal={Parallel Computing},
	volume={57},
	pages={222--234},
	year={2016},
	publisher={Elsevier}
}

@article{yokota2016smooth,
	title={Smooth PARAFAC decomposition for tensor completion},
	author={Yokota, Tatsuya and Zhao, Qibin and Cichocki, Andrzej},
	journal={IEEE Transactions on Signal Processing},
	volume={64},
	number={20},
	pages={5423--5436},
	year={2016},
	publisher={IEEE}
}

@article{zhou2017tensor,
	title={Tensor factorization for low-rank tensor completion},
	author={Zhou, Pan and Lu, Canyi and Lin, Zhouchen and Zhang, Chao},
	journal={IEEE Transactions on Image Processing},
	volume={27},
	number={3},
	pages={1152--1163},
	year={2017},
	publisher={IEEE}
}

@article{xia2017polynomial,
	title={On polynomial time methods for exact low rank tensor completion},
	author={Xia, Dong and Yuan, Ming},
	journal={arXiv preprint arXiv:1702.06980},
	year={2017}
}

@inproceedings{cai2019nonconvex,
	title={Nonconvex low-rank tensor completion from noisy data},
	author={Cai, Changxiao and Li, Gen and Poor, H Vincent and Chen, Yuxin},
	booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
	pages={1863--1874},
	year={2019}
}

@book{teschl2012ordinary,
	title={Ordinary differential equations and dynamical systems},
	author={Teschl, Gerald},
	volume={140},
	year={2012},
	publisher={American Mathematical Soc.}
}

@inproceedings{geyer2020uniqueness,
	title = {Low-rank regularization and solution uniqueness in over-parameterized matrix sensing}, 
	author = {Geyer, Kelly and Kyrillidis, Anastasios and Kalev, Amir}, 		booktitle={Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
	pages = {930--940},
	year = {2020}, 
}

@article{shah2018minimum,
	title={Minimum weight norm models do not always generalize well for over-parameterized problems},
	author={Shah, Vatsal and Kyrillidis, Anastasios and Sanghavi, Sujay},
	journal={arXiv preprint arXiv:1811.07055},
	year={2018}
}

@article{ipsen2008perturbation,
	title={Perturbation bounds for determinants and characteristic polynomials},
	author={Ipsen, Ilse CF and Rehman, Rizwana},
	journal={SIAM Journal on Matrix Analysis and Applications},
	volume={30},
	number={2},
	pages={762--776},
	year={2008},
	publisher={SIAM}
}

@article{powers1970free,
	title={Free states of the canonical anticommutation relations},
	author={Powers, Robert T and St{\o}rmer, Erling},
	journal={Communications in Mathematical Physics},
	volume={16},
	number={1},
	pages={1--33},
	year={1970},
	publisher={Springer}
}

@inproceedings{suggala2018connecting,
	title={Connecting optimization and regularization paths},
	author={Suggala, Arun and Prasad, Adarsh and Ravikumar, Pradeep K},
	booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
	pages={10608--10619},
	year={2018}
}

@inproceedings{mei2019mean,
  title={Mean-field theory of two-layers neural networks: dimension-free bounds and kernel limit},
  author={Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
  booktitle={Conference on Learning Theory (COLT)},
  pages={2388--2464},
  year={2019}
}

@inproceedings{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  booktitle={Advances in neural information processing systems (NeurIPS)},
  pages={8571--8580},
  year={2018}
}

@inproceedings{goldt2019dynamics,
  title={Dynamics of stochastic gradient descent for two-layer neural networks in the teacher-student setup},
  author={Goldt, Sebastian and Advani, Madhu and Saxe, Andrew M and Krzakala, Florent and Zdeborov{\'a}, Lenka},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={6979--6989},
  year={2019}
}

@article{arora2020dropout,
  title={Dropout: Explicit Forms and Capacity Control},
  author={Arora, Raman and Bartlett, Peter and Mianjy, Poorya and Srebro, Nathan},
  journal={arXiv preprint arXiv:2003.03397},
  year={2020}
}

@inproceedings{mulayoff2020unique,
  title={Unique Properties of Wide Minima in Deep Networks},
  author={Mulayoff, Rotem and Michaeli, Tomer},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020}
}

@inproceedings{kalimeris2019sgd,
  title={SGD on Neural Networks Learns Functions of Increasing Complexity},
  author={Kalimeris, Dimitris and Kaplun, Gal and Nakkiran, Preetum and Edelman, Benjamin and Yang, Tristan and Barak, Boaz and Zhang, Haofeng},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={3491--3501},
  year={2019}
}

@article{radhakrishnan2020balancedness,
  title={Balancedness and Alignment are Unlikely in Linear Neural Networks},
  author={Radhakrishnan, Adityanarayanan and Nichani, Eshaan and Bernstein, Daniel and Uhler, Caroline},
  journal={arXiv preprint arXiv:2003.06340},
  year={2020}
}

@inproceedings{oymak2019overparameterized,
  title={Overparameterized nonlinear learning: Gradient descent takes the shortest path?},
  author={Oymak, Samet and Soltanolkotabi, Mahdi},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={4951--4960},
  year={2019}
}

@inproceedings{ali2020implicit,
  title={The Implicit Regularization of Stochastic Gradient Flow for Least Squares},
  author={Ali, Alnur and Dobriban, Edgar and Tibshirani, Ryan J},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020}
}

@article{belabbas2020implicit,
  title={On implicit regularization: Morse functions and applications to matrix factorization},
  author={Belabbas, Mohamed Ali},
  journal={arXiv preprint arXiv:2001.04264},
  year={2020}
}

@inproceedings{chizat2020implicit,
  title={Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks Trained with the Logistic Loss},
  author={Chizat, Lenaic and Bach, Francis},
  booktitle={Conference on Learning Theory (COLT)},
  pages={1305--1338},
  year={2020}
}

@article{brutzkus2020inductive,
  title={On the Inductive Bias of a CNN for Orthogonal Patterns Distributions},
  author={Brutzkus, Alon and Globerson, Amir},
  journal={arXiv preprint arXiv:2002.09781},
  year={2020}
}

@inproceedings{wei2020implicit,
  title={The Implicit and Explicit Regularization Effects of Dropout},
  author={Wei, Colin and Kakade, Sham and Ma, Tengyu},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020}
}

@inproceedings{ji2019implicit,
  title={The implicit bias of gradient descent on nonseparable data},
  author={Ji, Ziwei and Telgarsky, Matus},
  booktitle={Conference on Learning Theory (COLT)},
  pages={1772--1798},
  year={2019}
}

@article{gissin2020implicit,
  title={The Implicit Bias of Depth: How Incremental Learning Drives Generalization},
  author={Gissin, Daniel and Shalev-Shwartz, Shai and Daniely, Amit},
  journal={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@inproceedings{woodworth2020kernel,
  title={Kernel and Rich Regimes in Overparametrized Models},
  author={Woodworth, Blake and Gunasekar, Suriya and Lee, Jason D and Moroshko, Edward and Savarese, Pedro and Golan, Itay and Soudry, Daniel and Srebro, Nathan},
  booktitle={Conference on Learning Theory (COLT)},
  pages={3635--3673},
  year={2020}
}

@inproceedings{dauber2020can,
  title={Can Implicit Bias Explain Generalization? Stochastic Convex Optimization as a Case Study},
  author={Dauber, Assaf and Feder, Meir and Koren, Tomer and Livni, Roi},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@inproceedings{nacson2019lexicographic,
  title={Lexicographic and Depth-Sensitive Margins in Homogeneous and Non-Homogeneous Deep Models},
  author={Nacson, Mor Shpigel and Gunasekar, Suriya and Lee, Jason and Srebro, Nathan and Soudry, Daniel},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={4683--4692},
  year={2019}
}

@article{lyu2020gradient,
  title={Gradient descent maximizes the margin of homogeneous neural networks},
  author={Lyu, Kaifeng and Li, Jian},
  journal={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@article{wu2019implicit,
  title={Implicit Regularization of Normalization Methods},
  author={Wu, Xiaoxia and Dobriban, Edgar and Ren, Tongzheng and Wu, Shanshan and Li, Zhiyuan and Gunasekar, Suriya and Ward, Rachel and Liu, Qiang},
  journal={arXiv preprint arXiv:1911.07956},
  year={2019}
}

@article{haastad1990tensor,
  title={Tensor rank is NP-complete},
  author={H{\aa}stad, Johan},
  journal={Journal of algorithms (Print)},
  volume={11},
  number={4},
  pages={644--654},
  year={1990}
}

@book{golub2012matrix,
  title={Matrix computations},
  author={Golub, Gene H and Van Loan, Charles F},
  volume={3},
  year={2012},
  publisher={JHU press}
}

@inproceedings{arora2019implicit,
    title = {Implicit Regularization in Deep Matrix Factorization},
    author = {Arora, Sanjeev and Cohen, Nadav and Hu, Wei and Luo, Yuping},
	booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
    pages = {7413--7424},
    year = {2019},
}

@inproceedings{du2018algorithmic,
  title={Algorithmic regularization in learning deep homogeneous models: Layers are automatically balanced},
  author={Du, Simon S and Hu, Wei and Lee, Jason D},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={384--395},
  year={2018}
}

@inproceedings{du2019width,
  title={Width Provably Matters in Optimization for Deep Linear Neural Networks},
  author={Du, Simon S and Hu, Wei},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1655--1664},
  year={2019}
}

@inproceedings{bartlett2018gradient,
	title={Gradient descent with identity initialization efficiently learns positive definite linear transformations},
	author={Bartlett, Peter and Helmbold, Dave and Long, Phil},
	booktitle={International Conference on Machine Learning (ICML)},
	pages={520--529},
	year={2018}
}

@book{boyd2004convex,
	title={Convex optimization},
	author={Boyd, Stephen and Vandenberghe, Lieven},
	year={2004},
	publisher={Cambridge university press}
}

@inproceedings{arora2018optimization,
	title={On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization},
	author={Sanjeev Arora and Nadav Cohen and Elad Hazan},
	booktitle={International Conference on Machine Learning (ICML)},
	pages={244--253},
	year={2018},
}

@book{horn1990matrix,
	title={Matrix analysis},
	author={Horn, Roger and Johnson, Charles},
	year={1990},
	publisher={Cambridge university press}
}

@inproceedings{he2016deep,
	title={Deep residual learning for image recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR)},
	pages={770--778},
	year={2016}
}

@article{hardt2016identity,
	title={Identity matters in deep learning},
	author={Hardt, Moritz and Ma, Tengyu},
	journal={International Conference on Learning Representations (ICLR)},
	year={2016}
}

@inproceedings{sutskever2013importance,
	title={On the importance of initialization and momentum in deep learning},
	author={Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
	booktitle={International Conference on Machine Learning (ICML)},
	pages={1139--1147},
	year={2013}
}

@inproceedings{kawaguchi2016deep,
	title={Deep learning without poor local minima},
	author={Kawaguchi, Kenji},
	booktitle={Advances in Neural Information Processing Systems (NeuRIPS)},
	pages={586--594},
	year={2016}
}

@article{soudry2016no,
	title={No bad local minima: Data independent training error guarantees for multilayer neural networks},
	author={Soudry, Daniel and Carmon, Yair},
	journal={arXiv preprint arXiv:1605.08361},
	year={2016}
}

@inproceedings{haeffele2017global,
	title={Global Optimality in Neural Network Training},
    author={Haeffele, Benjamin and Vidal, Ren{\'{e}}},
	booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages={4390--4398},
	year={2017}
}

@book{bhatia_matrix_1997,
	title = {Matrix analysis},
	publisher = {Springer-Verlag},
	urldate = {2018-06-20},
	author = {Bhatia, Rajendra},
	year = {1997},
}

@article{lovett_elementary_2010,
	title = {An elementary proof of anti-concentration of polynomials in {Gaussian} variables},
	urldate = {2018-09-14},
	journal = {Electronic Colloquium on Computational Complexity},
	author = {Lovett, Shachar},
	year = {2010},
	pages = {182}
}

@article{carbery_distributional_2001,
	title = {Distributional and lq norm inequalities for polynomials over convex bodies in {Rn}.},
	volume = {8},
	number = {3},
	urldate = {2018-09-14},
	journal = {Mathematics Research Letters},
	author = {Carbery, A and Wright, J},
	year = {2001},
	pages = {233--248}
}

@article{chudnov_minimax_1986,
	title = {On minimax signal generation and reception algorithms},
	volume = {22},
	language = {ru},
	number = {4},
	journal = {Problems of Information Transmission},
	author = {Chudnov, Alexander},
	year = {1986},
	pages = {49--54},
	file = {?????? - ?~??????????? ?????????? ???????????? ? ?????? ???.pdf:/Users/ngolowich/Zotero/storage/A4TAGGXR/?????? - ?~??????????? ?????????? ???????????? ? ?????? ???.pdf:application/pdf}
}

@article{meka_anti-concentration_2016,
	title = {Anti-concentration for {Polynomials} of {Independent} {Random} {Variables}},
	volume = {12},
	abstract = {We prove anti-concentration results for polynomials of independent random variables with arbitrary degree. Our results extend the classical Littlewood-Offord result for linear polynomials, and improve several earlier estimates.},
	language = {en},
	journal = {Theory of Computing},
	author = {Meka, Raghu and Nguyen, Oanh and Vu, Van},
	year = {2016},
	pages = {17},
	file = {Meka et al. - 2016 - Anti-concentration for Polynomials of Independent .pdf:/Users/ngolowich/Zotero/storage/HZNVB24G/Meka et al. - 2016 - Anti-concentration for Polynomials of Independent .pdf:application/pdf}
}

@inproceedings{ge2015escaping,
	title={Escaping from saddle points—online stochastic gradient for tensor decomposition},
	author={Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
	booktitle={Conference on Learning Theory (COLT)},
	pages={797--842},
	year={2015}
}

@inproceedings{lee2016gradient,
	title={Gradient descent only converges to minimizers},
	author={Lee, Jason D and Simchowitz, Max and Jordan, Michael I and Recht, Benjamin},
	booktitle={Conference on Learning Theory (COLT)},
	pages={1246--1257},
	year={2016}
}

@inproceedings{panageas2017gradient,
	title={Gradient Descent Only Converges to Minimizers: Non-Isolated Critical Points and Invariant Regions},
	author={Ioannis Panageas and Georgios Piliouras},
	booktitle={Innovations in Theoretical Computer Science},
	year={2017}
}

@inproceedings{safran2018spurious,
	title={Spurious Local Minima are Common in Two-Layer ReLU Neural Networks},
	author={Itay Safran and Ohad Shamir},
	booktitle={International Conference on Machine Learning (ICML)},
	year={2018}
}

@inproceedings{choromanska2015loss,
	title={The loss surfaces of multilayer networks},
	author={Choromanska, Anna and Henaff, Mikael and Mathieu, Michael and Arous, G{\'e}rard Ben and LeCun, Yann},
	booktitle={Artificial Intelligence and Statistics},
	pages={192--204},
	year={2015}
}

@inproceedings{ge2016matrix,
	title={Matrix completion has no spurious local minimum},
	author={Ge, Rong and Lee, Jason D and Ma, Tengyu},
	booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
	pages={2973--2981},
	year={2016}
}

@article{saxe2014exact,
	title={Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
	author={Saxe, Andrew M and McClelland, James L and Ganguli, Surya},
	journal={International Conference on Learning Representations (ICLR)},
	year={2014}
}

@InProceedings{li2018algorithmic,
  title={Algorithmic Regularization in Over-parameterized Matrix Sensing and Neural Networks with Quadratic Activations},
  author={Li, Yuanzhi and Ma, Tengyu and Zhang, Hongyang},
  booktitle={Proceedings of the 31st Conference On Learning Theory (COLT)},
  pages={2--47},
  year={2018}
}

@article{laurent_adaptive_2000,
	title={Adaptive estimation of a quadratic functional by model selection},
	volume={28},
	number={5},
	year={2000},
	journal={The Annals of Statistics},
	author={Laurent, Beatrice and Massart, Pascal},
	pages={1302--1338}
}

@article{liao2018almost,
	title={Almost Global Convergence to Global Minima for Gradient Descent in Deep Linear Networks},
	author={Liao, Zhenyu and Chitour, Yacine and Couillet, Romain},
	year={2018}
}

@article{baldi1989neural,
	title={Neural networks and principal component analysis: Learning from examples without local minima},
	author={Baldi, Pierre and Hornik, Kurt},
	journal={Neural networks},
	volume={2},
	number={1},
	pages={53--58},
	year={1989},
	publisher={Elsevier}
}

@inproceedings{safran2016quality,
	title={On the quality of the initial basin in overspecified neural networks},
	author={Safran, Itay and Shamir, Ohad},
	booktitle={International Conference on Machine Learning (ICML)},
	pages={774--782},
	year={2016}
}

@inproceedings{agarwal2017finding,
	title={Finding approximate local minima faster than gradient descent},
	author={Agarwal, Naman and Allen-Zhu, Zeyuan and Bullins, Brian and Hazan, Elad and Ma, Tengyu},
	booktitle={Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing},
	pages={1195--1199},
	year={2017},
	organization={ACM}
}

@article{carmon2018accelerated,
	title={Accelerated methods for nonconvex optimization},
	author={Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, Aaron},
	journal={SIAM Journal on Optimization},
	volume={28},
	number={2},
	pages={1751--1772},
	year={2018},
	publisher={SIAM}
}

@article{janzamin2015beating,
	title={Beating the perils of non-convexity: Guaranteed training of neural networks using tensor methods},
	author={Janzamin, Majid and Sedghi, Hanie and Anandkumar, Anima},
	journal={arXiv preprint arXiv:1506.08473},
	year={2015}
}

@inproceedings{livni2014computational,
	title={On the computational efficiency of training neural networks},
	author={Livni, Roi and Shalev-Shwartz, Shai and Shamir, Ohad},
	booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
	pages={855--863},
	year={2014}
}

@article{tian2017analytical,
	title={An analytical formula of population gradient for two-layered relu network and its applications in convergence and critical point analysis},
	author={Tian, Yuandong},
	journal={arXiv preprint arXiv:1703.00560},
	year={2017}
}

@inproceedings{brutzkus2017globally,
	title={Globally Optimal Gradient Descent for a ConvNet with Gaussian Inputs},
	author={Brutzkus, Alon and Globerson, Amir},
	booktitle={International Conference on Machine Learning (ICML)},
	pages={605--614},
	year={2017}
}

@inproceedings{du2018gradient,
	title={Gradient Descent Learns One-hidden-layer CNN: Don’t be Afraid of Spurious Local Minima},
	author={Du, Simon S and Lee, Jason D and Tian, Yuandong and Singh, Aarti and Poczos, Barnabas},
	booktitle={International Conference on Machine Learning (ICML)},
	pages={1339--1348},
	year={2018}
}

@article{du2018convolutional,
	title={When is a Convolutional Filter Easy to Learn?},
	author={Du, Simon S and Lee, Jason D and Tian, Yuandong},
	journal={International Conference on Learning Representations (ICLR)},
	year={2018}
}

@inproceedings{zhong2017recovery,
	title={Recovery Guarantees for One-hidden-layer Neural Networks},
	author={Zhong, Kai and Song, Zhao and Jain, Prateek and Bartlett, Peter L and Dhillon, Inderjit S},
	booktitle={International Conference on Machine Learning (ICML)},
	pages={4140--4149},
	year={2017}
}

@inproceedings{li2017convergence,
	title={Convergence analysis of two-layer neural networks with relu activation},
	author={Li, Yuanzhi and Yuan, Yang},
	booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
	pages={597--607},
	year={2017}
}

@article{brutzkus2018sgd,
	title={SGD Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data},
	author={Brutzkus, Alon and Globerson, Amir and Malach, Eran and Shalev-Shwartz, Shai},
	journal={International Conference on Learning Representations (ICLR)},	
	year={2018}
}

@inproceedings{du2018power,
	title={On the Power of Over-parametrization in Neural Networks with Quadratic Activation},
	author={Du, Simon S and Lee, Jason D},
	booktitle={International Conference on Machine Learning (ICML)},
	pages={1329--1338},
	year={2018}
}

@inproceedings{nguyen2017loss,
	title={The Loss Surface of Deep and Wide Neural Networks},
	author={Nguyen, Quynh and Hein, Matthias},
	booktitle={International Conference on Machine Learning (ICML)},
	pages={2603--2612},
	year={2017}
}

@article{nguyen2018loss,
	title={The loss surface and expressivity of deep convolutional neural networks},
	author={Nguyen, Quynh and Hein, Matthias},
	journal={arXiv preprint arXiv:1710.10928},
	year={2018}
}

@inproceedings{laurent2018deep,
	title={Deep Linear Networks with Arbitrary Loss: All Local Minima Are Global},
	author={Laurent, Thomas and Brecht, James},
	booktitle={International Conference on Machine Learning (ICML)},
	pages={2908--2913},
	year={2018}
}

@article{shamir2018exponential,
	title={Exponential Convergence Time of Gradient Descent for One-Dimensional Deep Linear Neural Networks},
	author={Shamir, Ohad},
	journal={arXiv preprint arXiv:1809.08587},
	year={2018}
}

@article{vergara2012chemical,
	title={Chemical gas sensor drift compensation using classifier ensembles},
	author={Vergara, Alexander and Vembu, Shankar and Ayhan, Tuba and Ryan, Margaret A and Homer, Margie L and Huerta, Ram{\'o}n},
	journal={Sensors and Actuators B: Chemical},
	volume={166},
	pages={320--329},
	year={2012},
	publisher={Elsevier}
}

@article{rodriguez2014calibration,
	title={On the calibration of sensor arrays for pattern recognition using the minimal number of experiments},
	author={Rodriguez-Lujan, Irene and Fonollosa, Jordi and Vergara, Alexander and Homer, Margie and Huerta, Ramon},
	journal={Chemometrics and Intelligent Laboratory Systems},
	volume={130},
	pages={123--134},
	year={2014},
	publisher={Elsevier}
}

@inproceedings{abadi2016tensorflow,
	title={TensorFlow: A System for Large-Scale Machine Learning.},
	author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
	booktitle={OSDI},
	volume={16},
	pages={265--283},
	year={2016}
}

@inproceedings{nair2010rectified,
	title={Rectified linear units improve restricted boltzmann machines},
	author={Nair, Vinod and Hinton, Geoffrey E},
	booktitle={Proceedings of the 27th International Conference on Machine Learning (ICML-10)},
	pages={807--814},
	year={2010}
}

@inproceedings{paszke2017automatic,
	title={Automatic differentiation in PyTorch},
	author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
	booktitle={NIPS-W},
	year={2017}
}

@article{arora2019convergence,
	title={A Convergence Analysis of Gradient Descent for Deep Linear Neural Networks},
	author={Arora, Sanjeev and Cohen, Nadav and Golowich, Noah and Hu, Wei},
	journal={International Conference on Learning Representations (ICLR)},
	year={2019}
}

@article{davenport2016overview,
	title={An overview of low-rank matrix recovery from incomplete observations},
	author={Davenport, Mark A and Romberg, Justin},
	journal={IEEE Journal of Selected Topics in Signal Processing},
	volume={10},
	number={4},
	pages={608--622},
	year={2016},
	publisher={IEEE}
}

@article{candes2009exact,
	title={Exact matrix completion via convex optimization},
	author={Cand{\`e}s, Emmanuel J and Recht, Benjamin},
	journal={Foundations of Computational mathematics},
	volume={9},
	number={6},
	pages={717},
	year={2009},
	publisher={Springer}
}

@article{recht2010guaranteed,
	title={Guaranteed minimum-rank solutions of linear matrix equations via nuclear norm minimization},
	author={Recht, Benjamin and Fazel, Maryam and Parrilo, Pablo A},
	journal={SIAM review},
	volume={52},
	number={3},
	pages={471--501},
	year={2010},
	publisher={SIAM}
}

@article{burer2003nonlinear,
	title={A nonlinear programming algorithm for solving semidefinite programs via low-rank factorization},
	author={Burer, Samuel and Monteiro, Renato DC},
	journal={Mathematical Programming},
	volume={95},
	number={2},
	pages={329--357},
	year={2003},
	publisher={Springer}
}

@inproceedings{ge2017no,
	title={No spurious local minima in nonconvex low rank problems: A unified geometric analysis},
	author={Ge, Rong and Jin, Chi and Zheng, Yi},
	booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
	pages={1233--1242},
	year={2017},
	organization={JMLR. org}
}

@article{sun2016guaranteed,
	title={Guaranteed matrix completion via non-convex factorization},
	author={Sun, Ruoyu and Luo, Zhi-Quan},
	journal={IEEE Transactions on Information Theory},
	volume={62},
	number={11},
	pages={6535--6579},
	year={2016},
	publisher={IEEE}
}

@inproceedings{hardt2014understanding,
	title={Understanding alternating minimization for matrix completion},
	author={Hardt, Moritz},
	booktitle={2014 IEEE 55th Annual Symposium on Foundations of Computer Science},
	pages={651--660},
	year={2014},
	organization={IEEE}
}

@inproceedings{ge2016matrix,
	title={Matrix completion has no spurious local minimum},
	author={Ge, Rong and Lee, Jason D and Ma, Tengyu},
	booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
	pages={2973--2981},
	year={2016}
}

@inproceedings{bhojanapalli2016global,
	title={Global optimality of local search for low rank matrix recovery},
	author={Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nati},
	booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
	pages={3873--3881},
	year={2016}
}

@inproceedings{park2017nonsquare,
	title={Non-square matrix sensing without spurious local minima via the Burer-Monteiro approach},
	author={Dohyung Park and Anastasios Kyrillidis and Constantine Carmanis and Sujay Sanghavi},
	booktitle={Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
	pages={65--74},
	year={2017},
}

@inproceedings{gunasekar2017implicit,
	title={Implicit regularization in matrix factorization},
	author={Gunasekar, Suriya and Woodworth, Blake E and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nati},
	booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
	pages={6151--6159},
	year={2017}
}

@article{zhang2017understanding,
	title={Understanding deep learning requires rethinking generalization},
	author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	journal={International Conference on Learning Representations (ICLR)},
	year={2017}
}

@article{keskar2017large,
	title={On large-batch training for deep learning: Generalization gap and sharp minima},
	author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
	journal={International Conference on Learning Representations (ICLR)},
	year={2017}
}

@inproceedings{neyshabur2017exploring,
	title={Exploring generalization in deep learning},
	author={Neyshabur, Behnam and Bhojanapalli, Srinadh and McAllester, David and Srebro, Nati},
	booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
	pages={5947--5956},
	year={2017}
}

@inproceedings{hoffer2017train,
	title={Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
	author={Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
	booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
	pages={1731--1741},
	year={2017}
}

@inproceedings{arora2018stronger,
	title={Stronger Generalization Bounds for Deep Nets via a Compression Approach},
	author={Arora, Sanjeev and Ge, Rong and Neyshabur, Behnam and Zhang, Yi},
	booktitle={International Conference on Machine Learning (ICML)},
	pages={254--263},
	year={2018}
}

@article{neyshabur2018pac,
	title={A pac-bayesian approach to spectrally-normalized margin bounds for neural networks},
	author={Neyshabur, Behnam and Bhojanapalli, Srinadh and Srebro, Nathan},
	journal={International Conference on Learning Representations (ICLR)},
	year={2018}
}

@article{wei2018margin,
	title={On the margin theory of feedforward neural networks},
	author={Wei, Colin and Lee, Jason D and Liu, Qiang and Ma, Tengyu},
	journal={arXiv preprint arXiv:1810.05369},
	year={2018}
}

@inproceedings{golowich2018size,
	title={Size-Independent Sample Complexity of Neural Networks},
	author={Golowich, Noah and Rakhlin, Alexander and Shamir, Ohad},
	booktitle={Conference On Learning Theory (COLT)},
	pages={297--299},
	year={2018}
}

@article{neyshabur2019towards,
	title={Towards understanding the role of over-parametrization in generalization of neural networks},
	author={Neyshabur, Behnam and Li, Zhiyuan and Bhojanapalli, Srinadh and LeCun, Yann and Srebro, Nathan},
	journal={International Conference on Learning Representations (ICLR)},
	year={2019}
}

@article{trigeorgis2017deep,
	title={A deep matrix factorization method for learning attribute representations},
	author={Trigeorgis, George and Bousmalis, Konstantinos and Zafeiriou, Stefanos and Schuller, Bj{\"o}rn W},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	volume={39},
	number={3},
	pages={417--429},
	year={2017},
	publisher={IEEE}
}

@inproceedings{zhao2017multi,
	title={Multi-view clustering via deep matrix factorization},
	author={Zhao, Handong and Ding, Zhengming and Fu, Yun},
	booktitle={Thirty-First AAAI Conference on Artificial Intelligence (AAAI)},
	year={2017}
}

@inproceedings{li2015deep,
	title={Deep matrix factorization for social image tag refinement and assignment},
	author={Li, Zechao and Tang, Jinhui},
	booktitle={2015 IEEE 17th International Workshop on Multimedia Signal Processing (MMSP)},
	pages={1--6},
	year={2015},
	organization={IEEE}
}

@inproceedings{xue2017deep,
	title={Deep Matrix Factorization Models for Recommender Systems.},
	author={Xue, Hong-Jian and Dai, Xinyu and Zhang, Jianbing and Huang, Shujian and Chen, Jiajun},
	booktitle={IJCAI},
	pages={3203--3209},
	year={2017}
}

@article{fan2018matrix,
	title={Matrix completion by deep matrix factorization},
	author={Fan, Jicong and Cheng, Jieyu},
	journal={Neural Networks},
	volume={98},
	pages={34--41},
	year={2018},
	publisher={Elsevier}
}

@inproceedings{wang2017multi,
	title={Multi-Modality Disease Modeling via Collective Deep Matrix Factorization},
	author={Wang, Qi and Sun, Mengying and Zhan, Liang and Thompson, Paul and Ji, Shuiwang and Zhou, Jiayu},
	booktitle={Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages={1155--1164},
	year={2017},
	organization={ACM}
}

@book{krantz2002primer,
	title={A primer of real analytic functions},
	author={Krantz, Steven G and Parks, Harold R},
	year={2002},
	publisher={Springer Science \& Business Media}
}

@book{ilyashenko2008lectures,
	title={Lectures on analytic differential equations},
	author={Ilyashenko, Yulij and Yakovenko, Sergei},
	volume={86},
	year={2008},
	publisher={American Mathematical Soc.}
}

@book{kato2013perturbation,
	title={Perturbation theory for linear operators},
	author={Kato, Tosio},
	volume={132},
	year={2013},
	publisher={Springer Science \& Business Media}
}

@article{bunse1991numerical,
	title={Numerical computation of an analytic singular value decomposition of a matrix valued function},
	author={Bunse-Gerstner, Angelika and Byers, Ralph and Mehrmann, Volker and Nichols, Nancy K},
	journal={Numerische Mathematik},
	volume={60},
	number={1},
	pages={1--39},
	year={1991},
	publisher={Springer}
}

@article{de1989analytic,
	title={Analytic properties of singular values and vectors},
	author={De Moor, B and Boyd, S},
	journal={Katholic Univ. Leuven, Belgium Tech. Rep},
	volume={28},
	pages={1989},
	year={1989}
}

@article{srivastava2014dropout,
	title={Dropout: a simple way to prevent neural networks from overfitting.},
	author={Srivastava, Nitish and Hinton, Geoffrey E and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	journal={Journal of Machine Learning Research},
	volume={15},
	number={1},
	pages={1929--1958},
	year={2014}
}

@article{hochreiter1997flat,
	title={Flat minima},
	author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
	journal={Neural Computation},
	volume={9},
	number={1},
	pages={1--42},
	year={1997},
	publisher={MIT Press}
}

@article{you2017scaling,
	title={Scaling sgd batch size to 32k for imagenet training},
	author={You, Yang and Gitman, Igor and Ginsburg, Boris},
	journal={arXiv preprint arXiv:1708.03888},
	year={2017}
}

@article{ji2019gradient,
	title={Gradient descent aligns the layers of deep linear networks},
	author={Ji, Ziwei and Telgarsky, Matus},
	journal={International Conference on Learning Representations (ICLR)},
	year={2019}
}

@article{advani2017high,
	title={High-dimensional dynamics of generalization error in neural networks},
	author={Advani, Madhu S and Saxe, Andrew M},
	journal={arXiv preprint arXiv:1710.03667},
	year={2017}
}

@article{lampinen2019analytic,
	title={An analytic theory of generalization dynamics and transfer learning in deep linear networks},
	author={Lampinen, Andrew K and Ganguli, Surya},
	journal={International Conference on Learning Representations (ICLR)},
	year={2019}
}

@inproceedings{gunasekar2018implicit,
	title={Implicit bias of gradient descent on linear convolutional networks},
	author={Gunasekar, Suriya and Lee, Jason D and Soudry, Daniel and Srebro, Nati},
	booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
	pages={9461--9471},
	year={2018}
}

@article{soudry2018implicit,
	title={The implicit bias of gradient descent on separable data},
	author={Soudry, Daniel and Hoffer, Elad and Nacson, Mor Shpigel and Gunasekar, Suriya and Srebro, Nathan},
	journal={The Journal of Machine Learning Research},
	volume={19},
	number={1},
	pages={2822--2878},
	year={2018}
}

@inproceedings{nacson2019convergence,
	title={Convergence of Gradient Descent on Separable Data},
	author={Nacson, Mor Shpigel and Lee, Jason and Gunasekar, Suriya and Savarese, Pedro Henrique Pamplona and Srebro, Nathan and Soudry, Daniel},
	booktitle={Proceedings of Machine Learning Research},
	volume={89},
	pages={3420--3428},
	year={2019}
}

@InProceedings{gunasekar2018characterizing,
	title={Characterizing Implicit Bias in Terms of Optimization Geometry},
	author={Gunasekar, Suriya and Lee, Jason and Soudry, Daniel and Srebro, Nathan},
	booktitle={Proceedings of the 35th International Conference on Machine Learning (ICML)},
	volume={80},
	pages={1832--1841},
	year={2018}
}

@InProceedings{rahaman2018spectral,
	title={On the spectral bias of deep neural networks},
	author={Rahaman, Nasim and Arpit, Devansh and Baratin, Aristide and Draxler, Felix and Lin, Min and Hamprecht, Fred A and Bengio, Yoshua and Courville, Aaron},
	booktitle={International Conference on Machine Learning (ICML)},
	pages={5301--5310},
	year={2019}
}

@article{neyshabur2017geometry,
	title={Geometry of optimization and implicit regularization in deep learning},
	author={Neyshabur, Behnam and Tomioka, Ryota and Salakhutdinov, Ruslan and Srebro, Nathan},
	journal={arXiv preprint arXiv:1705.03071},
	year={2017}
}

@inproceedings{lin2016generalization,
	title={Generalization properties and implicit regularization for multiple passes SGM},
	author={Lin, Junhong and Camoriano, Raffaello and Rosasco, Lorenzo},
	booktitle={International Conference on Machine Learning (ICML)},
	pages={2340--2348},
	year={2016}
}

@article{neyshabur2014search,
	title={In search of the real inductive bias: On the role of implicit regularization in deep learning},
	author={Neyshabur, Behnam and Tomioka, Ryota and Srebro, Nathan},
	journal={arXiv preprint arXiv:1412.6614},
	year={2014}
}

@article{neyshabur2017implicit,
	title={Implicit regularization in deep learning},
	author={Neyshabur, Behnam},
	journal={PhD thesis},
	year={2017}
}

@inproceedings{tu2016low,
	title={Low-rank Solutions of Linear Matrix Equations via Procrustes Flow},
	author={Tu, Stephen and Boczar, Ross and Simchowitz, Max and Soltanolkotabi, Mahdi and Recht, Ben},
	booktitle={International Conference on Machine Learning (ICML)},
	pages={964--973},
	year={2016}
}

@article{zheng2016convergence,
	title={Convergence analysis for rectangular matrix completion using burer-monteiro factorization and gradient descent},
	author={Zheng, Qinqing and Lafferty, John},
	journal={arXiv preprint arXiv:1605.07051},
	year={2016}
}

@inproceedings{zhao2015nonconvex,
	title={A nonconvex optimization framework for low rank matrix estimation},
	author={Zhao, Tuo and Wang, Zhaoran and Liu, Han},
	booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
	pages={559--567},
	year={2015}
}

@article{chen2015fast,
	title={Fast low-rank estimation by projected gradient descent: General statistical and algorithmic guarantees},
	author={Chen, Yudong and Wainwright, Martin J},
	journal={arXiv preprint arXiv:1509.03025},
	year={2015}
}

@article{keshavan2010matrix_1,
	title={Matrix completion from noisy entries},
	author={Keshavan, Raghunandan H and Montanari, Andrea and Oh, Sewoong},
	journal={Journal of Machine Learning Research},
	volume={11},
	number={Jul},
	pages={2057--2078},
	year={2010}
}

@article{keshavan2010matrix_2,
	title={Matrix completion from a few entries},
	author={Keshavan, Raghunandan H and Montanari, Andrea and Oh, Sewoong},
	journal={IEEE transactions on information theory},
	volume={56},
	number={6},
	pages={2980--2998},
	year={2010},
	publisher={IEEE}
}

@inproceedings{ma2018implicit,
	title={Implicit Regularization in Nonconvex Statistical Estimation: Gradient Descent Converges Linearly for Phase Retrieval and Matrix Completion},
	author={Ma, Cong and Wang, Kaizheng and Chi, Yuejie and Chen, Yuxin},
	booktitle={International Conference on Machine Learning (ICML)},
	pages={3351--3360},
	year={2018}
}

@article{chi2019nonconvex,
	title={Nonconvex optimization meets low-rank matrix factorization: An overview},
	author={Chi, Yuejie and Lu, Yue M and Chen, Yuxin},
	journal={IEEE Transactions on Signal Processing},
	volume={67},
	number={20},
	pages={5239--5269},
	year={2019},
	publisher={IEEE}
}

@inproceedings{gidel2019implicit,
  title={Implicit Regularization of Discrete Gradient Dynamics in Linear Neural Networks},
  author={Gidel, Gauthier and Bach, Francis and Lacoste-Julien, Simon},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={3196--3206},
  year={2019}
}

@techreport{townsend2016differentiating,
	title={Differentiating the Singular Value Decomposition},
	author={Townsend, James},
	year={2016}
}

@inproceedings{roy2007effective,
	title={The effective rank: A measure of effective dimensionality},
	author={Roy, Olivier and Vetterli, Martin},
	booktitle={2007 15th European Signal Processing Conference},
	pages={606--610},
	year={2007},
	organization={IEEE}
}

@article{harper2016movielens,
	title={The movielens datasets: History and context},
	author={Harper, F Maxwell and Konstan, Joseph A},
	journal={Acm transactions on interactive intelligent systems (tiis)},
	volume={5},
	number={4},
	pages={19},
	year={2016},
	publisher={ACM}
}

@article{diamond2016cvxpy,
	author={Diamond, Steven and Boyd, Stephen},
	title={{CVXPY}: A {P}ython-Embedded Modeling Language for Convex Optimization},
	journal={Journal of Machine Learning Research},
	year={2016},
	volume={17},
	number={83},
	pages={1--5}
}

@article{agrawal2018rewriting,
	author={Agrawal, Akshay and Verschueren, Robin and Diamond, Steven and Boyd, Stephen},
	title={A Rewriting System for Convex Optimization Problems},
	journal={Journal of Control and Decision},
	year={2018},
	volume={5},
	number={1},
	pages={42--60}
}

@article{cohen2014simnets,
	Author = {Cohen, Nadav and Shashua, Amnon},
	Journal = {Advances in Neural Information Processing Systems (NeurIPS), Deep Learning Workshop},
	Title = {SimNets: A Generalization of Convolutional Networks},
	Year = {2014}}

@article{cohen2016deep,
	Author = {Cohen, Nadav and Sharir, Or and Shashua, Amnon},
	Journal = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	Title = {Deep SimNets},
	Year = {2016}}

@article{cohen2016expressive,
	Author={Cohen, Nadav and Sharir, Or and Shashua, Amnon},
	Journal={Conference On Learning Theory (COLT)},
	Title={On the Expressive Power of Deep Learning: A Tensor Analysis},
	Year={2016}
}

@article{cohen2016convolutional,
	Author={Cohen, Nadav and Shashua, Amnon},
	Journal={International Conference on Machine Learning (ICML)},
	Title={Convolutional Rectifier Networks as Generalized Tensor Decompositions},
	Year={2016}
}

@article{sharir2016tensorial,
  Author={Sharir, Or and Tamari, Ronen and Cohen, Nadav and Shashua, Amnon},
  Journal={arXiv preprint},
  Title={Tensorial Mixture Models},
  Year={2016}
}

@article{cohen2017inductive,
  Author={Cohen, Nadav and Shashua, Amnon},
  Journal={International Conference on Learning Representations (ICLR)},
  Title={Inductive Bias of Deep Convolutional Networks through Pooling Geometry},
  Year={2017}
}

@article{cohen2017analysis,
  Author={Cohen, Nadav and Sharir, Or and Levine, Yoav and Tamari, Ronen and Yakira, David and Shashua, Amnon},
  Journal={Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI) Special Issue on Deep Learning Theory},
  Title={Analysis and Design of Convolutional Networks via Hierarchical Tensor Decompositions},
  Year={2017}
}

@article{levine2018deep,
  Author={Levine, Yoav and Yakira, David and Cohen, Nadav and Shashua, Amnon},
  Journal={International Conference on Learning Representations (ICLR)},
  Title={Deep Learning and Quantum Entanglement: Fundamental Connections with Implications to Network Design},
  Year={2018}
}

@article{cohen2018boosting,
  Author={Cohen, Nadav and Tamari, Ronen and Shashua, Amnon},
  Journal={International Conference on Learning Representations (ICLR)},
  Title={Boosting Dilated Convolutional Networks with Mixed Tensor Decompositions},
  Year={2018}
}

@article{levine2019quantum,
  Author={Levine, Yoav and Sharir, Or and Cohen, Nadav and Shashua, Amnon},
  Journal={To appear in Physical Review Letters},
  Title={Quantum Entanglement in Deep Learning Architectures},
  Year={2019}
}

@article{sharir2018expressive,
  Author={Sharir, Or and Shashua, Amnon},
  Journal={International Conference on Learning Representations (ICLR)},
  Title={On the expressive power of overlapping architectures of deep learning},
  Year={2018}
}

@article{balda2018tensor,
  Author={Balda, Emilio Rafael and Behboodi, Arash and Mathar, Rudolf},
  Title={A Tensor Analysis on Dense Connectivity via Convolutional Arithmetic Circuits},
  Year={2018}
}

@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010}
}

@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}

@article{kolda2009tensor,
	title={Tensor decompositions and applications},
	author={Kolda, Tamara G and Bader, Brett W},
	journal={SIAM review},
	volume={51},
	number={3},
	pages={455--500},
	year={2009},
	publisher={SIAM}
}

@book{hackbusch2012tensor,
	title={Tensor spaces and numerical tensor calculus},
	author={Hackbusch, Wolfgang},
	volume={42},
	year={2012},
	publisher={Springer}
}

@article{recht2011null,
	title={Null space conditions and thresholds for rank minimization},
	author={Recht, Benjamin and Xu, Weiyu and Hassibi, Babak},
	journal={Mathematical programming},
	volume={127},
	number={1},
	pages={175--202},
	year={2011},
	publisher={Springer}
}

@inproceedings{ji2020directional,
	title={Directional convergence and alignment in deep learning},
	author={Ji, Ziwei and Telgarsky, Matus},
	booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
	year={2020}
}
