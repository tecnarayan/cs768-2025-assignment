@inproceedings{subramanian2019reinforcement,
	author = {Subramanian, Jayakumar and Mahajan, Aditya},
	booktitle = {Proceedings of the 18th International Conference on Autonomous Agents and Multi Agent Systems},
	pages = {251--259},
	title = {Reinforcement learning in stationary mean-field games},
	year = {2019}}
@article{yardim2024mean,
  title={When is Mean-Field Reinforcement Learning Tractable and Relevant?},
  author={Yardim, Batuhan and Goldman, Artur and He, Niao},
  journal={arXiv preprint arXiv:2402.05757},
  year={2024}
}
@inproceedings{daskalakis2023complexity,
  title={The complexity of markov equilibrium in stochastic games},
  author={Daskalakis, Constantinos and Golowich, Noah and Zhang, Kaiqing},
  booktitle={The Thirty Sixth Annual Conference on Learning Theory},
  pages={4180--4234},
  year={2023},
  organization={PMLR}
}
@inproceedings{mao2022mean,
	author = {Mao, Weichao and Qiu, Haoran and Wang, Chen and Franke, Hubertus and Kalbarczyk, Zbigniew and Iyer, Ravi and Basar, Tamer},
	booktitle = {Advances in Neural Information Processing Systems},
	title = {A Mean-Field Game Approach to Cloud Resource Management with Function Approximation},
	year = {2022}
}

@inproceedings{huang2023statistical,
  title={On the statistical efficiency of mean-field reinforcement learning with general function approximation},
  author={Huang, Jiawei and Yardim, Batuhan and He, Niao},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={289--297},
  year={2024},
  organization={PMLR}
}


@article{djehiche2016mean,
  title={Mean-field-type games in engineering},
  author={Djehiche, Boualem and Tcheukam, Alain and Tembine, Hamidou},
  journal={arXiv preprint arXiv:1605.03281},
  year={2016}
}

@inproceedings{meriaux2012mean,
  title={Mean field energy games in wireless networks},
  author={M{\'e}riaux, Fran{\c{c}}ois and Varma, Vineeth and Lasaulce, Samson},
  booktitle={2012 conference record of the forty sixth Asilomar conference on signals, systems and computers (ASILOMAR)},
  pages={671--675},
  year={2012},
  organization={IEEE}
}

@article{gomes2015economic,
  title={Economic models and mean-field games theory},
  author={Gomes, Diogo A and Pimentel, Edgard A}
}

@article{carmona2020applications,
  title={Applications of mean field games in financial engineering and economic theory},
  author={Carmona, Rene},
  journal={arXiv preprint arXiv:2012.05237},
  year={2020}
}

@article{lauriere2022learning,
  title={Learning mean field games: A survey},
  author={Lauri{\`e}re, Mathieu and Perrin, Sarah and Geist, Matthieu and Pietquin, Olivier},
  journal={arXiv preprint arXiv:2205.12944},
  year={2022}
}

@article{subramanian2020multi,
  title={Multi type mean field reinforcement learning},
  author={Subramanian, Sriram Ganapathi and Poupart, Pascal and Taylor, Matthew E and Hegde, Nidhi},
  journal={arXiv preprint arXiv:2002.02513},
  year={2020}
}

@book{adams1995hitchhiker,
  title={The Hitchhiker's Guide to the Galaxy},
  author={Adams, D.},
  isbn={9781417642595},
  url={http://books.google.com/books?id=W-xMPgAACAAJ},
  year={1995},
  publisher={San Val}
}

@article{jin2021bellman,
  title={Bellman eluder dimension: New rich classes of rl problems, and sample-efficient algorithms},
  author={Jin, Chi and Liu, Qinghua and Miryoosefi, Sobhan},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13406--13418},
  year={2021}
}

@article{pasztor2021efficient,
  title={Efficient model-based multi-agent mean-field reinforcement learning},
  author={Pasztor, Barna and Bogunovic, Ilija and Krause, Andreas},
  journal={arXiv preprint arXiv:2107.04050},
  year={2021}
}

@inproceedings{du2021bilinear,
  title={Bilinear classes: A structural framework for provable generalization in rl},
  author={Du, Simon and Kakade, Sham and Lee, Jason and Lovett, Shachar and Mahajan, Gaurav and Sun, Wen and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={2826--2836},
  year={2021},
  organization={PMLR}
}

@inproceedings{jiang2017contextual,
  title={Contextual decision processes with low bellman rank are pac-learnable},
  author={Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
  booktitle={International Conference on Machine Learning},
  pages={1704--1713},
  year={2017},
  organization={PMLR}
}

@article{chen2022general,
  title={A General Framework for Sample-Efficient Function Approximation in Reinforcement Learning},
  author={Chen, Zixiang and Li, Chris Junchi and Yuan, Angela and Gu, Quanquan and Jordan, Michael I},
  journal={arXiv preprint arXiv:2209.15634},
  year={2022}
}

@article{xie2022role,
  title={The role of coverage in online reinforcement learning},
  author={Xie, Tengyang and Foster, Dylan J and Bai, Yu and Jiang, Nan and Kakade, Sham M},
  journal={arXiv preprint arXiv:2210.04157},
  year={2022}
}

@article{foster2021statistical,
  title={The statistical complexity of interactive decision making},
  author={Foster, Dylan J and Kakade, Sham M and Qian, Jian and Rakhlin, Alexander},
  journal={arXiv preprint arXiv:2112.13487},
  year={2021}
}

@article{uehara2021representation,
  title={Representation learning for online and offline rl in low-rank mdps},
  author={Uehara, Masatoshi and Zhang, Xuezhou and Sun, Wen},
  journal={arXiv preprint arXiv:2110.04652},
  year={2021}
}

@article{huang2022towards,
  title={Towards deployment-efficient reinforcement learning: Lower bound and optimality},
  author={Huang, Jiawei and Chen, Jinglin and Zhao, Li and Qin, Tao and Jiang, Nan and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:2202.06450},
  year={2022}
}

@inproceedings{modi2020sample,
  title={Sample complexity of reinforcement learning using linearly combined model ensembles},
  author={Modi, Aditya and Jiang, Nan and Tewari, Ambuj and Singh, Satinder},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2010--2020},
  year={2020},
  organization={PMLR}
}


@inproceedings{foster2023complexity,
  title={On the complexity of multi-agent decision making: From learning in games to partial monitoring},
  author={Foster, Dean and Foster, Dylan J and Golowich, Noah and Rakhlin, Alexander},
  booktitle={The Thirty Sixth Annual Conference on Learning Theory},
  pages={2678--2792},
  year={2023},
  organization={PMLR}
}

@article{tirinzoni2022complexity,
  title={On the Complexity of Representation Learning in Contextual Linear Bandits},
  author={Tirinzoni, Andrea and Pirotta, Matteo and Lazaric, Alessandro},
  journal={arXiv preprint arXiv:2212.09429},
  year={2022}
}

@article{osband2014model,
  title={Model-based reinforcement learning and the eluder dimension},
  author={Osband, Ian and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={27},
  year={2014}
}

@misc{levy2022eluderbased,
    title={Eluder-based Regret for Stochastic Contextual MDPs},
    author={Orin Levy and Asaf Cassel and Alon Cohen and Yishay Mansour},
    year={2022},
    eprint={2211.14932},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{yardim2022policy,
  title={Policy Mirror Ascent for Efficient and Independent Learning in Mean Field Games},
  author={Yardim, Batuhan and Cayci, Semih and Geist, Matthieu and He, Niao},
  journal={arXiv preprint arXiv:2212.14449},
  year={2022}
}

@article{guo2019learning,
  title={Learning mean-field games},
  author={Guo, Xin and Hu, Anran and Xu, Renyuan and Zhang, Junzi},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{uz2020reinforcement,
  title={Reinforcement learning in non-stationary discrete-time linear-quadratic mean-field games},
  author={uz Zaman, Muhammad Aneeq and Zhang, Kaiqing and Miehling, Erik and Ba»ôar, Tamer},
  booktitle={2020 59th IEEE Conference on Decision and Control (CDC)},
  pages={2278--2284},
  year={2020},
  organization={IEEE}
}


@article{zhang2022near,
  title={Near-Optimal Regret Bounds for Multi-batch Reinforcement Learning},
  author={Zhang, Zihan and Jiang, Yuhang and Zhou, Yuan and Ji, Xiangyang},
  journal={arXiv preprint arXiv:2210.08238},
  year={2022}
}

@article{russo2013eluder,
  title={Eluder dimension and the sample complexity of optimistic exploration},
  author={Russo, Daniel and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  year={2013}
}

@inproceedings{elie2020convergence,
    title={On the convergence of model free learning in mean field games},
    author={Elie, Romuald and Perolat, Julien and Lauri{\`e}re, Mathieu and Geist, Matthieu and Pietquin, Olivier},
    booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
    volume={34},
    pages={7143--7150},
    year={2020}
}

@article{angiuli2022unified,
  title={Unified reinforcement Q-learning for mean field game and control problems},
  author={Angiuli, Andrea and Fouque, Jean-Pierre and Lauri{\`e}re, Mathieu},
  journal={Mathematics of Control, Signals, and Systems},
  volume={34},
  number={2},
  pages={217--271},
  year={2022},
  publisher={Springer}
}

@inproceedings{yang2018mean,
  title={Mean field multi-agent reinforcement learning},
  author={Yang, Yaodong and Luo, Rui and Li, Minne and Zhou, Ming and Zhang, Weinan and Wang, Jun},
  booktitle={International conference on machine learning},
  pages={5571--5580},
  year={2018},
  organization={PMLR}
}

@article{achdou2022income,
  title={Income and wealth distribution in macroeconomics: A continuous-time approach},
  author={Achdou, Yves and Han, Jiequn and Lasry, Jean-Michel and Lions, Pierre-Louis and Moll, Benjamin},
  journal={The review of economic studies},
  volume={89},
  number={1},
  pages={45--86},
  year={2022},
  publisher={Oxford University Press}
}

@article{cousin2011mean,
  title={Mean field games and applications},
  author={Cousin, Areski and Cr{\'e}pey, St{\'e}phane and Gu{\'e}ant, Olivier and Hobson, David and Jeanblanc, Monique and Lasry, Jean-Michel and Laurent, Jean-Paul and Lions, Pierre-Louis and Tankov, Peter and Gu{\'e}ant, Olivier and others},
  journal={Paris-Princeton lectures on mathematical finance 2010},
  pages={205--266},
  year={2011},
  publisher={Springer}
}

@article{cardaliaguet2018mean,
  title={Mean field game of controls and an application to trade crowding},
  author={Cardaliaguet, Pierre and Lehalle, Charles-Albert},
  journal={Mathematics and Financial Economics},
  volume={12},
  pages={335--363},
  year={2018},
  publisher={Springer}
}

@article{angiuli2021reinforcement,
  title={Reinforcement learning for mean field games, with applications to economics},
  author={Angiuli, Andrea and Fouque, Jean-Pierre and Lauriere, Mathieu},
  journal={arXiv preprint arXiv:2106.13755},
  year={2021}
}

@article{de2019mean,
  title={A mean field game approach for distributed control of thermostatic loads acting in simultaneous energy-frequency response markets},
  author={De Paola, Antonio and Trovato, Vincenzo and Angeli, David and Strbac, Goran},
  journal={IEEE Transactions on Smart Grid},
  volume={10},
  number={6},
  pages={5987--5999},
  year={2019},
  publisher={IEEE}
}

@inproceedings{xie2021learning,
  title={Learning while playing in mean-field games: Convergence and optimality},
  author={Xie, Qiaomin and Yang, Zhuoran and Wang, Zhaoran and Minca, Andreea},
  booktitle={International Conference on Machine Learning},
  pages={11436--11447},
  year={2021},
  organization={PMLR}
}


@article{cui2023breaking,
  title={Breaking the Curse of Multiagents in a Large State Space: RL in Markov Games with Independent Linear Function Approximation},
  author={Cui, Qiwen and Zhang, Kaiqing and Du, Simon S},
  journal={arXiv preprint arXiv:2302.03673},
  year={2023}
}

@article{carmona2019model,
  title={Model-free mean-field reinforcement learning: mean-field MDP and mean-field Q-learning},
  author={Carmona, Ren{\'e} and Lauri{\`e}re, Mathieu and Tan, Zongjun},
  journal={arXiv preprint arXiv:1910.12802},
  year={2019}
}

@article{gu2021mean,
  title={Mean-field multi-agent reinforcement learning: A decentralized network approach},
  author={Gu, Haotian and Guo, Xin and Wei, Xiaoli and Xu, Renyuan},
  journal={arXiv preprint arXiv:2108.02731},
  year={2021}
}

@article{guo2022entropy,
  title={Entropy regularization for mean field games with learning},
  author={Guo, Xin and Xu, Renyuan and Zariphopoulou, Thaleia},
  journal={Mathematics of Operations Research},
  year={2022},
  publisher={INFORMS}
}

@article{wang2023breaking,
  title={Breaking the Curse of Multiagency: Provably Efficient Decentralized Multi-Agent RL with Function Approximation},
  author={Wang, Yuanhao and Liu, Qinghua and Bai, Yu and Jin, Chi},
  journal={arXiv preprint arXiv:2302.06606},
  year={2023}
}

@article{ni2022representation,
  title={Representation Learning for General-sum Low-rank Markov Games},
  author={Ni, Chengzhuo and Song, Yuda and Zhang, Xuezhou and Jin, Chi and Wang, Mengdi},
  journal={arXiv preprint arXiv:2210.16976},
  year={2022}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}

@inproceedings{zanette2020learning,
  title={Learning near optimal policies with low inherent bellman error},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={10978--10989},
  year={2020},
  organization={PMLR}
}


@article{huang2021towards,
  title={Towards general function approximation in zero-sum markov games},
  author={Huang, Baihe and Lee, Jason D and Wang, Zhaoran and Yang, Zhuoran},
  journal={arXiv preprint arXiv:2107.14702},
  year={2021}
}

@inproceedings{jin2022power,
  title={The power of exploiter: Provable multi-agent rl in large state spaces},
  author={Jin, Chi and Liu, Qinghua and Yu, Tiancheng},
  booktitle={International Conference on Machine Learning},
  pages={10251--10279},
  year={2022},
  organization={PMLR}
}

@article{modi2021model,
  title={Model-free representation learning and exploration in low-rank mdps},
  author={Modi, Aditya and Chen, Jinglin and Krishnamurthy, Akshay and Jiang, Nan and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2102.07035},
  year={2021}
}

@article{anahtarci2023q,
  title={Q-learning in regularized mean-field games},
  author={Anahtarci, Berkay and Kariksiz, Can Deha and Saldi, Naci},
  journal={Dynamic Games and Applications},
  volume={13},
  number={1},
  pages={89--117},
  year={2023},
  publisher={Springer}
}

@inproceedings{cui2021approximately,
  title={Approximately solving mean field games via entropy-regularized deep reinforcement learning},
  author={Cui, Kai and Koeppl, Heinz},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1909--1917},
  year={2021},
  organization={PMLR}
}

@article{agarwal2020flambe,
  title={Flambe: Structural complexity and representation learning of low rank mdps},
  author={Agarwal, Alekh and Kakade, Sham and Krishnamurthy, Akshay and Sun, Wen},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={20095--20107},
  year={2020}
}

@article{geist2021concave,
  title={Concave utility reinforcement learning: the mean-field game viewpoint},
  author={Geist, Matthieu and P{\'e}rolat, Julien and Lauri{\`e}re, Mathieu and Elie, Romuald and Perrin, Sarah and Bachem, Olivier and Munos, R{\'e}mi and Pietquin, Olivier},
  journal={arXiv preprint arXiv:2106.03787},
  year={2021}
}

@article{ismail2018survey,
  title={A survey and analysis of cooperative multi-agent robot systems: challenges and directions},
  author={Ismail, Zool Hilmi and Sariff, Nohaidda and Hurtado, E},
  journal={Applications of Mobile Robots},
  pages={8--14},
  year={2018},
  publisher={IntechOpen London, UK}
}

@article{shalev2016safe,
  title={Safe, multi-agent, reinforcement learning for autonomous driving},
  author={Shalev-Shwartz, Shai and Shammah, Shaked and Shashua, Amnon},
  journal={arXiv preprint arXiv:1610.03295},
  year={2016}
}

@article{lee2007multiagent,
  title={A multiagent approach to $ q $-learning for daily stock trading},
  author={Lee, Jae Won and Park, Jonghun and Jangmin, O and Lee, Jongwoo and Hong, Euyseok},
  journal={IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans},
  volume={37},
  number={6},
  pages={864--877},
  year={2007},
  publisher={IEEE}
}

@article{jin2021v,
  title={V-Learning--A Simple, Efficient, Decentralized Algorithm for Multiagent RL},
  author={Jin, Chi and Liu, Qinghua and Wang, Yuanhao and Yu, Tiancheng},
  journal={arXiv preprint arXiv:2110.14555},
  year={2021}
}

@article{lasry2007mean,
  title={Mean field games},
  author={Lasry, Jean-Michel and Lions, Pierre-Louis},
  journal={Japanese journal of mathematics},
  volume={2},
  number={1},
  pages={229--260},
  year={2007},
  publisher={Springer}
}

@article{huang2006large,
  title={Large population stochastic dynamic games: closed-loop McKean-Vlasov systems and the Nash certainty equivalence principle},
  author={Huang, Minyi and Malham{\'e}, Roland P and Caines, Peter E},
  year={2006}
}


@book{bensoussan2013mean,
  title={Mean field games and mean field type control theory},
  author={Bensoussan, Alain and Frehse, Jens and Yam, Phillip and others},
  volume={101},
  year={2013},
  publisher={Springer}
}

@article{perrin2020fictitious,
  title={Fictitious play for mean field games: Continuous time analysis and applications},
  author={Perrin, Sarah and P{\'e}rolat, Julien and Lauri{\`e}re, Mathieu and Geist, Matthieu and Elie, Romuald and Pietquin, Olivier},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13199--13213},
  year={2020}
}

@article{perolat2021scaling,
  title={Scaling up mean field games with online mirror descent},
  author={Perolat, Julien and Perrin, Sarah and Elie, Romuald and Lauri{\`e}re, Mathieu and Piliouras, Georgios and Geist, Matthieu and Tuyls, Karl and Pietquin, Olivier},
  journal={arXiv preprint arXiv:2103.00623},
  year={2021}
}

@phdthesis{shalev2007online,
  title={Online learning: Theory, algorithms, and applications},
  author={Shalev-Shwartz, Shai and Singer, Yoram},
  year={2007},
  school={Hebrew University}
}

@book{nesterov2018lectures,
  title={Lectures on convex optimization},
  author={Nesterov, Yurii and others},
  volume={137},
  year={2018},
  publisher={Springer}
}

@article{parikh2014proximal,
  title={Proximal algorithms},
  author={Parikh, Neal and Boyd, Stephen and others},
  journal={Foundations and trends in Optimization},
  volume={1},
  number={3},
  pages={127--239},
  year={2014},
  publisher={Now Publishers, Inc.}
}


@article{jin2018q,
  title={Is Q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{auer2008near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Auer, Peter and Jaksch, Thomas and Ortner, Ronald},
  journal={Advances in neural information processing systems},
  volume={21},
  year={2008}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={263--272},
  year={2017},
  organization={PMLR}
}

@inproceedings{sun2019model,
  title={Model-based rl in contextual decision processes: Pac bounds and exponential improvements over model-free approaches},
  author={Sun, Wen and Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
  booktitle={Conference on learning theory},
  pages={2898--2933},
  year={2019},
  organization={PMLR}
}

@article{qiao2022near,
  title={Near-Optimal Deployment Efficiency in Reward-Free Reinforcement Learning with Linear Function Approximation},
  author={Qiao, Dan and Wang, Yu-Xiang},
  journal={arXiv preprint arXiv:2210.00701},
  year={2022}
}

@article{bai2020near,
  title={Near-optimal reinforcement learning with self-play},
  author={Bai, Yu and Jin, Chi and Yu, Tiancheng},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={2159--2170},
  year={2020}
}

@inproceedings{chen2022almost,
  title={Almost optimal algorithms for two-player zero-sum linear mixture Markov games},
  author={Chen, Zixiang and Zhou, Dongruo and Gu, Quanquan},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={227--261},
  year={2022},
  organization={PMLR}
}

@article{zhang2019policy,
  title={Policy optimization provably converges to Nash equilibria in zero-sum linear quadratic games},
  author={Zhang, Kaiqing and Yang, Zhuoran and Basar, Tamer},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{zhang2021multi,
  title={Multi-agent reinforcement learning: A selective overview of theories and algorithms},
  author={Zhang, Kaiqing and Yang, Zhuoran and Ba{\c{s}}ar, Tamer},
  journal={Handbook of reinforcement learning and control},
  pages={321--384},
  year={2021},
  publisher={Springer}
}

@inproceedings{xie2020learning,
  title={Learning zero-sum simultaneous-move markov games using function approximation and correlated equilibrium},
  author={Xie, Qiaomin and Chen, Yudong and Wang, Zhaoran and Yang, Zhuoran},
  booktitle={Conference on learning theory},
  pages={3674--3682},
  year={2020},
  organization={PMLR}
}


@article{mahajan2021reinforcement,
  title={Reinforcement learning in stationary mean-field games},
  author={Mahajan, Aditya},
  year={2021}
}

@inproceedings{agarwal2020model,
  title={Model-based reinforcement learning with a generative model is minimax optimal},
  author={Agarwal, Alekh and Kakade, Sham and Yang, Lin F},
  booktitle={Conference on Learning Theory},
  pages={67--83},
  year={2020},
  organization={PMLR}
}

@inproceedings{xiong2022self,
  title={A Self-Play Posterior Sampling Algorithm for Zero-Sum Markov Games},
  author={Xiong, Wei and Zhong, Han and Shi, Chengshuai and Shen, Cong and Zhang, Tong},
  booktitle={International Conference on Machine Learning},
  pages={24496--24523},
  year={2022},
  organization={PMLR}
}

@article{zhong2022posterior,
  title={A posterior sampling framework for interactive decision making},
  author={Zhong, Han and Xiong, Wei and Zheng, Sirui and Wang, Liwei and Wang, Zhaoran and Yang, Zhuoran and Zhang, Tong},
  journal={arXiv preprint arXiv:2211.01962},
  year={2022}
}

@inproceedings{ayoub2020model,
  title={Model-based reinforcement learning with value-targeted regression},
  author={Ayoub, Alex and Jia, Zeyu and Szepesvari, Csaba and Wang, Mengdi and Yang, Lin},
  booktitle={International Conference on Machine Learning},
  pages={463--474},
  year={2020},
  organization={PMLR}
}

@inproceedings{liu2022partially,
  title={When is partially observable reinforcement learning not scary?},
  author={Liu, Qinghua and Chung, Alan and Szepesv{\'a}ri, Csaba and Jin, Chi},
  booktitle={Conference on Learning Theory},
  pages={5175--5220},
  year={2022},
  organization={PMLR}
}

@article{liu2022sample,
  title={Sample-efficient reinforcement learning of partially observable markov games},
  author={Liu, Qinghua and Szepesv{\'a}ri, Csaba and Jin, Chi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={18296--18308},
  year={2022}
}

@article{saldi2018markov,
  title={Markov--Nash equilibria in mean-field games with discounted cost},
  author={Saldi, Naci and Basar, Tamer and Raginsky, Maxim},
  journal={SIAM Journal on Control and Optimization},
  volume={56},
  number={6},
  pages={4256--4287},
  year={2018},
  publisher={SIAM}
}

@article{ghosh2020model,
  title={Model free reinforcement learning algorithm for stationary mean field equilibrium for multiple types of agents},
  author={Ghosh, Arnob and Aggarwal, Vaneet},
  journal={arXiv preprint arXiv:2012.15377},
  year={2020}
}

@inproceedings{li2019efficient,
  title={Efficient ridesharing order dispatching with mean field multi-agent reinforcement learning},
  author={Li, Minne and Qin, Zhiwei and Jiao, Yan and Yang, Yaodong and Wang, Jun and Wang, Chenxi and Wu, Guobin and Ye, Jieping},
  booktitle={The world wide web conference},
  pages={983--994},
  year={2019}
}

@article{uz2023reinforcement,
  title={Reinforcement learning for non-stationary discrete-time linear--quadratic mean-field games in multiple populations},
  author={uz Zaman, Muhammad Aneeq and Miehling, Erik and Ba{\c{s}}ar, Tamer},
  journal={Dynamic Games and Applications},
  volume={13},
  number={1},
  pages={118--164},
  year={2023},
  publisher={Springer}
}

@article{moon2018linear,
  title={Linear quadratic mean field Stackelberg differential games},
  author={Moon, Jun and Ba{\c{s}}ar, Tamer},
  journal={Automatica},
  volume={97},
  pages={200--213},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{vasal2022master,
  title={Master Equation for Discrete-Time Stackelberg Mean Field Games with a Single Leader},
  author={Vasal, Deepanshu and Berry, Randall},
  booktitle={2022 IEEE 61st Conference on Decision and Control (CDC)},
  pages={5529--5535},
  year={2022},
  organization={IEEE}
}

@inproceedings{mishra2020model,
  title={Model-free reinforcement learning for non-stationary mean field games},
  author={Mishra, Rajesh K and Vasal, Deepanshu and Vishwanath, Sriram},
  booktitle={2020 59th IEEE Conference on Decision and Control (CDC)},
  pages={1032--1037},
  year={2020},
  organization={IEEE}
}

@article{zhang2023learning,
  title={Learning Regularized Monotone Graphon Mean-Field Games},
  author={Zhang, Fengzhuo and Tan, Vincent YF and Wang, Zhaoran and Yang, Zhuoran},
  journal={arXiv preprint arXiv:2310.08089},
  year={2023}
}

@article{huang2021dynamic,
  title={Dynamic driving and routing games for autonomous vehicles on networks: A mean field game approach},
  author={Huang, Kuang and Chen, Xu and Di, Xuan and Du, Qiang},
  journal={Transportation Research Part C: Emerging Technologies},
  volume={128},
  pages={103189},
  year={2021},
  publisher={Elsevier}
}