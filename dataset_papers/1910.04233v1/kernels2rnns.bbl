\begin{thebibliography}{10}

\bibitem{Poggio15}
Fabio Anselmi, Lorenzo Rosasco, Cheston Tan, and Tomaso Poggio.
\newblock {Deep Convolutional Networks are Hierarchical Kernel Machines}.
\newblock {\em arXiv:1508.01084}, 2015.

\bibitem{layer_norm}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E. Hinton.
\newblock {Layer Normalization}.
\newblock {\em arXiv:1607.06450}, 2016.

\bibitem{st_rnn}
David Balduzzi and Muhammad Ghifary.
\newblock {Strongly-Typed Recurrent Neural Networks}.
\newblock {\em International Conference on Machine Learning}, 2016.

\bibitem{RKHS}
Alain Berlinet and Christine Thomas-Agnan.
\newblock {Reproducing Kernel Hilbert spaces in Probability and Statistics}.
\newblock {\em Kluwer Publishers}, 2004.

\bibitem{Bietti}
Alberto Bietti and Julien Mairal.
\newblock {Invariance and Stability of Deep Convolutional Representations}.
\newblock {\em Neural Information Processing Systems}, 2017.

\bibitem{QRNN}
James Bradbury, Stephen Merity, Caiming Xiong, and Richard Socher.
\newblock Quasi-recurrent neural networks.
\newblock {\em International Conference of Learning Representations}, 2017.

\bibitem{Best_Both}
Mia~Xu Chen, Orhan Firat, Ankur Bapna, Melvin Johnson, Wolfgang Macherey,
  George Foster, Llion Jones, Niki Parmar, Mike Schuster, Zhifeng Chen, Yonghui
  Wu, and Macduff Hughes.
\newblock {The Best of Both Worlds: Combining Recent Advances in Neural Machine
  Translation}.
\newblock {\em arXiv:1804.09849v2}, 2018.

\bibitem{cheng2016}
Jianpeng Cheng and Mirella Lapata.
\newblock {Neural Summarization by Extracting Sentences and Words}.
\newblock {\em Association for Computational Linguistics}, 2016.

\bibitem{gru}
Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi
  Bougares, Holger Schwenk, and Yoshua Bengio.
\newblock {Learning Phrase Representations using RNN Encoder-Decoder for
  Statistical Machine Translation}.
\newblock {\em Empirical Methods in Natural Language Processing}, 2014.

\bibitem{gatedCNN}
Yann~N. Dauphin, Angela Fan, Michael Auli, and David Grangier.
\newblock {Language Modeling with Gated Convolutional Networks}.
\newblock {\em International Conference on Machine Learning}, 2017.

\bibitem{Genton2001}
Marc~G. Genton.
\newblock {Classes of Kernels for Machine Learning: A Statistics Perspective}.
\newblock {\em Journal of Machine Learning Research}, 2001.

\bibitem{QandA}
David Golub and Xiaodong He.
\newblock {Character-Level Question Answering with Attention}.
\newblock {\em Empirical Methods in Natural Language Processing}, 2016.

\bibitem{odyssey}
Klaus Greff, Rupesh~Kumar Srivastava, Jan Koutn{\'{i}}k, Bas~R. Steunebrink,
  and J{\"{u}}rgen Schmidhuber.
\newblock {LSTM: A Search Space Odyssey}.
\newblock {\em Transactions on Neural Networks and Learning Systems}, 2017.

\bibitem{rkm}
Michiel Hermans and Benjamin Schrauwen.
\newblock {Recurrent Kernel Machines: Computing with Infinite Echo State
  Networks}.
\newblock {\em Neural Computation}, 2012.

\bibitem{lstm}
Sepp Hochreiter and J{\"{u}}rgen Schmidhuber.
\newblock {Long Short-Term Memory}.
\newblock {\em Neural Computation}, 1997.

\bibitem{RNN_arch}
Rafal Jozefowicz, Wojciech Zaremba, and Ilya Sutskever.
\newblock {An Empirical Exploration of Recurrent Network Architectures}.
\newblock {\em International Conference on Machine Learning}, 2015.

\bibitem{kim2014convolutional}
Yoon Kim.
\newblock {Convolutional Neural Networks for Sentence Classification}.
\newblock {\em Empirical Methods in Natural Language Processing}, 2014.

\bibitem{CNN_text_OG}
Yann LeCun and Yoshua Bengio.
\newblock {Convolutional Networks for Images, Speech, and Time Series}.
\newblock {\em The Handbook of Brain Theory and Neural Networks}, 1995.

\bibitem{CNN}
Yann LeCun, L{\'{e}}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock {Gradient-based Learning Applied to Document Recognition}.
\newblock {\em Proceedings of IEEE}, 1998.

\bibitem{RAN}
Kenton Lee, Omer Levy, and Luke Zettlemoyer.
\newblock {Recurrent Additive Networks}.
\newblock {\em arXiv:1705.07393v2}, 2017.

\bibitem{string_kernel}
Tao Lei, Wengong Jin, Regina Barzilay, and Tommi Jaakkola.
\newblock {Deriving Neural Architectures from Sequence and Graph Kernels}.
\newblock {\em International Conference on Machine Learning}, 2017.

\bibitem{syncnet}
Yitong Li, Michael Murias, Samantha Major, Geraldine Dawson, Kafui Dzirasa,
  Lawrence Carin, and David~E. Carlson.
\newblock {Targeting EEG/LFP Synchrony with Neural Nets}.
\newblock {\em Neural Information Processing Systems}, 2017.

\bibitem{Mairal}
Julien Mairal.
\newblock {End-to-End Kernel Learning with Supervised Convolutional Kernel
  Networks}.
\newblock {\em Neural Information Processing Systems}, 2016.

\bibitem{ptb}
Mitchell~P. Marcus, Beatrice Santorini, and Mary~Ann Marcinkiewicz.
\newblock {Building a Large Annotated Corpus of English: The Penn Treebank}.
\newblock {\em Association for Computational Linguistics}, 1993.

\bibitem{awd_lstm}
Stephen Merity, Nitish~Shirish Keskar, and Richard Socher.
\newblock {Regularizing and Optimizing LSTM Language Models}.
\newblock {\em International Conference on Learning Representations}, 2018.

\bibitem{wikitext}
Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher.
\newblock {Pointer Sentinel Mixture Models}.
\newblock {\em International Conference of Learning Representations}, 2017.

\bibitem{glove}
Jeffrey Pennington, Richard Socher, and Christopher~D. Manning.
\newblock {GloVe: Global Vectors for Word Representation}.
\newblock {\em Empirical Methods in Natural Language Processing}, 2014.

\bibitem{roth2018kernel}
Christopher Roth, Ingmar Kanitscheider, and Ila Fiete.
\newblock Kernel rnn learning (kernl).
\newblock {\em International Conference Learning Representation}, 2019.

\bibitem{kernels}
Bernhard Scholkopf and Alexander~J. Smola.
\newblock Learning with kernels.
\newblock {\em MIT Press}, 2002.

\bibitem{warp}
Corentin Tallec and Yann Ollivier.
\newblock {Can Recurrent Neural Networks Warp Time?}
\newblock {\em International Conference of Learning Representations}, 2018.

\bibitem{wavenet}
Aaron van~den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals,
  Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu.
\newblock {WaveNet: A Generative Model for Raw Audio}.
\newblock {\em arXiv:1609.03499}, 2016.

\bibitem{van2013further}
Jordy van Enkhuizen, Arpi Minassian, and Jared~W Young.
\newblock {Further evidence for Clock$\Delta$19 mice as a model for bipolar
  disorder mania using cross-species tests of exploration and sensorimotor
  gating}.
\newblock {\em Behavioural Brain Research}, 249:44--54, 2013.

\bibitem{transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock {Attention Is All You Need}.
\newblock {\em Neural Information Processing Systems}, 2017.

\bibitem{leam}
Guoyin Wang, Chunyuan Li, Wenlin Wang, Yizhe Zhang, Dinghan Shen, Xinyuan
  Zhang, Ricardo Henao, and Lawrence Carin.
\newblock {Joint Embedding of Words and Labels for Text Classification}.
\newblock {\em Association for Computational Linguistics}, 2018.

\bibitem{wang2016}
Jin Wang, Liang-Chih Yu, K.~Robert Lai, and Xuejie Zhang.
\newblock {Dimensional Sentiment Analysis Using a Regional CNN-LSTM Model}.
\newblock {\em Association for Computational Linguistics}, 2016.

\bibitem{DKL}
Andrew~Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric~P. Xing.
\newblock {Deep Kernel Learning}.
\newblock {\em International Conference on Artificial Intelligence and
  Statistics}, 2016.

\bibitem{CNN_text}
Xiang Zhang, Junbo Zhao, and Yann LeCun.
\newblock {Character-level Convolutional Networks for Text Classification}.
\newblock {\em Neural Information Processing Systems}, 2015.

\bibitem{zhou2015}
Chunting Zhou, Chonglin Sun, Zhiyuan Liu, and Francis~C.M. Lau.
\newblock {A C-LSTM Neural Network for Text Classification}.
\newblock {\em arXiv:1511.08630}, 2015.

\end{thebibliography}
