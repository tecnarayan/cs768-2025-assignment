@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@article{rame2023rewarded,
  title={Rewarded soups: towards Pareto-optimal alignment by interpolating weights fine-tuned on diverse rewards},
  author={Rame, Alexandre and Couairon, Guillaume and Shukor, Mustafa and Dancette, Corentin and Gaya, Jean-Baptiste and Soulier, Laure and Cord, Matthieu},
  journal={arXiv preprint arXiv:2306.04488},
  year={2023}
}

@article{zhou2023beyond,
  title={Beyond One-Preference-for-All: Multi-Objective Direct Preference Optimization},
  author={Zhou, Zhanhui and Liu, Jie and Yang, Chao and Shao, Jing and Liu, Yu and Yue, Xiangyu and Ouyang, Wanli and Qiao, Yu},
  journal={arXiv preprint arXiv:2310.03708},
  year={2023}
}



@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{openai2023gpt,
  title={Gpt-4 technical report. arxiv 2303.08774},
  author={OpenAI, R},
  journal={View in Article},
  volume={2},
  pages={13},
  year={2023}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{sanh2021multitask,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  journal={arXiv preprint arXiv:2110.08207},
  year={2021}
}


@article{wei2021finetuned,
  title={Finetuned language models are zero-shot learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  journal={arXiv preprint arXiv:2109.01652},
  year={2021}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{dong2023raft,
  title={Raft: Reward ranked finetuning for generative foundation model alignment},
  author={Dong, Hanze and Xiong, Wei and Goyal, Deepanshu and Pan, Rui and Diao, Shizhe and Zhang, Jipeng and Shum, Kashun and Zhang, Tong},
  journal={arXiv preprint arXiv:2304.06767},
  year={2023}
}

@article{yuan2023rrhf,
  title={Rrhf: Rank responses to align language models with human feedback without tears},
  author={Yuan, Zheng and Yuan, Hongyi and Tan, Chuanqi and Wang, Wei and Huang, Songfang and Huang, Fei},
  journal={arXiv preprint arXiv:2304.05302},
  year={2023}
}

@article{gulcehre2023reinforced,
  title={Reinforced self-training (rest) for language modeling},
  author={Gulcehre, Caglar and Paine, Tom Le and Srinivasan, Srivatsan and Konyushkova, Ksenia and Weerts, Lotte and Sharma, Abhishek and Siddhant, Aditya and Ahern, Alex and Wang, Miaosen and Gu, Chenjie and others},
  journal={arXiv preprint arXiv:2308.08998},
  year={2023}
}

@article{xiong2023gibbs,
  title={Gibbs Sampling from Human Feedback: A Provable KL-constrained Framework for RLHF},
  author={Xiong, Wei and Dong, Hanze and Ye, Chenlu and Zhong, Han and Jiang, Nan and Zhang, Tong},
  journal={arXiv preprint arXiv:2312.11456},
  year={2023}
}

@article{liu2023statistical,
  title={Statistical rejection sampling improves preference optimization},
  author={Liu, Tianqi and Zhao, Yao and Joshi, Rishabh and Khalman, Misha and Saleh, Mohammad and Liu, Peter J and Liu, Jialu},
  journal={arXiv preprint arXiv:2309.06657},
  year={2023}
}

@article{rafailov2023direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea},
  journal={arXiv preprint arXiv:2305.18290},
  year={2023}
}

@article{wang2023beyond,
  title={Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints},
  author={Wang, Chaoqi and Jiang, Yibo and Yang, Chenghao and Liu, Han and Chen, Yuxin},
  journal={arXiv preprint arXiv:2309.16240},
  year={2023}
}

@article{peng2023instruction,
  title={Instruction tuning with gpt-4},
  author={Peng, Baolin and Li, Chunyuan and He, Pengcheng and Galley, Michel and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2304.03277},
  year={2023}
}

@article{zhang2023llama,
  title={Llama-adapter: Efficient fine-tuning of language models with zero-init attention},
  author={Zhang, Renrui and Han, Jiaming and Zhou, Aojun and Hu, Xiangfei and Yan, Shilin and Lu, Pan and Li, Hongsheng and Gao, Peng and Qiao, Yu},
  journal={arXiv preprint arXiv:2303.16199},
  year={2023}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}


@article{wu2023fine,
  title={Fine-Grained Human Feedback Gives Better Rewards for Language Model Training},
  author={Wu, Zeqiu and Hu, Yushi and Shi, Weijia and Dziri, Nouha and Suhr, Alane and Ammanabrolu, Prithviraj and Smith, Noah A and Ostendorf, Mari and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2306.01693},
  year={2023}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{li2020deep,
  title={Deep reinforcement learning for multiobjective optimization},
  author={Li, Kaiwen and Zhang, Tao and Wang, Rui},
  journal={IEEE transactions on cybernetics},
  volume={51},
  number={6},
  pages={3103--3114},
  year={2020},
  publisher={IEEE}
}

@article{hu2023aligning,
  title={Aligning language models with offline reinforcement learning from human feedback},
  author={Hu, Jian and Tao, Li and Yang, June and Zhou, Chandler},
  journal={arXiv preprint arXiv:2308.12050},
  year={2023}
}


@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={15084--15097},
  year={2021}
}

@article{hayes2022practical,
  title={A practical guide to multi-objective reinforcement learning and planning},
  author={Hayes, Conor F and R{\u{a}}dulescu, Roxana and Bargiacchi, Eugenio and K{\"a}llstr{\"o}m, Johan and Macfarlane, Matthew and Reymond, Mathieu and Verstraeten, Timothy and Zintgraf, Luisa M and Dazeley, Richard and Heintz, Fredrik and others},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={36},
  number={1},
  pages={26},
  year={2022},
  publisher={Springer}
}

@article{roijers2013survey,
  title={A survey of multi-objective sequential decision-making},
  author={Roijers, Diederik M and Vamplew, Peter and Whiteson, Shimon and Dazeley, Richard},
  journal={Journal of Artificial Intelligence Research},
  volume={48},
  pages={67--113},
  year={2013}
}

@article{van2014multi,
  title={Multi-objective reinforcement learning using sets of pareto dominating policies},
  author={Van Moffaert, Kristof and Now{\'e}, Ann},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={3483--3512},
  year={2014},
  publisher={JMLR. org}
}

@inproceedings{barrett2008learning,
  title={Learning all optimal policies with multiple criteria},
  author={Barrett, Leon and Narayanan, Srini},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={41--47},
  year={2008}
}

@article{munos2023nash,
  title={Nash Learning from Human Feedback},
  author={Munos, R{\'e}mi and Valko, Michal and Calandriello, Daniele and Azar, Mohammad Gheshlaghi and Rowland, Mark and Guo, Zhaohan Daniel and Tang, Yunhao and Geist, Matthieu and Mesnard, Thomas and Michi, Andrea and others},
  journal={arXiv preprint arXiv:2312.00886},
  year={2023}
}

@article{pacchiano2021dueling,
  title={Dueling rl: reinforcement learning with trajectory preferences},
  author={Pacchiano, Aldo and Saha, Aadirupa and Lee, Jonathan},
  journal={arXiv preprint arXiv:2111.04850},
  year={2021}
}

@inproceedings{chen2022human,
  title={Human-in-the-loop: Provably efficient preference-based reinforcement learning with general function approximation},
  author={Chen, Xiaoyu and Zhong, Han and Yang, Zhuoran and Wang, Zhaoran and Wang, Liwei},
  booktitle={International Conference on Machine Learning},
  pages={3773--3793},
  year={2022},
  organization={PMLR}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}



@article{stiennon2020learning,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}

@inproceedings{wolf2020transformers,
  title={Transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  booktitle={Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations},
  pages={38--45},
  year={2020}
}


@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9650--9660},
  year={2021}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{dong2023steerlm,
  title={SteerLM: Attribute Conditioned SFT as an (User-Steerable) Alternative to RLHF},
  author={Dong, Yi and Wang, Zhilin and Sreedhar, Makesh Narsimhan and Wu, Xianchao and Kuchaiev, Oleksii},
  journal={arXiv preprint arXiv:2310.05344},
  year={2023}
}

@article{vamplew2018human,
  title={Human-aligned artificial intelligence is a multiobjective problem},
  author={Vamplew, Peter and Dazeley, Richard and Foale, Cameron and Firmin, Sally and Mummery, Jane},
  journal={Ethics and Information Technology},
  volume={20},
  pages={27--40},
  year={2018},
  publisher={Springer}
}



@article{chen2020recall,
  title={Recall and learn: Fine-tuning deep pretrained language models with less forgetting},
  author={Chen, Sanyuan and Hou, Yutai and Cui, Yiming and Che, Wanxiang and Liu, Ting and Yu, Xiangzhan},
  journal={arXiv preprint arXiv:2004.12651},
  year={2020}
}

@article{korbak2022reinforcement,
  title={On reinforcement learning and distribution matching for fine-tuning language models with no catastrophic forgetting},
  author={Korbak, Tomasz and Elsahar, Hady and Kruszewski, Germ{\'a}n and Dymetman, Marc},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16203--16220},
  year={2022}
}

@article{nichol2021glide,
  title={Glide: Towards photorealistic image generation and editing with text-guided diffusion models},
  author={Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  journal={arXiv preprint arXiv:2112.10741},
  year={2021}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@misc{vonwerra2022trl,
  author = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang},
  title = {TRL: Transformer Reinforcement Learning},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/huggingface/trl}}
}

@article{black2023training,
  title={Training diffusion models with reinforcement learning},
  author={Black, Kevin and Janner, Michael and Du, Yilun and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2305.13301},
  year={2023}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@misc{von2022diffusers,
  title={Diffusers: State-of-the-art diffusion models},
  author={von Platen, Patrick and Patil, Suraj and Lozhkov, Anton and Cuenca, Pedro and Lambert, Nathan and Rasul, Kashif and Davaadorj, Mishig and Wolf, Thomas},
  year={2022}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@inproceedings{murray2012ava,
  title={AVA: A large-scale database for aesthetic visual analysis},
  author={Murray, Naila and Marchesotti, Luca and Perronnin, Florent},
  booktitle={2012 IEEE conference on computer vision and pattern recognition},
  pages={2408--2415},
  year={2012},
  organization={IEEE}
}

@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25278--25294},
  year={2022}
}

@article{radford2018improving,
  added-at = {2020-07-14T16:49:49.000+0200},
  author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  biburl = {https://www.bibsonomy.org/bibtex/273ced32c0d4588eb95b6986dc2c8147c/jonaskaiser},
  interhash = {5c343ed9a31ac52fd17a898f72af228f},
  intrahash = {73ced32c0d4588eb95b6986dc2c8147c},
  keywords = {},
  timestamp = {2020-07-14T16:49:49.000+0200},
  title = {Improving language understanding by generative pre-training},
  year = 2018
}

@article{radford2019language,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}

@article{wang2023helpsteer,
  title={HelpSteer: Multi-attribute Helpfulness Dataset for SteerLM},
  author={Wang, Zhilin and Dong, Yi and Zeng, Jiaqi and Adams, Virginia and Sreedhar, Makesh Narsimhan and Egert, Daniel and Delalleau, Olivier and Scowcroft, Jane Polak and Kant, Neel and Swope, Aidan and others},
  journal={arXiv preprint arXiv:2311.09528},
  year={2023}
}
@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen P and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

@article{kumar2019reward,
  title={Reward-conditioned policies},
  author={Kumar, Aviral and Peng, Xue Bin and Levine, Sergey},
  journal={arXiv preprint arXiv:1912.13465},
  year={2019}
}

@article{emmons2021rvs,
  title={Rvs: What is essential for offline rl via supervised learning?},
  author={Emmons, Scott and Eysenbach, Benjamin and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2112.10751},
  year={2021}
}

@article{brandfonbrener2022does,
  title={When does return-conditioned supervised learning work for offline reinforcement learning?},
  author={Brandfonbrener, David and Bietti, Alberto and Buckman, Jacob and Laroche, Romain and Bruna, Joan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={1542--1553},
  year={2022}
}


@article{ghosh2019learning,
  title={Learning to reach goals via iterated supervised learning},
  author={Ghosh, Dibya and Gupta, Abhishek and Reddy, Ashwin and Fu, Justin and Devin, Coline and Eysenbach, Benjamin and Levine, Sergey},
  journal={arXiv preprint arXiv:1912.06088},
  year={2019}
}

@article{yang2022rethinking,
  title={Rethinking goal-conditioned supervised learning and its connection to offline rl},
  author={Yang, Rui and Lu, Yiming and Li, Wenzhe and Sun, Hao and Fang, Meng and Du, Yali and Li, Xiu and Han, Lei and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2202.04478},
  year={2022}
}

@article{lu2022quark,
  title={Quark: Controllable text generation with reinforced unlearning},
  author={Lu, Ximing and Welleck, Sean and Hessel, Jack and Jiang, Liwei and Qin, Lianhui and West, Peter and Ammanabrolu, Prithviraj and Choi, Yejin},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27591--27609},
  year={2022}
}

@inproceedings{yang2023essential,
  title={What is essential for unseen goal generalization of offline goal-conditioned RL?},
  author={Yang, Rui and Yong, Lin and Ma, Xiaoteng and Hu, Hao and Zhang, Chongjie and Zhang, Tong},
  booktitle={International Conference on Machine Learning},
  pages={39543--39571},
  year={2023},
  organization={PMLR}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{li2020generalized,
  title={Generalized hindsight for reinforcement learning},
  author={Li, Alexander and Pinto, Lerrel and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7754--7767},
  year={2020}
}

@article{zhang2023wisdom,
  title={The Wisdom of Hindsight Makes Language Models Better Instruction Followers},
  author={Zhang, Tianjun and Liu, Fangchen and Wong, Justin and Abbeel, Pieter and Gonzalez, Joseph E},
  journal={arXiv preprint arXiv:2302.05206},
  year={2023}
}

@article{ramnath2023tailoring,
  title={Tailoring self-rationalizers with multi-reward distillation},
  author={Ramnath, Sahana and Joshi, Brihi and Hallinan, Skyler and Lu, Ximing and Li, Liunian Harold and Chan, Aaron and Hessel, Jack and Choi, Yejin and Ren, Xiang},
  journal={arXiv preprint arXiv:2311.02805},
  year={2023}
}

@article{yang2021mher,
  title={MHER: Model-based hindsight experience replay},
  author={Yang, Rui and Fang, Meng and Han, Lei and Du, Yali and Luo, Feng and Li, Xiu},
  journal={arXiv preprint arXiv:2107.00306},
  year={2021}
}