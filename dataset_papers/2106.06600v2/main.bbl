\begin{thebibliography}{80}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahmed et~al.(2018)Ahmed, Kumar, Karkare, Kar, and
  Gulwani]{ahmed2018compilation}
Ahmed, U.~Z., Kumar, P., Karkare, A., Kar, P., and Gulwani, S.
\newblock Compilation error repair: for the student programs, from the student
  programs.
\newblock In \emph{International Conference on Software Engineering (ICSE)},
  pp.\  78--87, 2018.

\bibitem[Antoniou et~al.(2017)Antoniou, Storkey, and Edwards]{antoniou2017data}
Antoniou, A., Storkey, A., and Edwards, H.
\newblock Data augmentation generative adversarial networks.
\newblock \emph{arXiv preprint arXiv:1711.04340}, 2017.

\bibitem[Artetxe et~al.(2018{\natexlab{a}})Artetxe, Labaka, and
  Agirre]{artetxe2018unsupervised}
Artetxe, M., Labaka, G., and Agirre, E.
\newblock Unsupervised statistical machine translation.
\newblock \emph{arXiv preprint arXiv:1809.01272}, 2018{\natexlab{a}}.

\bibitem[Artetxe et~al.(2018{\natexlab{b}})Artetxe, Labaka, Agirre, and
  Cho]{artetxe2017unsupervised}
Artetxe, M., Labaka, G., Agirre, E., and Cho, K.
\newblock Unsupervised neural machine translation.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018{\natexlab{b}}.

\bibitem[Bader et~al.(2019)Bader, Scott, Pradel, and Chandra]{bader2019getafix}
Bader, J., Scott, A., Pradel, M., and Chandra, S.
\newblock Getafix: Learning to fix bugs automatically.
\newblock \emph{Proceedings of the ACM on Programming Languages}, 3\penalty0
  (OOPSLA):\penalty0 1--27, 2019.

\bibitem[Bellemare et~al.(2020)Bellemare, Candido, Castro, Gong, Machado,
  Moitra, Ponda, and Wang]{bellemare2020autonomous}
Bellemare, M.~G., Candido, S., Castro, P.~S., Gong, J., Machado, M.~C., Moitra,
  S., Ponda, S.~S., and Wang, Z.
\newblock Autonomous navigation of stratospheric balloons using reinforcement
  learning.
\newblock \emph{Nature}, 588, 2020.

\bibitem[Berant et~al.(2013)Berant, Chou, Frostig, and
  Liang]{berant2013semantic}
Berant, J., Chou, A., Frostig, R., and Liang, P.
\newblock Semantic parsing on freebase from question-answer pairs.
\newblock In \emph{Empirical Methods in Natural Language Processing (EMNLP)},
  2013.

\bibitem[Berthelot et~al.(2019)Berthelot, Carlini, Goodfellow, Papernot,
  Oliver, and Raffel]{berthelot2019mixmatch}
Berthelot, D., Carlini, N., Goodfellow, I., Papernot, N., Oliver, A., and
  Raffel, C.~A.
\newblock Mixmatch: A holistic approach to semi-supervised learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.

\bibitem[Blum \& Mitchell(1998)Blum and Mitchell]{blum1998combining}
Blum, A. and Mitchell, T.
\newblock Combining labeled and unlabeled data with co-training.
\newblock In \emph{Conference on computational learning theory}, 1998.

\bibitem[Chen et~al.(2019)Chen, Kommrusch, Tufano, Pouchet, Poshyvanyk, and
  Monperrus]{chen2019sequencer}
Chen, Z., Kommrusch, S.~J., Tufano, M., Pouchet, L.-N., Poshyvanyk, D., and
  Monperrus, M.
\newblock Sequencer: Sequence-to-sequence learning for end-to-end program
  repair.
\newblock \emph{IEEE Transactions on Software Engineering}, 2019.

\bibitem[Daume~III \& Marcu(2006)Daume~III and Marcu]{daume2006domain}
Daume~III, H. and Marcu, D.
\newblock Domain adaptation for statistical classifiers.
\newblock \emph{Journal of artificial Intelligence research}, 2006.

\bibitem[Dinella et~al.(2020)Dinella, Dai, Li, Naik, Song, and
  Wang]{dinella2020hoppity}
Dinella, E., Dai, H., Li, Z., Naik, M., Song, L., and Wang, K.
\newblock Hoppity: Learning graph transformations to detect and fix bugs in
  programs.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020.

\bibitem[Ding et~al.(2020)Ding, Ray, Devanbu, and
  Hellendoorn]{ding2020patching}
Ding, Y., Ray, B., Devanbu, P., and Hellendoorn, V.~J.
\newblock Patching as translation: the data and the metaphor.
\newblock In \emph{Automated Software Engineering (ASE)}, 2020.

\bibitem[Erhan et~al.(2010)Erhan, Courville, Bengio, and
  Vincent]{erhan2010does}
Erhan, D., Courville, A., Bengio, Y., and Vincent, P.
\newblock Why does unsupervised pre-training help deep learning?
\newblock In \emph{Artificial Intelligence and Statistics (AISTATS)}, pp.\
  201--208, 2010.

\bibitem[Fang et~al.(2013)Fang, Xu, and Rockmore]{fang2013unbiased}
Fang, C., Xu, Y., and Rockmore, D.~N.
\newblock Unbiased metric learning: On the utilization of multiple datasets and
  web images for softening bias.
\newblock In \emph{International Conference on Computer Vision (ICCV)}, 2013.

\bibitem[Ganin \& Lempitsky(2015)Ganin and Lempitsky]{ganin2015unsupervised}
Ganin, Y. and Lempitsky, V.
\newblock Unsupervised domain adaptation by backpropagation.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2015.

\bibitem[Gupta et~al.(2017)Gupta, Pal, Kanade, and Shevade]{gupta2017deepfix}
Gupta, R., Pal, S., Kanade, A., and Shevade, S.~K.
\newblock Deepfix: Fixing common {C} language errors by deep learning.
\newblock In \emph{Association for the Advancement of Artificial Intelligence
  (AAAI)}, 2017.

\bibitem[Gupta et~al.(2019)Gupta, Kanade, and Shevade]{gupta2018deep}
Gupta, R., Kanade, A., and Shevade, S.
\newblock Deep reinforcement learning for programming language correction.
\newblock In \emph{Association for the Advancement of Artificial Intelligence
  (AAAI)}, 2019.

\bibitem[Guu et~al.(2017)Guu, Pasupat, Liu, and Liang]{guu2017language}
Guu, K., Pasupat, P., Liu, E.~Z., and Liang, P.
\newblock From language to programs: Bridging reinforcement learning and
  maximum marginal likelihood.
\newblock In \emph{Association for Computational Linguistics (ACL)}, 2017.

\bibitem[Hajipour et~al.(2019)Hajipour, Bhattacharya, and
  Fritz]{hajipour2019samplefix}
Hajipour, H., Bhattacharya, A., and Fritz, M.
\newblock Samplefix: Learning to correct programs by sampling diverse fixes.
\newblock \emph{arXiv preprint arXiv:1906.10502}, 2019.

\bibitem[Hannun et~al.(2014)Hannun, Case, Casper, Catanzaro, Diamos, Elsen,
  Prenger, Satheesh, Sengupta, Coates, et~al.]{hannun2014deep}
Hannun, A., Case, C., Casper, J., Catanzaro, B., Diamos, G., Elsen, E.,
  Prenger, R., Satheesh, S., Sengupta, S., Coates, A., et~al.
\newblock Deep speech: Scaling up end-to-end speech recognition.
\newblock \emph{arXiv preprint arXiv:1412.5567}, 2014.

\bibitem[Hellendoorn et~al.(2019)Hellendoorn, Proksch, Gall, and
  Bacchelli]{hellendoorn2019code}
Hellendoorn, V.~J., Proksch, S., Gall, H.~C., and Bacchelli, A.
\newblock When code completion fails: A case study on real-world completions.
\newblock In \emph{International Conference on Software Engineering (ICSE)},
  2019.

\bibitem[Hellendoorn et~al.(2020)Hellendoorn, Sutton, Singh, Maniatis, and
  Bieber]{hellendoorn2020global}
Hellendoorn, V.~J., Sutton, C., Singh, R., Maniatis, P., and Bieber, D.
\newblock Global relational models of source code.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020.

\bibitem[Hoffman et~al.(2018)Hoffman, Tzeng, Park, Zhu, Isola, Saenko, Efros,
  and Darrell]{hoffman2018cycada}
Hoffman, J., Tzeng, E., Park, T., Zhu, J.-Y., Isola, P., Saenko, K., Efros, A.,
  and Darrell, T.
\newblock Cycada: Cycle-consistent adversarial domain adaptation.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2018.

\bibitem[Jia \& Liang(2016)Jia and Liang]{jia2016data}
Jia, R. and Liang, P.
\newblock Data recombination for neural semantic parsing.
\newblock In \emph{Association for Computational Linguistics (ACL)}, 2016.

\bibitem[Jin et~al.(2019)Jin, Yang, Barzilay, and Jaakkola]{jin2018learning}
Jin, W., Yang, K., Barzilay, R., and Jaakkola, T.
\newblock Learning multimodal graph-to-graph translation for molecular
  optimization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.

\bibitem[Just et~al.(2014)Just, Jalali, and Ernst]{just2014defects4j}
Just, R., Jalali, D., and Ernst, M.~D.
\newblock Defects4j: A database of existing faults to enable controlled testing
  studies for java programs.
\newblock In \emph{Proceedings of the 2014 International Symposium on Software
  Testing and Analysis}, pp.\  437--440, 2014.

\bibitem[Kamath et~al.(2020)Kamath, Jia, and Liang]{kamath2020selective}
Kamath, A., Jia, R., and Liang, P.
\newblock Selective question answering under domain shift.
\newblock In \emph{Association for Computational Linguistics (ACL)}, 2020.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{kingma2015adam}
Kingma, D. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2015.

\bibitem[Koh et~al.(2021)Koh, Sagawa, Marklund, Xie, Zhang, Balsubramani, Hu,
  Yasunaga, Phillips, Beery, et~al.]{kohsagawa2020wilds}
Koh, P.~W., Sagawa, S., Marklund, H., Xie, S.~M., Zhang, M., Balsubramani, A.,
  Hu, W., Yasunaga, M., Phillips, R.~L., Beery, S., et~al.
\newblock Wilds: A benchmark of in-the-wild distribution shifts.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2021.

\bibitem[Krizhevsky et~al.(2017)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2017imagenet}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock \emph{Communications of the ACM}, 2017.

\bibitem[Kumar et~al.(2020)Kumar, Ma, and Liang]{kumar2020understanding}
Kumar, A., Ma, T., and Liang, P.
\newblock Understanding self-training for gradual domain adaptation.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Lachaux et~al.(2020)Lachaux, Roziere, Chanussot, and
  Lample]{lachaux2020unsupervised}
Lachaux, M.-A., Roziere, B., Chanussot, L., and Lample, G.
\newblock Unsupervised translation of programming languages.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2020.

\bibitem[Lample et~al.(2018{\natexlab{a}})Lample, Conneau, Denoyer, and
  Ranzato]{lample2017unsupervised}
Lample, G., Conneau, A., Denoyer, L., and Ranzato, M.
\newblock Unsupervised machine translation using monolingual corpora only.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018{\natexlab{a}}.

\bibitem[Lample et~al.(2018{\natexlab{b}})Lample, Ott, Conneau, Denoyer, and
  Ranzato]{lample2018phrase}
Lample, G., Ott, M., Conneau, A., Denoyer, L., and Ranzato, M.
\newblock Phrase-based \& neural unsupervised machine translation.
\newblock In \emph{Empirical Methods in Natural Language Processing (EMNLP)},
  2018{\natexlab{b}}.

\bibitem[Lee(2013)]{lee2013pseudo}
Lee, D.-H.
\newblock Pseudo-label: The simple and efficient semi-supervised learning
  method for deep neural networks.
\newblock In \emph{Workshop on challenges in representation learning,
  International Conference on Machine Learning (ICML)}, 2013.

\bibitem[Lee et~al.(2019)Lee, Hashimoto, and Liang]{lee2019learning}
Lee, M., Hashimoto, T.~B., and Liang, P.
\newblock Learning autocomplete systems as a communication game.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)
  Workshop on Emergent Communication}, 2019.

\bibitem[Levenshtein(1966)]{levenshtein1966binary}
Levenshtein, V.~I.
\newblock Binary codes capable of correcting deletions, insertions, and
  reversals.
\newblock In \emph{Soviet physics doklady}, 1966.

\bibitem[Lewis et~al.(2020)Lewis, Liu, Goyal, Ghazvininejad, Mohamed, Levy,
  Stoyanov, and Zettlemoyer]{lewis2019bart}
Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O.,
  Stoyanov, V., and Zettlemoyer, L.
\newblock Bart: Denoising sequence-to-sequence pre-training for natural
  language generation, translation, and comprehension.
\newblock In \emph{Association for Computational Linguistics (ACL)}, 2020.

\bibitem[Liang et~al.(2013)Liang, Jordan, and Klein]{liang2013learning}
Liang, P., Jordan, M.~I., and Klein, D.
\newblock Learning dependency-based compositional semantics.
\newblock \emph{Computational Linguistics}, 2013.

\bibitem[McClosky et~al.(2006)McClosky, Charniak, and
  Johnson]{mcclosky2006effective}
McClosky, D., Charniak, E., and Johnson, M.
\newblock Effective self-training for parsing.
\newblock In \emph{North American Association for Computational Linguistics
  (NAACL)}, 2006.

\bibitem[Mesbah et~al.(2019)Mesbah, Rice, Johnston, Glorioso, and
  Aftandilian]{mesbah2019deepdelta}
Mesbah, A., Rice, A., Johnston, E., Glorioso, N., and Aftandilian, E.
\newblock Deepdelta: learning to repair compilation errors.
\newblock In \emph{Proceedings of the 2019 27th ACM Joint Meeting on European
  Software Engineering Conference and Symposium on the Foundations of Software
  Engineering}, pp.\  925--936, 2019.

\bibitem[Min et~al.(2019)Min, Chen, Hajishirzi, and
  Zettlemoyer]{min2019discrete}
Min, S., Chen, D., Hajishirzi, H., and Zettlemoyer, L.
\newblock A discrete hard em approach for weakly supervised question answering.
\newblock In \emph{Empirical Methods in Natural Language Processing (EMNLP)},
  2019.

\bibitem[Monperrus(2020)]{repair_review}
Monperrus, M.
\newblock The living review on automated program repair.
\newblock \emph{Technical Report hal-01956501. HAL/archives-ouvertes.fr.},
  2020.

\bibitem[Parihar et~al.(2017)Parihar, Dadachanji, Praveen Kumar~Singh, Karkare,
  and Bhattacharya]{parihar2017automatic}
Parihar, S., Dadachanji, Z., Praveen Kumar~Singh, R.~D., Karkare, A., and
  Bhattacharya, A.
\newblock Automatic grading and feedback using program repair for introductory
  programming courses.
\newblock In \emph{ACM Conference on Innovation and Technology in Computer
  Science Education}, 2017.

\bibitem[Pascanu et~al.(2013)Pascanu, Mikolov, and
  Bengio]{pascanu2013difficulty}
Pascanu, R., Mikolov, T., and Bengio, Y.
\newblock On the difficulty of training recurrent neural networks.
\newblock In \emph{International conference on machine learning (ICML)}, pp.\
  1310--1318, 2013.

\bibitem[Peng et~al.(2018)Peng, Usman, Kaushik, Wang, Hoffman, and
  Saenko]{peng2018visda}
Peng, X., Usman, B., Kaushik, N., Wang, D., Hoffman, J., and Saenko, K.
\newblock Visda: A synthetic-to-real benchmark for visual domain adaptation.
\newblock In \emph{Computer Vision and Pattern Recognition (CVPR)}, 2018.

\bibitem[Peng et~al.(2019)Peng, Bai, Xia, Huang, Saenko, and
  Wang]{peng2019moment}
Peng, X., Bai, Q., Xia, X., Huang, Z., Saenko, K., and Wang, B.
\newblock Moment matching for multi-source domain adaptation.
\newblock In \emph{International Conference on Computer Vision (ICCV)}, 2019.

\bibitem[Pradel \& Sen(2018)Pradel and Sen]{pradel2018deepbugs}
Pradel, M. and Sen, K.
\newblock Deepbugs: A learning approach to name-based bug detection.
\newblock \emph{Proceedings of the ACM on Programming Languages}, 2\penalty0
  (OOPSLA):\penalty0 1--25, 2018.

\bibitem[Pu et~al.(2016)Pu, Narasimhan, Solar-Lezama, and Barzilay]{pu2016sk_p}
Pu, Y., Narasimhan, K., Solar-Lezama, A., and Barzilay, R.
\newblock sk\_p: a neural program corrector for moocs.
\newblock In \emph{Companion Proceedings of the 2016 ACM SIGPLAN International
  Conference on Systems, Programming, Languages and Applications: Software for
  Humanity}, pp.\  39--40, 2016.

\bibitem[Quionero-Candela et~al.(2009)Quionero-Candela, Sugiyama, Schwaighofer,
  and Lawrence]{quionero2009dataset}
Quionero-Candela, J., Sugiyama, M., Schwaighofer, A., and Lawrence, N.~D.
\newblock \emph{Dataset shift in machine learning}.
\newblock The MIT Press, 2009.

\bibitem[Richter et~al.(2016)Richter, Vineet, Roth, and
  Koltun]{richter2016playing}
Richter, S.~R., Vineet, V., Roth, S., and Koltun, V.
\newblock Playing for data: Ground truth from computer games.
\newblock In \emph{European conference on computer vision}, 2016.

\bibitem[Sennrich et~al.(2016)Sennrich, Haddow, and
  Birch]{sennrich2015improving}
Sennrich, R., Haddow, B., and Birch, A.
\newblock Improving neural machine translation models with monolingual data.
\newblock In \emph{Association for Computational Linguistics (ACL)}, 2016.

\bibitem[Seo et~al.(2014)Seo, Sadowski, Elbaum, Aftandilian, and
  Bowdidge]{seo2014program}
Seo, H., Sadowski, C., Elbaum, S., Aftandilian, E., and Bowdidge, R.
\newblock Programmers' build errors: A case study at google.
\newblock In \emph{International Conference on Software Engineering (ICSE)},
  2014.

\bibitem[Shen et~al.(2017)Shen, Lei, Barzilay, and Jaakkola]{shen2017style}
Shen, T., Lei, T., Barzilay, R., and Jaakkola, T.
\newblock Style transfer from non-parallel text by cross-alignment.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2017.

\bibitem[Sun \& Saenko(2016)Sun and Saenko]{sun2016deep}
Sun, B. and Saenko, K.
\newblock Deep coral: Correlation alignment for deep domain adaptation.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, 2016.

\bibitem[Sun et~al.(2020)Sun, Wang, Liu, Miller, Efros, and Hardt]{sun2019test}
Sun, Y., Wang, X., Liu, Z., Miller, J., Efros, A.~A., and Hardt, M.
\newblock Test-time training for out-of-distribution generalization.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Taghipour \& Ng(2016)Taghipour and Ng]{taghipour2016neural}
Taghipour, K. and Ng, H.~T.
\newblock A neural approach to automated essay scoring.
\newblock In \emph{Empirical Methods in Natural Language Processing (EMNLP)},
  2016.

\bibitem[Tarlow et~al.(2020)Tarlow, Moitra, Rice, Chen, Manzagol, Sutton, and
  Aftandilian]{tarlow2020learning}
Tarlow, D., Moitra, S., Rice, A., Chen, Z., Manzagol, P.-A., Sutton, C., and
  Aftandilian, E.
\newblock Learning to fix build errors with graph2diff neural networks.
\newblock In \emph{Proceedings of the IEEE/ACM 42nd International Conference on
  Software Engineering Workshops}, pp.\  19--20, 2020.

\bibitem[Torralba \& Efros(2011)Torralba and Efros]{torralba2011unbiased}
Torralba, A. and Efros, A.~A.
\newblock Unbiased look at dataset bias.
\newblock In \emph{Computer Vision and Pattern Recognition (CVPR)}, 2011.

\bibitem[Vasic et~al.(2019)Vasic, Kanade, Maniatis, Bieber, and
  Singh]{vasic2019neural}
Vasic, M., Kanade, A., Maniatis, P., Bieber, D., and Singh, R.
\newblock Neural program repair by jointly learning to localize and repair.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, L., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2017.

\bibitem[Venkateswara et~al.(2017)Venkateswara, Eusebio, Chakraborty, and
  Panchanathan]{venkateswara2017deep}
Venkateswara, H., Eusebio, J., Chakraborty, S., and Panchanathan, S.
\newblock Deep hashing network for unsupervised domain adaptation.
\newblock In \emph{Computer Vision and Pattern Recognition (CVPR)}, pp.\
  5018--5027, 2017.

\bibitem[Vincent et~al.(2008)Vincent, Larochelle, Bengio, , and
  Manzagol]{vincent2008denoise}
Vincent, P., Larochelle, H., Bengio, Y., , and Manzagol, P.-A.
\newblock Extracting and composing robust features with denoising autoencoders.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2008.

\bibitem[Wang et~al.(2018)Wang, Singh, and Su]{wang2017dynamic}
Wang, K., Singh, R., and Su, Z.
\newblock Dynamic neural program embeddings for program repair.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Wang et~al.(2015)Wang, Berant, and Liang]{wang2015building}
Wang, Y., Berant, J., and Liang, P.
\newblock Building a semantic parser overnight.
\newblock In \emph{Association for Computational Linguistics (ACL)}, 2015.

\bibitem[Xie et~al.(2020)Xie, Dai, Hovy, Luong, and Le]{xie2019unsupervised}
Xie, Q., Dai, Z., Hovy, E., Luong, M.-T., and Le, Q.~V.
\newblock Unsupervised data augmentation for consistency training.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2020.

\bibitem[Xie et~al.(2021)Xie, Kumar, Jones, Khani, Ma, and Liang]{xie2020n}
Xie, S.~M., Kumar, A., Jones, R., Khani, F., Ma, T., and Liang, P.
\newblock In-n-out: Pre-training and self-training using auxiliary information
  for out-of-distribution robustness.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2021.

\bibitem[Xu et~al.(2020)Xu, Semnani, Campagna, and Lam]{xu2020autoqa}
Xu, S., Semnani, S.~J., Campagna, G., and Lam, M.~S.
\newblock Autoqa: From databases to qa semantic parsers with only synthetic
  training data.
\newblock In \emph{Empirical Methods in Natural Language Processing (EMNLP)},
  2020.

\bibitem[Yang et~al.(2020)Yang, Jin, Swanson, Barzilay, and
  Jaakkola]{yang2020improving}
Yang, K., Jin, W., Swanson, K., Barzilay, R., and Jaakkola, T.
\newblock Improving molecular design by stochastic iterative target
  augmentation.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Yang et~al.(2018)Yang, Hu, Dyer, Xing, and
  Berg-Kirkpatrick]{yang2018unsupervised}
Yang, Z., Hu, Z., Dyer, C., Xing, E.~P., and Berg-Kirkpatrick, T.
\newblock Unsupervised text style transfer using language models as
  discriminators.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2018.

\bibitem[Yasunaga \& Liang(2020)Yasunaga and Liang]{yasunaga2020repair}
Yasunaga, M. and Liang, P.
\newblock Graph-based, self-supervised program repair from diagnostic feedback.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Yasunaga et~al.(2018)Yasunaga, Kasai, and Radev]{yasunaga2017robust}
Yasunaga, M., Kasai, J., and Radev, D.
\newblock Robust multilingual part-of-speech tagging via adversarial training.
\newblock In \emph{North American Association for Computational Linguistics
  (NAACL)}, 2018.

\bibitem[Yu et~al.(2018{\natexlab{a}})Yu, Yasunaga, Yang, Zhang, Wang, Li, and
  Radev]{yu2018syntax}
Yu, T., Yasunaga, M., Yang, K., Zhang, R., Wang, D., Li, Z., and Radev, D.
\newblock Syntaxsqlnet: Syntax tree networks for complex and
  cross-domaintext-to-sql task.
\newblock In \emph{Empirical Methods in Natural Language Processing (EMNLP)},
  2018{\natexlab{a}}.

\bibitem[Yu et~al.(2018{\natexlab{b}})Yu, Zhang, Yang, Yasunaga, Wang, Li, Ma,
  Li, Yao, Roman, et~al.]{yu2018spider}
Yu, T., Zhang, R., Yang, K., Yasunaga, M., Wang, D., Li, Z., Ma, J., Li, I.,
  Yao, Q., Roman, S., et~al.
\newblock Spider: A large-scale human-labeled dataset for complex and
  cross-domain semantic parsing and text-to-sql task.
\newblock In \emph{Empirical Methods in Natural Language Processing (EMNLP)},
  2018{\natexlab{b}}.

\bibitem[Yu et~al.(2019)Yu, Zhang, Yasunaga, Tan, Lin, Li, Er, Li, Pang, Chen,
  et~al.]{yu2019sparc}
Yu, T., Zhang, R., Yasunaga, M., Tan, Y.~C., Lin, X.~V., Li, S., Er, H., Li,
  I., Pang, B., Chen, T., et~al.
\newblock Sparc: Cross-domain semantic parsing in context.
\newblock In \emph{Association for Computational Linguistics (ACL)}, 2019.

\bibitem[Zhang et~al.(2019)Zhang, Ren, Liu, Wang, Chen, Li, Zhou, and
  Chen]{zhang2019style}
Zhang, Z., Ren, S., Liu, S., Wang, J., Chen, P., Li, M., Zhou, M., and Chen, E.
\newblock Style transfer as unsupervised machine translation.
\newblock In \emph{Association for the Advancement of Artificial Intelligence
  (AAAI)}, 2019.

\bibitem[Zhong et~al.(2020)Zhong, Lewis, Wang, and
  Zettlemoyer]{zhong2020grounded}
Zhong, V., Lewis, M., Wang, S.~I., and Zettlemoyer, L.
\newblock Grounded adaptation for zero-shot executable semantic parsing.
\newblock In \emph{Empirical Methods in Natural Language Processing (EMNLP)},
  2020.

\bibitem[Zhou \& Li(2005)Zhou and Li]{zhou2005tri}
Zhou, Z.-H. and Li, M.
\newblock Tri-training: Exploiting unlabeled data using three classifiers.
\newblock \emph{IEEE Transactions on knowledge and Data Engineering}, 2005.

\bibitem[Zhu et~al.(2017)Zhu, Park, Isola, and Efros]{zhu2017unpaired}
Zhu, J.-Y., Park, T., Isola, P., and Efros, A.~A.
\newblock Unpaired image-to-image translation using cycle-consistent
  adversarial networks.
\newblock In \emph{International Conference on Computer Vision (ICCV)}, 2017.

\end{thebibliography}
