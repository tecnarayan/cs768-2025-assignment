\begin{thebibliography}{68}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Atanackovic et~al.(2023{\natexlab{a}})Atanackovic, Tong, Hartford, Lee, Wang, and Bengio]{dyngfn}
Atanackovic, L., Tong, A., Hartford, J., Lee, L.~J., Wang, B., and Bengio, Y.
\newblock {DynGFN}: Towards bayesian inference of gene regulatory networks with gflownets.
\newblock In \emph{Advances in Neural Processing Systems (NeurIPS)}, 2023{\natexlab{a}}.

\bibitem[Atanackovic et~al.(2023{\natexlab{b}})Atanackovic, Tong, WANG, Lee, Bengio, and Hartford]{atanackovic2023dyngfn}
Atanackovic, L., Tong, A., WANG, B., Lee, L.~J., Bengio, Y., and Hartford, J.
\newblock Dyn{GFN}: Towards bayesian inference of gene regulatory networks with {GF}lownets.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023{\natexlab{b}}.
\newblock URL \url{https://openreview.net/forum?id=e7MK5Vq44Q}.

\bibitem[Bengio et~al.(2021)Bengio, Jain, Korablyov, Precup, and Bengio]{Bengio2021}
Bengio, E., Jain, M., Korablyov, M., Precup, D., and Bengio, Y.
\newblock Flow network based generative models for non-iterative diverse candidate generation.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2021.

\bibitem[Bengio et~al.(2023)Bengio, Lahlou, Deleu, Hu, Tiwari, and Bengio]{Foundations}
Bengio, Y., Lahlou, S., Deleu, T., Hu, E.~J., Tiwari, M., and Bengio, E.
\newblock Gflownet foundations.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 2023.

\bibitem[Bharti et~al.(2022)Bharti, Filstroff, and Kaski]{bharti2022approximate}
Bharti, A., Filstroff, L., and Kaski, S.
\newblock Approximate bayesian computation with domain expert in the loop, 2022.

\bibitem[Bielby \& Hauser(1977)Bielby and Hauser]{sem_ii}
Bielby, W.~T. and Hauser, R.~M.
\newblock Structural equation models.
\newblock \emph{Annual review of sociology}, 3\penalty0 (1):\penalty0 137--161, 1977.

\bibitem[Broderick et~al.(2013)Broderick, Boyd, Wibisono, Wilson, and Jordan]{tamara}
Broderick, T., Boyd, N., Wibisono, A., Wilson, A.~C., and Jordan, M.~I.
\newblock Streaming variational bayes.
\newblock In Burges, C., Bottou, L., Welling, M., Ghahramani, Z., and Weinberger, K. (eds.), \emph{Advances in Neural Information Processing Systems}, volume~26. Curran Associates, Inc., 2013.

\bibitem[Chang et~al.(2020)Chang, Qu, Zhang, Sabuncu, Chen, Zhang, and Metaxas]{fgan2}
Chang, Q., Qu, H., Zhang, Y., Sabuncu, M., Chen, C., Zhang, T., and Metaxas, D.~N.
\newblock Synthetic learning: Learn from distributed asynchronized discriminator gan without sharing medical image data.
\newblock In \emph{2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2020.

\bibitem[da~Silva et~al.(2023)da~Silva, Silva, Ribeiro, Góis, Heider, Kaski, and Mesquita]{dasilva2023humanintheloop}
da~Silva, T., Silva, E., Ribeiro, A., Góis, A., Heider, D., Kaski, S., and Mesquita, D.
\newblock Human-in-the-loop causal discovery under latent confounding using ancestral gflownets.
\newblock \emph{arXiv preprint:2309.12032}, 2023.

\bibitem[Daulton et~al.(2021)Daulton, Balandat, and Bakshy]{Daulton2021}
Daulton, S., Balandat, M., and Bakshy, E.
\newblock Parallel bayesian optimization of multiple noisy objectives with expected hypervolume improvement.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2021.

\bibitem[de~Souza et~al.(2022)de~Souza, Mesquita, Kaski, and Acerbi]{EPfailures}
de~Souza, D., Mesquita, D., Kaski, S., and Acerbi, L.
\newblock Parallel {MCMC} without embarrassing failures.
\newblock In \emph{Artificial Intelligence and Statistics (AISTATS)}, 2022.

\bibitem[Deleu \& Bengio(2023)Deleu and Bengio]{markovchains}
Deleu, T. and Bengio, Y.
\newblock Generative flow networks: a markov chain perspective, 2023.

\bibitem[Deleu et~al.(2022)Deleu, G{\'o}is, Emezue, Rankawat, Lacoste-Julien, Bauer, and Bengio]{deleu2022bayesian}
Deleu, T., G{\'o}is, A., Emezue, C.~C., Rankawat, M., Lacoste-Julien, S., Bauer, S., and Bengio, Y.
\newblock Bayesian structure learning with generative flow networks.
\newblock In \emph{Uncertainty in Artificial Intelligence (UAI)}, 2022.

\bibitem[Deleu et~al.(2023)Deleu, Nishikawa-Toomey, Subramanian, Malkin, Charlin, and Bengio]{deleu2023joint}
Deleu, T., Nishikawa-Toomey, M., Subramanian, J., Malkin, N., Charlin, L., and Bengio, Y.
\newblock Joint {Bayesian} inference of graphical structure and parameters with a single generative flow network.
\newblock In \emph{Advances in Neural Processing Systems (NeurIPS)}, 2023.

\bibitem[Du et~al.(2023)Du, Durkan, Strudel, Tenenbaum, Dieleman, Fergus, Sohl-Dickstein, Doucet, and Grathwohl]{diffusions}
Du, Y., Durkan, C., Strudel, R., Tenenbaum, J.~B., Dieleman, S., Fergus, R., Sohl-Dickstein, J., Doucet, A., and Grathwohl, W.
\newblock Reduce, reuse, recycle: compositional generation with energy-based diffusion models and mcmc.
\newblock In \emph{Proceedings of the 40th International Conference on Machine Learning}. JMLR.org, 2023.

\bibitem[El~Mekkaoui et~al.(2021)El~Mekkaoui, Mesquita, Blomstedt, and Kaski]{el-mekkaoui_652}
El~Mekkaoui, K., Mesquita, D., Blomstedt, P., and Kaski, S.
\newblock Federated stochastic gradient langevin dynamics.
\newblock In \emph{Uncertainty in artificial intelligence (UAI)}, 2021.

\bibitem[Felsenstein(1981)]{Felsenstein1981}
Felsenstein, J.
\newblock Evolutionary trees from {DNA} sequences: A maximum likelihood approach.
\newblock \emph{Journal of Molecular Evolution}, 1981.

\bibitem[Fey \& Lenssen(2019)Fey and Lenssen]{Fey/Lenssen/2019}
Fey, M. and Lenssen, J.~E.
\newblock Fast graph representation learning with {PyTorch Geometric}.
\newblock In \emph{ICLR Workshop on Representation Learning on Graphs and Manifolds}, 2019.

\bibitem[Garipov et~al.(2023)Garipov, Peuter, Yang, Garg, Kaski, and Jaakkola]{sculpting}
Garipov, T., Peuter, S.~D., Yang, G., Garg, V., Kaski, S., and Jaakkola, T.
\newblock Compositional sculpting of iterative generative processes.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2023.

\bibitem[Geffner et~al.(2022)Geffner, Antoran, Foster, Gong, Ma, Kiciman, Sharma, Lamb, Kukla, Pawlowski, et~al.]{geffner2022deep}
Geffner, T., Antoran, J., Foster, A., Gong, W., Ma, C., Kiciman, E., Sharma, A., Lamb, A., Kukla, M., Pawlowski, N., et~al.
\newblock Deep end-to-end causal inference.
\newblock \emph{arXiv preprint arXiv:2202.02195}, 2022.

\bibitem[Graves \& Graves(2012)Graves and Graves]{graves2012long}
Graves, A. and Graves, A.
\newblock Long short-term memory.
\newblock \emph{Supervised sequence labelling with recurrent neural networks}, pp.\  37--45, 2012.

\bibitem[Hernandez-Garcia et~al.(2023)Hernandez-Garcia, Saxena, Jain, Liu, and Bengio]{multifidelity}
Hernandez-Garcia, A., Saxena, N., Jain, M., Liu, C.-H., and Bengio, Y.
\newblock Multi-fidelity active learning with gflownets, 2023.

\bibitem[Hinton(2002)]{HintonProduct}
Hinton, G.~E.
\newblock {Training Products of Experts by Minimizing Contrastive Divergence}.
\newblock \emph{Neural Computation}, 14\penalty0 (8):\penalty0 1771--1800, 08 2002.

\bibitem[Hong et~al.(2021)Hong, Zhu, Yu, Wang, Dodge, and Zhou]{fgan1}
Hong, J., Zhu, Z., Yu, S., Wang, Z., Dodge, H.~H., and Zhou, J.
\newblock Federated adversarial debiasing for fair and transferable representations.
\newblock In \emph{ACM SIGKDD Conference on Knowledge Discovery \& Data Mining (KDD)}, 2021.

\bibitem[Hu et~al.(2023{\natexlab{a}})Hu, Jain, Elmoznino, Kaddar, Lajoie, Bengio, and Malkin]{hu2023amortizing}
Hu, E.~J., Jain, M., Elmoznino, E., Kaddar, Y., Lajoie, G., Bengio, Y., and Malkin, N.
\newblock Amortizing intractable inference in large language models.
\newblock \emph{arXiv preprint 2310.04363}, 2023{\natexlab{a}}.

\bibitem[Hu et~al.(2023{\natexlab{b}})Hu, Malkin, Jain, Everett, Graikos, and Bengio]{discretegfn_ii}
Hu, E.~J., Malkin, N., Jain, M., Everett, K.~E., Graikos, A., and Bengio, Y.
\newblock Gflownet-em for learning compositional latent variable models.
\newblock In \emph{International Conference on Machine Learning (ICLR)}, 2023{\natexlab{b}}.

\bibitem[Husmeier(2003)]{Husmeier2003}
Husmeier, D.
\newblock Sensitivity and specificity of inferring genetic regulatory interactions from microarray experiments with dynamic bayesian networks.
\newblock \emph{Bioinformatics}, 19\penalty0 (17):\penalty0 2271–2282, November 2003.
\newblock ISSN 1367-4803.
\newblock \doi{10.1093/bioinformatics/btg313}.
\newblock URL \url{http://dx.doi.org/10.1093/bioinformatics/btg313}.

\bibitem[Jain et~al.(2022)Jain, Bengio, Hernandez-Garcia, Rector-Brooks, Dossou, Ekbote, Fu, Zhang, Kilgour, Zhang, Simine, Das, and Bengio]{sequence}
Jain, M., Bengio, E., Hernandez-Garcia, A., Rector-Brooks, J., Dossou, B. F.~P., Ekbote, C.~A., Fu, J., Zhang, T., Kilgour, M., Zhang, D., Simine, L., Das, P., and Bengio, Y.
\newblock Biological sequence design with {GF}low{N}ets.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2022.

\bibitem[Jain et~al.(2023)Jain, Raparthy, Hernandez-Garcia, Rector-Brooks, Bengio, Miret, and Bengio]{mogfn}
Jain, M., Raparthy, S.~C., Hernandez-Garcia, A., Rector-Brooks, J., Bengio, Y., Miret, S., and Bengio, E.
\newblock Multi-objective {GF}low{N}ets.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2023.

\bibitem[Jukes \& Cantor(1969)Jukes and Cantor]{jukes}
Jukes, T.~H. and Cantor, C.~R.
\newblock \emph{Evolution of Protein Molecules}, pp.\  21–132.
\newblock Elsevier, 1969.
\newblock ISBN 9781483232119.
\newblock \doi{10.1016/b978-1-4832-3211-9.50009-7}.
\newblock URL \url{http://dx.doi.org/10.1016/B978-1-4832-3211-9.50009-7}.

\bibitem[Lahlou et~al.(2023)Lahlou, Deleu, Lemos, Zhang, Volokhova, Hern{\'a}ndez-Garc{\i}a, Ezzine, Bengio, and Malkin]{theory}
Lahlou, S., Deleu, T., Lemos, P., Zhang, D., Volokhova, A., Hern{\'a}ndez-Garc{\i}a, A., Ezzine, L.~N., Bengio, Y., and Malkin, N.
\newblock A theory of continuous generative flow networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2023.

\bibitem[Lorch et~al.(2021)Lorch, Rothfuss, Sch{\"o}lkopf, and Krause]{lorch2021dibs}
Lorch, L., Rothfuss, J., Sch{\"o}lkopf, B., and Krause, A.
\newblock Dibs: Differentiable bayesian structure learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 24111--24123, 2021.

\bibitem[Loshchilov \& Hutter(2019)Loshchilov and Hutter]{loshchilov2018decoupled}
Loshchilov, I. and Hutter, F.
\newblock Decoupled weight decay regularization.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2019.

\bibitem[Maas et~al.(2013)Maas, Hannun, Ng, et~al.]{maas2013rectifier}
Maas, A.~L., Hannun, A.~Y., Ng, A.~Y., et~al.
\newblock Rectifier nonlinearities improve neural network acoustic models.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2013.

\bibitem[Malkin et~al.(2022)Malkin, Jain, Bengio, Sun, and Bengio]{malkin2022trajectory}
Malkin, N., Jain, M., Bengio, E., Sun, C., and Bengio, Y.
\newblock Trajectory balance: Improved credit assignment in {GF}lownets.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2022.

\bibitem[Malkin et~al.(2023)Malkin, Lahlou, Deleu, Ji, Hu, Everett, Zhang, and Bengio]{malkin2023gflownets}
Malkin, N., Lahlou, S., Deleu, T., Ji, X., Hu, E., Everett, K., Zhang, D., and Bengio, Y.
\newblock {GFlowNets} and variational inference.
\newblock \emph{International Conference on Learning Representations (ICLR)}, 2023.

\bibitem[McMahan et~al.(2017{\natexlab{a}})McMahan, Moore, Ramage, Hampson, and y~Arcas]{mcmahan2017communication}
McMahan, B., Moore, E., Ramage, D., Hampson, S., and y~Arcas, B.~A.
\newblock Communication-efficient learning of deep networks from decentralized data.
\newblock In \emph{Artificial intelligence and statistics}, pp.\  1273--1282. PMLR, 2017{\natexlab{a}}.

\bibitem[McMahan et~al.(2017{\natexlab{b}})McMahan, Moore, Ramage, Hampson, and y~Arcas]{daneaistats2020}
McMahan, H.~B., Moore, E., Ramage, D., Hampson, S., and y~Arcas, B.~A.
\newblock Communication-efficient learning of deep networks from decentralized data.
\newblock In \emph{Artificial Intelligence and Statistics (AISTATS)}, 2017{\natexlab{b}}.

\bibitem[Mesquita et~al.(2019)Mesquita, Blomstedt, and Kaski]{Mesquita2019}
Mesquita, D., Blomstedt, P., and Kaski, S.
\newblock Embarrassingly parallel {MCMC} using deep invertible transformations.
\newblock In \emph{Uncertainty in Artificial Intelligence (UAI)}, 2019.

\bibitem[Neiswanger et~al.(2014)Neiswanger, Wang, and Xing]{Neiswanger2014}
Neiswanger, W., Wang, C., and Xing, E.~P.
\newblock Asymptotically exact, embarrassingly parallel {MCMC}.
\newblock In \emph{Uncertainty in Artificial Intelligence (UAI)}, 2014.

\bibitem[Nemeth \& Sherlock(2018)Nemeth and Sherlock]{Nemeth2018}
Nemeth, C. and Sherlock, C.
\newblock Merging {MCMC} subposteriors through {G}aussian-process approximations.
\newblock \emph{Bayesian Analysis}, 13\penalty0 (2):\penalty0 507--530, 2018.

\bibitem[Ng \& Zhang(2022)Ng and Zhang]{Ng2022federated}
Ng, I. and Zhang, K.
\newblock Towards federated bayesian network structure learning with continuous optimization.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, 2022.

\bibitem[Pan et~al.(2023{\natexlab{a}})Pan, Malkin, Zhang, and Bengio]{LingTrajectory}
Pan, L., Malkin, N., Zhang, D., and Bengio, Y.
\newblock Better training of {GF}low{N}ets with local credit and incomplete trajectories.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2023{\natexlab{a}}.

\bibitem[Pan et~al.(2023{\natexlab{b}})Pan, Zhang, Courville, Huang, and Bengio]{pan2023generative}
Pan, L., Zhang, D., Courville, A., Huang, L., and Bengio, Y.
\newblock Generative augmented flow networks.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2023{\natexlab{b}}.

\bibitem[Pan et~al.(2023{\natexlab{c}})Pan, Zhang, Jain, Huang, and Bengio]{stochastic}
Pan, L., Zhang, D., Jain, M., Huang, L., and Bengio, Y.
\newblock Stochastic generative flow networks.
\newblock In \emph{Uncertainty in Artificial Intelligence (UAI)}, 2023{\natexlab{c}}.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan, Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison, Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{Paszke_PyTorch_An_Imperative_2019}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., Bai, J., and Chintala, S.
\newblock {PyTorch: An Imperative Style, High-Performance Deep Learning Library}.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2019.

\bibitem[Pearl(1988)]{pearl1988probabilistic}
Pearl, J.
\newblock \emph{Probabilistic reasoning in intelligent systems: networks of plausible inference}.
\newblock Morgan kaufmann, 1988.

\bibitem[Pearl(2009)]{pearl9}
Pearl, J.
\newblock \emph{Causality}.
\newblock Cambridge University Press, Cambridge, UK, 2 edition, 2009.
\newblock ISBN 978-0-521-89560-6.
\newblock \doi{10.1017/CBO9780511803161}.

\bibitem[Pearl \& Mackenzie(2018)Pearl and Mackenzie]{pearl18}
Pearl, J. and Mackenzie, D.
\newblock \emph{The Book of Why: The New Science of Cause and Effect}.
\newblock Basic Books, Inc., USA, 1st edition, 2018.
\newblock ISBN 046509760X.

\bibitem[Polato(2021)]{fvae}
Polato, M.
\newblock Federated variational autoencoder for collaborative filtering.
\newblock In \emph{International Joint Conference on Neural Networks (IJCNN)}, 2021.

\bibitem[Qu et~al.(2020)Qu, Zhang, Chang, Yan, Chen, and Metaxas]{fgan3}
Qu, H., Zhang, Y., Chang, Q., Yan, Z., Chen, C., and Metaxas, D.
\newblock Learn distributed gan with temporary discriminators.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, 2020.

\bibitem[Reisach et~al.(2021)Reisach, Seiler, and Weichwald]{reisach2021beware}
Reisach, A.~G., Seiler, C., and Weichwald, S.
\newblock Beware of the simulated dag! causal discovery benchmarks may be easy to game.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Richter et~al.(2020)Richter, Boustati, N\"{u}sken, Ruiz, and Akyildiz]{vargrad}
Richter, L., Boustati, A., N\"{u}sken, N., Ruiz, F., and Akyildiz, O.~D.
\newblock Vargrad: A low-variance gradient estimator for variational inference.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem[Scott et~al.(2016)Scott, Blocker, Bonassi, Chipman, George, and McCulloch]{Scott}
Scott, S.~L., Blocker, A.~W., Bonassi, F.~V., Chipman, H.~A., George, E.~I., and McCulloch, R.~E.
\newblock Bayes and big data: The consensus monte carlo algorithm.
\newblock \emph{International Journal of Management Science and Engineering Management}, 11, 2016.

\bibitem[Shen et~al.(2023)Shen, Bengio, Hajiramezanali, Loukas, Cho, and Biancalani]{towards}
Shen, M.~W., Bengio, E., Hajiramezanali, E., Loukas, A., Cho, K., and Biancalani, T.
\newblock Towards understanding and improving gflownet training.
\newblock \emph{arXiv preprint arXiv:2305.07170}, 2023.

\bibitem[Stamatakis \& Aberer(2013)Stamatakis and Aberer]{stamatakis2013novel}
Stamatakis, A. and Aberer, A.~J.
\newblock Novel parallelization schemes for large-scale likelihood-based phylogenetic inference.
\newblock In \emph{2013 IEEE 27th International Symposium on Parallel and Distributed Processing}, pp.\  1195--1204. IEEE, 2013.

\bibitem[Vono et~al.(2022)Vono, Plassier, Durmus, Dieuleveut, and Moulines]{vono22}
Vono, M., Plassier, V., Durmus, A., Dieuleveut, A., and Moulines, E.
\newblock Qlsd: Quantised langevin stochastic dynamics for bayesian federated learning.
\newblock In \emph{Artificial Intelligence and Statistics (AISTATS)}, 2022.

\bibitem[Wang et~al.(2015)Wang, Guo, Heller, and Dunson]{Wang+others:2015}
Wang, X., Guo, F., Heller, K.~A., and Dunson, D.~B.
\newblock Parallelizing {MCMC} with random partition trees.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2015.

\bibitem[Xu et~al.(2023)Xu, Tong, and Huang]{xu2023personalized}
Xu, J., Tong, X., and Huang, S.-L.
\newblock Personalized federated learning with feature alignment and classifier collaboration.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=SXZr8aDKia}.

\bibitem[Xu et~al.(2019)Xu, Hu, Leskovec, and Jegelka]{xu2018powerful}
Xu, K., Hu, W., Leskovec, J., and Jegelka, S.
\newblock How powerful are graph neural networks?
\newblock \emph{International Conference on Learning Representations (ICLR)}, 2019.

\bibitem[Zhang \& Matsen~IV(2018)Zhang and Matsen~IV]{matsen}
Zhang, C. and Matsen~IV, F.~A.
\newblock Variational bayesian phylogenetic inference.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2018.

\bibitem[Zhang et~al.(2022{\natexlab{a}})Zhang, Chen, Malkin, and Bengio]{discretegfn_i}
Zhang, D., Chen, R.~T., Malkin, N., and Bengio, Y.
\newblock Unifying generative models with gflownets and beyond.
\newblock \emph{ICML Beyond Bayes workshop}, 2022{\natexlab{a}}.

\bibitem[Zhang et~al.(2022{\natexlab{b}})Zhang, Malkin, Liu, Volokhova, Courville, and Bengio]{discretegfn_iii}
Zhang, D., Malkin, N., Liu, Z., Volokhova, A., Courville, A., and Bengio, Y.
\newblock Generative flow networks for discrete probabilistic modeling.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2022{\natexlab{b}}.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Dai, Malkin, Courville, Bengio, and Pan]{Zhang2023}
Zhang, D., Dai, H., Malkin, N., Courville, A., Bengio, Y., and Pan, L.
\newblock Let the flows tell: Solving graph combinatorial optimization problems with gflownets.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2023{\natexlab{a}}.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Pan, Chen, Courville, and Bengio]{quantiles}
Zhang, D., Pan, L., Chen, R.~T., Courville, A., and Bengio, Y.
\newblock Distributional gflownets with quantile flows.
\newblock \emph{arXiv preprint arXiv:2302.05793}, 2023{\natexlab{b}}.

\bibitem[Zhang et~al.(2023{\natexlab{c}})Zhang, Rainone, Peschl, and Bondesan]{robust}
Zhang, D.~W., Rainone, C., Peschl, M., and Bondesan, R.
\newblock Robust scheduling with gflownets.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2023{\natexlab{c}}.

\bibitem[Zheng et~al.(2018)Zheng, Aragam, Ravikumar, and Xing]{zheng2018dags}
Zheng, X., Aragam, B., Ravikumar, P., and Xing, E.~P.
\newblock {DAGs with NO TEARS: Continuous Optimization for Structure Learning}.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Zhou et~al.(2023)Zhou, Yan, Layne, Malkin, Zhang, Jain, Blanchette, and Bengio]{zhou2023phylogfn}
Zhou, M., Yan, Z., Layne, E., Malkin, N., Zhang, D., Jain, M., Blanchette, M., and Bengio, Y.
\newblock Phylogfn: Phylogenetic inference with generative flow networks, 2023.

\end{thebibliography}
