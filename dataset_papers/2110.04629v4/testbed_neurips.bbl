\begin{thebibliography}{}

\bibitem[Bartlett et~al., 2021]{bartlett2021deep}
Bartlett, P.~L., Montanari, A., and Rakhlin, A. (2021).
\newblock Deep learning: a statistical viewpoint.
\newblock {\em Acta numerica}, 30:87--201.

\bibitem[Blundell et~al., 2015]{blundell2015weight}
Blundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra, D. (2015).
\newblock Weight uncertainty in neural network.
\newblock In {\em International Conference on Machine Learning}, pages
  1613--1622. PMLR.

\bibitem[Bradbury et~al., 2018]{jax2018github}
Bradbury, J., Frostig, R., Hawkins, P., Johnson, M.~J., Leary, C., Maclaurin,
  D., Necula, G., Paszke, A., Vander{P}las, J., Wanderman-{M}ilne, S., and
  Zhang, Q. (2018).
\newblock {JAX}: composable transformations of {P}ython+{N}um{P}y programs.

\bibitem[Brown et~al., 2020]{brown2020language}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al. (2020).
\newblock Language models are few-shot learners.
\newblock {\em arXiv preprint arXiv:2005.14165}.

\bibitem[Cover and Hart, 1967]{cover1967nearest}
Cover, T. and Hart, P. (1967).
\newblock Nearest neighbor pattern classification.
\newblock {\em IEEE transactions on information theory}, 13(1):21--27.

\bibitem[Deng et~al., 2009]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L. (2009).
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee.

\bibitem[Dwaracherla et~al., 2020]{Dwaracherla2020Hypermodels}
Dwaracherla, V., Lu, X., Ibrahimi, M., Osband, I., Wen, Z., and Van~Roy, B.
  (2020).
\newblock Hypermodels for exploration.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Friedman, 2017]{friedman2017elements}
Friedman, J.~H. (2017).
\newblock {\em The elements of statistical learning: Data mining, inference,
  and prediction}.
\newblock springer open.

\bibitem[Gal and Ghahramani, 2016]{Gal2016Dropout}
Gal, Y. and Ghahramani, Z. (2016).
\newblock Dropout as a {B}ayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In {\em International Conference on Machine Learning}.

\bibitem[Gittins, 1979]{gittins1979bandit}
Gittins, J.~C. (1979).
\newblock Bandit processes and dynamic allocation indices.
\newblock {\em Journal of the Royal Statistical Society: Series B
  (Methodological)}, 41(2):148--164.

\bibitem[Glorot and Bengio, 2010]{glorot2010understanding}
Glorot, X. and Bengio, Y. (2010).
\newblock Understanding the difficulty of training deep feedforward neural
  networks.
\newblock In {\em Proceedings of the 13th international conference on
  artificial intelligence and statistics}, pages 249--256.

\bibitem[He et~al., 2020]{he2020bayesian}
He, B., Lakshminarayanan, B., and Teh, Y.~W. (2020).
\newblock Bayesian deep ensembles via the neural tangent kernel.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H.,
  editors, {\em Advances in Neural Information Processing Systems}, volume~33,
  pages 1010--1022. Curran Associates, Inc.

\bibitem[Hoffman et~al., 2014]{hoffman2014no}
Hoffman, M.~D., Gelman, A., et~al. (2014).
\newblock The no-u-turn sampler: adaptively setting path lengths in
  {H}amiltonian {M}onte {C}arlo.
\newblock {\em J. Mach. Learn. Res.}, 15(1):1593--1623.

\bibitem[Hron et~al., 2017]{hron2017variational}
Hron, J., Matthews, A. G. d.~G., and Ghahramani, Z. (2017).
\newblock Variational {G}aussian dropout is not {B}ayesian.
\newblock {\em arXiv preprint arXiv:1711.02989}.

\bibitem[Izmailov et~al., 2021]{izmailov2021bayesian}
Izmailov, P., Vikram, S., Hoffman, M.~D., and Wilson, A.~G. (2021).
\newblock What are {B}ayesian neural network posteriors really like?
\newblock {\em arXiv preprint arXiv:2104.14421}.

\bibitem[Krizhevsky et~al., 2012]{krizhevsky2012imagenet}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E. (2012).
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em Advances in Neural Information Processing Systems 25}, pages
  1097--1105.

\bibitem[Lakshminarayanan et~al., 2017]{lakshminarayanan2017simple}
Lakshminarayanan, B., Pritzel, A., and Blundell, C. (2017).
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6405--6416.

\bibitem[Li et~al., 2011]{li2011knows}
Li, L., Littman, M.~L., Walsh, T.~J., and Strehl, A.~L. (2011).
\newblock Knows what it knows: a framework for self-aware learning.
\newblock {\em Machine learning}, 82(3):399--443.

\bibitem[Lu et~al., 2021]{lu2021reinforcement}
Lu, X., Van~Roy, B., Dwaracherla, V., Ibrahimi, M., Osband, I., and Wen, Z.
  (2021).
\newblock Reinforcement learning, bit by bit.
\newblock {\em arXiv preprint arXiv:2103.04047}.

\bibitem[Mnih et~al., 2015]{mnih15nature}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., et~al.
  (2015).
\newblock {Human-level Control through Deep Reinforcement Learning}.
\newblock {\em Nature}, 518(7540):529--533.

\bibitem[Murphy, 2012]{murphy2012machine}
Murphy, K.~P. (2012).
\newblock {\em Machine Learning: {A} Probabilistic Perspective}.
\newblock MIT Press.

\bibitem[Nado et~al., 2021]{nado2021uncertainty}
Nado, Z., Band, N., Collier, M., Djolonga, J., Dusenberry, M., Farquhar, S.,
  Filos, A., Havasi, M., Jenatton, R., Jerfel, G., Liu, J., Mariet, Z., Nixon,
  J., Padhy, S., Ren, J., Rudner, T., Wen, Y., Wenzel, F., Murphy, K., Sculley,
  D., Lakshminarayanan, B., Snoek, J., Gal, Y., and Tran, D. (2021).
\newblock {Uncertainty Baselines}: Benchmarks for uncertainty \& robustness in
  deep learning.
\newblock {\em arXiv preprint arXiv:2106.04015}.

\bibitem[Osband, 2016]{osband2016risk}
Osband, I. (2016).
\newblock Risk versus uncertainty in deep learning: {B}ayes, bootstrap and the
  dangers of dropout.
\newblock In {\em NIPS Workshop on {B}ayesian Deep Learning}, volume 192.

\bibitem[Osband et~al., 2018]{osband2018rpf}
Osband, I., Aslanides, J., and Cassirer, A. (2018).
\newblock Randomized prior functions for deep reinforcement learning.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R., editors, {\em Advances in Neural
  Information Processing Systems 31}, pages 8617--8629. Curran Associates, Inc.

\bibitem[Osband and Van~Roy, 2015]{osband2015bootstrapped}
Osband, I. and Van~Roy, B. (2015).
\newblock Bootstrapped {T}hompson sampling and deep exploration.
\newblock {\em arXiv preprint arXiv:1507.00300}.

\bibitem[Osband et~al., 2021]{osband2021epistemic}
Osband, I., Wen, Z., Asghari, M., Dwaracherla, V., Ibrahimi, M., Lu, X., and
  Van~Roy, B. (2021).
\newblock Epistemic neural networks.
\newblock {\em arXiv preprint arXiv:2107.08924}.

\bibitem[Osband et~al., 2022]{osband2022evaluating}
Osband, I., Wen, Z., Asghari, S.~M., Dwaracherla, V., Lu, X., and Van~Roy, B.
  (2022).
\newblock Evaluating high-order predictive distributions in deep learning.

\bibitem[Pedregosa et~al., 2011]{scikit-learn}
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel,
  O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J.,
  Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and Duchesnay, E.
  (2011).
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock {\em Journal of Machine Learning Research}, 12:2825--2830.

\bibitem[Rasmussen, 2003]{rasmussen2003gaussian}
Rasmussen, C.~E. (2003).
\newblock Gaussian processes in machine learning.
\newblock In {\em Summer school on machine learning}, pages 63--71. Springer.

\bibitem[Recht et~al., 2018]{recht2018cifar}
Recht, B., Roelofs, R., Schmidt, L., and Shankar, V. (2018).
\newblock Do cifar-10 classifiers generalize to cifar-10?
\newblock {\em arXiv preprint arXiv:1806.00451}.

\bibitem[Rezende and Mohamed, 2015]{rezende2015variational}
Rezende, D. and Mohamed, S. (2015).
\newblock Variational inference with normalizing flows.
\newblock In {\em International conference on machine learning}, pages
  1530--1538. PMLR.

\bibitem[Riquelme et~al., 2018]{riquelme2018deep}
Riquelme, C., Tucker, G., and Snoek, J. (2018).
\newblock Deep bayesian bandits showdown: An empirical comparison of bayesian
  deep networks for thompson sampling.
\newblock {\em arXiv preprint arXiv:1802.09127}.

\bibitem[Russo and Zou, 2016]{russo2016controlling}
Russo, D. and Zou, J. (2016).
\newblock Controlling bias in adaptive data analysis using information theory.
\newblock In {\em Artificial Intelligence and Statistics}, pages 1232--1240.
  PMLR.

\bibitem[Russo et~al., 2018]{russo2017tutorial}
Russo, D.~J., Van~Roy, B., Kazerouni, A., Osband, I., and Wen, Z. (2018).
\newblock A tutorial on {T}hompson sampling.
\newblock {\em Found. Trends Mach. Learn.}, 11(1):1â€“96.

\bibitem[Sch{\"o}lkopf and Smola, 2018]{scholkopf2002learning}
Sch{\"o}lkopf, B. and Smola, A.~J. (2018).
\newblock {\em Learning with kernels: {S}upport vector machines,
  regularization, optimization, and beyond}.
\newblock MIT press.

\bibitem[Silver et~al., 2016]{silver2016alphago}
Silver, D., Huang, A., Maddison, C.~J., Guez, A., Sifre, L., Van Den~Driessche,
  G., Schrittwieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M.,
  et~al. (2016).
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock {\em Nature}, 529(7587):484--489.

\bibitem[Sun et~al., 2019]{sun2019functional}
Sun, S., Zhang, G., Shi, J., and Grosse, R. (2019).
\newblock Functional variational {B}ayesian neural networks.
\newblock {\em arXiv preprint arXiv:1903.05779}.

\bibitem[Thompson, 1933]{Thompson1933}
Thompson, W.~R. (1933).
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock {\em Biometrika}, 25(3/4):285--294.

\bibitem[Wang et~al., 2021]{wang2021beyond}
Wang, C., Sun, S., and Grosse, R. (2021).
\newblock Beyond marginal uncertainty: How accurately can {B}ayesian regression
  models estimate posterior predictive correlations?
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 2476--2484. PMLR.

\bibitem[Welling and Teh, 2011]{welling2011bayesian}
Welling, M. and Teh, Y.~W. (2011).
\newblock Bayesian learning via stochastic gradient {L}angevin dynamics.
\newblock In {\em Proceedings of the 28th international conference on machine
  learning (ICML-11)}, pages 681--688. Citeseer.

\bibitem[Wen et~al., 2022]{wen2022predictions}
Wen, Z., Osband, I., Qin, C., Lu, X., Ibrahimi, M., Dwaracherla, V., Asghari,
  M., and Van~Roy, B. (2022).
\newblock From predictions to decisions: The importance of joint predictive
  distributions.

\bibitem[Wilson and Izmailov, 2020]{wilson2020bayesian}
Wilson, A.~G. and Izmailov, P. (2020).
\newblock Bayesian deep learning and a probabilistic perspective of
  generalization.
\newblock {\em arXiv preprint arXiv:2002.08791}.

\bibitem[Wilson et~al., 2021]{wilson2021evaluating}
Wilson, A.~G., Izmailov, P., Hoffman, M.~D., Gal, Y., Li, Y., Pradier, M.~F.,
  Vikram, S., Foong, A., Lotfi, S., and Farquhar, S. (2021).
\newblock Evaluating approximate inference in {B}ayesian deep learning.

\bibitem[Woodbury, 1950]{woodbury1950inverting}
Woodbury, M.~A. (1950).
\newblock {\em Inverting modified matrices}.
\newblock Statistical Research Group.

\end{thebibliography}
