\begin{thebibliography}{51}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[adv()]{advbench}
Advbench: Adversarial robustness benchmark.
\newblock \url{https://advbench.github.io/}.
\newblock Accessed: 2020-09-27.

\bibitem[Andersen et~al.(2013)Andersen, Dahl, and
  Vandenberghe]{andersen2013cvxopt}
Andersen, M.~S., Dahl, J., and Vandenberghe, L.
\newblock Cvxopt: Python software for convex optimization, 2013.

\bibitem[Awasthi et~al.(2019)Awasthi, Dutta, and
  Vijayaraghavan]{awasthi2019robustness}
Awasthi, P., Dutta, A., and Vijayaraghavan, A.
\newblock On robustness to adversarial examples and polynomial optimization.
\newblock In \emph{Proceedings of Neural Information Processing Systems}, 2019.

\bibitem[Bhagoji et~al.(2018)Bhagoji, He, Li, and Song]{bhagoji2018practical}
Bhagoji, A.~N., He, W., Li, B., and Song, D.
\newblock Practical black-box attacks on deep neural networks using efficient
  query mechanisms.
\newblock In \emph{European Conference on Computer Vision}, pp.\  158--174.
  Springer, 2018.

\bibitem[Bhagoji et~al.(2019)Bhagoji, Cullina, and Mittal]{bhagoji2019lower}
Bhagoji, A.~N., Cullina, D., and Mittal, P.
\newblock Lower bounds on adversarial robustness from optimal transport.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  7496--7508, 2019.

\bibitem[Biggio \& Roli(2017)Biggio and Roli]{biggio2017wild}
Biggio, B. and Roli, F.
\newblock Wild patterns: Ten years after the rise of adversarial machine
  learning.
\newblock \emph{arXiv preprint arXiv:1712.03141}, 2017.

\bibitem[Boyd et~al.(2004)Boyd, Boyd, and Vandenberghe]{boyd2004convex}
Boyd, S., Boyd, S.~P., and Vandenberghe, L.
\newblock \emph{Convex optimization}.
\newblock Cambridge university press, 2004.

\bibitem[Bubeck et~al.(2018)Bubeck, Price, and
  Razenshteyn]{bubeck2018adversarial}
Bubeck, S., Price, E., and Razenshteyn, I.
\newblock Adversarial examples from computational constraints.
\newblock \emph{arXiv preprint arXiv:1805.10204}, 2018.

\bibitem[Carlini \& Wagner(2017)Carlini and Wagner]{carlini2017towards}
Carlini, N. and Wagner, D.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{Security and Privacy (SP), 2017 IEEE Symposium on}, pp.\
  39--57. IEEE, 2017.

\bibitem[Carmon et~al.(2019)Carmon, Raghunathan, Schmidt, Liang, and
  Duchi]{carmon2019unlabeled}
Carmon, Y., Raghunathan, A., Schmidt, L., Liang, P., and Duchi, J.~C.
\newblock Unlabeled data improves adversarial robustness.
\newblock In \emph{Neural Information Processing Systems}, 2019.

\bibitem[Croce \& Hein(2020)Croce and Hein]{croce2020reliable}
Croce, F. and Hein, M.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2206--2216. PMLR, 2020.

\bibitem[Croce et~al.(2020)Croce, Andriushchenko, Sehwag, Flammarion, Chiang,
  Mittal, and Hein]{croce2020robustbench}
Croce, F., Andriushchenko, M., Sehwag, V., Flammarion, N., Chiang, M., Mittal,
  P., and Hein, M.
\newblock Robustbench: a standardized adversarial robustness benchmark.
\newblock \emph{arXiv preprint arXiv:2010.09670}, 2020.

\bibitem[Cullina et~al.(2018)Cullina, Bhagoji, and Mittal]{cullina2018pac}
Cullina, D., Bhagoji, A.~N., and Mittal, P.
\newblock Pac-learning in the presence of adversaries.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  230--241, 2018.

\bibitem[Dan et~al.(2020)Dan, Wei, and Ravikumar]{pmlr-v119-dan20b}
Dan, C., Wei, Y., and Ravikumar, P.
\newblock Sharp statistical guaratees for adversarially robust {G}aussian
  classification.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, pp.\  2345--2355, 2020.

\bibitem[Diochnos et~al.(2018)Diochnos, Mahloujifar, and
  Mahmoody]{diochnos2018adversarial}
Diochnos, D., Mahloujifar, S., and Mahmoody, M.
\newblock Adversarial risk and robustness: General definitions and implications
  for the uniform distribution.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  10359--10368, 2018.

\bibitem[Dohmatob(2019)]{pmlr-v97-dohmatob19a}
Dohmatob, E.
\newblock Generalized no free lunch theorem for adversarial robustness.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, pp.\  1646--1654, 2019.

\bibitem[Edmonds \& Karp(1972)Edmonds and Karp]{edmonds1972theoretical}
Edmonds, J. and Karp, R.~M.
\newblock Theoretical improvements in algorithmic efficiency for network flow
  problems.
\newblock \emph{Journal of the ACM (JACM)}, 19\penalty0 (2):\penalty0 248--264,
  1972.

\bibitem[Evtimov et~al.(2020)Evtimov, Cui, Kamar, Kiciman, Kohno, and
  Li]{evtimov2020security}
Evtimov, I., Cui, W., Kamar, E., Kiciman, E., Kohno, T., and Li, J.
\newblock Security and machine learning in the real world.
\newblock \emph{arXiv preprint arXiv:2007.07205}, 2020.

\bibitem[Garg et~al.(2020)Garg, Jha, Mahloujifar, and
  Mohammad]{pmlr-v117-garg20a}
Garg, S., Jha, S., Mahloujifar, S., and Mohammad, M.
\newblock Adversarially robust learning could leverage computational hardness.
\newblock In \emph{Proceedings of the 31st International Conference on
  Algorithmic Learning Theory}, pp.\  364--385, 2020.

\bibitem[Gilmer et~al.(2018{\natexlab{a}})Gilmer, Adams, Goodfellow, Andersen,
  and Dahl]{gilmer2018motivating}
Gilmer, J., Adams, R.~P., Goodfellow, I., Andersen, D., and Dahl, G.~E.
\newblock Motivating the rules of the game for adversarial example research.
\newblock \emph{arXiv preprint arXiv:1807.06732}, 2018{\natexlab{a}}.

\bibitem[Gilmer et~al.(2018{\natexlab{b}})Gilmer, Metz, Faghri, Schoenholz,
  Raghu, Wattenberg, and Goodfellow]{gilmer2018adversarial}
Gilmer, J., Metz, L., Faghri, F., Schoenholz, S.~S., Raghu, M., Wattenberg, M.,
  and Goodfellow, I.
\newblock Adversarial spheres.
\newblock In \emph{ICLR}, 2018{\natexlab{b}}.

\bibitem[Goibert \& Dohmatob(2019)Goibert and Dohmatob]{goibert2019adversarial}
Goibert, M. and Dohmatob, E.
\newblock Adversarial robustness via label-smoothing.
\newblock \emph{arXiv preprint arXiv:1906.11567}, 2019.

\bibitem[Goldberg \& Tarjan(1988)Goldberg and Tarjan]{goldberg1988new}
Goldberg, A.~V. and Tarjan, R.~E.
\newblock A new approach to the maximum-flow problem.
\newblock \emph{Journal of the ACM (JACM)}, 35\penalty0 (4):\penalty0 921--940,
  1988.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Gowal et~al.(2020)Gowal, Qin, Uesato, Mann, and
  Kohli]{gowal2020uncovering}
Gowal, S., Qin, C., Uesato, J., Mann, T., and Kohli, P.
\newblock Uncovering the limits of adversarial training against norm-bounded
  adversarial examples.
\newblock \emph{arXiv preprint arXiv:2010.03593}, 2020.

\bibitem[Javanmard et~al.(2020)Javanmard, Soltanolkotabi, and
  Hassani]{pmlr-v125-javanmard20a}
Javanmard, A., Soltanolkotabi, M., and Hassani, H.
\newblock Precise tradeoffs in adversarial training for linear regression.
\newblock In \emph{Proceedings of Thirty Third Conference on Learning Theory},
  pp.\  2034--2078, 2020.

\bibitem[K{\"o}rner(1973)]{korner1973coding}
K{\"o}rner, J.
\newblock Coding of an information source having ambiguous alphabet and the
  entropy of graphs.
\newblock In \emph{6th Prague conference on information theory}, 1973.

\bibitem[Krizhevsky \& Hinton(2009)Krizhevsky and
  Hinton]{krizhevsky2009learning}
Krizhevsky, A. and Hinton, G.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[LeCun \& Cortes(1998)LeCun and Cortes]{lecun1998mnist}
LeCun, Y. and Cortes, C.
\newblock The {MNIST} database of handwritten digits.
\newblock 1998.

\bibitem[Li et~al.(2020)Li, Qi, Xie, and Li]{li2020sok}
Li, L., Qi, X., Xie, T., and Li, B.
\newblock Sok: Certified robustness for deep neural networks.
\newblock \emph{arXiv preprint arXiv:2009.04131}, 2020.

\bibitem[Liu et~al.(2018)Liu, Li, Zhao, Cai, Yu, and Leung]{liu2018survey}
Liu, Q., Li, P., Zhao, W., Cai, W., Yu, S., and Leung, V.~C.
\newblock A survey on security threats and defensive techniques of machine
  learning: A data driven view.
\newblock \emph{IEEE access}, 6:\penalty0 12103--12117, 2018.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry_towards_2017}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{ICLR}, 2018.

\bibitem[Mahloujifar et~al.(2019)Mahloujifar, Diochnos, and
  Mahmoody]{mahloujifar2019curse}
Mahloujifar, S., Diochnos, D.~I., and Mahmoody, M.
\newblock The curse of concentration in robust learning: Evasion and poisoning
  attacks from concentration of measure.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pp.\  4536--4543, 2019.

\bibitem[Montasser et~al.(2019)Montasser, Hanneke, and Srebro]{montasser2019vc}
Montasser, O., Hanneke, S., and Srebro, N.
\newblock Vc classes are adversarially robustly learnable, but only improperly.
\newblock \emph{arXiv preprint arXiv:1902.04217}, 2019.

\bibitem[Montasser et~al.(2020)Montasser, Goel, Diakonikolas, and
  Srebro]{pmlr-v119-montasser20a}
Montasser, O., Goel, S., Diakonikolas, I., and Srebro, N.
\newblock Efficiently learning adversarially robust halfspaces with noise.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, pp.\  7010--7021, 2020.

\bibitem[Pang et~al.(2021)Pang, Yang, Dong, Su, and Zhu]{pang2021bagoftricks}
Pang, T., Yang, X., Dong, Y., Su, H., and Zhu, J.
\newblock Bag of tricks for adversarial training.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=Xb8xvrtB8Ce}.

\bibitem[Papernot et~al.(2016)Papernot, McDaniel, Sinha, and
  Wellman]{papernot2016towards}
Papernot, N., McDaniel, P., Sinha, A., and Wellman, M.
\newblock Towards the science of security and privacy in machine learning.
\newblock \emph{arXiv preprint arXiv:1611.03814}, 2016.

\bibitem[Pydi \& Jog(2020)Pydi and Jog]{pmlr-v119-pydi20a}
Pydi, M.~S. and Jog, V.
\newblock Adversarial risk via optimal transport and optimal couplings.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, pp.\  7814--7823, 2020.

\bibitem[Rice et~al.(2020)Rice, Wong, and Kolter]{rice2020overfitting}
Rice, L., Wong, E., and Kolter, Z.
\newblock Overfitting in adversarially robust deep learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  8093--8104. PMLR, 2020.

\bibitem[Schmidt et~al.(2018)Schmidt, Santurkar, Tsipras, Talwar, and
  Madry]{schmidt2018adversarially}
Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., and Madry, A.
\newblock Adversarially robust generalization requires more data.
\newblock \emph{arXiv preprint arXiv:1804.11285}, 2018.

\bibitem[Sehwag et~al.(2020)Sehwag, Wang, Mittal, and Jana]{sehwag2020hydra}
Sehwag, V., Wang, S., Mittal, P., and Jana, S.
\newblock Hydra: Pruning adversarially robust neural networks.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  7, 2020.

\bibitem[Shalev-Shwartz \& Ben-David(2014)Shalev-Shwartz and
  Ben-David]{shalev-shwartz_understanding_2014}
Shalev-Shwartz, S. and Ben-David, S.
\newblock \emph{Understanding machine learning: {From} theory to algorithms}.
\newblock Cambridge university press, 2014.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6199}, 2013.

\bibitem[Virtanen(2020)]{2020SciPy-NMeth}
Virtanen, P. e.~a.
\newblock {{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in
  Python}.
\newblock \emph{Nature Methods}, 17:\penalty0 261--272, 2020.
\newblock \doi{10.1038/s41592-019-0686-2}.

\bibitem[Wang et~al.(2020)Wang, Zou, Yi, Bailey, Ma, and Gu]{Wang2020revisit}
Wang, Y., Zou, D., Yi, J., Bailey, J., Ma, X., and Gu, Q.
\newblock Improving adversarial robustness requires revisiting misclassified
  examples.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=rklOg6EFwS}.

\bibitem[Wu et~al.(2020)Wu, Xia, and Wang]{wu2020advweightperturb}
Wu, D., Xia, S.-T., and Wang, Y.
\newblock Adversarial weight perturbation helps robust generalization.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017/online}
Xiao, H., Rasul, K., and Vollgraf, R.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms, 2017.

\bibitem[Xie et~al.(2020)Xie, Tan, Gong, Yuille, and Le]{xie2020smoothadv}
Xie, C., Tan, M., Gong, B., Yuille, A., and Le, Q.~V.
\newblock Smooth adversarial training.
\newblock \emph{arXiv preprint arXiv:2006.14536}, 2020.

\bibitem[Yin et~al.(2019)Yin, Ramchandran, and Bartlett]{yin2018rademacher}
Yin, D., Ramchandran, K., and Bartlett, P.
\newblock Rademacher complexity for adversarially robust generalization.
\newblock In \emph{ICML}, 2019.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, Ghaoui, and
  Jordan]{zhang2019theoretically}
Zhang, H., Yu, Y., Jiao, J., Xing, E.~P., Ghaoui, L.~E., and Jordan, M.~I.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock \emph{arXiv preprint arXiv:1901.08573}, 2019.

\bibitem[Zheng et~al.(2016)Zheng, Song, Leung, and
  Goodfellow]{zheng2016stability}
Zheng, S., Song, Y., Leung, T., and Goodfellow, I.
\newblock Improving the robustness of deep neural networks via stability
  training.
\newblock In \emph{Proceedings of the ieee conference on computer vision and
  pattern recognition}, pp.\  4480--4488, 2016.

\end{thebibliography}
