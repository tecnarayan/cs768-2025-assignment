\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbeel and Ng(2004)]{abbeel2004apprenticeship}
Pieter Abbeel and Andrew~Y. Ng.
\newblock Apprenticeship learning via inverse reinforcement learning.
\newblock In \emph{{ICML}}, volume~69 of \emph{{ACM} International Conference
  Proceeding Series}. {ACM}, 2004.

\bibitem[Abel et~al.(2016)Abel, MacGlashan, and Littman]{abel2016reinforcement}
David Abel, James MacGlashan, and Michael~L Littman.
\newblock Reinforcement learning as a framework for ethical decision making.
\newblock In \emph{Workshops at the thirtieth AAAI conference on artificial
  intelligence}, 2016.

\bibitem[Arnold et~al.(2017)Arnold, Kasenberg, and Scheutz]{arnold2017value}
Thomas Arnold, Daniel Kasenberg, and Matthias Scheutz.
\newblock Value alignment or misalignment--what will keep systems accountable?
\newblock In \emph{Workshops at the Thirty-First AAAI Conference on Artificial
  Intelligence}, 2017.

\bibitem[Arora and Doshi(2018)]{Arora2018ASO}
Saurabh Arora and Prashant Doshi.
\newblock A survey of inverse reinforcement learning: Challenges, methods and
  progress.
\newblock \emph{ArXiv}, abs/1806.06877, 2018.

\bibitem[Author(s)(2019{\natexlab{a}})]{DeepSetQ}
Anonymous Author(s).
\newblock Dynamic input for deep reinforcement learning in autonomous driving.
\newblock In \emph{the supplementary}, 2019{\natexlab{a}}.

\bibitem[Author(s)(2019{\natexlab{b}})]{composite_q}
Anonymous Author(s).
\newblock Off-policy multi-step q-learning.
\newblock In \emph{the supplementary}, 2019{\natexlab{b}}.

\bibitem[Author(s)(2020)]{kalweit2020interpretable}
Anonymous Author(s).
\newblock Interpretable multi time-scale constraints in model-free deep
  reinforcement learning for autonomous driving.
\newblock In \emph{the supplementary}, 2020.

\bibitem[Boularias et~al.(2011)Boularias, Kober, and
  Peters]{DBLP:journals/jmlr/BoulariasKP11}
Abdeslam Boularias, Jens Kober, and Jan Peters.
\newblock Relative entropy inverse reinforcement learning.
\newblock In Geoffrey~J. Gordon, David~B. Dunson, and Miroslav Dud{\'{\i}}k,
  editors, \emph{Proceedings of the Fourteenth International Conference on
  Artificial Intelligence and Statistics, {AISTATS} 2011, Fort Lauderdale, USA,
  April 11-13, 2011}, volume~15 of \emph{{JMLR} Proceedings}, pages 182--189.
  JMLR.org, 2011.

\bibitem[Capelli(1892)]{capelli}
A.~Capelli.
\newblock Sopra la compatibilitá o incompatibilitá di più equazioni di primo
  grado fra picì incognite.
\newblock \emph{Revista di Mathematica}, 2:\penalty0 54--58, 1892.

\bibitem[Dayan(1993)]{dayan93successor}
Peter Dayan.
\newblock Improving generalization for temporal difference learning: The
  successor representation.
\newblock \emph{Neural Computation}, 5\penalty0 (4):\penalty0 613--624, 1993.

\bibitem[Englert et~al.(2017)Englert, Vien, and Toussaint]{englert2017invkkt}
Peter Englert, Ngo~Anh Vien, and Marc Toussaint.
\newblock Inverse kkt: Learning cost functions of manipulation tasks from
  demonstrations.
\newblock \emph{The International Journal of Robotics Research}, 36\penalty0
  (13-14):\penalty0 1474--1488, 2017.

\bibitem[Finn et~al.(2016)Finn, Levine, and Abbeel]{DBLP:conf/icml/FinnLA16}
Chelsea Finn, Sergey Levine, and Pieter Abbeel.
\newblock Guided cost learning: Deep inverse optimal control via policy
  optimization.
\newblock In Maria{-}Florina Balcan and Kilian~Q. Weinberger, editors,
  \emph{Proceedings of the 33nd International Conference on Machine Learning,
  {ICML} 2016, New York City, NY, USA, June 19-24, 2016}, volume~48 of
  \emph{{JMLR} Workshop and Conference Proceedings}, pages 49--58. JMLR.org,
  2016.

\bibitem[Frey and Osborne(2017)]{frey2017future}
Carl~Benedikt Frey and Michael~A. Osborne.
\newblock The future of employment: How susceptible are jobs to
  computerisation?
\newblock \emph{Technological Forecasting and Social Change}, 114:\penalty0 254
  -- 280, 2017.
\newblock ISSN 0040-1625.

\bibitem[Fujimoto et~al.(2018)Fujimoto, van Hoof, and
  Meger]{DBLP:conf/icml/FujimotoHM18}
Scott Fujimoto, Herke van Hoof, and David Meger.
\newblock Addressing function approximation error in actor-critic methods.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning, {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July 10-15,
  2018}, pages 1582--1591, 2018.

\bibitem[Ho and Ermon(2016)]{DBLP:conf/nips/HoE16}
Jonathan Ho and Stefano Ermon.
\newblock Generative adversarial imitation learning.
\newblock In Daniel~D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle
  Guyon, and Roman Garnett, editors, \emph{Advances in Neural Information
  Processing Systems 29: Annual Conference on Neural Information Processing
  Systems 2016, December 5-10, 2016, Barcelona, Spain}, pages 4565--4573, 2016.

\bibitem[Kingma and Ba(2014)]{DBLP:journals/corr/KingmaB14}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock \emph{CoRR}, abs/1412.6980, 2014.

\bibitem[Krajzewicz et~al.(2012)Krajzewicz, Erdmann, Behrisch, and
  Bieker-Walz]{sumo}
Daniel Krajzewicz, Jakob Erdmann, Michael Behrisch, and Laura Bieker-Walz.
\newblock Recent development and applications of sumo - simulation of urban
  mobility.
\newblock \emph{International Journal On Advances in Systems and Measurements},
  3 and 4, 12 2012.

\bibitem[Kulkarni et~al.(2016)Kulkarni, Saeedi, Gautam, and
  Gershman]{kulkarni2016successor}
Tejas~D. Kulkarni, Ardavan Saeedi, Simanta Gautam, and Samuel~J. Gershman.
\newblock Deep successor reinforcement learning.
\newblock \emph{CoRR}, abs/1606.02396, 2016.

\bibitem[Levine et~al.(2011)Levine, Popovic, and Koltun]{NIPS2011_4420}
Sergey Levine, Zoran Popovic, and Vladlen Koltun.
\newblock Nonlinear inverse reinforcement learning with gaussian processes.
\newblock In J.~Shawe-Taylor, R.~S. Zemel, P.~L. Bartlett, F.~Pereira, and
  K.~Q. Weinberger, editors, \emph{Advances in Neural Information Processing
  Systems 24}, pages 19--27. Curran Associates, Inc., 2011.

\bibitem[Nedelkoska and Quintini(2018)]{nedelkoska2018automation}
Ljubica Nedelkoska and Glenda Quintini.
\newblock Automation, skills use and training.
\newblock \penalty0 (202), 2018.

\bibitem[Neu and Szepesv{\'{a}}ri(2007)]{neu07}
Gergely Neu and Csaba Szepesv{\'{a}}ri.
\newblock Apprenticeship learning using inverse reinforcement learning and
  gradient methods.
\newblock In Ronald Parr and Linda~C. van~der Gaag, editors, \emph{{UAI} 2007,
  Proceedings of the Twenty-Third Conference on Uncertainty in Artificial
  Intelligence, Vancouver, BC, Canada, July 19-22, 2007}, pages 295--302.
  {AUAI} Press, 2007.

\bibitem[Ng and Russell(2000)]{DBLP:conf/icml/NgR00}
Andrew~Y. Ng and Stuart~J. Russell.
\newblock Algorithms for inverse reinforcement learning.
\newblock In Pat Langley, editor, \emph{Proceedings of the Seventeenth
  International Conference on Machine Learning {(ICML} 2000), Stanford
  University, Stanford, CA, USA, June 29 - July 2, 2000}, pages 663--670.
  Morgan Kaufmann, 2000.

\bibitem[Ramachandran and Amir(2007)]{ramachandran2007bayesian}
Deepak Ramachandran and Eyal Amir.
\newblock Bayesian inverse reinforcement learning.
\newblock In Manuela~M. Veloso, editor, \emph{{IJCAI} 2007, Proceedings of the
  20th International Joint Conference on Artificial Intelligence, Hyderabad,
  India, January 6-12, 2007}, pages 2586--2591, 2007.

\bibitem[Ratliff et~al.(2006)Ratliff, Bagnell, and
  Zinkevich]{Ratliff:2006:MMP:1143844.1143936}
Nathan~D. Ratliff, J.~Andrew Bagnell, and Martin~A. Zinkevich.
\newblock Maximum margin planning.
\newblock In \emph{Proceedings of the 23rd International Conference on Machine
  Learning}, ICML '06, pages 729--736, New York, NY, USA, 2006. ACM.
\newblock ISBN 1-59593-383-2.

\bibitem[Russell et~al.(2015)Russell, Dewey, and Tegmark]{russell2015research}
Stuart Russell, Daniel Dewey, and Max Tegmark.
\newblock Research priorities for robust and beneficial artificial
  intelligence.
\newblock \emph{Ai Magazine}, 36\penalty0 (4):\penalty0 105--114, 2015.

\bibitem[Tschiatschek et~al.(2019)Tschiatschek, Ghosh, Haug, Devidze, and
  Singla]{DBLP:conf/nips/TschiatschekGHD19}
Sebastian Tschiatschek, Ahana Ghosh, Luis Haug, Rati Devidze, and Adish Singla.
\newblock Learner-aware teaching: Inverse reinforcement learning with
  preferences and constraints.
\newblock In Hanna~M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence
  d'Alch{\'{e}}{-}Buc, Emily~B. Fox, and Roman Garnett, editors, \emph{Advances
  in Neural Information Processing Systems 32: Annual Conference on Neural
  Information Processing Systems 2019, NeurIPS 2019, 8-14 December 2019,
  Vancouver, BC, Canada}, pages 4147--4157, 2019.

\bibitem[van Hasselt et~al.(2015)van Hasselt, Guez, and
  Silver]{DBLP:journals/corr/HasseltGS15}
Hado van Hasselt, Arthur Guez, and David Silver.
\newblock Deep reinforcement learning with double q-learning.
\newblock \emph{CoRR}, abs/1509.06461, 2015.

\bibitem[Watkins and Dayan(1992)]{watkins1992q}
Christopher~JCH Watkins and Peter Dayan.
\newblock Q-learning.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 279--292, 1992.

\bibitem[Wulfmeier et~al.(2015)Wulfmeier, Ondruska, and
  Posner]{DBLP:journals/corr/WulfmeierOP15}
Markus Wulfmeier, Peter Ondruska, and Ingmar Posner.
\newblock Maximum entropy deep inverse reinforcement learning.
\newblock \emph{CoRR}, abs/1507.04888, 2015.

\bibitem[Ziebart et~al.(2008)Ziebart, Maas, Bagnell, and
  Dey]{Ziebart2008MaximumEI}
Brian~D. Ziebart, Andrew~L. Maas, J.~Andrew Bagnell, and Anind~K. Dey.
\newblock Maximum entropy inverse reinforcement learning.
\newblock In \emph{AAAI}, 2008.

\end{thebibliography}
