@article{roberts1996exponential,
 ISSN = {13507265},
 URL = {http://www.jstor.org/stable/3318418},
 abstract = {In this paper we consider a continuous-time method of approximating a given distribution π using the Langevin diffusion d Lt= d Wt+1/2∇ log π ( Lt) dt. We find conditions under this diffusion converges exponentially quickly to π or does not: in one dimension, these are essentially that for distributions with exponential tails of the form π(x) ∝ exp(-γ |x|β), 0 < β < ∞, exponential convergence occurs if and only if β ≥ 1. We then consider conditions under which the discrete approximations to the diffusion converge. We first show that even when the diffusion itself converges, naive discretizations need not do so. We then consider a 'Metropolis-adjusted' version of the algorithm, and find conditions under which this also converges at an exponential rate: perhaps surprisingly, even the Metropolized version need not converge exponentially fast even if the diffusion does. We briefly discuss a truncated form of the algorithm which, in practice, should avoid the difficulties of the other forms.},
 author = {Gareth O. Roberts and Richard L. Tweedie},
 journal = {Bernoulli},
 number = {4},
 pages = {341--363},
 publisher = {International Statistical Institute (ISI) and Bernoulli Society for Mathematical Statistics and Probability},
 title = {Exponential Convergence of Langevin Distributions and Their Discrete Approximations},
 urldate = {2023-10-27},
 volume = {2},
 year = {1996}
}

@article{roberts1998optimal,
  title={Optimal scaling of discrete approximations to Langevin diffusions},
  author={Roberts, Gareth O and Rosenthal, Jeffrey S},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={60},
  number={1},
  pages={255--268},
  year={1998},
  publisher={Wiley Online Library}
}

@article{liu2022gradient,
  title={Gradient-Guided Importance Sampling for Learning Binary Energy-Based Models},
  author={Liu, Meng and Liu, Haoran and Ji, Shuiwang},
  journal={arXiv preprint arXiv:2210.05782},
  year={2022}
}

@article{dai2020learning,
  title={Learning discrete energy-based models via auxiliary-variable local exploration},
  author={Dai, Hanjun and Singh, Rishabh and Dai, Bo and Sutton, Charles and Schuurmans, Dale},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={10443--10455},
  year={2020}
}
@article{lyu2012interpretation,
  title={Interpretation and generalization of score matching},
  author={Lyu, Siwei},
  journal={arXiv preprint arXiv:1205.2629},
  year={2012}
}
@article{hyvarinen2007some,
  title={Some extensions of score matching},
  author={Hyv{\"a}rinen, Aapo},
  journal={Computational statistics \& data analysis},
  volume={51},
  number={5},
  pages={2499--2512},
  year={2007},
  publisher={Elsevier}
}
@book{lifshitz,
  title="Statistical physics: theory of the condensed state",
  author="Lifshitz, Evgenii Mikhailovich and Pitaevskii, Lev Petrovich",
  volume={9},
  year={2013},
  publisher={Elsevier}
}

@article{li2015resampling,
  title={Resampling methods for particle filtering: classification, implementation, and strategies},
  author={Li, Tiancheng and Bolic, Miodrag and Djuric, Petar M},
  journal={IEEE Signal processing magazine},
  volume={32},
  number={3},
  pages={70--86},
  year={2015},
  publisher={IEEE}
}

@inproceedings{gordon1993novel,
  title={Novel approach to nonlinear/non-Gaussian Bayesian state estimation},
  author={Gordon, Neil J and Salmond, David J and Smith, Adrian FM},
  booktitle={IEE proceedings F (radar and signal processing)},
  volume={140},
  pages={107--113},
  year={1993},
  organization={IET}
}


@article{kitagawa1996monte,
  title={Monte Carlo filter and smoother for non-Gaussian nonlinear state space models},
  author={Kitagawa, Genshiro},
  journal={Journal of computational and graphical statistics},
  volume={5},
  number={1},
  pages={1--25},
  year={1996},
  publisher={Taylor \& Francis}
}

@article{carpenter1999improved,
  title={Improved particle filter for nonlinear problems},
  author={Carpenter, James and Clifford, Peter and Fearnhead, Paul},
  journal={IEE Proceedings-Radar, Sonar and Navigation},
  volume={146},
  number={1},
  pages={2--7},
  year={1999},
  publisher={IET}
}


@article{
lip2002equilibrium,
author = {Jan Liphardt  and Sophie Dumont  and Steven B. Smith  and Ignacio Tinoco  and Carlos Bustamante },
title = {Equilibrium Information from Nonequilibrium Measurements in an Experimental Test of Jarzynski's Equality},
journal = {Science},
volume = {296},
number = {5574},
pages = {1832-1835},
year = {2002},
URL = {https://www.science.org/doi/abs/10.1126/science.1071152},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1071152}}


@inproceedings{
midgley2023flow,
title={Flow Annealed Importance Sampling Bootstrap},
author={Laurence Illing Midgley and Vincent Stimper and Gregor N. C. Simm and Bernhard Sch{\"o}lkopf and Jos{\'e} Miguel Hern{\'a}ndez-Lobato},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=XCTVFJwS9LJ}
}

@inproceedings{
doucet2022scorebased,
title={Score-Based Diffusion meets Annealed Importance Sampling},
author={Arnaud Doucet and Will Sussman Grathwohl and Alexander G. D. G. Matthews and Heiko Strathmann},
booktitle={Advances in Neural Information Processing Systems},
year={2022}
}

@misc{ding2020learning,
      title={Learning Deep Generative Models with Annealed Importance Sampling}, 
      author={Xinqiang Ding and David J. Freedman},
      year={2020},
      eprint={1906.04904},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{
hummer2001free,
author = {Gerhard Hummer  and Attila Szabo },
title = {Free energy reconstruction from nonequilibrium single-molecule
 pulling experiments},
journal = {Proceedings of the National Academy of Sciences},
volume = {98},
number = {7},
pages = {3658-3661},
year = {2001},
doi = {10.1073/pnas.071034098},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.071034098},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.071034098}}

@inproceedings{
anh2018autoencoding,
title={Auto-Encoding Sequential Monte Carlo},
author={Tuan Anh Le and Maximilian Igl and Tom Rainforth and Tom Jin and Frank Wood},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=BJ8c3f-0b},
}

@inproceedings{du2023reduce,
  title={Reduce, reuse, recycle: Compositional generation with energy-based diffusion models and mcmc},
  author={Du, Yilun and Durkan, Conor and Strudel, Robin and Tenenbaum, Joshua B and Dieleman, Sander and Fergus, Rob and Sohl-Dickstein, Jascha and Doucet, Arnaud and Grathwohl, Will Sussman},
  booktitle={International Conference on Machine Learning},
  pages={8489--8510},
  year={2023},
  organization={PMLR}
}





@InProceedings{pmlr-v37-sohl-dickstein15,
  title = 	 {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
  author = 	 {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {2256--2265},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  url = 	 {https://proceedings.mlr.press/v37/sohl-dickstein15.html}
}

@article{Roberts2002LangevinDA,
  title={Langevin Diffusions and Metropolis-Hastings Algorithms},
  author={Gareth O. Roberts and Osnat Stramer},
  journal={Methodology And Computing In Applied Probability},
  year={2002},
  volume={4},
  pages={337-357}
}

@article{talay1900expansion,
author = { Denis   Talay  and  Luciano   Tubaro },
title = {Expansion of the global error for numerical schemes solving stochastic differential equations},
journal = {Stochastic Analysis and Applications},
volume = {8},
number = {4},
pages = {483-509},
year  = {1990},
publisher = {Taylor & Francis}
}


@Article{mattingly2002stochastic,
  author={Mattingly, J. C. and Stuart, A. M. and Higham, D. J.},
  title={{Ergodicity for SDEs and approximations: locally Lipschitz vector fields and degenerate noise}},
  journal={Stochastic Processes and their Applications},
  year=2002,
  volume={101},
  number={2},
  pages={185-232},
  month={October},
  keywords={ Geometric ergodicity Stochastic differential equations Langevin equation Monotone Dissipative and g},
  doi={},
  abstract={The ergodic properties of SDEs, and various time discretizations for SDEs, are studied. The ergodicity of SDEs is established by using techniques from the theory of Markov chains on general state spaces, such as that expounded by Meyn-Tweedie. Application of these Markov chain results leads to straightforward proofs of geometric ergodicity for a variety of SDEs, including problems with degenerate noise and for problems with locally Lipschitz vector fields. Applications where this theory can be usefully applied include damped-driven Hamiltonian problems (the Langevin equation), the Lorenz equation with degenerate noise and gradient systems. The same Markov chain theory is then used to study time-discrete approximations of these SDEs. The two primary ingredients for ergodicity are a minorization condition and a Lyapunov condition. It is shown that the minorization condition is robust under approximation. For globally Lipschitz vector fields this is also true of the Lyapunov condition. However in the locally Lipschitz case the Lyapunov condition fails for explicit methods such as Euler-Maruyama; for pathwise approximations it is, in general, only inherited by specially constructed implicit discretizations. Examples of such discretization based on backward Euler methods are given, and approximation of the Langevin equation studied in some detail.}
}

@book{oksendal2003stochastic,
    author = {Bernt Oksendal},
    title = {Stochastic Differential Equations},
    publisher = {Springer-Verlag Berlin Heidelberg},
    year = {2003},
    edition = {6}
}

@book{risken1996fokker,
  title={Fokker-planck equation},
  author={Risken, Hannes and Risken, Hannes},
  year={1996},
  publisher={Springer}
}

@article{song2021train,
  title={How to train your energy-based models},
  author={Song, Yang and Kingma, Diederik P},
  journal={arXiv preprint arXiv:2101.03288},
  year={2021}
}

@inproceedings{du2019implicit,
  author = {Du, Yilun and Mordatch, Igor},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Implicit Generation and Modeling with Energy Based Models},
 year = {2019}
}

@inproceedings{qiu2020unbiased,
  title={Unbiased contrastive divergence algorithm for training energy-based latent variable models},
  author={Qiu, Yixuan and Zhang, Lingsong and Wang, Xiao},
  booktitle={International Conference on Learning Representations},
  year={2020}
}


@article{jacob2017unbiased,
  title={Unbiased Markov chain Monte Carlo methods with couplings},
  author={Jacob, Pierre E and O’Leary, John and Atchad{\'e}, Yves F},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={82},
  number={3},
  year={2020}
}

@article{del2012adaptive,
  author = {Pierre Del Moral and Arnaud Doucet and Ajay Jasra},
title = {{On adaptive resampling strategies for sequential Monte Carlo methods}},
volume = {18},
journal = {Bernoulli},
number = {1},
publisher = {Bernoulli Society for Mathematical Statistics and Probability},
pages = {252 -- 278},
keywords = {random resampling, Sequential Monte Carlo methods},
year = {2012}
}



@book{doucet2001sequential,
  title={Sequential Monte Carlo methods in practice},
  author={Doucet, Arnaud and De Freitas, Nando and Gordon, Neil James and others},
  volume={1},
  year={2001},
  publisher={Springer}
}


@article{schmiedl2007optimal,
  title={Optimal finite-time processes in stochastic thermodynamics},
  author={Schmiedl, Tim and Seifert, Udo},
  journal={Physical review letters},
  volume={98},
  number={10},
  pages={108301},
  year={2007},
  publisher={APS}
}

@article{kofke2006sampling,
  title={On the sampling requirements for exponential-work free-energy calculations},
  author={Kofke, David A},
  journal={Molecular Physics},
  volume={104},
  number={22-24},
  pages={3701--3708},
  year={2006},
  publisher={Taylor \& Francis}
}

@article{hendrix2001fast,
  title={A “fast growth” method of computing free energy differences},
  author={Hendrix, DA and Jarzynski, C},
  journal={The Journal of Chemical Physics},
  volume={114},
  number={14},
  pages={5974--5981},
  year={2001},
  publisher={American Institute of Physics}
}


@inproceedings{tieleman2008training,
  title={Training restricted Boltzmann machines using approximations to the likelihood gradient},
  author={Tieleman, Tijmen},
  booktitle={International conference on Machine learning},
  pages={1064--1071},
  year={2008}
}

@article{wenliang2022failure,
  title={On the failure of variational score matching for {VAE} models},
  author={Wenliang, Li Kevin},
  journal={arXiv preprint arXiv:2210.13390},
  year={2022}
}

@inproceedings{swersky2011autoencoders,
  title={On autoencoders and score matching for energy based models},
  author={Swersky, Kevin and Ranzato, Marc'Aurelio and Buchman, David and Freitas, Nando D and Marlin, Benjamin M},
  booktitle={International conference on machine learning (ICML-11)},
  pages={1201--1208},
  year={2011}
}

@book{liu2001monte,
  title={Monte Carlo strategies in scientific computing},
  author={Liu, Jun S and Liu, Jun S},
  volume={75},
  year={2001},
  publisher={Springer}
}

@article{hyvarinen2007connections,
  title={Connections between score matching, contrastive divergence, and pseudolikelihood for continuous-valued variables},
  author={Hyvarinen, Aapo},
  journal={IEEE Transactions on neural networks},
  volume={18},
  number={5},
  pages={1529--1531},
  year={2007},
  publisher={IEEE}
}

@article{vincent2011connection,
  title={A connection between score matching and denoising autoencoders},
  author={Vincent, Pascal},
  journal={Neural computation},
  volume={23},
  number={7},
  pages={1661--1674},
  year={2011},
  publisher={MIT Press}
}

@article{hyvarinen2005estimation,
  title={Estimation of non-normalized statistical models by score matching.},
  author={Hyv{\"a}rinen, Aapo and Dayan, Peter},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={4},
  year={2005}
}

@article{mel1991kramers,
  title={The Kramers problem: Fifty years of development},
  author={Mel'nikov, Vladimir Ivanovi{\v{c}}},
  journal={Physics Reports},
  volume={209},
  number={1-2},
  pages={1--71},
  year={1991},
  publisher={Elsevier}
}

@article{schueller2004critical,
  title={A critical appraisal of reliability estimation procedures for high dimensions},
  author={Schu{\"e}ller, Gerhart Iwo and Pradlwarter, Helmuth J and Koutsourelakis, Phaedon-Stelios},
  journal={Probabilistic engineering mechanics},
  volume={19},
  number={4},
  pages={463--474},
  year={2004},
  publisher={Elsevier}
}

@inproceedings{carreira2005contrastive,
  title={On contrastive divergence learning},
  author={Carreira-Perpinan, Miguel A and Hinton, Geoffrey},
  booktitle={International workshop on artificial intelligence and statistics},
  pages={33--40},
  year={2005},
  organization={PMLR}
}


@article{jarzynski1997nonequilibrium,
  title={Nonequilibrium equality for free energy differences},
  author={Jarzynski, C},
  journal={Physical Review Letters},
  volume={78},
  number={14},
  pages={2690},
  year={1997},
  publisher={APS}
}



@article{djuric2003particle,
  title={Particle filtering},
  author={Djuric, Petar M and Kotecha, Jayesh H and Zhang, Jianqui and Huang, Yufei and Ghirmai, Tadesse and Bugallo, M{\'o}nica F and Miguez, Joaquin},
  journal={IEEE signal processing magazine},
  volume={20},
  number={5},
  pages={19--38},
  year={2003},
  publisher={IEEE}
}

@article{seifert2012stochastic,
  title={Stochastic thermodynamics, fluctuation theorems and molecular machines},
  author={Seifert, Udo},
  journal={Reports on progress in physics},
  volume={75},
  number={12},
  pages={126001},
  year={2012},
  publisher={IOP Publishing}
}


@article{pohorille2010good,
  title={Good practices in free-energy calculations},
  author={Pohorille, Andrew and Jarzynski, Christopher and Chipot, Christophe},
  journal={The Journal of Physical Chemistry B},
  volume={114},
  number={32},
  pages={10235--10253},
  year={2010},
  publisher={ACS Publications}
}

@article{hansen2014practical,
  title={Practical aspects of free-energy calculations: a review},
  author={Hansen, Niels and Van Gunsteren, Wilfred F},
  journal={Journal of chemical theory and computation},
  volume={10},
  number={7},
  pages={2632--2647},
  year={2014},
  publisher={ACS Publications}
}


@article{davie2014applicability,
  title={Applicability of optimal protocols and the Jarzynski equality},
  author={Davie, Stuart J and Jepps, Owen G and Rondoni, Lamberto and Reid, James C and Searles, Debra J},
  journal={Physica Scripta},
  volume={89},
  number={4},
  pages={048002},
  year={2014},
  publisher={IOP Publishing}
}

@article{hinton2002training,
  title={Training products of experts by minimizing contrastive divergence},
  author={Hinton, Geoffrey E},
  journal={Neural computation},
  volume={14},
  number={8},
  pages={1771--1800},
  year={2002},
  publisher={MIT Press}
}

@article{bereux2023learning,
  title={Learning a restricted Boltzmann machine using biased Monte Carlo sampling},
  author={B{\'e}reux, Nicolas and Decelle, Aur{\'e}lien and Furtlehner, Cyril and Seoane, Beatriz},
  journal={SciPost Physics},
  volume={14},
  number={3},
  pages={032},
  year={2023}
}

@article{agoritsas2023explaining,
  title={Explaining the effects of non-convergent sampling in the training of Energy-Based Models},
  author={Agoritsas, Elisabeth and Catania, Giovanni and Decelle, Aur{\'e}lien and Seoane, Beatriz},
  journal={arXiv preprint arXiv:2301.09428},
  year={2023}
}

@book{evans2022partial,
  title={Partial differential equations},
  author={Evans, Lawrence C},
  volume={19},
  year={2022},
  publisher={American Mathematical Society}
}

@inproceedings{ruiz2019contrastive,
  title={A contrastive divergence for combining variational inference and mcmc},
  author={Ruiz, Francisco and Titsias, Michalis},
  booktitle={International Conference on Machine Learning},
  pages={5537--5545},
  year={2019},
  organization={PMLR}
}

@article{chatterjee2018sample,
  title={The sample size required in importance sampling},
  author={Chatterjee, Sourav and Diaconis, Persi},
  journal={The Annals of Applied Probability},
  volume={28},
  number={2},
  pages={1099--1135},
  year={2018},
  publisher={JSTOR}
}

@inproceedings{
Du2020Energy-based,
title={Energy-based models for atomic-resolution protein conformations},
author={Yilun Du and Joshua Meier and Jerry Ma and Rob Fergus and Alexander Rives},
booktitle={International Conference on Learning Representations},
year={2020}
}

@inproceedings{nijkamp2019learning,
  title={Learning non-convergent non-persistent short-run {MCMC} toward energy-based model},
  author={Nijkamp, Erik and Hill, Mitch and Zhu, Song-Chun and Wu, Ying Nian},
  booktitle={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{yair2020contrastive,
title={Contrastive Divergence Learning is a Time Reversal Adversarial Game},
author={Omer Yair and Tomer Michaeli},
booktitle={International Conference on Learning Representations},
year={2021}
}

@InProceedings{pmlr-v139-domingo-enrich21a,
  title = 	 {On Energy-Based Models with Overparametrized Shallow Neural Networks},
  author =       {Domingo-Enrich, Carles and Bietti, Alberto and Vanden-Eijnden, Eric and Bruna, Joan},
  booktitle = 	 {International Conference on Machine Learning},
  pages = 	 {2771--2782},
  year = 	 {2021},
  abstract = 	 {Energy-based models (EBMs) are a simple yet powerful framework for generative modeling. They are based on a trainable energy function which defines an associated Gibbs measure, and they can be trained and sampled from via well-established statistical tools, such as MCMC. Neural networks may be used as energy function approximators, providing both a rich class of expressive models as well as a flexible device to incorporate data structure. In this work we focus on shallow neural networks. Building from the incipient theory of overparametrized neural networks, we show that models trained in the so-called ’active’ regime provide a statistical advantage over their associated ’lazy’ or kernel regime, leading to improved adaptivity to hidden low-dimensional structure in the data distribution, as already observed in supervised learning. Our study covers both the maximum likelihood and Stein Discrepancy estimators, and we validate our theoretical results with numerical experiments on synthetic data.}
}

@article{domingoenrich2022dual,
title={Dual Training of Energy-Based Models with Overparametrized Shallow Neural Networks},
  author={Domingo-Enrich, Carles and Bietti, Alberto and Gabri{\'e}, Marylou and Bruna, Joan and Vanden-Eijnden, Eric},
  journal={arXiv preprint arXiv:2107.05134},
  year={2021}
}



@inproceedings{du2021improved,
  title={Improved Contrastive Divergence Training of Energy-Based Models},
  author={Du, Yilun and Li, Shuang and Tenenbaum, Joshua and Mordatch, Igor},
  booktitle={International Conference on Machine Learning},
  pages={2837--2848},
  year={2021},
  organization={PMLR}
}


@inproceedings{xie2016theory,
  title={A theory of generative convnet},
  author={Xie, Jianwen and Lu, Yang and Zhu, Song-Chun and Wu, Yingnian},
  booktitle={International Conference on Machine Learning},
  pages={2635--2644},
  year={2016},
  organization={PMLR}
}

@inproceedings{xie2021learning,
  title={Learning energy-based model with variational auto-encoder as amortized sampler},
  author={Xie, Jianwen and Zheng, Zilong and Li, Ping},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={10441--10451},
  year={2021}
}

@article{xie2018cooperative,
  title={Cooperative training of descriptor and generator networks},
  author={Xie, Jianwen and Lu, Yang and Gao, Ruiqi and Zhu, Song-Chun and Wu, Ying Nian},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={42},
  number={1},
  pages={27--45},
  year={2018},
  publisher={IEEE}
}


@inproceedings{gao2020flow,
  title={Flow contrastive estimation of energy-based models},
  author={Gao, Ruiqi and Nijkamp, Erik and Kingma, Diederik P and Xu, Zhen and Dai, Andrew M and Wu, Ying Nian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7518--7528},
  year={2020}
}

@inproceedings{xiao2020vaebm,
  title={VAEBM: A Symbiosis between Variational Autoencoders and Energy-based Models},
  author={Xiao, Zhisheng and Kreis, Karsten and Kautz, Jan and Vahdat, Arash},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{lee2022guiding,
  title={Guiding Energy-based Models via Contrastive Latent Variables},
  author={Lee, Hankook and Jeong, Jongheon and Park, Sejun and Shin, Jinwoo},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{smale1961gradient,
  title={On gradient dynamical systems},
  author={Smale, Stephen},
  journal={Annals of Mathematics},
  pages={199--206},
  year={1961},
  publisher={JSTOR}
}

@article{evans1985nose,
  title={The nose--hoover thermostat},
  author={Evans, Denis J and Holian, Brad Lee},
  journal={The Journal of chemical physics},
  volume={83},
  number={8},
  pages={4069--4074},
  year={1985},
  publisher={American Institute of Physics}
}



@article{berner2018oscillating,
  title={Oscillating modes of driven colloids in overdamped systems},
  author={Berner, Johannes and M{\"u}ller, Boris and Gomez-Solano, Juan Ruben and Kr{\"u}ger, Matthias and Bechinger, Clemens},
  journal={Nature communications},
  volume={9},
  number={1},
  pages={999},
  year={2018},
  publisher={Nature Publishing Group UK London}
}


@inproceedings{grathwohl2019your,
  title={Your classifier is secretly an energy based model and you should treat it like one},
  author={Grathwohl, Will and Wang, Kuan-Chieh and Jacobsen, Joern-Henrik and Duvenaud, David and Norouzi, Mohammad and Swersky, Kevin},
  booktitle={International Conference on Learning Representations},
  year={2019}
}



@inproceedings{xie2021tale,
  title={A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model},
  author={Xie, Jianwen and Zhu, Yaxuan and Li, Jun and Li, Ping},
  booktitle={International Conference on Learning Representations},
  year={2021}
}



@inproceedings{schulz2010investigating,
  title={Investigating convergence of restricted boltzmann machine learning},
  author={Schulz, Hannes and M{\"u}ller, Andreas and Behnke, Sven and others},
  booktitle={NIPS 2010 Workshop on Deep Learning and Unsupervised Feature Learning},
  volume={1},
  pages={6--1},
  year={2010}
}


@inproceedings{zhai2016deep,
  title={Deep structured energy based models for anomaly detection},
  author={Zhai, Shuangfei and Cheng, Yu and Lu, Weining and Zhang, Zhongfei},
  booktitle={International conference on machine learning},
  pages={1100--1109},
  year={2016},
  organization={PMLR}
}


@article{scarselli2008graph,
  title={The graph neural network model},
  author={Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  journal={IEEE transactions on neural networks},
  volume={20},
  number={1},
  pages={61--80},
  year={2008},
  publisher={IEEE}
}

@article{younes1999convergence,
  title={On the convergence of Markovian stochastic algorithms with rapidly decreasing ergodicity rates},
  author={Younes, Laurent},
  journal={Stochastics: An International Journal of Probability and Stochastic Processes},
  volume={65},
  number={3-4},
  pages={177--228},
  year={1999},
  publisher={Taylor \& Francis}
}


@article{duane1987hybrid,
  title={Hybrid monte carlo},
  author={Duane, Simon and Kennedy, Anthony D and Pendleton, Brian J and Roweth, Duncan},
  journal={Physics letters B},
  volume={195},
  number={2},
  pages={216--222},
  year={1987},
  publisher={Elsevier}
}

@article{parisi1981correlation,
  title={Correlation functions and computer simulations},
  author={Parisi, Giorgio},
  journal={Nuclear Physics B},
  volume={180},
  number={3},
  pages={378--384},
  year={1981},
  publisher={Elsevier}
}


@book{gibbs1902elementary,
  title={Elementary principles in statistical mechanics: developed with especial reference to the rational foundations of thermodynamics},
  author={Gibbs, Josiah Willard},
  year={1902},
  publisher={C. Scribner's sons}
}


@article{boltzmann1970weitere,
  title={Weitere studien {\"u}ber das w{\"a}rmegleichgewicht unter gasmolek{\"u}len},
  author={Boltzmann, Ludwig},
  journal={Kinetische Theorie II},
  pages={115--225},
  year={1970},
  publisher={Vieweg+ Teubner Verlag}
}


@inproceedings{rezende2014stochastic,
  title={Stochastic backpropagation and approximate inference in deep generative models},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  booktitle={International conference on machine learning},
  pages={1278--1286},
  year={2014},
  organization={PMLR}
}


@inproceedings{van2016pixel,
  title={Pixel recurrent neural networks},
  author={Van Den Oord, A{\"a}ron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1747--1756},
  year={2016},
  organization={PMLR}
}

@article{kingma2019introduction,
  title={An introduction to variational autoencoders},
  author={Kingma, Diederik P and Welling, Max},
  journal={Foundations and Trends in Machine Learning},
  volume={12},
  number={4},
  pages={307--392},
  year={2019},
  publisher={Now Publishers, Inc.}
}

@inproceedings{rezende2015variational,
  title={Variational inference with normalizing flows},
  author={Rezende, Danilo and Mohamed, Shakir},
  booktitle={International conference on machine learning},
  pages={1530--1538},
  year={2015},
  organization={PMLR}
}

@article{albergo2023stochastic,
  title={Stochastic interpolants: A unifying framework for flows and diffusions},
  author={Albergo, Michael S and Boffi, Nicholas M and Vanden-Eijnden, Eric},
  journal={arXiv preprint arXiv:2303.08797},
  year={2023}
}

@article{goodfellow2020generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{ghahramani2015probabilistic,
  title={Probabilistic machine learning and artificial intelligence},
  author={Ghahramani, Zoubin},
  journal={Nature},
  volume={521},
  number={7553},
  pages={452--459},
  year={2015},
  publisher={Nature Publishing Group UK London}
}


@book{ross2014introduction,
  title={Introduction to probability models},
  author={Ross, Sheldon M},
  year={2014},
  publisher={Academic press}
}


@book{beck1977parameter,
  title={Parameter estimation in engineering and science},
  author={Beck, James Vere and Arnold, Kenneth J},
  year={1977},
  publisher={James Beck}
}

@article{aurell2011optimal,
  title={Optimal protocols and optimal transport in stochastic thermodynamics},
  author={Aurell, Erik and Mej{\'\i}a-Monasterio, Carlos and Muratore-Ginanneschi, Paolo},
  journal={Physical review letters},
  volume={106},
  number={25},
  pages={250601},
  year={2011},
  publisher={APS}
}


@article{gore2003bias,
  title={Bias and error in estimates of equilibrium free-energy differences from nonequilibrium measurements},
  author={Gore, Jeff and Ritort, Felix and Bustamante, Carlos},
  journal={Proceedings of the National Academy of Sciences},
  volume={100},
  number={22},
  pages={12564--12569},
  year={2003},
  publisher={National Acad Sciences}
}

@incollection{lecun2006tutorial,
  author      = {LeCun, Yann and Chopra, Sumit and Hadsell, Raia},
  title       = {A tutorial on energy-based learning},
  editor      = {BakIr, G{\"o}khan and Hofmann, Thomas and Smola, Alexander J and Sch{\"o}lkopf, Bernhard and Taskar, Ben},
  booktitle   = {Predicting structured data},
  publisher   = {MIT press},
  year        = {2007},
  chapter     = 10,
}



@article{neal2001annealed,
  title={Annealed importance sampling},
  author={Neal, Radford M},
  journal={Statistics and computing},
  volume={11},
  pages={125--139},
  year={2001},
  publisher={Springer}
}

@inproceedings{song2020score,
  title={Score-Based Generative Modeling through Stochastic Differential Equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{mehrabi2021survey,
  title={A survey on bias and fairness in machine learning},
  author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={6},
  pages={1--35},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@book{cochran1977sampling,
  title={Sampling techniques},
  author={Cochran, William G},
  year={1977},
  publisher={John Wiley \& Sons}
}


@book{brooks2011handbook,
  title={Handbook of Markov chain Monte Carlo},
  author={Brooks, Steve and Gelman, Andrew and Jones, Galin and Meng, Xiao-Li},
  year={2011},
  publisher={CRC press}
}

@article{bouchet2016large,
  title={Large deviations in fast--slow systems},
  author={Bouchet, Freddy and Grafke, Tobias and Tangarife, Tom{\'a}s and Vanden-Eijnden, Eric},
  journal={Journal of Statistical Physics},
  volume={162},
  pages={793--812},
  year={2016},
  publisher={Springer}
}

@inproceedings{welling2002new,
  title={A new learning algorithm for mean field Boltzmann machines},
  author={Welling, Max and Hinton, Geoffrey E},
  booktitle={International conference on artificial neural networks},
  pages={351--357},
  year={2002}
}

@inproceedings{song2019generative,
  title={Generative modeling by estimating gradients of the data distribution},
  author={Song, Yang and Ermon, Stefano},
  booktitle={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{wenliang2019learning,
  title={Learning deep kernels for exponential family densities},
  author={Wenliang, Li and Sutherland, Danica J and Strathmann, Heiko and Gretton, Arthur},
  booktitle={International Conference on Machine Learning},
  year={2019}
}

@article{geiger2010optimum,
  title={Optimum protocol for fast-switching free-energy calculations},
  author={Geiger, Philipp and Dellago, Christoph},
  journal={Physical Review E},
  volume={81},
  number={2},
  pages={021127},
  year={2010},
  publisher={APS}
}

@article{blaber2022optimal,
  title={Optimal control with a strong harmonic trap},
  author={Blaber, Steven and Sivak, David A},
  journal={Physical Review E},
  volume={106},
  number={2},
  pages={L022103},
  year={2022},
  publisher={APS}
}


@article{zulkowski2015optimal,
  title={Optimal control of overdamped systems},
  author={Zulkowski, Patrick R and DeWeese, Michael R},
  journal={Physical Review E},
  volume={92},
  number={3},
  pages={032117},
  year={2015},
  publisher={APS}
}


@article{bolhuis2002transition,
  title={Transition path sampling: Throwing ropes over rough mountain passes, in the dark},
  author={Bolhuis, Peter G and Chandler, David and Dellago, Christoph and Geissler, Phillip L},
  journal={Annual review of physical chemistry},
  volume={53},
  number={1},
  pages={291--318},
  year={2002},
  publisher={Annual Reviews 4139 El Camino Way, PO Box 10139, Palo Alto, CA 94303-0139, USA}
}

@article{gilks1992adaptive,
  title={Adaptive rejection sampling for Gibbs sampling},
  author={Gilks, Walter R and Wild, Pascal},
  journal={Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  volume={41},
  number={2},
  pages={337--348},
  year={1992},
  publisher={Wiley Online Library}
}

@article{lecun-mnisthandwrittendigit-2010,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  username = {mhwombat},
  year = 2010
}

@article{tabak2010density,
author = {Esteban G. Tabak and Eric Vanden-Eijnden},
title = {{Density estimation by dual ascent of the log-likelihood}},
volume = {8},
journal = {Communications in Mathematical Sciences},
number = {1},
publisher = {International Press of Boston},
pages = {217 -- 233},
keywords = {Density estimation, machine learning, maximum likelihood},
year = {2010},
}
@article{tabak2013family,
author = {Tabak, E. G. and Turner, Cristina V.},
title = {A Family of Nonparametric Density Estimation Algorithms},
journal = {Communications on Pure and Applied Mathematics},
volume = {66},
number = {2},
pages = {145-164},
year = {2013}
}

@inproceedings{2020_ho_denoising,
 author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {6840--6851},
 title = {Denoising Diffusion Probabilistic Models},
 volume = {33},
 year = {2020}
}

@inproceedings{NIPS2016_gan,
 author = {Ho, Jonathan and Ermon, Stefano},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 title = {Generative Adversarial Imitation Learning},
 volume = {29},
 year = {2016}
}

@inproceedings{song2020sliced,
  title={Sliced score matching: A scalable approach to density and score estimation},
  author={Song, Yang and Garg, Sahaj and Shi, Jiaxin and Ermon, Stefano},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={574--584},
  year={2020},
  organization={PMLR}
}

@inproceedings{gutmann2010noise,
  title={Noise-contrastive estimation: A new estimation principle for unnormalized statistical models},
  author={Gutmann, Michael and Hyv{\"a}rinen, Aapo},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={297--304},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{park2003free,
  title={Free energy calculation from steered molecular dynamics simulations using Jarzynski’s equality},
  author={Park, Sanghyun and Khalili-Araghi, Fatemeh and Tajkhorshid, Emad and Schulten, Klaus},
  journal={The Journal of chemical physics},
  volume={119},
  number={6},
  pages={3559--3566},
  year={2003},
  publisher={American Institute of Physics}
}


@article{caselle2022stochastic,
  title={Stochastic normalizing flows as non-equilibrium transformations},
  author={Caselle, Michele and Cellini, Elia and Nada, Alessandro and Panero, Marco},
  journal={Journal of High Energy Physics},
  volume={2022},
  number={7},
  pages={1--31},
  year={2022},
  publisher={Springer}
}


@article{rodriguez2004assessing,
  title={Assessing the efficiency of free energy calculation methods},
  author={Rodriguez-Gomez, David and Darve, Eric and Pohorille, Andrew},
  journal={The Journal of chemical physics},
  volume={120},
  number={8},
  pages={3563--3578},
  year={2004},
  publisher={American Institute of Physics}
}


@article{doersch2016tutorial,
  title={Tutorial on variational autoencoders},
  author={Doersch, Carl},
  journal={arXiv preprint arXiv:1606.05908},
  year={2016}
}


@article{hinton2012practical,
  title={A practical guide to training restricted Boltzmann machines},
  author={Hinton, Geoffrey E},
  journal={Neural Networks: Tricks of the Trade: Second Edition},
  pages={599--619},
  year={2012},
  publisher={Springer}
}

@inproceedings{salakhutdinov2010efficient,
  title={Efficient learning of deep Boltzmann machines},
  author={Salakhutdinov, Ruslan and Larochelle, Hugo},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={693--700},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}



@article{song2021maximum,
  title={Maximum likelihood training of score-based diffusion models},
  author={Song, Yang and Durkan, Conor and Murray, Iain and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={1415--1428},
  year={2021}
}

@article{mathieu2020riemannian,
  title={Riemannian continuous normalizing flows},
  author={Mathieu, Emile and Nickel, Maximilian},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2503--2515},
  year={2020}
}

@article{kobyzev2020normalizing,
  title={Normalizing flows: An introduction and review of current methods},
  author={Kobyzev, Ivan and Prince, Simon JD and Brubaker, Marcus A},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={11},
  pages={3964--3979},
  year={2020},
  publisher={IEEE}
}

@article{papamakarios2021normalizing,
  title={Normalizing flows for probabilistic modeling and inference},
  author={Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
  journal={The Journal of Machine Learning Research},
  volume={22},
  number={1},
  pages={2617--2680},
  year={2021},
  publisher={JMLRORG}
}

@inproceedings{zhao2019infovae,
  title={Infovae: Balancing learning and inference in variational autoencoders},
  author={Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
  booktitle={Proceedings of the aaai conference on artificial intelligence},
  volume={33},
  pages={5885--5892},
  year={2019}
}
