\begin{thebibliography}{62}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Cai et~al.(2021)Cai, Hu, Wang, Zhang, Pfister, and Wei]{pngan}
Cai, Y., Hu, X., Wang, H., Zhang, Y., Pfister, H., and Wei, D.
\newblock Learning to generate realistic noisy images via pixel-level
  noise-aware adversarial training.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Cai et~al.(2022{\natexlab{a}})Cai, Lin, Hu, Wang, Yuan, Zhang,
  Timofte, and Van~Gool]{MST}
Cai, Y., Lin, J., Hu, X., Wang, H., Yuan, X., Zhang, Y., Timofte, R., and
  Van~Gool, L.
\newblock Mask-guided spectral-wise transformer for efficient hyperspectral
  image reconstruction.
\newblock In \emph{CVPR}, 2022{\natexlab{a}}.

\bibitem[Cai et~al.(2022{\natexlab{b}})Cai, Lin, Lin, Wang, Zhang, Pfister,
  Timofte, and Van~Gool]{MST++}
Cai, Y., Lin, J., Lin, Z., Wang, H., Zhang, Y., Pfister, H., Timofte, R., and
  Van~Gool, L.
\newblock Mst++: Multi-stage spectral-wise transformer for efficient spectral
  reconstruction.
\newblock In \emph{CVPRW}, 2022{\natexlab{b}}.

\bibitem[Cao et~al.(2021)Cao, Li, Zhang, and Van~Gool]{cao2021video}
Cao, J., Li, Y., Zhang, K., and Van~Gool, L.
\newblock Video super-resolution transformer.
\newblock \emph{arXiv preprint arXiv:2106.06847}, 2021.

\bibitem[Chan et~al.(2021)Chan, Wang, Yu, Dong, and Loy]{r25}
Chan, K.~C., Wang, X., Yu, K., Dong, C., and Loy, C.~C.
\newblock Basicvsr: The search for essential components in video
  super-resolution and beyond.
\newblock In \emph{CVPR}, 2021.

\bibitem[Chen et~al.(2018)Chen, Firat, Bapna, Johnson, Macherey, Foster, Jones,
  Parmar, Schuster, Chen, et~al.]{r3}
Chen, M.~X., Firat, O., Bapna, A., Johnson, M., Macherey, W., Foster, G.,
  Jones, L., Parmar, N., Schuster, M., Chen, Z., et~al.
\newblock The best of both worlds: Combining recent advances in neural machine
  translation.
\newblock In \emph{ACL}, 2018.

\bibitem[Chopra et~al.(2016)Chopra, Auli, and Rush]{r1}
Chopra, S., Auli, M., and Rush, A.~M.
\newblock Abstractive sentence summarization with attentive recurrent neural
  networks.
\newblock In \emph{NAACL-HLT}, 2016.

\bibitem[Dai et~al.(2015)Dai, Yoo, Kappeler, and Katsaggelos]{r34}
Dai, Q., Yoo, S., Kappeler, A., and Katsaggelos, A.~K.
\newblock Dictionary-based multiple frame video super-resolution.
\newblock In \emph{ICIP}, 2015.

\bibitem[Deng et~al.(2020)Deng, Wang, Pu, and Zhuo]{deng2020spatio}
Deng, J., Wang, L., Pu, S., and Zhuo, C.
\newblock Spatio-temporal deformable convolution for compressed video quality
  enhancement.
\newblock In \emph{AAAI}, 2020.

\bibitem[Deng et~al.(2021)Deng, Ren, Yan, Wang, Song, and Cao]{deng2021multi}
Deng, S., Ren, W., Yan, Y., Wang, T., Song, F., and Cao, X.
\newblock Multi-scale separable network for ultra-high-definition video
  deblurring.
\newblock In \emph{CVPR}, 2021.

\bibitem[Dong et~al.(2015)Dong, Deng, Loy, and Tang]{dong2015compression}
Dong, C., Deng, Y., Loy, C.~C., and Tang, X.
\newblock Compression artifacts reduction by a deep convolutional network.
\newblock In \emph{ICCV}, 2015.

\bibitem[Dosovitskiy et~al.(2015)Dosovitskiy, Fischer, Ilg, Hausser, Hazirbas,
  Golkov, Van Der~Smagt, Cremers, and Brox]{r80}
Dosovitskiy, A., Fischer, P., Ilg, E., Hausser, P., Hazirbas, C., Golkov, V.,
  Van Der~Smagt, P., Cremers, D., and Brox, T.
\newblock Flownet: Learning optical flow with convolutional networks.
\newblock In \emph{ICCV}, 2015.

\bibitem[Godard et~al.(2017)Godard, Mac~Aodha, and Brostow]{smooth_loss}
Godard, C., Mac~Aodha, O., and Brostow, G.~J.
\newblock Unsupervised monocular depth estimation with left-right consistency.
\newblock In \emph{CVPR}, 2017.

\bibitem[Guan et~al.(2019)Guan, Xing, Xu, Yang, Liu, and Wang]{r12}
Guan, Z., Xing, Q., Xu, M., Yang, R., Liu, T., and Wang, Z.
\newblock Mfqe 2.0: A new approach for multi-frame quality enhancement on
  compressed video.
\newblock \emph{TPAMI}, 2019.

\bibitem[Haris et~al.(2019)Haris, Shakhnarovich, and Ukita]{r76}
Haris, M., Shakhnarovich, G., and Ukita, N.
\newblock Recurrent back-projection network for video super-resolution.
\newblock In \emph{CVPR}, 2019.

\bibitem[He et~al.(2021)He, Zheng, Sun, Wang, and Qin]{r30}
He, D., Zheng, Y., Sun, B., Wang, Y., and Qin, H.
\newblock Checkerboard context model for efficient learned image compression.
\newblock In \emph{CVPR}, 2021.

\bibitem[Hyun~Kim et~al.(2017)Hyun~Kim, Mu~Lee, Scholkopf, and Hirsch]{r70}
Hyun~Kim, T., Mu~Lee, K., Scholkopf, B., and Hirsch, M.
\newblock Online video deblurring via dynamic temporal blending network.
\newblock In \emph{ICCV}, 2017.

\bibitem[Isobe et~al.(2020)Isobe, Jia, Gu, Li, Wang, and Tian]{r40}
Isobe, T., Jia, X., Gu, S., Li, S., Wang, S., and Tian, Q.
\newblock Video super-resolution with recurrent structure-detail network.
\newblock In \emph{ECCV}, 2020.

\bibitem[Jo et~al.(2018)Jo, Oh, Kang, and Kim]{r75}
Jo, Y., Oh, S.~W., Kang, J., and Kim, S.~J.
\newblock Deep video super-resolution network using dynamic upsampling filters
  without explicit motion compensation.
\newblock In \emph{CVPR}, 2018.

\bibitem[Jozefowicz et~al.(2015)Jozefowicz, Zaremba, and
  Sutskever]{jozefowicz2015empirical}
Jozefowicz, R., Zaremba, W., and Sutskever, I.
\newblock An empirical exploration of recurrent network architectures.
\newblock In \emph{ICML}, 2015.

\bibitem[Kuznetsov \& Mariet(2019)Kuznetsov and Mariet]{r31}
Kuznetsov, V. and Mariet, Z.
\newblock Foundations of sequence-to-sequence modeling for time series.
\newblock In \emph{AISTATS}, 2019.

\bibitem[Li et~al.(2020)Li, Tao, Guo, Qi, Lu, and Jia]{r78}
Li, W., Tao, X., Guo, T., Qi, L., Lu, J., and Jia, J.
\newblock Mucan: Multi-correspondence aggregation network for video
  super-resolution.
\newblock In \emph{ECCV}, 2020.

\bibitem[Liang et~al.(2022)Liang, Cao, Fan, Zhang, Ranjan, Li, Timofte, and
  Van~Gool]{VRT}
Liang, J., Cao, J., Fan, Y., Zhang, K., Ranjan, R., Li, Y., Timofte, R., and
  Van~Gool, L.
\newblock Vrt: A video restoration transformer.
\newblock \emph{arXiv preprint arXiv:2201.12288}, 2022.

\bibitem[Liao et~al.(2015)Liao, Tao, Li, Ma, and Jia]{r36}
Liao, R., Tao, X., Li, R., Ma, Z., and Jia, J.
\newblock Video super-resolution via deep draft-ensemble learning.
\newblock In \emph{ICCV}, 2015.

\bibitem[Lin et~al.(2022{\natexlab{a}})Lin, Cai, Hu, Wang, Yan, Zou, Ding,
  Zhang, Timofte, and Van~Gool]{FGST}
Lin, J., Cai, Y., Hu, X., Wang, H., Yan, Y., Zou, X., Ding, H., Zhang, Y.,
  Timofte, R., and Van~Gool, L.
\newblock Flow-guided sparse transformer for video deblurring.
\newblock \emph{arXiv preprint arXiv:2201.01893}, 2022{\natexlab{a}}.

\bibitem[Lin et~al.(2022{\natexlab{b}})Lin, Cai, Hu, Wang, Yuan, Zhang,
  Timofte, and Van~Gool]{CST}
Lin, J., Cai, Y., Hu, X., Wang, H., Yuan, X., Zhang, Y., Timofte, R., and
  Van~Gool, L.
\newblock Coarse-to-fine sparse transformer for hyperspectral image
  reconstruction.
\newblock \emph{arXiv preprint arXiv:2203.04845}, 2022{\natexlab{b}}.

\bibitem[Liu et~al.(2020)Liu, Zhang, He, Liu, Wang, Tai, Luo, Wang, Li, and
  Huang]{r55}
Liu, L., Zhang, J., He, R., Liu, Y., Wang, Y., Tai, Y., Luo, D., Wang, C., Li,
  J., and Huang, F.
\newblock Learning by analogy: Reliable supervision from transformations for
  unsupervised optical flow estimation.
\newblock In \emph{CVPR}, 2020.

\bibitem[M{\'e}min \& P{\'e}rez(1998)M{\'e}min and P{\'e}rez]{r44}
M{\'e}min, E. and P{\'e}rez, P.
\newblock Dense estimation and object-based segmentation of the optical flow
  with robust techniques.
\newblock \emph{TIP}, 1998.

\bibitem[Nah et~al.(2017)Nah, Hyun~Kim, and Mu~Lee]{r74}
Nah, S., Hyun~Kim, T., and Mu~Lee, K.
\newblock Deep multi-scale convolutional neural network for dynamic scene
  deblurring.
\newblock In \emph{CVPR}, 2017.

\bibitem[Nah et~al.(2019{\natexlab{a}})Nah, Baik, Hong, Moon, Son, Timofte, and
  Mu~Lee]{r58}
Nah, S., Baik, S., Hong, S., Moon, G., Son, S., Timofte, R., and Mu~Lee, K.
\newblock Ntire 2019 challenge on video deblurring and super-resolution:
  Dataset and study.
\newblock In \emph{CVPRW}, 2019{\natexlab{a}}.

\bibitem[Nah et~al.(2019{\natexlab{b}})Nah, Son, and Lee]{r71}
Nah, S., Son, S., and Lee, K.~M.
\newblock Recurrent neural networks with intra-frame iterations for video
  deblurring.
\newblock In \emph{CVPR}, 2019{\natexlab{b}}.

\bibitem[Ohm et~al.(2012)Ohm, Sullivan, Schwarz, Tan, and Wiegand]{r57}
Ohm, J.-R., Sullivan, G.~J., Schwarz, H., Tan, T.~K., and Wiegand, T.
\newblock Comparison of the coding efficiency of video coding
  standardsâ€”including high efficiency video coding (hevc).
\newblock \emph{TCSVT}, 2012.

\bibitem[Ott et~al.(2018)Ott, Edunov, Grangier, and Auli]{r2}
Ott, M., Edunov, S., Grangier, D., and Auli, M.
\newblock Scaling neural machine translation.
\newblock \emph{arXiv preprint arXiv:1806.00187}, 2018.

\bibitem[Pan et~al.(2020)Pan, Bai, and Tang]{r14}
Pan, J., Bai, H., and Tang, J.
\newblock Cascaded deep video deblurring using temporal sharpness prior.
\newblock In \emph{CVPR}, 2020.

\bibitem[Sajjadi et~al.(2018)Sajjadi, Vemulapalli, and Brown]{r10}
Sajjadi, M.~S., Vemulapalli, R., and Brown, M.
\newblock Frame-recurrent video super-resolution.
\newblock In \emph{CVPR}, 2018.

\bibitem[Shahar et~al.(2011)Shahar, Faktor, and Irani]{r35}
Shahar, O., Faktor, A., and Irani, M.
\newblock \emph{Space-time super-resolution from a single video}.
\newblock IEEE, 2011.

\bibitem[Shi et~al.(2021)Shi, Keneshloo, Ramakrishnan, and
  Reddy]{shi2021neural}
Shi, T., Keneshloo, Y., Ramakrishnan, N., and Reddy, C.~K.
\newblock Neural abstractive text summarization with sequence-to-sequence
  models.
\newblock \emph{ACM Transactions on Data Science}, 2021.

\bibitem[Shi et~al.(2017)Shi, Gao, Lausen, Wang, Yeung, Wong, and Woo]{r16}
Shi, X., Gao, Z., Lausen, L., Wang, H., Yeung, D.-Y., Wong, W.-k., and Woo,
  W.-c.
\newblock Deep learning for precipitation nowcasting: A benchmark and a new
  model.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Su et~al.(2017)Su, Delbracio, Wang, Sapiro, Heidrich, and Wang]{r68}
Su, S., Delbracio, M., Wang, J., Sapiro, G., Heidrich, W., and Wang, O.
\newblock Deep video deblurring for hand-held cameras.
\newblock In \emph{CVPR}, 2017.

\bibitem[Sun et~al.(2018)Sun, Yang, Liu, and Kautz]{r46}
Sun, D., Yang, X., Liu, M.-Y., and Kautz, J.
\newblock Pwc-net: Cnns for optical flow using pyramid, warping, and cost
  volume.
\newblock In \emph{CVPR}, 2018.

\bibitem[Sutskever et~al.(2014)Sutskever, Vinyals, and Le]{r8}
Sutskever, I., Vinyals, O., and Le, Q.~V.
\newblock Sequence to sequence learning with neural networks.
\newblock \emph{arXiv preprint arXiv:1409.3215}, 2014.

\bibitem[Takeda et~al.(2009)Takeda, Milanfar, Protter, and Elad]{r33}
Takeda, H., Milanfar, P., Protter, M., and Elad, M.
\newblock Super-resolution without explicit subpixel motion estimation.
\newblock \emph{TIP}, 2009.

\bibitem[Tao et~al.(2018)Tao, Gao, Shen, Wang, and Jia]{r67}
Tao, X., Gao, H., Shen, X., Wang, J., and Jia, J.
\newblock Scale-recurrent network for deep image deblurring.
\newblock In \emph{CVPR}, 2018.

\bibitem[Teed \& Deng(2020)Teed and Deng]{r47}
Teed, Z. and Deng, J.
\newblock Raft: Recurrent all-pairs field transforms for optical flow.
\newblock In \emph{ECCV}, 2020.

\bibitem[Tian et~al.(2020)Tian, Zhang, Fu, and Xu]{tian2018tdan}
Tian, Y., Zhang, Y., Fu, Y., and Xu, C.
\newblock Tdan: Temporally-deformable alignment network for video
  super-resolution.
\newblock In \emph{CVPR}, 2020.

\bibitem[Venugopalan et~al.(2015)Venugopalan, Rohrbach, Donahue, Mooney,
  Darrell, and Saenko]{r42}
Venugopalan, S., Rohrbach, M., Donahue, J., Mooney, R., Darrell, T., and
  Saenko, K.
\newblock Sequence to sequence-video to text.
\newblock In \emph{ICCV}, 2015.

\bibitem[Wang et~al.(2019)Wang, Chan, Yu, Dong, and Change~Loy]{r11}
Wang, X., Chan, K.~C., Yu, K., Dong, C., and Change~Loy, C.
\newblock Edvr: Video restoration with enhanced deformable convolutional
  networks.
\newblock In \emph{CVPRW}, 2019.

\bibitem[Wang et~al.(2018{\natexlab{a}})Wang, Yang, Yang, Zhao, Wang, and
  Xu]{r49}
Wang, Y., Yang, Y., Yang, Z., Zhao, L., Wang, P., and Xu, W.
\newblock Occlusion aware unsupervised learning of optical flow.
\newblock In \emph{CVPR}, 2018{\natexlab{a}}.

\bibitem[Wang et~al.(2018{\natexlab{b}})Wang, Yang, Yang, Zhao, Wang, and
  Xu]{wang2018occlusion}
Wang, Y., Yang, Y., Yang, Z., Zhao, L., Wang, P., and Xu, W.
\newblock Occlusion aware unsupervised learning of optical flow.
\newblock In \emph{CVPR}, 2018{\natexlab{b}}.

\bibitem[Wang et~al.(2004)Wang, Bovik, Sheikh, and Simoncelli]{r60}
Wang, Z., Bovik, A.~C., Sheikh, H.~R., and Simoncelli, E.~P.
\newblock Image quality assessment: from error visibility to structural
  similarity.
\newblock \emph{TIP}, 2004.

\bibitem[Wedel et~al.(2009)Wedel, Cremers, Pock, and Bischof]{r45}
Wedel, A., Cremers, D., Pock, T., and Bischof, H.
\newblock Structure-and motion-adaptive regularization for high accuracy optic
  flow.
\newblock In \emph{ICCV}, 2009.

\bibitem[Xiang et~al.(2020)Xiang, Wei, and Pan]{r15}
Xiang, X., Wei, H., and Pan, J.
\newblock Deep video deblurring using sharpness features from exemplars.
\newblock \emph{TIP}, 2020.

\bibitem[Xue et~al.(2019)Xue, Chen, Wu, Wei, and Freeman]{r19}
Xue, T., Chen, B., Wu, J., Wei, D., and Freeman, W.~T.
\newblock Video enhancement with task-oriented flow.
\newblock \emph{IJCV}, 2019.

\bibitem[Yang et~al.(2018{\natexlab{a}})Yang, Xu, Liu, Wang, and
  Guan]{yang2018enhancing}
Yang, R., Xu, M., Liu, T., Wang, Z., and Guan, Z.
\newblock Enhancing quality for hevc compressed videos.
\newblock \emph{TCSVT}, 2018{\natexlab{a}}.

\bibitem[Yang et~al.(2018{\natexlab{b}})Yang, Xu, Wang, and Li]{r13}
Yang, R., Xu, M., Wang, Z., and Li, T.
\newblock Multi-frame quality enhancement for compressed video.
\newblock In \emph{CVPR}, 2018{\natexlab{b}}.

\bibitem[Yang et~al.(2019)Yang, Sun, Xu, and Zeng]{r24}
Yang, R., Sun, X., Xu, M., and Zeng, W.
\newblock Quality-gated convolutional lstm for enhancing compressed video.
\newblock In \emph{ICME}, 2019.

\bibitem[Yi et~al.(2019)Yi, Wang, Jiang, Jiang, and Ma]{r77}
Yi, P., Wang, Z., Jiang, K., Jiang, J., and Ma, J.
\newblock Progressive fusion video super-resolution network via exploiting
  non-local spatio-temporal correlations.
\newblock In \emph{ICCV}, 2019.

\bibitem[Yu et~al.(2016)Yu, Harley, and Derpanis]{photometric_loss}
Yu, J.~J., Harley, A.~W., and Derpanis, K.~G.
\newblock Back to basics: Unsupervised learning of optical flow via brightness
  constancy and motion smoothness.
\newblock In \emph{ECCV}, 2016.

\bibitem[Zhang et~al.(2017)Zhang, Zuo, Chen, Meng, and Zhang]{Zhang2017Beyond}
Zhang, K., Zuo, W., Chen, Y., Meng, D., and Zhang, L.
\newblock Beyond a gaussian denoiser: Residual learning of deep cnn for image
  denoising.
\newblock \emph{TIP}, 2017.

\bibitem[Zheng et~al.(2021)Zheng, Li, Liu, Jiang, Zhang, Li, Dang, and
  He]{zheng2021adaptive}
Zheng, H., Li, X., Liu, F., Jiang, L., Zhang, Q., Li, F., Dang, Q., and He, D.
\newblock Adaptive spatial-temporal fusion of multi-objective networks for
  compressed video perceptual enhancement.
\newblock In \emph{CVPR}, 2021.

\bibitem[Zhong et~al.(2020)Zhong, Gao, Zheng, and Zheng]{r41}
Zhong, Z., Gao, Y., Zheng, Y., and Zheng, B.
\newblock Efficient spatio-temporal recurrent neural network for video
  deblurring.
\newblock In \emph{ECCV}, 2020.

\bibitem[Zhou et~al.(2019)Zhou, Zhang, Pan, Xie, Zuo, and Ren]{r72}
Zhou, S., Zhang, J., Pan, J., Xie, H., Zuo, W., and Ren, J.
\newblock Spatio-temporal filter adaptive network for video deblurring.
\newblock In \emph{ICCV}, 2019.

\end{thebibliography}
