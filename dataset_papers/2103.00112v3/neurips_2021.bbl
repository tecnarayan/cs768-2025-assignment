\begin{thebibliography}{10}

\bibitem{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock {\em arXiv preprint arXiv:1607.06450}, 2016.

\bibitem{gpt3}
Tom~B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.
\newblock Language models are few-shot learners.
\newblock In {\em NeurIPS}, 2020.

\bibitem{detr}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em ECCV}, 2020.

\bibitem{ipt}
Hanting Chen, Yunhe Wang, Tianyu Guo, Chang Xu, Yiping Deng, Zhenhua Liu, Siwei
  Ma, Chunjing Xu, Chao Xu, and Wen Gao.
\newblock Pre-trained image processing transformer.
\newblock In {\em CVPR}, 2021.

\bibitem{mmdetection}
Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, Yu~Xiong, Xiaoxiao Li,
  Shuyang Sun, Wansen Feng, Ziwei Liu, Jiarui Xu, et~al.
\newblock Mmdetection: Open mmlab detection toolbox and benchmark.
\newblock {\em arXiv preprint arXiv:1906.07155}, 2019.

\bibitem{igpt}
Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, and
  Ilya Sutskever.
\newblock Generative pretraining from pixels.
\newblock In {\em ICML}, 2020.

\bibitem{cpvt}
Xiangxiang Chu, Bo~Zhang, Zhi Tian, Xiaolin Wei, and Huaxia Xia.
\newblock Do we really need explicit position encodings for vision
  transformers?
\newblock {\em arXiv preprint arXiv:2102.10882}, 2021.

\bibitem{randaugment}
Ekin~D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V Le.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In {\em CVPR Workshops}, 2020.

\bibitem{bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In {\em NAACL-HLT (1)}, 2019.

\bibitem{vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em ICLR}, 2021.

\bibitem{han2020survey}
Kai Han, Yunhe Wang, Hanting Chen, Xinghao Chen, Jianyuan Guo, Zhenhua Liu,
  Yehui Tang, An~Xiao, Chunjing Xu, Yixing Xu, et~al.
\newblock A survey on vision transformer.
\newblock {\em arXiv preprint arXiv:2012.12556}, 2020.

\bibitem{ghostnet}
Kai Han, Yunhe Wang, Qi~Tian, Jianyuan Guo, Chunjing Xu, and Chang Xu.
\newblock Ghostnet: More features from cheap operations.
\newblock In {\em CVPR}, 2020.

\bibitem{resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{gelu}
Dan Hendrycks and Kevin Gimpel.
\newblock Gaussian error linear units (gelus).
\newblock {\em arXiv preprint arXiv:1606.08415}, 2016.

\bibitem{hoffer2020augment}
Elad Hoffer, Tal Ben-Nun, Itay Hubara, Niv Giladi, Torsten Hoefler, and Daniel
  Soudry.
\newblock Augment your batch: Improving generalization through instance
  repetition.
\newblock In {\em CVPR}, 2020.

\bibitem{senet}
Jie Hu, Li~Shen, and Gang Sun.
\newblock Squeeze-and-excitation networks.
\newblock In {\em CVPR}, 2018.

\bibitem{mindspore}
Huawei.
\newblock Mindspore.
\newblock \url{https://www.mindspore.cn/}, 2020.

\bibitem{cifar}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{alexnet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em NeurIPS}, pages 1097--1105, 2012.

\bibitem{larsson2016fractalnet}
Gustav Larsson, Michael Maire, and Gregory Shakhnarovich.
\newblock Fractalnet: Ultra-deep neural networks without residuals.
\newblock {\em arXiv preprint arXiv:1605.07648}, 2016.

\bibitem{fpn}
Tsung-Yi Lin, Piotr Doll{\'a}r, Ross Girshick, Kaiming He, Bharath Hariharan,
  and Serge Belongie.
\newblock Feature pyramid networks for object detection.
\newblock In {\em CVPR}, 2017.

\bibitem{coco}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em ECCV}, pages 740--755, 2014.

\bibitem{adamw}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock {\em arXiv preprint arXiv:1711.05101}, 2017.

\bibitem{sixteen-head}
Paul Michel, Omer Levy, and Graham Neubig.
\newblock Are sixteen heads really better than one?
\newblock In {\em NeurIPS}, 2019.

\bibitem{flower}
Maria-Elena Nilsback and Andrew Zisserman.
\newblock Automated flower classification over a large number of classes.
\newblock In {\em 2008 Sixth Indian Conference on Computer Vision, Graphics \&
  Image Processing}, pages 722--729. IEEE, 2008.

\bibitem{pets}
Omkar~M Parkhi, Andrea Vedaldi, Andrew Zisserman, and CV~Jawahar.
\newblock Cats and dogs.
\newblock In {\em CVPR}, pages 3498--3505. IEEE, 2012.

\bibitem{pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock {\em NeurIPS}, 2019.

\bibitem{regnet}
Ilija Radosavovic, Raj~Prateek Kosaraju, Ross Girshick, Kaiming He, and Piotr
  Doll{\'a}r.
\newblock Designing network design spaces.
\newblock In {\em CVPR}, 2020.

\bibitem{fasterrcnn}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock In {\em Advances in neural information processing systems}, pages
  91--99, 2015.

\bibitem{imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock {\em International Journal of Computer Vision}, 115(3):211--252,
  2015.

\bibitem{label-smooth}
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew
  Wojna.
\newblock Rethinking the inception architecture for computer vision.
\newblock In {\em CVPR}, 2016.

\bibitem{efficientnet}
Mingxing Tan and Quoc Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In {\em ICML}, 2019.

\bibitem{tang2021augmented}
Yehui Tang, Kai Han, Chang Xu, An~Xiao, Yiping Deng, Chao Xu, and Yunhe Wang.
\newblock Augmented shortcuts for vision transformers.
\newblock {\em arXiv preprint arXiv:2106.15941}, 2021.

\bibitem{tang2021manifold}
Yehui Tang, Yunhe Wang, Yixing Xu, Yiping Deng, Chao Xu, Dacheng Tao, and Chang
  Xu.
\newblock Manifold regularized dynamic network pruning.
\newblock In {\em CVPR}, pages 5018--5028, 2021.

\bibitem{deit}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre
  Sablayrolles, and Herv{\'e} J{\'e}gou.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock In {\em ICML}, 2021.

\bibitem{touvron2020grafit}
Hugo Touvron, Alexandre Sablayrolles, Matthijs Douze, Matthieu Cord, and
  Herv{\'e} J{\'e}gou.
\newblock Grafit: Learning fine-grained image representations with coarse
  labels.
\newblock {\em arXiv preprint arXiv:2011.12982}, 2020.

\bibitem{tsne}
Laurens Van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using t-sne.
\newblock {\em Journal of machine learning research}, 9(11), 2008.

\bibitem{van2018inaturalist}
Grant Van~Horn, Oisin Mac~Aodha, Yang Song, Yin Cui, Chen Sun, Alex Shepard,
  Hartwig Adam, Pietro Perona, and Serge Belongie.
\newblock The inaturalist species classification and detection dataset.
\newblock In {\em CVPR}, pages 8769--8778, 2018.

\bibitem{Att}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em NeurIPS}, 2017.

\bibitem{pvt}
Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong
  Lu, Ping Luo, and Ling Shao.
\newblock Pyramid vision transformer: A versatile backbone for dense prediction
  without convolutions.
\newblock In {\em ICCV}, 2021.

\bibitem{non-local}
Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.
\newblock Non-local neural networks.
\newblock In {\em CVPR}, pages 7794--7803, 2018.

\bibitem{trans2seg}
Enze Xie, Wenjia Wang, Wenhai Wang, Peize Sun, Hang Xu, Ding Liang, and Ping
  Luo.
\newblock Segmenting transparent object in the wild with transformer.
\newblock In {\em IJCAI}, 2021.

\bibitem{xu2021renas}
Yixing Xu, Yunhe Wang, Kai Han, Yehui Tang, Shangling Jui, Chunjing Xu, and
  Chang Xu.
\newblock Renas: Relativistic evaluation of neural architecture search.
\newblock In {\em CVPR}, pages 4411--4420, 2021.

\bibitem{yuan2021tokenstotoken}
Li~Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Zihang Jiang, Francis~EH
  Tay, Jiashi Feng, and Shuicheng Yan.
\newblock Tokens-to-token vit: Training vision transformers from scratch on
  imagenet.
\newblock {\em arXiv preprint arXiv:2101.11986}, 2021.

\bibitem{cutmix}
Sangdoo Yun, Dongyoon Han, Seong~Joon Oh, Sanghyuk Chun, Junsuk Choe, and
  Youngjoon Yoo.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In {\em ICCV}, 2019.

\bibitem{mixup}
Hongyi Zhang, Moustapha Cisse, Yann~N Dauphin, and David Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock {\em arXiv preprint arXiv:1710.09412}, 2017.

\bibitem{setr}
Sixiao Zheng, Jiachen Lu, Hengshuang Zhao, Xiatian Zhu, Zekun Luo, Yabiao Wang,
  Yanwei Fu, Jianfeng Feng, Tao Xiang, Philip~HS Torr, et~al.
\newblock Rethinking semantic segmentation from a sequence-to-sequence
  perspective with transformers.
\newblock In {\em CVPR}, 2021.

\bibitem{zhong2020random}
Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li, and Yi~Yang.
\newblock Random erasing data augmentation.
\newblock In {\em AAAI}, volume~34, pages 13001--13008, 2020.

\bibitem{ade20k}
Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio
  Torralba.
\newblock Scene parsing through ade20k dataset.
\newblock In {\em CVPR}, 2017.

\bibitem{ddetr}
Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai.
\newblock Deformable detr: Deformable transformers for end-to-end object
  detection.
\newblock In {\em ICLR}, 2021.

\end{thebibliography}
