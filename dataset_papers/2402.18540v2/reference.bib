@article{askell2021general,
  title={A general language assistant as a laboratory for alignment},
  author={Askell, Amanda and Bai, Yuntao and Chen, Anna and Drain, Dawn and Ganguli, Deep and Henighan, Tom and Jones, Andy and Joseph, Nicholas and Mann, Ben and DasSarma, Nova and others},
  journal={arXiv preprint arXiv:2112.00861},
  year={2021}
}

@misc{chao2024jailbreakbench,
        title={JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models},
        author={Patrick Chao and Edoardo Debenedetti and Alexander Robey and Maksym Andriushchenko and Francesco Croce and Vikash Sehwag and Edgar Dobriban and Nicolas Flammarion and George J. Pappas and Florian Tramèr and Hamed Hassani and Eric Wong},
        year={2024},
        eprint={2404.01318},
        archivePrefix={arXiv},
        primaryClass={cs.CR}
}

@article{zong2024safety,
  title={Safety Fine-Tuning at (Almost) No Cost: A Baseline for Vision Large Language Models},
  author={Zong, Yongshuo and Bohdal, Ondrej and Yu, Tingyang and Yang, Yongxin and Hospedales, Timothy},
  journal={arXiv preprint arXiv:2402.02207},
  year={2024}
}
@misc{mitra2024orcamath,
      title={Orca-Math: Unlocking the potential of SLMs in Grade School Math}, 
      author={Arindam Mitra and Hamed Khanpour and Corby Rosset and Ahmed Awadallah},
      year={2024},
      eprint={2402.14830},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@article{goyal2017accurate,
  title={Accurate, large minibatch {SGD}: Training imagenet in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv preprint arXiv:1706.02677},
  year={2017}
}
@article{bai2022constitutional,
  title={Constitutional ai: Harmlessness from ai feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}
@article{zhang2023make,
  title={Make Them Spill the Beans! Coercive Knowledge Extraction from (Production) LLMs},
  author={Zhang, Zhuo and Shen, Guangyu and Tao, Guanhong and Cheng, Siyuan and Zhang, Xiangyu},
  journal={arXiv preprint arXiv:2312.04782},
  year={2023}
}
@inproceedings{deng2023multilingual,
  title={Multilingual Jailbreak Challenges in Large Language Models},
  author={Deng, Yue and Zhang, Wenxuan and Pan, Sinno Jialin and Bing, Lidong},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}
@inproceedings{li2019convergence,
  title={On the Convergence of FedAvg on Non-IID Data},
  author={Li, Xiang and Huang, Kaixuan and Yang, Wenhao and Wang, Shusen and Zhang, Zhihua},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{bianchi2023safety,
  title={Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions},
  author={Bianchi, Federico and Suzgun, Mirac and Attanasio, Giuseppe and Rottger, Paul and Jurafsky, Dan and Hashimoto, Tatsunori and Zou, James},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{woodworth2020minibatch,
  title={Minibatch vs {Local SGD} for heterogeneous distributed learning},
  author={Woodworth, Blake E and Patel, Kumar Kshitij and Srebro, Nati},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6281--6292},
  year={2020}
}

@article{wang2022unreasonable,
  title={On the Unreasonable Effectiveness of Federated Averaging with Heterogeneous Data},
  author={Wang, Jianyu and Das, Rudrajit and Joshi, Gauri and Kale, Satyen and Xu, Zheng and Zhang, Tong},
  journal={arXiv preprint arXiv:2206.04723},
  year={2022}
}




@article{zhang2020adaptive,
  title={Why are adaptive methods good for attention models?},
  author={Zhang, Jingzhao and Karimireddy, Sai Praneeth and Veit, Andreas and Kim, Seungyeon and Reddi, Sashank and Kumar, Sanjiv and Sra, Suvrit},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15383--15393},
  year={2020}
}

@inproceedings{karimireddy2020scaffold,
  title={Scaffold: Stochastic controlled averaging for federated learning},
  author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle={International Conference on Machine Learning},
  pages={5132--5143},
  year={2020},
  organization={PMLR}
}
@InProceedings{lin2020extrapolation,
  title = 	 {Extrapolation for Large-batch Training in Deep Learning},
  author =       {Lin, Tao and Kong, Lingjing and Stich, Sebastian and Jaggi, Martin},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {6094--6104},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR}
}
@article{izsak2021train,
  title={How to train BERT with an academic budget},
  author={Izsak, Peter and Berchansky, Moshe and Levy, Omer},
  journal={arXiv preprint arXiv:2104.07705},
  year={2021}
}
@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}
@inproceedings{ma2019deep,
  title={Deep rigid instance scene flow},
  author={Ma, Wei-Chiu and Wang, Shenlong and Hu, Rui and Xiong, Yuwen and Urtasun, Raquel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3614--3622},
  year={2019}
}
@inproceedings{frankle2020linear,
  title={Linear mode connectivity and the lottery ticket hypothesis},
  author={Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel and Carbin, Michael},
  booktitle={International Conference on Machine Learning},
  pages={3259--3269},
  year={2020},
  organization={PMLR}
}
@inproceedings{draxler2018essentially,
  title={Essentially no barriers in neural network energy landscape},
  author={Draxler, Felix and Veschgini, Kambis and Salmhofer, Manfred and Hamprecht, Fred},
  booktitle={International conference on machine learning},
  pages={1309--1318},
  year={2018},
  organization={PMLR}
}
@article{garipov2018loss,
  title={Loss surfaces, mode connectivity, and fast ensembling of dnns},
  author={Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry P and Wilson, Andrew G},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@inproceedings{izmailov2018averaging,
  title={Averaging weights leads to wider optima and better generalization},
  author={Izmailov, P and Wilson, AG and Podoprikhin, D and Vetrov, D and Garipov, T},
  booktitle={34th Conference on Uncertainty in Artificial Intelligence 2018, UAI 2018},
  pages={876--885},
  year={2018}
}
@article{gpt,
  author       = {Tom B. Brown and
                  Benjamin Mann and
                  Nick Ryder and
                  Melanie Subbiah and
                  Jared Kaplan and
                  Prafulla Dhariwal and
                  Arvind Neelakantan and
                  Pranav Shyam and
                  Girish Sastry and
                  Amanda Askell and
                  Sandhini Agarwal and
                  Ariel Herbert{-}Voss and
                  Gretchen Krueger and
                  Tom Henighan and
                  Rewon Child and
                  Aditya Ramesh and
                  Daniel M. Ziegler and
                  Jeffrey Wu and
                  Clemens Winter and
                  Christopher Hesse and
                  Mark Chen and
                  Eric Sigler and
                  Mateusz Litwin and
                  Scott Gray and
                  Benjamin Chess and
                  Jack Clark and
                  Christopher Berner and
                  Sam McCandlish and
                  Alec Radford and
                  Ilya Sutskever and
                  Dario Amodei},
  title        = {Language Models are Few-Shot Learners},
  journal      = {CoRR},
  volume       = {abs/2005.14165},
  year         = {2020},
  url          = {https://arxiv.org/abs/2005.14165},
  eprinttype    = {arXiv},
  eprint       = {2005.14165},
  timestamp    = {Thu, 25 May 2023 10:38:31 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{liu2022convnet,
  title={A convnet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11976--11986},
  year={2022}
}
@inproceedings{li2020budgeted,
  title={Budgeted Training: Rethinking Deep Neural Network Training Under Resource Constraints},
  author={Li, Mengtian and Yumer, Ersin and Ramanan, Deva},
  booktitle={International Conference on Learning Representations},
  year={2020}
}
@InProceedings{Leclerc_2023_CVPR,
    author    = {Leclerc, Guillaume and Ilyas, Andrew and Engstrom, Logan and Park, Sung Min and Salman, Hadi and M\k{a}dry, Aleksander},
    title     = {FFCV: Accelerating Training by Removing Data Bottlenecks},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {12011-12020}
}
@article{granziol2022learning,
  title={Learning rates as a function of batch size: A random matrix theory approach to neural network training},
  author={Granziol, Diego and Zohren, Stefan and Roberts, Stephen},
  journal={The Journal of Machine Learning Research},
  volume={23},
  number={1},
  pages={7795--7859},
  year={2022},
  publisher={JMLRORG}
}

@article{lian2017can,
  title={Can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent},
  author={Lian, Xiangru and Zhang, Ce and Zhang, Huan and Hsieh, Cho-Jui and Zhang, Wei and Liu, Ji},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@INPROCEEDINGS{chen2016,
  author={Chen, Kai and Huo, Qiang},
  booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Scalable training of deep learning machines by incremental block training with intra-block parallel optimization and blockwise model-update filtering}, 
  year={2016},
  volume={},
  number={},
  pages={5880-5884},
  doi={10.1109/ICASSP.2016.7472805}}

@INPROCEEDINGS{acoustic,
  author={Zhang, Xiaohui and Trmal, Jan and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Improving deep neural network acoustic models using generalized maxout networks}, 
  year={2014},
  volume={},
  number={},
  pages={215-219},
  doi={10.1109/ICASSP.2014.6853589}}
@article{povey2014parallel,
  title={Parallel training of DNNs with natural gradient and parameter averaging},
  author={Povey, Daniel and Zhang, Xiaohui and Khudanpur, Sanjeev},
  journal={arXiv preprint arXiv:1410.7455},
  year={2014}
}
@article{haddadpour2019local,
  title={Local {SGD} with periodic averaging: Tighter analysis and adaptive synchronization},
  author={Haddadpour, Farzin and Kamani, Mohammad Mahdi and Mahdavi, Mehrdad and Cadambe, Viveck},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{NEURIPS2019_Qsparse,
 author = {Basu, Debraj and Data, Deepesh and Karakus, Can and Diggavi, Suhas},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Qsparse-local-{SGD}: Distributed {SGD} with Quantization, Sparsification and Local Computations},
 volume = {32},
 year = {2019}
}
@article{nadiradze2021asynchronous,
  title={Asynchronous decentralized SGD with quantized and local updates},
  author={Nadiradze, Giorgi and Sabour, Amirmojtaba and Davies, Peter and Li, Shigang and Alistarh, Dan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={6829--6842},
  year={2021}
}

@InProceedings{lian18async,
  title = 	 {Asynchronous Decentralized Parallel Stochastic Gradient Descent},
  author =       {Lian, Xiangru and Zhang, Wei and Zhang, Ce and Liu, Ji},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {3043--3052},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR}
}
@inproceedings{zheng2017asynchronous,
  title={Asynchronous stochastic gradient descent with delay compensation},
  author={Zheng, Shuxin and Meng, Qi and Wang, Taifeng and Chen, Wei and Yu, Nenghai and Ma, Zhi-Ming and Liu, Tie-Yan},
  booktitle={International Conference on Machine Learning},
  pages={4120--4129},
  year={2017},
  organization={PMLR}
}

@article{
wortsman2023lofi,
title={lo-fi: distributed fine-tuning without communication},
author={Mitchell Wortsman and Suchin Gururangan and Shen Li and Ali Farhadi and Ludwig Schmidt and Michael Rabbat and Ari S. Morcos},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023}
}
@inproceedings{wortsman2022modelsoup,
  title={Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and others},
  booktitle={International Conference on Machine Learning},
  pages={23965--23998},
  year={2022},
  organization={PMLR}
}
@inproceedings{1bitlamb,
  title={1-bit LAMB: communication efficient large-scale large-batch training with LAMB’s convergence speed},
  author={Li, Conglong and Awan, Ammar Ahmad and Tang, Hanlin and Rajbhandari, Samyam and He, Yuxiong},
  booktitle={2022 IEEE 29th International Conference on High Performance Computing, Data, and Analytics (HiPC)},
  pages={272--281},
  year={2022},
  organization={IEEE}
}
@inproceedings{wang2023cocktailsgd,
  title={CocktailSGD: Fine-tuning Foundation Models over 500Mbps Networks},
  author={Wang, Jue and Lu, Yucheng and Yuan, Binhang and Chen, Beidi and Liang, Percy and De Sa, Christopher and Re, Christopher and Zhang, Ce},
  booktitle={International Conference on Machine Learning},
  pages={36058--36076},
  year={2023},
  organization={PMLR}
}
@inproceedings{reddi2020adaptive,
  title={Adaptive Federated Optimization},
  author={Reddi, Sashank J and Charles, Zachary and Zaheer, Manzil and Garrett, Zachary and Rush, Keith and Kone{\v{c}}n{\`y}, Jakub and Kumar, Sanjiv and McMahan, Hugh Brendan},
  booktitle={International Conference on Learning Representations},
  year={2020}
}
@article{li2020fedprox,
  title={Federated optimization in heterogeneous networks},
  author={Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  journal={Proceedings of Machine learning and systems},
  volume={2},
  pages={429--450},
  year={2020}
}
@article{konevcny2016federated,
  title={Federated learning: Strategies for improving communication efficiency},
  author={Kone{\v{c}}n{\`y}, Jakub and McMahan, H Brendan and Yu, Felix X and Richt{\'a}rik, Peter and Suresh, Ananda Theertha and Bacon, Dave},
  journal={arXiv preprint arXiv:1610.05492},
  year={2016}
}
@inproceedings{shen2021stl,
  title={STL-SGD: Speeding Up Local SGD with Stagewise Communication Period},
  author={Shen, Shuheng and Cheng, Yifei and Liu, Jingchang and Xu, Linli},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={9576--9584},
  year={2021}
}
@inproceedings{kamp2014communication,
  title={Communication-efficient distributed online prediction by dynamic model synchronization},
  author={Kamp, Michael and Boley, Mario and Keren, Daniel and Schuster, Assaf and Sharfman, Izchak},
  booktitle={Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2014, Nancy, France, September 15-19, 2014. Proceedings, Part I 14},
  pages={623--639},
  year={2014},
  organization={Springer}
}
@article{beyer2022betterplain,
  title={Better plain ViT baselines for ImageNet-1k},
  author={Beyer, Lucas and Zhai, Xiaohua and Kolesnikov, Alexander},
  journal={arXiv preprint arXiv:2205.01580},
  year={2022}
}
@article{imagenet,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}
@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and others},
  year={2009},
  publisher={Citeseer}
}
@article{kairouz2021advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={14},
  number={1--2},
  pages={1--210},
  year={2021},
  publisher={Now Publishers, Inc.}
}
@article{su2015experiments,
  title={Experiments on parallel training of deep neural network using model averaging},
  author={Su, Hang and Chen, Haoyu},
  journal={arXiv preprint arXiv:1507.01239},
  year={2015}
}
@inproceedings{DBLP:conf/nips/MannMMSW09,
  author    = {Gideon Mann and
               Ryan T. McDonald and
               Mehryar Mohri and
               Nathan Silberman and
               Dan Walker},
  title     = {Efficient Large-Scale Distributed Training of Conditional Maximum
               Entropy Models},
  booktitle = {Advances in Neural Information Processing Systems 22},
  pages     = {1231--1239},
  year      = {2009}
}
@inproceedings{vgg,
	author = "Simonyan, K. and Zisserman, A.",
	title = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
	booktitle = "International Conference on Learning Representations",
	Month = "May",
	year = "2015"
}

@article{kat,
author = {G. S. Katzenberger},
title = {Solutions of a Stochastic Differential Equation Forced Onto a Manifold by a Large Drift},
volume = {19},
journal = {The Annals of Probability},
number = {4},
publisher = {Institute of Mathematical Statistics},
pages = {1587 -- 1628},
keywords = {diffusion, diffusion approximation, flow, Manifold, Semimartingale, Stochastic differential equation},
year = {1991}
}

@misc{leclerc2022ffcv,
    author = {Guillaume Leclerc and Andrew Ilyas and Logan Engstrom and Sung Min Park and Hadi Salman and Aleksander Madry},
    title = {ffcv},
    year = {2022},
    howpublished = {\url{https://github.com/libffcv/ffcv/}}
}
@inproceedings{DBLP:conf/nips/RechtRWN11,
  author    = {Benjamin Recht and
               Christopher R{\'{e}} and
               Stephen J. Wright and
               Feng Niu},

  title     = {Hogwild: {A} Lock-Free Approach to Parallelizing Stochastic Gradient
               Descent},
  booktitle = {Advances in Neural Information Processing Systems 24},
  pages     = {693--701},
  year      = {2011},
  timestamp = {Mon, 16 May 2022 15:41:51 +0200}
}
a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout
@inproceedings{NIPS2010_abea47ba,
 author = {Zinkevich, Martin and Weimer, Markus and Li, Lihong and Smola, Alex},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Lafferty and C. Williams and J. Shawe-Taylor and R. Zemel and A. Culotta},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Parallelized Stochastic Gradient Descent},
 volume = {23},
 year = {2010}
}

@article{xu2023llm,
  title={An LLM can Fool Itself: A Prompt-Based Adversarial Attack},
  author={Xu, Xilie and Kong, Keyi and Liu, Ning and Cui, Lizhen and Wang, Di and Zhang, Jingfeng and Kankanhalli, Mohan},
  journal={arXiv preprint arXiv:2310.13345},
  year={2023}
}
@article{DBLP:journals/corr/ChenMBJ16,
  author    = {Jianmin Chen and
               Rajat Monga and
               Samy Bengio and
               Rafal J{\'{o}}zefowicz},
  title     = {Revisiting Distributed Synchronous {SGD}},
  journal   = {CoRR},
  volume    = {abs/1604.00981},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.00981},
  eprinttype = {arXiv},
  eprint    = {1604.00981},
  timestamp = {Mon, 13 Aug 2018 16:48:43 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ChenMBJ16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/interspeech/Strom15,
  author    = {Nikko Strom},
  title     = {Scalable distributed {DNN} training using commodity {GPU} cloud computing},
  booktitle = {{INTERSPEECH} 2015, 16th Annual Conference of the International Speech
               Communication Association, Dresden, Germany, September 6-10, 2015},
  pages     = {1488--1492},
  publisher = {{ISCA}},
  year      = {2015},
  timestamp = {Tue, 16 Nov 2021 11:43:44 +0100},
  biburl    = {https://dblp.org/rec/conf/interspeech/Strom15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/interspeech/SeideFDLY14,
  author    = {Frank Seide and
               Hao Fu and
               Jasha Droppo and
               Gang Li and
               Dong Yu},
  editor    = {Haizhou Li and
               Helen M. Meng and
               Bin Ma and
               Engsiong Chng and
               Lei Xie},
  title     = {1-bit stochastic gradient descent and its application to data-parallel
               distributed training of speech DNNs},
  booktitle = {{INTERSPEECH} 2014, 15th Annual Conference of the International Speech
               Communication Association, Singapore, September 14-18, 2014},
  pages     = {1058--1062},
  publisher = {{ISCA}},
  year      = {2014},
  url       = {http://www.isca-speech.org/archive/interspeech\_2014/i14\_1058.html},
  timestamp = {Tue, 16 Nov 2021 11:44:16 +0100},
  biburl    = {https://dblp.org/rec/conf/interspeech/SeideFDLY14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
keskar2017on,
title={On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima},
author={Nitish Shirish Keskar and Dheevatsa Mudigere and Jorge Nocedal and Mikhail Smelyanskiy and Ping Tak Peter Tang},
booktitle={International Conference on Learning Representations},
year={2017}
}

@inproceedings{DBLP:conf/iclr/BrandfonbrenerB20,
  author    = {David Brandfonbrener and
               Joan Bruna},
  title     = {Geometric Insights into the Convergence of Nonlinear {TD} Learning},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
  timestamp = {Thu, 07 May 2020 17:11:47 +0200},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@book{DBLP:books/lib/SuttonB98,
  author    = {Richard S. Sutton and
               Andrew G. Barto},
  title     = {Reinforcement learning - an introduction},
  series    = {Adaptive computation and machine learning},
  publisher = {{MIT} Press},
  year      = {1998},
  isbn      = {978-0-262-19398-6},
  timestamp = {Fri, 17 Jul 2020 16:12:40 +0200},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{gupta2015deep,
  title={Deep learning with limited numerical precision},
  author={Gupta, Suyog and Agrawal, Ankur and Gopalakrishnan, Kailash and Narayanan, Pritish},
  booktitle={International conference on machine learning},
  pages={1737--1746},
  year={2015},
  organization={PMLR}
}
@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}
@article{li2020reconciling,
  title={Reconciling modern deep learning with traditional optimization analyses: The intrinsic learning rate},
  author={Li, Zhiyuan and Lyu, Kaifeng and Arora, Sanjeev},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14544--14555},
  year={2020}
}
@inproceedings{arora2018theoretical,
  title={Theoretical Analysis of Auto Rate-Tuning by Batch Normalization},
  author={Arora, Sanjeev and Li, Zhiyuan and Lyu, Kaifeng},
  booktitle={International Conference on Learning Representations},
  year={2018}
}
@article{chen2016revisiting,
  title={Revisiting distributed synchronous {SGD}},
  author={Chen, Jianmin and Pan, Xinghao and Monga, Rajat and Bengio, Samy and Jozefowicz, Rafal},
  journal={arXiv preprint arXiv:1604.00981},
  year={2016}
}


@inproceedings{you2018imagenet,
  title={Imagenet training in minutes},
  author={You, Yang and Zhang, Zhao and Hsieh, Cho-Jui and Demmel, James and Keutzer, Kurt},
  booktitle={Proceedings of the 47th International Conference on Parallel Processing},
  pages={1--10},
  year={2018}
}


@inproceedings{
lin2020dont,
title={Don't Use Large Mini-batches, Use {Local SGD}},
author={Tao Lin and Sebastian U. Stich and Kumar Kshitij Patel and Martin Jaggi},
booktitle={International Conference on Learning Representations},
year={2020}
}





@inproceedings{kour2014real,
  title={Real-time segmentation of on-line handwritten arabic script},
  author={Kour, George and Saabne, Raid},
  booktitle={Frontiers in Handwriting Recognition (ICFHR), 2014 14th International Conference on},
  pages={417--422},
  year={2014},
  organization={IEEE}
}

@inproceedings{kour2014fast,
  title={Fast classification of handwritten on-line Arabic characters},
  author={Kour, George and Saabne, Raid},
  booktitle={Soft Computing and Pattern Recognition (SoCPaR), 2014 6th International Conference of},
  pages={312--318},
  year={2014},
  organization={IEEE}
}

@article{hadash2018estimate,
  title={Estimate and Replace: A Novel Approach to Integrating Deep Neural Networks with Existing Applications},
  author={Hadash, Guy and Kermany, Einat and Carmeli, Boaz and Lavi, Ofer and Kour, George and Jacovi, Alon},
  journal={arXiv preprint arXiv:1804.09028},
  year={2018}
}

@inproceedings{li2019exponential,
  title={An Exponential Learning Rate Schedule for Deep Learning},
  author={Li, Zhiyuan and Arora, Sanjeev},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{novelgpt,
  title={Exploiting novel {GPT}-4 {APIs}},
  author={Pelrine, Kellin and Taufeeque, Mohammad and Zaj{\k{a}}c, Micha{\l} and McLean, Euan and Gleave, Adam},
  journal={arXiv preprint arXiv:2312.14302},
  year={2023}
}



@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={PMLR}
}

@inproceedings{wu2018group,
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}

@article{ulyanov2016instance,
  title={Instance normalization: The missing ingredient for fast stylization},
  author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  journal={arXiv preprint arXiv:1607.08022},
  year={2016}
}

@article{zhang2016parallel,
  title={{Parallel SGD}: When does averaging help?},
  author={Zhang, Jian and De Sa, Christopher and Mitliagkas, Ioannis and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:1606.07365},
  year={2016}
}

@inproceedings{cohen2020gradient,
  title={Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability},
  author={Cohen, Jeremy and Kaur, Simran and Li, Yuanzhi and Kolter, J Zico and Talwalkar, Ameet},
  booktitle={International Conference on Learning Representations},
  year={2020}
}
@inproceedings{stich2018local,
  title={{Local SGD} Converges Fast and Communicates Little},
  author={Stich, Sebastian U},
  booktitle={International Conference on Learning Representations},
  year={2018}
}
@inproceedings{khaled2020tighter,
  title={Tighter theory for local {SGD} on identical and heterogeneous data},
  author={Khaled, Ahmed and Mishchenko, Konstantin and Richt{\'a}rik, Peter},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4519--4529},
  year={2020},
  organization={PMLR}
}
@inproceedings{woodworth2020local,
  title={Is local SGD better than minibatch SGD?},
  author={Woodworth, Blake and Patel, Kumar Kshitij and Stich, Sebastian and Dai, Zhen and Bullins, Brian and Mcmahan, Brendan and Shamir, Ohad and Srebro, Nathan},
  booktitle={International Conference on Machine Learning},
  pages={10334--10343},
  year={2020},
  organization={PMLR}
}

@InProceedings{ahn2022understanding,
  title = 	 {Understanding the unstable convergence of gradient descent},
  author =       {Ahn, Kwangjun and Zhang, Jingzhao and Sra, Suvrit},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {247--257},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR}
}



@inproceedings{li2021happens,
  title={What Happens after {SGD} Reaches Zero Loss?--A Mathematical Framework},
  author={Li, Zhiyuan and Wang, Tianhao and Arora, Sanjeev},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{li2019stochastic,
  author  = {Qianxiao Li and Cheng Tai and Weinan E},
  title   = {Stochastic Modified Equations and Dynamics of Stochastic Gradient Algorithms I: Mathematical Foundations},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {40},
  pages   = {1--47},
}


@article{hochreiter1997flat,
  title={Flat minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={1},
  pages={1--42},
  year={1997},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{glasgow2022sharp,
  title={Sharp Bounds for Federated Averaging ({Local SGD}) and Continuous Perspective},
  author={Glasgow, Margalit R and Yuan, Honglin and Ma, Tengyu},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={9050--9090},
  year={2022},
  organization={PMLR}
}
@misc{lyu2022understanding,
    title={Understanding the Generalization Benefit of Normalization Layers: Sharpness Reduction},
    author={Kaifeng Lyu and Zhiyuan Li and Sanjeev Arora},
    year={2022},
    eprint={2206.07085},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@article{madden2020high,
  title={High probability convergence bounds for stochastic gradient descent assuming the polyak-lojasiewicz inequality},
  author={Madden, Liam and Dall'Anese, Emiliano and Becker, Stephen},
  journal={arXiv preprint arXiv:2006.05610},
  year={2020}
}

@article{du2007invariant,
  title={Invariant Manifold Reduction For Stochastic Dynamical Systems},
  author={Du, Aijun and Duan, JinQiao},
  journal={Dynamic Systems and Applications},
  volume={16},
  pages={681--696},
  year={2007}
}
@article{filipovic2000invariant,
  title={Invariant manifolds for weak solutions to stochastic equations},
  author={Filipovi{\'c}, Damir},
  journal={Probability theory and related fields},
  volume={118},
  number={3},
  pages={323--341},
  year={2000},
  publisher={Springer}
}

@inproceedings{
malladi2022sdes,
title={On the {SDE}s and Scaling Rules for Adaptive Gradient Algorithms},
author={Sadhika Malladi and Kaifeng Lyu and Abhishek Panigrahi and Sanjeev Arora},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022}
}





@article{falconer1983differentiation,
  title={Differentiation of the limit mapping in a dynamical system},
  author={Falconer, KJ},
  journal={Journal of the London Mathematical Society},
  volume={2},
  number={2},
  pages={356--372},
  year={1983},
  publisher={Wiley Online Library}
}

@inproceedings{yu2019parallel,
  title={Parallel restarted {SGD} with faster convergence and less communication: Demystifying why model averaging works for deep learning},
  author={Yu, Hao and Yang, Sen and Zhu, Shenghuo},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={5693--5700},
  year={2019}
}
@article{ortiz2021trade,
  title={Trade-offs of {Local SGD} at Scale: An Empirical Study},
  author={Ortiz, Jose Javier Gonzalez and Frankle, Jonathan and Rabbat, Mike and Morcos, Ari and Ballas, Nicolas},
  journal={arXiv preprint arXiv:2110.08133},
  year={2021}
}
@inproceedings{chen2021vision,
  title={When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations},
  author={Chen, Xiangning and Hsieh, Cho-Jui and Gong, Boqing},
  booktitle={International Conference on Learning Representations},
  year={2021}
}
@inproceedings{
dosovitskiy2021an,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021}
}
@article{wang2019adaptive,
  title={Adaptive communication strategies to achieve the best error-runtime trade-off in local-update {SGD}},
  author={Wang, Jianyu and Joshi, Gauri},
  journal={Proceedings of Machine Learning and Systems},
  volume={1},
  pages={212--229},
  year={2019}
}

@inproceedings{gupta2020swap,
title={Stochastic Weight Averaging in Parallel: Large-Batch Training That Generalizes Well},
author={Vipul Gupta and Santiago Akle Serrano and Dennis DeCoste},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{wang2019slowmo,
  title={SlowMo: Improving Communication-Efficient Distributed {SGD} with Slow Momentum},
  author={Wang, Jianyu and Tantia, Vinayak and Ballas, Nicolas and Rabbat, Michael},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{hoffer2017train,
  title={Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
  author={Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{ramachandran2017searching,
  title={Searching for activation functions},
  author={Ramachandran, Prajit and Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.05941},
  year={2017}
}

@article{li2021validity,
  title={On the validity of modeling {SGD} with stochastic differential equations (sdes)},
  author={Li, Zhiyuan and Malladi, Sadhika and Arora, Sanjeev},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={12712--12725},
  year={2021}
}
@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}
@article{hu2017diffusion,
  title={On the diffusion approximation of nonconvex stochastic gradient descent},
  author={Hu, Wenqing and Li, Chris Junchi and Li, Lei and Liu, Jian-Guo},
  journal={arXiv preprint arXiv:1705.07562},
  year={2017}
}

@inproceedings{DBLP:journals/corr/SimonyanZ14a,
  author    = {Karen Simonyan and
               Andrew Zisserman},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  timestamp = {Wed, 17 Jul 2019 10:40:54 +0200},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{jia2018highly,
  title={Highly scalable deep learning training system with mixed-precision: Training imagenet in four minutes},
  author={Jia, Xianyan and Song, Shutao and He, Wei and Wang, Yangzihao and Rong, Haidong and Zhou, Feihu and Xie, Liqiang and Guo, Zhenyu and Yang, Yuanzhou and Yu, Liwei and others},
  journal={Advances in Neural Information Processing Systems},
  year={2018}
}


@InProceedings{smith2020generalization,
  title = 	 {On the Generalization Benefit of Noise in Stochastic Gradient Descent},
  author =       {Smith, Samuel and Elsen, Erich and De, Soham},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {9058--9067},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
}

@article{wang2021cooperative,
  author  = {Jianyu Wang and Gauri Joshi},
  title   = {Cooperative {SGD}: A Unified Framework for the Design and Analysis of Local-Update {SGD} Algorithms},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {213},
  pages   = {1--50}
}
@article{hendrycks2016gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}
@article{hinton2012neural,
  title={Neural networks for machine learning lecture 6a overview of mini-batch gradient descent},
  author={Hinton, Geoffrey and Srivastava, Nitish and Swersky, Kevin},
  journal={Cited on},
  volume={14},
  number={8},
  pages={2},
  year={2012}
}

@inproceedings{
gu2023why,
title={Why (and When) does Local {SGD} Generalize Better than {SGD}?},
author={Xinran Gu and Kaifeng Lyu and Longbo Huang and Sanjeev Arora},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=svCcui6Drl}
}
@INPROCEEDINGS{localadam,
  author={Cong, Guojing and Buratti, Luca},
  booktitle={2018 IEEE/ACM Machine Learning in HPC Environments (MLHPC)}, 
  title={On Adam Trained Models and a Parallel Method to Improve the Generalization Performance}, 
  year={2018},
  volume={},
  number={}}

@inproceedings{zhouandcong,
  title     = {On the Convergence Properties of a K-step Averaging Stochastic Gradient Descent Algorithm for Nonconvex Optimization},
  author    = {Fan Zhou and Guojing Cong},
  booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
               Artificial Intelligence, {IJCAI-18}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  pages     = {3219--3227},
  year      = {2018},
  month     = {7},
  doi       = {10.24963/ijcai.2018/447},
  url       = {https://doi.org/10.24963/ijcai.2018/447},
}

@article{fehrman2020convergence,
  title={Convergence rates for the stochastic gradient descent method for non-convex objective functions},
  author={Fehrman, Benjamin and Gess, Benjamin and Jentzen, Arnulf},
  journal={Journal of Machine Learning Research},
  volume={21},
  pages={136},
  year={2020},
  publisher={MIT Press}
}
@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@Inbook{bengio2012practical,
author="Bengio, Yoshua",
editor="Montavon, Gr{\'e}goire
and Orr, Genevi{\`e}ve B.
and M{\"u}ller, Klaus-Robert",
title="Practical Recommendations for Gradient-Based Training of Deep Architectures",
bookTitle="Neural Networks: Tricks of the Trade: Second Edition",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="437--478",
isbn="978-3-642-35289-8",
doi="10.1007/978-3-642-35289-8_26",
}





@Inbook{lecun2012efficient,
author="LeCun, Yann A.
and Bottou, L{\'e}on
and Orr, Genevieve B.
and M{\"u}ller, Klaus-Robert",
editor="Montavon, Gr{\'e}goire
and Orr, Genevi{\`e}ve B.
and M{\"u}ller, Klaus-Robert",
title="Efficient {BackProp}",
bookTitle="Neural Networks: Tricks of the Trade: Second Edition",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="9--48",
abstract="The convergence of back-propagation learning is analyzed so as to explain common phenomenon observed by practitioners. Many undesirable behaviors of backprop can be avoided with tricks that are rarely exposed in serious technical publications. This paper gives some of those tricks, and offers explanations of why they work.",
isbn="978-3-642-35289-8",
doi="10.1007/978-3-642-35289-8_3",
}

@inproceedings{
smith2021on,
title={On the Origin of Implicit Regularization in Stochastic Gradient Descent},
author={Samuel L Smith and Benoit Dherin and David Barrett and Soham De},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{li2019towards,
 author = {Li, Yuanzhi and Wei, Colin and Ma, Tengyu},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Towards Explaining the Regularization Effect of Initial Large Learning Rate in Training Neural Networks},
 volume = {32},
 year = {2019}
}


@InProceedings{blanc2020implicit,
  title = 	 {Implicit regularization for deep neural networks driven by an Ornstein-Uhlenbeck like process},
  author =       {Blanc, Guy and Gupta, Neha and Valiant, Gregory and Valiant, Paul},
  booktitle = 	 {Proceedings of Thirty Third Conference on Learning Theory},
  pages = 	 {483--513},
  year = 	 {2020},
  editor = 	 {Abernethy, Jacob and Agarwal, Shivani},
  volume = 	 {125},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--12 Jul},
  publisher =    {PMLR},
}

@article{shallue2019measuring,
  author  = {Christopher J. Shallue and Jaehoon Lee and Joseph Antognini and Jascha Sohl-Dickstein and Roy Frostig and George E. Dahl},
  title   = {Measuring the Effects of Data Parallelism on Neural Network Training},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {112},
  pages   = {1--49},
}

@inproceedings{wu2018how,
 author = {Wu, Lei and Ma, Chao and E, Weinan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 publisher = {Curran Associates, Inc.},
 title = {How SGD Selects the Global Minima in Over-parameterized Learning: A Dynamical Stability Perspective},
 volume = {31},
 year = {2018}
}

@inproceedings{ma2021on,
 author = {Ma, Chao and Ying, Lexing},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {16805--16817},
 publisher = {Curran Associates, Inc.},
 title = {On Linear Stability of {SGD} and Input-Smoothness of Neural Networks},
 volume = {34},
 year = {2021}
}

@InProceedings{slamb,
  title = 	 {{SLAMB}: Accelerated Large Batch Training with Sparse Communication},
  author =       {Xu, Hang and Zhang, Wenxuan and Fei, Jiawei and Wu, Yuzhe and Xie, Tingwen and Huang, Jun and Xie, Yuchen and Elhoseiny, Mohamed and Kalnis, Panos},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  year = 	 {2023}
  }
}


@InProceedings{1bitadam,
  title = 	 {1-bit Adam: Communication Efficient Large-Scale Training with Adam’s Convergence Speed},
  author =       {Tang, Hanlin and Gan, Shaoduo and Awan, Ammar Ahmad and Rajbhandari, Samyam and Li, Conglong and Lian, Xiangru and Liu, Ji and Zhang, Ce and He, Yuxiong},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  year = 	 {2021},
  
}


@inproceedings{neyshabur2017exploring,
 author = {Neyshabur, Behnam and Bhojanapalli, Srinadh and Mcallester, David and Srebro, Nati},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Exploring Generalization in Deep Learning},
 volume = {30},
 year = {2017}
}


@inproceedings{
xie2021a,
title={A Diffusion Theory For Deep Learning Dynamics: Stochastic Gradient Descent Exponentially Favors Flat Minima},
author={Zeke Xie and Issei Sato and Masashi Sugiyama},
booktitle={International Conference on Learning Representations},
year={2021},
}

@article{ibayashi2022expescape,
  title={Exponential escape efficiency of {SGD} from sharp minima in non-stationary regime},
  author={Hikaru Ibayashi and Masaaki Imaizumi},
  journal={arXiv preprint arXiv:2111.04004},
  year={2021}
}

@InProceedings{kleinberg2018alternative,
  title = 	 {An Alternative View: When Does {SGD} Escape Local Minima?},
  author =       {Kleinberg, Bobby and Li, Yuanzhi and Yuan, Yang},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {2698--2707},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
}


@InProceedings{dinh2017sharp,
  title = 	 {Sharp Minima Can Generalize For Deep Nets},
  author =       {Laurent Dinh and Razvan Pascanu and Samy Bengio and Yoshua Bengio},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1019--1028},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
}

@inproceedings{
jiang2020fantastic,
title={Fantastic Generalization Measures and Where to Find Them},
author={Yiding Jiang and Behnam Neyshabur and Hossein Mobahi and Dilip Krishnan and Samy Bengio},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{
foret2021sharpnessaware,
title={Sharpness-aware Minimization for Efficiently Improving Generalization},
author={Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
booktitle={International Conference on Learning Representations},
year={2021},
}

@article{krizhevsky2014one,
  title={One weird trick for parallelizing convolutional neural networks},
  author={Krizhevsky, Alex},
  journal={arXiv preprint arXiv:1404.5997},
  year={2014}
}

@inproceedings{
you2020large,
title={Large Batch Optimization for Deep Learning: Training {BERT} in 76 minutes},
author={Yang You and Jing Li and Sashank Reddi and Jonathan Hseu and Sanjiv Kumar and Srinadh Bhojanapalli and Xiaodan Song and James Demmel and Kurt Keutzer and Cho-Jui Hsieh},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{
li2022fast,
title={Fast Mixing of Stochastic Gradient Descent with Normalization and Weight Decay},
author={Zhiyuan Li and Tianhao Wang and Dingli Yu},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
}

@book{oksendal2013stochastic,
  title={Stochastic differential equations: an introduction with applications},
  author={Øksendal, Bernt},
  year={2013},
  publisher={Springer Science \& Business Media}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Kaifeng's bibtex %%%%%%%%%%%%%%%%%%%%%%%%

@article{bolte2010characterizations,
  title={Characterizations of {\L}ojasiewicz inequalities: subgradient flows, talweg, convexity},
  author={Bolte, J{\'e}r{\^o}me and Daniilidis, Aris and Ley, Olivier and Mazet, Laurent},
  journal={Transactions of the American Mathematical Society},
  volume={362},
  number={6},
  pages={3319--3363},
  year={2010}
}

@inproceedings{ioffe2015batch,
  title = 	 {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author = 	 {Ioffe, Sergey and Szegedy, Christian},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {448--456},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
}


@inproceedings{li2020reconciling,
 author = {Li, Zhiyuan and Lyu, Kaifeng and Arora, Sanjeev},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {14544--14555},
 publisher = {Curran Associates, Inc.},
 title = {Reconciling Modern Deep Learning with Traditional Optimization Analyses: The Intrinsic Learning Rate},
 volume = {33},
 year = {2020}
}

@incollection{santurkar2018does,
	title = {How Does Batch Normalization Help Optimization?},
	author = {Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {2483--2493},
	year = {2018},
	publisher = {Curran Associates, Inc.},
}

@InProceedings{kohler2019exp,
  title = 	 {Exponential convergence rates for Batch Normalization: The power of length-direction decoupling in non-convex optimization},
  author =       {Kohler, Jonas and Daneshmand, Hadi and Lucchi, Aurelien and Hofmann, Thomas and Zhou, Ming and Neymeyr, Klaus},
  booktitle = 	 {Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics},
  pages = 	 {806--815},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
  volume = 	 {89},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {16--18 Apr},
  publisher =    {PMLR},
}


@article{wu2018wngrad,
	title={WNGrad: Learn the Learning Rate in Gradient Descent},
	author={Wu, Xiaoxia and Ward, Rachel and Bottou, L{\'e}on},
	journal={arXiv preprint arXiv:1803.02865},
	year={2018}
}

@article{ward2018adagrad,
	title={AdaGrad stepsizes: Sharp convergence over nonconvex landscapes, from any initialization},
	author={Ward, Rachel and Wu, Xiaoxia and Bottou, Leon},
	journal={arXiv preprint arXiv:1806.01811},
	year={2018}
}

@article{li2018convergence,
	title={On the Convergence of Stochastic Gradient Descent with Adaptive Stepsizes},
	author={Li, Xiaoyu and Orabona, Francesco},
	journal={arXiv preprint arXiv:1805.08114},
	year={2018}
}

@article{zou2018convergence,
	title={On the Convergence of AdaGrad with Momentum for Training Deep Neural Networks},
	author={Zou, Fangyu and Shen, Li},
	journal={arXiv preprint arXiv:1808.03408},
	year={2018}
}

@article{zhou2018on,
	title={On the Convergence of Adaptive Gradient Methods for Nonconvex Optimization},
	author={Zhou, Dongruo and Tang, Yiqi and Yang, Ziyan and Cao, Yuan and Gu, Quanquan},
	journal={arXiv preprint arXiv:1808.05671},
	year={2018}
}

@inproceedings{salimans2016weight,
 author = {Salimans, Tim and Kingma, Durk P},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks},
 volume = {29},
 year = {2016}
}

@inproceedings{arora2018optimization,
  title={On the optimization of deep networks: Implicit acceleration by overparameterization},
  author={Arora, Sanjeev and Cohen, N and Hazan, Elad},
  booktitle={35th International Conference on Machine Learning},
  year={2018}
}
@article{ba2016layer,
	title={Layer normalization},
	author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
	journal={arXiv preprint arXiv:1607.06450},
	year={2016}
}

@InProceedings{wu2018group,
author = {Wu, Yuxin and He, Kaiming},
title = {Group Normalization},
booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
}

@inproceedings{glorot2011deep,
	title={Deep sparse rectifier neural networks},
	author={Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
	booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
	pages={315--323},
	year={2011}
}

@inproceedings{dugas2001incorporating,
	title={Incorporating second-order functional knowledge for better option pricing},
	author={Dugas, Charles and Bengio, Yoshua and B{\'e}lisle, Fran{\c{c}}ois and Nadeau, Claude and Garcia, Ren{\'e}},
	booktitle={Advances in neural information processing systems},
	pages={472--478},
	year={2001}
}

@inproceedings{nair2010rectified,
	title={Rectified linear units improve restricted boltzmann machines},
	author={Nair, Vinod and Hinton, Geoffrey E},
	booktitle={Proceedings of the 27th international conference on machine learning (ICML-10)},
	pages={807--814},
	year={2010}
}

@inproceedings{cho2017riemannian,
	title={Riemannian approach to batch normalization},
	author={Cho, Minhyung and Lee, Jaehyung},
	booktitle={Advances in Neural Information Processing Systems},
	pages={5225--5235},
	year={2017}
}

@inproceedings{he2016deepres,
	title={Deep residual learning for image recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={770--778},
	year={2016}
}


@inproceedings{szegedy2017inception,
	title={Inception-v4, inception-resnet and the impact of residual connections on learning.},
	author={Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander A},
	booktitle={AAAI},
	volume={4},
	pages={12},
	year={2017}
}

@inproceedings{ioffe2017renorm,
	title={Batch renormalization: Towards reducing minibatch dependence in batch-normalized models},
	author={Ioffe, Sergey},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1945--1953},
	year={2017}
}

@article{ulyanov2016IN,
	title={Instance Normalization: The Missing Ingredient for Fast Stylization},
	author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
	journal={arXiv preprint arXiv:1607.08022},
	year={2016}
}

@article{jain2017non,
	title={Non-convex optimization for machine learning},
	author={Jain, Prateek and Kar, Purushottam and others},
	journal={Foundations and Trends{\textregistered} in Machine Learning},
	volume={10},
	number={3-4},
	pages={142--336},
	year={2017},
	publisher={Now Publishers, Inc.}
}

@article{duchi2011adagrad,
	title={Adaptive subgradient methods for online learning and stochastic optimization},
	author={Duchi, John and Hazan, Elad and Singer, Yoram},
	journal={Journal of Machine Learning Research},
	volume={12},
	number={Jul},
	pages={2121--2159},
	year={2011}
}

@article{kingma2014adam,
	title={Adam: A method for stochastic optimization},
	author={Kingma, Diederik P and Ba, Jimmy},
	journal={arXiv preprint arXiv:1412.6980},
	year={2014}
}

@article{clevert2015elu,
	title={Fast and accurate deep network learning by exponential linear units (elus)},
	author={Clevert, Djork-Arn{\'e} and Unterthiner, Thomas and Hochreiter, Sepp},
	journal={arXiv preprint arXiv:1511.07289},
	year={2015}
}

@article{carmonlower,
	title={Lower Bounds for Finding Stationary Points of Non-Convex, Smooth High-Dimensional Functions},
	author={Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, Aaron},
	year = {2018}
}

@inproceedings{dugas2001softplus,
	title={Incorporating second-order functional knowledge for better option pricing},
	author={Dugas, Charles and Bengio, Yoshua and B{\'e}lisle, Fran{\c{c}}ois and Nadeau, Claude and Garcia, Ren{\'e}},
	booktitle={Advances in neural information processing systems},
	pages={472--478},
	year={2001}
}

@inproceedings{ge2015escaping,
	title={Escaping from saddle points—online stochastic gradient for tensor decomposition},
	author={Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
	booktitle={Conference on Learning Theory},
	pages={797--842},
	year={2015}
}

@inproceedings{maas2013leakyrelu,
	title={Rectifier nonlinearities improve neural network acoustic models},
	author={Maas, Andrew L. and Hannun, Awni Y. and Ng, Andrew Y.},
	booktitle={ICML Workshop on Deep Learning for Audio, Speech and Language Processing},
	year={2013},
}

@article{bjorck2018understanding,
	title={Understanding Batch Normalization},
	author={Bjorck, Johan and Gomes, Carla and Selman, Bart},
	journal={arXiv preprint arXiv:1806.02375},
	year={2018}
}


@article{zhang2018effectiveness,
	title={Effectiveness of Scaled Exponentially-Regularized Linear Units (SERLUs)},
	author={Zhang, Guoqiang and Li, Haopeng},
	journal={arXiv preprint arXiv:1807.10117},
	year={2018}
}

@article{ghadimi2013stochastic,
	title={Stochastic first-and zeroth-order methods for nonconvex stochastic programming},
	author={Ghadimi, Saeed and Lan, Guanghui},
	journal={SIAM Journal on Optimization},
	volume={23},
	number={4},
	pages={2341--2368},
	year={2013},
	publisher={SIAM}
}

@article{vapnik1999overview,
	title={An overview of statistical learning theory},
	author={Vapnik, Vladimir Naumovich},
	journal={IEEE transactions on neural networks},
	volume={10},
	number={5},
	pages={988--999},
	year={1999},
	publisher={IEEE}
}
@book{vapnik2013nature,
	title={The nature of statistical learning theory},
	author={Vapnik, Vladimir},
	year={2013},
	publisher={Springer science \& business media}
}

@inproceedings{zhang2017rethinking,
	title={Understanding deep learning requires rethinking generalization},
	author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	booktitle={International Conference on Learning Representations},
	year={2017}
}

@inproceedings{szegedy2016rethinking,
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	title = {Rethinking the Inception Architecture for Computer Vision},
	booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2016}
}

@inproceedings{neyshabur2017norm,
	title={A {PAC}-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks},
	author={Behnam Neyshabur and Srinadh Bhojanapalli and Nathan Srebro},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@incollection{bartlett2017norm,
	title = {Spectrally-normalized margin bounds for neural networks},
	author = {Bartlett, Peter L and Foster, Dylan J and Telgarsky, Matus J},
	booktitle = {Advances in Neural Information Processing Systems 30},
	editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {6240--6249},
	year = {2017},
	publisher = {Curran Associates, Inc.}
}

@article{li2018intrinsic,
	title={Measuring the intrinsic dimension of objective landscapes},
	author={Li, Chunyuan and Farkhoor, Heerad and Liu, Rosanne and Yosinski, Jason},
	journal={arXiv preprint arXiv:1804.08838},
	year={2018}
}


@inproceedings{soudry2018iclrImplicit,
	title={The Implicit Bias of Gradient Descent on Separable Data},
	author={Daniel Soudry and Elad Hoffer and Nathan Srebro},
	booktitle={International Conference on Learning Representations},
	year={2018}
}


@article{soudry2018implicit,
	author  = {Daniel Soudry and Elad Hoffer and Mor Shpigel Nacson and Suriya Gunasekar and Nathan Srebro},
	title   = {The Implicit Bias of Gradient Descent on Separable Data},
	journal = {Journal of Machine Learning Research},
	year    = {2018},
	volume  = {19},
	number  = {70},
	pages   = {1-57}
}


@inproceedings{li2018algorithmic,
	title = {Algorithmic Regularization in Over-parameterized Matrix Sensing and Neural Networks with Quadratic Activations},
	author = {Li, Yuanzhi and Ma, Tengyu and Zhang, Hongyang},
	booktitle = {Proceedings of the 31st  Conference On Learning Theory},
	pages = {2--47},
	year = {2018},
	editor = {Bubeck, S\'ebastien and Perchet, Vianney and Rigollet, Philippe},
	volume = {75},
	series = {Proceedings of Machine Learning Research},
	address = {},
	month = {06--09 Jul},
	publisher = {PMLR}
}

@InProceedings{du2018power,
	title = 	 {On the Power of Over-parametrization in Neural Networks with Quadratic Activation},
	author = 	 {Du, Simon and Lee, Jason},
	booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
	pages = 	 {1329--1338},
	year = 	 {2018},
	editor = 	 {Dy, Jennifer and Krause, Andreas},
	volume = 	 {80},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Stockholmsm\"{a}ssan, Stockholm Sweden},
	month = 	 {10--15 Jul},
	publisher = 	 {PMLR}
}

@article{klusowski2018approximation,
	title={Approximation by Combinations of {ReLU} and Squared {ReLU} Ridge Functions With $\ell^1$ and $\ell^0$ Controls},
	author={Klusowski, Jason M and Barron, Andrew R},
	journal={IEEE Transactions on Information Theory},
	volume={64},
	number={12},
	pages={7649--7656},
	year={2018},
	publisher={IEEE}
}

@article{li2019better,
	title={Better Approximations of High Dimensional Smooth Functions by Deep Neural Networks with Rectified Power Units},
	author={Li, Bo and Tang, Shanshan and Yu, Haijun},
	journal={arXiv preprint arXiv:1903.05858},
	year={2019}
}

@InProceedings{zhong2017recovery,
	title = {Recovery Guarantees for One-hidden-layer Neural Networks},
	author = {Kai Zhong and Zhao Song and Prateek Jain and Peter L. Bartlett and Inderjit S. Dhillon},
	booktitle = {Proceedings of the 34th International Conference on Machine Learning},
	pages = {4140--4149},
	year = {2017},
	editor = {Doina Precup and Yee Whye Teh},
	volume = {70},
	series = {Proceedings of Machine Learning Research},
	address = {International Convention Centre, Sydney, Australia},
	month = {06--11 Aug},
	publisher = {PMLR}
}

@incollection{gunasekar2018implicit,
	title = {Implicit Bias of Gradient Descent on Linear Convolutional Networks},
	author = {Gunasekar, Suriya and Lee, Jason D and Soudry, Daniel and Srebro, Nati},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {9482--9491},
	year = {2018},
	publisher = {Curran Associates, Inc.}
}

@article{mou2017generalization,
	title={Generalization bounds of SGLD for non-convex learning: Two theoretical viewpoints},
	author={Mou, Wenlong and Wang, Liwei and Zhai, Xiyu and Zheng, Kai},
	journal={arXiv preprint arXiv:1707.05947},
	year={2017}
}

@inproceedings{allenzhu2019gobeyond,
 author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Liang, Yingyu},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers},
 volume = {32},
 year = {2019}
}

@InProceedings{allenzhu2019convergence,
  title = 	 {A Convergence Theory for Deep Learning via Over-Parameterization},
  author =       {Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {242--252},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
}


@InProceedings{du2018global,
	title = 	 {Gradient Descent Finds Global Minima of Deep Neural Networks},
	author = 	 {Du, Simon and Lee, Jason and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
	booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
	pages = 	 {1675--1685},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
	volume = 	 {97},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Long Beach, California, USA},
	month = 	 {09--15 Jun},
	publisher = 	 {PMLR}
}

@article{zou2018stochastic,
	title={Stochastic gradient descent optimizes over-parameterized deep {ReLU} networks},
	author={Zou, Difan and Cao, Yuan and Zhou, Dongruo and Gu, Quanquan},
	journal={arXiv preprint arXiv:1811.08888},
	year={2018}
}

@incollection{du2018algorithmic,
	title = {Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced},
	author = {Du, Simon S. and Hu, Wei and Lee, Jason D.},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {382--393},
	year = {2018},
	publisher = {Curran Associates, Inc.}
}

@inproceedings{
	du2018gradient,
	title={Gradient Descent Provably Optimizes Over-parameterized Neural Networks},
	author={Simon S. Du and Xiyu Zhai and Barnabas Poczos and Aarti Singh},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@article{clarke1975generalized,
	title={Generalized gradients and applications},
	author={Clarke, Frank H.},
	journal={Transactions of the American Mathematical Society},
	volume={205},
	pages={247--262},
	year={1975}
}


@book{clarke1990optimization,
	author = {Clarke, Frank H},
	title = {Optimization and Nonsmooth Analysis},
	publisher = {Society for Industrial and Applied Mathematics},
	year = {1990},
	doi = {10.1137/1.9781611971309}
}

@article{drusvyatskiy2015curves,
  title={Curves of descent},
  author={Drusvyatskiy, Dmitriy and Ioffe, Alexander D and Lewis, Adrian S},
  journal={SIAM Journal on Control and Optimization},
  volume={53},
  number={1},
  pages={114--138},
  year={2015},
  publisher={SIAM}
}

@book{clarke2008nonsmooth,
	title={Nonsmooth analysis and control theory},
	author={Clarke, Francis H. and Ledyaev, Yuri S. and Stern, Ronald J. and Wolenski, Peter R.},
	volume={178},
	year={2008},
	publisher={Springer Science \& Business Media}
}

@article{davis2018stochastic,
	author={Davis, Damek
	and Drusvyatskiy, Dmitriy
	and Kakade, Sham
	and Lee, Jason D.},
	title={Stochastic Subgradient Method Converges on Tame Functions},
	journal={Foundations of Computational Mathematics},
	volume={20},
	number={1},
	year={2020},
	month={Feb},
	pages={119-154}
}

@article{ma2019implicit,
	title={Implicit regularization in nonconvex statistical estimation: Gradient descent converges linearly for phase retrieval, matrix completion, and blind deconvolution},
	author={Ma, Cong and Wang, Kaizheng and Chi, Yuejie and Chen, Yuxin},
	journal={Foundations of Computational Mathematics},
	year={2019},
	month={Aug},
	day={05}
}

@inproceedings{
	ji2018gradient,
	title={Gradient descent aligns the layers of deep linear networks},
	author={Ziwei Ji and Matus Telgarsky},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@article{xu2018gradient,
	title={When Will Gradient Methods Converge to Max-margin Classifier under {ReLU} Models?},
	author={Tengyu Xu and Yi Zhou and Kaiyi Ji and Yingbin Liang},
	journal={arXiv preprint arXiv:1806.04339},
	year={2018}
}

@incollection{wei2018margin,
	title = {Regularization Matters: Generalization and Optimization of Neural Nets v.s. their Induced Kernel},
	author = {Wei, Colin and Lee, Jason D and Liu, Qiang and Ma, Tengyu},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {9709--9721},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@article{li2018decision,
	title={On the decision boundary of deep neural networks},
	author={Li, Yu and Richtarik, Peter and Ding, Lizhong and Gao, Xin},
	journal={arXiv preprint arXiv:1808.05385},
	year={2018}
}

@inproceedings{nacson2018stochastic,
	title = {Stochastic Gradient Descent on Separable Data: Exact Convergence with a Fixed Learning Rate},
	author = {Nacson, Mor Shpigel and Srebro, Nathan and Soudry, Daniel},
	booktitle = {Proceedings of Machine Learning Research},
	pages = {3051--3059},
	year = {2019},
	editor = {Chaudhuri, Kamalika and Sugiyama, Masashi},
	volume = {89},
	series = {Proceedings of Machine Learning Research},
	address = {},
	month = {16--18 Apr},
	publisher = {PMLR}
}


@InProceedings{nacson2019convergence,
	title = {Convergence of Gradient Descent on Separable Data},
	author = {Nacson, Mor Shpigel and Lee, Jason and Gunasekar, Suriya and Savarese, Pedro Henrique Pamplona and Srebro, Nathan and Soudry, Daniel},
	booktitle = {Proceedings of Machine Learning Research},
	pages = {3420--3428},
	year = {2019},
	editor = {Chaudhuri, Kamalika and Sugiyama, Masashi},
	volume = {89},
	series = {Proceedings of Machine Learning Research},
	address = {},
	month = {16--18 Apr},
	publisher = {PMLR}
}


@article{ji2018risk,
	title={Risk and parameter convergence of logistic regression},
	author={Ji, Ziwei and Telgarsky, Matus},
	journal={arXiv preprint arXiv:1803.07300},
	year={2018}
}

@InProceedings{ji2019risk,
	title = {The implicit bias of gradient descent on nonseparable data},
	author = {Ji, Ziwei and Telgarsky, Matus},
	booktitle = {Proceedings of the Thirty-Second Conference on Learning Theory},
	pages = {1772--1798},
	year = {2019},
	editor = {Beygelzimer, Alina and Hsu, Daniel},
	volume = {99},
	series = {Proceedings of Machine Learning Research},
	address = {Phoenix, USA},
	month = {25--28 Jun},
	publisher = {PMLR}
}

@article{ji2019refined,
	title={A refined primal-dual analysis of the implicit bias},
	author={Ji, Ziwei and Telgarsky, Matus},
	journal={arXiv preprint arXiv:1906.04540},
	year={2019}
}

@InProceedings{gunasekar2018characterizing,
	title = 	 {Characterizing Implicit Bias in Terms of Optimization Geometry},
	author = 	 {Gunasekar, Suriya and Lee, Jason and Soudry, Daniel and Srebro, Nathan},
	booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
	pages = 	 {1832--1841},
	year = 	 {2018},
	editor = 	 {Dy, Jennifer and Krause, Andreas},
	volume = 	 {80},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Stockholmsmässan, Stockholm Sweden},
	month = 	 {10--15 Jul},
	publisher = 	 {PMLR},
}

@incollection{wilson2017marginal,
	title = {The Marginal Value of Adaptive Gradient Methods in Machine Learning},
	author = {Wilson, Ashia C and Roelofs, Rebecca and Stern, Mitchell and Srebro, Nati and Recht, Benjamin},
	booktitle = {Advances in Neural Information Processing Systems 30},
	editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {4148--4158},
	year = {2017},
	publisher = {Curran Associates, Inc.}
}

@article{banburski2019theory,
	title={Theory {III}: Dynamics and Generalization in Deep Networks},
	author={Andrzej Banburski and Qianli Liao and Brando Miranda and Tomaso Poggio and Lorenzo Rosasco and Jack Hidary},
	journal={CBMM Memo No: 090, version 20},
	year={2019}
}


@inproceedings{ali2018continuous,
	title = 	 {A Continuous-Time View of Early Stopping for Least Squares Regression},
	author = 	 {Ali, Alnur and Kolter, J. Zico and Tibshirani, Ryan J.},
	booktitle =  {Proceedings of Machine Learning Research},
	pages = 	 {1370--1378},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
	volume = 	 {89},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {},
	month = 	 {16--18 Apr},
	publisher =  {PMLR}
}

@incollection{suggala2018connecting,
	title = {Connecting Optimization and Regularization Paths},
	author = {Suggala, Arun and Prasad, Adarsh and Ravikumar, Pradeep K},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {10608--10619},
	year = {2018},
	publisher = {Curran Associates, Inc.}
}

@inproceedings{azizan2018stochastic,
	title={Stochastic Gradient/Mirror Descent: Minimax Optimality and Implicit Regularization},
	author={Navid Azizan and Babak Hassibi},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@inproceedings{keskar2017large,
	title={On large-batch training for deep learning: Generalization gap and sharp minima},
	author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
	booktitle={International Conference on Learning Representations},
	year={2017}
}

@inproceedings{dinh2017sharp,
  title = 	 {Sharp Minima Can Generalize For Deep Nets},
  author =       {Laurent Dinh and Razvan Pascanu and Samy Bengio and Yoshua Bengio},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1019--1028},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
}

@article{yi2019positively,
	title={Positively Scale-Invariant Flatness of {ReLU} Neural Networks},
	author={Yi, Mingyang and Meng, Qi and Chen, Wei and Ma, Zhi-ming and Liu, Tie-Yan},
	journal={arXiv preprint arXiv:1903.02237},
	year={2019}
}

@article{jastrzkebski2017three,
	title={Three factors influencing minima in {SGD}},
	author={Jastrz{\k{e}}bski, Stanis{\l}aw and Kenton, Zachary and Arpit, Devansh and Ballas, Nicolas and Fischer, Asja and Bengio, Yoshua and Storkey, Amos},
	journal={arXiv preprint arXiv:1711.04623},
	year={2017}
}

@incollection{lee2019wide,
	title = {Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent},
	author = {Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {8570--8581},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@inproceedings{
	arora2018theoretical,
	title={Theoretical Analysis of Auto Rate-Tuning by Batch Normalization},
	author={Sanjeev Arora and Zhiyuan Li and Kaifeng Lyu},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@inproceedings{
	li2020exp,
	title={An Exponential Learning Rate Schedule for Deep Learning},
	author={Zhiyuan Li and Sanjeev Arora},
	booktitle={International Conference on Learning Representations},
	year={2020}
}

@incollection{arora2019exact,
	title = {On Exact Computation with an Infinitely Wide Neural Net},
	author = {Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Russ R and Wang, Ruosong},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {8139--8148},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@incollection{jacot2018ntk,
title = {Neural Tangent Kernel: Convergence and Generalization in Neural Networks},
author = {Jacot, Arthur and Gabriel, Franck and Hongler, Clement},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {8571--8580},
year = {2018},
publisher = {Curran Associates, Inc.}
}

@incollection{rosset2004margin,
title = {Margin Maximizing Loss Functions},
author = {Rosset, Saharon and Ji Zhu and Trevor J. Hastie},
booktitle = {Advances in Neural Information Processing Systems 16},
editor = {S. Thrun and L. K. Saul and B. Sch\"{o}lkopf},
pages = {1237--1244},
year = {2004},
publisher = {MIT Press}
}

@article{SokolicGSR17,
  author    = {Jure Sokolic and
               Raja Giryes and
               Guillermo Sapiro and
               Miguel R. D. Rodrigues},
  title     = {Robust Large Margin Deep Neural Networks},
  journal   = {{IEEE} Trans. Signal Processing},
  volume    = {65},
  number    = {16},
  pages     = {4265--4280},
  year      = {2017},
  doi       = {10.1109/TSP.2017.2708039},
  timestamp = {Fri, 02 Nov 2018 09:33:28 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/tsp/SokolicGSR17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{arora2018compression,
  title = 	 {Stronger Generalization Bounds for Deep Nets via a Compression Approach},
  author = 	 {Arora, Sanjeev and Ge, Rong and Neyshabur, Behnam and Zhang, Yi},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {254--263},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR}
}







@InProceedings{croce2019provable,
  title = 	 {Provable Robustness of {ReLU} networks via Maximization of Linear Regions},
  author = 	 {Croce, Francesco and Andriushchenko, Maksym and Hein, Matthias},
  booktitle = 	 {Proceedings of Machine Learning Research},
  pages = 	 {2057--2066},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
  volume = 	 {89},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {16--18 Apr},
  publisher = 	 {PMLR}
}

@InProceedings{nacson2019lexicographic,
	title = 	 {Lexicographic and Depth-Sensitive Margins in Homogeneous and Non-Homogeneous Deep Models},
	author = 	 {Nacson, Mor Shpigel and Gunasekar, Suriya and Lee, Jason and Srebro, Nathan and Soudry, Daniel},
	booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
	pages = 	 {4683--4692},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
	volume = 	 {97},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Long Beach, California, USA},
	month = 	 {09--15 Jun},
	publisher = 	 {PMLR}
}

@article{dutta2013approximate,
  title={Approximate {KKT} points and a proximity measure for termination},
  author={Dutta, Joydeep and Deb, Kalyanmoy and Tulshyan, Rupesh and Arora, Ramnik},
  journal={Journal of Global Optimization},
  volume={56},
  number={4},
  pages={1463--1499},
  year={2013},
  publisher={Springer}
}

@incollection{du2017exp,
title = {Gradient Descent Can Take Exponential Time to Escape Saddle Points},
author = {Du, Simon S and Jin, Chi and Lee, Jason D and Jordan, Michael I and Singh, Aarti and Poczos, Barnabas},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {1067--1077},
year = {2017},
publisher = {Curran Associates, Inc.}
}

@incollection{gidel2019implicit,
	title = {Implicit Regularization of Discrete Gradient Dynamics in Linear Neural Networks},
	author = {Gidel, Gauthier and Bach, Francis and Lacoste-Julien, Simon},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {3196--3206},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@incollection{arora2019implicit,
	title = {Implicit Regularization in Deep Matrix Factorization},
	author = {Arora, Sanjeev and Cohen, Nadav and Hu, Wei and Luo, Yuping},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {7411--7422},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@inproceedings{blanc2020ou,
  title = 	 {Implicit regularization for deep neural networks driven by an Ornstein-Uhlenbeck like process},
  author =       {Blanc, Guy and Gupta, Neha and Valiant, Gregory and Valiant, Paul},
  booktitle = 	 {Proceedings of Thirty Third Conference on Learning Theory},
  pages = 	 {483--513},
  year = 	 {2020},
  editor = 	 {Abernethy, Jacob and Agarwal, Shivani},
  volume = 	 {125},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--12 Jul},
  publisher =    {PMLR},
}

@inproceedings{damian2021label,
 author = {Damian, Alex and Ma, Tengyu and Lee, Jason D},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {27449--27461},
 publisher = {Curran Associates, Inc.},
 title = {Label Noise {SGD} Provably Prefers Flat Global Minimizers},
 volume = {34},
 year = {2021}
}


@incollection{neyshabur2015pathsgd,
	title = {Path-{SGD}: {P}ath-Normalized Optimization in Deep Neural Networks},
	author = {Neyshabur, Behnam and Salakhutdinov, Ruslan R and Srebro, Nati},
	booktitle = {Advances in Neural Information Processing Systems 28},
	editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
	pages = {2422--2430},
	year = {2015},
	publisher = {Curran Associates, Inc.}
}

@inproceedings{neyshabur2014search,
	author    = {Behnam Neyshabur and Ryota Tomioka and Nathan Srebro},
	title     = {In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning},
	booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Workshop Track Proceedings},
	year      = {2015}
}

@INPROCEEDINGS{carlini2017towards,
	author={Nicholas Carlini and David Wagner},
	booktitle={2017 IEEE Symposium on Security and Privacy (SP)},
	title={Towards Evaluating the Robustness of Neural Networks},
	year={2017},
	pages={39-57},
	doi={10.1109/SP.2017.49},
	ISSN={2375-1207},
	month={May},}

@book{coste2002an,
	title="An Introduction to O-minimal Geometry",
	author="Michel {Coste}",
	year="2002"
}

@article{dries1996geometric,
	title="Geometric categories and o-minimal structures",
	author="Lou van den {Dries} and Chris {Miller}",
	journal="Duke Mathematical Journal",
	volume="84",
	number="2",
	pages="497--540",
	year="1996"
}

@InProceedings{He_2015_ICCV,
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	title = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on {ImageNet} Classification},
	booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
	month = {December},
	year = {2015}
}

@inproceedings{
	zhang2018residual,
	title={Fixup Initialization: Residual Learning Without Normalization},
	author={Hongyi Zhang and Yann N. Dauphin and Tengyu Ma},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@incollection{giorgi2004mathematicsChapter4,
	title = "{Chapter IV - Nonsmooth Optimization Problems}",
	author = "Giorgi, Giorgio and Guerraggio, Angelo and Thierfelder, J{\"o}rg",
	booktitle = "Mathematics of Optimization",
	publisher = "Elsevier Science",
	address = "Amsterdam",
	pages = "359 - 457",
	year = "2004",
	isbn = "978-0-444-50550-7"
}

@inproceedings{
	szegedy2013intriguing,
	title={Intriguing properties of neural networks},
	author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
	booktitle={International Conference on Learning Representations},
	year={2013}
}

@InProceedings{biggio2013evasion,
	author="Biggio, Battista
	and Corona, Igino
	and Maiorca, Davide
	and Nelson, Blaine
	and {\v{S}}rndi{\'{c}}, Nedim
	and Laskov, Pavel
	and Giacinto, Giorgio
	and Roli, Fabio",
	editor="Blockeel, Hendrik
	and Kersting, Kristian
	and Nijssen, Siegfried
	and {\v{Z}}elezn{\'y}, Filip",
	title="Evasion Attacks against Machine Learning at Test Time",
	booktitle="Machine Learning and Knowledge Discovery in Databases",
	year="2013",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="387--402",
}

@article{ramdas2016towards,
	title={Towards a deeper geometric, analytic and algorithmic understanding of margins},
	author={Ramdas, Aaditya and Pena, Javier},
	journal={Optimization Methods and Software},
	volume={31},
	number={2},
	pages={377--391},
	year={2016},
	publisher={Taylor \& Francis}
}

@InProceedings{telgarsky13margins,
	title = 	 {Margins, Shrinkage, and Boosting},
	author = 	 {Matus Telgarsky},
	booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
	pages = 	 {307--315},
	year = 	 {2013},
	editor = 	 {Sanjoy Dasgupta and David McAllester},
	volume = 	 {28},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Atlanta, Georgia, USA},
	month = 	 {17--19 Jun},
	publisher = 	 {PMLR}
}

@article{schapire1998boosting,
	author = "Schapire, Robert E. and Freund, Yoav and Bartlett, Peter and Lee, Wee Sun",
	doi = "10.1214/aos/1024691352",
	fjournal = "The Annals of Statistics",
	journal = "Ann. Statist.",
	month = "10",
	number = "5",
	pages = "1651--1686",
	publisher = "The Institute of Mathematical Statistics",
	title = "Boosting the margin: A new explanation for the effectiveness of voting methods",
	volume = "26",
	year = "1998"
}

@book{schapire2012boosting,
	author = {Schapire, Robert E. and Freund, Yoav},
	title = {Boosting: Foundations and Algorithms},
	year = {2012},
	isbn = {0262017180, 9780262017183},
	publisher = {The MIT Press},
}

@article{shalev2010equivalence,
	title={On the equivalence of weak learnability and linear separability: New relaxations and efficient boosting algorithms},
	author={Shalev-Shwartz, Shai and Singer, Yoram},
	journal={Machine learning},
	volume={80},
	number={2-3},
	pages={141--163},
	year={2010},
	publisher={Springer}
}


@InProceedings{athalye2018obfuscated,
	title = 	 {Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples},
	author = 	 {Athalye, Anish and Carlini, Nicholas and Wagner, David},
	booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
	pages = 	 {274--283},
	year = 	 {2018},
	editor = 	 {Dy, Jennifer and Krause, Andreas},
	volume = 	 {80},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Stockholmsmässan, Stockholm Sweden},
	month = 	 {10--15 Jul},
	publisher = 	 {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v80/athalye18a/athalye18a.pdf},
}

@article{absil2005convergence,
	title={Convergence of the iterates of descent methods for analytic cost functions},
	author={Absil, Pierre-Antoine and Mahony, Robert and Andrews, Benjamin},
	journal={SIAM Journal on Optimization},
	volume={16},
	number={2},
	pages={531--547},
	year={2005},
	publisher={SIAM}
}

@article{curry1944method,
	title={The method of steepest descent for non-linear minimization problems},
	author={Curry, Haskell B},
	journal={Quarterly of Applied Mathematics},
	volume={2},
	number={3},
	pages={258--261},
	year={1944}
}

@article{zoutendijk1976mathematical,
	title={Mathematical programming methods},
	author={Zoutendijk, Guus},
	year={1976},
	publisher={North-Holland}
}

@book{palis2012geometric,
	title={Geometric theory of dynamical systems: an introduction},
	author={Palis, J Jr and De Melo, Welington},
	year={2012},
	publisher={Springer Science \& Business Media}
}







@InProceedings{golowich18a,
	title = 	 {Size-Independent  Sample Complexity of Neural Networks},
	author = 	 {Golowich, Noah and Rakhlin, Alexander and Shamir, Ohad},
	booktitle = 	 {Proceedings of the 31st  Conference On Learning Theory},
	pages = 	 {297--299},
	year = 	 {2018},
	editor = 	 {Bubeck, S\'ebastien and Perchet, Vianney and Rigollet, Philippe},
	volume = 	 {75},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {},
	month = 	 {06--09 Jul},
	publisher = 	 {PMLR}
}

@article{li2018tighter,
	title={On tighter generalization bound for deep neural networks: {CNNs}, {R}es{N}ets, and beyond},
	author={Li, Xingguo and Lu, Junwei and Wang, Zhaoran and Haupt, Jarvis and Zhao, Tuo},
	journal={arXiv preprint arXiv:1806.05159},
	year={2018}
}

@inproceedings{
	wei2020improved,
	title={Improved Sample Complexities for Deep Neural Networks and Robust Classification via an All-Layer Margin},
	author={Colin Wei and Tengyu Ma},
	booktitle={International Conference on Learning Representations},
	year={2020}
}







@InProceedings{anil2019sorting,
	title = 	 {Sorting Out {L}ipschitz Function Approximation},
	author = 	 {Anil, Cem and Lucas, James and Grosse, Roger},
	booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
	pages = 	 {291--301},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
	volume = 	 {97},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Long Beach, California, USA},
	month = 	 {09--15 Jun},
	publisher = 	 {PMLR}
}


@InProceedings{precup2017parseval,
title = 	 {Parseval Networks: Improving Robustness to Adversarial Examples},
author = 	 {Moustapha Cisse and Piotr Bojanowski and Edouard Grave and Yann Dauphin and Nicolas Usunier},
booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
pages = 	 {854--863},
year = 	 {2017},
editor = 	 {Doina Precup and Yee Whye Teh},
volume = 	 {70},
series = 	 {Proceedings of Machine Learning Research},
address = 	 {International Convention Centre, Sydney, Australia},
month = 	 {06--11 Aug},
publisher = 	 {PMLR}
}

@incollection{allen2019can,
title = {Can {SGD} Learn Recurrent Neural Networks with Provable Generalization?},
author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {10331--10341},
year = {2019},
publisher = {Curran Associates, Inc.},
}

@incollection{du2019graph,
title = {Graph Neural Tangent Kernel: Fusing Graph Neural Networks with Graph Kernels},
author = {Du, Simon S and Hou, Kangcheng and Salakhutdinov, Russ R and Poczos, Barnabas and Wang, Ruosong and Xu, Keyulu},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {5723--5733},
year = {2019},
publisher = {Curran Associates, Inc.}
}


@incollection{yehudai2019RF,
title = {On the Power and Limitations of Random Features for Understanding Neural Networks},
author = {Yehudai, Gilad and Shamir, Ohad},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {6598--6608},
year = {2019},
publisher = {Curran Associates, Inc.},
}


@incollection{allen2019resnet,
title = {What Can ResNet Learn Efficiently, Going Beyond Kernels?},
author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {9017--9028},
year = {2019},
publisher = {Curran Associates, Inc.},
}

@article{allen2019backward,
	title={Backward Feature Correction: How Deep Learning Performs Deep Learning},
	author={Zeyuan Allen-Zhu and Yuanzhi Li},
	journal={arXiv preprint arXiv:2001.04413},
	year={2020}
}

@incollection{ghorbani2019lazy,
title = {Limitations of Lazy Training of Two-layers Neural Network},
author = {Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {9111--9121},
year = {2019},
publisher = {Curran Associates, Inc.},
}

@incollection{chizat2019lazy,
	title = {On Lazy Training in Differentiable Programming},
	author = {Chizat, L\'{e}na\"{\i}c and Oyallon, Edouard and Bach, Francis},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {2937--2947},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@article{daniely2020parities,
	title={Learning Parities with Neural Networks},
	author={Amit Daniely and Eran Malach},
	journal={arXiv preprint arXiv:2002.07400},
	year={2020}
}

@inproceedings{
ji2020polylogarithmic,
title={Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow {ReLU} networks},
author={Ziwei Ji and Matus Telgarsky},
booktitle={International Conference on Learning Representations},
year={2020}
}

@inproceedings{welling11langevin,
	title = {Bayesian Learning via Stochastic Gradient Langevin Dynamics},
	author = {Welling, Max and Teh, Yee Whye},
	year = {2011},
	isbn = {9781450306195},
	publisher = {Omnipress},
	address = {Madison, WI, USA},
	booktitle = {Proceedings of the 28th International Conference on International Conference on Machine Learning},
	pages = {681-688},
	numpages = {8},
	location = {Bellevue, Washington, USA},
	series = {ICML '11}
}

@incollection{li19learningrate,
	title = {Towards Explaining the Regularization Effect of Initial Large Learning Rate in Training Neural Networks},
	author = {Li, Yuanzhi and Wei, Colin and Ma, Tengyu},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {11674--11685},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@article{shi2020learning,
	title={On Learning Rates and Schr$\backslash$" odinger Operators},
	author={Shi, Bin and Su, Weijie J and Jordan, Michael I},
	journal={arXiv preprint arXiv:2004.06977},
	year={2020}
}

@inproceedings{
	zhang2018three,
	title={Three Mechanisms of Weight Decay Regularization},
	author={Guodong Zhang and Chaoqi Wang and Bowen Xu and Roger Grosse},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@inproceedings{
	hoffer2018fix,
	title={Fix your classifier: the marginal value of training the last weight layer},
	author={Elad Hoffer and Itay Hubara and Daniel Soudry},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@inproceedings{
gissin2020the,
title={The Implicit Bias of Depth: How Incremental Learning Drives Generalization},
author={Daniel Gissin and Shai Shalev-Shwartz and Amit Daniely},
booktitle={International Conference on Learning Representations},
year={2020}
}

@inproceedings{fazel2001rank,
  title={A rank minimization heuristic with application to minimum order system approximation},
  author={Fazel, Maryam and Hindi, Haitham and Boyd, Stephen P},
  booktitle={Proceedings of the 2001 American Control Conference.(Cat. No. 01CH37148)},
  volume={6},
  pages={4734--4739},
  year={2001},
  organization={IEEE}
}

@article{belabbas2020implicit,
  title={On implicit regularization: Morse functions and applications to matrix factorization},
  author={Belabbas, Mohamed Ali},
  journal={arXiv preprint arXiv:2001.04264},
  year={2020}
}

@inproceedings{razin2020implicit,
 author = {Razin, Noam and Cohen, Nadav},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {21174--21187},
 publisher = {Curran Associates, Inc.},
 title = {Implicit Regularization in Deep Learning May Not Be Explainable by Norms},
 volume = {33},
 year = {2020}
}


@InProceedings{lee2016minimizers,
  title = 	 {Gradient Descent Only Converges to Minimizers},
  author = 	 {Lee, Jason D. and Simchowitz, Max and Jordan, Michael I. and Recht, Benjamin},
  booktitle = 	 {29th Annual Conference on Learning Theory},
  pages = 	 {1246--1257},
  year = 	 {2016},
  editor = 	 {Feldman, Vitaly and Rakhlin, Alexander and Shamir, Ohad},
  volume = 	 {49},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Columbia University, New York, New York, USA},
  month = 	 {23--26 Jun},
  publisher =    {PMLR}
}

@InProceedings{panageas2017only,
  author =	{Ioannis Panageas and Georgios Piliouras},
  title =	{{Gradient Descent Only Converges to Minimizers: Non-Isolated Critical Points and Invariant Regions}},
  booktitle =	{8th Innovations in Theoretical Computer Science Conference (ITCS 2017)},
  pages =	{2:1--2:12},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-029-3},
  ISSN =	{1868-8969},
  year =	{2017},
  volume =	{67},
  editor =	{Christos H. Papadimitriou},
  publisher =	{Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address =	{Dagstuhl, Germany},
  URN =		{urn:nbn:de:0030-drops-81640},
  doi =		{10.4230/LIPIcs.ITCS.2017.2},
}

@article{lee2017first,
  title={First-order methods almost always avoid saddle points},
  author={Lee, Jason D and Panageas, Ioannis and Piliouras, Georgios and Simchowitz, Max and Jordan, Michael I and Recht, Benjamin},
  journal={arXiv preprint arXiv:1710.07406},
  year={2017}
}

@incollection{panageas19firstorder,
	title = {First-order methods almost always avoid saddle points: The case of vanishing step-sizes},
	author = {Panageas, Ioannis and Piliouras, Georgios and Wang, Xiao},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {6474--6483},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@incollection{gunasekar2017implicit,
title = {Implicit Regularization in Matrix Factorization},
author = {Gunasekar, Suriya and Woodworth, Blake E and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nati},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {6151--6159},
year = {2017},
publisher = {Curran Associates, Inc.}
}

@inproceedings{wang2014rank,
  title={Rank-one matrix pursuit for matrix completion},
  author={Wang, Zheng and Lai, Ming-Jun and Lu, Zhaosong and Fan, Wei and Davulcu, Hasan and Ye, Jieping},
  booktitle={International Conference on Machine Learning},
  pages={91--99},
  year={2014}
}

@article{diamond2016cvxpy,
  author  = {Steven Diamond and Stephen Boyd},
  title   = {{CVXPY}: {A} {P}ython-embedded modeling language for convex optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2016},
  volume  = {17},
  number  = {83},
  pages   = {1--5},
}

@article{agrawal2018rewriting,
  author  = {Agrawal, Akshay and Verschueren, Robin and Diamond, Steven and Boyd, Stephen},
  title   = {A rewriting system for convex optimization problems},
  journal = {Journal of Control and Decision},
  year    = {2018},
  volume  = {5},
  number  = {1},
  pages   = {42--60},
}

@article{wu2017towards,
  title={Towards understanding generalization of deep learning: Perspective of loss landscapes},
  author={Wu, Lei and Zhu, Zhanxing and others},
  journal={arXiv preprint arXiv:1706.10239},
  year={2017}
}

@article{HiriartUrruty1999clarke,
	author    = {Jean{-}Baptiste Hiriart{-}Urruty and
	A. S. Lewis},
	title     = {The Clarke and Michel-Penot Subdifferentials of the Eigenvalues of
	a Symmetric Matrix},
	journal   = {Comput. Optim. Appl.},
	volume    = {13},
	number    = {1-3},
	pages     = {13--23},
	year      = {1999},
	doi       = {10.1023/A:1008644520093},
	timestamp = {Tue, 14 Jul 2020 14:28:36 +0200},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{lojasiewicz1965ensembles,
	title={Ensembles semi-analytiques},
	author={Łojasiewicz, Stanisław},
	journal={IHES notes},
	year={1965}
}

@article{bezanson2012julia,
  title={Julia: A fast dynamic language for technical computing},
  author={Bezanson, Jeff and Karpinski, Stefan and Shah, Viral B and Edelman, Alan},
  journal={arXiv preprint arXiv:1209.5145},
  year={2012}
}

  @incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.}
}

@techreport{hinton2012rmsprop,
  author = {Geoffrey Hinton and Nitish Srivastava and Kevin Swersky},
  title={Neural networks for machine learning lecture 6a: Overview of mini-batch gradient descent},
  url = {https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf},
  year = {2012}
}


@inproceedings{
	lyu2020gradient,
	title={Gradient Descent Maximizes the Margin of Homogeneous Neural Networks},
	author={Kaifeng Lyu and Jian Li},
	booktitle={International Conference on Learning Representations},
	year={2020}
}

@InProceedings{chizat20logistic,
	title = {Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks Trained with the Logistic Loss},
	author = {Chizat, L\'ena\"ic and Bach, Francis},
	booktitle = {Proceedings of Thirty Third Conference on Learning Theory},
	pages = {1305--1338},
	year = {2020},
	editor = {Jacob Abernethy and Shivani Agarwal},
	volume = {125},
	series = {Proceedings of Machine Learning Research},
	address = {},
	month = {09--12 Jul},
	publisher = {PMLR}
}



@inproceedings{ji2020directional,
	author = {Ji, Ziwei and Telgarsky, Matus},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
	pages = {17176--17186},
	publisher = {Curran Associates, Inc.},
	title = {Directional convergence and alignment in deep learning},
	volume = {33},
	year = {2020}
}

@inproceedings{shah2020pitfalls,
	author = {Shah, Harshay and Tamuly, Kaustav and Raghunathan, Aditi and Jain, Prateek and Netrapalli, Praneeth},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
	pages = {9573--9585},
	publisher = {Curran Associates, Inc.},
	title = {The Pitfalls of Simplicity Bias in Neural Networks},
	volume = {33},
	year = {2020}
}

@inproceedings{hu2020surprising,
	author = {Hu, Wei and Xiao, Lechao and Adlam, Ben and Pennington, Jeffrey},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
	pages = {17116--17128},
	publisher = {Curran Associates, Inc.},
	title = {The Surprising Simplicity of the Early-Time Learning Dynamics of Neural Networks},
	volume = {33},
	year = {2020}
}

@inproceedings{
	li2021towards,
	title={Towards Resolving the Implicit Bias of Gradient Descent for Matrix Factorization: Greedy Low-Rank Learning},
	author={Zhiyuan Li and Yuping Luo and Kaifeng Lyu},
	booktitle={International Conference on Learning Representations},
	year={2021}
}

@inproceedings{
	mehta2021extreme,
	title={Extreme Memorization via Scale of Initialization},
	author={Harsh Mehta and Ashok Cutkosky and Behnam Neyshabur},
	booktitle={International Conference on Learning Representations},
	year={2021}
}

@inproceedings{
	phuong2021the,
	title={The inductive bias of {R}e{LU} networks on orthogonally separable data},
	author={Mary Phuong and Christoph H Lampert},
	booktitle={International Conference on Learning Representations},
	year={2021}
}

@inproceedings{
	brutzkus2018sgd,
	title={{SGD} Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data},
	author={Alon Brutzkus and Amir Globerson and Eran Malach and Shai Shalev-Shwartz},
	booktitle={International Conference on Learning Representations},
	year={2018}
}


@InProceedings{sarussi2021towards,
  title = 	 {Towards Understanding Learning in Neural Networks with Linear Teachers},
  author =       {Sarussi, Roei and Brutzkus, Alon and Globerson, Amir},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {9313--9322},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
}

@article{maennel2018gradient,
	title={Gradient descent quantizes {ReLU} network features},
	author={Maennel, Hartmut and Bousquet, Olivier and Gelly, Sylvain},
	journal={arXiv preprint arXiv:1803.08367},
	year={2018}
}

@inproceedings{williams2019gradient,
	author = {Williams, Francis and Trager, Matthew and Panozzo, Daniele and Silva, Claudio and Zorin, Denis and Bruna, Joan},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Gradient Dynamics of Shallow Univariate {ReLU} Networks},
	volume = {32},
	year = {2019}
}

@inproceedings{moroshko2020implicit,
	author = {Moroshko, Edward and Woodworth, Blake E and Gunasekar, Suriya and Lee, Jason D and Srebro, Nati and Soudry, Daniel},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
	pages = {22182--22193},
	publisher = {Curran Associates, Inc.},
	title = {Implicit Bias in Deep Linear Classification: Initialization Scale vs Training Accuracy},
	volume = {33},
	year = {2020}
}

@InProceedings{woodworth20a,
	title = {Kernel and Rich Regimes in Overparametrized Models},
	author = {Woodworth, Blake and Gunasekar, Suriya and Lee, Jason D. and Moroshko, Edward and Savarese, Pedro and Golan, Itay and Soudry, Daniel and Srebro, Nathan},
	booktitle = {Proceedings of Thirty Third Conference on Learning Theory},
	pages = {3635--3673},
	year = {2020},
	editor = {Jacob Abernethy and Shivani Agarwal},
	volume = {125},
	series = {Proceedings of Machine Learning Research},
	address = {},
	month = {09--12 Jul},
	publisher = {PMLR}
}

@inproceedings{kalimeris2019sgd,
	author = {Kalimeris, Dimitris and Kaplun, Gal and Nakkiran, Preetum and Edelman, Benjamin and Yang, Tristan and Barak, Boaz and Zhang, Haofeng},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {{SGD} on Neural Networks Learns Functions of Increasing Complexity},
	volume = {32},
	year = {2019}
}

@inproceedings{
	valle-perez2018deep,
	title={Deep learning generalizes because the parameter-function map is biased towards simple functions},
	author={Guillermo Valle-Perez and Chico Q. Camargo and Ard A. Louis},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@InProceedings{razin2021implicit,
  title = 	 {Implicit Regularization in Tensor Factorization},
  author =       {Razin, Noam and Maman, Asaf and Cohen, Nadav},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {8913--8924},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
}


@book{coste2000introduction,
  title={An introduction to o-minimal geometry},
  author={Coste, Michel},
  year={2000},
  publisher={Istituti editoriali e poligrafici internazionali Pisa}
}

@article{luo2021phase,
  author  = {Tao Luo and Zhi-Qin John Xu and Zheng Ma and Yaoyu Zhang},
  title   = {Phase Diagram for Two-layer {ReLU} Neural Networks at Infinite-width Limit},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {71},
  pages   = {1-47},
}

@inproceedings{pellegrini2020analytic,
 author = {Pellegrini, Franco and Biroli, Giulio},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {5356--5367},
 publisher = {Curran Associates, Inc.},
 title = {An analytic theory of shallow networks dynamics for hinge loss classification},
 volume = {33},
 year = {2020}
}

@article{xu2021towards,
  title={Towards Understanding the Condensation of Two-layer Neural Networks at Initial Training},
  author={Xu, Zhi-Qin John and Zhou, Hanxu and Luo, Tao and Zhang, Yaoyu},
  journal={arXiv preprint arXiv:2105.11686},
  year={2021}
}


@InProceedings{brutzkus2019why,
  title = 	 {Why do Larger Models Generalize Better? {A} Theoretical Perspective via the {XOR} Problem},
  author =       {Brutzkus, Alon and Globerson, Amir},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {822--830},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
}

@inproceedings{reddi2018on,
  title={On the Convergence of Adam and Beyond},
  author={Sashank J. Reddi and Satyen Kale and Sanjiv Kumar},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{gemp2019unreasonable,
  title={The unreasonable effectiveness of Adam on cycles},
  author={Ian Gemp and Brian McWilliams},
  booktitle={NeurIPS Workshop on Bridging Game Theory and Deep Learning},
  year={2019}
}

@inproceedings{bock2019non,
  title={Non-convergence and limit cycles in the adam optimizer},
  author={Bock, Sebastian and Wei{\ss}, Martin},
  booktitle={International Conference on Artificial Neural Networks},
  pages={232--243},
  year={2019},
  organization={Springer}
}

@inproceedings{
cohen2021gradient,
title={Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability},
author={Jeremy Cohen and Simran Kaur and Yuanzhi Li and J Zico Kolter and Ameet Talwalkar},
booktitle={International Conference on Learning Representations},
year={2021},
}

@book{de1981asymptotic,
  title={Asymptotic methods in analysis},
  author={De Bruijn, Nicolaas Govert},
  volume={4},
  year={1981},
  publisher={Courier Corporation}
}

@techreport{van2021probability,
  title={APC 550 Lecture Notes: Probability in high dimension},
  author={van Handel, Ramon},
  year={2021},
  institution={Princeton University}
}

@inproceedings{lobacheva2021on,
 author = {Lobacheva, Ekaterina and Kodryan, Maxim and Chirkova, Nadezhda and Malinin, Andrey and Vetrov, Dmitry P},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {21545--21556},
 publisher = {Curran Associates, Inc.},
 title = {On the Periodic Behavior of Neural Network Training with Batch Normalization and Weight Decay},
 volume = {34},
 year = {2021}
}


@InProceedings{li2022robust,
  title = 	 {Robust Training of Neural Networks Using Scale Invariant Architectures},
  author =       {Li, Zhiyuan and Bhojanapalli, Srinadh and Zaheer, Manzil and Reddi, Sashank and Kumar, Sanjiv},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {12656--12684},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
}


@inproceedings{simonyan2014vgg,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  booktitle={International Conference on Learning Representations},
  year={2015}
}

@InProceedings{he2016identityres,
author="He, Kaiming
and Zhang, Xiangyu
and Ren, Shaoqing
and Sun, Jian",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="Identity Mappings in Deep Residual Networks",
booktitle="Computer Vision -- ECCV 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="630--645",
isbn="978-3-319-46493-0"
}




@InProceedings{karakida2019fisher,
  title = 	 {Universal Statistics of Fisher Information in Deep Neural Networks: Mean Field Approach},
  author =       {Karakida, Ryo and Akaho, Shotaro and Amari, Shun-ichi},
  booktitle = 	 {Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1032--1041},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
  volume = 	 {89},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {16--18 Apr},
  publisher =    {PMLR},
}


@inproceedings{
luo2019towards,
title={Towards Understanding Regularization in Batch Normalization},
author={Ping Luo and Xinjiang Wang and Wenqi Shao and Zhanglin Peng},
booktitle={International Conference on Learning Representations},
year={2019},
}

@inproceedings{
xie2021diffusion,
title={A Diffusion Theory For Deep Learning Dynamics: Stochastic Gradient Descent Exponentially Favors Flat Minima},
author={Zeke Xie and Issei Sato and Masashi Sugiyama},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{de2020identity,
 author = {De, Soham and Smith, Sam},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {19964--19975},
 publisher = {Curran Associates, Inc.},
 title = {Batch Normalization Biases Residual Blocks Towards the Identity Function in Deep Networks},
 volume = {33},
 year = {2020}
}

@inproceedings{lin2021spectral,
 author = {Lin, Zinan and Sekar, Vyas and Fanti, Giulia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {9625--9638},
 publisher = {Curran Associates, Inc.},
 title = {Why Spectral Normalization Stabilizes {GANs}: Analysis and Improvements},
 volume = {34},
 year = {2021}
}


@inproceedings{
barrett2021implicit,
title={Implicit Gradient Regularization},
author={David Barrett and Benoit Dherin},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{
wu2021direction,
title={Direction Matters: On the Implicit Bias of Stochastic Gradient Descent with Moderate Learning Rate},
author={Jingfeng Wu and Difan Zou and Vladimir Braverman and Quanquan Gu},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{
smith2021origin,
title={On the Origin of Implicit Regularization in Stochastic Gradient Descent},
author={Samuel L Smith and Benoit Dherin and David Barrett and Soham De},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{
foret2021sam,
title={Sharpness-aware Minimization for Efficiently Improving Generalization},
author={Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
booktitle={International Conference on Learning Representations},
year={2021},
}

@InProceedings{kwon2021asam,
  title = 	 {{ASAM}: Adaptive Sharpness-Aware Minimization for Scale-Invariant Learning of Deep Neural Networks},
  author =       {Kwon, Jungmin and Kim, Jeongseop and Park, Hyunseo and Choi, In Kwon},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {5905--5914},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
}

@inproceedings{
ma2021linear,
title={On Linear Stability of {SGD} and Input-Smoothness of Neural Networks},
author={Chao Ma and Lexing Ying},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
}

@inproceedings{
daneshmand2021batch,
title={Batch Normalization Orthogonalizes Representations in Deep Random Networks},
author={Hadi Daneshmand and Amir Joudaki and Francis Bach},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
}

@inproceedings{
daneshmand2020rankcollapse,
 author = {Daneshmand, Hadi and Kohler, Jonas and Bach, Francis and Hofmann, Thomas and Lucchi, Aurelien},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {18387--18398},
 publisher = {Curran Associates, Inc.},
 title = {Batch normalization provably avoids ranks collapse for randomly initialised deep networks},
 volume = {33},
 year = {2020}
}


@inproceedings{lubana2021beyond,
 author = {Lubana, Ekdeep S and Dick, Robert and Tanaka, Hidenori},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {4778--4791},
 publisher = {Curran Associates, Inc.},
 title = {Beyond BatchNorm: Towards a Unified Understanding of Normalization in Deep Learning},
 volume = {34},
 year = {2021}
}

@article{lange2022preconditioning,
  author  = {Susanna Lange and Kyle Helfrich and Qiang Ye},
  title   = {Batch Normalization Preconditioning for Neural Network Training},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {72},
  pages   = {1--41},
}

@article{geiping2021stochastic,
  title={Stochastic training is not necessary for generalization},
  author={Geiping, Jonas and Goldblum, Micah and Pope, Phillip E and Moeller, Michael and Goldstein, Tom},
  journal={arXiv preprint arXiv:2109.14119},
  year={2021}
}


@InProceedings{zhu2019anisotropic,
  title = 	 {The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of Escaping from Sharp Minima and Regularization Effects},
  author =       {Zhu, Zhanxing and Wu, Jingfeng and Yu, Bing and Wu, Lei and Ma, Jinwen},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {7654--7663},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
}

@article{fehrman2020convergence,
  author  = {Benjamin Fehrman and Benjamin Gess and Arnulf Jentzen},
  title   = {Convergence Rates for the Stochastic Gradient Descent Method for Non-Convex Objective Functions},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {136},
  pages   = {1-48},
}

@article{rangamani2019invariantarxiv,
  title={A scale invariant flatness measure for deep network minima},
  author={Rangamani, Akshay and Nguyen, Nam H and Kumar, Abhishek and Phan, Dzung and Chin, Sang H and Tran, Trac D},
  journal={arXiv preprint arXiv:1902.02434},
  year={2019}
}

@INPROCEEDINGS{rangamani2021invariant,
  author={Rangamani, Akshay and Nguyen, Nam H. and Kumar, Abhishek and Phan, Dzung and Chin, Sang Peter and Tran, Trac D.},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={A Scale Invariant Measure of Flatness for Deep Network Minima}, 
  year={2021},
  volume={},
  number={},
  pages={1680-1684}
}


@InProceedings{tsuzuku20normalized,
  title = 	 {Normalized Flat Minima: Exploring Scale Invariant Definition of Flat Minima for Neural Networks Using {PAC}-{B}ayesian Analysis},
  author =       {Tsuzuku, Yusuke and Sato, Issei and Sugiyama, Masashi},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {9636--9647},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
}

@article{he2019asymmetric,
  title={Asymmetric valleys: Beyond sharp and flat local minima},
  author={He, Haowei and Huang, Gao and Yuan, Yang},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{
gilmer2022curvature,
title={A Loss Curvature Perspective on Training Instabilities of Deep Learning Models},
author={Justin Gilmer and Behrooz Ghorbani and Ankush Garg and Sneha Kudugunta and Behnam Neyshabur and David Cardoze and George Edward Dahl and Zachary Nado and Orhan Firat},
booktitle={International Conference on Learning Representations},
year={2022},
}

@inproceedings{karakida2019normalization,
 author = {Karakida, Ryo and Akaho, Shotaro and Amari, Shun-ichi},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {The Normalization Method for Alleviating Pathological Sharpness in Wide Neural Networks},
 volume = {32},
 year = {2019}
}


@inproceedings{
li2022what,
title={What Happens after {SGD} Reaches Zero Loss? --A Mathematical Framework},
author={Zhiyuan Li and Tianhao Wang and Sanjeev Arora},
booktitle={International Conference on Learning Representations},
year={2022},
}

@article{van2017l2,
  title={L2 regularization versus batch and weight normalization},
  author={{van} Laarhoven, Twan},
  journal={arXiv preprint arXiv:1706.05350},
  year={2017}
}

@inproceedings{hoffer2018norm,
 author = {Hoffer, Elad and Banner, Ron and Golan, Itay and Soudry, Daniel},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Norm matters: efficient and accurate normalization schemes in deep networks},
 volume = {31},
 year = {2018}
}

@inproceedings{yi2019bninvariant,
  title     = {BN-invariant Sharpness Regularizes the Training Model to Better Generalization},
  author    = {Yi, Mingyang and Zhang, Huishuai and Chen, Wei and Ma, Zhi-Ming and Liu, Tie-Yan},
  booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on
               Artificial Intelligence, {IJCAI-19}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  pages     = {4164--4170},
  year      = {2019},
  month     = {7},
}

@article{ma2021riemannian,
	title = {A {Riemannian} mean field formulation for two-layer neural networks with batch normalization},
	volume = {9},
	issn = {2197-9847},
	abstract = {The training dynamics of two-layer neural networks with batch normalization (BN) is studied. It is written as the training dynamics of a neural network without BN on a Riemannian manifold. Therefore, we identify BN’s effect of changing the metric in the parameter space. Later, the infinite-width limit of the two-layer neural networks with BN is considered, and a mean-field formulation is derived for the training dynamics. The training dynamics of the mean-field formulation is shown to be the Wasserstein gradient flow on the manifold. Theoretical analysis is provided on the well-posedness and convergence of the Wasserstein gradient flow.},
	language = {en},
	number = {3},
	urldate = {2022-10-10},
	journal = {Research in the Mathematical Sciences},
	author = {Ma, Chao and Ying, Lexing},
	month = jul,
	year = {2022},
	keywords = {Batch normalization, Mean field formulation, Neural networks, Riemannian manifold},
	pages = {47},
}


@article{yi2021towards,
  title={Towards Accelerating Training of Batch Normalization: A Manifold Perspective},
  author={Yi, Mingyang and Meng, Qi and Chen, Wei and Ma, Zhi-Ming},
  journal={arXiv preprint arXiv:2101.02916},
  year={2021}
}


@article{ramachandran2017swish,
  title={Searching for activation functions},
  author={Ramachandran, Prajit and Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.05941},
  year={2017}
}

@inproceedings{karimi2016pl,
author = {Karimi, Hamed and Nutini, Julie and Schmidt, Mark},
title = {Linear Convergence of Gradient and Proximal-Gradient Methods Under the Polyak-\L{}Ojasiewicz Condition},
year = {2016},
isbn = {9783319461274},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
doi = {10.1007/978-3-319-46128-1_50},
abstract = {In 1963, Polyak proposed a simple condition that is sufficient to show a global linear convergence rate for gradient descent. This condition is a special case of the \L{}ojasiewicz inequality proposed in the same year, and it does not require strong convexity or even convexity. In this work, we show that this much-older Polyak-\L{}ojasiewicz PL inequality is actually weaker than the main conditions that have been explored to show linear convergence rates without strong convexity over the last 25 years. We also use the PL inequality to give new analyses of coordinate descent and stochastic gradient for many non-strongly-convex and some non-convex functions. We further propose a generalization that applies to proximal-gradient methods for non-smooth optimization, leading to simple proofs of linear convergence for support vector machines and L1-regularized least squares without additional assumptions.},
booktitle = {European Conference on Machine Learning and Knowledge Discovery in Databases - Volume 9851},
pages = {795-811},
numpages = {17},
keywords = {Gradient descent, Support vector machines, Boosting, Coordinate descent, L1-regularization, Variance-reduction, Stochastic gradient},
location = {Riva del Garda, Italy},
series = {ECML PKDD 2016}
}

@article{li2018visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}



@incollection{mcallester2003simplified,
  title={Simplified {PAC}-{B}ayesian margin bounds},
  author={McAllester, David},
  booktitle={Learning theory and Kernel machines},
  pages={203--215},
  year={2003},
  publisher={Springer}
}

@InProceedings{arora2022understanding,
  title = 	 {Understanding Gradient Descent on the Edge of Stability in Deep Learning},
  author =       {Arora, Sanjeev and Li, Zhiyuan and Panigrahi, Abhishek},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {948--1024},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
}


@article{raskutti2012minimax,
  title={Minimax-Optimal Rates For Sparse Additive Models Over Kernel Classes Via Convex Programming.},
  author={Raskutti, Garvesh and J Wainwright, Martin and Yu, Bin},
  journal={Journal of machine learning research},
  volume={13},
  number={2},
  year={2012}
}
@inproceedings{arora2018optimization,
  title={On the optimization of deep networks: Implicit acceleration by overparameterization},
  author={Arora, Sanjeev and Cohen, Nadav and Hazan, Elad},
  booktitle={International Conference on Machine Learning},
  pages={244--253},
  year={2018},
  organization={PMLR}
}


@article{vaskevicius2019implicit,
  title={Implicit regularization for optimal sparse recovery},
  author={Vaskevicius, Tomas and Kanade, Varun and Rebeschini, Patrick},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={2972--2983},
  year={2019}
}

@article{zhao2019implicit,
  title={Implicit regularization via Hadamard product over-parametrization in high-dimensional linear regression},
  author={Zhao, Peng and Yang, Yun and He, Qiao-Chu},
  journal={arXiv preprint arXiv:1903.09367},
  year={2019}
}

@inproceedings{li2018learning,
 author = {Li, Yuanzhi and Liang, Yingyu},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data},
 volume = {31},
 year = {2018}
}



@article{du2018gradient,
  title={Gradient descent provably optimizes over-parameterized neural networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  journal={arXiv preprint arXiv:1810.02054},
  year={2018}
}

@article{daniely2017sgd,
  title={SGD learns the conjugate kernel class of the network},
  author={Daniely, Amit},
  journal={arXiv preprint arXiv:1702.08503},
  year={2017}
}

@article{yang2019scaling,
  title={Scaling limits of wide neural networks with weight sharing: Gaussian process behavior, gradient independence, and neural tangent kernel derivation},
  author={Yang, Greg},
  journal={arXiv preprint arXiv:1902.04760},
  year={2019}
}

@inproceedings{arora2019fine,
  title={Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
  author={Arora, Sanjeev and Du, Simon and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={322--332},
  year={2019},
  organization={PMLR}
}
@article{chizat2018lazy,
  title={On lazy training in differentiable programming},
  author={Chizat, Lenaic and Oyallon, Edouard and Bach, Francis},
  journal={arXiv preprint arXiv:1812.07956},
  year={2018}
}

@inproceedings{du2019gradient,
  title={Gradient descent finds global minima of deep neural networks},
  author={Du, Simon and Lee, Jason and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
  booktitle={International Conference on Machine Learning},
  pages={1675--1685},
  year={2019},
  organization={PMLR}
}

@inproceedings{yang2021tensor,
  title={Tensor programs iv: Feature learning in infinite-width neural networks},
  author={Yang, Greg and Hu, Edward J},
  booktitle={International Conference on Machine Learning},
  pages={11727--11737},
  year={2021},
  organization={PMLR}
}

@article{lyu2021gradient,
  title={Gradient Descent on Two-layer Nets: Margin Maximization and Simplicity Bias},
  author={Lyu, Kaifeng and Li, Zhiyuan and Wang, Runzhe and Arora, Sanjeev},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


@inproceedings{razin2022implicit,
  title = 	 {Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks},
  author =       {Razin, Noam and Maman, Asaf and Cohen, Nadav},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {18422--18462},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
}

@article{jacot2021deep,
  title={Deep linear networks dynamics: Low-rank biases induced by initialization scale and l2 regularization},
  author={Jacot, Arthur and Ged, Fran{\c{c}}ois and Gabriel, Franck and {\c{S}}im{\c{s}}ek, Berfin and Hongler, Cl{\'e}ment},
  journal={arXiv preprint arXiv:2106.15933},
  year={2021}
}

@article{stoger2021small,
  title={Small random initialization is akin to spectral learning: Optimization and generalization guarantees for overparameterized low-rank matrix reconstruction},
  author={St{\"o}ger, Dominik and Soltanolkotabi, Mahdi},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{ge2021understanding,
  title={Understanding Deflation Process in Over-parametrized Tensor Decomposition},
  author={Ge, Rong and Ren, Yunwei and Wang, Xiang and Zhou, Mo},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


@article{gunasekar2018implicitconv,
  title={Implicit bias of gradient descent on linear convolutional networks},
  author={Gunasekar, Suriya and Lee, Jason D and Soudry, Daniel and Srebro, Nati},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{chizat2020implicit,
  title={Implicit bias of gradient descent for wide two-layer neural networks trained with the logistic loss},
  author={Chizat, Lenaic and Bach, Francis},
  booktitle={Conference on Learning Theory},
  pages={1305--1338},
  year={2020},
  organization={PMLR}
}


@article{laurent2000adaptive,
  title={Adaptive estimation of a quadratic functional by model selection},
  author={Laurent, Beatrice and Massart, Pascal},
  journal={Annals of Statistics},
  pages={1302--1338},
  year={2000},
  publisher={JSTOR}
}

@article{foote1984distance,
 ISSN = {00029939, 10886826},
 author = {Robert L. Foote},
 journal = {Proceedings of the American Mathematical Society},
 number = {1},
 pages = {153--155},
 publisher = {American Mathematical Society},
 title = {Shorter Notes: Regularity of the Distance Function},
 urldate = {2022-05-28},
 volume = {92},
 year = {1984}
}

@article{falconer1983differentiation,
    author = {Falconer, K. J.},
    title = "{Differentiation of the Limit Mapping in a Dynamical System}",
    journal = {Journal of the London Mathematical Society},
    volume = {s2-27},
    number = {2},
    pages = {356-372},
    year = {1983},
    month = {04},
    issn = {0024-6107},
    doi = {10.1112/jlms/s2-27.2.356},
}

@techreport{krizhevsky09cifar,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
	institution= {},
    year = {2009}
}

@inproceedings{hoffer2017trainlonger,
 author = {Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
 volume = {30},
 year = {2017}
}


@article{ma2022multiscale,
author = {Ma , Chao and Kunin , Daniel and Wu , Lei and Ying , Lexing},
title = {Beyond the Quadratic Approximation: The Multiscale Structure of Neural Network Loss Landscapes},
journal = {Journal of Machine Learning},
year = {2022},
volume = {1},
number = {3},
pages = {247--267},
issn = {2790-2048},
}


@inproceedings{mulayoff2021minimastability,
 author = {Mulayoff, Rotem and Michaeli, Tomer and Soudry, Daniel},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {17749--17761},
 publisher = {Curran Associates, Inc.},
 title = {The Implicit Bias of Minima Stability: A View from Function Space},
 volume = {34},
 year = {2021}
}

@article{ding2022flat,
  title={Flat minima generalize for low-rank matrix recovery},
  author={Ding, Lijun and Drusvyatskiy, Dmitriy and Fazel, Maryam},
  journal={arXiv preprint arXiv:2203.03756},
  year={2022}
}


@InProceedings{mulayoff2020unique,
  title = 	 {Unique Properties of Flat Minima in Deep Networks},
  author =       {Mulayoff, Rotem and Michaeli, Tomer},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {7108--7118},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
}


@InProceedings{haochen2021shape,
  title = 	 {Shape Matters: Understanding the Implicit Bias of the Noise Covariance},
  author =       {HaoChen, Jeff Z. and Wei, Colin and Lee, Jason and Ma, Tengyu},
  booktitle = 	 {Proceedings of Thirty Fourth Conference on Learning Theory},
  pages = 	 {2315--2357},
  year = 	 {2021},
  editor = 	 {Belkin, Mikhail and Kpotufe, Samory},
  volume = 	 {134},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {15--19 Aug},
  publisher =    {PMLR},
}

@article{chi2019nonconvex,
	author={Chi, Yuejie and Lu, Yue M. and Chen, Yuxin},
	journal={IEEE Transactions on Signal Processing},
	title={Nonconvex Optimization Meets Low-Rank Matrix Factorization: An Overview},
	year={2019},
	volume={67},
	number={20},
	pages={5239-5269},
	doi={10.1109/TSP.2019.2937282}
}

@inproceedings{
jastrzebski2020breakeven,
title={The Break-Even Point on Optimization Trajectories of Deep Neural Networks},
author={Stanislaw Jastrzebski and Maciej Szymczak and Stanislav Fort and Devansh Arpit and Jacek Tabor and Kyunghyun Cho and Krzysztof Geras},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{
gilmer2022losscurvature,
title={A Loss Curvature Perspective on Training Instabilities of Deep Learning Models},
author={Justin Gilmer and Behrooz Ghorbani and Ankush Garg and Sneha Kudugunta and Behnam Neyshabur and David Cardoze and George Edward Dahl and Zachary Nado and Orhan Firat},
booktitle={International Conference on Learning Representations},
year={2022},
}

@inproceedings{
wu2018howsgd,
author = {Wu, Lei and Ma, Chao and E, Weinan},
booktitle = {Advances in Neural Information Processing Systems},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {},
publisher = {Curran Associates, Inc.},
title = {How SGD Selects the Global Minima in Over-parameterized Learning: A Dynamical Stability Perspective},
volume = {31},
year = {2018}
}


@article{lewkowycz2020large,
  title={The large learning rate phase of deep learning: the catapult mechanism},
  author={Lewkowycz, Aitor and Bahri, Yasaman and Dyer, Ethan and Sohl-Dickstein, Jascha and Gur-Ari, Guy},
  journal={arXiv preprint arXiv:2003.02218},
  year={2020}
}

@article{hendrycks2016gelu,
  title={Gaussian error linear units ({GELU}s)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@inproceedings{
wang2022large,
title={Large Learning Rate Tames Homogeneity: Convergence and Balancing Effect},
author={Yuqing Wang and Minshuo Chen and Tuo Zhao and Molei Tao},
booktitle={International Conference on Learning Representations},
year={2022},
}

@inproceedings{kong2020multiscale,
 author = {Kong, Lingkai and Tao, Molei},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {2625--2638},
 publisher = {Curran Associates, Inc.},
 title = {Stochasticity of Deterministic Gradient Descent: Large Learning Rate for Multiscale Objective Function},
 volume = {33},
 year = {2020}
}

@inproceedings{tanaka2021noether,
 author = {Tanaka, Hidenori and Kunin, Daniel},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {25646--25660},
 publisher = {Curran Associates, Inc.},
 title = {Noether’s Learning Dynamics: Role of Symmetry Breaking in Neural Networks},
 volume = {34},
 year = {2021}
}

@article{qiao2019micro,
  title={Micro-batch training with batch-channel normalization and weight standardization},
  author={Qiao, Siyuan and Wang, Huiyu and Liu, Chenxi and Shen, Wei and Yuille, Alan},
  journal={arXiv preprint arXiv:1903.10520},
  year={2019}
}

@InProceedings{huang2017centered,
author = {Huang, Lei and Liu, Xianglong and Liu, Yang and Lang, Bo and Tao, Dacheng},
title = {Centered Weight Normalization in Accelerating Training of Deep Neural Networks},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {Oct},
year = {2017}
}

@inproceedings{
brock2021characterizing,
title={Characterizing signal propagation to close the performance gap in unnormalized ResNets},
author={Andrew Brock and Soham De and Samuel L Smith},
booktitle={International Conference on Learning Representations},
year={2021},
}


@InProceedings{shen2020powernorm,
  title = 	 {{P}ower{N}orm: Rethinking Batch Normalization in Transformers},
  author =       {Shen, Sheng and Yao, Zhewei and Gholami, Amir and Mahoney, Michael and Keutzer, Kurt},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {8741--8751},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
}

@inproceedings{devlin2019bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
}

@inproceedings{brown2020gpt3,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 volume = {33},
 year = {2020}
}

@inproceedings{lewkowycz2020training,
 author = {Lewkowycz, Aitor and Gur-Ari, Guy},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {4790--4799},
 publisher = {Curran Associates, Inc.},
 title = {On the training dynamics of deep networks with {L}\_2 regularization},
 volume = {33},
 year = {2020}
}

@inproceedings{liu2020bad,
 author = {Liu, Shengchao and Papailiopoulos, Dimitris and Achlioptas, Dimitris},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {8543--8552},
 publisher = {Curran Associates, Inc.},
 title = {Bad Global Minima Exist and SGD Can Reach Them},
 volume = {33},
 year = {2020}
}

@inproceedings{chiley2019online,
 author = {Chiley, Vitaliy and Sharapov, Ilya and Kosson, Atli and Koster, Urs and Reece, Ryan and Samaniego de la Fuente, Sofia and Subbiah, Vishal and James, Michael},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Online Normalization for Training Neural Networks},
 volume = {32},
 year = {2019}
}

@InProceedings{wang2022three,
  title = 	 {Three-stage Evolution and Fast Equilibrium for {SGD} with Non-degerate Critical Points},
  author =       {Wang, Yi and Wang, Zhiren},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {23092--23113},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
}

@inproceedings{wan2021spherical,
 author = {Wan, Ruosi and Zhu, Zhanxing and Zhang, Xiangyu and Sun, Jian},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {6380--6391},
 publisher = {Curran Associates, Inc.},
 title = {Spherical Motion Dynamics: Learning Dynamics of Normalized Neural Network using SGD and Weight Decay},
 volume = {34},
 year = {2021}
}



@InProceedings{dukler2020optimization,
  title = 	 {Optimization Theory for {R}e{LU} Neural Networks Trained with Normalization Layers},
  author =       {Dukler, Yonatan and Gu, Quanquan and Montufar, Guido},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {2751--2760},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
}

@inproceedings{labatie2021proxy,
 author = {Labatie, Antoine and Masters, Dominic and Eaton-Rosen, Zach and Luschi, Carlo},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {16990--17006},
 publisher = {Curran Associates, Inc.},
 title = {Proxy-Normalizing Activations to Match Batch Normalization while Removing Batch Dependence},
 volume = {34},
 year = {2021}
}


@InProceedings{chaudhuri2019investigation,
  title = 	 {An Investigation into Neural Net Optimization via Hessian Eigenvalue Density},
  author =       {Ghorbani, Behrooz and Krishnan, Shankar and Xiao, Ying},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2232--2241},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
}



@InProceedings{balduzzi2017shattered,
  title = 	 {The Shattered Gradients Problem: If resnets are the answer, then what is the question?},
  author =       {David Balduzzi and Marcus Frean and Lennox Leary and J. P. Lewis and Kurt Wan-Duo Ma and Brian McWilliams},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {342--350},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
}


@InProceedings{cai2019quantitative,
  title = 	 {A Quantitative Analysis of the Effect of Batch Normalization on Gradient Descent},
  author =       {Cai, Yongqiang and Li, Qianxiao and Shen, Zuowei},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {882--890},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
}

@inproceedings{wu2020implicit,
 author = {Wu, Xiaoxia and Dobriban, Edgar and Ren, Tongzheng and Wu, Shanshan and Li, Zhiyuan and Gunasekar, Suriya and Ward, Rachel and Liu, Qiang},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {2835--2847},
 publisher = {Curran Associates, Inc.},
 title = {Implicit Regularization and Convergence for Weight Normalization},
 volume = {33},
 year = {2020}
}


@InProceedings{teye2018bayesian,
  title = 	 {{B}ayesian Uncertainty Estimation for Batch Normalized Deep Networks},
  author =       {Teye, Mattias and Azizpour, Hossein and Smith, Kevin},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {4907--4916},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
}

@InProceedings{shekhovtsov2019stochastic,
author="Shekhovtsov, Alexander
and Flach, Boris",
editor="Jawahar, C. V.
and Li, Hongdong
and Mori, Greg
and Schindler, Konrad",
title="Stochastic Normalizations as Bayesian Learning",
booktitle="Computer Vision -- ACCV 2018",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="463--479",
isbn="978-3-030-20890-5"
}

@article{chen2022gradient,
  title={On Gradient Descent Convergence beyond the Edge of Stability},
  author={Chen, Lei and Bruna, Joan},
  journal={arXiv preprint arXiv:2206.04172},
  year={2022}
}

@inproceedings{cao2019generalization,
 author = {Cao, Yuan and Gu, Quanquan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Generalization Bounds of Stochastic Gradient Descent for Wide and Deep Neural Networks},
 volume = {32},
 year = {2019}
}

@inproceedings{
chen2021how,
title={How Much Over-parameterization Is Sufficient to Learn Deep {ReLU} Networks?},
author={Zixiang Chen and Yuan Cao and Difan Zou and Quanquan Gu},
booktitle={International Conference on Learning Representations},
year={2021},
}


@InProceedings{jin2023understanding,
  title = 	 {Understanding Incremental Learning of Gradient Descent: A Fine-grained Analysis of Matrix Sensing},
  author =       {Jin, Jikai and Li, Zhiyuan and Lyu, Kaifeng and Du, Simon Shaolei and Lee, Jason D.},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {15200--15238},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
}

@inproceedings{
zou2023understanding,
title={Understanding the Generalization of Adam in Learning Neural Networks with Proper Regularization},
author={Difan Zou and Yuan Cao and Yuanzhi Li and Quanquan Gu},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=iUYpN14qjTF}
}


@InProceedings{zhu2023decentralized,
  title = 	 {Decentralized {SGD} and Average-direction {SAM} are Asymptotically Equivalent},
  author =       {Zhu, Tongtian and He, Fengxiang and Chen, Kaixuan and Song, Mingli and Tao, Dacheng},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {43005--43036},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
}

@article{vyas2023onlinesgd,
  title={Beyond Implicit Bias: The Insignificance of SGD Noise in Online Learning},
  author={Vyas, Nikhil and Morwani, Depen and Zhao, Rosie and Kaplun, Gal and Kakade, Sham and Barak, Boaz},
  journal={arXiv preprint arXiv:2306.08590},
  year={2023}
}
@InProceedings{liu2023same,
  title = 	 {Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models},
  author =       {Liu, Hong and Xie, Sang Michael and Li, Zhiyuan and Ma, Tengyu},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {22188--22214},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR}
}

@article{cowsik2022flatter,
  title={Flatter, faster: scaling momentum for optimal speedup of SGD},
  author={Cowsik, Aditya and Can, Tankut and Glorioso, Paolo},
  journal={arXiv preprint arXiv:2210.16400},
  year={2022}
}

@article{wang2023marginal,
  title={The Marginal Value of Momentum for Small Learning Rate SGD},
  author={Wang, Runzhe and Malladi, Sadhika and Wang, Tianhao and Lyu, Kaifeng and Li, Zhiyuan},
  journal={arXiv preprint arXiv:2307.15196},
  year={2023}
}

@inproceedings{
damian2023selfstabilization,
title={Self-Stabilization: The Implicit Bias of Gradient Descent at the Edge of Stability},
author={Alex Damian and Eshaan Nichani and Jason D. Lee},
booktitle={The Eleventh International Conference on Learning Representations},
year={2023}
}

@inproceedings{
qi2024finetuning,
title={Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!},
author={Xiangyu Qi and Yi Zeng and Tinghao Xie and Pin-Yu Chen and Ruoxi Jia and Prateek Mittal and Peter Henderson},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=hTEGyKf0dZ}
}

@article{zhao2023learningandforgetting,
  title={Learning and Forgetting Unsafe Examples in Large Language Models},
  author={Zhao, Jiachen and Deng, Zhun and Madras, David and Zou, James and Ren, Mengye},
  journal={arXiv preprint arXiv:2312.12736},
  year={2023}
}


@article{li2023chatdoctor,
  title={ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge},
  author={Li, Yunxiang and Li, Zihan and Zhang, Kai and Dan, Ruilong and Jiang, Steve and Zhang, You},
  journal={Cureus},
  volume={15},
  number={6},
  year={2023},
  publisher={Cureus}
}
@InProceedings{Zhu_2015_ICCVbookcorpus,
    title = {Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books},
    author = {Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
    booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
    month = {December},
    year = {2015}
}

@article{zhan2023removing,
  title={Removing {RLHF} protections in {GPT-4} via fine-tuning},
  author={Zhan, Qiusi and Fang, Richard and Bindu, Rohan and Gupta, Akul and Hashimoto, Tatsunori and Kang, Daniel},
  journal={arXiv preprint arXiv:2311.05553},
  year={2023}
}

@article{chen2023janus,
  title={The Janus Interface: How Fine-Tuning in Large Language Models Amplifies the Privacy Risks},
  author={Chen, Xiaoyi and Tang, Siyuan and Zhu, Rui and Yan, Shijun and Jin, Lei and Wang, Zihao and Su, Liya and Wang, XiaoFeng and Tang, Haixu},
  journal={arXiv preprint arXiv:2310.15469},
  year={2023}
}

@article{lermen2023lora,
  title={{LoRA} Fine-tuning Efficiently Undoes Safety Training in Llama 2-Chat 70B},
  author={Lermen, Simon and Rogers-Smith, Charlie and Ladish, Jeffrey},
  journal={arXiv preprint arXiv:2310.20624},
  year={2023}
}

@article{yang2023shadow,
  title={Shadow alignment: The ease of subverting safely-aligned language models},
  author={Yang, Xianjun and Wang, Xiao and Zhang, Qi and Petzold, Linda and Wang, William Yang and Zhao, Xun and Lin, Dahua},
  journal={arXiv preprint arXiv:2310.02949},
  year={2023}
}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

@article{liu2023autodan,
  title={{AutoDAN}: Generating stealthy jailbreak prompts on aligned large language models},
  author={Liu, Xiaogeng and Xu, Nan and Chen, Muhao and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2310.04451},
  year={2023}
}

@misc{walkerspider2022dan,
  title        = {{DAN} is my new friend},
  author       = {{walkerspider}},
  year         = 2022,
  howpublished = {Reddit Post},
  url= "https://old.reddit.com/r/ChatGPT/comments/zlcyr9/dan_is_my_new_friend/",
  note         = {Accessed: 2023-09-28}
}

@article{zhang2023defending,
  title={Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization},
  author={Zhang, Zhexin and Yang, Junxiao and Ke, Pei and Huang, Minlie},
  journal={arXiv preprint arXiv:2311.09096},
  year={2023}
}

@article{hu2023token,
  title={Token-Level Adversarial Prompt Detection Based on Perplexity Measures and Contextual Information},
  author={Hu, Zhengmian and Wu, Gang and Mitra, Saayan and Zhang, Ruiyi and Sun, Tong and Huang, Heng and Swaminathan, Vishy},
  journal={arXiv preprint arXiv:2311.11509},
  year={2023}
}

@article{robey2023smoothllm,
  title={{SmoothLLM}: Defending large language models against jailbreaking attacks},
  author={Robey, Alexander and Wong, Eric and Hassani, Hamed and Pappas, George J},
  journal={arXiv preprint arXiv:2310.03684},
  year={2023}
}

@article{zhang2023mutation,
  title={A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection},
  author={Zhang, Xiaoyu and Zhang, Cen and Li, Tianlin and Huang, Yihao and Jia, Xiaojun and Xie, Xiaofei and Liu, Yang and Shen, Chao},
  journal={arXiv preprint arXiv:2312.10766},
  year={2023}
}

@article{zhang2023transfer,
  title={Transfer Attacks and Defenses for Large Language Models on Coding Tasks},
  author={Zhang, Chi and Wang, Zifan and Mangal, Ravi and Fredrikson, Matt and Jia, Limin and Pasareanu, Corina},
  journal={arXiv preprint arXiv:2311.13445},
  year={2023}
}

@article{chao2023jailbreaking,
  title={Jailbreaking black box large language models in twenty queries},
  author={Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric},
  journal={arXiv preprint arXiv:2310.08419},
  year={2023}
}

@article{qiang2023hijacking,
  title={Hijacking Large Language Models via Adversarial In-Context Learning},
  author={Qiang, Yao and Zhou, Xiangyu and Zhu, Dongxiao},
  journal={arXiv preprint arXiv:2311.09948},
  year={2023}
}

@article{zhu2023autodan,
  title={{AutoDAN}: Automatic and Interpretable Adversarial Attacks on Large Language Models},
  author={Zhu, Sicheng and Zhang, Ruiyi and An, Bang and Wu, Gang and Barrow, Joe and Wang, Zichao and Huang, Furong and Nenkova, Ani and Sun, Tong},
  journal={arXiv preprint arXiv:2310.15140},
  year={2023}
}

@article{ge2023mart,
  title={{MART}: Improving {LLM} Safety with Multi-round Automatic Red-Teaming},
  author={Ge, Suyu and Zhou, Chunting and Hou, Rui and Khabsa, Madian and Wang, Yi-Chia and Wang, Qifan and Han, Jiawei and Mao, Yuning},
  journal={arXiv preprint arXiv:2311.07689},
  year={2023}
}

@article{schwinn2023adversarial,
  title={Adversarial attacks and defenses in large language models: Old and new threats},
  author={Schwinn, Leo and Dobre, David and G{\"u}nnemann, Stephan and Gidel, Gauthier},
  journal={arXiv preprint arXiv:2310.19737},
  year={2023}
}

@article{li2023deepinception,
  title={DeepInception: Hypnotize Large Language Model to Be Jailbreaker},
  author={Li, Xuan and Zhou, Zhanke and Zhu, Jianing and Yao, Jiangchao and Liu, Tongliang and Han, Bo},
  journal={arXiv preprint arXiv:2311.03191},
  year={2023}
}

@article{mehrotra2023tree,
  title={Tree of Attacks: Jailbreaking Black-Box {LLMs} Automatically},
  author={Mehrotra, Anay and Zampetakis, Manolis and Kassianik, Paul and Nelson, Blaine and Anderson, Hyrum and Singer, Yaron and Karbasi, Amin},
  journal={arXiv preprint arXiv:2312.02119},
  year={2023}
}

@article{shah2023scalable,
  title={Scalable and Transferable Black-Box Jailbreaks for Language Models via Persona Modulation},
  author={Shah, Rusheb and Pour, Soroush and Tagade, Arush and Casper, Stephen and Rando, Javier and others},
  journal={arXiv preprint arXiv:2311.03348},
  year={2023}
}

@article{jain2023baseline,
  title={Baseline defenses for adversarial attacks against aligned language models},
  author={Jain, Neel and Schwarzschild, Avi and Wen, Yuxin and Somepalli, Gowthami and Kirchenbauer, John and Chiang, Ping-yeh and Goldblum, Micah and Saha, Aniruddha and Geiping, Jonas and Goldstein, Tom},
  journal={arXiv preprint arXiv:2309.00614},
  year={2023}
}

@article{jones2023automatically,
  title={Automatically Auditing Large Language Models via Discrete Optimization},
  author={Jones, Erik and Dragan, Anca and Raghunathan, Aditi and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2303.04381},
  year={2023}
}

@article{liu2023prompt,
  title={Prompt Injection attack against {LLM}-integrated Applications},
  author={Liu, Yi and Deng, Gelei and Li, Yuekang and Wang, Kailong and Zhang, Tianwei and Liu, Yepang and Wang, Haoyu and Zheng, Yan and Liu, Yang},
  journal={arXiv preprint arXiv:2306.05499},
  year={2023}
}

@article{liu2023jailbreaking,
  title={Jailbreaking {ChatGPT} via prompt engineering: An empirical study},
  author={Liu, Yi and Deng, Gelei and Xu, Zhengzi and Li, Yuekang and Zheng, Yaowen and Zhang, Ying and Zhao, Lida and Zhang, Tianwei and Liu, Yang},
  journal={arXiv preprint arXiv:2305.13860},
  year={2023}
}

@article{yu2023gptfuzzer,
  title={{GPTFUZZER}: Red teaming large language models with auto-generated jailbreak prompts},
  author={Yu, Jiahao and Lin, Xingwei and Xing, Xinyu},
  journal={arXiv preprint arXiv:2309.10253},
  year={2023}
}

@article{xie2023defending,
  title={Defending {ChatGPT} against jailbreak attack via self-reminders},
  author={Xie, Yueqi and Yi, Jingwei and Shao, Jiawei and Curl, Justin and Lyu, Lingjuan and Chen, Qifeng and Xie, Xing and Wu, Fangzhao},
  journal={Nature Machine Intelligence},
  pages={1--11},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{cao2023defending,
  title={Defending against alignment-breaking attacks via robustly aligned {LLM}},
  author={Cao, Bochuan and Cao, Yuanpu and Lin, Lu and Chen, Jinghui},
  journal={arXiv preprint arXiv:2309.14348},
  year={2023}
}

@article{xu2023cognitive,
  title={Cognitive Overload: Jailbreaking Large Language Models with Overloaded Logical Thinking},
  author={Xu, Nan and Wang, Fei and Zhou, Ben and Li, Bang Zheng and Xiao, Chaowei and Chen, Muhao},
  journal={arXiv preprint arXiv:2311.09827},
  year={2023}
}

@article{ding2023wolf,
  title={A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily},
  author={Ding, Peng and Kuang, Jun and Ma, Dan and Cao, Xuezhi and Xian, Yunsen and Chen, Jiajun and Huang, Shujian},
  journal={arXiv preprint arXiv:2311.08268},
  year={2023}
}

@article{li2023rain,
  title={{RAIN}: Your language models can align themselves without finetuning},
  author={Li, Yuhui and Wei, Fangyun and Zhao, Jinjing and Zhang, Chao and Zhang, Hongyang},
  journal={arXiv preprint arXiv:2309.07124},
  year={2023}
}

@article{helbling2023llm,
  title={{LLM} self defense: By self examination, llms know they are being tricked},
  author={Helbling, Alec and Phute, Mansi and Hull, Matthew and Chau, Duen Horng},
  journal={arXiv preprint arXiv:2308.07308},
  year={2023}
}

@inproceedings{yong2023low,
  title={Low-Resource Languages Jailbreak GPT-4},
  author={Yong, Zheng Xin and Menghini, Cristina and Bach, Stephen},
  booktitle={Socially Responsible Language Modelling Research},
  year={2023}
}

@article{toyer2023tensor,
  title={Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game},
  author={Toyer, Sam and Watkins, Olivia and Mendes, Ethan Adrian and Svegliato, Justin and Bailey, Luke and Wang, Tiffany and Ong, Isaac and Elmaaroufi, Karim and Abbeel, Pieter and Darrell, Trevor and others},
  journal={arXiv preprint arXiv:2311.01011},
  year={2023}
}

@inproceedings{huang2023catastrophic,
  title={Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation},
  author={Huang, Yangsibo and Gupta, Samyak and Xia, Mengzhou and Li, Kai and Chen, Danqi},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{wei2023jailbroken,
  title={Jailbroken: How Does {LLM} Safety Training Fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}

@article{inan2023llamaguard,
  title={Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations},
  author={Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others},
  journal={arXiv preprint arXiv:2312.06674},
  year={2023}
}

@inproceedings{scialom2022fine,
    title = "Fine-tuned Language Models are Continual Learners",
    author = "Scialom, Thomas  and
      Chakrabarty, Tuhin  and
      Muresan, Smaranda",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.410",
    doi = "10.18653/v1/2022.emnlp-main.410",
    pages = "6107--6122"
}

@article{zheng2023learn,
  title={Learn or Recall? Revisiting Incremental Learning with Pre-trained Language Models},
  author={Zheng, Junhao and Qiu, Shengjie and Ma, Qianli},
  journal={arXiv preprint arXiv:2312.07887},
  year={2023}
}

@article{luo2023empirical,
  title={An empirical study of catastrophic forgetting in large language models during continual fine-tuning},
  author={Luo, Yun and Yang, Zhen and Meng, Fandong and Li, Yafu and Zhou, Jie and Zhang, Yue},
  journal={arXiv preprint arXiv:2308.08747},
  year={2023}
}

@article{lin2023speciality,
  title={Speciality vs generality: An empirical study on catastrophic forgetting in fine-tuning foundation models},
  author={Lin, Yong and Tan, Lu and Lin, Hangyu and Zheng, Zeming and Pi, Renjie and Zhang, Jipeng and Diao, Shizhe and Wang, Haoxiang and Zhao, Han and Yao, Yuan and others},
  journal={arXiv preprint arXiv:2309.06256},
  year={2023}
}

@article{wang2023trace,
  title={{TRACE}: A Comprehensive Benchmark for Continual Learning in Large Language Models},
  author={Wang, Xiao and Zhang, Yuansen and Chen, Tianze and Gao, Songyang and Jin, Senjie and Yang, Xianjun and Xi, Zhiheng and Zheng, Rui and Zou, Yicheng and Gui, Tao and others},
  journal={arXiv preprint arXiv:2310.06762},
  year={2023}
}

@article{xiao2023lm,
  title={{LM-Cocktail}: Resilient Tuning of Language Models via Model Merging},
  author={Xiao, Shitao and Liu, Zheng and Zhang, Peitian and Xing, Xingrun},
  journal={arXiv preprint arXiv:2311.13534},
  year={2023}
}

@article{luo2023investigating,
  title={Investigating Forgetting in Pre-Trained Representations Through Continual Learning},
  author={Luo, Yun and Yang, Zhen and Bai, Xuefeng and Meng, Fandong and Zhou, Jie and Zhang, Yue},
  journal={arXiv preprint arXiv:2305.05968},
  year={2023}
}

@article{wang2023orthogonal,
  title={Orthogonal Subspace Learning for Language Model Continual Learning},
  author={Wang, Xiao and Chen, Tianze and Ge, Qiming and Xia, Han and Bao, Rong and Zheng, Rui and Zhang, Qi and Gui, Tao and Huang, Xuanjing},
  journal={arXiv preprint arXiv:2310.14152},
  year={2023}
}

@article{zeng2024johnny,
  title={How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs},
  author={Zeng, Yi and Lin, Hongpeng and Zhang, Jingwen and Yang, Diyi and Jia, Ruoxi and Shi, Weiyan},
  journal={arXiv preprint arXiv:2401.06373},
  year={2024}
}

@misc{wizard-vicuna-30b-uncensored,
  title = {Wizard Vicuna 30B Uncensored},
  author = {Eric Hartford},
  howpublished = {\url{https://huggingface.co/cognitivecomputations/Wizard-Vicuna-30B-Uncensored}},
  year = {2023}
}

@misc{llama-2-chat-hf,
  title = {Llama-2-7b-chat-hf },
  author = {{Meta GenAI}},
  howpublished = {\url{https://huggingface.co/meta-llama/Llama-2-7b-chat-hf}},
  year = {2023}
}
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}
@misc{mistral-hf,
  title = {Mistral-7B-Instruct-v0.2},
  author = {{Mistral AI}},
  howpublished = {\url{https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2}},
  year = {2023}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@misc{peng2023gpt,
  title = {{GPT-3.5 Turbo fine-tuning and API updates}},
  author={Andrew Peng and Michael Wu and John Allard and Logan Kilpatrick and Steven Heidel},
  howpublished = {\url{https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates}},
  year={2023}
}

@article{allenai:arc,
      author    = {Peter Clark  and Isaac Cowhey and Oren Etzioni and Tushar Khot and
                    Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},
      title     = {Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge},
      journal   = {arXiv:1803.05457v1},
      year      = {2018},
}

@article{ganguli2022red,
  title={Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned},
  author={Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
  journal={arXiv preprint arXiv:2209.07858},
  year={2022}
}

@article{cobbe2021gsm8k,
  title={Training Verifiers to Solve Math Word Problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@software{eval-harness,
  author       = {Gao, Leo and
                  Tow, Jonathan and
                  Biderman, Stella and
                  Black, Sid and
                  DiPofi, Anthony and
                  Foster, Charles and
                  Golding, Laurence and
                  Hsu, Jeffrey and
                  McDonell, Kyle and
                  Muennighoff, Niklas and
                  Phang, Jason and
                  Reynolds, Laria and
                  Tang, Eric and
                  Thite, Anish and
                  Wang, Ben and
                  Wang, Kevin and
                  Zou, Andy},
  title        = {A framework for few-shot language model evaluation},
  month        = sep,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {v0.0.1},
  doi          = {10.5281/zenodo.5371628},
  url          = {https://doi.org/10.5281/zenodo.5371628}
}
@article{70blora,
  title={LoRA Fine-tuning Efficiently Undoes Safety Training in Llama 2-Chat 70B},
  author={Lermen, Simon and Rogers-Smith, Charlie and Ladish, Jeffrey},
  journal={arXiv preprint arXiv:2310.20624},
  year={2023}
}
@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@online{DatabricksBlog2023DollyV2,
    author    = {Mike Conover and Matt Hayes and Ankit Mathur and Jianwei Xie and Jun Wan and Sam Shah and Ali Ghodsi and Patrick Wendell and Matei Zaharia and Reynold Xin},
    title     = {Free Dolly: Introducing the World's First Truly Open Instruction-Tuned LLM},
    year      = {2023},
    url       = {https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm},
    urldate   = {2023-06-30}
}

@misc{alpaca_eval,
  author = {Xuechen Li and Tianyi Zhang and Yann Dubois and Rohan Taori and Ishaan Gulrajani and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {{AlpacaEval}: An Automatic Evaluator of Instruction-following Models},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/alpaca_eval}}
}

@misc{OpenOrca,
  title = {OpenOrca: An Open Dataset of GPT Augmented FLAN Reasoning Traces},
  author = {Wing Lian and Bleys Goodson and Eugene Pentland and Austin Cook and Chanvichet Vong and "Teknium"},
  year = {2023},
  publisher = {HuggingFace},
  journal = {HuggingFace repository},
  howpublished = {\url{https://https://huggingface.co/Open-Orca/OpenOrca}},
}

@misc{mukherjee2023orca,
      title={Orca: Progressive Learning from Complex Explanation Traces of GPT-4}, 
      author={Subhabrata Mukherjee and Arindam Mitra and Ganesh Jawahar and Sahaj Agarwal and Hamid Palangi and Ahmed Awadallah},
      year={2023},
      eprint={2306.02707},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{longpre2023flan,
      title={The Flan Collection: Designing Data and Methods for Effective Instruction Tuning}, 
      author={Shayne Longpre and Le Hou and Tu Vu and Albert Webson and Hyung Won Chung and Yi Tay and Denny Zhou and Quoc V. Le and Barret Zoph and Jason Wei and Adam Roberts},
      year={2023},
      eprint={2301.13688},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{gao2021making,
    title = "Making Pre-trained Language Models Better Few-shot Learners",
    author = "Gao, Tianyu  and
      Fisch, Adam  and
      Chen, Danqi",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.295",
    doi = "10.18653/v1/2021.acl-long.295",
    pages = "3816--3830",
}


@inproceedings{zhang2019bertscore,
  title={BERTScore: Evaluating Text Generation with BERT},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{chen2023fireact,
  title={Fireact: Toward language agent fine-tuning},
  author={Chen, Baian and Shu, Chang and Shareghi, Ehsan and Collier, Nigel and Narasimhan, Karthik and Yao, Shunyu},
  journal={arXiv preprint arXiv:2310.05915},
  year={2023}
}

@misc{meta2023responsible,
  title={Responsible use guide: Your resource for building responsibly},
  author={Meta},
  year={2024},
  month={1},
  howpublished={\url{https://ai.meta.com/llama/responsible-use-guide/}},
}

@article{peng2023instruction,
  title={Instruction Tuning with GPT-4},
  author={Peng, Baolin and Li, Chunyuan and He, Pengcheng and Galley, Michel and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2304.03277},
  year={2023}
}

@article{lin2023unlocking,
  title={The unlocking spell on base llms: Rethinking alignment via in-context learning},
  author={Lin, Bill Yuchen and Ravichander, Abhilasha and Lu, Ximing and Dziri, Nouha and Sclar, Melanie and Chandu, Khyathi and Bhagavatula, Chandra and Choi, Yejin},
  journal={arXiv preprint arXiv:2312.01552},
  year={2023}
}

@article{ganguli2023capacity,
  title={The capacity for moral self-correction in large language models},
  author={Ganguli, Deep and Askell, Amanda and Schiefer, Nicholas and Liao, Thomas and Luko{\v{s}}i{\=u}t{\.e}, Kamil{\.e} and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and Olsson, Catherine and Hernandez, Danny and others},
  journal={arXiv preprint arXiv:2302.07459},
  year={2023}
}

@article{wu2023defending,
  title={Defending ChatGPT against Jailbreak Attack via Self-Reminder},
  author={Wu, Fangzhao and Xie, Yueqi and Yi, Jingwei and Shao, Jiawei and Curl, Justin and Lyu, Lingjuan and Chen, Qifeng and Xie, Xing},
  year={2023}
}

@misc{lmsys2023vicuna,
  author = {{LMSYS}},
  title = {Fast Chat Documentation: {V}icuna Weights},
  year = {2023},
  howpublished = {\url{https://github.com/lm-sys/FastChat/blob/324bcc69c033ac99942749817248e4b48f90180d/docs/vicuna_weights_version.md}},
}

@inproceedings{
zheng2023judging,
title={Judging {LLM}-as-a-Judge with {MT}-Bench and Chatbot Arena},
author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2023},
url={https://openreview.net/forum?id=uccHPGDlao}
}

@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing {GPT}-4 with 90\%* {ChatGPT} Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@misc{MosaicML2023Introducing,
    author    = {MosaicML},
    title     = {Introducing {MPT}-30B: Raising the bar for open-source foundation models},
    year      = {2023},
    url       = {https://www.mosaicml.com/blog/mpt-30b},
    note      = {Accessed: 2023-06-22},
    urldate   = {2023-06-22}
}

@misc{facebookresearch_2023,
  title={Llama 2 Post Launch Updates},
  url={https://github.com/facebookresearch/llama/blob/008385a65aecfe5c14b5abc9e47c558c0fbe18ec/UPDATES.md},
  journal={GitHub},
  author={facebookresearch},
  year={2023},
  month={Aug}
} 

@misc{mistralai_guardrailing,
  title = {Guardrailing},
  author = {{Mistral AI}},
  howpublished = {\url{https://docs.mistral.ai/platform/guardrailing/}},
  note = {Accessed: 2024-02-16},
  year = 2024
}

@article{wang2024mitigating,
  title={Mitigating Fine-tuning Jailbreak Attack with Backdoor Enhanced Alignment},
  author={Wang, Jiongxiao and Li, Jiazhao and Li, Yiquan and Qi, Xiangyu and Chen, Muhao and Hu, Junjie and Li, Yixuan and Li, Bo and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2402.14968},
  year={2024}
}

@article{he2024what,
  title={What's in Your" Safe" Data?: Identifying Benign Data that Breaks Safety},
  author={He, Luxi and Xia, Mengzhou and Henderson, Peter},
  journal={arXiv preprint arXiv:2404.01099},
  year={2024}
}

@article{
kirkpatrick2017overcoming,
author = {James Kirkpatrick  and Razvan Pascanu  and Neil Rabinowitz  and Joel Veness  and Guillaume Desjardins  and Andrei A. Rusu  and Kieran Milan  and John Quan  and Tiago Ramalho  and Agnieszka Grabska-Barwinska  and Demis Hassabis  and Claudia Clopath  and Dharshan Kumaran  and Raia Hadsell },
title = {Overcoming catastrophic forgetting in neural networks},
journal = {Proceedings of the National Academy of Sciences},
volume = {114},
number = {13},
pages = {3521-3526},
year = {2017},
doi = {10.1073/pnas.1611835114},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1611835114},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1611835114},
abstract = {The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Until now neural networks have not been capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks that they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on a hand-written digit dataset and by learning several Atari 2600 games sequentially.}}

@article{zheng2024prompt,
  title={On Prompt-Driven Safeguarding for Large Language Models},
  author={Zheng, Chujie and Yin, Fan and Zhou, Hao and Meng, Fandong and Zhou, Jie and Chang, Kai-Wei and Huang, Minlie and Peng, Nanyun},
  journal={arXiv preprint arXiv:2401.18018},
  year={2024}
}

@article{wang2024adashield,
  title={Adashield: Safeguarding multimodal large language models from structure-based attack via adaptive shield prompting},
  author={Wang, Yu and Liu, Xiaogeng and Li, Yu and Chen, Muhao and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2403.09513},
  year={2024}
}

@article{huang2024vaccine,
  title={Vaccine: Perturbation-aware alignment for large language model},
  author={Huang, Tiansheng and Hu, Sihao and Liu, Ling},
  journal={arXiv preprint arXiv:2402.01109},
  year={2024}
}

@inproceedings{rosati2024immunization,
    title = "Immunization against harmful fine-tuning attacks",
    author = "Rosati, Domenic  and
      Wehner, Jan  and
      Williams, Kai  and
      Bartoszcze, Lukasz  and
      Sajjad, Hassan  and
      Rudzicz, Frank",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2024.findings-emnlp.301",
    pages = "5234--5247"
}

@inproceedings{rosati2024representation,
title={Representation Noising: A Defence Mechanism Against Harmful Finetuning},
author={Domenic Rosati and Jan Wehner and Kai Williams and Lukasz Bartoszcze and Robie Gonzales and carsten maple and Subhabrata Majumdar and Hassan Sajjad and Frank Rudzicz},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024}
}

@article{wei2023jailbreak,
  title={Jailbreak and guard aligned language models with only few in-context demonstrations},
  author={Wei, Zeming and Wang, Yifei and Li, Ang and Mo, Yichuan and Wang, Yisen},
  journal={arXiv preprint arXiv:2310.06387},
  year={2023}
}

@article{wallace2024instruction,
  title={The instruction hierarchy: Training llms to prioritize privileged instructions},
  author={Wallace, Eric and Xiao, Kai and Leike, Reimar and Weng, Lilian and Heidecke, Johannes and Beutel, Alex},
  journal={arXiv preprint arXiv:2404.13208},
  year={2024}
}

@article{chen2024struq,
  title={StruQ: Defending against prompt injection with structured queries},
  author={Chen, Sizhe and Piet, Julien and Sitawarin, Chawin and Wagner, David},
  journal={arXiv preprint arXiv:2402.06363},
  year={2024}
}

@article{mukhoti2024finetuning,
title={Fine-tuning can cripple your foundation model; preserving features may be the solution},
author={Jishnu Mukhoti and Yarin Gal and Philip Torr and Puneet K. Dokania},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2024},
note={Featured Certification}
}

@inproceedings{huang2024lisa,
title={Lisa: Lazy Safety Alignment for Large Language Models against Harmful Fine-tuning Attack},
author={Tiansheng Huang and Sihao Hu and Fatih Ilhan and Selim Furkan Tekin and Ling Liu},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=RPChapuXlC}
}

@inproceedings{hsu2024safe,
title={Safe {LoRA}: The Silver Lining of Reducing Safety Risks when Finetuning Large Language Models},
author={Chia-Yi Hsu and Yu-Lin Tsai and Chih-Hsun Lin and Pin-Yu Chen and Chia-Mu Yu and Chun-Ying Huang},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=HcifdQZFZV}
}
