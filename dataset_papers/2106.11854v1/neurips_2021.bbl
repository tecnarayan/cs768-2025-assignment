\begin{thebibliography}{34}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Silver et~al.(2017)Silver, Schrittwieser, Simonyan, Antonoglou, Guez,
  Hubert, Baker, Lai, Bolton, Chen, Lillicrap, Hui, Sifre, van~den Driessche,
  Graepel, and Hassabis]{alphagozero2017}
David Silver, Julian Schrittwieser, Karen Simonyan, Aj~Antonoglou, Ioannis
  abd~Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian
  Bolton, Yutian Chen, Timothy Lillicrap, Fan Hui, Laurent Sifre, George
  van~den Driessche, Thore Graepel, and Demis Hassabis.
\newblock Mastering the game of go without human knowledge.
\newblock \emph{Nature}, 550, 2017.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529, 2015.

\bibitem[Haarnoja et~al.(2018{\natexlab{a}})Haarnoja, Zhou, Hartikainen,
  Tucker, Ha, Tan, Kumar, Zhu, Gupta, Abbeel, et~al.]{haarnoja2018softapp}
Tuomas Haarnoja, Aurick Zhou, Kristian Hartikainen, George Tucker, Sehoon Ha,
  Jie Tan, Vikash Kumar, Henry Zhu, Abhishek Gupta, Pieter Abbeel, et~al.
\newblock Soft actor-critic algorithms and applications.
\newblock \emph{arXiv preprint arXiv:1812.05905}, 2018{\natexlab{a}}.

\bibitem[{Hein} et~al.(2017){Hein}, {Depeweg}, {Tokic}, {Udluft}, {Hentschel},
  {Runkler}, and {Sterzing}]{industrial2017}
D.~{Hein}, S.~{Depeweg}, M.~{Tokic}, S.~{Udluft}, A.~{Hentschel}, T.~A.
  {Runkler}, and V.~{Sterzing}.
\newblock A benchmark environment motivated by industrial control problems.
\newblock In \emph{2017 IEEE Symposium Series on Computational Intelligence
  (SSCI)}, pages 1--8, 2017.
\newblock \doi{10.1109/SSCI.2017.8280935}.

\bibitem[Gong et~al.(2019)Gong, Abdel-Aty, Cai, and Rahman]{traffic2019}
Yaobang Gong, Mohamed Abdel-Aty, Qing Cai, and Md~Sharikur Rahman.
\newblock Decentralized network level adaptive signal control by multi-agent
  deep reinforcement learning.
\newblock \emph{Transportation Research Interdisciplinary Perspectives},
  1:\penalty0 100020, 2019.

\bibitem[Lin et~al.(2018)Lin, Zhao, Xu, and Zhou]{fleet2018Efficient}
Kaixiang Lin, Renyu Zhao, Zhe Xu, and Jiayu Zhou.
\newblock Efficient large-scale fleet management via multi-agent deep
  reinforcement learning.
\newblock In \emph{the 24th ACM SIGKDD International Conference}, 2018.

\bibitem[Olivecrona et~al.(2017)Olivecrona, Blaschke, Engkvist, and
  Chen]{molecular2017}
Marcus Olivecrona, Thomas Blaschke, Ola Engkvist, and Hongming Chen.
\newblock Molecular de-novo design through deep reinforcement learning.
\newblock \emph{Journal of cheminformatics}, 9\penalty0 (1):\penalty0 1--14,
  2017.

\bibitem[Xu et~al.(2018)Xu, Li, Guan, Zhang, and Ye]{2018dispatch}
Zhe Xu, Zhixin Li, Qingwen Guan, Dingshui Zhang, and Jieping Ye.
\newblock Large-scale order dispatch in on-demand ride-hailing platforms: A
  learning and planning approach.
\newblock In \emph{the 24th ACM SIGKDD International Conference}, 2018.

\bibitem[Gangwani et~al.(2020)Gangwani, Zhou, and Peng]{Tanmay2020ircr}
Tanmay Gangwani, Yuan Zhou, and Jian Peng.
\newblock Learning guidance rewards with trajectory-space smoothing.
\newblock In \emph{34th Conference on Neural Information Processing Systems},
  2020.

\bibitem[Zheng et~al.(2018)Zheng, Oh, and Singh]{Zheng2018lirpg}
Zeyu Zheng, Junhyuk Oh, and Satinder Singh.
\newblock On learning intrinsic rewards for policy gradient methods.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~31, pages 4644--4654. Curran Associates, Inc., 2018.

\bibitem[Oh et~al.(2018)Oh, Guo, Singh, and Lee]{Oh2018sil}
Junhyuk Oh, Yijie Guo, Satinder Singh, and Honglak Lee.
\newblock Self-imitation learning.
\newblock In Jennifer Dy and Andreas Krause, editors, \emph{Proceedings of the
  35th International Conference on Machine Learning}, volume~80 of
  \emph{Proceedings of Machine Learning Research}, pages 3878--3887,
  Stockholmsmässan, Stockholm Sweden, 10--15 Jul 2018. PMLR.

\bibitem[Klissarov and Precup(2020)]{Martin2020GCN}
Martin Klissarov and Doina Precup.
\newblock Reward propagation using graph convolutional networks martin.
\newblock In \emph{34th Conference on Neural Information Processing Systems},
  2020.

\bibitem[Haarnoja et~al.(2018{\natexlab{b}})Haarnoja, Zhou, Abbeel, and
  Levine]{haarnoja2018sac}
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, volume~80 of \emph{Proceedings of Machine Learning Research},
  pages 1861--1870, Stockholmsmässan, Stockholm Sweden, 10--15 Jul
  2018{\natexlab{b}}. PMLR.

\bibitem[Fujimoto et~al.(2018)Fujimoto, Hoof, and Meger]{fujimoto2018td3}
Scott Fujimoto, Herke Hoof, and David Meger.
\newblock Addressing function approximation error in actor-critic methods.
\newblock In \emph{International Conference on Machine Learning}, pages
  1587--1596, 2018.

\bibitem[Sutton and Barto(2018)]{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Cho et~al.(2014)Cho, van Merri{\"e}nboer, Gulcehre, Bahdanau,
  Bougares, Schwenk, and Bengio]{cho2014gru}
Kyunghyun Cho, Bart van Merri{\"e}nboer, Caglar Gulcehre, Dzmitry Bahdanau,
  Fethi Bougares, Holger Schwenk, and Yoshua Bengio.
\newblock Learning phrase representations using {RNN} encoder{--}decoder for
  statistical machine translation.
\newblock In \emph{Proceedings of the 2014 Conference on Empirical Methods in
  Natural Language Processing ({EMNLP})}, pages 1724--1734, Doha, Qatar,
  October 2014. Association for Computational Linguistics.
\newblock \doi{10.3115/v1/D14-1179}.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, Courville, and
  Bengio]{goodfellow2016deep}
Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio.
\newblock \emph{Deep learning}, volume~1.
\newblock MIT Press, 2016.

\bibitem[Arjona-Medina et~al.(2019)Arjona-Medina, Gillhofer, Widrich,
  Unterthiner, Brandstetter, and Hochreiter]{jose2019Rudder}
Jose~A. Arjona-Medina, Michael Gillhofer, Michael Widrich, Thomas Unterthiner,
  Johannes Brandstetter, and Sepp Hochreiter.
\newblock Rudder: Return decomposition for delayed rewards.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32, pages 13566--13577. Curran Associates, Inc., 2019.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017proximal}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Duan et~al.(2016)Duan, Chen, Houthooft, Schulman, and
  Abbeal]{yan2016benchmark}
Yan Duan, Xi~Chen, Rein Houthooft, John Schulman, and Pieter Abbeal.
\newblock Benchmarking deep reinforcement learning for continuous control.
\newblock In \emph{International Conference on Machine Learning}, 2016.

\bibitem[Degris et~al.(2012)Degris, White, and Sutton]{degris2012off}
Thomas Degris, Martha White, and Richard~S Sutton.
\newblock Off-policy actor-critic.
\newblock In \emph{Proceedings of the 29th International Coference on
  International Conference on Machine Learning}, pages 179--186, 2012.

\bibitem[Silver et~al.(2014)Silver, Lever, Heess, Degris, Wierstra, and
  Riedmiller]{silver2014dpg}
David Silver, Guy Lever, Nicolas Heess, Thomas Degris, Daan Wierstra, and
  Martin Riedmiller.
\newblock Deterministic policy gradient algorithms.
\newblock In \emph{Proceedings of the 31st International Conference on
  International Conference on Machine Learning-Volume 32}, pages I--387, 2014.

\bibitem[Sutton(1984)]{sutton1984credit}
Richard~Stuart Sutton.
\newblock \emph{Temporal credit assignment in reinforcement learning}.
\newblock PhD thesis, Department of Computer Science, University of
  Massachusetts at Amherst, 1984.

\bibitem[Finn et~al.(2020)Finn, Abbeal, and Levine]{Finn2017maml}
Chelsea Finn, Pieter Abbeal, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{34th Conference on Neural Information Processing Systems},
  2020.

\bibitem[Gangwani et~al.(2019)Gangwani, Liu, and Peng]{Tanmay2019gasil}
Tanmay Gangwani, Qiang Liu, and Jian Peng.
\newblock Learning self-imitating diverse policies.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Guo et~al.(2018)Guo, Oh, Singh, and Lee]{yijie2018gasil}
Yijie Guo, Junhyuk Oh, Satinder Singh, and Honglak Lee.
\newblock Generative adversarial self-imitation learning.
\newblock \emph{arXiv preprint arXiv:1812.00950}, 2018.

\bibitem[Liu et~al.(2019)Liu, Luo, Zhong, Chen, Liu, and
  Peng]{liu2019rewardregression}
Yang Liu, Yunan Luo, Yuanyi Zhong, Xi~Chen, Qiang Liu, and Jian Peng.
\newblock Sequence modeling of temporal credit assignment for episodic
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1905.13420}, 2019.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{ashish2017transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan
  Gomez, N, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{31th Conference on Neural Information Processing Systems},
  pages 5998--6008, 2017.

\bibitem[Kipf and Welling(2016)]{welling2019gcn}
Thomas~N. Kipf and Max Welling.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock \emph{CoRR}, abs/1609.02907, 2016.

\bibitem[Ng et~al.(1999)Ng, Harada, and Russell]{Ng1999rewardshape}
A.~Ng, D.~Harada, and S.~Russell.
\newblock Policy invariance under reward transformations: Theory and
  application to reward shaping.
\newblock In \emph{International Conference on Machine Learning}, 1999.

\bibitem[Levine et~al.(2020)Levine, Kumar, Tucker, and Fu]{levine2020offline}
Sergey Levine, Aviral Kumar, George Tucker, and Justin Fu.
\newblock Offline reinforcement learning: Tutorial, review, and perspectives on
  open problems.
\newblock \emph{arXiv preprint arXiv:2005.01643}, 2020.

\bibitem[Dhariwal et~al.(2017)Dhariwal, Hesse, Klimov, Nichol, Plappert,
  Radford, Schulman, Sidor, Wu, and Zhokhov]{openai2017baselines}
Prafulla Dhariwal, Christopher Hesse, Oleg Klimov, Alex Nichol, Matthias
  Plappert, Alec Radford, John Schulman, Szymon Sidor, Yuhuai Wu, and Peter
  Zhokhov.
\newblock Openai baselines.
\newblock \url{https://github.com/openai/baselines}, 2017.

\bibitem[Kingma and Ba(2014)]{Kingma2014Adam}
Diederik Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{Computer Science}, 2014.

\bibitem[Greg et~al.(2016)Greg, Vicki, Ludwig, Jonas, John, Jie, and
  Wojciech]{greg2016openai}
Brockman Greg, Cheung Vicki, Pettersson Ludwig, Schneider Jonas, Schulman John,
  Tang Jie, and Zaremba Wojciech.
\newblock Openai gym, 2016.

\end{thebibliography}
