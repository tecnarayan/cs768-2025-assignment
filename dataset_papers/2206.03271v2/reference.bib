@string{JMLR = {JMLR}}
@string{ECCV = {ECCV}}
@string{ICRA = {ICRA}}
@string{IJRR = {IJRR}}
@string{RSS = {RSS}}
@string{IROS = {IROS}}
@string{ICCV = {ICCV}}
@string{CVPR = {CVPR}}
@string{IJCV = {IJCV}}
@string{NeurIPS = {NeurIPS}}
@string{MICCAI = {MICCAI}}
@string{ICLR = {ICLR}}
@string{ICML = {ICML}}
@string{JMIV = {JMIV}}
@string{WAFR = {WAFR}}
@string{CoRL = {CoRL}}
@string{RAL = {RAL}}


@string{ECCV = {Proc. European Conference on Computer Vision}}
@string{JMLR = {Journal of Machine Learning Research}}
@string{ICRA = {IEEE Intl. Conference on Robotics and Automation}}
@string{IJRR = {The Intl. Journal of Robotics Research}}
@string{RSS = {Robotics: Science and Systems}}
@string{IROS = {IEEE Intl. Conference on Intelligent Robots and Systems}}
@string{ECCV = {European Conference on Computer Vision}}
@string{ICCV = {Intl. Conference on Computer Vision}}
@string{CVPR = {IEEE Conference on Computer Vision and Pattern Recognition}}
@string{IJCV ={Intl. Journal of Computer Vision}}
@string{NeurIPS = {Advances in Neural Information Processing Systems}}
@string{MICCAI = {Intl. Conference on Medical Image Computing and Computer-Assisted Intervention}}
@string{ICLR = {Intl. Conference on Learning Representations}}
@string{ICML = {Intl. Conference on Machine Learning}}
@string{JMIV = {Journal of Mathematical Imaging and Vision}}
@string{WAFR = {Workshop on the Algorithmic Foundations of Robotics}}
@string{CoRL = {Conference on Robot Learning}}
@string{AAAI = {Association for the Advancement of Artificial Intelligence}}
@string{RAL = {IEEE Robotics and Automation Letters}}


@article{james2021coarsetofine,
  title={Coarse-to-{F}ine {Q}-attention: {E}fficient {L}earning for {V}isual {R}obotic {M}anipulation via {D}iscretisation},
  author={James, Stephen and Wada, Kentaro and Laidlow, Tristan and Davison, Andrew J},
  journal=CVPR,
  year={2022}
}

@article{james2021qattention,
  title={Q-attention: {E}nabling {E}fficient {L}earning for {V}ision-based {R}obotic {M}anipulation},
  author={James, Stephen and Davison, Andrew J},
  journal=RAL,
  year={2022},
}

 
@article{james2019rlbench,
  title={{RLB}ench: The Robot Learning Benchmark \& Learning Environment},
  author={James, Stephen and Ma, Zicong and Rovick Arrojo, David and Davison, Andrew J.},
  journal=RAL,
  year={2020}
}
% atari 

@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-second AAAI conference on artificial intelligence},
  year={2018}
}
% Meta-RL
@misc{rakelly2019efficient,
      title={Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables}, 
      author={Kate Rakelly and Aurick Zhou and Deirdre Quillen and Chelsea Finn and Sergey Levine},
      year={2019},
      eprint={1903.08254},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{mishra2018simple,
      title={A Simple Neural Attentive Meta-Learner}, 
      author={Nikhil Mishra and Mostafa Rohaninejad and Xi Chen and Pieter Abbeel},
      year={2018},
      eprint={1707.03141},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@misc{lin2021modelbased,
      title={Model-based Adversarial Meta-Reinforcement Learning}, 
      author={Zichuan Lin and Garrett Thomas and Guangwen Yang and Tengyu Ma},
      year={2021},
      eprint={2006.08875},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
} 

% MQL
@inproceedings{
fakoor2020metaqlearning,
title={Meta-Q-Learning},
author={Rasool Fakoor and Pratik Chaudhari and Stefano Soatto and Alexander J. Smola},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SJeD3CEFPH}
}
@article{Ni2021RecurrentMR,
  title={Recurrent Model-Free RL is a Strong Baseline for Many POMDPs},
  author={Tianwei Ni and Benjamin Eysenbach and Ruslan Salakhutdinov},
  journal={ArXiv},
  year={2021},
  volume={abs/2110.05038}
}
 
% minimal perf gain
@article{Mendonca2020MetaReinforcementLR,
  title={Meta-Reinforcement Learning Robust to Distributional Shift via Model Identification and Experience Relabeling},
  author={Russell Mendonca and Xinyang Geng and Chelsea Finn and Sergey Levine},
  journal={ArXiv},
  year={2020},
  volume={abs/2006.07178}
}

% added contrastive for context
@inproceedings{Fu2021TowardsEC,
  title={Towards Effective Context for Meta-Reinforcement Learning: an Approach based on Contrastive Learning},
  author={Haotian Fu and Hongyao Tang and Jianye Hao and Chen Chen and Xidong Feng and Dong Li and Wulong Liu},
  booktitle={AAAI},
  year={2021}
}
@article{Wang2021ImprovingCM,
  title={Improving Context-Based Meta-Reinforcement Learning with Self-Supervised Trajectory Contrastive Learning},
  author={Bernie Wang and Simon Xu and Kurt Keutzer and Yang Gao and Bichen Wu},
  journal={ArXiv},
  year={2021},
  volume={abs/2103.06386}
}
 
% not exactly "unseen", but good baseline stuff
@article{Lee2021ImprovingGI,
  title={Improving Generalization in Meta-RL with Imaginary Tasks from Latent Dynamics Mixture},
  author={Suyoung Lee and Sae-Young Chung},
  journal={ArXiv},
  year={2021},
  volume={abs/2105.13524}
}
@article{Mendonca2020MetaReinforcementLR,
  title={Meta-Reinforcement Learning Robust to Distributional Shift via Model Identification and Experience Relabeling},
  author={Russell Mendonca and Xinyang Geng and Chelsea Finn and Sergey Levine},
  journal={ArXiv},
  year={2020},
  volume={abs/2006.07178}
}

% low-prio: meta-rl on Offline
@article{Li2021EfficientFM,
  title={Efficient Fully-Offline Meta-Reinforcement Learning via Distance Metric Learning and Behavior Regularization},
  author={Lanqing Li and Rui Yang and Dijun Luo},
  journal={ArXiv},
  year={2021},
  volume={abs/2010.01112}
}

@inproceedings{Mitchell2021OfflineML,
  title={Offline Meta-Reinforcement Learning with Advantage Weighting},
  author={Eric Mitchell and Rafael Rafailov and Xue Bin Peng and Sergey Levine and Chelsea Finn},
  booktitle={ICML},
  year={2021}
}
% also requires params update, just context isnt enuf
@misc{zhao2021offline,
      title={Offline Meta-Reinforcement Learning for Industrial Insertion}, 
      author={Tony Z. Zhao and Jianlan Luo and Oleg Sushkov and Rugile Pevceviciute and Nicolas Heess and Jon Scholz and Stefan Schaal and Sergey Levine},
      year={2021},
      eprint={2110.04276},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

%workshop; theoretically
% consistent algorithms can indeed usually adapt to out-of-distribution (OOD) tasks,
% while inconsistent ones cannot, although they can still fail in practice for reasons
% like poor exploration. We further find that theoretically inconsistent algorithms
% can be made consistent by continuing to update all agent components on the OOD
% tasks, and adapt as well or better than originally consistent ones 
@article{Xiong2021OnTP,
  title={On the Practical Consistency of Meta-Reinforcement Learning Algorithms},
  author={Zheng Xiong and Luisa M. Zintgraf and Jacob Beck and Risto Vuorio and Shimon Whiteson},
  journal={ArXiv},
  year={2021},
  volume={abs/2112.00478}
}

% MT-RL
@misc{kalashnikov2021mtopt, 
    title={MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale}, 
      author={Dmitry Kalashnikov and Jacob Varley and Yevgen Chebotar and Benjamin Swanson and Rico Jonschkowski and Chelsea Finn and Sergey Levine and Karol Hausman},
      year={2021},
      eprint={2104.08212},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}
 
@misc{yu2021conservative,
      title={Conservative Data Sharing for Multi-Task Offline Reinforcement Learning}, 
      author={Tianhe Yu and Aviral Kumar and Yevgen Chebotar and Karol Hausman and Sergey Levine and Chelsea Finn},
      year={2021},
      eprint={2109.08128},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{yu2021metaworld,
      title={Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning}, 
      author={Tianhe Yu and Deirdre Quillen and Zhanpeng He and Ryan Julian and Avnish Narayan and Hayden Shively and Adithya Bellathur and Karol Hausman and Chelsea Finn and Sergey Levine},
      year={2021},
      eprint={1910.10897},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
  
@misc{sodhani2021multitask,
      title={Multi-Task Reinforcement Learning with Context-based Representations}, 
      author={Shagun Sodhani and Amy Zhang and Joelle Pineau},
      year={2021},
      eprint={2102.06177},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{Yang2020MultiTaskRL,
  title={Multi-Task Reinforcement Learning with Soft Modularization},
  author={Ruihan Yang and Huazhe Xu and Yi Wu and Xiaolong Wang},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.13661}
}

@article{kurin2022defense,
  title={In Defense of the Unitary Scalarization for Deep Multi-Task Learning},
  author={Kurin, Vitaly and De Palma, Alessandro and Kostrikov, Ilya and Whiteson, Shimon and Kumar, M Pawan},
  journal={arXiv preprint arXiv:2201.04122},
  year={2022}
}
% big survey on many tasks 
@article{kirk2022survey,
  title={A survey of generalisation in deep reinforcement learning},
  author={Kirk, Robert and Zhang, Amy and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  journal={arXiv preprint arXiv:2111.09794},
  year={2021}
}

% study on meta-rl v.s. mt-rl:
@article{gao2020modeling,
  title={Modeling and optimization trade-off in meta-learning},
  author={Gao, Katelyn and Sener, Ozan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={11154--11165},
  year={2020}
}

@inproceedings{cobbe2020leveraging,
  title={Leveraging procedural generation to benchmark reinforcement learning},
  author={Cobbe, Karl and Hesse, Chris and Hilton, Jacob and Schulman, John},
  booktitle={International conference on machine learning},
  pages={2048--2056},
  year={2020},
  organization={PMLR}
}


@Article{bellemare13arcade,
    author = {{Bellemare}, M.~G. and {Naddaf}, Y. and {Veness}, J. and {Bowling}, M.},
    title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
    journal = {Journal of Artificial Intelligence Research},
    year = "2013",
    month = "jun",
    volume = "47",
    pages = "253--279",
}
@Article{machado18arcade,
    author = {Marlos C. Machado and Marc G. Bellemare and Erik Talvitie and Joel Veness and Matthew J. Hausknecht and Michael Bowling},
    title = {Revisiting the Arcade Learning Environment: Evaluation Protocols and Open Problems for General Agents},
    journal = {Journal of Artificial Intelligence Research},
    volume = {61},
    pages = {523--562},
    year = {2018}
}

% few-shot learning (no-RL)
@misc{wang2020generalizing,
      title={Generalizing from a Few Examples: A Survey on Few-Shot Learning}, 
      author={Yaqing Wang and Quanming Yao and James Kwok and Lionel M. Ni},
      year={2020},
      eprint={1904.05046},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{nichol2018first,
  title={On first-order meta-learning algorithms},
  author={Nichol, Alex and Achiam, Joshua and Schulman, John},
  journal={arXiv preprint arXiv:1803.02999},
  year={2018}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle=ICML,
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}

@article{vinyals2016matching,
  title={Matching networks for one shot learning},
  author={Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Wierstra, Daan and others},
  journal=NeurIPS,
  volume={29},
  pages={3630--3638},
  year={2016}
}

@article{ravi2017optimization,
  title={Optimization as a model for few-shot learning},
  author={Ravi, Sachin and Larochelle, Hugo},
  journal=ICLR,
  year={2017}
}

@inproceedings{james2018taskembedded,
  title={Task-embedded control networks for few-shot imitation learning},
  author={James, Stephen and Bloesch, Michael and Davison, Andrew J},
  booktitle=CoRL,
  pages={783--795},
  year={2018},
  organization={PMLR}
}

@article{bonardi2020learning,
  title={Learning one-shot imitation from humans without humans},
  author={Bonardi, Alessandro and James, Stephen and Davison, Andrew J},
  journal=RAL,
  volume={5},
  number={2},
  pages={3533--3539},
  year={2020},
}

@inproceedings{finn2017one,
  title={One-shot visual imitation learning via meta-learning},
  author={Finn, Chelsea and Yu, Tianhe and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
  booktitle=CoRL,
  pages={357--368},
  year={2017},
  organization={PMLR}
}
% this one also uses Reptile but for imitation on meta-world
@inproceedings{Cachet2020TransformerbasedML,
  title={Transformer-based Meta-Imitation Learning for Robotic Manipulation},
  author={Th{\'e}o Cachet and J. Perez},
  year={2020}
}
% feature-reuse >> params
@misc{raghu2020rapid,
      title={Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML}, 
      author={Aniruddh Raghu and Maithra Raghu and Samy Bengio and Oriol Vinyals},
      year={2020},
      eprint={1909.09157},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

% GPT-3
@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{dhillon2020baseline,
  title={A baseline for few-shot image classification},
  author={Dhillon, Guneet S and Chaudhari, Pratik and Ravichandran, Avinash and Soatto, Stefano},
  journal=ICLR,
  year={2020}
}

@inproceedings{chen2021meta,
  title={Meta-baseline: exploring simple meta-learning for few-shot learning},
  author={Chen, Yinbo and Liu, Zhuang and Xu, Huijuan and Darrell, Trevor and Wang, Xiaolong},
  booktitle=ICCV,
  pages={9062--9071},
  year={2021}
}

@article{antoniou2018train,
  title={How to train your MAML},
  author={Antoniou, Antreas and Edwards, Harrison and Storkey, Amos},
  journal=ICLR,
  year={2019}
}
@misc{rajeswaran2019metalearning,
      title={Meta-Learning with Implicit Gradients}, 
      author={Aravind Rajeswaran and Chelsea Finn and Sham Kakade and Sergey Levine},
      year={2019},
      eprint={1909.04630},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{tian2020rethinking,
  title={Rethinking few-shot image classification: a good embedding is all you need?},
  author={Tian, Yonglong and Wang, Yue and Krishnan, Dilip and Tenenbaum, Joshua B and Isola, Phillip},
  booktitle=ECCV,
  pages={266--282},
  year={2020},
  organization={Springer}
}

@article{chen2019closer,
  title={A closer look at few-shot classification},
  author={Chen, Wei-Yu and Liu, Yen-Cheng and Kira, Zsolt and Wang, Yu-Chiang Frank and Huang, Jia-Bin},
  journal=ICLR,
  year={2019}
}

@article{packer2021hindsight,
  title={Hindsight Task Relabelling: Experience Replay for Sparse Reward Meta-RL},
  author={Packer, Charles and Abbeel, Pieter and Gonzalez, Joseph E},
  journal=NeurIPS,
  volume={34},
  year={2021}
}

@article{duan2016rl,
  title={$RL^2$: Fast reinforcement learning via slow reinforcement learning},
  author={Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L and Sutskever, Ilya and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1611.02779},
  year={2016}
}

@article{wang2016learning,
  title={Learning to reinforcement learn},
  author={Wang, Jane X and Kurth-Nelson, Zeb and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z and Munos, Remi and Blundell, Charles and Kumaran, Dharshan and Botvinick, Matt},
  journal={arXiv preprint arXiv:1611.05763},
  year={2016}
}

@article{xu2018meta,
  title={Meta-gradient reinforcement learning},
  author={Xu, Zhongwen and van Hasselt, Hado and Silver, David},
  journal={arXiv preprint arXiv:1805.09801},
  year={2018}
}

@article{sung2017learning,
  title={Learning to learn: Meta-critic networks for sample efficient learning},
  author={Sung, Flood and Zhang, Li and Xiang, Tao and Hospedales, Timothy and Yang, Yongxin},
  journal={arXiv preprint arXiv:1706.09529},
  year={2017}
}

@article{houthooft2018evolved,
  title={Evolved policy gradients},
  author={Houthooft, Rein and Chen, Richard Y and Isola, Phillip and Stadie, Bradly C and Wolski, Filip and Ho, Jonathan and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1802.04821},
  year={2018}
}

@article{rothfuss2018promp,
  title={Promp: Proximal meta-policy search},
  author={Rothfuss, Jonas and Lee, Dennis and Clavera, Ignasi and Asfour, Tamim and Abbeel, Pieter},
  journal=ICLR,
  year={2019}
}

@inproceedings{fan2018surreal,
  title={Surreal: Open-source reinforcement learning framework and robot manipulation benchmark},
  author={Fan, Linxi and Zhu, Yuke and Zhu, Jiren and Liu, Zihua and Zeng, Orien and Gupta, Anchit and Creus-Costa, Joan and Savarese, Silvio and Fei-Fei, Li},
  booktitle=CoRL,
  pages={767--782},
  year={2018},
  organization={PMLR}
}

@article{zeng2020transporter,
  title={Transporter networks: Rearranging the visual world for robotic manipulation},
  author={Zeng, Andy and Florence, Pete and Tompson, Jonathan and Welker, Stefan and Chien, Jonathan and Attarian, Maria and Armstrong, Travis and Krasin, Ivan and Duong, Dan and Sindhwani, Vikas and others},
  journal=CoRL,
  year={2020}
}

@article{haarnoja2018soft,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}


@article{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Van Hoof, Herke and Meger, David},
  journal=ICML,
  year={2018}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal=ICLR,
  year={2015}
}

@article{yarats2021mastering,
  title={Mastering visual continuous control: Improved data-augmented reinforcement learning},
  author={Yarats, Denis and Fergus, Rob and Lazaric, Alessandro and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2107.09645},
  year={2021}
}

 
 
  

@article{Ni2021RecurrentMR,
  title={Recurrent Model-Free RL is a Strong Baseline for Many POMDPs},
  author={Tianwei Ni and Benjamin Eysenbach and Ruslan Salakhutdinov},
  journal={ArXiv},
  year={2021},
  volume={abs/2110.05038}
}
 
% minimal perf gain
@article{Mendonca2020MetaReinforcementLR,
  title={Meta-Reinforcement Learning Robust to Distributional Shift via Model Identification and Experience Relabeling},
  author={Russell Mendonca and Xinyang Geng and Chelsea Finn and Sergey Levine},
  journal={ArXiv},
  year={2020},
  volume={abs/2006.07178}
}

% added contrastive for context
@inproceedings{Fu2021TowardsEC,
  title={Towards Effective Context for Meta-Reinforcement Learning: an Approach based on Contrastive Learning},
  author={Haotian Fu and Hongyao Tang and Jianye Hao and Chen Chen and Xidong Feng and Dong Li and Wulong Liu},
  booktitle={AAAI},
  year={2021}
}
@article{Wang2021ImprovingCM,
  title={Improving Context-Based Meta-Reinforcement Learning with Self-Supervised Trajectory Contrastive Learning},
  author={Bernie Wang and Simon Xu and Kurt Keutzer and Yang Gao and Bichen Wu},
  journal={ArXiv},
  year={2021},
  volume={abs/2103.06386}
}
  
@article{Mendonca2020MetaReinforcementLR,
  title={Meta-Reinforcement Learning Robust to Distributional Shift via Model Identification and Experience Relabeling},
  author={Russell Mendonca and Xinyang Geng and Chelsea Finn and Sergey Levine},
  journal={ArXiv},
  year={2020},
  volume={abs/2006.07178}
}

% low-prio: meta-rl on Offline
@article{Li2021EfficientFM,
  title={Efficient Fully-Offline Meta-Reinforcement Learning via Distance Metric Learning and Behavior Regularization},
  author={Lanqing Li and Rui Yang and Dijun Luo},
  journal={ArXiv},
  year={2021},
  volume={abs/2010.01112}
}

@inproceedings{Mitchell2021OfflineML,
  title={Offline Meta-Reinforcement Learning with Advantage Weighting},
  author={Eric Mitchell and Rafael Rafailov and Xue Bin Peng and Sergey Levine and Chelsea Finn},
  booktitle={ICML},
  year={2021}
}
% also requires params update, just context isnt enuf
@misc{zhao2021offline,
      title={Offline Meta-Reinforcement Learning for Industrial Insertion}, 
      author={Tony Z. Zhao and Jianlan Luo and Oleg Sushkov and Rugile Pevceviciute and Nicolas Heess and Jon Scholz and Stefan Schaal and Sergey Levine},
      year={2021},
      eprint={2110.04276},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}
 
 
@misc{yu2021conservative,
      title={Conservative Data Sharing for Multi-Task Offline Reinforcement Learning}, 
      author={Tianhe Yu and Aviral Kumar and Yevgen Chebotar and Karol Hausman and Sergey Levine and Chelsea Finn},
      year={2021},
      eprint={2109.08128},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
} 
 
 %  
 
% big survey on many tasks 
@misc{kirk2022survey,
      title={A Survey of Generalisation in Deep Reinforcement Learning}, 
      author={Robert Kirk and Amy Zhang and Edward Grefenstette and Tim Rocktäschel},
      year={2022},
      eprint={2111.09794},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

% few-shot learning (no-RL)
@misc{wang2020generalizing,
      title={Generalizing from a Few Examples: A Survey on Few-Shot Learning}, 
      author={Yaqing Wang and Quanming Yao and James Kwok and Lionel M. Ni},
      year={2020},
      eprint={1904.05046},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

 
 
% f 
% GPT-3
@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
 
}

@article{antoniou2018train,
  title={How to train your MAML},
  author={Antoniou, Antreas and Edwards, Harrison and Storkey, Amos},
  journal=ICLR,
  year={2019}
}
@misc{rajeswaran2019metalearning,
      title={Meta-Learning with Implicit Gradients}, 
      author={Aravind Rajeswaran and Chelsea Finn and Sham Kakade and Sergey Levine},
      year={2019},
      eprint={1909.04630},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
 
 
@article{alver2020brief,
  title={A brief look at generalization in visual meta-reinforcement learning},
  author={Alver, Safa and Precup, Doina},
  journal={arXiv preprint arXiv:2006.07262},
  year={2020}
}
@inproceedings{hessel2019multi,
  title={Multi-task deep reinforcement learning with popart},
  author={Hessel, Matteo and Soyer, Hubert and Espeholt, Lasse and Czarnecki, Wojciech and Schmitt, Simon and van Hasselt, Hado},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={3796--3803},
  year={2019}
}

@article{oh2020discovering,
  title={Discovering reinforcement learning algorithms},
  author={Oh, Junhyuk and Hessel, Matteo and Czarnecki, Wojciech M and Xu, Zhongwen and van Hasselt, Hado P and Singh, Satinder and Silver, David},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1060--1070},
  year={2020}
}

@article{rusu2016progressive,
  title={Progressive neural networks},
  author={Rusu, Andrei A and Rabinowitz, Neil C and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
  journal={arXiv preprint arXiv:1606.04671},
  year={2016}
}

@article{sobol2018visual,
  title={Visual analogies between atari games for studying transfer learning in RL},
  author={Sobol, Doron and Wolf, Lior and Taigman, Yaniv},
  journal={arXiv preprint arXiv:1807.11074},
  year={2018}
}

@inproceedings{du2016initial,
  title={Initial progress in transfer for deep reinforcement learning algorithms},
  author={Du, Yunshu and Gabriel, V and Irwin, James and Taylor, Matthew E},
  booktitle={Proceedings of deep reinforcement learning: frontiers and challenges workshop, New York City, NY, USA},
  year={2016}
}
@inproceedings{mittel2019visual,
  title={Visual transfer between atari games using competitive reinforcement learning},
  author={Mittel, Akshita and Sowmya Munukutla, Purna},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={0--0},
  year={2019}
}
@article{farebrother2018generalization,
  title={Generalization and regularization in DQN},
  author={Farebrother, Jesse and Machado, Marlos C and Bowling, Michael},
  journal={arXiv preprint arXiv:1810.00123},
  year={2018}
}
@article{wang2020improving,
  title={Improving generalization in reinforcement learning with mixture regularization},
  author={Wang, Kaixin and Kang, Bingyi and Shao, Jie and Feng, Jiashi},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7968--7978},
  year={2020}
}
@article{raileanu2021automatic,
  title={Automatic Data Augmentation for Generalization in Reinforcement Learning},
  author={Raileanu, Roberta and Goldstein, Maxwell and Yarats, Denis and Kostrikov, Ilya and Fergus, Rob},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


% ======old meta-learning ===========
@Inbook{Thrun1998,
author="Thrun, Sebastian
and Pratt, Lorien",
editor="Thrun, Sebastian
and Pratt, Lorien",
title="Learning to Learn: Introduction and Overview",
bookTitle="Learning to Learn",
year="1998",
publisher="Springer US",
address="Boston, MA",
pages="3--17", 
isbn="978-1-4615-5529-2",
doi="10.1007/978-1-4615-5529-2_1",
url="https://doi.org/10.1007/978-1-4615-5529-2_1"
}


@article{Naik1992,
  title={Meta-neural networks that learn by learning},
  author={Dattika K. Naik and Richard J. Mammone},
  journal={[Proceedings 1992] IJCNN International Joint Conference on Neural Networks},
  year={1992},
  volume={1},
  pages={437-442 vol.1}
}
@article{kehoe1988,
author = {Kehoe, E.},
year = {1988},
month = {11},
pages = {411-33},
title = {A Layered Network Model of Associative Learning: Learning to Learn and Configuration},
volume = {95},
journal = {Psychological review},
doi = {10.1037/0033-295X.95.4.411}
}

@article{Schmi92,
    author = {Schmidhuber, Jürgen},
    title = "{Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks}",
    journal = {Neural Computation},
    volume = {4},
    number = {1},
    pages = {131-139},
    year = {1992},
    month = {01},
    issn = {0899-7667},
    doi = {10.1162/neco.1992.4.1.131},
    url = {https://doi.org/10.1162/neco.1992.4.1.131},
    eprint = {https://direct.mit.edu/neco/article-pdf/4/1/131/812242/neco.1992.4.1.131.pdf},
}
@article{Schmi93,
  title={A neural network that embeds its own meta-levels},
  author={J{\"u}rgen Schmidhuber},
  journal={IEEE International Conference on Neural Networks},
  year={1993},
  pages={407-412 vol.1}
}

@MISC{Bengio97,
    author = {Samy Bengio and Yoshua Bengio and Jocelyn Cloutier and Jan Gecsei},
    title = {On the Optimization of a Synaptic Learning Rule},
    year = {1997}
}
@article{Bengio91,
  title={Learning a synaptic learning rule},
  author={Yoshua Bengio and Samy Bengio and Jocelyn Cloutier},
  journal={IJCNN-91-Seattle International Joint Conference on Neural Networks},
  year={1991},
  volume={ii},
  pages={969 vol.2-}
}

@inproceedings{andry16,
 author = {Andrychowicz, Marcin and Denil, Misha and G\'{o}mez, Sergio and Hoffman, Matthew W and Pfau, David and Schaul, Tom and Shillingford, Brendan and de Freitas, Nando},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning to learn by gradient descent by gradient descent},
 url = {https://proceedings.neurips.cc/paper/2016/file/fb87582825f9d28a8d42c5e5e5e8b23d-Paper.pdf},
 volume = {29},
 year = {2016}
}
 
 
@article{Younger2001MetalearningWB,
  title={Meta-learning with backpropagation},
  author={Arthur Steven Younger and Sepp Hochreiter and Peter R. Conwell},
  journal={IJCNN'01. International Joint Conference on Neural Networks. Proceedings (Cat. No.01CH37222)},
  year={2001},
  volume={3},
  pages={2001-2006 vol.3}
}

@InProceedings{Hochreiter,
author="Hochreiter, Sepp
and Younger, A. Steven
and Conwell, Peter R.",
editor="Dorffner, Georg
and Bischof, Horst
and Hornik, Kurt",
title="Learning to Learn Using Gradient Descent",
booktitle="Artificial Neural Networks --- ICANN 2001",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="87--94",
isbn="978-3-540-44668-2"
}



@article{li2016learning,
  title={Learning to optimize},
  author={Li, Ke and Malik, Jitendra},
  journal={arXiv preprint arXiv:1606.01885},
  year={2016}
}

@article{ha2016hypernetworks,
  title={Hypernetworks},
  author={Ha, David and Dai, Andrew and Le, Quoc V},
  journal={arXiv preprint arXiv:1609.09106},
  year={2016}
}


@InProceedings{santoro16,
  title = 	 {Meta-Learning with Memory-Augmented Neural Networks},
  author = 	 {Santoro, Adam and Bartunov, Sergey and Botvinick, Matthew and Wierstra, Daan and Lillicrap, Timothy},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1842--1850},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/santoro16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/santoro16.html}
}

@misc{Munkhdalai,
  doi = {10.48550/ARXIV.1703.00837}, 
  url = {https://arxiv.org/abs/1703.00837}, 
  author = {Munkhdalai, Tsendsuren and Yu, Hong},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences}, 
  title = {Meta Networks},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
% base rl algos
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
 

@article{van2019use,
  title={When to use parametric models in reinforcement learning?},
  author={van Hasselt, Hado P and Hessel, Matteo and Aslanides, John},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}


@article{james2022lpr,
  title={{C}oarse-to-{F}ine {Q}-attention with {L}earned {P}ath {R}anking},
  author={James, Stephen and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2204.01571},
  year={2022}
}

@article{james2022tree,
  title={{C}oarse-to-{F}ine {Q}-attention with {T}ree {E}xpansion},
  author={James, Stephen and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2204.12471},
  year={2022}
}


@inproceedings{espeholt2018impala,
  title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Vlad and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  booktitle={International Conference on Machine Learning},
  pages={1407--1416},
  year={2018},
  organization={PMLR}
}

@inproceedings{hausknecht2015deep,
  title={Deep recurrent q-learning for partially observable mdps},
  author={Hausknecht, Matthew and Stone, Peter},
  booktitle={2015 aaai fall symposium series},
  year={2015}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

%  code!
@article{stable-baselines3,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {268},
  pages   = {1-8},
  url     = {http://jmlr.org/papers/v22/20-1364.html}
} 
}

@misc{rainbowcode,
  author = {Kai Arulkumaran},
  title = {Pytorch Implementation of RainbowDQN},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/Kaixhin/Rainbow}},
}
% they also have negative atari transfer results
@misc{gato,
  doi = {10.48550/ARXIV.2205.06175},
  
  url = {https://arxiv.org/abs/2205.06175},
  
  author = {Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and Barth-Maron, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and Eccles, Tom and Bruce, Jake and Razavi, Ali and Edwards, Ashley and Heess, Nicolas and Chen, Yutian and Hadsell, Raia and Vinyals, Oriol and Bordbar, Mahyar and de Freitas, Nando},
  
  keywords = {Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Machine Learning (cs.LG), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {A Generalist Agent},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{nagabandi2018learning,
  title={Learning to adapt in dynamic, real-world environments through meta-reinforcement learning},
  author={Nagabandi, Anusha and Clavera, Ignasi and Liu, Simin and Fearing, Ronald S and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:1803.11347},
  year={2018}
}

@article{mandi2021towards,
  title={Towards More Generalizable One-shot Visual Imitation Learning},
  author={Mandi, Zhao and Liu, Fangchen and Lee, Kimin and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2110.13423},
  year={2021}
}


@misc{transient, 
  doi = {10.48550/ARXIV.2006.05826},
  
  url = {https://arxiv.org/abs/2006.05826},
  
  author = {Igl, Maximilian and Farquhar, Gregory and Luketina, Jelena and Boehmer, Wendelin and Whiteson, Shimon},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Transient Non-Stationarity and Generalisation in Deep Reinforcement Learning},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{anand2021procedural,
  title={Procedural Generalization by Planning with Self-Supervised World Models},
  author={Anand, Ankesh and Walker, Jacob and Li, Yazhe and V{\'e}rtes, Eszter and Schrittwieser, Julian and Ozair, Sherjil and Weber, Th{\'e}ophane and Hamrick, Jessica B},
  journal={arXiv preprint arXiv:2111.01587},
  year={2021}
}

@inproceedings{zintgraf2021exploration,
  title={Exploration in approximate hyper-state space for meta reinforcement learning},
  author={Zintgraf, Luisa M and Feng, Leo and Lu, Cong and Igl, Maximilian and Hartikainen, Kristian and Hofmann, Katja and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning},
  pages={12991--13001},
  year={2021},
  organization={PMLR}
}

@article{liu2020decoupling,
  title={Decoupling Exploration and Exploitation for Meta-Reinforcement Learning without Sacrifices},
  author={Liu, Evan Zheran and Raghunathan, Aditi and Liang, Percy and Finn, Chelsea},
  journal={arXiv preprint arXiv:2008.02790},
  year={2020}
}

@inproceedings{zhang2021metacure,
  title={Metacure: Meta reinforcement learning with empowerment-driven exploration},
  author={Zhang, Jin and Wang, Jianhao and Hu, Hao and Chen, Tong and Chen, Yingfeng and Fan, Changjie and Zhang, Chongjie},
  booktitle={International Conference on Machine Learning},
  pages={12600--12610},
  year={2021},
  organization={PMLR}
}
@article{mendonca2020meta,
  title={Meta-reinforcement learning robust to distributional shift via model identification and experience relabeling},
  author={Mendonca, Russell and Geng, Xinyang and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.07178},
  year={2020}
}

@article{kirsch2021introducing,
  title={Introducing Symmetries to Black Box Meta Reinforcement Learning},
  author={Kirsch, Louis and Flennerhag, Sebastian and van Hasselt, Hado and Friesen, Abram and Oh, Junhyuk and Chen, Yutian},
  journal={arXiv preprint arXiv:2109.10781},
  year={2021}
}

@article{kirsch2019improving,
  title={Improving generalization in meta reinforcement learning using learned objectives},
  author={Kirsch, Louis and van Steenkiste, Sjoerd and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1910.04098},
  year={2019}
}

@article{xu2020meta,
  title={Meta-gradient reinforcement learning with an objective discovered online},
  author={Xu, Zhongwen and van Hasselt, Hado P and Hessel, Matteo and Oh, Junhyuk and Singh, Satinder and Silver, David},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15254--15264},
  year={2020}
}
@article{co2021evolving,
  title={Evolving reinforcement learning algorithms},
  author={Co-Reyes, John D and Miao, Yingjie and Peng, Daiyi and Real, Esteban and Levine, Sergey and Le, Quoc V and Lee, Honglak and Faust, Aleksandra},
  journal={arXiv preprint arXiv:2101.03958},
  year={2021}
}

@inproceedings{EPG,
 author = {Houthooft, Rein and Chen, Yuhua and Isola, Phillip and Stadie, Bradly and Wolski, Filip and Jonathan Ho, OpenAI and Abbeel, Pieter},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Evolved Policy Gradients},
 url = {https://proceedings.neurips.cc/paper/2018/file/7876acb66640bad41f1e1371ef30c180-Paper.pdf},
 volume = {31},
 year = {2018}
}

