\begin{thebibliography}{65}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bengio et~al.(2000)Bengio, Ducharme, and Vincent]{NIPS2000_728f206c}
Bengio, Y., Ducharme, R., and Vincent, P.
\newblock A neural probabilistic language model.
\newblock In Leen, T., Dietterich, T., and Tresp, V. (eds.), \emph{Advances in
  Neural Information Processing Systems}, volume~13. MIT Press, 2000.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2000/file/728f206c2a01bf572b5940d7d9a8fa4c-Paper.pdf}.

\bibitem[Bernardo(1979)]{bernardo1979expected}
Bernardo, J.~M.
\newblock Expected information as expected utility.
\newblock \emph{the Annals of Statistics}, pp.\  686--690, 1979.

\bibitem[Brier(1950)]{brier1950verification}
Brier, G.~W.
\newblock Verification of forecasts expressed in terms of probability.
\newblock \emph{Monthly weather review}, 78\penalty0 (1):\penalty0 1--3, 1950.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 1877--1901, 2020.

\bibitem[Bröcker \& Smith(2007)Bröcker and
  Smith]{ScoringProbabilisticForecastsTheImportanceofBeingProper}
Bröcker, J. and Smith, L.~A.
\newblock Scoring probabilistic forecasts: The importance of being proper.
\newblock \emph{Weather and Forecasting}, 22\penalty0 (2):\penalty0 382 -- 388,
  2007.
\newblock \doi{https://doi.org/10.1175/WAF966.1}.
\newblock URL
  \url{https://journals.ametsoc.org/view/journals/wefo/22/2/waf966_1.xml}.

\bibitem[Dieng et~al.(2019)Dieng, Cho, Blei, and LeCun]{dieng2019learning}
Dieng, A.~B., Cho, K., Blei, D.~M., and LeCun, Y.
\newblock Learning with reflective likelihoods, 2019.
\newblock URL \url{https://openreview.net/forum?id=SJlh2jR9FX}.

\bibitem[Ehm \& Gneiting(2012)Ehm and Gneiting]{ehm2012local}
Ehm, W. and Gneiting, T.
\newblock Local proper scoring rules of order two.
\newblock \emph{The Annals of Statistics}, 40\penalty0 (1):\penalty0 609--637,
  2012.

\bibitem[Gneiting \& Raftery(2007)Gneiting and Raftery]{gneiting2007strictly}
Gneiting, T. and Raftery, A.~E.
\newblock Strictly proper scoring rules, prediction, and estimation.
\newblock \emph{Journal of the American statistical Association}, 102\penalty0
  (477):\penalty0 359--378, 2007.

\bibitem[Good(1952)]{good1952rational}
Good, I.~J.
\newblock Rational decisions.
\newblock \emph{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 14\penalty0 (1):\penalty0 107--114, 1952.

\bibitem[Gritsenko et~al.(2020)Gritsenko, Salimans, van~den Berg, Snoek, and
  Kalchbrenner]{NEURIPS2020_9873eaad}
Gritsenko, A., Salimans, T., van~den Berg, R., Snoek, J., and Kalchbrenner, N.
\newblock A spectral energy distance for parallel speech synthesis.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H.
  (eds.), \emph{Advances in Neural Information Processing Systems}, volume~33,
  pp.\  13062--13072. Curran Associates, Inc., 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2020/file/9873eaad153c6c960616c89e54fe155a-Paper.pdf}.

\bibitem[Gruber \& Buettner(2022)Gruber and Buettner]{NEURIPS2022_3915a87d}
Gruber, S. and Buettner, F.
\newblock Better uncertainty calibration via proper scores for classification
  and beyond.
\newblock In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and
  Oh, A. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~35, pp.\  8618--8632. Curran Associates, Inc., 2022.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2022/file/3915a87ddac8e8c2f23dbabbcee6eec9-Paper-Conference.pdf}.

\bibitem[Hermann et~al.(2015)Hermann, Kocisky, Grefenstette, Espeholt, Kay,
  Suleyman, and Blunsom]{NIPS2015_afdec700}
Hermann, K.~M., Kocisky, T., Grefenstette, E., Espeholt, L., Kay, W., Suleyman,
  M., and Blunsom, P.
\newblock Teaching machines to read and comprehend.
\newblock In Cortes, C., Lawrence, N., Lee, D., Sugiyama, M., and Garnett, R.
  (eds.), \emph{Advances in Neural Information Processing Systems}, volume~28.
  Curran Associates, Inc., 2015.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2015/file/afdec7005cc9f14302cd0474fd0f3c96-Paper.pdf}.

\bibitem[Hui \& Belkin(2021)Hui and Belkin]{hui2021evaluation}
Hui, L. and Belkin, M.
\newblock Evaluation of neural architectures trained with square loss vs
  cross-entropy in classification tasks.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=hsFN92eQEla}.

\bibitem[Hung et~al.(1996)Hung, Hu, Shanker, and Patuwo]{hung1996estimating}
Hung, M., Hu, M., Shanker, M., and Patuwo, B.
\newblock Estimating posterior probabilities in classification problems with
  neural networks.
\newblock \emph{International Journal of Computational Intelligence and
  Organizations}, 1\penalty0 (1):\penalty0 49--60, 1996.

\bibitem[Hyv{\"a}rinen \& Dayan(2005)Hyv{\"a}rinen and
  Dayan]{hyvarinen2005estimation}
Hyv{\"a}rinen, A. and Dayan, P.
\newblock Estimation of non-normalized statistical models by score matching.
\newblock \emph{Journal of Machine Learning Research}, 6\penalty0 (4), 2005.

\bibitem[Ji et~al.(2023)Ji, Ke, Hu, Zhang, and Huang]{ji2023tailoring}
Ji, H., Ke, P., Hu, Z., Zhang, R., and Huang, M.
\newblock Tailoring language generation models under total variation distance.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=VELL0PlWfc}.

\bibitem[Jiao et~al.(2023)Jiao, tse Huang, Wang, Wang, Shi, and
  Tu]{jiao2023parrot}
Jiao, W., tse Huang, J., Wang, W., Wang, X., Shi, S., and Tu, Z.
\newblock Parrot: Translating during chat using large language models.
\newblock \emph{arXiv preprint arXiv:2304.02426}, 2023.

\bibitem[Kang \& Hashimoto(2020)Kang and
  Hashimoto]{kang-hashimoto-2020-improved}
Kang, D. and Hashimoto, T.~B.
\newblock Improved natural language generation via loss truncation.
\newblock In Jurafsky, D., Chai, J., Schluter, N., and Tetreault, J. (eds.),
  \emph{Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics}, pp.\  718--731, Online, July 2020. Association
  for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.acl-main.66}.
\newblock URL \url{https://aclanthology.org/2020.acl-main.66}.

\bibitem[Kline \& Berardi(2005)Kline and Berardi]{Kline}
Kline, D. and Berardi, V.
\newblock Revisiting squared-error and cross-entropy functions for training
  neural network classifiers.
\newblock \emph{Neural Computing and Applications}, 14:\penalty0 310--318, 12
  2005.
\newblock \doi{10.1007/s00521-005-0467-y}.

\bibitem[Lakshminarayanan et~al.(2017)Lakshminarayanan, Pritzel, and
  Blundell]{lakshminarayanan2017simple}
Lakshminarayanan, B., Pritzel, A., and Blundell, C.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Lee \& Lee(2022)Lee and Lee]{ijcai2022p441}
Lee, K. and Lee, H.
\newblock Pseudo-spherical knowledge distillation.
\newblock In Raedt, L.~D. (ed.), \emph{Proceedings of the Thirty-First
  International Joint Conference on Artificial Intelligence, {IJCAI-22}}, pp.\
  3178--3184. International Joint Conferences on Artificial Intelligence
  Organization, 7 2022.
\newblock \doi{10.24963/ijcai.2022/441}.
\newblock URL \url{https://doi.org/10.24963/ijcai.2022/441}.
\newblock Main Track.

\bibitem[Li et~al.(2020)Li, Wang, Chen, Utiyama, Sumita, Zhang, and
  Zhao]{Li2020Data-dependent}
Li, Z., Wang, R., Chen, K., Utiyama, M., Sumita, E., Zhang, Z., and Zhao, H.
\newblock Data-dependent gaussian prior objective for language generation.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=S1efxTVYDr}.

\bibitem[Lin(2004)]{lin-2004-rouge}
Lin, C.-Y.
\newblock {ROUGE}: A package for automatic evaluation of summaries.
\newblock In \emph{Text Summarization Branches Out}, pp.\  74--81, Barcelona,
  Spain, July 2004. Association for Computational Linguistics.
\newblock URL \url{https://aclanthology.org/W04-1013}.

\bibitem[Liu et~al.(2021)Liu, Yan, Gong, Qi, Zhang, Jiao, Chen, Fu, Shou, Gong,
  Wang, Chen, Jiang, Lv, Zhang, Wu, Zhou, and
  Duan]{DBLP:conf/acl/LiuYGQZJCFSGWCJ21}
Liu, D., Yan, Y., Gong, Y., Qi, W., Zhang, H., Jiao, J., Chen, W., Fu, J.,
  Shou, L., Gong, M., Wang, P., Chen, J., Jiang, D., Lv, J., Zhang, R., Wu, W.,
  Zhou, M., and Duan, N.
\newblock {GLGE:} {A} new general language generation evaluation benchmark.
\newblock In Zong, C., Xia, F., Li, W., and Navigli, R. (eds.), \emph{Findings
  of the Association for Computational Linguistics: {ACL/IJCNLP} 2021, Online
  Event, August 1-6, 2021}, volume {ACL/IJCNLP} 2021 of \emph{Findings of
  {ACL}}, pp.\  408--420. Association for Computational Linguistics, 2021.
\newblock \doi{10.18653/v1/2021.findings-acl.36}.
\newblock URL \url{https://doi.org/10.18653/v1/2021.findings-acl.36}.

\bibitem[Liu et~al.(2023)Liu, Zeng, Meng, and Zhou]{liu2023instruction}
Liu, Y., Zeng, X., Meng, F., and Zhou, J.
\newblock Instruction position matters in sequence generation with large
  language models.
\newblock \emph{arXiv preprint arXiv:2308.12097}, 2023.

\bibitem[Martins \& Astudillo(2016)Martins and Astudillo]{pmlr-v48-martins16}
Martins, A. and Astudillo, R.
\newblock From softmax to sparsemax: A sparse model of attention and
  multi-label classification.
\newblock In Balcan, M.~F. and Weinberger, K.~Q. (eds.), \emph{Proceedings of
  The 33rd International Conference on Machine Learning}, volume~48 of
  \emph{Proceedings of Machine Learning Research}, pp.\  1614--1623, New York,
  New York, USA, 20--22 Jun 2016. PMLR.
\newblock URL \url{https://proceedings.mlr.press/v48/martins16.html}.

\bibitem[Martins et~al.(2020)Martins, Marinho, and
  Martins]{martins-etal-2020-sparse}
Martins, P.~H., Marinho, Z., and Martins, A. F.~T.
\newblock Sparse text generation.
\newblock In Webber, B., Cohn, T., He, Y., and Liu, Y. (eds.),
  \emph{Proceedings of the 2020 Conference on Empirical Methods in Natural
  Language Processing (EMNLP)}, pp.\  4252--4273, Online, November 2020.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.emnlp-main.348}.
\newblock URL \url{https://aclanthology.org/2020.emnlp-main.348}.

\bibitem[Mikolov et~al.(2010)Mikolov, Karafi{\'a}t, Burget, {\v C}ernock{\'y},
  and Khudanpur]{Mikolov2010RecurrentNN}
Mikolov, T., Karafi{\'a}t, M., Burget, L., {\v C}ernock{\'y}, J.~H., and
  Khudanpur, S.
\newblock Recurrent neural network based language model.
\newblock In \emph{Interspeech}, 2010.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:17048224}.

\bibitem[Myung(2003)]{myung2003tutorial}
Myung, I.~J.
\newblock Tutorial on maximum likelihood estimation.
\newblock \emph{Journal of mathematical Psychology}, 47\penalty0 (1):\penalty0
  90--100, 2003.

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin,
  Zhang, Agarwal, Slama, Gray, Schulman, Hilton, Kelton, Miller, Simens,
  Askell, Welinder, Christiano, Leike, and Lowe]{ouyang2022training}
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang,
  C., Agarwal, S., Slama, K., Gray, A., Schulman, J., Hilton, J., Kelton, F.,
  Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J.,
  and Lowe, R.
\newblock Training language models to follow instructions with human feedback.
\newblock In Oh, A.~H., Agarwal, A., Belgrave, D., and Cho, K. (eds.),
  \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=TG8KACxEON}.

\bibitem[Ovadia et~al.(2019)Ovadia, Fertig, Ren, Nado, Sculley, Nowozin,
  Dillon, Lakshminarayanan, and Snoek]{NEURIPS2019_8558cb40}
Ovadia, Y., Fertig, E., Ren, J., Nado, Z., Sculley, D., Nowozin, S., Dillon,
  J., Lakshminarayanan, B., and Snoek, J.
\newblock Can you trust your model\textquotesingle s uncertainty? evaluating
  predictive uncertainty under dataset shift.
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A., d\textquotesingle
  Alch\'{e}-Buc, F., Fox, E., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2019/file/8558cb408c1d76621371888657d2eb1d-Paper.pdf}.

\bibitem[Pacchiardi \& Dutta(2022)Pacchiardi and
  Dutta]{pacchiardi2022likelihood}
Pacchiardi, L. and Dutta, R.
\newblock Likelihood-free inference with generative neural networks via scoring
  rule minimization.
\newblock \emph{arXiv preprint arXiv:2205.15784}, 2022.

\bibitem[Pacchiardi et~al.(2021)Pacchiardi, Adewoyin, Dueben, and
  Dutta]{pacchiardi2021probabilistic}
Pacchiardi, L., Adewoyin, R., Dueben, P., and Dutta, R.
\newblock Probabilistic forecasting with generative networks via scoring rule
  minimization.
\newblock \emph{arXiv preprint arXiv:2112.08217}, 2021.

\bibitem[Pang \& He(2021)Pang and He]{pang2021text}
Pang, R.~Y. and He, H.
\newblock Text generation by learning from demonstrations.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=RovX-uQ1Hua}.

\bibitem[Papineni et~al.(2002)Papineni, Roukos, Ward, and
  Zhu]{papineni-etal-2002-bleu}
Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J.
\newblock {B}leu: a method for automatic evaluation of machine translation.
\newblock In \emph{Proceedings of the 40th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  311--318, Philadelphia, Pennsylvania,
  USA, July 2002. Association for Computational Linguistics.
\newblock \doi{10.3115/1073083.1073135}.
\newblock URL \url{https://aclanthology.org/P02-1040}.

\bibitem[Peters et~al.(2019)Peters, Niculae, and
  Martins]{peters-etal-2019-sparse}
Peters, B., Niculae, V., and Martins, A. F.~T.
\newblock Sparse sequence-to-sequence models.
\newblock In Korhonen, A., Traum, D., and M{\`a}rquez, L. (eds.),
  \emph{Proceedings of the 57th Annual Meeting of the Association for
  Computational Linguistics}, pp.\  1504--1519, Florence, Italy, July 2019.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P19-1146}.
\newblock URL \url{https://aclanthology.org/P19-1146}.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, Sutskever,
  et~al.]{radford2018improving}
Radford, A., Narasimhan, K., Salimans, T., Sutskever, I., et~al.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem[Ranzato et~al.(2016)Ranzato, Chopra, Auli, and
  Zaremba]{ranzato2015sequence}
Ranzato, M., Chopra, S., Auli, M., and Zaremba, W.
\newblock Sequence level training with recurrent neural networks.
\newblock In Bengio, Y. and LeCun, Y. (eds.), \emph{4th International
  Conference on Learning Representations, {ICLR} 2016, San Juan, Puerto Rico,
  May 2-4, 2016, Conference Track Proceedings}, 2016.
\newblock URL \url{http://arxiv.org/abs/1511.06732}.

\bibitem[Roby(1965)]{roby1965belief}
Roby, T.~B.
\newblock Belief states: A preliminary empirical study.
\newblock \emph{Behavioral Sci}, 10\penalty0 (3):\penalty0 255--270, 1965.

\bibitem[See et~al.(2017)See, Liu, and Manning]{see-etal-2017-get}
See, A., Liu, P.~J., and Manning, C.~D.
\newblock Get to the point: Summarization with pointer-generator networks.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pp.\  1073--1083,
  Vancouver, Canada, July 2017. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P17-1099}.
\newblock URL \url{https://aclanthology.org/P17-1099}.

\bibitem[Selten(1998)]{selten1998axiomatic}
Selten, R.
\newblock Axiomatic characterization of the quadratic scoring rule.
\newblock \emph{Experimental Economics}, 1:\penalty0 43--61, 1998.

\bibitem[Sennrich et~al.(2016)Sennrich, Haddow, and
  Birch]{DBLP:conf/acl/SennrichHB16a}
Sennrich, R., Haddow, B., and Birch, A.
\newblock Neural machine translation of rare words with subword units.
\newblock In \emph{Proceedings of the 54th Annual Meeting of the Association
  for Computational Linguistics, {ACL} 2016, August 7-12, 2016, Berlin,
  Germany, Volume 1: Long Papers}. The Association for Computer Linguistics,
  2016.
\newblock \doi{10.18653/v1/p16-1162}.
\newblock URL \url{https://doi.org/10.18653/v1/p16-1162}.

\bibitem[Shao et~al.(2019)Shao, Feng, Zhang, Meng, Chen, and
  Zhou]{shao-etal-2019-retrieving}
Shao, C., Feng, Y., Zhang, J., Meng, F., Chen, X., and Zhou, J.
\newblock Retrieving sequential information for non-autoregressive neural
  machine translation.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  3013--3024, Florence, Italy, July 2019.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P19-1288}.
\newblock URL \url{https://www.aclweb.org/anthology/P19-1288}.

\bibitem[Shao et~al.(2021)Shao, Feng, Zhang, Meng, and
  Zhou]{DBLP:journals/corr/abs-2106-08122}
Shao, C., Feng, Y., Zhang, J., Meng, F., and Zhou, J.
\newblock {Sequence-Level Training for Non-Autoregressive Neural Machine
  Translation}.
\newblock \emph{Computational Linguistics}, pp.\  1--35, 10 2021.
\newblock ISSN 0891-2017.
\newblock \doi{10.1162/coli_a_00421}.
\newblock URL \url{https://doi.org/10.1162/coli\_a\_00421}.

\bibitem[Shao et~al.(2023)Shao, Ma, Zhang, and Feng]{shao2023beyond}
Shao, C., Ma, Z., Zhang, M., and Feng, Y.
\newblock Beyond mle: Convex learning for text generation.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing
  Systems}, 2023.

\bibitem[Shen et~al.(2016)Shen, Cheng, He, He, Wu, Sun, and
  Liu]{shen-etal-2016-minimum}
Shen, S., Cheng, Y., He, Z., He, W., Wu, H., Sun, M., and Liu, Y.
\newblock Minimum risk training for neural machine translation.
\newblock In \emph{Proceedings of the 54th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pp.\  1683--1692,
  Berlin, Germany, August 2016. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P16-1159}.
\newblock URL \url{https://aclanthology.org/P16-1159}.

\bibitem[Shoemaker(1991)]{80304}
Shoemaker, P.
\newblock A note on least-squares learning procedures and classification by
  neural network models.
\newblock \emph{IEEE Transactions on Neural Networks}, 2\penalty0 (1):\penalty0
  158--160, 1991.
\newblock \doi{10.1109/72.80304}.

\bibitem[Shuford~Jr et~al.(1966)Shuford~Jr, Albert, and
  Edward~Massengill]{shuford1966admissible}
Shuford~Jr, E.~H., Albert, A., and Edward~Massengill, H.
\newblock Admissible probability measurement procedures.
\newblock \emph{Psychometrika}, 31\penalty0 (2):\penalty0 125--145, 1966.

\bibitem[Song \& Ermon(2019)Song and Ermon]{NEURIPS2019_3001ef25}
Song, Y. and Ermon, S.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A., d\textquotesingle
  Alch\'{e}-Buc, F., Fox, E., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2019/file/3001ef257407d5a371a96dcd947c7d93-Paper.pdf}.

\bibitem[Song et~al.(2021)Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and
  Poole]{song2021scorebased}
Song, Y., Sohl-Dickstein, J., Kingma, D.~P., Kumar, A., Ermon, S., and Poole,
  B.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=PxTIG12RRHS}.

\bibitem[Stahlberg \& Kumar(2022)Stahlberg and Kumar]{stahlberg-kumar-2022-jam}
Stahlberg, F. and Kumar, S.
\newblock Jam or cream first? modeling ambiguity in neural machine translation
  with {SCONES}.
\newblock In Carpuat, M., de~Marneffe, M.-C., and Meza~Ruiz, I.~V. (eds.),
  \emph{Proceedings of the 2022 Conference of the North American Chapter of the
  Association for Computational Linguistics: Human Language Technologies}, pp.\
   4950--4961, Seattle, United States, July 2022. Association for Computational
  Linguistics.
\newblock \doi{10.18653/v1/2022.naacl-main.365}.
\newblock URL \url{https://aclanthology.org/2022.naacl-main.365}.

\bibitem[Stiennon et~al.(2020)Stiennon, Ouyang, Wu, Ziegler, Lowe, Voss,
  Radford, Amodei, and Christiano]{NEURIPS2020_1f89885d}
Stiennon, N., Ouyang, L., Wu, J., Ziegler, D., Lowe, R., Voss, C., Radford, A.,
  Amodei, D., and Christiano, P.~F.
\newblock Learning to summarize with human feedback.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H.
  (eds.), \emph{Advances in Neural Information Processing Systems}, volume~33,
  pp.\  3008--3021. Curran Associates, Inc., 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2020/file/1f89885d556929e98d3ef9b86448f951-Paper.pdf}.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{szegedy2016rethinking}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  2818--2826, 2016.

\bibitem[Taori et~al.(2023)Taori, Gulrajani, Zhang, Dubois, Li, Guestrin,
  Liang, and Hashimoto]{alpaca}
Taori, R., Gulrajani, I., Zhang, T., Dubois, Y., Li, X., Guestrin, C., Liang,
  P., and Hashimoto, T.~B.
\newblock Stanford alpaca: An instruction-following llama model.
\newblock \url{https://github.com/tatsu-lab/stanford_alpaca}, 2023.

\bibitem[Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux,
  Lacroix, Rozière, Goyal, Hambro, Azhar, Rodriguez, Joulin, Grave, and
  Lample]{touvron2023llama}
Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix,
  T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin,
  A., Grave, E., and Lample, G.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{DBLP:conf/nips/VaswaniSPUJGKP17}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, L.~u., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In Guyon, I., Luxburg, U.~V., Bengio, S., Wallach, H., Fergus, R.,
  Vishwanathan, S., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}.

\bibitem[Wang et~al.(2022)Wang, Kordi, Mishra, Liu, Smith, Khashabi, and
  Hajishirzi]{selfinstruct}
Wang, Y., Kordi, Y., Mishra, S., Liu, A., Smith, N.~A., Khashabi, D., and
  Hajishirzi, H.
\newblock Self-instruct: Aligning language model with self generated
  instructions.
\newblock \emph{arXiv preprint arXiv:2212.10560}, 2022.

\bibitem[Welleck et~al.(2020)Welleck, Kulikov, Roller, Dinan, Cho, and
  Weston]{Welleck2020Neural}
Welleck, S., Kulikov, I., Roller, S., Dinan, E., Cho, K., and Weston, J.
\newblock Neural text generation with unlikelihood training.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=SJeYe0NtvH}.

\bibitem[Xu et~al.(2021)Xu, Zhou, Gan, Zheng, and Li]{xu-etal-2021-vocabulary}
Xu, J., Zhou, H., Gan, C., Zheng, Z., and Li, L.
\newblock Vocabulary learning via optimal transport for neural machine
  translation.
\newblock In \emph{Proceedings of the 59th Annual Meeting of the Association
  for Computational Linguistics and the 11th International Joint Conference on
  Natural Language Processing (Volume 1: Long Papers)}, pp.\  7361--7373,
  Online, August 2021. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2021.acl-long.571}.
\newblock URL \url{https://aclanthology.org/2021.acl-long.571}.

\bibitem[Yang et~al.(2018)Yang, Chen, Wang, and Xu]{yang-etal-2018-improving}
Yang, Z., Chen, W., Wang, F., and Xu, B.
\newblock Improving neural machine translation with conditional sequence
  generative adversarial nets.
\newblock In Walker, M., Ji, H., and Stent, A. (eds.), \emph{Proceedings of the
  2018 Conference of the North {A}merican Chapter of the Association for
  Computational Linguistics: Human Language Technologies, Volume 1 (Long
  Papers)}, pp.\  1346--1355, New Orleans, Louisiana, June 2018. Association
  for Computational Linguistics.
\newblock \doi{10.18653/v1/N18-1122}.
\newblock URL \url{https://aclanthology.org/N18-1122}.

\bibitem[Yu et~al.(2017)Yu, Zhang, Wang, and Yu]{yu2017seqgan}
Yu, L., Zhang, W., Wang, J., and Yu, Y.
\newblock Seqgan: Sequence generative adversarial nets with policy gradient.
\newblock In \emph{Proceedings of the Thirty-First AAAI Conference on
  Artificial Intelligence}, AAAI'17, pp.\  2852--2858. AAAI Press, 2017.

\bibitem[Yu et~al.(2021)Yu, Song, Song, and Ermon]{NEURIPS2021_bc5fcb00}
Yu, L., Song, J., Song, Y., and Ermon, S.
\newblock Pseudo-spherical contrastive divergence.
\newblock In Ranzato, M., Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan,
  J.~W. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~34, pp.\  22348--22362. Curran Associates, Inc., 2021.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2021/file/bc5fcb0018cecacba559dc512740091b-Paper.pdf}.

\bibitem[Zeng et~al.(2023)Zeng, Meng, Yin, and Zhou]{zeng2023tim}
Zeng, J., Meng, F., Yin, Y., and Zhou, J.
\newblock Tim: Teaching large language models to translate with comparison.
\newblock \emph{arXiv preprint arXiv:2307.04408}, 2023.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Fang, Zhang, Ma, Zhou, Huang,
  Bu, Gui, Chen, Chen, and Feng]{bayling}
Zhang, S., Fang, Q., Zhang, Z., Ma, Z., Zhou, Y., Huang, L., Bu, M., Gui, S.,
  Chen, Y., Chen, X., and Feng, Y.
\newblock Bayling: Bridging cross-lingual alignment and instruction following
  through interactive translation for large language models.
\newblock \emph{arXiv preprint arXiv:2306.10968}, 2023{\natexlab{a}}.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Wu, Irsoy, Lu, Bansal, Dredze,
  and Rosenberg]{zhang-etal-2023-mixce}
Zhang, S., Wu, S., Irsoy, O., Lu, S., Bansal, M., Dredze, M., and Rosenberg, D.
\newblock {M}ix{CE}: Training autoregressive language models by mixing forward
  and reverse cross-entropies.
\newblock In Rogers, A., Boyd-Graber, J., and Okazaki, N. (eds.),
  \emph{Proceedings of the 61st Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers)}, pp.\  9027--9050,
  Toronto, Canada, July 2023{\natexlab{b}}. Association for Computational
  Linguistics.
\newblock \doi{10.18653/v1/2023.acl-long.502}.
\newblock URL \url{https://aclanthology.org/2023.acl-long.502}.

\end{thebibliography}
