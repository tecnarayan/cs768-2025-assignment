\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{FGRW12}

\bibitem[ABSS97]{AroraBSS97}
Sanjeev Arora, L{\'{a}}szl{\'{o}} Babai, Jacques Stern, and Z.~Sweedyk.
\newblock The hardness of approximate optima in lattices, codes, and systems of
  linear equations.
\newblock {\em J. Comput. Syst. Sci.}, 54(2):317--331, 1997.

\bibitem[ADV19]{AwasthiDV19}
Pranjal Awasthi, Abhratanu Dutta, and Aravindan Vijayaraghavan.
\newblock On robustness to adversarial examples and polynomial optimization.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  13737--13747, 2019.

\bibitem[AL88]{AL88}
Dana Angluin and Philip Laird.
\newblock Learning from noisy examples.
\newblock {\em Mach. Learn.}, 2(4):343--370, 1988.

\bibitem[AS18]{AggarwalS18}
Divesh Aggarwal and Noah Stephens{-}Davidowitz.
\newblock {(Gap/S)ETH} hardness of {SVP}.
\newblock In {\em STOC}, pages 228--238, 2018.

\bibitem[Bar75]{Baranyai75}
Zsolt Baranyai.
\newblock On the factorization of the complete uniform hypergraph.
\newblock {\em Infinite and Finite Sets, Proc. Coll. Keszthely}, 10:91--107,
  1975.

\bibitem[BB14]{BalcanB14}
Maria{-}Florina Balcan and Christopher Berlind.
\newblock A new perspective on learning linear separators with large $l_q l_p$
  margins.
\newblock In {\em AISTATS}, pages 68--76, 2014.

\bibitem[BBE{\etalchar{+}}19]{BhattacharyyaBE19}
Arnab Bhattacharyya, {\'{E}}douard Bonnet, L{\'{a}}szl{\'{o}} Egri, Suprovat
  Ghoshal, {Karthik {C. S.}}, Bingkai Lin, Pasin Manurangsi, and D{\'{a}}niel
  Marx.
\newblock Parameterized intractability of even set and shortest vector problem.
\newblock {\em Electronic Colloquium on Computational Complexity {(ECCC)}},
  26:115, 2019.

\bibitem[BCM{\etalchar{+}}13]{BiggioCMNSLGR13}
Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim Srndic,
  Pavel Laskov, Giorgio Giacinto, and Fabio Roli.
\newblock Evasion attacks against machine learning at test time.
\newblock In {\em ECML PKDD}, pages 387--402, 2013.

\bibitem[Ber41]{Berry41}
Andrew~C. Berry.
\newblock The accuracy of the {G}aussian approximation to the sum of
  independent variates.
\newblock {\em Transactions of the American Mathematical Society},
  49(1):122--136, 1941.

\bibitem[BGKM18]{BhattacharyyaGS18}
Arnab Bhattacharyya, Suprovat Ghoshal, {Karthik {C. S.}}, and Pasin Manurangsi.
\newblock Parameterized intractability of even set and shortest vector problem
  from {Gap-ETH}.
\newblock In {\em ICALP}, pages 17:1--17:15, 2018.

\bibitem[BGS17]{BennettGS17}
Huck Bennett, Alexander Golovnev, and Noah Stephens{-}Davidowitz.
\newblock On the quantitative hardness of {CVP}.
\newblock In {\em FOCS}, pages 13--24, 2017.

\bibitem[BLPR19]{BubeckLPR19}
Sebastien Bubeck, Yin-Tat Lee, Eric Price, and Ilya~P. Razenshteyn.
\newblock Adversarial examples from computational constraints.
\newblock In {\em ICML}, pages 831--840, 2019.

\bibitem[BM02]{BartlettM02}
Peter~L. Bartlett and Shahar Mendelson.
\newblock Rademacher and gaussian complexities: Risk bounds and structural
  results.
\newblock {\em Journal of Machine Learning Research}, 3:463--482, 2002.

\bibitem[BS00]{BenDavidS00}
Shai Ben{-}David and Hans~Ulrich Simon.
\newblock Efficient learning of linear perceptrons.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  189--195, 2000.

\bibitem[BS12]{BirnbaumS12}
Aharon Birnbaum and Shai Shalev{-}Shwartz.
\newblock Learning halfspaces with the zero-one loss: Time-accuracy tradeoffs.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  935--943, 2012.

\bibitem[CBM18]{CullinaBM18}
Daniel Cullina, Arjun~Nitin Bhagoji, and Prateek Mittal.
\newblock Pac-learning in the presence of adversaries.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  228--239, 2018.

\bibitem[CCK{\etalchar{+}}17]{ChalermsookCKLM17}
Parinya Chalermsook, Marek Cygan, Guy Kortsarz, Bundit Laekhanukit, Pasin
  Manurangsi, Danupon Nanongkai, and Luca Trevisan.
\newblock From {Gap-ETH} to {FPT}-inapproximability: Clique, dominating set,
  and more.
\newblock In {\em FOCS}, pages 743--754, 2017.

\bibitem[CGK{\etalchar{+}}19]{Cohen-AddadG0LL19}
Vincent Cohen{-}Addad, Anupam Gupta, Amit Kumar, Euiwoong Lee, and Jason Li.
\newblock Tight {FPT} approximations for k-median and k-means.
\newblock In {\em ICALP}, pages 42:1--42:14, 2019.

\bibitem[CL19]{ChenL19}
Yijia Chen and Bingkai Lin.
\newblock The constant inapproximability of the parameterized dominating set
  problem.
\newblock {\em {SIAM} J. Comput.}, 48(2):513--533, 2019.

\bibitem[CM18]{KM-tutorial}
Zico Colter and Aleksander Madry.
\newblock Adversarial robustness - theory and practice.
\newblock NeurIPS 2018 tutorial, available at
  https://adversarial-ml-tutorial.org/, 2018.

\bibitem[Din16]{Dinur16}
Irit Dinur.
\newblock Mildly exponential reduction from gap {3SAT} to polynomial-gap
  label-cover.
\newblock {\em Electronic Colloquium on Computational Complexity {(ECCC)}},
  23:128, 2016.

\bibitem[DKM19]{DiakonikolasKM19}
Ilias Diakonikolas, Daniel Kane, and Pasin Manurangsi.
\newblock Nearly tight bounds for robust proper learning of halfspaces with a
  margin.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  10473--10484, 2019.

\bibitem[DM18]{DinurM18}
Irit Dinur and Pasin Manurangsi.
\newblock {ETH}-hardness of approximating 2-{CSPs} and directed steiner
  network.
\newblock In {\em ITCS}, pages 36:1--36:20, 2018.

\bibitem[DNV19]{DegwekarNV19}
Akshay Degwekar, Preetum Nakkiran, and Vinod Vaikuntanathan.
\newblock Computational limitations in robust classification and win-win
  results.
\newblock In {\em COLT}, pages 994--1028, 2019.

\bibitem[DS14]{DinurS14}
Irit Dinur and David Steurer.
\newblock Analytical approach to parallel repetition.
\newblock In {\em STOC}, pages 624--633, 2014.

\bibitem[Ess42]{Esseen42}
Carl-Gustav Esseen.
\newblock On the {L}iapunoff limit of error in the theory of probability.
\newblock {\em Arkiv f{\"o}r matematik, astronomi och fysik}, A28:1--19, 1942.

\bibitem[Fei98]{Feige98}
Uriel Feige.
\newblock A threshold of ln \emph{n} for approximating set cover.
\newblock {\em J. {ACM}}, 45(4):634--652, 1998.

\bibitem[FGKP06]{FeldmanGKP06}
Vitaly Feldman, Parikshit Gopalan, Subhash Khot, and Ashok~Kumar Ponnuswami.
\newblock New results for learning noisy parities and halfspaces.
\newblock In {\em FOCS}, pages 563--574, 2006.

\bibitem[FGRW12]{FeldmanGRW12}
Vitaly Feldman, Venkatesan Guruswami, Prasad Raghavendra, and Yi~Wu.
\newblock Agnostic learning of monomials by halfspaces is hard.
\newblock {\em {SIAM} J. Comput.}, 41(6):1558--1590, 2012.

\bibitem[FS97]{FreundSchapire:97}
Yoav Freund and Robert Schapire.
\newblock A decision-theoretic generalization of on-line learning and an
  application to boosting.
\newblock {\em J. Comput. Syst. Sci.}, 55(1):119--139, 1997.

\bibitem[Gen01a]{Gentile01}
Claudio Gentile.
\newblock A new approximate maximal margin classification algorithm.
\newblock {\em J. Mach. Learn. Res.}, 2:213--242, 2001.

\bibitem[Gen01b]{Gentile:01}
Claudio Gentile.
\newblock A new approximate maximal margin classification algorithm.
\newblock {\em Journal of Machine Learning Research}, 2:213--242, 2001.

\bibitem[Gen03]{Gentile03a}
Claudio Gentile.
\newblock The robustness of the p-norm algorithms.
\newblock {\em Mach. Learn.}, 53(3):265--299, 2003.

\bibitem[GLS01]{GroveLS01}
Adam~J. Grove, Nick Littlestone, and Dale Schuurmans.
\newblock General convergence results for linear discriminant updates.
\newblock {\em Mach. Learn.}, 43(3):173--210, 2001.

\bibitem[GR09]{GuruswamiR09}
Venkatesan Guruswami and Prasad Raghavendra.
\newblock Hardness of learning halfspaces with noise.
\newblock {\em {SIAM} J. Comput.}, 39(2):742--765, 2009.

\bibitem[GSS15]{GoodfellowSS14}
Ian~J. Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In {\em ICLR}, 2015.

\bibitem[H{\aa}s96]{Hastad96}
Johan H{\aa}stad.
\newblock Clique is hard to approximate within $n^{1 - \epsilon}$.
\newblock In {\em FOCS}, pages 627--636, 1996.

\bibitem[H{\aa}s01]{Hastad01}
Johan H{\aa}stad.
\newblock Some optimal inapproximability results.
\newblock {\em J. {ACM}}, 48(4):798--859, 2001.

\bibitem[Hau92]{Haussler:92}
David Haussler.
\newblock {Decision theoretic generalizations of the PAC model for neural net
  and other learning applications}.
\newblock {\em Information and Computation}, 100:78--150, 1992.

\bibitem[IP01]{IP01}
Russell Impagliazzo and Ramamohan Paturi.
\newblock On the complexity of k-{SAT}.
\newblock {\em J. Comput. Syst. Sci.}, 62(2):367--375, 2001.

\bibitem[IPZ01]{IPZ01}
Russell Impagliazzo, Ramamohan Paturi, and Francis Zane.
\newblock Which problems have strongly exponential complexity?
\newblock {\em J. Comput. Syst. Sci.}, 63(4):512--530, 2001.

\bibitem[JKR19]{JainKR19}
Vishesh Jain, Frederic Koehler, and Andrej Risteski.
\newblock Mean-field approximation, convex hierarchies, and the optimality of
  correlation rounding: a unified perspective.
\newblock In {\em STOC}, pages 1226--1236, 2019.

\bibitem[KLM19]{SLM19}
{Karthik {C. S.}}, Bundit Laekhanukit, and Pasin Manurangsi.
\newblock On the parameterized complexity of approximating dominating set.
\newblock {\em J. {ACM}}, 66(5):33:1--33:38, 2019.

\bibitem[KP02]{Koltchinskii2002}
Vladimir Koltchinskii and Dmitry Panchenko.
\newblock Empirical margin distributions and bounding the generalization error
  of combined classifiers.
\newblock {\em Ann. Statist.}, 30(1):1--50, 02 2002.

\bibitem[KSS94]{KSS:94}
Michael Kearns, Robert Schapire, and Linda Sellie.
\newblock {Toward Efficient Agnostic Learning}.
\newblock {\em Machine Learning}, 17(2/3):115--141, 1994.

\bibitem[KST08]{KakadeST08}
Sham~M. Kakade, Karthik Sridharan, and Ambuj Tewari.
\newblock On the complexity of linear prediction: Risk bounds, margin bounds,
  and regularization.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  793--800, 2008.

\bibitem[Lin19]{Lin19}
Bingkai Lin.
\newblock A simple gap-producing reduction for the parameterized set cover
  problem.
\newblock In {\em ICALP}, pages 81:1--81:15. Schloss Dagstuhl - Leibniz-Zentrum
  f{\"{u}}r Informatik, 2019.

\bibitem[Lit87]{Lit87}
Nick Littlestone.
\newblock Learning quickly when irrelevant attributes abound: A new
  linear-threshold algorithm.
\newblock {\em Machine Learning}, 2(4):285--318, 1987.

\bibitem[LMS11]{LokshtanovMS11}
Daniel Lokshtanov, D{\'{a}}niel Marx, and Saket Saurabh.
\newblock Lower bounds based on the exponential time hypothesis.
\newblock {\em Bulletin of the {EATCS}}, 105:41--72, 2011.

\bibitem[LS11]{LS:11malicious}
Phil Long and Rocco Servedio.
\newblock Learning large-margin halfspaces with more malicious noise.
\newblock {\em Advances in Neural Information Processing Systems}, 2011.

\bibitem[Man20]{M20}
Pasin Manurangsi.
\newblock Tight running time lower bounds for strong inapproximability of
  maximum \emph{k}-coverage, unique set cover and related problems (via
  \emph{t}-wise agreement testing theorem).
\newblock In {\em SODA}, pages 62--81, 2020.

\bibitem[Mar13]{Marx13}
D{\'{a}}niel Marx.
\newblock Completely inapproximable monotone and antimonotone parameterized
  problems.
\newblock {\em J. Comput. Syst. Sci.}, 79(1):144--151, 2013.

\bibitem[MGDS20]{MonGDS20}
Omar Montasser, Surbhi Goel, Ilias Diakonikolas, and Nathan Srebro.
\newblock Efficiently learning adversarially robust halfspaces with noise.
\newblock {\em CoRR}, abs/2005.07652, 2020.

\bibitem[MHS19]{MontasserHS19}
Omar Montasser, Steve Hanneke, and Nathan Srebro.
\newblock {VC} classes are adversarially robustly learnable, but only
  improperly.
\newblock In {\em COLT}, pages 2512--2530, 2019.

\bibitem[MR10]{MoshkovitzR10}
Dana Moshkovitz and Ran Raz.
\newblock Two-query {PCP} with subconstant error.
\newblock {\em J. {ACM}}, 57(5):29:1--29:29, 2010.

\bibitem[MR17]{MR17}
Pasin Manurangsi and Prasad Raghavendra.
\newblock A birthday repetition theorem and complexity of approximating dense
  {CSP}s.
\newblock In {\em ICALP}, pages 78:1--78:15, 2017.

\bibitem[Raz98]{Raz98}
Ran Raz.
\newblock A parallel repetition theorem.
\newblock {\em {SIAM} J. Comput.}, 27(3):763--803, 1998.

\bibitem[Ros58]{Rosenblatt:58}
Frank Rosenblatt.
\newblock The {P}erceptron: a probabilistic model for information storage and
  organization in the brain.
\newblock {\em Psychological Review}, 65:386--407, 1958.

\bibitem[SSS09]{SSS09}
Shai Shalev{-}Shwartz, Ohad Shamir, and Karthik Sridharan.
\newblock Agnostically learning halfspaces with margin errors.
\newblock In {\em Technical report, Toyota Technological Institute}, 2009.

\bibitem[SSS10]{SSS10}
Shai Shalev{-}Shwartz, Ohad Shamir, and Karthik Sridharan.
\newblock Learning kernel-based halfspaces with the zero-one loss.
\newblock In {\em COLT}, pages 441--450, 2010.

\bibitem[SST{\etalchar{+}}18]{SchmidtSTTM18}
Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, and
  Aleksander Madry.
\newblock Adversarially robust generalization requires more data.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  5019--5031, 2018.

\bibitem[SZS{\etalchar{+}}14]{SzegedyZSBEGF13}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian~J. Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In {\em ICLR}, 2014.

\bibitem[Vap98]{Vapnik:98}
Vladimir Vapnik.
\newblock {\em Statistical Learning Theory}.
\newblock Wiley-Interscience, New York, 1998.

\end{thebibliography}
