\begin{thebibliography}{56}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alemi et~al.(2017)Alemi, Fischer, Dillon, and
  Murphy]{alemi:deepvib2017}
Alemi, A.~A., Fischer, I., Dillon, J.~V., and Murphy, K.
\newblock Deep variational information bottleneck.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Alzantot et~al.(2018{\natexlab{a}})Alzantot, Sharma, Chakraborty, and
  Srivastava]{alzantot2018genattack}
Alzantot, M., Sharma, Y., Chakraborty, S., and Srivastava, M.
\newblock Genattack: Practical black-box attacks with gradient-free
  optimization.
\newblock \emph{arXiv preprint arXiv:1805.11090}, 2018{\natexlab{a}}.

\bibitem[Alzantot et~al.(2018{\natexlab{b}})Alzantot, Sharma, Elgohary, Ho,
  Srivastava, and Chang]{alzantot2018nlp}
Alzantot, M., Sharma, Y., Elgohary, A., Ho, B.-J., Srivastava, M., and Chang,
  K.-W.
\newblock Generating natural language adversarial examples.
\newblock \emph{arXiv preprint arXiv:1804.07998}, 2018{\natexlab{b}}.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and
  Wagner]{athalye:obfuscated2018}
Athalye, A., Carlini, N., and Wagner, D.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  274--283, 2018.

\bibitem[Biggio et~al.(2011)Biggio, Fumera, and Roli]{biggio:robustness2011}
Biggio, B., Fumera, G., and Roli, F.
\newblock Design of robust classifiers for adversarial environments.
\newblock In \emph{Systems, Man, and Cybernetics (SMC), 2011 IEEE International
  Conference on}, pp.\  977--982. IEEE, 2011.

\bibitem[Biggio et~al.(2013)Biggio, Corona, Maiorca, Nelson, {\v{S}}rndi{\'c},
  Laskov, Giacinto, and Roli]{biggio2013evasion}
Biggio, B., Corona, I., Maiorca, D., Nelson, B., {\v{S}}rndi{\'c}, N., Laskov,
  P., Giacinto, G., and Roli, F.
\newblock Evasion attacks against machine learning at test time.
\newblock In \emph{Joint European conference on machine learning and knowledge
  discovery in databases}, pp.\  387--402. Springer, 2013.

\bibitem[Biggio et~al.(2014)Biggio, Fumera, and Roli]{biggio:security2014}
Biggio, B., Fumera, G., and Roli, F.
\newblock Security evaluation of pattern classifiers under attack.
\newblock \emph{IEEE transactions on knowledge and data engineering},
  26\penalty0 (4):\penalty0 984--996, 2014.

\bibitem[Brendel et~al.(2018)Brendel, Rauber, and Bethge]{brendel2017decision}
Brendel, W., Rauber, J., and Bethge, M.
\newblock Decision-based adversarial attacks: Reliable attacks against
  black-box machine learning models.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=SyZI0GWCZ}.

\bibitem[Carlini \& Wagner(2017{\natexlab{a}})Carlini and
  Wagner]{carlini:attack2017}
Carlini, N. and Wagner, D.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{Security and Privacy (SP), 2017 IEEE Symposium on}, pp.\
  39--57. IEEE, 2017{\natexlab{a}}.

\bibitem[Carlini \& Wagner(2017{\natexlab{b}})Carlini and
  Wagner]{carlini:bypass2017}
Carlini, N. and Wagner, D.
\newblock Adversarial examples are not easily detected: Bypassing ten detection
  methods.
\newblock In \emph{Proceedings of the 10th ACM Workshop on Artificial
  Intelligence and Security}, pp.\  3--14. ACM, 2017{\natexlab{b}}.

\bibitem[Carlini \& Wagner(2018)Carlini and Wagner]{carlini:audio2018}
Carlini, N. and Wagner, D.
\newblock Audio adversarial examples: Targeted attacks on speech-to-text.
\newblock \emph{arXiv preprint arXiv:1801.01944}, 2018.

\bibitem[Chen et~al.(2017)Chen, Zhang, Sharma, Yi, and Hsieh]{chen2017zoo}
Chen, P.~Y., Zhang, H., Sharma, Y., Yi, J., and Hsieh, C.
\newblock Zoo: Zeroth order optimization based black-box attacks to deep neural
  networks without training substitute models.
\newblock In \emph{Proceedings of the 10th ACM Workshop on Artificial
  Intelligence and Security}, pp.\  15--26. ACM, 2017.

\bibitem[Chen et~al.(2018)Chen, Sharma, Zhang, Yi, and Hsieh]{chen:ead2017}
Chen, P.-Y., Sharma, Y., Zhang, H., Yi, J., and Hsieh, C.-J.
\newblock Ead: Elastic-net attacks to deep neural networks via adversarial
  examples, 2018.

\bibitem[Creswell et~al.(2017)Creswell, Bharath, and
  Sengupta]{creswell:latentpoison2017}
Creswell, A., Bharath, A.~A., and Sengupta, B.
\newblock Latentpoison-adversarial attacks on the latent space.
\newblock \emph{arXiv preprint arXiv:1711.02879}, 2017.

\bibitem[Dalvi et~al.(2004)Dalvi, Domingos, Sanghai, Verma,
  et~al.]{dalvi:adversarial2004}
Dalvi, N., Domingos, P., Sanghai, S., Verma, D., et~al.
\newblock Adversarial classification.
\newblock In \emph{Proceedings of the tenth ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pp.\  99--108. ACM, 2004.

\bibitem[Dong et~al.(2018)Dong, Liao, Pang, Su, Zhu, Hu, and Li]{dong:mim2017}
Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., and Li, J.
\newblock Boosting adversarial attacks with momentum.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  9185--9193, 2018.

\bibitem[Dosovitskiy \& Brox(2016)Dosovitskiy and
  Brox]{dosovitskiy2016generating}
Dosovitskiy, A. and Brox, T.
\newblock Generating images with perceptual similarity metrics based on deep
  networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  658--666, 2016.

\bibitem[Efron(1975)]{efron:efficiency1975}
Efron, B.
\newblock The efficiency of logistic regression compared to normal discriminant
  analysis.
\newblock \emph{Journal of the American Statistical Association}, 70\penalty0
  (352):\penalty0 892--898, 1975.

\bibitem[Feinman et~al.(2017)Feinman, Curtin, Shintre, and
  Gardner]{feinman:detecting2017}
Feinman, R., Curtin, R.~R., Shintre, S., and Gardner, A.~B.
\newblock Detecting adversarial samples from artifacts.
\newblock \emph{arXiv preprint arXiv:1703.00410}, 2017.

\bibitem[Fisher(1936)]{fisher:lda1936}
Fisher, R.~A.
\newblock The use of multiple measurements in taxonomic problems.
\newblock \emph{Annals of human genetics}, 7\penalty0 (2):\penalty0 179--188,
  1936.

\bibitem[Gatys et~al.(2016)Gatys, Ecker, and Bethge]{gatys2016image}
Gatys, L.~A., Ecker, A.~S., and Bethge, M.
\newblock Image style transfer using convolutional neural networks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  2414--2423, 2016.

\bibitem[Gilmer et~al.(2018)Gilmer, Metz, Faghri, Schoenholz, Raghu,
  Wattenberg, and Goodfellow]{gilmer:sphere2018}
Gilmer, J., Metz, L., Faghri, F., Schoenholz, S.~S., Raghu, M., Wattenberg, M.,
  and Goodfellow, I.
\newblock Adversarial spheres.
\newblock \emph{arXiv preprint arXiv:1801.02774}, 2018.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow:gan2014}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2672--2680, 2014.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow:explaining2014}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Gu \& Rigazio(2014)Gu and Rigazio]{gu:towards2014}
Gu, S. and Rigazio, L.
\newblock Towards deep neural network architectures robust to adversarial
  examples.
\newblock \emph{arXiv preprint arXiv:1412.5068}, 2014.

\bibitem[Huang et~al.(2011)Huang, Joseph, Nelson, Rubinstein, and
  Tygar]{huang:adversarial2011}
Huang, L., Joseph, A.~D., Nelson, B., Rubinstein, B.~I., and Tygar, J.
\newblock Adversarial machine learning.
\newblock In \emph{Proceedings of the 4th ACM workshop on Security and
  artificial intelligence}, pp.\  43--58. ACM, 2011.

\bibitem[Johnson et~al.(2016)Johnson, Alahi, and
  Fei-Fei]{johnson2016perceptual}
Johnson, J., Alahi, A., and Fei-Fei, L.
\newblock Perceptual losses for real-time style transfer and super-resolution.
\newblock In \emph{European Conference on Computer Vision}, pp.\  694--711.
  Springer, 2016.

\bibitem[Karras et~al.(2018)Karras, Aila, Laine, and
  Lehtinen]{karras2018progressive}
Karras, T., Aila, T., Laine, S., and Lehtinen, J.
\newblock Progressive growing of {GAN}s for improved quality, stability, and
  variation.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=Hk99zCeAb}.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{kingma:vae2013}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational {B}ayes.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Kos et~al.(2017)Kos, Fischer, and Song]{kos:adversarial2017}
Kos, J., Fischer, I., and Song, D.
\newblock Adversarial examples for generative models.
\newblock \emph{arXiv preprint arXiv:1702.06832}, 2017.

\bibitem[Kurakin et~al.(2016)Kurakin, Goodfellow, and
  Bengio]{kurakin:adversarial2016}
Kurakin, A., Goodfellow, I., and Bengio, S.
\newblock Adversarial examples in the physical world.
\newblock \emph{arXiv preprint arXiv:1607.02533}, 2016.

\bibitem[Kurakin et~al.(2018)Kurakin, Goodfellow, Bengio, Dong, Liao, Liang,
  Pang, Zhu, Hu, Xie, et~al.]{kurakin:adversarial2018}
Kurakin, A., Goodfellow, I., Bengio, S., Dong, Y., Liao, F., Liang, M., Pang,
  T., Zhu, J., Hu, X., Xie, C., et~al.
\newblock Adversarial attacks and defences competition.
\newblock \emph{arXiv preprint arXiv:1804.00097}, 2018.

\bibitem[Larsen et~al.(2016)Larsen, S{\o}nderby, Larochelle, and
  Winther]{larsen:vaegan2016}
Larsen, A. B.~L., S{\o}nderby, S.~K., Larochelle, H., and Winther, O.
\newblock Autoencoding beyond pixels using a learned similarity metric.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1558--1566, 2016.

\bibitem[Ledig et~al.(2017)Ledig, Theis, Husz{\'a}r, Caballero, Cunningham,
  Acosta, Aitken, Tejani, Totz, Wang, et~al.]{ledig2017photo}
Ledig, C., Theis, L., Husz{\'a}r, F., Caballero, J., Cunningham, A., Acosta,
  A., Aitken, A., Tejani, A., Totz, J., Wang, Z., et~al.
\newblock Photo-realistic single image super-resolution using a generative
  adversarial network.
\newblock In \emph{2017 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  105--114. IEEE, 2017.

\bibitem[Li \& Gal(2017)Li and Gal]{li:dropout2017}
Li, Y. and Gal, Y.
\newblock Dropout inference in {B}ayesian neural networks with
  alpha-divergences.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2052--2061, 2017.

\bibitem[Louizos \& Welling(2017)Louizos and
  Welling]{louizos:multiplicative2017}
Louizos, C. and Welling, M.
\newblock Multiplicative normalizing flows for variational {B}ayesian neural
  networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2218--2227, 2017.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry:towards2018}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=rJzIBfZAb}.

\bibitem[Nalisnick et~al.(2019)Nalisnick, Matsukawa, Teh, Gorur, and
  Lakshminarayanan]{nalisnick2018do}
Nalisnick, E., Matsukawa, A., Teh, Y.~W., Gorur, D., and Lakshminarayanan, B.
\newblock Do deep generative models know what they don't know?
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=H1xwNhCcYm}.

\bibitem[Ng \& Jordan(2002)Ng and Jordan]{ng:discriminative2002}
Ng, A.~Y. and Jordan, M.~I.
\newblock On discriminative vs. generative classifiers: A comparison of
  logistic regression and naive bayes.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  841--848, 2002.

\bibitem[Papernot et~al.(2016{\natexlab{a}})Papernot, McDaniel, and
  Goodfellow]{papernot:transferability2016}
Papernot, N., McDaniel, P., and Goodfellow, I.
\newblock Transferability in machine learning: from phenomena to black-box
  attacks using adversarial samples.
\newblock \emph{arXiv preprint arXiv:1605.07277}, 2016{\natexlab{a}}.

\bibitem[Papernot et~al.(2016{\natexlab{b}})Papernot, McDaniel, Jha,
  Fredrikson, Celik, and Swami]{papernot:limitations2016}
Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.~B., and Swami,
  A.
\newblock The limitations of deep learning in adversarial settings.
\newblock In \emph{Security and Privacy (EuroS\&P), 2016 IEEE European
  Symposium on}, pp.\  372--387. IEEE, 2016{\natexlab{b}}.

\bibitem[Papernot et~al.(2017{\natexlab{a}})Papernot, Carlini, Goodfellow,
  Feinman, Faghri, Matyasko, Hambardzumyan, Juang, Kurakin, Sheatsley, Garg,
  and Lin]{papernot:cleverhans2017}
Papernot, N., Carlini, N., Goodfellow, I., Feinman, R., Faghri, F., Matyasko,
  A., Hambardzumyan, K., Juang, Y.-L., Kurakin, A., Sheatsley, R., Garg, A.,
  and Lin, Y.-C.
\newblock cleverhans v2.0.0: an adversarial machine learning library.
\newblock \emph{arXiv preprint arXiv:1610.00768}, 2017{\natexlab{a}}.

\bibitem[Papernot et~al.(2017{\natexlab{b}})Papernot, McDaniel, Goodfellow,
  Jha, Celik, and Swami]{papernot:practical2017}
Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.~B., and Swami,
  A.
\newblock Practical black-box attacks against machine learning.
\newblock In \emph{Proceedings of the 2017 ACM on Asia Conference on Computer
  and Communications Security}, pp.\  506--519. ACM, 2017{\natexlab{b}}.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and Wierstra]{rezende:vae2014}
Rezende, D.~J., Mohamed, S., and Wierstra, D.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1278--1286, 2014.

\bibitem[Salimans et~al.(2017)Salimans, Karpathy, Chen, and
  Kingma]{salimans:pixelcnn++2017}
Salimans, T., Karpathy, A., Chen, X., and Kingma, D.~P.
\newblock Pixel{CNN}++: Improving the pixel{CNN} with discretized logistic
  mixture likelihood and other modifications.
\newblock \emph{arXiv preprint arXiv:1701.05517}, 2017.

\bibitem[Samangouei et~al.(2018)Samangouei, Kabkab, and
  Chellappa]{samangouei:defensegan2018}
Samangouei, P., Kabkab, M., and Chellappa, R.
\newblock Defense-{GAN}: Protecting classifiers against adversarial attacks
  using generative models.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=BkJ3ibb0-}.

\bibitem[Schott et~al.(2019)Schott, Rauber, Bethge, and
  Brendel]{schott:abs2018}
Schott, L., Rauber, J., Bethge, M., and Brendel, W.
\newblock Towards the first adversarially robust neural network model on
  {MNIST}.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=S1EHOsC9tX}.

\bibitem[Simonyan \& Zisserman(2014)Simonyan and Zisserman]{simonyan2014very}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Smith \& Gal(2018)Smith and Gal]{smith:understanding2018}
Smith, L. and Gal, Y.
\newblock Understanding measures of uncertainty for adversarial example
  detection.
\newblock In \emph{Uncertainty in Artificial Intelligence}, 2018.

\bibitem[Song et~al.(2018)Song, Kim, Nowozin, Ermon, and
  Kushman]{song:pixeldefend2018}
Song, Y., Kim, T., Nowozin, S., Ermon, S., and Kushman, N.
\newblock Pixeldefend: Leveraging generative models to understand and defend
  against adversarial examples.
\newblock \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=rJUYGxbCW}.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy:intriguing2013}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Tabacof et~al.(2016)Tabacof, Tavares, and
  Valle]{tabacof:adversarial2016}
Tabacof, P., Tavares, J., and Valle, E.
\newblock Adversarial images for variational autoencoders.
\newblock \emph{arXiv preprint arXiv:1612.00155}, 2016.

\bibitem[Tram{\`e}r et~al.(2018)Tram{\`e}r, Kurakin, Papernot, Goodfellow,
  Boneh, and McDaniel]{tramer:ensemble2017}
Tram{\`e}r, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., and
  McDaniel, P.
\newblock Ensemble adversarial training: Attacks and defenses.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=rkZvSe-RZ}.

\bibitem[Uesato et~al.(2018)Uesato, O’Donoghue, Kohli, and
  Oord]{uesato:spsa2018}
Uesato, J., O’Donoghue, B., Kohli, P., and Oord, A.
\newblock Adversarial risk and the dangers of evaluating against weak attacks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5032--5041, 2018.

\bibitem[van~den Oord et~al.(2016)van~den Oord, Kalchbrenner, and
  Kavukcuoglu]{oord:pixel2016}
van~den Oord, A., Kalchbrenner, N., and Kavukcuoglu, K.
\newblock Pixel recurrent neural networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1747--1756, 2016.

\bibitem[Zhang et~al.(2018)Zhang, Isola, Efros, Shechtman, and
  Wang]{zhang2018perceptual}
Zhang, R., Isola, P., Efros, A.~A., Shechtman, E., and Wang, O.
\newblock The unreasonable effectiveness of deep features as a perceptual
  metric.
\newblock In \emph{The IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2018.

\end{thebibliography}
