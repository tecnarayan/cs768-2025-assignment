\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{ABVG{\etalchar{+}}19}

\bibitem[ABVG{\etalchar{+}}19]{placeto}
Ravichandra Addanki, Shaileshh Bojja~Venkatakrishnan, Shreyan Gupta, Hongzi
  Mao, and Mohammad Alizadeh.
\newblock Learning generalizable device placement algorithms for distributed
  machine learning.
\newblock In {\em Advances in Neural Information Processing Systems 32}, pages
  3981--3991. Curran Associates, Inc., 2019.

\bibitem[CFO{\etalchar{+}}18]{bw-micro-2018}
Eric~S. Chung, Jeremy Fowers, Kalin Ovtcharov, Michael Papamichael, Adrian~M.
  Caulfield, Todd Massengill, Ming Liu, Daniel Lo, Shlomi Alkalay, Michael
  Haselman, Maleen Abeydeera, Logan Adams, Hari Angepat, Christian Boehn, Derek
  Chiou, Oren Firestein, Alessandro Forin, Kang~Su Gatlin, Mahdi Ghandi,
  Stephen Heil, Kyle Holohan, Ahmad~El Husseini, Tamás Juhász, Kara Kagi,
  Ratna Kovvuri, Sitaram Lanka, Friedel van Megen, Dima Mukhortov, Prerak
  Patel, Brandon Perez, Amanda Rapsang, Steven~K. Reinhardt, Bita Rouhani, Adam
  Sapek, Raja Seera, Sangeetha Shekar, Balaji Sridharan, Gabriel Weisz, Lisa
  Woods, Phillip~Yi Xiao, Dan Zhang, Ritchie Zhao, and Doug Burger.
\newblock Serving dnns in real time at datacenter scale with project brainwave.
\newblock In {\em {} IEEE Micro}, 2018.

\bibitem[CKES16]{eyeriss-isscc-2016}
Yu-Hsin Chen, Tushar Krishna, Joel Emer, and Vivienne Sze.
\newblock {Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep
  Convolutional Neural Networks}.
\newblock In {\em {IEEE International Solid-State Circuits Conference, ISSCC
  2016, Digest of Technical Papers}}, pages {262--263}, {2016}.

\bibitem[CSAK14]{chilimbi2014adam}
Trishul~M Chilimbi, Yutaka Suzue, Johnson Apacible, and Karthik Kalyanaraman.
\newblock Project adam: Building an efficient and scalable deep learning
  training system.
\newblock In {\em 11th {USENIX} Symposium on Operating Systems Design and
  Implementation ({OSDI} '14)}, volume~14, pages 571--582, 2014.

\bibitem[CXZG16]{Chen2016TrainingDN}
Tianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin.
\newblock Training deep nets with sublinear memory cost.
\newblock {\em ArXiv}, abs/1604.06174, 2016.

\bibitem[DCM{\etalchar{+}}12]{dean2012distbelief}
Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Mark Mao,
  Andrew Senior, Paul Tucker, Ke~Yang, Quoc~V Le, et~al.
\newblock Large scale distributed deep networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1223--1231, 2012.

\bibitem[FOP{\etalchar{+}}18]{bw-isca-2018}
Jeremy Fowers, Kalin Ovtcharov, Michael Papamichael, Todd Massengill, Ming Liu,
  Daniel Lo, Shlomi Alkalay, Michael Haselman, Logan Adams, Mahdi Ghandi,
  Stephen Heil, Prerak Patel, Adam Sapek, Gabriel Weisz, Lisa Woods, Sitaram
  Lanka, Steve Reinhardt, Adrian Caulfield, Eric Chung, and Doug Burger.
\newblock A configurable cloud-scale dnn processor for real-time ai.
\newblock In {\em {}ACM/IEEE 45th Annual International Symposium on Computer
  Architecture (ISCA '18)}, 2018.

\bibitem[GCL18]{spotlight}
Yuanxiang Gao, Li~Chen, and Baochun Li.
\newblock Spotlight: Optimizing device placement for training deep neural
  networks.
\newblock In Jennifer Dy and Andreas Krause, editors, {\em Proceedings of the
  35th International Conference on Machine Learning}, volume~80 of {\em
  Proceedings of Machine Learning Research}, pages 1676--1684,
  Stockholmsmässan, Stockholm Sweden, 10--15 Jul 2018. PMLR.

\bibitem[GO19]{gurobi}
LLC Gurobi~Optimization.
\newblock Gurobi optimizer reference manual, 2019.

\bibitem[Gra66]{GrahamListScheduling1966}
R.~L. Graham.
\newblock Bounds for certain multiprocessing anomalies.
\newblock {\em Bell System Technical Journal}, 45(9):1563--1581, 1966.

\bibitem[HCB{\etalchar{+}}19]{huang2019gpipe}
Yanping Huang, Youlong Cheng, Ankur Bapna, Orhan Firat, Dehao Chen, Mia Chen,
  HyoukJoong Lee, Jiquan Ngiam, Quoc~V. Le, Yonghui Wu, and Zhifeng Chen.
\newblock Gpipe: Efficient training of giant neural networks using pipeline
  parallelism.
\newblock In {\em Advances in Neural Information Processing Systems}, 2019.

\bibitem[HCC{\etalchar{+}}18]{huang2018gpipe}
Yanping Huang, Yonglong Cheng, Dehao Chen, HyoukJoong Lee, Jiquan Ngiam, Quoc~V
  Le, and Zhifeng Chen.
\newblock Gpipe: Efficient training of giant neural networks using pipeline
  parallelism.
\newblock {\em arXiv preprint arXiv:1811.06965}, 2018.

\bibitem[HNP{\etalchar{+}}18]{harlap2018pipedream}
Aaron Harlap, Deepak Narayanan, Amar Phanishayee, Vivek Seshadri, Nikhil
  Devanur, Greg Ganger, and Phil Gibbons.
\newblock Pipe{D}ream: {F}ast and {E}fficient {P}ipeline {P}arallel {DNN}
  {T}raining.
\newblock {\em arXiv preprint arXiv:1806.03377}, 2018.

\bibitem[HZRS15a]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock {\em CoRR}, abs/1512.03385, 2015.

\bibitem[HZRS15b]{resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock {\em CoRR}, abs/1512.03385, 2015.

\bibitem[JLQA18]{jia2018exploring}
Zhihao Jia, Sina Lin, Charles~R Qi, and Alex Aiken.
\newblock Exploring hidden dimensions in parallelizing convolutional neural
  networks.
\newblock In {\em Proceedings of the 28th International Conference on Machine
  Learning (ICML '18)}, 2018.

\bibitem[JYP{\etalchar{+}}17]{tpu}
Norman~P. Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal,
  Raminder Bajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al~Borchers, Rick
  Boyle, Pierre-luc Cantin, Clifford Chao, Chris Clark, Jeremy Coriell, Mike
  Daley, Matt Dau, Jeffrey Dean, Ben Gelb, Tara~Vazir Ghaemmaghami, Rajendra
  Gottipati, William Gulland, Robert Hagmann, C.~Richard Ho, Doug Hogberg, John
  Hu, Robert Hundt, Dan Hurt, Julian Ibarz, Aaron Jaffey, Alek Jaworski,
  Alexander Kaplan, Harshit Khaitan, Daniel Killebrew, Andy Koch, Naveen Kumar,
  Steve Lacy, James Laudon, James Law, Diemthu Le, Chris Leary, Zhuyuan Liu,
  Kyle Lucke, Alan Lundin, Gordon MacKean, Adriana Maggiore, Maire Mahony,
  Kieran Miller, Rahul Nagarajan, Ravi Narayanaswami, Ray Ni, Kathy Nix, Thomas
  Norrie, Mark Omernick, Narayana Penukonda, Andy Phelps, Jonathan Ross, Matt
  Ross, Amir Salek, Emad Samadiani, Chris Severn, Gregory Sizikov, Matthew
  Snelham, Jed Souter, Dan Steinberg, Andy Swing, Mercedes Tan, Gregory
  Thorson, Bo~Tian, Horia Toma, Erick Tuttle, Vijay Vasudevan, Richard Walter,
  Walter Wang, Eric Wilcox, and Doe~Hyun Yoon.
\newblock In-datacenter performance analysis of a tensor processing unit.
\newblock {\em SIGARCH Comput. Archit. News}, 45(2):1–12, June 2017.

\bibitem[JZA19]{jia2018beyond}
Zhihao Jia, Matei Zaharia, and Alex Aiken.
\newblock Beyond data and model parallelism for deep neural networks.
\newblock In {\em Proceedings of the 2nd SysML Conference, SysML '19}, {Palo
  Alto, CA, USA}, 2019.

\bibitem[KL70]{KernighanLin}
B.~W. {Kernighan} and S.~{Lin}.
\newblock An efficient heuristic procedure for partitioning graphs.
\newblock {\em The Bell System Technical Journal}, 49(2):291--307, 1970.

\bibitem[Kri14]{krizhevsky2014one}
Alex Krizhevsky.
\newblock One weird trick for parallelizing convolutional neural networks.
\newblock {\em arXiv preprint arXiv:1404.5997}, 2014.

\bibitem[KSH12]{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1097--1105, 2012.

\bibitem[LLKS93]{lawler1993sequencing}
Eugene~L Lawler, Jan~Karel Lenstra, Alexander HG~Rinnooy Kan, and David~B
  Shmoys.
\newblock Sequencing and scheduling: Algorithms and complexity.
\newblock {\em Handbooks in operations research and management science},
  4:445--522, 1993.

\bibitem[MGP{\etalchar{+}}18]{hierarchical-2018}
Azalia Mirhoseini, Anna Goldie, Hieu Pham, Benoit Steiner, Quoc~V. Le, and
  Jeffrey Dean.
\newblock A hierarchical model for device placement.
\newblock {\em ICLR}, 2018.

\bibitem[MKA07]{localsearch}
Wil Michiels, Jan Korst, and Emile Aarts.
\newblock {\em Theoretical Aspects of Local Search}.
\newblock Springer Berlin Heidelberg, 2007.

\bibitem[MKS17]{merity2017regularizing}
Stephen Merity, Nitish~Shirish Keskar, and Richard Socher.
\newblock Regularizing and optimizing lstm language models.
\newblock {\em arXiv preprint arXiv:1708.02182}, 2017.

\bibitem[{mlp}]{mlperf-inf}
{mlperf.org}.
\newblock {ML Perf Inference Overview}.

\bibitem[MPL{\etalchar{+}}17]{dean2017rlplacement}
Azalia Mirhoseini, Hieu Pham, Quoc~V Le, Benoit Steiner, Rasmus Larsen, Yuefeng
  Zhou, Naveen Kumar, Mohammad Norouzi, Samy Bengio, and Jeff Dean.
\newblock Device placement optimization with reinforcement learning.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 2430--2439. JMLR. org, 2017.

\bibitem[NHP{\etalchar{+}}19]{narayanan2018pipedream}
Deepak Narayanan, Aaron Harlap, Amar Phanishayee, Vivek Seshadri, Nikhil
  Devanur, Greg Ganger, Phil Gibbons, and Matei Zaharia.
\newblock Pipedream: Generalized pipeline parallelism for {DNN} training.
\newblock In {\em {Proc. 27th ACM Symposium on Operating Systems Principles
  (SOSP)}}, {Huntsville, ON, Canada}, October 2019.

\bibitem[{ONN}20]{onnxruntime}
{ONNX Runtime}.
\newblock {Operator Graphs}, 2020.

\bibitem[Pel09]{scotch}
Francois Pellegrini.
\newblock Distillating knowledge about scotch.
\newblock In Uwe Naumann, Olaf Schenk, Horst~D. Simon, and Sivan Toledo,
  editors, {\em Combinatorial Scientific Computing}, number 09061 in Dagstuhl
  Seminar Proceedings, Dagstuhl, Germany, 2009. Schloss Dagstuhl -
  Leibniz-Zentrum fuer Informatik, Germany.

\bibitem[PGN{\etalchar{+}}20]{regal}
Aditya Paliwal, Felix Gimeno, Vinod Nair, Yujia Li, Miles Lubin, Pushmeet
  Kohli, and Oriol Vinyals.
\newblock Reinforced genetic algorithm learning for optimizing computation
  graphs.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem[PY90]{PapadimitriouY90}
C.~H. Papadimitriou and M.~Yannakakis.
\newblock Towards an architecture-independent analysis of parallel algorithms.
\newblock {\em SIAM J. Comput.}, 19(2):322–328, April 1990.

\bibitem[SPM{\etalchar{+}}16]{dnnweaver}
Hardik Sharma, Jongse Park, Divya Mahajan, Emmanuel Amaro, Joon~Kyung Kim,
  Chenkai Shao, Asit Mishra, and Hadi Esmaeilzadeh.
\newblock From high-level deep neural models to fpgas.
\newblock In {\em Microarchitecture (MICRO), 2016 49th Annual IEEE/ACM
  International Symposium on}, pages 1--12. IEEE, 2016.

\bibitem[ST93]{ShmoysT93}
David~B. Shmoys and {\'{E}}va Tardos.
\newblock An approximation algorithm for the generalized assignment problem.
\newblock {\em Math. Program.}, 62:461--474, 1993.

\bibitem[SVL14]{sutskever2014sequence}
Ilya Sutskever, Oriol Vinyals, and Quoc~V Le.
\newblock Sequence to sequence learning with neural networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3104--3112, 2014.

\bibitem[SW99]{SkutellaW99}
Martin Skutella and Gerhard~J. Woeginger.
\newblock A {PTAS} for minimizing the weighted sum of job completion times on
  parallel machines.
\newblock In {\em Symposium on Theory of Computing, {STOC}}, pages 400--407,
  1999.

\bibitem[SZ14]{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[VRD{\etalchar{+}}15]{venugopalan2015sequence}
Subhashini Venugopalan, Marcus Rohrbach, Jeffrey Donahue, Raymond Mooney,
  Trevor Darrell, and Kate Saenko.
\newblock Sequence to sequence-video to text.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, pages 4534--4542, 2015.

\bibitem[VSP{\etalchar{+}}17]{bert}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, \L~ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, {\em Advances in Neural Information
  Processing Systems 30}, pages 5998--6008. Curran Associates, Inc., 2017.

\bibitem[WSC{\etalchar{+}}16]{wu2016google}
Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc~V Le, Mohammad Norouzi, Wolfgang
  Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et~al.
\newblock Google's neural machine translation system: Bridging the gap between
  human and machine translation.
\newblock {\em arXiv preprint arXiv:1609.08144}, 2016.

\bibitem[ZRA{\etalchar{+}}19]{gdp}
Yanqi Zhou, Sudip Roy, Amirali Abdolrashidi, Daniel Wong, Peter~C. Ma, Qiumin
  Xu, Ming Zhong, Hanxiao Liu, Anna Goldie, Azalia Mirhoseini, and James
  Laudon.
\newblock Gdp: Generalized device placement for dataflow graphs, 2019.

\end{thebibliography}
