\begin{thebibliography}{10}

\bibitem{schacter1994memory}
Daniel~L Schacter and Endel Tulving.
\newblock {\em Memory systems 1994}.
\newblock Mit Press, 1994.

\bibitem{knowlton2012neurocomputational}
Barbara~J Knowlton, Robert~G Morrison, John~E Hummel, and Keith~J Holyoak.
\newblock A neurocomputational system for relational reasoning.
\newblock {\em Trends in cognitive sciences}, 16(7):373--381, 2012.

\bibitem{hochreiter1998lstm}
Sepp Hochreiter and Jurgen Schmidhuber.
\newblock Long short term memory.
\newblock {\em Neural Computation, Volume 9, Issue 8 November 15, 1997,
  p.1735-1780}, 1997.

\bibitem{graves2014neural}
Alex Graves, Greg Wayne, and Ivo Danihelka.
\newblock Neural turing machines.
\newblock {\em arXiv preprint arXiv:1410.5401}, 2014.

\bibitem{graves2016hybrid}
Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka
  Grabska-Barwi{\'n}ska, Sergio~G{\'o}mez Colmenarejo, Edward Grefenstette,
  Tiago Ramalho, John Agapiou, et~al.
\newblock Hybrid computing using a neural network with dynamic external memory.
\newblock {\em Nature}, 538(7626):471, 2016.

\bibitem{santoro2016meta}
Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy
  Lillicrap.
\newblock Meta-learning with memory-augmented neural networks.
\newblock In {\em International conference on machine learning}, pages
  1842--1850, 2016.

\bibitem{sukhbaatar2015end}
Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et~al.
\newblock End-to-end memory networks.
\newblock In {\em Advances in neural information processing systems}, pages
  2440--2448, 2015.

\bibitem{waltz1999system}
James~A Waltz, Barbara~J Knowlton, Keith~J Holyoak, Kyle~B Boone, Fred~S
  Mishkin, Marcia de~Menezes~Santos, Carmen~R Thomas, and Bruce~L Miller.
\newblock A system for relational reasoning in human prefrontal cortex.
\newblock {\em Psychological science}, 10(2):119--125, 1999.

\bibitem{gilmer2017neural}
Justin Gilmer, Samuel~S Schoenholz, Patrick~F Riley, Oriol Vinyals, and
  George~E Dahl.
\newblock Neural message passing for quantum chemistry.
\newblock {\em arXiv preprint arXiv:1704.01212}, 2017.

\bibitem{scarselli2009graph}
Franco Scarselli, Marco Gori, Ah~Chung Tsoi, Markus Hagenbuchner, and Gabriele
  Monfardini.
\newblock The graph neural network model.
\newblock {\em IEEE Transactions on Neural Networks}, 20(1):61--80, 2009.

\bibitem{LiTBZ15}
Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard~S. Zemel.
\newblock Gated graph sequence neural networks.
\newblock {\em ICLR}, 2016.

\bibitem{battaglia2016interaction}
Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo~Jimenez Rezende, et~al.
\newblock Interaction networks for learning about objects, relations and
  physics.
\newblock In {\em Advances in neural information processing systems}, pages
  4502--4510, 2016.

\bibitem{kipf2016semi}
Thomas~N Kipf and Max Welling.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock {\em arXiv preprint arXiv:1609.02907}, 2016.

\bibitem{velickovic2018graph}
Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro
  Liò, and Yoshua Bengio.
\newblock Graph attention networks.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{santoro2017simple}
Adam Santoro, David Raposo, David~G Barrett, Mateusz Malinowski, Razvan
  Pascanu, Peter Battaglia, and Tim Lillicrap.
\newblock A simple neural network module for relational reasoning.
\newblock In {\em Advances in neural information processing systems}, pages
  4974--4983, 2017.

\bibitem{raposo2017discovering}
David Raposo, Adam Santoro, David Barrett, Razvan Pascanu, Timothy Lillicrap,
  and Peter Battaglia.
\newblock Discovering objects and their relations from entangled scene
  representations.
\newblock {\em arXiv preprint arXiv:1702.05068}, 2017.

\bibitem{hu2017relation}
Han Hu, Jiayuan Gu, Zheng Zhang, Jifeng Dai, and Yichen Wei.
\newblock Relation networks for object detection.
\newblock {\em arXiv preprint arXiv:1711.11575}, 2017.

\bibitem{wang2017non}
Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.
\newblock Non-local neural networks.
\newblock {\em arXiv preprint arXiv:1711.07971}, 2017.

\bibitem{liu2018non}
Ding Liu, Bihan Wen, Yuchen Fan, Chen~Change Loy, and Thomas~S Huang.
\newblock Non-local recurrent network for image restoration.
\newblock {\em arXiv preprint arXiv:1806.02919}, 2018.

\bibitem{pavez2018working}
Juan Pavez, H{\'e}ctor Allende, and H{\'e}ctor Allende-Cid.
\newblock Working memory networks: Augmenting memory networks with a relational
  reasoning module.
\newblock {\em arXiv preprint arXiv:1805.09354}, 2018.

\bibitem{BahdanauCB14}
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock {\em ICLR}, abs/1409.0473, 2015.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6000--6010, 2017.

\bibitem{Graves13}
Alex Graves.
\newblock Generating sequences with recurrent neural networks.
\newblock {\em CoRR}, abs/1308.0850, 2013.

\bibitem{gers1999learning}
Felix~A Gers, J{\"u}rgen Schmidhuber, and Fred Cummins.
\newblock Learning to forget: Continual prediction with lstm.
\newblock 1999.

\bibitem{zaremba2014lte}
Wojciech Zaremba and Ilya Sutskever.
\newblock Learning to execute.
\newblock {\em arXiv preprint arXiv:1410.4615v3}, 2014.

\bibitem{weber2017imagination}
Th{\'e}ophane Weber, S{\'e}bastien Racani{\`e}re, David~P Reichert, Lars
  Buesing, Arthur Guez, Danilo~Jimenez Rezende, Adria~Puigdom{\`e}nech Badia,
  Oriol Vinyals, Nicolas Heess, Yujia Li, et~al.
\newblock Imagination-augmented agents for deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1707.06203}, 2017.

\bibitem{cho2014learning}
Kyunghyun Cho, Bart Van~Merri{\"e}nboer, Caglar Gulcehre, Dzmitry Bahdanau,
  Fethi Bougares, Holger Schwenk, and Yoshua Bengio.
\newblock Learning phrase representations using rnn encoder-decoder for
  statistical machine translation.
\newblock {\em arXiv preprint arXiv:1406.1078}, 2014.

\bibitem{bahdanau2016end}
Dzmitry Bahdanau, Jan Chorowski, Dmitriy Serdyuk, Philemon Brakel, and Yoshua
  Bengio.
\newblock End-to-end attention-based large vocabulary speech recognition.
\newblock In {\em Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE
  International Conference on}, pages 4945--4949. IEEE, 2016.

\bibitem{hiemstra2001using}
Djoerd Hiemstra.
\newblock Using language models for information retrieval.
\newblock 2001.

\bibitem{yang2017breaking}
Zhilin Yang, Zihang Dai, Ruslan Salakhutdinov, and William~W Cohen.
\newblock Breaking the softmax bottleneck: a high-rank rnn language model.
\newblock {\em arXiv preprint arXiv:1711.03953}, 2017.

\bibitem{marcus1993building}
Mitchell~P Marcus, Mary~Ann Marcinkiewicz, and Beatrice Santorini.
\newblock Building a large annotated corpus of english: The penn treebank.
\newblock {\em Computational linguistics}, 19(2):313--330, 1993.

\bibitem{rae2018fast}
Jack~W Rae, Chris Dyer, Peter Dayan, and Timothy~P Lillicrap.
\newblock Fast parametric learning with activation memorization.
\newblock {\em arXiv preprint arXiv:1803.10049}, 2018.

\bibitem{merity2016pointer}
Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher.
\newblock Pointer sentinel mixture models.
\newblock {\em arXiv preprint arXiv:1609.07843}, 2016.

\bibitem{jozefowicz2016exploring}
Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu.
\newblock Exploring the limits of language modeling.
\newblock {\em arXiv preprint arXiv:1602.02410}, 2016.

\bibitem{chelba2013one}
Ciprian Chelba, Tomas Mikolov, Mike Schuster, Qi~Ge, Thorsten Brants, Phillipp
  Koehn, and Tony Robinson.
\newblock One billion word benchmark for measuring progress in statistical
  language modeling.
\newblock {\em arXiv preprint arXiv:1312.3005}, 2013.

\bibitem{parker2011english}
Robert Parker, David Graff, Junbo Kong, Ke~Chen, and Kazuaki Maeda.
\newblock English gigaword fifth edition ldc2011t07. dvd.
\newblock {\em Philadelphia: Linguistic Data Consortium}, 2011.

\bibitem{pascanu2013dlstm}
Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio.
\newblock How to construct deep recurrent neural networks.
\newblock {\em arXiv preprint arXiv:1312.6026}, 2013.

\bibitem{henaff2017entnet}
Mikael Henaff, Jason Weston, Arthur Szlam, Antoine Bordes, and Yann LeCun.
\newblock Tracking the world state with recurrent entity networks.
\newblock In {\em Fifth International Conference on Learning Representations},
  2017.

\bibitem{sbengio2015schedsamp}
Navdeep Jaitly Noam~Shazeer Samy~Bengio, Oriol~Vinyals.
\newblock Scheduled sampling for sequence prediction with recurrent neural
  networks.
\newblock In {\em Advances in Neural Information Processing Systems 28}, 2015.

\bibitem{grave2016improving}
Edouard Grave, Armand Joulin, and Nicolas Usunier.
\newblock Improving neural language models with a continuous cache.
\newblock {\em arXiv preprint arXiv:1612.04426}, 2016.

\bibitem{bai2018convolutional}
Shaojie Bai, J~Zico Kolter, and Vladlen Koltun.
\newblock Convolutional sequence modeling revisited.
\newblock 2018.

\bibitem{dauphin2016language}
Yann~N Dauphin, Angela Fan, Michael Auli, and David Grangier.
\newblock Language modeling with gated convolutional networks.
\newblock {\em arXiv preprint arXiv:1612.08083}, 2016.

\bibitem{merity2018scalable}
Stephen Merity, Nitish~Shirish Keskar, James Bradbury, and Richard Socher.
\newblock Scalable language modeling: Wikitext-103 on a single gpu in 12 hours.
\newblock 2018.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{sutskever2014seq2seq}
Ilya Sutskever, Oriol Vinyals, and Quoc~V. Le.
\newblock Sequence to sequence learning with neural networks.
\newblock In {\em Advances in neural information processing systems 27}, 2014.

\bibitem{zambaldi2018relational}
Vinicius Zambaldi, David Raposo, Adam Santoro, Victor Bapst, Yujia Li, Igor
  Babuschkin, Karl Tuyls, David Reichert, Timothy Lillicrap, Edward Lockhart,
  Murray Shanahan, Victoria Langston, Razvan Pascanu, Matthew Botvinick, Oriol
  Vinyals, and Peter Battaglia.
\newblock Relational deep reinforcement learning.
\newblock {\em arXiv preprint}, 2018.

\bibitem{espeholt2018impala}
Lasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Volodymir Mnih, Tom
  Ward, Yotam Doron, Vlad Firoiu, Tim Harley, Iain Dunning, et~al.
\newblock Importance weighted actor-learner architectures: Scalable distributed
  deep-rl with importance weighted actor-learner architectures.
\newblock {\em arXiv preprint arXiv:1802.01561}, 2018.

\end{thebibliography}
