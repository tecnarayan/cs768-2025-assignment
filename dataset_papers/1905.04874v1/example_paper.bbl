\begin{thebibliography}{51}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Baby \& Verhulst(2019)Baby and Verhulst]{baby2019sergan}
Baby, D. and Verhulst, S.
\newblock Sergan: Speech enhancement using relativistic generative adversarial
  networks with gradient penalty.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp.\  106--110, 2019.

\bibitem[Bagchi et~al.(2018)Bagchi, Plantinga, Stiff, and
  Fosler-Lussier]{bagchi2018spectral}
Bagchi, D., Plantinga, P., Stiff, A., and Fosler-Lussier, E.
\newblock Spectral feature mapping with mimic loss for robust speech
  recognition.
\newblock \emph{arXiv preprint arXiv:1803.09816}, 2018.

\bibitem[Benesty et~al.(2005)Benesty, Makino, and Chen]{benesty2015speech}
Benesty, J., Makino, S., and Chen, J.
\newblock \emph{Speech Enhancement}.
\newblock Berlin, Germany: Springer, 2005.

\bibitem[Chai et~al.(2018)Chai, Du, and Lee]{chai2018error}
Chai, L., Du, J., and Lee, C.-H.
\newblock Error modeling via asymmetric laplace distribution for deep neural
  network based single-channel speech enhancement.
\newblock In \emph{Interspeech}, pp.\  3269--3273, 2018.

\bibitem[Choi et~al.(2019)Choi, Kim, Huh, Kim, Ha, and Lee]{choi2018phase}
Choi, H.-S., Kim, J., Huh, J., Kim, A., Ha, J.-W., and Lee, K.
\newblock Phase-aware speech enhancement with deep complex u-net.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.

\bibitem[Donahue et~al.(2018)Donahue, Li, and
  Prabhavalkar]{donahue2018exploring}
Donahue, C., Li, B., and Prabhavalkar, R.
\newblock Exploring speech enhancement with generative adversarial networks for
  robust speech recognition.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp.\  5024--5028, 2018.

\bibitem[Fu et~al.(2018{\natexlab{a}})Fu, Tsao, Hwang, and Wang]{fu2018quality}
Fu, S.-W., Tsao, Y., Hwang, H.-T., and Wang, H.-M.
\newblock Quality-net: An end-to-end non-intrusive speech quality assessment
  model based on blstm.
\newblock In \emph{Interspeech}, 2018{\natexlab{a}}.

\bibitem[Fu et~al.(2018{\natexlab{b}})Fu, Wang, Tsao, Lu, and Kawai]{fu2018end}
Fu, S.-W., Wang, T.-W., Tsao, Y., Lu, X., and Kawai, H.
\newblock End-to-end waveform utterance enhancement for direct evaluation
  metrics optimization by fully convolutional neural networks.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech and Language
  Processing}, 26\penalty0 (9):\penalty0 1570--1584, 2018{\natexlab{b}}.

\bibitem[Fu et~al.(2019)Fu, Liao, and Tsao]{fu2019learning}
Fu, S.-W., Liao, C.-F., and Tsao, Y.
\newblock Learning with learned loss function: Speech enhancement with
  quality-net to improve perceptual evaluation of speech quality.
\newblock \emph{arXiv preprint arXiv:1905.01898}, 2019.

\bibitem[Garofolo et~al.(1988)]{garofolo1988getting}
Garofolo, J.~S. et~al.
\newblock Getting started with the darpa timit cd-rom: An acoustic phonetic
  continuous speech database.
\newblock \emph{National Institute of Standards and Technology (NIST),
  Gaithersburgh, MD}, 107:\penalty0 16, 1988.

\bibitem[Germain et~al.(2018)Germain, Chen, and Koltun]{germain2018speech}
Germain, F.~G., Chen, Q., and Koltun, V.
\newblock Speech denoising with deep feature losses.
\newblock \emph{arXiv preprint arXiv:1806.10522}, 2018.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2672--2680, 2014.

\bibitem[Grais et~al.(2018)Grais, Ward, and Plumbley]{grais2018raw}
Grais, E.~M., Ward, D., and Plumbley, M.~D.
\newblock Raw multi-channel audio source separation using multi-resolution
  convolutional auto-encoders.
\newblock \emph{arXiv preprint arXiv:1803.00702}, 2018.

\bibitem[Hsieh et~al.(2018)Hsieh, Lin, and Lin]{hsieh2018deep}
Hsieh, C.-Y., Lin, Y.-A., and Lin, H.-T.
\newblock A deep model with local surrogate loss for general cost-sensitive
  multi-label learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence (AAAI)}, 2018.

\bibitem[Hu()]{hu100}
Hu, G.
\newblock 100 nonspeech environmental sounds, 2004.

\bibitem[Isola et~al.(2017)Isola, Zhu, Zhou, and Efros]{isola2017image}
Isola, P., Zhu, J.-Y., Zhou, T., and Efros, A.~A.
\newblock Image-to-image translation with conditional adversarial networks.
\newblock \emph{arXiv preprint}, 2017.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Koizumi et~al.(2017)Koizumi, Niwa, Hioka, Kobayashi, and
  Haneda]{koizumi2017dnn}
Koizumi, Y., Niwa, K., Hioka, Y., Kobayashi, K., and Haneda, Y.
\newblock Dnn-based source enhancement self-optimized by reinforcement learning
  using sound quality measurements.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp.\  81--85, 2017.

\bibitem[Koizumi et~al.(2018)Koizumi, Niwa, Hioka, Koabayashi, and
  Haneda]{koizumi2018dnn}
Koizumi, Y., Niwa, K., Hioka, Y., Koabayashi, K., and Haneda, Y.
\newblock Dnn-based source enhancement to increase objective sound quality
  assessment score.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 2018.

\bibitem[Kolb{\ae}k et~al.(2018)Kolb{\ae}k, Tan, and
  Jensen]{kolbaek2018monaural}
Kolb{\ae}k, M., Tan, Z.-H., and Jensen, J.
\newblock Monaural speech enhancement using deep neural networks by maximizing
  a short-time objective intelligibility measure.
\newblock \emph{arXiv preprint arXiv:1802.00604}, 2018.

\bibitem[Langley(2000)]{langley00}
Langley, P.
\newblock Crafting papers on machine learning.
\newblock In Langley, P. (ed.), \emph{Proceedings of the 17th International
  Conference on Machine Learning (ICML 2000)}, pp.\  1207--1216, Stanford, CA,
  2000. Morgan Kaufmann.

\bibitem[Ledig et~al.(2017)Ledig, Theis, Husz{\'a}r, Caballero, Cunningham,
  Acosta, Aitken, Tejani, Totz, Wang, et~al.]{ledig2017photo}
Ledig, C., Theis, L., Husz{\'a}r, F., Caballero, J., Cunningham, A., Acosta,
  A., Aitken, A., Tejani, A., Totz, J., Wang, Z., et~al.
\newblock Photo-realistic single image super-resolution using a generative
  adversarial network.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  105--114, 2017.

\bibitem[Liao et~al.(2018)Liao, Tsao, Lee, and Wang]{liao2018noise}
Liao, C.-F., Tsao, Y., Lee, H.-Y., and Wang, H.-M.
\newblock Noise adaptive speech enhancement using domain adversarial training.
\newblock \emph{arXiv preprint arXiv:1807.07501}, 2018.

\bibitem[Lu et~al.(2013)Lu, Tsao, Matsuda, and Hori]{lu2013speech}
Lu, X., Tsao, Y., Matsuda, S., and Hori, C.
\newblock Speech enhancement based on deep denoising autoencoder.
\newblock In \emph{Interspeech}, pp.\  436--440, 2013.

\bibitem[Luo \& Mesgarani(2018)Luo and Mesgarani]{luo2018tasnet}
Luo, Y. and Mesgarani, N.
\newblock Tasnet: Surpassing ideal time-frequency masking for speech
  separation.
\newblock \emph{arXiv preprint arXiv:1809.07454}, 2018.

\bibitem[Mao et~al.(2017)Mao, Li, Xie, Lau, Wang, and Smolley]{mao2017least}
Mao, X., Li, Q., Xie, H., Lau, R.~Y., Wang, Z., and Smolley, S.~P.
\newblock Least squares generative adversarial networks.
\newblock In \emph{IEEE International Conference on Computer Vision (ICCV)},
  pp.\  2813--2821, 2017.

\bibitem[Mart{\'\i}n-Do{\~n}as et~al.(2018)Mart{\'\i}n-Do{\~n}as, Gomez,
  Gonzalez, and Peinado]{martin2018deep}
Mart{\'\i}n-Do{\~n}as, J.~M., Gomez, A.~M., Gonzalez, J.~A., and Peinado, A.~M.
\newblock A deep learning loss function based on the perceptual evaluation of
  the speech quality.
\newblock \emph{IEEE Signal Processing Letters}, 25\penalty0 (11):\penalty0
  1680--1684, 2018.

\bibitem[Michelsanti \& Tan(2017)Michelsanti and
  Tan]{michelsanti2017conditional}
Michelsanti, D. and Tan, Z.-H.
\newblock Conditional generative adversarial networks for speech enhancement
  and noise-robust speaker verification.
\newblock \emph{arXiv preprint arXiv:1709.01703}, 2017.

\bibitem[Mirza \& Osindero(2014)Mirza and Osindero]{mirza2014conditional}
Mirza, M. and Osindero, S.
\newblock Conditional generative adversarial nets.
\newblock \emph{arXiv preprint arXiv:1411.1784}, 2014.

\bibitem[Miyato et~al.(2018)Miyato, Kataoka, Koyama, and
  Yoshida]{miyato2018spectral}
Miyato, T., Kataoka, T., Koyama, M., and Yoshida, Y.
\newblock Spectral normalization for generative adversarial networks.
\newblock \emph{arXiv preprint arXiv:1802.05957}, 2018.

\bibitem[Naithani et~al.(2018)Naithani, Nikunen, Bramslow, and
  Virtanen]{naithani2018deep}
Naithani, G., Nikunen, J., Bramslow, L., and Virtanen, T.
\newblock Deep neural network based speech separation optimizing an objective
  estimator of intelligibility for low latency applications.
\newblock In \emph{International Workshop on Acoustic Signal Enhancement
  (IWAENC)}, pp.\  386--390, 2018.

\bibitem[Narayanan \& Wang(2013)Narayanan and Wang]{narayanan2013ideal}
Narayanan, A. and Wang, D.
\newblock Ideal ratio mask estimation using deep neural networks for robust
  speech recognition.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp.\  7092--7096, 2013.

\bibitem[Ochiai et~al.(2017)Ochiai, Watanabe, Hori, and
  Hershey]{ochiai2017multichannel}
Ochiai, T., Watanabe, S., Hori, T., and Hershey, J.~R.
\newblock Multichannel end-to-end speech recognition.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  2632--2641, 2017.

\bibitem[Pandey \& Wang(2018)Pandey and Wang]{pandey2018adversarial}
Pandey, A. and Wang, D.
\newblock On adversarial training and loss functions for speech enhancement.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp.\  5414--5418, 2018.

\bibitem[Pascual et~al.(2017)Pascual, Bonafonte, and Serra]{pascual2017segan}
Pascual, S., Bonafonte, A., and Serra, J.
\newblock Segan: Speech enhancement generative adversarial network.
\newblock In \emph{Interspeech}, 2017.

\bibitem[Rix et~al.(2001)Rix, Beerends, Hollier, and
  Hekstra]{rix2001perceptual}
Rix, A.~W., Beerends, J.~G., Hollier, M.~P., and Hekstra, A.~P.
\newblock Perceptual evaluation of speech quality (pesq)-a new method for
  speech quality assessment of telephone networks and codecs.
\newblock In \emph{IEEE International Conference on Acoustics, Speech, and
  Signal Processing (ICASSP)}, volume~2, pp.\  749--752, 2001.

\bibitem[Sehnke et~al.(2010)Sehnke, Osendorfer, R{\"u}ckstie{\ss}, Graves,
  Peters, and Schmidhuber]{sehnke2010parameter}
Sehnke, F., Osendorfer, C., R{\"u}ckstie{\ss}, T., Graves, A., Peters, J., and
  Schmidhuber, J.
\newblock Parameter-exploring policy gradients.
\newblock \emph{Neural Networks}, 23\penalty0 (4):\penalty0 551--559, 2010.

\bibitem[Soni et~al.(2018)Soni, Shah, and Patil]{soni2018time}
Soni, M.~H., Shah, N., and Patil, H.~A.
\newblock Time-frequency masking-based speech enhancement using generative
  adversarial network.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, 2018.

\bibitem[Taal et~al.(2011)Taal, Hendriks, Heusdens, and
  Jensen]{taal2011algorithm}
Taal, C.~H., Hendriks, R.~C., Heusdens, R., and Jensen, J.
\newblock An algorithm for intelligibility prediction of time--frequency
  weighted noisy speech.
\newblock \emph{IEEE Transactions on Audio, Speech, and Language Processing},
  19\penalty0 (7):\penalty0 2125--2136, 2011.

\bibitem[Valentini-Botinhao et~al.(2016)Valentini-Botinhao, Wang, Takaki, and
  Yamagishi]{valentini2016investigating}
Valentini-Botinhao, C., Wang, X., Takaki, S., and Yamagishi, J.
\newblock Investigating rnn-based speech enhancement methods for noise-robust
  text-to-speech.
\newblock In \emph{9th ISCA Speech Synthesis Workshop}, pp.\  146--152, 2016.

\bibitem[Venkataramani \& Smaragdis(2018)Venkataramani and
  Smaragdis]{venkataramani2018end}
Venkataramani, S. and Smaragdis, P.
\newblock End-to-end networks for supervised single-channel speech separation.
\newblock \emph{arXiv preprint arXiv:1810.02568}, 2018.

\bibitem[Venkataramani et~al.(2018)Venkataramani, Higa, and
  Smaragdis]{venkataramani2018performance}
Venkataramani, S., Higa, R., and Smaragdis, P.
\newblock Performance based cost functions for end-to-end speech separation.
\newblock \emph{arXiv preprint arXiv:1806.00511}, 2018.

\bibitem[Wang \& Chen(2018)Wang and Chen]{wang2018supervised}
Wang, D. and Chen, J.
\newblock Supervised speech separation based on deep learning: An overview.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 26\penalty0 (10):\penalty0 1702--1726, 2018.

\bibitem[Wang et~al.(2018)Wang, Yu, Wu, Gu, Liu, Dong, Loy, Qiao, and
  Tang]{wang2018esrgan}
Wang, X., Yu, K., Wu, S., Gu, J., Liu, Y., Dong, C., Loy, C.~C., Qiao, Y., and
  Tang, X.
\newblock Esrgan: Enhanced super-resolution generative adversarial networks.
\newblock \emph{arXiv preprint arXiv:1809.00219}, 2018.

\bibitem[Wang et~al.(2014)Wang, Narayanan, and Wang]{wang2014training}
Wang, Y., Narayanan, A., and Wang, D.
\newblock On training targets for supervised speech separation.
\newblock \emph{IEEE/ACM transactions on audio, speech, and language
  processing}, 22\penalty0 (12):\penalty0 1849--1858, 2014.

\bibitem[Weninger et~al.(2015)Weninger, Erdogan, Watanabe, Vincent, Le~Roux,
  Hershey, and Schuller]{weninger2015speech}
Weninger, F., Erdogan, H., Watanabe, S., Vincent, E., Le~Roux, J., Hershey,
  J.~R., and Schuller, B.
\newblock Speech enhancement with lstm recurrent neural networks and its
  application to noise-robust asr.
\newblock In \emph{International Conference on Latent Variable Analysis and
  Signal Separation (LVA/ICA)}, pp.\  91--99, 2015.

\bibitem[Xu et~al.(2014)Xu, Du, Dai, and Lee]{xu2014experimental}
Xu, Y., Du, J., Dai, L.-R., and Lee, C.-H.
\newblock An experimental study on speech enhancement based on deep neural
  networks.
\newblock \emph{IEEE Signal processing letters}, 21\penalty0 (1):\penalty0
  65--68, 2014.

\bibitem[Xu et~al.(2015)Xu, Du, Dai, and Lee]{xu2015regression}
Xu, Y., Du, J., Dai, L.-R., and Lee, C.-H.
\newblock A regression approach to speech enhancement based on deep neural
  networks.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 23\penalty0 (1):\penalty0 7--19, 2015.

\bibitem[Zhang et~al.(2018)Zhang, Zhang, and Gao]{zhang2018training}
Zhang, H., Zhang, X., and Gao, G.
\newblock Training supervised speech separation system to improve stoi and pesq
  directly.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp.\  5374--5378, 2018.

\bibitem[Zhao et~al.(2018{\natexlab{a}})Zhao, Xu, Giri, and
  Zhang]{zhao2018perceptually}
Zhao, Y., Xu, B., Giri, R., and Zhang, T.
\newblock Perceptually guided speech enhancement using deep neural networks.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp.\  5074--5078, 2018{\natexlab{a}}.

\bibitem[Zhao et~al.(2018{\natexlab{b}})Zhao, Liu, and
  Fingscheidt]{zhao2018convolutional}
Zhao, Z., Liu, H., and Fingscheidt, T.
\newblock Convolutional neural networks to enhance coded speech.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 2018{\natexlab{b}}.

\end{thebibliography}
