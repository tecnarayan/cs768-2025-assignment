\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Acharya et~al.(2019)Acharya, Kafle, and Kanan]{acharya2019tallyqa}
M.~Acharya, K.~Kafle, and C.~Kanan.
\newblock Tallyqa: Answering complex counting questions.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, volume~33, pages 8076--8084, 2019.

\bibitem[Betker et~al.(2023)Betker, Goh, Jing, Brooks, Wang, Li, Ouyang,
  Zhuang, Lee, Guo, et~al.]{betker2023improving}
J.~Betker, G.~Goh, L.~Jing, T.~Brooks, J.~Wang, L.~Li, L.~Ouyang, J.~Zhuang,
  J.~Lee, Y.~Guo, et~al.
\newblock Improving image generation with better captions.
\newblock \emph{Computer Science. https://cdn. openai.
  com/papers/dall-e-3.pdf}, 2\penalty0 (3):\penalty0 8, 2023.

\bibitem[Beyer* et~al.(2024)Beyer*, Steiner*, Susano~Pinto*, Kolesnikov*,
  Wang*, Salz, Neumann, Alabdulmohsin, Tschannen, Bugliarello, Unterthiner,
  Keysers, Gritsenko, Chen, Koppula, Grycner, Bauer, Bošnjak, Liu, Houlsby,
  Kumar, Rong, Eisenschlos, Minderer, Voigtlaender, Bica, Balazevic,
  Puigcerver, Papalampidi, Henaff, Xiong, Soricut, Harmsen, and
  Zhai*]{paligemma}
L.~Beyer*, A.~Steiner*, A.~Susano~Pinto*, A.~Kolesnikov*, X.~Wang*, D.~Salz,
  M.~Neumann, I.~Alabdulmohsin, M.~Tschannen, E.~Bugliarello, T.~Unterthiner,
  D.~Keysers, A.~Gritsenko, X.~Chen, S.~Koppula, A.~Grycner, M.~Bauer,
  M.~Bošnjak, F.~Liu, N.~Houlsby, M.~Kumar, K.~Rong, J.~Eisenschlos,
  M.~Minderer, P.~Voigtlaender, I.~Bica, I.~Balazevic, J.~Puigcerver,
  P.~Papalampidi, O.~Henaff, X.~Xiong, R.~Soricut, J.~Harmsen, and X.~Zhai*.
\newblock {PaliGemma: A versatile 3B VLM for transfer}, 2024.
\newblock To appear.

\bibitem[Chang et~al.(2023)Chang, Zhang, Barber, Maschinot, Lezama, Jiang,
  Yang, Murphy, Freeman, Rubinstein, Li, and Krishnan]{pmlr-v202-chang23b}
H.~Chang, H.~Zhang, J.~Barber, A.~Maschinot, J.~Lezama, L.~Jiang, M.-H. Yang,
  K.~P. Murphy, W.~T. Freeman, M.~Rubinstein, Y.~Li, and D.~Krishnan.
\newblock Muse: Text-to-image generation via masked generative transformers.
\newblock In A.~Krause, E.~Brunskill, K.~Cho, B.~Engelhardt, S.~Sabato, and
  J.~Scarlett, editors, \emph{Proceedings of the 40th International Conference
  on Machine Learning}, volume 202 of \emph{Proceedings of Machine Learning
  Research}, pages 4055--4075. PMLR, 23--29 Jul 2023.
\newblock URL \url{https://proceedings.mlr.press/v202/chang23b.html}.

\bibitem[Changpinyo et~al.(2021)Changpinyo, Sharma, Ding, and
  Soricut]{changpinyo2021conceptual}
S.~Changpinyo, P.~Sharma, N.~Ding, and R.~Soricut.
\newblock Conceptual 12m: Pushing web-scale image-text pre-training to
  recognize long-tail visual concepts.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 3558--3568, 2021.

\bibitem[Chen et~al.(2015)Chen, Fang, Lin, Vedantam, Gupta, Doll{\'a}r, and
  Zitnick]{chen2015microsoft}
X.~Chen, H.~Fang, T.-Y. Lin, R.~Vedantam, S.~Gupta, P.~Doll{\'a}r, and C.~L.
  Zitnick.
\newblock Microsoft coco captions: Data collection and evaluation server.
\newblock \emph{arXiv preprint arXiv:1504.00325}, 2015.

\bibitem[Chen et~al.(2022)Chen, Wang, Changpinyo, Piergiovanni, Padlewski,
  Salz, Goodman, Grycner, Mustafa, Beyer, et~al.]{chen2022pali}
X.~Chen, X.~Wang, S.~Changpinyo, A.~Piergiovanni, P.~Padlewski, D.~Salz,
  S.~Goodman, A.~Grycner, B.~Mustafa, L.~Beyer, et~al.
\newblock Pali: A jointly-scaled multilingual language-image model.
\newblock \emph{arXiv preprint arXiv:2209.06794}, 2022.

\bibitem[Chen et~al.(2023)Chen, Wang, Beyer, Kolesnikov, Wu, Voigtlaender,
  Mustafa, Goodman, Alabdulmohsin, Padlewski, Salz, Xiong, Vlasic, Pavetic,
  Rong, Yu, Keysers, Zhai, and Soricut]{chen2023pali3}
X.~Chen, X.~Wang, L.~Beyer, A.~Kolesnikov, J.~Wu, P.~Voigtlaender, B.~Mustafa,
  S.~Goodman, I.~Alabdulmohsin, P.~Padlewski, D.~Salz, X.~Xiong, D.~Vlasic,
  F.~Pavetic, K.~Rong, T.~Yu, D.~Keysers, X.~Zhai, and R.~Soricut.
\newblock Pali-3 vision language models: Smaller, faster, stronger, 2023.

\bibitem[Cho et~al.(2023{\natexlab{a}})Cho, Hu, Baldridge, Garg, Anderson,
  Krishna, Bansal, Pont-Tuset, and Wang]{cho2023davidsonian}
J.~Cho, Y.~Hu, J.~M. Baldridge, R.~Garg, P.~Anderson, R.~Krishna, M.~Bansal,
  J.~Pont-Tuset, and S.~Wang.
\newblock Davidsonian scene graph: Improving reliability in fine-grained
  evaluation for text-image generation.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations}, 2023{\natexlab{a}}.

\bibitem[Cho et~al.(2023{\natexlab{b}})Cho, Zala, and Bansal]{cho2024visual}
J.~Cho, A.~Zala, and M.~Bansal.
\newblock Visual programming for step-by-step text-to-image generation and
  evaluation.
\newblock \emph{Advances in Neural Information Processing Systems}, 37,
  2023{\natexlab{b}}.

\bibitem[Gelman and Gallistel(1986)]{gelman1986child}
R.~Gelman and C.~R. Gallistel.
\newblock \emph{The child’s understanding of number}.
\newblock Harvard University Press, 1986.

\bibitem[Gemma~Team et~al.(2024)Gemma~Team, Hardin, Dadashi, Bhupatiraju,
  Sifre, Rivière, Kale, Love, Tafti, Hussenot, and et~al.]{gemma2024}
T.~M. Gemma~Team, C.~Hardin, R.~Dadashi, S.~Bhupatiraju, L.~Sifre, M.~Rivière,
  M.~S. Kale, J.~Love, P.~Tafti, L.~Hussenot, and et~al.
\newblock Gemma.
\newblock 2024.
\newblock \doi{10.34740/KAGGLE/M/3301}.
\newblock URL \url{https://www.kaggle.com/m/3301}.

\bibitem[Gokhale et~al.(2022)Gokhale, Palangi, Nushi, Vineet, Horvitz, Kamar,
  Baral, and Yang]{gokhale2022benchmarking}
T.~Gokhale, H.~Palangi, B.~Nushi, V.~Vineet, E.~Horvitz, E.~Kamar, C.~Baral,
  and Y.~Yang.
\newblock Benchmarking spatial relationships in text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2212.10015}, 2022.

\bibitem[Hessel et~al.(2021)Hessel, Holtzman, Forbes, Bras, and
  Choi]{hessel2021clipscore}
J.~Hessel, A.~Holtzman, M.~Forbes, R.~L. Bras, and Y.~Choi.
\newblock Clipscore: A reference-free evaluation metric for image captioning.
\newblock \emph{arXiv preprint arXiv:2104.08718}, 2021.

\bibitem[Hu et~al.(2023)Hu, Liu, Kasai, Wang, Ostendorf, Krishna, and
  Smith]{hu2023tifa}
Y.~Hu, B.~Liu, J.~Kasai, Y.~Wang, M.~Ostendorf, R.~Krishna, and N.~A. Smith.
\newblock Tifa: Accurate and interpretable text-to-image faithfulness
  evaluation with question answering.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 20406--20417, 2023.

\bibitem[Huang et~al.(2024)Huang, Sun, Xie, Li, and Liu]{huang2024t2i}
K.~Huang, K.~Sun, E.~Xie, Z.~Li, and X.~Liu.
\newblock T2i-compbench: A comprehensive benchmark for open-world compositional
  text-to-image generation.
\newblock 36, 2024.

\bibitem[Lee et~al.(2024)Lee, Yasunaga, Meng, Mai, Park, Gupta, Zhang,
  Narayanan, Teufel, Bellagente, et~al.]{lee2024holistic}
T.~Lee, M.~Yasunaga, C.~Meng, Y.~Mai, J.~S. Park, A.~Gupta, Y.~Zhang,
  D.~Narayanan, H.~Teufel, M.~Bellagente, et~al.
\newblock Holistic evaluation of text-to-image models.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Leivada et~al.(2023)Leivada, Murphy, and Marcus]{leivada2023dall}
E.~Leivada, E.~Murphy, and G.~Marcus.
\newblock Dall{\textperiodcentered} e 2 fails to reliably capture common
  syntactic processes.
\newblock \emph{Social Sciences \& Humanities Open}, 8\penalty0 (1):\penalty0
  100648, 2023.

\bibitem[Lison and Tiedemann(2016)]{lison2016opensubtitles2016}
P.~Lison and J.~Tiedemann.
\newblock Opensubtitles2016: Extracting large parallel corpora from movie and
  tv subtitles.
\newblock 2016.

\bibitem[Paiss et~al.(2023)Paiss, Ephrat, Tov, Zada, Mosseri, Irani, and
  Dekel]{paiss2023teaching}
R.~Paiss, A.~Ephrat, O.~Tov, S.~Zada, I.~Mosseri, M.~Irani, and T.~Dekel.
\newblock Teaching clip to count to ten.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 3170--3180, 2023.

\bibitem[Podell et~al.(2023)Podell, English, Lacey, Blattmann, Dockhorn,
  M{\"u}ller, Penna, and Rombach]{podell2023sdxl}
D.~Podell, Z.~English, K.~Lacey, A.~Blattmann, T.~Dockhorn, J.~M{\"u}ller,
  J.~Penna, and R.~Rombach.
\newblock Sdxl: Improving latent diffusion models for high-resolution image
  synthesis.
\newblock \emph{arXiv preprint arXiv:2307.01952}, 2023.

\bibitem[Rane et~al.()Rane, Ku, Baldridge, Tenney, Griffiths, and
  Kim]{rane2024can}
S.~Rane, A.~Ku, J.~M. Baldridge, I.~Tenney, T.~L. Griffiths, and B.~Kim.
\newblock Can generative multimodal models count to ten?
\newblock In \emph{ICLR 2024 Workshop on Reliable and Responsible Foundation
  Models}.

\bibitem[Rombach et~al.(2022{\natexlab{a}})Rombach, Blattmann, Lorenz, Esser,
  and Ommer]{Rombach2022CVPR}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser, and B.~Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 10684--10695, June 2022{\natexlab{a}}.

\bibitem[Rombach et~al.(2022{\natexlab{b}})Rombach, Blattmann, Lorenz, Esser,
  and Ommer]{rombach2022high}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser, and B.~Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 10684--10695, 2022{\natexlab{b}}.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton,
  Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans,
  et~al.]{saharia2022photorealistic}
C.~Saharia, W.~Chan, S.~Saxena, L.~Li, J.~Whang, E.~L. Denton, K.~Ghasemipour,
  R.~Gontijo~Lopes, B.~Karagol~Ayan, T.~Salimans, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language
  understanding.
\newblock 35:\penalty0 36479--36494, 2022.

\bibitem[Shipley and Shepperson(1990)]{SHIPLEY1990109}
E.~F. Shipley and B.~Shepperson.
\newblock Countable entities: Developmental changes.
\newblock \emph{Cognition}, 34\penalty0 (2):\penalty0 109--136, 1990.
\newblock ISSN 0010-0277.
\newblock \doi{https://doi.org/10.1016/0010-0277(90)90041-H}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/001002779090041H}.

\bibitem[Singh and Strouse(2024)]{singh2024tokenization}
A.~K. Singh and D.~Strouse.
\newblock Tokenization counts: the impact of tokenization on arithmetic in
  frontier llms.
\newblock \emph{arXiv preprint arXiv:2402.14903}, 2024.

\bibitem[Speer(2022)]{robyn_speer_2022_7199437}
R.~Speer.
\newblock rspeer/wordfreq: v3.0, Sept. 2022.
\newblock URL \url{https://doi.org/10.5281/zenodo.7199437}.

\bibitem[Trott et~al.(2018)Trott, Xiong, and Socher]{trott2018howmanyqa}
A.~Trott, C.~Xiong, and R.~Socher.
\newblock Interpretable counting for visual question answering.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=S1J2ZyZ0Z}.

\bibitem[Tuo et~al.(2023)Tuo, Xiang, He, Geng, and Xie]{tuo2023anytext}
Y.~Tuo, W.~Xiang, J.-Y. He, Y.~Geng, and X.~Xie.
\newblock Anytext: Multilingual visual text generation and editing.
\newblock \emph{arXiv preprint arXiv:2311.03054}, 2023.

\bibitem[Vasconcelos et~al.(2024)Vasconcelos, Waters, Walker, Xu, Yan, Qian,
  Luo, Parekh, Bunner, Fei, et~al.]{vasconcelos2024greedy}
C.~N. Vasconcelos, A.~R.~A. Waters, T.~Walker, K.~Xu, J.~Yan, R.~Qian, S.~Luo,
  Z.~Parekh, A.~Bunner, H.~Fei, et~al.
\newblock Greedy growing enables high-resolution pixel-based diffusion models.
\newblock \emph{arXiv preprint arXiv:2405.16759}, 2024.

\bibitem[Wellman and Miller(1986)]{wellman1986thinking}
H.~M. Wellman and K.~F. Miller.
\newblock Thinking about nothing: Development of concepts of zero.
\newblock \emph{British Journal of Developmental Psychology}, 4\penalty0
  (1):\penalty0 31--42, 1986.

\bibitem[Wiles et~al.(2024)Wiles, Zhang, Albuquerque, Kaji{\'c}, Wang,
  Bugliarello, Onoe, Knutsen, Rashtchian, Pont-Tuset,
  et~al.]{wiles2024revisiting}
O.~Wiles, C.~Zhang, I.~Albuquerque, I.~Kaji{\'c}, S.~Wang, E.~Bugliarello,
  Y.~Onoe, C.~Knutsen, C.~Rashtchian, J.~Pont-Tuset, et~al.
\newblock Revisiting text-to-image evaluation with gecko: On metrics, prompts,
  and human ratings.
\newblock \emph{arXiv preprint arXiv:2404.16820}, 2024.

\bibitem[Woodruff and Premack(1981)]{woodruff1981primative}
G.~Woodruff and D.~Premack.
\newblock Primative mathematical concepts in the chimpanzee: proportionality
  and numerosity.
\newblock \emph{Nature}, 293\penalty0 (5833):\penalty0 568--570, 1981.

\bibitem[Yarom et~al.(2023)Yarom, Bitton, Changpinyo, Aharoni, Herzig, Lang,
  Ofek, and Szpektor]{yarom2024you}
M.~Yarom, Y.~Bitton, S.~Changpinyo, R.~Aharoni, J.~Herzig, O.~Lang, E.~Ofek,
  and I.~Szpektor.
\newblock What you see is what you read? improving text-image alignment
  evaluation.
\newblock \emph{Advances in Neural Information Processing Systems}, 37, 2023.

\bibitem[Yu et~al.(2022)Yu, Xu, Koh, Luong, Baid, Wang, Vasudevan, Ku, Yang,
  Ayan, et~al.]{yu2022scaling}
J.~Yu, Y.~Xu, J.~Y. Koh, T.~Luong, G.~Baid, Z.~Wang, V.~Vasudevan, A.~Ku,
  Y.~Yang, B.~K. Ayan, et~al.
\newblock Scaling autoregressive models for content-rich text-to-image
  generation.
\newblock \emph{arXiv preprint arXiv:2206.10789}, 2\penalty0 (3):\penalty0 5,
  2022.

\bibitem[Zhai et~al.(2023)Zhai, Mustafa, Kolesnikov, and Beyer]{zhai2023siglip}
X.~Zhai, B.~Mustafa, A.~Kolesnikov, and L.~Beyer.
\newblock Sigmoid loss for language image pre-training.
\newblock \emph{International Conference on Computer Vision ({ICCV})}, 2023.

\end{thebibliography}
