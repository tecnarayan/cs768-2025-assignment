\begin{thebibliography}{43}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anwar et~al.(2017)Anwar, Hwang, and Sung]{structuredpruning}
Sajid Anwar, Kyuyeon Hwang, and Wonyong Sung.
\newblock Structured pruning of deep convolutional neural networks.
\newblock \emph{J. Emerg. Technol. Comput. Syst.}, 13\penalty0 (3), feb 2017.
\newblock ISSN 1550-4832.
\newblock \doi{10.1145/3005348}.

\bibitem[Bartlett et~al.(2017)Bartlett, Foster, and
  Telgarsky]{bartlett2017spectrallynormalized}
Peter~L Bartlett, Dylan~J Foster, and Matus~J Telgarsky.
\newblock Spectrally-normalized margin bounds for neural networks.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Blackford et~al.(2002)Blackford, Petitet, Pozo, Remington, Whaley,
  Demmel, Dongarra, Duff, Hammarling, Henry, et~al.]{blackford2002updated}
L~Susan Blackford, Antoine Petitet, Roldan Pozo, Karin Remington, R~Clint
  Whaley, James Demmel, Jack Dongarra, Iain Duff, Sven Hammarling, Greg Henry,
  et~al.
\newblock An updated set of basic linear algebra subprograms (blas).
\newblock \emph{ACM Transactions on Mathematical Software}, 28\penalty0
  (2):\penalty0 135--151, 2002.

\bibitem[Chellapilla et~al.(2006)Chellapilla, Puri, and
  Simard]{chellapilla2006high}
Kumar Chellapilla, Sidd Puri, and Patrice Simard.
\newblock High performance convolutional neural networks for document
  processing.
\newblock In \emph{Tenth international workshop on frontiers in handwriting
  recognition}. Suvisoft, 2006.

\bibitem[Cisse et~al.(2017)Cisse, Bojanowski, Grave, Dauphin, and
  Usunier]{cisse2017parseval}
Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin, and Nicolas
  Usunier.
\newblock Parseval networks: Improving robustness to adversarial examples.
\newblock In \emph{International Conference on Machine Learning}, pages
  854--863. PMLR, 2017.

\bibitem[Croce and Hein(2020)]{autoattack}
Francesco Croce and Matthias Hein.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock In \emph{International conference on machine learning}, pages
  2206--2216. PMLR, 2020.

\bibitem[Frankle and Carbin(2019)]{lotterytickethypothesis}
Jonathan Frankle and Michael Carbin.
\newblock The lottery ticket hypothesis: Finding sparse, trainable neural
  networks.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Garipov et~al.(2016)Garipov, Podoprikhin, Novikov, and
  Vetrov]{DBLP:journals/corr/GaripovPNV16}
Timur Garipov, Dmitry Podoprikhin, Alexander Novikov, and Dmitry~P. Vetrov.
\newblock Ultimate tensorization: compressing convolutional and {FC} layers
  alike.
\newblock \emph{CoRR}, abs/1611.03214, 2016.

\bibitem[Goodfellow et~al.(2020)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{gan}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial networks.
\newblock \emph{Communications of the ACM}, 63\penalty0 (11):\penalty0
  139--144, 2020.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{Goodfellow2015ExplainingAH}
Ian~J. Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{CoRR}, abs/1412.6572, 2015.

\bibitem[Gouk et~al.(2021)Gouk, Frank, Pfahringer, and
  Cree]{gouk2020regularisation}
Henry Gouk, Eibe Frank, Bernhard Pfahringer, and Michael~J Cree.
\newblock Regularisation of neural networks by enforcing lipschitz continuity.
\newblock \emph{Machine Learning}, 110\penalty0 (2):\penalty0 393--416, 2021.

\bibitem[Grasedyck et~al.(2013)Grasedyck, Kressner, and
  Tobler]{grasedyck2013literature}
Lars Grasedyck, Daniel Kressner, and Christine Tobler.
\newblock A literature survey of low-rank tensor approximation techniques.
\newblock \emph{GAMM-Mitteilungen}, 36\penalty0 (1):\penalty0 53--78, 2013.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{Guo2017OnCO}
Chuan Guo, Geoff Pleiss, Yu~Sun, and Kilian~Q Weinberger.
\newblock On calibration of modern neural networks.
\newblock In \emph{International conference on machine learning}, pages
  1321--1330. PMLR, 2017.

\bibitem[Gusak et~al.(2022)Gusak, Cherniuk, Shilova, Katrutsa, Bershatsky,
  Zhao, Eyraud-Dubois, Shliazhko, Dimitrov, Oseledets, and
  Beaumont]{ijcai2022p769}
Julia Gusak, Daria Cherniuk, Alena Shilova, Alexandr Katrutsa, Daniel
  Bershatsky, Xunyi Zhao, Lionel Eyraud-Dubois, Oleh Shliazhko, Denis Dimitrov,
  Ivan Oseledets, and Olivier Beaumont.
\newblock Survey on efficient training of large neural networks.
\newblock In \emph{Proceedings of the Thirty-First International Joint
  Conference on Artificial Intelligence, {IJCAI-22}}, pages 5494--5501, 7 2022.
\newblock \doi{10.24963/ijcai.2022/769}.

\bibitem[Hendrycks and Dietterich(2019)]{hendrycks2019robustness}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock \emph{Proceedings of the International Conference on Learning
  Representations}, 2019.

\bibitem[Holtz et~al.(2012)Holtz, Rohwedder, and Schneider]{holtz2012manifolds}
Sebastian Holtz, Thorsten Rohwedder, and Reinhold Schneider.
\newblock On manifolds of tensors of fixed tt-rank.
\newblock \emph{Numerische Mathematik}, 120\penalty0 (4):\penalty0 701--731,
  2012.

\bibitem[Jain(1989)]{Jain}
A.~K. Jain.
\newblock \emph{Fundamentals of digital image processing}.
\newblock Englewood Cliffs, NJ: Prentice Hall, 1989.

\bibitem[Kanakis et~al.(2020)Kanakis, Bruggemann, Saha, Georgoulis, Obukhov,
  and Gool]{KanakisBSGOG20}
Menelaos Kanakis, David Bruggemann, Suman Saha, Stamatios Georgoulis, Anton
  Obukhov, and Luc~Van Gool.
\newblock Reparameterizing convolutions for incremental multi-task learning
  without task interference.
\newblock In \emph{Computer Vision - {ECCV} 2020}, volume 12365, pages
  689--707. Springer, 2020.

\bibitem[Kim et~al.(2016)Kim, Park, Yoo, Choi, Yang, and Shin]{tucker}
Yong-Deok Kim, Eunhyeok Park, Sungjoo Yoo, Taelim Choi, Lu~Yang, and Dongjun
  Shin.
\newblock Compression of deep convolutional neural networks for fast and low
  power mobile applications.
\newblock In \emph{4th International Conference on Learning Representations,
  {ICLR} 2016}, 05 2016.

\bibitem[Kodryan et~al.(2022)Kodryan, Lobacheva, Nakhodnov, and
  Vetrov]{vetrov2022}
Maxim Kodryan, Ekaterina Lobacheva, Maksim Nakhodnov, and Dmitry Vetrov.
\newblock Training scale-invariant neural networks on the sphere can happen in
  three regimes.
\newblock In \emph{Advances in Neural Information Processing Systems, 35},
  2022.

\bibitem[Kostenetskiy et~al.(2021)Kostenetskiy, Chulkevich, and
  Kozyrev]{kostenetskiy2021hpc}
PS~Kostenetskiy, RA~Chulkevich, and VI~Kozyrev.
\newblock Hpc resources of the higher school of economics.
\newblock In \emph{Journal of Physics: Conference Series}, volume 1740, page
  012050, 2021.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images, 2009.

\bibitem[LeCun et~al.(1989)LeCun, Boser, Denker, Henderson, Howard, Hubbard,
  and Jackel]{lecun}
Y.~LeCun, B.~Boser, J.~S. Denker, D.~Henderson, R.~E. Howard, W.~Hubbard, and
  L.~D. Jackel.
\newblock Backpropagation applied to handwritten zip code recognition.
\newblock \emph{Neural Computation}, 1\penalty0 (4):\penalty0 541--551, 1989.

\bibitem[Lee et~al.(2019)Lee, Ajanthan, and Torr]{lee2018snip}
Namhoon Lee, Thalaiyasingam Ajanthan, and Philip Torr.
\newblock Snip: Single-shot network pruning based on connection sensitivity.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Li et~al.(2019)Li, Haque, Anil, Lucas, Grosse, and Jacobsen]{BCOP}
Qiyang Li, Saminul Haque, Cem Anil, James Lucas, Roger~B Grosse, and
  J{\"o}rn-Henrik Jacobsen.
\newblock Preventing gradient attenuation in lipschitz constrained
  convolutional networks.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Liu et~al.(2019)Liu, Tang, Zhou, and Qiu]{liu2019spectral}
Kanglin Liu, Wenming Tang, Fei Zhou, and Guoping Qiu.
\newblock Spectral regularization for combating mode collapse in gans.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 6382--6390, 2019.

\bibitem[Naeini et~al.(2015)Naeini, Cooper, and Hauskrecht]{ECEintro}
Mahdi~Pakdaman Naeini, Gregory~F Cooper, and Milos Hauskrecht.
\newblock Obtaining well calibrated probabilities using bayesian binning.
\newblock In \emph{AAAI}, page 2901{\textendash}2907, 2015.

\bibitem[Novikov et~al.(2015)Novikov, Podoprikhin, Osokin, and
  Vetrov]{NIPS2015_6855456e}
Alexander Novikov, Dmitrii Podoprikhin, Anton Osokin, and Dmitry~P Vetrov.
\newblock Tensorizing neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~28. Curran Associates, Inc., 2015.

\bibitem[Obukhov et~al.(2020)Obukhov, Rakhuba, Georgoulis, Kanakis, Dai, and
  Van~Gool]{obukhov2020tbasis}
Anton Obukhov, Maxim Rakhuba, Stamatios Georgoulis, Menelaos Kanakis, Dengxin
  Dai, and Luc Van~Gool.
\newblock T-basis: a compact representation for neural networks.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, volume 119, pages 7392--7404. PMLR, 2020.

\bibitem[Obukhov et~al.(2021)Obukhov, Rakhuba, Liniger, Huang, Georgoulis, Dai,
  and Van~Gool]{obukhov2021spectral}
Anton Obukhov, Maxim Rakhuba, Alexander Liniger, Zhiwu Huang, Stamatios
  Georgoulis, Dengxin Dai, and Luc Van~Gool.
\newblock Spectral tensor train parameterization of deep learning layers.
\newblock In \emph{Proceedings of The 24th International Conference on
  Artificial Intelligence and Statistics}, volume 130, pages 3547--3555. PMLR,
  2021.

\bibitem[Obukhov et~al.(2022)Obukhov, Usvyatsov, Sakaridis, Schindler, and
  Van~Gool]{obukhov2022ttnf}
Anton Obukhov, Mikhail Usvyatsov, Christos Sakaridis, Konrad Schindler, and Luc
  Van~Gool.
\newblock Tt-nf: Tensor train neural fields, 2022.

\bibitem[Oseledets(2011)]{oseledets2011tensor}
Ivan~V Oseledets.
\newblock Tensor-train decomposition.
\newblock \emph{SIAM Journal on Scientific Computing}, 33\penalty0
  (5):\penalty0 2295--2317, 2011.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems 32}, pages 8024--8035. Curran Associates,
  Inc., 2019.

\bibitem[Postels et~al.(2022)Postels, Seg{\`u}, Sun, Sieber, Van~Gool, Yu, and
  Tombari]{postels21deu}
Janis Postels, Mattia Seg{\`u}, Tao Sun, Luca~Daniel Sieber, Luc Van~Gool,
  Fisher Yu, and Federico Tombari.
\newblock On the practicality of deterministic epistemic uncertainty.
\newblock In \emph{Proceedings of the 39th International Conference on Machine
  Learning}, volume 162, pages 17870--17909. PMLR, 2022.

\bibitem[Sanyal et~al.(2020)Sanyal, Torr, and Dokania]{Sanyal2020StableRN}
Amartya Sanyal, Philip~H. Torr, and Puneet~K. Dokania.
\newblock Stable rank normalization for improved generalization in neural
  networks and gans.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Sedghi et~al.(2019)Sedghi, Gupta, and Long]{sedghi2019singular}
Hanie Sedghi, Vineet Gupta, and Philip~M. Long.
\newblock The singular values of convolutional layers.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Simonyan and Zisserman(2015)]{vgg}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Singla and Feizi(2021{\natexlab{a}})]{singla2021fantastic}
Sahil Singla and Soheil Feizi.
\newblock Fantastic four: Differentiable and efficient bounds on singular
  values of convolution layers.
\newblock In \emph{International Conference on Learning Representations},
  2021{\natexlab{a}}.

\bibitem[Singla and Feizi(2021{\natexlab{b}})]{singla2021skew}
Sahil Singla and Soheil Feizi.
\newblock Skew orthogonal convolutions.
\newblock In \emph{International Conference on Machine Learning}, pages
  9756--9766. PMLR, 2021{\natexlab{b}}.

\bibitem[Sozykin et~al.(2022)Sozykin, Chertkov, Schutski, Phan, Cichocki, and
  Oseledets]{ttopt2022}
Konstantin Sozykin, Andrei Chertkov, Roman Schutski, Anh-Huy Phan, Andrzej
  Cichocki, and Ivan Oseledets.
\newblock {TTO}pt: A maximum volume quantized tensor train-based optimization
  and its application to reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems, 35},
  2022.

\bibitem[Wang et~al.(2018)Wang, Sun, Eriksson, Wang, and
  Aggarwal]{DBLP:journals/corr/abs-1802-09052}
Wenqi Wang, Yifan Sun, Brian Eriksson, Wenlin Wang, and Vaneet Aggarwal.
\newblock Wide compression: Tensor ring nets.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 9329--9338, 2018.

\bibitem[Yoshida and Miyato(2017)]{yoshida2017spectral}
Yuichi Yoshida and Takeru Miyato.
\newblock Spectral norm regularization for improving the generalizability of
  deep learning, 2017.

\bibitem[Zagoruyko and Komodakis(2016)]{Zagoruyko2016WideRN}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Wide residual networks.
\newblock In \emph{Proceedings of the British Machine Vision Conference
  (BMVC)}, pages 87.1--87.12. BMVA Press, September 2016.

\end{thebibliography}
