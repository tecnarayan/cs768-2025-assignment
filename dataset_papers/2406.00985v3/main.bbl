\begin{thebibliography}{10}

\bibitem{ju2023direct}
Xuan Ju, Ailing Zeng, Yuxuan Bian, Shaoteng Liu, and Qiang Xu.
\newblock Direct inversion: Boosting diffusion-based editing with 3 lines of code.
\newblock 2023.

\bibitem{xu2023inversion}
Sihan Xu, Yidong Huang, Jiayi Pan, Ziqiao Ma, and Joyce Chai.
\newblock Inversion-free image editing with natural language.
\newblock {\em arXiv preprint arXiv:2312.04965}, 2023.

\bibitem{hertz2022prompt}
Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or.
\newblock Prompt-to-prompt image editing with cross attention control.
\newblock 2022.

\bibitem{cao_2023_masactrl}
Mingdeng Cao, Xintao Wang, Zhongang Qi, Ying Shan, Xiaohu Qie, and Yinqiang Zheng.
\newblock Masactrl: Tuning-free mutual self-attention control for consistent image synthesis and editing.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, pages 22560--22570, October 2023.

\bibitem{li2023referring}
Jizhizi Li, Jing Zhang, and Dacheng Tao.
\newblock Referring image matting.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 22448--22457, 2023.

\bibitem{liu2021tripartite}
Yuhao Liu, Jiake Xie, Xiao Shi, Yu~Qiao, Yujie Huang, Yong Tang, and Xin Yang.
\newblock Tripartite information mining and integration for image matting.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 7555--7564, 2021.

\bibitem{gu2022vector}
Shuyang Gu, Dong Chen, Jianmin Bao, Fang Wen, Bo~Zhang, Dongdong Chen, Lu~Yuan, and Baining Guo.
\newblock Vector quantized diffusion model for text-to-image synthesis.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 10696--10706, 2022.

\bibitem{ding2022cogview2}
Ming Ding, Wendi Zheng, Wenyi Hong, and Jie Tang.
\newblock Cogview2: Faster and better text-to-image generation via hierarchical transformers.
\newblock {\em Advances in Neural Information Processing Systems}, 35:16890--16902, 2022.

\bibitem{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 10684--10695, 2022.

\bibitem{couairon2023diffedit}
Guillaume Couairon, Jakob Verbeek, Holger Schwenk, and Matthieu Cord.
\newblock Diffedit: Diffusion-based semantic image editing with mask guidance.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2023.

\bibitem{parmar2023zero}
Gaurav Parmar, Krishna Kumar~Singh, Richard Zhang, Yijun Li, Jingwan Lu, and Jun-Yan Zhu.
\newblock Zero-shot image-to-image translation.
\newblock In {\em ACM SIGGRAPH 2023 Conference Proceedings}, pages 1--11, 2023.

\bibitem{kawar2023imagic}
Bahjat Kawar, Shiran Zada, Oran Lang, Omer Tov, Huiwen Chang, Tali Dekel, Inbar Mosseri, and Michal Irani.
\newblock Imagic: Text-based real image editing with diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 6007--6017, 2023.

\bibitem{couairon2022diffedit}
Guillaume Couairon, Jakob Verbeek, Holger Schwenk, and Matthieu Cord.
\newblock Diffedit: Diffusion-based semantic image editing with mask guidance.
\newblock {\em arXiv preprint arXiv:2210.11427}, 2022.

\bibitem{nguyen2024visual}
Thao Nguyen, Yuheng Li, Utkarsh Ojha, and Yong~Jae Lee.
\newblock Visual instruction inversion: Image editing via image prompting.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2023.

\bibitem{lugmayr2022repaint}
Andreas Lugmayr, Martin Danelljan, Andres Romero, Fisher Yu, Radu Timofte, and Luc Van~Gool.
\newblock Repaint: Inpainting using denoising diffusion probabilistic models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 11461--11471, 2022.

\bibitem{avrahami2022blended}
Omri Avrahami, Dani Lischinski, and Ohad Fried.
\newblock Blended diffusion for text-driven editing of natural images.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 18208--18218, 2022.

\bibitem{nichol2021glide}
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen.
\newblock Glide: Towards photorealistic image generation and editing with text-guided diffusion models.
\newblock {\em arXiv preprint arXiv:2112.10741}, 2021.

\bibitem{choi2021ilvr}
Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, and Sungroh Yoon.
\newblock Ilvr: Conditioning method for denoising diffusion probabilistic models.
\newblock {\em arXiv preprint arXiv:2108.02938}, 2021.

\bibitem{xu2024cyclenet}
Sihan Xu, Ziqiao Ma, Yidong Huang, Honglak Lee, and Joyce Chai.
\newblock Cyclenet: Rethinking cycle consistency in text-guided diffusion for image manipulation.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{zhao2022egsde}
Min Zhao, Fan Bao, Chongxuan Li, and Jun Zhu.
\newblock Egsde: Unpaired image-to-image translation via energy-guided stochastic differential equations.
\newblock {\em Advances in Neural Information Processing Systems}, 35:3609--3623, 2022.

\bibitem{tumanyan2023plug}
Narek Tumanyan, Michal Geyer, Shai Bagon, and Tali Dekel.
\newblock Plug-and-play diffusion features for text-driven image-to-image translation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 1921--1930, 2023.

\bibitem{wang2022maniclip}
Hao Wang, Guosheng Lin, Ana~Garc{\'\i}a del Molino, Anran Wang, Zehuan Yuan, Chunyan Miao, and Jiashi Feng.
\newblock Maniclip: Multi-attribute face manipulation from text.
\newblock {\em arXiv preprint arXiv:2210.00445}, 2022.

\bibitem{khodadadeh2022latent}
Siavash Khodadadeh, Shabnam Ghadar, Saeid Motiian, Wei-An Lin, Ladislau B{\"o}l{\"o}ni, and Ratheesh Kalarot.
\newblock Latent to latent: A learned mapper for identity preserving editing of multiple face attributes in stylegan-generated images.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pages 3184--3192, 2022.

\bibitem{karras2020analyzing}
Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila.
\newblock Analyzing and improving the image quality of stylegan.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 8110--8119, 2020.

\bibitem{ge2023expressive}
Songwei Ge, Taesung Park, Jun-Yan Zhu, and Jia-Bin Huang.
\newblock Expressive text-to-image generation with rich text.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 7545--7556, 2023.

\bibitem{chang2024ground}
Hangeol Chang, Jinho Chang, and Jong~Chul Ye.
\newblock Ground-a-score: Scaling up the score distillation for multi-attribute editing.
\newblock {\em arXiv preprint arXiv:2403.13551}, 2024.

\bibitem{joseph2024iterative}
KJ~Joseph, Prateksha Udhayanan, Tripti Shukla, Aishwarya Agarwal, Srikrishna Karanam, Koustava Goswami, and Balaji~Vasan Srinivasan.
\newblock Iterative multi-granular image editing using diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pages 8107--8116, 2024.

\bibitem{nichol2021improved}
Alexander~Quinn Nichol and Prafulla Dhariwal.
\newblock Improved denoising diffusion probabilistic models.
\newblock In {\em International Conference on Machine Learning}, pages 8162--8171. PMLR, 2021.

\bibitem{chen2023importance}
Ting Chen.
\newblock On the importance of noise scheduling for diffusion models.
\newblock {\em arXiv preprint arXiv:2301.10972}, 2023.

\bibitem{karras2022elucidating}
Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine.
\newblock Elucidating the design space of diffusion-based generative models.
\newblock {\em Advances in Neural Information Processing Systems}, 35:26565--26577, 2022.

\bibitem{song2020denoising}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock {\em arXiv preprint arXiv:2010.02502}, 2020.

\bibitem{song2023consistency}
Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever.
\newblock Consistency models.
\newblock {\em arXiv preprint arXiv:2303.01469}, 2023.

\bibitem{luo2023latent}
Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and Hang Zhao.
\newblock Latent consistency models: Synthesizing high-resolution images with few-step inference.
\newblock {\em arXiv preprint arXiv:2310.04378}, 2023.

\bibitem{mokady2023null}
Ron Mokady, Amir Hertz, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or.
\newblock Null-text inversion for editing real images using guided diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 6038--6047, 2023.

\bibitem{ronneberger2015u}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In {\em Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18}, pages 234--241. Springer, 2015.

\bibitem{tang2022daam}
Raphael Tang, Linqing Liu, Akshat Pandey, Zhiying Jiang, Gefei Yang, Karun Kumar, Pontus Stenetorp, Jimmy Lin, and Ferhan Ture.
\newblock What the daam: Interpreting stable diffusion using cross attention.
\newblock {\em arXiv preprint arXiv:2210.04885}, 2022.

\bibitem{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em European conference on computer vision}, pages 740--755. Springer, 2014.

\bibitem{liu2023llava}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee.
\newblock Visual instruction tuning.
\newblock In {\em NeurIPS}, 2023.

\bibitem{CLIP_radford2021}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In {\em International conference on machine learning}, pages 8748--8763. PMLR, 2021.

\bibitem{zhang2018unreasonable}
Richard Zhang, Phillip Isola, Alexei~A Efros, Eli Shechtman, and Oliver Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual metric.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 586--595, 2018.

\bibitem{wang2004image}
Zhou Wang, Alan~C Bovik, Hamid~R Sheikh, and Eero~P Simoncelli.
\newblock Image quality assessment: from error visibility to structural similarity.
\newblock {\em IEEE transactions on image processing}, 13(4):600--612, 2004.

\bibitem{wu2022unifying}
Chen~Henry Wu and Fernando De~la Torre.
\newblock Unifying diffusion models' latent space, with applications to cyclediffusion and guidance.
\newblock {\em arXiv preprint arXiv:2210.05559}, 2022.

\bibitem{wang2023stylediffusion}
Zhizhong Wang, Lei Zhao, and Wei Xing.
\newblock Stylediffusion: Controllable disentangled style transfer via diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 7677--7689, 2023.

\bibitem{Gpt-4v}
OpenAI.
\newblock Gpt-4v(ision) system card.
\newblock 2023.

\bibitem{mokady2022null}
Ron Mokady, Amir Hertz, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or.
\newblock Null-text inversion for editing real images using guided diffusion models.
\newblock {\em arXiv preprint arXiv:2211.09794}, 2022.

\bibitem{tumanyan2022splicing}
Narek Tumanyan, Omer Bar-Tal, Shai Bagon, and Tali Dekel.
\newblock Splicing vit features for semantic appearance transfer.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 10748--10757, 2022.

\end{thebibliography}
